[
    {
        "cwe": "CWE-191",
        "func_name": "torvalds/deassemble_neg_contexts",
        "score": 0.8157125115394592,
        "func_before": "static __le32 deassemble_neg_contexts(struct ksmbd_conn *conn,\n\t\t\t\t      struct smb2_negotiate_req *req,\n\t\t\t\t      int len_of_smb)\n{\n\t/* +4 is to account for the RFC1001 len field */\n\tstruct smb2_neg_context *pctx = (struct smb2_neg_context *)req;\n\tint i = 0, len_of_ctxts;\n\tint offset = le32_to_cpu(req->NegotiateContextOffset);\n\tint neg_ctxt_cnt = le16_to_cpu(req->NegotiateContextCount);\n\t__le32 status = STATUS_INVALID_PARAMETER;\n\n\tksmbd_debug(SMB, \"decoding %d negotiate contexts\\n\", neg_ctxt_cnt);\n\tif (len_of_smb <= offset) {\n\t\tksmbd_debug(SMB, \"Invalid response: negotiate context offset\\n\");\n\t\treturn status;\n\t}\n\n\tlen_of_ctxts = len_of_smb - offset;\n\n\twhile (i++ < neg_ctxt_cnt) {\n\t\tint clen, ctxt_len;\n\n\t\tif (len_of_ctxts < sizeof(struct smb2_neg_context))\n\t\t\tbreak;\n\n\t\tpctx = (struct smb2_neg_context *)((char *)pctx + offset);\n\t\tclen = le16_to_cpu(pctx->DataLength);\n\t\tctxt_len = clen + sizeof(struct smb2_neg_context);\n\n\t\tif (ctxt_len > len_of_ctxts)\n\t\t\tbreak;\n\n\t\tif (pctx->ContextType == SMB2_PREAUTH_INTEGRITY_CAPABILITIES) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_PREAUTH_INTEGRITY_CAPABILITIES context\\n\");\n\t\t\tif (conn->preauth_info->Preauth_HashId)\n\t\t\t\tbreak;\n\n\t\t\tstatus = decode_preauth_ctxt(conn,\n\t\t\t\t\t\t     (struct smb2_preauth_neg_context *)pctx,\n\t\t\t\t\t\t     ctxt_len);\n\t\t\tif (status != STATUS_SUCCESS)\n\t\t\t\tbreak;\n\t\t} else if (pctx->ContextType == SMB2_ENCRYPTION_CAPABILITIES) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_ENCRYPTION_CAPABILITIES context\\n\");\n\t\t\tif (conn->cipher_type)\n\t\t\t\tbreak;\n\n\t\t\tdecode_encrypt_ctxt(conn,\n\t\t\t\t\t    (struct smb2_encryption_neg_context *)pctx,\n\t\t\t\t\t    ctxt_len);\n\t\t} else if (pctx->ContextType == SMB2_COMPRESSION_CAPABILITIES) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_COMPRESSION_CAPABILITIES context\\n\");\n\t\t\tif (conn->compress_algorithm)\n\t\t\t\tbreak;\n\n\t\t\tdecode_compress_ctxt(conn,\n\t\t\t\t\t     (struct smb2_compression_capabilities_context *)pctx);\n\t\t} else if (pctx->ContextType == SMB2_NETNAME_NEGOTIATE_CONTEXT_ID) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_NETNAME_NEGOTIATE_CONTEXT_ID context\\n\");\n\t\t} else if (pctx->ContextType == SMB2_POSIX_EXTENSIONS_AVAILABLE) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_POSIX_EXTENSIONS_AVAILABLE context\\n\");\n\t\t\tconn->posix_ext_supported = true;\n\t\t} else if (pctx->ContextType == SMB2_SIGNING_CAPABILITIES) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_SIGNING_CAPABILITIES context\\n\");\n\n\t\t\tdecode_sign_cap_ctxt(conn,\n\t\t\t\t\t     (struct smb2_signing_capabilities *)pctx,\n\t\t\t\t\t     ctxt_len);\n\t\t}\n\n\t\t/* offsets must be 8 byte aligned */\n\t\tclen = (clen + 7) & ~0x7;\n\t\toffset = clen + sizeof(struct smb2_neg_context);\n\t\tlen_of_ctxts -= clen + sizeof(struct smb2_neg_context);\n\t}\n\treturn status;\n}",
        "func_after": "static __le32 deassemble_neg_contexts(struct ksmbd_conn *conn,\n\t\t\t\t      struct smb2_negotiate_req *req,\n\t\t\t\t      unsigned int len_of_smb)\n{\n\t/* +4 is to account for the RFC1001 len field */\n\tstruct smb2_neg_context *pctx = (struct smb2_neg_context *)req;\n\tint i = 0, len_of_ctxts;\n\tunsigned int offset = le32_to_cpu(req->NegotiateContextOffset);\n\tunsigned int neg_ctxt_cnt = le16_to_cpu(req->NegotiateContextCount);\n\t__le32 status = STATUS_INVALID_PARAMETER;\n\n\tksmbd_debug(SMB, \"decoding %d negotiate contexts\\n\", neg_ctxt_cnt);\n\tif (len_of_smb <= offset) {\n\t\tksmbd_debug(SMB, \"Invalid response: negotiate context offset\\n\");\n\t\treturn status;\n\t}\n\n\tlen_of_ctxts = len_of_smb - offset;\n\n\twhile (i++ < neg_ctxt_cnt) {\n\t\tint clen, ctxt_len;\n\n\t\tif (len_of_ctxts < (int)sizeof(struct smb2_neg_context))\n\t\t\tbreak;\n\n\t\tpctx = (struct smb2_neg_context *)((char *)pctx + offset);\n\t\tclen = le16_to_cpu(pctx->DataLength);\n\t\tctxt_len = clen + sizeof(struct smb2_neg_context);\n\n\t\tif (ctxt_len > len_of_ctxts)\n\t\t\tbreak;\n\n\t\tif (pctx->ContextType == SMB2_PREAUTH_INTEGRITY_CAPABILITIES) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_PREAUTH_INTEGRITY_CAPABILITIES context\\n\");\n\t\t\tif (conn->preauth_info->Preauth_HashId)\n\t\t\t\tbreak;\n\n\t\t\tstatus = decode_preauth_ctxt(conn,\n\t\t\t\t\t\t     (struct smb2_preauth_neg_context *)pctx,\n\t\t\t\t\t\t     ctxt_len);\n\t\t\tif (status != STATUS_SUCCESS)\n\t\t\t\tbreak;\n\t\t} else if (pctx->ContextType == SMB2_ENCRYPTION_CAPABILITIES) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_ENCRYPTION_CAPABILITIES context\\n\");\n\t\t\tif (conn->cipher_type)\n\t\t\t\tbreak;\n\n\t\t\tdecode_encrypt_ctxt(conn,\n\t\t\t\t\t    (struct smb2_encryption_neg_context *)pctx,\n\t\t\t\t\t    ctxt_len);\n\t\t} else if (pctx->ContextType == SMB2_COMPRESSION_CAPABILITIES) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_COMPRESSION_CAPABILITIES context\\n\");\n\t\t\tif (conn->compress_algorithm)\n\t\t\t\tbreak;\n\n\t\t\tdecode_compress_ctxt(conn,\n\t\t\t\t\t     (struct smb2_compression_capabilities_context *)pctx);\n\t\t} else if (pctx->ContextType == SMB2_NETNAME_NEGOTIATE_CONTEXT_ID) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_NETNAME_NEGOTIATE_CONTEXT_ID context\\n\");\n\t\t} else if (pctx->ContextType == SMB2_POSIX_EXTENSIONS_AVAILABLE) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_POSIX_EXTENSIONS_AVAILABLE context\\n\");\n\t\t\tconn->posix_ext_supported = true;\n\t\t} else if (pctx->ContextType == SMB2_SIGNING_CAPABILITIES) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_SIGNING_CAPABILITIES context\\n\");\n\n\t\t\tdecode_sign_cap_ctxt(conn,\n\t\t\t\t\t     (struct smb2_signing_capabilities *)pctx,\n\t\t\t\t\t     ctxt_len);\n\t\t}\n\n\t\t/* offsets must be 8 byte aligned */\n\t\toffset = (ctxt_len + 7) & ~0x7;\n\t\tlen_of_ctxts -= offset;\n\t}\n\treturn status;\n}",
        "description": "An issue was discovered in the Linux kernel prior to version 6.3.8. Within the ksmbd component located in the SMB server directory, there is an integer underflow and out-of-bounds read vulnerability in the deassemble_neg_contexts function.",
        "commit": "The vulnerability involves an integer underflow condition in the SMB2 protocol negotiation process within the Linux kernel. Specifically, the initial check compares `clen + sizeof(struct smb2_neg_context)` against `len_of_ctxts`. However, during the loop, `len_of_ctxts` is decremented by `((clen + 7) & ~0x7) + sizeof(struct smb2_neg_context)`, which can lead to an underflow if `clen` undergoes 8-byte alignment. To prevent this, the check should use `(clen + 7) & ~0x7` instead. Additionally, certain variables should be declared as unsigned to avoid similar issues. The vulnerability results in a slab-out-of-bounds read error, as indicated by the kernel log, leading to potential memory corruption and system instability."
    },
    {
        "cwe": "CWE-763",
        "func_name": "facebook/write",
        "score": 0.7949223518371582,
        "func_before": "size_t\nwrite(Protocol_* iprot, const StructInfo& structInfo, const void* object) {\n  DCHECK(object);\n  size_t written = iprot->writeStructBegin(structInfo.name);\n  if (UNLIKELY(structInfo.unionExt != nullptr)) {\n    const FieldInfo* end = structInfo.fieldInfos + structInfo.numFields;\n    const auto& unionId =\n        activeUnionMemberId(object, structInfo.unionExt->unionTypeOffset);\n    const FieldInfo* found = std::lower_bound(\n        structInfo.fieldInfos,\n        end,\n        unionId,\n        [](const FieldInfo& lhs, FieldID rhs) { return lhs.id < rhs; });\n    if (found < end && found->id == unionId) {\n      const OptionalThriftValue value = getValue(*found->typeInfo, object);\n      if (value.hasValue()) {\n        written += writeField(iprot, *found, value.value());\n      } else if (found->typeInfo->type == protocol::TType::T_STRUCT) {\n        written += iprot->writeFieldBegin(\n            found->name, found->typeInfo->type, found->id);\n        written += iprot->writeStructBegin(found->name);\n        written += iprot->writeStructEnd();\n        written += iprot->writeFieldStop();\n        written += iprot->writeFieldEnd();\n      }\n    }\n  } else {\n    for (std::int16_t index = 0; index < structInfo.numFields; index++) {\n      const auto& fieldInfo = structInfo.fieldInfos[index];\n      if (fieldInfo.isUnqualified || fieldInfo.issetOffset == 0 ||\n          fieldIsSet(object, fieldInfo.issetOffset)) {\n        const OptionalThriftValue value =\n            getValue(*fieldInfo.typeInfo, getMember(fieldInfo, object));\n        if (value.hasValue()) {\n          written += writeField(iprot, fieldInfo, value.value());\n        }\n      }\n    }\n  }\n\n  written += iprot->writeFieldStop();\n  written += iprot->writeStructEnd();\n  return written;\n}",
        "func_after": "size_t\nwrite(Protocol_* iprot, const StructInfo& structInfo, const void* object) {\n  DCHECK(object);\n  size_t written = iprot->writeStructBegin(structInfo.name);\n  if (UNLIKELY(structInfo.unionExt != nullptr)) {\n    const FieldInfo* end = structInfo.fieldInfos + structInfo.numFields;\n    const auto& activeId = getActiveId(object, structInfo);\n    const FieldInfo* found = std::lower_bound(\n        structInfo.fieldInfos,\n        end,\n        activeId,\n        [](const FieldInfo& lhs, FieldID rhs) { return lhs.id < rhs; });\n    if (found < end && found->id == activeId) {\n      const OptionalThriftValue value = getValue(*found->typeInfo, object);\n      if (value.hasValue()) {\n        written += writeField(iprot, *found, value.value());\n      } else if (found->typeInfo->type == protocol::TType::T_STRUCT) {\n        written += iprot->writeFieldBegin(\n            found->name, found->typeInfo->type, found->id);\n        written += iprot->writeStructBegin(found->name);\n        written += iprot->writeStructEnd();\n        written += iprot->writeFieldStop();\n        written += iprot->writeFieldEnd();\n      }\n    }\n  } else {\n    for (std::int16_t index = 0; index < structInfo.numFields; index++) {\n      const auto& fieldInfo = structInfo.fieldInfos[index];\n      if (fieldInfo.isUnqualified || fieldInfo.issetOffset == 0 ||\n          fieldIsSet(object, fieldInfo.issetOffset)) {\n        const OptionalThriftValue value =\n            getValue(*fieldInfo.typeInfo, getMember(fieldInfo, object));\n        if (value.hasValue()) {\n          written += writeField(iprot, fieldInfo, value.value());\n        }\n      }\n    }\n  }\n\n  written += iprot->writeFieldStop();\n  written += iprot->writeStructEnd();\n  return written;\n}",
        "description": "An invalid free operation within Thrift's table-based serialization can lead to application crashes or enable code execution and other unintended consequences. This vulnerability impacts Facebook Thrift versions prior to v2021.02.22.00.",
        "commit": "It was discovered that the table-based serializer improperly handled invalid union data, leading to potential memory leaks and other undesirable effects. Specifically, when duplicate union data was encountered, the previous active member of the union was overwritten without invoking the destructor of the old object. Additionally, if the second piece of data was incomplete, the incorrect destructor was called during stack unwinding, resulting in segmentation faults, data corruption, or other issues. The fix involves clearing the union if there is an active member and correcting the type of the data member that holds the active field ID."
    },
    {
        "cwe": "CWE-119",
        "func_name": "torvalds/hugetlb_mcopy_atomic_pte",
        "score": 0.8121357560157776,
        "func_before": "int hugetlb_mcopy_atomic_pte(struct mm_struct *dst_mm,\n\t\t\t    pte_t *dst_pte,\n\t\t\t    struct vm_area_struct *dst_vma,\n\t\t\t    unsigned long dst_addr,\n\t\t\t    unsigned long src_addr,\n\t\t\t    struct page **pagep)\n{\n\tint vm_shared = dst_vma->vm_flags & VM_SHARED;\n\tstruct hstate *h = hstate_vma(dst_vma);\n\tpte_t _dst_pte;\n\tspinlock_t *ptl;\n\tint ret;\n\tstruct page *page;\n\n\tif (!*pagep) {\n\t\tret = -ENOMEM;\n\t\tpage = alloc_huge_page(dst_vma, dst_addr, 0);\n\t\tif (IS_ERR(page))\n\t\t\tgoto out;\n\n\t\tret = copy_huge_page_from_user(page,\n\t\t\t\t\t\t(const void __user *) src_addr,\n\t\t\t\t\t\tpages_per_huge_page(h), false);\n\n\t\t/* fallback to copy_from_user outside mmap_sem */\n\t\tif (unlikely(ret)) {\n\t\t\tret = -EFAULT;\n\t\t\t*pagep = page;\n\t\t\t/* don't free the page */\n\t\t\tgoto out;\n\t\t}\n\t} else {\n\t\tpage = *pagep;\n\t\t*pagep = NULL;\n\t}\n\n\t/*\n\t * The memory barrier inside __SetPageUptodate makes sure that\n\t * preceding stores to the page contents become visible before\n\t * the set_pte_at() write.\n\t */\n\t__SetPageUptodate(page);\n\tset_page_huge_active(page);\n\n\t/*\n\t * If shared, add to page cache\n\t */\n\tif (vm_shared) {\n\t\tstruct address_space *mapping = dst_vma->vm_file->f_mapping;\n\t\tpgoff_t idx = vma_hugecache_offset(h, dst_vma, dst_addr);\n\n\t\tret = huge_add_to_page_cache(page, mapping, idx);\n\t\tif (ret)\n\t\t\tgoto out_release_nounlock;\n\t}\n\n\tptl = huge_pte_lockptr(h, dst_mm, dst_pte);\n\tspin_lock(ptl);\n\n\tret = -EEXIST;\n\tif (!huge_pte_none(huge_ptep_get(dst_pte)))\n\t\tgoto out_release_unlock;\n\n\tif (vm_shared) {\n\t\tpage_dup_rmap(page, true);\n\t} else {\n\t\tClearPagePrivate(page);\n\t\thugepage_add_new_anon_rmap(page, dst_vma, dst_addr);\n\t}\n\n\t_dst_pte = make_huge_pte(dst_vma, page, dst_vma->vm_flags & VM_WRITE);\n\tif (dst_vma->vm_flags & VM_WRITE)\n\t\t_dst_pte = huge_pte_mkdirty(_dst_pte);\n\t_dst_pte = pte_mkyoung(_dst_pte);\n\n\tset_huge_pte_at(dst_mm, dst_addr, dst_pte, _dst_pte);\n\n\t(void)huge_ptep_set_access_flags(dst_vma, dst_addr, dst_pte, _dst_pte,\n\t\t\t\t\tdst_vma->vm_flags & VM_WRITE);\n\thugetlb_count_add(pages_per_huge_page(h), dst_mm);\n\n\t/* No need to invalidate - it was non-present before */\n\tupdate_mmu_cache(dst_vma, dst_addr, dst_pte);\n\n\tspin_unlock(ptl);\n\tif (vm_shared)\n\t\tunlock_page(page);\n\tret = 0;\nout:\n\treturn ret;\nout_release_unlock:\n\tspin_unlock(ptl);\n\tif (vm_shared)\n\t\tunlock_page(page);\nout_release_nounlock:\n\tput_page(page);\n\tgoto out;\n}",
        "func_after": "int hugetlb_mcopy_atomic_pte(struct mm_struct *dst_mm,\n\t\t\t    pte_t *dst_pte,\n\t\t\t    struct vm_area_struct *dst_vma,\n\t\t\t    unsigned long dst_addr,\n\t\t\t    unsigned long src_addr,\n\t\t\t    struct page **pagep)\n{\n\tstruct address_space *mapping;\n\tpgoff_t idx;\n\tunsigned long size;\n\tint vm_shared = dst_vma->vm_flags & VM_SHARED;\n\tstruct hstate *h = hstate_vma(dst_vma);\n\tpte_t _dst_pte;\n\tspinlock_t *ptl;\n\tint ret;\n\tstruct page *page;\n\n\tif (!*pagep) {\n\t\tret = -ENOMEM;\n\t\tpage = alloc_huge_page(dst_vma, dst_addr, 0);\n\t\tif (IS_ERR(page))\n\t\t\tgoto out;\n\n\t\tret = copy_huge_page_from_user(page,\n\t\t\t\t\t\t(const void __user *) src_addr,\n\t\t\t\t\t\tpages_per_huge_page(h), false);\n\n\t\t/* fallback to copy_from_user outside mmap_sem */\n\t\tif (unlikely(ret)) {\n\t\t\tret = -EFAULT;\n\t\t\t*pagep = page;\n\t\t\t/* don't free the page */\n\t\t\tgoto out;\n\t\t}\n\t} else {\n\t\tpage = *pagep;\n\t\t*pagep = NULL;\n\t}\n\n\t/*\n\t * The memory barrier inside __SetPageUptodate makes sure that\n\t * preceding stores to the page contents become visible before\n\t * the set_pte_at() write.\n\t */\n\t__SetPageUptodate(page);\n\tset_page_huge_active(page);\n\n\tmapping = dst_vma->vm_file->f_mapping;\n\tidx = vma_hugecache_offset(h, dst_vma, dst_addr);\n\n\t/*\n\t * If shared, add to page cache\n\t */\n\tif (vm_shared) {\n\t\tsize = i_size_read(mapping->host) >> huge_page_shift(h);\n\t\tret = -EFAULT;\n\t\tif (idx >= size)\n\t\t\tgoto out_release_nounlock;\n\n\t\t/*\n\t\t * Serialization between remove_inode_hugepages() and\n\t\t * huge_add_to_page_cache() below happens through the\n\t\t * hugetlb_fault_mutex_table that here must be hold by\n\t\t * the caller.\n\t\t */\n\t\tret = huge_add_to_page_cache(page, mapping, idx);\n\t\tif (ret)\n\t\t\tgoto out_release_nounlock;\n\t}\n\n\tptl = huge_pte_lockptr(h, dst_mm, dst_pte);\n\tspin_lock(ptl);\n\n\t/*\n\t * Recheck the i_size after holding PT lock to make sure not\n\t * to leave any page mapped (as page_mapped()) beyond the end\n\t * of the i_size (remove_inode_hugepages() is strict about\n\t * enforcing that). If we bail out here, we'll also leave a\n\t * page in the radix tree in the vm_shared case beyond the end\n\t * of the i_size, but remove_inode_hugepages() will take care\n\t * of it as soon as we drop the hugetlb_fault_mutex_table.\n\t */\n\tsize = i_size_read(mapping->host) >> huge_page_shift(h);\n\tret = -EFAULT;\n\tif (idx >= size)\n\t\tgoto out_release_unlock;\n\n\tret = -EEXIST;\n\tif (!huge_pte_none(huge_ptep_get(dst_pte)))\n\t\tgoto out_release_unlock;\n\n\tif (vm_shared) {\n\t\tpage_dup_rmap(page, true);\n\t} else {\n\t\tClearPagePrivate(page);\n\t\thugepage_add_new_anon_rmap(page, dst_vma, dst_addr);\n\t}\n\n\t_dst_pte = make_huge_pte(dst_vma, page, dst_vma->vm_flags & VM_WRITE);\n\tif (dst_vma->vm_flags & VM_WRITE)\n\t\t_dst_pte = huge_pte_mkdirty(_dst_pte);\n\t_dst_pte = pte_mkyoung(_dst_pte);\n\n\tset_huge_pte_at(dst_mm, dst_addr, dst_pte, _dst_pte);\n\n\t(void)huge_ptep_set_access_flags(dst_vma, dst_addr, dst_pte, _dst_pte,\n\t\t\t\t\tdst_vma->vm_flags & VM_WRITE);\n\thugetlb_count_add(pages_per_huge_page(h), dst_mm);\n\n\t/* No need to invalidate - it was non-present before */\n\tupdate_mmu_cache(dst_vma, dst_addr, dst_pte);\n\n\tspin_unlock(ptl);\n\tif (vm_shared)\n\t\tunlock_page(page);\n\tret = 0;\nout:\n\treturn ret;\nout_release_unlock:\n\tspin_unlock(ptl);\n\tif (vm_shared)\n\t\tunlock_page(page);\nout_release_nounlock:\n\tput_page(page);\n\tgoto out;\n}",
        "description": "A flaw was identified in the hugetlb_mcopy_atomic_pte function within the Linux kernel's memory management module, affecting versions prior to 4.13.12. The absence of a proper size check in this function could lead to a denial of service condition, indicated by a BUG.",
        "commit": "A vulnerability was identified in the userfaultfd functionality related to hugetlbfs, where the UFFDIO_COPY operation could inadvertently extend beyond the intended size of the file (i_size). This issue led to a kernel panic (oops) at fs/hugetlbfs/inode.c:484, triggered by the absence of an i_size check in the hugetlb_mcopy_atomic_pte function. Although mmap() operations could succeed beyond the end of the i_size after vmtruncate had removed virtual memory areas (vmas) in those ranges, subsequent faults, including UFFDIO_COPY, should not be allowed to succeed. The proposed solution involves modifying the return value to userland to indicate a SIGBUS-like condition, similar to what a page fault would produce, but this approach was deemed less useful due to the difficulty in distinguishing between SIGSEGV and SIGBUS through meaningful syscall return values."
    },
    {
        "cwe": "CWE-125",
        "func_name": "the-tcpdump-group/nfsreq_print_noaddr",
        "score": 0.8131949305534363,
        "func_before": "void\nnfsreq_print_noaddr(netdissect_options *ndo,\n                    register const u_char *bp, u_int length,\n                    register const u_char *bp2)\n{\n\tregister const struct sunrpc_msg *rp;\n\tregister const uint32_t *dp;\n\tnfs_type type;\n\tint v3;\n\tuint32_t proc;\n\tuint32_t access_flags;\n\tstruct nfsv3_sattr sa3;\n\n\tND_PRINT((ndo, \"%d\", length));\n\tnfserr = 0;\t\t/* assume no error */\n\trp = (const struct sunrpc_msg *)bp;\n\n\tif (!xid_map_enter(ndo, rp, bp2))\t/* record proc number for later on */\n\t\tgoto trunc;\n\n\tv3 = (EXTRACT_32BITS(&rp->rm_call.cb_vers) == NFS_VER3);\n\tproc = EXTRACT_32BITS(&rp->rm_call.cb_proc);\n\n\tif (!v3 && proc < NFS_NPROCS)\n\t\tproc =  nfsv3_procid[proc];\n\n\tND_PRINT((ndo, \" %s\", tok2str(nfsproc_str, \"proc-%u\", proc)));\n\tswitch (proc) {\n\n\tcase NFSPROC_GETATTR:\n\tcase NFSPROC_SETATTR:\n\tcase NFSPROC_READLINK:\n\tcase NFSPROC_FSSTAT:\n\tcase NFSPROC_FSINFO:\n\tcase NFSPROC_PATHCONF:\n\t\tif ((dp = parsereq(ndo, rp, length)) != NULL &&\n\t\t    parsefh(ndo, dp, v3) != NULL)\n\t\t\treturn;\n\t\tbreak;\n\n\tcase NFSPROC_LOOKUP:\n\tcase NFSPROC_CREATE:\n\tcase NFSPROC_MKDIR:\n\tcase NFSPROC_REMOVE:\n\tcase NFSPROC_RMDIR:\n\t\tif ((dp = parsereq(ndo, rp, length)) != NULL &&\n\t\t    parsefhn(ndo, dp, v3) != NULL)\n\t\t\treturn;\n\t\tbreak;\n\n\tcase NFSPROC_ACCESS:\n\t\tif ((dp = parsereq(ndo, rp, length)) != NULL &&\n\t\t    (dp = parsefh(ndo, dp, v3)) != NULL) {\n\t\t\tND_TCHECK(dp[0]);\n\t\t\taccess_flags = EXTRACT_32BITS(&dp[0]);\n\t\t\tif (access_flags & ~NFSV3ACCESS_FULL) {\n\t\t\t\t/* NFSV3ACCESS definitions aren't up to date */\n\t\t\t\tND_PRINT((ndo, \" %04x\", access_flags));\n\t\t\t} else if ((access_flags & NFSV3ACCESS_FULL) == NFSV3ACCESS_FULL) {\n\t\t\t\tND_PRINT((ndo, \" NFS_ACCESS_FULL\"));\n\t\t\t} else {\n\t\t\t\tchar separator = ' ';\n\t\t\t\tif (access_flags & NFSV3ACCESS_READ) {\n\t\t\t\t\tND_PRINT((ndo, \" NFS_ACCESS_READ\"));\n\t\t\t\t\tseparator = '|';\n\t\t\t\t}\n\t\t\t\tif (access_flags & NFSV3ACCESS_LOOKUP) {\n\t\t\t\t\tND_PRINT((ndo, \"%cNFS_ACCESS_LOOKUP\", separator));\n\t\t\t\t\tseparator = '|';\n\t\t\t\t}\n\t\t\t\tif (access_flags & NFSV3ACCESS_MODIFY) {\n\t\t\t\t\tND_PRINT((ndo, \"%cNFS_ACCESS_MODIFY\", separator));\n\t\t\t\t\tseparator = '|';\n\t\t\t\t}\n\t\t\t\tif (access_flags & NFSV3ACCESS_EXTEND) {\n\t\t\t\t\tND_PRINT((ndo, \"%cNFS_ACCESS_EXTEND\", separator));\n\t\t\t\t\tseparator = '|';\n\t\t\t\t}\n\t\t\t\tif (access_flags & NFSV3ACCESS_DELETE) {\n\t\t\t\t\tND_PRINT((ndo, \"%cNFS_ACCESS_DELETE\", separator));\n\t\t\t\t\tseparator = '|';\n\t\t\t\t}\n\t\t\t\tif (access_flags & NFSV3ACCESS_EXECUTE)\n\t\t\t\t\tND_PRINT((ndo, \"%cNFS_ACCESS_EXECUTE\", separator));\n\t\t\t}\n\t\t\treturn;\n\t\t}\n\t\tbreak;\n\n\tcase NFSPROC_READ:\n\t\tif ((dp = parsereq(ndo, rp, length)) != NULL &&\n\t\t    (dp = parsefh(ndo, dp, v3)) != NULL) {\n\t\t\tif (v3) {\n\t\t\t\tND_TCHECK(dp[2]);\n\t\t\t\tND_PRINT((ndo, \" %u bytes @ %\" PRIu64,\n\t\t\t\t       EXTRACT_32BITS(&dp[2]),\n\t\t\t\t       EXTRACT_64BITS(&dp[0])));\n\t\t\t} else {\n\t\t\t\tND_TCHECK(dp[1]);\n\t\t\t\tND_PRINT((ndo, \" %u bytes @ %u\",\n\t\t\t\t    EXTRACT_32BITS(&dp[1]),\n\t\t\t\t    EXTRACT_32BITS(&dp[0])));\n\t\t\t}\n\t\t\treturn;\n\t\t}\n\t\tbreak;\n\n\tcase NFSPROC_WRITE:\n\t\tif ((dp = parsereq(ndo, rp, length)) != NULL &&\n\t\t    (dp = parsefh(ndo, dp, v3)) != NULL) {\n\t\t\tif (v3) {\n\t\t\t\tND_TCHECK(dp[2]);\n\t\t\t\tND_PRINT((ndo, \" %u (%u) bytes @ %\" PRIu64,\n\t\t\t\t\t\tEXTRACT_32BITS(&dp[4]),\n\t\t\t\t\t\tEXTRACT_32BITS(&dp[2]),\n\t\t\t\t\t\tEXTRACT_64BITS(&dp[0])));\n\t\t\t\tif (ndo->ndo_vflag) {\n\t\t\t\t\tdp += 3;\n\t\t\t\t\tND_TCHECK(dp[0]);\n\t\t\t\t\tND_PRINT((ndo, \" <%s>\",\n\t\t\t\t\t\ttok2str(nfsv3_writemodes,\n\t\t\t\t\t\t\tNULL, EXTRACT_32BITS(dp))));\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tND_TCHECK(dp[3]);\n\t\t\t\tND_PRINT((ndo, \" %u (%u) bytes @ %u (%u)\",\n\t\t\t\t\t\tEXTRACT_32BITS(&dp[3]),\n\t\t\t\t\t\tEXTRACT_32BITS(&dp[2]),\n\t\t\t\t\t\tEXTRACT_32BITS(&dp[1]),\n\t\t\t\t\t\tEXTRACT_32BITS(&dp[0])));\n\t\t\t}\n\t\t\treturn;\n\t\t}\n\t\tbreak;\n\n\tcase NFSPROC_SYMLINK:\n\t\tif ((dp = parsereq(ndo, rp, length)) != NULL &&\n\t\t    (dp = parsefhn(ndo, dp, v3)) != NULL) {\n\t\t\tND_PRINT((ndo, \" ->\"));\n\t\t\tif (v3 && (dp = parse_sattr3(ndo, dp, &sa3)) == NULL)\n\t\t\t\tbreak;\n\t\t\tif (parsefn(ndo, dp) == NULL)\n\t\t\t\tbreak;\n\t\t\tif (v3 && ndo->ndo_vflag)\n\t\t\t\tprint_sattr3(ndo, &sa3, ndo->ndo_vflag);\n\t\t\treturn;\n\t\t}\n\t\tbreak;\n\n\tcase NFSPROC_MKNOD:\n\t\tif ((dp = parsereq(ndo, rp, length)) != NULL &&\n\t\t    (dp = parsefhn(ndo, dp, v3)) != NULL) {\n\t\t\tND_TCHECK(*dp);\n\t\t\ttype = (nfs_type)EXTRACT_32BITS(dp);\n\t\t\tdp++;\n\t\t\tif ((dp = parse_sattr3(ndo, dp, &sa3)) == NULL)\n\t\t\t\tbreak;\n\t\t\tND_PRINT((ndo, \" %s\", tok2str(type2str, \"unk-ft %d\", type)));\n\t\t\tif (ndo->ndo_vflag && (type == NFCHR || type == NFBLK)) {\n\t\t\t\tND_TCHECK(dp[1]);\n\t\t\t\tND_PRINT((ndo, \" %u/%u\",\n\t\t\t\t       EXTRACT_32BITS(&dp[0]),\n\t\t\t\t       EXTRACT_32BITS(&dp[1])));\n\t\t\t\tdp += 2;\n\t\t\t}\n\t\t\tif (ndo->ndo_vflag)\n\t\t\t\tprint_sattr3(ndo, &sa3, ndo->ndo_vflag);\n\t\t\treturn;\n\t\t}\n\t\tbreak;\n\n\tcase NFSPROC_RENAME:\n\t\tif ((dp = parsereq(ndo, rp, length)) != NULL &&\n\t\t    (dp = parsefhn(ndo, dp, v3)) != NULL) {\n\t\t\tND_PRINT((ndo, \" ->\"));\n\t\t\tif (parsefhn(ndo, dp, v3) != NULL)\n\t\t\t\treturn;\n\t\t}\n\t\tbreak;\n\n\tcase NFSPROC_LINK:\n\t\tif ((dp = parsereq(ndo, rp, length)) != NULL &&\n\t\t    (dp = parsefh(ndo, dp, v3)) != NULL) {\n\t\t\tND_PRINT((ndo, \" ->\"));\n\t\t\tif (parsefhn(ndo, dp, v3) != NULL)\n\t\t\t\treturn;\n\t\t}\n\t\tbreak;\n\n\tcase NFSPROC_READDIR:\n\t\tif ((dp = parsereq(ndo, rp, length)) != NULL &&\n\t\t    (dp = parsefh(ndo, dp, v3)) != NULL) {\n\t\t\tif (v3) {\n\t\t\t\tND_TCHECK(dp[4]);\n\t\t\t\t/*\n\t\t\t\t * We shouldn't really try to interpret the\n\t\t\t\t * offset cookie here.\n\t\t\t\t */\n\t\t\t\tND_PRINT((ndo, \" %u bytes @ %\" PRId64,\n\t\t\t\t    EXTRACT_32BITS(&dp[4]),\n\t\t\t\t    EXTRACT_64BITS(&dp[0])));\n\t\t\t\tif (ndo->ndo_vflag)\n\t\t\t\t\tND_PRINT((ndo, \" verf %08x%08x\", dp[2], dp[3]));\n\t\t\t} else {\n\t\t\t\tND_TCHECK(dp[1]);\n\t\t\t\t/*\n\t\t\t\t * Print the offset as signed, since -1 is\n\t\t\t\t * common, but offsets > 2^31 aren't.\n\t\t\t\t */\n\t\t\t\tND_PRINT((ndo, \" %u bytes @ %d\",\n\t\t\t\t    EXTRACT_32BITS(&dp[1]),\n\t\t\t\t    EXTRACT_32BITS(&dp[0])));\n\t\t\t}\n\t\t\treturn;\n\t\t}\n\t\tbreak;\n\n\tcase NFSPROC_READDIRPLUS:\n\t\tif ((dp = parsereq(ndo, rp, length)) != NULL &&\n\t\t    (dp = parsefh(ndo, dp, v3)) != NULL) {\n\t\t\tND_TCHECK(dp[4]);\n\t\t\t/*\n\t\t\t * We don't try to interpret the offset\n\t\t\t * cookie here.\n\t\t\t */\n\t\t\tND_PRINT((ndo, \" %u bytes @ %\" PRId64,\n\t\t\t\tEXTRACT_32BITS(&dp[4]),\n\t\t\t\tEXTRACT_64BITS(&dp[0])));\n\t\t\tif (ndo->ndo_vflag) {\n\t\t\t\tND_TCHECK(dp[5]);\n\t\t\t\tND_PRINT((ndo, \" max %u verf %08x%08x\",\n\t\t\t\t       EXTRACT_32BITS(&dp[5]), dp[2], dp[3]));\n\t\t\t}\n\t\t\treturn;\n\t\t}\n\t\tbreak;\n\n\tcase NFSPROC_COMMIT:\n\t\tif ((dp = parsereq(ndo, rp, length)) != NULL &&\n\t\t    (dp = parsefh(ndo, dp, v3)) != NULL) {\n\t\t\tND_TCHECK(dp[2]);\n\t\t\tND_PRINT((ndo, \" %u bytes @ %\" PRIu64,\n\t\t\t\tEXTRACT_32BITS(&dp[2]),\n\t\t\t\tEXTRACT_64BITS(&dp[0])));\n\t\t\treturn;\n\t\t}\n\t\tbreak;\n\n\tdefault:\n\t\treturn;\n\t}\n\ntrunc:\n\tif (!nfserr)\n\t\tND_PRINT((ndo, \"%s\", tstr));\n}",
        "func_after": "void\nnfsreq_print_noaddr(netdissect_options *ndo,\n                    register const u_char *bp, u_int length,\n                    register const u_char *bp2)\n{\n\tregister const struct sunrpc_msg *rp;\n\tregister const uint32_t *dp;\n\tnfs_type type;\n\tint v3;\n\tuint32_t proc;\n\tuint32_t access_flags;\n\tstruct nfsv3_sattr sa3;\n\n\tND_PRINT((ndo, \"%d\", length));\n\tnfserr = 0;\t\t/* assume no error */\n\trp = (const struct sunrpc_msg *)bp;\n\n\tif (!xid_map_enter(ndo, rp, bp2))\t/* record proc number for later on */\n\t\tgoto trunc;\n\n\tv3 = (EXTRACT_32BITS(&rp->rm_call.cb_vers) == NFS_VER3);\n\tproc = EXTRACT_32BITS(&rp->rm_call.cb_proc);\n\n\tif (!v3 && proc < NFS_NPROCS)\n\t\tproc =  nfsv3_procid[proc];\n\n\tND_PRINT((ndo, \" %s\", tok2str(nfsproc_str, \"proc-%u\", proc)));\n\tswitch (proc) {\n\n\tcase NFSPROC_GETATTR:\n\tcase NFSPROC_SETATTR:\n\tcase NFSPROC_READLINK:\n\tcase NFSPROC_FSSTAT:\n\tcase NFSPROC_FSINFO:\n\tcase NFSPROC_PATHCONF:\n\t\tif ((dp = parsereq(ndo, rp, length)) != NULL &&\n\t\t    parsefh(ndo, dp, v3) != NULL)\n\t\t\treturn;\n\t\tbreak;\n\n\tcase NFSPROC_LOOKUP:\n\tcase NFSPROC_CREATE:\n\tcase NFSPROC_MKDIR:\n\tcase NFSPROC_REMOVE:\n\tcase NFSPROC_RMDIR:\n\t\tif ((dp = parsereq(ndo, rp, length)) != NULL &&\n\t\t    parsefhn(ndo, dp, v3) != NULL)\n\t\t\treturn;\n\t\tbreak;\n\n\tcase NFSPROC_ACCESS:\n\t\tif ((dp = parsereq(ndo, rp, length)) != NULL &&\n\t\t    (dp = parsefh(ndo, dp, v3)) != NULL) {\n\t\t\tND_TCHECK(dp[0]);\n\t\t\taccess_flags = EXTRACT_32BITS(&dp[0]);\n\t\t\tif (access_flags & ~NFSV3ACCESS_FULL) {\n\t\t\t\t/* NFSV3ACCESS definitions aren't up to date */\n\t\t\t\tND_PRINT((ndo, \" %04x\", access_flags));\n\t\t\t} else if ((access_flags & NFSV3ACCESS_FULL) == NFSV3ACCESS_FULL) {\n\t\t\t\tND_PRINT((ndo, \" NFS_ACCESS_FULL\"));\n\t\t\t} else {\n\t\t\t\tchar separator = ' ';\n\t\t\t\tif (access_flags & NFSV3ACCESS_READ) {\n\t\t\t\t\tND_PRINT((ndo, \" NFS_ACCESS_READ\"));\n\t\t\t\t\tseparator = '|';\n\t\t\t\t}\n\t\t\t\tif (access_flags & NFSV3ACCESS_LOOKUP) {\n\t\t\t\t\tND_PRINT((ndo, \"%cNFS_ACCESS_LOOKUP\", separator));\n\t\t\t\t\tseparator = '|';\n\t\t\t\t}\n\t\t\t\tif (access_flags & NFSV3ACCESS_MODIFY) {\n\t\t\t\t\tND_PRINT((ndo, \"%cNFS_ACCESS_MODIFY\", separator));\n\t\t\t\t\tseparator = '|';\n\t\t\t\t}\n\t\t\t\tif (access_flags & NFSV3ACCESS_EXTEND) {\n\t\t\t\t\tND_PRINT((ndo, \"%cNFS_ACCESS_EXTEND\", separator));\n\t\t\t\t\tseparator = '|';\n\t\t\t\t}\n\t\t\t\tif (access_flags & NFSV3ACCESS_DELETE) {\n\t\t\t\t\tND_PRINT((ndo, \"%cNFS_ACCESS_DELETE\", separator));\n\t\t\t\t\tseparator = '|';\n\t\t\t\t}\n\t\t\t\tif (access_flags & NFSV3ACCESS_EXECUTE)\n\t\t\t\t\tND_PRINT((ndo, \"%cNFS_ACCESS_EXECUTE\", separator));\n\t\t\t}\n\t\t\treturn;\n\t\t}\n\t\tbreak;\n\n\tcase NFSPROC_READ:\n\t\tif ((dp = parsereq(ndo, rp, length)) != NULL &&\n\t\t    (dp = parsefh(ndo, dp, v3)) != NULL) {\n\t\t\tif (v3) {\n\t\t\t\tND_TCHECK(dp[2]);\n\t\t\t\tND_PRINT((ndo, \" %u bytes @ %\" PRIu64,\n\t\t\t\t       EXTRACT_32BITS(&dp[2]),\n\t\t\t\t       EXTRACT_64BITS(&dp[0])));\n\t\t\t} else {\n\t\t\t\tND_TCHECK(dp[1]);\n\t\t\t\tND_PRINT((ndo, \" %u bytes @ %u\",\n\t\t\t\t    EXTRACT_32BITS(&dp[1]),\n\t\t\t\t    EXTRACT_32BITS(&dp[0])));\n\t\t\t}\n\t\t\treturn;\n\t\t}\n\t\tbreak;\n\n\tcase NFSPROC_WRITE:\n\t\tif ((dp = parsereq(ndo, rp, length)) != NULL &&\n\t\t    (dp = parsefh(ndo, dp, v3)) != NULL) {\n\t\t\tif (v3) {\n\t\t\t\tND_TCHECK(dp[4]);\n\t\t\t\tND_PRINT((ndo, \" %u (%u) bytes @ %\" PRIu64,\n\t\t\t\t\t\tEXTRACT_32BITS(&dp[4]),\n\t\t\t\t\t\tEXTRACT_32BITS(&dp[2]),\n\t\t\t\t\t\tEXTRACT_64BITS(&dp[0])));\n\t\t\t\tif (ndo->ndo_vflag) {\n\t\t\t\t\tND_PRINT((ndo, \" <%s>\",\n\t\t\t\t\t\ttok2str(nfsv3_writemodes,\n\t\t\t\t\t\t\tNULL, EXTRACT_32BITS(&dp[3]))));\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tND_TCHECK(dp[3]);\n\t\t\t\tND_PRINT((ndo, \" %u (%u) bytes @ %u (%u)\",\n\t\t\t\t\t\tEXTRACT_32BITS(&dp[3]),\n\t\t\t\t\t\tEXTRACT_32BITS(&dp[2]),\n\t\t\t\t\t\tEXTRACT_32BITS(&dp[1]),\n\t\t\t\t\t\tEXTRACT_32BITS(&dp[0])));\n\t\t\t}\n\t\t\treturn;\n\t\t}\n\t\tbreak;\n\n\tcase NFSPROC_SYMLINK:\n\t\tif ((dp = parsereq(ndo, rp, length)) != NULL &&\n\t\t    (dp = parsefhn(ndo, dp, v3)) != NULL) {\n\t\t\tND_PRINT((ndo, \" ->\"));\n\t\t\tif (v3 && (dp = parse_sattr3(ndo, dp, &sa3)) == NULL)\n\t\t\t\tbreak;\n\t\t\tif (parsefn(ndo, dp) == NULL)\n\t\t\t\tbreak;\n\t\t\tif (v3 && ndo->ndo_vflag)\n\t\t\t\tprint_sattr3(ndo, &sa3, ndo->ndo_vflag);\n\t\t\treturn;\n\t\t}\n\t\tbreak;\n\n\tcase NFSPROC_MKNOD:\n\t\tif ((dp = parsereq(ndo, rp, length)) != NULL &&\n\t\t    (dp = parsefhn(ndo, dp, v3)) != NULL) {\n\t\t\tND_TCHECK(*dp);\n\t\t\ttype = (nfs_type)EXTRACT_32BITS(dp);\n\t\t\tdp++;\n\t\t\tif ((dp = parse_sattr3(ndo, dp, &sa3)) == NULL)\n\t\t\t\tbreak;\n\t\t\tND_PRINT((ndo, \" %s\", tok2str(type2str, \"unk-ft %d\", type)));\n\t\t\tif (ndo->ndo_vflag && (type == NFCHR || type == NFBLK)) {\n\t\t\t\tND_TCHECK(dp[1]);\n\t\t\t\tND_PRINT((ndo, \" %u/%u\",\n\t\t\t\t       EXTRACT_32BITS(&dp[0]),\n\t\t\t\t       EXTRACT_32BITS(&dp[1])));\n\t\t\t\tdp += 2;\n\t\t\t}\n\t\t\tif (ndo->ndo_vflag)\n\t\t\t\tprint_sattr3(ndo, &sa3, ndo->ndo_vflag);\n\t\t\treturn;\n\t\t}\n\t\tbreak;\n\n\tcase NFSPROC_RENAME:\n\t\tif ((dp = parsereq(ndo, rp, length)) != NULL &&\n\t\t    (dp = parsefhn(ndo, dp, v3)) != NULL) {\n\t\t\tND_PRINT((ndo, \" ->\"));\n\t\t\tif (parsefhn(ndo, dp, v3) != NULL)\n\t\t\t\treturn;\n\t\t}\n\t\tbreak;\n\n\tcase NFSPROC_LINK:\n\t\tif ((dp = parsereq(ndo, rp, length)) != NULL &&\n\t\t    (dp = parsefh(ndo, dp, v3)) != NULL) {\n\t\t\tND_PRINT((ndo, \" ->\"));\n\t\t\tif (parsefhn(ndo, dp, v3) != NULL)\n\t\t\t\treturn;\n\t\t}\n\t\tbreak;\n\n\tcase NFSPROC_READDIR:\n\t\tif ((dp = parsereq(ndo, rp, length)) != NULL &&\n\t\t    (dp = parsefh(ndo, dp, v3)) != NULL) {\n\t\t\tif (v3) {\n\t\t\t\tND_TCHECK(dp[4]);\n\t\t\t\t/*\n\t\t\t\t * We shouldn't really try to interpret the\n\t\t\t\t * offset cookie here.\n\t\t\t\t */\n\t\t\t\tND_PRINT((ndo, \" %u bytes @ %\" PRId64,\n\t\t\t\t    EXTRACT_32BITS(&dp[4]),\n\t\t\t\t    EXTRACT_64BITS(&dp[0])));\n\t\t\t\tif (ndo->ndo_vflag)\n\t\t\t\t\tND_PRINT((ndo, \" verf %08x%08x\", dp[2], dp[3]));\n\t\t\t} else {\n\t\t\t\tND_TCHECK(dp[1]);\n\t\t\t\t/*\n\t\t\t\t * Print the offset as signed, since -1 is\n\t\t\t\t * common, but offsets > 2^31 aren't.\n\t\t\t\t */\n\t\t\t\tND_PRINT((ndo, \" %u bytes @ %d\",\n\t\t\t\t    EXTRACT_32BITS(&dp[1]),\n\t\t\t\t    EXTRACT_32BITS(&dp[0])));\n\t\t\t}\n\t\t\treturn;\n\t\t}\n\t\tbreak;\n\n\tcase NFSPROC_READDIRPLUS:\n\t\tif ((dp = parsereq(ndo, rp, length)) != NULL &&\n\t\t    (dp = parsefh(ndo, dp, v3)) != NULL) {\n\t\t\tND_TCHECK(dp[4]);\n\t\t\t/*\n\t\t\t * We don't try to interpret the offset\n\t\t\t * cookie here.\n\t\t\t */\n\t\t\tND_PRINT((ndo, \" %u bytes @ %\" PRId64,\n\t\t\t\tEXTRACT_32BITS(&dp[4]),\n\t\t\t\tEXTRACT_64BITS(&dp[0])));\n\t\t\tif (ndo->ndo_vflag) {\n\t\t\t\tND_TCHECK(dp[5]);\n\t\t\t\tND_PRINT((ndo, \" max %u verf %08x%08x\",\n\t\t\t\t       EXTRACT_32BITS(&dp[5]), dp[2], dp[3]));\n\t\t\t}\n\t\t\treturn;\n\t\t}\n\t\tbreak;\n\n\tcase NFSPROC_COMMIT:\n\t\tif ((dp = parsereq(ndo, rp, length)) != NULL &&\n\t\t    (dp = parsefh(ndo, dp, v3)) != NULL) {\n\t\t\tND_TCHECK(dp[2]);\n\t\t\tND_PRINT((ndo, \" %u bytes @ %\" PRIu64,\n\t\t\t\tEXTRACT_32BITS(&dp[2]),\n\t\t\t\tEXTRACT_64BITS(&dp[0])));\n\t\t\treturn;\n\t\t}\n\t\tbreak;\n\n\tdefault:\n\t\treturn;\n\t}\n\ntrunc:\n\tif (!nfserr)\n\t\tND_PRINT((ndo, \"%s\", tstr));\n}",
        "description": "The NFS parser in tcpdump, prior to version 4.9.2, suffers from a buffer over-read issue within the interp_reply function.",
        "commit": "The NFSv3 WRITE procedure lacked proper bounds checking, specifically for the length of the opaque data being written. This oversight allowed for a buffer over-read vulnerability. Additionally, the code was updated to ensure that the entire `ar_stat` field is present in the captured data and to clarify the handling of the \"stable\" argument by removing redundant checks. A test case was included to verify the fix for checking before fetching the \"access\" part of the NFSv3 ACCESS results."
    },
    {
        "cwe": "CWE-672",
        "func_name": "torvalds/get_gate_page",
        "score": 0.8019403219223022,
        "func_before": "static int get_gate_page(struct mm_struct *mm, unsigned long address,\n\t\tunsigned int gup_flags, struct vm_area_struct **vma,\n\t\tstruct page **page)\n{\n\tpgd_t *pgd;\n\tp4d_t *p4d;\n\tpud_t *pud;\n\tpmd_t *pmd;\n\tpte_t *pte;\n\tint ret = -EFAULT;\n\n\t/* user gate pages are read-only */\n\tif (gup_flags & FOLL_WRITE)\n\t\treturn -EFAULT;\n\tif (address > TASK_SIZE)\n\t\tpgd = pgd_offset_k(address);\n\telse\n\t\tpgd = pgd_offset_gate(mm, address);\n\tif (pgd_none(*pgd))\n\t\treturn -EFAULT;\n\tp4d = p4d_offset(pgd, address);\n\tif (p4d_none(*p4d))\n\t\treturn -EFAULT;\n\tpud = pud_offset(p4d, address);\n\tif (pud_none(*pud))\n\t\treturn -EFAULT;\n\tpmd = pmd_offset(pud, address);\n\tif (!pmd_present(*pmd))\n\t\treturn -EFAULT;\n\tVM_BUG_ON(pmd_trans_huge(*pmd));\n\tpte = pte_offset_map(pmd, address);\n\tif (pte_none(*pte))\n\t\tgoto unmap;\n\t*vma = get_gate_vma(mm);\n\tif (!page)\n\t\tgoto out;\n\t*page = vm_normal_page(*vma, address, *pte);\n\tif (!*page) {\n\t\tif ((gup_flags & FOLL_DUMP) || !is_zero_pfn(pte_pfn(*pte)))\n\t\t\tgoto unmap;\n\t\t*page = pte_page(*pte);\n\t}\n\tif (unlikely(!try_get_page(*page))) {\n\t\tret = -ENOMEM;\n\t\tgoto unmap;\n\t}\nout:\n\tret = 0;\nunmap:\n\tpte_unmap(pte);\n\treturn ret;\n}",
        "func_after": "static int get_gate_page(struct mm_struct *mm, unsigned long address,\n\t\tunsigned int gup_flags, struct vm_area_struct **vma,\n\t\tstruct page **page)\n{\n\tpgd_t *pgd;\n\tp4d_t *p4d;\n\tpud_t *pud;\n\tpmd_t *pmd;\n\tpte_t *pte;\n\tint ret = -EFAULT;\n\n\t/* user gate pages are read-only */\n\tif (gup_flags & FOLL_WRITE)\n\t\treturn -EFAULT;\n\tif (address > TASK_SIZE)\n\t\tpgd = pgd_offset_k(address);\n\telse\n\t\tpgd = pgd_offset_gate(mm, address);\n\tif (pgd_none(*pgd))\n\t\treturn -EFAULT;\n\tp4d = p4d_offset(pgd, address);\n\tif (p4d_none(*p4d))\n\t\treturn -EFAULT;\n\tpud = pud_offset(p4d, address);\n\tif (pud_none(*pud))\n\t\treturn -EFAULT;\n\tpmd = pmd_offset(pud, address);\n\tif (!pmd_present(*pmd))\n\t\treturn -EFAULT;\n\tVM_BUG_ON(pmd_trans_huge(*pmd));\n\tpte = pte_offset_map(pmd, address);\n\tif (pte_none(*pte))\n\t\tgoto unmap;\n\t*vma = get_gate_vma(mm);\n\tif (!page)\n\t\tgoto out;\n\t*page = vm_normal_page(*vma, address, *pte);\n\tif (!*page) {\n\t\tif ((gup_flags & FOLL_DUMP) || !is_zero_pfn(pte_pfn(*pte)))\n\t\t\tgoto unmap;\n\t\t*page = pte_page(*pte);\n\t}\n\tif (unlikely(!try_grab_page(*page, gup_flags))) {\n\t\tret = -ENOMEM;\n\t\tgoto unmap;\n\t}\nout:\n\tret = 0;\nunmap:\n\tpte_unmap(pte);\n\treturn ret;\n}",
        "description": "\"In the Linux kernel versions 5.7.x and 5.8.x prior to 5.8.7, a privilege escalation vulnerability exists due to incorrect reference counting of the struct page backing the vsyscall page, resulting in a refcount underflow. This issue can be exploited by any 64-bit process that has access to ptrace() or process_vm_readv() functions.\"",
        "commit": "It was discovered that gate pages were overlooked during the conversion from `get` to `pin_user_pages()`, leading to reference count imbalances. This issue can be reliably reproduced by running the x86 selftests with `vsyscall=emulate` enabled (the default setting). The problem arises because `pin_user_pages()` uses a \"bias\" value, manipulating the reference count by 1024 instead of 1, which is used by `get_user_pages()`. Gate pages, such as the vsyscall page, are typically part of the kernel image but are mapped to userspace, allowing access through interfaces using `get/pin_user_pages()`. The reference count of these kernel pages is adjusted similarly to normal user pages on the get/pin side to ensure consistency on the put/unpin side. However, `get_gate_page()` uses `try_get_page()`, which increments the reference count by 1, not 1024, even when called in the `pin_user_pages()` path. This results in a reference count discrepancy of 1023 when `unpin_user_pages()` is eventually called. The fix involves using `try_grab_page()` instead of `try_get_page()` and passing the appropriate flags to respect `FOLL_PIN`. This bug has been present since the introduction of `FOLL_PIN` support in commit 3faa52c03f44, which first appeared in the 5.7 release."
    }
]