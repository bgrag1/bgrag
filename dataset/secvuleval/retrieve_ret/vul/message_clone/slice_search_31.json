[
    {
        "cwe": "CWE-129",
        "func_name": "admesh/stl_fix_normal_directions",
        "score": 0.7041780352592468,
        "func_before": "void\nstl_fix_normal_directions(stl_file *stl) {\n  char *norm_sw;\n  /*  int edge_num;*/\n  /*  int vnot;*/\n  int checked = 0;\n  int facet_num;\n  /*  int next_facet;*/\n  int i;\n  int j;\n  struct stl_normal {\n    int               facet_num;\n    struct stl_normal *next;\n  };\n  struct stl_normal *head;\n  struct stl_normal *tail;\n  struct stl_normal *newn;\n  struct stl_normal *temp;\n\n  if (stl->error) return;\n\n  /* Initialize linked list. */\n  head = (struct stl_normal*)malloc(sizeof(struct stl_normal));\n  if(head == NULL) perror(\"stl_fix_normal_directions\");\n  tail = (struct stl_normal*)malloc(sizeof(struct stl_normal));\n  if(tail == NULL) perror(\"stl_fix_normal_directions\");\n  head->next = tail;\n  tail->next = tail;\n\n  /* Initialize list that keeps track of already fixed facets. */\n  norm_sw = (char*)calloc(stl->stats.number_of_facets, sizeof(char));\n  if(norm_sw == NULL) perror(\"stl_fix_normal_directions\");\n\n\n  facet_num = 0;\n  /* If normal vector is not within tolerance and backwards:\n     Arbitrarily starts at face 0.  If this one is wrong, we're screwed.  Thankfully, the chances\n     of it being wrong randomly are low if most of the triangles are right: */\n  if(stl_check_normal_vector(stl, 0, 0) == 2)\n    stl_reverse_facet(stl, 0);\n\n  /* Say that we've fixed this facet: */\n  norm_sw[facet_num] = 1;\n  checked++;\n\n  for(;;) {\n    /* Add neighbors_to_list.\n       Add unconnected neighbors to the list:a  */\n    for(j = 0; j < 3; j++) {\n      /* Reverse the neighboring facets if necessary. */\n      if(stl->neighbors_start[facet_num].which_vertex_not[j] > 2) {\n        /* If the facet has a neighbor that is -1, it means that edge isn't shared by another facet */\n        if(stl->neighbors_start[facet_num].neighbor[j] != -1) {\n          stl_reverse_facet\n          (stl, stl->neighbors_start[facet_num].neighbor[j]);\n        }\n      }\n      /* If this edge of the facet is connected: */\n      if(stl->neighbors_start[facet_num].neighbor[j] != -1) {\n        /* If we haven't fixed this facet yet, add it to the list: */\n        if(norm_sw[stl->neighbors_start[facet_num].neighbor[j]] != 1) {\n          /* Add node to beginning of list. */\n          newn = (struct stl_normal*)malloc(sizeof(struct stl_normal));\n          if(newn == NULL) perror(\"stl_fix_normal_directions\");\n          newn->facet_num = stl->neighbors_start[facet_num].neighbor[j];\n          newn->next = head->next;\n          head->next = newn;\n        }\n      }\n    }\n    /* Get next facet to fix from top of list. */\n    if(head->next != tail) {\n      facet_num = head->next->facet_num;\n      if(norm_sw[facet_num] != 1) { /* If facet is in list mutiple times */\n        norm_sw[facet_num] = 1; /* Record this one as being fixed. */\n        checked++;\n      }\n      temp = head->next;\t/* Delete this facet from the list. */\n      head->next = head->next->next;\n      free(temp);\n    } else { /* if we ran out of facets to fix: */\n      /* All of the facets in this part have been fixed. */\n      stl->stats.number_of_parts += 1;\n      if(checked >= stl->stats.number_of_facets) {\n        /* All of the facets have been checked.  Bail out. */\n        break;\n      } else {\n        /* There is another part here.  Find it and continue. */\n        for(i = 0; i < stl->stats.number_of_facets; i++) {\n          if(norm_sw[i] == 0) {\n            /* This is the first facet of the next part. */\n            facet_num = i;\n            if(stl_check_normal_vector(stl, i, 0) == 2) {\n              stl_reverse_facet(stl, i);\n            }\n\n            norm_sw[facet_num] = 1;\n            checked++;\n            break;\n          }\n        }\n      }\n    }\n  }\n  free(head);\n  free(tail);\n  free(norm_sw);\n}",
        "func_after": "void\nstl_fix_normal_directions(stl_file *stl) {\n  char *norm_sw;\n  /*  int edge_num;*/\n  /*  int vnot;*/\n  int checked = 0;\n  int facet_num;\n  /*  int next_facet;*/\n  int i;\n  int j;\n  struct stl_normal {\n    int               facet_num;\n    struct stl_normal *next;\n  };\n  struct stl_normal *head;\n  struct stl_normal *tail;\n  struct stl_normal *newn;\n  struct stl_normal *temp;\n\n  if (stl->error) return;\n\n  /* Initialize linked list. */\n  head = (struct stl_normal*)malloc(sizeof(struct stl_normal));\n  if(head == NULL) perror(\"stl_fix_normal_directions\");\n  tail = (struct stl_normal*)malloc(sizeof(struct stl_normal));\n  if(tail == NULL) perror(\"stl_fix_normal_directions\");\n  head->next = tail;\n  tail->next = tail;\n\n  /* Initialize list that keeps track of already fixed facets. */\n  norm_sw = (char*)calloc(stl->stats.number_of_facets, sizeof(char));\n  if(norm_sw == NULL) perror(\"stl_fix_normal_directions\");\n\n\n  facet_num = 0;\n  /* If normal vector is not within tolerance and backwards:\n     Arbitrarily starts at face 0.  If this one is wrong, we're screwed.  Thankfully, the chances\n     of it being wrong randomly are low if most of the triangles are right: */\n  if(stl_check_normal_vector(stl, 0, 0) == 2)\n    stl_reverse_facet(stl, 0);\n\n  /* Say that we've fixed this facet: */\n  norm_sw[facet_num] = 1;\n  checked++;\n\n  for(;;) {\n    /* Add neighbors_to_list.\n       Add unconnected neighbors to the list:a  */\n    for(j = 0; j < 3; j++) {\n      /* Reverse the neighboring facets if necessary. */\n      if(stl->neighbors_start[facet_num].which_vertex_not[j] > 2) {\n        /* If the facet has a neighbor that is -1, it means that edge isn't shared by another facet */\n        if(stl->neighbors_start[facet_num].neighbor[j] != -1) {\n          stl_reverse_facet\n          (stl, stl->neighbors_start[facet_num].neighbor[j]);\n        }\n      }\n      /* If this edge of the facet is connected: */\n      if(stl->neighbors_start[facet_num].neighbor[j] != -1 &&\n         stl->neighbors_start[facet_num].neighbor[j] < stl->stats.number_of_facets*sizeof(char)) {\n        /* If we haven't fixed this facet yet, add it to the list: */\n        if(norm_sw[stl->neighbors_start[facet_num].neighbor[j]] != 1) {\n          /* Add node to beginning of list. */\n          newn = (struct stl_normal*)malloc(sizeof(struct stl_normal));\n          if(newn == NULL) perror(\"stl_fix_normal_directions\");\n          newn->facet_num = stl->neighbors_start[facet_num].neighbor[j];\n          newn->next = head->next;\n          head->next = newn;\n        }\n      }\n    }\n    /* Get next facet to fix from top of list. */\n    if(head->next != tail) {\n      facet_num = head->next->facet_num;\n      if(norm_sw[facet_num] != 1) { /* If facet is in list mutiple times */\n        norm_sw[facet_num] = 1; /* Record this one as being fixed. */\n        checked++;\n      }\n      temp = head->next;\t/* Delete this facet from the list. */\n      head->next = head->next->next;\n      free(temp);\n    } else { /* if we ran out of facets to fix: */\n      /* All of the facets in this part have been fixed. */\n      stl->stats.number_of_parts += 1;\n      if(checked >= stl->stats.number_of_facets) {\n        /* All of the facets have been checked.  Bail out. */\n        break;\n      } else {\n        /* There is another part here.  Find it and continue. */\n        for(i = 0; i < stl->stats.number_of_facets; i++) {\n          if(norm_sw[i] == 0) {\n            /* This is the first facet of the next part. */\n            facet_num = i;\n            if(stl_check_normal_vector(stl, i, 0) == 2) {\n              stl_reverse_facet(stl, i);\n            }\n\n            norm_sw[facet_num] = 1;\n            checked++;\n            break;\n          }\n        }\n      }\n    }\n  }\n  free(head);\n  free(tail);\n  free(norm_sw);\n}",
        "description": "An improper array index validation vulnerability exists in the stl_fix_normal_directions functionality of ADMesh. A specially-crafted STL file can lead to a heap buffer overflow. An attacker can exploit this by providing a malicious file.",
        "commit": "The vulnerability involves a check for the `neighbor_index` within the `stl_check_normal_vector` function. This fix addresses an issue identified in ticket #60."
    },
    {
        "cwe": "CWE-191",
        "func_name": "torvalds/deassemble_neg_contexts",
        "score": 0.7316998839378357,
        "func_before": "static __le32 deassemble_neg_contexts(struct ksmbd_conn *conn,\n\t\t\t\t      struct smb2_negotiate_req *req,\n\t\t\t\t      int len_of_smb)\n{\n\t/* +4 is to account for the RFC1001 len field */\n\tstruct smb2_neg_context *pctx = (struct smb2_neg_context *)req;\n\tint i = 0, len_of_ctxts;\n\tint offset = le32_to_cpu(req->NegotiateContextOffset);\n\tint neg_ctxt_cnt = le16_to_cpu(req->NegotiateContextCount);\n\t__le32 status = STATUS_INVALID_PARAMETER;\n\n\tksmbd_debug(SMB, \"decoding %d negotiate contexts\\n\", neg_ctxt_cnt);\n\tif (len_of_smb <= offset) {\n\t\tksmbd_debug(SMB, \"Invalid response: negotiate context offset\\n\");\n\t\treturn status;\n\t}\n\n\tlen_of_ctxts = len_of_smb - offset;\n\n\twhile (i++ < neg_ctxt_cnt) {\n\t\tint clen, ctxt_len;\n\n\t\tif (len_of_ctxts < sizeof(struct smb2_neg_context))\n\t\t\tbreak;\n\n\t\tpctx = (struct smb2_neg_context *)((char *)pctx + offset);\n\t\tclen = le16_to_cpu(pctx->DataLength);\n\t\tctxt_len = clen + sizeof(struct smb2_neg_context);\n\n\t\tif (ctxt_len > len_of_ctxts)\n\t\t\tbreak;\n\n\t\tif (pctx->ContextType == SMB2_PREAUTH_INTEGRITY_CAPABILITIES) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_PREAUTH_INTEGRITY_CAPABILITIES context\\n\");\n\t\t\tif (conn->preauth_info->Preauth_HashId)\n\t\t\t\tbreak;\n\n\t\t\tstatus = decode_preauth_ctxt(conn,\n\t\t\t\t\t\t     (struct smb2_preauth_neg_context *)pctx,\n\t\t\t\t\t\t     ctxt_len);\n\t\t\tif (status != STATUS_SUCCESS)\n\t\t\t\tbreak;\n\t\t} else if (pctx->ContextType == SMB2_ENCRYPTION_CAPABILITIES) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_ENCRYPTION_CAPABILITIES context\\n\");\n\t\t\tif (conn->cipher_type)\n\t\t\t\tbreak;\n\n\t\t\tdecode_encrypt_ctxt(conn,\n\t\t\t\t\t    (struct smb2_encryption_neg_context *)pctx,\n\t\t\t\t\t    ctxt_len);\n\t\t} else if (pctx->ContextType == SMB2_COMPRESSION_CAPABILITIES) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_COMPRESSION_CAPABILITIES context\\n\");\n\t\t\tif (conn->compress_algorithm)\n\t\t\t\tbreak;\n\n\t\t\tdecode_compress_ctxt(conn,\n\t\t\t\t\t     (struct smb2_compression_capabilities_context *)pctx);\n\t\t} else if (pctx->ContextType == SMB2_NETNAME_NEGOTIATE_CONTEXT_ID) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_NETNAME_NEGOTIATE_CONTEXT_ID context\\n\");\n\t\t} else if (pctx->ContextType == SMB2_POSIX_EXTENSIONS_AVAILABLE) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_POSIX_EXTENSIONS_AVAILABLE context\\n\");\n\t\t\tconn->posix_ext_supported = true;\n\t\t} else if (pctx->ContextType == SMB2_SIGNING_CAPABILITIES) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_SIGNING_CAPABILITIES context\\n\");\n\n\t\t\tdecode_sign_cap_ctxt(conn,\n\t\t\t\t\t     (struct smb2_signing_capabilities *)pctx,\n\t\t\t\t\t     ctxt_len);\n\t\t}\n\n\t\t/* offsets must be 8 byte aligned */\n\t\tclen = (clen + 7) & ~0x7;\n\t\toffset = clen + sizeof(struct smb2_neg_context);\n\t\tlen_of_ctxts -= clen + sizeof(struct smb2_neg_context);\n\t}\n\treturn status;\n}",
        "func_after": "static __le32 deassemble_neg_contexts(struct ksmbd_conn *conn,\n\t\t\t\t      struct smb2_negotiate_req *req,\n\t\t\t\t      unsigned int len_of_smb)\n{\n\t/* +4 is to account for the RFC1001 len field */\n\tstruct smb2_neg_context *pctx = (struct smb2_neg_context *)req;\n\tint i = 0, len_of_ctxts;\n\tunsigned int offset = le32_to_cpu(req->NegotiateContextOffset);\n\tunsigned int neg_ctxt_cnt = le16_to_cpu(req->NegotiateContextCount);\n\t__le32 status = STATUS_INVALID_PARAMETER;\n\n\tksmbd_debug(SMB, \"decoding %d negotiate contexts\\n\", neg_ctxt_cnt);\n\tif (len_of_smb <= offset) {\n\t\tksmbd_debug(SMB, \"Invalid response: negotiate context offset\\n\");\n\t\treturn status;\n\t}\n\n\tlen_of_ctxts = len_of_smb - offset;\n\n\twhile (i++ < neg_ctxt_cnt) {\n\t\tint clen, ctxt_len;\n\n\t\tif (len_of_ctxts < (int)sizeof(struct smb2_neg_context))\n\t\t\tbreak;\n\n\t\tpctx = (struct smb2_neg_context *)((char *)pctx + offset);\n\t\tclen = le16_to_cpu(pctx->DataLength);\n\t\tctxt_len = clen + sizeof(struct smb2_neg_context);\n\n\t\tif (ctxt_len > len_of_ctxts)\n\t\t\tbreak;\n\n\t\tif (pctx->ContextType == SMB2_PREAUTH_INTEGRITY_CAPABILITIES) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_PREAUTH_INTEGRITY_CAPABILITIES context\\n\");\n\t\t\tif (conn->preauth_info->Preauth_HashId)\n\t\t\t\tbreak;\n\n\t\t\tstatus = decode_preauth_ctxt(conn,\n\t\t\t\t\t\t     (struct smb2_preauth_neg_context *)pctx,\n\t\t\t\t\t\t     ctxt_len);\n\t\t\tif (status != STATUS_SUCCESS)\n\t\t\t\tbreak;\n\t\t} else if (pctx->ContextType == SMB2_ENCRYPTION_CAPABILITIES) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_ENCRYPTION_CAPABILITIES context\\n\");\n\t\t\tif (conn->cipher_type)\n\t\t\t\tbreak;\n\n\t\t\tdecode_encrypt_ctxt(conn,\n\t\t\t\t\t    (struct smb2_encryption_neg_context *)pctx,\n\t\t\t\t\t    ctxt_len);\n\t\t} else if (pctx->ContextType == SMB2_COMPRESSION_CAPABILITIES) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_COMPRESSION_CAPABILITIES context\\n\");\n\t\t\tif (conn->compress_algorithm)\n\t\t\t\tbreak;\n\n\t\t\tdecode_compress_ctxt(conn,\n\t\t\t\t\t     (struct smb2_compression_capabilities_context *)pctx);\n\t\t} else if (pctx->ContextType == SMB2_NETNAME_NEGOTIATE_CONTEXT_ID) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_NETNAME_NEGOTIATE_CONTEXT_ID context\\n\");\n\t\t} else if (pctx->ContextType == SMB2_POSIX_EXTENSIONS_AVAILABLE) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_POSIX_EXTENSIONS_AVAILABLE context\\n\");\n\t\t\tconn->posix_ext_supported = true;\n\t\t} else if (pctx->ContextType == SMB2_SIGNING_CAPABILITIES) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_SIGNING_CAPABILITIES context\\n\");\n\n\t\t\tdecode_sign_cap_ctxt(conn,\n\t\t\t\t\t     (struct smb2_signing_capabilities *)pctx,\n\t\t\t\t\t     ctxt_len);\n\t\t}\n\n\t\t/* offsets must be 8 byte aligned */\n\t\toffset = (ctxt_len + 7) & ~0x7;\n\t\tlen_of_ctxts -= offset;\n\t}\n\treturn status;\n}",
        "description": "An issue was discovered in the Linux kernel prior to version 6.3.8. Within the ksmbd component located in the SMB server directory, there is an integer underflow and out-of-bounds read vulnerability in the deassemble_neg_contexts function.",
        "commit": "The vulnerability involves an integer underflow condition in the SMB2 protocol negotiation process within the Linux kernel. Specifically, the initial check compares `clen + sizeof(struct smb2_neg_context)` against `len_of_ctxts`. However, during the loop, `len_of_ctxts` is decremented by `((clen + 7) & ~0x7) + sizeof(struct smb2_neg_context)`, which can lead to an underflow if `clen` undergoes 8-byte alignment. To prevent this, the check should use `(clen + 7) & ~0x7` instead. Additionally, certain variables should be declared as unsigned to avoid similar issues. The vulnerability results in a slab-out-of-bounds read error, as indicated by the kernel log, leading to potential memory corruption and system instability."
    },
    {
        "cwe": "CWE-1284",
        "func_name": "Samsung/crypto_bignum_allocate",
        "score": 0.699979841709137,
        "func_before": "struct bignum *crypto_bignum_allocate(size_t size_bits)\n{\n\tsize_t sz = mpa_StaticVarSizeInU32(size_bits) *\tsizeof(uint32_t);\n\tstruct mpa_numbase_struct *bn = calloc(1, sz);\n\n\tif (!bn)\n\t\treturn NULL;\n\tbn->alloc = sz - MPA_NUMBASE_METADATA_SIZE_IN_U32 * sizeof(uint32_t);\n\treturn (struct bignum *)bn;\n}",
        "func_after": "struct bignum *crypto_bignum_allocate(size_t size_bits)\n{\n\tsize_t sz = mpa_StaticVarSizeInU32(size_bits) *\tsizeof(uint32_t);\n\t// struct mpa_numbase_struct *bn = calloc(1, sz);\n\tstruct mpa_numbase_struct *bn= TEE_Malloc(sz, TEE_MALLOC_FILL_ZERO);\n\tif (!bn)\n\t\treturn NULL;\n\tbn->alloc = sz - MPA_NUMBASE_METADATA_SIZE_IN_U32 * sizeof(uint32_t);\n\treturn (struct bignum *)bn;\n}",
        "description": "The function `tee_obj_free` in Samsung mTower through version 0.3.0 enables a trusted application to cause a Denial of Service (DoS) by calling the function `TEE_AllocateOperation` with a disrupted heap layout, which is associated with `utee_cryp_obj_alloc`.",
        "commit": "A vulnerability has been addressed in a software system, specifically identified by CVE-2022-40761."
    },
    {
        "cwe": "CWE-254",
        "func_name": "android/impeg2d_dec_d_slice",
        "score": 0.7127395868301392,
        "func_before": "IMPEG2D_ERROR_CODES_T impeg2d_dec_d_slice(dec_state_t *ps_dec)\n{\n    UWORD32 i;\n    yuv_buf_t *ps_cur_frm_buf  = &ps_dec->s_cur_frm_buf;\n\n    stream_t   *ps_stream       = &ps_dec->s_bit_stream;\n    UWORD8   *pu1_vld_buf;\n\n    WORD16 i2_dc_diff;\n    UWORD32 u4_frame_width = ps_dec->u2_frame_width;\n    UWORD32 u4_frm_offset = 0;\n    if(ps_dec->u2_picture_structure != FRAME_PICTURE)\n    {\n        u4_frame_width <<= 1;\n        if(ps_dec->u2_picture_structure == BOTTOM_FIELD)\n        {\n            u4_frm_offset = ps_dec->u2_frame_width;\n        }\n    }\n\n    do\n    {\n\n        UWORD32 u4_x_offset, u4_y_offset;\n        UWORD32 u4_blk_pos;\n        WORD16 i2_dc_val;\n\n        UWORD32 u4_dst_x_offset     = u4_frm_offset + (ps_dec->u2_mb_x << 4);\n        UWORD32 u4_dst_y_offset     = (ps_dec->u2_mb_y << 4) * u4_frame_width;\n        UWORD8 *pu1_vld_buf8        = ps_cur_frm_buf->pu1_y + u4_dst_x_offset + u4_dst_y_offset;\n        UWORD32 u4_dst_wd           = u4_frame_width;\n        /*------------------------------------------------------------------*/\n        /* Discard the Macroblock stuffing in case of MPEG-1 stream         */\n        /*------------------------------------------------------------------*/\n        while(impeg2d_bit_stream_nxt(ps_stream,MB_STUFFING_CODE_LEN) == MB_STUFFING_CODE)\n            impeg2d_bit_stream_flush(ps_stream,MB_STUFFING_CODE_LEN);\n\n        /*------------------------------------------------------------------*/\n        /* Flush 2 bits from bitstream [MB_Type and MacroBlockAddrIncrement]*/\n        /*------------------------------------------------------------------*/\n        impeg2d_bit_stream_flush(ps_stream,1);\n\n        if(impeg2d_bit_stream_get(ps_stream, 1) != 0x01)\n        {\n            /* Ignore and continue decoding. */\n        }\n\n        /* Process LUMA blocks of the MB */\n        for(i = 0; i < NUM_LUMA_BLKS; ++i)\n        {\n\n            u4_x_offset    = gai2_impeg2_blk_x_off[i];\n            u4_y_offset    = gai2_impeg2_blk_y_off_frm[i] ;\n            u4_blk_pos     = (u4_y_offset * u4_dst_wd) + u4_x_offset;\n            pu1_vld_buf     = pu1_vld_buf8 + u4_blk_pos;\n\n            i2_dc_diff = impeg2d_get_luma_dc_diff(ps_stream);\n            i2_dc_val = ps_dec->u2_def_dc_pred[Y_LUMA] + i2_dc_diff;\n            ps_dec->u2_def_dc_pred[Y_LUMA] = i2_dc_val;\n            i2_dc_val = CLIP_U8(i2_dc_val);\n\n            ps_dec->pf_memset_8bit_8x8_block(pu1_vld_buf, i2_dc_val, u4_dst_wd);\n        }\n\n\n\n        /* Process U block of the MB */\n\n        u4_dst_x_offset                >>= 1;\n        u4_dst_y_offset                >>= 2;\n        u4_dst_wd                      >>= 1;\n        pu1_vld_buf                     = ps_cur_frm_buf->pu1_u + u4_dst_x_offset + u4_dst_y_offset;\n        i2_dc_diff                     = impeg2d_get_chroma_dc_diff(ps_stream);\n        i2_dc_val                      = ps_dec->u2_def_dc_pred[U_CHROMA] + i2_dc_diff;\n        ps_dec->u2_def_dc_pred[U_CHROMA]    = i2_dc_val;\n        i2_dc_val = CLIP_U8(i2_dc_val);\n        ps_dec->pf_memset_8bit_8x8_block(pu1_vld_buf, i2_dc_val, u4_dst_wd);\n\n\n        /* Process V block of the MB */\n\n        pu1_vld_buf                     = ps_cur_frm_buf->pu1_v + u4_dst_x_offset + u4_dst_y_offset;\n        i2_dc_diff                     = impeg2d_get_chroma_dc_diff(ps_stream);\n        i2_dc_val                      = ps_dec->u2_def_dc_pred[V_CHROMA] + i2_dc_diff;\n        ps_dec->u2_def_dc_pred[V_CHROMA]    = i2_dc_val;\n        i2_dc_val = CLIP_U8(i2_dc_val);\n        ps_dec->pf_memset_8bit_8x8_block(pu1_vld_buf, i2_dc_val, u4_dst_wd);\n\n        /* Common MB processing Steps */\n\n\n        ps_dec->u2_num_mbs_left--;\n        ps_dec->u2_mb_x++;\n\n        if(ps_dec->s_bit_stream.u4_offset > ps_dec->s_bit_stream.u4_max_offset)\n        {\n            return IMPEG2D_BITSTREAM_BUFF_EXCEEDED_ERR;\n        }\n        else if (ps_dec->u2_mb_x == ps_dec->u2_num_horiz_mb)\n        {\n            ps_dec->u2_mb_x = 0;\n            ps_dec->u2_mb_y++;\n\n        }\n\n        /* Flush end of macro block */\n        impeg2d_bit_stream_flush(ps_stream,1);\n    }\n    while(ps_dec->u2_num_mbs_left != 0 && impeg2d_bit_stream_nxt(&ps_dec->s_bit_stream,23) != 0x0);\n    return (IMPEG2D_ERROR_CODES_T)IVD_ERROR_NONE;\n}",
        "func_after": "IMPEG2D_ERROR_CODES_T impeg2d_dec_d_slice(dec_state_t *ps_dec)\n{\n    UWORD32 i;\n    yuv_buf_t *ps_cur_frm_buf  = &ps_dec->s_cur_frm_buf;\n\n    stream_t   *ps_stream       = &ps_dec->s_bit_stream;\n    UWORD8   *pu1_vld_buf;\n\n    WORD16 i2_dc_diff;\n    UWORD32 u4_frame_width = ps_dec->u2_frame_width;\n    UWORD32 u4_frm_offset = 0;\n    if(ps_dec->u2_picture_structure != FRAME_PICTURE)\n    {\n        u4_frame_width <<= 1;\n        if(ps_dec->u2_picture_structure == BOTTOM_FIELD)\n        {\n            u4_frm_offset = ps_dec->u2_frame_width;\n        }\n    }\n\n    do\n    {\n\n        UWORD32 u4_x_offset, u4_y_offset;\n        UWORD32 u4_blk_pos;\n        WORD16 i2_dc_val;\n\n        UWORD32 u4_dst_x_offset     = u4_frm_offset + (ps_dec->u2_mb_x << 4);\n        UWORD32 u4_dst_y_offset     = (ps_dec->u2_mb_y << 4) * u4_frame_width;\n        UWORD8 *pu1_vld_buf8        = ps_cur_frm_buf->pu1_y + u4_dst_x_offset + u4_dst_y_offset;\n        UWORD32 u4_dst_wd           = u4_frame_width;\n        /*------------------------------------------------------------------*/\n        /* Discard the Macroblock stuffing in case of MPEG-1 stream         */\n        /*------------------------------------------------------------------*/\n        while(impeg2d_bit_stream_nxt(ps_stream,MB_STUFFING_CODE_LEN) == MB_STUFFING_CODE &&\n                ps_stream->u4_offset < ps_stream->u4_max_offset)\n            impeg2d_bit_stream_flush(ps_stream,MB_STUFFING_CODE_LEN);\n\n        /*------------------------------------------------------------------*/\n        /* Flush 2 bits from bitstream [MB_Type and MacroBlockAddrIncrement]*/\n        /*------------------------------------------------------------------*/\n        impeg2d_bit_stream_flush(ps_stream,1);\n\n        if(impeg2d_bit_stream_get(ps_stream, 1) != 0x01)\n        {\n            /* Ignore and continue decoding. */\n        }\n\n        /* Process LUMA blocks of the MB */\n        for(i = 0; i < NUM_LUMA_BLKS; ++i)\n        {\n\n            u4_x_offset    = gai2_impeg2_blk_x_off[i];\n            u4_y_offset    = gai2_impeg2_blk_y_off_frm[i] ;\n            u4_blk_pos     = (u4_y_offset * u4_dst_wd) + u4_x_offset;\n            pu1_vld_buf     = pu1_vld_buf8 + u4_blk_pos;\n\n            i2_dc_diff = impeg2d_get_luma_dc_diff(ps_stream);\n            i2_dc_val = ps_dec->u2_def_dc_pred[Y_LUMA] + i2_dc_diff;\n            ps_dec->u2_def_dc_pred[Y_LUMA] = i2_dc_val;\n            i2_dc_val = CLIP_U8(i2_dc_val);\n\n            ps_dec->pf_memset_8bit_8x8_block(pu1_vld_buf, i2_dc_val, u4_dst_wd);\n        }\n\n\n\n        /* Process U block of the MB */\n\n        u4_dst_x_offset                >>= 1;\n        u4_dst_y_offset                >>= 2;\n        u4_dst_wd                      >>= 1;\n        pu1_vld_buf                     = ps_cur_frm_buf->pu1_u + u4_dst_x_offset + u4_dst_y_offset;\n        i2_dc_diff                     = impeg2d_get_chroma_dc_diff(ps_stream);\n        i2_dc_val                      = ps_dec->u2_def_dc_pred[U_CHROMA] + i2_dc_diff;\n        ps_dec->u2_def_dc_pred[U_CHROMA]    = i2_dc_val;\n        i2_dc_val = CLIP_U8(i2_dc_val);\n        ps_dec->pf_memset_8bit_8x8_block(pu1_vld_buf, i2_dc_val, u4_dst_wd);\n\n\n        /* Process V block of the MB */\n\n        pu1_vld_buf                     = ps_cur_frm_buf->pu1_v + u4_dst_x_offset + u4_dst_y_offset;\n        i2_dc_diff                     = impeg2d_get_chroma_dc_diff(ps_stream);\n        i2_dc_val                      = ps_dec->u2_def_dc_pred[V_CHROMA] + i2_dc_diff;\n        ps_dec->u2_def_dc_pred[V_CHROMA]    = i2_dc_val;\n        i2_dc_val = CLIP_U8(i2_dc_val);\n        ps_dec->pf_memset_8bit_8x8_block(pu1_vld_buf, i2_dc_val, u4_dst_wd);\n\n        /* Common MB processing Steps */\n\n\n        ps_dec->u2_num_mbs_left--;\n        ps_dec->u2_mb_x++;\n\n        if(ps_dec->s_bit_stream.u4_offset > ps_dec->s_bit_stream.u4_max_offset)\n        {\n            return IMPEG2D_BITSTREAM_BUFF_EXCEEDED_ERR;\n        }\n        else if (ps_dec->u2_mb_x == ps_dec->u2_num_horiz_mb)\n        {\n            ps_dec->u2_mb_x = 0;\n            ps_dec->u2_mb_y++;\n\n        }\n\n        /* Flush end of macro block */\n        impeg2d_bit_stream_flush(ps_stream,1);\n    }\n    while(ps_dec->u2_num_mbs_left != 0 && impeg2d_bit_stream_nxt(&ps_dec->s_bit_stream,23) != 0x0);\n    return (IMPEG2D_ERROR_CODES_T)IVD_ERROR_NONE;\n}",
        "description": "libstagefright in Android versions prior to March 1, 2016, contains a vulnerability that allows attackers to gain unauthorized access to sensitive information by manipulating Bitstream data. This flaw enables attackers to potentially bypass an unspecified security mechanism, such as Signature or SignatureOrSystem access, through crafted input.",
        "commit": "Fixed bit stream access to ensure that reads do not exceed the allocated size."
    },
    {
        "cwe": "CWE-345",
        "func_name": "xen-project/set_iommu_pde_present",
        "score": 0.6820824146270752,
        "func_before": "static unsigned int set_iommu_pde_present(struct amd_iommu_pte *pte,\n                                          unsigned long next_mfn,\n                                          unsigned int next_level, bool iw,\n                                          bool ir)\n{\n    unsigned int flush_flags = IOMMU_FLUSHF_added;\n\n    if ( pte->pr &&\n         (pte->mfn != next_mfn ||\n          pte->iw != iw ||\n          pte->ir != ir ||\n          pte->next_level != next_level) )\n            flush_flags |= IOMMU_FLUSHF_modified;\n\n    /*\n     * FC bit should be enabled in PTE, this helps to solve potential\n     * issues with ATS devices\n     */\n    pte->fc = !next_level;\n\n    pte->mfn = next_mfn;\n    pte->iw = iw;\n    pte->ir = ir;\n    pte->next_level = next_level;\n    pte->pr = 1;\n\n    return flush_flags;\n}",
        "func_after": "static unsigned int set_iommu_pde_present(union amd_iommu_pte *pte,\n                                          unsigned long next_mfn,\n                                          unsigned int next_level, bool iw,\n                                          bool ir)\n{\n    unsigned int flush_flags = IOMMU_FLUSHF_added;\n\n    if ( pte->pr &&\n         (pte->mfn != next_mfn ||\n          pte->iw != iw ||\n          pte->ir != ir ||\n          pte->next_level != next_level) )\n            flush_flags |= IOMMU_FLUSHF_modified;\n\n    /*\n     * FC bit should be enabled in PTE, this helps to solve potential\n     * issues with ATS devices\n     */\n    pte->fc = !next_level;\n\n    pte->mfn = next_mfn;\n    pte->iw = iw;\n    pte->ir = ir;\n    pte->next_level = next_level;\n    pte->pr = 1;\n\n    return flush_flags;\n}",
        "description": "An issue was discovered in Xen versions up to 4.14.x, where x86 guest operating system users could potentially cause a denial of service through data corruption, lead to a data leak, or escalate privileges by exploiting a condition where an AMD IOMMU page-table entry is partially updated.",
        "commit": "Updating live Page Table Entries (PTEs) atomically is crucial to prevent issues related to compiler reordering and partial updates. The vulnerability arises when updating PTEs bit by bit, which can lead to the compiler rearranging these updates or splitting them into multiple memory writes. To mitigate this, it is recommended to construct the new PTE entry entirely in a local variable, perform the necessary checks based on this complete entry, and then write the new entry in a single instruction. Additionally, using functions like `memset()` to clear PTEs is unsafe because the order of writes is undefined, potentially leading to incomplete or incorrect clearing of the PTE. This issue is part of XSA-347."
    }
]