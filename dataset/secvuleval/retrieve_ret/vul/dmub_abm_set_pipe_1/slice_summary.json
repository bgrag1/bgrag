[
    {
        "cwe": "CWE-776",
        "func_name": "libexpat/externalParEntProcessor",
        "score": 0.7257348299026489,
        "func_before": "static enum XML_Error PTRCALL\nexternalParEntProcessor(XML_Parser parser, const char *s, const char *end,\n                        const char **nextPtr) {\n  const char *next = s;\n  int tok;\n\n  tok = XmlPrologTok(parser->m_encoding, s, end, &next);\n  if (tok <= 0) {\n    if (! parser->m_parsingStatus.finalBuffer && tok != XML_TOK_INVALID) {\n      *nextPtr = s;\n      return XML_ERROR_NONE;\n    }\n    switch (tok) {\n    case XML_TOK_INVALID:\n      return XML_ERROR_INVALID_TOKEN;\n    case XML_TOK_PARTIAL:\n      return XML_ERROR_UNCLOSED_TOKEN;\n    case XML_TOK_PARTIAL_CHAR:\n      return XML_ERROR_PARTIAL_CHAR;\n    case XML_TOK_NONE: /* start == end */\n    default:\n      break;\n    }\n  }\n  /* This would cause the next stage, i.e. doProlog to be passed XML_TOK_BOM.\n     However, when parsing an external subset, doProlog will not accept a BOM\n     as valid, and report a syntax error, so we have to skip the BOM\n  */\n  else if (tok == XML_TOK_BOM) {\n    s = next;\n    tok = XmlPrologTok(parser->m_encoding, s, end, &next);\n  }\n\n  parser->m_processor = prologProcessor;\n  return doProlog(parser, parser->m_encoding, s, end, tok, next, nextPtr,\n                  (XML_Bool)! parser->m_parsingStatus.finalBuffer);\n}",
        "func_after": "static enum XML_Error PTRCALL\nexternalParEntProcessor(XML_Parser parser, const char *s, const char *end,\n                        const char **nextPtr) {\n  const char *next = s;\n  int tok;\n\n  tok = XmlPrologTok(parser->m_encoding, s, end, &next);\n  if (tok <= 0) {\n    if (! parser->m_parsingStatus.finalBuffer && tok != XML_TOK_INVALID) {\n      *nextPtr = s;\n      return XML_ERROR_NONE;\n    }\n    switch (tok) {\n    case XML_TOK_INVALID:\n      return XML_ERROR_INVALID_TOKEN;\n    case XML_TOK_PARTIAL:\n      return XML_ERROR_UNCLOSED_TOKEN;\n    case XML_TOK_PARTIAL_CHAR:\n      return XML_ERROR_PARTIAL_CHAR;\n    case XML_TOK_NONE: /* start == end */\n    default:\n      break;\n    }\n  }\n  /* This would cause the next stage, i.e. doProlog to be passed XML_TOK_BOM.\n     However, when parsing an external subset, doProlog will not accept a BOM\n     as valid, and report a syntax error, so we have to skip the BOM\n  */\n  else if (tok == XML_TOK_BOM) {\n    s = next;\n    tok = XmlPrologTok(parser->m_encoding, s, end, &next);\n  }\n\n  parser->m_processor = prologProcessor;\n  return doProlog(parser, parser->m_encoding, s, end, tok, next, nextPtr,\n                  (XML_Bool)! parser->m_parsingStatus.finalBuffer, XML_TRUE);\n}",
        "description": "In versions of libexpat prior to 2.2.8, maliciously crafted XML input could cause the parser to prematurely transition from DTD parsing to document parsing. Subsequently, invoking functions such as XML_GetCurrentLineNumber or XML_GetCurrentColumnNumber led to a heap-based buffer over-read.",
        "commit": "output: \"Denial of service vulnerability due to improper handling of internal entities within the XML parsing process.\""
    },
    {
        "cwe": "CWE-74",
        "func_name": "flatpak/flatpak_run_add_environment_args",
        "score": 0.7762910723686218,
        "func_before": "gboolean\nflatpak_run_add_environment_args (FlatpakBwrap    *bwrap,\n                                  const char      *app_info_path,\n                                  FlatpakRunFlags  flags,\n                                  const char      *app_id,\n                                  FlatpakContext  *context,\n                                  GFile           *app_id_dir,\n                                  GPtrArray       *previous_app_id_dirs,\n                                  FlatpakExports **exports_out,\n                                  GCancellable    *cancellable,\n                                  GError         **error)\n{\n  g_autoptr(GError) my_error = NULL;\n  g_autoptr(FlatpakExports) exports = NULL;\n  g_autoptr(FlatpakBwrap) proxy_arg_bwrap = flatpak_bwrap_new (flatpak_bwrap_empty_env);\n  gboolean has_wayland = FALSE;\n  gboolean allow_x11 = FALSE;\n\n  if ((context->shares & FLATPAK_CONTEXT_SHARED_IPC) == 0)\n    {\n      g_debug (\"Disallowing ipc access\");\n      flatpak_bwrap_add_args (bwrap, \"--unshare-ipc\", NULL);\n    }\n\n  if ((context->shares & FLATPAK_CONTEXT_SHARED_NETWORK) == 0)\n    {\n      g_debug (\"Disallowing network access\");\n      flatpak_bwrap_add_args (bwrap, \"--unshare-net\", NULL);\n    }\n\n  if (context->devices & FLATPAK_CONTEXT_DEVICE_ALL)\n    {\n      flatpak_bwrap_add_args (bwrap,\n                              \"--dev-bind\", \"/dev\", \"/dev\",\n                              NULL);\n      /* Don't expose the host /dev/shm, just the device nodes, unless explicitly allowed */\n      if (g_file_test (\"/dev/shm\", G_FILE_TEST_IS_DIR))\n        {\n          if ((context->devices & FLATPAK_CONTEXT_DEVICE_SHM) == 0)\n            flatpak_bwrap_add_args (bwrap,\n                                    \"--tmpfs\", \"/dev/shm\",\n                                    NULL);\n        }\n      else if (g_file_test (\"/dev/shm\", G_FILE_TEST_IS_SYMLINK))\n        {\n          g_autofree char *link = flatpak_readlink (\"/dev/shm\", NULL);\n\n          /* On debian (with sysv init) the host /dev/shm is a symlink to /run/shm, so we can't\n             mount on top of it. */\n          if (g_strcmp0 (link, \"/run/shm\") == 0)\n            {\n              if (context->devices & FLATPAK_CONTEXT_DEVICE_SHM &&\n                  g_file_test (\"/run/shm\", G_FILE_TEST_IS_DIR))\n                flatpak_bwrap_add_args (bwrap,\n                                        \"--bind\", \"/run/shm\", \"/run/shm\",\n                                        NULL);\n              else\n                flatpak_bwrap_add_args (bwrap,\n                                        \"--dir\", \"/run/shm\",\n                                        NULL);\n            }\n          else\n            g_warning (\"Unexpected /dev/shm symlink %s\", link);\n        }\n    }\n  else\n    {\n      flatpak_bwrap_add_args (bwrap,\n                              \"--dev\", \"/dev\",\n                              NULL);\n      if (context->devices & FLATPAK_CONTEXT_DEVICE_DRI)\n        {\n          g_debug (\"Allowing dri access\");\n          int i;\n          char *dri_devices[] = {\n            \"/dev/dri\",\n            /* mali */\n            \"/dev/mali\",\n            \"/dev/mali0\",\n            \"/dev/umplock\",\n            /* nvidia */\n            \"/dev/nvidiactl\",\n            \"/dev/nvidia-modeset\",\n            /* nvidia OpenCL/CUDA */\n            \"/dev/nvidia-uvm\",\n            \"/dev/nvidia-uvm-tools\",\n          };\n\n          for (i = 0; i < G_N_ELEMENTS (dri_devices); i++)\n            {\n              if (g_file_test (dri_devices[i], G_FILE_TEST_EXISTS))\n                flatpak_bwrap_add_args (bwrap, \"--dev-bind\", dri_devices[i], dri_devices[i], NULL);\n            }\n\n          /* Each Nvidia card gets its own device.\n             This is a fairly arbitrary limit but ASUS sells mining boards supporting 20 in theory. */\n          char nvidia_dev[14]; /* /dev/nvidia plus up to 2 digits */\n          for (i = 0; i < 20; i++)\n            {\n              g_snprintf (nvidia_dev, sizeof (nvidia_dev), \"/dev/nvidia%d\", i);\n              if (g_file_test (nvidia_dev, G_FILE_TEST_EXISTS))\n                flatpak_bwrap_add_args (bwrap, \"--dev-bind\", nvidia_dev, nvidia_dev, NULL);\n            }\n        }\n\n      if (context->devices & FLATPAK_CONTEXT_DEVICE_KVM)\n        {\n          g_debug (\"Allowing kvm access\");\n          if (g_file_test (\"/dev/kvm\", G_FILE_TEST_EXISTS))\n            flatpak_bwrap_add_args (bwrap, \"--dev-bind\", \"/dev/kvm\", \"/dev/kvm\", NULL);\n        }\n\n      if (context->devices & FLATPAK_CONTEXT_DEVICE_SHM)\n        {\n          /* This is a symlink to /run/shm on debian, so bind to real target */\n          g_autofree char *real_dev_shm = realpath (\"/dev/shm\", NULL);\n\n          g_debug (\"Allowing /dev/shm access (as %s)\", real_dev_shm);\n          if (real_dev_shm != NULL)\n              flatpak_bwrap_add_args (bwrap, \"--bind\", real_dev_shm, \"/dev/shm\", NULL);\n        }\n    }\n\n  flatpak_context_append_bwrap_filesystem (context, bwrap, app_id, app_id_dir, previous_app_id_dirs, &exports);\n\n  if (context->sockets & FLATPAK_CONTEXT_SOCKET_WAYLAND)\n    {\n      g_debug (\"Allowing wayland access\");\n      has_wayland = flatpak_run_add_wayland_args (bwrap);\n    }\n\n  if ((context->sockets & FLATPAK_CONTEXT_SOCKET_FALLBACK_X11) != 0)\n    allow_x11 = !has_wayland;\n  else\n    allow_x11 = (context->sockets & FLATPAK_CONTEXT_SOCKET_X11) != 0;\n\n  flatpak_run_add_x11_args (bwrap, allow_x11);\n\n  if (context->sockets & FLATPAK_CONTEXT_SOCKET_SSH_AUTH)\n    {\n      flatpak_run_add_ssh_args (bwrap);\n    }\n\n  if (context->sockets & FLATPAK_CONTEXT_SOCKET_PULSEAUDIO)\n    {\n      g_debug (\"Allowing pulseaudio access\");\n      flatpak_run_add_pulseaudio_args (bwrap);\n    }\n\n  if (context->sockets & FLATPAK_CONTEXT_SOCKET_PCSC)\n    {\n      flatpak_run_add_pcsc_args (bwrap);\n    }\n\n  if (context->sockets & FLATPAK_CONTEXT_SOCKET_CUPS)\n    {\n      flatpak_run_add_cups_args (bwrap);\n    }\n\n  flatpak_run_add_session_dbus_args (bwrap, proxy_arg_bwrap, context, flags, app_id);\n  flatpak_run_add_system_dbus_args (bwrap, proxy_arg_bwrap, context, flags);\n  flatpak_run_add_a11y_dbus_args (bwrap, proxy_arg_bwrap, context, flags);\n\n  if (g_environ_getenv (bwrap->envp, \"LD_LIBRARY_PATH\") != NULL)\n    {\n      /* LD_LIBRARY_PATH is overridden for setuid helper, so pass it as cmdline arg */\n      flatpak_bwrap_add_args (bwrap,\n                              \"--setenv\", \"LD_LIBRARY_PATH\", g_environ_getenv (bwrap->envp, \"LD_LIBRARY_PATH\"),\n                              NULL);\n      flatpak_bwrap_unset_env (bwrap, \"LD_LIBRARY_PATH\");\n    }\n\n  if (g_environ_getenv (bwrap->envp, \"TMPDIR\") != NULL)\n    {\n      /* TMPDIR is overridden for setuid helper, so pass it as cmdline arg */\n      flatpak_bwrap_add_args (bwrap,\n                              \"--setenv\", \"TMPDIR\", g_environ_getenv (bwrap->envp, \"TMPDIR\"),\n                              NULL);\n      flatpak_bwrap_unset_env (bwrap, \"TMPDIR\");\n    }\n\n  /* Must run this before spawning the dbus proxy, to ensure it\n     ends up in the app cgroup */\n  if (!flatpak_run_in_transient_unit (app_id, &my_error))\n    {\n      /* We still run along even if we don't get a cgroup, as nothing\n         really depends on it. Its just nice to have */\n      g_debug (\"Failed to run in transient scope: %s\", my_error->message);\n      g_clear_error (&my_error);\n    }\n\n  if (!flatpak_bwrap_is_empty (proxy_arg_bwrap) &&\n      !start_dbus_proxy (bwrap, proxy_arg_bwrap, app_info_path, error))\n    return FALSE;\n\n  if (exports_out)\n    *exports_out = g_steal_pointer (&exports);\n\n  return TRUE;\n}",
        "func_after": "gboolean\nflatpak_run_add_environment_args (FlatpakBwrap    *bwrap,\n                                  const char      *app_info_path,\n                                  FlatpakRunFlags  flags,\n                                  const char      *app_id,\n                                  FlatpakContext  *context,\n                                  GFile           *app_id_dir,\n                                  GPtrArray       *previous_app_id_dirs,\n                                  FlatpakExports **exports_out,\n                                  GCancellable    *cancellable,\n                                  GError         **error)\n{\n  g_autoptr(GError) my_error = NULL;\n  g_autoptr(FlatpakExports) exports = NULL;\n  g_autoptr(FlatpakBwrap) proxy_arg_bwrap = flatpak_bwrap_new (flatpak_bwrap_empty_env);\n  gboolean has_wayland = FALSE;\n  gboolean allow_x11 = FALSE;\n\n  if ((context->shares & FLATPAK_CONTEXT_SHARED_IPC) == 0)\n    {\n      g_debug (\"Disallowing ipc access\");\n      flatpak_bwrap_add_args (bwrap, \"--unshare-ipc\", NULL);\n    }\n\n  if ((context->shares & FLATPAK_CONTEXT_SHARED_NETWORK) == 0)\n    {\n      g_debug (\"Disallowing network access\");\n      flatpak_bwrap_add_args (bwrap, \"--unshare-net\", NULL);\n    }\n\n  if (context->devices & FLATPAK_CONTEXT_DEVICE_ALL)\n    {\n      flatpak_bwrap_add_args (bwrap,\n                              \"--dev-bind\", \"/dev\", \"/dev\",\n                              NULL);\n      /* Don't expose the host /dev/shm, just the device nodes, unless explicitly allowed */\n      if (g_file_test (\"/dev/shm\", G_FILE_TEST_IS_DIR))\n        {\n          if ((context->devices & FLATPAK_CONTEXT_DEVICE_SHM) == 0)\n            flatpak_bwrap_add_args (bwrap,\n                                    \"--tmpfs\", \"/dev/shm\",\n                                    NULL);\n        }\n      else if (g_file_test (\"/dev/shm\", G_FILE_TEST_IS_SYMLINK))\n        {\n          g_autofree char *link = flatpak_readlink (\"/dev/shm\", NULL);\n\n          /* On debian (with sysv init) the host /dev/shm is a symlink to /run/shm, so we can't\n             mount on top of it. */\n          if (g_strcmp0 (link, \"/run/shm\") == 0)\n            {\n              if (context->devices & FLATPAK_CONTEXT_DEVICE_SHM &&\n                  g_file_test (\"/run/shm\", G_FILE_TEST_IS_DIR))\n                flatpak_bwrap_add_args (bwrap,\n                                        \"--bind\", \"/run/shm\", \"/run/shm\",\n                                        NULL);\n              else\n                flatpak_bwrap_add_args (bwrap,\n                                        \"--dir\", \"/run/shm\",\n                                        NULL);\n            }\n          else\n            g_warning (\"Unexpected /dev/shm symlink %s\", link);\n        }\n    }\n  else\n    {\n      flatpak_bwrap_add_args (bwrap,\n                              \"--dev\", \"/dev\",\n                              NULL);\n      if (context->devices & FLATPAK_CONTEXT_DEVICE_DRI)\n        {\n          g_debug (\"Allowing dri access\");\n          int i;\n          char *dri_devices[] = {\n            \"/dev/dri\",\n            /* mali */\n            \"/dev/mali\",\n            \"/dev/mali0\",\n            \"/dev/umplock\",\n            /* nvidia */\n            \"/dev/nvidiactl\",\n            \"/dev/nvidia-modeset\",\n            /* nvidia OpenCL/CUDA */\n            \"/dev/nvidia-uvm\",\n            \"/dev/nvidia-uvm-tools\",\n          };\n\n          for (i = 0; i < G_N_ELEMENTS (dri_devices); i++)\n            {\n              if (g_file_test (dri_devices[i], G_FILE_TEST_EXISTS))\n                flatpak_bwrap_add_args (bwrap, \"--dev-bind\", dri_devices[i], dri_devices[i], NULL);\n            }\n\n          /* Each Nvidia card gets its own device.\n             This is a fairly arbitrary limit but ASUS sells mining boards supporting 20 in theory. */\n          char nvidia_dev[14]; /* /dev/nvidia plus up to 2 digits */\n          for (i = 0; i < 20; i++)\n            {\n              g_snprintf (nvidia_dev, sizeof (nvidia_dev), \"/dev/nvidia%d\", i);\n              if (g_file_test (nvidia_dev, G_FILE_TEST_EXISTS))\n                flatpak_bwrap_add_args (bwrap, \"--dev-bind\", nvidia_dev, nvidia_dev, NULL);\n            }\n        }\n\n      if (context->devices & FLATPAK_CONTEXT_DEVICE_KVM)\n        {\n          g_debug (\"Allowing kvm access\");\n          if (g_file_test (\"/dev/kvm\", G_FILE_TEST_EXISTS))\n            flatpak_bwrap_add_args (bwrap, \"--dev-bind\", \"/dev/kvm\", \"/dev/kvm\", NULL);\n        }\n\n      if (context->devices & FLATPAK_CONTEXT_DEVICE_SHM)\n        {\n          /* This is a symlink to /run/shm on debian, so bind to real target */\n          g_autofree char *real_dev_shm = realpath (\"/dev/shm\", NULL);\n\n          g_debug (\"Allowing /dev/shm access (as %s)\", real_dev_shm);\n          if (real_dev_shm != NULL)\n              flatpak_bwrap_add_args (bwrap, \"--bind\", real_dev_shm, \"/dev/shm\", NULL);\n        }\n    }\n\n  flatpak_context_append_bwrap_filesystem (context, bwrap, app_id, app_id_dir, previous_app_id_dirs, &exports);\n\n  if (context->sockets & FLATPAK_CONTEXT_SOCKET_WAYLAND)\n    {\n      g_debug (\"Allowing wayland access\");\n      has_wayland = flatpak_run_add_wayland_args (bwrap);\n    }\n\n  if ((context->sockets & FLATPAK_CONTEXT_SOCKET_FALLBACK_X11) != 0)\n    allow_x11 = !has_wayland;\n  else\n    allow_x11 = (context->sockets & FLATPAK_CONTEXT_SOCKET_X11) != 0;\n\n  flatpak_run_add_x11_args (bwrap, allow_x11);\n\n  if (context->sockets & FLATPAK_CONTEXT_SOCKET_SSH_AUTH)\n    {\n      flatpak_run_add_ssh_args (bwrap);\n    }\n\n  if (context->sockets & FLATPAK_CONTEXT_SOCKET_PULSEAUDIO)\n    {\n      g_debug (\"Allowing pulseaudio access\");\n      flatpak_run_add_pulseaudio_args (bwrap);\n    }\n\n  if (context->sockets & FLATPAK_CONTEXT_SOCKET_PCSC)\n    {\n      flatpak_run_add_pcsc_args (bwrap);\n    }\n\n  if (context->sockets & FLATPAK_CONTEXT_SOCKET_CUPS)\n    {\n      flatpak_run_add_cups_args (bwrap);\n    }\n\n  flatpak_run_add_session_dbus_args (bwrap, proxy_arg_bwrap, context, flags, app_id);\n  flatpak_run_add_system_dbus_args (bwrap, proxy_arg_bwrap, context, flags);\n  flatpak_run_add_a11y_dbus_args (bwrap, proxy_arg_bwrap, context, flags);\n\n  /* Must run this before spawning the dbus proxy, to ensure it\n     ends up in the app cgroup */\n  if (!flatpak_run_in_transient_unit (app_id, &my_error))\n    {\n      /* We still run along even if we don't get a cgroup, as nothing\n         really depends on it. Its just nice to have */\n      g_debug (\"Failed to run in transient scope: %s\", my_error->message);\n      g_clear_error (&my_error);\n    }\n\n  if (!flatpak_bwrap_is_empty (proxy_arg_bwrap) &&\n      !start_dbus_proxy (bwrap, proxy_arg_bwrap, app_info_path, error))\n    return FALSE;\n\n  if (exports_out)\n    *exports_out = g_steal_pointer (&exports);\n\n  return TRUE;\n}",
        "description": "A vulnerability was identified in the Flatpak portal service (`flatpak-portal`), allowing sandboxed applications to execute arbitrary code on the host system, effectively enabling a sandbox escape. This issue affects versions of Flatpak from 0.11.4 up to but not including fixed versions 1.8.5 and 1.10.0. The Flatpak portal service facilitates launching subprocesses within new sandbox instances, either with the same or more restrictive security settings compared to the calling application. Vulnerable versions pass caller-specified environment variables to non-sandboxed processes on the host system, particularly to the `flatpak run` command used for launching new sandbox instances. Malicious or compromised applications could exploit this by setting environment variables trusted by the `flatpak run` command, thereby executing arbitrary code outside the sandbox. As a temporary workaround, disabling the `flatpak-portal` service mitigates the vulnerability but may prevent many Flatpak applications from functioning correctly. This issue has been resolved in versions 1.8.5 and 1.10.0.",
        "commit": "The vulnerability involves converting all environment variables into arguments for `bwrap`, a tool used to create isolated execution environments. This conversion helps prevent certain environment variables from being filtered out by a setuid `bwrap`. Additionally, it ensures that even if these variables come from an untrusted source, they cannot be used to inject arbitrary code into a non-setuid `bwrap` through mechanisms like `LD_PRELOAD`. By bundling these variables into a `memfd` or temporary file, they are not included in `argv`, making them inaccessible to processes running under a different user ID. This measure is crucial for protecting sensitive information such as tokens or other secrets."
    },
    {
        "cwe": "CWE-119",
        "func_name": "torvalds/hugetlb_mcopy_atomic_pte",
        "score": 0.7869960069656372,
        "func_before": "int hugetlb_mcopy_atomic_pte(struct mm_struct *dst_mm,\n\t\t\t    pte_t *dst_pte,\n\t\t\t    struct vm_area_struct *dst_vma,\n\t\t\t    unsigned long dst_addr,\n\t\t\t    unsigned long src_addr,\n\t\t\t    struct page **pagep)\n{\n\tint vm_shared = dst_vma->vm_flags & VM_SHARED;\n\tstruct hstate *h = hstate_vma(dst_vma);\n\tpte_t _dst_pte;\n\tspinlock_t *ptl;\n\tint ret;\n\tstruct page *page;\n\n\tif (!*pagep) {\n\t\tret = -ENOMEM;\n\t\tpage = alloc_huge_page(dst_vma, dst_addr, 0);\n\t\tif (IS_ERR(page))\n\t\t\tgoto out;\n\n\t\tret = copy_huge_page_from_user(page,\n\t\t\t\t\t\t(const void __user *) src_addr,\n\t\t\t\t\t\tpages_per_huge_page(h), false);\n\n\t\t/* fallback to copy_from_user outside mmap_sem */\n\t\tif (unlikely(ret)) {\n\t\t\tret = -EFAULT;\n\t\t\t*pagep = page;\n\t\t\t/* don't free the page */\n\t\t\tgoto out;\n\t\t}\n\t} else {\n\t\tpage = *pagep;\n\t\t*pagep = NULL;\n\t}\n\n\t/*\n\t * The memory barrier inside __SetPageUptodate makes sure that\n\t * preceding stores to the page contents become visible before\n\t * the set_pte_at() write.\n\t */\n\t__SetPageUptodate(page);\n\tset_page_huge_active(page);\n\n\t/*\n\t * If shared, add to page cache\n\t */\n\tif (vm_shared) {\n\t\tstruct address_space *mapping = dst_vma->vm_file->f_mapping;\n\t\tpgoff_t idx = vma_hugecache_offset(h, dst_vma, dst_addr);\n\n\t\tret = huge_add_to_page_cache(page, mapping, idx);\n\t\tif (ret)\n\t\t\tgoto out_release_nounlock;\n\t}\n\n\tptl = huge_pte_lockptr(h, dst_mm, dst_pte);\n\tspin_lock(ptl);\n\n\tret = -EEXIST;\n\tif (!huge_pte_none(huge_ptep_get(dst_pte)))\n\t\tgoto out_release_unlock;\n\n\tif (vm_shared) {\n\t\tpage_dup_rmap(page, true);\n\t} else {\n\t\tClearPagePrivate(page);\n\t\thugepage_add_new_anon_rmap(page, dst_vma, dst_addr);\n\t}\n\n\t_dst_pte = make_huge_pte(dst_vma, page, dst_vma->vm_flags & VM_WRITE);\n\tif (dst_vma->vm_flags & VM_WRITE)\n\t\t_dst_pte = huge_pte_mkdirty(_dst_pte);\n\t_dst_pte = pte_mkyoung(_dst_pte);\n\n\tset_huge_pte_at(dst_mm, dst_addr, dst_pte, _dst_pte);\n\n\t(void)huge_ptep_set_access_flags(dst_vma, dst_addr, dst_pte, _dst_pte,\n\t\t\t\t\tdst_vma->vm_flags & VM_WRITE);\n\thugetlb_count_add(pages_per_huge_page(h), dst_mm);\n\n\t/* No need to invalidate - it was non-present before */\n\tupdate_mmu_cache(dst_vma, dst_addr, dst_pte);\n\n\tspin_unlock(ptl);\n\tif (vm_shared)\n\t\tunlock_page(page);\n\tret = 0;\nout:\n\treturn ret;\nout_release_unlock:\n\tspin_unlock(ptl);\n\tif (vm_shared)\n\t\tunlock_page(page);\nout_release_nounlock:\n\tput_page(page);\n\tgoto out;\n}",
        "func_after": "int hugetlb_mcopy_atomic_pte(struct mm_struct *dst_mm,\n\t\t\t    pte_t *dst_pte,\n\t\t\t    struct vm_area_struct *dst_vma,\n\t\t\t    unsigned long dst_addr,\n\t\t\t    unsigned long src_addr,\n\t\t\t    struct page **pagep)\n{\n\tstruct address_space *mapping;\n\tpgoff_t idx;\n\tunsigned long size;\n\tint vm_shared = dst_vma->vm_flags & VM_SHARED;\n\tstruct hstate *h = hstate_vma(dst_vma);\n\tpte_t _dst_pte;\n\tspinlock_t *ptl;\n\tint ret;\n\tstruct page *page;\n\n\tif (!*pagep) {\n\t\tret = -ENOMEM;\n\t\tpage = alloc_huge_page(dst_vma, dst_addr, 0);\n\t\tif (IS_ERR(page))\n\t\t\tgoto out;\n\n\t\tret = copy_huge_page_from_user(page,\n\t\t\t\t\t\t(const void __user *) src_addr,\n\t\t\t\t\t\tpages_per_huge_page(h), false);\n\n\t\t/* fallback to copy_from_user outside mmap_sem */\n\t\tif (unlikely(ret)) {\n\t\t\tret = -EFAULT;\n\t\t\t*pagep = page;\n\t\t\t/* don't free the page */\n\t\t\tgoto out;\n\t\t}\n\t} else {\n\t\tpage = *pagep;\n\t\t*pagep = NULL;\n\t}\n\n\t/*\n\t * The memory barrier inside __SetPageUptodate makes sure that\n\t * preceding stores to the page contents become visible before\n\t * the set_pte_at() write.\n\t */\n\t__SetPageUptodate(page);\n\tset_page_huge_active(page);\n\n\tmapping = dst_vma->vm_file->f_mapping;\n\tidx = vma_hugecache_offset(h, dst_vma, dst_addr);\n\n\t/*\n\t * If shared, add to page cache\n\t */\n\tif (vm_shared) {\n\t\tsize = i_size_read(mapping->host) >> huge_page_shift(h);\n\t\tret = -EFAULT;\n\t\tif (idx >= size)\n\t\t\tgoto out_release_nounlock;\n\n\t\t/*\n\t\t * Serialization between remove_inode_hugepages() and\n\t\t * huge_add_to_page_cache() below happens through the\n\t\t * hugetlb_fault_mutex_table that here must be hold by\n\t\t * the caller.\n\t\t */\n\t\tret = huge_add_to_page_cache(page, mapping, idx);\n\t\tif (ret)\n\t\t\tgoto out_release_nounlock;\n\t}\n\n\tptl = huge_pte_lockptr(h, dst_mm, dst_pte);\n\tspin_lock(ptl);\n\n\t/*\n\t * Recheck the i_size after holding PT lock to make sure not\n\t * to leave any page mapped (as page_mapped()) beyond the end\n\t * of the i_size (remove_inode_hugepages() is strict about\n\t * enforcing that). If we bail out here, we'll also leave a\n\t * page in the radix tree in the vm_shared case beyond the end\n\t * of the i_size, but remove_inode_hugepages() will take care\n\t * of it as soon as we drop the hugetlb_fault_mutex_table.\n\t */\n\tsize = i_size_read(mapping->host) >> huge_page_shift(h);\n\tret = -EFAULT;\n\tif (idx >= size)\n\t\tgoto out_release_unlock;\n\n\tret = -EEXIST;\n\tif (!huge_pte_none(huge_ptep_get(dst_pte)))\n\t\tgoto out_release_unlock;\n\n\tif (vm_shared) {\n\t\tpage_dup_rmap(page, true);\n\t} else {\n\t\tClearPagePrivate(page);\n\t\thugepage_add_new_anon_rmap(page, dst_vma, dst_addr);\n\t}\n\n\t_dst_pte = make_huge_pte(dst_vma, page, dst_vma->vm_flags & VM_WRITE);\n\tif (dst_vma->vm_flags & VM_WRITE)\n\t\t_dst_pte = huge_pte_mkdirty(_dst_pte);\n\t_dst_pte = pte_mkyoung(_dst_pte);\n\n\tset_huge_pte_at(dst_mm, dst_addr, dst_pte, _dst_pte);\n\n\t(void)huge_ptep_set_access_flags(dst_vma, dst_addr, dst_pte, _dst_pte,\n\t\t\t\t\tdst_vma->vm_flags & VM_WRITE);\n\thugetlb_count_add(pages_per_huge_page(h), dst_mm);\n\n\t/* No need to invalidate - it was non-present before */\n\tupdate_mmu_cache(dst_vma, dst_addr, dst_pte);\n\n\tspin_unlock(ptl);\n\tif (vm_shared)\n\t\tunlock_page(page);\n\tret = 0;\nout:\n\treturn ret;\nout_release_unlock:\n\tspin_unlock(ptl);\n\tif (vm_shared)\n\t\tunlock_page(page);\nout_release_nounlock:\n\tput_page(page);\n\tgoto out;\n}",
        "description": "A flaw was identified in the hugetlb_mcopy_atomic_pte function within the Linux kernel's memory management module, affecting versions prior to 4.13.12. The absence of a proper size check in this function could lead to a denial of service condition, indicated by a BUG.",
        "commit": "A vulnerability was identified in the userfaultfd functionality related to hugetlbfs, where the UFFDIO_COPY operation could inadvertently extend beyond the intended size of the file (i_size). This issue led to a kernel panic (oops) at fs/hugetlbfs/inode.c:484, triggered by the absence of an i_size check in the hugetlb_mcopy_atomic_pte function. Although mmap() operations could succeed beyond the end of the i_size after vmtruncate had removed virtual memory areas (vmas) in those ranges, subsequent faults, including UFFDIO_COPY, should not be allowed to succeed. The proposed solution involves modifying the return value to userland to indicate a SIGBUS-like condition, similar to what a page fault would produce, but this approach was deemed less useful due to the difficulty in distinguishing between SIGSEGV and SIGBUS through meaningful syscall return values."
    },
    {
        "cwe": "CWE-670",
        "func_name": "xen-project/port_is_valid",
        "score": 0.6991750597953796,
        "func_before": "static inline bool_t port_is_valid(struct domain *d, unsigned int p)\n{\n    return p < read_atomic(&d->valid_evtchns);\n}",
        "func_after": "static inline bool_t port_is_valid(struct domain *d, unsigned int p)\n{\n    if ( p >= read_atomic(&d->valid_evtchns) )\n        return false;\n\n    /*\n     * The caller will usually access the event channel afterwards and\n     * may be done without taking the per-domain lock. The barrier is\n     * going in pair the smp_wmb() barrier in evtchn_allocate_port().\n     */\n    smp_rmb();\n\n    return true;\n}",
        "description": "An issue was discovered in Xen through version 4.14.x, where memory barriers are absent during the access or allocation of event channels. Event channels control structures can be accessed without locks as long as the port is deemed valid. However, the absence of an appropriate memory barrier (such as smp_*mb()) allows the compiler and CPU to reorder memory accesses. This could enable a malicious guest to trigger a hypervisor crash, leading to a Denial of Service (DoS). Additionally, information leaks and privilege escalations cannot be ruled out. The vulnerability affects all versions of Xen, with the likelihood of exploitation depending on the CPU and compiler used to build Xen. The exact impact varies based on the compiler's code generation options and the CPU's ability to reorder memory accesses. It is recommended to consult the CPU vendor for guidance on potential vulnerabilities on Arm systems, while x86 systems are only vulnerable if a compiler performs reordering.",
        "commit": "It was discovered that the Xen hypervisor's event channel management lacked appropriate memory barriers during both allocation and access operations. Specifically, while the allocation of an event channel bucket is protected by a per-domain lock, accessing the bucket can occur without the lock being held, relying instead on the `port_is_valid()` function to ensure the port has an associated structure. However, due to potential compiler and processor reordering of memory accesses, there is a risk that updates to `d->valid_evtchns` could occur before the new bucket is fully allocated. To mitigate this issue, memory barriers were added: a write memory barrier during allocation and a read memory barrier when checking if the port is valid. This addresses a reordering problem that could lead to unintended behavior."
    }
]