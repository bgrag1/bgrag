[
    {
        "cwe": "CWE-415",
        "func_name": "binutils-gdb/get_num_dynamic_syms",
        "score": 0.7542176246643066,
        "func_before": "static unsigned long\nget_num_dynamic_syms (Filedata * filedata)\n{\n  unsigned long num_of_syms = 0;\n\n  if (!do_histogram && (!do_using_dynamic || do_dyn_syms))\n    return num_of_syms;\n\n  if (dynamic_info[DT_HASH])\n    {\n      unsigned char nb[8];\n      unsigned char nc[8];\n      unsigned int hash_ent_size = 4;\n\n      if ((filedata->file_header.e_machine == EM_ALPHA\n\t   || filedata->file_header.e_machine == EM_S390\n\t   || filedata->file_header.e_machine == EM_S390_OLD)\n\t  && filedata->file_header.e_ident[EI_CLASS] == ELFCLASS64)\n\thash_ent_size = 8;\n\n      if (fseek (filedata->handle,\n\t\t (archive_file_offset\n\t\t  + offset_from_vma (filedata, dynamic_info[DT_HASH],\n\t\t\t\t     sizeof nb + sizeof nc)),\n\t\t SEEK_SET))\n\t{\n\t  error (_(\"Unable to seek to start of dynamic information\\n\"));\n\t  goto no_hash;\n\t}\n\n      if (fread (nb, hash_ent_size, 1, filedata->handle) != 1)\n\t{\n\t  error (_(\"Failed to read in number of buckets\\n\"));\n\t  goto no_hash;\n\t}\n\n      if (fread (nc, hash_ent_size, 1, filedata->handle) != 1)\n\t{\n\t  error (_(\"Failed to read in number of chains\\n\"));\n\t  goto no_hash;\n\t}\n\n      nbuckets = byte_get (nb, hash_ent_size);\n      nchains = byte_get (nc, hash_ent_size);\n      num_of_syms = nchains;\n\n      buckets = get_dynamic_data (filedata, nbuckets, hash_ent_size);\n      chains  = get_dynamic_data (filedata, nchains, hash_ent_size);\n\n  no_hash:\n      if (num_of_syms == 0)\n\t{\n\t  if (buckets)\n\t    {\n\t      free (buckets);\n\t      buckets = NULL;\n\t    }\n\t  if (chains)\n\t    {\n\t      free (chains);\n\t      buckets = NULL;\n\t    }\n\t  nbuckets = 0;\n\t}\n    }\n\n  if (dynamic_info_DT_GNU_HASH)\n    {\n      unsigned char nb[16];\n      bfd_vma i, maxchain = 0xffffffff, bitmaskwords;\n      bfd_vma buckets_vma;\n      unsigned long hn;\n      bfd_boolean gnu_hash_error = FALSE;\n\n      if (fseek (filedata->handle,\n\t\t (archive_file_offset\n\t\t  + offset_from_vma (filedata, dynamic_info_DT_GNU_HASH,\n\t\t\t\t     sizeof nb)),\n\t\t SEEK_SET))\n\t{\n\t  error (_(\"Unable to seek to start of dynamic information\\n\"));\n\t  gnu_hash_error = TRUE;\n\t  goto no_gnu_hash;\n\t}\n\n      if (fread (nb, 16, 1, filedata->handle) != 1)\n\t{\n\t  error (_(\"Failed to read in number of buckets\\n\"));\n\t  gnu_hash_error = TRUE;\n\t  goto no_gnu_hash;\n\t}\n\n      ngnubuckets = byte_get (nb, 4);\n      gnusymidx = byte_get (nb + 4, 4);\n      bitmaskwords = byte_get (nb + 8, 4);\n      buckets_vma = dynamic_info_DT_GNU_HASH + 16;\n      if (is_32bit_elf)\n\tbuckets_vma += bitmaskwords * 4;\n      else\n\tbuckets_vma += bitmaskwords * 8;\n\n      if (fseek (filedata->handle,\n\t\t (archive_file_offset\n\t\t  + offset_from_vma (filedata, buckets_vma, 4)),\n\t\t SEEK_SET))\n\t{\n\t  error (_(\"Unable to seek to start of dynamic information\\n\"));\n\t  gnu_hash_error = TRUE;\n\t  goto no_gnu_hash;\n\t}\n\n      gnubuckets = get_dynamic_data (filedata, ngnubuckets, 4);\n\n      if (gnubuckets == NULL)\n\t{\n\t  gnu_hash_error = TRUE;\n\t  goto no_gnu_hash;\n\t}\n\n      for (i = 0; i < ngnubuckets; i++)\n\tif (gnubuckets[i] != 0)\n\t  {\n\t    if (gnubuckets[i] < gnusymidx)\n\t      {\n\t\tgnu_hash_error = TRUE;\n\t\treturn FALSE;\n\t      }\n\n\t    if (maxchain == 0xffffffff || gnubuckets[i] > maxchain)\n\t      maxchain = gnubuckets[i];\n\t  }\n\n      if (maxchain == 0xffffffff)\n\t{\n\t  gnu_hash_error = TRUE;\n\t  goto no_gnu_hash;\n\t}\n\n      maxchain -= gnusymidx;\n\n      if (fseek (filedata->handle,\n\t\t (archive_file_offset\n\t\t  + offset_from_vma (filedata, buckets_vma\n\t\t\t\t\t   + 4 * (ngnubuckets + maxchain), 4)),\n\t\t SEEK_SET))\n\t{\n\t  error (_(\"Unable to seek to start of dynamic information\\n\"));\n\t  gnu_hash_error = TRUE;\n\t  goto no_gnu_hash;\n\t}\n\n      do\n\t{\n\t  if (fread (nb, 4, 1, filedata->handle) != 1)\n\t    {\n\t      error (_(\"Failed to determine last chain length\\n\"));\n\t  gnu_hash_error = TRUE;\n\t      goto no_gnu_hash;\n\t    }\n\n\t  if (maxchain + 1 == 0)\n\t    {\n\t      gnu_hash_error = TRUE;\n\t      goto no_gnu_hash;\n\t    }\n\n\t  ++maxchain;\n\t}\n      while ((byte_get (nb, 4) & 1) == 0);\n\n      if (fseek (filedata->handle,\n\t\t (archive_file_offset\n\t\t  + offset_from_vma (filedata, buckets_vma + 4 * ngnubuckets, 4)),\n\t\t SEEK_SET))\n\t{\n\t  error (_(\"Unable to seek to start of dynamic information\\n\"));\n\t  gnu_hash_error = TRUE;\n\t  goto no_gnu_hash;\n\t}\n\n      gnuchains = get_dynamic_data (filedata, maxchain, 4);\n      ngnuchains = maxchain;\n\n      if (gnuchains == NULL)\n\t{\n\t  gnu_hash_error = TRUE;\n\t  goto no_gnu_hash;\n\t}\n\n      if (dynamic_info_DT_MIPS_XHASH)\n\t{\n\t  if (fseek (filedata->handle,\n\t\t     (archive_file_offset\n\t\t      + offset_from_vma (filedata, (buckets_vma\n\t\t\t\t\t\t    + 4 * (ngnubuckets\n\t\t\t\t\t\t\t   + maxchain)), 4)),\n\t\t     SEEK_SET))\n\t    {\n\t      error (_(\"Unable to seek to start of dynamic information\\n\"));\n\t      gnu_hash_error = TRUE;\n\t      goto no_gnu_hash;\n\t    }\n\n\t  mipsxlat = get_dynamic_data (filedata, maxchain, 4);\n\t}\n\n      for (hn = 0; hn < ngnubuckets; ++hn)\n\tif (gnubuckets[hn] != 0)\n\t  {\n\t    bfd_vma si = gnubuckets[hn];\n\t    bfd_vma off = si - gnusymidx;\n\n\t    do\n\t      {\n\t\tif (dynamic_info_DT_MIPS_XHASH)\n\t\t  {\n\t\t    if (mipsxlat[off] >= num_of_syms)\n\t\t      num_of_syms = mipsxlat[off] + 1;\n\t\t  }\n\t\telse\n\t\t  {\n\t\t    if (si >= num_of_syms)\n\t\t      num_of_syms = si + 1;\n\t\t  }\n\t\tsi++;\n\t      }\n\t    while (off < ngnuchains && (gnuchains[off++] & 1) == 0);\n\t  }\n\n  no_gnu_hash:\n      if (gnu_hash_error)\n\t{\n\t  if (mipsxlat)\n\t    {\n\t      free (mipsxlat);\n\t      mipsxlat = NULL;\n\t    }\n\t  if (gnuchains)\n\t    {\n\t      free (gnuchains);\n\t      gnuchains = NULL;\n\t    }\n\t  if (gnubuckets)\n\t    {\n\t      free (gnubuckets);\n\t      gnubuckets = NULL;\n\t    }\n\t  ngnubuckets = 0;\n\t  ngnuchains = 0;\n\t}\n    }\n\n  return num_of_syms;\n}",
        "func_after": "static unsigned long\nget_num_dynamic_syms (Filedata * filedata)\n{\n  unsigned long num_of_syms = 0;\n\n  if (!do_histogram && (!do_using_dynamic || do_dyn_syms))\n    return num_of_syms;\n\n  if (dynamic_info[DT_HASH])\n    {\n      unsigned char nb[8];\n      unsigned char nc[8];\n      unsigned int hash_ent_size = 4;\n\n      if ((filedata->file_header.e_machine == EM_ALPHA\n\t   || filedata->file_header.e_machine == EM_S390\n\t   || filedata->file_header.e_machine == EM_S390_OLD)\n\t  && filedata->file_header.e_ident[EI_CLASS] == ELFCLASS64)\n\thash_ent_size = 8;\n\n      if (fseek (filedata->handle,\n\t\t (archive_file_offset\n\t\t  + offset_from_vma (filedata, dynamic_info[DT_HASH],\n\t\t\t\t     sizeof nb + sizeof nc)),\n\t\t SEEK_SET))\n\t{\n\t  error (_(\"Unable to seek to start of dynamic information\\n\"));\n\t  goto no_hash;\n\t}\n\n      if (fread (nb, hash_ent_size, 1, filedata->handle) != 1)\n\t{\n\t  error (_(\"Failed to read in number of buckets\\n\"));\n\t  goto no_hash;\n\t}\n\n      if (fread (nc, hash_ent_size, 1, filedata->handle) != 1)\n\t{\n\t  error (_(\"Failed to read in number of chains\\n\"));\n\t  goto no_hash;\n\t}\n\n      nbuckets = byte_get (nb, hash_ent_size);\n      nchains = byte_get (nc, hash_ent_size);\n      num_of_syms = nchains;\n\n      buckets = get_dynamic_data (filedata, nbuckets, hash_ent_size);\n      chains  = get_dynamic_data (filedata, nchains, hash_ent_size);\n\n  no_hash:\n      if (num_of_syms == 0)\n\t{\n\t  if (buckets)\n\t    {\n\t      free (buckets);\n\t      buckets = NULL;\n\t    }\n\t  if (chains)\n\t    {\n\t      free (chains);\n\t      chains = NULL;\n\t    }\n\t  nbuckets = 0;\n\t}\n    }\n\n  if (dynamic_info_DT_GNU_HASH)\n    {\n      unsigned char nb[16];\n      bfd_vma i, maxchain = 0xffffffff, bitmaskwords;\n      bfd_vma buckets_vma;\n      unsigned long hn;\n      bfd_boolean gnu_hash_error = FALSE;\n\n      if (fseek (filedata->handle,\n\t\t (archive_file_offset\n\t\t  + offset_from_vma (filedata, dynamic_info_DT_GNU_HASH,\n\t\t\t\t     sizeof nb)),\n\t\t SEEK_SET))\n\t{\n\t  error (_(\"Unable to seek to start of dynamic information\\n\"));\n\t  gnu_hash_error = TRUE;\n\t  goto no_gnu_hash;\n\t}\n\n      if (fread (nb, 16, 1, filedata->handle) != 1)\n\t{\n\t  error (_(\"Failed to read in number of buckets\\n\"));\n\t  gnu_hash_error = TRUE;\n\t  goto no_gnu_hash;\n\t}\n\n      ngnubuckets = byte_get (nb, 4);\n      gnusymidx = byte_get (nb + 4, 4);\n      bitmaskwords = byte_get (nb + 8, 4);\n      buckets_vma = dynamic_info_DT_GNU_HASH + 16;\n      if (is_32bit_elf)\n\tbuckets_vma += bitmaskwords * 4;\n      else\n\tbuckets_vma += bitmaskwords * 8;\n\n      if (fseek (filedata->handle,\n\t\t (archive_file_offset\n\t\t  + offset_from_vma (filedata, buckets_vma, 4)),\n\t\t SEEK_SET))\n\t{\n\t  error (_(\"Unable to seek to start of dynamic information\\n\"));\n\t  gnu_hash_error = TRUE;\n\t  goto no_gnu_hash;\n\t}\n\n      gnubuckets = get_dynamic_data (filedata, ngnubuckets, 4);\n\n      if (gnubuckets == NULL)\n\t{\n\t  gnu_hash_error = TRUE;\n\t  goto no_gnu_hash;\n\t}\n\n      for (i = 0; i < ngnubuckets; i++)\n\tif (gnubuckets[i] != 0)\n\t  {\n\t    if (gnubuckets[i] < gnusymidx)\n\t      {\n\t\tgnu_hash_error = TRUE;\n\t\treturn FALSE;\n\t      }\n\n\t    if (maxchain == 0xffffffff || gnubuckets[i] > maxchain)\n\t      maxchain = gnubuckets[i];\n\t  }\n\n      if (maxchain == 0xffffffff)\n\t{\n\t  gnu_hash_error = TRUE;\n\t  goto no_gnu_hash;\n\t}\n\n      maxchain -= gnusymidx;\n\n      if (fseek (filedata->handle,\n\t\t (archive_file_offset\n\t\t  + offset_from_vma (filedata, buckets_vma\n\t\t\t\t\t   + 4 * (ngnubuckets + maxchain), 4)),\n\t\t SEEK_SET))\n\t{\n\t  error (_(\"Unable to seek to start of dynamic information\\n\"));\n\t  gnu_hash_error = TRUE;\n\t  goto no_gnu_hash;\n\t}\n\n      do\n\t{\n\t  if (fread (nb, 4, 1, filedata->handle) != 1)\n\t    {\n\t      error (_(\"Failed to determine last chain length\\n\"));\n\t  gnu_hash_error = TRUE;\n\t      goto no_gnu_hash;\n\t    }\n\n\t  if (maxchain + 1 == 0)\n\t    {\n\t      gnu_hash_error = TRUE;\n\t      goto no_gnu_hash;\n\t    }\n\n\t  ++maxchain;\n\t}\n      while ((byte_get (nb, 4) & 1) == 0);\n\n      if (fseek (filedata->handle,\n\t\t (archive_file_offset\n\t\t  + offset_from_vma (filedata, buckets_vma + 4 * ngnubuckets, 4)),\n\t\t SEEK_SET))\n\t{\n\t  error (_(\"Unable to seek to start of dynamic information\\n\"));\n\t  gnu_hash_error = TRUE;\n\t  goto no_gnu_hash;\n\t}\n\n      gnuchains = get_dynamic_data (filedata, maxchain, 4);\n      ngnuchains = maxchain;\n\n      if (gnuchains == NULL)\n\t{\n\t  gnu_hash_error = TRUE;\n\t  goto no_gnu_hash;\n\t}\n\n      if (dynamic_info_DT_MIPS_XHASH)\n\t{\n\t  if (fseek (filedata->handle,\n\t\t     (archive_file_offset\n\t\t      + offset_from_vma (filedata, (buckets_vma\n\t\t\t\t\t\t    + 4 * (ngnubuckets\n\t\t\t\t\t\t\t   + maxchain)), 4)),\n\t\t     SEEK_SET))\n\t    {\n\t      error (_(\"Unable to seek to start of dynamic information\\n\"));\n\t      gnu_hash_error = TRUE;\n\t      goto no_gnu_hash;\n\t    }\n\n\t  mipsxlat = get_dynamic_data (filedata, maxchain, 4);\n\t}\n\n      for (hn = 0; hn < ngnubuckets; ++hn)\n\tif (gnubuckets[hn] != 0)\n\t  {\n\t    bfd_vma si = gnubuckets[hn];\n\t    bfd_vma off = si - gnusymidx;\n\n\t    do\n\t      {\n\t\tif (dynamic_info_DT_MIPS_XHASH)\n\t\t  {\n\t\t    if (mipsxlat[off] >= num_of_syms)\n\t\t      num_of_syms = mipsxlat[off] + 1;\n\t\t  }\n\t\telse\n\t\t  {\n\t\t    if (si >= num_of_syms)\n\t\t      num_of_syms = si + 1;\n\t\t  }\n\t\tsi++;\n\t      }\n\t    while (off < ngnuchains && (gnuchains[off++] & 1) == 0);\n\t  }\n\n  no_gnu_hash:\n      if (gnu_hash_error)\n\t{\n\t  if (mipsxlat)\n\t    {\n\t      free (mipsxlat);\n\t      mipsxlat = NULL;\n\t    }\n\t  if (gnuchains)\n\t    {\n\t      free (gnuchains);\n\t      gnuchains = NULL;\n\t    }\n\t  if (gnubuckets)\n\t    {\n\t      free (gnubuckets);\n\t      gnubuckets = NULL;\n\t    }\n\t  ngnubuckets = 0;\n\t  ngnuchains = 0;\n\t}\n    }\n\n  return num_of_syms;\n}",
        "description": "A double free vulnerability exists in the Binary File Descriptor (BFD), also known as libbfd, within GNU Binutils 2.35 during the processing of symbol tables, specifically as exhibited in the readelf utility through the manipulation of a specially crafted file.",
        "commit": "The vulnerability knowledge has been abstracted and generalized as follows:\n\n\"A typo fix was made in the `readelf` tool to consolidate the functionality of the `--syms` and `--use-dynamic` options with the `--dyn-syms` option.\""
    },
    {
        "cwe": "CWE-134",
        "func_name": "wireapp/audio_level_json",
        "score": 0.752332329750061,
        "func_before": "int audio_level_json(struct list *levell,\n\t\t     const char *userid_self, const char *clientid_self,\n\t\t     char **json_str, char **anon_str)\n{\n\tstruct json_object *jobj;\n\tstruct json_object *jarr;\n\tchar uid_anon[ANON_ID_LEN];\n\tchar cid_anon[ANON_CLIENT_LEN];\n\tstruct mbuf *pmb = NULL;\n\tint err = 0;\n\tstruct le *le;\n\n\tif (!levell || !json_str)\n\t\treturn EINVAL;\n\t\n\tjobj = jzon_alloc_object();\n\tif (!jobj)\n\t\treturn ENOMEM;\n\n\tjarr = jzon_alloc_array();\n\tif (!jarr) {\n\t\terr = ENOMEM;\n\t\tgoto out;\n\t}\n\n\tif (anon_str) {\n\t\tpmb = mbuf_alloc(512);\n\t\tmbuf_printf(pmb, \"%zu levels: \", list_count(levell));\n\t}\n\t\n\tLIST_FOREACH(levell, le) {\n\t\tstruct audio_level *a = le->data;\n\t\tstruct json_object *ja;\n\t\tconst char *userid = a->userid;\n\t\tconst char *clientid = a->clientid;\n\n\t\tif (a->is_self) {\n\t\t\tif (userid_self)\n\t\t\t\tuserid = userid_self;\n\t\t\tif (clientid_self)\n\t\t\t\tclientid = clientid_self;\n\t\t}\n\n\t\tja = jzon_alloc_object();\n\t\tif (ja) {\n\t\t\tjzon_add_str(ja, \"userid\", userid);\n\t\t\tjzon_add_str(ja, \"clientid\", clientid);\n\t\t\tjzon_add_int(ja, \"audio_level\",\n\t\t\t\t     (int32_t)a->aulevel_smooth);\n\t\t\tjzon_add_int(ja, \"audio_level_now\",\n\t\t\t\t     (int32_t)a->aulevel);\n\t\t}\n\t\tjson_object_array_add(jarr, ja);\n\n\t\t/* add to info string */\n\t\tif (pmb) {\n\t\t\tanon_id(uid_anon, userid);\n\t\t\tanon_client(cid_anon, clientid);\n\t\t\tmbuf_printf(pmb, \"{[%s.%s] audio_level: %d/%d}\",\n\t\t\t\t    uid_anon, cid_anon,\n\t\t\t\t    a->aulevel_smooth, a->aulevel);\n\t\t\tif (le != levell->tail)\n\t\t\t\tmbuf_printf(pmb, \",\");\n\t\t}\t\t\n\t}\n\tjson_object_object_add(jobj, \"audio_levels\", jarr);\n\n\tif (pmb) {\n\t\tpmb->pos = 0;\n\t\tmbuf_strdup(pmb, anon_str, pmb->end);\n\t\tmem_deref(pmb);\n\t}\n\n\tjzon_encode(json_str, jobj);\n out:\t\n\tmem_deref(jobj);\n\n\treturn err;\n}",
        "func_after": "int audio_level_json(struct list *levell,\n\t\t     const char *userid_self, const char *clientid_self,\n\t\t     char **json_str, char **anon_str)\n{\n\tstruct json_object *jobj;\n\tstruct json_object *jarr;\n\tchar uid_anon[ANON_ID_LEN];\n\tchar cid_anon[ANON_CLIENT_LEN];\n\tstruct mbuf *pmb = NULL;\n\tint err = 0;\n\tstruct le *le;\n\n\tif (!levell || !json_str)\n\t\treturn EINVAL;\n\t\n\tjobj = jzon_alloc_object();\n\tif (!jobj)\n\t\treturn ENOMEM;\n\n\tjarr = jzon_alloc_array();\n\tif (!jarr) {\n\t\terr = ENOMEM;\n\t\tgoto out;\n\t}\n\n\tif (anon_str) {\n\t\tpmb = mbuf_alloc(512);\n\t\tmbuf_printf(pmb, \"%zu levels: \", list_count(levell));\n\t}\n\t\n\tLIST_FOREACH(levell, le) {\n\t\tstruct audio_level *a = le->data;\n\t\tstruct json_object *ja;\n\t\tconst char *userid = a->userid;\n\t\tconst char *clientid = a->clientid;\n\n\t\tif (a->is_self) {\n\t\t\tif (userid_self)\n\t\t\t\tuserid = userid_self;\n\t\t\tif (clientid_self)\n\t\t\t\tclientid = clientid_self;\n\t\t}\n\n\t\tja = jzon_alloc_object();\n\t\tif (ja) {\n\t\t\tjzon_add_str(ja, \"userid\", \"%s\", userid);\n\t\t\tjzon_add_str(ja, \"clientid\", \"%s\", clientid);\n\t\t\tjzon_add_int(ja, \"audio_level\",\n\t\t\t\t     (int32_t)a->aulevel_smooth);\n\t\t\tjzon_add_int(ja, \"audio_level_now\",\n\t\t\t\t     (int32_t)a->aulevel);\n\t\t}\n\t\tjson_object_array_add(jarr, ja);\n\n\t\t/* add to info string */\n\t\tif (pmb) {\n\t\t\tanon_id(uid_anon, userid);\n\t\t\tanon_client(cid_anon, clientid);\n\t\t\tmbuf_printf(pmb, \"{[%s.%s] audio_level: %d/%d}\",\n\t\t\t\t    uid_anon, cid_anon,\n\t\t\t\t    a->aulevel_smooth, a->aulevel);\n\t\t\tif (le != levell->tail)\n\t\t\t\tmbuf_printf(pmb, \",\");\n\t\t}\t\t\n\t}\n\tjson_object_object_add(jobj, \"audio_levels\", jarr);\n\n\tif (pmb) {\n\t\tpmb->pos = 0;\n\t\tmbuf_strdup(pmb, anon_str, pmb->end);\n\t\tmem_deref(pmb);\n\t}\n\n\tjzon_encode(json_str, jobj);\n out:\t\n\tmem_deref(jobj);\n\n\treturn err;\n}",
        "description": "A remote format string vulnerability in the wire-avs component of Wire, an open-source messenger, affects versions prior to 7.1.12. This vulnerability could lead to a denial of service or the execution of arbitrary code by an attacker. The issue has been addressed in wire-avs version 7.1.12, and there are currently no known workarounds available.",
        "commit": "The process of importing the latest release-7.1 files from an old repository."
    },
    {
        "cwe": "CWE-667",
        "func_name": "torvalds/pipe_to_file",
        "score": 0.7629551291465759,
        "func_before": "static int pipe_to_file(struct pipe_inode_info *pipe, struct pipe_buffer *buf,\n\t\t\tstruct splice_desc *sd)\n{\n\tstruct file *file = sd->u.file;\n\tstruct address_space *mapping = file->f_mapping;\n\tunsigned int offset, this_len;\n\tstruct page *page;\n\tpgoff_t index;\n\tint ret;\n\n\t/*\n\t * make sure the data in this buffer is uptodate\n\t */\n\tret = buf->ops->confirm(pipe, buf);\n\tif (unlikely(ret))\n\t\treturn ret;\n\n\tindex = sd->pos >> PAGE_CACHE_SHIFT;\n\toffset = sd->pos & ~PAGE_CACHE_MASK;\n\n\tthis_len = sd->len;\n\tif (this_len + offset > PAGE_CACHE_SIZE)\n\t\tthis_len = PAGE_CACHE_SIZE - offset;\n\nfind_page:\n\tpage = find_lock_page(mapping, index);\n\tif (!page) {\n\t\tret = -ENOMEM;\n\t\tpage = page_cache_alloc_cold(mapping);\n\t\tif (unlikely(!page))\n\t\t\tgoto out_ret;\n\n\t\t/*\n\t\t * This will also lock the page\n\t\t */\n\t\tret = add_to_page_cache_lru(page, mapping, index,\n\t\t\t\t\t    GFP_KERNEL);\n\t\tif (unlikely(ret))\n\t\t\tgoto out;\n\t}\n\n\tret = mapping->a_ops->prepare_write(file, page, offset, offset+this_len);\n\tif (unlikely(ret)) {\n\t\tloff_t isize = i_size_read(mapping->host);\n\n\t\tif (ret != AOP_TRUNCATED_PAGE)\n\t\t\tunlock_page(page);\n\t\tpage_cache_release(page);\n\t\tif (ret == AOP_TRUNCATED_PAGE)\n\t\t\tgoto find_page;\n\n\t\t/*\n\t\t * prepare_write() may have instantiated a few blocks\n\t\t * outside i_size.  Trim these off again.\n\t\t */\n\t\tif (sd->pos + this_len > isize)\n\t\t\tvmtruncate(mapping->host, isize);\n\n\t\tgoto out_ret;\n\t}\n\n\tif (buf->page != page) {\n\t\t/*\n\t\t * Careful, ->map() uses KM_USER0!\n\t\t */\n\t\tchar *src = buf->ops->map(pipe, buf, 1);\n\t\tchar *dst = kmap_atomic(page, KM_USER1);\n\n\t\tmemcpy(dst + offset, src + buf->offset, this_len);\n\t\tflush_dcache_page(page);\n\t\tkunmap_atomic(dst, KM_USER1);\n\t\tbuf->ops->unmap(pipe, buf, src);\n\t}\n\n\tret = mapping->a_ops->commit_write(file, page, offset, offset+this_len);\n\tif (ret) {\n\t\tif (ret == AOP_TRUNCATED_PAGE) {\n\t\t\tpage_cache_release(page);\n\t\t\tgoto find_page;\n\t\t}\n\t\tif (ret < 0)\n\t\t\tgoto out;\n\t\t/*\n\t\t * Partial write has happened, so 'ret' already initialized by\n\t\t * number of bytes written, Where is nothing we have to do here.\n\t\t */\n\t} else\n\t\tret = this_len;\n\t/*\n\t * Return the number of bytes written and mark page as\n\t * accessed, we are now done!\n\t */\n\tmark_page_accessed(page);\nout:\n\tpage_cache_release(page);\n\tunlock_page(page);\nout_ret:\n\treturn ret;\n}",
        "func_after": "static int pipe_to_file(struct pipe_inode_info *pipe, struct pipe_buffer *buf,\n\t\t\tstruct splice_desc *sd)\n{\n\tstruct file *file = sd->u.file;\n\tstruct address_space *mapping = file->f_mapping;\n\tunsigned int offset, this_len;\n\tstruct page *page;\n\tpgoff_t index;\n\tint ret;\n\n\t/*\n\t * make sure the data in this buffer is uptodate\n\t */\n\tret = buf->ops->confirm(pipe, buf);\n\tif (unlikely(ret))\n\t\treturn ret;\n\n\tindex = sd->pos >> PAGE_CACHE_SHIFT;\n\toffset = sd->pos & ~PAGE_CACHE_MASK;\n\n\tthis_len = sd->len;\n\tif (this_len + offset > PAGE_CACHE_SIZE)\n\t\tthis_len = PAGE_CACHE_SIZE - offset;\n\nfind_page:\n\tpage = find_lock_page(mapping, index);\n\tif (!page) {\n\t\tret = -ENOMEM;\n\t\tpage = page_cache_alloc_cold(mapping);\n\t\tif (unlikely(!page))\n\t\t\tgoto out_ret;\n\n\t\t/*\n\t\t * This will also lock the page\n\t\t */\n\t\tret = add_to_page_cache_lru(page, mapping, index,\n\t\t\t\t\t    GFP_KERNEL);\n\t\tif (unlikely(ret))\n\t\t\tgoto out_release;\n\t}\n\n\tret = mapping->a_ops->prepare_write(file, page, offset, offset+this_len);\n\tif (unlikely(ret)) {\n\t\tloff_t isize = i_size_read(mapping->host);\n\n\t\tif (ret != AOP_TRUNCATED_PAGE)\n\t\t\tunlock_page(page);\n\t\tpage_cache_release(page);\n\t\tif (ret == AOP_TRUNCATED_PAGE)\n\t\t\tgoto find_page;\n\n\t\t/*\n\t\t * prepare_write() may have instantiated a few blocks\n\t\t * outside i_size.  Trim these off again.\n\t\t */\n\t\tif (sd->pos + this_len > isize)\n\t\t\tvmtruncate(mapping->host, isize);\n\n\t\tgoto out_ret;\n\t}\n\n\tif (buf->page != page) {\n\t\t/*\n\t\t * Careful, ->map() uses KM_USER0!\n\t\t */\n\t\tchar *src = buf->ops->map(pipe, buf, 1);\n\t\tchar *dst = kmap_atomic(page, KM_USER1);\n\n\t\tmemcpy(dst + offset, src + buf->offset, this_len);\n\t\tflush_dcache_page(page);\n\t\tkunmap_atomic(dst, KM_USER1);\n\t\tbuf->ops->unmap(pipe, buf, src);\n\t}\n\n\tret = mapping->a_ops->commit_write(file, page, offset, offset+this_len);\n\tif (ret) {\n\t\tif (ret == AOP_TRUNCATED_PAGE) {\n\t\t\tpage_cache_release(page);\n\t\t\tgoto find_page;\n\t\t}\n\t\tif (ret < 0)\n\t\t\tgoto out;\n\t\t/*\n\t\t * Partial write has happened, so 'ret' already initialized by\n\t\t * number of bytes written, Where is nothing we have to do here.\n\t\t */\n\t} else\n\t\tret = this_len;\n\t/*\n\t * Return the number of bytes written and mark page as\n\t * accessed, we are now done!\n\t */\n\tmark_page_accessed(page);\nout:\n\tunlock_page(page);\nout_release:\n\tpage_cache_release(page);\nout_ret:\n\treturn ret;\n}",
        "description": "In the splice subsystem of the Linux kernel prior to version 2.6.22.2, there is an issue where the `add_to_page_cache_lru` function's failure is not adequately managed. As a result, the system attempts to unlock a page that was not previously locked, leading to a denial of service condition characterized by a kernel BUG and potential system crash. This vulnerability can be exploited by local users using tools such as fio for I/O operations.",
        "commit": "If the `add_to_page_cache_lru()` function fails, the page remains unlocked. However, the subsequent code in `splice` jumps to an error path that attempts to release and unlock the page, leading to a `BUG()` in `unlock_page()`. This issue can be resolved by introducing an additional label that solely handles the page release without attempting to unlock it. This bug was triggered on EL5 by Gurudas Pai using the fio tool."
    },
    {
        "cwe": "CWE-367",
        "func_name": "torvalds/enter_svm_guest_mode",
        "score": 0.7409204244613647,
        "func_before": "int enter_svm_guest_mode(struct vcpu_svm *svm, u64 vmcb12_gpa,\n\t\t\t struct vmcb *vmcb12)\n{\n\tint ret;\n\n\tsvm->nested.vmcb12_gpa = vmcb12_gpa;\n\tload_nested_vmcb_control(svm, &vmcb12->control);\n\tnested_prepare_vmcb_save(svm, vmcb12);\n\tnested_prepare_vmcb_control(svm);\n\n\tret = nested_svm_load_cr3(&svm->vcpu, vmcb12->save.cr3,\n\t\t\t\t  nested_npt_enabled(svm));\n\tif (ret)\n\t\treturn ret;\n\n\tsvm_set_gif(svm, true);\n\n\treturn 0;\n}",
        "func_after": "int enter_svm_guest_mode(struct vcpu_svm *svm, u64 vmcb12_gpa,\n\t\t\t struct vmcb *vmcb12)\n{\n\tint ret;\n\n\tsvm->nested.vmcb12_gpa = vmcb12_gpa;\n\tnested_prepare_vmcb_save(svm, vmcb12);\n\tnested_prepare_vmcb_control(svm);\n\n\tret = nested_svm_load_cr3(&svm->vcpu, vmcb12->save.cr3,\n\t\t\t\t  nested_npt_enabled(svm));\n\tif (ret)\n\t\treturn ret;\n\n\tsvm_set_gif(svm, true);\n\n\treturn 0;\n}",
        "description": "A use-after-free vulnerability exists in the Linux kernel prior to version 5.11.12 within the AMD KVM SVM nested virtualization module. This flaw allows an AMD KVM guest to potentially bypass access controls on host OS Model-Specific Registers (MSRs) when multiple nested guests are present. The issue arises due to a Time-of-Check to Time-of-Use (TOCTOU) race condition involving a VMCB12 double fetch in the `nested_svm_vmrun` function.",
        "commit": "To avoid race conditions between checking and using nested VMCB controls, ensuring that the VMRUN intercept is consistently reflected to the nested hypervisor rather than being processed by the host is crucial. Without this patch, there is a risk that `svm->nested.hsave` could point to the MSR permission bitmap for nested guests, leading to potential vulnerabilities such as CVE-2021-29657."
    },
    {
        "cwe": "CWE-191",
        "func_name": "torvalds/deassemble_neg_contexts",
        "score": 0.7678866982460022,
        "func_before": "static __le32 deassemble_neg_contexts(struct ksmbd_conn *conn,\n\t\t\t\t      struct smb2_negotiate_req *req,\n\t\t\t\t      int len_of_smb)\n{\n\t/* +4 is to account for the RFC1001 len field */\n\tstruct smb2_neg_context *pctx = (struct smb2_neg_context *)req;\n\tint i = 0, len_of_ctxts;\n\tint offset = le32_to_cpu(req->NegotiateContextOffset);\n\tint neg_ctxt_cnt = le16_to_cpu(req->NegotiateContextCount);\n\t__le32 status = STATUS_INVALID_PARAMETER;\n\n\tksmbd_debug(SMB, \"decoding %d negotiate contexts\\n\", neg_ctxt_cnt);\n\tif (len_of_smb <= offset) {\n\t\tksmbd_debug(SMB, \"Invalid response: negotiate context offset\\n\");\n\t\treturn status;\n\t}\n\n\tlen_of_ctxts = len_of_smb - offset;\n\n\twhile (i++ < neg_ctxt_cnt) {\n\t\tint clen, ctxt_len;\n\n\t\tif (len_of_ctxts < sizeof(struct smb2_neg_context))\n\t\t\tbreak;\n\n\t\tpctx = (struct smb2_neg_context *)((char *)pctx + offset);\n\t\tclen = le16_to_cpu(pctx->DataLength);\n\t\tctxt_len = clen + sizeof(struct smb2_neg_context);\n\n\t\tif (ctxt_len > len_of_ctxts)\n\t\t\tbreak;\n\n\t\tif (pctx->ContextType == SMB2_PREAUTH_INTEGRITY_CAPABILITIES) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_PREAUTH_INTEGRITY_CAPABILITIES context\\n\");\n\t\t\tif (conn->preauth_info->Preauth_HashId)\n\t\t\t\tbreak;\n\n\t\t\tstatus = decode_preauth_ctxt(conn,\n\t\t\t\t\t\t     (struct smb2_preauth_neg_context *)pctx,\n\t\t\t\t\t\t     ctxt_len);\n\t\t\tif (status != STATUS_SUCCESS)\n\t\t\t\tbreak;\n\t\t} else if (pctx->ContextType == SMB2_ENCRYPTION_CAPABILITIES) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_ENCRYPTION_CAPABILITIES context\\n\");\n\t\t\tif (conn->cipher_type)\n\t\t\t\tbreak;\n\n\t\t\tdecode_encrypt_ctxt(conn,\n\t\t\t\t\t    (struct smb2_encryption_neg_context *)pctx,\n\t\t\t\t\t    ctxt_len);\n\t\t} else if (pctx->ContextType == SMB2_COMPRESSION_CAPABILITIES) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_COMPRESSION_CAPABILITIES context\\n\");\n\t\t\tif (conn->compress_algorithm)\n\t\t\t\tbreak;\n\n\t\t\tdecode_compress_ctxt(conn,\n\t\t\t\t\t     (struct smb2_compression_capabilities_context *)pctx);\n\t\t} else if (pctx->ContextType == SMB2_NETNAME_NEGOTIATE_CONTEXT_ID) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_NETNAME_NEGOTIATE_CONTEXT_ID context\\n\");\n\t\t} else if (pctx->ContextType == SMB2_POSIX_EXTENSIONS_AVAILABLE) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_POSIX_EXTENSIONS_AVAILABLE context\\n\");\n\t\t\tconn->posix_ext_supported = true;\n\t\t} else if (pctx->ContextType == SMB2_SIGNING_CAPABILITIES) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_SIGNING_CAPABILITIES context\\n\");\n\n\t\t\tdecode_sign_cap_ctxt(conn,\n\t\t\t\t\t     (struct smb2_signing_capabilities *)pctx,\n\t\t\t\t\t     ctxt_len);\n\t\t}\n\n\t\t/* offsets must be 8 byte aligned */\n\t\tclen = (clen + 7) & ~0x7;\n\t\toffset = clen + sizeof(struct smb2_neg_context);\n\t\tlen_of_ctxts -= clen + sizeof(struct smb2_neg_context);\n\t}\n\treturn status;\n}",
        "func_after": "static __le32 deassemble_neg_contexts(struct ksmbd_conn *conn,\n\t\t\t\t      struct smb2_negotiate_req *req,\n\t\t\t\t      unsigned int len_of_smb)\n{\n\t/* +4 is to account for the RFC1001 len field */\n\tstruct smb2_neg_context *pctx = (struct smb2_neg_context *)req;\n\tint i = 0, len_of_ctxts;\n\tunsigned int offset = le32_to_cpu(req->NegotiateContextOffset);\n\tunsigned int neg_ctxt_cnt = le16_to_cpu(req->NegotiateContextCount);\n\t__le32 status = STATUS_INVALID_PARAMETER;\n\n\tksmbd_debug(SMB, \"decoding %d negotiate contexts\\n\", neg_ctxt_cnt);\n\tif (len_of_smb <= offset) {\n\t\tksmbd_debug(SMB, \"Invalid response: negotiate context offset\\n\");\n\t\treturn status;\n\t}\n\n\tlen_of_ctxts = len_of_smb - offset;\n\n\twhile (i++ < neg_ctxt_cnt) {\n\t\tint clen, ctxt_len;\n\n\t\tif (len_of_ctxts < (int)sizeof(struct smb2_neg_context))\n\t\t\tbreak;\n\n\t\tpctx = (struct smb2_neg_context *)((char *)pctx + offset);\n\t\tclen = le16_to_cpu(pctx->DataLength);\n\t\tctxt_len = clen + sizeof(struct smb2_neg_context);\n\n\t\tif (ctxt_len > len_of_ctxts)\n\t\t\tbreak;\n\n\t\tif (pctx->ContextType == SMB2_PREAUTH_INTEGRITY_CAPABILITIES) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_PREAUTH_INTEGRITY_CAPABILITIES context\\n\");\n\t\t\tif (conn->preauth_info->Preauth_HashId)\n\t\t\t\tbreak;\n\n\t\t\tstatus = decode_preauth_ctxt(conn,\n\t\t\t\t\t\t     (struct smb2_preauth_neg_context *)pctx,\n\t\t\t\t\t\t     ctxt_len);\n\t\t\tif (status != STATUS_SUCCESS)\n\t\t\t\tbreak;\n\t\t} else if (pctx->ContextType == SMB2_ENCRYPTION_CAPABILITIES) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_ENCRYPTION_CAPABILITIES context\\n\");\n\t\t\tif (conn->cipher_type)\n\t\t\t\tbreak;\n\n\t\t\tdecode_encrypt_ctxt(conn,\n\t\t\t\t\t    (struct smb2_encryption_neg_context *)pctx,\n\t\t\t\t\t    ctxt_len);\n\t\t} else if (pctx->ContextType == SMB2_COMPRESSION_CAPABILITIES) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_COMPRESSION_CAPABILITIES context\\n\");\n\t\t\tif (conn->compress_algorithm)\n\t\t\t\tbreak;\n\n\t\t\tdecode_compress_ctxt(conn,\n\t\t\t\t\t     (struct smb2_compression_capabilities_context *)pctx);\n\t\t} else if (pctx->ContextType == SMB2_NETNAME_NEGOTIATE_CONTEXT_ID) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_NETNAME_NEGOTIATE_CONTEXT_ID context\\n\");\n\t\t} else if (pctx->ContextType == SMB2_POSIX_EXTENSIONS_AVAILABLE) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_POSIX_EXTENSIONS_AVAILABLE context\\n\");\n\t\t\tconn->posix_ext_supported = true;\n\t\t} else if (pctx->ContextType == SMB2_SIGNING_CAPABILITIES) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_SIGNING_CAPABILITIES context\\n\");\n\n\t\t\tdecode_sign_cap_ctxt(conn,\n\t\t\t\t\t     (struct smb2_signing_capabilities *)pctx,\n\t\t\t\t\t     ctxt_len);\n\t\t}\n\n\t\t/* offsets must be 8 byte aligned */\n\t\toffset = (ctxt_len + 7) & ~0x7;\n\t\tlen_of_ctxts -= offset;\n\t}\n\treturn status;\n}",
        "description": "An issue was discovered in the Linux kernel prior to version 6.3.8. Within the ksmbd component located in the SMB server directory, there is an integer underflow and out-of-bounds read vulnerability in the deassemble_neg_contexts function.",
        "commit": "The vulnerability involves an integer underflow condition in the SMB2 protocol negotiation process within the Linux kernel. Specifically, the initial check compares `clen + sizeof(struct smb2_neg_context)` against `len_of_ctxts`. However, during the loop, `len_of_ctxts` is decremented by `((clen + 7) & ~0x7) + sizeof(struct smb2_neg_context)`, which can lead to an underflow if `clen` undergoes 8-byte alignment. To prevent this, the check should use `(clen + 7) & ~0x7` instead. Additionally, certain variables should be declared as unsigned to avoid similar issues. The vulnerability results in a slab-out-of-bounds read error, as indicated by the kernel log, leading to potential memory corruption and system instability."
    }
]