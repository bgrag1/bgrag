[
    {
        "cwe": "CWE-824",
        "func_name": "gerbv/gerbv_open_image",
        "score": 0.7495582699775696,
        "func_before": "int\ngerbv_open_image(gerbv_project_t *gerbvProject, gchar const* filename, int idx, int reload,\n\t\tgerbv_HID_Attribute *fattr, int n_fattr, gboolean forceLoadFile)\n{\n    gerb_file_t *fd;\n    gerbv_image_t *parsed_image = NULL, *parsed_image2 = NULL;\n    gint retv = -1;\n    gboolean isPnpFile = FALSE, foundBinary;\n    gerbv_HID_Attribute *attr_list = NULL;\n    int n_attr = 0;\n    /* If we're reloading, we'll pass in our file format attribute list\n     * since this is our hook for letting the user override the fileformat.\n     */\n    if (reload)\n\t{\n\t    /* We're reloading so use the attribute list in memory */\n\t    attr_list =  gerbvProject->file[idx]->image->info->attr_list;\n\t    n_attr =  gerbvProject->file[idx]->image->info->n_attr;\n\t}\n    else\n\t{\n\t    /* We're not reloading so use the attribute list read from the \n\t     * project file if given or NULL otherwise.\n\t     */\n\t    attr_list = fattr;\n\t    n_attr = n_fattr;\n\t}\n    /* if we don't have enough spots, then grow the file list by 2 to account for the possible \n       loading of two images for PNP files */\n    if ((idx+1) >= gerbvProject->max_files) {\n\tgerbvProject->file = g_renew (gerbv_fileinfo_t *,\n\t\t\tgerbvProject->file, gerbvProject->max_files + 2);\n\n\tgerbvProject->file[gerbvProject->max_files] = NULL;\n\tgerbvProject->file[gerbvProject->max_files+1] = NULL;\n\tgerbvProject->max_files += 2;\n    }\n    \n    dprintf(\"In open_image, about to try opening filename = %s\\n\", filename);\n    \n    fd = gerb_fopen(filename);\n    if (fd == NULL) {\n\tGERB_COMPILE_ERROR(_(\"Trying to open \\\"%s\\\": %s\"),\n\t\t\tfilename, strerror(errno));\n\treturn -1;\n    }\n\n    /* Store filename info fd for further use */\n    fd->filename = g_strdup(filename);\n    \n    dprintf(\"In open_image, successfully opened file.  Now check its type....\\n\");\n    /* Here's where we decide what file type we have */\n    /* Note: if the file has some invalid characters in it but still appears to\n       be a valid file, we check with the user if he wants to continue (only\n       if user opens the layer from the menu...if from the command line, we go\n       ahead and try to load it anyways) */\n\n    if (gerber_is_rs274x_p(fd, &foundBinary)) {\n\tdprintf(\"Found RS-274X file\\n\");\n\tif (!foundBinary || forceLoadFile) {\n\t\t/* figure out the directory path in case parse_gerb needs to\n\t\t * load any include files */\n\t\tgchar *currentLoadDirectory = g_path_get_dirname (filename);\n\t\tparsed_image = parse_gerb(fd, currentLoadDirectory);\n\t\tg_free (currentLoadDirectory);\n\t}\n    } else if(drill_file_p(fd, &foundBinary)) {\n\tdprintf(\"Found drill file\\n\");\n\tif (!foundBinary || forceLoadFile)\n\t    parsed_image = parse_drillfile(fd, attr_list, n_attr, reload);\n\t\n    } else if (pick_and_place_check_file_type(fd, &foundBinary)) {\n\tdprintf(\"Found pick-n-place file\\n\");\n\tif (!foundBinary || forceLoadFile) {\n\t\tif (!reload) {\n\t\t\tpick_and_place_parse_file_to_images(fd, &parsed_image, &parsed_image2);\n\t\t} else {\n\t\t\tswitch (gerbvProject->file[idx]->image->layertype) {\n\t\t\tcase GERBV_LAYERTYPE_PICKANDPLACE_TOP:\n\t\t\t\t/* Non NULL pointer is used as \"not to reload\" mark */\n\t\t\t\tparsed_image2 = (void *)!NULL;\n\t\t\t\tpick_and_place_parse_file_to_images(fd, &parsed_image, &parsed_image2);\n\t\t\t\tparsed_image2 = NULL;\n\t\t\t\tbreak;\n\t\t\tcase GERBV_LAYERTYPE_PICKANDPLACE_BOT:\n\t\t\t\t/* Non NULL pointer is used as \"not to reload\" mark */\n\t\t\t\tparsed_image2 = (void *)!NULL;\n\t\t\t\tpick_and_place_parse_file_to_images(fd, &parsed_image2, &parsed_image);\n\t\t\t\tparsed_image2 = NULL;\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tGERB_COMPILE_ERROR(_(\"%s: unknown pick-and-place board side to reload\"), filename);\n\t\t\t}\n\t\t}\n\t\t\t\n\t\tisPnpFile = TRUE;\n\t}\n    } else if (gerber_is_rs274d_p(fd)) {\n\tgchar *str = g_strdup_printf(_(\"Most likely found a RS-274D file \"\n\t\t\t\"\\\"%s\\\" ... trying to open anyways\\n\"), filename);\n\tdprintf(\"%s\", str);\n\tg_warning(\"%s\", str);\n\tg_free (str);\n\n\tif (!foundBinary || forceLoadFile) {\n\t\t/* figure out the directory path in case parse_gerb needs to\n\t\t * load any include files */\n\t\tgchar *currentLoadDirectory = g_path_get_dirname (filename);\n\t\tparsed_image = parse_gerb(fd, currentLoadDirectory);\n\t\tg_free (currentLoadDirectory);\n\t}\n    } else {\n\t/* This is not a known file */\n\tdprintf(\"Unknown filetype\");\n\tGERB_COMPILE_ERROR(_(\"%s: Unknown file type.\"), filename);\n\tparsed_image = NULL;\n    }\n    \n    g_free(fd->filename);\n    gerb_fclose(fd);\n    if (parsed_image == NULL) {\n\treturn -1;\n    }\n    \n    if (parsed_image) {\n\t/* strip the filename to the base */\n\tgchar *baseName = g_path_get_basename (filename);\n\tgchar *displayedName;\n\tif (isPnpFile)\n\t\tdisplayedName = g_strconcat (baseName, _(\" (top)\"), NULL);\n\telse\n\t\tdisplayedName = g_strdup (baseName);\n    \tretv = gerbv_add_parsed_image_to_project (gerbvProject, parsed_image, filename, displayedName, idx, reload);\n    \tg_free (baseName);\n    \tg_free (displayedName);\n    }\n\n    /* Set layer_dirty flag to FALSE */\n    gerbvProject->file[idx]->layer_dirty = FALSE;\n\n    /* for PNP place files, we may need to add a second image for the other\n       board side */\n    if (parsed_image2) {\n      /* strip the filename to the base */\n\tgchar *baseName = g_path_get_basename (filename);\n\tgchar *displayedName;\n\tdisplayedName = g_strconcat (baseName, _(\" (bottom)\"), NULL);\n    \tretv = gerbv_add_parsed_image_to_project (gerbvProject, parsed_image2, filename, displayedName, idx + 1, reload);\n    \tg_free (baseName);\n    \tg_free (displayedName);\n    }\n\n    return retv;\n}",
        "func_after": "int\ngerbv_open_image(gerbv_project_t *gerbvProject, gchar const* filename, int idx, int reload,\n\t\tgerbv_HID_Attribute *fattr, int n_fattr, gboolean forceLoadFile)\n{\n    gerb_file_t *fd;\n    gerbv_image_t *parsed_image = NULL, *parsed_image2 = NULL;\n    gint retv = -1;\n    gboolean isPnpFile = FALSE, foundBinary;\n    gerbv_HID_Attribute *attr_list = NULL;\n    int n_attr = 0;\n    /* If we're reloading, we'll pass in our file format attribute list\n     * since this is our hook for letting the user override the fileformat.\n     */\n    if (reload)\n\t{\n\t    /* We're reloading so use the attribute list in memory */\n\t    attr_list =  gerbvProject->file[idx]->image->info->attr_list;\n\t    n_attr =  gerbvProject->file[idx]->image->info->n_attr;\n\t}\n    else\n\t{\n\t    /* We're not reloading so use the attribute list read from the \n\t     * project file if given or NULL otherwise.\n\t     */\n\t    attr_list = fattr;\n\t    n_attr = n_fattr;\n\t}\n    /* if we don't have enough spots, then grow the file list by 2 to account for the possible \n       loading of two images for PNP files */\n    if ((idx+1) >= gerbvProject->max_files) {\n\tgerbvProject->file = g_renew (gerbv_fileinfo_t *,\n\t\t\tgerbvProject->file, gerbvProject->max_files + 2);\n\n\tgerbvProject->file[gerbvProject->max_files] = NULL;\n\tgerbvProject->file[gerbvProject->max_files+1] = NULL;\n\tgerbvProject->max_files += 2;\n    }\n    \n    dprintf(\"In open_image, about to try opening filename = %s\\n\", filename);\n    \n    fd = gerb_fopen(filename);\n    if (fd == NULL) {\n\tGERB_COMPILE_ERROR(_(\"Trying to open \\\"%s\\\": %s\"),\n\t\t\tfilename, strerror(errno));\n\treturn -1;\n    }\n\n    dprintf(\"In open_image, successfully opened file.  Now check its type....\\n\");\n    /* Here's where we decide what file type we have */\n    /* Note: if the file has some invalid characters in it but still appears to\n       be a valid file, we check with the user if he wants to continue (only\n       if user opens the layer from the menu...if from the command line, we go\n       ahead and try to load it anyways) */\n\n    if (gerber_is_rs274x_p(fd, &foundBinary)) {\n\tdprintf(\"Found RS-274X file\\n\");\n\tif (!foundBinary || forceLoadFile) {\n\t\t/* figure out the directory path in case parse_gerb needs to\n\t\t * load any include files */\n\t\tgchar *currentLoadDirectory = g_path_get_dirname (filename);\n\t\tparsed_image = parse_gerb(fd, currentLoadDirectory);\n\t\tg_free (currentLoadDirectory);\n\t}\n    } else if(drill_file_p(fd, &foundBinary)) {\n\tdprintf(\"Found drill file\\n\");\n\tif (!foundBinary || forceLoadFile)\n\t    parsed_image = parse_drillfile(fd, attr_list, n_attr, reload);\n\t\n    } else if (pick_and_place_check_file_type(fd, &foundBinary)) {\n\tdprintf(\"Found pick-n-place file\\n\");\n\tif (!foundBinary || forceLoadFile) {\n\t\tif (!reload) {\n\t\t\tpick_and_place_parse_file_to_images(fd, &parsed_image, &parsed_image2);\n\t\t} else {\n\t\t\tswitch (gerbvProject->file[idx]->image->layertype) {\n\t\t\tcase GERBV_LAYERTYPE_PICKANDPLACE_TOP:\n\t\t\t\t/* Non NULL pointer is used as \"not to reload\" mark */\n\t\t\t\tparsed_image2 = (void *)!NULL;\n\t\t\t\tpick_and_place_parse_file_to_images(fd, &parsed_image, &parsed_image2);\n\t\t\t\tparsed_image2 = NULL;\n\t\t\t\tbreak;\n\t\t\tcase GERBV_LAYERTYPE_PICKANDPLACE_BOT:\n\t\t\t\t/* Non NULL pointer is used as \"not to reload\" mark */\n\t\t\t\tparsed_image2 = (void *)!NULL;\n\t\t\t\tpick_and_place_parse_file_to_images(fd, &parsed_image2, &parsed_image);\n\t\t\t\tparsed_image2 = NULL;\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tGERB_COMPILE_ERROR(_(\"%s: unknown pick-and-place board side to reload\"), filename);\n\t\t\t}\n\t\t}\n\t\t\t\n\t\tisPnpFile = TRUE;\n\t}\n    } else if (gerber_is_rs274d_p(fd)) {\n\tgchar *str = g_strdup_printf(_(\"Most likely found a RS-274D file \"\n\t\t\t\"\\\"%s\\\" ... trying to open anyways\\n\"), filename);\n\tdprintf(\"%s\", str);\n\tg_warning(\"%s\", str);\n\tg_free (str);\n\n\tif (!foundBinary || forceLoadFile) {\n\t\t/* figure out the directory path in case parse_gerb needs to\n\t\t * load any include files */\n\t\tgchar *currentLoadDirectory = g_path_get_dirname (filename);\n\t\tparsed_image = parse_gerb(fd, currentLoadDirectory);\n\t\tg_free (currentLoadDirectory);\n\t}\n    } else {\n\t/* This is not a known file */\n\tdprintf(\"Unknown filetype\");\n\tGERB_COMPILE_ERROR(_(\"%s: Unknown file type.\"), filename);\n\tparsed_image = NULL;\n    }\n    \n    gerb_fclose(fd);\n    if (parsed_image == NULL) {\n\treturn -1;\n    }\n    \n    if (parsed_image) {\n\t/* strip the filename to the base */\n\tgchar *baseName = g_path_get_basename (filename);\n\tgchar *displayedName;\n\tif (isPnpFile)\n\t\tdisplayedName = g_strconcat (baseName, _(\" (top)\"), NULL);\n\telse\n\t\tdisplayedName = g_strdup (baseName);\n    \tretv = gerbv_add_parsed_image_to_project (gerbvProject, parsed_image, filename, displayedName, idx, reload);\n    \tg_free (baseName);\n    \tg_free (displayedName);\n    }\n\n    /* Set layer_dirty flag to FALSE */\n    gerbvProject->file[idx]->layer_dirty = FALSE;\n\n    /* for PNP place files, we may need to add a second image for the other\n       board side */\n    if (parsed_image2) {\n      /* strip the filename to the base */\n\tgchar *baseName = g_path_get_basename (filename);\n\tgchar *displayedName;\n\tdisplayedName = g_strconcat (baseName, _(\" (bottom)\"), NULL);\n    \tretv = gerbv_add_parsed_image_to_project (gerbvProject, parsed_image2, filename, displayedName, idx + 1, reload);\n    \tg_free (baseName);\n    \tg_free (displayedName);\n    }\n\n    return retv;\n}",
        "description": "A user with control over file input to Gerbv, between versions 2.4.0 and 2.10.0, can trigger a crash and achieve a denial-of-service condition by providing a specially crafted Gerber RS-274X file.",
        "commit": "An out-of-bounds memory access vulnerability related to filename handling was identified. To address this, all filename allocation and deallocation have been centralized within the `gerb_fopen` and `gerb_fclose` functions, eliminating the need for the caller to manage these operations. Additionally, a previously allocated `includeFilename` was not being properly freed, which has now been corrected. Unit tests have been added to ensure proper memory management using Valgrind."
    },
    {
        "cwe": "CWE-407",
        "func_name": "reddit/find_link_ref",
        "score": 0.713615894317627,
        "func_before": "static struct link_ref *\nfind_link_ref(struct link_ref **references, uint8_t *name, size_t length)\n{\n\tunsigned int hash = hash_link_ref(name, length);\n\tstruct link_ref *ref = NULL;\n\n\tref = references[hash % REF_TABLE_SIZE];\n\n\twhile (ref != NULL) {\n\t\tif (ref->id == hash)\n\t\t\treturn ref;\n\n\t\tref = ref->next;\n\t}\n\n\treturn NULL;\n}",
        "func_after": "static struct link_ref *\nfind_link_ref(struct link_ref **references, uint8_t *name, size_t length)\n{\n\tunsigned int hash = hash_link_ref(name, length);\n\tstruct link_ref *ref = NULL;\n\n\tref = references[hash % REF_TABLE_SIZE];\n\n\twhile (ref != NULL) {\n\t\tif (ref->id == hash && ref->label->size == length) {\n\t\t\tif (strncasecmp((char *)ref->label->data, (char *) name, length) == 0) {\n\t\t\t\treturn ref;\n\t\t\t}\n\t\t}\n\n\t\tref = ref->next;\n\t}\n\n\treturn NULL;\n}",
        "description": "Snudown, a Reddit-specific fork of the Sundown Markdown parser with Python integration, was found to be vulnerable to denial of service (DoS) attacks due to weaknesses in its reference table implementation. Specifically, the hash function used for inserting references into a hash table was weak, allowing attackers to generate a large number of collisions. Additionally, the hash table permitted duplicate entries, leading to prolonged retrieval times. These issues collectively make the system susceptible to hash-collision DoS attacks, a form of algorithmic complexity attack. Users are advised to update to version 1.7.0 to mitigate these vulnerabilities.",
        "commit": "A vulnerability related to hash collisions has been identified and addressed by implementing a case-insensitive SipHash function to replace the existing reference hash function. Additionally, changes were made to the `link_ref` structure to include a label, and updates were applied to the `find_link_ref` and `add_link_ref` functions to ensure they compare link labels as well as hashes and disallow duplicate entries, respectively. A cast was added to convert from `uint8_t` to `char` for use with `strncasecmp`. The README markdown was updated to remove TODO items, and support for generating Python 2 wheels was added. Furthermore, logic was included to handle older versions of glibc that do not have the `getrandom` function, impacting the staging environment."
    },
    {
        "cwe": "CWE-189",
        "func_name": "torvalds/i915_gem_execbuffer2",
        "score": 0.740733802318573,
        "func_before": "int\ni915_gem_execbuffer2(struct drm_device *dev, void *data,\n\t\t     struct drm_file *file)\n{\n\tstruct drm_i915_gem_execbuffer2 *args = data;\n\tstruct drm_i915_gem_exec_object2 *exec2_list = NULL;\n\tint ret;\n\n\tif (args->buffer_count < 1) {\n\t\tDRM_DEBUG(\"execbuf2 with %d buffers\\n\", args->buffer_count);\n\t\treturn -EINVAL;\n\t}\n\n\texec2_list = kmalloc(sizeof(*exec2_list)*args->buffer_count,\n\t\t\t     GFP_KERNEL | __GFP_NOWARN | __GFP_NORETRY);\n\tif (exec2_list == NULL)\n\t\texec2_list = drm_malloc_ab(sizeof(*exec2_list),\n\t\t\t\t\t   args->buffer_count);\n\tif (exec2_list == NULL) {\n\t\tDRM_DEBUG(\"Failed to allocate exec list for %d buffers\\n\",\n\t\t\t  args->buffer_count);\n\t\treturn -ENOMEM;\n\t}\n\tret = copy_from_user(exec2_list,\n\t\t\t     (struct drm_i915_relocation_entry __user *)\n\t\t\t     (uintptr_t) args->buffers_ptr,\n\t\t\t     sizeof(*exec2_list) * args->buffer_count);\n\tif (ret != 0) {\n\t\tDRM_DEBUG(\"copy %d exec entries failed %d\\n\",\n\t\t\t  args->buffer_count, ret);\n\t\tdrm_free_large(exec2_list);\n\t\treturn -EFAULT;\n\t}\n\n\tret = i915_gem_do_execbuffer(dev, data, file, args, exec2_list);\n\tif (!ret) {\n\t\t/* Copy the new buffer offsets back to the user's exec list. */\n\t\tret = copy_to_user((struct drm_i915_relocation_entry __user *)\n\t\t\t\t   (uintptr_t) args->buffers_ptr,\n\t\t\t\t   exec2_list,\n\t\t\t\t   sizeof(*exec2_list) * args->buffer_count);\n\t\tif (ret) {\n\t\t\tret = -EFAULT;\n\t\t\tDRM_DEBUG(\"failed to copy %d exec entries \"\n\t\t\t\t  \"back to user (%d)\\n\",\n\t\t\t\t  args->buffer_count, ret);\n\t\t}\n\t}\n\n\tdrm_free_large(exec2_list);\n\treturn ret;\n}",
        "func_after": "int\ni915_gem_execbuffer2(struct drm_device *dev, void *data,\n\t\t     struct drm_file *file)\n{\n\tstruct drm_i915_gem_execbuffer2 *args = data;\n\tstruct drm_i915_gem_exec_object2 *exec2_list = NULL;\n\tint ret;\n\n\tif (args->buffer_count < 1 ||\n\t    args->buffer_count > UINT_MAX / sizeof(*exec2_list)) {\n\t\tDRM_DEBUG(\"execbuf2 with %d buffers\\n\", args->buffer_count);\n\t\treturn -EINVAL;\n\t}\n\n\texec2_list = kmalloc(sizeof(*exec2_list)*args->buffer_count,\n\t\t\t     GFP_KERNEL | __GFP_NOWARN | __GFP_NORETRY);\n\tif (exec2_list == NULL)\n\t\texec2_list = drm_malloc_ab(sizeof(*exec2_list),\n\t\t\t\t\t   args->buffer_count);\n\tif (exec2_list == NULL) {\n\t\tDRM_DEBUG(\"Failed to allocate exec list for %d buffers\\n\",\n\t\t\t  args->buffer_count);\n\t\treturn -ENOMEM;\n\t}\n\tret = copy_from_user(exec2_list,\n\t\t\t     (struct drm_i915_relocation_entry __user *)\n\t\t\t     (uintptr_t) args->buffers_ptr,\n\t\t\t     sizeof(*exec2_list) * args->buffer_count);\n\tif (ret != 0) {\n\t\tDRM_DEBUG(\"copy %d exec entries failed %d\\n\",\n\t\t\t  args->buffer_count, ret);\n\t\tdrm_free_large(exec2_list);\n\t\treturn -EFAULT;\n\t}\n\n\tret = i915_gem_do_execbuffer(dev, data, file, args, exec2_list);\n\tif (!ret) {\n\t\t/* Copy the new buffer offsets back to the user's exec list. */\n\t\tret = copy_to_user((struct drm_i915_relocation_entry __user *)\n\t\t\t\t   (uintptr_t) args->buffers_ptr,\n\t\t\t\t   exec2_list,\n\t\t\t\t   sizeof(*exec2_list) * args->buffer_count);\n\t\tif (ret) {\n\t\t\tret = -EFAULT;\n\t\t\tDRM_DEBUG(\"failed to copy %d exec entries \"\n\t\t\t\t  \"back to user (%d)\\n\",\n\t\t\t\t  args->buffer_count, ret);\n\t\t}\n\t}\n\n\tdrm_free_large(exec2_list);\n\treturn ret;\n}",
        "description": "An integer overflow vulnerability exists within the `i915_gem_execbuffer2` function of the DRM subsystem in the Linux kernel prior to version 3.3.5 on 32-bit platforms. This flaw allows local users to trigger a denial of service through an out-of-bounds write or potentially cause other unspecified impacts via a specially crafted ioctl call.",
        "commit": "A vulnerability was identified in the i915 driver of the DRM subsystem within the Linux kernel, where a large `args->buffer_count` value provided by userspace through an ioctl call could cause an integer overflow on 32-bit systems. This overflow affects the calculation of the allocation size for temporary execution buffers, potentially leading to out-of-bounds memory access. This issue arose due to changes introduced in commit 8408c282, which attempted to optimize buffer allocation by first trying a normal large `kmalloc`."
    },
    {
        "cwe": "CWE-326",
        "func_name": "torvalds/__ipv6_select_ident",
        "score": 0.7314881682395935,
        "func_before": "static u32 __ipv6_select_ident(struct net *net, u32 hashrnd,\n\t\t\t       const struct in6_addr *dst,\n\t\t\t       const struct in6_addr *src)\n{\n\tu32 hash, id;\n\n\thash = __ipv6_addr_jhash(dst, hashrnd);\n\thash = __ipv6_addr_jhash(src, hash);\n\thash ^= net_hash_mix(net);\n\n\t/* Treat id of 0 as unset and if we get 0 back from ip_idents_reserve,\n\t * set the hight order instead thus minimizing possible future\n\t * collisions.\n\t */\n\tid = ip_idents_reserve(hash, 1);\n\tif (unlikely(!id))\n\t\tid = 1 << 31;\n\n\treturn id;\n}",
        "func_after": "static u32 __ipv6_select_ident(struct net *net,\n\t\t\t       const struct in6_addr *dst,\n\t\t\t       const struct in6_addr *src)\n{\n\tconst struct {\n\t\tstruct in6_addr dst;\n\t\tstruct in6_addr src;\n\t} __aligned(SIPHASH_ALIGNMENT) combined = {\n\t\t.dst = *dst,\n\t\t.src = *src,\n\t};\n\tu32 hash, id;\n\n\t/* Note the following code is not safe, but this is okay. */\n\tif (unlikely(siphash_key_is_zero(&net->ipv4.ip_id_key)))\n\t\tget_random_bytes(&net->ipv4.ip_id_key,\n\t\t\t\t sizeof(net->ipv4.ip_id_key));\n\n\thash = siphash(&combined, sizeof(combined), &net->ipv4.ip_id_key);\n\n\t/* Treat id of 0 as unset and if we get 0 back from ip_idents_reserve,\n\t * set the hight order instead thus minimizing possible future\n\t * collisions.\n\t */\n\tid = ip_idents_reserve(hash, 1);\n\tif (unlikely(!id))\n\t\tid = 1 << 31;\n\n\treturn id;\n}",
        "description": "In versions of the Linux kernel prior to 5.1.7, an attacker can track devices by analyzing the IP ID values generated by the kernel for connectionless protocols such as UDP and ICMP. By sending traffic to multiple destination IP addresses, it is possible to induce hash collisions within the counter array, potentially revealing the hashing key through enumeration. This vulnerability can be exploited by hosting a specially crafted web page that leverages technologies like WebRTC or gQUIC to direct UDP traffic to IP addresses controlled by the attacker.",
        "commit": "The IP ID generation mechanism in the networking stack is deemed insufficiently secure due to potential vulnerabilities that could be exploited by attackers. Despite recent improvements such as the introduction of a 64-bit key and the Jenkins hash function, these measures are still considered risky. Therefore, it is recommended to transition to using siphash with its 128-bit keys to enhance the security of IP ID generation."
    },
    {
        "cwe": "CWE-190",
        "func_name": "kernel/__htab_map_lookup_and_delete_batch",
        "score": 0.7568625807762146,
        "func_before": "static int\n__htab_map_lookup_and_delete_batch(struct bpf_map *map,\n\t\t\t\t   const union bpf_attr *attr,\n\t\t\t\t   union bpf_attr __user *uattr,\n\t\t\t\t   bool do_delete, bool is_lru_map,\n\t\t\t\t   bool is_percpu)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tu32 bucket_cnt, total, key_size, value_size, roundup_key_size;\n\tvoid *keys = NULL, *values = NULL, *value, *dst_key, *dst_val;\n\tvoid __user *uvalues = u64_to_user_ptr(attr->batch.values);\n\tvoid __user *ukeys = u64_to_user_ptr(attr->batch.keys);\n\tvoid __user *ubatch = u64_to_user_ptr(attr->batch.in_batch);\n\tu32 batch, max_count, size, bucket_size;\n\tstruct htab_elem *node_to_free = NULL;\n\tu64 elem_map_flags, map_flags;\n\tstruct hlist_nulls_head *head;\n\tstruct hlist_nulls_node *n;\n\tunsigned long flags = 0;\n\tbool locked = false;\n\tstruct htab_elem *l;\n\tstruct bucket *b;\n\tint ret = 0;\n\n\telem_map_flags = attr->batch.elem_flags;\n\tif ((elem_map_flags & ~BPF_F_LOCK) ||\n\t    ((elem_map_flags & BPF_F_LOCK) && !map_value_has_spin_lock(map)))\n\t\treturn -EINVAL;\n\n\tmap_flags = attr->batch.flags;\n\tif (map_flags)\n\t\treturn -EINVAL;\n\n\tmax_count = attr->batch.count;\n\tif (!max_count)\n\t\treturn 0;\n\n\tif (put_user(0, &uattr->batch.count))\n\t\treturn -EFAULT;\n\n\tbatch = 0;\n\tif (ubatch && copy_from_user(&batch, ubatch, sizeof(batch)))\n\t\treturn -EFAULT;\n\n\tif (batch >= htab->n_buckets)\n\t\treturn -ENOENT;\n\n\tkey_size = htab->map.key_size;\n\troundup_key_size = round_up(htab->map.key_size, 8);\n\tvalue_size = htab->map.value_size;\n\tsize = round_up(value_size, 8);\n\tif (is_percpu)\n\t\tvalue_size = size * num_possible_cpus();\n\ttotal = 0;\n\t/* while experimenting with hash tables with sizes ranging from 10 to\n\t * 1000, it was observed that a bucket can have upto 5 entries.\n\t */\n\tbucket_size = 5;\n\nalloc:\n\t/* We cannot do copy_from_user or copy_to_user inside\n\t * the rcu_read_lock. Allocate enough space here.\n\t */\n\tkeys = kvmalloc(key_size * bucket_size, GFP_USER | __GFP_NOWARN);\n\tvalues = kvmalloc(value_size * bucket_size, GFP_USER | __GFP_NOWARN);\n\tif (!keys || !values) {\n\t\tret = -ENOMEM;\n\t\tgoto after_loop;\n\t}\n\nagain:\n\tbpf_disable_instrumentation();\n\trcu_read_lock();\nagain_nocopy:\n\tdst_key = keys;\n\tdst_val = values;\n\tb = &htab->buckets[batch];\n\thead = &b->head;\n\t/* do not grab the lock unless need it (bucket_cnt > 0). */\n\tif (locked) {\n\t\tret = htab_lock_bucket(htab, b, batch, &flags);\n\t\tif (ret)\n\t\t\tgoto next_batch;\n\t}\n\n\tbucket_cnt = 0;\n\thlist_nulls_for_each_entry_rcu(l, n, head, hash_node)\n\t\tbucket_cnt++;\n\n\tif (bucket_cnt && !locked) {\n\t\tlocked = true;\n\t\tgoto again_nocopy;\n\t}\n\n\tif (bucket_cnt > (max_count - total)) {\n\t\tif (total == 0)\n\t\t\tret = -ENOSPC;\n\t\t/* Note that since bucket_cnt > 0 here, it is implicit\n\t\t * that the locked was grabbed, so release it.\n\t\t */\n\t\thtab_unlock_bucket(htab, b, batch, flags);\n\t\trcu_read_unlock();\n\t\tbpf_enable_instrumentation();\n\t\tgoto after_loop;\n\t}\n\n\tif (bucket_cnt > bucket_size) {\n\t\tbucket_size = bucket_cnt;\n\t\t/* Note that since bucket_cnt > 0 here, it is implicit\n\t\t * that the locked was grabbed, so release it.\n\t\t */\n\t\thtab_unlock_bucket(htab, b, batch, flags);\n\t\trcu_read_unlock();\n\t\tbpf_enable_instrumentation();\n\t\tkvfree(keys);\n\t\tkvfree(values);\n\t\tgoto alloc;\n\t}\n\n\t/* Next block is only safe to run if you have grabbed the lock */\n\tif (!locked)\n\t\tgoto next_batch;\n\n\thlist_nulls_for_each_entry_safe(l, n, head, hash_node) {\n\t\tmemcpy(dst_key, l->key, key_size);\n\n\t\tif (is_percpu) {\n\t\t\tint off = 0, cpu;\n\t\t\tvoid __percpu *pptr;\n\n\t\t\tpptr = htab_elem_get_ptr(l, map->key_size);\n\t\t\tfor_each_possible_cpu(cpu) {\n\t\t\t\tbpf_long_memcpy(dst_val + off,\n\t\t\t\t\t\tper_cpu_ptr(pptr, cpu), size);\n\t\t\t\toff += size;\n\t\t\t}\n\t\t} else {\n\t\t\tvalue = l->key + roundup_key_size;\n\t\t\tif (elem_map_flags & BPF_F_LOCK)\n\t\t\t\tcopy_map_value_locked(map, dst_val, value,\n\t\t\t\t\t\t      true);\n\t\t\telse\n\t\t\t\tcopy_map_value(map, dst_val, value);\n\t\t\tcheck_and_init_map_lock(map, dst_val);\n\t\t}\n\t\tif (do_delete) {\n\t\t\thlist_nulls_del_rcu(&l->hash_node);\n\n\t\t\t/* bpf_lru_push_free() will acquire lru_lock, which\n\t\t\t * may cause deadlock. See comments in function\n\t\t\t * prealloc_lru_pop(). Let us do bpf_lru_push_free()\n\t\t\t * after releasing the bucket lock.\n\t\t\t */\n\t\t\tif (is_lru_map) {\n\t\t\t\tl->batch_flink = node_to_free;\n\t\t\t\tnode_to_free = l;\n\t\t\t} else {\n\t\t\t\tfree_htab_elem(htab, l);\n\t\t\t}\n\t\t}\n\t\tdst_key += key_size;\n\t\tdst_val += value_size;\n\t}\n\n\thtab_unlock_bucket(htab, b, batch, flags);\n\tlocked = false;\n\n\twhile (node_to_free) {\n\t\tl = node_to_free;\n\t\tnode_to_free = node_to_free->batch_flink;\n\t\tbpf_lru_push_free(&htab->lru, &l->lru_node);\n\t}\n\nnext_batch:\n\t/* If we are not copying data, we can go to next bucket and avoid\n\t * unlocking the rcu.\n\t */\n\tif (!bucket_cnt && (batch + 1 < htab->n_buckets)) {\n\t\tbatch++;\n\t\tgoto again_nocopy;\n\t}\n\n\trcu_read_unlock();\n\tbpf_enable_instrumentation();\n\tif (bucket_cnt && (copy_to_user(ukeys + total * key_size, keys,\n\t    key_size * bucket_cnt) ||\n\t    copy_to_user(uvalues + total * value_size, values,\n\t    value_size * bucket_cnt))) {\n\t\tret = -EFAULT;\n\t\tgoto after_loop;\n\t}\n\n\ttotal += bucket_cnt;\n\tbatch++;\n\tif (batch >= htab->n_buckets) {\n\t\tret = -ENOENT;\n\t\tgoto after_loop;\n\t}\n\tgoto again;\n\nafter_loop:\n\tif (ret == -EFAULT)\n\t\tgoto out;\n\n\t/* copy # of entries and next batch */\n\tubatch = u64_to_user_ptr(attr->batch.out_batch);\n\tif (copy_to_user(ubatch, &batch, sizeof(batch)) ||\n\t    put_user(total, &uattr->batch.count))\n\t\tret = -EFAULT;\n\nout:\n\tkvfree(keys);\n\tkvfree(values);\n\treturn ret;\n}",
        "func_after": "static int\n__htab_map_lookup_and_delete_batch(struct bpf_map *map,\n\t\t\t\t   const union bpf_attr *attr,\n\t\t\t\t   union bpf_attr __user *uattr,\n\t\t\t\t   bool do_delete, bool is_lru_map,\n\t\t\t\t   bool is_percpu)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tu32 bucket_cnt, total, key_size, value_size, roundup_key_size;\n\tvoid *keys = NULL, *values = NULL, *value, *dst_key, *dst_val;\n\tvoid __user *uvalues = u64_to_user_ptr(attr->batch.values);\n\tvoid __user *ukeys = u64_to_user_ptr(attr->batch.keys);\n\tvoid __user *ubatch = u64_to_user_ptr(attr->batch.in_batch);\n\tu32 batch, max_count, size, bucket_size;\n\tstruct htab_elem *node_to_free = NULL;\n\tu64 elem_map_flags, map_flags;\n\tstruct hlist_nulls_head *head;\n\tstruct hlist_nulls_node *n;\n\tunsigned long flags = 0;\n\tbool locked = false;\n\tstruct htab_elem *l;\n\tstruct bucket *b;\n\tint ret = 0;\n\n\telem_map_flags = attr->batch.elem_flags;\n\tif ((elem_map_flags & ~BPF_F_LOCK) ||\n\t    ((elem_map_flags & BPF_F_LOCK) && !map_value_has_spin_lock(map)))\n\t\treturn -EINVAL;\n\n\tmap_flags = attr->batch.flags;\n\tif (map_flags)\n\t\treturn -EINVAL;\n\n\tmax_count = attr->batch.count;\n\tif (!max_count)\n\t\treturn 0;\n\n\tif (put_user(0, &uattr->batch.count))\n\t\treturn -EFAULT;\n\n\tbatch = 0;\n\tif (ubatch && copy_from_user(&batch, ubatch, sizeof(batch)))\n\t\treturn -EFAULT;\n\n\tif (batch >= htab->n_buckets)\n\t\treturn -ENOENT;\n\n\tkey_size = htab->map.key_size;\n\troundup_key_size = round_up(htab->map.key_size, 8);\n\tvalue_size = htab->map.value_size;\n\tsize = round_up(value_size, 8);\n\tif (is_percpu)\n\t\tvalue_size = size * num_possible_cpus();\n\ttotal = 0;\n\t/* while experimenting with hash tables with sizes ranging from 10 to\n\t * 1000, it was observed that a bucket can have upto 5 entries.\n\t */\n\tbucket_size = 5;\n\nalloc:\n\t/* We cannot do copy_from_user or copy_to_user inside\n\t * the rcu_read_lock. Allocate enough space here.\n\t */\n\tkeys = kvmalloc_array(key_size, bucket_size, GFP_USER | __GFP_NOWARN);\n\tvalues = kvmalloc_array(value_size, bucket_size, GFP_USER | __GFP_NOWARN);\n\tif (!keys || !values) {\n\t\tret = -ENOMEM;\n\t\tgoto after_loop;\n\t}\n\nagain:\n\tbpf_disable_instrumentation();\n\trcu_read_lock();\nagain_nocopy:\n\tdst_key = keys;\n\tdst_val = values;\n\tb = &htab->buckets[batch];\n\thead = &b->head;\n\t/* do not grab the lock unless need it (bucket_cnt > 0). */\n\tif (locked) {\n\t\tret = htab_lock_bucket(htab, b, batch, &flags);\n\t\tif (ret)\n\t\t\tgoto next_batch;\n\t}\n\n\tbucket_cnt = 0;\n\thlist_nulls_for_each_entry_rcu(l, n, head, hash_node)\n\t\tbucket_cnt++;\n\n\tif (bucket_cnt && !locked) {\n\t\tlocked = true;\n\t\tgoto again_nocopy;\n\t}\n\n\tif (bucket_cnt > (max_count - total)) {\n\t\tif (total == 0)\n\t\t\tret = -ENOSPC;\n\t\t/* Note that since bucket_cnt > 0 here, it is implicit\n\t\t * that the locked was grabbed, so release it.\n\t\t */\n\t\thtab_unlock_bucket(htab, b, batch, flags);\n\t\trcu_read_unlock();\n\t\tbpf_enable_instrumentation();\n\t\tgoto after_loop;\n\t}\n\n\tif (bucket_cnt > bucket_size) {\n\t\tbucket_size = bucket_cnt;\n\t\t/* Note that since bucket_cnt > 0 here, it is implicit\n\t\t * that the locked was grabbed, so release it.\n\t\t */\n\t\thtab_unlock_bucket(htab, b, batch, flags);\n\t\trcu_read_unlock();\n\t\tbpf_enable_instrumentation();\n\t\tkvfree(keys);\n\t\tkvfree(values);\n\t\tgoto alloc;\n\t}\n\n\t/* Next block is only safe to run if you have grabbed the lock */\n\tif (!locked)\n\t\tgoto next_batch;\n\n\thlist_nulls_for_each_entry_safe(l, n, head, hash_node) {\n\t\tmemcpy(dst_key, l->key, key_size);\n\n\t\tif (is_percpu) {\n\t\t\tint off = 0, cpu;\n\t\t\tvoid __percpu *pptr;\n\n\t\t\tpptr = htab_elem_get_ptr(l, map->key_size);\n\t\t\tfor_each_possible_cpu(cpu) {\n\t\t\t\tbpf_long_memcpy(dst_val + off,\n\t\t\t\t\t\tper_cpu_ptr(pptr, cpu), size);\n\t\t\t\toff += size;\n\t\t\t}\n\t\t} else {\n\t\t\tvalue = l->key + roundup_key_size;\n\t\t\tif (elem_map_flags & BPF_F_LOCK)\n\t\t\t\tcopy_map_value_locked(map, dst_val, value,\n\t\t\t\t\t\t      true);\n\t\t\telse\n\t\t\t\tcopy_map_value(map, dst_val, value);\n\t\t\tcheck_and_init_map_lock(map, dst_val);\n\t\t}\n\t\tif (do_delete) {\n\t\t\thlist_nulls_del_rcu(&l->hash_node);\n\n\t\t\t/* bpf_lru_push_free() will acquire lru_lock, which\n\t\t\t * may cause deadlock. See comments in function\n\t\t\t * prealloc_lru_pop(). Let us do bpf_lru_push_free()\n\t\t\t * after releasing the bucket lock.\n\t\t\t */\n\t\t\tif (is_lru_map) {\n\t\t\t\tl->batch_flink = node_to_free;\n\t\t\t\tnode_to_free = l;\n\t\t\t} else {\n\t\t\t\tfree_htab_elem(htab, l);\n\t\t\t}\n\t\t}\n\t\tdst_key += key_size;\n\t\tdst_val += value_size;\n\t}\n\n\thtab_unlock_bucket(htab, b, batch, flags);\n\tlocked = false;\n\n\twhile (node_to_free) {\n\t\tl = node_to_free;\n\t\tnode_to_free = node_to_free->batch_flink;\n\t\tbpf_lru_push_free(&htab->lru, &l->lru_node);\n\t}\n\nnext_batch:\n\t/* If we are not copying data, we can go to next bucket and avoid\n\t * unlocking the rcu.\n\t */\n\tif (!bucket_cnt && (batch + 1 < htab->n_buckets)) {\n\t\tbatch++;\n\t\tgoto again_nocopy;\n\t}\n\n\trcu_read_unlock();\n\tbpf_enable_instrumentation();\n\tif (bucket_cnt && (copy_to_user(ukeys + total * key_size, keys,\n\t    key_size * bucket_cnt) ||\n\t    copy_to_user(uvalues + total * value_size, values,\n\t    value_size * bucket_cnt))) {\n\t\tret = -EFAULT;\n\t\tgoto after_loop;\n\t}\n\n\ttotal += bucket_cnt;\n\tbatch++;\n\tif (batch >= htab->n_buckets) {\n\t\tret = -ENOENT;\n\t\tgoto after_loop;\n\t}\n\tgoto again;\n\nafter_loop:\n\tif (ret == -EFAULT)\n\t\tgoto out;\n\n\t/* copy # of entries and next batch */\n\tubatch = u64_to_user_ptr(attr->batch.out_batch);\n\tif (copy_to_user(ubatch, &batch, sizeof(batch)) ||\n\t    put_user(total, &uattr->batch.count))\n\t\tret = -EFAULT;\n\nout:\n\tkvfree(keys);\n\tkvfree(values);\n\treturn ret;\n}",
        "description": "In the Linux kernel up to version 5.13.8, an integer overflow and out-of-bounds write occur in the hash table implementation when numerous elements are stored in a single bucket. While exploitation may require the CAP_SYS_ADMIN capability, this vulnerability poses a risk of unauthorized memory access and potential system instability.",
        "commit": "In the function `__htab_map_lookup_and_delete_batch()`, during the iteration over hash buckets to count the number of elements (`bucket_size`), an integer overflow can occur if `bucket_size` becomes sufficiently large. This overflow leads to an out-of-bounds write, as indicated by the KASAN report. The vulnerability arises because the multiplication used to calculate the size for `kvmalloc()` can exceed the maximum allowable value, resulting in incorrect memory allocation.\n\nTo exploit this vulnerability, an attacker can manipulate the hash table by inserting a large number of elements with the same hash value, thereby increasing `bucket_size`. An attacker with `CAP_SYS_ADMIN` privileges can easily trigger this overflow by using the `BPF_F_ZERO_SEED` flag, which sets the random seed for the hash function (`jhash()`) to zero, allowing precise control over key distribution. Without `CAP_SYS_ADMIN`, while technically possible to guess the random seed and trigger the overflow, the probability is low and would require a significant amount of time.\n\nThe fix involves replacing the `kvmalloc()` function with `kvmalloc_array()` to safely handle the memory allocation, preventing integer overflow and ensuring correct memory bounds."
    }
]