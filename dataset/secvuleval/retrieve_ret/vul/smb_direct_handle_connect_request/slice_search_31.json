[
    {
        "cwe": "CWE-191",
        "func_name": "torvalds/deassemble_neg_contexts",
        "score": 0.7912006974220276,
        "func_before": "static __le32 deassemble_neg_contexts(struct ksmbd_conn *conn,\n\t\t\t\t      struct smb2_negotiate_req *req,\n\t\t\t\t      int len_of_smb)\n{\n\t/* +4 is to account for the RFC1001 len field */\n\tstruct smb2_neg_context *pctx = (struct smb2_neg_context *)req;\n\tint i = 0, len_of_ctxts;\n\tint offset = le32_to_cpu(req->NegotiateContextOffset);\n\tint neg_ctxt_cnt = le16_to_cpu(req->NegotiateContextCount);\n\t__le32 status = STATUS_INVALID_PARAMETER;\n\n\tksmbd_debug(SMB, \"decoding %d negotiate contexts\\n\", neg_ctxt_cnt);\n\tif (len_of_smb <= offset) {\n\t\tksmbd_debug(SMB, \"Invalid response: negotiate context offset\\n\");\n\t\treturn status;\n\t}\n\n\tlen_of_ctxts = len_of_smb - offset;\n\n\twhile (i++ < neg_ctxt_cnt) {\n\t\tint clen, ctxt_len;\n\n\t\tif (len_of_ctxts < sizeof(struct smb2_neg_context))\n\t\t\tbreak;\n\n\t\tpctx = (struct smb2_neg_context *)((char *)pctx + offset);\n\t\tclen = le16_to_cpu(pctx->DataLength);\n\t\tctxt_len = clen + sizeof(struct smb2_neg_context);\n\n\t\tif (ctxt_len > len_of_ctxts)\n\t\t\tbreak;\n\n\t\tif (pctx->ContextType == SMB2_PREAUTH_INTEGRITY_CAPABILITIES) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_PREAUTH_INTEGRITY_CAPABILITIES context\\n\");\n\t\t\tif (conn->preauth_info->Preauth_HashId)\n\t\t\t\tbreak;\n\n\t\t\tstatus = decode_preauth_ctxt(conn,\n\t\t\t\t\t\t     (struct smb2_preauth_neg_context *)pctx,\n\t\t\t\t\t\t     ctxt_len);\n\t\t\tif (status != STATUS_SUCCESS)\n\t\t\t\tbreak;\n\t\t} else if (pctx->ContextType == SMB2_ENCRYPTION_CAPABILITIES) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_ENCRYPTION_CAPABILITIES context\\n\");\n\t\t\tif (conn->cipher_type)\n\t\t\t\tbreak;\n\n\t\t\tdecode_encrypt_ctxt(conn,\n\t\t\t\t\t    (struct smb2_encryption_neg_context *)pctx,\n\t\t\t\t\t    ctxt_len);\n\t\t} else if (pctx->ContextType == SMB2_COMPRESSION_CAPABILITIES) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_COMPRESSION_CAPABILITIES context\\n\");\n\t\t\tif (conn->compress_algorithm)\n\t\t\t\tbreak;\n\n\t\t\tdecode_compress_ctxt(conn,\n\t\t\t\t\t     (struct smb2_compression_capabilities_context *)pctx);\n\t\t} else if (pctx->ContextType == SMB2_NETNAME_NEGOTIATE_CONTEXT_ID) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_NETNAME_NEGOTIATE_CONTEXT_ID context\\n\");\n\t\t} else if (pctx->ContextType == SMB2_POSIX_EXTENSIONS_AVAILABLE) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_POSIX_EXTENSIONS_AVAILABLE context\\n\");\n\t\t\tconn->posix_ext_supported = true;\n\t\t} else if (pctx->ContextType == SMB2_SIGNING_CAPABILITIES) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_SIGNING_CAPABILITIES context\\n\");\n\n\t\t\tdecode_sign_cap_ctxt(conn,\n\t\t\t\t\t     (struct smb2_signing_capabilities *)pctx,\n\t\t\t\t\t     ctxt_len);\n\t\t}\n\n\t\t/* offsets must be 8 byte aligned */\n\t\tclen = (clen + 7) & ~0x7;\n\t\toffset = clen + sizeof(struct smb2_neg_context);\n\t\tlen_of_ctxts -= clen + sizeof(struct smb2_neg_context);\n\t}\n\treturn status;\n}",
        "func_after": "static __le32 deassemble_neg_contexts(struct ksmbd_conn *conn,\n\t\t\t\t      struct smb2_negotiate_req *req,\n\t\t\t\t      unsigned int len_of_smb)\n{\n\t/* +4 is to account for the RFC1001 len field */\n\tstruct smb2_neg_context *pctx = (struct smb2_neg_context *)req;\n\tint i = 0, len_of_ctxts;\n\tunsigned int offset = le32_to_cpu(req->NegotiateContextOffset);\n\tunsigned int neg_ctxt_cnt = le16_to_cpu(req->NegotiateContextCount);\n\t__le32 status = STATUS_INVALID_PARAMETER;\n\n\tksmbd_debug(SMB, \"decoding %d negotiate contexts\\n\", neg_ctxt_cnt);\n\tif (len_of_smb <= offset) {\n\t\tksmbd_debug(SMB, \"Invalid response: negotiate context offset\\n\");\n\t\treturn status;\n\t}\n\n\tlen_of_ctxts = len_of_smb - offset;\n\n\twhile (i++ < neg_ctxt_cnt) {\n\t\tint clen, ctxt_len;\n\n\t\tif (len_of_ctxts < (int)sizeof(struct smb2_neg_context))\n\t\t\tbreak;\n\n\t\tpctx = (struct smb2_neg_context *)((char *)pctx + offset);\n\t\tclen = le16_to_cpu(pctx->DataLength);\n\t\tctxt_len = clen + sizeof(struct smb2_neg_context);\n\n\t\tif (ctxt_len > len_of_ctxts)\n\t\t\tbreak;\n\n\t\tif (pctx->ContextType == SMB2_PREAUTH_INTEGRITY_CAPABILITIES) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_PREAUTH_INTEGRITY_CAPABILITIES context\\n\");\n\t\t\tif (conn->preauth_info->Preauth_HashId)\n\t\t\t\tbreak;\n\n\t\t\tstatus = decode_preauth_ctxt(conn,\n\t\t\t\t\t\t     (struct smb2_preauth_neg_context *)pctx,\n\t\t\t\t\t\t     ctxt_len);\n\t\t\tif (status != STATUS_SUCCESS)\n\t\t\t\tbreak;\n\t\t} else if (pctx->ContextType == SMB2_ENCRYPTION_CAPABILITIES) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_ENCRYPTION_CAPABILITIES context\\n\");\n\t\t\tif (conn->cipher_type)\n\t\t\t\tbreak;\n\n\t\t\tdecode_encrypt_ctxt(conn,\n\t\t\t\t\t    (struct smb2_encryption_neg_context *)pctx,\n\t\t\t\t\t    ctxt_len);\n\t\t} else if (pctx->ContextType == SMB2_COMPRESSION_CAPABILITIES) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_COMPRESSION_CAPABILITIES context\\n\");\n\t\t\tif (conn->compress_algorithm)\n\t\t\t\tbreak;\n\n\t\t\tdecode_compress_ctxt(conn,\n\t\t\t\t\t     (struct smb2_compression_capabilities_context *)pctx);\n\t\t} else if (pctx->ContextType == SMB2_NETNAME_NEGOTIATE_CONTEXT_ID) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_NETNAME_NEGOTIATE_CONTEXT_ID context\\n\");\n\t\t} else if (pctx->ContextType == SMB2_POSIX_EXTENSIONS_AVAILABLE) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_POSIX_EXTENSIONS_AVAILABLE context\\n\");\n\t\t\tconn->posix_ext_supported = true;\n\t\t} else if (pctx->ContextType == SMB2_SIGNING_CAPABILITIES) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_SIGNING_CAPABILITIES context\\n\");\n\n\t\t\tdecode_sign_cap_ctxt(conn,\n\t\t\t\t\t     (struct smb2_signing_capabilities *)pctx,\n\t\t\t\t\t     ctxt_len);\n\t\t}\n\n\t\t/* offsets must be 8 byte aligned */\n\t\toffset = (ctxt_len + 7) & ~0x7;\n\t\tlen_of_ctxts -= offset;\n\t}\n\treturn status;\n}",
        "description": "An issue was discovered in the Linux kernel prior to version 6.3.8. Within the ksmbd component located in the SMB server directory, there is an integer underflow and out-of-bounds read vulnerability in the deassemble_neg_contexts function.",
        "commit": "The vulnerability involves an integer underflow condition in the SMB2 protocol negotiation process within the Linux kernel. Specifically, the initial check compares `clen + sizeof(struct smb2_neg_context)` against `len_of_ctxts`. However, during the loop, `len_of_ctxts` is decremented by `((clen + 7) & ~0x7) + sizeof(struct smb2_neg_context)`, which can lead to an underflow if `clen` undergoes 8-byte alignment. To prevent this, the check should use `(clen + 7) & ~0x7` instead. Additionally, certain variables should be declared as unsigned to avoid similar issues. The vulnerability results in a slab-out-of-bounds read error, as indicated by the kernel log, leading to potential memory corruption and system instability."
    },
    {
        "cwe": "CWE-415",
        "func_name": "fontconfig/FcDirCacheMapFd",
        "score": 0.7753555774688721,
        "func_before": "static FcCache *\nFcDirCacheMapFd (FcConfig *config, int fd, struct stat *fd_stat, struct stat *dir_stat)\n{\n    FcCache\t*cache;\n    FcBool\tallocated = FcFalse;\n\n    if (fd_stat->st_size < (int) sizeof (FcCache))\n\treturn NULL;\n    cache = FcCacheFindByStat (fd_stat);\n    if (cache)\n    {\n\tif (FcCacheTimeValid (config, cache, dir_stat))\n\t    return cache;\n\tFcDirCacheUnload (cache);\n\tcache = NULL;\n    }\n\n    /*\n     * Large cache files are mmap'ed, smaller cache files are read. This\n     * balances the system cost of mmap against per-process memory usage.\n     */\n    if (FcCacheIsMmapSafe (fd) && fd_stat->st_size >= FC_CACHE_MIN_MMAP)\n    {\n#if defined(HAVE_MMAP) || defined(__CYGWIN__)\n\tcache = mmap (0, fd_stat->st_size, PROT_READ, MAP_SHARED, fd, 0);\n#if (HAVE_POSIX_FADVISE) && defined(POSIX_FADV_WILLNEED)\n\tposix_fadvise (fd, 0, fd_stat->st_size, POSIX_FADV_WILLNEED);\n#endif\n\tif (cache == MAP_FAILED)\n\t    cache = NULL;\n#elif defined(_WIN32)\n\t{\n\t    HANDLE hFileMap;\n\n\t    cache = NULL;\n\t    hFileMap = CreateFileMapping((HANDLE) _get_osfhandle(fd), NULL,\n\t\t\t\t\t PAGE_READONLY, 0, 0, NULL);\n\t    if (hFileMap != NULL)\n\t    {\n\t\tcache = MapViewOfFile (hFileMap, FILE_MAP_READ, 0, 0,\n\t\t\t\t       fd_stat->st_size);\n\t\tCloseHandle (hFileMap);\n\t    }\n\t}\n#endif\n    }\n    if (!cache)\n    {\n\tcache = malloc (fd_stat->st_size);\n\tif (!cache)\n\t    return NULL;\n\n\tif (read (fd, cache, fd_stat->st_size) != fd_stat->st_size)\n\t{\n\t    free (cache);\n\t    return NULL;\n\t}\n\tallocated = FcTrue;\n    }\n    if (cache->magic != FC_CACHE_MAGIC_MMAP ||\n\tcache->version < FC_CACHE_VERSION_NUMBER ||\n\tcache->size != (intptr_t) fd_stat->st_size ||\n\t!FcCacheTimeValid (config, cache, dir_stat) ||\n\t!FcCacheInsert (cache, fd_stat))\n    {\n\tif (allocated)\n\t    free (cache);\n\telse\n\t{\n#if defined(HAVE_MMAP) || defined(__CYGWIN__)\n\t    munmap (cache, fd_stat->st_size);\n#elif defined(_WIN32)\n\t    UnmapViewOfFile (cache);\n#endif\n\t}\n\treturn NULL;\n    }\n\n    /* Mark allocated caches so they're freed rather than unmapped */\n    if (allocated)\n\tcache->magic = FC_CACHE_MAGIC_ALLOC;\n\t\n    return cache;\n}",
        "func_after": "static FcCache *\nFcDirCacheMapFd (FcConfig *config, int fd, struct stat *fd_stat, struct stat *dir_stat)\n{\n    FcCache\t*cache;\n    FcBool\tallocated = FcFalse;\n\n    if (fd_stat->st_size > INTPTR_MAX ||\n        fd_stat->st_size < (int) sizeof (FcCache))\n\treturn NULL;\n    cache = FcCacheFindByStat (fd_stat);\n    if (cache)\n    {\n\tif (FcCacheTimeValid (config, cache, dir_stat))\n\t    return cache;\n\tFcDirCacheUnload (cache);\n\tcache = NULL;\n    }\n\n    /*\n     * Large cache files are mmap'ed, smaller cache files are read. This\n     * balances the system cost of mmap against per-process memory usage.\n     */\n    if (FcCacheIsMmapSafe (fd) && fd_stat->st_size >= FC_CACHE_MIN_MMAP)\n    {\n#if defined(HAVE_MMAP) || defined(__CYGWIN__)\n\tcache = mmap (0, fd_stat->st_size, PROT_READ, MAP_SHARED, fd, 0);\n#if (HAVE_POSIX_FADVISE) && defined(POSIX_FADV_WILLNEED)\n\tposix_fadvise (fd, 0, fd_stat->st_size, POSIX_FADV_WILLNEED);\n#endif\n\tif (cache == MAP_FAILED)\n\t    cache = NULL;\n#elif defined(_WIN32)\n\t{\n\t    HANDLE hFileMap;\n\n\t    cache = NULL;\n\t    hFileMap = CreateFileMapping((HANDLE) _get_osfhandle(fd), NULL,\n\t\t\t\t\t PAGE_READONLY, 0, 0, NULL);\n\t    if (hFileMap != NULL)\n\t    {\n\t\tcache = MapViewOfFile (hFileMap, FILE_MAP_READ, 0, 0,\n\t\t\t\t       fd_stat->st_size);\n\t\tCloseHandle (hFileMap);\n\t    }\n\t}\n#endif\n    }\n    if (!cache)\n    {\n\tcache = malloc (fd_stat->st_size);\n\tif (!cache)\n\t    return NULL;\n\n\tif (read (fd, cache, fd_stat->st_size) != fd_stat->st_size)\n\t{\n\t    free (cache);\n\t    return NULL;\n\t}\n\tallocated = FcTrue;\n    }\n    if (cache->magic != FC_CACHE_MAGIC_MMAP ||\n\tcache->version < FC_CACHE_VERSION_NUMBER ||\n\tcache->size != (intptr_t) fd_stat->st_size ||\n        !FcCacheOffsetsValid (cache) ||\n\t!FcCacheTimeValid (config, cache, dir_stat) ||\n\t!FcCacheInsert (cache, fd_stat))\n    {\n\tif (allocated)\n\t    free (cache);\n\telse\n\t{\n#if defined(HAVE_MMAP) || defined(__CYGWIN__)\n\t    munmap (cache, fd_stat->st_size);\n#elif defined(_WIN32)\n\t    UnmapViewOfFile (cache);\n#endif\n\t}\n\treturn NULL;\n    }\n\n    /* Mark allocated caches so they're freed rather than unmapped */\n    if (allocated)\n\tcache->magic = FC_CACHE_MAGIC_ALLOC;\n\t\n    return cache;\n}",
        "description": "Fontconfig versions prior to 2.12.1 do not properly validate offsets, enabling local users to exploit this flaw by crafting a cache file that triggers arbitrary free calls. This can lead to double free vulnerabilities and allow for the execution of arbitrary code.",
        "commit": "The vulnerability involves insufficient validation of cache files, specifically regarding the contained offsets and pointers. Despite checking the magic number and timestamps, the validation process does not ensure that offsets are within legal ranges or are valid pointers. This lack of validation enables attackers to trigger arbitrary `free()` calls, leading to double free attacks and potentially arbitrary code execution. The conversion of offsets to pointers through macros also allows attackers to bypass Address Space Layout Randomization (ASLR) protections. This attack vector can lead to privilege escalation, particularly when exploiting setuid binaries like `fbterm`. Users can exploit this by creating or modifying cache files in user-private directories, which setuid binaries then scan, making them vulnerable to such attacks. Additionally, the vulnerability can cause endless loops by creating circular linked lists. The patch addresses these issues by ensuring that:\n\n- The file size does not exceed the maximum addressable space, primarily affecting 32-bit systems.\n- Offsets are non-negative and within file boundaries.\n- Cache files do not contain pointers; all \"pointer or offset\" fields must be offsets or NULL.\n- Linked list iteration does not exceed the specified number of elements, preventing endless loops.\n\nIf any of these conditions are violated, the cache is recreated. Although this patch resolves many issues, it does not address the problem of using `mmap()` in setuid binaries, as it is impossible to guarantee that malicious users will not alter cache files after verification. Handling this aspect should be addressed in a separate patch."
    },
    {
        "cwe": "CWE-193",
        "func_name": "torvalds/ext4_ext_insert_extent",
        "score": 0.7896609902381897,
        "func_before": "int ext4_ext_insert_extent(handle_t *handle, struct inode *inode,\n\t\t\t\tstruct ext4_ext_path *path,\n\t\t\t\tstruct ext4_extent *newext, int flag)\n{\n\tstruct ext4_extent_header *eh;\n\tstruct ext4_extent *ex, *fex;\n\tstruct ext4_extent *nearex; /* nearest extent */\n\tstruct ext4_ext_path *npath = NULL;\n\tint depth, len, err;\n\text4_lblk_t next;\n\tunsigned uninitialized = 0;\n\tint flags = 0;\n\n\tif (unlikely(ext4_ext_get_actual_len(newext) == 0)) {\n\t\tEXT4_ERROR_INODE(inode, \"ext4_ext_get_actual_len(newext) == 0\");\n\t\treturn -EIO;\n\t}\n\tdepth = ext_depth(inode);\n\tex = path[depth].p_ext;\n\tif (unlikely(path[depth].p_hdr == NULL)) {\n\t\tEXT4_ERROR_INODE(inode, \"path[%d].p_hdr == NULL\", depth);\n\t\treturn -EIO;\n\t}\n\n\t/* try to insert block into found extent and return */\n\tif (ex && !(flag & EXT4_GET_BLOCKS_PRE_IO)\n\t\t&& ext4_can_extents_be_merged(inode, ex, newext)) {\n\t\text_debug(\"append [%d]%d block to %d:[%d]%d (from %llu)\\n\",\n\t\t\t  ext4_ext_is_uninitialized(newext),\n\t\t\t  ext4_ext_get_actual_len(newext),\n\t\t\t  le32_to_cpu(ex->ee_block),\n\t\t\t  ext4_ext_is_uninitialized(ex),\n\t\t\t  ext4_ext_get_actual_len(ex),\n\t\t\t  ext4_ext_pblock(ex));\n\t\terr = ext4_ext_get_access(handle, inode, path + depth);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\t/*\n\t\t * ext4_can_extents_be_merged should have checked that either\n\t\t * both extents are uninitialized, or both aren't. Thus we\n\t\t * need to check only one of them here.\n\t\t */\n\t\tif (ext4_ext_is_uninitialized(ex))\n\t\t\tuninitialized = 1;\n\t\tex->ee_len = cpu_to_le16(ext4_ext_get_actual_len(ex)\n\t\t\t\t\t+ ext4_ext_get_actual_len(newext));\n\t\tif (uninitialized)\n\t\t\text4_ext_mark_uninitialized(ex);\n\t\teh = path[depth].p_hdr;\n\t\tnearex = ex;\n\t\tgoto merge;\n\t}\n\nrepeat:\n\tdepth = ext_depth(inode);\n\teh = path[depth].p_hdr;\n\tif (le16_to_cpu(eh->eh_entries) < le16_to_cpu(eh->eh_max))\n\t\tgoto has_space;\n\n\t/* probably next leaf has space for us? */\n\tfex = EXT_LAST_EXTENT(eh);\n\tnext = ext4_ext_next_leaf_block(inode, path);\n\tif (le32_to_cpu(newext->ee_block) > le32_to_cpu(fex->ee_block)\n\t    && next != EXT_MAX_BLOCK) {\n\t\text_debug(\"next leaf block - %d\\n\", next);\n\t\tBUG_ON(npath != NULL);\n\t\tnpath = ext4_ext_find_extent(inode, next, NULL);\n\t\tif (IS_ERR(npath))\n\t\t\treturn PTR_ERR(npath);\n\t\tBUG_ON(npath->p_depth != path->p_depth);\n\t\teh = npath[depth].p_hdr;\n\t\tif (le16_to_cpu(eh->eh_entries) < le16_to_cpu(eh->eh_max)) {\n\t\t\text_debug(\"next leaf isn't full(%d)\\n\",\n\t\t\t\t  le16_to_cpu(eh->eh_entries));\n\t\t\tpath = npath;\n\t\t\tgoto repeat;\n\t\t}\n\t\text_debug(\"next leaf has no free space(%d,%d)\\n\",\n\t\t\t  le16_to_cpu(eh->eh_entries), le16_to_cpu(eh->eh_max));\n\t}\n\n\t/*\n\t * There is no free space in the found leaf.\n\t * We're gonna add a new leaf in the tree.\n\t */\n\tif (flag & EXT4_GET_BLOCKS_PUNCH_OUT_EXT)\n\t\tflags = EXT4_MB_USE_ROOT_BLOCKS;\n\terr = ext4_ext_create_new_leaf(handle, inode, flags, path, newext);\n\tif (err)\n\t\tgoto cleanup;\n\tdepth = ext_depth(inode);\n\teh = path[depth].p_hdr;\n\nhas_space:\n\tnearex = path[depth].p_ext;\n\n\terr = ext4_ext_get_access(handle, inode, path + depth);\n\tif (err)\n\t\tgoto cleanup;\n\n\tif (!nearex) {\n\t\t/* there is no extent in this leaf, create first one */\n\t\text_debug(\"first extent in the leaf: %d:%llu:[%d]%d\\n\",\n\t\t\t\tle32_to_cpu(newext->ee_block),\n\t\t\t\text4_ext_pblock(newext),\n\t\t\t\text4_ext_is_uninitialized(newext),\n\t\t\t\text4_ext_get_actual_len(newext));\n\t\tpath[depth].p_ext = EXT_FIRST_EXTENT(eh);\n\t} else if (le32_to_cpu(newext->ee_block)\n\t\t\t   > le32_to_cpu(nearex->ee_block)) {\n/*\t\tBUG_ON(newext->ee_block == nearex->ee_block); */\n\t\tif (nearex != EXT_LAST_EXTENT(eh)) {\n\t\t\tlen = EXT_MAX_EXTENT(eh) - nearex;\n\t\t\tlen = (len - 1) * sizeof(struct ext4_extent);\n\t\t\tlen = len < 0 ? 0 : len;\n\t\t\text_debug(\"insert %d:%llu:[%d]%d after: nearest 0x%p, \"\n\t\t\t\t\t\"move %d from 0x%p to 0x%p\\n\",\n\t\t\t\t\tle32_to_cpu(newext->ee_block),\n\t\t\t\t\text4_ext_pblock(newext),\n\t\t\t\t\text4_ext_is_uninitialized(newext),\n\t\t\t\t\text4_ext_get_actual_len(newext),\n\t\t\t\t\tnearex, len, nearex + 1, nearex + 2);\n\t\t\tmemmove(nearex + 2, nearex + 1, len);\n\t\t}\n\t\tpath[depth].p_ext = nearex + 1;\n\t} else {\n\t\tBUG_ON(newext->ee_block == nearex->ee_block);\n\t\tlen = (EXT_MAX_EXTENT(eh) - nearex) * sizeof(struct ext4_extent);\n\t\tlen = len < 0 ? 0 : len;\n\t\text_debug(\"insert %d:%llu:[%d]%d before: nearest 0x%p, \"\n\t\t\t\t\"move %d from 0x%p to 0x%p\\n\",\n\t\t\t\tle32_to_cpu(newext->ee_block),\n\t\t\t\text4_ext_pblock(newext),\n\t\t\t\text4_ext_is_uninitialized(newext),\n\t\t\t\text4_ext_get_actual_len(newext),\n\t\t\t\tnearex, len, nearex + 1, nearex + 2);\n\t\tmemmove(nearex + 1, nearex, len);\n\t\tpath[depth].p_ext = nearex;\n\t}\n\n\tle16_add_cpu(&eh->eh_entries, 1);\n\tnearex = path[depth].p_ext;\n\tnearex->ee_block = newext->ee_block;\n\text4_ext_store_pblock(nearex, ext4_ext_pblock(newext));\n\tnearex->ee_len = newext->ee_len;\n\nmerge:\n\t/* try to merge extents to the right */\n\tif (!(flag & EXT4_GET_BLOCKS_PRE_IO))\n\t\text4_ext_try_to_merge(inode, path, nearex);\n\n\t/* try to merge extents to the left */\n\n\t/* time to correct all indexes above */\n\terr = ext4_ext_correct_indexes(handle, inode, path);\n\tif (err)\n\t\tgoto cleanup;\n\n\terr = ext4_ext_dirty(handle, inode, path + depth);\n\ncleanup:\n\tif (npath) {\n\t\text4_ext_drop_refs(npath);\n\t\tkfree(npath);\n\t}\n\text4_ext_invalidate_cache(inode);\n\treturn err;\n}",
        "func_after": "int ext4_ext_insert_extent(handle_t *handle, struct inode *inode,\n\t\t\t\tstruct ext4_ext_path *path,\n\t\t\t\tstruct ext4_extent *newext, int flag)\n{\n\tstruct ext4_extent_header *eh;\n\tstruct ext4_extent *ex, *fex;\n\tstruct ext4_extent *nearex; /* nearest extent */\n\tstruct ext4_ext_path *npath = NULL;\n\tint depth, len, err;\n\text4_lblk_t next;\n\tunsigned uninitialized = 0;\n\tint flags = 0;\n\n\tif (unlikely(ext4_ext_get_actual_len(newext) == 0)) {\n\t\tEXT4_ERROR_INODE(inode, \"ext4_ext_get_actual_len(newext) == 0\");\n\t\treturn -EIO;\n\t}\n\tdepth = ext_depth(inode);\n\tex = path[depth].p_ext;\n\tif (unlikely(path[depth].p_hdr == NULL)) {\n\t\tEXT4_ERROR_INODE(inode, \"path[%d].p_hdr == NULL\", depth);\n\t\treturn -EIO;\n\t}\n\n\t/* try to insert block into found extent and return */\n\tif (ex && !(flag & EXT4_GET_BLOCKS_PRE_IO)\n\t\t&& ext4_can_extents_be_merged(inode, ex, newext)) {\n\t\text_debug(\"append [%d]%d block to %d:[%d]%d (from %llu)\\n\",\n\t\t\t  ext4_ext_is_uninitialized(newext),\n\t\t\t  ext4_ext_get_actual_len(newext),\n\t\t\t  le32_to_cpu(ex->ee_block),\n\t\t\t  ext4_ext_is_uninitialized(ex),\n\t\t\t  ext4_ext_get_actual_len(ex),\n\t\t\t  ext4_ext_pblock(ex));\n\t\terr = ext4_ext_get_access(handle, inode, path + depth);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\t/*\n\t\t * ext4_can_extents_be_merged should have checked that either\n\t\t * both extents are uninitialized, or both aren't. Thus we\n\t\t * need to check only one of them here.\n\t\t */\n\t\tif (ext4_ext_is_uninitialized(ex))\n\t\t\tuninitialized = 1;\n\t\tex->ee_len = cpu_to_le16(ext4_ext_get_actual_len(ex)\n\t\t\t\t\t+ ext4_ext_get_actual_len(newext));\n\t\tif (uninitialized)\n\t\t\text4_ext_mark_uninitialized(ex);\n\t\teh = path[depth].p_hdr;\n\t\tnearex = ex;\n\t\tgoto merge;\n\t}\n\nrepeat:\n\tdepth = ext_depth(inode);\n\teh = path[depth].p_hdr;\n\tif (le16_to_cpu(eh->eh_entries) < le16_to_cpu(eh->eh_max))\n\t\tgoto has_space;\n\n\t/* probably next leaf has space for us? */\n\tfex = EXT_LAST_EXTENT(eh);\n\tnext = ext4_ext_next_leaf_block(inode, path);\n\tif (le32_to_cpu(newext->ee_block) > le32_to_cpu(fex->ee_block)\n\t    && next != EXT_MAX_BLOCKS) {\n\t\text_debug(\"next leaf block - %d\\n\", next);\n\t\tBUG_ON(npath != NULL);\n\t\tnpath = ext4_ext_find_extent(inode, next, NULL);\n\t\tif (IS_ERR(npath))\n\t\t\treturn PTR_ERR(npath);\n\t\tBUG_ON(npath->p_depth != path->p_depth);\n\t\teh = npath[depth].p_hdr;\n\t\tif (le16_to_cpu(eh->eh_entries) < le16_to_cpu(eh->eh_max)) {\n\t\t\text_debug(\"next leaf isn't full(%d)\\n\",\n\t\t\t\t  le16_to_cpu(eh->eh_entries));\n\t\t\tpath = npath;\n\t\t\tgoto repeat;\n\t\t}\n\t\text_debug(\"next leaf has no free space(%d,%d)\\n\",\n\t\t\t  le16_to_cpu(eh->eh_entries), le16_to_cpu(eh->eh_max));\n\t}\n\n\t/*\n\t * There is no free space in the found leaf.\n\t * We're gonna add a new leaf in the tree.\n\t */\n\tif (flag & EXT4_GET_BLOCKS_PUNCH_OUT_EXT)\n\t\tflags = EXT4_MB_USE_ROOT_BLOCKS;\n\terr = ext4_ext_create_new_leaf(handle, inode, flags, path, newext);\n\tif (err)\n\t\tgoto cleanup;\n\tdepth = ext_depth(inode);\n\teh = path[depth].p_hdr;\n\nhas_space:\n\tnearex = path[depth].p_ext;\n\n\terr = ext4_ext_get_access(handle, inode, path + depth);\n\tif (err)\n\t\tgoto cleanup;\n\n\tif (!nearex) {\n\t\t/* there is no extent in this leaf, create first one */\n\t\text_debug(\"first extent in the leaf: %d:%llu:[%d]%d\\n\",\n\t\t\t\tle32_to_cpu(newext->ee_block),\n\t\t\t\text4_ext_pblock(newext),\n\t\t\t\text4_ext_is_uninitialized(newext),\n\t\t\t\text4_ext_get_actual_len(newext));\n\t\tpath[depth].p_ext = EXT_FIRST_EXTENT(eh);\n\t} else if (le32_to_cpu(newext->ee_block)\n\t\t\t   > le32_to_cpu(nearex->ee_block)) {\n/*\t\tBUG_ON(newext->ee_block == nearex->ee_block); */\n\t\tif (nearex != EXT_LAST_EXTENT(eh)) {\n\t\t\tlen = EXT_MAX_EXTENT(eh) - nearex;\n\t\t\tlen = (len - 1) * sizeof(struct ext4_extent);\n\t\t\tlen = len < 0 ? 0 : len;\n\t\t\text_debug(\"insert %d:%llu:[%d]%d after: nearest 0x%p, \"\n\t\t\t\t\t\"move %d from 0x%p to 0x%p\\n\",\n\t\t\t\t\tle32_to_cpu(newext->ee_block),\n\t\t\t\t\text4_ext_pblock(newext),\n\t\t\t\t\text4_ext_is_uninitialized(newext),\n\t\t\t\t\text4_ext_get_actual_len(newext),\n\t\t\t\t\tnearex, len, nearex + 1, nearex + 2);\n\t\t\tmemmove(nearex + 2, nearex + 1, len);\n\t\t}\n\t\tpath[depth].p_ext = nearex + 1;\n\t} else {\n\t\tBUG_ON(newext->ee_block == nearex->ee_block);\n\t\tlen = (EXT_MAX_EXTENT(eh) - nearex) * sizeof(struct ext4_extent);\n\t\tlen = len < 0 ? 0 : len;\n\t\text_debug(\"insert %d:%llu:[%d]%d before: nearest 0x%p, \"\n\t\t\t\t\"move %d from 0x%p to 0x%p\\n\",\n\t\t\t\tle32_to_cpu(newext->ee_block),\n\t\t\t\text4_ext_pblock(newext),\n\t\t\t\text4_ext_is_uninitialized(newext),\n\t\t\t\text4_ext_get_actual_len(newext),\n\t\t\t\tnearex, len, nearex + 1, nearex + 2);\n\t\tmemmove(nearex + 1, nearex, len);\n\t\tpath[depth].p_ext = nearex;\n\t}\n\n\tle16_add_cpu(&eh->eh_entries, 1);\n\tnearex = path[depth].p_ext;\n\tnearex->ee_block = newext->ee_block;\n\text4_ext_store_pblock(nearex, ext4_ext_pblock(newext));\n\tnearex->ee_len = newext->ee_len;\n\nmerge:\n\t/* try to merge extents to the right */\n\tif (!(flag & EXT4_GET_BLOCKS_PRE_IO))\n\t\text4_ext_try_to_merge(inode, path, nearex);\n\n\t/* try to merge extents to the left */\n\n\t/* time to correct all indexes above */\n\terr = ext4_ext_correct_indexes(handle, inode, path);\n\tif (err)\n\t\tgoto cleanup;\n\n\terr = ext4_ext_dirty(handle, inode, path + depth);\n\ncleanup:\n\tif (npath) {\n\t\text4_ext_drop_refs(npath);\n\t\tkfree(npath);\n\t}\n\text4_ext_invalidate_cache(inode);\n\treturn err;\n}",
        "description": "Multiple off-by-one errors in the ext4 subsystem of the Linux kernel, prior to a specific release candidate, enable local users to trigger a denial of service (resulting in BUG_ON and system crashes) through write operations on sparse files in extent format, particularly when the block number corresponds to the maximum possible 32-bit unsigned integer.",
        "commit": "A vulnerability was identified in the ext4 file system where writing to the last block (2^32-1) of a sparse file in extent format triggers a BUG_ON condition in the ext4_ext_put_gap_in_cache() function. The root cause is that the maximum bytes (s_maxbytes) are set such that the block at s_maxbytes fits into a 32-bit on-disk extent format, but the extent structure stores start block number and length in blocks, requiring EXT_MAX_BLOCK + 1 to cover the entire extent range. To resolve this issue without altering the struct ext4_extent members' meanings, s_maxbytes should be reduced by one filesystem block. Additionally, the commit renames EXT_MAX_BLOCK to EXT_MAX_BLOCKS and adjusts its usage to represent the maximum number of blocks in an extent, addressing inconsistencies in its application throughout the codebase. This bug can be reproduced by sequentially writing to the second-to-last and last blocks of a sparse file using the dd command."
    },
    {
        "cwe": "CWE-369",
        "func_name": "upx/PackLinuxElf64::elf_lookup",
        "score": 0.7796072959899902,
        "func_before": "Elf64_Sym const *PackLinuxElf64__elf_lookup(char const *name) const\n{\n    if (hashtab && dynsym && dynstr) {\n        unsigned const nbucket = get_te32(&hashtab[0]);\n        unsigned const *const buckets = &hashtab[2];\n        unsigned const *const chains = &buckets[nbucket];\n        unsigned const m = elf_hash(name) % nbucket;\n        if (!nbucket\n        ||  (unsigned)(file_size - ((char const *)buckets - (char const *)(void const *)file_image))\n                <= sizeof(unsigned)*nbucket ) {\n            char msg[80]; snprintf(msg, sizeof(msg),\n                \"bad nbucket %#x\\n\", nbucket);\n            throwCantPack(msg);\n        }\n        unsigned si;\n        for (si= get_te32(&buckets[m]); 0!=si; si= get_te32(&chains[si])) {\n            char const *const p= get_dynsym_name(si, (unsigned)-1);\n            if (0==strcmp(name, p)) {\n                return &dynsym[si];\n            }\n        }\n    }\n    if (gashtab && dynsym && dynstr) {\n        unsigned const n_bucket = get_te32(&gashtab[0]);\n        unsigned const symbias  = get_te32(&gashtab[1]);\n        unsigned const n_bitmask = get_te32(&gashtab[2]);\n        unsigned const gnu_shift = get_te32(&gashtab[3]);\n        upx_uint64_t const *const bitmask = (upx_uint64_t const *)(void const *)&gashtab[4];\n        unsigned     const *const buckets = (unsigned const *)&bitmask[n_bitmask];\n        unsigned     const *const hasharr = &buckets[n_bucket];\n        if (!n_bucket\n        || (void const *)&file_image[file_size] <= (void const *)hasharr) {\n            char msg[80]; snprintf(msg, sizeof(msg),\n                \"bad n_bucket %#x\\n\", n_bucket);\n            throwCantPack(msg);\n        }\n        if (!n_bitmask\n        || (unsigned)(file_size - ((char const *)bitmask - (char const *)(void const *)file_image))\n                <= sizeof(unsigned)*n_bitmask ) {\n            char msg[80]; snprintf(msg, sizeof(msg),\n                \"bad n_bitmask %#x\\n\", n_bitmask);\n            throwCantPack(msg);\n        }\n\n        unsigned const h = gnu_hash(name);\n        unsigned const hbit1 = 077& h;\n        unsigned const hbit2 = 077& (h>>gnu_shift);\n        upx_uint64_t const w = get_te64(&bitmask[(n_bitmask -1) & (h>>6)]);\n\n        if (1& (w>>hbit1) & (w>>hbit2)) {\n            unsigned bucket = get_te32(&buckets[h % n_bucket]);\n            if (n_bucket <= bucket) {\n                char msg[80]; snprintf(msg, sizeof(msg),\n                        \"bad DT_GNU_HASH n_bucket{%#x} <= buckets[%d]{%#x}\\n\",\n                        n_bucket, h % n_bucket, bucket);\n                throwCantPack(msg);\n            }\n            if (0!=bucket) {\n                Elf64_Sym const *dsp = &dynsym[bucket];\n                unsigned const *hp = &hasharr[bucket - symbias];\n\n                do if (0==((h ^ get_te32(hp))>>1)) {\n                    unsigned st_name = get_te32(&dsp->st_name);\n                    char const *const p = get_str_name(st_name, (unsigned)-1);\n                    if (0==strcmp(name, p)) {\n                        return dsp;\n                    }\n                } while (++dsp,\n                        (char const *)hp < (char const *)&file_image[file_size]\n                    &&  0==(1u& get_te32(hp++)));\n            }\n        }\n    }\n    return 0;\n\n}",
        "func_after": "Elf64_Sym const *PackLinuxElf64__elf_lookup(char const *name) const\n{\n    if (hashtab && dynsym && dynstr) {\n        unsigned const nbucket = get_te32(&hashtab[0]);\n        unsigned const *const buckets = &hashtab[2];\n        unsigned const *const chains = &buckets[nbucket];\n        if (!nbucket\n        ||  (unsigned)(file_size - ((char const *)buckets - (char const *)(void const *)file_image))\n                <= sizeof(unsigned)*nbucket ) {\n            char msg[80]; snprintf(msg, sizeof(msg),\n                \"bad nbucket %#x\\n\", nbucket);\n            throwCantPack(msg);\n        }\n        unsigned const m = elf_hash(name) % nbucket;\n        unsigned si;\n        for (si= get_te32(&buckets[m]); 0!=si; si= get_te32(&chains[si])) {\n            char const *const p= get_dynsym_name(si, (unsigned)-1);\n            if (0==strcmp(name, p)) {\n                return &dynsym[si];\n            }\n        }\n    }\n    if (gashtab && dynsym && dynstr) {\n        unsigned const n_bucket = get_te32(&gashtab[0]);\n        unsigned const symbias  = get_te32(&gashtab[1]);\n        unsigned const n_bitmask = get_te32(&gashtab[2]);\n        unsigned const gnu_shift = get_te32(&gashtab[3]);\n        upx_uint64_t const *const bitmask = (upx_uint64_t const *)(void const *)&gashtab[4];\n        unsigned     const *const buckets = (unsigned const *)&bitmask[n_bitmask];\n        unsigned     const *const hasharr = &buckets[n_bucket];\n        if (!n_bucket\n        || (void const *)&file_image[file_size] <= (void const *)hasharr) {\n            char msg[80]; snprintf(msg, sizeof(msg),\n                \"bad n_bucket %#x\\n\", n_bucket);\n            throwCantPack(msg);\n        }\n        if (!n_bitmask\n        || (unsigned)(file_size - ((char const *)bitmask - (char const *)(void const *)file_image))\n                <= sizeof(unsigned)*n_bitmask ) {\n            char msg[80]; snprintf(msg, sizeof(msg),\n                \"bad n_bitmask %#x\\n\", n_bitmask);\n            throwCantPack(msg);\n        }\n\n        unsigned const h = gnu_hash(name);\n        unsigned const hbit1 = 077& h;\n        unsigned const hbit2 = 077& (h>>gnu_shift);\n        upx_uint64_t const w = get_te64(&bitmask[(n_bitmask -1) & (h>>6)]);\n\n        if (1& (w>>hbit1) & (w>>hbit2)) {\n            unsigned bucket = get_te32(&buckets[h % n_bucket]);\n            if (n_bucket <= bucket) {\n                char msg[80]; snprintf(msg, sizeof(msg),\n                        \"bad DT_GNU_HASH n_bucket{%#x} <= buckets[%d]{%#x}\\n\",\n                        n_bucket, h % n_bucket, bucket);\n                throwCantPack(msg);\n            }\n            if (0!=bucket) {\n                Elf64_Sym const *dsp = &dynsym[bucket];\n                unsigned const *hp = &hasharr[bucket - symbias];\n\n                do if (0==((h ^ get_te32(hp))>>1)) {\n                    unsigned st_name = get_te32(&dsp->st_name);\n                    char const *const p = get_str_name(st_name, (unsigned)-1);\n                    if (0==strcmp(name, p)) {\n                        return dsp;\n                    }\n                } while (++dsp,\n                        (char const *)hp < (char const *)&file_image[file_size]\n                    &&  0==(1u& get_te32(hp++)));\n            }\n        }\n    }\n    return 0;\n\n}",
        "description": "An floating point exception was discovered in the elf_lookup function within the UPX decompression utility, specifically in version 4.0.0, when processing a specially crafted Mach-O file.",
        "commit": "It was identified that there is a need to avoid setting `nbucket` to zero in the UPX compression tool, as indicated by an issue reported in the GitHub repository. This modification was made in the `p_lx_elf.cpp` file."
    },
    {
        "cwe": "CWE-662",
        "func_name": "torvalds/do_fontx_ioctl",
        "score": 0.7612249255180359,
        "func_before": "static inline int do_fontx_ioctl(int cmd,\n\t\tstruct consolefontdesc __user *user_cfd,\n\t\tstruct console_font_op *op)\n{\n\tstruct consolefontdesc cfdarg;\n\tint i;\n\n\tif (copy_from_user(&cfdarg, user_cfd, sizeof(struct consolefontdesc)))\n\t\treturn -EFAULT;\n\n\tswitch (cmd) {\n\tcase PIO_FONTX:\n\t\top->op = KD_FONT_OP_SET;\n\t\top->flags = KD_FONT_FLAG_OLD;\n\t\top->width = 8;\n\t\top->height = cfdarg.charheight;\n\t\top->charcount = cfdarg.charcount;\n\t\top->data = cfdarg.chardata;\n\t\treturn con_font_op(vc_cons[fg_console].d, op);\n\tcase GIO_FONTX: {\n\t\top->op = KD_FONT_OP_GET;\n\t\top->flags = KD_FONT_FLAG_OLD;\n\t\top->width = 8;\n\t\top->height = cfdarg.charheight;\n\t\top->charcount = cfdarg.charcount;\n\t\top->data = cfdarg.chardata;\n\t\ti = con_font_op(vc_cons[fg_console].d, op);\n\t\tif (i)\n\t\t\treturn i;\n\t\tcfdarg.charheight = op->height;\n\t\tcfdarg.charcount = op->charcount;\n\t\tif (copy_to_user(user_cfd, &cfdarg, sizeof(struct consolefontdesc)))\n\t\t\treturn -EFAULT;\n\t\treturn 0;\n\t\t}\n\t}\n\treturn -EINVAL;\n}",
        "func_after": "static inline int do_fontx_ioctl(struct vc_data *vc, int cmd,\n\t\tstruct consolefontdesc __user *user_cfd,\n\t\tstruct console_font_op *op)\n{\n\tstruct consolefontdesc cfdarg;\n\tint i;\n\n\tif (copy_from_user(&cfdarg, user_cfd, sizeof(struct consolefontdesc)))\n\t\treturn -EFAULT;\n\n\tswitch (cmd) {\n\tcase PIO_FONTX:\n\t\top->op = KD_FONT_OP_SET;\n\t\top->flags = KD_FONT_FLAG_OLD;\n\t\top->width = 8;\n\t\top->height = cfdarg.charheight;\n\t\top->charcount = cfdarg.charcount;\n\t\top->data = cfdarg.chardata;\n\t\treturn con_font_op(vc, op);\n\n\tcase GIO_FONTX:\n\t\top->op = KD_FONT_OP_GET;\n\t\top->flags = KD_FONT_FLAG_OLD;\n\t\top->width = 8;\n\t\top->height = cfdarg.charheight;\n\t\top->charcount = cfdarg.charcount;\n\t\top->data = cfdarg.chardata;\n\t\ti = con_font_op(vc, op);\n\t\tif (i)\n\t\t\treturn i;\n\t\tcfdarg.charheight = op->height;\n\t\tcfdarg.charcount = op->charcount;\n\t\tif (copy_to_user(user_cfd, &cfdarg, sizeof(struct consolefontdesc)))\n\t\t\treturn -EFAULT;\n\t\treturn 0;\n\t}\n\treturn -EINVAL;\n}",
        "description": "A flaw was identified in the Linux Kernel where access to a global variable used for managing the foreground console is not adequately synchronized, resulting in a use-after-free error within the function responsible for font operations.",
        "commit": "Some font-related terminal I/O control operations previously utilized the current foreground virtual console (VC) for their execution. This practice has been discontinued to address a data race condition involving the `fg_console` variable. Notably, both Michael Ellerman and Jiri Slaby have observed that these I/O control operations are deprecated and should have been removed earlier. They suggest that most systems now use the `KDFONTOP` ioctl instead. Additionally, Michael notes that BusyBox's `loadfont` program transitioned to using `KDFONTOP` precisely due to this bug, which was identified approximately 12 years ago."
    }
]