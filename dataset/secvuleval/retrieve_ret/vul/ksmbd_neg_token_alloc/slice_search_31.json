[
    {
        "cwe": "CWE-191",
        "func_name": "torvalds/deassemble_neg_contexts",
        "score": 0.8132514357566833,
        "func_before": "static __le32 deassemble_neg_contexts(struct ksmbd_conn *conn,\n\t\t\t\t      struct smb2_negotiate_req *req,\n\t\t\t\t      int len_of_smb)\n{\n\t/* +4 is to account for the RFC1001 len field */\n\tstruct smb2_neg_context *pctx = (struct smb2_neg_context *)req;\n\tint i = 0, len_of_ctxts;\n\tint offset = le32_to_cpu(req->NegotiateContextOffset);\n\tint neg_ctxt_cnt = le16_to_cpu(req->NegotiateContextCount);\n\t__le32 status = STATUS_INVALID_PARAMETER;\n\n\tksmbd_debug(SMB, \"decoding %d negotiate contexts\\n\", neg_ctxt_cnt);\n\tif (len_of_smb <= offset) {\n\t\tksmbd_debug(SMB, \"Invalid response: negotiate context offset\\n\");\n\t\treturn status;\n\t}\n\n\tlen_of_ctxts = len_of_smb - offset;\n\n\twhile (i++ < neg_ctxt_cnt) {\n\t\tint clen, ctxt_len;\n\n\t\tif (len_of_ctxts < sizeof(struct smb2_neg_context))\n\t\t\tbreak;\n\n\t\tpctx = (struct smb2_neg_context *)((char *)pctx + offset);\n\t\tclen = le16_to_cpu(pctx->DataLength);\n\t\tctxt_len = clen + sizeof(struct smb2_neg_context);\n\n\t\tif (ctxt_len > len_of_ctxts)\n\t\t\tbreak;\n\n\t\tif (pctx->ContextType == SMB2_PREAUTH_INTEGRITY_CAPABILITIES) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_PREAUTH_INTEGRITY_CAPABILITIES context\\n\");\n\t\t\tif (conn->preauth_info->Preauth_HashId)\n\t\t\t\tbreak;\n\n\t\t\tstatus = decode_preauth_ctxt(conn,\n\t\t\t\t\t\t     (struct smb2_preauth_neg_context *)pctx,\n\t\t\t\t\t\t     ctxt_len);\n\t\t\tif (status != STATUS_SUCCESS)\n\t\t\t\tbreak;\n\t\t} else if (pctx->ContextType == SMB2_ENCRYPTION_CAPABILITIES) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_ENCRYPTION_CAPABILITIES context\\n\");\n\t\t\tif (conn->cipher_type)\n\t\t\t\tbreak;\n\n\t\t\tdecode_encrypt_ctxt(conn,\n\t\t\t\t\t    (struct smb2_encryption_neg_context *)pctx,\n\t\t\t\t\t    ctxt_len);\n\t\t} else if (pctx->ContextType == SMB2_COMPRESSION_CAPABILITIES) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_COMPRESSION_CAPABILITIES context\\n\");\n\t\t\tif (conn->compress_algorithm)\n\t\t\t\tbreak;\n\n\t\t\tdecode_compress_ctxt(conn,\n\t\t\t\t\t     (struct smb2_compression_capabilities_context *)pctx);\n\t\t} else if (pctx->ContextType == SMB2_NETNAME_NEGOTIATE_CONTEXT_ID) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_NETNAME_NEGOTIATE_CONTEXT_ID context\\n\");\n\t\t} else if (pctx->ContextType == SMB2_POSIX_EXTENSIONS_AVAILABLE) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_POSIX_EXTENSIONS_AVAILABLE context\\n\");\n\t\t\tconn->posix_ext_supported = true;\n\t\t} else if (pctx->ContextType == SMB2_SIGNING_CAPABILITIES) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_SIGNING_CAPABILITIES context\\n\");\n\n\t\t\tdecode_sign_cap_ctxt(conn,\n\t\t\t\t\t     (struct smb2_signing_capabilities *)pctx,\n\t\t\t\t\t     ctxt_len);\n\t\t}\n\n\t\t/* offsets must be 8 byte aligned */\n\t\tclen = (clen + 7) & ~0x7;\n\t\toffset = clen + sizeof(struct smb2_neg_context);\n\t\tlen_of_ctxts -= clen + sizeof(struct smb2_neg_context);\n\t}\n\treturn status;\n}",
        "func_after": "static __le32 deassemble_neg_contexts(struct ksmbd_conn *conn,\n\t\t\t\t      struct smb2_negotiate_req *req,\n\t\t\t\t      unsigned int len_of_smb)\n{\n\t/* +4 is to account for the RFC1001 len field */\n\tstruct smb2_neg_context *pctx = (struct smb2_neg_context *)req;\n\tint i = 0, len_of_ctxts;\n\tunsigned int offset = le32_to_cpu(req->NegotiateContextOffset);\n\tunsigned int neg_ctxt_cnt = le16_to_cpu(req->NegotiateContextCount);\n\t__le32 status = STATUS_INVALID_PARAMETER;\n\n\tksmbd_debug(SMB, \"decoding %d negotiate contexts\\n\", neg_ctxt_cnt);\n\tif (len_of_smb <= offset) {\n\t\tksmbd_debug(SMB, \"Invalid response: negotiate context offset\\n\");\n\t\treturn status;\n\t}\n\n\tlen_of_ctxts = len_of_smb - offset;\n\n\twhile (i++ < neg_ctxt_cnt) {\n\t\tint clen, ctxt_len;\n\n\t\tif (len_of_ctxts < (int)sizeof(struct smb2_neg_context))\n\t\t\tbreak;\n\n\t\tpctx = (struct smb2_neg_context *)((char *)pctx + offset);\n\t\tclen = le16_to_cpu(pctx->DataLength);\n\t\tctxt_len = clen + sizeof(struct smb2_neg_context);\n\n\t\tif (ctxt_len > len_of_ctxts)\n\t\t\tbreak;\n\n\t\tif (pctx->ContextType == SMB2_PREAUTH_INTEGRITY_CAPABILITIES) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_PREAUTH_INTEGRITY_CAPABILITIES context\\n\");\n\t\t\tif (conn->preauth_info->Preauth_HashId)\n\t\t\t\tbreak;\n\n\t\t\tstatus = decode_preauth_ctxt(conn,\n\t\t\t\t\t\t     (struct smb2_preauth_neg_context *)pctx,\n\t\t\t\t\t\t     ctxt_len);\n\t\t\tif (status != STATUS_SUCCESS)\n\t\t\t\tbreak;\n\t\t} else if (pctx->ContextType == SMB2_ENCRYPTION_CAPABILITIES) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_ENCRYPTION_CAPABILITIES context\\n\");\n\t\t\tif (conn->cipher_type)\n\t\t\t\tbreak;\n\n\t\t\tdecode_encrypt_ctxt(conn,\n\t\t\t\t\t    (struct smb2_encryption_neg_context *)pctx,\n\t\t\t\t\t    ctxt_len);\n\t\t} else if (pctx->ContextType == SMB2_COMPRESSION_CAPABILITIES) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_COMPRESSION_CAPABILITIES context\\n\");\n\t\t\tif (conn->compress_algorithm)\n\t\t\t\tbreak;\n\n\t\t\tdecode_compress_ctxt(conn,\n\t\t\t\t\t     (struct smb2_compression_capabilities_context *)pctx);\n\t\t} else if (pctx->ContextType == SMB2_NETNAME_NEGOTIATE_CONTEXT_ID) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_NETNAME_NEGOTIATE_CONTEXT_ID context\\n\");\n\t\t} else if (pctx->ContextType == SMB2_POSIX_EXTENSIONS_AVAILABLE) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_POSIX_EXTENSIONS_AVAILABLE context\\n\");\n\t\t\tconn->posix_ext_supported = true;\n\t\t} else if (pctx->ContextType == SMB2_SIGNING_CAPABILITIES) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_SIGNING_CAPABILITIES context\\n\");\n\n\t\t\tdecode_sign_cap_ctxt(conn,\n\t\t\t\t\t     (struct smb2_signing_capabilities *)pctx,\n\t\t\t\t\t     ctxt_len);\n\t\t}\n\n\t\t/* offsets must be 8 byte aligned */\n\t\toffset = (ctxt_len + 7) & ~0x7;\n\t\tlen_of_ctxts -= offset;\n\t}\n\treturn status;\n}",
        "description": "An issue was discovered in the Linux kernel prior to version 6.3.8. Within the ksmbd component located in the SMB server directory, there is an integer underflow and out-of-bounds read vulnerability in the deassemble_neg_contexts function.",
        "commit": "The vulnerability involves an integer underflow condition in the SMB2 protocol negotiation process within the Linux kernel. Specifically, the initial check compares `clen + sizeof(struct smb2_neg_context)` against `len_of_ctxts`. However, during the loop, `len_of_ctxts` is decremented by `((clen + 7) & ~0x7) + sizeof(struct smb2_neg_context)`, which can lead to an underflow if `clen` undergoes 8-byte alignment. To prevent this, the check should use `(clen + 7) & ~0x7` instead. Additionally, certain variables should be declared as unsigned to avoid similar issues. The vulnerability results in a slab-out-of-bounds read error, as indicated by the kernel log, leading to potential memory corruption and system instability."
    },
    {
        "cwe": "CWE-264",
        "func_name": "newlib-cygwin/lsaauth",
        "score": 0.805709183216095,
        "func_before": "HANDLE\nlsaauth (cygsid &usersid, user_groups &new_groups)\n{\n  cygsidlist tmp_gsids (cygsidlist_auto, 12);\n  cygpsid pgrpsid;\n  LSA_STRING name;\n  HANDLE lsa_hdl = NULL, lsa = NULL;\n  LSA_OPERATIONAL_MODE sec_mode;\n  NTSTATUS status, sub_status;\n  ULONG package_id, size;\n  LUID auth_luid = SYSTEM_LUID;\n  struct {\n    LSA_STRING str;\n    CHAR buf[16];\n  } origin;\n  DWORD ulen = UNLEN + 1;\n  DWORD dlen = MAX_DOMAIN_NAME_LEN + 1;\n  SID_NAME_USE use;\n  cyglsa_t *authinf = NULL;\n  ULONG authinf_size;\n  TOKEN_SOURCE ts;\n  PCYG_TOKEN_GROUPS gsids = NULL;\n  PTOKEN_PRIVILEGES privs = NULL;\n  PACL dacl = NULL;\n  PVOID profile = NULL;\n  LUID luid;\n  QUOTA_LIMITS quota;\n  size_t psize = 0, gsize = 0, dsize = 0;\n  OFFSET offset, sids_offset;\n  int tmpidx, non_well_known_cnt;\n\n  HANDLE user_token = NULL;\n\n  push_self_privilege (SE_TCB_PRIVILEGE, true);\n\n  /* Register as logon process. */\n  RtlInitAnsiString (&name, \"Cygwin\");\n  SetLastError (0);\n  status = LsaRegisterLogonProcess (&name, &lsa_hdl, &sec_mode);\n  if (status != STATUS_SUCCESS)\n    {\n      debug_printf (\"LsaRegisterLogonProcess: %y\", status);\n      __seterrno_from_nt_status (status);\n      goto out;\n    }\n  else if (GetLastError () == ERROR_PROC_NOT_FOUND)\n    {\n      debug_printf (\"Couldn't load Secur32.dll\");\n      goto out;\n    }\n  /* Get handle to our own LSA package. */\n  RtlInitAnsiString (&name, CYG_LSA_PKGNAME);\n  status = LsaLookupAuthenticationPackage (lsa_hdl, &name, &package_id);\n  if (status != STATUS_SUCCESS)\n    {\n      debug_printf (\"LsaLookupAuthenticationPackage: %y\", status);\n      __seterrno_from_nt_status (status);\n      goto out;\n    }\n\n  /* Open policy object. */\n  if (!(lsa = lsa_open_policy (NULL, POLICY_EXECUTE)))\n    goto out;\n\n  /* Create origin. */\n  stpcpy (origin.buf, \"Cygwin\");\n  RtlInitAnsiString (&origin.str, origin.buf);\n  /* Create token source. */\n  memcpy (ts.SourceName, \"Cygwin.1\", 8);\n  ts.SourceIdentifier.HighPart = 0;\n  ts.SourceIdentifier.LowPart = 0x0103;\n\n  /* Create list of groups, the user is member in. */\n  int auth_pos;\n  if (new_groups.issetgroups ())\n    get_setgroups_sidlist (tmp_gsids, usersid, NULL, new_groups, auth_luid,\n\t\t\t   auth_pos);\n  else if (!get_initgroups_sidlist (tmp_gsids, usersid, new_groups.pgsid,\n\t\t\t\t    NULL, auth_luid, auth_pos))\n    goto out;\n\n  tmp_gsids.debug_print (\"tmp_gsids\");\n\n  /* Evaluate size of TOKEN_GROUPS list */\n  non_well_known_cnt =  tmp_gsids.non_well_known_count ();\n  gsize = sizeof (DWORD) + non_well_known_cnt * sizeof (SID_AND_ATTRIBUTES);\n  tmpidx = -1;\n  for (int i = 0; i < non_well_known_cnt; ++i)\n    if ((tmpidx = tmp_gsids.next_non_well_known_sid (tmpidx)) >= 0)\n      gsize += RtlLengthSid (tmp_gsids.sids[tmpidx]);\n\n  /* Retrieve list of privileges of that user.  The MIC SID is created by\n     the LSA here. */\n  if (!(privs = get_priv_list (lsa, usersid, tmp_gsids, psize, NULL)))\n    goto out;\n\n  /* Create DefaultDacl. */\n  dsize = sizeof (ACL) + 3 * sizeof (ACCESS_ALLOWED_ACE)\n\t  + RtlLengthSid (usersid)\n\t  + RtlLengthSid (well_known_admins_sid)\n\t  + RtlLengthSid (well_known_system_sid);\n  dacl = (PACL) alloca (dsize);\n  if (!NT_SUCCESS (RtlCreateAcl (dacl, dsize, ACL_REVISION)))\n    goto out;\n  if (!NT_SUCCESS (RtlAddAccessAllowedAce (dacl, ACL_REVISION, GENERIC_ALL,\n\t\t\t\t\t   usersid)))\n    goto out;\n  if (!NT_SUCCESS (RtlAddAccessAllowedAce (dacl, ACL_REVISION, GENERIC_ALL,\n\t\t\t\t\t   well_known_admins_sid)))\n    goto out;\n  if (!NT_SUCCESS (RtlAddAccessAllowedAce (dacl, ACL_REVISION, GENERIC_ALL,\n\t\t\t\t\t   well_known_system_sid)))\n    goto out;\n\n  /* Evaluate authinf size and allocate authinf. */\n  authinf_size = (authinf->data - (PBYTE) authinf);\n  authinf_size += RtlLengthSid (usersid);\t    /* User SID */\n  authinf_size += gsize;\t\t\t    /* Groups + Group SIDs */\n  /* When trying to define the admins group as primary group on Vista,\n     LsaLogonUser fails with error STATUS_INVALID_OWNER.  As workaround\n     we define \"Local\" as primary group here.  Seteuid32 sets the primary\n     group to the group set in /etc/passwd anyway. */\n  if (new_groups.pgsid == well_known_admins_sid)\n    pgrpsid = well_known_local_sid;\n  else\n    pgrpsid = new_groups.pgsid;\n\n  authinf_size += RtlLengthSid (pgrpsid);\t    /* Primary Group SID */\n\n  authinf_size += psize;\t\t\t    /* Privileges */\n  authinf_size += 0;\t\t\t\t    /* Owner SID */\n  authinf_size += dsize;\t\t\t    /* Default DACL */\n\n  authinf = (cyglsa_t *) alloca (authinf_size);\n  authinf->inf_size = authinf_size - ((PBYTE) &authinf->inf - (PBYTE) authinf);\n\n  authinf->magic = CYG_LSA_MAGIC;\n\n  if (!LookupAccountSidW (NULL, usersid, authinf->username, &ulen,\n\t\t\t  authinf->domain, &dlen, &use))\n    {\n      __seterrno ();\n      goto out;\n    }\n\n  /* Store stuff in authinf with offset relative to start of \"inf\" member,\n     instead of using pointers. */\n  offset = authinf->data - (PBYTE) &authinf->inf;\n\n  authinf->inf.ExpirationTime.LowPart = 0xffffffffL;\n  authinf->inf.ExpirationTime.HighPart = 0x7fffffffL;\n  /* User SID */\n  authinf->inf.User.User.Sid = offset;\n  authinf->inf.User.User.Attributes = 0;\n  RtlCopySid (RtlLengthSid (usersid), (PSID) ((PBYTE) &authinf->inf + offset),\n\t      usersid);\n  offset += RtlLengthSid (usersid);\n  /* Groups */\n  authinf->inf.Groups = offset;\n  gsids = (PCYG_TOKEN_GROUPS) ((PBYTE) &authinf->inf + offset);\n  sids_offset = offset + sizeof (ULONG) + non_well_known_cnt\n\t\t\t\t\t  * sizeof (SID_AND_ATTRIBUTES);\n  gsids->GroupCount = non_well_known_cnt;\n  /* Group SIDs */\n  tmpidx = -1;\n  for (int i = 0; i < non_well_known_cnt; ++i)\n    {\n      if ((tmpidx = tmp_gsids.next_non_well_known_sid (tmpidx)) < 0)\n\tbreak;\n      gsids->Groups[i].Sid = sids_offset;\n      gsids->Groups[i].Attributes = SE_GROUP_MANDATORY\n\t\t\t\t    | SE_GROUP_ENABLED_BY_DEFAULT\n\t\t\t\t    | SE_GROUP_ENABLED;\n      RtlCopySid (RtlLengthSid (tmp_gsids.sids[tmpidx]),\n\t\t  (PSID) ((PBYTE) &authinf->inf + sids_offset),\n\t\t  tmp_gsids.sids[tmpidx]);\n      sids_offset += RtlLengthSid (tmp_gsids.sids[tmpidx]);\n    }\n  offset += gsize;\n  /* Primary Group SID */\n  authinf->inf.PrimaryGroup.PrimaryGroup = offset;\n  RtlCopySid (RtlLengthSid (pgrpsid), (PSID) ((PBYTE) &authinf->inf + offset),\n\t      pgrpsid);\n  offset += RtlLengthSid (pgrpsid);\n  /* Privileges */\n  authinf->inf.Privileges = offset;\n  memcpy ((PBYTE) &authinf->inf + offset, privs, psize);\n  offset += psize;\n  /* Owner */\n  authinf->inf.Owner.Owner = 0;\n  /* Default DACL */\n  authinf->inf.DefaultDacl.DefaultDacl = offset;\n  memcpy ((PBYTE) &authinf->inf + offset, dacl, dsize);\n\n  authinf->checksum = CYG_LSA_MAGIC;\n  PDWORD csp;\n  PDWORD csp_end;\n  csp = (PDWORD) &authinf->username;\n  csp_end = (PDWORD) ((PBYTE) authinf + authinf_size);\n  while (csp < csp_end)\n    authinf->checksum += *csp++;\n\n  /* Try to logon... */\n  status = LsaLogonUser (lsa_hdl, (PLSA_STRING) &origin, Interactive,\n\t\t\t package_id, authinf, authinf_size, NULL, &ts,\n\t\t\t &profile, &size, &luid, &user_token, &quota,\n\t\t\t &sub_status);\n  if (status != STATUS_SUCCESS)\n    {\n      debug_printf (\"LsaLogonUser: %y (sub-status %y)\", status, sub_status);\n      __seterrno_from_nt_status (status);\n      goto out;\n    }\n  if (profile)\n    {\n#ifdef JUST_ANOTHER_NONWORKING_SOLUTION\n      /* See ../lsaauth/cyglsa.c. */\n      cygprf_t *prf = (cygprf_t *) profile;\n      if (prf->magic_pre == MAGIC_PRE && prf->magic_post == MAGIC_POST\n\t  && prf->token)\n\t{\n\t  CloseHandle (user_token);\n\t  user_token = prf->token;\n\t  system_printf (\"Got token through profile: %p\", user_token);\n\t}\n#endif /* JUST_ANOTHER_NONWORKING_SOLUTION */\n      LsaFreeReturnBuffer (profile);\n    }\n  user_token = get_full_privileged_inheritable_token (user_token);\n\nout:\n  if (privs)\n    free (privs);\n  lsa_close_policy (lsa);\n  if (lsa_hdl)\n    LsaDeregisterLogonProcess (lsa_hdl);\n  pop_self_privilege ();\n\n  debug_printf (\"%p = lsaauth ()\", user_token);\n  return user_token;\n}",
        "func_after": "HANDLE\nlsaauth (cygsid &usersid, user_groups &new_groups)\n{\n  cygsidlist tmp_gsids (cygsidlist_auto, 12);\n  cygpsid pgrpsid;\n  LSA_STRING name;\n  HANDLE lsa_hdl = NULL, lsa = NULL;\n  LSA_OPERATIONAL_MODE sec_mode;\n  NTSTATUS status, sub_status;\n  ULONG package_id, size;\n  struct {\n    LSA_STRING str;\n    CHAR buf[16];\n  } origin;\n  DWORD ulen = UNLEN + 1;\n  DWORD dlen = MAX_DOMAIN_NAME_LEN + 1;\n  SID_NAME_USE use;\n  cyglsa_t *authinf = NULL;\n  ULONG authinf_size;\n  TOKEN_SOURCE ts;\n  PCYG_TOKEN_GROUPS gsids = NULL;\n  PTOKEN_PRIVILEGES privs = NULL;\n  PACL dacl = NULL;\n  PVOID profile = NULL;\n  LUID luid;\n  QUOTA_LIMITS quota;\n  size_t psize = 0, gsize = 0, dsize = 0;\n  OFFSET offset, sids_offset;\n  int tmpidx, non_well_known_cnt;\n\n  HANDLE user_token = NULL;\n\n  push_self_privilege (SE_TCB_PRIVILEGE, true);\n\n  /* Register as logon process. */\n  RtlInitAnsiString (&name, \"Cygwin\");\n  SetLastError (0);\n  status = LsaRegisterLogonProcess (&name, &lsa_hdl, &sec_mode);\n  if (status != STATUS_SUCCESS)\n    {\n      debug_printf (\"LsaRegisterLogonProcess: %y\", status);\n      __seterrno_from_nt_status (status);\n      goto out;\n    }\n  else if (GetLastError () == ERROR_PROC_NOT_FOUND)\n    {\n      debug_printf (\"Couldn't load Secur32.dll\");\n      goto out;\n    }\n  /* Get handle to our own LSA package. */\n  RtlInitAnsiString (&name, CYG_LSA_PKGNAME);\n  status = LsaLookupAuthenticationPackage (lsa_hdl, &name, &package_id);\n  if (status != STATUS_SUCCESS)\n    {\n      debug_printf (\"LsaLookupAuthenticationPackage: %y\", status);\n      __seterrno_from_nt_status (status);\n      goto out;\n    }\n\n  /* Open policy object. */\n  if (!(lsa = lsa_open_policy (NULL, POLICY_EXECUTE)))\n    goto out;\n\n  /* Create origin. */\n  stpcpy (origin.buf, \"Cygwin\");\n  RtlInitAnsiString (&origin.str, origin.buf);\n  /* Create token source. */\n  memcpy (ts.SourceName, \"Cygwin.1\", 8);\n  ts.SourceIdentifier.HighPart = 0;\n  ts.SourceIdentifier.LowPart = 0x0103;\n\n  /* Create list of groups, the user is member in. */\n  if (new_groups.issetgroups ())\n    get_setgroups_sidlist (tmp_gsids, usersid, NULL, new_groups);\n  else if (!get_initgroups_sidlist (tmp_gsids, usersid, new_groups.pgsid,\n\t\t\t\t    NULL))\n    goto out;\n\n  tmp_gsids.debug_print (\"tmp_gsids\");\n\n  /* Evaluate size of TOKEN_GROUPS list */\n  non_well_known_cnt =  tmp_gsids.non_well_known_count ();\n  gsize = sizeof (DWORD) + non_well_known_cnt * sizeof (SID_AND_ATTRIBUTES);\n  tmpidx = -1;\n  for (int i = 0; i < non_well_known_cnt; ++i)\n    if ((tmpidx = tmp_gsids.next_non_well_known_sid (tmpidx)) >= 0)\n      gsize += RtlLengthSid (tmp_gsids.sids[tmpidx]);\n\n  /* Retrieve list of privileges of that user.  The MIC SID is created by\n     the LSA here. */\n  if (!(privs = get_priv_list (lsa, usersid, tmp_gsids, psize, NULL)))\n    goto out;\n\n  /* Create DefaultDacl. */\n  dsize = sizeof (ACL) + 3 * sizeof (ACCESS_ALLOWED_ACE)\n\t  + RtlLengthSid (usersid)\n\t  + RtlLengthSid (well_known_admins_sid)\n\t  + RtlLengthSid (well_known_system_sid);\n  dacl = (PACL) alloca (dsize);\n  if (!NT_SUCCESS (RtlCreateAcl (dacl, dsize, ACL_REVISION)))\n    goto out;\n  if (!NT_SUCCESS (RtlAddAccessAllowedAce (dacl, ACL_REVISION, GENERIC_ALL,\n\t\t\t\t\t   usersid)))\n    goto out;\n  if (!NT_SUCCESS (RtlAddAccessAllowedAce (dacl, ACL_REVISION, GENERIC_ALL,\n\t\t\t\t\t   well_known_admins_sid)))\n    goto out;\n  if (!NT_SUCCESS (RtlAddAccessAllowedAce (dacl, ACL_REVISION, GENERIC_ALL,\n\t\t\t\t\t   well_known_system_sid)))\n    goto out;\n\n  /* Evaluate authinf size and allocate authinf. */\n  authinf_size = (authinf->data - (PBYTE) authinf);\n  authinf_size += RtlLengthSid (usersid);\t    /* User SID */\n  authinf_size += gsize;\t\t\t    /* Groups + Group SIDs */\n  /* When trying to define the admins group as primary group on Vista,\n     LsaLogonUser fails with error STATUS_INVALID_OWNER.  As workaround\n     we define \"Local\" as primary group here.  Seteuid32 sets the primary\n     group to the group set in /etc/passwd anyway. */\n  if (new_groups.pgsid == well_known_admins_sid)\n    pgrpsid = well_known_local_sid;\n  else\n    pgrpsid = new_groups.pgsid;\n\n  authinf_size += RtlLengthSid (pgrpsid);\t    /* Primary Group SID */\n\n  authinf_size += psize;\t\t\t    /* Privileges */\n  authinf_size += 0;\t\t\t\t    /* Owner SID */\n  authinf_size += dsize;\t\t\t    /* Default DACL */\n\n  authinf = (cyglsa_t *) alloca (authinf_size);\n  authinf->inf_size = authinf_size - ((PBYTE) &authinf->inf - (PBYTE) authinf);\n\n  authinf->magic = CYG_LSA_MAGIC;\n\n  if (!LookupAccountSidW (NULL, usersid, authinf->username, &ulen,\n\t\t\t  authinf->domain, &dlen, &use))\n    {\n      __seterrno ();\n      goto out;\n    }\n\n  /* Store stuff in authinf with offset relative to start of \"inf\" member,\n     instead of using pointers. */\n  offset = authinf->data - (PBYTE) &authinf->inf;\n\n  authinf->inf.ExpirationTime.LowPart = 0xffffffffL;\n  authinf->inf.ExpirationTime.HighPart = 0x7fffffffL;\n  /* User SID */\n  authinf->inf.User.User.Sid = offset;\n  authinf->inf.User.User.Attributes = 0;\n  RtlCopySid (RtlLengthSid (usersid), (PSID) ((PBYTE) &authinf->inf + offset),\n\t      usersid);\n  offset += RtlLengthSid (usersid);\n  /* Groups */\n  authinf->inf.Groups = offset;\n  gsids = (PCYG_TOKEN_GROUPS) ((PBYTE) &authinf->inf + offset);\n  sids_offset = offset + sizeof (ULONG) + non_well_known_cnt\n\t\t\t\t\t  * sizeof (SID_AND_ATTRIBUTES);\n  gsids->GroupCount = non_well_known_cnt;\n  /* Group SIDs */\n  tmpidx = -1;\n  for (int i = 0; i < non_well_known_cnt; ++i)\n    {\n      if ((tmpidx = tmp_gsids.next_non_well_known_sid (tmpidx)) < 0)\n\tbreak;\n      gsids->Groups[i].Sid = sids_offset;\n      gsids->Groups[i].Attributes = SE_GROUP_MANDATORY\n\t\t\t\t    | SE_GROUP_ENABLED_BY_DEFAULT\n\t\t\t\t    | SE_GROUP_ENABLED;\n      RtlCopySid (RtlLengthSid (tmp_gsids.sids[tmpidx]),\n\t\t  (PSID) ((PBYTE) &authinf->inf + sids_offset),\n\t\t  tmp_gsids.sids[tmpidx]);\n      sids_offset += RtlLengthSid (tmp_gsids.sids[tmpidx]);\n    }\n  offset += gsize;\n  /* Primary Group SID */\n  authinf->inf.PrimaryGroup.PrimaryGroup = offset;\n  RtlCopySid (RtlLengthSid (pgrpsid), (PSID) ((PBYTE) &authinf->inf + offset),\n\t      pgrpsid);\n  offset += RtlLengthSid (pgrpsid);\n  /* Privileges */\n  authinf->inf.Privileges = offset;\n  memcpy ((PBYTE) &authinf->inf + offset, privs, psize);\n  offset += psize;\n  /* Owner */\n  authinf->inf.Owner.Owner = 0;\n  /* Default DACL */\n  authinf->inf.DefaultDacl.DefaultDacl = offset;\n  memcpy ((PBYTE) &authinf->inf + offset, dacl, dsize);\n\n  authinf->checksum = CYG_LSA_MAGIC;\n  PDWORD csp;\n  PDWORD csp_end;\n  csp = (PDWORD) &authinf->username;\n  csp_end = (PDWORD) ((PBYTE) authinf + authinf_size);\n  while (csp < csp_end)\n    authinf->checksum += *csp++;\n\n  /* Try to logon... */\n  status = LsaLogonUser (lsa_hdl, (PLSA_STRING) &origin, Interactive,\n\t\t\t package_id, authinf, authinf_size, NULL, &ts,\n\t\t\t &profile, &size, &luid, &user_token, &quota,\n\t\t\t &sub_status);\n  if (status != STATUS_SUCCESS)\n    {\n      debug_printf (\"LsaLogonUser: %y (sub-status %y)\", status, sub_status);\n      __seterrno_from_nt_status (status);\n      goto out;\n    }\n  if (profile)\n    {\n#ifdef JUST_ANOTHER_NONWORKING_SOLUTION\n      /* See ../lsaauth/cyglsa.c. */\n      cygprf_t *prf = (cygprf_t *) profile;\n      if (prf->magic_pre == MAGIC_PRE && prf->magic_post == MAGIC_POST\n\t  && prf->token)\n\t{\n\t  CloseHandle (user_token);\n\t  user_token = prf->token;\n\t  system_printf (\"Got token through profile: %p\", user_token);\n\t}\n#endif /* JUST_ANOTHER_NONWORKING_SOLUTION */\n      LsaFreeReturnBuffer (profile);\n    }\n  user_token = get_full_privileged_inheritable_token (user_token);\n\nout:\n  if (privs)\n    free (privs);\n  lsa_close_policy (lsa);\n  if (lsa_hdl)\n    LsaDeregisterLogonProcess (lsa_hdl);\n  pop_self_privilege ();\n\n  debug_printf (\"%p = lsaauth ()\", user_token);\n  return user_token;\n}",
        "description": "Cygwin versions prior to 2.5.0 fail to correctly update permissions during user changes, enabling attackers to escalate their privileges.",
        "commit": "The vulnerability involves the creation of a security token without using the caller's credentials in the `sec_auth.cc` file. Specifically, the `get_token_group_sidlist`, `get_initgroups_sidlist`, and `get_setgroups_sidlist` functions have been modified to remove parameters related to authentication (`auth_luid` and `auth_pos`) and the code that adds a logon SID. The `create_token` function now explicitly sets the `auth_luid` to either `ANONYMOUS_LOGON_LUID` or `LOCALSERVICE_LUID` based on the operating system, and no longer handles the logon SID since it is no longer generated. Additionally, the `lsaauth` function has removed unused local variables `auth_luid` and `auth_pos`. A new element `has_broken_whoami` has been added to `wincap.h`, and implemented in `wincap.cc`. This change results in the creation of tokens without proper authentication context, potentially leading to unauthorized access or privilege escalation."
    },
    {
        "cwe": "CWE-330",
        "func_name": "torvalds/sfb_enqueue",
        "score": 0.8066959381103516,
        "func_before": "static int sfb_enqueue(struct sk_buff *skb, struct Qdisc *sch,\n\t\t       struct sk_buff **to_free)\n{\n\n\tstruct sfb_sched_data *q = qdisc_priv(sch);\n\tstruct Qdisc *child = q->qdisc;\n\tstruct tcf_proto *fl;\n\tint i;\n\tu32 p_min = ~0;\n\tu32 minqlen = ~0;\n\tu32 r, sfbhash;\n\tu32 slot = q->slot;\n\tint ret = NET_XMIT_SUCCESS | __NET_XMIT_BYPASS;\n\n\tif (unlikely(sch->q.qlen >= q->limit)) {\n\t\tqdisc_qstats_overlimit(sch);\n\t\tq->stats.queuedrop++;\n\t\tgoto drop;\n\t}\n\n\tif (q->rehash_interval > 0) {\n\t\tunsigned long limit = q->rehash_time + q->rehash_interval;\n\n\t\tif (unlikely(time_after(jiffies, limit))) {\n\t\t\tsfb_swap_slot(q);\n\t\t\tq->rehash_time = jiffies;\n\t\t} else if (unlikely(!q->double_buffering && q->warmup_time > 0 &&\n\t\t\t\t    time_after(jiffies, limit - q->warmup_time))) {\n\t\t\tq->double_buffering = true;\n\t\t}\n\t}\n\n\tfl = rcu_dereference_bh(q->filter_list);\n\tif (fl) {\n\t\tu32 salt;\n\n\t\t/* If using external classifiers, get result and record it. */\n\t\tif (!sfb_classify(skb, fl, &ret, &salt))\n\t\t\tgoto other_drop;\n\t\tsfbhash = jhash_1word(salt, q->bins[slot].perturbation);\n\t} else {\n\t\tsfbhash = skb_get_hash_perturb(skb, q->bins[slot].perturbation);\n\t}\n\n\n\tif (!sfbhash)\n\t\tsfbhash = 1;\n\tsfb_skb_cb(skb)->hashes[slot] = sfbhash;\n\n\tfor (i = 0; i < SFB_LEVELS; i++) {\n\t\tu32 hash = sfbhash & SFB_BUCKET_MASK;\n\t\tstruct sfb_bucket *b = &q->bins[slot].bins[i][hash];\n\n\t\tsfbhash >>= SFB_BUCKET_SHIFT;\n\t\tif (b->qlen == 0)\n\t\t\tdecrement_prob(b, q);\n\t\telse if (b->qlen >= q->bin_size)\n\t\t\tincrement_prob(b, q);\n\t\tif (minqlen > b->qlen)\n\t\t\tminqlen = b->qlen;\n\t\tif (p_min > b->p_mark)\n\t\t\tp_min = b->p_mark;\n\t}\n\n\tslot ^= 1;\n\tsfb_skb_cb(skb)->hashes[slot] = 0;\n\n\tif (unlikely(minqlen >= q->max)) {\n\t\tqdisc_qstats_overlimit(sch);\n\t\tq->stats.bucketdrop++;\n\t\tgoto drop;\n\t}\n\n\tif (unlikely(p_min >= SFB_MAX_PROB)) {\n\t\t/* Inelastic flow */\n\t\tif (q->double_buffering) {\n\t\t\tsfbhash = skb_get_hash_perturb(skb,\n\t\t\t    q->bins[slot].perturbation);\n\t\t\tif (!sfbhash)\n\t\t\t\tsfbhash = 1;\n\t\t\tsfb_skb_cb(skb)->hashes[slot] = sfbhash;\n\n\t\t\tfor (i = 0; i < SFB_LEVELS; i++) {\n\t\t\t\tu32 hash = sfbhash & SFB_BUCKET_MASK;\n\t\t\t\tstruct sfb_bucket *b = &q->bins[slot].bins[i][hash];\n\n\t\t\t\tsfbhash >>= SFB_BUCKET_SHIFT;\n\t\t\t\tif (b->qlen == 0)\n\t\t\t\t\tdecrement_prob(b, q);\n\t\t\t\telse if (b->qlen >= q->bin_size)\n\t\t\t\t\tincrement_prob(b, q);\n\t\t\t}\n\t\t}\n\t\tif (sfb_rate_limit(skb, q)) {\n\t\t\tqdisc_qstats_overlimit(sch);\n\t\t\tq->stats.penaltydrop++;\n\t\t\tgoto drop;\n\t\t}\n\t\tgoto enqueue;\n\t}\n\n\tr = prandom_u32() & SFB_MAX_PROB;\n\n\tif (unlikely(r < p_min)) {\n\t\tif (unlikely(p_min > SFB_MAX_PROB / 2)) {\n\t\t\t/* If we're marking that many packets, then either\n\t\t\t * this flow is unresponsive, or we're badly congested.\n\t\t\t * In either case, we want to start dropping packets.\n\t\t\t */\n\t\t\tif (r < (p_min - SFB_MAX_PROB / 2) * 2) {\n\t\t\t\tq->stats.earlydrop++;\n\t\t\t\tgoto drop;\n\t\t\t}\n\t\t}\n\t\tif (INET_ECN_set_ce(skb)) {\n\t\t\tq->stats.marked++;\n\t\t} else {\n\t\t\tq->stats.earlydrop++;\n\t\t\tgoto drop;\n\t\t}\n\t}\n\nenqueue:\n\tret = qdisc_enqueue(skb, child, to_free);\n\tif (likely(ret == NET_XMIT_SUCCESS)) {\n\t\tqdisc_qstats_backlog_inc(sch, skb);\n\t\tsch->q.qlen++;\n\t\tincrement_qlen(skb, q);\n\t} else if (net_xmit_drop_count(ret)) {\n\t\tq->stats.childdrop++;\n\t\tqdisc_qstats_drop(sch);\n\t}\n\treturn ret;\n\ndrop:\n\tqdisc_drop(skb, sch, to_free);\n\treturn NET_XMIT_CN;\nother_drop:\n\tif (ret & __NET_XMIT_BYPASS)\n\t\tqdisc_qstats_drop(sch);\n\tkfree_skb(skb);\n\treturn ret;\n}",
        "func_after": "static int sfb_enqueue(struct sk_buff *skb, struct Qdisc *sch,\n\t\t       struct sk_buff **to_free)\n{\n\n\tstruct sfb_sched_data *q = qdisc_priv(sch);\n\tstruct Qdisc *child = q->qdisc;\n\tstruct tcf_proto *fl;\n\tint i;\n\tu32 p_min = ~0;\n\tu32 minqlen = ~0;\n\tu32 r, sfbhash;\n\tu32 slot = q->slot;\n\tint ret = NET_XMIT_SUCCESS | __NET_XMIT_BYPASS;\n\n\tif (unlikely(sch->q.qlen >= q->limit)) {\n\t\tqdisc_qstats_overlimit(sch);\n\t\tq->stats.queuedrop++;\n\t\tgoto drop;\n\t}\n\n\tif (q->rehash_interval > 0) {\n\t\tunsigned long limit = q->rehash_time + q->rehash_interval;\n\n\t\tif (unlikely(time_after(jiffies, limit))) {\n\t\t\tsfb_swap_slot(q);\n\t\t\tq->rehash_time = jiffies;\n\t\t} else if (unlikely(!q->double_buffering && q->warmup_time > 0 &&\n\t\t\t\t    time_after(jiffies, limit - q->warmup_time))) {\n\t\t\tq->double_buffering = true;\n\t\t}\n\t}\n\n\tfl = rcu_dereference_bh(q->filter_list);\n\tif (fl) {\n\t\tu32 salt;\n\n\t\t/* If using external classifiers, get result and record it. */\n\t\tif (!sfb_classify(skb, fl, &ret, &salt))\n\t\t\tgoto other_drop;\n\t\tsfbhash = siphash_1u32(salt, &q->bins[slot].perturbation);\n\t} else {\n\t\tsfbhash = skb_get_hash_perturb(skb, &q->bins[slot].perturbation);\n\t}\n\n\n\tif (!sfbhash)\n\t\tsfbhash = 1;\n\tsfb_skb_cb(skb)->hashes[slot] = sfbhash;\n\n\tfor (i = 0; i < SFB_LEVELS; i++) {\n\t\tu32 hash = sfbhash & SFB_BUCKET_MASK;\n\t\tstruct sfb_bucket *b = &q->bins[slot].bins[i][hash];\n\n\t\tsfbhash >>= SFB_BUCKET_SHIFT;\n\t\tif (b->qlen == 0)\n\t\t\tdecrement_prob(b, q);\n\t\telse if (b->qlen >= q->bin_size)\n\t\t\tincrement_prob(b, q);\n\t\tif (minqlen > b->qlen)\n\t\t\tminqlen = b->qlen;\n\t\tif (p_min > b->p_mark)\n\t\t\tp_min = b->p_mark;\n\t}\n\n\tslot ^= 1;\n\tsfb_skb_cb(skb)->hashes[slot] = 0;\n\n\tif (unlikely(minqlen >= q->max)) {\n\t\tqdisc_qstats_overlimit(sch);\n\t\tq->stats.bucketdrop++;\n\t\tgoto drop;\n\t}\n\n\tif (unlikely(p_min >= SFB_MAX_PROB)) {\n\t\t/* Inelastic flow */\n\t\tif (q->double_buffering) {\n\t\t\tsfbhash = skb_get_hash_perturb(skb,\n\t\t\t    &q->bins[slot].perturbation);\n\t\t\tif (!sfbhash)\n\t\t\t\tsfbhash = 1;\n\t\t\tsfb_skb_cb(skb)->hashes[slot] = sfbhash;\n\n\t\t\tfor (i = 0; i < SFB_LEVELS; i++) {\n\t\t\t\tu32 hash = sfbhash & SFB_BUCKET_MASK;\n\t\t\t\tstruct sfb_bucket *b = &q->bins[slot].bins[i][hash];\n\n\t\t\t\tsfbhash >>= SFB_BUCKET_SHIFT;\n\t\t\t\tif (b->qlen == 0)\n\t\t\t\t\tdecrement_prob(b, q);\n\t\t\t\telse if (b->qlen >= q->bin_size)\n\t\t\t\t\tincrement_prob(b, q);\n\t\t\t}\n\t\t}\n\t\tif (sfb_rate_limit(skb, q)) {\n\t\t\tqdisc_qstats_overlimit(sch);\n\t\t\tq->stats.penaltydrop++;\n\t\t\tgoto drop;\n\t\t}\n\t\tgoto enqueue;\n\t}\n\n\tr = prandom_u32() & SFB_MAX_PROB;\n\n\tif (unlikely(r < p_min)) {\n\t\tif (unlikely(p_min > SFB_MAX_PROB / 2)) {\n\t\t\t/* If we're marking that many packets, then either\n\t\t\t * this flow is unresponsive, or we're badly congested.\n\t\t\t * In either case, we want to start dropping packets.\n\t\t\t */\n\t\t\tif (r < (p_min - SFB_MAX_PROB / 2) * 2) {\n\t\t\t\tq->stats.earlydrop++;\n\t\t\t\tgoto drop;\n\t\t\t}\n\t\t}\n\t\tif (INET_ECN_set_ce(skb)) {\n\t\t\tq->stats.marked++;\n\t\t} else {\n\t\t\tq->stats.earlydrop++;\n\t\t\tgoto drop;\n\t\t}\n\t}\n\nenqueue:\n\tret = qdisc_enqueue(skb, child, to_free);\n\tif (likely(ret == NET_XMIT_SUCCESS)) {\n\t\tqdisc_qstats_backlog_inc(sch, skb);\n\t\tsch->q.qlen++;\n\t\tincrement_qlen(skb, q);\n\t} else if (net_xmit_drop_count(ret)) {\n\t\tq->stats.childdrop++;\n\t\tqdisc_qstats_drop(sch);\n\t}\n\treturn ret;\n\ndrop:\n\tqdisc_drop(skb, sch, to_free);\n\treturn NET_XMIT_CN;\nother_drop:\n\tif (ret & __NET_XMIT_BYPASS)\n\t\tqdisc_qstats_drop(sch);\n\tkfree_skb(skb);\n\treturn ret;\n}",
        "description": "The flow_dissector feature in the Linux kernel from version 4.3 up to but not including 5.3.10 suffers from a device tracking vulnerability, identified as CID-55667441c84f. This vulnerability arises due to the reliance on a 32-bit hashrnd value as a secret for the auto flowlabel of a UDP IPv6 packet. Additionally, the use of jhash instead of siphash exacerbates the issue. Since the hashrnd value remains constant from the time of system boot, it can be deduced by an attacker, thereby compromising the intended security measures. This problem is present in the net/core/flow_dissector.c file and related components.",
        "commit": "The vulnerability involves the use of a 32-bit secret in generating auto flowlabels for UDP IPv6 packets, which can be inferred by attackers to identify devices or users. The secret is initialized only at boot time and is used in conjunction with the jhash function to create flow labels that are predictable. This predictability poses a significant privacy risk. The proposed solution is to switch from using jhash to a cryptographically strong pseudo-random function like siphash, similar to changes made in the IP ID generator. This switch aims to enhance security by making the flow label generation process less predictable and thereby reducing the risk of device/user identification."
    },
    {
        "cwe": "CWE-119",
        "func_name": "torvalds/hugetlb_mcopy_atomic_pte",
        "score": 0.8105156421661377,
        "func_before": "int hugetlb_mcopy_atomic_pte(struct mm_struct *dst_mm,\n\t\t\t    pte_t *dst_pte,\n\t\t\t    struct vm_area_struct *dst_vma,\n\t\t\t    unsigned long dst_addr,\n\t\t\t    unsigned long src_addr,\n\t\t\t    struct page **pagep)\n{\n\tint vm_shared = dst_vma->vm_flags & VM_SHARED;\n\tstruct hstate *h = hstate_vma(dst_vma);\n\tpte_t _dst_pte;\n\tspinlock_t *ptl;\n\tint ret;\n\tstruct page *page;\n\n\tif (!*pagep) {\n\t\tret = -ENOMEM;\n\t\tpage = alloc_huge_page(dst_vma, dst_addr, 0);\n\t\tif (IS_ERR(page))\n\t\t\tgoto out;\n\n\t\tret = copy_huge_page_from_user(page,\n\t\t\t\t\t\t(const void __user *) src_addr,\n\t\t\t\t\t\tpages_per_huge_page(h), false);\n\n\t\t/* fallback to copy_from_user outside mmap_sem */\n\t\tif (unlikely(ret)) {\n\t\t\tret = -EFAULT;\n\t\t\t*pagep = page;\n\t\t\t/* don't free the page */\n\t\t\tgoto out;\n\t\t}\n\t} else {\n\t\tpage = *pagep;\n\t\t*pagep = NULL;\n\t}\n\n\t/*\n\t * The memory barrier inside __SetPageUptodate makes sure that\n\t * preceding stores to the page contents become visible before\n\t * the set_pte_at() write.\n\t */\n\t__SetPageUptodate(page);\n\tset_page_huge_active(page);\n\n\t/*\n\t * If shared, add to page cache\n\t */\n\tif (vm_shared) {\n\t\tstruct address_space *mapping = dst_vma->vm_file->f_mapping;\n\t\tpgoff_t idx = vma_hugecache_offset(h, dst_vma, dst_addr);\n\n\t\tret = huge_add_to_page_cache(page, mapping, idx);\n\t\tif (ret)\n\t\t\tgoto out_release_nounlock;\n\t}\n\n\tptl = huge_pte_lockptr(h, dst_mm, dst_pte);\n\tspin_lock(ptl);\n\n\tret = -EEXIST;\n\tif (!huge_pte_none(huge_ptep_get(dst_pte)))\n\t\tgoto out_release_unlock;\n\n\tif (vm_shared) {\n\t\tpage_dup_rmap(page, true);\n\t} else {\n\t\tClearPagePrivate(page);\n\t\thugepage_add_new_anon_rmap(page, dst_vma, dst_addr);\n\t}\n\n\t_dst_pte = make_huge_pte(dst_vma, page, dst_vma->vm_flags & VM_WRITE);\n\tif (dst_vma->vm_flags & VM_WRITE)\n\t\t_dst_pte = huge_pte_mkdirty(_dst_pte);\n\t_dst_pte = pte_mkyoung(_dst_pte);\n\n\tset_huge_pte_at(dst_mm, dst_addr, dst_pte, _dst_pte);\n\n\t(void)huge_ptep_set_access_flags(dst_vma, dst_addr, dst_pte, _dst_pte,\n\t\t\t\t\tdst_vma->vm_flags & VM_WRITE);\n\thugetlb_count_add(pages_per_huge_page(h), dst_mm);\n\n\t/* No need to invalidate - it was non-present before */\n\tupdate_mmu_cache(dst_vma, dst_addr, dst_pte);\n\n\tspin_unlock(ptl);\n\tif (vm_shared)\n\t\tunlock_page(page);\n\tret = 0;\nout:\n\treturn ret;\nout_release_unlock:\n\tspin_unlock(ptl);\n\tif (vm_shared)\n\t\tunlock_page(page);\nout_release_nounlock:\n\tput_page(page);\n\tgoto out;\n}",
        "func_after": "int hugetlb_mcopy_atomic_pte(struct mm_struct *dst_mm,\n\t\t\t    pte_t *dst_pte,\n\t\t\t    struct vm_area_struct *dst_vma,\n\t\t\t    unsigned long dst_addr,\n\t\t\t    unsigned long src_addr,\n\t\t\t    struct page **pagep)\n{\n\tstruct address_space *mapping;\n\tpgoff_t idx;\n\tunsigned long size;\n\tint vm_shared = dst_vma->vm_flags & VM_SHARED;\n\tstruct hstate *h = hstate_vma(dst_vma);\n\tpte_t _dst_pte;\n\tspinlock_t *ptl;\n\tint ret;\n\tstruct page *page;\n\n\tif (!*pagep) {\n\t\tret = -ENOMEM;\n\t\tpage = alloc_huge_page(dst_vma, dst_addr, 0);\n\t\tif (IS_ERR(page))\n\t\t\tgoto out;\n\n\t\tret = copy_huge_page_from_user(page,\n\t\t\t\t\t\t(const void __user *) src_addr,\n\t\t\t\t\t\tpages_per_huge_page(h), false);\n\n\t\t/* fallback to copy_from_user outside mmap_sem */\n\t\tif (unlikely(ret)) {\n\t\t\tret = -EFAULT;\n\t\t\t*pagep = page;\n\t\t\t/* don't free the page */\n\t\t\tgoto out;\n\t\t}\n\t} else {\n\t\tpage = *pagep;\n\t\t*pagep = NULL;\n\t}\n\n\t/*\n\t * The memory barrier inside __SetPageUptodate makes sure that\n\t * preceding stores to the page contents become visible before\n\t * the set_pte_at() write.\n\t */\n\t__SetPageUptodate(page);\n\tset_page_huge_active(page);\n\n\tmapping = dst_vma->vm_file->f_mapping;\n\tidx = vma_hugecache_offset(h, dst_vma, dst_addr);\n\n\t/*\n\t * If shared, add to page cache\n\t */\n\tif (vm_shared) {\n\t\tsize = i_size_read(mapping->host) >> huge_page_shift(h);\n\t\tret = -EFAULT;\n\t\tif (idx >= size)\n\t\t\tgoto out_release_nounlock;\n\n\t\t/*\n\t\t * Serialization between remove_inode_hugepages() and\n\t\t * huge_add_to_page_cache() below happens through the\n\t\t * hugetlb_fault_mutex_table that here must be hold by\n\t\t * the caller.\n\t\t */\n\t\tret = huge_add_to_page_cache(page, mapping, idx);\n\t\tif (ret)\n\t\t\tgoto out_release_nounlock;\n\t}\n\n\tptl = huge_pte_lockptr(h, dst_mm, dst_pte);\n\tspin_lock(ptl);\n\n\t/*\n\t * Recheck the i_size after holding PT lock to make sure not\n\t * to leave any page mapped (as page_mapped()) beyond the end\n\t * of the i_size (remove_inode_hugepages() is strict about\n\t * enforcing that). If we bail out here, we'll also leave a\n\t * page in the radix tree in the vm_shared case beyond the end\n\t * of the i_size, but remove_inode_hugepages() will take care\n\t * of it as soon as we drop the hugetlb_fault_mutex_table.\n\t */\n\tsize = i_size_read(mapping->host) >> huge_page_shift(h);\n\tret = -EFAULT;\n\tif (idx >= size)\n\t\tgoto out_release_unlock;\n\n\tret = -EEXIST;\n\tif (!huge_pte_none(huge_ptep_get(dst_pte)))\n\t\tgoto out_release_unlock;\n\n\tif (vm_shared) {\n\t\tpage_dup_rmap(page, true);\n\t} else {\n\t\tClearPagePrivate(page);\n\t\thugepage_add_new_anon_rmap(page, dst_vma, dst_addr);\n\t}\n\n\t_dst_pte = make_huge_pte(dst_vma, page, dst_vma->vm_flags & VM_WRITE);\n\tif (dst_vma->vm_flags & VM_WRITE)\n\t\t_dst_pte = huge_pte_mkdirty(_dst_pte);\n\t_dst_pte = pte_mkyoung(_dst_pte);\n\n\tset_huge_pte_at(dst_mm, dst_addr, dst_pte, _dst_pte);\n\n\t(void)huge_ptep_set_access_flags(dst_vma, dst_addr, dst_pte, _dst_pte,\n\t\t\t\t\tdst_vma->vm_flags & VM_WRITE);\n\thugetlb_count_add(pages_per_huge_page(h), dst_mm);\n\n\t/* No need to invalidate - it was non-present before */\n\tupdate_mmu_cache(dst_vma, dst_addr, dst_pte);\n\n\tspin_unlock(ptl);\n\tif (vm_shared)\n\t\tunlock_page(page);\n\tret = 0;\nout:\n\treturn ret;\nout_release_unlock:\n\tspin_unlock(ptl);\n\tif (vm_shared)\n\t\tunlock_page(page);\nout_release_nounlock:\n\tput_page(page);\n\tgoto out;\n}",
        "description": "A flaw was identified in the hugetlb_mcopy_atomic_pte function within the Linux kernel's memory management module, affecting versions prior to 4.13.12. The absence of a proper size check in this function could lead to a denial of service condition, indicated by a BUG.",
        "commit": "A vulnerability was identified in the userfaultfd functionality related to hugetlbfs, where the UFFDIO_COPY operation could inadvertently extend beyond the intended size of the file (i_size). This issue led to a kernel panic (oops) at fs/hugetlbfs/inode.c:484, triggered by the absence of an i_size check in the hugetlb_mcopy_atomic_pte function. Although mmap() operations could succeed beyond the end of the i_size after vmtruncate had removed virtual memory areas (vmas) in those ranges, subsequent faults, including UFFDIO_COPY, should not be allowed to succeed. The proposed solution involves modifying the return value to userland to indicate a SIGBUS-like condition, similar to what a page fault would produce, but this approach was deemed less useful due to the difficulty in distinguishing between SIGSEGV and SIGBUS through meaningful syscall return values."
    },
    {
        "cwe": "CWE-787",
        "func_name": "OP-TEE/syscall_obj_generate_key",
        "score": 0.8116146326065063,
        "func_before": "TEE_Result syscall_obj_generate_key(unsigned long obj, unsigned long key_size,\n\t\t\tconst struct utee_attribute *usr_params,\n\t\t\tunsigned long param_count)\n{\n\tTEE_Result res;\n\tstruct tee_ta_session *sess;\n\tconst struct tee_cryp_obj_type_props *type_props;\n\tstruct tee_obj *o;\n\tstruct tee_cryp_obj_secret *key;\n\tsize_t byte_size;\n\tTEE_Attribute *params = NULL;\n\n\tres = tee_ta_get_current_session(&sess);\n\tif (res != TEE_SUCCESS)\n\t\treturn res;\n\n\tres = tee_obj_get(to_user_ta_ctx(sess->ctx),\n\t\t\t  tee_svc_uref_to_vaddr(obj), &o);\n\tif (res != TEE_SUCCESS)\n\t\treturn res;\n\n\t/* Must be a transient object */\n\tif ((o->info.handleFlags & TEE_HANDLE_FLAG_PERSISTENT) != 0)\n\t\treturn TEE_ERROR_BAD_STATE;\n\n\t/* Must not be initialized already */\n\tif ((o->info.handleFlags & TEE_HANDLE_FLAG_INITIALIZED) != 0)\n\t\treturn TEE_ERROR_BAD_STATE;\n\n\t/* Find description of object */\n\ttype_props = tee_svc_find_type_props(o->info.objectType);\n\tif (!type_props)\n\t\treturn TEE_ERROR_NOT_SUPPORTED;\n\n\t/* Check that maxKeySize follows restrictions */\n\tif (key_size % type_props->quanta != 0)\n\t\treturn TEE_ERROR_NOT_SUPPORTED;\n\tif (key_size < type_props->min_size)\n\t\treturn TEE_ERROR_NOT_SUPPORTED;\n\tif (key_size > type_props->max_size)\n\t\treturn TEE_ERROR_NOT_SUPPORTED;\n\n\tparams = malloc(sizeof(TEE_Attribute) * param_count);\n\tif (!params)\n\t\treturn TEE_ERROR_OUT_OF_MEMORY;\n\tres = copy_in_attrs(to_user_ta_ctx(sess->ctx), usr_params, param_count,\n\t\t\t    params);\n\tif (res != TEE_SUCCESS)\n\t\tgoto out;\n\n\tres = tee_svc_cryp_check_attr(ATTR_USAGE_GENERATE_KEY, type_props,\n\t\t\t\t      params, param_count);\n\tif (res != TEE_SUCCESS)\n\t\tgoto out;\n\n\tswitch (o->info.objectType) {\n\tcase TEE_TYPE_AES:\n\tcase TEE_TYPE_DES:\n\tcase TEE_TYPE_DES3:\n\tcase TEE_TYPE_HMAC_MD5:\n\tcase TEE_TYPE_HMAC_SHA1:\n\tcase TEE_TYPE_HMAC_SHA224:\n\tcase TEE_TYPE_HMAC_SHA256:\n\tcase TEE_TYPE_HMAC_SHA384:\n\tcase TEE_TYPE_HMAC_SHA512:\n\tcase TEE_TYPE_GENERIC_SECRET:\n\t\tbyte_size = key_size / 8;\n\n\t\t/*\n\t\t * We have to do it like this because the parity bits aren't\n\t\t * counted when telling the size of the key in bits.\n\t\t */\n\t\tif (o->info.objectType == TEE_TYPE_DES ||\n\t\t    o->info.objectType == TEE_TYPE_DES3) {\n\t\t\tbyte_size = (key_size + key_size / 7) / 8;\n\t\t}\n\n\t\tkey = (struct tee_cryp_obj_secret *)o->attr;\n\t\tif (byte_size > key->alloc_size) {\n\t\t\tres = TEE_ERROR_EXCESS_DATA;\n\t\t\tgoto out;\n\t\t}\n\n\t\tres = crypto_rng_read((void *)(key + 1), byte_size);\n\t\tif (res != TEE_SUCCESS)\n\t\t\tgoto out;\n\n\t\tkey->key_size = byte_size;\n\n\t\t/* Set bits for all known attributes for this object type */\n\t\to->have_attrs = (1 << type_props->num_type_attrs) - 1;\n\n\t\tbreak;\n\n\tcase TEE_TYPE_RSA_KEYPAIR:\n\t\tres = tee_svc_obj_generate_key_rsa(o, type_props, key_size,\n\t\t\t\t\t\t   params, param_count);\n\t\tif (res != TEE_SUCCESS)\n\t\t\tgoto out;\n\t\tbreak;\n\n\tcase TEE_TYPE_DSA_KEYPAIR:\n\t\tres = tee_svc_obj_generate_key_dsa(o, type_props, key_size);\n\t\tif (res != TEE_SUCCESS)\n\t\t\tgoto out;\n\t\tbreak;\n\n\tcase TEE_TYPE_DH_KEYPAIR:\n\t\tres = tee_svc_obj_generate_key_dh(o, type_props, key_size,\n\t\t\t\t\t\t  params, param_count);\n\t\tif (res != TEE_SUCCESS)\n\t\t\tgoto out;\n\t\tbreak;\n\n\tcase TEE_TYPE_ECDSA_KEYPAIR:\n\tcase TEE_TYPE_ECDH_KEYPAIR:\n\t\tres = tee_svc_obj_generate_key_ecc(o, type_props, key_size,\n\t\t\t\t\t\t  params, param_count);\n\t\tif (res != TEE_SUCCESS)\n\t\t\tgoto out;\n\t\tbreak;\n\n\tdefault:\n\t\tres = TEE_ERROR_BAD_FORMAT;\n\t}\n\nout:\n\tfree(params);\n\tif (res == TEE_SUCCESS) {\n\t\to->info.keySize = key_size;\n\t\to->info.handleFlags |= TEE_HANDLE_FLAG_INITIALIZED;\n\t}\n\treturn res;\n}",
        "func_after": "TEE_Result syscall_obj_generate_key(unsigned long obj, unsigned long key_size,\n\t\t\tconst struct utee_attribute *usr_params,\n\t\t\tunsigned long param_count)\n{\n\tTEE_Result res;\n\tstruct tee_ta_session *sess;\n\tconst struct tee_cryp_obj_type_props *type_props;\n\tstruct tee_obj *o;\n\tstruct tee_cryp_obj_secret *key;\n\tsize_t byte_size;\n\tTEE_Attribute *params = NULL;\n\n\tres = tee_ta_get_current_session(&sess);\n\tif (res != TEE_SUCCESS)\n\t\treturn res;\n\n\tres = tee_obj_get(to_user_ta_ctx(sess->ctx),\n\t\t\t  tee_svc_uref_to_vaddr(obj), &o);\n\tif (res != TEE_SUCCESS)\n\t\treturn res;\n\n\t/* Must be a transient object */\n\tif ((o->info.handleFlags & TEE_HANDLE_FLAG_PERSISTENT) != 0)\n\t\treturn TEE_ERROR_BAD_STATE;\n\n\t/* Must not be initialized already */\n\tif ((o->info.handleFlags & TEE_HANDLE_FLAG_INITIALIZED) != 0)\n\t\treturn TEE_ERROR_BAD_STATE;\n\n\t/* Find description of object */\n\ttype_props = tee_svc_find_type_props(o->info.objectType);\n\tif (!type_props)\n\t\treturn TEE_ERROR_NOT_SUPPORTED;\n\n\t/* Check that maxKeySize follows restrictions */\n\tif (key_size % type_props->quanta != 0)\n\t\treturn TEE_ERROR_NOT_SUPPORTED;\n\tif (key_size < type_props->min_size)\n\t\treturn TEE_ERROR_NOT_SUPPORTED;\n\tif (key_size > type_props->max_size)\n\t\treturn TEE_ERROR_NOT_SUPPORTED;\n\n\tsize_t alloc_size = 0;\n\n\tif (MUL_OVERFLOW(sizeof(TEE_Attribute), param_count, &alloc_size))\n\t\treturn TEE_ERROR_OVERFLOW;\n\n\tparams = malloc(alloc_size);\n\tif (!params)\n\t\treturn TEE_ERROR_OUT_OF_MEMORY;\n\tres = copy_in_attrs(to_user_ta_ctx(sess->ctx), usr_params, param_count,\n\t\t\t    params);\n\tif (res != TEE_SUCCESS)\n\t\tgoto out;\n\n\tres = tee_svc_cryp_check_attr(ATTR_USAGE_GENERATE_KEY, type_props,\n\t\t\t\t      params, param_count);\n\tif (res != TEE_SUCCESS)\n\t\tgoto out;\n\n\tswitch (o->info.objectType) {\n\tcase TEE_TYPE_AES:\n\tcase TEE_TYPE_DES:\n\tcase TEE_TYPE_DES3:\n\tcase TEE_TYPE_HMAC_MD5:\n\tcase TEE_TYPE_HMAC_SHA1:\n\tcase TEE_TYPE_HMAC_SHA224:\n\tcase TEE_TYPE_HMAC_SHA256:\n\tcase TEE_TYPE_HMAC_SHA384:\n\tcase TEE_TYPE_HMAC_SHA512:\n\tcase TEE_TYPE_GENERIC_SECRET:\n\t\tbyte_size = key_size / 8;\n\n\t\t/*\n\t\t * We have to do it like this because the parity bits aren't\n\t\t * counted when telling the size of the key in bits.\n\t\t */\n\t\tif (o->info.objectType == TEE_TYPE_DES ||\n\t\t    o->info.objectType == TEE_TYPE_DES3) {\n\t\t\tbyte_size = (key_size + key_size / 7) / 8;\n\t\t}\n\n\t\tkey = (struct tee_cryp_obj_secret *)o->attr;\n\t\tif (byte_size > key->alloc_size) {\n\t\t\tres = TEE_ERROR_EXCESS_DATA;\n\t\t\tgoto out;\n\t\t}\n\n\t\tres = crypto_rng_read((void *)(key + 1), byte_size);\n\t\tif (res != TEE_SUCCESS)\n\t\t\tgoto out;\n\n\t\tkey->key_size = byte_size;\n\n\t\t/* Set bits for all known attributes for this object type */\n\t\to->have_attrs = (1 << type_props->num_type_attrs) - 1;\n\n\t\tbreak;\n\n\tcase TEE_TYPE_RSA_KEYPAIR:\n\t\tres = tee_svc_obj_generate_key_rsa(o, type_props, key_size,\n\t\t\t\t\t\t   params, param_count);\n\t\tif (res != TEE_SUCCESS)\n\t\t\tgoto out;\n\t\tbreak;\n\n\tcase TEE_TYPE_DSA_KEYPAIR:\n\t\tres = tee_svc_obj_generate_key_dsa(o, type_props, key_size);\n\t\tif (res != TEE_SUCCESS)\n\t\t\tgoto out;\n\t\tbreak;\n\n\tcase TEE_TYPE_DH_KEYPAIR:\n\t\tres = tee_svc_obj_generate_key_dh(o, type_props, key_size,\n\t\t\t\t\t\t  params, param_count);\n\t\tif (res != TEE_SUCCESS)\n\t\t\tgoto out;\n\t\tbreak;\n\n\tcase TEE_TYPE_ECDSA_KEYPAIR:\n\tcase TEE_TYPE_ECDH_KEYPAIR:\n\t\tres = tee_svc_obj_generate_key_ecc(o, type_props, key_size,\n\t\t\t\t\t\t  params, param_count);\n\t\tif (res != TEE_SUCCESS)\n\t\t\tgoto out;\n\t\tbreak;\n\n\tdefault:\n\t\tres = TEE_ERROR_BAD_FORMAT;\n\t}\n\nout:\n\tfree(params);\n\tif (res == TEE_SUCCESS) {\n\t\to->info.keySize = key_size;\n\t\to->info.handleFlags |= TEE_HANDLE_FLAG_INITIALIZED;\n\t}\n\treturn res;\n}",
        "description": "Linaro/OP-TEE versions 3.3.0 and earlier are vulnerable to a buffer overflow, which could lead to the execution of arbitrary code within the Trusted Execution Environment (TEE) core (kernel) context. This issue affects the optee_os component. The vulnerability has been addressed in versions 3.4.0 and later.",
        "commit": "It was discovered that there is a risk of heap-based overflow due to insufficient checking for allocation overflow in cryptographic function calls. Without verifying the allocation size, there is a possibility of allocating a buffer that is smaller than expected, which could result in attacker-controlled data being written beyond the buffer's boundaries."
    }
]