[
    {
        "cwe": "CWE-476",
        "func_name": "ImageMagick/LoadOpenCLDevices",
        "score": 0.6690937876701355,
        "func_before": "static void LoadOpenCLDevices(MagickCLEnv clEnv)\n{\n  cl_context_properties\n    properties[3];\n\n  cl_device_id\n    *devices;\n\n  cl_int\n    status;\n\n  cl_platform_id\n    *platforms;\n\n  cl_uint\n    i,\n    j,\n    next,\n    number_devices,\n    number_platforms;\n\n  size_t\n    length;\n\n  number_platforms=0;\n  if (openCL_library->clGetPlatformIDs(0,NULL,&number_platforms) != CL_SUCCESS)\n    return;\n  if (number_platforms == 0)\n    return;\n  platforms=(cl_platform_id *) AcquireMagickMemory(number_platforms*\n    sizeof(cl_platform_id));\n  if (platforms == (cl_platform_id *) NULL)\n    return;\n  if (openCL_library->clGetPlatformIDs(number_platforms,platforms,NULL) != CL_SUCCESS)\n    {\n       platforms=(cl_platform_id *) RelinquishMagickMemory(platforms);\n       return;\n    }\n  for (i = 0; i < number_platforms; i++)\n  {\n    number_devices=GetOpenCLDeviceCount(clEnv,platforms[i]);\n    if (number_devices == 0)\n      platforms[i]=(cl_platform_id) NULL;\n    else\n      clEnv->number_devices+=number_devices;\n  }\n  if (clEnv->number_devices == 0)\n    {\n      platforms=(cl_platform_id *) RelinquishMagickMemory(platforms);\n      return;\n    }\n  clEnv->devices=(MagickCLDevice *) AcquireQuantumMemory(clEnv->number_devices,\n    sizeof(MagickCLDevice));\n  if (clEnv->devices == (MagickCLDevice *) NULL)\n    {\n      RelinquishMagickCLDevices(clEnv);\n      platforms=(cl_platform_id *) RelinquishMagickMemory(platforms);\n      return;\n    }\n  (void) ResetMagickMemory(clEnv->devices,0,clEnv->number_devices*\n    sizeof(MagickCLDevice));\n  devices=(cl_device_id *) AcquireQuantumMemory(clEnv->number_devices,\n    sizeof(cl_device_id));\n  if (devices == (cl_device_id *) NULL)\n    {\n      platforms=(cl_platform_id *) RelinquishMagickMemory(platforms);\n      RelinquishMagickCLDevices(clEnv);\n      return;\n    }\n  clEnv->number_contexts=(size_t) number_platforms;\n  clEnv->contexts=(cl_context *) AcquireQuantumMemory(clEnv->number_contexts,\n    sizeof(cl_context));\n  if (clEnv->contexts == (cl_context *) NULL)\n    {\n      devices=(cl_device_id *) RelinquishMagickMemory(devices);\n      platforms=(cl_platform_id *) RelinquishMagickMemory(platforms);\n      RelinquishMagickCLDevices(clEnv);\n      return;\n    }\n  next=0;\n  for (i = 0; i < number_platforms; i++)\n  {\n    if (platforms[i] == (cl_platform_id) NULL)\n      continue;\n\n    status=clEnv->library->clGetDeviceIDs(platforms[i],CL_DEVICE_TYPE_CPU | \n      CL_DEVICE_TYPE_GPU,(cl_uint) clEnv->number_devices,devices,&number_devices);\n    if (status != CL_SUCCESS)\n      continue;\n\n    properties[0]=CL_CONTEXT_PLATFORM;\n    properties[1]=(cl_context_properties) platforms[i];\n    properties[2]=0;\n    clEnv->contexts[i]=openCL_library->clCreateContext(properties,number_devices,\n      devices,NULL,NULL,&status);\n    if (status != CL_SUCCESS)\n      continue;\n\n    for (j = 0; j < number_devices; j++,next++)\n    {\n      MagickCLDevice\n        device;\n\n      device=AcquireMagickCLDevice();\n      if (device == (MagickCLDevice) NULL)\n        break;\n\n      device->context=clEnv->contexts[i];\n      device->deviceID=devices[j];\n\n      openCL_library->clGetPlatformInfo(platforms[i],CL_PLATFORM_NAME,0,NULL,\n        &length);\n      device->platform_name=AcquireQuantumMemory(length,\n        sizeof(*device->platform_name));\n      openCL_library->clGetPlatformInfo(platforms[i],CL_PLATFORM_NAME,length,\n        device->platform_name,NULL);\n\n      openCL_library->clGetPlatformInfo(platforms[i],CL_PLATFORM_VENDOR,0,NULL,\n        &length);\n      device->vendor_name=AcquireQuantumMemory(length,\n        sizeof(*device->vendor_name));\n      openCL_library->clGetPlatformInfo(platforms[i],CL_PLATFORM_VENDOR,length,\n        device->vendor_name,NULL);\n\n      openCL_library->clGetDeviceInfo(devices[j],CL_DEVICE_NAME,0,NULL,\n        &length);\n      device->name=AcquireQuantumMemory(length,sizeof(*device->name));\n      openCL_library->clGetDeviceInfo(devices[j],CL_DEVICE_NAME,length,\n        device->name,NULL);\n\n      openCL_library->clGetDeviceInfo(devices[j],CL_DRIVER_VERSION,0,NULL,\n        &length);\n      device->version=AcquireQuantumMemory(length,sizeof(*device->version));\n      openCL_library->clGetDeviceInfo(devices[j],CL_DRIVER_VERSION,length,\n        device->version,NULL);\n\n      openCL_library->clGetDeviceInfo(devices[j],CL_DEVICE_MAX_CLOCK_FREQUENCY,\n        sizeof(cl_uint),&device->max_clock_frequency,NULL);\n\n      openCL_library->clGetDeviceInfo(devices[j],CL_DEVICE_MAX_COMPUTE_UNITS,\n        sizeof(cl_uint),&device->max_compute_units,NULL);\n\n      openCL_library->clGetDeviceInfo(devices[j],CL_DEVICE_TYPE,\n        sizeof(cl_device_type),&device->type,NULL);\n\n      openCL_library->clGetDeviceInfo(devices[j],CL_DEVICE_LOCAL_MEM_SIZE,\n        sizeof(cl_ulong),&device->local_memory_size,NULL);\n\n      clEnv->devices[next]=device;\n    }\n  }\n  if (next != clEnv->number_devices)\n    RelinquishMagickCLDevices(clEnv);\n  platforms=(cl_platform_id *) RelinquishMagickMemory(platforms);\n  devices=(cl_device_id *) RelinquishMagickMemory(devices);\n}",
        "func_after": "static void LoadOpenCLDevices(MagickCLEnv clEnv)\n{\n  cl_context_properties\n    properties[3];\n\n  cl_device_id\n    *devices;\n\n  cl_int\n    status;\n\n  cl_platform_id\n    *platforms;\n\n  cl_uint\n    i,\n    j,\n    next,\n    number_devices,\n    number_platforms;\n\n  size_t\n    length;\n\n  number_platforms=0;\n  if (openCL_library->clGetPlatformIDs(0,NULL,&number_platforms) != CL_SUCCESS)\n    return;\n  if (number_platforms == 0)\n    return;\n  platforms=(cl_platform_id *) AcquireMagickMemory(number_platforms*\n    sizeof(cl_platform_id));\n  if (platforms == (cl_platform_id *) NULL)\n    return;\n  if (openCL_library->clGetPlatformIDs(number_platforms,platforms,NULL) != CL_SUCCESS)\n    {\n       platforms=(cl_platform_id *) RelinquishMagickMemory(platforms);\n       return;\n    }\n  for (i = 0; i < number_platforms; i++)\n  {\n    number_devices=GetOpenCLDeviceCount(clEnv,platforms[i]);\n    if (number_devices == 0)\n      platforms[i]=(cl_platform_id) NULL;\n    else\n      clEnv->number_devices+=number_devices;\n  }\n  if (clEnv->number_devices == 0)\n    {\n      platforms=(cl_platform_id *) RelinquishMagickMemory(platforms);\n      return;\n    }\n  clEnv->devices=(MagickCLDevice *) AcquireQuantumMemory(clEnv->number_devices,\n    sizeof(MagickCLDevice));\n  if (clEnv->devices == (MagickCLDevice *) NULL)\n    {\n      RelinquishMagickCLDevices(clEnv);\n      platforms=(cl_platform_id *) RelinquishMagickMemory(platforms);\n      return;\n    }\n  (void) ResetMagickMemory(clEnv->devices,0,clEnv->number_devices*\n    sizeof(MagickCLDevice));\n  devices=(cl_device_id *) AcquireQuantumMemory(clEnv->number_devices,\n    sizeof(cl_device_id));\n  if (devices == (cl_device_id *) NULL)\n    {\n      platforms=(cl_platform_id *) RelinquishMagickMemory(platforms);\n      RelinquishMagickCLDevices(clEnv);\n      return;\n    }\n  clEnv->number_contexts=(size_t) number_platforms;\n  clEnv->contexts=(cl_context *) AcquireQuantumMemory(clEnv->number_contexts,\n    sizeof(cl_context));\n  if (clEnv->contexts == (cl_context *) NULL)\n    {\n      devices=(cl_device_id *) RelinquishMagickMemory(devices);\n      platforms=(cl_platform_id *) RelinquishMagickMemory(platforms);\n      RelinquishMagickCLDevices(clEnv);\n      return;\n    }\n  next=0;\n  for (i = 0; i < number_platforms; i++)\n  {\n    if (platforms[i] == (cl_platform_id) NULL)\n      continue;\n\n    status=clEnv->library->clGetDeviceIDs(platforms[i],CL_DEVICE_TYPE_CPU | \n      CL_DEVICE_TYPE_GPU,(cl_uint) clEnv->number_devices,devices,&number_devices);\n    if (status != CL_SUCCESS)\n      continue;\n\n    properties[0]=CL_CONTEXT_PLATFORM;\n    properties[1]=(cl_context_properties) platforms[i];\n    properties[2]=0;\n    clEnv->contexts[i]=openCL_library->clCreateContext(properties,number_devices,\n      devices,NULL,NULL,&status);\n    if (status != CL_SUCCESS)\n      continue;\n\n    for (j = 0; j < number_devices; j++,next++)\n    {\n      MagickCLDevice\n        device;\n\n      device=AcquireMagickCLDevice();\n      if (device == (MagickCLDevice) NULL)\n        break;\n\n      device->context=clEnv->contexts[i];\n      device->deviceID=devices[j];\n\n      openCL_library->clGetPlatformInfo(platforms[i],CL_PLATFORM_NAME,0,NULL,\n        &length);\n      device->platform_name=AcquireCriticalMemory(length*\n        sizeof(*device->platform_name));\n      openCL_library->clGetPlatformInfo(platforms[i],CL_PLATFORM_NAME,length,\n        device->platform_name,NULL);\n\n      openCL_library->clGetPlatformInfo(platforms[i],CL_PLATFORM_VENDOR,0,NULL,\n        &length);\n      device->vendor_name=AcquireQuantumMemory(length,\n        sizeof(*device->vendor_name));\n      openCL_library->clGetPlatformInfo(platforms[i],CL_PLATFORM_VENDOR,length,\n        device->vendor_name,NULL);\n\n      openCL_library->clGetDeviceInfo(devices[j],CL_DEVICE_NAME,0,NULL,\n        &length);\n      device->name=AcquireQuantumMemory(length,sizeof(*device->name));\n      openCL_library->clGetDeviceInfo(devices[j],CL_DEVICE_NAME,length,\n        device->name,NULL);\n\n      openCL_library->clGetDeviceInfo(devices[j],CL_DRIVER_VERSION,0,NULL,\n        &length);\n      device->version=AcquireQuantumMemory(length,sizeof(*device->version));\n      openCL_library->clGetDeviceInfo(devices[j],CL_DRIVER_VERSION,length,\n        device->version,NULL);\n\n      openCL_library->clGetDeviceInfo(devices[j],CL_DEVICE_MAX_CLOCK_FREQUENCY,\n        sizeof(cl_uint),&device->max_clock_frequency,NULL);\n\n      openCL_library->clGetDeviceInfo(devices[j],CL_DEVICE_MAX_COMPUTE_UNITS,\n        sizeof(cl_uint),&device->max_compute_units,NULL);\n\n      openCL_library->clGetDeviceInfo(devices[j],CL_DEVICE_TYPE,\n        sizeof(cl_device_type),&device->type,NULL);\n\n      openCL_library->clGetDeviceInfo(devices[j],CL_DEVICE_LOCAL_MEM_SIZE,\n        sizeof(cl_ulong),&device->local_memory_size,NULL);\n\n      clEnv->devices[next]=device;\n    }\n  }\n  if (next != clEnv->number_devices)\n    RelinquishMagickCLDevices(clEnv);\n  platforms=(cl_platform_id *) RelinquishMagickMemory(platforms);\n  devices=(cl_device_id *) RelinquishMagickMemory(devices);\n}",
        "description": "An issue was discovered in ImageMagick where a NULL pointer dereference vulnerability exists in the function responsible for loading OpenCL devices. This flaw allows attackers to trigger a denial of service through the use of a specially crafted file.",
        "commit": "It was discovered that ImageMagick, a popular image processing library, contains a vulnerability related to improper handling of certain image formats, potentially leading to buffer overflows or other memory corruption issues."
    },
    {
        "cwe": "CWE-681",
        "func_name": "FreeRDP/update_recv_secondary_order",
        "score": 0.6655503511428833,
        "func_before": "static BOOL update_recv_secondary_order(rdpUpdate* update, wStream* s, BYTE flags)\n{\n\tBOOL rc = FALSE;\n\tsize_t start, end, diff;\n\tBYTE orderType;\n\tUINT16 extraFlags;\n\tUINT16 orderLength;\n\trdpContext* context = update->context;\n\trdpSettings* settings = context->settings;\n\trdpSecondaryUpdate* secondary = update->secondary;\n\tconst char* name;\n\n\tif (Stream_GetRemainingLength(s) < 5)\n\t{\n\t\tWLog_Print(update->log, WLOG_ERROR, \"Stream_GetRemainingLength(s) < 5\");\n\t\treturn FALSE;\n\t}\n\n\tStream_Read_UINT16(s, orderLength); /* orderLength (2 bytes) */\n\tStream_Read_UINT16(s, extraFlags);  /* extraFlags (2 bytes) */\n\tStream_Read_UINT8(s, orderType);    /* orderType (1 byte) */\n\tif (Stream_GetRemainingLength(s) < orderLength + 7U)\n\t{\n\t\tWLog_Print(update->log, WLOG_ERROR, \"Stream_GetRemainingLength(s) %\" PRIuz \" < %\" PRIu16,\n\t\t           Stream_GetRemainingLength(s), orderLength + 7);\n\t\treturn FALSE;\n\t}\n\n\tstart = Stream_GetPosition(s);\n\tname = secondary_order_string(orderType);\n\tWLog_Print(update->log, WLOG_DEBUG, \"Secondary Drawing Order %s\", name);\n\n\tif (!check_secondary_order_supported(update->log, settings, orderType, name))\n\t\treturn FALSE;\n\n\tswitch (orderType)\n\t{\n\t\tcase ORDER_TYPE_BITMAP_UNCOMPRESSED:\n\t\tcase ORDER_TYPE_CACHE_BITMAP_COMPRESSED:\n\t\t{\n\t\t\tconst BOOL compressed = (orderType == ORDER_TYPE_CACHE_BITMAP_COMPRESSED);\n\t\t\tCACHE_BITMAP_ORDER* order =\n\t\t\t    update_read_cache_bitmap_order(update, s, compressed, extraFlags);\n\n\t\t\tif (order)\n\t\t\t{\n\t\t\t\trc = IFCALLRESULT(FALSE, secondary->CacheBitmap, context, order);\n\t\t\t\tfree_cache_bitmap_order(context, order);\n\t\t\t}\n\t\t}\n\t\tbreak;\n\n\t\tcase ORDER_TYPE_BITMAP_UNCOMPRESSED_V2:\n\t\tcase ORDER_TYPE_BITMAP_COMPRESSED_V2:\n\t\t{\n\t\t\tconst BOOL compressed = (orderType == ORDER_TYPE_BITMAP_COMPRESSED_V2);\n\t\t\tCACHE_BITMAP_V2_ORDER* order =\n\t\t\t    update_read_cache_bitmap_v2_order(update, s, compressed, extraFlags);\n\n\t\t\tif (order)\n\t\t\t{\n\t\t\t\trc = IFCALLRESULT(FALSE, secondary->CacheBitmapV2, context, order);\n\t\t\t\tfree_cache_bitmap_v2_order(context, order);\n\t\t\t}\n\t\t}\n\t\tbreak;\n\n\t\tcase ORDER_TYPE_BITMAP_COMPRESSED_V3:\n\t\t{\n\t\t\tCACHE_BITMAP_V3_ORDER* order = update_read_cache_bitmap_v3_order(update, s, extraFlags);\n\n\t\t\tif (order)\n\t\t\t{\n\t\t\t\trc = IFCALLRESULT(FALSE, secondary->CacheBitmapV3, context, order);\n\t\t\t\tfree_cache_bitmap_v3_order(context, order);\n\t\t\t}\n\t\t}\n\t\tbreak;\n\n\t\tcase ORDER_TYPE_CACHE_COLOR_TABLE:\n\t\t{\n\t\t\tCACHE_COLOR_TABLE_ORDER* order =\n\t\t\t    update_read_cache_color_table_order(update, s, extraFlags);\n\n\t\t\tif (order)\n\t\t\t{\n\t\t\t\trc = IFCALLRESULT(FALSE, secondary->CacheColorTable, context, order);\n\t\t\t\tfree_cache_color_table_order(context, order);\n\t\t\t}\n\t\t}\n\t\tbreak;\n\n\t\tcase ORDER_TYPE_CACHE_GLYPH:\n\t\t{\n\t\t\tswitch (settings->GlyphSupportLevel)\n\t\t\t{\n\t\t\t\tcase GLYPH_SUPPORT_PARTIAL:\n\t\t\t\tcase GLYPH_SUPPORT_FULL:\n\t\t\t\t{\n\t\t\t\t\tCACHE_GLYPH_ORDER* order = update_read_cache_glyph_order(update, s, extraFlags);\n\n\t\t\t\t\tif (order)\n\t\t\t\t\t{\n\t\t\t\t\t\trc = IFCALLRESULT(FALSE, secondary->CacheGlyph, context, order);\n\t\t\t\t\t\tfree_cache_glyph_order(context, order);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tbreak;\n\n\t\t\t\tcase GLYPH_SUPPORT_ENCODE:\n\t\t\t\t{\n\t\t\t\t\tCACHE_GLYPH_V2_ORDER* order =\n\t\t\t\t\t    update_read_cache_glyph_v2_order(update, s, extraFlags);\n\n\t\t\t\t\tif (order)\n\t\t\t\t\t{\n\t\t\t\t\t\trc = IFCALLRESULT(FALSE, secondary->CacheGlyphV2, context, order);\n\t\t\t\t\t\tfree_cache_glyph_v2_order(context, order);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tbreak;\n\n\t\t\t\tcase GLYPH_SUPPORT_NONE:\n\t\t\t\tdefault:\n\t\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tbreak;\n\n\t\tcase ORDER_TYPE_CACHE_BRUSH:\n\t\t\t/* [MS-RDPEGDI] 2.2.2.2.1.2.7 Cache Brush (CACHE_BRUSH_ORDER) */\n\t\t\t{\n\t\t\t\tCACHE_BRUSH_ORDER* order = update_read_cache_brush_order(update, s, extraFlags);\n\n\t\t\t\tif (order)\n\t\t\t\t{\n\t\t\t\t\trc = IFCALLRESULT(FALSE, secondary->CacheBrush, context, order);\n\t\t\t\t\tfree_cache_brush_order(context, order);\n\t\t\t\t}\n\t\t\t}\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tWLog_Print(update->log, WLOG_WARN, \"SECONDARY ORDER %s not supported\", name);\n\t\t\tbreak;\n\t}\n\n\tif (!rc)\n\t{\n\t\tWLog_Print(update->log, WLOG_ERROR, \"SECONDARY ORDER %s failed\", name);\n\t}\n\n\tstart += orderLength + 7;\n\tend = Stream_GetPosition(s);\n\tif (start > end)\n\t{\n\t\tWLog_Print(update->log, WLOG_WARN, \"SECONDARY_ORDER %s: read %\" PRIuz \"bytes too much\",\n\t\t           name, end - start);\n\t\treturn FALSE;\n\t}\n\tdiff = start - end;\n\tif (diff > 0)\n\t{\n\t\tWLog_Print(update->log, WLOG_DEBUG,\n\t\t           \"SECONDARY_ORDER %s: read %\" PRIuz \"bytes short, skipping\", name, diff);\n\t\tStream_Seek(s, diff);\n\t}\n\treturn rc;\n}",
        "func_after": "static BOOL update_recv_secondary_order(rdpUpdate* update, wStream* s, BYTE flags)\n{\n\tBOOL rc = FALSE;\n\tsize_t start, end, diff;\n\tBYTE orderType;\n\tUINT16 extraFlags;\n\tUINT16 orderLength;\n\trdpContext* context = update->context;\n\trdpSettings* settings = context->settings;\n\trdpSecondaryUpdate* secondary = update->secondary;\n\tconst char* name;\n\n\tif (Stream_GetRemainingLength(s) < 5)\n\t{\n\t\tWLog_Print(update->log, WLOG_ERROR, \"Stream_GetRemainingLength(s) < 5\");\n\t\treturn FALSE;\n\t}\n\n\tStream_Read_UINT16(s, orderLength); /* orderLength (2 bytes) */\n\tStream_Read_UINT16(s, extraFlags);  /* extraFlags (2 bytes) */\n\tStream_Read_UINT8(s, orderType);    /* orderType (1 byte) */\n\tif (Stream_GetRemainingLength(s) < orderLength + 7U)\n\t{\n\t\tWLog_Print(update->log, WLOG_ERROR, \"Stream_GetRemainingLength(s) %\" PRIuz \" < %\" PRIu16,\n\t\t           Stream_GetRemainingLength(s), orderLength + 7);\n\t\treturn FALSE;\n\t}\n\n\tstart = Stream_GetPosition(s);\n\tname = secondary_order_string(orderType);\n\tWLog_Print(update->log, WLOG_DEBUG, \"Secondary Drawing Order %s\", name);\n\n\tif (!check_secondary_order_supported(update->log, settings, orderType, name))\n\t\treturn FALSE;\n\n\tswitch (orderType)\n\t{\n\t\tcase ORDER_TYPE_BITMAP_UNCOMPRESSED:\n\t\tcase ORDER_TYPE_CACHE_BITMAP_COMPRESSED:\n\t\t{\n\t\t\tconst BOOL compressed = (orderType == ORDER_TYPE_CACHE_BITMAP_COMPRESSED);\n\t\t\tCACHE_BITMAP_ORDER* order =\n\t\t\t    update_read_cache_bitmap_order(update, s, compressed, extraFlags);\n\n\t\t\tif (order)\n\t\t\t{\n\t\t\t\trc = IFCALLRESULT(FALSE, secondary->CacheBitmap, context, order);\n\t\t\t\tfree_cache_bitmap_order(context, order);\n\t\t\t}\n\t\t}\n\t\tbreak;\n\n\t\tcase ORDER_TYPE_BITMAP_UNCOMPRESSED_V2:\n\t\tcase ORDER_TYPE_BITMAP_COMPRESSED_V2:\n\t\t{\n\t\t\tconst BOOL compressed = (orderType == ORDER_TYPE_BITMAP_COMPRESSED_V2);\n\t\t\tCACHE_BITMAP_V2_ORDER* order =\n\t\t\t    update_read_cache_bitmap_v2_order(update, s, compressed, extraFlags);\n\n\t\t\tif (order)\n\t\t\t{\n\t\t\t\trc = IFCALLRESULT(FALSE, secondary->CacheBitmapV2, context, order);\n\t\t\t\tfree_cache_bitmap_v2_order(context, order);\n\t\t\t}\n\t\t}\n\t\tbreak;\n\n\t\tcase ORDER_TYPE_BITMAP_COMPRESSED_V3:\n\t\t{\n\t\t\tCACHE_BITMAP_V3_ORDER* order = update_read_cache_bitmap_v3_order(update, s, extraFlags);\n\n\t\t\tif (order)\n\t\t\t{\n\t\t\t\trc = IFCALLRESULT(FALSE, secondary->CacheBitmapV3, context, order);\n\t\t\t\tfree_cache_bitmap_v3_order(context, order);\n\t\t\t}\n\t\t}\n\t\tbreak;\n\n\t\tcase ORDER_TYPE_CACHE_COLOR_TABLE:\n\t\t{\n\t\t\tCACHE_COLOR_TABLE_ORDER* order =\n\t\t\t    update_read_cache_color_table_order(update, s, extraFlags);\n\n\t\t\tif (order)\n\t\t\t{\n\t\t\t\trc = IFCALLRESULT(FALSE, secondary->CacheColorTable, context, order);\n\t\t\t\tfree_cache_color_table_order(context, order);\n\t\t\t}\n\t\t}\n\t\tbreak;\n\n\t\tcase ORDER_TYPE_CACHE_GLYPH:\n\t\t{\n\t\t\tswitch (settings->GlyphSupportLevel)\n\t\t\t{\n\t\t\t\tcase GLYPH_SUPPORT_PARTIAL:\n\t\t\t\tcase GLYPH_SUPPORT_FULL:\n\t\t\t\t{\n\t\t\t\t\tCACHE_GLYPH_ORDER* order = update_read_cache_glyph_order(update, s, extraFlags);\n\n\t\t\t\t\tif (order)\n\t\t\t\t\t{\n\t\t\t\t\t\trc = IFCALLRESULT(FALSE, secondary->CacheGlyph, context, order);\n\t\t\t\t\t\tfree_cache_glyph_order(context, order);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tbreak;\n\n\t\t\t\tcase GLYPH_SUPPORT_ENCODE:\n\t\t\t\t{\n\t\t\t\t\tCACHE_GLYPH_V2_ORDER* order =\n\t\t\t\t\t    update_read_cache_glyph_v2_order(update, s, extraFlags);\n\n\t\t\t\t\tif (order)\n\t\t\t\t\t{\n\t\t\t\t\t\trc = IFCALLRESULT(FALSE, secondary->CacheGlyphV2, context, order);\n\t\t\t\t\t\tfree_cache_glyph_v2_order(context, order);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tbreak;\n\n\t\t\t\tcase GLYPH_SUPPORT_NONE:\n\t\t\t\tdefault:\n\t\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tbreak;\n\n\t\tcase ORDER_TYPE_CACHE_BRUSH:\n\t\t\t/* [MS-RDPEGDI] 2.2.2.2.1.2.7 Cache Brush (CACHE_BRUSH_ORDER) */\n\t\t\t{\n\t\t\t\tCACHE_BRUSH_ORDER* order = update_read_cache_brush_order(update, s, extraFlags);\n\n\t\t\t\tif (order)\n\t\t\t\t{\n\t\t\t\t\trc = IFCALLRESULT(FALSE, secondary->CacheBrush, context, order);\n\t\t\t\t\tfree_cache_brush_order(context, order);\n\t\t\t\t}\n\t\t\t}\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tWLog_Print(update->log, WLOG_WARN, \"SECONDARY ORDER %s not supported\", name);\n\t\t\tbreak;\n\t}\n\n\tif (!rc)\n\t{\n\t\tWLog_Print(update->log, WLOG_ERROR, \"SECONDARY ORDER %s failed\", name);\n\t}\n\n\tstart += orderLength + 7;\n\tend = Stream_GetPosition(s);\n\tif (start > end)\n\t{\n\t\tWLog_Print(update->log, WLOG_WARN, \"SECONDARY_ORDER %s: read %\" PRIuz \"bytes too much\",\n\t\t           name, end - start);\n\t\treturn FALSE;\n\t}\n\tdiff = end - start;\n\tif (diff > 0)\n\t{\n\t\tWLog_Print(update->log, WLOG_DEBUG,\n\t\t           \"SECONDARY_ORDER %s: read %\" PRIuz \"bytes short, skipping\", name, diff);\n\t\tif (!Stream_SafeSeek(s, diff))\n\t\t\treturn FALSE;\n\t}\n\treturn rc;\n}",
        "description": "In FreeRDP versions prior to 2.1.2, there exists an integer casting vulnerability within the `update_recv_secondary_order` function. This vulnerability affects all clients configured with both `+glyph-cache` and `relax-order-checks` options. This issue has been addressed in version 2.1.2.",
        "commit": "An out-of-bounds (OOB) read vulnerability was addressed in the `update_recv_secondary_order` function. This issue was identified and reported by @antonio-morales."
    },
    {
        "cwe": "CWE-787",
        "func_name": "OP-TEE/syscall_asymm_verify",
        "score": 0.6752598881721497,
        "func_before": "TEE_Result syscall_asymm_verify(unsigned long state,\n\t\t\tconst struct utee_attribute *usr_params,\n\t\t\tsize_t num_params, const void *data, size_t data_len,\n\t\t\tconst void *sig, size_t sig_len)\n{\n\tTEE_Result res;\n\tstruct tee_cryp_state *cs;\n\tstruct tee_ta_session *sess;\n\tstruct tee_obj *o;\n\tsize_t hash_size;\n\tint salt_len = 0;\n\tTEE_Attribute *params = NULL;\n\tuint32_t hash_algo;\n\tstruct user_ta_ctx *utc;\n\n\tres = tee_ta_get_current_session(&sess);\n\tif (res != TEE_SUCCESS)\n\t\treturn res;\n\tutc = to_user_ta_ctx(sess->ctx);\n\n\tres = tee_svc_cryp_get_state(sess, tee_svc_uref_to_vaddr(state), &cs);\n\tif (res != TEE_SUCCESS)\n\t\treturn res;\n\n\tif (cs->mode != TEE_MODE_VERIFY)\n\t\treturn TEE_ERROR_BAD_PARAMETERS;\n\n\tres = tee_mmu_check_access_rights(utc,\n\t\t\t\t\t  TEE_MEMORY_ACCESS_READ |\n\t\t\t\t\t  TEE_MEMORY_ACCESS_ANY_OWNER,\n\t\t\t\t\t  (uaddr_t)data, data_len);\n\tif (res != TEE_SUCCESS)\n\t\treturn res;\n\n\tres = tee_mmu_check_access_rights(utc,\n\t\t\t\t\t  TEE_MEMORY_ACCESS_READ |\n\t\t\t\t\t  TEE_MEMORY_ACCESS_ANY_OWNER,\n\t\t\t\t\t  (uaddr_t)sig, sig_len);\n\tif (res != TEE_SUCCESS)\n\t\treturn res;\n\n\tparams = malloc(sizeof(TEE_Attribute) * num_params);\n\tif (!params)\n\t\treturn TEE_ERROR_OUT_OF_MEMORY;\n\tres = copy_in_attrs(utc, usr_params, num_params, params);\n\tif (res != TEE_SUCCESS)\n\t\tgoto out;\n\n\tres = tee_obj_get(utc, cs->key1, &o);\n\tif (res != TEE_SUCCESS)\n\t\tgoto out;\n\tif ((o->info.handleFlags & TEE_HANDLE_FLAG_INITIALIZED) == 0) {\n\t\tres = TEE_ERROR_BAD_PARAMETERS;\n\t\tgoto out;\n\t}\n\n\tswitch (TEE_ALG_GET_MAIN_ALG(cs->algo)) {\n\tcase TEE_MAIN_ALGO_RSA:\n\t\tif (cs->algo != TEE_ALG_RSASSA_PKCS1_V1_5) {\n\t\t\thash_algo = TEE_DIGEST_HASH_TO_ALGO(cs->algo);\n\t\t\tres = tee_hash_get_digest_size(hash_algo, &hash_size);\n\t\t\tif (res != TEE_SUCCESS)\n\t\t\t\tbreak;\n\t\t\tif (data_len != hash_size) {\n\t\t\t\tres = TEE_ERROR_BAD_PARAMETERS;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tsalt_len = pkcs1_get_salt_len(params, num_params,\n\t\t\t\t\t\t      hash_size);\n\t\t}\n\t\tres = crypto_acipher_rsassa_verify(cs->algo, o->attr, salt_len,\n\t\t\t\t\t\t   data, data_len, sig,\n\t\t\t\t\t\t   sig_len);\n\t\tbreak;\n\n\tcase TEE_MAIN_ALGO_DSA:\n\t\thash_algo = TEE_DIGEST_HASH_TO_ALGO(cs->algo);\n\t\tres = tee_hash_get_digest_size(hash_algo, &hash_size);\n\t\tif (res != TEE_SUCCESS)\n\t\t\tbreak;\n\t\t/*\n\t\t * Depending on the DSA algorithm (NIST), the digital signature\n\t\t * output size may be truncated to the size of a key pair\n\t\t * (Q prime size). Q prime size must be less or equal than the\n\t\t * hash output length of the hash algorithm involved.\n\t\t */\n\t\tif (data_len > hash_size) {\n\t\t\tres = TEE_ERROR_BAD_PARAMETERS;\n\t\t\tbreak;\n\t\t}\n\t\tres = crypto_acipher_dsa_verify(cs->algo, o->attr, data,\n\t\t\t\t\t\tdata_len, sig, sig_len);\n\t\tbreak;\n\n\tcase TEE_MAIN_ALGO_ECDSA:\n\t\tres = crypto_acipher_ecc_verify(cs->algo, o->attr, data,\n\t\t\t\t\t\tdata_len, sig, sig_len);\n\t\tbreak;\n\n\tdefault:\n\t\tres = TEE_ERROR_NOT_SUPPORTED;\n\t}\n\nout:\n\tfree(params);\n\treturn res;\n}",
        "func_after": "TEE_Result syscall_asymm_verify(unsigned long state,\n\t\t\tconst struct utee_attribute *usr_params,\n\t\t\tsize_t num_params, const void *data, size_t data_len,\n\t\t\tconst void *sig, size_t sig_len)\n{\n\tTEE_Result res;\n\tstruct tee_cryp_state *cs;\n\tstruct tee_ta_session *sess;\n\tstruct tee_obj *o;\n\tsize_t hash_size;\n\tint salt_len = 0;\n\tTEE_Attribute *params = NULL;\n\tuint32_t hash_algo;\n\tstruct user_ta_ctx *utc;\n\n\tres = tee_ta_get_current_session(&sess);\n\tif (res != TEE_SUCCESS)\n\t\treturn res;\n\tutc = to_user_ta_ctx(sess->ctx);\n\n\tres = tee_svc_cryp_get_state(sess, tee_svc_uref_to_vaddr(state), &cs);\n\tif (res != TEE_SUCCESS)\n\t\treturn res;\n\n\tif (cs->mode != TEE_MODE_VERIFY)\n\t\treturn TEE_ERROR_BAD_PARAMETERS;\n\n\tres = tee_mmu_check_access_rights(utc,\n\t\t\t\t\t  TEE_MEMORY_ACCESS_READ |\n\t\t\t\t\t  TEE_MEMORY_ACCESS_ANY_OWNER,\n\t\t\t\t\t  (uaddr_t)data, data_len);\n\tif (res != TEE_SUCCESS)\n\t\treturn res;\n\n\tres = tee_mmu_check_access_rights(utc,\n\t\t\t\t\t  TEE_MEMORY_ACCESS_READ |\n\t\t\t\t\t  TEE_MEMORY_ACCESS_ANY_OWNER,\n\t\t\t\t\t  (uaddr_t)sig, sig_len);\n\tif (res != TEE_SUCCESS)\n\t\treturn res;\n\n\tsize_t alloc_size = 0;\n\n\tif (MUL_OVERFLOW(sizeof(TEE_Attribute), num_params, &alloc_size))\n\t\treturn TEE_ERROR_OVERFLOW;\n\n\tparams = malloc(alloc_size);\n\tif (!params)\n\t\treturn TEE_ERROR_OUT_OF_MEMORY;\n\tres = copy_in_attrs(utc, usr_params, num_params, params);\n\tif (res != TEE_SUCCESS)\n\t\tgoto out;\n\n\tres = tee_obj_get(utc, cs->key1, &o);\n\tif (res != TEE_SUCCESS)\n\t\tgoto out;\n\tif ((o->info.handleFlags & TEE_HANDLE_FLAG_INITIALIZED) == 0) {\n\t\tres = TEE_ERROR_BAD_PARAMETERS;\n\t\tgoto out;\n\t}\n\n\tswitch (TEE_ALG_GET_MAIN_ALG(cs->algo)) {\n\tcase TEE_MAIN_ALGO_RSA:\n\t\tif (cs->algo != TEE_ALG_RSASSA_PKCS1_V1_5) {\n\t\t\thash_algo = TEE_DIGEST_HASH_TO_ALGO(cs->algo);\n\t\t\tres = tee_hash_get_digest_size(hash_algo, &hash_size);\n\t\t\tif (res != TEE_SUCCESS)\n\t\t\t\tbreak;\n\t\t\tif (data_len != hash_size) {\n\t\t\t\tres = TEE_ERROR_BAD_PARAMETERS;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tsalt_len = pkcs1_get_salt_len(params, num_params,\n\t\t\t\t\t\t      hash_size);\n\t\t}\n\t\tres = crypto_acipher_rsassa_verify(cs->algo, o->attr, salt_len,\n\t\t\t\t\t\t   data, data_len, sig,\n\t\t\t\t\t\t   sig_len);\n\t\tbreak;\n\n\tcase TEE_MAIN_ALGO_DSA:\n\t\thash_algo = TEE_DIGEST_HASH_TO_ALGO(cs->algo);\n\t\tres = tee_hash_get_digest_size(hash_algo, &hash_size);\n\t\tif (res != TEE_SUCCESS)\n\t\t\tbreak;\n\t\t/*\n\t\t * Depending on the DSA algorithm (NIST), the digital signature\n\t\t * output size may be truncated to the size of a key pair\n\t\t * (Q prime size). Q prime size must be less or equal than the\n\t\t * hash output length of the hash algorithm involved.\n\t\t */\n\t\tif (data_len > hash_size) {\n\t\t\tres = TEE_ERROR_BAD_PARAMETERS;\n\t\t\tbreak;\n\t\t}\n\t\tres = crypto_acipher_dsa_verify(cs->algo, o->attr, data,\n\t\t\t\t\t\tdata_len, sig, sig_len);\n\t\tbreak;\n\n\tcase TEE_MAIN_ALGO_ECDSA:\n\t\tres = crypto_acipher_ecc_verify(cs->algo, o->attr, data,\n\t\t\t\t\t\tdata_len, sig, sig_len);\n\t\tbreak;\n\n\tdefault:\n\t\tres = TEE_ERROR_NOT_SUPPORTED;\n\t}\n\nout:\n\tfree(params);\n\treturn res;\n}",
        "description": "Linaro/OP-TEE versions 3.3.0 and earlier are vulnerable to a buffer overflow, which could lead to code execution within the Trusted Execution Environment (TEE) core (kernel) context. This issue affects the optee_os component. The vulnerability has been addressed in versions 3.4.0 and later.",
        "commit": "Without performing overflow checks during buffer allocation in cryptographic operations, there is a risk of allocating a buffer that is smaller than intended. This can result in a heap-based overflow, allowing attackers to write data outside the buffer's boundaries."
    },
    {
        "cwe": "CWE-125",
        "func_name": "the-tcpdump-group/nfsreq_print_noaddr",
        "score": 0.6742739081382751,
        "func_before": "void\nnfsreq_print_noaddr(netdissect_options *ndo,\n                    register const u_char *bp, u_int length,\n                    register const u_char *bp2)\n{\n\tregister const struct sunrpc_msg *rp;\n\tregister const uint32_t *dp;\n\tnfs_type type;\n\tint v3;\n\tuint32_t proc;\n\tuint32_t access_flags;\n\tstruct nfsv3_sattr sa3;\n\n\tND_PRINT((ndo, \"%d\", length));\n\tnfserr = 0;\t\t/* assume no error */\n\trp = (const struct sunrpc_msg *)bp;\n\n\tif (!xid_map_enter(ndo, rp, bp2))\t/* record proc number for later on */\n\t\tgoto trunc;\n\n\tv3 = (EXTRACT_32BITS(&rp->rm_call.cb_vers) == NFS_VER3);\n\tproc = EXTRACT_32BITS(&rp->rm_call.cb_proc);\n\n\tif (!v3 && proc < NFS_NPROCS)\n\t\tproc =  nfsv3_procid[proc];\n\n\tND_PRINT((ndo, \" %s\", tok2str(nfsproc_str, \"proc-%u\", proc)));\n\tswitch (proc) {\n\n\tcase NFSPROC_GETATTR:\n\tcase NFSPROC_SETATTR:\n\tcase NFSPROC_READLINK:\n\tcase NFSPROC_FSSTAT:\n\tcase NFSPROC_FSINFO:\n\tcase NFSPROC_PATHCONF:\n\t\tif ((dp = parsereq(ndo, rp, length)) != NULL &&\n\t\t    parsefh(ndo, dp, v3) != NULL)\n\t\t\treturn;\n\t\tbreak;\n\n\tcase NFSPROC_LOOKUP:\n\tcase NFSPROC_CREATE:\n\tcase NFSPROC_MKDIR:\n\tcase NFSPROC_REMOVE:\n\tcase NFSPROC_RMDIR:\n\t\tif ((dp = parsereq(ndo, rp, length)) != NULL &&\n\t\t    parsefhn(ndo, dp, v3) != NULL)\n\t\t\treturn;\n\t\tbreak;\n\n\tcase NFSPROC_ACCESS:\n\t\tif ((dp = parsereq(ndo, rp, length)) != NULL &&\n\t\t    (dp = parsefh(ndo, dp, v3)) != NULL) {\n\t\t\tND_TCHECK(dp[0]);\n\t\t\taccess_flags = EXTRACT_32BITS(&dp[0]);\n\t\t\tif (access_flags & ~NFSV3ACCESS_FULL) {\n\t\t\t\t/* NFSV3ACCESS definitions aren't up to date */\n\t\t\t\tND_PRINT((ndo, \" %04x\", access_flags));\n\t\t\t} else if ((access_flags & NFSV3ACCESS_FULL) == NFSV3ACCESS_FULL) {\n\t\t\t\tND_PRINT((ndo, \" NFS_ACCESS_FULL\"));\n\t\t\t} else {\n\t\t\t\tchar separator = ' ';\n\t\t\t\tif (access_flags & NFSV3ACCESS_READ) {\n\t\t\t\t\tND_PRINT((ndo, \" NFS_ACCESS_READ\"));\n\t\t\t\t\tseparator = '|';\n\t\t\t\t}\n\t\t\t\tif (access_flags & NFSV3ACCESS_LOOKUP) {\n\t\t\t\t\tND_PRINT((ndo, \"%cNFS_ACCESS_LOOKUP\", separator));\n\t\t\t\t\tseparator = '|';\n\t\t\t\t}\n\t\t\t\tif (access_flags & NFSV3ACCESS_MODIFY) {\n\t\t\t\t\tND_PRINT((ndo, \"%cNFS_ACCESS_MODIFY\", separator));\n\t\t\t\t\tseparator = '|';\n\t\t\t\t}\n\t\t\t\tif (access_flags & NFSV3ACCESS_EXTEND) {\n\t\t\t\t\tND_PRINT((ndo, \"%cNFS_ACCESS_EXTEND\", separator));\n\t\t\t\t\tseparator = '|';\n\t\t\t\t}\n\t\t\t\tif (access_flags & NFSV3ACCESS_DELETE) {\n\t\t\t\t\tND_PRINT((ndo, \"%cNFS_ACCESS_DELETE\", separator));\n\t\t\t\t\tseparator = '|';\n\t\t\t\t}\n\t\t\t\tif (access_flags & NFSV3ACCESS_EXECUTE)\n\t\t\t\t\tND_PRINT((ndo, \"%cNFS_ACCESS_EXECUTE\", separator));\n\t\t\t}\n\t\t\treturn;\n\t\t}\n\t\tbreak;\n\n\tcase NFSPROC_READ:\n\t\tif ((dp = parsereq(ndo, rp, length)) != NULL &&\n\t\t    (dp = parsefh(ndo, dp, v3)) != NULL) {\n\t\t\tif (v3) {\n\t\t\t\tND_TCHECK(dp[2]);\n\t\t\t\tND_PRINT((ndo, \" %u bytes @ %\" PRIu64,\n\t\t\t\t       EXTRACT_32BITS(&dp[2]),\n\t\t\t\t       EXTRACT_64BITS(&dp[0])));\n\t\t\t} else {\n\t\t\t\tND_TCHECK(dp[1]);\n\t\t\t\tND_PRINT((ndo, \" %u bytes @ %u\",\n\t\t\t\t    EXTRACT_32BITS(&dp[1]),\n\t\t\t\t    EXTRACT_32BITS(&dp[0])));\n\t\t\t}\n\t\t\treturn;\n\t\t}\n\t\tbreak;\n\n\tcase NFSPROC_WRITE:\n\t\tif ((dp = parsereq(ndo, rp, length)) != NULL &&\n\t\t    (dp = parsefh(ndo, dp, v3)) != NULL) {\n\t\t\tif (v3) {\n\t\t\t\tND_TCHECK(dp[2]);\n\t\t\t\tND_PRINT((ndo, \" %u (%u) bytes @ %\" PRIu64,\n\t\t\t\t\t\tEXTRACT_32BITS(&dp[4]),\n\t\t\t\t\t\tEXTRACT_32BITS(&dp[2]),\n\t\t\t\t\t\tEXTRACT_64BITS(&dp[0])));\n\t\t\t\tif (ndo->ndo_vflag) {\n\t\t\t\t\tdp += 3;\n\t\t\t\t\tND_TCHECK(dp[0]);\n\t\t\t\t\tND_PRINT((ndo, \" <%s>\",\n\t\t\t\t\t\ttok2str(nfsv3_writemodes,\n\t\t\t\t\t\t\tNULL, EXTRACT_32BITS(dp))));\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tND_TCHECK(dp[3]);\n\t\t\t\tND_PRINT((ndo, \" %u (%u) bytes @ %u (%u)\",\n\t\t\t\t\t\tEXTRACT_32BITS(&dp[3]),\n\t\t\t\t\t\tEXTRACT_32BITS(&dp[2]),\n\t\t\t\t\t\tEXTRACT_32BITS(&dp[1]),\n\t\t\t\t\t\tEXTRACT_32BITS(&dp[0])));\n\t\t\t}\n\t\t\treturn;\n\t\t}\n\t\tbreak;\n\n\tcase NFSPROC_SYMLINK:\n\t\tif ((dp = parsereq(ndo, rp, length)) != NULL &&\n\t\t    (dp = parsefhn(ndo, dp, v3)) != NULL) {\n\t\t\tND_PRINT((ndo, \" ->\"));\n\t\t\tif (v3 && (dp = parse_sattr3(ndo, dp, &sa3)) == NULL)\n\t\t\t\tbreak;\n\t\t\tif (parsefn(ndo, dp) == NULL)\n\t\t\t\tbreak;\n\t\t\tif (v3 && ndo->ndo_vflag)\n\t\t\t\tprint_sattr3(ndo, &sa3, ndo->ndo_vflag);\n\t\t\treturn;\n\t\t}\n\t\tbreak;\n\n\tcase NFSPROC_MKNOD:\n\t\tif ((dp = parsereq(ndo, rp, length)) != NULL &&\n\t\t    (dp = parsefhn(ndo, dp, v3)) != NULL) {\n\t\t\tND_TCHECK(*dp);\n\t\t\ttype = (nfs_type)EXTRACT_32BITS(dp);\n\t\t\tdp++;\n\t\t\tif ((dp = parse_sattr3(ndo, dp, &sa3)) == NULL)\n\t\t\t\tbreak;\n\t\t\tND_PRINT((ndo, \" %s\", tok2str(type2str, \"unk-ft %d\", type)));\n\t\t\tif (ndo->ndo_vflag && (type == NFCHR || type == NFBLK)) {\n\t\t\t\tND_TCHECK(dp[1]);\n\t\t\t\tND_PRINT((ndo, \" %u/%u\",\n\t\t\t\t       EXTRACT_32BITS(&dp[0]),\n\t\t\t\t       EXTRACT_32BITS(&dp[1])));\n\t\t\t\tdp += 2;\n\t\t\t}\n\t\t\tif (ndo->ndo_vflag)\n\t\t\t\tprint_sattr3(ndo, &sa3, ndo->ndo_vflag);\n\t\t\treturn;\n\t\t}\n\t\tbreak;\n\n\tcase NFSPROC_RENAME:\n\t\tif ((dp = parsereq(ndo, rp, length)) != NULL &&\n\t\t    (dp = parsefhn(ndo, dp, v3)) != NULL) {\n\t\t\tND_PRINT((ndo, \" ->\"));\n\t\t\tif (parsefhn(ndo, dp, v3) != NULL)\n\t\t\t\treturn;\n\t\t}\n\t\tbreak;\n\n\tcase NFSPROC_LINK:\n\t\tif ((dp = parsereq(ndo, rp, length)) != NULL &&\n\t\t    (dp = parsefh(ndo, dp, v3)) != NULL) {\n\t\t\tND_PRINT((ndo, \" ->\"));\n\t\t\tif (parsefhn(ndo, dp, v3) != NULL)\n\t\t\t\treturn;\n\t\t}\n\t\tbreak;\n\n\tcase NFSPROC_READDIR:\n\t\tif ((dp = parsereq(ndo, rp, length)) != NULL &&\n\t\t    (dp = parsefh(ndo, dp, v3)) != NULL) {\n\t\t\tif (v3) {\n\t\t\t\tND_TCHECK(dp[4]);\n\t\t\t\t/*\n\t\t\t\t * We shouldn't really try to interpret the\n\t\t\t\t * offset cookie here.\n\t\t\t\t */\n\t\t\t\tND_PRINT((ndo, \" %u bytes @ %\" PRId64,\n\t\t\t\t    EXTRACT_32BITS(&dp[4]),\n\t\t\t\t    EXTRACT_64BITS(&dp[0])));\n\t\t\t\tif (ndo->ndo_vflag)\n\t\t\t\t\tND_PRINT((ndo, \" verf %08x%08x\", dp[2], dp[3]));\n\t\t\t} else {\n\t\t\t\tND_TCHECK(dp[1]);\n\t\t\t\t/*\n\t\t\t\t * Print the offset as signed, since -1 is\n\t\t\t\t * common, but offsets > 2^31 aren't.\n\t\t\t\t */\n\t\t\t\tND_PRINT((ndo, \" %u bytes @ %d\",\n\t\t\t\t    EXTRACT_32BITS(&dp[1]),\n\t\t\t\t    EXTRACT_32BITS(&dp[0])));\n\t\t\t}\n\t\t\treturn;\n\t\t}\n\t\tbreak;\n\n\tcase NFSPROC_READDIRPLUS:\n\t\tif ((dp = parsereq(ndo, rp, length)) != NULL &&\n\t\t    (dp = parsefh(ndo, dp, v3)) != NULL) {\n\t\t\tND_TCHECK(dp[4]);\n\t\t\t/*\n\t\t\t * We don't try to interpret the offset\n\t\t\t * cookie here.\n\t\t\t */\n\t\t\tND_PRINT((ndo, \" %u bytes @ %\" PRId64,\n\t\t\t\tEXTRACT_32BITS(&dp[4]),\n\t\t\t\tEXTRACT_64BITS(&dp[0])));\n\t\t\tif (ndo->ndo_vflag) {\n\t\t\t\tND_TCHECK(dp[5]);\n\t\t\t\tND_PRINT((ndo, \" max %u verf %08x%08x\",\n\t\t\t\t       EXTRACT_32BITS(&dp[5]), dp[2], dp[3]));\n\t\t\t}\n\t\t\treturn;\n\t\t}\n\t\tbreak;\n\n\tcase NFSPROC_COMMIT:\n\t\tif ((dp = parsereq(ndo, rp, length)) != NULL &&\n\t\t    (dp = parsefh(ndo, dp, v3)) != NULL) {\n\t\t\tND_TCHECK(dp[2]);\n\t\t\tND_PRINT((ndo, \" %u bytes @ %\" PRIu64,\n\t\t\t\tEXTRACT_32BITS(&dp[2]),\n\t\t\t\tEXTRACT_64BITS(&dp[0])));\n\t\t\treturn;\n\t\t}\n\t\tbreak;\n\n\tdefault:\n\t\treturn;\n\t}\n\ntrunc:\n\tif (!nfserr)\n\t\tND_PRINT((ndo, \"%s\", tstr));\n}",
        "func_after": "void\nnfsreq_print_noaddr(netdissect_options *ndo,\n                    register const u_char *bp, u_int length,\n                    register const u_char *bp2)\n{\n\tregister const struct sunrpc_msg *rp;\n\tregister const uint32_t *dp;\n\tnfs_type type;\n\tint v3;\n\tuint32_t proc;\n\tuint32_t access_flags;\n\tstruct nfsv3_sattr sa3;\n\n\tND_PRINT((ndo, \"%d\", length));\n\tnfserr = 0;\t\t/* assume no error */\n\trp = (const struct sunrpc_msg *)bp;\n\n\tif (!xid_map_enter(ndo, rp, bp2))\t/* record proc number for later on */\n\t\tgoto trunc;\n\n\tv3 = (EXTRACT_32BITS(&rp->rm_call.cb_vers) == NFS_VER3);\n\tproc = EXTRACT_32BITS(&rp->rm_call.cb_proc);\n\n\tif (!v3 && proc < NFS_NPROCS)\n\t\tproc =  nfsv3_procid[proc];\n\n\tND_PRINT((ndo, \" %s\", tok2str(nfsproc_str, \"proc-%u\", proc)));\n\tswitch (proc) {\n\n\tcase NFSPROC_GETATTR:\n\tcase NFSPROC_SETATTR:\n\tcase NFSPROC_READLINK:\n\tcase NFSPROC_FSSTAT:\n\tcase NFSPROC_FSINFO:\n\tcase NFSPROC_PATHCONF:\n\t\tif ((dp = parsereq(ndo, rp, length)) != NULL &&\n\t\t    parsefh(ndo, dp, v3) != NULL)\n\t\t\treturn;\n\t\tbreak;\n\n\tcase NFSPROC_LOOKUP:\n\tcase NFSPROC_CREATE:\n\tcase NFSPROC_MKDIR:\n\tcase NFSPROC_REMOVE:\n\tcase NFSPROC_RMDIR:\n\t\tif ((dp = parsereq(ndo, rp, length)) != NULL &&\n\t\t    parsefhn(ndo, dp, v3) != NULL)\n\t\t\treturn;\n\t\tbreak;\n\n\tcase NFSPROC_ACCESS:\n\t\tif ((dp = parsereq(ndo, rp, length)) != NULL &&\n\t\t    (dp = parsefh(ndo, dp, v3)) != NULL) {\n\t\t\tND_TCHECK(dp[0]);\n\t\t\taccess_flags = EXTRACT_32BITS(&dp[0]);\n\t\t\tif (access_flags & ~NFSV3ACCESS_FULL) {\n\t\t\t\t/* NFSV3ACCESS definitions aren't up to date */\n\t\t\t\tND_PRINT((ndo, \" %04x\", access_flags));\n\t\t\t} else if ((access_flags & NFSV3ACCESS_FULL) == NFSV3ACCESS_FULL) {\n\t\t\t\tND_PRINT((ndo, \" NFS_ACCESS_FULL\"));\n\t\t\t} else {\n\t\t\t\tchar separator = ' ';\n\t\t\t\tif (access_flags & NFSV3ACCESS_READ) {\n\t\t\t\t\tND_PRINT((ndo, \" NFS_ACCESS_READ\"));\n\t\t\t\t\tseparator = '|';\n\t\t\t\t}\n\t\t\t\tif (access_flags & NFSV3ACCESS_LOOKUP) {\n\t\t\t\t\tND_PRINT((ndo, \"%cNFS_ACCESS_LOOKUP\", separator));\n\t\t\t\t\tseparator = '|';\n\t\t\t\t}\n\t\t\t\tif (access_flags & NFSV3ACCESS_MODIFY) {\n\t\t\t\t\tND_PRINT((ndo, \"%cNFS_ACCESS_MODIFY\", separator));\n\t\t\t\t\tseparator = '|';\n\t\t\t\t}\n\t\t\t\tif (access_flags & NFSV3ACCESS_EXTEND) {\n\t\t\t\t\tND_PRINT((ndo, \"%cNFS_ACCESS_EXTEND\", separator));\n\t\t\t\t\tseparator = '|';\n\t\t\t\t}\n\t\t\t\tif (access_flags & NFSV3ACCESS_DELETE) {\n\t\t\t\t\tND_PRINT((ndo, \"%cNFS_ACCESS_DELETE\", separator));\n\t\t\t\t\tseparator = '|';\n\t\t\t\t}\n\t\t\t\tif (access_flags & NFSV3ACCESS_EXECUTE)\n\t\t\t\t\tND_PRINT((ndo, \"%cNFS_ACCESS_EXECUTE\", separator));\n\t\t\t}\n\t\t\treturn;\n\t\t}\n\t\tbreak;\n\n\tcase NFSPROC_READ:\n\t\tif ((dp = parsereq(ndo, rp, length)) != NULL &&\n\t\t    (dp = parsefh(ndo, dp, v3)) != NULL) {\n\t\t\tif (v3) {\n\t\t\t\tND_TCHECK(dp[2]);\n\t\t\t\tND_PRINT((ndo, \" %u bytes @ %\" PRIu64,\n\t\t\t\t       EXTRACT_32BITS(&dp[2]),\n\t\t\t\t       EXTRACT_64BITS(&dp[0])));\n\t\t\t} else {\n\t\t\t\tND_TCHECK(dp[1]);\n\t\t\t\tND_PRINT((ndo, \" %u bytes @ %u\",\n\t\t\t\t    EXTRACT_32BITS(&dp[1]),\n\t\t\t\t    EXTRACT_32BITS(&dp[0])));\n\t\t\t}\n\t\t\treturn;\n\t\t}\n\t\tbreak;\n\n\tcase NFSPROC_WRITE:\n\t\tif ((dp = parsereq(ndo, rp, length)) != NULL &&\n\t\t    (dp = parsefh(ndo, dp, v3)) != NULL) {\n\t\t\tif (v3) {\n\t\t\t\tND_TCHECK(dp[4]);\n\t\t\t\tND_PRINT((ndo, \" %u (%u) bytes @ %\" PRIu64,\n\t\t\t\t\t\tEXTRACT_32BITS(&dp[4]),\n\t\t\t\t\t\tEXTRACT_32BITS(&dp[2]),\n\t\t\t\t\t\tEXTRACT_64BITS(&dp[0])));\n\t\t\t\tif (ndo->ndo_vflag) {\n\t\t\t\t\tND_PRINT((ndo, \" <%s>\",\n\t\t\t\t\t\ttok2str(nfsv3_writemodes,\n\t\t\t\t\t\t\tNULL, EXTRACT_32BITS(&dp[3]))));\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tND_TCHECK(dp[3]);\n\t\t\t\tND_PRINT((ndo, \" %u (%u) bytes @ %u (%u)\",\n\t\t\t\t\t\tEXTRACT_32BITS(&dp[3]),\n\t\t\t\t\t\tEXTRACT_32BITS(&dp[2]),\n\t\t\t\t\t\tEXTRACT_32BITS(&dp[1]),\n\t\t\t\t\t\tEXTRACT_32BITS(&dp[0])));\n\t\t\t}\n\t\t\treturn;\n\t\t}\n\t\tbreak;\n\n\tcase NFSPROC_SYMLINK:\n\t\tif ((dp = parsereq(ndo, rp, length)) != NULL &&\n\t\t    (dp = parsefhn(ndo, dp, v3)) != NULL) {\n\t\t\tND_PRINT((ndo, \" ->\"));\n\t\t\tif (v3 && (dp = parse_sattr3(ndo, dp, &sa3)) == NULL)\n\t\t\t\tbreak;\n\t\t\tif (parsefn(ndo, dp) == NULL)\n\t\t\t\tbreak;\n\t\t\tif (v3 && ndo->ndo_vflag)\n\t\t\t\tprint_sattr3(ndo, &sa3, ndo->ndo_vflag);\n\t\t\treturn;\n\t\t}\n\t\tbreak;\n\n\tcase NFSPROC_MKNOD:\n\t\tif ((dp = parsereq(ndo, rp, length)) != NULL &&\n\t\t    (dp = parsefhn(ndo, dp, v3)) != NULL) {\n\t\t\tND_TCHECK(*dp);\n\t\t\ttype = (nfs_type)EXTRACT_32BITS(dp);\n\t\t\tdp++;\n\t\t\tif ((dp = parse_sattr3(ndo, dp, &sa3)) == NULL)\n\t\t\t\tbreak;\n\t\t\tND_PRINT((ndo, \" %s\", tok2str(type2str, \"unk-ft %d\", type)));\n\t\t\tif (ndo->ndo_vflag && (type == NFCHR || type == NFBLK)) {\n\t\t\t\tND_TCHECK(dp[1]);\n\t\t\t\tND_PRINT((ndo, \" %u/%u\",\n\t\t\t\t       EXTRACT_32BITS(&dp[0]),\n\t\t\t\t       EXTRACT_32BITS(&dp[1])));\n\t\t\t\tdp += 2;\n\t\t\t}\n\t\t\tif (ndo->ndo_vflag)\n\t\t\t\tprint_sattr3(ndo, &sa3, ndo->ndo_vflag);\n\t\t\treturn;\n\t\t}\n\t\tbreak;\n\n\tcase NFSPROC_RENAME:\n\t\tif ((dp = parsereq(ndo, rp, length)) != NULL &&\n\t\t    (dp = parsefhn(ndo, dp, v3)) != NULL) {\n\t\t\tND_PRINT((ndo, \" ->\"));\n\t\t\tif (parsefhn(ndo, dp, v3) != NULL)\n\t\t\t\treturn;\n\t\t}\n\t\tbreak;\n\n\tcase NFSPROC_LINK:\n\t\tif ((dp = parsereq(ndo, rp, length)) != NULL &&\n\t\t    (dp = parsefh(ndo, dp, v3)) != NULL) {\n\t\t\tND_PRINT((ndo, \" ->\"));\n\t\t\tif (parsefhn(ndo, dp, v3) != NULL)\n\t\t\t\treturn;\n\t\t}\n\t\tbreak;\n\n\tcase NFSPROC_READDIR:\n\t\tif ((dp = parsereq(ndo, rp, length)) != NULL &&\n\t\t    (dp = parsefh(ndo, dp, v3)) != NULL) {\n\t\t\tif (v3) {\n\t\t\t\tND_TCHECK(dp[4]);\n\t\t\t\t/*\n\t\t\t\t * We shouldn't really try to interpret the\n\t\t\t\t * offset cookie here.\n\t\t\t\t */\n\t\t\t\tND_PRINT((ndo, \" %u bytes @ %\" PRId64,\n\t\t\t\t    EXTRACT_32BITS(&dp[4]),\n\t\t\t\t    EXTRACT_64BITS(&dp[0])));\n\t\t\t\tif (ndo->ndo_vflag)\n\t\t\t\t\tND_PRINT((ndo, \" verf %08x%08x\", dp[2], dp[3]));\n\t\t\t} else {\n\t\t\t\tND_TCHECK(dp[1]);\n\t\t\t\t/*\n\t\t\t\t * Print the offset as signed, since -1 is\n\t\t\t\t * common, but offsets > 2^31 aren't.\n\t\t\t\t */\n\t\t\t\tND_PRINT((ndo, \" %u bytes @ %d\",\n\t\t\t\t    EXTRACT_32BITS(&dp[1]),\n\t\t\t\t    EXTRACT_32BITS(&dp[0])));\n\t\t\t}\n\t\t\treturn;\n\t\t}\n\t\tbreak;\n\n\tcase NFSPROC_READDIRPLUS:\n\t\tif ((dp = parsereq(ndo, rp, length)) != NULL &&\n\t\t    (dp = parsefh(ndo, dp, v3)) != NULL) {\n\t\t\tND_TCHECK(dp[4]);\n\t\t\t/*\n\t\t\t * We don't try to interpret the offset\n\t\t\t * cookie here.\n\t\t\t */\n\t\t\tND_PRINT((ndo, \" %u bytes @ %\" PRId64,\n\t\t\t\tEXTRACT_32BITS(&dp[4]),\n\t\t\t\tEXTRACT_64BITS(&dp[0])));\n\t\t\tif (ndo->ndo_vflag) {\n\t\t\t\tND_TCHECK(dp[5]);\n\t\t\t\tND_PRINT((ndo, \" max %u verf %08x%08x\",\n\t\t\t\t       EXTRACT_32BITS(&dp[5]), dp[2], dp[3]));\n\t\t\t}\n\t\t\treturn;\n\t\t}\n\t\tbreak;\n\n\tcase NFSPROC_COMMIT:\n\t\tif ((dp = parsereq(ndo, rp, length)) != NULL &&\n\t\t    (dp = parsefh(ndo, dp, v3)) != NULL) {\n\t\t\tND_TCHECK(dp[2]);\n\t\t\tND_PRINT((ndo, \" %u bytes @ %\" PRIu64,\n\t\t\t\tEXTRACT_32BITS(&dp[2]),\n\t\t\t\tEXTRACT_64BITS(&dp[0])));\n\t\t\treturn;\n\t\t}\n\t\tbreak;\n\n\tdefault:\n\t\treturn;\n\t}\n\ntrunc:\n\tif (!nfserr)\n\t\tND_PRINT((ndo, \"%s\", tstr));\n}",
        "description": "The NFS parser in tcpdump, prior to version 4.9.2, suffers from a buffer over-read issue within the interp_reply function.",
        "commit": "The NFSv3 WRITE procedure lacked proper bounds checking, specifically for the length of the opaque data being written. This oversight allowed for a buffer over-read vulnerability. Additionally, the code was updated to ensure that the entire `ar_stat` field is present in the captured data and to clarify the handling of the \"stable\" argument by removing redundant checks. A test case was included to verify the fix for checking before fetching the \"access\" part of the NFSv3 ACCESS results."
    },
    {
        "cwe": "CWE-755",
        "func_name": "xen-project/map_grant_ref",
        "score": 0.6680914759635925,
        "func_before": "static void\nmap_grant_ref(\n    struct gnttab_map_grant_ref *op)\n{\n    struct domain *ld, *rd, *owner = NULL;\n    struct grant_table *lgt, *rgt;\n    grant_ref_t ref;\n    grant_handle_t handle;\n    mfn_t mfn;\n    struct page_info *pg = NULL;\n    int            rc = GNTST_okay;\n    unsigned int   cache_flags, clear_flags = 0, refcnt = 0, typecnt = 0;\n    bool           host_map_created = false;\n    struct active_grant_entry *act = NULL;\n    struct grant_mapping *mt;\n    grant_entry_header_t *shah;\n    uint16_t *status;\n    bool_t need_iommu;\n\n    ld = current->domain;\n\n    if ( unlikely((op->flags & (GNTMAP_device_map|GNTMAP_host_map)) == 0) )\n    {\n        gdprintk(XENLOG_INFO, \"Bad flags in grant map op: %x\\n\", op->flags);\n        op->status = GNTST_bad_gntref;\n        return;\n    }\n\n    if ( unlikely(paging_mode_external(ld) &&\n                  (op->flags & (GNTMAP_device_map|GNTMAP_application_map|\n                            GNTMAP_contains_pte))) )\n    {\n        gdprintk(XENLOG_INFO, \"No device mapping in HVM domain\\n\");\n        op->status = GNTST_general_error;\n        return;\n    }\n\n    if ( unlikely((rd = rcu_lock_domain_by_id(op->dom)) == NULL) )\n    {\n        gdprintk(XENLOG_INFO, \"Could not find domain %d\\n\", op->dom);\n        op->status = GNTST_bad_domain;\n        return;\n    }\n\n    rc = xsm_grant_mapref(XSM_HOOK, ld, rd, op->flags);\n    if ( rc )\n    {\n        rcu_unlock_domain(rd);\n        op->status = GNTST_permission_denied;\n        return;\n    }\n\n    lgt = ld->grant_table;\n    handle = get_maptrack_handle(lgt);\n    if ( unlikely(handle == INVALID_MAPTRACK_HANDLE) )\n    {\n        rcu_unlock_domain(rd);\n        gdprintk(XENLOG_INFO, \"Failed to obtain maptrack handle\\n\");\n        op->status = GNTST_no_device_space;\n        return;\n    }\n\n    rgt = rd->grant_table;\n    grant_read_lock(rgt);\n\n    /* Bounds check on the grant ref */\n    ref = op->ref;\n    if ( unlikely(ref >= nr_grant_entries(rgt)))\n        PIN_FAIL(unlock_out, GNTST_bad_gntref, \"Bad ref %#x for d%d\\n\",\n                 ref, rgt->domain->domain_id);\n\n    /* This call also ensures the above check cannot be passed speculatively */\n    shah = shared_entry_header(rgt, ref);\n    act = active_entry_acquire(rgt, ref);\n\n    /* Make sure we do not access memory speculatively */\n    status = evaluate_nospec(rgt->gt_version == 1) ? &shah->flags\n                                                 : &status_entry(rgt, ref);\n\n    /* If already pinned, check the active domid and avoid refcnt overflow. */\n    if ( act->pin &&\n         ((act->domid != ld->domain_id) ||\n          (act->pin & 0x80808080U) != 0 ||\n          (act->is_sub_page)) )\n        PIN_FAIL(act_release_out, GNTST_general_error,\n                 \"Bad domain (%d != %d), or risk of counter overflow %08x, or subpage %d\\n\",\n                 act->domid, ld->domain_id, act->pin, act->is_sub_page);\n\n    if ( !act->pin ||\n         (!(op->flags & GNTMAP_readonly) &&\n          !(act->pin & (GNTPIN_hstw_mask|GNTPIN_devw_mask))) )\n    {\n        if ( (rc = _set_status(shah, status, rd, rgt->gt_version, act,\n                               op->flags & GNTMAP_readonly, 1,\n                               ld->domain_id) != GNTST_okay) )\n            goto act_release_out;\n\n        if ( !act->pin )\n        {\n            unsigned long gfn = evaluate_nospec(rgt->gt_version == 1) ?\n                                shared_entry_v1(rgt, ref).frame :\n                                shared_entry_v2(rgt, ref).full_page.frame;\n\n            rc = get_paged_frame(gfn, &mfn, &pg,\n                                 op->flags & GNTMAP_readonly, rd);\n            if ( rc != GNTST_okay )\n                goto unlock_out_clear;\n            act_set_gfn(act, _gfn(gfn));\n            act->domid = ld->domain_id;\n            act->mfn = mfn;\n            act->start = 0;\n            act->length = PAGE_SIZE;\n            act->is_sub_page = false;\n            act->trans_domain = rd;\n            act->trans_gref = ref;\n        }\n    }\n\n    if ( op->flags & GNTMAP_device_map )\n        act->pin += (op->flags & GNTMAP_readonly) ?\n            GNTPIN_devr_inc : GNTPIN_devw_inc;\n    if ( op->flags & GNTMAP_host_map )\n        act->pin += (op->flags & GNTMAP_readonly) ?\n            GNTPIN_hstr_inc : GNTPIN_hstw_inc;\n\n    mfn = act->mfn;\n\n    cache_flags = (shah->flags & (GTF_PAT | GTF_PWT | GTF_PCD) );\n\n    active_entry_release(act);\n    grant_read_unlock(rgt);\n\n    /* pg may be set, with a refcount included, from get_paged_frame(). */\n    if ( !pg )\n    {\n        pg = mfn_valid(mfn) ? mfn_to_page(mfn) : NULL;\n        if ( pg )\n            owner = page_get_owner_and_reference(pg);\n    }\n    else\n        owner = page_get_owner(pg);\n\n    if ( owner )\n        refcnt++;\n\n    if ( !pg || (owner == dom_io) )\n    {\n        /* Only needed the reference to confirm dom_io ownership. */\n        if ( pg )\n        {\n            put_page(pg);\n            refcnt--;\n        }\n\n        if ( paging_mode_external(ld) )\n        {\n            gdprintk(XENLOG_WARNING, \"HVM guests can't grant map iomem\\n\");\n            rc = GNTST_general_error;\n            goto undo_out;\n        }\n\n        if ( !iomem_access_permitted(rd, mfn_x(mfn), mfn_x(mfn)) )\n        {\n            gdprintk(XENLOG_WARNING,\n                     \"Iomem mapping not permitted %#\"PRI_mfn\" (domain %d)\\n\",\n                     mfn_x(mfn), rd->domain_id);\n            rc = GNTST_general_error;\n            goto undo_out;\n        }\n\n        if ( op->flags & GNTMAP_host_map )\n        {\n            rc = create_grant_host_mapping(op->host_addr, mfn, op->flags,\n                                           cache_flags);\n            if ( rc != GNTST_okay )\n                goto undo_out;\n\n            host_map_created = true;\n        }\n    }\n    else if ( owner == rd || (dom_cow && owner == dom_cow) )\n    {\n        if ( (op->flags & GNTMAP_device_map) && !(op->flags & GNTMAP_readonly) )\n        {\n            if ( (owner == dom_cow) ||\n                 !get_page_type(pg, PGT_writable_page) )\n                goto could_not_pin;\n            typecnt++;\n        }\n\n        if ( op->flags & GNTMAP_host_map )\n        {\n            /*\n             * Only need to grab another reference if device_map claimed\n             * the other one.\n             */\n            if ( op->flags & GNTMAP_device_map )\n            {\n                if ( !get_page(pg, rd) )\n                    goto could_not_pin;\n                refcnt++;\n            }\n\n            if ( gnttab_host_mapping_get_page_type(op->flags & GNTMAP_readonly,\n                                                   ld, rd) )\n            {\n                if ( (owner == dom_cow) ||\n                     !get_page_type(pg, PGT_writable_page) )\n                    goto could_not_pin;\n                typecnt++;\n            }\n\n            rc = create_grant_host_mapping(op->host_addr, mfn, op->flags, 0);\n            if ( rc != GNTST_okay )\n                goto undo_out;\n\n            host_map_created = true;\n        }\n    }\n    else\n    {\n    could_not_pin:\n        if ( !rd->is_dying )\n            gdprintk(XENLOG_WARNING, \"Could not pin grant frame %#\"PRI_mfn\"\\n\",\n                     mfn_x(mfn));\n        rc = GNTST_general_error;\n        goto undo_out;\n    }\n\n    need_iommu = gnttab_need_iommu_mapping(ld);\n    if ( need_iommu )\n    {\n        unsigned int kind;\n\n        double_gt_lock(lgt, rgt);\n\n        /*\n         * We're not translated, so we know that dfns and mfns are\n         * the same things, so the IOMMU entry is always 1-to-1.\n         */\n        kind = mapkind(lgt, rd, mfn);\n        if ( !(op->flags & GNTMAP_readonly) &&\n             !(kind & MAPKIND_WRITE) )\n            kind = IOMMUF_readable | IOMMUF_writable;\n        else if ( !kind )\n            kind = IOMMUF_readable;\n        else\n            kind = 0;\n        if ( kind && iommu_legacy_map(ld, _dfn(mfn_x(mfn)), mfn, 0, kind) )\n        {\n            double_gt_unlock(lgt, rgt);\n            rc = GNTST_general_error;\n            goto undo_out;\n        }\n    }\n\n    TRACE_1D(TRC_MEM_PAGE_GRANT_MAP, op->dom);\n\n    /*\n     * All maptrack entry users check mt->flags first before using the\n     * other fields so just ensure the flags field is stored last.\n     *\n     * However, if gnttab_need_iommu_mapping() then this would race\n     * with a concurrent mapkind() call (on an unmap, for example)\n     * and a lock is required.\n     */\n    mt = &maptrack_entry(lgt, handle);\n    mt->domid = op->dom;\n    mt->ref   = op->ref;\n    smp_wmb();\n    write_atomic(&mt->flags, op->flags);\n\n    if ( need_iommu )\n        double_gt_unlock(lgt, rgt);\n\n    op->dev_bus_addr = mfn_to_maddr(mfn);\n    op->handle       = handle;\n    op->status       = GNTST_okay;\n\n    rcu_unlock_domain(rd);\n    return;\n\n undo_out:\n    if ( host_map_created )\n    {\n        replace_grant_host_mapping(op->host_addr, mfn, 0, op->flags);\n        gnttab_flush_tlb(ld);\n    }\n\n    while ( typecnt-- )\n        put_page_type(pg);\n\n    while ( refcnt-- )\n        put_page(pg);\n\n    grant_read_lock(rgt);\n\n    act = active_entry_acquire(rgt, op->ref);\n\n    if ( op->flags & GNTMAP_device_map )\n        act->pin -= (op->flags & GNTMAP_readonly) ?\n            GNTPIN_devr_inc : GNTPIN_devw_inc;\n    if ( op->flags & GNTMAP_host_map )\n        act->pin -= (op->flags & GNTMAP_readonly) ?\n            GNTPIN_hstr_inc : GNTPIN_hstw_inc;\n\n unlock_out_clear:\n    if ( !(op->flags & GNTMAP_readonly) &&\n         !(act->pin & (GNTPIN_hstw_mask|GNTPIN_devw_mask)) )\n        clear_flags |= GTF_writing;\n\n    if ( !act->pin )\n        clear_flags |= GTF_reading;\n\n    if ( clear_flags )\n        gnttab_clear_flags(rd, clear_flags, status);\n\n act_release_out:\n    active_entry_release(act);\n\n unlock_out:\n    grant_read_unlock(rgt);\n    op->status = rc;\n    put_maptrack_handle(lgt, handle);\n    rcu_unlock_domain(rd);\n}",
        "func_after": "static void\nmap_grant_ref(\n    struct gnttab_map_grant_ref *op)\n{\n    struct domain *ld, *rd, *owner = NULL;\n    struct grant_table *lgt, *rgt;\n    grant_ref_t ref;\n    grant_handle_t handle;\n    mfn_t mfn;\n    struct page_info *pg = NULL;\n    int            rc = GNTST_okay;\n    unsigned int   cache_flags, clear_flags = 0, refcnt = 0, typecnt = 0;\n    bool           host_map_created = false;\n    struct active_grant_entry *act = NULL;\n    struct grant_mapping *mt;\n    grant_entry_header_t *shah;\n    uint16_t *status;\n    bool_t need_iommu;\n\n    ld = current->domain;\n\n    if ( unlikely((op->flags & (GNTMAP_device_map|GNTMAP_host_map)) == 0) )\n    {\n        gdprintk(XENLOG_INFO, \"Bad flags in grant map op: %x\\n\", op->flags);\n        op->status = GNTST_bad_gntref;\n        return;\n    }\n\n    if ( unlikely(paging_mode_external(ld) &&\n                  (op->flags & (GNTMAP_device_map|GNTMAP_application_map|\n                            GNTMAP_contains_pte))) )\n    {\n        gdprintk(XENLOG_INFO, \"No device mapping in HVM domain\\n\");\n        op->status = GNTST_general_error;\n        return;\n    }\n\n    if ( unlikely((rd = rcu_lock_domain_by_id(op->dom)) == NULL) )\n    {\n        gdprintk(XENLOG_INFO, \"Could not find domain %d\\n\", op->dom);\n        op->status = GNTST_bad_domain;\n        return;\n    }\n\n    rc = xsm_grant_mapref(XSM_HOOK, ld, rd, op->flags);\n    if ( rc )\n    {\n        rcu_unlock_domain(rd);\n        op->status = GNTST_permission_denied;\n        return;\n    }\n\n    lgt = ld->grant_table;\n    handle = get_maptrack_handle(lgt);\n    if ( unlikely(handle == INVALID_MAPTRACK_HANDLE) )\n    {\n        rcu_unlock_domain(rd);\n        gdprintk(XENLOG_INFO, \"Failed to obtain maptrack handle\\n\");\n        op->status = GNTST_no_device_space;\n        return;\n    }\n\n    rgt = rd->grant_table;\n    grant_read_lock(rgt);\n\n    /* Bounds check on the grant ref */\n    ref = op->ref;\n    if ( unlikely(ref >= nr_grant_entries(rgt)))\n        PIN_FAIL(unlock_out, GNTST_bad_gntref, \"Bad ref %#x for d%d\\n\",\n                 ref, rgt->domain->domain_id);\n\n    /* This call also ensures the above check cannot be passed speculatively */\n    shah = shared_entry_header(rgt, ref);\n    act = active_entry_acquire(rgt, ref);\n\n    /* Make sure we do not access memory speculatively */\n    status = evaluate_nospec(rgt->gt_version == 1) ? &shah->flags\n                                                 : &status_entry(rgt, ref);\n\n    /* If already pinned, check the active domid and avoid refcnt overflow. */\n    if ( act->pin &&\n         ((act->domid != ld->domain_id) ||\n          (act->pin & 0x80808080U) != 0 ||\n          (act->is_sub_page)) )\n        PIN_FAIL(act_release_out, GNTST_general_error,\n                 \"Bad domain (%d != %d), or risk of counter overflow %08x, or subpage %d\\n\",\n                 act->domid, ld->domain_id, act->pin, act->is_sub_page);\n\n    if ( !act->pin ||\n         (!(op->flags & GNTMAP_readonly) &&\n          !(act->pin & (GNTPIN_hstw_mask|GNTPIN_devw_mask))) )\n    {\n        if ( (rc = _set_status(shah, status, rd, rgt->gt_version, act,\n                               op->flags & GNTMAP_readonly, 1,\n                               ld->domain_id)) != GNTST_okay )\n            goto act_release_out;\n\n        if ( !act->pin )\n        {\n            unsigned long gfn = evaluate_nospec(rgt->gt_version == 1) ?\n                                shared_entry_v1(rgt, ref).frame :\n                                shared_entry_v2(rgt, ref).full_page.frame;\n\n            rc = get_paged_frame(gfn, &mfn, &pg,\n                                 op->flags & GNTMAP_readonly, rd);\n            if ( rc != GNTST_okay )\n                goto unlock_out_clear;\n            act_set_gfn(act, _gfn(gfn));\n            act->domid = ld->domain_id;\n            act->mfn = mfn;\n            act->start = 0;\n            act->length = PAGE_SIZE;\n            act->is_sub_page = false;\n            act->trans_domain = rd;\n            act->trans_gref = ref;\n        }\n    }\n\n    if ( op->flags & GNTMAP_device_map )\n        act->pin += (op->flags & GNTMAP_readonly) ?\n            GNTPIN_devr_inc : GNTPIN_devw_inc;\n    if ( op->flags & GNTMAP_host_map )\n        act->pin += (op->flags & GNTMAP_readonly) ?\n            GNTPIN_hstr_inc : GNTPIN_hstw_inc;\n\n    mfn = act->mfn;\n\n    cache_flags = (shah->flags & (GTF_PAT | GTF_PWT | GTF_PCD) );\n\n    active_entry_release(act);\n    grant_read_unlock(rgt);\n\n    /* pg may be set, with a refcount included, from get_paged_frame(). */\n    if ( !pg )\n    {\n        pg = mfn_valid(mfn) ? mfn_to_page(mfn) : NULL;\n        if ( pg )\n            owner = page_get_owner_and_reference(pg);\n    }\n    else\n        owner = page_get_owner(pg);\n\n    if ( owner )\n        refcnt++;\n\n    if ( !pg || (owner == dom_io) )\n    {\n        /* Only needed the reference to confirm dom_io ownership. */\n        if ( pg )\n        {\n            put_page(pg);\n            refcnt--;\n        }\n\n        if ( paging_mode_external(ld) )\n        {\n            gdprintk(XENLOG_WARNING, \"HVM guests can't grant map iomem\\n\");\n            rc = GNTST_general_error;\n            goto undo_out;\n        }\n\n        if ( !iomem_access_permitted(rd, mfn_x(mfn), mfn_x(mfn)) )\n        {\n            gdprintk(XENLOG_WARNING,\n                     \"Iomem mapping not permitted %#\"PRI_mfn\" (domain %d)\\n\",\n                     mfn_x(mfn), rd->domain_id);\n            rc = GNTST_general_error;\n            goto undo_out;\n        }\n\n        if ( op->flags & GNTMAP_host_map )\n        {\n            rc = create_grant_host_mapping(op->host_addr, mfn, op->flags,\n                                           cache_flags);\n            if ( rc != GNTST_okay )\n                goto undo_out;\n\n            host_map_created = true;\n        }\n    }\n    else if ( owner == rd || (dom_cow && owner == dom_cow) )\n    {\n        if ( (op->flags & GNTMAP_device_map) && !(op->flags & GNTMAP_readonly) )\n        {\n            if ( (owner == dom_cow) ||\n                 !get_page_type(pg, PGT_writable_page) )\n                goto could_not_pin;\n            typecnt++;\n        }\n\n        if ( op->flags & GNTMAP_host_map )\n        {\n            /*\n             * Only need to grab another reference if device_map claimed\n             * the other one.\n             */\n            if ( op->flags & GNTMAP_device_map )\n            {\n                if ( !get_page(pg, rd) )\n                    goto could_not_pin;\n                refcnt++;\n            }\n\n            if ( gnttab_host_mapping_get_page_type(op->flags & GNTMAP_readonly,\n                                                   ld, rd) )\n            {\n                if ( (owner == dom_cow) ||\n                     !get_page_type(pg, PGT_writable_page) )\n                    goto could_not_pin;\n                typecnt++;\n            }\n\n            rc = create_grant_host_mapping(op->host_addr, mfn, op->flags, 0);\n            if ( rc != GNTST_okay )\n                goto undo_out;\n\n            host_map_created = true;\n        }\n    }\n    else\n    {\n    could_not_pin:\n        if ( !rd->is_dying )\n            gdprintk(XENLOG_WARNING, \"Could not pin grant frame %#\"PRI_mfn\"\\n\",\n                     mfn_x(mfn));\n        rc = GNTST_general_error;\n        goto undo_out;\n    }\n\n    need_iommu = gnttab_need_iommu_mapping(ld);\n    if ( need_iommu )\n    {\n        unsigned int kind;\n\n        double_gt_lock(lgt, rgt);\n\n        /*\n         * We're not translated, so we know that dfns and mfns are\n         * the same things, so the IOMMU entry is always 1-to-1.\n         */\n        kind = mapkind(lgt, rd, mfn);\n        if ( !(op->flags & GNTMAP_readonly) &&\n             !(kind & MAPKIND_WRITE) )\n            kind = IOMMUF_readable | IOMMUF_writable;\n        else if ( !kind )\n            kind = IOMMUF_readable;\n        else\n            kind = 0;\n        if ( kind && iommu_legacy_map(ld, _dfn(mfn_x(mfn)), mfn, 0, kind) )\n        {\n            double_gt_unlock(lgt, rgt);\n            rc = GNTST_general_error;\n            goto undo_out;\n        }\n    }\n\n    TRACE_1D(TRC_MEM_PAGE_GRANT_MAP, op->dom);\n\n    /*\n     * All maptrack entry users check mt->flags first before using the\n     * other fields so just ensure the flags field is stored last.\n     *\n     * However, if gnttab_need_iommu_mapping() then this would race\n     * with a concurrent mapkind() call (on an unmap, for example)\n     * and a lock is required.\n     */\n    mt = &maptrack_entry(lgt, handle);\n    mt->domid = op->dom;\n    mt->ref   = op->ref;\n    smp_wmb();\n    write_atomic(&mt->flags, op->flags);\n\n    if ( need_iommu )\n        double_gt_unlock(lgt, rgt);\n\n    op->dev_bus_addr = mfn_to_maddr(mfn);\n    op->handle       = handle;\n    op->status       = GNTST_okay;\n\n    rcu_unlock_domain(rd);\n    return;\n\n undo_out:\n    if ( host_map_created )\n    {\n        replace_grant_host_mapping(op->host_addr, mfn, 0, op->flags);\n        gnttab_flush_tlb(ld);\n    }\n\n    while ( typecnt-- )\n        put_page_type(pg);\n\n    while ( refcnt-- )\n        put_page(pg);\n\n    grant_read_lock(rgt);\n\n    act = active_entry_acquire(rgt, op->ref);\n\n    if ( op->flags & GNTMAP_device_map )\n        act->pin -= (op->flags & GNTMAP_readonly) ?\n            GNTPIN_devr_inc : GNTPIN_devw_inc;\n    if ( op->flags & GNTMAP_host_map )\n        act->pin -= (op->flags & GNTMAP_readonly) ?\n            GNTPIN_hstr_inc : GNTPIN_hstw_inc;\n\n unlock_out_clear:\n    if ( !(op->flags & GNTMAP_readonly) &&\n         !(act->pin & (GNTPIN_hstw_mask|GNTPIN_devw_mask)) )\n        clear_flags |= GTF_writing;\n\n    if ( !act->pin )\n        clear_flags |= GTF_reading;\n\n    if ( clear_flags )\n        gnttab_clear_flags(rd, clear_flags, status);\n\n act_release_out:\n    active_entry_release(act);\n\n unlock_out:\n    grant_read_unlock(rgt);\n    op->status = rc;\n    put_maptrack_handle(lgt, handle);\n    rcu_unlock_domain(rd);\n}",
        "description": "An issue was discovered in Xen versions up to 4.13.x, where guest operating system users could trigger a denial of service due to an improper error handling mechanism in the GNTTABOP_map_grant operation. Grant table operations are supposed to return 0 for success and a negative number for errors; however, a coding mistake resulted in one error path returning 1 instead of a negative value. The grant table code in Linux interprets this as a successful operation and continues with incorrectly initialized state. A malicious or buggy guest could manipulate its grant table to exploit this flaw, causing a crash in the Linux-based dom0 or backend domain when a backend domain attempts to map a grant.",
        "commit": "A function within the Xen hypervisor, specifically related to mapping grant references, had its error handling logic inadvertently altered. This change caused the function to return an incorrect status code when a critical operation failed, leading to unexpected behavior in the Linux kernel's network and block device backends. This issue could result in system crashes due to improper handling of guest states."
    }
]