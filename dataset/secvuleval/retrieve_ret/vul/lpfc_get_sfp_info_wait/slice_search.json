[
    {
        "cwe": "CWE-20",
        "func_name": "libarchive/archive_read_format_iso9660_read_header",
        "score": 0.8115240931510925,
        "func_before": "static int\narchive_read_format_iso9660_read_header(struct archive_read *a,\n    struct archive_entry *entry)\n{\n\tstruct iso9660 *iso9660;\n\tstruct file_info *file;\n\tint r, rd_r = ARCHIVE_OK;\n\n\tiso9660 = (struct iso9660 *)(a->format->data);\n\n\tif (!a->archive.archive_format) {\n\t\ta->archive.archive_format = ARCHIVE_FORMAT_ISO9660;\n\t\ta->archive.archive_format_name = \"ISO9660\";\n\t}\n\n\tif (iso9660->current_position == 0) {\n\t\tr = choose_volume(a, iso9660);\n\t\tif (r != ARCHIVE_OK)\n\t\t\treturn (r);\n\t}\n\n\tfile = NULL;/* Eliminate a warning. */\n\t/* Get the next entry that appears after the current offset. */\n\tr = next_entry_seek(a, iso9660, &file);\n\tif (r != ARCHIVE_OK)\n\t\treturn (r);\n\n\tif (iso9660->seenJoliet) {\n\t\t/*\n\t\t * Convert UTF-16BE of a filename to local locale MBS\n\t\t * and store the result into a filename field.\n\t\t */\n\t\tif (iso9660->sconv_utf16be == NULL) {\n\t\t\tiso9660->sconv_utf16be =\n\t\t\t    archive_string_conversion_from_charset(\n\t\t\t\t&(a->archive), \"UTF-16BE\", 1);\n\t\t\tif (iso9660->sconv_utf16be == NULL)\n\t\t\t\t/* Coundn't allocate memory */\n\t\t\t\treturn (ARCHIVE_FATAL);\n\t\t}\n\t\tif (iso9660->utf16be_path == NULL) {\n\t\t\tiso9660->utf16be_path = malloc(UTF16_NAME_MAX);\n\t\t\tif (iso9660->utf16be_path == NULL) {\n\t\t\t\tarchive_set_error(&a->archive, ENOMEM,\n\t\t\t\t    \"No memory\");\n\t\t\t\treturn (ARCHIVE_FATAL);\n\t\t\t}\n\t\t}\n\t\tif (iso9660->utf16be_previous_path == NULL) {\n\t\t\tiso9660->utf16be_previous_path = malloc(UTF16_NAME_MAX);\n\t\t\tif (iso9660->utf16be_previous_path == NULL) {\n\t\t\t\tarchive_set_error(&a->archive, ENOMEM,\n\t\t\t\t    \"No memory\");\n\t\t\t\treturn (ARCHIVE_FATAL);\n\t\t\t}\n\t\t}\n\n\t\tiso9660->utf16be_path_len = 0;\n\t\tif (build_pathname_utf16be(iso9660->utf16be_path,\n\t\t    UTF16_NAME_MAX, &(iso9660->utf16be_path_len), file) != 0) {\n\t\t\tarchive_set_error(&a->archive,\n\t\t\t    ARCHIVE_ERRNO_FILE_FORMAT,\n\t\t\t    \"Pathname is too long\");\n\t\t}\n\n\t\tr = archive_entry_copy_pathname_l(entry,\n\t\t    (const char *)iso9660->utf16be_path,\n\t\t    iso9660->utf16be_path_len,\n\t\t    iso9660->sconv_utf16be);\n\t\tif (r != 0) {\n\t\t\tif (errno == ENOMEM) {\n\t\t\t\tarchive_set_error(&a->archive, ENOMEM,\n\t\t\t\t    \"No memory for Pathname\");\n\t\t\t\treturn (ARCHIVE_FATAL);\n\t\t\t}\n\t\t\tarchive_set_error(&a->archive,\n\t\t\t    ARCHIVE_ERRNO_FILE_FORMAT,\n\t\t\t    \"Pathname cannot be converted \"\n\t\t\t    \"from %s to current locale.\",\n\t\t\t    archive_string_conversion_charset_name(\n\t\t\t      iso9660->sconv_utf16be));\n\n\t\t\trd_r = ARCHIVE_WARN;\n\t\t}\n\t} else {\n\t\tarchive_string_empty(&iso9660->pathname);\n\t\tarchive_entry_set_pathname(entry,\n\t\t    build_pathname(&iso9660->pathname, file));\n\t}\n\n\tiso9660->entry_bytes_remaining = file->size;\n\t/* Offset for sparse-file-aware clients. */\n\tiso9660->entry_sparse_offset = 0;\n\n\tif (file->offset + file->size > iso9660->volume_size) {\n\t\tarchive_set_error(&a->archive, ARCHIVE_ERRNO_MISC,\n\t\t    \"File is beyond end-of-media: %s\",\n\t\t    archive_entry_pathname(entry));\n\t\tiso9660->entry_bytes_remaining = 0;\n\t\treturn (ARCHIVE_WARN);\n\t}\n\n\t/* Set up the entry structure with information about this entry. */\n\tarchive_entry_set_mode(entry, file->mode);\n\tarchive_entry_set_uid(entry, file->uid);\n\tarchive_entry_set_gid(entry, file->gid);\n\tarchive_entry_set_nlink(entry, file->nlinks);\n\tif (file->birthtime_is_set)\n\t\tarchive_entry_set_birthtime(entry, file->birthtime, 0);\n\telse\n\t\tarchive_entry_unset_birthtime(entry);\n\tarchive_entry_set_mtime(entry, file->mtime, 0);\n\tarchive_entry_set_ctime(entry, file->ctime, 0);\n\tarchive_entry_set_atime(entry, file->atime, 0);\n\t/* N.B.: Rock Ridge supports 64-bit device numbers. */\n\tarchive_entry_set_rdev(entry, (dev_t)file->rdev);\n\tarchive_entry_set_size(entry, iso9660->entry_bytes_remaining);\n\tif (file->symlink.s != NULL)\n\t\tarchive_entry_copy_symlink(entry, file->symlink.s);\n\n\t/* Note: If the input isn't seekable, we can't rewind to\n\t * return the same body again, so if the next entry refers to\n\t * the same data, we have to return it as a hardlink to the\n\t * original entry. */\n\tif (file->number != -1 &&\n\t    file->number == iso9660->previous_number) {\n\t\tif (iso9660->seenJoliet) {\n\t\t\tr = archive_entry_copy_hardlink_l(entry,\n\t\t\t    (const char *)iso9660->utf16be_previous_path,\n\t\t\t    iso9660->utf16be_previous_path_len,\n\t\t\t    iso9660->sconv_utf16be);\n\t\t\tif (r != 0) {\n\t\t\t\tif (errno == ENOMEM) {\n\t\t\t\t\tarchive_set_error(&a->archive, ENOMEM,\n\t\t\t\t\t    \"No memory for Linkname\");\n\t\t\t\t\treturn (ARCHIVE_FATAL);\n\t\t\t\t}\n\t\t\t\tarchive_set_error(&a->archive,\n\t\t\t\t    ARCHIVE_ERRNO_FILE_FORMAT,\n\t\t\t\t    \"Linkname cannot be converted \"\n\t\t\t\t    \"from %s to current locale.\",\n\t\t\t\t    archive_string_conversion_charset_name(\n\t\t\t\t      iso9660->sconv_utf16be));\n\t\t\t\trd_r = ARCHIVE_WARN;\n\t\t\t}\n\t\t} else\n\t\t\tarchive_entry_set_hardlink(entry,\n\t\t\t    iso9660->previous_pathname.s);\n\t\tarchive_entry_unset_size(entry);\n\t\tiso9660->entry_bytes_remaining = 0;\n\t\treturn (rd_r);\n\t}\n\n\tif ((file->mode & AE_IFMT) != AE_IFDIR &&\n\t    file->offset < iso9660->current_position) {\n\t\tint64_t r64;\n\n\t\tr64 = __archive_read_seek(a, file->offset, SEEK_SET);\n\t\tif (r64 != (int64_t)file->offset) {\n\t\t\t/* We can't seek backwards to extract it, so issue\n\t\t\t * a warning.  Note that this can only happen if\n\t\t\t * this entry was added to the heap after we passed\n\t\t\t * this offset, that is, only if the directory\n\t\t\t * mentioning this entry is later than the body of\n\t\t\t * the entry. Such layouts are very unusual; most\n\t\t\t * ISO9660 writers lay out and record all directory\n\t\t\t * information first, then store all file bodies. */\n\t\t\tarchive_set_error(&a->archive, ARCHIVE_ERRNO_MISC,\n\t\t\t    \"Ignoring out-of-order file @%jx (%s) %jd < %jd\",\n\t\t\t    (intmax_t)file->number,\n\t\t\t    iso9660->pathname.s,\n\t\t\t    (intmax_t)file->offset,\n\t\t\t    (intmax_t)iso9660->current_position);\n\t\t\tiso9660->entry_bytes_remaining = 0;\n\t\t\treturn (ARCHIVE_WARN);\n\t\t}\n\t\tiso9660->current_position = (uint64_t)r64;\n\t}\n\n\t/* Initialize zisofs variables. */\n\tiso9660->entry_zisofs.pz = file->pz;\n\tif (file->pz) {\n#ifdef HAVE_ZLIB_H\n\t\tstruct zisofs  *zisofs;\n\n\t\tzisofs = &iso9660->entry_zisofs;\n\t\tzisofs->initialized = 0;\n\t\tzisofs->pz_log2_bs = file->pz_log2_bs;\n\t\tzisofs->pz_uncompressed_size = file->pz_uncompressed_size;\n\t\tzisofs->pz_offset = 0;\n\t\tzisofs->header_avail = 0;\n\t\tzisofs->header_passed = 0;\n\t\tzisofs->block_pointers_avail = 0;\n#endif\n\t\tarchive_entry_set_size(entry, file->pz_uncompressed_size);\n\t}\n\n\tiso9660->previous_number = file->number;\n\tif (iso9660->seenJoliet) {\n\t\tmemcpy(iso9660->utf16be_previous_path, iso9660->utf16be_path,\n\t\t    iso9660->utf16be_path_len);\n\t\tiso9660->utf16be_previous_path_len = iso9660->utf16be_path_len;\n\t} else\n\t\tarchive_strcpy(\n\t\t    &iso9660->previous_pathname, iso9660->pathname.s);\n\n\t/* Reset entry_bytes_remaining if the file is multi extent. */\n\tiso9660->entry_content = file->contents.first;\n\tif (iso9660->entry_content != NULL)\n\t\tiso9660->entry_bytes_remaining = iso9660->entry_content->size;\n\n\tif (archive_entry_filetype(entry) == AE_IFDIR) {\n\t\t/* Overwrite nlinks by proper link number which is\n\t\t * calculated from number of sub directories. */\n\t\tarchive_entry_set_nlink(entry, 2 + file->subdirs);\n\t\t/* Directory data has been read completely. */\n\t\tiso9660->entry_bytes_remaining = 0;\n\t}\n\n\tif (rd_r != ARCHIVE_OK)\n\t\treturn (rd_r);\n\treturn (ARCHIVE_OK);\n}",
        "func_after": "static int\narchive_read_format_iso9660_read_header(struct archive_read *a,\n    struct archive_entry *entry)\n{\n\tstruct iso9660 *iso9660;\n\tstruct file_info *file;\n\tint r, rd_r = ARCHIVE_OK;\n\n\tiso9660 = (struct iso9660 *)(a->format->data);\n\n\tif (!a->archive.archive_format) {\n\t\ta->archive.archive_format = ARCHIVE_FORMAT_ISO9660;\n\t\ta->archive.archive_format_name = \"ISO9660\";\n\t}\n\n\tif (iso9660->current_position == 0) {\n\t\tr = choose_volume(a, iso9660);\n\t\tif (r != ARCHIVE_OK)\n\t\t\treturn (r);\n\t}\n\n\tfile = NULL;/* Eliminate a warning. */\n\t/* Get the next entry that appears after the current offset. */\n\tr = next_entry_seek(a, iso9660, &file);\n\tif (r != ARCHIVE_OK)\n\t\treturn (r);\n\n\tif (iso9660->seenJoliet) {\n\t\t/*\n\t\t * Convert UTF-16BE of a filename to local locale MBS\n\t\t * and store the result into a filename field.\n\t\t */\n\t\tif (iso9660->sconv_utf16be == NULL) {\n\t\t\tiso9660->sconv_utf16be =\n\t\t\t    archive_string_conversion_from_charset(\n\t\t\t\t&(a->archive), \"UTF-16BE\", 1);\n\t\t\tif (iso9660->sconv_utf16be == NULL)\n\t\t\t\t/* Coundn't allocate memory */\n\t\t\t\treturn (ARCHIVE_FATAL);\n\t\t}\n\t\tif (iso9660->utf16be_path == NULL) {\n\t\t\tiso9660->utf16be_path = malloc(UTF16_NAME_MAX);\n\t\t\tif (iso9660->utf16be_path == NULL) {\n\t\t\t\tarchive_set_error(&a->archive, ENOMEM,\n\t\t\t\t    \"No memory\");\n\t\t\t\treturn (ARCHIVE_FATAL);\n\t\t\t}\n\t\t}\n\t\tif (iso9660->utf16be_previous_path == NULL) {\n\t\t\tiso9660->utf16be_previous_path = malloc(UTF16_NAME_MAX);\n\t\t\tif (iso9660->utf16be_previous_path == NULL) {\n\t\t\t\tarchive_set_error(&a->archive, ENOMEM,\n\t\t\t\t    \"No memory\");\n\t\t\t\treturn (ARCHIVE_FATAL);\n\t\t\t}\n\t\t}\n\n\t\tiso9660->utf16be_path_len = 0;\n\t\tif (build_pathname_utf16be(iso9660->utf16be_path,\n\t\t    UTF16_NAME_MAX, &(iso9660->utf16be_path_len), file) != 0) {\n\t\t\tarchive_set_error(&a->archive,\n\t\t\t    ARCHIVE_ERRNO_FILE_FORMAT,\n\t\t\t    \"Pathname is too long\");\n\t\t\treturn (ARCHIVE_FATAL);\n\t\t}\n\n\t\tr = archive_entry_copy_pathname_l(entry,\n\t\t    (const char *)iso9660->utf16be_path,\n\t\t    iso9660->utf16be_path_len,\n\t\t    iso9660->sconv_utf16be);\n\t\tif (r != 0) {\n\t\t\tif (errno == ENOMEM) {\n\t\t\t\tarchive_set_error(&a->archive, ENOMEM,\n\t\t\t\t    \"No memory for Pathname\");\n\t\t\t\treturn (ARCHIVE_FATAL);\n\t\t\t}\n\t\t\tarchive_set_error(&a->archive,\n\t\t\t    ARCHIVE_ERRNO_FILE_FORMAT,\n\t\t\t    \"Pathname cannot be converted \"\n\t\t\t    \"from %s to current locale.\",\n\t\t\t    archive_string_conversion_charset_name(\n\t\t\t      iso9660->sconv_utf16be));\n\n\t\t\trd_r = ARCHIVE_WARN;\n\t\t}\n\t} else {\n\t\tconst char *path = build_pathname(&iso9660->pathname, file, 0);\n\t\tif (path == NULL) {\n\t\t\tarchive_set_error(&a->archive,\n\t\t\t    ARCHIVE_ERRNO_FILE_FORMAT,\n\t\t\t    \"Pathname is too long\");\n\t\t\treturn (ARCHIVE_FATAL);\n\t\t} else {\n\t\t\tarchive_string_empty(&iso9660->pathname);\n\t\t\tarchive_entry_set_pathname(entry, path);\n\t\t}\n\t}\n\n\tiso9660->entry_bytes_remaining = file->size;\n\t/* Offset for sparse-file-aware clients. */\n\tiso9660->entry_sparse_offset = 0;\n\n\tif (file->offset + file->size > iso9660->volume_size) {\n\t\tarchive_set_error(&a->archive, ARCHIVE_ERRNO_MISC,\n\t\t    \"File is beyond end-of-media: %s\",\n\t\t    archive_entry_pathname(entry));\n\t\tiso9660->entry_bytes_remaining = 0;\n\t\treturn (ARCHIVE_WARN);\n\t}\n\n\t/* Set up the entry structure with information about this entry. */\n\tarchive_entry_set_mode(entry, file->mode);\n\tarchive_entry_set_uid(entry, file->uid);\n\tarchive_entry_set_gid(entry, file->gid);\n\tarchive_entry_set_nlink(entry, file->nlinks);\n\tif (file->birthtime_is_set)\n\t\tarchive_entry_set_birthtime(entry, file->birthtime, 0);\n\telse\n\t\tarchive_entry_unset_birthtime(entry);\n\tarchive_entry_set_mtime(entry, file->mtime, 0);\n\tarchive_entry_set_ctime(entry, file->ctime, 0);\n\tarchive_entry_set_atime(entry, file->atime, 0);\n\t/* N.B.: Rock Ridge supports 64-bit device numbers. */\n\tarchive_entry_set_rdev(entry, (dev_t)file->rdev);\n\tarchive_entry_set_size(entry, iso9660->entry_bytes_remaining);\n\tif (file->symlink.s != NULL)\n\t\tarchive_entry_copy_symlink(entry, file->symlink.s);\n\n\t/* Note: If the input isn't seekable, we can't rewind to\n\t * return the same body again, so if the next entry refers to\n\t * the same data, we have to return it as a hardlink to the\n\t * original entry. */\n\tif (file->number != -1 &&\n\t    file->number == iso9660->previous_number) {\n\t\tif (iso9660->seenJoliet) {\n\t\t\tr = archive_entry_copy_hardlink_l(entry,\n\t\t\t    (const char *)iso9660->utf16be_previous_path,\n\t\t\t    iso9660->utf16be_previous_path_len,\n\t\t\t    iso9660->sconv_utf16be);\n\t\t\tif (r != 0) {\n\t\t\t\tif (errno == ENOMEM) {\n\t\t\t\t\tarchive_set_error(&a->archive, ENOMEM,\n\t\t\t\t\t    \"No memory for Linkname\");\n\t\t\t\t\treturn (ARCHIVE_FATAL);\n\t\t\t\t}\n\t\t\t\tarchive_set_error(&a->archive,\n\t\t\t\t    ARCHIVE_ERRNO_FILE_FORMAT,\n\t\t\t\t    \"Linkname cannot be converted \"\n\t\t\t\t    \"from %s to current locale.\",\n\t\t\t\t    archive_string_conversion_charset_name(\n\t\t\t\t      iso9660->sconv_utf16be));\n\t\t\t\trd_r = ARCHIVE_WARN;\n\t\t\t}\n\t\t} else\n\t\t\tarchive_entry_set_hardlink(entry,\n\t\t\t    iso9660->previous_pathname.s);\n\t\tarchive_entry_unset_size(entry);\n\t\tiso9660->entry_bytes_remaining = 0;\n\t\treturn (rd_r);\n\t}\n\n\tif ((file->mode & AE_IFMT) != AE_IFDIR &&\n\t    file->offset < iso9660->current_position) {\n\t\tint64_t r64;\n\n\t\tr64 = __archive_read_seek(a, file->offset, SEEK_SET);\n\t\tif (r64 != (int64_t)file->offset) {\n\t\t\t/* We can't seek backwards to extract it, so issue\n\t\t\t * a warning.  Note that this can only happen if\n\t\t\t * this entry was added to the heap after we passed\n\t\t\t * this offset, that is, only if the directory\n\t\t\t * mentioning this entry is later than the body of\n\t\t\t * the entry. Such layouts are very unusual; most\n\t\t\t * ISO9660 writers lay out and record all directory\n\t\t\t * information first, then store all file bodies. */\n\t\t\tarchive_set_error(&a->archive, ARCHIVE_ERRNO_MISC,\n\t\t\t    \"Ignoring out-of-order file @%jx (%s) %jd < %jd\",\n\t\t\t    (intmax_t)file->number,\n\t\t\t    iso9660->pathname.s,\n\t\t\t    (intmax_t)file->offset,\n\t\t\t    (intmax_t)iso9660->current_position);\n\t\t\tiso9660->entry_bytes_remaining = 0;\n\t\t\treturn (ARCHIVE_WARN);\n\t\t}\n\t\tiso9660->current_position = (uint64_t)r64;\n\t}\n\n\t/* Initialize zisofs variables. */\n\tiso9660->entry_zisofs.pz = file->pz;\n\tif (file->pz) {\n#ifdef HAVE_ZLIB_H\n\t\tstruct zisofs  *zisofs;\n\n\t\tzisofs = &iso9660->entry_zisofs;\n\t\tzisofs->initialized = 0;\n\t\tzisofs->pz_log2_bs = file->pz_log2_bs;\n\t\tzisofs->pz_uncompressed_size = file->pz_uncompressed_size;\n\t\tzisofs->pz_offset = 0;\n\t\tzisofs->header_avail = 0;\n\t\tzisofs->header_passed = 0;\n\t\tzisofs->block_pointers_avail = 0;\n#endif\n\t\tarchive_entry_set_size(entry, file->pz_uncompressed_size);\n\t}\n\n\tiso9660->previous_number = file->number;\n\tif (iso9660->seenJoliet) {\n\t\tmemcpy(iso9660->utf16be_previous_path, iso9660->utf16be_path,\n\t\t    iso9660->utf16be_path_len);\n\t\tiso9660->utf16be_previous_path_len = iso9660->utf16be_path_len;\n\t} else\n\t\tarchive_strcpy(\n\t\t    &iso9660->previous_pathname, iso9660->pathname.s);\n\n\t/* Reset entry_bytes_remaining if the file is multi extent. */\n\tiso9660->entry_content = file->contents.first;\n\tif (iso9660->entry_content != NULL)\n\t\tiso9660->entry_bytes_remaining = iso9660->entry_content->size;\n\n\tif (archive_entry_filetype(entry) == AE_IFDIR) {\n\t\t/* Overwrite nlinks by proper link number which is\n\t\t * calculated from number of sub directories. */\n\t\tarchive_entry_set_nlink(entry, 2 + file->subdirs);\n\t\t/* Directory data has been read completely. */\n\t\tiso9660->entry_bytes_remaining = 0;\n\t}\n\n\tif (rd_r != ARCHIVE_OK)\n\t\treturn (rd_r);\n\treturn (ARCHIVE_OK);\n}",
        "description": "bsdtar in libarchive versions prior to 3.2.0 is susceptible to a denial of service (infinite loop) caused by processing an ISO archive containing a directory that references itself.",
        "commit": "Issue #522: Malformed ISO files can lead to a segmentation fault due to excessive directory recursion. Specifically, the system can crash when assembling ISO paths through recursive directory traversal, reaching up to 130,000 directory levels. This vulnerability is addressed by implementing a limit on directory recursion to 1,000 elements. Future improvements should focus on detecting and tracking directory loops directly."
    },
    {
        "cwe": "CWE-119",
        "func_name": "torvalds/do_page_fault",
        "score": 0.8081685304641724,
        "func_before": "asmlinkage\n#endif\nvoid __kprobes do_page_fault(struct pt_regs *regs, unsigned long error_code)\n{\n\tstruct task_struct *tsk;\n\tstruct mm_struct *mm;\n\tstruct vm_area_struct *vma;\n\tunsigned long address;\n\tint write, si_code;\n\tint fault;\n#ifdef CONFIG_X86_64\n\tunsigned long flags;\n\tint sig;\n#endif\n\n\ttsk = current;\n\tmm = tsk->mm;\n\tprefetchw(&mm->mmap_sem);\n\n\t/* get the address */\n\taddress = read_cr2();\n\n\tsi_code = SEGV_MAPERR;\n\n\tif (notify_page_fault(regs))\n\t\treturn;\n\tif (unlikely(kmmio_fault(regs, address)))\n\t\treturn;\n\n\t/*\n\t * We fault-in kernel-space virtual memory on-demand. The\n\t * 'reference' page table is init_mm.pgd.\n\t *\n\t * NOTE! We MUST NOT take any locks for this case. We may\n\t * be in an interrupt or a critical region, and should\n\t * only copy the information from the master page table,\n\t * nothing more.\n\t *\n\t * This verifies that the fault happens in kernel space\n\t * (error_code & 4) == 0, and that the fault was not a\n\t * protection error (error_code & 9) == 0.\n\t */\n#ifdef CONFIG_X86_32\n\tif (unlikely(address >= TASK_SIZE)) {\n#else\n\tif (unlikely(address >= TASK_SIZE64)) {\n#endif\n\t\tif (!(error_code & (PF_RSVD|PF_USER|PF_PROT)) &&\n\t\t    vmalloc_fault(address) >= 0)\n\t\t\treturn;\n\n\t\t/* Can handle a stale RO->RW TLB */\n\t\tif (spurious_fault(address, error_code))\n\t\t\treturn;\n\n\t\t/*\n\t\t * Don't take the mm semaphore here. If we fixup a prefetch\n\t\t * fault we could otherwise deadlock.\n\t\t */\n\t\tgoto bad_area_nosemaphore;\n\t}\n\n\n\t/*\n\t * It's safe to allow irq's after cr2 has been saved and the\n\t * vmalloc fault has been handled.\n\t *\n\t * User-mode registers count as a user access even for any\n\t * potential system fault or CPU buglet.\n\t */\n\tif (user_mode_vm(regs)) {\n\t\tlocal_irq_enable();\n\t\terror_code |= PF_USER;\n\t} else if (regs->flags & X86_EFLAGS_IF)\n\t\tlocal_irq_enable();\n\n#ifdef CONFIG_X86_64\n\tif (unlikely(error_code & PF_RSVD))\n\t\tpgtable_bad(address, regs, error_code);\n#endif\n\n\t/*\n\t * If we're in an interrupt, have no user context or are running in an\n\t * atomic region then we must not take the fault.\n\t */\n\tif (unlikely(in_atomic() || !mm))\n\t\tgoto bad_area_nosemaphore;\n\n\t/*\n\t * When running in the kernel we expect faults to occur only to\n\t * addresses in user space.  All other faults represent errors in the\n\t * kernel and should generate an OOPS.  Unfortunately, in the case of an\n\t * erroneous fault occurring in a code path which already holds mmap_sem\n\t * we will deadlock attempting to validate the fault against the\n\t * address space.  Luckily the kernel only validly references user\n\t * space from well defined areas of code, which are listed in the\n\t * exceptions table.\n\t *\n\t * As the vast majority of faults will be valid we will only perform\n\t * the source reference check when there is a possibility of a deadlock.\n\t * Attempt to lock the address space, if we cannot we then validate the\n\t * source.  If this is invalid we can skip the address space check,\n\t * thus avoiding the deadlock.\n\t */\n\tif (!down_read_trylock(&mm->mmap_sem)) {\n\t\tif ((error_code & PF_USER) == 0 &&\n\t\t    !search_exception_tables(regs->ip))\n\t\t\tgoto bad_area_nosemaphore;\n\t\tdown_read(&mm->mmap_sem);\n\t}\n\n\tvma = find_vma(mm, address);\n\tif (!vma)\n\t\tgoto bad_area;\n\tif (vma->vm_start <= address)\n\t\tgoto good_area;\n\tif (!(vma->vm_flags & VM_GROWSDOWN))\n\t\tgoto bad_area;\n\tif (error_code & PF_USER) {\n\t\t/*\n\t\t * Accessing the stack below %sp is always a bug.\n\t\t * The large cushion allows instructions like enter\n\t\t * and pusha to work.  (\"enter $65535,$31\" pushes\n\t\t * 32 pointers and then decrements %sp by 65535.)\n\t\t */\n\t\tif (address + 65536 + 32 * sizeof(unsigned long) < regs->sp)\n\t\t\tgoto bad_area;\n\t}\n\tif (expand_stack(vma, address))\n\t\tgoto bad_area;\n/*\n * Ok, we have a good vm_area for this memory access, so\n * we can handle it..\n */\ngood_area:\n\tsi_code = SEGV_ACCERR;\n\twrite = 0;\n\tswitch (error_code & (PF_PROT|PF_WRITE)) {\n\tdefault:\t/* 3: write, present */\n\t\t/* fall through */\n\tcase PF_WRITE:\t\t/* write, not present */\n\t\tif (!(vma->vm_flags & VM_WRITE))\n\t\t\tgoto bad_area;\n\t\twrite++;\n\t\tbreak;\n\tcase PF_PROT:\t\t/* read, present */\n\t\tgoto bad_area;\n\tcase 0:\t\t\t/* read, not present */\n\t\tif (!(vma->vm_flags & (VM_READ | VM_EXEC | VM_WRITE)))\n\t\t\tgoto bad_area;\n\t}\n\n\t/*\n\t * If for any reason at all we couldn't handle the fault,\n\t * make sure we exit gracefully rather than endlessly redo\n\t * the fault.\n\t */\n\tfault = handle_mm_fault(mm, vma, address, write);\n\tif (unlikely(fault & VM_FAULT_ERROR)) {\n\t\tif (fault & VM_FAULT_OOM)\n\t\t\tgoto out_of_memory;\n\t\telse if (fault & VM_FAULT_SIGBUS)\n\t\t\tgoto do_sigbus;\n\t\tBUG();\n\t}\n\tif (fault & VM_FAULT_MAJOR)\n\t\ttsk->maj_flt++;\n\telse\n\t\ttsk->min_flt++;\n\n#ifdef CONFIG_X86_32\n\t/*\n\t * Did it hit the DOS screen memory VA from vm86 mode?\n\t */\n\tif (v8086_mode(regs)) {\n\t\tunsigned long bit = (address - 0xA0000) >> PAGE_SHIFT;\n\t\tif (bit < 32)\n\t\t\ttsk->thread.screen_bitmap |= 1 << bit;\n\t}\n#endif\n\tup_read(&mm->mmap_sem);\n\treturn;\n\n/*\n * Something tried to access memory that isn't in our memory map..\n * Fix it, but check if it's kernel or user first..\n */\nbad_area:\n\tup_read(&mm->mmap_sem);\n\nbad_area_nosemaphore:\n\t/* User mode accesses just cause a SIGSEGV */\n\tif (error_code & PF_USER) {\n\t\t/*\n\t\t * It's possible to have interrupts off here.\n\t\t */\n\t\tlocal_irq_enable();\n\n\t\t/*\n\t\t * Valid to do another page fault here because this one came\n\t\t * from user space.\n\t\t */\n\t\tif (is_prefetch(regs, address, error_code))\n\t\t\treturn;\n\n\t\tif (is_errata100(regs, address))\n\t\t\treturn;\n\n\t\tif (show_unhandled_signals && unhandled_signal(tsk, SIGSEGV) &&\n\t\t    printk_ratelimit()) {\n\t\t\tprintk(\n\t\t\t\"%s%s[%d]: segfault at %lx ip %p sp %p error %lx\",\n\t\t\ttask_pid_nr(tsk) > 1 ? KERN_INFO : KERN_EMERG,\n\t\t\ttsk->comm, task_pid_nr(tsk), address,\n\t\t\t(void *) regs->ip, (void *) regs->sp, error_code);\n\t\t\tprint_vma_addr(\" in \", regs->ip);\n\t\t\tprintk(\"\\n\");\n\t\t}\n\n\t\ttsk->thread.cr2 = address;\n\t\t/* Kernel addresses are always protection faults */\n\t\ttsk->thread.error_code = error_code | (address >= TASK_SIZE);\n\t\ttsk->thread.trap_no = 14;\n\t\tforce_sig_info_fault(SIGSEGV, si_code, address, tsk);\n\t\treturn;\n\t}\n\n\tif (is_f00f_bug(regs, address))\n\t\treturn;\n\nno_context:\n\t/* Are we prepared to handle this kernel fault?  */\n\tif (fixup_exception(regs))\n\t\treturn;\n\n\t/*\n\t * X86_32\n\t * Valid to do another page fault here, because if this fault\n\t * had been triggered by is_prefetch fixup_exception would have\n\t * handled it.\n\t *\n\t * X86_64\n\t * Hall of shame of CPU/BIOS bugs.\n\t */\n\tif (is_prefetch(regs, address, error_code))\n\t\treturn;\n\n\tif (is_errata93(regs, address))\n\t\treturn;\n\n/*\n * Oops. The kernel tried to access some bad page. We'll have to\n * terminate things with extreme prejudice.\n */\n#ifdef CONFIG_X86_32\n\tbust_spinlocks(1);\n#else\n\tflags = oops_begin();\n#endif\n\n\tshow_fault_oops(regs, error_code, address);\n\n\ttsk->thread.cr2 = address;\n\ttsk->thread.trap_no = 14;\n\ttsk->thread.error_code = error_code;\n\n#ifdef CONFIG_X86_32\n\tdie(\"Oops\", regs, error_code);\n\tbust_spinlocks(0);\n\tdo_exit(SIGKILL);\n#else\n\tsig = SIGKILL;\n\tif (__die(\"Oops\", regs, error_code))\n\t\tsig = 0;\n\t/* Executive summary in case the body of the oops scrolled away */\n\tprintk(KERN_EMERG \"CR2: %016lx\\n\", address);\n\toops_end(flags, regs, sig);\n#endif\n\nout_of_memory:\n\t/*\n\t * We ran out of memory, call the OOM killer, and return the userspace\n\t * (which will retry the fault, or kill us if we got oom-killed).\n\t */\n\tup_read(&mm->mmap_sem);\n\tpagefault_out_of_memory();\n\treturn;\n\ndo_sigbus:\n\tup_read(&mm->mmap_sem);\n\n\t/* Kernel mode? Handle exceptions or die */\n\tif (!(error_code & PF_USER))\n\t\tgoto no_context;\n#ifdef CONFIG_X86_32\n\t/* User space => ok to do another page fault */\n\tif (is_prefetch(regs, address, error_code))\n\t\treturn;\n#endif\n\ttsk->thread.cr2 = address;\n\ttsk->thread.error_code = error_code;\n\ttsk->thread.trap_no = 14;\n\tforce_sig_info_fault(SIGBUS, BUS_ADRERR, address, tsk);\n}",
        "func_after": "asmlinkage\n#endif\nvoid __kprobes do_page_fault(struct pt_regs *regs, unsigned long error_code)\n{\n\tstruct task_struct *tsk;\n\tstruct mm_struct *mm;\n\tstruct vm_area_struct *vma;\n\tunsigned long address;\n\tint write, si_code;\n\tint fault;\n#ifdef CONFIG_X86_64\n\tunsigned long flags;\n\tint sig;\n#endif\n\n\ttsk = current;\n\tmm = tsk->mm;\n\tprefetchw(&mm->mmap_sem);\n\n\t/* get the address */\n\taddress = read_cr2();\n\n\tsi_code = SEGV_MAPERR;\n\n\tif (unlikely(kmmio_fault(regs, address)))\n\t\treturn;\n\n\t/*\n\t * We fault-in kernel-space virtual memory on-demand. The\n\t * 'reference' page table is init_mm.pgd.\n\t *\n\t * NOTE! We MUST NOT take any locks for this case. We may\n\t * be in an interrupt or a critical region, and should\n\t * only copy the information from the master page table,\n\t * nothing more.\n\t *\n\t * This verifies that the fault happens in kernel space\n\t * (error_code & 4) == 0, and that the fault was not a\n\t * protection error (error_code & 9) == 0.\n\t */\n#ifdef CONFIG_X86_32\n\tif (unlikely(address >= TASK_SIZE)) {\n#else\n\tif (unlikely(address >= TASK_SIZE64)) {\n#endif\n\t\tif (!(error_code & (PF_RSVD|PF_USER|PF_PROT)) &&\n\t\t    vmalloc_fault(address) >= 0)\n\t\t\treturn;\n\n\t\t/* Can handle a stale RO->RW TLB */\n\t\tif (spurious_fault(address, error_code))\n\t\t\treturn;\n\n\t\t/* kprobes don't want to hook the spurious faults. */\n\t\tif (notify_page_fault(regs))\n\t\t\treturn;\n\t\t/*\n\t\t * Don't take the mm semaphore here. If we fixup a prefetch\n\t\t * fault we could otherwise deadlock.\n\t\t */\n\t\tgoto bad_area_nosemaphore;\n\t}\n\n\t/* kprobes don't want to hook the spurious faults. */\n\tif (notify_page_fault(regs))\n\t\treturn;\n\n\t/*\n\t * It's safe to allow irq's after cr2 has been saved and the\n\t * vmalloc fault has been handled.\n\t *\n\t * User-mode registers count as a user access even for any\n\t * potential system fault or CPU buglet.\n\t */\n\tif (user_mode_vm(regs)) {\n\t\tlocal_irq_enable();\n\t\terror_code |= PF_USER;\n\t} else if (regs->flags & X86_EFLAGS_IF)\n\t\tlocal_irq_enable();\n\n#ifdef CONFIG_X86_64\n\tif (unlikely(error_code & PF_RSVD))\n\t\tpgtable_bad(address, regs, error_code);\n#endif\n\n\t/*\n\t * If we're in an interrupt, have no user context or are running in an\n\t * atomic region then we must not take the fault.\n\t */\n\tif (unlikely(in_atomic() || !mm))\n\t\tgoto bad_area_nosemaphore;\n\n\t/*\n\t * When running in the kernel we expect faults to occur only to\n\t * addresses in user space.  All other faults represent errors in the\n\t * kernel and should generate an OOPS.  Unfortunately, in the case of an\n\t * erroneous fault occurring in a code path which already holds mmap_sem\n\t * we will deadlock attempting to validate the fault against the\n\t * address space.  Luckily the kernel only validly references user\n\t * space from well defined areas of code, which are listed in the\n\t * exceptions table.\n\t *\n\t * As the vast majority of faults will be valid we will only perform\n\t * the source reference check when there is a possibility of a deadlock.\n\t * Attempt to lock the address space, if we cannot we then validate the\n\t * source.  If this is invalid we can skip the address space check,\n\t * thus avoiding the deadlock.\n\t */\n\tif (!down_read_trylock(&mm->mmap_sem)) {\n\t\tif ((error_code & PF_USER) == 0 &&\n\t\t    !search_exception_tables(regs->ip))\n\t\t\tgoto bad_area_nosemaphore;\n\t\tdown_read(&mm->mmap_sem);\n\t}\n\n\tvma = find_vma(mm, address);\n\tif (!vma)\n\t\tgoto bad_area;\n\tif (vma->vm_start <= address)\n\t\tgoto good_area;\n\tif (!(vma->vm_flags & VM_GROWSDOWN))\n\t\tgoto bad_area;\n\tif (error_code & PF_USER) {\n\t\t/*\n\t\t * Accessing the stack below %sp is always a bug.\n\t\t * The large cushion allows instructions like enter\n\t\t * and pusha to work.  (\"enter $65535,$31\" pushes\n\t\t * 32 pointers and then decrements %sp by 65535.)\n\t\t */\n\t\tif (address + 65536 + 32 * sizeof(unsigned long) < regs->sp)\n\t\t\tgoto bad_area;\n\t}\n\tif (expand_stack(vma, address))\n\t\tgoto bad_area;\n/*\n * Ok, we have a good vm_area for this memory access, so\n * we can handle it..\n */\ngood_area:\n\tsi_code = SEGV_ACCERR;\n\twrite = 0;\n\tswitch (error_code & (PF_PROT|PF_WRITE)) {\n\tdefault:\t/* 3: write, present */\n\t\t/* fall through */\n\tcase PF_WRITE:\t\t/* write, not present */\n\t\tif (!(vma->vm_flags & VM_WRITE))\n\t\t\tgoto bad_area;\n\t\twrite++;\n\t\tbreak;\n\tcase PF_PROT:\t\t/* read, present */\n\t\tgoto bad_area;\n\tcase 0:\t\t\t/* read, not present */\n\t\tif (!(vma->vm_flags & (VM_READ | VM_EXEC | VM_WRITE)))\n\t\t\tgoto bad_area;\n\t}\n\n\t/*\n\t * If for any reason at all we couldn't handle the fault,\n\t * make sure we exit gracefully rather than endlessly redo\n\t * the fault.\n\t */\n\tfault = handle_mm_fault(mm, vma, address, write);\n\tif (unlikely(fault & VM_FAULT_ERROR)) {\n\t\tif (fault & VM_FAULT_OOM)\n\t\t\tgoto out_of_memory;\n\t\telse if (fault & VM_FAULT_SIGBUS)\n\t\t\tgoto do_sigbus;\n\t\tBUG();\n\t}\n\tif (fault & VM_FAULT_MAJOR)\n\t\ttsk->maj_flt++;\n\telse\n\t\ttsk->min_flt++;\n\n#ifdef CONFIG_X86_32\n\t/*\n\t * Did it hit the DOS screen memory VA from vm86 mode?\n\t */\n\tif (v8086_mode(regs)) {\n\t\tunsigned long bit = (address - 0xA0000) >> PAGE_SHIFT;\n\t\tif (bit < 32)\n\t\t\ttsk->thread.screen_bitmap |= 1 << bit;\n\t}\n#endif\n\tup_read(&mm->mmap_sem);\n\treturn;\n\n/*\n * Something tried to access memory that isn't in our memory map..\n * Fix it, but check if it's kernel or user first..\n */\nbad_area:\n\tup_read(&mm->mmap_sem);\n\nbad_area_nosemaphore:\n\t/* User mode accesses just cause a SIGSEGV */\n\tif (error_code & PF_USER) {\n\t\t/*\n\t\t * It's possible to have interrupts off here.\n\t\t */\n\t\tlocal_irq_enable();\n\n\t\t/*\n\t\t * Valid to do another page fault here because this one came\n\t\t * from user space.\n\t\t */\n\t\tif (is_prefetch(regs, address, error_code))\n\t\t\treturn;\n\n\t\tif (is_errata100(regs, address))\n\t\t\treturn;\n\n\t\tif (show_unhandled_signals && unhandled_signal(tsk, SIGSEGV) &&\n\t\t    printk_ratelimit()) {\n\t\t\tprintk(\n\t\t\t\"%s%s[%d]: segfault at %lx ip %p sp %p error %lx\",\n\t\t\ttask_pid_nr(tsk) > 1 ? KERN_INFO : KERN_EMERG,\n\t\t\ttsk->comm, task_pid_nr(tsk), address,\n\t\t\t(void *) regs->ip, (void *) regs->sp, error_code);\n\t\t\tprint_vma_addr(\" in \", regs->ip);\n\t\t\tprintk(\"\\n\");\n\t\t}\n\n\t\ttsk->thread.cr2 = address;\n\t\t/* Kernel addresses are always protection faults */\n\t\ttsk->thread.error_code = error_code | (address >= TASK_SIZE);\n\t\ttsk->thread.trap_no = 14;\n\t\tforce_sig_info_fault(SIGSEGV, si_code, address, tsk);\n\t\treturn;\n\t}\n\n\tif (is_f00f_bug(regs, address))\n\t\treturn;\n\nno_context:\n\t/* Are we prepared to handle this kernel fault?  */\n\tif (fixup_exception(regs))\n\t\treturn;\n\n\t/*\n\t * X86_32\n\t * Valid to do another page fault here, because if this fault\n\t * had been triggered by is_prefetch fixup_exception would have\n\t * handled it.\n\t *\n\t * X86_64\n\t * Hall of shame of CPU/BIOS bugs.\n\t */\n\tif (is_prefetch(regs, address, error_code))\n\t\treturn;\n\n\tif (is_errata93(regs, address))\n\t\treturn;\n\n/*\n * Oops. The kernel tried to access some bad page. We'll have to\n * terminate things with extreme prejudice.\n */\n#ifdef CONFIG_X86_32\n\tbust_spinlocks(1);\n#else\n\tflags = oops_begin();\n#endif\n\n\tshow_fault_oops(regs, error_code, address);\n\n\ttsk->thread.cr2 = address;\n\ttsk->thread.trap_no = 14;\n\ttsk->thread.error_code = error_code;\n\n#ifdef CONFIG_X86_32\n\tdie(\"Oops\", regs, error_code);\n\tbust_spinlocks(0);\n\tdo_exit(SIGKILL);\n#else\n\tsig = SIGKILL;\n\tif (__die(\"Oops\", regs, error_code))\n\t\tsig = 0;\n\t/* Executive summary in case the body of the oops scrolled away */\n\tprintk(KERN_EMERG \"CR2: %016lx\\n\", address);\n\toops_end(flags, regs, sig);\n#endif\n\nout_of_memory:\n\t/*\n\t * We ran out of memory, call the OOM killer, and return the userspace\n\t * (which will retry the fault, or kill us if we got oom-killed).\n\t */\n\tup_read(&mm->mmap_sem);\n\tpagefault_out_of_memory();\n\treturn;\n\ndo_sigbus:\n\tup_read(&mm->mmap_sem);\n\n\t/* Kernel mode? Handle exceptions or die */\n\tif (!(error_code & PF_USER))\n\t\tgoto no_context;\n#ifdef CONFIG_X86_32\n\t/* User space => ok to do another page fault */\n\tif (is_prefetch(regs, address, error_code))\n\t\treturn;\n#endif\n\ttsk->thread.cr2 = address;\n\ttsk->thread.error_code = error_code;\n\ttsk->thread.trap_no = 14;\n\tforce_sig_info_fault(SIGBUS, BUS_ADRERR, address, tsk);\n}",
        "description": "A stack consumption vulnerability exists in the `do_page_fault` function within the Linux kernel prior to version 2.6.28.5. This flaw allows local users to induce a denial of service through memory corruption or potentially escalate privileges by exploiting undefined vectors that trigger page faults on systems with registered Kprobes probes.",
        "commit": "To prevent kprobes from catching spurious faults that lead to infinite recursive page faults and memory corruption due to stack overflow."
    },
    {
        "cwe": "CWE-770",
        "func_name": "binutils-gdb/_bfd_elf_slurp_version_tables",
        "score": 0.7998188138008118,
        "func_before": "bfd_boolean\n_bfd_elf_slurp_version_tables (bfd *abfd, bfd_boolean default_imported_symver)\n{\n  bfd_byte *contents = NULL;\n  unsigned int freeidx = 0;\n\n  if (elf_dynverref (abfd) != 0)\n    {\n      Elf_Internal_Shdr *hdr;\n      Elf_External_Verneed *everneed;\n      Elf_Internal_Verneed *iverneed;\n      unsigned int i;\n      bfd_byte *contents_end;\n\n      hdr = &elf_tdata (abfd)->dynverref_hdr;\n\n      if (hdr->sh_info == 0 || hdr->sh_size < sizeof (Elf_External_Verneed))\n\t{\nerror_return_bad_verref:\n\t  _bfd_error_handler\n\t    (_(\"%B: .gnu.version_r invalid entry\"), abfd);\n\t  bfd_set_error (bfd_error_bad_value);\nerror_return_verref:\n\t  elf_tdata (abfd)->verref = NULL;\n\t  elf_tdata (abfd)->cverrefs = 0;\n\t  goto error_return;\n\t}\n\n      contents = (bfd_byte *) bfd_malloc (hdr->sh_size);\n      if (contents == NULL)\n\tgoto error_return_verref;\n\n      if (bfd_seek (abfd, hdr->sh_offset, SEEK_SET) != 0\n\t  || bfd_bread (contents, hdr->sh_size, abfd) != hdr->sh_size)\n\tgoto error_return_verref;\n\n      elf_tdata (abfd)->verref = (Elf_Internal_Verneed *)\n\tbfd_zalloc2 (abfd, hdr->sh_info, sizeof (Elf_Internal_Verneed));\n\n      if (elf_tdata (abfd)->verref == NULL)\n\tgoto error_return_verref;\n\n      BFD_ASSERT (sizeof (Elf_External_Verneed)\n\t\t  == sizeof (Elf_External_Vernaux));\n      contents_end = contents + hdr->sh_size - sizeof (Elf_External_Verneed);\n      everneed = (Elf_External_Verneed *) contents;\n      iverneed = elf_tdata (abfd)->verref;\n      for (i = 0; i < hdr->sh_info; i++, iverneed++)\n\t{\n\t  Elf_External_Vernaux *evernaux;\n\t  Elf_Internal_Vernaux *ivernaux;\n\t  unsigned int j;\n\n\t  _bfd_elf_swap_verneed_in (abfd, everneed, iverneed);\n\n\t  iverneed->vn_bfd = abfd;\n\n\t  iverneed->vn_filename =\n\t    bfd_elf_string_from_elf_section (abfd, hdr->sh_link,\n\t\t\t\t\t     iverneed->vn_file);\n\t  if (iverneed->vn_filename == NULL)\n\t    goto error_return_bad_verref;\n\n\t  if (iverneed->vn_cnt == 0)\n\t    iverneed->vn_auxptr = NULL;\n\t  else\n\t    {\n\t      iverneed->vn_auxptr = (struct elf_internal_vernaux *)\n                  bfd_alloc2 (abfd, iverneed->vn_cnt,\n                              sizeof (Elf_Internal_Vernaux));\n\t      if (iverneed->vn_auxptr == NULL)\n\t\tgoto error_return_verref;\n\t    }\n\n\t  if (iverneed->vn_aux\n\t      > (size_t) (contents_end - (bfd_byte *) everneed))\n\t    goto error_return_bad_verref;\n\n\t  evernaux = ((Elf_External_Vernaux *)\n\t\t      ((bfd_byte *) everneed + iverneed->vn_aux));\n\t  ivernaux = iverneed->vn_auxptr;\n\t  for (j = 0; j < iverneed->vn_cnt; j++, ivernaux++)\n\t    {\n\t      _bfd_elf_swap_vernaux_in (abfd, evernaux, ivernaux);\n\n\t      ivernaux->vna_nodename =\n\t\tbfd_elf_string_from_elf_section (abfd, hdr->sh_link,\n\t\t\t\t\t\t ivernaux->vna_name);\n\t      if (ivernaux->vna_nodename == NULL)\n\t\tgoto error_return_bad_verref;\n\n\t      if (ivernaux->vna_other > freeidx)\n\t\tfreeidx = ivernaux->vna_other;\n\n\t      ivernaux->vna_nextptr = NULL;\n\t      if (ivernaux->vna_next == 0)\n\t\t{\n\t\t  iverneed->vn_cnt = j + 1;\n\t\t  break;\n\t\t}\n\t      if (j + 1 < iverneed->vn_cnt)\n\t\tivernaux->vna_nextptr = ivernaux + 1;\n\n\t      if (ivernaux->vna_next\n\t\t  > (size_t) (contents_end - (bfd_byte *) evernaux))\n\t\tgoto error_return_bad_verref;\n\n\t      evernaux = ((Elf_External_Vernaux *)\n\t\t\t  ((bfd_byte *) evernaux + ivernaux->vna_next));\n\t    }\n\n\t  iverneed->vn_nextref = NULL;\n\t  if (iverneed->vn_next == 0)\n\t    break;\n\t  if (i + 1 < hdr->sh_info)\n\t    iverneed->vn_nextref = iverneed + 1;\n\n\t  if (iverneed->vn_next\n\t      > (size_t) (contents_end - (bfd_byte *) everneed))\n\t    goto error_return_bad_verref;\n\n\t  everneed = ((Elf_External_Verneed *)\n\t\t      ((bfd_byte *) everneed + iverneed->vn_next));\n\t}\n      elf_tdata (abfd)->cverrefs = i;\n\n      free (contents);\n      contents = NULL;\n    }\n\n  if (elf_dynverdef (abfd) != 0)\n    {\n      Elf_Internal_Shdr *hdr;\n      Elf_External_Verdef *everdef;\n      Elf_Internal_Verdef *iverdef;\n      Elf_Internal_Verdef *iverdefarr;\n      Elf_Internal_Verdef iverdefmem;\n      unsigned int i;\n      unsigned int maxidx;\n      bfd_byte *contents_end_def, *contents_end_aux;\n\n      hdr = &elf_tdata (abfd)->dynverdef_hdr;\n\n      if (hdr->sh_info == 0 || hdr->sh_size < sizeof (Elf_External_Verdef))\n\t{\n\terror_return_bad_verdef:\n\t  _bfd_error_handler\n\t    (_(\"%B: .gnu.version_d invalid entry\"), abfd);\n\t  bfd_set_error (bfd_error_bad_value);\n\terror_return_verdef:\n\t  elf_tdata (abfd)->verdef = NULL;\n\t  elf_tdata (abfd)->cverdefs = 0;\n\t  goto error_return;\n\t}\n\n      contents = (bfd_byte *) bfd_malloc (hdr->sh_size);\n      if (contents == NULL)\n\tgoto error_return_verdef;\n      if (bfd_seek (abfd, hdr->sh_offset, SEEK_SET) != 0\n\t  || bfd_bread (contents, hdr->sh_size, abfd) != hdr->sh_size)\n\tgoto error_return_verdef;\n\n      BFD_ASSERT (sizeof (Elf_External_Verdef)\n\t\t  >= sizeof (Elf_External_Verdaux));\n      contents_end_def = contents + hdr->sh_size\n\t\t\t - sizeof (Elf_External_Verdef);\n      contents_end_aux = contents + hdr->sh_size\n\t\t\t - sizeof (Elf_External_Verdaux);\n\n      /* We know the number of entries in the section but not the maximum\n\t index.  Therefore we have to run through all entries and find\n\t the maximum.  */\n      everdef = (Elf_External_Verdef *) contents;\n      maxidx = 0;\n      for (i = 0; i < hdr->sh_info; ++i)\n\t{\n\t  _bfd_elf_swap_verdef_in (abfd, everdef, &iverdefmem);\n\n\t  if ((iverdefmem.vd_ndx & ((unsigned) VERSYM_VERSION)) == 0)\n\t    goto error_return_bad_verdef;\n\t  if ((iverdefmem.vd_ndx & ((unsigned) VERSYM_VERSION)) > maxidx)\n\t    maxidx = iverdefmem.vd_ndx & ((unsigned) VERSYM_VERSION);\n\n\t  if (iverdefmem.vd_next == 0)\n\t    break;\n\n\t  if (iverdefmem.vd_next\n\t      > (size_t) (contents_end_def - (bfd_byte *) everdef))\n\t    goto error_return_bad_verdef;\n\n\t  everdef = ((Elf_External_Verdef *)\n\t\t     ((bfd_byte *) everdef + iverdefmem.vd_next));\n\t}\n\n      if (default_imported_symver)\n\t{\n\t  if (freeidx > maxidx)\n\t    maxidx = ++freeidx;\n\t  else\n\t    freeidx = ++maxidx;\n\t}\n\n      elf_tdata (abfd)->verdef = (Elf_Internal_Verdef *)\n\tbfd_zalloc2 (abfd, maxidx, sizeof (Elf_Internal_Verdef));\n      if (elf_tdata (abfd)->verdef == NULL)\n\tgoto error_return_verdef;\n\n      elf_tdata (abfd)->cverdefs = maxidx;\n\n      everdef = (Elf_External_Verdef *) contents;\n      iverdefarr = elf_tdata (abfd)->verdef;\n      for (i = 0; i < hdr->sh_info; i++)\n\t{\n\t  Elf_External_Verdaux *everdaux;\n\t  Elf_Internal_Verdaux *iverdaux;\n\t  unsigned int j;\n\n\t  _bfd_elf_swap_verdef_in (abfd, everdef, &iverdefmem);\n\n\t  if ((iverdefmem.vd_ndx & VERSYM_VERSION) == 0)\n\t    goto error_return_bad_verdef;\n\n\t  iverdef = &iverdefarr[(iverdefmem.vd_ndx & VERSYM_VERSION) - 1];\n\t  memcpy (iverdef, &iverdefmem, offsetof (Elf_Internal_Verdef, vd_bfd));\n\n\t  iverdef->vd_bfd = abfd;\n\n\t  if (iverdef->vd_cnt == 0)\n\t    iverdef->vd_auxptr = NULL;\n\t  else\n\t    {\n\t      iverdef->vd_auxptr = (struct elf_internal_verdaux *)\n                  bfd_alloc2 (abfd, iverdef->vd_cnt,\n                              sizeof (Elf_Internal_Verdaux));\n\t      if (iverdef->vd_auxptr == NULL)\n\t\tgoto error_return_verdef;\n\t    }\n\n\t  if (iverdef->vd_aux\n\t      > (size_t) (contents_end_aux - (bfd_byte *) everdef))\n\t    goto error_return_bad_verdef;\n\n\t  everdaux = ((Elf_External_Verdaux *)\n\t\t      ((bfd_byte *) everdef + iverdef->vd_aux));\n\t  iverdaux = iverdef->vd_auxptr;\n\t  for (j = 0; j < iverdef->vd_cnt; j++, iverdaux++)\n\t    {\n\t      _bfd_elf_swap_verdaux_in (abfd, everdaux, iverdaux);\n\n\t      iverdaux->vda_nodename =\n\t\tbfd_elf_string_from_elf_section (abfd, hdr->sh_link,\n\t\t\t\t\t\t iverdaux->vda_name);\n\t      if (iverdaux->vda_nodename == NULL)\n\t\tgoto error_return_bad_verdef;\n\n\t      iverdaux->vda_nextptr = NULL;\n\t      if (iverdaux->vda_next == 0)\n\t\t{\n\t\t  iverdef->vd_cnt = j + 1;\n\t\t  break;\n\t\t}\n\t      if (j + 1 < iverdef->vd_cnt)\n\t\tiverdaux->vda_nextptr = iverdaux + 1;\n\n\t      if (iverdaux->vda_next\n\t\t  > (size_t) (contents_end_aux - (bfd_byte *) everdaux))\n\t\tgoto error_return_bad_verdef;\n\n\t      everdaux = ((Elf_External_Verdaux *)\n\t\t\t  ((bfd_byte *) everdaux + iverdaux->vda_next));\n\t    }\n\n\t  iverdef->vd_nodename = NULL;\n\t  if (iverdef->vd_cnt)\n\t    iverdef->vd_nodename = iverdef->vd_auxptr->vda_nodename;\n\n\t  iverdef->vd_nextdef = NULL;\n\t  if (iverdef->vd_next == 0)\n\t    break;\n\t  if ((size_t) (iverdef - iverdefarr) + 1 < maxidx)\n\t    iverdef->vd_nextdef = iverdef + 1;\n\n\t  everdef = ((Elf_External_Verdef *)\n\t\t     ((bfd_byte *) everdef + iverdef->vd_next));\n\t}\n\n      free (contents);\n      contents = NULL;\n    }\n  else if (default_imported_symver)\n    {\n      if (freeidx < 3)\n\tfreeidx = 3;\n      else\n\tfreeidx++;\n\n      elf_tdata (abfd)->verdef = (Elf_Internal_Verdef *)\n          bfd_zalloc2 (abfd, freeidx, sizeof (Elf_Internal_Verdef));\n      if (elf_tdata (abfd)->verdef == NULL)\n\tgoto error_return;\n\n      elf_tdata (abfd)->cverdefs = freeidx;\n    }\n\n  /* Create a default version based on the soname.  */\n  if (default_imported_symver)\n    {\n      Elf_Internal_Verdef *iverdef;\n      Elf_Internal_Verdaux *iverdaux;\n\n      iverdef = &elf_tdata (abfd)->verdef[freeidx - 1];\n\n      iverdef->vd_version = VER_DEF_CURRENT;\n      iverdef->vd_flags = 0;\n      iverdef->vd_ndx = freeidx;\n      iverdef->vd_cnt = 1;\n\n      iverdef->vd_bfd = abfd;\n\n      iverdef->vd_nodename = bfd_elf_get_dt_soname (abfd);\n      if (iverdef->vd_nodename == NULL)\n\tgoto error_return_verdef;\n      iverdef->vd_nextdef = NULL;\n      iverdef->vd_auxptr = ((struct elf_internal_verdaux *)\n\t\t\t    bfd_zalloc (abfd, sizeof (Elf_Internal_Verdaux)));\n      if (iverdef->vd_auxptr == NULL)\n\tgoto error_return_verdef;\n\n      iverdaux = iverdef->vd_auxptr;\n      iverdaux->vda_nodename = iverdef->vd_nodename;\n    }\n\n  return TRUE;\n\n error_return:\n  if (contents != NULL)\n    free (contents);\n  return FALSE;\n}",
        "func_after": "bfd_boolean\n_bfd_elf_slurp_version_tables (bfd *abfd, bfd_boolean default_imported_symver)\n{\n  bfd_byte *contents = NULL;\n  unsigned int freeidx = 0;\n\n  if (elf_dynverref (abfd) != 0)\n    {\n      Elf_Internal_Shdr *hdr;\n      Elf_External_Verneed *everneed;\n      Elf_Internal_Verneed *iverneed;\n      unsigned int i;\n      bfd_byte *contents_end;\n\n      hdr = &elf_tdata (abfd)->dynverref_hdr;\n\n      if (hdr->sh_info == 0\n\t  || hdr->sh_info > hdr->sh_size / sizeof (Elf_External_Verneed))\n\t{\nerror_return_bad_verref:\n\t  _bfd_error_handler\n\t    (_(\"%B: .gnu.version_r invalid entry\"), abfd);\n\t  bfd_set_error (bfd_error_bad_value);\nerror_return_verref:\n\t  elf_tdata (abfd)->verref = NULL;\n\t  elf_tdata (abfd)->cverrefs = 0;\n\t  goto error_return;\n\t}\n\n      contents = (bfd_byte *) bfd_malloc (hdr->sh_size);\n      if (contents == NULL)\n\tgoto error_return_verref;\n\n      if (bfd_seek (abfd, hdr->sh_offset, SEEK_SET) != 0\n\t  || bfd_bread (contents, hdr->sh_size, abfd) != hdr->sh_size)\n\tgoto error_return_verref;\n\n      elf_tdata (abfd)->verref = (Elf_Internal_Verneed *)\n\tbfd_alloc2 (abfd, hdr->sh_info, sizeof (Elf_Internal_Verneed));\n\n      if (elf_tdata (abfd)->verref == NULL)\n\tgoto error_return_verref;\n\n      BFD_ASSERT (sizeof (Elf_External_Verneed)\n\t\t  == sizeof (Elf_External_Vernaux));\n      contents_end = contents + hdr->sh_size - sizeof (Elf_External_Verneed);\n      everneed = (Elf_External_Verneed *) contents;\n      iverneed = elf_tdata (abfd)->verref;\n      for (i = 0; i < hdr->sh_info; i++, iverneed++)\n\t{\n\t  Elf_External_Vernaux *evernaux;\n\t  Elf_Internal_Vernaux *ivernaux;\n\t  unsigned int j;\n\n\t  _bfd_elf_swap_verneed_in (abfd, everneed, iverneed);\n\n\t  iverneed->vn_bfd = abfd;\n\n\t  iverneed->vn_filename =\n\t    bfd_elf_string_from_elf_section (abfd, hdr->sh_link,\n\t\t\t\t\t     iverneed->vn_file);\n\t  if (iverneed->vn_filename == NULL)\n\t    goto error_return_bad_verref;\n\n\t  if (iverneed->vn_cnt == 0)\n\t    iverneed->vn_auxptr = NULL;\n\t  else\n\t    {\n\t      iverneed->vn_auxptr = (struct elf_internal_vernaux *)\n                  bfd_alloc2 (abfd, iverneed->vn_cnt,\n                              sizeof (Elf_Internal_Vernaux));\n\t      if (iverneed->vn_auxptr == NULL)\n\t\tgoto error_return_verref;\n\t    }\n\n\t  if (iverneed->vn_aux\n\t      > (size_t) (contents_end - (bfd_byte *) everneed))\n\t    goto error_return_bad_verref;\n\n\t  evernaux = ((Elf_External_Vernaux *)\n\t\t      ((bfd_byte *) everneed + iverneed->vn_aux));\n\t  ivernaux = iverneed->vn_auxptr;\n\t  for (j = 0; j < iverneed->vn_cnt; j++, ivernaux++)\n\t    {\n\t      _bfd_elf_swap_vernaux_in (abfd, evernaux, ivernaux);\n\n\t      ivernaux->vna_nodename =\n\t\tbfd_elf_string_from_elf_section (abfd, hdr->sh_link,\n\t\t\t\t\t\t ivernaux->vna_name);\n\t      if (ivernaux->vna_nodename == NULL)\n\t\tgoto error_return_bad_verref;\n\n\t      if (ivernaux->vna_other > freeidx)\n\t\tfreeidx = ivernaux->vna_other;\n\n\t      ivernaux->vna_nextptr = NULL;\n\t      if (ivernaux->vna_next == 0)\n\t\t{\n\t\t  iverneed->vn_cnt = j + 1;\n\t\t  break;\n\t\t}\n\t      if (j + 1 < iverneed->vn_cnt)\n\t\tivernaux->vna_nextptr = ivernaux + 1;\n\n\t      if (ivernaux->vna_next\n\t\t  > (size_t) (contents_end - (bfd_byte *) evernaux))\n\t\tgoto error_return_bad_verref;\n\n\t      evernaux = ((Elf_External_Vernaux *)\n\t\t\t  ((bfd_byte *) evernaux + ivernaux->vna_next));\n\t    }\n\n\t  iverneed->vn_nextref = NULL;\n\t  if (iverneed->vn_next == 0)\n\t    break;\n\t  if (i + 1 < hdr->sh_info)\n\t    iverneed->vn_nextref = iverneed + 1;\n\n\t  if (iverneed->vn_next\n\t      > (size_t) (contents_end - (bfd_byte *) everneed))\n\t    goto error_return_bad_verref;\n\n\t  everneed = ((Elf_External_Verneed *)\n\t\t      ((bfd_byte *) everneed + iverneed->vn_next));\n\t}\n      elf_tdata (abfd)->cverrefs = i;\n\n      free (contents);\n      contents = NULL;\n    }\n\n  if (elf_dynverdef (abfd) != 0)\n    {\n      Elf_Internal_Shdr *hdr;\n      Elf_External_Verdef *everdef;\n      Elf_Internal_Verdef *iverdef;\n      Elf_Internal_Verdef *iverdefarr;\n      Elf_Internal_Verdef iverdefmem;\n      unsigned int i;\n      unsigned int maxidx;\n      bfd_byte *contents_end_def, *contents_end_aux;\n\n      hdr = &elf_tdata (abfd)->dynverdef_hdr;\n\n      if (hdr->sh_info == 0 || hdr->sh_size < sizeof (Elf_External_Verdef))\n\t{\n\terror_return_bad_verdef:\n\t  _bfd_error_handler\n\t    (_(\"%B: .gnu.version_d invalid entry\"), abfd);\n\t  bfd_set_error (bfd_error_bad_value);\n\terror_return_verdef:\n\t  elf_tdata (abfd)->verdef = NULL;\n\t  elf_tdata (abfd)->cverdefs = 0;\n\t  goto error_return;\n\t}\n\n      contents = (bfd_byte *) bfd_malloc (hdr->sh_size);\n      if (contents == NULL)\n\tgoto error_return_verdef;\n      if (bfd_seek (abfd, hdr->sh_offset, SEEK_SET) != 0\n\t  || bfd_bread (contents, hdr->sh_size, abfd) != hdr->sh_size)\n\tgoto error_return_verdef;\n\n      BFD_ASSERT (sizeof (Elf_External_Verdef)\n\t\t  >= sizeof (Elf_External_Verdaux));\n      contents_end_def = contents + hdr->sh_size\n\t\t\t - sizeof (Elf_External_Verdef);\n      contents_end_aux = contents + hdr->sh_size\n\t\t\t - sizeof (Elf_External_Verdaux);\n\n      /* We know the number of entries in the section but not the maximum\n\t index.  Therefore we have to run through all entries and find\n\t the maximum.  */\n      everdef = (Elf_External_Verdef *) contents;\n      maxidx = 0;\n      for (i = 0; i < hdr->sh_info; ++i)\n\t{\n\t  _bfd_elf_swap_verdef_in (abfd, everdef, &iverdefmem);\n\n\t  if ((iverdefmem.vd_ndx & ((unsigned) VERSYM_VERSION)) == 0)\n\t    goto error_return_bad_verdef;\n\t  if ((iverdefmem.vd_ndx & ((unsigned) VERSYM_VERSION)) > maxidx)\n\t    maxidx = iverdefmem.vd_ndx & ((unsigned) VERSYM_VERSION);\n\n\t  if (iverdefmem.vd_next == 0)\n\t    break;\n\n\t  if (iverdefmem.vd_next\n\t      > (size_t) (contents_end_def - (bfd_byte *) everdef))\n\t    goto error_return_bad_verdef;\n\n\t  everdef = ((Elf_External_Verdef *)\n\t\t     ((bfd_byte *) everdef + iverdefmem.vd_next));\n\t}\n\n      if (default_imported_symver)\n\t{\n\t  if (freeidx > maxidx)\n\t    maxidx = ++freeidx;\n\t  else\n\t    freeidx = ++maxidx;\n\t}\n\n      elf_tdata (abfd)->verdef = (Elf_Internal_Verdef *)\n\tbfd_zalloc2 (abfd, maxidx, sizeof (Elf_Internal_Verdef));\n      if (elf_tdata (abfd)->verdef == NULL)\n\tgoto error_return_verdef;\n\n      elf_tdata (abfd)->cverdefs = maxidx;\n\n      everdef = (Elf_External_Verdef *) contents;\n      iverdefarr = elf_tdata (abfd)->verdef;\n      for (i = 0; i < hdr->sh_info; i++)\n\t{\n\t  Elf_External_Verdaux *everdaux;\n\t  Elf_Internal_Verdaux *iverdaux;\n\t  unsigned int j;\n\n\t  _bfd_elf_swap_verdef_in (abfd, everdef, &iverdefmem);\n\n\t  if ((iverdefmem.vd_ndx & VERSYM_VERSION) == 0)\n\t    goto error_return_bad_verdef;\n\n\t  iverdef = &iverdefarr[(iverdefmem.vd_ndx & VERSYM_VERSION) - 1];\n\t  memcpy (iverdef, &iverdefmem, offsetof (Elf_Internal_Verdef, vd_bfd));\n\n\t  iverdef->vd_bfd = abfd;\n\n\t  if (iverdef->vd_cnt == 0)\n\t    iverdef->vd_auxptr = NULL;\n\t  else\n\t    {\n\t      iverdef->vd_auxptr = (struct elf_internal_verdaux *)\n                  bfd_alloc2 (abfd, iverdef->vd_cnt,\n                              sizeof (Elf_Internal_Verdaux));\n\t      if (iverdef->vd_auxptr == NULL)\n\t\tgoto error_return_verdef;\n\t    }\n\n\t  if (iverdef->vd_aux\n\t      > (size_t) (contents_end_aux - (bfd_byte *) everdef))\n\t    goto error_return_bad_verdef;\n\n\t  everdaux = ((Elf_External_Verdaux *)\n\t\t      ((bfd_byte *) everdef + iverdef->vd_aux));\n\t  iverdaux = iverdef->vd_auxptr;\n\t  for (j = 0; j < iverdef->vd_cnt; j++, iverdaux++)\n\t    {\n\t      _bfd_elf_swap_verdaux_in (abfd, everdaux, iverdaux);\n\n\t      iverdaux->vda_nodename =\n\t\tbfd_elf_string_from_elf_section (abfd, hdr->sh_link,\n\t\t\t\t\t\t iverdaux->vda_name);\n\t      if (iverdaux->vda_nodename == NULL)\n\t\tgoto error_return_bad_verdef;\n\n\t      iverdaux->vda_nextptr = NULL;\n\t      if (iverdaux->vda_next == 0)\n\t\t{\n\t\t  iverdef->vd_cnt = j + 1;\n\t\t  break;\n\t\t}\n\t      if (j + 1 < iverdef->vd_cnt)\n\t\tiverdaux->vda_nextptr = iverdaux + 1;\n\n\t      if (iverdaux->vda_next\n\t\t  > (size_t) (contents_end_aux - (bfd_byte *) everdaux))\n\t\tgoto error_return_bad_verdef;\n\n\t      everdaux = ((Elf_External_Verdaux *)\n\t\t\t  ((bfd_byte *) everdaux + iverdaux->vda_next));\n\t    }\n\n\t  iverdef->vd_nodename = NULL;\n\t  if (iverdef->vd_cnt)\n\t    iverdef->vd_nodename = iverdef->vd_auxptr->vda_nodename;\n\n\t  iverdef->vd_nextdef = NULL;\n\t  if (iverdef->vd_next == 0)\n\t    break;\n\t  if ((size_t) (iverdef - iverdefarr) + 1 < maxidx)\n\t    iverdef->vd_nextdef = iverdef + 1;\n\n\t  everdef = ((Elf_External_Verdef *)\n\t\t     ((bfd_byte *) everdef + iverdef->vd_next));\n\t}\n\n      free (contents);\n      contents = NULL;\n    }\n  else if (default_imported_symver)\n    {\n      if (freeidx < 3)\n\tfreeidx = 3;\n      else\n\tfreeidx++;\n\n      elf_tdata (abfd)->verdef = (Elf_Internal_Verdef *)\n          bfd_zalloc2 (abfd, freeidx, sizeof (Elf_Internal_Verdef));\n      if (elf_tdata (abfd)->verdef == NULL)\n\tgoto error_return;\n\n      elf_tdata (abfd)->cverdefs = freeidx;\n    }\n\n  /* Create a default version based on the soname.  */\n  if (default_imported_symver)\n    {\n      Elf_Internal_Verdef *iverdef;\n      Elf_Internal_Verdaux *iverdaux;\n\n      iverdef = &elf_tdata (abfd)->verdef[freeidx - 1];\n\n      iverdef->vd_version = VER_DEF_CURRENT;\n      iverdef->vd_flags = 0;\n      iverdef->vd_ndx = freeidx;\n      iverdef->vd_cnt = 1;\n\n      iverdef->vd_bfd = abfd;\n\n      iverdef->vd_nodename = bfd_elf_get_dt_soname (abfd);\n      if (iverdef->vd_nodename == NULL)\n\tgoto error_return_verdef;\n      iverdef->vd_nextdef = NULL;\n      iverdef->vd_auxptr = ((struct elf_internal_verdaux *)\n\t\t\t    bfd_zalloc (abfd, sizeof (Elf_Internal_Verdaux)));\n      if (iverdef->vd_auxptr == NULL)\n\tgoto error_return_verdef;\n\n      iverdaux = iverdef->vd_auxptr;\n      iverdaux->vda_nodename = iverdef->vd_nodename;\n    }\n\n  return TRUE;\n\n error_return:\n  if (contents != NULL)\n    free (contents);\n  return FALSE;\n}",
        "description": "The _bfd_elf_slurp_version_tables function in the BFD library, part of GNU Binutils 2.29, is susceptible to a denial of service attack. This vulnerability arises from excessive memory allocation when processing a specially crafted ELF file, leading to potential application crashes.",
        "commit": "The vulnerability involves a memory allocation issue within the ELF (Executable and Linkable Format) handling module of a binary file format library. Specifically, the code performs a sanity check on the size of the `SHT_GNU_verneed` section, ensuring it meets certain minimum requirements related to the number of version entries (`sh_info`). Additionally, since the code either fully initializes all fields of the version entries or exits with an error, there is no need to zero-initialize the allocated memory for these entries. The fix includes modifying the `_bfd_elf_slurp_version_tables` function to test the `sh_info` field of the `SHT_GNU_verneed` section for validity and to avoid zero-initializing the memory allocated for version references."
    },
    {
        "cwe": "CWE-125",
        "func_name": "torvalds/do_split",
        "score": 0.8099257349967957,
        "func_before": "static struct ext4_dir_entry_2 *do_split(handle_t *handle, struct inode *dir,\n\t\t\tstruct buffer_head **bh,struct dx_frame *frame,\n\t\t\tstruct dx_hash_info *hinfo)\n{\n\tunsigned blocksize = dir->i_sb->s_blocksize;\n\tunsigned count, continued;\n\tstruct buffer_head *bh2;\n\text4_lblk_t newblock;\n\tu32 hash2;\n\tstruct dx_map_entry *map;\n\tchar *data1 = (*bh)->b_data, *data2;\n\tunsigned split, move, size;\n\tstruct ext4_dir_entry_2 *de = NULL, *de2;\n\tint\tcsum_size = 0;\n\tint\terr = 0, i;\n\n\tif (ext4_has_metadata_csum(dir->i_sb))\n\t\tcsum_size = sizeof(struct ext4_dir_entry_tail);\n\n\tbh2 = ext4_append(handle, dir, &newblock);\n\tif (IS_ERR(bh2)) {\n\t\tbrelse(*bh);\n\t\t*bh = NULL;\n\t\treturn (struct ext4_dir_entry_2 *) bh2;\n\t}\n\n\tBUFFER_TRACE(*bh, \"get_write_access\");\n\terr = ext4_journal_get_write_access(handle, *bh);\n\tif (err)\n\t\tgoto journal_error;\n\n\tBUFFER_TRACE(frame->bh, \"get_write_access\");\n\terr = ext4_journal_get_write_access(handle, frame->bh);\n\tif (err)\n\t\tgoto journal_error;\n\n\tdata2 = bh2->b_data;\n\n\t/* create map in the end of data2 block */\n\tmap = (struct dx_map_entry *) (data2 + blocksize);\n\tcount = dx_make_map(dir, (struct ext4_dir_entry_2 *) data1,\n\t\t\t     blocksize, hinfo, map);\n\tmap -= count;\n\tdx_sort_map(map, count);\n\t/* Split the existing block in the middle, size-wise */\n\tsize = 0;\n\tmove = 0;\n\tfor (i = count-1; i >= 0; i--) {\n\t\t/* is more than half of this entry in 2nd half of the block? */\n\t\tif (size + map[i].size/2 > blocksize/2)\n\t\t\tbreak;\n\t\tsize += map[i].size;\n\t\tmove++;\n\t}\n\t/* map index at which we will split */\n\tsplit = count - move;\n\thash2 = map[split].hash;\n\tcontinued = hash2 == map[split - 1].hash;\n\tdxtrace(printk(KERN_INFO \"Split block %lu at %x, %i/%i\\n\",\n\t\t\t(unsigned long)dx_get_block(frame->at),\n\t\t\t\t\thash2, split, count-split));\n\n\t/* Fancy dance to stay within two buffers */\n\tde2 = dx_move_dirents(data1, data2, map + split, count - split,\n\t\t\t      blocksize);\n\tde = dx_pack_dirents(data1, blocksize);\n\tde->rec_len = ext4_rec_len_to_disk(data1 + (blocksize - csum_size) -\n\t\t\t\t\t   (char *) de,\n\t\t\t\t\t   blocksize);\n\tde2->rec_len = ext4_rec_len_to_disk(data2 + (blocksize - csum_size) -\n\t\t\t\t\t    (char *) de2,\n\t\t\t\t\t    blocksize);\n\tif (csum_size) {\n\t\text4_initialize_dirent_tail(*bh, blocksize);\n\t\text4_initialize_dirent_tail(bh2, blocksize);\n\t}\n\n\tdxtrace(dx_show_leaf(dir, hinfo, (struct ext4_dir_entry_2 *) data1,\n\t\t\tblocksize, 1));\n\tdxtrace(dx_show_leaf(dir, hinfo, (struct ext4_dir_entry_2 *) data2,\n\t\t\tblocksize, 1));\n\n\t/* Which block gets the new entry? */\n\tif (hinfo->hash >= hash2) {\n\t\tswap(*bh, bh2);\n\t\tde = de2;\n\t}\n\tdx_insert_block(frame, hash2 + continued, newblock);\n\terr = ext4_handle_dirty_dirblock(handle, dir, bh2);\n\tif (err)\n\t\tgoto journal_error;\n\terr = ext4_handle_dirty_dx_node(handle, dir, frame->bh);\n\tif (err)\n\t\tgoto journal_error;\n\tbrelse(bh2);\n\tdxtrace(dx_show_index(\"frame\", frame->entries));\n\treturn de;\n\njournal_error:\n\tbrelse(*bh);\n\tbrelse(bh2);\n\t*bh = NULL;\n\text4_std_error(dir->i_sb, err);\n\treturn ERR_PTR(err);\n}",
        "func_after": "static struct ext4_dir_entry_2 *do_split(handle_t *handle, struct inode *dir,\n\t\t\tstruct buffer_head **bh,struct dx_frame *frame,\n\t\t\tstruct dx_hash_info *hinfo)\n{\n\tunsigned blocksize = dir->i_sb->s_blocksize;\n\tunsigned count, continued;\n\tstruct buffer_head *bh2;\n\text4_lblk_t newblock;\n\tu32 hash2;\n\tstruct dx_map_entry *map;\n\tchar *data1 = (*bh)->b_data, *data2;\n\tunsigned split, move, size;\n\tstruct ext4_dir_entry_2 *de = NULL, *de2;\n\tint\tcsum_size = 0;\n\tint\terr = 0, i;\n\n\tif (ext4_has_metadata_csum(dir->i_sb))\n\t\tcsum_size = sizeof(struct ext4_dir_entry_tail);\n\n\tbh2 = ext4_append(handle, dir, &newblock);\n\tif (IS_ERR(bh2)) {\n\t\tbrelse(*bh);\n\t\t*bh = NULL;\n\t\treturn (struct ext4_dir_entry_2 *) bh2;\n\t}\n\n\tBUFFER_TRACE(*bh, \"get_write_access\");\n\terr = ext4_journal_get_write_access(handle, *bh);\n\tif (err)\n\t\tgoto journal_error;\n\n\tBUFFER_TRACE(frame->bh, \"get_write_access\");\n\terr = ext4_journal_get_write_access(handle, frame->bh);\n\tif (err)\n\t\tgoto journal_error;\n\n\tdata2 = bh2->b_data;\n\n\t/* create map in the end of data2 block */\n\tmap = (struct dx_map_entry *) (data2 + blocksize);\n\tcount = dx_make_map(dir, (struct ext4_dir_entry_2 *) data1,\n\t\t\t     blocksize, hinfo, map);\n\tmap -= count;\n\tdx_sort_map(map, count);\n\t/* Ensure that neither split block is over half full */\n\tsize = 0;\n\tmove = 0;\n\tfor (i = count-1; i >= 0; i--) {\n\t\t/* is more than half of this entry in 2nd half of the block? */\n\t\tif (size + map[i].size/2 > blocksize/2)\n\t\t\tbreak;\n\t\tsize += map[i].size;\n\t\tmove++;\n\t}\n\t/*\n\t * map index at which we will split\n\t *\n\t * If the sum of active entries didn't exceed half the block size, just\n\t * split it in half by count; each resulting block will have at least\n\t * half the space free.\n\t */\n\tif (i > 0)\n\t\tsplit = count - move;\n\telse\n\t\tsplit = count/2;\n\n\thash2 = map[split].hash;\n\tcontinued = hash2 == map[split - 1].hash;\n\tdxtrace(printk(KERN_INFO \"Split block %lu at %x, %i/%i\\n\",\n\t\t\t(unsigned long)dx_get_block(frame->at),\n\t\t\t\t\thash2, split, count-split));\n\n\t/* Fancy dance to stay within two buffers */\n\tde2 = dx_move_dirents(data1, data2, map + split, count - split,\n\t\t\t      blocksize);\n\tde = dx_pack_dirents(data1, blocksize);\n\tde->rec_len = ext4_rec_len_to_disk(data1 + (blocksize - csum_size) -\n\t\t\t\t\t   (char *) de,\n\t\t\t\t\t   blocksize);\n\tde2->rec_len = ext4_rec_len_to_disk(data2 + (blocksize - csum_size) -\n\t\t\t\t\t    (char *) de2,\n\t\t\t\t\t    blocksize);\n\tif (csum_size) {\n\t\text4_initialize_dirent_tail(*bh, blocksize);\n\t\text4_initialize_dirent_tail(bh2, blocksize);\n\t}\n\n\tdxtrace(dx_show_leaf(dir, hinfo, (struct ext4_dir_entry_2 *) data1,\n\t\t\tblocksize, 1));\n\tdxtrace(dx_show_leaf(dir, hinfo, (struct ext4_dir_entry_2 *) data2,\n\t\t\tblocksize, 1));\n\n\t/* Which block gets the new entry? */\n\tif (hinfo->hash >= hash2) {\n\t\tswap(*bh, bh2);\n\t\tde = de2;\n\t}\n\tdx_insert_block(frame, hash2 + continued, newblock);\n\terr = ext4_handle_dirty_dirblock(handle, dir, bh2);\n\tif (err)\n\t\tgoto journal_error;\n\terr = ext4_handle_dirty_dx_node(handle, dir, frame->bh);\n\tif (err)\n\t\tgoto journal_error;\n\tbrelse(bh2);\n\tdxtrace(dx_show_index(\"frame\", frame->entries));\n\treturn de;\n\njournal_error:\n\tbrelse(*bh);\n\tbrelse(bh2);\n\t*bh = NULL;\n\text4_std_error(dir->i_sb, err);\n\treturn ERR_PTR(err);\n}",
        "description": "A memory out-of-bounds read flaw was identified in the Linux kernel prior to version 5.9-rc2, specifically within the ext3/ext4 file system. This flaw occurs when accessing a directory with broken indexing, potentially allowing a local user to crash the system if such a directory exists. The primary risk associated with this vulnerability is a decrease in system availability.",
        "commit": "If a directory passed to the `do_split()` function lacks sufficient active entries to surpass half the block size, it may result in iterating through all \"count\" entries without identifying a split point. In such cases, where `count` equals `move` and `split` becomes zero, an attempt to access a negative index in the `map[]` array could occur. To prevent this, detect this scenario and fall back to splitting at half of the count, ensuring that each split block still has ample space greater than half the block size."
    },
    {
        "cwe": "CWE-662",
        "func_name": "torvalds/do_fontx_ioctl",
        "score": 0.7807816863059998,
        "func_before": "static inline int do_fontx_ioctl(int cmd,\n\t\tstruct consolefontdesc __user *user_cfd,\n\t\tstruct console_font_op *op)\n{\n\tstruct consolefontdesc cfdarg;\n\tint i;\n\n\tif (copy_from_user(&cfdarg, user_cfd, sizeof(struct consolefontdesc)))\n\t\treturn -EFAULT;\n\n\tswitch (cmd) {\n\tcase PIO_FONTX:\n\t\top->op = KD_FONT_OP_SET;\n\t\top->flags = KD_FONT_FLAG_OLD;\n\t\top->width = 8;\n\t\top->height = cfdarg.charheight;\n\t\top->charcount = cfdarg.charcount;\n\t\top->data = cfdarg.chardata;\n\t\treturn con_font_op(vc_cons[fg_console].d, op);\n\tcase GIO_FONTX: {\n\t\top->op = KD_FONT_OP_GET;\n\t\top->flags = KD_FONT_FLAG_OLD;\n\t\top->width = 8;\n\t\top->height = cfdarg.charheight;\n\t\top->charcount = cfdarg.charcount;\n\t\top->data = cfdarg.chardata;\n\t\ti = con_font_op(vc_cons[fg_console].d, op);\n\t\tif (i)\n\t\t\treturn i;\n\t\tcfdarg.charheight = op->height;\n\t\tcfdarg.charcount = op->charcount;\n\t\tif (copy_to_user(user_cfd, &cfdarg, sizeof(struct consolefontdesc)))\n\t\t\treturn -EFAULT;\n\t\treturn 0;\n\t\t}\n\t}\n\treturn -EINVAL;\n}",
        "func_after": "static inline int do_fontx_ioctl(struct vc_data *vc, int cmd,\n\t\tstruct consolefontdesc __user *user_cfd,\n\t\tstruct console_font_op *op)\n{\n\tstruct consolefontdesc cfdarg;\n\tint i;\n\n\tif (copy_from_user(&cfdarg, user_cfd, sizeof(struct consolefontdesc)))\n\t\treturn -EFAULT;\n\n\tswitch (cmd) {\n\tcase PIO_FONTX:\n\t\top->op = KD_FONT_OP_SET;\n\t\top->flags = KD_FONT_FLAG_OLD;\n\t\top->width = 8;\n\t\top->height = cfdarg.charheight;\n\t\top->charcount = cfdarg.charcount;\n\t\top->data = cfdarg.chardata;\n\t\treturn con_font_op(vc, op);\n\n\tcase GIO_FONTX:\n\t\top->op = KD_FONT_OP_GET;\n\t\top->flags = KD_FONT_FLAG_OLD;\n\t\top->width = 8;\n\t\top->height = cfdarg.charheight;\n\t\top->charcount = cfdarg.charcount;\n\t\top->data = cfdarg.chardata;\n\t\ti = con_font_op(vc, op);\n\t\tif (i)\n\t\t\treturn i;\n\t\tcfdarg.charheight = op->height;\n\t\tcfdarg.charcount = op->charcount;\n\t\tif (copy_to_user(user_cfd, &cfdarg, sizeof(struct consolefontdesc)))\n\t\t\treturn -EFAULT;\n\t\treturn 0;\n\t}\n\treturn -EINVAL;\n}",
        "description": "A flaw was identified in the Linux Kernel where access to a global variable used for managing the foreground console is not adequately synchronized, resulting in a use-after-free error within the function responsible for font operations.",
        "commit": "Some font-related terminal I/O control operations previously utilized the current foreground virtual console (VC) for their execution. This practice has been discontinued to address a data race condition involving the `fg_console` variable. Notably, both Michael Ellerman and Jiri Slaby have observed that these I/O control operations are deprecated and should have been removed earlier. They suggest that most systems now use the `KDFONTOP` ioctl instead. Additionally, Michael notes that BusyBox's `loadfont` program transitioned to using `KDFONTOP` precisely due to this bug, which was identified approximately 12 years ago."
    }
]