[
    {
        "cwe": "CWE-129",
        "func_name": "admesh/stl_fix_normal_directions",
        "score": 0.7139195799827576,
        "func_before": "void\nstl_fix_normal_directions(stl_file *stl) {\n  char *norm_sw;\n  /*  int edge_num;*/\n  /*  int vnot;*/\n  int checked = 0;\n  int facet_num;\n  /*  int next_facet;*/\n  int i;\n  int j;\n  struct stl_normal {\n    int               facet_num;\n    struct stl_normal *next;\n  };\n  struct stl_normal *head;\n  struct stl_normal *tail;\n  struct stl_normal *newn;\n  struct stl_normal *temp;\n\n  if (stl->error) return;\n\n  /* Initialize linked list. */\n  head = (struct stl_normal*)malloc(sizeof(struct stl_normal));\n  if(head == NULL) perror(\"stl_fix_normal_directions\");\n  tail = (struct stl_normal*)malloc(sizeof(struct stl_normal));\n  if(tail == NULL) perror(\"stl_fix_normal_directions\");\n  head->next = tail;\n  tail->next = tail;\n\n  /* Initialize list that keeps track of already fixed facets. */\n  norm_sw = (char*)calloc(stl->stats.number_of_facets, sizeof(char));\n  if(norm_sw == NULL) perror(\"stl_fix_normal_directions\");\n\n\n  facet_num = 0;\n  /* If normal vector is not within tolerance and backwards:\n     Arbitrarily starts at face 0.  If this one is wrong, we're screwed.  Thankfully, the chances\n     of it being wrong randomly are low if most of the triangles are right: */\n  if(stl_check_normal_vector(stl, 0, 0) == 2)\n    stl_reverse_facet(stl, 0);\n\n  /* Say that we've fixed this facet: */\n  norm_sw[facet_num] = 1;\n  checked++;\n\n  for(;;) {\n    /* Add neighbors_to_list.\n       Add unconnected neighbors to the list:a  */\n    for(j = 0; j < 3; j++) {\n      /* Reverse the neighboring facets if necessary. */\n      if(stl->neighbors_start[facet_num].which_vertex_not[j] > 2) {\n        /* If the facet has a neighbor that is -1, it means that edge isn't shared by another facet */\n        if(stl->neighbors_start[facet_num].neighbor[j] != -1) {\n          stl_reverse_facet\n          (stl, stl->neighbors_start[facet_num].neighbor[j]);\n        }\n      }\n      /* If this edge of the facet is connected: */\n      if(stl->neighbors_start[facet_num].neighbor[j] != -1) {\n        /* If we haven't fixed this facet yet, add it to the list: */\n        if(norm_sw[stl->neighbors_start[facet_num].neighbor[j]] != 1) {\n          /* Add node to beginning of list. */\n          newn = (struct stl_normal*)malloc(sizeof(struct stl_normal));\n          if(newn == NULL) perror(\"stl_fix_normal_directions\");\n          newn->facet_num = stl->neighbors_start[facet_num].neighbor[j];\n          newn->next = head->next;\n          head->next = newn;\n        }\n      }\n    }\n    /* Get next facet to fix from top of list. */\n    if(head->next != tail) {\n      facet_num = head->next->facet_num;\n      if(norm_sw[facet_num] != 1) { /* If facet is in list mutiple times */\n        norm_sw[facet_num] = 1; /* Record this one as being fixed. */\n        checked++;\n      }\n      temp = head->next;\t/* Delete this facet from the list. */\n      head->next = head->next->next;\n      free(temp);\n    } else { /* if we ran out of facets to fix: */\n      /* All of the facets in this part have been fixed. */\n      stl->stats.number_of_parts += 1;\n      if(checked >= stl->stats.number_of_facets) {\n        /* All of the facets have been checked.  Bail out. */\n        break;\n      } else {\n        /* There is another part here.  Find it and continue. */\n        for(i = 0; i < stl->stats.number_of_facets; i++) {\n          if(norm_sw[i] == 0) {\n            /* This is the first facet of the next part. */\n            facet_num = i;\n            if(stl_check_normal_vector(stl, i, 0) == 2) {\n              stl_reverse_facet(stl, i);\n            }\n\n            norm_sw[facet_num] = 1;\n            checked++;\n            break;\n          }\n        }\n      }\n    }\n  }\n  free(head);\n  free(tail);\n  free(norm_sw);\n}",
        "func_after": "void\nstl_fix_normal_directions(stl_file *stl) {\n  char *norm_sw;\n  /*  int edge_num;*/\n  /*  int vnot;*/\n  int checked = 0;\n  int facet_num;\n  /*  int next_facet;*/\n  int i;\n  int j;\n  struct stl_normal {\n    int               facet_num;\n    struct stl_normal *next;\n  };\n  struct stl_normal *head;\n  struct stl_normal *tail;\n  struct stl_normal *newn;\n  struct stl_normal *temp;\n\n  if (stl->error) return;\n\n  /* Initialize linked list. */\n  head = (struct stl_normal*)malloc(sizeof(struct stl_normal));\n  if(head == NULL) perror(\"stl_fix_normal_directions\");\n  tail = (struct stl_normal*)malloc(sizeof(struct stl_normal));\n  if(tail == NULL) perror(\"stl_fix_normal_directions\");\n  head->next = tail;\n  tail->next = tail;\n\n  /* Initialize list that keeps track of already fixed facets. */\n  norm_sw = (char*)calloc(stl->stats.number_of_facets, sizeof(char));\n  if(norm_sw == NULL) perror(\"stl_fix_normal_directions\");\n\n\n  facet_num = 0;\n  /* If normal vector is not within tolerance and backwards:\n     Arbitrarily starts at face 0.  If this one is wrong, we're screwed.  Thankfully, the chances\n     of it being wrong randomly are low if most of the triangles are right: */\n  if(stl_check_normal_vector(stl, 0, 0) == 2)\n    stl_reverse_facet(stl, 0);\n\n  /* Say that we've fixed this facet: */\n  norm_sw[facet_num] = 1;\n  checked++;\n\n  for(;;) {\n    /* Add neighbors_to_list.\n       Add unconnected neighbors to the list:a  */\n    for(j = 0; j < 3; j++) {\n      /* Reverse the neighboring facets if necessary. */\n      if(stl->neighbors_start[facet_num].which_vertex_not[j] > 2) {\n        /* If the facet has a neighbor that is -1, it means that edge isn't shared by another facet */\n        if(stl->neighbors_start[facet_num].neighbor[j] != -1) {\n          stl_reverse_facet\n          (stl, stl->neighbors_start[facet_num].neighbor[j]);\n        }\n      }\n      /* If this edge of the facet is connected: */\n      if(stl->neighbors_start[facet_num].neighbor[j] != -1 &&\n         stl->neighbors_start[facet_num].neighbor[j] < stl->stats.number_of_facets*sizeof(char)) {\n        /* If we haven't fixed this facet yet, add it to the list: */\n        if(norm_sw[stl->neighbors_start[facet_num].neighbor[j]] != 1) {\n          /* Add node to beginning of list. */\n          newn = (struct stl_normal*)malloc(sizeof(struct stl_normal));\n          if(newn == NULL) perror(\"stl_fix_normal_directions\");\n          newn->facet_num = stl->neighbors_start[facet_num].neighbor[j];\n          newn->next = head->next;\n          head->next = newn;\n        }\n      }\n    }\n    /* Get next facet to fix from top of list. */\n    if(head->next != tail) {\n      facet_num = head->next->facet_num;\n      if(norm_sw[facet_num] != 1) { /* If facet is in list mutiple times */\n        norm_sw[facet_num] = 1; /* Record this one as being fixed. */\n        checked++;\n      }\n      temp = head->next;\t/* Delete this facet from the list. */\n      head->next = head->next->next;\n      free(temp);\n    } else { /* if we ran out of facets to fix: */\n      /* All of the facets in this part have been fixed. */\n      stl->stats.number_of_parts += 1;\n      if(checked >= stl->stats.number_of_facets) {\n        /* All of the facets have been checked.  Bail out. */\n        break;\n      } else {\n        /* There is another part here.  Find it and continue. */\n        for(i = 0; i < stl->stats.number_of_facets; i++) {\n          if(norm_sw[i] == 0) {\n            /* This is the first facet of the next part. */\n            facet_num = i;\n            if(stl_check_normal_vector(stl, i, 0) == 2) {\n              stl_reverse_facet(stl, i);\n            }\n\n            norm_sw[facet_num] = 1;\n            checked++;\n            break;\n          }\n        }\n      }\n    }\n  }\n  free(head);\n  free(tail);\n  free(norm_sw);\n}",
        "description": "An improper array index validation vulnerability exists in the stl_fix_normal_directions functionality of ADMesh. A specially-crafted STL file can lead to a heap buffer overflow. An attacker can exploit this by providing a malicious file.",
        "commit": "The vulnerability involves a check for the `neighbor_index` within the `stl_check_normal_vector` function. This fix addresses an issue identified in ticket #60."
    },
    {
        "cwe": "CWE-20",
        "func_name": "torvalds/cifs_lookup",
        "score": 0.7430855631828308,
        "func_before": "struct dentry *\ncifs_lookup(struct inode *parent_dir_inode, struct dentry *direntry,\n\t    struct nameidata *nd)\n{\n\tint xid;\n\tint rc = 0; /* to get around spurious gcc warning, set to zero here */\n\t__u32 oplock = enable_oplocks ? REQ_OPLOCK : 0;\n\t__u16 fileHandle = 0;\n\tbool posix_open = false;\n\tstruct cifs_sb_info *cifs_sb;\n\tstruct tcon_link *tlink;\n\tstruct cifs_tcon *pTcon;\n\tstruct cifsFileInfo *cfile;\n\tstruct inode *newInode = NULL;\n\tchar *full_path = NULL;\n\tstruct file *filp;\n\n\txid = GetXid();\n\n\tcFYI(1, \"parent inode = 0x%p name is: %s and dentry = 0x%p\",\n\t      parent_dir_inode, direntry->d_name.name, direntry);\n\n\t/* check whether path exists */\n\n\tcifs_sb = CIFS_SB(parent_dir_inode->i_sb);\n\ttlink = cifs_sb_tlink(cifs_sb);\n\tif (IS_ERR(tlink)) {\n\t\tFreeXid(xid);\n\t\treturn (struct dentry *)tlink;\n\t}\n\tpTcon = tlink_tcon(tlink);\n\n\t/*\n\t * Don't allow the separator character in a path component.\n\t * The VFS will not allow \"/\", but \"\\\" is allowed by posix.\n\t */\n\tif (!(cifs_sb->mnt_cifs_flags & CIFS_MOUNT_POSIX_PATHS)) {\n\t\tint i;\n\t\tfor (i = 0; i < direntry->d_name.len; i++)\n\t\t\tif (direntry->d_name.name[i] == '\\\\') {\n\t\t\t\tcFYI(1, \"Invalid file name\");\n\t\t\t\trc = -EINVAL;\n\t\t\t\tgoto lookup_out;\n\t\t\t}\n\t}\n\n\t/*\n\t * O_EXCL: optimize away the lookup, but don't hash the dentry. Let\n\t * the VFS handle the create.\n\t */\n\tif (nd && (nd->flags & LOOKUP_EXCL)) {\n\t\td_instantiate(direntry, NULL);\n\t\trc = 0;\n\t\tgoto lookup_out;\n\t}\n\n\t/* can not grab the rename sem here since it would\n\tdeadlock in the cases (beginning of sys_rename itself)\n\tin which we already have the sb rename sem */\n\tfull_path = build_path_from_dentry(direntry);\n\tif (full_path == NULL) {\n\t\trc = -ENOMEM;\n\t\tgoto lookup_out;\n\t}\n\n\tif (direntry->d_inode != NULL) {\n\t\tcFYI(1, \"non-NULL inode in lookup\");\n\t} else {\n\t\tcFYI(1, \"NULL inode in lookup\");\n\t}\n\tcFYI(1, \"Full path: %s inode = 0x%p\", full_path, direntry->d_inode);\n\n\t/* Posix open is only called (at lookup time) for file create now.\n\t * For opens (rather than creates), because we do not know if it\n\t * is a file or directory yet, and current Samba no longer allows\n\t * us to do posix open on dirs, we could end up wasting an open call\n\t * on what turns out to be a dir. For file opens, we wait to call posix\n\t * open till cifs_open.  It could be added here (lookup) in the future\n\t * but the performance tradeoff of the extra network request when EISDIR\n\t * or EACCES is returned would have to be weighed against the 50%\n\t * reduction in network traffic in the other paths.\n\t */\n\tif (pTcon->unix_ext) {\n\t\tif (nd && !(nd->flags & LOOKUP_DIRECTORY) &&\n\t\t     (nd->flags & LOOKUP_OPEN) && !pTcon->broken_posix_open &&\n\t\t     (nd->intent.open.file->f_flags & O_CREAT)) {\n\t\t\trc = cifs_posix_open(full_path, &newInode,\n\t\t\t\t\tparent_dir_inode->i_sb,\n\t\t\t\t\tnd->intent.open.create_mode,\n\t\t\t\t\tnd->intent.open.file->f_flags, &oplock,\n\t\t\t\t\t&fileHandle, xid);\n\t\t\t/*\n\t\t\t * The check below works around a bug in POSIX\n\t\t\t * open in samba versions 3.3.1 and earlier where\n\t\t\t * open could incorrectly fail with invalid parameter.\n\t\t\t * If either that or op not supported returned, follow\n\t\t\t * the normal lookup.\n\t\t\t */\n\t\t\tif ((rc == 0) || (rc == -ENOENT))\n\t\t\t\tposix_open = true;\n\t\t\telse if ((rc == -EINVAL) || (rc != -EOPNOTSUPP))\n\t\t\t\tpTcon->broken_posix_open = true;\n\t\t}\n\t\tif (!posix_open)\n\t\t\trc = cifs_get_inode_info_unix(&newInode, full_path,\n\t\t\t\t\t\tparent_dir_inode->i_sb, xid);\n\t} else\n\t\trc = cifs_get_inode_info(&newInode, full_path, NULL,\n\t\t\t\tparent_dir_inode->i_sb, xid, NULL);\n\n\tif ((rc == 0) && (newInode != NULL)) {\n\t\td_add(direntry, newInode);\n\t\tif (posix_open) {\n\t\t\tfilp = lookup_instantiate_filp(nd, direntry,\n\t\t\t\t\t\t       generic_file_open);\n\t\t\tif (IS_ERR(filp)) {\n\t\t\t\trc = PTR_ERR(filp);\n\t\t\t\tCIFSSMBClose(xid, pTcon, fileHandle);\n\t\t\t\tgoto lookup_out;\n\t\t\t}\n\n\t\t\tcfile = cifs_new_fileinfo(fileHandle, filp, tlink,\n\t\t\t\t\t\t  oplock);\n\t\t\tif (cfile == NULL) {\n\t\t\t\tfput(filp);\n\t\t\t\tCIFSSMBClose(xid, pTcon, fileHandle);\n\t\t\t\trc = -ENOMEM;\n\t\t\t\tgoto lookup_out;\n\t\t\t}\n\t\t}\n\t\t/* since paths are not looked up by component - the parent\n\t\t   directories are presumed to be good here */\n\t\trenew_parental_timestamps(direntry);\n\n\t} else if (rc == -ENOENT) {\n\t\trc = 0;\n\t\tdirentry->d_time = jiffies;\n\t\td_add(direntry, NULL);\n\t/*\tif it was once a directory (but how can we tell?) we could do\n\t\tshrink_dcache_parent(direntry); */\n\t} else if (rc != -EACCES) {\n\t\tcERROR(1, \"Unexpected lookup error %d\", rc);\n\t\t/* We special case check for Access Denied - since that\n\t\tis a common return code */\n\t}\n\nlookup_out:\n\tkfree(full_path);\n\tcifs_put_tlink(tlink);\n\tFreeXid(xid);\n\treturn ERR_PTR(rc);\n}",
        "func_after": "struct dentry *\ncifs_lookup(struct inode *parent_dir_inode, struct dentry *direntry,\n\t    struct nameidata *nd)\n{\n\tint xid;\n\tint rc = 0; /* to get around spurious gcc warning, set to zero here */\n\t__u32 oplock = enable_oplocks ? REQ_OPLOCK : 0;\n\t__u16 fileHandle = 0;\n\tbool posix_open = false;\n\tstruct cifs_sb_info *cifs_sb;\n\tstruct tcon_link *tlink;\n\tstruct cifs_tcon *pTcon;\n\tstruct cifsFileInfo *cfile;\n\tstruct inode *newInode = NULL;\n\tchar *full_path = NULL;\n\tstruct file *filp;\n\n\txid = GetXid();\n\n\tcFYI(1, \"parent inode = 0x%p name is: %s and dentry = 0x%p\",\n\t      parent_dir_inode, direntry->d_name.name, direntry);\n\n\t/* check whether path exists */\n\n\tcifs_sb = CIFS_SB(parent_dir_inode->i_sb);\n\ttlink = cifs_sb_tlink(cifs_sb);\n\tif (IS_ERR(tlink)) {\n\t\tFreeXid(xid);\n\t\treturn (struct dentry *)tlink;\n\t}\n\tpTcon = tlink_tcon(tlink);\n\n\t/*\n\t * Don't allow the separator character in a path component.\n\t * The VFS will not allow \"/\", but \"\\\" is allowed by posix.\n\t */\n\tif (!(cifs_sb->mnt_cifs_flags & CIFS_MOUNT_POSIX_PATHS)) {\n\t\tint i;\n\t\tfor (i = 0; i < direntry->d_name.len; i++)\n\t\t\tif (direntry->d_name.name[i] == '\\\\') {\n\t\t\t\tcFYI(1, \"Invalid file name\");\n\t\t\t\trc = -EINVAL;\n\t\t\t\tgoto lookup_out;\n\t\t\t}\n\t}\n\n\t/*\n\t * O_EXCL: optimize away the lookup, but don't hash the dentry. Let\n\t * the VFS handle the create.\n\t */\n\tif (nd && (nd->flags & LOOKUP_EXCL)) {\n\t\td_instantiate(direntry, NULL);\n\t\trc = 0;\n\t\tgoto lookup_out;\n\t}\n\n\t/* can not grab the rename sem here since it would\n\tdeadlock in the cases (beginning of sys_rename itself)\n\tin which we already have the sb rename sem */\n\tfull_path = build_path_from_dentry(direntry);\n\tif (full_path == NULL) {\n\t\trc = -ENOMEM;\n\t\tgoto lookup_out;\n\t}\n\n\tif (direntry->d_inode != NULL) {\n\t\tcFYI(1, \"non-NULL inode in lookup\");\n\t} else {\n\t\tcFYI(1, \"NULL inode in lookup\");\n\t}\n\tcFYI(1, \"Full path: %s inode = 0x%p\", full_path, direntry->d_inode);\n\n\t/* Posix open is only called (at lookup time) for file create now.\n\t * For opens (rather than creates), because we do not know if it\n\t * is a file or directory yet, and current Samba no longer allows\n\t * us to do posix open on dirs, we could end up wasting an open call\n\t * on what turns out to be a dir. For file opens, we wait to call posix\n\t * open till cifs_open.  It could be added here (lookup) in the future\n\t * but the performance tradeoff of the extra network request when EISDIR\n\t * or EACCES is returned would have to be weighed against the 50%\n\t * reduction in network traffic in the other paths.\n\t */\n\tif (pTcon->unix_ext) {\n\t\tif (nd && !(nd->flags & LOOKUP_DIRECTORY) &&\n\t\t     (nd->flags & LOOKUP_OPEN) && !pTcon->broken_posix_open &&\n\t\t     (nd->intent.open.file->f_flags & O_CREAT)) {\n\t\t\trc = cifs_posix_open(full_path, &newInode,\n\t\t\t\t\tparent_dir_inode->i_sb,\n\t\t\t\t\tnd->intent.open.create_mode,\n\t\t\t\t\tnd->intent.open.file->f_flags, &oplock,\n\t\t\t\t\t&fileHandle, xid);\n\t\t\t/*\n\t\t\t * The check below works around a bug in POSIX\n\t\t\t * open in samba versions 3.3.1 and earlier where\n\t\t\t * open could incorrectly fail with invalid parameter.\n\t\t\t * If either that or op not supported returned, follow\n\t\t\t * the normal lookup.\n\t\t\t */\n\t\t\tswitch (rc) {\n\t\t\tcase 0:\n\t\t\t\t/*\n\t\t\t\t * The server may allow us to open things like\n\t\t\t\t * FIFOs, but the client isn't set up to deal\n\t\t\t\t * with that. If it's not a regular file, just\n\t\t\t\t * close it and proceed as if it were a normal\n\t\t\t\t * lookup.\n\t\t\t\t */\n\t\t\t\tif (newInode && !S_ISREG(newInode->i_mode)) {\n\t\t\t\t\tCIFSSMBClose(xid, pTcon, fileHandle);\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\tcase -ENOENT:\n\t\t\t\tposix_open = true;\n\t\t\tcase -EOPNOTSUPP:\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tpTcon->broken_posix_open = true;\n\t\t\t}\n\t\t}\n\t\tif (!posix_open)\n\t\t\trc = cifs_get_inode_info_unix(&newInode, full_path,\n\t\t\t\t\t\tparent_dir_inode->i_sb, xid);\n\t} else\n\t\trc = cifs_get_inode_info(&newInode, full_path, NULL,\n\t\t\t\tparent_dir_inode->i_sb, xid, NULL);\n\n\tif ((rc == 0) && (newInode != NULL)) {\n\t\td_add(direntry, newInode);\n\t\tif (posix_open) {\n\t\t\tfilp = lookup_instantiate_filp(nd, direntry,\n\t\t\t\t\t\t       generic_file_open);\n\t\t\tif (IS_ERR(filp)) {\n\t\t\t\trc = PTR_ERR(filp);\n\t\t\t\tCIFSSMBClose(xid, pTcon, fileHandle);\n\t\t\t\tgoto lookup_out;\n\t\t\t}\n\n\t\t\tcfile = cifs_new_fileinfo(fileHandle, filp, tlink,\n\t\t\t\t\t\t  oplock);\n\t\t\tif (cfile == NULL) {\n\t\t\t\tfput(filp);\n\t\t\t\tCIFSSMBClose(xid, pTcon, fileHandle);\n\t\t\t\trc = -ENOMEM;\n\t\t\t\tgoto lookup_out;\n\t\t\t}\n\t\t}\n\t\t/* since paths are not looked up by component - the parent\n\t\t   directories are presumed to be good here */\n\t\trenew_parental_timestamps(direntry);\n\n\t} else if (rc == -ENOENT) {\n\t\trc = 0;\n\t\tdirentry->d_time = jiffies;\n\t\td_add(direntry, NULL);\n\t/*\tif it was once a directory (but how can we tell?) we could do\n\t\tshrink_dcache_parent(direntry); */\n\t} else if (rc != -EACCES) {\n\t\tcERROR(1, \"Unexpected lookup error %d\", rc);\n\t\t/* We special case check for Access Denied - since that\n\t\tis a common return code */\n\t}\n\nlookup_out:\n\tkfree(full_path);\n\tcifs_put_tlink(tlink);\n\tFreeXid(xid);\n\treturn ERR_PTR(rc);\n}",
        "description": "The `cifs_lookup` function in the CIFS directory handling module of the Linux kernel, prior to version 3.2.10, permits local users to trigger a denial of service (OOPS) condition by attempting to access a special file, such as a FIFO.",
        "commit": "The CIFS code attempts to open files during lookup under specific conditions. However, if the file turned out to be a FIFO or another special file type, the open file handle would be leaked, resulting in a dentry reference count mismatch and causing an oops error during unmount. This issue has been resolved by ensuring that the file handle on the server is closed if the file is not a regular file. Additionally, the code has been refactored to use a switch statement instead of a complex if-else structure."
    },
    {
        "cwe": "CWE-1284",
        "func_name": "Samsung/crypto_bignum_allocate",
        "score": 0.7131437659263611,
        "func_before": "struct bignum *crypto_bignum_allocate(size_t size_bits)\n{\n\tsize_t sz = mpa_StaticVarSizeInU32(size_bits) *\tsizeof(uint32_t);\n\tstruct mpa_numbase_struct *bn = calloc(1, sz);\n\n\tif (!bn)\n\t\treturn NULL;\n\tbn->alloc = sz - MPA_NUMBASE_METADATA_SIZE_IN_U32 * sizeof(uint32_t);\n\treturn (struct bignum *)bn;\n}",
        "func_after": "struct bignum *crypto_bignum_allocate(size_t size_bits)\n{\n\tsize_t sz = mpa_StaticVarSizeInU32(size_bits) *\tsizeof(uint32_t);\n\t// struct mpa_numbase_struct *bn = calloc(1, sz);\n\tstruct mpa_numbase_struct *bn= TEE_Malloc(sz, TEE_MALLOC_FILL_ZERO);\n\tif (!bn)\n\t\treturn NULL;\n\tbn->alloc = sz - MPA_NUMBASE_METADATA_SIZE_IN_U32 * sizeof(uint32_t);\n\treturn (struct bignum *)bn;\n}",
        "description": "The function `tee_obj_free` in Samsung mTower through version 0.3.0 enables a trusted application to cause a Denial of Service (DoS) by calling the function `TEE_AllocateOperation` with a disrupted heap layout, which is associated with `utee_cryp_obj_alloc`.",
        "commit": "A vulnerability has been addressed in a software system, specifically identified by CVE-2022-40761."
    },
    {
        "cwe": "CWE-330",
        "func_name": "torvalds/sfb_enqueue",
        "score": 0.737171471118927,
        "func_before": "static int sfb_enqueue(struct sk_buff *skb, struct Qdisc *sch,\n\t\t       struct sk_buff **to_free)\n{\n\n\tstruct sfb_sched_data *q = qdisc_priv(sch);\n\tstruct Qdisc *child = q->qdisc;\n\tstruct tcf_proto *fl;\n\tint i;\n\tu32 p_min = ~0;\n\tu32 minqlen = ~0;\n\tu32 r, sfbhash;\n\tu32 slot = q->slot;\n\tint ret = NET_XMIT_SUCCESS | __NET_XMIT_BYPASS;\n\n\tif (unlikely(sch->q.qlen >= q->limit)) {\n\t\tqdisc_qstats_overlimit(sch);\n\t\tq->stats.queuedrop++;\n\t\tgoto drop;\n\t}\n\n\tif (q->rehash_interval > 0) {\n\t\tunsigned long limit = q->rehash_time + q->rehash_interval;\n\n\t\tif (unlikely(time_after(jiffies, limit))) {\n\t\t\tsfb_swap_slot(q);\n\t\t\tq->rehash_time = jiffies;\n\t\t} else if (unlikely(!q->double_buffering && q->warmup_time > 0 &&\n\t\t\t\t    time_after(jiffies, limit - q->warmup_time))) {\n\t\t\tq->double_buffering = true;\n\t\t}\n\t}\n\n\tfl = rcu_dereference_bh(q->filter_list);\n\tif (fl) {\n\t\tu32 salt;\n\n\t\t/* If using external classifiers, get result and record it. */\n\t\tif (!sfb_classify(skb, fl, &ret, &salt))\n\t\t\tgoto other_drop;\n\t\tsfbhash = jhash_1word(salt, q->bins[slot].perturbation);\n\t} else {\n\t\tsfbhash = skb_get_hash_perturb(skb, q->bins[slot].perturbation);\n\t}\n\n\n\tif (!sfbhash)\n\t\tsfbhash = 1;\n\tsfb_skb_cb(skb)->hashes[slot] = sfbhash;\n\n\tfor (i = 0; i < SFB_LEVELS; i++) {\n\t\tu32 hash = sfbhash & SFB_BUCKET_MASK;\n\t\tstruct sfb_bucket *b = &q->bins[slot].bins[i][hash];\n\n\t\tsfbhash >>= SFB_BUCKET_SHIFT;\n\t\tif (b->qlen == 0)\n\t\t\tdecrement_prob(b, q);\n\t\telse if (b->qlen >= q->bin_size)\n\t\t\tincrement_prob(b, q);\n\t\tif (minqlen > b->qlen)\n\t\t\tminqlen = b->qlen;\n\t\tif (p_min > b->p_mark)\n\t\t\tp_min = b->p_mark;\n\t}\n\n\tslot ^= 1;\n\tsfb_skb_cb(skb)->hashes[slot] = 0;\n\n\tif (unlikely(minqlen >= q->max)) {\n\t\tqdisc_qstats_overlimit(sch);\n\t\tq->stats.bucketdrop++;\n\t\tgoto drop;\n\t}\n\n\tif (unlikely(p_min >= SFB_MAX_PROB)) {\n\t\t/* Inelastic flow */\n\t\tif (q->double_buffering) {\n\t\t\tsfbhash = skb_get_hash_perturb(skb,\n\t\t\t    q->bins[slot].perturbation);\n\t\t\tif (!sfbhash)\n\t\t\t\tsfbhash = 1;\n\t\t\tsfb_skb_cb(skb)->hashes[slot] = sfbhash;\n\n\t\t\tfor (i = 0; i < SFB_LEVELS; i++) {\n\t\t\t\tu32 hash = sfbhash & SFB_BUCKET_MASK;\n\t\t\t\tstruct sfb_bucket *b = &q->bins[slot].bins[i][hash];\n\n\t\t\t\tsfbhash >>= SFB_BUCKET_SHIFT;\n\t\t\t\tif (b->qlen == 0)\n\t\t\t\t\tdecrement_prob(b, q);\n\t\t\t\telse if (b->qlen >= q->bin_size)\n\t\t\t\t\tincrement_prob(b, q);\n\t\t\t}\n\t\t}\n\t\tif (sfb_rate_limit(skb, q)) {\n\t\t\tqdisc_qstats_overlimit(sch);\n\t\t\tq->stats.penaltydrop++;\n\t\t\tgoto drop;\n\t\t}\n\t\tgoto enqueue;\n\t}\n\n\tr = prandom_u32() & SFB_MAX_PROB;\n\n\tif (unlikely(r < p_min)) {\n\t\tif (unlikely(p_min > SFB_MAX_PROB / 2)) {\n\t\t\t/* If we're marking that many packets, then either\n\t\t\t * this flow is unresponsive, or we're badly congested.\n\t\t\t * In either case, we want to start dropping packets.\n\t\t\t */\n\t\t\tif (r < (p_min - SFB_MAX_PROB / 2) * 2) {\n\t\t\t\tq->stats.earlydrop++;\n\t\t\t\tgoto drop;\n\t\t\t}\n\t\t}\n\t\tif (INET_ECN_set_ce(skb)) {\n\t\t\tq->stats.marked++;\n\t\t} else {\n\t\t\tq->stats.earlydrop++;\n\t\t\tgoto drop;\n\t\t}\n\t}\n\nenqueue:\n\tret = qdisc_enqueue(skb, child, to_free);\n\tif (likely(ret == NET_XMIT_SUCCESS)) {\n\t\tqdisc_qstats_backlog_inc(sch, skb);\n\t\tsch->q.qlen++;\n\t\tincrement_qlen(skb, q);\n\t} else if (net_xmit_drop_count(ret)) {\n\t\tq->stats.childdrop++;\n\t\tqdisc_qstats_drop(sch);\n\t}\n\treturn ret;\n\ndrop:\n\tqdisc_drop(skb, sch, to_free);\n\treturn NET_XMIT_CN;\nother_drop:\n\tif (ret & __NET_XMIT_BYPASS)\n\t\tqdisc_qstats_drop(sch);\n\tkfree_skb(skb);\n\treturn ret;\n}",
        "func_after": "static int sfb_enqueue(struct sk_buff *skb, struct Qdisc *sch,\n\t\t       struct sk_buff **to_free)\n{\n\n\tstruct sfb_sched_data *q = qdisc_priv(sch);\n\tstruct Qdisc *child = q->qdisc;\n\tstruct tcf_proto *fl;\n\tint i;\n\tu32 p_min = ~0;\n\tu32 minqlen = ~0;\n\tu32 r, sfbhash;\n\tu32 slot = q->slot;\n\tint ret = NET_XMIT_SUCCESS | __NET_XMIT_BYPASS;\n\n\tif (unlikely(sch->q.qlen >= q->limit)) {\n\t\tqdisc_qstats_overlimit(sch);\n\t\tq->stats.queuedrop++;\n\t\tgoto drop;\n\t}\n\n\tif (q->rehash_interval > 0) {\n\t\tunsigned long limit = q->rehash_time + q->rehash_interval;\n\n\t\tif (unlikely(time_after(jiffies, limit))) {\n\t\t\tsfb_swap_slot(q);\n\t\t\tq->rehash_time = jiffies;\n\t\t} else if (unlikely(!q->double_buffering && q->warmup_time > 0 &&\n\t\t\t\t    time_after(jiffies, limit - q->warmup_time))) {\n\t\t\tq->double_buffering = true;\n\t\t}\n\t}\n\n\tfl = rcu_dereference_bh(q->filter_list);\n\tif (fl) {\n\t\tu32 salt;\n\n\t\t/* If using external classifiers, get result and record it. */\n\t\tif (!sfb_classify(skb, fl, &ret, &salt))\n\t\t\tgoto other_drop;\n\t\tsfbhash = siphash_1u32(salt, &q->bins[slot].perturbation);\n\t} else {\n\t\tsfbhash = skb_get_hash_perturb(skb, &q->bins[slot].perturbation);\n\t}\n\n\n\tif (!sfbhash)\n\t\tsfbhash = 1;\n\tsfb_skb_cb(skb)->hashes[slot] = sfbhash;\n\n\tfor (i = 0; i < SFB_LEVELS; i++) {\n\t\tu32 hash = sfbhash & SFB_BUCKET_MASK;\n\t\tstruct sfb_bucket *b = &q->bins[slot].bins[i][hash];\n\n\t\tsfbhash >>= SFB_BUCKET_SHIFT;\n\t\tif (b->qlen == 0)\n\t\t\tdecrement_prob(b, q);\n\t\telse if (b->qlen >= q->bin_size)\n\t\t\tincrement_prob(b, q);\n\t\tif (minqlen > b->qlen)\n\t\t\tminqlen = b->qlen;\n\t\tif (p_min > b->p_mark)\n\t\t\tp_min = b->p_mark;\n\t}\n\n\tslot ^= 1;\n\tsfb_skb_cb(skb)->hashes[slot] = 0;\n\n\tif (unlikely(minqlen >= q->max)) {\n\t\tqdisc_qstats_overlimit(sch);\n\t\tq->stats.bucketdrop++;\n\t\tgoto drop;\n\t}\n\n\tif (unlikely(p_min >= SFB_MAX_PROB)) {\n\t\t/* Inelastic flow */\n\t\tif (q->double_buffering) {\n\t\t\tsfbhash = skb_get_hash_perturb(skb,\n\t\t\t    &q->bins[slot].perturbation);\n\t\t\tif (!sfbhash)\n\t\t\t\tsfbhash = 1;\n\t\t\tsfb_skb_cb(skb)->hashes[slot] = sfbhash;\n\n\t\t\tfor (i = 0; i < SFB_LEVELS; i++) {\n\t\t\t\tu32 hash = sfbhash & SFB_BUCKET_MASK;\n\t\t\t\tstruct sfb_bucket *b = &q->bins[slot].bins[i][hash];\n\n\t\t\t\tsfbhash >>= SFB_BUCKET_SHIFT;\n\t\t\t\tif (b->qlen == 0)\n\t\t\t\t\tdecrement_prob(b, q);\n\t\t\t\telse if (b->qlen >= q->bin_size)\n\t\t\t\t\tincrement_prob(b, q);\n\t\t\t}\n\t\t}\n\t\tif (sfb_rate_limit(skb, q)) {\n\t\t\tqdisc_qstats_overlimit(sch);\n\t\t\tq->stats.penaltydrop++;\n\t\t\tgoto drop;\n\t\t}\n\t\tgoto enqueue;\n\t}\n\n\tr = prandom_u32() & SFB_MAX_PROB;\n\n\tif (unlikely(r < p_min)) {\n\t\tif (unlikely(p_min > SFB_MAX_PROB / 2)) {\n\t\t\t/* If we're marking that many packets, then either\n\t\t\t * this flow is unresponsive, or we're badly congested.\n\t\t\t * In either case, we want to start dropping packets.\n\t\t\t */\n\t\t\tif (r < (p_min - SFB_MAX_PROB / 2) * 2) {\n\t\t\t\tq->stats.earlydrop++;\n\t\t\t\tgoto drop;\n\t\t\t}\n\t\t}\n\t\tif (INET_ECN_set_ce(skb)) {\n\t\t\tq->stats.marked++;\n\t\t} else {\n\t\t\tq->stats.earlydrop++;\n\t\t\tgoto drop;\n\t\t}\n\t}\n\nenqueue:\n\tret = qdisc_enqueue(skb, child, to_free);\n\tif (likely(ret == NET_XMIT_SUCCESS)) {\n\t\tqdisc_qstats_backlog_inc(sch, skb);\n\t\tsch->q.qlen++;\n\t\tincrement_qlen(skb, q);\n\t} else if (net_xmit_drop_count(ret)) {\n\t\tq->stats.childdrop++;\n\t\tqdisc_qstats_drop(sch);\n\t}\n\treturn ret;\n\ndrop:\n\tqdisc_drop(skb, sch, to_free);\n\treturn NET_XMIT_CN;\nother_drop:\n\tif (ret & __NET_XMIT_BYPASS)\n\t\tqdisc_qstats_drop(sch);\n\tkfree_skb(skb);\n\treturn ret;\n}",
        "description": "The flow_dissector feature in the Linux kernel from version 4.3 up to but not including 5.3.10 suffers from a device tracking vulnerability, identified as CID-55667441c84f. This vulnerability arises due to the reliance on a 32-bit hashrnd value as a secret for the auto flowlabel of a UDP IPv6 packet. Additionally, the use of jhash instead of siphash exacerbates the issue. Since the hashrnd value remains constant from the time of system boot, it can be deduced by an attacker, thereby compromising the intended security measures. This problem is present in the net/core/flow_dissector.c file and related components.",
        "commit": "The vulnerability involves the use of a 32-bit secret in generating auto flowlabels for UDP IPv6 packets, which can be inferred by attackers to identify devices or users. The secret is initialized only at boot time and is used in conjunction with the jhash function to create flow labels that are predictable. This predictability poses a significant privacy risk. The proposed solution is to switch from using jhash to a cryptographically strong pseudo-random function like siphash, similar to changes made in the IP ID generator. This switch aims to enhance security by making the flow label generation process less predictable and thereby reducing the risk of device/user identification."
    },
    {
        "cwe": "CWE-347",
        "func_name": "rpm-software-management/pgpPrtParams",
        "score": 0.7165977358818054,
        "func_before": "int pgpPrtParams(const uint8_t * pkts, size_t pktlen, unsigned int pkttype,\n\t\t pgpDigParams * ret)\n{\n    const uint8_t *p = pkts;\n    const uint8_t *pend = pkts + pktlen;\n    pgpDigParams digp = NULL;\n    struct pgpPkt pkt;\n    int rc = -1; /* assume failure */\n\n    while (p < pend) {\n\tif (decodePkt(p, (pend - p), &pkt))\n\t    break;\n\n\tif (digp == NULL) {\n\t    if (pkttype && pkt.tag != pkttype) {\n\t\tbreak;\n\t    } else {\n\t\tdigp = pgpDigParamsNew(pkt.tag);\n\t    }\n\t}\n\n\tif (pgpPrtPkt(&pkt, digp))\n\t    break;\n\n\tp += (pkt.body - pkt.head) + pkt.blen;\n\tif (pkttype == PGPTAG_SIGNATURE)\n\t    break;\n    }\n\n    rc = (digp && (p == pend)) ? 0 : -1;\n\n    if (ret && rc == 0) {\n\t*ret = digp;\n    } else {\n\tpgpDigParamsFree(digp);\n    }\n    return rc;\n}",
        "func_after": "int pgpPrtParams(const uint8_t * pkts, size_t pktlen, unsigned int pkttype,\n\t\t pgpDigParams * ret)\n{\n    const uint8_t *p = pkts;\n    const uint8_t *pend = pkts + pktlen;\n    pgpDigParams digp = NULL;\n    pgpDigParams selfsig = NULL;\n    int i = 0;\n    int alloced = 16; /* plenty for normal cases */\n    struct pgpPkt *all = xmalloc(alloced * sizeof(*all));\n    int rc = -1; /* assume failure */\n    int expect = 0;\n    int prevtag = 0;\n\n    while (p < pend) {\n\tstruct pgpPkt *pkt = &all[i];\n\tif (decodePkt(p, (pend - p), pkt))\n\t    break;\n\n\tif (digp == NULL) {\n\t    if (pkttype && pkt->tag != pkttype) {\n\t\tbreak;\n\t    } else {\n\t\tdigp = pgpDigParamsNew(pkt->tag);\n\t    }\n\t}\n\n\tif (expect) {\n\t    if (pkt->tag != expect)\n\t\tbreak;\n\t    selfsig = pgpDigParamsNew(pkt->tag);\n\t}\n\n\tif (pgpPrtPkt(pkt, selfsig ? selfsig : digp))\n\t    break;\n\n\tif (selfsig) {\n\t    /* subkeys must be followed by binding signature */\n\t    if (prevtag == PGPTAG_PUBLIC_SUBKEY) {\n\t\tif (selfsig->sigtype != PGPSIGTYPE_SUBKEY_BINDING)\n\t\t    break;\n\t    }\n\n\t    int xx = pgpVerifySelf(digp, selfsig, all, i);\n\n\t    selfsig = pgpDigParamsFree(selfsig);\n\t    if (xx)\n\t\tbreak;\n\t    expect = 0;\n\t}\n\n\tif (pkt->tag == PGPTAG_PUBLIC_SUBKEY)\n\t    expect = PGPTAG_SIGNATURE;\n\tprevtag = pkt->tag;\n\n\ti++;\n\tp += (pkt->body - pkt->head) + pkt->blen;\n\tif (pkttype == PGPTAG_SIGNATURE)\n\t    break;\n\n\tif (alloced <= i) {\n\t    alloced *= 2;\n\t    all = xrealloc(all, alloced * sizeof(*all));\n\t}\n    }\n\n    rc = (digp && (p == pend) && expect == 0) ? 0 : -1;\n\n    free(all);\n    if (ret && rc == 0) {\n\t*ret = digp;\n    } else {\n\tpgpDigParamsFree(digp);\n    }\n    return rc;\n}",
        "description": "There is a flaw in RPM's signature functionality where it does not verify the binding signature of subkeys before importing them. This can allow an attacker to add or trick another party into adding a malicious subkey to a legitimate public key, potentially causing RPM to trust a malicious signature. The primary impact of this flaw is on data integrity. Exploitation requires compromising an RPM repository or convincing an administrator to install an untrusted RPM or public key. It is recommended to only use RPMs and public keys from trusted sources.",
        "commit": "To enhance the applicability of the given vulnerability knowledge across different scenarios, we can abstract and generalize it as follows:\n\n**Abstracted and Generalized Description:**\n\n\"A vulnerability was identified in the parsing mechanism of PGP public keys, where the implementation lacked enforcement of subkey binding signatures as mandated by the OpenPGP RFC. To address this, a workaround was introduced to ensure that all subkeys are validated by a binding signature from the primary key. This solution involves storing raw packets internally during decoding to facilitate access to previous elements for validating ordering and data integrity. Additionally, test cases were added to handle manipulated keys that previously could be imported successfully. This fix aims to improve the robustness of the parser without altering the API to maximize compatibility with older versions.\""
    }
]