[
    {
        "cwe": "CWE-613",
        "func_name": "arangodb/RestAuthHandler::execute",
        "score": 0.740469753742218,
        "func_before": "RestStatus RestAuthHandler__execute() {\n  auto const type = _request->requestType();\n  if (type != rest::RequestType::POST) {\n    generateError(rest::ResponseCode::METHOD_NOT_ALLOWED, TRI_ERROR_HTTP_METHOD_NOT_ALLOWED);\n    return RestStatus::DONE;\n  }\n\n  bool parseSuccess = false;\n  VPackSlice slice = this->parseVPackBody(parseSuccess);\n  if (!parseSuccess) { // error already set\n    return RestStatus::DONE;\n  }\n\n  if (!slice.isObject()) {\n    return badRequest();\n  }\n\n  VPackSlice usernameSlice = slice.get(\"username\");\n  VPackSlice passwordSlice = slice.get(\"password\");\n\n  if (!usernameSlice.isString() || !passwordSlice.isString()) {\n    return badRequest();\n  }\n\n  _username = usernameSlice.copyString();\n  std::string const password = passwordSlice.copyString();\n\n  auth::UserManager* um = AuthenticationFeature::instance()->userManager();\n  if (um == nullptr) {\n    std::string msg = \"This server does not support users\";\n    LOG_TOPIC(\"2e7d4\", ERR, Logger::AUTHENTICATION) << msg;\n    generateError(rest::ResponseCode::UNAUTHORIZED, TRI_ERROR_HTTP_UNAUTHORIZED, msg);\n  } else if (um->checkPassword(_username, password)) {\n    VPackBuilder resultBuilder;\n    {\n      VPackObjectBuilder b(&resultBuilder);\n      std::string jwt = generateJwt(_username, password);\n      resultBuilder.add(\"jwt\", VPackValue(jwt));\n    }\n\n    _isValid = true;\n    generateDocument(resultBuilder.slice(), true, &VPackOptions::Defaults);\n  } else {\n    // mop: rfc 2616 10.4.2 (if credentials wrong 401)\n    generateError(rest::ResponseCode::UNAUTHORIZED, TRI_ERROR_HTTP_UNAUTHORIZED,\n                  \"Wrong credentials\");\n  }\n  return RestStatus::DONE;\n}",
        "func_after": "RestStatus RestAuthHandler__execute() {\n  auto const type = _request->requestType();\n  if (type != rest::RequestType::POST) {\n    generateError(rest::ResponseCode::METHOD_NOT_ALLOWED, TRI_ERROR_HTTP_METHOD_NOT_ALLOWED);\n    return RestStatus::DONE;\n  }\n\n  bool parseSuccess = false;\n  VPackSlice slice = this->parseVPackBody(parseSuccess);\n  if (!parseSuccess) { // error already set\n    return RestStatus::DONE;\n  }\n\n  if (!slice.isObject()) {\n    return badRequest();\n  }\n\n  VPackSlice usernameSlice = slice.get(\"username\");\n  VPackSlice passwordSlice = slice.get(\"password\");\n\n  if (!usernameSlice.isString() || !passwordSlice.isString()) {\n    return badRequest();\n  }\n\n  std::string const username = usernameSlice.copyString();\n  std::string const password = passwordSlice.copyString();\n\n  bool isValid = false;\n\n  auto guard = scopeGuard([&]() {\n    try {\n      if (isValid) {\n        events::LoggedIn(*_request, username);\n      } else {\n        events::CredentialsBad(*_request, username);\n      }\n    } catch (...) {\n      // nothing we can do\n    }\n  });\n  \n  auth::UserManager* um = AuthenticationFeature::instance()->userManager();\n  if (um == nullptr) {\n    std::string msg = \"This server does not support users\";\n    LOG_TOPIC(\"2e7d4\", ERR, Logger::AUTHENTICATION) << msg;\n    generateError(rest::ResponseCode::UNAUTHORIZED, TRI_ERROR_HTTP_UNAUTHORIZED, msg);\n  } else if (um->checkPassword(username, password)) {\n    VPackBuilder resultBuilder;\n    {\n      VPackObjectBuilder b(&resultBuilder);\n      resultBuilder.add(\"jwt\", VPackValue(generateJwt(username)));\n    }\n\n    isValid = true;\n    generateDocument(resultBuilder.slice(), true, &VPackOptions::Defaults);\n  } else {\n    // mop: rfc 2616 10.4.2 (if credentials wrong 401)\n    generateError(rest::ResponseCode::UNAUTHORIZED, TRI_ERROR_HTTP_UNAUTHORIZED,\n                  \"Wrong credentials\");\n  }\n  return RestStatus::DONE;\n}",
        "description": "ArangoDB versions v3.7.6 through v3.8.3 are susceptible to an Insufficient Session Expiration issue. Specifically, when an administrator changes a user's password, the associated session is not invalidated. This failure allows a malicious user who is still logged in to continue performing arbitrary actions within the system.",
        "commit": "The startup parameter `--server.session-timeout` has been revived."
    },
    {
        "cwe": "CWE-1284",
        "func_name": "Samsung/crypto_bignum_allocate",
        "score": 0.7582710385322571,
        "func_before": "struct bignum *crypto_bignum_allocate(size_t size_bits)\n{\n\tsize_t sz = mpa_StaticVarSizeInU32(size_bits) *\tsizeof(uint32_t);\n\tstruct mpa_numbase_struct *bn = calloc(1, sz);\n\n\tif (!bn)\n\t\treturn NULL;\n\tbn->alloc = sz - MPA_NUMBASE_METADATA_SIZE_IN_U32 * sizeof(uint32_t);\n\treturn (struct bignum *)bn;\n}",
        "func_after": "struct bignum *crypto_bignum_allocate(size_t size_bits)\n{\n\tsize_t sz = mpa_StaticVarSizeInU32(size_bits) *\tsizeof(uint32_t);\n\t// struct mpa_numbase_struct *bn = calloc(1, sz);\n\tstruct mpa_numbase_struct *bn= TEE_Malloc(sz, TEE_MALLOC_FILL_ZERO);\n\tif (!bn)\n\t\treturn NULL;\n\tbn->alloc = sz - MPA_NUMBASE_METADATA_SIZE_IN_U32 * sizeof(uint32_t);\n\treturn (struct bignum *)bn;\n}",
        "description": "The function `tee_obj_free` in Samsung mTower through version 0.3.0 enables a trusted application to cause a Denial of Service (DoS) by calling the function `TEE_AllocateOperation` with a disrupted heap layout, which is associated with `utee_cryp_obj_alloc`.",
        "commit": "A vulnerability has been addressed in a software system, specifically identified by CVE-2022-40761."
    },
    {
        "cwe": "CWE-770",
        "func_name": "binutils-gdb/_bfd_elf_slurp_version_tables",
        "score": 0.7706273794174194,
        "func_before": "bfd_boolean\n_bfd_elf_slurp_version_tables (bfd *abfd, bfd_boolean default_imported_symver)\n{\n  bfd_byte *contents = NULL;\n  unsigned int freeidx = 0;\n\n  if (elf_dynverref (abfd) != 0)\n    {\n      Elf_Internal_Shdr *hdr;\n      Elf_External_Verneed *everneed;\n      Elf_Internal_Verneed *iverneed;\n      unsigned int i;\n      bfd_byte *contents_end;\n\n      hdr = &elf_tdata (abfd)->dynverref_hdr;\n\n      if (hdr->sh_info == 0 || hdr->sh_size < sizeof (Elf_External_Verneed))\n\t{\nerror_return_bad_verref:\n\t  _bfd_error_handler\n\t    (_(\"%B: .gnu.version_r invalid entry\"), abfd);\n\t  bfd_set_error (bfd_error_bad_value);\nerror_return_verref:\n\t  elf_tdata (abfd)->verref = NULL;\n\t  elf_tdata (abfd)->cverrefs = 0;\n\t  goto error_return;\n\t}\n\n      contents = (bfd_byte *) bfd_malloc (hdr->sh_size);\n      if (contents == NULL)\n\tgoto error_return_verref;\n\n      if (bfd_seek (abfd, hdr->sh_offset, SEEK_SET) != 0\n\t  || bfd_bread (contents, hdr->sh_size, abfd) != hdr->sh_size)\n\tgoto error_return_verref;\n\n      elf_tdata (abfd)->verref = (Elf_Internal_Verneed *)\n\tbfd_zalloc2 (abfd, hdr->sh_info, sizeof (Elf_Internal_Verneed));\n\n      if (elf_tdata (abfd)->verref == NULL)\n\tgoto error_return_verref;\n\n      BFD_ASSERT (sizeof (Elf_External_Verneed)\n\t\t  == sizeof (Elf_External_Vernaux));\n      contents_end = contents + hdr->sh_size - sizeof (Elf_External_Verneed);\n      everneed = (Elf_External_Verneed *) contents;\n      iverneed = elf_tdata (abfd)->verref;\n      for (i = 0; i < hdr->sh_info; i++, iverneed++)\n\t{\n\t  Elf_External_Vernaux *evernaux;\n\t  Elf_Internal_Vernaux *ivernaux;\n\t  unsigned int j;\n\n\t  _bfd_elf_swap_verneed_in (abfd, everneed, iverneed);\n\n\t  iverneed->vn_bfd = abfd;\n\n\t  iverneed->vn_filename =\n\t    bfd_elf_string_from_elf_section (abfd, hdr->sh_link,\n\t\t\t\t\t     iverneed->vn_file);\n\t  if (iverneed->vn_filename == NULL)\n\t    goto error_return_bad_verref;\n\n\t  if (iverneed->vn_cnt == 0)\n\t    iverneed->vn_auxptr = NULL;\n\t  else\n\t    {\n\t      iverneed->vn_auxptr = (struct elf_internal_vernaux *)\n                  bfd_alloc2 (abfd, iverneed->vn_cnt,\n                              sizeof (Elf_Internal_Vernaux));\n\t      if (iverneed->vn_auxptr == NULL)\n\t\tgoto error_return_verref;\n\t    }\n\n\t  if (iverneed->vn_aux\n\t      > (size_t) (contents_end - (bfd_byte *) everneed))\n\t    goto error_return_bad_verref;\n\n\t  evernaux = ((Elf_External_Vernaux *)\n\t\t      ((bfd_byte *) everneed + iverneed->vn_aux));\n\t  ivernaux = iverneed->vn_auxptr;\n\t  for (j = 0; j < iverneed->vn_cnt; j++, ivernaux++)\n\t    {\n\t      _bfd_elf_swap_vernaux_in (abfd, evernaux, ivernaux);\n\n\t      ivernaux->vna_nodename =\n\t\tbfd_elf_string_from_elf_section (abfd, hdr->sh_link,\n\t\t\t\t\t\t ivernaux->vna_name);\n\t      if (ivernaux->vna_nodename == NULL)\n\t\tgoto error_return_bad_verref;\n\n\t      if (ivernaux->vna_other > freeidx)\n\t\tfreeidx = ivernaux->vna_other;\n\n\t      ivernaux->vna_nextptr = NULL;\n\t      if (ivernaux->vna_next == 0)\n\t\t{\n\t\t  iverneed->vn_cnt = j + 1;\n\t\t  break;\n\t\t}\n\t      if (j + 1 < iverneed->vn_cnt)\n\t\tivernaux->vna_nextptr = ivernaux + 1;\n\n\t      if (ivernaux->vna_next\n\t\t  > (size_t) (contents_end - (bfd_byte *) evernaux))\n\t\tgoto error_return_bad_verref;\n\n\t      evernaux = ((Elf_External_Vernaux *)\n\t\t\t  ((bfd_byte *) evernaux + ivernaux->vna_next));\n\t    }\n\n\t  iverneed->vn_nextref = NULL;\n\t  if (iverneed->vn_next == 0)\n\t    break;\n\t  if (i + 1 < hdr->sh_info)\n\t    iverneed->vn_nextref = iverneed + 1;\n\n\t  if (iverneed->vn_next\n\t      > (size_t) (contents_end - (bfd_byte *) everneed))\n\t    goto error_return_bad_verref;\n\n\t  everneed = ((Elf_External_Verneed *)\n\t\t      ((bfd_byte *) everneed + iverneed->vn_next));\n\t}\n      elf_tdata (abfd)->cverrefs = i;\n\n      free (contents);\n      contents = NULL;\n    }\n\n  if (elf_dynverdef (abfd) != 0)\n    {\n      Elf_Internal_Shdr *hdr;\n      Elf_External_Verdef *everdef;\n      Elf_Internal_Verdef *iverdef;\n      Elf_Internal_Verdef *iverdefarr;\n      Elf_Internal_Verdef iverdefmem;\n      unsigned int i;\n      unsigned int maxidx;\n      bfd_byte *contents_end_def, *contents_end_aux;\n\n      hdr = &elf_tdata (abfd)->dynverdef_hdr;\n\n      if (hdr->sh_info == 0 || hdr->sh_size < sizeof (Elf_External_Verdef))\n\t{\n\terror_return_bad_verdef:\n\t  _bfd_error_handler\n\t    (_(\"%B: .gnu.version_d invalid entry\"), abfd);\n\t  bfd_set_error (bfd_error_bad_value);\n\terror_return_verdef:\n\t  elf_tdata (abfd)->verdef = NULL;\n\t  elf_tdata (abfd)->cverdefs = 0;\n\t  goto error_return;\n\t}\n\n      contents = (bfd_byte *) bfd_malloc (hdr->sh_size);\n      if (contents == NULL)\n\tgoto error_return_verdef;\n      if (bfd_seek (abfd, hdr->sh_offset, SEEK_SET) != 0\n\t  || bfd_bread (contents, hdr->sh_size, abfd) != hdr->sh_size)\n\tgoto error_return_verdef;\n\n      BFD_ASSERT (sizeof (Elf_External_Verdef)\n\t\t  >= sizeof (Elf_External_Verdaux));\n      contents_end_def = contents + hdr->sh_size\n\t\t\t - sizeof (Elf_External_Verdef);\n      contents_end_aux = contents + hdr->sh_size\n\t\t\t - sizeof (Elf_External_Verdaux);\n\n      /* We know the number of entries in the section but not the maximum\n\t index.  Therefore we have to run through all entries and find\n\t the maximum.  */\n      everdef = (Elf_External_Verdef *) contents;\n      maxidx = 0;\n      for (i = 0; i < hdr->sh_info; ++i)\n\t{\n\t  _bfd_elf_swap_verdef_in (abfd, everdef, &iverdefmem);\n\n\t  if ((iverdefmem.vd_ndx & ((unsigned) VERSYM_VERSION)) == 0)\n\t    goto error_return_bad_verdef;\n\t  if ((iverdefmem.vd_ndx & ((unsigned) VERSYM_VERSION)) > maxidx)\n\t    maxidx = iverdefmem.vd_ndx & ((unsigned) VERSYM_VERSION);\n\n\t  if (iverdefmem.vd_next == 0)\n\t    break;\n\n\t  if (iverdefmem.vd_next\n\t      > (size_t) (contents_end_def - (bfd_byte *) everdef))\n\t    goto error_return_bad_verdef;\n\n\t  everdef = ((Elf_External_Verdef *)\n\t\t     ((bfd_byte *) everdef + iverdefmem.vd_next));\n\t}\n\n      if (default_imported_symver)\n\t{\n\t  if (freeidx > maxidx)\n\t    maxidx = ++freeidx;\n\t  else\n\t    freeidx = ++maxidx;\n\t}\n\n      elf_tdata (abfd)->verdef = (Elf_Internal_Verdef *)\n\tbfd_zalloc2 (abfd, maxidx, sizeof (Elf_Internal_Verdef));\n      if (elf_tdata (abfd)->verdef == NULL)\n\tgoto error_return_verdef;\n\n      elf_tdata (abfd)->cverdefs = maxidx;\n\n      everdef = (Elf_External_Verdef *) contents;\n      iverdefarr = elf_tdata (abfd)->verdef;\n      for (i = 0; i < hdr->sh_info; i++)\n\t{\n\t  Elf_External_Verdaux *everdaux;\n\t  Elf_Internal_Verdaux *iverdaux;\n\t  unsigned int j;\n\n\t  _bfd_elf_swap_verdef_in (abfd, everdef, &iverdefmem);\n\n\t  if ((iverdefmem.vd_ndx & VERSYM_VERSION) == 0)\n\t    goto error_return_bad_verdef;\n\n\t  iverdef = &iverdefarr[(iverdefmem.vd_ndx & VERSYM_VERSION) - 1];\n\t  memcpy (iverdef, &iverdefmem, offsetof (Elf_Internal_Verdef, vd_bfd));\n\n\t  iverdef->vd_bfd = abfd;\n\n\t  if (iverdef->vd_cnt == 0)\n\t    iverdef->vd_auxptr = NULL;\n\t  else\n\t    {\n\t      iverdef->vd_auxptr = (struct elf_internal_verdaux *)\n                  bfd_alloc2 (abfd, iverdef->vd_cnt,\n                              sizeof (Elf_Internal_Verdaux));\n\t      if (iverdef->vd_auxptr == NULL)\n\t\tgoto error_return_verdef;\n\t    }\n\n\t  if (iverdef->vd_aux\n\t      > (size_t) (contents_end_aux - (bfd_byte *) everdef))\n\t    goto error_return_bad_verdef;\n\n\t  everdaux = ((Elf_External_Verdaux *)\n\t\t      ((bfd_byte *) everdef + iverdef->vd_aux));\n\t  iverdaux = iverdef->vd_auxptr;\n\t  for (j = 0; j < iverdef->vd_cnt; j++, iverdaux++)\n\t    {\n\t      _bfd_elf_swap_verdaux_in (abfd, everdaux, iverdaux);\n\n\t      iverdaux->vda_nodename =\n\t\tbfd_elf_string_from_elf_section (abfd, hdr->sh_link,\n\t\t\t\t\t\t iverdaux->vda_name);\n\t      if (iverdaux->vda_nodename == NULL)\n\t\tgoto error_return_bad_verdef;\n\n\t      iverdaux->vda_nextptr = NULL;\n\t      if (iverdaux->vda_next == 0)\n\t\t{\n\t\t  iverdef->vd_cnt = j + 1;\n\t\t  break;\n\t\t}\n\t      if (j + 1 < iverdef->vd_cnt)\n\t\tiverdaux->vda_nextptr = iverdaux + 1;\n\n\t      if (iverdaux->vda_next\n\t\t  > (size_t) (contents_end_aux - (bfd_byte *) everdaux))\n\t\tgoto error_return_bad_verdef;\n\n\t      everdaux = ((Elf_External_Verdaux *)\n\t\t\t  ((bfd_byte *) everdaux + iverdaux->vda_next));\n\t    }\n\n\t  iverdef->vd_nodename = NULL;\n\t  if (iverdef->vd_cnt)\n\t    iverdef->vd_nodename = iverdef->vd_auxptr->vda_nodename;\n\n\t  iverdef->vd_nextdef = NULL;\n\t  if (iverdef->vd_next == 0)\n\t    break;\n\t  if ((size_t) (iverdef - iverdefarr) + 1 < maxidx)\n\t    iverdef->vd_nextdef = iverdef + 1;\n\n\t  everdef = ((Elf_External_Verdef *)\n\t\t     ((bfd_byte *) everdef + iverdef->vd_next));\n\t}\n\n      free (contents);\n      contents = NULL;\n    }\n  else if (default_imported_symver)\n    {\n      if (freeidx < 3)\n\tfreeidx = 3;\n      else\n\tfreeidx++;\n\n      elf_tdata (abfd)->verdef = (Elf_Internal_Verdef *)\n          bfd_zalloc2 (abfd, freeidx, sizeof (Elf_Internal_Verdef));\n      if (elf_tdata (abfd)->verdef == NULL)\n\tgoto error_return;\n\n      elf_tdata (abfd)->cverdefs = freeidx;\n    }\n\n  /* Create a default version based on the soname.  */\n  if (default_imported_symver)\n    {\n      Elf_Internal_Verdef *iverdef;\n      Elf_Internal_Verdaux *iverdaux;\n\n      iverdef = &elf_tdata (abfd)->verdef[freeidx - 1];\n\n      iverdef->vd_version = VER_DEF_CURRENT;\n      iverdef->vd_flags = 0;\n      iverdef->vd_ndx = freeidx;\n      iverdef->vd_cnt = 1;\n\n      iverdef->vd_bfd = abfd;\n\n      iverdef->vd_nodename = bfd_elf_get_dt_soname (abfd);\n      if (iverdef->vd_nodename == NULL)\n\tgoto error_return_verdef;\n      iverdef->vd_nextdef = NULL;\n      iverdef->vd_auxptr = ((struct elf_internal_verdaux *)\n\t\t\t    bfd_zalloc (abfd, sizeof (Elf_Internal_Verdaux)));\n      if (iverdef->vd_auxptr == NULL)\n\tgoto error_return_verdef;\n\n      iverdaux = iverdef->vd_auxptr;\n      iverdaux->vda_nodename = iverdef->vd_nodename;\n    }\n\n  return TRUE;\n\n error_return:\n  if (contents != NULL)\n    free (contents);\n  return FALSE;\n}",
        "func_after": "bfd_boolean\n_bfd_elf_slurp_version_tables (bfd *abfd, bfd_boolean default_imported_symver)\n{\n  bfd_byte *contents = NULL;\n  unsigned int freeidx = 0;\n\n  if (elf_dynverref (abfd) != 0)\n    {\n      Elf_Internal_Shdr *hdr;\n      Elf_External_Verneed *everneed;\n      Elf_Internal_Verneed *iverneed;\n      unsigned int i;\n      bfd_byte *contents_end;\n\n      hdr = &elf_tdata (abfd)->dynverref_hdr;\n\n      if (hdr->sh_info == 0\n\t  || hdr->sh_info > hdr->sh_size / sizeof (Elf_External_Verneed))\n\t{\nerror_return_bad_verref:\n\t  _bfd_error_handler\n\t    (_(\"%B: .gnu.version_r invalid entry\"), abfd);\n\t  bfd_set_error (bfd_error_bad_value);\nerror_return_verref:\n\t  elf_tdata (abfd)->verref = NULL;\n\t  elf_tdata (abfd)->cverrefs = 0;\n\t  goto error_return;\n\t}\n\n      contents = (bfd_byte *) bfd_malloc (hdr->sh_size);\n      if (contents == NULL)\n\tgoto error_return_verref;\n\n      if (bfd_seek (abfd, hdr->sh_offset, SEEK_SET) != 0\n\t  || bfd_bread (contents, hdr->sh_size, abfd) != hdr->sh_size)\n\tgoto error_return_verref;\n\n      elf_tdata (abfd)->verref = (Elf_Internal_Verneed *)\n\tbfd_alloc2 (abfd, hdr->sh_info, sizeof (Elf_Internal_Verneed));\n\n      if (elf_tdata (abfd)->verref == NULL)\n\tgoto error_return_verref;\n\n      BFD_ASSERT (sizeof (Elf_External_Verneed)\n\t\t  == sizeof (Elf_External_Vernaux));\n      contents_end = contents + hdr->sh_size - sizeof (Elf_External_Verneed);\n      everneed = (Elf_External_Verneed *) contents;\n      iverneed = elf_tdata (abfd)->verref;\n      for (i = 0; i < hdr->sh_info; i++, iverneed++)\n\t{\n\t  Elf_External_Vernaux *evernaux;\n\t  Elf_Internal_Vernaux *ivernaux;\n\t  unsigned int j;\n\n\t  _bfd_elf_swap_verneed_in (abfd, everneed, iverneed);\n\n\t  iverneed->vn_bfd = abfd;\n\n\t  iverneed->vn_filename =\n\t    bfd_elf_string_from_elf_section (abfd, hdr->sh_link,\n\t\t\t\t\t     iverneed->vn_file);\n\t  if (iverneed->vn_filename == NULL)\n\t    goto error_return_bad_verref;\n\n\t  if (iverneed->vn_cnt == 0)\n\t    iverneed->vn_auxptr = NULL;\n\t  else\n\t    {\n\t      iverneed->vn_auxptr = (struct elf_internal_vernaux *)\n                  bfd_alloc2 (abfd, iverneed->vn_cnt,\n                              sizeof (Elf_Internal_Vernaux));\n\t      if (iverneed->vn_auxptr == NULL)\n\t\tgoto error_return_verref;\n\t    }\n\n\t  if (iverneed->vn_aux\n\t      > (size_t) (contents_end - (bfd_byte *) everneed))\n\t    goto error_return_bad_verref;\n\n\t  evernaux = ((Elf_External_Vernaux *)\n\t\t      ((bfd_byte *) everneed + iverneed->vn_aux));\n\t  ivernaux = iverneed->vn_auxptr;\n\t  for (j = 0; j < iverneed->vn_cnt; j++, ivernaux++)\n\t    {\n\t      _bfd_elf_swap_vernaux_in (abfd, evernaux, ivernaux);\n\n\t      ivernaux->vna_nodename =\n\t\tbfd_elf_string_from_elf_section (abfd, hdr->sh_link,\n\t\t\t\t\t\t ivernaux->vna_name);\n\t      if (ivernaux->vna_nodename == NULL)\n\t\tgoto error_return_bad_verref;\n\n\t      if (ivernaux->vna_other > freeidx)\n\t\tfreeidx = ivernaux->vna_other;\n\n\t      ivernaux->vna_nextptr = NULL;\n\t      if (ivernaux->vna_next == 0)\n\t\t{\n\t\t  iverneed->vn_cnt = j + 1;\n\t\t  break;\n\t\t}\n\t      if (j + 1 < iverneed->vn_cnt)\n\t\tivernaux->vna_nextptr = ivernaux + 1;\n\n\t      if (ivernaux->vna_next\n\t\t  > (size_t) (contents_end - (bfd_byte *) evernaux))\n\t\tgoto error_return_bad_verref;\n\n\t      evernaux = ((Elf_External_Vernaux *)\n\t\t\t  ((bfd_byte *) evernaux + ivernaux->vna_next));\n\t    }\n\n\t  iverneed->vn_nextref = NULL;\n\t  if (iverneed->vn_next == 0)\n\t    break;\n\t  if (i + 1 < hdr->sh_info)\n\t    iverneed->vn_nextref = iverneed + 1;\n\n\t  if (iverneed->vn_next\n\t      > (size_t) (contents_end - (bfd_byte *) everneed))\n\t    goto error_return_bad_verref;\n\n\t  everneed = ((Elf_External_Verneed *)\n\t\t      ((bfd_byte *) everneed + iverneed->vn_next));\n\t}\n      elf_tdata (abfd)->cverrefs = i;\n\n      free (contents);\n      contents = NULL;\n    }\n\n  if (elf_dynverdef (abfd) != 0)\n    {\n      Elf_Internal_Shdr *hdr;\n      Elf_External_Verdef *everdef;\n      Elf_Internal_Verdef *iverdef;\n      Elf_Internal_Verdef *iverdefarr;\n      Elf_Internal_Verdef iverdefmem;\n      unsigned int i;\n      unsigned int maxidx;\n      bfd_byte *contents_end_def, *contents_end_aux;\n\n      hdr = &elf_tdata (abfd)->dynverdef_hdr;\n\n      if (hdr->sh_info == 0 || hdr->sh_size < sizeof (Elf_External_Verdef))\n\t{\n\terror_return_bad_verdef:\n\t  _bfd_error_handler\n\t    (_(\"%B: .gnu.version_d invalid entry\"), abfd);\n\t  bfd_set_error (bfd_error_bad_value);\n\terror_return_verdef:\n\t  elf_tdata (abfd)->verdef = NULL;\n\t  elf_tdata (abfd)->cverdefs = 0;\n\t  goto error_return;\n\t}\n\n      contents = (bfd_byte *) bfd_malloc (hdr->sh_size);\n      if (contents == NULL)\n\tgoto error_return_verdef;\n      if (bfd_seek (abfd, hdr->sh_offset, SEEK_SET) != 0\n\t  || bfd_bread (contents, hdr->sh_size, abfd) != hdr->sh_size)\n\tgoto error_return_verdef;\n\n      BFD_ASSERT (sizeof (Elf_External_Verdef)\n\t\t  >= sizeof (Elf_External_Verdaux));\n      contents_end_def = contents + hdr->sh_size\n\t\t\t - sizeof (Elf_External_Verdef);\n      contents_end_aux = contents + hdr->sh_size\n\t\t\t - sizeof (Elf_External_Verdaux);\n\n      /* We know the number of entries in the section but not the maximum\n\t index.  Therefore we have to run through all entries and find\n\t the maximum.  */\n      everdef = (Elf_External_Verdef *) contents;\n      maxidx = 0;\n      for (i = 0; i < hdr->sh_info; ++i)\n\t{\n\t  _bfd_elf_swap_verdef_in (abfd, everdef, &iverdefmem);\n\n\t  if ((iverdefmem.vd_ndx & ((unsigned) VERSYM_VERSION)) == 0)\n\t    goto error_return_bad_verdef;\n\t  if ((iverdefmem.vd_ndx & ((unsigned) VERSYM_VERSION)) > maxidx)\n\t    maxidx = iverdefmem.vd_ndx & ((unsigned) VERSYM_VERSION);\n\n\t  if (iverdefmem.vd_next == 0)\n\t    break;\n\n\t  if (iverdefmem.vd_next\n\t      > (size_t) (contents_end_def - (bfd_byte *) everdef))\n\t    goto error_return_bad_verdef;\n\n\t  everdef = ((Elf_External_Verdef *)\n\t\t     ((bfd_byte *) everdef + iverdefmem.vd_next));\n\t}\n\n      if (default_imported_symver)\n\t{\n\t  if (freeidx > maxidx)\n\t    maxidx = ++freeidx;\n\t  else\n\t    freeidx = ++maxidx;\n\t}\n\n      elf_tdata (abfd)->verdef = (Elf_Internal_Verdef *)\n\tbfd_zalloc2 (abfd, maxidx, sizeof (Elf_Internal_Verdef));\n      if (elf_tdata (abfd)->verdef == NULL)\n\tgoto error_return_verdef;\n\n      elf_tdata (abfd)->cverdefs = maxidx;\n\n      everdef = (Elf_External_Verdef *) contents;\n      iverdefarr = elf_tdata (abfd)->verdef;\n      for (i = 0; i < hdr->sh_info; i++)\n\t{\n\t  Elf_External_Verdaux *everdaux;\n\t  Elf_Internal_Verdaux *iverdaux;\n\t  unsigned int j;\n\n\t  _bfd_elf_swap_verdef_in (abfd, everdef, &iverdefmem);\n\n\t  if ((iverdefmem.vd_ndx & VERSYM_VERSION) == 0)\n\t    goto error_return_bad_verdef;\n\n\t  iverdef = &iverdefarr[(iverdefmem.vd_ndx & VERSYM_VERSION) - 1];\n\t  memcpy (iverdef, &iverdefmem, offsetof (Elf_Internal_Verdef, vd_bfd));\n\n\t  iverdef->vd_bfd = abfd;\n\n\t  if (iverdef->vd_cnt == 0)\n\t    iverdef->vd_auxptr = NULL;\n\t  else\n\t    {\n\t      iverdef->vd_auxptr = (struct elf_internal_verdaux *)\n                  bfd_alloc2 (abfd, iverdef->vd_cnt,\n                              sizeof (Elf_Internal_Verdaux));\n\t      if (iverdef->vd_auxptr == NULL)\n\t\tgoto error_return_verdef;\n\t    }\n\n\t  if (iverdef->vd_aux\n\t      > (size_t) (contents_end_aux - (bfd_byte *) everdef))\n\t    goto error_return_bad_verdef;\n\n\t  everdaux = ((Elf_External_Verdaux *)\n\t\t      ((bfd_byte *) everdef + iverdef->vd_aux));\n\t  iverdaux = iverdef->vd_auxptr;\n\t  for (j = 0; j < iverdef->vd_cnt; j++, iverdaux++)\n\t    {\n\t      _bfd_elf_swap_verdaux_in (abfd, everdaux, iverdaux);\n\n\t      iverdaux->vda_nodename =\n\t\tbfd_elf_string_from_elf_section (abfd, hdr->sh_link,\n\t\t\t\t\t\t iverdaux->vda_name);\n\t      if (iverdaux->vda_nodename == NULL)\n\t\tgoto error_return_bad_verdef;\n\n\t      iverdaux->vda_nextptr = NULL;\n\t      if (iverdaux->vda_next == 0)\n\t\t{\n\t\t  iverdef->vd_cnt = j + 1;\n\t\t  break;\n\t\t}\n\t      if (j + 1 < iverdef->vd_cnt)\n\t\tiverdaux->vda_nextptr = iverdaux + 1;\n\n\t      if (iverdaux->vda_next\n\t\t  > (size_t) (contents_end_aux - (bfd_byte *) everdaux))\n\t\tgoto error_return_bad_verdef;\n\n\t      everdaux = ((Elf_External_Verdaux *)\n\t\t\t  ((bfd_byte *) everdaux + iverdaux->vda_next));\n\t    }\n\n\t  iverdef->vd_nodename = NULL;\n\t  if (iverdef->vd_cnt)\n\t    iverdef->vd_nodename = iverdef->vd_auxptr->vda_nodename;\n\n\t  iverdef->vd_nextdef = NULL;\n\t  if (iverdef->vd_next == 0)\n\t    break;\n\t  if ((size_t) (iverdef - iverdefarr) + 1 < maxidx)\n\t    iverdef->vd_nextdef = iverdef + 1;\n\n\t  everdef = ((Elf_External_Verdef *)\n\t\t     ((bfd_byte *) everdef + iverdef->vd_next));\n\t}\n\n      free (contents);\n      contents = NULL;\n    }\n  else if (default_imported_symver)\n    {\n      if (freeidx < 3)\n\tfreeidx = 3;\n      else\n\tfreeidx++;\n\n      elf_tdata (abfd)->verdef = (Elf_Internal_Verdef *)\n          bfd_zalloc2 (abfd, freeidx, sizeof (Elf_Internal_Verdef));\n      if (elf_tdata (abfd)->verdef == NULL)\n\tgoto error_return;\n\n      elf_tdata (abfd)->cverdefs = freeidx;\n    }\n\n  /* Create a default version based on the soname.  */\n  if (default_imported_symver)\n    {\n      Elf_Internal_Verdef *iverdef;\n      Elf_Internal_Verdaux *iverdaux;\n\n      iverdef = &elf_tdata (abfd)->verdef[freeidx - 1];\n\n      iverdef->vd_version = VER_DEF_CURRENT;\n      iverdef->vd_flags = 0;\n      iverdef->vd_ndx = freeidx;\n      iverdef->vd_cnt = 1;\n\n      iverdef->vd_bfd = abfd;\n\n      iverdef->vd_nodename = bfd_elf_get_dt_soname (abfd);\n      if (iverdef->vd_nodename == NULL)\n\tgoto error_return_verdef;\n      iverdef->vd_nextdef = NULL;\n      iverdef->vd_auxptr = ((struct elf_internal_verdaux *)\n\t\t\t    bfd_zalloc (abfd, sizeof (Elf_Internal_Verdaux)));\n      if (iverdef->vd_auxptr == NULL)\n\tgoto error_return_verdef;\n\n      iverdaux = iverdef->vd_auxptr;\n      iverdaux->vda_nodename = iverdef->vd_nodename;\n    }\n\n  return TRUE;\n\n error_return:\n  if (contents != NULL)\n    free (contents);\n  return FALSE;\n}",
        "description": "The _bfd_elf_slurp_version_tables function in the BFD library, part of GNU Binutils 2.29, is susceptible to a denial of service attack. This vulnerability arises from excessive memory allocation when processing a specially crafted ELF file, leading to potential application crashes.",
        "commit": "The vulnerability involves a memory allocation issue within the ELF (Executable and Linkable Format) handling module of a binary file format library. Specifically, the code performs a sanity check on the size of the `SHT_GNU_verneed` section, ensuring it meets certain minimum requirements related to the number of version entries (`sh_info`). Additionally, since the code either fully initializes all fields of the version entries or exits with an error, there is no need to zero-initialize the allocated memory for these entries. The fix includes modifying the `_bfd_elf_slurp_version_tables` function to test the `sh_info` field of the `SHT_GNU_verneed` section for validity and to avoid zero-initializing the memory allocated for version references."
    },
    {
        "cwe": "CWE-407",
        "func_name": "reddit/find_link_ref",
        "score": 0.7410665154457092,
        "func_before": "static struct link_ref *\nfind_link_ref(struct link_ref **references, uint8_t *name, size_t length)\n{\n\tunsigned int hash = hash_link_ref(name, length);\n\tstruct link_ref *ref = NULL;\n\n\tref = references[hash % REF_TABLE_SIZE];\n\n\twhile (ref != NULL) {\n\t\tif (ref->id == hash)\n\t\t\treturn ref;\n\n\t\tref = ref->next;\n\t}\n\n\treturn NULL;\n}",
        "func_after": "static struct link_ref *\nfind_link_ref(struct link_ref **references, uint8_t *name, size_t length)\n{\n\tunsigned int hash = hash_link_ref(name, length);\n\tstruct link_ref *ref = NULL;\n\n\tref = references[hash % REF_TABLE_SIZE];\n\n\twhile (ref != NULL) {\n\t\tif (ref->id == hash && ref->label->size == length) {\n\t\t\tif (strncasecmp((char *)ref->label->data, (char *) name, length) == 0) {\n\t\t\t\treturn ref;\n\t\t\t}\n\t\t}\n\n\t\tref = ref->next;\n\t}\n\n\treturn NULL;\n}",
        "description": "Snudown, a Reddit-specific fork of the Sundown Markdown parser with Python integration, was found to be vulnerable to denial of service (DoS) attacks due to weaknesses in its reference table implementation. Specifically, the hash function used for inserting references into a hash table was weak, allowing attackers to generate a large number of collisions. Additionally, the hash table permitted duplicate entries, leading to prolonged retrieval times. These issues collectively make the system susceptible to hash-collision DoS attacks, a form of algorithmic complexity attack. Users are advised to update to version 1.7.0 to mitigate these vulnerabilities.",
        "commit": "A vulnerability related to hash collisions has been identified and addressed by implementing a case-insensitive SipHash function to replace the existing reference hash function. Additionally, changes were made to the `link_ref` structure to include a label, and updates were applied to the `find_link_ref` and `add_link_ref` functions to ensure they compare link labels as well as hashes and disallow duplicate entries, respectively. A cast was added to convert from `uint8_t` to `char` for use with `strncasecmp`. The README markdown was updated to remove TODO items, and support for generating Python 2 wheels was added. Furthermore, logic was included to handle older versions of glibc that do not have the `getrandom` function, impacting the staging environment."
    },
    {
        "cwe": "CWE-119",
        "func_name": "torvalds/hugetlb_mcopy_atomic_pte",
        "score": 0.7803310751914978,
        "func_before": "int hugetlb_mcopy_atomic_pte(struct mm_struct *dst_mm,\n\t\t\t    pte_t *dst_pte,\n\t\t\t    struct vm_area_struct *dst_vma,\n\t\t\t    unsigned long dst_addr,\n\t\t\t    unsigned long src_addr,\n\t\t\t    struct page **pagep)\n{\n\tint vm_shared = dst_vma->vm_flags & VM_SHARED;\n\tstruct hstate *h = hstate_vma(dst_vma);\n\tpte_t _dst_pte;\n\tspinlock_t *ptl;\n\tint ret;\n\tstruct page *page;\n\n\tif (!*pagep) {\n\t\tret = -ENOMEM;\n\t\tpage = alloc_huge_page(dst_vma, dst_addr, 0);\n\t\tif (IS_ERR(page))\n\t\t\tgoto out;\n\n\t\tret = copy_huge_page_from_user(page,\n\t\t\t\t\t\t(const void __user *) src_addr,\n\t\t\t\t\t\tpages_per_huge_page(h), false);\n\n\t\t/* fallback to copy_from_user outside mmap_sem */\n\t\tif (unlikely(ret)) {\n\t\t\tret = -EFAULT;\n\t\t\t*pagep = page;\n\t\t\t/* don't free the page */\n\t\t\tgoto out;\n\t\t}\n\t} else {\n\t\tpage = *pagep;\n\t\t*pagep = NULL;\n\t}\n\n\t/*\n\t * The memory barrier inside __SetPageUptodate makes sure that\n\t * preceding stores to the page contents become visible before\n\t * the set_pte_at() write.\n\t */\n\t__SetPageUptodate(page);\n\tset_page_huge_active(page);\n\n\t/*\n\t * If shared, add to page cache\n\t */\n\tif (vm_shared) {\n\t\tstruct address_space *mapping = dst_vma->vm_file->f_mapping;\n\t\tpgoff_t idx = vma_hugecache_offset(h, dst_vma, dst_addr);\n\n\t\tret = huge_add_to_page_cache(page, mapping, idx);\n\t\tif (ret)\n\t\t\tgoto out_release_nounlock;\n\t}\n\n\tptl = huge_pte_lockptr(h, dst_mm, dst_pte);\n\tspin_lock(ptl);\n\n\tret = -EEXIST;\n\tif (!huge_pte_none(huge_ptep_get(dst_pte)))\n\t\tgoto out_release_unlock;\n\n\tif (vm_shared) {\n\t\tpage_dup_rmap(page, true);\n\t} else {\n\t\tClearPagePrivate(page);\n\t\thugepage_add_new_anon_rmap(page, dst_vma, dst_addr);\n\t}\n\n\t_dst_pte = make_huge_pte(dst_vma, page, dst_vma->vm_flags & VM_WRITE);\n\tif (dst_vma->vm_flags & VM_WRITE)\n\t\t_dst_pte = huge_pte_mkdirty(_dst_pte);\n\t_dst_pte = pte_mkyoung(_dst_pte);\n\n\tset_huge_pte_at(dst_mm, dst_addr, dst_pte, _dst_pte);\n\n\t(void)huge_ptep_set_access_flags(dst_vma, dst_addr, dst_pte, _dst_pte,\n\t\t\t\t\tdst_vma->vm_flags & VM_WRITE);\n\thugetlb_count_add(pages_per_huge_page(h), dst_mm);\n\n\t/* No need to invalidate - it was non-present before */\n\tupdate_mmu_cache(dst_vma, dst_addr, dst_pte);\n\n\tspin_unlock(ptl);\n\tif (vm_shared)\n\t\tunlock_page(page);\n\tret = 0;\nout:\n\treturn ret;\nout_release_unlock:\n\tspin_unlock(ptl);\n\tif (vm_shared)\n\t\tunlock_page(page);\nout_release_nounlock:\n\tput_page(page);\n\tgoto out;\n}",
        "func_after": "int hugetlb_mcopy_atomic_pte(struct mm_struct *dst_mm,\n\t\t\t    pte_t *dst_pte,\n\t\t\t    struct vm_area_struct *dst_vma,\n\t\t\t    unsigned long dst_addr,\n\t\t\t    unsigned long src_addr,\n\t\t\t    struct page **pagep)\n{\n\tstruct address_space *mapping;\n\tpgoff_t idx;\n\tunsigned long size;\n\tint vm_shared = dst_vma->vm_flags & VM_SHARED;\n\tstruct hstate *h = hstate_vma(dst_vma);\n\tpte_t _dst_pte;\n\tspinlock_t *ptl;\n\tint ret;\n\tstruct page *page;\n\n\tif (!*pagep) {\n\t\tret = -ENOMEM;\n\t\tpage = alloc_huge_page(dst_vma, dst_addr, 0);\n\t\tif (IS_ERR(page))\n\t\t\tgoto out;\n\n\t\tret = copy_huge_page_from_user(page,\n\t\t\t\t\t\t(const void __user *) src_addr,\n\t\t\t\t\t\tpages_per_huge_page(h), false);\n\n\t\t/* fallback to copy_from_user outside mmap_sem */\n\t\tif (unlikely(ret)) {\n\t\t\tret = -EFAULT;\n\t\t\t*pagep = page;\n\t\t\t/* don't free the page */\n\t\t\tgoto out;\n\t\t}\n\t} else {\n\t\tpage = *pagep;\n\t\t*pagep = NULL;\n\t}\n\n\t/*\n\t * The memory barrier inside __SetPageUptodate makes sure that\n\t * preceding stores to the page contents become visible before\n\t * the set_pte_at() write.\n\t */\n\t__SetPageUptodate(page);\n\tset_page_huge_active(page);\n\n\tmapping = dst_vma->vm_file->f_mapping;\n\tidx = vma_hugecache_offset(h, dst_vma, dst_addr);\n\n\t/*\n\t * If shared, add to page cache\n\t */\n\tif (vm_shared) {\n\t\tsize = i_size_read(mapping->host) >> huge_page_shift(h);\n\t\tret = -EFAULT;\n\t\tif (idx >= size)\n\t\t\tgoto out_release_nounlock;\n\n\t\t/*\n\t\t * Serialization between remove_inode_hugepages() and\n\t\t * huge_add_to_page_cache() below happens through the\n\t\t * hugetlb_fault_mutex_table that here must be hold by\n\t\t * the caller.\n\t\t */\n\t\tret = huge_add_to_page_cache(page, mapping, idx);\n\t\tif (ret)\n\t\t\tgoto out_release_nounlock;\n\t}\n\n\tptl = huge_pte_lockptr(h, dst_mm, dst_pte);\n\tspin_lock(ptl);\n\n\t/*\n\t * Recheck the i_size after holding PT lock to make sure not\n\t * to leave any page mapped (as page_mapped()) beyond the end\n\t * of the i_size (remove_inode_hugepages() is strict about\n\t * enforcing that). If we bail out here, we'll also leave a\n\t * page in the radix tree in the vm_shared case beyond the end\n\t * of the i_size, but remove_inode_hugepages() will take care\n\t * of it as soon as we drop the hugetlb_fault_mutex_table.\n\t */\n\tsize = i_size_read(mapping->host) >> huge_page_shift(h);\n\tret = -EFAULT;\n\tif (idx >= size)\n\t\tgoto out_release_unlock;\n\n\tret = -EEXIST;\n\tif (!huge_pte_none(huge_ptep_get(dst_pte)))\n\t\tgoto out_release_unlock;\n\n\tif (vm_shared) {\n\t\tpage_dup_rmap(page, true);\n\t} else {\n\t\tClearPagePrivate(page);\n\t\thugepage_add_new_anon_rmap(page, dst_vma, dst_addr);\n\t}\n\n\t_dst_pte = make_huge_pte(dst_vma, page, dst_vma->vm_flags & VM_WRITE);\n\tif (dst_vma->vm_flags & VM_WRITE)\n\t\t_dst_pte = huge_pte_mkdirty(_dst_pte);\n\t_dst_pte = pte_mkyoung(_dst_pte);\n\n\tset_huge_pte_at(dst_mm, dst_addr, dst_pte, _dst_pte);\n\n\t(void)huge_ptep_set_access_flags(dst_vma, dst_addr, dst_pte, _dst_pte,\n\t\t\t\t\tdst_vma->vm_flags & VM_WRITE);\n\thugetlb_count_add(pages_per_huge_page(h), dst_mm);\n\n\t/* No need to invalidate - it was non-present before */\n\tupdate_mmu_cache(dst_vma, dst_addr, dst_pte);\n\n\tspin_unlock(ptl);\n\tif (vm_shared)\n\t\tunlock_page(page);\n\tret = 0;\nout:\n\treturn ret;\nout_release_unlock:\n\tspin_unlock(ptl);\n\tif (vm_shared)\n\t\tunlock_page(page);\nout_release_nounlock:\n\tput_page(page);\n\tgoto out;\n}",
        "description": "A flaw was identified in the hugetlb_mcopy_atomic_pte function within the Linux kernel's memory management module, affecting versions prior to 4.13.12. The absence of a proper size check in this function could lead to a denial of service condition, indicated by a BUG.",
        "commit": "A vulnerability was identified in the userfaultfd functionality related to hugetlbfs, where the UFFDIO_COPY operation could inadvertently extend beyond the intended size of the file (i_size). This issue led to a kernel panic (oops) at fs/hugetlbfs/inode.c:484, triggered by the absence of an i_size check in the hugetlb_mcopy_atomic_pte function. Although mmap() operations could succeed beyond the end of the i_size after vmtruncate had removed virtual memory areas (vmas) in those ranges, subsequent faults, including UFFDIO_COPY, should not be allowed to succeed. The proposed solution involves modifying the return value to userland to indicate a SIGBUS-like condition, similar to what a page fault would produce, but this approach was deemed less useful due to the difficulty in distinguishing between SIGSEGV and SIGBUS through meaningful syscall return values."
    }
]