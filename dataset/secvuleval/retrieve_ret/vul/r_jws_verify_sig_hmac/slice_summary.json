[
    {
        "cwe": "CWE-613",
        "func_name": "arangodb/RestAuthHandler::execute",
        "score": 0.7343342304229736,
        "func_before": "RestStatus RestAuthHandler__execute() {\n  auto const type = _request->requestType();\n  if (type != rest::RequestType::POST) {\n    generateError(rest::ResponseCode::METHOD_NOT_ALLOWED, TRI_ERROR_HTTP_METHOD_NOT_ALLOWED);\n    return RestStatus::DONE;\n  }\n\n  bool parseSuccess = false;\n  VPackSlice slice = this->parseVPackBody(parseSuccess);\n  if (!parseSuccess) { // error already set\n    return RestStatus::DONE;\n  }\n\n  if (!slice.isObject()) {\n    return badRequest();\n  }\n\n  VPackSlice usernameSlice = slice.get(\"username\");\n  VPackSlice passwordSlice = slice.get(\"password\");\n\n  if (!usernameSlice.isString() || !passwordSlice.isString()) {\n    return badRequest();\n  }\n\n  _username = usernameSlice.copyString();\n  std::string const password = passwordSlice.copyString();\n\n  auth::UserManager* um = AuthenticationFeature::instance()->userManager();\n  if (um == nullptr) {\n    std::string msg = \"This server does not support users\";\n    LOG_TOPIC(\"2e7d4\", ERR, Logger::AUTHENTICATION) << msg;\n    generateError(rest::ResponseCode::UNAUTHORIZED, TRI_ERROR_HTTP_UNAUTHORIZED, msg);\n  } else if (um->checkPassword(_username, password)) {\n    VPackBuilder resultBuilder;\n    {\n      VPackObjectBuilder b(&resultBuilder);\n      std::string jwt = generateJwt(_username, password);\n      resultBuilder.add(\"jwt\", VPackValue(jwt));\n    }\n\n    _isValid = true;\n    generateDocument(resultBuilder.slice(), true, &VPackOptions::Defaults);\n  } else {\n    // mop: rfc 2616 10.4.2 (if credentials wrong 401)\n    generateError(rest::ResponseCode::UNAUTHORIZED, TRI_ERROR_HTTP_UNAUTHORIZED,\n                  \"Wrong credentials\");\n  }\n  return RestStatus::DONE;\n}",
        "func_after": "RestStatus RestAuthHandler__execute() {\n  auto const type = _request->requestType();\n  if (type != rest::RequestType::POST) {\n    generateError(rest::ResponseCode::METHOD_NOT_ALLOWED, TRI_ERROR_HTTP_METHOD_NOT_ALLOWED);\n    return RestStatus::DONE;\n  }\n\n  bool parseSuccess = false;\n  VPackSlice slice = this->parseVPackBody(parseSuccess);\n  if (!parseSuccess) { // error already set\n    return RestStatus::DONE;\n  }\n\n  if (!slice.isObject()) {\n    return badRequest();\n  }\n\n  VPackSlice usernameSlice = slice.get(\"username\");\n  VPackSlice passwordSlice = slice.get(\"password\");\n\n  if (!usernameSlice.isString() || !passwordSlice.isString()) {\n    return badRequest();\n  }\n\n  std::string const username = usernameSlice.copyString();\n  std::string const password = passwordSlice.copyString();\n\n  bool isValid = false;\n\n  auto guard = scopeGuard([&]() {\n    try {\n      if (isValid) {\n        events::LoggedIn(*_request, username);\n      } else {\n        events::CredentialsBad(*_request, username);\n      }\n    } catch (...) {\n      // nothing we can do\n    }\n  });\n  \n  auth::UserManager* um = AuthenticationFeature::instance()->userManager();\n  if (um == nullptr) {\n    std::string msg = \"This server does not support users\";\n    LOG_TOPIC(\"2e7d4\", ERR, Logger::AUTHENTICATION) << msg;\n    generateError(rest::ResponseCode::UNAUTHORIZED, TRI_ERROR_HTTP_UNAUTHORIZED, msg);\n  } else if (um->checkPassword(username, password)) {\n    VPackBuilder resultBuilder;\n    {\n      VPackObjectBuilder b(&resultBuilder);\n      resultBuilder.add(\"jwt\", VPackValue(generateJwt(username)));\n    }\n\n    isValid = true;\n    generateDocument(resultBuilder.slice(), true, &VPackOptions::Defaults);\n  } else {\n    // mop: rfc 2616 10.4.2 (if credentials wrong 401)\n    generateError(rest::ResponseCode::UNAUTHORIZED, TRI_ERROR_HTTP_UNAUTHORIZED,\n                  \"Wrong credentials\");\n  }\n  return RestStatus::DONE;\n}",
        "description": "ArangoDB versions v3.7.6 through v3.8.3 are susceptible to an Insufficient Session Expiration issue. Specifically, when an administrator changes a user's password, the associated session is not invalidated. This failure allows a malicious user who is still logged in to continue performing arbitrary actions within the system.",
        "commit": "The startup parameter `--server.session-timeout` has been revived."
    },
    {
        "cwe": "CWE-863",
        "func_name": "torvalds/internal_get_user_pages_fast",
        "score": 0.7686684727668762,
        "func_before": "static int internal_get_user_pages_fast(unsigned long start, int nr_pages,\n\t\t\t\t\tunsigned int gup_flags,\n\t\t\t\t\tstruct page **pages)\n{\n\tunsigned long addr, len, end;\n\tint nr_pinned = 0, ret = 0;\n\n\tif (WARN_ON_ONCE(gup_flags & ~(FOLL_WRITE | FOLL_LONGTERM |\n\t\t\t\t       FOLL_FORCE | FOLL_PIN | FOLL_GET)))\n\t\treturn -EINVAL;\n\n\tstart = untagged_addr(start) & PAGE_MASK;\n\taddr = start;\n\tlen = (unsigned long) nr_pages << PAGE_SHIFT;\n\tend = start + len;\n\n\tif (end <= start)\n\t\treturn 0;\n\tif (unlikely(!access_ok((void __user *)start, len)))\n\t\treturn -EFAULT;\n\n\tif (IS_ENABLED(CONFIG_HAVE_FAST_GUP) &&\n\t    gup_fast_permitted(start, end)) {\n\t\tlocal_irq_disable();\n\t\tgup_pgd_range(addr, end, gup_flags, pages, &nr_pinned);\n\t\tlocal_irq_enable();\n\t\tret = nr_pinned;\n\t}\n\n\tif (nr_pinned < nr_pages) {\n\t\t/* Try to get the remaining pages with get_user_pages */\n\t\tstart += nr_pinned << PAGE_SHIFT;\n\t\tpages += nr_pinned;\n\n\t\tret = __gup_longterm_unlocked(start, nr_pages - nr_pinned,\n\t\t\t\t\t      gup_flags, pages);\n\n\t\t/* Have to be a bit careful with return values */\n\t\tif (nr_pinned > 0) {\n\t\t\tif (ret < 0)\n\t\t\t\tret = nr_pinned;\n\t\t\telse\n\t\t\t\tret += nr_pinned;\n\t\t}\n\t}\n\n\treturn ret;\n}",
        "func_after": "static int internal_get_user_pages_fast(unsigned long start, int nr_pages,\n\t\t\t\t\tunsigned int gup_flags,\n\t\t\t\t\tstruct page **pages)\n{\n\tunsigned long addr, len, end;\n\tint nr_pinned = 0, ret = 0;\n\n\tif (WARN_ON_ONCE(gup_flags & ~(FOLL_WRITE | FOLL_LONGTERM |\n\t\t\t\t       FOLL_FORCE | FOLL_PIN | FOLL_GET)))\n\t\treturn -EINVAL;\n\n\tstart = untagged_addr(start) & PAGE_MASK;\n\taddr = start;\n\tlen = (unsigned long) nr_pages << PAGE_SHIFT;\n\tend = start + len;\n\n\tif (end <= start)\n\t\treturn 0;\n\tif (unlikely(!access_ok((void __user *)start, len)))\n\t\treturn -EFAULT;\n\n\t/*\n\t * The FAST_GUP case requires FOLL_WRITE even for pure reads,\n\t * because get_user_pages() may need to cause an early COW in\n\t * order to avoid confusing the normal COW routines. So only\n\t * targets that are already writable are safe to do by just\n\t * looking at the page tables.\n\t */\n\tif (IS_ENABLED(CONFIG_HAVE_FAST_GUP) &&\n\t    gup_fast_permitted(start, end)) {\n\t\tlocal_irq_disable();\n\t\tgup_pgd_range(addr, end, gup_flags | FOLL_WRITE, pages, &nr_pinned);\n\t\tlocal_irq_enable();\n\t\tret = nr_pinned;\n\t}\n\n\tif (nr_pinned < nr_pages) {\n\t\t/* Try to get the remaining pages with get_user_pages */\n\t\tstart += nr_pinned << PAGE_SHIFT;\n\t\tpages += nr_pinned;\n\n\t\tret = __gup_longterm_unlocked(start, nr_pages - nr_pinned,\n\t\t\t\t\t      gup_flags, pages);\n\n\t\t/* Have to be a bit careful with return values */\n\t\tif (nr_pinned > 0) {\n\t\t\tif (ret < 0)\n\t\t\t\tret = nr_pinned;\n\t\t\telse\n\t\t\t\tret += nr_pinned;\n\t\t}\n\t}\n\n\treturn ret;\n}",
        "description": "An issue was discovered in the Linux kernel prior to version 5.7.3, affecting the memory management components located in mm/gup.c and mm/huge_memory.c. The get_user_pages (gup) implementation, when utilized for copy-on-write pages, fails to correctly handle read operation semantics, potentially resulting in unintended write access.",
        "commit": "The vulnerability involves the `get_user_pages()` function in the Linux kernel, which can lead to ambiguous behavior when dealing with copy-on-write (COW) pages. Specifically, the function may return a page pointer that is no longer associated with the original virtual memory area (VM) due to potential COW events. This ambiguity arises because the direction and timing of COW events are undefined, and a page can be unmapped by the thread that performed the `get_user_pages()` call, especially under memory pressure.\n\nTo mitigate this issue, the kernel introduces a change to force a COW event by setting the `FOLL_WRITE` flag when `FOLL_GET` or `FOLL_PIN` is used on a COW mapping. This ensures that the page is properly isolated from other VMs, preventing unintended access or control. However, this change affects the behavior of `get_user_pages_fast()`, which now refuses to follow read-only pages due to the potential need for COW breaking, leading to slower processing in such cases.\n\nThe current semantics are as follows:\n- `__get_user_pages_fast()`: No changes; it does not break COW unless explicitly asked.\n- `get_user_pages_fast()`: Refuses to follow read-only pages, requiring the slow path for COW breaking.\n- `get_user_pages()`: Forces COW breaking for COW mappings when using `FOLL_GET` or `FOLL_PIN`.\n\nThis change aims to clarify the semantics of `get_user_pages()` and reduce the risk of subtle bugs related to COW behavior. While this addresses the ambiguity, it is noted that true shared mappings will still allow pages to change under the user, meaning `get_user_pages()` does not guarantee a \"stable\" page."
    },
    {
        "cwe": "CWE-354",
        "func_name": "systemd/journal_file_offline_close",
        "score": 0.7472009658813477,
        "func_before": "JournalFile* journal_file_offline_close(JournalFile *f) {\n        if (!f)\n                return NULL;\n\n#if HAVE_GCRYPT\n        /* Write the final tag */\n        if (JOURNAL_HEADER_SEALED(f->header) && journal_file_writable(f)) {\n                int r;\n\n                r = journal_file_append_tag(f);\n                if (r < 0)\n                        log_error_errno(r, \"Failed to append tag when closing journal: %m\");\n        }\n#endif\n\n        if (sd_event_source_get_enabled(f->post_change_timer, NULL) > 0)\n                journal_file_post_change(f);\n        sd_event_source_disable_unref(f->post_change_timer);\n\n        journal_file_set_offline(f, true);\n\n        return journal_file_close(f);\n}",
        "func_after": "JournalFile* journal_file_offline_close(JournalFile *f) {\n        if (!f)\n                return NULL;\n\n        journal_file_write_final_tag(f);\n\n        if (sd_event_source_get_enabled(f->post_change_timer, NULL) > 0)\n                journal_file_post_change(f);\n        sd_event_source_disable_unref(f->post_change_timer);\n\n        journal_file_set_offline(f, true);\n\n        return journal_file_close(f);\n}",
        "description": "An issue was discovered in systemd where an attacker can manipulate a sealed log file by truncating it and then resuming the log sealing process. This manipulation allows the attacker to alter the log content without detection, as integrity checks do not reveal any errors.",
        "commit": "The vulnerability involves an issue in the `journalctl` tool where empty log epochs are not properly sealed, allowing attackers to manipulate sealed logs by truncating them and continuing without detection during verification. This defect partially addresses CVE-2023-31438. To fully resolve the issue, the system should enforce that there is exactly one seal per epoch and prevent sealing until an epoch has ended. Additionally, a new journal-file flag, `HEADER_COMPATIBLE_SEALED_CONTINUOUS`, has been introduced to indicate continuous sealing and determine whether missing cryptographic epochs should result in warnings or errors."
    },
    {
        "cwe": "CWE-1284",
        "func_name": "Samsung/crypto_bignum_allocate",
        "score": 0.7520413398742676,
        "func_before": "struct bignum *crypto_bignum_allocate(size_t size_bits)\n{\n\tsize_t sz = mpa_StaticVarSizeInU32(size_bits) *\tsizeof(uint32_t);\n\tstruct mpa_numbase_struct *bn = calloc(1, sz);\n\n\tif (!bn)\n\t\treturn NULL;\n\tbn->alloc = sz - MPA_NUMBASE_METADATA_SIZE_IN_U32 * sizeof(uint32_t);\n\treturn (struct bignum *)bn;\n}",
        "func_after": "struct bignum *crypto_bignum_allocate(size_t size_bits)\n{\n\tsize_t sz = mpa_StaticVarSizeInU32(size_bits) *\tsizeof(uint32_t);\n\t// struct mpa_numbase_struct *bn = calloc(1, sz);\n\tstruct mpa_numbase_struct *bn= TEE_Malloc(sz, TEE_MALLOC_FILL_ZERO);\n\tif (!bn)\n\t\treturn NULL;\n\tbn->alloc = sz - MPA_NUMBASE_METADATA_SIZE_IN_U32 * sizeof(uint32_t);\n\treturn (struct bignum *)bn;\n}",
        "description": "The function `tee_obj_free` in Samsung mTower through version 0.3.0 enables a trusted application to cause a Denial of Service (DoS) by calling the function `TEE_AllocateOperation` with a disrupted heap layout, which is associated with `utee_cryp_obj_alloc`.",
        "commit": "A vulnerability has been addressed in a software system, specifically identified by CVE-2022-40761."
    },
    {
        "cwe": "CWE-444",
        "func_name": "haproxy/http_parse_cont_len_header",
        "score": 0.7492063641548157,
        "func_before": "int http_parse_cont_len_header(struct ist *value, unsigned long long *body_len,\n                               int not_first)\n{\n\tchar *e, *n;\n\tunsigned long long cl;\n\tstruct ist word;\n\tint check_prev = not_first;\n\n\tword.ptr = value->ptr - 1; // -1 for next loop's pre-increment\n\te = value->ptr + value->len;\n\n\twhile (++word.ptr < e) {\n\t\t/* skip leading delimiter and blanks */\n\t\tif (unlikely(HTTP_IS_LWS(*word.ptr)))\n\t\t\tcontinue;\n\n\t\t/* digits only now */\n\t\tfor (cl = 0, n = word.ptr; n < e; n++) {\n\t\t\tunsigned int c = *n - '0';\n\t\t\tif (unlikely(c > 9)) {\n\t\t\t\t/* non-digit */\n\t\t\t\tif (unlikely(n == word.ptr)) // spaces only\n\t\t\t\t\tgoto fail;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (unlikely(cl > ULLONG_MAX / 10ULL))\n\t\t\t\tgoto fail; /* multiply overflow */\n\t\t\tcl = cl * 10ULL;\n\t\t\tif (unlikely(cl + c < cl))\n\t\t\t\tgoto fail; /* addition overflow */\n\t\t\tcl = cl + c;\n\t\t}\n\n\t\t/* keep a copy of the exact cleaned value */\n\t\tword.len = n - word.ptr;\n\n\t\t/* skip trailing LWS till next comma or EOL */\n\t\tfor (; n < e; n++) {\n\t\t\tif (!HTTP_IS_LWS(*n)) {\n\t\t\t\tif (unlikely(*n != ','))\n\t\t\t\t\tgoto fail;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\t/* if duplicate, must be equal */\n\t\tif (check_prev && cl != *body_len)\n\t\t\tgoto fail;\n\n\t\t/* OK, store this result as the one to be indexed */\n\t\t*body_len = cl;\n\t\t*value = word;\n\t\tword.ptr = n;\n\t\tcheck_prev = 1;\n\t}\n\n\t/* here we've reached the end with a single value or a series of\n\t * identical values, all matching previous series if any. The last\n\t * parsed value was sent back into <value>. We just have to decide\n\t * if this occurrence has to be indexed (it's the first one) or\n\t * silently skipped (it's not the first one)\n\t */\n\treturn !not_first;\n fail:\n\treturn -1;\n}",
        "func_after": "int http_parse_cont_len_header(struct ist *value, unsigned long long *body_len,\n                               int not_first)\n{\n\tchar *e, *n;\n\tunsigned long long cl;\n\tstruct ist word;\n\tint check_prev = not_first;\n\n\tword.ptr = value->ptr;\n\te = value->ptr + value->len;\n\n\twhile (1) {\n\t\tif (word.ptr >= e) {\n\t\t\t/* empty header or empty value */\n\t\t\tgoto fail;\n\t\t}\n\n\t\t/* skip leading delimiter and blanks */\n\t\tif (unlikely(HTTP_IS_LWS(*word.ptr))) {\n\t\t\tword.ptr++;\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* digits only now */\n\t\tfor (cl = 0, n = word.ptr; n < e; n++) {\n\t\t\tunsigned int c = *n - '0';\n\t\t\tif (unlikely(c > 9)) {\n\t\t\t\t/* non-digit */\n\t\t\t\tif (unlikely(n == word.ptr)) // spaces only\n\t\t\t\t\tgoto fail;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (unlikely(cl > ULLONG_MAX / 10ULL))\n\t\t\t\tgoto fail; /* multiply overflow */\n\t\t\tcl = cl * 10ULL;\n\t\t\tif (unlikely(cl + c < cl))\n\t\t\t\tgoto fail; /* addition overflow */\n\t\t\tcl = cl + c;\n\t\t}\n\n\t\t/* keep a copy of the exact cleaned value */\n\t\tword.len = n - word.ptr;\n\n\t\t/* skip trailing LWS till next comma or EOL */\n\t\tfor (; n < e; n++) {\n\t\t\tif (!HTTP_IS_LWS(*n)) {\n\t\t\t\tif (unlikely(*n != ','))\n\t\t\t\t\tgoto fail;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\t/* if duplicate, must be equal */\n\t\tif (check_prev && cl != *body_len)\n\t\t\tgoto fail;\n\n\t\t/* OK, store this result as the one to be indexed */\n\t\t*body_len = cl;\n\t\t*value = word;\n\n\t\t/* Now either n==e and we're done, or n points to the comma,\n\t\t * and we skip it and continue.\n\t\t */\n\t\tif (n++ == e)\n\t\t\tbreak;\n\n\t\tword.ptr = n;\n\t\tcheck_prev = 1;\n\t}\n\n\t/* here we've reached the end with a single value or a series of\n\t * identical values, all matching previous series if any. The last\n\t * parsed value was sent back into <value>. We just have to decide\n\t * if this occurrence has to be indexed (it's the first one) or\n\t * silently skipped (it's not the first one)\n\t */\n\treturn !not_first;\n fail:\n\treturn -1;\n}",
        "description": "HAProxy versions up to 2.0.32, 2.1.x, 2.2.x through 2.2.30, 2.3.x, 2.4.x through 2.4.23, 2.5.x, and 2.6.x before 2.6.15, 2.7.x before 2.7.10, and 2.8.x before 2.8.2 forward empty Content-Length headers, which violates RFC 9110 section 8.6. In rare scenarios, an HTTP/1 server positioned behind HAProxy may misinterpret the payload as an additional request.",
        "commit": "A vulnerability was identified in the HTTP content-length header parsing mechanism, where an empty or trailing-comma value could be misinterpreted as an absent header. This oversight allowed such headers to pass through to the backend server without proper validation, potentially exposing vulnerable servers to attacks. The risk varies based on the backend server's handling of content-length headers, but users relying on HAProxy to protect known-vulnerable servers are particularly at risk. A configuration-based workaround involves explicitly rejecting requests with empty content-length headers in the frontend settings. The permanent fix requires modifying the parser to ensure that only valid values are accepted, rejecting any empty values encountered. This change needs to be applied across all supported versions of the software. The modifications were made to functions such as `h1_parse_cont_len_header()` and `http_parse_cont_len_header()`, with additional considerations for compatibility with Lua and future deprecation plans. Comprehensive testing was conducted to validate these changes."
    }
]