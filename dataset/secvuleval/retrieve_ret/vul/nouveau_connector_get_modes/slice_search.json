[
    {
        "cwe": "CWE-754",
        "func_name": "torvalds/copy_params",
        "score": 0.7753117084503174,
        "func_before": "static int copy_params(struct dm_ioctl __user *user, struct dm_ioctl *param_kernel,\n\t\t       int ioctl_flags, struct dm_ioctl **param, int *param_flags)\n{\n\tstruct dm_ioctl *dmi;\n\tint secure_data;\n\tconst size_t minimum_data_size = offsetof(struct dm_ioctl, data);\n\n\t/* check_version() already copied version from userspace, avoid TOCTOU */\n\tif (copy_from_user((char *)param_kernel + sizeof(param_kernel->version),\n\t\t\t   (char __user *)user + sizeof(param_kernel->version),\n\t\t\t   minimum_data_size - sizeof(param_kernel->version)))\n\t\treturn -EFAULT;\n\n\tif (param_kernel->data_size < minimum_data_size) {\n\t\tDMERR(\"Invalid data size in the ioctl structure: %u\",\n\t\t      param_kernel->data_size);\n\t\treturn -EINVAL;\n\t}\n\n\tsecure_data = param_kernel->flags & DM_SECURE_DATA_FLAG;\n\n\t*param_flags = secure_data ? DM_WIPE_BUFFER : 0;\n\n\tif (ioctl_flags & IOCTL_FLAGS_NO_PARAMS) {\n\t\tdmi = param_kernel;\n\t\tdmi->data_size = minimum_data_size;\n\t\tgoto data_copied;\n\t}\n\n\t/*\n\t * Use __GFP_HIGH to avoid low memory issues when a device is\n\t * suspended and the ioctl is needed to resume it.\n\t * Use kmalloc() rather than vmalloc() when we can.\n\t */\n\tdmi = NULL;\n\tdmi = kvmalloc(param_kernel->data_size, GFP_NOIO | __GFP_HIGH);\n\n\tif (!dmi) {\n\t\tif (secure_data && clear_user(user, param_kernel->data_size))\n\t\t\treturn -EFAULT;\n\t\treturn -ENOMEM;\n\t}\n\n\t*param_flags |= DM_PARAMS_MALLOC;\n\n\t/* Copy from param_kernel (which was already copied from user) */\n\tmemcpy(dmi, param_kernel, minimum_data_size);\n\n\tif (copy_from_user(&dmi->data, (char __user *)user + minimum_data_size,\n\t\t\t   param_kernel->data_size - minimum_data_size))\n\t\tgoto bad;\ndata_copied:\n\t/* Wipe the user buffer so we do not return it to userspace */\n\tif (secure_data && clear_user(user, param_kernel->data_size))\n\t\tgoto bad;\n\n\t*param = dmi;\n\treturn 0;\n\nbad:\n\tfree_params(dmi, param_kernel->data_size, *param_flags);\n\n\treturn -EFAULT;\n}",
        "func_after": "static int copy_params(struct dm_ioctl __user *user, struct dm_ioctl *param_kernel,\n\t\t       int ioctl_flags, struct dm_ioctl **param, int *param_flags)\n{\n\tstruct dm_ioctl *dmi;\n\tint secure_data;\n\tconst size_t minimum_data_size = offsetof(struct dm_ioctl, data);\n\n\t/* check_version() already copied version from userspace, avoid TOCTOU */\n\tif (copy_from_user((char *)param_kernel + sizeof(param_kernel->version),\n\t\t\t   (char __user *)user + sizeof(param_kernel->version),\n\t\t\t   minimum_data_size - sizeof(param_kernel->version)))\n\t\treturn -EFAULT;\n\n\tif (unlikely(param_kernel->data_size < minimum_data_size) ||\n\t    unlikely(param_kernel->data_size > DM_MAX_TARGETS * DM_MAX_TARGET_PARAMS)) {\n\t\tDMERR(\"Invalid data size in the ioctl structure: %u\",\n\t\t      param_kernel->data_size);\n\t\treturn -EINVAL;\n\t}\n\n\tsecure_data = param_kernel->flags & DM_SECURE_DATA_FLAG;\n\n\t*param_flags = secure_data ? DM_WIPE_BUFFER : 0;\n\n\tif (ioctl_flags & IOCTL_FLAGS_NO_PARAMS) {\n\t\tdmi = param_kernel;\n\t\tdmi->data_size = minimum_data_size;\n\t\tgoto data_copied;\n\t}\n\n\t/*\n\t * Use __GFP_HIGH to avoid low memory issues when a device is\n\t * suspended and the ioctl is needed to resume it.\n\t * Use kmalloc() rather than vmalloc() when we can.\n\t */\n\tdmi = NULL;\n\tdmi = kvmalloc(param_kernel->data_size, GFP_NOIO | __GFP_HIGH);\n\n\tif (!dmi) {\n\t\tif (secure_data && clear_user(user, param_kernel->data_size))\n\t\t\treturn -EFAULT;\n\t\treturn -ENOMEM;\n\t}\n\n\t*param_flags |= DM_PARAMS_MALLOC;\n\n\t/* Copy from param_kernel (which was already copied from user) */\n\tmemcpy(dmi, param_kernel, minimum_data_size);\n\n\tif (copy_from_user(&dmi->data, (char __user *)user + minimum_data_size,\n\t\t\t   param_kernel->data_size - minimum_data_size))\n\t\tgoto bad;\ndata_copied:\n\t/* Wipe the user buffer so we do not return it to userspace */\n\tif (secure_data && clear_user(user, param_kernel->data_size))\n\t\tgoto bad;\n\n\t*param = dmi;\n\treturn 0;\n\nbad:\n\tfree_params(dmi, param_kernel->data_size, *param_flags);\n\n\treturn -EFAULT;\n}",
        "description": "The `dm_table_create` function in the device mapper module of the Linux kernel, up to version 6.7.4, may allocate more than `INT_MAX` bytes during the `alloc_targets` process due to a lack of validation for the `struct dm_ioctl.target_count`. This oversight can lead to a system crash.",
        "commit": "The `kvmalloc` function generates a warning when the requested size exceeds `INT_MAX`. This issue was identified during automated syscall testing. To prevent such warnings, the commit imposes a limit of 1,048,576 targets and restricts the parameter area size to 1,073,741,824 bytes."
    },
    {
        "cwe": "CWE-440",
        "func_name": "eclipse-openj9/Java_java_lang_invoke_InterfaceHandle_convertITableIndexToVTableIndex",
        "score": 0.7478041648864746,
        "func_before": "JNIEXPORT jint JNICALL Java_java_lang_invoke_InterfaceHandle_convertITableIndexToVTableIndex\n  (JNIEnv *env, jclass InterfaceMethodHandle, jlong interfaceArg, jint itableIndex, jlong receiverClassArg)\n   {\n   J9Class  *interfaceClass = (J9Class*)(intptr_t)interfaceArg;\n   J9Class  *receiverClass  = (J9Class*)(intptr_t)receiverClassArg;\n   J9ITable *itableEntry;\n   for (itableEntry = (J9ITable*)receiverClass->iTable; itableEntry; itableEntry = itableEntry->next)\n      if (itableEntry->interfaceClass == interfaceClass)\n         break;\n   TR_ASSERT(itableEntry, \"Shouldn't call convertITableIndexToVTableIndex without first ensuring the receiver implements the interface\");\n   UDATA *itableArray = (UDATA*)(itableEntry+1);\n   return (itableArray[itableIndex] - sizeof(J9Class))/sizeof(intptr_t);\n#if 0 // TODO:JSR292: We probably want to do something more like this instead, so it will properly handle exceptional cases\n   struct\n      {\n      UDATA interfaceClass;\n      UDATA methodIndex;\n      } indexAndLiterals =\n      {\n      (UDATA)interfaceClass,\n      (UDATA)itableIndex\n      };\n   J9Object *receiver = (J9Object*)receiverArg;\n   return (jint)jitLookupInterfaceMethod(receiver->clazz, &indexAndLiterals, 0);\n#endif\n   }",
        "func_after": "JNIEXPORT jint JNICALL Java_java_lang_invoke_InterfaceHandle_convertITableIndexToVTableIndex\n  (JNIEnv *env, jclass InterfaceMethodHandle, jlong interfaceArg, jint itableIndex, jlong receiverClassArg)\n   {\n   J9Class  *interfaceClass = (J9Class*)(intptr_t)interfaceArg;\n   J9Class  *receiverClass  = (J9Class*)(intptr_t)receiverClassArg;\n   J9ITable *itableEntry;\n   for (itableEntry = (J9ITable*)receiverClass->iTable; itableEntry; itableEntry = itableEntry->next)\n      if (itableEntry->interfaceClass == interfaceClass)\n         break;\n   TR_ASSERT(itableEntry, \"Shouldn't call convertITableIndexToVTableIndex without first ensuring the receiver implements the interface\");\n   UDATA *itableArray = (UDATA*)(itableEntry+1);\n   UDATA vTableOffset = itableArray[itableIndex];\n   J9Method *method = *(J9Method**)((UDATA)receiverClass + vTableOffset);\n   if ((J9_ROM_METHOD_FROM_RAM_METHOD(method)->modifiers & J9AccPublic) == 0)\n      return -1;\n\n   return (vTableOffset - sizeof(J9Class))/sizeof(intptr_t);\n#if 0 // TODO:JSR292: We probably want to do something more like this instead, so it will properly handle exceptional cases\n   struct\n      {\n      UDATA interfaceClass;\n      UDATA methodIndex;\n      } indexAndLiterals =\n      {\n      (UDATA)interfaceClass,\n      (UDATA)itableIndex\n      };\n   J9Object *receiver = (J9Object*)receiverArg;\n   return (jint)jitLookupInterfaceMethod(receiver->clazz, &indexAndLiterals, 0);\n#endif\n   }",
        "description": "In versions of Eclipse Openj9 prior to 0.29.0, the Java Virtual Machine (JVM) fails to throw an IllegalAccessError when MethodHandles are used to invoke methods that are not accessible through interfaces.",
        "commit": "The vulnerability involves a situation where an `IllegalAccessError` (IAE) is not being thrown appropriately when an `InterfaceHandle` encounters a non-public method during dispatch. The expected behavior is for the dispatch mechanism implemented by `InterfaceHandle` to mimic that of `invokeinterface`, which throws an `IAE` when attempting to access non-public methods. This discrepancy allows unauthorized access to non-public methods, potentially leading to security vulnerabilities."
    },
    {
        "cwe": "CWE-843",
        "func_name": "torvalds/__fib6_rule_action",
        "score": 0.7630495429039001,
        "func_before": "static int __fib6_rule_action(struct fib_rule *rule, struct flowi *flp,\n\t\t\t      int flags, struct fib_lookup_arg *arg)\n{\n\tstruct flowi6 *flp6 = &flp->u.ip6;\n\tstruct rt6_info *rt = NULL;\n\tstruct fib6_table *table;\n\tstruct net *net = rule->fr_net;\n\tpol_lookup_t lookup = arg->lookup_ptr;\n\tint err = 0;\n\tu32 tb_id;\n\n\tswitch (rule->action) {\n\tcase FR_ACT_TO_TBL:\n\t\tbreak;\n\tcase FR_ACT_UNREACHABLE:\n\t\terr = -ENETUNREACH;\n\t\trt = net->ipv6.ip6_null_entry;\n\t\tgoto discard_pkt;\n\tdefault:\n\tcase FR_ACT_BLACKHOLE:\n\t\terr = -EINVAL;\n\t\trt = net->ipv6.ip6_blk_hole_entry;\n\t\tgoto discard_pkt;\n\tcase FR_ACT_PROHIBIT:\n\t\terr = -EACCES;\n\t\trt = net->ipv6.ip6_prohibit_entry;\n\t\tgoto discard_pkt;\n\t}\n\n\ttb_id = fib_rule_get_table(rule, arg);\n\ttable = fib6_get_table(net, tb_id);\n\tif (!table) {\n\t\terr = -EAGAIN;\n\t\tgoto out;\n\t}\n\n\trt = lookup(net, table, flp6, arg->lookup_data, flags);\n\tif (rt != net->ipv6.ip6_null_entry) {\n\t\terr = fib6_rule_saddr(net, rule, flags, flp6,\n\t\t\t\t      ip6_dst_idev(&rt->dst)->dev);\n\n\t\tif (err == -EAGAIN)\n\t\t\tgoto again;\n\n\t\terr = rt->dst.error;\n\t\tif (err != -EAGAIN)\n\t\t\tgoto out;\n\t}\nagain:\n\tip6_rt_put(rt);\n\terr = -EAGAIN;\n\trt = NULL;\n\tgoto out;\n\ndiscard_pkt:\n\tdst_hold(&rt->dst);\nout:\n\targ->result = rt;\n\treturn err;\n}",
        "func_after": "static int __fib6_rule_action(struct fib_rule *rule, struct flowi *flp,\n\t\t\t      int flags, struct fib_lookup_arg *arg)\n{\n\tstruct fib6_result *res = arg->result;\n\tstruct flowi6 *flp6 = &flp->u.ip6;\n\tstruct rt6_info *rt = NULL;\n\tstruct fib6_table *table;\n\tstruct net *net = rule->fr_net;\n\tpol_lookup_t lookup = arg->lookup_ptr;\n\tint err = 0;\n\tu32 tb_id;\n\n\tswitch (rule->action) {\n\tcase FR_ACT_TO_TBL:\n\t\tbreak;\n\tcase FR_ACT_UNREACHABLE:\n\t\terr = -ENETUNREACH;\n\t\trt = net->ipv6.ip6_null_entry;\n\t\tgoto discard_pkt;\n\tdefault:\n\tcase FR_ACT_BLACKHOLE:\n\t\terr = -EINVAL;\n\t\trt = net->ipv6.ip6_blk_hole_entry;\n\t\tgoto discard_pkt;\n\tcase FR_ACT_PROHIBIT:\n\t\terr = -EACCES;\n\t\trt = net->ipv6.ip6_prohibit_entry;\n\t\tgoto discard_pkt;\n\t}\n\n\ttb_id = fib_rule_get_table(rule, arg);\n\ttable = fib6_get_table(net, tb_id);\n\tif (!table) {\n\t\terr = -EAGAIN;\n\t\tgoto out;\n\t}\n\n\trt = lookup(net, table, flp6, arg->lookup_data, flags);\n\tif (rt != net->ipv6.ip6_null_entry) {\n\t\terr = fib6_rule_saddr(net, rule, flags, flp6,\n\t\t\t\t      ip6_dst_idev(&rt->dst)->dev);\n\n\t\tif (err == -EAGAIN)\n\t\t\tgoto again;\n\n\t\terr = rt->dst.error;\n\t\tif (err != -EAGAIN)\n\t\t\tgoto out;\n\t}\nagain:\n\tip6_rt_put(rt);\n\terr = -EAGAIN;\n\trt = NULL;\n\tgoto out;\n\ndiscard_pkt:\n\tdst_hold(&rt->dst);\nout:\n\tres->rt6 = rt;\n\treturn err;\n}",
        "description": "A flaw was identified in the IPv6 module of the Linux kernel, where the variable `arg.result` was inconsistently utilized within the function `fib6_rule_lookup`. At times, it held a value of type `rt6_info`, while at other times it held a value of type `fib6_info`. This inconsistency was not properly managed in other parts of the code that anticipated `rt6_info` unconditionally, potentially resulting in a kernel panic during the execution of `fib6_rule_suppress`.",
        "commit": "The use of the `result` argument in `fib_lookup_arg` is inconsistent within IPv6 routing mechanisms. Specifically, `arg.result` is sometimes utilized as a `fib6_result` and other times as a container for `rt6_info`. To address this inconsistency, `rt6_info` should be incorporated into `fib6_result`, ensuring uniform usage of `arg.result` throughout IPv6 routing rules. Additionally, the `rt6` entry is populated during lookups that return a `dst_entry`, but not for direct `fib_lookups` that merely require a `fib6_info`."
    },
    {
        "cwe": "CWE-755",
        "func_name": "xen-project/map_grant_ref",
        "score": 0.7731810212135315,
        "func_before": "static void\nmap_grant_ref(\n    struct gnttab_map_grant_ref *op)\n{\n    struct domain *ld, *rd, *owner = NULL;\n    struct grant_table *lgt, *rgt;\n    grant_ref_t ref;\n    grant_handle_t handle;\n    mfn_t mfn;\n    struct page_info *pg = NULL;\n    int            rc = GNTST_okay;\n    unsigned int   cache_flags, clear_flags = 0, refcnt = 0, typecnt = 0;\n    bool           host_map_created = false;\n    struct active_grant_entry *act = NULL;\n    struct grant_mapping *mt;\n    grant_entry_header_t *shah;\n    uint16_t *status;\n    bool_t need_iommu;\n\n    ld = current->domain;\n\n    if ( unlikely((op->flags & (GNTMAP_device_map|GNTMAP_host_map)) == 0) )\n    {\n        gdprintk(XENLOG_INFO, \"Bad flags in grant map op: %x\\n\", op->flags);\n        op->status = GNTST_bad_gntref;\n        return;\n    }\n\n    if ( unlikely(paging_mode_external(ld) &&\n                  (op->flags & (GNTMAP_device_map|GNTMAP_application_map|\n                            GNTMAP_contains_pte))) )\n    {\n        gdprintk(XENLOG_INFO, \"No device mapping in HVM domain\\n\");\n        op->status = GNTST_general_error;\n        return;\n    }\n\n    if ( unlikely((rd = rcu_lock_domain_by_id(op->dom)) == NULL) )\n    {\n        gdprintk(XENLOG_INFO, \"Could not find domain %d\\n\", op->dom);\n        op->status = GNTST_bad_domain;\n        return;\n    }\n\n    rc = xsm_grant_mapref(XSM_HOOK, ld, rd, op->flags);\n    if ( rc )\n    {\n        rcu_unlock_domain(rd);\n        op->status = GNTST_permission_denied;\n        return;\n    }\n\n    lgt = ld->grant_table;\n    handle = get_maptrack_handle(lgt);\n    if ( unlikely(handle == INVALID_MAPTRACK_HANDLE) )\n    {\n        rcu_unlock_domain(rd);\n        gdprintk(XENLOG_INFO, \"Failed to obtain maptrack handle\\n\");\n        op->status = GNTST_no_device_space;\n        return;\n    }\n\n    rgt = rd->grant_table;\n    grant_read_lock(rgt);\n\n    /* Bounds check on the grant ref */\n    ref = op->ref;\n    if ( unlikely(ref >= nr_grant_entries(rgt)))\n        PIN_FAIL(unlock_out, GNTST_bad_gntref, \"Bad ref %#x for d%d\\n\",\n                 ref, rgt->domain->domain_id);\n\n    /* This call also ensures the above check cannot be passed speculatively */\n    shah = shared_entry_header(rgt, ref);\n    act = active_entry_acquire(rgt, ref);\n\n    /* Make sure we do not access memory speculatively */\n    status = evaluate_nospec(rgt->gt_version == 1) ? &shah->flags\n                                                 : &status_entry(rgt, ref);\n\n    /* If already pinned, check the active domid and avoid refcnt overflow. */\n    if ( act->pin &&\n         ((act->domid != ld->domain_id) ||\n          (act->pin & 0x80808080U) != 0 ||\n          (act->is_sub_page)) )\n        PIN_FAIL(act_release_out, GNTST_general_error,\n                 \"Bad domain (%d != %d), or risk of counter overflow %08x, or subpage %d\\n\",\n                 act->domid, ld->domain_id, act->pin, act->is_sub_page);\n\n    if ( !act->pin ||\n         (!(op->flags & GNTMAP_readonly) &&\n          !(act->pin & (GNTPIN_hstw_mask|GNTPIN_devw_mask))) )\n    {\n        if ( (rc = _set_status(shah, status, rd, rgt->gt_version, act,\n                               op->flags & GNTMAP_readonly, 1,\n                               ld->domain_id) != GNTST_okay) )\n            goto act_release_out;\n\n        if ( !act->pin )\n        {\n            unsigned long gfn = evaluate_nospec(rgt->gt_version == 1) ?\n                                shared_entry_v1(rgt, ref).frame :\n                                shared_entry_v2(rgt, ref).full_page.frame;\n\n            rc = get_paged_frame(gfn, &mfn, &pg,\n                                 op->flags & GNTMAP_readonly, rd);\n            if ( rc != GNTST_okay )\n                goto unlock_out_clear;\n            act_set_gfn(act, _gfn(gfn));\n            act->domid = ld->domain_id;\n            act->mfn = mfn;\n            act->start = 0;\n            act->length = PAGE_SIZE;\n            act->is_sub_page = false;\n            act->trans_domain = rd;\n            act->trans_gref = ref;\n        }\n    }\n\n    if ( op->flags & GNTMAP_device_map )\n        act->pin += (op->flags & GNTMAP_readonly) ?\n            GNTPIN_devr_inc : GNTPIN_devw_inc;\n    if ( op->flags & GNTMAP_host_map )\n        act->pin += (op->flags & GNTMAP_readonly) ?\n            GNTPIN_hstr_inc : GNTPIN_hstw_inc;\n\n    mfn = act->mfn;\n\n    cache_flags = (shah->flags & (GTF_PAT | GTF_PWT | GTF_PCD) );\n\n    active_entry_release(act);\n    grant_read_unlock(rgt);\n\n    /* pg may be set, with a refcount included, from get_paged_frame(). */\n    if ( !pg )\n    {\n        pg = mfn_valid(mfn) ? mfn_to_page(mfn) : NULL;\n        if ( pg )\n            owner = page_get_owner_and_reference(pg);\n    }\n    else\n        owner = page_get_owner(pg);\n\n    if ( owner )\n        refcnt++;\n\n    if ( !pg || (owner == dom_io) )\n    {\n        /* Only needed the reference to confirm dom_io ownership. */\n        if ( pg )\n        {\n            put_page(pg);\n            refcnt--;\n        }\n\n        if ( paging_mode_external(ld) )\n        {\n            gdprintk(XENLOG_WARNING, \"HVM guests can't grant map iomem\\n\");\n            rc = GNTST_general_error;\n            goto undo_out;\n        }\n\n        if ( !iomem_access_permitted(rd, mfn_x(mfn), mfn_x(mfn)) )\n        {\n            gdprintk(XENLOG_WARNING,\n                     \"Iomem mapping not permitted %#\"PRI_mfn\" (domain %d)\\n\",\n                     mfn_x(mfn), rd->domain_id);\n            rc = GNTST_general_error;\n            goto undo_out;\n        }\n\n        if ( op->flags & GNTMAP_host_map )\n        {\n            rc = create_grant_host_mapping(op->host_addr, mfn, op->flags,\n                                           cache_flags);\n            if ( rc != GNTST_okay )\n                goto undo_out;\n\n            host_map_created = true;\n        }\n    }\n    else if ( owner == rd || (dom_cow && owner == dom_cow) )\n    {\n        if ( (op->flags & GNTMAP_device_map) && !(op->flags & GNTMAP_readonly) )\n        {\n            if ( (owner == dom_cow) ||\n                 !get_page_type(pg, PGT_writable_page) )\n                goto could_not_pin;\n            typecnt++;\n        }\n\n        if ( op->flags & GNTMAP_host_map )\n        {\n            /*\n             * Only need to grab another reference if device_map claimed\n             * the other one.\n             */\n            if ( op->flags & GNTMAP_device_map )\n            {\n                if ( !get_page(pg, rd) )\n                    goto could_not_pin;\n                refcnt++;\n            }\n\n            if ( gnttab_host_mapping_get_page_type(op->flags & GNTMAP_readonly,\n                                                   ld, rd) )\n            {\n                if ( (owner == dom_cow) ||\n                     !get_page_type(pg, PGT_writable_page) )\n                    goto could_not_pin;\n                typecnt++;\n            }\n\n            rc = create_grant_host_mapping(op->host_addr, mfn, op->flags, 0);\n            if ( rc != GNTST_okay )\n                goto undo_out;\n\n            host_map_created = true;\n        }\n    }\n    else\n    {\n    could_not_pin:\n        if ( !rd->is_dying )\n            gdprintk(XENLOG_WARNING, \"Could not pin grant frame %#\"PRI_mfn\"\\n\",\n                     mfn_x(mfn));\n        rc = GNTST_general_error;\n        goto undo_out;\n    }\n\n    need_iommu = gnttab_need_iommu_mapping(ld);\n    if ( need_iommu )\n    {\n        unsigned int kind;\n\n        double_gt_lock(lgt, rgt);\n\n        /*\n         * We're not translated, so we know that dfns and mfns are\n         * the same things, so the IOMMU entry is always 1-to-1.\n         */\n        kind = mapkind(lgt, rd, mfn);\n        if ( !(op->flags & GNTMAP_readonly) &&\n             !(kind & MAPKIND_WRITE) )\n            kind = IOMMUF_readable | IOMMUF_writable;\n        else if ( !kind )\n            kind = IOMMUF_readable;\n        else\n            kind = 0;\n        if ( kind && iommu_legacy_map(ld, _dfn(mfn_x(mfn)), mfn, 0, kind) )\n        {\n            double_gt_unlock(lgt, rgt);\n            rc = GNTST_general_error;\n            goto undo_out;\n        }\n    }\n\n    TRACE_1D(TRC_MEM_PAGE_GRANT_MAP, op->dom);\n\n    /*\n     * All maptrack entry users check mt->flags first before using the\n     * other fields so just ensure the flags field is stored last.\n     *\n     * However, if gnttab_need_iommu_mapping() then this would race\n     * with a concurrent mapkind() call (on an unmap, for example)\n     * and a lock is required.\n     */\n    mt = &maptrack_entry(lgt, handle);\n    mt->domid = op->dom;\n    mt->ref   = op->ref;\n    smp_wmb();\n    write_atomic(&mt->flags, op->flags);\n\n    if ( need_iommu )\n        double_gt_unlock(lgt, rgt);\n\n    op->dev_bus_addr = mfn_to_maddr(mfn);\n    op->handle       = handle;\n    op->status       = GNTST_okay;\n\n    rcu_unlock_domain(rd);\n    return;\n\n undo_out:\n    if ( host_map_created )\n    {\n        replace_grant_host_mapping(op->host_addr, mfn, 0, op->flags);\n        gnttab_flush_tlb(ld);\n    }\n\n    while ( typecnt-- )\n        put_page_type(pg);\n\n    while ( refcnt-- )\n        put_page(pg);\n\n    grant_read_lock(rgt);\n\n    act = active_entry_acquire(rgt, op->ref);\n\n    if ( op->flags & GNTMAP_device_map )\n        act->pin -= (op->flags & GNTMAP_readonly) ?\n            GNTPIN_devr_inc : GNTPIN_devw_inc;\n    if ( op->flags & GNTMAP_host_map )\n        act->pin -= (op->flags & GNTMAP_readonly) ?\n            GNTPIN_hstr_inc : GNTPIN_hstw_inc;\n\n unlock_out_clear:\n    if ( !(op->flags & GNTMAP_readonly) &&\n         !(act->pin & (GNTPIN_hstw_mask|GNTPIN_devw_mask)) )\n        clear_flags |= GTF_writing;\n\n    if ( !act->pin )\n        clear_flags |= GTF_reading;\n\n    if ( clear_flags )\n        gnttab_clear_flags(rd, clear_flags, status);\n\n act_release_out:\n    active_entry_release(act);\n\n unlock_out:\n    grant_read_unlock(rgt);\n    op->status = rc;\n    put_maptrack_handle(lgt, handle);\n    rcu_unlock_domain(rd);\n}",
        "func_after": "static void\nmap_grant_ref(\n    struct gnttab_map_grant_ref *op)\n{\n    struct domain *ld, *rd, *owner = NULL;\n    struct grant_table *lgt, *rgt;\n    grant_ref_t ref;\n    grant_handle_t handle;\n    mfn_t mfn;\n    struct page_info *pg = NULL;\n    int            rc = GNTST_okay;\n    unsigned int   cache_flags, clear_flags = 0, refcnt = 0, typecnt = 0;\n    bool           host_map_created = false;\n    struct active_grant_entry *act = NULL;\n    struct grant_mapping *mt;\n    grant_entry_header_t *shah;\n    uint16_t *status;\n    bool_t need_iommu;\n\n    ld = current->domain;\n\n    if ( unlikely((op->flags & (GNTMAP_device_map|GNTMAP_host_map)) == 0) )\n    {\n        gdprintk(XENLOG_INFO, \"Bad flags in grant map op: %x\\n\", op->flags);\n        op->status = GNTST_bad_gntref;\n        return;\n    }\n\n    if ( unlikely(paging_mode_external(ld) &&\n                  (op->flags & (GNTMAP_device_map|GNTMAP_application_map|\n                            GNTMAP_contains_pte))) )\n    {\n        gdprintk(XENLOG_INFO, \"No device mapping in HVM domain\\n\");\n        op->status = GNTST_general_error;\n        return;\n    }\n\n    if ( unlikely((rd = rcu_lock_domain_by_id(op->dom)) == NULL) )\n    {\n        gdprintk(XENLOG_INFO, \"Could not find domain %d\\n\", op->dom);\n        op->status = GNTST_bad_domain;\n        return;\n    }\n\n    rc = xsm_grant_mapref(XSM_HOOK, ld, rd, op->flags);\n    if ( rc )\n    {\n        rcu_unlock_domain(rd);\n        op->status = GNTST_permission_denied;\n        return;\n    }\n\n    lgt = ld->grant_table;\n    handle = get_maptrack_handle(lgt);\n    if ( unlikely(handle == INVALID_MAPTRACK_HANDLE) )\n    {\n        rcu_unlock_domain(rd);\n        gdprintk(XENLOG_INFO, \"Failed to obtain maptrack handle\\n\");\n        op->status = GNTST_no_device_space;\n        return;\n    }\n\n    rgt = rd->grant_table;\n    grant_read_lock(rgt);\n\n    /* Bounds check on the grant ref */\n    ref = op->ref;\n    if ( unlikely(ref >= nr_grant_entries(rgt)))\n        PIN_FAIL(unlock_out, GNTST_bad_gntref, \"Bad ref %#x for d%d\\n\",\n                 ref, rgt->domain->domain_id);\n\n    /* This call also ensures the above check cannot be passed speculatively */\n    shah = shared_entry_header(rgt, ref);\n    act = active_entry_acquire(rgt, ref);\n\n    /* Make sure we do not access memory speculatively */\n    status = evaluate_nospec(rgt->gt_version == 1) ? &shah->flags\n                                                 : &status_entry(rgt, ref);\n\n    /* If already pinned, check the active domid and avoid refcnt overflow. */\n    if ( act->pin &&\n         ((act->domid != ld->domain_id) ||\n          (act->pin & 0x80808080U) != 0 ||\n          (act->is_sub_page)) )\n        PIN_FAIL(act_release_out, GNTST_general_error,\n                 \"Bad domain (%d != %d), or risk of counter overflow %08x, or subpage %d\\n\",\n                 act->domid, ld->domain_id, act->pin, act->is_sub_page);\n\n    if ( !act->pin ||\n         (!(op->flags & GNTMAP_readonly) &&\n          !(act->pin & (GNTPIN_hstw_mask|GNTPIN_devw_mask))) )\n    {\n        if ( (rc = _set_status(shah, status, rd, rgt->gt_version, act,\n                               op->flags & GNTMAP_readonly, 1,\n                               ld->domain_id)) != GNTST_okay )\n            goto act_release_out;\n\n        if ( !act->pin )\n        {\n            unsigned long gfn = evaluate_nospec(rgt->gt_version == 1) ?\n                                shared_entry_v1(rgt, ref).frame :\n                                shared_entry_v2(rgt, ref).full_page.frame;\n\n            rc = get_paged_frame(gfn, &mfn, &pg,\n                                 op->flags & GNTMAP_readonly, rd);\n            if ( rc != GNTST_okay )\n                goto unlock_out_clear;\n            act_set_gfn(act, _gfn(gfn));\n            act->domid = ld->domain_id;\n            act->mfn = mfn;\n            act->start = 0;\n            act->length = PAGE_SIZE;\n            act->is_sub_page = false;\n            act->trans_domain = rd;\n            act->trans_gref = ref;\n        }\n    }\n\n    if ( op->flags & GNTMAP_device_map )\n        act->pin += (op->flags & GNTMAP_readonly) ?\n            GNTPIN_devr_inc : GNTPIN_devw_inc;\n    if ( op->flags & GNTMAP_host_map )\n        act->pin += (op->flags & GNTMAP_readonly) ?\n            GNTPIN_hstr_inc : GNTPIN_hstw_inc;\n\n    mfn = act->mfn;\n\n    cache_flags = (shah->flags & (GTF_PAT | GTF_PWT | GTF_PCD) );\n\n    active_entry_release(act);\n    grant_read_unlock(rgt);\n\n    /* pg may be set, with a refcount included, from get_paged_frame(). */\n    if ( !pg )\n    {\n        pg = mfn_valid(mfn) ? mfn_to_page(mfn) : NULL;\n        if ( pg )\n            owner = page_get_owner_and_reference(pg);\n    }\n    else\n        owner = page_get_owner(pg);\n\n    if ( owner )\n        refcnt++;\n\n    if ( !pg || (owner == dom_io) )\n    {\n        /* Only needed the reference to confirm dom_io ownership. */\n        if ( pg )\n        {\n            put_page(pg);\n            refcnt--;\n        }\n\n        if ( paging_mode_external(ld) )\n        {\n            gdprintk(XENLOG_WARNING, \"HVM guests can't grant map iomem\\n\");\n            rc = GNTST_general_error;\n            goto undo_out;\n        }\n\n        if ( !iomem_access_permitted(rd, mfn_x(mfn), mfn_x(mfn)) )\n        {\n            gdprintk(XENLOG_WARNING,\n                     \"Iomem mapping not permitted %#\"PRI_mfn\" (domain %d)\\n\",\n                     mfn_x(mfn), rd->domain_id);\n            rc = GNTST_general_error;\n            goto undo_out;\n        }\n\n        if ( op->flags & GNTMAP_host_map )\n        {\n            rc = create_grant_host_mapping(op->host_addr, mfn, op->flags,\n                                           cache_flags);\n            if ( rc != GNTST_okay )\n                goto undo_out;\n\n            host_map_created = true;\n        }\n    }\n    else if ( owner == rd || (dom_cow && owner == dom_cow) )\n    {\n        if ( (op->flags & GNTMAP_device_map) && !(op->flags & GNTMAP_readonly) )\n        {\n            if ( (owner == dom_cow) ||\n                 !get_page_type(pg, PGT_writable_page) )\n                goto could_not_pin;\n            typecnt++;\n        }\n\n        if ( op->flags & GNTMAP_host_map )\n        {\n            /*\n             * Only need to grab another reference if device_map claimed\n             * the other one.\n             */\n            if ( op->flags & GNTMAP_device_map )\n            {\n                if ( !get_page(pg, rd) )\n                    goto could_not_pin;\n                refcnt++;\n            }\n\n            if ( gnttab_host_mapping_get_page_type(op->flags & GNTMAP_readonly,\n                                                   ld, rd) )\n            {\n                if ( (owner == dom_cow) ||\n                     !get_page_type(pg, PGT_writable_page) )\n                    goto could_not_pin;\n                typecnt++;\n            }\n\n            rc = create_grant_host_mapping(op->host_addr, mfn, op->flags, 0);\n            if ( rc != GNTST_okay )\n                goto undo_out;\n\n            host_map_created = true;\n        }\n    }\n    else\n    {\n    could_not_pin:\n        if ( !rd->is_dying )\n            gdprintk(XENLOG_WARNING, \"Could not pin grant frame %#\"PRI_mfn\"\\n\",\n                     mfn_x(mfn));\n        rc = GNTST_general_error;\n        goto undo_out;\n    }\n\n    need_iommu = gnttab_need_iommu_mapping(ld);\n    if ( need_iommu )\n    {\n        unsigned int kind;\n\n        double_gt_lock(lgt, rgt);\n\n        /*\n         * We're not translated, so we know that dfns and mfns are\n         * the same things, so the IOMMU entry is always 1-to-1.\n         */\n        kind = mapkind(lgt, rd, mfn);\n        if ( !(op->flags & GNTMAP_readonly) &&\n             !(kind & MAPKIND_WRITE) )\n            kind = IOMMUF_readable | IOMMUF_writable;\n        else if ( !kind )\n            kind = IOMMUF_readable;\n        else\n            kind = 0;\n        if ( kind && iommu_legacy_map(ld, _dfn(mfn_x(mfn)), mfn, 0, kind) )\n        {\n            double_gt_unlock(lgt, rgt);\n            rc = GNTST_general_error;\n            goto undo_out;\n        }\n    }\n\n    TRACE_1D(TRC_MEM_PAGE_GRANT_MAP, op->dom);\n\n    /*\n     * All maptrack entry users check mt->flags first before using the\n     * other fields so just ensure the flags field is stored last.\n     *\n     * However, if gnttab_need_iommu_mapping() then this would race\n     * with a concurrent mapkind() call (on an unmap, for example)\n     * and a lock is required.\n     */\n    mt = &maptrack_entry(lgt, handle);\n    mt->domid = op->dom;\n    mt->ref   = op->ref;\n    smp_wmb();\n    write_atomic(&mt->flags, op->flags);\n\n    if ( need_iommu )\n        double_gt_unlock(lgt, rgt);\n\n    op->dev_bus_addr = mfn_to_maddr(mfn);\n    op->handle       = handle;\n    op->status       = GNTST_okay;\n\n    rcu_unlock_domain(rd);\n    return;\n\n undo_out:\n    if ( host_map_created )\n    {\n        replace_grant_host_mapping(op->host_addr, mfn, 0, op->flags);\n        gnttab_flush_tlb(ld);\n    }\n\n    while ( typecnt-- )\n        put_page_type(pg);\n\n    while ( refcnt-- )\n        put_page(pg);\n\n    grant_read_lock(rgt);\n\n    act = active_entry_acquire(rgt, op->ref);\n\n    if ( op->flags & GNTMAP_device_map )\n        act->pin -= (op->flags & GNTMAP_readonly) ?\n            GNTPIN_devr_inc : GNTPIN_devw_inc;\n    if ( op->flags & GNTMAP_host_map )\n        act->pin -= (op->flags & GNTMAP_readonly) ?\n            GNTPIN_hstr_inc : GNTPIN_hstw_inc;\n\n unlock_out_clear:\n    if ( !(op->flags & GNTMAP_readonly) &&\n         !(act->pin & (GNTPIN_hstw_mask|GNTPIN_devw_mask)) )\n        clear_flags |= GTF_writing;\n\n    if ( !act->pin )\n        clear_flags |= GTF_reading;\n\n    if ( clear_flags )\n        gnttab_clear_flags(rd, clear_flags, status);\n\n act_release_out:\n    active_entry_release(act);\n\n unlock_out:\n    grant_read_unlock(rgt);\n    op->status = rc;\n    put_maptrack_handle(lgt, handle);\n    rcu_unlock_domain(rd);\n}",
        "description": "An issue was discovered in Xen versions up to 4.13.x, where guest operating system users could trigger a denial of service due to an improper error handling mechanism in the GNTTABOP_map_grant operation. Grant table operations are supposed to return 0 for success and a negative number for errors; however, a coding mistake resulted in one error path returning 1 instead of a negative value. The grant table code in Linux interprets this as a successful operation and continues with incorrectly initialized state. A malicious or buggy guest could manipulate its grant table to exploit this flaw, causing a crash in the Linux-based dom0 or backend domain when a backend domain attempts to map a grant.",
        "commit": "A function within the Xen hypervisor, specifically related to mapping grant references, had its error handling logic inadvertently altered. This change caused the function to return an incorrect status code when a critical operation failed, leading to unexpected behavior in the Linux kernel's network and block device backends. This issue could result in system crashes due to improper handling of guest states."
    },
    {
        "cwe": "CWE-120",
        "func_name": "ClusterLabs/_blackbox_vlogger",
        "score": 0.772144079208374,
        "func_before": "static void\n_blackbox_vlogger(int32_t target,\n\t\t  struct qb_log_callsite *cs, struct timespec *timestamp, va_list ap)\n{\n\tsize_t max_size;\n\tsize_t actual_size;\n\tuint32_t fn_size;\n\tchar *chunk;\n\tchar *msg_len_pt;\n\tuint32_t msg_len;\n\tstruct qb_log_target *t = qb_log_target_get(target);\n\n\tif (t->instance == NULL) {\n\t\treturn;\n\t}\n\n\tfn_size = strlen(cs->function) + 1;\n\n\tactual_size = 4 * sizeof(uint32_t) + sizeof(uint8_t) + fn_size + sizeof(struct timespec);\n\tmax_size = actual_size + t->max_line_length;\n\n\tchunk = qb_rb_chunk_alloc(t->instance, max_size);\n\n\tif (chunk == NULL) {\n\t\t/* something bad has happened. abort blackbox logging */\n\t\tqb_util_perror(LOG_ERR, \"Blackbox allocation error, aborting blackbox log %s\", t->filename);\n\t\tqb_rb_close(qb_rb_lastref_and_ret(\n\t\t\t(struct qb_ringbuffer_s **) &t->instance\n\t\t));\n\t\treturn;\n\t}\n\n\t/* line number */\n\tmemcpy(chunk, &cs->lineno, sizeof(uint32_t));\n\tchunk += sizeof(uint32_t);\n\n\t/* tags */\n\tmemcpy(chunk, &cs->tags, sizeof(uint32_t));\n\tchunk += sizeof(uint32_t);\n\n\t/* log level/priority */\n\tmemcpy(chunk, &cs->priority, sizeof(uint8_t));\n\tchunk += sizeof(uint8_t);\n\n\t/* function name */\n\tmemcpy(chunk, &fn_size, sizeof(uint32_t));\n\tchunk += sizeof(uint32_t);\n\tmemcpy(chunk, cs->function, fn_size);\n\tchunk += fn_size;\n\n\t/* timestamp */\n\tmemcpy(chunk, timestamp, sizeof(struct timespec));\n\tchunk += sizeof(struct timespec);\n\n\t/* log message length */\n\tmsg_len_pt = chunk;\n\tchunk += sizeof(uint32_t);\n\n\t/* log message */\n\tmsg_len = qb_vsnprintf_serialize(chunk, max_size, cs->format, ap);\n\tif (msg_len >= max_size) {\n\t    chunk = msg_len_pt + sizeof(uint32_t); /* Reset */\n\n\t    /* Leave this at QB_LOG_MAX_LEN so as not to overflow the blackbox */\n\t    msg_len = qb_vsnprintf_serialize(chunk, QB_LOG_MAX_LEN,\n\t\t\"Log message too long to be stored in the blackbox.  \"\\\n\t\t\"Maximum is QB_LOG_MAX_LEN\" , ap);\n\t}\n\n\tactual_size += msg_len;\n\n\t/* now that we know the length, write it\n\t */\n\tmemcpy(msg_len_pt, &msg_len, sizeof(uint32_t));\n\n\t(void)qb_rb_chunk_commit(t->instance, actual_size);\n}",
        "func_after": "static void\n_blackbox_vlogger(int32_t target,\n\t\t  struct qb_log_callsite *cs, struct timespec *timestamp, va_list ap)\n{\n\tsize_t max_size;\n\tsize_t actual_size;\n\tuint32_t fn_size;\n\tchar *chunk;\n\tchar *msg_len_pt;\n\tuint32_t msg_len;\n\tstruct qb_log_target *t = qb_log_target_get(target);\n\n\tif (t->instance == NULL) {\n\t\treturn;\n\t}\n\n\tfn_size = strlen(cs->function) + 1;\n\n\tactual_size = 4 * sizeof(uint32_t) + sizeof(uint8_t) + fn_size + sizeof(struct timespec);\n\tmax_size = actual_size + t->max_line_length;\n\n\tchunk = qb_rb_chunk_alloc(t->instance, max_size);\n\n\tif (chunk == NULL) {\n\t\t/* something bad has happened. abort blackbox logging */\n\t\tqb_util_perror(LOG_ERR, \"Blackbox allocation error, aborting blackbox log %s\", t->filename);\n\t\tqb_rb_close(qb_rb_lastref_and_ret(\n\t\t\t(struct qb_ringbuffer_s **) &t->instance\n\t\t));\n\t\treturn;\n\t}\n\n\t/* line number */\n\tmemcpy(chunk, &cs->lineno, sizeof(uint32_t));\n\tchunk += sizeof(uint32_t);\n\n\t/* tags */\n\tmemcpy(chunk, &cs->tags, sizeof(uint32_t));\n\tchunk += sizeof(uint32_t);\n\n\t/* log level/priority */\n\tmemcpy(chunk, &cs->priority, sizeof(uint8_t));\n\tchunk += sizeof(uint8_t);\n\n\t/* function name */\n\tmemcpy(chunk, &fn_size, sizeof(uint32_t));\n\tchunk += sizeof(uint32_t);\n\tmemcpy(chunk, cs->function, fn_size);\n\tchunk += fn_size;\n\n\t/* timestamp */\n\tmemcpy(chunk, timestamp, sizeof(struct timespec));\n\tchunk += sizeof(struct timespec);\n\n\t/* log message length */\n\tmsg_len_pt = chunk;\n\tchunk += sizeof(uint32_t);\n\n\t/* log message */\n\tmsg_len = qb_vsnprintf_serialize(chunk, t->max_line_length, cs->format, ap);\n\tif (msg_len >= t->max_line_length) {\n\t    chunk = msg_len_pt + sizeof(uint32_t); /* Reset */\n\n\t    /* Leave this at QB_LOG_MAX_LEN so as not to overflow the blackbox */\n\t    msg_len = qb_vsnprintf_serialize(chunk, QB_LOG_MAX_LEN,\n\t\t\"Log message too long to be stored in the blackbox.  \"\\\n\t\t\"Maximum is QB_LOG_MAX_LEN\" , ap);\n\t}\n\n\tactual_size += msg_len;\n\n\t/* now that we know the length, write it\n\t */\n\tmemcpy(msg_len_pt, &msg_len, sizeof(uint32_t));\n\n\t(void)qb_rb_chunk_commit(t->instance, actual_size);\n}",
        "description": "log_blackbox.c in libqb prior to version 2.0.8 is susceptible to a buffer overflow due to the neglect of considering the header size when processing long log messages.",
        "commit": "The vulnerability knowledge has been abstracted and generalized as follows:\n\n\"A function responsible for serializing log messages potentially suffers from an overflow issue due to improper buffer size calculation. The original implementation used 'max_size' to limit the length of the formatted log message, but failed to account for the additional space required for the log header ('actual_size'). This oversight has been corrected by adjusting the maximum length parameter to 't->max_line_length', ensuring it accurately reflects the remaining buffer space. Additionally, error checks have been introduced to the blackbox calls at the end of the test to ensure proper functionality and to prevent masking of failures.\""
    }
]