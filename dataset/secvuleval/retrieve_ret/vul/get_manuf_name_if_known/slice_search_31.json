[
    {
        "cwe": "CWE-20",
        "func_name": "torvalds/make_indexed_dir",
        "score": 0.7971031665802002,
        "func_before": "static int make_indexed_dir(handle_t *handle, struct dentry *dentry,\n\t\t\t    struct inode *inode, struct buffer_head *bh)\n{\n\tstruct inode\t*dir = dentry->d_parent->d_inode;\n\tconst char\t*name = dentry->d_name.name;\n\tint\t\tnamelen = dentry->d_name.len;\n\tstruct buffer_head *bh2;\n\tstruct dx_root\t*root;\n\tstruct dx_frame\tframes[2], *frame;\n\tstruct dx_entry *entries;\n\tstruct ext4_dir_entry_2\t*de, *de2;\n\tchar\t\t*data1, *top;\n\tunsigned\tlen;\n\tint\t\tretval;\n\tunsigned\tblocksize;\n\tstruct dx_hash_info hinfo;\n\text4_lblk_t  block;\n\tstruct fake_dirent *fde;\n\n\tblocksize =  dir->i_sb->s_blocksize;\n\tdxtrace(printk(KERN_DEBUG \"Creating index\\n\"));\n\tretval = ext4_journal_get_write_access(handle, bh);\n\tif (retval) {\n\t\text4_std_error(dir->i_sb, retval);\n\t\tbrelse(bh);\n\t\treturn retval;\n\t}\n\troot = (struct dx_root *) bh->b_data;\n\n\tbh2 = ext4_append(handle, dir, &block, &retval);\n\tif (!(bh2)) {\n\t\tbrelse(bh);\n\t\treturn retval;\n\t}\n\tEXT4_I(dir)->i_flags |= EXT4_INDEX_FL;\n\tdata1 = bh2->b_data;\n\n\t/* The 0th block becomes the root, move the dirents out */\n\tfde = &root->dotdot;\n\tde = (struct ext4_dir_entry_2 *)((char *)fde +\n\t\text4_rec_len_from_disk(fde->rec_len));\n\tlen = ((char *) root) + blocksize - (char *) de;\n\tmemcpy (data1, de, len);\n\tde = (struct ext4_dir_entry_2 *) data1;\n\ttop = data1 + len;\n\twhile ((char *)(de2 = ext4_next_entry(de)) < top)\n\t\tde = de2;\n\tde->rec_len = ext4_rec_len_to_disk(data1 + blocksize - (char *) de);\n\t/* Initialize the root; the dot dirents already exist */\n\tde = (struct ext4_dir_entry_2 *) (&root->dotdot);\n\tde->rec_len = ext4_rec_len_to_disk(blocksize - EXT4_DIR_REC_LEN(2));\n\tmemset (&root->info, 0, sizeof(root->info));\n\troot->info.info_length = sizeof(root->info);\n\troot->info.hash_version = EXT4_SB(dir->i_sb)->s_def_hash_version;\n\tentries = root->entries;\n\tdx_set_block(entries, 1);\n\tdx_set_count(entries, 1);\n\tdx_set_limit(entries, dx_root_limit(dir, sizeof(root->info)));\n\n\t/* Initialize as for dx_probe */\n\thinfo.hash_version = root->info.hash_version;\n\tif (hinfo.hash_version <= DX_HASH_TEA)\n\t\thinfo.hash_version += EXT4_SB(dir->i_sb)->s_hash_unsigned;\n\thinfo.seed = EXT4_SB(dir->i_sb)->s_hash_seed;\n\text4fs_dirhash(name, namelen, &hinfo);\n\tframe = frames;\n\tframe->entries = entries;\n\tframe->at = entries;\n\tframe->bh = bh;\n\tbh = bh2;\n\tde = do_split(handle,dir, &bh, frame, &hinfo, &retval);\n\tdx_release (frames);\n\tif (!(de))\n\t\treturn retval;\n\n\treturn add_dirent_to_buf(handle, dentry, inode, de, bh);\n}",
        "func_after": "static int make_indexed_dir(handle_t *handle, struct dentry *dentry,\n\t\t\t    struct inode *inode, struct buffer_head *bh)\n{\n\tstruct inode\t*dir = dentry->d_parent->d_inode;\n\tconst char\t*name = dentry->d_name.name;\n\tint\t\tnamelen = dentry->d_name.len;\n\tstruct buffer_head *bh2;\n\tstruct dx_root\t*root;\n\tstruct dx_frame\tframes[2], *frame;\n\tstruct dx_entry *entries;\n\tstruct ext4_dir_entry_2\t*de, *de2;\n\tchar\t\t*data1, *top;\n\tunsigned\tlen;\n\tint\t\tretval;\n\tunsigned\tblocksize;\n\tstruct dx_hash_info hinfo;\n\text4_lblk_t  block;\n\tstruct fake_dirent *fde;\n\n\tblocksize =  dir->i_sb->s_blocksize;\n\tdxtrace(printk(KERN_DEBUG \"Creating index: inode %lu\\n\", dir->i_ino));\n\tretval = ext4_journal_get_write_access(handle, bh);\n\tif (retval) {\n\t\text4_std_error(dir->i_sb, retval);\n\t\tbrelse(bh);\n\t\treturn retval;\n\t}\n\troot = (struct dx_root *) bh->b_data;\n\n\t/* The 0th block becomes the root, move the dirents out */\n\tfde = &root->dotdot;\n\tde = (struct ext4_dir_entry_2 *)((char *)fde +\n\t\text4_rec_len_from_disk(fde->rec_len));\n\tif ((char *) de >= (((char *) root) + blocksize)) {\n\t\text4_error(dir->i_sb, __func__,\n\t\t\t   \"invalid rec_len for '..' in inode %lu\",\n\t\t\t   dir->i_ino);\n\t\tbrelse(bh);\n\t\treturn -EIO;\n\t}\n\tlen = ((char *) root) + blocksize - (char *) de;\n\n\t/* Allocate new block for the 0th block's dirents */\n\tbh2 = ext4_append(handle, dir, &block, &retval);\n\tif (!(bh2)) {\n\t\tbrelse(bh);\n\t\treturn retval;\n\t}\n\tEXT4_I(dir)->i_flags |= EXT4_INDEX_FL;\n\tdata1 = bh2->b_data;\n\n\tmemcpy (data1, de, len);\n\tde = (struct ext4_dir_entry_2 *) data1;\n\ttop = data1 + len;\n\twhile ((char *)(de2 = ext4_next_entry(de)) < top)\n\t\tde = de2;\n\tde->rec_len = ext4_rec_len_to_disk(data1 + blocksize - (char *) de);\n\t/* Initialize the root; the dot dirents already exist */\n\tde = (struct ext4_dir_entry_2 *) (&root->dotdot);\n\tde->rec_len = ext4_rec_len_to_disk(blocksize - EXT4_DIR_REC_LEN(2));\n\tmemset (&root->info, 0, sizeof(root->info));\n\troot->info.info_length = sizeof(root->info);\n\troot->info.hash_version = EXT4_SB(dir->i_sb)->s_def_hash_version;\n\tentries = root->entries;\n\tdx_set_block(entries, 1);\n\tdx_set_count(entries, 1);\n\tdx_set_limit(entries, dx_root_limit(dir, sizeof(root->info)));\n\n\t/* Initialize as for dx_probe */\n\thinfo.hash_version = root->info.hash_version;\n\tif (hinfo.hash_version <= DX_HASH_TEA)\n\t\thinfo.hash_version += EXT4_SB(dir->i_sb)->s_hash_unsigned;\n\thinfo.seed = EXT4_SB(dir->i_sb)->s_hash_seed;\n\text4fs_dirhash(name, namelen, &hinfo);\n\tframe = frames;\n\tframe->entries = entries;\n\tframe->at = entries;\n\tframe->bh = bh;\n\tbh = bh2;\n\tde = do_split(handle,dir, &bh, frame, &hinfo, &retval);\n\tdx_release (frames);\n\tif (!(de))\n\t\treturn retval;\n\n\treturn add_dirent_to_buf(handle, dentry, inode, de, bh);\n}",
        "description": "The `make_indexed_dir` function in the ext4 filesystem module of the Linux kernel, prior to versions 2.6.27.19 and 2.6.28.7, lacks validation for a specific `rec_len` field. This oversight enables local users to trigger a denial of service (OOPS) condition by mounting a specially crafted ext4 filesystem.",
        "commit": "It was discovered that a failure to validate the `rec_len` field in the '.' entry within a directory structure could lead to overrunning the directory block, resulting in a kernel panic on a deliberately corrupted filesystem."
    },
    {
        "cwe": "CWE-476",
        "func_name": "ImageMagick/LoadOpenCLDevices",
        "score": 0.7892711758613586,
        "func_before": "static void LoadOpenCLDevices(MagickCLEnv clEnv)\n{\n  cl_context_properties\n    properties[3];\n\n  cl_device_id\n    *devices;\n\n  cl_int\n    status;\n\n  cl_platform_id\n    *platforms;\n\n  cl_uint\n    i,\n    j,\n    next,\n    number_devices,\n    number_platforms;\n\n  size_t\n    length;\n\n  number_platforms=0;\n  if (openCL_library->clGetPlatformIDs(0,NULL,&number_platforms) != CL_SUCCESS)\n    return;\n  if (number_platforms == 0)\n    return;\n  platforms=(cl_platform_id *) AcquireMagickMemory(number_platforms*\n    sizeof(cl_platform_id));\n  if (platforms == (cl_platform_id *) NULL)\n    return;\n  if (openCL_library->clGetPlatformIDs(number_platforms,platforms,NULL) != CL_SUCCESS)\n    {\n       platforms=(cl_platform_id *) RelinquishMagickMemory(platforms);\n       return;\n    }\n  for (i = 0; i < number_platforms; i++)\n  {\n    number_devices=GetOpenCLDeviceCount(clEnv,platforms[i]);\n    if (number_devices == 0)\n      platforms[i]=(cl_platform_id) NULL;\n    else\n      clEnv->number_devices+=number_devices;\n  }\n  if (clEnv->number_devices == 0)\n    {\n      platforms=(cl_platform_id *) RelinquishMagickMemory(platforms);\n      return;\n    }\n  clEnv->devices=(MagickCLDevice *) AcquireQuantumMemory(clEnv->number_devices,\n    sizeof(MagickCLDevice));\n  if (clEnv->devices == (MagickCLDevice *) NULL)\n    {\n      RelinquishMagickCLDevices(clEnv);\n      platforms=(cl_platform_id *) RelinquishMagickMemory(platforms);\n      return;\n    }\n  (void) ResetMagickMemory(clEnv->devices,0,clEnv->number_devices*\n    sizeof(MagickCLDevice));\n  devices=(cl_device_id *) AcquireQuantumMemory(clEnv->number_devices,\n    sizeof(cl_device_id));\n  if (devices == (cl_device_id *) NULL)\n    {\n      platforms=(cl_platform_id *) RelinquishMagickMemory(platforms);\n      RelinquishMagickCLDevices(clEnv);\n      return;\n    }\n  clEnv->number_contexts=(size_t) number_platforms;\n  clEnv->contexts=(cl_context *) AcquireQuantumMemory(clEnv->number_contexts,\n    sizeof(cl_context));\n  if (clEnv->contexts == (cl_context *) NULL)\n    {\n      devices=(cl_device_id *) RelinquishMagickMemory(devices);\n      platforms=(cl_platform_id *) RelinquishMagickMemory(platforms);\n      RelinquishMagickCLDevices(clEnv);\n      return;\n    }\n  next=0;\n  for (i = 0; i < number_platforms; i++)\n  {\n    if (platforms[i] == (cl_platform_id) NULL)\n      continue;\n\n    status=clEnv->library->clGetDeviceIDs(platforms[i],CL_DEVICE_TYPE_CPU | \n      CL_DEVICE_TYPE_GPU,(cl_uint) clEnv->number_devices,devices,&number_devices);\n    if (status != CL_SUCCESS)\n      continue;\n\n    properties[0]=CL_CONTEXT_PLATFORM;\n    properties[1]=(cl_context_properties) platforms[i];\n    properties[2]=0;\n    clEnv->contexts[i]=openCL_library->clCreateContext(properties,number_devices,\n      devices,NULL,NULL,&status);\n    if (status != CL_SUCCESS)\n      continue;\n\n    for (j = 0; j < number_devices; j++,next++)\n    {\n      MagickCLDevice\n        device;\n\n      device=AcquireMagickCLDevice();\n      if (device == (MagickCLDevice) NULL)\n        break;\n\n      device->context=clEnv->contexts[i];\n      device->deviceID=devices[j];\n\n      openCL_library->clGetPlatformInfo(platforms[i],CL_PLATFORM_NAME,0,NULL,\n        &length);\n      device->platform_name=AcquireQuantumMemory(length,\n        sizeof(*device->platform_name));\n      openCL_library->clGetPlatformInfo(platforms[i],CL_PLATFORM_NAME,length,\n        device->platform_name,NULL);\n\n      openCL_library->clGetPlatformInfo(platforms[i],CL_PLATFORM_VENDOR,0,NULL,\n        &length);\n      device->vendor_name=AcquireQuantumMemory(length,\n        sizeof(*device->vendor_name));\n      openCL_library->clGetPlatformInfo(platforms[i],CL_PLATFORM_VENDOR,length,\n        device->vendor_name,NULL);\n\n      openCL_library->clGetDeviceInfo(devices[j],CL_DEVICE_NAME,0,NULL,\n        &length);\n      device->name=AcquireQuantumMemory(length,sizeof(*device->name));\n      openCL_library->clGetDeviceInfo(devices[j],CL_DEVICE_NAME,length,\n        device->name,NULL);\n\n      openCL_library->clGetDeviceInfo(devices[j],CL_DRIVER_VERSION,0,NULL,\n        &length);\n      device->version=AcquireQuantumMemory(length,sizeof(*device->version));\n      openCL_library->clGetDeviceInfo(devices[j],CL_DRIVER_VERSION,length,\n        device->version,NULL);\n\n      openCL_library->clGetDeviceInfo(devices[j],CL_DEVICE_MAX_CLOCK_FREQUENCY,\n        sizeof(cl_uint),&device->max_clock_frequency,NULL);\n\n      openCL_library->clGetDeviceInfo(devices[j],CL_DEVICE_MAX_COMPUTE_UNITS,\n        sizeof(cl_uint),&device->max_compute_units,NULL);\n\n      openCL_library->clGetDeviceInfo(devices[j],CL_DEVICE_TYPE,\n        sizeof(cl_device_type),&device->type,NULL);\n\n      openCL_library->clGetDeviceInfo(devices[j],CL_DEVICE_LOCAL_MEM_SIZE,\n        sizeof(cl_ulong),&device->local_memory_size,NULL);\n\n      clEnv->devices[next]=device;\n    }\n  }\n  if (next != clEnv->number_devices)\n    RelinquishMagickCLDevices(clEnv);\n  platforms=(cl_platform_id *) RelinquishMagickMemory(platforms);\n  devices=(cl_device_id *) RelinquishMagickMemory(devices);\n}",
        "func_after": "static void LoadOpenCLDevices(MagickCLEnv clEnv)\n{\n  cl_context_properties\n    properties[3];\n\n  cl_device_id\n    *devices;\n\n  cl_int\n    status;\n\n  cl_platform_id\n    *platforms;\n\n  cl_uint\n    i,\n    j,\n    next,\n    number_devices,\n    number_platforms;\n\n  size_t\n    length;\n\n  number_platforms=0;\n  if (openCL_library->clGetPlatformIDs(0,NULL,&number_platforms) != CL_SUCCESS)\n    return;\n  if (number_platforms == 0)\n    return;\n  platforms=(cl_platform_id *) AcquireMagickMemory(number_platforms*\n    sizeof(cl_platform_id));\n  if (platforms == (cl_platform_id *) NULL)\n    return;\n  if (openCL_library->clGetPlatformIDs(number_platforms,platforms,NULL) != CL_SUCCESS)\n    {\n       platforms=(cl_platform_id *) RelinquishMagickMemory(platforms);\n       return;\n    }\n  for (i = 0; i < number_platforms; i++)\n  {\n    number_devices=GetOpenCLDeviceCount(clEnv,platforms[i]);\n    if (number_devices == 0)\n      platforms[i]=(cl_platform_id) NULL;\n    else\n      clEnv->number_devices+=number_devices;\n  }\n  if (clEnv->number_devices == 0)\n    {\n      platforms=(cl_platform_id *) RelinquishMagickMemory(platforms);\n      return;\n    }\n  clEnv->devices=(MagickCLDevice *) AcquireQuantumMemory(clEnv->number_devices,\n    sizeof(MagickCLDevice));\n  if (clEnv->devices == (MagickCLDevice *) NULL)\n    {\n      RelinquishMagickCLDevices(clEnv);\n      platforms=(cl_platform_id *) RelinquishMagickMemory(platforms);\n      return;\n    }\n  (void) ResetMagickMemory(clEnv->devices,0,clEnv->number_devices*\n    sizeof(MagickCLDevice));\n  devices=(cl_device_id *) AcquireQuantumMemory(clEnv->number_devices,\n    sizeof(cl_device_id));\n  if (devices == (cl_device_id *) NULL)\n    {\n      platforms=(cl_platform_id *) RelinquishMagickMemory(platforms);\n      RelinquishMagickCLDevices(clEnv);\n      return;\n    }\n  clEnv->number_contexts=(size_t) number_platforms;\n  clEnv->contexts=(cl_context *) AcquireQuantumMemory(clEnv->number_contexts,\n    sizeof(cl_context));\n  if (clEnv->contexts == (cl_context *) NULL)\n    {\n      devices=(cl_device_id *) RelinquishMagickMemory(devices);\n      platforms=(cl_platform_id *) RelinquishMagickMemory(platforms);\n      RelinquishMagickCLDevices(clEnv);\n      return;\n    }\n  next=0;\n  for (i = 0; i < number_platforms; i++)\n  {\n    if (platforms[i] == (cl_platform_id) NULL)\n      continue;\n\n    status=clEnv->library->clGetDeviceIDs(platforms[i],CL_DEVICE_TYPE_CPU | \n      CL_DEVICE_TYPE_GPU,(cl_uint) clEnv->number_devices,devices,&number_devices);\n    if (status != CL_SUCCESS)\n      continue;\n\n    properties[0]=CL_CONTEXT_PLATFORM;\n    properties[1]=(cl_context_properties) platforms[i];\n    properties[2]=0;\n    clEnv->contexts[i]=openCL_library->clCreateContext(properties,number_devices,\n      devices,NULL,NULL,&status);\n    if (status != CL_SUCCESS)\n      continue;\n\n    for (j = 0; j < number_devices; j++,next++)\n    {\n      MagickCLDevice\n        device;\n\n      device=AcquireMagickCLDevice();\n      if (device == (MagickCLDevice) NULL)\n        break;\n\n      device->context=clEnv->contexts[i];\n      device->deviceID=devices[j];\n\n      openCL_library->clGetPlatformInfo(platforms[i],CL_PLATFORM_NAME,0,NULL,\n        &length);\n      device->platform_name=AcquireCriticalMemory(length*\n        sizeof(*device->platform_name));\n      openCL_library->clGetPlatformInfo(platforms[i],CL_PLATFORM_NAME,length,\n        device->platform_name,NULL);\n\n      openCL_library->clGetPlatformInfo(platforms[i],CL_PLATFORM_VENDOR,0,NULL,\n        &length);\n      device->vendor_name=AcquireQuantumMemory(length,\n        sizeof(*device->vendor_name));\n      openCL_library->clGetPlatformInfo(platforms[i],CL_PLATFORM_VENDOR,length,\n        device->vendor_name,NULL);\n\n      openCL_library->clGetDeviceInfo(devices[j],CL_DEVICE_NAME,0,NULL,\n        &length);\n      device->name=AcquireQuantumMemory(length,sizeof(*device->name));\n      openCL_library->clGetDeviceInfo(devices[j],CL_DEVICE_NAME,length,\n        device->name,NULL);\n\n      openCL_library->clGetDeviceInfo(devices[j],CL_DRIVER_VERSION,0,NULL,\n        &length);\n      device->version=AcquireQuantumMemory(length,sizeof(*device->version));\n      openCL_library->clGetDeviceInfo(devices[j],CL_DRIVER_VERSION,length,\n        device->version,NULL);\n\n      openCL_library->clGetDeviceInfo(devices[j],CL_DEVICE_MAX_CLOCK_FREQUENCY,\n        sizeof(cl_uint),&device->max_clock_frequency,NULL);\n\n      openCL_library->clGetDeviceInfo(devices[j],CL_DEVICE_MAX_COMPUTE_UNITS,\n        sizeof(cl_uint),&device->max_compute_units,NULL);\n\n      openCL_library->clGetDeviceInfo(devices[j],CL_DEVICE_TYPE,\n        sizeof(cl_device_type),&device->type,NULL);\n\n      openCL_library->clGetDeviceInfo(devices[j],CL_DEVICE_LOCAL_MEM_SIZE,\n        sizeof(cl_ulong),&device->local_memory_size,NULL);\n\n      clEnv->devices[next]=device;\n    }\n  }\n  if (next != clEnv->number_devices)\n    RelinquishMagickCLDevices(clEnv);\n  platforms=(cl_platform_id *) RelinquishMagickMemory(platforms);\n  devices=(cl_device_id *) RelinquishMagickMemory(devices);\n}",
        "description": "An issue was discovered in ImageMagick where a NULL pointer dereference vulnerability exists in the function responsible for loading OpenCL devices. This flaw allows attackers to trigger a denial of service through the use of a specially crafted file.",
        "commit": "It was discovered that ImageMagick, a popular image processing library, contains a vulnerability related to improper handling of certain image formats, potentially leading to buffer overflows or other memory corruption issues."
    },
    {
        "cwe": "CWE-345",
        "func_name": "xen-project/set_iommu_pde_present",
        "score": 0.7723833322525024,
        "func_before": "static unsigned int set_iommu_pde_present(struct amd_iommu_pte *pte,\n                                          unsigned long next_mfn,\n                                          unsigned int next_level, bool iw,\n                                          bool ir)\n{\n    unsigned int flush_flags = IOMMU_FLUSHF_added;\n\n    if ( pte->pr &&\n         (pte->mfn != next_mfn ||\n          pte->iw != iw ||\n          pte->ir != ir ||\n          pte->next_level != next_level) )\n            flush_flags |= IOMMU_FLUSHF_modified;\n\n    /*\n     * FC bit should be enabled in PTE, this helps to solve potential\n     * issues with ATS devices\n     */\n    pte->fc = !next_level;\n\n    pte->mfn = next_mfn;\n    pte->iw = iw;\n    pte->ir = ir;\n    pte->next_level = next_level;\n    pte->pr = 1;\n\n    return flush_flags;\n}",
        "func_after": "static unsigned int set_iommu_pde_present(union amd_iommu_pte *pte,\n                                          unsigned long next_mfn,\n                                          unsigned int next_level, bool iw,\n                                          bool ir)\n{\n    unsigned int flush_flags = IOMMU_FLUSHF_added;\n\n    if ( pte->pr &&\n         (pte->mfn != next_mfn ||\n          pte->iw != iw ||\n          pte->ir != ir ||\n          pte->next_level != next_level) )\n            flush_flags |= IOMMU_FLUSHF_modified;\n\n    /*\n     * FC bit should be enabled in PTE, this helps to solve potential\n     * issues with ATS devices\n     */\n    pte->fc = !next_level;\n\n    pte->mfn = next_mfn;\n    pte->iw = iw;\n    pte->ir = ir;\n    pte->next_level = next_level;\n    pte->pr = 1;\n\n    return flush_flags;\n}",
        "description": "An issue was discovered in Xen versions up to 4.14.x, where x86 guest operating system users could potentially cause a denial of service through data corruption, lead to a data leak, or escalate privileges by exploiting a condition where an AMD IOMMU page-table entry is partially updated.",
        "commit": "Updating live Page Table Entries (PTEs) atomically is crucial to prevent issues related to compiler reordering and partial updates. The vulnerability arises when updating PTEs bit by bit, which can lead to the compiler rearranging these updates or splitting them into multiple memory writes. To mitigate this, it is recommended to construct the new PTE entry entirely in a local variable, perform the necessary checks based on this complete entry, and then write the new entry in a single instruction. Additionally, using functions like `memset()` to clear PTEs is unsafe because the order of writes is undefined, potentially leading to incomplete or incorrect clearing of the PTE. This issue is part of XSA-347."
    },
    {
        "cwe": "CWE-78",
        "func_name": "shadowsocks/construct_command_line",
        "score": 0.7892439961433411,
        "func_before": "static char *\nconstruct_command_line(struct manager_ctx *manager, struct server *server)\n{\n    static char cmd[BUF_SIZE];\n    char *method = manager->method;\n    int i;\n\n    build_config(working_dir, server);\n\n    if (server->method) method = server->method;\n    memset(cmd, 0, BUF_SIZE);\n    snprintf(cmd, BUF_SIZE,\n             \"%s -m %s --manager-address %s -f %s/.shadowsocks_%s.pid -c %s/.shadowsocks_%s.conf\",\n             executable, method, manager->manager_address,\n             working_dir, server->port, working_dir, server->port);\n\n    if (manager->acl != NULL) {\n        int len = strlen(cmd);\n        snprintf(cmd + len, BUF_SIZE - len, \" --acl %s\", manager->acl);\n    }\n    if (manager->timeout != NULL) {\n        int len = strlen(cmd);\n        snprintf(cmd + len, BUF_SIZE - len, \" -t %s\", manager->timeout);\n    }\n#ifdef HAVE_SETRLIMIT\n    if (manager->nofile) {\n        int len = strlen(cmd);\n        snprintf(cmd + len, BUF_SIZE - len, \" -n %d\", manager->nofile);\n    }\n#endif\n    if (manager->user != NULL) {\n        int len = strlen(cmd);\n        snprintf(cmd + len, BUF_SIZE - len, \" -a %s\", manager->user);\n    }\n    if (manager->verbose) {\n        int len = strlen(cmd);\n        snprintf(cmd + len, BUF_SIZE - len, \" -v\");\n    }\n    if (server->mode == NULL && manager->mode == UDP_ONLY) {\n        int len = strlen(cmd);\n        snprintf(cmd + len, BUF_SIZE - len, \" -U\");\n    }\n    if (server->mode == NULL && manager->mode == TCP_AND_UDP) {\n        int len = strlen(cmd);\n        snprintf(cmd + len, BUF_SIZE - len, \" -u\");\n    }\n    if (server->fast_open[0] == 0 && manager->fast_open) {\n        int len = strlen(cmd);\n        snprintf(cmd + len, BUF_SIZE - len, \" --fast-open\");\n    }\n    if (manager->ipv6first) {\n        int len = strlen(cmd);\n        snprintf(cmd + len, BUF_SIZE - len, \" -6\");\n    }\n    if (manager->mtu) {\n        int len = strlen(cmd);\n        snprintf(cmd + len, BUF_SIZE - len, \" --mtu %d\", manager->mtu);\n    }\n    if (server->plugin == NULL && manager->plugin) {\n        int len = strlen(cmd);\n        snprintf(cmd + len, BUF_SIZE - len, \" --plugin \\\"%s\\\"\", manager->plugin);\n    }\n    if (server->plugin_opts == NULL && manager->plugin_opts) {\n        int len = strlen(cmd);\n        snprintf(cmd + len, BUF_SIZE - len, \" --plugin-opts \\\"%s\\\"\", manager->plugin_opts);\n    }\n    for (i = 0; i < manager->nameserver_num; i++) {\n        int len = strlen(cmd);\n        snprintf(cmd + len, BUF_SIZE - len, \" -d %s\", manager->nameservers[i]);\n    }\n    for (i = 0; i < manager->host_num; i++) {\n        int len = strlen(cmd);\n        snprintf(cmd + len, BUF_SIZE - len, \" -s %s\", manager->hosts[i]);\n    }\n    // Always enable reuse port\n    {\n        int len = strlen(cmd);\n        snprintf(cmd + len, BUF_SIZE - len, \" --reuse-port\");\n    }\n\n    if (verbose) {\n        LOGI(\"cmd: %s\", cmd);\n    }\n\n    return cmd;\n}",
        "func_after": "static char *\nconstruct_command_line(struct manager_ctx *manager, struct server *server)\n{\n    static char cmd[BUF_SIZE];\n    int i;\n    int port;\n\n    port = atoi(server->port);\n\n    build_config(working_dir, manager, server);\n\n    memset(cmd, 0, BUF_SIZE);\n    snprintf(cmd, BUF_SIZE,\n             \"%s --manager-address %s -f %s/.shadowsocks_%d.pid -c %s/.shadowsocks_%d.conf\",\n             executable, manager->manager_address, working_dir, port, working_dir, port);\n\n    if (manager->acl != NULL) {\n        int len = strlen(cmd);\n        snprintf(cmd + len, BUF_SIZE - len, \" --acl %s\", manager->acl);\n    }\n    if (manager->timeout != NULL) {\n        int len = strlen(cmd);\n        snprintf(cmd + len, BUF_SIZE - len, \" -t %s\", manager->timeout);\n    }\n#ifdef HAVE_SETRLIMIT\n    if (manager->nofile) {\n        int len = strlen(cmd);\n        snprintf(cmd + len, BUF_SIZE - len, \" -n %d\", manager->nofile);\n    }\n#endif\n    if (manager->user != NULL) {\n        int len = strlen(cmd);\n        snprintf(cmd + len, BUF_SIZE - len, \" -a %s\", manager->user);\n    }\n    if (manager->verbose) {\n        int len = strlen(cmd);\n        snprintf(cmd + len, BUF_SIZE - len, \" -v\");\n    }\n    if (server->mode == NULL && manager->mode == UDP_ONLY) {\n        int len = strlen(cmd);\n        snprintf(cmd + len, BUF_SIZE - len, \" -U\");\n    }\n    if (server->mode == NULL && manager->mode == TCP_AND_UDP) {\n        int len = strlen(cmd);\n        snprintf(cmd + len, BUF_SIZE - len, \" -u\");\n    }\n    if (server->fast_open[0] == 0 && manager->fast_open) {\n        int len = strlen(cmd);\n        snprintf(cmd + len, BUF_SIZE - len, \" --fast-open\");\n    }\n    if (manager->ipv6first) {\n        int len = strlen(cmd);\n        snprintf(cmd + len, BUF_SIZE - len, \" -6\");\n    }\n    if (manager->mtu) {\n        int len = strlen(cmd);\n        snprintf(cmd + len, BUF_SIZE - len, \" --mtu %d\", manager->mtu);\n    }\n    if (server->plugin == NULL && manager->plugin) {\n        int len = strlen(cmd);\n        snprintf(cmd + len, BUF_SIZE - len, \" --plugin \\\"%s\\\"\", manager->plugin);\n    }\n    if (server->plugin_opts == NULL && manager->plugin_opts) {\n        int len = strlen(cmd);\n        snprintf(cmd + len, BUF_SIZE - len, \" --plugin-opts \\\"%s\\\"\", manager->plugin_opts);\n    }\n    for (i = 0; i < manager->nameserver_num; i++) {\n        int len = strlen(cmd);\n        snprintf(cmd + len, BUF_SIZE - len, \" -d %s\", manager->nameservers[i]);\n    }\n    for (i = 0; i < manager->host_num; i++) {\n        int len = strlen(cmd);\n        snprintf(cmd + len, BUF_SIZE - len, \" -s %s\", manager->hosts[i]);\n    }\n    // Always enable reuse port\n    {\n        int len = strlen(cmd);\n        snprintf(cmd + len, BUF_SIZE - len, \" --reuse-port\");\n    }\n\n    if (verbose) {\n        LOGI(\"cmd: %s\", cmd);\n    }\n\n    return cmd;\n}",
        "description": "In the `ss-manager` component of the Shadowsocks-libev library version 3.1.0, there exists a vulnerability due to improper parsing of JSON configuration requests received via UDP traffic on `127.0.0.1`. This issue facilitates command injection through the use of shell metacharacters. The vulnerability is associated with functions such as `add_server`, `build_config`, and `construct_command_line`.",
        "commit": "<Abstracted Description begin>\nA fix has been implemented to address an unspecified issue identified by ticket number 1734.\n<Abstracted Description end>"
    },
    {
        "cwe": "CWE-670",
        "func_name": "xen-project/port_is_valid",
        "score": 0.7502231597900391,
        "func_before": "static inline bool_t port_is_valid(struct domain *d, unsigned int p)\n{\n    return p < read_atomic(&d->valid_evtchns);\n}",
        "func_after": "static inline bool_t port_is_valid(struct domain *d, unsigned int p)\n{\n    if ( p >= read_atomic(&d->valid_evtchns) )\n        return false;\n\n    /*\n     * The caller will usually access the event channel afterwards and\n     * may be done without taking the per-domain lock. The barrier is\n     * going in pair the smp_wmb() barrier in evtchn_allocate_port().\n     */\n    smp_rmb();\n\n    return true;\n}",
        "description": "An issue was discovered in Xen through version 4.14.x, where memory barriers are absent during the access or allocation of event channels. Event channels control structures can be accessed without locks as long as the port is deemed valid. However, the absence of an appropriate memory barrier (such as smp_*mb()) allows the compiler and CPU to reorder memory accesses. This could enable a malicious guest to trigger a hypervisor crash, leading to a Denial of Service (DoS). Additionally, information leaks and privilege escalations cannot be ruled out. The vulnerability affects all versions of Xen, with the likelihood of exploitation depending on the CPU and compiler used to build Xen. The exact impact varies based on the compiler's code generation options and the CPU's ability to reorder memory accesses. It is recommended to consult the CPU vendor for guidance on potential vulnerabilities on Arm systems, while x86 systems are only vulnerable if a compiler performs reordering.",
        "commit": "It was discovered that the Xen hypervisor's event channel management lacked appropriate memory barriers during both allocation and access operations. Specifically, while the allocation of an event channel bucket is protected by a per-domain lock, accessing the bucket can occur without the lock being held, relying instead on the `port_is_valid()` function to ensure the port has an associated structure. However, due to potential compiler and processor reordering of memory accesses, there is a risk that updates to `d->valid_evtchns` could occur before the new bucket is fully allocated. To mitigate this issue, memory barriers were added: a write memory barrier during allocation and a read memory barrier when checking if the port is valid. This addresses a reordering problem that could lead to unintended behavior."
    }
]