[
    {
        "cwe": "CWE-665",
        "func_name": "torvalds/__skb_flow_dissect",
        "score": 0.7703654766082764,
        "func_before": "bool __skb_flow_dissect(const struct sk_buff *skb,\n\t\t\tstruct flow_dissector *flow_dissector,\n\t\t\tvoid *target_container,\n\t\t\tvoid *data, __be16 proto, int nhoff, int hlen)\n{\n\tstruct flow_dissector_key_control *key_control;\n\tstruct flow_dissector_key_basic *key_basic;\n\tstruct flow_dissector_key_addrs *key_addrs;\n\tstruct flow_dissector_key_ports *key_ports;\n\tstruct flow_dissector_key_tags *key_tags;\n\tstruct flow_dissector_key_keyid *key_keyid;\n\tu8 ip_proto = 0;\n\n\tif (!data) {\n\t\tdata = skb->data;\n\t\tproto = skb->protocol;\n\t\tnhoff = skb_network_offset(skb);\n\t\thlen = skb_headlen(skb);\n\t}\n\n\t/* It is ensured by skb_flow_dissector_init() that control key will\n\t * be always present.\n\t */\n\tkey_control = skb_flow_dissector_target(flow_dissector,\n\t\t\t\t\t\tFLOW_DISSECTOR_KEY_CONTROL,\n\t\t\t\t\t\ttarget_container);\n\n\t/* It is ensured by skb_flow_dissector_init() that basic key will\n\t * be always present.\n\t */\n\tkey_basic = skb_flow_dissector_target(flow_dissector,\n\t\t\t\t\t      FLOW_DISSECTOR_KEY_BASIC,\n\t\t\t\t\t      target_container);\n\n\tif (skb_flow_dissector_uses_key(flow_dissector,\n\t\t\t\t\tFLOW_DISSECTOR_KEY_ETH_ADDRS)) {\n\t\tstruct ethhdr *eth = eth_hdr(skb);\n\t\tstruct flow_dissector_key_eth_addrs *key_eth_addrs;\n\n\t\tkey_eth_addrs = skb_flow_dissector_target(flow_dissector,\n\t\t\t\t\t\t\t  FLOW_DISSECTOR_KEY_ETH_ADDRS,\n\t\t\t\t\t\t\t  target_container);\n\t\tmemcpy(key_eth_addrs, &eth->h_dest, sizeof(*key_eth_addrs));\n\t}\n\nagain:\n\tswitch (proto) {\n\tcase htons(ETH_P_IP): {\n\t\tconst struct iphdr *iph;\n\t\tstruct iphdr _iph;\nip:\n\t\tiph = __skb_header_pointer(skb, nhoff, sizeof(_iph), data, hlen, &_iph);\n\t\tif (!iph || iph->ihl < 5)\n\t\t\treturn false;\n\t\tnhoff += iph->ihl * 4;\n\n\t\tip_proto = iph->protocol;\n\t\tif (ip_is_fragment(iph))\n\t\t\tip_proto = 0;\n\n\t\tif (!skb_flow_dissector_uses_key(flow_dissector,\n\t\t\t\t\t\t FLOW_DISSECTOR_KEY_IPV4_ADDRS))\n\t\t\tbreak;\n\n\t\tkey_addrs = skb_flow_dissector_target(flow_dissector,\n\t\t\t      FLOW_DISSECTOR_KEY_IPV4_ADDRS, target_container);\n\t\tmemcpy(&key_addrs->v4addrs, &iph->saddr,\n\t\t       sizeof(key_addrs->v4addrs));\n\t\tkey_control->addr_type = FLOW_DISSECTOR_KEY_IPV4_ADDRS;\n\t\tbreak;\n\t}\n\tcase htons(ETH_P_IPV6): {\n\t\tconst struct ipv6hdr *iph;\n\t\tstruct ipv6hdr _iph;\n\t\t__be32 flow_label;\n\nipv6:\n\t\tiph = __skb_header_pointer(skb, nhoff, sizeof(_iph), data, hlen, &_iph);\n\t\tif (!iph)\n\t\t\treturn false;\n\n\t\tip_proto = iph->nexthdr;\n\t\tnhoff += sizeof(struct ipv6hdr);\n\n\t\tif (skb_flow_dissector_uses_key(flow_dissector,\n\t\t\t\t\t\tFLOW_DISSECTOR_KEY_IPV6_ADDRS)) {\n\t\t\tstruct flow_dissector_key_ipv6_addrs *key_ipv6_addrs;\n\n\t\t\tkey_ipv6_addrs = skb_flow_dissector_target(flow_dissector,\n\t\t\t\t\t\t\t\t   FLOW_DISSECTOR_KEY_IPV6_ADDRS,\n\t\t\t\t\t\t\t\t   target_container);\n\n\t\t\tmemcpy(key_ipv6_addrs, &iph->saddr, sizeof(*key_ipv6_addrs));\n\t\t\tkey_control->addr_type = FLOW_DISSECTOR_KEY_IPV6_ADDRS;\n\t\t}\n\n\t\tflow_label = ip6_flowlabel(iph);\n\t\tif (flow_label) {\n\t\t\tif (skb_flow_dissector_uses_key(flow_dissector,\n\t\t\t\tFLOW_DISSECTOR_KEY_FLOW_LABEL)) {\n\t\t\t\tkey_tags = skb_flow_dissector_target(flow_dissector,\n\t\t\t\t\t\t\t\t     FLOW_DISSECTOR_KEY_FLOW_LABEL,\n\t\t\t\t\t\t\t\t     target_container);\n\t\t\t\tkey_tags->flow_label = ntohl(flow_label);\n\t\t\t}\n\t\t}\n\n\t\tbreak;\n\t}\n\tcase htons(ETH_P_8021AD):\n\tcase htons(ETH_P_8021Q): {\n\t\tconst struct vlan_hdr *vlan;\n\t\tstruct vlan_hdr _vlan;\n\n\t\tvlan = __skb_header_pointer(skb, nhoff, sizeof(_vlan), data, hlen, &_vlan);\n\t\tif (!vlan)\n\t\t\treturn false;\n\n\t\tif (skb_flow_dissector_uses_key(flow_dissector,\n\t\t\t\t\t\tFLOW_DISSECTOR_KEY_VLANID)) {\n\t\t\tkey_tags = skb_flow_dissector_target(flow_dissector,\n\t\t\t\t\t\t\t     FLOW_DISSECTOR_KEY_VLANID,\n\t\t\t\t\t\t\t     target_container);\n\n\t\t\tkey_tags->vlan_id = skb_vlan_tag_get_id(skb);\n\t\t}\n\n\t\tproto = vlan->h_vlan_encapsulated_proto;\n\t\tnhoff += sizeof(*vlan);\n\t\tgoto again;\n\t}\n\tcase htons(ETH_P_PPP_SES): {\n\t\tstruct {\n\t\t\tstruct pppoe_hdr hdr;\n\t\t\t__be16 proto;\n\t\t} *hdr, _hdr;\n\t\thdr = __skb_header_pointer(skb, nhoff, sizeof(_hdr), data, hlen, &_hdr);\n\t\tif (!hdr)\n\t\t\treturn false;\n\t\tproto = hdr->proto;\n\t\tnhoff += PPPOE_SES_HLEN;\n\t\tswitch (proto) {\n\t\tcase htons(PPP_IP):\n\t\t\tgoto ip;\n\t\tcase htons(PPP_IPV6):\n\t\t\tgoto ipv6;\n\t\tdefault:\n\t\t\treturn false;\n\t\t}\n\t}\n\tcase htons(ETH_P_TIPC): {\n\t\tstruct {\n\t\t\t__be32 pre[3];\n\t\t\t__be32 srcnode;\n\t\t} *hdr, _hdr;\n\t\thdr = __skb_header_pointer(skb, nhoff, sizeof(_hdr), data, hlen, &_hdr);\n\t\tif (!hdr)\n\t\t\treturn false;\n\t\tkey_basic->n_proto = proto;\n\t\tkey_control->thoff = (u16)nhoff;\n\n\t\tif (skb_flow_dissector_uses_key(flow_dissector,\n\t\t\t\t\t\tFLOW_DISSECTOR_KEY_TIPC_ADDRS)) {\n\t\t\tkey_addrs = skb_flow_dissector_target(flow_dissector,\n\t\t\t\t\t\t\t      FLOW_DISSECTOR_KEY_TIPC_ADDRS,\n\t\t\t\t\t\t\t      target_container);\n\t\t\tkey_addrs->tipcaddrs.srcnode = hdr->srcnode;\n\t\t\tkey_control->addr_type = FLOW_DISSECTOR_KEY_TIPC_ADDRS;\n\t\t}\n\t\treturn true;\n\t}\n\n\tcase htons(ETH_P_MPLS_UC):\n\tcase htons(ETH_P_MPLS_MC): {\n\t\tstruct mpls_label *hdr, _hdr[2];\nmpls:\n\t\thdr = __skb_header_pointer(skb, nhoff, sizeof(_hdr), data,\n\t\t\t\t\t   hlen, &_hdr);\n\t\tif (!hdr)\n\t\t\treturn false;\n\n\t\tif ((ntohl(hdr[0].entry) & MPLS_LS_LABEL_MASK) >>\n\t\t     MPLS_LS_LABEL_SHIFT == MPLS_LABEL_ENTROPY) {\n\t\t\tif (skb_flow_dissector_uses_key(flow_dissector,\n\t\t\t\t\t\t\tFLOW_DISSECTOR_KEY_MPLS_ENTROPY)) {\n\t\t\t\tkey_keyid = skb_flow_dissector_target(flow_dissector,\n\t\t\t\t\t\t\t\t      FLOW_DISSECTOR_KEY_MPLS_ENTROPY,\n\t\t\t\t\t\t\t\t      target_container);\n\t\t\t\tkey_keyid->keyid = hdr[1].entry &\n\t\t\t\t\thtonl(MPLS_LS_LABEL_MASK);\n\t\t\t}\n\n\t\t\tkey_basic->n_proto = proto;\n\t\t\tkey_basic->ip_proto = ip_proto;\n\t\t\tkey_control->thoff = (u16)nhoff;\n\n\t\t\treturn true;\n\t\t}\n\n\t\treturn true;\n\t}\n\n\tcase htons(ETH_P_FCOE):\n\t\tkey_control->thoff = (u16)(nhoff + FCOE_HEADER_LEN);\n\t\t/* fall through */\n\tdefault:\n\t\treturn false;\n\t}\n\nip_proto_again:\n\tswitch (ip_proto) {\n\tcase IPPROTO_GRE: {\n\t\tstruct gre_hdr {\n\t\t\t__be16 flags;\n\t\t\t__be16 proto;\n\t\t} *hdr, _hdr;\n\n\t\thdr = __skb_header_pointer(skb, nhoff, sizeof(_hdr), data, hlen, &_hdr);\n\t\tif (!hdr)\n\t\t\treturn false;\n\t\t/*\n\t\t * Only look inside GRE if version zero and no\n\t\t * routing\n\t\t */\n\t\tif (hdr->flags & (GRE_VERSION | GRE_ROUTING))\n\t\t\tbreak;\n\n\t\tproto = hdr->proto;\n\t\tnhoff += 4;\n\t\tif (hdr->flags & GRE_CSUM)\n\t\t\tnhoff += 4;\n\t\tif (hdr->flags & GRE_KEY) {\n\t\t\tconst __be32 *keyid;\n\t\t\t__be32 _keyid;\n\n\t\t\tkeyid = __skb_header_pointer(skb, nhoff, sizeof(_keyid),\n\t\t\t\t\t\t     data, hlen, &_keyid);\n\n\t\t\tif (!keyid)\n\t\t\t\treturn false;\n\n\t\t\tif (skb_flow_dissector_uses_key(flow_dissector,\n\t\t\t\t\t\t\tFLOW_DISSECTOR_KEY_GRE_KEYID)) {\n\t\t\t\tkey_keyid = skb_flow_dissector_target(flow_dissector,\n\t\t\t\t\t\t\t\t      FLOW_DISSECTOR_KEY_GRE_KEYID,\n\t\t\t\t\t\t\t\t      target_container);\n\t\t\t\tkey_keyid->keyid = *keyid;\n\t\t\t}\n\t\t\tnhoff += 4;\n\t\t}\n\t\tif (hdr->flags & GRE_SEQ)\n\t\t\tnhoff += 4;\n\t\tif (proto == htons(ETH_P_TEB)) {\n\t\t\tconst struct ethhdr *eth;\n\t\t\tstruct ethhdr _eth;\n\n\t\t\teth = __skb_header_pointer(skb, nhoff,\n\t\t\t\t\t\t   sizeof(_eth),\n\t\t\t\t\t\t   data, hlen, &_eth);\n\t\t\tif (!eth)\n\t\t\t\treturn false;\n\t\t\tproto = eth->h_proto;\n\t\t\tnhoff += sizeof(*eth);\n\t\t}\n\t\tgoto again;\n\t}\n\tcase NEXTHDR_HOP:\n\tcase NEXTHDR_ROUTING:\n\tcase NEXTHDR_DEST: {\n\t\tu8 _opthdr[2], *opthdr;\n\n\t\tif (proto != htons(ETH_P_IPV6))\n\t\t\tbreak;\n\n\t\topthdr = __skb_header_pointer(skb, nhoff, sizeof(_opthdr),\n\t\t\t\t\t      data, hlen, &_opthdr);\n\t\tif (!opthdr)\n\t\t\treturn false;\n\n\t\tip_proto = opthdr[0];\n\t\tnhoff += (opthdr[1] + 1) << 3;\n\n\t\tgoto ip_proto_again;\n\t}\n\tcase IPPROTO_IPIP:\n\t\tproto = htons(ETH_P_IP);\n\t\tgoto ip;\n\tcase IPPROTO_IPV6:\n\t\tproto = htons(ETH_P_IPV6);\n\t\tgoto ipv6;\n\tcase IPPROTO_MPLS:\n\t\tproto = htons(ETH_P_MPLS_UC);\n\t\tgoto mpls;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tkey_basic->n_proto = proto;\n\tkey_basic->ip_proto = ip_proto;\n\tkey_control->thoff = (u16)nhoff;\n\n\tif (skb_flow_dissector_uses_key(flow_dissector,\n\t\t\t\t\tFLOW_DISSECTOR_KEY_PORTS)) {\n\t\tkey_ports = skb_flow_dissector_target(flow_dissector,\n\t\t\t\t\t\t      FLOW_DISSECTOR_KEY_PORTS,\n\t\t\t\t\t\t      target_container);\n\t\tkey_ports->ports = __skb_flow_get_ports(skb, nhoff, ip_proto,\n\t\t\t\t\t\t\tdata, hlen);\n\t}\n\n\treturn true;\n}",
        "func_after": "bool __skb_flow_dissect(const struct sk_buff *skb,\n\t\t\tstruct flow_dissector *flow_dissector,\n\t\t\tvoid *target_container,\n\t\t\tvoid *data, __be16 proto, int nhoff, int hlen)\n{\n\tstruct flow_dissector_key_control *key_control;\n\tstruct flow_dissector_key_basic *key_basic;\n\tstruct flow_dissector_key_addrs *key_addrs;\n\tstruct flow_dissector_key_ports *key_ports;\n\tstruct flow_dissector_key_tags *key_tags;\n\tstruct flow_dissector_key_keyid *key_keyid;\n\tu8 ip_proto = 0;\n\tbool ret = false;\n\n\tif (!data) {\n\t\tdata = skb->data;\n\t\tproto = skb->protocol;\n\t\tnhoff = skb_network_offset(skb);\n\t\thlen = skb_headlen(skb);\n\t}\n\n\t/* It is ensured by skb_flow_dissector_init() that control key will\n\t * be always present.\n\t */\n\tkey_control = skb_flow_dissector_target(flow_dissector,\n\t\t\t\t\t\tFLOW_DISSECTOR_KEY_CONTROL,\n\t\t\t\t\t\ttarget_container);\n\n\t/* It is ensured by skb_flow_dissector_init() that basic key will\n\t * be always present.\n\t */\n\tkey_basic = skb_flow_dissector_target(flow_dissector,\n\t\t\t\t\t      FLOW_DISSECTOR_KEY_BASIC,\n\t\t\t\t\t      target_container);\n\n\tif (skb_flow_dissector_uses_key(flow_dissector,\n\t\t\t\t\tFLOW_DISSECTOR_KEY_ETH_ADDRS)) {\n\t\tstruct ethhdr *eth = eth_hdr(skb);\n\t\tstruct flow_dissector_key_eth_addrs *key_eth_addrs;\n\n\t\tkey_eth_addrs = skb_flow_dissector_target(flow_dissector,\n\t\t\t\t\t\t\t  FLOW_DISSECTOR_KEY_ETH_ADDRS,\n\t\t\t\t\t\t\t  target_container);\n\t\tmemcpy(key_eth_addrs, &eth->h_dest, sizeof(*key_eth_addrs));\n\t}\n\nagain:\n\tswitch (proto) {\n\tcase htons(ETH_P_IP): {\n\t\tconst struct iphdr *iph;\n\t\tstruct iphdr _iph;\nip:\n\t\tiph = __skb_header_pointer(skb, nhoff, sizeof(_iph), data, hlen, &_iph);\n\t\tif (!iph || iph->ihl < 5)\n\t\t\tgoto out_bad;\n\t\tnhoff += iph->ihl * 4;\n\n\t\tip_proto = iph->protocol;\n\t\tif (ip_is_fragment(iph))\n\t\t\tip_proto = 0;\n\n\t\tif (!skb_flow_dissector_uses_key(flow_dissector,\n\t\t\t\t\t\t FLOW_DISSECTOR_KEY_IPV4_ADDRS))\n\t\t\tbreak;\n\n\t\tkey_addrs = skb_flow_dissector_target(flow_dissector,\n\t\t\t      FLOW_DISSECTOR_KEY_IPV4_ADDRS, target_container);\n\t\tmemcpy(&key_addrs->v4addrs, &iph->saddr,\n\t\t       sizeof(key_addrs->v4addrs));\n\t\tkey_control->addr_type = FLOW_DISSECTOR_KEY_IPV4_ADDRS;\n\t\tbreak;\n\t}\n\tcase htons(ETH_P_IPV6): {\n\t\tconst struct ipv6hdr *iph;\n\t\tstruct ipv6hdr _iph;\n\t\t__be32 flow_label;\n\nipv6:\n\t\tiph = __skb_header_pointer(skb, nhoff, sizeof(_iph), data, hlen, &_iph);\n\t\tif (!iph)\n\t\t\tgoto out_bad;\n\n\t\tip_proto = iph->nexthdr;\n\t\tnhoff += sizeof(struct ipv6hdr);\n\n\t\tif (skb_flow_dissector_uses_key(flow_dissector,\n\t\t\t\t\t\tFLOW_DISSECTOR_KEY_IPV6_ADDRS)) {\n\t\t\tstruct flow_dissector_key_ipv6_addrs *key_ipv6_addrs;\n\n\t\t\tkey_ipv6_addrs = skb_flow_dissector_target(flow_dissector,\n\t\t\t\t\t\t\t\t   FLOW_DISSECTOR_KEY_IPV6_ADDRS,\n\t\t\t\t\t\t\t\t   target_container);\n\n\t\t\tmemcpy(key_ipv6_addrs, &iph->saddr, sizeof(*key_ipv6_addrs));\n\t\t\tkey_control->addr_type = FLOW_DISSECTOR_KEY_IPV6_ADDRS;\n\t\t}\n\n\t\tflow_label = ip6_flowlabel(iph);\n\t\tif (flow_label) {\n\t\t\tif (skb_flow_dissector_uses_key(flow_dissector,\n\t\t\t\tFLOW_DISSECTOR_KEY_FLOW_LABEL)) {\n\t\t\t\tkey_tags = skb_flow_dissector_target(flow_dissector,\n\t\t\t\t\t\t\t\t     FLOW_DISSECTOR_KEY_FLOW_LABEL,\n\t\t\t\t\t\t\t\t     target_container);\n\t\t\t\tkey_tags->flow_label = ntohl(flow_label);\n\t\t\t}\n\t\t}\n\n\t\tbreak;\n\t}\n\tcase htons(ETH_P_8021AD):\n\tcase htons(ETH_P_8021Q): {\n\t\tconst struct vlan_hdr *vlan;\n\t\tstruct vlan_hdr _vlan;\n\n\t\tvlan = __skb_header_pointer(skb, nhoff, sizeof(_vlan), data, hlen, &_vlan);\n\t\tif (!vlan)\n\t\t\tgoto out_bad;\n\n\t\tif (skb_flow_dissector_uses_key(flow_dissector,\n\t\t\t\t\t\tFLOW_DISSECTOR_KEY_VLANID)) {\n\t\t\tkey_tags = skb_flow_dissector_target(flow_dissector,\n\t\t\t\t\t\t\t     FLOW_DISSECTOR_KEY_VLANID,\n\t\t\t\t\t\t\t     target_container);\n\n\t\t\tkey_tags->vlan_id = skb_vlan_tag_get_id(skb);\n\t\t}\n\n\t\tproto = vlan->h_vlan_encapsulated_proto;\n\t\tnhoff += sizeof(*vlan);\n\t\tgoto again;\n\t}\n\tcase htons(ETH_P_PPP_SES): {\n\t\tstruct {\n\t\t\tstruct pppoe_hdr hdr;\n\t\t\t__be16 proto;\n\t\t} *hdr, _hdr;\n\t\thdr = __skb_header_pointer(skb, nhoff, sizeof(_hdr), data, hlen, &_hdr);\n\t\tif (!hdr)\n\t\t\tgoto out_bad;\n\t\tproto = hdr->proto;\n\t\tnhoff += PPPOE_SES_HLEN;\n\t\tswitch (proto) {\n\t\tcase htons(PPP_IP):\n\t\t\tgoto ip;\n\t\tcase htons(PPP_IPV6):\n\t\t\tgoto ipv6;\n\t\tdefault:\n\t\t\tgoto out_bad;\n\t\t}\n\t}\n\tcase htons(ETH_P_TIPC): {\n\t\tstruct {\n\t\t\t__be32 pre[3];\n\t\t\t__be32 srcnode;\n\t\t} *hdr, _hdr;\n\t\thdr = __skb_header_pointer(skb, nhoff, sizeof(_hdr), data, hlen, &_hdr);\n\t\tif (!hdr)\n\t\t\tgoto out_bad;\n\n\t\tif (skb_flow_dissector_uses_key(flow_dissector,\n\t\t\t\t\t\tFLOW_DISSECTOR_KEY_TIPC_ADDRS)) {\n\t\t\tkey_addrs = skb_flow_dissector_target(flow_dissector,\n\t\t\t\t\t\t\t      FLOW_DISSECTOR_KEY_TIPC_ADDRS,\n\t\t\t\t\t\t\t      target_container);\n\t\t\tkey_addrs->tipcaddrs.srcnode = hdr->srcnode;\n\t\t\tkey_control->addr_type = FLOW_DISSECTOR_KEY_TIPC_ADDRS;\n\t\t}\n\t\tgoto out_good;\n\t}\n\n\tcase htons(ETH_P_MPLS_UC):\n\tcase htons(ETH_P_MPLS_MC): {\n\t\tstruct mpls_label *hdr, _hdr[2];\nmpls:\n\t\thdr = __skb_header_pointer(skb, nhoff, sizeof(_hdr), data,\n\t\t\t\t\t   hlen, &_hdr);\n\t\tif (!hdr)\n\t\t\tgoto out_bad;\n\n\t\tif ((ntohl(hdr[0].entry) & MPLS_LS_LABEL_MASK) >>\n\t\t     MPLS_LS_LABEL_SHIFT == MPLS_LABEL_ENTROPY) {\n\t\t\tif (skb_flow_dissector_uses_key(flow_dissector,\n\t\t\t\t\t\t\tFLOW_DISSECTOR_KEY_MPLS_ENTROPY)) {\n\t\t\t\tkey_keyid = skb_flow_dissector_target(flow_dissector,\n\t\t\t\t\t\t\t\t      FLOW_DISSECTOR_KEY_MPLS_ENTROPY,\n\t\t\t\t\t\t\t\t      target_container);\n\t\t\t\tkey_keyid->keyid = hdr[1].entry &\n\t\t\t\t\thtonl(MPLS_LS_LABEL_MASK);\n\t\t\t}\n\n\t\t\tgoto out_good;\n\t\t}\n\n\t\tgoto out_good;\n\t}\n\n\tcase htons(ETH_P_FCOE):\n\t\tkey_control->thoff = (u16)(nhoff + FCOE_HEADER_LEN);\n\t\t/* fall through */\n\tdefault:\n\t\tgoto out_bad;\n\t}\n\nip_proto_again:\n\tswitch (ip_proto) {\n\tcase IPPROTO_GRE: {\n\t\tstruct gre_hdr {\n\t\t\t__be16 flags;\n\t\t\t__be16 proto;\n\t\t} *hdr, _hdr;\n\n\t\thdr = __skb_header_pointer(skb, nhoff, sizeof(_hdr), data, hlen, &_hdr);\n\t\tif (!hdr)\n\t\t\tgoto out_bad;\n\t\t/*\n\t\t * Only look inside GRE if version zero and no\n\t\t * routing\n\t\t */\n\t\tif (hdr->flags & (GRE_VERSION | GRE_ROUTING))\n\t\t\tbreak;\n\n\t\tproto = hdr->proto;\n\t\tnhoff += 4;\n\t\tif (hdr->flags & GRE_CSUM)\n\t\t\tnhoff += 4;\n\t\tif (hdr->flags & GRE_KEY) {\n\t\t\tconst __be32 *keyid;\n\t\t\t__be32 _keyid;\n\n\t\t\tkeyid = __skb_header_pointer(skb, nhoff, sizeof(_keyid),\n\t\t\t\t\t\t     data, hlen, &_keyid);\n\n\t\t\tif (!keyid)\n\t\t\t\tgoto out_bad;\n\n\t\t\tif (skb_flow_dissector_uses_key(flow_dissector,\n\t\t\t\t\t\t\tFLOW_DISSECTOR_KEY_GRE_KEYID)) {\n\t\t\t\tkey_keyid = skb_flow_dissector_target(flow_dissector,\n\t\t\t\t\t\t\t\t      FLOW_DISSECTOR_KEY_GRE_KEYID,\n\t\t\t\t\t\t\t\t      target_container);\n\t\t\t\tkey_keyid->keyid = *keyid;\n\t\t\t}\n\t\t\tnhoff += 4;\n\t\t}\n\t\tif (hdr->flags & GRE_SEQ)\n\t\t\tnhoff += 4;\n\t\tif (proto == htons(ETH_P_TEB)) {\n\t\t\tconst struct ethhdr *eth;\n\t\t\tstruct ethhdr _eth;\n\n\t\t\teth = __skb_header_pointer(skb, nhoff,\n\t\t\t\t\t\t   sizeof(_eth),\n\t\t\t\t\t\t   data, hlen, &_eth);\n\t\t\tif (!eth)\n\t\t\t\tgoto out_bad;\n\t\t\tproto = eth->h_proto;\n\t\t\tnhoff += sizeof(*eth);\n\t\t}\n\t\tgoto again;\n\t}\n\tcase NEXTHDR_HOP:\n\tcase NEXTHDR_ROUTING:\n\tcase NEXTHDR_DEST: {\n\t\tu8 _opthdr[2], *opthdr;\n\n\t\tif (proto != htons(ETH_P_IPV6))\n\t\t\tbreak;\n\n\t\topthdr = __skb_header_pointer(skb, nhoff, sizeof(_opthdr),\n\t\t\t\t\t      data, hlen, &_opthdr);\n\t\tif (!opthdr)\n\t\t\tgoto out_bad;\n\n\t\tip_proto = opthdr[0];\n\t\tnhoff += (opthdr[1] + 1) << 3;\n\n\t\tgoto ip_proto_again;\n\t}\n\tcase IPPROTO_IPIP:\n\t\tproto = htons(ETH_P_IP);\n\t\tgoto ip;\n\tcase IPPROTO_IPV6:\n\t\tproto = htons(ETH_P_IPV6);\n\t\tgoto ipv6;\n\tcase IPPROTO_MPLS:\n\t\tproto = htons(ETH_P_MPLS_UC);\n\t\tgoto mpls;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tif (skb_flow_dissector_uses_key(flow_dissector,\n\t\t\t\t\tFLOW_DISSECTOR_KEY_PORTS)) {\n\t\tkey_ports = skb_flow_dissector_target(flow_dissector,\n\t\t\t\t\t\t      FLOW_DISSECTOR_KEY_PORTS,\n\t\t\t\t\t\t      target_container);\n\t\tkey_ports->ports = __skb_flow_get_ports(skb, nhoff, ip_proto,\n\t\t\t\t\t\t\tdata, hlen);\n\t}\n\nout_good:\n\tret = true;\n\nout_bad:\n\tkey_basic->n_proto = proto;\n\tkey_basic->ip_proto = ip_proto;\n\tkey_control->thoff = (u16)nhoff;\n\n\treturn ret;\n}",
        "description": "The `__skb_flow_dissect` function in the Linux kernel, prior to version 4.3, does not guarantee the initialization of certain protocol fields (`n_proto`, `ip_proto`, and `thoff`). This oversight enables remote attackers to exploit a single crafted MPLS packet to trigger a denial of service (system crash) or potentially execute arbitrary code.",
        "commit": "The vulnerability involves a function responsible for dissecting network flows, where instead of returning immediately upon encountering a parsing failure, it jumps to cleanup code. This approach ensures that even in the event of a failure, some protocol values are set in the key_control structure, although there may still be valid information in the key_tags that was established before the error occurred."
    },
    {
        "cwe": "CWE-863",
        "func_name": "torvalds/internal_get_user_pages_fast",
        "score": 0.764733612537384,
        "func_before": "static int internal_get_user_pages_fast(unsigned long start, int nr_pages,\n\t\t\t\t\tunsigned int gup_flags,\n\t\t\t\t\tstruct page **pages)\n{\n\tunsigned long addr, len, end;\n\tint nr_pinned = 0, ret = 0;\n\n\tif (WARN_ON_ONCE(gup_flags & ~(FOLL_WRITE | FOLL_LONGTERM |\n\t\t\t\t       FOLL_FORCE | FOLL_PIN | FOLL_GET)))\n\t\treturn -EINVAL;\n\n\tstart = untagged_addr(start) & PAGE_MASK;\n\taddr = start;\n\tlen = (unsigned long) nr_pages << PAGE_SHIFT;\n\tend = start + len;\n\n\tif (end <= start)\n\t\treturn 0;\n\tif (unlikely(!access_ok((void __user *)start, len)))\n\t\treturn -EFAULT;\n\n\tif (IS_ENABLED(CONFIG_HAVE_FAST_GUP) &&\n\t    gup_fast_permitted(start, end)) {\n\t\tlocal_irq_disable();\n\t\tgup_pgd_range(addr, end, gup_flags, pages, &nr_pinned);\n\t\tlocal_irq_enable();\n\t\tret = nr_pinned;\n\t}\n\n\tif (nr_pinned < nr_pages) {\n\t\t/* Try to get the remaining pages with get_user_pages */\n\t\tstart += nr_pinned << PAGE_SHIFT;\n\t\tpages += nr_pinned;\n\n\t\tret = __gup_longterm_unlocked(start, nr_pages - nr_pinned,\n\t\t\t\t\t      gup_flags, pages);\n\n\t\t/* Have to be a bit careful with return values */\n\t\tif (nr_pinned > 0) {\n\t\t\tif (ret < 0)\n\t\t\t\tret = nr_pinned;\n\t\t\telse\n\t\t\t\tret += nr_pinned;\n\t\t}\n\t}\n\n\treturn ret;\n}",
        "func_after": "static int internal_get_user_pages_fast(unsigned long start, int nr_pages,\n\t\t\t\t\tunsigned int gup_flags,\n\t\t\t\t\tstruct page **pages)\n{\n\tunsigned long addr, len, end;\n\tint nr_pinned = 0, ret = 0;\n\n\tif (WARN_ON_ONCE(gup_flags & ~(FOLL_WRITE | FOLL_LONGTERM |\n\t\t\t\t       FOLL_FORCE | FOLL_PIN | FOLL_GET)))\n\t\treturn -EINVAL;\n\n\tstart = untagged_addr(start) & PAGE_MASK;\n\taddr = start;\n\tlen = (unsigned long) nr_pages << PAGE_SHIFT;\n\tend = start + len;\n\n\tif (end <= start)\n\t\treturn 0;\n\tif (unlikely(!access_ok((void __user *)start, len)))\n\t\treturn -EFAULT;\n\n\t/*\n\t * The FAST_GUP case requires FOLL_WRITE even for pure reads,\n\t * because get_user_pages() may need to cause an early COW in\n\t * order to avoid confusing the normal COW routines. So only\n\t * targets that are already writable are safe to do by just\n\t * looking at the page tables.\n\t */\n\tif (IS_ENABLED(CONFIG_HAVE_FAST_GUP) &&\n\t    gup_fast_permitted(start, end)) {\n\t\tlocal_irq_disable();\n\t\tgup_pgd_range(addr, end, gup_flags | FOLL_WRITE, pages, &nr_pinned);\n\t\tlocal_irq_enable();\n\t\tret = nr_pinned;\n\t}\n\n\tif (nr_pinned < nr_pages) {\n\t\t/* Try to get the remaining pages with get_user_pages */\n\t\tstart += nr_pinned << PAGE_SHIFT;\n\t\tpages += nr_pinned;\n\n\t\tret = __gup_longterm_unlocked(start, nr_pages - nr_pinned,\n\t\t\t\t\t      gup_flags, pages);\n\n\t\t/* Have to be a bit careful with return values */\n\t\tif (nr_pinned > 0) {\n\t\t\tif (ret < 0)\n\t\t\t\tret = nr_pinned;\n\t\t\telse\n\t\t\t\tret += nr_pinned;\n\t\t}\n\t}\n\n\treturn ret;\n}",
        "description": "An issue was discovered in the Linux kernel prior to version 5.7.3, affecting the memory management components located in mm/gup.c and mm/huge_memory.c. The get_user_pages (gup) implementation, when utilized for copy-on-write pages, fails to correctly handle read operation semantics, potentially resulting in unintended write access.",
        "commit": "The vulnerability involves the `get_user_pages()` function in the Linux kernel, which can lead to ambiguous behavior when dealing with copy-on-write (COW) pages. Specifically, the function may return a page pointer that is no longer associated with the original virtual memory area (VM) due to potential COW events. This ambiguity arises because the direction and timing of COW events are undefined, and a page can be unmapped by the thread that performed the `get_user_pages()` call, especially under memory pressure.\n\nTo mitigate this issue, the kernel introduces a change to force a COW event by setting the `FOLL_WRITE` flag when `FOLL_GET` or `FOLL_PIN` is used on a COW mapping. This ensures that the page is properly isolated from other VMs, preventing unintended access or control. However, this change affects the behavior of `get_user_pages_fast()`, which now refuses to follow read-only pages due to the potential need for COW breaking, leading to slower processing in such cases.\n\nThe current semantics are as follows:\n- `__get_user_pages_fast()`: No changes; it does not break COW unless explicitly asked.\n- `get_user_pages_fast()`: Refuses to follow read-only pages, requiring the slow path for COW breaking.\n- `get_user_pages()`: Forces COW breaking for COW mappings when using `FOLL_GET` or `FOLL_PIN`.\n\nThis change aims to clarify the semantics of `get_user_pages()` and reduce the risk of subtle bugs related to COW behavior. While this addresses the ambiguity, it is noted that true shared mappings will still allow pages to change under the user, meaning `get_user_pages()` does not guarantee a \"stable\" page."
    },
    {
        "cwe": "CWE-203",
        "func_name": "barebox/check_passwd",
        "score": 0.7587136030197144,
        "func_before": "static int check_passwd(unsigned char *passwd, size_t length)\n{\n\tstruct digest *d = NULL;\n\tunsigned char *passwd1_sum;\n\tunsigned char *passwd2_sum;\n\tint ret = 0;\n\tint hash_len;\n\n\tif (IS_ENABLED(CONFIG_PASSWD_CRYPTO_PBKDF2)) {\n\t\thash_len = PBKDF2_LENGTH;\n\t} else {\n\t\td = digest_alloc(PASSWD_SUM);\n\t\tif (!d) {\n\t\t\tpr_err(\"No such digest: %s\\n\",\n\t\t\t       PASSWD_SUM ? PASSWD_SUM : \"NULL\");\n\t\t\treturn -ENOENT;\n\t\t}\n\n\t\thash_len = digest_length(d);\n\t}\n\n\tpasswd1_sum = calloc(hash_len * 2, sizeof(unsigned char));\n\tif (!passwd1_sum)\n\t\treturn -ENOMEM;\n\n\tpasswd2_sum = passwd1_sum + hash_len;\n\n\tif (is_passwd_env_enable())\n\t\tret = read_env_passwd(passwd2_sum, hash_len);\n\telse if (is_passwd_default_enable())\n\t\tret = read_default_passwd(passwd2_sum, hash_len);\n\telse\n\t\tret = -EINVAL;\n\n\tif (ret < 0)\n\t\tgoto err;\n\n\tif (IS_ENABLED(CONFIG_PASSWD_CRYPTO_PBKDF2)) {\n\t\tchar *key = passwd2_sum + PBKDF2_SALT_LEN;\n\t\tchar *salt = passwd2_sum;\n\t\tint keylen = PBKDF2_LENGTH - PBKDF2_SALT_LEN;\n\n\t\tret = pkcs5_pbkdf2_hmac_sha1(passwd, length, salt,\n\t\t\tPBKDF2_SALT_LEN, PBKDF2_COUNT, keylen, passwd1_sum);\n\t\tif (ret)\n\t\t\tgoto err;\n\n\t\tif (strncmp(passwd1_sum, key, keylen) == 0)\n\t\t\tret = 1;\n\t} else {\n\t\tret = digest_digest(d, passwd, length, passwd1_sum);\n\n\t\tif (ret)\n\t\t\tgoto err;\n\n\t\tif (strncmp(passwd1_sum, passwd2_sum, hash_len) == 0)\n\t\t\tret = 1;\n\t}\n\nerr:\n\tfree(passwd1_sum);\n\tdigest_free(d);\n\n\treturn ret;\n}",
        "func_after": "static int check_passwd(unsigned char *passwd, size_t length)\n{\n\tstruct digest *d = NULL;\n\tunsigned char *passwd1_sum;\n\tunsigned char *passwd2_sum;\n\tint ret = 0;\n\tint hash_len;\n\n\tif (IS_ENABLED(CONFIG_PASSWD_CRYPTO_PBKDF2)) {\n\t\thash_len = PBKDF2_LENGTH;\n\t} else {\n\t\td = digest_alloc(PASSWD_SUM);\n\t\tif (!d) {\n\t\t\tpr_err(\"No such digest: %s\\n\",\n\t\t\t       PASSWD_SUM ? PASSWD_SUM : \"NULL\");\n\t\t\treturn -ENOENT;\n\t\t}\n\n\t\thash_len = digest_length(d);\n\t}\n\n\tpasswd1_sum = calloc(hash_len * 2, sizeof(unsigned char));\n\tif (!passwd1_sum)\n\t\treturn -ENOMEM;\n\n\tpasswd2_sum = passwd1_sum + hash_len;\n\n\tif (is_passwd_env_enable())\n\t\tret = read_env_passwd(passwd2_sum, hash_len);\n\telse if (is_passwd_default_enable())\n\t\tret = read_default_passwd(passwd2_sum, hash_len);\n\telse\n\t\tret = -EINVAL;\n\n\tif (ret < 0)\n\t\tgoto err;\n\n\tif (IS_ENABLED(CONFIG_PASSWD_CRYPTO_PBKDF2)) {\n\t\tchar *key = passwd2_sum + PBKDF2_SALT_LEN;\n\t\tchar *salt = passwd2_sum;\n\t\tint keylen = PBKDF2_LENGTH - PBKDF2_SALT_LEN;\n\n\t\tret = pkcs5_pbkdf2_hmac_sha1(passwd, length, salt,\n\t\t\tPBKDF2_SALT_LEN, PBKDF2_COUNT, keylen, passwd1_sum);\n\t\tif (ret)\n\t\t\tgoto err;\n\n\t\tif (!crypto_memneq(passwd1_sum, key, keylen))\n\t\t\tret = 1;\n\t} else {\n\t\tret = digest_digest(d, passwd, length, passwd1_sum);\n\n\t\tif (ret)\n\t\t\tgoto err;\n\n\t\tif (!crypto_memneq(passwd1_sum, passwd2_sum, hash_len))\n\t\t\tret = 1;\n\t}\n\nerr:\n\tfree(passwd1_sum);\n\tdigest_free(d);\n\n\treturn ret;\n}",
        "description": "The Pengutronix barebox, up to version 2021.07.0, suffers from a vulnerability where timing information is leaked due to the use of `strncmp` during hash comparisons.",
        "commit": "Cryptographic verifications should employ a time-constant comparison method to prevent attackers from inferring secret information by observing system behavior. Therefore, it is recommended to use functions like `crypto_memneq()` instead of `memcmp()` for comparing sensitive data such as password hashes."
    },
    {
        "cwe": "CWE-668",
        "func_name": "xen-project/sh_install_xen_entries_in_l4",
        "score": 0.7339527606964111,
        "func_before": "void sh_install_xen_entries_in_l4(struct domain *d, mfn_t gl4mfn, mfn_t sl4mfn)\n{\n    shadow_l4e_t *sl4e;\n    unsigned int slots;\n\n    sl4e = map_domain_page(sl4mfn);\n    BUILD_BUG_ON(sizeof (l4_pgentry_t) != sizeof (shadow_l4e_t));\n\n    /* Copy the common Xen mappings from the idle domain */\n    slots = (shadow_mode_external(d)\n             ? ROOT_PAGETABLE_XEN_SLOTS\n             : ROOT_PAGETABLE_PV_XEN_SLOTS);\n    memcpy(&sl4e[ROOT_PAGETABLE_FIRST_XEN_SLOT],\n           &idle_pg_table[ROOT_PAGETABLE_FIRST_XEN_SLOT],\n           slots * sizeof(l4_pgentry_t));\n\n    /* Install the per-domain mappings for this domain */\n    sl4e[shadow_l4_table_offset(PERDOMAIN_VIRT_START)] =\n        shadow_l4e_from_mfn(page_to_mfn(d->arch.perdomain_l3_pg),\n                            __PAGE_HYPERVISOR_RW);\n\n    if ( !shadow_mode_external(d) && !is_pv_32bit_domain(d) &&\n         !VM_ASSIST(d, m2p_strict) )\n    {\n        /* open coded zap_ro_mpt(mfn_x(sl4mfn)): */\n        sl4e[shadow_l4_table_offset(RO_MPT_VIRT_START)] = shadow_l4e_empty();\n    }\n\n    /* Shadow linear mapping for 4-level shadows.  N.B. for 3-level\n     * shadows on 64-bit xen, this linear mapping is later replaced by the\n     * monitor pagetable structure, which is built in make_monitor_table\n     * and maintained by sh_update_linear_entries. */\n    sl4e[shadow_l4_table_offset(SH_LINEAR_PT_VIRT_START)] =\n        shadow_l4e_from_mfn(sl4mfn, __PAGE_HYPERVISOR_RW);\n\n    /* Self linear mapping.  */\n    if ( shadow_mode_translate(d) && !shadow_mode_external(d) )\n    {\n        // linear tables may not be used with translated PV guests\n        sl4e[shadow_l4_table_offset(LINEAR_PT_VIRT_START)] =\n            shadow_l4e_empty();\n    }\n    else\n    {\n        sl4e[shadow_l4_table_offset(LINEAR_PT_VIRT_START)] =\n            shadow_l4e_from_mfn(gl4mfn, __PAGE_HYPERVISOR_RW);\n    }\n\n    unmap_domain_page(sl4e);\n}",
        "func_after": "void sh_install_xen_entries_in_l4(struct domain *d, mfn_t gl4mfn, mfn_t sl4mfn)\n{\n    shadow_l4e_t *sl4e;\n    unsigned int slots;\n\n    sl4e = map_domain_page(sl4mfn);\n    BUILD_BUG_ON(sizeof (l4_pgentry_t) != sizeof (shadow_l4e_t));\n\n    /* Copy the common Xen mappings from the idle domain */\n    slots = (shadow_mode_external(d)\n             ? ROOT_PAGETABLE_XEN_SLOTS\n             : ROOT_PAGETABLE_PV_XEN_SLOTS);\n    memcpy(&sl4e[ROOT_PAGETABLE_FIRST_XEN_SLOT],\n           &idle_pg_table[ROOT_PAGETABLE_FIRST_XEN_SLOT],\n           slots * sizeof(l4_pgentry_t));\n\n    /* Install the per-domain mappings for this domain */\n    sl4e[shadow_l4_table_offset(PERDOMAIN_VIRT_START)] =\n        shadow_l4e_from_mfn(page_to_mfn(d->arch.perdomain_l3_pg),\n                            __PAGE_HYPERVISOR_RW);\n\n    if ( !shadow_mode_external(d) && !is_pv_32bit_domain(d) &&\n         !VM_ASSIST(d, m2p_strict) )\n    {\n        /* open coded zap_ro_mpt(mfn_x(sl4mfn)): */\n        sl4e[shadow_l4_table_offset(RO_MPT_VIRT_START)] = shadow_l4e_empty();\n    }\n\n    /*\n     * Linear mapping slots:\n     *\n     * Calling this function with gl4mfn == sl4mfn is used to construct a\n     * monitor table for translated domains.  In this case, gl4mfn forms the\n     * self-linear mapping (i.e. not pointing into the translated domain), and\n     * the shadow-linear slot is skipped.  The shadow-linear slot is either\n     * filled when constructing lower level monitor tables, or via\n     * sh_update_cr3() for 4-level guests.\n     *\n     * Calling this function with gl4mfn != sl4mfn is used for non-translated\n     * guests, where the shadow-linear slot is actually self-linear, and the\n     * guest-linear slot points into the guests view of its pagetables.\n     */\n    if ( shadow_mode_translate(d) )\n    {\n        ASSERT(mfn_eq(gl4mfn, sl4mfn));\n\n        sl4e[shadow_l4_table_offset(SH_LINEAR_PT_VIRT_START)] =\n            shadow_l4e_empty();\n    }\n    else\n    {\n        ASSERT(!mfn_eq(gl4mfn, sl4mfn));\n\n        sl4e[shadow_l4_table_offset(SH_LINEAR_PT_VIRT_START)] =\n            shadow_l4e_from_mfn(sl4mfn, __PAGE_HYPERVISOR_RW);\n    }\n\n    sl4e[shadow_l4_table_offset(LINEAR_PT_VIRT_START)] =\n        shadow_l4e_from_mfn(gl4mfn, __PAGE_HYPERVISOR_RW);\n\n    unmap_domain_page(sl4e);\n}",
        "description": "An issue was discovered in Xen versions up to 4.9.x, where x86 HVM guest OS users could potentially cause a denial of service (hypervisor crash) or escalate privileges due to improper handling of self-linear shadow mappings in translated guests.",
        "commit": "When setting up a monitor table for 4-level translated guests in the x86/shadow module, avoid creating self-linear shadow mappings. These mappings can confuse the writable heuristic logic, causing it to follow Xen's mappings instead of the guests' shadows. As a result, the function `sh_guess_wrmap()` must handle cases where no shadow-linear mapping is present, which happens each time a vCPU switches to 4-level paging from a different mode. Appropriate shadow-linear slots are inserted into the monitor table either during the construction of lower-level tables or by `sh_update_cr3()`. Additionally, clarify the safety of other mappings; although they may appear unsafe, creating guest-linear mappings for translated domains is correct because they are self-linear and do not point into the translated domain. Remove a redundant clause for guests that are not external translators. This addresses issue XSA-243."
    },
    {
        "cwe": "CWE-20",
        "func_name": "torvalds/cifs_lookup",
        "score": 0.7735373377799988,
        "func_before": "struct dentry *\ncifs_lookup(struct inode *parent_dir_inode, struct dentry *direntry,\n\t    struct nameidata *nd)\n{\n\tint xid;\n\tint rc = 0; /* to get around spurious gcc warning, set to zero here */\n\t__u32 oplock = enable_oplocks ? REQ_OPLOCK : 0;\n\t__u16 fileHandle = 0;\n\tbool posix_open = false;\n\tstruct cifs_sb_info *cifs_sb;\n\tstruct tcon_link *tlink;\n\tstruct cifs_tcon *pTcon;\n\tstruct cifsFileInfo *cfile;\n\tstruct inode *newInode = NULL;\n\tchar *full_path = NULL;\n\tstruct file *filp;\n\n\txid = GetXid();\n\n\tcFYI(1, \"parent inode = 0x%p name is: %s and dentry = 0x%p\",\n\t      parent_dir_inode, direntry->d_name.name, direntry);\n\n\t/* check whether path exists */\n\n\tcifs_sb = CIFS_SB(parent_dir_inode->i_sb);\n\ttlink = cifs_sb_tlink(cifs_sb);\n\tif (IS_ERR(tlink)) {\n\t\tFreeXid(xid);\n\t\treturn (struct dentry *)tlink;\n\t}\n\tpTcon = tlink_tcon(tlink);\n\n\t/*\n\t * Don't allow the separator character in a path component.\n\t * The VFS will not allow \"/\", but \"\\\" is allowed by posix.\n\t */\n\tif (!(cifs_sb->mnt_cifs_flags & CIFS_MOUNT_POSIX_PATHS)) {\n\t\tint i;\n\t\tfor (i = 0; i < direntry->d_name.len; i++)\n\t\t\tif (direntry->d_name.name[i] == '\\\\') {\n\t\t\t\tcFYI(1, \"Invalid file name\");\n\t\t\t\trc = -EINVAL;\n\t\t\t\tgoto lookup_out;\n\t\t\t}\n\t}\n\n\t/*\n\t * O_EXCL: optimize away the lookup, but don't hash the dentry. Let\n\t * the VFS handle the create.\n\t */\n\tif (nd && (nd->flags & LOOKUP_EXCL)) {\n\t\td_instantiate(direntry, NULL);\n\t\trc = 0;\n\t\tgoto lookup_out;\n\t}\n\n\t/* can not grab the rename sem here since it would\n\tdeadlock in the cases (beginning of sys_rename itself)\n\tin which we already have the sb rename sem */\n\tfull_path = build_path_from_dentry(direntry);\n\tif (full_path == NULL) {\n\t\trc = -ENOMEM;\n\t\tgoto lookup_out;\n\t}\n\n\tif (direntry->d_inode != NULL) {\n\t\tcFYI(1, \"non-NULL inode in lookup\");\n\t} else {\n\t\tcFYI(1, \"NULL inode in lookup\");\n\t}\n\tcFYI(1, \"Full path: %s inode = 0x%p\", full_path, direntry->d_inode);\n\n\t/* Posix open is only called (at lookup time) for file create now.\n\t * For opens (rather than creates), because we do not know if it\n\t * is a file or directory yet, and current Samba no longer allows\n\t * us to do posix open on dirs, we could end up wasting an open call\n\t * on what turns out to be a dir. For file opens, we wait to call posix\n\t * open till cifs_open.  It could be added here (lookup) in the future\n\t * but the performance tradeoff of the extra network request when EISDIR\n\t * or EACCES is returned would have to be weighed against the 50%\n\t * reduction in network traffic in the other paths.\n\t */\n\tif (pTcon->unix_ext) {\n\t\tif (nd && !(nd->flags & LOOKUP_DIRECTORY) &&\n\t\t     (nd->flags & LOOKUP_OPEN) && !pTcon->broken_posix_open &&\n\t\t     (nd->intent.open.file->f_flags & O_CREAT)) {\n\t\t\trc = cifs_posix_open(full_path, &newInode,\n\t\t\t\t\tparent_dir_inode->i_sb,\n\t\t\t\t\tnd->intent.open.create_mode,\n\t\t\t\t\tnd->intent.open.file->f_flags, &oplock,\n\t\t\t\t\t&fileHandle, xid);\n\t\t\t/*\n\t\t\t * The check below works around a bug in POSIX\n\t\t\t * open in samba versions 3.3.1 and earlier where\n\t\t\t * open could incorrectly fail with invalid parameter.\n\t\t\t * If either that or op not supported returned, follow\n\t\t\t * the normal lookup.\n\t\t\t */\n\t\t\tif ((rc == 0) || (rc == -ENOENT))\n\t\t\t\tposix_open = true;\n\t\t\telse if ((rc == -EINVAL) || (rc != -EOPNOTSUPP))\n\t\t\t\tpTcon->broken_posix_open = true;\n\t\t}\n\t\tif (!posix_open)\n\t\t\trc = cifs_get_inode_info_unix(&newInode, full_path,\n\t\t\t\t\t\tparent_dir_inode->i_sb, xid);\n\t} else\n\t\trc = cifs_get_inode_info(&newInode, full_path, NULL,\n\t\t\t\tparent_dir_inode->i_sb, xid, NULL);\n\n\tif ((rc == 0) && (newInode != NULL)) {\n\t\td_add(direntry, newInode);\n\t\tif (posix_open) {\n\t\t\tfilp = lookup_instantiate_filp(nd, direntry,\n\t\t\t\t\t\t       generic_file_open);\n\t\t\tif (IS_ERR(filp)) {\n\t\t\t\trc = PTR_ERR(filp);\n\t\t\t\tCIFSSMBClose(xid, pTcon, fileHandle);\n\t\t\t\tgoto lookup_out;\n\t\t\t}\n\n\t\t\tcfile = cifs_new_fileinfo(fileHandle, filp, tlink,\n\t\t\t\t\t\t  oplock);\n\t\t\tif (cfile == NULL) {\n\t\t\t\tfput(filp);\n\t\t\t\tCIFSSMBClose(xid, pTcon, fileHandle);\n\t\t\t\trc = -ENOMEM;\n\t\t\t\tgoto lookup_out;\n\t\t\t}\n\t\t}\n\t\t/* since paths are not looked up by component - the parent\n\t\t   directories are presumed to be good here */\n\t\trenew_parental_timestamps(direntry);\n\n\t} else if (rc == -ENOENT) {\n\t\trc = 0;\n\t\tdirentry->d_time = jiffies;\n\t\td_add(direntry, NULL);\n\t/*\tif it was once a directory (but how can we tell?) we could do\n\t\tshrink_dcache_parent(direntry); */\n\t} else if (rc != -EACCES) {\n\t\tcERROR(1, \"Unexpected lookup error %d\", rc);\n\t\t/* We special case check for Access Denied - since that\n\t\tis a common return code */\n\t}\n\nlookup_out:\n\tkfree(full_path);\n\tcifs_put_tlink(tlink);\n\tFreeXid(xid);\n\treturn ERR_PTR(rc);\n}",
        "func_after": "struct dentry *\ncifs_lookup(struct inode *parent_dir_inode, struct dentry *direntry,\n\t    struct nameidata *nd)\n{\n\tint xid;\n\tint rc = 0; /* to get around spurious gcc warning, set to zero here */\n\t__u32 oplock = enable_oplocks ? REQ_OPLOCK : 0;\n\t__u16 fileHandle = 0;\n\tbool posix_open = false;\n\tstruct cifs_sb_info *cifs_sb;\n\tstruct tcon_link *tlink;\n\tstruct cifs_tcon *pTcon;\n\tstruct cifsFileInfo *cfile;\n\tstruct inode *newInode = NULL;\n\tchar *full_path = NULL;\n\tstruct file *filp;\n\n\txid = GetXid();\n\n\tcFYI(1, \"parent inode = 0x%p name is: %s and dentry = 0x%p\",\n\t      parent_dir_inode, direntry->d_name.name, direntry);\n\n\t/* check whether path exists */\n\n\tcifs_sb = CIFS_SB(parent_dir_inode->i_sb);\n\ttlink = cifs_sb_tlink(cifs_sb);\n\tif (IS_ERR(tlink)) {\n\t\tFreeXid(xid);\n\t\treturn (struct dentry *)tlink;\n\t}\n\tpTcon = tlink_tcon(tlink);\n\n\t/*\n\t * Don't allow the separator character in a path component.\n\t * The VFS will not allow \"/\", but \"\\\" is allowed by posix.\n\t */\n\tif (!(cifs_sb->mnt_cifs_flags & CIFS_MOUNT_POSIX_PATHS)) {\n\t\tint i;\n\t\tfor (i = 0; i < direntry->d_name.len; i++)\n\t\t\tif (direntry->d_name.name[i] == '\\\\') {\n\t\t\t\tcFYI(1, \"Invalid file name\");\n\t\t\t\trc = -EINVAL;\n\t\t\t\tgoto lookup_out;\n\t\t\t}\n\t}\n\n\t/*\n\t * O_EXCL: optimize away the lookup, but don't hash the dentry. Let\n\t * the VFS handle the create.\n\t */\n\tif (nd && (nd->flags & LOOKUP_EXCL)) {\n\t\td_instantiate(direntry, NULL);\n\t\trc = 0;\n\t\tgoto lookup_out;\n\t}\n\n\t/* can not grab the rename sem here since it would\n\tdeadlock in the cases (beginning of sys_rename itself)\n\tin which we already have the sb rename sem */\n\tfull_path = build_path_from_dentry(direntry);\n\tif (full_path == NULL) {\n\t\trc = -ENOMEM;\n\t\tgoto lookup_out;\n\t}\n\n\tif (direntry->d_inode != NULL) {\n\t\tcFYI(1, \"non-NULL inode in lookup\");\n\t} else {\n\t\tcFYI(1, \"NULL inode in lookup\");\n\t}\n\tcFYI(1, \"Full path: %s inode = 0x%p\", full_path, direntry->d_inode);\n\n\t/* Posix open is only called (at lookup time) for file create now.\n\t * For opens (rather than creates), because we do not know if it\n\t * is a file or directory yet, and current Samba no longer allows\n\t * us to do posix open on dirs, we could end up wasting an open call\n\t * on what turns out to be a dir. For file opens, we wait to call posix\n\t * open till cifs_open.  It could be added here (lookup) in the future\n\t * but the performance tradeoff of the extra network request when EISDIR\n\t * or EACCES is returned would have to be weighed against the 50%\n\t * reduction in network traffic in the other paths.\n\t */\n\tif (pTcon->unix_ext) {\n\t\tif (nd && !(nd->flags & LOOKUP_DIRECTORY) &&\n\t\t     (nd->flags & LOOKUP_OPEN) && !pTcon->broken_posix_open &&\n\t\t     (nd->intent.open.file->f_flags & O_CREAT)) {\n\t\t\trc = cifs_posix_open(full_path, &newInode,\n\t\t\t\t\tparent_dir_inode->i_sb,\n\t\t\t\t\tnd->intent.open.create_mode,\n\t\t\t\t\tnd->intent.open.file->f_flags, &oplock,\n\t\t\t\t\t&fileHandle, xid);\n\t\t\t/*\n\t\t\t * The check below works around a bug in POSIX\n\t\t\t * open in samba versions 3.3.1 and earlier where\n\t\t\t * open could incorrectly fail with invalid parameter.\n\t\t\t * If either that or op not supported returned, follow\n\t\t\t * the normal lookup.\n\t\t\t */\n\t\t\tswitch (rc) {\n\t\t\tcase 0:\n\t\t\t\t/*\n\t\t\t\t * The server may allow us to open things like\n\t\t\t\t * FIFOs, but the client isn't set up to deal\n\t\t\t\t * with that. If it's not a regular file, just\n\t\t\t\t * close it and proceed as if it were a normal\n\t\t\t\t * lookup.\n\t\t\t\t */\n\t\t\t\tif (newInode && !S_ISREG(newInode->i_mode)) {\n\t\t\t\t\tCIFSSMBClose(xid, pTcon, fileHandle);\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\tcase -ENOENT:\n\t\t\t\tposix_open = true;\n\t\t\tcase -EOPNOTSUPP:\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tpTcon->broken_posix_open = true;\n\t\t\t}\n\t\t}\n\t\tif (!posix_open)\n\t\t\trc = cifs_get_inode_info_unix(&newInode, full_path,\n\t\t\t\t\t\tparent_dir_inode->i_sb, xid);\n\t} else\n\t\trc = cifs_get_inode_info(&newInode, full_path, NULL,\n\t\t\t\tparent_dir_inode->i_sb, xid, NULL);\n\n\tif ((rc == 0) && (newInode != NULL)) {\n\t\td_add(direntry, newInode);\n\t\tif (posix_open) {\n\t\t\tfilp = lookup_instantiate_filp(nd, direntry,\n\t\t\t\t\t\t       generic_file_open);\n\t\t\tif (IS_ERR(filp)) {\n\t\t\t\trc = PTR_ERR(filp);\n\t\t\t\tCIFSSMBClose(xid, pTcon, fileHandle);\n\t\t\t\tgoto lookup_out;\n\t\t\t}\n\n\t\t\tcfile = cifs_new_fileinfo(fileHandle, filp, tlink,\n\t\t\t\t\t\t  oplock);\n\t\t\tif (cfile == NULL) {\n\t\t\t\tfput(filp);\n\t\t\t\tCIFSSMBClose(xid, pTcon, fileHandle);\n\t\t\t\trc = -ENOMEM;\n\t\t\t\tgoto lookup_out;\n\t\t\t}\n\t\t}\n\t\t/* since paths are not looked up by component - the parent\n\t\t   directories are presumed to be good here */\n\t\trenew_parental_timestamps(direntry);\n\n\t} else if (rc == -ENOENT) {\n\t\trc = 0;\n\t\tdirentry->d_time = jiffies;\n\t\td_add(direntry, NULL);\n\t/*\tif it was once a directory (but how can we tell?) we could do\n\t\tshrink_dcache_parent(direntry); */\n\t} else if (rc != -EACCES) {\n\t\tcERROR(1, \"Unexpected lookup error %d\", rc);\n\t\t/* We special case check for Access Denied - since that\n\t\tis a common return code */\n\t}\n\nlookup_out:\n\tkfree(full_path);\n\tcifs_put_tlink(tlink);\n\tFreeXid(xid);\n\treturn ERR_PTR(rc);\n}",
        "description": "The `cifs_lookup` function in the CIFS directory handling module of the Linux kernel, prior to version 3.2.10, permits local users to trigger a denial of service (OOPS) condition by attempting to access a special file, such as a FIFO.",
        "commit": "The CIFS code attempts to open files during lookup under specific conditions. However, if the file turned out to be a FIFO or another special file type, the open file handle would be leaked, resulting in a dentry reference count mismatch and causing an oops error during unmount. This issue has been resolved by ensuring that the file handle on the server is closed if the file is not a regular file. Additionally, the code has been refactored to use a switch statement instead of a complex if-else structure."
    }
]