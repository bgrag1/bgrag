[
    {
        "cwe": "CWE-193",
        "func_name": "torvalds/ext4_ext_insert_extent",
        "score": 0.7120878100395203,
        "func_before": "int ext4_ext_insert_extent(handle_t *handle, struct inode *inode,\n\t\t\t\tstruct ext4_ext_path *path,\n\t\t\t\tstruct ext4_extent *newext, int flag)\n{\n\tstruct ext4_extent_header *eh;\n\tstruct ext4_extent *ex, *fex;\n\tstruct ext4_extent *nearex; /* nearest extent */\n\tstruct ext4_ext_path *npath = NULL;\n\tint depth, len, err;\n\text4_lblk_t next;\n\tunsigned uninitialized = 0;\n\tint flags = 0;\n\n\tif (unlikely(ext4_ext_get_actual_len(newext) == 0)) {\n\t\tEXT4_ERROR_INODE(inode, \"ext4_ext_get_actual_len(newext) == 0\");\n\t\treturn -EIO;\n\t}\n\tdepth = ext_depth(inode);\n\tex = path[depth].p_ext;\n\tif (unlikely(path[depth].p_hdr == NULL)) {\n\t\tEXT4_ERROR_INODE(inode, \"path[%d].p_hdr == NULL\", depth);\n\t\treturn -EIO;\n\t}\n\n\t/* try to insert block into found extent and return */\n\tif (ex && !(flag & EXT4_GET_BLOCKS_PRE_IO)\n\t\t&& ext4_can_extents_be_merged(inode, ex, newext)) {\n\t\text_debug(\"append [%d]%d block to %d:[%d]%d (from %llu)\\n\",\n\t\t\t  ext4_ext_is_uninitialized(newext),\n\t\t\t  ext4_ext_get_actual_len(newext),\n\t\t\t  le32_to_cpu(ex->ee_block),\n\t\t\t  ext4_ext_is_uninitialized(ex),\n\t\t\t  ext4_ext_get_actual_len(ex),\n\t\t\t  ext4_ext_pblock(ex));\n\t\terr = ext4_ext_get_access(handle, inode, path + depth);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\t/*\n\t\t * ext4_can_extents_be_merged should have checked that either\n\t\t * both extents are uninitialized, or both aren't. Thus we\n\t\t * need to check only one of them here.\n\t\t */\n\t\tif (ext4_ext_is_uninitialized(ex))\n\t\t\tuninitialized = 1;\n\t\tex->ee_len = cpu_to_le16(ext4_ext_get_actual_len(ex)\n\t\t\t\t\t+ ext4_ext_get_actual_len(newext));\n\t\tif (uninitialized)\n\t\t\text4_ext_mark_uninitialized(ex);\n\t\teh = path[depth].p_hdr;\n\t\tnearex = ex;\n\t\tgoto merge;\n\t}\n\nrepeat:\n\tdepth = ext_depth(inode);\n\teh = path[depth].p_hdr;\n\tif (le16_to_cpu(eh->eh_entries) < le16_to_cpu(eh->eh_max))\n\t\tgoto has_space;\n\n\t/* probably next leaf has space for us? */\n\tfex = EXT_LAST_EXTENT(eh);\n\tnext = ext4_ext_next_leaf_block(inode, path);\n\tif (le32_to_cpu(newext->ee_block) > le32_to_cpu(fex->ee_block)\n\t    && next != EXT_MAX_BLOCK) {\n\t\text_debug(\"next leaf block - %d\\n\", next);\n\t\tBUG_ON(npath != NULL);\n\t\tnpath = ext4_ext_find_extent(inode, next, NULL);\n\t\tif (IS_ERR(npath))\n\t\t\treturn PTR_ERR(npath);\n\t\tBUG_ON(npath->p_depth != path->p_depth);\n\t\teh = npath[depth].p_hdr;\n\t\tif (le16_to_cpu(eh->eh_entries) < le16_to_cpu(eh->eh_max)) {\n\t\t\text_debug(\"next leaf isn't full(%d)\\n\",\n\t\t\t\t  le16_to_cpu(eh->eh_entries));\n\t\t\tpath = npath;\n\t\t\tgoto repeat;\n\t\t}\n\t\text_debug(\"next leaf has no free space(%d,%d)\\n\",\n\t\t\t  le16_to_cpu(eh->eh_entries), le16_to_cpu(eh->eh_max));\n\t}\n\n\t/*\n\t * There is no free space in the found leaf.\n\t * We're gonna add a new leaf in the tree.\n\t */\n\tif (flag & EXT4_GET_BLOCKS_PUNCH_OUT_EXT)\n\t\tflags = EXT4_MB_USE_ROOT_BLOCKS;\n\terr = ext4_ext_create_new_leaf(handle, inode, flags, path, newext);\n\tif (err)\n\t\tgoto cleanup;\n\tdepth = ext_depth(inode);\n\teh = path[depth].p_hdr;\n\nhas_space:\n\tnearex = path[depth].p_ext;\n\n\terr = ext4_ext_get_access(handle, inode, path + depth);\n\tif (err)\n\t\tgoto cleanup;\n\n\tif (!nearex) {\n\t\t/* there is no extent in this leaf, create first one */\n\t\text_debug(\"first extent in the leaf: %d:%llu:[%d]%d\\n\",\n\t\t\t\tle32_to_cpu(newext->ee_block),\n\t\t\t\text4_ext_pblock(newext),\n\t\t\t\text4_ext_is_uninitialized(newext),\n\t\t\t\text4_ext_get_actual_len(newext));\n\t\tpath[depth].p_ext = EXT_FIRST_EXTENT(eh);\n\t} else if (le32_to_cpu(newext->ee_block)\n\t\t\t   > le32_to_cpu(nearex->ee_block)) {\n/*\t\tBUG_ON(newext->ee_block == nearex->ee_block); */\n\t\tif (nearex != EXT_LAST_EXTENT(eh)) {\n\t\t\tlen = EXT_MAX_EXTENT(eh) - nearex;\n\t\t\tlen = (len - 1) * sizeof(struct ext4_extent);\n\t\t\tlen = len < 0 ? 0 : len;\n\t\t\text_debug(\"insert %d:%llu:[%d]%d after: nearest 0x%p, \"\n\t\t\t\t\t\"move %d from 0x%p to 0x%p\\n\",\n\t\t\t\t\tle32_to_cpu(newext->ee_block),\n\t\t\t\t\text4_ext_pblock(newext),\n\t\t\t\t\text4_ext_is_uninitialized(newext),\n\t\t\t\t\text4_ext_get_actual_len(newext),\n\t\t\t\t\tnearex, len, nearex + 1, nearex + 2);\n\t\t\tmemmove(nearex + 2, nearex + 1, len);\n\t\t}\n\t\tpath[depth].p_ext = nearex + 1;\n\t} else {\n\t\tBUG_ON(newext->ee_block == nearex->ee_block);\n\t\tlen = (EXT_MAX_EXTENT(eh) - nearex) * sizeof(struct ext4_extent);\n\t\tlen = len < 0 ? 0 : len;\n\t\text_debug(\"insert %d:%llu:[%d]%d before: nearest 0x%p, \"\n\t\t\t\t\"move %d from 0x%p to 0x%p\\n\",\n\t\t\t\tle32_to_cpu(newext->ee_block),\n\t\t\t\text4_ext_pblock(newext),\n\t\t\t\text4_ext_is_uninitialized(newext),\n\t\t\t\text4_ext_get_actual_len(newext),\n\t\t\t\tnearex, len, nearex + 1, nearex + 2);\n\t\tmemmove(nearex + 1, nearex, len);\n\t\tpath[depth].p_ext = nearex;\n\t}\n\n\tle16_add_cpu(&eh->eh_entries, 1);\n\tnearex = path[depth].p_ext;\n\tnearex->ee_block = newext->ee_block;\n\text4_ext_store_pblock(nearex, ext4_ext_pblock(newext));\n\tnearex->ee_len = newext->ee_len;\n\nmerge:\n\t/* try to merge extents to the right */\n\tif (!(flag & EXT4_GET_BLOCKS_PRE_IO))\n\t\text4_ext_try_to_merge(inode, path, nearex);\n\n\t/* try to merge extents to the left */\n\n\t/* time to correct all indexes above */\n\terr = ext4_ext_correct_indexes(handle, inode, path);\n\tif (err)\n\t\tgoto cleanup;\n\n\terr = ext4_ext_dirty(handle, inode, path + depth);\n\ncleanup:\n\tif (npath) {\n\t\text4_ext_drop_refs(npath);\n\t\tkfree(npath);\n\t}\n\text4_ext_invalidate_cache(inode);\n\treturn err;\n}",
        "func_after": "int ext4_ext_insert_extent(handle_t *handle, struct inode *inode,\n\t\t\t\tstruct ext4_ext_path *path,\n\t\t\t\tstruct ext4_extent *newext, int flag)\n{\n\tstruct ext4_extent_header *eh;\n\tstruct ext4_extent *ex, *fex;\n\tstruct ext4_extent *nearex; /* nearest extent */\n\tstruct ext4_ext_path *npath = NULL;\n\tint depth, len, err;\n\text4_lblk_t next;\n\tunsigned uninitialized = 0;\n\tint flags = 0;\n\n\tif (unlikely(ext4_ext_get_actual_len(newext) == 0)) {\n\t\tEXT4_ERROR_INODE(inode, \"ext4_ext_get_actual_len(newext) == 0\");\n\t\treturn -EIO;\n\t}\n\tdepth = ext_depth(inode);\n\tex = path[depth].p_ext;\n\tif (unlikely(path[depth].p_hdr == NULL)) {\n\t\tEXT4_ERROR_INODE(inode, \"path[%d].p_hdr == NULL\", depth);\n\t\treturn -EIO;\n\t}\n\n\t/* try to insert block into found extent and return */\n\tif (ex && !(flag & EXT4_GET_BLOCKS_PRE_IO)\n\t\t&& ext4_can_extents_be_merged(inode, ex, newext)) {\n\t\text_debug(\"append [%d]%d block to %d:[%d]%d (from %llu)\\n\",\n\t\t\t  ext4_ext_is_uninitialized(newext),\n\t\t\t  ext4_ext_get_actual_len(newext),\n\t\t\t  le32_to_cpu(ex->ee_block),\n\t\t\t  ext4_ext_is_uninitialized(ex),\n\t\t\t  ext4_ext_get_actual_len(ex),\n\t\t\t  ext4_ext_pblock(ex));\n\t\terr = ext4_ext_get_access(handle, inode, path + depth);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\t/*\n\t\t * ext4_can_extents_be_merged should have checked that either\n\t\t * both extents are uninitialized, or both aren't. Thus we\n\t\t * need to check only one of them here.\n\t\t */\n\t\tif (ext4_ext_is_uninitialized(ex))\n\t\t\tuninitialized = 1;\n\t\tex->ee_len = cpu_to_le16(ext4_ext_get_actual_len(ex)\n\t\t\t\t\t+ ext4_ext_get_actual_len(newext));\n\t\tif (uninitialized)\n\t\t\text4_ext_mark_uninitialized(ex);\n\t\teh = path[depth].p_hdr;\n\t\tnearex = ex;\n\t\tgoto merge;\n\t}\n\nrepeat:\n\tdepth = ext_depth(inode);\n\teh = path[depth].p_hdr;\n\tif (le16_to_cpu(eh->eh_entries) < le16_to_cpu(eh->eh_max))\n\t\tgoto has_space;\n\n\t/* probably next leaf has space for us? */\n\tfex = EXT_LAST_EXTENT(eh);\n\tnext = ext4_ext_next_leaf_block(inode, path);\n\tif (le32_to_cpu(newext->ee_block) > le32_to_cpu(fex->ee_block)\n\t    && next != EXT_MAX_BLOCKS) {\n\t\text_debug(\"next leaf block - %d\\n\", next);\n\t\tBUG_ON(npath != NULL);\n\t\tnpath = ext4_ext_find_extent(inode, next, NULL);\n\t\tif (IS_ERR(npath))\n\t\t\treturn PTR_ERR(npath);\n\t\tBUG_ON(npath->p_depth != path->p_depth);\n\t\teh = npath[depth].p_hdr;\n\t\tif (le16_to_cpu(eh->eh_entries) < le16_to_cpu(eh->eh_max)) {\n\t\t\text_debug(\"next leaf isn't full(%d)\\n\",\n\t\t\t\t  le16_to_cpu(eh->eh_entries));\n\t\t\tpath = npath;\n\t\t\tgoto repeat;\n\t\t}\n\t\text_debug(\"next leaf has no free space(%d,%d)\\n\",\n\t\t\t  le16_to_cpu(eh->eh_entries), le16_to_cpu(eh->eh_max));\n\t}\n\n\t/*\n\t * There is no free space in the found leaf.\n\t * We're gonna add a new leaf in the tree.\n\t */\n\tif (flag & EXT4_GET_BLOCKS_PUNCH_OUT_EXT)\n\t\tflags = EXT4_MB_USE_ROOT_BLOCKS;\n\terr = ext4_ext_create_new_leaf(handle, inode, flags, path, newext);\n\tif (err)\n\t\tgoto cleanup;\n\tdepth = ext_depth(inode);\n\teh = path[depth].p_hdr;\n\nhas_space:\n\tnearex = path[depth].p_ext;\n\n\terr = ext4_ext_get_access(handle, inode, path + depth);\n\tif (err)\n\t\tgoto cleanup;\n\n\tif (!nearex) {\n\t\t/* there is no extent in this leaf, create first one */\n\t\text_debug(\"first extent in the leaf: %d:%llu:[%d]%d\\n\",\n\t\t\t\tle32_to_cpu(newext->ee_block),\n\t\t\t\text4_ext_pblock(newext),\n\t\t\t\text4_ext_is_uninitialized(newext),\n\t\t\t\text4_ext_get_actual_len(newext));\n\t\tpath[depth].p_ext = EXT_FIRST_EXTENT(eh);\n\t} else if (le32_to_cpu(newext->ee_block)\n\t\t\t   > le32_to_cpu(nearex->ee_block)) {\n/*\t\tBUG_ON(newext->ee_block == nearex->ee_block); */\n\t\tif (nearex != EXT_LAST_EXTENT(eh)) {\n\t\t\tlen = EXT_MAX_EXTENT(eh) - nearex;\n\t\t\tlen = (len - 1) * sizeof(struct ext4_extent);\n\t\t\tlen = len < 0 ? 0 : len;\n\t\t\text_debug(\"insert %d:%llu:[%d]%d after: nearest 0x%p, \"\n\t\t\t\t\t\"move %d from 0x%p to 0x%p\\n\",\n\t\t\t\t\tle32_to_cpu(newext->ee_block),\n\t\t\t\t\text4_ext_pblock(newext),\n\t\t\t\t\text4_ext_is_uninitialized(newext),\n\t\t\t\t\text4_ext_get_actual_len(newext),\n\t\t\t\t\tnearex, len, nearex + 1, nearex + 2);\n\t\t\tmemmove(nearex + 2, nearex + 1, len);\n\t\t}\n\t\tpath[depth].p_ext = nearex + 1;\n\t} else {\n\t\tBUG_ON(newext->ee_block == nearex->ee_block);\n\t\tlen = (EXT_MAX_EXTENT(eh) - nearex) * sizeof(struct ext4_extent);\n\t\tlen = len < 0 ? 0 : len;\n\t\text_debug(\"insert %d:%llu:[%d]%d before: nearest 0x%p, \"\n\t\t\t\t\"move %d from 0x%p to 0x%p\\n\",\n\t\t\t\tle32_to_cpu(newext->ee_block),\n\t\t\t\text4_ext_pblock(newext),\n\t\t\t\text4_ext_is_uninitialized(newext),\n\t\t\t\text4_ext_get_actual_len(newext),\n\t\t\t\tnearex, len, nearex + 1, nearex + 2);\n\t\tmemmove(nearex + 1, nearex, len);\n\t\tpath[depth].p_ext = nearex;\n\t}\n\n\tle16_add_cpu(&eh->eh_entries, 1);\n\tnearex = path[depth].p_ext;\n\tnearex->ee_block = newext->ee_block;\n\text4_ext_store_pblock(nearex, ext4_ext_pblock(newext));\n\tnearex->ee_len = newext->ee_len;\n\nmerge:\n\t/* try to merge extents to the right */\n\tif (!(flag & EXT4_GET_BLOCKS_PRE_IO))\n\t\text4_ext_try_to_merge(inode, path, nearex);\n\n\t/* try to merge extents to the left */\n\n\t/* time to correct all indexes above */\n\terr = ext4_ext_correct_indexes(handle, inode, path);\n\tif (err)\n\t\tgoto cleanup;\n\n\terr = ext4_ext_dirty(handle, inode, path + depth);\n\ncleanup:\n\tif (npath) {\n\t\text4_ext_drop_refs(npath);\n\t\tkfree(npath);\n\t}\n\text4_ext_invalidate_cache(inode);\n\treturn err;\n}",
        "description": "Multiple off-by-one errors in the ext4 subsystem of the Linux kernel, prior to a specific release candidate, enable local users to trigger a denial of service (resulting in BUG_ON and system crashes) through write operations on sparse files in extent format, particularly when the block number corresponds to the maximum possible 32-bit unsigned integer.",
        "commit": "A vulnerability was identified in the ext4 file system where writing to the last block (2^32-1) of a sparse file in extent format triggers a BUG_ON condition in the ext4_ext_put_gap_in_cache() function. The root cause is that the maximum bytes (s_maxbytes) are set such that the block at s_maxbytes fits into a 32-bit on-disk extent format, but the extent structure stores start block number and length in blocks, requiring EXT_MAX_BLOCK + 1 to cover the entire extent range. To resolve this issue without altering the struct ext4_extent members' meanings, s_maxbytes should be reduced by one filesystem block. Additionally, the commit renames EXT_MAX_BLOCK to EXT_MAX_BLOCKS and adjusts its usage to represent the maximum number of blocks in an extent, addressing inconsistencies in its application throughout the codebase. This bug can be reproduced by sequentially writing to the second-to-last and last blocks of a sparse file using the dd command."
    },
    {
        "cwe": "CWE-121",
        "func_name": "kernel/chap_server_compute_md5",
        "score": 0.7057045698165894,
        "func_before": "static int chap_server_compute_md5(\n\tstruct iscsi_conn *conn,\n\tstruct iscsi_node_auth *auth,\n\tchar *nr_in_ptr,\n\tchar *nr_out_ptr,\n\tunsigned int *nr_out_len)\n{\n\tunsigned long id;\n\tunsigned char id_as_uchar;\n\tunsigned char digest[MD5_SIGNATURE_SIZE];\n\tunsigned char type, response[MD5_SIGNATURE_SIZE * 2 + 2];\n\tunsigned char identifier[10], *challenge = NULL;\n\tunsigned char *challenge_binhex = NULL;\n\tunsigned char client_digest[MD5_SIGNATURE_SIZE];\n\tunsigned char server_digest[MD5_SIGNATURE_SIZE];\n\tunsigned char chap_n[MAX_CHAP_N_SIZE], chap_r[MAX_RESPONSE_LENGTH];\n\tsize_t compare_len;\n\tstruct iscsi_chap *chap = conn->auth_protocol;\n\tstruct crypto_shash *tfm = NULL;\n\tstruct shash_desc *desc = NULL;\n\tint auth_ret = -1, ret, challenge_len;\n\n\tmemset(identifier, 0, 10);\n\tmemset(chap_n, 0, MAX_CHAP_N_SIZE);\n\tmemset(chap_r, 0, MAX_RESPONSE_LENGTH);\n\tmemset(digest, 0, MD5_SIGNATURE_SIZE);\n\tmemset(response, 0, MD5_SIGNATURE_SIZE * 2 + 2);\n\tmemset(client_digest, 0, MD5_SIGNATURE_SIZE);\n\tmemset(server_digest, 0, MD5_SIGNATURE_SIZE);\n\n\tchallenge = kzalloc(CHAP_CHALLENGE_STR_LEN, GFP_KERNEL);\n\tif (!challenge) {\n\t\tpr_err(\"Unable to allocate challenge buffer\\n\");\n\t\tgoto out;\n\t}\n\n\tchallenge_binhex = kzalloc(CHAP_CHALLENGE_STR_LEN, GFP_KERNEL);\n\tif (!challenge_binhex) {\n\t\tpr_err(\"Unable to allocate challenge_binhex buffer\\n\");\n\t\tgoto out;\n\t}\n\t/*\n\t * Extract CHAP_N.\n\t */\n\tif (extract_param(nr_in_ptr, \"CHAP_N\", MAX_CHAP_N_SIZE, chap_n,\n\t\t\t\t&type) < 0) {\n\t\tpr_err(\"Could not find CHAP_N.\\n\");\n\t\tgoto out;\n\t}\n\tif (type == HEX) {\n\t\tpr_err(\"Could not find CHAP_N.\\n\");\n\t\tgoto out;\n\t}\n\n\t/* Include the terminating NULL in the compare */\n\tcompare_len = strlen(auth->userid) + 1;\n\tif (strncmp(chap_n, auth->userid, compare_len) != 0) {\n\t\tpr_err(\"CHAP_N values do not match!\\n\");\n\t\tgoto out;\n\t}\n\tpr_debug(\"[server] Got CHAP_N=%s\\n\", chap_n);\n\t/*\n\t * Extract CHAP_R.\n\t */\n\tif (extract_param(nr_in_ptr, \"CHAP_R\", MAX_RESPONSE_LENGTH, chap_r,\n\t\t\t\t&type) < 0) {\n\t\tpr_err(\"Could not find CHAP_R.\\n\");\n\t\tgoto out;\n\t}\n\tif (type != HEX) {\n\t\tpr_err(\"Could not find CHAP_R.\\n\");\n\t\tgoto out;\n\t}\n\n\tpr_debug(\"[server] Got CHAP_R=%s\\n\", chap_r);\n\tchap_string_to_hex(client_digest, chap_r, strlen(chap_r));\n\n\ttfm = crypto_alloc_shash(\"md5\", 0, 0);\n\tif (IS_ERR(tfm)) {\n\t\ttfm = NULL;\n\t\tpr_err(\"Unable to allocate struct crypto_shash\\n\");\n\t\tgoto out;\n\t}\n\n\tdesc = kmalloc(sizeof(*desc) + crypto_shash_descsize(tfm), GFP_KERNEL);\n\tif (!desc) {\n\t\tpr_err(\"Unable to allocate struct shash_desc\\n\");\n\t\tgoto out;\n\t}\n\n\tdesc->tfm = tfm;\n\tdesc->flags = 0;\n\n\tret = crypto_shash_init(desc);\n\tif (ret < 0) {\n\t\tpr_err(\"crypto_shash_init() failed\\n\");\n\t\tgoto out;\n\t}\n\n\tret = crypto_shash_update(desc, &chap->id, 1);\n\tif (ret < 0) {\n\t\tpr_err(\"crypto_shash_update() failed for id\\n\");\n\t\tgoto out;\n\t}\n\n\tret = crypto_shash_update(desc, (char *)&auth->password,\n\t\t\t\t  strlen(auth->password));\n\tif (ret < 0) {\n\t\tpr_err(\"crypto_shash_update() failed for password\\n\");\n\t\tgoto out;\n\t}\n\n\tret = crypto_shash_finup(desc, chap->challenge,\n\t\t\t\t CHAP_CHALLENGE_LENGTH, server_digest);\n\tif (ret < 0) {\n\t\tpr_err(\"crypto_shash_finup() failed for challenge\\n\");\n\t\tgoto out;\n\t}\n\n\tchap_binaryhex_to_asciihex(response, server_digest, MD5_SIGNATURE_SIZE);\n\tpr_debug(\"[server] MD5 Server Digest: %s\\n\", response);\n\n\tif (memcmp(server_digest, client_digest, MD5_SIGNATURE_SIZE) != 0) {\n\t\tpr_debug(\"[server] MD5 Digests do not match!\\n\\n\");\n\t\tgoto out;\n\t} else\n\t\tpr_debug(\"[server] MD5 Digests match, CHAP connection\"\n\t\t\t\t\" successful.\\n\\n\");\n\t/*\n\t * One way authentication has succeeded, return now if mutual\n\t * authentication is not enabled.\n\t */\n\tif (!auth->authenticate_target) {\n\t\tauth_ret = 0;\n\t\tgoto out;\n\t}\n\t/*\n\t * Get CHAP_I.\n\t */\n\tif (extract_param(nr_in_ptr, \"CHAP_I\", 10, identifier, &type) < 0) {\n\t\tpr_err(\"Could not find CHAP_I.\\n\");\n\t\tgoto out;\n\t}\n\n\tif (type == HEX)\n\t\tret = kstrtoul(&identifier[2], 0, &id);\n\telse\n\t\tret = kstrtoul(identifier, 0, &id);\n\n\tif (ret < 0) {\n\t\tpr_err(\"kstrtoul() failed for CHAP identifier: %d\\n\", ret);\n\t\tgoto out;\n\t}\n\tif (id > 255) {\n\t\tpr_err(\"chap identifier: %lu greater than 255\\n\", id);\n\t\tgoto out;\n\t}\n\t/*\n\t * RFC 1994 says Identifier is no more than octet (8 bits).\n\t */\n\tpr_debug(\"[server] Got CHAP_I=%lu\\n\", id);\n\t/*\n\t * Get CHAP_C.\n\t */\n\tif (extract_param(nr_in_ptr, \"CHAP_C\", CHAP_CHALLENGE_STR_LEN,\n\t\t\tchallenge, &type) < 0) {\n\t\tpr_err(\"Could not find CHAP_C.\\n\");\n\t\tgoto out;\n\t}\n\n\tif (type != HEX) {\n\t\tpr_err(\"Could not find CHAP_C.\\n\");\n\t\tgoto out;\n\t}\n\tpr_debug(\"[server] Got CHAP_C=%s\\n\", challenge);\n\tchallenge_len = chap_string_to_hex(challenge_binhex, challenge,\n\t\t\t\tstrlen(challenge));\n\tif (!challenge_len) {\n\t\tpr_err(\"Unable to convert incoming challenge\\n\");\n\t\tgoto out;\n\t}\n\tif (challenge_len > 1024) {\n\t\tpr_err(\"CHAP_C exceeds maximum binary size of 1024 bytes\\n\");\n\t\tgoto out;\n\t}\n\t/*\n\t * During mutual authentication, the CHAP_C generated by the\n\t * initiator must not match the original CHAP_C generated by\n\t * the target.\n\t */\n\tif (!memcmp(challenge_binhex, chap->challenge, CHAP_CHALLENGE_LENGTH)) {\n\t\tpr_err(\"initiator CHAP_C matches target CHAP_C, failing\"\n\t\t       \" login attempt\\n\");\n\t\tgoto out;\n\t}\n\t/*\n\t * Generate CHAP_N and CHAP_R for mutual authentication.\n\t */\n\tret = crypto_shash_init(desc);\n\tif (ret < 0) {\n\t\tpr_err(\"crypto_shash_init() failed\\n\");\n\t\tgoto out;\n\t}\n\n\t/* To handle both endiannesses */\n\tid_as_uchar = id;\n\tret = crypto_shash_update(desc, &id_as_uchar, 1);\n\tif (ret < 0) {\n\t\tpr_err(\"crypto_shash_update() failed for id\\n\");\n\t\tgoto out;\n\t}\n\n\tret = crypto_shash_update(desc, auth->password_mutual,\n\t\t\t\t  strlen(auth->password_mutual));\n\tif (ret < 0) {\n\t\tpr_err(\"crypto_shash_update() failed for\"\n\t\t\t\t\" password_mutual\\n\");\n\t\tgoto out;\n\t}\n\t/*\n\t * Convert received challenge to binary hex.\n\t */\n\tret = crypto_shash_finup(desc, challenge_binhex, challenge_len,\n\t\t\t\t digest);\n\tif (ret < 0) {\n\t\tpr_err(\"crypto_shash_finup() failed for ma challenge\\n\");\n\t\tgoto out;\n\t}\n\n\t/*\n\t * Generate CHAP_N and CHAP_R.\n\t */\n\t*nr_out_len = sprintf(nr_out_ptr, \"CHAP_N=%s\", auth->userid_mutual);\n\t*nr_out_len += 1;\n\tpr_debug(\"[server] Sending CHAP_N=%s\\n\", auth->userid_mutual);\n\t/*\n\t * Convert response from binary hex to ascii hext.\n\t */\n\tchap_binaryhex_to_asciihex(response, digest, MD5_SIGNATURE_SIZE);\n\t*nr_out_len += sprintf(nr_out_ptr + *nr_out_len, \"CHAP_R=0x%s\",\n\t\t\tresponse);\n\t*nr_out_len += 1;\n\tpr_debug(\"[server] Sending CHAP_R=0x%s\\n\", response);\n\tauth_ret = 0;\nout:\n\tkzfree(desc);\n\tif (tfm)\n\t\tcrypto_free_shash(tfm);\n\tkfree(challenge);\n\tkfree(challenge_binhex);\n\treturn auth_ret;\n}",
        "func_after": "static int chap_server_compute_md5(\n\tstruct iscsi_conn *conn,\n\tstruct iscsi_node_auth *auth,\n\tchar *nr_in_ptr,\n\tchar *nr_out_ptr,\n\tunsigned int *nr_out_len)\n{\n\tunsigned long id;\n\tunsigned char id_as_uchar;\n\tunsigned char digest[MD5_SIGNATURE_SIZE];\n\tunsigned char type, response[MD5_SIGNATURE_SIZE * 2 + 2];\n\tunsigned char identifier[10], *challenge = NULL;\n\tunsigned char *challenge_binhex = NULL;\n\tunsigned char client_digest[MD5_SIGNATURE_SIZE];\n\tunsigned char server_digest[MD5_SIGNATURE_SIZE];\n\tunsigned char chap_n[MAX_CHAP_N_SIZE], chap_r[MAX_RESPONSE_LENGTH];\n\tsize_t compare_len;\n\tstruct iscsi_chap *chap = conn->auth_protocol;\n\tstruct crypto_shash *tfm = NULL;\n\tstruct shash_desc *desc = NULL;\n\tint auth_ret = -1, ret, challenge_len;\n\n\tmemset(identifier, 0, 10);\n\tmemset(chap_n, 0, MAX_CHAP_N_SIZE);\n\tmemset(chap_r, 0, MAX_RESPONSE_LENGTH);\n\tmemset(digest, 0, MD5_SIGNATURE_SIZE);\n\tmemset(response, 0, MD5_SIGNATURE_SIZE * 2 + 2);\n\tmemset(client_digest, 0, MD5_SIGNATURE_SIZE);\n\tmemset(server_digest, 0, MD5_SIGNATURE_SIZE);\n\n\tchallenge = kzalloc(CHAP_CHALLENGE_STR_LEN, GFP_KERNEL);\n\tif (!challenge) {\n\t\tpr_err(\"Unable to allocate challenge buffer\\n\");\n\t\tgoto out;\n\t}\n\n\tchallenge_binhex = kzalloc(CHAP_CHALLENGE_STR_LEN, GFP_KERNEL);\n\tif (!challenge_binhex) {\n\t\tpr_err(\"Unable to allocate challenge_binhex buffer\\n\");\n\t\tgoto out;\n\t}\n\t/*\n\t * Extract CHAP_N.\n\t */\n\tif (extract_param(nr_in_ptr, \"CHAP_N\", MAX_CHAP_N_SIZE, chap_n,\n\t\t\t\t&type) < 0) {\n\t\tpr_err(\"Could not find CHAP_N.\\n\");\n\t\tgoto out;\n\t}\n\tif (type == HEX) {\n\t\tpr_err(\"Could not find CHAP_N.\\n\");\n\t\tgoto out;\n\t}\n\n\t/* Include the terminating NULL in the compare */\n\tcompare_len = strlen(auth->userid) + 1;\n\tif (strncmp(chap_n, auth->userid, compare_len) != 0) {\n\t\tpr_err(\"CHAP_N values do not match!\\n\");\n\t\tgoto out;\n\t}\n\tpr_debug(\"[server] Got CHAP_N=%s\\n\", chap_n);\n\t/*\n\t * Extract CHAP_R.\n\t */\n\tif (extract_param(nr_in_ptr, \"CHAP_R\", MAX_RESPONSE_LENGTH, chap_r,\n\t\t\t\t&type) < 0) {\n\t\tpr_err(\"Could not find CHAP_R.\\n\");\n\t\tgoto out;\n\t}\n\tif (type != HEX) {\n\t\tpr_err(\"Could not find CHAP_R.\\n\");\n\t\tgoto out;\n\t}\n\tif (strlen(chap_r) != MD5_SIGNATURE_SIZE * 2) {\n\t\tpr_err(\"Malformed CHAP_R\\n\");\n\t\tgoto out;\n\t}\n\tif (hex2bin(client_digest, chap_r, MD5_SIGNATURE_SIZE) < 0) {\n\t\tpr_err(\"Malformed CHAP_R\\n\");\n\t\tgoto out;\n\t}\n\n\tpr_debug(\"[server] Got CHAP_R=%s\\n\", chap_r);\n\n\ttfm = crypto_alloc_shash(\"md5\", 0, 0);\n\tif (IS_ERR(tfm)) {\n\t\ttfm = NULL;\n\t\tpr_err(\"Unable to allocate struct crypto_shash\\n\");\n\t\tgoto out;\n\t}\n\n\tdesc = kmalloc(sizeof(*desc) + crypto_shash_descsize(tfm), GFP_KERNEL);\n\tif (!desc) {\n\t\tpr_err(\"Unable to allocate struct shash_desc\\n\");\n\t\tgoto out;\n\t}\n\n\tdesc->tfm = tfm;\n\tdesc->flags = 0;\n\n\tret = crypto_shash_init(desc);\n\tif (ret < 0) {\n\t\tpr_err(\"crypto_shash_init() failed\\n\");\n\t\tgoto out;\n\t}\n\n\tret = crypto_shash_update(desc, &chap->id, 1);\n\tif (ret < 0) {\n\t\tpr_err(\"crypto_shash_update() failed for id\\n\");\n\t\tgoto out;\n\t}\n\n\tret = crypto_shash_update(desc, (char *)&auth->password,\n\t\t\t\t  strlen(auth->password));\n\tif (ret < 0) {\n\t\tpr_err(\"crypto_shash_update() failed for password\\n\");\n\t\tgoto out;\n\t}\n\n\tret = crypto_shash_finup(desc, chap->challenge,\n\t\t\t\t CHAP_CHALLENGE_LENGTH, server_digest);\n\tif (ret < 0) {\n\t\tpr_err(\"crypto_shash_finup() failed for challenge\\n\");\n\t\tgoto out;\n\t}\n\n\tchap_binaryhex_to_asciihex(response, server_digest, MD5_SIGNATURE_SIZE);\n\tpr_debug(\"[server] MD5 Server Digest: %s\\n\", response);\n\n\tif (memcmp(server_digest, client_digest, MD5_SIGNATURE_SIZE) != 0) {\n\t\tpr_debug(\"[server] MD5 Digests do not match!\\n\\n\");\n\t\tgoto out;\n\t} else\n\t\tpr_debug(\"[server] MD5 Digests match, CHAP connection\"\n\t\t\t\t\" successful.\\n\\n\");\n\t/*\n\t * One way authentication has succeeded, return now if mutual\n\t * authentication is not enabled.\n\t */\n\tif (!auth->authenticate_target) {\n\t\tauth_ret = 0;\n\t\tgoto out;\n\t}\n\t/*\n\t * Get CHAP_I.\n\t */\n\tif (extract_param(nr_in_ptr, \"CHAP_I\", 10, identifier, &type) < 0) {\n\t\tpr_err(\"Could not find CHAP_I.\\n\");\n\t\tgoto out;\n\t}\n\n\tif (type == HEX)\n\t\tret = kstrtoul(&identifier[2], 0, &id);\n\telse\n\t\tret = kstrtoul(identifier, 0, &id);\n\n\tif (ret < 0) {\n\t\tpr_err(\"kstrtoul() failed for CHAP identifier: %d\\n\", ret);\n\t\tgoto out;\n\t}\n\tif (id > 255) {\n\t\tpr_err(\"chap identifier: %lu greater than 255\\n\", id);\n\t\tgoto out;\n\t}\n\t/*\n\t * RFC 1994 says Identifier is no more than octet (8 bits).\n\t */\n\tpr_debug(\"[server] Got CHAP_I=%lu\\n\", id);\n\t/*\n\t * Get CHAP_C.\n\t */\n\tif (extract_param(nr_in_ptr, \"CHAP_C\", CHAP_CHALLENGE_STR_LEN,\n\t\t\tchallenge, &type) < 0) {\n\t\tpr_err(\"Could not find CHAP_C.\\n\");\n\t\tgoto out;\n\t}\n\n\tif (type != HEX) {\n\t\tpr_err(\"Could not find CHAP_C.\\n\");\n\t\tgoto out;\n\t}\n\tchallenge_len = DIV_ROUND_UP(strlen(challenge), 2);\n\tif (!challenge_len) {\n\t\tpr_err(\"Unable to convert incoming challenge\\n\");\n\t\tgoto out;\n\t}\n\tif (challenge_len > 1024) {\n\t\tpr_err(\"CHAP_C exceeds maximum binary size of 1024 bytes\\n\");\n\t\tgoto out;\n\t}\n\tif (hex2bin(challenge_binhex, challenge, challenge_len) < 0) {\n\t\tpr_err(\"Malformed CHAP_C\\n\");\n\t\tgoto out;\n\t}\n\tpr_debug(\"[server] Got CHAP_C=%s\\n\", challenge);\n\t/*\n\t * During mutual authentication, the CHAP_C generated by the\n\t * initiator must not match the original CHAP_C generated by\n\t * the target.\n\t */\n\tif (!memcmp(challenge_binhex, chap->challenge, CHAP_CHALLENGE_LENGTH)) {\n\t\tpr_err(\"initiator CHAP_C matches target CHAP_C, failing\"\n\t\t       \" login attempt\\n\");\n\t\tgoto out;\n\t}\n\t/*\n\t * Generate CHAP_N and CHAP_R for mutual authentication.\n\t */\n\tret = crypto_shash_init(desc);\n\tif (ret < 0) {\n\t\tpr_err(\"crypto_shash_init() failed\\n\");\n\t\tgoto out;\n\t}\n\n\t/* To handle both endiannesses */\n\tid_as_uchar = id;\n\tret = crypto_shash_update(desc, &id_as_uchar, 1);\n\tif (ret < 0) {\n\t\tpr_err(\"crypto_shash_update() failed for id\\n\");\n\t\tgoto out;\n\t}\n\n\tret = crypto_shash_update(desc, auth->password_mutual,\n\t\t\t\t  strlen(auth->password_mutual));\n\tif (ret < 0) {\n\t\tpr_err(\"crypto_shash_update() failed for\"\n\t\t\t\t\" password_mutual\\n\");\n\t\tgoto out;\n\t}\n\t/*\n\t * Convert received challenge to binary hex.\n\t */\n\tret = crypto_shash_finup(desc, challenge_binhex, challenge_len,\n\t\t\t\t digest);\n\tif (ret < 0) {\n\t\tpr_err(\"crypto_shash_finup() failed for ma challenge\\n\");\n\t\tgoto out;\n\t}\n\n\t/*\n\t * Generate CHAP_N and CHAP_R.\n\t */\n\t*nr_out_len = sprintf(nr_out_ptr, \"CHAP_N=%s\", auth->userid_mutual);\n\t*nr_out_len += 1;\n\tpr_debug(\"[server] Sending CHAP_N=%s\\n\", auth->userid_mutual);\n\t/*\n\t * Convert response from binary hex to ascii hext.\n\t */\n\tchap_binaryhex_to_asciihex(response, digest, MD5_SIGNATURE_SIZE);\n\t*nr_out_len += sprintf(nr_out_ptr + *nr_out_len, \"CHAP_R=0x%s\",\n\t\t\tresponse);\n\t*nr_out_len += 1;\n\tpr_debug(\"[server] Sending CHAP_R=0x%s\\n\", response);\n\tauth_ret = 0;\nout:\n\tkzfree(desc);\n\tif (tfm)\n\t\tcrypto_free_shash(tfm);\n\tkfree(challenge);\n\tkfree(challenge_binhex);\n\treturn auth_ret;\n}",
        "description": "A security flaw exists in the chap_server_compute_md5() function within the ISCSI target code of the Linux kernel, where an unauthenticated remote attacker can exploit a stack buffer overflow to overwrite up to 17 bytes of the stack. This vulnerability arises during the processing of an authentication request from an ISCSI initiator. For an attack to be successful, the iSCSI target must be enabled on the victim host. The impact of the overflow varies based on the target's build environment, including the compiler, compile flags, and hardware architecture, potentially leading to a system crash, denial-of-service, or unauthorized access to data exported by the iSCSI target. Although privilege escalation is not conclusively proven, it remains a concern. This vulnerability affects kernel versions 4.18.x, 4.14.x, and 3.10.x.",
        "commit": "Please provide the specific vulnerability knowledge you would like me to abstract and generalize."
    },
    {
        "cwe": "CWE-444",
        "func_name": "haproxy/http_parse_cont_len_header",
        "score": 0.6828178763389587,
        "func_before": "int http_parse_cont_len_header(struct ist *value, unsigned long long *body_len,\n                               int not_first)\n{\n\tchar *e, *n;\n\tunsigned long long cl;\n\tstruct ist word;\n\tint check_prev = not_first;\n\n\tword.ptr = value->ptr - 1; // -1 for next loop's pre-increment\n\te = value->ptr + value->len;\n\n\twhile (++word.ptr < e) {\n\t\t/* skip leading delimiter and blanks */\n\t\tif (unlikely(HTTP_IS_LWS(*word.ptr)))\n\t\t\tcontinue;\n\n\t\t/* digits only now */\n\t\tfor (cl = 0, n = word.ptr; n < e; n++) {\n\t\t\tunsigned int c = *n - '0';\n\t\t\tif (unlikely(c > 9)) {\n\t\t\t\t/* non-digit */\n\t\t\t\tif (unlikely(n == word.ptr)) // spaces only\n\t\t\t\t\tgoto fail;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (unlikely(cl > ULLONG_MAX / 10ULL))\n\t\t\t\tgoto fail; /* multiply overflow */\n\t\t\tcl = cl * 10ULL;\n\t\t\tif (unlikely(cl + c < cl))\n\t\t\t\tgoto fail; /* addition overflow */\n\t\t\tcl = cl + c;\n\t\t}\n\n\t\t/* keep a copy of the exact cleaned value */\n\t\tword.len = n - word.ptr;\n\n\t\t/* skip trailing LWS till next comma or EOL */\n\t\tfor (; n < e; n++) {\n\t\t\tif (!HTTP_IS_LWS(*n)) {\n\t\t\t\tif (unlikely(*n != ','))\n\t\t\t\t\tgoto fail;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\t/* if duplicate, must be equal */\n\t\tif (check_prev && cl != *body_len)\n\t\t\tgoto fail;\n\n\t\t/* OK, store this result as the one to be indexed */\n\t\t*body_len = cl;\n\t\t*value = word;\n\t\tword.ptr = n;\n\t\tcheck_prev = 1;\n\t}\n\n\t/* here we've reached the end with a single value or a series of\n\t * identical values, all matching previous series if any. The last\n\t * parsed value was sent back into <value>. We just have to decide\n\t * if this occurrence has to be indexed (it's the first one) or\n\t * silently skipped (it's not the first one)\n\t */\n\treturn !not_first;\n fail:\n\treturn -1;\n}",
        "func_after": "int http_parse_cont_len_header(struct ist *value, unsigned long long *body_len,\n                               int not_first)\n{\n\tchar *e, *n;\n\tunsigned long long cl;\n\tstruct ist word;\n\tint check_prev = not_first;\n\n\tword.ptr = value->ptr;\n\te = value->ptr + value->len;\n\n\twhile (1) {\n\t\tif (word.ptr >= e) {\n\t\t\t/* empty header or empty value */\n\t\t\tgoto fail;\n\t\t}\n\n\t\t/* skip leading delimiter and blanks */\n\t\tif (unlikely(HTTP_IS_LWS(*word.ptr))) {\n\t\t\tword.ptr++;\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* digits only now */\n\t\tfor (cl = 0, n = word.ptr; n < e; n++) {\n\t\t\tunsigned int c = *n - '0';\n\t\t\tif (unlikely(c > 9)) {\n\t\t\t\t/* non-digit */\n\t\t\t\tif (unlikely(n == word.ptr)) // spaces only\n\t\t\t\t\tgoto fail;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (unlikely(cl > ULLONG_MAX / 10ULL))\n\t\t\t\tgoto fail; /* multiply overflow */\n\t\t\tcl = cl * 10ULL;\n\t\t\tif (unlikely(cl + c < cl))\n\t\t\t\tgoto fail; /* addition overflow */\n\t\t\tcl = cl + c;\n\t\t}\n\n\t\t/* keep a copy of the exact cleaned value */\n\t\tword.len = n - word.ptr;\n\n\t\t/* skip trailing LWS till next comma or EOL */\n\t\tfor (; n < e; n++) {\n\t\t\tif (!HTTP_IS_LWS(*n)) {\n\t\t\t\tif (unlikely(*n != ','))\n\t\t\t\t\tgoto fail;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\t/* if duplicate, must be equal */\n\t\tif (check_prev && cl != *body_len)\n\t\t\tgoto fail;\n\n\t\t/* OK, store this result as the one to be indexed */\n\t\t*body_len = cl;\n\t\t*value = word;\n\n\t\t/* Now either n==e and we're done, or n points to the comma,\n\t\t * and we skip it and continue.\n\t\t */\n\t\tif (n++ == e)\n\t\t\tbreak;\n\n\t\tword.ptr = n;\n\t\tcheck_prev = 1;\n\t}\n\n\t/* here we've reached the end with a single value or a series of\n\t * identical values, all matching previous series if any. The last\n\t * parsed value was sent back into <value>. We just have to decide\n\t * if this occurrence has to be indexed (it's the first one) or\n\t * silently skipped (it's not the first one)\n\t */\n\treturn !not_first;\n fail:\n\treturn -1;\n}",
        "description": "HAProxy versions up to 2.0.32, 2.1.x, 2.2.x through 2.2.30, 2.3.x, 2.4.x through 2.4.23, 2.5.x, and 2.6.x before 2.6.15, 2.7.x before 2.7.10, and 2.8.x before 2.8.2 forward empty Content-Length headers, which violates RFC 9110 section 8.6. In rare scenarios, an HTTP/1 server positioned behind HAProxy may misinterpret the payload as an additional request.",
        "commit": "A vulnerability was identified in the HTTP content-length header parsing mechanism, where an empty or trailing-comma value could be misinterpreted as an absent header. This oversight allowed such headers to pass through to the backend server without proper validation, potentially exposing vulnerable servers to attacks. The risk varies based on the backend server's handling of content-length headers, but users relying on HAProxy to protect known-vulnerable servers are particularly at risk. A configuration-based workaround involves explicitly rejecting requests with empty content-length headers in the frontend settings. The permanent fix requires modifying the parser to ensure that only valid values are accepted, rejecting any empty values encountered. This change needs to be applied across all supported versions of the software. The modifications were made to functions such as `h1_parse_cont_len_header()` and `http_parse_cont_len_header()`, with additional considerations for compatibility with Lua and future deprecation plans. Comprehensive testing was conducted to validate these changes."
    },
    {
        "cwe": "CWE-662",
        "func_name": "torvalds/do_fontx_ioctl",
        "score": 0.6881072521209717,
        "func_before": "static inline int do_fontx_ioctl(int cmd,\n\t\tstruct consolefontdesc __user *user_cfd,\n\t\tstruct console_font_op *op)\n{\n\tstruct consolefontdesc cfdarg;\n\tint i;\n\n\tif (copy_from_user(&cfdarg, user_cfd, sizeof(struct consolefontdesc)))\n\t\treturn -EFAULT;\n\n\tswitch (cmd) {\n\tcase PIO_FONTX:\n\t\top->op = KD_FONT_OP_SET;\n\t\top->flags = KD_FONT_FLAG_OLD;\n\t\top->width = 8;\n\t\top->height = cfdarg.charheight;\n\t\top->charcount = cfdarg.charcount;\n\t\top->data = cfdarg.chardata;\n\t\treturn con_font_op(vc_cons[fg_console].d, op);\n\tcase GIO_FONTX: {\n\t\top->op = KD_FONT_OP_GET;\n\t\top->flags = KD_FONT_FLAG_OLD;\n\t\top->width = 8;\n\t\top->height = cfdarg.charheight;\n\t\top->charcount = cfdarg.charcount;\n\t\top->data = cfdarg.chardata;\n\t\ti = con_font_op(vc_cons[fg_console].d, op);\n\t\tif (i)\n\t\t\treturn i;\n\t\tcfdarg.charheight = op->height;\n\t\tcfdarg.charcount = op->charcount;\n\t\tif (copy_to_user(user_cfd, &cfdarg, sizeof(struct consolefontdesc)))\n\t\t\treturn -EFAULT;\n\t\treturn 0;\n\t\t}\n\t}\n\treturn -EINVAL;\n}",
        "func_after": "static inline int do_fontx_ioctl(struct vc_data *vc, int cmd,\n\t\tstruct consolefontdesc __user *user_cfd,\n\t\tstruct console_font_op *op)\n{\n\tstruct consolefontdesc cfdarg;\n\tint i;\n\n\tif (copy_from_user(&cfdarg, user_cfd, sizeof(struct consolefontdesc)))\n\t\treturn -EFAULT;\n\n\tswitch (cmd) {\n\tcase PIO_FONTX:\n\t\top->op = KD_FONT_OP_SET;\n\t\top->flags = KD_FONT_FLAG_OLD;\n\t\top->width = 8;\n\t\top->height = cfdarg.charheight;\n\t\top->charcount = cfdarg.charcount;\n\t\top->data = cfdarg.chardata;\n\t\treturn con_font_op(vc, op);\n\n\tcase GIO_FONTX:\n\t\top->op = KD_FONT_OP_GET;\n\t\top->flags = KD_FONT_FLAG_OLD;\n\t\top->width = 8;\n\t\top->height = cfdarg.charheight;\n\t\top->charcount = cfdarg.charcount;\n\t\top->data = cfdarg.chardata;\n\t\ti = con_font_op(vc, op);\n\t\tif (i)\n\t\t\treturn i;\n\t\tcfdarg.charheight = op->height;\n\t\tcfdarg.charcount = op->charcount;\n\t\tif (copy_to_user(user_cfd, &cfdarg, sizeof(struct consolefontdesc)))\n\t\t\treturn -EFAULT;\n\t\treturn 0;\n\t}\n\treturn -EINVAL;\n}",
        "description": "A flaw was identified in the Linux Kernel where access to a global variable used for managing the foreground console is not adequately synchronized, resulting in a use-after-free error within the function responsible for font operations.",
        "commit": "Some font-related terminal I/O control operations previously utilized the current foreground virtual console (VC) for their execution. This practice has been discontinued to address a data race condition involving the `fg_console` variable. Notably, both Michael Ellerman and Jiri Slaby have observed that these I/O control operations are deprecated and should have been removed earlier. They suggest that most systems now use the `KDFONTOP` ioctl instead. Additionally, Michael notes that BusyBox's `loadfont` program transitioned to using `KDFONTOP` precisely due to this bug, which was identified approximately 12 years ago."
    },
    {
        "cwe": "CWE-119",
        "func_name": "torvalds/hugetlb_mcopy_atomic_pte",
        "score": 0.7093725204467773,
        "func_before": "int hugetlb_mcopy_atomic_pte(struct mm_struct *dst_mm,\n\t\t\t    pte_t *dst_pte,\n\t\t\t    struct vm_area_struct *dst_vma,\n\t\t\t    unsigned long dst_addr,\n\t\t\t    unsigned long src_addr,\n\t\t\t    struct page **pagep)\n{\n\tint vm_shared = dst_vma->vm_flags & VM_SHARED;\n\tstruct hstate *h = hstate_vma(dst_vma);\n\tpte_t _dst_pte;\n\tspinlock_t *ptl;\n\tint ret;\n\tstruct page *page;\n\n\tif (!*pagep) {\n\t\tret = -ENOMEM;\n\t\tpage = alloc_huge_page(dst_vma, dst_addr, 0);\n\t\tif (IS_ERR(page))\n\t\t\tgoto out;\n\n\t\tret = copy_huge_page_from_user(page,\n\t\t\t\t\t\t(const void __user *) src_addr,\n\t\t\t\t\t\tpages_per_huge_page(h), false);\n\n\t\t/* fallback to copy_from_user outside mmap_sem */\n\t\tif (unlikely(ret)) {\n\t\t\tret = -EFAULT;\n\t\t\t*pagep = page;\n\t\t\t/* don't free the page */\n\t\t\tgoto out;\n\t\t}\n\t} else {\n\t\tpage = *pagep;\n\t\t*pagep = NULL;\n\t}\n\n\t/*\n\t * The memory barrier inside __SetPageUptodate makes sure that\n\t * preceding stores to the page contents become visible before\n\t * the set_pte_at() write.\n\t */\n\t__SetPageUptodate(page);\n\tset_page_huge_active(page);\n\n\t/*\n\t * If shared, add to page cache\n\t */\n\tif (vm_shared) {\n\t\tstruct address_space *mapping = dst_vma->vm_file->f_mapping;\n\t\tpgoff_t idx = vma_hugecache_offset(h, dst_vma, dst_addr);\n\n\t\tret = huge_add_to_page_cache(page, mapping, idx);\n\t\tif (ret)\n\t\t\tgoto out_release_nounlock;\n\t}\n\n\tptl = huge_pte_lockptr(h, dst_mm, dst_pte);\n\tspin_lock(ptl);\n\n\tret = -EEXIST;\n\tif (!huge_pte_none(huge_ptep_get(dst_pte)))\n\t\tgoto out_release_unlock;\n\n\tif (vm_shared) {\n\t\tpage_dup_rmap(page, true);\n\t} else {\n\t\tClearPagePrivate(page);\n\t\thugepage_add_new_anon_rmap(page, dst_vma, dst_addr);\n\t}\n\n\t_dst_pte = make_huge_pte(dst_vma, page, dst_vma->vm_flags & VM_WRITE);\n\tif (dst_vma->vm_flags & VM_WRITE)\n\t\t_dst_pte = huge_pte_mkdirty(_dst_pte);\n\t_dst_pte = pte_mkyoung(_dst_pte);\n\n\tset_huge_pte_at(dst_mm, dst_addr, dst_pte, _dst_pte);\n\n\t(void)huge_ptep_set_access_flags(dst_vma, dst_addr, dst_pte, _dst_pte,\n\t\t\t\t\tdst_vma->vm_flags & VM_WRITE);\n\thugetlb_count_add(pages_per_huge_page(h), dst_mm);\n\n\t/* No need to invalidate - it was non-present before */\n\tupdate_mmu_cache(dst_vma, dst_addr, dst_pte);\n\n\tspin_unlock(ptl);\n\tif (vm_shared)\n\t\tunlock_page(page);\n\tret = 0;\nout:\n\treturn ret;\nout_release_unlock:\n\tspin_unlock(ptl);\n\tif (vm_shared)\n\t\tunlock_page(page);\nout_release_nounlock:\n\tput_page(page);\n\tgoto out;\n}",
        "func_after": "int hugetlb_mcopy_atomic_pte(struct mm_struct *dst_mm,\n\t\t\t    pte_t *dst_pte,\n\t\t\t    struct vm_area_struct *dst_vma,\n\t\t\t    unsigned long dst_addr,\n\t\t\t    unsigned long src_addr,\n\t\t\t    struct page **pagep)\n{\n\tstruct address_space *mapping;\n\tpgoff_t idx;\n\tunsigned long size;\n\tint vm_shared = dst_vma->vm_flags & VM_SHARED;\n\tstruct hstate *h = hstate_vma(dst_vma);\n\tpte_t _dst_pte;\n\tspinlock_t *ptl;\n\tint ret;\n\tstruct page *page;\n\n\tif (!*pagep) {\n\t\tret = -ENOMEM;\n\t\tpage = alloc_huge_page(dst_vma, dst_addr, 0);\n\t\tif (IS_ERR(page))\n\t\t\tgoto out;\n\n\t\tret = copy_huge_page_from_user(page,\n\t\t\t\t\t\t(const void __user *) src_addr,\n\t\t\t\t\t\tpages_per_huge_page(h), false);\n\n\t\t/* fallback to copy_from_user outside mmap_sem */\n\t\tif (unlikely(ret)) {\n\t\t\tret = -EFAULT;\n\t\t\t*pagep = page;\n\t\t\t/* don't free the page */\n\t\t\tgoto out;\n\t\t}\n\t} else {\n\t\tpage = *pagep;\n\t\t*pagep = NULL;\n\t}\n\n\t/*\n\t * The memory barrier inside __SetPageUptodate makes sure that\n\t * preceding stores to the page contents become visible before\n\t * the set_pte_at() write.\n\t */\n\t__SetPageUptodate(page);\n\tset_page_huge_active(page);\n\n\tmapping = dst_vma->vm_file->f_mapping;\n\tidx = vma_hugecache_offset(h, dst_vma, dst_addr);\n\n\t/*\n\t * If shared, add to page cache\n\t */\n\tif (vm_shared) {\n\t\tsize = i_size_read(mapping->host) >> huge_page_shift(h);\n\t\tret = -EFAULT;\n\t\tif (idx >= size)\n\t\t\tgoto out_release_nounlock;\n\n\t\t/*\n\t\t * Serialization between remove_inode_hugepages() and\n\t\t * huge_add_to_page_cache() below happens through the\n\t\t * hugetlb_fault_mutex_table that here must be hold by\n\t\t * the caller.\n\t\t */\n\t\tret = huge_add_to_page_cache(page, mapping, idx);\n\t\tif (ret)\n\t\t\tgoto out_release_nounlock;\n\t}\n\n\tptl = huge_pte_lockptr(h, dst_mm, dst_pte);\n\tspin_lock(ptl);\n\n\t/*\n\t * Recheck the i_size after holding PT lock to make sure not\n\t * to leave any page mapped (as page_mapped()) beyond the end\n\t * of the i_size (remove_inode_hugepages() is strict about\n\t * enforcing that). If we bail out here, we'll also leave a\n\t * page in the radix tree in the vm_shared case beyond the end\n\t * of the i_size, but remove_inode_hugepages() will take care\n\t * of it as soon as we drop the hugetlb_fault_mutex_table.\n\t */\n\tsize = i_size_read(mapping->host) >> huge_page_shift(h);\n\tret = -EFAULT;\n\tif (idx >= size)\n\t\tgoto out_release_unlock;\n\n\tret = -EEXIST;\n\tif (!huge_pte_none(huge_ptep_get(dst_pte)))\n\t\tgoto out_release_unlock;\n\n\tif (vm_shared) {\n\t\tpage_dup_rmap(page, true);\n\t} else {\n\t\tClearPagePrivate(page);\n\t\thugepage_add_new_anon_rmap(page, dst_vma, dst_addr);\n\t}\n\n\t_dst_pte = make_huge_pte(dst_vma, page, dst_vma->vm_flags & VM_WRITE);\n\tif (dst_vma->vm_flags & VM_WRITE)\n\t\t_dst_pte = huge_pte_mkdirty(_dst_pte);\n\t_dst_pte = pte_mkyoung(_dst_pte);\n\n\tset_huge_pte_at(dst_mm, dst_addr, dst_pte, _dst_pte);\n\n\t(void)huge_ptep_set_access_flags(dst_vma, dst_addr, dst_pte, _dst_pte,\n\t\t\t\t\tdst_vma->vm_flags & VM_WRITE);\n\thugetlb_count_add(pages_per_huge_page(h), dst_mm);\n\n\t/* No need to invalidate - it was non-present before */\n\tupdate_mmu_cache(dst_vma, dst_addr, dst_pte);\n\n\tspin_unlock(ptl);\n\tif (vm_shared)\n\t\tunlock_page(page);\n\tret = 0;\nout:\n\treturn ret;\nout_release_unlock:\n\tspin_unlock(ptl);\n\tif (vm_shared)\n\t\tunlock_page(page);\nout_release_nounlock:\n\tput_page(page);\n\tgoto out;\n}",
        "description": "A flaw was identified in the hugetlb_mcopy_atomic_pte function within the Linux kernel's memory management module, affecting versions prior to 4.13.12. The absence of a proper size check in this function could lead to a denial of service condition, indicated by a BUG.",
        "commit": "A vulnerability was identified in the userfaultfd functionality related to hugetlbfs, where the UFFDIO_COPY operation could inadvertently extend beyond the intended size of the file (i_size). This issue led to a kernel panic (oops) at fs/hugetlbfs/inode.c:484, triggered by the absence of an i_size check in the hugetlb_mcopy_atomic_pte function. Although mmap() operations could succeed beyond the end of the i_size after vmtruncate had removed virtual memory areas (vmas) in those ranges, subsequent faults, including UFFDIO_COPY, should not be allowed to succeed. The proposed solution involves modifying the return value to userland to indicate a SIGBUS-like condition, similar to what a page fault would produce, but this approach was deemed less useful due to the difficulty in distinguishing between SIGSEGV and SIGBUS through meaningful syscall return values."
    }
]