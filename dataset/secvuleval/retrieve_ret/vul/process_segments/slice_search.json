[
    {
        "cwe": "CWE-415",
        "func_name": "binutils-gdb/get_num_dynamic_syms",
        "score": 0.6926532983779907,
        "func_before": "static unsigned long\nget_num_dynamic_syms (Filedata * filedata)\n{\n  unsigned long num_of_syms = 0;\n\n  if (!do_histogram && (!do_using_dynamic || do_dyn_syms))\n    return num_of_syms;\n\n  if (dynamic_info[DT_HASH])\n    {\n      unsigned char nb[8];\n      unsigned char nc[8];\n      unsigned int hash_ent_size = 4;\n\n      if ((filedata->file_header.e_machine == EM_ALPHA\n\t   || filedata->file_header.e_machine == EM_S390\n\t   || filedata->file_header.e_machine == EM_S390_OLD)\n\t  && filedata->file_header.e_ident[EI_CLASS] == ELFCLASS64)\n\thash_ent_size = 8;\n\n      if (fseek (filedata->handle,\n\t\t (archive_file_offset\n\t\t  + offset_from_vma (filedata, dynamic_info[DT_HASH],\n\t\t\t\t     sizeof nb + sizeof nc)),\n\t\t SEEK_SET))\n\t{\n\t  error (_(\"Unable to seek to start of dynamic information\\n\"));\n\t  goto no_hash;\n\t}\n\n      if (fread (nb, hash_ent_size, 1, filedata->handle) != 1)\n\t{\n\t  error (_(\"Failed to read in number of buckets\\n\"));\n\t  goto no_hash;\n\t}\n\n      if (fread (nc, hash_ent_size, 1, filedata->handle) != 1)\n\t{\n\t  error (_(\"Failed to read in number of chains\\n\"));\n\t  goto no_hash;\n\t}\n\n      nbuckets = byte_get (nb, hash_ent_size);\n      nchains = byte_get (nc, hash_ent_size);\n      num_of_syms = nchains;\n\n      buckets = get_dynamic_data (filedata, nbuckets, hash_ent_size);\n      chains  = get_dynamic_data (filedata, nchains, hash_ent_size);\n\n  no_hash:\n      if (num_of_syms == 0)\n\t{\n\t  if (buckets)\n\t    {\n\t      free (buckets);\n\t      buckets = NULL;\n\t    }\n\t  if (chains)\n\t    {\n\t      free (chains);\n\t      buckets = NULL;\n\t    }\n\t  nbuckets = 0;\n\t}\n    }\n\n  if (dynamic_info_DT_GNU_HASH)\n    {\n      unsigned char nb[16];\n      bfd_vma i, maxchain = 0xffffffff, bitmaskwords;\n      bfd_vma buckets_vma;\n      unsigned long hn;\n      bfd_boolean gnu_hash_error = FALSE;\n\n      if (fseek (filedata->handle,\n\t\t (archive_file_offset\n\t\t  + offset_from_vma (filedata, dynamic_info_DT_GNU_HASH,\n\t\t\t\t     sizeof nb)),\n\t\t SEEK_SET))\n\t{\n\t  error (_(\"Unable to seek to start of dynamic information\\n\"));\n\t  gnu_hash_error = TRUE;\n\t  goto no_gnu_hash;\n\t}\n\n      if (fread (nb, 16, 1, filedata->handle) != 1)\n\t{\n\t  error (_(\"Failed to read in number of buckets\\n\"));\n\t  gnu_hash_error = TRUE;\n\t  goto no_gnu_hash;\n\t}\n\n      ngnubuckets = byte_get (nb, 4);\n      gnusymidx = byte_get (nb + 4, 4);\n      bitmaskwords = byte_get (nb + 8, 4);\n      buckets_vma = dynamic_info_DT_GNU_HASH + 16;\n      if (is_32bit_elf)\n\tbuckets_vma += bitmaskwords * 4;\n      else\n\tbuckets_vma += bitmaskwords * 8;\n\n      if (fseek (filedata->handle,\n\t\t (archive_file_offset\n\t\t  + offset_from_vma (filedata, buckets_vma, 4)),\n\t\t SEEK_SET))\n\t{\n\t  error (_(\"Unable to seek to start of dynamic information\\n\"));\n\t  gnu_hash_error = TRUE;\n\t  goto no_gnu_hash;\n\t}\n\n      gnubuckets = get_dynamic_data (filedata, ngnubuckets, 4);\n\n      if (gnubuckets == NULL)\n\t{\n\t  gnu_hash_error = TRUE;\n\t  goto no_gnu_hash;\n\t}\n\n      for (i = 0; i < ngnubuckets; i++)\n\tif (gnubuckets[i] != 0)\n\t  {\n\t    if (gnubuckets[i] < gnusymidx)\n\t      {\n\t\tgnu_hash_error = TRUE;\n\t\treturn FALSE;\n\t      }\n\n\t    if (maxchain == 0xffffffff || gnubuckets[i] > maxchain)\n\t      maxchain = gnubuckets[i];\n\t  }\n\n      if (maxchain == 0xffffffff)\n\t{\n\t  gnu_hash_error = TRUE;\n\t  goto no_gnu_hash;\n\t}\n\n      maxchain -= gnusymidx;\n\n      if (fseek (filedata->handle,\n\t\t (archive_file_offset\n\t\t  + offset_from_vma (filedata, buckets_vma\n\t\t\t\t\t   + 4 * (ngnubuckets + maxchain), 4)),\n\t\t SEEK_SET))\n\t{\n\t  error (_(\"Unable to seek to start of dynamic information\\n\"));\n\t  gnu_hash_error = TRUE;\n\t  goto no_gnu_hash;\n\t}\n\n      do\n\t{\n\t  if (fread (nb, 4, 1, filedata->handle) != 1)\n\t    {\n\t      error (_(\"Failed to determine last chain length\\n\"));\n\t  gnu_hash_error = TRUE;\n\t      goto no_gnu_hash;\n\t    }\n\n\t  if (maxchain + 1 == 0)\n\t    {\n\t      gnu_hash_error = TRUE;\n\t      goto no_gnu_hash;\n\t    }\n\n\t  ++maxchain;\n\t}\n      while ((byte_get (nb, 4) & 1) == 0);\n\n      if (fseek (filedata->handle,\n\t\t (archive_file_offset\n\t\t  + offset_from_vma (filedata, buckets_vma + 4 * ngnubuckets, 4)),\n\t\t SEEK_SET))\n\t{\n\t  error (_(\"Unable to seek to start of dynamic information\\n\"));\n\t  gnu_hash_error = TRUE;\n\t  goto no_gnu_hash;\n\t}\n\n      gnuchains = get_dynamic_data (filedata, maxchain, 4);\n      ngnuchains = maxchain;\n\n      if (gnuchains == NULL)\n\t{\n\t  gnu_hash_error = TRUE;\n\t  goto no_gnu_hash;\n\t}\n\n      if (dynamic_info_DT_MIPS_XHASH)\n\t{\n\t  if (fseek (filedata->handle,\n\t\t     (archive_file_offset\n\t\t      + offset_from_vma (filedata, (buckets_vma\n\t\t\t\t\t\t    + 4 * (ngnubuckets\n\t\t\t\t\t\t\t   + maxchain)), 4)),\n\t\t     SEEK_SET))\n\t    {\n\t      error (_(\"Unable to seek to start of dynamic information\\n\"));\n\t      gnu_hash_error = TRUE;\n\t      goto no_gnu_hash;\n\t    }\n\n\t  mipsxlat = get_dynamic_data (filedata, maxchain, 4);\n\t}\n\n      for (hn = 0; hn < ngnubuckets; ++hn)\n\tif (gnubuckets[hn] != 0)\n\t  {\n\t    bfd_vma si = gnubuckets[hn];\n\t    bfd_vma off = si - gnusymidx;\n\n\t    do\n\t      {\n\t\tif (dynamic_info_DT_MIPS_XHASH)\n\t\t  {\n\t\t    if (mipsxlat[off] >= num_of_syms)\n\t\t      num_of_syms = mipsxlat[off] + 1;\n\t\t  }\n\t\telse\n\t\t  {\n\t\t    if (si >= num_of_syms)\n\t\t      num_of_syms = si + 1;\n\t\t  }\n\t\tsi++;\n\t      }\n\t    while (off < ngnuchains && (gnuchains[off++] & 1) == 0);\n\t  }\n\n  no_gnu_hash:\n      if (gnu_hash_error)\n\t{\n\t  if (mipsxlat)\n\t    {\n\t      free (mipsxlat);\n\t      mipsxlat = NULL;\n\t    }\n\t  if (gnuchains)\n\t    {\n\t      free (gnuchains);\n\t      gnuchains = NULL;\n\t    }\n\t  if (gnubuckets)\n\t    {\n\t      free (gnubuckets);\n\t      gnubuckets = NULL;\n\t    }\n\t  ngnubuckets = 0;\n\t  ngnuchains = 0;\n\t}\n    }\n\n  return num_of_syms;\n}",
        "func_after": "static unsigned long\nget_num_dynamic_syms (Filedata * filedata)\n{\n  unsigned long num_of_syms = 0;\n\n  if (!do_histogram && (!do_using_dynamic || do_dyn_syms))\n    return num_of_syms;\n\n  if (dynamic_info[DT_HASH])\n    {\n      unsigned char nb[8];\n      unsigned char nc[8];\n      unsigned int hash_ent_size = 4;\n\n      if ((filedata->file_header.e_machine == EM_ALPHA\n\t   || filedata->file_header.e_machine == EM_S390\n\t   || filedata->file_header.e_machine == EM_S390_OLD)\n\t  && filedata->file_header.e_ident[EI_CLASS] == ELFCLASS64)\n\thash_ent_size = 8;\n\n      if (fseek (filedata->handle,\n\t\t (archive_file_offset\n\t\t  + offset_from_vma (filedata, dynamic_info[DT_HASH],\n\t\t\t\t     sizeof nb + sizeof nc)),\n\t\t SEEK_SET))\n\t{\n\t  error (_(\"Unable to seek to start of dynamic information\\n\"));\n\t  goto no_hash;\n\t}\n\n      if (fread (nb, hash_ent_size, 1, filedata->handle) != 1)\n\t{\n\t  error (_(\"Failed to read in number of buckets\\n\"));\n\t  goto no_hash;\n\t}\n\n      if (fread (nc, hash_ent_size, 1, filedata->handle) != 1)\n\t{\n\t  error (_(\"Failed to read in number of chains\\n\"));\n\t  goto no_hash;\n\t}\n\n      nbuckets = byte_get (nb, hash_ent_size);\n      nchains = byte_get (nc, hash_ent_size);\n      num_of_syms = nchains;\n\n      buckets = get_dynamic_data (filedata, nbuckets, hash_ent_size);\n      chains  = get_dynamic_data (filedata, nchains, hash_ent_size);\n\n  no_hash:\n      if (num_of_syms == 0)\n\t{\n\t  if (buckets)\n\t    {\n\t      free (buckets);\n\t      buckets = NULL;\n\t    }\n\t  if (chains)\n\t    {\n\t      free (chains);\n\t      chains = NULL;\n\t    }\n\t  nbuckets = 0;\n\t}\n    }\n\n  if (dynamic_info_DT_GNU_HASH)\n    {\n      unsigned char nb[16];\n      bfd_vma i, maxchain = 0xffffffff, bitmaskwords;\n      bfd_vma buckets_vma;\n      unsigned long hn;\n      bfd_boolean gnu_hash_error = FALSE;\n\n      if (fseek (filedata->handle,\n\t\t (archive_file_offset\n\t\t  + offset_from_vma (filedata, dynamic_info_DT_GNU_HASH,\n\t\t\t\t     sizeof nb)),\n\t\t SEEK_SET))\n\t{\n\t  error (_(\"Unable to seek to start of dynamic information\\n\"));\n\t  gnu_hash_error = TRUE;\n\t  goto no_gnu_hash;\n\t}\n\n      if (fread (nb, 16, 1, filedata->handle) != 1)\n\t{\n\t  error (_(\"Failed to read in number of buckets\\n\"));\n\t  gnu_hash_error = TRUE;\n\t  goto no_gnu_hash;\n\t}\n\n      ngnubuckets = byte_get (nb, 4);\n      gnusymidx = byte_get (nb + 4, 4);\n      bitmaskwords = byte_get (nb + 8, 4);\n      buckets_vma = dynamic_info_DT_GNU_HASH + 16;\n      if (is_32bit_elf)\n\tbuckets_vma += bitmaskwords * 4;\n      else\n\tbuckets_vma += bitmaskwords * 8;\n\n      if (fseek (filedata->handle,\n\t\t (archive_file_offset\n\t\t  + offset_from_vma (filedata, buckets_vma, 4)),\n\t\t SEEK_SET))\n\t{\n\t  error (_(\"Unable to seek to start of dynamic information\\n\"));\n\t  gnu_hash_error = TRUE;\n\t  goto no_gnu_hash;\n\t}\n\n      gnubuckets = get_dynamic_data (filedata, ngnubuckets, 4);\n\n      if (gnubuckets == NULL)\n\t{\n\t  gnu_hash_error = TRUE;\n\t  goto no_gnu_hash;\n\t}\n\n      for (i = 0; i < ngnubuckets; i++)\n\tif (gnubuckets[i] != 0)\n\t  {\n\t    if (gnubuckets[i] < gnusymidx)\n\t      {\n\t\tgnu_hash_error = TRUE;\n\t\treturn FALSE;\n\t      }\n\n\t    if (maxchain == 0xffffffff || gnubuckets[i] > maxchain)\n\t      maxchain = gnubuckets[i];\n\t  }\n\n      if (maxchain == 0xffffffff)\n\t{\n\t  gnu_hash_error = TRUE;\n\t  goto no_gnu_hash;\n\t}\n\n      maxchain -= gnusymidx;\n\n      if (fseek (filedata->handle,\n\t\t (archive_file_offset\n\t\t  + offset_from_vma (filedata, buckets_vma\n\t\t\t\t\t   + 4 * (ngnubuckets + maxchain), 4)),\n\t\t SEEK_SET))\n\t{\n\t  error (_(\"Unable to seek to start of dynamic information\\n\"));\n\t  gnu_hash_error = TRUE;\n\t  goto no_gnu_hash;\n\t}\n\n      do\n\t{\n\t  if (fread (nb, 4, 1, filedata->handle) != 1)\n\t    {\n\t      error (_(\"Failed to determine last chain length\\n\"));\n\t  gnu_hash_error = TRUE;\n\t      goto no_gnu_hash;\n\t    }\n\n\t  if (maxchain + 1 == 0)\n\t    {\n\t      gnu_hash_error = TRUE;\n\t      goto no_gnu_hash;\n\t    }\n\n\t  ++maxchain;\n\t}\n      while ((byte_get (nb, 4) & 1) == 0);\n\n      if (fseek (filedata->handle,\n\t\t (archive_file_offset\n\t\t  + offset_from_vma (filedata, buckets_vma + 4 * ngnubuckets, 4)),\n\t\t SEEK_SET))\n\t{\n\t  error (_(\"Unable to seek to start of dynamic information\\n\"));\n\t  gnu_hash_error = TRUE;\n\t  goto no_gnu_hash;\n\t}\n\n      gnuchains = get_dynamic_data (filedata, maxchain, 4);\n      ngnuchains = maxchain;\n\n      if (gnuchains == NULL)\n\t{\n\t  gnu_hash_error = TRUE;\n\t  goto no_gnu_hash;\n\t}\n\n      if (dynamic_info_DT_MIPS_XHASH)\n\t{\n\t  if (fseek (filedata->handle,\n\t\t     (archive_file_offset\n\t\t      + offset_from_vma (filedata, (buckets_vma\n\t\t\t\t\t\t    + 4 * (ngnubuckets\n\t\t\t\t\t\t\t   + maxchain)), 4)),\n\t\t     SEEK_SET))\n\t    {\n\t      error (_(\"Unable to seek to start of dynamic information\\n\"));\n\t      gnu_hash_error = TRUE;\n\t      goto no_gnu_hash;\n\t    }\n\n\t  mipsxlat = get_dynamic_data (filedata, maxchain, 4);\n\t}\n\n      for (hn = 0; hn < ngnubuckets; ++hn)\n\tif (gnubuckets[hn] != 0)\n\t  {\n\t    bfd_vma si = gnubuckets[hn];\n\t    bfd_vma off = si - gnusymidx;\n\n\t    do\n\t      {\n\t\tif (dynamic_info_DT_MIPS_XHASH)\n\t\t  {\n\t\t    if (mipsxlat[off] >= num_of_syms)\n\t\t      num_of_syms = mipsxlat[off] + 1;\n\t\t  }\n\t\telse\n\t\t  {\n\t\t    if (si >= num_of_syms)\n\t\t      num_of_syms = si + 1;\n\t\t  }\n\t\tsi++;\n\t      }\n\t    while (off < ngnuchains && (gnuchains[off++] & 1) == 0);\n\t  }\n\n  no_gnu_hash:\n      if (gnu_hash_error)\n\t{\n\t  if (mipsxlat)\n\t    {\n\t      free (mipsxlat);\n\t      mipsxlat = NULL;\n\t    }\n\t  if (gnuchains)\n\t    {\n\t      free (gnuchains);\n\t      gnuchains = NULL;\n\t    }\n\t  if (gnubuckets)\n\t    {\n\t      free (gnubuckets);\n\t      gnubuckets = NULL;\n\t    }\n\t  ngnubuckets = 0;\n\t  ngnuchains = 0;\n\t}\n    }\n\n  return num_of_syms;\n}",
        "description": "A double free vulnerability exists in the Binary File Descriptor (BFD), also known as libbfd, within GNU Binutils 2.35 during the processing of symbol tables, specifically as exhibited in the readelf utility through the manipulation of a specially crafted file.",
        "commit": "The vulnerability knowledge has been abstracted and generalized as follows:\n\n\"A typo fix was made in the `readelf` tool to consolidate the functionality of the `--syms` and `--use-dynamic` options with the `--dyn-syms` option.\""
    },
    {
        "cwe": "CWE-191",
        "func_name": "torvalds/deassemble_neg_contexts",
        "score": 0.7092693448066711,
        "func_before": "static __le32 deassemble_neg_contexts(struct ksmbd_conn *conn,\n\t\t\t\t      struct smb2_negotiate_req *req,\n\t\t\t\t      int len_of_smb)\n{\n\t/* +4 is to account for the RFC1001 len field */\n\tstruct smb2_neg_context *pctx = (struct smb2_neg_context *)req;\n\tint i = 0, len_of_ctxts;\n\tint offset = le32_to_cpu(req->NegotiateContextOffset);\n\tint neg_ctxt_cnt = le16_to_cpu(req->NegotiateContextCount);\n\t__le32 status = STATUS_INVALID_PARAMETER;\n\n\tksmbd_debug(SMB, \"decoding %d negotiate contexts\\n\", neg_ctxt_cnt);\n\tif (len_of_smb <= offset) {\n\t\tksmbd_debug(SMB, \"Invalid response: negotiate context offset\\n\");\n\t\treturn status;\n\t}\n\n\tlen_of_ctxts = len_of_smb - offset;\n\n\twhile (i++ < neg_ctxt_cnt) {\n\t\tint clen, ctxt_len;\n\n\t\tif (len_of_ctxts < sizeof(struct smb2_neg_context))\n\t\t\tbreak;\n\n\t\tpctx = (struct smb2_neg_context *)((char *)pctx + offset);\n\t\tclen = le16_to_cpu(pctx->DataLength);\n\t\tctxt_len = clen + sizeof(struct smb2_neg_context);\n\n\t\tif (ctxt_len > len_of_ctxts)\n\t\t\tbreak;\n\n\t\tif (pctx->ContextType == SMB2_PREAUTH_INTEGRITY_CAPABILITIES) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_PREAUTH_INTEGRITY_CAPABILITIES context\\n\");\n\t\t\tif (conn->preauth_info->Preauth_HashId)\n\t\t\t\tbreak;\n\n\t\t\tstatus = decode_preauth_ctxt(conn,\n\t\t\t\t\t\t     (struct smb2_preauth_neg_context *)pctx,\n\t\t\t\t\t\t     ctxt_len);\n\t\t\tif (status != STATUS_SUCCESS)\n\t\t\t\tbreak;\n\t\t} else if (pctx->ContextType == SMB2_ENCRYPTION_CAPABILITIES) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_ENCRYPTION_CAPABILITIES context\\n\");\n\t\t\tif (conn->cipher_type)\n\t\t\t\tbreak;\n\n\t\t\tdecode_encrypt_ctxt(conn,\n\t\t\t\t\t    (struct smb2_encryption_neg_context *)pctx,\n\t\t\t\t\t    ctxt_len);\n\t\t} else if (pctx->ContextType == SMB2_COMPRESSION_CAPABILITIES) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_COMPRESSION_CAPABILITIES context\\n\");\n\t\t\tif (conn->compress_algorithm)\n\t\t\t\tbreak;\n\n\t\t\tdecode_compress_ctxt(conn,\n\t\t\t\t\t     (struct smb2_compression_capabilities_context *)pctx);\n\t\t} else if (pctx->ContextType == SMB2_NETNAME_NEGOTIATE_CONTEXT_ID) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_NETNAME_NEGOTIATE_CONTEXT_ID context\\n\");\n\t\t} else if (pctx->ContextType == SMB2_POSIX_EXTENSIONS_AVAILABLE) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_POSIX_EXTENSIONS_AVAILABLE context\\n\");\n\t\t\tconn->posix_ext_supported = true;\n\t\t} else if (pctx->ContextType == SMB2_SIGNING_CAPABILITIES) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_SIGNING_CAPABILITIES context\\n\");\n\n\t\t\tdecode_sign_cap_ctxt(conn,\n\t\t\t\t\t     (struct smb2_signing_capabilities *)pctx,\n\t\t\t\t\t     ctxt_len);\n\t\t}\n\n\t\t/* offsets must be 8 byte aligned */\n\t\tclen = (clen + 7) & ~0x7;\n\t\toffset = clen + sizeof(struct smb2_neg_context);\n\t\tlen_of_ctxts -= clen + sizeof(struct smb2_neg_context);\n\t}\n\treturn status;\n}",
        "func_after": "static __le32 deassemble_neg_contexts(struct ksmbd_conn *conn,\n\t\t\t\t      struct smb2_negotiate_req *req,\n\t\t\t\t      unsigned int len_of_smb)\n{\n\t/* +4 is to account for the RFC1001 len field */\n\tstruct smb2_neg_context *pctx = (struct smb2_neg_context *)req;\n\tint i = 0, len_of_ctxts;\n\tunsigned int offset = le32_to_cpu(req->NegotiateContextOffset);\n\tunsigned int neg_ctxt_cnt = le16_to_cpu(req->NegotiateContextCount);\n\t__le32 status = STATUS_INVALID_PARAMETER;\n\n\tksmbd_debug(SMB, \"decoding %d negotiate contexts\\n\", neg_ctxt_cnt);\n\tif (len_of_smb <= offset) {\n\t\tksmbd_debug(SMB, \"Invalid response: negotiate context offset\\n\");\n\t\treturn status;\n\t}\n\n\tlen_of_ctxts = len_of_smb - offset;\n\n\twhile (i++ < neg_ctxt_cnt) {\n\t\tint clen, ctxt_len;\n\n\t\tif (len_of_ctxts < (int)sizeof(struct smb2_neg_context))\n\t\t\tbreak;\n\n\t\tpctx = (struct smb2_neg_context *)((char *)pctx + offset);\n\t\tclen = le16_to_cpu(pctx->DataLength);\n\t\tctxt_len = clen + sizeof(struct smb2_neg_context);\n\n\t\tif (ctxt_len > len_of_ctxts)\n\t\t\tbreak;\n\n\t\tif (pctx->ContextType == SMB2_PREAUTH_INTEGRITY_CAPABILITIES) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_PREAUTH_INTEGRITY_CAPABILITIES context\\n\");\n\t\t\tif (conn->preauth_info->Preauth_HashId)\n\t\t\t\tbreak;\n\n\t\t\tstatus = decode_preauth_ctxt(conn,\n\t\t\t\t\t\t     (struct smb2_preauth_neg_context *)pctx,\n\t\t\t\t\t\t     ctxt_len);\n\t\t\tif (status != STATUS_SUCCESS)\n\t\t\t\tbreak;\n\t\t} else if (pctx->ContextType == SMB2_ENCRYPTION_CAPABILITIES) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_ENCRYPTION_CAPABILITIES context\\n\");\n\t\t\tif (conn->cipher_type)\n\t\t\t\tbreak;\n\n\t\t\tdecode_encrypt_ctxt(conn,\n\t\t\t\t\t    (struct smb2_encryption_neg_context *)pctx,\n\t\t\t\t\t    ctxt_len);\n\t\t} else if (pctx->ContextType == SMB2_COMPRESSION_CAPABILITIES) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_COMPRESSION_CAPABILITIES context\\n\");\n\t\t\tif (conn->compress_algorithm)\n\t\t\t\tbreak;\n\n\t\t\tdecode_compress_ctxt(conn,\n\t\t\t\t\t     (struct smb2_compression_capabilities_context *)pctx);\n\t\t} else if (pctx->ContextType == SMB2_NETNAME_NEGOTIATE_CONTEXT_ID) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_NETNAME_NEGOTIATE_CONTEXT_ID context\\n\");\n\t\t} else if (pctx->ContextType == SMB2_POSIX_EXTENSIONS_AVAILABLE) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_POSIX_EXTENSIONS_AVAILABLE context\\n\");\n\t\t\tconn->posix_ext_supported = true;\n\t\t} else if (pctx->ContextType == SMB2_SIGNING_CAPABILITIES) {\n\t\t\tksmbd_debug(SMB,\n\t\t\t\t    \"deassemble SMB2_SIGNING_CAPABILITIES context\\n\");\n\n\t\t\tdecode_sign_cap_ctxt(conn,\n\t\t\t\t\t     (struct smb2_signing_capabilities *)pctx,\n\t\t\t\t\t     ctxt_len);\n\t\t}\n\n\t\t/* offsets must be 8 byte aligned */\n\t\toffset = (ctxt_len + 7) & ~0x7;\n\t\tlen_of_ctxts -= offset;\n\t}\n\treturn status;\n}",
        "description": "An issue was discovered in the Linux kernel prior to version 6.3.8. Within the ksmbd component located in the SMB server directory, there is an integer underflow and out-of-bounds read vulnerability in the deassemble_neg_contexts function.",
        "commit": "The vulnerability involves an integer underflow condition in the SMB2 protocol negotiation process within the Linux kernel. Specifically, the initial check compares `clen + sizeof(struct smb2_neg_context)` against `len_of_ctxts`. However, during the loop, `len_of_ctxts` is decremented by `((clen + 7) & ~0x7) + sizeof(struct smb2_neg_context)`, which can lead to an underflow if `clen` undergoes 8-byte alignment. To prevent this, the check should use `(clen + 7) & ~0x7` instead. Additionally, certain variables should be declared as unsigned to avoid similar issues. The vulnerability results in a slab-out-of-bounds read error, as indicated by the kernel log, leading to potential memory corruption and system instability."
    },
    {
        "cwe": "CWE-129",
        "func_name": "admesh/stl_fix_normal_directions",
        "score": 0.680851936340332,
        "func_before": "void\nstl_fix_normal_directions(stl_file *stl) {\n  char *norm_sw;\n  /*  int edge_num;*/\n  /*  int vnot;*/\n  int checked = 0;\n  int facet_num;\n  /*  int next_facet;*/\n  int i;\n  int j;\n  struct stl_normal {\n    int               facet_num;\n    struct stl_normal *next;\n  };\n  struct stl_normal *head;\n  struct stl_normal *tail;\n  struct stl_normal *newn;\n  struct stl_normal *temp;\n\n  if (stl->error) return;\n\n  /* Initialize linked list. */\n  head = (struct stl_normal*)malloc(sizeof(struct stl_normal));\n  if(head == NULL) perror(\"stl_fix_normal_directions\");\n  tail = (struct stl_normal*)malloc(sizeof(struct stl_normal));\n  if(tail == NULL) perror(\"stl_fix_normal_directions\");\n  head->next = tail;\n  tail->next = tail;\n\n  /* Initialize list that keeps track of already fixed facets. */\n  norm_sw = (char*)calloc(stl->stats.number_of_facets, sizeof(char));\n  if(norm_sw == NULL) perror(\"stl_fix_normal_directions\");\n\n\n  facet_num = 0;\n  /* If normal vector is not within tolerance and backwards:\n     Arbitrarily starts at face 0.  If this one is wrong, we're screwed.  Thankfully, the chances\n     of it being wrong randomly are low if most of the triangles are right: */\n  if(stl_check_normal_vector(stl, 0, 0) == 2)\n    stl_reverse_facet(stl, 0);\n\n  /* Say that we've fixed this facet: */\n  norm_sw[facet_num] = 1;\n  checked++;\n\n  for(;;) {\n    /* Add neighbors_to_list.\n       Add unconnected neighbors to the list:a  */\n    for(j = 0; j < 3; j++) {\n      /* Reverse the neighboring facets if necessary. */\n      if(stl->neighbors_start[facet_num].which_vertex_not[j] > 2) {\n        /* If the facet has a neighbor that is -1, it means that edge isn't shared by another facet */\n        if(stl->neighbors_start[facet_num].neighbor[j] != -1) {\n          stl_reverse_facet\n          (stl, stl->neighbors_start[facet_num].neighbor[j]);\n        }\n      }\n      /* If this edge of the facet is connected: */\n      if(stl->neighbors_start[facet_num].neighbor[j] != -1) {\n        /* If we haven't fixed this facet yet, add it to the list: */\n        if(norm_sw[stl->neighbors_start[facet_num].neighbor[j]] != 1) {\n          /* Add node to beginning of list. */\n          newn = (struct stl_normal*)malloc(sizeof(struct stl_normal));\n          if(newn == NULL) perror(\"stl_fix_normal_directions\");\n          newn->facet_num = stl->neighbors_start[facet_num].neighbor[j];\n          newn->next = head->next;\n          head->next = newn;\n        }\n      }\n    }\n    /* Get next facet to fix from top of list. */\n    if(head->next != tail) {\n      facet_num = head->next->facet_num;\n      if(norm_sw[facet_num] != 1) { /* If facet is in list mutiple times */\n        norm_sw[facet_num] = 1; /* Record this one as being fixed. */\n        checked++;\n      }\n      temp = head->next;\t/* Delete this facet from the list. */\n      head->next = head->next->next;\n      free(temp);\n    } else { /* if we ran out of facets to fix: */\n      /* All of the facets in this part have been fixed. */\n      stl->stats.number_of_parts += 1;\n      if(checked >= stl->stats.number_of_facets) {\n        /* All of the facets have been checked.  Bail out. */\n        break;\n      } else {\n        /* There is another part here.  Find it and continue. */\n        for(i = 0; i < stl->stats.number_of_facets; i++) {\n          if(norm_sw[i] == 0) {\n            /* This is the first facet of the next part. */\n            facet_num = i;\n            if(stl_check_normal_vector(stl, i, 0) == 2) {\n              stl_reverse_facet(stl, i);\n            }\n\n            norm_sw[facet_num] = 1;\n            checked++;\n            break;\n          }\n        }\n      }\n    }\n  }\n  free(head);\n  free(tail);\n  free(norm_sw);\n}",
        "func_after": "void\nstl_fix_normal_directions(stl_file *stl) {\n  char *norm_sw;\n  /*  int edge_num;*/\n  /*  int vnot;*/\n  int checked = 0;\n  int facet_num;\n  /*  int next_facet;*/\n  int i;\n  int j;\n  struct stl_normal {\n    int               facet_num;\n    struct stl_normal *next;\n  };\n  struct stl_normal *head;\n  struct stl_normal *tail;\n  struct stl_normal *newn;\n  struct stl_normal *temp;\n\n  if (stl->error) return;\n\n  /* Initialize linked list. */\n  head = (struct stl_normal*)malloc(sizeof(struct stl_normal));\n  if(head == NULL) perror(\"stl_fix_normal_directions\");\n  tail = (struct stl_normal*)malloc(sizeof(struct stl_normal));\n  if(tail == NULL) perror(\"stl_fix_normal_directions\");\n  head->next = tail;\n  tail->next = tail;\n\n  /* Initialize list that keeps track of already fixed facets. */\n  norm_sw = (char*)calloc(stl->stats.number_of_facets, sizeof(char));\n  if(norm_sw == NULL) perror(\"stl_fix_normal_directions\");\n\n\n  facet_num = 0;\n  /* If normal vector is not within tolerance and backwards:\n     Arbitrarily starts at face 0.  If this one is wrong, we're screwed.  Thankfully, the chances\n     of it being wrong randomly are low if most of the triangles are right: */\n  if(stl_check_normal_vector(stl, 0, 0) == 2)\n    stl_reverse_facet(stl, 0);\n\n  /* Say that we've fixed this facet: */\n  norm_sw[facet_num] = 1;\n  checked++;\n\n  for(;;) {\n    /* Add neighbors_to_list.\n       Add unconnected neighbors to the list:a  */\n    for(j = 0; j < 3; j++) {\n      /* Reverse the neighboring facets if necessary. */\n      if(stl->neighbors_start[facet_num].which_vertex_not[j] > 2) {\n        /* If the facet has a neighbor that is -1, it means that edge isn't shared by another facet */\n        if(stl->neighbors_start[facet_num].neighbor[j] != -1) {\n          stl_reverse_facet\n          (stl, stl->neighbors_start[facet_num].neighbor[j]);\n        }\n      }\n      /* If this edge of the facet is connected: */\n      if(stl->neighbors_start[facet_num].neighbor[j] != -1 &&\n         stl->neighbors_start[facet_num].neighbor[j] < stl->stats.number_of_facets*sizeof(char)) {\n        /* If we haven't fixed this facet yet, add it to the list: */\n        if(norm_sw[stl->neighbors_start[facet_num].neighbor[j]] != 1) {\n          /* Add node to beginning of list. */\n          newn = (struct stl_normal*)malloc(sizeof(struct stl_normal));\n          if(newn == NULL) perror(\"stl_fix_normal_directions\");\n          newn->facet_num = stl->neighbors_start[facet_num].neighbor[j];\n          newn->next = head->next;\n          head->next = newn;\n        }\n      }\n    }\n    /* Get next facet to fix from top of list. */\n    if(head->next != tail) {\n      facet_num = head->next->facet_num;\n      if(norm_sw[facet_num] != 1) { /* If facet is in list mutiple times */\n        norm_sw[facet_num] = 1; /* Record this one as being fixed. */\n        checked++;\n      }\n      temp = head->next;\t/* Delete this facet from the list. */\n      head->next = head->next->next;\n      free(temp);\n    } else { /* if we ran out of facets to fix: */\n      /* All of the facets in this part have been fixed. */\n      stl->stats.number_of_parts += 1;\n      if(checked >= stl->stats.number_of_facets) {\n        /* All of the facets have been checked.  Bail out. */\n        break;\n      } else {\n        /* There is another part here.  Find it and continue. */\n        for(i = 0; i < stl->stats.number_of_facets; i++) {\n          if(norm_sw[i] == 0) {\n            /* This is the first facet of the next part. */\n            facet_num = i;\n            if(stl_check_normal_vector(stl, i, 0) == 2) {\n              stl_reverse_facet(stl, i);\n            }\n\n            norm_sw[facet_num] = 1;\n            checked++;\n            break;\n          }\n        }\n      }\n    }\n  }\n  free(head);\n  free(tail);\n  free(norm_sw);\n}",
        "description": "An improper array index validation vulnerability exists in the stl_fix_normal_directions functionality of ADMesh. A specially-crafted STL file can lead to a heap buffer overflow. An attacker can exploit this by providing a malicious file.",
        "commit": "The vulnerability involves a check for the `neighbor_index` within the `stl_check_normal_vector` function. This fix addresses an issue identified in ticket #60."
    },
    {
        "cwe": "CWE-119",
        "func_name": "torvalds/hugetlb_mcopy_atomic_pte",
        "score": 0.7042721509933472,
        "func_before": "int hugetlb_mcopy_atomic_pte(struct mm_struct *dst_mm,\n\t\t\t    pte_t *dst_pte,\n\t\t\t    struct vm_area_struct *dst_vma,\n\t\t\t    unsigned long dst_addr,\n\t\t\t    unsigned long src_addr,\n\t\t\t    struct page **pagep)\n{\n\tint vm_shared = dst_vma->vm_flags & VM_SHARED;\n\tstruct hstate *h = hstate_vma(dst_vma);\n\tpte_t _dst_pte;\n\tspinlock_t *ptl;\n\tint ret;\n\tstruct page *page;\n\n\tif (!*pagep) {\n\t\tret = -ENOMEM;\n\t\tpage = alloc_huge_page(dst_vma, dst_addr, 0);\n\t\tif (IS_ERR(page))\n\t\t\tgoto out;\n\n\t\tret = copy_huge_page_from_user(page,\n\t\t\t\t\t\t(const void __user *) src_addr,\n\t\t\t\t\t\tpages_per_huge_page(h), false);\n\n\t\t/* fallback to copy_from_user outside mmap_sem */\n\t\tif (unlikely(ret)) {\n\t\t\tret = -EFAULT;\n\t\t\t*pagep = page;\n\t\t\t/* don't free the page */\n\t\t\tgoto out;\n\t\t}\n\t} else {\n\t\tpage = *pagep;\n\t\t*pagep = NULL;\n\t}\n\n\t/*\n\t * The memory barrier inside __SetPageUptodate makes sure that\n\t * preceding stores to the page contents become visible before\n\t * the set_pte_at() write.\n\t */\n\t__SetPageUptodate(page);\n\tset_page_huge_active(page);\n\n\t/*\n\t * If shared, add to page cache\n\t */\n\tif (vm_shared) {\n\t\tstruct address_space *mapping = dst_vma->vm_file->f_mapping;\n\t\tpgoff_t idx = vma_hugecache_offset(h, dst_vma, dst_addr);\n\n\t\tret = huge_add_to_page_cache(page, mapping, idx);\n\t\tif (ret)\n\t\t\tgoto out_release_nounlock;\n\t}\n\n\tptl = huge_pte_lockptr(h, dst_mm, dst_pte);\n\tspin_lock(ptl);\n\n\tret = -EEXIST;\n\tif (!huge_pte_none(huge_ptep_get(dst_pte)))\n\t\tgoto out_release_unlock;\n\n\tif (vm_shared) {\n\t\tpage_dup_rmap(page, true);\n\t} else {\n\t\tClearPagePrivate(page);\n\t\thugepage_add_new_anon_rmap(page, dst_vma, dst_addr);\n\t}\n\n\t_dst_pte = make_huge_pte(dst_vma, page, dst_vma->vm_flags & VM_WRITE);\n\tif (dst_vma->vm_flags & VM_WRITE)\n\t\t_dst_pte = huge_pte_mkdirty(_dst_pte);\n\t_dst_pte = pte_mkyoung(_dst_pte);\n\n\tset_huge_pte_at(dst_mm, dst_addr, dst_pte, _dst_pte);\n\n\t(void)huge_ptep_set_access_flags(dst_vma, dst_addr, dst_pte, _dst_pte,\n\t\t\t\t\tdst_vma->vm_flags & VM_WRITE);\n\thugetlb_count_add(pages_per_huge_page(h), dst_mm);\n\n\t/* No need to invalidate - it was non-present before */\n\tupdate_mmu_cache(dst_vma, dst_addr, dst_pte);\n\n\tspin_unlock(ptl);\n\tif (vm_shared)\n\t\tunlock_page(page);\n\tret = 0;\nout:\n\treturn ret;\nout_release_unlock:\n\tspin_unlock(ptl);\n\tif (vm_shared)\n\t\tunlock_page(page);\nout_release_nounlock:\n\tput_page(page);\n\tgoto out;\n}",
        "func_after": "int hugetlb_mcopy_atomic_pte(struct mm_struct *dst_mm,\n\t\t\t    pte_t *dst_pte,\n\t\t\t    struct vm_area_struct *dst_vma,\n\t\t\t    unsigned long dst_addr,\n\t\t\t    unsigned long src_addr,\n\t\t\t    struct page **pagep)\n{\n\tstruct address_space *mapping;\n\tpgoff_t idx;\n\tunsigned long size;\n\tint vm_shared = dst_vma->vm_flags & VM_SHARED;\n\tstruct hstate *h = hstate_vma(dst_vma);\n\tpte_t _dst_pte;\n\tspinlock_t *ptl;\n\tint ret;\n\tstruct page *page;\n\n\tif (!*pagep) {\n\t\tret = -ENOMEM;\n\t\tpage = alloc_huge_page(dst_vma, dst_addr, 0);\n\t\tif (IS_ERR(page))\n\t\t\tgoto out;\n\n\t\tret = copy_huge_page_from_user(page,\n\t\t\t\t\t\t(const void __user *) src_addr,\n\t\t\t\t\t\tpages_per_huge_page(h), false);\n\n\t\t/* fallback to copy_from_user outside mmap_sem */\n\t\tif (unlikely(ret)) {\n\t\t\tret = -EFAULT;\n\t\t\t*pagep = page;\n\t\t\t/* don't free the page */\n\t\t\tgoto out;\n\t\t}\n\t} else {\n\t\tpage = *pagep;\n\t\t*pagep = NULL;\n\t}\n\n\t/*\n\t * The memory barrier inside __SetPageUptodate makes sure that\n\t * preceding stores to the page contents become visible before\n\t * the set_pte_at() write.\n\t */\n\t__SetPageUptodate(page);\n\tset_page_huge_active(page);\n\n\tmapping = dst_vma->vm_file->f_mapping;\n\tidx = vma_hugecache_offset(h, dst_vma, dst_addr);\n\n\t/*\n\t * If shared, add to page cache\n\t */\n\tif (vm_shared) {\n\t\tsize = i_size_read(mapping->host) >> huge_page_shift(h);\n\t\tret = -EFAULT;\n\t\tif (idx >= size)\n\t\t\tgoto out_release_nounlock;\n\n\t\t/*\n\t\t * Serialization between remove_inode_hugepages() and\n\t\t * huge_add_to_page_cache() below happens through the\n\t\t * hugetlb_fault_mutex_table that here must be hold by\n\t\t * the caller.\n\t\t */\n\t\tret = huge_add_to_page_cache(page, mapping, idx);\n\t\tif (ret)\n\t\t\tgoto out_release_nounlock;\n\t}\n\n\tptl = huge_pte_lockptr(h, dst_mm, dst_pte);\n\tspin_lock(ptl);\n\n\t/*\n\t * Recheck the i_size after holding PT lock to make sure not\n\t * to leave any page mapped (as page_mapped()) beyond the end\n\t * of the i_size (remove_inode_hugepages() is strict about\n\t * enforcing that). If we bail out here, we'll also leave a\n\t * page in the radix tree in the vm_shared case beyond the end\n\t * of the i_size, but remove_inode_hugepages() will take care\n\t * of it as soon as we drop the hugetlb_fault_mutex_table.\n\t */\n\tsize = i_size_read(mapping->host) >> huge_page_shift(h);\n\tret = -EFAULT;\n\tif (idx >= size)\n\t\tgoto out_release_unlock;\n\n\tret = -EEXIST;\n\tif (!huge_pte_none(huge_ptep_get(dst_pte)))\n\t\tgoto out_release_unlock;\n\n\tif (vm_shared) {\n\t\tpage_dup_rmap(page, true);\n\t} else {\n\t\tClearPagePrivate(page);\n\t\thugepage_add_new_anon_rmap(page, dst_vma, dst_addr);\n\t}\n\n\t_dst_pte = make_huge_pte(dst_vma, page, dst_vma->vm_flags & VM_WRITE);\n\tif (dst_vma->vm_flags & VM_WRITE)\n\t\t_dst_pte = huge_pte_mkdirty(_dst_pte);\n\t_dst_pte = pte_mkyoung(_dst_pte);\n\n\tset_huge_pte_at(dst_mm, dst_addr, dst_pte, _dst_pte);\n\n\t(void)huge_ptep_set_access_flags(dst_vma, dst_addr, dst_pte, _dst_pte,\n\t\t\t\t\tdst_vma->vm_flags & VM_WRITE);\n\thugetlb_count_add(pages_per_huge_page(h), dst_mm);\n\n\t/* No need to invalidate - it was non-present before */\n\tupdate_mmu_cache(dst_vma, dst_addr, dst_pte);\n\n\tspin_unlock(ptl);\n\tif (vm_shared)\n\t\tunlock_page(page);\n\tret = 0;\nout:\n\treturn ret;\nout_release_unlock:\n\tspin_unlock(ptl);\n\tif (vm_shared)\n\t\tunlock_page(page);\nout_release_nounlock:\n\tput_page(page);\n\tgoto out;\n}",
        "description": "A flaw was identified in the hugetlb_mcopy_atomic_pte function within the Linux kernel's memory management module, affecting versions prior to 4.13.12. The absence of a proper size check in this function could lead to a denial of service condition, indicated by a BUG.",
        "commit": "A vulnerability was identified in the userfaultfd functionality related to hugetlbfs, where the UFFDIO_COPY operation could inadvertently extend beyond the intended size of the file (i_size). This issue led to a kernel panic (oops) at fs/hugetlbfs/inode.c:484, triggered by the absence of an i_size check in the hugetlb_mcopy_atomic_pte function. Although mmap() operations could succeed beyond the end of the i_size after vmtruncate had removed virtual memory areas (vmas) in those ranges, subsequent faults, including UFFDIO_COPY, should not be allowed to succeed. The proposed solution involves modifying the return value to userland to indicate a SIGBUS-like condition, similar to what a page fault would produce, but this approach was deemed less useful due to the difficulty in distinguishing between SIGSEGV and SIGBUS through meaningful syscall return values."
    },
    {
        "cwe": "CWE-189",
        "func_name": "torvalds/i915_gem_execbuffer2",
        "score": 0.6888980269432068,
        "func_before": "int\ni915_gem_execbuffer2(struct drm_device *dev, void *data,\n\t\t     struct drm_file *file)\n{\n\tstruct drm_i915_gem_execbuffer2 *args = data;\n\tstruct drm_i915_gem_exec_object2 *exec2_list = NULL;\n\tint ret;\n\n\tif (args->buffer_count < 1) {\n\t\tDRM_DEBUG(\"execbuf2 with %d buffers\\n\", args->buffer_count);\n\t\treturn -EINVAL;\n\t}\n\n\texec2_list = kmalloc(sizeof(*exec2_list)*args->buffer_count,\n\t\t\t     GFP_KERNEL | __GFP_NOWARN | __GFP_NORETRY);\n\tif (exec2_list == NULL)\n\t\texec2_list = drm_malloc_ab(sizeof(*exec2_list),\n\t\t\t\t\t   args->buffer_count);\n\tif (exec2_list == NULL) {\n\t\tDRM_DEBUG(\"Failed to allocate exec list for %d buffers\\n\",\n\t\t\t  args->buffer_count);\n\t\treturn -ENOMEM;\n\t}\n\tret = copy_from_user(exec2_list,\n\t\t\t     (struct drm_i915_relocation_entry __user *)\n\t\t\t     (uintptr_t) args->buffers_ptr,\n\t\t\t     sizeof(*exec2_list) * args->buffer_count);\n\tif (ret != 0) {\n\t\tDRM_DEBUG(\"copy %d exec entries failed %d\\n\",\n\t\t\t  args->buffer_count, ret);\n\t\tdrm_free_large(exec2_list);\n\t\treturn -EFAULT;\n\t}\n\n\tret = i915_gem_do_execbuffer(dev, data, file, args, exec2_list);\n\tif (!ret) {\n\t\t/* Copy the new buffer offsets back to the user's exec list. */\n\t\tret = copy_to_user((struct drm_i915_relocation_entry __user *)\n\t\t\t\t   (uintptr_t) args->buffers_ptr,\n\t\t\t\t   exec2_list,\n\t\t\t\t   sizeof(*exec2_list) * args->buffer_count);\n\t\tif (ret) {\n\t\t\tret = -EFAULT;\n\t\t\tDRM_DEBUG(\"failed to copy %d exec entries \"\n\t\t\t\t  \"back to user (%d)\\n\",\n\t\t\t\t  args->buffer_count, ret);\n\t\t}\n\t}\n\n\tdrm_free_large(exec2_list);\n\treturn ret;\n}",
        "func_after": "int\ni915_gem_execbuffer2(struct drm_device *dev, void *data,\n\t\t     struct drm_file *file)\n{\n\tstruct drm_i915_gem_execbuffer2 *args = data;\n\tstruct drm_i915_gem_exec_object2 *exec2_list = NULL;\n\tint ret;\n\n\tif (args->buffer_count < 1 ||\n\t    args->buffer_count > UINT_MAX / sizeof(*exec2_list)) {\n\t\tDRM_DEBUG(\"execbuf2 with %d buffers\\n\", args->buffer_count);\n\t\treturn -EINVAL;\n\t}\n\n\texec2_list = kmalloc(sizeof(*exec2_list)*args->buffer_count,\n\t\t\t     GFP_KERNEL | __GFP_NOWARN | __GFP_NORETRY);\n\tif (exec2_list == NULL)\n\t\texec2_list = drm_malloc_ab(sizeof(*exec2_list),\n\t\t\t\t\t   args->buffer_count);\n\tif (exec2_list == NULL) {\n\t\tDRM_DEBUG(\"Failed to allocate exec list for %d buffers\\n\",\n\t\t\t  args->buffer_count);\n\t\treturn -ENOMEM;\n\t}\n\tret = copy_from_user(exec2_list,\n\t\t\t     (struct drm_i915_relocation_entry __user *)\n\t\t\t     (uintptr_t) args->buffers_ptr,\n\t\t\t     sizeof(*exec2_list) * args->buffer_count);\n\tif (ret != 0) {\n\t\tDRM_DEBUG(\"copy %d exec entries failed %d\\n\",\n\t\t\t  args->buffer_count, ret);\n\t\tdrm_free_large(exec2_list);\n\t\treturn -EFAULT;\n\t}\n\n\tret = i915_gem_do_execbuffer(dev, data, file, args, exec2_list);\n\tif (!ret) {\n\t\t/* Copy the new buffer offsets back to the user's exec list. */\n\t\tret = copy_to_user((struct drm_i915_relocation_entry __user *)\n\t\t\t\t   (uintptr_t) args->buffers_ptr,\n\t\t\t\t   exec2_list,\n\t\t\t\t   sizeof(*exec2_list) * args->buffer_count);\n\t\tif (ret) {\n\t\t\tret = -EFAULT;\n\t\t\tDRM_DEBUG(\"failed to copy %d exec entries \"\n\t\t\t\t  \"back to user (%d)\\n\",\n\t\t\t\t  args->buffer_count, ret);\n\t\t}\n\t}\n\n\tdrm_free_large(exec2_list);\n\treturn ret;\n}",
        "description": "An integer overflow vulnerability exists within the `i915_gem_execbuffer2` function of the DRM subsystem in the Linux kernel prior to version 3.3.5 on 32-bit platforms. This flaw allows local users to trigger a denial of service through an out-of-bounds write or potentially cause other unspecified impacts via a specially crafted ioctl call.",
        "commit": "A vulnerability was identified in the i915 driver of the DRM subsystem within the Linux kernel, where a large `args->buffer_count` value provided by userspace through an ioctl call could cause an integer overflow on 32-bit systems. This overflow affects the calculation of the allocation size for temporary execution buffers, potentially leading to out-of-bounds memory access. This issue arose due to changes introduced in commit 8408c282, which attempted to optimize buffer allocation by first trying a normal large `kmalloc`."
    }
]