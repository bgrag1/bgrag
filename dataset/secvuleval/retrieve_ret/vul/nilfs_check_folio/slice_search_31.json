[
    {
        "cwe": "CWE-129",
        "func_name": "admesh/stl_fix_normal_directions",
        "score": 0.77646404504776,
        "func_before": "void\nstl_fix_normal_directions(stl_file *stl) {\n  char *norm_sw;\n  /*  int edge_num;*/\n  /*  int vnot;*/\n  int checked = 0;\n  int facet_num;\n  /*  int next_facet;*/\n  int i;\n  int j;\n  struct stl_normal {\n    int               facet_num;\n    struct stl_normal *next;\n  };\n  struct stl_normal *head;\n  struct stl_normal *tail;\n  struct stl_normal *newn;\n  struct stl_normal *temp;\n\n  if (stl->error) return;\n\n  /* Initialize linked list. */\n  head = (struct stl_normal*)malloc(sizeof(struct stl_normal));\n  if(head == NULL) perror(\"stl_fix_normal_directions\");\n  tail = (struct stl_normal*)malloc(sizeof(struct stl_normal));\n  if(tail == NULL) perror(\"stl_fix_normal_directions\");\n  head->next = tail;\n  tail->next = tail;\n\n  /* Initialize list that keeps track of already fixed facets. */\n  norm_sw = (char*)calloc(stl->stats.number_of_facets, sizeof(char));\n  if(norm_sw == NULL) perror(\"stl_fix_normal_directions\");\n\n\n  facet_num = 0;\n  /* If normal vector is not within tolerance and backwards:\n     Arbitrarily starts at face 0.  If this one is wrong, we're screwed.  Thankfully, the chances\n     of it being wrong randomly are low if most of the triangles are right: */\n  if(stl_check_normal_vector(stl, 0, 0) == 2)\n    stl_reverse_facet(stl, 0);\n\n  /* Say that we've fixed this facet: */\n  norm_sw[facet_num] = 1;\n  checked++;\n\n  for(;;) {\n    /* Add neighbors_to_list.\n       Add unconnected neighbors to the list:a  */\n    for(j = 0; j < 3; j++) {\n      /* Reverse the neighboring facets if necessary. */\n      if(stl->neighbors_start[facet_num].which_vertex_not[j] > 2) {\n        /* If the facet has a neighbor that is -1, it means that edge isn't shared by another facet */\n        if(stl->neighbors_start[facet_num].neighbor[j] != -1) {\n          stl_reverse_facet\n          (stl, stl->neighbors_start[facet_num].neighbor[j]);\n        }\n      }\n      /* If this edge of the facet is connected: */\n      if(stl->neighbors_start[facet_num].neighbor[j] != -1) {\n        /* If we haven't fixed this facet yet, add it to the list: */\n        if(norm_sw[stl->neighbors_start[facet_num].neighbor[j]] != 1) {\n          /* Add node to beginning of list. */\n          newn = (struct stl_normal*)malloc(sizeof(struct stl_normal));\n          if(newn == NULL) perror(\"stl_fix_normal_directions\");\n          newn->facet_num = stl->neighbors_start[facet_num].neighbor[j];\n          newn->next = head->next;\n          head->next = newn;\n        }\n      }\n    }\n    /* Get next facet to fix from top of list. */\n    if(head->next != tail) {\n      facet_num = head->next->facet_num;\n      if(norm_sw[facet_num] != 1) { /* If facet is in list mutiple times */\n        norm_sw[facet_num] = 1; /* Record this one as being fixed. */\n        checked++;\n      }\n      temp = head->next;\t/* Delete this facet from the list. */\n      head->next = head->next->next;\n      free(temp);\n    } else { /* if we ran out of facets to fix: */\n      /* All of the facets in this part have been fixed. */\n      stl->stats.number_of_parts += 1;\n      if(checked >= stl->stats.number_of_facets) {\n        /* All of the facets have been checked.  Bail out. */\n        break;\n      } else {\n        /* There is another part here.  Find it and continue. */\n        for(i = 0; i < stl->stats.number_of_facets; i++) {\n          if(norm_sw[i] == 0) {\n            /* This is the first facet of the next part. */\n            facet_num = i;\n            if(stl_check_normal_vector(stl, i, 0) == 2) {\n              stl_reverse_facet(stl, i);\n            }\n\n            norm_sw[facet_num] = 1;\n            checked++;\n            break;\n          }\n        }\n      }\n    }\n  }\n  free(head);\n  free(tail);\n  free(norm_sw);\n}",
        "func_after": "void\nstl_fix_normal_directions(stl_file *stl) {\n  char *norm_sw;\n  /*  int edge_num;*/\n  /*  int vnot;*/\n  int checked = 0;\n  int facet_num;\n  /*  int next_facet;*/\n  int i;\n  int j;\n  struct stl_normal {\n    int               facet_num;\n    struct stl_normal *next;\n  };\n  struct stl_normal *head;\n  struct stl_normal *tail;\n  struct stl_normal *newn;\n  struct stl_normal *temp;\n\n  if (stl->error) return;\n\n  /* Initialize linked list. */\n  head = (struct stl_normal*)malloc(sizeof(struct stl_normal));\n  if(head == NULL) perror(\"stl_fix_normal_directions\");\n  tail = (struct stl_normal*)malloc(sizeof(struct stl_normal));\n  if(tail == NULL) perror(\"stl_fix_normal_directions\");\n  head->next = tail;\n  tail->next = tail;\n\n  /* Initialize list that keeps track of already fixed facets. */\n  norm_sw = (char*)calloc(stl->stats.number_of_facets, sizeof(char));\n  if(norm_sw == NULL) perror(\"stl_fix_normal_directions\");\n\n\n  facet_num = 0;\n  /* If normal vector is not within tolerance and backwards:\n     Arbitrarily starts at face 0.  If this one is wrong, we're screwed.  Thankfully, the chances\n     of it being wrong randomly are low if most of the triangles are right: */\n  if(stl_check_normal_vector(stl, 0, 0) == 2)\n    stl_reverse_facet(stl, 0);\n\n  /* Say that we've fixed this facet: */\n  norm_sw[facet_num] = 1;\n  checked++;\n\n  for(;;) {\n    /* Add neighbors_to_list.\n       Add unconnected neighbors to the list:a  */\n    for(j = 0; j < 3; j++) {\n      /* Reverse the neighboring facets if necessary. */\n      if(stl->neighbors_start[facet_num].which_vertex_not[j] > 2) {\n        /* If the facet has a neighbor that is -1, it means that edge isn't shared by another facet */\n        if(stl->neighbors_start[facet_num].neighbor[j] != -1) {\n          stl_reverse_facet\n          (stl, stl->neighbors_start[facet_num].neighbor[j]);\n        }\n      }\n      /* If this edge of the facet is connected: */\n      if(stl->neighbors_start[facet_num].neighbor[j] != -1 &&\n         stl->neighbors_start[facet_num].neighbor[j] < stl->stats.number_of_facets*sizeof(char)) {\n        /* If we haven't fixed this facet yet, add it to the list: */\n        if(norm_sw[stl->neighbors_start[facet_num].neighbor[j]] != 1) {\n          /* Add node to beginning of list. */\n          newn = (struct stl_normal*)malloc(sizeof(struct stl_normal));\n          if(newn == NULL) perror(\"stl_fix_normal_directions\");\n          newn->facet_num = stl->neighbors_start[facet_num].neighbor[j];\n          newn->next = head->next;\n          head->next = newn;\n        }\n      }\n    }\n    /* Get next facet to fix from top of list. */\n    if(head->next != tail) {\n      facet_num = head->next->facet_num;\n      if(norm_sw[facet_num] != 1) { /* If facet is in list mutiple times */\n        norm_sw[facet_num] = 1; /* Record this one as being fixed. */\n        checked++;\n      }\n      temp = head->next;\t/* Delete this facet from the list. */\n      head->next = head->next->next;\n      free(temp);\n    } else { /* if we ran out of facets to fix: */\n      /* All of the facets in this part have been fixed. */\n      stl->stats.number_of_parts += 1;\n      if(checked >= stl->stats.number_of_facets) {\n        /* All of the facets have been checked.  Bail out. */\n        break;\n      } else {\n        /* There is another part here.  Find it and continue. */\n        for(i = 0; i < stl->stats.number_of_facets; i++) {\n          if(norm_sw[i] == 0) {\n            /* This is the first facet of the next part. */\n            facet_num = i;\n            if(stl_check_normal_vector(stl, i, 0) == 2) {\n              stl_reverse_facet(stl, i);\n            }\n\n            norm_sw[facet_num] = 1;\n            checked++;\n            break;\n          }\n        }\n      }\n    }\n  }\n  free(head);\n  free(tail);\n  free(norm_sw);\n}",
        "description": "An improper array index validation vulnerability exists in the stl_fix_normal_directions functionality of ADMesh. A specially-crafted STL file can lead to a heap buffer overflow. An attacker can exploit this by providing a malicious file.",
        "commit": "The vulnerability involves a check for the `neighbor_index` within the `stl_check_normal_vector` function. This fix addresses an issue identified in ticket #60."
    },
    {
        "cwe": "CWE-17",
        "func_name": "torvalds/udf_find_entry",
        "score": 0.8047287464141846,
        "func_before": "static struct fileIdentDesc *udf_find_entry(struct inode *dir,\n\t\t\t\t\t    const struct qstr *child,\n\t\t\t\t\t    struct udf_fileident_bh *fibh,\n\t\t\t\t\t    struct fileIdentDesc *cfi)\n{\n\tstruct fileIdentDesc *fi = NULL;\n\tloff_t f_pos;\n\tint block, flen;\n\tunsigned char *fname = NULL;\n\tunsigned char *nameptr;\n\tuint8_t lfi;\n\tuint16_t liu;\n\tloff_t size;\n\tstruct kernel_lb_addr eloc;\n\tuint32_t elen;\n\tsector_t offset;\n\tstruct extent_position epos = {};\n\tstruct udf_inode_info *dinfo = UDF_I(dir);\n\tint isdotdot = child->len == 2 &&\n\t\tchild->name[0] == '.' && child->name[1] == '.';\n\n\tsize = udf_ext0_offset(dir) + dir->i_size;\n\tf_pos = udf_ext0_offset(dir);\n\n\tfibh->sbh = fibh->ebh = NULL;\n\tfibh->soffset = fibh->eoffset = f_pos & (dir->i_sb->s_blocksize - 1);\n\tif (dinfo->i_alloc_type != ICBTAG_FLAG_AD_IN_ICB) {\n\t\tif (inode_bmap(dir, f_pos >> dir->i_sb->s_blocksize_bits, &epos,\n\t\t    &eloc, &elen, &offset) != (EXT_RECORDED_ALLOCATED >> 30))\n\t\t\tgoto out_err;\n\t\tblock = udf_get_lb_pblock(dir->i_sb, &eloc, offset);\n\t\tif ((++offset << dir->i_sb->s_blocksize_bits) < elen) {\n\t\t\tif (dinfo->i_alloc_type == ICBTAG_FLAG_AD_SHORT)\n\t\t\t\tepos.offset -= sizeof(struct short_ad);\n\t\t\telse if (dinfo->i_alloc_type == ICBTAG_FLAG_AD_LONG)\n\t\t\t\tepos.offset -= sizeof(struct long_ad);\n\t\t} else\n\t\t\toffset = 0;\n\n\t\tfibh->sbh = fibh->ebh = udf_tread(dir->i_sb, block);\n\t\tif (!fibh->sbh)\n\t\t\tgoto out_err;\n\t}\n\n\tfname = kmalloc(UDF_NAME_LEN, GFP_NOFS);\n\tif (!fname)\n\t\tgoto out_err;\n\n\twhile (f_pos < size) {\n\t\tfi = udf_fileident_read(dir, &f_pos, fibh, cfi, &epos, &eloc,\n\t\t\t\t\t&elen, &offset);\n\t\tif (!fi)\n\t\t\tgoto out_err;\n\n\t\tliu = le16_to_cpu(cfi->lengthOfImpUse);\n\t\tlfi = cfi->lengthFileIdent;\n\n\t\tif (fibh->sbh == fibh->ebh) {\n\t\t\tnameptr = fi->fileIdent + liu;\n\t\t} else {\n\t\t\tint poffset;\t/* Unpaded ending offset */\n\n\t\t\tpoffset = fibh->soffset + sizeof(struct fileIdentDesc) +\n\t\t\t\t\tliu + lfi;\n\n\t\t\tif (poffset >= lfi)\n\t\t\t\tnameptr = (uint8_t *)(fibh->ebh->b_data +\n\t\t\t\t\t\t      poffset - lfi);\n\t\t\telse {\n\t\t\t\tnameptr = fname;\n\t\t\t\tmemcpy(nameptr, fi->fileIdent + liu,\n\t\t\t\t\tlfi - poffset);\n\t\t\t\tmemcpy(nameptr + lfi - poffset,\n\t\t\t\t\tfibh->ebh->b_data, poffset);\n\t\t\t}\n\t\t}\n\n\t\tif ((cfi->fileCharacteristics & FID_FILE_CHAR_DELETED) != 0) {\n\t\t\tif (!UDF_QUERY_FLAG(dir->i_sb, UDF_FLAG_UNDELETE))\n\t\t\t\tcontinue;\n\t\t}\n\n\t\tif ((cfi->fileCharacteristics & FID_FILE_CHAR_HIDDEN) != 0) {\n\t\t\tif (!UDF_QUERY_FLAG(dir->i_sb, UDF_FLAG_UNHIDE))\n\t\t\t\tcontinue;\n\t\t}\n\n\t\tif ((cfi->fileCharacteristics & FID_FILE_CHAR_PARENT) &&\n\t\t    isdotdot)\n\t\t\tgoto out_ok;\n\n\t\tif (!lfi)\n\t\t\tcontinue;\n\n\t\tflen = udf_get_filename(dir->i_sb, nameptr, fname, lfi);\n\t\tif (flen && udf_match(flen, fname, child->len, child->name))\n\t\t\tgoto out_ok;\n\t}\n\nout_err:\n\tfi = NULL;\n\tif (fibh->sbh != fibh->ebh)\n\t\tbrelse(fibh->ebh);\n\tbrelse(fibh->sbh);\nout_ok:\n\tbrelse(epos.bh);\n\tkfree(fname);\n\n\treturn fi;\n}",
        "func_after": "static struct fileIdentDesc *udf_find_entry(struct inode *dir,\n\t\t\t\t\t    const struct qstr *child,\n\t\t\t\t\t    struct udf_fileident_bh *fibh,\n\t\t\t\t\t    struct fileIdentDesc *cfi)\n{\n\tstruct fileIdentDesc *fi = NULL;\n\tloff_t f_pos;\n\tint block, flen;\n\tunsigned char *fname = NULL;\n\tunsigned char *nameptr;\n\tuint8_t lfi;\n\tuint16_t liu;\n\tloff_t size;\n\tstruct kernel_lb_addr eloc;\n\tuint32_t elen;\n\tsector_t offset;\n\tstruct extent_position epos = {};\n\tstruct udf_inode_info *dinfo = UDF_I(dir);\n\tint isdotdot = child->len == 2 &&\n\t\tchild->name[0] == '.' && child->name[1] == '.';\n\n\tsize = udf_ext0_offset(dir) + dir->i_size;\n\tf_pos = udf_ext0_offset(dir);\n\n\tfibh->sbh = fibh->ebh = NULL;\n\tfibh->soffset = fibh->eoffset = f_pos & (dir->i_sb->s_blocksize - 1);\n\tif (dinfo->i_alloc_type != ICBTAG_FLAG_AD_IN_ICB) {\n\t\tif (inode_bmap(dir, f_pos >> dir->i_sb->s_blocksize_bits, &epos,\n\t\t    &eloc, &elen, &offset) != (EXT_RECORDED_ALLOCATED >> 30))\n\t\t\tgoto out_err;\n\t\tblock = udf_get_lb_pblock(dir->i_sb, &eloc, offset);\n\t\tif ((++offset << dir->i_sb->s_blocksize_bits) < elen) {\n\t\t\tif (dinfo->i_alloc_type == ICBTAG_FLAG_AD_SHORT)\n\t\t\t\tepos.offset -= sizeof(struct short_ad);\n\t\t\telse if (dinfo->i_alloc_type == ICBTAG_FLAG_AD_LONG)\n\t\t\t\tepos.offset -= sizeof(struct long_ad);\n\t\t} else\n\t\t\toffset = 0;\n\n\t\tfibh->sbh = fibh->ebh = udf_tread(dir->i_sb, block);\n\t\tif (!fibh->sbh)\n\t\t\tgoto out_err;\n\t}\n\n\tfname = kmalloc(UDF_NAME_LEN, GFP_NOFS);\n\tif (!fname)\n\t\tgoto out_err;\n\n\twhile (f_pos < size) {\n\t\tfi = udf_fileident_read(dir, &f_pos, fibh, cfi, &epos, &eloc,\n\t\t\t\t\t&elen, &offset);\n\t\tif (!fi)\n\t\t\tgoto out_err;\n\n\t\tliu = le16_to_cpu(cfi->lengthOfImpUse);\n\t\tlfi = cfi->lengthFileIdent;\n\n\t\tif (fibh->sbh == fibh->ebh) {\n\t\t\tnameptr = fi->fileIdent + liu;\n\t\t} else {\n\t\t\tint poffset;\t/* Unpaded ending offset */\n\n\t\t\tpoffset = fibh->soffset + sizeof(struct fileIdentDesc) +\n\t\t\t\t\tliu + lfi;\n\n\t\t\tif (poffset >= lfi)\n\t\t\t\tnameptr = (uint8_t *)(fibh->ebh->b_data +\n\t\t\t\t\t\t      poffset - lfi);\n\t\t\telse {\n\t\t\t\tnameptr = fname;\n\t\t\t\tmemcpy(nameptr, fi->fileIdent + liu,\n\t\t\t\t\tlfi - poffset);\n\t\t\t\tmemcpy(nameptr + lfi - poffset,\n\t\t\t\t\tfibh->ebh->b_data, poffset);\n\t\t\t}\n\t\t}\n\n\t\tif ((cfi->fileCharacteristics & FID_FILE_CHAR_DELETED) != 0) {\n\t\t\tif (!UDF_QUERY_FLAG(dir->i_sb, UDF_FLAG_UNDELETE))\n\t\t\t\tcontinue;\n\t\t}\n\n\t\tif ((cfi->fileCharacteristics & FID_FILE_CHAR_HIDDEN) != 0) {\n\t\t\tif (!UDF_QUERY_FLAG(dir->i_sb, UDF_FLAG_UNHIDE))\n\t\t\t\tcontinue;\n\t\t}\n\n\t\tif ((cfi->fileCharacteristics & FID_FILE_CHAR_PARENT) &&\n\t\t    isdotdot)\n\t\t\tgoto out_ok;\n\n\t\tif (!lfi)\n\t\t\tcontinue;\n\n\t\tflen = udf_get_filename(dir->i_sb, nameptr, lfi, fname,\n\t\t\t\t\tUDF_NAME_LEN);\n\t\tif (flen && udf_match(flen, fname, child->len, child->name))\n\t\t\tgoto out_ok;\n\t}\n\nout_err:\n\tfi = NULL;\n\tif (fibh->sbh != fibh->ebh)\n\t\tbrelse(fibh->ebh);\n\tbrelse(fibh->sbh);\nout_ok:\n\tbrelse(epos.bh);\n\tkfree(fname);\n\n\treturn fi;\n}",
        "description": "The UDF filesystem implementation in the Linux kernel prior to version 3.18.2 does not verify that sufficient space is allocated for storing a symlink target's name along with a trailing null character. This oversight enables local users to potentially access sensitive information through a specially crafted filesystem image.",
        "commit": "The vulnerability involves a failure to verify whether the resolved path from reading a symbolic link fits within the allocated buffer size. This oversight occurs during the process of reading symlinks, where the code does not account for potential encoding conversions that could increase the path length. Consequently, there is a risk that the path may exceed the buffer capacity, leading to buffer overflow issues."
    },
    {
        "cwe": "CWE-119",
        "func_name": "torvalds/hugetlb_mcopy_atomic_pte",
        "score": 0.7992992997169495,
        "func_before": "int hugetlb_mcopy_atomic_pte(struct mm_struct *dst_mm,\n\t\t\t    pte_t *dst_pte,\n\t\t\t    struct vm_area_struct *dst_vma,\n\t\t\t    unsigned long dst_addr,\n\t\t\t    unsigned long src_addr,\n\t\t\t    struct page **pagep)\n{\n\tint vm_shared = dst_vma->vm_flags & VM_SHARED;\n\tstruct hstate *h = hstate_vma(dst_vma);\n\tpte_t _dst_pte;\n\tspinlock_t *ptl;\n\tint ret;\n\tstruct page *page;\n\n\tif (!*pagep) {\n\t\tret = -ENOMEM;\n\t\tpage = alloc_huge_page(dst_vma, dst_addr, 0);\n\t\tif (IS_ERR(page))\n\t\t\tgoto out;\n\n\t\tret = copy_huge_page_from_user(page,\n\t\t\t\t\t\t(const void __user *) src_addr,\n\t\t\t\t\t\tpages_per_huge_page(h), false);\n\n\t\t/* fallback to copy_from_user outside mmap_sem */\n\t\tif (unlikely(ret)) {\n\t\t\tret = -EFAULT;\n\t\t\t*pagep = page;\n\t\t\t/* don't free the page */\n\t\t\tgoto out;\n\t\t}\n\t} else {\n\t\tpage = *pagep;\n\t\t*pagep = NULL;\n\t}\n\n\t/*\n\t * The memory barrier inside __SetPageUptodate makes sure that\n\t * preceding stores to the page contents become visible before\n\t * the set_pte_at() write.\n\t */\n\t__SetPageUptodate(page);\n\tset_page_huge_active(page);\n\n\t/*\n\t * If shared, add to page cache\n\t */\n\tif (vm_shared) {\n\t\tstruct address_space *mapping = dst_vma->vm_file->f_mapping;\n\t\tpgoff_t idx = vma_hugecache_offset(h, dst_vma, dst_addr);\n\n\t\tret = huge_add_to_page_cache(page, mapping, idx);\n\t\tif (ret)\n\t\t\tgoto out_release_nounlock;\n\t}\n\n\tptl = huge_pte_lockptr(h, dst_mm, dst_pte);\n\tspin_lock(ptl);\n\n\tret = -EEXIST;\n\tif (!huge_pte_none(huge_ptep_get(dst_pte)))\n\t\tgoto out_release_unlock;\n\n\tif (vm_shared) {\n\t\tpage_dup_rmap(page, true);\n\t} else {\n\t\tClearPagePrivate(page);\n\t\thugepage_add_new_anon_rmap(page, dst_vma, dst_addr);\n\t}\n\n\t_dst_pte = make_huge_pte(dst_vma, page, dst_vma->vm_flags & VM_WRITE);\n\tif (dst_vma->vm_flags & VM_WRITE)\n\t\t_dst_pte = huge_pte_mkdirty(_dst_pte);\n\t_dst_pte = pte_mkyoung(_dst_pte);\n\n\tset_huge_pte_at(dst_mm, dst_addr, dst_pte, _dst_pte);\n\n\t(void)huge_ptep_set_access_flags(dst_vma, dst_addr, dst_pte, _dst_pte,\n\t\t\t\t\tdst_vma->vm_flags & VM_WRITE);\n\thugetlb_count_add(pages_per_huge_page(h), dst_mm);\n\n\t/* No need to invalidate - it was non-present before */\n\tupdate_mmu_cache(dst_vma, dst_addr, dst_pte);\n\n\tspin_unlock(ptl);\n\tif (vm_shared)\n\t\tunlock_page(page);\n\tret = 0;\nout:\n\treturn ret;\nout_release_unlock:\n\tspin_unlock(ptl);\n\tif (vm_shared)\n\t\tunlock_page(page);\nout_release_nounlock:\n\tput_page(page);\n\tgoto out;\n}",
        "func_after": "int hugetlb_mcopy_atomic_pte(struct mm_struct *dst_mm,\n\t\t\t    pte_t *dst_pte,\n\t\t\t    struct vm_area_struct *dst_vma,\n\t\t\t    unsigned long dst_addr,\n\t\t\t    unsigned long src_addr,\n\t\t\t    struct page **pagep)\n{\n\tstruct address_space *mapping;\n\tpgoff_t idx;\n\tunsigned long size;\n\tint vm_shared = dst_vma->vm_flags & VM_SHARED;\n\tstruct hstate *h = hstate_vma(dst_vma);\n\tpte_t _dst_pte;\n\tspinlock_t *ptl;\n\tint ret;\n\tstruct page *page;\n\n\tif (!*pagep) {\n\t\tret = -ENOMEM;\n\t\tpage = alloc_huge_page(dst_vma, dst_addr, 0);\n\t\tif (IS_ERR(page))\n\t\t\tgoto out;\n\n\t\tret = copy_huge_page_from_user(page,\n\t\t\t\t\t\t(const void __user *) src_addr,\n\t\t\t\t\t\tpages_per_huge_page(h), false);\n\n\t\t/* fallback to copy_from_user outside mmap_sem */\n\t\tif (unlikely(ret)) {\n\t\t\tret = -EFAULT;\n\t\t\t*pagep = page;\n\t\t\t/* don't free the page */\n\t\t\tgoto out;\n\t\t}\n\t} else {\n\t\tpage = *pagep;\n\t\t*pagep = NULL;\n\t}\n\n\t/*\n\t * The memory barrier inside __SetPageUptodate makes sure that\n\t * preceding stores to the page contents become visible before\n\t * the set_pte_at() write.\n\t */\n\t__SetPageUptodate(page);\n\tset_page_huge_active(page);\n\n\tmapping = dst_vma->vm_file->f_mapping;\n\tidx = vma_hugecache_offset(h, dst_vma, dst_addr);\n\n\t/*\n\t * If shared, add to page cache\n\t */\n\tif (vm_shared) {\n\t\tsize = i_size_read(mapping->host) >> huge_page_shift(h);\n\t\tret = -EFAULT;\n\t\tif (idx >= size)\n\t\t\tgoto out_release_nounlock;\n\n\t\t/*\n\t\t * Serialization between remove_inode_hugepages() and\n\t\t * huge_add_to_page_cache() below happens through the\n\t\t * hugetlb_fault_mutex_table that here must be hold by\n\t\t * the caller.\n\t\t */\n\t\tret = huge_add_to_page_cache(page, mapping, idx);\n\t\tif (ret)\n\t\t\tgoto out_release_nounlock;\n\t}\n\n\tptl = huge_pte_lockptr(h, dst_mm, dst_pte);\n\tspin_lock(ptl);\n\n\t/*\n\t * Recheck the i_size after holding PT lock to make sure not\n\t * to leave any page mapped (as page_mapped()) beyond the end\n\t * of the i_size (remove_inode_hugepages() is strict about\n\t * enforcing that). If we bail out here, we'll also leave a\n\t * page in the radix tree in the vm_shared case beyond the end\n\t * of the i_size, but remove_inode_hugepages() will take care\n\t * of it as soon as we drop the hugetlb_fault_mutex_table.\n\t */\n\tsize = i_size_read(mapping->host) >> huge_page_shift(h);\n\tret = -EFAULT;\n\tif (idx >= size)\n\t\tgoto out_release_unlock;\n\n\tret = -EEXIST;\n\tif (!huge_pte_none(huge_ptep_get(dst_pte)))\n\t\tgoto out_release_unlock;\n\n\tif (vm_shared) {\n\t\tpage_dup_rmap(page, true);\n\t} else {\n\t\tClearPagePrivate(page);\n\t\thugepage_add_new_anon_rmap(page, dst_vma, dst_addr);\n\t}\n\n\t_dst_pte = make_huge_pte(dst_vma, page, dst_vma->vm_flags & VM_WRITE);\n\tif (dst_vma->vm_flags & VM_WRITE)\n\t\t_dst_pte = huge_pte_mkdirty(_dst_pte);\n\t_dst_pte = pte_mkyoung(_dst_pte);\n\n\tset_huge_pte_at(dst_mm, dst_addr, dst_pte, _dst_pte);\n\n\t(void)huge_ptep_set_access_flags(dst_vma, dst_addr, dst_pte, _dst_pte,\n\t\t\t\t\tdst_vma->vm_flags & VM_WRITE);\n\thugetlb_count_add(pages_per_huge_page(h), dst_mm);\n\n\t/* No need to invalidate - it was non-present before */\n\tupdate_mmu_cache(dst_vma, dst_addr, dst_pte);\n\n\tspin_unlock(ptl);\n\tif (vm_shared)\n\t\tunlock_page(page);\n\tret = 0;\nout:\n\treturn ret;\nout_release_unlock:\n\tspin_unlock(ptl);\n\tif (vm_shared)\n\t\tunlock_page(page);\nout_release_nounlock:\n\tput_page(page);\n\tgoto out;\n}",
        "description": "A flaw was identified in the hugetlb_mcopy_atomic_pte function within the Linux kernel's memory management module, affecting versions prior to 4.13.12. The absence of a proper size check in this function could lead to a denial of service condition, indicated by a BUG.",
        "commit": "A vulnerability was identified in the userfaultfd functionality related to hugetlbfs, where the UFFDIO_COPY operation could inadvertently extend beyond the intended size of the file (i_size). This issue led to a kernel panic (oops) at fs/hugetlbfs/inode.c:484, triggered by the absence of an i_size check in the hugetlb_mcopy_atomic_pte function. Although mmap() operations could succeed beyond the end of the i_size after vmtruncate had removed virtual memory areas (vmas) in those ranges, subsequent faults, including UFFDIO_COPY, should not be allowed to succeed. The proposed solution involves modifying the return value to userland to indicate a SIGBUS-like condition, similar to what a page fault would produce, but this approach was deemed less useful due to the difficulty in distinguishing between SIGSEGV and SIGBUS through meaningful syscall return values."
    },
    {
        "cwe": "CWE-131",
        "func_name": "the-tcpdump-group/daemon_msg_findallif_req",
        "score": 0.7969788312911987,
        "func_before": "static int\ndaemon_msg_findallif_req(uint8 ver, struct daemon_slpars *pars, uint32 plen)\n{\n\tchar errbuf[PCAP_ERRBUF_SIZE];\t\t// buffer for network errors\n\tchar errmsgbuf[PCAP_ERRBUF_SIZE];\t// buffer for errors to send to the client\n\tchar sendbuf[RPCAP_NETBUF_SIZE];\t// temporary buffer in which data to be sent is buffered\n\tint sendbufidx = 0;\t\t\t// index which keeps the number of bytes currently buffered\n\tpcap_if_t *alldevs = NULL;\t\t// pointer to the header of the interface chain\n\tpcap_if_t *d;\t\t\t\t// temp pointer needed to scan the interface chain\n\tstruct pcap_addr *address;\t\t// pcap structure that keeps a network address of an interface\n\tstruct rpcap_findalldevs_if *findalldevs_if;// rpcap structure that packet all the data of an interface together\n\tuint16 nif = 0;\t\t\t\t// counts the number of interface listed\n\n\t// Discard the rest of the message; there shouldn't be any payload.\n\tif (rpcapd_discard(pars->sockctrl, plen) == -1)\n\t{\n\t\t// Network error.\n\t\treturn -1;\n\t}\n\n\t// Retrieve the device list\n\tif (pcap_findalldevs(&alldevs, errmsgbuf) == -1)\n\t\tgoto error;\n\n\tif (alldevs == NULL)\n\t{\n\t\tif (rpcap_senderror(pars->sockctrl, ver, PCAP_ERR_NOREMOTEIF,\n\t\t\t\"No interfaces found! Make sure libpcap/WinPcap is properly installed\"\n\t\t\t\" and you have the right to access to the remote device.\",\n\t\t\terrbuf) == -1)\n\t\t{\n\t\t\trpcapd_log(LOGPRIO_ERROR, \"Send to client failed: %s\", errbuf);\n\t\t\treturn -1;\n\t\t}\n\t\treturn 0;\n\t}\n\n\t// checks the number of interfaces and it computes the total length of the payload\n\tfor (d = alldevs; d != NULL; d = d->next)\n\t{\n\t\tnif++;\n\n\t\tif (d->description)\n\t\t\tplen+= strlen(d->description);\n\t\tif (d->name)\n\t\t\tplen+= strlen(d->name);\n\n\t\tplen+= sizeof(struct rpcap_findalldevs_if);\n\n\t\tfor (address = d->addresses; address != NULL; address = address->next)\n\t\t{\n\t\t\t/*\n\t\t\t * Send only IPv4 and IPv6 addresses over the wire.\n\t\t\t */\n\t\t\tswitch (address->addr->sa_family)\n\t\t\t{\n\t\t\tcase AF_INET:\n#ifdef AF_INET6\n\t\t\tcase AF_INET6:\n#endif\n\t\t\t\tplen+= (sizeof(struct rpcap_sockaddr) * 4);\n\t\t\t\tbreak;\n\n\t\t\tdefault:\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\t// RPCAP findalldevs command\n\tif (sock_bufferize(NULL, sizeof(struct rpcap_header), NULL,\n\t    &sendbufidx, RPCAP_NETBUF_SIZE, SOCKBUF_CHECKONLY, errmsgbuf,\n\t    PCAP_ERRBUF_SIZE) == -1)\n\t\tgoto error;\n\n\trpcap_createhdr((struct rpcap_header *) sendbuf, ver,\n\t    RPCAP_MSG_FINDALLIF_REPLY, nif, plen);\n\n\t// send the interface list\n\tfor (d = alldevs; d != NULL; d = d->next)\n\t{\n\t\tuint16 lname, ldescr;\n\n\t\tfindalldevs_if = (struct rpcap_findalldevs_if *) &sendbuf[sendbufidx];\n\n\t\tif (sock_bufferize(NULL, sizeof(struct rpcap_findalldevs_if), NULL,\n\t\t    &sendbufidx, RPCAP_NETBUF_SIZE, SOCKBUF_CHECKONLY, errmsgbuf, PCAP_ERRBUF_SIZE) == -1)\n\t\t\tgoto error;\n\n\t\tmemset(findalldevs_if, 0, sizeof(struct rpcap_findalldevs_if));\n\n\t\tif (d->description) ldescr = (short) strlen(d->description);\n\t\telse ldescr = 0;\n\t\tif (d->name) lname = (short) strlen(d->name);\n\t\telse lname = 0;\n\n\t\tfindalldevs_if->desclen = htons(ldescr);\n\t\tfindalldevs_if->namelen = htons(lname);\n\t\tfindalldevs_if->flags = htonl(d->flags);\n\n\t\tfor (address = d->addresses; address != NULL; address = address->next)\n\t\t{\n\t\t\t/*\n\t\t\t * Send only IPv4 and IPv6 addresses over the wire.\n\t\t\t */\n\t\t\tswitch (address->addr->sa_family)\n\t\t\t{\n\t\t\tcase AF_INET:\n#ifdef AF_INET6\n\t\t\tcase AF_INET6:\n#endif\n\t\t\t\tfindalldevs_if->naddr++;\n\t\t\t\tbreak;\n\n\t\t\tdefault:\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tfindalldevs_if->naddr = htons(findalldevs_if->naddr);\n\n\t\tif (sock_bufferize(d->name, lname, sendbuf, &sendbufidx,\n\t\t    RPCAP_NETBUF_SIZE, SOCKBUF_BUFFERIZE, errmsgbuf,\n\t\t    PCAP_ERRBUF_SIZE) == -1)\n\t\t\tgoto error;\n\n\t\tif (sock_bufferize(d->description, ldescr, sendbuf, &sendbufidx,\n\t\t    RPCAP_NETBUF_SIZE, SOCKBUF_BUFFERIZE, errmsgbuf,\n\t\t    PCAP_ERRBUF_SIZE) == -1)\n\t\t\tgoto error;\n\n\t\t// send all addresses\n\t\tfor (address = d->addresses; address != NULL; address = address->next)\n\t\t{\n\t\t\tstruct rpcap_sockaddr *sockaddr;\n\n\t\t\t/*\n\t\t\t * Send only IPv4 and IPv6 addresses over the wire.\n\t\t\t */\n\t\t\tswitch (address->addr->sa_family)\n\t\t\t{\n\t\t\tcase AF_INET:\n#ifdef AF_INET6\n\t\t\tcase AF_INET6:\n#endif\n\t\t\t\tsockaddr = (struct rpcap_sockaddr *) &sendbuf[sendbufidx];\n\t\t\t\tif (sock_bufferize(NULL, sizeof(struct rpcap_sockaddr), NULL,\n\t\t\t\t    &sendbufidx, RPCAP_NETBUF_SIZE, SOCKBUF_CHECKONLY, errmsgbuf, PCAP_ERRBUF_SIZE) == -1)\n\t\t\t\t\tgoto error;\n\t\t\t\tdaemon_seraddr((struct sockaddr_storage *) address->addr, sockaddr);\n\n\t\t\t\tsockaddr = (struct rpcap_sockaddr *) &sendbuf[sendbufidx];\n\t\t\t\tif (sock_bufferize(NULL, sizeof(struct rpcap_sockaddr), NULL,\n\t\t\t\t    &sendbufidx, RPCAP_NETBUF_SIZE, SOCKBUF_CHECKONLY, errmsgbuf, PCAP_ERRBUF_SIZE) == -1)\n\t\t\t\t\tgoto error;\n\t\t\t\tdaemon_seraddr((struct sockaddr_storage *) address->netmask, sockaddr);\n\n\t\t\t\tsockaddr = (struct rpcap_sockaddr *) &sendbuf[sendbufidx];\n\t\t\t\tif (sock_bufferize(NULL, sizeof(struct rpcap_sockaddr), NULL,\n\t\t\t\t    &sendbufidx, RPCAP_NETBUF_SIZE, SOCKBUF_CHECKONLY, errmsgbuf, PCAP_ERRBUF_SIZE) == -1)\n\t\t\t\t\tgoto error;\n\t\t\t\tdaemon_seraddr((struct sockaddr_storage *) address->broadaddr, sockaddr);\n\n\t\t\t\tsockaddr = (struct rpcap_sockaddr *) &sendbuf[sendbufidx];\n\t\t\t\tif (sock_bufferize(NULL, sizeof(struct rpcap_sockaddr), NULL,\n\t\t\t\t    &sendbufidx, RPCAP_NETBUF_SIZE, SOCKBUF_CHECKONLY, errmsgbuf, PCAP_ERRBUF_SIZE) == -1)\n\t\t\t\t\tgoto error;\n\t\t\t\tdaemon_seraddr((struct sockaddr_storage *) address->dstaddr, sockaddr);\n\t\t\t\tbreak;\n\n\t\t\tdefault:\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\t// We no longer need the device list. Free it.\n\tpcap_freealldevs(alldevs);\n\n\t// Send a final command that says \"now send it!\"\n\tif (sock_send(pars->sockctrl, sendbuf, sendbufidx, errbuf, PCAP_ERRBUF_SIZE) == -1)\n\t{\n\t\trpcapd_log(LOGPRIO_ERROR, \"Send to client failed: %s\", errbuf);\n\t\treturn -1;\n\t}\n\n\treturn 0;\n\nerror:\n\tif (alldevs)\n\t\tpcap_freealldevs(alldevs);\n\n\tif (rpcap_senderror(pars->sockctrl, ver, PCAP_ERR_FINDALLIF,\n\t    errmsgbuf, errbuf) == -1)\n\t{\n\t\trpcapd_log(LOGPRIO_ERROR, \"Send to client failed: %s\", errbuf);\n\t\treturn -1;\n\t}\n\treturn 0;\n}",
        "func_after": "static int\ndaemon_msg_findallif_req(uint8 ver, struct daemon_slpars *pars, uint32 plen)\n{\n\tchar errbuf[PCAP_ERRBUF_SIZE];\t\t// buffer for network errors\n\tchar errmsgbuf[PCAP_ERRBUF_SIZE];\t// buffer for errors to send to the client\n\tchar sendbuf[RPCAP_NETBUF_SIZE];\t// temporary buffer in which data to be sent is buffered\n\tint sendbufidx = 0;\t\t\t// index which keeps the number of bytes currently buffered\n\tpcap_if_t *alldevs = NULL;\t\t// pointer to the header of the interface chain\n\tpcap_if_t *d;\t\t\t\t// temp pointer needed to scan the interface chain\n\tstruct pcap_addr *address;\t\t// pcap structure that keeps a network address of an interface\n\tstruct rpcap_findalldevs_if *findalldevs_if;// rpcap structure that packet all the data of an interface together\n\tuint32 replylen;\t\t\t// length of reply payload\n\tuint16 nif = 0;\t\t\t\t// counts the number of interface listed\n\n\t// Discard the rest of the message; there shouldn't be any payload.\n\tif (rpcapd_discard(pars->sockctrl, plen) == -1)\n\t{\n\t\t// Network error.\n\t\treturn -1;\n\t}\n\n\t// Retrieve the device list\n\tif (pcap_findalldevs(&alldevs, errmsgbuf) == -1)\n\t\tgoto error;\n\n\tif (alldevs == NULL)\n\t{\n\t\tif (rpcap_senderror(pars->sockctrl, ver, PCAP_ERR_NOREMOTEIF,\n\t\t\t\"No interfaces found! Make sure libpcap/WinPcap is properly installed\"\n\t\t\t\" and you have the right to access to the remote device.\",\n\t\t\terrbuf) == -1)\n\t\t{\n\t\t\trpcapd_log(LOGPRIO_ERROR, \"Send to client failed: %s\", errbuf);\n\t\t\treturn -1;\n\t\t}\n\t\treturn 0;\n\t}\n\n\t// This checks the number of interfaces and computes the total\n\t// length of the payload.\n\treplylen = 0;\n\tfor (d = alldevs; d != NULL; d = d->next)\n\t{\n\t\tnif++;\n\n\t\tif (d->description)\n\t\t\treplylen += strlen(d->description);\n\t\tif (d->name)\n\t\t\treplylen += strlen(d->name);\n\n\t\treplylen += sizeof(struct rpcap_findalldevs_if);\n\n\t\tfor (address = d->addresses; address != NULL; address = address->next)\n\t\t{\n\t\t\t/*\n\t\t\t * Send only IPv4 and IPv6 addresses over the wire.\n\t\t\t */\n\t\t\tswitch (address->addr->sa_family)\n\t\t\t{\n\t\t\tcase AF_INET:\n#ifdef AF_INET6\n\t\t\tcase AF_INET6:\n#endif\n\t\t\t\treplylen += (sizeof(struct rpcap_sockaddr) * 4);\n\t\t\t\tbreak;\n\n\t\t\tdefault:\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\t// RPCAP findalldevs command\n\tif (sock_bufferize(NULL, sizeof(struct rpcap_header), NULL,\n\t    &sendbufidx, RPCAP_NETBUF_SIZE, SOCKBUF_CHECKONLY, errmsgbuf,\n\t    PCAP_ERRBUF_SIZE) == -1)\n\t\tgoto error;\n\n\trpcap_createhdr((struct rpcap_header *) sendbuf, ver,\n\t    RPCAP_MSG_FINDALLIF_REPLY, nif, replylen);\n\n\t// send the interface list\n\tfor (d = alldevs; d != NULL; d = d->next)\n\t{\n\t\tuint16 lname, ldescr;\n\n\t\tfindalldevs_if = (struct rpcap_findalldevs_if *) &sendbuf[sendbufidx];\n\n\t\tif (sock_bufferize(NULL, sizeof(struct rpcap_findalldevs_if), NULL,\n\t\t    &sendbufidx, RPCAP_NETBUF_SIZE, SOCKBUF_CHECKONLY, errmsgbuf, PCAP_ERRBUF_SIZE) == -1)\n\t\t\tgoto error;\n\n\t\tmemset(findalldevs_if, 0, sizeof(struct rpcap_findalldevs_if));\n\n\t\tif (d->description) ldescr = (short) strlen(d->description);\n\t\telse ldescr = 0;\n\t\tif (d->name) lname = (short) strlen(d->name);\n\t\telse lname = 0;\n\n\t\tfindalldevs_if->desclen = htons(ldescr);\n\t\tfindalldevs_if->namelen = htons(lname);\n\t\tfindalldevs_if->flags = htonl(d->flags);\n\n\t\tfor (address = d->addresses; address != NULL; address = address->next)\n\t\t{\n\t\t\t/*\n\t\t\t * Send only IPv4 and IPv6 addresses over the wire.\n\t\t\t */\n\t\t\tswitch (address->addr->sa_family)\n\t\t\t{\n\t\t\tcase AF_INET:\n#ifdef AF_INET6\n\t\t\tcase AF_INET6:\n#endif\n\t\t\t\tfindalldevs_if->naddr++;\n\t\t\t\tbreak;\n\n\t\t\tdefault:\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tfindalldevs_if->naddr = htons(findalldevs_if->naddr);\n\n\t\tif (sock_bufferize(d->name, lname, sendbuf, &sendbufidx,\n\t\t    RPCAP_NETBUF_SIZE, SOCKBUF_BUFFERIZE, errmsgbuf,\n\t\t    PCAP_ERRBUF_SIZE) == -1)\n\t\t\tgoto error;\n\n\t\tif (sock_bufferize(d->description, ldescr, sendbuf, &sendbufidx,\n\t\t    RPCAP_NETBUF_SIZE, SOCKBUF_BUFFERIZE, errmsgbuf,\n\t\t    PCAP_ERRBUF_SIZE) == -1)\n\t\t\tgoto error;\n\n\t\t// send all addresses\n\t\tfor (address = d->addresses; address != NULL; address = address->next)\n\t\t{\n\t\t\tstruct rpcap_sockaddr *sockaddr;\n\n\t\t\t/*\n\t\t\t * Send only IPv4 and IPv6 addresses over the wire.\n\t\t\t */\n\t\t\tswitch (address->addr->sa_family)\n\t\t\t{\n\t\t\tcase AF_INET:\n#ifdef AF_INET6\n\t\t\tcase AF_INET6:\n#endif\n\t\t\t\tsockaddr = (struct rpcap_sockaddr *) &sendbuf[sendbufidx];\n\t\t\t\tif (sock_bufferize(NULL, sizeof(struct rpcap_sockaddr), NULL,\n\t\t\t\t    &sendbufidx, RPCAP_NETBUF_SIZE, SOCKBUF_CHECKONLY, errmsgbuf, PCAP_ERRBUF_SIZE) == -1)\n\t\t\t\t\tgoto error;\n\t\t\t\tdaemon_seraddr((struct sockaddr_storage *) address->addr, sockaddr);\n\n\t\t\t\tsockaddr = (struct rpcap_sockaddr *) &sendbuf[sendbufidx];\n\t\t\t\tif (sock_bufferize(NULL, sizeof(struct rpcap_sockaddr), NULL,\n\t\t\t\t    &sendbufidx, RPCAP_NETBUF_SIZE, SOCKBUF_CHECKONLY, errmsgbuf, PCAP_ERRBUF_SIZE) == -1)\n\t\t\t\t\tgoto error;\n\t\t\t\tdaemon_seraddr((struct sockaddr_storage *) address->netmask, sockaddr);\n\n\t\t\t\tsockaddr = (struct rpcap_sockaddr *) &sendbuf[sendbufidx];\n\t\t\t\tif (sock_bufferize(NULL, sizeof(struct rpcap_sockaddr), NULL,\n\t\t\t\t    &sendbufidx, RPCAP_NETBUF_SIZE, SOCKBUF_CHECKONLY, errmsgbuf, PCAP_ERRBUF_SIZE) == -1)\n\t\t\t\t\tgoto error;\n\t\t\t\tdaemon_seraddr((struct sockaddr_storage *) address->broadaddr, sockaddr);\n\n\t\t\t\tsockaddr = (struct rpcap_sockaddr *) &sendbuf[sendbufidx];\n\t\t\t\tif (sock_bufferize(NULL, sizeof(struct rpcap_sockaddr), NULL,\n\t\t\t\t    &sendbufidx, RPCAP_NETBUF_SIZE, SOCKBUF_CHECKONLY, errmsgbuf, PCAP_ERRBUF_SIZE) == -1)\n\t\t\t\t\tgoto error;\n\t\t\t\tdaemon_seraddr((struct sockaddr_storage *) address->dstaddr, sockaddr);\n\t\t\t\tbreak;\n\n\t\t\tdefault:\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\t// We no longer need the device list. Free it.\n\tpcap_freealldevs(alldevs);\n\n\t// Send a final command that says \"now send it!\"\n\tif (sock_send(pars->sockctrl, sendbuf, sendbufidx, errbuf, PCAP_ERRBUF_SIZE) == -1)\n\t{\n\t\trpcapd_log(LOGPRIO_ERROR, \"Send to client failed: %s\", errbuf);\n\t\treturn -1;\n\t}\n\n\treturn 0;\n\nerror:\n\tif (alldevs)\n\t\tpcap_freealldevs(alldevs);\n\n\tif (rpcap_senderror(pars->sockctrl, ver, PCAP_ERR_FINDALLIF,\n\t    errmsgbuf, errbuf) == -1)\n\t{\n\t\trpcapd_log(LOGPRIO_ERROR, \"Send to client failed: %s\", errbuf);\n\t\treturn -1;\n\t}\n\treturn 0;\n}",
        "description": "rpcapd/daemon.c in libpcap before 1.9.1 improperly handles certain length values due to the reuse of a variable, potentially exposing an attack vector that involves additional data appended to the end of a request.",
        "commit": "Using the same local variable to calculate both the remaining request length and the reply payload length can lead to confusion and potential errors, especially if the request contains additional data at the end. This practice can result in incorrect handling of packet capture operations, posing a security risk."
    },
    {
        "cwe": "CWE-284",
        "func_name": "xen-project/mod_l1_entry",
        "score": 0.791355550289154,
        "func_before": "static int mod_l1_entry(l1_pgentry_t *pl1e, l1_pgentry_t nl1e,\n                        unsigned long gl1mfn, int preserve_ad,\n                        struct vcpu *pt_vcpu, struct domain *pg_dom)\n{\n    l1_pgentry_t ol1e;\n    struct domain *pt_dom = pt_vcpu->domain;\n    int rc = 0;\n\n    if ( unlikely(__copy_from_user(&ol1e, pl1e, sizeof(ol1e)) != 0) )\n        return -EFAULT;\n\n    if ( unlikely(paging_mode_refcounts(pt_dom)) )\n    {\n        if ( UPDATE_ENTRY(l1, pl1e, ol1e, nl1e, gl1mfn, pt_vcpu, preserve_ad) )\n            return 0;\n        return -EBUSY;\n    }\n\n    if ( l1e_get_flags(nl1e) & _PAGE_PRESENT )\n    {\n        /* Translate foreign guest addresses. */\n        struct page_info *page = NULL;\n\n        if ( unlikely(l1e_get_flags(nl1e) & l1_disallow_mask(pt_dom)) )\n        {\n            MEM_LOG(\"Bad L1 flags %x\",\n                    l1e_get_flags(nl1e) & l1_disallow_mask(pt_dom));\n            return -EINVAL;\n        }\n\n        if ( paging_mode_translate(pg_dom) )\n        {\n            page = get_page_from_gfn(pg_dom, l1e_get_pfn(nl1e), NULL, P2M_ALLOC);\n            if ( !page )\n                return -EINVAL;\n            nl1e = l1e_from_pfn(page_to_mfn(page), l1e_get_flags(nl1e));\n        }\n\n        /* Fast path for identical mapping, r/w, presence, and cachability. */\n        if ( !l1e_has_changed(ol1e, nl1e,\n                              PAGE_CACHE_ATTRS | _PAGE_RW | _PAGE_PRESENT) )\n        {\n            adjust_guest_l1e(nl1e, pt_dom);\n            rc = UPDATE_ENTRY(l1, pl1e, ol1e, nl1e, gl1mfn, pt_vcpu,\n                              preserve_ad);\n            if ( page )\n                put_page(page);\n            return rc ? 0 : -EBUSY;\n        }\n\n        switch ( rc = get_page_from_l1e(nl1e, pt_dom, pg_dom) )\n        {\n        default:\n            if ( page )\n                put_page(page);\n            return rc;\n        case 0:\n            break;\n        case _PAGE_RW ... _PAGE_RW | PAGE_CACHE_ATTRS:\n            ASSERT(!(rc & ~(_PAGE_RW | PAGE_CACHE_ATTRS)));\n            l1e_flip_flags(nl1e, rc);\n            rc = 0;\n            break;\n        }\n        if ( page )\n            put_page(page);\n\n        adjust_guest_l1e(nl1e, pt_dom);\n        if ( unlikely(!UPDATE_ENTRY(l1, pl1e, ol1e, nl1e, gl1mfn, pt_vcpu,\n                                    preserve_ad)) )\n        {\n            ol1e = nl1e;\n            rc = -EBUSY;\n        }\n    }\n    else if ( unlikely(!UPDATE_ENTRY(l1, pl1e, ol1e, nl1e, gl1mfn, pt_vcpu,\n                                     preserve_ad)) )\n    {\n        return -EBUSY;\n    }\n\n    put_page_from_l1e(ol1e, pt_dom);\n    return rc;\n}",
        "func_after": "static int mod_l1_entry(l1_pgentry_t *pl1e, l1_pgentry_t nl1e,\n                        unsigned long gl1mfn, int preserve_ad,\n                        struct vcpu *pt_vcpu, struct domain *pg_dom)\n{\n    l1_pgentry_t ol1e;\n    struct domain *pt_dom = pt_vcpu->domain;\n    int rc = 0;\n\n    if ( unlikely(__copy_from_user(&ol1e, pl1e, sizeof(ol1e)) != 0) )\n        return -EFAULT;\n\n    if ( unlikely(paging_mode_refcounts(pt_dom)) )\n    {\n        if ( UPDATE_ENTRY(l1, pl1e, ol1e, nl1e, gl1mfn, pt_vcpu, preserve_ad) )\n            return 0;\n        return -EBUSY;\n    }\n\n    if ( l1e_get_flags(nl1e) & _PAGE_PRESENT )\n    {\n        /* Translate foreign guest addresses. */\n        struct page_info *page = NULL;\n\n        if ( unlikely(l1e_get_flags(nl1e) & l1_disallow_mask(pt_dom)) )\n        {\n            MEM_LOG(\"Bad L1 flags %x\",\n                    l1e_get_flags(nl1e) & l1_disallow_mask(pt_dom));\n            return -EINVAL;\n        }\n\n        if ( paging_mode_translate(pg_dom) )\n        {\n            page = get_page_from_gfn(pg_dom, l1e_get_pfn(nl1e), NULL, P2M_ALLOC);\n            if ( !page )\n                return -EINVAL;\n            nl1e = l1e_from_pfn(page_to_mfn(page), l1e_get_flags(nl1e));\n        }\n\n        /* Fast path for sufficiently-similar mappings. */\n        if ( !l1e_has_changed(ol1e, nl1e, ~FASTPATH_FLAG_WHITELIST) )\n        {\n            adjust_guest_l1e(nl1e, pt_dom);\n            rc = UPDATE_ENTRY(l1, pl1e, ol1e, nl1e, gl1mfn, pt_vcpu,\n                              preserve_ad);\n            if ( page )\n                put_page(page);\n            return rc ? 0 : -EBUSY;\n        }\n\n        switch ( rc = get_page_from_l1e(nl1e, pt_dom, pg_dom) )\n        {\n        default:\n            if ( page )\n                put_page(page);\n            return rc;\n        case 0:\n            break;\n        case _PAGE_RW ... _PAGE_RW | PAGE_CACHE_ATTRS:\n            ASSERT(!(rc & ~(_PAGE_RW | PAGE_CACHE_ATTRS)));\n            l1e_flip_flags(nl1e, rc);\n            rc = 0;\n            break;\n        }\n        if ( page )\n            put_page(page);\n\n        adjust_guest_l1e(nl1e, pt_dom);\n        if ( unlikely(!UPDATE_ENTRY(l1, pl1e, ol1e, nl1e, gl1mfn, pt_vcpu,\n                                    preserve_ad)) )\n        {\n            ol1e = nl1e;\n            rc = -EBUSY;\n        }\n    }\n    else if ( unlikely(!UPDATE_ENTRY(l1, pl1e, ol1e, nl1e, gl1mfn, pt_vcpu,\n                                     preserve_ad)) )\n    {\n        return -EBUSY;\n    }\n\n    put_page_from_l1e(ol1e, pt_dom);\n    return rc;\n}",
        "description": "The PV pagetable code in the Xen hypervisor, specifically in versions 4.7.x and earlier, permits local 32-bit PV guest OS administrators to escalate their privileges to those of the host OS by exploiting fast-paths designed for updating pagetable entries.",
        "commit": "The vulnerability involves modifying the `mod_l?_entry()` fastpath in the x86/pv module to remove unsafe bits. Changes related to writeability and cacheability must now undergo full re-validation. The logic has been reworked as a whitelist to improve clarity. This addresses a specific security advisory, XSA-182."
    }
]