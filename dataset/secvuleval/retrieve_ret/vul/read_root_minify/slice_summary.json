[
    {
        "cwe": "CWE-385",
        "func_name": "openssl/ecdsa_sign_setup",
        "score": 0.7556820511817932,
        "func_before": "static int ecdsa_sign_setup(EC_KEY *eckey, BN_CTX *ctx_in,\n\t\t\t\t\tBIGNUM **kinvp, BIGNUM **rp,\n\t\t\t\t\tconst unsigned char *dgst, int dlen)\n{\n\tBN_CTX   *ctx = NULL;\n\tBIGNUM\t *k = NULL, *r = NULL, *order = NULL, *X = NULL;\n\tEC_POINT *tmp_point=NULL;\n\tconst EC_GROUP *group;\n\tint \t ret = 0;\n\n\tif (eckey == NULL || (group = EC_KEY_get0_group(eckey)) == NULL)\n\t{\n\t\tECDSAerr(ECDSA_F_ECDSA_SIGN_SETUP, ERR_R_PASSED_NULL_PARAMETER);\n\t\treturn 0;\n\t}\n\n\tif (ctx_in == NULL) \n\t{\n\t\tif ((ctx = BN_CTX_new()) == NULL)\n\t\t{\n\t\t\tECDSAerr(ECDSA_F_ECDSA_SIGN_SETUP,ERR_R_MALLOC_FAILURE);\n\t\t\treturn 0;\n\t\t}\n\t}\n\telse\n\t\tctx = ctx_in;\n\n\tk     = BN_new();\t/* this value is later returned in *kinvp */\n\tr     = BN_new();\t/* this value is later returned in *rp    */\n\torder = BN_new();\n\tX     = BN_new();\n\tif (!k || !r || !order || !X)\n\t{\n\t\tECDSAerr(ECDSA_F_ECDSA_SIGN_SETUP, ERR_R_MALLOC_FAILURE);\n\t\tgoto err;\n\t}\n\tif ((tmp_point = EC_POINT_new(group)) == NULL)\n\t{\n\t\tECDSAerr(ECDSA_F_ECDSA_SIGN_SETUP, ERR_R_EC_LIB);\n\t\tgoto err;\n\t}\n\tif (!EC_GROUP_get_order(group, order, ctx))\n\t{\n\t\tECDSAerr(ECDSA_F_ECDSA_SIGN_SETUP, ERR_R_EC_LIB);\n\t\tgoto err;\n\t}\n\n#ifdef OPENSSL_FIPS\n\tif (!fips_check_ec_prng(eckey))\n\t\tgoto err;\n#endif\n\t\n\tdo\n\t{\n\t\t/* get random k */\t\n\t\tdo\n#ifndef OPENSSL_NO_SHA512\n\t\t\tif (dgst != NULL)\n\t\t\t{\n\t\t\t\tif (!BN_generate_dsa_nonce(k, order, EC_KEY_get0_private_key(eckey),\n\t\t\t\t\t\t\t   dgst, dlen, ctx))\n\t\t\t\t\t{\n\t\t\t\t\tECDSAerr(ECDSA_F_ECDSA_SIGN_SETUP,\n\t\t\t\t\t\t ECDSA_R_RANDOM_NUMBER_GENERATION_FAILED);\n\t\t\t\t\tgoto err;\n\t\t\t\t\t}\n\t\t\t}\n\t\t\telse\n#endif\n\t\t\t{\n\t\t\t\tif (!BN_rand_range(k, order))\n\t\t\t\t{\n\t\t\t\t\tECDSAerr(ECDSA_F_ECDSA_SIGN_SETUP,\n\t\t\t\t\t\t ECDSA_R_RANDOM_NUMBER_GENERATION_FAILED);\n\t\t\t\t\tgoto err;\n\t\t\t\t}\n\t\t\t}\n\t\twhile (BN_is_zero(k));\n\n\t\t/* We do not want timing information to leak the length of k,\n\t\t * so we compute G*k using an equivalent scalar of fixed\n\t\t * bit-length. */\n\n\t\tif (!BN_add(k, k, order)) goto err;\n\t\tif (BN_num_bits(k) <= BN_num_bits(order))\n\t\t\tif (!BN_add(k, k, order)) goto err;\n\n\t\t/* compute r the x-coordinate of generator * k */\n\t\tif (!EC_POINT_mul(group, tmp_point, k, NULL, NULL, ctx))\n\t\t{\n\t\t\tECDSAerr(ECDSA_F_ECDSA_SIGN_SETUP, ERR_R_EC_LIB);\n\t\t\tgoto err;\n\t\t}\n\t\tif (EC_METHOD_get_field_type(EC_GROUP_method_of(group)) == NID_X9_62_prime_field)\n\t\t{\n\t\t\tif (!EC_POINT_get_affine_coordinates_GFp(group,\n\t\t\t\ttmp_point, X, NULL, ctx))\n\t\t\t{\n\t\t\t\tECDSAerr(ECDSA_F_ECDSA_SIGN_SETUP,ERR_R_EC_LIB);\n\t\t\t\tgoto err;\n\t\t\t}\n\t\t}\n#ifndef OPENSSL_NO_EC2M\n\t\telse /* NID_X9_62_characteristic_two_field */\n\t\t{\n\t\t\tif (!EC_POINT_get_affine_coordinates_GF2m(group,\n\t\t\t\ttmp_point, X, NULL, ctx))\n\t\t\t{\n\t\t\t\tECDSAerr(ECDSA_F_ECDSA_SIGN_SETUP,ERR_R_EC_LIB);\n\t\t\t\tgoto err;\n\t\t\t}\n\t\t}\n#endif\n\t\tif (!BN_nnmod(r, X, order, ctx))\n\t\t{\n\t\t\tECDSAerr(ECDSA_F_ECDSA_SIGN_SETUP, ERR_R_BN_LIB);\n\t\t\tgoto err;\n\t\t}\n\t}\n\twhile (BN_is_zero(r));\n\n\t/* compute the inverse of k */\n\tif (!BN_mod_inverse(k, k, order, ctx))\n\t{\n\t\tECDSAerr(ECDSA_F_ECDSA_SIGN_SETUP, ERR_R_BN_LIB);\n\t\tgoto err;\t\n\t}\n\t/* clear old values if necessary */\n\tif (*rp != NULL)\n\t\tBN_clear_free(*rp);\n\tif (*kinvp != NULL) \n\t\tBN_clear_free(*kinvp);\n\t/* save the pre-computed values  */\n\t*rp    = r;\n\t*kinvp = k;\n\tret = 1;\nerr:\n\tif (!ret)\n\t{\n\t\tif (k != NULL) BN_clear_free(k);\n\t\tif (r != NULL) BN_clear_free(r);\n\t}\n\tif (ctx_in == NULL) \n\t\tBN_CTX_free(ctx);\n\tif (order != NULL)\n\t\tBN_free(order);\n\tif (tmp_point != NULL) \n\t\tEC_POINT_free(tmp_point);\n\tif (X)\n\t\tBN_clear_free(X);\n\treturn(ret);\n}",
        "func_after": "static int ecdsa_sign_setup(EC_KEY *eckey, BN_CTX *ctx_in,\n\t\t\t\t\tBIGNUM **kinvp, BIGNUM **rp,\n\t\t\t\t\tconst unsigned char *dgst, int dlen)\n{\n\tBN_CTX   *ctx = NULL;\n\tBIGNUM\t *k = NULL, *r = NULL, *order = NULL, *X = NULL;\n\tEC_POINT *tmp_point=NULL;\n\tconst EC_GROUP *group;\n\tint \t ret = 0;\n\n\tif (eckey == NULL || (group = EC_KEY_get0_group(eckey)) == NULL)\n\t{\n\t\tECDSAerr(ECDSA_F_ECDSA_SIGN_SETUP, ERR_R_PASSED_NULL_PARAMETER);\n\t\treturn 0;\n\t}\n\n\tif (ctx_in == NULL) \n\t{\n\t\tif ((ctx = BN_CTX_new()) == NULL)\n\t\t{\n\t\t\tECDSAerr(ECDSA_F_ECDSA_SIGN_SETUP,ERR_R_MALLOC_FAILURE);\n\t\t\treturn 0;\n\t\t}\n\t}\n\telse\n\t\tctx = ctx_in;\n\n\tk     = BN_new();\t/* this value is later returned in *kinvp */\n\tr     = BN_new();\t/* this value is later returned in *rp    */\n\torder = BN_new();\n\tX     = BN_new();\n\tif (!k || !r || !order || !X)\n\t{\n\t\tECDSAerr(ECDSA_F_ECDSA_SIGN_SETUP, ERR_R_MALLOC_FAILURE);\n\t\tgoto err;\n\t}\n\tif ((tmp_point = EC_POINT_new(group)) == NULL)\n\t{\n\t\tECDSAerr(ECDSA_F_ECDSA_SIGN_SETUP, ERR_R_EC_LIB);\n\t\tgoto err;\n\t}\n\tif (!EC_GROUP_get_order(group, order, ctx))\n\t{\n\t\tECDSAerr(ECDSA_F_ECDSA_SIGN_SETUP, ERR_R_EC_LIB);\n\t\tgoto err;\n\t}\n\n#ifdef OPENSSL_FIPS\n\tif (!fips_check_ec_prng(eckey))\n\t\tgoto err;\n#endif\n\t\n\tdo\n\t{\n\t\t/* get random k */\t\n\t\tdo\n#ifndef OPENSSL_NO_SHA512\n\t\t\tif (dgst != NULL)\n\t\t\t{\n\t\t\t\tif (!BN_generate_dsa_nonce(k, order, EC_KEY_get0_private_key(eckey),\n\t\t\t\t\t\t\t   dgst, dlen, ctx))\n\t\t\t\t\t{\n\t\t\t\t\tECDSAerr(ECDSA_F_ECDSA_SIGN_SETUP,\n\t\t\t\t\t\t ECDSA_R_RANDOM_NUMBER_GENERATION_FAILED);\n\t\t\t\t\tgoto err;\n\t\t\t\t\t}\n\t\t\t}\n\t\t\telse\n#endif\n\t\t\t{\n\t\t\t\tif (!BN_rand_range(k, order))\n\t\t\t\t{\n\t\t\t\t\tECDSAerr(ECDSA_F_ECDSA_SIGN_SETUP,\n\t\t\t\t\t\t ECDSA_R_RANDOM_NUMBER_GENERATION_FAILED);\n\t\t\t\t\tgoto err;\n\t\t\t\t}\n\t\t\t}\n\t\twhile (BN_is_zero(k));\n\n\t\t/* We do not want timing information to leak the length of k,\n\t\t * so we compute G*k using an equivalent scalar of fixed\n\t\t * bit-length. */\n\n\t\tif (!BN_add(k, k, order)) goto err;\n\t\tif (BN_num_bits(k) <= BN_num_bits(order))\n\t\t\tif (!BN_add(k, k, order)) goto err;\n\n\t\t/* compute r the x-coordinate of generator * k */\n\t\tif (!EC_POINT_mul(group, tmp_point, k, NULL, NULL, ctx))\n\t\t{\n\t\t\tECDSAerr(ECDSA_F_ECDSA_SIGN_SETUP, ERR_R_EC_LIB);\n\t\t\tgoto err;\n\t\t}\n\t\tif (EC_METHOD_get_field_type(EC_GROUP_method_of(group)) == NID_X9_62_prime_field)\n\t\t{\n\t\t\tif (!EC_POINT_get_affine_coordinates_GFp(group,\n\t\t\t\ttmp_point, X, NULL, ctx))\n\t\t\t{\n\t\t\t\tECDSAerr(ECDSA_F_ECDSA_SIGN_SETUP,ERR_R_EC_LIB);\n\t\t\t\tgoto err;\n\t\t\t}\n\t\t}\n#ifndef OPENSSL_NO_EC2M\n\t\telse /* NID_X9_62_characteristic_two_field */\n\t\t{\n\t\t\tif (!EC_POINT_get_affine_coordinates_GF2m(group,\n\t\t\t\ttmp_point, X, NULL, ctx))\n\t\t\t{\n\t\t\t\tECDSAerr(ECDSA_F_ECDSA_SIGN_SETUP,ERR_R_EC_LIB);\n\t\t\t\tgoto err;\n\t\t\t}\n\t\t}\n#endif\n\t\tif (!BN_nnmod(r, X, order, ctx))\n\t\t{\n\t\t\tECDSAerr(ECDSA_F_ECDSA_SIGN_SETUP, ERR_R_BN_LIB);\n\t\t\tgoto err;\n\t\t}\n\t}\n\twhile (BN_is_zero(r));\n\n\t/* compute the inverse of k */\n\tif (EC_GROUP_get_mont_data(group) != NULL)\n\t\t{\n\t\t/* We want inverse in constant time, therefore we utilize the\n\t\t * fact order must be prime and use Fermats Little Theorem\n\t\t * instead. */\n\t\tif (!BN_set_word(X, 2) )\n\t\t\t{\n\t\t\tECDSAerr(ECDSA_F_ECDSA_SIGN_SETUP, ERR_R_BN_LIB);\n\t\t\tgoto err;\n\t\t\t}\n\t\tif (!BN_mod_sub(X, order, X, order, ctx))\n\t\t\t{\n\t\t\tECDSAerr(ECDSA_F_ECDSA_SIGN_SETUP, ERR_R_BN_LIB);\n\t\t\tgoto err;\n\t\t\t}\n\t\tBN_set_flags(X, BN_FLG_CONSTTIME);\n\t\tif (!BN_mod_exp_mont_consttime(k, k, X, order, ctx, EC_GROUP_get_mont_data(group)))\n\t\t\t{\n\t\t\tECDSAerr(ECDSA_F_ECDSA_SIGN_SETUP, ERR_R_BN_LIB);\n\t\t\tgoto err;\n\t\t\t}\n\t\t}\n\telse\n\t\t{\n\t\tif (!BN_mod_inverse(k, k, order, ctx))\n\t\t\t{\n\t\t\tECDSAerr(ECDSA_F_ECDSA_SIGN_SETUP, ERR_R_BN_LIB);\n\t\t\tgoto err;\t\n\t\t\t}\n\t\t}\n\n\t/* clear old values if necessary */\n\tif (*rp != NULL)\n\t\tBN_clear_free(*rp);\n\tif (*kinvp != NULL) \n\t\tBN_clear_free(*kinvp);\n\t/* save the pre-computed values  */\n\t*rp    = r;\n\t*kinvp = k;\n\tret = 1;\nerr:\n\tif (!ret)\n\t{\n\t\tif (k != NULL) BN_clear_free(k);\n\t\tif (r != NULL) BN_clear_free(r);\n\t}\n\tif (ctx_in == NULL) \n\t\tBN_CTX_free(ctx);\n\tif (order != NULL)\n\t\tBN_free(order);\n\tif (tmp_point != NULL) \n\t\tEC_POINT_free(tmp_point);\n\tif (X)\n\t\tBN_clear_free(X);\n\treturn(ret);\n}",
        "description": "A timing attack vulnerability was identified in OpenSSL versions prior to 1.0.1u, enabling a malicious user with local access to potentially recover ECDSA P-256 private keys through the exploitation of timing variations in cryptographic operations.",
        "commit": "The vulnerability knowledge has been abstracted and generalized as follows:\n\n\"The implementation of ECDSA includes an option to utilize BN_mod_exp_mont_consttime, a constant-time modular exponentiation function. This enhancement aims to improve the security of ECDSA operations.\""
    },
    {
        "cwe": "CWE-19",
        "func_name": "torvalds/xfs_attr_rmtval_set",
        "score": 0.7580453157424927,
        "func_before": "int\nxfs_attr_rmtval_set(\n\tstruct xfs_da_args\t*args)\n{\n\tstruct xfs_inode\t*dp = args->dp;\n\tstruct xfs_mount\t*mp = dp->i_mount;\n\tstruct xfs_bmbt_irec\tmap;\n\txfs_dablk_t\t\tlblkno;\n\txfs_fileoff_t\t\tlfileoff = 0;\n\t__uint8_t\t\t*src = args->value;\n\tint\t\t\tblkcnt;\n\tint\t\t\tvaluelen;\n\tint\t\t\tnmap;\n\tint\t\t\terror;\n\tint\t\t\toffset = 0;\n\n\ttrace_xfs_attr_rmtval_set(args);\n\n\t/*\n\t * Find a \"hole\" in the attribute address space large enough for\n\t * us to drop the new attribute's value into. Because CRC enable\n\t * attributes have headers, we can't just do a straight byte to FSB\n\t * conversion and have to take the header space into account.\n\t */\n\tblkcnt = xfs_attr3_rmt_blocks(mp, args->valuelen);\n\terror = xfs_bmap_first_unused(args->trans, args->dp, blkcnt, &lfileoff,\n\t\t\t\t\t\t   XFS_ATTR_FORK);\n\tif (error)\n\t\treturn error;\n\n\targs->rmtblkno = lblkno = (xfs_dablk_t)lfileoff;\n\targs->rmtblkcnt = blkcnt;\n\n\t/*\n\t * Roll through the \"value\", allocating blocks on disk as required.\n\t */\n\twhile (blkcnt > 0) {\n\t\tint\tcommitted;\n\n\t\t/*\n\t\t * Allocate a single extent, up to the size of the value.\n\t\t */\n\t\txfs_bmap_init(args->flist, args->firstblock);\n\t\tnmap = 1;\n\t\terror = xfs_bmapi_write(args->trans, dp, (xfs_fileoff_t)lblkno,\n\t\t\t\t  blkcnt,\n\t\t\t\t  XFS_BMAPI_ATTRFORK | XFS_BMAPI_METADATA,\n\t\t\t\t  args->firstblock, args->total, &map, &nmap,\n\t\t\t\t  args->flist);\n\t\tif (!error) {\n\t\t\terror = xfs_bmap_finish(&args->trans, args->flist,\n\t\t\t\t\t\t&committed);\n\t\t}\n\t\tif (error) {\n\t\t\tASSERT(committed);\n\t\t\targs->trans = NULL;\n\t\t\txfs_bmap_cancel(args->flist);\n\t\t\treturn(error);\n\t\t}\n\n\t\t/*\n\t\t * bmap_finish() may have committed the last trans and started\n\t\t * a new one.  We need the inode to be in all transactions.\n\t\t */\n\t\tif (committed)\n\t\t\txfs_trans_ijoin(args->trans, dp, 0);\n\n\t\tASSERT(nmap == 1);\n\t\tASSERT((map.br_startblock != DELAYSTARTBLOCK) &&\n\t\t       (map.br_startblock != HOLESTARTBLOCK));\n\t\tlblkno += map.br_blockcount;\n\t\tblkcnt -= map.br_blockcount;\n\n\t\t/*\n\t\t * Start the next trans in the chain.\n\t\t */\n\t\terror = xfs_trans_roll(&args->trans, dp);\n\t\tif (error)\n\t\t\treturn (error);\n\t}\n\n\t/*\n\t * Roll through the \"value\", copying the attribute value to the\n\t * already-allocated blocks.  Blocks are written synchronously\n\t * so that we can know they are all on disk before we turn off\n\t * the INCOMPLETE flag.\n\t */\n\tlblkno = args->rmtblkno;\n\tblkcnt = args->rmtblkcnt;\n\tvaluelen = args->valuelen;\n\twhile (valuelen > 0) {\n\t\tstruct xfs_buf\t*bp;\n\t\txfs_daddr_t\tdblkno;\n\t\tint\t\tdblkcnt;\n\n\t\tASSERT(blkcnt > 0);\n\n\t\txfs_bmap_init(args->flist, args->firstblock);\n\t\tnmap = 1;\n\t\terror = xfs_bmapi_read(dp, (xfs_fileoff_t)lblkno,\n\t\t\t\t       blkcnt, &map, &nmap,\n\t\t\t\t       XFS_BMAPI_ATTRFORK);\n\t\tif (error)\n\t\t\treturn(error);\n\t\tASSERT(nmap == 1);\n\t\tASSERT((map.br_startblock != DELAYSTARTBLOCK) &&\n\t\t       (map.br_startblock != HOLESTARTBLOCK));\n\n\t\tdblkno = XFS_FSB_TO_DADDR(mp, map.br_startblock),\n\t\tdblkcnt = XFS_FSB_TO_BB(mp, map.br_blockcount);\n\n\t\tbp = xfs_buf_get(mp->m_ddev_targp, dblkno, dblkcnt, 0);\n\t\tif (!bp)\n\t\t\treturn ENOMEM;\n\t\tbp->b_ops = &xfs_attr3_rmt_buf_ops;\n\n\t\txfs_attr_rmtval_copyin(mp, bp, args->dp->i_ino, &offset,\n\t\t\t\t       &valuelen, &src);\n\n\t\terror = xfs_bwrite(bp);\t/* GROT: NOTE: synchronous write */\n\t\txfs_buf_relse(bp);\n\t\tif (error)\n\t\t\treturn error;\n\n\n\t\t/* roll attribute extent map forwards */\n\t\tlblkno += map.br_blockcount;\n\t\tblkcnt -= map.br_blockcount;\n\t}\n\tASSERT(valuelen == 0);\n\treturn 0;\n}",
        "func_after": "int\nxfs_attr_rmtval_set(\n\tstruct xfs_da_args\t*args)\n{\n\tstruct xfs_inode\t*dp = args->dp;\n\tstruct xfs_mount\t*mp = dp->i_mount;\n\tstruct xfs_bmbt_irec\tmap;\n\txfs_dablk_t\t\tlblkno;\n\txfs_fileoff_t\t\tlfileoff = 0;\n\t__uint8_t\t\t*src = args->value;\n\tint\t\t\tblkcnt;\n\tint\t\t\tvaluelen;\n\tint\t\t\tnmap;\n\tint\t\t\terror;\n\tint\t\t\toffset = 0;\n\n\ttrace_xfs_attr_rmtval_set(args);\n\n\t/*\n\t * Find a \"hole\" in the attribute address space large enough for\n\t * us to drop the new attribute's value into. Because CRC enable\n\t * attributes have headers, we can't just do a straight byte to FSB\n\t * conversion and have to take the header space into account.\n\t */\n\tblkcnt = xfs_attr3_rmt_blocks(mp, args->rmtvaluelen);\n\terror = xfs_bmap_first_unused(args->trans, args->dp, blkcnt, &lfileoff,\n\t\t\t\t\t\t   XFS_ATTR_FORK);\n\tif (error)\n\t\treturn error;\n\n\targs->rmtblkno = lblkno = (xfs_dablk_t)lfileoff;\n\targs->rmtblkcnt = blkcnt;\n\n\t/*\n\t * Roll through the \"value\", allocating blocks on disk as required.\n\t */\n\twhile (blkcnt > 0) {\n\t\tint\tcommitted;\n\n\t\t/*\n\t\t * Allocate a single extent, up to the size of the value.\n\t\t */\n\t\txfs_bmap_init(args->flist, args->firstblock);\n\t\tnmap = 1;\n\t\terror = xfs_bmapi_write(args->trans, dp, (xfs_fileoff_t)lblkno,\n\t\t\t\t  blkcnt,\n\t\t\t\t  XFS_BMAPI_ATTRFORK | XFS_BMAPI_METADATA,\n\t\t\t\t  args->firstblock, args->total, &map, &nmap,\n\t\t\t\t  args->flist);\n\t\tif (!error) {\n\t\t\terror = xfs_bmap_finish(&args->trans, args->flist,\n\t\t\t\t\t\t&committed);\n\t\t}\n\t\tif (error) {\n\t\t\tASSERT(committed);\n\t\t\targs->trans = NULL;\n\t\t\txfs_bmap_cancel(args->flist);\n\t\t\treturn(error);\n\t\t}\n\n\t\t/*\n\t\t * bmap_finish() may have committed the last trans and started\n\t\t * a new one.  We need the inode to be in all transactions.\n\t\t */\n\t\tif (committed)\n\t\t\txfs_trans_ijoin(args->trans, dp, 0);\n\n\t\tASSERT(nmap == 1);\n\t\tASSERT((map.br_startblock != DELAYSTARTBLOCK) &&\n\t\t       (map.br_startblock != HOLESTARTBLOCK));\n\t\tlblkno += map.br_blockcount;\n\t\tblkcnt -= map.br_blockcount;\n\n\t\t/*\n\t\t * Start the next trans in the chain.\n\t\t */\n\t\terror = xfs_trans_roll(&args->trans, dp);\n\t\tif (error)\n\t\t\treturn (error);\n\t}\n\n\t/*\n\t * Roll through the \"value\", copying the attribute value to the\n\t * already-allocated blocks.  Blocks are written synchronously\n\t * so that we can know they are all on disk before we turn off\n\t * the INCOMPLETE flag.\n\t */\n\tlblkno = args->rmtblkno;\n\tblkcnt = args->rmtblkcnt;\n\tvaluelen = args->rmtvaluelen;\n\twhile (valuelen > 0) {\n\t\tstruct xfs_buf\t*bp;\n\t\txfs_daddr_t\tdblkno;\n\t\tint\t\tdblkcnt;\n\n\t\tASSERT(blkcnt > 0);\n\n\t\txfs_bmap_init(args->flist, args->firstblock);\n\t\tnmap = 1;\n\t\terror = xfs_bmapi_read(dp, (xfs_fileoff_t)lblkno,\n\t\t\t\t       blkcnt, &map, &nmap,\n\t\t\t\t       XFS_BMAPI_ATTRFORK);\n\t\tif (error)\n\t\t\treturn(error);\n\t\tASSERT(nmap == 1);\n\t\tASSERT((map.br_startblock != DELAYSTARTBLOCK) &&\n\t\t       (map.br_startblock != HOLESTARTBLOCK));\n\n\t\tdblkno = XFS_FSB_TO_DADDR(mp, map.br_startblock),\n\t\tdblkcnt = XFS_FSB_TO_BB(mp, map.br_blockcount);\n\n\t\tbp = xfs_buf_get(mp->m_ddev_targp, dblkno, dblkcnt, 0);\n\t\tif (!bp)\n\t\t\treturn ENOMEM;\n\t\tbp->b_ops = &xfs_attr3_rmt_buf_ops;\n\n\t\txfs_attr_rmtval_copyin(mp, bp, args->dp->i_ino, &offset,\n\t\t\t\t       &valuelen, &src);\n\n\t\terror = xfs_bwrite(bp);\t/* GROT: NOTE: synchronous write */\n\t\txfs_buf_relse(bp);\n\t\tif (error)\n\t\t\treturn error;\n\n\n\t\t/* roll attribute extent map forwards */\n\t\tlblkno += map.br_blockcount;\n\t\tblkcnt -= map.br_blockcount;\n\t}\n\tASSERT(valuelen == 0);\n\treturn 0;\n}",
        "description": "The XFS implementation in the Linux kernel prior to version 3.15 improperly utilizes an outdated size value during remote attribute replacement, enabling local users to trigger a denial of service through transaction overruns and data corruption, or potentially escalate their privileges by exploiting XFS filesystem access.",
        "commit": "A vulnerability in the XFS filesystem allows for a remote attribute overwrite, leading to a transaction overrun. During remote attribute lookups, the length of the attribute is passed in the `xfs_da_args` structure to ensure correct CRC calculations and validity checks. However, this inadvertently modifies the `args->valuelen` parameter when replacing a remote attribute. Specifically, the lookup operation overwrites `args->valuelen` with the length of the existing remote attribute, causing the new attribute to be created with the incorrect size. If the new attribute is significantly smaller than the old one, this results in a transaction overrun and an assertion failure in debug kernels. The fix involves maintaining separate lengths for the remote attribute value and the attribute value within the `xfs_da_args` structure. Additionally, ensuring that remote block contexts saved for later renames are properly reset to avoid confusing the state of the attribute to be removed with the new attribute's state."
    },
    {
        "cwe": "CWE-119",
        "func_name": "torvalds/hugetlb_mcopy_atomic_pte",
        "score": 0.7595990300178528,
        "func_before": "int hugetlb_mcopy_atomic_pte(struct mm_struct *dst_mm,\n\t\t\t    pte_t *dst_pte,\n\t\t\t    struct vm_area_struct *dst_vma,\n\t\t\t    unsigned long dst_addr,\n\t\t\t    unsigned long src_addr,\n\t\t\t    struct page **pagep)\n{\n\tint vm_shared = dst_vma->vm_flags & VM_SHARED;\n\tstruct hstate *h = hstate_vma(dst_vma);\n\tpte_t _dst_pte;\n\tspinlock_t *ptl;\n\tint ret;\n\tstruct page *page;\n\n\tif (!*pagep) {\n\t\tret = -ENOMEM;\n\t\tpage = alloc_huge_page(dst_vma, dst_addr, 0);\n\t\tif (IS_ERR(page))\n\t\t\tgoto out;\n\n\t\tret = copy_huge_page_from_user(page,\n\t\t\t\t\t\t(const void __user *) src_addr,\n\t\t\t\t\t\tpages_per_huge_page(h), false);\n\n\t\t/* fallback to copy_from_user outside mmap_sem */\n\t\tif (unlikely(ret)) {\n\t\t\tret = -EFAULT;\n\t\t\t*pagep = page;\n\t\t\t/* don't free the page */\n\t\t\tgoto out;\n\t\t}\n\t} else {\n\t\tpage = *pagep;\n\t\t*pagep = NULL;\n\t}\n\n\t/*\n\t * The memory barrier inside __SetPageUptodate makes sure that\n\t * preceding stores to the page contents become visible before\n\t * the set_pte_at() write.\n\t */\n\t__SetPageUptodate(page);\n\tset_page_huge_active(page);\n\n\t/*\n\t * If shared, add to page cache\n\t */\n\tif (vm_shared) {\n\t\tstruct address_space *mapping = dst_vma->vm_file->f_mapping;\n\t\tpgoff_t idx = vma_hugecache_offset(h, dst_vma, dst_addr);\n\n\t\tret = huge_add_to_page_cache(page, mapping, idx);\n\t\tif (ret)\n\t\t\tgoto out_release_nounlock;\n\t}\n\n\tptl = huge_pte_lockptr(h, dst_mm, dst_pte);\n\tspin_lock(ptl);\n\n\tret = -EEXIST;\n\tif (!huge_pte_none(huge_ptep_get(dst_pte)))\n\t\tgoto out_release_unlock;\n\n\tif (vm_shared) {\n\t\tpage_dup_rmap(page, true);\n\t} else {\n\t\tClearPagePrivate(page);\n\t\thugepage_add_new_anon_rmap(page, dst_vma, dst_addr);\n\t}\n\n\t_dst_pte = make_huge_pte(dst_vma, page, dst_vma->vm_flags & VM_WRITE);\n\tif (dst_vma->vm_flags & VM_WRITE)\n\t\t_dst_pte = huge_pte_mkdirty(_dst_pte);\n\t_dst_pte = pte_mkyoung(_dst_pte);\n\n\tset_huge_pte_at(dst_mm, dst_addr, dst_pte, _dst_pte);\n\n\t(void)huge_ptep_set_access_flags(dst_vma, dst_addr, dst_pte, _dst_pte,\n\t\t\t\t\tdst_vma->vm_flags & VM_WRITE);\n\thugetlb_count_add(pages_per_huge_page(h), dst_mm);\n\n\t/* No need to invalidate - it was non-present before */\n\tupdate_mmu_cache(dst_vma, dst_addr, dst_pte);\n\n\tspin_unlock(ptl);\n\tif (vm_shared)\n\t\tunlock_page(page);\n\tret = 0;\nout:\n\treturn ret;\nout_release_unlock:\n\tspin_unlock(ptl);\n\tif (vm_shared)\n\t\tunlock_page(page);\nout_release_nounlock:\n\tput_page(page);\n\tgoto out;\n}",
        "func_after": "int hugetlb_mcopy_atomic_pte(struct mm_struct *dst_mm,\n\t\t\t    pte_t *dst_pte,\n\t\t\t    struct vm_area_struct *dst_vma,\n\t\t\t    unsigned long dst_addr,\n\t\t\t    unsigned long src_addr,\n\t\t\t    struct page **pagep)\n{\n\tstruct address_space *mapping;\n\tpgoff_t idx;\n\tunsigned long size;\n\tint vm_shared = dst_vma->vm_flags & VM_SHARED;\n\tstruct hstate *h = hstate_vma(dst_vma);\n\tpte_t _dst_pte;\n\tspinlock_t *ptl;\n\tint ret;\n\tstruct page *page;\n\n\tif (!*pagep) {\n\t\tret = -ENOMEM;\n\t\tpage = alloc_huge_page(dst_vma, dst_addr, 0);\n\t\tif (IS_ERR(page))\n\t\t\tgoto out;\n\n\t\tret = copy_huge_page_from_user(page,\n\t\t\t\t\t\t(const void __user *) src_addr,\n\t\t\t\t\t\tpages_per_huge_page(h), false);\n\n\t\t/* fallback to copy_from_user outside mmap_sem */\n\t\tif (unlikely(ret)) {\n\t\t\tret = -EFAULT;\n\t\t\t*pagep = page;\n\t\t\t/* don't free the page */\n\t\t\tgoto out;\n\t\t}\n\t} else {\n\t\tpage = *pagep;\n\t\t*pagep = NULL;\n\t}\n\n\t/*\n\t * The memory barrier inside __SetPageUptodate makes sure that\n\t * preceding stores to the page contents become visible before\n\t * the set_pte_at() write.\n\t */\n\t__SetPageUptodate(page);\n\tset_page_huge_active(page);\n\n\tmapping = dst_vma->vm_file->f_mapping;\n\tidx = vma_hugecache_offset(h, dst_vma, dst_addr);\n\n\t/*\n\t * If shared, add to page cache\n\t */\n\tif (vm_shared) {\n\t\tsize = i_size_read(mapping->host) >> huge_page_shift(h);\n\t\tret = -EFAULT;\n\t\tif (idx >= size)\n\t\t\tgoto out_release_nounlock;\n\n\t\t/*\n\t\t * Serialization between remove_inode_hugepages() and\n\t\t * huge_add_to_page_cache() below happens through the\n\t\t * hugetlb_fault_mutex_table that here must be hold by\n\t\t * the caller.\n\t\t */\n\t\tret = huge_add_to_page_cache(page, mapping, idx);\n\t\tif (ret)\n\t\t\tgoto out_release_nounlock;\n\t}\n\n\tptl = huge_pte_lockptr(h, dst_mm, dst_pte);\n\tspin_lock(ptl);\n\n\t/*\n\t * Recheck the i_size after holding PT lock to make sure not\n\t * to leave any page mapped (as page_mapped()) beyond the end\n\t * of the i_size (remove_inode_hugepages() is strict about\n\t * enforcing that). If we bail out here, we'll also leave a\n\t * page in the radix tree in the vm_shared case beyond the end\n\t * of the i_size, but remove_inode_hugepages() will take care\n\t * of it as soon as we drop the hugetlb_fault_mutex_table.\n\t */\n\tsize = i_size_read(mapping->host) >> huge_page_shift(h);\n\tret = -EFAULT;\n\tif (idx >= size)\n\t\tgoto out_release_unlock;\n\n\tret = -EEXIST;\n\tif (!huge_pte_none(huge_ptep_get(dst_pte)))\n\t\tgoto out_release_unlock;\n\n\tif (vm_shared) {\n\t\tpage_dup_rmap(page, true);\n\t} else {\n\t\tClearPagePrivate(page);\n\t\thugepage_add_new_anon_rmap(page, dst_vma, dst_addr);\n\t}\n\n\t_dst_pte = make_huge_pte(dst_vma, page, dst_vma->vm_flags & VM_WRITE);\n\tif (dst_vma->vm_flags & VM_WRITE)\n\t\t_dst_pte = huge_pte_mkdirty(_dst_pte);\n\t_dst_pte = pte_mkyoung(_dst_pte);\n\n\tset_huge_pte_at(dst_mm, dst_addr, dst_pte, _dst_pte);\n\n\t(void)huge_ptep_set_access_flags(dst_vma, dst_addr, dst_pte, _dst_pte,\n\t\t\t\t\tdst_vma->vm_flags & VM_WRITE);\n\thugetlb_count_add(pages_per_huge_page(h), dst_mm);\n\n\t/* No need to invalidate - it was non-present before */\n\tupdate_mmu_cache(dst_vma, dst_addr, dst_pte);\n\n\tspin_unlock(ptl);\n\tif (vm_shared)\n\t\tunlock_page(page);\n\tret = 0;\nout:\n\treturn ret;\nout_release_unlock:\n\tspin_unlock(ptl);\n\tif (vm_shared)\n\t\tunlock_page(page);\nout_release_nounlock:\n\tput_page(page);\n\tgoto out;\n}",
        "description": "A flaw was identified in the hugetlb_mcopy_atomic_pte function within the Linux kernel's memory management module, affecting versions prior to 4.13.12. The absence of a proper size check in this function could lead to a denial of service condition, indicated by a BUG.",
        "commit": "A vulnerability was identified in the userfaultfd functionality related to hugetlbfs, where the UFFDIO_COPY operation could inadvertently extend beyond the intended size of the file (i_size). This issue led to a kernel panic (oops) at fs/hugetlbfs/inode.c:484, triggered by the absence of an i_size check in the hugetlb_mcopy_atomic_pte function. Although mmap() operations could succeed beyond the end of the i_size after vmtruncate had removed virtual memory areas (vmas) in those ranges, subsequent faults, including UFFDIO_COPY, should not be allowed to succeed. The proposed solution involves modifying the return value to userland to indicate a SIGBUS-like condition, similar to what a page fault would produce, but this approach was deemed less useful due to the difficulty in distinguishing between SIGSEGV and SIGBUS through meaningful syscall return values."
    },
    {
        "cwe": "CWE-611",
        "func_name": "UIKit0/plist_from_xml",
        "score": 0.7047317624092102,
        "func_before": "PLIST_API void plist_from_xml(const char *plist_xml, uint32_t length, plist_t * plist)\n{\n    xmlDocPtr plist_doc = xmlParseMemory(plist_xml, length);\n    xmlNodePtr root_node = xmlDocGetRootElement(plist_doc);\n\n    xml_to_node(root_node, plist);\n    xmlFreeDoc(plist_doc);\n}",
        "func_after": "PLIST_API void plist_from_xml(const char *plist_xml, uint32_t length, plist_t * plist)\n{\n    /* CVE-2013-0339: disable external entity loading to prevent XXE vulnerability */\n    xmlSetExternalEntityLoader(plist_xml_external_entity_loader);\n\n    /* read XML from memory and disable network access for security reasons */\n    xmlDocPtr plist_doc = xmlReadMemory(plist_xml, length, \"plist_from_xml:memory\", NULL, XML_PARSE_NONET);\n    if (plist_doc) {\n        xmlNodePtr root_node = xmlDocGetRootElement(plist_doc);\n\n        xml_to_node(root_node, plist);\n        xmlFreeDoc(plist_doc);\n    }\n}",
        "description": "A vulnerability has been identified in the UIKit0 libplist library version 1.12, affecting the plist_from_xml function within the XML Handler component. This issue involves improper handling of XML external entity references, which could lead to potential security risks. To address this, a patch with the identifier c086cb139af7c82845f6d565e636073ff4b37440 has been developed. It is advised to apply this patch to mitigate the vulnerability.",
        "commit": "A security vulnerability related to XML property lists (plists) has been identified, where an attacker could potentially exploit a limited but possible XML External Entity (XXE) flaw. This vulnerability arises from the use of a specially crafted XML file that leverages a custom Document Type Definition (DTD) with an external entity reference. Such a file, when processed by the plistutil tool, could facilitate unauthorized GET requests to arbitrary URLs or disclose local files. Although practical exploitation is constrained, the issue has been addressed to enhance security. This vulnerability is analogous to CVE-2013-0339 observed in libxml2 and aligns with CWE-827. The vulnerability was reported by Lo\u00efc B\u00e9nis from calypt.com."
    },
    {
        "cwe": "CWE-212",
        "func_name": "linux4sam/secure_decrypt",
        "score": 0.7300318479537964,
        "func_before": "int secure_decrypt(void *data, unsigned int data_length, int is_signed)\n{\n\tat91_aes_key_size_t key_size;\n\tunsigned int cmac_key[8], cipher_key[8];\n\tunsigned int iv[AT91_AES_IV_SIZE_WORD];\n\tunsigned int computed_cmac[AT91_AES_BLOCK_SIZE_WORD];\n\tunsigned int fixed_length;\n\tconst unsigned int *cmac;\n\tint rc = -1;\n\n\t/* Init keys */\n\tinit_keys(&key_size, cipher_key, cmac_key, iv);\n\n\t/* Init periph */\n\tat91_aes_init();\n\n\t/* Check signature if required */\n\tif (is_signed) {\n\t\t/* Compute the CMAC */\n\t\tif (at91_aes_cmac(data_length, data, computed_cmac,\n\t\t\t\t  key_size, cmac_key))\n\t\t\tgoto exit;\n\n\t\t/* Check the CMAC */\n\t\tfixed_length = at91_aes_roundup(data_length);\n\t\tcmac = (const unsigned int *)((char *)data + fixed_length);\n\t\tif (!consttime_memequal(cmac, computed_cmac, AT91_AES_BLOCK_SIZE_BYTE))\n\t\t\tgoto exit;\n\t}\n\n\t/* Decrypt the whole file */\n\tif (at91_aes_cbc(data_length, data, data, 0,\n\t\t\t key_size, cipher_key, iv))\n\t\tgoto exit;\n\n\trc = 0;\nexit:\n\t/* Reset periph */\n\tat91_aes_cleanup();\n\n\t/* Reset keys */\n\tmemset(cmac_key, 0, sizeof(cmac_key));\n\tmemset(cipher_key, 0, sizeof(cipher_key));\n\tmemset(iv, 0, sizeof(iv));\n\n\treturn rc;\n}",
        "func_after": "static int secure_decrypt(void *data, unsigned int data_length, int is_signed)\n{\n\tat91_aes_key_size_t key_size;\n\tunsigned int computed_cmac[AT91_AES_BLOCK_SIZE_WORD];\n\tunsigned int fixed_length;\n\tconst unsigned int *cmac;\n\tint rc = -1;\n\n#if defined(CONFIG_AES_KEY_SIZE_128)\n\tkey_size = AT91_AES_KEY_SIZE_128;\n#elif defined(CONFIG_AES_KEY_SIZE_192)\n\tkey_size = AT91_AES_KEY_SIZE_192;\n#elif defined(CONFIG_AES_KEY_SIZE_256)\n\tkey_size = AT91_AES_KEY_SIZE_256;\n#else\n#error \"bad AES key size\"\n#endif\n\n\t/* Init periph */\n\tat91_aes_init();\n\n\t/* Check signature if required */\n\tif (is_signed) {\n\t\t/* Compute the CMAC */\n\t\tif (at91_aes_cmac(data_length, data, computed_cmac,\n\t\t\t\t  key_size, cmac_key))\n\t\t\tgoto exit;\n\n\t\t/* Check the CMAC */\n\t\tfixed_length = at91_aes_roundup(data_length);\n\t\tcmac = (const unsigned int *)((char *)data + fixed_length);\n\t\tif (!consttime_memequal(cmac, computed_cmac, AT91_AES_BLOCK_SIZE_BYTE))\n\t\t\tgoto exit;\n\t}\n\n\t/* Decrypt the whole file */\n\tif (at91_aes_cbc(data_length, data, data, 0,\n\t\t\t key_size, cipher_key, iv))\n\t\tgoto exit;\n\n\trc = 0;\nexit:\n\t/* Reset periph */\n\tat91_aes_cleanup();\n\n\treturn rc;\n}",
        "description": "AT91bootstrap versions prior to 3.9.2 fail to adequately clear encryption and authentication keys from memory before transitioning control to a less privileged software component. This failure can be exploited to expose these keys, potentially allowing attackers to encrypt and sign subsequent boot stages, such as the bootloader.",
        "commit": "The vulnerability knowledge has been abstracted and generalized as follows:\n\n\"Keys were moved into static arrays to prevent their copying from the code section to the stack during initialization. By hardcoding the keys into the data section at compile time and ensuring they can be completely wiped after use, this change enhances security by reducing the risk of key exposure.\""
    }
]