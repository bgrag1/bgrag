[
    {
        "cwe": "CWE-17",
        "func_name": "torvalds/udf_find_entry",
        "score": 0.7779011726379395,
        "func_before": "static struct fileIdentDesc *udf_find_entry(struct inode *dir,\n\t\t\t\t\t    const struct qstr *child,\n\t\t\t\t\t    struct udf_fileident_bh *fibh,\n\t\t\t\t\t    struct fileIdentDesc *cfi)\n{\n\tstruct fileIdentDesc *fi = NULL;\n\tloff_t f_pos;\n\tint block, flen;\n\tunsigned char *fname = NULL;\n\tunsigned char *nameptr;\n\tuint8_t lfi;\n\tuint16_t liu;\n\tloff_t size;\n\tstruct kernel_lb_addr eloc;\n\tuint32_t elen;\n\tsector_t offset;\n\tstruct extent_position epos = {};\n\tstruct udf_inode_info *dinfo = UDF_I(dir);\n\tint isdotdot = child->len == 2 &&\n\t\tchild->name[0] == '.' && child->name[1] == '.';\n\n\tsize = udf_ext0_offset(dir) + dir->i_size;\n\tf_pos = udf_ext0_offset(dir);\n\n\tfibh->sbh = fibh->ebh = NULL;\n\tfibh->soffset = fibh->eoffset = f_pos & (dir->i_sb->s_blocksize - 1);\n\tif (dinfo->i_alloc_type != ICBTAG_FLAG_AD_IN_ICB) {\n\t\tif (inode_bmap(dir, f_pos >> dir->i_sb->s_blocksize_bits, &epos,\n\t\t    &eloc, &elen, &offset) != (EXT_RECORDED_ALLOCATED >> 30))\n\t\t\tgoto out_err;\n\t\tblock = udf_get_lb_pblock(dir->i_sb, &eloc, offset);\n\t\tif ((++offset << dir->i_sb->s_blocksize_bits) < elen) {\n\t\t\tif (dinfo->i_alloc_type == ICBTAG_FLAG_AD_SHORT)\n\t\t\t\tepos.offset -= sizeof(struct short_ad);\n\t\t\telse if (dinfo->i_alloc_type == ICBTAG_FLAG_AD_LONG)\n\t\t\t\tepos.offset -= sizeof(struct long_ad);\n\t\t} else\n\t\t\toffset = 0;\n\n\t\tfibh->sbh = fibh->ebh = udf_tread(dir->i_sb, block);\n\t\tif (!fibh->sbh)\n\t\t\tgoto out_err;\n\t}\n\n\tfname = kmalloc(UDF_NAME_LEN, GFP_NOFS);\n\tif (!fname)\n\t\tgoto out_err;\n\n\twhile (f_pos < size) {\n\t\tfi = udf_fileident_read(dir, &f_pos, fibh, cfi, &epos, &eloc,\n\t\t\t\t\t&elen, &offset);\n\t\tif (!fi)\n\t\t\tgoto out_err;\n\n\t\tliu = le16_to_cpu(cfi->lengthOfImpUse);\n\t\tlfi = cfi->lengthFileIdent;\n\n\t\tif (fibh->sbh == fibh->ebh) {\n\t\t\tnameptr = fi->fileIdent + liu;\n\t\t} else {\n\t\t\tint poffset;\t/* Unpaded ending offset */\n\n\t\t\tpoffset = fibh->soffset + sizeof(struct fileIdentDesc) +\n\t\t\t\t\tliu + lfi;\n\n\t\t\tif (poffset >= lfi)\n\t\t\t\tnameptr = (uint8_t *)(fibh->ebh->b_data +\n\t\t\t\t\t\t      poffset - lfi);\n\t\t\telse {\n\t\t\t\tnameptr = fname;\n\t\t\t\tmemcpy(nameptr, fi->fileIdent + liu,\n\t\t\t\t\tlfi - poffset);\n\t\t\t\tmemcpy(nameptr + lfi - poffset,\n\t\t\t\t\tfibh->ebh->b_data, poffset);\n\t\t\t}\n\t\t}\n\n\t\tif ((cfi->fileCharacteristics & FID_FILE_CHAR_DELETED) != 0) {\n\t\t\tif (!UDF_QUERY_FLAG(dir->i_sb, UDF_FLAG_UNDELETE))\n\t\t\t\tcontinue;\n\t\t}\n\n\t\tif ((cfi->fileCharacteristics & FID_FILE_CHAR_HIDDEN) != 0) {\n\t\t\tif (!UDF_QUERY_FLAG(dir->i_sb, UDF_FLAG_UNHIDE))\n\t\t\t\tcontinue;\n\t\t}\n\n\t\tif ((cfi->fileCharacteristics & FID_FILE_CHAR_PARENT) &&\n\t\t    isdotdot)\n\t\t\tgoto out_ok;\n\n\t\tif (!lfi)\n\t\t\tcontinue;\n\n\t\tflen = udf_get_filename(dir->i_sb, nameptr, fname, lfi);\n\t\tif (flen && udf_match(flen, fname, child->len, child->name))\n\t\t\tgoto out_ok;\n\t}\n\nout_err:\n\tfi = NULL;\n\tif (fibh->sbh != fibh->ebh)\n\t\tbrelse(fibh->ebh);\n\tbrelse(fibh->sbh);\nout_ok:\n\tbrelse(epos.bh);\n\tkfree(fname);\n\n\treturn fi;\n}",
        "func_after": "static struct fileIdentDesc *udf_find_entry(struct inode *dir,\n\t\t\t\t\t    const struct qstr *child,\n\t\t\t\t\t    struct udf_fileident_bh *fibh,\n\t\t\t\t\t    struct fileIdentDesc *cfi)\n{\n\tstruct fileIdentDesc *fi = NULL;\n\tloff_t f_pos;\n\tint block, flen;\n\tunsigned char *fname = NULL;\n\tunsigned char *nameptr;\n\tuint8_t lfi;\n\tuint16_t liu;\n\tloff_t size;\n\tstruct kernel_lb_addr eloc;\n\tuint32_t elen;\n\tsector_t offset;\n\tstruct extent_position epos = {};\n\tstruct udf_inode_info *dinfo = UDF_I(dir);\n\tint isdotdot = child->len == 2 &&\n\t\tchild->name[0] == '.' && child->name[1] == '.';\n\n\tsize = udf_ext0_offset(dir) + dir->i_size;\n\tf_pos = udf_ext0_offset(dir);\n\n\tfibh->sbh = fibh->ebh = NULL;\n\tfibh->soffset = fibh->eoffset = f_pos & (dir->i_sb->s_blocksize - 1);\n\tif (dinfo->i_alloc_type != ICBTAG_FLAG_AD_IN_ICB) {\n\t\tif (inode_bmap(dir, f_pos >> dir->i_sb->s_blocksize_bits, &epos,\n\t\t    &eloc, &elen, &offset) != (EXT_RECORDED_ALLOCATED >> 30))\n\t\t\tgoto out_err;\n\t\tblock = udf_get_lb_pblock(dir->i_sb, &eloc, offset);\n\t\tif ((++offset << dir->i_sb->s_blocksize_bits) < elen) {\n\t\t\tif (dinfo->i_alloc_type == ICBTAG_FLAG_AD_SHORT)\n\t\t\t\tepos.offset -= sizeof(struct short_ad);\n\t\t\telse if (dinfo->i_alloc_type == ICBTAG_FLAG_AD_LONG)\n\t\t\t\tepos.offset -= sizeof(struct long_ad);\n\t\t} else\n\t\t\toffset = 0;\n\n\t\tfibh->sbh = fibh->ebh = udf_tread(dir->i_sb, block);\n\t\tif (!fibh->sbh)\n\t\t\tgoto out_err;\n\t}\n\n\tfname = kmalloc(UDF_NAME_LEN, GFP_NOFS);\n\tif (!fname)\n\t\tgoto out_err;\n\n\twhile (f_pos < size) {\n\t\tfi = udf_fileident_read(dir, &f_pos, fibh, cfi, &epos, &eloc,\n\t\t\t\t\t&elen, &offset);\n\t\tif (!fi)\n\t\t\tgoto out_err;\n\n\t\tliu = le16_to_cpu(cfi->lengthOfImpUse);\n\t\tlfi = cfi->lengthFileIdent;\n\n\t\tif (fibh->sbh == fibh->ebh) {\n\t\t\tnameptr = fi->fileIdent + liu;\n\t\t} else {\n\t\t\tint poffset;\t/* Unpaded ending offset */\n\n\t\t\tpoffset = fibh->soffset + sizeof(struct fileIdentDesc) +\n\t\t\t\t\tliu + lfi;\n\n\t\t\tif (poffset >= lfi)\n\t\t\t\tnameptr = (uint8_t *)(fibh->ebh->b_data +\n\t\t\t\t\t\t      poffset - lfi);\n\t\t\telse {\n\t\t\t\tnameptr = fname;\n\t\t\t\tmemcpy(nameptr, fi->fileIdent + liu,\n\t\t\t\t\tlfi - poffset);\n\t\t\t\tmemcpy(nameptr + lfi - poffset,\n\t\t\t\t\tfibh->ebh->b_data, poffset);\n\t\t\t}\n\t\t}\n\n\t\tif ((cfi->fileCharacteristics & FID_FILE_CHAR_DELETED) != 0) {\n\t\t\tif (!UDF_QUERY_FLAG(dir->i_sb, UDF_FLAG_UNDELETE))\n\t\t\t\tcontinue;\n\t\t}\n\n\t\tif ((cfi->fileCharacteristics & FID_FILE_CHAR_HIDDEN) != 0) {\n\t\t\tif (!UDF_QUERY_FLAG(dir->i_sb, UDF_FLAG_UNHIDE))\n\t\t\t\tcontinue;\n\t\t}\n\n\t\tif ((cfi->fileCharacteristics & FID_FILE_CHAR_PARENT) &&\n\t\t    isdotdot)\n\t\t\tgoto out_ok;\n\n\t\tif (!lfi)\n\t\t\tcontinue;\n\n\t\tflen = udf_get_filename(dir->i_sb, nameptr, lfi, fname,\n\t\t\t\t\tUDF_NAME_LEN);\n\t\tif (flen && udf_match(flen, fname, child->len, child->name))\n\t\t\tgoto out_ok;\n\t}\n\nout_err:\n\tfi = NULL;\n\tif (fibh->sbh != fibh->ebh)\n\t\tbrelse(fibh->ebh);\n\tbrelse(fibh->sbh);\nout_ok:\n\tbrelse(epos.bh);\n\tkfree(fname);\n\n\treturn fi;\n}",
        "description": "The UDF filesystem implementation in the Linux kernel prior to version 3.18.2 does not verify that sufficient space is allocated for storing a symlink target's name along with a trailing null character. This oversight enables local users to potentially access sensitive information through a specially crafted filesystem image.",
        "commit": "The vulnerability involves a failure to verify whether the resolved path from reading a symbolic link fits within the allocated buffer size. This oversight occurs during the process of reading symlinks, where the code does not account for potential encoding conversions that could increase the path length. Consequently, there is a risk that the path may exceed the buffer capacity, leading to buffer overflow issues."
    },
    {
        "cwe": "CWE-189",
        "func_name": "torvalds/i915_gem_execbuffer2",
        "score": 0.7574936747550964,
        "func_before": "int\ni915_gem_execbuffer2(struct drm_device *dev, void *data,\n\t\t     struct drm_file *file)\n{\n\tstruct drm_i915_gem_execbuffer2 *args = data;\n\tstruct drm_i915_gem_exec_object2 *exec2_list = NULL;\n\tint ret;\n\n\tif (args->buffer_count < 1) {\n\t\tDRM_DEBUG(\"execbuf2 with %d buffers\\n\", args->buffer_count);\n\t\treturn -EINVAL;\n\t}\n\n\texec2_list = kmalloc(sizeof(*exec2_list)*args->buffer_count,\n\t\t\t     GFP_KERNEL | __GFP_NOWARN | __GFP_NORETRY);\n\tif (exec2_list == NULL)\n\t\texec2_list = drm_malloc_ab(sizeof(*exec2_list),\n\t\t\t\t\t   args->buffer_count);\n\tif (exec2_list == NULL) {\n\t\tDRM_DEBUG(\"Failed to allocate exec list for %d buffers\\n\",\n\t\t\t  args->buffer_count);\n\t\treturn -ENOMEM;\n\t}\n\tret = copy_from_user(exec2_list,\n\t\t\t     (struct drm_i915_relocation_entry __user *)\n\t\t\t     (uintptr_t) args->buffers_ptr,\n\t\t\t     sizeof(*exec2_list) * args->buffer_count);\n\tif (ret != 0) {\n\t\tDRM_DEBUG(\"copy %d exec entries failed %d\\n\",\n\t\t\t  args->buffer_count, ret);\n\t\tdrm_free_large(exec2_list);\n\t\treturn -EFAULT;\n\t}\n\n\tret = i915_gem_do_execbuffer(dev, data, file, args, exec2_list);\n\tif (!ret) {\n\t\t/* Copy the new buffer offsets back to the user's exec list. */\n\t\tret = copy_to_user((struct drm_i915_relocation_entry __user *)\n\t\t\t\t   (uintptr_t) args->buffers_ptr,\n\t\t\t\t   exec2_list,\n\t\t\t\t   sizeof(*exec2_list) * args->buffer_count);\n\t\tif (ret) {\n\t\t\tret = -EFAULT;\n\t\t\tDRM_DEBUG(\"failed to copy %d exec entries \"\n\t\t\t\t  \"back to user (%d)\\n\",\n\t\t\t\t  args->buffer_count, ret);\n\t\t}\n\t}\n\n\tdrm_free_large(exec2_list);\n\treturn ret;\n}",
        "func_after": "int\ni915_gem_execbuffer2(struct drm_device *dev, void *data,\n\t\t     struct drm_file *file)\n{\n\tstruct drm_i915_gem_execbuffer2 *args = data;\n\tstruct drm_i915_gem_exec_object2 *exec2_list = NULL;\n\tint ret;\n\n\tif (args->buffer_count < 1 ||\n\t    args->buffer_count > UINT_MAX / sizeof(*exec2_list)) {\n\t\tDRM_DEBUG(\"execbuf2 with %d buffers\\n\", args->buffer_count);\n\t\treturn -EINVAL;\n\t}\n\n\texec2_list = kmalloc(sizeof(*exec2_list)*args->buffer_count,\n\t\t\t     GFP_KERNEL | __GFP_NOWARN | __GFP_NORETRY);\n\tif (exec2_list == NULL)\n\t\texec2_list = drm_malloc_ab(sizeof(*exec2_list),\n\t\t\t\t\t   args->buffer_count);\n\tif (exec2_list == NULL) {\n\t\tDRM_DEBUG(\"Failed to allocate exec list for %d buffers\\n\",\n\t\t\t  args->buffer_count);\n\t\treturn -ENOMEM;\n\t}\n\tret = copy_from_user(exec2_list,\n\t\t\t     (struct drm_i915_relocation_entry __user *)\n\t\t\t     (uintptr_t) args->buffers_ptr,\n\t\t\t     sizeof(*exec2_list) * args->buffer_count);\n\tif (ret != 0) {\n\t\tDRM_DEBUG(\"copy %d exec entries failed %d\\n\",\n\t\t\t  args->buffer_count, ret);\n\t\tdrm_free_large(exec2_list);\n\t\treturn -EFAULT;\n\t}\n\n\tret = i915_gem_do_execbuffer(dev, data, file, args, exec2_list);\n\tif (!ret) {\n\t\t/* Copy the new buffer offsets back to the user's exec list. */\n\t\tret = copy_to_user((struct drm_i915_relocation_entry __user *)\n\t\t\t\t   (uintptr_t) args->buffers_ptr,\n\t\t\t\t   exec2_list,\n\t\t\t\t   sizeof(*exec2_list) * args->buffer_count);\n\t\tif (ret) {\n\t\t\tret = -EFAULT;\n\t\t\tDRM_DEBUG(\"failed to copy %d exec entries \"\n\t\t\t\t  \"back to user (%d)\\n\",\n\t\t\t\t  args->buffer_count, ret);\n\t\t}\n\t}\n\n\tdrm_free_large(exec2_list);\n\treturn ret;\n}",
        "description": "An integer overflow vulnerability exists within the `i915_gem_execbuffer2` function of the DRM subsystem in the Linux kernel prior to version 3.3.5 on 32-bit platforms. This flaw allows local users to trigger a denial of service through an out-of-bounds write or potentially cause other unspecified impacts via a specially crafted ioctl call.",
        "commit": "A vulnerability was identified in the i915 driver of the DRM subsystem within the Linux kernel, where a large `args->buffer_count` value provided by userspace through an ioctl call could cause an integer overflow on 32-bit systems. This overflow affects the calculation of the allocation size for temporary execution buffers, potentially leading to out-of-bounds memory access. This issue arose due to changes introduced in commit 8408c282, which attempted to optimize buffer allocation by first trying a normal large `kmalloc`."
    },
    {
        "cwe": "CWE-665",
        "func_name": "torvalds/__skb_flow_dissect",
        "score": 0.7720255851745605,
        "func_before": "bool __skb_flow_dissect(const struct sk_buff *skb,\n\t\t\tstruct flow_dissector *flow_dissector,\n\t\t\tvoid *target_container,\n\t\t\tvoid *data, __be16 proto, int nhoff, int hlen)\n{\n\tstruct flow_dissector_key_control *key_control;\n\tstruct flow_dissector_key_basic *key_basic;\n\tstruct flow_dissector_key_addrs *key_addrs;\n\tstruct flow_dissector_key_ports *key_ports;\n\tstruct flow_dissector_key_tags *key_tags;\n\tstruct flow_dissector_key_keyid *key_keyid;\n\tu8 ip_proto = 0;\n\n\tif (!data) {\n\t\tdata = skb->data;\n\t\tproto = skb->protocol;\n\t\tnhoff = skb_network_offset(skb);\n\t\thlen = skb_headlen(skb);\n\t}\n\n\t/* It is ensured by skb_flow_dissector_init() that control key will\n\t * be always present.\n\t */\n\tkey_control = skb_flow_dissector_target(flow_dissector,\n\t\t\t\t\t\tFLOW_DISSECTOR_KEY_CONTROL,\n\t\t\t\t\t\ttarget_container);\n\n\t/* It is ensured by skb_flow_dissector_init() that basic key will\n\t * be always present.\n\t */\n\tkey_basic = skb_flow_dissector_target(flow_dissector,\n\t\t\t\t\t      FLOW_DISSECTOR_KEY_BASIC,\n\t\t\t\t\t      target_container);\n\n\tif (skb_flow_dissector_uses_key(flow_dissector,\n\t\t\t\t\tFLOW_DISSECTOR_KEY_ETH_ADDRS)) {\n\t\tstruct ethhdr *eth = eth_hdr(skb);\n\t\tstruct flow_dissector_key_eth_addrs *key_eth_addrs;\n\n\t\tkey_eth_addrs = skb_flow_dissector_target(flow_dissector,\n\t\t\t\t\t\t\t  FLOW_DISSECTOR_KEY_ETH_ADDRS,\n\t\t\t\t\t\t\t  target_container);\n\t\tmemcpy(key_eth_addrs, &eth->h_dest, sizeof(*key_eth_addrs));\n\t}\n\nagain:\n\tswitch (proto) {\n\tcase htons(ETH_P_IP): {\n\t\tconst struct iphdr *iph;\n\t\tstruct iphdr _iph;\nip:\n\t\tiph = __skb_header_pointer(skb, nhoff, sizeof(_iph), data, hlen, &_iph);\n\t\tif (!iph || iph->ihl < 5)\n\t\t\treturn false;\n\t\tnhoff += iph->ihl * 4;\n\n\t\tip_proto = iph->protocol;\n\t\tif (ip_is_fragment(iph))\n\t\t\tip_proto = 0;\n\n\t\tif (!skb_flow_dissector_uses_key(flow_dissector,\n\t\t\t\t\t\t FLOW_DISSECTOR_KEY_IPV4_ADDRS))\n\t\t\tbreak;\n\n\t\tkey_addrs = skb_flow_dissector_target(flow_dissector,\n\t\t\t      FLOW_DISSECTOR_KEY_IPV4_ADDRS, target_container);\n\t\tmemcpy(&key_addrs->v4addrs, &iph->saddr,\n\t\t       sizeof(key_addrs->v4addrs));\n\t\tkey_control->addr_type = FLOW_DISSECTOR_KEY_IPV4_ADDRS;\n\t\tbreak;\n\t}\n\tcase htons(ETH_P_IPV6): {\n\t\tconst struct ipv6hdr *iph;\n\t\tstruct ipv6hdr _iph;\n\t\t__be32 flow_label;\n\nipv6:\n\t\tiph = __skb_header_pointer(skb, nhoff, sizeof(_iph), data, hlen, &_iph);\n\t\tif (!iph)\n\t\t\treturn false;\n\n\t\tip_proto = iph->nexthdr;\n\t\tnhoff += sizeof(struct ipv6hdr);\n\n\t\tif (skb_flow_dissector_uses_key(flow_dissector,\n\t\t\t\t\t\tFLOW_DISSECTOR_KEY_IPV6_ADDRS)) {\n\t\t\tstruct flow_dissector_key_ipv6_addrs *key_ipv6_addrs;\n\n\t\t\tkey_ipv6_addrs = skb_flow_dissector_target(flow_dissector,\n\t\t\t\t\t\t\t\t   FLOW_DISSECTOR_KEY_IPV6_ADDRS,\n\t\t\t\t\t\t\t\t   target_container);\n\n\t\t\tmemcpy(key_ipv6_addrs, &iph->saddr, sizeof(*key_ipv6_addrs));\n\t\t\tkey_control->addr_type = FLOW_DISSECTOR_KEY_IPV6_ADDRS;\n\t\t}\n\n\t\tflow_label = ip6_flowlabel(iph);\n\t\tif (flow_label) {\n\t\t\tif (skb_flow_dissector_uses_key(flow_dissector,\n\t\t\t\tFLOW_DISSECTOR_KEY_FLOW_LABEL)) {\n\t\t\t\tkey_tags = skb_flow_dissector_target(flow_dissector,\n\t\t\t\t\t\t\t\t     FLOW_DISSECTOR_KEY_FLOW_LABEL,\n\t\t\t\t\t\t\t\t     target_container);\n\t\t\t\tkey_tags->flow_label = ntohl(flow_label);\n\t\t\t}\n\t\t}\n\n\t\tbreak;\n\t}\n\tcase htons(ETH_P_8021AD):\n\tcase htons(ETH_P_8021Q): {\n\t\tconst struct vlan_hdr *vlan;\n\t\tstruct vlan_hdr _vlan;\n\n\t\tvlan = __skb_header_pointer(skb, nhoff, sizeof(_vlan), data, hlen, &_vlan);\n\t\tif (!vlan)\n\t\t\treturn false;\n\n\t\tif (skb_flow_dissector_uses_key(flow_dissector,\n\t\t\t\t\t\tFLOW_DISSECTOR_KEY_VLANID)) {\n\t\t\tkey_tags = skb_flow_dissector_target(flow_dissector,\n\t\t\t\t\t\t\t     FLOW_DISSECTOR_KEY_VLANID,\n\t\t\t\t\t\t\t     target_container);\n\n\t\t\tkey_tags->vlan_id = skb_vlan_tag_get_id(skb);\n\t\t}\n\n\t\tproto = vlan->h_vlan_encapsulated_proto;\n\t\tnhoff += sizeof(*vlan);\n\t\tgoto again;\n\t}\n\tcase htons(ETH_P_PPP_SES): {\n\t\tstruct {\n\t\t\tstruct pppoe_hdr hdr;\n\t\t\t__be16 proto;\n\t\t} *hdr, _hdr;\n\t\thdr = __skb_header_pointer(skb, nhoff, sizeof(_hdr), data, hlen, &_hdr);\n\t\tif (!hdr)\n\t\t\treturn false;\n\t\tproto = hdr->proto;\n\t\tnhoff += PPPOE_SES_HLEN;\n\t\tswitch (proto) {\n\t\tcase htons(PPP_IP):\n\t\t\tgoto ip;\n\t\tcase htons(PPP_IPV6):\n\t\t\tgoto ipv6;\n\t\tdefault:\n\t\t\treturn false;\n\t\t}\n\t}\n\tcase htons(ETH_P_TIPC): {\n\t\tstruct {\n\t\t\t__be32 pre[3];\n\t\t\t__be32 srcnode;\n\t\t} *hdr, _hdr;\n\t\thdr = __skb_header_pointer(skb, nhoff, sizeof(_hdr), data, hlen, &_hdr);\n\t\tif (!hdr)\n\t\t\treturn false;\n\t\tkey_basic->n_proto = proto;\n\t\tkey_control->thoff = (u16)nhoff;\n\n\t\tif (skb_flow_dissector_uses_key(flow_dissector,\n\t\t\t\t\t\tFLOW_DISSECTOR_KEY_TIPC_ADDRS)) {\n\t\t\tkey_addrs = skb_flow_dissector_target(flow_dissector,\n\t\t\t\t\t\t\t      FLOW_DISSECTOR_KEY_TIPC_ADDRS,\n\t\t\t\t\t\t\t      target_container);\n\t\t\tkey_addrs->tipcaddrs.srcnode = hdr->srcnode;\n\t\t\tkey_control->addr_type = FLOW_DISSECTOR_KEY_TIPC_ADDRS;\n\t\t}\n\t\treturn true;\n\t}\n\n\tcase htons(ETH_P_MPLS_UC):\n\tcase htons(ETH_P_MPLS_MC): {\n\t\tstruct mpls_label *hdr, _hdr[2];\nmpls:\n\t\thdr = __skb_header_pointer(skb, nhoff, sizeof(_hdr), data,\n\t\t\t\t\t   hlen, &_hdr);\n\t\tif (!hdr)\n\t\t\treturn false;\n\n\t\tif ((ntohl(hdr[0].entry) & MPLS_LS_LABEL_MASK) >>\n\t\t     MPLS_LS_LABEL_SHIFT == MPLS_LABEL_ENTROPY) {\n\t\t\tif (skb_flow_dissector_uses_key(flow_dissector,\n\t\t\t\t\t\t\tFLOW_DISSECTOR_KEY_MPLS_ENTROPY)) {\n\t\t\t\tkey_keyid = skb_flow_dissector_target(flow_dissector,\n\t\t\t\t\t\t\t\t      FLOW_DISSECTOR_KEY_MPLS_ENTROPY,\n\t\t\t\t\t\t\t\t      target_container);\n\t\t\t\tkey_keyid->keyid = hdr[1].entry &\n\t\t\t\t\thtonl(MPLS_LS_LABEL_MASK);\n\t\t\t}\n\n\t\t\tkey_basic->n_proto = proto;\n\t\t\tkey_basic->ip_proto = ip_proto;\n\t\t\tkey_control->thoff = (u16)nhoff;\n\n\t\t\treturn true;\n\t\t}\n\n\t\treturn true;\n\t}\n\n\tcase htons(ETH_P_FCOE):\n\t\tkey_control->thoff = (u16)(nhoff + FCOE_HEADER_LEN);\n\t\t/* fall through */\n\tdefault:\n\t\treturn false;\n\t}\n\nip_proto_again:\n\tswitch (ip_proto) {\n\tcase IPPROTO_GRE: {\n\t\tstruct gre_hdr {\n\t\t\t__be16 flags;\n\t\t\t__be16 proto;\n\t\t} *hdr, _hdr;\n\n\t\thdr = __skb_header_pointer(skb, nhoff, sizeof(_hdr), data, hlen, &_hdr);\n\t\tif (!hdr)\n\t\t\treturn false;\n\t\t/*\n\t\t * Only look inside GRE if version zero and no\n\t\t * routing\n\t\t */\n\t\tif (hdr->flags & (GRE_VERSION | GRE_ROUTING))\n\t\t\tbreak;\n\n\t\tproto = hdr->proto;\n\t\tnhoff += 4;\n\t\tif (hdr->flags & GRE_CSUM)\n\t\t\tnhoff += 4;\n\t\tif (hdr->flags & GRE_KEY) {\n\t\t\tconst __be32 *keyid;\n\t\t\t__be32 _keyid;\n\n\t\t\tkeyid = __skb_header_pointer(skb, nhoff, sizeof(_keyid),\n\t\t\t\t\t\t     data, hlen, &_keyid);\n\n\t\t\tif (!keyid)\n\t\t\t\treturn false;\n\n\t\t\tif (skb_flow_dissector_uses_key(flow_dissector,\n\t\t\t\t\t\t\tFLOW_DISSECTOR_KEY_GRE_KEYID)) {\n\t\t\t\tkey_keyid = skb_flow_dissector_target(flow_dissector,\n\t\t\t\t\t\t\t\t      FLOW_DISSECTOR_KEY_GRE_KEYID,\n\t\t\t\t\t\t\t\t      target_container);\n\t\t\t\tkey_keyid->keyid = *keyid;\n\t\t\t}\n\t\t\tnhoff += 4;\n\t\t}\n\t\tif (hdr->flags & GRE_SEQ)\n\t\t\tnhoff += 4;\n\t\tif (proto == htons(ETH_P_TEB)) {\n\t\t\tconst struct ethhdr *eth;\n\t\t\tstruct ethhdr _eth;\n\n\t\t\teth = __skb_header_pointer(skb, nhoff,\n\t\t\t\t\t\t   sizeof(_eth),\n\t\t\t\t\t\t   data, hlen, &_eth);\n\t\t\tif (!eth)\n\t\t\t\treturn false;\n\t\t\tproto = eth->h_proto;\n\t\t\tnhoff += sizeof(*eth);\n\t\t}\n\t\tgoto again;\n\t}\n\tcase NEXTHDR_HOP:\n\tcase NEXTHDR_ROUTING:\n\tcase NEXTHDR_DEST: {\n\t\tu8 _opthdr[2], *opthdr;\n\n\t\tif (proto != htons(ETH_P_IPV6))\n\t\t\tbreak;\n\n\t\topthdr = __skb_header_pointer(skb, nhoff, sizeof(_opthdr),\n\t\t\t\t\t      data, hlen, &_opthdr);\n\t\tif (!opthdr)\n\t\t\treturn false;\n\n\t\tip_proto = opthdr[0];\n\t\tnhoff += (opthdr[1] + 1) << 3;\n\n\t\tgoto ip_proto_again;\n\t}\n\tcase IPPROTO_IPIP:\n\t\tproto = htons(ETH_P_IP);\n\t\tgoto ip;\n\tcase IPPROTO_IPV6:\n\t\tproto = htons(ETH_P_IPV6);\n\t\tgoto ipv6;\n\tcase IPPROTO_MPLS:\n\t\tproto = htons(ETH_P_MPLS_UC);\n\t\tgoto mpls;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tkey_basic->n_proto = proto;\n\tkey_basic->ip_proto = ip_proto;\n\tkey_control->thoff = (u16)nhoff;\n\n\tif (skb_flow_dissector_uses_key(flow_dissector,\n\t\t\t\t\tFLOW_DISSECTOR_KEY_PORTS)) {\n\t\tkey_ports = skb_flow_dissector_target(flow_dissector,\n\t\t\t\t\t\t      FLOW_DISSECTOR_KEY_PORTS,\n\t\t\t\t\t\t      target_container);\n\t\tkey_ports->ports = __skb_flow_get_ports(skb, nhoff, ip_proto,\n\t\t\t\t\t\t\tdata, hlen);\n\t}\n\n\treturn true;\n}",
        "func_after": "bool __skb_flow_dissect(const struct sk_buff *skb,\n\t\t\tstruct flow_dissector *flow_dissector,\n\t\t\tvoid *target_container,\n\t\t\tvoid *data, __be16 proto, int nhoff, int hlen)\n{\n\tstruct flow_dissector_key_control *key_control;\n\tstruct flow_dissector_key_basic *key_basic;\n\tstruct flow_dissector_key_addrs *key_addrs;\n\tstruct flow_dissector_key_ports *key_ports;\n\tstruct flow_dissector_key_tags *key_tags;\n\tstruct flow_dissector_key_keyid *key_keyid;\n\tu8 ip_proto = 0;\n\tbool ret = false;\n\n\tif (!data) {\n\t\tdata = skb->data;\n\t\tproto = skb->protocol;\n\t\tnhoff = skb_network_offset(skb);\n\t\thlen = skb_headlen(skb);\n\t}\n\n\t/* It is ensured by skb_flow_dissector_init() that control key will\n\t * be always present.\n\t */\n\tkey_control = skb_flow_dissector_target(flow_dissector,\n\t\t\t\t\t\tFLOW_DISSECTOR_KEY_CONTROL,\n\t\t\t\t\t\ttarget_container);\n\n\t/* It is ensured by skb_flow_dissector_init() that basic key will\n\t * be always present.\n\t */\n\tkey_basic = skb_flow_dissector_target(flow_dissector,\n\t\t\t\t\t      FLOW_DISSECTOR_KEY_BASIC,\n\t\t\t\t\t      target_container);\n\n\tif (skb_flow_dissector_uses_key(flow_dissector,\n\t\t\t\t\tFLOW_DISSECTOR_KEY_ETH_ADDRS)) {\n\t\tstruct ethhdr *eth = eth_hdr(skb);\n\t\tstruct flow_dissector_key_eth_addrs *key_eth_addrs;\n\n\t\tkey_eth_addrs = skb_flow_dissector_target(flow_dissector,\n\t\t\t\t\t\t\t  FLOW_DISSECTOR_KEY_ETH_ADDRS,\n\t\t\t\t\t\t\t  target_container);\n\t\tmemcpy(key_eth_addrs, &eth->h_dest, sizeof(*key_eth_addrs));\n\t}\n\nagain:\n\tswitch (proto) {\n\tcase htons(ETH_P_IP): {\n\t\tconst struct iphdr *iph;\n\t\tstruct iphdr _iph;\nip:\n\t\tiph = __skb_header_pointer(skb, nhoff, sizeof(_iph), data, hlen, &_iph);\n\t\tif (!iph || iph->ihl < 5)\n\t\t\tgoto out_bad;\n\t\tnhoff += iph->ihl * 4;\n\n\t\tip_proto = iph->protocol;\n\t\tif (ip_is_fragment(iph))\n\t\t\tip_proto = 0;\n\n\t\tif (!skb_flow_dissector_uses_key(flow_dissector,\n\t\t\t\t\t\t FLOW_DISSECTOR_KEY_IPV4_ADDRS))\n\t\t\tbreak;\n\n\t\tkey_addrs = skb_flow_dissector_target(flow_dissector,\n\t\t\t      FLOW_DISSECTOR_KEY_IPV4_ADDRS, target_container);\n\t\tmemcpy(&key_addrs->v4addrs, &iph->saddr,\n\t\t       sizeof(key_addrs->v4addrs));\n\t\tkey_control->addr_type = FLOW_DISSECTOR_KEY_IPV4_ADDRS;\n\t\tbreak;\n\t}\n\tcase htons(ETH_P_IPV6): {\n\t\tconst struct ipv6hdr *iph;\n\t\tstruct ipv6hdr _iph;\n\t\t__be32 flow_label;\n\nipv6:\n\t\tiph = __skb_header_pointer(skb, nhoff, sizeof(_iph), data, hlen, &_iph);\n\t\tif (!iph)\n\t\t\tgoto out_bad;\n\n\t\tip_proto = iph->nexthdr;\n\t\tnhoff += sizeof(struct ipv6hdr);\n\n\t\tif (skb_flow_dissector_uses_key(flow_dissector,\n\t\t\t\t\t\tFLOW_DISSECTOR_KEY_IPV6_ADDRS)) {\n\t\t\tstruct flow_dissector_key_ipv6_addrs *key_ipv6_addrs;\n\n\t\t\tkey_ipv6_addrs = skb_flow_dissector_target(flow_dissector,\n\t\t\t\t\t\t\t\t   FLOW_DISSECTOR_KEY_IPV6_ADDRS,\n\t\t\t\t\t\t\t\t   target_container);\n\n\t\t\tmemcpy(key_ipv6_addrs, &iph->saddr, sizeof(*key_ipv6_addrs));\n\t\t\tkey_control->addr_type = FLOW_DISSECTOR_KEY_IPV6_ADDRS;\n\t\t}\n\n\t\tflow_label = ip6_flowlabel(iph);\n\t\tif (flow_label) {\n\t\t\tif (skb_flow_dissector_uses_key(flow_dissector,\n\t\t\t\tFLOW_DISSECTOR_KEY_FLOW_LABEL)) {\n\t\t\t\tkey_tags = skb_flow_dissector_target(flow_dissector,\n\t\t\t\t\t\t\t\t     FLOW_DISSECTOR_KEY_FLOW_LABEL,\n\t\t\t\t\t\t\t\t     target_container);\n\t\t\t\tkey_tags->flow_label = ntohl(flow_label);\n\t\t\t}\n\t\t}\n\n\t\tbreak;\n\t}\n\tcase htons(ETH_P_8021AD):\n\tcase htons(ETH_P_8021Q): {\n\t\tconst struct vlan_hdr *vlan;\n\t\tstruct vlan_hdr _vlan;\n\n\t\tvlan = __skb_header_pointer(skb, nhoff, sizeof(_vlan), data, hlen, &_vlan);\n\t\tif (!vlan)\n\t\t\tgoto out_bad;\n\n\t\tif (skb_flow_dissector_uses_key(flow_dissector,\n\t\t\t\t\t\tFLOW_DISSECTOR_KEY_VLANID)) {\n\t\t\tkey_tags = skb_flow_dissector_target(flow_dissector,\n\t\t\t\t\t\t\t     FLOW_DISSECTOR_KEY_VLANID,\n\t\t\t\t\t\t\t     target_container);\n\n\t\t\tkey_tags->vlan_id = skb_vlan_tag_get_id(skb);\n\t\t}\n\n\t\tproto = vlan->h_vlan_encapsulated_proto;\n\t\tnhoff += sizeof(*vlan);\n\t\tgoto again;\n\t}\n\tcase htons(ETH_P_PPP_SES): {\n\t\tstruct {\n\t\t\tstruct pppoe_hdr hdr;\n\t\t\t__be16 proto;\n\t\t} *hdr, _hdr;\n\t\thdr = __skb_header_pointer(skb, nhoff, sizeof(_hdr), data, hlen, &_hdr);\n\t\tif (!hdr)\n\t\t\tgoto out_bad;\n\t\tproto = hdr->proto;\n\t\tnhoff += PPPOE_SES_HLEN;\n\t\tswitch (proto) {\n\t\tcase htons(PPP_IP):\n\t\t\tgoto ip;\n\t\tcase htons(PPP_IPV6):\n\t\t\tgoto ipv6;\n\t\tdefault:\n\t\t\tgoto out_bad;\n\t\t}\n\t}\n\tcase htons(ETH_P_TIPC): {\n\t\tstruct {\n\t\t\t__be32 pre[3];\n\t\t\t__be32 srcnode;\n\t\t} *hdr, _hdr;\n\t\thdr = __skb_header_pointer(skb, nhoff, sizeof(_hdr), data, hlen, &_hdr);\n\t\tif (!hdr)\n\t\t\tgoto out_bad;\n\n\t\tif (skb_flow_dissector_uses_key(flow_dissector,\n\t\t\t\t\t\tFLOW_DISSECTOR_KEY_TIPC_ADDRS)) {\n\t\t\tkey_addrs = skb_flow_dissector_target(flow_dissector,\n\t\t\t\t\t\t\t      FLOW_DISSECTOR_KEY_TIPC_ADDRS,\n\t\t\t\t\t\t\t      target_container);\n\t\t\tkey_addrs->tipcaddrs.srcnode = hdr->srcnode;\n\t\t\tkey_control->addr_type = FLOW_DISSECTOR_KEY_TIPC_ADDRS;\n\t\t}\n\t\tgoto out_good;\n\t}\n\n\tcase htons(ETH_P_MPLS_UC):\n\tcase htons(ETH_P_MPLS_MC): {\n\t\tstruct mpls_label *hdr, _hdr[2];\nmpls:\n\t\thdr = __skb_header_pointer(skb, nhoff, sizeof(_hdr), data,\n\t\t\t\t\t   hlen, &_hdr);\n\t\tif (!hdr)\n\t\t\tgoto out_bad;\n\n\t\tif ((ntohl(hdr[0].entry) & MPLS_LS_LABEL_MASK) >>\n\t\t     MPLS_LS_LABEL_SHIFT == MPLS_LABEL_ENTROPY) {\n\t\t\tif (skb_flow_dissector_uses_key(flow_dissector,\n\t\t\t\t\t\t\tFLOW_DISSECTOR_KEY_MPLS_ENTROPY)) {\n\t\t\t\tkey_keyid = skb_flow_dissector_target(flow_dissector,\n\t\t\t\t\t\t\t\t      FLOW_DISSECTOR_KEY_MPLS_ENTROPY,\n\t\t\t\t\t\t\t\t      target_container);\n\t\t\t\tkey_keyid->keyid = hdr[1].entry &\n\t\t\t\t\thtonl(MPLS_LS_LABEL_MASK);\n\t\t\t}\n\n\t\t\tgoto out_good;\n\t\t}\n\n\t\tgoto out_good;\n\t}\n\n\tcase htons(ETH_P_FCOE):\n\t\tkey_control->thoff = (u16)(nhoff + FCOE_HEADER_LEN);\n\t\t/* fall through */\n\tdefault:\n\t\tgoto out_bad;\n\t}\n\nip_proto_again:\n\tswitch (ip_proto) {\n\tcase IPPROTO_GRE: {\n\t\tstruct gre_hdr {\n\t\t\t__be16 flags;\n\t\t\t__be16 proto;\n\t\t} *hdr, _hdr;\n\n\t\thdr = __skb_header_pointer(skb, nhoff, sizeof(_hdr), data, hlen, &_hdr);\n\t\tif (!hdr)\n\t\t\tgoto out_bad;\n\t\t/*\n\t\t * Only look inside GRE if version zero and no\n\t\t * routing\n\t\t */\n\t\tif (hdr->flags & (GRE_VERSION | GRE_ROUTING))\n\t\t\tbreak;\n\n\t\tproto = hdr->proto;\n\t\tnhoff += 4;\n\t\tif (hdr->flags & GRE_CSUM)\n\t\t\tnhoff += 4;\n\t\tif (hdr->flags & GRE_KEY) {\n\t\t\tconst __be32 *keyid;\n\t\t\t__be32 _keyid;\n\n\t\t\tkeyid = __skb_header_pointer(skb, nhoff, sizeof(_keyid),\n\t\t\t\t\t\t     data, hlen, &_keyid);\n\n\t\t\tif (!keyid)\n\t\t\t\tgoto out_bad;\n\n\t\t\tif (skb_flow_dissector_uses_key(flow_dissector,\n\t\t\t\t\t\t\tFLOW_DISSECTOR_KEY_GRE_KEYID)) {\n\t\t\t\tkey_keyid = skb_flow_dissector_target(flow_dissector,\n\t\t\t\t\t\t\t\t      FLOW_DISSECTOR_KEY_GRE_KEYID,\n\t\t\t\t\t\t\t\t      target_container);\n\t\t\t\tkey_keyid->keyid = *keyid;\n\t\t\t}\n\t\t\tnhoff += 4;\n\t\t}\n\t\tif (hdr->flags & GRE_SEQ)\n\t\t\tnhoff += 4;\n\t\tif (proto == htons(ETH_P_TEB)) {\n\t\t\tconst struct ethhdr *eth;\n\t\t\tstruct ethhdr _eth;\n\n\t\t\teth = __skb_header_pointer(skb, nhoff,\n\t\t\t\t\t\t   sizeof(_eth),\n\t\t\t\t\t\t   data, hlen, &_eth);\n\t\t\tif (!eth)\n\t\t\t\tgoto out_bad;\n\t\t\tproto = eth->h_proto;\n\t\t\tnhoff += sizeof(*eth);\n\t\t}\n\t\tgoto again;\n\t}\n\tcase NEXTHDR_HOP:\n\tcase NEXTHDR_ROUTING:\n\tcase NEXTHDR_DEST: {\n\t\tu8 _opthdr[2], *opthdr;\n\n\t\tif (proto != htons(ETH_P_IPV6))\n\t\t\tbreak;\n\n\t\topthdr = __skb_header_pointer(skb, nhoff, sizeof(_opthdr),\n\t\t\t\t\t      data, hlen, &_opthdr);\n\t\tif (!opthdr)\n\t\t\tgoto out_bad;\n\n\t\tip_proto = opthdr[0];\n\t\tnhoff += (opthdr[1] + 1) << 3;\n\n\t\tgoto ip_proto_again;\n\t}\n\tcase IPPROTO_IPIP:\n\t\tproto = htons(ETH_P_IP);\n\t\tgoto ip;\n\tcase IPPROTO_IPV6:\n\t\tproto = htons(ETH_P_IPV6);\n\t\tgoto ipv6;\n\tcase IPPROTO_MPLS:\n\t\tproto = htons(ETH_P_MPLS_UC);\n\t\tgoto mpls;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tif (skb_flow_dissector_uses_key(flow_dissector,\n\t\t\t\t\tFLOW_DISSECTOR_KEY_PORTS)) {\n\t\tkey_ports = skb_flow_dissector_target(flow_dissector,\n\t\t\t\t\t\t      FLOW_DISSECTOR_KEY_PORTS,\n\t\t\t\t\t\t      target_container);\n\t\tkey_ports->ports = __skb_flow_get_ports(skb, nhoff, ip_proto,\n\t\t\t\t\t\t\tdata, hlen);\n\t}\n\nout_good:\n\tret = true;\n\nout_bad:\n\tkey_basic->n_proto = proto;\n\tkey_basic->ip_proto = ip_proto;\n\tkey_control->thoff = (u16)nhoff;\n\n\treturn ret;\n}",
        "description": "The `__skb_flow_dissect` function in the Linux kernel, prior to version 4.3, does not guarantee the initialization of certain protocol fields (`n_proto`, `ip_proto`, and `thoff`). This oversight enables remote attackers to exploit a single crafted MPLS packet to trigger a denial of service (system crash) or potentially execute arbitrary code.",
        "commit": "The vulnerability involves a function responsible for dissecting network flows, where instead of returning immediately upon encountering a parsing failure, it jumps to cleanup code. This approach ensures that even in the event of a failure, some protocol values are set in the key_control structure, although there may still be valid information in the key_tags that was established before the error occurred."
    },
    {
        "cwe": "CWE-326",
        "func_name": "torvalds/__ipv6_select_ident",
        "score": 0.7473057508468628,
        "func_before": "static u32 __ipv6_select_ident(struct net *net, u32 hashrnd,\n\t\t\t       const struct in6_addr *dst,\n\t\t\t       const struct in6_addr *src)\n{\n\tu32 hash, id;\n\n\thash = __ipv6_addr_jhash(dst, hashrnd);\n\thash = __ipv6_addr_jhash(src, hash);\n\thash ^= net_hash_mix(net);\n\n\t/* Treat id of 0 as unset and if we get 0 back from ip_idents_reserve,\n\t * set the hight order instead thus minimizing possible future\n\t * collisions.\n\t */\n\tid = ip_idents_reserve(hash, 1);\n\tif (unlikely(!id))\n\t\tid = 1 << 31;\n\n\treturn id;\n}",
        "func_after": "static u32 __ipv6_select_ident(struct net *net,\n\t\t\t       const struct in6_addr *dst,\n\t\t\t       const struct in6_addr *src)\n{\n\tconst struct {\n\t\tstruct in6_addr dst;\n\t\tstruct in6_addr src;\n\t} __aligned(SIPHASH_ALIGNMENT) combined = {\n\t\t.dst = *dst,\n\t\t.src = *src,\n\t};\n\tu32 hash, id;\n\n\t/* Note the following code is not safe, but this is okay. */\n\tif (unlikely(siphash_key_is_zero(&net->ipv4.ip_id_key)))\n\t\tget_random_bytes(&net->ipv4.ip_id_key,\n\t\t\t\t sizeof(net->ipv4.ip_id_key));\n\n\thash = siphash(&combined, sizeof(combined), &net->ipv4.ip_id_key);\n\n\t/* Treat id of 0 as unset and if we get 0 back from ip_idents_reserve,\n\t * set the hight order instead thus minimizing possible future\n\t * collisions.\n\t */\n\tid = ip_idents_reserve(hash, 1);\n\tif (unlikely(!id))\n\t\tid = 1 << 31;\n\n\treturn id;\n}",
        "description": "In versions of the Linux kernel prior to 5.1.7, an attacker can track devices by analyzing the IP ID values generated by the kernel for connectionless protocols such as UDP and ICMP. By sending traffic to multiple destination IP addresses, it is possible to induce hash collisions within the counter array, potentially revealing the hashing key through enumeration. This vulnerability can be exploited by hosting a specially crafted web page that leverages technologies like WebRTC or gQUIC to direct UDP traffic to IP addresses controlled by the attacker.",
        "commit": "The IP ID generation mechanism in the networking stack is deemed insufficiently secure due to potential vulnerabilities that could be exploited by attackers. Despite recent improvements such as the introduction of a 64-bit key and the Jenkins hash function, these measures are still considered risky. Therefore, it is recommended to transition to using siphash with its 128-bit keys to enhance the security of IP ID generation."
    },
    {
        "cwe": "CWE-284",
        "func_name": "xen-project/mod_l1_entry",
        "score": 0.7639691233634949,
        "func_before": "static int mod_l1_entry(l1_pgentry_t *pl1e, l1_pgentry_t nl1e,\n                        unsigned long gl1mfn, int preserve_ad,\n                        struct vcpu *pt_vcpu, struct domain *pg_dom)\n{\n    l1_pgentry_t ol1e;\n    struct domain *pt_dom = pt_vcpu->domain;\n    int rc = 0;\n\n    if ( unlikely(__copy_from_user(&ol1e, pl1e, sizeof(ol1e)) != 0) )\n        return -EFAULT;\n\n    if ( unlikely(paging_mode_refcounts(pt_dom)) )\n    {\n        if ( UPDATE_ENTRY(l1, pl1e, ol1e, nl1e, gl1mfn, pt_vcpu, preserve_ad) )\n            return 0;\n        return -EBUSY;\n    }\n\n    if ( l1e_get_flags(nl1e) & _PAGE_PRESENT )\n    {\n        /* Translate foreign guest addresses. */\n        struct page_info *page = NULL;\n\n        if ( unlikely(l1e_get_flags(nl1e) & l1_disallow_mask(pt_dom)) )\n        {\n            MEM_LOG(\"Bad L1 flags %x\",\n                    l1e_get_flags(nl1e) & l1_disallow_mask(pt_dom));\n            return -EINVAL;\n        }\n\n        if ( paging_mode_translate(pg_dom) )\n        {\n            page = get_page_from_gfn(pg_dom, l1e_get_pfn(nl1e), NULL, P2M_ALLOC);\n            if ( !page )\n                return -EINVAL;\n            nl1e = l1e_from_pfn(page_to_mfn(page), l1e_get_flags(nl1e));\n        }\n\n        /* Fast path for identical mapping, r/w, presence, and cachability. */\n        if ( !l1e_has_changed(ol1e, nl1e,\n                              PAGE_CACHE_ATTRS | _PAGE_RW | _PAGE_PRESENT) )\n        {\n            adjust_guest_l1e(nl1e, pt_dom);\n            rc = UPDATE_ENTRY(l1, pl1e, ol1e, nl1e, gl1mfn, pt_vcpu,\n                              preserve_ad);\n            if ( page )\n                put_page(page);\n            return rc ? 0 : -EBUSY;\n        }\n\n        switch ( rc = get_page_from_l1e(nl1e, pt_dom, pg_dom) )\n        {\n        default:\n            if ( page )\n                put_page(page);\n            return rc;\n        case 0:\n            break;\n        case _PAGE_RW ... _PAGE_RW | PAGE_CACHE_ATTRS:\n            ASSERT(!(rc & ~(_PAGE_RW | PAGE_CACHE_ATTRS)));\n            l1e_flip_flags(nl1e, rc);\n            rc = 0;\n            break;\n        }\n        if ( page )\n            put_page(page);\n\n        adjust_guest_l1e(nl1e, pt_dom);\n        if ( unlikely(!UPDATE_ENTRY(l1, pl1e, ol1e, nl1e, gl1mfn, pt_vcpu,\n                                    preserve_ad)) )\n        {\n            ol1e = nl1e;\n            rc = -EBUSY;\n        }\n    }\n    else if ( unlikely(!UPDATE_ENTRY(l1, pl1e, ol1e, nl1e, gl1mfn, pt_vcpu,\n                                     preserve_ad)) )\n    {\n        return -EBUSY;\n    }\n\n    put_page_from_l1e(ol1e, pt_dom);\n    return rc;\n}",
        "func_after": "static int mod_l1_entry(l1_pgentry_t *pl1e, l1_pgentry_t nl1e,\n                        unsigned long gl1mfn, int preserve_ad,\n                        struct vcpu *pt_vcpu, struct domain *pg_dom)\n{\n    l1_pgentry_t ol1e;\n    struct domain *pt_dom = pt_vcpu->domain;\n    int rc = 0;\n\n    if ( unlikely(__copy_from_user(&ol1e, pl1e, sizeof(ol1e)) != 0) )\n        return -EFAULT;\n\n    if ( unlikely(paging_mode_refcounts(pt_dom)) )\n    {\n        if ( UPDATE_ENTRY(l1, pl1e, ol1e, nl1e, gl1mfn, pt_vcpu, preserve_ad) )\n            return 0;\n        return -EBUSY;\n    }\n\n    if ( l1e_get_flags(nl1e) & _PAGE_PRESENT )\n    {\n        /* Translate foreign guest addresses. */\n        struct page_info *page = NULL;\n\n        if ( unlikely(l1e_get_flags(nl1e) & l1_disallow_mask(pt_dom)) )\n        {\n            MEM_LOG(\"Bad L1 flags %x\",\n                    l1e_get_flags(nl1e) & l1_disallow_mask(pt_dom));\n            return -EINVAL;\n        }\n\n        if ( paging_mode_translate(pg_dom) )\n        {\n            page = get_page_from_gfn(pg_dom, l1e_get_pfn(nl1e), NULL, P2M_ALLOC);\n            if ( !page )\n                return -EINVAL;\n            nl1e = l1e_from_pfn(page_to_mfn(page), l1e_get_flags(nl1e));\n        }\n\n        /* Fast path for sufficiently-similar mappings. */\n        if ( !l1e_has_changed(ol1e, nl1e, ~FASTPATH_FLAG_WHITELIST) )\n        {\n            adjust_guest_l1e(nl1e, pt_dom);\n            rc = UPDATE_ENTRY(l1, pl1e, ol1e, nl1e, gl1mfn, pt_vcpu,\n                              preserve_ad);\n            if ( page )\n                put_page(page);\n            return rc ? 0 : -EBUSY;\n        }\n\n        switch ( rc = get_page_from_l1e(nl1e, pt_dom, pg_dom) )\n        {\n        default:\n            if ( page )\n                put_page(page);\n            return rc;\n        case 0:\n            break;\n        case _PAGE_RW ... _PAGE_RW | PAGE_CACHE_ATTRS:\n            ASSERT(!(rc & ~(_PAGE_RW | PAGE_CACHE_ATTRS)));\n            l1e_flip_flags(nl1e, rc);\n            rc = 0;\n            break;\n        }\n        if ( page )\n            put_page(page);\n\n        adjust_guest_l1e(nl1e, pt_dom);\n        if ( unlikely(!UPDATE_ENTRY(l1, pl1e, ol1e, nl1e, gl1mfn, pt_vcpu,\n                                    preserve_ad)) )\n        {\n            ol1e = nl1e;\n            rc = -EBUSY;\n        }\n    }\n    else if ( unlikely(!UPDATE_ENTRY(l1, pl1e, ol1e, nl1e, gl1mfn, pt_vcpu,\n                                     preserve_ad)) )\n    {\n        return -EBUSY;\n    }\n\n    put_page_from_l1e(ol1e, pt_dom);\n    return rc;\n}",
        "description": "The PV pagetable code in the Xen hypervisor, specifically in versions 4.7.x and earlier, permits local 32-bit PV guest OS administrators to escalate their privileges to those of the host OS by exploiting fast-paths designed for updating pagetable entries.",
        "commit": "The vulnerability involves modifying the `mod_l?_entry()` fastpath in the x86/pv module to remove unsafe bits. Changes related to writeability and cacheability must now undergo full re-validation. The logic has been reworked as a whitelist to improve clarity. This addresses a specific security advisory, XSA-182."
    }
]