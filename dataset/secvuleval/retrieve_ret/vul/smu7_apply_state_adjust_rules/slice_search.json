[
    {
        "cwe": "CWE-911",
        "func_name": "torvalds/u32_destroy_key",
        "score": 0.779875636100769,
        "func_before": "static int u32_destroy_key(struct tc_u_knode *n, bool free_pf)\n{\n\tstruct tc_u_hnode *ht = rtnl_dereference(n->ht_down);\n\n\ttcf_exts_destroy(&n->exts);\n\ttcf_exts_put_net(&n->exts);\n\tif (ht && --ht->refcnt == 0)\n\t\tkfree(ht);\n#ifdef CONFIG_CLS_U32_PERF\n\tif (free_pf)\n\t\tfree_percpu(n->pf);\n#endif\n#ifdef CONFIG_CLS_U32_MARK\n\tif (free_pf)\n\t\tfree_percpu(n->pcpu_success);\n#endif\n\tkfree(n);\n\treturn 0;\n}",
        "func_after": "static void u32_destroy_key(struct tc_u_knode *n, bool free_pf)\n{\n\ttcf_exts_put_net(&n->exts);\n#ifdef CONFIG_CLS_U32_PERF\n\tif (free_pf)\n\t\tfree_percpu(n->pf);\n#endif\n#ifdef CONFIG_CLS_U32_MARK\n\tif (free_pf)\n\t\tfree_percpu(n->pcpu_success);\n#endif\n\t__u32_destroy_key(n);\n}",
        "description": "An Improper Update of Reference Count vulnerability in the networking scheduler component of the Linux Kernel enables a local attacker to achieve privilege escalation to root. This issue impacts Linux Kernel versions prior to 5.18 and versions 4.14 and later.",
        "commit": "A vulnerability was identified in the Linux kernel where an extra `put_net()` operation is detected prematurely. Specifically, functions such as `u32_init_knode()` and `tcf_exts_init()` populate the `->exts.net` pointer without elevating the reference count on the network namespace (`netns`). The reference count is incremented only when `tcf_exts_get_net()` is called. Consequently, two calls to `u32_destroy_key()` from `u32_change()` attempt to release an invalid reference on the `netns`, leading to a refcount decrement hitting zero and potential memory leaks. This issue occurs in the Linux kernel prior to a specific version, affecting the handling of network traffic classification and filtering mechanisms."
    },
    {
        "cwe": "CWE-400",
        "func_name": "Exiv2/ProcessUTF8Portion",
        "score": 0.8224382400512695,
        "func_before": "static size_t\nProcessUTF8Portion ( XMLParserAdapter * xmlParser,\n\t\t\t\t\t const XMP_Uns8 *   buffer,\n\t\t\t\t\t size_t\t\t\t\tlength,\n\t\t\t\t\t bool\t\t\t\tlast )\n{\n\tconst XMP_Uns8 * bufEnd = buffer + length;\n\t\n\tconst XMP_Uns8 * spanStart = buffer;\n\tconst XMP_Uns8 * spanEnd;\n\t\t\n\tfor ( spanEnd = spanStart; spanEnd < bufEnd; ++spanEnd ) {\n\n\t\tif ( (0x20 <= *spanEnd) && (*spanEnd <= 0x7E) && (*spanEnd != '&') ) continue;\t// A regular ASCII character.\n\n\t\tif ( *spanEnd >= 0x80 ) {\n\t\t\n\t\t\t// See if this is a multi-byte UTF-8 sequence, or a Latin-1 character to replace.\n\n\t\t\tint uniLen = CountUTF8 ( spanEnd, bufEnd );\n\n\t\t\tif ( uniLen > 0 ) {\n\n\t\t\t\t// A valid UTF-8 character, keep it as-is.\n\t\t\t\tspanEnd += uniLen - 1;\t// ! The loop increment will put back the +1.\n\n\t\t\t} else if ( (uniLen < 0) && (! last) ) {\n\n\t\t\t\t// Have a partial UTF-8 character at the end of the buffer and more input coming.\n\t\t\t\txmlParser->ParseBuffer ( spanStart, (spanEnd - spanStart), false );\n\t\t\t\treturn (spanEnd - buffer);\n\n\t\t\t} else {\n\n\t\t\t\t// Not a valid UTF-8 sequence. Replace the first byte with the Latin-1 equivalent.\n\t\t\t\txmlParser->ParseBuffer ( spanStart, (spanEnd - spanStart), false );\n\t\t\t\tconst char * replacement = kReplaceLatin1 [ *spanEnd - 0x80 ];\n\t\t\t\txmlParser->ParseBuffer ( replacement, strlen ( replacement ), false );\n\t\t\t\tspanStart = spanEnd + 1;\t// ! The loop increment will do \"spanEnd = spanStart\".\n\n\t\t\t}\n\t\t\n\t\t} else if ( (*spanEnd < 0x20) || (*spanEnd == 0x7F) ) {\n\n\t\t\t// Replace ASCII controls other than tab, LF, and CR with a space.\n\n\t\t\tif ( (*spanEnd == kTab) || (*spanEnd == kLF) || (*spanEnd == kCR) ) continue;\n\n\t\t\txmlParser->ParseBuffer ( spanStart, (spanEnd - spanStart), false );\n\t\t\txmlParser->ParseBuffer ( \" \", 1, false );\n\t\t\tspanStart = spanEnd + 1;\t// ! The loop increment will do \"spanEnd = spanStart\".\n\t\t\n\t\t} else {\n\t\t\n\t\t\t// See if this is a numeric escape sequence for a prohibited ASCII control.\n\t\t\t\n\t\t\tXMP_Assert ( *spanEnd == '&' );\n\t\t\tint escLen = CountControlEscape ( spanEnd, bufEnd );\n\t\t\t\n\t\t\tif ( escLen < 0 ) {\n\n\t\t\t\t// Have a partial numeric escape in this buffer, wait for more input.\n\t\t\t\tif ( last ) continue;\t// No more buffers, not an escape, absorb as normal input.\n\t\t\t\txmlParser->ParseBuffer ( spanStart, (spanEnd - spanStart), false );\n\t\t\t\treturn (spanEnd - buffer);\n\n\t\t\t} else if ( escLen > 0 ) {\n\n\t\t\t\t// Have a complete numeric escape to replace.\n\t\t\t\txmlParser->ParseBuffer ( spanStart, (spanEnd - spanStart), false );\n\t\t\t\txmlParser->ParseBuffer ( \" \", 1, false );\n\t\t\t\tspanStart = spanEnd + escLen;\n\t\t\t\tspanEnd = spanStart - 1;\t// ! The loop continuation will increment spanEnd!\n\n\t\t\t}\n\n\t\t}\n\t\t\n\t}\n\t\n\tXMP_Assert ( spanEnd == bufEnd );\n\n\tif ( spanStart < bufEnd ) xmlParser->ParseBuffer ( spanStart, (spanEnd - spanStart), false );\n\tif ( last ) xmlParser->ParseBuffer ( \" \", 1, true );\n\t\n\treturn length;\n\n}",
        "func_after": "static size_t\nProcessUTF8Portion ( XMLParserAdapter * xmlParser,\n\t\t\t\t\t const XMP_Uns8 *   buffer,\n\t\t\t\t\t size_t\t\t\t\tlength,\n\t\t\t\t\t bool\t\t\t\tlast )\n{\n\tconst XMP_Uns8 * bufEnd = buffer + length;\n\t\n\tconst XMP_Uns8 * spanEnd;\n\n\t// `buffer` is copied into this std::string. If `buffer` only\n\t// contains valid UTF-8 and no escape characters, then the copy\n\t// will be identical to the original, but invalid characters are\n\t// replaced - usually with a space character.  This std::string was\n\t// added as a performance fix for:\n\t// https://github.com/Exiv2/exiv2/security/advisories/GHSA-w8mv-g8qq-36mj\n\t// Previously, the code was repeatedly calling\n\t// `xmlParser->ParseBuffer()`, which turned out to have quadratic\n\t// complexity, because expat kept reparsing the entire string from\n\t// the beginning.\n\tstd::string copy;\n\t\t\n\tfor ( spanEnd = buffer; spanEnd < bufEnd; ++spanEnd ) {\n\n\t\tif ( (0x20 <= *spanEnd) && (*spanEnd <= 0x7E) && (*spanEnd != '&') ) {\n\t\t\tcopy.push_back(*spanEnd);\n\t\t\tcontinue;\t// A regular ASCII character.\n\t\t}\n\n\t\tif ( *spanEnd >= 0x80 ) {\n\t\t\n\t\t\t// See if this is a multi-byte UTF-8 sequence, or a Latin-1 character to replace.\n\n\t\t\tint uniLen = CountUTF8 ( spanEnd, bufEnd );\n\n\t\t\tif ( uniLen > 0 ) {\n\n\t\t\t\t// A valid UTF-8 character, keep it as-is.\n\t\t\t\tcopy.append((const char*)spanEnd, uniLen);\n\t\t\t\tspanEnd += uniLen - 1;\t// ! The loop increment will put back the +1.\n\n\t\t\t} else if ( (uniLen < 0) && (! last) ) {\n\n\t\t\t\t// Have a partial UTF-8 character at the end of the buffer and more input coming.\n\t\t\t\txmlParser->ParseBuffer ( copy.c_str(), copy.size(), false );\n\t\t\t\treturn (spanEnd - buffer);\n\n\t\t\t} else {\n\n\t\t\t\t// Not a valid UTF-8 sequence. Replace the first byte with the Latin-1 equivalent.\n\t\t\t\tconst char * replacement = kReplaceLatin1 [ *spanEnd - 0x80 ];\n\t\t\t\tcopy.append ( replacement );\n\n\t\t\t}\n\t\t\n\t\t} else if ( (*spanEnd < 0x20) || (*spanEnd == 0x7F) ) {\n\n\t\t\t// Replace ASCII controls other than tab, LF, and CR with a space.\n\n\t\t\tif ( (*spanEnd == kTab) || (*spanEnd == kLF) || (*spanEnd == kCR) ) {\n\t\t\t\tcopy.push_back(*spanEnd);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tcopy.push_back(' ');\n\t\t\n\t\t} else {\n\t\t\n\t\t\t// See if this is a numeric escape sequence for a prohibited ASCII control.\n\t\t\t\n\t\t\tXMP_Assert ( *spanEnd == '&' );\n\t\t\tint escLen = CountControlEscape ( spanEnd, bufEnd );\n\t\t\t\n\t\t\tif ( escLen < 0 ) {\n\n\t\t\t\t// Have a partial numeric escape in this buffer, wait for more input.\n\t\t\t\tif ( last ) {\n\t\t\t\t\tcopy.push_back('&');\n\t\t\t\t\tcontinue;\t// No more buffers, not an escape, absorb as normal input.\n\t\t\t\t}\n\t\t\t\txmlParser->ParseBuffer ( copy.c_str(), copy.size(), false );\n\t\t\t\treturn (spanEnd - buffer);\n\n\t\t\t} else if ( escLen > 0 ) {\n\n\t\t\t\t// Have a complete numeric escape to replace.\n\t\t\t\tcopy.push_back(' ');\n\t\t\t\tspanEnd = spanEnd + escLen - 1;\t// ! The loop continuation will increment spanEnd!\n\n\t\t\t} else {\n\t\t\t\tcopy.push_back('&');\n\t\t\t}\n\n\t\t}\n\t\t\n\t}\n\t\n\tXMP_Assert ( spanEnd == bufEnd );\n\tcopy.push_back(' ');\n\txmlParser->ParseBuffer ( copy.c_str(), copy.size(), true );\n\treturn length;\n\n}",
        "description": "An inefficient algorithm with quadratic complexity was identified in Exiv2 versions up to v0.27.3. This algorithm is activated when Exiv2 writes metadata to a specially crafted image file. An attacker could exploit this vulnerability to cause a denial of service by convincing a victim to run Exiv2 on such an image file. The issue has been resolved in version v0.27.4. It's important to note that this vulnerability primarily affects the less commonly used metadata writing operation compared to the more frequent reading operation.",
        "commit": "output: \"A performance bug characterized by quadratic complexity has been addressed.\""
    },
    {
        "cwe": "CWE-193",
        "func_name": "torvalds/ext4_ext_insert_extent",
        "score": 0.8366562128067017,
        "func_before": "int ext4_ext_insert_extent(handle_t *handle, struct inode *inode,\n\t\t\t\tstruct ext4_ext_path *path,\n\t\t\t\tstruct ext4_extent *newext, int flag)\n{\n\tstruct ext4_extent_header *eh;\n\tstruct ext4_extent *ex, *fex;\n\tstruct ext4_extent *nearex; /* nearest extent */\n\tstruct ext4_ext_path *npath = NULL;\n\tint depth, len, err;\n\text4_lblk_t next;\n\tunsigned uninitialized = 0;\n\tint flags = 0;\n\n\tif (unlikely(ext4_ext_get_actual_len(newext) == 0)) {\n\t\tEXT4_ERROR_INODE(inode, \"ext4_ext_get_actual_len(newext) == 0\");\n\t\treturn -EIO;\n\t}\n\tdepth = ext_depth(inode);\n\tex = path[depth].p_ext;\n\tif (unlikely(path[depth].p_hdr == NULL)) {\n\t\tEXT4_ERROR_INODE(inode, \"path[%d].p_hdr == NULL\", depth);\n\t\treturn -EIO;\n\t}\n\n\t/* try to insert block into found extent and return */\n\tif (ex && !(flag & EXT4_GET_BLOCKS_PRE_IO)\n\t\t&& ext4_can_extents_be_merged(inode, ex, newext)) {\n\t\text_debug(\"append [%d]%d block to %d:[%d]%d (from %llu)\\n\",\n\t\t\t  ext4_ext_is_uninitialized(newext),\n\t\t\t  ext4_ext_get_actual_len(newext),\n\t\t\t  le32_to_cpu(ex->ee_block),\n\t\t\t  ext4_ext_is_uninitialized(ex),\n\t\t\t  ext4_ext_get_actual_len(ex),\n\t\t\t  ext4_ext_pblock(ex));\n\t\terr = ext4_ext_get_access(handle, inode, path + depth);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\t/*\n\t\t * ext4_can_extents_be_merged should have checked that either\n\t\t * both extents are uninitialized, or both aren't. Thus we\n\t\t * need to check only one of them here.\n\t\t */\n\t\tif (ext4_ext_is_uninitialized(ex))\n\t\t\tuninitialized = 1;\n\t\tex->ee_len = cpu_to_le16(ext4_ext_get_actual_len(ex)\n\t\t\t\t\t+ ext4_ext_get_actual_len(newext));\n\t\tif (uninitialized)\n\t\t\text4_ext_mark_uninitialized(ex);\n\t\teh = path[depth].p_hdr;\n\t\tnearex = ex;\n\t\tgoto merge;\n\t}\n\nrepeat:\n\tdepth = ext_depth(inode);\n\teh = path[depth].p_hdr;\n\tif (le16_to_cpu(eh->eh_entries) < le16_to_cpu(eh->eh_max))\n\t\tgoto has_space;\n\n\t/* probably next leaf has space for us? */\n\tfex = EXT_LAST_EXTENT(eh);\n\tnext = ext4_ext_next_leaf_block(inode, path);\n\tif (le32_to_cpu(newext->ee_block) > le32_to_cpu(fex->ee_block)\n\t    && next != EXT_MAX_BLOCK) {\n\t\text_debug(\"next leaf block - %d\\n\", next);\n\t\tBUG_ON(npath != NULL);\n\t\tnpath = ext4_ext_find_extent(inode, next, NULL);\n\t\tif (IS_ERR(npath))\n\t\t\treturn PTR_ERR(npath);\n\t\tBUG_ON(npath->p_depth != path->p_depth);\n\t\teh = npath[depth].p_hdr;\n\t\tif (le16_to_cpu(eh->eh_entries) < le16_to_cpu(eh->eh_max)) {\n\t\t\text_debug(\"next leaf isn't full(%d)\\n\",\n\t\t\t\t  le16_to_cpu(eh->eh_entries));\n\t\t\tpath = npath;\n\t\t\tgoto repeat;\n\t\t}\n\t\text_debug(\"next leaf has no free space(%d,%d)\\n\",\n\t\t\t  le16_to_cpu(eh->eh_entries), le16_to_cpu(eh->eh_max));\n\t}\n\n\t/*\n\t * There is no free space in the found leaf.\n\t * We're gonna add a new leaf in the tree.\n\t */\n\tif (flag & EXT4_GET_BLOCKS_PUNCH_OUT_EXT)\n\t\tflags = EXT4_MB_USE_ROOT_BLOCKS;\n\terr = ext4_ext_create_new_leaf(handle, inode, flags, path, newext);\n\tif (err)\n\t\tgoto cleanup;\n\tdepth = ext_depth(inode);\n\teh = path[depth].p_hdr;\n\nhas_space:\n\tnearex = path[depth].p_ext;\n\n\terr = ext4_ext_get_access(handle, inode, path + depth);\n\tif (err)\n\t\tgoto cleanup;\n\n\tif (!nearex) {\n\t\t/* there is no extent in this leaf, create first one */\n\t\text_debug(\"first extent in the leaf: %d:%llu:[%d]%d\\n\",\n\t\t\t\tle32_to_cpu(newext->ee_block),\n\t\t\t\text4_ext_pblock(newext),\n\t\t\t\text4_ext_is_uninitialized(newext),\n\t\t\t\text4_ext_get_actual_len(newext));\n\t\tpath[depth].p_ext = EXT_FIRST_EXTENT(eh);\n\t} else if (le32_to_cpu(newext->ee_block)\n\t\t\t   > le32_to_cpu(nearex->ee_block)) {\n/*\t\tBUG_ON(newext->ee_block == nearex->ee_block); */\n\t\tif (nearex != EXT_LAST_EXTENT(eh)) {\n\t\t\tlen = EXT_MAX_EXTENT(eh) - nearex;\n\t\t\tlen = (len - 1) * sizeof(struct ext4_extent);\n\t\t\tlen = len < 0 ? 0 : len;\n\t\t\text_debug(\"insert %d:%llu:[%d]%d after: nearest 0x%p, \"\n\t\t\t\t\t\"move %d from 0x%p to 0x%p\\n\",\n\t\t\t\t\tle32_to_cpu(newext->ee_block),\n\t\t\t\t\text4_ext_pblock(newext),\n\t\t\t\t\text4_ext_is_uninitialized(newext),\n\t\t\t\t\text4_ext_get_actual_len(newext),\n\t\t\t\t\tnearex, len, nearex + 1, nearex + 2);\n\t\t\tmemmove(nearex + 2, nearex + 1, len);\n\t\t}\n\t\tpath[depth].p_ext = nearex + 1;\n\t} else {\n\t\tBUG_ON(newext->ee_block == nearex->ee_block);\n\t\tlen = (EXT_MAX_EXTENT(eh) - nearex) * sizeof(struct ext4_extent);\n\t\tlen = len < 0 ? 0 : len;\n\t\text_debug(\"insert %d:%llu:[%d]%d before: nearest 0x%p, \"\n\t\t\t\t\"move %d from 0x%p to 0x%p\\n\",\n\t\t\t\tle32_to_cpu(newext->ee_block),\n\t\t\t\text4_ext_pblock(newext),\n\t\t\t\text4_ext_is_uninitialized(newext),\n\t\t\t\text4_ext_get_actual_len(newext),\n\t\t\t\tnearex, len, nearex + 1, nearex + 2);\n\t\tmemmove(nearex + 1, nearex, len);\n\t\tpath[depth].p_ext = nearex;\n\t}\n\n\tle16_add_cpu(&eh->eh_entries, 1);\n\tnearex = path[depth].p_ext;\n\tnearex->ee_block = newext->ee_block;\n\text4_ext_store_pblock(nearex, ext4_ext_pblock(newext));\n\tnearex->ee_len = newext->ee_len;\n\nmerge:\n\t/* try to merge extents to the right */\n\tif (!(flag & EXT4_GET_BLOCKS_PRE_IO))\n\t\text4_ext_try_to_merge(inode, path, nearex);\n\n\t/* try to merge extents to the left */\n\n\t/* time to correct all indexes above */\n\terr = ext4_ext_correct_indexes(handle, inode, path);\n\tif (err)\n\t\tgoto cleanup;\n\n\terr = ext4_ext_dirty(handle, inode, path + depth);\n\ncleanup:\n\tif (npath) {\n\t\text4_ext_drop_refs(npath);\n\t\tkfree(npath);\n\t}\n\text4_ext_invalidate_cache(inode);\n\treturn err;\n}",
        "func_after": "int ext4_ext_insert_extent(handle_t *handle, struct inode *inode,\n\t\t\t\tstruct ext4_ext_path *path,\n\t\t\t\tstruct ext4_extent *newext, int flag)\n{\n\tstruct ext4_extent_header *eh;\n\tstruct ext4_extent *ex, *fex;\n\tstruct ext4_extent *nearex; /* nearest extent */\n\tstruct ext4_ext_path *npath = NULL;\n\tint depth, len, err;\n\text4_lblk_t next;\n\tunsigned uninitialized = 0;\n\tint flags = 0;\n\n\tif (unlikely(ext4_ext_get_actual_len(newext) == 0)) {\n\t\tEXT4_ERROR_INODE(inode, \"ext4_ext_get_actual_len(newext) == 0\");\n\t\treturn -EIO;\n\t}\n\tdepth = ext_depth(inode);\n\tex = path[depth].p_ext;\n\tif (unlikely(path[depth].p_hdr == NULL)) {\n\t\tEXT4_ERROR_INODE(inode, \"path[%d].p_hdr == NULL\", depth);\n\t\treturn -EIO;\n\t}\n\n\t/* try to insert block into found extent and return */\n\tif (ex && !(flag & EXT4_GET_BLOCKS_PRE_IO)\n\t\t&& ext4_can_extents_be_merged(inode, ex, newext)) {\n\t\text_debug(\"append [%d]%d block to %d:[%d]%d (from %llu)\\n\",\n\t\t\t  ext4_ext_is_uninitialized(newext),\n\t\t\t  ext4_ext_get_actual_len(newext),\n\t\t\t  le32_to_cpu(ex->ee_block),\n\t\t\t  ext4_ext_is_uninitialized(ex),\n\t\t\t  ext4_ext_get_actual_len(ex),\n\t\t\t  ext4_ext_pblock(ex));\n\t\terr = ext4_ext_get_access(handle, inode, path + depth);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\t/*\n\t\t * ext4_can_extents_be_merged should have checked that either\n\t\t * both extents are uninitialized, or both aren't. Thus we\n\t\t * need to check only one of them here.\n\t\t */\n\t\tif (ext4_ext_is_uninitialized(ex))\n\t\t\tuninitialized = 1;\n\t\tex->ee_len = cpu_to_le16(ext4_ext_get_actual_len(ex)\n\t\t\t\t\t+ ext4_ext_get_actual_len(newext));\n\t\tif (uninitialized)\n\t\t\text4_ext_mark_uninitialized(ex);\n\t\teh = path[depth].p_hdr;\n\t\tnearex = ex;\n\t\tgoto merge;\n\t}\n\nrepeat:\n\tdepth = ext_depth(inode);\n\teh = path[depth].p_hdr;\n\tif (le16_to_cpu(eh->eh_entries) < le16_to_cpu(eh->eh_max))\n\t\tgoto has_space;\n\n\t/* probably next leaf has space for us? */\n\tfex = EXT_LAST_EXTENT(eh);\n\tnext = ext4_ext_next_leaf_block(inode, path);\n\tif (le32_to_cpu(newext->ee_block) > le32_to_cpu(fex->ee_block)\n\t    && next != EXT_MAX_BLOCKS) {\n\t\text_debug(\"next leaf block - %d\\n\", next);\n\t\tBUG_ON(npath != NULL);\n\t\tnpath = ext4_ext_find_extent(inode, next, NULL);\n\t\tif (IS_ERR(npath))\n\t\t\treturn PTR_ERR(npath);\n\t\tBUG_ON(npath->p_depth != path->p_depth);\n\t\teh = npath[depth].p_hdr;\n\t\tif (le16_to_cpu(eh->eh_entries) < le16_to_cpu(eh->eh_max)) {\n\t\t\text_debug(\"next leaf isn't full(%d)\\n\",\n\t\t\t\t  le16_to_cpu(eh->eh_entries));\n\t\t\tpath = npath;\n\t\t\tgoto repeat;\n\t\t}\n\t\text_debug(\"next leaf has no free space(%d,%d)\\n\",\n\t\t\t  le16_to_cpu(eh->eh_entries), le16_to_cpu(eh->eh_max));\n\t}\n\n\t/*\n\t * There is no free space in the found leaf.\n\t * We're gonna add a new leaf in the tree.\n\t */\n\tif (flag & EXT4_GET_BLOCKS_PUNCH_OUT_EXT)\n\t\tflags = EXT4_MB_USE_ROOT_BLOCKS;\n\terr = ext4_ext_create_new_leaf(handle, inode, flags, path, newext);\n\tif (err)\n\t\tgoto cleanup;\n\tdepth = ext_depth(inode);\n\teh = path[depth].p_hdr;\n\nhas_space:\n\tnearex = path[depth].p_ext;\n\n\terr = ext4_ext_get_access(handle, inode, path + depth);\n\tif (err)\n\t\tgoto cleanup;\n\n\tif (!nearex) {\n\t\t/* there is no extent in this leaf, create first one */\n\t\text_debug(\"first extent in the leaf: %d:%llu:[%d]%d\\n\",\n\t\t\t\tle32_to_cpu(newext->ee_block),\n\t\t\t\text4_ext_pblock(newext),\n\t\t\t\text4_ext_is_uninitialized(newext),\n\t\t\t\text4_ext_get_actual_len(newext));\n\t\tpath[depth].p_ext = EXT_FIRST_EXTENT(eh);\n\t} else if (le32_to_cpu(newext->ee_block)\n\t\t\t   > le32_to_cpu(nearex->ee_block)) {\n/*\t\tBUG_ON(newext->ee_block == nearex->ee_block); */\n\t\tif (nearex != EXT_LAST_EXTENT(eh)) {\n\t\t\tlen = EXT_MAX_EXTENT(eh) - nearex;\n\t\t\tlen = (len - 1) * sizeof(struct ext4_extent);\n\t\t\tlen = len < 0 ? 0 : len;\n\t\t\text_debug(\"insert %d:%llu:[%d]%d after: nearest 0x%p, \"\n\t\t\t\t\t\"move %d from 0x%p to 0x%p\\n\",\n\t\t\t\t\tle32_to_cpu(newext->ee_block),\n\t\t\t\t\text4_ext_pblock(newext),\n\t\t\t\t\text4_ext_is_uninitialized(newext),\n\t\t\t\t\text4_ext_get_actual_len(newext),\n\t\t\t\t\tnearex, len, nearex + 1, nearex + 2);\n\t\t\tmemmove(nearex + 2, nearex + 1, len);\n\t\t}\n\t\tpath[depth].p_ext = nearex + 1;\n\t} else {\n\t\tBUG_ON(newext->ee_block == nearex->ee_block);\n\t\tlen = (EXT_MAX_EXTENT(eh) - nearex) * sizeof(struct ext4_extent);\n\t\tlen = len < 0 ? 0 : len;\n\t\text_debug(\"insert %d:%llu:[%d]%d before: nearest 0x%p, \"\n\t\t\t\t\"move %d from 0x%p to 0x%p\\n\",\n\t\t\t\tle32_to_cpu(newext->ee_block),\n\t\t\t\text4_ext_pblock(newext),\n\t\t\t\text4_ext_is_uninitialized(newext),\n\t\t\t\text4_ext_get_actual_len(newext),\n\t\t\t\tnearex, len, nearex + 1, nearex + 2);\n\t\tmemmove(nearex + 1, nearex, len);\n\t\tpath[depth].p_ext = nearex;\n\t}\n\n\tle16_add_cpu(&eh->eh_entries, 1);\n\tnearex = path[depth].p_ext;\n\tnearex->ee_block = newext->ee_block;\n\text4_ext_store_pblock(nearex, ext4_ext_pblock(newext));\n\tnearex->ee_len = newext->ee_len;\n\nmerge:\n\t/* try to merge extents to the right */\n\tif (!(flag & EXT4_GET_BLOCKS_PRE_IO))\n\t\text4_ext_try_to_merge(inode, path, nearex);\n\n\t/* try to merge extents to the left */\n\n\t/* time to correct all indexes above */\n\terr = ext4_ext_correct_indexes(handle, inode, path);\n\tif (err)\n\t\tgoto cleanup;\n\n\terr = ext4_ext_dirty(handle, inode, path + depth);\n\ncleanup:\n\tif (npath) {\n\t\text4_ext_drop_refs(npath);\n\t\tkfree(npath);\n\t}\n\text4_ext_invalidate_cache(inode);\n\treturn err;\n}",
        "description": "Multiple off-by-one errors in the ext4 subsystem of the Linux kernel, prior to a specific release candidate, enable local users to trigger a denial of service (resulting in BUG_ON and system crashes) through write operations on sparse files in extent format, particularly when the block number corresponds to the maximum possible 32-bit unsigned integer.",
        "commit": "A vulnerability was identified in the ext4 file system where writing to the last block (2^32-1) of a sparse file in extent format triggers a BUG_ON condition in the ext4_ext_put_gap_in_cache() function. The root cause is that the maximum bytes (s_maxbytes) are set such that the block at s_maxbytes fits into a 32-bit on-disk extent format, but the extent structure stores start block number and length in blocks, requiring EXT_MAX_BLOCK + 1 to cover the entire extent range. To resolve this issue without altering the struct ext4_extent members' meanings, s_maxbytes should be reduced by one filesystem block. Additionally, the commit renames EXT_MAX_BLOCK to EXT_MAX_BLOCKS and adjusts its usage to represent the maximum number of blocks in an extent, addressing inconsistencies in its application throughout the codebase. This bug can be reproduced by sequentially writing to the second-to-last and last blocks of a sparse file using the dd command."
    },
    {
        "cwe": "CWE-662",
        "func_name": "torvalds/do_fontx_ioctl",
        "score": 0.8076859712600708,
        "func_before": "static inline int do_fontx_ioctl(int cmd,\n\t\tstruct consolefontdesc __user *user_cfd,\n\t\tstruct console_font_op *op)\n{\n\tstruct consolefontdesc cfdarg;\n\tint i;\n\n\tif (copy_from_user(&cfdarg, user_cfd, sizeof(struct consolefontdesc)))\n\t\treturn -EFAULT;\n\n\tswitch (cmd) {\n\tcase PIO_FONTX:\n\t\top->op = KD_FONT_OP_SET;\n\t\top->flags = KD_FONT_FLAG_OLD;\n\t\top->width = 8;\n\t\top->height = cfdarg.charheight;\n\t\top->charcount = cfdarg.charcount;\n\t\top->data = cfdarg.chardata;\n\t\treturn con_font_op(vc_cons[fg_console].d, op);\n\tcase GIO_FONTX: {\n\t\top->op = KD_FONT_OP_GET;\n\t\top->flags = KD_FONT_FLAG_OLD;\n\t\top->width = 8;\n\t\top->height = cfdarg.charheight;\n\t\top->charcount = cfdarg.charcount;\n\t\top->data = cfdarg.chardata;\n\t\ti = con_font_op(vc_cons[fg_console].d, op);\n\t\tif (i)\n\t\t\treturn i;\n\t\tcfdarg.charheight = op->height;\n\t\tcfdarg.charcount = op->charcount;\n\t\tif (copy_to_user(user_cfd, &cfdarg, sizeof(struct consolefontdesc)))\n\t\t\treturn -EFAULT;\n\t\treturn 0;\n\t\t}\n\t}\n\treturn -EINVAL;\n}",
        "func_after": "static inline int do_fontx_ioctl(struct vc_data *vc, int cmd,\n\t\tstruct consolefontdesc __user *user_cfd,\n\t\tstruct console_font_op *op)\n{\n\tstruct consolefontdesc cfdarg;\n\tint i;\n\n\tif (copy_from_user(&cfdarg, user_cfd, sizeof(struct consolefontdesc)))\n\t\treturn -EFAULT;\n\n\tswitch (cmd) {\n\tcase PIO_FONTX:\n\t\top->op = KD_FONT_OP_SET;\n\t\top->flags = KD_FONT_FLAG_OLD;\n\t\top->width = 8;\n\t\top->height = cfdarg.charheight;\n\t\top->charcount = cfdarg.charcount;\n\t\top->data = cfdarg.chardata;\n\t\treturn con_font_op(vc, op);\n\n\tcase GIO_FONTX:\n\t\top->op = KD_FONT_OP_GET;\n\t\top->flags = KD_FONT_FLAG_OLD;\n\t\top->width = 8;\n\t\top->height = cfdarg.charheight;\n\t\top->charcount = cfdarg.charcount;\n\t\top->data = cfdarg.chardata;\n\t\ti = con_font_op(vc, op);\n\t\tif (i)\n\t\t\treturn i;\n\t\tcfdarg.charheight = op->height;\n\t\tcfdarg.charcount = op->charcount;\n\t\tif (copy_to_user(user_cfd, &cfdarg, sizeof(struct consolefontdesc)))\n\t\t\treturn -EFAULT;\n\t\treturn 0;\n\t}\n\treturn -EINVAL;\n}",
        "description": "A flaw was identified in the Linux Kernel where access to a global variable used for managing the foreground console is not adequately synchronized, resulting in a use-after-free error within the function responsible for font operations.",
        "commit": "Some font-related terminal I/O control operations previously utilized the current foreground virtual console (VC) for their execution. This practice has been discontinued to address a data race condition involving the `fg_console` variable. Notably, both Michael Ellerman and Jiri Slaby have observed that these I/O control operations are deprecated and should have been removed earlier. They suggest that most systems now use the `KDFONTOP` ioctl instead. Additionally, Michael notes that BusyBox's `loadfont` program transitioned to using `KDFONTOP` precisely due to this bug, which was identified approximately 12 years ago."
    },
    {
        "cwe": "CWE-19",
        "func_name": "torvalds/do_page_fault",
        "score": 0.8312035799026489,
        "func_before": "static int __kprobes do_page_fault(unsigned long addr, unsigned int esr,\n\t\t\t\t   struct pt_regs *regs)\n{\n\tstruct task_struct *tsk;\n\tstruct mm_struct *mm;\n\tint fault, sig, code;\n\tunsigned long vm_flags = VM_READ | VM_WRITE;\n\tunsigned int mm_flags = FAULT_FLAG_ALLOW_RETRY | FAULT_FLAG_KILLABLE;\n\n\ttsk = current;\n\tmm  = tsk->mm;\n\n\t/* Enable interrupts if they were enabled in the parent context. */\n\tif (interrupts_enabled(regs))\n\t\tlocal_irq_enable();\n\n\t/*\n\t * If we're in an interrupt or have no user context, we must not take\n\t * the fault.\n\t */\n\tif (in_atomic() || !mm)\n\t\tgoto no_context;\n\n\tif (user_mode(regs))\n\t\tmm_flags |= FAULT_FLAG_USER;\n\n\tif (esr & ESR_LNX_EXEC) {\n\t\tvm_flags = VM_EXEC;\n\t} else if ((esr & ESR_EL1_WRITE) && !(esr & ESR_EL1_CM)) {\n\t\tvm_flags = VM_WRITE;\n\t\tmm_flags |= FAULT_FLAG_WRITE;\n\t}\n\n\t/*\n\t * As per x86, we may deadlock here. However, since the kernel only\n\t * validly references user space from well defined areas of the code,\n\t * we can bug out early if this is from code which shouldn't.\n\t */\n\tif (!down_read_trylock(&mm->mmap_sem)) {\n\t\tif (!user_mode(regs) && !search_exception_tables(regs->pc))\n\t\t\tgoto no_context;\nretry:\n\t\tdown_read(&mm->mmap_sem);\n\t} else {\n\t\t/*\n\t\t * The above down_read_trylock() might have succeeded in which\n\t\t * case, we'll have missed the might_sleep() from down_read().\n\t\t */\n\t\tmight_sleep();\n#ifdef CONFIG_DEBUG_VM\n\t\tif (!user_mode(regs) && !search_exception_tables(regs->pc))\n\t\t\tgoto no_context;\n#endif\n\t}\n\n\tfault = __do_page_fault(mm, addr, mm_flags, vm_flags, tsk);\n\n\t/*\n\t * If we need to retry but a fatal signal is pending, handle the\n\t * signal first. We do not need to release the mmap_sem because it\n\t * would already be released in __lock_page_or_retry in mm/filemap.c.\n\t */\n\tif ((fault & VM_FAULT_RETRY) && fatal_signal_pending(current))\n\t\treturn 0;\n\n\t/*\n\t * Major/minor page fault accounting is only done on the initial\n\t * attempt. If we go through a retry, it is extremely likely that the\n\t * page will be found in page cache at that point.\n\t */\n\n\tperf_sw_event(PERF_COUNT_SW_PAGE_FAULTS, 1, regs, addr);\n\tif (mm_flags & FAULT_FLAG_ALLOW_RETRY) {\n\t\tif (fault & VM_FAULT_MAJOR) {\n\t\t\ttsk->maj_flt++;\n\t\t\tperf_sw_event(PERF_COUNT_SW_PAGE_FAULTS_MAJ, 1, regs,\n\t\t\t\t      addr);\n\t\t} else {\n\t\t\ttsk->min_flt++;\n\t\t\tperf_sw_event(PERF_COUNT_SW_PAGE_FAULTS_MIN, 1, regs,\n\t\t\t\t      addr);\n\t\t}\n\t\tif (fault & VM_FAULT_RETRY) {\n\t\t\t/*\n\t\t\t * Clear FAULT_FLAG_ALLOW_RETRY to avoid any risk of\n\t\t\t * starvation.\n\t\t\t */\n\t\t\tmm_flags &= ~FAULT_FLAG_ALLOW_RETRY;\n\t\t\tgoto retry;\n\t\t}\n\t}\n\n\tup_read(&mm->mmap_sem);\n\n\t/*\n\t * Handle the \"normal\" case first - VM_FAULT_MAJOR / VM_FAULT_MINOR\n\t */\n\tif (likely(!(fault & (VM_FAULT_ERROR | VM_FAULT_BADMAP |\n\t\t\t      VM_FAULT_BADACCESS))))\n\t\treturn 0;\n\n\t/*\n\t * If we are in kernel mode at this point, we have no context to\n\t * handle this fault with.\n\t */\n\tif (!user_mode(regs))\n\t\tgoto no_context;\n\n\tif (fault & VM_FAULT_OOM) {\n\t\t/*\n\t\t * We ran out of memory, call the OOM killer, and return to\n\t\t * userspace (which will retry the fault, or kill us if we got\n\t\t * oom-killed).\n\t\t */\n\t\tpagefault_out_of_memory();\n\t\treturn 0;\n\t}\n\n\tif (fault & VM_FAULT_SIGBUS) {\n\t\t/*\n\t\t * We had some memory, but were unable to successfully fix up\n\t\t * this page fault.\n\t\t */\n\t\tsig = SIGBUS;\n\t\tcode = BUS_ADRERR;\n\t} else {\n\t\t/*\n\t\t * Something tried to access memory that isn't in our memory\n\t\t * map.\n\t\t */\n\t\tsig = SIGSEGV;\n\t\tcode = fault == VM_FAULT_BADACCESS ?\n\t\t\tSEGV_ACCERR : SEGV_MAPERR;\n\t}\n\n\t__do_user_fault(tsk, addr, esr, sig, code, regs);\n\treturn 0;\n\nno_context:\n\t__do_kernel_fault(mm, addr, esr, regs);\n\treturn 0;\n}",
        "func_after": "static int __kprobes do_page_fault(unsigned long addr, unsigned int esr,\n\t\t\t\t   struct pt_regs *regs)\n{\n\tstruct task_struct *tsk;\n\tstruct mm_struct *mm;\n\tint fault, sig, code;\n\tunsigned long vm_flags = VM_READ | VM_WRITE | VM_EXEC;\n\tunsigned int mm_flags = FAULT_FLAG_ALLOW_RETRY | FAULT_FLAG_KILLABLE;\n\n\ttsk = current;\n\tmm  = tsk->mm;\n\n\t/* Enable interrupts if they were enabled in the parent context. */\n\tif (interrupts_enabled(regs))\n\t\tlocal_irq_enable();\n\n\t/*\n\t * If we're in an interrupt or have no user context, we must not take\n\t * the fault.\n\t */\n\tif (in_atomic() || !mm)\n\t\tgoto no_context;\n\n\tif (user_mode(regs))\n\t\tmm_flags |= FAULT_FLAG_USER;\n\n\tif (esr & ESR_LNX_EXEC) {\n\t\tvm_flags = VM_EXEC;\n\t} else if ((esr & ESR_EL1_WRITE) && !(esr & ESR_EL1_CM)) {\n\t\tvm_flags = VM_WRITE;\n\t\tmm_flags |= FAULT_FLAG_WRITE;\n\t}\n\n\t/*\n\t * As per x86, we may deadlock here. However, since the kernel only\n\t * validly references user space from well defined areas of the code,\n\t * we can bug out early if this is from code which shouldn't.\n\t */\n\tif (!down_read_trylock(&mm->mmap_sem)) {\n\t\tif (!user_mode(regs) && !search_exception_tables(regs->pc))\n\t\t\tgoto no_context;\nretry:\n\t\tdown_read(&mm->mmap_sem);\n\t} else {\n\t\t/*\n\t\t * The above down_read_trylock() might have succeeded in which\n\t\t * case, we'll have missed the might_sleep() from down_read().\n\t\t */\n\t\tmight_sleep();\n#ifdef CONFIG_DEBUG_VM\n\t\tif (!user_mode(regs) && !search_exception_tables(regs->pc))\n\t\t\tgoto no_context;\n#endif\n\t}\n\n\tfault = __do_page_fault(mm, addr, mm_flags, vm_flags, tsk);\n\n\t/*\n\t * If we need to retry but a fatal signal is pending, handle the\n\t * signal first. We do not need to release the mmap_sem because it\n\t * would already be released in __lock_page_or_retry in mm/filemap.c.\n\t */\n\tif ((fault & VM_FAULT_RETRY) && fatal_signal_pending(current))\n\t\treturn 0;\n\n\t/*\n\t * Major/minor page fault accounting is only done on the initial\n\t * attempt. If we go through a retry, it is extremely likely that the\n\t * page will be found in page cache at that point.\n\t */\n\n\tperf_sw_event(PERF_COUNT_SW_PAGE_FAULTS, 1, regs, addr);\n\tif (mm_flags & FAULT_FLAG_ALLOW_RETRY) {\n\t\tif (fault & VM_FAULT_MAJOR) {\n\t\t\ttsk->maj_flt++;\n\t\t\tperf_sw_event(PERF_COUNT_SW_PAGE_FAULTS_MAJ, 1, regs,\n\t\t\t\t      addr);\n\t\t} else {\n\t\t\ttsk->min_flt++;\n\t\t\tperf_sw_event(PERF_COUNT_SW_PAGE_FAULTS_MIN, 1, regs,\n\t\t\t\t      addr);\n\t\t}\n\t\tif (fault & VM_FAULT_RETRY) {\n\t\t\t/*\n\t\t\t * Clear FAULT_FLAG_ALLOW_RETRY to avoid any risk of\n\t\t\t * starvation.\n\t\t\t */\n\t\t\tmm_flags &= ~FAULT_FLAG_ALLOW_RETRY;\n\t\t\tgoto retry;\n\t\t}\n\t}\n\n\tup_read(&mm->mmap_sem);\n\n\t/*\n\t * Handle the \"normal\" case first - VM_FAULT_MAJOR / VM_FAULT_MINOR\n\t */\n\tif (likely(!(fault & (VM_FAULT_ERROR | VM_FAULT_BADMAP |\n\t\t\t      VM_FAULT_BADACCESS))))\n\t\treturn 0;\n\n\t/*\n\t * If we are in kernel mode at this point, we have no context to\n\t * handle this fault with.\n\t */\n\tif (!user_mode(regs))\n\t\tgoto no_context;\n\n\tif (fault & VM_FAULT_OOM) {\n\t\t/*\n\t\t * We ran out of memory, call the OOM killer, and return to\n\t\t * userspace (which will retry the fault, or kill us if we got\n\t\t * oom-killed).\n\t\t */\n\t\tpagefault_out_of_memory();\n\t\treturn 0;\n\t}\n\n\tif (fault & VM_FAULT_SIGBUS) {\n\t\t/*\n\t\t * We had some memory, but were unable to successfully fix up\n\t\t * this page fault.\n\t\t */\n\t\tsig = SIGBUS;\n\t\tcode = BUS_ADRERR;\n\t} else {\n\t\t/*\n\t\t * Something tried to access memory that isn't in our memory\n\t\t * map.\n\t\t */\n\t\tsig = SIGSEGV;\n\t\tcode = fault == VM_FAULT_BADACCESS ?\n\t\t\tSEGV_ACCERR : SEGV_MAPERR;\n\t}\n\n\t__do_user_fault(tsk, addr, esr, sig, code, regs);\n\treturn 0;\n\nno_context:\n\t__do_kernel_fault(mm, addr, esr, regs);\n\treturn 0;\n}",
        "description": "In the Linux kernel prior to version 3.15-rc5-next-20140519, as utilized in Android versions before 2016-07-05 on Nexus 5X and 6P devices, there exists a flaw in the handling of execute-only pages within the architecture-specific page table header file. This mishandling enables attackers to escalate their privileges through the deployment of a specially crafted application.",
        "commit": "This reverts a change that introduced execute-only page access permissions for ARM64 architectures. Although the intention was to enhance security for memory maps with execute-only permissions, it fails to prevent kernel-level reads. Given that SECCOMP (secure computing mode) has not yet been implemented for ARM64, reverting this patch is necessary to avoid misleading users about the effectiveness of execute-only mappings."
    }
]