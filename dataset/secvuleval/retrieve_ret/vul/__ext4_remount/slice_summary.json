[
    {
        "cwe": "CWE-119",
        "func_name": "torvalds/hugetlb_mcopy_atomic_pte",
        "score": 0.765964150428772,
        "func_before": "int hugetlb_mcopy_atomic_pte(struct mm_struct *dst_mm,\n\t\t\t    pte_t *dst_pte,\n\t\t\t    struct vm_area_struct *dst_vma,\n\t\t\t    unsigned long dst_addr,\n\t\t\t    unsigned long src_addr,\n\t\t\t    struct page **pagep)\n{\n\tint vm_shared = dst_vma->vm_flags & VM_SHARED;\n\tstruct hstate *h = hstate_vma(dst_vma);\n\tpte_t _dst_pte;\n\tspinlock_t *ptl;\n\tint ret;\n\tstruct page *page;\n\n\tif (!*pagep) {\n\t\tret = -ENOMEM;\n\t\tpage = alloc_huge_page(dst_vma, dst_addr, 0);\n\t\tif (IS_ERR(page))\n\t\t\tgoto out;\n\n\t\tret = copy_huge_page_from_user(page,\n\t\t\t\t\t\t(const void __user *) src_addr,\n\t\t\t\t\t\tpages_per_huge_page(h), false);\n\n\t\t/* fallback to copy_from_user outside mmap_sem */\n\t\tif (unlikely(ret)) {\n\t\t\tret = -EFAULT;\n\t\t\t*pagep = page;\n\t\t\t/* don't free the page */\n\t\t\tgoto out;\n\t\t}\n\t} else {\n\t\tpage = *pagep;\n\t\t*pagep = NULL;\n\t}\n\n\t/*\n\t * The memory barrier inside __SetPageUptodate makes sure that\n\t * preceding stores to the page contents become visible before\n\t * the set_pte_at() write.\n\t */\n\t__SetPageUptodate(page);\n\tset_page_huge_active(page);\n\n\t/*\n\t * If shared, add to page cache\n\t */\n\tif (vm_shared) {\n\t\tstruct address_space *mapping = dst_vma->vm_file->f_mapping;\n\t\tpgoff_t idx = vma_hugecache_offset(h, dst_vma, dst_addr);\n\n\t\tret = huge_add_to_page_cache(page, mapping, idx);\n\t\tif (ret)\n\t\t\tgoto out_release_nounlock;\n\t}\n\n\tptl = huge_pte_lockptr(h, dst_mm, dst_pte);\n\tspin_lock(ptl);\n\n\tret = -EEXIST;\n\tif (!huge_pte_none(huge_ptep_get(dst_pte)))\n\t\tgoto out_release_unlock;\n\n\tif (vm_shared) {\n\t\tpage_dup_rmap(page, true);\n\t} else {\n\t\tClearPagePrivate(page);\n\t\thugepage_add_new_anon_rmap(page, dst_vma, dst_addr);\n\t}\n\n\t_dst_pte = make_huge_pte(dst_vma, page, dst_vma->vm_flags & VM_WRITE);\n\tif (dst_vma->vm_flags & VM_WRITE)\n\t\t_dst_pte = huge_pte_mkdirty(_dst_pte);\n\t_dst_pte = pte_mkyoung(_dst_pte);\n\n\tset_huge_pte_at(dst_mm, dst_addr, dst_pte, _dst_pte);\n\n\t(void)huge_ptep_set_access_flags(dst_vma, dst_addr, dst_pte, _dst_pte,\n\t\t\t\t\tdst_vma->vm_flags & VM_WRITE);\n\thugetlb_count_add(pages_per_huge_page(h), dst_mm);\n\n\t/* No need to invalidate - it was non-present before */\n\tupdate_mmu_cache(dst_vma, dst_addr, dst_pte);\n\n\tspin_unlock(ptl);\n\tif (vm_shared)\n\t\tunlock_page(page);\n\tret = 0;\nout:\n\treturn ret;\nout_release_unlock:\n\tspin_unlock(ptl);\n\tif (vm_shared)\n\t\tunlock_page(page);\nout_release_nounlock:\n\tput_page(page);\n\tgoto out;\n}",
        "func_after": "int hugetlb_mcopy_atomic_pte(struct mm_struct *dst_mm,\n\t\t\t    pte_t *dst_pte,\n\t\t\t    struct vm_area_struct *dst_vma,\n\t\t\t    unsigned long dst_addr,\n\t\t\t    unsigned long src_addr,\n\t\t\t    struct page **pagep)\n{\n\tstruct address_space *mapping;\n\tpgoff_t idx;\n\tunsigned long size;\n\tint vm_shared = dst_vma->vm_flags & VM_SHARED;\n\tstruct hstate *h = hstate_vma(dst_vma);\n\tpte_t _dst_pte;\n\tspinlock_t *ptl;\n\tint ret;\n\tstruct page *page;\n\n\tif (!*pagep) {\n\t\tret = -ENOMEM;\n\t\tpage = alloc_huge_page(dst_vma, dst_addr, 0);\n\t\tif (IS_ERR(page))\n\t\t\tgoto out;\n\n\t\tret = copy_huge_page_from_user(page,\n\t\t\t\t\t\t(const void __user *) src_addr,\n\t\t\t\t\t\tpages_per_huge_page(h), false);\n\n\t\t/* fallback to copy_from_user outside mmap_sem */\n\t\tif (unlikely(ret)) {\n\t\t\tret = -EFAULT;\n\t\t\t*pagep = page;\n\t\t\t/* don't free the page */\n\t\t\tgoto out;\n\t\t}\n\t} else {\n\t\tpage = *pagep;\n\t\t*pagep = NULL;\n\t}\n\n\t/*\n\t * The memory barrier inside __SetPageUptodate makes sure that\n\t * preceding stores to the page contents become visible before\n\t * the set_pte_at() write.\n\t */\n\t__SetPageUptodate(page);\n\tset_page_huge_active(page);\n\n\tmapping = dst_vma->vm_file->f_mapping;\n\tidx = vma_hugecache_offset(h, dst_vma, dst_addr);\n\n\t/*\n\t * If shared, add to page cache\n\t */\n\tif (vm_shared) {\n\t\tsize = i_size_read(mapping->host) >> huge_page_shift(h);\n\t\tret = -EFAULT;\n\t\tif (idx >= size)\n\t\t\tgoto out_release_nounlock;\n\n\t\t/*\n\t\t * Serialization between remove_inode_hugepages() and\n\t\t * huge_add_to_page_cache() below happens through the\n\t\t * hugetlb_fault_mutex_table that here must be hold by\n\t\t * the caller.\n\t\t */\n\t\tret = huge_add_to_page_cache(page, mapping, idx);\n\t\tif (ret)\n\t\t\tgoto out_release_nounlock;\n\t}\n\n\tptl = huge_pte_lockptr(h, dst_mm, dst_pte);\n\tspin_lock(ptl);\n\n\t/*\n\t * Recheck the i_size after holding PT lock to make sure not\n\t * to leave any page mapped (as page_mapped()) beyond the end\n\t * of the i_size (remove_inode_hugepages() is strict about\n\t * enforcing that). If we bail out here, we'll also leave a\n\t * page in the radix tree in the vm_shared case beyond the end\n\t * of the i_size, but remove_inode_hugepages() will take care\n\t * of it as soon as we drop the hugetlb_fault_mutex_table.\n\t */\n\tsize = i_size_read(mapping->host) >> huge_page_shift(h);\n\tret = -EFAULT;\n\tif (idx >= size)\n\t\tgoto out_release_unlock;\n\n\tret = -EEXIST;\n\tif (!huge_pte_none(huge_ptep_get(dst_pte)))\n\t\tgoto out_release_unlock;\n\n\tif (vm_shared) {\n\t\tpage_dup_rmap(page, true);\n\t} else {\n\t\tClearPagePrivate(page);\n\t\thugepage_add_new_anon_rmap(page, dst_vma, dst_addr);\n\t}\n\n\t_dst_pte = make_huge_pte(dst_vma, page, dst_vma->vm_flags & VM_WRITE);\n\tif (dst_vma->vm_flags & VM_WRITE)\n\t\t_dst_pte = huge_pte_mkdirty(_dst_pte);\n\t_dst_pte = pte_mkyoung(_dst_pte);\n\n\tset_huge_pte_at(dst_mm, dst_addr, dst_pte, _dst_pte);\n\n\t(void)huge_ptep_set_access_flags(dst_vma, dst_addr, dst_pte, _dst_pte,\n\t\t\t\t\tdst_vma->vm_flags & VM_WRITE);\n\thugetlb_count_add(pages_per_huge_page(h), dst_mm);\n\n\t/* No need to invalidate - it was non-present before */\n\tupdate_mmu_cache(dst_vma, dst_addr, dst_pte);\n\n\tspin_unlock(ptl);\n\tif (vm_shared)\n\t\tunlock_page(page);\n\tret = 0;\nout:\n\treturn ret;\nout_release_unlock:\n\tspin_unlock(ptl);\n\tif (vm_shared)\n\t\tunlock_page(page);\nout_release_nounlock:\n\tput_page(page);\n\tgoto out;\n}",
        "description": "A flaw was identified in the hugetlb_mcopy_atomic_pte function within the Linux kernel's memory management module, affecting versions prior to 4.13.12. The absence of a proper size check in this function could lead to a denial of service condition, indicated by a BUG.",
        "commit": "A vulnerability was identified in the userfaultfd functionality related to hugetlbfs, where the UFFDIO_COPY operation could inadvertently extend beyond the intended size of the file (i_size). This issue led to a kernel panic (oops) at fs/hugetlbfs/inode.c:484, triggered by the absence of an i_size check in the hugetlb_mcopy_atomic_pte function. Although mmap() operations could succeed beyond the end of the i_size after vmtruncate had removed virtual memory areas (vmas) in those ranges, subsequent faults, including UFFDIO_COPY, should not be allowed to succeed. The proposed solution involves modifying the return value to userland to indicate a SIGBUS-like condition, similar to what a page fault would produce, but this approach was deemed less useful due to the difficulty in distinguishing between SIGSEGV and SIGBUS through meaningful syscall return values."
    },
    {
        "cwe": "CWE-264",
        "func_name": "newlib-cygwin/lsaauth",
        "score": 0.7611958980560303,
        "func_before": "HANDLE\nlsaauth (cygsid &usersid, user_groups &new_groups)\n{\n  cygsidlist tmp_gsids (cygsidlist_auto, 12);\n  cygpsid pgrpsid;\n  LSA_STRING name;\n  HANDLE lsa_hdl = NULL, lsa = NULL;\n  LSA_OPERATIONAL_MODE sec_mode;\n  NTSTATUS status, sub_status;\n  ULONG package_id, size;\n  LUID auth_luid = SYSTEM_LUID;\n  struct {\n    LSA_STRING str;\n    CHAR buf[16];\n  } origin;\n  DWORD ulen = UNLEN + 1;\n  DWORD dlen = MAX_DOMAIN_NAME_LEN + 1;\n  SID_NAME_USE use;\n  cyglsa_t *authinf = NULL;\n  ULONG authinf_size;\n  TOKEN_SOURCE ts;\n  PCYG_TOKEN_GROUPS gsids = NULL;\n  PTOKEN_PRIVILEGES privs = NULL;\n  PACL dacl = NULL;\n  PVOID profile = NULL;\n  LUID luid;\n  QUOTA_LIMITS quota;\n  size_t psize = 0, gsize = 0, dsize = 0;\n  OFFSET offset, sids_offset;\n  int tmpidx, non_well_known_cnt;\n\n  HANDLE user_token = NULL;\n\n  push_self_privilege (SE_TCB_PRIVILEGE, true);\n\n  /* Register as logon process. */\n  RtlInitAnsiString (&name, \"Cygwin\");\n  SetLastError (0);\n  status = LsaRegisterLogonProcess (&name, &lsa_hdl, &sec_mode);\n  if (status != STATUS_SUCCESS)\n    {\n      debug_printf (\"LsaRegisterLogonProcess: %y\", status);\n      __seterrno_from_nt_status (status);\n      goto out;\n    }\n  else if (GetLastError () == ERROR_PROC_NOT_FOUND)\n    {\n      debug_printf (\"Couldn't load Secur32.dll\");\n      goto out;\n    }\n  /* Get handle to our own LSA package. */\n  RtlInitAnsiString (&name, CYG_LSA_PKGNAME);\n  status = LsaLookupAuthenticationPackage (lsa_hdl, &name, &package_id);\n  if (status != STATUS_SUCCESS)\n    {\n      debug_printf (\"LsaLookupAuthenticationPackage: %y\", status);\n      __seterrno_from_nt_status (status);\n      goto out;\n    }\n\n  /* Open policy object. */\n  if (!(lsa = lsa_open_policy (NULL, POLICY_EXECUTE)))\n    goto out;\n\n  /* Create origin. */\n  stpcpy (origin.buf, \"Cygwin\");\n  RtlInitAnsiString (&origin.str, origin.buf);\n  /* Create token source. */\n  memcpy (ts.SourceName, \"Cygwin.1\", 8);\n  ts.SourceIdentifier.HighPart = 0;\n  ts.SourceIdentifier.LowPart = 0x0103;\n\n  /* Create list of groups, the user is member in. */\n  int auth_pos;\n  if (new_groups.issetgroups ())\n    get_setgroups_sidlist (tmp_gsids, usersid, NULL, new_groups, auth_luid,\n\t\t\t   auth_pos);\n  else if (!get_initgroups_sidlist (tmp_gsids, usersid, new_groups.pgsid,\n\t\t\t\t    NULL, auth_luid, auth_pos))\n    goto out;\n\n  tmp_gsids.debug_print (\"tmp_gsids\");\n\n  /* Evaluate size of TOKEN_GROUPS list */\n  non_well_known_cnt =  tmp_gsids.non_well_known_count ();\n  gsize = sizeof (DWORD) + non_well_known_cnt * sizeof (SID_AND_ATTRIBUTES);\n  tmpidx = -1;\n  for (int i = 0; i < non_well_known_cnt; ++i)\n    if ((tmpidx = tmp_gsids.next_non_well_known_sid (tmpidx)) >= 0)\n      gsize += RtlLengthSid (tmp_gsids.sids[tmpidx]);\n\n  /* Retrieve list of privileges of that user.  The MIC SID is created by\n     the LSA here. */\n  if (!(privs = get_priv_list (lsa, usersid, tmp_gsids, psize, NULL)))\n    goto out;\n\n  /* Create DefaultDacl. */\n  dsize = sizeof (ACL) + 3 * sizeof (ACCESS_ALLOWED_ACE)\n\t  + RtlLengthSid (usersid)\n\t  + RtlLengthSid (well_known_admins_sid)\n\t  + RtlLengthSid (well_known_system_sid);\n  dacl = (PACL) alloca (dsize);\n  if (!NT_SUCCESS (RtlCreateAcl (dacl, dsize, ACL_REVISION)))\n    goto out;\n  if (!NT_SUCCESS (RtlAddAccessAllowedAce (dacl, ACL_REVISION, GENERIC_ALL,\n\t\t\t\t\t   usersid)))\n    goto out;\n  if (!NT_SUCCESS (RtlAddAccessAllowedAce (dacl, ACL_REVISION, GENERIC_ALL,\n\t\t\t\t\t   well_known_admins_sid)))\n    goto out;\n  if (!NT_SUCCESS (RtlAddAccessAllowedAce (dacl, ACL_REVISION, GENERIC_ALL,\n\t\t\t\t\t   well_known_system_sid)))\n    goto out;\n\n  /* Evaluate authinf size and allocate authinf. */\n  authinf_size = (authinf->data - (PBYTE) authinf);\n  authinf_size += RtlLengthSid (usersid);\t    /* User SID */\n  authinf_size += gsize;\t\t\t    /* Groups + Group SIDs */\n  /* When trying to define the admins group as primary group on Vista,\n     LsaLogonUser fails with error STATUS_INVALID_OWNER.  As workaround\n     we define \"Local\" as primary group here.  Seteuid32 sets the primary\n     group to the group set in /etc/passwd anyway. */\n  if (new_groups.pgsid == well_known_admins_sid)\n    pgrpsid = well_known_local_sid;\n  else\n    pgrpsid = new_groups.pgsid;\n\n  authinf_size += RtlLengthSid (pgrpsid);\t    /* Primary Group SID */\n\n  authinf_size += psize;\t\t\t    /* Privileges */\n  authinf_size += 0;\t\t\t\t    /* Owner SID */\n  authinf_size += dsize;\t\t\t    /* Default DACL */\n\n  authinf = (cyglsa_t *) alloca (authinf_size);\n  authinf->inf_size = authinf_size - ((PBYTE) &authinf->inf - (PBYTE) authinf);\n\n  authinf->magic = CYG_LSA_MAGIC;\n\n  if (!LookupAccountSidW (NULL, usersid, authinf->username, &ulen,\n\t\t\t  authinf->domain, &dlen, &use))\n    {\n      __seterrno ();\n      goto out;\n    }\n\n  /* Store stuff in authinf with offset relative to start of \"inf\" member,\n     instead of using pointers. */\n  offset = authinf->data - (PBYTE) &authinf->inf;\n\n  authinf->inf.ExpirationTime.LowPart = 0xffffffffL;\n  authinf->inf.ExpirationTime.HighPart = 0x7fffffffL;\n  /* User SID */\n  authinf->inf.User.User.Sid = offset;\n  authinf->inf.User.User.Attributes = 0;\n  RtlCopySid (RtlLengthSid (usersid), (PSID) ((PBYTE) &authinf->inf + offset),\n\t      usersid);\n  offset += RtlLengthSid (usersid);\n  /* Groups */\n  authinf->inf.Groups = offset;\n  gsids = (PCYG_TOKEN_GROUPS) ((PBYTE) &authinf->inf + offset);\n  sids_offset = offset + sizeof (ULONG) + non_well_known_cnt\n\t\t\t\t\t  * sizeof (SID_AND_ATTRIBUTES);\n  gsids->GroupCount = non_well_known_cnt;\n  /* Group SIDs */\n  tmpidx = -1;\n  for (int i = 0; i < non_well_known_cnt; ++i)\n    {\n      if ((tmpidx = tmp_gsids.next_non_well_known_sid (tmpidx)) < 0)\n\tbreak;\n      gsids->Groups[i].Sid = sids_offset;\n      gsids->Groups[i].Attributes = SE_GROUP_MANDATORY\n\t\t\t\t    | SE_GROUP_ENABLED_BY_DEFAULT\n\t\t\t\t    | SE_GROUP_ENABLED;\n      RtlCopySid (RtlLengthSid (tmp_gsids.sids[tmpidx]),\n\t\t  (PSID) ((PBYTE) &authinf->inf + sids_offset),\n\t\t  tmp_gsids.sids[tmpidx]);\n      sids_offset += RtlLengthSid (tmp_gsids.sids[tmpidx]);\n    }\n  offset += gsize;\n  /* Primary Group SID */\n  authinf->inf.PrimaryGroup.PrimaryGroup = offset;\n  RtlCopySid (RtlLengthSid (pgrpsid), (PSID) ((PBYTE) &authinf->inf + offset),\n\t      pgrpsid);\n  offset += RtlLengthSid (pgrpsid);\n  /* Privileges */\n  authinf->inf.Privileges = offset;\n  memcpy ((PBYTE) &authinf->inf + offset, privs, psize);\n  offset += psize;\n  /* Owner */\n  authinf->inf.Owner.Owner = 0;\n  /* Default DACL */\n  authinf->inf.DefaultDacl.DefaultDacl = offset;\n  memcpy ((PBYTE) &authinf->inf + offset, dacl, dsize);\n\n  authinf->checksum = CYG_LSA_MAGIC;\n  PDWORD csp;\n  PDWORD csp_end;\n  csp = (PDWORD) &authinf->username;\n  csp_end = (PDWORD) ((PBYTE) authinf + authinf_size);\n  while (csp < csp_end)\n    authinf->checksum += *csp++;\n\n  /* Try to logon... */\n  status = LsaLogonUser (lsa_hdl, (PLSA_STRING) &origin, Interactive,\n\t\t\t package_id, authinf, authinf_size, NULL, &ts,\n\t\t\t &profile, &size, &luid, &user_token, &quota,\n\t\t\t &sub_status);\n  if (status != STATUS_SUCCESS)\n    {\n      debug_printf (\"LsaLogonUser: %y (sub-status %y)\", status, sub_status);\n      __seterrno_from_nt_status (status);\n      goto out;\n    }\n  if (profile)\n    {\n#ifdef JUST_ANOTHER_NONWORKING_SOLUTION\n      /* See ../lsaauth/cyglsa.c. */\n      cygprf_t *prf = (cygprf_t *) profile;\n      if (prf->magic_pre == MAGIC_PRE && prf->magic_post == MAGIC_POST\n\t  && prf->token)\n\t{\n\t  CloseHandle (user_token);\n\t  user_token = prf->token;\n\t  system_printf (\"Got token through profile: %p\", user_token);\n\t}\n#endif /* JUST_ANOTHER_NONWORKING_SOLUTION */\n      LsaFreeReturnBuffer (profile);\n    }\n  user_token = get_full_privileged_inheritable_token (user_token);\n\nout:\n  if (privs)\n    free (privs);\n  lsa_close_policy (lsa);\n  if (lsa_hdl)\n    LsaDeregisterLogonProcess (lsa_hdl);\n  pop_self_privilege ();\n\n  debug_printf (\"%p = lsaauth ()\", user_token);\n  return user_token;\n}",
        "func_after": "HANDLE\nlsaauth (cygsid &usersid, user_groups &new_groups)\n{\n  cygsidlist tmp_gsids (cygsidlist_auto, 12);\n  cygpsid pgrpsid;\n  LSA_STRING name;\n  HANDLE lsa_hdl = NULL, lsa = NULL;\n  LSA_OPERATIONAL_MODE sec_mode;\n  NTSTATUS status, sub_status;\n  ULONG package_id, size;\n  struct {\n    LSA_STRING str;\n    CHAR buf[16];\n  } origin;\n  DWORD ulen = UNLEN + 1;\n  DWORD dlen = MAX_DOMAIN_NAME_LEN + 1;\n  SID_NAME_USE use;\n  cyglsa_t *authinf = NULL;\n  ULONG authinf_size;\n  TOKEN_SOURCE ts;\n  PCYG_TOKEN_GROUPS gsids = NULL;\n  PTOKEN_PRIVILEGES privs = NULL;\n  PACL dacl = NULL;\n  PVOID profile = NULL;\n  LUID luid;\n  QUOTA_LIMITS quota;\n  size_t psize = 0, gsize = 0, dsize = 0;\n  OFFSET offset, sids_offset;\n  int tmpidx, non_well_known_cnt;\n\n  HANDLE user_token = NULL;\n\n  push_self_privilege (SE_TCB_PRIVILEGE, true);\n\n  /* Register as logon process. */\n  RtlInitAnsiString (&name, \"Cygwin\");\n  SetLastError (0);\n  status = LsaRegisterLogonProcess (&name, &lsa_hdl, &sec_mode);\n  if (status != STATUS_SUCCESS)\n    {\n      debug_printf (\"LsaRegisterLogonProcess: %y\", status);\n      __seterrno_from_nt_status (status);\n      goto out;\n    }\n  else if (GetLastError () == ERROR_PROC_NOT_FOUND)\n    {\n      debug_printf (\"Couldn't load Secur32.dll\");\n      goto out;\n    }\n  /* Get handle to our own LSA package. */\n  RtlInitAnsiString (&name, CYG_LSA_PKGNAME);\n  status = LsaLookupAuthenticationPackage (lsa_hdl, &name, &package_id);\n  if (status != STATUS_SUCCESS)\n    {\n      debug_printf (\"LsaLookupAuthenticationPackage: %y\", status);\n      __seterrno_from_nt_status (status);\n      goto out;\n    }\n\n  /* Open policy object. */\n  if (!(lsa = lsa_open_policy (NULL, POLICY_EXECUTE)))\n    goto out;\n\n  /* Create origin. */\n  stpcpy (origin.buf, \"Cygwin\");\n  RtlInitAnsiString (&origin.str, origin.buf);\n  /* Create token source. */\n  memcpy (ts.SourceName, \"Cygwin.1\", 8);\n  ts.SourceIdentifier.HighPart = 0;\n  ts.SourceIdentifier.LowPart = 0x0103;\n\n  /* Create list of groups, the user is member in. */\n  if (new_groups.issetgroups ())\n    get_setgroups_sidlist (tmp_gsids, usersid, NULL, new_groups);\n  else if (!get_initgroups_sidlist (tmp_gsids, usersid, new_groups.pgsid,\n\t\t\t\t    NULL))\n    goto out;\n\n  tmp_gsids.debug_print (\"tmp_gsids\");\n\n  /* Evaluate size of TOKEN_GROUPS list */\n  non_well_known_cnt =  tmp_gsids.non_well_known_count ();\n  gsize = sizeof (DWORD) + non_well_known_cnt * sizeof (SID_AND_ATTRIBUTES);\n  tmpidx = -1;\n  for (int i = 0; i < non_well_known_cnt; ++i)\n    if ((tmpidx = tmp_gsids.next_non_well_known_sid (tmpidx)) >= 0)\n      gsize += RtlLengthSid (tmp_gsids.sids[tmpidx]);\n\n  /* Retrieve list of privileges of that user.  The MIC SID is created by\n     the LSA here. */\n  if (!(privs = get_priv_list (lsa, usersid, tmp_gsids, psize, NULL)))\n    goto out;\n\n  /* Create DefaultDacl. */\n  dsize = sizeof (ACL) + 3 * sizeof (ACCESS_ALLOWED_ACE)\n\t  + RtlLengthSid (usersid)\n\t  + RtlLengthSid (well_known_admins_sid)\n\t  + RtlLengthSid (well_known_system_sid);\n  dacl = (PACL) alloca (dsize);\n  if (!NT_SUCCESS (RtlCreateAcl (dacl, dsize, ACL_REVISION)))\n    goto out;\n  if (!NT_SUCCESS (RtlAddAccessAllowedAce (dacl, ACL_REVISION, GENERIC_ALL,\n\t\t\t\t\t   usersid)))\n    goto out;\n  if (!NT_SUCCESS (RtlAddAccessAllowedAce (dacl, ACL_REVISION, GENERIC_ALL,\n\t\t\t\t\t   well_known_admins_sid)))\n    goto out;\n  if (!NT_SUCCESS (RtlAddAccessAllowedAce (dacl, ACL_REVISION, GENERIC_ALL,\n\t\t\t\t\t   well_known_system_sid)))\n    goto out;\n\n  /* Evaluate authinf size and allocate authinf. */\n  authinf_size = (authinf->data - (PBYTE) authinf);\n  authinf_size += RtlLengthSid (usersid);\t    /* User SID */\n  authinf_size += gsize;\t\t\t    /* Groups + Group SIDs */\n  /* When trying to define the admins group as primary group on Vista,\n     LsaLogonUser fails with error STATUS_INVALID_OWNER.  As workaround\n     we define \"Local\" as primary group here.  Seteuid32 sets the primary\n     group to the group set in /etc/passwd anyway. */\n  if (new_groups.pgsid == well_known_admins_sid)\n    pgrpsid = well_known_local_sid;\n  else\n    pgrpsid = new_groups.pgsid;\n\n  authinf_size += RtlLengthSid (pgrpsid);\t    /* Primary Group SID */\n\n  authinf_size += psize;\t\t\t    /* Privileges */\n  authinf_size += 0;\t\t\t\t    /* Owner SID */\n  authinf_size += dsize;\t\t\t    /* Default DACL */\n\n  authinf = (cyglsa_t *) alloca (authinf_size);\n  authinf->inf_size = authinf_size - ((PBYTE) &authinf->inf - (PBYTE) authinf);\n\n  authinf->magic = CYG_LSA_MAGIC;\n\n  if (!LookupAccountSidW (NULL, usersid, authinf->username, &ulen,\n\t\t\t  authinf->domain, &dlen, &use))\n    {\n      __seterrno ();\n      goto out;\n    }\n\n  /* Store stuff in authinf with offset relative to start of \"inf\" member,\n     instead of using pointers. */\n  offset = authinf->data - (PBYTE) &authinf->inf;\n\n  authinf->inf.ExpirationTime.LowPart = 0xffffffffL;\n  authinf->inf.ExpirationTime.HighPart = 0x7fffffffL;\n  /* User SID */\n  authinf->inf.User.User.Sid = offset;\n  authinf->inf.User.User.Attributes = 0;\n  RtlCopySid (RtlLengthSid (usersid), (PSID) ((PBYTE) &authinf->inf + offset),\n\t      usersid);\n  offset += RtlLengthSid (usersid);\n  /* Groups */\n  authinf->inf.Groups = offset;\n  gsids = (PCYG_TOKEN_GROUPS) ((PBYTE) &authinf->inf + offset);\n  sids_offset = offset + sizeof (ULONG) + non_well_known_cnt\n\t\t\t\t\t  * sizeof (SID_AND_ATTRIBUTES);\n  gsids->GroupCount = non_well_known_cnt;\n  /* Group SIDs */\n  tmpidx = -1;\n  for (int i = 0; i < non_well_known_cnt; ++i)\n    {\n      if ((tmpidx = tmp_gsids.next_non_well_known_sid (tmpidx)) < 0)\n\tbreak;\n      gsids->Groups[i].Sid = sids_offset;\n      gsids->Groups[i].Attributes = SE_GROUP_MANDATORY\n\t\t\t\t    | SE_GROUP_ENABLED_BY_DEFAULT\n\t\t\t\t    | SE_GROUP_ENABLED;\n      RtlCopySid (RtlLengthSid (tmp_gsids.sids[tmpidx]),\n\t\t  (PSID) ((PBYTE) &authinf->inf + sids_offset),\n\t\t  tmp_gsids.sids[tmpidx]);\n      sids_offset += RtlLengthSid (tmp_gsids.sids[tmpidx]);\n    }\n  offset += gsize;\n  /* Primary Group SID */\n  authinf->inf.PrimaryGroup.PrimaryGroup = offset;\n  RtlCopySid (RtlLengthSid (pgrpsid), (PSID) ((PBYTE) &authinf->inf + offset),\n\t      pgrpsid);\n  offset += RtlLengthSid (pgrpsid);\n  /* Privileges */\n  authinf->inf.Privileges = offset;\n  memcpy ((PBYTE) &authinf->inf + offset, privs, psize);\n  offset += psize;\n  /* Owner */\n  authinf->inf.Owner.Owner = 0;\n  /* Default DACL */\n  authinf->inf.DefaultDacl.DefaultDacl = offset;\n  memcpy ((PBYTE) &authinf->inf + offset, dacl, dsize);\n\n  authinf->checksum = CYG_LSA_MAGIC;\n  PDWORD csp;\n  PDWORD csp_end;\n  csp = (PDWORD) &authinf->username;\n  csp_end = (PDWORD) ((PBYTE) authinf + authinf_size);\n  while (csp < csp_end)\n    authinf->checksum += *csp++;\n\n  /* Try to logon... */\n  status = LsaLogonUser (lsa_hdl, (PLSA_STRING) &origin, Interactive,\n\t\t\t package_id, authinf, authinf_size, NULL, &ts,\n\t\t\t &profile, &size, &luid, &user_token, &quota,\n\t\t\t &sub_status);\n  if (status != STATUS_SUCCESS)\n    {\n      debug_printf (\"LsaLogonUser: %y (sub-status %y)\", status, sub_status);\n      __seterrno_from_nt_status (status);\n      goto out;\n    }\n  if (profile)\n    {\n#ifdef JUST_ANOTHER_NONWORKING_SOLUTION\n      /* See ../lsaauth/cyglsa.c. */\n      cygprf_t *prf = (cygprf_t *) profile;\n      if (prf->magic_pre == MAGIC_PRE && prf->magic_post == MAGIC_POST\n\t  && prf->token)\n\t{\n\t  CloseHandle (user_token);\n\t  user_token = prf->token;\n\t  system_printf (\"Got token through profile: %p\", user_token);\n\t}\n#endif /* JUST_ANOTHER_NONWORKING_SOLUTION */\n      LsaFreeReturnBuffer (profile);\n    }\n  user_token = get_full_privileged_inheritable_token (user_token);\n\nout:\n  if (privs)\n    free (privs);\n  lsa_close_policy (lsa);\n  if (lsa_hdl)\n    LsaDeregisterLogonProcess (lsa_hdl);\n  pop_self_privilege ();\n\n  debug_printf (\"%p = lsaauth ()\", user_token);\n  return user_token;\n}",
        "description": "Cygwin versions prior to 2.5.0 fail to correctly update permissions during user changes, enabling attackers to escalate their privileges.",
        "commit": "The vulnerability involves the creation of a security token without using the caller's credentials in the `sec_auth.cc` file. Specifically, the `get_token_group_sidlist`, `get_initgroups_sidlist`, and `get_setgroups_sidlist` functions have been modified to remove parameters related to authentication (`auth_luid` and `auth_pos`) and the code that adds a logon SID. The `create_token` function now explicitly sets the `auth_luid` to either `ANONYMOUS_LOGON_LUID` or `LOCALSERVICE_LUID` based on the operating system, and no longer handles the logon SID since it is no longer generated. Additionally, the `lsaauth` function has removed unused local variables `auth_luid` and `auth_pos`. A new element `has_broken_whoami` has been added to `wincap.h`, and implemented in `wincap.cc`. This change results in the creation of tokens without proper authentication context, potentially leading to unauthorized access or privilege escalation."
    },
    {
        "cwe": "CWE-121",
        "func_name": "libtiff/TIFFReadCustomDirectory",
        "score": 0.7616158127784729,
        "func_before": "int\nTIFFReadCustomDirectory(TIFF* tif, toff_t diroff,\n\t\t\tconst TIFFFieldArray* infoarray)\n{\n\tstatic const char module[] = \"TIFFReadCustomDirectory\";\n\tTIFFDirEntry* dir;\n\tuint16_t dircount;\n\tTIFFDirEntry* dp;\n\tuint16_t di;\n\tconst TIFFField* fip;\n\tuint32_t fii;\n        (*tif->tif_cleanup)(tif);   /* cleanup any previous compression state */\n\t_TIFFSetupFields(tif, infoarray);\n\tdircount=TIFFFetchDirectory(tif,diroff,&dir,NULL);\n\tif (!dircount)\n\t{\n\t\tTIFFErrorExt(tif->tif_clientdata,module,\n\t\t    \"Failed to read custom directory at offset %\" PRIu64,diroff);\n\t\treturn 0;\n\t}\n\tTIFFFreeDirectory(tif);\n\t_TIFFmemset(&tif->tif_dir, 0, sizeof(TIFFDirectory));\n\tTIFFReadDirectoryCheckOrder(tif,dir,dircount);\n\tfor (di=0, dp=dir; di<dircount; di++, dp++)\n\t{\n\t\tTIFFReadDirectoryFindFieldInfo(tif,dp->tdir_tag,&fii);\n\t\tif (fii == FAILED_FII)\n\t\t{\n\t\t\tTIFFWarningExt(tif->tif_clientdata, module,\n\t\t\t    \"Unknown field with tag %\"PRIu16\" (0x%\"PRIx16\") encountered\",\n\t\t\t    dp->tdir_tag, dp->tdir_tag);\n\t\t\tif (!_TIFFMergeFields(tif, _TIFFCreateAnonField(tif,\n\t\t\t\t\t\tdp->tdir_tag,\n\t\t\t\t\t\t(TIFFDataType) dp->tdir_type),\n\t\t\t\t\t     1)) {\n\t\t\t\tTIFFWarningExt(tif->tif_clientdata, module,\n\t\t\t\t    \"Registering anonymous field with tag %\"PRIu16\" (0x%\"PRIx16\") failed\",\n\t\t\t\t    dp->tdir_tag, dp->tdir_tag);\n\t\t\t\tdp->tdir_ignore = TRUE;\n\t\t\t} else {\n\t\t\t\tTIFFReadDirectoryFindFieldInfo(tif,dp->tdir_tag,&fii);\n\t\t\t\tassert( fii != FAILED_FII );\n\t\t\t}\n\t\t}\n\t\tif (!dp->tdir_ignore)\n\t\t{\n\t\t\tfip=tif->tif_fields[fii];\n\t\t\tif (fip->field_bit==FIELD_IGNORE)\n\t\t\t\tdp->tdir_ignore = TRUE;\n\t\t\telse\n\t\t\t{\n\t\t\t\t/* check data type */\n\t\t\t\twhile ((fip->field_type!=TIFF_ANY)&&(fip->field_type!=dp->tdir_type))\n\t\t\t\t{\n\t\t\t\t\tfii++;\n\t\t\t\t\tif ((fii==tif->tif_nfields)||\n\t\t\t\t\t    (tif->tif_fields[fii]->field_tag!=(uint32_t)dp->tdir_tag))\n\t\t\t\t\t{\n\t\t\t\t\t\tfii=0xFFFF;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t\tfip=tif->tif_fields[fii];\n\t\t\t\t}\n\t\t\t\tif (fii==0xFFFF)\n\t\t\t\t{\n\t\t\t\t\tTIFFWarningExt(tif->tif_clientdata, module,\n\t\t\t\t\t    \"Wrong data type %\"PRIu16\" for \\\"%s\\\"; tag ignored\",\n\t\t\t\t\t    dp->tdir_type,fip->field_name);\n\t\t\t\t\tdp->tdir_ignore = TRUE;\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\t/* check count if known in advance */\n\t\t\t\t\tif ((fip->field_readcount!=TIFF_VARIABLE)&&\n\t\t\t\t\t    (fip->field_readcount!=TIFF_VARIABLE2))\n\t\t\t\t\t{\n\t\t\t\t\t\tuint32_t expected;\n\t\t\t\t\t\tif (fip->field_readcount==TIFF_SPP)\n\t\t\t\t\t\t\texpected=(uint32_t)tif->tif_dir.td_samplesperpixel;\n\t\t\t\t\t\telse\n\t\t\t\t\t\t\texpected=(uint32_t)fip->field_readcount;\n\t\t\t\t\t\tif (!CheckDirCount(tif,dp,expected))\n\t\t\t\t\t\t\tdp->tdir_ignore = TRUE;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (!dp->tdir_ignore) {\n\t\t\t\tswitch (dp->tdir_tag) \n\t\t\t\t{\n\t\t\t\t\tcase EXIFTAG_SUBJECTDISTANCE:\n                        if(fip->field_name != NULL && strncmp(fip->field_name, \"Tag \", 4) != 0 ) {\n                            /* should only be called on a Exif directory */\n                            /* when exifFields[] is active */\n                            (void)TIFFFetchSubjectDistance(tif, dp);\n                        }\n                        else {\n                            (void)TIFFFetchNormalTag(tif, dp, TRUE);\n                        }\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tdefault:\n\t\t\t\t\t\t(void)TIFFFetchNormalTag(tif, dp, TRUE);\n\t\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t} /*-- if (!dp->tdir_ignore) */\n\t\t}\n\t}\n\tif (dir)\n\t\t_TIFFfree(dir);\n\treturn 1;\n}",
        "func_after": "int\nTIFFReadCustomDirectory(TIFF* tif, toff_t diroff,\n\t\t\tconst TIFFFieldArray* infoarray)\n{\n\tstatic const char module[] = \"TIFFReadCustomDirectory\";\n\tTIFFDirEntry* dir;\n\tuint16_t dircount;\n\tTIFFDirEntry* dp;\n\tuint16_t di;\n\tconst TIFFField* fip;\n\tuint32_t fii;\n        (*tif->tif_cleanup)(tif);   /* cleanup any previous compression state */\n\t_TIFFSetupFields(tif, infoarray);\n\tdircount=TIFFFetchDirectory(tif,diroff,&dir,NULL);\n\tif (!dircount)\n\t{\n\t\tTIFFErrorExt(tif->tif_clientdata,module,\n\t\t    \"Failed to read custom directory at offset %\" PRIu64,diroff);\n\t\treturn 0;\n\t}\n\tTIFFFreeDirectory(tif);\n\t_TIFFmemset(&tif->tif_dir, 0, sizeof(TIFFDirectory));\n\tTIFFReadDirectoryCheckOrder(tif,dir,dircount);\n\tfor (di=0, dp=dir; di<dircount; di++, dp++)\n\t{\n\t\tTIFFReadDirectoryFindFieldInfo(tif,dp->tdir_tag,&fii);\n\t\tif (fii == FAILED_FII)\n\t\t{\n\t\t\tTIFFWarningExt(tif->tif_clientdata, module,\n\t\t\t    \"Unknown field with tag %\"PRIu16\" (0x%\"PRIx16\") encountered\",\n\t\t\t    dp->tdir_tag, dp->tdir_tag);\n\t\t\tif (!_TIFFMergeFields(tif, _TIFFCreateAnonField(tif,\n\t\t\t\t\t\tdp->tdir_tag,\n\t\t\t\t\t\t(TIFFDataType) dp->tdir_type),\n\t\t\t\t\t     1)) {\n\t\t\t\tTIFFWarningExt(tif->tif_clientdata, module,\n\t\t\t\t    \"Registering anonymous field with tag %\"PRIu16\" (0x%\"PRIx16\") failed\",\n\t\t\t\t    dp->tdir_tag, dp->tdir_tag);\n\t\t\t\tdp->tdir_ignore = TRUE;\n\t\t\t} else {\n\t\t\t\tTIFFReadDirectoryFindFieldInfo(tif,dp->tdir_tag,&fii);\n\t\t\t\tassert( fii != FAILED_FII );\n\t\t\t}\n\t\t}\n\t\tif (!dp->tdir_ignore)\n\t\t{\n\t\t\tfip=tif->tif_fields[fii];\n\t\t\tif (fip->field_bit==FIELD_IGNORE)\n\t\t\t\tdp->tdir_ignore = TRUE;\n\t\t\telse\n\t\t\t{\n\t\t\t\t/* check data type */\n\t\t\t\twhile ((fip->field_type!=TIFF_ANY)&&(fip->field_type!=dp->tdir_type))\n\t\t\t\t{\n\t\t\t\t\tfii++;\n\t\t\t\t\tif ((fii==tif->tif_nfields)||\n\t\t\t\t\t    (tif->tif_fields[fii]->field_tag!=(uint32_t)dp->tdir_tag))\n\t\t\t\t\t{\n\t\t\t\t\t\tfii=0xFFFF;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t\tfip=tif->tif_fields[fii];\n\t\t\t\t}\n\t\t\t\tif (fii==0xFFFF)\n\t\t\t\t{\n\t\t\t\t\tTIFFWarningExt(tif->tif_clientdata, module,\n\t\t\t\t\t    \"Wrong data type %\"PRIu16\" for \\\"%s\\\"; tag ignored\",\n\t\t\t\t\t    dp->tdir_type,fip->field_name);\n\t\t\t\t\tdp->tdir_ignore = TRUE;\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\t/* check count if known in advance */\n\t\t\t\t\tif ((fip->field_readcount!=TIFF_VARIABLE)&&\n\t\t\t\t\t    (fip->field_readcount!=TIFF_VARIABLE2))\n\t\t\t\t\t{\n\t\t\t\t\t\tuint32_t expected;\n\t\t\t\t\t\tif (fip->field_readcount==TIFF_SPP)\n\t\t\t\t\t\t\texpected=(uint32_t)tif->tif_dir.td_samplesperpixel;\n\t\t\t\t\t\telse\n\t\t\t\t\t\t\texpected=(uint32_t)fip->field_readcount;\n\t\t\t\t\t\tif (!CheckDirCount(tif,dp,expected))\n\t\t\t\t\t\t\tdp->tdir_ignore = TRUE;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (!dp->tdir_ignore) {\n\t\t\t\tswitch (dp->tdir_tag) \n\t\t\t\t{\n\t\t\t\t\tcase EXIFTAG_SUBJECTDISTANCE:\n                        if(!TIFFFieldIsAnonymous(fip)) {\n                            /* should only be called on a Exif directory */\n                            /* when exifFields[] is active */\n                            (void)TIFFFetchSubjectDistance(tif, dp);\n                        }\n                        else {\n                            (void)TIFFFetchNormalTag(tif, dp, TRUE);\n                        }\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tdefault:\n\t\t\t\t\t\t(void)TIFFFetchNormalTag(tif, dp, TRUE);\n\t\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t} /*-- if (!dp->tdir_ignore) */\n\t\t}\n\t}\n\tif (dir)\n\t\t_TIFFfree(dir);\n\treturn 1;\n}",
        "description": "A stack buffer overflow vulnerability exists in the `main()` function of Libtiffs' `tiffcp.c`. This flaw enables an attacker to exploit it by providing a specially crafted TIFF file to the `tiffcp` tool, resulting in a stack buffer overflow. This can lead to memory corruption and ultimately cause a crash, leading to a denial of service.",
        "commit": "The addition of an extra flag for handling anonymous or unknown tags."
    },
    {
        "cwe": "CWE-416",
        "func_name": "torvalds/ipt_do_table",
        "score": 0.7685721516609192,
        "func_before": "unsigned int\nipt_do_table(struct sk_buff *skb,\n\t     const struct nf_hook_state *state,\n\t     struct xt_table *table)\n{\n\tunsigned int hook = state->hook;\n\tstatic const char nulldevname[IFNAMSIZ] __attribute__((aligned(sizeof(long))));\n\tconst struct iphdr *ip;\n\t/* Initializing verdict to NF_DROP keeps gcc happy. */\n\tunsigned int verdict = NF_DROP;\n\tconst char *indev, *outdev;\n\tconst void *table_base;\n\tstruct ipt_entry *e, **jumpstack;\n\tunsigned int stackidx, cpu;\n\tconst struct xt_table_info *private;\n\tstruct xt_action_param acpar;\n\tunsigned int addend;\n\n\t/* Initialization */\n\tstackidx = 0;\n\tip = ip_hdr(skb);\n\tindev = state->in ? state->in->name : nulldevname;\n\toutdev = state->out ? state->out->name : nulldevname;\n\t/* We handle fragments by dealing with the first fragment as\n\t * if it was a normal packet.  All other fragments are treated\n\t * normally, except that they will NEVER match rules that ask\n\t * things we don't know, ie. tcp syn flag or ports).  If the\n\t * rule is also a fragment-specific rule, non-fragments won't\n\t * match it. */\n\tacpar.fragoff = ntohs(ip->frag_off) & IP_OFFSET;\n\tacpar.thoff   = ip_hdrlen(skb);\n\tacpar.hotdrop = false;\n\tacpar.state   = state;\n\n\tWARN_ON(!(table->valid_hooks & (1 << hook)));\n\tlocal_bh_disable();\n\taddend = xt_write_recseq_begin();\n\tprivate = READ_ONCE(table->private); /* Address dependency. */\n\tcpu        = smp_processor_id();\n\ttable_base = private->entries;\n\tjumpstack  = (struct ipt_entry **)private->jumpstack[cpu];\n\n\t/* Switch to alternate jumpstack if we're being invoked via TEE.\n\t * TEE issues XT_CONTINUE verdict on original skb so we must not\n\t * clobber the jumpstack.\n\t *\n\t * For recursion via REJECT or SYNPROXY the stack will be clobbered\n\t * but it is no problem since absolute verdict is issued by these.\n\t */\n\tif (static_key_false(&xt_tee_enabled))\n\t\tjumpstack += private->stacksize * __this_cpu_read(nf_skb_duplicated);\n\n\te = get_entry(table_base, private->hook_entry[hook]);\n\n\tdo {\n\t\tconst struct xt_entry_target *t;\n\t\tconst struct xt_entry_match *ematch;\n\t\tstruct xt_counters *counter;\n\n\t\tWARN_ON(!e);\n\t\tif (!ip_packet_match(ip, indev, outdev,\n\t\t    &e->ip, acpar.fragoff)) {\n no_match:\n\t\t\te = ipt_next_entry(e);\n\t\t\tcontinue;\n\t\t}\n\n\t\txt_ematch_foreach(ematch, e) {\n\t\t\tacpar.match     = ematch->u.kernel.match;\n\t\t\tacpar.matchinfo = ematch->data;\n\t\t\tif (!acpar.match->match(skb, &acpar))\n\t\t\t\tgoto no_match;\n\t\t}\n\n\t\tcounter = xt_get_this_cpu_counter(&e->counters);\n\t\tADD_COUNTER(*counter, skb->len, 1);\n\n\t\tt = ipt_get_target_c(e);\n\t\tWARN_ON(!t->u.kernel.target);\n\n#if IS_ENABLED(CONFIG_NETFILTER_XT_TARGET_TRACE)\n\t\t/* The packet is traced: log it */\n\t\tif (unlikely(skb->nf_trace))\n\t\t\ttrace_packet(state->net, skb, hook, state->in,\n\t\t\t\t     state->out, table->name, private, e);\n#endif\n\t\t/* Standard target? */\n\t\tif (!t->u.kernel.target->target) {\n\t\t\tint v;\n\n\t\t\tv = ((struct xt_standard_target *)t)->verdict;\n\t\t\tif (v < 0) {\n\t\t\t\t/* Pop from stack? */\n\t\t\t\tif (v != XT_RETURN) {\n\t\t\t\t\tverdict = (unsigned int)(-v) - 1;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tif (stackidx == 0) {\n\t\t\t\t\te = get_entry(table_base,\n\t\t\t\t\t    private->underflow[hook]);\n\t\t\t\t} else {\n\t\t\t\t\te = jumpstack[--stackidx];\n\t\t\t\t\te = ipt_next_entry(e);\n\t\t\t\t}\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (table_base + v != ipt_next_entry(e) &&\n\t\t\t    !(e->ip.flags & IPT_F_GOTO)) {\n\t\t\t\tif (unlikely(stackidx >= private->stacksize)) {\n\t\t\t\t\tverdict = NF_DROP;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tjumpstack[stackidx++] = e;\n\t\t\t}\n\n\t\t\te = get_entry(table_base, v);\n\t\t\tcontinue;\n\t\t}\n\n\t\tacpar.target   = t->u.kernel.target;\n\t\tacpar.targinfo = t->data;\n\n\t\tverdict = t->u.kernel.target->target(skb, &acpar);\n\t\tif (verdict == XT_CONTINUE) {\n\t\t\t/* Target might have changed stuff. */\n\t\t\tip = ip_hdr(skb);\n\t\t\te = ipt_next_entry(e);\n\t\t} else {\n\t\t\t/* Verdict */\n\t\t\tbreak;\n\t\t}\n\t} while (!acpar.hotdrop);\n\n\txt_write_recseq_end(addend);\n\tlocal_bh_enable();\n\n\tif (acpar.hotdrop)\n\t\treturn NF_DROP;\n\telse return verdict;\n}",
        "func_after": "unsigned int\nipt_do_table(struct sk_buff *skb,\n\t     const struct nf_hook_state *state,\n\t     struct xt_table *table)\n{\n\tunsigned int hook = state->hook;\n\tstatic const char nulldevname[IFNAMSIZ] __attribute__((aligned(sizeof(long))));\n\tconst struct iphdr *ip;\n\t/* Initializing verdict to NF_DROP keeps gcc happy. */\n\tunsigned int verdict = NF_DROP;\n\tconst char *indev, *outdev;\n\tconst void *table_base;\n\tstruct ipt_entry *e, **jumpstack;\n\tunsigned int stackidx, cpu;\n\tconst struct xt_table_info *private;\n\tstruct xt_action_param acpar;\n\tunsigned int addend;\n\n\t/* Initialization */\n\tstackidx = 0;\n\tip = ip_hdr(skb);\n\tindev = state->in ? state->in->name : nulldevname;\n\toutdev = state->out ? state->out->name : nulldevname;\n\t/* We handle fragments by dealing with the first fragment as\n\t * if it was a normal packet.  All other fragments are treated\n\t * normally, except that they will NEVER match rules that ask\n\t * things we don't know, ie. tcp syn flag or ports).  If the\n\t * rule is also a fragment-specific rule, non-fragments won't\n\t * match it. */\n\tacpar.fragoff = ntohs(ip->frag_off) & IP_OFFSET;\n\tacpar.thoff   = ip_hdrlen(skb);\n\tacpar.hotdrop = false;\n\tacpar.state   = state;\n\n\tWARN_ON(!(table->valid_hooks & (1 << hook)));\n\tlocal_bh_disable();\n\taddend = xt_write_recseq_begin();\n\tprivate = rcu_access_pointer(table->private);\n\tcpu        = smp_processor_id();\n\ttable_base = private->entries;\n\tjumpstack  = (struct ipt_entry **)private->jumpstack[cpu];\n\n\t/* Switch to alternate jumpstack if we're being invoked via TEE.\n\t * TEE issues XT_CONTINUE verdict on original skb so we must not\n\t * clobber the jumpstack.\n\t *\n\t * For recursion via REJECT or SYNPROXY the stack will be clobbered\n\t * but it is no problem since absolute verdict is issued by these.\n\t */\n\tif (static_key_false(&xt_tee_enabled))\n\t\tjumpstack += private->stacksize * __this_cpu_read(nf_skb_duplicated);\n\n\te = get_entry(table_base, private->hook_entry[hook]);\n\n\tdo {\n\t\tconst struct xt_entry_target *t;\n\t\tconst struct xt_entry_match *ematch;\n\t\tstruct xt_counters *counter;\n\n\t\tWARN_ON(!e);\n\t\tif (!ip_packet_match(ip, indev, outdev,\n\t\t    &e->ip, acpar.fragoff)) {\n no_match:\n\t\t\te = ipt_next_entry(e);\n\t\t\tcontinue;\n\t\t}\n\n\t\txt_ematch_foreach(ematch, e) {\n\t\t\tacpar.match     = ematch->u.kernel.match;\n\t\t\tacpar.matchinfo = ematch->data;\n\t\t\tif (!acpar.match->match(skb, &acpar))\n\t\t\t\tgoto no_match;\n\t\t}\n\n\t\tcounter = xt_get_this_cpu_counter(&e->counters);\n\t\tADD_COUNTER(*counter, skb->len, 1);\n\n\t\tt = ipt_get_target_c(e);\n\t\tWARN_ON(!t->u.kernel.target);\n\n#if IS_ENABLED(CONFIG_NETFILTER_XT_TARGET_TRACE)\n\t\t/* The packet is traced: log it */\n\t\tif (unlikely(skb->nf_trace))\n\t\t\ttrace_packet(state->net, skb, hook, state->in,\n\t\t\t\t     state->out, table->name, private, e);\n#endif\n\t\t/* Standard target? */\n\t\tif (!t->u.kernel.target->target) {\n\t\t\tint v;\n\n\t\t\tv = ((struct xt_standard_target *)t)->verdict;\n\t\t\tif (v < 0) {\n\t\t\t\t/* Pop from stack? */\n\t\t\t\tif (v != XT_RETURN) {\n\t\t\t\t\tverdict = (unsigned int)(-v) - 1;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tif (stackidx == 0) {\n\t\t\t\t\te = get_entry(table_base,\n\t\t\t\t\t    private->underflow[hook]);\n\t\t\t\t} else {\n\t\t\t\t\te = jumpstack[--stackidx];\n\t\t\t\t\te = ipt_next_entry(e);\n\t\t\t\t}\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (table_base + v != ipt_next_entry(e) &&\n\t\t\t    !(e->ip.flags & IPT_F_GOTO)) {\n\t\t\t\tif (unlikely(stackidx >= private->stacksize)) {\n\t\t\t\t\tverdict = NF_DROP;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tjumpstack[stackidx++] = e;\n\t\t\t}\n\n\t\t\te = get_entry(table_base, v);\n\t\t\tcontinue;\n\t\t}\n\n\t\tacpar.target   = t->u.kernel.target;\n\t\tacpar.targinfo = t->data;\n\n\t\tverdict = t->u.kernel.target->target(skb, &acpar);\n\t\tif (verdict == XT_CONTINUE) {\n\t\t\t/* Target might have changed stuff. */\n\t\t\tip = ip_hdr(skb);\n\t\t\te = ipt_next_entry(e);\n\t\t} else {\n\t\t\t/* Verdict */\n\t\t\tbreak;\n\t\t}\n\t} while (!acpar.hotdrop);\n\n\txt_write_recseq_end(addend);\n\tlocal_bh_enable();\n\n\tif (acpar.hotdrop)\n\t\treturn NF_DROP;\n\telse return verdict;\n}",
        "description": "An issue was discovered in the netfilter component of the Linux kernel prior to version 5.10. This vulnerability involves a use-after-free condition in the packet processing context due to improper handling of per-CPU sequence counts during concurrent iptables rule replacements. This flaw could be exploited by users with the CAP_NET_ADMIN capability in an unprivileged namespace.",
        "commit": "When performing concurrent iptables rules replacement, the system checks the per-CPU sequence count after assigning new information. This sequence count is intended to synchronize with the packet path without using explicit locking. If packets are currently using the old table information, the sequence count is incremented to an odd value and then to an even value after processing. After assigning the new table information, a write memory barrier is executed to ensure all CPUs see the latest value. If the packet path starts with the old table information, the sequence counter remains odd, and the iptables replacement waits until the sequence count is even before freeing the old table information. However, if the CPU delays executing the new table information assignment and memory barrier, another CPU's packet path may still use the old table information. This delay can lead to a use-after-free error in the packet processing context, resulting in a kernel NULL pointer dereference. To fix this issue, either enforce instruction ordering after the new table information assignment or switch to RCU for synchronization."
    },
    {
        "cwe": "CWE-74",
        "func_name": "flatpak/flatpak_run_add_environment_args",
        "score": 0.7538030743598938,
        "func_before": "gboolean\nflatpak_run_add_environment_args (FlatpakBwrap    *bwrap,\n                                  const char      *app_info_path,\n                                  FlatpakRunFlags  flags,\n                                  const char      *app_id,\n                                  FlatpakContext  *context,\n                                  GFile           *app_id_dir,\n                                  GPtrArray       *previous_app_id_dirs,\n                                  FlatpakExports **exports_out,\n                                  GCancellable    *cancellable,\n                                  GError         **error)\n{\n  g_autoptr(GError) my_error = NULL;\n  g_autoptr(FlatpakExports) exports = NULL;\n  g_autoptr(FlatpakBwrap) proxy_arg_bwrap = flatpak_bwrap_new (flatpak_bwrap_empty_env);\n  gboolean has_wayland = FALSE;\n  gboolean allow_x11 = FALSE;\n\n  if ((context->shares & FLATPAK_CONTEXT_SHARED_IPC) == 0)\n    {\n      g_debug (\"Disallowing ipc access\");\n      flatpak_bwrap_add_args (bwrap, \"--unshare-ipc\", NULL);\n    }\n\n  if ((context->shares & FLATPAK_CONTEXT_SHARED_NETWORK) == 0)\n    {\n      g_debug (\"Disallowing network access\");\n      flatpak_bwrap_add_args (bwrap, \"--unshare-net\", NULL);\n    }\n\n  if (context->devices & FLATPAK_CONTEXT_DEVICE_ALL)\n    {\n      flatpak_bwrap_add_args (bwrap,\n                              \"--dev-bind\", \"/dev\", \"/dev\",\n                              NULL);\n      /* Don't expose the host /dev/shm, just the device nodes, unless explicitly allowed */\n      if (g_file_test (\"/dev/shm\", G_FILE_TEST_IS_DIR))\n        {\n          if ((context->devices & FLATPAK_CONTEXT_DEVICE_SHM) == 0)\n            flatpak_bwrap_add_args (bwrap,\n                                    \"--tmpfs\", \"/dev/shm\",\n                                    NULL);\n        }\n      else if (g_file_test (\"/dev/shm\", G_FILE_TEST_IS_SYMLINK))\n        {\n          g_autofree char *link = flatpak_readlink (\"/dev/shm\", NULL);\n\n          /* On debian (with sysv init) the host /dev/shm is a symlink to /run/shm, so we can't\n             mount on top of it. */\n          if (g_strcmp0 (link, \"/run/shm\") == 0)\n            {\n              if (context->devices & FLATPAK_CONTEXT_DEVICE_SHM &&\n                  g_file_test (\"/run/shm\", G_FILE_TEST_IS_DIR))\n                flatpak_bwrap_add_args (bwrap,\n                                        \"--bind\", \"/run/shm\", \"/run/shm\",\n                                        NULL);\n              else\n                flatpak_bwrap_add_args (bwrap,\n                                        \"--dir\", \"/run/shm\",\n                                        NULL);\n            }\n          else\n            g_warning (\"Unexpected /dev/shm symlink %s\", link);\n        }\n    }\n  else\n    {\n      flatpak_bwrap_add_args (bwrap,\n                              \"--dev\", \"/dev\",\n                              NULL);\n      if (context->devices & FLATPAK_CONTEXT_DEVICE_DRI)\n        {\n          g_debug (\"Allowing dri access\");\n          int i;\n          char *dri_devices[] = {\n            \"/dev/dri\",\n            /* mali */\n            \"/dev/mali\",\n            \"/dev/mali0\",\n            \"/dev/umplock\",\n            /* nvidia */\n            \"/dev/nvidiactl\",\n            \"/dev/nvidia-modeset\",\n            /* nvidia OpenCL/CUDA */\n            \"/dev/nvidia-uvm\",\n            \"/dev/nvidia-uvm-tools\",\n          };\n\n          for (i = 0; i < G_N_ELEMENTS (dri_devices); i++)\n            {\n              if (g_file_test (dri_devices[i], G_FILE_TEST_EXISTS))\n                flatpak_bwrap_add_args (bwrap, \"--dev-bind\", dri_devices[i], dri_devices[i], NULL);\n            }\n\n          /* Each Nvidia card gets its own device.\n             This is a fairly arbitrary limit but ASUS sells mining boards supporting 20 in theory. */\n          char nvidia_dev[14]; /* /dev/nvidia plus up to 2 digits */\n          for (i = 0; i < 20; i++)\n            {\n              g_snprintf (nvidia_dev, sizeof (nvidia_dev), \"/dev/nvidia%d\", i);\n              if (g_file_test (nvidia_dev, G_FILE_TEST_EXISTS))\n                flatpak_bwrap_add_args (bwrap, \"--dev-bind\", nvidia_dev, nvidia_dev, NULL);\n            }\n        }\n\n      if (context->devices & FLATPAK_CONTEXT_DEVICE_KVM)\n        {\n          g_debug (\"Allowing kvm access\");\n          if (g_file_test (\"/dev/kvm\", G_FILE_TEST_EXISTS))\n            flatpak_bwrap_add_args (bwrap, \"--dev-bind\", \"/dev/kvm\", \"/dev/kvm\", NULL);\n        }\n\n      if (context->devices & FLATPAK_CONTEXT_DEVICE_SHM)\n        {\n          /* This is a symlink to /run/shm on debian, so bind to real target */\n          g_autofree char *real_dev_shm = realpath (\"/dev/shm\", NULL);\n\n          g_debug (\"Allowing /dev/shm access (as %s)\", real_dev_shm);\n          if (real_dev_shm != NULL)\n              flatpak_bwrap_add_args (bwrap, \"--bind\", real_dev_shm, \"/dev/shm\", NULL);\n        }\n    }\n\n  flatpak_context_append_bwrap_filesystem (context, bwrap, app_id, app_id_dir, previous_app_id_dirs, &exports);\n\n  if (context->sockets & FLATPAK_CONTEXT_SOCKET_WAYLAND)\n    {\n      g_debug (\"Allowing wayland access\");\n      has_wayland = flatpak_run_add_wayland_args (bwrap);\n    }\n\n  if ((context->sockets & FLATPAK_CONTEXT_SOCKET_FALLBACK_X11) != 0)\n    allow_x11 = !has_wayland;\n  else\n    allow_x11 = (context->sockets & FLATPAK_CONTEXT_SOCKET_X11) != 0;\n\n  flatpak_run_add_x11_args (bwrap, allow_x11);\n\n  if (context->sockets & FLATPAK_CONTEXT_SOCKET_SSH_AUTH)\n    {\n      flatpak_run_add_ssh_args (bwrap);\n    }\n\n  if (context->sockets & FLATPAK_CONTEXT_SOCKET_PULSEAUDIO)\n    {\n      g_debug (\"Allowing pulseaudio access\");\n      flatpak_run_add_pulseaudio_args (bwrap);\n    }\n\n  if (context->sockets & FLATPAK_CONTEXT_SOCKET_PCSC)\n    {\n      flatpak_run_add_pcsc_args (bwrap);\n    }\n\n  if (context->sockets & FLATPAK_CONTEXT_SOCKET_CUPS)\n    {\n      flatpak_run_add_cups_args (bwrap);\n    }\n\n  flatpak_run_add_session_dbus_args (bwrap, proxy_arg_bwrap, context, flags, app_id);\n  flatpak_run_add_system_dbus_args (bwrap, proxy_arg_bwrap, context, flags);\n  flatpak_run_add_a11y_dbus_args (bwrap, proxy_arg_bwrap, context, flags);\n\n  if (g_environ_getenv (bwrap->envp, \"LD_LIBRARY_PATH\") != NULL)\n    {\n      /* LD_LIBRARY_PATH is overridden for setuid helper, so pass it as cmdline arg */\n      flatpak_bwrap_add_args (bwrap,\n                              \"--setenv\", \"LD_LIBRARY_PATH\", g_environ_getenv (bwrap->envp, \"LD_LIBRARY_PATH\"),\n                              NULL);\n      flatpak_bwrap_unset_env (bwrap, \"LD_LIBRARY_PATH\");\n    }\n\n  if (g_environ_getenv (bwrap->envp, \"TMPDIR\") != NULL)\n    {\n      /* TMPDIR is overridden for setuid helper, so pass it as cmdline arg */\n      flatpak_bwrap_add_args (bwrap,\n                              \"--setenv\", \"TMPDIR\", g_environ_getenv (bwrap->envp, \"TMPDIR\"),\n                              NULL);\n      flatpak_bwrap_unset_env (bwrap, \"TMPDIR\");\n    }\n\n  /* Must run this before spawning the dbus proxy, to ensure it\n     ends up in the app cgroup */\n  if (!flatpak_run_in_transient_unit (app_id, &my_error))\n    {\n      /* We still run along even if we don't get a cgroup, as nothing\n         really depends on it. Its just nice to have */\n      g_debug (\"Failed to run in transient scope: %s\", my_error->message);\n      g_clear_error (&my_error);\n    }\n\n  if (!flatpak_bwrap_is_empty (proxy_arg_bwrap) &&\n      !start_dbus_proxy (bwrap, proxy_arg_bwrap, app_info_path, error))\n    return FALSE;\n\n  if (exports_out)\n    *exports_out = g_steal_pointer (&exports);\n\n  return TRUE;\n}",
        "func_after": "gboolean\nflatpak_run_add_environment_args (FlatpakBwrap    *bwrap,\n                                  const char      *app_info_path,\n                                  FlatpakRunFlags  flags,\n                                  const char      *app_id,\n                                  FlatpakContext  *context,\n                                  GFile           *app_id_dir,\n                                  GPtrArray       *previous_app_id_dirs,\n                                  FlatpakExports **exports_out,\n                                  GCancellable    *cancellable,\n                                  GError         **error)\n{\n  g_autoptr(GError) my_error = NULL;\n  g_autoptr(FlatpakExports) exports = NULL;\n  g_autoptr(FlatpakBwrap) proxy_arg_bwrap = flatpak_bwrap_new (flatpak_bwrap_empty_env);\n  gboolean has_wayland = FALSE;\n  gboolean allow_x11 = FALSE;\n\n  if ((context->shares & FLATPAK_CONTEXT_SHARED_IPC) == 0)\n    {\n      g_debug (\"Disallowing ipc access\");\n      flatpak_bwrap_add_args (bwrap, \"--unshare-ipc\", NULL);\n    }\n\n  if ((context->shares & FLATPAK_CONTEXT_SHARED_NETWORK) == 0)\n    {\n      g_debug (\"Disallowing network access\");\n      flatpak_bwrap_add_args (bwrap, \"--unshare-net\", NULL);\n    }\n\n  if (context->devices & FLATPAK_CONTEXT_DEVICE_ALL)\n    {\n      flatpak_bwrap_add_args (bwrap,\n                              \"--dev-bind\", \"/dev\", \"/dev\",\n                              NULL);\n      /* Don't expose the host /dev/shm, just the device nodes, unless explicitly allowed */\n      if (g_file_test (\"/dev/shm\", G_FILE_TEST_IS_DIR))\n        {\n          if ((context->devices & FLATPAK_CONTEXT_DEVICE_SHM) == 0)\n            flatpak_bwrap_add_args (bwrap,\n                                    \"--tmpfs\", \"/dev/shm\",\n                                    NULL);\n        }\n      else if (g_file_test (\"/dev/shm\", G_FILE_TEST_IS_SYMLINK))\n        {\n          g_autofree char *link = flatpak_readlink (\"/dev/shm\", NULL);\n\n          /* On debian (with sysv init) the host /dev/shm is a symlink to /run/shm, so we can't\n             mount on top of it. */\n          if (g_strcmp0 (link, \"/run/shm\") == 0)\n            {\n              if (context->devices & FLATPAK_CONTEXT_DEVICE_SHM &&\n                  g_file_test (\"/run/shm\", G_FILE_TEST_IS_DIR))\n                flatpak_bwrap_add_args (bwrap,\n                                        \"--bind\", \"/run/shm\", \"/run/shm\",\n                                        NULL);\n              else\n                flatpak_bwrap_add_args (bwrap,\n                                        \"--dir\", \"/run/shm\",\n                                        NULL);\n            }\n          else\n            g_warning (\"Unexpected /dev/shm symlink %s\", link);\n        }\n    }\n  else\n    {\n      flatpak_bwrap_add_args (bwrap,\n                              \"--dev\", \"/dev\",\n                              NULL);\n      if (context->devices & FLATPAK_CONTEXT_DEVICE_DRI)\n        {\n          g_debug (\"Allowing dri access\");\n          int i;\n          char *dri_devices[] = {\n            \"/dev/dri\",\n            /* mali */\n            \"/dev/mali\",\n            \"/dev/mali0\",\n            \"/dev/umplock\",\n            /* nvidia */\n            \"/dev/nvidiactl\",\n            \"/dev/nvidia-modeset\",\n            /* nvidia OpenCL/CUDA */\n            \"/dev/nvidia-uvm\",\n            \"/dev/nvidia-uvm-tools\",\n          };\n\n          for (i = 0; i < G_N_ELEMENTS (dri_devices); i++)\n            {\n              if (g_file_test (dri_devices[i], G_FILE_TEST_EXISTS))\n                flatpak_bwrap_add_args (bwrap, \"--dev-bind\", dri_devices[i], dri_devices[i], NULL);\n            }\n\n          /* Each Nvidia card gets its own device.\n             This is a fairly arbitrary limit but ASUS sells mining boards supporting 20 in theory. */\n          char nvidia_dev[14]; /* /dev/nvidia plus up to 2 digits */\n          for (i = 0; i < 20; i++)\n            {\n              g_snprintf (nvidia_dev, sizeof (nvidia_dev), \"/dev/nvidia%d\", i);\n              if (g_file_test (nvidia_dev, G_FILE_TEST_EXISTS))\n                flatpak_bwrap_add_args (bwrap, \"--dev-bind\", nvidia_dev, nvidia_dev, NULL);\n            }\n        }\n\n      if (context->devices & FLATPAK_CONTEXT_DEVICE_KVM)\n        {\n          g_debug (\"Allowing kvm access\");\n          if (g_file_test (\"/dev/kvm\", G_FILE_TEST_EXISTS))\n            flatpak_bwrap_add_args (bwrap, \"--dev-bind\", \"/dev/kvm\", \"/dev/kvm\", NULL);\n        }\n\n      if (context->devices & FLATPAK_CONTEXT_DEVICE_SHM)\n        {\n          /* This is a symlink to /run/shm on debian, so bind to real target */\n          g_autofree char *real_dev_shm = realpath (\"/dev/shm\", NULL);\n\n          g_debug (\"Allowing /dev/shm access (as %s)\", real_dev_shm);\n          if (real_dev_shm != NULL)\n              flatpak_bwrap_add_args (bwrap, \"--bind\", real_dev_shm, \"/dev/shm\", NULL);\n        }\n    }\n\n  flatpak_context_append_bwrap_filesystem (context, bwrap, app_id, app_id_dir, previous_app_id_dirs, &exports);\n\n  if (context->sockets & FLATPAK_CONTEXT_SOCKET_WAYLAND)\n    {\n      g_debug (\"Allowing wayland access\");\n      has_wayland = flatpak_run_add_wayland_args (bwrap);\n    }\n\n  if ((context->sockets & FLATPAK_CONTEXT_SOCKET_FALLBACK_X11) != 0)\n    allow_x11 = !has_wayland;\n  else\n    allow_x11 = (context->sockets & FLATPAK_CONTEXT_SOCKET_X11) != 0;\n\n  flatpak_run_add_x11_args (bwrap, allow_x11);\n\n  if (context->sockets & FLATPAK_CONTEXT_SOCKET_SSH_AUTH)\n    {\n      flatpak_run_add_ssh_args (bwrap);\n    }\n\n  if (context->sockets & FLATPAK_CONTEXT_SOCKET_PULSEAUDIO)\n    {\n      g_debug (\"Allowing pulseaudio access\");\n      flatpak_run_add_pulseaudio_args (bwrap);\n    }\n\n  if (context->sockets & FLATPAK_CONTEXT_SOCKET_PCSC)\n    {\n      flatpak_run_add_pcsc_args (bwrap);\n    }\n\n  if (context->sockets & FLATPAK_CONTEXT_SOCKET_CUPS)\n    {\n      flatpak_run_add_cups_args (bwrap);\n    }\n\n  flatpak_run_add_session_dbus_args (bwrap, proxy_arg_bwrap, context, flags, app_id);\n  flatpak_run_add_system_dbus_args (bwrap, proxy_arg_bwrap, context, flags);\n  flatpak_run_add_a11y_dbus_args (bwrap, proxy_arg_bwrap, context, flags);\n\n  /* Must run this before spawning the dbus proxy, to ensure it\n     ends up in the app cgroup */\n  if (!flatpak_run_in_transient_unit (app_id, &my_error))\n    {\n      /* We still run along even if we don't get a cgroup, as nothing\n         really depends on it. Its just nice to have */\n      g_debug (\"Failed to run in transient scope: %s\", my_error->message);\n      g_clear_error (&my_error);\n    }\n\n  if (!flatpak_bwrap_is_empty (proxy_arg_bwrap) &&\n      !start_dbus_proxy (bwrap, proxy_arg_bwrap, app_info_path, error))\n    return FALSE;\n\n  if (exports_out)\n    *exports_out = g_steal_pointer (&exports);\n\n  return TRUE;\n}",
        "description": "A vulnerability was identified in the Flatpak portal service (`flatpak-portal`), allowing sandboxed applications to execute arbitrary code on the host system, effectively enabling a sandbox escape. This issue affects versions of Flatpak from 0.11.4 up to but not including fixed versions 1.8.5 and 1.10.0. The Flatpak portal service facilitates launching subprocesses within new sandbox instances, either with the same or more restrictive security settings compared to the calling application. Vulnerable versions pass caller-specified environment variables to non-sandboxed processes on the host system, particularly to the `flatpak run` command used for launching new sandbox instances. Malicious or compromised applications could exploit this by setting environment variables trusted by the `flatpak run` command, thereby executing arbitrary code outside the sandbox. As a temporary workaround, disabling the `flatpak-portal` service mitigates the vulnerability but may prevent many Flatpak applications from functioning correctly. This issue has been resolved in versions 1.8.5 and 1.10.0.",
        "commit": "The vulnerability involves converting all environment variables into arguments for `bwrap`, a tool used to create isolated execution environments. This conversion helps prevent certain environment variables from being filtered out by a setuid `bwrap`. Additionally, it ensures that even if these variables come from an untrusted source, they cannot be used to inject arbitrary code into a non-setuid `bwrap` through mechanisms like `LD_PRELOAD`. By bundling these variables into a `memfd` or temporary file, they are not included in `argv`, making them inaccessible to processes running under a different user ID. This measure is crucial for protecting sensitive information such as tokens or other secrets."
    }
]