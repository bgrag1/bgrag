static int load_video_binaries(struct ia_css_pipe *pipe)
{
	struct ia_css_frame_info video_in_info, tnr_info,
		       *video_vf_info, video_bds_out_info, *pipe_out_info, *pipe_vf_out_info;
	bool online;
	int err = 0;
	bool continuous = pipe->stream->config.continuous;
	unsigned int i;
	unsigned int num_output_pins;
	struct ia_css_frame_info video_bin_out_info;
	bool need_scaler = false;
	bool vf_res_different_than_output = false;
	bool need_vf_pp = false;
	int vf_ds_log2;
	struct ia_css_video_settings *mycs  = &pipe->pipe_settings.video;

	IA_CSS_ENTER_PRIVATE("");
	assert(pipe);
	assert(pipe->mode == IA_CSS_PIPE_ID_VIDEO);
	/*
	 * we only test the video_binary because offline video doesn't need a
	 * vf_pp binary and online does not (always use) the copy_binary.
	 * All are always reset at the same time anyway.
	 */
	if (mycs->video_binary.info)
		return 0;

	online = pipe->stream->config.online;
	pipe_out_info = &pipe->output_info[0];
	pipe_vf_out_info = &pipe->vf_output_info[0];

	assert(pipe_out_info);

	/*
	 * There is no explicit input format requirement for raw or yuv
	 * What matters is that there is a binary that supports the stream format.
	 * This is checked in the binary_find(), so no need to check it here
	 */
	err = ia_css_util_check_input(&pipe->stream->config, false, false);
	if (err)
		return err;
	/* cannot have online video and input_mode memory */
	if (online && pipe->stream->config.mode == IA_CSS_INPUT_MODE_MEMORY)
		return -EINVAL;
	if (pipe->enable_viewfinder[IA_CSS_PIPE_OUTPUT_STAGE_0]) {
		err = ia_css_util_check_vf_out_info(pipe_out_info,
						    pipe_vf_out_info);
		if (err)
			return err;
	} else {
		err = ia_css_frame_check_info(pipe_out_info);
		if (err)
			return err;
	}

	if (pipe->out_yuv_ds_input_info.res.width)
		video_bin_out_info = pipe->out_yuv_ds_input_info;
	else
		video_bin_out_info = *pipe_out_info;

	/* Video */
	if (pipe->enable_viewfinder[IA_CSS_PIPE_OUTPUT_STAGE_0]) {
		video_vf_info = pipe_vf_out_info;
		vf_res_different_than_output = (video_vf_info->res.width !=
						video_bin_out_info.res.width) ||
					       (video_vf_info->res.height != video_bin_out_info.res.height);
	} else {
		video_vf_info = NULL;
	}

	need_scaler = need_downscaling(video_bin_out_info.res, pipe_out_info->res);

	/* we build up the pipeline starting at the end */
	/* YUV post-processing if needed */
	if (need_scaler) {
		struct ia_css_cas_binary_descr cas_scaler_descr = { };

		/* NV12 is the common format that is supported by both */
		/* yuv_scaler and the video_xx_isp2_min binaries. */
		video_bin_out_info.format = IA_CSS_FRAME_FORMAT_NV12;

		err = ia_css_pipe_create_cas_scaler_desc_single_output(
			  &video_bin_out_info,
			  pipe_out_info,
			  NULL,
			  &cas_scaler_descr);
		if (err)
			return err;
		mycs->num_yuv_scaler = cas_scaler_descr.num_stage;
		mycs->yuv_scaler_binary = kcalloc(cas_scaler_descr.num_stage,
						  sizeof(struct ia_css_binary),
						  GFP_KERNEL);
		if (!mycs->yuv_scaler_binary) {
			mycs->num_yuv_scaler = 0;
			err = -ENOMEM;
			return err;
		}
		mycs->is_output_stage = kcalloc(cas_scaler_descr.num_stage,
						sizeof(bool), GFP_KERNEL);
		if (!mycs->is_output_stage) {
			err = -ENOMEM;
			return err;
		}
		for (i = 0; i < cas_scaler_descr.num_stage; i++) {
			struct ia_css_binary_descr yuv_scaler_descr;

			mycs->is_output_stage[i] = cas_scaler_descr.is_output_stage[i];
			ia_css_pipe_get_yuvscaler_binarydesc(pipe,
							     &yuv_scaler_descr, &cas_scaler_descr.in_info[i],
							     &cas_scaler_descr.out_info[i],
							     &cas_scaler_descr.internal_out_info[i],
							     &cas_scaler_descr.vf_info[i]);
			err = ia_css_binary_find(&yuv_scaler_descr,
						 &mycs->yuv_scaler_binary[i]);
			if (err) {
				kfree(mycs->is_output_stage);
				mycs->is_output_stage = NULL;
				return err;
			}
		}
		ia_css_pipe_destroy_cas_scaler_desc(&cas_scaler_descr);
	}

	{
		struct ia_css_binary_descr video_descr;
		enum ia_css_frame_format vf_info_format;

		err = ia_css_pipe_get_video_binarydesc(pipe,
						       &video_descr, &video_in_info, &video_bds_out_info, &video_bin_out_info,
						       video_vf_info,
						       pipe->stream->config.left_padding);
		if (err)
			return err;

		/*
		 * In the case where video_vf_info is not NULL, this allows
		 * us to find a potential video library with desired vf format.
		 * If success, no vf_pp binary is needed.
		 * If failed, we will look up video binary with YUV_LINE vf format
		 */
		err = ia_css_binary_find(&video_descr,
					 &mycs->video_binary);

		if (err) {
			/* This will do another video binary lookup later for YUV_LINE format*/
			if (video_vf_info)
				need_vf_pp = true;
			else
				return err;
		} else if (video_vf_info) {
			/*
			 * The first video binary lookup is successful, but we
			 * may still need vf_pp binary based on additional check
			 */
			num_output_pins = mycs->video_binary.info->num_output_pins;
			vf_ds_log2 = mycs->video_binary.vf_downscale_log2;

			/*
			 * If the binary has dual output pins, we need vf_pp
			 * if the resolution is different.
			 */
			need_vf_pp |= ((num_output_pins == 2) && vf_res_different_than_output);

			/*
			 * If the binary has single output pin, we need vf_pp
			 * if additional scaling is needed for vf
			 */
			need_vf_pp |= ((num_output_pins == 1) &&
				       ((video_vf_info->res.width << vf_ds_log2 != pipe_out_info->res.width) ||
					(video_vf_info->res.height << vf_ds_log2 != pipe_out_info->res.height)));
		}

		if (need_vf_pp) {
			/* save the current vf_info format for restoration later */
			ia_css_debug_dtrace(IA_CSS_DEBUG_TRACE,
					    "load_video_binaries() need_vf_pp; find video binary with YUV_LINE again\n");

			vf_info_format = video_vf_info->format;

			if (!pipe->config.enable_vfpp_bci)
				ia_css_frame_info_set_format(video_vf_info,
							     IA_CSS_FRAME_FORMAT_YUV_LINE);

			ia_css_binary_destroy_isp_parameters(&mycs->video_binary);

			err = ia_css_binary_find(&video_descr,
						 &mycs->video_binary);

			/* restore original vf_info format */
			ia_css_frame_info_set_format(video_vf_info,
						     vf_info_format);
			if (err)
				return err;
		}
	}

	/*
	 * If a video binary does not use a ref_frame, we set the frame delay
	 * to 0. This is the case for the 1-stage low-power video binary.
	 */
	if (!mycs->video_binary.info->sp.enable.ref_frame)
		pipe->dvs_frame_delay = 0;

	/*
	 * The delay latency determines the number of invalid frames after
	 * a stream is started.
	 */
	pipe->num_invalid_frames = pipe->dvs_frame_delay;
	pipe->info.num_invalid_frames = pipe->num_invalid_frames;

	/*
	 * Viewfinder frames also decrement num_invalid_frames. If the pipe
	 * outputs a viewfinder output, then we need double the number of
	 * invalid frames
	 */
	if (video_vf_info)
		pipe->num_invalid_frames *= 2;

	ia_css_debug_dtrace(IA_CSS_DEBUG_TRACE,
			    "load_video_binaries() num_invalid_frames=%d dvs_frame_delay=%d\n",
			    pipe->num_invalid_frames, pipe->dvs_frame_delay);

	/* pqiao TODO: temp hack for PO, should be removed after offline YUVPP is enabled */
	if (!IS_ISP2401) {
		/* Copy */
		if (!online && !continuous) {
			/*
			 * TODO: what exactly needs doing, prepend the copy binary to
			 *	 video base this only on !online?
			 */
			err = load_copy_binary(pipe,
					       &mycs->copy_binary,
					       &mycs->video_binary);
			if (err)
				return err;
		}
	}

	if (pipe->enable_viewfinder[IA_CSS_PIPE_OUTPUT_STAGE_0] && need_vf_pp) {
		struct ia_css_binary_descr vf_pp_descr;

		if (mycs->video_binary.vf_frame_info.format
		    == IA_CSS_FRAME_FORMAT_YUV_LINE) {
			ia_css_pipe_get_vfpp_binarydesc(pipe, &vf_pp_descr,
							&mycs->video_binary.vf_frame_info,
							pipe_vf_out_info);
		} else {
			/*
			 * output from main binary is not yuv line. currently
			 * this is possible only when bci is enabled on vfpp
			 * output
			 */
			assert(pipe->config.enable_vfpp_bci);
			ia_css_pipe_get_yuvscaler_binarydesc(pipe, &vf_pp_descr,
							     &mycs->video_binary.vf_frame_info,
							     pipe_vf_out_info, NULL, NULL);
		}

		err = ia_css_binary_find(&vf_pp_descr,
					 &mycs->vf_pp_binary);
		if (err)
			return err;
	}

	err = allocate_delay_frames(pipe);

	if (err)
		return err;

	if (mycs->video_binary.info->sp.enable.block_output) {
		tnr_info = mycs->video_binary.out_frame_info[0];

		/* Make tnr reference buffers output block height align */
		tnr_info.res.height = CEIL_MUL(tnr_info.res.height,
					       mycs->video_binary.info->sp.block.output_block_height);
	} else {
		tnr_info = mycs->video_binary.internal_frame_info;
	}
	tnr_info.format = IA_CSS_FRAME_FORMAT_YUV_LINE;
	tnr_info.raw_bit_depth = SH_CSS_TNR_BIT_DEPTH;

	for (i = 0; i < NUM_VIDEO_TNR_FRAMES; i++) {
		if (mycs->tnr_frames[i]) {
			ia_css_frame_free(mycs->tnr_frames[i]);
			mycs->tnr_frames[i] = NULL;
		}
		err = ia_css_frame_allocate_from_info(
			  &mycs->tnr_frames[i],
			  &tnr_info);
		if (err)
			return err;
	}
	IA_CSS_LEAVE_PRIVATE("");
	return 0;
}
