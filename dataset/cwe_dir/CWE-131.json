[
    {
        "cve_id": "CVE-2019-3560",
        "func_name": "facebookincubator/fizz/PlaintextReadRecordLayer::read",
        "description": "An improperly performed length calculation on a buffer in PlaintextRecordLayer could lead to an infinite loop and denial-of-service based on user input. This issue affected versions of fizz prior to v2019.03.04.00.",
        "git_url": "https://github.com/facebookincubator/fizz/commit/40bbb161e72fb609608d53b9d64c56bb961a6ee2",
        "commit_title": "Avoid arithmetic operation on uint16 read from the wire.",
        "commit_text": " Summary: This could overflow previously.  CVE-2019-3560  Reviewed By: yfeldblum  Differential Revision: D14152362  fbshipit-source-id: c0ebb3fc59b49c7c23e6bcb90458c19cd891be65",
        "func_before": "folly::Optional<TLSMessage> PlaintextReadRecordLayer::read(\n    folly::IOBufQueue& buf) {\n  while (true) {\n    folly::io::Cursor cursor(buf.front());\n\n    if (buf.empty() || !cursor.canAdvance(kPlaintextHeaderSize)) {\n      return folly::none;\n    }\n\n    TLSMessage msg;\n    msg.type = static_cast<ContentType>(cursor.readBE<ContentTypeType>());\n\n    if (skipEncryptedRecords_) {\n      if (msg.type == ContentType::application_data) {\n        cursor.skip(sizeof(ProtocolVersion));\n        auto length = cursor.readBE<uint16_t>();\n        if (buf.chainLength() < (cursor - buf.front()) + length) {\n          return folly::none;\n        }\n        length +=\n            sizeof(ContentType) + sizeof(ProtocolVersion) + sizeof(uint16_t);\n        buf.trimStart(length);\n        continue;\n      } else if (msg.type != ContentType::change_cipher_spec) {\n        skipEncryptedRecords_ = false;\n      }\n    }\n\n    switch (msg.type) {\n      case ContentType::handshake:\n      case ContentType::alert:\n        break;\n      case ContentType::change_cipher_spec:\n        break;\n      default:\n        throw std::runtime_error(folly::to<std::string>(\n            \"received plaintext content type \",\n            static_cast<ContentTypeType>(msg.type),\n            \", header: \",\n            folly::hexlify(buf.splitAtMost(10)->coalesce())));\n    }\n\n    receivedRecordVersion_ =\n        static_cast<ProtocolVersion>(cursor.readBE<ProtocolVersionType>());\n\n    auto length = cursor.readBE<uint16_t>();\n    if (length > kMaxPlaintextRecordSize) {\n      throw std::runtime_error(\"received too long plaintext record\");\n    }\n    if (length == 0) {\n      throw std::runtime_error(\"received empty plaintext record\");\n    }\n    if (buf.chainLength() < (cursor - buf.front()) + length) {\n      return folly::none;\n    }\n\n    cursor.clone(msg.fragment, length);\n\n    buf.trimStart(cursor - buf.front());\n\n    if (msg.type == ContentType::change_cipher_spec) {\n      msg.fragment->coalesce();\n      if (msg.fragment->length() == 1 && *msg.fragment->data() == 0x01) {\n        continue;\n      } else {\n        throw FizzException(\n            \"received ccs\", AlertDescription::illegal_parameter);\n      }\n    }\n\n    return std::move(msg);\n  }\n}",
        "func": "folly::Optional<TLSMessage> PlaintextReadRecordLayer::read(\n    folly::IOBufQueue& buf) {\n  while (true) {\n    folly::io::Cursor cursor(buf.front());\n\n    if (buf.empty() || !cursor.canAdvance(kPlaintextHeaderSize)) {\n      return folly::none;\n    }\n\n    TLSMessage msg;\n    msg.type = static_cast<ContentType>(cursor.readBE<ContentTypeType>());\n\n    if (skipEncryptedRecords_) {\n      if (msg.type == ContentType::application_data) {\n        cursor.skip(sizeof(ProtocolVersion));\n        auto length = cursor.readBE<uint16_t>();\n        if (buf.chainLength() < (cursor - buf.front()) + length) {\n          return folly::none;\n        }\n        buf.trimStart(static_cast<size_t>(kPlaintextHeaderSize) + length);\n        continue;\n      } else if (msg.type != ContentType::change_cipher_spec) {\n        skipEncryptedRecords_ = false;\n      }\n    }\n\n    switch (msg.type) {\n      case ContentType::handshake:\n      case ContentType::alert:\n        break;\n      case ContentType::change_cipher_spec:\n        break;\n      default:\n        throw std::runtime_error(folly::to<std::string>(\n            \"received plaintext content type \",\n            static_cast<ContentTypeType>(msg.type),\n            \", header: \",\n            folly::hexlify(buf.splitAtMost(10)->coalesce())));\n    }\n\n    receivedRecordVersion_ =\n        static_cast<ProtocolVersion>(cursor.readBE<ProtocolVersionType>());\n\n    auto length = cursor.readBE<uint16_t>();\n    if (length > kMaxPlaintextRecordSize) {\n      throw std::runtime_error(\"received too long plaintext record\");\n    }\n    if (length == 0) {\n      throw std::runtime_error(\"received empty plaintext record\");\n    }\n    if (buf.chainLength() < (cursor - buf.front()) + length) {\n      return folly::none;\n    }\n\n    cursor.clone(msg.fragment, length);\n\n    buf.trimStart(cursor - buf.front());\n\n    if (msg.type == ContentType::change_cipher_spec) {\n      msg.fragment->coalesce();\n      if (msg.fragment->length() == 1 && *msg.fragment->data() == 0x01) {\n        continue;\n      } else {\n        throw FizzException(\n            \"received ccs\", AlertDescription::illegal_parameter);\n      }\n    }\n\n    return std::move(msg);\n  }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -17,9 +17,7 @@\n         if (buf.chainLength() < (cursor - buf.front()) + length) {\n           return folly::none;\n         }\n-        length +=\n-            sizeof(ContentType) + sizeof(ProtocolVersion) + sizeof(uint16_t);\n-        buf.trimStart(length);\n+        buf.trimStart(static_cast<size_t>(kPlaintextHeaderSize) + length);\n         continue;\n       } else if (msg.type != ContentType::change_cipher_spec) {\n         skipEncryptedRecords_ = false;",
        "diff_line_info": {
            "deleted_lines": [
                "        length +=",
                "            sizeof(ContentType) + sizeof(ProtocolVersion) + sizeof(uint16_t);",
                "        buf.trimStart(length);"
            ],
            "added_lines": [
                "        buf.trimStart(static_cast<size_t>(kPlaintextHeaderSize) + length);"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-15161",
        "func_name": "the-tcpdump-group/libpcap/daemon_msg_findallif_req",
        "description": "rpcapd/daemon.c in libpcap before 1.9.1 mishandles certain length values because of reuse of a variable. This may open up an attack vector involving extra data at the end of a request.",
        "git_url": "https://github.com/the-tcpdump-group/libpcap/commit/617b12c0339db4891d117b661982126c495439ea",
        "commit_title": "Calculate the reply payload length in a local variable.",
        "commit_text": " Using the same variable for the remaining request length and the reply length is confusing at best and can cause errors at worst (if the request had extra stuff at the end, so that the variable is non-zero).  This addresses Include Security issue I8: [libpcap] Remote Packet Capture Daemon Parameter Reuse.",
        "func_before": "static int\ndaemon_msg_findallif_req(uint8 ver, struct daemon_slpars *pars, uint32 plen)\n{\n\tchar errbuf[PCAP_ERRBUF_SIZE];\t\t// buffer for network errors\n\tchar errmsgbuf[PCAP_ERRBUF_SIZE];\t// buffer for errors to send to the client\n\tchar sendbuf[RPCAP_NETBUF_SIZE];\t// temporary buffer in which data to be sent is buffered\n\tint sendbufidx = 0;\t\t\t// index which keeps the number of bytes currently buffered\n\tpcap_if_t *alldevs = NULL;\t\t// pointer to the header of the interface chain\n\tpcap_if_t *d;\t\t\t\t// temp pointer needed to scan the interface chain\n\tstruct pcap_addr *address;\t\t// pcap structure that keeps a network address of an interface\n\tstruct rpcap_findalldevs_if *findalldevs_if;// rpcap structure that packet all the data of an interface together\n\tuint16 nif = 0;\t\t\t\t// counts the number of interface listed\n\n\t// Discard the rest of the message; there shouldn't be any payload.\n\tif (rpcapd_discard(pars->sockctrl, plen) == -1)\n\t{\n\t\t// Network error.\n\t\treturn -1;\n\t}\n\n\t// Retrieve the device list\n\tif (pcap_findalldevs(&alldevs, errmsgbuf) == -1)\n\t\tgoto error;\n\n\tif (alldevs == NULL)\n\t{\n\t\tif (rpcap_senderror(pars->sockctrl, ver, PCAP_ERR_NOREMOTEIF,\n\t\t\t\"No interfaces found! Make sure libpcap/WinPcap is properly installed\"\n\t\t\t\" and you have the right to access to the remote device.\",\n\t\t\terrbuf) == -1)\n\t\t{\n\t\t\trpcapd_log(LOGPRIO_ERROR, \"Send to client failed: %s\", errbuf);\n\t\t\treturn -1;\n\t\t}\n\t\treturn 0;\n\t}\n\n\t// checks the number of interfaces and it computes the total length of the payload\n\tfor (d = alldevs; d != NULL; d = d->next)\n\t{\n\t\tnif++;\n\n\t\tif (d->description)\n\t\t\tplen+= strlen(d->description);\n\t\tif (d->name)\n\t\t\tplen+= strlen(d->name);\n\n\t\tplen+= sizeof(struct rpcap_findalldevs_if);\n\n\t\tfor (address = d->addresses; address != NULL; address = address->next)\n\t\t{\n\t\t\t/*\n\t\t\t * Send only IPv4 and IPv6 addresses over the wire.\n\t\t\t */\n\t\t\tswitch (address->addr->sa_family)\n\t\t\t{\n\t\t\tcase AF_INET:\n#ifdef AF_INET6\n\t\t\tcase AF_INET6:\n#endif\n\t\t\t\tplen+= (sizeof(struct rpcap_sockaddr) * 4);\n\t\t\t\tbreak;\n\n\t\t\tdefault:\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\t// RPCAP findalldevs command\n\tif (sock_bufferize(NULL, sizeof(struct rpcap_header), NULL,\n\t    &sendbufidx, RPCAP_NETBUF_SIZE, SOCKBUF_CHECKONLY, errmsgbuf,\n\t    PCAP_ERRBUF_SIZE) == -1)\n\t\tgoto error;\n\n\trpcap_createhdr((struct rpcap_header *) sendbuf, ver,\n\t    RPCAP_MSG_FINDALLIF_REPLY, nif, plen);\n\n\t// send the interface list\n\tfor (d = alldevs; d != NULL; d = d->next)\n\t{\n\t\tuint16 lname, ldescr;\n\n\t\tfindalldevs_if = (struct rpcap_findalldevs_if *) &sendbuf[sendbufidx];\n\n\t\tif (sock_bufferize(NULL, sizeof(struct rpcap_findalldevs_if), NULL,\n\t\t    &sendbufidx, RPCAP_NETBUF_SIZE, SOCKBUF_CHECKONLY, errmsgbuf, PCAP_ERRBUF_SIZE) == -1)\n\t\t\tgoto error;\n\n\t\tmemset(findalldevs_if, 0, sizeof(struct rpcap_findalldevs_if));\n\n\t\tif (d->description) ldescr = (short) strlen(d->description);\n\t\telse ldescr = 0;\n\t\tif (d->name) lname = (short) strlen(d->name);\n\t\telse lname = 0;\n\n\t\tfindalldevs_if->desclen = htons(ldescr);\n\t\tfindalldevs_if->namelen = htons(lname);\n\t\tfindalldevs_if->flags = htonl(d->flags);\n\n\t\tfor (address = d->addresses; address != NULL; address = address->next)\n\t\t{\n\t\t\t/*\n\t\t\t * Send only IPv4 and IPv6 addresses over the wire.\n\t\t\t */\n\t\t\tswitch (address->addr->sa_family)\n\t\t\t{\n\t\t\tcase AF_INET:\n#ifdef AF_INET6\n\t\t\tcase AF_INET6:\n#endif\n\t\t\t\tfindalldevs_if->naddr++;\n\t\t\t\tbreak;\n\n\t\t\tdefault:\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tfindalldevs_if->naddr = htons(findalldevs_if->naddr);\n\n\t\tif (sock_bufferize(d->name, lname, sendbuf, &sendbufidx,\n\t\t    RPCAP_NETBUF_SIZE, SOCKBUF_BUFFERIZE, errmsgbuf,\n\t\t    PCAP_ERRBUF_SIZE) == -1)\n\t\t\tgoto error;\n\n\t\tif (sock_bufferize(d->description, ldescr, sendbuf, &sendbufidx,\n\t\t    RPCAP_NETBUF_SIZE, SOCKBUF_BUFFERIZE, errmsgbuf,\n\t\t    PCAP_ERRBUF_SIZE) == -1)\n\t\t\tgoto error;\n\n\t\t// send all addresses\n\t\tfor (address = d->addresses; address != NULL; address = address->next)\n\t\t{\n\t\t\tstruct rpcap_sockaddr *sockaddr;\n\n\t\t\t/*\n\t\t\t * Send only IPv4 and IPv6 addresses over the wire.\n\t\t\t */\n\t\t\tswitch (address->addr->sa_family)\n\t\t\t{\n\t\t\tcase AF_INET:\n#ifdef AF_INET6\n\t\t\tcase AF_INET6:\n#endif\n\t\t\t\tsockaddr = (struct rpcap_sockaddr *) &sendbuf[sendbufidx];\n\t\t\t\tif (sock_bufferize(NULL, sizeof(struct rpcap_sockaddr), NULL,\n\t\t\t\t    &sendbufidx, RPCAP_NETBUF_SIZE, SOCKBUF_CHECKONLY, errmsgbuf, PCAP_ERRBUF_SIZE) == -1)\n\t\t\t\t\tgoto error;\n\t\t\t\tdaemon_seraddr((struct sockaddr_storage *) address->addr, sockaddr);\n\n\t\t\t\tsockaddr = (struct rpcap_sockaddr *) &sendbuf[sendbufidx];\n\t\t\t\tif (sock_bufferize(NULL, sizeof(struct rpcap_sockaddr), NULL,\n\t\t\t\t    &sendbufidx, RPCAP_NETBUF_SIZE, SOCKBUF_CHECKONLY, errmsgbuf, PCAP_ERRBUF_SIZE) == -1)\n\t\t\t\t\tgoto error;\n\t\t\t\tdaemon_seraddr((struct sockaddr_storage *) address->netmask, sockaddr);\n\n\t\t\t\tsockaddr = (struct rpcap_sockaddr *) &sendbuf[sendbufidx];\n\t\t\t\tif (sock_bufferize(NULL, sizeof(struct rpcap_sockaddr), NULL,\n\t\t\t\t    &sendbufidx, RPCAP_NETBUF_SIZE, SOCKBUF_CHECKONLY, errmsgbuf, PCAP_ERRBUF_SIZE) == -1)\n\t\t\t\t\tgoto error;\n\t\t\t\tdaemon_seraddr((struct sockaddr_storage *) address->broadaddr, sockaddr);\n\n\t\t\t\tsockaddr = (struct rpcap_sockaddr *) &sendbuf[sendbufidx];\n\t\t\t\tif (sock_bufferize(NULL, sizeof(struct rpcap_sockaddr), NULL,\n\t\t\t\t    &sendbufidx, RPCAP_NETBUF_SIZE, SOCKBUF_CHECKONLY, errmsgbuf, PCAP_ERRBUF_SIZE) == -1)\n\t\t\t\t\tgoto error;\n\t\t\t\tdaemon_seraddr((struct sockaddr_storage *) address->dstaddr, sockaddr);\n\t\t\t\tbreak;\n\n\t\t\tdefault:\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\t// We no longer need the device list. Free it.\n\tpcap_freealldevs(alldevs);\n\n\t// Send a final command that says \"now send it!\"\n\tif (sock_send(pars->sockctrl, sendbuf, sendbufidx, errbuf, PCAP_ERRBUF_SIZE) == -1)\n\t{\n\t\trpcapd_log(LOGPRIO_ERROR, \"Send to client failed: %s\", errbuf);\n\t\treturn -1;\n\t}\n\n\treturn 0;\n\nerror:\n\tif (alldevs)\n\t\tpcap_freealldevs(alldevs);\n\n\tif (rpcap_senderror(pars->sockctrl, ver, PCAP_ERR_FINDALLIF,\n\t    errmsgbuf, errbuf) == -1)\n\t{\n\t\trpcapd_log(LOGPRIO_ERROR, \"Send to client failed: %s\", errbuf);\n\t\treturn -1;\n\t}\n\treturn 0;\n}",
        "func": "static int\ndaemon_msg_findallif_req(uint8 ver, struct daemon_slpars *pars, uint32 plen)\n{\n\tchar errbuf[PCAP_ERRBUF_SIZE];\t\t// buffer for network errors\n\tchar errmsgbuf[PCAP_ERRBUF_SIZE];\t// buffer for errors to send to the client\n\tchar sendbuf[RPCAP_NETBUF_SIZE];\t// temporary buffer in which data to be sent is buffered\n\tint sendbufidx = 0;\t\t\t// index which keeps the number of bytes currently buffered\n\tpcap_if_t *alldevs = NULL;\t\t// pointer to the header of the interface chain\n\tpcap_if_t *d;\t\t\t\t// temp pointer needed to scan the interface chain\n\tstruct pcap_addr *address;\t\t// pcap structure that keeps a network address of an interface\n\tstruct rpcap_findalldevs_if *findalldevs_if;// rpcap structure that packet all the data of an interface together\n\tuint32 replylen;\t\t\t// length of reply payload\n\tuint16 nif = 0;\t\t\t\t// counts the number of interface listed\n\n\t// Discard the rest of the message; there shouldn't be any payload.\n\tif (rpcapd_discard(pars->sockctrl, plen) == -1)\n\t{\n\t\t// Network error.\n\t\treturn -1;\n\t}\n\n\t// Retrieve the device list\n\tif (pcap_findalldevs(&alldevs, errmsgbuf) == -1)\n\t\tgoto error;\n\n\tif (alldevs == NULL)\n\t{\n\t\tif (rpcap_senderror(pars->sockctrl, ver, PCAP_ERR_NOREMOTEIF,\n\t\t\t\"No interfaces found! Make sure libpcap/WinPcap is properly installed\"\n\t\t\t\" and you have the right to access to the remote device.\",\n\t\t\terrbuf) == -1)\n\t\t{\n\t\t\trpcapd_log(LOGPRIO_ERROR, \"Send to client failed: %s\", errbuf);\n\t\t\treturn -1;\n\t\t}\n\t\treturn 0;\n\t}\n\n\t// This checks the number of interfaces and computes the total\n\t// length of the payload.\n\treplylen = 0;\n\tfor (d = alldevs; d != NULL; d = d->next)\n\t{\n\t\tnif++;\n\n\t\tif (d->description)\n\t\t\treplylen += strlen(d->description);\n\t\tif (d->name)\n\t\t\treplylen += strlen(d->name);\n\n\t\treplylen += sizeof(struct rpcap_findalldevs_if);\n\n\t\tfor (address = d->addresses; address != NULL; address = address->next)\n\t\t{\n\t\t\t/*\n\t\t\t * Send only IPv4 and IPv6 addresses over the wire.\n\t\t\t */\n\t\t\tswitch (address->addr->sa_family)\n\t\t\t{\n\t\t\tcase AF_INET:\n#ifdef AF_INET6\n\t\t\tcase AF_INET6:\n#endif\n\t\t\t\treplylen += (sizeof(struct rpcap_sockaddr) * 4);\n\t\t\t\tbreak;\n\n\t\t\tdefault:\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\t// RPCAP findalldevs command\n\tif (sock_bufferize(NULL, sizeof(struct rpcap_header), NULL,\n\t    &sendbufidx, RPCAP_NETBUF_SIZE, SOCKBUF_CHECKONLY, errmsgbuf,\n\t    PCAP_ERRBUF_SIZE) == -1)\n\t\tgoto error;\n\n\trpcap_createhdr((struct rpcap_header *) sendbuf, ver,\n\t    RPCAP_MSG_FINDALLIF_REPLY, nif, replylen);\n\n\t// send the interface list\n\tfor (d = alldevs; d != NULL; d = d->next)\n\t{\n\t\tuint16 lname, ldescr;\n\n\t\tfindalldevs_if = (struct rpcap_findalldevs_if *) &sendbuf[sendbufidx];\n\n\t\tif (sock_bufferize(NULL, sizeof(struct rpcap_findalldevs_if), NULL,\n\t\t    &sendbufidx, RPCAP_NETBUF_SIZE, SOCKBUF_CHECKONLY, errmsgbuf, PCAP_ERRBUF_SIZE) == -1)\n\t\t\tgoto error;\n\n\t\tmemset(findalldevs_if, 0, sizeof(struct rpcap_findalldevs_if));\n\n\t\tif (d->description) ldescr = (short) strlen(d->description);\n\t\telse ldescr = 0;\n\t\tif (d->name) lname = (short) strlen(d->name);\n\t\telse lname = 0;\n\n\t\tfindalldevs_if->desclen = htons(ldescr);\n\t\tfindalldevs_if->namelen = htons(lname);\n\t\tfindalldevs_if->flags = htonl(d->flags);\n\n\t\tfor (address = d->addresses; address != NULL; address = address->next)\n\t\t{\n\t\t\t/*\n\t\t\t * Send only IPv4 and IPv6 addresses over the wire.\n\t\t\t */\n\t\t\tswitch (address->addr->sa_family)\n\t\t\t{\n\t\t\tcase AF_INET:\n#ifdef AF_INET6\n\t\t\tcase AF_INET6:\n#endif\n\t\t\t\tfindalldevs_if->naddr++;\n\t\t\t\tbreak;\n\n\t\t\tdefault:\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tfindalldevs_if->naddr = htons(findalldevs_if->naddr);\n\n\t\tif (sock_bufferize(d->name, lname, sendbuf, &sendbufidx,\n\t\t    RPCAP_NETBUF_SIZE, SOCKBUF_BUFFERIZE, errmsgbuf,\n\t\t    PCAP_ERRBUF_SIZE) == -1)\n\t\t\tgoto error;\n\n\t\tif (sock_bufferize(d->description, ldescr, sendbuf, &sendbufidx,\n\t\t    RPCAP_NETBUF_SIZE, SOCKBUF_BUFFERIZE, errmsgbuf,\n\t\t    PCAP_ERRBUF_SIZE) == -1)\n\t\t\tgoto error;\n\n\t\t// send all addresses\n\t\tfor (address = d->addresses; address != NULL; address = address->next)\n\t\t{\n\t\t\tstruct rpcap_sockaddr *sockaddr;\n\n\t\t\t/*\n\t\t\t * Send only IPv4 and IPv6 addresses over the wire.\n\t\t\t */\n\t\t\tswitch (address->addr->sa_family)\n\t\t\t{\n\t\t\tcase AF_INET:\n#ifdef AF_INET6\n\t\t\tcase AF_INET6:\n#endif\n\t\t\t\tsockaddr = (struct rpcap_sockaddr *) &sendbuf[sendbufidx];\n\t\t\t\tif (sock_bufferize(NULL, sizeof(struct rpcap_sockaddr), NULL,\n\t\t\t\t    &sendbufidx, RPCAP_NETBUF_SIZE, SOCKBUF_CHECKONLY, errmsgbuf, PCAP_ERRBUF_SIZE) == -1)\n\t\t\t\t\tgoto error;\n\t\t\t\tdaemon_seraddr((struct sockaddr_storage *) address->addr, sockaddr);\n\n\t\t\t\tsockaddr = (struct rpcap_sockaddr *) &sendbuf[sendbufidx];\n\t\t\t\tif (sock_bufferize(NULL, sizeof(struct rpcap_sockaddr), NULL,\n\t\t\t\t    &sendbufidx, RPCAP_NETBUF_SIZE, SOCKBUF_CHECKONLY, errmsgbuf, PCAP_ERRBUF_SIZE) == -1)\n\t\t\t\t\tgoto error;\n\t\t\t\tdaemon_seraddr((struct sockaddr_storage *) address->netmask, sockaddr);\n\n\t\t\t\tsockaddr = (struct rpcap_sockaddr *) &sendbuf[sendbufidx];\n\t\t\t\tif (sock_bufferize(NULL, sizeof(struct rpcap_sockaddr), NULL,\n\t\t\t\t    &sendbufidx, RPCAP_NETBUF_SIZE, SOCKBUF_CHECKONLY, errmsgbuf, PCAP_ERRBUF_SIZE) == -1)\n\t\t\t\t\tgoto error;\n\t\t\t\tdaemon_seraddr((struct sockaddr_storage *) address->broadaddr, sockaddr);\n\n\t\t\t\tsockaddr = (struct rpcap_sockaddr *) &sendbuf[sendbufidx];\n\t\t\t\tif (sock_bufferize(NULL, sizeof(struct rpcap_sockaddr), NULL,\n\t\t\t\t    &sendbufidx, RPCAP_NETBUF_SIZE, SOCKBUF_CHECKONLY, errmsgbuf, PCAP_ERRBUF_SIZE) == -1)\n\t\t\t\t\tgoto error;\n\t\t\t\tdaemon_seraddr((struct sockaddr_storage *) address->dstaddr, sockaddr);\n\t\t\t\tbreak;\n\n\t\t\tdefault:\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\t// We no longer need the device list. Free it.\n\tpcap_freealldevs(alldevs);\n\n\t// Send a final command that says \"now send it!\"\n\tif (sock_send(pars->sockctrl, sendbuf, sendbufidx, errbuf, PCAP_ERRBUF_SIZE) == -1)\n\t{\n\t\trpcapd_log(LOGPRIO_ERROR, \"Send to client failed: %s\", errbuf);\n\t\treturn -1;\n\t}\n\n\treturn 0;\n\nerror:\n\tif (alldevs)\n\t\tpcap_freealldevs(alldevs);\n\n\tif (rpcap_senderror(pars->sockctrl, ver, PCAP_ERR_FINDALLIF,\n\t    errmsgbuf, errbuf) == -1)\n\t{\n\t\trpcapd_log(LOGPRIO_ERROR, \"Send to client failed: %s\", errbuf);\n\t\treturn -1;\n\t}\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -9,6 +9,7 @@\n \tpcap_if_t *d;\t\t\t\t// temp pointer needed to scan the interface chain\n \tstruct pcap_addr *address;\t\t// pcap structure that keeps a network address of an interface\n \tstruct rpcap_findalldevs_if *findalldevs_if;// rpcap structure that packet all the data of an interface together\n+\tuint32 replylen;\t\t\t// length of reply payload\n \tuint16 nif = 0;\t\t\t\t// counts the number of interface listed\n \n \t// Discard the rest of the message; there shouldn't be any payload.\n@@ -35,17 +36,19 @@\n \t\treturn 0;\n \t}\n \n-\t// checks the number of interfaces and it computes the total length of the payload\n+\t// This checks the number of interfaces and computes the total\n+\t// length of the payload.\n+\treplylen = 0;\n \tfor (d = alldevs; d != NULL; d = d->next)\n \t{\n \t\tnif++;\n \n \t\tif (d->description)\n-\t\t\tplen+= strlen(d->description);\n+\t\t\treplylen += strlen(d->description);\n \t\tif (d->name)\n-\t\t\tplen+= strlen(d->name);\n-\n-\t\tplen+= sizeof(struct rpcap_findalldevs_if);\n+\t\t\treplylen += strlen(d->name);\n+\n+\t\treplylen += sizeof(struct rpcap_findalldevs_if);\n \n \t\tfor (address = d->addresses; address != NULL; address = address->next)\n \t\t{\n@@ -58,7 +61,7 @@\n #ifdef AF_INET6\n \t\t\tcase AF_INET6:\n #endif\n-\t\t\t\tplen+= (sizeof(struct rpcap_sockaddr) * 4);\n+\t\t\t\treplylen += (sizeof(struct rpcap_sockaddr) * 4);\n \t\t\t\tbreak;\n \n \t\t\tdefault:\n@@ -74,7 +77,7 @@\n \t\tgoto error;\n \n \trpcap_createhdr((struct rpcap_header *) sendbuf, ver,\n-\t    RPCAP_MSG_FINDALLIF_REPLY, nif, plen);\n+\t    RPCAP_MSG_FINDALLIF_REPLY, nif, replylen);\n \n \t// send the interface list\n \tfor (d = alldevs; d != NULL; d = d->next)",
        "diff_line_info": {
            "deleted_lines": [
                "\t// checks the number of interfaces and it computes the total length of the payload",
                "\t\t\tplen+= strlen(d->description);",
                "\t\t\tplen+= strlen(d->name);",
                "",
                "\t\tplen+= sizeof(struct rpcap_findalldevs_if);",
                "\t\t\t\tplen+= (sizeof(struct rpcap_sockaddr) * 4);",
                "\t    RPCAP_MSG_FINDALLIF_REPLY, nif, plen);"
            ],
            "added_lines": [
                "\tuint32 replylen;\t\t\t// length of reply payload",
                "\t// This checks the number of interfaces and computes the total",
                "\t// length of the payload.",
                "\treplylen = 0;",
                "\t\t\treplylen += strlen(d->description);",
                "\t\t\treplylen += strlen(d->name);",
                "",
                "\t\treplylen += sizeof(struct rpcap_findalldevs_if);",
                "\t\t\t\treplylen += (sizeof(struct rpcap_sockaddr) * 4);",
                "\t    RPCAP_MSG_FINDALLIF_REPLY, nif, replylen);"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-4155",
        "func_name": "torvalds/linux/xfs_ioc_space",
        "description": "A data leak flaw was found in the way XFS_IOC_ALLOCSP IOCTL in the XFS filesystem allowed for size increase of files with unaligned size. A local attacker could use this flaw to leak data on the XFS filesystem otherwise not accessible to them.",
        "git_url": "https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?h=983d8e60f50806f90534cc5373d0ce867e5aaf79",
        "commit_title": "The old ALLOCSP/FREESP ioctls in XFS can be used to preallocate space at",
        "commit_text": "the end of files, just like fallocate and RESVSP.  Make the behavior consistent with the other ioctls.  ",
        "func_before": "int\nxfs_ioc_space(\n\tstruct file\t\t*filp,\n\txfs_flock64_t\t\t*bf)\n{\n\tstruct inode\t\t*inode = file_inode(filp);\n\tstruct xfs_inode\t*ip = XFS_I(inode);\n\tstruct iattr\t\tiattr;\n\tenum xfs_prealloc_flags\tflags = XFS_PREALLOC_CLEAR;\n\tuint\t\t\tiolock = XFS_IOLOCK_EXCL | XFS_MMAPLOCK_EXCL;\n\tint\t\t\terror;\n\n\tif (inode->i_flags & (S_IMMUTABLE|S_APPEND))\n\t\treturn -EPERM;\n\n\tif (!(filp->f_mode & FMODE_WRITE))\n\t\treturn -EBADF;\n\n\tif (!S_ISREG(inode->i_mode))\n\t\treturn -EINVAL;\n\n\tif (xfs_is_always_cow_inode(ip))\n\t\treturn -EOPNOTSUPP;\n\n\tif (filp->f_flags & O_DSYNC)\n\t\tflags |= XFS_PREALLOC_SYNC;\n\tif (filp->f_mode & FMODE_NOCMTIME)\n\t\tflags |= XFS_PREALLOC_INVISIBLE;\n\n\terror = mnt_want_write_file(filp);\n\tif (error)\n\t\treturn error;\n\n\txfs_ilock(ip, iolock);\n\terror = xfs_break_layouts(inode, &iolock, BREAK_UNMAP);\n\tif (error)\n\t\tgoto out_unlock;\n\tinode_dio_wait(inode);\n\n\tswitch (bf->l_whence) {\n\tcase 0: /*SEEK_SET*/\n\t\tbreak;\n\tcase 1: /*SEEK_CUR*/\n\t\tbf->l_start += filp->f_pos;\n\t\tbreak;\n\tcase 2: /*SEEK_END*/\n\t\tbf->l_start += XFS_ISIZE(ip);\n\t\tbreak;\n\tdefault:\n\t\terror = -EINVAL;\n\t\tgoto out_unlock;\n\t}\n\n\tif (bf->l_start < 0 || bf->l_start > inode->i_sb->s_maxbytes) {\n\t\terror = -EINVAL;\n\t\tgoto out_unlock;\n\t}\n\n\tif (bf->l_start > XFS_ISIZE(ip)) {\n\t\terror = xfs_alloc_file_space(ip, XFS_ISIZE(ip),\n\t\t\t\tbf->l_start - XFS_ISIZE(ip), 0);\n\t\tif (error)\n\t\t\tgoto out_unlock;\n\t}\n\n\tiattr.ia_valid = ATTR_SIZE;\n\tiattr.ia_size = bf->l_start;\n\terror = xfs_vn_setattr_size(file_mnt_user_ns(filp), file_dentry(filp),\n\t\t\t\t    &iattr);\n\tif (error)\n\t\tgoto out_unlock;\n\n\terror = xfs_update_prealloc_flags(ip, flags);\n\nout_unlock:\n\txfs_iunlock(ip, iolock);\n\tmnt_drop_write_file(filp);\n\treturn error;\n}",
        "func": "int\nxfs_ioc_space(\n\tstruct file\t\t*filp,\n\txfs_flock64_t\t\t*bf)\n{\n\tstruct inode\t\t*inode = file_inode(filp);\n\tstruct xfs_inode\t*ip = XFS_I(inode);\n\tstruct iattr\t\tiattr;\n\tenum xfs_prealloc_flags\tflags = XFS_PREALLOC_CLEAR;\n\tuint\t\t\tiolock = XFS_IOLOCK_EXCL | XFS_MMAPLOCK_EXCL;\n\tint\t\t\terror;\n\n\tif (inode->i_flags & (S_IMMUTABLE|S_APPEND))\n\t\treturn -EPERM;\n\n\tif (!(filp->f_mode & FMODE_WRITE))\n\t\treturn -EBADF;\n\n\tif (!S_ISREG(inode->i_mode))\n\t\treturn -EINVAL;\n\n\tif (xfs_is_always_cow_inode(ip))\n\t\treturn -EOPNOTSUPP;\n\n\tif (filp->f_flags & O_DSYNC)\n\t\tflags |= XFS_PREALLOC_SYNC;\n\tif (filp->f_mode & FMODE_NOCMTIME)\n\t\tflags |= XFS_PREALLOC_INVISIBLE;\n\n\terror = mnt_want_write_file(filp);\n\tif (error)\n\t\treturn error;\n\n\txfs_ilock(ip, iolock);\n\terror = xfs_break_layouts(inode, &iolock, BREAK_UNMAP);\n\tif (error)\n\t\tgoto out_unlock;\n\tinode_dio_wait(inode);\n\n\tswitch (bf->l_whence) {\n\tcase 0: /*SEEK_SET*/\n\t\tbreak;\n\tcase 1: /*SEEK_CUR*/\n\t\tbf->l_start += filp->f_pos;\n\t\tbreak;\n\tcase 2: /*SEEK_END*/\n\t\tbf->l_start += XFS_ISIZE(ip);\n\t\tbreak;\n\tdefault:\n\t\terror = -EINVAL;\n\t\tgoto out_unlock;\n\t}\n\n\tif (bf->l_start < 0 || bf->l_start > inode->i_sb->s_maxbytes) {\n\t\terror = -EINVAL;\n\t\tgoto out_unlock;\n\t}\n\n\tif (bf->l_start > XFS_ISIZE(ip)) {\n\t\terror = xfs_alloc_file_space(ip, XFS_ISIZE(ip),\n\t\t\t\tbf->l_start - XFS_ISIZE(ip),\n\t\t\t\tXFS_BMAPI_PREALLOC);\n\t\tif (error)\n\t\t\tgoto out_unlock;\n\t}\n\n\tiattr.ia_valid = ATTR_SIZE;\n\tiattr.ia_size = bf->l_start;\n\terror = xfs_vn_setattr_size(file_mnt_user_ns(filp), file_dentry(filp),\n\t\t\t\t    &iattr);\n\tif (error)\n\t\tgoto out_unlock;\n\n\terror = xfs_update_prealloc_flags(ip, flags);\n\nout_unlock:\n\txfs_iunlock(ip, iolock);\n\tmnt_drop_write_file(filp);\n\treturn error;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -58,7 +58,8 @@\n \n \tif (bf->l_start > XFS_ISIZE(ip)) {\n \t\terror = xfs_alloc_file_space(ip, XFS_ISIZE(ip),\n-\t\t\t\tbf->l_start - XFS_ISIZE(ip), 0);\n+\t\t\t\tbf->l_start - XFS_ISIZE(ip),\n+\t\t\t\tXFS_BMAPI_PREALLOC);\n \t\tif (error)\n \t\t\tgoto out_unlock;\n \t}",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\t\tbf->l_start - XFS_ISIZE(ip), 0);"
            ],
            "added_lines": [
                "\t\t\t\tbf->l_start - XFS_ISIZE(ip),",
                "\t\t\t\tXFS_BMAPI_PREALLOC);"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-2953",
        "func_name": "libtiff/process_command_opts",
        "description": "LibTIFF 4.4.0 has an out-of-bounds read in extractImageSection in tools/tiffcrop.c:6905, allowing attackers to cause a denial-of-service via a crafted tiff file. For users that compile libtiff from sources, the fix is available with commit 48d6ece8.",
        "git_url": "https://gitlab.com/libtiff/libtiff/-/commit/8fe3735942ea1d90d8cef843b55b3efe8ab6feaf",
        "commit_title": "According to Richard Nolde https://gitlab.com/libtiff/libtiff/-/issues/401#note_877637400 the tiffcrop option „-S“ is also mutually exclusive to the other crop options (-X|-Y), -Z and -z.",
        "commit_text": " This is now checked and ends tiffcrop if those arguments are not mutually exclusive.  This MR will fix the following tiffcrop issues: #349, #414, #422, #423, #424 ",
        "func_before": "void  process_command_opts (int argc, char *argv[], char *mp, char *mode, uint32_t *dirnum,\n                            uint16_t *defconfig, uint16_t *deffillorder, uint32_t *deftilewidth,\n                            uint32_t *deftilelength, uint32_t *defrowsperstrip,\n                            struct crop_mask *crop_data, struct pagedef *page,\n                            struct dump_opts *dump,\n                            unsigned int     *imagelist, unsigned int   *image_count )\n    {\n    int   c, good_args = 0;\n    char *opt_offset   = NULL;    /* Position in string of value sought */\n    char *opt_ptr      = NULL;    /* Pointer to next token in option set */\n    char *sep          = NULL;    /* Pointer to a token separator */\n    unsigned int  i, j, start, end;\n#if !HAVE_DECL_OPTARG\n    extern int   optind;\n    extern char* optarg;\n#endif\n\n    *mp++ = 'w';\n    *mp = '\\0';\n    while ((c = getopt(argc, argv,\n       \"ac:d:e:f:hik:l:m:p:r:stvw:z:BCD:E:F:H:I:J:K:LMN:O:P:R:S:U:V:X:Y:Z:\")) != -1)\n      {\n    good_args++;\n    switch (c) {\n      case 'a': mode[0] = 'a';\t/* append to output */\n\t\tbreak;\n      case 'c':\tif (!processCompressOptions(optarg)) /* compression scheme */\n\t\t  {\n\t\t  TIFFError (\"Unknown compression option\", \"%s\", optarg);\n                  TIFFError (\"For valid options type\", \"tiffcrop -h\");\n                  exit (EXIT_FAILURE);\n                  }\n\t\tbreak;\n      case 'd':\tstart = strtoul(optarg, NULL, 0); /* initial IFD offset */\n\t        if (start == 0)\n                  {\n\t\t  TIFFError (\"\",\"Directory offset must be greater than zero\");\n\t\t  TIFFError (\"For valid options type\", \"tiffcrop -h\");\n                  exit (EXIT_FAILURE);\n\t\t  }\n\t        *dirnum = start - 1;\n\t\tbreak;\n      case 'e': switch (tolower((int) optarg[0])) /* image export modes*/\n                  {\n\t\t  case 'c': crop_data->exp_mode = ONE_FILE_COMPOSITE;\n \t\t            crop_data->img_mode = COMPOSITE_IMAGES;\n\t\t            break; /* Composite */\n\t\t  case 'd': crop_data->exp_mode = ONE_FILE_SEPARATED;\n \t\t            crop_data->img_mode = SEPARATED_IMAGES;\n\t\t            break; /* Divided */\n\t\t  case 'i': crop_data->exp_mode = FILE_PER_IMAGE_COMPOSITE;\n \t\t            crop_data->img_mode = COMPOSITE_IMAGES;\n\t\t            break; /* Image */\n\t\t  case 'm': crop_data->exp_mode = FILE_PER_IMAGE_SEPARATED;\n \t\t            crop_data->img_mode = SEPARATED_IMAGES;\n\t\t            break; /* Multiple */\n\t\t  case 's': crop_data->exp_mode = FILE_PER_SELECTION;\n \t\t            crop_data->img_mode = SEPARATED_IMAGES;\n\t\t            break; /* Sections */\n\t\t  default:  TIFFError (\"Unknown export mode\",\"%s\", optarg);\n                            TIFFError (\"For valid options type\", \"tiffcrop -h\");\n                            exit (EXIT_FAILURE);\n                  }\n\t        break;\n      case 'f':\tif (streq(optarg, \"lsb2msb\"))\t   /* fill order */\n\t\t  *deffillorder = FILLORDER_LSB2MSB;\n\t\telse if (streq(optarg, \"msb2lsb\"))\n\t\t  *deffillorder = FILLORDER_MSB2LSB;\n\t\telse\n\t\t  {\n\t\t  TIFFError (\"Unknown fill order\", \"%s\", optarg);\n                  TIFFError (\"For valid options type\", \"tiffcrop -h\");\n                  exit (EXIT_FAILURE);\n                  }\n\t\tbreak;\n      case 'h':\tusage(EXIT_SUCCESS);\n\t\tbreak;\n      case 'i':\tignore = TRUE;\t\t/* ignore errors */\n\t\tbreak;\n      case 'k':\tmaxMalloc = (tmsize_t)strtoul(optarg, NULL, 0) << 20;\n\t\tbreak;\n      case 'l':\touttiled = TRUE;\t /* tile length */\n\t\t*deftilelength = atoi(optarg);\n\t\tbreak;\n      case 'p': /* planar configuration */\n\t\tif (streq(optarg, \"separate\"))\n\t\t  *defconfig = PLANARCONFIG_SEPARATE;\n\t\telse if (streq(optarg, \"contig\"))\n\t\t  *defconfig = PLANARCONFIG_CONTIG;\n\t\telse\n\t\t  {\n\t\t  TIFFError (\"Unknown planar configuration\", \"%s\", optarg);\n                  TIFFError (\"For valid options type\", \"tiffcrop -h\");\n                  exit (EXIT_FAILURE);\n                  }\n\t\tbreak;\n      case 'r':\t/* rows/strip */\n\t\t*defrowsperstrip = atol(optarg);\n\t\tbreak;\n      case 's':\t/* generate stripped output */\n\t\touttiled = FALSE;\n\t\tbreak;\n      case 't':\t/* generate tiled output */\n\t\touttiled = TRUE;\n\t\tbreak;\n      case 'v': printf(\"Library Release: %s\\n\", TIFFGetVersion());\n                printf(\"Tiffcrop version: %s, last updated: %s\\n\",\n\t\t\t   tiffcrop_version_id, tiffcrop_rev_date);\n\t        printf(\"Tiffcp code: Copyright (c) 1988-1997 Sam Leffler\\n\");\n\t\tprintf(\"           : Copyright (c) 1991-1997 Silicon Graphics, Inc\\n\");\n                printf(\"Tiffcrop additions: Copyright (c) 2007-2010 Richard Nolde\\n\");\n\t        exit (EXIT_SUCCESS);\n\t\tbreak;\n      case 'w':\t/* tile width */\n\t\touttiled = TRUE;\n\t\t*deftilewidth = atoi(optarg);\n\t\tbreak;\n      case 'z': /* regions of an image specified as x1,y1,x2,y2:x3,y3,x4,y4 etc */\n\t        crop_data->crop_mode |= CROP_REGIONS;\n\t\tfor (i = 0, opt_ptr = strtok (optarg, \":\");\n                   ((opt_ptr != NULL) &&  (i < MAX_REGIONS));\n                    (opt_ptr = strtok (NULL, \":\")), i++)\n                    {\n\t\t    crop_data->regions++;\n                    if (sscanf(opt_ptr, \"%lf,%lf,%lf,%lf\",\n\t\t\t       &crop_data->corners[i].X1, &crop_data->corners[i].Y1,\n\t\t\t       &crop_data->corners[i].X2, &crop_data->corners[i].Y2) != 4)\n                      {\n                      TIFFError (\"Unable to parse coordinates for region\", \"%u %s\", i, optarg);\n\t\t      TIFFError (\"For valid options type\", \"tiffcrop -h\");\n                      exit (EXIT_FAILURE);\n\t\t      }\n                    }\n                /*  check for remaining elements over MAX_REGIONS */\n                if ((opt_ptr != NULL) && (i >= MAX_REGIONS))\n                  {\n\t\t  TIFFError (\"Region list exceeds limit of\", \"%d regions %s\", MAX_REGIONS, optarg);\n\t\t  TIFFError (\"For valid options type\", \"tiffcrop -h\");\n                  exit (EXIT_FAILURE);;\n                  }\n\t\tbreak;\n      /* options for file open modes */\n      case 'B': *mp++ = 'b'; *mp = '\\0';\n\t\tbreak;\n      case 'L': *mp++ = 'l'; *mp = '\\0';\n\t\tbreak;\n      case 'M': *mp++ = 'm'; *mp = '\\0';\n\t\tbreak;\n      case 'C': *mp++ = 'c'; *mp = '\\0';\n\t\tbreak;\n      /* options for Debugging / data dump */\n      case 'D': for (i = 0, opt_ptr = strtok (optarg, \",\");\n                    (opt_ptr != NULL);\n                    (opt_ptr = strtok (NULL, \",\")), i++)\n                    {\n\t\t    opt_offset = strpbrk(opt_ptr, \":=\");\n                    if (opt_offset == NULL)\n                      {\n                      TIFFError(\"Invalid dump option\", \"%s\", optarg);\n                      TIFFError (\"For valid options type\", \"tiffcrop -h\");\n                      exit (EXIT_FAILURE);\n\t\t      }\n                      \n                    *opt_offset = '\\0';\n                    /* convert option to lowercase */\n                    end = strlen (opt_ptr);\n                    for (i = 0; i < end; i++)\n                      *(opt_ptr + i) = tolower((int) *(opt_ptr + i));\n                    /* Look for dump format specification */\n                    if (strncmp(opt_ptr, \"for\", 3) == 0)\n                      {\n\t\t      /* convert value to lowercase */\n                      end = strlen (opt_offset + 1);\n                      for (i = 1; i <= end; i++)\n                        *(opt_offset + i) = tolower((int) *(opt_offset + i));\n                      /* check dump format value */\n\t\t      if (strncmp (opt_offset + 1, \"txt\", 3) == 0)\n                        {\n                        dump->format = DUMP_TEXT;\n                        strcpy (dump->mode, \"w\");\n                        }\n                      else\n                        {\n\t\t        if (strncmp(opt_offset + 1, \"raw\", 3) == 0)\n                          {\n                          dump->format = DUMP_RAW;\n                          strcpy (dump->mode, \"wb\");\n                          }\n                        else\n                          {\n                          TIFFError(\"parse_command_opts\", \"Unknown dump format %s\", opt_offset + 1);\n                          TIFFError (\"For valid options type\", \"tiffcrop -h\");\n                          exit (EXIT_FAILURE);\n\t\t          }\n\t\t\t}\n                      }\n\t\t    else\n                      { /* Look for dump level specification */\n                      if (strncmp (opt_ptr, \"lev\", 3) == 0)\n                        dump->level = atoi(opt_offset + 1);\n                        /* Look for input data dump file name */\n                      if (strncmp (opt_ptr, \"in\", 2) == 0)\n\t\t        {\n                        strncpy (dump->infilename, opt_offset + 1, PATH_MAX - 20);\n                        dump->infilename[PATH_MAX - 20] = '\\0';\n                        }\n                        /* Look for output data dump file name */\n                      if (strncmp (opt_ptr, \"out\", 3) == 0)\n\t\t\t{\n                        strncpy (dump->outfilename, opt_offset + 1, PATH_MAX - 20);\n                        dump->outfilename[PATH_MAX - 20] = '\\0';\n                        }\n                      if (strncmp (opt_ptr, \"deb\", 3) == 0)\n\t\t\tdump->debug = atoi(opt_offset + 1);\n\t\t      }\n                    }\n\t        if ((strlen(dump->infilename)) || (strlen(dump->outfilename)))\n                  {\n\t\t  if (dump->level == 1)\n                    TIFFError(\"\",\"Defaulting to dump level 1, no data.\");\n\t          if (dump->format == DUMP_NONE)\n                    {\n\t\t    TIFFError(\"\", \"You must specify a dump format for dump files\");\n\t\t    TIFFError (\"For valid options type\", \"tiffcrop -h\");\n\t\t    exit (EXIT_FAILURE);\n\t\t    }\n                  }\n\t        break;\n\n      /* image manipulation routine options */\n      case 'm': /* margins to exclude from selection, uppercase M was already used */\n\t\t/* order of values must be TOP, LEFT, BOTTOM, RIGHT */\n\t\tcrop_data->crop_mode |= CROP_MARGINS;\n                for (i = 0, opt_ptr = strtok (optarg, \",:\");\n                    ((opt_ptr != NULL) &&  (i < 4));\n                     (opt_ptr = strtok (NULL, \",:\")), i++)\n                    {\n\t\t    crop_data->margins[i] = atof(opt_ptr);\n                    }\n\t\tbreak;\n      case 'E':\t/* edge reference */\n\t\tswitch (tolower((int) optarg[0]))\n                  {\n\t\t  case 't': crop_data->edge_ref = EDGE_TOP;\n                            break;\n                  case 'b': crop_data->edge_ref = EDGE_BOTTOM;\n                             break;\n                  case 'l': crop_data->edge_ref = EDGE_LEFT;\n                            break;\n                  case 'r': crop_data->edge_ref = EDGE_RIGHT;\n                            break;\n\t\t  default:  TIFFError (\"Edge reference must be top, bottom, left, or right\", \"%s\", optarg);\n\t\t\t    TIFFError (\"For valid options type\", \"tiffcrop -h\");\n                            exit (EXIT_FAILURE);\n\t\t  }\n\t\tbreak;\n      case 'F': /* flip eg mirror image or cropped segment, M was already used */\n\t\tcrop_data->crop_mode |= CROP_MIRROR;\n\t\tswitch (tolower((int) optarg[0]))\n                  {\n\t\t  case  'h': crop_data->mirror = MIRROR_HORIZ;\n                             break;\n                  case  'v': crop_data->mirror = MIRROR_VERT;\n                             break;\n                  case  'b': crop_data->mirror = MIRROR_BOTH;\n                             break;\n\t\t  default:   TIFFError (\"Flip mode must be horiz, vert, or both\", \"%s\", optarg);\n\t\t\t     TIFFError (\"For valid options type\", \"tiffcrop -h\");\n                             exit (EXIT_FAILURE);\n\t\t  }\n\t\tbreak;\n      case 'H': /* set horizontal resolution to new value */\n\t\tpage->hres = atof (optarg);\n                page->mode |= PAGE_MODE_RESOLUTION;\n\t\tbreak;\n      case 'I': /* invert the color space, eg black to white */\n\t\tcrop_data->crop_mode |= CROP_INVERT;\n                /* The PHOTOMETIC_INTERPRETATION tag may be updated */\n                if (streq(optarg, \"black\"))\n                  {\n\t\t  crop_data->photometric = PHOTOMETRIC_MINISBLACK;\n\t\t  continue;\n                  }\n                if (streq(optarg, \"white\"))\n                  {\n\t\t  crop_data->photometric = PHOTOMETRIC_MINISWHITE;\n                  continue;\n                  }\n                if (streq(optarg, \"data\")) \n                  {\n\t\t  crop_data->photometric = INVERT_DATA_ONLY;\n                  continue;\n                  }\n                if (streq(optarg, \"both\"))\n                  {\n\t\t  crop_data->photometric = INVERT_DATA_AND_TAG;\n                  continue;\n                  }\n\n\t\tTIFFError(\"Missing or unknown option for inverting PHOTOMETRIC_INTERPRETATION\", \"%s\", optarg);\n\t\tTIFFError (\"For valid options type\", \"tiffcrop -h\");\n                exit (EXIT_FAILURE);\n\t\tbreak;\n      case 'J': /* horizontal margin for sectioned output pages */\n\t\tpage->hmargin = atof(optarg);\n                page->mode |= PAGE_MODE_MARGINS;\n\t\tbreak;\n      case 'K': /* vertical margin for sectioned output pages*/\n                page->vmargin = atof(optarg);\n                page->mode |= PAGE_MODE_MARGINS;\n\t\tbreak;\n      case 'N':\t/* list of images to process */\n                for (i = 0, opt_ptr = strtok (optarg, \",\");\n                    ((opt_ptr != NULL) &&  (i < MAX_IMAGES));\n                     (opt_ptr = strtok (NULL, \",\")))\n                     { /* We do not know how many images are in file yet \n\t\t\t* so we build a list to include the maximum allowed\n                        * and follow it until we hit the end of the file.\n                        * Image count is not accurate for odd, even, last\n                        * so page numbers won't be valid either.\n                        */\n\t\t     if (streq(opt_ptr, \"odd\"))\n                       {\n\t\t       for (j = 1; j <= MAX_IMAGES; j += 2)\n\t\t\t imagelist[i++] = j;\n                       *image_count = (MAX_IMAGES - 1) / 2;\n                       break;\n\t\t       }\n\t\t     else\n                       {\n\t\t       if (streq(opt_ptr, \"even\"))\n                         {\n\t\t\t for (j = 2; j <= MAX_IMAGES; j += 2)\n\t\t\t   imagelist[i++] = j;\n                         *image_count = MAX_IMAGES / 2;\n                         break;\n\t\t\t }\n\t\t       else\n                         {\n\t\t\t if (streq(opt_ptr, \"last\"))\n\t\t\t   imagelist[i++] = MAX_IMAGES;\n\t\t\t else  /* single value between commas */\n\t\t\t   {\n\t\t\t   sep = strpbrk(opt_ptr, \":-\");\n\t\t\t   if (!sep)\n\t\t\t     imagelist[i++] = atoi(opt_ptr);\n                           else\n                             {\n\t\t\t     *sep = '\\0';\n                             start = atoi (opt_ptr);\n                             if (!strcmp((sep + 1), \"last\"))\n\t\t\t       end = MAX_IMAGES;\n                             else\n                               end = atoi (sep + 1);\n                             for (j = start; j <= end && j - start + i < MAX_IMAGES; j++)\n\t\t\t       imagelist[i++] = j;\n\t\t\t     }\n\t\t\t   }\n\t\t\t }\n\t\t      }\n\t\t    }\n                *image_count = i;\n\t\tbreak;\n      case 'O': /* page orientation */ \n\t\tswitch (tolower((int) optarg[0]))\n                  {\n\t\t  case  'a': page->orient = ORIENTATION_AUTO;\n                             break;\n\t\t  case  'p': page->orient = ORIENTATION_PORTRAIT;\n                             break;\n\t\t  case  'l': page->orient = ORIENTATION_LANDSCAPE;\n                             break;\n\t\t  default:  TIFFError (\"Orientation must be portrait, landscape, or auto.\", \"%s\", optarg);\n\t\t\t    TIFFError (\"For valid options type\", \"tiffcrop -h\");\n                            exit (EXIT_FAILURE);\n\t\t  }\n\t\tbreak;\n      case 'P': /* page size selection */ \n\t        if (sscanf(optarg, \"%lfx%lf\", &page->width, &page->length) == 2)\n                  {\n                  strcpy (page->name, \"Custom\"); \n                  page->mode |= PAGE_MODE_PAPERSIZE;\n                  break;\n                  }\n                if (get_page_geometry (optarg, page))\n                  {\n\t\t  if (!strcmp(optarg, \"list\"))\n                    {\n\t\t    TIFFError(\"\", \"Name            Width   Length (in inches)\");\n                    for (i = 0; i < MAX_PAPERNAMES - 1; i++)\n                      TIFFError (\"\", \"%-15.15s %5.2f   %5.2f\", \n\t\t\t       PaperTable[i].name, PaperTable[i].width, \n                               PaperTable[i].length);\n\t\t    exit (EXIT_FAILURE);\n                    }\n     \n\t\t  TIFFError (\"Invalid paper size\", \"%s\", optarg);\n                  TIFFError (\"\", \"Select one of:\");\n\t\t  TIFFError(\"\", \"Name            Width   Length (in inches)\");\n                  for (i = 0; i < MAX_PAPERNAMES - 1; i++)\n                    TIFFError (\"\", \"%-15.15s %5.2f   %5.2f\", \n\t\t\t       PaperTable[i].name, PaperTable[i].width, \n                               PaperTable[i].length);\n\t\t  exit (EXIT_FAILURE);\n\t\t  }\n\t\telse\n                  {\n                  page->mode |= PAGE_MODE_PAPERSIZE;\n\t\t  }\n\t\tbreak;\n      case 'R': /* rotate image or cropped segment */\n\t\tcrop_data->crop_mode |= CROP_ROTATE;\n\t\tswitch (strtoul(optarg, NULL, 0))\n                  {\n\t\t  case  90:  crop_data->rotation = (uint16_t)90;\n                             break;\n                  case  180: crop_data->rotation = (uint16_t)180;\n                             break;\n                  case  270: crop_data->rotation = (uint16_t)270;\n                             break;\n\t\t  default:   TIFFError (\"Rotation must be 90, 180, or 270 degrees clockwise\", \"%s\", optarg);\n\t\t\t     TIFFError (\"For valid options type\", \"tiffcrop -h\");\n                             exit (EXIT_FAILURE);\n\t\t  }\n\t\tbreak;\n      case 'S':\t/* subdivide into Cols:Rows sections, eg 3:2 would be 3 across and 2 down */\n\t\tsep = strpbrk(optarg, \",:\");\n\t\tif (sep)\n                  {\n                  *sep = '\\0';\n                  page->cols = atoi(optarg);\n                  page->rows = atoi(sep +1);\n\t\t  }\n                else\n                  {\n                  page->cols = atoi(optarg);\n                  page->rows = atoi(optarg);\n\t\t  }\n                if ((page->cols * page->rows) > MAX_SECTIONS)\n                  {\n\t\t  TIFFError (\"Limit for subdivisions, ie rows x columns, exceeded\", \"%d\", MAX_SECTIONS);\n\t\t  exit (EXIT_FAILURE);\n                  }\n                page->mode |= PAGE_MODE_ROWSCOLS;\n\t\tbreak;\n      case 'U':\t/* units for measurements and offsets */\n\t\tif (streq(optarg, \"in\"))\n                  {\n\t\t  crop_data->res_unit = RESUNIT_INCH;\n\t\t  page->res_unit = RESUNIT_INCH;\n\t\t  }\n\t\telse if (streq(optarg, \"cm\"))\n\t\t  {\n\t\t  crop_data->res_unit = RESUNIT_CENTIMETER;\n\t\t  page->res_unit = RESUNIT_CENTIMETER;\n\t\t  }\n\t\telse if (streq(optarg, \"px\"))\n\t\t  {\n\t\t  crop_data->res_unit = RESUNIT_NONE;\n\t\t  page->res_unit = RESUNIT_NONE;\n\t\t  }\n\t\telse\n                  {\n\t\t  TIFFError (\"Illegal unit of measure\",\"%s\", optarg);\n\t\t  TIFFError (\"For valid options type\", \"tiffcrop -h\");\n                  exit (EXIT_FAILURE);\n\t\t  }\n\t\tbreak;\n      case 'V': /* set vertical resolution to new value */\n\t\tpage->vres = atof (optarg);\n                page->mode |= PAGE_MODE_RESOLUTION;\n\t\tbreak;\n      case 'X':\t/* selection width */\n\t\tcrop_data->crop_mode |= CROP_WIDTH;\n\t\tcrop_data->width = atof(optarg);\n\t\tbreak;\n      case 'Y':\t/* selection length */\n\t\tcrop_data->crop_mode |= CROP_LENGTH;\n\t\tcrop_data->length = atof(optarg);\n\t\tbreak;\n      case 'Z': /* zones of an image X:Y read as zone X of Y */\n\t\tcrop_data->crop_mode |= CROP_ZONES;\n\t\tfor (i = 0, opt_ptr = strtok (optarg, \",\");\n                   ((opt_ptr != NULL) &&  (i < MAX_REGIONS));\n                    (opt_ptr = strtok (NULL, \",\")), i++)\n                    {\n\t\t    crop_data->zones++;\n\t\t    opt_offset = strchr(opt_ptr, ':');\n\t\t    if (!opt_offset) {\n\t\t\tTIFFError(\"Wrong parameter syntax for -Z\", \"tiffcrop -h\");\n\t\t\texit(EXIT_FAILURE);\n\t\t    }\n                    *opt_offset = '\\0';\n                    crop_data->zonelist[i].position = atoi(opt_ptr);\n                    crop_data->zonelist[i].total    = atoi(opt_offset + 1);\n                    }\n                /*  check for remaining elements over MAX_REGIONS */\n                if ((opt_ptr != NULL) && (i >= MAX_REGIONS))\n                  {\n\t\t  TIFFError(\"Zone list exceeds region limit\", \"%d\",  MAX_REGIONS);\n\t\t  exit (EXIT_FAILURE);\n                  }\n\t\tbreak;\n    case '?':\tTIFFError (\"For valid options type\", \"tiffcrop -h\");\n                exit (EXIT_FAILURE);\n\t\t/*NOTREACHED*/\n      }\n    }\n    /*-- Check for not allowed combinations (e.g. -X, -Y and -Z and -z are mutually exclusive) --*/\n    char XY, Z, R;\n    XY = ((crop_data->crop_mode & CROP_WIDTH) || (crop_data->crop_mode & CROP_LENGTH));\n    Z = (crop_data->crop_mode & CROP_ZONES);\n    R = (crop_data->crop_mode & CROP_REGIONS);\n    if ((XY && Z) || (XY && R) || (Z && R)) {\n        TIFFError(\"tiffcrop input error\", \"The crop options(-X|-Y), -Z and -z are mutually exclusive.->Exit\");\n        exit(EXIT_FAILURE);\n    }\n  }",
        "func": "void  process_command_opts (int argc, char *argv[], char *mp, char *mode, uint32_t *dirnum,\n                            uint16_t *defconfig, uint16_t *deffillorder, uint32_t *deftilewidth,\n                            uint32_t *deftilelength, uint32_t *defrowsperstrip,\n                            struct crop_mask *crop_data, struct pagedef *page,\n                            struct dump_opts *dump,\n                            unsigned int     *imagelist, unsigned int   *image_count )\n    {\n    int   c, good_args = 0;\n    char *opt_offset   = NULL;    /* Position in string of value sought */\n    char *opt_ptr      = NULL;    /* Pointer to next token in option set */\n    char *sep          = NULL;    /* Pointer to a token separator */\n    unsigned int  i, j, start, end;\n#if !HAVE_DECL_OPTARG\n    extern int   optind;\n    extern char* optarg;\n#endif\n\n    *mp++ = 'w';\n    *mp = '\\0';\n    while ((c = getopt(argc, argv,\n       \"ac:d:e:f:hik:l:m:p:r:stvw:z:BCD:E:F:H:I:J:K:LMN:O:P:R:S:U:V:X:Y:Z:\")) != -1)\n      {\n    good_args++;\n    switch (c) {\n      case 'a': mode[0] = 'a';\t/* append to output */\n\t\tbreak;\n      case 'c':\tif (!processCompressOptions(optarg)) /* compression scheme */\n\t\t  {\n\t\t  TIFFError (\"Unknown compression option\", \"%s\", optarg);\n                  TIFFError (\"For valid options type\", \"tiffcrop -h\");\n                  exit (EXIT_FAILURE);\n                  }\n\t\tbreak;\n      case 'd':\tstart = strtoul(optarg, NULL, 0); /* initial IFD offset */\n\t        if (start == 0)\n                  {\n\t\t  TIFFError (\"\",\"Directory offset must be greater than zero\");\n\t\t  TIFFError (\"For valid options type\", \"tiffcrop -h\");\n                  exit (EXIT_FAILURE);\n\t\t  }\n\t        *dirnum = start - 1;\n\t\tbreak;\n      case 'e': switch (tolower((int) optarg[0])) /* image export modes*/\n                  {\n\t\t  case 'c': crop_data->exp_mode = ONE_FILE_COMPOSITE;\n \t\t            crop_data->img_mode = COMPOSITE_IMAGES;\n\t\t            break; /* Composite */\n\t\t  case 'd': crop_data->exp_mode = ONE_FILE_SEPARATED;\n \t\t            crop_data->img_mode = SEPARATED_IMAGES;\n\t\t            break; /* Divided */\n\t\t  case 'i': crop_data->exp_mode = FILE_PER_IMAGE_COMPOSITE;\n \t\t            crop_data->img_mode = COMPOSITE_IMAGES;\n\t\t            break; /* Image */\n\t\t  case 'm': crop_data->exp_mode = FILE_PER_IMAGE_SEPARATED;\n \t\t            crop_data->img_mode = SEPARATED_IMAGES;\n\t\t            break; /* Multiple */\n\t\t  case 's': crop_data->exp_mode = FILE_PER_SELECTION;\n \t\t            crop_data->img_mode = SEPARATED_IMAGES;\n\t\t            break; /* Sections */\n\t\t  default:  TIFFError (\"Unknown export mode\",\"%s\", optarg);\n                            TIFFError (\"For valid options type\", \"tiffcrop -h\");\n                            exit (EXIT_FAILURE);\n                  }\n\t        break;\n      case 'f':\tif (streq(optarg, \"lsb2msb\"))\t   /* fill order */\n\t\t  *deffillorder = FILLORDER_LSB2MSB;\n\t\telse if (streq(optarg, \"msb2lsb\"))\n\t\t  *deffillorder = FILLORDER_MSB2LSB;\n\t\telse\n\t\t  {\n\t\t  TIFFError (\"Unknown fill order\", \"%s\", optarg);\n                  TIFFError (\"For valid options type\", \"tiffcrop -h\");\n                  exit (EXIT_FAILURE);\n                  }\n\t\tbreak;\n      case 'h':\tusage(EXIT_SUCCESS);\n\t\tbreak;\n      case 'i':\tignore = TRUE;\t\t/* ignore errors */\n\t\tbreak;\n      case 'k':\tmaxMalloc = (tmsize_t)strtoul(optarg, NULL, 0) << 20;\n\t\tbreak;\n      case 'l':\touttiled = TRUE;\t /* tile length */\n\t\t*deftilelength = atoi(optarg);\n\t\tbreak;\n      case 'p': /* planar configuration */\n\t\tif (streq(optarg, \"separate\"))\n\t\t  *defconfig = PLANARCONFIG_SEPARATE;\n\t\telse if (streq(optarg, \"contig\"))\n\t\t  *defconfig = PLANARCONFIG_CONTIG;\n\t\telse\n\t\t  {\n\t\t  TIFFError (\"Unknown planar configuration\", \"%s\", optarg);\n                  TIFFError (\"For valid options type\", \"tiffcrop -h\");\n                  exit (EXIT_FAILURE);\n                  }\n\t\tbreak;\n      case 'r':\t/* rows/strip */\n\t\t*defrowsperstrip = atol(optarg);\n\t\tbreak;\n      case 's':\t/* generate stripped output */\n\t\touttiled = FALSE;\n\t\tbreak;\n      case 't':\t/* generate tiled output */\n\t\touttiled = TRUE;\n\t\tbreak;\n      case 'v': printf(\"Library Release: %s\\n\", TIFFGetVersion());\n                printf(\"Tiffcrop version: %s, last updated: %s\\n\",\n\t\t\t   tiffcrop_version_id, tiffcrop_rev_date);\n\t        printf(\"Tiffcp code: Copyright (c) 1988-1997 Sam Leffler\\n\");\n\t\tprintf(\"           : Copyright (c) 1991-1997 Silicon Graphics, Inc\\n\");\n                printf(\"Tiffcrop additions: Copyright (c) 2007-2010 Richard Nolde\\n\");\n\t        exit (EXIT_SUCCESS);\n\t\tbreak;\n      case 'w':\t/* tile width */\n\t\touttiled = TRUE;\n\t\t*deftilewidth = atoi(optarg);\n\t\tbreak;\n      case 'z': /* regions of an image specified as x1,y1,x2,y2:x3,y3,x4,y4 etc */\n\t        crop_data->crop_mode |= CROP_REGIONS;\n\t\tfor (i = 0, opt_ptr = strtok (optarg, \":\");\n                   ((opt_ptr != NULL) &&  (i < MAX_REGIONS));\n                    (opt_ptr = strtok (NULL, \":\")), i++)\n                    {\n\t\t    crop_data->regions++;\n                    if (sscanf(opt_ptr, \"%lf,%lf,%lf,%lf\",\n\t\t\t       &crop_data->corners[i].X1, &crop_data->corners[i].Y1,\n\t\t\t       &crop_data->corners[i].X2, &crop_data->corners[i].Y2) != 4)\n                      {\n                      TIFFError (\"Unable to parse coordinates for region\", \"%u %s\", i, optarg);\n\t\t      TIFFError (\"For valid options type\", \"tiffcrop -h\");\n                      exit (EXIT_FAILURE);\n\t\t      }\n                    }\n                /*  check for remaining elements over MAX_REGIONS */\n                if ((opt_ptr != NULL) && (i >= MAX_REGIONS))\n                  {\n\t\t  TIFFError (\"Region list exceeds limit of\", \"%d regions %s\", MAX_REGIONS, optarg);\n\t\t  TIFFError (\"For valid options type\", \"tiffcrop -h\");\n                  exit (EXIT_FAILURE);;\n                  }\n\t\tbreak;\n      /* options for file open modes */\n      case 'B': *mp++ = 'b'; *mp = '\\0';\n\t\tbreak;\n      case 'L': *mp++ = 'l'; *mp = '\\0';\n\t\tbreak;\n      case 'M': *mp++ = 'm'; *mp = '\\0';\n\t\tbreak;\n      case 'C': *mp++ = 'c'; *mp = '\\0';\n\t\tbreak;\n      /* options for Debugging / data dump */\n      case 'D': for (i = 0, opt_ptr = strtok (optarg, \",\");\n                    (opt_ptr != NULL);\n                    (opt_ptr = strtok (NULL, \",\")), i++)\n                    {\n\t\t    opt_offset = strpbrk(opt_ptr, \":=\");\n                    if (opt_offset == NULL)\n                      {\n                      TIFFError(\"Invalid dump option\", \"%s\", optarg);\n                      TIFFError (\"For valid options type\", \"tiffcrop -h\");\n                      exit (EXIT_FAILURE);\n\t\t      }\n                      \n                    *opt_offset = '\\0';\n                    /* convert option to lowercase */\n                    end = strlen (opt_ptr);\n                    for (i = 0; i < end; i++)\n                      *(opt_ptr + i) = tolower((int) *(opt_ptr + i));\n                    /* Look for dump format specification */\n                    if (strncmp(opt_ptr, \"for\", 3) == 0)\n                      {\n\t\t      /* convert value to lowercase */\n                      end = strlen (opt_offset + 1);\n                      for (i = 1; i <= end; i++)\n                        *(opt_offset + i) = tolower((int) *(opt_offset + i));\n                      /* check dump format value */\n\t\t      if (strncmp (opt_offset + 1, \"txt\", 3) == 0)\n                        {\n                        dump->format = DUMP_TEXT;\n                        strcpy (dump->mode, \"w\");\n                        }\n                      else\n                        {\n\t\t        if (strncmp(opt_offset + 1, \"raw\", 3) == 0)\n                          {\n                          dump->format = DUMP_RAW;\n                          strcpy (dump->mode, \"wb\");\n                          }\n                        else\n                          {\n                          TIFFError(\"parse_command_opts\", \"Unknown dump format %s\", opt_offset + 1);\n                          TIFFError (\"For valid options type\", \"tiffcrop -h\");\n                          exit (EXIT_FAILURE);\n\t\t          }\n\t\t\t}\n                      }\n\t\t    else\n                      { /* Look for dump level specification */\n                      if (strncmp (opt_ptr, \"lev\", 3) == 0)\n                        dump->level = atoi(opt_offset + 1);\n                        /* Look for input data dump file name */\n                      if (strncmp (opt_ptr, \"in\", 2) == 0)\n\t\t        {\n                        strncpy (dump->infilename, opt_offset + 1, PATH_MAX - 20);\n                        dump->infilename[PATH_MAX - 20] = '\\0';\n                        }\n                        /* Look for output data dump file name */\n                      if (strncmp (opt_ptr, \"out\", 3) == 0)\n\t\t\t{\n                        strncpy (dump->outfilename, opt_offset + 1, PATH_MAX - 20);\n                        dump->outfilename[PATH_MAX - 20] = '\\0';\n                        }\n                      if (strncmp (opt_ptr, \"deb\", 3) == 0)\n\t\t\tdump->debug = atoi(opt_offset + 1);\n\t\t      }\n                    }\n\t        if ((strlen(dump->infilename)) || (strlen(dump->outfilename)))\n                  {\n\t\t  if (dump->level == 1)\n                    TIFFError(\"\",\"Defaulting to dump level 1, no data.\");\n\t          if (dump->format == DUMP_NONE)\n                    {\n\t\t    TIFFError(\"\", \"You must specify a dump format for dump files\");\n\t\t    TIFFError (\"For valid options type\", \"tiffcrop -h\");\n\t\t    exit (EXIT_FAILURE);\n\t\t    }\n                  }\n\t        break;\n\n      /* image manipulation routine options */\n      case 'm': /* margins to exclude from selection, uppercase M was already used */\n\t\t/* order of values must be TOP, LEFT, BOTTOM, RIGHT */\n\t\tcrop_data->crop_mode |= CROP_MARGINS;\n                for (i = 0, opt_ptr = strtok (optarg, \",:\");\n                    ((opt_ptr != NULL) &&  (i < 4));\n                     (opt_ptr = strtok (NULL, \",:\")), i++)\n                    {\n\t\t    crop_data->margins[i] = atof(opt_ptr);\n                    }\n\t\tbreak;\n      case 'E':\t/* edge reference */\n\t\tswitch (tolower((int) optarg[0]))\n                  {\n\t\t  case 't': crop_data->edge_ref = EDGE_TOP;\n                            break;\n                  case 'b': crop_data->edge_ref = EDGE_BOTTOM;\n                             break;\n                  case 'l': crop_data->edge_ref = EDGE_LEFT;\n                            break;\n                  case 'r': crop_data->edge_ref = EDGE_RIGHT;\n                            break;\n\t\t  default:  TIFFError (\"Edge reference must be top, bottom, left, or right\", \"%s\", optarg);\n\t\t\t    TIFFError (\"For valid options type\", \"tiffcrop -h\");\n                            exit (EXIT_FAILURE);\n\t\t  }\n\t\tbreak;\n      case 'F': /* flip eg mirror image or cropped segment, M was already used */\n\t\tcrop_data->crop_mode |= CROP_MIRROR;\n\t\tswitch (tolower((int) optarg[0]))\n                  {\n\t\t  case  'h': crop_data->mirror = MIRROR_HORIZ;\n                             break;\n                  case  'v': crop_data->mirror = MIRROR_VERT;\n                             break;\n                  case  'b': crop_data->mirror = MIRROR_BOTH;\n                             break;\n\t\t  default:   TIFFError (\"Flip mode must be horiz, vert, or both\", \"%s\", optarg);\n\t\t\t     TIFFError (\"For valid options type\", \"tiffcrop -h\");\n                             exit (EXIT_FAILURE);\n\t\t  }\n\t\tbreak;\n      case 'H': /* set horizontal resolution to new value */\n\t\tpage->hres = atof (optarg);\n                page->mode |= PAGE_MODE_RESOLUTION;\n\t\tbreak;\n      case 'I': /* invert the color space, eg black to white */\n\t\tcrop_data->crop_mode |= CROP_INVERT;\n                /* The PHOTOMETIC_INTERPRETATION tag may be updated */\n                if (streq(optarg, \"black\"))\n                  {\n\t\t  crop_data->photometric = PHOTOMETRIC_MINISBLACK;\n\t\t  continue;\n                  }\n                if (streq(optarg, \"white\"))\n                  {\n\t\t  crop_data->photometric = PHOTOMETRIC_MINISWHITE;\n                  continue;\n                  }\n                if (streq(optarg, \"data\")) \n                  {\n\t\t  crop_data->photometric = INVERT_DATA_ONLY;\n                  continue;\n                  }\n                if (streq(optarg, \"both\"))\n                  {\n\t\t  crop_data->photometric = INVERT_DATA_AND_TAG;\n                  continue;\n                  }\n\n\t\tTIFFError(\"Missing or unknown option for inverting PHOTOMETRIC_INTERPRETATION\", \"%s\", optarg);\n\t\tTIFFError (\"For valid options type\", \"tiffcrop -h\");\n                exit (EXIT_FAILURE);\n\t\tbreak;\n      case 'J': /* horizontal margin for sectioned output pages */\n\t\tpage->hmargin = atof(optarg);\n                page->mode |= PAGE_MODE_MARGINS;\n\t\tbreak;\n      case 'K': /* vertical margin for sectioned output pages*/\n                page->vmargin = atof(optarg);\n                page->mode |= PAGE_MODE_MARGINS;\n\t\tbreak;\n      case 'N':\t/* list of images to process */\n                for (i = 0, opt_ptr = strtok (optarg, \",\");\n                    ((opt_ptr != NULL) &&  (i < MAX_IMAGES));\n                     (opt_ptr = strtok (NULL, \",\")))\n                     { /* We do not know how many images are in file yet \n\t\t\t* so we build a list to include the maximum allowed\n                        * and follow it until we hit the end of the file.\n                        * Image count is not accurate for odd, even, last\n                        * so page numbers won't be valid either.\n                        */\n\t\t     if (streq(opt_ptr, \"odd\"))\n                       {\n\t\t       for (j = 1; j <= MAX_IMAGES; j += 2)\n\t\t\t imagelist[i++] = j;\n                       *image_count = (MAX_IMAGES - 1) / 2;\n                       break;\n\t\t       }\n\t\t     else\n                       {\n\t\t       if (streq(opt_ptr, \"even\"))\n                         {\n\t\t\t for (j = 2; j <= MAX_IMAGES; j += 2)\n\t\t\t   imagelist[i++] = j;\n                         *image_count = MAX_IMAGES / 2;\n                         break;\n\t\t\t }\n\t\t       else\n                         {\n\t\t\t if (streq(opt_ptr, \"last\"))\n\t\t\t   imagelist[i++] = MAX_IMAGES;\n\t\t\t else  /* single value between commas */\n\t\t\t   {\n\t\t\t   sep = strpbrk(opt_ptr, \":-\");\n\t\t\t   if (!sep)\n\t\t\t     imagelist[i++] = atoi(opt_ptr);\n                           else\n                             {\n\t\t\t     *sep = '\\0';\n                             start = atoi (opt_ptr);\n                             if (!strcmp((sep + 1), \"last\"))\n\t\t\t       end = MAX_IMAGES;\n                             else\n                               end = atoi (sep + 1);\n                             for (j = start; j <= end && j - start + i < MAX_IMAGES; j++)\n\t\t\t       imagelist[i++] = j;\n\t\t\t     }\n\t\t\t   }\n\t\t\t }\n\t\t      }\n\t\t    }\n                *image_count = i;\n\t\tbreak;\n      case 'O': /* page orientation */ \n\t\tswitch (tolower((int) optarg[0]))\n                  {\n\t\t  case  'a': page->orient = ORIENTATION_AUTO;\n                             break;\n\t\t  case  'p': page->orient = ORIENTATION_PORTRAIT;\n                             break;\n\t\t  case  'l': page->orient = ORIENTATION_LANDSCAPE;\n                             break;\n\t\t  default:  TIFFError (\"Orientation must be portrait, landscape, or auto.\", \"%s\", optarg);\n\t\t\t    TIFFError (\"For valid options type\", \"tiffcrop -h\");\n                            exit (EXIT_FAILURE);\n\t\t  }\n\t\tbreak;\n      case 'P': /* page size selection */ \n\t        if (sscanf(optarg, \"%lfx%lf\", &page->width, &page->length) == 2)\n                  {\n                  strcpy (page->name, \"Custom\"); \n                  page->mode |= PAGE_MODE_PAPERSIZE;\n                  break;\n                  }\n                if (get_page_geometry (optarg, page))\n                  {\n\t\t  if (!strcmp(optarg, \"list\"))\n                    {\n\t\t    TIFFError(\"\", \"Name            Width   Length (in inches)\");\n                    for (i = 0; i < MAX_PAPERNAMES - 1; i++)\n                      TIFFError (\"\", \"%-15.15s %5.2f   %5.2f\", \n\t\t\t       PaperTable[i].name, PaperTable[i].width, \n                               PaperTable[i].length);\n\t\t    exit (EXIT_FAILURE);\n                    }\n     \n\t\t  TIFFError (\"Invalid paper size\", \"%s\", optarg);\n                  TIFFError (\"\", \"Select one of:\");\n\t\t  TIFFError(\"\", \"Name            Width   Length (in inches)\");\n                  for (i = 0; i < MAX_PAPERNAMES - 1; i++)\n                    TIFFError (\"\", \"%-15.15s %5.2f   %5.2f\", \n\t\t\t       PaperTable[i].name, PaperTable[i].width, \n                               PaperTable[i].length);\n\t\t  exit (EXIT_FAILURE);\n\t\t  }\n\t\telse\n                  {\n                  page->mode |= PAGE_MODE_PAPERSIZE;\n\t\t  }\n\t\tbreak;\n      case 'R': /* rotate image or cropped segment */\n\t\tcrop_data->crop_mode |= CROP_ROTATE;\n\t\tswitch (strtoul(optarg, NULL, 0))\n                  {\n\t\t  case  90:  crop_data->rotation = (uint16_t)90;\n                             break;\n                  case  180: crop_data->rotation = (uint16_t)180;\n                             break;\n                  case  270: crop_data->rotation = (uint16_t)270;\n                             break;\n\t\t  default:   TIFFError (\"Rotation must be 90, 180, or 270 degrees clockwise\", \"%s\", optarg);\n\t\t\t     TIFFError (\"For valid options type\", \"tiffcrop -h\");\n                             exit (EXIT_FAILURE);\n\t\t  }\n\t\tbreak;\n      case 'S':\t/* subdivide into Cols:Rows sections, eg 3:2 would be 3 across and 2 down */\n\t\tsep = strpbrk(optarg, \",:\");\n\t\tif (sep)\n                  {\n                  *sep = '\\0';\n                  page->cols = atoi(optarg);\n                  page->rows = atoi(sep +1);\n\t\t  }\n                else\n                  {\n                  page->cols = atoi(optarg);\n                  page->rows = atoi(optarg);\n\t\t  }\n                if ((page->cols * page->rows) > MAX_SECTIONS)\n                  {\n\t\t  TIFFError (\"Limit for subdivisions, ie rows x columns, exceeded\", \"%d\", MAX_SECTIONS);\n\t\t  exit (EXIT_FAILURE);\n                  }\n                page->mode |= PAGE_MODE_ROWSCOLS;\n\t\tbreak;\n      case 'U':\t/* units for measurements and offsets */\n\t\tif (streq(optarg, \"in\"))\n                  {\n\t\t  crop_data->res_unit = RESUNIT_INCH;\n\t\t  page->res_unit = RESUNIT_INCH;\n\t\t  }\n\t\telse if (streq(optarg, \"cm\"))\n\t\t  {\n\t\t  crop_data->res_unit = RESUNIT_CENTIMETER;\n\t\t  page->res_unit = RESUNIT_CENTIMETER;\n\t\t  }\n\t\telse if (streq(optarg, \"px\"))\n\t\t  {\n\t\t  crop_data->res_unit = RESUNIT_NONE;\n\t\t  page->res_unit = RESUNIT_NONE;\n\t\t  }\n\t\telse\n                  {\n\t\t  TIFFError (\"Illegal unit of measure\",\"%s\", optarg);\n\t\t  TIFFError (\"For valid options type\", \"tiffcrop -h\");\n                  exit (EXIT_FAILURE);\n\t\t  }\n\t\tbreak;\n      case 'V': /* set vertical resolution to new value */\n\t\tpage->vres = atof (optarg);\n                page->mode |= PAGE_MODE_RESOLUTION;\n\t\tbreak;\n      case 'X':\t/* selection width */\n\t\tcrop_data->crop_mode |= CROP_WIDTH;\n\t\tcrop_data->width = atof(optarg);\n\t\tbreak;\n      case 'Y':\t/* selection length */\n\t\tcrop_data->crop_mode |= CROP_LENGTH;\n\t\tcrop_data->length = atof(optarg);\n\t\tbreak;\n      case 'Z': /* zones of an image X:Y read as zone X of Y */\n\t\tcrop_data->crop_mode |= CROP_ZONES;\n\t\tfor (i = 0, opt_ptr = strtok (optarg, \",\");\n                   ((opt_ptr != NULL) &&  (i < MAX_REGIONS));\n                    (opt_ptr = strtok (NULL, \",\")), i++)\n                    {\n\t\t    crop_data->zones++;\n\t\t    opt_offset = strchr(opt_ptr, ':');\n\t\t    if (!opt_offset) {\n\t\t\tTIFFError(\"Wrong parameter syntax for -Z\", \"tiffcrop -h\");\n\t\t\texit(EXIT_FAILURE);\n\t\t    }\n                    *opt_offset = '\\0';\n                    crop_data->zonelist[i].position = atoi(opt_ptr);\n                    crop_data->zonelist[i].total    = atoi(opt_offset + 1);\n                    }\n                /*  check for remaining elements over MAX_REGIONS */\n                if ((opt_ptr != NULL) && (i >= MAX_REGIONS))\n                  {\n\t\t  TIFFError(\"Zone list exceeds region limit\", \"%d\",  MAX_REGIONS);\n\t\t  exit (EXIT_FAILURE);\n                  }\n\t\tbreak;\n    case '?':\tTIFFError (\"For valid options type\", \"tiffcrop -h\");\n                exit (EXIT_FAILURE);\n\t\t/*NOTREACHED*/\n      }\n    }\n    /*-- Check for not allowed combinations (e.g. -X, -Y and -Z, -z and -S are mutually exclusive) --*/\n    char XY, Z, R, S;\n    XY = ((crop_data->crop_mode & CROP_WIDTH) || (crop_data->crop_mode & CROP_LENGTH));\n    Z = (crop_data->crop_mode & CROP_ZONES);\n    R = (crop_data->crop_mode & CROP_REGIONS);\n    S = (page->mode & PAGE_MODE_ROWSCOLS);\n    if ((XY && Z) || (XY && R) || (XY && S) || (Z && R) || (Z && S) || (R && S)) {\n        TIFFError(\"tiffcrop input error\", \"The crop options(-X|-Y), -Z, -z and -S are mutually exclusive.->Exit\");\n        exit(EXIT_FAILURE);\n    }\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -506,13 +506,14 @@\n \t\t/*NOTREACHED*/\n       }\n     }\n-    /*-- Check for not allowed combinations (e.g. -X, -Y and -Z and -z are mutually exclusive) --*/\n-    char XY, Z, R;\n+    /*-- Check for not allowed combinations (e.g. -X, -Y and -Z, -z and -S are mutually exclusive) --*/\n+    char XY, Z, R, S;\n     XY = ((crop_data->crop_mode & CROP_WIDTH) || (crop_data->crop_mode & CROP_LENGTH));\n     Z = (crop_data->crop_mode & CROP_ZONES);\n     R = (crop_data->crop_mode & CROP_REGIONS);\n-    if ((XY && Z) || (XY && R) || (Z && R)) {\n-        TIFFError(\"tiffcrop input error\", \"The crop options(-X|-Y), -Z and -z are mutually exclusive.->Exit\");\n+    S = (page->mode & PAGE_MODE_ROWSCOLS);\n+    if ((XY && Z) || (XY && R) || (XY && S) || (Z && R) || (Z && S) || (R && S)) {\n+        TIFFError(\"tiffcrop input error\", \"The crop options(-X|-Y), -Z, -z and -S are mutually exclusive.->Exit\");\n         exit(EXIT_FAILURE);\n     }\n   }",
        "diff_line_info": {
            "deleted_lines": [
                "    /*-- Check for not allowed combinations (e.g. -X, -Y and -Z and -z are mutually exclusive) --*/",
                "    char XY, Z, R;",
                "    if ((XY && Z) || (XY && R) || (Z && R)) {",
                "        TIFFError(\"tiffcrop input error\", \"The crop options(-X|-Y), -Z and -z are mutually exclusive.->Exit\");"
            ],
            "added_lines": [
                "    /*-- Check for not allowed combinations (e.g. -X, -Y and -Z, -z and -S are mutually exclusive) --*/",
                "    char XY, Z, R, S;",
                "    S = (page->mode & PAGE_MODE_ROWSCOLS);",
                "    if ((XY && Z) || (XY && R) || (XY && S) || (Z && R) || (Z && S) || (R && S)) {",
                "        TIFFError(\"tiffcrop input error\", \"The crop options(-X|-Y), -Z, -z and -S are mutually exclusive.->Exit\");"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-2953",
        "func_name": "libtiff/process_command_opts",
        "description": "LibTIFF 4.4.0 has an out-of-bounds read in extractImageSection in tools/tiffcrop.c:6905, allowing attackers to cause a denial-of-service via a crafted tiff file. For users that compile libtiff from sources, the fix is available with commit 48d6ece8.",
        "git_url": "https://gitlab.com/libtiff/libtiff/-/commit/bad48e90b410df32172006c7876da449ba62cdba",
        "commit_title": "tiffcrop -S option: Make decision simpler.",
        "commit_text": "",
        "func_before": "void  process_command_opts (int argc, char *argv[], char *mp, char *mode, uint32_t *dirnum,\n                            uint16_t *defconfig, uint16_t *deffillorder, uint32_t *deftilewidth,\n                            uint32_t *deftilelength, uint32_t *defrowsperstrip,\n                            struct crop_mask *crop_data, struct pagedef *page,\n                            struct dump_opts *dump,\n                            unsigned int     *imagelist, unsigned int   *image_count )\n    {\n    int   c, good_args = 0;\n    char *opt_offset   = NULL;    /* Position in string of value sought */\n    char *opt_ptr      = NULL;    /* Pointer to next token in option set */\n    char *sep          = NULL;    /* Pointer to a token separator */\n    unsigned int  i, j, start, end;\n#if !HAVE_DECL_OPTARG\n    extern int   optind;\n    extern char* optarg;\n#endif\n\n    *mp++ = 'w';\n    *mp = '\\0';\n    while ((c = getopt(argc, argv,\n       \"ac:d:e:f:hik:l:m:p:r:stvw:z:BCD:E:F:H:I:J:K:LMN:O:P:R:S:U:V:X:Y:Z:\")) != -1)\n      {\n    good_args++;\n    switch (c) {\n      case 'a': mode[0] = 'a';\t/* append to output */\n\t\tbreak;\n      case 'c':\tif (!processCompressOptions(optarg)) /* compression scheme */\n\t\t  {\n\t\t  TIFFError (\"Unknown compression option\", \"%s\", optarg);\n                  TIFFError (\"For valid options type\", \"tiffcrop -h\");\n                  exit (EXIT_FAILURE);\n                  }\n\t\tbreak;\n      case 'd':\tstart = strtoul(optarg, NULL, 0); /* initial IFD offset */\n\t        if (start == 0)\n                  {\n\t\t  TIFFError (\"\",\"Directory offset must be greater than zero\");\n\t\t  TIFFError (\"For valid options type\", \"tiffcrop -h\");\n                  exit (EXIT_FAILURE);\n\t\t  }\n\t        *dirnum = start - 1;\n\t\tbreak;\n      case 'e': switch (tolower((int) optarg[0])) /* image export modes*/\n                  {\n\t\t  case 'c': crop_data->exp_mode = ONE_FILE_COMPOSITE;\n \t\t            crop_data->img_mode = COMPOSITE_IMAGES;\n\t\t            break; /* Composite */\n\t\t  case 'd': crop_data->exp_mode = ONE_FILE_SEPARATED;\n \t\t            crop_data->img_mode = SEPARATED_IMAGES;\n\t\t            break; /* Divided */\n\t\t  case 'i': crop_data->exp_mode = FILE_PER_IMAGE_COMPOSITE;\n \t\t            crop_data->img_mode = COMPOSITE_IMAGES;\n\t\t            break; /* Image */\n\t\t  case 'm': crop_data->exp_mode = FILE_PER_IMAGE_SEPARATED;\n \t\t            crop_data->img_mode = SEPARATED_IMAGES;\n\t\t            break; /* Multiple */\n\t\t  case 's': crop_data->exp_mode = FILE_PER_SELECTION;\n \t\t            crop_data->img_mode = SEPARATED_IMAGES;\n\t\t            break; /* Sections */\n\t\t  default:  TIFFError (\"Unknown export mode\",\"%s\", optarg);\n                            TIFFError (\"For valid options type\", \"tiffcrop -h\");\n                            exit (EXIT_FAILURE);\n                  }\n\t        break;\n      case 'f':\tif (streq(optarg, \"lsb2msb\"))\t   /* fill order */\n\t\t  *deffillorder = FILLORDER_LSB2MSB;\n\t\telse if (streq(optarg, \"msb2lsb\"))\n\t\t  *deffillorder = FILLORDER_MSB2LSB;\n\t\telse\n\t\t  {\n\t\t  TIFFError (\"Unknown fill order\", \"%s\", optarg);\n                  TIFFError (\"For valid options type\", \"tiffcrop -h\");\n                  exit (EXIT_FAILURE);\n                  }\n\t\tbreak;\n      case 'h':\tusage(EXIT_SUCCESS);\n\t\tbreak;\n      case 'i':\tignore = TRUE;\t\t/* ignore errors */\n\t\tbreak;\n      case 'k':\tmaxMalloc = (tmsize_t)strtoul(optarg, NULL, 0) << 20;\n\t\tbreak;\n      case 'l':\touttiled = TRUE;\t /* tile length */\n\t\t*deftilelength = atoi(optarg);\n\t\tbreak;\n      case 'p': /* planar configuration */\n\t\tif (streq(optarg, \"separate\"))\n\t\t  *defconfig = PLANARCONFIG_SEPARATE;\n\t\telse if (streq(optarg, \"contig\"))\n\t\t  *defconfig = PLANARCONFIG_CONTIG;\n\t\telse\n\t\t  {\n\t\t  TIFFError (\"Unknown planar configuration\", \"%s\", optarg);\n                  TIFFError (\"For valid options type\", \"tiffcrop -h\");\n                  exit (EXIT_FAILURE);\n                  }\n\t\tbreak;\n      case 'r':\t/* rows/strip */\n\t\t*defrowsperstrip = atol(optarg);\n\t\tbreak;\n      case 's':\t/* generate stripped output */\n\t\touttiled = FALSE;\n\t\tbreak;\n      case 't':\t/* generate tiled output */\n\t\touttiled = TRUE;\n\t\tbreak;\n      case 'v': printf(\"Library Release: %s\\n\", TIFFGetVersion());\n                printf(\"Tiffcrop version: %s, last updated: %s\\n\",\n\t\t\t   tiffcrop_version_id, tiffcrop_rev_date);\n\t        printf(\"Tiffcp code: Copyright (c) 1988-1997 Sam Leffler\\n\");\n\t\tprintf(\"           : Copyright (c) 1991-1997 Silicon Graphics, Inc\\n\");\n                printf(\"Tiffcrop additions: Copyright (c) 2007-2010 Richard Nolde\\n\");\n\t        exit (EXIT_SUCCESS);\n\t\tbreak;\n      case 'w':\t/* tile width */\n\t\touttiled = TRUE;\n\t\t*deftilewidth = atoi(optarg);\n\t\tbreak;\n      case 'z': /* regions of an image specified as x1,y1,x2,y2:x3,y3,x4,y4 etc */\n\t        crop_data->crop_mode |= CROP_REGIONS;\n\t\tfor (i = 0, opt_ptr = strtok (optarg, \":\");\n                   ((opt_ptr != NULL) &&  (i < MAX_REGIONS));\n                    (opt_ptr = strtok (NULL, \":\")), i++)\n                    {\n\t\t    crop_data->regions++;\n                    if (sscanf(opt_ptr, \"%lf,%lf,%lf,%lf\",\n\t\t\t       &crop_data->corners[i].X1, &crop_data->corners[i].Y1,\n\t\t\t       &crop_data->corners[i].X2, &crop_data->corners[i].Y2) != 4)\n                      {\n                      TIFFError (\"Unable to parse coordinates for region\", \"%u %s\", i, optarg);\n\t\t      TIFFError (\"For valid options type\", \"tiffcrop -h\");\n                      exit (EXIT_FAILURE);\n\t\t      }\n                    }\n                /*  check for remaining elements over MAX_REGIONS */\n                if ((opt_ptr != NULL) && (i >= MAX_REGIONS))\n                  {\n\t\t  TIFFError (\"Region list exceeds limit of\", \"%d regions %s\", MAX_REGIONS, optarg);\n\t\t  TIFFError (\"For valid options type\", \"tiffcrop -h\");\n                  exit (EXIT_FAILURE);;\n                  }\n\t\tbreak;\n      /* options for file open modes */\n      case 'B': *mp++ = 'b'; *mp = '\\0';\n\t\tbreak;\n      case 'L': *mp++ = 'l'; *mp = '\\0';\n\t\tbreak;\n      case 'M': *mp++ = 'm'; *mp = '\\0';\n\t\tbreak;\n      case 'C': *mp++ = 'c'; *mp = '\\0';\n\t\tbreak;\n      /* options for Debugging / data dump */\n      case 'D': for (i = 0, opt_ptr = strtok (optarg, \",\");\n                    (opt_ptr != NULL);\n                    (opt_ptr = strtok (NULL, \",\")), i++)\n                    {\n\t\t    opt_offset = strpbrk(opt_ptr, \":=\");\n                    if (opt_offset == NULL)\n                      {\n                      TIFFError(\"Invalid dump option\", \"%s\", optarg);\n                      TIFFError (\"For valid options type\", \"tiffcrop -h\");\n                      exit (EXIT_FAILURE);\n\t\t      }\n                      \n                    *opt_offset = '\\0';\n                    /* convert option to lowercase */\n                    end = strlen (opt_ptr);\n                    for (i = 0; i < end; i++)\n                      *(opt_ptr + i) = tolower((int) *(opt_ptr + i));\n                    /* Look for dump format specification */\n                    if (strncmp(opt_ptr, \"for\", 3) == 0)\n                      {\n\t\t      /* convert value to lowercase */\n                      end = strlen (opt_offset + 1);\n                      for (i = 1; i <= end; i++)\n                        *(opt_offset + i) = tolower((int) *(opt_offset + i));\n                      /* check dump format value */\n\t\t      if (strncmp (opt_offset + 1, \"txt\", 3) == 0)\n                        {\n                        dump->format = DUMP_TEXT;\n                        strcpy (dump->mode, \"w\");\n                        }\n                      else\n                        {\n\t\t        if (strncmp(opt_offset + 1, \"raw\", 3) == 0)\n                          {\n                          dump->format = DUMP_RAW;\n                          strcpy (dump->mode, \"wb\");\n                          }\n                        else\n                          {\n                          TIFFError(\"parse_command_opts\", \"Unknown dump format %s\", opt_offset + 1);\n                          TIFFError (\"For valid options type\", \"tiffcrop -h\");\n                          exit (EXIT_FAILURE);\n\t\t          }\n\t\t\t}\n                      }\n\t\t    else\n                      { /* Look for dump level specification */\n                      if (strncmp (opt_ptr, \"lev\", 3) == 0)\n                        dump->level = atoi(opt_offset + 1);\n                        /* Look for input data dump file name */\n                      if (strncmp (opt_ptr, \"in\", 2) == 0)\n\t\t        {\n                        strncpy (dump->infilename, opt_offset + 1, PATH_MAX - 20);\n                        dump->infilename[PATH_MAX - 20] = '\\0';\n                        }\n                        /* Look for output data dump file name */\n                      if (strncmp (opt_ptr, \"out\", 3) == 0)\n\t\t\t{\n                        strncpy (dump->outfilename, opt_offset + 1, PATH_MAX - 20);\n                        dump->outfilename[PATH_MAX - 20] = '\\0';\n                        }\n                      if (strncmp (opt_ptr, \"deb\", 3) == 0)\n\t\t\tdump->debug = atoi(opt_offset + 1);\n\t\t      }\n                    }\n\t        if ((strlen(dump->infilename)) || (strlen(dump->outfilename)))\n                  {\n\t\t  if (dump->level == 1)\n                    TIFFError(\"\",\"Defaulting to dump level 1, no data.\");\n\t          if (dump->format == DUMP_NONE)\n                    {\n\t\t    TIFFError(\"\", \"You must specify a dump format for dump files\");\n\t\t    TIFFError (\"For valid options type\", \"tiffcrop -h\");\n\t\t    exit (EXIT_FAILURE);\n\t\t    }\n                  }\n\t        break;\n\n      /* image manipulation routine options */\n      case 'm': /* margins to exclude from selection, uppercase M was already used */\n\t\t/* order of values must be TOP, LEFT, BOTTOM, RIGHT */\n\t\tcrop_data->crop_mode |= CROP_MARGINS;\n                for (i = 0, opt_ptr = strtok (optarg, \",:\");\n                    ((opt_ptr != NULL) &&  (i < 4));\n                     (opt_ptr = strtok (NULL, \",:\")), i++)\n                    {\n\t\t    crop_data->margins[i] = atof(opt_ptr);\n                    }\n\t\tbreak;\n      case 'E':\t/* edge reference */\n\t\tswitch (tolower((int) optarg[0]))\n                  {\n\t\t  case 't': crop_data->edge_ref = EDGE_TOP;\n                            break;\n                  case 'b': crop_data->edge_ref = EDGE_BOTTOM;\n                             break;\n                  case 'l': crop_data->edge_ref = EDGE_LEFT;\n                            break;\n                  case 'r': crop_data->edge_ref = EDGE_RIGHT;\n                            break;\n\t\t  default:  TIFFError (\"Edge reference must be top, bottom, left, or right\", \"%s\", optarg);\n\t\t\t    TIFFError (\"For valid options type\", \"tiffcrop -h\");\n                            exit (EXIT_FAILURE);\n\t\t  }\n\t\tbreak;\n      case 'F': /* flip eg mirror image or cropped segment, M was already used */\n\t\tcrop_data->crop_mode |= CROP_MIRROR;\n\t\tswitch (tolower((int) optarg[0]))\n                  {\n\t\t  case  'h': crop_data->mirror = MIRROR_HORIZ;\n                             break;\n                  case  'v': crop_data->mirror = MIRROR_VERT;\n                             break;\n                  case  'b': crop_data->mirror = MIRROR_BOTH;\n                             break;\n\t\t  default:   TIFFError (\"Flip mode must be horiz, vert, or both\", \"%s\", optarg);\n\t\t\t     TIFFError (\"For valid options type\", \"tiffcrop -h\");\n                             exit (EXIT_FAILURE);\n\t\t  }\n\t\tbreak;\n      case 'H': /* set horizontal resolution to new value */\n\t\tpage->hres = atof (optarg);\n                page->mode |= PAGE_MODE_RESOLUTION;\n\t\tbreak;\n      case 'I': /* invert the color space, eg black to white */\n\t\tcrop_data->crop_mode |= CROP_INVERT;\n                /* The PHOTOMETIC_INTERPRETATION tag may be updated */\n                if (streq(optarg, \"black\"))\n                  {\n\t\t  crop_data->photometric = PHOTOMETRIC_MINISBLACK;\n\t\t  continue;\n                  }\n                if (streq(optarg, \"white\"))\n                  {\n\t\t  crop_data->photometric = PHOTOMETRIC_MINISWHITE;\n                  continue;\n                  }\n                if (streq(optarg, \"data\")) \n                  {\n\t\t  crop_data->photometric = INVERT_DATA_ONLY;\n                  continue;\n                  }\n                if (streq(optarg, \"both\"))\n                  {\n\t\t  crop_data->photometric = INVERT_DATA_AND_TAG;\n                  continue;\n                  }\n\n\t\tTIFFError(\"Missing or unknown option for inverting PHOTOMETRIC_INTERPRETATION\", \"%s\", optarg);\n\t\tTIFFError (\"For valid options type\", \"tiffcrop -h\");\n                exit (EXIT_FAILURE);\n\t\tbreak;\n      case 'J': /* horizontal margin for sectioned output pages */\n\t\tpage->hmargin = atof(optarg);\n                page->mode |= PAGE_MODE_MARGINS;\n\t\tbreak;\n      case 'K': /* vertical margin for sectioned output pages*/\n                page->vmargin = atof(optarg);\n                page->mode |= PAGE_MODE_MARGINS;\n\t\tbreak;\n      case 'N':\t/* list of images to process */\n                for (i = 0, opt_ptr = strtok (optarg, \",\");\n                    ((opt_ptr != NULL) &&  (i < MAX_IMAGES));\n                     (opt_ptr = strtok (NULL, \",\")))\n                     { /* We do not know how many images are in file yet \n\t\t\t* so we build a list to include the maximum allowed\n                        * and follow it until we hit the end of the file.\n                        * Image count is not accurate for odd, even, last\n                        * so page numbers won't be valid either.\n                        */\n\t\t     if (streq(opt_ptr, \"odd\"))\n                       {\n\t\t       for (j = 1; j <= MAX_IMAGES; j += 2)\n\t\t\t imagelist[i++] = j;\n                       *image_count = (MAX_IMAGES - 1) / 2;\n                       break;\n\t\t       }\n\t\t     else\n                       {\n\t\t       if (streq(opt_ptr, \"even\"))\n                         {\n\t\t\t for (j = 2; j <= MAX_IMAGES; j += 2)\n\t\t\t   imagelist[i++] = j;\n                         *image_count = MAX_IMAGES / 2;\n                         break;\n\t\t\t }\n\t\t       else\n                         {\n\t\t\t if (streq(opt_ptr, \"last\"))\n\t\t\t   imagelist[i++] = MAX_IMAGES;\n\t\t\t else  /* single value between commas */\n\t\t\t   {\n\t\t\t   sep = strpbrk(opt_ptr, \":-\");\n\t\t\t   if (!sep)\n\t\t\t     imagelist[i++] = atoi(opt_ptr);\n                           else\n                             {\n\t\t\t     *sep = '\\0';\n                             start = atoi (opt_ptr);\n                             if (!strcmp((sep + 1), \"last\"))\n\t\t\t       end = MAX_IMAGES;\n                             else\n                               end = atoi (sep + 1);\n                             for (j = start; j <= end && j - start + i < MAX_IMAGES; j++)\n\t\t\t       imagelist[i++] = j;\n\t\t\t     }\n\t\t\t   }\n\t\t\t }\n\t\t      }\n\t\t    }\n                *image_count = i;\n\t\tbreak;\n      case 'O': /* page orientation */ \n\t\tswitch (tolower((int) optarg[0]))\n                  {\n\t\t  case  'a': page->orient = ORIENTATION_AUTO;\n                             break;\n\t\t  case  'p': page->orient = ORIENTATION_PORTRAIT;\n                             break;\n\t\t  case  'l': page->orient = ORIENTATION_LANDSCAPE;\n                             break;\n\t\t  default:  TIFFError (\"Orientation must be portrait, landscape, or auto.\", \"%s\", optarg);\n\t\t\t    TIFFError (\"For valid options type\", \"tiffcrop -h\");\n                            exit (EXIT_FAILURE);\n\t\t  }\n\t\tbreak;\n      case 'P': /* page size selection */ \n\t        if (sscanf(optarg, \"%lfx%lf\", &page->width, &page->length) == 2)\n                  {\n                  strcpy (page->name, \"Custom\"); \n                  page->mode |= PAGE_MODE_PAPERSIZE;\n                  break;\n                  }\n                if (get_page_geometry (optarg, page))\n                  {\n\t\t  if (!strcmp(optarg, \"list\"))\n                    {\n\t\t    TIFFError(\"\", \"Name            Width   Length (in inches)\");\n                    for (i = 0; i < MAX_PAPERNAMES - 1; i++)\n                      TIFFError (\"\", \"%-15.15s %5.2f   %5.2f\", \n\t\t\t       PaperTable[i].name, PaperTable[i].width, \n                               PaperTable[i].length);\n\t\t    exit (EXIT_FAILURE);\n                    }\n     \n\t\t  TIFFError (\"Invalid paper size\", \"%s\", optarg);\n                  TIFFError (\"\", \"Select one of:\");\n\t\t  TIFFError(\"\", \"Name            Width   Length (in inches)\");\n                  for (i = 0; i < MAX_PAPERNAMES - 1; i++)\n                    TIFFError (\"\", \"%-15.15s %5.2f   %5.2f\", \n\t\t\t       PaperTable[i].name, PaperTable[i].width, \n                               PaperTable[i].length);\n\t\t  exit (EXIT_FAILURE);\n\t\t  }\n\t\telse\n                  {\n                  page->mode |= PAGE_MODE_PAPERSIZE;\n\t\t  }\n\t\tbreak;\n      case 'R': /* rotate image or cropped segment */\n\t\tcrop_data->crop_mode |= CROP_ROTATE;\n\t\tswitch (strtoul(optarg, NULL, 0))\n                  {\n\t\t  case  90:  crop_data->rotation = (uint16_t)90;\n                             break;\n                  case  180: crop_data->rotation = (uint16_t)180;\n                             break;\n                  case  270: crop_data->rotation = (uint16_t)270;\n                             break;\n\t\t  default:   TIFFError (\"Rotation must be 90, 180, or 270 degrees clockwise\", \"%s\", optarg);\n\t\t\t     TIFFError (\"For valid options type\", \"tiffcrop -h\");\n                             exit (EXIT_FAILURE);\n\t\t  }\n\t\tbreak;\n      case 'S':\t/* subdivide into Cols:Rows sections, eg 3:2 would be 3 across and 2 down */\n\t\tsep = strpbrk(optarg, \",:\");\n\t\tif (sep)\n                  {\n                  *sep = '\\0';\n                  page->cols = atoi(optarg);\n                  page->rows = atoi(sep +1);\n\t\t  }\n                else\n                  {\n                  page->cols = atoi(optarg);\n                  page->rows = atoi(optarg);\n\t\t  }\n                if ((page->cols * page->rows) > MAX_SECTIONS)\n                  {\n\t\t  TIFFError (\"Limit for subdivisions, ie rows x columns, exceeded\", \"%d\", MAX_SECTIONS);\n\t\t  exit (EXIT_FAILURE);\n                  }\n                page->mode |= PAGE_MODE_ROWSCOLS;\n\t\tbreak;\n      case 'U':\t/* units for measurements and offsets */\n\t\tif (streq(optarg, \"in\"))\n                  {\n\t\t  crop_data->res_unit = RESUNIT_INCH;\n\t\t  page->res_unit = RESUNIT_INCH;\n\t\t  }\n\t\telse if (streq(optarg, \"cm\"))\n\t\t  {\n\t\t  crop_data->res_unit = RESUNIT_CENTIMETER;\n\t\t  page->res_unit = RESUNIT_CENTIMETER;\n\t\t  }\n\t\telse if (streq(optarg, \"px\"))\n\t\t  {\n\t\t  crop_data->res_unit = RESUNIT_NONE;\n\t\t  page->res_unit = RESUNIT_NONE;\n\t\t  }\n\t\telse\n                  {\n\t\t  TIFFError (\"Illegal unit of measure\",\"%s\", optarg);\n\t\t  TIFFError (\"For valid options type\", \"tiffcrop -h\");\n                  exit (EXIT_FAILURE);\n\t\t  }\n\t\tbreak;\n      case 'V': /* set vertical resolution to new value */\n\t\tpage->vres = atof (optarg);\n                page->mode |= PAGE_MODE_RESOLUTION;\n\t\tbreak;\n      case 'X':\t/* selection width */\n\t\tcrop_data->crop_mode |= CROP_WIDTH;\n\t\tcrop_data->width = atof(optarg);\n\t\tbreak;\n      case 'Y':\t/* selection length */\n\t\tcrop_data->crop_mode |= CROP_LENGTH;\n\t\tcrop_data->length = atof(optarg);\n\t\tbreak;\n      case 'Z': /* zones of an image X:Y read as zone X of Y */\n\t\tcrop_data->crop_mode |= CROP_ZONES;\n\t\tfor (i = 0, opt_ptr = strtok (optarg, \",\");\n                   ((opt_ptr != NULL) &&  (i < MAX_REGIONS));\n                    (opt_ptr = strtok (NULL, \",\")), i++)\n                    {\n\t\t    crop_data->zones++;\n\t\t    opt_offset = strchr(opt_ptr, ':');\n\t\t    if (!opt_offset) {\n\t\t\tTIFFError(\"Wrong parameter syntax for -Z\", \"tiffcrop -h\");\n\t\t\texit(EXIT_FAILURE);\n\t\t    }\n                    *opt_offset = '\\0';\n                    crop_data->zonelist[i].position = atoi(opt_ptr);\n                    crop_data->zonelist[i].total    = atoi(opt_offset + 1);\n                    }\n                /*  check for remaining elements over MAX_REGIONS */\n                if ((opt_ptr != NULL) && (i >= MAX_REGIONS))\n                  {\n\t\t  TIFFError(\"Zone list exceeds region limit\", \"%d\",  MAX_REGIONS);\n\t\t  exit (EXIT_FAILURE);\n                  }\n\t\tbreak;\n    case '?':\tTIFFError (\"For valid options type\", \"tiffcrop -h\");\n                exit (EXIT_FAILURE);\n\t\t/*NOTREACHED*/\n      }\n    }\n    /*-- Check for not allowed combinations (e.g. -X, -Y and -Z, -z and -S are mutually exclusive) --*/\n    char XY, Z, R, S;\n    XY = ((crop_data->crop_mode & CROP_WIDTH) || (crop_data->crop_mode & CROP_LENGTH));\n    Z = (crop_data->crop_mode & CROP_ZONES);\n    R = (crop_data->crop_mode & CROP_REGIONS);\n    S = (page->mode & PAGE_MODE_ROWSCOLS);\n    if ((XY && Z) || (XY && R) || (XY && S) || (Z && R) || (Z && S) || (R && S)) {\n        TIFFError(\"tiffcrop input error\", \"The crop options(-X|-Y), -Z, -z and -S are mutually exclusive.->Exit\");\n        exit(EXIT_FAILURE);\n    }\n  }",
        "func": "void  process_command_opts (int argc, char *argv[], char *mp, char *mode, uint32_t *dirnum,\n                            uint16_t *defconfig, uint16_t *deffillorder, uint32_t *deftilewidth,\n                            uint32_t *deftilelength, uint32_t *defrowsperstrip,\n                            struct crop_mask *crop_data, struct pagedef *page,\n                            struct dump_opts *dump,\n                            unsigned int     *imagelist, unsigned int   *image_count )\n    {\n    int   c, good_args = 0;\n    char *opt_offset   = NULL;    /* Position in string of value sought */\n    char *opt_ptr      = NULL;    /* Pointer to next token in option set */\n    char *sep          = NULL;    /* Pointer to a token separator */\n    unsigned int  i, j, start, end;\n#if !HAVE_DECL_OPTARG\n    extern int   optind;\n    extern char* optarg;\n#endif\n\n    *mp++ = 'w';\n    *mp = '\\0';\n    while ((c = getopt(argc, argv,\n       \"ac:d:e:f:hik:l:m:p:r:stvw:z:BCD:E:F:H:I:J:K:LMN:O:P:R:S:U:V:X:Y:Z:\")) != -1)\n      {\n    good_args++;\n    switch (c) {\n      case 'a': mode[0] = 'a';\t/* append to output */\n\t\tbreak;\n      case 'c':\tif (!processCompressOptions(optarg)) /* compression scheme */\n\t\t  {\n\t\t  TIFFError (\"Unknown compression option\", \"%s\", optarg);\n                  TIFFError (\"For valid options type\", \"tiffcrop -h\");\n                  exit (EXIT_FAILURE);\n                  }\n\t\tbreak;\n      case 'd':\tstart = strtoul(optarg, NULL, 0); /* initial IFD offset */\n\t        if (start == 0)\n                  {\n\t\t  TIFFError (\"\",\"Directory offset must be greater than zero\");\n\t\t  TIFFError (\"For valid options type\", \"tiffcrop -h\");\n                  exit (EXIT_FAILURE);\n\t\t  }\n\t        *dirnum = start - 1;\n\t\tbreak;\n      case 'e': switch (tolower((int) optarg[0])) /* image export modes*/\n                  {\n\t\t  case 'c': crop_data->exp_mode = ONE_FILE_COMPOSITE;\n \t\t            crop_data->img_mode = COMPOSITE_IMAGES;\n\t\t            break; /* Composite */\n\t\t  case 'd': crop_data->exp_mode = ONE_FILE_SEPARATED;\n \t\t            crop_data->img_mode = SEPARATED_IMAGES;\n\t\t            break; /* Divided */\n\t\t  case 'i': crop_data->exp_mode = FILE_PER_IMAGE_COMPOSITE;\n \t\t            crop_data->img_mode = COMPOSITE_IMAGES;\n\t\t            break; /* Image */\n\t\t  case 'm': crop_data->exp_mode = FILE_PER_IMAGE_SEPARATED;\n \t\t            crop_data->img_mode = SEPARATED_IMAGES;\n\t\t            break; /* Multiple */\n\t\t  case 's': crop_data->exp_mode = FILE_PER_SELECTION;\n \t\t            crop_data->img_mode = SEPARATED_IMAGES;\n\t\t            break; /* Sections */\n\t\t  default:  TIFFError (\"Unknown export mode\",\"%s\", optarg);\n                            TIFFError (\"For valid options type\", \"tiffcrop -h\");\n                            exit (EXIT_FAILURE);\n                  }\n\t        break;\n      case 'f':\tif (streq(optarg, \"lsb2msb\"))\t   /* fill order */\n\t\t  *deffillorder = FILLORDER_LSB2MSB;\n\t\telse if (streq(optarg, \"msb2lsb\"))\n\t\t  *deffillorder = FILLORDER_MSB2LSB;\n\t\telse\n\t\t  {\n\t\t  TIFFError (\"Unknown fill order\", \"%s\", optarg);\n                  TIFFError (\"For valid options type\", \"tiffcrop -h\");\n                  exit (EXIT_FAILURE);\n                  }\n\t\tbreak;\n      case 'h':\tusage(EXIT_SUCCESS);\n\t\tbreak;\n      case 'i':\tignore = TRUE;\t\t/* ignore errors */\n\t\tbreak;\n      case 'k':\tmaxMalloc = (tmsize_t)strtoul(optarg, NULL, 0) << 20;\n\t\tbreak;\n      case 'l':\touttiled = TRUE;\t /* tile length */\n\t\t*deftilelength = atoi(optarg);\n\t\tbreak;\n      case 'p': /* planar configuration */\n\t\tif (streq(optarg, \"separate\"))\n\t\t  *defconfig = PLANARCONFIG_SEPARATE;\n\t\telse if (streq(optarg, \"contig\"))\n\t\t  *defconfig = PLANARCONFIG_CONTIG;\n\t\telse\n\t\t  {\n\t\t  TIFFError (\"Unknown planar configuration\", \"%s\", optarg);\n                  TIFFError (\"For valid options type\", \"tiffcrop -h\");\n                  exit (EXIT_FAILURE);\n                  }\n\t\tbreak;\n      case 'r':\t/* rows/strip */\n\t\t*defrowsperstrip = atol(optarg);\n\t\tbreak;\n      case 's':\t/* generate stripped output */\n\t\touttiled = FALSE;\n\t\tbreak;\n      case 't':\t/* generate tiled output */\n\t\touttiled = TRUE;\n\t\tbreak;\n      case 'v': printf(\"Library Release: %s\\n\", TIFFGetVersion());\n                printf(\"Tiffcrop version: %s, last updated: %s\\n\",\n\t\t\t   tiffcrop_version_id, tiffcrop_rev_date);\n\t        printf(\"Tiffcp code: Copyright (c) 1988-1997 Sam Leffler\\n\");\n\t\tprintf(\"           : Copyright (c) 1991-1997 Silicon Graphics, Inc\\n\");\n                printf(\"Tiffcrop additions: Copyright (c) 2007-2010 Richard Nolde\\n\");\n\t        exit (EXIT_SUCCESS);\n\t\tbreak;\n      case 'w':\t/* tile width */\n\t\touttiled = TRUE;\n\t\t*deftilewidth = atoi(optarg);\n\t\tbreak;\n      case 'z': /* regions of an image specified as x1,y1,x2,y2:x3,y3,x4,y4 etc */\n\t        crop_data->crop_mode |= CROP_REGIONS;\n\t\tfor (i = 0, opt_ptr = strtok (optarg, \":\");\n                   ((opt_ptr != NULL) &&  (i < MAX_REGIONS));\n                    (opt_ptr = strtok (NULL, \":\")), i++)\n                    {\n\t\t    crop_data->regions++;\n                    if (sscanf(opt_ptr, \"%lf,%lf,%lf,%lf\",\n\t\t\t       &crop_data->corners[i].X1, &crop_data->corners[i].Y1,\n\t\t\t       &crop_data->corners[i].X2, &crop_data->corners[i].Y2) != 4)\n                      {\n                      TIFFError (\"Unable to parse coordinates for region\", \"%u %s\", i, optarg);\n\t\t      TIFFError (\"For valid options type\", \"tiffcrop -h\");\n                      exit (EXIT_FAILURE);\n\t\t      }\n                    }\n                /*  check for remaining elements over MAX_REGIONS */\n                if ((opt_ptr != NULL) && (i >= MAX_REGIONS))\n                  {\n\t\t  TIFFError (\"Region list exceeds limit of\", \"%d regions %s\", MAX_REGIONS, optarg);\n\t\t  TIFFError (\"For valid options type\", \"tiffcrop -h\");\n                  exit (EXIT_FAILURE);;\n                  }\n\t\tbreak;\n      /* options for file open modes */\n      case 'B': *mp++ = 'b'; *mp = '\\0';\n\t\tbreak;\n      case 'L': *mp++ = 'l'; *mp = '\\0';\n\t\tbreak;\n      case 'M': *mp++ = 'm'; *mp = '\\0';\n\t\tbreak;\n      case 'C': *mp++ = 'c'; *mp = '\\0';\n\t\tbreak;\n      /* options for Debugging / data dump */\n      case 'D': for (i = 0, opt_ptr = strtok (optarg, \",\");\n                    (opt_ptr != NULL);\n                    (opt_ptr = strtok (NULL, \",\")), i++)\n                    {\n\t\t    opt_offset = strpbrk(opt_ptr, \":=\");\n                    if (opt_offset == NULL)\n                      {\n                      TIFFError(\"Invalid dump option\", \"%s\", optarg);\n                      TIFFError (\"For valid options type\", \"tiffcrop -h\");\n                      exit (EXIT_FAILURE);\n\t\t      }\n                      \n                    *opt_offset = '\\0';\n                    /* convert option to lowercase */\n                    end = strlen (opt_ptr);\n                    for (i = 0; i < end; i++)\n                      *(opt_ptr + i) = tolower((int) *(opt_ptr + i));\n                    /* Look for dump format specification */\n                    if (strncmp(opt_ptr, \"for\", 3) == 0)\n                      {\n\t\t      /* convert value to lowercase */\n                      end = strlen (opt_offset + 1);\n                      for (i = 1; i <= end; i++)\n                        *(opt_offset + i) = tolower((int) *(opt_offset + i));\n                      /* check dump format value */\n\t\t      if (strncmp (opt_offset + 1, \"txt\", 3) == 0)\n                        {\n                        dump->format = DUMP_TEXT;\n                        strcpy (dump->mode, \"w\");\n                        }\n                      else\n                        {\n\t\t        if (strncmp(opt_offset + 1, \"raw\", 3) == 0)\n                          {\n                          dump->format = DUMP_RAW;\n                          strcpy (dump->mode, \"wb\");\n                          }\n                        else\n                          {\n                          TIFFError(\"parse_command_opts\", \"Unknown dump format %s\", opt_offset + 1);\n                          TIFFError (\"For valid options type\", \"tiffcrop -h\");\n                          exit (EXIT_FAILURE);\n\t\t          }\n\t\t\t}\n                      }\n\t\t    else\n                      { /* Look for dump level specification */\n                      if (strncmp (opt_ptr, \"lev\", 3) == 0)\n                        dump->level = atoi(opt_offset + 1);\n                        /* Look for input data dump file name */\n                      if (strncmp (opt_ptr, \"in\", 2) == 0)\n\t\t        {\n                        strncpy (dump->infilename, opt_offset + 1, PATH_MAX - 20);\n                        dump->infilename[PATH_MAX - 20] = '\\0';\n                        }\n                        /* Look for output data dump file name */\n                      if (strncmp (opt_ptr, \"out\", 3) == 0)\n\t\t\t{\n                        strncpy (dump->outfilename, opt_offset + 1, PATH_MAX - 20);\n                        dump->outfilename[PATH_MAX - 20] = '\\0';\n                        }\n                      if (strncmp (opt_ptr, \"deb\", 3) == 0)\n\t\t\tdump->debug = atoi(opt_offset + 1);\n\t\t      }\n                    }\n\t        if ((strlen(dump->infilename)) || (strlen(dump->outfilename)))\n                  {\n\t\t  if (dump->level == 1)\n                    TIFFError(\"\",\"Defaulting to dump level 1, no data.\");\n\t          if (dump->format == DUMP_NONE)\n                    {\n\t\t    TIFFError(\"\", \"You must specify a dump format for dump files\");\n\t\t    TIFFError (\"For valid options type\", \"tiffcrop -h\");\n\t\t    exit (EXIT_FAILURE);\n\t\t    }\n                  }\n\t        break;\n\n      /* image manipulation routine options */\n      case 'm': /* margins to exclude from selection, uppercase M was already used */\n\t\t/* order of values must be TOP, LEFT, BOTTOM, RIGHT */\n\t\tcrop_data->crop_mode |= CROP_MARGINS;\n                for (i = 0, opt_ptr = strtok (optarg, \",:\");\n                    ((opt_ptr != NULL) &&  (i < 4));\n                     (opt_ptr = strtok (NULL, \",:\")), i++)\n                    {\n\t\t    crop_data->margins[i] = atof(opt_ptr);\n                    }\n\t\tbreak;\n      case 'E':\t/* edge reference */\n\t\tswitch (tolower((int) optarg[0]))\n                  {\n\t\t  case 't': crop_data->edge_ref = EDGE_TOP;\n                            break;\n                  case 'b': crop_data->edge_ref = EDGE_BOTTOM;\n                             break;\n                  case 'l': crop_data->edge_ref = EDGE_LEFT;\n                            break;\n                  case 'r': crop_data->edge_ref = EDGE_RIGHT;\n                            break;\n\t\t  default:  TIFFError (\"Edge reference must be top, bottom, left, or right\", \"%s\", optarg);\n\t\t\t    TIFFError (\"For valid options type\", \"tiffcrop -h\");\n                            exit (EXIT_FAILURE);\n\t\t  }\n\t\tbreak;\n      case 'F': /* flip eg mirror image or cropped segment, M was already used */\n\t\tcrop_data->crop_mode |= CROP_MIRROR;\n\t\tswitch (tolower((int) optarg[0]))\n                  {\n\t\t  case  'h': crop_data->mirror = MIRROR_HORIZ;\n                             break;\n                  case  'v': crop_data->mirror = MIRROR_VERT;\n                             break;\n                  case  'b': crop_data->mirror = MIRROR_BOTH;\n                             break;\n\t\t  default:   TIFFError (\"Flip mode must be horiz, vert, or both\", \"%s\", optarg);\n\t\t\t     TIFFError (\"For valid options type\", \"tiffcrop -h\");\n                             exit (EXIT_FAILURE);\n\t\t  }\n\t\tbreak;\n      case 'H': /* set horizontal resolution to new value */\n\t\tpage->hres = atof (optarg);\n                page->mode |= PAGE_MODE_RESOLUTION;\n\t\tbreak;\n      case 'I': /* invert the color space, eg black to white */\n\t\tcrop_data->crop_mode |= CROP_INVERT;\n                /* The PHOTOMETIC_INTERPRETATION tag may be updated */\n                if (streq(optarg, \"black\"))\n                  {\n\t\t  crop_data->photometric = PHOTOMETRIC_MINISBLACK;\n\t\t  continue;\n                  }\n                if (streq(optarg, \"white\"))\n                  {\n\t\t  crop_data->photometric = PHOTOMETRIC_MINISWHITE;\n                  continue;\n                  }\n                if (streq(optarg, \"data\")) \n                  {\n\t\t  crop_data->photometric = INVERT_DATA_ONLY;\n                  continue;\n                  }\n                if (streq(optarg, \"both\"))\n                  {\n\t\t  crop_data->photometric = INVERT_DATA_AND_TAG;\n                  continue;\n                  }\n\n\t\tTIFFError(\"Missing or unknown option for inverting PHOTOMETRIC_INTERPRETATION\", \"%s\", optarg);\n\t\tTIFFError (\"For valid options type\", \"tiffcrop -h\");\n                exit (EXIT_FAILURE);\n\t\tbreak;\n      case 'J': /* horizontal margin for sectioned output pages */\n\t\tpage->hmargin = atof(optarg);\n                page->mode |= PAGE_MODE_MARGINS;\n\t\tbreak;\n      case 'K': /* vertical margin for sectioned output pages*/\n                page->vmargin = atof(optarg);\n                page->mode |= PAGE_MODE_MARGINS;\n\t\tbreak;\n      case 'N':\t/* list of images to process */\n                for (i = 0, opt_ptr = strtok (optarg, \",\");\n                    ((opt_ptr != NULL) &&  (i < MAX_IMAGES));\n                     (opt_ptr = strtok (NULL, \",\")))\n                     { /* We do not know how many images are in file yet \n\t\t\t* so we build a list to include the maximum allowed\n                        * and follow it until we hit the end of the file.\n                        * Image count is not accurate for odd, even, last\n                        * so page numbers won't be valid either.\n                        */\n\t\t     if (streq(opt_ptr, \"odd\"))\n                       {\n\t\t       for (j = 1; j <= MAX_IMAGES; j += 2)\n\t\t\t imagelist[i++] = j;\n                       *image_count = (MAX_IMAGES - 1) / 2;\n                       break;\n\t\t       }\n\t\t     else\n                       {\n\t\t       if (streq(opt_ptr, \"even\"))\n                         {\n\t\t\t for (j = 2; j <= MAX_IMAGES; j += 2)\n\t\t\t   imagelist[i++] = j;\n                         *image_count = MAX_IMAGES / 2;\n                         break;\n\t\t\t }\n\t\t       else\n                         {\n\t\t\t if (streq(opt_ptr, \"last\"))\n\t\t\t   imagelist[i++] = MAX_IMAGES;\n\t\t\t else  /* single value between commas */\n\t\t\t   {\n\t\t\t   sep = strpbrk(opt_ptr, \":-\");\n\t\t\t   if (!sep)\n\t\t\t     imagelist[i++] = atoi(opt_ptr);\n                           else\n                             {\n\t\t\t     *sep = '\\0';\n                             start = atoi (opt_ptr);\n                             if (!strcmp((sep + 1), \"last\"))\n\t\t\t       end = MAX_IMAGES;\n                             else\n                               end = atoi (sep + 1);\n                             for (j = start; j <= end && j - start + i < MAX_IMAGES; j++)\n\t\t\t       imagelist[i++] = j;\n\t\t\t     }\n\t\t\t   }\n\t\t\t }\n\t\t      }\n\t\t    }\n                *image_count = i;\n\t\tbreak;\n      case 'O': /* page orientation */ \n\t\tswitch (tolower((int) optarg[0]))\n                  {\n\t\t  case  'a': page->orient = ORIENTATION_AUTO;\n                             break;\n\t\t  case  'p': page->orient = ORIENTATION_PORTRAIT;\n                             break;\n\t\t  case  'l': page->orient = ORIENTATION_LANDSCAPE;\n                             break;\n\t\t  default:  TIFFError (\"Orientation must be portrait, landscape, or auto.\", \"%s\", optarg);\n\t\t\t    TIFFError (\"For valid options type\", \"tiffcrop -h\");\n                            exit (EXIT_FAILURE);\n\t\t  }\n\t\tbreak;\n      case 'P': /* page size selection */ \n\t        if (sscanf(optarg, \"%lfx%lf\", &page->width, &page->length) == 2)\n                  {\n                  strcpy (page->name, \"Custom\"); \n                  page->mode |= PAGE_MODE_PAPERSIZE;\n                  break;\n                  }\n                if (get_page_geometry (optarg, page))\n                  {\n\t\t  if (!strcmp(optarg, \"list\"))\n                    {\n\t\t    TIFFError(\"\", \"Name            Width   Length (in inches)\");\n                    for (i = 0; i < MAX_PAPERNAMES - 1; i++)\n                      TIFFError (\"\", \"%-15.15s %5.2f   %5.2f\", \n\t\t\t       PaperTable[i].name, PaperTable[i].width, \n                               PaperTable[i].length);\n\t\t    exit (EXIT_FAILURE);\n                    }\n     \n\t\t  TIFFError (\"Invalid paper size\", \"%s\", optarg);\n                  TIFFError (\"\", \"Select one of:\");\n\t\t  TIFFError(\"\", \"Name            Width   Length (in inches)\");\n                  for (i = 0; i < MAX_PAPERNAMES - 1; i++)\n                    TIFFError (\"\", \"%-15.15s %5.2f   %5.2f\", \n\t\t\t       PaperTable[i].name, PaperTable[i].width, \n                               PaperTable[i].length);\n\t\t  exit (EXIT_FAILURE);\n\t\t  }\n\t\telse\n                  {\n                  page->mode |= PAGE_MODE_PAPERSIZE;\n\t\t  }\n\t\tbreak;\n      case 'R': /* rotate image or cropped segment */\n\t\tcrop_data->crop_mode |= CROP_ROTATE;\n\t\tswitch (strtoul(optarg, NULL, 0))\n                  {\n\t\t  case  90:  crop_data->rotation = (uint16_t)90;\n                             break;\n                  case  180: crop_data->rotation = (uint16_t)180;\n                             break;\n                  case  270: crop_data->rotation = (uint16_t)270;\n                             break;\n\t\t  default:   TIFFError (\"Rotation must be 90, 180, or 270 degrees clockwise\", \"%s\", optarg);\n\t\t\t     TIFFError (\"For valid options type\", \"tiffcrop -h\");\n                             exit (EXIT_FAILURE);\n\t\t  }\n\t\tbreak;\n      case 'S':\t/* subdivide into Cols:Rows sections, eg 3:2 would be 3 across and 2 down */\n\t\tsep = strpbrk(optarg, \",:\");\n\t\tif (sep)\n                  {\n                  *sep = '\\0';\n                  page->cols = atoi(optarg);\n                  page->rows = atoi(sep +1);\n\t\t  }\n                else\n                  {\n                  page->cols = atoi(optarg);\n                  page->rows = atoi(optarg);\n\t\t  }\n                if ((page->cols * page->rows) > MAX_SECTIONS)\n                  {\n\t\t  TIFFError (\"Limit for subdivisions, ie rows x columns, exceeded\", \"%d\", MAX_SECTIONS);\n\t\t  exit (EXIT_FAILURE);\n                  }\n                page->mode |= PAGE_MODE_ROWSCOLS;\n\t\tbreak;\n      case 'U':\t/* units for measurements and offsets */\n\t\tif (streq(optarg, \"in\"))\n                  {\n\t\t  crop_data->res_unit = RESUNIT_INCH;\n\t\t  page->res_unit = RESUNIT_INCH;\n\t\t  }\n\t\telse if (streq(optarg, \"cm\"))\n\t\t  {\n\t\t  crop_data->res_unit = RESUNIT_CENTIMETER;\n\t\t  page->res_unit = RESUNIT_CENTIMETER;\n\t\t  }\n\t\telse if (streq(optarg, \"px\"))\n\t\t  {\n\t\t  crop_data->res_unit = RESUNIT_NONE;\n\t\t  page->res_unit = RESUNIT_NONE;\n\t\t  }\n\t\telse\n                  {\n\t\t  TIFFError (\"Illegal unit of measure\",\"%s\", optarg);\n\t\t  TIFFError (\"For valid options type\", \"tiffcrop -h\");\n                  exit (EXIT_FAILURE);\n\t\t  }\n\t\tbreak;\n      case 'V': /* set vertical resolution to new value */\n\t\tpage->vres = atof (optarg);\n                page->mode |= PAGE_MODE_RESOLUTION;\n\t\tbreak;\n      case 'X':\t/* selection width */\n\t\tcrop_data->crop_mode |= CROP_WIDTH;\n\t\tcrop_data->width = atof(optarg);\n\t\tbreak;\n      case 'Y':\t/* selection length */\n\t\tcrop_data->crop_mode |= CROP_LENGTH;\n\t\tcrop_data->length = atof(optarg);\n\t\tbreak;\n      case 'Z': /* zones of an image X:Y read as zone X of Y */\n\t\tcrop_data->crop_mode |= CROP_ZONES;\n\t\tfor (i = 0, opt_ptr = strtok (optarg, \",\");\n                   ((opt_ptr != NULL) &&  (i < MAX_REGIONS));\n                    (opt_ptr = strtok (NULL, \",\")), i++)\n                    {\n\t\t    crop_data->zones++;\n\t\t    opt_offset = strchr(opt_ptr, ':');\n\t\t    if (!opt_offset) {\n\t\t\tTIFFError(\"Wrong parameter syntax for -Z\", \"tiffcrop -h\");\n\t\t\texit(EXIT_FAILURE);\n\t\t    }\n                    *opt_offset = '\\0';\n                    crop_data->zonelist[i].position = atoi(opt_ptr);\n                    crop_data->zonelist[i].total    = atoi(opt_offset + 1);\n                    }\n                /*  check for remaining elements over MAX_REGIONS */\n                if ((opt_ptr != NULL) && (i >= MAX_REGIONS))\n                  {\n\t\t  TIFFError(\"Zone list exceeds region limit\", \"%d\",  MAX_REGIONS);\n\t\t  exit (EXIT_FAILURE);\n                  }\n\t\tbreak;\n    case '?':\tTIFFError (\"For valid options type\", \"tiffcrop -h\");\n                exit (EXIT_FAILURE);\n\t\t/*NOTREACHED*/\n      }\n    }\n    /*-- Check for not allowed combinations (e.g. -X, -Y and -Z, -z and -S are mutually exclusive) --*/\n    char XY, Z, R, S;\n    XY = ((crop_data->crop_mode & CROP_WIDTH) || (crop_data->crop_mode & CROP_LENGTH)) ? 1 : 0;\n    Z = (crop_data->crop_mode & CROP_ZONES) ? 1 : 0;\n    R = (crop_data->crop_mode & CROP_REGIONS) ? 1 : 0;\n    S = (page->mode & PAGE_MODE_ROWSCOLS) ? 1 : 0;\n    if (XY + Z + R + S > 1) {\n        TIFFError(\"tiffcrop input error\", \"The crop options(-X|-Y), -Z, -z and -S are mutually exclusive.->Exit\");\n        exit(EXIT_FAILURE);\n    }\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -508,11 +508,11 @@\n     }\n     /*-- Check for not allowed combinations (e.g. -X, -Y and -Z, -z and -S are mutually exclusive) --*/\n     char XY, Z, R, S;\n-    XY = ((crop_data->crop_mode & CROP_WIDTH) || (crop_data->crop_mode & CROP_LENGTH));\n-    Z = (crop_data->crop_mode & CROP_ZONES);\n-    R = (crop_data->crop_mode & CROP_REGIONS);\n-    S = (page->mode & PAGE_MODE_ROWSCOLS);\n-    if ((XY && Z) || (XY && R) || (XY && S) || (Z && R) || (Z && S) || (R && S)) {\n+    XY = ((crop_data->crop_mode & CROP_WIDTH) || (crop_data->crop_mode & CROP_LENGTH)) ? 1 : 0;\n+    Z = (crop_data->crop_mode & CROP_ZONES) ? 1 : 0;\n+    R = (crop_data->crop_mode & CROP_REGIONS) ? 1 : 0;\n+    S = (page->mode & PAGE_MODE_ROWSCOLS) ? 1 : 0;\n+    if (XY + Z + R + S > 1) {\n         TIFFError(\"tiffcrop input error\", \"The crop options(-X|-Y), -Z, -z and -S are mutually exclusive.->Exit\");\n         exit(EXIT_FAILURE);\n     }",
        "diff_line_info": {
            "deleted_lines": [
                "    XY = ((crop_data->crop_mode & CROP_WIDTH) || (crop_data->crop_mode & CROP_LENGTH));",
                "    Z = (crop_data->crop_mode & CROP_ZONES);",
                "    R = (crop_data->crop_mode & CROP_REGIONS);",
                "    S = (page->mode & PAGE_MODE_ROWSCOLS);",
                "    if ((XY && Z) || (XY && R) || (XY && S) || (Z && R) || (Z && S) || (R && S)) {"
            ],
            "added_lines": [
                "    XY = ((crop_data->crop_mode & CROP_WIDTH) || (crop_data->crop_mode & CROP_LENGTH)) ? 1 : 0;",
                "    Z = (crop_data->crop_mode & CROP_ZONES) ? 1 : 0;",
                "    R = (crop_data->crop_mode & CROP_REGIONS) ? 1 : 0;",
                "    S = (page->mode & PAGE_MODE_ROWSCOLS) ? 1 : 0;",
                "    if (XY + Z + R + S > 1) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-14934",
        "func_name": "binutils-gdb/process_debug_info",
        "description": "process_debug_info in dwarf.c in the Binary File Descriptor (BFD) library (aka libbfd), as distributed in GNU Binutils 2.29, allows remote attackers to cause a denial of service (infinite loop) via a crafted ELF file that contains a negative size value in a CU structure.",
        "git_url": "https://sourceware.org/git/gitweb.cgi?p=binutils-gdb.git;h=19485196044b2521af979f1e5c4a89bfb90fba0b",
        "commit_title": "",
        "commit_text": "Prevent an infinite loop in the DWARF parsing code when encountering a CU structure with a small negative size.  \tPR 22219 \t* dwarf.c (process_debug_info): Add a check for a negative \tcu_length field. ",
        "func_before": "static int\nprocess_debug_info (struct dwarf_section *section,\n\t\t    void *file,\n\t\t    enum dwarf_section_display_enum abbrev_sec,\n\t\t    int do_loc,\n\t\t    int do_types)\n{\n  unsigned char *start = section->start;\n  unsigned char *end = start + section->size;\n  unsigned char *section_begin;\n  unsigned int unit;\n  unsigned int num_units = 0;\n\n  if ((do_loc || do_debug_loc || do_debug_ranges)\n      && num_debug_info_entries == 0\n      && ! do_types)\n    {\n      dwarf_vma length;\n\n      /* First scan the section to get the number of comp units.  */\n      for (section_begin = start, num_units = 0; section_begin < end;\n\t   num_units ++)\n\t{\n\t  /* Read the first 4 bytes.  For a 32-bit DWARF section, this\n\t     will be the length.  For a 64-bit DWARF section, it'll be\n\t     the escape code 0xffffffff followed by an 8 byte length.  */\n\t  SAFE_BYTE_GET (length, section_begin, 4, end);\n\n\t  if (length == 0xffffffff)\n\t    {\n\t      SAFE_BYTE_GET (length, section_begin + 4, 8, end);\n\t      section_begin += length + 12;\n\t    }\n\t  else if (length >= 0xfffffff0 && length < 0xffffffff)\n\t    {\n\t      warn (_(\"Reserved length value (0x%s) found in section %s\\n\"),\n\t\t    dwarf_vmatoa (\"x\", length), section->name);\n\t      return 0;\n\t    }\n\t  else\n\t    section_begin += length + 4;\n\n\t  /* Negative values are illegal, they may even cause infinite\n\t     looping.  This can happen if we can't accurately apply\n\t     relocations to an object file, or if the file is corrupt.  */\n\t  if ((signed long) length <= 0 || section_begin < start)\n\t    {\n\t      warn (_(\"Corrupt unit length (0x%s) found in section %s\\n\"),\n\t\t    dwarf_vmatoa (\"x\", length), section->name);\n\t      return 0;\n\t    }\n\t}\n\n      if (num_units == 0)\n\t{\n\t  error (_(\"No comp units in %s section ?\\n\"), section->name);\n\t  return 0;\n\t}\n\n      /* Then allocate an array to hold the information.  */\n      debug_information = (debug_info *) cmalloc (num_units,\n\t\t\t\t\t\t  sizeof (* debug_information));\n      if (debug_information == NULL)\n\t{\n\t  error (_(\"Not enough memory for a debug info array of %u entries\\n\"),\n\t\t num_units);\n\t  alloc_num_debug_info_entries = num_debug_info_entries = 0;\n\t  return 0;\n\t}\n      /* PR 17531: file: 92ca3797.\n\t We cannot rely upon the debug_information array being initialised\n\t before it is used.  A corrupt file could easily contain references\n\t to a unit for which information has not been made available.  So\n\t we ensure that the array is zeroed here.  */\n      memset (debug_information, 0, num_units * sizeof (*debug_information));\n\n      alloc_num_debug_info_entries = num_units;\n    }\n\n  if (!do_loc)\n    {\n      if (dwarf_start_die == 0)\n\tprintf (_(\"Contents of the %s section:\\n\\n\"), section->name);\n\n      load_debug_section (str, file);\n      load_debug_section (line_str, file);\n      load_debug_section (str_dwo, file);\n      load_debug_section (str_index, file);\n      load_debug_section (str_index_dwo, file);\n      load_debug_section (debug_addr, file);\n    }\n\n  load_debug_section (abbrev_sec, file);\n  if (debug_displays [abbrev_sec].section.start == NULL)\n    {\n      warn (_(\"Unable to locate %s section!\\n\"),\n\t    debug_displays [abbrev_sec].section.name);\n      return 0;\n    }\n\n  for (section_begin = start, unit = 0; start < end; unit++)\n    {\n      DWARF2_Internal_CompUnit compunit;\n      unsigned char *hdrptr;\n      unsigned char *tags;\n      int level, last_level, saved_level;\n      dwarf_vma cu_offset;\n      unsigned int offset_size;\n      int initial_length_size;\n      dwarf_vma signature_high = 0;\n      dwarf_vma signature_low = 0;\n      dwarf_vma type_offset = 0;\n      struct cu_tu_set *this_set;\n      dwarf_vma abbrev_base;\n      size_t abbrev_size;\n\n      hdrptr = start;\n\n      SAFE_BYTE_GET_AND_INC (compunit.cu_length, hdrptr, 4, end);\n\n      if (compunit.cu_length == 0xffffffff)\n\t{\n\t  SAFE_BYTE_GET_AND_INC (compunit.cu_length, hdrptr, 8, end);\n\t  offset_size = 8;\n\t  initial_length_size = 12;\n\t}\n      else\n\t{\n\t  offset_size = 4;\n\t  initial_length_size = 4;\n\t}\n\n      SAFE_BYTE_GET_AND_INC (compunit.cu_version, hdrptr, 2, end);\n\n      cu_offset = start - section_begin;\n\n      this_set = find_cu_tu_set_v2 (cu_offset, do_types);\n\n      if (compunit.cu_version < 5)\n\t{\n\t  compunit.cu_unit_type = DW_UT_compile;\n\t  /* Initialize it due to a false compiler warning.  */\n\t  compunit.cu_pointer_size = -1;\n\t}\n      else\n\t{\n\t  SAFE_BYTE_GET_AND_INC (compunit.cu_unit_type, hdrptr, 1, end);\n\t  do_types = (compunit.cu_unit_type == DW_UT_type);\n\n\t  SAFE_BYTE_GET_AND_INC (compunit.cu_pointer_size, hdrptr, 1, end);\n\t}\n\n      SAFE_BYTE_GET_AND_INC (compunit.cu_abbrev_offset, hdrptr, offset_size, end);\n\n      if (this_set == NULL)\n\t{\n\t  abbrev_base = 0;\n\t  abbrev_size = debug_displays [abbrev_sec].section.size;\n\t}\n      else\n\t{\n\t  abbrev_base = this_set->section_offsets [DW_SECT_ABBREV];\n\t  abbrev_size = this_set->section_sizes [DW_SECT_ABBREV];\n\t}\n\n      if (compunit.cu_version < 5)\n\tSAFE_BYTE_GET_AND_INC (compunit.cu_pointer_size, hdrptr, 1, end);\n\n      /* PR 17512: file: 001-108546-0.001:0.1.  */\n      if (compunit.cu_pointer_size < 2 || compunit.cu_pointer_size > 8)\n\t{\n\t  warn (_(\"Invalid pointer size (%d) in compunit header, using %d instead\\n\"),\n\t\tcompunit.cu_pointer_size, offset_size);\n\t  compunit.cu_pointer_size = offset_size;\n\t}\n\n      if (do_types)\n\t{\n\t  SAFE_BYTE_GET64 (hdrptr, &signature_high, &signature_low, end);\n\t  hdrptr += 8;\n\t  SAFE_BYTE_GET_AND_INC (type_offset, hdrptr, offset_size, end);\n\t}\n\n      if ((do_loc || do_debug_loc || do_debug_ranges)\n\t  && num_debug_info_entries == 0\n\t  && ! do_types)\n\t{\n\t  debug_information [unit].cu_offset = cu_offset;\n\t  debug_information [unit].pointer_size\n\t    = compunit.cu_pointer_size;\n\t  debug_information [unit].offset_size = offset_size;\n\t  debug_information [unit].dwarf_version = compunit.cu_version;\n\t  debug_information [unit].base_address = 0;\n\t  debug_information [unit].addr_base = DEBUG_INFO_UNAVAILABLE;\n\t  debug_information [unit].ranges_base = DEBUG_INFO_UNAVAILABLE;\n\t  debug_information [unit].loc_offsets = NULL;\n\t  debug_information [unit].have_frame_base = NULL;\n\t  debug_information [unit].max_loc_offsets = 0;\n\t  debug_information [unit].num_loc_offsets = 0;\n\t  debug_information [unit].range_lists = NULL;\n\t  debug_information [unit].max_range_lists= 0;\n\t  debug_information [unit].num_range_lists = 0;\n\t}\n\n      if (!do_loc && dwarf_start_die == 0)\n\t{\n\t  printf (_(\"  Compilation Unit @ offset 0x%s:\\n\"),\n\t\t  dwarf_vmatoa (\"x\", cu_offset));\n\t  printf (_(\"   Length:        0x%s (%s)\\n\"),\n\t\t  dwarf_vmatoa (\"x\", compunit.cu_length),\n\t\t  offset_size == 8 ? \"64-bit\" : \"32-bit\");\n\t  printf (_(\"   Version:       %d\\n\"), compunit.cu_version);\n\t  printf (_(\"   Abbrev Offset: 0x%s\\n\"),\n\t\t  dwarf_vmatoa (\"x\", compunit.cu_abbrev_offset));\n\t  printf (_(\"   Pointer Size:  %d\\n\"), compunit.cu_pointer_size);\n\t  if (do_types)\n\t    {\n\t      char buf[64];\n\n\t      printf (_(\"   Signature:     0x%s\\n\"),\n\t\t      dwarf_vmatoa64 (signature_high, signature_low,\n\t\t\t\t      buf, sizeof (buf)));\n\t      printf (_(\"   Type Offset:   0x%s\\n\"),\n\t\t      dwarf_vmatoa (\"x\", type_offset));\n\t    }\n\t  if (this_set != NULL)\n\t    {\n\t      dwarf_vma *offsets = this_set->section_offsets;\n\t      size_t *sizes = this_set->section_sizes;\n\n\t      printf (_(\"   Section contributions:\\n\"));\n\t      printf (_(\"    .debug_abbrev.dwo:       0x%s  0x%s\\n\"),\n\t\t      dwarf_vmatoa (\"x\", offsets [DW_SECT_ABBREV]),\n\t\t      dwarf_vmatoa (\"x\", sizes [DW_SECT_ABBREV]));\n\t      printf (_(\"    .debug_line.dwo:         0x%s  0x%s\\n\"),\n\t\t      dwarf_vmatoa (\"x\", offsets [DW_SECT_LINE]),\n\t\t      dwarf_vmatoa (\"x\", sizes [DW_SECT_LINE]));\n\t      printf (_(\"    .debug_loc.dwo:          0x%s  0x%s\\n\"),\n\t\t      dwarf_vmatoa (\"x\", offsets [DW_SECT_LOC]),\n\t\t      dwarf_vmatoa (\"x\", sizes [DW_SECT_LOC]));\n\t      printf (_(\"    .debug_str_offsets.dwo:  0x%s  0x%s\\n\"),\n\t\t      dwarf_vmatoa (\"x\", offsets [DW_SECT_STR_OFFSETS]),\n\t\t      dwarf_vmatoa (\"x\", sizes [DW_SECT_STR_OFFSETS]));\n\t    }\n\t}\n\n      if (cu_offset + compunit.cu_length + initial_length_size\n\t  > section->size)\n\t{\n\t  warn (_(\"Debug info is corrupted, length of CU at %s\"\n\t\t  \" extends beyond end of section (length = %s)\\n\"),\n\t\tdwarf_vmatoa (\"x\", cu_offset),\n\t\tdwarf_vmatoa (\"x\", compunit.cu_length));\n\t  num_units = unit;\n\t  break;\n\t}\n      tags = hdrptr;\n      start += compunit.cu_length + initial_length_size;\n\n      if (start > end)\n\t{\n\t  warn (_(\"Debug info is corrupt.  CU at %s extends beyond end of section\"),\n\t\tdwarf_vmatoa (\"x\", cu_offset));\n\t  start = end;\n\t}\n\n      if (compunit.cu_version < 2 || compunit.cu_version > 5)\n\t{\n\t  warn (_(\"CU at offset %s contains corrupt or \"\n\t\t  \"unsupported version number: %d.\\n\"),\n\t\tdwarf_vmatoa (\"x\", cu_offset), compunit.cu_version);\n\t  continue;\n\t}\n\n      if (compunit.cu_unit_type != DW_UT_compile\n\t  && compunit.cu_unit_type != DW_UT_type)\n\t{\n\t  warn (_(\"CU at offset %s contains corrupt or \"\n\t\t  \"unsupported unit type: %d.\\n\"),\n\t\tdwarf_vmatoa (\"x\", cu_offset), compunit.cu_unit_type);\n\t  continue;\n\t}\n\n      free_abbrevs ();\n\n      /* Process the abbrevs used by this compilation unit.  */\n      if (compunit.cu_abbrev_offset >= abbrev_size)\n\twarn (_(\"Debug info is corrupted, abbrev offset (%lx) is larger than abbrev section size (%lx)\\n\"),\n\t      (unsigned long) compunit.cu_abbrev_offset,\n\t      (unsigned long) abbrev_size);\n      /* PR 17531: file:4bcd9ce9.  */\n      else if ((abbrev_base + abbrev_size)\n\t       > debug_displays [abbrev_sec].section.size)\n\twarn (_(\"Debug info is corrupted, abbrev size (%lx) is larger than abbrev section size (%lx)\\n\"),\n\t      (unsigned long) abbrev_base + abbrev_size,\n\t      (unsigned long) debug_displays [abbrev_sec].section.size);\n      else\n\tprocess_abbrev_section\n\t  (((unsigned char *) debug_displays [abbrev_sec].section.start\n\t    + abbrev_base + compunit.cu_abbrev_offset),\n\t   ((unsigned char *) debug_displays [abbrev_sec].section.start\n\t    + abbrev_base + abbrev_size));\n\n      level = 0;\n      last_level = level;\n      saved_level = -1;\n      while (tags < start)\n\t{\n\t  unsigned int bytes_read;\n\t  unsigned long abbrev_number;\n\t  unsigned long die_offset;\n\t  abbrev_entry *entry;\n\t  abbrev_attr *attr;\n\t  int do_printing = 1;\n\n\t  die_offset = tags - section_begin;\n\n\t  abbrev_number = read_uleb128 (tags, & bytes_read, start);\n\t  tags += bytes_read;\n\n\t  /* A null DIE marks the end of a list of siblings or it may also be\n\t     a section padding.  */\n\t  if (abbrev_number == 0)\n\t    {\n\t      /* Check if it can be a section padding for the last CU.  */\n\t      if (level == 0 && start == end)\n\t\t{\n\t\t  unsigned char *chk;\n\n\t\t  for (chk = tags; chk < start; chk++)\n\t\t    if (*chk != 0)\n\t\t      break;\n\t\t  if (chk == start)\n\t\t    break;\n\t\t}\n\n\t      if (!do_loc && die_offset >= dwarf_start_die\n\t\t  && (dwarf_cutoff_level == -1\n\t\t      || level < dwarf_cutoff_level))\n\t\tprintf (_(\" <%d><%lx>: Abbrev Number: 0\\n\"),\n\t\t\tlevel, die_offset);\n\n\t      --level;\n\t      if (level < 0)\n\t\t{\n\t\t  static unsigned num_bogus_warns = 0;\n\n\t\t  if (num_bogus_warns < 3)\n\t\t    {\n\t\t      warn (_(\"Bogus end-of-siblings marker detected at offset %lx in %s section\\n\"),\n\t\t\t    die_offset, section->name);\n\t\t      num_bogus_warns ++;\n\t\t      if (num_bogus_warns == 3)\n\t\t\twarn (_(\"Further warnings about bogus end-of-sibling markers suppressed\\n\"));\n\t\t    }\n\t\t}\n\t      if (dwarf_start_die != 0 && level < saved_level)\n\t\treturn 1;\n\t      continue;\n\t    }\n\n\t  if (!do_loc)\n\t    {\n\t      if (dwarf_start_die != 0 && die_offset < dwarf_start_die)\n\t\tdo_printing = 0;\n\t      else\n\t\t{\n\t\t  if (dwarf_start_die != 0 && die_offset == dwarf_start_die)\n\t\t    saved_level = level;\n\t\t  do_printing = (dwarf_cutoff_level == -1\n\t\t\t\t || level < dwarf_cutoff_level);\n\t\t  if (do_printing)\n\t\t    printf (_(\" <%d><%lx>: Abbrev Number: %lu\"),\n\t\t\t    level, die_offset, abbrev_number);\n\t\t  else if (dwarf_cutoff_level == -1\n\t\t\t   || last_level < dwarf_cutoff_level)\n\t\t    printf (_(\" <%d><%lx>: ...\\n\"), level, die_offset);\n\t\t  last_level = level;\n\t\t}\n\t    }\n\n\t  /* Scan through the abbreviation list until we reach the\n\t     correct entry.  */\n\t  for (entry = first_abbrev;\n\t       entry && entry->entry != abbrev_number;\n\t       entry = entry->next)\n\t    continue;\n\n\t  if (entry == NULL)\n\t    {\n\t      if (!do_loc && do_printing)\n\t\t{\n\t\t  printf (\"\\n\");\n\t\t  fflush (stdout);\n\t\t}\n\t      warn (_(\"DIE at offset 0x%lx refers to abbreviation number %lu which does not exist\\n\"),\n\t\t    die_offset, abbrev_number);\n\t      return 0;\n\t    }\n\n\t  if (!do_loc && do_printing)\n\t    printf (\" (%s)\\n\", get_TAG_name (entry->tag));\n\n\t  switch (entry->tag)\n\t    {\n\t    default:\n\t      need_base_address = 0;\n\t      break;\n\t    case DW_TAG_compile_unit:\n\t      need_base_address = 1;\n\t      break;\n\t    case DW_TAG_entry_point:\n\t    case DW_TAG_subprogram:\n\t      need_base_address = 0;\n\t      /* Assuming that there is no DW_AT_frame_base.  */\n\t      have_frame_base = 0;\n\t      break;\n\t    }\n\n\t  debug_info *debug_info_p =\n\t    (debug_information && unit < alloc_num_debug_info_entries)\n\t    ? debug_information + unit : NULL;\n\n\t  assert (!debug_info_p\n\t\t  || (debug_info_p->num_loc_offsets\n\t\t      == debug_info_p->num_loc_views));\n\n\t  for (attr = entry->first_attr;\n\t       attr && attr->attribute;\n\t       attr = attr->next)\n\t    {\n\t      if (! do_loc && do_printing)\n\t\t/* Show the offset from where the tag was extracted.  */\n\t\tprintf (\"    <%lx>\", (unsigned long)(tags - section_begin));\n\n\t      tags = read_and_display_attr (attr->attribute,\n\t\t\t\t\t    attr->form,\n\t\t\t\t\t    attr->implicit_const,\n\t\t\t\t\t    tags,\n\t\t\t\t\t    end,\n\t\t\t\t\t    cu_offset,\n\t\t\t\t\t    compunit.cu_pointer_size,\n\t\t\t\t\t    offset_size,\n\t\t\t\t\t    compunit.cu_version,\n\t\t\t\t\t    debug_info_p,\n\t\t\t\t\t    do_loc || ! do_printing,\n\t\t\t\t\t    section,\n\t\t\t\t\t    this_set);\n\t    }\n\n\t  /* If a locview attribute appears before a location one,\n\t     make sure we don't associate it with an earlier\n\t     loclist. */\n\t  if (debug_info_p)\n\t    switch (debug_info_p->num_loc_offsets - debug_info_p->num_loc_views)\n\t      {\n\t      case 1:\n\t\tdebug_info_p->loc_views [debug_info_p->num_loc_views] = vm1;\n\t\tdebug_info_p->num_loc_views++;\n\t\tassert (debug_info_p->num_loc_views\n\t\t\t== debug_info_p->num_loc_offsets);\n\t\tbreak;\n\n\t      case 0:\n\t\tbreak;\n\n\t      case -1:\n\t\twarn(_(\"DIE has locviews without loclist\\n\"));\n\t\tdebug_info_p->num_loc_views--;\n\t\tbreak;\n\n\t      default:\n\t\tassert (0);\n\t    }\n\n\t  if (entry->children)\n\t    ++level;\n\t}\n    }\n\n  /* Set num_debug_info_entries here so that it can be used to check if\n     we need to process .debug_loc and .debug_ranges sections.  */\n  if ((do_loc || do_debug_loc || do_debug_ranges)\n      && num_debug_info_entries == 0\n      && ! do_types)\n    {\n      if (num_units > alloc_num_debug_info_entries)\n\tnum_debug_info_entries = alloc_num_debug_info_entries;\n      else\n\tnum_debug_info_entries = num_units;\n    }\n\n  if (!do_loc)\n    printf (\"\\n\");\n\n  return 1;\n}",
        "func": "static int\nprocess_debug_info (struct dwarf_section *section,\n\t\t    void *file,\n\t\t    enum dwarf_section_display_enum abbrev_sec,\n\t\t    int do_loc,\n\t\t    int do_types)\n{\n  unsigned char *start = section->start;\n  unsigned char *end = start + section->size;\n  unsigned char *section_begin;\n  unsigned int unit;\n  unsigned int num_units = 0;\n\n  if ((do_loc || do_debug_loc || do_debug_ranges)\n      && num_debug_info_entries == 0\n      && ! do_types)\n    {\n      dwarf_vma length;\n\n      /* First scan the section to get the number of comp units.  */\n      for (section_begin = start, num_units = 0; section_begin < end;\n\t   num_units ++)\n\t{\n\t  /* Read the first 4 bytes.  For a 32-bit DWARF section, this\n\t     will be the length.  For a 64-bit DWARF section, it'll be\n\t     the escape code 0xffffffff followed by an 8 byte length.  */\n\t  SAFE_BYTE_GET (length, section_begin, 4, end);\n\n\t  if (length == 0xffffffff)\n\t    {\n\t      SAFE_BYTE_GET (length, section_begin + 4, 8, end);\n\t      section_begin += length + 12;\n\t    }\n\t  else if (length >= 0xfffffff0 && length < 0xffffffff)\n\t    {\n\t      warn (_(\"Reserved length value (0x%s) found in section %s\\n\"),\n\t\t    dwarf_vmatoa (\"x\", length), section->name);\n\t      return 0;\n\t    }\n\t  else\n\t    section_begin += length + 4;\n\n\t  /* Negative values are illegal, they may even cause infinite\n\t     looping.  This can happen if we can't accurately apply\n\t     relocations to an object file, or if the file is corrupt.  */\n\t  if ((signed long) length <= 0 || section_begin < start)\n\t    {\n\t      warn (_(\"Corrupt unit length (0x%s) found in section %s\\n\"),\n\t\t    dwarf_vmatoa (\"x\", length), section->name);\n\t      return 0;\n\t    }\n\t}\n\n      if (num_units == 0)\n\t{\n\t  error (_(\"No comp units in %s section ?\\n\"), section->name);\n\t  return 0;\n\t}\n\n      /* Then allocate an array to hold the information.  */\n      debug_information = (debug_info *) cmalloc (num_units,\n\t\t\t\t\t\t  sizeof (* debug_information));\n      if (debug_information == NULL)\n\t{\n\t  error (_(\"Not enough memory for a debug info array of %u entries\\n\"),\n\t\t num_units);\n\t  alloc_num_debug_info_entries = num_debug_info_entries = 0;\n\t  return 0;\n\t}\n      /* PR 17531: file: 92ca3797.\n\t We cannot rely upon the debug_information array being initialised\n\t before it is used.  A corrupt file could easily contain references\n\t to a unit for which information has not been made available.  So\n\t we ensure that the array is zeroed here.  */\n      memset (debug_information, 0, num_units * sizeof (*debug_information));\n\n      alloc_num_debug_info_entries = num_units;\n    }\n\n  if (!do_loc)\n    {\n      if (dwarf_start_die == 0)\n\tprintf (_(\"Contents of the %s section:\\n\\n\"), section->name);\n\n      load_debug_section (str, file);\n      load_debug_section (line_str, file);\n      load_debug_section (str_dwo, file);\n      load_debug_section (str_index, file);\n      load_debug_section (str_index_dwo, file);\n      load_debug_section (debug_addr, file);\n    }\n\n  load_debug_section (abbrev_sec, file);\n  if (debug_displays [abbrev_sec].section.start == NULL)\n    {\n      warn (_(\"Unable to locate %s section!\\n\"),\n\t    debug_displays [abbrev_sec].section.name);\n      return 0;\n    }\n\n  for (section_begin = start, unit = 0; start < end; unit++)\n    {\n      DWARF2_Internal_CompUnit compunit;\n      unsigned char *hdrptr;\n      unsigned char *tags;\n      int level, last_level, saved_level;\n      dwarf_vma cu_offset;\n      unsigned int offset_size;\n      unsigned int initial_length_size;\n      dwarf_vma signature_high = 0;\n      dwarf_vma signature_low = 0;\n      dwarf_vma type_offset = 0;\n      struct cu_tu_set *this_set;\n      dwarf_vma abbrev_base;\n      size_t abbrev_size;\n\n      hdrptr = start;\n\n      SAFE_BYTE_GET_AND_INC (compunit.cu_length, hdrptr, 4, end);\n\n      if (compunit.cu_length == 0xffffffff)\n\t{\n\t  SAFE_BYTE_GET_AND_INC (compunit.cu_length, hdrptr, 8, end);\n\t  offset_size = 8;\n\t  initial_length_size = 12;\n\t}\n      else\n\t{\n\t  offset_size = 4;\n\t  initial_length_size = 4;\n\t}\n\n      SAFE_BYTE_GET_AND_INC (compunit.cu_version, hdrptr, 2, end);\n\n      cu_offset = start - section_begin;\n\n      this_set = find_cu_tu_set_v2 (cu_offset, do_types);\n\n      if (compunit.cu_version < 5)\n\t{\n\t  compunit.cu_unit_type = DW_UT_compile;\n\t  /* Initialize it due to a false compiler warning.  */\n\t  compunit.cu_pointer_size = -1;\n\t}\n      else\n\t{\n\t  SAFE_BYTE_GET_AND_INC (compunit.cu_unit_type, hdrptr, 1, end);\n\t  do_types = (compunit.cu_unit_type == DW_UT_type);\n\n\t  SAFE_BYTE_GET_AND_INC (compunit.cu_pointer_size, hdrptr, 1, end);\n\t}\n\n      SAFE_BYTE_GET_AND_INC (compunit.cu_abbrev_offset, hdrptr, offset_size, end);\n\n      if (this_set == NULL)\n\t{\n\t  abbrev_base = 0;\n\t  abbrev_size = debug_displays [abbrev_sec].section.size;\n\t}\n      else\n\t{\n\t  abbrev_base = this_set->section_offsets [DW_SECT_ABBREV];\n\t  abbrev_size = this_set->section_sizes [DW_SECT_ABBREV];\n\t}\n\n      if (compunit.cu_version < 5)\n\tSAFE_BYTE_GET_AND_INC (compunit.cu_pointer_size, hdrptr, 1, end);\n\n      /* PR 17512: file: 001-108546-0.001:0.1.  */\n      if (compunit.cu_pointer_size < 2 || compunit.cu_pointer_size > 8)\n\t{\n\t  warn (_(\"Invalid pointer size (%d) in compunit header, using %d instead\\n\"),\n\t\tcompunit.cu_pointer_size, offset_size);\n\t  compunit.cu_pointer_size = offset_size;\n\t}\n\n      if (do_types)\n\t{\n\t  SAFE_BYTE_GET64 (hdrptr, &signature_high, &signature_low, end);\n\t  hdrptr += 8;\n\t  SAFE_BYTE_GET_AND_INC (type_offset, hdrptr, offset_size, end);\n\t}\n\n      if ((do_loc || do_debug_loc || do_debug_ranges)\n\t  && num_debug_info_entries == 0\n\t  && ! do_types)\n\t{\n\t  debug_information [unit].cu_offset = cu_offset;\n\t  debug_information [unit].pointer_size\n\t    = compunit.cu_pointer_size;\n\t  debug_information [unit].offset_size = offset_size;\n\t  debug_information [unit].dwarf_version = compunit.cu_version;\n\t  debug_information [unit].base_address = 0;\n\t  debug_information [unit].addr_base = DEBUG_INFO_UNAVAILABLE;\n\t  debug_information [unit].ranges_base = DEBUG_INFO_UNAVAILABLE;\n\t  debug_information [unit].loc_offsets = NULL;\n\t  debug_information [unit].have_frame_base = NULL;\n\t  debug_information [unit].max_loc_offsets = 0;\n\t  debug_information [unit].num_loc_offsets = 0;\n\t  debug_information [unit].range_lists = NULL;\n\t  debug_information [unit].max_range_lists= 0;\n\t  debug_information [unit].num_range_lists = 0;\n\t}\n\n      if (!do_loc && dwarf_start_die == 0)\n\t{\n\t  printf (_(\"  Compilation Unit @ offset 0x%s:\\n\"),\n\t\t  dwarf_vmatoa (\"x\", cu_offset));\n\t  printf (_(\"   Length:        0x%s (%s)\\n\"),\n\t\t  dwarf_vmatoa (\"x\", compunit.cu_length),\n\t\t  offset_size == 8 ? \"64-bit\" : \"32-bit\");\n\t  printf (_(\"   Version:       %d\\n\"), compunit.cu_version);\n\t  printf (_(\"   Abbrev Offset: 0x%s\\n\"),\n\t\t  dwarf_vmatoa (\"x\", compunit.cu_abbrev_offset));\n\t  printf (_(\"   Pointer Size:  %d\\n\"), compunit.cu_pointer_size);\n\t  if (do_types)\n\t    {\n\t      char buf[64];\n\n\t      printf (_(\"   Signature:     0x%s\\n\"),\n\t\t      dwarf_vmatoa64 (signature_high, signature_low,\n\t\t\t\t      buf, sizeof (buf)));\n\t      printf (_(\"   Type Offset:   0x%s\\n\"),\n\t\t      dwarf_vmatoa (\"x\", type_offset));\n\t    }\n\t  if (this_set != NULL)\n\t    {\n\t      dwarf_vma *offsets = this_set->section_offsets;\n\t      size_t *sizes = this_set->section_sizes;\n\n\t      printf (_(\"   Section contributions:\\n\"));\n\t      printf (_(\"    .debug_abbrev.dwo:       0x%s  0x%s\\n\"),\n\t\t      dwarf_vmatoa (\"x\", offsets [DW_SECT_ABBREV]),\n\t\t      dwarf_vmatoa (\"x\", sizes [DW_SECT_ABBREV]));\n\t      printf (_(\"    .debug_line.dwo:         0x%s  0x%s\\n\"),\n\t\t      dwarf_vmatoa (\"x\", offsets [DW_SECT_LINE]),\n\t\t      dwarf_vmatoa (\"x\", sizes [DW_SECT_LINE]));\n\t      printf (_(\"    .debug_loc.dwo:          0x%s  0x%s\\n\"),\n\t\t      dwarf_vmatoa (\"x\", offsets [DW_SECT_LOC]),\n\t\t      dwarf_vmatoa (\"x\", sizes [DW_SECT_LOC]));\n\t      printf (_(\"    .debug_str_offsets.dwo:  0x%s  0x%s\\n\"),\n\t\t      dwarf_vmatoa (\"x\", offsets [DW_SECT_STR_OFFSETS]),\n\t\t      dwarf_vmatoa (\"x\", sizes [DW_SECT_STR_OFFSETS]));\n\t    }\n\t}\n\n      if (cu_offset + compunit.cu_length + initial_length_size\n\t  > section->size)\n\t{\n\t  warn (_(\"Debug info is corrupted, length of CU at %s\"\n\t\t  \" extends beyond end of section (length = %s)\\n\"),\n\t\tdwarf_vmatoa (\"x\", cu_offset),\n\t\tdwarf_vmatoa (\"x\", compunit.cu_length));\n\t  num_units = unit;\n\t  break;\n\t}\n      else if (compunit.cu_length + initial_length_size < initial_length_size)\n\t{\n\t  warn (_(\"Debug info is corrupted, length of CU at %s is negative (%s)\\n\"),\n\t\tdwarf_vmatoa (\"x\", cu_offset),\n\t\tdwarf_vmatoa (\"x\", compunit.cu_length));\n\t  num_units = unit;\n\t  break;\n\t}\n\n      tags = hdrptr;\n      start += compunit.cu_length + initial_length_size;\n\n      if (start > end)\n\t{\n\t  warn (_(\"Debug info is corrupt.  CU at %s extends beyond end of section\"),\n\t\tdwarf_vmatoa (\"x\", cu_offset));\n\t  start = end;\n\t}\n\n      if (compunit.cu_version < 2 || compunit.cu_version > 5)\n\t{\n\t  warn (_(\"CU at offset %s contains corrupt or \"\n\t\t  \"unsupported version number: %d.\\n\"),\n\t\tdwarf_vmatoa (\"x\", cu_offset), compunit.cu_version);\n\t  continue;\n\t}\n\n      if (compunit.cu_unit_type != DW_UT_compile\n\t  && compunit.cu_unit_type != DW_UT_type)\n\t{\n\t  warn (_(\"CU at offset %s contains corrupt or \"\n\t\t  \"unsupported unit type: %d.\\n\"),\n\t\tdwarf_vmatoa (\"x\", cu_offset), compunit.cu_unit_type);\n\t  continue;\n\t}\n\n      free_abbrevs ();\n\n      /* Process the abbrevs used by this compilation unit.  */\n      if (compunit.cu_abbrev_offset >= abbrev_size)\n\twarn (_(\"Debug info is corrupted, abbrev offset (%lx) is larger than abbrev section size (%lx)\\n\"),\n\t      (unsigned long) compunit.cu_abbrev_offset,\n\t      (unsigned long) abbrev_size);\n      /* PR 17531: file:4bcd9ce9.  */\n      else if ((abbrev_base + abbrev_size)\n\t       > debug_displays [abbrev_sec].section.size)\n\twarn (_(\"Debug info is corrupted, abbrev size (%lx) is larger than abbrev section size (%lx)\\n\"),\n\t      (unsigned long) abbrev_base + abbrev_size,\n\t      (unsigned long) debug_displays [abbrev_sec].section.size);\n      else\n\tprocess_abbrev_section\n\t  (((unsigned char *) debug_displays [abbrev_sec].section.start\n\t    + abbrev_base + compunit.cu_abbrev_offset),\n\t   ((unsigned char *) debug_displays [abbrev_sec].section.start\n\t    + abbrev_base + abbrev_size));\n\n      level = 0;\n      last_level = level;\n      saved_level = -1;\n      while (tags < start)\n\t{\n\t  unsigned int bytes_read;\n\t  unsigned long abbrev_number;\n\t  unsigned long die_offset;\n\t  abbrev_entry *entry;\n\t  abbrev_attr *attr;\n\t  int do_printing = 1;\n\n\t  die_offset = tags - section_begin;\n\n\t  abbrev_number = read_uleb128 (tags, & bytes_read, start);\n\t  tags += bytes_read;\n\n\t  /* A null DIE marks the end of a list of siblings or it may also be\n\t     a section padding.  */\n\t  if (abbrev_number == 0)\n\t    {\n\t      /* Check if it can be a section padding for the last CU.  */\n\t      if (level == 0 && start == end)\n\t\t{\n\t\t  unsigned char *chk;\n\n\t\t  for (chk = tags; chk < start; chk++)\n\t\t    if (*chk != 0)\n\t\t      break;\n\t\t  if (chk == start)\n\t\t    break;\n\t\t}\n\n\t      if (!do_loc && die_offset >= dwarf_start_die\n\t\t  && (dwarf_cutoff_level == -1\n\t\t      || level < dwarf_cutoff_level))\n\t\tprintf (_(\" <%d><%lx>: Abbrev Number: 0\\n\"),\n\t\t\tlevel, die_offset);\n\n\t      --level;\n\t      if (level < 0)\n\t\t{\n\t\t  static unsigned num_bogus_warns = 0;\n\n\t\t  if (num_bogus_warns < 3)\n\t\t    {\n\t\t      warn (_(\"Bogus end-of-siblings marker detected at offset %lx in %s section\\n\"),\n\t\t\t    die_offset, section->name);\n\t\t      num_bogus_warns ++;\n\t\t      if (num_bogus_warns == 3)\n\t\t\twarn (_(\"Further warnings about bogus end-of-sibling markers suppressed\\n\"));\n\t\t    }\n\t\t}\n\t      if (dwarf_start_die != 0 && level < saved_level)\n\t\treturn 1;\n\t      continue;\n\t    }\n\n\t  if (!do_loc)\n\t    {\n\t      if (dwarf_start_die != 0 && die_offset < dwarf_start_die)\n\t\tdo_printing = 0;\n\t      else\n\t\t{\n\t\t  if (dwarf_start_die != 0 && die_offset == dwarf_start_die)\n\t\t    saved_level = level;\n\t\t  do_printing = (dwarf_cutoff_level == -1\n\t\t\t\t || level < dwarf_cutoff_level);\n\t\t  if (do_printing)\n\t\t    printf (_(\" <%d><%lx>: Abbrev Number: %lu\"),\n\t\t\t    level, die_offset, abbrev_number);\n\t\t  else if (dwarf_cutoff_level == -1\n\t\t\t   || last_level < dwarf_cutoff_level)\n\t\t    printf (_(\" <%d><%lx>: ...\\n\"), level, die_offset);\n\t\t  last_level = level;\n\t\t}\n\t    }\n\n\t  /* Scan through the abbreviation list until we reach the\n\t     correct entry.  */\n\t  for (entry = first_abbrev;\n\t       entry && entry->entry != abbrev_number;\n\t       entry = entry->next)\n\t    continue;\n\n\t  if (entry == NULL)\n\t    {\n\t      if (!do_loc && do_printing)\n\t\t{\n\t\t  printf (\"\\n\");\n\t\t  fflush (stdout);\n\t\t}\n\t      warn (_(\"DIE at offset 0x%lx refers to abbreviation number %lu which does not exist\\n\"),\n\t\t    die_offset, abbrev_number);\n\t      return 0;\n\t    }\n\n\t  if (!do_loc && do_printing)\n\t    printf (\" (%s)\\n\", get_TAG_name (entry->tag));\n\n\t  switch (entry->tag)\n\t    {\n\t    default:\n\t      need_base_address = 0;\n\t      break;\n\t    case DW_TAG_compile_unit:\n\t      need_base_address = 1;\n\t      break;\n\t    case DW_TAG_entry_point:\n\t    case DW_TAG_subprogram:\n\t      need_base_address = 0;\n\t      /* Assuming that there is no DW_AT_frame_base.  */\n\t      have_frame_base = 0;\n\t      break;\n\t    }\n\n\t  debug_info *debug_info_p =\n\t    (debug_information && unit < alloc_num_debug_info_entries)\n\t    ? debug_information + unit : NULL;\n\n\t  assert (!debug_info_p\n\t\t  || (debug_info_p->num_loc_offsets\n\t\t      == debug_info_p->num_loc_views));\n\n\t  for (attr = entry->first_attr;\n\t       attr && attr->attribute;\n\t       attr = attr->next)\n\t    {\n\t      if (! do_loc && do_printing)\n\t\t/* Show the offset from where the tag was extracted.  */\n\t\tprintf (\"    <%lx>\", (unsigned long)(tags - section_begin));\n\n\t      tags = read_and_display_attr (attr->attribute,\n\t\t\t\t\t    attr->form,\n\t\t\t\t\t    attr->implicit_const,\n\t\t\t\t\t    tags,\n\t\t\t\t\t    end,\n\t\t\t\t\t    cu_offset,\n\t\t\t\t\t    compunit.cu_pointer_size,\n\t\t\t\t\t    offset_size,\n\t\t\t\t\t    compunit.cu_version,\n\t\t\t\t\t    debug_info_p,\n\t\t\t\t\t    do_loc || ! do_printing,\n\t\t\t\t\t    section,\n\t\t\t\t\t    this_set);\n\t    }\n\n\t  /* If a locview attribute appears before a location one,\n\t     make sure we don't associate it with an earlier\n\t     loclist. */\n\t  if (debug_info_p)\n\t    switch (debug_info_p->num_loc_offsets - debug_info_p->num_loc_views)\n\t      {\n\t      case 1:\n\t\tdebug_info_p->loc_views [debug_info_p->num_loc_views] = vm1;\n\t\tdebug_info_p->num_loc_views++;\n\t\tassert (debug_info_p->num_loc_views\n\t\t\t== debug_info_p->num_loc_offsets);\n\t\tbreak;\n\n\t      case 0:\n\t\tbreak;\n\n\t      case -1:\n\t\twarn(_(\"DIE has locviews without loclist\\n\"));\n\t\tdebug_info_p->num_loc_views--;\n\t\tbreak;\n\n\t      default:\n\t\tassert (0);\n\t    }\n\n\t  if (entry->children)\n\t    ++level;\n\t}\n    }\n\n  /* Set num_debug_info_entries here so that it can be used to check if\n     we need to process .debug_loc and .debug_ranges sections.  */\n  if ((do_loc || do_debug_loc || do_debug_ranges)\n      && num_debug_info_entries == 0\n      && ! do_types)\n    {\n      if (num_units > alloc_num_debug_info_entries)\n\tnum_debug_info_entries = alloc_num_debug_info_entries;\n      else\n\tnum_debug_info_entries = num_units;\n    }\n\n  if (!do_loc)\n    printf (\"\\n\");\n\n  return 1;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -106,7 +106,7 @@\n       int level, last_level, saved_level;\n       dwarf_vma cu_offset;\n       unsigned int offset_size;\n-      int initial_length_size;\n+      unsigned int initial_length_size;\n       dwarf_vma signature_high = 0;\n       dwarf_vma signature_low = 0;\n       dwarf_vma type_offset = 0;\n@@ -254,6 +254,15 @@\n \t  num_units = unit;\n \t  break;\n \t}\n+      else if (compunit.cu_length + initial_length_size < initial_length_size)\n+\t{\n+\t  warn (_(\"Debug info is corrupted, length of CU at %s is negative (%s)\\n\"),\n+\t\tdwarf_vmatoa (\"x\", cu_offset),\n+\t\tdwarf_vmatoa (\"x\", compunit.cu_length));\n+\t  num_units = unit;\n+\t  break;\n+\t}\n+\n       tags = hdrptr;\n       start += compunit.cu_length + initial_length_size;\n ",
        "diff_line_info": {
            "deleted_lines": [
                "      int initial_length_size;"
            ],
            "added_lines": [
                "      unsigned int initial_length_size;",
                "      else if (compunit.cu_length + initial_length_size < initial_length_size)",
                "\t{",
                "\t  warn (_(\"Debug info is corrupted, length of CU at %s is negative (%s)\\n\"),",
                "\t\tdwarf_vmatoa (\"x\", cu_offset),",
                "\t\tdwarf_vmatoa (\"x\", compunit.cu_length));",
                "\t  num_units = unit;",
                "\t  break;",
                "\t}",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2020-15350",
        "func_name": "RIOT-OS/RIOT/base64_estimate_decode_size",
        "description": "RIOT 2020.04 has a buffer overflow in the base64 decoder. The decoding function base64_decode() uses an output buffer estimation function to compute the required buffer capacity and validate against the provided buffer size. The base64_estimate_decode_size() function calculates the expected decoded size with an arithmetic round-off error and does not take into account possible padding bytes. Due to this underestimation, it may be possible to craft base64 input that causes a buffer overflow.",
        "git_url": "https://github.com/RIOT-OS/RIOT/commit/f8ac003bbfe11956578dd2189827686c27374d06",
        "commit_title": "base64: Fixed decode buffer size estimation",
        "commit_text": " Fixed required result buffer size underestimation in base64_estimate_decode_size() function.",
        "func_before": "static inline size_t base64_estimate_decode_size(size_t base64_in_size)\n{\n    return ((base64_in_size / 4) * 3);\n}",
        "func": "static inline size_t base64_estimate_decode_size(size_t base64_in_size)\n{\n    return (((base64_in_size + 3) / 4) * 3);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,4 +1,4 @@\n static inline size_t base64_estimate_decode_size(size_t base64_in_size)\n {\n-    return ((base64_in_size / 4) * 3);\n+    return (((base64_in_size + 3) / 4) * 3);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    return ((base64_in_size / 4) * 3);"
            ],
            "added_lines": [
                "    return (((base64_in_size + 3) / 4) * 3);"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-15350",
        "func_name": "RIOT-OS/RIOT/base64_encode",
        "description": "RIOT 2020.04 has a buffer overflow in the base64 decoder. The decoding function base64_decode() uses an output buffer estimation function to compute the required buffer capacity and validate against the provided buffer size. The base64_estimate_decode_size() function calculates the expected decoded size with an arithmetic round-off error and does not take into account possible padding bytes. Due to this underestimation, it may be possible to craft base64 input that causes a buffer overflow.",
        "git_url": "https://github.com/RIOT-OS/RIOT/commit/3c7fd0cdc93c1a1be1ccdc394b5bd8d8aef7a303",
        "commit_title": "sys/base64: Use void pointer for buffers in API",
        "commit_text": " This is a non-breaking change, as `unsigned char *` can implicitly be converted to `void *`.",
        "func_before": "int base64_encode(const void *data_in, size_t data_in_size,\n                  unsigned char *base64_out, size_t *base64_out_size)\n{\n    return base64_encode_base(data_in, data_in_size, base64_out, base64_out_size, false);\n}",
        "func": "int base64_encode(const void *data_in, size_t data_in_size,\n                  void *base64_out, size_t *base64_out_size)\n{\n    return base64_encode_base(data_in, data_in_size, base64_out, base64_out_size, false);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,5 @@\n int base64_encode(const void *data_in, size_t data_in_size,\n-                  unsigned char *base64_out, size_t *base64_out_size)\n+                  void *base64_out, size_t *base64_out_size)\n {\n     return base64_encode_base(data_in, data_in_size, base64_out, base64_out_size, false);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "                  unsigned char *base64_out, size_t *base64_out_size)"
            ],
            "added_lines": [
                "                  void *base64_out, size_t *base64_out_size)"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-15350",
        "func_name": "RIOT-OS/RIOT/base64_encode_base",
        "description": "RIOT 2020.04 has a buffer overflow in the base64 decoder. The decoding function base64_decode() uses an output buffer estimation function to compute the required buffer capacity and validate against the provided buffer size. The base64_estimate_decode_size() function calculates the expected decoded size with an arithmetic round-off error and does not take into account possible padding bytes. Due to this underestimation, it may be possible to craft base64 input that causes a buffer overflow.",
        "git_url": "https://github.com/RIOT-OS/RIOT/commit/3c7fd0cdc93c1a1be1ccdc394b5bd8d8aef7a303",
        "commit_title": "sys/base64: Use void pointer for buffers in API",
        "commit_text": " This is a non-breaking change, as `unsigned char *` can implicitly be converted to `void *`.",
        "func_before": "static int base64_encode_base(const void *data_in, size_t data_in_size,\n                              unsigned char *base64_out, size_t *base64_out_size,\n                              bool urlsafe)\n{\n    const unsigned char *in = data_in;\n    size_t required_size = base64_estimate_encode_size(data_in_size);\n\n    if (data_in == NULL) {\n        return BASE64_ERROR_DATA_IN;\n    }\n\n    if (data_in_size == 0) {\n        *base64_out_size = 0;\n        return BASE64_SUCCESS;\n    }\n\n    if (*base64_out_size < required_size) {\n        *base64_out_size = required_size;\n        return BASE64_ERROR_BUFFER_OUT_SIZE;\n    }\n\n    if (base64_out == NULL) {\n        return BASE64_ERROR_BUFFER_OUT;\n    }\n\n    int iterate_base64_buffer = 0;\n    unsigned char nNum = 0;\n    int nLst = 0;\n    int njump = 0;\n\n    for (int i = 0; i < (int)(data_in_size); ++i) {\n        unsigned char tmpval;\n        njump++;\n        tmpval = *(in + i);\n\n        nNum = (tmpval >> (2 * njump));\n\n        if (njump == 4) {\n            nNum = nLst << (8 - 2 * njump);\n            njump = 0;\n            nLst = 0;\n            --i;\n        }\n        else {\n            nNum += nLst << (8 - 2 * njump);\n            nLst =  tmpval & ((1 << njump * 2) - 1);\n        }\n\n        base64_out[iterate_base64_buffer++] = getsymbol(nNum, urlsafe);\n    }\n\n    /* The last character is not finished yet */\n    njump++;\n\n    nNum = nLst << (8 - 2 * njump);\n    base64_out[iterate_base64_buffer++] = getsymbol(nNum, urlsafe);\n\n    /* if required we append '=' for the required dividability */\n    while (iterate_base64_buffer % 4) {\n        base64_out[iterate_base64_buffer++] = '=';\n    }\n\n    *base64_out_size = iterate_base64_buffer;\n\n    return BASE64_SUCCESS;\n}",
        "func": "static int base64_encode_base(const void *data_in, size_t data_in_size,\n                              void *base64_out, size_t *base64_out_size,\n                              bool urlsafe)\n{\n    const uint8_t *in = data_in;\n    uint8_t *out = base64_out;\n    size_t required_size = base64_estimate_encode_size(data_in_size);\n\n    if (data_in == NULL) {\n        return BASE64_ERROR_DATA_IN;\n    }\n\n    if (data_in_size == 0) {\n        *base64_out_size = 0;\n        return BASE64_SUCCESS;\n    }\n\n    if (*base64_out_size < required_size) {\n        *base64_out_size = required_size;\n        return BASE64_ERROR_BUFFER_OUT_SIZE;\n    }\n\n    if (out == NULL) {\n        return BASE64_ERROR_BUFFER_OUT;\n    }\n\n    int iterate_base64_buffer = 0;\n    uint8_t n_num = 0;\n    int nLst = 0;\n    int njump = 0;\n\n    for (int i = 0; i < (int)(data_in_size); ++i) {\n        uint8_t tmpval;\n        njump++;\n        tmpval = *(in + i);\n\n        n_num = (tmpval >> (2 * njump));\n\n        if (njump == 4) {\n            n_num = nLst << (8 - 2 * njump);\n            njump = 0;\n            nLst = 0;\n            --i;\n        }\n        else {\n            n_num += nLst << (8 - 2 * njump);\n            nLst =  tmpval & ((1 << njump * 2) - 1);\n        }\n\n        out[iterate_base64_buffer++] = getsymbol(n_num, urlsafe);\n    }\n\n    /* The last character is not finished yet */\n    njump++;\n\n    n_num = nLst << (8 - 2 * njump);\n    out[iterate_base64_buffer++] = getsymbol(n_num, urlsafe);\n\n    /* if required we append '=' for the required dividability */\n    while (iterate_base64_buffer % 4) {\n        out[iterate_base64_buffer++] = '=';\n    }\n\n    *base64_out_size = iterate_base64_buffer;\n\n    return BASE64_SUCCESS;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,8 +1,9 @@\n static int base64_encode_base(const void *data_in, size_t data_in_size,\n-                              unsigned char *base64_out, size_t *base64_out_size,\n+                              void *base64_out, size_t *base64_out_size,\n                               bool urlsafe)\n {\n-    const unsigned char *in = data_in;\n+    const uint8_t *in = data_in;\n+    uint8_t *out = base64_out;\n     size_t required_size = base64_estimate_encode_size(data_in_size);\n \n     if (data_in == NULL) {\n@@ -19,45 +20,45 @@\n         return BASE64_ERROR_BUFFER_OUT_SIZE;\n     }\n \n-    if (base64_out == NULL) {\n+    if (out == NULL) {\n         return BASE64_ERROR_BUFFER_OUT;\n     }\n \n     int iterate_base64_buffer = 0;\n-    unsigned char nNum = 0;\n+    uint8_t n_num = 0;\n     int nLst = 0;\n     int njump = 0;\n \n     for (int i = 0; i < (int)(data_in_size); ++i) {\n-        unsigned char tmpval;\n+        uint8_t tmpval;\n         njump++;\n         tmpval = *(in + i);\n \n-        nNum = (tmpval >> (2 * njump));\n+        n_num = (tmpval >> (2 * njump));\n \n         if (njump == 4) {\n-            nNum = nLst << (8 - 2 * njump);\n+            n_num = nLst << (8 - 2 * njump);\n             njump = 0;\n             nLst = 0;\n             --i;\n         }\n         else {\n-            nNum += nLst << (8 - 2 * njump);\n+            n_num += nLst << (8 - 2 * njump);\n             nLst =  tmpval & ((1 << njump * 2) - 1);\n         }\n \n-        base64_out[iterate_base64_buffer++] = getsymbol(nNum, urlsafe);\n+        out[iterate_base64_buffer++] = getsymbol(n_num, urlsafe);\n     }\n \n     /* The last character is not finished yet */\n     njump++;\n \n-    nNum = nLst << (8 - 2 * njump);\n-    base64_out[iterate_base64_buffer++] = getsymbol(nNum, urlsafe);\n+    n_num = nLst << (8 - 2 * njump);\n+    out[iterate_base64_buffer++] = getsymbol(n_num, urlsafe);\n \n     /* if required we append '=' for the required dividability */\n     while (iterate_base64_buffer % 4) {\n-        base64_out[iterate_base64_buffer++] = '=';\n+        out[iterate_base64_buffer++] = '=';\n     }\n \n     *base64_out_size = iterate_base64_buffer;",
        "diff_line_info": {
            "deleted_lines": [
                "                              unsigned char *base64_out, size_t *base64_out_size,",
                "    const unsigned char *in = data_in;",
                "    if (base64_out == NULL) {",
                "    unsigned char nNum = 0;",
                "        unsigned char tmpval;",
                "        nNum = (tmpval >> (2 * njump));",
                "            nNum = nLst << (8 - 2 * njump);",
                "            nNum += nLst << (8 - 2 * njump);",
                "        base64_out[iterate_base64_buffer++] = getsymbol(nNum, urlsafe);",
                "    nNum = nLst << (8 - 2 * njump);",
                "    base64_out[iterate_base64_buffer++] = getsymbol(nNum, urlsafe);",
                "        base64_out[iterate_base64_buffer++] = '=';"
            ],
            "added_lines": [
                "                              void *base64_out, size_t *base64_out_size,",
                "    const uint8_t *in = data_in;",
                "    uint8_t *out = base64_out;",
                "    if (out == NULL) {",
                "    uint8_t n_num = 0;",
                "        uint8_t tmpval;",
                "        n_num = (tmpval >> (2 * njump));",
                "            n_num = nLst << (8 - 2 * njump);",
                "            n_num += nLst << (8 - 2 * njump);",
                "        out[iterate_base64_buffer++] = getsymbol(n_num, urlsafe);",
                "    n_num = nLst << (8 - 2 * njump);",
                "    out[iterate_base64_buffer++] = getsymbol(n_num, urlsafe);",
                "        out[iterate_base64_buffer++] = '=';"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-15350",
        "func_name": "RIOT-OS/RIOT/base64_decode",
        "description": "RIOT 2020.04 has a buffer overflow in the base64 decoder. The decoding function base64_decode() uses an output buffer estimation function to compute the required buffer capacity and validate against the provided buffer size. The base64_estimate_decode_size() function calculates the expected decoded size with an arithmetic round-off error and does not take into account possible padding bytes. Due to this underestimation, it may be possible to craft base64 input that causes a buffer overflow.",
        "git_url": "https://github.com/RIOT-OS/RIOT/commit/3c7fd0cdc93c1a1be1ccdc394b5bd8d8aef7a303",
        "commit_title": "sys/base64: Use void pointer for buffers in API",
        "commit_text": " This is a non-breaking change, as `unsigned char *` can implicitly be converted to `void *`.",
        "func_before": "int base64_decode(const unsigned char *base64_in, size_t base64_in_size,\n                  void *data_out, size_t *data_out_size)\n{\n    unsigned char *out = data_out;\n    size_t required_size = base64_estimate_decode_size(base64_in_size);\n\n    if (base64_in == NULL) {\n        return BASE64_ERROR_DATA_IN;\n    }\n\n    if (base64_in_size == 0) {\n        *data_out_size = 0;\n        return BASE64_SUCCESS;\n    }\n\n    if (base64_in_size < 4) {\n        return BASE64_ERROR_DATA_IN_SIZE;\n    }\n\n    if (*data_out_size < required_size) {\n        *data_out_size = required_size;\n        return BASE64_ERROR_BUFFER_OUT_SIZE;\n    }\n\n    if (data_out == NULL) {\n        return BASE64_ERROR_BUFFER_OUT;\n    }\n\n    int iterate_data_buffer = 0;\n    unsigned char nNum = 0;\n    int nLst = getcode(base64_in[0]) << 2;\n    int code = 0;\n\n    int mask = 2;\n\n    for (int i = 1; i < (int)(base64_in_size); i++) {\n        code = getcode(base64_in[i]);\n\n        if (code == BASE64_NOT_DEFINED || code == BASE64_EQUALS) {\n            continue;\n        }\n\n        int nm = (0xFF << (2 * mask));\n\n        nNum = nLst + ((code & (0xFF & nm)) >> (2 * mask));\n        nLst = (code & (0xFF & ~nm)) << (8 - (2 * mask));\n\n        (mask != 3) ? out[iterate_data_buffer++] = nNum : nNum;\n        (mask == 0) ? mask = 3 : mask--;\n    }\n\n    if (code == BASE64_EQUALS) {\n        /* add the last character to the data_out buffer */\n        out[iterate_data_buffer] = nNum;\n    }\n\n    *data_out_size = iterate_data_buffer;\n    return BASE64_SUCCESS;\n}",
        "func": "int base64_decode(const void *base64_in, size_t base64_in_size,\n                  void *data_out, size_t *data_out_size)\n{\n    uint8_t *out = data_out;\n    const uint8_t *in = base64_in;\n    size_t required_size = base64_estimate_decode_size(base64_in_size);\n\n    if (in == NULL) {\n        return BASE64_ERROR_DATA_IN;\n    }\n\n    if (base64_in_size == 0) {\n        *data_out_size = 0;\n        return BASE64_SUCCESS;\n    }\n\n    if (base64_in_size < 4) {\n        return BASE64_ERROR_DATA_IN_SIZE;\n    }\n\n    if (*data_out_size < required_size) {\n        *data_out_size = required_size;\n        return BASE64_ERROR_BUFFER_OUT_SIZE;\n    }\n\n    if (data_out == NULL) {\n        return BASE64_ERROR_BUFFER_OUT;\n    }\n\n    int iterate_data_buffer = 0;\n    uint8_t n_num = 0;\n    int nLst = getcode(in[0]) << 2;\n    int code = 0;\n\n    int mask = 2;\n\n    for (int i = 1; i < (int)(base64_in_size); i++) {\n        code = getcode(in[i]);\n\n        if (code == BASE64_NOT_DEFINED || code == BASE64_EQUALS) {\n            continue;\n        }\n\n        int nm = (0xFF << (2 * mask));\n\n        n_num = nLst + ((code & (0xFF & nm)) >> (2 * mask));\n        nLst = (code & (0xFF & ~nm)) << (8 - (2 * mask));\n\n        (mask != 3) ? out[iterate_data_buffer++] = n_num : n_num;\n        (mask == 0) ? mask = 3 : mask--;\n    }\n\n    if (code == BASE64_EQUALS) {\n        /* add the last character to the data_out buffer */\n        out[iterate_data_buffer] = n_num;\n    }\n\n    *data_out_size = iterate_data_buffer;\n    return BASE64_SUCCESS;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,10 +1,11 @@\n-int base64_decode(const unsigned char *base64_in, size_t base64_in_size,\n+int base64_decode(const void *base64_in, size_t base64_in_size,\n                   void *data_out, size_t *data_out_size)\n {\n-    unsigned char *out = data_out;\n+    uint8_t *out = data_out;\n+    const uint8_t *in = base64_in;\n     size_t required_size = base64_estimate_decode_size(base64_in_size);\n \n-    if (base64_in == NULL) {\n+    if (in == NULL) {\n         return BASE64_ERROR_DATA_IN;\n     }\n \n@@ -27,14 +28,14 @@\n     }\n \n     int iterate_data_buffer = 0;\n-    unsigned char nNum = 0;\n-    int nLst = getcode(base64_in[0]) << 2;\n+    uint8_t n_num = 0;\n+    int nLst = getcode(in[0]) << 2;\n     int code = 0;\n \n     int mask = 2;\n \n     for (int i = 1; i < (int)(base64_in_size); i++) {\n-        code = getcode(base64_in[i]);\n+        code = getcode(in[i]);\n \n         if (code == BASE64_NOT_DEFINED || code == BASE64_EQUALS) {\n             continue;\n@@ -42,16 +43,16 @@\n \n         int nm = (0xFF << (2 * mask));\n \n-        nNum = nLst + ((code & (0xFF & nm)) >> (2 * mask));\n+        n_num = nLst + ((code & (0xFF & nm)) >> (2 * mask));\n         nLst = (code & (0xFF & ~nm)) << (8 - (2 * mask));\n \n-        (mask != 3) ? out[iterate_data_buffer++] = nNum : nNum;\n+        (mask != 3) ? out[iterate_data_buffer++] = n_num : n_num;\n         (mask == 0) ? mask = 3 : mask--;\n     }\n \n     if (code == BASE64_EQUALS) {\n         /* add the last character to the data_out buffer */\n-        out[iterate_data_buffer] = nNum;\n+        out[iterate_data_buffer] = n_num;\n     }\n \n     *data_out_size = iterate_data_buffer;",
        "diff_line_info": {
            "deleted_lines": [
                "int base64_decode(const unsigned char *base64_in, size_t base64_in_size,",
                "    unsigned char *out = data_out;",
                "    if (base64_in == NULL) {",
                "    unsigned char nNum = 0;",
                "    int nLst = getcode(base64_in[0]) << 2;",
                "        code = getcode(base64_in[i]);",
                "        nNum = nLst + ((code & (0xFF & nm)) >> (2 * mask));",
                "        (mask != 3) ? out[iterate_data_buffer++] = nNum : nNum;",
                "        out[iterate_data_buffer] = nNum;"
            ],
            "added_lines": [
                "int base64_decode(const void *base64_in, size_t base64_in_size,",
                "    uint8_t *out = data_out;",
                "    const uint8_t *in = base64_in;",
                "    if (in == NULL) {",
                "    uint8_t n_num = 0;",
                "    int nLst = getcode(in[0]) << 2;",
                "        code = getcode(in[i]);",
                "        n_num = nLst + ((code & (0xFF & nm)) >> (2 * mask));",
                "        (mask != 3) ? out[iterate_data_buffer++] = n_num : n_num;",
                "        out[iterate_data_buffer] = n_num;"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-15350",
        "func_name": "RIOT-OS/RIOT/getcode",
        "description": "RIOT 2020.04 has a buffer overflow in the base64 decoder. The decoding function base64_decode() uses an output buffer estimation function to compute the required buffer capacity and validate against the provided buffer size. The base64_estimate_decode_size() function calculates the expected decoded size with an arithmetic round-off error and does not take into account possible padding bytes. Due to this underestimation, it may be possible to craft base64 input that causes a buffer overflow.",
        "git_url": "https://github.com/RIOT-OS/RIOT/commit/3c7fd0cdc93c1a1be1ccdc394b5bd8d8aef7a303",
        "commit_title": "sys/base64: Use void pointer for buffers in API",
        "commit_text": " This is a non-breaking change, as `unsigned char *` can implicitly be converted to `void *`.",
        "func_before": "static int getcode(char symbol)\n{\n    if (symbol == '/') {\n        return BASE64_SLASH;\n    }\n\n    if (symbol == '_') {\n        return BASE64_UNDERLINE;\n    }\n\n    if (symbol == '+') {\n        return BASE64_PLUS;\n    }\n\n    if (symbol == '-') {\n        return BASE64_MINUS;\n    }\n\n    if (symbol == '=') {\n        /* indicates a padded base64 end */\n        return BASE64_EQUALS;\n    }\n\n    if (symbol < '0') {\n        /* indicates that the given symbol is not base64 and should be ignored */\n        return BASE64_NOT_DEFINED;\n    }\n\n    if (symbol <= '9' && symbol >= '0') {\n        return (symbol + (BASE64_NUMBER_UPPER_BOUND - '9'));\n    }\n\n    if (symbol <= 'Z' && symbol >= 'A') {\n        return (symbol - 'A');\n    }\n\n    if (symbol <= 'z' && symbol >= 'a') {\n        return (symbol + (BASE64_SMALL_UPPER_BOUND - 'z'));\n    }\n\n    /* indicates that the given symbol is not base64 and should be ignored */\n    return BASE64_NOT_DEFINED;\n}",
        "func": "static uint8_t getcode(char symbol)\n{\n    if (symbol == '/') {\n        return BASE64_SLASH;\n    }\n\n    if (symbol == '_') {\n        return BASE64_UNDERLINE;\n    }\n\n    if (symbol == '+') {\n        return BASE64_PLUS;\n    }\n\n    if (symbol == '-') {\n        return BASE64_MINUS;\n    }\n\n    if (symbol == '=') {\n        /* indicates a padded base64 end */\n        return BASE64_EQUALS;\n    }\n\n    if (symbol < '0') {\n        /* indicates that the given symbol is not base64 and should be ignored */\n        return BASE64_NOT_DEFINED;\n    }\n\n    if (symbol <= '9' && symbol >= '0') {\n        return (symbol + (BASE64_NUMBER_UPPER_BOUND - '9'));\n    }\n\n    if (symbol <= 'Z' && symbol >= 'A') {\n        return (symbol - 'A');\n    }\n\n    if (symbol <= 'z' && symbol >= 'a') {\n        return (symbol + (BASE64_SMALL_UPPER_BOUND - 'z'));\n    }\n\n    /* indicates that the given symbol is not base64 and should be ignored */\n    return BASE64_NOT_DEFINED;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,4 +1,4 @@\n-static int getcode(char symbol)\n+static uint8_t getcode(char symbol)\n {\n     if (symbol == '/') {\n         return BASE64_SLASH;",
        "diff_line_info": {
            "deleted_lines": [
                "static int getcode(char symbol)"
            ],
            "added_lines": [
                "static uint8_t getcode(char symbol)"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-15350",
        "func_name": "RIOT-OS/RIOT/base64url_encode",
        "description": "RIOT 2020.04 has a buffer overflow in the base64 decoder. The decoding function base64_decode() uses an output buffer estimation function to compute the required buffer capacity and validate against the provided buffer size. The base64_estimate_decode_size() function calculates the expected decoded size with an arithmetic round-off error and does not take into account possible padding bytes. Due to this underestimation, it may be possible to craft base64 input that causes a buffer overflow.",
        "git_url": "https://github.com/RIOT-OS/RIOT/commit/3c7fd0cdc93c1a1be1ccdc394b5bd8d8aef7a303",
        "commit_title": "sys/base64: Use void pointer for buffers in API",
        "commit_text": " This is a non-breaking change, as `unsigned char *` can implicitly be converted to `void *`.",
        "func_before": "int base64url_encode(const void *data_in, size_t data_in_size,\n                     unsigned char *base64_out, size_t *base64_out_size)\n{\n    return base64_encode_base(data_in, data_in_size, base64_out, base64_out_size, true);\n}",
        "func": "int base64url_encode(const void *data_in, size_t data_in_size,\n                     void *base64_out, size_t *base64_out_size)\n{\n    return base64_encode_base(data_in, data_in_size, base64_out, base64_out_size, true);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,5 @@\n int base64url_encode(const void *data_in, size_t data_in_size,\n-                     unsigned char *base64_out, size_t *base64_out_size)\n+                     void *base64_out, size_t *base64_out_size)\n {\n     return base64_encode_base(data_in, data_in_size, base64_out, base64_out_size, true);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "                     unsigned char *base64_out, size_t *base64_out_size)"
            ],
            "added_lines": [
                "                     void *base64_out, size_t *base64_out_size)"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-15350",
        "func_name": "RIOT-OS/RIOT/getsymbol",
        "description": "RIOT 2020.04 has a buffer overflow in the base64 decoder. The decoding function base64_decode() uses an output buffer estimation function to compute the required buffer capacity and validate against the provided buffer size. The base64_estimate_decode_size() function calculates the expected decoded size with an arithmetic round-off error and does not take into account possible padding bytes. Due to this underestimation, it may be possible to craft base64 input that causes a buffer overflow.",
        "git_url": "https://github.com/RIOT-OS/RIOT/commit/3c7fd0cdc93c1a1be1ccdc394b5bd8d8aef7a303",
        "commit_title": "sys/base64: Use void pointer for buffers in API",
        "commit_text": " This is a non-breaking change, as `unsigned char *` can implicitly be converted to `void *`.",
        "func_before": "static char getsymbol(unsigned char code, bool urlsafe)\n{\n    if (!IS_ACTIVE(MODULE_BASE64URL)) {\n        urlsafe = false;\n    }\n\n    if (urlsafe && code == BASE64_UNDERLINE) {\n        return '_';\n    }\n\n    if (urlsafe && code == BASE64_MINUS) {\n        return '-';\n    }\n\n    if (!urlsafe && code == BASE64_SLASH) {\n        return '/';\n    }\n\n    if (!urlsafe && code == BASE64_PLUS) {\n        return '+';\n    }\n\n    if (code <= BASE64_CAPITAL_UPPER_BOUND) {\n        return (code + 'A');\n    }\n\n    if (code <= BASE64_SMALL_UPPER_BOUND) {\n        return (code + ('z' - BASE64_SMALL_UPPER_BOUND));\n    }\n\n    if (code <= BASE64_NUMBER_UPPER_BOUND) {\n        return (code + ('9' - BASE64_NUMBER_UPPER_BOUND));\n    }\n\n    return (char)BASE64_NOT_DEFINED;\n}",
        "func": "static char getsymbol(uint8_t code, bool urlsafe)\n{\n    if (!IS_ACTIVE(MODULE_BASE64URL)) {\n        urlsafe = false;\n    }\n\n    if (urlsafe && code == BASE64_UNDERLINE) {\n        return '_';\n    }\n\n    if (urlsafe && code == BASE64_MINUS) {\n        return '-';\n    }\n\n    if (!urlsafe && code == BASE64_SLASH) {\n        return '/';\n    }\n\n    if (!urlsafe && code == BASE64_PLUS) {\n        return '+';\n    }\n\n    if (code <= BASE64_CAPITAL_UPPER_BOUND) {\n        return (code + 'A');\n    }\n\n    if (code <= BASE64_SMALL_UPPER_BOUND) {\n        return (code + ('z' - BASE64_SMALL_UPPER_BOUND));\n    }\n\n    if (code <= BASE64_NUMBER_UPPER_BOUND) {\n        return (code + ('9' - BASE64_NUMBER_UPPER_BOUND));\n    }\n\n    return (char)BASE64_NOT_DEFINED;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,4 +1,4 @@\n-static char getsymbol(unsigned char code, bool urlsafe)\n+static char getsymbol(uint8_t code, bool urlsafe)\n {\n     if (!IS_ACTIVE(MODULE_BASE64URL)) {\n         urlsafe = false;",
        "diff_line_info": {
            "deleted_lines": [
                "static char getsymbol(unsigned char code, bool urlsafe)"
            ],
            "added_lines": [
                "static char getsymbol(uint8_t code, bool urlsafe)"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-14385",
        "func_name": "torvalds/linux/xfs_attr_shortform_verify",
        "description": "A flaw was found in the Linux kernel before 5.9-rc4. A failure of the file system metadata validator in XFS can cause an inode with a valid, user-creatable extended attribute to be flagged as corrupt. This can lead to the filesystem being shutdown, or otherwise rendered inaccessible until it is remounted, leading to a denial of service. The highest threat from this vulnerability is to system availability.",
        "git_url": "https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?h=f4020438fab05364018c91f7e02ebdd192085933",
        "commit_title": "The boundary test for the fixed-offset parts of xfs_attr_sf_entry in",
        "commit_text": "xfs_attr_shortform_verify is off by one, because the variable array at the end is defined as nameval[1] not nameval[]. Hence we need to subtract 1 from the calculation.  This can be shown by:  # touch file # setfattr -n root.a file  and verifications will fail when it's written to disk.  This only matters for a last attribute which has a single-byte name and no value, otherwise the combination of namelen & valuelen will push endp further out and this test won't fail.  ",
        "func_before": "xfs_failaddr_t\nxfs_attr_shortform_verify(\n\tstruct xfs_inode\t\t*ip)\n{\n\tstruct xfs_attr_shortform\t*sfp;\n\tstruct xfs_attr_sf_entry\t*sfep;\n\tstruct xfs_attr_sf_entry\t*next_sfep;\n\tchar\t\t\t\t*endp;\n\tstruct xfs_ifork\t\t*ifp;\n\tint\t\t\t\ti;\n\tint64_t\t\t\t\tsize;\n\n\tASSERT(ip->i_afp->if_format == XFS_DINODE_FMT_LOCAL);\n\tifp = XFS_IFORK_PTR(ip, XFS_ATTR_FORK);\n\tsfp = (struct xfs_attr_shortform *)ifp->if_u1.if_data;\n\tsize = ifp->if_bytes;\n\n\t/*\n\t * Give up if the attribute is way too short.\n\t */\n\tif (size < sizeof(struct xfs_attr_sf_hdr))\n\t\treturn __this_address;\n\n\tendp = (char *)sfp + size;\n\n\t/* Check all reported entries */\n\tsfep = &sfp->list[0];\n\tfor (i = 0; i < sfp->hdr.count; i++) {\n\t\t/*\n\t\t * struct xfs_attr_sf_entry has a variable length.\n\t\t * Check the fixed-offset parts of the structure are\n\t\t * within the data buffer.\n\t\t */\n\t\tif (((char *)sfep + sizeof(*sfep)) >= endp)\n\t\t\treturn __this_address;\n\n\t\t/* Don't allow names with known bad length. */\n\t\tif (sfep->namelen == 0)\n\t\t\treturn __this_address;\n\n\t\t/*\n\t\t * Check that the variable-length part of the structure is\n\t\t * within the data buffer.  The next entry starts after the\n\t\t * name component, so nextentry is an acceptable test.\n\t\t */\n\t\tnext_sfep = XFS_ATTR_SF_NEXTENTRY(sfep);\n\t\tif ((char *)next_sfep > endp)\n\t\t\treturn __this_address;\n\n\t\t/*\n\t\t * Check for unknown flags.  Short form doesn't support\n\t\t * the incomplete or local bits, so we can use the namespace\n\t\t * mask here.\n\t\t */\n\t\tif (sfep->flags & ~XFS_ATTR_NSP_ONDISK_MASK)\n\t\t\treturn __this_address;\n\n\t\t/*\n\t\t * Check for invalid namespace combinations.  We only allow\n\t\t * one namespace flag per xattr, so we can just count the\n\t\t * bits (i.e. hweight) here.\n\t\t */\n\t\tif (hweight8(sfep->flags & XFS_ATTR_NSP_ONDISK_MASK) > 1)\n\t\t\treturn __this_address;\n\n\t\tsfep = next_sfep;\n\t}\n\tif ((void *)sfep != (void *)endp)\n\t\treturn __this_address;\n\n\treturn NULL;\n}",
        "func": "xfs_failaddr_t\nxfs_attr_shortform_verify(\n\tstruct xfs_inode\t\t*ip)\n{\n\tstruct xfs_attr_shortform\t*sfp;\n\tstruct xfs_attr_sf_entry\t*sfep;\n\tstruct xfs_attr_sf_entry\t*next_sfep;\n\tchar\t\t\t\t*endp;\n\tstruct xfs_ifork\t\t*ifp;\n\tint\t\t\t\ti;\n\tint64_t\t\t\t\tsize;\n\n\tASSERT(ip->i_afp->if_format == XFS_DINODE_FMT_LOCAL);\n\tifp = XFS_IFORK_PTR(ip, XFS_ATTR_FORK);\n\tsfp = (struct xfs_attr_shortform *)ifp->if_u1.if_data;\n\tsize = ifp->if_bytes;\n\n\t/*\n\t * Give up if the attribute is way too short.\n\t */\n\tif (size < sizeof(struct xfs_attr_sf_hdr))\n\t\treturn __this_address;\n\n\tendp = (char *)sfp + size;\n\n\t/* Check all reported entries */\n\tsfep = &sfp->list[0];\n\tfor (i = 0; i < sfp->hdr.count; i++) {\n\t\t/*\n\t\t * struct xfs_attr_sf_entry has a variable length.\n\t\t * Check the fixed-offset parts of the structure are\n\t\t * within the data buffer.\n\t\t * xfs_attr_sf_entry is defined with a 1-byte variable\n\t\t * array at the end, so we must subtract that off.\n\t\t */\n\t\tif (((char *)sfep + sizeof(*sfep) - 1) >= endp)\n\t\t\treturn __this_address;\n\n\t\t/* Don't allow names with known bad length. */\n\t\tif (sfep->namelen == 0)\n\t\t\treturn __this_address;\n\n\t\t/*\n\t\t * Check that the variable-length part of the structure is\n\t\t * within the data buffer.  The next entry starts after the\n\t\t * name component, so nextentry is an acceptable test.\n\t\t */\n\t\tnext_sfep = XFS_ATTR_SF_NEXTENTRY(sfep);\n\t\tif ((char *)next_sfep > endp)\n\t\t\treturn __this_address;\n\n\t\t/*\n\t\t * Check for unknown flags.  Short form doesn't support\n\t\t * the incomplete or local bits, so we can use the namespace\n\t\t * mask here.\n\t\t */\n\t\tif (sfep->flags & ~XFS_ATTR_NSP_ONDISK_MASK)\n\t\t\treturn __this_address;\n\n\t\t/*\n\t\t * Check for invalid namespace combinations.  We only allow\n\t\t * one namespace flag per xattr, so we can just count the\n\t\t * bits (i.e. hweight) here.\n\t\t */\n\t\tif (hweight8(sfep->flags & XFS_ATTR_NSP_ONDISK_MASK) > 1)\n\t\t\treturn __this_address;\n\n\t\tsfep = next_sfep;\n\t}\n\tif ((void *)sfep != (void *)endp)\n\t\treturn __this_address;\n\n\treturn NULL;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -30,8 +30,10 @@\n \t\t * struct xfs_attr_sf_entry has a variable length.\n \t\t * Check the fixed-offset parts of the structure are\n \t\t * within the data buffer.\n+\t\t * xfs_attr_sf_entry is defined with a 1-byte variable\n+\t\t * array at the end, so we must subtract that off.\n \t\t */\n-\t\tif (((char *)sfep + sizeof(*sfep)) >= endp)\n+\t\tif (((char *)sfep + sizeof(*sfep) - 1) >= endp)\n \t\t\treturn __this_address;\n \n \t\t/* Don't allow names with known bad length. */",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tif (((char *)sfep + sizeof(*sfep)) >= endp)"
            ],
            "added_lines": [
                "\t\t * xfs_attr_sf_entry is defined with a 1-byte variable",
                "\t\t * array at the end, so we must subtract that off.",
                "\t\tif (((char *)sfep + sizeof(*sfep) - 1) >= endp)"
            ]
        }
    },
    {
        "cve_id": "CVE-2023-45871",
        "func_name": "torvalds/linux/igb_set_rx_buffer_len",
        "description": "An issue was discovered in drivers/net/ethernet/intel/igb/igb_main.c in the IGB driver in the Linux kernel before 6.5.3. A buffer size may not be adequate for frames larger than the MTU.",
        "git_url": "https://git.kernel.org/pub/scm/linux/kernel/git/stable/linux.git/commit/?h=bb5ed01cd2428cd25b1c88a3a9cba87055eb289f",
        "commit_title": "Increase the RX buffer size to 3K when the SBP bit is on. The size of",
        "commit_text": "the RX buffer determines the number of pages allocated which may not be sufficient for receive frames larger than the set MTU size.  Cc: stable@vger.kernel.org ",
        "func_before": "static void igb_set_rx_buffer_len(struct igb_adapter *adapter,\n\t\t\t\t  struct igb_ring *rx_ring)\n{\n\t/* set build_skb and buffer size flags */\n\tclear_ring_build_skb_enabled(rx_ring);\n\tclear_ring_uses_large_buffer(rx_ring);\n\n\tif (adapter->flags & IGB_FLAG_RX_LEGACY)\n\t\treturn;\n\n\tset_ring_build_skb_enabled(rx_ring);\n\n#if (PAGE_SIZE < 8192)\n\tif (adapter->max_frame_size <= IGB_MAX_FRAME_BUILD_SKB)\n\t\treturn;\n\n\tset_ring_uses_large_buffer(rx_ring);\n#endif\n}",
        "func": "static void igb_set_rx_buffer_len(struct igb_adapter *adapter,\n\t\t\t\t  struct igb_ring *rx_ring)\n{\n#if (PAGE_SIZE < 8192)\n\tstruct e1000_hw *hw = &adapter->hw;\n#endif\n\n\t/* set build_skb and buffer size flags */\n\tclear_ring_build_skb_enabled(rx_ring);\n\tclear_ring_uses_large_buffer(rx_ring);\n\n\tif (adapter->flags & IGB_FLAG_RX_LEGACY)\n\t\treturn;\n\n\tset_ring_build_skb_enabled(rx_ring);\n\n#if (PAGE_SIZE < 8192)\n\tif (adapter->max_frame_size > IGB_MAX_FRAME_BUILD_SKB ||\n\t    rd32(E1000_RCTL) & E1000_RCTL_SBP)\n\t\tset_ring_uses_large_buffer(rx_ring);\n#endif\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,10 @@\n static void igb_set_rx_buffer_len(struct igb_adapter *adapter,\n \t\t\t\t  struct igb_ring *rx_ring)\n {\n+#if (PAGE_SIZE < 8192)\n+\tstruct e1000_hw *hw = &adapter->hw;\n+#endif\n+\n \t/* set build_skb and buffer size flags */\n \tclear_ring_build_skb_enabled(rx_ring);\n \tclear_ring_uses_large_buffer(rx_ring);\n@@ -11,9 +15,8 @@\n \tset_ring_build_skb_enabled(rx_ring);\n \n #if (PAGE_SIZE < 8192)\n-\tif (adapter->max_frame_size <= IGB_MAX_FRAME_BUILD_SKB)\n-\t\treturn;\n-\n-\tset_ring_uses_large_buffer(rx_ring);\n+\tif (adapter->max_frame_size > IGB_MAX_FRAME_BUILD_SKB ||\n+\t    rd32(E1000_RCTL) & E1000_RCTL_SBP)\n+\t\tset_ring_uses_large_buffer(rx_ring);\n #endif\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (adapter->max_frame_size <= IGB_MAX_FRAME_BUILD_SKB)",
                "\t\treturn;",
                "",
                "\tset_ring_uses_large_buffer(rx_ring);"
            ],
            "added_lines": [
                "#if (PAGE_SIZE < 8192)",
                "\tstruct e1000_hw *hw = &adapter->hw;",
                "#endif",
                "",
                "\tif (adapter->max_frame_size > IGB_MAX_FRAME_BUILD_SKB ||",
                "\t    rd32(E1000_RCTL) & E1000_RCTL_SBP)",
                "\t\tset_ring_uses_large_buffer(rx_ring);"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-29545",
        "func_name": "tensorflow/SparseTensorToCSRSparseMatrixCPUFunctor::operator()",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. An attacker can trigger a denial of service via a `CHECK`-fail in converting sparse tensors to CSR Sparse matrices. This is because the implementation(https://github.com/tensorflow/tensorflow/blob/800346f2c03a27e182dd4fba48295f65e7790739/tensorflow/core/kernels/sparse/kernels.cc#L66) does a double redirection to access an element of an array allocated on the heap. If the value at `indices(i, 0)` is such that `indices(i, 0) + 1` is outside the bounds of `csr_row_ptr`, this results in writing outside of bounds of heap allocated data. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/1e922ccdf6bf46a3a52641f99fd47d54c1decd13",
        "commit_title": "Fix crash in `SparseTensorToCSRSparseMatrixCPUFunctor`",
        "commit_text": " PiperOrigin-RevId: 370110290",
        "func_before": "Status SparseTensorToCSRSparseMatrixCPUFunctor::operator()(\n    const int64 batch_size, const int num_rows,\n    TTypes<int64>::ConstMatrix indices, TTypes<int32>::Vec batch_ptr,\n    TTypes<int32>::Vec csr_row_ptr, TTypes<int32>::Vec csr_col_ind) {\n  // Validate inputs.\n  if (batch_ptr.size() != batch_size + 1) {\n    return errors::InvalidArgument(\n        \"Expected batch_ptr.size() == batch_size + 1. Got: \", batch_ptr.size(),\n        \" vs. \", batch_size + 1);\n  }\n  if (csr_row_ptr.size() != batch_size * (num_rows + 1)) {\n    return errors::InvalidArgument(\n        \"Expected csr_row_ptr.size() == batch_size * (num_rows + 1). Got: \",\n        csr_row_ptr.size(), \" vs. \", batch_size * (num_rows + 1));\n  }\n\n  const int64 total_nnz = indices.dimension(0);\n  const int rank = indices.dimension(1);\n  if (rank == 2 && batch_size != 1) {\n    return errors::InvalidArgument(\n        \"Expected batch_size == 1 when rank is 2. Got batch_size: \",\n        batch_size);\n  }\n  if (csr_col_ind.size() != total_nnz) {\n    return errors::InvalidArgument(\n        \"Expected csr_col_ind.size() == total_nnz. Got: \", csr_col_ind.size(),\n        \" vs. \", total_nnz);\n  }\n\n  int prev_batch = -1;\n  if (rank == 2) {\n    // For a single batch, the batch_ptrs are {0, total_nnz}.\n    batch_ptr(0) = 0;\n    ++prev_batch;\n\n    for (int64 i = 0; i < total_nnz; ++i) {\n      // For now, the rows pointers store the corresponding row counts.\n      csr_row_ptr(indices(i, 0) + 1) += 1;\n      csr_col_ind(i) = indices(i, 1);\n    }\n  } else {  // rank == 3\n    for (int64 i = 0; i < total_nnz; ++i) {\n      const int cur_batch = indices(i, 0);\n      // For now, the rows pointers store the corresponding row counts.\n      csr_row_ptr(cur_batch * (num_rows + 1) + indices(i, 1) + 1) += 1;\n      csr_col_ind(i) = indices(i, 2);\n\n      // We're at a new batch and might have skipped over empty batches.\n      while (prev_batch < cur_batch) {\n        // The previous batch ends at position i.\n        batch_ptr(prev_batch + 1) = i;\n        ++prev_batch;\n      }\n    }\n  }\n  // Set the last element of batch_ptr and account for trailing empty batches.\n  while (prev_batch < batch_size) {\n    batch_ptr(prev_batch + 1) = total_nnz;\n    ++prev_batch;\n  }\n\n  // Compute the cumulative row counts for each batch.\n  for (int batch_idx = 0; batch_idx < batch_size; ++batch_idx) {\n    auto* row_ptr_batch = csr_row_ptr.data() + batch_idx * (num_rows + 1);\n    std::partial_sum(row_ptr_batch, row_ptr_batch + num_rows + 1,\n                     row_ptr_batch);\n  }\n  return Status::OK();\n}",
        "func": "Status SparseTensorToCSRSparseMatrixCPUFunctor::operator()(\n    const int64 batch_size, const int num_rows,\n    TTypes<int64>::ConstMatrix indices, TTypes<int32>::Vec batch_ptr,\n    TTypes<int32>::Vec csr_row_ptr, TTypes<int32>::Vec csr_col_ind) {\n  // Validate inputs.\n  if (batch_ptr.size() != batch_size + 1) {\n    return errors::InvalidArgument(\n        \"Expected batch_ptr.size() == batch_size + 1. Got: \", batch_ptr.size(),\n        \" vs. \", batch_size + 1);\n  }\n  if (csr_row_ptr.size() != batch_size * (num_rows + 1)) {\n    return errors::InvalidArgument(\n        \"Expected csr_row_ptr.size() == batch_size * (num_rows + 1). Got: \",\n        csr_row_ptr.size(), \" vs. \", batch_size * (num_rows + 1));\n  }\n\n  const int64 total_nnz = indices.dimension(0);\n  const int rank = indices.dimension(1);\n  if (rank == 2 && batch_size != 1) {\n    return errors::InvalidArgument(\n        \"Expected batch_size == 1 when rank is 2. Got batch_size: \",\n        batch_size);\n  }\n  if (csr_col_ind.size() != total_nnz) {\n    return errors::InvalidArgument(\n        \"Expected csr_col_ind.size() == total_nnz. Got: \", csr_col_ind.size(),\n        \" vs. \", total_nnz);\n  }\n\n  int prev_batch = -1;\n  if (rank == 2) {\n    // For a single batch, the batch_ptrs are {0, total_nnz}.\n    batch_ptr(0) = 0;\n    ++prev_batch;\n\n    for (int64 i = 0; i < total_nnz; ++i) {\n      // For now, the rows pointers store the corresponding row counts.\n      int64 ix = indices(i, 0) + 1;\n      if (ix >= csr_row_ptr.size()) {\n        return errors::InvalidArgument(\"Got an index \", ix,\n                                       \" that is outside of csr_row_ptr\");\n      }\n      csr_row_ptr(indices(i, 0) + 1) += 1;\n      csr_col_ind(i) = indices(i, 1);\n    }\n  } else {  // rank == 3\n    for (int64 i = 0; i < total_nnz; ++i) {\n      const int cur_batch = indices(i, 0);\n      // For now, the rows pointers store the corresponding row counts.\n      csr_row_ptr(cur_batch * (num_rows + 1) + indices(i, 1) + 1) += 1;\n      csr_col_ind(i) = indices(i, 2);\n\n      // We're at a new batch and might have skipped over empty batches.\n      while (prev_batch < cur_batch) {\n        // The previous batch ends at position i.\n        batch_ptr(prev_batch + 1) = i;\n        ++prev_batch;\n      }\n    }\n  }\n  // Set the last element of batch_ptr and account for trailing empty batches.\n  while (prev_batch < batch_size) {\n    batch_ptr(prev_batch + 1) = total_nnz;\n    ++prev_batch;\n  }\n\n  // Compute the cumulative row counts for each batch.\n  for (int batch_idx = 0; batch_idx < batch_size; ++batch_idx) {\n    auto* row_ptr_batch = csr_row_ptr.data() + batch_idx * (num_rows + 1);\n    std::partial_sum(row_ptr_batch, row_ptr_batch + num_rows + 1,\n                     row_ptr_batch);\n  }\n  return Status::OK();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -35,6 +35,11 @@\n \n     for (int64 i = 0; i < total_nnz; ++i) {\n       // For now, the rows pointers store the corresponding row counts.\n+      int64 ix = indices(i, 0) + 1;\n+      if (ix >= csr_row_ptr.size()) {\n+        return errors::InvalidArgument(\"Got an index \", ix,\n+                                       \" that is outside of csr_row_ptr\");\n+      }\n       csr_row_ptr(indices(i, 0) + 1) += 1;\n       csr_col_ind(i) = indices(i, 1);\n     }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "      int64 ix = indices(i, 0) + 1;",
                "      if (ix >= csr_row_ptr.size()) {",
                "        return errors::InvalidArgument(\"Got an index \", ix,",
                "                                       \" that is outside of csr_row_ptr\");",
                "      }"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-29608",
        "func_name": "tensorflow/CalculateOutputIndexRowSplit",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. Due to lack of validation in `tf.raw_ops.RaggedTensorToTensor`, an attacker can exploit an undefined behavior if input arguments are empty. The implementation(https://github.com/tensorflow/tensorflow/blob/656e7673b14acd7835dc778867f84916c6d1cac2/tensorflow/core/kernels/ragged_tensor_to_tensor_op.cc#L356-L360) only checks that one of the tensors is not empty, but does not check for the other ones. There are multiple `DCHECK` validations to prevent heap OOB, but these are no-op in release builds, hence they don't prevent anything. The fix will be included in TensorFlow 2.5.0. We will also cherrypick these commits on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/b761c9b652af2107cfbc33efd19be0ce41daa33e",
        "commit_title": "Fix `tf.raw_ops.RaggedTensorToTensor` failing CHECK.",
        "commit_text": " PiperOrigin-RevId: 368706628",
        "func_before": "void CalculateOutputIndexRowSplit(\n      const RowPartitionTensor& row_split,\n      const vector<INDEX_TYPE>& parent_output_index,\n      INDEX_TYPE output_index_multiplier, INDEX_TYPE output_size,\n      vector<INDEX_TYPE>* result) {\n    INDEX_TYPE row_split_size = row_split.size();\n    if (row_split_size > 0) {\n      result->reserve(row_split(row_split_size - 1));\n    }\n    for (INDEX_TYPE i = 0; i < row_split_size - 1; ++i) {\n      INDEX_TYPE row_length = row_split(i + 1) - row_split(i);\n      INDEX_TYPE real_length = std::min(output_size, row_length);\n      INDEX_TYPE parent_output_index_current = parent_output_index[i];\n\n      if (parent_output_index_current == -1) {\n        real_length = 0;\n      }\n      for (INDEX_TYPE j = 0; j < real_length; ++j) {\n        result->push_back(parent_output_index_current);\n        parent_output_index_current += output_index_multiplier;\n      }\n      for (INDEX_TYPE j = 0; j < row_length - real_length; ++j) {\n        result->push_back(-1);\n      }\n    }\n    if (row_split_size > 0) {\n      DCHECK_EQ(result->size(), row_split(row_split_size - 1));\n    }\n  }",
        "func": "void CalculateOutputIndexRowSplit(\n      OpKernelContext* context, const RowPartitionTensor& row_split,\n      const vector<INDEX_TYPE>& parent_output_index,\n      INDEX_TYPE output_index_multiplier, INDEX_TYPE output_size,\n      vector<INDEX_TYPE>* result) {\n    INDEX_TYPE row_split_size = row_split.size();\n    if (row_split_size > 0) {\n      result->reserve(row_split(row_split_size - 1));\n    }\n    for (INDEX_TYPE i = 0; i < row_split_size - 1; ++i) {\n      INDEX_TYPE row_length = row_split(i + 1) - row_split(i);\n      INDEX_TYPE real_length = std::min(output_size, row_length);\n      INDEX_TYPE parent_output_index_current = parent_output_index[i];\n\n      if (parent_output_index_current == -1) {\n        real_length = 0;\n      }\n      for (INDEX_TYPE j = 0; j < real_length; ++j) {\n        result->push_back(parent_output_index_current);\n        parent_output_index_current += output_index_multiplier;\n      }\n      for (INDEX_TYPE j = 0; j < row_length - real_length; ++j) {\n        result->push_back(-1);\n      }\n    }\n    if (row_split_size > 0) {\n      OP_REQUIRES(context, result->size() == row_split(row_split_size - 1),\n                  errors::InvalidArgument(\"Invalid row split size.\"));\n    }\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,5 @@\n void CalculateOutputIndexRowSplit(\n-      const RowPartitionTensor& row_split,\n+      OpKernelContext* context, const RowPartitionTensor& row_split,\n       const vector<INDEX_TYPE>& parent_output_index,\n       INDEX_TYPE output_index_multiplier, INDEX_TYPE output_size,\n       vector<INDEX_TYPE>* result) {\n@@ -24,6 +24,7 @@\n       }\n     }\n     if (row_split_size > 0) {\n-      DCHECK_EQ(result->size(), row_split(row_split_size - 1));\n+      OP_REQUIRES(context, result->size() == row_split(row_split_size - 1),\n+                  errors::InvalidArgument(\"Invalid row split size.\"));\n     }\n   }",
        "diff_line_info": {
            "deleted_lines": [
                "      const RowPartitionTensor& row_split,",
                "      DCHECK_EQ(result->size(), row_split(row_split_size - 1));"
            ],
            "added_lines": [
                "      OpKernelContext* context, const RowPartitionTensor& row_split,",
                "      OP_REQUIRES(context, result->size() == row_split(row_split_size - 1),",
                "                  errors::InvalidArgument(\"Invalid row split size.\"));"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-29608",
        "func_name": "tensorflow/CalculateOutputIndexValueRowID",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. Due to lack of validation in `tf.raw_ops.RaggedTensorToTensor`, an attacker can exploit an undefined behavior if input arguments are empty. The implementation(https://github.com/tensorflow/tensorflow/blob/656e7673b14acd7835dc778867f84916c6d1cac2/tensorflow/core/kernels/ragged_tensor_to_tensor_op.cc#L356-L360) only checks that one of the tensors is not empty, but does not check for the other ones. There are multiple `DCHECK` validations to prevent heap OOB, but these are no-op in release builds, hence they don't prevent anything. The fix will be included in TensorFlow 2.5.0. We will also cherrypick these commits on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/b761c9b652af2107cfbc33efd19be0ce41daa33e",
        "commit_title": "Fix `tf.raw_ops.RaggedTensorToTensor` failing CHECK.",
        "commit_text": " PiperOrigin-RevId: 368706628",
        "func_before": "void CalculateOutputIndexValueRowID(\n      const RowPartitionTensor& value_rowids,\n      const vector<INDEX_TYPE>& parent_output_index,\n      INDEX_TYPE output_index_multiplier, INDEX_TYPE output_size,\n      vector<INDEX_TYPE>* result) {\n    const INDEX_TYPE index_size = value_rowids.size();\n    result->reserve(index_size);\n    if (index_size == 0) {\n      return;\n    }\n\n    INDEX_TYPE current_output_column = 0;\n    INDEX_TYPE current_value_rowid = value_rowids(0);\n    DCHECK_LT(current_value_rowid, parent_output_index.size());\n    INDEX_TYPE current_output_index = parent_output_index[current_value_rowid];\n    result->push_back(current_output_index);\n    for (INDEX_TYPE i = 1; i < index_size; ++i) {\n      INDEX_TYPE next_value_rowid = value_rowids(i);\n      if (next_value_rowid == current_value_rowid) {\n        if (current_output_index >= 0) {\n          ++current_output_column;\n          if (current_output_column < output_size) {\n            current_output_index += output_index_multiplier;\n          } else {\n            current_output_index = -1;\n          }\n        }\n      } else {\n        current_output_column = 0;\n        current_value_rowid = next_value_rowid;\n        DCHECK_LT(next_value_rowid, parent_output_index.size());\n        current_output_index = parent_output_index[next_value_rowid];\n      }\n      result->push_back(current_output_index);\n    }\n    DCHECK_EQ(result->size(), value_rowids.size());\n  }",
        "func": "void CalculateOutputIndexValueRowID(\n      OpKernelContext* context, const RowPartitionTensor& value_rowids,\n      const vector<INDEX_TYPE>& parent_output_index,\n      INDEX_TYPE output_index_multiplier, INDEX_TYPE output_size,\n      vector<INDEX_TYPE>* result) {\n    const INDEX_TYPE index_size = value_rowids.size();\n    result->reserve(index_size);\n    if (index_size == 0) {\n      return;\n    }\n\n    INDEX_TYPE current_output_column = 0;\n    INDEX_TYPE current_value_rowid = value_rowids(0);\n    DCHECK_LT(current_value_rowid, parent_output_index.size());\n    INDEX_TYPE current_output_index = parent_output_index[current_value_rowid];\n    result->push_back(current_output_index);\n    for (INDEX_TYPE i = 1; i < index_size; ++i) {\n      INDEX_TYPE next_value_rowid = value_rowids(i);\n      if (next_value_rowid == current_value_rowid) {\n        if (current_output_index >= 0) {\n          ++current_output_column;\n          if (current_output_column < output_size) {\n            current_output_index += output_index_multiplier;\n          } else {\n            current_output_index = -1;\n          }\n        }\n      } else {\n        current_output_column = 0;\n        current_value_rowid = next_value_rowid;\n        DCHECK_LT(next_value_rowid, parent_output_index.size());\n        current_output_index = parent_output_index[next_value_rowid];\n      }\n      result->push_back(current_output_index);\n    }\n    OP_REQUIRES(context, result->size() == value_rowids.size(),\n                errors::InvalidArgument(\"Invalid row ids.\"));\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,5 @@\n void CalculateOutputIndexValueRowID(\n-      const RowPartitionTensor& value_rowids,\n+      OpKernelContext* context, const RowPartitionTensor& value_rowids,\n       const vector<INDEX_TYPE>& parent_output_index,\n       INDEX_TYPE output_index_multiplier, INDEX_TYPE output_size,\n       vector<INDEX_TYPE>* result) {\n@@ -33,5 +33,6 @@\n       }\n       result->push_back(current_output_index);\n     }\n-    DCHECK_EQ(result->size(), value_rowids.size());\n+    OP_REQUIRES(context, result->size() == value_rowids.size(),\n+                errors::InvalidArgument(\"Invalid row ids.\"));\n   }",
        "diff_line_info": {
            "deleted_lines": [
                "      const RowPartitionTensor& value_rowids,",
                "    DCHECK_EQ(result->size(), value_rowids.size());"
            ],
            "added_lines": [
                "      OpKernelContext* context, const RowPartitionTensor& value_rowids,",
                "    OP_REQUIRES(context, result->size() == value_rowids.size(),",
                "                errors::InvalidArgument(\"Invalid row ids.\"));"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-29608",
        "func_name": "tensorflow/CalculateOutputIndex",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. Due to lack of validation in `tf.raw_ops.RaggedTensorToTensor`, an attacker can exploit an undefined behavior if input arguments are empty. The implementation(https://github.com/tensorflow/tensorflow/blob/656e7673b14acd7835dc778867f84916c6d1cac2/tensorflow/core/kernels/ragged_tensor_to_tensor_op.cc#L356-L360) only checks that one of the tensors is not empty, but does not check for the other ones. There are multiple `DCHECK` validations to prevent heap OOB, but these are no-op in release builds, hence they don't prevent anything. The fix will be included in TensorFlow 2.5.0. We will also cherrypick these commits on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/b761c9b652af2107cfbc33efd19be0ce41daa33e",
        "commit_title": "Fix `tf.raw_ops.RaggedTensorToTensor` failing CHECK.",
        "commit_text": " PiperOrigin-RevId: 368706628",
        "func_before": "Status CalculateOutputIndex(OpKernelContext* context, int dimension,\n                              const vector<INDEX_TYPE>& parent_output_index,\n                              INDEX_TYPE output_index_multiplier,\n                              INDEX_TYPE output_size,\n                              vector<INDEX_TYPE>* result) {\n    const RowPartitionTensor row_partition_tensor =\n        GetRowPartitionTensor(context, dimension);\n    auto partition_type = GetRowPartitionTypeByDimension(dimension);\n    switch (partition_type) {\n      case RowPartitionType::VALUE_ROWIDS:\n        CalculateOutputIndexValueRowID(\n            row_partition_tensor, parent_output_index, output_index_multiplier,\n            output_size, result);\n        return tensorflow::Status::OK();\n      case RowPartitionType::ROW_SPLITS:\n        CalculateOutputIndexRowSplit(row_partition_tensor, parent_output_index,\n                                     output_index_multiplier, output_size,\n                                     result);\n        return tensorflow::Status::OK();\n      default:\n        return errors::InvalidArgument(\n            \"Unsupported partition type:\",\n            RowPartitionTypeToString(partition_type));\n    }\n  }",
        "func": "Status CalculateOutputIndex(OpKernelContext* context, int dimension,\n                              const vector<INDEX_TYPE>& parent_output_index,\n                              INDEX_TYPE output_index_multiplier,\n                              INDEX_TYPE output_size,\n                              vector<INDEX_TYPE>* result) {\n    const RowPartitionTensor row_partition_tensor =\n        GetRowPartitionTensor(context, dimension);\n    auto partition_type = GetRowPartitionTypeByDimension(dimension);\n    switch (partition_type) {\n      case RowPartitionType::VALUE_ROWIDS:\n        CalculateOutputIndexValueRowID(\n            context, row_partition_tensor, parent_output_index,\n            output_index_multiplier, output_size, result);\n        return tensorflow::Status::OK();\n      case RowPartitionType::ROW_SPLITS:\n        CalculateOutputIndexRowSplit(\n            context, row_partition_tensor, parent_output_index,\n            output_index_multiplier, output_size, result);\n        return tensorflow::Status::OK();\n      default:\n        return errors::InvalidArgument(\n            \"Unsupported partition type:\",\n            RowPartitionTypeToString(partition_type));\n    }\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -9,13 +9,13 @@\n     switch (partition_type) {\n       case RowPartitionType::VALUE_ROWIDS:\n         CalculateOutputIndexValueRowID(\n-            row_partition_tensor, parent_output_index, output_index_multiplier,\n-            output_size, result);\n+            context, row_partition_tensor, parent_output_index,\n+            output_index_multiplier, output_size, result);\n         return tensorflow::Status::OK();\n       case RowPartitionType::ROW_SPLITS:\n-        CalculateOutputIndexRowSplit(row_partition_tensor, parent_output_index,\n-                                     output_index_multiplier, output_size,\n-                                     result);\n+        CalculateOutputIndexRowSplit(\n+            context, row_partition_tensor, parent_output_index,\n+            output_index_multiplier, output_size, result);\n         return tensorflow::Status::OK();\n       default:\n         return errors::InvalidArgument(",
        "diff_line_info": {
            "deleted_lines": [
                "            row_partition_tensor, parent_output_index, output_index_multiplier,",
                "            output_size, result);",
                "        CalculateOutputIndexRowSplit(row_partition_tensor, parent_output_index,",
                "                                     output_index_multiplier, output_size,",
                "                                     result);"
            ],
            "added_lines": [
                "            context, row_partition_tensor, parent_output_index,",
                "            output_index_multiplier, output_size, result);",
                "        CalculateOutputIndexRowSplit(",
                "            context, row_partition_tensor, parent_output_index,",
                "            output_index_multiplier, output_size, result);"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-29608",
        "func_name": "tensorflow/CalculateOutputIndexRowSplit",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. Due to lack of validation in `tf.raw_ops.RaggedTensorToTensor`, an attacker can exploit an undefined behavior if input arguments are empty. The implementation(https://github.com/tensorflow/tensorflow/blob/656e7673b14acd7835dc778867f84916c6d1cac2/tensorflow/core/kernels/ragged_tensor_to_tensor_op.cc#L356-L360) only checks that one of the tensors is not empty, but does not check for the other ones. There are multiple `DCHECK` validations to prevent heap OOB, but these are no-op in release builds, hence they don't prevent anything. The fix will be included in TensorFlow 2.5.0. We will also cherrypick these commits on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/c4d7afb6a5986b04505aca4466ae1951686c80f6",
        "commit_title": "Fix heap OOB / undefined behavior in `RaggedTensorToTensor`",
        "commit_text": " PiperOrigin-RevId: 373244623",
        "func_before": "void CalculateOutputIndexRowSplit(\n      OpKernelContext* context, const RowPartitionTensor& row_split,\n      const vector<INDEX_TYPE>& parent_output_index,\n      INDEX_TYPE output_index_multiplier, INDEX_TYPE output_size,\n      vector<INDEX_TYPE>* result) {\n    INDEX_TYPE row_split_size = row_split.size();\n    if (row_split_size > 0) {\n      result->reserve(row_split(row_split_size - 1));\n    }\n    for (INDEX_TYPE i = 0; i < row_split_size - 1; ++i) {\n      INDEX_TYPE row_length = row_split(i + 1) - row_split(i);\n      INDEX_TYPE real_length = std::min(output_size, row_length);\n      INDEX_TYPE parent_output_index_current = parent_output_index[i];\n\n      if (parent_output_index_current == -1) {\n        real_length = 0;\n      }\n      for (INDEX_TYPE j = 0; j < real_length; ++j) {\n        result->push_back(parent_output_index_current);\n        parent_output_index_current += output_index_multiplier;\n      }\n      for (INDEX_TYPE j = 0; j < row_length - real_length; ++j) {\n        result->push_back(-1);\n      }\n    }\n    if (row_split_size > 0) {\n      OP_REQUIRES(context, result->size() == row_split(row_split_size - 1),\n                  errors::InvalidArgument(\"Invalid row split size.\"));\n    }\n  }",
        "func": "Status CalculateOutputIndexRowSplit(\n      const RowPartitionTensor& row_split,\n      const vector<INDEX_TYPE>& parent_output_index,\n      INDEX_TYPE output_index_multiplier, INDEX_TYPE output_size,\n      vector<INDEX_TYPE>* result) {\n    INDEX_TYPE row_split_size = row_split.size();\n    if (row_split_size > 0) {\n      result->reserve(row_split(row_split_size - 1));\n    }\n    for (INDEX_TYPE i = 0; i < row_split_size - 1; ++i) {\n      INDEX_TYPE row_length = row_split(i + 1) - row_split(i);\n      INDEX_TYPE real_length = std::min(output_size, row_length);\n      INDEX_TYPE parent_output_index_current = parent_output_index[i];\n\n      if (parent_output_index_current == -1) {\n        real_length = 0;\n      }\n      for (INDEX_TYPE j = 0; j < real_length; ++j) {\n        result->push_back(parent_output_index_current);\n        parent_output_index_current += output_index_multiplier;\n      }\n      for (INDEX_TYPE j = 0; j < row_length - real_length; ++j) {\n        result->push_back(-1);\n      }\n    }\n    if (row_split_size > 0 && result->size() != row_split(row_split_size - 1)) {\n      return errors::InvalidArgument(\"Invalid row split size.\");\n    }\n\n    return Status::OK();\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,5 @@\n-void CalculateOutputIndexRowSplit(\n-      OpKernelContext* context, const RowPartitionTensor& row_split,\n+Status CalculateOutputIndexRowSplit(\n+      const RowPartitionTensor& row_split,\n       const vector<INDEX_TYPE>& parent_output_index,\n       INDEX_TYPE output_index_multiplier, INDEX_TYPE output_size,\n       vector<INDEX_TYPE>* result) {\n@@ -23,8 +23,9 @@\n         result->push_back(-1);\n       }\n     }\n-    if (row_split_size > 0) {\n-      OP_REQUIRES(context, result->size() == row_split(row_split_size - 1),\n-                  errors::InvalidArgument(\"Invalid row split size.\"));\n+    if (row_split_size > 0 && result->size() != row_split(row_split_size - 1)) {\n+      return errors::InvalidArgument(\"Invalid row split size.\");\n     }\n+\n+    return Status::OK();\n   }",
        "diff_line_info": {
            "deleted_lines": [
                "void CalculateOutputIndexRowSplit(",
                "      OpKernelContext* context, const RowPartitionTensor& row_split,",
                "    if (row_split_size > 0) {",
                "      OP_REQUIRES(context, result->size() == row_split(row_split_size - 1),",
                "                  errors::InvalidArgument(\"Invalid row split size.\"));"
            ],
            "added_lines": [
                "Status CalculateOutputIndexRowSplit(",
                "      const RowPartitionTensor& row_split,",
                "    if (row_split_size > 0 && result->size() != row_split(row_split_size - 1)) {",
                "      return errors::InvalidArgument(\"Invalid row split size.\");",
                "",
                "    return Status::OK();"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-29608",
        "func_name": "tensorflow/CalculateOutputIndexValueRowID",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. Due to lack of validation in `tf.raw_ops.RaggedTensorToTensor`, an attacker can exploit an undefined behavior if input arguments are empty. The implementation(https://github.com/tensorflow/tensorflow/blob/656e7673b14acd7835dc778867f84916c6d1cac2/tensorflow/core/kernels/ragged_tensor_to_tensor_op.cc#L356-L360) only checks that one of the tensors is not empty, but does not check for the other ones. There are multiple `DCHECK` validations to prevent heap OOB, but these are no-op in release builds, hence they don't prevent anything. The fix will be included in TensorFlow 2.5.0. We will also cherrypick these commits on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/c4d7afb6a5986b04505aca4466ae1951686c80f6",
        "commit_title": "Fix heap OOB / undefined behavior in `RaggedTensorToTensor`",
        "commit_text": " PiperOrigin-RevId: 373244623",
        "func_before": "void CalculateOutputIndexValueRowID(\n      OpKernelContext* context, const RowPartitionTensor& value_rowids,\n      const vector<INDEX_TYPE>& parent_output_index,\n      INDEX_TYPE output_index_multiplier, INDEX_TYPE output_size,\n      vector<INDEX_TYPE>* result) {\n    const INDEX_TYPE index_size = value_rowids.size();\n    result->reserve(index_size);\n    if (index_size == 0) {\n      return;\n    }\n\n    INDEX_TYPE current_output_column = 0;\n    INDEX_TYPE current_value_rowid = value_rowids(0);\n    DCHECK_LT(current_value_rowid, parent_output_index.size());\n    INDEX_TYPE current_output_index = parent_output_index[current_value_rowid];\n    result->push_back(current_output_index);\n    for (INDEX_TYPE i = 1; i < index_size; ++i) {\n      INDEX_TYPE next_value_rowid = value_rowids(i);\n      if (next_value_rowid == current_value_rowid) {\n        if (current_output_index >= 0) {\n          ++current_output_column;\n          if (current_output_column < output_size) {\n            current_output_index += output_index_multiplier;\n          } else {\n            current_output_index = -1;\n          }\n        }\n      } else {\n        current_output_column = 0;\n        current_value_rowid = next_value_rowid;\n        DCHECK_LT(next_value_rowid, parent_output_index.size());\n        current_output_index = parent_output_index[next_value_rowid];\n      }\n      result->push_back(current_output_index);\n    }\n    OP_REQUIRES(context, result->size() == value_rowids.size(),\n                errors::InvalidArgument(\"Invalid row ids.\"));\n  }",
        "func": "Status CalculateOutputIndexValueRowID(\n      const RowPartitionTensor& value_rowids,\n      const vector<INDEX_TYPE>& parent_output_index,\n      INDEX_TYPE output_index_multiplier, INDEX_TYPE output_size,\n      vector<INDEX_TYPE>* result) {\n    const INDEX_TYPE index_size = value_rowids.size();\n    result->reserve(index_size);\n    if (index_size == 0) {\n      return Status::OK();\n    }\n\n    INDEX_TYPE current_output_column = 0;\n    INDEX_TYPE current_value_rowid = value_rowids(0);\n\n    if (current_value_rowid >= parent_output_index.size()) {\n      return errors::InvalidArgument(\n          \"Got current_value_rowid=\", current_value_rowid,\n          \" which is not less than \", parent_output_index.size());\n    }\n\n    INDEX_TYPE current_output_index = parent_output_index[current_value_rowid];\n    result->push_back(current_output_index);\n    for (INDEX_TYPE i = 1; i < index_size; ++i) {\n      INDEX_TYPE next_value_rowid = value_rowids(i);\n      if (next_value_rowid == current_value_rowid) {\n        if (current_output_index >= 0) {\n          ++current_output_column;\n          if (current_output_column < output_size) {\n            current_output_index += output_index_multiplier;\n          } else {\n            current_output_index = -1;\n          }\n        }\n      } else {\n        current_output_column = 0;\n        current_value_rowid = next_value_rowid;\n\n        if (next_value_rowid >= parent_output_index.size()) {\n          return errors::InvalidArgument(\n              \"Got next_value_rowid=\", next_value_rowid,\n              \" which is not less than \", parent_output_index.size());\n        }\n\n        current_output_index = parent_output_index[next_value_rowid];\n      }\n      result->push_back(current_output_index);\n    }\n\n    if (result->size() != value_rowids.size()) {\n      return errors::InvalidArgument(\"Invalid row ids.\");\n    }\n\n    return Status::OK();\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,17 +1,23 @@\n-void CalculateOutputIndexValueRowID(\n-      OpKernelContext* context, const RowPartitionTensor& value_rowids,\n+Status CalculateOutputIndexValueRowID(\n+      const RowPartitionTensor& value_rowids,\n       const vector<INDEX_TYPE>& parent_output_index,\n       INDEX_TYPE output_index_multiplier, INDEX_TYPE output_size,\n       vector<INDEX_TYPE>* result) {\n     const INDEX_TYPE index_size = value_rowids.size();\n     result->reserve(index_size);\n     if (index_size == 0) {\n-      return;\n+      return Status::OK();\n     }\n \n     INDEX_TYPE current_output_column = 0;\n     INDEX_TYPE current_value_rowid = value_rowids(0);\n-    DCHECK_LT(current_value_rowid, parent_output_index.size());\n+\n+    if (current_value_rowid >= parent_output_index.size()) {\n+      return errors::InvalidArgument(\n+          \"Got current_value_rowid=\", current_value_rowid,\n+          \" which is not less than \", parent_output_index.size());\n+    }\n+\n     INDEX_TYPE current_output_index = parent_output_index[current_value_rowid];\n     result->push_back(current_output_index);\n     for (INDEX_TYPE i = 1; i < index_size; ++i) {\n@@ -28,11 +34,21 @@\n       } else {\n         current_output_column = 0;\n         current_value_rowid = next_value_rowid;\n-        DCHECK_LT(next_value_rowid, parent_output_index.size());\n+\n+        if (next_value_rowid >= parent_output_index.size()) {\n+          return errors::InvalidArgument(\n+              \"Got next_value_rowid=\", next_value_rowid,\n+              \" which is not less than \", parent_output_index.size());\n+        }\n+\n         current_output_index = parent_output_index[next_value_rowid];\n       }\n       result->push_back(current_output_index);\n     }\n-    OP_REQUIRES(context, result->size() == value_rowids.size(),\n-                errors::InvalidArgument(\"Invalid row ids.\"));\n+\n+    if (result->size() != value_rowids.size()) {\n+      return errors::InvalidArgument(\"Invalid row ids.\");\n+    }\n+\n+    return Status::OK();\n   }",
        "diff_line_info": {
            "deleted_lines": [
                "void CalculateOutputIndexValueRowID(",
                "      OpKernelContext* context, const RowPartitionTensor& value_rowids,",
                "      return;",
                "    DCHECK_LT(current_value_rowid, parent_output_index.size());",
                "        DCHECK_LT(next_value_rowid, parent_output_index.size());",
                "    OP_REQUIRES(context, result->size() == value_rowids.size(),",
                "                errors::InvalidArgument(\"Invalid row ids.\"));"
            ],
            "added_lines": [
                "Status CalculateOutputIndexValueRowID(",
                "      const RowPartitionTensor& value_rowids,",
                "      return Status::OK();",
                "",
                "    if (current_value_rowid >= parent_output_index.size()) {",
                "      return errors::InvalidArgument(",
                "          \"Got current_value_rowid=\", current_value_rowid,",
                "          \" which is not less than \", parent_output_index.size());",
                "    }",
                "",
                "",
                "        if (next_value_rowid >= parent_output_index.size()) {",
                "          return errors::InvalidArgument(",
                "              \"Got next_value_rowid=\", next_value_rowid,",
                "              \" which is not less than \", parent_output_index.size());",
                "        }",
                "",
                "",
                "    if (result->size() != value_rowids.size()) {",
                "      return errors::InvalidArgument(\"Invalid row ids.\");",
                "    }",
                "",
                "    return Status::OK();"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-29608",
        "func_name": "tensorflow/CalculateOutputIndex",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. Due to lack of validation in `tf.raw_ops.RaggedTensorToTensor`, an attacker can exploit an undefined behavior if input arguments are empty. The implementation(https://github.com/tensorflow/tensorflow/blob/656e7673b14acd7835dc778867f84916c6d1cac2/tensorflow/core/kernels/ragged_tensor_to_tensor_op.cc#L356-L360) only checks that one of the tensors is not empty, but does not check for the other ones. There are multiple `DCHECK` validations to prevent heap OOB, but these are no-op in release builds, hence they don't prevent anything. The fix will be included in TensorFlow 2.5.0. We will also cherrypick these commits on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/c4d7afb6a5986b04505aca4466ae1951686c80f6",
        "commit_title": "Fix heap OOB / undefined behavior in `RaggedTensorToTensor`",
        "commit_text": " PiperOrigin-RevId: 373244623",
        "func_before": "Status CalculateOutputIndex(OpKernelContext* context, int dimension,\n                              const vector<INDEX_TYPE>& parent_output_index,\n                              INDEX_TYPE output_index_multiplier,\n                              INDEX_TYPE output_size,\n                              vector<INDEX_TYPE>* result) {\n    const RowPartitionTensor row_partition_tensor =\n        GetRowPartitionTensor(context, dimension);\n    auto partition_type = GetRowPartitionTypeByDimension(dimension);\n    switch (partition_type) {\n      case RowPartitionType::VALUE_ROWIDS:\n        CalculateOutputIndexValueRowID(\n            context, row_partition_tensor, parent_output_index,\n            output_index_multiplier, output_size, result);\n        return tensorflow::Status::OK();\n      case RowPartitionType::ROW_SPLITS:\n        if (row_partition_tensor.size() - 1 > parent_output_index.size()) {\n          return errors::InvalidArgument(\n              \"Row partition size is greater than output size: \",\n              row_partition_tensor.size() - 1, \" > \",\n              parent_output_index.size());\n        }\n        CalculateOutputIndexRowSplit(\n            context, row_partition_tensor, parent_output_index,\n            output_index_multiplier, output_size, result);\n        return tensorflow::Status::OK();\n      default:\n        return errors::InvalidArgument(\n            \"Unsupported partition type:\",\n            RowPartitionTypeToString(partition_type));\n    }\n  }",
        "func": "Status CalculateOutputIndex(OpKernelContext* context, int dimension,\n                              const vector<INDEX_TYPE>& parent_output_index,\n                              INDEX_TYPE output_index_multiplier,\n                              INDEX_TYPE output_size,\n                              vector<INDEX_TYPE>* result) {\n    const RowPartitionTensor row_partition_tensor =\n        GetRowPartitionTensor(context, dimension);\n    auto partition_type = GetRowPartitionTypeByDimension(dimension);\n    switch (partition_type) {\n      case RowPartitionType::VALUE_ROWIDS:\n        return CalculateOutputIndexValueRowID(\n            row_partition_tensor, parent_output_index, output_index_multiplier,\n            output_size, result);\n      case RowPartitionType::ROW_SPLITS:\n        if (row_partition_tensor.size() - 1 > parent_output_index.size()) {\n          return errors::InvalidArgument(\n              \"Row partition size is greater than output size: \",\n              row_partition_tensor.size() - 1, \" > \",\n              parent_output_index.size());\n        }\n        return CalculateOutputIndexRowSplit(\n            row_partition_tensor, parent_output_index, output_index_multiplier,\n            output_size, result);\n      default:\n        return errors::InvalidArgument(\n            \"Unsupported partition type:\",\n            RowPartitionTypeToString(partition_type));\n    }\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -8,10 +8,9 @@\n     auto partition_type = GetRowPartitionTypeByDimension(dimension);\n     switch (partition_type) {\n       case RowPartitionType::VALUE_ROWIDS:\n-        CalculateOutputIndexValueRowID(\n-            context, row_partition_tensor, parent_output_index,\n-            output_index_multiplier, output_size, result);\n-        return tensorflow::Status::OK();\n+        return CalculateOutputIndexValueRowID(\n+            row_partition_tensor, parent_output_index, output_index_multiplier,\n+            output_size, result);\n       case RowPartitionType::ROW_SPLITS:\n         if (row_partition_tensor.size() - 1 > parent_output_index.size()) {\n           return errors::InvalidArgument(\n@@ -19,10 +18,9 @@\n               row_partition_tensor.size() - 1, \" > \",\n               parent_output_index.size());\n         }\n-        CalculateOutputIndexRowSplit(\n-            context, row_partition_tensor, parent_output_index,\n-            output_index_multiplier, output_size, result);\n-        return tensorflow::Status::OK();\n+        return CalculateOutputIndexRowSplit(\n+            row_partition_tensor, parent_output_index, output_index_multiplier,\n+            output_size, result);\n       default:\n         return errors::InvalidArgument(\n             \"Unsupported partition type:\",",
        "diff_line_info": {
            "deleted_lines": [
                "        CalculateOutputIndexValueRowID(",
                "            context, row_partition_tensor, parent_output_index,",
                "            output_index_multiplier, output_size, result);",
                "        return tensorflow::Status::OK();",
                "        CalculateOutputIndexRowSplit(",
                "            context, row_partition_tensor, parent_output_index,",
                "            output_index_multiplier, output_size, result);",
                "        return tensorflow::Status::OK();"
            ],
            "added_lines": [
                "        return CalculateOutputIndexValueRowID(",
                "            row_partition_tensor, parent_output_index, output_index_multiplier,",
                "            output_size, result);",
                "        return CalculateOutputIndexRowSplit(",
                "            row_partition_tensor, parent_output_index, output_index_multiplier,",
                "            output_size, result);"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-29608",
        "func_name": "tensorflow/Compute",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. Due to lack of validation in `tf.raw_ops.RaggedTensorToTensor`, an attacker can exploit an undefined behavior if input arguments are empty. The implementation(https://github.com/tensorflow/tensorflow/blob/656e7673b14acd7835dc778867f84916c6d1cac2/tensorflow/core/kernels/ragged_tensor_to_tensor_op.cc#L356-L360) only checks that one of the tensors is not empty, but does not check for the other ones. There are multiple `DCHECK` validations to prevent heap OOB, but these are no-op in release builds, hence they don't prevent anything. The fix will be included in TensorFlow 2.5.0. We will also cherrypick these commits on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/f94ef358bb3e91d517446454edff6535bcfe8e4a",
        "commit_title": "Fix `tf.raw_ops.RaggedTensorToTensor` failing CHECK in `tensor.cc`.",
        "commit_text": " PiperOrigin-RevId: 368300502",
        "func_before": "void Compute(OpKernelContext* context) override {\n    INDEX_TYPE first_dimension;\n    OP_REQUIRES_OK(context, GetFirstDimensionSize(context, &first_dimension));\n    vector<INDEX_TYPE> output_size;\n    OP_REQUIRES_OK(context,\n                   CalculateOutputSize(first_dimension, context, &output_size));\n    vector<INDEX_TYPE> multiplier;\n    multiplier.resize(ragged_rank_ + 1);\n\n    multiplier[multiplier.size() - 1] = 1;\n    for (int i = multiplier.size() - 2; i >= 0; --i) {\n      multiplier[i] = multiplier[i + 1] * output_size[i + 1];\n    }\n    // Full size of the tensor.\n    TensorShape output_shape;\n    OP_REQUIRES_OK(context,\n                   TensorShapeUtils::MakeShape(output_size, &output_shape));\n    Tensor* output_tensor = nullptr;\n\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(0, output_shape, &output_tensor));\n    const INDEX_TYPE full_size = multiplier[0] * output_size[0];\n    if (full_size > 0) {\n      vector<INDEX_TYPE> output_index, new_output_index;\n      int nvals = context->input(kValueInputIndex).shape().dim_size(0);\n      output_index.reserve(nvals);\n      new_output_index.reserve(nvals);\n\n      CalculateFirstParentOutputIndex(first_dimension, multiplier[0],\n                                      output_size[0], &output_index);\n      for (int i = 1; i <= ragged_rank_; ++i) {\n        OP_REQUIRES_OK(context, CalculateOutputIndex(\n                                    context, i - 1, output_index, multiplier[i],\n                                    output_size[i], &new_output_index));\n        output_index.swap(new_output_index);\n        new_output_index.clear();\n      }\n\n      SetOutput(context, ragged_rank_, output_index, output_tensor);\n    }\n  }",
        "func": "void Compute(OpKernelContext* context) override {\n    INDEX_TYPE first_dimension;\n    const Tensor first_partition_tensor =\n        context->input(kFirstPartitionInputIndex);\n    OP_REQUIRES(context, first_partition_tensor.NumElements() > 0,\n                errors::InvalidArgument(\"Invalid first partition input. Tensor \"\n                                        \"requires at least one element.\"));\n    OP_REQUIRES_OK(context, GetFirstDimensionSize(context, &first_dimension));\n    vector<INDEX_TYPE> output_size;\n    OP_REQUIRES_OK(context,\n                   CalculateOutputSize(first_dimension, context, &output_size));\n    vector<INDEX_TYPE> multiplier;\n    multiplier.resize(ragged_rank_ + 1);\n\n    multiplier[multiplier.size() - 1] = 1;\n    for (int i = multiplier.size() - 2; i >= 0; --i) {\n      multiplier[i] = multiplier[i + 1] * output_size[i + 1];\n    }\n    // Full size of the tensor.\n    TensorShape output_shape;\n    OP_REQUIRES_OK(context,\n                   TensorShapeUtils::MakeShape(output_size, &output_shape));\n    Tensor* output_tensor = nullptr;\n\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(0, output_shape, &output_tensor));\n    const INDEX_TYPE full_size = multiplier[0] * output_size[0];\n    if (full_size > 0) {\n      vector<INDEX_TYPE> output_index, new_output_index;\n      int nvals = context->input(kValueInputIndex).shape().dim_size(0);\n      output_index.reserve(nvals);\n      new_output_index.reserve(nvals);\n\n      CalculateFirstParentOutputIndex(first_dimension, multiplier[0],\n                                      output_size[0], &output_index);\n      for (int i = 1; i <= ragged_rank_; ++i) {\n        OP_REQUIRES_OK(context, CalculateOutputIndex(\n                                    context, i - 1, output_index, multiplier[i],\n                                    output_size[i], &new_output_index));\n        output_index.swap(new_output_index);\n        new_output_index.clear();\n      }\n\n      SetOutput(context, ragged_rank_, output_index, output_tensor);\n    }\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,10 @@\n void Compute(OpKernelContext* context) override {\n     INDEX_TYPE first_dimension;\n+    const Tensor first_partition_tensor =\n+        context->input(kFirstPartitionInputIndex);\n+    OP_REQUIRES(context, first_partition_tensor.NumElements() > 0,\n+                errors::InvalidArgument(\"Invalid first partition input. Tensor \"\n+                                        \"requires at least one element.\"));\n     OP_REQUIRES_OK(context, GetFirstDimensionSize(context, &first_dimension));\n     vector<INDEX_TYPE> output_size;\n     OP_REQUIRES_OK(context,",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    const Tensor first_partition_tensor =",
                "        context->input(kFirstPartitionInputIndex);",
                "    OP_REQUIRES(context, first_partition_tensor.NumElements() > 0,",
                "                errors::InvalidArgument(\"Invalid first partition input. Tensor \"",
                "                                        \"requires at least one element.\"));"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-41885",
        "func_name": "tensorflow/Compute",
        "description": "TensorFlow is an open source platform for machine learning. When `tf.raw_ops.FusedResizeAndPadConv2D` is given a large tensor shape, it overflows. We have patched the issue in GitHub commit d66e1d568275e6a2947de97dca7a102a211e01ce. The fix will be included in TensorFlow 2.11. We will also cherrypick this commit on TensorFlow 2.10.1, 2.9.3, and TensorFlow 2.8.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/d66e1d568275e6a2947de97dca7a102a211e01ce",
        "commit_title": "Fix tensor shape overflow in FusedResizeAndPadConv2D.",
        "commit_text": " Replaced TensorShape constructor by Factory method with status.  PiperOrigin-RevId: 477742686",
        "func_before": "void Compute(OpKernelContext* context) override {\n    // Input tensor is of the following dimensions:\n    // [ batch, in_rows, in_cols, in_depth ]\n    const Tensor& input = context->input(0);\n    OP_REQUIRES(context, (input.shape().num_elements() > 0),\n                errors::InvalidArgument(\"Input tensor can't be empty\"));\n\n    ImageResizerState st(false, false);\n    if (DoResize) {\n      st = ImageResizerState(align_corners_, false);\n      st.ValidateAndCalculateOutputSize(context);\n      if (!context->status().ok()) return;\n    } else {\n      // Set up the resize parameters to do no scaling at all.\n      st.batch_size = input.dim_size(0);\n      st.out_height = input.dim_size(1);\n      st.out_width = input.dim_size(2);\n      st.in_height = input.dim_size(1);\n      st.in_width = input.dim_size(2);\n      st.channels = input.dim_size(3);\n      st.height_scale = 1.0f;\n      st.width_scale = 1.0f;\n    }\n    TensorShape resized_shape(\n        {input.dim_size(0), st.out_height, st.out_width, input.dim_size(3)});\n    int paddings_index;\n    int filter_index;\n    if (DoResize) {\n      paddings_index = 2;\n      filter_index = 3;\n    } else {\n      paddings_index = 1;\n      filter_index = 2;\n    }\n    const Tensor& paddings = context->input(paddings_index);\n\n    const int dims = resized_shape.dims();\n    OP_REQUIRES(\n        context,\n        TensorShapeUtils::IsMatrix(paddings.shape()) &&\n            paddings.dim_size(1) == 2,\n        errors::InvalidArgument(\"paddings must be a matrix with 2 columns: \",\n                                paddings.shape().DebugString()));\n    OP_REQUIRES(\n        context, dims == paddings.dim_size(0),\n        errors::InvalidArgument(\n            \"The first dimension of paddings must be the rank of inputs: \",\n            dims, \" \", paddings.shape().DebugString(), \" \",\n            resized_shape.DebugString()));\n    OP_REQUIRES(\n        context, dims == paddings.dim_size(0),\n        errors::InvalidArgument(\n            \"The first dimension of paddings must be the rank of inputs: \",\n            dims, \" \", paddings.shape().DebugString(), \" \",\n            resized_shape.DebugString()));\n\n    OP_REQUIRES(\n        context, dims == 4,\n        errors::InvalidArgument(\n            \"Fused mirror padding only supports four-dimensional inputs, but \",\n            dims, \" requested\"));\n\n    // Compute the shape of the output tensor, and allocate it.\n    TensorShape padded_shape;\n    TTypes<int32>::ConstMatrix paddings_matrix = paddings.matrix<int32>();\n    for (int d = 0; d < dims; ++d) {\n      const int32_t before =\n          paddings_matrix(d, 0);  // Pad before existing elements.\n      const int32_t after =\n          paddings_matrix(d, 1);  // Pad after existing elements.\n      OP_REQUIRES(context, before >= 0 && after >= 0,\n                  errors::InvalidArgument(\n                      \"paddings must be non-negative: \", before, \" \", after));\n      if (offset_ == 0) {  // SYMMETRIC mode.\n        OP_REQUIRES(\n            context,\n            before <= resized_shape.dim_size(d) &&\n                after <= resized_shape.dim_size(d),\n            errors::InvalidArgument(\"paddings must be no greater \"\n                                    \"than the dimension size: \",\n                                    before, \", \", after, \" greater than \",\n                                    resized_shape.dim_size(d)));\n      } else if (offset_ == 1) {  // REFLECT mode.\n        OP_REQUIRES(\n            context,\n            before < resized_shape.dim_size(d) &&\n                after < resized_shape.dim_size(d),\n            errors::InvalidArgument(\"paddings must be less than\"\n                                    \" the dimension size: \",\n                                    before, \", \", after, \" not less than \",\n                                    resized_shape.dim_size(d)));\n      }\n      padded_shape.AddDim(before + resized_shape.dim_size(d) + after);\n    }\n\n    OP_REQUIRES(\n        context, ((paddings_matrix(0, 0) == 0) && (paddings_matrix(0, 1) == 0)),\n        errors::InvalidArgument(\n            \"Fused mirror padding only support spatial padding, not batches: \",\n            paddings.DebugString()));\n    OP_REQUIRES(\n        context, ((paddings_matrix(3, 0) == 0) && (paddings_matrix(3, 1) == 0)),\n        errors::InvalidArgument(\n            \"Fused mirror padding only support spatial padding, not channels: \",\n            paddings.DebugString()));\n    const int32_t top_padding = paddings_matrix(1, 0);\n    const int32_t bottom_padding = paddings_matrix(1, 1);\n    const int32_t left_padding = paddings_matrix(2, 0);\n    const int32_t right_padding = paddings_matrix(2, 1);\n\n    // Input filter is of the following dimensions:\n    // [ filter_rows, filter_cols, in_depth, out_depth]\n    const Tensor& filter = context->input(filter_index);\n\n    // For 2D convolution, there should be 4 dimensions.\n    OP_REQUIRES(context, padded_shape.dims() == 4,\n                errors::InvalidArgument(\"input must be 4-dimensional\",\n                                        padded_shape.DebugString()));\n    OP_REQUIRES(context, filter.dims() == 4,\n                errors::InvalidArgument(\"filter must be 4-dimensional: \",\n                                        filter.shape().DebugString()));\n\n    // We only check the first three dims, since the depth is accessed as an\n    // int64 below.\n    for (int i = 0; i < 3; i++) {\n      OP_REQUIRES(\n          context,\n          FastBoundsCheck(filter.dim_size(i), std::numeric_limits<int>::max()),\n          errors::InvalidArgument(\"filter too large\"));\n    }\n\n    // The last dimension for input is in_depth. It must be the same as the\n    // filter's in_depth.\n    const int64_t in_depth = padded_shape.dim_size(3);\n    OP_REQUIRES(context, in_depth == filter.dim_size(2),\n                errors::InvalidArgument(\n                    \"input and filter must have the same depth: \", in_depth,\n                    \" vs \", filter.dim_size(2)));\n\n    // The last dimension for filter is out_depth.\n    const int out_depth = static_cast<int>(filter.dim_size(3));\n\n    // The second dimension for input is rows/height.\n    // The first dimension for filter is rows/height.\n    const int64_t padded_rows_raw = padded_shape.dim_size(1);\n    OP_REQUIRES(\n        context,\n        FastBoundsCheck(padded_rows_raw, std::numeric_limits<int>::max()),\n        errors::InvalidArgument(\"Input rows too large\"));\n    const int padded_rows = static_cast<int>(padded_rows_raw);\n    const int filter_rows = static_cast<int>(filter.dim_size(0));\n    const int resized_rows = static_cast<int>(resized_shape.dim_size(1));\n\n    // The third dimension for input is columns/width.\n    // The second dimension for filter is columns/width.\n    const int64_t padded_cols_raw = padded_shape.dim_size(2);\n    OP_REQUIRES(\n        context,\n        FastBoundsCheck(padded_cols_raw, std::numeric_limits<int>::max()),\n        errors::InvalidArgument(\"Input cols too large\"));\n    const int padded_cols = static_cast<int>(padded_cols_raw);\n    const int filter_cols = static_cast<int>(filter.dim_size(1));\n    const int resized_cols = static_cast<int>(resized_shape.dim_size(2));\n\n    // The first dimension for input is batch.\n    const int64_t batch_raw = padded_shape.dim_size(0);\n    OP_REQUIRES(context,\n                FastBoundsCheck(batch_raw, std::numeric_limits<int>::max()),\n                errors::InvalidArgument(\"batch is too large\"));\n    const int batch = static_cast<int>(batch_raw);\n\n    // For now we take the stride from the second and third dimensions only (we\n    // do not support striding on the batch or depth dimension).\n    const int stride_rows = GetTensorDim(strides_, FORMAT_NHWC, 'H');\n    const int stride_cols = GetTensorDim(strides_, FORMAT_NHWC, 'W');\n\n    int64_t out_rows = 0, out_cols = 0, pad_rows = 0, pad_cols = 0;\n    OP_REQUIRES_OK(context,\n                   GetWindowedOutputSize(padded_rows, filter_rows, stride_rows,\n                                         padding_, &out_rows, &pad_rows));\n    OP_REQUIRES_OK(context,\n                   GetWindowedOutputSize(padded_cols, filter_cols, stride_cols,\n                                         padding_, &out_cols, &pad_cols));\n    TensorShape out_shape =\n        ShapeFromFormat(FORMAT_NHWC, batch, out_rows, out_cols, out_depth);\n    OP_REQUIRES(context, (out_shape.num_elements() > 0),\n                errors::InvalidArgument(\"Output tensor can't be empty\"));\n\n    // Output tensor is of the following dimensions:\n    // [ in_batch, out_rows, out_cols, out_depth ]\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(context, context->allocate_output(0, out_shape, &output));\n\n    VLOG(2) << \"FusedConv2D: \" << name() << \", in_depth = \" << in_depth\n            << \", padded_cols = \" << padded_cols\n            << \", resized_cols = \" << resized_cols\n            << \", filter_cols = \" << filter_cols\n            << \", padded_rows = \" << padded_rows\n            << \", resized_rows = \" << resized_rows\n            << \", filter_rows = \" << filter_rows\n            << \", stride_rows = \" << stride_rows\n            << \", stride_cols = \" << stride_cols\n            << \", out_depth = \" << out_depth << \", DoResize=\" << DoResize;\n\n    // If there is nothing to compute, return.\n    if (out_shape.num_elements() == 0) {\n      return;\n    }\n    TConvFunctor conv_functor;\n    conv_functor(context, input, batch, resized_rows, resized_cols, padded_rows,\n                 padded_cols, in_depth, filter.flat<T>().data(), filter_rows,\n                 filter_cols, out_depth, stride_rows, stride_cols, padding_,\n                 output->flat<T>().data(), out_rows, out_cols, st, top_padding,\n                 bottom_padding, left_padding, right_padding, offset_);\n  }",
        "func": "void Compute(OpKernelContext* context) override {\n    // Input tensor is of the following dimensions:\n    // [ batch, in_rows, in_cols, in_depth ]\n    const Tensor& input = context->input(0);\n    OP_REQUIRES(context, (input.shape().num_elements() > 0),\n                errors::InvalidArgument(\"Input tensor can't be empty\"));\n\n    ImageResizerState st(false, false);\n    if (DoResize) {\n      st = ImageResizerState(align_corners_, false);\n      st.ValidateAndCalculateOutputSize(context);\n      if (!context->status().ok()) return;\n    } else {\n      // Set up the resize parameters to do no scaling at all.\n      st.batch_size = input.dim_size(0);\n      st.out_height = input.dim_size(1);\n      st.out_width = input.dim_size(2);\n      st.in_height = input.dim_size(1);\n      st.in_width = input.dim_size(2);\n      st.channels = input.dim_size(3);\n      st.height_scale = 1.0f;\n      st.width_scale = 1.0f;\n    }\n    TensorShape resized_shape;\n    OP_REQUIRES_OK(context, TensorShape::BuildTensorShape(\n                                {input.dim_size(0), st.out_height, st.out_width,\n                                 input.dim_size(3)},\n                                &resized_shape));\n    int paddings_index;\n    int filter_index;\n    if (DoResize) {\n      paddings_index = 2;\n      filter_index = 3;\n    } else {\n      paddings_index = 1;\n      filter_index = 2;\n    }\n    const Tensor& paddings = context->input(paddings_index);\n\n    const int dims = resized_shape.dims();\n    OP_REQUIRES(\n        context,\n        TensorShapeUtils::IsMatrix(paddings.shape()) &&\n            paddings.dim_size(1) == 2,\n        errors::InvalidArgument(\"paddings must be a matrix with 2 columns: \",\n                                paddings.shape().DebugString()));\n    OP_REQUIRES(\n        context, dims == paddings.dim_size(0),\n        errors::InvalidArgument(\n            \"The first dimension of paddings must be the rank of inputs: \",\n            dims, \" \", paddings.shape().DebugString(), \" \",\n            resized_shape.DebugString()));\n    OP_REQUIRES(\n        context, dims == paddings.dim_size(0),\n        errors::InvalidArgument(\n            \"The first dimension of paddings must be the rank of inputs: \",\n            dims, \" \", paddings.shape().DebugString(), \" \",\n            resized_shape.DebugString()));\n\n    OP_REQUIRES(\n        context, dims == 4,\n        errors::InvalidArgument(\n            \"Fused mirror padding only supports four-dimensional inputs, but \",\n            dims, \" requested\"));\n\n    // Compute the shape of the output tensor, and allocate it.\n    TensorShape padded_shape;\n    TTypes<int32>::ConstMatrix paddings_matrix = paddings.matrix<int32>();\n    for (int d = 0; d < dims; ++d) {\n      const int32_t before =\n          paddings_matrix(d, 0);  // Pad before existing elements.\n      const int32_t after =\n          paddings_matrix(d, 1);  // Pad after existing elements.\n      OP_REQUIRES(context, before >= 0 && after >= 0,\n                  errors::InvalidArgument(\n                      \"paddings must be non-negative: \", before, \" \", after));\n      if (offset_ == 0) {  // SYMMETRIC mode.\n        OP_REQUIRES(\n            context,\n            before <= resized_shape.dim_size(d) &&\n                after <= resized_shape.dim_size(d),\n            errors::InvalidArgument(\"paddings must be no greater \"\n                                    \"than the dimension size: \",\n                                    before, \", \", after, \" greater than \",\n                                    resized_shape.dim_size(d)));\n      } else if (offset_ == 1) {  // REFLECT mode.\n        OP_REQUIRES(\n            context,\n            before < resized_shape.dim_size(d) &&\n                after < resized_shape.dim_size(d),\n            errors::InvalidArgument(\"paddings must be less than\"\n                                    \" the dimension size: \",\n                                    before, \", \", after, \" not less than \",\n                                    resized_shape.dim_size(d)));\n      }\n      padded_shape.AddDim(before + resized_shape.dim_size(d) + after);\n    }\n\n    OP_REQUIRES(\n        context, ((paddings_matrix(0, 0) == 0) && (paddings_matrix(0, 1) == 0)),\n        errors::InvalidArgument(\n            \"Fused mirror padding only support spatial padding, not batches: \",\n            paddings.DebugString()));\n    OP_REQUIRES(\n        context, ((paddings_matrix(3, 0) == 0) && (paddings_matrix(3, 1) == 0)),\n        errors::InvalidArgument(\n            \"Fused mirror padding only support spatial padding, not channels: \",\n            paddings.DebugString()));\n    const int32_t top_padding = paddings_matrix(1, 0);\n    const int32_t bottom_padding = paddings_matrix(1, 1);\n    const int32_t left_padding = paddings_matrix(2, 0);\n    const int32_t right_padding = paddings_matrix(2, 1);\n\n    // Input filter is of the following dimensions:\n    // [ filter_rows, filter_cols, in_depth, out_depth]\n    const Tensor& filter = context->input(filter_index);\n\n    // For 2D convolution, there should be 4 dimensions.\n    OP_REQUIRES(context, padded_shape.dims() == 4,\n                errors::InvalidArgument(\"input must be 4-dimensional\",\n                                        padded_shape.DebugString()));\n    OP_REQUIRES(context, filter.dims() == 4,\n                errors::InvalidArgument(\"filter must be 4-dimensional: \",\n                                        filter.shape().DebugString()));\n\n    // We only check the first three dims, since the depth is accessed as an\n    // int64 below.\n    for (int i = 0; i < 3; i++) {\n      OP_REQUIRES(\n          context,\n          FastBoundsCheck(filter.dim_size(i), std::numeric_limits<int>::max()),\n          errors::InvalidArgument(\"filter too large\"));\n    }\n\n    // The last dimension for input is in_depth. It must be the same as the\n    // filter's in_depth.\n    const int64_t in_depth = padded_shape.dim_size(3);\n    OP_REQUIRES(context, in_depth == filter.dim_size(2),\n                errors::InvalidArgument(\n                    \"input and filter must have the same depth: \", in_depth,\n                    \" vs \", filter.dim_size(2)));\n\n    // The last dimension for filter is out_depth.\n    const int out_depth = static_cast<int>(filter.dim_size(3));\n\n    // The second dimension for input is rows/height.\n    // The first dimension for filter is rows/height.\n    const int64_t padded_rows_raw = padded_shape.dim_size(1);\n    OP_REQUIRES(\n        context,\n        FastBoundsCheck(padded_rows_raw, std::numeric_limits<int>::max()),\n        errors::InvalidArgument(\"Input rows too large\"));\n    const int padded_rows = static_cast<int>(padded_rows_raw);\n    const int filter_rows = static_cast<int>(filter.dim_size(0));\n    const int resized_rows = static_cast<int>(resized_shape.dim_size(1));\n\n    // The third dimension for input is columns/width.\n    // The second dimension for filter is columns/width.\n    const int64_t padded_cols_raw = padded_shape.dim_size(2);\n    OP_REQUIRES(\n        context,\n        FastBoundsCheck(padded_cols_raw, std::numeric_limits<int>::max()),\n        errors::InvalidArgument(\"Input cols too large\"));\n    const int padded_cols = static_cast<int>(padded_cols_raw);\n    const int filter_cols = static_cast<int>(filter.dim_size(1));\n    const int resized_cols = static_cast<int>(resized_shape.dim_size(2));\n\n    // The first dimension for input is batch.\n    const int64_t batch_raw = padded_shape.dim_size(0);\n    OP_REQUIRES(context,\n                FastBoundsCheck(batch_raw, std::numeric_limits<int>::max()),\n                errors::InvalidArgument(\"batch is too large\"));\n    const int batch = static_cast<int>(batch_raw);\n\n    // For now we take the stride from the second and third dimensions only (we\n    // do not support striding on the batch or depth dimension).\n    const int stride_rows = GetTensorDim(strides_, FORMAT_NHWC, 'H');\n    const int stride_cols = GetTensorDim(strides_, FORMAT_NHWC, 'W');\n\n    int64_t out_rows = 0, out_cols = 0, pad_rows = 0, pad_cols = 0;\n    OP_REQUIRES_OK(context,\n                   GetWindowedOutputSize(padded_rows, filter_rows, stride_rows,\n                                         padding_, &out_rows, &pad_rows));\n    OP_REQUIRES_OK(context,\n                   GetWindowedOutputSize(padded_cols, filter_cols, stride_cols,\n                                         padding_, &out_cols, &pad_cols));\n    TensorShape out_shape =\n        ShapeFromFormat(FORMAT_NHWC, batch, out_rows, out_cols, out_depth);\n    OP_REQUIRES(context, (out_shape.num_elements() > 0),\n                errors::InvalidArgument(\"Output tensor can't be empty\"));\n\n    // Output tensor is of the following dimensions:\n    // [ in_batch, out_rows, out_cols, out_depth ]\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(context, context->allocate_output(0, out_shape, &output));\n\n    VLOG(2) << \"FusedConv2D: \" << name() << \", in_depth = \" << in_depth\n            << \", padded_cols = \" << padded_cols\n            << \", resized_cols = \" << resized_cols\n            << \", filter_cols = \" << filter_cols\n            << \", padded_rows = \" << padded_rows\n            << \", resized_rows = \" << resized_rows\n            << \", filter_rows = \" << filter_rows\n            << \", stride_rows = \" << stride_rows\n            << \", stride_cols = \" << stride_cols\n            << \", out_depth = \" << out_depth << \", DoResize=\" << DoResize;\n\n    // If there is nothing to compute, return.\n    if (out_shape.num_elements() == 0) {\n      return;\n    }\n    TConvFunctor conv_functor;\n    conv_functor(context, input, batch, resized_rows, resized_cols, padded_rows,\n                 padded_cols, in_depth, filter.flat<T>().data(), filter_rows,\n                 filter_cols, out_depth, stride_rows, stride_cols, padding_,\n                 output->flat<T>().data(), out_rows, out_cols, st, top_padding,\n                 bottom_padding, left_padding, right_padding, offset_);\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -21,8 +21,11 @@\n       st.height_scale = 1.0f;\n       st.width_scale = 1.0f;\n     }\n-    TensorShape resized_shape(\n-        {input.dim_size(0), st.out_height, st.out_width, input.dim_size(3)});\n+    TensorShape resized_shape;\n+    OP_REQUIRES_OK(context, TensorShape::BuildTensorShape(\n+                                {input.dim_size(0), st.out_height, st.out_width,\n+                                 input.dim_size(3)},\n+                                &resized_shape));\n     int paddings_index;\n     int filter_index;\n     if (DoResize) {",
        "diff_line_info": {
            "deleted_lines": [
                "    TensorShape resized_shape(",
                "        {input.dim_size(0), st.out_height, st.out_width, input.dim_size(3)});"
            ],
            "added_lines": [
                "    TensorShape resized_shape;",
                "    OP_REQUIRES_OK(context, TensorShape::BuildTensorShape(",
                "                                {input.dim_size(0), st.out_height, st.out_width,",
                "                                 input.dim_size(3)},",
                "                                &resized_shape));"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-41886",
        "func_name": "tensorflow/DoImageProjectiveTransformOp",
        "description": "TensorFlow is an open source platform for machine learning. When `tf.raw_ops.ImageProjectiveTransformV2` is given a large output shape, it overflows. We have patched the issue in GitHub commit 8faa6ea692985dbe6ce10e1a3168e0bd60a723ba. The fix will be included in TensorFlow 2.11. We will also cherrypick this commit on TensorFlow 2.10.1, 2.9.3, and TensorFlow 2.8.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/8faa6ea692985dbe6ce10e1a3168e0bd60a723ba",
        "commit_title": "Fix tf.raw_ops.ImageProjectiveTransformV2 vulnerability with large output_shape.",
        "commit_text": " Note: This fix will have to be cherry picked in r2.10, r2.9, and r2.8. PiperOrigin-RevId: 479125772",
        "func_before": "void DoImageProjectiveTransformOp(OpKernelContext* ctx,\n                                  const Interpolation& interpolation,\n                                  const Mode& fill_mode) {\n  const Tensor& images_t = ctx->input(0);\n  const Tensor& transform_t = ctx->input(1);\n  OP_REQUIRES(ctx, images_t.shape().dims() == 4,\n              errors::InvalidArgument(\"Input images must have rank 4\"));\n  OP_REQUIRES(ctx,\n              (TensorShapeUtils::IsMatrix(transform_t.shape()) &&\n               (transform_t.dim_size(0) == images_t.dim_size(0) ||\n                transform_t.dim_size(0) == 1) &&\n               transform_t.dim_size(1) == 8),\n              errors::InvalidArgument(\n                  \"Input transform should be num_images x 8 or 1 x 8\"));\n\n  int32_t out_height, out_width;\n  // Kernel is shared by legacy \"ImageProjectiveTransform\" op with 2 args.\n  if (ctx->num_inputs() >= 3) {\n    const Tensor& shape_t = ctx->input(2);\n    OP_REQUIRES(ctx, shape_t.dims() == 1,\n                errors::InvalidArgument(\"output shape must be 1-dimensional\",\n                                        shape_t.shape().DebugString()));\n    OP_REQUIRES(ctx, shape_t.NumElements() == 2,\n                errors::InvalidArgument(\"output shape must have two elements\",\n                                        shape_t.shape().DebugString()));\n    auto shape_vec = shape_t.vec<int32>();\n    out_height = shape_vec(0);\n    out_width = shape_vec(1);\n    OP_REQUIRES(ctx, out_height > 0 && out_width > 0,\n                errors::InvalidArgument(\"output dimensions must be positive\"));\n  } else {\n    // Shape is N (batch size), H (height), W (width), C (channels).\n    out_height = images_t.shape().dim_size(1);\n    out_width = images_t.shape().dim_size(2);\n  }\n\n  T fill_value(0);\n  // Kernel is shared by \"ImageProjectiveTransformV2\" with 3 args.\n  if (ctx->num_inputs() >= 4) {\n    const Tensor& fill_value_t = ctx->input(3);\n    OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(fill_value_t.shape()),\n                errors::InvalidArgument(\"fill_value must be a scalar\",\n                                        fill_value_t.shape().DebugString()));\n    fill_value = static_cast<T>(*(fill_value_t.scalar<float>().data()));\n  }\n\n  Tensor* output_t;\n  OP_REQUIRES_OK(\n      ctx, ctx->allocate_output(0,\n                                TensorShape({images_t.dim_size(0), out_height,\n                                             out_width, images_t.dim_size(3)}),\n                                &output_t));\n  auto output = output_t->tensor<T, 4>();\n  auto images = images_t.tensor<T, 4>();\n  auto transform = transform_t.matrix<float>();\n\n  (FillProjectiveTransform<Device, T>(interpolation))(\n      ctx->eigen_device<Device>(), &output, images, transform, fill_mode,\n      fill_value);\n}",
        "func": "void DoImageProjectiveTransformOp(OpKernelContext* ctx,\n                                  const Interpolation& interpolation,\n                                  const Mode& fill_mode) {\n  const Tensor& images_t = ctx->input(0);\n  const Tensor& transform_t = ctx->input(1);\n  OP_REQUIRES(ctx, images_t.shape().dims() == 4,\n              errors::InvalidArgument(\"Input images must have rank 4\"));\n  OP_REQUIRES(ctx,\n              (TensorShapeUtils::IsMatrix(transform_t.shape()) &&\n               (transform_t.dim_size(0) == images_t.dim_size(0) ||\n                transform_t.dim_size(0) == 1) &&\n               transform_t.dim_size(1) == 8),\n              errors::InvalidArgument(\n                  \"Input transform should be num_images x 8 or 1 x 8\"));\n\n  int32_t out_height, out_width;\n  // Kernel is shared by legacy \"ImageProjectiveTransform\" op with 2 args.\n  if (ctx->num_inputs() >= 3) {\n    const Tensor& shape_t = ctx->input(2);\n    OP_REQUIRES(ctx, shape_t.dims() == 1,\n                errors::InvalidArgument(\"output shape must be 1-dimensional\",\n                                        shape_t.shape().DebugString()));\n    OP_REQUIRES(ctx, shape_t.NumElements() == 2,\n                errors::InvalidArgument(\"output shape must have two elements\",\n                                        shape_t.shape().DebugString()));\n    auto shape_vec = shape_t.vec<int32>();\n    out_height = shape_vec(0);\n    out_width = shape_vec(1);\n    OP_REQUIRES(ctx, out_height > 0 && out_width > 0,\n                errors::InvalidArgument(\"output dimensions must be positive\"));\n  } else {\n    // Shape is N (batch size), H (height), W (width), C (channels).\n    out_height = images_t.shape().dim_size(1);\n    out_width = images_t.shape().dim_size(2);\n  }\n\n  T fill_value(0);\n  // Kernel is shared by \"ImageProjectiveTransformV2\" with 3 args.\n  if (ctx->num_inputs() >= 4) {\n    const Tensor& fill_value_t = ctx->input(3);\n    OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(fill_value_t.shape()),\n                errors::InvalidArgument(\"fill_value must be a scalar\",\n                                        fill_value_t.shape().DebugString()));\n    fill_value = static_cast<T>(*(fill_value_t.scalar<float>().data()));\n  }\n\n  Tensor* output_t;\n  TensorShape output_shape;\n  OP_REQUIRES_OK(\n      ctx, TensorShape::BuildTensorShape({images_t.dim_size(0), out_height,\n                                          out_width, images_t.dim_size(3)},\n                                         &output_shape));\n  OP_REQUIRES_OK(ctx, ctx->allocate_output(0, output_shape, &output_t));\n  auto output = output_t->tensor<T, 4>();\n  auto images = images_t.tensor<T, 4>();\n  auto transform = transform_t.matrix<float>();\n\n  (FillProjectiveTransform<Device, T>(interpolation))(\n      ctx->eigen_device<Device>(), &output, images, transform, fill_mode,\n      fill_value);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -45,11 +45,12 @@\n   }\n \n   Tensor* output_t;\n+  TensorShape output_shape;\n   OP_REQUIRES_OK(\n-      ctx, ctx->allocate_output(0,\n-                                TensorShape({images_t.dim_size(0), out_height,\n-                                             out_width, images_t.dim_size(3)}),\n-                                &output_t));\n+      ctx, TensorShape::BuildTensorShape({images_t.dim_size(0), out_height,\n+                                          out_width, images_t.dim_size(3)},\n+                                         &output_shape));\n+  OP_REQUIRES_OK(ctx, ctx->allocate_output(0, output_shape, &output_t));\n   auto output = output_t->tensor<T, 4>();\n   auto images = images_t.tensor<T, 4>();\n   auto transform = transform_t.matrix<float>();",
        "diff_line_info": {
            "deleted_lines": [
                "      ctx, ctx->allocate_output(0,",
                "                                TensorShape({images_t.dim_size(0), out_height,",
                "                                             out_width, images_t.dim_size(3)}),",
                "                                &output_t));"
            ],
            "added_lines": [
                "  TensorShape output_shape;",
                "      ctx, TensorShape::BuildTensorShape({images_t.dim_size(0), out_height,",
                "                                          out_width, images_t.dim_size(3)},",
                "                                         &output_shape));",
                "  OP_REQUIRES_OK(ctx, ctx->allocate_output(0, output_shape, &output_t));"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-41887",
        "func_name": "tensorflow/OneByM",
        "description": "TensorFlow is an open source platform for machine learning. `tf.keras.losses.poisson` receives a `y_pred` and `y_true` that are passed through `functor::mul` in `BinaryOp`. If the resulting dimensions overflow an `int32`, TensorFlow will crash due to a size mismatch during broadcast assignment. We have patched the issue in GitHub commit c5b30379ba87cbe774b08ac50c1f6d36df4ebb7c. The fix will be included in TensorFlow 2.11. We will also cherrypick this commit on TensorFlow 2.10.1 and 2.9.3, as these are also affected and still in supported range. However, we will not cherrypick this commit into TensorFlow 2.8.x, as it depends on Eigen behavior that changed between 2.8 and 2.9.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/c5b30379ba87cbe774b08ac50c1f6d36df4ebb7c",
        "commit_title": "Fix cwise dimension overflow issue again.",
        "commit_text": " If resulting dimensions overflow an int32, we were seeing an overflow and crash due to size mismatch during broadcast assignment.  The cause is a simple dimension type mismatch.  Note that actual tests for this are currently impractical, since successful operations require more than 2^32 elements and OOM on most machines.  PiperOrigin-RevId: 479336566",
        "func_before": "inline Eigen::IndexList<Eigen::type2index<1>, int> OneByM(int m) {\n    Eigen::IndexList<Eigen::type2index<1>, int> ret;\n    ret.set(1, m);\n    return ret;\n  }",
        "func": "inline Eigen::IndexList<Eigen::type2index<1>, Eigen::DenseIndex> OneByM(\n      Eigen::DenseIndex m) {\n    Eigen::IndexList<Eigen::type2index<1>, Eigen::DenseIndex> ret;\n    ret.set(1, m);\n    return ret;\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,6 @@\n-inline Eigen::IndexList<Eigen::type2index<1>, int> OneByM(int m) {\n-    Eigen::IndexList<Eigen::type2index<1>, int> ret;\n+inline Eigen::IndexList<Eigen::type2index<1>, Eigen::DenseIndex> OneByM(\n+      Eigen::DenseIndex m) {\n+    Eigen::IndexList<Eigen::type2index<1>, Eigen::DenseIndex> ret;\n     ret.set(1, m);\n     return ret;\n   }",
        "diff_line_info": {
            "deleted_lines": [
                "inline Eigen::IndexList<Eigen::type2index<1>, int> OneByM(int m) {",
                "    Eigen::IndexList<Eigen::type2index<1>, int> ret;"
            ],
            "added_lines": [
                "inline Eigen::IndexList<Eigen::type2index<1>, Eigen::DenseIndex> OneByM(",
                "      Eigen::DenseIndex m) {",
                "    Eigen::IndexList<Eigen::type2index<1>, Eigen::DenseIndex> ret;"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-41887",
        "func_name": "tensorflow/NByOne",
        "description": "TensorFlow is an open source platform for machine learning. `tf.keras.losses.poisson` receives a `y_pred` and `y_true` that are passed through `functor::mul` in `BinaryOp`. If the resulting dimensions overflow an `int32`, TensorFlow will crash due to a size mismatch during broadcast assignment. We have patched the issue in GitHub commit c5b30379ba87cbe774b08ac50c1f6d36df4ebb7c. The fix will be included in TensorFlow 2.11. We will also cherrypick this commit on TensorFlow 2.10.1 and 2.9.3, as these are also affected and still in supported range. However, we will not cherrypick this commit into TensorFlow 2.8.x, as it depends on Eigen behavior that changed between 2.8 and 2.9.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/c5b30379ba87cbe774b08ac50c1f6d36df4ebb7c",
        "commit_title": "Fix cwise dimension overflow issue again.",
        "commit_text": " If resulting dimensions overflow an int32, we were seeing an overflow and crash due to size mismatch during broadcast assignment.  The cause is a simple dimension type mismatch.  Note that actual tests for this are currently impractical, since successful operations require more than 2^32 elements and OOM on most machines.  PiperOrigin-RevId: 479336566",
        "func_before": "inline Eigen::IndexList<int, Eigen::type2index<1>> NByOne(int n) {\n    Eigen::IndexList<int, Eigen::type2index<1>> ret;\n    ret.set(0, n);\n    return ret;\n  }",
        "func": "inline Eigen::IndexList<Eigen::DenseIndex, Eigen::type2index<1>> NByOne(\n      Eigen::DenseIndex n) {\n    Eigen::IndexList<Eigen::DenseIndex, Eigen::type2index<1>> ret;\n    ret.set(0, n);\n    return ret;\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,6 @@\n-inline Eigen::IndexList<int, Eigen::type2index<1>> NByOne(int n) {\n-    Eigen::IndexList<int, Eigen::type2index<1>> ret;\n+inline Eigen::IndexList<Eigen::DenseIndex, Eigen::type2index<1>> NByOne(\n+      Eigen::DenseIndex n) {\n+    Eigen::IndexList<Eigen::DenseIndex, Eigen::type2index<1>> ret;\n     ret.set(0, n);\n     return ret;\n   }",
        "diff_line_info": {
            "deleted_lines": [
                "inline Eigen::IndexList<int, Eigen::type2index<1>> NByOne(int n) {",
                "    Eigen::IndexList<int, Eigen::type2index<1>> ret;"
            ],
            "added_lines": [
                "inline Eigen::IndexList<Eigen::DenseIndex, Eigen::type2index<1>> NByOne(",
                "      Eigen::DenseIndex n) {",
                "    Eigen::IndexList<Eigen::DenseIndex, Eigen::type2index<1>> ret;"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-41907",
        "func_name": "tensorflow/Compute",
        "description": "TensorFlow is an open source platform for machine learning. When `tf.raw_ops.ResizeNearestNeighborGrad` is given a large `size` input, it overflows. We have patched the issue in GitHub commit 00c821af032ba9e5f5fa3fe14690c8d28a657624. The fix will be included in TensorFlow 2.11. We will also cherrypick this commit on TensorFlow 2.10.1, 2.9.3, and TensorFlow 2.8.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/00c821af032ba9e5f5fa3fe14690c8d28a657624",
        "commit_title": "Fix tf.raw_ops.ResizeNearestNeighborGrad vulnerability with large dimensions.",
        "commit_text": " Note: This fix will have to be cherry picked in r2.10, r2.9, and r2.8. PiperOrigin-RevId: 479141644",
        "func_before": "void Compute(OpKernelContext* context) override {\n    // Grab and validate the input:\n    const Tensor& input = context->input(0);\n    OP_REQUIRES(context, input.dims() == 4,\n                errors::InvalidArgument(\"input must be 4-dimensional\",\n                                        input.shape().DebugString()));\n\n    // Grab and validate the output shape:\n    const Tensor& shape_t = context->input(1);\n    OP_REQUIRES(context, shape_t.dims() == 1,\n                errors::InvalidArgument(\"shape_t must be 1-dimensional\",\n                                        shape_t.shape().DebugString()));\n    OP_REQUIRES(context, shape_t.NumElements() == 2,\n                errors::InvalidArgument(\"shape_t must have two elements\",\n                                        shape_t.shape().DebugString()));\n\n    auto sizes = shape_t.vec<int32>();\n    OP_REQUIRES(context, sizes(0) > 0 && sizes(1) > 0,\n                errors::InvalidArgument(\"shape_t's elements must be positive\"));\n\n    if (std::is_same<Device, GPUDevice>::value) {\n      OP_REQUIRES(\n          context, !OpDeterminismRequired(),\n          errors::Unimplemented(\n              \"A deterministic GPU implementation of ResizeNearestNeighborGrad\"\n              \" is not currently available.\"));\n    }\n\n    const int64_t batch_size = input.dim_size(0);\n    const int64_t in_height = input.dim_size(1);\n    const int64_t in_width = input.dim_size(2);\n    const int64_t channels = input.dim_size(3);\n\n    const int64_t out_height = sizes(0);\n    const int64_t out_width = sizes(1);\n\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(\n        context,\n        context->allocate_output(\n            0, TensorShape({batch_size, out_height, out_width, channels}),\n            &output));\n\n    // Return if the output is empty.\n    if (output->NumElements() == 0) return;\n\n    typename TTypes<T, 4>::ConstTensor input_data(input.tensor<T, 4>());\n    typename TTypes<T, 4>::Tensor output_data(output->tensor<T, 4>());\n\n    const float height_scale =\n        CalculateResizeScale(out_height, in_height, align_corners_);\n    const float width_scale =\n        CalculateResizeScale(out_width, in_width, align_corners_);\n\n    bool status;\n    if (half_pixel_centers_) {\n      if (align_corners_) {\n        status = functor::ResizeNearestNeighborGrad<Device, T,\n                                                    /*half_pixel_centers=*/true,\n                                                    /*align_corners=*/true>()(\n            context->eigen_device<Device>(), input_data, height_scale,\n            width_scale, output_data);\n      } else {\n        status = functor::ResizeNearestNeighborGrad<Device, T,\n                                                    /*half_pixel_centers=*/true,\n                                                    /*align_corners=*/false>()(\n            context->eigen_device<Device>(), input_data, height_scale,\n            width_scale, output_data);\n      }\n    } else {\n      if (align_corners_) {\n        status =\n            functor::ResizeNearestNeighborGrad<Device, T,\n                                               /*half_pixel_centers=*/false,\n                                               /*align_corners=*/true>()(\n                context->eigen_device<Device>(), input_data, height_scale,\n                width_scale, output_data);\n      } else {\n        status =\n            functor::ResizeNearestNeighborGrad<Device, T,\n                                               /*half_pixel_centers=*/false,\n                                               /*align_corners=*/false>()(\n                context->eigen_device<Device>(), input_data, height_scale,\n                width_scale, output_data);\n      }\n    }\n    if (!status) {\n      context->SetStatus(\n          errors::Internal(\"Failed launching ResizeNearestNeighborGrad\"));\n    }\n  }",
        "func": "void Compute(OpKernelContext* context) override {\n    // Grab and validate the input:\n    const Tensor& input = context->input(0);\n    OP_REQUIRES(context, input.dims() == 4,\n                errors::InvalidArgument(\"input must be 4-dimensional\",\n                                        input.shape().DebugString()));\n\n    // Grab and validate the output shape:\n    const Tensor& shape_t = context->input(1);\n    OP_REQUIRES(context, shape_t.dims() == 1,\n                errors::InvalidArgument(\"shape_t must be 1-dimensional\",\n                                        shape_t.shape().DebugString()));\n    OP_REQUIRES(context, shape_t.NumElements() == 2,\n                errors::InvalidArgument(\"shape_t must have two elements\",\n                                        shape_t.shape().DebugString()));\n\n    auto sizes = shape_t.vec<int32>();\n    OP_REQUIRES(context, sizes(0) > 0 && sizes(1) > 0,\n                errors::InvalidArgument(\"shape_t's elements must be positive\"));\n\n    if (std::is_same<Device, GPUDevice>::value) {\n      OP_REQUIRES(\n          context, !OpDeterminismRequired(),\n          errors::Unimplemented(\n              \"A deterministic GPU implementation of ResizeNearestNeighborGrad\"\n              \" is not currently available.\"));\n    }\n\n    const int64_t batch_size = input.dim_size(0);\n    const int64_t in_height = input.dim_size(1);\n    const int64_t in_width = input.dim_size(2);\n    const int64_t channels = input.dim_size(3);\n\n    const int64_t out_height = sizes(0);\n    const int64_t out_width = sizes(1);\n\n    Tensor* output = nullptr;\n    TensorShape shape;\n    OP_REQUIRES_OK(context,\n                   TensorShape::BuildTensorShape(\n                       {batch_size, out_height, out_width, channels}, &shape));\n    OP_REQUIRES_OK(context, context->allocate_output(0, shape, &output));\n\n    // Return if the output is empty.\n    if (output->NumElements() == 0) return;\n\n    typename TTypes<T, 4>::ConstTensor input_data(input.tensor<T, 4>());\n    typename TTypes<T, 4>::Tensor output_data(output->tensor<T, 4>());\n\n    const float height_scale =\n        CalculateResizeScale(out_height, in_height, align_corners_);\n    const float width_scale =\n        CalculateResizeScale(out_width, in_width, align_corners_);\n\n    bool status;\n    if (half_pixel_centers_) {\n      if (align_corners_) {\n        status = functor::ResizeNearestNeighborGrad<Device, T,\n                                                    /*half_pixel_centers=*/true,\n                                                    /*align_corners=*/true>()(\n            context->eigen_device<Device>(), input_data, height_scale,\n            width_scale, output_data);\n      } else {\n        status = functor::ResizeNearestNeighborGrad<Device, T,\n                                                    /*half_pixel_centers=*/true,\n                                                    /*align_corners=*/false>()(\n            context->eigen_device<Device>(), input_data, height_scale,\n            width_scale, output_data);\n      }\n    } else {\n      if (align_corners_) {\n        status =\n            functor::ResizeNearestNeighborGrad<Device, T,\n                                               /*half_pixel_centers=*/false,\n                                               /*align_corners=*/true>()(\n                context->eigen_device<Device>(), input_data, height_scale,\n                width_scale, output_data);\n      } else {\n        status =\n            functor::ResizeNearestNeighborGrad<Device, T,\n                                               /*half_pixel_centers=*/false,\n                                               /*align_corners=*/false>()(\n                context->eigen_device<Device>(), input_data, height_scale,\n                width_scale, output_data);\n      }\n    }\n    if (!status) {\n      context->SetStatus(\n          errors::Internal(\"Failed launching ResizeNearestNeighborGrad\"));\n    }\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -35,11 +35,11 @@\n     const int64_t out_width = sizes(1);\n \n     Tensor* output = nullptr;\n-    OP_REQUIRES_OK(\n-        context,\n-        context->allocate_output(\n-            0, TensorShape({batch_size, out_height, out_width, channels}),\n-            &output));\n+    TensorShape shape;\n+    OP_REQUIRES_OK(context,\n+                   TensorShape::BuildTensorShape(\n+                       {batch_size, out_height, out_width, channels}, &shape));\n+    OP_REQUIRES_OK(context, context->allocate_output(0, shape, &output));\n \n     // Return if the output is empty.\n     if (output->NumElements() == 0) return;",
        "diff_line_info": {
            "deleted_lines": [
                "    OP_REQUIRES_OK(",
                "        context,",
                "        context->allocate_output(",
                "            0, TensorShape({batch_size, out_height, out_width, channels}),",
                "            &output));"
            ],
            "added_lines": [
                "    TensorShape shape;",
                "    OP_REQUIRES_OK(context,",
                "                   TensorShape::BuildTensorShape(",
                "                       {batch_size, out_height, out_width, channels}, &shape));",
                "    OP_REQUIRES_OK(context, context->allocate_output(0, shape, &output));"
            ]
        }
    },
    {
        "cve_id": "CVE-2023-1175",
        "func_name": "vim/op_yank",
        "description": "Incorrect Calculation of Buffer Size in GitHub repository vim/vim prior to 9.0.1378.",
        "git_url": "https://github.com/vim/vim/commit/c99cbf8f289bdda5d4a77d7ec415850a520330ba",
        "commit_title": "patch 9.0.1378: illegal memory access when using virtual editing",
        "commit_text": " Problem:    Illegal memory access when using virtual editing. Solution:   Make sure \"startspaces\" is not negative.",
        "func_before": "int\nop_yank(oparg_T *oap, int deleting, int mess)\n{\n    long\t\ty_idx;\t\t// index in y_array[]\n    yankreg_T\t\t*curr;\t\t// copy of y_current\n    yankreg_T\t\tnewreg;\t\t// new yank register when appending\n    char_u\t\t**new_ptr;\n    linenr_T\t\tlnum;\t\t// current line number\n    long\t\tj;\n    int\t\t\tyanktype = oap->motion_type;\n    long\t\tyanklines = oap->line_count;\n    linenr_T\t\tyankendlnum = oap->end.lnum;\n    char_u\t\t*p;\n    char_u\t\t*pnew;\n    struct block_def\tbd;\n#if defined(FEAT_CLIPBOARD) && defined(FEAT_X11)\n    int\t\t\tdid_star = FALSE;\n#endif\n\n\t\t\t\t    // check for read-only register\n    if (oap->regname != 0 && !valid_yank_reg(oap->regname, TRUE))\n    {\n\tbeep_flush();\n\treturn FAIL;\n    }\n    if (oap->regname == '_')\t    // black hole: nothing to do\n\treturn OK;\n\n#ifdef FEAT_CLIPBOARD\n    if (!clip_star.available && oap->regname == '*')\n\toap->regname = 0;\n    else if (!clip_plus.available && oap->regname == '+')\n\toap->regname = 0;\n#endif\n\n    if (!deleting)\t\t    // op_delete() already set y_current\n\tget_yank_register(oap->regname, TRUE);\n\n    curr = y_current;\n\t\t\t\t    // append to existing contents\n    if (y_append && y_current->y_array != NULL)\n\ty_current = &newreg;\n    else\n\tfree_yank_all();\t    // free previously yanked lines\n\n    // If the cursor was in column 1 before and after the movement, and the\n    // operator is not inclusive, the yank is always linewise.\n    if (       oap->motion_type == MCHAR\n\t    && oap->start.col == 0\n\t    && !oap->inclusive\n\t    && (!oap->is_VIsual || *p_sel == 'o')\n\t    && !oap->block_mode\n\t    && oap->end.col == 0\n\t    && yanklines > 1)\n    {\n\tyanktype = MLINE;\n\t--yankendlnum;\n\t--yanklines;\n    }\n\n    y_current->y_size = yanklines;\n    y_current->y_type = yanktype;   // set the yank register type\n    y_current->y_width = 0;\n    y_current->y_array = lalloc_clear(sizeof(char_u *) * yanklines, TRUE);\n    if (y_current->y_array == NULL)\n    {\n\ty_current = curr;\n\treturn FAIL;\n    }\n#ifdef FEAT_VIMINFO\n    y_current->y_time_set = vim_time();\n#endif\n\n    y_idx = 0;\n    lnum = oap->start.lnum;\n\n    if (oap->block_mode)\n    {\n\t// Visual block mode\n\ty_current->y_type = MBLOCK;\t    // set the yank register type\n\ty_current->y_width = oap->end_vcol - oap->start_vcol;\n\n\tif (curwin->w_curswant == MAXCOL && y_current->y_width > 0)\n\t    y_current->y_width--;\n    }\n\n    for ( ; lnum <= yankendlnum; lnum++, y_idx++)\n    {\n\tswitch (y_current->y_type)\n\t{\n\t    case MBLOCK:\n\t\tblock_prep(oap, &bd, lnum, FALSE);\n\t\tif (yank_copy_line(&bd, y_idx, oap->excl_tr_ws) == FAIL)\n\t\t    goto fail;\n\t\tbreak;\n\n\t    case MLINE:\n\t\tif ((y_current->y_array[y_idx] =\n\t\t\t\t\t    vim_strsave(ml_get(lnum))) == NULL)\n\t\t    goto fail;\n\t\tbreak;\n\n\t    case MCHAR:\n\t\t{\n\t\t    colnr_T startcol = 0, endcol = MAXCOL;\n\t\t    int\t    is_oneChar = FALSE;\n\t\t    colnr_T cs, ce;\n\n\t\t    p = ml_get(lnum);\n\t\t    bd.startspaces = 0;\n\t\t    bd.endspaces = 0;\n\n\t\t    if (lnum == oap->start.lnum)\n\t\t    {\n\t\t\tstartcol = oap->start.col;\n\t\t\tif (virtual_op)\n\t\t\t{\n\t\t\t    getvcol(curwin, &oap->start, &cs, NULL, &ce);\n\t\t\t    if (ce != cs && oap->start.coladd > 0)\n\t\t\t    {\n\t\t\t\t// Part of a tab selected -- but don't\n\t\t\t\t// double-count it.\n\t\t\t\tbd.startspaces = (ce - cs + 1)\n\t\t\t\t\t\t\t  - oap->start.coladd;\n\t\t\t\tstartcol++;\n\t\t\t    }\n\t\t\t}\n\t\t    }\n\n\t\t    if (lnum == oap->end.lnum)\n\t\t    {\n\t\t\tendcol = oap->end.col;\n\t\t\tif (virtual_op)\n\t\t\t{\n\t\t\t    getvcol(curwin, &oap->end, &cs, NULL, &ce);\n\t\t\t    if (p[endcol] == NUL || (cs + oap->end.coladd < ce\n\t\t\t\t\t// Don't add space for double-wide\n\t\t\t\t\t// char; endcol will be on last byte\n\t\t\t\t\t// of multi-byte char.\n\t\t\t\t\t&& (*mb_head_off)(p, p + endcol) == 0))\n\t\t\t    {\n\t\t\t\tif (oap->start.lnum == oap->end.lnum\n\t\t\t\t\t    && oap->start.col == oap->end.col)\n\t\t\t\t{\n\t\t\t\t    // Special case: inside a single char\n\t\t\t\t    is_oneChar = TRUE;\n\t\t\t\t    bd.startspaces = oap->end.coladd\n\t\t\t\t\t - oap->start.coladd + oap->inclusive;\n\t\t\t\t    endcol = startcol;\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t    bd.endspaces = oap->end.coladd\n\t\t\t\t\t\t\t     + oap->inclusive;\n\t\t\t\t    endcol -= oap->inclusive;\n\t\t\t\t}\n\t\t\t    }\n\t\t\t}\n\t\t    }\n\t\t    if (endcol == MAXCOL)\n\t\t\tendcol = (colnr_T)STRLEN(p);\n\t\t    if (startcol > endcol || is_oneChar)\n\t\t\tbd.textlen = 0;\n\t\t    else\n\t\t\tbd.textlen = endcol - startcol + oap->inclusive;\n\t\t    bd.textstart = p + startcol;\n\t\t    if (yank_copy_line(&bd, y_idx, FALSE) == FAIL)\n\t\t\tgoto fail;\n\t\t    break;\n\t\t}\n\t\t// NOTREACHED\n\t}\n    }\n\n    if (curr != y_current)\t// append the new block to the old block\n    {\n\tnew_ptr = ALLOC_MULT(char_u *, curr->y_size + y_current->y_size);\n\tif (new_ptr == NULL)\n\t    goto fail;\n\tfor (j = 0; j < curr->y_size; ++j)\n\t    new_ptr[j] = curr->y_array[j];\n\tvim_free(curr->y_array);\n\tcurr->y_array = new_ptr;\n#ifdef FEAT_VIMINFO\n\tcurr->y_time_set = vim_time();\n#endif\n\n\tif (yanktype == MLINE)\t// MLINE overrides MCHAR and MBLOCK\n\t    curr->y_type = MLINE;\n\n\t// Concatenate the last line of the old block with the first line of\n\t// the new block, unless being Vi compatible.\n\tif (curr->y_type == MCHAR && vim_strchr(p_cpo, CPO_REGAPPEND) == NULL)\n\t{\n\t    pnew = alloc(STRLEN(curr->y_array[curr->y_size - 1])\n\t\t\t\t\t  + STRLEN(y_current->y_array[0]) + 1);\n\t    if (pnew == NULL)\n\t    {\n\t\ty_idx = y_current->y_size - 1;\n\t\tgoto fail;\n\t    }\n\t    STRCPY(pnew, curr->y_array[--j]);\n\t    STRCAT(pnew, y_current->y_array[0]);\n\t    vim_free(curr->y_array[j]);\n\t    vim_free(y_current->y_array[0]);\n\t    curr->y_array[j++] = pnew;\n\t    y_idx = 1;\n\t}\n\telse\n\t    y_idx = 0;\n\twhile (y_idx < y_current->y_size)\n\t    curr->y_array[j++] = y_current->y_array[y_idx++];\n\tcurr->y_size = j;\n\tvim_free(y_current->y_array);\n\ty_current = curr;\n    }\n\n    if (mess)\t\t\t// Display message about yank?\n    {\n\tif (yanktype == MCHAR\n\t\t&& !oap->block_mode\n\t\t&& yanklines == 1)\n\t    yanklines = 0;\n\t// Some versions of Vi use \">=\" here, some don't...\n\tif (yanklines > p_report)\n\t{\n\t    char namebuf[100];\n\n\t    if (oap->regname == NUL)\n\t\t*namebuf = NUL;\n\t    else\n\t\tvim_snprintf(namebuf, sizeof(namebuf),\n\t\t\t\t\t\t_(\" into \\\"%c\"), oap->regname);\n\n\t    // redisplay now, so message is not deleted\n\t    update_topline_redraw();\n\t    if (oap->block_mode)\n\t    {\n\t\tsmsg(NGETTEXT(\"block of %ld line yanked%s\",\n\t\t\t\t     \"block of %ld lines yanked%s\", yanklines),\n\t\t\tyanklines, namebuf);\n\t    }\n\t    else\n\t    {\n\t\tsmsg(NGETTEXT(\"%ld line yanked%s\",\n\t\t\t\t\t      \"%ld lines yanked%s\", yanklines),\n\t\t\tyanklines, namebuf);\n\t    }\n\t}\n    }\n\n    if ((cmdmod.cmod_flags & CMOD_LOCKMARKS) == 0)\n    {\n\t// Set \"'[\" and \"']\" marks.\n\tcurbuf->b_op_start = oap->start;\n\tcurbuf->b_op_end = oap->end;\n\tif (yanktype == MLINE && !oap->block_mode)\n\t{\n\t    curbuf->b_op_start.col = 0;\n\t    curbuf->b_op_end.col = MAXCOL;\n\t}\n    }\n\n#ifdef FEAT_CLIPBOARD\n    // If we were yanking to the '*' register, send result to clipboard.\n    // If no register was specified, and \"unnamed\" in 'clipboard', make a copy\n    // to the '*' register.\n    if (clip_star.available\n\t    && (curr == &(y_regs[STAR_REGISTER])\n\t\t|| (!deleting && oap->regname == 0\n\t\t   && ((clip_unnamed | clip_unnamed_saved) & CLIP_UNNAMED))))\n    {\n\tif (curr != &(y_regs[STAR_REGISTER]))\n\t    // Copy the text from register 0 to the clipboard register.\n\t    copy_yank_reg(&(y_regs[STAR_REGISTER]));\n\n\tclip_own_selection(&clip_star);\n\tclip_gen_set_selection(&clip_star);\n# ifdef FEAT_X11\n\tdid_star = TRUE;\n# endif\n    }\n\n# ifdef FEAT_X11\n    // If we were yanking to the '+' register, send result to selection.\n    // Also copy to the '*' register, in case auto-select is off.  But not when\n    // 'clipboard' has \"unnamedplus\" and not \"unnamed\"; and not when\n    // deleting and both \"unnamedplus\" and \"unnamed\".\n    if (clip_plus.available\n\t    && (curr == &(y_regs[PLUS_REGISTER])\n\t\t|| (!deleting && oap->regname == 0\n\t\t  && ((clip_unnamed | clip_unnamed_saved) &\n\t\t\t\t\t\t\t  CLIP_UNNAMED_PLUS))))\n    {\n\tif (curr != &(y_regs[PLUS_REGISTER]))\n\t    // Copy the text from register 0 to the clipboard register.\n\t    copy_yank_reg(&(y_regs[PLUS_REGISTER]));\n\n\tclip_own_selection(&clip_plus);\n\tclip_gen_set_selection(&clip_plus);\n\tif (!clip_isautosel_star()\n\t\t&& !clip_isautosel_plus()\n\t\t&& !((clip_unnamed | clip_unnamed_saved) == CLIP_UNNAMED_PLUS)\n\t\t&& !(deleting && (clip_unnamed | clip_unnamed_saved)\n\t\t\t\t\t == (CLIP_UNNAMED | CLIP_UNNAMED_PLUS))\n\t\t&& !did_star\n\t\t&& curr == &(y_regs[PLUS_REGISTER]))\n\t{\n\t    copy_yank_reg(&(y_regs[STAR_REGISTER]));\n\t    clip_own_selection(&clip_star);\n\t    clip_gen_set_selection(&clip_star);\n\t}\n    }\n# endif\n#endif\n\n#if defined(FEAT_EVAL)\n    if (!deleting && has_textyankpost())\n\tyank_do_autocmd(oap, y_current);\n#endif\n\n    return OK;\n\nfail:\t\t// free the allocated lines\n    free_yank(y_idx + 1);\n    y_current = curr;\n    return FAIL;\n}",
        "func": "int\nop_yank(oparg_T *oap, int deleting, int mess)\n{\n    long\t\ty_idx;\t\t// index in y_array[]\n    yankreg_T\t\t*curr;\t\t// copy of y_current\n    yankreg_T\t\tnewreg;\t\t// new yank register when appending\n    char_u\t\t**new_ptr;\n    linenr_T\t\tlnum;\t\t// current line number\n    long\t\tj;\n    int\t\t\tyanktype = oap->motion_type;\n    long\t\tyanklines = oap->line_count;\n    linenr_T\t\tyankendlnum = oap->end.lnum;\n    char_u\t\t*p;\n    char_u\t\t*pnew;\n    struct block_def\tbd;\n#if defined(FEAT_CLIPBOARD) && defined(FEAT_X11)\n    int\t\t\tdid_star = FALSE;\n#endif\n\n\t\t\t\t    // check for read-only register\n    if (oap->regname != 0 && !valid_yank_reg(oap->regname, TRUE))\n    {\n\tbeep_flush();\n\treturn FAIL;\n    }\n    if (oap->regname == '_')\t    // black hole: nothing to do\n\treturn OK;\n\n#ifdef FEAT_CLIPBOARD\n    if (!clip_star.available && oap->regname == '*')\n\toap->regname = 0;\n    else if (!clip_plus.available && oap->regname == '+')\n\toap->regname = 0;\n#endif\n\n    if (!deleting)\t\t    // op_delete() already set y_current\n\tget_yank_register(oap->regname, TRUE);\n\n    curr = y_current;\n\t\t\t\t    // append to existing contents\n    if (y_append && y_current->y_array != NULL)\n\ty_current = &newreg;\n    else\n\tfree_yank_all();\t    // free previously yanked lines\n\n    // If the cursor was in column 1 before and after the movement, and the\n    // operator is not inclusive, the yank is always linewise.\n    if (       oap->motion_type == MCHAR\n\t    && oap->start.col == 0\n\t    && !oap->inclusive\n\t    && (!oap->is_VIsual || *p_sel == 'o')\n\t    && !oap->block_mode\n\t    && oap->end.col == 0\n\t    && yanklines > 1)\n    {\n\tyanktype = MLINE;\n\t--yankendlnum;\n\t--yanklines;\n    }\n\n    y_current->y_size = yanklines;\n    y_current->y_type = yanktype;   // set the yank register type\n    y_current->y_width = 0;\n    y_current->y_array = lalloc_clear(sizeof(char_u *) * yanklines, TRUE);\n    if (y_current->y_array == NULL)\n    {\n\ty_current = curr;\n\treturn FAIL;\n    }\n#ifdef FEAT_VIMINFO\n    y_current->y_time_set = vim_time();\n#endif\n\n    y_idx = 0;\n    lnum = oap->start.lnum;\n\n    if (oap->block_mode)\n    {\n\t// Visual block mode\n\ty_current->y_type = MBLOCK;\t    // set the yank register type\n\ty_current->y_width = oap->end_vcol - oap->start_vcol;\n\n\tif (curwin->w_curswant == MAXCOL && y_current->y_width > 0)\n\t    y_current->y_width--;\n    }\n\n    for ( ; lnum <= yankendlnum; lnum++, y_idx++)\n    {\n\tswitch (y_current->y_type)\n\t{\n\t    case MBLOCK:\n\t\tblock_prep(oap, &bd, lnum, FALSE);\n\t\tif (yank_copy_line(&bd, y_idx, oap->excl_tr_ws) == FAIL)\n\t\t    goto fail;\n\t\tbreak;\n\n\t    case MLINE:\n\t\tif ((y_current->y_array[y_idx] =\n\t\t\t\t\t    vim_strsave(ml_get(lnum))) == NULL)\n\t\t    goto fail;\n\t\tbreak;\n\n\t    case MCHAR:\n\t\t{\n\t\t    colnr_T startcol = 0, endcol = MAXCOL;\n\t\t    int\t    is_oneChar = FALSE;\n\t\t    colnr_T cs, ce;\n\n\t\t    p = ml_get(lnum);\n\t\t    bd.startspaces = 0;\n\t\t    bd.endspaces = 0;\n\n\t\t    if (lnum == oap->start.lnum)\n\t\t    {\n\t\t\tstartcol = oap->start.col;\n\t\t\tif (virtual_op)\n\t\t\t{\n\t\t\t    getvcol(curwin, &oap->start, &cs, NULL, &ce);\n\t\t\t    if (ce != cs && oap->start.coladd > 0)\n\t\t\t    {\n\t\t\t\t// Part of a tab selected -- but don't\n\t\t\t\t// double-count it.\n\t\t\t\tbd.startspaces = (ce - cs + 1)\n\t\t\t\t\t\t\t  - oap->start.coladd;\n\t\t\t\tif (bd.startspaces < 0)\n\t\t\t\t    bd.startspaces = 0;\n\t\t\t\tstartcol++;\n\t\t\t    }\n\t\t\t}\n\t\t    }\n\n\t\t    if (lnum == oap->end.lnum)\n\t\t    {\n\t\t\tendcol = oap->end.col;\n\t\t\tif (virtual_op)\n\t\t\t{\n\t\t\t    getvcol(curwin, &oap->end, &cs, NULL, &ce);\n\t\t\t    if (p[endcol] == NUL || (cs + oap->end.coladd < ce\n\t\t\t\t\t// Don't add space for double-wide\n\t\t\t\t\t// char; endcol will be on last byte\n\t\t\t\t\t// of multi-byte char.\n\t\t\t\t\t&& (*mb_head_off)(p, p + endcol) == 0))\n\t\t\t    {\n\t\t\t\tif (oap->start.lnum == oap->end.lnum\n\t\t\t\t\t    && oap->start.col == oap->end.col)\n\t\t\t\t{\n\t\t\t\t    // Special case: inside a single char\n\t\t\t\t    is_oneChar = TRUE;\n\t\t\t\t    bd.startspaces = oap->end.coladd\n\t\t\t\t\t - oap->start.coladd + oap->inclusive;\n\t\t\t\t    endcol = startcol;\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t    bd.endspaces = oap->end.coladd\n\t\t\t\t\t\t\t     + oap->inclusive;\n\t\t\t\t    endcol -= oap->inclusive;\n\t\t\t\t}\n\t\t\t    }\n\t\t\t}\n\t\t    }\n\t\t    if (endcol == MAXCOL)\n\t\t\tendcol = (colnr_T)STRLEN(p);\n\t\t    if (startcol > endcol || is_oneChar)\n\t\t\tbd.textlen = 0;\n\t\t    else\n\t\t\tbd.textlen = endcol - startcol + oap->inclusive;\n\t\t    bd.textstart = p + startcol;\n\t\t    if (yank_copy_line(&bd, y_idx, FALSE) == FAIL)\n\t\t\tgoto fail;\n\t\t    break;\n\t\t}\n\t\t// NOTREACHED\n\t}\n    }\n\n    if (curr != y_current)\t// append the new block to the old block\n    {\n\tnew_ptr = ALLOC_MULT(char_u *, curr->y_size + y_current->y_size);\n\tif (new_ptr == NULL)\n\t    goto fail;\n\tfor (j = 0; j < curr->y_size; ++j)\n\t    new_ptr[j] = curr->y_array[j];\n\tvim_free(curr->y_array);\n\tcurr->y_array = new_ptr;\n#ifdef FEAT_VIMINFO\n\tcurr->y_time_set = vim_time();\n#endif\n\n\tif (yanktype == MLINE)\t// MLINE overrides MCHAR and MBLOCK\n\t    curr->y_type = MLINE;\n\n\t// Concatenate the last line of the old block with the first line of\n\t// the new block, unless being Vi compatible.\n\tif (curr->y_type == MCHAR && vim_strchr(p_cpo, CPO_REGAPPEND) == NULL)\n\t{\n\t    pnew = alloc(STRLEN(curr->y_array[curr->y_size - 1])\n\t\t\t\t\t  + STRLEN(y_current->y_array[0]) + 1);\n\t    if (pnew == NULL)\n\t    {\n\t\ty_idx = y_current->y_size - 1;\n\t\tgoto fail;\n\t    }\n\t    STRCPY(pnew, curr->y_array[--j]);\n\t    STRCAT(pnew, y_current->y_array[0]);\n\t    vim_free(curr->y_array[j]);\n\t    vim_free(y_current->y_array[0]);\n\t    curr->y_array[j++] = pnew;\n\t    y_idx = 1;\n\t}\n\telse\n\t    y_idx = 0;\n\twhile (y_idx < y_current->y_size)\n\t    curr->y_array[j++] = y_current->y_array[y_idx++];\n\tcurr->y_size = j;\n\tvim_free(y_current->y_array);\n\ty_current = curr;\n    }\n\n    if (mess)\t\t\t// Display message about yank?\n    {\n\tif (yanktype == MCHAR\n\t\t&& !oap->block_mode\n\t\t&& yanklines == 1)\n\t    yanklines = 0;\n\t// Some versions of Vi use \">=\" here, some don't...\n\tif (yanklines > p_report)\n\t{\n\t    char namebuf[100];\n\n\t    if (oap->regname == NUL)\n\t\t*namebuf = NUL;\n\t    else\n\t\tvim_snprintf(namebuf, sizeof(namebuf),\n\t\t\t\t\t\t_(\" into \\\"%c\"), oap->regname);\n\n\t    // redisplay now, so message is not deleted\n\t    update_topline_redraw();\n\t    if (oap->block_mode)\n\t    {\n\t\tsmsg(NGETTEXT(\"block of %ld line yanked%s\",\n\t\t\t\t     \"block of %ld lines yanked%s\", yanklines),\n\t\t\tyanklines, namebuf);\n\t    }\n\t    else\n\t    {\n\t\tsmsg(NGETTEXT(\"%ld line yanked%s\",\n\t\t\t\t\t      \"%ld lines yanked%s\", yanklines),\n\t\t\tyanklines, namebuf);\n\t    }\n\t}\n    }\n\n    if ((cmdmod.cmod_flags & CMOD_LOCKMARKS) == 0)\n    {\n\t// Set \"'[\" and \"']\" marks.\n\tcurbuf->b_op_start = oap->start;\n\tcurbuf->b_op_end = oap->end;\n\tif (yanktype == MLINE && !oap->block_mode)\n\t{\n\t    curbuf->b_op_start.col = 0;\n\t    curbuf->b_op_end.col = MAXCOL;\n\t}\n    }\n\n#ifdef FEAT_CLIPBOARD\n    // If we were yanking to the '*' register, send result to clipboard.\n    // If no register was specified, and \"unnamed\" in 'clipboard', make a copy\n    // to the '*' register.\n    if (clip_star.available\n\t    && (curr == &(y_regs[STAR_REGISTER])\n\t\t|| (!deleting && oap->regname == 0\n\t\t   && ((clip_unnamed | clip_unnamed_saved) & CLIP_UNNAMED))))\n    {\n\tif (curr != &(y_regs[STAR_REGISTER]))\n\t    // Copy the text from register 0 to the clipboard register.\n\t    copy_yank_reg(&(y_regs[STAR_REGISTER]));\n\n\tclip_own_selection(&clip_star);\n\tclip_gen_set_selection(&clip_star);\n# ifdef FEAT_X11\n\tdid_star = TRUE;\n# endif\n    }\n\n# ifdef FEAT_X11\n    // If we were yanking to the '+' register, send result to selection.\n    // Also copy to the '*' register, in case auto-select is off.  But not when\n    // 'clipboard' has \"unnamedplus\" and not \"unnamed\"; and not when\n    // deleting and both \"unnamedplus\" and \"unnamed\".\n    if (clip_plus.available\n\t    && (curr == &(y_regs[PLUS_REGISTER])\n\t\t|| (!deleting && oap->regname == 0\n\t\t  && ((clip_unnamed | clip_unnamed_saved) &\n\t\t\t\t\t\t\t  CLIP_UNNAMED_PLUS))))\n    {\n\tif (curr != &(y_regs[PLUS_REGISTER]))\n\t    // Copy the text from register 0 to the clipboard register.\n\t    copy_yank_reg(&(y_regs[PLUS_REGISTER]));\n\n\tclip_own_selection(&clip_plus);\n\tclip_gen_set_selection(&clip_plus);\n\tif (!clip_isautosel_star()\n\t\t&& !clip_isautosel_plus()\n\t\t&& !((clip_unnamed | clip_unnamed_saved) == CLIP_UNNAMED_PLUS)\n\t\t&& !(deleting && (clip_unnamed | clip_unnamed_saved)\n\t\t\t\t\t == (CLIP_UNNAMED | CLIP_UNNAMED_PLUS))\n\t\t&& !did_star\n\t\t&& curr == &(y_regs[PLUS_REGISTER]))\n\t{\n\t    copy_yank_reg(&(y_regs[STAR_REGISTER]));\n\t    clip_own_selection(&clip_star);\n\t    clip_gen_set_selection(&clip_star);\n\t}\n    }\n# endif\n#endif\n\n#if defined(FEAT_EVAL)\n    if (!deleting && has_textyankpost())\n\tyank_do_autocmd(oap, y_current);\n#endif\n\n    return OK;\n\nfail:\t\t// free the allocated lines\n    free_yank(y_idx + 1);\n    y_current = curr;\n    return FAIL;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -122,6 +122,8 @@\n \t\t\t\t// double-count it.\n \t\t\t\tbd.startspaces = (ce - cs + 1)\n \t\t\t\t\t\t\t  - oap->start.coladd;\n+\t\t\t\tif (bd.startspaces < 0)\n+\t\t\t\t    bd.startspaces = 0;\n \t\t\t\tstartcol++;\n \t\t\t    }\n \t\t\t}",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t\t\t\tif (bd.startspaces < 0)",
                "\t\t\t\t    bd.startspaces = 0;"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-28039",
        "func_name": "torvalds/linux/xen_vmalloc_p2m_tree",
        "description": "An issue was discovered in the Linux kernel 5.9.x through 5.11.3, as used with Xen. In some less-common configurations, an x86 PV guest OS user can crash a Dom0 or driver domain via a large amount of I/O activity. The issue relates to misuse of guest physical addresses when a configuration has CONFIG_XEN_UNPOPULATED_ALLOC but not CONFIG_XEN_BALLOON_MEMORY_HOTPLUG.",
        "git_url": "https://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/commit/?h=882213990d32fd224340a4533f6318dd152be4b2",
        "commit_title": "Since commit 9e2369c06c8a18 (\"xen: add helpers to allocate unpopulated",
        "commit_text": "memory\") foreign mappings are using guest physical addresses allocated via ZONE_DEVICE functionality.  This will result in problems for the case of no balloon memory hotplug being configured, as the p2m list will only cover the initial memory size of the domain. Any ZONE_DEVICE allocated address will be outside the p2m range and thus a mapping can't be established with that memory address.  Fix that by extending the p2m size for that case. At the same time add a check for a to be created mapping to be within the p2m limits in order to detect errors early.  While changing a comment, remove some 32-bit leftovers.  This is XSA-369.  Cc: <stable@vger.kernel.org> # 5.9 ",
        "func_before": "void __init xen_vmalloc_p2m_tree(void)\n{\n\tstatic struct vm_struct vm;\n\tunsigned long p2m_limit;\n\n\txen_p2m_last_pfn = xen_max_p2m_pfn;\n\n\tp2m_limit = (phys_addr_t)P2M_LIMIT * 1024 * 1024 * 1024 / PAGE_SIZE;\n\tvm.flags = VM_ALLOC;\n\tvm.size = ALIGN(sizeof(unsigned long) * max(xen_max_p2m_pfn, p2m_limit),\n\t\t\tPMD_SIZE * PMDS_PER_MID_PAGE);\n\tvm_area_register_early(&vm, PMD_SIZE * PMDS_PER_MID_PAGE);\n\tpr_notice(\"p2m virtual area at %p, size is %lx\\n\", vm.addr, vm.size);\n\n\txen_max_p2m_pfn = vm.size / sizeof(unsigned long);\n\n\txen_rebuild_p2m_list(vm.addr);\n\n\txen_p2m_addr = vm.addr;\n\txen_p2m_size = xen_max_p2m_pfn;\n\n\txen_inv_extra_mem();\n}",
        "func": "void __init xen_vmalloc_p2m_tree(void)\n{\n\tstatic struct vm_struct vm;\n\tunsigned long p2m_limit;\n\n\txen_p2m_last_pfn = xen_max_p2m_pfn;\n\n\tp2m_limit = (phys_addr_t)P2M_LIMIT * 1024 * 1024 * 1024 / PAGE_SIZE;\n\tif (!p2m_limit && IS_ENABLED(CONFIG_XEN_UNPOPULATED_ALLOC))\n\t\tp2m_limit = xen_start_info->nr_pages * XEN_EXTRA_MEM_RATIO;\n\n\tvm.flags = VM_ALLOC;\n\tvm.size = ALIGN(sizeof(unsigned long) * max(xen_max_p2m_pfn, p2m_limit),\n\t\t\tPMD_SIZE * PMDS_PER_MID_PAGE);\n\tvm_area_register_early(&vm, PMD_SIZE * PMDS_PER_MID_PAGE);\n\tpr_notice(\"p2m virtual area at %p, size is %lx\\n\", vm.addr, vm.size);\n\n\txen_max_p2m_pfn = vm.size / sizeof(unsigned long);\n\n\txen_rebuild_p2m_list(vm.addr);\n\n\txen_p2m_addr = vm.addr;\n\txen_p2m_size = xen_max_p2m_pfn;\n\n\txen_inv_extra_mem();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -6,6 +6,9 @@\n \txen_p2m_last_pfn = xen_max_p2m_pfn;\n \n \tp2m_limit = (phys_addr_t)P2M_LIMIT * 1024 * 1024 * 1024 / PAGE_SIZE;\n+\tif (!p2m_limit && IS_ENABLED(CONFIG_XEN_UNPOPULATED_ALLOC))\n+\t\tp2m_limit = xen_start_info->nr_pages * XEN_EXTRA_MEM_RATIO;\n+\n \tvm.flags = VM_ALLOC;\n \tvm.size = ALIGN(sizeof(unsigned long) * max(xen_max_p2m_pfn, p2m_limit),\n \t\t\tPMD_SIZE * PMDS_PER_MID_PAGE);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tif (!p2m_limit && IS_ENABLED(CONFIG_XEN_UNPOPULATED_ALLOC))",
                "\t\tp2m_limit = xen_start_info->nr_pages * XEN_EXTRA_MEM_RATIO;",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2021-28039",
        "func_name": "torvalds/linux/__set_phys_to_machine",
        "description": "An issue was discovered in the Linux kernel 5.9.x through 5.11.3, as used with Xen. In some less-common configurations, an x86 PV guest OS user can crash a Dom0 or driver domain via a large amount of I/O activity. The issue relates to misuse of guest physical addresses when a configuration has CONFIG_XEN_UNPOPULATED_ALLOC but not CONFIG_XEN_BALLOON_MEMORY_HOTPLUG.",
        "git_url": "https://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/commit/?h=882213990d32fd224340a4533f6318dd152be4b2",
        "commit_title": "Since commit 9e2369c06c8a18 (\"xen: add helpers to allocate unpopulated",
        "commit_text": "memory\") foreign mappings are using guest physical addresses allocated via ZONE_DEVICE functionality.  This will result in problems for the case of no balloon memory hotplug being configured, as the p2m list will only cover the initial memory size of the domain. Any ZONE_DEVICE allocated address will be outside the p2m range and thus a mapping can't be established with that memory address.  Fix that by extending the p2m size for that case. At the same time add a check for a to be created mapping to be within the p2m limits in order to detect errors early.  While changing a comment, remove some 32-bit leftovers.  This is XSA-369.  Cc: <stable@vger.kernel.org> # 5.9 ",
        "func_before": "bool __set_phys_to_machine(unsigned long pfn, unsigned long mfn)\n{\n\tpte_t *ptep;\n\tunsigned int level;\n\n\tif (unlikely(pfn >= xen_p2m_size)) {\n\t\tBUG_ON(mfn != INVALID_P2M_ENTRY);\n\t\treturn true;\n\t}\n\n\t/*\n\t * The interface requires atomic updates on p2m elements.\n\t * xen_safe_write_ulong() is using an atomic store via asm().\n\t */\n\tif (likely(!xen_safe_write_ulong(xen_p2m_addr + pfn, mfn)))\n\t\treturn true;\n\n\tptep = lookup_address((unsigned long)(xen_p2m_addr + pfn), &level);\n\tBUG_ON(!ptep || level != PG_LEVEL_4K);\n\n\tif (pte_pfn(*ptep) == PFN_DOWN(__pa(p2m_missing)))\n\t\treturn mfn == INVALID_P2M_ENTRY;\n\n\tif (pte_pfn(*ptep) == PFN_DOWN(__pa(p2m_identity)))\n\t\treturn mfn == IDENTITY_FRAME(pfn);\n\n\treturn false;\n}",
        "func": "bool __set_phys_to_machine(unsigned long pfn, unsigned long mfn)\n{\n\tpte_t *ptep;\n\tunsigned int level;\n\n\t/* Only invalid entries allowed above the highest p2m covered frame. */\n\tif (unlikely(pfn >= xen_p2m_size))\n\t\treturn mfn == INVALID_P2M_ENTRY;\n\n\t/*\n\t * The interface requires atomic updates on p2m elements.\n\t * xen_safe_write_ulong() is using an atomic store via asm().\n\t */\n\tif (likely(!xen_safe_write_ulong(xen_p2m_addr + pfn, mfn)))\n\t\treturn true;\n\n\tptep = lookup_address((unsigned long)(xen_p2m_addr + pfn), &level);\n\tBUG_ON(!ptep || level != PG_LEVEL_4K);\n\n\tif (pte_pfn(*ptep) == PFN_DOWN(__pa(p2m_missing)))\n\t\treturn mfn == INVALID_P2M_ENTRY;\n\n\tif (pte_pfn(*ptep) == PFN_DOWN(__pa(p2m_identity)))\n\t\treturn mfn == IDENTITY_FRAME(pfn);\n\n\treturn false;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,10 +3,9 @@\n \tpte_t *ptep;\n \tunsigned int level;\n \n-\tif (unlikely(pfn >= xen_p2m_size)) {\n-\t\tBUG_ON(mfn != INVALID_P2M_ENTRY);\n-\t\treturn true;\n-\t}\n+\t/* Only invalid entries allowed above the highest p2m covered frame. */\n+\tif (unlikely(pfn >= xen_p2m_size))\n+\t\treturn mfn == INVALID_P2M_ENTRY;\n \n \t/*\n \t * The interface requires atomic updates on p2m elements.",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (unlikely(pfn >= xen_p2m_size)) {",
                "\t\tBUG_ON(mfn != INVALID_P2M_ENTRY);",
                "\t\treturn true;",
                "\t}"
            ],
            "added_lines": [
                "\t/* Only invalid entries allowed above the highest p2m covered frame. */",
                "\tif (unlikely(pfn >= xen_p2m_size))",
                "\t\treturn mfn == INVALID_P2M_ENTRY;"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-28039",
        "func_name": "torvalds/linux/xen_memory_setup",
        "description": "An issue was discovered in the Linux kernel 5.9.x through 5.11.3, as used with Xen. In some less-common configurations, an x86 PV guest OS user can crash a Dom0 or driver domain via a large amount of I/O activity. The issue relates to misuse of guest physical addresses when a configuration has CONFIG_XEN_UNPOPULATED_ALLOC but not CONFIG_XEN_BALLOON_MEMORY_HOTPLUG.",
        "git_url": "https://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/commit/?h=882213990d32fd224340a4533f6318dd152be4b2",
        "commit_title": "Since commit 9e2369c06c8a18 (\"xen: add helpers to allocate unpopulated",
        "commit_text": "memory\") foreign mappings are using guest physical addresses allocated via ZONE_DEVICE functionality.  This will result in problems for the case of no balloon memory hotplug being configured, as the p2m list will only cover the initial memory size of the domain. Any ZONE_DEVICE allocated address will be outside the p2m range and thus a mapping can't be established with that memory address.  Fix that by extending the p2m size for that case. At the same time add a check for a to be created mapping to be within the p2m limits in order to detect errors early.  While changing a comment, remove some 32-bit leftovers.  This is XSA-369.  Cc: <stable@vger.kernel.org> # 5.9 ",
        "func_before": "char * __init xen_memory_setup(void)\n{\n\tunsigned long max_pfn, pfn_s, n_pfns;\n\tphys_addr_t mem_end, addr, size, chunk_size;\n\tu32 type;\n\tint rc;\n\tstruct xen_memory_map memmap;\n\tunsigned long max_pages;\n\tunsigned long extra_pages = 0;\n\tint i;\n\tint op;\n\n\txen_parse_512gb();\n\tmax_pfn = xen_get_pages_limit();\n\tmax_pfn = min(max_pfn, xen_start_info->nr_pages);\n\tmem_end = PFN_PHYS(max_pfn);\n\n\tmemmap.nr_entries = ARRAY_SIZE(xen_e820_table.entries);\n\tset_xen_guest_handle(memmap.buffer, xen_e820_table.entries);\n\n#if defined(CONFIG_MEMORY_HOTPLUG) && defined(CONFIG_XEN_BALLOON)\n\txen_saved_max_mem_size = max_mem_size;\n#endif\n\n\top = xen_initial_domain() ?\n\t\tXENMEM_machine_memory_map :\n\t\tXENMEM_memory_map;\n\trc = HYPERVISOR_memory_op(op, &memmap);\n\tif (rc == -ENOSYS) {\n\t\tBUG_ON(xen_initial_domain());\n\t\tmemmap.nr_entries = 1;\n\t\txen_e820_table.entries[0].addr = 0ULL;\n\t\txen_e820_table.entries[0].size = mem_end;\n\t\t/* 8MB slack (to balance backend allocations). */\n\t\txen_e820_table.entries[0].size += 8ULL << 20;\n\t\txen_e820_table.entries[0].type = E820_TYPE_RAM;\n\t\trc = 0;\n\t}\n\tBUG_ON(rc);\n\tBUG_ON(memmap.nr_entries == 0);\n\txen_e820_table.nr_entries = memmap.nr_entries;\n\n\t/*\n\t * Xen won't allow a 1:1 mapping to be created to UNUSABLE\n\t * regions, so if we're using the machine memory map leave the\n\t * region as RAM as it is in the pseudo-physical map.\n\t *\n\t * UNUSABLE regions in domUs are not handled and will need\n\t * a patch in the future.\n\t */\n\tif (xen_initial_domain())\n\t\txen_ignore_unusable();\n\n\t/* Make sure the Xen-supplied memory map is well-ordered. */\n\te820__update_table(&xen_e820_table);\n\n\tmax_pages = xen_get_max_pages();\n\n\t/* How many extra pages do we need due to remapping? */\n\tmax_pages += xen_foreach_remap_area(max_pfn, xen_count_remap_pages);\n\n\tif (max_pages > max_pfn)\n\t\textra_pages += max_pages - max_pfn;\n\n\t/*\n\t * Clamp the amount of extra memory to a EXTRA_MEM_RATIO\n\t * factor the base size.  On non-highmem systems, the base\n\t * size is the full initial memory allocation; on highmem it\n\t * is limited to the max size of lowmem, so that it doesn't\n\t * get completely filled.\n\t *\n\t * Make sure we have no memory above max_pages, as this area\n\t * isn't handled by the p2m management.\n\t *\n\t * In principle there could be a problem in lowmem systems if\n\t * the initial memory is also very large with respect to\n\t * lowmem, but we won't try to deal with that here.\n\t */\n\textra_pages = min3(EXTRA_MEM_RATIO * min(max_pfn, PFN_DOWN(MAXMEM)),\n\t\t\t   extra_pages, max_pages - max_pfn);\n\ti = 0;\n\taddr = xen_e820_table.entries[0].addr;\n\tsize = xen_e820_table.entries[0].size;\n\twhile (i < xen_e820_table.nr_entries) {\n\t\tbool discard = false;\n\n\t\tchunk_size = size;\n\t\ttype = xen_e820_table.entries[i].type;\n\n\t\tif (type == E820_TYPE_RAM) {\n\t\t\tif (addr < mem_end) {\n\t\t\t\tchunk_size = min(size, mem_end - addr);\n\t\t\t} else if (extra_pages) {\n\t\t\t\tchunk_size = min(size, PFN_PHYS(extra_pages));\n\t\t\t\tpfn_s = PFN_UP(addr);\n\t\t\t\tn_pfns = PFN_DOWN(addr + chunk_size) - pfn_s;\n\t\t\t\textra_pages -= n_pfns;\n\t\t\t\txen_add_extra_mem(pfn_s, n_pfns);\n\t\t\t\txen_max_p2m_pfn = pfn_s + n_pfns;\n\t\t\t} else\n\t\t\t\tdiscard = true;\n\t\t}\n\n\t\tif (!discard)\n\t\t\txen_align_and_add_e820_region(addr, chunk_size, type);\n\n\t\taddr += chunk_size;\n\t\tsize -= chunk_size;\n\t\tif (size == 0) {\n\t\t\ti++;\n\t\t\tif (i < xen_e820_table.nr_entries) {\n\t\t\t\taddr = xen_e820_table.entries[i].addr;\n\t\t\t\tsize = xen_e820_table.entries[i].size;\n\t\t\t}\n\t\t}\n\t}\n\n\t/*\n\t * Set the rest as identity mapped, in case PCI BARs are\n\t * located here.\n\t */\n\tset_phys_range_identity(addr / PAGE_SIZE, ~0ul);\n\n\t/*\n\t * In domU, the ISA region is normal, usable memory, but we\n\t * reserve ISA memory anyway because too many things poke\n\t * about in there.\n\t */\n\te820__range_add(ISA_START_ADDRESS, ISA_END_ADDRESS - ISA_START_ADDRESS, E820_TYPE_RESERVED);\n\n\te820__update_table(e820_table);\n\n\t/*\n\t * Check whether the kernel itself conflicts with the target E820 map.\n\t * Failing now is better than running into weird problems later due\n\t * to relocating (and even reusing) pages with kernel text or data.\n\t */\n\tif (xen_is_e820_reserved(__pa_symbol(_text),\n\t\t\t__pa_symbol(__bss_stop) - __pa_symbol(_text))) {\n\t\txen_raw_console_write(\"Xen hypervisor allocated kernel memory conflicts with E820 map\\n\");\n\t\tBUG();\n\t}\n\n\t/*\n\t * Check for a conflict of the hypervisor supplied page tables with\n\t * the target E820 map.\n\t */\n\txen_pt_check_e820();\n\n\txen_reserve_xen_mfnlist();\n\n\t/* Check for a conflict of the initrd with the target E820 map. */\n\tif (xen_is_e820_reserved(boot_params.hdr.ramdisk_image,\n\t\t\t\t boot_params.hdr.ramdisk_size)) {\n\t\tphys_addr_t new_area, start, size;\n\n\t\tnew_area = xen_find_free_area(boot_params.hdr.ramdisk_size);\n\t\tif (!new_area) {\n\t\t\txen_raw_console_write(\"Can't find new memory area for initrd needed due to E820 map conflict\\n\");\n\t\t\tBUG();\n\t\t}\n\n\t\tstart = boot_params.hdr.ramdisk_image;\n\t\tsize = boot_params.hdr.ramdisk_size;\n\t\txen_phys_memcpy(new_area, start, size);\n\t\tpr_info(\"initrd moved from [mem %#010llx-%#010llx] to [mem %#010llx-%#010llx]\\n\",\n\t\t\tstart, start + size, new_area, new_area + size);\n\t\tmemblock_free(start, size);\n\t\tboot_params.hdr.ramdisk_image = new_area;\n\t\tboot_params.ext_ramdisk_image = new_area >> 32;\n\t}\n\n\t/*\n\t * Set identity map on non-RAM pages and prepare remapping the\n\t * underlying RAM.\n\t */\n\txen_foreach_remap_area(max_pfn, xen_set_identity_and_remap_chunk);\n\n\tpr_info(\"Released %ld page(s)\\n\", xen_released_pages);\n\n\treturn \"Xen\";\n}",
        "func": "char * __init xen_memory_setup(void)\n{\n\tunsigned long max_pfn, pfn_s, n_pfns;\n\tphys_addr_t mem_end, addr, size, chunk_size;\n\tu32 type;\n\tint rc;\n\tstruct xen_memory_map memmap;\n\tunsigned long max_pages;\n\tunsigned long extra_pages = 0;\n\tint i;\n\tint op;\n\n\txen_parse_512gb();\n\tmax_pfn = xen_get_pages_limit();\n\tmax_pfn = min(max_pfn, xen_start_info->nr_pages);\n\tmem_end = PFN_PHYS(max_pfn);\n\n\tmemmap.nr_entries = ARRAY_SIZE(xen_e820_table.entries);\n\tset_xen_guest_handle(memmap.buffer, xen_e820_table.entries);\n\n#if defined(CONFIG_MEMORY_HOTPLUG) && defined(CONFIG_XEN_BALLOON)\n\txen_saved_max_mem_size = max_mem_size;\n#endif\n\n\top = xen_initial_domain() ?\n\t\tXENMEM_machine_memory_map :\n\t\tXENMEM_memory_map;\n\trc = HYPERVISOR_memory_op(op, &memmap);\n\tif (rc == -ENOSYS) {\n\t\tBUG_ON(xen_initial_domain());\n\t\tmemmap.nr_entries = 1;\n\t\txen_e820_table.entries[0].addr = 0ULL;\n\t\txen_e820_table.entries[0].size = mem_end;\n\t\t/* 8MB slack (to balance backend allocations). */\n\t\txen_e820_table.entries[0].size += 8ULL << 20;\n\t\txen_e820_table.entries[0].type = E820_TYPE_RAM;\n\t\trc = 0;\n\t}\n\tBUG_ON(rc);\n\tBUG_ON(memmap.nr_entries == 0);\n\txen_e820_table.nr_entries = memmap.nr_entries;\n\n\t/*\n\t * Xen won't allow a 1:1 mapping to be created to UNUSABLE\n\t * regions, so if we're using the machine memory map leave the\n\t * region as RAM as it is in the pseudo-physical map.\n\t *\n\t * UNUSABLE regions in domUs are not handled and will need\n\t * a patch in the future.\n\t */\n\tif (xen_initial_domain())\n\t\txen_ignore_unusable();\n\n\t/* Make sure the Xen-supplied memory map is well-ordered. */\n\te820__update_table(&xen_e820_table);\n\n\tmax_pages = xen_get_max_pages();\n\n\t/* How many extra pages do we need due to remapping? */\n\tmax_pages += xen_foreach_remap_area(max_pfn, xen_count_remap_pages);\n\n\tif (max_pages > max_pfn)\n\t\textra_pages += max_pages - max_pfn;\n\n\t/*\n\t * Clamp the amount of extra memory to a XEN_EXTRA_MEM_RATIO\n\t * factor the base size.\n\t *\n\t * Make sure we have no memory above max_pages, as this area\n\t * isn't handled by the p2m management.\n\t */\n\textra_pages = min3(XEN_EXTRA_MEM_RATIO * min(max_pfn, PFN_DOWN(MAXMEM)),\n\t\t\t   extra_pages, max_pages - max_pfn);\n\ti = 0;\n\taddr = xen_e820_table.entries[0].addr;\n\tsize = xen_e820_table.entries[0].size;\n\twhile (i < xen_e820_table.nr_entries) {\n\t\tbool discard = false;\n\n\t\tchunk_size = size;\n\t\ttype = xen_e820_table.entries[i].type;\n\n\t\tif (type == E820_TYPE_RAM) {\n\t\t\tif (addr < mem_end) {\n\t\t\t\tchunk_size = min(size, mem_end - addr);\n\t\t\t} else if (extra_pages) {\n\t\t\t\tchunk_size = min(size, PFN_PHYS(extra_pages));\n\t\t\t\tpfn_s = PFN_UP(addr);\n\t\t\t\tn_pfns = PFN_DOWN(addr + chunk_size) - pfn_s;\n\t\t\t\textra_pages -= n_pfns;\n\t\t\t\txen_add_extra_mem(pfn_s, n_pfns);\n\t\t\t\txen_max_p2m_pfn = pfn_s + n_pfns;\n\t\t\t} else\n\t\t\t\tdiscard = true;\n\t\t}\n\n\t\tif (!discard)\n\t\t\txen_align_and_add_e820_region(addr, chunk_size, type);\n\n\t\taddr += chunk_size;\n\t\tsize -= chunk_size;\n\t\tif (size == 0) {\n\t\t\ti++;\n\t\t\tif (i < xen_e820_table.nr_entries) {\n\t\t\t\taddr = xen_e820_table.entries[i].addr;\n\t\t\t\tsize = xen_e820_table.entries[i].size;\n\t\t\t}\n\t\t}\n\t}\n\n\t/*\n\t * Set the rest as identity mapped, in case PCI BARs are\n\t * located here.\n\t */\n\tset_phys_range_identity(addr / PAGE_SIZE, ~0ul);\n\n\t/*\n\t * In domU, the ISA region is normal, usable memory, but we\n\t * reserve ISA memory anyway because too many things poke\n\t * about in there.\n\t */\n\te820__range_add(ISA_START_ADDRESS, ISA_END_ADDRESS - ISA_START_ADDRESS, E820_TYPE_RESERVED);\n\n\te820__update_table(e820_table);\n\n\t/*\n\t * Check whether the kernel itself conflicts with the target E820 map.\n\t * Failing now is better than running into weird problems later due\n\t * to relocating (and even reusing) pages with kernel text or data.\n\t */\n\tif (xen_is_e820_reserved(__pa_symbol(_text),\n\t\t\t__pa_symbol(__bss_stop) - __pa_symbol(_text))) {\n\t\txen_raw_console_write(\"Xen hypervisor allocated kernel memory conflicts with E820 map\\n\");\n\t\tBUG();\n\t}\n\n\t/*\n\t * Check for a conflict of the hypervisor supplied page tables with\n\t * the target E820 map.\n\t */\n\txen_pt_check_e820();\n\n\txen_reserve_xen_mfnlist();\n\n\t/* Check for a conflict of the initrd with the target E820 map. */\n\tif (xen_is_e820_reserved(boot_params.hdr.ramdisk_image,\n\t\t\t\t boot_params.hdr.ramdisk_size)) {\n\t\tphys_addr_t new_area, start, size;\n\n\t\tnew_area = xen_find_free_area(boot_params.hdr.ramdisk_size);\n\t\tif (!new_area) {\n\t\t\txen_raw_console_write(\"Can't find new memory area for initrd needed due to E820 map conflict\\n\");\n\t\t\tBUG();\n\t\t}\n\n\t\tstart = boot_params.hdr.ramdisk_image;\n\t\tsize = boot_params.hdr.ramdisk_size;\n\t\txen_phys_memcpy(new_area, start, size);\n\t\tpr_info(\"initrd moved from [mem %#010llx-%#010llx] to [mem %#010llx-%#010llx]\\n\",\n\t\t\tstart, start + size, new_area, new_area + size);\n\t\tmemblock_free(start, size);\n\t\tboot_params.hdr.ramdisk_image = new_area;\n\t\tboot_params.ext_ramdisk_image = new_area >> 32;\n\t}\n\n\t/*\n\t * Set identity map on non-RAM pages and prepare remapping the\n\t * underlying RAM.\n\t */\n\txen_foreach_remap_area(max_pfn, xen_set_identity_and_remap_chunk);\n\n\tpr_info(\"Released %ld page(s)\\n\", xen_released_pages);\n\n\treturn \"Xen\";\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -63,20 +63,13 @@\n \t\textra_pages += max_pages - max_pfn;\n \n \t/*\n-\t * Clamp the amount of extra memory to a EXTRA_MEM_RATIO\n-\t * factor the base size.  On non-highmem systems, the base\n-\t * size is the full initial memory allocation; on highmem it\n-\t * is limited to the max size of lowmem, so that it doesn't\n-\t * get completely filled.\n+\t * Clamp the amount of extra memory to a XEN_EXTRA_MEM_RATIO\n+\t * factor the base size.\n \t *\n \t * Make sure we have no memory above max_pages, as this area\n \t * isn't handled by the p2m management.\n-\t *\n-\t * In principle there could be a problem in lowmem systems if\n-\t * the initial memory is also very large with respect to\n-\t * lowmem, but we won't try to deal with that here.\n \t */\n-\textra_pages = min3(EXTRA_MEM_RATIO * min(max_pfn, PFN_DOWN(MAXMEM)),\n+\textra_pages = min3(XEN_EXTRA_MEM_RATIO * min(max_pfn, PFN_DOWN(MAXMEM)),\n \t\t\t   extra_pages, max_pages - max_pfn);\n \ti = 0;\n \taddr = xen_e820_table.entries[0].addr;",
        "diff_line_info": {
            "deleted_lines": [
                "\t * Clamp the amount of extra memory to a EXTRA_MEM_RATIO",
                "\t * factor the base size.  On non-highmem systems, the base",
                "\t * size is the full initial memory allocation; on highmem it",
                "\t * is limited to the max size of lowmem, so that it doesn't",
                "\t * get completely filled.",
                "\t *",
                "\t * In principle there could be a problem in lowmem systems if",
                "\t * the initial memory is also very large with respect to",
                "\t * lowmem, but we won't try to deal with that here.",
                "\textra_pages = min3(EXTRA_MEM_RATIO * min(max_pfn, PFN_DOWN(MAXMEM)),"
            ],
            "added_lines": [
                "\t * Clamp the amount of extra memory to a XEN_EXTRA_MEM_RATIO",
                "\t * factor the base size.",
                "\textra_pages = min3(XEN_EXTRA_MEM_RATIO * min(max_pfn, PFN_DOWN(MAXMEM)),"
            ]
        }
    }
]