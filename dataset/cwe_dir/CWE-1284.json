[
    {
        "cve_id": "CVE-2022-23580",
        "func_name": "tensorflow/InferenceContext::InternalMakeShapeFromTensor",
        "description": "Tensorflow is an Open Source Machine Learning Framework. During shape inference, TensorFlow can allocate a large vector based on a value from a tensor controlled by the user. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/1361fb7e29449629e1df94d44e0427ebec8c83c7",
        "commit_title": "Fix abort caused by allocating a too large vector.",
        "commit_text": " We need to make sure that the number of dimensions in a shape is within limits.  PiperOrigin-RevId: 408997911",
        "func_before": "Status InferenceContext::InternalMakeShapeFromTensor(\n    bool treat_unknown_scalar_tensor_as_unknown_shape, const Tensor* t,\n    ShapeHandle tensor_shape, ShapeHandle* out) {\n  // Only callers who have set\n  if (!treat_unknown_scalar_tensor_as_unknown_shape) {\n    TF_RETURN_IF_ERROR(WithRank(tensor_shape, 1, &tensor_shape));\n  }\n  if (t == nullptr) {\n    // This is guarded by the check above.\n    if (Rank(tensor_shape) == 0) {\n      return ReturnUnknownShape(out);\n    }\n    // Shape tensor is not known, but if the shape of the shape tensor is then\n    // the right number of unknown dims can be created.\n    DimensionHandle shape_dim = Dim(tensor_shape, 0);\n    if (!ValueKnown(shape_dim)) {\n      return ReturnUnknownShape(out);\n    }\n    const auto num_dims = Value(shape_dim);\n    std::vector<DimensionHandle> dims;\n    dims.reserve(num_dims);\n    for (int i = 0; i < num_dims; i++) dims.push_back(UnknownDim());\n    return ReturnCreatedShape(dims, out);\n  }\n\n  if (t->shape().dims() == 0) {\n    if (t->dtype() == DataType::DT_INT32) {\n      auto flat_t = t->scalar<int32>();\n      if (flat_t() != -1) {\n        *out = nullptr;\n        return errors::InvalidArgument(\n            \"Input tensor must be rank 1, or if its rank 0 it must have value \"\n            \"-1 \"\n            \"(representing an unknown shape).  Saw value: \",\n            flat_t());\n      }\n      return ReturnUnknownShape(out);\n    } else if (t->dtype() == DataType::DT_INT64) {\n      auto flat_t = t->scalar<int64_t>();\n      if (flat_t() != -1) {\n        *out = nullptr;\n        return errors::InvalidArgument(\n            \"Input tensor must be rank 1, or if its rank 0 it must have value \"\n            \"-1 \"\n            \"(representing an unknown shape).  Saw value: \",\n            flat_t());\n      }\n      return ReturnUnknownShape(out);\n    } else {\n      *out = nullptr;\n      return errors::InvalidArgument(\n          \"Input tensor must be int32 or int64, but was \",\n          DataTypeString(t->dtype()));\n    }\n  }\n\n  if (t->shape().dims() != 1) {\n    *out = nullptr;\n    return errors::InvalidArgument(\n        \"Input tensor must be rank 1, but was rank \", t->shape().dims(), \".\",\n        ((t->shape().dims() == 0)\n             ? \"If it is rank 0 rank 0 it must have statically known value -1 \"\n               \"(representing an unknown shape). \"\n             : \" \"),\n        \"Saw tensor shape \", t->shape().DebugString());\n  }\n  std::vector<DimensionHandle> dims;\n  if (t->dtype() == DataType::DT_INT32) {\n    auto flat_t = t->flat<int32>();\n    for (int i = 0; i < flat_t.size(); ++i) {\n      const int32_t val = flat_t(i);\n      if (val < -1) {\n        return errors::InvalidArgument(\n            \"Invalid value in tensor used for shape: \", val);\n      }\n      // -1 will become an unknown dim.\n      dims.push_back(MakeDim(val));\n    }\n  } else if (t->dtype() == DataType::DT_INT64) {\n    auto flat_t = t->flat<int64_t>();\n    for (int i = 0; i < flat_t.size(); ++i) {\n      const int64_t val = flat_t(i);\n      if (val < -1) {\n        return errors::InvalidArgument(\n            \"Invalid value in tensor used for shape: \", val);\n      }\n      // -1 will become an unknown dim.\n      dims.push_back(MakeDim(val));\n    }\n  } else {\n    *out = nullptr;\n    return errors::InvalidArgument(\n        \"Input tensor must be int32 or int64, but was \",\n        DataTypeString(t->dtype()));\n  }\n\n  return ReturnCreatedShape(dims, out);\n}",
        "func": "Status InferenceContext::InternalMakeShapeFromTensor(\n    bool treat_unknown_scalar_tensor_as_unknown_shape, const Tensor* t,\n    ShapeHandle tensor_shape, ShapeHandle* out) {\n  // Only callers who have set\n  if (!treat_unknown_scalar_tensor_as_unknown_shape) {\n    TF_RETURN_IF_ERROR(WithRank(tensor_shape, 1, &tensor_shape));\n  }\n  if (t == nullptr) {\n    // This is guarded by the check above.\n    if (Rank(tensor_shape) == 0) {\n      return ReturnUnknownShape(out);\n    }\n    // Shape tensor is not known, but if the shape of the shape tensor is then\n    // the right number of unknown dims can be created.\n    DimensionHandle shape_dim = Dim(tensor_shape, 0);\n    if (!ValueKnown(shape_dim)) {\n      return ReturnUnknownShape(out);\n    }\n    const auto num_dims = Value(shape_dim);\n    // TODO(mihaimaruseac): Should be `TensorShape::MaxDimensions()` as we are\n    // not able to materialize shapes with more than this number of dimensions\n    // but then shape inference would fail for operations such as\n    // `tf.range`/`tf.ones`, etc. where the shape is not really materialized,\n    // only used during the inference. Hence, just prevent doing a `reserve`\n    // with a very large argument.\n    const int64_t max_dimensions = 1 << 20;\n    if (num_dims >= max_dimensions) {\n      return errors::Internal(\n          \"Cannot create a tensor with \", num_dims,\n          \" dimensions, as these would be more than maximum of \",\n          max_dimensions);\n    }\n    std::vector<DimensionHandle> dims;\n    dims.reserve(num_dims);\n    for (int i = 0; i < num_dims; i++) dims.push_back(UnknownDim());\n    return ReturnCreatedShape(dims, out);\n  }\n\n  if (t->shape().dims() == 0) {\n    if (t->dtype() == DataType::DT_INT32) {\n      auto flat_t = t->scalar<int32>();\n      if (flat_t() != -1) {\n        *out = nullptr;\n        return errors::InvalidArgument(\n            \"Input tensor must be rank 1, or if its rank 0 it must have value \"\n            \"-1 \"\n            \"(representing an unknown shape).  Saw value: \",\n            flat_t());\n      }\n      return ReturnUnknownShape(out);\n    } else if (t->dtype() == DataType::DT_INT64) {\n      auto flat_t = t->scalar<int64_t>();\n      if (flat_t() != -1) {\n        *out = nullptr;\n        return errors::InvalidArgument(\n            \"Input tensor must be rank 1, or if its rank 0 it must have value \"\n            \"-1 \"\n            \"(representing an unknown shape).  Saw value: \",\n            flat_t());\n      }\n      return ReturnUnknownShape(out);\n    } else {\n      *out = nullptr;\n      return errors::InvalidArgument(\n          \"Input tensor must be int32 or int64, but was \",\n          DataTypeString(t->dtype()));\n    }\n  }\n\n  if (t->shape().dims() != 1) {\n    *out = nullptr;\n    return errors::InvalidArgument(\n        \"Input tensor must be rank 1, but was rank \", t->shape().dims(), \".\",\n        ((t->shape().dims() == 0)\n             ? \"If it is rank 0 rank 0 it must have statically known value -1 \"\n               \"(representing an unknown shape). \"\n             : \" \"),\n        \"Saw tensor shape \", t->shape().DebugString());\n  }\n  std::vector<DimensionHandle> dims;\n  if (t->dtype() == DataType::DT_INT32) {\n    auto flat_t = t->flat<int32>();\n    for (int i = 0; i < flat_t.size(); ++i) {\n      const int32_t val = flat_t(i);\n      if (val < -1) {\n        return errors::InvalidArgument(\n            \"Invalid value in tensor used for shape: \", val);\n      }\n      // -1 will become an unknown dim.\n      dims.push_back(MakeDim(val));\n    }\n  } else if (t->dtype() == DataType::DT_INT64) {\n    auto flat_t = t->flat<int64_t>();\n    for (int i = 0; i < flat_t.size(); ++i) {\n      const int64_t val = flat_t(i);\n      if (val < -1) {\n        return errors::InvalidArgument(\n            \"Invalid value in tensor used for shape: \", val);\n      }\n      // -1 will become an unknown dim.\n      dims.push_back(MakeDim(val));\n    }\n  } else {\n    *out = nullptr;\n    return errors::InvalidArgument(\n        \"Input tensor must be int32 or int64, but was \",\n        DataTypeString(t->dtype()));\n  }\n\n  return ReturnCreatedShape(dims, out);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -17,6 +17,19 @@\n       return ReturnUnknownShape(out);\n     }\n     const auto num_dims = Value(shape_dim);\n+    // TODO(mihaimaruseac): Should be `TensorShape::MaxDimensions()` as we are\n+    // not able to materialize shapes with more than this number of dimensions\n+    // but then shape inference would fail for operations such as\n+    // `tf.range`/`tf.ones`, etc. where the shape is not really materialized,\n+    // only used during the inference. Hence, just prevent doing a `reserve`\n+    // with a very large argument.\n+    const int64_t max_dimensions = 1 << 20;\n+    if (num_dims >= max_dimensions) {\n+      return errors::Internal(\n+          \"Cannot create a tensor with \", num_dims,\n+          \" dimensions, as these would be more than maximum of \",\n+          max_dimensions);\n+    }\n     std::vector<DimensionHandle> dims;\n     dims.reserve(num_dims);\n     for (int i = 0; i < num_dims; i++) dims.push_back(UnknownDim());",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    // TODO(mihaimaruseac): Should be `TensorShape::MaxDimensions()` as we are",
                "    // not able to materialize shapes with more than this number of dimensions",
                "    // but then shape inference would fail for operations such as",
                "    // `tf.range`/`tf.ones`, etc. where the shape is not really materialized,",
                "    // only used during the inference. Hence, just prevent doing a `reserve`",
                "    // with a very large argument.",
                "    const int64_t max_dimensions = 1 << 20;",
                "    if (num_dims >= max_dimensions) {",
                "      return errors::Internal(",
                "          \"Cannot create a tensor with \", num_dims,",
                "          \" dimensions, as these would be more than maximum of \",",
                "          max_dimensions);",
                "    }"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-2845",
        "func_name": "vim/display_dollar",
        "description": "Improper Validation of Specified Quantity in Input in GitHub repository vim/vim prior to 9.0.0218.\n\n",
        "git_url": "https://github.com/vim/vim/commit/e98c88c44c308edaea5994b8ad4363e65030968c",
        "commit_title": "patch 9.0.0218: reading before the start of the line",
        "commit_text": " Problem:    Reading before the start of the line. Solution:   When displaying \"$\" check the column is not negative.",
        "func_before": "void\ndisplay_dollar(colnr_T col)\n{\n    colnr_T save_col;\n\n    if (!redrawing())\n\treturn;\n\n    cursor_off();\n    save_col = curwin->w_cursor.col;\n    curwin->w_cursor.col = col;\n    if (has_mbyte)\n    {\n\tchar_u *p;\n\n\t// If on the last byte of a multi-byte move to the first byte.\n\tp = ml_get_curline();\n\tcurwin->w_cursor.col -= (*mb_head_off)(p, p + col);\n    }\n    curs_columns(FALSE);\t    // recompute w_wrow and w_wcol\n    if (curwin->w_wcol < curwin->w_width)\n    {\n\tedit_putchar('$', FALSE);\n\tdollar_vcol = curwin->w_virtcol;\n    }\n    curwin->w_cursor.col = save_col;\n}",
        "func": "void\ndisplay_dollar(colnr_T col_arg)\n{\n    colnr_T col = col_arg < 0 ? 0 : col_arg;\n    colnr_T save_col;\n\n    if (!redrawing())\n\treturn;\n\n    cursor_off();\n    save_col = curwin->w_cursor.col;\n    curwin->w_cursor.col = col;\n    if (has_mbyte)\n    {\n\tchar_u *p;\n\n\t// If on the last byte of a multi-byte move to the first byte.\n\tp = ml_get_curline();\n\tcurwin->w_cursor.col -= (*mb_head_off)(p, p + col);\n    }\n    curs_columns(FALSE);\t    // recompute w_wrow and w_wcol\n    if (curwin->w_wcol < curwin->w_width)\n    {\n\tedit_putchar('$', FALSE);\n\tdollar_vcol = curwin->w_virtcol;\n    }\n    curwin->w_cursor.col = save_col;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,7 @@\n void\n-display_dollar(colnr_T col)\n+display_dollar(colnr_T col_arg)\n {\n+    colnr_T col = col_arg < 0 ? 0 : col_arg;\n     colnr_T save_col;\n \n     if (!redrawing())",
        "diff_line_info": {
            "deleted_lines": [
                "display_dollar(colnr_T col)"
            ],
            "added_lines": [
                "display_dollar(colnr_T col_arg)",
                "    colnr_T col = col_arg < 0 ? 0 : col_arg;"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-40761",
        "func_name": "Samsung/mTower/tee_obj_alloc",
        "description": "The function tee_obj_free in Samsung mTower through 0.3.0 allows a trusted application to trigger a Denial of Service (DoS) by invoking the function TEE_AllocateOperation with a disturbed heap layout, related to utee_cryp_obj_alloc.",
        "git_url": "https://github.com/Samsung/mTower/commit/c5f30c70e48786e1aef8c815f35e406a6c4fb3ae",
        "commit_title": "Fixed CVE-2022-40761",
        "commit_text": "",
        "func_before": "struct tee_obj *tee_obj_alloc(void)\n{\n\treturn calloc(1, sizeof(struct tee_obj));\n}",
        "func": "struct tee_obj *tee_obj_alloc(void)\n{\n\t// return calloc(1, sizeof(struct tee_obj));\n\treturn TEE_Malloc(sizeof(struct tee_obj), TEE_MALLOC_FILL_ZERO);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,4 +1,5 @@\n struct tee_obj *tee_obj_alloc(void)\n {\n-\treturn calloc(1, sizeof(struct tee_obj));\n+\t// return calloc(1, sizeof(struct tee_obj));\n+\treturn TEE_Malloc(sizeof(struct tee_obj), TEE_MALLOC_FILL_ZERO);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\treturn calloc(1, sizeof(struct tee_obj));"
            ],
            "added_lines": [
                "\t// return calloc(1, sizeof(struct tee_obj));",
                "\treturn TEE_Malloc(sizeof(struct tee_obj), TEE_MALLOC_FILL_ZERO);"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-40761",
        "func_name": "Samsung/mTower/tee_obj_set_type",
        "description": "The function tee_obj_free in Samsung mTower through 0.3.0 allows a trusted application to trigger a Denial of Service (DoS) by invoking the function TEE_AllocateOperation with a disturbed heap layout, related to utee_cryp_obj_alloc.",
        "git_url": "https://github.com/Samsung/mTower/commit/c5f30c70e48786e1aef8c815f35e406a6c4fb3ae",
        "commit_title": "Fixed CVE-2022-40761",
        "commit_text": "",
        "func_before": "TEE_Result tee_obj_set_type(struct tee_obj *o, uint32_t obj_type,\n\t\t\t    size_t max_key_size)\n{\n\tTEE_Result res = TEE_SUCCESS;\n\tconst struct tee_cryp_obj_type_props *type_props;\n\n\t/* Can only set type for newly allocated objs */\n\tif (o->attr)\n\t\treturn TEE_ERROR_BAD_STATE;\n\n\t/*\n\t * Verify that maxKeySize is supported and find out how\n\t * much should be allocated.\n\t */\n\n\tif (obj_type == TEE_TYPE_DATA) {\n\t\tif (max_key_size)\n\t\t\treturn TEE_ERROR_NOT_SUPPORTED;\n\t} else {\n\t\t/* Find description of object */\n\t\ttype_props = tee_svc_find_type_props(obj_type);\n\t\tif (!type_props)\n\t\t\treturn TEE_ERROR_NOT_SUPPORTED;\n\n\t\t/* Check that maxKeySize follows restrictions */\n\t\tif (max_key_size % type_props->quanta != 0)\n\t\t\treturn TEE_ERROR_NOT_SUPPORTED;\n\t\tif (max_key_size < type_props->min_size)\n\t\t\treturn TEE_ERROR_NOT_SUPPORTED;\n\t\tif (max_key_size > type_props->max_size)\n\t\t\treturn TEE_ERROR_NOT_SUPPORTED;\n\n\t\to->attr = calloc(1, type_props->alloc_size);\n\t\tif (!o->attr)\n\t\t\treturn TEE_ERROR_OUT_OF_MEMORY;\n\t}\n\n\t/* If we have a key structure, pre-allocate the bignums inside */\n\tswitch (obj_type) {\n//\tcase TEE_TYPE_RSA_PUBLIC_KEY:\n//\t\tres = crypto_acipher_alloc_rsa_public_key(o->attr,\n//\t\t\t\t\t\t\t  max_key_size);\n//\t\tbreak;\n//\tcase TEE_TYPE_RSA_KEYPAIR:\n//\t\tres = crypto_acipher_alloc_rsa_keypair(o->attr, max_key_size);\n//\t\tbreak;\n//\tcase TEE_TYPE_DSA_PUBLIC_KEY:\n//\t\tres = crypto_acipher_alloc_dsa_public_key(o->attr,\n//\t\t\t\t\t\t\t  max_key_size);\n//\t\tbreak;\n//\tcase TEE_TYPE_DSA_KEYPAIR:\n//\t\tres = crypto_acipher_alloc_dsa_keypair(o->attr, max_key_size);\n//\t\tbreak;\n//\tcase TEE_TYPE_DH_KEYPAIR:\n//\t\tres = crypto_acipher_alloc_dh_keypair(o->attr, max_key_size);\n//\t\tbreak;\n//\tcase TEE_TYPE_ECDSA_PUBLIC_KEY:\n//\tcase TEE_TYPE_ECDH_PUBLIC_KEY:\n//\t\tres = crypto_acipher_alloc_ecc_public_key(o->attr,\n//\t\t\t\t\t\t\t  max_key_size);\n//\t\tbreak;\n//\tcase TEE_TYPE_ECDSA_KEYPAIR:\n//\tcase TEE_TYPE_ECDH_KEYPAIR:\n//\t\tres = crypto_acipher_alloc_ecc_keypair(o->attr, max_key_size);\n//\t\tbreak;\n\tdefault:\n\t\tif (obj_type != TEE_TYPE_DATA) {\n\t\t\tstruct tee_cryp_obj_secret *key = o->attr;\n\n\t\t\tkey->alloc_size = type_props->alloc_size -\n\t\t\t\t\t  sizeof(*key);\n\t\t}\n\t\tbreak;\n\t}\n\n\tif (res != TEE_SUCCESS)\n\t\treturn res;\n\n\to->info.objectType = obj_type;\n\to->info.maxKeySize = max_key_size;\n\to->info.objectUsage = TEE_USAGE_DEFAULT;\n\n\treturn TEE_SUCCESS;\n}",
        "func": "TEE_Result tee_obj_set_type(struct tee_obj *o, uint32_t obj_type,\n\t\t\t    size_t max_key_size)\n{\n\tTEE_Result res = TEE_SUCCESS;\n\tconst struct tee_cryp_obj_type_props *type_props;\n\n\t/* Can only set type for newly allocated objs */\n\tif (o->attr)\n\t\treturn TEE_ERROR_BAD_STATE;\n\n\t/*\n\t * Verify that maxKeySize is supported and find out how\n\t * much should be allocated.\n\t */\n\n\tif (obj_type == TEE_TYPE_DATA) {\n\t\tif (max_key_size)\n\t\t\treturn TEE_ERROR_NOT_SUPPORTED;\n\t} else {\n\t\t/* Find description of object */\n\t\ttype_props = tee_svc_find_type_props(obj_type);\n\t\tif (!type_props)\n\t\t\treturn TEE_ERROR_NOT_SUPPORTED;\n\n\t\t/* Check that maxKeySize follows restrictions */\n\t\tif (max_key_size % type_props->quanta != 0)\n\t\t\treturn TEE_ERROR_NOT_SUPPORTED;\n\t\tif (max_key_size < type_props->min_size)\n\t\t\treturn TEE_ERROR_NOT_SUPPORTED;\n\t\tif (max_key_size > type_props->max_size)\n\t\t\treturn TEE_ERROR_NOT_SUPPORTED;\n\n\t\to->attr = TEE_Malloc(type_props->alloc_size, TEE_MALLOC_FILL_ZERO);\n\t\t// o->attr = calloc(1, type_props->alloc_size);\n\t\tif (!o->attr)\n\t\t\treturn TEE_ERROR_OUT_OF_MEMORY;\n\t}\n\n\t/* If we have a key structure, pre-allocate the bignums inside */\n\tswitch (obj_type) {\n//\tcase TEE_TYPE_RSA_PUBLIC_KEY:\n//\t\tres = crypto_acipher_alloc_rsa_public_key(o->attr,\n//\t\t\t\t\t\t\t  max_key_size);\n//\t\tbreak;\n//\tcase TEE_TYPE_RSA_KEYPAIR:\n//\t\tres = crypto_acipher_alloc_rsa_keypair(o->attr, max_key_size);\n//\t\tbreak;\n//\tcase TEE_TYPE_DSA_PUBLIC_KEY:\n//\t\tres = crypto_acipher_alloc_dsa_public_key(o->attr,\n//\t\t\t\t\t\t\t  max_key_size);\n//\t\tbreak;\n//\tcase TEE_TYPE_DSA_KEYPAIR:\n//\t\tres = crypto_acipher_alloc_dsa_keypair(o->attr, max_key_size);\n//\t\tbreak;\n//\tcase TEE_TYPE_DH_KEYPAIR:\n//\t\tres = crypto_acipher_alloc_dh_keypair(o->attr, max_key_size);\n//\t\tbreak;\n//\tcase TEE_TYPE_ECDSA_PUBLIC_KEY:\n//\tcase TEE_TYPE_ECDH_PUBLIC_KEY:\n//\t\tres = crypto_acipher_alloc_ecc_public_key(o->attr,\n//\t\t\t\t\t\t\t  max_key_size);\n//\t\tbreak;\n//\tcase TEE_TYPE_ECDSA_KEYPAIR:\n//\tcase TEE_TYPE_ECDH_KEYPAIR:\n//\t\tres = crypto_acipher_alloc_ecc_keypair(o->attr, max_key_size);\n//\t\tbreak;\n\tdefault:\n\t\tif (obj_type != TEE_TYPE_DATA) {\n\t\t\tstruct tee_cryp_obj_secret *key = o->attr;\n\n\t\t\tkey->alloc_size = type_props->alloc_size -\n\t\t\t\t\t  sizeof(*key);\n\t\t}\n\t\tbreak;\n\t}\n\n\tif (res != TEE_SUCCESS)\n\t\treturn res;\n\n\to->info.objectType = obj_type;\n\to->info.maxKeySize = max_key_size;\n\to->info.objectUsage = TEE_USAGE_DEFAULT;\n\n\treturn TEE_SUCCESS;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -30,7 +30,8 @@\n \t\tif (max_key_size > type_props->max_size)\n \t\t\treturn TEE_ERROR_NOT_SUPPORTED;\n \n-\t\to->attr = calloc(1, type_props->alloc_size);\n+\t\to->attr = TEE_Malloc(type_props->alloc_size, TEE_MALLOC_FILL_ZERO);\n+\t\t// o->attr = calloc(1, type_props->alloc_size);\n \t\tif (!o->attr)\n \t\t\treturn TEE_ERROR_OUT_OF_MEMORY;\n \t}",
        "diff_line_info": {
            "deleted_lines": [
                "\t\to->attr = calloc(1, type_props->alloc_size);"
            ],
            "added_lines": [
                "\t\to->attr = TEE_Malloc(type_props->alloc_size, TEE_MALLOC_FILL_ZERO);",
                "\t\t// o->attr = calloc(1, type_props->alloc_size);"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-40761",
        "func_name": "Samsung/mTower/utee_cryp_state_alloc",
        "description": "The function tee_obj_free in Samsung mTower through 0.3.0 allows a trusted application to trigger a Denial of Service (DoS) by invoking the function TEE_AllocateOperation with a disturbed heap layout, related to utee_cryp_obj_alloc.",
        "git_url": "https://github.com/Samsung/mTower/commit/c5f30c70e48786e1aef8c815f35e406a6c4fb3ae",
        "commit_title": "Fixed CVE-2022-40761",
        "commit_text": "",
        "func_before": "TEE_Result utee_cryp_state_alloc(unsigned long algo, unsigned long mode,\n\t\t\tunsigned long key1, unsigned long key2,\n\t\t\tuint32_t *state)\n{\n\tTEE_Result res;\n\tstruct tee_cryp_state *cs;\n\tstruct tee_ta_session *sess;\n\tstruct tee_obj *o1 = NULL;\n\tstruct tee_obj *o2 = NULL;\n\tstruct user_ta_ctx *utc;\n\n\tres = tee_ta_get_current_session(&sess);\n\tif (res != TEE_SUCCESS)\n\t\treturn res;\n\tutc = to_user_ta_ctx(sess->ctx);\n\n\tif (key1 != 0) {\n\t\tres = tee_obj_get(utc, tee_svc_uref_to_vaddr(key1), &o1);\n\t\tif (res != TEE_SUCCESS)\n\t\t\treturn res;\n\t\tif (o1->busy)\n\t\t\treturn TEE_ERROR_BAD_PARAMETERS;\n\t\tres = tee_svc_cryp_check_key_type(o1, algo, mode);\n\t\tif (res != TEE_SUCCESS)\n\t\t\treturn res;\n\t}\n\tif (key2 != 0) {\n\t\tres = tee_obj_get(utc, tee_svc_uref_to_vaddr(key2), &o2);\n\t\tif (res != TEE_SUCCESS)\n\t\t\treturn res;\n\t\tif (o2->busy)\n\t\t\treturn TEE_ERROR_BAD_PARAMETERS;\n\t\tres = tee_svc_cryp_check_key_type(o2, algo, mode);\n\t\tif (res != TEE_SUCCESS)\n\t\t\treturn res;\n\t}\n\n\tcs = calloc(1, sizeof(struct tee_cryp_state));\n\tif (!cs)\n\t\treturn TEE_ERROR_OUT_OF_MEMORY;\n\tTAILQ_INSERT_TAIL(&utc->cryp_states, cs, link);\n\tcs->algo = algo;\n\tcs->mode = mode;\n\n\tswitch (TEE_ALG_GET_CLASS(algo)) {\n\tcase TEE_OPERATION_CIPHER:\n\t\tif ((algo == TEE_ALG_AES_XTS && (key1 == 0 || key2 == 0)) ||\n\t\t    (algo != TEE_ALG_AES_XTS && (key1 == 0 || key2 != 0))) {\n\t\t\tres = TEE_ERROR_BAD_PARAMETERS;\n\t\t} else {\n\t\t\tres = crypto_cipher_alloc_ctx(&cs->ctx, algo);\n\t\t\tif (res != TEE_SUCCESS)\n\t\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\tcase TEE_OPERATION_AE:\n\t\tif (key1 == 0 || key2 != 0) {\n\t\t\tres = TEE_ERROR_BAD_PARAMETERS;\n\t\t} else {\n//\t\t\tres = crypto_authenc_alloc_ctx(&cs->ctx, algo);\n//\t\t\tif (res != TEE_SUCCESS)\n//\t\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\tcase TEE_OPERATION_MAC:\n\t\tif (key1 == 0 || key2 != 0) {\n\t\t\tres = TEE_ERROR_BAD_PARAMETERS;\n\t\t} else {\n\t\t\tres = crypto_mac_alloc_ctx(&cs->ctx, algo);\n\t\t\tif (res != TEE_SUCCESS)\n\t\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\tcase TEE_OPERATION_DIGEST:\n\t\tif (key1 != 0 || key2 != 0) {\n\t\t\tres = TEE_ERROR_BAD_PARAMETERS;\n\t\t} else {\n\t\t\tres = crypto_hash_alloc_ctx(&cs->ctx, algo);\n\t\t\tif (res != TEE_SUCCESS)\n\t\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\tcase TEE_OPERATION_ASYMMETRIC_CIPHER:\n\tcase TEE_OPERATION_ASYMMETRIC_SIGNATURE:\n\t\tif (key1 == 0 || key2 != 0)\n\t\t\tres = TEE_ERROR_BAD_PARAMETERS;\n\t\tbreak;\n\tcase TEE_OPERATION_KEY_DERIVATION:\n\t\tif (key1 == 0 || key2 != 0)\n\t\t\tres = TEE_ERROR_BAD_PARAMETERS;\n\t\tbreak;\n\tdefault:\n\t\tres = TEE_ERROR_NOT_SUPPORTED;\n\t\tbreak;\n\t}\n\tif (res != TEE_SUCCESS)\n\t\tgoto out;\n\n\tres = tee_svc_copy_kaddr_to_uref(state, cs);\n\tif (res != TEE_SUCCESS)\n\t\tgoto out;\n\n\t/* Register keys */\n\tif (o1 != NULL) {\n\t\to1->busy = true;\n\t\tcs->key1 = (vaddr_t)o1;\n\t}\n\tif (o2 != NULL) {\n\t\to2->busy = true;\n\t\tcs->key2 = (vaddr_t)o2;\n\t}\n\nout:\n\tif (res != TEE_SUCCESS)\n\t\tcryp_state_free(utc, cs);\n\treturn res;\n}",
        "func": "TEE_Result utee_cryp_state_alloc(unsigned long algo, unsigned long mode,\n\t\t\tunsigned long key1, unsigned long key2,\n\t\t\tuint32_t *state)\n{\n\tTEE_Result res;\n\tstruct tee_cryp_state *cs;\n\tstruct tee_ta_session *sess;\n\tstruct tee_obj *o1 = NULL;\n\tstruct tee_obj *o2 = NULL;\n\tstruct user_ta_ctx *utc;\n\n\tres = tee_ta_get_current_session(&sess);\n\tif (res != TEE_SUCCESS)\n\t\treturn res;\n\tutc = to_user_ta_ctx(sess->ctx);\n\n\tif (key1 != 0) {\n\t\tres = tee_obj_get(utc, tee_svc_uref_to_vaddr(key1), &o1);\n\t\tif (res != TEE_SUCCESS)\n\t\t\treturn res;\n\t\tif (o1->busy)\n\t\t\treturn TEE_ERROR_BAD_PARAMETERS;\n\t\tres = tee_svc_cryp_check_key_type(o1, algo, mode);\n\t\tif (res != TEE_SUCCESS)\n\t\t\treturn res;\n\t}\n\tif (key2 != 0) {\n\t\tres = tee_obj_get(utc, tee_svc_uref_to_vaddr(key2), &o2);\n\t\tif (res != TEE_SUCCESS)\n\t\t\treturn res;\n\t\tif (o2->busy)\n\t\t\treturn TEE_ERROR_BAD_PARAMETERS;\n\t\tres = tee_svc_cryp_check_key_type(o2, algo, mode);\n\t\tif (res != TEE_SUCCESS)\n\t\t\treturn res;\n\t}\n\n\tcs = TEE_Malloc(sizeof(struct tee_cryp_state), TEE_MALLOC_FILL_ZERO);\n\t// cs = calloc(1, sizeof(struct tee_cryp_state));\n\tif (!cs)\n\t\treturn TEE_ERROR_OUT_OF_MEMORY;\n\tTAILQ_INSERT_TAIL(&utc->cryp_states, cs, link);\n\tcs->algo = algo;\n\tcs->mode = mode;\n\n\tswitch (TEE_ALG_GET_CLASS(algo)) {\n\tcase TEE_OPERATION_CIPHER:\n\t\tif ((algo == TEE_ALG_AES_XTS && (key1 == 0 || key2 == 0)) ||\n\t\t    (algo != TEE_ALG_AES_XTS && (key1 == 0 || key2 != 0))) {\n\t\t\tres = TEE_ERROR_BAD_PARAMETERS;\n\t\t} else {\n\t\t\tres = crypto_cipher_alloc_ctx(&cs->ctx, algo);\n\t\t\tif (res != TEE_SUCCESS)\n\t\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\tcase TEE_OPERATION_AE:\n\t\tif (key1 == 0 || key2 != 0) {\n\t\t\tres = TEE_ERROR_BAD_PARAMETERS;\n\t\t} else {\n//\t\t\tres = crypto_authenc_alloc_ctx(&cs->ctx, algo);\n//\t\t\tif (res != TEE_SUCCESS)\n//\t\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\tcase TEE_OPERATION_MAC:\n\t\tif (key1 == 0 || key2 != 0) {\n\t\t\tres = TEE_ERROR_BAD_PARAMETERS;\n\t\t} else {\n\t\t\tres = crypto_mac_alloc_ctx(&cs->ctx, algo);\n\t\t\tif (res != TEE_SUCCESS)\n\t\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\tcase TEE_OPERATION_DIGEST:\n\t\tif (key1 != 0 || key2 != 0) {\n\t\t\tres = TEE_ERROR_BAD_PARAMETERS;\n\t\t} else {\n\t\t\tres = crypto_hash_alloc_ctx(&cs->ctx, algo);\n\t\t\tif (res != TEE_SUCCESS)\n\t\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\tcase TEE_OPERATION_ASYMMETRIC_CIPHER:\n\tcase TEE_OPERATION_ASYMMETRIC_SIGNATURE:\n\t\tif (key1 == 0 || key2 != 0)\n\t\t\tres = TEE_ERROR_BAD_PARAMETERS;\n\t\tbreak;\n\tcase TEE_OPERATION_KEY_DERIVATION:\n\t\tif (key1 == 0 || key2 != 0)\n\t\t\tres = TEE_ERROR_BAD_PARAMETERS;\n\t\tbreak;\n\tdefault:\n\t\tres = TEE_ERROR_NOT_SUPPORTED;\n\t\tbreak;\n\t}\n\tif (res != TEE_SUCCESS)\n\t\tgoto out;\n\n\tres = tee_svc_copy_kaddr_to_uref(state, cs);\n\tif (res != TEE_SUCCESS)\n\t\tgoto out;\n\n\t/* Register keys */\n\tif (o1 != NULL) {\n\t\to1->busy = true;\n\t\tcs->key1 = (vaddr_t)o1;\n\t}\n\tif (o2 != NULL) {\n\t\to2->busy = true;\n\t\tcs->key2 = (vaddr_t)o2;\n\t}\n\nout:\n\tif (res != TEE_SUCCESS)\n\t\tcryp_state_free(utc, cs);\n\treturn res;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -35,7 +35,8 @@\n \t\t\treturn res;\n \t}\n \n-\tcs = calloc(1, sizeof(struct tee_cryp_state));\n+\tcs = TEE_Malloc(sizeof(struct tee_cryp_state), TEE_MALLOC_FILL_ZERO);\n+\t// cs = calloc(1, sizeof(struct tee_cryp_state));\n \tif (!cs)\n \t\treturn TEE_ERROR_OUT_OF_MEMORY;\n \tTAILQ_INSERT_TAIL(&utc->cryp_states, cs, link);",
        "diff_line_info": {
            "deleted_lines": [
                "\tcs = calloc(1, sizeof(struct tee_cryp_state));"
            ],
            "added_lines": [
                "\tcs = TEE_Malloc(sizeof(struct tee_cryp_state), TEE_MALLOC_FILL_ZERO);",
                "\t// cs = calloc(1, sizeof(struct tee_cryp_state));"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-40761",
        "func_name": "Samsung/mTower/tee_ta_init_pseudo_ta_session",
        "description": "The function tee_obj_free in Samsung mTower through 0.3.0 allows a trusted application to trigger a Denial of Service (DoS) by invoking the function TEE_AllocateOperation with a disturbed heap layout, related to utee_cryp_obj_alloc.",
        "git_url": "https://github.com/Samsung/mTower/commit/c5f30c70e48786e1aef8c815f35e406a6c4fb3ae",
        "commit_title": "Fixed CVE-2022-40761",
        "commit_text": "",
        "func_before": "TEE_Result tee_ta_init_pseudo_ta_session(const TEE_UUID *uuid,\n\t\t\tstruct tee_ta_session *s)\n{\n\tstruct pseudo_ta_ctx *stc = NULL;\n\tstruct tee_ta_ctx *ctx;\n\tconst struct pseudo_ta_head *ta;\n\n  DMSG(\"Lookup pseudo TA %pUl\", (void *)uuid);\n\n\tta = &__start_ta_head_section;\n\twhile (true) {\n\t\tif (ta >= &__stop_ta_head_section)\n\t\t\treturn TEE_ERROR_ITEM_NOT_FOUND;\n//    uuid_print(&ta->uuid);\n//    uuid_print(uuid);\n\t\tif (memcmp(&ta->uuid, uuid, sizeof(TEE_UUID)) == 0)\n\t\t\tbreak;\n\t\tta++;\n\t}\n\n\t/* Load a new TA and create a session */\n\tDMSG(\"Open %s\", ta->name);\n\tstc = calloc(1, sizeof(struct pseudo_ta_ctx));\n\tif (!stc)\n\t\treturn TEE_ERROR_OUT_OF_MEMORY;\n\tctx = &stc->ctx;\n\n//\tctx->ref_count = 1;\n\ts->ctx = ctx;\n\tctx->flags = ta->flags;\n\tstc->pseudo_ta = ta;\n\tctx->uuid = ta->uuid;\n\tctx->ops = &pseudo_ta_ops;\n\tTAILQ_INSERT_TAIL(&tee_ctxes, ctx, link);\n\n\tDMSG(\"%s : %pUl\", stc->pseudo_ta->name, (void *)&ctx->uuid);\n\n\treturn TEE_SUCCESS;\n}",
        "func": "TEE_Result tee_ta_init_pseudo_ta_session(const TEE_UUID *uuid,\n\t\t\tstruct tee_ta_session *s)\n{\n\tstruct pseudo_ta_ctx *stc = NULL;\n\tstruct tee_ta_ctx *ctx;\n\tconst struct pseudo_ta_head *ta;\n\n  DMSG(\"Lookup pseudo TA %pUl\", (void *)uuid);\n\n\tta = &__start_ta_head_section;\n\twhile (true) {\n\t\tif (ta >= &__stop_ta_head_section)\n\t\t\treturn TEE_ERROR_ITEM_NOT_FOUND;\n//    uuid_print(&ta->uuid);\n//    uuid_print(uuid);\n\t\tif (memcmp(&ta->uuid, uuid, sizeof(TEE_UUID)) == 0)\n\t\t\tbreak;\n\t\tta++;\n\t}\n\n\t/* Load a new TA and create a session */\n\tDMSG(\"Open %s\", ta->name);\n\t// stc = calloc(1, sizeof(struct pseudo_ta_ctx));\n\tstc = TEE_Malloc(sizeof(struct pseudo_ta_ctx), TEE_MALLOC_FILL_ZERO);\n\tif (!stc)\n\t\treturn TEE_ERROR_OUT_OF_MEMORY;\n\tctx = &stc->ctx;\n\n//\tctx->ref_count = 1;\n\ts->ctx = ctx;\n\tctx->flags = ta->flags;\n\tstc->pseudo_ta = ta;\n\tctx->uuid = ta->uuid;\n\tctx->ops = &pseudo_ta_ops;\n\tTAILQ_INSERT_TAIL(&tee_ctxes, ctx, link);\n\n\tDMSG(\"%s : %pUl\", stc->pseudo_ta->name, (void *)&ctx->uuid);\n\n\treturn TEE_SUCCESS;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -20,7 +20,8 @@\n \n \t/* Load a new TA and create a session */\n \tDMSG(\"Open %s\", ta->name);\n-\tstc = calloc(1, sizeof(struct pseudo_ta_ctx));\n+\t// stc = calloc(1, sizeof(struct pseudo_ta_ctx));\n+\tstc = TEE_Malloc(sizeof(struct pseudo_ta_ctx), TEE_MALLOC_FILL_ZERO);\n \tif (!stc)\n \t\treturn TEE_ERROR_OUT_OF_MEMORY;\n \tctx = &stc->ctx;",
        "diff_line_info": {
            "deleted_lines": [
                "\tstc = calloc(1, sizeof(struct pseudo_ta_ctx));"
            ],
            "added_lines": [
                "\t// stc = calloc(1, sizeof(struct pseudo_ta_ctx));",
                "\tstc = TEE_Malloc(sizeof(struct pseudo_ta_ctx), TEE_MALLOC_FILL_ZERO);"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-40761",
        "func_name": "Samsung/mTower/crypto_aes_ccm_alloc_ctx",
        "description": "The function tee_obj_free in Samsung mTower through 0.3.0 allows a trusted application to trigger a Denial of Service (DoS) by invoking the function TEE_AllocateOperation with a disturbed heap layout, related to utee_cryp_obj_alloc.",
        "git_url": "https://github.com/Samsung/mTower/commit/c5f30c70e48786e1aef8c815f35e406a6c4fb3ae",
        "commit_title": "Fixed CVE-2022-40761",
        "commit_text": "",
        "func_before": "TEE_Result crypto_aes_ccm_alloc_ctx(void **ctx_ret)\n{\n\tstruct tee_ccm_state *ctx = calloc(1, sizeof(*ctx));\n\n\tif (!ctx)\n\t\treturn TEE_ERROR_OUT_OF_MEMORY;\n\n\t*ctx_ret = ctx;\n\treturn TEE_SUCCESS;\n}",
        "func": "TEE_Result crypto_aes_ccm_alloc_ctx(void **ctx_ret)\n{\n\tstruct tee_ccm_state *ctx = TEE_Malloc(sizeof(*ctx), TEE_MALLOC_FILL_ZERO);\n\t// struct tee_ccm_state *ctx = calloc(1, sizeof(*ctx));\n\n\tif (!ctx)\n\t\treturn TEE_ERROR_OUT_OF_MEMORY;\n\n\t*ctx_ret = ctx;\n\treturn TEE_SUCCESS;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,7 @@\n TEE_Result crypto_aes_ccm_alloc_ctx(void **ctx_ret)\n {\n-\tstruct tee_ccm_state *ctx = calloc(1, sizeof(*ctx));\n+\tstruct tee_ccm_state *ctx = TEE_Malloc(sizeof(*ctx), TEE_MALLOC_FILL_ZERO);\n+\t// struct tee_ccm_state *ctx = calloc(1, sizeof(*ctx));\n \n \tif (!ctx)\n \t\treturn TEE_ERROR_OUT_OF_MEMORY;",
        "diff_line_info": {
            "deleted_lines": [
                "\tstruct tee_ccm_state *ctx = calloc(1, sizeof(*ctx));"
            ],
            "added_lines": [
                "\tstruct tee_ccm_state *ctx = TEE_Malloc(sizeof(*ctx), TEE_MALLOC_FILL_ZERO);",
                "\t// struct tee_ccm_state *ctx = calloc(1, sizeof(*ctx));"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-40761",
        "func_name": "Samsung/mTower/crypto_hash_alloc_ctx",
        "description": "The function tee_obj_free in Samsung mTower through 0.3.0 allows a trusted application to trigger a Denial of Service (DoS) by invoking the function TEE_AllocateOperation with a disturbed heap layout, related to utee_cryp_obj_alloc.",
        "git_url": "https://github.com/Samsung/mTower/commit/c5f30c70e48786e1aef8c815f35e406a6c4fb3ae",
        "commit_title": "Fixed CVE-2022-40761",
        "commit_text": "",
        "func_before": "TEE_Result crypto_hash_alloc_ctx(void **ctx_ret, uint32_t algo)\n{\n\tTEE_Result res;\n\tsize_t ctx_size;\n\tvoid *ctx;\n\n\tres = hash_get_ctx_size(algo, &ctx_size);\n\tif (res)\n\t\treturn res;\n\n\tctx = calloc(1, ctx_size);\n\tif (!ctx)\n\t\treturn TEE_ERROR_OUT_OF_MEMORY;\n\n\t*ctx_ret = ctx;\n\treturn TEE_SUCCESS;\n}",
        "func": "TEE_Result crypto_hash_alloc_ctx(void **ctx_ret, uint32_t algo)\n{\n\tTEE_Result res;\n\tsize_t ctx_size;\n\tvoid *ctx;\n\n\tres = hash_get_ctx_size(algo, &ctx_size);\n\tif (res)\n\t\treturn res;\n\n\tctx = TEE_Malloc(ctx_size, TEE_MALLOC_FILL_ZERO);\n\t// ctx = calloc(1, ctx_size);\n\tif (!ctx)\n\t\treturn TEE_ERROR_OUT_OF_MEMORY;\n\n\t*ctx_ret = ctx;\n\treturn TEE_SUCCESS;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -8,7 +8,8 @@\n \tif (res)\n \t\treturn res;\n \n-\tctx = calloc(1, ctx_size);\n+\tctx = TEE_Malloc(ctx_size, TEE_MALLOC_FILL_ZERO);\n+\t// ctx = calloc(1, ctx_size);\n \tif (!ctx)\n \t\treturn TEE_ERROR_OUT_OF_MEMORY;\n ",
        "diff_line_info": {
            "deleted_lines": [
                "\tctx = calloc(1, ctx_size);"
            ],
            "added_lines": [
                "\tctx = TEE_Malloc(ctx_size, TEE_MALLOC_FILL_ZERO);",
                "\t// ctx = calloc(1, ctx_size);"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-40761",
        "func_name": "Samsung/mTower/crypto_aes_gcm_alloc_ctx",
        "description": "The function tee_obj_free in Samsung mTower through 0.3.0 allows a trusted application to trigger a Denial of Service (DoS) by invoking the function TEE_AllocateOperation with a disturbed heap layout, related to utee_cryp_obj_alloc.",
        "git_url": "https://github.com/Samsung/mTower/commit/c5f30c70e48786e1aef8c815f35e406a6c4fb3ae",
        "commit_title": "Fixed CVE-2022-40761",
        "commit_text": "",
        "func_before": "TEE_Result crypto_aes_gcm_alloc_ctx(void **ctx_ret)\n{\n\tstruct tee_gcm_state *ctx = calloc(1, sizeof(*ctx));\n\n\tif (!ctx)\n\t\treturn TEE_ERROR_OUT_OF_MEMORY;\n\n\t*ctx_ret = ctx;\n\treturn TEE_SUCCESS;\n}",
        "func": "TEE_Result crypto_aes_gcm_alloc_ctx(void **ctx_ret)\n{\n\tstruct tee_gcm_state *ctx =  TEE_Malloc(sizeof(*ctx), TEE_MALLOC_FILL_ZERO);\n\t// struct tee_gcm_state *ctx = calloc(1, sizeof(*ctx));\n\n\tif (!ctx)\n\t\treturn TEE_ERROR_OUT_OF_MEMORY;\n\n\t*ctx_ret = ctx;\n\treturn TEE_SUCCESS;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,7 @@\n TEE_Result crypto_aes_gcm_alloc_ctx(void **ctx_ret)\n {\n-\tstruct tee_gcm_state *ctx = calloc(1, sizeof(*ctx));\n+\tstruct tee_gcm_state *ctx =  TEE_Malloc(sizeof(*ctx), TEE_MALLOC_FILL_ZERO);\n+\t// struct tee_gcm_state *ctx = calloc(1, sizeof(*ctx));\n \n \tif (!ctx)\n \t\treturn TEE_ERROR_OUT_OF_MEMORY;",
        "diff_line_info": {
            "deleted_lines": [
                "\tstruct tee_gcm_state *ctx = calloc(1, sizeof(*ctx));"
            ],
            "added_lines": [
                "\tstruct tee_gcm_state *ctx =  TEE_Malloc(sizeof(*ctx), TEE_MALLOC_FILL_ZERO);",
                "\t// struct tee_gcm_state *ctx = calloc(1, sizeof(*ctx));"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-40761",
        "func_name": "Samsung/mTower/crypto_bignum_allocate",
        "description": "The function tee_obj_free in Samsung mTower through 0.3.0 allows a trusted application to trigger a Denial of Service (DoS) by invoking the function TEE_AllocateOperation with a disturbed heap layout, related to utee_cryp_obj_alloc.",
        "git_url": "https://github.com/Samsung/mTower/commit/c5f30c70e48786e1aef8c815f35e406a6c4fb3ae",
        "commit_title": "Fixed CVE-2022-40761",
        "commit_text": "",
        "func_before": "struct bignum *crypto_bignum_allocate(size_t size_bits)\n{\n\tsize_t sz = mpa_StaticVarSizeInU32(size_bits) *\tsizeof(uint32_t);\n\tstruct mpa_numbase_struct *bn = calloc(1, sz);\n\n\tif (!bn)\n\t\treturn NULL;\n\tbn->alloc = sz - MPA_NUMBASE_METADATA_SIZE_IN_U32 * sizeof(uint32_t);\n\treturn (struct bignum *)bn;\n}",
        "func": "struct bignum *crypto_bignum_allocate(size_t size_bits)\n{\n\tsize_t sz = mpa_StaticVarSizeInU32(size_bits) *\tsizeof(uint32_t);\n\t// struct mpa_numbase_struct *bn = calloc(1, sz);\n\tstruct mpa_numbase_struct *bn= TEE_Malloc(sz, TEE_MALLOC_FILL_ZERO);\n\tif (!bn)\n\t\treturn NULL;\n\tbn->alloc = sz - MPA_NUMBASE_METADATA_SIZE_IN_U32 * sizeof(uint32_t);\n\treturn (struct bignum *)bn;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,8 +1,8 @@\n struct bignum *crypto_bignum_allocate(size_t size_bits)\n {\n \tsize_t sz = mpa_StaticVarSizeInU32(size_bits) *\tsizeof(uint32_t);\n-\tstruct mpa_numbase_struct *bn = calloc(1, sz);\n-\n+\t// struct mpa_numbase_struct *bn = calloc(1, sz);\n+\tstruct mpa_numbase_struct *bn= TEE_Malloc(sz, TEE_MALLOC_FILL_ZERO);\n \tif (!bn)\n \t\treturn NULL;\n \tbn->alloc = sz - MPA_NUMBASE_METADATA_SIZE_IN_U32 * sizeof(uint32_t);",
        "diff_line_info": {
            "deleted_lines": [
                "\tstruct mpa_numbase_struct *bn = calloc(1, sz);",
                ""
            ],
            "added_lines": [
                "\t// struct mpa_numbase_struct *bn = calloc(1, sz);",
                "\tstruct mpa_numbase_struct *bn= TEE_Malloc(sz, TEE_MALLOC_FILL_ZERO);"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-40761",
        "func_name": "Samsung/mTower/crypto_cipher_alloc_ctx",
        "description": "The function tee_obj_free in Samsung mTower through 0.3.0 allows a trusted application to trigger a Denial of Service (DoS) by invoking the function TEE_AllocateOperation with a disturbed heap layout, related to utee_cryp_obj_alloc.",
        "git_url": "https://github.com/Samsung/mTower/commit/c5f30c70e48786e1aef8c815f35e406a6c4fb3ae",
        "commit_title": "Fixed CVE-2022-40761",
        "commit_text": "",
        "func_before": "TEE_Result crypto_cipher_alloc_ctx(void **ctx_ret, uint32_t algo)\n{\n\tTEE_Result res;\n\tsize_t ctx_size;\n\tvoid *ctx;\n\n\tres = cipher_get_ctx_size(algo, &ctx_size);\n\n\tif (res)\n\t\treturn res;\n\n\tctx = calloc(1, ctx_size);\n\tif (!ctx)\n\t\treturn TEE_ERROR_OUT_OF_MEMORY;\n\n\t*ctx_ret = ctx;\n\treturn TEE_SUCCESS;\n}",
        "func": "TEE_Result crypto_cipher_alloc_ctx(void **ctx_ret, uint32_t algo)\n{\n\tTEE_Result res;\n\tsize_t ctx_size;\n\tvoid *ctx;\n\n\tres = cipher_get_ctx_size(algo, &ctx_size);\n\n\tif (res)\n\t\treturn res;\n\n\t// ctx = calloc(1, ctx_size);\n\tctx = TEE_Malloc(ctx_size, TEE_MALLOC_FILL_ZERO);\n\tif (!ctx)\n\t\treturn TEE_ERROR_OUT_OF_MEMORY;\n\n\t*ctx_ret = ctx;\n\treturn TEE_SUCCESS;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -9,7 +9,8 @@\n \tif (res)\n \t\treturn res;\n \n-\tctx = calloc(1, ctx_size);\n+\t// ctx = calloc(1, ctx_size);\n+\tctx = TEE_Malloc(ctx_size, TEE_MALLOC_FILL_ZERO);\n \tif (!ctx)\n \t\treturn TEE_ERROR_OUT_OF_MEMORY;\n ",
        "diff_line_info": {
            "deleted_lines": [
                "\tctx = calloc(1, ctx_size);"
            ],
            "added_lines": [
                "\t// ctx = calloc(1, ctx_size);",
                "\tctx = TEE_Malloc(ctx_size, TEE_MALLOC_FILL_ZERO);"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-40761",
        "func_name": "Samsung/mTower/crypto_mac_alloc_ctx",
        "description": "The function tee_obj_free in Samsung mTower through 0.3.0 allows a trusted application to trigger a Denial of Service (DoS) by invoking the function TEE_AllocateOperation with a disturbed heap layout, related to utee_cryp_obj_alloc.",
        "git_url": "https://github.com/Samsung/mTower/commit/c5f30c70e48786e1aef8c815f35e406a6c4fb3ae",
        "commit_title": "Fixed CVE-2022-40761",
        "commit_text": "",
        "func_before": "TEE_Result crypto_mac_alloc_ctx(void **ctx_ret, uint32_t algo)\n{\n\tTEE_Result res;\n\tsize_t ctx_size;\n\tvoid *ctx;\n\n\tres = mac_get_ctx_size(algo, &ctx_size);\n\tif (res)\n\t\treturn res;\n\n\tctx = calloc(1, ctx_size);\n\tif (!ctx)\n\t\treturn TEE_ERROR_OUT_OF_MEMORY;\n\n\t*ctx_ret = ctx;\n\treturn TEE_SUCCESS;\n}",
        "func": "TEE_Result crypto_mac_alloc_ctx(void **ctx_ret, uint32_t algo)\n{\n\tTEE_Result res;\n\tsize_t ctx_size;\n\tvoid *ctx;\n\n\tres = mac_get_ctx_size(algo, &ctx_size);\n\tif (res)\n\t\treturn res;\n\tctx = TEE_Malloc(ctx_size, TEE_MALLOC_FILL_ZERO);\n\t// ctx = calloc(1, ctx_size);\n\tif (!ctx)\n\t\treturn TEE_ERROR_OUT_OF_MEMORY;\n\n\t*ctx_ret = ctx;\n\treturn TEE_SUCCESS;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -7,8 +7,8 @@\n \tres = mac_get_ctx_size(algo, &ctx_size);\n \tif (res)\n \t\treturn res;\n-\n-\tctx = calloc(1, ctx_size);\n+\tctx = TEE_Malloc(ctx_size, TEE_MALLOC_FILL_ZERO);\n+\t// ctx = calloc(1, ctx_size);\n \tif (!ctx)\n \t\treturn TEE_ERROR_OUT_OF_MEMORY;\n ",
        "diff_line_info": {
            "deleted_lines": [
                "",
                "\tctx = calloc(1, ctx_size);"
            ],
            "added_lines": [
                "\tctx = TEE_Malloc(ctx_size, TEE_MALLOC_FILL_ZERO);",
                "\t// ctx = calloc(1, ctx_size);"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-40761",
        "func_name": "Samsung/mTower/tee_pobj_get",
        "description": "The function tee_obj_free in Samsung mTower through 0.3.0 allows a trusted application to trigger a Denial of Service (DoS) by invoking the function TEE_AllocateOperation with a disturbed heap layout, related to utee_cryp_obj_alloc.",
        "git_url": "https://github.com/Samsung/mTower/commit/c5f30c70e48786e1aef8c815f35e406a6c4fb3ae",
        "commit_title": "Fixed CVE-2022-40761",
        "commit_text": "",
        "func_before": "TEE_Result tee_pobj_get(TEE_UUID *uuid, void *obj_id, uint32_t obj_id_len,\n\t\t\tuint32_t flags, bool temporary,\n\t\t\tconst struct tee_file_operations *fops,\n\t\t\tstruct tee_pobj **obj)\n{\n\tstruct tee_pobj *o;\n\tTEE_Result res;\n\n\t*obj = NULL;\n\n//\tmutex_lock(&pobjs_mutex);\n\t/* Check if file is open */\n\tTAILQ_FOREACH(o, &tee_pobjs, link) {\n\t\tif ((obj_id_len == o->obj_id_len) &&\n\t\t    (memcmp(obj_id, o->obj_id, obj_id_len) == 0) &&\n\t\t    (memcmp(uuid, &o->uuid, sizeof(TEE_UUID)) == 0) &&\n\t\t    (fops == o->fops)) {\n\t\t\t*obj = o;\n\t\t}\n\t}\n\n\tif (*obj) {\n\t\tif (temporary != (*obj)->temporary) {\n\t\t\tres = TEE_ERROR_ACCESS_CONFLICT;\n\t\t\tgoto out;\n\t\t}\n\t\tres = tee_pobj_check_access((*obj)->flags, flags);\n\t\tif (res == TEE_SUCCESS)\n\t\t\t(*obj)->refcnt++;\n\t\tgoto out;\n\t}\n\n\t/* new file */\n\to = calloc(1, sizeof(struct tee_pobj));\n\tif (!o) {\n\t\tres = TEE_ERROR_OUT_OF_MEMORY;\n\t\tgoto out;\n\t}\n\n\to->refcnt = 1;\n\tmemcpy(&o->uuid, uuid, sizeof(TEE_UUID));\n\to->flags = flags;\n\to->fops = fops;\n\to->temporary = temporary;\n\n\to->obj_id = malloc(obj_id_len);\n\tif (o->obj_id == NULL) {\n\t\tfree(o);\n\t\tres = TEE_ERROR_OUT_OF_MEMORY;\n\t\tgoto out;\n\t}\n\tmemcpy(o->obj_id, obj_id, obj_id_len);\n\to->obj_id_len = obj_id_len;\n\n\tTAILQ_INSERT_TAIL(&tee_pobjs, o, link);\n\t*obj = o;\n\n\tres = TEE_SUCCESS;\nout:\n\tif (res != TEE_SUCCESS)\n\t\t*obj = NULL;\n//\tmutex_unlock(&pobjs_mutex);\n\treturn res;\n}",
        "func": "TEE_Result tee_pobj_get(TEE_UUID *uuid, void *obj_id, uint32_t obj_id_len,\n\t\t\tuint32_t flags, bool temporary,\n\t\t\tconst struct tee_file_operations *fops,\n\t\t\tstruct tee_pobj **obj)\n{\n\tstruct tee_pobj *o;\n\tTEE_Result res;\n\n\t*obj = NULL;\n\n//\tmutex_lock(&pobjs_mutex);\n\t/* Check if file is open */\n\tTAILQ_FOREACH(o, &tee_pobjs, link) {\n\t\tif ((obj_id_len == o->obj_id_len) &&\n\t\t    (memcmp(obj_id, o->obj_id, obj_id_len) == 0) &&\n\t\t    (memcmp(uuid, &o->uuid, sizeof(TEE_UUID)) == 0) &&\n\t\t    (fops == o->fops)) {\n\t\t\t*obj = o;\n\t\t}\n\t}\n\n\tif (*obj) {\n\t\tif (temporary != (*obj)->temporary) {\n\t\t\tres = TEE_ERROR_ACCESS_CONFLICT;\n\t\t\tgoto out;\n\t\t}\n\t\tres = tee_pobj_check_access((*obj)->flags, flags);\n\t\tif (res == TEE_SUCCESS)\n\t\t\t(*obj)->refcnt++;\n\t\tgoto out;\n\t}\n\n\t/* new file */\n\to = TEE_Malloc(sizeof(struct tee_pobj), TEE_MALLOC_FILL_ZERO);\n\t// o = calloc(1, sizeof(struct tee_pobj));\n\tif (!o) {\n\t\tres = TEE_ERROR_OUT_OF_MEMORY;\n\t\tgoto out;\n\t}\n\n\to->refcnt = 1;\n\tmemcpy(&o->uuid, uuid, sizeof(TEE_UUID));\n\to->flags = flags;\n\to->fops = fops;\n\to->temporary = temporary;\n\n\to->obj_id = malloc(obj_id_len);\n\tif (o->obj_id == NULL) {\n\t\tfree(o);\n\t\tres = TEE_ERROR_OUT_OF_MEMORY;\n\t\tgoto out;\n\t}\n\tmemcpy(o->obj_id, obj_id, obj_id_len);\n\to->obj_id_len = obj_id_len;\n\n\tTAILQ_INSERT_TAIL(&tee_pobjs, o, link);\n\t*obj = o;\n\n\tres = TEE_SUCCESS;\nout:\n\tif (res != TEE_SUCCESS)\n\t\t*obj = NULL;\n//\tmutex_unlock(&pobjs_mutex);\n\treturn res;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -31,7 +31,8 @@\n \t}\n \n \t/* new file */\n-\to = calloc(1, sizeof(struct tee_pobj));\n+\to = TEE_Malloc(sizeof(struct tee_pobj), TEE_MALLOC_FILL_ZERO);\n+\t// o = calloc(1, sizeof(struct tee_pobj));\n \tif (!o) {\n \t\tres = TEE_ERROR_OUT_OF_MEMORY;\n \t\tgoto out;",
        "diff_line_info": {
            "deleted_lines": [
                "\to = calloc(1, sizeof(struct tee_pobj));"
            ],
            "added_lines": [
                "\to = TEE_Malloc(sizeof(struct tee_pobj), TEE_MALLOC_FILL_ZERO);",
                "\t// o = calloc(1, sizeof(struct tee_pobj));"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-40761",
        "func_name": "Samsung/mTower/tee_ta_init_session",
        "description": "The function tee_obj_free in Samsung mTower through 0.3.0 allows a trusted application to trigger a Denial of Service (DoS) by invoking the function TEE_AllocateOperation with a disturbed heap layout, related to utee_cryp_obj_alloc.",
        "git_url": "https://github.com/Samsung/mTower/commit/c5f30c70e48786e1aef8c815f35e406a6c4fb3ae",
        "commit_title": "Fixed CVE-2022-40761",
        "commit_text": "",
        "func_before": "static TEE_Result tee_ta_init_session(TEE_ErrorOrigin *err,\n\t\t\t\tstruct tee_ta_session_head *open_sessions,\n\t\t\t\tconst TEE_UUID *uuid,\n\t\t\t\tstruct tee_ta_session **sess)\n{\n\tTEE_Result res;\n//\tstruct tee_ta_ctx *ctx;\n//  struct tee_ta_session *s = calloc(1, sizeof(struct tee_ta_session));\n  struct tee_ta_session *s = malloc(sizeof(struct tee_ta_session));\n  *err = TEE_ORIGIN_TEE;\n  if (!s)\n    return TEE_ERROR_OUT_OF_MEMORY;\n\n  memset(s,0,sizeof(struct tee_ta_session));\n\n//\n//\ts->cancel_mask = true;\n//\tcondvar_init(&s->refc_cv);\n//\tcondvar_init(&s->lock_cv);\n//\ts->lock_thread = THREAD_ID_INVALID;\n//\ts->ref_count = 1;\n//\n//\n//\t/*\n//\t * We take the global TA mutex here and hold it while doing\n//\t * RPC to load the TA. This big critical section should be broken\n//\t * down into smaller pieces.\n//\t */\n//\n//\n//\tmutex_lock(&tee_ta_mutex);\n\tTAILQ_INSERT_TAIL(open_sessions, s, link);\n\n\t/* Look for already loaded TA */\n//\tctx = tee_ta_context_find(uuid);\n//\tif (ctx) {\n//\t\tres = tee_ta_init_session_with_context(ctx, s);\n//\t\tif (res == TEE_SUCCESS || res != TEE_ERROR_ITEM_NOT_FOUND)\n//\t\t\tgoto out;\n//\t}\n\n\t/* Look for static TA */\n\tres = tee_ta_init_pseudo_ta_session(uuid, s);\n\tif (res == TEE_SUCCESS || res != TEE_ERROR_ITEM_NOT_FOUND)\n\t\tgoto out;\n\n\t/* Look for user TA */\n\tres = tee_ta_init_user_ta_session(uuid, s);\n\nout:\n\tif (res == TEE_SUCCESS) {\n\t\t*sess = s;\n\t} else {\n\t\tTAILQ_REMOVE(open_sessions, s, link);\n\t\tfree(s);\n\t}\n//\tmutex_unlock(&tee_ta_mutex);\n\treturn res;\n}",
        "func": "static TEE_Result tee_ta_init_session(TEE_ErrorOrigin *err,\n\t\t\t\tstruct tee_ta_session_head *open_sessions,\n\t\t\t\tconst TEE_UUID *uuid,\n\t\t\t\tstruct tee_ta_session **sess)\n{\n\tTEE_Result res;\n//\tstruct tee_ta_ctx *ctx;\n//  struct tee_ta_session *s = calloc(1, sizeof(struct tee_ta_session));\n\n// TEE_Malloc(sizeof(struct pseudo_ta_ctx), TEE_MALLOC_FILL_ZERO);\n//   struct tee_ta_session *s = malloc(sizeof(struct tee_ta_session));\n  struct tee_ta_session *s = TEE_Malloc(sizeof(struct tee_ta_session), TEE_MALLOC_FILL_ZERO);\n  *err = TEE_ORIGIN_TEE;\n  if (!s)\n    return TEE_ERROR_OUT_OF_MEMORY;\n\n  memset(s,0,sizeof(struct tee_ta_session));\n\n//\n//\ts->cancel_mask = true;\n//\tcondvar_init(&s->refc_cv);\n//\tcondvar_init(&s->lock_cv);\n//\ts->lock_thread = THREAD_ID_INVALID;\n//\ts->ref_count = 1;\n//\n//\n//\t/*\n//\t * We take the global TA mutex here and hold it while doing\n//\t * RPC to load the TA. This big critical section should be broken\n//\t * down into smaller pieces.\n//\t */\n//\n//\n//\tmutex_lock(&tee_ta_mutex);\n\tTAILQ_INSERT_TAIL(open_sessions, s, link);\n\n\t/* Look for already loaded TA */\n//\tctx = tee_ta_context_find(uuid);\n//\tif (ctx) {\n//\t\tres = tee_ta_init_session_with_context(ctx, s);\n//\t\tif (res == TEE_SUCCESS || res != TEE_ERROR_ITEM_NOT_FOUND)\n//\t\t\tgoto out;\n//\t}\n\n\t/* Look for static TA */\n\tres = tee_ta_init_pseudo_ta_session(uuid, s);\n\tif (res == TEE_SUCCESS || res != TEE_ERROR_ITEM_NOT_FOUND)\n\t\tgoto out;\n\n\t/* Look for user TA */\n\tres = tee_ta_init_user_ta_session(uuid, s);\n\nout:\n\tif (res == TEE_SUCCESS) {\n\t\t*sess = s;\n\t} else {\n\t\tTAILQ_REMOVE(open_sessions, s, link);\n\t\tfree(s);\n\t}\n//\tmutex_unlock(&tee_ta_mutex);\n\treturn res;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -6,7 +6,10 @@\n \tTEE_Result res;\n //\tstruct tee_ta_ctx *ctx;\n //  struct tee_ta_session *s = calloc(1, sizeof(struct tee_ta_session));\n-  struct tee_ta_session *s = malloc(sizeof(struct tee_ta_session));\n+\n+// TEE_Malloc(sizeof(struct pseudo_ta_ctx), TEE_MALLOC_FILL_ZERO);\n+//   struct tee_ta_session *s = malloc(sizeof(struct tee_ta_session));\n+  struct tee_ta_session *s = TEE_Malloc(sizeof(struct tee_ta_session), TEE_MALLOC_FILL_ZERO);\n   *err = TEE_ORIGIN_TEE;\n   if (!s)\n     return TEE_ERROR_OUT_OF_MEMORY;",
        "diff_line_info": {
            "deleted_lines": [
                "  struct tee_ta_session *s = malloc(sizeof(struct tee_ta_session));"
            ],
            "added_lines": [
                "",
                "// TEE_Malloc(sizeof(struct pseudo_ta_ctx), TEE_MALLOC_FILL_ZERO);",
                "//   struct tee_ta_session *s = malloc(sizeof(struct tee_ta_session));",
                "  struct tee_ta_session *s = TEE_Malloc(sizeof(struct tee_ta_session), TEE_MALLOC_FILL_ZERO);"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-40761",
        "func_name": "Samsung/mTower/tee_ta_init_user_ta_session",
        "description": "The function tee_obj_free in Samsung mTower through 0.3.0 allows a trusted application to trigger a Denial of Service (DoS) by invoking the function TEE_AllocateOperation with a disturbed heap layout, related to utee_cryp_obj_alloc.",
        "git_url": "https://github.com/Samsung/mTower/commit/c5f30c70e48786e1aef8c815f35e406a6c4fb3ae",
        "commit_title": "Fixed CVE-2022-40761",
        "commit_text": "",
        "func_before": "TEE_Result tee_ta_init_user_ta_session(const TEE_UUID *uuid,\n\t\t\tstruct tee_ta_session *s)\n{\n//\tconst struct user_ta_store_ops *store;\n\tTEE_Result res;\n\n  struct user_ta_ctx *utc = NULL;\n  struct user_ta_head *ta_head;\n//  struct user_ta_store_handle *ta_handle = NULL;\n\n//  res = ta_store->open(uuid, &ta_handle);\n//  if (res != TEE_SUCCESS)\n//    return res;\n\n  DMSG(\"Lookup user TA %pUl\", (void *)uuid);\n\n  ta_head = (struct user_ta_head *)&__start_user_ta_head_section;\n  while (true) {\n    if (ta_head >= &__stop_user_ta_head_section)\n      return TEE_ERROR_ITEM_NOT_FOUND;\n\n//    uuid_print(&ta_head->uuid);\n//    uuid_print(uuid);\n\n    if (memcmp(&ta_head->uuid, uuid, sizeof(TEE_UUID)) == 0)\n      break;\n    ta_head++;\n  }\n\n  /* Load a new TA and create a session */\n  DMSG(\"Open %s\", ta_head->name);\n\n  /* Register context */\n  utc = calloc(1, sizeof(struct user_ta_ctx));\n  if (!utc) {\n    res = TEE_ERROR_OUT_OF_MEMORY;\n    goto error_return;\n  }\n\n  TAILQ_INIT(&utc->open_sessions);\n  TAILQ_INIT(&utc->cryp_states);\n  TAILQ_INIT(&utc->objects);\n  //TAILQ_INIT(&utc->storage_enums);\n  s->ctx = &utc->ctx;\n\n  utc->ctx.flags = ta_head->flags;\n  utc->ctx.uuid = ta_head->uuid;\n  utc->user_ta = ta_head;\n//  utc->entry_func = ta_head->entry.ptr64;\n  utc->ctx.ops = &user_ta_ops;\n\n  TAILQ_INSERT_TAIL(&tee_ctxes, &utc->ctx, link);\n\n  DMSG(\"Context was successfully inserted!\");\n\n  return TEE_SUCCESS;\n\n//  DMSG(\"%s : %pUl\", stc->pseudo_ta->name, (void *)&ctx->uuid);\n\n//\tSLIST_FOREACH(store, &uta_store_list, link) {\n//\t\tDMSG(\"Lookup user TA %pUl (%s)\", (void *)uuid,\n//\t\t     store->description);\n//\t\tres = ta_load(uuid, store, &s->ctx);\n//\t\tif (res == TEE_ERROR_ITEM_NOT_FOUND)\n//\t\t\tcontinue;\n//\t\tif (res == TEE_SUCCESS)\n//\t\t\ts->ctx->ops = &user_ta_ops;\n//\t\telse\n//\t\t\tDMSG(\"res=0x%x\", res);\n//\t\treturn res;\n//\t}\nerror_return:\n\treturn res;\n}",
        "func": "TEE_Result tee_ta_init_user_ta_session(const TEE_UUID *uuid,\n\t\t\tstruct tee_ta_session *s)\n{\n//\tconst struct user_ta_store_ops *store;\n\tTEE_Result res;\n\n  struct user_ta_ctx *utc = NULL;\n  struct user_ta_head *ta_head;\n//  struct user_ta_store_handle *ta_handle = NULL;\n\n//  res = ta_store->open(uuid, &ta_handle);\n//  if (res != TEE_SUCCESS)\n//    return res;\n\n  DMSG(\"Lookup user TA %pUl\", (void *)uuid);\n\n  ta_head = (struct user_ta_head *)&__start_user_ta_head_section;\n  while (true) {\n    if (ta_head >= &__stop_user_ta_head_section)\n      return TEE_ERROR_ITEM_NOT_FOUND;\n\n//    uuid_print(&ta_head->uuid);\n//    uuid_print(uuid);\n\n    if (memcmp(&ta_head->uuid, uuid, sizeof(TEE_UUID)) == 0)\n      break;\n    ta_head++;\n  }\n\n  /* Load a new TA and create a session */\n  DMSG(\"Open %s\", ta_head->name);\n\n  /* Register context */\n  // utc = calloc(1, sizeof(struct user_ta_ctx));\n  utc = TEE_Malloc(sizeof(struct user_ta_ctx), TEE_MALLOC_FILL_ZERO);\n  if (!utc) {\n    res = TEE_ERROR_OUT_OF_MEMORY;\n    goto error_return;\n  }\n\n  TAILQ_INIT(&utc->open_sessions);\n  TAILQ_INIT(&utc->cryp_states);\n  TAILQ_INIT(&utc->objects);\n  //TAILQ_INIT(&utc->storage_enums);\n  s->ctx = &utc->ctx;\n\n  utc->ctx.flags = ta_head->flags;\n  utc->ctx.uuid = ta_head->uuid;\n  utc->user_ta = ta_head;\n//  utc->entry_func = ta_head->entry.ptr64;\n  utc->ctx.ops = &user_ta_ops;\n\n  TAILQ_INSERT_TAIL(&tee_ctxes, &utc->ctx, link);\n\n  DMSG(\"Context was successfully inserted!\");\n\n  return TEE_SUCCESS;\n\n//  DMSG(\"%s : %pUl\", stc->pseudo_ta->name, (void *)&ctx->uuid);\n\n//\tSLIST_FOREACH(store, &uta_store_list, link) {\n//\t\tDMSG(\"Lookup user TA %pUl (%s)\", (void *)uuid,\n//\t\t     store->description);\n//\t\tres = ta_load(uuid, store, &s->ctx);\n//\t\tif (res == TEE_ERROR_ITEM_NOT_FOUND)\n//\t\t\tcontinue;\n//\t\tif (res == TEE_SUCCESS)\n//\t\t\ts->ctx->ops = &user_ta_ops;\n//\t\telse\n//\t\t\tDMSG(\"res=0x%x\", res);\n//\t\treturn res;\n//\t}\nerror_return:\n\treturn res;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -31,7 +31,8 @@\n   DMSG(\"Open %s\", ta_head->name);\n \n   /* Register context */\n-  utc = calloc(1, sizeof(struct user_ta_ctx));\n+  // utc = calloc(1, sizeof(struct user_ta_ctx));\n+  utc = TEE_Malloc(sizeof(struct user_ta_ctx), TEE_MALLOC_FILL_ZERO);\n   if (!utc) {\n     res = TEE_ERROR_OUT_OF_MEMORY;\n     goto error_return;",
        "diff_line_info": {
            "deleted_lines": [
                "  utc = calloc(1, sizeof(struct user_ta_ctx));"
            ],
            "added_lines": [
                "  // utc = calloc(1, sizeof(struct user_ta_ctx));",
                "  utc = TEE_Malloc(sizeof(struct user_ta_ctx), TEE_MALLOC_FILL_ZERO);"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-36938",
        "func_name": "facebook/redex/validate_dex_header",
        "description": "DexLoader function get_stringidx_fromdex() in Redex prior to commit 3b44c64 can load an out of bound address when loading the string index table, potentially allowing remote code execution during processing of a 3rd party Android APK file.",
        "git_url": "https://github.com/facebook/redex/commit/3b44c640346b77bfb7ef36e2413688dd460288d2",
        "commit_title": "Add more ids table size bound checks",
        "commit_text": " Summary: When loading Dex files, for the size of each section tables, we did not do enough checks on whether the encoded size of the table is actually out of bound. Having the additional checks makes Dex file loading a bit safer. :)  Reviewed By: agampe  Differential Revision: D41043723  fbshipit-source-id: 874de6a1081e27130ea7b175cfe5b455a49466a7",
        "func_before": "static void validate_dex_header(const dex_header* dh,\n                                size_t dexsize,\n                                int support_dex_version) {\n  bool supported = false;\n  switch (support_dex_version) {\n  case 38:\n    supported = supported ||\n                !memcmp(dh->magic, DEX_HEADER_DEXMAGIC_V38, sizeof(dh->magic));\n    FALLTHROUGH_INTENDED; /* intentional fallthrough to also check for v37 */\n  case 37:\n    supported = supported ||\n                !memcmp(dh->magic, DEX_HEADER_DEXMAGIC_V37, sizeof(dh->magic));\n    FALLTHROUGH_INTENDED; /* intentional fallthrough to also check for v35 */\n  case 35:\n    supported = supported ||\n                !memcmp(dh->magic, DEX_HEADER_DEXMAGIC_V35, sizeof(dh->magic));\n    break;\n  default:\n    not_reached_log(\"Unrecognized support_dex_version %d\\n\",\n                    support_dex_version);\n  }\n  always_assert_log(supported, \"Bad dex magic %s for support_dex_version %d\\n\",\n                    dh->magic, support_dex_version);\n  always_assert_log(\n      dh->file_size == dexsize,\n      \"Reported size in header (%zu) does not match file size (%u)\\n\",\n      dexsize,\n      dh->file_size);\n  auto off = (uint64_t)dh->class_defs_off;\n  auto limit = off + dh->class_defs_size * sizeof(dex_class_def);\n  always_assert_log(off < dexsize, \"class_defs_off out of range\");\n  always_assert_log(limit <= dexsize, \"invalid class_defs_size\");\n}",
        "func": "static void validate_dex_header(const dex_header* dh,\n                                size_t dexsize,\n                                int support_dex_version) {\n  always_assert_log(sizeof(dex_header) <= dexsize,\n                    \"Header size (%lu) is larger than file size (%zu)\\n\",\n                    dexsize,\n                    sizeof(dex_header));\n  bool supported = false;\n  switch (support_dex_version) {\n  case 38:\n    supported = supported ||\n                !memcmp(dh->magic, DEX_HEADER_DEXMAGIC_V38, sizeof(dh->magic));\n    FALLTHROUGH_INTENDED; /* intentional fallthrough to also check for v37 */\n  case 37:\n    supported = supported ||\n                !memcmp(dh->magic, DEX_HEADER_DEXMAGIC_V37, sizeof(dh->magic));\n    FALLTHROUGH_INTENDED; /* intentional fallthrough to also check for v35 */\n  case 35:\n    supported = supported ||\n                !memcmp(dh->magic, DEX_HEADER_DEXMAGIC_V35, sizeof(dh->magic));\n    break;\n  default:\n    not_reached_log(\"Unrecognized support_dex_version %d\\n\",\n                    support_dex_version);\n  }\n  always_assert_log(supported, \"Bad dex magic %s for support_dex_version %d\\n\",\n                    dh->magic, support_dex_version);\n  always_assert_log(\n      dh->file_size == dexsize,\n      \"Reported size in header (%zu) does not match file size (%u)\\n\",\n      dexsize,\n      dh->file_size);\n\n  auto str_ids_off = (uint64_t)dh->string_ids_off;\n  auto str_ids_limit =\n      str_ids_off + dh->string_ids_size * sizeof(dex_string_id);\n  always_assert_log(str_ids_off < dexsize, \"string_ids_off out of range\");\n  always_assert_log(str_ids_limit <= dexsize, \"invalid string_ids_size\");\n\n  auto type_ids_off = (uint64_t)dh->type_ids_off;\n  auto type_ids_limit = type_ids_off + dh->type_ids_size * sizeof(dex_type_id);\n  always_assert_log(type_ids_off < dexsize, \"type_ids_off out of range\");\n  always_assert_log(type_ids_limit <= dexsize, \"invalid type_ids_size\");\n\n  auto proto_ids_off = (uint64_t)dh->proto_ids_off;\n  auto proto_ids_limit =\n      proto_ids_off + dh->proto_ids_size * sizeof(dex_proto_id);\n  always_assert_log(proto_ids_off < dexsize, \"proto_ids_off out of range\");\n  always_assert_log(proto_ids_limit <= dexsize, \"invalid proto_ids_size\");\n\n  auto field_ids_off = (uint64_t)dh->field_ids_off;\n  auto field_ids_limit =\n      field_ids_off + dh->field_ids_size * sizeof(dex_field_id);\n  always_assert_log(field_ids_off < dexsize, \"field_ids_off out of range\");\n  always_assert_log(field_ids_limit <= dexsize, \"invalid field_ids_size\");\n\n  auto meth_ids_off = (uint64_t)dh->method_ids_off;\n  auto meth_ids_limit =\n      meth_ids_off + dh->method_ids_size * sizeof(dex_method_id);\n  always_assert_log(meth_ids_off < dexsize, \"method_ids_off out of range\");\n  always_assert_log(meth_ids_limit <= dexsize, \"invalid method_ids_size\");\n\n  auto cls_defs_off = (uint64_t)dh->class_defs_off;\n  auto cls_defs_limit =\n      cls_defs_off + dh->class_defs_size * sizeof(dex_class_def);\n  always_assert_log(cls_defs_off < dexsize, \"class_defs_off out of range\");\n  always_assert_log(cls_defs_limit <= dexsize, \"invalid class_defs_size\");\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,10 @@\n static void validate_dex_header(const dex_header* dh,\n                                 size_t dexsize,\n                                 int support_dex_version) {\n+  always_assert_log(sizeof(dex_header) <= dexsize,\n+                    \"Header size (%lu) is larger than file size (%zu)\\n\",\n+                    dexsize,\n+                    sizeof(dex_header));\n   bool supported = false;\n   switch (support_dex_version) {\n   case 38:\n@@ -26,8 +30,39 @@\n       \"Reported size in header (%zu) does not match file size (%u)\\n\",\n       dexsize,\n       dh->file_size);\n-  auto off = (uint64_t)dh->class_defs_off;\n-  auto limit = off + dh->class_defs_size * sizeof(dex_class_def);\n-  always_assert_log(off < dexsize, \"class_defs_off out of range\");\n-  always_assert_log(limit <= dexsize, \"invalid class_defs_size\");\n+\n+  auto str_ids_off = (uint64_t)dh->string_ids_off;\n+  auto str_ids_limit =\n+      str_ids_off + dh->string_ids_size * sizeof(dex_string_id);\n+  always_assert_log(str_ids_off < dexsize, \"string_ids_off out of range\");\n+  always_assert_log(str_ids_limit <= dexsize, \"invalid string_ids_size\");\n+\n+  auto type_ids_off = (uint64_t)dh->type_ids_off;\n+  auto type_ids_limit = type_ids_off + dh->type_ids_size * sizeof(dex_type_id);\n+  always_assert_log(type_ids_off < dexsize, \"type_ids_off out of range\");\n+  always_assert_log(type_ids_limit <= dexsize, \"invalid type_ids_size\");\n+\n+  auto proto_ids_off = (uint64_t)dh->proto_ids_off;\n+  auto proto_ids_limit =\n+      proto_ids_off + dh->proto_ids_size * sizeof(dex_proto_id);\n+  always_assert_log(proto_ids_off < dexsize, \"proto_ids_off out of range\");\n+  always_assert_log(proto_ids_limit <= dexsize, \"invalid proto_ids_size\");\n+\n+  auto field_ids_off = (uint64_t)dh->field_ids_off;\n+  auto field_ids_limit =\n+      field_ids_off + dh->field_ids_size * sizeof(dex_field_id);\n+  always_assert_log(field_ids_off < dexsize, \"field_ids_off out of range\");\n+  always_assert_log(field_ids_limit <= dexsize, \"invalid field_ids_size\");\n+\n+  auto meth_ids_off = (uint64_t)dh->method_ids_off;\n+  auto meth_ids_limit =\n+      meth_ids_off + dh->method_ids_size * sizeof(dex_method_id);\n+  always_assert_log(meth_ids_off < dexsize, \"method_ids_off out of range\");\n+  always_assert_log(meth_ids_limit <= dexsize, \"invalid method_ids_size\");\n+\n+  auto cls_defs_off = (uint64_t)dh->class_defs_off;\n+  auto cls_defs_limit =\n+      cls_defs_off + dh->class_defs_size * sizeof(dex_class_def);\n+  always_assert_log(cls_defs_off < dexsize, \"class_defs_off out of range\");\n+  always_assert_log(cls_defs_limit <= dexsize, \"invalid class_defs_size\");\n }",
        "diff_line_info": {
            "deleted_lines": [
                "  auto off = (uint64_t)dh->class_defs_off;",
                "  auto limit = off + dh->class_defs_size * sizeof(dex_class_def);",
                "  always_assert_log(off < dexsize, \"class_defs_off out of range\");",
                "  always_assert_log(limit <= dexsize, \"invalid class_defs_size\");"
            ],
            "added_lines": [
                "  always_assert_log(sizeof(dex_header) <= dexsize,",
                "                    \"Header size (%lu) is larger than file size (%zu)\\n\",",
                "                    dexsize,",
                "                    sizeof(dex_header));",
                "",
                "  auto str_ids_off = (uint64_t)dh->string_ids_off;",
                "  auto str_ids_limit =",
                "      str_ids_off + dh->string_ids_size * sizeof(dex_string_id);",
                "  always_assert_log(str_ids_off < dexsize, \"string_ids_off out of range\");",
                "  always_assert_log(str_ids_limit <= dexsize, \"invalid string_ids_size\");",
                "",
                "  auto type_ids_off = (uint64_t)dh->type_ids_off;",
                "  auto type_ids_limit = type_ids_off + dh->type_ids_size * sizeof(dex_type_id);",
                "  always_assert_log(type_ids_off < dexsize, \"type_ids_off out of range\");",
                "  always_assert_log(type_ids_limit <= dexsize, \"invalid type_ids_size\");",
                "",
                "  auto proto_ids_off = (uint64_t)dh->proto_ids_off;",
                "  auto proto_ids_limit =",
                "      proto_ids_off + dh->proto_ids_size * sizeof(dex_proto_id);",
                "  always_assert_log(proto_ids_off < dexsize, \"proto_ids_off out of range\");",
                "  always_assert_log(proto_ids_limit <= dexsize, \"invalid proto_ids_size\");",
                "",
                "  auto field_ids_off = (uint64_t)dh->field_ids_off;",
                "  auto field_ids_limit =",
                "      field_ids_off + dh->field_ids_size * sizeof(dex_field_id);",
                "  always_assert_log(field_ids_off < dexsize, \"field_ids_off out of range\");",
                "  always_assert_log(field_ids_limit <= dexsize, \"invalid field_ids_size\");",
                "",
                "  auto meth_ids_off = (uint64_t)dh->method_ids_off;",
                "  auto meth_ids_limit =",
                "      meth_ids_off + dh->method_ids_size * sizeof(dex_method_id);",
                "  always_assert_log(meth_ids_off < dexsize, \"method_ids_off out of range\");",
                "  always_assert_log(meth_ids_limit <= dexsize, \"invalid method_ids_size\");",
                "",
                "  auto cls_defs_off = (uint64_t)dh->class_defs_off;",
                "  auto cls_defs_limit =",
                "      cls_defs_off + dh->class_defs_size * sizeof(dex_class_def);",
                "  always_assert_log(cls_defs_off < dexsize, \"class_defs_off out of range\");",
                "  always_assert_log(cls_defs_limit <= dexsize, \"invalid class_defs_size\");"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-37674",
        "func_name": "tensorflow/SpatialMaxPoolWithArgMaxHelper",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions an attacker can trigger a denial of service via a segmentation fault in `tf.raw_ops.MaxPoolGrad` caused by missing validation. The [implementation](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/core/kernels/maxpooling_op.cc) misses some validation for the `orig_input` and `orig_output` tensors. The fixes for CVE-2021-29579 were incomplete. We have patched the issue in GitHub commit 136b51f10903e044308cf77117c0ed9871350475. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/136b51f10903e044308cf77117c0ed9871350475",
        "commit_title": "Add missing validation to `maxpooling_op.cc`",
        "commit_text": " PiperOrigin-RevId: 387932441",
        "func_before": "static void SpatialMaxPoolWithArgMaxHelper(\n    OpKernelContext* context, Tensor* output, Tensor* output_arg_max,\n    Tensor* input_backprop, const Tensor& tensor_in, const Tensor& out_backprop,\n    const PoolParameters& params, const bool include_batch_in_index) {\n  if (input_backprop != nullptr) {\n    OP_REQUIRES(\n        context, include_batch_in_index,\n        errors::Internal(\n            \"SpatialMaxPoolWithArgMaxHelper requires include_batch_in_index \"\n            \"to be True when input_backprop != nullptr\"));\n    OP_REQUIRES(\n        context, (std::is_same<Targmax, int64>::value),\n        errors::Internal(\"SpatialMaxPoolWithArgMaxHelper requires Targmax \"\n                         \"to be int64 when input_backprop != nullptr\"));\n  }\n\n  typedef Eigen::Map<const Eigen::Matrix<T, Eigen::Dynamic, Eigen::Dynamic>>\n      ConstEigenMatrixMap;\n  typedef Eigen::Map<Eigen::Matrix<T, Eigen::Dynamic, Eigen::Dynamic>>\n      EigenMatrixMap;\n  typedef Eigen::Map<Eigen::Matrix<Targmax, Eigen::Dynamic, Eigen::Dynamic>>\n      EigenIndexMatrixMap;\n\n  ConstEigenMatrixMap in_mat(\n      tensor_in.flat<T>().data(), params.depth,\n      params.tensor_in_cols * params.tensor_in_rows * params.tensor_in_batch);\n  EigenMatrixMap out_mat(\n      output->flat<T>().data(), params.depth,\n      params.out_width * params.out_height * params.tensor_in_batch);\n  EigenIndexMatrixMap out_arg_max_mat(\n      output_arg_max->flat<Targmax>().data(), params.depth,\n      params.out_width * params.out_height * params.tensor_in_batch);\n\n  const DeviceBase::CpuWorkerThreads& worker_threads =\n      *(context->device()->tensorflow_cpu_worker_threads());\n\n  // The following code basically does the following:\n  // 1. Flattens the input and output tensors into two dimensional arrays.\n  //    tensor_in_as_matrix:\n  //      depth by (tensor_in_cols * tensor_in_rows * tensor_in_batch)\n  //    output_as_matrix:\n  //      depth by (out_width * out_height * tensor_in_batch)\n  //\n  // 2. Walks through the set of columns in the flattened tensor_in_as_matrix,\n  //    and updates the corresponding column(s) in output_as_matrix with the\n  //    max value.\n  auto shard = [&params, &in_mat, &out_mat, &out_arg_max_mat, &input_backprop,\n                &output_arg_max, &out_backprop,\n                include_batch_in_index](int64_t start, int64_t limit) {\n    const int32_t depth = params.depth;\n    const int32_t in_rows = params.tensor_in_rows;\n    const int32_t in_cols = params.tensor_in_cols;\n    const int32_t pad_top = params.pad_top;\n    const int32_t pad_left = params.pad_left;\n    const int32_t window_rows = params.window_rows;\n    const int32_t window_cols = params.window_cols;\n    const int32_t row_stride = params.row_stride;\n    const int32_t col_stride = params.col_stride;\n    const int32_t out_height = params.out_height;\n    const int32_t out_width = params.out_width;\n\n    {\n      // Initializes the output tensor with MIN<T>.\n      const int32_t output_image_size = out_height * out_width * depth;\n      EigenMatrixMap out_shard(out_mat.data() + start * output_image_size, 1,\n                               (limit - start) * output_image_size);\n      out_shard.setConstant(Eigen::NumTraits<T>::lowest());\n      EigenIndexMatrixMap out_arg_max_shard(\n          out_arg_max_mat.data() + start * output_image_size, 1,\n          (limit - start) * output_image_size);\n      out_arg_max_shard.setConstant(kInvalidMaxPoolingIndex);\n    }\n\n    for (int64_t b = start; b < limit; ++b) {\n      for (int h = 0; h < in_rows; ++h) {\n        for (int w = 0; w < in_cols; ++w) {\n          // (h_start, h_end) * (w_start, w_end) is the range that the input\n          // vector projects to.\n          const int hpad = h + pad_top;\n          const int wpad = w + pad_left;\n          const int h_start =\n              (hpad < window_rows) ? 0 : (hpad - window_rows) / row_stride + 1;\n          const int h_end = std::min(hpad / row_stride + 1, out_height);\n          const int w_start =\n              (wpad < window_cols) ? 0 : (wpad - window_cols) / col_stride + 1;\n          const int w_end = std::min(wpad / col_stride + 1, out_width);\n          // compute elementwise max\n          const int64_t in_index = (b * in_rows + h) * in_cols + w;\n          for (int ph = h_start; ph < h_end; ++ph) {\n            const int64_t out_index_base = (b * out_height + ph) * out_width;\n            for (int pw = w_start; pw < w_end; ++pw) {\n              const int64_t out_index = out_index_base + pw;\n              /// NOTES(zhengxq): not using the eigen matrix operation for\n              /// now.\n              for (int d = 0; d < depth; ++d) {\n                const T& input_ref = in_mat.coeffRef(d, in_index);\n                T& output_ref = out_mat.coeffRef(d, out_index);\n                Targmax& out_arg_max_ref =\n                    out_arg_max_mat.coeffRef(d, out_index);\n                if (output_ref < input_ref ||\n                    out_arg_max_ref == kInvalidMaxPoolingIndex) {\n                  output_ref = input_ref;\n                  if (include_batch_in_index) {\n                    out_arg_max_ref = in_index * depth + d;\n                  } else {\n                    out_arg_max_ref = (h * in_cols + w) * depth + d;\n                  }\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n\n    if (input_backprop != nullptr) {\n      auto input_backprop_flat = input_backprop->flat<T>();\n      auto out_arg_max_flat = output_arg_max->flat<int64>();\n      auto out_backprop_flat = out_backprop.flat<T>();\n\n      // Initialize output to 0.\n      const int64_t in_size = in_rows * in_cols * depth;\n      const int64_t in_start = start * in_size;\n      const int64_t in_end = limit * in_size;\n      EigenMatrixMap in_shard(input_backprop_flat.data() + in_start, 1,\n                              in_end - in_start);\n      in_shard.setConstant(T(0));\n\n      // Backpropagate.\n      const int out_size = out_height * out_width * depth;\n      const int out_start = start * out_size;\n      const int out_end = limit * out_size;\n      for (int index = out_start; index < out_end; ++index) {\n        int input_backprop_index = out_arg_max_flat(index);\n        // Although this check is in the inner loop, it is worth its value\n        // so we don't end up with memory corruptions. Our benchmark shows that\n        // the performance impact is quite small\n        // CHECK(input_backprop_index >= in_start && input_backprop_index <\n        // in_end)\n        FastBoundsCheck(input_backprop_index - in_start, in_end - in_start);\n        if (index < out_backprop.NumElements()) {\n          input_backprop_flat(input_backprop_index) += out_backprop_flat(index);\n        }\n      }\n    }\n  };\n\n  const int64_t shard_cost = params.tensor_in_rows * params.tensor_in_cols *\n                             params.depth * params.window_rows *\n                             params.window_cols;\n  Shard(worker_threads.num_threads, worker_threads.workers,\n        params.tensor_in_batch, shard_cost, shard);\n}",
        "func": "static void SpatialMaxPoolWithArgMaxHelper(\n    OpKernelContext* context, Tensor* output, Tensor* output_arg_max,\n    Tensor* input_backprop, const Tensor& tensor_in, const Tensor& out_backprop,\n    const PoolParameters& params, const bool include_batch_in_index) {\n  if (input_backprop != nullptr) {\n    OP_REQUIRES(\n        context, include_batch_in_index,\n        errors::Internal(\n            \"SpatialMaxPoolWithArgMaxHelper requires include_batch_in_index \"\n            \"to be True when input_backprop != nullptr\"));\n    OP_REQUIRES(\n        context, (std::is_same<Targmax, int64>::value),\n        errors::Internal(\"SpatialMaxPoolWithArgMaxHelper requires Targmax \"\n                         \"to be int64 when input_backprop != nullptr\"));\n  }\n  if (tensor_in.NumElements() == 0 || output->NumElements() == 0) return;\n\n  typedef Eigen::Map<const Eigen::Matrix<T, Eigen::Dynamic, Eigen::Dynamic>>\n      ConstEigenMatrixMap;\n  typedef Eigen::Map<Eigen::Matrix<T, Eigen::Dynamic, Eigen::Dynamic>>\n      EigenMatrixMap;\n  typedef Eigen::Map<Eigen::Matrix<Targmax, Eigen::Dynamic, Eigen::Dynamic>>\n      EigenIndexMatrixMap;\n\n  ConstEigenMatrixMap in_mat(\n      tensor_in.flat<T>().data(), params.depth,\n      params.tensor_in_cols * params.tensor_in_rows * params.tensor_in_batch);\n  EigenMatrixMap out_mat(\n      output->flat<T>().data(), params.depth,\n      params.out_width * params.out_height * params.tensor_in_batch);\n  EigenIndexMatrixMap out_arg_max_mat(\n      output_arg_max->flat<Targmax>().data(), params.depth,\n      params.out_width * params.out_height * params.tensor_in_batch);\n\n  const DeviceBase::CpuWorkerThreads& worker_threads =\n      *(context->device()->tensorflow_cpu_worker_threads());\n\n  // The following code basically does the following:\n  // 1. Flattens the input and output tensors into two dimensional arrays.\n  //    tensor_in_as_matrix:\n  //      depth by (tensor_in_cols * tensor_in_rows * tensor_in_batch)\n  //    output_as_matrix:\n  //      depth by (out_width * out_height * tensor_in_batch)\n  //\n  // 2. Walks through the set of columns in the flattened tensor_in_as_matrix,\n  //    and updates the corresponding column(s) in output_as_matrix with the\n  //    max value.\n  auto shard = [&params, &in_mat, &out_mat, &out_arg_max_mat, &input_backprop,\n                &output_arg_max, &out_backprop,\n                include_batch_in_index](int64_t start, int64_t limit) {\n    const int32_t depth = params.depth;\n    const int32_t in_rows = params.tensor_in_rows;\n    const int32_t in_cols = params.tensor_in_cols;\n    const int32_t pad_top = params.pad_top;\n    const int32_t pad_left = params.pad_left;\n    const int32_t window_rows = params.window_rows;\n    const int32_t window_cols = params.window_cols;\n    const int32_t row_stride = params.row_stride;\n    const int32_t col_stride = params.col_stride;\n    const int32_t out_height = params.out_height;\n    const int32_t out_width = params.out_width;\n\n    {\n      // Initializes the output tensor with MIN<T>.\n      const int32_t output_image_size = out_height * out_width * depth;\n      EigenMatrixMap out_shard(out_mat.data() + start * output_image_size, 1,\n                               (limit - start) * output_image_size);\n      out_shard.setConstant(Eigen::NumTraits<T>::lowest());\n      EigenIndexMatrixMap out_arg_max_shard(\n          out_arg_max_mat.data() + start * output_image_size, 1,\n          (limit - start) * output_image_size);\n      out_arg_max_shard.setConstant(kInvalidMaxPoolingIndex);\n    }\n\n    for (int64_t b = start; b < limit; ++b) {\n      for (int h = 0; h < in_rows; ++h) {\n        for (int w = 0; w < in_cols; ++w) {\n          // (h_start, h_end) * (w_start, w_end) is the range that the input\n          // vector projects to.\n          const int hpad = h + pad_top;\n          const int wpad = w + pad_left;\n          const int h_start =\n              (hpad < window_rows) ? 0 : (hpad - window_rows) / row_stride + 1;\n          const int h_end = std::min(hpad / row_stride + 1, out_height);\n          const int w_start =\n              (wpad < window_cols) ? 0 : (wpad - window_cols) / col_stride + 1;\n          const int w_end = std::min(wpad / col_stride + 1, out_width);\n          // compute elementwise max\n          const int64_t in_index = (b * in_rows + h) * in_cols + w;\n          for (int ph = h_start; ph < h_end; ++ph) {\n            const int64_t out_index_base = (b * out_height + ph) * out_width;\n            for (int pw = w_start; pw < w_end; ++pw) {\n              const int64_t out_index = out_index_base + pw;\n              /// NOTES(zhengxq): not using the eigen matrix operation for\n              /// now.\n              for (int d = 0; d < depth; ++d) {\n                const T& input_ref = in_mat.coeffRef(d, in_index);\n                T& output_ref = out_mat.coeffRef(d, out_index);\n                Targmax& out_arg_max_ref =\n                    out_arg_max_mat.coeffRef(d, out_index);\n                if (output_ref < input_ref ||\n                    out_arg_max_ref == kInvalidMaxPoolingIndex) {\n                  output_ref = input_ref;\n                  if (include_batch_in_index) {\n                    out_arg_max_ref = in_index * depth + d;\n                  } else {\n                    out_arg_max_ref = (h * in_cols + w) * depth + d;\n                  }\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n\n    if (input_backprop != nullptr) {\n      auto input_backprop_flat = input_backprop->flat<T>();\n      auto out_arg_max_flat = output_arg_max->flat<int64>();\n      auto out_backprop_flat = out_backprop.flat<T>();\n\n      // Initialize output to 0.\n      const int64_t in_size = in_rows * in_cols * depth;\n      const int64_t in_start = start * in_size;\n      const int64_t in_end = limit * in_size;\n      EigenMatrixMap in_shard(input_backprop_flat.data() + in_start, 1,\n                              in_end - in_start);\n      in_shard.setConstant(T(0));\n\n      // Backpropagate.\n      const int out_size = out_height * out_width * depth;\n      const int out_start = start * out_size;\n      const int out_end = limit * out_size;\n      for (int index = out_start; index < out_end; ++index) {\n        int input_backprop_index = out_arg_max_flat(index);\n        // Although this check is in the inner loop, it is worth its value\n        // so we don't end up with memory corruptions. Our benchmark shows that\n        // the performance impact is quite small\n        // CHECK(input_backprop_index >= in_start && input_backprop_index <\n        // in_end)\n        FastBoundsCheck(input_backprop_index - in_start, in_end - in_start);\n        if (index < out_backprop.NumElements()) {\n          input_backprop_flat(input_backprop_index) += out_backprop_flat(index);\n        }\n      }\n    }\n  };\n\n  const int64_t shard_cost = params.tensor_in_rows * params.tensor_in_cols *\n                             params.depth * params.window_rows *\n                             params.window_cols;\n  Shard(worker_threads.num_threads, worker_threads.workers,\n        params.tensor_in_batch, shard_cost, shard);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -13,6 +13,7 @@\n         errors::Internal(\"SpatialMaxPoolWithArgMaxHelper requires Targmax \"\n                          \"to be int64 when input_backprop != nullptr\"));\n   }\n+  if (tensor_in.NumElements() == 0 || output->NumElements() == 0) return;\n \n   typedef Eigen::Map<const Eigen::Matrix<T, Eigen::Dynamic, Eigen::Dynamic>>\n       ConstEigenMatrixMap;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "  if (tensor_in.NumElements() == 0 || output->NumElements() == 0) return;"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-37674",
        "func_name": "tensorflow/PoolParameters::PoolParameters",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions an attacker can trigger a denial of service via a segmentation fault in `tf.raw_ops.MaxPoolGrad` caused by missing validation. The [implementation](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/core/kernels/maxpooling_op.cc) misses some validation for the `orig_input` and `orig_output` tensors. The fixes for CVE-2021-29579 were incomplete. We have patched the issue in GitHub commit 136b51f10903e044308cf77117c0ed9871350475. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/136b51f10903e044308cf77117c0ed9871350475",
        "commit_title": "Add missing validation to `maxpooling_op.cc`",
        "commit_text": " PiperOrigin-RevId: 387932441",
        "func_before": "PoolParameters::PoolParameters(OpKernelContext* context,\n                               const std::vector<int32>& ksize,\n                               const std::vector<int32>& stride,\n                               Padding padding,\n                               std::vector<int64> explicit_paddings,\n                               TensorFormat data_format,\n                               const TensorShape& tensor_in_shape) {\n  // For maxpooling, tensor_in should have 2 spatial dimensions.\n  // Note: the total number of dimensions could be 4 for NHWC, NCHW,\n  // or 5 for NCHW_VECT_C.\n  OP_REQUIRES(context,\n              GetTensorSpatialDims(tensor_in_shape.dims(), data_format) == 2,\n              errors::InvalidArgument(\n                  \"tensor_in_shape must have 2 spatial dimensions. \",\n                  tensor_in_shape.dims(), \" \", data_format));\n\n  this->data_format = data_format;\n  depth = GetTensorDim(tensor_in_shape, data_format, 'C') *\n          (data_format == FORMAT_NCHW_VECT_C ? 4 : 1);\n  tensor_in_cols = GetTensorDim(tensor_in_shape, data_format, 'W');\n  tensor_in_rows = GetTensorDim(tensor_in_shape, data_format, 'H');\n  tensor_in_batch = GetTensorDim(tensor_in_shape, data_format, 'N');\n  window_rows = GetTensorDim(ksize, data_format, 'H');\n  window_cols = GetTensorDim(ksize, data_format, 'W');\n  depth_window = GetTensorDim(ksize, data_format, 'C');\n  row_stride = GetTensorDim(stride, data_format, 'H');\n  col_stride = GetTensorDim(stride, data_format, 'W');\n  depth_stride = GetTensorDim(stride, data_format, 'C');\n\n  // We only support 2D pooling across width/height and depthwise\n  // pooling, not a combination.\n  OP_REQUIRES(context,\n              (depth_window == 1 || (window_rows == 1 && window_cols == 1)),\n              errors::Unimplemented(\n                  \"MaxPooling supports exactly one of pooling across depth \"\n                  \"or pooling across width/height.\"));\n  if (padding == Padding::EXPLICIT) {\n    OP_REQUIRES_OK(context, CheckValidPadding(padding, explicit_paddings,\n                                              /*num_dims=*/4, data_format));\n    GetExplicitPaddingForDim(explicit_paddings, data_format, 'H', &pad_top,\n                             &pad_bottom);\n    GetExplicitPaddingForDim(explicit_paddings, data_format, 'W', &pad_left,\n                             &pad_right);\n    OP_REQUIRES_OK(context, CheckPaddingSize(window_rows, window_cols, pad_top,\n                                             pad_bottom, pad_left, pad_right));\n  }\n\n  if (depth_window == 1) {\n    OP_REQUIRES_OK(context, GetWindowedOutputSizeVerbose(\n                                tensor_in_rows, window_rows, row_stride,\n                                padding, &out_height, &pad_top, &pad_bottom));\n    OP_REQUIRES_OK(context, GetWindowedOutputSizeVerbose(\n                                tensor_in_cols, window_cols, col_stride,\n                                padding, &out_width, &pad_left, &pad_right));\n    pad_depth = 0;\n    out_depth = depth;\n  } else {\n    // Our current version of depthwise max pooling does not support\n    // any padding, and expects the depth_window to equal the\n    // depth_stride (no overlapping).\n    OP_REQUIRES(\n        context, depth % depth_window == 0,\n        errors::Unimplemented(\"Depthwise max pooling requires the depth \"\n                              \"window to evenly divide the input depth\"));\n    OP_REQUIRES(\n        context, depth_stride == depth_window,\n        errors::Unimplemented(\"Depthwise max pooling requires the depth \"\n                              \"window to equal the depth stride\"));\n\n    // The current version of depthwise max is only implemented on CPU.\n    OP_REQUIRES(context,\n                (DeviceType(static_cast<Device*>(context->device())\n                                ->attributes()\n                                .device_type()) == DeviceType(DEVICE_CPU)),\n                errors::Unimplemented(\"Depthwise max pooling is currently \"\n                                      \"only implemented for CPU devices.\"));\n\n    pad_depth = 0;\n    out_depth = depth / depth_window;\n  }\n}",
        "func": "PoolParameters::PoolParameters(OpKernelContext* context,\n                               const std::vector<int32>& ksize,\n                               const std::vector<int32>& stride,\n                               Padding padding,\n                               std::vector<int64> explicit_paddings,\n                               TensorFormat data_format,\n                               const TensorShape& tensor_in_shape) {\n  // For maxpooling, tensor_in should have 2 spatial dimensions.\n  // Note: the total number of dimensions could be 4 for NHWC, NCHW,\n  // or 5 for NCHW_VECT_C.\n  OP_REQUIRES(context,\n              GetTensorSpatialDims(tensor_in_shape.dims(), data_format) == 2,\n              errors::InvalidArgument(\n                  \"tensor_in_shape must have 2 spatial dimensions. \",\n                  tensor_in_shape.dims(), \" \", data_format));\n\n  this->data_format = data_format;\n  depth = GetTensorDim(tensor_in_shape, data_format, 'C') *\n          (data_format == FORMAT_NCHW_VECT_C ? 4 : 1);\n  tensor_in_cols = GetTensorDim(tensor_in_shape, data_format, 'W');\n  tensor_in_rows = GetTensorDim(tensor_in_shape, data_format, 'H');\n  tensor_in_batch = GetTensorDim(tensor_in_shape, data_format, 'N');\n  window_rows = GetTensorDim(ksize, data_format, 'H');\n  window_cols = GetTensorDim(ksize, data_format, 'W');\n  depth_window = GetTensorDim(ksize, data_format, 'C');\n  row_stride = GetTensorDim(stride, data_format, 'H');\n  col_stride = GetTensorDim(stride, data_format, 'W');\n  depth_stride = GetTensorDim(stride, data_format, 'C');\n\n  // We only support 2D pooling across width/height and depthwise\n  // pooling, not a combination.\n  OP_REQUIRES(context,\n              (depth_window == 1 || (window_rows == 1 && window_cols == 1)),\n              errors::Unimplemented(\n                  \"MaxPooling supports exactly one of pooling across depth \"\n                  \"or pooling across width/height.\"));\n  if (padding == Padding::EXPLICIT) {\n    OP_REQUIRES_OK(context, CheckValidPadding(padding, explicit_paddings,\n                                              /*num_dims=*/4, data_format));\n    GetExplicitPaddingForDim(explicit_paddings, data_format, 'H', &pad_top,\n                             &pad_bottom);\n    GetExplicitPaddingForDim(explicit_paddings, data_format, 'W', &pad_left,\n                             &pad_right);\n    OP_REQUIRES_OK(context, CheckPaddingSize(window_rows, window_cols, pad_top,\n                                             pad_bottom, pad_left, pad_right));\n  }\n\n  if (depth_window == 1) {\n    OP_REQUIRES_OK(context, GetWindowedOutputSizeVerbose(\n                                tensor_in_rows, window_rows, row_stride,\n                                padding, &out_height, &pad_top, &pad_bottom));\n    OP_REQUIRES_OK(context, GetWindowedOutputSizeVerbose(\n                                tensor_in_cols, window_cols, col_stride,\n                                padding, &out_width, &pad_left, &pad_right));\n    pad_depth = 0;\n    out_depth = depth;\n  } else {\n    OP_REQUIRES(context, depth_window > 0,\n                errors::InvalidArgument(\"depth_window must not be 0\"));\n    // Our current version of depthwise max pooling does not support\n    // any padding, and expects the depth_window to equal the\n    // depth_stride (no overlapping).\n    OP_REQUIRES(\n        context, depth % depth_window == 0,\n        errors::Unimplemented(\"Depthwise max pooling requires the depth \"\n                              \"window to evenly divide the input depth\"));\n    OP_REQUIRES(\n        context, depth_stride == depth_window,\n        errors::Unimplemented(\"Depthwise max pooling requires the depth \"\n                              \"window to equal the depth stride\"));\n\n    // The current version of depthwise max is only implemented on CPU.\n    OP_REQUIRES(context,\n                (DeviceType(static_cast<Device*>(context->device())\n                                ->attributes()\n                                .device_type()) == DeviceType(DEVICE_CPU)),\n                errors::Unimplemented(\"Depthwise max pooling is currently \"\n                                      \"only implemented for CPU devices.\"));\n\n    pad_depth = 0;\n    out_depth = depth / depth_window;\n  }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -55,6 +55,8 @@\n     pad_depth = 0;\n     out_depth = depth;\n   } else {\n+    OP_REQUIRES(context, depth_window > 0,\n+                errors::InvalidArgument(\"depth_window must not be 0\"));\n     // Our current version of depthwise max pooling does not support\n     // any padding, and expects the depth_window to equal the\n     // depth_stride (no overlapping).",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    OP_REQUIRES(context, depth_window > 0,",
                "                errors::InvalidArgument(\"depth_window must not be 0\"));"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-25375",
        "func_name": "torvalds/linux/rndis_set_response",
        "description": "An issue was discovered in drivers/usb/gadget/function/rndis.c in the Linux kernel before 5.16.10. The RNDIS USB gadget lacks validation of the size of the RNDIS_MSG_SET command. Attackers can obtain sensitive information from kernel memory.",
        "git_url": "https://github.com/torvalds/linux/commit/38ea1eac7d88072bbffb630e2b3db83ca649b826",
        "commit_title": "usb: gadget: rndis: check size of RNDIS_MSG_SET command",
        "commit_text": " Check the size of the RNDIS_MSG_SET command given to us before attempting to respond to an invalid message size.  Cc: stable@kernel.org",
        "func_before": "static int rndis_set_response(struct rndis_params *params,\n\t\t\t      rndis_set_msg_type *buf)\n{\n\tu32 BufLength, BufOffset;\n\trndis_set_cmplt_type *resp;\n\trndis_resp_t *r;\n\n\tr = rndis_add_response(params, sizeof(rndis_set_cmplt_type));\n\tif (!r)\n\t\treturn -ENOMEM;\n\tresp = (rndis_set_cmplt_type *)r->buf;\n\n\tBufLength = le32_to_cpu(buf->InformationBufferLength);\n\tBufOffset = le32_to_cpu(buf->InformationBufferOffset);\n\n#ifdef\tVERBOSE_DEBUG\n\tpr_debug(\"%s: Length: %d\\n\", __func__, BufLength);\n\tpr_debug(\"%s: Offset: %d\\n\", __func__, BufOffset);\n\tpr_debug(\"%s: InfoBuffer: \", __func__);\n\n\tfor (i = 0; i < BufLength; i++) {\n\t\tpr_debug(\"%02x \", *(((u8 *) buf) + i + 8 + BufOffset));\n\t}\n\n\tpr_debug(\"\\n\");\n#endif\n\n\tresp->MessageType = cpu_to_le32(RNDIS_MSG_SET_C);\n\tresp->MessageLength = cpu_to_le32(16);\n\tresp->RequestID = buf->RequestID; /* Still LE in msg buffer */\n\tif (gen_ndis_set_resp(params, le32_to_cpu(buf->OID),\n\t\t\t((u8 *)buf) + 8 + BufOffset, BufLength, r))\n\t\tresp->Status = cpu_to_le32(RNDIS_STATUS_NOT_SUPPORTED);\n\telse\n\t\tresp->Status = cpu_to_le32(RNDIS_STATUS_SUCCESS);\n\n\tparams->resp_avail(params->v);\n\treturn 0;\n}",
        "func": "static int rndis_set_response(struct rndis_params *params,\n\t\t\t      rndis_set_msg_type *buf)\n{\n\tu32 BufLength, BufOffset;\n\trndis_set_cmplt_type *resp;\n\trndis_resp_t *r;\n\n\tBufLength = le32_to_cpu(buf->InformationBufferLength);\n\tBufOffset = le32_to_cpu(buf->InformationBufferOffset);\n\tif ((BufLength > RNDIS_MAX_TOTAL_SIZE) ||\n\t    (BufOffset + 8 >= RNDIS_MAX_TOTAL_SIZE))\n\t\t    return -EINVAL;\n\n\tr = rndis_add_response(params, sizeof(rndis_set_cmplt_type));\n\tif (!r)\n\t\treturn -ENOMEM;\n\tresp = (rndis_set_cmplt_type *)r->buf;\n\n#ifdef\tVERBOSE_DEBUG\n\tpr_debug(\"%s: Length: %d\\n\", __func__, BufLength);\n\tpr_debug(\"%s: Offset: %d\\n\", __func__, BufOffset);\n\tpr_debug(\"%s: InfoBuffer: \", __func__);\n\n\tfor (i = 0; i < BufLength; i++) {\n\t\tpr_debug(\"%02x \", *(((u8 *) buf) + i + 8 + BufOffset));\n\t}\n\n\tpr_debug(\"\\n\");\n#endif\n\n\tresp->MessageType = cpu_to_le32(RNDIS_MSG_SET_C);\n\tresp->MessageLength = cpu_to_le32(16);\n\tresp->RequestID = buf->RequestID; /* Still LE in msg buffer */\n\tif (gen_ndis_set_resp(params, le32_to_cpu(buf->OID),\n\t\t\t((u8 *)buf) + 8 + BufOffset, BufLength, r))\n\t\tresp->Status = cpu_to_le32(RNDIS_STATUS_NOT_SUPPORTED);\n\telse\n\t\tresp->Status = cpu_to_le32(RNDIS_STATUS_SUCCESS);\n\n\tparams->resp_avail(params->v);\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,13 +5,16 @@\n \trndis_set_cmplt_type *resp;\n \trndis_resp_t *r;\n \n+\tBufLength = le32_to_cpu(buf->InformationBufferLength);\n+\tBufOffset = le32_to_cpu(buf->InformationBufferOffset);\n+\tif ((BufLength > RNDIS_MAX_TOTAL_SIZE) ||\n+\t    (BufOffset + 8 >= RNDIS_MAX_TOTAL_SIZE))\n+\t\t    return -EINVAL;\n+\n \tr = rndis_add_response(params, sizeof(rndis_set_cmplt_type));\n \tif (!r)\n \t\treturn -ENOMEM;\n \tresp = (rndis_set_cmplt_type *)r->buf;\n-\n-\tBufLength = le32_to_cpu(buf->InformationBufferLength);\n-\tBufOffset = le32_to_cpu(buf->InformationBufferOffset);\n \n #ifdef\tVERBOSE_DEBUG\n \tpr_debug(\"%s: Length: %d\\n\", __func__, BufLength);",
        "diff_line_info": {
            "deleted_lines": [
                "",
                "\tBufLength = le32_to_cpu(buf->InformationBufferLength);",
                "\tBufOffset = le32_to_cpu(buf->InformationBufferOffset);"
            ],
            "added_lines": [
                "\tBufLength = le32_to_cpu(buf->InformationBufferLength);",
                "\tBufOffset = le32_to_cpu(buf->InformationBufferOffset);",
                "\tif ((BufLength > RNDIS_MAX_TOTAL_SIZE) ||",
                "\t    (BufOffset + 8 >= RNDIS_MAX_TOTAL_SIZE))",
                "\t\t    return -EINVAL;",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2022-26127",
        "func_name": "FRRouting/frr/parse_packet",
        "description": "A buffer overflow vulnerability exists in FRRouting through 8.1.0 due to missing a check on the input packet length in the babel_packet_examin function in babeld/message.c.",
        "git_url": "https://github.com/FRRouting/frr/commit/50044ec7fe129e0a74d3a679dd29fe17ce30e6bf",
        "commit_title": "babeld: fix #10487 by adding a check on packet length",
        "commit_text": " The body length of a packet should satisfy the condition: packetlen >= bodylen + 4. Otherwise, heap overflows may happen. ",
        "func_before": "void\nparse_packet(const unsigned char *from, struct interface *ifp,\n             const unsigned char *packet, int packetlen)\n{\n    int i;\n    const unsigned char *message;\n    unsigned char type, len;\n    int bodylen;\n    struct neighbour *neigh;\n    int have_router_id = 0, have_v4_prefix = 0, have_v6_prefix = 0,\n        have_v4_nh = 0, have_v6_nh = 0;\n    unsigned char router_id[8], v4_prefix[16], v6_prefix[16],\n        v4_nh[16], v6_nh[16];\n    int have_hello_rtt = 0;\n    /* Content of the RTT sub-TLV on IHU messages. */\n    unsigned int hello_send_us = 0, hello_rtt_receive_time = 0;\n    babel_interface_nfo *babel_ifp = babel_get_if_nfo(ifp);\n\n    if(babel_ifp->flags & BABEL_IF_TIMESTAMPS) {\n        /* We want to track exactly when we received this packet. */\n        gettime(&babel_now);\n    }\n\n    if(!linklocal(from)) {\n        flog_err(EC_BABEL_PACKET,\n\t\t  \"Received packet from non-local address %s.\",\n                  format_address(from));\n        return;\n    }\n\n    if (babel_packet_examin (packet, packetlen)) {\n        flog_err(EC_BABEL_PACKET,\n\t\t  \"Received malformed packet on %s from %s.\",\n                  ifp->name, format_address(from));\n        return;\n    }\n\n    neigh = find_neighbour(from, ifp);\n    if(neigh == NULL) {\n        flog_err(EC_BABEL_PACKET, \"Couldn't allocate neighbour.\");\n        return;\n    }\n\n    DO_NTOHS(bodylen, packet + 2);\n\n    if(bodylen + 4 > packetlen) {\n        flog_err(EC_BABEL_PACKET, \"Received truncated packet (%d + 4 > %d).\",\n                 bodylen, packetlen);\n        bodylen = packetlen - 4;\n    }\n\n    i = 0;\n    while(i < bodylen) {\n        message = packet + 4 + i;\n        type = message[0];\n        if(type == MESSAGE_PAD1) {\n            debugf(BABEL_DEBUG_COMMON,\"Received pad1 from %s on %s.\",\n                   format_address(from), ifp->name);\n            i++;\n            continue;\n        }\n        len = message[1];\n\n        if(type == MESSAGE_PADN) {\n            debugf(BABEL_DEBUG_COMMON,\"Received pad%d from %s on %s.\",\n                   len, format_address(from), ifp->name);\n        } else if(type == MESSAGE_ACK_REQ) {\n            unsigned short nonce, interval;\n            DO_NTOHS(nonce, message + 4);\n            DO_NTOHS(interval, message + 6);\n            debugf(BABEL_DEBUG_COMMON,\"Received ack-req (%04X %d) from %s on %s.\",\n                   nonce, interval, format_address(from), ifp->name);\n            send_ack(neigh, nonce, interval);\n        } else if(type == MESSAGE_ACK) {\n            debugf(BABEL_DEBUG_COMMON,\"Received ack from %s on %s.\",\n                   format_address(from), ifp->name);\n            /* Nothing right now */\n        } else if(type == MESSAGE_HELLO) {\n            unsigned short seqno, interval;\n            int changed;\n            unsigned int timestamp = 0;\n            DO_NTOHS(seqno, message + 4);\n            DO_NTOHS(interval, message + 6);\n            debugf(BABEL_DEBUG_COMMON,\"Received hello %d (%d) from %s on %s.\",\n                   seqno, interval,\n                   format_address(from), ifp->name);\n            changed = update_neighbour(neigh, seqno, interval);\n            update_neighbour_metric(neigh, changed);\n            if(interval > 0)\n                /* Multiply by 3/2 to allow hellos to expire. */\n                schedule_neighbours_check(interval * 15, 0);\n            /* Sub-TLV handling. */\n            if(len > 8) {\n                if(parse_hello_subtlv(message + 8, len - 6, &timestamp) > 0) {\n                    neigh->hello_send_us = timestamp;\n                    neigh->hello_rtt_receive_time = babel_now;\n                    have_hello_rtt = 1;\n                }\n            }\n        } else if(type == MESSAGE_IHU) {\n            unsigned short txcost, interval;\n            unsigned char address[16];\n            int rc;\n            DO_NTOHS(txcost, message + 4);\n            DO_NTOHS(interval, message + 6);\n            rc = network_address(message[2], message + 8, len - 6, address);\n            if(rc < 0) goto fail;\n            debugf(BABEL_DEBUG_COMMON,\"Received ihu %d (%d) from %s on %s for %s.\",\n                   txcost, interval,\n                   format_address(from), ifp->name,\n                   format_address(address));\n            if(message[2] == 0 || is_interface_ll_address(ifp, address)) {\n                int changed = txcost != neigh->txcost;\n                neigh->txcost = txcost;\n                neigh->ihu_time = babel_now;\n                neigh->ihu_interval = interval;\n                update_neighbour_metric(neigh, changed);\n                if(interval > 0)\n                    /* Multiply by 3/2 to allow neighbours to expire. */\n                    schedule_neighbours_check(interval * 45, 0);\n                /* RTT sub-TLV. */\n                if(len > 10 + rc)\n                    parse_ihu_subtlv(message + 8 + rc, len - 6 - rc,\n                                     &hello_send_us, &hello_rtt_receive_time);\n            }\n        } else if(type == MESSAGE_ROUTER_ID) {\n            memcpy(router_id, message + 4, 8);\n            have_router_id = 1;\n            debugf(BABEL_DEBUG_COMMON,\"Received router-id %s from %s on %s.\",\n                   format_eui64(router_id), format_address(from), ifp->name);\n        } else if(type == MESSAGE_NH) {\n            unsigned char nh[16];\n            int rc;\n            rc = network_address(message[2], message + 4, len - 2,\n                                 nh);\n            if(rc < 0) {\n                have_v4_nh = 0;\n                have_v6_nh = 0;\n                goto fail;\n            }\n            debugf(BABEL_DEBUG_COMMON,\"Received nh %s (%d) from %s on %s.\",\n                   format_address(nh), message[2],\n                   format_address(from), ifp->name);\n            if(message[2] == 1) {\n                memcpy(v4_nh, nh, 16);\n                have_v4_nh = 1;\n            } else {\n                memcpy(v6_nh, nh, 16);\n                have_v6_nh = 1;\n            }\n        } else if(type == MESSAGE_UPDATE) {\n            unsigned char prefix[16], *nh;\n            unsigned char plen;\n            unsigned char channels[DIVERSITY_HOPS];\n            unsigned short interval, seqno, metric;\n            int rc, parsed_len;\n            DO_NTOHS(interval, message + 6);\n            DO_NTOHS(seqno, message + 8);\n            DO_NTOHS(metric, message + 10);\n            if(message[5] == 0 ||\n               (message[2] == 1 ? have_v4_prefix : have_v6_prefix))\n                rc = network_prefix(message[2], message[4], message[5],\n                                    message + 12,\n                                    message[2] == 1 ? v4_prefix : v6_prefix,\n                                    len - 10, prefix);\n            else\n                rc = -1;\n            if(rc < 0) {\n                if(message[3] & 0x80)\n                    have_v4_prefix = have_v6_prefix = 0;\n                goto fail;\n            }\n            parsed_len = 10 + rc;\n\n            plen = message[4] + (message[2] == 1 ? 96 : 0);\n\n            if(message[3] & 0x80) {\n                if(message[2] == 1) {\n                    memcpy(v4_prefix, prefix, 16);\n                    have_v4_prefix = 1;\n                } else {\n                    memcpy(v6_prefix, prefix, 16);\n                    have_v6_prefix = 1;\n                }\n            }\n            if(message[3] & 0x40) {\n                if(message[2] == 1) {\n                    memset(router_id, 0, 4);\n                    memcpy(router_id + 4, prefix + 12, 4);\n                } else {\n                    memcpy(router_id, prefix + 8, 8);\n                }\n                have_router_id = 1;\n            }\n            if(!have_router_id && message[2] != 0) {\n                flog_err(EC_BABEL_PACKET,\n\t\t\t  \"Received prefix with no router id.\");\n                goto fail;\n            }\n            debugf(BABEL_DEBUG_COMMON,\"Received update%s%s for %s from %s on %s.\",\n                   (message[3] & 0x80) ? \"/prefix\" : \"\",\n                   (message[3] & 0x40) ? \"/id\" : \"\",\n                   format_prefix(prefix, plen),\n                   format_address(from), ifp->name);\n\n            if(message[2] == 0) {\n                if(metric < 0xFFFF) {\n                    flog_err(EC_BABEL_PACKET,\n\t\t\t      \"Received wildcard update with finite metric.\");\n                    goto done;\n                }\n                retract_neighbour_routes(neigh);\n                goto done;\n            } else if(message[2] == 1) {\n                if(!have_v4_nh)\n                    goto fail;\n                nh = v4_nh;\n            } else if(have_v6_nh) {\n                nh = v6_nh;\n            } else {\n                nh = neigh->address;\n            }\n\n            if(message[2] == 1) {\n                if(!babel_get_if_nfo(ifp)->ipv4)\n                    goto done;\n            }\n\n            if((babel_get_if_nfo(ifp)->flags & BABEL_IF_FARAWAY)) {\n                channels[0] = 0;\n            } else {\n                /* This will be overwritten by parse_update_subtlv below. */\n                if(metric < 256) {\n                    /* Assume non-interfering (wired) link. */\n                    channels[0] = 0;\n                } else {\n                    /* Assume interfering. */\n                    channels[0] = BABEL_IF_CHANNEL_INTERFERING;\n                    channels[1] = 0;\n                }\n\n                if(parsed_len < len)\n                    parse_update_subtlv(message + 2 + parsed_len,\n                                        len - parsed_len, channels);\n            }\n\n            update_route(router_id, prefix, plen, seqno, metric, interval,\n                         neigh, nh,\n                         channels, channels_len(channels));\n        } else if(type == MESSAGE_REQUEST) {\n            unsigned char prefix[16], plen;\n            int rc;\n            rc = network_prefix(message[2], message[3], 0,\n                                message + 4, NULL, len - 2, prefix);\n            if(rc < 0) goto fail;\n            plen = message[3] + (message[2] == 1 ? 96 : 0);\n            debugf(BABEL_DEBUG_COMMON,\"Received request for %s from %s on %s.\",\n                   message[2] == 0 ? \"any\" : format_prefix(prefix, plen),\n                   format_address(from), ifp->name);\n            if(message[2] == 0) {\n                struct babel_interface *neigh_ifp =babel_get_if_nfo(neigh->ifp);\n                /* If a neighbour is requesting a full route dump from us,\n                   we might as well send it an IHU. */\n                send_ihu(neigh, NULL);\n                /* Since nodes send wildcard requests on boot, booting\n                   a large number of nodes at the same time may cause an\n                   update storm.  Ignore a wildcard request that happens\n                   shortly after we sent a full update. */\n                if(neigh_ifp->last_update_time <\n                   (time_t)(babel_now.tv_sec -\n                            MAX(neigh_ifp->hello_interval / 100, 1)))\n                    send_update(neigh->ifp, 0, NULL, 0);\n            } else {\n                send_update(neigh->ifp, 0, prefix, plen);\n            }\n        } else if(type == MESSAGE_MH_REQUEST) {\n            unsigned char prefix[16], plen;\n            unsigned short seqno;\n            int rc;\n            DO_NTOHS(seqno, message + 4);\n            rc = network_prefix(message[2], message[3], 0,\n                                message + 16, NULL, len - 14, prefix);\n            if(rc < 0) goto fail;\n            plen = message[3] + (message[2] == 1 ? 96 : 0);\n            debugf(BABEL_DEBUG_COMMON,\"Received request (%d) for %s from %s on %s (%s, %d).\",\n                   message[6],\n                   format_prefix(prefix, plen),\n                   format_address(from), ifp->name,\n                   format_eui64(message + 8), seqno);\n            handle_request(neigh, prefix, plen, message[6],\n                           seqno, message + 8);\n        } else {\n            debugf(BABEL_DEBUG_COMMON,\"Received unknown packet type %d from %s on %s.\",\n                   type, format_address(from), ifp->name);\n        }\n    done:\n        i += len + 2;\n        continue;\n\n    fail:\n        flog_err(EC_BABEL_PACKET,\n\t\t  \"Couldn't parse packet (%d, %d) from %s on %s.\",\n                  message[0], message[1], format_address(from), ifp->name);\n        goto done;\n    }\n\n    /* We can calculate the RTT to this neighbour. */\n    if(have_hello_rtt && hello_send_us && hello_rtt_receive_time) {\n        int remote_waiting_us, local_waiting_us;\n        unsigned int rtt, smoothed_rtt;\n        unsigned int old_rttcost;\n        int changed = 0;\n        remote_waiting_us = neigh->hello_send_us - hello_rtt_receive_time;\n        local_waiting_us = time_us(neigh->hello_rtt_receive_time) -\n            hello_send_us;\n\n        /* Sanity checks (validity window of 10 minutes). */\n        if(remote_waiting_us < 0 || local_waiting_us < 0 ||\n           remote_waiting_us > 600000000 || local_waiting_us > 600000000)\n            return;\n\n        rtt = MAX(0, local_waiting_us - remote_waiting_us);\n        debugf(BABEL_DEBUG_COMMON, \"RTT to %s on %s sample result: %d us.\",\n               format_address(from), ifp->name, rtt);\n\n        old_rttcost = neighbour_rttcost(neigh);\n        if (valid_rtt(neigh)) {\n            /* Running exponential average. */\n            smoothed_rtt = (babel_ifp->rtt_decay * rtt +\n\t\t\t    (256 - babel_ifp->rtt_decay) * neigh->rtt);\n            /* Rounding (up or down) to get closer to the sample. */\n            neigh->rtt = (neigh->rtt >= rtt) ? smoothed_rtt / 256 :\n                (smoothed_rtt + 255) / 256;\n        } else {\n            /* We prefer to be conservative with new neighbours\n               (higher RTT) */\n            assert(rtt <= 0x7FFFFFFF);\n            neigh->rtt = 2*rtt;\n        }\n        changed = (neighbour_rttcost(neigh) == old_rttcost ? 0 : 1);\n        update_neighbour_metric(neigh, changed);\n        neigh->rtt_time = babel_now;\n    }\n    return;\n}",
        "func": "void\nparse_packet(const unsigned char *from, struct interface *ifp,\n             const unsigned char *packet, int packetlen)\n{\n    int i;\n    const unsigned char *message;\n    unsigned char type, len;\n    int bodylen;\n    struct neighbour *neigh;\n    int have_router_id = 0, have_v4_prefix = 0, have_v6_prefix = 0,\n        have_v4_nh = 0, have_v6_nh = 0;\n    unsigned char router_id[8], v4_prefix[16], v6_prefix[16],\n        v4_nh[16], v6_nh[16];\n    int have_hello_rtt = 0;\n    /* Content of the RTT sub-TLV on IHU messages. */\n    unsigned int hello_send_us = 0, hello_rtt_receive_time = 0;\n    babel_interface_nfo *babel_ifp = babel_get_if_nfo(ifp);\n\n    if(babel_ifp->flags & BABEL_IF_TIMESTAMPS) {\n        /* We want to track exactly when we received this packet. */\n        gettime(&babel_now);\n    }\n\n    if(!linklocal(from)) {\n        flog_err(EC_BABEL_PACKET,\n\t\t  \"Received packet from non-local address %s.\",\n                  format_address(from));\n        return;\n    }\n\n    if (babel_packet_examin (packet, packetlen)) {\n        flog_err(EC_BABEL_PACKET,\n\t\t  \"Received malformed packet on %s from %s.\",\n                  ifp->name, format_address(from));\n        return;\n    }\n\n    neigh = find_neighbour(from, ifp);\n    if(neigh == NULL) {\n        flog_err(EC_BABEL_PACKET, \"Couldn't allocate neighbour.\");\n        return;\n    }\n\n    DO_NTOHS(bodylen, packet + 2);\n\n    i = 0;\n    while(i < bodylen) {\n        message = packet + 4 + i;\n        type = message[0];\n        if(type == MESSAGE_PAD1) {\n            debugf(BABEL_DEBUG_COMMON,\"Received pad1 from %s on %s.\",\n                   format_address(from), ifp->name);\n            i++;\n            continue;\n        }\n        len = message[1];\n\n        if(type == MESSAGE_PADN) {\n            debugf(BABEL_DEBUG_COMMON,\"Received pad%d from %s on %s.\",\n                   len, format_address(from), ifp->name);\n        } else if(type == MESSAGE_ACK_REQ) {\n            unsigned short nonce, interval;\n            DO_NTOHS(nonce, message + 4);\n            DO_NTOHS(interval, message + 6);\n            debugf(BABEL_DEBUG_COMMON,\"Received ack-req (%04X %d) from %s on %s.\",\n                   nonce, interval, format_address(from), ifp->name);\n            send_ack(neigh, nonce, interval);\n        } else if(type == MESSAGE_ACK) {\n            debugf(BABEL_DEBUG_COMMON,\"Received ack from %s on %s.\",\n                   format_address(from), ifp->name);\n            /* Nothing right now */\n        } else if(type == MESSAGE_HELLO) {\n            unsigned short seqno, interval;\n            int changed;\n            unsigned int timestamp = 0;\n            DO_NTOHS(seqno, message + 4);\n            DO_NTOHS(interval, message + 6);\n            debugf(BABEL_DEBUG_COMMON,\"Received hello %d (%d) from %s on %s.\",\n                   seqno, interval,\n                   format_address(from), ifp->name);\n            changed = update_neighbour(neigh, seqno, interval);\n            update_neighbour_metric(neigh, changed);\n            if(interval > 0)\n                /* Multiply by 3/2 to allow hellos to expire. */\n                schedule_neighbours_check(interval * 15, 0);\n            /* Sub-TLV handling. */\n            if(len > 8) {\n                if(parse_hello_subtlv(message + 8, len - 6, &timestamp) > 0) {\n                    neigh->hello_send_us = timestamp;\n                    neigh->hello_rtt_receive_time = babel_now;\n                    have_hello_rtt = 1;\n                }\n            }\n        } else if(type == MESSAGE_IHU) {\n            unsigned short txcost, interval;\n            unsigned char address[16];\n            int rc;\n            DO_NTOHS(txcost, message + 4);\n            DO_NTOHS(interval, message + 6);\n            rc = network_address(message[2], message + 8, len - 6, address);\n            if(rc < 0) goto fail;\n            debugf(BABEL_DEBUG_COMMON,\"Received ihu %d (%d) from %s on %s for %s.\",\n                   txcost, interval,\n                   format_address(from), ifp->name,\n                   format_address(address));\n            if(message[2] == 0 || is_interface_ll_address(ifp, address)) {\n                int changed = txcost != neigh->txcost;\n                neigh->txcost = txcost;\n                neigh->ihu_time = babel_now;\n                neigh->ihu_interval = interval;\n                update_neighbour_metric(neigh, changed);\n                if(interval > 0)\n                    /* Multiply by 3/2 to allow neighbours to expire. */\n                    schedule_neighbours_check(interval * 45, 0);\n                /* RTT sub-TLV. */\n                if(len > 10 + rc)\n                    parse_ihu_subtlv(message + 8 + rc, len - 6 - rc,\n                                     &hello_send_us, &hello_rtt_receive_time);\n            }\n        } else if(type == MESSAGE_ROUTER_ID) {\n            memcpy(router_id, message + 4, 8);\n            have_router_id = 1;\n            debugf(BABEL_DEBUG_COMMON,\"Received router-id %s from %s on %s.\",\n                   format_eui64(router_id), format_address(from), ifp->name);\n        } else if(type == MESSAGE_NH) {\n            unsigned char nh[16];\n            int rc;\n            rc = network_address(message[2], message + 4, len - 2,\n                                 nh);\n            if(rc < 0) {\n                have_v4_nh = 0;\n                have_v6_nh = 0;\n                goto fail;\n            }\n            debugf(BABEL_DEBUG_COMMON,\"Received nh %s (%d) from %s on %s.\",\n                   format_address(nh), message[2],\n                   format_address(from), ifp->name);\n            if(message[2] == 1) {\n                memcpy(v4_nh, nh, 16);\n                have_v4_nh = 1;\n            } else {\n                memcpy(v6_nh, nh, 16);\n                have_v6_nh = 1;\n            }\n        } else if(type == MESSAGE_UPDATE) {\n            unsigned char prefix[16], *nh;\n            unsigned char plen;\n            unsigned char channels[DIVERSITY_HOPS];\n            unsigned short interval, seqno, metric;\n            int rc, parsed_len;\n            DO_NTOHS(interval, message + 6);\n            DO_NTOHS(seqno, message + 8);\n            DO_NTOHS(metric, message + 10);\n            if(message[5] == 0 ||\n               (message[2] == 1 ? have_v4_prefix : have_v6_prefix))\n                rc = network_prefix(message[2], message[4], message[5],\n                                    message + 12,\n                                    message[2] == 1 ? v4_prefix : v6_prefix,\n                                    len - 10, prefix);\n            else\n                rc = -1;\n            if(rc < 0) {\n                if(message[3] & 0x80)\n                    have_v4_prefix = have_v6_prefix = 0;\n                goto fail;\n            }\n            parsed_len = 10 + rc;\n\n            plen = message[4] + (message[2] == 1 ? 96 : 0);\n\n            if(message[3] & 0x80) {\n                if(message[2] == 1) {\n                    memcpy(v4_prefix, prefix, 16);\n                    have_v4_prefix = 1;\n                } else {\n                    memcpy(v6_prefix, prefix, 16);\n                    have_v6_prefix = 1;\n                }\n            }\n            if(message[3] & 0x40) {\n                if(message[2] == 1) {\n                    memset(router_id, 0, 4);\n                    memcpy(router_id + 4, prefix + 12, 4);\n                } else {\n                    memcpy(router_id, prefix + 8, 8);\n                }\n                have_router_id = 1;\n            }\n            if(!have_router_id && message[2] != 0) {\n                flog_err(EC_BABEL_PACKET,\n\t\t\t  \"Received prefix with no router id.\");\n                goto fail;\n            }\n            debugf(BABEL_DEBUG_COMMON,\"Received update%s%s for %s from %s on %s.\",\n                   (message[3] & 0x80) ? \"/prefix\" : \"\",\n                   (message[3] & 0x40) ? \"/id\" : \"\",\n                   format_prefix(prefix, plen),\n                   format_address(from), ifp->name);\n\n            if(message[2] == 0) {\n                if(metric < 0xFFFF) {\n                    flog_err(EC_BABEL_PACKET,\n\t\t\t      \"Received wildcard update with finite metric.\");\n                    goto done;\n                }\n                retract_neighbour_routes(neigh);\n                goto done;\n            } else if(message[2] == 1) {\n                if(!have_v4_nh)\n                    goto fail;\n                nh = v4_nh;\n            } else if(have_v6_nh) {\n                nh = v6_nh;\n            } else {\n                nh = neigh->address;\n            }\n\n            if(message[2] == 1) {\n                if(!babel_get_if_nfo(ifp)->ipv4)\n                    goto done;\n            }\n\n            if((babel_get_if_nfo(ifp)->flags & BABEL_IF_FARAWAY)) {\n                channels[0] = 0;\n            } else {\n                /* This will be overwritten by parse_update_subtlv below. */\n                if(metric < 256) {\n                    /* Assume non-interfering (wired) link. */\n                    channels[0] = 0;\n                } else {\n                    /* Assume interfering. */\n                    channels[0] = BABEL_IF_CHANNEL_INTERFERING;\n                    channels[1] = 0;\n                }\n\n                if(parsed_len < len)\n                    parse_update_subtlv(message + 2 + parsed_len,\n                                        len - parsed_len, channels);\n            }\n\n            update_route(router_id, prefix, plen, seqno, metric, interval,\n                         neigh, nh,\n                         channels, channels_len(channels));\n        } else if(type == MESSAGE_REQUEST) {\n            unsigned char prefix[16], plen;\n            int rc;\n            rc = network_prefix(message[2], message[3], 0,\n                                message + 4, NULL, len - 2, prefix);\n            if(rc < 0) goto fail;\n            plen = message[3] + (message[2] == 1 ? 96 : 0);\n            debugf(BABEL_DEBUG_COMMON,\"Received request for %s from %s on %s.\",\n                   message[2] == 0 ? \"any\" : format_prefix(prefix, plen),\n                   format_address(from), ifp->name);\n            if(message[2] == 0) {\n                struct babel_interface *neigh_ifp =babel_get_if_nfo(neigh->ifp);\n                /* If a neighbour is requesting a full route dump from us,\n                   we might as well send it an IHU. */\n                send_ihu(neigh, NULL);\n                /* Since nodes send wildcard requests on boot, booting\n                   a large number of nodes at the same time may cause an\n                   update storm.  Ignore a wildcard request that happens\n                   shortly after we sent a full update. */\n                if(neigh_ifp->last_update_time <\n                   (time_t)(babel_now.tv_sec -\n                            MAX(neigh_ifp->hello_interval / 100, 1)))\n                    send_update(neigh->ifp, 0, NULL, 0);\n            } else {\n                send_update(neigh->ifp, 0, prefix, plen);\n            }\n        } else if(type == MESSAGE_MH_REQUEST) {\n            unsigned char prefix[16], plen;\n            unsigned short seqno;\n            int rc;\n            DO_NTOHS(seqno, message + 4);\n            rc = network_prefix(message[2], message[3], 0,\n                                message + 16, NULL, len - 14, prefix);\n            if(rc < 0) goto fail;\n            plen = message[3] + (message[2] == 1 ? 96 : 0);\n            debugf(BABEL_DEBUG_COMMON,\"Received request (%d) for %s from %s on %s (%s, %d).\",\n                   message[6],\n                   format_prefix(prefix, plen),\n                   format_address(from), ifp->name,\n                   format_eui64(message + 8), seqno);\n            handle_request(neigh, prefix, plen, message[6],\n                           seqno, message + 8);\n        } else {\n            debugf(BABEL_DEBUG_COMMON,\"Received unknown packet type %d from %s on %s.\",\n                   type, format_address(from), ifp->name);\n        }\n    done:\n        i += len + 2;\n        continue;\n\n    fail:\n        flog_err(EC_BABEL_PACKET,\n\t\t  \"Couldn't parse packet (%d, %d) from %s on %s.\",\n                  message[0], message[1], format_address(from), ifp->name);\n        goto done;\n    }\n\n    /* We can calculate the RTT to this neighbour. */\n    if(have_hello_rtt && hello_send_us && hello_rtt_receive_time) {\n        int remote_waiting_us, local_waiting_us;\n        unsigned int rtt, smoothed_rtt;\n        unsigned int old_rttcost;\n        int changed = 0;\n        remote_waiting_us = neigh->hello_send_us - hello_rtt_receive_time;\n        local_waiting_us = time_us(neigh->hello_rtt_receive_time) -\n            hello_send_us;\n\n        /* Sanity checks (validity window of 10 minutes). */\n        if(remote_waiting_us < 0 || local_waiting_us < 0 ||\n           remote_waiting_us > 600000000 || local_waiting_us > 600000000)\n            return;\n\n        rtt = MAX(0, local_waiting_us - remote_waiting_us);\n        debugf(BABEL_DEBUG_COMMON, \"RTT to %s on %s sample result: %d us.\",\n               format_address(from), ifp->name, rtt);\n\n        old_rttcost = neighbour_rttcost(neigh);\n        if (valid_rtt(neigh)) {\n            /* Running exponential average. */\n            smoothed_rtt = (babel_ifp->rtt_decay * rtt +\n\t\t\t    (256 - babel_ifp->rtt_decay) * neigh->rtt);\n            /* Rounding (up or down) to get closer to the sample. */\n            neigh->rtt = (neigh->rtt >= rtt) ? smoothed_rtt / 256 :\n                (smoothed_rtt + 255) / 256;\n        } else {\n            /* We prefer to be conservative with new neighbours\n               (higher RTT) */\n            assert(rtt <= 0x7FFFFFFF);\n            neigh->rtt = 2*rtt;\n        }\n        changed = (neighbour_rttcost(neigh) == old_rttcost ? 0 : 1);\n        update_neighbour_metric(neigh, changed);\n        neigh->rtt_time = babel_now;\n    }\n    return;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -42,12 +42,6 @@\n     }\n \n     DO_NTOHS(bodylen, packet + 2);\n-\n-    if(bodylen + 4 > packetlen) {\n-        flog_err(EC_BABEL_PACKET, \"Received truncated packet (%d + 4 > %d).\",\n-                 bodylen, packetlen);\n-        bodylen = packetlen - 4;\n-    }\n \n     i = 0;\n     while(i < bodylen) {",
        "diff_line_info": {
            "deleted_lines": [
                "",
                "    if(bodylen + 4 > packetlen) {",
                "        flog_err(EC_BABEL_PACKET, \"Received truncated packet (%d + 4 > %d).\",",
                "                 bodylen, packetlen);",
                "        bodylen = packetlen - 4;",
                "    }"
            ],
            "added_lines": []
        }
    },
    {
        "cve_id": "CVE-2022-26127",
        "func_name": "FRRouting/frr/babel_packet_examin",
        "description": "A buffer overflow vulnerability exists in FRRouting through 8.1.0 due to missing a check on the input packet length in the babel_packet_examin function in babeld/message.c.",
        "git_url": "https://github.com/FRRouting/frr/commit/50044ec7fe129e0a74d3a679dd29fe17ce30e6bf",
        "commit_title": "babeld: fix #10487 by adding a check on packet length",
        "commit_text": " The body length of a packet should satisfy the condition: packetlen >= bodylen + 4. Otherwise, heap overflows may happen. ",
        "func_before": "static int\nbabel_packet_examin(const unsigned char *packet, int packetlen)\n{\n    unsigned i = 0, bodylen;\n    const unsigned char *message;\n    unsigned char type, len;\n\n    if(packetlen < 4 || packet[0] != 42 || packet[1] != 2)\n        return 1;\n    DO_NTOHS(bodylen, packet + 2);\n    while (i < bodylen){\n        message = packet + 4 + i;\n        type = message[0];\n        if(type == MESSAGE_PAD1) {\n            i++;\n            continue;\n        }\n        if(i + 1 > bodylen) {\n            debugf(BABEL_DEBUG_COMMON,\"Received truncated message.\");\n            return 1;\n        }\n        len = message[1];\n        if(i + len > bodylen) {\n            debugf(BABEL_DEBUG_COMMON,\"Received truncated message.\");\n            return 1;\n        }\n        /* not Pad1 */\n        if(type <= MESSAGE_MAX && tlv_min_length[type] && len < tlv_min_length[type]) {\n            debugf(BABEL_DEBUG_COMMON,\"Undersized %u TLV\", type);\n            return 1;\n        }\n        i += len + 2;\n    }\n    return 0;\n}",
        "func": "static int\nbabel_packet_examin(const unsigned char *packet, int packetlen)\n{\n    int i = 0, bodylen;\n    const unsigned char *message;\n    unsigned char type, len;\n\n    if(packetlen < 4 || packet[0] != 42 || packet[1] != 2)\n        return 1;\n    DO_NTOHS(bodylen, packet + 2);\n    if(bodylen + 4 > packetlen) {\n        debugf(BABEL_DEBUG_COMMON, \"Received truncated packet (%d + 4 > %d).\",\n                 bodylen, packetlen);\n        return 1;\n    }\n    while (i < bodylen){\n        message = packet + 4 + i;\n        type = message[0];\n        if(type == MESSAGE_PAD1) {\n            i++;\n            continue;\n        }\n        if(i + 1 > bodylen) {\n            debugf(BABEL_DEBUG_COMMON,\"Received truncated message.\");\n            return 1;\n        }\n        len = message[1];\n        if(i + len > bodylen) {\n            debugf(BABEL_DEBUG_COMMON,\"Received truncated message.\");\n            return 1;\n        }\n        /* not Pad1 */\n        if(type <= MESSAGE_MAX && tlv_min_length[type] && len < tlv_min_length[type]) {\n            debugf(BABEL_DEBUG_COMMON,\"Undersized %u TLV\", type);\n            return 1;\n        }\n        i += len + 2;\n    }\n    return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,13 +1,18 @@\n static int\n babel_packet_examin(const unsigned char *packet, int packetlen)\n {\n-    unsigned i = 0, bodylen;\n+    int i = 0, bodylen;\n     const unsigned char *message;\n     unsigned char type, len;\n \n     if(packetlen < 4 || packet[0] != 42 || packet[1] != 2)\n         return 1;\n     DO_NTOHS(bodylen, packet + 2);\n+    if(bodylen + 4 > packetlen) {\n+        debugf(BABEL_DEBUG_COMMON, \"Received truncated packet (%d + 4 > %d).\",\n+                 bodylen, packetlen);\n+        return 1;\n+    }\n     while (i < bodylen){\n         message = packet + 4 + i;\n         type = message[0];",
        "diff_line_info": {
            "deleted_lines": [
                "    unsigned i = 0, bodylen;"
            ],
            "added_lines": [
                "    int i = 0, bodylen;",
                "    if(bodylen + 4 > packetlen) {",
                "        debugf(BABEL_DEBUG_COMMON, \"Received truncated packet (%d + 4 > %d).\",",
                "                 bodylen, packetlen);",
                "        return 1;",
                "    }"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-26128",
        "func_name": "FRRouting/frr/parse_ihu_subtlv",
        "description": "A buffer overflow vulnerability exists in FRRouting through 8.1.0 due to a wrong check on the input packet length in the babel_packet_examin function in babeld/message.c.",
        "git_url": "https://github.com/FRRouting/frr/commit/c3793352a8d76d2eee1edc38a9a16c1c8a6573f4",
        "commit_title": "babeld: fix #10502 #10503 by repairing the checks on length",
        "commit_text": " This patch repairs the checking conditions on length in four functions: babel_packet_examin, parse_hello_subtlv, parse_ihu_subtlv, and parse_update_subtlv ",
        "func_before": "static int\nparse_ihu_subtlv(const unsigned char *a, int alen,\n                 unsigned int *hello_send_us,\n                 unsigned int *hello_rtt_receive_time)\n{\n    int type, len, i = 0, ret = 0;\n\n    while(i < alen) {\n        type = a[0];\n        if(type == SUBTLV_PAD1) {\n            i++;\n            continue;\n        }\n\n        if(i + 1 > alen) {\n            flog_err(EC_BABEL_PACKET,\n\t\t      \"Received truncated sub-TLV on IHU message.\");\n            return -1;\n        }\n        len = a[i + 1];\n        if(i + len > alen) {\n            flog_err(EC_BABEL_PACKET,\n\t\t      \"Received truncated sub-TLV on IHU message.\");\n            return -1;\n        }\n\n        if(type == SUBTLV_PADN) {\n            /* Nothing to do. */\n        } else if(type == SUBTLV_TIMESTAMP) {\n            if(len >= 8) {\n                DO_NTOHL(*hello_send_us, a + i + 2);\n                DO_NTOHL(*hello_rtt_receive_time, a + i + 6);\n                ret = 1;\n            }\n            else {\n                flog_err(EC_BABEL_PACKET,\n\t\t\t  \"Received incorrect RTT sub-TLV on IHU message.\");\n            }\n        } else {\n            debugf(BABEL_DEBUG_COMMON,\n                   \"Received unknown IHU sub-TLV type %d.\", type);\n        }\n\n        i += len + 2;\n    }\n    return ret;\n}",
        "func": "static int\nparse_ihu_subtlv(const unsigned char *a, int alen,\n                 unsigned int *hello_send_us,\n                 unsigned int *hello_rtt_receive_time)\n{\n    int type, len, i = 0, ret = 0;\n\n    while(i < alen) {\n        type = a[i];\n        if(type == SUBTLV_PAD1) {\n            i++;\n            continue;\n        }\n\n        if(i + 1 >= alen) {\n            flog_err(EC_BABEL_PACKET,\n\t\t      \"Received truncated sub-TLV on IHU message.\");\n            return -1;\n        }\n        len = a[i + 1];\n        if(i + len + 2 > alen) {\n            flog_err(EC_BABEL_PACKET,\n\t\t      \"Received truncated sub-TLV on IHU message.\");\n            return -1;\n        }\n\n        if(type == SUBTLV_PADN) {\n            /* Nothing to do. */\n        } else if(type == SUBTLV_TIMESTAMP) {\n            if(len >= 8) {\n                DO_NTOHL(*hello_send_us, a + i + 2);\n                DO_NTOHL(*hello_rtt_receive_time, a + i + 6);\n                ret = 1;\n            }\n            else {\n                flog_err(EC_BABEL_PACKET,\n\t\t\t  \"Received incorrect RTT sub-TLV on IHU message.\");\n            }\n        } else {\n            debugf(BABEL_DEBUG_COMMON,\n                   \"Received unknown IHU sub-TLV type %d.\", type);\n        }\n\n        i += len + 2;\n    }\n    return ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -6,19 +6,19 @@\n     int type, len, i = 0, ret = 0;\n \n     while(i < alen) {\n-        type = a[0];\n+        type = a[i];\n         if(type == SUBTLV_PAD1) {\n             i++;\n             continue;\n         }\n \n-        if(i + 1 > alen) {\n+        if(i + 1 >= alen) {\n             flog_err(EC_BABEL_PACKET,\n \t\t      \"Received truncated sub-TLV on IHU message.\");\n             return -1;\n         }\n         len = a[i + 1];\n-        if(i + len > alen) {\n+        if(i + len + 2 > alen) {\n             flog_err(EC_BABEL_PACKET,\n \t\t      \"Received truncated sub-TLV on IHU message.\");\n             return -1;",
        "diff_line_info": {
            "deleted_lines": [
                "        type = a[0];",
                "        if(i + 1 > alen) {",
                "        if(i + len > alen) {"
            ],
            "added_lines": [
                "        type = a[i];",
                "        if(i + 1 >= alen) {",
                "        if(i + len + 2 > alen) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-26128",
        "func_name": "FRRouting/frr/parse_update_subtlv",
        "description": "A buffer overflow vulnerability exists in FRRouting through 8.1.0 due to a wrong check on the input packet length in the babel_packet_examin function in babeld/message.c.",
        "git_url": "https://github.com/FRRouting/frr/commit/c3793352a8d76d2eee1edc38a9a16c1c8a6573f4",
        "commit_title": "babeld: fix #10502 #10503 by repairing the checks on length",
        "commit_text": " This patch repairs the checking conditions on length in four functions: babel_packet_examin, parse_hello_subtlv, parse_ihu_subtlv, and parse_update_subtlv ",
        "func_before": "static void\nparse_update_subtlv(const unsigned char *a, int alen,\n                    unsigned char *channels)\n{\n    int type, len, i = 0;\n\n    while(i < alen) {\n        type = a[i];\n        if(type == SUBTLV_PAD1) {\n            i++;\n            continue;\n        }\n\n        if(i + 1 > alen) {\n            flog_err(EC_BABEL_PACKET, \"Received truncated attributes.\");\n            return;\n        }\n        len = a[i + 1];\n        if(i + len > alen) {\n            flog_err(EC_BABEL_PACKET, \"Received truncated attributes.\");\n            return;\n        }\n\n        if(type == SUBTLV_PADN) {\n            /* Nothing. */\n        } else if(type == SUBTLV_DIVERSITY) {\n            if(len > DIVERSITY_HOPS) {\n                flog_err(EC_BABEL_PACKET,\n\t\t\t  \"Received overlong channel information (%d > %d).n\",\n                          len, DIVERSITY_HOPS);\n                len = DIVERSITY_HOPS;\n            }\n            if(memchr(a + i + 2, 0, len) != NULL) {\n                /* 0 is reserved. */\n                flog_err(EC_BABEL_PACKET, \"Channel information contains 0!\");\n                return;\n            }\n            memset(channels, 0, DIVERSITY_HOPS);\n            memcpy(channels, a + i + 2, len);\n        } else {\n            debugf(BABEL_DEBUG_COMMON,\n                   \"Received unknown route attribute %d.\", type);\n        }\n\n        i += len + 2;\n    }\n}",
        "func": "static void\nparse_update_subtlv(const unsigned char *a, int alen,\n                    unsigned char *channels)\n{\n    int type, len, i = 0;\n\n    while(i < alen) {\n        type = a[i];\n        if(type == SUBTLV_PAD1) {\n            i++;\n            continue;\n        }\n\n        if(i + 1 >= alen) {\n            flog_err(EC_BABEL_PACKET, \"Received truncated attributes.\");\n            return;\n        }\n        len = a[i + 1];\n        if(i + len + 2 > alen) {\n            flog_err(EC_BABEL_PACKET, \"Received truncated attributes.\");\n            return;\n        }\n\n        if(type == SUBTLV_PADN) {\n            /* Nothing. */\n        } else if(type == SUBTLV_DIVERSITY) {\n            if(len > DIVERSITY_HOPS) {\n                flog_err(EC_BABEL_PACKET,\n\t\t\t  \"Received overlong channel information (%d > %d).n\",\n                          len, DIVERSITY_HOPS);\n                len = DIVERSITY_HOPS;\n            }\n            if(memchr(a + i + 2, 0, len) != NULL) {\n                /* 0 is reserved. */\n                flog_err(EC_BABEL_PACKET, \"Channel information contains 0!\");\n                return;\n            }\n            memset(channels, 0, DIVERSITY_HOPS);\n            memcpy(channels, a + i + 2, len);\n        } else {\n            debugf(BABEL_DEBUG_COMMON,\n                   \"Received unknown route attribute %d.\", type);\n        }\n\n        i += len + 2;\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -11,12 +11,12 @@\n             continue;\n         }\n \n-        if(i + 1 > alen) {\n+        if(i + 1 >= alen) {\n             flog_err(EC_BABEL_PACKET, \"Received truncated attributes.\");\n             return;\n         }\n         len = a[i + 1];\n-        if(i + len > alen) {\n+        if(i + len + 2 > alen) {\n             flog_err(EC_BABEL_PACKET, \"Received truncated attributes.\");\n             return;\n         }",
        "diff_line_info": {
            "deleted_lines": [
                "        if(i + 1 > alen) {",
                "        if(i + len > alen) {"
            ],
            "added_lines": [
                "        if(i + 1 >= alen) {",
                "        if(i + len + 2 > alen) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-26128",
        "func_name": "FRRouting/frr/parse_hello_subtlv",
        "description": "A buffer overflow vulnerability exists in FRRouting through 8.1.0 due to a wrong check on the input packet length in the babel_packet_examin function in babeld/message.c.",
        "git_url": "https://github.com/FRRouting/frr/commit/c3793352a8d76d2eee1edc38a9a16c1c8a6573f4",
        "commit_title": "babeld: fix #10502 #10503 by repairing the checks on length",
        "commit_text": " This patch repairs the checking conditions on length in four functions: babel_packet_examin, parse_hello_subtlv, parse_ihu_subtlv, and parse_update_subtlv ",
        "func_before": "static int\nparse_hello_subtlv(const unsigned char *a, int alen,\n                   unsigned int *hello_send_us)\n{\n    int type, len, i = 0, ret = 0;\n\n    while(i < alen) {\n        type = a[0];\n        if(type == SUBTLV_PAD1) {\n            i++;\n            continue;\n        }\n\n        if(i + 1 > alen) {\n            flog_err(EC_BABEL_PACKET,\n\t\t      \"Received truncated sub-TLV on Hello message.\");\n            return -1;\n        }\n        len = a[i + 1];\n        if(i + len > alen) {\n            flog_err(EC_BABEL_PACKET,\n\t\t      \"Received truncated sub-TLV on Hello message.\");\n            return -1;\n        }\n\n        if(type == SUBTLV_PADN) {\n            /* Nothing to do. */\n        } else if(type == SUBTLV_TIMESTAMP) {\n            if(len >= 4) {\n                DO_NTOHL(*hello_send_us, a + i + 2);\n                ret = 1;\n            } else {\n                flog_err(EC_BABEL_PACKET,\n\t\t\t  \"Received incorrect RTT sub-TLV on Hello message.\");\n            }\n        } else {\n            debugf(BABEL_DEBUG_COMMON,\n                   \"Received unknown Hello sub-TLV type %d.\", type);\n        }\n\n        i += len + 2;\n    }\n    return ret;\n}",
        "func": "static int\nparse_hello_subtlv(const unsigned char *a, int alen,\n                   unsigned int *hello_send_us)\n{\n    int type, len, i = 0, ret = 0;\n\n    while(i < alen) {\n        type = a[i];\n        if(type == SUBTLV_PAD1) {\n            i++;\n            continue;\n        }\n\n        if(i + 1 >= alen) {\n            flog_err(EC_BABEL_PACKET,\n\t\t      \"Received truncated sub-TLV on Hello message.\");\n            return -1;\n        }\n        len = a[i + 1];\n        if(i + len + 2 > alen) {\n            flog_err(EC_BABEL_PACKET,\n\t\t      \"Received truncated sub-TLV on Hello message.\");\n            return -1;\n        }\n\n        if(type == SUBTLV_PADN) {\n            /* Nothing to do. */\n        } else if(type == SUBTLV_TIMESTAMP) {\n            if(len >= 4) {\n                DO_NTOHL(*hello_send_us, a + i + 2);\n                ret = 1;\n            } else {\n                flog_err(EC_BABEL_PACKET,\n\t\t\t  \"Received incorrect RTT sub-TLV on Hello message.\");\n            }\n        } else {\n            debugf(BABEL_DEBUG_COMMON,\n                   \"Received unknown Hello sub-TLV type %d.\", type);\n        }\n\n        i += len + 2;\n    }\n    return ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,19 +5,19 @@\n     int type, len, i = 0, ret = 0;\n \n     while(i < alen) {\n-        type = a[0];\n+        type = a[i];\n         if(type == SUBTLV_PAD1) {\n             i++;\n             continue;\n         }\n \n-        if(i + 1 > alen) {\n+        if(i + 1 >= alen) {\n             flog_err(EC_BABEL_PACKET,\n \t\t      \"Received truncated sub-TLV on Hello message.\");\n             return -1;\n         }\n         len = a[i + 1];\n-        if(i + len > alen) {\n+        if(i + len + 2 > alen) {\n             flog_err(EC_BABEL_PACKET,\n \t\t      \"Received truncated sub-TLV on Hello message.\");\n             return -1;",
        "diff_line_info": {
            "deleted_lines": [
                "        type = a[0];",
                "        if(i + 1 > alen) {",
                "        if(i + len > alen) {"
            ],
            "added_lines": [
                "        type = a[i];",
                "        if(i + 1 >= alen) {",
                "        if(i + len + 2 > alen) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-26128",
        "func_name": "FRRouting/frr/babel_packet_examin",
        "description": "A buffer overflow vulnerability exists in FRRouting through 8.1.0 due to a wrong check on the input packet length in the babel_packet_examin function in babeld/message.c.",
        "git_url": "https://github.com/FRRouting/frr/commit/c3793352a8d76d2eee1edc38a9a16c1c8a6573f4",
        "commit_title": "babeld: fix #10502 #10503 by repairing the checks on length",
        "commit_text": " This patch repairs the checking conditions on length in four functions: babel_packet_examin, parse_hello_subtlv, parse_ihu_subtlv, and parse_update_subtlv ",
        "func_before": "static int\nbabel_packet_examin(const unsigned char *packet, int packetlen)\n{\n    unsigned i = 0, bodylen;\n    const unsigned char *message;\n    unsigned char type, len;\n\n    if(packetlen < 4 || packet[0] != 42 || packet[1] != 2)\n        return 1;\n    DO_NTOHS(bodylen, packet + 2);\n    while (i < bodylen){\n        message = packet + 4 + i;\n        type = message[0];\n        if(type == MESSAGE_PAD1) {\n            i++;\n            continue;\n        }\n        if(i + 1 > bodylen) {\n            debugf(BABEL_DEBUG_COMMON,\"Received truncated message.\");\n            return 1;\n        }\n        len = message[1];\n        if(i + len > bodylen) {\n            debugf(BABEL_DEBUG_COMMON,\"Received truncated message.\");\n            return 1;\n        }\n        /* not Pad1 */\n        if(type <= MESSAGE_MAX && tlv_min_length[type] && len < tlv_min_length[type]) {\n            debugf(BABEL_DEBUG_COMMON,\"Undersized %u TLV\", type);\n            return 1;\n        }\n        i += len + 2;\n    }\n    return 0;\n}",
        "func": "static int\nbabel_packet_examin(const unsigned char *packet, int packetlen)\n{\n    unsigned i = 0, bodylen;\n    const unsigned char *message;\n    unsigned char type, len;\n\n    if(packetlen < 4 || packet[0] != 42 || packet[1] != 2)\n        return 1;\n    DO_NTOHS(bodylen, packet + 2);\n    while (i < bodylen){\n        message = packet + 4 + i;\n        type = message[0];\n        if(type == MESSAGE_PAD1) {\n            i++;\n            continue;\n        }\n        if(i + 2 > bodylen) {\n            debugf(BABEL_DEBUG_COMMON,\"Received truncated message.\");\n            return 1;\n        }\n        len = message[1];\n        if(i + len + 2 > bodylen) {\n            debugf(BABEL_DEBUG_COMMON,\"Received truncated message.\");\n            return 1;\n        }\n        /* not Pad1 */\n        if(type <= MESSAGE_MAX && tlv_min_length[type] && len < tlv_min_length[type]) {\n            debugf(BABEL_DEBUG_COMMON,\"Undersized %u TLV\", type);\n            return 1;\n        }\n        i += len + 2;\n    }\n    return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -15,12 +15,12 @@\n             i++;\n             continue;\n         }\n-        if(i + 1 > bodylen) {\n+        if(i + 2 > bodylen) {\n             debugf(BABEL_DEBUG_COMMON,\"Received truncated message.\");\n             return 1;\n         }\n         len = message[1];\n-        if(i + len > bodylen) {\n+        if(i + len + 2 > bodylen) {\n             debugf(BABEL_DEBUG_COMMON,\"Received truncated message.\");\n             return 1;\n         }",
        "diff_line_info": {
            "deleted_lines": [
                "        if(i + 1 > bodylen) {",
                "        if(i + len > bodylen) {"
            ],
            "added_lines": [
                "        if(i + 2 > bodylen) {",
                "        if(i + len + 2 > bodylen) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-29196",
        "func_name": "tensorflow/Compute",
        "description": "TensorFlow is an open source platform for machine learning. Prior to versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4, the implementation of `tf.raw_ops.Conv3DBackpropFilterV2` does not fully validate the input arguments. This results in a `CHECK`-failure which can be used to trigger a denial of service attack. The code does not validate that the `filter_sizes` argument is a vector. Versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4 contain a patch for this issue.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/174c5096f303d5be7ed2ca2662b08371bff4ab88",
        "commit_title": "Fix failed check in Conv3DBackpropFilterV2.",
        "commit_text": " Passing in a rank-0 `filter_size` causes a check fail and crash, coming from a `filter_size.vec<>()` call.  Here we check the size first.  PiperOrigin-RevId: 445517122",
        "func_before": "void Compute(OpKernelContext* context) override {\n    const Tensor& input = context->input(0);\n    const TensorShape& input_shape = input.shape();\n\n    const Tensor& out_backprop = context->input(2);\n    const TensorShape& out_backprop_shape = out_backprop.shape();\n\n    TensorShape filter_shape;\n    if (takes_shape_) {\n      const Tensor& filter_sizes = context->input(1);\n      OP_REQUIRES_OK(context, tensor::MakeShape(filter_sizes, &filter_shape));\n    } else {\n      filter_shape = context->input(1).shape();\n    }\n\n    ConvBackpropDimensions dims;\n    OP_REQUIRES_OK(\n        context,\n        ConvBackpropComputeDimensionsV2(\n            \"Conv3DBackpropFilterOp\", /*num_spatial_dims=*/3, input_shape,\n            filter_shape, out_backprop_shape, dilation_, stride_, padding_,\n            /*explicit_paddings=*/{}, data_format_, &dims));\n\n    Tensor* filter_backprop;\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(0, filter_shape, &filter_backprop));\n\n    auto* stream = context->op_device_context()->stream();\n    OP_REQUIRES(context, stream, errors::Internal(\"No GPU stream available.\"));\n\n    bool is_grouped_convolution = filter_shape.dim_size(3) != dims.in_depth;\n    if (!is_grouped_convolution && dims.filter_size(1) == 1 &&\n        dims.filter_size(2) == 1 && dims.filter_size(0) == 1 &&\n        dims.dilation(2) == 1 && dims.dilation(1) == 1 &&\n        dims.dilation(0) == 1 && dims.stride(2) == 1 && dims.stride(1) == 1 &&\n        dims.stride(0) == 1 && data_format_ == FORMAT_NHWC) {\n      const uint64 m = dims.in_depth;\n      const uint64 k = dims.batch_size * dims.input_size(1) *\n                       dims.input_size(2) * dims.input_size(0);\n      const uint64 n = dims.out_depth;\n\n      // The shape of output backprop is\n      //   [batch, out_z, out_y, out_x, out_depth]\n      // From cublas's perspective, it is: n x k\n      auto a_ptr = AsDeviceMemory(out_backprop.template flat<T>().data(),\n                                  out_backprop.template flat<T>().size());\n\n      // The shape of input is:\n      //   [batch, in_z, in_y, in_x, in_depth],\n      // From cublas's perspective, it is: m x k\n      auto b_ptr = AsDeviceMemory(input.template flat<T>().data(),\n                                  input.template flat<T>().size());\n\n      // The shape of the filter backprop is:\n      //   [1, 1, 1, in_depth, out_depth]\n      // From cublas's perspective, it is: n x m\n      auto c_ptr = AsDeviceMemory(filter_backprop->template flat<T>().data(),\n                                  filter_backprop->template flat<T>().size());\n\n      OP_REQUIRES_OK(context,\n                     stream->ThenBlasGemm(se::blas::Transpose::kNoTranspose,\n                                          se::blas::Transpose::kTranspose, n, m,\n                                          k, a_ptr, n, b_ptr, m, &c_ptr, n));\n      return;\n    } else if (!is_grouped_convolution &&\n               dims.filter_size(0) == dims.input_size(0) &&\n               dims.filter_size(1) == dims.input_size(1) &&\n               dims.filter_size(2) == dims.input_size(2) &&\n               padding_ == Padding::VALID && data_format_ == FORMAT_NHWC) {\n      const uint64 m = dims.input_size(0) * dims.input_size(1) *\n                       dims.input_size(2) * dims.in_depth;\n      const uint64 k = dims.batch_size;\n      const uint64 n = dims.out_depth;\n\n      auto a_ptr = AsDeviceMemory(input.template flat<T>().data(),\n                                  input.template flat<T>().size());\n      auto b_ptr = AsDeviceMemory(out_backprop.template flat<T>().data(),\n                                  out_backprop.template flat<T>().size());\n      auto c_ptr = AsDeviceMemory(filter_backprop->template flat<T>().data(),\n                                  filter_backprop->template flat<T>().size());\n\n      OP_REQUIRES_OK(context,\n                     stream->ThenBlasGemm(se::blas::Transpose::kNoTranspose,\n                                          se::blas::Transpose::kTranspose, n, m,\n                                          k, b_ptr, n, a_ptr, m, &c_ptr, n));\n      return;\n    }\n\n    int padding_planes = dims.SpatialPadding(padding_, 0);\n    int padding_rows = dims.SpatialPadding(padding_, 1);\n    int padding_cols = dims.SpatialPadding(padding_, 2);\n    const bool planes_odd = (padding_planes % 2 != 0);\n    const bool rows_odd = (padding_rows % 2 != 0);\n    const bool cols_odd = (padding_cols % 2 != 0);\n\n    Tensor compatible_input;\n    if (rows_odd || cols_odd || planes_odd) {\n      OP_REQUIRES_OK(context,\n                     context->allocate_temp(\n                         DataTypeToEnum<T>::value,\n                         ShapeFromFormat(data_format_, dims.batch_size,\n                                         {{dims.input_size(0) + planes_odd,\n                                           dims.input_size(1) + rows_odd,\n                                           dims.input_size(2) + cols_odd}},\n                                         dims.in_depth),\n                         &compatible_input));\n      functor::PadInput<GPUDevice, T, int, 5>()(\n          context->template eigen_device<GPUDevice>(),\n          To32Bit(input.tensor<T, 5>()), {{0, 0, 0}},\n          {{planes_odd, rows_odd, cols_odd}},\n          To32Bit(compatible_input.tensor<T, 5>()), data_format_, T{});\n    } else {\n      compatible_input = input;\n    }\n\n    CHECK(padding_rows >= 0 && padding_cols >= 0 && padding_planes >= 0)\n        << \"Negative paddings: (\" << padding_rows << \", \" << padding_cols\n        << \", \" << padding_planes << \")\";\n\n#if GOOGLE_CUDA\n    const bool compute_in_nhwc =\n        CUDNN_VERSION >= 8000 && DataTypeToEnum<T>::value == DT_HALF;\n#else\n    // fast NDHWC implementation is a CUDA only feature\n    const bool compute_in_nhwc = false;\n#endif\n    const TensorFormat compute_data_format =\n        (compute_in_nhwc && data_format_ == FORMAT_NHWC) ? FORMAT_NHWC\n                                                         : FORMAT_NCHW;\n\n    VLOG(3) << \"Compute Conv3DBackpropFilter with cuDNN:\"\n            << \" data_format=\" << ToString(data_format_)\n            << \" compute_data_format=\" << ToString(compute_data_format);\n\n    constexpr auto kComputeInNHWC =\n        std::make_tuple(se::dnn::DataLayout::kBatchYXDepth,\n                        se::dnn::FilterLayout::kOutputYXInput);\n    constexpr auto kComputeInNCHW =\n        std::make_tuple(se::dnn::DataLayout::kBatchDepthYX,\n                        se::dnn::FilterLayout::kOutputInputYX);\n\n    se::dnn::DataLayout compute_data_layout;\n    se::dnn::FilterLayout filter_layout;\n\n    std::tie(compute_data_layout, filter_layout) =\n        compute_data_format == FORMAT_NHWC ? kComputeInNHWC : kComputeInNCHW;\n\n    se::dnn::BatchDescriptor input_desc(3);\n    input_desc.set_count(dims.batch_size)\n        .set_spatial_dim(DimIndex::X,\n                         GetTensorDim(compatible_input, data_format_, '2'))\n        .set_spatial_dim(DimIndex::Y,\n                         GetTensorDim(compatible_input, data_format_, '1'))\n        .set_spatial_dim(DimIndex::Z,\n                         GetTensorDim(compatible_input, data_format_, '0'))\n        .set_feature_map_count(dims.in_depth)\n        .set_layout(compute_data_layout);\n    se::dnn::BatchDescriptor output_desc(3);\n    output_desc.set_count(dims.batch_size)\n        .set_spatial_dim(DimIndex::X, dims.output_size(2))\n        .set_spatial_dim(DimIndex::Y, dims.output_size(1))\n        .set_spatial_dim(DimIndex::Z, dims.output_size(0))\n        .set_feature_map_count(dims.out_depth)\n        .set_layout(compute_data_layout);\n    se::dnn::FilterDescriptor filter_desc(3);\n    filter_desc.set_spatial_dim(DimIndex::X, dims.filter_size(2))\n        .set_spatial_dim(DimIndex::Y, dims.filter_size(1))\n        .set_spatial_dim(DimIndex::Z, dims.filter_size(0))\n        .set_input_feature_map_count(filter_shape.dim_size(3))\n        .set_output_feature_map_count(filter_shape.dim_size(4))\n        .set_layout(filter_layout);\n    se::dnn::ConvolutionDescriptor conv_desc(3);\n    conv_desc.set_dilation_rate(DimIndex::X, dims.dilation(2))\n        .set_dilation_rate(DimIndex::Y, dims.dilation(1))\n        .set_dilation_rate(DimIndex::Z, dims.dilation(0))\n        .set_filter_stride(DimIndex::X, dims.stride(2))\n        .set_filter_stride(DimIndex::Y, dims.stride(1))\n        .set_filter_stride(DimIndex::Z, dims.stride(0))\n        .set_zero_padding(DimIndex::X, padding_cols / 2)\n        .set_zero_padding(DimIndex::Y, padding_rows / 2)\n        .set_zero_padding(DimIndex::Z, padding_planes / 2)\n        .set_group_count(dims.in_depth / filter_shape.dim_size(3));\n\n    Tensor pre_transformed_filter_backprop;\n    auto dst_format =\n        compute_data_format == FORMAT_NCHW ? FORMAT_OIHW : FORMAT_OHWI;\n    TensorShape dst_shape =\n        dst_format == FORMAT_OIHW\n            ? TensorShape({filter_shape.dim_size(4), filter_shape.dim_size(3),\n                           dims.filter_size(0), dims.filter_size(1),\n                           dims.filter_size(2)})\n            : TensorShape({filter_shape.dim_size(4), dims.filter_size(0),\n                           dims.filter_size(1), dims.filter_size(2),\n                           filter_shape.dim_size(3)});\n    OP_REQUIRES_OK(context,\n                   context->allocate_temp(DataTypeToEnum<T>::value, dst_shape,\n                                          &pre_transformed_filter_backprop));\n\n    Tensor transformed_out_backprop;\n    if (data_format_ == FORMAT_NHWC && compute_data_format == FORMAT_NCHW) {\n      VLOG(4) << \"Convert the `out_backprop` tensor from NDHWC to NCDHW.\";\n      TensorShape nchw_shape = {dims.batch_size, dims.out_depth,\n                                dims.output_size(0), dims.output_size(1),\n                                dims.output_size(2)};\n      OP_REQUIRES_OK(\n          context, context->allocate_temp(DataTypeToEnum<T>::value, nchw_shape,\n                                          &transformed_out_backprop));\n      if (dims.out_depth > 1) {\n        functor::NHWCToNCHW<GPUDevice, T, 5>()(\n            context->eigen_device<GPUDevice>(), out_backprop.tensor<T, 5>(),\n            transformed_out_backprop.tensor<T, 5>());\n      } else {\n        CHECK(transformed_out_backprop.CopyFrom(out_backprop, nchw_shape));\n      }\n    } else {\n      transformed_out_backprop = out_backprop;\n    }\n    Tensor transformed_input;\n    if (data_format_ == FORMAT_NHWC && compute_data_format == FORMAT_NCHW) {\n      VLOG(4) << \"Convert the `input` tensor from NDHWC to NCDHW.\";\n      TensorShape nchw_shape = {\n          dims.batch_size, dims.in_depth, compatible_input.dim_size(1),\n          compatible_input.dim_size(2), compatible_input.dim_size(3)};\n      if (dims.in_depth > 1) {\n        OP_REQUIRES_OK(context,\n                       context->allocate_temp(DataTypeToEnum<T>::value,\n                                              nchw_shape, &transformed_input));\n        functor::NHWCToNCHW<GPUDevice, T, 5>()(\n            context->eigen_device<GPUDevice>(),\n            const_cast<const Tensor&>(compatible_input).tensor<T, 5>(),\n            transformed_input.tensor<T, 5>());\n      } else {\n        CHECK(transformed_input.CopyFrom(compatible_input, nchw_shape));\n      }\n    } else {\n      transformed_input = compatible_input;\n    }\n\n    auto out_backprop_ptr =\n        AsDeviceMemory(transformed_out_backprop.template flat<T>().data(),\n                       transformed_out_backprop.template flat<T>().size());\n    auto filter_backprop_ptr = AsDeviceMemory(\n        pre_transformed_filter_backprop.template flat<T>().data(),\n        pre_transformed_filter_backprop.template flat<T>().size());\n    auto input_ptr =\n        AsDeviceMemory(transformed_input.template flat<T>().data(),\n                       transformed_input.template flat<T>().size());\n\n    static int64_t ConvolveBackwardFilterScratchSize = GetDnnWorkspaceLimit(\n        \"TF_CUDNN_WORKSPACE_LIMIT_IN_MB\", 1LL << 32);  // 4GB by default\n\n    const int device_id = stream->parent()->device_ordinal();\n    DataType dtype = input.dtype();\n    const ConvParameters conv_parameters = {\n        dims.batch_size,\n        dims.in_depth,\n        {{dims.input_size(0), dims.input_size(1), dims.input_size(2)}},\n        compute_data_format,\n        dims.out_depth,\n        {{dims.filter_size(0), dims.filter_size(1), dims.filter_size(2)}},\n        {{dims.dilation(0), dims.dilation(1), dims.dilation(2)}},\n        {{dims.stride(0), dims.stride(1), dims.stride(2)}},\n        {{padding_planes, padding_rows, padding_cols}},\n        dtype,\n        device_id,\n        conv_desc.group_count()};\n\n    using se::dnn::AlgorithmConfig;\n    using se::dnn::AlgorithmDesc;\n    using se::dnn::ProfileResult;\n\n    auto entry_or = AutotuneUnfusedConv(\n        cudnn_use_autotune_, AutotuneConv3dBwdFilter::GetInstance(),\n        conv_parameters, context, se::dnn::ConvolutionKind::BACKWARD_FILTER,\n        input_desc, input_ptr, filter_desc, filter_backprop_ptr, conv_desc,\n        output_desc, out_backprop_ptr, ConvolveBackwardFilterScratchSize);\n    OP_REQUIRES_OK(context, entry_or.status());\n    auto autotune_entry = entry_or.ConsumeValueOrDie();\n\n    DnnScratchAllocator scratch_allocator(ConvolveBackwardFilterScratchSize,\n                                          context);\n    Status cudnn_launch_status = LaunchAutotunedConv(\n        autotune_entry, &scratch_allocator,\n        se::dnn::ConvolutionKind::BACKWARD_FILTER, stream, input_desc,\n        input_ptr, filter_desc, filter_backprop_ptr, conv_desc, output_desc,\n        out_backprop_ptr);\n    if (!cudnn_launch_status.ok()) {\n      context->SetStatus(cudnn_launch_status);\n      return;\n    }\n\n    auto toConstTensor = [](const Tensor& x) -> const Tensor { return x; };\n    functor::ReverseTransformFilter<GPUDevice, T, 5>()(\n        context->eigen_device<GPUDevice>(), /*src_filter_format=*/dst_format,\n        toConstTensor(pre_transformed_filter_backprop).template tensor<T, 5>(),\n        filter_backprop->tensor<T, 5>());\n  }",
        "func": "void Compute(OpKernelContext* context) override {\n    const Tensor& input = context->input(0);\n    const TensorShape& input_shape = input.shape();\n\n    const Tensor& out_backprop = context->input(2);\n    const TensorShape& out_backprop_shape = out_backprop.shape();\n\n    TensorShape filter_shape;\n    if (takes_shape_) {\n      const Tensor& filter_sizes = context->input(1);\n      OP_REQUIRES(context, TensorShapeUtils::IsVector(filter_sizes.shape()),\n                  errors::InvalidArgument(\n                      \"filter_sizes shape must be rank 1 but is rank \",\n                      filter_sizes.shape().dims()));\n      OP_REQUIRES_OK(context, tensor::MakeShape(filter_sizes, &filter_shape));\n    } else {\n      filter_shape = context->input(1).shape();\n    }\n\n    ConvBackpropDimensions dims;\n    OP_REQUIRES_OK(\n        context,\n        ConvBackpropComputeDimensionsV2(\n            \"Conv3DBackpropFilterOp\", /*num_spatial_dims=*/3, input_shape,\n            filter_shape, out_backprop_shape, dilation_, stride_, padding_,\n            /*explicit_paddings=*/{}, data_format_, &dims));\n\n    Tensor* filter_backprop;\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(0, filter_shape, &filter_backprop));\n\n    auto* stream = context->op_device_context()->stream();\n    OP_REQUIRES(context, stream, errors::Internal(\"No GPU stream available.\"));\n\n    bool is_grouped_convolution = filter_shape.dim_size(3) != dims.in_depth;\n    if (!is_grouped_convolution && dims.filter_size(1) == 1 &&\n        dims.filter_size(2) == 1 && dims.filter_size(0) == 1 &&\n        dims.dilation(2) == 1 && dims.dilation(1) == 1 &&\n        dims.dilation(0) == 1 && dims.stride(2) == 1 && dims.stride(1) == 1 &&\n        dims.stride(0) == 1 && data_format_ == FORMAT_NHWC) {\n      const uint64 m = dims.in_depth;\n      const uint64 k = dims.batch_size * dims.input_size(1) *\n                       dims.input_size(2) * dims.input_size(0);\n      const uint64 n = dims.out_depth;\n\n      // The shape of output backprop is\n      //   [batch, out_z, out_y, out_x, out_depth]\n      // From cublas's perspective, it is: n x k\n      auto a_ptr = AsDeviceMemory(out_backprop.template flat<T>().data(),\n                                  out_backprop.template flat<T>().size());\n\n      // The shape of input is:\n      //   [batch, in_z, in_y, in_x, in_depth],\n      // From cublas's perspective, it is: m x k\n      auto b_ptr = AsDeviceMemory(input.template flat<T>().data(),\n                                  input.template flat<T>().size());\n\n      // The shape of the filter backprop is:\n      //   [1, 1, 1, in_depth, out_depth]\n      // From cublas's perspective, it is: n x m\n      auto c_ptr = AsDeviceMemory(filter_backprop->template flat<T>().data(),\n                                  filter_backprop->template flat<T>().size());\n\n      OP_REQUIRES_OK(context,\n                     stream->ThenBlasGemm(se::blas::Transpose::kNoTranspose,\n                                          se::blas::Transpose::kTranspose, n, m,\n                                          k, a_ptr, n, b_ptr, m, &c_ptr, n));\n      return;\n    } else if (!is_grouped_convolution &&\n               dims.filter_size(0) == dims.input_size(0) &&\n               dims.filter_size(1) == dims.input_size(1) &&\n               dims.filter_size(2) == dims.input_size(2) &&\n               padding_ == Padding::VALID && data_format_ == FORMAT_NHWC) {\n      const uint64 m = dims.input_size(0) * dims.input_size(1) *\n                       dims.input_size(2) * dims.in_depth;\n      const uint64 k = dims.batch_size;\n      const uint64 n = dims.out_depth;\n\n      auto a_ptr = AsDeviceMemory(input.template flat<T>().data(),\n                                  input.template flat<T>().size());\n      auto b_ptr = AsDeviceMemory(out_backprop.template flat<T>().data(),\n                                  out_backprop.template flat<T>().size());\n      auto c_ptr = AsDeviceMemory(filter_backprop->template flat<T>().data(),\n                                  filter_backprop->template flat<T>().size());\n\n      OP_REQUIRES_OK(context,\n                     stream->ThenBlasGemm(se::blas::Transpose::kNoTranspose,\n                                          se::blas::Transpose::kTranspose, n, m,\n                                          k, b_ptr, n, a_ptr, m, &c_ptr, n));\n      return;\n    }\n\n    int padding_planes = dims.SpatialPadding(padding_, 0);\n    int padding_rows = dims.SpatialPadding(padding_, 1);\n    int padding_cols = dims.SpatialPadding(padding_, 2);\n    const bool planes_odd = (padding_planes % 2 != 0);\n    const bool rows_odd = (padding_rows % 2 != 0);\n    const bool cols_odd = (padding_cols % 2 != 0);\n\n    Tensor compatible_input;\n    if (rows_odd || cols_odd || planes_odd) {\n      OP_REQUIRES_OK(context,\n                     context->allocate_temp(\n                         DataTypeToEnum<T>::value,\n                         ShapeFromFormat(data_format_, dims.batch_size,\n                                         {{dims.input_size(0) + planes_odd,\n                                           dims.input_size(1) + rows_odd,\n                                           dims.input_size(2) + cols_odd}},\n                                         dims.in_depth),\n                         &compatible_input));\n      functor::PadInput<GPUDevice, T, int, 5>()(\n          context->template eigen_device<GPUDevice>(),\n          To32Bit(input.tensor<T, 5>()), {{0, 0, 0}},\n          {{planes_odd, rows_odd, cols_odd}},\n          To32Bit(compatible_input.tensor<T, 5>()), data_format_, T{});\n    } else {\n      compatible_input = input;\n    }\n\n    CHECK(padding_rows >= 0 && padding_cols >= 0 && padding_planes >= 0)\n        << \"Negative paddings: (\" << padding_rows << \", \" << padding_cols\n        << \", \" << padding_planes << \")\";\n\n#if GOOGLE_CUDA\n    const bool compute_in_nhwc =\n        CUDNN_VERSION >= 8000 && DataTypeToEnum<T>::value == DT_HALF;\n#else\n    // fast NDHWC implementation is a CUDA only feature\n    const bool compute_in_nhwc = false;\n#endif\n    const TensorFormat compute_data_format =\n        (compute_in_nhwc && data_format_ == FORMAT_NHWC) ? FORMAT_NHWC\n                                                         : FORMAT_NCHW;\n\n    VLOG(3) << \"Compute Conv3DBackpropFilter with cuDNN:\"\n            << \" data_format=\" << ToString(data_format_)\n            << \" compute_data_format=\" << ToString(compute_data_format);\n\n    constexpr auto kComputeInNHWC =\n        std::make_tuple(se::dnn::DataLayout::kBatchYXDepth,\n                        se::dnn::FilterLayout::kOutputYXInput);\n    constexpr auto kComputeInNCHW =\n        std::make_tuple(se::dnn::DataLayout::kBatchDepthYX,\n                        se::dnn::FilterLayout::kOutputInputYX);\n\n    se::dnn::DataLayout compute_data_layout;\n    se::dnn::FilterLayout filter_layout;\n\n    std::tie(compute_data_layout, filter_layout) =\n        compute_data_format == FORMAT_NHWC ? kComputeInNHWC : kComputeInNCHW;\n\n    se::dnn::BatchDescriptor input_desc(3);\n    input_desc.set_count(dims.batch_size)\n        .set_spatial_dim(DimIndex::X,\n                         GetTensorDim(compatible_input, data_format_, '2'))\n        .set_spatial_dim(DimIndex::Y,\n                         GetTensorDim(compatible_input, data_format_, '1'))\n        .set_spatial_dim(DimIndex::Z,\n                         GetTensorDim(compatible_input, data_format_, '0'))\n        .set_feature_map_count(dims.in_depth)\n        .set_layout(compute_data_layout);\n    se::dnn::BatchDescriptor output_desc(3);\n    output_desc.set_count(dims.batch_size)\n        .set_spatial_dim(DimIndex::X, dims.output_size(2))\n        .set_spatial_dim(DimIndex::Y, dims.output_size(1))\n        .set_spatial_dim(DimIndex::Z, dims.output_size(0))\n        .set_feature_map_count(dims.out_depth)\n        .set_layout(compute_data_layout);\n    se::dnn::FilterDescriptor filter_desc(3);\n    filter_desc.set_spatial_dim(DimIndex::X, dims.filter_size(2))\n        .set_spatial_dim(DimIndex::Y, dims.filter_size(1))\n        .set_spatial_dim(DimIndex::Z, dims.filter_size(0))\n        .set_input_feature_map_count(filter_shape.dim_size(3))\n        .set_output_feature_map_count(filter_shape.dim_size(4))\n        .set_layout(filter_layout);\n    se::dnn::ConvolutionDescriptor conv_desc(3);\n    conv_desc.set_dilation_rate(DimIndex::X, dims.dilation(2))\n        .set_dilation_rate(DimIndex::Y, dims.dilation(1))\n        .set_dilation_rate(DimIndex::Z, dims.dilation(0))\n        .set_filter_stride(DimIndex::X, dims.stride(2))\n        .set_filter_stride(DimIndex::Y, dims.stride(1))\n        .set_filter_stride(DimIndex::Z, dims.stride(0))\n        .set_zero_padding(DimIndex::X, padding_cols / 2)\n        .set_zero_padding(DimIndex::Y, padding_rows / 2)\n        .set_zero_padding(DimIndex::Z, padding_planes / 2)\n        .set_group_count(dims.in_depth / filter_shape.dim_size(3));\n\n    Tensor pre_transformed_filter_backprop;\n    auto dst_format =\n        compute_data_format == FORMAT_NCHW ? FORMAT_OIHW : FORMAT_OHWI;\n    TensorShape dst_shape =\n        dst_format == FORMAT_OIHW\n            ? TensorShape({filter_shape.dim_size(4), filter_shape.dim_size(3),\n                           dims.filter_size(0), dims.filter_size(1),\n                           dims.filter_size(2)})\n            : TensorShape({filter_shape.dim_size(4), dims.filter_size(0),\n                           dims.filter_size(1), dims.filter_size(2),\n                           filter_shape.dim_size(3)});\n    OP_REQUIRES_OK(context,\n                   context->allocate_temp(DataTypeToEnum<T>::value, dst_shape,\n                                          &pre_transformed_filter_backprop));\n\n    Tensor transformed_out_backprop;\n    if (data_format_ == FORMAT_NHWC && compute_data_format == FORMAT_NCHW) {\n      VLOG(4) << \"Convert the `out_backprop` tensor from NDHWC to NCDHW.\";\n      TensorShape nchw_shape = {dims.batch_size, dims.out_depth,\n                                dims.output_size(0), dims.output_size(1),\n                                dims.output_size(2)};\n      OP_REQUIRES_OK(\n          context, context->allocate_temp(DataTypeToEnum<T>::value, nchw_shape,\n                                          &transformed_out_backprop));\n      if (dims.out_depth > 1) {\n        functor::NHWCToNCHW<GPUDevice, T, 5>()(\n            context->eigen_device<GPUDevice>(), out_backprop.tensor<T, 5>(),\n            transformed_out_backprop.tensor<T, 5>());\n      } else {\n        CHECK(transformed_out_backprop.CopyFrom(out_backprop, nchw_shape));\n      }\n    } else {\n      transformed_out_backprop = out_backprop;\n    }\n    Tensor transformed_input;\n    if (data_format_ == FORMAT_NHWC && compute_data_format == FORMAT_NCHW) {\n      VLOG(4) << \"Convert the `input` tensor from NDHWC to NCDHW.\";\n      TensorShape nchw_shape = {\n          dims.batch_size, dims.in_depth, compatible_input.dim_size(1),\n          compatible_input.dim_size(2), compatible_input.dim_size(3)};\n      if (dims.in_depth > 1) {\n        OP_REQUIRES_OK(context,\n                       context->allocate_temp(DataTypeToEnum<T>::value,\n                                              nchw_shape, &transformed_input));\n        functor::NHWCToNCHW<GPUDevice, T, 5>()(\n            context->eigen_device<GPUDevice>(),\n            const_cast<const Tensor&>(compatible_input).tensor<T, 5>(),\n            transformed_input.tensor<T, 5>());\n      } else {\n        CHECK(transformed_input.CopyFrom(compatible_input, nchw_shape));\n      }\n    } else {\n      transformed_input = compatible_input;\n    }\n\n    auto out_backprop_ptr =\n        AsDeviceMemory(transformed_out_backprop.template flat<T>().data(),\n                       transformed_out_backprop.template flat<T>().size());\n    auto filter_backprop_ptr = AsDeviceMemory(\n        pre_transformed_filter_backprop.template flat<T>().data(),\n        pre_transformed_filter_backprop.template flat<T>().size());\n    auto input_ptr =\n        AsDeviceMemory(transformed_input.template flat<T>().data(),\n                       transformed_input.template flat<T>().size());\n\n    static int64_t ConvolveBackwardFilterScratchSize = GetDnnWorkspaceLimit(\n        \"TF_CUDNN_WORKSPACE_LIMIT_IN_MB\", 1LL << 32);  // 4GB by default\n\n    const int device_id = stream->parent()->device_ordinal();\n    DataType dtype = input.dtype();\n    const ConvParameters conv_parameters = {\n        dims.batch_size,\n        dims.in_depth,\n        {{dims.input_size(0), dims.input_size(1), dims.input_size(2)}},\n        compute_data_format,\n        dims.out_depth,\n        {{dims.filter_size(0), dims.filter_size(1), dims.filter_size(2)}},\n        {{dims.dilation(0), dims.dilation(1), dims.dilation(2)}},\n        {{dims.stride(0), dims.stride(1), dims.stride(2)}},\n        {{padding_planes, padding_rows, padding_cols}},\n        dtype,\n        device_id,\n        conv_desc.group_count()};\n\n    using se::dnn::AlgorithmConfig;\n    using se::dnn::AlgorithmDesc;\n    using se::dnn::ProfileResult;\n\n    auto entry_or = AutotuneUnfusedConv(\n        cudnn_use_autotune_, AutotuneConv3dBwdFilter::GetInstance(),\n        conv_parameters, context, se::dnn::ConvolutionKind::BACKWARD_FILTER,\n        input_desc, input_ptr, filter_desc, filter_backprop_ptr, conv_desc,\n        output_desc, out_backprop_ptr, ConvolveBackwardFilterScratchSize);\n    OP_REQUIRES_OK(context, entry_or.status());\n    auto autotune_entry = entry_or.ConsumeValueOrDie();\n\n    DnnScratchAllocator scratch_allocator(ConvolveBackwardFilterScratchSize,\n                                          context);\n    Status cudnn_launch_status = LaunchAutotunedConv(\n        autotune_entry, &scratch_allocator,\n        se::dnn::ConvolutionKind::BACKWARD_FILTER, stream, input_desc,\n        input_ptr, filter_desc, filter_backprop_ptr, conv_desc, output_desc,\n        out_backprop_ptr);\n    if (!cudnn_launch_status.ok()) {\n      context->SetStatus(cudnn_launch_status);\n      return;\n    }\n\n    auto toConstTensor = [](const Tensor& x) -> const Tensor { return x; };\n    functor::ReverseTransformFilter<GPUDevice, T, 5>()(\n        context->eigen_device<GPUDevice>(), /*src_filter_format=*/dst_format,\n        toConstTensor(pre_transformed_filter_backprop).template tensor<T, 5>(),\n        filter_backprop->tensor<T, 5>());\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -8,6 +8,10 @@\n     TensorShape filter_shape;\n     if (takes_shape_) {\n       const Tensor& filter_sizes = context->input(1);\n+      OP_REQUIRES(context, TensorShapeUtils::IsVector(filter_sizes.shape()),\n+                  errors::InvalidArgument(\n+                      \"filter_sizes shape must be rank 1 but is rank \",\n+                      filter_sizes.shape().dims()));\n       OP_REQUIRES_OK(context, tensor::MakeShape(filter_sizes, &filter_shape));\n     } else {\n       filter_shape = context->input(1).shape();",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "      OP_REQUIRES(context, TensorShapeUtils::IsVector(filter_sizes.shape()),",
                "                  errors::InvalidArgument(",
                "                      \"filter_sizes shape must be rank 1 but is rank \",",
                "                      filter_sizes.shape().dims()));"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-41877",
        "func_name": "FreeRDP/drive_process_irp_query_directory",
        "description": "FreeRDP is a free remote desktop protocol library and clients. Affected versions of FreeRDP are missing input length validation in `drive` channel. A malicious server can trick a FreeRDP based client to read out of bound data and send it back to the server. This issue has been addressed in version 2.9.0 and all users are advised to upgrade. Users unable to upgrade should not use the drive redirection channel - command line options `/drive`, `+drives` or `+home-drive`.",
        "git_url": "https://github.com/FreeRDP/FreeRDP/commit/6655841cf2a00b764f855040aecb8803cfc5eaba",
        "commit_title": "Fixed missing stream length check in drive_file_query_directory",
        "commit_text": " (cherry picked from commit 4e4bb79795d6ac85473fb7a83e53ccf63d204b93)",
        "func_before": "static UINT drive_process_irp_query_directory(DRIVE_DEVICE* drive, IRP* irp)\n{\n\tconst WCHAR* path;\n\tDRIVE_FILE* file;\n\tBYTE InitialQuery;\n\tUINT32 PathLength;\n\tUINT32 FsInformationClass;\n\n\tif (!drive || !irp || !irp->Complete)\n\t\treturn ERROR_INVALID_PARAMETER;\n\n\tif (Stream_GetRemainingLength(irp->input) < 32)\n\t\treturn ERROR_INVALID_DATA;\n\n\tStream_Read_UINT32(irp->input, FsInformationClass);\n\tStream_Read_UINT8(irp->input, InitialQuery);\n\tStream_Read_UINT32(irp->input, PathLength);\n\tStream_Seek(irp->input, 23); /* Padding */\n\tpath = (WCHAR*)Stream_Pointer(irp->input);\n\tfile = drive_get_file_by_id(drive, irp->FileId);\n\n\tif (file == NULL)\n\t{\n\t\tirp->IoStatus = STATUS_UNSUCCESSFUL;\n\t\tStream_Write_UINT32(irp->output, 0); /* Length */\n\t}\n\telse if (!drive_file_query_directory(file, FsInformationClass, InitialQuery, path, PathLength,\n\t                                     irp->output))\n\t{\n\t\tirp->IoStatus = drive_map_windows_err(GetLastError());\n\t}\n\n\treturn irp->Complete(irp);\n}",
        "func": "static UINT drive_process_irp_query_directory(DRIVE_DEVICE* drive, IRP* irp)\n{\n\tconst WCHAR* path;\n\tDRIVE_FILE* file;\n\tBYTE InitialQuery;\n\tUINT32 PathLength;\n\tUINT32 FsInformationClass;\n\n\tif (!drive || !irp || !irp->Complete)\n\t\treturn ERROR_INVALID_PARAMETER;\n\n\tif (Stream_GetRemainingLength(irp->input) < 32)\n\t\treturn ERROR_INVALID_DATA;\n\n\tStream_Read_UINT32(irp->input, FsInformationClass);\n\tStream_Read_UINT8(irp->input, InitialQuery);\n\tStream_Read_UINT32(irp->input, PathLength);\n\tStream_Seek(irp->input, 23); /* Padding */\n\tpath = (WCHAR*)Stream_Pointer(irp->input);\n\tif (!Stream_CheckAndLogRequiredLength(TAG, irp->input, PathLength))\n\t\treturn ERROR_INVALID_DATA;\n\n\tfile = drive_get_file_by_id(drive, irp->FileId);\n\n\tif (file == NULL)\n\t{\n\t\tirp->IoStatus = STATUS_UNSUCCESSFUL;\n\t\tStream_Write_UINT32(irp->output, 0); /* Length */\n\t}\n\telse if (!drive_file_query_directory(file, FsInformationClass, InitialQuery, path, PathLength,\n\t                                     irp->output))\n\t{\n\t\tirp->IoStatus = drive_map_windows_err(GetLastError());\n\t}\n\n\treturn irp->Complete(irp);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -17,6 +17,9 @@\n \tStream_Read_UINT32(irp->input, PathLength);\n \tStream_Seek(irp->input, 23); /* Padding */\n \tpath = (WCHAR*)Stream_Pointer(irp->input);\n+\tif (!Stream_CheckAndLogRequiredLength(TAG, irp->input, PathLength))\n+\t\treturn ERROR_INVALID_DATA;\n+\n \tfile = drive_get_file_by_id(drive, irp->FileId);\n \n \tif (file == NULL)",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tif (!Stream_CheckAndLogRequiredLength(TAG, irp->input, PathLength))",
                "\t\treturn ERROR_INVALID_DATA;",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2022-41896",
        "func_name": "tensorflow/Mfcc::Initialize",
        "description": "TensorFlow is an open source platform for machine learning. If `ThreadUnsafeUnigramCandidateSampler` is given input `filterbank_channel_count` greater than the allowed max size, TensorFlow will crash. We have patched the issue in GitHub commit 39ec7eaf1428e90c37787e5b3fbd68ebd3c48860. The fix will be included in TensorFlow 2.11. We will also cherrypick this commit on TensorFlow 2.10.1, 2.9.3, and TensorFlow 2.8.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/39ec7eaf1428e90c37787e5b3fbd68ebd3c48860",
        "commit_title": "Make MfccMelFilterbank fail initialization if num_channels is > max int value.",
        "commit_text": " Also initialize MfccDct only if MfccMelFilterbank initialization was successful.  PiperOrigin-RevId: 477844246",
        "func_before": "bool Mfcc::Initialize(int input_length, double input_sample_rate) {\n  bool initialized = mel_filterbank_.Initialize(\n      input_length, input_sample_rate, filterbank_channel_count_,\n      lower_frequency_limit_, upper_frequency_limit_);\n  initialized &=\n      dct_.Initialize(filterbank_channel_count_, dct_coefficient_count_);\n  initialized_ = initialized;\n  return initialized;\n}",
        "func": "bool Mfcc::Initialize(int input_length, double input_sample_rate) {\n  bool initialized = mel_filterbank_.Initialize(\n      input_length, input_sample_rate, filterbank_channel_count_,\n      lower_frequency_limit_, upper_frequency_limit_);\n  if (initialized) {\n    initialized =\n        dct_.Initialize(filterbank_channel_count_, dct_coefficient_count_);\n  }\n  initialized_ = initialized;\n  return initialized;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,8 +2,10 @@\n   bool initialized = mel_filterbank_.Initialize(\n       input_length, input_sample_rate, filterbank_channel_count_,\n       lower_frequency_limit_, upper_frequency_limit_);\n-  initialized &=\n-      dct_.Initialize(filterbank_channel_count_, dct_coefficient_count_);\n+  if (initialized) {\n+    initialized =\n+        dct_.Initialize(filterbank_channel_count_, dct_coefficient_count_);\n+  }\n   initialized_ = initialized;\n   return initialized;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "  initialized &=",
                "      dct_.Initialize(filterbank_channel_count_, dct_coefficient_count_);"
            ],
            "added_lines": [
                "  if (initialized) {",
                "    initialized =",
                "        dct_.Initialize(filterbank_channel_count_, dct_coefficient_count_);",
                "  }"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-41896",
        "func_name": "tensorflow/Compute",
        "description": "TensorFlow is an open source platform for machine learning. If `ThreadUnsafeUnigramCandidateSampler` is given input `filterbank_channel_count` greater than the allowed max size, TensorFlow will crash. We have patched the issue in GitHub commit 39ec7eaf1428e90c37787e5b3fbd68ebd3c48860. The fix will be included in TensorFlow 2.11. We will also cherrypick this commit on TensorFlow 2.10.1, 2.9.3, and TensorFlow 2.8.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/39ec7eaf1428e90c37787e5b3fbd68ebd3c48860",
        "commit_title": "Make MfccMelFilterbank fail initialization if num_channels is > max int value.",
        "commit_text": " Also initialize MfccDct only if MfccMelFilterbank initialization was successful.  PiperOrigin-RevId: 477844246",
        "func_before": "void Compute(OpKernelContext* context) override {\n    const Tensor& spectrogram = context->input(0);\n    OP_REQUIRES(context, spectrogram.dims() == 3,\n                errors::InvalidArgument(\"spectrogram must be 3-dimensional\",\n                                        spectrogram.shape().DebugString()));\n    const Tensor& sample_rate_tensor = context->input(1);\n    OP_REQUIRES(context, TensorShapeUtils::IsScalar(sample_rate_tensor.shape()),\n                errors::InvalidArgument(\n                    \"Input sample_rate should be a scalar tensor, got \",\n                    sample_rate_tensor.shape().DebugString(), \" instead.\"));\n    const int32_t sample_rate = sample_rate_tensor.scalar<int32>()();\n\n    const int spectrogram_channels = spectrogram.dim_size(2);\n    const int spectrogram_samples = spectrogram.dim_size(1);\n    const int audio_channels = spectrogram.dim_size(0);\n\n    Mfcc mfcc;\n    mfcc.set_upper_frequency_limit(upper_frequency_limit_);\n    mfcc.set_lower_frequency_limit(lower_frequency_limit_);\n    mfcc.set_filterbank_channel_count(filterbank_channel_count_);\n    mfcc.set_dct_coefficient_count(dct_coefficient_count_);\n    OP_REQUIRES(context, mfcc.Initialize(spectrogram_channels, sample_rate),\n                errors::InvalidArgument(\n                    \"Mfcc initialization failed for channel count \",\n                    spectrogram_channels, \" and sample rate \", sample_rate));\n\n    Tensor* output_tensor = nullptr;\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(\n                       0,\n                       TensorShape({audio_channels, spectrogram_samples,\n                                    dct_coefficient_count_}),\n                       &output_tensor));\n\n    const float* spectrogram_flat = spectrogram.flat<float>().data();\n    float* output_flat = output_tensor->flat<float>().data();\n\n    for (int audio_channel = 0; audio_channel < audio_channels;\n         ++audio_channel) {\n      for (int spectrogram_sample = 0; spectrogram_sample < spectrogram_samples;\n           ++spectrogram_sample) {\n        const float* sample_data =\n            spectrogram_flat +\n            (audio_channel * spectrogram_samples * spectrogram_channels) +\n            (spectrogram_sample * spectrogram_channels);\n        std::vector<double> mfcc_input(sample_data,\n                                       sample_data + spectrogram_channels);\n        std::vector<double> mfcc_output;\n        mfcc.Compute(mfcc_input, &mfcc_output);\n        DCHECK_EQ(dct_coefficient_count_, mfcc_output.size());\n        float* output_data =\n            output_flat +\n            (audio_channel * spectrogram_samples * dct_coefficient_count_) +\n            (spectrogram_sample * dct_coefficient_count_);\n        for (int i = 0; i < dct_coefficient_count_; ++i) {\n          output_data[i] = mfcc_output[i];\n        }\n      }\n    }\n  }",
        "func": "void Compute(OpKernelContext* context) override {\n    const Tensor& spectrogram = context->input(0);\n    OP_REQUIRES(context, spectrogram.dims() == 3,\n                errors::InvalidArgument(\"spectrogram must be 3-dimensional\",\n                                        spectrogram.shape().DebugString()));\n    const Tensor& sample_rate_tensor = context->input(1);\n    OP_REQUIRES(context, TensorShapeUtils::IsScalar(sample_rate_tensor.shape()),\n                errors::InvalidArgument(\n                    \"Input sample_rate should be a scalar tensor, got \",\n                    sample_rate_tensor.shape().DebugString(), \" instead.\"));\n    const int32_t sample_rate = sample_rate_tensor.scalar<int32>()();\n\n    const int spectrogram_channels = spectrogram.dim_size(2);\n    const int spectrogram_samples = spectrogram.dim_size(1);\n    const int audio_channels = spectrogram.dim_size(0);\n\n    Mfcc mfcc;\n    mfcc.set_upper_frequency_limit(upper_frequency_limit_);\n    mfcc.set_lower_frequency_limit(lower_frequency_limit_);\n    mfcc.set_filterbank_channel_count(filterbank_channel_count_);\n    mfcc.set_dct_coefficient_count(dct_coefficient_count_);\n    OP_REQUIRES(\n        context, mfcc.Initialize(spectrogram_channels, sample_rate),\n        errors::InvalidArgument(\"Mfcc initialization failed for channel count \",\n                                spectrogram_channels, \", sample rate \",\n                                sample_rate, \" and filterbank_channel_count \",\n                                filterbank_channel_count_));\n\n    Tensor* output_tensor = nullptr;\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(\n                       0,\n                       TensorShape({audio_channels, spectrogram_samples,\n                                    dct_coefficient_count_}),\n                       &output_tensor));\n\n    const float* spectrogram_flat = spectrogram.flat<float>().data();\n    float* output_flat = output_tensor->flat<float>().data();\n\n    for (int audio_channel = 0; audio_channel < audio_channels;\n         ++audio_channel) {\n      for (int spectrogram_sample = 0; spectrogram_sample < spectrogram_samples;\n           ++spectrogram_sample) {\n        const float* sample_data =\n            spectrogram_flat +\n            (audio_channel * spectrogram_samples * spectrogram_channels) +\n            (spectrogram_sample * spectrogram_channels);\n        std::vector<double> mfcc_input(sample_data,\n                                       sample_data + spectrogram_channels);\n        std::vector<double> mfcc_output;\n        mfcc.Compute(mfcc_input, &mfcc_output);\n        DCHECK_EQ(dct_coefficient_count_, mfcc_output.size());\n        float* output_data =\n            output_flat +\n            (audio_channel * spectrogram_samples * dct_coefficient_count_) +\n            (spectrogram_sample * dct_coefficient_count_);\n        for (int i = 0; i < dct_coefficient_count_; ++i) {\n          output_data[i] = mfcc_output[i];\n        }\n      }\n    }\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -19,10 +19,12 @@\n     mfcc.set_lower_frequency_limit(lower_frequency_limit_);\n     mfcc.set_filterbank_channel_count(filterbank_channel_count_);\n     mfcc.set_dct_coefficient_count(dct_coefficient_count_);\n-    OP_REQUIRES(context, mfcc.Initialize(spectrogram_channels, sample_rate),\n-                errors::InvalidArgument(\n-                    \"Mfcc initialization failed for channel count \",\n-                    spectrogram_channels, \" and sample rate \", sample_rate));\n+    OP_REQUIRES(\n+        context, mfcc.Initialize(spectrogram_channels, sample_rate),\n+        errors::InvalidArgument(\"Mfcc initialization failed for channel count \",\n+                                spectrogram_channels, \", sample rate \",\n+                                sample_rate, \" and filterbank_channel_count \",\n+                                filterbank_channel_count_));\n \n     Tensor* output_tensor = nullptr;\n     OP_REQUIRES_OK(context,",
        "diff_line_info": {
            "deleted_lines": [
                "    OP_REQUIRES(context, mfcc.Initialize(spectrogram_channels, sample_rate),",
                "                errors::InvalidArgument(",
                "                    \"Mfcc initialization failed for channel count \",",
                "                    spectrogram_channels, \" and sample rate \", sample_rate));"
            ],
            "added_lines": [
                "    OP_REQUIRES(",
                "        context, mfcc.Initialize(spectrogram_channels, sample_rate),",
                "        errors::InvalidArgument(\"Mfcc initialization failed for channel count \",",
                "                                spectrogram_channels, \", sample rate \",",
                "                                sample_rate, \" and filterbank_channel_count \",",
                "                                filterbank_channel_count_));"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-41896",
        "func_name": "tensorflow/MfccMelFilterbank::Initialize",
        "description": "TensorFlow is an open source platform for machine learning. If `ThreadUnsafeUnigramCandidateSampler` is given input `filterbank_channel_count` greater than the allowed max size, TensorFlow will crash. We have patched the issue in GitHub commit 39ec7eaf1428e90c37787e5b3fbd68ebd3c48860. The fix will be included in TensorFlow 2.11. We will also cherrypick this commit on TensorFlow 2.10.1, 2.9.3, and TensorFlow 2.8.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/39ec7eaf1428e90c37787e5b3fbd68ebd3c48860",
        "commit_title": "Make MfccMelFilterbank fail initialization if num_channels is > max int value.",
        "commit_text": " Also initialize MfccDct only if MfccMelFilterbank initialization was successful.  PiperOrigin-RevId: 477844246",
        "func_before": "bool MfccMelFilterbank::Initialize(int input_length, double input_sample_rate,\n                                   int output_channel_count,\n                                   double lower_frequency_limit,\n                                   double upper_frequency_limit) {\n  num_channels_ = output_channel_count;\n  sample_rate_ = input_sample_rate;\n  input_length_ = input_length;\n\n  if (num_channels_ < 1) {\n    LOG(ERROR) << \"Number of filterbank channels must be positive.\";\n    return false;\n  }\n\n  if (sample_rate_ <= 0) {\n    LOG(ERROR) << \"Sample rate must be positive.\";\n    return false;\n  }\n\n  if (input_length < 2) {\n    LOG(ERROR) << \"Input length must greater than 1.\";\n    return false;\n  }\n\n  if (lower_frequency_limit < 0) {\n    LOG(ERROR) << \"Lower frequency limit must be nonnegative.\";\n    return false;\n  }\n\n  if (upper_frequency_limit <= lower_frequency_limit) {\n    LOG(ERROR) << \"Upper frequency limit must be greater than \"\n               << \"lower frequency limit.\";\n    return false;\n  }\n\n  // An extra center frequency is computed at the top to get the upper\n  // limit on the high side of the final triangular filter.\n  center_frequencies_.resize(num_channels_ + 1);\n  const double mel_low = FreqToMel(lower_frequency_limit);\n  const double mel_hi = FreqToMel(upper_frequency_limit);\n  const double mel_span = mel_hi - mel_low;\n  const double mel_spacing = mel_span / static_cast<double>(num_channels_ + 1);\n  for (int i = 0; i < num_channels_ + 1; ++i) {\n    center_frequencies_[i] = mel_low + (mel_spacing * (i + 1));\n  }\n\n  // Always exclude DC; emulate HTK.\n  const double hz_per_sbin =\n      0.5 * sample_rate_ / static_cast<double>(input_length_ - 1);\n  start_index_ = static_cast<int>(1.5 + (lower_frequency_limit / hz_per_sbin));\n  end_index_ = static_cast<int>(upper_frequency_limit / hz_per_sbin);\n\n  // Maps the input spectrum bin indices to filter bank channels/indices. For\n  // each FFT bin, band_mapper tells us which channel this bin contributes to\n  // on the right side of the triangle.  Thus this bin also contributes to the\n  // left side of the next channel's triangle response.\n  band_mapper_.resize(input_length_);\n  int channel = 0;\n  for (int i = 0; i < input_length_; ++i) {\n    double melf = FreqToMel(i * hz_per_sbin);\n    if ((i < start_index_) || (i > end_index_)) {\n      band_mapper_[i] = -2;  // Indicate an unused Fourier coefficient.\n    } else {\n      while ((channel < num_channels_) &&\n             (center_frequencies_[channel] < melf)) {\n        ++channel;\n      }\n      band_mapper_[i] = channel - 1;  // Can be == -1\n    }\n  }\n\n  // Create the weighting functions to taper the band edges.  The contribution\n  // of any one FFT bin is based on its distance along the continuum between two\n  // mel-channel center frequencies.  This bin contributes weights_[i] to the\n  // current channel and 1-weights_[i] to the next channel.\n  weights_.resize(input_length_);\n  for (int i = 0; i < input_length_; ++i) {\n    channel = band_mapper_[i];\n    if ((i < start_index_) || (i > end_index_)) {\n      weights_[i] = 0.0;\n    } else {\n      if (channel >= 0) {\n        weights_[i] =\n            (center_frequencies_[channel + 1] - FreqToMel(i * hz_per_sbin)) /\n            (center_frequencies_[channel + 1] - center_frequencies_[channel]);\n      } else {\n        weights_[i] = (center_frequencies_[0] - FreqToMel(i * hz_per_sbin)) /\n                      (center_frequencies_[0] - mel_low);\n      }\n    }\n  }\n  // Check the sum of FFT bin weights for every mel band to identify\n  // situations where the mel bands are so narrow that they don't get\n  // significant weight on enough (or any) FFT bins -- i.e., too many\n  // mel bands have been requested for the given FFT size.\n  std::vector<int> bad_channels;\n  for (int c = 0; c < num_channels_; ++c) {\n    float band_weights_sum = 0.0;\n    for (int i = 0; i < input_length_; ++i) {\n      if (band_mapper_[i] == c - 1) {\n        band_weights_sum += (1.0 - weights_[i]);\n      } else if (band_mapper_[i] == c) {\n        band_weights_sum += weights_[i];\n      }\n    }\n    // The lowest mel channels have the fewest FFT bins and the lowest\n    // weights sum.  But given that the target gain at the center frequency\n    // is 1.0, if the total sum of weights is 0.5, we're in bad shape.\n    if (band_weights_sum < 0.5) {\n      bad_channels.push_back(c);\n    }\n  }\n  if (!bad_channels.empty()) {\n    LOG(ERROR) << \"Missing \" << bad_channels.size() << \" bands \"\n               << \" starting at \" << bad_channels[0]\n               << \" in mel-frequency design. \"\n               << \"Perhaps too many channels or \"\n               << \"not enough frequency resolution in spectrum. (\"\n               << \"input_length: \" << input_length\n               << \" input_sample_rate: \" << input_sample_rate\n               << \" output_channel_count: \" << output_channel_count\n               << \" lower_frequency_limit: \" << lower_frequency_limit\n               << \" upper_frequency_limit: \" << upper_frequency_limit;\n  }\n  initialized_ = true;\n  return true;\n}",
        "func": "bool MfccMelFilterbank::Initialize(int input_length, double input_sample_rate,\n                                   int output_channel_count,\n                                   double lower_frequency_limit,\n                                   double upper_frequency_limit) {\n  num_channels_ = output_channel_count;\n  sample_rate_ = input_sample_rate;\n  input_length_ = input_length;\n\n  if (num_channels_ < 1) {\n    LOG(ERROR) << \"Number of filterbank channels must be positive.\";\n    return false;\n  }\n\n  if (sample_rate_ <= 0) {\n    LOG(ERROR) << \"Sample rate must be positive.\";\n    return false;\n  }\n\n  if (input_length < 2) {\n    LOG(ERROR) << \"Input length must greater than 1.\";\n    return false;\n  }\n\n  if (lower_frequency_limit < 0) {\n    LOG(ERROR) << \"Lower frequency limit must be nonnegative.\";\n    return false;\n  }\n\n  if (upper_frequency_limit <= lower_frequency_limit) {\n    LOG(ERROR) << \"Upper frequency limit must be greater than \"\n               << \"lower frequency limit.\";\n    return false;\n  }\n\n  // An extra center frequency is computed at the top to get the upper\n  // limit on the high side of the final triangular filter.\n  std::size_t center_frequencies_size = std::size_t(num_channels_) + 1;\n  if (center_frequencies_size >= std::numeric_limits<int>::max() ||\n      center_frequencies_size > center_frequencies_.max_size()) {\n    LOG(ERROR) << \"Number of filterbank channels must be less than \"\n               << std::numeric_limits<int>::max()\n               << \" and less than or equal to \"\n               << center_frequencies_.max_size();\n    return false;\n  }\n  center_frequencies_.resize(center_frequencies_size);\n\n  const double mel_low = FreqToMel(lower_frequency_limit);\n  const double mel_hi = FreqToMel(upper_frequency_limit);\n  const double mel_span = mel_hi - mel_low;\n  const double mel_spacing = mel_span / static_cast<double>(num_channels_ + 1);\n  for (int i = 0; i < num_channels_ + 1; ++i) {\n    center_frequencies_[i] = mel_low + (mel_spacing * (i + 1));\n  }\n\n  // Always exclude DC; emulate HTK.\n  const double hz_per_sbin =\n      0.5 * sample_rate_ / static_cast<double>(input_length_ - 1);\n  start_index_ = static_cast<int>(1.5 + (lower_frequency_limit / hz_per_sbin));\n  end_index_ = static_cast<int>(upper_frequency_limit / hz_per_sbin);\n\n  // Maps the input spectrum bin indices to filter bank channels/indices. For\n  // each FFT bin, band_mapper tells us which channel this bin contributes to\n  // on the right side of the triangle.  Thus this bin also contributes to the\n  // left side of the next channel's triangle response.\n  band_mapper_.resize(input_length_);\n  int channel = 0;\n  for (int i = 0; i < input_length_; ++i) {\n    double melf = FreqToMel(i * hz_per_sbin);\n    if ((i < start_index_) || (i > end_index_)) {\n      band_mapper_[i] = -2;  // Indicate an unused Fourier coefficient.\n    } else {\n      while ((channel < num_channels_) &&\n             (center_frequencies_[channel] < melf)) {\n        ++channel;\n      }\n      band_mapper_[i] = channel - 1;  // Can be == -1\n    }\n  }\n\n  // Create the weighting functions to taper the band edges.  The contribution\n  // of any one FFT bin is based on its distance along the continuum between two\n  // mel-channel center frequencies.  This bin contributes weights_[i] to the\n  // current channel and 1-weights_[i] to the next channel.\n  weights_.resize(input_length_);\n  for (int i = 0; i < input_length_; ++i) {\n    channel = band_mapper_[i];\n    if ((i < start_index_) || (i > end_index_)) {\n      weights_[i] = 0.0;\n    } else {\n      if (channel >= 0) {\n        weights_[i] =\n            (center_frequencies_[channel + 1] - FreqToMel(i * hz_per_sbin)) /\n            (center_frequencies_[channel + 1] - center_frequencies_[channel]);\n      } else {\n        weights_[i] = (center_frequencies_[0] - FreqToMel(i * hz_per_sbin)) /\n                      (center_frequencies_[0] - mel_low);\n      }\n    }\n  }\n  // Check the sum of FFT bin weights for every mel band to identify\n  // situations where the mel bands are so narrow that they don't get\n  // significant weight on enough (or any) FFT bins -- i.e., too many\n  // mel bands have been requested for the given FFT size.\n  std::vector<int> bad_channels;\n  for (int c = 0; c < num_channels_; ++c) {\n    float band_weights_sum = 0.0;\n    for (int i = 0; i < input_length_; ++i) {\n      if (band_mapper_[i] == c - 1) {\n        band_weights_sum += (1.0 - weights_[i]);\n      } else if (band_mapper_[i] == c) {\n        band_weights_sum += weights_[i];\n      }\n    }\n    // The lowest mel channels have the fewest FFT bins and the lowest\n    // weights sum.  But given that the target gain at the center frequency\n    // is 1.0, if the total sum of weights is 0.5, we're in bad shape.\n    if (band_weights_sum < 0.5) {\n      bad_channels.push_back(c);\n    }\n  }\n  if (!bad_channels.empty()) {\n    LOG(ERROR) << \"Missing \" << bad_channels.size() << \" bands \"\n               << \" starting at \" << bad_channels[0]\n               << \" in mel-frequency design. \"\n               << \"Perhaps too many channels or \"\n               << \"not enough frequency resolution in spectrum. (\"\n               << \"input_length: \" << input_length\n               << \" input_sample_rate: \" << input_sample_rate\n               << \" output_channel_count: \" << output_channel_count\n               << \" lower_frequency_limit: \" << lower_frequency_limit\n               << \" upper_frequency_limit: \" << upper_frequency_limit;\n  }\n  initialized_ = true;\n  return true;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -34,7 +34,17 @@\n \n   // An extra center frequency is computed at the top to get the upper\n   // limit on the high side of the final triangular filter.\n-  center_frequencies_.resize(num_channels_ + 1);\n+  std::size_t center_frequencies_size = std::size_t(num_channels_) + 1;\n+  if (center_frequencies_size >= std::numeric_limits<int>::max() ||\n+      center_frequencies_size > center_frequencies_.max_size()) {\n+    LOG(ERROR) << \"Number of filterbank channels must be less than \"\n+               << std::numeric_limits<int>::max()\n+               << \" and less than or equal to \"\n+               << center_frequencies_.max_size();\n+    return false;\n+  }\n+  center_frequencies_.resize(center_frequencies_size);\n+\n   const double mel_low = FreqToMel(lower_frequency_limit);\n   const double mel_hi = FreqToMel(upper_frequency_limit);\n   const double mel_span = mel_hi - mel_low;",
        "diff_line_info": {
            "deleted_lines": [
                "  center_frequencies_.resize(num_channels_ + 1);"
            ],
            "added_lines": [
                "  std::size_t center_frequencies_size = std::size_t(num_channels_) + 1;",
                "  if (center_frequencies_size >= std::numeric_limits<int>::max() ||",
                "      center_frequencies_size > center_frequencies_.max_size()) {",
                "    LOG(ERROR) << \"Number of filterbank channels must be less than \"",
                "               << std::numeric_limits<int>::max()",
                "               << \" and less than or equal to \"",
                "               << center_frequencies_.max_size();",
                "    return false;",
                "  }",
                "  center_frequencies_.resize(center_frequencies_size);",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2022-4904",
        "func_name": "c-ares/config_sortlist",
        "description": "A flaw was found in the c-ares package. The ares_set_sortlist is missing checks about the validity of the input string, which allows a possible arbitrary length stack overflow. This issue may cause a denial of service or a limited impact on confidentiality and integrity.",
        "git_url": "https://github.com/c-ares/c-ares/commit/ac596026e77244481fd68736ae7f15855803a08a",
        "commit_title": "Add str len check in config_sortlist to avoid stack overflow",
        "commit_text": " In ares_set_sortlist, it calls config_sortlist(..., sortstr) to parse the input str and initialize a sortlist configuration.  However, ares_set_sortlist has not any checks about the validity of the input str. It is very easy to create an arbitrary length stack overflow with the unchecked `memcpy(ipbuf, str, q-str);` and `memcpy(ipbufpfx, str, q-str);` statements in the config_sortlist call, which could potentially cause severe security impact in practical programs.  This commit add necessary check for `ipbuf` and `ipbufpfx` which avoid the potential stack overflows.  fixes #496 ",
        "func_before": "static int config_sortlist(struct apattern **sortlist, int *nsort,\n                           const char *str)\n{\n  struct apattern pat;\n  const char *q;\n\n  /* Add sortlist entries. */\n  while (*str && *str != ';')\n    {\n      int bits;\n      char ipbuf[16], ipbufpfx[32];\n      /* Find just the IP */\n      q = str;\n      while (*q && *q != '/' && *q != ';' && !ISSPACE(*q))\n        q++;\n      memcpy(ipbuf, str, q-str);\n      ipbuf[q-str] = '\\0';\n      /* Find the prefix */\n      if (*q == '/')\n        {\n          const char *str2 = q+1;\n          while (*q && *q != ';' && !ISSPACE(*q))\n            q++;\n          memcpy(ipbufpfx, str, q-str);\n          ipbufpfx[q-str] = '\\0';\n          str = str2;\n        }\n      else\n        ipbufpfx[0] = '\\0';\n      /* Lets see if it is CIDR */\n      /* First we'll try IPv6 */\n      if ((bits = ares_inet_net_pton(AF_INET6, ipbufpfx[0] ? ipbufpfx : ipbuf,\n                                     &pat.addrV6,\n                                     sizeof(pat.addrV6))) > 0)\n        {\n          pat.type = PATTERN_CIDR;\n          pat.mask.bits = (unsigned short)bits;\n          pat.family = AF_INET6;\n          if (!sortlist_alloc(sortlist, nsort, &pat)) {\n            ares_free(*sortlist);\n            *sortlist = NULL;\n            return ARES_ENOMEM;\n          }\n        }\n      else if (ipbufpfx[0] &&\n               (bits = ares_inet_net_pton(AF_INET, ipbufpfx, &pat.addrV4,\n                                          sizeof(pat.addrV4))) > 0)\n        {\n          pat.type = PATTERN_CIDR;\n          pat.mask.bits = (unsigned short)bits;\n          pat.family = AF_INET;\n          if (!sortlist_alloc(sortlist, nsort, &pat)) {\n            ares_free(*sortlist);\n            *sortlist = NULL;\n            return ARES_ENOMEM;\n          }\n        }\n      /* See if it is just a regular IP */\n      else if (ip_addr(ipbuf, q-str, &pat.addrV4) == 0)\n        {\n          if (ipbufpfx[0])\n            {\n              memcpy(ipbuf, str, q-str);\n              ipbuf[q-str] = '\\0';\n              if (ip_addr(ipbuf, q-str, &pat.mask.addr4) != 0)\n                natural_mask(&pat);\n            }\n          else\n            natural_mask(&pat);\n          pat.family = AF_INET;\n          pat.type = PATTERN_MASK;\n          if (!sortlist_alloc(sortlist, nsort, &pat)) {\n            ares_free(*sortlist);\n            *sortlist = NULL;\n            return ARES_ENOMEM;\n          }\n        }\n      else\n        {\n          while (*q && *q != ';' && !ISSPACE(*q))\n            q++;\n        }\n      str = q;\n      while (ISSPACE(*str))\n        str++;\n    }\n\n  return ARES_SUCCESS;\n}",
        "func": "static int config_sortlist(struct apattern **sortlist, int *nsort,\n                           const char *str)\n{\n  struct apattern pat;\n  const char *q;\n\n  /* Add sortlist entries. */\n  while (*str && *str != ';')\n    {\n      int bits;\n      char ipbuf[16], ipbufpfx[32];\n      /* Find just the IP */\n      q = str;\n      while (*q && *q != '/' && *q != ';' && !ISSPACE(*q))\n        q++;\n      if (q-str >= 16)\n        return ARES_EBADSTR;\n      memcpy(ipbuf, str, q-str);\n      ipbuf[q-str] = '\\0';\n      /* Find the prefix */\n      if (*q == '/')\n        {\n          const char *str2 = q+1;\n          while (*q && *q != ';' && !ISSPACE(*q))\n            q++;\n          if (q-str >= 32)\n            return ARES_EBADSTR;\n          memcpy(ipbufpfx, str, q-str);\n          ipbufpfx[q-str] = '\\0';\n          str = str2;\n        }\n      else\n        ipbufpfx[0] = '\\0';\n      /* Lets see if it is CIDR */\n      /* First we'll try IPv6 */\n      if ((bits = ares_inet_net_pton(AF_INET6, ipbufpfx[0] ? ipbufpfx : ipbuf,\n                                     &pat.addrV6,\n                                     sizeof(pat.addrV6))) > 0)\n        {\n          pat.type = PATTERN_CIDR;\n          pat.mask.bits = (unsigned short)bits;\n          pat.family = AF_INET6;\n          if (!sortlist_alloc(sortlist, nsort, &pat)) {\n            ares_free(*sortlist);\n            *sortlist = NULL;\n            return ARES_ENOMEM;\n          }\n        }\n      else if (ipbufpfx[0] &&\n               (bits = ares_inet_net_pton(AF_INET, ipbufpfx, &pat.addrV4,\n                                          sizeof(pat.addrV4))) > 0)\n        {\n          pat.type = PATTERN_CIDR;\n          pat.mask.bits = (unsigned short)bits;\n          pat.family = AF_INET;\n          if (!sortlist_alloc(sortlist, nsort, &pat)) {\n            ares_free(*sortlist);\n            *sortlist = NULL;\n            return ARES_ENOMEM;\n          }\n        }\n      /* See if it is just a regular IP */\n      else if (ip_addr(ipbuf, q-str, &pat.addrV4) == 0)\n        {\n          if (ipbufpfx[0])\n            {\n              memcpy(ipbuf, str, q-str);\n              ipbuf[q-str] = '\\0';\n              if (ip_addr(ipbuf, q-str, &pat.mask.addr4) != 0)\n                natural_mask(&pat);\n            }\n          else\n            natural_mask(&pat);\n          pat.family = AF_INET;\n          pat.type = PATTERN_MASK;\n          if (!sortlist_alloc(sortlist, nsort, &pat)) {\n            ares_free(*sortlist);\n            *sortlist = NULL;\n            return ARES_ENOMEM;\n          }\n        }\n      else\n        {\n          while (*q && *q != ';' && !ISSPACE(*q))\n            q++;\n        }\n      str = q;\n      while (ISSPACE(*str))\n        str++;\n    }\n\n  return ARES_SUCCESS;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -13,6 +13,8 @@\n       q = str;\n       while (*q && *q != '/' && *q != ';' && !ISSPACE(*q))\n         q++;\n+      if (q-str >= 16)\n+        return ARES_EBADSTR;\n       memcpy(ipbuf, str, q-str);\n       ipbuf[q-str] = '\\0';\n       /* Find the prefix */\n@@ -21,6 +23,8 @@\n           const char *str2 = q+1;\n           while (*q && *q != ';' && !ISSPACE(*q))\n             q++;\n+          if (q-str >= 32)\n+            return ARES_EBADSTR;\n           memcpy(ipbufpfx, str, q-str);\n           ipbufpfx[q-str] = '\\0';\n           str = str2;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "      if (q-str >= 16)",
                "        return ARES_EBADSTR;",
                "          if (q-str >= 32)",
                "            return ARES_EBADSTR;"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-43267",
        "func_name": "torvalds/linux/tipc_crypto_key_rcv",
        "description": "An issue was discovered in net/tipc/crypto.c in the Linux kernel before 5.14.16. The Transparent Inter-Process Communication (TIPC) functionality allows remote attackers to exploit insufficient validation of user-supplied sizes for the MSG_CRYPTO message type.",
        "git_url": "https://github.com/torvalds/linux/commit/fa40d9734a57bcbfa79a280189799f76c88f7bb0",
        "commit_title": "tipc: fix size validations for the MSG_CRYPTO type",
        "commit_text": " The function tipc_crypto_key_rcv is used to parse MSG_CRYPTO messages to receive keys from other nodes in the cluster in order to decrypt any further messages from them. This patch verifies that any supplied sizes in the message body are valid for the received message. ",
        "func_before": "static bool tipc_crypto_key_rcv(struct tipc_crypto *rx, struct tipc_msg *hdr)\n{\n\tstruct tipc_crypto *tx = tipc_net(rx->net)->crypto_tx;\n\tstruct tipc_aead_key *skey = NULL;\n\tu16 key_gen = msg_key_gen(hdr);\n\tu16 size = msg_data_sz(hdr);\n\tu8 *data = msg_data(hdr);\n\n\tspin_lock(&rx->lock);\n\tif (unlikely(rx->skey || (key_gen == rx->key_gen && rx->key.keys))) {\n\t\tpr_err(\"%s: key existed <%p>, gen %d vs %d\\n\", rx->name,\n\t\t       rx->skey, key_gen, rx->key_gen);\n\t\tgoto exit;\n\t}\n\n\t/* Allocate memory for the key */\n\tskey = kmalloc(size, GFP_ATOMIC);\n\tif (unlikely(!skey)) {\n\t\tpr_err(\"%s: unable to allocate memory for skey\\n\", rx->name);\n\t\tgoto exit;\n\t}\n\n\t/* Copy key from msg data */\n\tskey->keylen = ntohl(*((__be32 *)(data + TIPC_AEAD_ALG_NAME)));\n\tmemcpy(skey->alg_name, data, TIPC_AEAD_ALG_NAME);\n\tmemcpy(skey->key, data + TIPC_AEAD_ALG_NAME + sizeof(__be32),\n\t       skey->keylen);\n\n\t/* Sanity check */\n\tif (unlikely(size != tipc_aead_key_size(skey))) {\n\t\tkfree(skey);\n\t\tskey = NULL;\n\t\tgoto exit;\n\t}\n\n\trx->key_gen = key_gen;\n\trx->skey_mode = msg_key_mode(hdr);\n\trx->skey = skey;\n\trx->nokey = 0;\n\tmb(); /* for nokey flag */\n\nexit:\n\tspin_unlock(&rx->lock);\n\n\t/* Schedule the key attaching on this crypto */\n\tif (likely(skey && queue_delayed_work(tx->wq, &rx->work, 0)))\n\t\treturn true;\n\n\treturn false;\n}",
        "func": "static bool tipc_crypto_key_rcv(struct tipc_crypto *rx, struct tipc_msg *hdr)\n{\n\tstruct tipc_crypto *tx = tipc_net(rx->net)->crypto_tx;\n\tstruct tipc_aead_key *skey = NULL;\n\tu16 key_gen = msg_key_gen(hdr);\n\tu16 size = msg_data_sz(hdr);\n\tu8 *data = msg_data(hdr);\n\tunsigned int keylen;\n\n\t/* Verify whether the size can exist in the packet */\n\tif (unlikely(size < sizeof(struct tipc_aead_key) + TIPC_AEAD_KEYLEN_MIN)) {\n\t\tpr_debug(\"%s: message data size is too small\\n\", rx->name);\n\t\tgoto exit;\n\t}\n\n\tkeylen = ntohl(*((__be32 *)(data + TIPC_AEAD_ALG_NAME)));\n\n\t/* Verify the supplied size values */\n\tif (unlikely(size != keylen + sizeof(struct tipc_aead_key) ||\n\t\t     keylen > TIPC_AEAD_KEY_SIZE_MAX)) {\n\t\tpr_debug(\"%s: invalid MSG_CRYPTO key size\\n\", rx->name);\n\t\tgoto exit;\n\t}\n\n\tspin_lock(&rx->lock);\n\tif (unlikely(rx->skey || (key_gen == rx->key_gen && rx->key.keys))) {\n\t\tpr_err(\"%s: key existed <%p>, gen %d vs %d\\n\", rx->name,\n\t\t       rx->skey, key_gen, rx->key_gen);\n\t\tgoto exit_unlock;\n\t}\n\n\t/* Allocate memory for the key */\n\tskey = kmalloc(size, GFP_ATOMIC);\n\tif (unlikely(!skey)) {\n\t\tpr_err(\"%s: unable to allocate memory for skey\\n\", rx->name);\n\t\tgoto exit_unlock;\n\t}\n\n\t/* Copy key from msg data */\n\tskey->keylen = keylen;\n\tmemcpy(skey->alg_name, data, TIPC_AEAD_ALG_NAME);\n\tmemcpy(skey->key, data + TIPC_AEAD_ALG_NAME + sizeof(__be32),\n\t       skey->keylen);\n\n\trx->key_gen = key_gen;\n\trx->skey_mode = msg_key_mode(hdr);\n\trx->skey = skey;\n\trx->nokey = 0;\n\tmb(); /* for nokey flag */\n\nexit_unlock:\n\tspin_unlock(&rx->lock);\n\nexit:\n\t/* Schedule the key attaching on this crypto */\n\tif (likely(skey && queue_delayed_work(tx->wq, &rx->work, 0)))\n\t\treturn true;\n\n\treturn false;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,33 +5,42 @@\n \tu16 key_gen = msg_key_gen(hdr);\n \tu16 size = msg_data_sz(hdr);\n \tu8 *data = msg_data(hdr);\n+\tunsigned int keylen;\n+\n+\t/* Verify whether the size can exist in the packet */\n+\tif (unlikely(size < sizeof(struct tipc_aead_key) + TIPC_AEAD_KEYLEN_MIN)) {\n+\t\tpr_debug(\"%s: message data size is too small\\n\", rx->name);\n+\t\tgoto exit;\n+\t}\n+\n+\tkeylen = ntohl(*((__be32 *)(data + TIPC_AEAD_ALG_NAME)));\n+\n+\t/* Verify the supplied size values */\n+\tif (unlikely(size != keylen + sizeof(struct tipc_aead_key) ||\n+\t\t     keylen > TIPC_AEAD_KEY_SIZE_MAX)) {\n+\t\tpr_debug(\"%s: invalid MSG_CRYPTO key size\\n\", rx->name);\n+\t\tgoto exit;\n+\t}\n \n \tspin_lock(&rx->lock);\n \tif (unlikely(rx->skey || (key_gen == rx->key_gen && rx->key.keys))) {\n \t\tpr_err(\"%s: key existed <%p>, gen %d vs %d\\n\", rx->name,\n \t\t       rx->skey, key_gen, rx->key_gen);\n-\t\tgoto exit;\n+\t\tgoto exit_unlock;\n \t}\n \n \t/* Allocate memory for the key */\n \tskey = kmalloc(size, GFP_ATOMIC);\n \tif (unlikely(!skey)) {\n \t\tpr_err(\"%s: unable to allocate memory for skey\\n\", rx->name);\n-\t\tgoto exit;\n+\t\tgoto exit_unlock;\n \t}\n \n \t/* Copy key from msg data */\n-\tskey->keylen = ntohl(*((__be32 *)(data + TIPC_AEAD_ALG_NAME)));\n+\tskey->keylen = keylen;\n \tmemcpy(skey->alg_name, data, TIPC_AEAD_ALG_NAME);\n \tmemcpy(skey->key, data + TIPC_AEAD_ALG_NAME + sizeof(__be32),\n \t       skey->keylen);\n-\n-\t/* Sanity check */\n-\tif (unlikely(size != tipc_aead_key_size(skey))) {\n-\t\tkfree(skey);\n-\t\tskey = NULL;\n-\t\tgoto exit;\n-\t}\n \n \trx->key_gen = key_gen;\n \trx->skey_mode = msg_key_mode(hdr);\n@@ -39,9 +48,10 @@\n \trx->nokey = 0;\n \tmb(); /* for nokey flag */\n \n-exit:\n+exit_unlock:\n \tspin_unlock(&rx->lock);\n \n+exit:\n \t/* Schedule the key attaching on this crypto */\n \tif (likely(skey && queue_delayed_work(tx->wq, &rx->work, 0)))\n \t\treturn true;",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tgoto exit;",
                "\t\tgoto exit;",
                "\tskey->keylen = ntohl(*((__be32 *)(data + TIPC_AEAD_ALG_NAME)));",
                "",
                "\t/* Sanity check */",
                "\tif (unlikely(size != tipc_aead_key_size(skey))) {",
                "\t\tkfree(skey);",
                "\t\tskey = NULL;",
                "\t\tgoto exit;",
                "\t}",
                "exit:"
            ],
            "added_lines": [
                "\tunsigned int keylen;",
                "",
                "\t/* Verify whether the size can exist in the packet */",
                "\tif (unlikely(size < sizeof(struct tipc_aead_key) + TIPC_AEAD_KEYLEN_MIN)) {",
                "\t\tpr_debug(\"%s: message data size is too small\\n\", rx->name);",
                "\t\tgoto exit;",
                "\t}",
                "",
                "\tkeylen = ntohl(*((__be32 *)(data + TIPC_AEAD_ALG_NAME)));",
                "",
                "\t/* Verify the supplied size values */",
                "\tif (unlikely(size != keylen + sizeof(struct tipc_aead_key) ||",
                "\t\t     keylen > TIPC_AEAD_KEY_SIZE_MAX)) {",
                "\t\tpr_debug(\"%s: invalid MSG_CRYPTO key size\\n\", rx->name);",
                "\t\tgoto exit;",
                "\t}",
                "\t\tgoto exit_unlock;",
                "\t\tgoto exit_unlock;",
                "\tskey->keylen = keylen;",
                "exit_unlock:",
                "exit:"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-45462",
        "func_name": "open5gs/_gtpv1_u_recv_cb",
        "description": "In Open5GS 2.4.0, a crafted packet from UE can crash SGW-U/UPF.",
        "git_url": "https://github.com/open5gs/open5gs/commit/a0f2535cb5a29bba6dbbccdb90c74ccd770cc700",
        "commit_title": "A crafted packet from UE can crash SGW-U/UPF",
        "commit_text": "",
        "func_before": "static void _gtpv1_u_recv_cb(short when, ogs_socket_t fd, void *data)\n{\n    int len;\n    ssize_t size;\n    char buf[OGS_ADDRSTRLEN];\n\n    sgwu_sess_t *sess = NULL;\n\n    ogs_pkbuf_t *pkbuf = NULL;\n    ogs_sockaddr_t from;\n\n    ogs_gtp_header_t *gtp_h = NULL;\n    ogs_pfcp_user_plane_report_t report;\n\n    uint32_t teid;\n    uint8_t qfi;\n\n    ogs_assert(fd != INVALID_SOCKET);\n\n    pkbuf = ogs_pkbuf_alloc(packet_pool, OGS_MAX_PKT_LEN);\n    ogs_assert(pkbuf);\n    ogs_pkbuf_put(pkbuf, OGS_MAX_PKT_LEN);\n\n    size = ogs_recvfrom(fd, pkbuf->data, pkbuf->len, 0, &from);\n    if (size <= 0) {\n        ogs_log_message(OGS_LOG_ERROR, ogs_socket_errno,\n                \"ogs_recv() failed\");\n        goto cleanup;\n    }\n\n    ogs_pkbuf_trim(pkbuf, size);\n\n    ogs_assert(pkbuf);\n    ogs_assert(pkbuf->len);\n\n    gtp_h = (ogs_gtp_header_t *)pkbuf->data;\n    if (gtp_h->version != OGS_GTP_VERSION_1) {\n        ogs_error(\"[DROP] Invalid GTPU version [%d]\", gtp_h->version);\n        ogs_log_hexdump(OGS_LOG_ERROR, pkbuf->data, pkbuf->len);\n        goto cleanup;\n    }\n\n    if (gtp_h->type == OGS_GTPU_MSGTYPE_ECHO_REQ) {\n        ogs_pkbuf_t *echo_rsp;\n\n        ogs_debug(\"[RECV] Echo Request from [%s]\", OGS_ADDR(&from, buf));\n        echo_rsp = ogs_gtp_handle_echo_req(pkbuf);\n        ogs_expect(echo_rsp);\n        if (echo_rsp) {\n            ssize_t sent;\n\n            /* Echo reply */\n            ogs_debug(\"[SEND] Echo Response to [%s]\", OGS_ADDR(&from, buf));\n\n            sent = ogs_sendto(fd, echo_rsp->data, echo_rsp->len, 0, &from);\n            if (sent < 0 || sent != echo_rsp->len) {\n                ogs_log_message(OGS_LOG_ERROR, ogs_socket_errno,\n                        \"ogs_sendto() failed\");\n            }\n            ogs_pkbuf_free(echo_rsp);\n        }\n        goto cleanup;\n    }\n\n    teid = be32toh(gtp_h->teid);\n\n    ogs_debug(\"[RECV] GPU-U Type [%d] from [%s] : TEID[0x%x]\",\n            gtp_h->type, OGS_ADDR(&from, buf), teid);\n\n    qfi = 0;\n    if (gtp_h->flags & OGS_GTPU_FLAGS_E) {\n        /*\n         * TS29.281\n         * 5.2.1 General format of the GTP-U Extension Header\n         * Figure 5.2.1-3: Definition of Extension Header Type\n         *\n         * Note 4 : For a GTP-PDU with several Extension Headers, the PDU\n         *          Session Container should be the first Extension Header\n         */\n        ogs_gtp_extension_header_t *extension_header =\n            (ogs_gtp_extension_header_t *)(pkbuf->data + OGS_GTPV1U_HEADER_LEN);\n        ogs_assert(extension_header);\n        if (extension_header->type ==\n                OGS_GTP_EXTENSION_HEADER_TYPE_PDU_SESSION_CONTAINER) {\n            if (extension_header->pdu_type ==\n                OGS_GTP_EXTENSION_HEADER_PDU_TYPE_UL_PDU_SESSION_INFORMATION) {\n                    ogs_debug(\"   QFI [0x%x]\",\n                            extension_header->qos_flow_identifier);\n                    qfi = extension_header->qos_flow_identifier;\n            }\n        }\n    }\n\n    /* Remove GTP header and send packets to peer NF */\n    len = ogs_gtpu_header_len(pkbuf);\n    if (len < 0) {\n        ogs_error(\"[DROP] Cannot decode GTPU packet\");\n        ogs_log_hexdump(OGS_LOG_ERROR, pkbuf->data, pkbuf->len);\n        goto cleanup;\n    }\n    ogs_assert(ogs_pkbuf_pull(pkbuf, len));\n\n    if (gtp_h->type == OGS_GTPU_MSGTYPE_END_MARKER) {\n        /* Nothing */\n\n    } else if (gtp_h->type == OGS_GTPU_MSGTYPE_ERR_IND) {\n        ogs_pfcp_far_t *far = NULL;\n\n        far = ogs_pfcp_far_find_by_error_indication(pkbuf);\n        if (far) {\n            ogs_assert(true ==\n                ogs_pfcp_up_handle_error_indication(far, &report));\n\n            if (report.type.error_indication_report) {\n                ogs_assert(far->sess);\n                sess = SGWU_SESS(far->sess);\n                ogs_assert(sess);\n\n                ogs_assert(OGS_OK ==\n                    sgwu_pfcp_send_session_report_request(sess, &report));\n            }\n\n        } else {\n            ogs_error(\"[DROP] Cannot find FAR by Error-Indication\");\n            ogs_log_hexdump(OGS_LOG_ERROR, pkbuf->data, pkbuf->len);\n        }\n    } else if (gtp_h->type == OGS_GTPU_MSGTYPE_GPDU) {\n        struct ip *ip_h = NULL;\n        ogs_pfcp_object_t *pfcp_object = NULL;\n        ogs_pfcp_sess_t *pfcp_sess = NULL;\n        ogs_pfcp_pdr_t *pdr = NULL;\n\n        ip_h = (struct ip *)pkbuf->data;\n        ogs_assert(ip_h);\n\n        pfcp_object = ogs_pfcp_object_find_by_teid(teid);\n        if (!pfcp_object) {\n            /* TODO : Send Error Indication */\n            goto cleanup;\n        }\n\n        switch(pfcp_object->type) {\n        case OGS_PFCP_OBJ_PDR_TYPE:\n            pdr = (ogs_pfcp_pdr_t *)pfcp_object;\n            ogs_assert(pdr);\n            break;\n        case OGS_PFCP_OBJ_SESS_TYPE:\n            pfcp_sess = (ogs_pfcp_sess_t *)pfcp_object;\n            ogs_assert(pfcp_sess);\n\n            ogs_list_for_each(&pfcp_sess->pdr_list, pdr) {\n                /* Check if Source Interface */\n                if (pdr->src_if != OGS_PFCP_INTERFACE_ACCESS &&\n                    pdr->src_if != OGS_PFCP_INTERFACE_CP_FUNCTION)\n                    continue;\n\n                /* Check if TEID */\n                if (teid != pdr->f_teid.teid)\n                    continue;\n\n                /* Check if QFI */\n                if (qfi && pdr->qfi != qfi)\n                    continue;\n\n                /* Check if Rule List in PDR */\n                if (ogs_list_first(&pdr->rule_list) &&\n                    ogs_pfcp_pdr_rule_find_by_packet(pdr, pkbuf) == NULL)\n                    continue;\n\n                break;\n            }\n\n            if (!pdr) {\n                /* TODO : Send Error Indication */\n                goto cleanup;\n            }\n\n            break;\n        default:\n            ogs_fatal(\"Unknown type [%d]\", pfcp_object->type);\n            ogs_assert_if_reached();\n        }\n\n        ogs_assert(pdr);\n        ogs_assert(true == ogs_pfcp_up_handle_pdr(pdr, pkbuf, &report));\n\n        if (report.type.downlink_data_report) {\n            ogs_assert(pdr->sess);\n            ogs_assert(pdr->sess->obj.type == OGS_PFCP_OBJ_SESS_TYPE);\n            sess = SGWU_SESS(pdr->sess);\n            ogs_assert(sess);\n\n            report.downlink_data.pdr_id = pdr->id;\n            report.downlink_data.qfi = qfi; /* for 5GC */\n\n            ogs_assert(OGS_OK ==\n                sgwu_pfcp_send_session_report_request(sess, &report));\n        }\n    } else {\n        ogs_error(\"[DROP] Invalid GTPU Type [%d]\", gtp_h->type);\n        ogs_log_hexdump(OGS_LOG_ERROR, pkbuf->data, pkbuf->len);\n    }\n\ncleanup:\n    ogs_pkbuf_free(pkbuf);\n}",
        "func": "static void _gtpv1_u_recv_cb(short when, ogs_socket_t fd, void *data)\n{\n    int len;\n    ssize_t size;\n    char buf[OGS_ADDRSTRLEN];\n\n    sgwu_sess_t *sess = NULL;\n\n    ogs_pkbuf_t *pkbuf = NULL;\n    ogs_sockaddr_t from;\n\n    ogs_gtp_header_t *gtp_h = NULL;\n    ogs_pfcp_user_plane_report_t report;\n\n    uint32_t teid;\n    uint8_t qfi;\n\n    ogs_assert(fd != INVALID_SOCKET);\n\n    pkbuf = ogs_pkbuf_alloc(packet_pool, OGS_MAX_PKT_LEN);\n    ogs_assert(pkbuf);\n    ogs_pkbuf_put(pkbuf, OGS_MAX_PKT_LEN);\n\n    size = ogs_recvfrom(fd, pkbuf->data, pkbuf->len, 0, &from);\n    if (size <= 0) {\n        ogs_log_message(OGS_LOG_ERROR, ogs_socket_errno,\n                \"ogs_recv() failed\");\n        goto cleanup;\n    }\n\n    ogs_pkbuf_trim(pkbuf, size);\n\n    ogs_assert(pkbuf);\n    ogs_assert(pkbuf->len);\n\n    gtp_h = (ogs_gtp_header_t *)pkbuf->data;\n    if (gtp_h->version != OGS_GTP_VERSION_1) {\n        ogs_error(\"[DROP] Invalid GTPU version [%d]\", gtp_h->version);\n        ogs_log_hexdump(OGS_LOG_ERROR, pkbuf->data, pkbuf->len);\n        goto cleanup;\n    }\n\n    if (gtp_h->type == OGS_GTPU_MSGTYPE_ECHO_REQ) {\n        ogs_pkbuf_t *echo_rsp;\n\n        ogs_debug(\"[RECV] Echo Request from [%s]\", OGS_ADDR(&from, buf));\n        echo_rsp = ogs_gtp_handle_echo_req(pkbuf);\n        ogs_expect(echo_rsp);\n        if (echo_rsp) {\n            ssize_t sent;\n\n            /* Echo reply */\n            ogs_debug(\"[SEND] Echo Response to [%s]\", OGS_ADDR(&from, buf));\n\n            sent = ogs_sendto(fd, echo_rsp->data, echo_rsp->len, 0, &from);\n            if (sent < 0 || sent != echo_rsp->len) {\n                ogs_log_message(OGS_LOG_ERROR, ogs_socket_errno,\n                        \"ogs_sendto() failed\");\n            }\n            ogs_pkbuf_free(echo_rsp);\n        }\n        goto cleanup;\n    }\n\n    teid = be32toh(gtp_h->teid);\n\n    ogs_debug(\"[RECV] GPU-U Type [%d] from [%s] : TEID[0x%x]\",\n            gtp_h->type, OGS_ADDR(&from, buf), teid);\n\n    qfi = 0;\n    if (gtp_h->flags & OGS_GTPU_FLAGS_E) {\n        /*\n         * TS29.281\n         * 5.2.1 General format of the GTP-U Extension Header\n         * Figure 5.2.1-3: Definition of Extension Header Type\n         *\n         * Note 4 : For a GTP-PDU with several Extension Headers, the PDU\n         *          Session Container should be the first Extension Header\n         */\n        ogs_gtp_extension_header_t *extension_header =\n            (ogs_gtp_extension_header_t *)(pkbuf->data + OGS_GTPV1U_HEADER_LEN);\n        ogs_assert(extension_header);\n        if (extension_header->type ==\n                OGS_GTP_EXTENSION_HEADER_TYPE_PDU_SESSION_CONTAINER) {\n            if (extension_header->pdu_type ==\n                OGS_GTP_EXTENSION_HEADER_PDU_TYPE_UL_PDU_SESSION_INFORMATION) {\n                    ogs_debug(\"   QFI [0x%x]\",\n                            extension_header->qos_flow_identifier);\n                    qfi = extension_header->qos_flow_identifier;\n            }\n        }\n    }\n\n    /* Remove GTP header and send packets to peer NF */\n    len = ogs_gtpu_header_len(pkbuf);\n    if (len < 0) {\n        ogs_error(\"[DROP] Cannot decode GTPU packet\");\n        ogs_log_hexdump(OGS_LOG_ERROR, pkbuf->data, pkbuf->len);\n        goto cleanup;\n    }\n    if (gtp_h->type != OGS_GTPU_MSGTYPE_END_MARKER &&\n        pkbuf->len <= len) {\n        ogs_error(\"[DROP] Small GTPU packet(type:%d len:%d)\", gtp_h->type, len);\n        ogs_log_hexdump(OGS_LOG_ERROR, pkbuf->data, pkbuf->len);\n        goto cleanup;\n    }\n    ogs_assert(ogs_pkbuf_pull(pkbuf, len));\n\n    if (gtp_h->type == OGS_GTPU_MSGTYPE_END_MARKER) {\n        /* Nothing */\n\n    } else if (gtp_h->type == OGS_GTPU_MSGTYPE_ERR_IND) {\n        ogs_pfcp_far_t *far = NULL;\n\n        far = ogs_pfcp_far_find_by_error_indication(pkbuf);\n        if (far) {\n            ogs_assert(true ==\n                ogs_pfcp_up_handle_error_indication(far, &report));\n\n            if (report.type.error_indication_report) {\n                ogs_assert(far->sess);\n                sess = SGWU_SESS(far->sess);\n                ogs_assert(sess);\n\n                ogs_assert(OGS_OK ==\n                    sgwu_pfcp_send_session_report_request(sess, &report));\n            }\n\n        } else {\n            ogs_error(\"[DROP] Cannot find FAR by Error-Indication\");\n            ogs_log_hexdump(OGS_LOG_ERROR, pkbuf->data, pkbuf->len);\n        }\n    } else if (gtp_h->type == OGS_GTPU_MSGTYPE_GPDU) {\n        struct ip *ip_h = NULL;\n        ogs_pfcp_object_t *pfcp_object = NULL;\n        ogs_pfcp_sess_t *pfcp_sess = NULL;\n        ogs_pfcp_pdr_t *pdr = NULL;\n\n        ip_h = (struct ip *)pkbuf->data;\n        ogs_assert(ip_h);\n\n        pfcp_object = ogs_pfcp_object_find_by_teid(teid);\n        if (!pfcp_object) {\n            /* TODO : Send Error Indication */\n            goto cleanup;\n        }\n\n        switch(pfcp_object->type) {\n        case OGS_PFCP_OBJ_PDR_TYPE:\n            pdr = (ogs_pfcp_pdr_t *)pfcp_object;\n            ogs_assert(pdr);\n            break;\n        case OGS_PFCP_OBJ_SESS_TYPE:\n            pfcp_sess = (ogs_pfcp_sess_t *)pfcp_object;\n            ogs_assert(pfcp_sess);\n\n            ogs_list_for_each(&pfcp_sess->pdr_list, pdr) {\n                /* Check if Source Interface */\n                if (pdr->src_if != OGS_PFCP_INTERFACE_ACCESS &&\n                    pdr->src_if != OGS_PFCP_INTERFACE_CP_FUNCTION)\n                    continue;\n\n                /* Check if TEID */\n                if (teid != pdr->f_teid.teid)\n                    continue;\n\n                /* Check if QFI */\n                if (qfi && pdr->qfi != qfi)\n                    continue;\n\n                /* Check if Rule List in PDR */\n                if (ogs_list_first(&pdr->rule_list) &&\n                    ogs_pfcp_pdr_rule_find_by_packet(pdr, pkbuf) == NULL)\n                    continue;\n\n                break;\n            }\n\n            if (!pdr) {\n                /* TODO : Send Error Indication */\n                goto cleanup;\n            }\n\n            break;\n        default:\n            ogs_fatal(\"Unknown type [%d]\", pfcp_object->type);\n            ogs_assert_if_reached();\n        }\n\n        ogs_assert(pdr);\n        ogs_assert(true == ogs_pfcp_up_handle_pdr(pdr, pkbuf, &report));\n\n        if (report.type.downlink_data_report) {\n            ogs_assert(pdr->sess);\n            ogs_assert(pdr->sess->obj.type == OGS_PFCP_OBJ_SESS_TYPE);\n            sess = SGWU_SESS(pdr->sess);\n            ogs_assert(sess);\n\n            report.downlink_data.pdr_id = pdr->id;\n            report.downlink_data.qfi = qfi; /* for 5GC */\n\n            ogs_assert(OGS_OK ==\n                sgwu_pfcp_send_session_report_request(sess, &report));\n        }\n    } else {\n        ogs_error(\"[DROP] Invalid GTPU Type [%d]\", gtp_h->type);\n        ogs_log_hexdump(OGS_LOG_ERROR, pkbuf->data, pkbuf->len);\n    }\n\ncleanup:\n    ogs_pkbuf_free(pkbuf);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -98,6 +98,12 @@\n         ogs_log_hexdump(OGS_LOG_ERROR, pkbuf->data, pkbuf->len);\n         goto cleanup;\n     }\n+    if (gtp_h->type != OGS_GTPU_MSGTYPE_END_MARKER &&\n+        pkbuf->len <= len) {\n+        ogs_error(\"[DROP] Small GTPU packet(type:%d len:%d)\", gtp_h->type, len);\n+        ogs_log_hexdump(OGS_LOG_ERROR, pkbuf->data, pkbuf->len);\n+        goto cleanup;\n+    }\n     ogs_assert(ogs_pkbuf_pull(pkbuf, len));\n \n     if (gtp_h->type == OGS_GTPU_MSGTYPE_END_MARKER) {",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    if (gtp_h->type != OGS_GTPU_MSGTYPE_END_MARKER &&",
                "        pkbuf->len <= len) {",
                "        ogs_error(\"[DROP] Small GTPU packet(type:%d len:%d)\", gtp_h->type, len);",
                "        ogs_log_hexdump(OGS_LOG_ERROR, pkbuf->data, pkbuf->len);",
                "        goto cleanup;",
                "    }"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-45462",
        "func_name": "open5gs/_gtpv1_u_recv_cb",
        "description": "In Open5GS 2.4.0, a crafted packet from UE can crash SGW-U/UPF.",
        "git_url": "https://github.com/open5gs/open5gs/commit/a0f2535cb5a29bba6dbbccdb90c74ccd770cc700",
        "commit_title": "A crafted packet from UE can crash SGW-U/UPF",
        "commit_text": "",
        "func_before": "static void _gtpv1_u_recv_cb(short when, ogs_socket_t fd, void *data)\n{\n    int len;\n    ssize_t size;\n    char buf[OGS_ADDRSTRLEN];\n\n    sgwu_sess_t *sess = NULL;\n\n    ogs_pkbuf_t *pkbuf = NULL;\n    ogs_sockaddr_t from;\n\n    ogs_gtp_header_t *gtp_h = NULL;\n    ogs_pfcp_user_plane_report_t report;\n\n    uint32_t teid;\n    uint8_t qfi;\n\n    ogs_assert(fd != INVALID_SOCKET);\n\n    pkbuf = ogs_pkbuf_alloc(packet_pool, OGS_MAX_PKT_LEN);\n    ogs_assert(pkbuf);\n    ogs_pkbuf_put(pkbuf, OGS_MAX_PKT_LEN);\n\n    size = ogs_recvfrom(fd, pkbuf->data, pkbuf->len, 0, &from);\n    if (size <= 0) {\n        ogs_log_message(OGS_LOG_ERROR, ogs_socket_errno,\n                \"ogs_recv() failed\");\n        goto cleanup;\n    }\n\n    ogs_pkbuf_trim(pkbuf, size);\n\n    ogs_assert(pkbuf);\n    ogs_assert(pkbuf->len);\n\n    gtp_h = (ogs_gtp_header_t *)pkbuf->data;\n    if (gtp_h->version != OGS_GTP_VERSION_1) {\n        ogs_error(\"[DROP] Invalid GTPU version [%d]\", gtp_h->version);\n        ogs_log_hexdump(OGS_LOG_ERROR, pkbuf->data, pkbuf->len);\n        goto cleanup;\n    }\n\n    if (gtp_h->type == OGS_GTPU_MSGTYPE_ECHO_REQ) {\n        ogs_pkbuf_t *echo_rsp;\n\n        ogs_debug(\"[RECV] Echo Request from [%s]\", OGS_ADDR(&from, buf));\n        echo_rsp = ogs_gtp_handle_echo_req(pkbuf);\n        ogs_expect(echo_rsp);\n        if (echo_rsp) {\n            ssize_t sent;\n\n            /* Echo reply */\n            ogs_debug(\"[SEND] Echo Response to [%s]\", OGS_ADDR(&from, buf));\n\n            sent = ogs_sendto(fd, echo_rsp->data, echo_rsp->len, 0, &from);\n            if (sent < 0 || sent != echo_rsp->len) {\n                ogs_log_message(OGS_LOG_ERROR, ogs_socket_errno,\n                        \"ogs_sendto() failed\");\n            }\n            ogs_pkbuf_free(echo_rsp);\n        }\n        goto cleanup;\n    }\n\n    teid = be32toh(gtp_h->teid);\n\n    ogs_debug(\"[RECV] GPU-U Type [%d] from [%s] : TEID[0x%x]\",\n            gtp_h->type, OGS_ADDR(&from, buf), teid);\n\n    qfi = 0;\n    if (gtp_h->flags & OGS_GTPU_FLAGS_E) {\n        /*\n         * TS29.281\n         * 5.2.1 General format of the GTP-U Extension Header\n         * Figure 5.2.1-3: Definition of Extension Header Type\n         *\n         * Note 4 : For a GTP-PDU with several Extension Headers, the PDU\n         *          Session Container should be the first Extension Header\n         */\n        ogs_gtp_extension_header_t *extension_header =\n            (ogs_gtp_extension_header_t *)(pkbuf->data + OGS_GTPV1U_HEADER_LEN);\n        ogs_assert(extension_header);\n        if (extension_header->type ==\n                OGS_GTP_EXTENSION_HEADER_TYPE_PDU_SESSION_CONTAINER) {\n            if (extension_header->pdu_type ==\n                OGS_GTP_EXTENSION_HEADER_PDU_TYPE_UL_PDU_SESSION_INFORMATION) {\n                    ogs_debug(\"   QFI [0x%x]\",\n                            extension_header->qos_flow_identifier);\n                    qfi = extension_header->qos_flow_identifier;\n            }\n        }\n    }\n\n    /* Remove GTP header and send packets to peer NF */\n    len = ogs_gtpu_header_len(pkbuf);\n    if (len < 0) {\n        ogs_error(\"[DROP] Cannot decode GTPU packet\");\n        ogs_log_hexdump(OGS_LOG_ERROR, pkbuf->data, pkbuf->len);\n        goto cleanup;\n    }\n    ogs_assert(ogs_pkbuf_pull(pkbuf, len));\n\n    if (gtp_h->type == OGS_GTPU_MSGTYPE_END_MARKER) {\n        /* Nothing */\n\n    } else if (gtp_h->type == OGS_GTPU_MSGTYPE_ERR_IND) {\n        ogs_pfcp_far_t *far = NULL;\n\n        far = ogs_pfcp_far_find_by_error_indication(pkbuf);\n        if (far) {\n            ogs_assert(true ==\n                ogs_pfcp_up_handle_error_indication(far, &report));\n\n            if (report.type.error_indication_report) {\n                ogs_assert(far->sess);\n                sess = SGWU_SESS(far->sess);\n                ogs_assert(sess);\n\n                ogs_assert(OGS_OK ==\n                    sgwu_pfcp_send_session_report_request(sess, &report));\n            }\n\n        } else {\n            ogs_error(\"[DROP] Cannot find FAR by Error-Indication\");\n            ogs_log_hexdump(OGS_LOG_ERROR, pkbuf->data, pkbuf->len);\n        }\n    } else if (gtp_h->type == OGS_GTPU_MSGTYPE_GPDU) {\n        struct ip *ip_h = NULL;\n        ogs_pfcp_object_t *pfcp_object = NULL;\n        ogs_pfcp_sess_t *pfcp_sess = NULL;\n        ogs_pfcp_pdr_t *pdr = NULL;\n\n        ip_h = (struct ip *)pkbuf->data;\n        ogs_assert(ip_h);\n\n        pfcp_object = ogs_pfcp_object_find_by_teid(teid);\n        if (!pfcp_object) {\n            /* TODO : Send Error Indication */\n            goto cleanup;\n        }\n\n        switch(pfcp_object->type) {\n        case OGS_PFCP_OBJ_PDR_TYPE:\n            pdr = (ogs_pfcp_pdr_t *)pfcp_object;\n            ogs_assert(pdr);\n            break;\n        case OGS_PFCP_OBJ_SESS_TYPE:\n            pfcp_sess = (ogs_pfcp_sess_t *)pfcp_object;\n            ogs_assert(pfcp_sess);\n\n            ogs_list_for_each(&pfcp_sess->pdr_list, pdr) {\n                /* Check if Source Interface */\n                if (pdr->src_if != OGS_PFCP_INTERFACE_ACCESS &&\n                    pdr->src_if != OGS_PFCP_INTERFACE_CP_FUNCTION)\n                    continue;\n\n                /* Check if TEID */\n                if (teid != pdr->f_teid.teid)\n                    continue;\n\n                /* Check if QFI */\n                if (qfi && pdr->qfi != qfi)\n                    continue;\n\n                /* Check if Rule List in PDR */\n                if (ogs_list_first(&pdr->rule_list) &&\n                    ogs_pfcp_pdr_rule_find_by_packet(pdr, pkbuf) == NULL)\n                    continue;\n\n                break;\n            }\n\n            if (!pdr) {\n                /* TODO : Send Error Indication */\n                goto cleanup;\n            }\n\n            break;\n        default:\n            ogs_fatal(\"Unknown type [%d]\", pfcp_object->type);\n            ogs_assert_if_reached();\n        }\n\n        ogs_assert(pdr);\n        ogs_assert(true == ogs_pfcp_up_handle_pdr(pdr, pkbuf, &report));\n\n        if (report.type.downlink_data_report) {\n            ogs_assert(pdr->sess);\n            ogs_assert(pdr->sess->obj.type == OGS_PFCP_OBJ_SESS_TYPE);\n            sess = SGWU_SESS(pdr->sess);\n            ogs_assert(sess);\n\n            report.downlink_data.pdr_id = pdr->id;\n            report.downlink_data.qfi = qfi; /* for 5GC */\n\n            ogs_assert(OGS_OK ==\n                sgwu_pfcp_send_session_report_request(sess, &report));\n        }\n    } else {\n        ogs_error(\"[DROP] Invalid GTPU Type [%d]\", gtp_h->type);\n        ogs_log_hexdump(OGS_LOG_ERROR, pkbuf->data, pkbuf->len);\n    }\n\ncleanup:\n    ogs_pkbuf_free(pkbuf);\n}",
        "func": "static void _gtpv1_u_recv_cb(short when, ogs_socket_t fd, void *data)\n{\n    int len;\n    ssize_t size;\n    char buf[OGS_ADDRSTRLEN];\n\n    sgwu_sess_t *sess = NULL;\n\n    ogs_pkbuf_t *pkbuf = NULL;\n    ogs_sockaddr_t from;\n\n    ogs_gtp_header_t *gtp_h = NULL;\n    ogs_pfcp_user_plane_report_t report;\n\n    uint32_t teid;\n    uint8_t qfi;\n\n    ogs_assert(fd != INVALID_SOCKET);\n\n    pkbuf = ogs_pkbuf_alloc(packet_pool, OGS_MAX_PKT_LEN);\n    ogs_assert(pkbuf);\n    ogs_pkbuf_put(pkbuf, OGS_MAX_PKT_LEN);\n\n    size = ogs_recvfrom(fd, pkbuf->data, pkbuf->len, 0, &from);\n    if (size <= 0) {\n        ogs_log_message(OGS_LOG_ERROR, ogs_socket_errno,\n                \"ogs_recv() failed\");\n        goto cleanup;\n    }\n\n    ogs_pkbuf_trim(pkbuf, size);\n\n    ogs_assert(pkbuf);\n    ogs_assert(pkbuf->len);\n\n    gtp_h = (ogs_gtp_header_t *)pkbuf->data;\n    if (gtp_h->version != OGS_GTP_VERSION_1) {\n        ogs_error(\"[DROP] Invalid GTPU version [%d]\", gtp_h->version);\n        ogs_log_hexdump(OGS_LOG_ERROR, pkbuf->data, pkbuf->len);\n        goto cleanup;\n    }\n\n    if (gtp_h->type == OGS_GTPU_MSGTYPE_ECHO_REQ) {\n        ogs_pkbuf_t *echo_rsp;\n\n        ogs_debug(\"[RECV] Echo Request from [%s]\", OGS_ADDR(&from, buf));\n        echo_rsp = ogs_gtp_handle_echo_req(pkbuf);\n        ogs_expect(echo_rsp);\n        if (echo_rsp) {\n            ssize_t sent;\n\n            /* Echo reply */\n            ogs_debug(\"[SEND] Echo Response to [%s]\", OGS_ADDR(&from, buf));\n\n            sent = ogs_sendto(fd, echo_rsp->data, echo_rsp->len, 0, &from);\n            if (sent < 0 || sent != echo_rsp->len) {\n                ogs_log_message(OGS_LOG_ERROR, ogs_socket_errno,\n                        \"ogs_sendto() failed\");\n            }\n            ogs_pkbuf_free(echo_rsp);\n        }\n        goto cleanup;\n    }\n\n    teid = be32toh(gtp_h->teid);\n\n    ogs_debug(\"[RECV] GPU-U Type [%d] from [%s] : TEID[0x%x]\",\n            gtp_h->type, OGS_ADDR(&from, buf), teid);\n\n    qfi = 0;\n    if (gtp_h->flags & OGS_GTPU_FLAGS_E) {\n        /*\n         * TS29.281\n         * 5.2.1 General format of the GTP-U Extension Header\n         * Figure 5.2.1-3: Definition of Extension Header Type\n         *\n         * Note 4 : For a GTP-PDU with several Extension Headers, the PDU\n         *          Session Container should be the first Extension Header\n         */\n        ogs_gtp_extension_header_t *extension_header =\n            (ogs_gtp_extension_header_t *)(pkbuf->data + OGS_GTPV1U_HEADER_LEN);\n        ogs_assert(extension_header);\n        if (extension_header->type ==\n                OGS_GTP_EXTENSION_HEADER_TYPE_PDU_SESSION_CONTAINER) {\n            if (extension_header->pdu_type ==\n                OGS_GTP_EXTENSION_HEADER_PDU_TYPE_UL_PDU_SESSION_INFORMATION) {\n                    ogs_debug(\"   QFI [0x%x]\",\n                            extension_header->qos_flow_identifier);\n                    qfi = extension_header->qos_flow_identifier;\n            }\n        }\n    }\n\n    /* Remove GTP header and send packets to peer NF */\n    len = ogs_gtpu_header_len(pkbuf);\n    if (len < 0) {\n        ogs_error(\"[DROP] Cannot decode GTPU packet\");\n        ogs_log_hexdump(OGS_LOG_ERROR, pkbuf->data, pkbuf->len);\n        goto cleanup;\n    }\n    if (gtp_h->type != OGS_GTPU_MSGTYPE_END_MARKER &&\n        pkbuf->len <= len) {\n        ogs_error(\"[DROP] Small GTPU packet(type:%d len:%d)\", gtp_h->type, len);\n        ogs_log_hexdump(OGS_LOG_ERROR, pkbuf->data, pkbuf->len);\n        goto cleanup;\n    }\n    ogs_assert(ogs_pkbuf_pull(pkbuf, len));\n\n    if (gtp_h->type == OGS_GTPU_MSGTYPE_END_MARKER) {\n        /* Nothing */\n\n    } else if (gtp_h->type == OGS_GTPU_MSGTYPE_ERR_IND) {\n        ogs_pfcp_far_t *far = NULL;\n\n        far = ogs_pfcp_far_find_by_error_indication(pkbuf);\n        if (far) {\n            ogs_assert(true ==\n                ogs_pfcp_up_handle_error_indication(far, &report));\n\n            if (report.type.error_indication_report) {\n                ogs_assert(far->sess);\n                sess = SGWU_SESS(far->sess);\n                ogs_assert(sess);\n\n                ogs_assert(OGS_OK ==\n                    sgwu_pfcp_send_session_report_request(sess, &report));\n            }\n\n        } else {\n            ogs_error(\"[DROP] Cannot find FAR by Error-Indication\");\n            ogs_log_hexdump(OGS_LOG_ERROR, pkbuf->data, pkbuf->len);\n        }\n    } else if (gtp_h->type == OGS_GTPU_MSGTYPE_GPDU) {\n        struct ip *ip_h = NULL;\n        ogs_pfcp_object_t *pfcp_object = NULL;\n        ogs_pfcp_sess_t *pfcp_sess = NULL;\n        ogs_pfcp_pdr_t *pdr = NULL;\n\n        ip_h = (struct ip *)pkbuf->data;\n        ogs_assert(ip_h);\n\n        pfcp_object = ogs_pfcp_object_find_by_teid(teid);\n        if (!pfcp_object) {\n            /* TODO : Send Error Indication */\n            goto cleanup;\n        }\n\n        switch(pfcp_object->type) {\n        case OGS_PFCP_OBJ_PDR_TYPE:\n            pdr = (ogs_pfcp_pdr_t *)pfcp_object;\n            ogs_assert(pdr);\n            break;\n        case OGS_PFCP_OBJ_SESS_TYPE:\n            pfcp_sess = (ogs_pfcp_sess_t *)pfcp_object;\n            ogs_assert(pfcp_sess);\n\n            ogs_list_for_each(&pfcp_sess->pdr_list, pdr) {\n                /* Check if Source Interface */\n                if (pdr->src_if != OGS_PFCP_INTERFACE_ACCESS &&\n                    pdr->src_if != OGS_PFCP_INTERFACE_CP_FUNCTION)\n                    continue;\n\n                /* Check if TEID */\n                if (teid != pdr->f_teid.teid)\n                    continue;\n\n                /* Check if QFI */\n                if (qfi && pdr->qfi != qfi)\n                    continue;\n\n                /* Check if Rule List in PDR */\n                if (ogs_list_first(&pdr->rule_list) &&\n                    ogs_pfcp_pdr_rule_find_by_packet(pdr, pkbuf) == NULL)\n                    continue;\n\n                break;\n            }\n\n            if (!pdr) {\n                /* TODO : Send Error Indication */\n                goto cleanup;\n            }\n\n            break;\n        default:\n            ogs_fatal(\"Unknown type [%d]\", pfcp_object->type);\n            ogs_assert_if_reached();\n        }\n\n        ogs_assert(pdr);\n        ogs_assert(true == ogs_pfcp_up_handle_pdr(pdr, pkbuf, &report));\n\n        if (report.type.downlink_data_report) {\n            ogs_assert(pdr->sess);\n            ogs_assert(pdr->sess->obj.type == OGS_PFCP_OBJ_SESS_TYPE);\n            sess = SGWU_SESS(pdr->sess);\n            ogs_assert(sess);\n\n            report.downlink_data.pdr_id = pdr->id;\n            report.downlink_data.qfi = qfi; /* for 5GC */\n\n            ogs_assert(OGS_OK ==\n                sgwu_pfcp_send_session_report_request(sess, &report));\n        }\n    } else {\n        ogs_error(\"[DROP] Invalid GTPU Type [%d]\", gtp_h->type);\n        ogs_log_hexdump(OGS_LOG_ERROR, pkbuf->data, pkbuf->len);\n    }\n\ncleanup:\n    ogs_pkbuf_free(pkbuf);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -98,6 +98,12 @@\n         ogs_log_hexdump(OGS_LOG_ERROR, pkbuf->data, pkbuf->len);\n         goto cleanup;\n     }\n+    if (gtp_h->type != OGS_GTPU_MSGTYPE_END_MARKER &&\n+        pkbuf->len <= len) {\n+        ogs_error(\"[DROP] Small GTPU packet(type:%d len:%d)\", gtp_h->type, len);\n+        ogs_log_hexdump(OGS_LOG_ERROR, pkbuf->data, pkbuf->len);\n+        goto cleanup;\n+    }\n     ogs_assert(ogs_pkbuf_pull(pkbuf, len));\n \n     if (gtp_h->type == OGS_GTPU_MSGTYPE_END_MARKER) {",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    if (gtp_h->type != OGS_GTPU_MSGTYPE_END_MARKER &&",
                "        pkbuf->len <= len) {",
                "        ogs_error(\"[DROP] Small GTPU packet(type:%d len:%d)\", gtp_h->type, len);",
                "        ogs_log_hexdump(OGS_LOG_ERROR, pkbuf->data, pkbuf->len);",
                "        goto cleanup;",
                "    }"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-45462",
        "func_name": "open5gs/_gtpv1_u_recv_cb",
        "description": "In Open5GS 2.4.0, a crafted packet from UE can crash SGW-U/UPF.",
        "git_url": "https://github.com/open5gs/open5gs/commit/a0f2535cb5a29bba6dbbccdb90c74ccd770cc700",
        "commit_title": "A crafted packet from UE can crash SGW-U/UPF",
        "commit_text": "",
        "func_before": "static void _gtpv1_u_recv_cb(short when, ogs_socket_t fd, void *data)\n{\n    int len;\n    ssize_t size;\n    char buf[OGS_ADDRSTRLEN];\n\n    sgwu_sess_t *sess = NULL;\n\n    ogs_pkbuf_t *pkbuf = NULL;\n    ogs_sockaddr_t from;\n\n    ogs_gtp_header_t *gtp_h = NULL;\n    ogs_pfcp_user_plane_report_t report;\n\n    uint32_t teid;\n    uint8_t qfi;\n\n    ogs_assert(fd != INVALID_SOCKET);\n\n    pkbuf = ogs_pkbuf_alloc(packet_pool, OGS_MAX_PKT_LEN);\n    ogs_assert(pkbuf);\n    ogs_pkbuf_put(pkbuf, OGS_MAX_PKT_LEN);\n\n    size = ogs_recvfrom(fd, pkbuf->data, pkbuf->len, 0, &from);\n    if (size <= 0) {\n        ogs_log_message(OGS_LOG_ERROR, ogs_socket_errno,\n                \"ogs_recv() failed\");\n        goto cleanup;\n    }\n\n    ogs_pkbuf_trim(pkbuf, size);\n\n    ogs_assert(pkbuf);\n    ogs_assert(pkbuf->len);\n\n    gtp_h = (ogs_gtp_header_t *)pkbuf->data;\n    if (gtp_h->version != OGS_GTP_VERSION_1) {\n        ogs_error(\"[DROP] Invalid GTPU version [%d]\", gtp_h->version);\n        ogs_log_hexdump(OGS_LOG_ERROR, pkbuf->data, pkbuf->len);\n        goto cleanup;\n    }\n\n    if (gtp_h->type == OGS_GTPU_MSGTYPE_ECHO_REQ) {\n        ogs_pkbuf_t *echo_rsp;\n\n        ogs_debug(\"[RECV] Echo Request from [%s]\", OGS_ADDR(&from, buf));\n        echo_rsp = ogs_gtp_handle_echo_req(pkbuf);\n        ogs_expect(echo_rsp);\n        if (echo_rsp) {\n            ssize_t sent;\n\n            /* Echo reply */\n            ogs_debug(\"[SEND] Echo Response to [%s]\", OGS_ADDR(&from, buf));\n\n            sent = ogs_sendto(fd, echo_rsp->data, echo_rsp->len, 0, &from);\n            if (sent < 0 || sent != echo_rsp->len) {\n                ogs_log_message(OGS_LOG_ERROR, ogs_socket_errno,\n                        \"ogs_sendto() failed\");\n            }\n            ogs_pkbuf_free(echo_rsp);\n        }\n        goto cleanup;\n    }\n\n    teid = be32toh(gtp_h->teid);\n\n    ogs_debug(\"[RECV] GPU-U Type [%d] from [%s] : TEID[0x%x]\",\n            gtp_h->type, OGS_ADDR(&from, buf), teid);\n\n    qfi = 0;\n    if (gtp_h->flags & OGS_GTPU_FLAGS_E) {\n        /*\n         * TS29.281\n         * 5.2.1 General format of the GTP-U Extension Header\n         * Figure 5.2.1-3: Definition of Extension Header Type\n         *\n         * Note 4 : For a GTP-PDU with several Extension Headers, the PDU\n         *          Session Container should be the first Extension Header\n         */\n        ogs_gtp_extension_header_t *extension_header =\n            (ogs_gtp_extension_header_t *)(pkbuf->data + OGS_GTPV1U_HEADER_LEN);\n        ogs_assert(extension_header);\n        if (extension_header->type ==\n                OGS_GTP_EXTENSION_HEADER_TYPE_PDU_SESSION_CONTAINER) {\n            if (extension_header->pdu_type ==\n                OGS_GTP_EXTENSION_HEADER_PDU_TYPE_UL_PDU_SESSION_INFORMATION) {\n                    ogs_debug(\"   QFI [0x%x]\",\n                            extension_header->qos_flow_identifier);\n                    qfi = extension_header->qos_flow_identifier;\n            }\n        }\n    }\n\n    /* Remove GTP header and send packets to peer NF */\n    len = ogs_gtpu_header_len(pkbuf);\n    if (len < 0) {\n        ogs_error(\"[DROP] Cannot decode GTPU packet\");\n        ogs_log_hexdump(OGS_LOG_ERROR, pkbuf->data, pkbuf->len);\n        goto cleanup;\n    }\n    ogs_assert(ogs_pkbuf_pull(pkbuf, len));\n\n    if (gtp_h->type == OGS_GTPU_MSGTYPE_END_MARKER) {\n        /* Nothing */\n\n    } else if (gtp_h->type == OGS_GTPU_MSGTYPE_ERR_IND) {\n        ogs_pfcp_far_t *far = NULL;\n\n        far = ogs_pfcp_far_find_by_error_indication(pkbuf);\n        if (far) {\n            ogs_assert(true ==\n                ogs_pfcp_up_handle_error_indication(far, &report));\n\n            if (report.type.error_indication_report) {\n                ogs_assert(far->sess);\n                sess = SGWU_SESS(far->sess);\n                ogs_assert(sess);\n\n                ogs_assert(OGS_OK ==\n                    sgwu_pfcp_send_session_report_request(sess, &report));\n            }\n\n        } else {\n            ogs_error(\"[DROP] Cannot find FAR by Error-Indication\");\n            ogs_log_hexdump(OGS_LOG_ERROR, pkbuf->data, pkbuf->len);\n        }\n    } else if (gtp_h->type == OGS_GTPU_MSGTYPE_GPDU) {\n        struct ip *ip_h = NULL;\n        ogs_pfcp_object_t *pfcp_object = NULL;\n        ogs_pfcp_sess_t *pfcp_sess = NULL;\n        ogs_pfcp_pdr_t *pdr = NULL;\n\n        ip_h = (struct ip *)pkbuf->data;\n        ogs_assert(ip_h);\n\n        pfcp_object = ogs_pfcp_object_find_by_teid(teid);\n        if (!pfcp_object) {\n            /* TODO : Send Error Indication */\n            goto cleanup;\n        }\n\n        switch(pfcp_object->type) {\n        case OGS_PFCP_OBJ_PDR_TYPE:\n            pdr = (ogs_pfcp_pdr_t *)pfcp_object;\n            ogs_assert(pdr);\n            break;\n        case OGS_PFCP_OBJ_SESS_TYPE:\n            pfcp_sess = (ogs_pfcp_sess_t *)pfcp_object;\n            ogs_assert(pfcp_sess);\n\n            ogs_list_for_each(&pfcp_sess->pdr_list, pdr) {\n                /* Check if Source Interface */\n                if (pdr->src_if != OGS_PFCP_INTERFACE_ACCESS &&\n                    pdr->src_if != OGS_PFCP_INTERFACE_CP_FUNCTION)\n                    continue;\n\n                /* Check if TEID */\n                if (teid != pdr->f_teid.teid)\n                    continue;\n\n                /* Check if QFI */\n                if (qfi && pdr->qfi != qfi)\n                    continue;\n\n                /* Check if Rule List in PDR */\n                if (ogs_list_first(&pdr->rule_list) &&\n                    ogs_pfcp_pdr_rule_find_by_packet(pdr, pkbuf) == NULL)\n                    continue;\n\n                break;\n            }\n\n            if (!pdr) {\n                /* TODO : Send Error Indication */\n                goto cleanup;\n            }\n\n            break;\n        default:\n            ogs_fatal(\"Unknown type [%d]\", pfcp_object->type);\n            ogs_assert_if_reached();\n        }\n\n        ogs_assert(pdr);\n        ogs_assert(true == ogs_pfcp_up_handle_pdr(pdr, pkbuf, &report));\n\n        if (report.type.downlink_data_report) {\n            ogs_assert(pdr->sess);\n            ogs_assert(pdr->sess->obj.type == OGS_PFCP_OBJ_SESS_TYPE);\n            sess = SGWU_SESS(pdr->sess);\n            ogs_assert(sess);\n\n            report.downlink_data.pdr_id = pdr->id;\n            report.downlink_data.qfi = qfi; /* for 5GC */\n\n            ogs_assert(OGS_OK ==\n                sgwu_pfcp_send_session_report_request(sess, &report));\n        }\n    } else {\n        ogs_error(\"[DROP] Invalid GTPU Type [%d]\", gtp_h->type);\n        ogs_log_hexdump(OGS_LOG_ERROR, pkbuf->data, pkbuf->len);\n    }\n\ncleanup:\n    ogs_pkbuf_free(pkbuf);\n}",
        "func": "static void _gtpv1_u_recv_cb(short when, ogs_socket_t fd, void *data)\n{\n    int len;\n    ssize_t size;\n    char buf[OGS_ADDRSTRLEN];\n\n    sgwu_sess_t *sess = NULL;\n\n    ogs_pkbuf_t *pkbuf = NULL;\n    ogs_sockaddr_t from;\n\n    ogs_gtp_header_t *gtp_h = NULL;\n    ogs_pfcp_user_plane_report_t report;\n\n    uint32_t teid;\n    uint8_t qfi;\n\n    ogs_assert(fd != INVALID_SOCKET);\n\n    pkbuf = ogs_pkbuf_alloc(packet_pool, OGS_MAX_PKT_LEN);\n    ogs_assert(pkbuf);\n    ogs_pkbuf_put(pkbuf, OGS_MAX_PKT_LEN);\n\n    size = ogs_recvfrom(fd, pkbuf->data, pkbuf->len, 0, &from);\n    if (size <= 0) {\n        ogs_log_message(OGS_LOG_ERROR, ogs_socket_errno,\n                \"ogs_recv() failed\");\n        goto cleanup;\n    }\n\n    ogs_pkbuf_trim(pkbuf, size);\n\n    ogs_assert(pkbuf);\n    ogs_assert(pkbuf->len);\n\n    gtp_h = (ogs_gtp_header_t *)pkbuf->data;\n    if (gtp_h->version != OGS_GTP_VERSION_1) {\n        ogs_error(\"[DROP] Invalid GTPU version [%d]\", gtp_h->version);\n        ogs_log_hexdump(OGS_LOG_ERROR, pkbuf->data, pkbuf->len);\n        goto cleanup;\n    }\n\n    if (gtp_h->type == OGS_GTPU_MSGTYPE_ECHO_REQ) {\n        ogs_pkbuf_t *echo_rsp;\n\n        ogs_debug(\"[RECV] Echo Request from [%s]\", OGS_ADDR(&from, buf));\n        echo_rsp = ogs_gtp_handle_echo_req(pkbuf);\n        ogs_expect(echo_rsp);\n        if (echo_rsp) {\n            ssize_t sent;\n\n            /* Echo reply */\n            ogs_debug(\"[SEND] Echo Response to [%s]\", OGS_ADDR(&from, buf));\n\n            sent = ogs_sendto(fd, echo_rsp->data, echo_rsp->len, 0, &from);\n            if (sent < 0 || sent != echo_rsp->len) {\n                ogs_log_message(OGS_LOG_ERROR, ogs_socket_errno,\n                        \"ogs_sendto() failed\");\n            }\n            ogs_pkbuf_free(echo_rsp);\n        }\n        goto cleanup;\n    }\n\n    teid = be32toh(gtp_h->teid);\n\n    ogs_debug(\"[RECV] GPU-U Type [%d] from [%s] : TEID[0x%x]\",\n            gtp_h->type, OGS_ADDR(&from, buf), teid);\n\n    qfi = 0;\n    if (gtp_h->flags & OGS_GTPU_FLAGS_E) {\n        /*\n         * TS29.281\n         * 5.2.1 General format of the GTP-U Extension Header\n         * Figure 5.2.1-3: Definition of Extension Header Type\n         *\n         * Note 4 : For a GTP-PDU with several Extension Headers, the PDU\n         *          Session Container should be the first Extension Header\n         */\n        ogs_gtp_extension_header_t *extension_header =\n            (ogs_gtp_extension_header_t *)(pkbuf->data + OGS_GTPV1U_HEADER_LEN);\n        ogs_assert(extension_header);\n        if (extension_header->type ==\n                OGS_GTP_EXTENSION_HEADER_TYPE_PDU_SESSION_CONTAINER) {\n            if (extension_header->pdu_type ==\n                OGS_GTP_EXTENSION_HEADER_PDU_TYPE_UL_PDU_SESSION_INFORMATION) {\n                    ogs_debug(\"   QFI [0x%x]\",\n                            extension_header->qos_flow_identifier);\n                    qfi = extension_header->qos_flow_identifier;\n            }\n        }\n    }\n\n    /* Remove GTP header and send packets to peer NF */\n    len = ogs_gtpu_header_len(pkbuf);\n    if (len < 0) {\n        ogs_error(\"[DROP] Cannot decode GTPU packet\");\n        ogs_log_hexdump(OGS_LOG_ERROR, pkbuf->data, pkbuf->len);\n        goto cleanup;\n    }\n    if (gtp_h->type != OGS_GTPU_MSGTYPE_END_MARKER &&\n        pkbuf->len <= len) {\n        ogs_error(\"[DROP] Small GTPU packet(type:%d len:%d)\", gtp_h->type, len);\n        ogs_log_hexdump(OGS_LOG_ERROR, pkbuf->data, pkbuf->len);\n        goto cleanup;\n    }\n    ogs_assert(ogs_pkbuf_pull(pkbuf, len));\n\n    if (gtp_h->type == OGS_GTPU_MSGTYPE_END_MARKER) {\n        /* Nothing */\n\n    } else if (gtp_h->type == OGS_GTPU_MSGTYPE_ERR_IND) {\n        ogs_pfcp_far_t *far = NULL;\n\n        far = ogs_pfcp_far_find_by_error_indication(pkbuf);\n        if (far) {\n            ogs_assert(true ==\n                ogs_pfcp_up_handle_error_indication(far, &report));\n\n            if (report.type.error_indication_report) {\n                ogs_assert(far->sess);\n                sess = SGWU_SESS(far->sess);\n                ogs_assert(sess);\n\n                ogs_assert(OGS_OK ==\n                    sgwu_pfcp_send_session_report_request(sess, &report));\n            }\n\n        } else {\n            ogs_error(\"[DROP] Cannot find FAR by Error-Indication\");\n            ogs_log_hexdump(OGS_LOG_ERROR, pkbuf->data, pkbuf->len);\n        }\n    } else if (gtp_h->type == OGS_GTPU_MSGTYPE_GPDU) {\n        struct ip *ip_h = NULL;\n        ogs_pfcp_object_t *pfcp_object = NULL;\n        ogs_pfcp_sess_t *pfcp_sess = NULL;\n        ogs_pfcp_pdr_t *pdr = NULL;\n\n        ip_h = (struct ip *)pkbuf->data;\n        ogs_assert(ip_h);\n\n        pfcp_object = ogs_pfcp_object_find_by_teid(teid);\n        if (!pfcp_object) {\n            /* TODO : Send Error Indication */\n            goto cleanup;\n        }\n\n        switch(pfcp_object->type) {\n        case OGS_PFCP_OBJ_PDR_TYPE:\n            pdr = (ogs_pfcp_pdr_t *)pfcp_object;\n            ogs_assert(pdr);\n            break;\n        case OGS_PFCP_OBJ_SESS_TYPE:\n            pfcp_sess = (ogs_pfcp_sess_t *)pfcp_object;\n            ogs_assert(pfcp_sess);\n\n            ogs_list_for_each(&pfcp_sess->pdr_list, pdr) {\n                /* Check if Source Interface */\n                if (pdr->src_if != OGS_PFCP_INTERFACE_ACCESS &&\n                    pdr->src_if != OGS_PFCP_INTERFACE_CP_FUNCTION)\n                    continue;\n\n                /* Check if TEID */\n                if (teid != pdr->f_teid.teid)\n                    continue;\n\n                /* Check if QFI */\n                if (qfi && pdr->qfi != qfi)\n                    continue;\n\n                /* Check if Rule List in PDR */\n                if (ogs_list_first(&pdr->rule_list) &&\n                    ogs_pfcp_pdr_rule_find_by_packet(pdr, pkbuf) == NULL)\n                    continue;\n\n                break;\n            }\n\n            if (!pdr) {\n                /* TODO : Send Error Indication */\n                goto cleanup;\n            }\n\n            break;\n        default:\n            ogs_fatal(\"Unknown type [%d]\", pfcp_object->type);\n            ogs_assert_if_reached();\n        }\n\n        ogs_assert(pdr);\n        ogs_assert(true == ogs_pfcp_up_handle_pdr(pdr, pkbuf, &report));\n\n        if (report.type.downlink_data_report) {\n            ogs_assert(pdr->sess);\n            ogs_assert(pdr->sess->obj.type == OGS_PFCP_OBJ_SESS_TYPE);\n            sess = SGWU_SESS(pdr->sess);\n            ogs_assert(sess);\n\n            report.downlink_data.pdr_id = pdr->id;\n            report.downlink_data.qfi = qfi; /* for 5GC */\n\n            ogs_assert(OGS_OK ==\n                sgwu_pfcp_send_session_report_request(sess, &report));\n        }\n    } else {\n        ogs_error(\"[DROP] Invalid GTPU Type [%d]\", gtp_h->type);\n        ogs_log_hexdump(OGS_LOG_ERROR, pkbuf->data, pkbuf->len);\n    }\n\ncleanup:\n    ogs_pkbuf_free(pkbuf);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -98,6 +98,12 @@\n         ogs_log_hexdump(OGS_LOG_ERROR, pkbuf->data, pkbuf->len);\n         goto cleanup;\n     }\n+    if (gtp_h->type != OGS_GTPU_MSGTYPE_END_MARKER &&\n+        pkbuf->len <= len) {\n+        ogs_error(\"[DROP] Small GTPU packet(type:%d len:%d)\", gtp_h->type, len);\n+        ogs_log_hexdump(OGS_LOG_ERROR, pkbuf->data, pkbuf->len);\n+        goto cleanup;\n+    }\n     ogs_assert(ogs_pkbuf_pull(pkbuf, len));\n \n     if (gtp_h->type == OGS_GTPU_MSGTYPE_END_MARKER) {",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    if (gtp_h->type != OGS_GTPU_MSGTYPE_END_MARKER &&",
                "        pkbuf->len <= len) {",
                "        ogs_error(\"[DROP] Small GTPU packet(type:%d len:%d)\", gtp_h->type, len);",
                "        ogs_log_hexdump(OGS_LOG_ERROR, pkbuf->data, pkbuf->len);",
                "        goto cleanup;",
                "    }"
            ]
        }
    }
]