[
    {
        "cve_id": "CVE-2021-40524",
        "func_name": "jedisct1/pure-ftpd/dostor",
        "description": "In Pure-FTPd before 1.0.50, an incorrect max_filesize quota mechanism in the server allows attackers to upload files of unbounded size, which may lead to denial of service or a server hang. This occurs because a certain greater-than-zero test does not anticipate an initial -1 value. (Versions 1.0.23 through 1.0.49 are affected.)",
        "git_url": "https://github.com/jedisct1/pure-ftpd/commit/37ad222868e52271905b94afea4fc780d83294b4",
        "commit_title": "Initialize the max upload file size when quotas are enabled",
        "commit_text": " Due to an unwanted check, files causing the quota to be exceeded were deleted after the upload, but not during the upload.  The bug was introduced in 2009 in version 1.0.23  Spotted by @DroidTest, thanks!",
        "func_before": "void dostor(char *name, const int append, const int autorename)\n{\n    ULHandler ulhandler;\n    int f;\n    const char *ul_name = NULL;\n    const char *atomic_file = NULL;\n    off_t filesize = (off_t) 0U;\n    struct stat st;\n    double started = 0.0;\n    signed char overwrite = 0;\n    int overflow = 0;\n    int ret = -1;\n    off_t max_filesize = (off_t) -1;\n#ifdef QUOTAS\n    Quota quota;\n#endif\n    const char *name2 = NULL;\n\n    if (type < 1 || (type == 1 && restartat > (off_t) 1)) {\n        addreply_noformat(503, MSG_NO_ASCII_RESUME);\n        goto end;\n    }\n#ifndef ANON_CAN_RESUME\n    if (guest != 0 && anon_noupload != 0) {\n        addreply_noformat(550, MSG_ANON_CANT_OVERWRITE);\n        goto end;\n    }\n#endif\n    if (ul_check_free_space(name, -1.0) == 0) {\n        addreply_noformat(552, MSG_NO_DISK_SPACE);\n        goto end;\n    }\n    if (checknamesanity(name, dot_write_ok) != 0) {\n        addreply(553, MSG_SANITY_FILE_FAILURE, name);\n        goto end;\n    }\n    if (autorename != 0) {\n        no_truncate = 1;\n    }\n    if (restartat > (off_t) 0 || no_truncate != 0) {\n        if ((atomic_file = get_atomic_file(name)) == NULL) {\n            addreply(553, MSG_SANITY_FILE_FAILURE, name);\n            goto end;\n        }\n        if (restartat > (off_t) 0 &&\n            rename(name, atomic_file) != 0 && errno != ENOENT) {\n            error(553, MSG_RENAME_FAILURE);\n            atomic_file = NULL;\n            goto end;\n        }\n    }\n    if (atomic_file != NULL) {\n        ul_name = atomic_file;\n    } else {\n        ul_name = name;\n    }\n    if (atomic_file == NULL &&\n        (f = open(ul_name, O_WRONLY | O_NOFOLLOW)) != -1) {\n        overwrite++;\n    } else if ((f = open(ul_name, O_CREAT | O_WRONLY | O_NOFOLLOW,\n                         (mode_t) 0777 & ~u_mask)) == -1) {\n        error(553, MSG_OPEN_FAILURE2);\n        goto end;\n    }\n    if (fstat(f, &st) < 0) {\n        (void) close(f);\n        error(553, MSG_STAT_FAILURE2);\n        goto end;\n    }\n    if (!S_ISREG(st.st_mode)) {\n        (void) close(f);\n        addreply_noformat(550, MSG_NOT_REGULAR_FILE);\n        goto end;\n    }\n    alarm(MAX_SESSION_XFER_IDLE);\n\n    /* Anonymous users *CAN* overwrite 0-bytes files - This is the right behavior */\n    if (st.st_size > (off_t) 0) {\n#ifndef ANON_CAN_RESUME\n        if (guest != 0) {\n            addreply_noformat(550, MSG_ANON_CANT_OVERWRITE);\n            (void) close(f);\n            goto end;\n        }\n#endif\n        if (append != 0) {\n            restartat = st.st_size;\n        }\n    } else {\n        restartat = (off_t) 0;\n    }\n    if (restartat > st.st_size) {\n        restartat = st.st_size;\n    }\n    if (restartat > (off_t) 0 && lseek(f, restartat, SEEK_SET) < (off_t) 0) {\n        (void) close(f);\n        error(451, \"seek\");\n        goto end;\n    }\n    if (restartat < st.st_size) {\n        if (ftruncate(f, restartat) < 0) {\n            (void) close(f);\n            error(451, \"ftruncate\");\n            goto end;\n        }\n#ifdef QUOTAS\n        if (restartat != st.st_size) {\n            (void) quota_update(NULL, 0LL,\n                                (long long) (restartat - st.st_size),\n                                &overflow);\n        }\n#endif\n    }\n#ifdef QUOTAS\n    if (quota_update(&quota, 0LL, 0LL, &overflow) == 0 &&\n        (overflow > 0 || quota.files >= user_quota_files ||\n         quota.size > user_quota_size ||\n         (max_filesize >= (off_t) 0 &&\n          (max_filesize = user_quota_size - quota.size) < (off_t) 0))) {\n        overflow = 1;\n        (void) close(f);\n        goto afterquota;\n    }\n#endif\n    opendata();\n    if (xferfd == -1) {\n        (void) close(f);\n        goto end;\n    }\n    doreply();\n# ifdef WITH_TLS\n    if (data_protection_level == CPL_PRIVATE) {\n        tls_init_data_session(xferfd, passive);\n    }\n# endif\n    state_needs_update = 1;\n    setprocessname(\"pure-ftpd (UPLOAD)\");\n    filesize = restartat;\n\n#ifdef FTPWHO\n    if (shm_data_cur != NULL) {\n        const size_t sl = strlen(name);\n\n        ftpwho_lock();\n        shm_data_cur->state = FTPWHO_STATE_UPLOAD;\n        shm_data_cur->download_total_size = (off_t) 0U;\n        shm_data_cur->download_current_size = (off_t) filesize;\n        shm_data_cur->restartat = restartat;\n        (void) time(&shm_data_cur->xfer_date);\n        if (sl < sizeof shm_data_cur->filename) {\n            memcpy(shm_data_cur->filename, name, sl);\n            shm_data_cur->filename[sl] = 0;\n        } else {\n            memcpy(shm_data_cur->filename,\n                   &name[sl - sizeof shm_data_cur->filename - 1U],\n                   sizeof shm_data_cur->filename);\n        }\n        ftpwho_unlock();\n    }\n#endif\n\n    /* Here starts the real upload code */\n\n    started = get_usec_time();\n\n    if (ul_init(&ulhandler, clientfd, tls_cnx, xferfd, name, f, tls_data_cnx,\n                restartat, type == 1, throttling_bandwidth_ul,\n                max_filesize) == 0) {\n        ret = ul_send(&ulhandler);\n        ul_exit(&ulhandler);\n    } else {\n        ret = -1;\n    }\n    (void) close(f);\n    closedata();\n\n    /* Here ends the real upload code */\n\n#ifdef SHOW_REAL_DISK_SPACE\n    if (FSTATFS(f, &statfsbuf) == 0) {\n        double space;\n\n        space = (double) STATFS_BAVAIL(statfsbuf) *\n            (double) STATFS_FRSIZE(statfsbuf);\n        if (space > 524288.0) {\n            addreply(0, MSG_SPACE_FREE_M, space / 1048576.0);\n        } else {\n            addreply(0, MSG_SPACE_FREE_K, space / 1024.0);\n        }\n    }\n#endif\n\n    uploaded += (unsigned long long) ulhandler.total_uploaded;\n    {\n        off_t atomic_file_size;\n        off_t original_file_size;\n        int files_count;\n\n        if (overwrite == 0) {\n            files_count = 1;\n        } else {\n            files_count = 0;\n        }\n        if (autorename != 0 && restartat == (off_t) 0) {\n            if ((atomic_file_size = get_file_size(atomic_file)) < (off_t) 0) {\n                goto afterquota;\n            }\n            if (tryautorename(atomic_file, name, &name2) != 0) {\n                error(553, MSG_RENAME_FAILURE);\n                goto afterquota;\n            } else {\n#ifdef QUOTAS\n                ul_quota_update(name2 ? name2 : name, 1, atomic_file_size);\n#endif\n                atomic_file = NULL;\n            }\n        } else if (atomic_file != NULL) {\n            if ((atomic_file_size = get_file_size(atomic_file)) < (off_t) 0) {\n                goto afterquota;\n            }\n            if ((original_file_size = get_file_size(name)) < (off_t) 0 ||\n                restartat > original_file_size) {\n                original_file_size = restartat;\n            }\n            if (rename(atomic_file, name) != 0) {\n                error(553, MSG_RENAME_FAILURE);\n                goto afterquota;\n            } else {\n#ifdef QUOTAS\n                overflow = ul_quota_update\n                    (name, files_count, atomic_file_size - original_file_size);\n#endif\n                atomic_file = NULL;\n            }\n        } else {\n#ifdef QUOTAS\n            overflow = ul_quota_update\n                (name, files_count, ulhandler.total_uploaded);\n#endif\n        }\n    }\n    afterquota:\n    if (overflow > 0) {\n        addreply(552, MSG_QUOTA_EXCEEDED, name);\n    } else {\n        if (ret == 0) {\n            addreply_noformat(226, MSG_TRANSFER_SUCCESSFUL);\n        } else {\n            addreply_noformat(451, MSG_ABORTED);\n        }\n        displayrate(MSG_UPLOADED, ulhandler.total_uploaded, started,\n                    name2 ? name2 : name, 1);\n    }\n    end:\n    restartat = (off_t) 0;\n    if (atomic_file != NULL) {\n        unlink(atomic_file);\n        atomic_file = NULL;\n    }\n}",
        "func": "void dostor(char *name, const int append, const int autorename)\n{\n    ULHandler ulhandler;\n    int f;\n    const char *ul_name = NULL;\n    const char *atomic_file = NULL;\n    off_t filesize = (off_t) 0U;\n    struct stat st;\n    double started = 0.0;\n    signed char overwrite = 0;\n    int overflow = 0;\n    int ret = -1;\n    off_t max_filesize = (off_t) -1;\n#ifdef QUOTAS\n    Quota quota;\n#endif\n    const char *name2 = NULL;\n\n    if (type < 1 || (type == 1 && restartat > (off_t) 1)) {\n        addreply_noformat(503, MSG_NO_ASCII_RESUME);\n        goto end;\n    }\n#ifndef ANON_CAN_RESUME\n    if (guest != 0 && anon_noupload != 0) {\n        addreply_noformat(550, MSG_ANON_CANT_OVERWRITE);\n        goto end;\n    }\n#endif\n    if (ul_check_free_space(name, -1.0) == 0) {\n        addreply_noformat(552, MSG_NO_DISK_SPACE);\n        goto end;\n    }\n    if (checknamesanity(name, dot_write_ok) != 0) {\n        addreply(553, MSG_SANITY_FILE_FAILURE, name);\n        goto end;\n    }\n    if (autorename != 0) {\n        no_truncate = 1;\n    }\n    if (restartat > (off_t) 0 || no_truncate != 0) {\n        if ((atomic_file = get_atomic_file(name)) == NULL) {\n            addreply(553, MSG_SANITY_FILE_FAILURE, name);\n            goto end;\n        }\n        if (restartat > (off_t) 0 &&\n            rename(name, atomic_file) != 0 && errno != ENOENT) {\n            error(553, MSG_RENAME_FAILURE);\n            atomic_file = NULL;\n            goto end;\n        }\n    }\n    if (atomic_file != NULL) {\n        ul_name = atomic_file;\n    } else {\n        ul_name = name;\n    }\n    if (atomic_file == NULL &&\n        (f = open(ul_name, O_WRONLY | O_NOFOLLOW)) != -1) {\n        overwrite++;\n    } else if ((f = open(ul_name, O_CREAT | O_WRONLY | O_NOFOLLOW,\n                         (mode_t) 0777 & ~u_mask)) == -1) {\n        error(553, MSG_OPEN_FAILURE2);\n        goto end;\n    }\n    if (fstat(f, &st) < 0) {\n        (void) close(f);\n        error(553, MSG_STAT_FAILURE2);\n        goto end;\n    }\n    if (!S_ISREG(st.st_mode)) {\n        (void) close(f);\n        addreply_noformat(550, MSG_NOT_REGULAR_FILE);\n        goto end;\n    }\n    alarm(MAX_SESSION_XFER_IDLE);\n\n    /* Anonymous users *CAN* overwrite 0-bytes files - This is the right behavior */\n    if (st.st_size > (off_t) 0) {\n#ifndef ANON_CAN_RESUME\n        if (guest != 0) {\n            addreply_noformat(550, MSG_ANON_CANT_OVERWRITE);\n            (void) close(f);\n            goto end;\n        }\n#endif\n        if (append != 0) {\n            restartat = st.st_size;\n        }\n    } else {\n        restartat = (off_t) 0;\n    }\n    if (restartat > st.st_size) {\n        restartat = st.st_size;\n    }\n    if (restartat > (off_t) 0 && lseek(f, restartat, SEEK_SET) < (off_t) 0) {\n        (void) close(f);\n        error(451, \"seek\");\n        goto end;\n    }\n    if (restartat < st.st_size) {\n        if (ftruncate(f, restartat) < 0) {\n            (void) close(f);\n            error(451, \"ftruncate\");\n            goto end;\n        }\n#ifdef QUOTAS\n        if (restartat != st.st_size) {\n            (void) quota_update(NULL, 0LL,\n                                (long long) (restartat - st.st_size),\n                                &overflow);\n        }\n#endif\n    }\n#ifdef QUOTAS\n    if (quota_update(&quota, 0LL, 0LL, &overflow) == 0 &&\n        (overflow > 0 || quota.files >= user_quota_files ||\n         quota.size > user_quota_size ||\n         (max_filesize = user_quota_size - quota.size) < (off_t) 0)) {\n        overflow = 1;\n        (void) close(f);\n        goto afterquota;\n    }\n#endif\n    opendata();\n    if (xferfd == -1) {\n        (void) close(f);\n        goto end;\n    }\n    doreply();\n# ifdef WITH_TLS\n    if (data_protection_level == CPL_PRIVATE) {\n        tls_init_data_session(xferfd, passive);\n    }\n# endif\n    state_needs_update = 1;\n    setprocessname(\"pure-ftpd (UPLOAD)\");\n    filesize = restartat;\n\n#ifdef FTPWHO\n    if (shm_data_cur != NULL) {\n        const size_t sl = strlen(name);\n\n        ftpwho_lock();\n        shm_data_cur->state = FTPWHO_STATE_UPLOAD;\n        shm_data_cur->download_total_size = (off_t) 0U;\n        shm_data_cur->download_current_size = (off_t) filesize;\n        shm_data_cur->restartat = restartat;\n        (void) time(&shm_data_cur->xfer_date);\n        if (sl < sizeof shm_data_cur->filename) {\n            memcpy(shm_data_cur->filename, name, sl);\n            shm_data_cur->filename[sl] = 0;\n        } else {\n            memcpy(shm_data_cur->filename,\n                   &name[sl - sizeof shm_data_cur->filename - 1U],\n                   sizeof shm_data_cur->filename);\n        }\n        ftpwho_unlock();\n    }\n#endif\n\n    /* Here starts the real upload code */\n\n    started = get_usec_time();\n\n    if (ul_init(&ulhandler, clientfd, tls_cnx, xferfd, name, f, tls_data_cnx,\n                restartat, type == 1, throttling_bandwidth_ul,\n                max_filesize) == 0) {\n        ret = ul_send(&ulhandler);\n        ul_exit(&ulhandler);\n    } else {\n        ret = -1;\n    }\n    (void) close(f);\n    closedata();\n\n    /* Here ends the real upload code */\n\n#ifdef SHOW_REAL_DISK_SPACE\n    if (FSTATFS(f, &statfsbuf) == 0) {\n        double space;\n\n        space = (double) STATFS_BAVAIL(statfsbuf) *\n            (double) STATFS_FRSIZE(statfsbuf);\n        if (space > 524288.0) {\n            addreply(0, MSG_SPACE_FREE_M, space / 1048576.0);\n        } else {\n            addreply(0, MSG_SPACE_FREE_K, space / 1024.0);\n        }\n    }\n#endif\n\n    uploaded += (unsigned long long) ulhandler.total_uploaded;\n    {\n        off_t atomic_file_size;\n        off_t original_file_size;\n        int files_count;\n\n        if (overwrite == 0) {\n            files_count = 1;\n        } else {\n            files_count = 0;\n        }\n        if (autorename != 0 && restartat == (off_t) 0) {\n            if ((atomic_file_size = get_file_size(atomic_file)) < (off_t) 0) {\n                goto afterquota;\n            }\n            if (tryautorename(atomic_file, name, &name2) != 0) {\n                error(553, MSG_RENAME_FAILURE);\n                goto afterquota;\n            } else {\n#ifdef QUOTAS\n                ul_quota_update(name2 ? name2 : name, 1, atomic_file_size);\n#endif\n                atomic_file = NULL;\n            }\n        } else if (atomic_file != NULL) {\n            if ((atomic_file_size = get_file_size(atomic_file)) < (off_t) 0) {\n                goto afterquota;\n            }\n            if ((original_file_size = get_file_size(name)) < (off_t) 0 ||\n                restartat > original_file_size) {\n                original_file_size = restartat;\n            }\n            if (rename(atomic_file, name) != 0) {\n                error(553, MSG_RENAME_FAILURE);\n                goto afterquota;\n            } else {\n#ifdef QUOTAS\n                overflow = ul_quota_update\n                    (name, files_count, atomic_file_size - original_file_size);\n#endif\n                atomic_file = NULL;\n            }\n        } else {\n#ifdef QUOTAS\n            overflow = ul_quota_update\n                (name, files_count, ulhandler.total_uploaded);\n#endif\n        }\n    }\n    afterquota:\n    if (overflow > 0) {\n        addreply(552, MSG_QUOTA_EXCEEDED, name);\n    } else {\n        if (ret == 0) {\n            addreply_noformat(226, MSG_TRANSFER_SUCCESSFUL);\n        } else {\n            addreply_noformat(451, MSG_ABORTED);\n        }\n        displayrate(MSG_UPLOADED, ulhandler.total_uploaded, started,\n                    name2 ? name2 : name, 1);\n    }\n    end:\n    restartat = (off_t) 0;\n    if (atomic_file != NULL) {\n        unlink(atomic_file);\n        atomic_file = NULL;\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -115,8 +115,7 @@\n     if (quota_update(&quota, 0LL, 0LL, &overflow) == 0 &&\n         (overflow > 0 || quota.files >= user_quota_files ||\n          quota.size > user_quota_size ||\n-         (max_filesize >= (off_t) 0 &&\n-          (max_filesize = user_quota_size - quota.size) < (off_t) 0))) {\n+         (max_filesize = user_quota_size - quota.size) < (off_t) 0)) {\n         overflow = 1;\n         (void) close(f);\n         goto afterquota;",
        "diff_line_info": {
            "deleted_lines": [
                "         (max_filesize >= (off_t) 0 &&",
                "          (max_filesize = user_quota_size - quota.size) < (off_t) 0))) {"
            ],
            "added_lines": [
                "         (max_filesize = user_quota_size - quota.size) < (off_t) 0)) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-28927",
        "func_name": "tindy2013/subconverter/groupGenerate",
        "description": "A remote code execution (RCE) vulnerability in Subconverter v0.7.2 allows attackers to execute arbitrary code via crafted config and url parameters.",
        "git_url": "https://github.com/tindy2013/subconverter/commit/ce8d2bd0f13f05fcbd2ed90755d097f402393dd3",
        "commit_title": "Enhancements",
        "commit_text": " Add authorization check before loading scripts. Add detailed logs when loading preference settings.",
        "func_before": "void groupGenerate(const std::string &rule, std::vector<Proxy> &nodelist, string_array &filtered_nodelist, bool add_direct, extra_settings &ext)\n{\n    std::string real_rule;\n    if(startsWith(rule, \"[]\") && add_direct)\n    {\n        filtered_nodelist.emplace_back(rule.substr(2));\n    }\n#ifndef NO_JS_RUNTIME\n    else if(startsWith(rule, \"script:\"))\n    {\n        script_safe_runner(ext.js_runtime, ext.js_context, [&](qjs::Context &ctx){\n            std::string script = fileGet(rule.substr(7), true);\n            try\n            {\n                ctx.eval(script);\n                auto filter = (std::function<std::string(const std::vector<Proxy>&)>) ctx.eval(\"filter\");\n                std::string result_list = filter(nodelist);\n                filtered_nodelist = split(regTrim(result_list), \"\\n\");\n            }\n            catch (qjs::exception)\n            {\n                script_print_stack(ctx);\n            }\n        }, global.scriptCleanContext);\n    }\n#endif // NO_JS_RUNTIME\n    else\n    {\n        for(Proxy &x : nodelist)\n        {\n            if(applyMatcher(rule, real_rule, x) && (real_rule.empty() || regFind(x.Remark, real_rule)) && std::find(filtered_nodelist.begin(), filtered_nodelist.end(), x.Remark) == filtered_nodelist.end())\n                filtered_nodelist.emplace_back(x.Remark);\n        }\n    }\n}",
        "func": "void groupGenerate(const std::string &rule, std::vector<Proxy> &nodelist, string_array &filtered_nodelist, bool add_direct, extra_settings &ext)\n{\n    std::string real_rule;\n    if(startsWith(rule, \"[]\") && add_direct)\n    {\n        filtered_nodelist.emplace_back(rule.substr(2));\n    }\n#ifndef NO_JS_RUNTIME\n    else if(startsWith(rule, \"script:\") && ext.authorized)\n    {\n        script_safe_runner(ext.js_runtime, ext.js_context, [&](qjs::Context &ctx){\n            std::string script = fileGet(rule.substr(7), true);\n            try\n            {\n                ctx.eval(script);\n                auto filter = (std::function<std::string(const std::vector<Proxy>&)>) ctx.eval(\"filter\");\n                std::string result_list = filter(nodelist);\n                filtered_nodelist = split(regTrim(result_list), \"\\n\");\n            }\n            catch (qjs::exception)\n            {\n                script_print_stack(ctx);\n            }\n        }, global.scriptCleanContext);\n    }\n#endif // NO_JS_RUNTIME\n    else\n    {\n        for(Proxy &x : nodelist)\n        {\n            if(applyMatcher(rule, real_rule, x) && (real_rule.empty() || regFind(x.Remark, real_rule)) && std::find(filtered_nodelist.begin(), filtered_nodelist.end(), x.Remark) == filtered_nodelist.end())\n                filtered_nodelist.emplace_back(x.Remark);\n        }\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -6,7 +6,7 @@\n         filtered_nodelist.emplace_back(rule.substr(2));\n     }\n #ifndef NO_JS_RUNTIME\n-    else if(startsWith(rule, \"script:\"))\n+    else if(startsWith(rule, \"script:\") && ext.authorized)\n     {\n         script_safe_runner(ext.js_runtime, ext.js_context, [&](qjs::Context &ctx){\n             std::string script = fileGet(rule.substr(7), true);",
        "diff_line_info": {
            "deleted_lines": [
                "    else if(startsWith(rule, \"script:\"))"
            ],
            "added_lines": [
                "    else if(startsWith(rule, \"script:\") && ext.authorized)"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-28927",
        "func_name": "tindy2013/subconverter/preprocessNodes",
        "description": "A remote code execution (RCE) vulnerability in Subconverter v0.7.2 allows attackers to execute arbitrary code via crafted config and url parameters.",
        "git_url": "https://github.com/tindy2013/subconverter/commit/ce8d2bd0f13f05fcbd2ed90755d097f402393dd3",
        "commit_title": "Enhancements",
        "commit_text": " Add authorization check before loading scripts. Add detailed logs when loading preference settings.",
        "func_before": "void preprocessNodes(std::vector<Proxy> &nodes, extra_settings &ext)\n{\n    std::for_each(nodes.begin(), nodes.end(), [&ext](Proxy &x)\n    {\n        if(ext.remove_emoji)\n            x.Remark = trim(removeEmoji(x.Remark));\n\n        nodeRename(x, ext.rename_array, ext);\n\n        if(ext.add_emoji)\n            x.Remark = addEmoji(x, ext.emoji_array, ext);\n    });\n\n    if(ext.sort_flag)\n    {\n        bool failed = true;\n        if(ext.sort_script.size())\n        {\n            std::string script = ext.sort_script;\n            if(startsWith(script, \"path:\"))\n                script = fileGet(script.substr(5), false);\n            script_safe_runner(ext.js_runtime, ext.js_context, [&](qjs::Context &ctx)\n            {\n                try\n                {\n                    ctx.eval(script);\n                    auto compare = (std::function<int(const Proxy&, const Proxy&)>) ctx.eval(\"compare\");\n                    auto comparer = [&](const Proxy &a, const Proxy &b)\n                    {\n                        if(a.Type == ProxyType::Unknow)\n                            return 1;\n                        if(b.Type == ProxyType::Unknow)\n                            return 0;\n                        return compare(a, b);\n                    };\n                    std::stable_sort(nodes.begin(), nodes.end(), comparer);\n                    failed = false;\n                }\n                catch(qjs::exception)\n                {\n                    script_print_stack(ctx);\n                }\n            }, global.scriptCleanContext);\n        }\n        if(failed) std::stable_sort(nodes.begin(), nodes.end(), [](const Proxy &a, const Proxy &b)\n        {\n            return a.Remark < b.Remark;\n        });\n    }\n}",
        "func": "void preprocessNodes(std::vector<Proxy> &nodes, extra_settings &ext)\n{\n    std::for_each(nodes.begin(), nodes.end(), [&ext](Proxy &x)\n    {\n        if(ext.remove_emoji)\n            x.Remark = trim(removeEmoji(x.Remark));\n\n        nodeRename(x, ext.rename_array, ext);\n\n        if(ext.add_emoji)\n            x.Remark = addEmoji(x, ext.emoji_array, ext);\n    });\n\n    if(ext.sort_flag)\n    {\n        bool failed = true;\n        if(ext.sort_script.size() && ext.authorized)\n        {\n            std::string script = ext.sort_script;\n            if(startsWith(script, \"path:\"))\n                script = fileGet(script.substr(5), false);\n            script_safe_runner(ext.js_runtime, ext.js_context, [&](qjs::Context &ctx)\n            {\n                try\n                {\n                    ctx.eval(script);\n                    auto compare = (std::function<int(const Proxy&, const Proxy&)>) ctx.eval(\"compare\");\n                    auto comparer = [&](const Proxy &a, const Proxy &b)\n                    {\n                        if(a.Type == ProxyType::Unknow)\n                            return 1;\n                        if(b.Type == ProxyType::Unknow)\n                            return 0;\n                        return compare(a, b);\n                    };\n                    std::stable_sort(nodes.begin(), nodes.end(), comparer);\n                    failed = false;\n                }\n                catch(qjs::exception)\n                {\n                    script_print_stack(ctx);\n                }\n            }, global.scriptCleanContext);\n        }\n        if(failed) std::stable_sort(nodes.begin(), nodes.end(), [](const Proxy &a, const Proxy &b)\n        {\n            return a.Remark < b.Remark;\n        });\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -14,7 +14,7 @@\n     if(ext.sort_flag)\n     {\n         bool failed = true;\n-        if(ext.sort_script.size())\n+        if(ext.sort_script.size() && ext.authorized)\n         {\n             std::string script = ext.sort_script;\n             if(startsWith(script, \"path:\"))",
        "diff_line_info": {
            "deleted_lines": [
                "        if(ext.sort_script.size())"
            ],
            "added_lines": [
                "        if(ext.sort_script.size() && ext.authorized)"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-28927",
        "func_name": "tindy2013/subconverter/addNodes",
        "description": "A remote code execution (RCE) vulnerability in Subconverter v0.7.2 allows attackers to execute arbitrary code via crafted config and url parameters.",
        "git_url": "https://github.com/tindy2013/subconverter/commit/ce8d2bd0f13f05fcbd2ed90755d097f402393dd3",
        "commit_title": "Enhancements",
        "commit_text": " Add authorization check before loading scripts. Add detailed logs when loading preference settings.",
        "func_before": "int addNodes(std::string link, std::vector<Proxy> &allNodes, int groupID, parse_settings &parse_set)\n{\n    std::string &proxy = *parse_set.proxy, &subInfo = *parse_set.sub_info;\n    string_array &exclude_remarks = *parse_set.exclude_remarks;\n    string_array &include_remarks = *parse_set.include_remarks;\n    RegexMatchConfigs &stream_rules = *parse_set.stream_rules;\n    RegexMatchConfigs &time_rules = *parse_set.time_rules;\n    string_icase_map *request_headers = parse_set.request_header;\n    bool &authorized = parse_set.authorized;\n\n    ConfType linkType = ConfType::Unknow;\n    std::vector<Proxy> nodes;\n    Proxy node;\n    std::string strSub, extra_headers, custom_group;\n\n    // TODO: replace with startsWith if appropriate\n    link = replaceAllDistinct(link, \"\\\"\", \"\");\n\n    /// script:filepath,arg1,arg2,...\n    script_safe_runner(parse_set.js_runtime, parse_set.js_context, [&](qjs::Context &ctx)\n    {\n        if(startsWith(link, \"script:\")) /// process subscription with script\n        {\n            writeLog(0, \"Found script link. Start running...\", LOG_LEVEL_INFO);\n            string_array args = split(link.substr(7), \",\");\n            if(args.size() >= 1)\n            {\n                std::string script = fileGet(args[0], false);\n                try\n                {\n                    ctx.eval(script);\n                    args.erase(args.begin()); /// remove script path\n                    auto parse = (std::function<std::string(const std::string&, const string_array&)>) ctx.eval(\"parse\");\n                    switch(args.size())\n                    {\n                    case 0:\n                        link = parse(std::string(), string_array());\n                        break;\n                    case 1:\n                        link = parse(args[0], string_array());\n                        break;\n                    default:\n                        {\n                            std::string first = args[0];\n                            args.erase(args.begin());\n                            link = parse(first, args);\n                            break;\n                        }\n                    }\n                }\n                catch(qjs::exception)\n                {\n                    script_print_stack(ctx);\n                }\n            }\n        }\n    }, global.scriptCleanContext);\n            /*\n            duk_context *ctx = duktape_init();\n            defer(duk_destroy_heap(ctx);)\n            duktape_peval(ctx, script);\n            duk_get_global_string(ctx, \"parse\");\n            for(size_t i = 1; i < args.size(); i++)\n                duk_push_string(ctx, trim(args[i]).c_str());\n            if(duk_pcall(ctx, args.size() - 1) == 0)\n                link = duktape_get_res_str(ctx);\n            else\n            {\n                writeLog(0, \"Error when trying to evaluate script:\\n\" + duktape_get_err_stack(ctx), LOG_LEVEL_ERROR);\n                duk_pop(ctx); /// pop err\n            }\n            */\n\n    /// tag:group_name,link\n    if(startsWith(link, \"tag:\"))\n    {\n        string_size pos = link.find(\",\");\n        if(pos != link.npos)\n        {\n            custom_group = link.substr(4, pos - 4);\n            link.erase(0, pos + 1);\n        }\n    }\n\n    if(link == \"nullnode\")\n    {\n        node.GroupId = 0;\n        writeLog(0, \"Adding node placeholder...\");\n        allNodes.emplace_back(std::move(node));\n        return 0;\n    }\n\n    writeLog(LOG_TYPE_INFO, \"Received Link.\");\n    if(startsWith(link, \"https://t.me/socks\") || startsWith(link, \"tg://socks\"))\n        linkType = ConfType::SOCKS;\n    else if(startsWith(link, \"https://t.me/http\") || startsWith(link, \"tg://http\"))\n        linkType = ConfType::HTTP;\n    else if(isLink(link) || startsWith(link, \"surge:///install-config\"))\n        linkType = ConfType::SUB;\n    else if(startsWith(link, \"Netch://\"))\n        linkType = ConfType::Netch;\n    else if(fileExist(link))\n        linkType = ConfType::Local;\n\n    switch(linkType)\n    {\n    case ConfType::SUB:\n        writeLog(LOG_TYPE_INFO, \"Downloading subscription data...\");\n        if(startsWith(link, \"surge:///install-config\")) //surge config link\n            link = urlDecode(getUrlArg(link, \"url\"));\n        strSub = webGet(link, proxy, global.cacheSubscription, &extra_headers, request_headers);\n        /*\n        if(strSub.size() == 0)\n        {\n            //try to get it again with system proxy\n            writeLog(LOG_TYPE_WARN, \"Cannot download subscription directly. Using system proxy.\");\n            strProxy = getSystemProxy();\n            if(strProxy != \"\")\n            {\n                strSub = webGet(link, strProxy);\n            }\n            else\n                writeLog(LOG_TYPE_WARN, \"No system proxy is set. Skipping.\");\n        }\n        */\n        if(strSub.size())\n        {\n            writeLog(LOG_TYPE_INFO, \"Parsing subscription data...\");\n            if(explodeConfContent(strSub, nodes) == 0)\n            {\n                writeLog(LOG_TYPE_ERROR, \"Invalid subscription: '\" + link + \"'!\");\n                return -1;\n            }\n            if(startsWith(strSub, \"ssd://\"))\n            {\n                getSubInfoFromSSD(strSub, subInfo);\n            }\n            else\n            {\n                if(!getSubInfoFromHeader(extra_headers, subInfo))\n                    getSubInfoFromNodes(nodes, stream_rules, time_rules, subInfo);\n            }\n            filterNodes(nodes, exclude_remarks, include_remarks, groupID);\n            for(Proxy &x : nodes)\n            {\n                x.GroupId = groupID;\n                if(custom_group.size())\n                    x.Group = custom_group;\n            }\n            copyNodes(nodes, allNodes);\n        }\n        else\n        {\n            writeLog(LOG_TYPE_ERROR, \"Cannot download subscription data.\");\n            return -1;\n        }\n        break;\n    case ConfType::Local:\n        if(!authorized)\n            return -1;\n        writeLog(LOG_TYPE_INFO, \"Parsing configuration file data...\");\n        if(explodeConf(link, nodes) == 0)\n        {\n            writeLog(LOG_TYPE_ERROR, \"Invalid configuration file!\");\n            return -1;\n        }\n        if(startsWith(strSub, \"ssd://\"))\n        {\n            getSubInfoFromSSD(strSub, subInfo);\n        }\n        else\n        {\n            getSubInfoFromNodes(nodes, stream_rules, time_rules, subInfo);\n        }\n        filterNodes(nodes, exclude_remarks, include_remarks, groupID);\n        for(Proxy &x : nodes)\n        {\n            x.GroupId = groupID;\n            if(custom_group.size())\n                x.Group = custom_group;\n        }\n        copyNodes(nodes, allNodes);\n        break;\n    default:\n        explode(link, node);\n        if(node.Type == -1)\n        {\n            writeLog(LOG_TYPE_ERROR, \"No valid link found.\");\n            return -1;\n        }\n        node.GroupId = groupID;\n        if(custom_group.size())\n            node.Group = custom_group;\n        allNodes.emplace_back(std::move(node));\n    }\n    return 0;\n}",
        "func": "int addNodes(std::string link, std::vector<Proxy> &allNodes, int groupID, parse_settings &parse_set)\n{\n    std::string &proxy = *parse_set.proxy, &subInfo = *parse_set.sub_info;\n    string_array &exclude_remarks = *parse_set.exclude_remarks;\n    string_array &include_remarks = *parse_set.include_remarks;\n    RegexMatchConfigs &stream_rules = *parse_set.stream_rules;\n    RegexMatchConfigs &time_rules = *parse_set.time_rules;\n    string_icase_map *request_headers = parse_set.request_header;\n    bool &authorized = parse_set.authorized;\n\n    ConfType linkType = ConfType::Unknow;\n    std::vector<Proxy> nodes;\n    Proxy node;\n    std::string strSub, extra_headers, custom_group;\n\n    // TODO: replace with startsWith if appropriate\n    link = replaceAllDistinct(link, \"\\\"\", \"\");\n\n    /// script:filepath,arg1,arg2,...\n    if(authorized) script_safe_runner(parse_set.js_runtime, parse_set.js_context, [&](qjs::Context &ctx)\n    {\n        if(startsWith(link, \"script:\")) /// process subscription with script\n        {\n            writeLog(0, \"Found script link. Start running...\", LOG_LEVEL_INFO);\n            string_array args = split(link.substr(7), \",\");\n            if(args.size() >= 1)\n            {\n                std::string script = fileGet(args[0], false);\n                try\n                {\n                    ctx.eval(script);\n                    args.erase(args.begin()); /// remove script path\n                    auto parse = (std::function<std::string(const std::string&, const string_array&)>) ctx.eval(\"parse\");\n                    switch(args.size())\n                    {\n                    case 0:\n                        link = parse(std::string(), string_array());\n                        break;\n                    case 1:\n                        link = parse(args[0], string_array());\n                        break;\n                    default:\n                        {\n                            std::string first = args[0];\n                            args.erase(args.begin());\n                            link = parse(first, args);\n                            break;\n                        }\n                    }\n                }\n                catch(qjs::exception)\n                {\n                    script_print_stack(ctx);\n                }\n            }\n        }\n    }, global.scriptCleanContext);\n            /*\n            duk_context *ctx = duktape_init();\n            defer(duk_destroy_heap(ctx);)\n            duktape_peval(ctx, script);\n            duk_get_global_string(ctx, \"parse\");\n            for(size_t i = 1; i < args.size(); i++)\n                duk_push_string(ctx, trim(args[i]).c_str());\n            if(duk_pcall(ctx, args.size() - 1) == 0)\n                link = duktape_get_res_str(ctx);\n            else\n            {\n                writeLog(0, \"Error when trying to evaluate script:\\n\" + duktape_get_err_stack(ctx), LOG_LEVEL_ERROR);\n                duk_pop(ctx); /// pop err\n            }\n            */\n\n    /// tag:group_name,link\n    if(startsWith(link, \"tag:\"))\n    {\n        string_size pos = link.find(\",\");\n        if(pos != link.npos)\n        {\n            custom_group = link.substr(4, pos - 4);\n            link.erase(0, pos + 1);\n        }\n    }\n\n    if(link == \"nullnode\")\n    {\n        node.GroupId = 0;\n        writeLog(0, \"Adding node placeholder...\");\n        allNodes.emplace_back(std::move(node));\n        return 0;\n    }\n\n    writeLog(LOG_TYPE_INFO, \"Received Link.\");\n    if(startsWith(link, \"https://t.me/socks\") || startsWith(link, \"tg://socks\"))\n        linkType = ConfType::SOCKS;\n    else if(startsWith(link, \"https://t.me/http\") || startsWith(link, \"tg://http\"))\n        linkType = ConfType::HTTP;\n    else if(isLink(link) || startsWith(link, \"surge:///install-config\"))\n        linkType = ConfType::SUB;\n    else if(startsWith(link, \"Netch://\"))\n        linkType = ConfType::Netch;\n    else if(fileExist(link))\n        linkType = ConfType::Local;\n\n    switch(linkType)\n    {\n    case ConfType::SUB:\n        writeLog(LOG_TYPE_INFO, \"Downloading subscription data...\");\n        if(startsWith(link, \"surge:///install-config\")) //surge config link\n            link = urlDecode(getUrlArg(link, \"url\"));\n        strSub = webGet(link, proxy, global.cacheSubscription, &extra_headers, request_headers);\n        /*\n        if(strSub.size() == 0)\n        {\n            //try to get it again with system proxy\n            writeLog(LOG_TYPE_WARN, \"Cannot download subscription directly. Using system proxy.\");\n            strProxy = getSystemProxy();\n            if(strProxy != \"\")\n            {\n                strSub = webGet(link, strProxy);\n            }\n            else\n                writeLog(LOG_TYPE_WARN, \"No system proxy is set. Skipping.\");\n        }\n        */\n        if(strSub.size())\n        {\n            writeLog(LOG_TYPE_INFO, \"Parsing subscription data...\");\n            if(explodeConfContent(strSub, nodes) == 0)\n            {\n                writeLog(LOG_TYPE_ERROR, \"Invalid subscription: '\" + link + \"'!\");\n                return -1;\n            }\n            if(startsWith(strSub, \"ssd://\"))\n            {\n                getSubInfoFromSSD(strSub, subInfo);\n            }\n            else\n            {\n                if(!getSubInfoFromHeader(extra_headers, subInfo))\n                    getSubInfoFromNodes(nodes, stream_rules, time_rules, subInfo);\n            }\n            filterNodes(nodes, exclude_remarks, include_remarks, groupID);\n            for(Proxy &x : nodes)\n            {\n                x.GroupId = groupID;\n                if(custom_group.size())\n                    x.Group = custom_group;\n            }\n            copyNodes(nodes, allNodes);\n        }\n        else\n        {\n            writeLog(LOG_TYPE_ERROR, \"Cannot download subscription data.\");\n            return -1;\n        }\n        break;\n    case ConfType::Local:\n        if(!authorized)\n            return -1;\n        writeLog(LOG_TYPE_INFO, \"Parsing configuration file data...\");\n        if(explodeConf(link, nodes) == 0)\n        {\n            writeLog(LOG_TYPE_ERROR, \"Invalid configuration file!\");\n            return -1;\n        }\n        if(startsWith(strSub, \"ssd://\"))\n        {\n            getSubInfoFromSSD(strSub, subInfo);\n        }\n        else\n        {\n            getSubInfoFromNodes(nodes, stream_rules, time_rules, subInfo);\n        }\n        filterNodes(nodes, exclude_remarks, include_remarks, groupID);\n        for(Proxy &x : nodes)\n        {\n            x.GroupId = groupID;\n            if(custom_group.size())\n                x.Group = custom_group;\n        }\n        copyNodes(nodes, allNodes);\n        break;\n    default:\n        explode(link, node);\n        if(node.Type == -1)\n        {\n            writeLog(LOG_TYPE_ERROR, \"No valid link found.\");\n            return -1;\n        }\n        node.GroupId = groupID;\n        if(custom_group.size())\n            node.Group = custom_group;\n        allNodes.emplace_back(std::move(node));\n    }\n    return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -17,7 +17,7 @@\n     link = replaceAllDistinct(link, \"\\\"\", \"\");\n \n     /// script:filepath,arg1,arg2,...\n-    script_safe_runner(parse_set.js_runtime, parse_set.js_context, [&](qjs::Context &ctx)\n+    if(authorized) script_safe_runner(parse_set.js_runtime, parse_set.js_context, [&](qjs::Context &ctx)\n     {\n         if(startsWith(link, \"script:\")) /// process subscription with script\n         {",
        "diff_line_info": {
            "deleted_lines": [
                "    script_safe_runner(parse_set.js_runtime, parse_set.js_context, [&](qjs::Context &ctx)"
            ],
            "added_lines": [
                "    if(authorized) script_safe_runner(parse_set.js_runtime, parse_set.js_context, [&](qjs::Context &ctx)"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-28927",
        "func_name": "tindy2013/subconverter/addEmoji",
        "description": "A remote code execution (RCE) vulnerability in Subconverter v0.7.2 allows attackers to execute arbitrary code via crafted config and url parameters.",
        "git_url": "https://github.com/tindy2013/subconverter/commit/ce8d2bd0f13f05fcbd2ed90755d097f402393dd3",
        "commit_title": "Enhancements",
        "commit_text": " Add authorization check before loading scripts. Add detailed logs when loading preference settings.",
        "func_before": "std::string addEmoji(const Proxy &node, const RegexMatchConfigs &emoji_array, extra_settings &ext)\n{\n    std::string real_rule, ret;\n\n    for(const RegexMatchConfig &x : emoji_array)\n    {\n        if(!x.Script.empty())\n        {\n            std::string result;\n            script_safe_runner(ext.js_runtime, ext.js_context, [&](qjs::Context &ctx)\n            {\n                std::string script = x.Script;\n                if(startsWith(script, \"path:\"))\n                    script = fileGet(script.substr(5), true);\n                try\n                {\n                    ctx.eval(script);\n                    auto getEmoji = (std::function<std::string(const Proxy&)>) ctx.eval(\"getEmoji\");\n                    ret = getEmoji(node);\n                    if(!ret.empty())\n                        result = ret + \" \" + node.Remark;\n                }\n                catch (qjs::exception)\n                {\n                    script_print_stack(ctx);\n                }\n            }, global.scriptCleanContext);\n            if(!result.empty())\n                return result;\n            continue;\n        }\n        if(x.Replace.empty())\n            continue;\n        if(applyMatcher(x.Match, real_rule, node) && real_rule.size() && regFind(node.Remark, real_rule))\n            return x.Replace + \" \" + node.Remark;\n    }\n    return node.Remark;\n}",
        "func": "std::string addEmoji(const Proxy &node, const RegexMatchConfigs &emoji_array, extra_settings &ext)\n{\n    std::string real_rule, ret;\n\n    for(const RegexMatchConfig &x : emoji_array)\n    {\n        if(!x.Script.empty() && ext.authorized)\n        {\n            std::string result;\n            script_safe_runner(ext.js_runtime, ext.js_context, [&](qjs::Context &ctx)\n            {\n                std::string script = x.Script;\n                if(startsWith(script, \"path:\"))\n                    script = fileGet(script.substr(5), true);\n                try\n                {\n                    ctx.eval(script);\n                    auto getEmoji = (std::function<std::string(const Proxy&)>) ctx.eval(\"getEmoji\");\n                    ret = getEmoji(node);\n                    if(!ret.empty())\n                        result = ret + \" \" + node.Remark;\n                }\n                catch (qjs::exception)\n                {\n                    script_print_stack(ctx);\n                }\n            }, global.scriptCleanContext);\n            if(!result.empty())\n                return result;\n            continue;\n        }\n        if(x.Replace.empty())\n            continue;\n        if(applyMatcher(x.Match, real_rule, node) && real_rule.size() && regFind(node.Remark, real_rule))\n            return x.Replace + \" \" + node.Remark;\n    }\n    return node.Remark;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,7 +4,7 @@\n \n     for(const RegexMatchConfig &x : emoji_array)\n     {\n-        if(!x.Script.empty())\n+        if(!x.Script.empty() && ext.authorized)\n         {\n             std::string result;\n             script_safe_runner(ext.js_runtime, ext.js_context, [&](qjs::Context &ctx)",
        "diff_line_info": {
            "deleted_lines": [
                "        if(!x.Script.empty())"
            ],
            "added_lines": [
                "        if(!x.Script.empty() && ext.authorized)"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-28927",
        "func_name": "tindy2013/subconverter/nodeRename",
        "description": "A remote code execution (RCE) vulnerability in Subconverter v0.7.2 allows attackers to execute arbitrary code via crafted config and url parameters.",
        "git_url": "https://github.com/tindy2013/subconverter/commit/ce8d2bd0f13f05fcbd2ed90755d097f402393dd3",
        "commit_title": "Enhancements",
        "commit_text": " Add authorization check before loading scripts. Add detailed logs when loading preference settings.",
        "func_before": "void nodeRename(Proxy &node, const RegexMatchConfigs &rename_array, extra_settings &ext)\n{\n    std::string &remark = node.Remark, original_remark = node.Remark, returned_remark, real_rule;\n\n    for(const RegexMatchConfig &x : rename_array)\n    {\n        if(!x.Script.empty())\n        {\n            script_safe_runner(ext.js_runtime, ext.js_context, [&](qjs::Context &ctx)\n            {\n                std::string script = x.Script;\n                if(startsWith(script, \"path:\"))\n                    script = fileGet(script.substr(5), true);\n                try\n                {\n                    ctx.eval(script);\n                    auto rename = (std::function<std::string(const Proxy&)>) ctx.eval(\"rename\");\n                    returned_remark = rename(node);\n                    if(!returned_remark.empty())\n                        remark = returned_remark;\n                }\n                catch (qjs::exception)\n                {\n                    script_print_stack(ctx);\n                }\n            }, global.scriptCleanContext);\n            continue;\n        }\n        if(applyMatcher(x.Match, real_rule, node) && real_rule.size())\n            remark = regReplace(remark, real_rule, x.Replace);\n    }\n    if(remark.empty())\n        remark = original_remark;\n    return;\n}",
        "func": "void nodeRename(Proxy &node, const RegexMatchConfigs &rename_array, extra_settings &ext)\n{\n    std::string &remark = node.Remark, original_remark = node.Remark, returned_remark, real_rule;\n\n    for(const RegexMatchConfig &x : rename_array)\n    {\n        if(!x.Script.empty() && ext.authorized)\n        {\n            script_safe_runner(ext.js_runtime, ext.js_context, [&](qjs::Context &ctx)\n            {\n                std::string script = x.Script;\n                if(startsWith(script, \"path:\"))\n                    script = fileGet(script.substr(5), true);\n                try\n                {\n                    ctx.eval(script);\n                    auto rename = (std::function<std::string(const Proxy&)>) ctx.eval(\"rename\");\n                    returned_remark = rename(node);\n                    if(!returned_remark.empty())\n                        remark = returned_remark;\n                }\n                catch (qjs::exception)\n                {\n                    script_print_stack(ctx);\n                }\n            }, global.scriptCleanContext);\n            continue;\n        }\n        if(applyMatcher(x.Match, real_rule, node) && real_rule.size())\n            remark = regReplace(remark, real_rule, x.Replace);\n    }\n    if(remark.empty())\n        remark = original_remark;\n    return;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,7 +4,7 @@\n \n     for(const RegexMatchConfig &x : rename_array)\n     {\n-        if(!x.Script.empty())\n+        if(!x.Script.empty() && ext.authorized)\n         {\n             script_safe_runner(ext.js_runtime, ext.js_context, [&](qjs::Context &ctx)\n             {",
        "diff_line_info": {
            "deleted_lines": [
                "        if(!x.Script.empty())"
            ],
            "added_lines": [
                "        if(!x.Script.empty() && ext.authorized)"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-28927",
        "func_name": "tindy2013/subconverter/subconverter",
        "description": "A remote code execution (RCE) vulnerability in Subconverter v0.7.2 allows attackers to execute arbitrary code via crafted config and url parameters.",
        "git_url": "https://github.com/tindy2013/subconverter/commit/ce8d2bd0f13f05fcbd2ed90755d097f402393dd3",
        "commit_title": "Enhancements",
        "commit_text": " Add authorization check before loading scripts. Add detailed logs when loading preference settings.",
        "func_before": "std::string subconverter(RESPONSE_CALLBACK_ARGS)\n{\n    std::string &argument = request.argument;\n    int *status_code = &response.status_code;\n\n    std::string argTarget = getUrlArg(argument, \"target\"), argSurgeVer = getUrlArg(argument, \"ver\");\n    tribool argClashNewField = getUrlArg(argument, \"new_name\");\n    int intSurgeVer = argSurgeVer.size() ? to_int(argSurgeVer, 3) : 3;\n    if(argTarget == \"auto\")\n        matchUserAgent(request.headers[\"User-Agent\"], argTarget, argClashNewField, intSurgeVer);\n\n    /// don't try to load groups or rulesets when generating simple subscriptions\n    bool lSimpleSubscription = false;\n    switch(hash_(argTarget))\n    {\n    case \"ss\"_hash: case \"ssd\"_hash: case \"ssr\"_hash: case \"sssub\"_hash: case \"v2ray\"_hash: case \"trojan\"_hash: case \"mixed\"_hash:\n        lSimpleSubscription = true;\n        break;\n    case \"clash\"_hash: case \"clashr\"_hash: case \"surge\"_hash: case \"quan\"_hash: case \"quanx\"_hash: case \"loon\"_hash: case \"surfboard\"_hash: case \"mellow\"_hash:\n        break;\n    default:\n        *status_code = 400;\n        return \"Invalid target!\";\n    }\n    //check if we need to read configuration\n    if((!global.APIMode || global.CFWChildProcess) && !global.generatorMode)\n        readConf();\n\n    /// string values\n    std::string argUrl = urlDecode(getUrlArg(argument, \"url\"));\n    std::string argGroupName = urlDecode(getUrlArg(argument, \"group\")), argUploadPath = getUrlArg(argument, \"upload_path\");\n    std::string argIncludeRemark = urlDecode(getUrlArg(argument, \"include\")), argExcludeRemark = urlDecode(getUrlArg(argument, \"exclude\"));\n    std::string argCustomGroups = urlSafeBase64Decode(getUrlArg(argument, \"groups\")), argCustomRulesets = urlSafeBase64Decode(getUrlArg(argument, \"ruleset\")), argExternalConfig = urlDecode(getUrlArg(argument, \"config\"));\n    std::string argDeviceID = getUrlArg(argument, \"dev_id\"), argFilename = urlDecode(getUrlArg(argument, \"filename\")), argUpdateInterval = getUrlArg(argument, \"interval\"), argUpdateStrict = getUrlArg(argument, \"strict\");\n    std::string argRenames = urlDecode(getUrlArg(argument, \"rename\")), argFilterScript = urlDecode(getUrlArg(argument, \"filter_script\"));\n\n    /// switches with default value\n    tribool argUpload = getUrlArg(argument, \"upload\"), argEmoji = getUrlArg(argument, \"emoji\"), argAddEmoji = getUrlArg(argument, \"add_emoji\"), argRemoveEmoji = getUrlArg(argument, \"remove_emoji\");\n    tribool argAppendType = getUrlArg(argument, \"append_type\"), argTFO = getUrlArg(argument, \"tfo\"), argUDP = getUrlArg(argument, \"udp\"), argGenNodeList = getUrlArg(argument, \"list\");\n    tribool argSort = getUrlArg(argument, \"sort\"), argUseSortScript = getUrlArg(argument, \"sort_script\");\n    tribool argGenClashScript = getUrlArg(argument, \"script\"), argEnableInsert = getUrlArg(argument, \"insert\");\n    tribool argSkipCertVerify = getUrlArg(argument, \"scv\"), argFilterDeprecated = getUrlArg(argument, \"fdn\"), argExpandRulesets = getUrlArg(argument, \"expand\"), argAppendUserinfo = getUrlArg(argument, \"append_info\");\n    tribool argPrependInsert = getUrlArg(argument, \"prepend\"), argGenClassicalRuleProvider = getUrlArg(argument, \"classic\"), argTLS13 = getUrlArg(argument, \"tls13\");\n\n    std::string base_content, output_content;\n    ProxyGroupConfigs lCustomProxyGroups = global.customProxyGroups;\n    RulesetConfigs lCustomRulesets = global.customRulesets;\n    string_array lIncludeRemarks = global.includeRemarks, lExcludeRemarks = global.excludeRemarks;\n    std::vector<RulesetContent> lRulesetContent;\n    extra_settings ext;\n    std::string subInfo, dummy;\n    int interval = argUpdateInterval.size() ? to_int(argUpdateInterval, global.updateInterval) : global.updateInterval;\n    bool authorized = !global.APIMode || getUrlArg(argument, \"token\") == global.accessToken, strict = argUpdateStrict.size() ? argUpdateStrict == \"true\" : global.updateStrict;\n\n    if(std::find(gRegexBlacklist.cbegin(), gRegexBlacklist.cend(), argIncludeRemark) != gRegexBlacklist.cend() || std::find(gRegexBlacklist.cbegin(), gRegexBlacklist.cend(), argExcludeRemark) != gRegexBlacklist.cend())\n        return \"Invalid request!\";\n\n    /// for external configuration\n    std::string lClashBase = global.clashBase, lSurgeBase = global.surgeBase, lMellowBase = global.mellowBase, lSurfboardBase = global.surfboardBase;\n    std::string lQuanBase = global.quanBase, lQuanXBase = global.quanXBase, lLoonBase = global.loonBase, lSSSubBase = global.SSSubBase;\n\n    /// validate urls\n    argEnableInsert.define(global.enableInsert);\n    if(!argUrl.size() && (!global.APIMode || authorized))\n        argUrl = global.defaultUrls;\n    if((!argUrl.size() && !(global.insertUrls.size() && argEnableInsert)) || !argTarget.size())\n    {\n        *status_code = 400;\n        return \"Invalid request!\";\n    }\n\n    /// load request arguments as template variables\n    string_array req_args = split(argument, \"&\");\n    string_map req_arg_map;\n    for(std::string &x : req_args)\n    {\n        string_size pos = x.find(\"=\");\n        if(pos == x.npos)\n        {\n            req_arg_map[x] = \"\";\n            continue;\n        }\n        if(x.substr(0, pos) == \"token\")\n            continue;\n        req_arg_map[x.substr(0, pos)] = x.substr(pos + 1);\n    }\n    req_arg_map[\"target\"] = argTarget;\n    req_arg_map[\"ver\"] = std::to_string(intSurgeVer);\n\n    /// save template variables\n    template_args tpl_args;\n    tpl_args.global_vars = global.templateVars;\n    tpl_args.request_params = req_arg_map;\n\n    /// check for proxy settings\n    std::string proxy = parseProxy(global.proxySubscription);\n\n    /// check other flags\n    ext.append_proxy_type = argAppendType.get(global.appendType);\n    if((argTarget == \"clash\" || argTarget == \"clashr\") && argGenClashScript.is_undef())\n        argExpandRulesets.define(true);\n\n    ext.clash_proxies_style = global.clashProxiesStyle;\n\n    /// read preference from argument, assign global var if not in argument\n    ext.tfo.define(argTFO).define(global.TFOFlag);\n    ext.udp.define(argUDP).define(global.UDPFlag);\n    ext.skip_cert_verify.define(argSkipCertVerify).define(global.skipCertVerify);\n    ext.tls13.define(argTLS13).define(global.TLS13Flag);\n\n    ext.sort_flag = argSort.get(global.enableSort);\n    argUseSortScript.define(global.sortScript.size() != 0);\n    if(ext.sort_flag && argUseSortScript)\n        ext.sort_script = global.sortScript;\n    ext.filter_deprecated = argFilterDeprecated.get(global.filterDeprecated);\n    ext.clash_new_field_name = argClashNewField.get(global.clashUseNewField);\n    ext.clash_script = argGenClashScript.get();\n    ext.clash_classical_ruleset = argGenClassicalRuleProvider.get();\n    if(!argExpandRulesets)\n        ext.clash_new_field_name = true;\n    else\n        ext.clash_script = false;\n\n    ext.nodelist = argGenNodeList;\n    ext.surge_ssr_path = global.surgeSSRPath;\n    ext.quanx_dev_id = argDeviceID.size() ? argDeviceID : global.quanXDevID;\n    ext.enable_rule_generator = global.enableRuleGen;\n    ext.overwrite_original_rules = global.overwriteOriginalRules;\n    if(!argExpandRulesets)\n        ext.managed_config_prefix = global.managedConfigPrefix;\n\n    /// load external configuration\n    if(argExternalConfig.empty())\n        argExternalConfig = global.defaultExtConfig;\n    if(argExternalConfig.size())\n    {\n        //std::cerr<<\"External configuration file provided. Loading...\\n\";\n        writeLog(0, \"External configuration file provided. Loading...\", LOG_LEVEL_INFO);\n        ExternalConfig extconf;\n        extconf.tpl_args = &tpl_args;\n        if(loadExternalConfig(argExternalConfig, extconf) == 0)\n        {\n            if(!ext.nodelist)\n            {\n                checkExternalBase(extconf.sssub_rule_base, lSSSubBase);\n                if(!lSimpleSubscription)\n                {\n                    checkExternalBase(extconf.clash_rule_base, lClashBase);\n                    checkExternalBase(extconf.surge_rule_base, lSurgeBase);\n                    checkExternalBase(extconf.surfboard_rule_base, lSurfboardBase);\n                    checkExternalBase(extconf.mellow_rule_base, lMellowBase);\n                    checkExternalBase(extconf.quan_rule_base, lQuanBase);\n                    checkExternalBase(extconf.quanx_rule_base, lQuanXBase);\n                    checkExternalBase(extconf.loon_rule_base, lLoonBase);\n\n                    if(extconf.surge_ruleset.size())\n                        lCustomRulesets = extconf.surge_ruleset;\n                    if(extconf.custom_proxy_group.size())\n                        lCustomProxyGroups = extconf.custom_proxy_group;\n                    ext.enable_rule_generator = extconf.enable_rule_generator;\n                    ext.overwrite_original_rules = extconf.overwrite_original_rules;\n                }\n            }\n            if(extconf.rename.size())\n                ext.rename_array = extconf.rename;\n            if(extconf.emoji.size())\n                ext.emoji_array = extconf.emoji;\n            if(extconf.include.size())\n                lIncludeRemarks = extconf.include;\n            if(extconf.exclude.size())\n                lExcludeRemarks = extconf.exclude;\n            argAddEmoji.define(extconf.add_emoji);\n            argRemoveEmoji.define(extconf.remove_old_emoji);\n        }\n    }\n    else\n    {\n        if(!lSimpleSubscription)\n        {\n            /// loading custom groups\n            if(argCustomGroups.size() && !ext.nodelist)\n            {\n                string_array vArray = split(argCustomGroups, \"@\");\n                lCustomProxyGroups = INIBinding::from<ProxyGroupConfig>::from_ini(vArray);\n            }\n\n            /// loading custom rulesets\n            if(argCustomRulesets.size() && !ext.nodelist)\n            {\n                string_array vArray = split(argCustomRulesets, \"@\");\n                lCustomRulesets = INIBinding::from<RulesetConfig>::from_ini(vArray);\n            }\n        }\n    }\n    if(ext.enable_rule_generator && !ext.nodelist && !lSimpleSubscription)\n    {\n        if(lCustomRulesets != global.customRulesets)\n            refreshRulesets(lCustomRulesets, lRulesetContent);\n        else\n        {\n            if(global.updateRulesetOnRequest)\n                refreshRulesets(global.customRulesets, global.rulesetsContent);\n            lRulesetContent = global.rulesetsContent;\n        }\n    }\n\n    if(!argEmoji.is_undef())\n    {\n        argAddEmoji.set(argEmoji);\n        argRemoveEmoji.set(true);\n    }\n    ext.add_emoji = argAddEmoji.get(global.addEmoji);\n    ext.remove_emoji = argRemoveEmoji.get(global.removeEmoji);\n    if(ext.add_emoji && ext.emoji_array.empty())\n        ext.emoji_array = safe_get_emojis();\n    if(argRenames.size())\n        ext.rename_array = INIBinding::from<RegexMatchConfig>::from_ini(split(argRenames, \"`\"), \"@\");\n    else if(ext.rename_array.empty())\n        ext.rename_array = safe_get_renames();\n\n    /// check custom include/exclude settings\n    if(argIncludeRemark.size() && regValid(argIncludeRemark))\n        lIncludeRemarks = string_array{argIncludeRemark};\n    if(argExcludeRemark.size() && regValid(argExcludeRemark))\n        lExcludeRemarks = string_array{argExcludeRemark};\n\n    /// initialize script runtime\n    if(authorized && !global.scriptCleanContext)\n    {\n        ext.js_runtime = new qjs::Runtime();\n        script_runtime_init(*ext.js_runtime);\n        ext.js_context = new qjs::Context(*ext.js_runtime);\n        script_context_init(*ext.js_context);\n    }\n\n    //start parsing urls\n    RegexMatchConfigs stream_temp = safe_get_streams(), time_temp = safe_get_times();\n\n    //loading urls\n    string_array urls;\n    std::vector<Proxy> nodes, insert_nodes;\n    int groupID = 0;\n\n    parse_settings parse_set;\n    parse_set.proxy = &proxy;\n    parse_set.exclude_remarks = &lExcludeRemarks;\n    parse_set.include_remarks = &lIncludeRemarks;\n    parse_set.stream_rules = &stream_temp;\n    parse_set.time_rules = &time_temp;\n    parse_set.sub_info = &subInfo;\n    parse_set.authorized = authorized;\n    parse_set.request_header = &request.headers;\n    parse_set.js_runtime = ext.js_runtime;\n    parse_set.js_context = ext.js_context;\n\n    if(global.insertUrls.size() && argEnableInsert)\n    {\n        groupID = -1;\n        urls = split(global.insertUrls, \"|\");\n        importItems(urls, true);\n        for(std::string &x : urls)\n        {\n            x = regTrim(x);\n            writeLog(0, \"Fetching node data from url '\" + x + \"'.\", LOG_LEVEL_INFO);\n            if(addNodes(x, insert_nodes, groupID, parse_set) == -1)\n            {\n                if(global.skipFailedLinks)\n                    writeLog(0, \"The following link doesn't contain any valid node info: \" + x, LOG_LEVEL_WARNING);\n                else\n                {\n                    *status_code = 400;\n                    return \"The following link doesn't contain any valid node info: \" + x;\n                }\n            }\n            groupID--;\n        }\n    }\n    urls = split(argUrl, \"|\");\n    importItems(urls, true);\n    groupID = 0;\n    for(std::string &x : urls)\n    {\n        x = regTrim(x);\n        //std::cerr<<\"Fetching node data from url '\"<<x<<\"'.\"<<std::endl;\n        writeLog(0, \"Fetching node data from url '\" + x + \"'.\", LOG_LEVEL_INFO);\n        if(addNodes(x, nodes, groupID, parse_set) == -1)\n        {\n            if(global.skipFailedLinks)\n                writeLog(0, \"The following link doesn't contain any valid node info: \" + x, LOG_LEVEL_WARNING);\n            else\n            {\n                *status_code = 400;\n                return \"The following link doesn't contain any valid node info: \" + x;\n            }\n        }\n        groupID++;\n    }\n    //exit if found nothing\n    if(!nodes.size() && !insert_nodes.size())\n    {\n        *status_code = 400;\n        return \"No nodes were found!\";\n    }\n    if(subInfo.size() && argAppendUserinfo.get(global.appendUserinfo))\n        response.headers.emplace(\"Subscription-UserInfo\", subInfo);\n\n    if(request.method == \"HEAD\")\n        return \"\";\n\n    argPrependInsert.define(global.prependInsert);\n    if(argPrependInsert)\n    {\n        std::move(nodes.begin(), nodes.end(), std::back_inserter(insert_nodes));\n        nodes.swap(insert_nodes);\n    }\n    else\n    {\n        std::move(insert_nodes.begin(), insert_nodes.end(), std::back_inserter(nodes));\n    }\n    //run filter script\n    std::string filterScript = global.filterScript;\n    if(authorized && !argFilterScript.empty())\n        filterScript = argFilterScript;\n    if(filterScript.size())\n    {\n        if(startsWith(filterScript, \"path:\"))\n            filterScript = fileGet(filterScript.substr(5), false);\n        /*\n        duk_context *ctx = duktape_init();\n        if(ctx)\n        {\n            defer(duk_destroy_heap(ctx);)\n            if(duktape_peval(ctx, filterScript) == 0)\n            {\n                auto filter = [&](const Proxy &x)\n                {\n                    duk_get_global_string(ctx, \"filter\");\n                    duktape_push_Proxy(ctx, x);\n                    duk_pcall(ctx, 1);\n                    return !duktape_get_res_bool(ctx);\n                };\n                nodes.erase(std::remove_if(nodes.begin(), nodes.end(), filter), nodes.end());\n            }\n            else\n            {\n                writeLog(0, \"Error when trying to parse script:\\n\" + duktape_get_err_stack(ctx), LOG_LEVEL_ERROR);\n                duk_pop(ctx); /// pop err\n            }\n        }\n        */\n        script_safe_runner(ext.js_runtime, ext.js_context, [&](qjs::Context &ctx)\n        {\n            try\n            {\n                ctx.eval(filterScript);\n                auto filter = (std::function<bool(const Proxy&)>) ctx.eval(\"filter\");\n                nodes.erase(std::remove_if(nodes.begin(), nodes.end(), filter), nodes.end());\n            }\n            catch(qjs::exception)\n            {\n                script_print_stack(ctx);\n            }\n        }, global.scriptCleanContext);\n    }\n\n    //check custom group name\n    if(argGroupName.size())\n        for(Proxy &x : nodes)\n            x.Group = argGroupName;\n\n    //do pre-process now\n    preprocessNodes(nodes, ext);\n\n    /*\n    //insert node info to template\n    int index = 0;\n    std::string template_node_prefix;\n    for(Proxy &x : nodes)\n    {\n        template_node_prefix = std::to_string(index) + \".\";\n        tpl_args.node_list[template_node_prefix + \"remarks\"] = x.remarks;\n        tpl_args.node_list[template_node_prefix + \"group\"] = x.Group;\n        tpl_args.node_list[template_node_prefix + \"groupid\"] = std::to_string(x.GroupId);\n        index++;\n    }\n    */\n\n    ProxyGroupConfigs dummy_group;\n    std::vector<RulesetContent> dummy_ruleset;\n    std::string managed_url = base64Decode(urlDecode(getUrlArg(argument, \"profile_data\")));\n    if(managed_url.empty())\n        managed_url = global.managedConfigPrefix + \"/sub?\" + argument;\n\n    //std::cerr<<\"Generate target: \";\n    proxy = parseProxy(global.proxyConfig);\n    switch(hash_(argTarget))\n    {\n    case \"clash\"_hash: case \"clashr\"_hash:\n        writeLog(0, argTarget == \"clashr\" ? \"Generate target: ClashR\" : \"Generate target: Clash\", LOG_LEVEL_INFO);\n        tpl_args.local_vars[\"clash.new_field_name\"] = ext.clash_new_field_name ? \"true\" : \"false\";\n        response.headers[\"profile-update-interval\"] = std::to_string(interval / 3600);\n        if(ext.nodelist)\n        {\n            YAML::Node yamlnode;\n            proxyToClash(nodes, yamlnode, dummy_group, argTarget == \"clashr\", ext);\n            output_content = YAML::Dump(yamlnode);\n        }\n        else\n        {\n            if(render_template(fetchFile(lClashBase, proxy, global.cacheConfig), tpl_args, base_content, global.templatePath) != 0)\n            {\n                *status_code = 400;\n                return base_content;\n            }\n            output_content = proxyToClash(nodes, base_content, lRulesetContent, lCustomProxyGroups, argTarget == \"clashr\", ext);\n        }\n\n        if(argUpload)\n            uploadGist(argTarget, argUploadPath, output_content, false);\n        break;\n    case \"surge\"_hash:\n\n        writeLog(0, \"Generate target: Surge \" + std::to_string(intSurgeVer), LOG_LEVEL_INFO);\n\n        if(ext.nodelist)\n        {\n            output_content = proxyToSurge(nodes, base_content, dummy_ruleset, dummy_group, intSurgeVer, ext);\n\n            if(argUpload)\n                uploadGist(\"surge\" + argSurgeVer + \"list\", argUploadPath, output_content, true);\n        }\n        else\n        {\n            if(render_template(fetchFile(lSurgeBase, proxy, global.cacheConfig), tpl_args, base_content, global.templatePath) != 0)\n            {\n                *status_code = 400;\n                return base_content;\n            }\n            output_content = proxyToSurge(nodes, base_content, lRulesetContent, lCustomProxyGroups, intSurgeVer, ext);\n\n            if(argUpload)\n                uploadGist(\"surge\" + argSurgeVer, argUploadPath, output_content, true);\n\n            if(global.writeManagedConfig && global.managedConfigPrefix.size())\n                output_content = \"#!MANAGED-CONFIG \" + managed_url + (interval ? \" interval=\" + std::to_string(interval) : \"\") \\\n                 + \" strict=\" + std::string(strict ? \"true\" : \"false\") + \"\\n\\n\" + output_content;\n        }\n        break;\n    case \"surfboard\"_hash:\n        writeLog(0, \"Generate target: Surfboard\", LOG_LEVEL_INFO);\n\n        if(render_template(fetchFile(lSurfboardBase, proxy, global.cacheConfig), tpl_args, base_content, global.templatePath) != 0)\n        {\n            *status_code = 400;\n            return base_content;\n        }\n        output_content = proxyToSurge(nodes, base_content, lRulesetContent, lCustomProxyGroups, -3, ext);\n        if(argUpload)\n            uploadGist(\"surfboard\", argUploadPath, output_content, true);\n\n        if(global.writeManagedConfig && global.managedConfigPrefix.size())\n            output_content = \"#!MANAGED-CONFIG \" + managed_url + (interval ? \" interval=\" + std::to_string(interval) : \"\") \\\n                 + \" strict=\" + std::string(strict ? \"true\" : \"false\") + \"\\n\\n\" + output_content;\n        break;\n    case \"mellow\"_hash:\n        writeLog(0, \"Generate target: Mellow\", LOG_LEVEL_INFO);\n\n        if(render_template(fetchFile(lMellowBase, proxy, global.cacheConfig), tpl_args, base_content, global.templatePath) != 0)\n        {\n            *status_code = 400;\n            return base_content;\n        }\n        output_content = proxyToMellow(nodes, base_content, lRulesetContent, lCustomProxyGroups, ext);\n\n        if(argUpload)\n            uploadGist(\"mellow\", argUploadPath, output_content, true);\n        break;\n    case \"sssub\"_hash:\n        writeLog(0, \"Generate target: SS Subscription\", LOG_LEVEL_INFO);\n\n        if(render_template(fetchFile(lSSSubBase, proxy, global.cacheConfig), tpl_args, base_content, global.templatePath) != 0)\n        {\n            *status_code = 400;\n            return base_content;\n        }\n        output_content = proxyToSSSub(base_content, nodes, ext);\n        if(argUpload)\n            uploadGist(\"sssub\", argUploadPath, output_content, false);\n        break;\n    case \"ss\"_hash:\n        writeLog(0, \"Generate target: SS\", LOG_LEVEL_INFO);\n        output_content = proxyToSingle(nodes, 1, ext);\n        if(argUpload)\n            uploadGist(\"ss\", argUploadPath, output_content, false);\n        break;\n    case \"ssr\"_hash:\n        writeLog(0, \"Generate target: SSR\", LOG_LEVEL_INFO);\n        output_content = proxyToSingle(nodes, 2, ext);\n        if(argUpload)\n            uploadGist(\"ssr\", argUploadPath, output_content, false);\n        break;\n    case \"v2ray\"_hash:\n        writeLog(0, \"Generate target: v2rayN\", LOG_LEVEL_INFO);\n        output_content = proxyToSingle(nodes, 4, ext);\n        if(argUpload)\n            uploadGist(\"v2ray\", argUploadPath, output_content, false);\n        break;\n    case \"trojan\"_hash:\n        writeLog(0, \"Generate target: Trojan\", LOG_LEVEL_INFO);\n        output_content = proxyToSingle(nodes, 8, ext);\n        if(argUpload)\n            uploadGist(\"trojan\", argUploadPath, output_content, false);\n        break;\n    case \"mixed\"_hash:\n        writeLog(0, \"Generate target: Standard Subscription\", LOG_LEVEL_INFO);\n        output_content = proxyToSingle(nodes, 15, ext);\n        if(argUpload)\n            uploadGist(\"sub\", argUploadPath, output_content, false);\n        break;\n    case \"quan\"_hash:\n        writeLog(0, \"Generate target: Quantumult\", LOG_LEVEL_INFO);\n        if(!ext.nodelist)\n        {\n            if(render_template(fetchFile(lQuanBase, proxy, global.cacheConfig), tpl_args, base_content, global.templatePath) != 0)\n            {\n                *status_code = 400;\n                return base_content;\n            }\n        }\n\n        output_content = proxyToQuan(nodes, base_content, lRulesetContent, lCustomProxyGroups, ext);\n\n        if(argUpload)\n            uploadGist(\"quan\", argUploadPath, output_content, false);\n        break;\n    case \"quanx\"_hash:\n        writeLog(0, \"Generate target: Quantumult X\", LOG_LEVEL_INFO);\n        if(!ext.nodelist)\n        {\n            if(render_template(fetchFile(lQuanXBase, proxy, global.cacheConfig), tpl_args, base_content, global.templatePath) != 0)\n            {\n                *status_code = 400;\n                return base_content;\n            }\n        }\n\n        output_content = proxyToQuanX(nodes, base_content, lRulesetContent, lCustomProxyGroups, ext);\n\n        if(argUpload)\n            uploadGist(\"quanx\", argUploadPath, output_content, false);\n        break;\n    case \"loon\"_hash:\n        writeLog(0, \"Generate target: Loon\", LOG_LEVEL_INFO);\n        if(!ext.nodelist)\n        {\n            if(render_template(fetchFile(lLoonBase, proxy, global.cacheConfig), tpl_args, base_content, global.templatePath) != 0)\n            {\n                *status_code = 400;\n                return base_content;\n            }\n        }\n\n        output_content = proxyToLoon(nodes, base_content, lRulesetContent, lCustomProxyGroups, ext);\n\n        if(argUpload)\n            uploadGist(\"loon\", argUploadPath, output_content, false);\n        break;\n    case \"ssd\"_hash:\n        writeLog(0, \"Generate target: SSD\", LOG_LEVEL_INFO);\n        output_content = proxyToSSD(nodes, argGroupName, subInfo, ext);\n        if(argUpload)\n            uploadGist(\"ssd\", argUploadPath, output_content, false);\n        break;\n    default:\n        writeLog(0, \"Generate target: Unspecified\", LOG_LEVEL_INFO);\n        *status_code = 500;\n        return \"Unrecognized target\";\n    }\n    writeLog(0, \"Generate completed.\", LOG_LEVEL_INFO);\n    if(argFilename.size())\n        response.headers.emplace(\"Content-Disposition\", \"attachment; filename=\\\"\" + argFilename + \"\\\"; filename*=utf-8''\" + urlEncode(argFilename));\n    return output_content;\n}",
        "func": "std::string subconverter(RESPONSE_CALLBACK_ARGS)\n{\n    std::string &argument = request.argument;\n    int *status_code = &response.status_code;\n\n    std::string argTarget = getUrlArg(argument, \"target\"), argSurgeVer = getUrlArg(argument, \"ver\");\n    tribool argClashNewField = getUrlArg(argument, \"new_name\");\n    int intSurgeVer = argSurgeVer.size() ? to_int(argSurgeVer, 3) : 3;\n    if(argTarget == \"auto\")\n        matchUserAgent(request.headers[\"User-Agent\"], argTarget, argClashNewField, intSurgeVer);\n\n    /// don't try to load groups or rulesets when generating simple subscriptions\n    bool lSimpleSubscription = false;\n    switch(hash_(argTarget))\n    {\n    case \"ss\"_hash: case \"ssd\"_hash: case \"ssr\"_hash: case \"sssub\"_hash: case \"v2ray\"_hash: case \"trojan\"_hash: case \"mixed\"_hash:\n        lSimpleSubscription = true;\n        break;\n    case \"clash\"_hash: case \"clashr\"_hash: case \"surge\"_hash: case \"quan\"_hash: case \"quanx\"_hash: case \"loon\"_hash: case \"surfboard\"_hash: case \"mellow\"_hash:\n        break;\n    default:\n        *status_code = 400;\n        return \"Invalid target!\";\n    }\n    //check if we need to read configuration\n    if((!global.APIMode || global.CFWChildProcess) && !global.generatorMode)\n        readConf();\n\n    /// string values\n    std::string argUrl = urlDecode(getUrlArg(argument, \"url\"));\n    std::string argGroupName = urlDecode(getUrlArg(argument, \"group\")), argUploadPath = getUrlArg(argument, \"upload_path\");\n    std::string argIncludeRemark = urlDecode(getUrlArg(argument, \"include\")), argExcludeRemark = urlDecode(getUrlArg(argument, \"exclude\"));\n    std::string argCustomGroups = urlSafeBase64Decode(getUrlArg(argument, \"groups\")), argCustomRulesets = urlSafeBase64Decode(getUrlArg(argument, \"ruleset\")), argExternalConfig = urlDecode(getUrlArg(argument, \"config\"));\n    std::string argDeviceID = getUrlArg(argument, \"dev_id\"), argFilename = urlDecode(getUrlArg(argument, \"filename\")), argUpdateInterval = getUrlArg(argument, \"interval\"), argUpdateStrict = getUrlArg(argument, \"strict\");\n    std::string argRenames = urlDecode(getUrlArg(argument, \"rename\")), argFilterScript = urlDecode(getUrlArg(argument, \"filter_script\"));\n\n    /// switches with default value\n    tribool argUpload = getUrlArg(argument, \"upload\"), argEmoji = getUrlArg(argument, \"emoji\"), argAddEmoji = getUrlArg(argument, \"add_emoji\"), argRemoveEmoji = getUrlArg(argument, \"remove_emoji\");\n    tribool argAppendType = getUrlArg(argument, \"append_type\"), argTFO = getUrlArg(argument, \"tfo\"), argUDP = getUrlArg(argument, \"udp\"), argGenNodeList = getUrlArg(argument, \"list\");\n    tribool argSort = getUrlArg(argument, \"sort\"), argUseSortScript = getUrlArg(argument, \"sort_script\");\n    tribool argGenClashScript = getUrlArg(argument, \"script\"), argEnableInsert = getUrlArg(argument, \"insert\");\n    tribool argSkipCertVerify = getUrlArg(argument, \"scv\"), argFilterDeprecated = getUrlArg(argument, \"fdn\"), argExpandRulesets = getUrlArg(argument, \"expand\"), argAppendUserinfo = getUrlArg(argument, \"append_info\");\n    tribool argPrependInsert = getUrlArg(argument, \"prepend\"), argGenClassicalRuleProvider = getUrlArg(argument, \"classic\"), argTLS13 = getUrlArg(argument, \"tls13\");\n\n    std::string base_content, output_content;\n    ProxyGroupConfigs lCustomProxyGroups = global.customProxyGroups;\n    RulesetConfigs lCustomRulesets = global.customRulesets;\n    string_array lIncludeRemarks = global.includeRemarks, lExcludeRemarks = global.excludeRemarks;\n    std::vector<RulesetContent> lRulesetContent;\n    extra_settings ext;\n    std::string subInfo, dummy;\n    int interval = argUpdateInterval.size() ? to_int(argUpdateInterval, global.updateInterval) : global.updateInterval;\n    bool authorized = !global.APIMode || getUrlArg(argument, \"token\") == global.accessToken, strict = argUpdateStrict.size() ? argUpdateStrict == \"true\" : global.updateStrict;\n\n    if(std::find(gRegexBlacklist.cbegin(), gRegexBlacklist.cend(), argIncludeRemark) != gRegexBlacklist.cend() || std::find(gRegexBlacklist.cbegin(), gRegexBlacklist.cend(), argExcludeRemark) != gRegexBlacklist.cend())\n        return \"Invalid request!\";\n\n    /// for external configuration\n    std::string lClashBase = global.clashBase, lSurgeBase = global.surgeBase, lMellowBase = global.mellowBase, lSurfboardBase = global.surfboardBase;\n    std::string lQuanBase = global.quanBase, lQuanXBase = global.quanXBase, lLoonBase = global.loonBase, lSSSubBase = global.SSSubBase;\n\n    /// validate urls\n    argEnableInsert.define(global.enableInsert);\n    if(!argUrl.size() && (!global.APIMode || authorized))\n        argUrl = global.defaultUrls;\n    if((!argUrl.size() && !(global.insertUrls.size() && argEnableInsert)) || !argTarget.size())\n    {\n        *status_code = 400;\n        return \"Invalid request!\";\n    }\n\n    /// load request arguments as template variables\n    string_array req_args = split(argument, \"&\");\n    string_map req_arg_map;\n    for(std::string &x : req_args)\n    {\n        string_size pos = x.find(\"=\");\n        if(pos == x.npos)\n        {\n            req_arg_map[x] = \"\";\n            continue;\n        }\n        if(x.substr(0, pos) == \"token\")\n            continue;\n        req_arg_map[x.substr(0, pos)] = x.substr(pos + 1);\n    }\n    req_arg_map[\"target\"] = argTarget;\n    req_arg_map[\"ver\"] = std::to_string(intSurgeVer);\n\n    /// save template variables\n    template_args tpl_args;\n    tpl_args.global_vars = global.templateVars;\n    tpl_args.request_params = req_arg_map;\n\n    /// check for proxy settings\n    std::string proxy = parseProxy(global.proxySubscription);\n\n    /// check other flags\n    ext.authorized = authorized;\n    ext.append_proxy_type = argAppendType.get(global.appendType);\n    if((argTarget == \"clash\" || argTarget == \"clashr\") && argGenClashScript.is_undef())\n        argExpandRulesets.define(true);\n\n    ext.clash_proxies_style = global.clashProxiesStyle;\n\n    /// read preference from argument, assign global var if not in argument\n    ext.tfo.define(argTFO).define(global.TFOFlag);\n    ext.udp.define(argUDP).define(global.UDPFlag);\n    ext.skip_cert_verify.define(argSkipCertVerify).define(global.skipCertVerify);\n    ext.tls13.define(argTLS13).define(global.TLS13Flag);\n\n    ext.sort_flag = argSort.get(global.enableSort);\n    argUseSortScript.define(global.sortScript.size() != 0);\n    if(ext.sort_flag && argUseSortScript)\n        ext.sort_script = global.sortScript;\n    ext.filter_deprecated = argFilterDeprecated.get(global.filterDeprecated);\n    ext.clash_new_field_name = argClashNewField.get(global.clashUseNewField);\n    ext.clash_script = argGenClashScript.get();\n    ext.clash_classical_ruleset = argGenClassicalRuleProvider.get();\n    if(!argExpandRulesets)\n        ext.clash_new_field_name = true;\n    else\n        ext.clash_script = false;\n\n    ext.nodelist = argGenNodeList;\n    ext.surge_ssr_path = global.surgeSSRPath;\n    ext.quanx_dev_id = argDeviceID.size() ? argDeviceID : global.quanXDevID;\n    ext.enable_rule_generator = global.enableRuleGen;\n    ext.overwrite_original_rules = global.overwriteOriginalRules;\n    if(!argExpandRulesets)\n        ext.managed_config_prefix = global.managedConfigPrefix;\n\n    /// load external configuration\n    if(argExternalConfig.empty())\n        argExternalConfig = global.defaultExtConfig;\n    if(argExternalConfig.size())\n    {\n        //std::cerr<<\"External configuration file provided. Loading...\\n\";\n        writeLog(0, \"External configuration file provided. Loading...\", LOG_LEVEL_INFO);\n        ExternalConfig extconf;\n        extconf.tpl_args = &tpl_args;\n        if(loadExternalConfig(argExternalConfig, extconf) == 0)\n        {\n            if(!ext.nodelist)\n            {\n                checkExternalBase(extconf.sssub_rule_base, lSSSubBase);\n                if(!lSimpleSubscription)\n                {\n                    checkExternalBase(extconf.clash_rule_base, lClashBase);\n                    checkExternalBase(extconf.surge_rule_base, lSurgeBase);\n                    checkExternalBase(extconf.surfboard_rule_base, lSurfboardBase);\n                    checkExternalBase(extconf.mellow_rule_base, lMellowBase);\n                    checkExternalBase(extconf.quan_rule_base, lQuanBase);\n                    checkExternalBase(extconf.quanx_rule_base, lQuanXBase);\n                    checkExternalBase(extconf.loon_rule_base, lLoonBase);\n\n                    if(extconf.surge_ruleset.size())\n                        lCustomRulesets = extconf.surge_ruleset;\n                    if(extconf.custom_proxy_group.size())\n                        lCustomProxyGroups = extconf.custom_proxy_group;\n                    ext.enable_rule_generator = extconf.enable_rule_generator;\n                    ext.overwrite_original_rules = extconf.overwrite_original_rules;\n                }\n            }\n            if(extconf.rename.size())\n                ext.rename_array = extconf.rename;\n            if(extconf.emoji.size())\n                ext.emoji_array = extconf.emoji;\n            if(extconf.include.size())\n                lIncludeRemarks = extconf.include;\n            if(extconf.exclude.size())\n                lExcludeRemarks = extconf.exclude;\n            argAddEmoji.define(extconf.add_emoji);\n            argRemoveEmoji.define(extconf.remove_old_emoji);\n        }\n    }\n    else\n    {\n        if(!lSimpleSubscription)\n        {\n            /// loading custom groups\n            if(argCustomGroups.size() && !ext.nodelist)\n            {\n                string_array vArray = split(argCustomGroups, \"@\");\n                lCustomProxyGroups = INIBinding::from<ProxyGroupConfig>::from_ini(vArray);\n            }\n\n            /// loading custom rulesets\n            if(argCustomRulesets.size() && !ext.nodelist)\n            {\n                string_array vArray = split(argCustomRulesets, \"@\");\n                lCustomRulesets = INIBinding::from<RulesetConfig>::from_ini(vArray);\n            }\n        }\n    }\n    if(ext.enable_rule_generator && !ext.nodelist && !lSimpleSubscription)\n    {\n        if(lCustomRulesets != global.customRulesets)\n            refreshRulesets(lCustomRulesets, lRulesetContent);\n        else\n        {\n            if(global.updateRulesetOnRequest)\n                refreshRulesets(global.customRulesets, global.rulesetsContent);\n            lRulesetContent = global.rulesetsContent;\n        }\n    }\n\n    if(!argEmoji.is_undef())\n    {\n        argAddEmoji.set(argEmoji);\n        argRemoveEmoji.set(true);\n    }\n    ext.add_emoji = argAddEmoji.get(global.addEmoji);\n    ext.remove_emoji = argRemoveEmoji.get(global.removeEmoji);\n    if(ext.add_emoji && ext.emoji_array.empty())\n        ext.emoji_array = safe_get_emojis();\n    if(argRenames.size())\n        ext.rename_array = INIBinding::from<RegexMatchConfig>::from_ini(split(argRenames, \"`\"), \"@\");\n    else if(ext.rename_array.empty())\n        ext.rename_array = safe_get_renames();\n\n    /// check custom include/exclude settings\n    if(argIncludeRemark.size() && regValid(argIncludeRemark))\n        lIncludeRemarks = string_array{argIncludeRemark};\n    if(argExcludeRemark.size() && regValid(argExcludeRemark))\n        lExcludeRemarks = string_array{argExcludeRemark};\n\n    /// initialize script runtime\n    if(authorized && !global.scriptCleanContext)\n    {\n        ext.js_runtime = new qjs::Runtime();\n        script_runtime_init(*ext.js_runtime);\n        ext.js_context = new qjs::Context(*ext.js_runtime);\n        script_context_init(*ext.js_context);\n    }\n\n    //start parsing urls\n    RegexMatchConfigs stream_temp = safe_get_streams(), time_temp = safe_get_times();\n\n    //loading urls\n    string_array urls;\n    std::vector<Proxy> nodes, insert_nodes;\n    int groupID = 0;\n\n    parse_settings parse_set;\n    parse_set.proxy = &proxy;\n    parse_set.exclude_remarks = &lExcludeRemarks;\n    parse_set.include_remarks = &lIncludeRemarks;\n    parse_set.stream_rules = &stream_temp;\n    parse_set.time_rules = &time_temp;\n    parse_set.sub_info = &subInfo;\n    parse_set.authorized = authorized;\n    parse_set.request_header = &request.headers;\n    parse_set.js_runtime = ext.js_runtime;\n    parse_set.js_context = ext.js_context;\n\n    if(global.insertUrls.size() && argEnableInsert)\n    {\n        groupID = -1;\n        urls = split(global.insertUrls, \"|\");\n        importItems(urls, true);\n        for(std::string &x : urls)\n        {\n            x = regTrim(x);\n            writeLog(0, \"Fetching node data from url '\" + x + \"'.\", LOG_LEVEL_INFO);\n            if(addNodes(x, insert_nodes, groupID, parse_set) == -1)\n            {\n                if(global.skipFailedLinks)\n                    writeLog(0, \"The following link doesn't contain any valid node info: \" + x, LOG_LEVEL_WARNING);\n                else\n                {\n                    *status_code = 400;\n                    return \"The following link doesn't contain any valid node info: \" + x;\n                }\n            }\n            groupID--;\n        }\n    }\n    urls = split(argUrl, \"|\");\n    importItems(urls, true);\n    groupID = 0;\n    for(std::string &x : urls)\n    {\n        x = regTrim(x);\n        //std::cerr<<\"Fetching node data from url '\"<<x<<\"'.\"<<std::endl;\n        writeLog(0, \"Fetching node data from url '\" + x + \"'.\", LOG_LEVEL_INFO);\n        if(addNodes(x, nodes, groupID, parse_set) == -1)\n        {\n            if(global.skipFailedLinks)\n                writeLog(0, \"The following link doesn't contain any valid node info: \" + x, LOG_LEVEL_WARNING);\n            else\n            {\n                *status_code = 400;\n                return \"The following link doesn't contain any valid node info: \" + x;\n            }\n        }\n        groupID++;\n    }\n    //exit if found nothing\n    if(!nodes.size() && !insert_nodes.size())\n    {\n        *status_code = 400;\n        return \"No nodes were found!\";\n    }\n    if(subInfo.size() && argAppendUserinfo.get(global.appendUserinfo))\n        response.headers.emplace(\"Subscription-UserInfo\", subInfo);\n\n    if(request.method == \"HEAD\")\n        return \"\";\n\n    argPrependInsert.define(global.prependInsert);\n    if(argPrependInsert)\n    {\n        std::move(nodes.begin(), nodes.end(), std::back_inserter(insert_nodes));\n        nodes.swap(insert_nodes);\n    }\n    else\n    {\n        std::move(insert_nodes.begin(), insert_nodes.end(), std::back_inserter(nodes));\n    }\n    //run filter script\n    std::string filterScript = global.filterScript;\n    if(authorized && !argFilterScript.empty())\n        filterScript = argFilterScript;\n    if(filterScript.size())\n    {\n        if(startsWith(filterScript, \"path:\"))\n            filterScript = fileGet(filterScript.substr(5), false);\n        /*\n        duk_context *ctx = duktape_init();\n        if(ctx)\n        {\n            defer(duk_destroy_heap(ctx);)\n            if(duktape_peval(ctx, filterScript) == 0)\n            {\n                auto filter = [&](const Proxy &x)\n                {\n                    duk_get_global_string(ctx, \"filter\");\n                    duktape_push_Proxy(ctx, x);\n                    duk_pcall(ctx, 1);\n                    return !duktape_get_res_bool(ctx);\n                };\n                nodes.erase(std::remove_if(nodes.begin(), nodes.end(), filter), nodes.end());\n            }\n            else\n            {\n                writeLog(0, \"Error when trying to parse script:\\n\" + duktape_get_err_stack(ctx), LOG_LEVEL_ERROR);\n                duk_pop(ctx); /// pop err\n            }\n        }\n        */\n        script_safe_runner(ext.js_runtime, ext.js_context, [&](qjs::Context &ctx)\n        {\n            try\n            {\n                ctx.eval(filterScript);\n                auto filter = (std::function<bool(const Proxy&)>) ctx.eval(\"filter\");\n                nodes.erase(std::remove_if(nodes.begin(), nodes.end(), filter), nodes.end());\n            }\n            catch(qjs::exception)\n            {\n                script_print_stack(ctx);\n            }\n        }, global.scriptCleanContext);\n    }\n\n    //check custom group name\n    if(argGroupName.size())\n        for(Proxy &x : nodes)\n            x.Group = argGroupName;\n\n    //do pre-process now\n    preprocessNodes(nodes, ext);\n\n    /*\n    //insert node info to template\n    int index = 0;\n    std::string template_node_prefix;\n    for(Proxy &x : nodes)\n    {\n        template_node_prefix = std::to_string(index) + \".\";\n        tpl_args.node_list[template_node_prefix + \"remarks\"] = x.remarks;\n        tpl_args.node_list[template_node_prefix + \"group\"] = x.Group;\n        tpl_args.node_list[template_node_prefix + \"groupid\"] = std::to_string(x.GroupId);\n        index++;\n    }\n    */\n\n    ProxyGroupConfigs dummy_group;\n    std::vector<RulesetContent> dummy_ruleset;\n    std::string managed_url = base64Decode(urlDecode(getUrlArg(argument, \"profile_data\")));\n    if(managed_url.empty())\n        managed_url = global.managedConfigPrefix + \"/sub?\" + argument;\n\n    //std::cerr<<\"Generate target: \";\n    proxy = parseProxy(global.proxyConfig);\n    switch(hash_(argTarget))\n    {\n    case \"clash\"_hash: case \"clashr\"_hash:\n        writeLog(0, argTarget == \"clashr\" ? \"Generate target: ClashR\" : \"Generate target: Clash\", LOG_LEVEL_INFO);\n        tpl_args.local_vars[\"clash.new_field_name\"] = ext.clash_new_field_name ? \"true\" : \"false\";\n        response.headers[\"profile-update-interval\"] = std::to_string(interval / 3600);\n        if(ext.nodelist)\n        {\n            YAML::Node yamlnode;\n            proxyToClash(nodes, yamlnode, dummy_group, argTarget == \"clashr\", ext);\n            output_content = YAML::Dump(yamlnode);\n        }\n        else\n        {\n            if(render_template(fetchFile(lClashBase, proxy, global.cacheConfig), tpl_args, base_content, global.templatePath) != 0)\n            {\n                *status_code = 400;\n                return base_content;\n            }\n            output_content = proxyToClash(nodes, base_content, lRulesetContent, lCustomProxyGroups, argTarget == \"clashr\", ext);\n        }\n\n        if(argUpload)\n            uploadGist(argTarget, argUploadPath, output_content, false);\n        break;\n    case \"surge\"_hash:\n\n        writeLog(0, \"Generate target: Surge \" + std::to_string(intSurgeVer), LOG_LEVEL_INFO);\n\n        if(ext.nodelist)\n        {\n            output_content = proxyToSurge(nodes, base_content, dummy_ruleset, dummy_group, intSurgeVer, ext);\n\n            if(argUpload)\n                uploadGist(\"surge\" + argSurgeVer + \"list\", argUploadPath, output_content, true);\n        }\n        else\n        {\n            if(render_template(fetchFile(lSurgeBase, proxy, global.cacheConfig), tpl_args, base_content, global.templatePath) != 0)\n            {\n                *status_code = 400;\n                return base_content;\n            }\n            output_content = proxyToSurge(nodes, base_content, lRulesetContent, lCustomProxyGroups, intSurgeVer, ext);\n\n            if(argUpload)\n                uploadGist(\"surge\" + argSurgeVer, argUploadPath, output_content, true);\n\n            if(global.writeManagedConfig && global.managedConfigPrefix.size())\n                output_content = \"#!MANAGED-CONFIG \" + managed_url + (interval ? \" interval=\" + std::to_string(interval) : \"\") \\\n                 + \" strict=\" + std::string(strict ? \"true\" : \"false\") + \"\\n\\n\" + output_content;\n        }\n        break;\n    case \"surfboard\"_hash:\n        writeLog(0, \"Generate target: Surfboard\", LOG_LEVEL_INFO);\n\n        if(render_template(fetchFile(lSurfboardBase, proxy, global.cacheConfig), tpl_args, base_content, global.templatePath) != 0)\n        {\n            *status_code = 400;\n            return base_content;\n        }\n        output_content = proxyToSurge(nodes, base_content, lRulesetContent, lCustomProxyGroups, -3, ext);\n        if(argUpload)\n            uploadGist(\"surfboard\", argUploadPath, output_content, true);\n\n        if(global.writeManagedConfig && global.managedConfigPrefix.size())\n            output_content = \"#!MANAGED-CONFIG \" + managed_url + (interval ? \" interval=\" + std::to_string(interval) : \"\") \\\n                 + \" strict=\" + std::string(strict ? \"true\" : \"false\") + \"\\n\\n\" + output_content;\n        break;\n    case \"mellow\"_hash:\n        writeLog(0, \"Generate target: Mellow\", LOG_LEVEL_INFO);\n\n        if(render_template(fetchFile(lMellowBase, proxy, global.cacheConfig), tpl_args, base_content, global.templatePath) != 0)\n        {\n            *status_code = 400;\n            return base_content;\n        }\n        output_content = proxyToMellow(nodes, base_content, lRulesetContent, lCustomProxyGroups, ext);\n\n        if(argUpload)\n            uploadGist(\"mellow\", argUploadPath, output_content, true);\n        break;\n    case \"sssub\"_hash:\n        writeLog(0, \"Generate target: SS Subscription\", LOG_LEVEL_INFO);\n\n        if(render_template(fetchFile(lSSSubBase, proxy, global.cacheConfig), tpl_args, base_content, global.templatePath) != 0)\n        {\n            *status_code = 400;\n            return base_content;\n        }\n        output_content = proxyToSSSub(base_content, nodes, ext);\n        if(argUpload)\n            uploadGist(\"sssub\", argUploadPath, output_content, false);\n        break;\n    case \"ss\"_hash:\n        writeLog(0, \"Generate target: SS\", LOG_LEVEL_INFO);\n        output_content = proxyToSingle(nodes, 1, ext);\n        if(argUpload)\n            uploadGist(\"ss\", argUploadPath, output_content, false);\n        break;\n    case \"ssr\"_hash:\n        writeLog(0, \"Generate target: SSR\", LOG_LEVEL_INFO);\n        output_content = proxyToSingle(nodes, 2, ext);\n        if(argUpload)\n            uploadGist(\"ssr\", argUploadPath, output_content, false);\n        break;\n    case \"v2ray\"_hash:\n        writeLog(0, \"Generate target: v2rayN\", LOG_LEVEL_INFO);\n        output_content = proxyToSingle(nodes, 4, ext);\n        if(argUpload)\n            uploadGist(\"v2ray\", argUploadPath, output_content, false);\n        break;\n    case \"trojan\"_hash:\n        writeLog(0, \"Generate target: Trojan\", LOG_LEVEL_INFO);\n        output_content = proxyToSingle(nodes, 8, ext);\n        if(argUpload)\n            uploadGist(\"trojan\", argUploadPath, output_content, false);\n        break;\n    case \"mixed\"_hash:\n        writeLog(0, \"Generate target: Standard Subscription\", LOG_LEVEL_INFO);\n        output_content = proxyToSingle(nodes, 15, ext);\n        if(argUpload)\n            uploadGist(\"sub\", argUploadPath, output_content, false);\n        break;\n    case \"quan\"_hash:\n        writeLog(0, \"Generate target: Quantumult\", LOG_LEVEL_INFO);\n        if(!ext.nodelist)\n        {\n            if(render_template(fetchFile(lQuanBase, proxy, global.cacheConfig), tpl_args, base_content, global.templatePath) != 0)\n            {\n                *status_code = 400;\n                return base_content;\n            }\n        }\n\n        output_content = proxyToQuan(nodes, base_content, lRulesetContent, lCustomProxyGroups, ext);\n\n        if(argUpload)\n            uploadGist(\"quan\", argUploadPath, output_content, false);\n        break;\n    case \"quanx\"_hash:\n        writeLog(0, \"Generate target: Quantumult X\", LOG_LEVEL_INFO);\n        if(!ext.nodelist)\n        {\n            if(render_template(fetchFile(lQuanXBase, proxy, global.cacheConfig), tpl_args, base_content, global.templatePath) != 0)\n            {\n                *status_code = 400;\n                return base_content;\n            }\n        }\n\n        output_content = proxyToQuanX(nodes, base_content, lRulesetContent, lCustomProxyGroups, ext);\n\n        if(argUpload)\n            uploadGist(\"quanx\", argUploadPath, output_content, false);\n        break;\n    case \"loon\"_hash:\n        writeLog(0, \"Generate target: Loon\", LOG_LEVEL_INFO);\n        if(!ext.nodelist)\n        {\n            if(render_template(fetchFile(lLoonBase, proxy, global.cacheConfig), tpl_args, base_content, global.templatePath) != 0)\n            {\n                *status_code = 400;\n                return base_content;\n            }\n        }\n\n        output_content = proxyToLoon(nodes, base_content, lRulesetContent, lCustomProxyGroups, ext);\n\n        if(argUpload)\n            uploadGist(\"loon\", argUploadPath, output_content, false);\n        break;\n    case \"ssd\"_hash:\n        writeLog(0, \"Generate target: SSD\", LOG_LEVEL_INFO);\n        output_content = proxyToSSD(nodes, argGroupName, subInfo, ext);\n        if(argUpload)\n            uploadGist(\"ssd\", argUploadPath, output_content, false);\n        break;\n    default:\n        writeLog(0, \"Generate target: Unspecified\", LOG_LEVEL_INFO);\n        *status_code = 500;\n        return \"Unrecognized target\";\n    }\n    writeLog(0, \"Generate completed.\", LOG_LEVEL_INFO);\n    if(argFilename.size())\n        response.headers.emplace(\"Content-Disposition\", \"attachment; filename=\\\"\" + argFilename + \"\\\"; filename*=utf-8''\" + urlEncode(argFilename));\n    return output_content;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -96,6 +96,7 @@\n     std::string proxy = parseProxy(global.proxySubscription);\n \n     /// check other flags\n+    ext.authorized = authorized;\n     ext.append_proxy_type = argAppendType.get(global.appendType);\n     if((argTarget == \"clash\" || argTarget == \"clashr\") && argGenClashScript.is_undef())\n         argExpandRulesets.define(true);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    ext.authorized = authorized;"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-28927",
        "func_name": "tindy2013/subconverter/readConf",
        "description": "A remote code execution (RCE) vulnerability in Subconverter v0.7.2 allows attackers to execute arbitrary code via crafted config and url parameters.",
        "git_url": "https://github.com/tindy2013/subconverter/commit/ce8d2bd0f13f05fcbd2ed90755d097f402393dd3",
        "commit_title": "Enhancements",
        "commit_text": " Add authorization check before loading scripts. Add detailed logs when loading preference settings.",
        "func_before": "void readConf()\n{\n    guarded_mutex guard(gMutexConfigure);\n    //std::cerr<<\"Reading preference settings...\"<<std::endl;\n    writeLog(0, \"Reading preference settings...\", LOG_LEVEL_INFO);\n\n    eraseElements(global.excludeRemarks);\n    eraseElements(global.includeRemarks);\n    eraseElements(global.customProxyGroups);\n    eraseElements(global.customRulesets);\n\n    try\n    {\n        std::string prefdata = fileGet(global.prefPath, false);\n        if(prefdata.find(\"common:\") != prefdata.npos)\n        {\n            YAML::Node yaml = YAML::Load(prefdata);\n            if(yaml.size() && yaml[\"common\"])\n                return readYAMLConf(yaml);\n        }\n        toml::value conf = parseToml(prefdata, global.prefPath);\n        if(!conf.is_uninitialized() && toml::find_or<int>(conf, \"version\", 0))\n            return readTOMLConf(conf);\n    }\n    catch (YAML::Exception &e)\n    {\n        //ignore yaml parse error\n    }\n    catch (toml::exception &e)\n    {\n        //ignore toml parse error\n        writeLog(0, e.what(), LOG_LEVEL_DEBUG);\n    }\n\n    INIReader ini;\n    ini.allow_dup_section_titles = true;\n    //ini.do_utf8_to_gbk = true;\n    int retVal = ini.ParseFile(global.prefPath);\n    if(retVal != INIREADER_EXCEPTION_NONE)\n    {\n        //std::cerr<<\"Unable to load preference settings. Reason: \"<<ini.GetLastError()<<\"\\n\";\n        writeLog(0, \"Unable to load preference settings. Reason: \" + ini.GetLastError(), LOG_LEVEL_FATAL);\n        return;\n    }\n\n    string_array tempArray;\n\n    ini.EnterSection(\"common\");\n    ini.GetBoolIfExist(\"api_mode\", global.APIMode);\n    ini.GetIfExist(\"api_access_token\", global.accessToken);\n    ini.GetIfExist(\"default_url\", global.defaultUrls);\n    global.enableInsert = ini.Get(\"enable_insert\");\n    ini.GetIfExist(\"insert_url\", global.insertUrls);\n    ini.GetBoolIfExist(\"prepend_insert_url\", global.prependInsert);\n    if(ini.ItemPrefixExist(\"exclude_remarks\"))\n        ini.GetAll(\"exclude_remarks\", global.excludeRemarks);\n    if(ini.ItemPrefixExist(\"include_remarks\"))\n        ini.GetAll(\"include_remarks\", global.includeRemarks);\n    global.filterScript = ini.GetBool(\"enable_filter\") ? ini.Get(\"filter_script\"): \"\";\n    ini.GetIfExist(\"base_path\", global.basePath);\n    ini.GetIfExist(\"clash_rule_base\", global.clashBase);\n    ini.GetIfExist(\"surge_rule_base\", global.surgeBase);\n    ini.GetIfExist(\"surfboard_rule_base\", global.surfboardBase);\n    ini.GetIfExist(\"mellow_rule_base\", global.mellowBase);\n    ini.GetIfExist(\"quan_rule_base\", global.quanBase);\n    ini.GetIfExist(\"quanx_rule_base\", global.quanXBase);\n    ini.GetIfExist(\"loon_rule_base\", global.loonBase);\n    ini.GetIfExist(\"default_external_config\", global.defaultExtConfig);\n    ini.GetBoolIfExist(\"append_proxy_type\", global.appendType);\n    ini.GetIfExist(\"proxy_config\", global.proxyConfig);\n    ini.GetIfExist(\"proxy_ruleset\", global.proxyRuleset);\n    ini.GetIfExist(\"proxy_subscription\", global.proxySubscription);\n\n    if(ini.SectionExist(\"surge_external_proxy\"))\n    {\n        ini.EnterSection(\"surge_external_proxy\");\n        ini.GetIfExist(\"surge_ssr_path\", global.surgeSSRPath);\n        ini.GetBoolIfExist(\"resolve_hostname\", global.surgeResolveHostname);\n    }\n\n    if(ini.SectionExist(\"node_pref\"))\n    {\n        ini.EnterSection(\"node_pref\");\n        /*\n        ini.GetBoolIfExist(\"udp_flag\", udp_flag);\n        ini.GetBoolIfExist(\"tcp_fast_open_flag\", tfo_flag);\n        ini.GetBoolIfExist(\"skip_cert_verify_flag\", scv_flag);\n        */\n        global.UDPFlag.set(ini.Get(\"udp_flag\"));\n        global.TFOFlag.set(ini.Get(\"tcp_fast_open_flag\"));\n        global.skipCertVerify.set(ini.Get(\"skip_cert_verify_flag\"));\n        global.TLS13Flag.set(ini.Get(\"tls13_flag\"));\n        ini.GetBoolIfExist(\"sort_flag\", global.enableSort);\n        global.sortScript = ini.Get(\"sort_script\");\n        ini.GetBoolIfExist(\"filter_deprecated_nodes\", global.filterDeprecated);\n        ini.GetBoolIfExist(\"append_sub_userinfo\", global.appendUserinfo);\n        ini.GetBoolIfExist(\"clash_use_new_field_name\", global.clashUseNewField);\n        ini.GetIfExist(\"clash_proxies_style\", global.clashProxiesStyle);\n        if(ini.ItemPrefixExist(\"rename_node\"))\n        {\n            ini.GetAll(\"rename_node\", tempArray);\n            importItems(tempArray, false);\n            auto configs = INIBinding::from<RegexMatchConfig>::from_ini(tempArray, \"@\");\n            safe_set_renames(configs);\n            eraseElements(tempArray);\n        }\n    }\n\n    if(ini.SectionExist(\"userinfo\"))\n    {\n        ini.EnterSection(\"userinfo\");\n        if(ini.ItemPrefixExist(\"stream_rule\"))\n        {\n            ini.GetAll(\"stream_rule\", tempArray);\n            importItems(tempArray, false);\n            auto configs = INIBinding::from<RegexMatchConfig>::from_ini(tempArray, \"|\");\n            safe_set_streams(configs);\n            eraseElements(tempArray);\n        }\n        if(ini.ItemPrefixExist(\"time_rule\"))\n        {\n            ini.GetAll(\"time_rule\", tempArray);\n            importItems(tempArray, false);\n            auto configs = INIBinding::from<RegexMatchConfig>::from_ini(tempArray, \"|\");\n            safe_set_times(configs);\n            eraseElements(tempArray);\n        }\n    }\n\n    ini.EnterSection(\"managed_config\");\n    ini.GetBoolIfExist(\"write_managed_config\", global.writeManagedConfig);\n    ini.GetIfExist(\"managed_config_prefix\", global.managedConfigPrefix);\n    ini.GetIntIfExist(\"config_update_interval\", global.updateInterval);\n    ini.GetBoolIfExist(\"config_update_strict\", global.updateStrict);\n    ini.GetIfExist(\"quanx_device_id\", global.quanXDevID);\n\n    ini.EnterSection(\"emojis\");\n    ini.GetBoolIfExist(\"add_emoji\", global.addEmoji);\n    ini.GetBoolIfExist(\"remove_old_emoji\", global.removeEmoji);\n    if(ini.ItemPrefixExist(\"rule\"))\n    {\n        ini.GetAll(\"rule\", tempArray);\n        importItems(tempArray, false);\n        auto configs = INIBinding::from<RegexMatchConfig>::from_ini(tempArray, \",\");\n        safe_set_emojis(configs);\n        eraseElements(tempArray);\n    }\n\n    if(ini.SectionExist(\"rulesets\"))\n        ini.EnterSection(\"rulesets\");\n    else\n        ini.EnterSection(\"ruleset\");\n    global.enableRuleGen = ini.GetBool(\"enabled\");\n    if(global.enableRuleGen)\n    {\n        ini.GetBoolIfExist(\"overwrite_original_rules\", global.overwriteOriginalRules);\n        ini.GetBoolIfExist(\"update_ruleset_on_request\", global.updateRulesetOnRequest);\n        if(ini.ItemPrefixExist(\"ruleset\"))\n        {\n            string_array vArray;\n            ini.GetAll(\"ruleset\", vArray);\n            importItems(vArray, false);\n            global.customRulesets = INIBinding::from<RulesetConfig>::from_ini(vArray);\n        }\n        else if(ini.ItemPrefixExist(\"surge_ruleset\"))\n        {\n            string_array vArray;\n            ini.GetAll(\"surge_ruleset\", vArray);\n            importItems(vArray, false);\n            global.customRulesets = INIBinding::from<RulesetConfig>::from_ini(vArray);\n        }\n    }\n    else\n    {\n        global.overwriteOriginalRules = false;\n        global.updateRulesetOnRequest = false;\n    }\n\n    if(ini.SectionExist(\"proxy_groups\"))\n        ini.EnterSection(\"proxy_groups\");\n    else\n        ini.EnterSection(\"clash_proxy_group\");\n    if(ini.ItemPrefixExist(\"custom_proxy_group\"))\n    {\n        string_array vArray;\n        ini.GetAll(\"custom_proxy_group\", vArray);\n        importItems(vArray, false);\n        global.customProxyGroups = INIBinding::from<ProxyGroupConfig>::from_ini(vArray);\n    }\n\n    ini.EnterSection(\"template\");\n    ini.GetIfExist(\"template_path\", global.templatePath);\n    string_multimap tempmap;\n    ini.GetItems(tempmap);\n    eraseElements(global.templateVars);\n    for(auto &x : tempmap)\n    {\n        if(x.first == \"template_path\")\n            continue;\n        global.templateVars[x.first] = x.second;\n    }\n    global.templateVars[\"managed_config_prefix\"] = global.managedConfigPrefix;\n\n    if(ini.SectionExist(\"aliases\"))\n    {\n        ini.EnterSection(\"aliases\");\n        ini.GetItems(tempmap);\n        webServer.reset_redirect();\n        for(auto &x : tempmap)\n            webServer.append_redirect(x.first, x.second);\n    }\n\n    if(ini.SectionExist(\"tasks\"))\n    {\n        string_array vArray;\n        ini.EnterSection(\"tasks\");\n        ini.GetAll(\"task\", vArray);\n        importItems(vArray, false);\n        global.enableCron = !vArray.empty();\n        global.cronTasks = INIBinding::from<CronTaskConfig>::from_ini(vArray);\n        refresh_schedule();\n    }\n\n    ini.EnterSection(\"server\");\n    ini.GetIfExist(\"listen\", global.listenAddress);\n    ini.GetIntIfExist(\"port\", global.listenPort);\n    webServer.serve_file_root = ini.Get(\"serve_file_root\");\n    webServer.serve_file = !webServer.serve_file_root.empty();\n\n    ini.EnterSection(\"advanced\");\n    std::string log_level;\n    ini.GetIfExist(\"log_level\", log_level);\n    ini.GetBoolIfExist(\"print_debug_info\", global.printDbgInfo);\n    if(global.printDbgInfo)\n        global.logLevel = LOG_LEVEL_VERBOSE;\n    else\n    {\n        switch(hash_(log_level))\n        {\n        case \"warn\"_hash:\n            global.logLevel = LOG_LEVEL_WARNING;\n            break;\n        case \"error\"_hash:\n            global.logLevel = LOG_LEVEL_ERROR;\n            break;\n        case \"fatal\"_hash:\n            global.logLevel = LOG_LEVEL_FATAL;\n            break;\n        case \"verbose\"_hash:\n            global.logLevel = LOG_LEVEL_VERBOSE;\n            break;\n        case \"debug\"_hash:\n            global.logLevel = LOG_LEVEL_DEBUG;\n            break;\n        default:\n            global.logLevel = LOG_LEVEL_INFO;\n        }\n    }\n    ini.GetIntIfExist(\"max_pending_connections\", global.maxPendingConns);\n    ini.GetIntIfExist(\"max_concurrent_threads\", global.maxConcurThreads);\n    ini.GetNumberIfExist(\"max_allowed_rulesets\", global.maxAllowedRulesets);\n    ini.GetNumberIfExist(\"max_allowed_rules\", global.maxAllowedRules);\n    ini.GetNumberIfExist(\"max_allowed_download_size\", global.maxAllowedDownloadSize);\n    if(ini.ItemExist(\"enable_cache\"))\n    {\n        if(ini.GetBool(\"enable_cache\"))\n        {\n            ini.GetIntIfExist(\"cache_subscription\", global.cacheSubscription);\n            ini.GetIntIfExist(\"cache_config\", global.cacheConfig);\n            ini.GetIntIfExist(\"cache_ruleset\", global.cacheRuleset);\n            ini.GetBoolIfExist(\"serve_cache_on_fetch_fail\", global.serveCacheOnFetchFail);\n        }\n        else\n        {\n            global.cacheSubscription = global.cacheConfig = global.cacheRuleset = 0; //disable cache\n            global.serveCacheOnFetchFail = false;\n        }\n    }\n    ini.GetBoolIfExist(\"script_clean_context\", global.scriptCleanContext);\n    ini.GetBoolIfExist(\"async_fetch_ruleset\", global.asyncFetchRuleset);\n    ini.GetBoolIfExist(\"skip_failed_links\", global.skipFailedLinks);\n\n    //std::cerr<<\"Read preference settings completed.\"<<std::endl;\n    writeLog(0, \"Read preference settings completed.\", LOG_LEVEL_INFO);\n}",
        "func": "void readConf()\n{\n    guarded_mutex guard(gMutexConfigure);\n    writeLog(0, \"Loading preference settings...\", LOG_LEVEL_INFO);\n\n    eraseElements(global.excludeRemarks);\n    eraseElements(global.includeRemarks);\n    eraseElements(global.customProxyGroups);\n    eraseElements(global.customRulesets);\n\n    try\n    {\n        std::string prefdata = fileGet(global.prefPath, false);\n        if(prefdata.find(\"common:\") != prefdata.npos)\n        {\n            YAML::Node yaml = YAML::Load(prefdata);\n            if(yaml.size() && yaml[\"common\"])\n                return readYAMLConf(yaml);\n        }\n        toml::value conf = parseToml(prefdata, global.prefPath);\n        if(!conf.is_uninitialized() && toml::find_or<int>(conf, \"version\", 0))\n            return readTOMLConf(conf);\n    }\n    catch (YAML::Exception &e)\n    {\n        //ignore yaml parse error\n        writeLog(0, e.what(), LOG_LEVEL_DEBUG);\n        writeLog(0, \"Unable to load preference settings as YAML.\", LOG_LEVEL_DEBUG);\n    }\n    catch (toml::exception &e)\n    {\n        //ignore toml parse error\n        writeLog(0, e.what(), LOG_LEVEL_DEBUG);\n        writeLog(0, \"Unable to load preference settings as TOML.\", LOG_LEVEL_DEBUG);\n    }\n\n    INIReader ini;\n    ini.allow_dup_section_titles = true;\n    //ini.do_utf8_to_gbk = true;\n    int retVal = ini.ParseFile(global.prefPath);\n    if(retVal != INIREADER_EXCEPTION_NONE)\n    {\n        writeLog(0, \"Unable to load preference settings as INI. Reason: \" + ini.GetLastError(), LOG_LEVEL_FATAL);\n        return;\n    }\n\n    string_array tempArray;\n\n    ini.EnterSection(\"common\");\n    ini.GetBoolIfExist(\"api_mode\", global.APIMode);\n    ini.GetIfExist(\"api_access_token\", global.accessToken);\n    ini.GetIfExist(\"default_url\", global.defaultUrls);\n    global.enableInsert = ini.Get(\"enable_insert\");\n    ini.GetIfExist(\"insert_url\", global.insertUrls);\n    ini.GetBoolIfExist(\"prepend_insert_url\", global.prependInsert);\n    if(ini.ItemPrefixExist(\"exclude_remarks\"))\n        ini.GetAll(\"exclude_remarks\", global.excludeRemarks);\n    if(ini.ItemPrefixExist(\"include_remarks\"))\n        ini.GetAll(\"include_remarks\", global.includeRemarks);\n    global.filterScript = ini.GetBool(\"enable_filter\") ? ini.Get(\"filter_script\"): \"\";\n    ini.GetIfExist(\"base_path\", global.basePath);\n    ini.GetIfExist(\"clash_rule_base\", global.clashBase);\n    ini.GetIfExist(\"surge_rule_base\", global.surgeBase);\n    ini.GetIfExist(\"surfboard_rule_base\", global.surfboardBase);\n    ini.GetIfExist(\"mellow_rule_base\", global.mellowBase);\n    ini.GetIfExist(\"quan_rule_base\", global.quanBase);\n    ini.GetIfExist(\"quanx_rule_base\", global.quanXBase);\n    ini.GetIfExist(\"loon_rule_base\", global.loonBase);\n    ini.GetIfExist(\"default_external_config\", global.defaultExtConfig);\n    ini.GetBoolIfExist(\"append_proxy_type\", global.appendType);\n    ini.GetIfExist(\"proxy_config\", global.proxyConfig);\n    ini.GetIfExist(\"proxy_ruleset\", global.proxyRuleset);\n    ini.GetIfExist(\"proxy_subscription\", global.proxySubscription);\n\n    if(ini.SectionExist(\"surge_external_proxy\"))\n    {\n        ini.EnterSection(\"surge_external_proxy\");\n        ini.GetIfExist(\"surge_ssr_path\", global.surgeSSRPath);\n        ini.GetBoolIfExist(\"resolve_hostname\", global.surgeResolveHostname);\n    }\n\n    if(ini.SectionExist(\"node_pref\"))\n    {\n        ini.EnterSection(\"node_pref\");\n        /*\n        ini.GetBoolIfExist(\"udp_flag\", udp_flag);\n        ini.GetBoolIfExist(\"tcp_fast_open_flag\", tfo_flag);\n        ini.GetBoolIfExist(\"skip_cert_verify_flag\", scv_flag);\n        */\n        global.UDPFlag.set(ini.Get(\"udp_flag\"));\n        global.TFOFlag.set(ini.Get(\"tcp_fast_open_flag\"));\n        global.skipCertVerify.set(ini.Get(\"skip_cert_verify_flag\"));\n        global.TLS13Flag.set(ini.Get(\"tls13_flag\"));\n        ini.GetBoolIfExist(\"sort_flag\", global.enableSort);\n        global.sortScript = ini.Get(\"sort_script\");\n        ini.GetBoolIfExist(\"filter_deprecated_nodes\", global.filterDeprecated);\n        ini.GetBoolIfExist(\"append_sub_userinfo\", global.appendUserinfo);\n        ini.GetBoolIfExist(\"clash_use_new_field_name\", global.clashUseNewField);\n        ini.GetIfExist(\"clash_proxies_style\", global.clashProxiesStyle);\n        if(ini.ItemPrefixExist(\"rename_node\"))\n        {\n            ini.GetAll(\"rename_node\", tempArray);\n            importItems(tempArray, false);\n            auto configs = INIBinding::from<RegexMatchConfig>::from_ini(tempArray, \"@\");\n            safe_set_renames(configs);\n            eraseElements(tempArray);\n        }\n    }\n\n    if(ini.SectionExist(\"userinfo\"))\n    {\n        ini.EnterSection(\"userinfo\");\n        if(ini.ItemPrefixExist(\"stream_rule\"))\n        {\n            ini.GetAll(\"stream_rule\", tempArray);\n            importItems(tempArray, false);\n            auto configs = INIBinding::from<RegexMatchConfig>::from_ini(tempArray, \"|\");\n            safe_set_streams(configs);\n            eraseElements(tempArray);\n        }\n        if(ini.ItemPrefixExist(\"time_rule\"))\n        {\n            ini.GetAll(\"time_rule\", tempArray);\n            importItems(tempArray, false);\n            auto configs = INIBinding::from<RegexMatchConfig>::from_ini(tempArray, \"|\");\n            safe_set_times(configs);\n            eraseElements(tempArray);\n        }\n    }\n\n    ini.EnterSection(\"managed_config\");\n    ini.GetBoolIfExist(\"write_managed_config\", global.writeManagedConfig);\n    ini.GetIfExist(\"managed_config_prefix\", global.managedConfigPrefix);\n    ini.GetIntIfExist(\"config_update_interval\", global.updateInterval);\n    ini.GetBoolIfExist(\"config_update_strict\", global.updateStrict);\n    ini.GetIfExist(\"quanx_device_id\", global.quanXDevID);\n\n    ini.EnterSection(\"emojis\");\n    ini.GetBoolIfExist(\"add_emoji\", global.addEmoji);\n    ini.GetBoolIfExist(\"remove_old_emoji\", global.removeEmoji);\n    if(ini.ItemPrefixExist(\"rule\"))\n    {\n        ini.GetAll(\"rule\", tempArray);\n        importItems(tempArray, false);\n        auto configs = INIBinding::from<RegexMatchConfig>::from_ini(tempArray, \",\");\n        safe_set_emojis(configs);\n        eraseElements(tempArray);\n    }\n\n    if(ini.SectionExist(\"rulesets\"))\n        ini.EnterSection(\"rulesets\");\n    else\n        ini.EnterSection(\"ruleset\");\n    global.enableRuleGen = ini.GetBool(\"enabled\");\n    if(global.enableRuleGen)\n    {\n        ini.GetBoolIfExist(\"overwrite_original_rules\", global.overwriteOriginalRules);\n        ini.GetBoolIfExist(\"update_ruleset_on_request\", global.updateRulesetOnRequest);\n        if(ini.ItemPrefixExist(\"ruleset\"))\n        {\n            string_array vArray;\n            ini.GetAll(\"ruleset\", vArray);\n            importItems(vArray, false);\n            global.customRulesets = INIBinding::from<RulesetConfig>::from_ini(vArray);\n        }\n        else if(ini.ItemPrefixExist(\"surge_ruleset\"))\n        {\n            string_array vArray;\n            ini.GetAll(\"surge_ruleset\", vArray);\n            importItems(vArray, false);\n            global.customRulesets = INIBinding::from<RulesetConfig>::from_ini(vArray);\n        }\n    }\n    else\n    {\n        global.overwriteOriginalRules = false;\n        global.updateRulesetOnRequest = false;\n    }\n\n    if(ini.SectionExist(\"proxy_groups\"))\n        ini.EnterSection(\"proxy_groups\");\n    else\n        ini.EnterSection(\"clash_proxy_group\");\n    if(ini.ItemPrefixExist(\"custom_proxy_group\"))\n    {\n        string_array vArray;\n        ini.GetAll(\"custom_proxy_group\", vArray);\n        importItems(vArray, false);\n        global.customProxyGroups = INIBinding::from<ProxyGroupConfig>::from_ini(vArray);\n    }\n\n    ini.EnterSection(\"template\");\n    ini.GetIfExist(\"template_path\", global.templatePath);\n    string_multimap tempmap;\n    ini.GetItems(tempmap);\n    eraseElements(global.templateVars);\n    for(auto &x : tempmap)\n    {\n        if(x.first == \"template_path\")\n            continue;\n        global.templateVars[x.first] = x.second;\n    }\n    global.templateVars[\"managed_config_prefix\"] = global.managedConfigPrefix;\n\n    if(ini.SectionExist(\"aliases\"))\n    {\n        ini.EnterSection(\"aliases\");\n        ini.GetItems(tempmap);\n        webServer.reset_redirect();\n        for(auto &x : tempmap)\n            webServer.append_redirect(x.first, x.second);\n    }\n\n    if(ini.SectionExist(\"tasks\"))\n    {\n        string_array vArray;\n        ini.EnterSection(\"tasks\");\n        ini.GetAll(\"task\", vArray);\n        importItems(vArray, false);\n        global.enableCron = !vArray.empty();\n        global.cronTasks = INIBinding::from<CronTaskConfig>::from_ini(vArray);\n        refresh_schedule();\n    }\n\n    ini.EnterSection(\"server\");\n    ini.GetIfExist(\"listen\", global.listenAddress);\n    ini.GetIntIfExist(\"port\", global.listenPort);\n    webServer.serve_file_root = ini.Get(\"serve_file_root\");\n    webServer.serve_file = !webServer.serve_file_root.empty();\n\n    ini.EnterSection(\"advanced\");\n    std::string log_level;\n    ini.GetIfExist(\"log_level\", log_level);\n    ini.GetBoolIfExist(\"print_debug_info\", global.printDbgInfo);\n    if(global.printDbgInfo)\n        global.logLevel = LOG_LEVEL_VERBOSE;\n    else\n    {\n        switch(hash_(log_level))\n        {\n        case \"warn\"_hash:\n            global.logLevel = LOG_LEVEL_WARNING;\n            break;\n        case \"error\"_hash:\n            global.logLevel = LOG_LEVEL_ERROR;\n            break;\n        case \"fatal\"_hash:\n            global.logLevel = LOG_LEVEL_FATAL;\n            break;\n        case \"verbose\"_hash:\n            global.logLevel = LOG_LEVEL_VERBOSE;\n            break;\n        case \"debug\"_hash:\n            global.logLevel = LOG_LEVEL_DEBUG;\n            break;\n        default:\n            global.logLevel = LOG_LEVEL_INFO;\n        }\n    }\n    ini.GetIntIfExist(\"max_pending_connections\", global.maxPendingConns);\n    ini.GetIntIfExist(\"max_concurrent_threads\", global.maxConcurThreads);\n    ini.GetNumberIfExist(\"max_allowed_rulesets\", global.maxAllowedRulesets);\n    ini.GetNumberIfExist(\"max_allowed_rules\", global.maxAllowedRules);\n    ini.GetNumberIfExist(\"max_allowed_download_size\", global.maxAllowedDownloadSize);\n    if(ini.ItemExist(\"enable_cache\"))\n    {\n        if(ini.GetBool(\"enable_cache\"))\n        {\n            ini.GetIntIfExist(\"cache_subscription\", global.cacheSubscription);\n            ini.GetIntIfExist(\"cache_config\", global.cacheConfig);\n            ini.GetIntIfExist(\"cache_ruleset\", global.cacheRuleset);\n            ini.GetBoolIfExist(\"serve_cache_on_fetch_fail\", global.serveCacheOnFetchFail);\n        }\n        else\n        {\n            global.cacheSubscription = global.cacheConfig = global.cacheRuleset = 0; //disable cache\n            global.serveCacheOnFetchFail = false;\n        }\n    }\n    ini.GetBoolIfExist(\"script_clean_context\", global.scriptCleanContext);\n    ini.GetBoolIfExist(\"async_fetch_ruleset\", global.asyncFetchRuleset);\n    ini.GetBoolIfExist(\"skip_failed_links\", global.skipFailedLinks);\n\n    writeLog(0, \"Load preference settings in INI format completed.\", LOG_LEVEL_INFO);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,8 +1,7 @@\n void readConf()\n {\n     guarded_mutex guard(gMutexConfigure);\n-    //std::cerr<<\"Reading preference settings...\"<<std::endl;\n-    writeLog(0, \"Reading preference settings...\", LOG_LEVEL_INFO);\n+    writeLog(0, \"Loading preference settings...\", LOG_LEVEL_INFO);\n \n     eraseElements(global.excludeRemarks);\n     eraseElements(global.includeRemarks);\n@@ -25,11 +24,14 @@\n     catch (YAML::Exception &e)\n     {\n         //ignore yaml parse error\n+        writeLog(0, e.what(), LOG_LEVEL_DEBUG);\n+        writeLog(0, \"Unable to load preference settings as YAML.\", LOG_LEVEL_DEBUG);\n     }\n     catch (toml::exception &e)\n     {\n         //ignore toml parse error\n         writeLog(0, e.what(), LOG_LEVEL_DEBUG);\n+        writeLog(0, \"Unable to load preference settings as TOML.\", LOG_LEVEL_DEBUG);\n     }\n \n     INIReader ini;\n@@ -38,8 +40,7 @@\n     int retVal = ini.ParseFile(global.prefPath);\n     if(retVal != INIREADER_EXCEPTION_NONE)\n     {\n-        //std::cerr<<\"Unable to load preference settings. Reason: \"<<ini.GetLastError()<<\"\\n\";\n-        writeLog(0, \"Unable to load preference settings. Reason: \" + ini.GetLastError(), LOG_LEVEL_FATAL);\n+        writeLog(0, \"Unable to load preference settings as INI. Reason: \" + ini.GetLastError(), LOG_LEVEL_FATAL);\n         return;\n     }\n \n@@ -280,6 +281,5 @@\n     ini.GetBoolIfExist(\"async_fetch_ruleset\", global.asyncFetchRuleset);\n     ini.GetBoolIfExist(\"skip_failed_links\", global.skipFailedLinks);\n \n-    //std::cerr<<\"Read preference settings completed.\"<<std::endl;\n-    writeLog(0, \"Read preference settings completed.\", LOG_LEVEL_INFO);\n+    writeLog(0, \"Load preference settings in INI format completed.\", LOG_LEVEL_INFO);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    //std::cerr<<\"Reading preference settings...\"<<std::endl;",
                "    writeLog(0, \"Reading preference settings...\", LOG_LEVEL_INFO);",
                "        //std::cerr<<\"Unable to load preference settings. Reason: \"<<ini.GetLastError()<<\"\\n\";",
                "        writeLog(0, \"Unable to load preference settings. Reason: \" + ini.GetLastError(), LOG_LEVEL_FATAL);",
                "    //std::cerr<<\"Read preference settings completed.\"<<std::endl;",
                "    writeLog(0, \"Read preference settings completed.\", LOG_LEVEL_INFO);"
            ],
            "added_lines": [
                "    writeLog(0, \"Loading preference settings...\", LOG_LEVEL_INFO);",
                "        writeLog(0, e.what(), LOG_LEVEL_DEBUG);",
                "        writeLog(0, \"Unable to load preference settings as YAML.\", LOG_LEVEL_DEBUG);",
                "        writeLog(0, \"Unable to load preference settings as TOML.\", LOG_LEVEL_DEBUG);",
                "        writeLog(0, \"Unable to load preference settings as INI. Reason: \" + ini.GetLastError(), LOG_LEVEL_FATAL);",
                "    writeLog(0, \"Load preference settings in INI format completed.\", LOG_LEVEL_INFO);"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-28927",
        "func_name": "tindy2013/subconverter/readTOMLConf",
        "description": "A remote code execution (RCE) vulnerability in Subconverter v0.7.2 allows attackers to execute arbitrary code via crafted config and url parameters.",
        "git_url": "https://github.com/tindy2013/subconverter/commit/ce8d2bd0f13f05fcbd2ed90755d097f402393dd3",
        "commit_title": "Enhancements",
        "commit_text": " Add authorization check before loading scripts. Add detailed logs when loading preference settings.",
        "func_before": "void readTOMLConf(toml::value &root)\n{\n    const auto &section_common = toml::find(root, \"common\");\n    string_array default_url, insert_url;\n\n    find_if_exist(section_common, \"default_url\", default_url, \"insert_url\", insert_url);\n    global.defaultUrls = join(default_url, \"|\");\n    global.insertUrls = join(insert_url, \"|\");\n\n    bool filter = false;\n    find_if_exist(section_common,\n                  \"api_mode\", global.APIMode,\n                  \"api_access_token\", global.accessToken,\n                  \"exclude_remarks\", global.excludeRemarks,\n                  \"include_remarks\", global.includeRemarks,\n                  \"enable_insert\", global.enableInsert,\n                  \"prepend_insert_url\", global.prependInsert,\n                  \"enable_filter\", filter,\n                  \"default_external_config\", global.defaultExtConfig,\n                  \"base_path\", global.basePath,\n                  \"clash_rule_base\", global.clashBase,\n                  \"surge_rule_base\", global.surgeBase,\n                  \"surfboard_rule_base\", global.surfboardBase,\n                  \"mellow_rule_base\", global.mellowBase,\n                  \"quan_rule_base\", global.quanBase,\n                  \"quanx_rule_base\", global.quanXBase,\n                  \"loon_rule_base\", global.loonBase,\n                  \"proxy_config\", global.proxyConfig,\n                  \"proxy_ruleset\", global.proxyRuleset,\n                  \"proxy_subscription\", global.proxySubscription,\n                  \"append_proxy_type\", global.appendType\n    );\n\n    if(filter)\n        find_if_exist(section_common, \"filter_script\", global.filterScript);\n    else\n        global.filterScript.clear();\n\n    safe_set_streams(toml::find_or<RegexMatchConfigs>(root, \"userinfo\", \"stream_rule\", RegexMatchConfigs{}));\n    safe_set_times(toml::find_or<RegexMatchConfigs>(root, \"userinfo\", \"time_rule\", RegexMatchConfigs{}));\n\n    const auto &section_node_pref = toml::find(root, \"node_pref\");\n\n    find_if_exist(section_node_pref,\n                  \"udp_flag\", global.UDPFlag,\n                  \"tcp_fast_open_flag\", global.TFOFlag,\n                  \"skip_cert_verify_flag\", global.skipCertVerify,\n                  \"tls13_flag\", global.TLS13Flag,\n                  \"sort_flag\", global.enableSort,\n                  \"sort_script\", global.sortScript,\n                  \"filter_deprecated_nodes\", global.filterDeprecated,\n                  \"append_sub_userinfo\", global.appendUserinfo,\n                  \"clash_use_new_field_name\", global.clashUseNewField,\n                  \"clash_proxies_style\", global.clashProxiesStyle\n    );\n\n    auto renameconfs = toml::find_or<std::vector<toml::value>>(section_node_pref, \"rename_node\", {});\n    importItems(renameconfs, \"rename_node\", false);\n    safe_set_renames(toml::get<RegexMatchConfigs>(toml::value(renameconfs)));\n\n    const auto &section_managed = toml::find(root, \"managed_config\");\n\n    find_if_exist(section_managed,\n                  \"write_managed_config\", global.writeManagedConfig,\n                  \"managed_config_prefix\", global.managedConfigPrefix,\n                  \"config_update_interval\", global.updateInterval,\n                  \"config_update_strict\", global.updateStrict,\n                  \"quanx_device_id\", global.quanXDevID\n    );\n\n    const auto &section_surge_external = toml::find(root, \"surge_external_proxy\");\n    find_if_exist(section_surge_external,\n                  \"surge_ssr_path\", global.surgeSSRPath,\n                  \"resolve_hostname\", global.surgeResolveHostname\n    );\n\n    const auto &section_emojis = toml::find(root, \"emojis\");\n\n    find_if_exist(section_emojis,\n                  \"add_emoji\", global.addEmoji,\n                  \"remove_old_emoji\", global.removeEmoji\n    );\n\n    auto emojiconfs = toml::find_or<std::vector<toml::value>>(section_emojis, \"emoji\", {});\n    importItems(emojiconfs, \"emoji\", false);\n    safe_set_emojis(toml::get<RegexMatchConfigs>(toml::value(emojiconfs)));\n\n    auto groups = toml::find_or<std::vector<toml::value>>(root, \"custom_groups\", {});\n    importItems(groups, \"custom_groups\", false);\n    global.customProxyGroups = toml::get<ProxyGroupConfigs>(toml::value(groups));\n\n    const auto &section_ruleset = toml::find(root, \"ruleset\");\n\n    find_if_exist(section_ruleset,\n                  \"enabled\", global.enableRuleGen,\n                  \"overwrite_original_rules\", global.overwriteOriginalRules,\n                  \"update_ruleset_on_request\", global.updateRulesetOnRequest\n    );\n\n    auto rulesets = toml::find_or<std::vector<toml::value>>(root, \"rulesets\", {});\n    importItems(rulesets, \"rulesets\", false);\n    global.customRulesets = toml::get<RulesetConfigs>(toml::value(rulesets));\n\n    const auto &section_template = toml::find(root, \"template\");\n\n    global.templatePath = toml::find_or(section_template, \"template_path\", \"template\");\n\n    eraseElements(global.templateVars);\n    operate_toml_kv_table(toml::find_or<std::vector<toml::table>>(section_template, \"globals\", {}), \"key\", \"value\", [&](const toml::value &key, const toml::value &value)\n    {\n        global.templateVars[key.as_string()] = value.as_string();\n    });\n\n    webServer.reset_redirect();\n    operate_toml_kv_table(toml::find_or<std::vector<toml::table>>(root, \"aliases\", {}), \"uri\", \"target\", [&](const toml::value &key, const toml::value &value)\n    {\n        webServer.append_redirect(key.as_string(), value.as_string());\n    });\n\n    auto tasks = toml::find_or<std::vector<toml::value>>(root, \"tasks\", {});\n    importItems(tasks, \"tasks\", false);\n    global.cronTasks = toml::get<CronTaskConfigs>(toml::value(tasks));\n\n    const auto &section_server = toml::find(root, \"server\");\n\n    find_if_exist(section_server,\n                  \"listen\", global.listenAddress,\n                  \"port\", global.listenPort,\n                  \"serve_file_root\", webServer.serve_file_root\n    );\n    webServer.serve_file = !webServer.serve_file_root.empty();\n\n    const auto &section_advanced = toml::find(root, \"advanced\");\n\n    std::string log_level;\n    bool enable_cache = true;\n    int cache_subscription = global.cacheSubscription, cache_config = global.cacheConfig, cache_ruleset = global.cacheRuleset;\n\n    find_if_exist(section_advanced,\n                  \"log_level\", log_level,\n                  \"print_debug_info\", global.printDbgInfo,\n                  \"max_pending_connections\", global.maxPendingConns,\n                  \"max_concurrent_threads\", global.maxConcurThreads,\n                  \"max_allowed_rulesets\", global.maxAllowedRulesets,\n                  \"max_allowed_rules\", global.maxAllowedRules,\n                  \"max_allowed_download_size\", global.maxAllowedDownloadSize,\n                  \"enable_cache\", enable_cache,\n                  \"cache_subscription\", cache_subscription,\n                  \"cache_config\", cache_config,\n                  \"cache_ruleset\", cache_ruleset,\n                  \"script_clean_context\", global.scriptCleanContext,\n                  \"async_fetch_ruleset\", global.asyncFetchRuleset,\n                  \"skip_failed_links\", global.skipFailedLinks\n    );\n\n    if(global.printDbgInfo)\n        global.logLevel = LOG_LEVEL_VERBOSE;\n    else\n    {\n        switch(hash_(log_level))\n        {\n        case \"warn\"_hash:\n            global.logLevel = LOG_LEVEL_WARNING;\n            break;\n        case \"error\"_hash:\n            global.logLevel = LOG_LEVEL_ERROR;\n            break;\n        case \"fatal\"_hash:\n            global.logLevel = LOG_LEVEL_FATAL;\n            break;\n        case \"verbose\"_hash:\n            global.logLevel = LOG_LEVEL_VERBOSE;\n            break;\n        case \"debug\"_hash:\n            global.logLevel = LOG_LEVEL_DEBUG;\n            break;\n        default:\n            global.logLevel = LOG_LEVEL_INFO;\n        }\n    }\n\n    if(enable_cache)\n    {\n        global.cacheSubscription = cache_subscription;\n        global.cacheConfig = cache_config;\n        global.cacheRuleset = cache_ruleset;\n    }\n    else\n    {\n        global.cacheSubscription = global.cacheConfig = global.cacheRuleset = 0;\n    }\n}",
        "func": "void readTOMLConf(toml::value &root)\n{\n    const auto &section_common = toml::find(root, \"common\");\n    string_array default_url, insert_url;\n\n    find_if_exist(section_common, \"default_url\", default_url, \"insert_url\", insert_url);\n    global.defaultUrls = join(default_url, \"|\");\n    global.insertUrls = join(insert_url, \"|\");\n\n    bool filter = false;\n    find_if_exist(section_common,\n                  \"api_mode\", global.APIMode,\n                  \"api_access_token\", global.accessToken,\n                  \"exclude_remarks\", global.excludeRemarks,\n                  \"include_remarks\", global.includeRemarks,\n                  \"enable_insert\", global.enableInsert,\n                  \"prepend_insert_url\", global.prependInsert,\n                  \"enable_filter\", filter,\n                  \"default_external_config\", global.defaultExtConfig,\n                  \"base_path\", global.basePath,\n                  \"clash_rule_base\", global.clashBase,\n                  \"surge_rule_base\", global.surgeBase,\n                  \"surfboard_rule_base\", global.surfboardBase,\n                  \"mellow_rule_base\", global.mellowBase,\n                  \"quan_rule_base\", global.quanBase,\n                  \"quanx_rule_base\", global.quanXBase,\n                  \"loon_rule_base\", global.loonBase,\n                  \"proxy_config\", global.proxyConfig,\n                  \"proxy_ruleset\", global.proxyRuleset,\n                  \"proxy_subscription\", global.proxySubscription,\n                  \"append_proxy_type\", global.appendType\n    );\n\n    if(filter)\n        find_if_exist(section_common, \"filter_script\", global.filterScript);\n    else\n        global.filterScript.clear();\n\n    safe_set_streams(toml::find_or<RegexMatchConfigs>(root, \"userinfo\", \"stream_rule\", RegexMatchConfigs{}));\n    safe_set_times(toml::find_or<RegexMatchConfigs>(root, \"userinfo\", \"time_rule\", RegexMatchConfigs{}));\n\n    const auto &section_node_pref = toml::find(root, \"node_pref\");\n\n    find_if_exist(section_node_pref,\n                  \"udp_flag\", global.UDPFlag,\n                  \"tcp_fast_open_flag\", global.TFOFlag,\n                  \"skip_cert_verify_flag\", global.skipCertVerify,\n                  \"tls13_flag\", global.TLS13Flag,\n                  \"sort_flag\", global.enableSort,\n                  \"sort_script\", global.sortScript,\n                  \"filter_deprecated_nodes\", global.filterDeprecated,\n                  \"append_sub_userinfo\", global.appendUserinfo,\n                  \"clash_use_new_field_name\", global.clashUseNewField,\n                  \"clash_proxies_style\", global.clashProxiesStyle\n    );\n\n    auto renameconfs = toml::find_or<std::vector<toml::value>>(section_node_pref, \"rename_node\", {});\n    importItems(renameconfs, \"rename_node\", false);\n    safe_set_renames(toml::get<RegexMatchConfigs>(toml::value(renameconfs)));\n\n    const auto &section_managed = toml::find(root, \"managed_config\");\n\n    find_if_exist(section_managed,\n                  \"write_managed_config\", global.writeManagedConfig,\n                  \"managed_config_prefix\", global.managedConfigPrefix,\n                  \"config_update_interval\", global.updateInterval,\n                  \"config_update_strict\", global.updateStrict,\n                  \"quanx_device_id\", global.quanXDevID\n    );\n\n    const auto &section_surge_external = toml::find(root, \"surge_external_proxy\");\n    find_if_exist(section_surge_external,\n                  \"surge_ssr_path\", global.surgeSSRPath,\n                  \"resolve_hostname\", global.surgeResolveHostname\n    );\n\n    const auto &section_emojis = toml::find(root, \"emojis\");\n\n    find_if_exist(section_emojis,\n                  \"add_emoji\", global.addEmoji,\n                  \"remove_old_emoji\", global.removeEmoji\n    );\n\n    auto emojiconfs = toml::find_or<std::vector<toml::value>>(section_emojis, \"emoji\", {});\n    importItems(emojiconfs, \"emoji\", false);\n    safe_set_emojis(toml::get<RegexMatchConfigs>(toml::value(emojiconfs)));\n\n    auto groups = toml::find_or<std::vector<toml::value>>(root, \"custom_groups\", {});\n    importItems(groups, \"custom_groups\", false);\n    global.customProxyGroups = toml::get<ProxyGroupConfigs>(toml::value(groups));\n\n    const auto &section_ruleset = toml::find(root, \"ruleset\");\n\n    find_if_exist(section_ruleset,\n                  \"enabled\", global.enableRuleGen,\n                  \"overwrite_original_rules\", global.overwriteOriginalRules,\n                  \"update_ruleset_on_request\", global.updateRulesetOnRequest\n    );\n\n    auto rulesets = toml::find_or<std::vector<toml::value>>(root, \"rulesets\", {});\n    importItems(rulesets, \"rulesets\", false);\n    global.customRulesets = toml::get<RulesetConfigs>(toml::value(rulesets));\n\n    const auto &section_template = toml::find(root, \"template\");\n\n    global.templatePath = toml::find_or(section_template, \"template_path\", \"template\");\n\n    eraseElements(global.templateVars);\n    operate_toml_kv_table(toml::find_or<std::vector<toml::table>>(section_template, \"globals\", {}), \"key\", \"value\", [&](const toml::value &key, const toml::value &value)\n    {\n        global.templateVars[key.as_string()] = value.as_string();\n    });\n\n    webServer.reset_redirect();\n    operate_toml_kv_table(toml::find_or<std::vector<toml::table>>(root, \"aliases\", {}), \"uri\", \"target\", [&](const toml::value &key, const toml::value &value)\n    {\n        webServer.append_redirect(key.as_string(), value.as_string());\n    });\n\n    auto tasks = toml::find_or<std::vector<toml::value>>(root, \"tasks\", {});\n    importItems(tasks, \"tasks\", false);\n    global.cronTasks = toml::get<CronTaskConfigs>(toml::value(tasks));\n\n    const auto &section_server = toml::find(root, \"server\");\n\n    find_if_exist(section_server,\n                  \"listen\", global.listenAddress,\n                  \"port\", global.listenPort,\n                  \"serve_file_root\", webServer.serve_file_root\n    );\n    webServer.serve_file = !webServer.serve_file_root.empty();\n\n    const auto &section_advanced = toml::find(root, \"advanced\");\n\n    std::string log_level;\n    bool enable_cache = true;\n    int cache_subscription = global.cacheSubscription, cache_config = global.cacheConfig, cache_ruleset = global.cacheRuleset;\n\n    find_if_exist(section_advanced,\n                  \"log_level\", log_level,\n                  \"print_debug_info\", global.printDbgInfo,\n                  \"max_pending_connections\", global.maxPendingConns,\n                  \"max_concurrent_threads\", global.maxConcurThreads,\n                  \"max_allowed_rulesets\", global.maxAllowedRulesets,\n                  \"max_allowed_rules\", global.maxAllowedRules,\n                  \"max_allowed_download_size\", global.maxAllowedDownloadSize,\n                  \"enable_cache\", enable_cache,\n                  \"cache_subscription\", cache_subscription,\n                  \"cache_config\", cache_config,\n                  \"cache_ruleset\", cache_ruleset,\n                  \"script_clean_context\", global.scriptCleanContext,\n                  \"async_fetch_ruleset\", global.asyncFetchRuleset,\n                  \"skip_failed_links\", global.skipFailedLinks\n    );\n\n    if(global.printDbgInfo)\n        global.logLevel = LOG_LEVEL_VERBOSE;\n    else\n    {\n        switch(hash_(log_level))\n        {\n        case \"warn\"_hash:\n            global.logLevel = LOG_LEVEL_WARNING;\n            break;\n        case \"error\"_hash:\n            global.logLevel = LOG_LEVEL_ERROR;\n            break;\n        case \"fatal\"_hash:\n            global.logLevel = LOG_LEVEL_FATAL;\n            break;\n        case \"verbose\"_hash:\n            global.logLevel = LOG_LEVEL_VERBOSE;\n            break;\n        case \"debug\"_hash:\n            global.logLevel = LOG_LEVEL_DEBUG;\n            break;\n        default:\n            global.logLevel = LOG_LEVEL_INFO;\n        }\n    }\n\n    if(enable_cache)\n    {\n        global.cacheSubscription = cache_subscription;\n        global.cacheConfig = cache_config;\n        global.cacheRuleset = cache_ruleset;\n    }\n    else\n    {\n        global.cacheSubscription = global.cacheConfig = global.cacheRuleset = 0;\n    }\n\n    writeLog(0, \"Load preference settings in TOML format completed.\", LOG_LEVEL_INFO);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -189,4 +189,6 @@\n     {\n         global.cacheSubscription = global.cacheConfig = global.cacheRuleset = 0;\n     }\n+\n+    writeLog(0, \"Load preference settings in TOML format completed.\", LOG_LEVEL_INFO);\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "    writeLog(0, \"Load preference settings in TOML format completed.\", LOG_LEVEL_INFO);"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-28927",
        "func_name": "tindy2013/subconverter/readYAMLConf",
        "description": "A remote code execution (RCE) vulnerability in Subconverter v0.7.2 allows attackers to execute arbitrary code via crafted config and url parameters.",
        "git_url": "https://github.com/tindy2013/subconverter/commit/ce8d2bd0f13f05fcbd2ed90755d097f402393dd3",
        "commit_title": "Enhancements",
        "commit_text": " Add authorization check before loading scripts. Add detailed logs when loading preference settings.",
        "func_before": "void readYAMLConf(YAML::Node &node)\n{\n    YAML::Node section = node[\"common\"];\n    std::string strLine;\n    string_array tempArray;\n\n    section[\"api_mode\"] >> global.APIMode;\n    section[\"api_access_token\"] >> global.accessToken;\n    if(section[\"default_url\"].IsSequence())\n    {\n        section[\"default_url\"] >> tempArray;\n        if(tempArray.size())\n        {\n            strLine = std::accumulate(std::next(tempArray.begin()), tempArray.end(), tempArray[0], [](std::string a, std::string b)\n            {\n                return std::move(a) + \"|\" + std::move(b);\n            });\n            global.defaultUrls = strLine;\n            eraseElements(tempArray);\n        }\n    }\n    global.enableInsert = safe_as<std::string>(section[\"enable_insert\"]);\n    if(section[\"insert_url\"].IsSequence())\n    {\n        section[\"insert_url\"] >> tempArray;\n        if(tempArray.size())\n        {\n            strLine = std::accumulate(std::next(tempArray.begin()), tempArray.end(), tempArray[0], [](std::string a, std::string b)\n            {\n                return std::move(a) + \"|\" + std::move(b);\n            });\n            global.insertUrls = strLine;\n            eraseElements(tempArray);\n        }\n    }\n    section[\"prepend_insert_url\"] >> global.prependInsert;\n    if(section[\"exclude_remarks\"].IsSequence())\n        section[\"exclude_remarks\"] >> global.excludeRemarks;\n    if(section[\"include_remarks\"].IsSequence())\n        section[\"include_remarks\"] >> global.includeRemarks;\n    global.filterScript = safe_as<bool>(section[\"enable_filter\"]) ? safe_as<std::string>(section[\"filter_script\"]) : \"\";\n    section[\"base_path\"] >> global.basePath;\n    section[\"clash_rule_base\"] >> global.clashBase;\n    section[\"surge_rule_base\"] >> global.surgeBase;\n    section[\"surfboard_rule_base\"] >> global.surfboardBase;\n    section[\"mellow_rule_base\"] >> global.mellowBase;\n    section[\"quan_rule_base\"] >> global.quanBase;\n    section[\"quanx_rule_base\"] >> global.quanXBase;\n    section[\"loon_rule_base\"] >> global.loonBase;\n    section[\"sssub_rule_base\"] >> global.SSSubBase;\n\n    section[\"default_external_config\"] >> global.defaultExtConfig;\n    section[\"append_proxy_type\"] >> global.appendType;\n    section[\"proxy_config\"] >> global.proxyConfig;\n    section[\"proxy_ruleset\"] >> global.proxyRuleset;\n    section[\"proxy_subscription\"] >> global.proxySubscription;\n\n    if(node[\"userinfo\"].IsDefined())\n    {\n        section = node[\"userinfo\"];\n        if(section[\"stream_rule\"].IsSequence())\n        {\n            readRegexMatch(section[\"stream_rule\"], \"|\", tempArray, false);\n            auto configs = INIBinding::from<RegexMatchConfig>::from_ini(tempArray, \"|\");\n            safe_set_streams(configs);\n            eraseElements(tempArray);\n        }\n        if(section[\"time_rule\"].IsSequence())\n        {\n            readRegexMatch(section[\"time_rule\"], \"|\", tempArray, false);\n            auto configs = INIBinding::from<RegexMatchConfig>::from_ini(tempArray, \"|\");\n            safe_set_times(configs);\n            eraseElements(tempArray);\n        }\n    }\n\n    if(node[\"node_pref\"].IsDefined())\n    {\n        section = node[\"node_pref\"];\n        /*\n        section[\"udp_flag\"] >> udp_flag;\n        section[\"tcp_fast_open_flag\"] >> tfo_flag;\n        section[\"skip_cert_verify_flag\"] >> scv_flag;\n        */\n        global.UDPFlag.set(safe_as<std::string>(section[\"udp_flag\"]));\n        global.TFOFlag.set(safe_as<std::string>(section[\"tcp_fast_open_flag\"]));\n        global.skipCertVerify.set(safe_as<std::string>(section[\"skip_cert_verify_flag\"]));\n        global.TLS13Flag.set(safe_as<std::string>(section[\"tls13_flag\"]));\n        section[\"sort_flag\"] >> global.enableSort;\n        section[\"sort_script\"] >> global.sortScript;\n        section[\"filter_deprecated_nodes\"] >> global.filterDeprecated;\n        section[\"append_sub_userinfo\"] >> global.appendUserinfo;\n        section[\"clash_use_new_field_name\"] >> global.clashUseNewField;\n        section[\"clash_proxies_style\"] >> global.clashProxiesStyle;\n    }\n\n    if(section[\"rename_node\"].IsSequence())\n    {\n        readRegexMatch(section[\"rename_node\"], \"@\", tempArray, false);\n        auto configs = INIBinding::from<RegexMatchConfig>::from_ini(tempArray, \"@\");\n        safe_set_renames(configs);\n        eraseElements(tempArray);\n    }\n\n    if(node[\"managed_config\"].IsDefined())\n    {\n        section = node[\"managed_config\"];\n        section[\"write_managed_config\"] >> global.writeManagedConfig;\n        section[\"managed_config_prefix\"] >> global.managedConfigPrefix;\n        section[\"config_update_interval\"] >> global.updateInterval;\n        section[\"config_update_strict\"] >> global.updateStrict;\n        section[\"quanx_device_id\"] >> global.quanXDevID;\n    }\n\n    if(node[\"surge_external_proxy\"].IsDefined())\n    {\n        node[\"surge_external_proxy\"][\"surge_ssr_path\"] >> global.surgeSSRPath;\n        node[\"surge_external_proxy\"][\"resolve_hostname\"] >> global.surgeResolveHostname;\n    }\n\n    if(node[\"emojis\"].IsDefined())\n    {\n        section = node[\"emojis\"];\n        section[\"add_emoji\"] >> global.addEmoji;\n        section[\"remove_old_emoji\"] >> global.removeEmoji;\n        if(section[\"rules\"].IsSequence())\n        {\n            readEmoji(section[\"rules\"], tempArray, false);\n            auto configs = INIBinding::from<RegexMatchConfig>::from_ini(tempArray, \",\");\n            safe_set_emojis(configs);\n            eraseElements(tempArray);\n        }\n    }\n\n    const char *rulesets_title = node[\"rulesets\"].IsDefined() ? \"rulesets\" : \"ruleset\";\n    if(node[rulesets_title].IsDefined())\n    {\n        section = node[rulesets_title];\n        section[\"enabled\"] >> global.enableRuleGen;\n        if(!global.enableRuleGen)\n        {\n            global.overwriteOriginalRules = false;\n            global.updateRulesetOnRequest = false;\n        }\n        else\n        {\n            section[\"overwrite_original_rules\"] >> global.overwriteOriginalRules;\n            section[\"update_ruleset_on_request\"] >> global.updateRulesetOnRequest;\n        }\n        const char *ruleset_title = section[\"rulesets\"].IsDefined() ? \"rulesets\" : \"surge_ruleset\";\n        if(section[ruleset_title].IsSequence())\n        {\n            string_array vArray;\n            readRuleset(section[ruleset_title], vArray, false);\n            global.customRulesets = INIBinding::from<RulesetConfig>::from_ini(vArray);\n        }\n    }\n\n    const char *groups_title = node[\"proxy_groups\"].IsDefined() ? \"proxy_groups\" : \"proxy_group\";\n    if(node[groups_title].IsDefined() && node[groups_title][\"custom_proxy_group\"].IsDefined())\n    {\n        string_array vArray;\n        readGroup(node[groups_title][\"custom_proxy_group\"], vArray, false);\n        global.customProxyGroups = INIBinding::from<ProxyGroupConfig>::from_ini(vArray);\n    }\n\n    if(node[\"template\"].IsDefined())\n    {\n        node[\"template\"][\"template_path\"] >> global.templatePath;\n        if(node[\"template\"][\"globals\"].IsSequence())\n        {\n            eraseElements(global.templateVars);\n            for(size_t i = 0; i < node[\"template\"][\"globals\"].size(); i++)\n            {\n                std::string key, value;\n                node[\"template\"][\"globals\"][i][\"key\"] >> key;\n                node[\"template\"][\"globals\"][i][\"value\"] >> value;\n                global.templateVars[key] = value;\n            }\n        }\n    }\n\n    if(node[\"aliases\"].IsSequence())\n    {\n        webServer.reset_redirect();\n        for(size_t i = 0; i < node[\"aliases\"].size(); i++)\n        {\n            std::string uri, target;\n            node[\"aliases\"][i][\"uri\"] >> uri;\n            node[\"aliases\"][i][\"target\"] >> target;\n            webServer.append_redirect(uri, target);\n        }\n    }\n\n    if(node[\"tasks\"].IsSequence())\n    {\n        string_array vArray;\n        for(size_t i = 0; i < node[\"tasks\"].size(); i++)\n        {\n            std::string name, exp, path, timeout;\n            node[\"tasks\"][i][\"import\"] >> name;\n            if(name.size())\n            {\n                vArray.emplace_back(\"!!import:\" + name);\n                continue;\n            }\n            node[\"tasks\"][i][\"name\"] >> name;\n            node[\"tasks\"][i][\"cronexp\"] >> exp;\n            node[\"tasks\"][i][\"path\"] >> path;\n            node[\"tasks\"][i][\"timeout\"] >> timeout;\n            strLine = name + \"`\" + exp + \"`\" + path + \"`\" + timeout;\n            vArray.emplace_back(std::move(strLine));\n        }\n        importItems(vArray, false);\n        global.enableCron = !vArray.empty();\n        global.cronTasks = INIBinding::from<CronTaskConfig>::from_ini(vArray);\n        refresh_schedule();\n    }\n\n    if(node[\"server\"].IsDefined())\n    {\n        node[\"server\"][\"listen\"] >> global.listenAddress;\n        node[\"server\"][\"port\"] >> global.listenPort;\n        node[\"server\"][\"serve_file_root\"] >>= webServer.serve_file_root;\n        webServer.serve_file = !webServer.serve_file_root.empty();\n    }\n\n    if(node[\"advanced\"].IsDefined())\n    {\n        std::string log_level;\n        node[\"advanced\"][\"log_level\"] >> log_level;\n        node[\"advanced\"][\"print_debug_info\"] >> global.printDbgInfo;\n        if(global.printDbgInfo)\n            global.logLevel = LOG_LEVEL_VERBOSE;\n        else\n        {\n            switch(hash_(log_level))\n            {\n            case \"warn\"_hash:\n                global.logLevel = LOG_LEVEL_WARNING;\n                break;\n            case \"error\"_hash:\n                global.logLevel = LOG_LEVEL_ERROR;\n                break;\n            case \"fatal\"_hash:\n                global.logLevel = LOG_LEVEL_FATAL;\n                break;\n            case \"verbose\"_hash:\n                global.logLevel = LOG_LEVEL_VERBOSE;\n                break;\n            case \"debug\"_hash:\n                global.logLevel = LOG_LEVEL_DEBUG;\n                break;\n            default:\n                global.logLevel = LOG_LEVEL_INFO;\n            }\n        }\n        node[\"advanced\"][\"max_pending_connections\"] >> global.maxPendingConns;\n        node[\"advanced\"][\"max_concurrent_threads\"] >> global.maxConcurThreads;\n        node[\"advanced\"][\"max_allowed_rulesets\"] >> global.maxAllowedRulesets;\n        node[\"advanced\"][\"max_allowed_rules\"] >> global.maxAllowedRules;\n        node[\"advanced\"][\"max_allowed_download_size\"] >> global.maxAllowedDownloadSize;\n        if(node[\"advanced\"][\"enable_cache\"].IsDefined())\n        {\n            if(safe_as<bool>(node[\"advanced\"][\"enable_cache\"]))\n            {\n                node[\"advanced\"][\"cache_subscription\"] >> global.cacheSubscription;\n                node[\"advanced\"][\"cache_config\"] >> global.cacheConfig;\n                node[\"advanced\"][\"cache_ruleset\"] >> global.cacheRuleset;\n                node[\"advanced\"][\"serve_cache_on_fetch_fail\"] >> global.serveCacheOnFetchFail;\n            }\n            else\n                global.cacheSubscription = global.cacheConfig = global.cacheRuleset = 0; //disable cache\n        }\n        node[\"advanced\"][\"script_clean_context\"] >> global.scriptCleanContext;\n        node[\"advanced\"][\"async_fetch_ruleset\"] >> global.asyncFetchRuleset;\n        node[\"advanced\"][\"skip_failed_links\"] >> global.skipFailedLinks;\n    }\n}",
        "func": "void readYAMLConf(YAML::Node &node)\n{\n    YAML::Node section = node[\"common\"];\n    std::string strLine;\n    string_array tempArray;\n\n    section[\"api_mode\"] >> global.APIMode;\n    section[\"api_access_token\"] >> global.accessToken;\n    if(section[\"default_url\"].IsSequence())\n    {\n        section[\"default_url\"] >> tempArray;\n        if(tempArray.size())\n        {\n            strLine = std::accumulate(std::next(tempArray.begin()), tempArray.end(), tempArray[0], [](std::string a, std::string b)\n            {\n                return std::move(a) + \"|\" + std::move(b);\n            });\n            global.defaultUrls = strLine;\n            eraseElements(tempArray);\n        }\n    }\n    global.enableInsert = safe_as<std::string>(section[\"enable_insert\"]);\n    if(section[\"insert_url\"].IsSequence())\n    {\n        section[\"insert_url\"] >> tempArray;\n        if(tempArray.size())\n        {\n            strLine = std::accumulate(std::next(tempArray.begin()), tempArray.end(), tempArray[0], [](std::string a, std::string b)\n            {\n                return std::move(a) + \"|\" + std::move(b);\n            });\n            global.insertUrls = strLine;\n            eraseElements(tempArray);\n        }\n    }\n    section[\"prepend_insert_url\"] >> global.prependInsert;\n    if(section[\"exclude_remarks\"].IsSequence())\n        section[\"exclude_remarks\"] >> global.excludeRemarks;\n    if(section[\"include_remarks\"].IsSequence())\n        section[\"include_remarks\"] >> global.includeRemarks;\n    global.filterScript = safe_as<bool>(section[\"enable_filter\"]) ? safe_as<std::string>(section[\"filter_script\"]) : \"\";\n    section[\"base_path\"] >> global.basePath;\n    section[\"clash_rule_base\"] >> global.clashBase;\n    section[\"surge_rule_base\"] >> global.surgeBase;\n    section[\"surfboard_rule_base\"] >> global.surfboardBase;\n    section[\"mellow_rule_base\"] >> global.mellowBase;\n    section[\"quan_rule_base\"] >> global.quanBase;\n    section[\"quanx_rule_base\"] >> global.quanXBase;\n    section[\"loon_rule_base\"] >> global.loonBase;\n    section[\"sssub_rule_base\"] >> global.SSSubBase;\n\n    section[\"default_external_config\"] >> global.defaultExtConfig;\n    section[\"append_proxy_type\"] >> global.appendType;\n    section[\"proxy_config\"] >> global.proxyConfig;\n    section[\"proxy_ruleset\"] >> global.proxyRuleset;\n    section[\"proxy_subscription\"] >> global.proxySubscription;\n\n    if(node[\"userinfo\"].IsDefined())\n    {\n        section = node[\"userinfo\"];\n        if(section[\"stream_rule\"].IsSequence())\n        {\n            readRegexMatch(section[\"stream_rule\"], \"|\", tempArray, false);\n            auto configs = INIBinding::from<RegexMatchConfig>::from_ini(tempArray, \"|\");\n            safe_set_streams(configs);\n            eraseElements(tempArray);\n        }\n        if(section[\"time_rule\"].IsSequence())\n        {\n            readRegexMatch(section[\"time_rule\"], \"|\", tempArray, false);\n            auto configs = INIBinding::from<RegexMatchConfig>::from_ini(tempArray, \"|\");\n            safe_set_times(configs);\n            eraseElements(tempArray);\n        }\n    }\n\n    if(node[\"node_pref\"].IsDefined())\n    {\n        section = node[\"node_pref\"];\n        /*\n        section[\"udp_flag\"] >> udp_flag;\n        section[\"tcp_fast_open_flag\"] >> tfo_flag;\n        section[\"skip_cert_verify_flag\"] >> scv_flag;\n        */\n        global.UDPFlag.set(safe_as<std::string>(section[\"udp_flag\"]));\n        global.TFOFlag.set(safe_as<std::string>(section[\"tcp_fast_open_flag\"]));\n        global.skipCertVerify.set(safe_as<std::string>(section[\"skip_cert_verify_flag\"]));\n        global.TLS13Flag.set(safe_as<std::string>(section[\"tls13_flag\"]));\n        section[\"sort_flag\"] >> global.enableSort;\n        section[\"sort_script\"] >> global.sortScript;\n        section[\"filter_deprecated_nodes\"] >> global.filterDeprecated;\n        section[\"append_sub_userinfo\"] >> global.appendUserinfo;\n        section[\"clash_use_new_field_name\"] >> global.clashUseNewField;\n        section[\"clash_proxies_style\"] >> global.clashProxiesStyle;\n    }\n\n    if(section[\"rename_node\"].IsSequence())\n    {\n        readRegexMatch(section[\"rename_node\"], \"@\", tempArray, false);\n        auto configs = INIBinding::from<RegexMatchConfig>::from_ini(tempArray, \"@\");\n        safe_set_renames(configs);\n        eraseElements(tempArray);\n    }\n\n    if(node[\"managed_config\"].IsDefined())\n    {\n        section = node[\"managed_config\"];\n        section[\"write_managed_config\"] >> global.writeManagedConfig;\n        section[\"managed_config_prefix\"] >> global.managedConfigPrefix;\n        section[\"config_update_interval\"] >> global.updateInterval;\n        section[\"config_update_strict\"] >> global.updateStrict;\n        section[\"quanx_device_id\"] >> global.quanXDevID;\n    }\n\n    if(node[\"surge_external_proxy\"].IsDefined())\n    {\n        node[\"surge_external_proxy\"][\"surge_ssr_path\"] >> global.surgeSSRPath;\n        node[\"surge_external_proxy\"][\"resolve_hostname\"] >> global.surgeResolveHostname;\n    }\n\n    if(node[\"emojis\"].IsDefined())\n    {\n        section = node[\"emojis\"];\n        section[\"add_emoji\"] >> global.addEmoji;\n        section[\"remove_old_emoji\"] >> global.removeEmoji;\n        if(section[\"rules\"].IsSequence())\n        {\n            readEmoji(section[\"rules\"], tempArray, false);\n            auto configs = INIBinding::from<RegexMatchConfig>::from_ini(tempArray, \",\");\n            safe_set_emojis(configs);\n            eraseElements(tempArray);\n        }\n    }\n\n    const char *rulesets_title = node[\"rulesets\"].IsDefined() ? \"rulesets\" : \"ruleset\";\n    if(node[rulesets_title].IsDefined())\n    {\n        section = node[rulesets_title];\n        section[\"enabled\"] >> global.enableRuleGen;\n        if(!global.enableRuleGen)\n        {\n            global.overwriteOriginalRules = false;\n            global.updateRulesetOnRequest = false;\n        }\n        else\n        {\n            section[\"overwrite_original_rules\"] >> global.overwriteOriginalRules;\n            section[\"update_ruleset_on_request\"] >> global.updateRulesetOnRequest;\n        }\n        const char *ruleset_title = section[\"rulesets\"].IsDefined() ? \"rulesets\" : \"surge_ruleset\";\n        if(section[ruleset_title].IsSequence())\n        {\n            string_array vArray;\n            readRuleset(section[ruleset_title], vArray, false);\n            global.customRulesets = INIBinding::from<RulesetConfig>::from_ini(vArray);\n        }\n    }\n\n    const char *groups_title = node[\"proxy_groups\"].IsDefined() ? \"proxy_groups\" : \"proxy_group\";\n    if(node[groups_title].IsDefined() && node[groups_title][\"custom_proxy_group\"].IsDefined())\n    {\n        string_array vArray;\n        readGroup(node[groups_title][\"custom_proxy_group\"], vArray, false);\n        global.customProxyGroups = INIBinding::from<ProxyGroupConfig>::from_ini(vArray);\n    }\n\n    if(node[\"template\"].IsDefined())\n    {\n        node[\"template\"][\"template_path\"] >> global.templatePath;\n        if(node[\"template\"][\"globals\"].IsSequence())\n        {\n            eraseElements(global.templateVars);\n            for(size_t i = 0; i < node[\"template\"][\"globals\"].size(); i++)\n            {\n                std::string key, value;\n                node[\"template\"][\"globals\"][i][\"key\"] >> key;\n                node[\"template\"][\"globals\"][i][\"value\"] >> value;\n                global.templateVars[key] = value;\n            }\n        }\n    }\n\n    if(node[\"aliases\"].IsSequence())\n    {\n        webServer.reset_redirect();\n        for(size_t i = 0; i < node[\"aliases\"].size(); i++)\n        {\n            std::string uri, target;\n            node[\"aliases\"][i][\"uri\"] >> uri;\n            node[\"aliases\"][i][\"target\"] >> target;\n            webServer.append_redirect(uri, target);\n        }\n    }\n\n    if(node[\"tasks\"].IsSequence())\n    {\n        string_array vArray;\n        for(size_t i = 0; i < node[\"tasks\"].size(); i++)\n        {\n            std::string name, exp, path, timeout;\n            node[\"tasks\"][i][\"import\"] >> name;\n            if(name.size())\n            {\n                vArray.emplace_back(\"!!import:\" + name);\n                continue;\n            }\n            node[\"tasks\"][i][\"name\"] >> name;\n            node[\"tasks\"][i][\"cronexp\"] >> exp;\n            node[\"tasks\"][i][\"path\"] >> path;\n            node[\"tasks\"][i][\"timeout\"] >> timeout;\n            strLine = name + \"`\" + exp + \"`\" + path + \"`\" + timeout;\n            vArray.emplace_back(std::move(strLine));\n        }\n        importItems(vArray, false);\n        global.enableCron = !vArray.empty();\n        global.cronTasks = INIBinding::from<CronTaskConfig>::from_ini(vArray);\n        refresh_schedule();\n    }\n\n    if(node[\"server\"].IsDefined())\n    {\n        node[\"server\"][\"listen\"] >> global.listenAddress;\n        node[\"server\"][\"port\"] >> global.listenPort;\n        node[\"server\"][\"serve_file_root\"] >>= webServer.serve_file_root;\n        webServer.serve_file = !webServer.serve_file_root.empty();\n    }\n\n    if(node[\"advanced\"].IsDefined())\n    {\n        std::string log_level;\n        node[\"advanced\"][\"log_level\"] >> log_level;\n        node[\"advanced\"][\"print_debug_info\"] >> global.printDbgInfo;\n        if(global.printDbgInfo)\n            global.logLevel = LOG_LEVEL_VERBOSE;\n        else\n        {\n            switch(hash_(log_level))\n            {\n            case \"warn\"_hash:\n                global.logLevel = LOG_LEVEL_WARNING;\n                break;\n            case \"error\"_hash:\n                global.logLevel = LOG_LEVEL_ERROR;\n                break;\n            case \"fatal\"_hash:\n                global.logLevel = LOG_LEVEL_FATAL;\n                break;\n            case \"verbose\"_hash:\n                global.logLevel = LOG_LEVEL_VERBOSE;\n                break;\n            case \"debug\"_hash:\n                global.logLevel = LOG_LEVEL_DEBUG;\n                break;\n            default:\n                global.logLevel = LOG_LEVEL_INFO;\n            }\n        }\n        node[\"advanced\"][\"max_pending_connections\"] >> global.maxPendingConns;\n        node[\"advanced\"][\"max_concurrent_threads\"] >> global.maxConcurThreads;\n        node[\"advanced\"][\"max_allowed_rulesets\"] >> global.maxAllowedRulesets;\n        node[\"advanced\"][\"max_allowed_rules\"] >> global.maxAllowedRules;\n        node[\"advanced\"][\"max_allowed_download_size\"] >> global.maxAllowedDownloadSize;\n        if(node[\"advanced\"][\"enable_cache\"].IsDefined())\n        {\n            if(safe_as<bool>(node[\"advanced\"][\"enable_cache\"]))\n            {\n                node[\"advanced\"][\"cache_subscription\"] >> global.cacheSubscription;\n                node[\"advanced\"][\"cache_config\"] >> global.cacheConfig;\n                node[\"advanced\"][\"cache_ruleset\"] >> global.cacheRuleset;\n                node[\"advanced\"][\"serve_cache_on_fetch_fail\"] >> global.serveCacheOnFetchFail;\n            }\n            else\n                global.cacheSubscription = global.cacheConfig = global.cacheRuleset = 0; //disable cache\n        }\n        node[\"advanced\"][\"script_clean_context\"] >> global.scriptCleanContext;\n        node[\"advanced\"][\"async_fetch_ruleset\"] >> global.asyncFetchRuleset;\n        node[\"advanced\"][\"skip_failed_links\"] >> global.skipFailedLinks;\n    }\n    writeLog(0, \"Load preference settings in YAML format completed.\", LOG_LEVEL_INFO);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -276,4 +276,5 @@\n         node[\"advanced\"][\"async_fetch_ruleset\"] >> global.asyncFetchRuleset;\n         node[\"advanced\"][\"skip_failed_links\"] >> global.skipFailedLinks;\n     }\n+    writeLog(0, \"Load preference settings in YAML format completed.\", LOG_LEVEL_INFO);\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    writeLog(0, \"Load preference settings in YAML format completed.\", LOG_LEVEL_INFO);"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-19925",
        "func_name": "sqlite/zipfileUpdate",
        "description": "zipfileUpdate in ext/misc/zipfile.c in SQLite 3.30.1 mishandles a NULL pathname during an update of a ZIP archive.",
        "git_url": "https://github.com/sqlite/sqlite/commit/54d501092d88c0cf89bec4279951f548fb0b8618",
        "commit_title": "Fix the zipfile extension so that INSERT works even if the pathname of",
        "commit_text": "the file being inserted is a NULL.  Bug discovered by the Yongheng and Rui fuzzer.  FossilOrigin-Name: a80f84b511231204658304226de3e075a55afc2e3f39ac063716f7a57f585c06",
        "func_before": "static int zipfileUpdate(\n  sqlite3_vtab *pVtab, \n  int nVal, \n  sqlite3_value **apVal, \n  sqlite_int64 *pRowid\n){\n  ZipfileTab *pTab = (ZipfileTab*)pVtab;\n  int rc = SQLITE_OK;             /* Return Code */\n  ZipfileEntry *pNew = 0;         /* New in-memory CDS entry */\n\n  u32 mode = 0;                   /* Mode for new entry */\n  u32 mTime = 0;                  /* Modification time for new entry */\n  i64 sz = 0;                     /* Uncompressed size */\n  const char *zPath = 0;          /* Path for new entry */\n  int nPath = 0;                  /* strlen(zPath) */\n  const u8 *pData = 0;            /* Pointer to buffer containing content */\n  int nData = 0;                  /* Size of pData buffer in bytes */\n  int iMethod = 0;                /* Compression method for new entry */\n  u8 *pFree = 0;                  /* Free this */\n  char *zFree = 0;                /* Also free this */\n  ZipfileEntry *pOld = 0;\n  ZipfileEntry *pOld2 = 0;\n  int bUpdate = 0;                /* True for an update that modifies \"name\" */\n  int bIsDir = 0;\n  u32 iCrc32 = 0;\n\n  if( pTab->pWriteFd==0 ){\n    rc = zipfileBegin(pVtab);\n    if( rc!=SQLITE_OK ) return rc;\n  }\n\n  /* If this is a DELETE or UPDATE, find the archive entry to delete. */\n  if( sqlite3_value_type(apVal[0])!=SQLITE_NULL ){\n    const char *zDelete = (const char*)sqlite3_value_text(apVal[0]);\n    int nDelete = (int)strlen(zDelete);\n    if( nVal>1 ){\n      const char *zUpdate = (const char*)sqlite3_value_text(apVal[1]);\n      if( zUpdate && zipfileComparePath(zUpdate, zDelete, nDelete)!=0 ){\n        bUpdate = 1;\n      }\n    }\n    for(pOld=pTab->pFirstEntry; 1; pOld=pOld->pNext){\n      if( zipfileComparePath(pOld->cds.zFile, zDelete, nDelete)==0 ){\n        break;\n      }\n      assert( pOld->pNext );\n    }\n  }\n\n  if( nVal>1 ){\n    /* Check that \"sz\" and \"rawdata\" are both NULL: */\n    if( sqlite3_value_type(apVal[5])!=SQLITE_NULL ){\n      zipfileTableErr(pTab, \"sz must be NULL\");\n      rc = SQLITE_CONSTRAINT;\n    }\n    if( sqlite3_value_type(apVal[6])!=SQLITE_NULL ){\n      zipfileTableErr(pTab, \"rawdata must be NULL\"); \n      rc = SQLITE_CONSTRAINT;\n    }\n\n    if( rc==SQLITE_OK ){\n      if( sqlite3_value_type(apVal[7])==SQLITE_NULL ){\n        /* data=NULL. A directory */\n        bIsDir = 1;\n      }else{\n        /* Value specified for \"data\", and possibly \"method\". This must be\n        ** a regular file or a symlink. */\n        const u8 *aIn = sqlite3_value_blob(apVal[7]);\n        int nIn = sqlite3_value_bytes(apVal[7]);\n        int bAuto = sqlite3_value_type(apVal[8])==SQLITE_NULL;\n\n        iMethod = sqlite3_value_int(apVal[8]);\n        sz = nIn;\n        pData = aIn;\n        nData = nIn;\n        if( iMethod!=0 && iMethod!=8 ){\n          zipfileTableErr(pTab, \"unknown compression method: %d\", iMethod);\n          rc = SQLITE_CONSTRAINT;\n        }else{\n          if( bAuto || iMethod ){\n            int nCmp;\n            rc = zipfileDeflate(aIn, nIn, &pFree, &nCmp, &pTab->base.zErrMsg);\n            if( rc==SQLITE_OK ){\n              if( iMethod || nCmp<nIn ){\n                iMethod = 8;\n                pData = pFree;\n                nData = nCmp;\n              }\n            }\n          }\n          iCrc32 = crc32(0, aIn, nIn);\n        }\n      }\n    }\n\n    if( rc==SQLITE_OK ){\n      rc = zipfileGetMode(apVal[3], bIsDir, &mode, &pTab->base.zErrMsg);\n    }\n\n    if( rc==SQLITE_OK ){\n      zPath = (const char*)sqlite3_value_text(apVal[2]);\n      nPath = (int)strlen(zPath);\n      mTime = zipfileGetTime(apVal[4]);\n    }\n\n    if( rc==SQLITE_OK && bIsDir ){\n      /* For a directory, check that the last character in the path is a\n      ** '/'. This appears to be required for compatibility with info-zip\n      ** (the unzip command on unix). It does not create directories\n      ** otherwise.  */\n      if( zPath[nPath-1]!='/' ){\n        zFree = sqlite3_mprintf(\"%s/\", zPath);\n        if( zFree==0 ){ rc = SQLITE_NOMEM; }\n        zPath = (const char*)zFree;\n        nPath++;\n      }\n    }\n\n    /* Check that we're not inserting a duplicate entry -OR- updating an\n    ** entry with a path, thereby making it into a duplicate. */\n    if( (pOld==0 || bUpdate) && rc==SQLITE_OK ){\n      ZipfileEntry *p;\n      for(p=pTab->pFirstEntry; p; p=p->pNext){\n        if( zipfileComparePath(p->cds.zFile, zPath, nPath)==0 ){\n          switch( sqlite3_vtab_on_conflict(pTab->db) ){\n            case SQLITE_IGNORE: {\n              goto zipfile_update_done;\n            }\n            case SQLITE_REPLACE: {\n              pOld2 = p;\n              break;\n            }\n            default: {\n              zipfileTableErr(pTab, \"duplicate name: \\\"%s\\\"\", zPath);\n              rc = SQLITE_CONSTRAINT;\n              break;\n            }\n          }\n          break;\n        }\n      }\n    }\n\n    if( rc==SQLITE_OK ){\n      /* Create the new CDS record. */\n      pNew = zipfileNewEntry(zPath);\n      if( pNew==0 ){\n        rc = SQLITE_NOMEM;\n      }else{\n        pNew->cds.iVersionMadeBy = ZIPFILE_NEWENTRY_MADEBY;\n        pNew->cds.iVersionExtract = ZIPFILE_NEWENTRY_REQUIRED;\n        pNew->cds.flags = ZIPFILE_NEWENTRY_FLAGS;\n        pNew->cds.iCompression = (u16)iMethod;\n        zipfileMtimeToDos(&pNew->cds, mTime);\n        pNew->cds.crc32 = iCrc32;\n        pNew->cds.szCompressed = nData;\n        pNew->cds.szUncompressed = (u32)sz;\n        pNew->cds.iExternalAttr = (mode<<16);\n        pNew->cds.iOffset = (u32)pTab->szCurrent;\n        pNew->cds.nFile = (u16)nPath;\n        pNew->mUnixTime = (u32)mTime;\n        rc = zipfileAppendEntry(pTab, pNew, pData, nData);\n        zipfileAddEntry(pTab, pOld, pNew);\n      }\n    }\n  }\n\n  if( rc==SQLITE_OK && (pOld || pOld2) ){\n    ZipfileCsr *pCsr;\n    for(pCsr=pTab->pCsrList; pCsr; pCsr=pCsr->pCsrNext){\n      if( pCsr->pCurrent && (pCsr->pCurrent==pOld || pCsr->pCurrent==pOld2) ){\n        pCsr->pCurrent = pCsr->pCurrent->pNext;\n        pCsr->bNoop = 1;\n      }\n    }\n\n    zipfileRemoveEntryFromList(pTab, pOld);\n    zipfileRemoveEntryFromList(pTab, pOld2);\n  }\n\nzipfile_update_done:\n  sqlite3_free(pFree);\n  sqlite3_free(zFree);\n  return rc;\n}",
        "func": "static int zipfileUpdate(\n  sqlite3_vtab *pVtab, \n  int nVal, \n  sqlite3_value **apVal, \n  sqlite_int64 *pRowid\n){\n  ZipfileTab *pTab = (ZipfileTab*)pVtab;\n  int rc = SQLITE_OK;             /* Return Code */\n  ZipfileEntry *pNew = 0;         /* New in-memory CDS entry */\n\n  u32 mode = 0;                   /* Mode for new entry */\n  u32 mTime = 0;                  /* Modification time for new entry */\n  i64 sz = 0;                     /* Uncompressed size */\n  const char *zPath = 0;          /* Path for new entry */\n  int nPath = 0;                  /* strlen(zPath) */\n  const u8 *pData = 0;            /* Pointer to buffer containing content */\n  int nData = 0;                  /* Size of pData buffer in bytes */\n  int iMethod = 0;                /* Compression method for new entry */\n  u8 *pFree = 0;                  /* Free this */\n  char *zFree = 0;                /* Also free this */\n  ZipfileEntry *pOld = 0;\n  ZipfileEntry *pOld2 = 0;\n  int bUpdate = 0;                /* True for an update that modifies \"name\" */\n  int bIsDir = 0;\n  u32 iCrc32 = 0;\n\n  if( pTab->pWriteFd==0 ){\n    rc = zipfileBegin(pVtab);\n    if( rc!=SQLITE_OK ) return rc;\n  }\n\n  /* If this is a DELETE or UPDATE, find the archive entry to delete. */\n  if( sqlite3_value_type(apVal[0])!=SQLITE_NULL ){\n    const char *zDelete = (const char*)sqlite3_value_text(apVal[0]);\n    int nDelete = (int)strlen(zDelete);\n    if( nVal>1 ){\n      const char *zUpdate = (const char*)sqlite3_value_text(apVal[1]);\n      if( zUpdate && zipfileComparePath(zUpdate, zDelete, nDelete)!=0 ){\n        bUpdate = 1;\n      }\n    }\n    for(pOld=pTab->pFirstEntry; 1; pOld=pOld->pNext){\n      if( zipfileComparePath(pOld->cds.zFile, zDelete, nDelete)==0 ){\n        break;\n      }\n      assert( pOld->pNext );\n    }\n  }\n\n  if( nVal>1 ){\n    /* Check that \"sz\" and \"rawdata\" are both NULL: */\n    if( sqlite3_value_type(apVal[5])!=SQLITE_NULL ){\n      zipfileTableErr(pTab, \"sz must be NULL\");\n      rc = SQLITE_CONSTRAINT;\n    }\n    if( sqlite3_value_type(apVal[6])!=SQLITE_NULL ){\n      zipfileTableErr(pTab, \"rawdata must be NULL\"); \n      rc = SQLITE_CONSTRAINT;\n    }\n\n    if( rc==SQLITE_OK ){\n      if( sqlite3_value_type(apVal[7])==SQLITE_NULL ){\n        /* data=NULL. A directory */\n        bIsDir = 1;\n      }else{\n        /* Value specified for \"data\", and possibly \"method\". This must be\n        ** a regular file or a symlink. */\n        const u8 *aIn = sqlite3_value_blob(apVal[7]);\n        int nIn = sqlite3_value_bytes(apVal[7]);\n        int bAuto = sqlite3_value_type(apVal[8])==SQLITE_NULL;\n\n        iMethod = sqlite3_value_int(apVal[8]);\n        sz = nIn;\n        pData = aIn;\n        nData = nIn;\n        if( iMethod!=0 && iMethod!=8 ){\n          zipfileTableErr(pTab, \"unknown compression method: %d\", iMethod);\n          rc = SQLITE_CONSTRAINT;\n        }else{\n          if( bAuto || iMethod ){\n            int nCmp;\n            rc = zipfileDeflate(aIn, nIn, &pFree, &nCmp, &pTab->base.zErrMsg);\n            if( rc==SQLITE_OK ){\n              if( iMethod || nCmp<nIn ){\n                iMethod = 8;\n                pData = pFree;\n                nData = nCmp;\n              }\n            }\n          }\n          iCrc32 = crc32(0, aIn, nIn);\n        }\n      }\n    }\n\n    if( rc==SQLITE_OK ){\n      rc = zipfileGetMode(apVal[3], bIsDir, &mode, &pTab->base.zErrMsg);\n    }\n\n    if( rc==SQLITE_OK ){\n      zPath = (const char*)sqlite3_value_text(apVal[2]);\n      if( zPath==0 ) zPath = \"\";\n      nPath = (int)strlen(zPath);\n      mTime = zipfileGetTime(apVal[4]);\n    }\n\n    if( rc==SQLITE_OK && bIsDir ){\n      /* For a directory, check that the last character in the path is a\n      ** '/'. This appears to be required for compatibility with info-zip\n      ** (the unzip command on unix). It does not create directories\n      ** otherwise.  */\n      if( zPath[nPath-1]!='/' ){\n        zFree = sqlite3_mprintf(\"%s/\", zPath);\n        if( zFree==0 ){ rc = SQLITE_NOMEM; }\n        zPath = (const char*)zFree;\n        nPath++;\n      }\n    }\n\n    /* Check that we're not inserting a duplicate entry -OR- updating an\n    ** entry with a path, thereby making it into a duplicate. */\n    if( (pOld==0 || bUpdate) && rc==SQLITE_OK ){\n      ZipfileEntry *p;\n      for(p=pTab->pFirstEntry; p; p=p->pNext){\n        if( zipfileComparePath(p->cds.zFile, zPath, nPath)==0 ){\n          switch( sqlite3_vtab_on_conflict(pTab->db) ){\n            case SQLITE_IGNORE: {\n              goto zipfile_update_done;\n            }\n            case SQLITE_REPLACE: {\n              pOld2 = p;\n              break;\n            }\n            default: {\n              zipfileTableErr(pTab, \"duplicate name: \\\"%s\\\"\", zPath);\n              rc = SQLITE_CONSTRAINT;\n              break;\n            }\n          }\n          break;\n        }\n      }\n    }\n\n    if( rc==SQLITE_OK ){\n      /* Create the new CDS record. */\n      pNew = zipfileNewEntry(zPath);\n      if( pNew==0 ){\n        rc = SQLITE_NOMEM;\n      }else{\n        pNew->cds.iVersionMadeBy = ZIPFILE_NEWENTRY_MADEBY;\n        pNew->cds.iVersionExtract = ZIPFILE_NEWENTRY_REQUIRED;\n        pNew->cds.flags = ZIPFILE_NEWENTRY_FLAGS;\n        pNew->cds.iCompression = (u16)iMethod;\n        zipfileMtimeToDos(&pNew->cds, mTime);\n        pNew->cds.crc32 = iCrc32;\n        pNew->cds.szCompressed = nData;\n        pNew->cds.szUncompressed = (u32)sz;\n        pNew->cds.iExternalAttr = (mode<<16);\n        pNew->cds.iOffset = (u32)pTab->szCurrent;\n        pNew->cds.nFile = (u16)nPath;\n        pNew->mUnixTime = (u32)mTime;\n        rc = zipfileAppendEntry(pTab, pNew, pData, nData);\n        zipfileAddEntry(pTab, pOld, pNew);\n      }\n    }\n  }\n\n  if( rc==SQLITE_OK && (pOld || pOld2) ){\n    ZipfileCsr *pCsr;\n    for(pCsr=pTab->pCsrList; pCsr; pCsr=pCsr->pCsrNext){\n      if( pCsr->pCurrent && (pCsr->pCurrent==pOld || pCsr->pCurrent==pOld2) ){\n        pCsr->pCurrent = pCsr->pCurrent->pNext;\n        pCsr->bNoop = 1;\n      }\n    }\n\n    zipfileRemoveEntryFromList(pTab, pOld);\n    zipfileRemoveEntryFromList(pTab, pOld2);\n  }\n\nzipfile_update_done:\n  sqlite3_free(pFree);\n  sqlite3_free(zFree);\n  return rc;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -99,6 +99,7 @@\n \n     if( rc==SQLITE_OK ){\n       zPath = (const char*)sqlite3_value_text(apVal[2]);\n+      if( zPath==0 ) zPath = \"\";\n       nPath = (int)strlen(zPath);\n       mTime = zipfileGetTime(apVal[4]);\n     }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "      if( zPath==0 ) zPath = \"\";"
            ]
        }
    },
    {
        "cve_id": "CVE-2010-4661",
        "func_name": "udisks/device_filesystem_mount_authorized_cb",
        "description": "udisks before 1.0.3 allows a local user to load arbitrary Linux kernel modules.",
        "git_url": "http://cgit.freedesktop.org/udisks/commit/?id=c933a929f07421ec747cebb24d5e620fc2b97037",
        "commit_title": "Validate what is passed to the mount(8) command. In particular, only",
        "commit_text": "allow either well-known filesystems, filesystems already loaded or filesystem explicitly allowed by the administrator via the /etc/filesystems file.  See https://bugs.freedesktop.org/show_bug.cgi?id=32232 for details.  ",
        "func_before": "static void\ndevice_filesystem_mount_authorized_cb (Daemon *daemon,\n                                       Device *device,\n                                       DBusGMethodInvocation *context,\n                                       const gchar *action_id,\n                                       guint num_user_data,\n                                       gpointer *user_data_elements)\n{\n  const gchar *filesystem_type = user_data_elements[0];\n  gchar **given_options = user_data_elements[1];\n  int n;\n  GString *s;\n  char *argv[10];\n  char *mount_point;\n  char *fstype;\n  char *mount_options;\n  GError *error;\n  uid_t caller_uid;\n  gboolean remove_dir_on_unmount;\n  const FSMountOptions *fsmo;\n  char **options;\n  char uid_buf[32];\n\n  fstype = NULL;\n  options = NULL;\n  mount_options = NULL;\n  mount_point = NULL;\n  remove_dir_on_unmount = FALSE;\n  error = NULL;\n\n  daemon_local_get_uid (device->priv->daemon, &caller_uid, context);\n\n  if (device->priv->id_usage == NULL || strcmp (device->priv->id_usage, \"filesystem\") != 0)\n    {\n      if ((g_strcmp0 (filesystem_type, \"auto\") == 0 || g_strcmp0 (filesystem_type, \"\") == 0) && device->priv->id_usage\n          == NULL)\n        {\n          /* if we don't know the usage of the device and 'auto' or '' is passed for fstype\n           * then just try that.. this is to make, for example, mounting /dev/fd0 work (we\n           * don't probe such devices for filesystems in udev)\n           */\n        }\n      else\n        {\n          throw_error (context, ERROR_FAILED, \"Not a mountable file system\");\n          goto out;\n        }\n    }\n\n  if (device_local_is_busy (device, FALSE, &error))\n    {\n      dbus_g_method_return_error (context, error);\n      g_error_free (error);\n      goto out;\n    }\n\n  /* Check if the device is referenced in /etc/fstab; if so, attempt to\n   * mount the device as the user\n   */\n  if (is_device_in_fstab (device, &mount_point))\n    {\n      n = 0;\n      snprintf (uid_buf, sizeof uid_buf, \"%d\", caller_uid);\n      argv[n++] = \"udisks-helper-fstab-mounter\";\n      argv[n++] = \"mount\";\n      argv[n++] = device->priv->device_file;\n      argv[n++] = uid_buf;\n      argv[n++] = NULL;\n      goto run_job;\n    }\n\n  /* set the fstype */\n  fstype = NULL;\n  if (strlen (filesystem_type) == 0)\n    {\n      if (device->priv->id_type != NULL && strlen (device->priv->id_type) > 0)\n        {\n          fstype = g_strdup (device->priv->id_type);\n        }\n      else\n        {\n          fstype = g_strdup (\"auto\");\n        }\n    }\n  else\n    {\n      fstype = g_strdup (filesystem_type);\n    }\n\n  fsmo = find_mount_options_for_fs (fstype);\n\n  /* always prepend some reasonable default mount options; these are\n   * chosen here; the user can override them if he wants to\n   */\n  options = prepend_default_mount_options (device, fsmo, caller_uid, given_options);\n\n  /* validate mount options and check for authorizations */\n  s = g_string_new (\"uhelper=udisks,nodev,nosuid\");\n  for (n = 0; options[n] != NULL; n++)\n    {\n      const char *option = options[n];\n\n      /* avoid attacks like passing \"shortname=lower,uid=0\" as a single mount option */\n      if (strstr (option, \",\") != NULL)\n        {\n          throw_error (context, ERROR_INVALID_OPTION, \"Malformed mount option: \", option);\n          g_string_free (s, TRUE);\n          goto out;\n        }\n\n      /* first check if the mount option is allowed */\n      if (!is_mount_option_allowed (fsmo, option, caller_uid))\n        {\n          throw_error (context, ERROR_INVALID_OPTION, \"Mount option %s is not allowed\", option);\n          g_string_free (s, TRUE);\n          goto out;\n        }\n\n      g_string_append_c (s, ',');\n      g_string_append (s, option);\n    }\n  mount_options = g_string_free (s, FALSE);\n\n  g_print (\"**** USING MOUNT OPTIONS '%s' FOR DEVICE %s\\n\", mount_options, device->priv->device_file);\n\n  if (device->priv->device_is_mounted)\n    {\n      throw_error (context, ERROR_FAILED, \"Device is already mounted\");\n      goto out;\n    }\n\n  /* Determine the mount point to use.\n   *\n   * TODO: use characteristics of the drive such as the name, connection etc.\n   *       to get better names (/media/disk is kinda lame).\n   */\n  if (device->priv->id_label != NULL && strlen (device->priv->id_label) > 0)\n    {\n      GString * s;\n\n      s = g_string_new (\"/media/\");\n      for (n = 0; device->priv->id_label[n] != '\\0'; n++)\n        {\n          gint c = device->priv->id_label[n];\n          if (c == '/')\n            g_string_append_c (s, '_');\n          else\n            g_string_append_c (s, c);\n        }\n\n      mount_point = g_string_free (s, FALSE);\n    }\n  else if (device->priv->id_uuid != NULL && strlen (device->priv->id_uuid) > 0)\n    {\n\n      GString * s;\n\n      s = g_string_new (\"/media/\");\n      for (n = 0; device->priv->id_uuid[n] != '\\0'; n++)\n        {\n          gint c = device->priv->id_uuid[n];\n          if (c == '/')\n            g_string_append_c (s, '_');\n          else\n            g_string_append_c (s, c);\n        }\n\n      mount_point = g_string_free (s, FALSE);\n\n    }\n  else\n    {\n      mount_point = g_strdup (\"/media/disk\");\n    }\n\n try_another_mount_point:\n  /* ... then uniqify the mount point and mkdir it */\n  if (g_file_test (mount_point, G_FILE_TEST_EXISTS))\n    {\n      char *s = mount_point;\n      /* TODO: append numbers instead of _, __ and so on */\n      mount_point = g_strdup_printf (\"%s_\", mount_point);\n      g_free (s);\n      goto try_another_mount_point;\n    }\n\n  remove_dir_on_unmount = TRUE;\n\n  if (g_mkdir (mount_point, 0700) != 0)\n    {\n      throw_error (context, ERROR_FAILED, \"Error creating moint point: %m\");\n      goto out;\n    }\n\n  /* now that we have a mount point, immediately add it to the\n   * /var/lib/udisks/mtab file.\n   *\n   * If mounting fails we'll clean it up in filesystem_mount_completed_cb. If it\n   * hangs we'll clean it up the next time we start up.\n   */\n  mount_file_add (device->priv->device_file, mount_point, caller_uid, remove_dir_on_unmount);\n\n  n = 0;\n  argv[n++] = \"mount\";\n  argv[n++] = \"-t\";\n  argv[n++] = fstype;\n  argv[n++] = \"-o\";\n  argv[n++] = mount_options;\n  argv[n++] = device->priv->device_file;\n  argv[n++] = mount_point;\n  argv[n++] = NULL;\n\n run_job:\n\n  error = NULL;\n  if (!job_new (context,\n                \"FilesystemMount\",\n                FALSE,\n                device,\n                argv,\n                NULL,\n                filesystem_mount_completed_cb,\n                FALSE,\n                filesystem_mount_data_new (mount_point, remove_dir_on_unmount),\n                (GDestroyNotify) filesystem_mount_data_free))\n    {\n      if (remove_dir_on_unmount)\n        {\n          mount_file_remove (device->priv->device_file, mount_point);\n          if (g_rmdir (mount_point) != 0)\n            {\n              g_warning (\"Error removing dir in early mount error path: %m\");\n            }\n        }\n      goto out;\n    }\n\n out:\n  g_free (fstype);\n  g_free (mount_options);\n  g_free (mount_point);\n  g_strfreev (options);\n}",
        "func": "static void\ndevice_filesystem_mount_authorized_cb (Daemon *daemon,\n                                       Device *device,\n                                       DBusGMethodInvocation *context,\n                                       const gchar *action_id,\n                                       guint num_user_data,\n                                       gpointer *user_data_elements)\n{\n  const gchar *filesystem_type = user_data_elements[0];\n  gchar **given_options = user_data_elements[1];\n  int n;\n  GString *s;\n  char *argv[10];\n  char *mount_point;\n  char *fstype;\n  char *mount_options;\n  GError *error;\n  uid_t caller_uid;\n  gboolean remove_dir_on_unmount;\n  const FSMountOptions *fsmo;\n  char **options;\n  char uid_buf[32];\n\n  fstype = NULL;\n  options = NULL;\n  mount_options = NULL;\n  mount_point = NULL;\n  remove_dir_on_unmount = FALSE;\n  error = NULL;\n\n  /* If the user requests the filesystem type, error out unless the\n   * filesystem type is\n   *\n   * - well-known [1]; or\n   * - in the /etc/filesystems file; or\n   * - in the /proc/filesystems file\n   *\n   * We do this because mount(8) on Linux allows loading any arbitrary\n   * kernel module (when invoked as root) by passing something appropriate\n   * to the -t option. So we have to validate whatever we pass.\n   *\n   * See https://bugs.freedesktop.org/show_bug.cgi?id=32232 for more\n   * details.\n   *\n   * [1] : since /etc/filesystems may be horribly out of date and not\n   *       contain e.g. ext4\n   */\n  if (filesystem_type != NULL && strlen (filesystem_type) > 0 &&\n      g_strcmp0 (filesystem_type, \"auto\") != 0)\n    {\n      if (!is_allowed_filesystem (filesystem_type))\n        {\n          throw_error (context, ERROR_FAILED,\n                       \"Requested filesystem type is neither well-known nor \"\n                       \"in /proc/filesystems nor in /etc/filesystems\");\n          goto out;\n        }\n    }\n\n  daemon_local_get_uid (device->priv->daemon, &caller_uid, context);\n\n  if (device->priv->id_usage == NULL || strcmp (device->priv->id_usage, \"filesystem\") != 0)\n    {\n      if ((g_strcmp0 (filesystem_type, \"auto\") == 0 || g_strcmp0 (filesystem_type, \"\") == 0) && device->priv->id_usage\n          == NULL)\n        {\n          /* if we don't know the usage of the device and 'auto' or '' is passed for fstype\n           * then just try that.. this is to make, for example, mounting /dev/fd0 work (we\n           * don't probe such devices for filesystems in udev)\n           */\n        }\n      else\n        {\n          throw_error (context, ERROR_FAILED, \"Not a mountable file system\");\n          goto out;\n        }\n    }\n\n  if (device_local_is_busy (device, FALSE, &error))\n    {\n      dbus_g_method_return_error (context, error);\n      g_error_free (error);\n      goto out;\n    }\n\n  /* Check if the device is referenced in /etc/fstab; if so, attempt to\n   * mount the device as the user\n   */\n  if (is_device_in_fstab (device, &mount_point))\n    {\n      n = 0;\n      snprintf (uid_buf, sizeof uid_buf, \"%d\", caller_uid);\n      argv[n++] = \"udisks-helper-fstab-mounter\";\n      argv[n++] = \"mount\";\n      argv[n++] = device->priv->device_file;\n      argv[n++] = uid_buf;\n      argv[n++] = NULL;\n      goto run_job;\n    }\n\n  /* set the fstype */\n  fstype = NULL;\n  if (strlen (filesystem_type) == 0)\n    {\n      if (device->priv->id_type != NULL && strlen (device->priv->id_type) > 0)\n        {\n          fstype = g_strdup (device->priv->id_type);\n        }\n      else\n        {\n          fstype = g_strdup (\"auto\");\n        }\n    }\n  else\n    {\n      fstype = g_strdup (filesystem_type);\n    }\n\n  fsmo = find_mount_options_for_fs (fstype);\n\n  /* always prepend some reasonable default mount options; these are\n   * chosen here; the user can override them if he wants to\n   */\n  options = prepend_default_mount_options (device, fsmo, caller_uid, given_options);\n\n  /* validate mount options and check for authorizations */\n  s = g_string_new (\"uhelper=udisks,nodev,nosuid\");\n  for (n = 0; options[n] != NULL; n++)\n    {\n      const char *option = options[n];\n\n      /* avoid attacks like passing \"shortname=lower,uid=0\" as a single mount option */\n      if (strstr (option, \",\") != NULL)\n        {\n          throw_error (context, ERROR_INVALID_OPTION, \"Malformed mount option: \", option);\n          g_string_free (s, TRUE);\n          goto out;\n        }\n\n      /* first check if the mount option is allowed */\n      if (!is_mount_option_allowed (fsmo, option, caller_uid))\n        {\n          throw_error (context, ERROR_INVALID_OPTION, \"Mount option %s is not allowed\", option);\n          g_string_free (s, TRUE);\n          goto out;\n        }\n\n      g_string_append_c (s, ',');\n      g_string_append (s, option);\n    }\n  mount_options = g_string_free (s, FALSE);\n\n  g_print (\"**** USING MOUNT OPTIONS '%s' FOR DEVICE %s\\n\", mount_options, device->priv->device_file);\n\n  if (device->priv->device_is_mounted)\n    {\n      throw_error (context, ERROR_FAILED, \"Device is already mounted\");\n      goto out;\n    }\n\n  /* Determine the mount point to use.\n   *\n   * TODO: use characteristics of the drive such as the name, connection etc.\n   *       to get better names (/media/disk is kinda lame).\n   */\n  if (device->priv->id_label != NULL && strlen (device->priv->id_label) > 0)\n    {\n      GString * s;\n\n      s = g_string_new (\"/media/\");\n      for (n = 0; device->priv->id_label[n] != '\\0'; n++)\n        {\n          gint c = device->priv->id_label[n];\n          if (c == '/')\n            g_string_append_c (s, '_');\n          else\n            g_string_append_c (s, c);\n        }\n\n      mount_point = g_string_free (s, FALSE);\n    }\n  else if (device->priv->id_uuid != NULL && strlen (device->priv->id_uuid) > 0)\n    {\n\n      GString * s;\n\n      s = g_string_new (\"/media/\");\n      for (n = 0; device->priv->id_uuid[n] != '\\0'; n++)\n        {\n          gint c = device->priv->id_uuid[n];\n          if (c == '/')\n            g_string_append_c (s, '_');\n          else\n            g_string_append_c (s, c);\n        }\n\n      mount_point = g_string_free (s, FALSE);\n\n    }\n  else\n    {\n      mount_point = g_strdup (\"/media/disk\");\n    }\n\n try_another_mount_point:\n  /* ... then uniqify the mount point and mkdir it */\n  if (g_file_test (mount_point, G_FILE_TEST_EXISTS))\n    {\n      char *s = mount_point;\n      /* TODO: append numbers instead of _, __ and so on */\n      mount_point = g_strdup_printf (\"%s_\", mount_point);\n      g_free (s);\n      goto try_another_mount_point;\n    }\n\n  remove_dir_on_unmount = TRUE;\n\n  if (g_mkdir (mount_point, 0700) != 0)\n    {\n      throw_error (context, ERROR_FAILED, \"Error creating moint point: %m\");\n      goto out;\n    }\n\n  /* now that we have a mount point, immediately add it to the\n   * /var/lib/udisks/mtab file.\n   *\n   * If mounting fails we'll clean it up in filesystem_mount_completed_cb. If it\n   * hangs we'll clean it up the next time we start up.\n   */\n  mount_file_add (device->priv->device_file, mount_point, caller_uid, remove_dir_on_unmount);\n\n  n = 0;\n  argv[n++] = \"mount\";\n  argv[n++] = \"-t\";\n  argv[n++] = fstype;\n  argv[n++] = \"-o\";\n  argv[n++] = mount_options;\n  argv[n++] = device->priv->device_file;\n  argv[n++] = mount_point;\n  argv[n++] = NULL;\n\n run_job:\n\n  error = NULL;\n  if (!job_new (context,\n                \"FilesystemMount\",\n                FALSE,\n                device,\n                argv,\n                NULL,\n                filesystem_mount_completed_cb,\n                FALSE,\n                filesystem_mount_data_new (mount_point, remove_dir_on_unmount),\n                (GDestroyNotify) filesystem_mount_data_free))\n    {\n      if (remove_dir_on_unmount)\n        {\n          mount_file_remove (device->priv->device_file, mount_point);\n          if (g_rmdir (mount_point) != 0)\n            {\n              g_warning (\"Error removing dir in early mount error path: %m\");\n            }\n        }\n      goto out;\n    }\n\n out:\n  g_free (fstype);\n  g_free (mount_options);\n  g_free (mount_point);\n  g_strfreev (options);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -28,6 +28,35 @@\n   remove_dir_on_unmount = FALSE;\n   error = NULL;\n \n+  /* If the user requests the filesystem type, error out unless the\n+   * filesystem type is\n+   *\n+   * - well-known [1]; or\n+   * - in the /etc/filesystems file; or\n+   * - in the /proc/filesystems file\n+   *\n+   * We do this because mount(8) on Linux allows loading any arbitrary\n+   * kernel module (when invoked as root) by passing something appropriate\n+   * to the -t option. So we have to validate whatever we pass.\n+   *\n+   * See https://bugs.freedesktop.org/show_bug.cgi?id=32232 for more\n+   * details.\n+   *\n+   * [1] : since /etc/filesystems may be horribly out of date and not\n+   *       contain e.g. ext4\n+   */\n+  if (filesystem_type != NULL && strlen (filesystem_type) > 0 &&\n+      g_strcmp0 (filesystem_type, \"auto\") != 0)\n+    {\n+      if (!is_allowed_filesystem (filesystem_type))\n+        {\n+          throw_error (context, ERROR_FAILED,\n+                       \"Requested filesystem type is neither well-known nor \"\n+                       \"in /proc/filesystems nor in /etc/filesystems\");\n+          goto out;\n+        }\n+    }\n+\n   daemon_local_get_uid (device->priv->daemon, &caller_uid, context);\n \n   if (device->priv->id_usage == NULL || strcmp (device->priv->id_usage, \"filesystem\") != 0)",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "  /* If the user requests the filesystem type, error out unless the",
                "   * filesystem type is",
                "   *",
                "   * - well-known [1]; or",
                "   * - in the /etc/filesystems file; or",
                "   * - in the /proc/filesystems file",
                "   *",
                "   * We do this because mount(8) on Linux allows loading any arbitrary",
                "   * kernel module (when invoked as root) by passing something appropriate",
                "   * to the -t option. So we have to validate whatever we pass.",
                "   *",
                "   * See https://bugs.freedesktop.org/show_bug.cgi?id=32232 for more",
                "   * details.",
                "   *",
                "   * [1] : since /etc/filesystems may be horribly out of date and not",
                "   *       contain e.g. ext4",
                "   */",
                "  if (filesystem_type != NULL && strlen (filesystem_type) > 0 &&",
                "      g_strcmp0 (filesystem_type, \"auto\") != 0)",
                "    {",
                "      if (!is_allowed_filesystem (filesystem_type))",
                "        {",
                "          throw_error (context, ERROR_FAILED,",
                "                       \"Requested filesystem type is neither well-known nor \"",
                "                       \"in /proc/filesystems nor in /etc/filesystems\");",
                "          goto out;",
                "        }",
                "    }",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2017-12678",
        "func_name": "taglib/FrameFactory::rebuildAggregateFrames",
        "description": "In TagLib 1.11.1, the rebuildAggregateFrames function in id3v2framefactory.cpp has a pointer to cast vulnerability, which allows remote attackers to cause a denial of service or possibly have unspecified other impact via a crafted audio file.",
        "git_url": "https://github.com/taglib/taglib/commit/cb9f07d9dcd791b63e622da43f7b232adaec0a9a",
        "commit_title": "Don't assume TDRC is an instance of TextIdentificationFrame (#831)",
        "commit_text": " If TDRC is encrypted, FrameFactory::createFrame() returns UnknownFrame\r which causes problems in rebuildAggregateFrames() when it is assumed\r that TDRC is a TextIdentificationFrame",
        "func_before": "void FrameFactory::rebuildAggregateFrames(ID3v2::Tag *tag) const\n{\n  if(tag->header()->majorVersion() < 4 &&\n     tag->frameList(\"TDRC\").size() == 1 &&\n     tag->frameList(\"TDAT\").size() == 1)\n  {\n    TextIdentificationFrame *tdrc =\n      static_cast<TextIdentificationFrame *>(tag->frameList(\"TDRC\").front());\n    UnknownFrame *tdat = static_cast<UnknownFrame *>(tag->frameList(\"TDAT\").front());\n\n    if(tdrc->fieldList().size() == 1 &&\n       tdrc->fieldList().front().size() == 4 &&\n       tdat->data().size() >= 5)\n    {\n      String date(tdat->data().mid(1), String::Type(tdat->data()[0]));\n      if(date.length() == 4) {\n        tdrc->setText(tdrc->toString() + '-' + date.substr(2, 2) + '-' + date.substr(0, 2));\n        if(tag->frameList(\"TIME\").size() == 1) {\n          UnknownFrame *timeframe = static_cast<UnknownFrame *>(tag->frameList(\"TIME\").front());\n          if(timeframe->data().size() >= 5) {\n            String time(timeframe->data().mid(1), String::Type(timeframe->data()[0]));\n            if(time.length() == 4) {\n              tdrc->setText(tdrc->toString() + 'T' + time.substr(0, 2) + ':' + time.substr(2, 2));\n            }\n          }\n        }\n      }\n    }\n  }\n}",
        "func": "void FrameFactory::rebuildAggregateFrames(ID3v2::Tag *tag) const\n{\n  if(tag->header()->majorVersion() < 4 &&\n     tag->frameList(\"TDRC\").size() == 1 &&\n     tag->frameList(\"TDAT\").size() == 1)\n  {\n    TextIdentificationFrame *tdrc =\n      dynamic_cast<TextIdentificationFrame *>(tag->frameList(\"TDRC\").front());\n    UnknownFrame *tdat = static_cast<UnknownFrame *>(tag->frameList(\"TDAT\").front());\n\n    if(tdrc &&\n       tdrc->fieldList().size() == 1 &&\n       tdrc->fieldList().front().size() == 4 &&\n       tdat->data().size() >= 5)\n    {\n      String date(tdat->data().mid(1), String::Type(tdat->data()[0]));\n      if(date.length() == 4) {\n        tdrc->setText(tdrc->toString() + '-' + date.substr(2, 2) + '-' + date.substr(0, 2));\n        if(tag->frameList(\"TIME\").size() == 1) {\n          UnknownFrame *timeframe = static_cast<UnknownFrame *>(tag->frameList(\"TIME\").front());\n          if(timeframe->data().size() >= 5) {\n            String time(timeframe->data().mid(1), String::Type(timeframe->data()[0]));\n            if(time.length() == 4) {\n              tdrc->setText(tdrc->toString() + 'T' + time.substr(0, 2) + ':' + time.substr(2, 2));\n            }\n          }\n        }\n      }\n    }\n  }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,10 +5,11 @@\n      tag->frameList(\"TDAT\").size() == 1)\n   {\n     TextIdentificationFrame *tdrc =\n-      static_cast<TextIdentificationFrame *>(tag->frameList(\"TDRC\").front());\n+      dynamic_cast<TextIdentificationFrame *>(tag->frameList(\"TDRC\").front());\n     UnknownFrame *tdat = static_cast<UnknownFrame *>(tag->frameList(\"TDAT\").front());\n \n-    if(tdrc->fieldList().size() == 1 &&\n+    if(tdrc &&\n+       tdrc->fieldList().size() == 1 &&\n        tdrc->fieldList().front().size() == 4 &&\n        tdat->data().size() >= 5)\n     {",
        "diff_line_info": {
            "deleted_lines": [
                "      static_cast<TextIdentificationFrame *>(tag->frameList(\"TDRC\").front());",
                "    if(tdrc->fieldList().size() == 1 &&"
            ],
            "added_lines": [
                "      dynamic_cast<TextIdentificationFrame *>(tag->frameList(\"TDRC\").front());",
                "    if(tdrc &&",
                "       tdrc->fieldList().size() == 1 &&"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-11722",
        "func_name": "crawl/CLua::init_libraries",
        "description": "Dungeon Crawl Stone Soup (aka DCSS or crawl) before 0.25 allows remote attackers to execute arbitrary code via Lua bytecode embedded in an uploaded .crawlrc file.",
        "git_url": "https://github.com/crawl/crawl/commit/fc522ff6eb1bbb85e3de60c60a45762571e48c28",
        "commit_title": "Disable lua load(), loadstring() bytcode loading",
        "commit_text": "",
        "func_before": "void CLua::init_libraries()\n{\n    lua_stack_cleaner clean(state());\n\n    lua_pushcfunction(_state, lua_loadstring);\n    lua_setglobal(_state, \"loadstring\");\n\n    // Open Crawl bindings\n    cluaopen_kills(_state);\n    cluaopen_you(_state);\n    cluaopen_item(_state);\n    cluaopen_food(_state);\n    cluaopen_crawl(_state);\n    cluaopen_file(_state);\n    cluaopen_moninf(_state);\n    cluaopen_options(_state);\n    cluaopen_travel(_state);\n    cluaopen_view(_state);\n    cluaopen_spells(_state);\n\n    cluaopen_globals(_state);\n\n    execfile(\"dlua/macro.lua\", true, true);\n\n    // All hook names must be chk_????\n    execstring(\"chk_startgame = { }\", \"base\");\n\n    lua_register(_state, \"loadfile\", _clua_loadfile);\n    lua_register(_state, \"dofile\", _clua_dofile);\n\n    lua_register(_state, \"crawl_require\", _clua_require);\n\n    execfile(\"dlua/util.lua\", true, true);\n    execfile(\"dlua/iter.lua\", true, true);\n    execfile(\"dlua/tags.lua\", true, true);\n    execfile(\"dlua/init.lua\", true, true);\n\n    if (managed_vm)\n    {\n        lua_register(_state, \"pcall\", _clua_guarded_pcall);\n        execfile(\"dlua/userbase.lua\", true, true);\n        execfile(\"dlua/persist.lua\", true, true);\n    }\n}",
        "func": "void CLua::init_libraries()\n{\n    lua_stack_cleaner clean(state());\n\n    lua_pushcfunction(_state, lua_loadstring);\n    lua_setglobal(_state, \"loadstring\");\n    lua_pushnil(_state);\n    lua_setglobal(_state, \"load\");\n\n    // Open Crawl bindings\n    cluaopen_kills(_state);\n    cluaopen_you(_state);\n    cluaopen_item(_state);\n    cluaopen_food(_state);\n    cluaopen_crawl(_state);\n    cluaopen_file(_state);\n    cluaopen_moninf(_state);\n    cluaopen_options(_state);\n    cluaopen_travel(_state);\n    cluaopen_view(_state);\n    cluaopen_spells(_state);\n\n    cluaopen_globals(_state);\n\n    execfile(\"dlua/macro.lua\", true, true);\n\n    // All hook names must be chk_????\n    execstring(\"chk_startgame = { }\", \"base\");\n\n    lua_register(_state, \"loadfile\", _clua_loadfile);\n    lua_register(_state, \"dofile\", _clua_dofile);\n\n    lua_register(_state, \"crawl_require\", _clua_require);\n\n    execfile(\"dlua/util.lua\", true, true);\n    execfile(\"dlua/iter.lua\", true, true);\n    execfile(\"dlua/tags.lua\", true, true);\n    execfile(\"dlua/init.lua\", true, true);\n\n    if (managed_vm)\n    {\n        lua_register(_state, \"pcall\", _clua_guarded_pcall);\n        execfile(\"dlua/userbase.lua\", true, true);\n        execfile(\"dlua/persist.lua\", true, true);\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,6 +4,8 @@\n \n     lua_pushcfunction(_state, lua_loadstring);\n     lua_setglobal(_state, \"loadstring\");\n+    lua_pushnil(_state);\n+    lua_setglobal(_state, \"load\");\n \n     // Open Crawl bindings\n     cluaopen_kills(_state);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    lua_pushnil(_state);",
                "    lua_setglobal(_state, \"load\");"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-11722",
        "func_name": "crawl/CLua::loadfile",
        "description": "Dungeon Crawl Stone Soup (aka DCSS or crawl) before 0.25 allows remote attackers to execute arbitrary code via Lua bytecode embedded in an uploaded .crawlrc file.",
        "git_url": "https://github.com/crawl/crawl/commit/fc522ff6eb1bbb85e3de60c60a45762571e48c28",
        "commit_title": "Disable lua load(), loadstring() bytcode loading",
        "commit_text": "",
        "func_before": "int CLua::loadfile(lua_State *ls, const char *filename, bool trusted,\n                   bool die_on_fail)\n{\n    if (!ls)\n        return -1;\n\n    if (!is_path_safe(filename, trusted))\n    {\n        lua_pushstring(\n            ls,\n            make_stringf(\"invalid filename: %s\", filename).c_str());\n        return -1;\n    }\n\n    string file = datafile_path(filename, die_on_fail);\n    if (file.empty())\n    {\n        lua_pushstring(ls,\n                       make_stringf(\"Can't find \\\"%s\\\"\", filename).c_str());\n        return -1;\n    }\n\n    FileLineInput f(file.c_str());\n    string script;\n    while (!f.eof())\n        script += f.get_line() + \"\\n\";\n\n    // prefixing with @ stops lua from adding [string \"%s\"]\n    return luaL_loadbuffer(ls, &script[0], script.length(),\n                           (\"@\" + file).c_str());\n}",
        "func": "int CLua::loadfile(lua_State *ls, const char *filename, bool trusted,\n                   bool die_on_fail)\n{\n    if (!ls)\n        return -1;\n\n    if (!is_path_safe(filename, trusted))\n    {\n        lua_pushstring(\n            ls,\n            make_stringf(\"invalid filename: %s\", filename).c_str());\n        return -1;\n    }\n\n    string file = datafile_path(filename, die_on_fail);\n    if (file.empty())\n    {\n        lua_pushstring(ls,\n                       make_stringf(\"Can't find \\\"%s\\\"\", filename).c_str());\n        return -1;\n    }\n\n    FileLineInput f(file.c_str());\n    string script;\n    while (!f.eof())\n        script += f.get_line() + \"\\n\";\n\n    if (script[0] == 0x1b)\n        abort();\n\n    // prefixing with @ stops lua from adding [string \"%s\"]\n    return luaL_loadbuffer(ls, &script[0], script.length(),\n                           (\"@\" + file).c_str());\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -25,6 +25,9 @@\n     while (!f.eof())\n         script += f.get_line() + \"\\n\";\n \n+    if (script[0] == 0x1b)\n+        abort();\n+\n     // prefixing with @ stops lua from adding [string \"%s\"]\n     return luaL_loadbuffer(ls, &script[0], script.length(),\n                            (\"@\" + file).c_str());",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    if (script[0] == 0x1b)",
                "        abort();",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2020-11722",
        "func_name": "crawl/CLua::init_libraries",
        "description": "Dungeon Crawl Stone Soup (aka DCSS or crawl) before 0.25 allows remote attackers to execute arbitrary code via Lua bytecode embedded in an uploaded .crawlrc file.",
        "git_url": "https://github.com/crawl/crawl/commit/768f60da87a3fa0b5561da5ade9309577c176d04",
        "commit_title": "Disable lua bytecode loading",
        "commit_text": "",
        "func_before": "void CLua::init_libraries()\n{\n    lua_stack_cleaner clean(state());\n\n    // Open Crawl bindings\n    cluaopen_kills(_state);\n    cluaopen_you(_state);\n    cluaopen_item(_state);\n    cluaopen_food(_state);\n    cluaopen_crawl(_state);\n    cluaopen_file(_state);\n    cluaopen_moninf(_state);\n    cluaopen_options(_state);\n    cluaopen_travel(_state);\n    cluaopen_view(_state);\n    cluaopen_spells(_state);\n\n    cluaopen_globals(_state);\n\n    execfile(\"dlua/macro.lua\", true, true);\n\n    // All hook names must be chk_????\n    execstring(\"chk_startgame = { }\", \"base\");\n\n    lua_register(_state, \"loadfile\", _clua_loadfile);\n    lua_register(_state, \"dofile\", _clua_dofile);\n\n    lua_register(_state, \"crawl_require\", _clua_require);\n\n    execfile(\"dlua/util.lua\", true, true);\n    execfile(\"dlua/iter.lua\", true, true);\n    execfile(\"dlua/tags.lua\", true, true);\n    execfile(\"dlua/init.lua\", true, true);\n\n    if (managed_vm)\n    {\n        lua_register(_state, \"pcall\", _clua_guarded_pcall);\n        execfile(\"dlua/userbase.lua\", true, true);\n        execfile(\"dlua/persist.lua\", true, true);\n    }\n}",
        "func": "void CLua::init_libraries()\n{\n    lua_stack_cleaner clean(state());\n\n    lua_pushcfunction(_state, lua_loadstring);\n    lua_setglobal(_state, \"loadstring\");\n\n    // Open Crawl bindings\n    cluaopen_kills(_state);\n    cluaopen_you(_state);\n    cluaopen_item(_state);\n    cluaopen_food(_state);\n    cluaopen_crawl(_state);\n    cluaopen_file(_state);\n    cluaopen_moninf(_state);\n    cluaopen_options(_state);\n    cluaopen_travel(_state);\n    cluaopen_view(_state);\n    cluaopen_spells(_state);\n\n    cluaopen_globals(_state);\n\n    execfile(\"dlua/macro.lua\", true, true);\n\n    // All hook names must be chk_????\n    execstring(\"chk_startgame = { }\", \"base\");\n\n    lua_register(_state, \"loadfile\", _clua_loadfile);\n    lua_register(_state, \"dofile\", _clua_dofile);\n\n    lua_register(_state, \"crawl_require\", _clua_require);\n\n    execfile(\"dlua/util.lua\", true, true);\n    execfile(\"dlua/iter.lua\", true, true);\n    execfile(\"dlua/tags.lua\", true, true);\n    execfile(\"dlua/init.lua\", true, true);\n\n    if (managed_vm)\n    {\n        lua_register(_state, \"pcall\", _clua_guarded_pcall);\n        execfile(\"dlua/userbase.lua\", true, true);\n        execfile(\"dlua/persist.lua\", true, true);\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,9 @@\n void CLua::init_libraries()\n {\n     lua_stack_cleaner clean(state());\n+\n+    lua_pushcfunction(_state, lua_loadstring);\n+    lua_setglobal(_state, \"loadstring\");\n \n     // Open Crawl bindings\n     cluaopen_kills(_state);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "    lua_pushcfunction(_state, lua_loadstring);",
                "    lua_setglobal(_state, \"loadstring\");"
            ]
        }
    }
]