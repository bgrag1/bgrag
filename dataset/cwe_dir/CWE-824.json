[
    {
        "cve_id": "CVE-2016-4343",
        "func_name": "php/php-src/phar_parse_tarfile",
        "description": "The phar_make_dirstream function in ext/phar/dirstream.c in PHP before 5.6.18 and 7.x before 7.0.3 mishandles zero-size ././@LongLink files, which allows remote attackers to cause a denial of service (uninitialized pointer dereference) or possibly have unspecified other impact via a crafted TAR archive.",
        "git_url": "https://github.com/php/php-src/commit/9649ca1630433473a307d015ba1a79a4a7a779f5",
        "commit_title": "Fixed bug #71331 - Uninitialized pointer in phar_make_dirstream()",
        "commit_text": "",
        "func_before": "int phar_parse_tarfile(php_stream* fp, char *fname, int fname_len, char *alias, int alias_len, phar_archive_data** pphar, int is_data, php_uint32 compression, char **error TSRMLS_DC) /* {{{ */\n{\n\tchar buf[512], *actual_alias = NULL, *p;\n\tphar_entry_info entry = {0};\n\tsize_t pos = 0, read, totalsize;\n\ttar_header *hdr;\n\tphp_uint32 sum1, sum2, size, old;\n\tphar_archive_data *myphar, **actual;\n\tint last_was_longlink = 0;\n\tint linkname_len;\n\n\tif (error) {\n\t\t*error = NULL;\n\t}\n\n\tphp_stream_seek(fp, 0, SEEK_END);\n\ttotalsize = php_stream_tell(fp);\n\tphp_stream_seek(fp, 0, SEEK_SET);\n\tread = php_stream_read(fp, buf, sizeof(buf));\n\n\tif (read != sizeof(buf)) {\n\t\tif (error) {\n\t\t\tspprintf(error, 4096, \"phar error: \\\"%s\\\" is not a tar file or is truncated\", fname);\n\t\t}\n\t\tphp_stream_close(fp);\n\t\treturn FAILURE;\n\t}\n\n\thdr = (tar_header*)buf;\n\told = (memcmp(hdr->magic, \"ustar\", sizeof(\"ustar\")-1) != 0);\n\n\tmyphar = (phar_archive_data *) pecalloc(1, sizeof(phar_archive_data), PHAR_G(persist));\n\tmyphar->is_persistent = PHAR_G(persist);\n\t/* estimate number of entries, can't be certain with tar files */\n\tzend_hash_init(&myphar->manifest, 2 + (totalsize >> 12),\n\t\tzend_get_hash_value, destroy_phar_manifest_entry, (zend_bool)myphar->is_persistent);\n\tzend_hash_init(&myphar->mounted_dirs, 5,\n\t\tzend_get_hash_value, NULL, (zend_bool)myphar->is_persistent);\n\tzend_hash_init(&myphar->virtual_dirs, 4 + (totalsize >> 11),\n\t\tzend_get_hash_value, NULL, (zend_bool)myphar->is_persistent);\n\tmyphar->is_tar = 1;\n\t/* remember whether this entire phar was compressed with gz/bzip2 */\n\tmyphar->flags = compression;\n\n\tentry.is_tar = 1;\n\tentry.is_crc_checked = 1;\n\tentry.phar = myphar;\n\tpos += sizeof(buf);\n\n\tdo {\n\t\tphar_entry_info *newentry;\n\n\t\tpos = php_stream_tell(fp);\n\t\thdr = (tar_header*) buf;\n\t\tsum1 = phar_tar_number(hdr->checksum, sizeof(hdr->checksum));\n\t\tif (sum1 == 0 && phar_tar_checksum(buf, sizeof(buf)) == 0) {\n\t\t\tbreak;\n\t\t}\n\t\tmemset(hdr->checksum, ' ', sizeof(hdr->checksum));\n\t\tsum2 = phar_tar_checksum(buf, old?sizeof(old_tar_header):sizeof(tar_header));\n\n\t\tsize = entry.uncompressed_filesize = entry.compressed_filesize =\n\t\t\tphar_tar_number(hdr->size, sizeof(hdr->size));\n\n\t\t/* skip global/file headers (pax) */\n\t\tif (!old && (hdr->typeflag == TAR_GLOBAL_HDR || hdr->typeflag == TAR_FILE_HDR)) {\n\t\t\tsize = (size+511)&~511;\n\t\t\tgoto next;\n\t\t}\n\n\t\tif (((!old && hdr->prefix[0] == 0) || old) && strnlen(hdr->name, 100) == sizeof(\".phar/signature.bin\")-1 && !strncmp(hdr->name, \".phar/signature.bin\", sizeof(\".phar/signature.bin\")-1)) {\n\t\t\toff_t curloc;\n\n\t\t\tif (size > 511) {\n\t\t\t\tif (error) {\n\t\t\t\t\tspprintf(error, 4096, \"phar error: tar-based phar \\\"%s\\\" has signature that is larger than 511 bytes, cannot process\", fname);\n\t\t\t\t}\nbail:\n\t\t\t\tphp_stream_close(fp);\n\t\t\t\tphar_destroy_phar_data(myphar TSRMLS_CC);\n\t\t\t\treturn FAILURE;\n\t\t\t}\n\t\t\tcurloc = php_stream_tell(fp);\n\t\t\tread = php_stream_read(fp, buf, size);\n\t\t\tif (read != size) {\n\t\t\t\tif (error) {\n\t\t\t\t\tspprintf(error, 4096, \"phar error: tar-based phar \\\"%s\\\" signature cannot be read\", fname);\n\t\t\t\t}\n\t\t\t\tgoto bail;\n\t\t\t}\n#ifdef WORDS_BIGENDIAN\n# define PHAR_GET_32(buffer) \\\n\t(((((unsigned char*)(buffer))[3]) << 24) \\\n\t\t| ((((unsigned char*)(buffer))[2]) << 16) \\\n\t\t| ((((unsigned char*)(buffer))[1]) <<  8) \\\n\t\t| (((unsigned char*)(buffer))[0]))\n#else\n# define PHAR_GET_32(buffer) (php_uint32) *(buffer)\n#endif\n\t\t\tmyphar->sig_flags = PHAR_GET_32(buf);\n\t\t\tif (FAILURE == phar_verify_signature(fp, php_stream_tell(fp) - size - 512, myphar->sig_flags, buf + 8, size - 8, fname, &myphar->signature, &myphar->sig_len, error TSRMLS_CC)) {\n\t\t\t\tif (error) {\n\t\t\t\t\tchar *save = *error;\n\t\t\t\t\tspprintf(error, 4096, \"phar error: tar-based phar \\\"%s\\\" signature cannot be verified: %s\", fname, save);\n\t\t\t\t\tefree(save);\n\t\t\t\t}\n\t\t\t\tgoto bail;\n\t\t\t}\n\t\t\tphp_stream_seek(fp, curloc + 512, SEEK_SET);\n\t\t\t/* signature checked out, let's ensure this is the last file in the phar */\n\t\t\tif (((hdr->typeflag == '\\0') || (hdr->typeflag == TAR_FILE)) && size > 0) {\n\t\t\t\t/* this is not good enough - seek succeeds even on truncated tars */\n\t\t\t\tphp_stream_seek(fp, 512, SEEK_CUR);\n\t\t\t\tif ((uint)php_stream_tell(fp) > totalsize) {\n\t\t\t\t\tif (error) {\n\t\t\t\t\t\tspprintf(error, 4096, \"phar error: \\\"%s\\\" is a corrupted tar file (truncated)\", fname);\n\t\t\t\t\t}\n\t\t\t\t\tphp_stream_close(fp);\n\t\t\t\t\tphar_destroy_phar_data(myphar TSRMLS_CC);\n\t\t\t\t\treturn FAILURE;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tread = php_stream_read(fp, buf, sizeof(buf));\n\n\t\t\tif (read != sizeof(buf)) {\n\t\t\t\tif (error) {\n\t\t\t\t\tspprintf(error, 4096, \"phar error: \\\"%s\\\" is a corrupted tar file (truncated)\", fname);\n\t\t\t\t}\n\t\t\t\tphp_stream_close(fp);\n\t\t\t\tphar_destroy_phar_data(myphar TSRMLS_CC);\n\t\t\t\treturn FAILURE;\n\t\t\t}\n\n\t\t\thdr = (tar_header*) buf;\n\t\t\tsum1 = phar_tar_number(hdr->checksum, sizeof(hdr->checksum));\n\n\t\t\tif (sum1 == 0 && phar_tar_checksum(buf, sizeof(buf)) == 0) {\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tif (error) {\n\t\t\t\tspprintf(error, 4096, \"phar error: \\\"%s\\\" has entries after signature, invalid phar\", fname);\n\t\t\t}\n\n\t\t\tgoto bail;\n\t\t}\n\n\t\tif (!last_was_longlink && hdr->typeflag == 'L') {\n\t\t\tlast_was_longlink = 1;\n\t\t\t/* support the ././@LongLink system for storing long filenames */\n\t\t\tentry.filename_len = entry.uncompressed_filesize;\n\n\t\t\t/* Check for overflow - bug 61065 */\n\t\t\tif (entry.filename_len == UINT_MAX) {\n\t\t\t\tif (error) {\n\t\t\t\t\tspprintf(error, 4096, \"phar error: \\\"%s\\\" is a corrupted tar file (invalid entry size)\", fname);\n\t\t\t\t}\n\t\t\t\tphp_stream_close(fp);\n\t\t\t\tphar_destroy_phar_data(myphar TSRMLS_CC);\n\t\t\t\treturn FAILURE;\n\t\t\t}\n\t\t\tentry.filename = pemalloc(entry.filename_len+1, myphar->is_persistent);\n\n\t\t\tread = php_stream_read(fp, entry.filename, entry.filename_len);\n\t\t\tif (read != entry.filename_len) {\n\t\t\t\tefree(entry.filename);\n\t\t\t\tif (error) {\n\t\t\t\t\tspprintf(error, 4096, \"phar error: \\\"%s\\\" is a corrupted tar file (truncated)\", fname);\n\t\t\t\t}\n\t\t\t\tphp_stream_close(fp);\n\t\t\t\tphar_destroy_phar_data(myphar TSRMLS_CC);\n\t\t\t\treturn FAILURE;\n\t\t\t}\n\t\t\tentry.filename[entry.filename_len] = '\\0';\n\n\t\t\t/* skip blank stuff */\n\t\t\tsize = ((size+511)&~511) - size;\n\n\t\t\t/* this is not good enough - seek succeeds even on truncated tars */\n\t\t\tphp_stream_seek(fp, size, SEEK_CUR);\n\t\t\tif ((uint)php_stream_tell(fp) > totalsize) {\n\t\t\t\tefree(entry.filename);\n\t\t\t\tif (error) {\n\t\t\t\t\tspprintf(error, 4096, \"phar error: \\\"%s\\\" is a corrupted tar file (truncated)\", fname);\n\t\t\t\t}\n\t\t\t\tphp_stream_close(fp);\n\t\t\t\tphar_destroy_phar_data(myphar TSRMLS_CC);\n\t\t\t\treturn FAILURE;\n\t\t\t}\n\n\t\t\tread = php_stream_read(fp, buf, sizeof(buf));\n\n\t\t\tif (read != sizeof(buf)) {\n\t\t\t\tefree(entry.filename);\n\t\t\t\tif (error) {\n\t\t\t\t\tspprintf(error, 4096, \"phar error: \\\"%s\\\" is a corrupted tar file (truncated)\", fname);\n\t\t\t\t}\n\t\t\t\tphp_stream_close(fp);\n\t\t\t\tphar_destroy_phar_data(myphar TSRMLS_CC);\n\t\t\t\treturn FAILURE;\n\t\t\t}\n\t\t\tcontinue;\n\t\t} else if (!last_was_longlink && !old && hdr->prefix[0] != 0) {\n\t\t\tchar name[256];\n\t\t\tint i, j;\n\n\t\t\tfor (i = 0; i < 155; i++) {\n\t\t\t\tname[i] = hdr->prefix[i];\n\t\t\t\tif (name[i] == '\\0') {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tname[i++] = '/';\n\t\t\tfor (j = 0; j < 100; j++) {\n\t\t\t\tname[i+j] = hdr->name[j];\n\t\t\t\tif (name[i+j] == '\\0') {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tentry.filename_len = i+j;\n\n\t\t\tif (name[entry.filename_len - 1] == '/') {\n\t\t\t\t/* some tar programs store directories with trailing slash */\n\t\t\t\tentry.filename_len--;\n\t\t\t}\n\t\t\tentry.filename = pestrndup(name, entry.filename_len, myphar->is_persistent);\n\t\t} else if (!last_was_longlink) {\n\t\t\tint i;\n\n\t\t\t/* calculate strlen, which can be no longer than 100 */\n\t\t\tfor (i = 0; i < 100; i++) {\n\t\t\t\tif (hdr->name[i] == '\\0') {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tentry.filename_len = i;\n\t\t\tentry.filename = pestrndup(hdr->name, i, myphar->is_persistent);\n\n\t\t\tif (i > 0 && entry.filename[entry.filename_len - 1] == '/') {\n\t\t\t\t/* some tar programs store directories with trailing slash */\n\t\t\t\tentry.filename[entry.filename_len - 1] = '\\0';\n\t\t\t\tentry.filename_len--;\n\t\t\t}\n\t\t}\n\t\tlast_was_longlink = 0;\n\n\t\tphar_add_virtual_dirs(myphar, entry.filename, entry.filename_len TSRMLS_CC);\n\n\t\tif (sum1 != sum2) {\n\t\t\tif (error) {\n\t\t\t\tspprintf(error, 4096, \"phar error: \\\"%s\\\" is a corrupted tar file (checksum mismatch of file \\\"%s\\\")\", fname, entry.filename);\n\t\t\t}\n\t\t\tpefree(entry.filename, myphar->is_persistent);\n\t\t\tphp_stream_close(fp);\n\t\t\tphar_destroy_phar_data(myphar TSRMLS_CC);\n\t\t\treturn FAILURE;\n\t\t}\n\n\t\tentry.tar_type = ((old & (hdr->typeflag == '\\0')) ? TAR_FILE : hdr->typeflag);\n\t\tentry.offset = entry.offset_abs = pos; /* header_offset unused in tar */\n\t\tentry.fp_type = PHAR_FP;\n\t\tentry.flags = phar_tar_number(hdr->mode, sizeof(hdr->mode)) & PHAR_ENT_PERM_MASK;\n\t\tentry.timestamp = phar_tar_number(hdr->mtime, sizeof(hdr->mtime));\n\t\tentry.is_persistent = myphar->is_persistent;\n#ifndef S_ISDIR\n#define S_ISDIR(mode)\t(((mode)&S_IFMT) == S_IFDIR)\n#endif\n\t\tif (old && entry.tar_type == TAR_FILE && S_ISDIR(entry.flags)) {\n\t\t\tentry.tar_type = TAR_DIR;\n\t\t}\n\n\t\tif (entry.tar_type == TAR_DIR) {\n\t\t\tentry.is_dir = 1;\n\t\t} else {\n\t\t\tentry.is_dir = 0;\n\t\t}\n\n\t\tentry.link = NULL;\n\t\t/* link field is null-terminated unless it has 100 non-null chars.\n\t\t * Thus we can not use strlen. */\n\t\tlinkname_len = strnlen(hdr->linkname, 100);\n\t\tif (entry.tar_type == TAR_LINK) {\n\t\t\tif (!zend_hash_exists(&myphar->manifest, hdr->linkname, linkname_len)) {\n\t\t\t\tif (error) {\n\t\t\t\t\tspprintf(error, 4096, \"phar error: \\\"%s\\\" is a corrupted tar file - hard link to non-existent file \\\"%.*s\\\"\", fname, linkname_len, hdr->linkname);\n\t\t\t\t}\n\t\t\t\tpefree(entry.filename, entry.is_persistent);\n\t\t\t\tphp_stream_close(fp);\n\t\t\t\tphar_destroy_phar_data(myphar TSRMLS_CC);\n\t\t\t\treturn FAILURE;\n\t\t\t}\n\t\t\tentry.link = estrndup(hdr->linkname, linkname_len);\n\t\t} else if (entry.tar_type == TAR_SYMLINK) {\n\t\t\tentry.link = estrndup(hdr->linkname, linkname_len);\n\t\t}\n\t\tphar_set_inode(&entry TSRMLS_CC);\n\t\tzend_hash_add(&myphar->manifest, entry.filename, entry.filename_len, (void*)&entry, sizeof(phar_entry_info), (void **) &newentry);\n\n\t\tif (entry.is_persistent) {\n\t\t\t++entry.manifest_pos;\n\t\t}\n\n\t\tif (entry.filename_len >= sizeof(\".phar/.metadata\")-1 && !memcmp(entry.filename, \".phar/.metadata\", sizeof(\".phar/.metadata\")-1)) {\n\t\t\tif (FAILURE == phar_tar_process_metadata(newentry, fp TSRMLS_CC)) {\n\t\t\t\tif (error) {\n\t\t\t\t\tspprintf(error, 4096, \"phar error: tar-based phar \\\"%s\\\" has invalid metadata in magic file \\\"%s\\\"\", fname, entry.filename);\n\t\t\t\t}\n\t\t\t\tphp_stream_close(fp);\n\t\t\t\tphar_destroy_phar_data(myphar TSRMLS_CC);\n\t\t\t\treturn FAILURE;\n\t\t\t}\n\t\t}\n\n\t\tif (!actual_alias && entry.filename_len == sizeof(\".phar/alias.txt\")-1 && !strncmp(entry.filename, \".phar/alias.txt\", sizeof(\".phar/alias.txt\")-1)) {\n\t\t\t/* found explicit alias */\n\t\t\tif (size > 511) {\n\t\t\t\tif (error) {\n\t\t\t\t\tspprintf(error, 4096, \"phar error: tar-based phar \\\"%s\\\" has alias that is larger than 511 bytes, cannot process\", fname);\n\t\t\t\t}\n\t\t\t\tphp_stream_close(fp);\n\t\t\t\tphar_destroy_phar_data(myphar TSRMLS_CC);\n\t\t\t\treturn FAILURE;\n\t\t\t}\n\n\t\t\tread = php_stream_read(fp, buf, size);\n\n\t\t\tif (read == size) {\n\t\t\t\tbuf[size] = '\\0';\n\t\t\t\tif (!phar_validate_alias(buf, size)) {\n\t\t\t\t\tif (size > 50) {\n\t\t\t\t\t\tbuf[50] = '.';\n\t\t\t\t\t\tbuf[51] = '.';\n\t\t\t\t\t\tbuf[52] = '.';\n\t\t\t\t\t\tbuf[53] = '\\0';\n\t\t\t\t\t}\n\n\t\t\t\t\tif (error) {\n\t\t\t\t\t\tspprintf(error, 4096, \"phar error: invalid alias \\\"%s\\\" in tar-based phar \\\"%s\\\"\", buf, fname);\n\t\t\t\t\t}\n\n\t\t\t\t\tphp_stream_close(fp);\n\t\t\t\t\tphar_destroy_phar_data(myphar TSRMLS_CC);\n\t\t\t\t\treturn FAILURE;\n\t\t\t\t}\n\n\t\t\t\tactual_alias = pestrndup(buf, size, myphar->is_persistent);\n\t\t\t\tmyphar->alias = actual_alias;\n\t\t\t\tmyphar->alias_len = size;\n\t\t\t\tphp_stream_seek(fp, pos, SEEK_SET);\n\t\t\t} else {\n\t\t\t\tif (error) {\n\t\t\t\t\tspprintf(error, 4096, \"phar error: Unable to read alias from tar-based phar \\\"%s\\\"\", fname);\n\t\t\t\t}\n\n\t\t\t\tphp_stream_close(fp);\n\t\t\t\tphar_destroy_phar_data(myphar TSRMLS_CC);\n\t\t\t\treturn FAILURE;\n\t\t\t}\n\t\t}\n\n\t\tsize = (size+511)&~511;\n\n\t\tif (((hdr->typeflag == '\\0') || (hdr->typeflag == TAR_FILE)) && size > 0) {\nnext:\n\t\t\t/* this is not good enough - seek succeeds even on truncated tars */\n\t\t\tphp_stream_seek(fp, size, SEEK_CUR);\n\t\t\tif ((uint)php_stream_tell(fp) > totalsize) {\n\t\t\t\tif (error) {\n\t\t\t\t\tspprintf(error, 4096, \"phar error: \\\"%s\\\" is a corrupted tar file (truncated)\", fname);\n\t\t\t\t}\n\t\t\t\tphp_stream_close(fp);\n\t\t\t\tphar_destroy_phar_data(myphar TSRMLS_CC);\n\t\t\t\treturn FAILURE;\n\t\t\t}\n\t\t}\n\n\t\tread = php_stream_read(fp, buf, sizeof(buf));\n\n\t\tif (read != sizeof(buf)) {\n\t\t\tif (error) {\n\t\t\t\tspprintf(error, 4096, \"phar error: \\\"%s\\\" is a corrupted tar file (truncated)\", fname);\n\t\t\t}\n\t\t\tphp_stream_close(fp);\n\t\t\tphar_destroy_phar_data(myphar TSRMLS_CC);\n\t\t\treturn FAILURE;\n\t\t}\n\t} while (read != 0);\n\n\tif (zend_hash_exists(&(myphar->manifest), \".phar/stub.php\", sizeof(\".phar/stub.php\")-1)) {\n\t\tmyphar->is_data = 0;\n\t} else {\n\t\tmyphar->is_data = 1;\n\t}\n\n\t/* ensure signature set */\n\tif (!myphar->is_data && PHAR_G(require_hash) && !myphar->signature) {\n\t\tphp_stream_close(fp);\n\t\tphar_destroy_phar_data(myphar TSRMLS_CC);\n\t\tif (error) {\n\t\t\tspprintf(error, 0, \"tar-based phar \\\"%s\\\" does not have a signature\", fname);\n\t\t}\n\t\treturn FAILURE;\n\t}\n\n\tmyphar->fname = pestrndup(fname, fname_len, myphar->is_persistent);\n#ifdef PHP_WIN32\n\tphar_unixify_path_separators(myphar->fname, fname_len);\n#endif\n\tmyphar->fname_len = fname_len;\n\tmyphar->fp = fp;\n\tp = strrchr(myphar->fname, '/');\n\n\tif (p) {\n\t\tmyphar->ext = memchr(p, '.', (myphar->fname + fname_len) - p);\n\t\tif (myphar->ext == p) {\n\t\t\tmyphar->ext = memchr(p + 1, '.', (myphar->fname + fname_len) - p - 1);\n\t\t}\n\t\tif (myphar->ext) {\n\t\t\tmyphar->ext_len = (myphar->fname + fname_len) - myphar->ext;\n\t\t}\n\t}\n\n\tphar_request_initialize(TSRMLS_C);\n\n\tif (SUCCESS != zend_hash_add(&(PHAR_GLOBALS->phar_fname_map), myphar->fname, fname_len, (void*)&myphar, sizeof(phar_archive_data*), (void **)&actual)) {\n\t\tif (error) {\n\t\t\tspprintf(error, 4096, \"phar error: Unable to add tar-based phar \\\"%s\\\" to phar registry\", fname);\n\t\t}\n\t\tphp_stream_close(fp);\n\t\tphar_destroy_phar_data(myphar TSRMLS_CC);\n\t\treturn FAILURE;\n\t}\n\n\tmyphar = *actual;\n\n\tif (actual_alias) {\n\t\tphar_archive_data **fd_ptr;\n\n\t\tmyphar->is_temporary_alias = 0;\n\n\t\tif (SUCCESS == zend_hash_find(&(PHAR_GLOBALS->phar_alias_map), actual_alias, myphar->alias_len, (void **)&fd_ptr)) {\n\t\t\tif (SUCCESS != phar_free_alias(*fd_ptr, actual_alias, myphar->alias_len TSRMLS_CC)) {\n\t\t\t\tif (error) {\n\t\t\t\t\tspprintf(error, 4096, \"phar error: Unable to add tar-based phar \\\"%s\\\", alias is already in use\", fname);\n\t\t\t\t}\n\t\t\t\tzend_hash_del(&(PHAR_GLOBALS->phar_fname_map), myphar->fname, fname_len);\n\t\t\t\treturn FAILURE;\n\t\t\t}\n\t\t}\n\n\t\tzend_hash_add(&(PHAR_GLOBALS->phar_alias_map), actual_alias, myphar->alias_len, (void*)&myphar, sizeof(phar_archive_data*), NULL);\n\t} else {\n\t\tphar_archive_data **fd_ptr;\n\n\t\tif (alias_len) {\n\t\t\tif (SUCCESS == zend_hash_find(&(PHAR_GLOBALS->phar_alias_map), alias, alias_len, (void **)&fd_ptr)) {\n\t\t\t\tif (SUCCESS != phar_free_alias(*fd_ptr, alias, alias_len TSRMLS_CC)) {\n\t\t\t\t\tif (error) {\n\t\t\t\t\t\tspprintf(error, 4096, \"phar error: Unable to add tar-based phar \\\"%s\\\", alias is already in use\", fname);\n\t\t\t\t\t}\n\t\t\t\t\tzend_hash_del(&(PHAR_GLOBALS->phar_fname_map), myphar->fname, fname_len);\n\t\t\t\t\treturn FAILURE;\n\t\t\t\t}\n\t\t\t}\n\t\t\tzend_hash_add(&(PHAR_GLOBALS->phar_alias_map), alias, alias_len, (void*)&myphar, sizeof(phar_archive_data*), NULL);\n\t\t\tmyphar->alias = pestrndup(alias, alias_len, myphar->is_persistent);\n\t\t\tmyphar->alias_len = alias_len;\n\t\t} else {\n\t\t\tmyphar->alias = pestrndup(myphar->fname, fname_len, myphar->is_persistent);\n\t\t\tmyphar->alias_len = fname_len;\n\t\t}\n\n\t\tmyphar->is_temporary_alias = 1;\n\t}\n\n\tif (pphar) {\n\t\t*pphar = myphar;\n\t}\n\n\treturn SUCCESS;\n}",
        "func": "int phar_parse_tarfile(php_stream* fp, char *fname, int fname_len, char *alias, int alias_len, phar_archive_data** pphar, int is_data, php_uint32 compression, char **error TSRMLS_DC) /* {{{ */\n{\n\tchar buf[512], *actual_alias = NULL, *p;\n\tphar_entry_info entry = {0};\n\tsize_t pos = 0, read, totalsize;\n\ttar_header *hdr;\n\tphp_uint32 sum1, sum2, size, old;\n\tphar_archive_data *myphar, **actual;\n\tint last_was_longlink = 0;\n\tint linkname_len;\n\n\tif (error) {\n\t\t*error = NULL;\n\t}\n\n\tphp_stream_seek(fp, 0, SEEK_END);\n\ttotalsize = php_stream_tell(fp);\n\tphp_stream_seek(fp, 0, SEEK_SET);\n\tread = php_stream_read(fp, buf, sizeof(buf));\n\n\tif (read != sizeof(buf)) {\n\t\tif (error) {\n\t\t\tspprintf(error, 4096, \"phar error: \\\"%s\\\" is not a tar file or is truncated\", fname);\n\t\t}\n\t\tphp_stream_close(fp);\n\t\treturn FAILURE;\n\t}\n\n\thdr = (tar_header*)buf;\n\told = (memcmp(hdr->magic, \"ustar\", sizeof(\"ustar\")-1) != 0);\n\n\tmyphar = (phar_archive_data *) pecalloc(1, sizeof(phar_archive_data), PHAR_G(persist));\n\tmyphar->is_persistent = PHAR_G(persist);\n\t/* estimate number of entries, can't be certain with tar files */\n\tzend_hash_init(&myphar->manifest, 2 + (totalsize >> 12),\n\t\tzend_get_hash_value, destroy_phar_manifest_entry, (zend_bool)myphar->is_persistent);\n\tzend_hash_init(&myphar->mounted_dirs, 5,\n\t\tzend_get_hash_value, NULL, (zend_bool)myphar->is_persistent);\n\tzend_hash_init(&myphar->virtual_dirs, 4 + (totalsize >> 11),\n\t\tzend_get_hash_value, NULL, (zend_bool)myphar->is_persistent);\n\tmyphar->is_tar = 1;\n\t/* remember whether this entire phar was compressed with gz/bzip2 */\n\tmyphar->flags = compression;\n\n\tentry.is_tar = 1;\n\tentry.is_crc_checked = 1;\n\tentry.phar = myphar;\n\tpos += sizeof(buf);\n\n\tdo {\n\t\tphar_entry_info *newentry;\n\n\t\tpos = php_stream_tell(fp);\n\t\thdr = (tar_header*) buf;\n\t\tsum1 = phar_tar_number(hdr->checksum, sizeof(hdr->checksum));\n\t\tif (sum1 == 0 && phar_tar_checksum(buf, sizeof(buf)) == 0) {\n\t\t\tbreak;\n\t\t}\n\t\tmemset(hdr->checksum, ' ', sizeof(hdr->checksum));\n\t\tsum2 = phar_tar_checksum(buf, old?sizeof(old_tar_header):sizeof(tar_header));\n\n\t\tsize = entry.uncompressed_filesize = entry.compressed_filesize =\n\t\t\tphar_tar_number(hdr->size, sizeof(hdr->size));\n\n\t\t/* skip global/file headers (pax) */\n\t\tif (!old && (hdr->typeflag == TAR_GLOBAL_HDR || hdr->typeflag == TAR_FILE_HDR)) {\n\t\t\tsize = (size+511)&~511;\n\t\t\tgoto next;\n\t\t}\n\n\t\tif (((!old && hdr->prefix[0] == 0) || old) && strnlen(hdr->name, 100) == sizeof(\".phar/signature.bin\")-1 && !strncmp(hdr->name, \".phar/signature.bin\", sizeof(\".phar/signature.bin\")-1)) {\n\t\t\toff_t curloc;\n\n\t\t\tif (size > 511) {\n\t\t\t\tif (error) {\n\t\t\t\t\tspprintf(error, 4096, \"phar error: tar-based phar \\\"%s\\\" has signature that is larger than 511 bytes, cannot process\", fname);\n\t\t\t\t}\nbail:\n\t\t\t\tphp_stream_close(fp);\n\t\t\t\tphar_destroy_phar_data(myphar TSRMLS_CC);\n\t\t\t\treturn FAILURE;\n\t\t\t}\n\t\t\tcurloc = php_stream_tell(fp);\n\t\t\tread = php_stream_read(fp, buf, size);\n\t\t\tif (read != size) {\n\t\t\t\tif (error) {\n\t\t\t\t\tspprintf(error, 4096, \"phar error: tar-based phar \\\"%s\\\" signature cannot be read\", fname);\n\t\t\t\t}\n\t\t\t\tgoto bail;\n\t\t\t}\n#ifdef WORDS_BIGENDIAN\n# define PHAR_GET_32(buffer) \\\n\t(((((unsigned char*)(buffer))[3]) << 24) \\\n\t\t| ((((unsigned char*)(buffer))[2]) << 16) \\\n\t\t| ((((unsigned char*)(buffer))[1]) <<  8) \\\n\t\t| (((unsigned char*)(buffer))[0]))\n#else\n# define PHAR_GET_32(buffer) (php_uint32) *(buffer)\n#endif\n\t\t\tmyphar->sig_flags = PHAR_GET_32(buf);\n\t\t\tif (FAILURE == phar_verify_signature(fp, php_stream_tell(fp) - size - 512, myphar->sig_flags, buf + 8, size - 8, fname, &myphar->signature, &myphar->sig_len, error TSRMLS_CC)) {\n\t\t\t\tif (error) {\n\t\t\t\t\tchar *save = *error;\n\t\t\t\t\tspprintf(error, 4096, \"phar error: tar-based phar \\\"%s\\\" signature cannot be verified: %s\", fname, save);\n\t\t\t\t\tefree(save);\n\t\t\t\t}\n\t\t\t\tgoto bail;\n\t\t\t}\n\t\t\tphp_stream_seek(fp, curloc + 512, SEEK_SET);\n\t\t\t/* signature checked out, let's ensure this is the last file in the phar */\n\t\t\tif (((hdr->typeflag == '\\0') || (hdr->typeflag == TAR_FILE)) && size > 0) {\n\t\t\t\t/* this is not good enough - seek succeeds even on truncated tars */\n\t\t\t\tphp_stream_seek(fp, 512, SEEK_CUR);\n\t\t\t\tif ((uint)php_stream_tell(fp) > totalsize) {\n\t\t\t\t\tif (error) {\n\t\t\t\t\t\tspprintf(error, 4096, \"phar error: \\\"%s\\\" is a corrupted tar file (truncated)\", fname);\n\t\t\t\t\t}\n\t\t\t\t\tphp_stream_close(fp);\n\t\t\t\t\tphar_destroy_phar_data(myphar TSRMLS_CC);\n\t\t\t\t\treturn FAILURE;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tread = php_stream_read(fp, buf, sizeof(buf));\n\n\t\t\tif (read != sizeof(buf)) {\n\t\t\t\tif (error) {\n\t\t\t\t\tspprintf(error, 4096, \"phar error: \\\"%s\\\" is a corrupted tar file (truncated)\", fname);\n\t\t\t\t}\n\t\t\t\tphp_stream_close(fp);\n\t\t\t\tphar_destroy_phar_data(myphar TSRMLS_CC);\n\t\t\t\treturn FAILURE;\n\t\t\t}\n\n\t\t\thdr = (tar_header*) buf;\n\t\t\tsum1 = phar_tar_number(hdr->checksum, sizeof(hdr->checksum));\n\n\t\t\tif (sum1 == 0 && phar_tar_checksum(buf, sizeof(buf)) == 0) {\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tif (error) {\n\t\t\t\tspprintf(error, 4096, \"phar error: \\\"%s\\\" has entries after signature, invalid phar\", fname);\n\t\t\t}\n\n\t\t\tgoto bail;\n\t\t}\n\n\t\tif (!last_was_longlink && hdr->typeflag == 'L') {\n\t\t\tlast_was_longlink = 1;\n\t\t\t/* support the ././@LongLink system for storing long filenames */\n\t\t\tentry.filename_len = entry.uncompressed_filesize;\n\n\t\t\t/* Check for overflow - bug 61065 */\n\t\t\tif (entry.filename_len == UINT_MAX || entry.filename_len == 0) {\n\t\t\t\tif (error) {\n\t\t\t\t\tspprintf(error, 4096, \"phar error: \\\"%s\\\" is a corrupted tar file (invalid entry size)\", fname);\n\t\t\t\t}\n\t\t\t\tphp_stream_close(fp);\n\t\t\t\tphar_destroy_phar_data(myphar TSRMLS_CC);\n\t\t\t\treturn FAILURE;\n\t\t\t}\n\t\t\tentry.filename = pemalloc(entry.filename_len+1, myphar->is_persistent);\n\n\t\t\tread = php_stream_read(fp, entry.filename, entry.filename_len);\n\t\t\tif (read != entry.filename_len) {\n\t\t\t\tefree(entry.filename);\n\t\t\t\tif (error) {\n\t\t\t\t\tspprintf(error, 4096, \"phar error: \\\"%s\\\" is a corrupted tar file (truncated)\", fname);\n\t\t\t\t}\n\t\t\t\tphp_stream_close(fp);\n\t\t\t\tphar_destroy_phar_data(myphar TSRMLS_CC);\n\t\t\t\treturn FAILURE;\n\t\t\t}\n\t\t\tentry.filename[entry.filename_len] = '\\0';\n\n\t\t\t/* skip blank stuff */\n\t\t\tsize = ((size+511)&~511) - size;\n\n\t\t\t/* this is not good enough - seek succeeds even on truncated tars */\n\t\t\tphp_stream_seek(fp, size, SEEK_CUR);\n\t\t\tif ((uint)php_stream_tell(fp) > totalsize) {\n\t\t\t\tefree(entry.filename);\n\t\t\t\tif (error) {\n\t\t\t\t\tspprintf(error, 4096, \"phar error: \\\"%s\\\" is a corrupted tar file (truncated)\", fname);\n\t\t\t\t}\n\t\t\t\tphp_stream_close(fp);\n\t\t\t\tphar_destroy_phar_data(myphar TSRMLS_CC);\n\t\t\t\treturn FAILURE;\n\t\t\t}\n\n\t\t\tread = php_stream_read(fp, buf, sizeof(buf));\n\n\t\t\tif (read != sizeof(buf)) {\n\t\t\t\tefree(entry.filename);\n\t\t\t\tif (error) {\n\t\t\t\t\tspprintf(error, 4096, \"phar error: \\\"%s\\\" is a corrupted tar file (truncated)\", fname);\n\t\t\t\t}\n\t\t\t\tphp_stream_close(fp);\n\t\t\t\tphar_destroy_phar_data(myphar TSRMLS_CC);\n\t\t\t\treturn FAILURE;\n\t\t\t}\n\t\t\tcontinue;\n\t\t} else if (!last_was_longlink && !old && hdr->prefix[0] != 0) {\n\t\t\tchar name[256];\n\t\t\tint i, j;\n\n\t\t\tfor (i = 0; i < 155; i++) {\n\t\t\t\tname[i] = hdr->prefix[i];\n\t\t\t\tif (name[i] == '\\0') {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tname[i++] = '/';\n\t\t\tfor (j = 0; j < 100; j++) {\n\t\t\t\tname[i+j] = hdr->name[j];\n\t\t\t\tif (name[i+j] == '\\0') {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tentry.filename_len = i+j;\n\n\t\t\tif (name[entry.filename_len - 1] == '/') {\n\t\t\t\t/* some tar programs store directories with trailing slash */\n\t\t\t\tentry.filename_len--;\n\t\t\t}\n\t\t\tentry.filename = pestrndup(name, entry.filename_len, myphar->is_persistent);\n\t\t} else if (!last_was_longlink) {\n\t\t\tint i;\n\n\t\t\t/* calculate strlen, which can be no longer than 100 */\n\t\t\tfor (i = 0; i < 100; i++) {\n\t\t\t\tif (hdr->name[i] == '\\0') {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tentry.filename_len = i;\n\t\t\tentry.filename = pestrndup(hdr->name, i, myphar->is_persistent);\n\n\t\t\tif (i > 0 && entry.filename[entry.filename_len - 1] == '/') {\n\t\t\t\t/* some tar programs store directories with trailing slash */\n\t\t\t\tentry.filename[entry.filename_len - 1] = '\\0';\n\t\t\t\tentry.filename_len--;\n\t\t\t}\n\t\t}\n\t\tlast_was_longlink = 0;\n\n\t\tphar_add_virtual_dirs(myphar, entry.filename, entry.filename_len TSRMLS_CC);\n\n\t\tif (sum1 != sum2) {\n\t\t\tif (error) {\n\t\t\t\tspprintf(error, 4096, \"phar error: \\\"%s\\\" is a corrupted tar file (checksum mismatch of file \\\"%s\\\")\", fname, entry.filename);\n\t\t\t}\n\t\t\tpefree(entry.filename, myphar->is_persistent);\n\t\t\tphp_stream_close(fp);\n\t\t\tphar_destroy_phar_data(myphar TSRMLS_CC);\n\t\t\treturn FAILURE;\n\t\t}\n\n\t\tentry.tar_type = ((old & (hdr->typeflag == '\\0')) ? TAR_FILE : hdr->typeflag);\n\t\tentry.offset = entry.offset_abs = pos; /* header_offset unused in tar */\n\t\tentry.fp_type = PHAR_FP;\n\t\tentry.flags = phar_tar_number(hdr->mode, sizeof(hdr->mode)) & PHAR_ENT_PERM_MASK;\n\t\tentry.timestamp = phar_tar_number(hdr->mtime, sizeof(hdr->mtime));\n\t\tentry.is_persistent = myphar->is_persistent;\n#ifndef S_ISDIR\n#define S_ISDIR(mode)\t(((mode)&S_IFMT) == S_IFDIR)\n#endif\n\t\tif (old && entry.tar_type == TAR_FILE && S_ISDIR(entry.flags)) {\n\t\t\tentry.tar_type = TAR_DIR;\n\t\t}\n\n\t\tif (entry.tar_type == TAR_DIR) {\n\t\t\tentry.is_dir = 1;\n\t\t} else {\n\t\t\tentry.is_dir = 0;\n\t\t}\n\n\t\tentry.link = NULL;\n\t\t/* link field is null-terminated unless it has 100 non-null chars.\n\t\t * Thus we can not use strlen. */\n\t\tlinkname_len = strnlen(hdr->linkname, 100);\n\t\tif (entry.tar_type == TAR_LINK) {\n\t\t\tif (!zend_hash_exists(&myphar->manifest, hdr->linkname, linkname_len)) {\n\t\t\t\tif (error) {\n\t\t\t\t\tspprintf(error, 4096, \"phar error: \\\"%s\\\" is a corrupted tar file - hard link to non-existent file \\\"%.*s\\\"\", fname, linkname_len, hdr->linkname);\n\t\t\t\t}\n\t\t\t\tpefree(entry.filename, entry.is_persistent);\n\t\t\t\tphp_stream_close(fp);\n\t\t\t\tphar_destroy_phar_data(myphar TSRMLS_CC);\n\t\t\t\treturn FAILURE;\n\t\t\t}\n\t\t\tentry.link = estrndup(hdr->linkname, linkname_len);\n\t\t} else if (entry.tar_type == TAR_SYMLINK) {\n\t\t\tentry.link = estrndup(hdr->linkname, linkname_len);\n\t\t}\n\t\tphar_set_inode(&entry TSRMLS_CC);\n\t\tzend_hash_add(&myphar->manifest, entry.filename, entry.filename_len, (void*)&entry, sizeof(phar_entry_info), (void **) &newentry);\n\n\t\tif (entry.is_persistent) {\n\t\t\t++entry.manifest_pos;\n\t\t}\n\n\t\tif (entry.filename_len >= sizeof(\".phar/.metadata\")-1 && !memcmp(entry.filename, \".phar/.metadata\", sizeof(\".phar/.metadata\")-1)) {\n\t\t\tif (FAILURE == phar_tar_process_metadata(newentry, fp TSRMLS_CC)) {\n\t\t\t\tif (error) {\n\t\t\t\t\tspprintf(error, 4096, \"phar error: tar-based phar \\\"%s\\\" has invalid metadata in magic file \\\"%s\\\"\", fname, entry.filename);\n\t\t\t\t}\n\t\t\t\tphp_stream_close(fp);\n\t\t\t\tphar_destroy_phar_data(myphar TSRMLS_CC);\n\t\t\t\treturn FAILURE;\n\t\t\t}\n\t\t}\n\n\t\tif (!actual_alias && entry.filename_len == sizeof(\".phar/alias.txt\")-1 && !strncmp(entry.filename, \".phar/alias.txt\", sizeof(\".phar/alias.txt\")-1)) {\n\t\t\t/* found explicit alias */\n\t\t\tif (size > 511) {\n\t\t\t\tif (error) {\n\t\t\t\t\tspprintf(error, 4096, \"phar error: tar-based phar \\\"%s\\\" has alias that is larger than 511 bytes, cannot process\", fname);\n\t\t\t\t}\n\t\t\t\tphp_stream_close(fp);\n\t\t\t\tphar_destroy_phar_data(myphar TSRMLS_CC);\n\t\t\t\treturn FAILURE;\n\t\t\t}\n\n\t\t\tread = php_stream_read(fp, buf, size);\n\n\t\t\tif (read == size) {\n\t\t\t\tbuf[size] = '\\0';\n\t\t\t\tif (!phar_validate_alias(buf, size)) {\n\t\t\t\t\tif (size > 50) {\n\t\t\t\t\t\tbuf[50] = '.';\n\t\t\t\t\t\tbuf[51] = '.';\n\t\t\t\t\t\tbuf[52] = '.';\n\t\t\t\t\t\tbuf[53] = '\\0';\n\t\t\t\t\t}\n\n\t\t\t\t\tif (error) {\n\t\t\t\t\t\tspprintf(error, 4096, \"phar error: invalid alias \\\"%s\\\" in tar-based phar \\\"%s\\\"\", buf, fname);\n\t\t\t\t\t}\n\n\t\t\t\t\tphp_stream_close(fp);\n\t\t\t\t\tphar_destroy_phar_data(myphar TSRMLS_CC);\n\t\t\t\t\treturn FAILURE;\n\t\t\t\t}\n\n\t\t\t\tactual_alias = pestrndup(buf, size, myphar->is_persistent);\n\t\t\t\tmyphar->alias = actual_alias;\n\t\t\t\tmyphar->alias_len = size;\n\t\t\t\tphp_stream_seek(fp, pos, SEEK_SET);\n\t\t\t} else {\n\t\t\t\tif (error) {\n\t\t\t\t\tspprintf(error, 4096, \"phar error: Unable to read alias from tar-based phar \\\"%s\\\"\", fname);\n\t\t\t\t}\n\n\t\t\t\tphp_stream_close(fp);\n\t\t\t\tphar_destroy_phar_data(myphar TSRMLS_CC);\n\t\t\t\treturn FAILURE;\n\t\t\t}\n\t\t}\n\n\t\tsize = (size+511)&~511;\n\n\t\tif (((hdr->typeflag == '\\0') || (hdr->typeflag == TAR_FILE)) && size > 0) {\nnext:\n\t\t\t/* this is not good enough - seek succeeds even on truncated tars */\n\t\t\tphp_stream_seek(fp, size, SEEK_CUR);\n\t\t\tif ((uint)php_stream_tell(fp) > totalsize) {\n\t\t\t\tif (error) {\n\t\t\t\t\tspprintf(error, 4096, \"phar error: \\\"%s\\\" is a corrupted tar file (truncated)\", fname);\n\t\t\t\t}\n\t\t\t\tphp_stream_close(fp);\n\t\t\t\tphar_destroy_phar_data(myphar TSRMLS_CC);\n\t\t\t\treturn FAILURE;\n\t\t\t}\n\t\t}\n\n\t\tread = php_stream_read(fp, buf, sizeof(buf));\n\n\t\tif (read != sizeof(buf)) {\n\t\t\tif (error) {\n\t\t\t\tspprintf(error, 4096, \"phar error: \\\"%s\\\" is a corrupted tar file (truncated)\", fname);\n\t\t\t}\n\t\t\tphp_stream_close(fp);\n\t\t\tphar_destroy_phar_data(myphar TSRMLS_CC);\n\t\t\treturn FAILURE;\n\t\t}\n\t} while (read != 0);\n\n\tif (zend_hash_exists(&(myphar->manifest), \".phar/stub.php\", sizeof(\".phar/stub.php\")-1)) {\n\t\tmyphar->is_data = 0;\n\t} else {\n\t\tmyphar->is_data = 1;\n\t}\n\n\t/* ensure signature set */\n\tif (!myphar->is_data && PHAR_G(require_hash) && !myphar->signature) {\n\t\tphp_stream_close(fp);\n\t\tphar_destroy_phar_data(myphar TSRMLS_CC);\n\t\tif (error) {\n\t\t\tspprintf(error, 0, \"tar-based phar \\\"%s\\\" does not have a signature\", fname);\n\t\t}\n\t\treturn FAILURE;\n\t}\n\n\tmyphar->fname = pestrndup(fname, fname_len, myphar->is_persistent);\n#ifdef PHP_WIN32\n\tphar_unixify_path_separators(myphar->fname, fname_len);\n#endif\n\tmyphar->fname_len = fname_len;\n\tmyphar->fp = fp;\n\tp = strrchr(myphar->fname, '/');\n\n\tif (p) {\n\t\tmyphar->ext = memchr(p, '.', (myphar->fname + fname_len) - p);\n\t\tif (myphar->ext == p) {\n\t\t\tmyphar->ext = memchr(p + 1, '.', (myphar->fname + fname_len) - p - 1);\n\t\t}\n\t\tif (myphar->ext) {\n\t\t\tmyphar->ext_len = (myphar->fname + fname_len) - myphar->ext;\n\t\t}\n\t}\n\n\tphar_request_initialize(TSRMLS_C);\n\n\tif (SUCCESS != zend_hash_add(&(PHAR_GLOBALS->phar_fname_map), myphar->fname, fname_len, (void*)&myphar, sizeof(phar_archive_data*), (void **)&actual)) {\n\t\tif (error) {\n\t\t\tspprintf(error, 4096, \"phar error: Unable to add tar-based phar \\\"%s\\\" to phar registry\", fname);\n\t\t}\n\t\tphp_stream_close(fp);\n\t\tphar_destroy_phar_data(myphar TSRMLS_CC);\n\t\treturn FAILURE;\n\t}\n\n\tmyphar = *actual;\n\n\tif (actual_alias) {\n\t\tphar_archive_data **fd_ptr;\n\n\t\tmyphar->is_temporary_alias = 0;\n\n\t\tif (SUCCESS == zend_hash_find(&(PHAR_GLOBALS->phar_alias_map), actual_alias, myphar->alias_len, (void **)&fd_ptr)) {\n\t\t\tif (SUCCESS != phar_free_alias(*fd_ptr, actual_alias, myphar->alias_len TSRMLS_CC)) {\n\t\t\t\tif (error) {\n\t\t\t\t\tspprintf(error, 4096, \"phar error: Unable to add tar-based phar \\\"%s\\\", alias is already in use\", fname);\n\t\t\t\t}\n\t\t\t\tzend_hash_del(&(PHAR_GLOBALS->phar_fname_map), myphar->fname, fname_len);\n\t\t\t\treturn FAILURE;\n\t\t\t}\n\t\t}\n\n\t\tzend_hash_add(&(PHAR_GLOBALS->phar_alias_map), actual_alias, myphar->alias_len, (void*)&myphar, sizeof(phar_archive_data*), NULL);\n\t} else {\n\t\tphar_archive_data **fd_ptr;\n\n\t\tif (alias_len) {\n\t\t\tif (SUCCESS == zend_hash_find(&(PHAR_GLOBALS->phar_alias_map), alias, alias_len, (void **)&fd_ptr)) {\n\t\t\t\tif (SUCCESS != phar_free_alias(*fd_ptr, alias, alias_len TSRMLS_CC)) {\n\t\t\t\t\tif (error) {\n\t\t\t\t\t\tspprintf(error, 4096, \"phar error: Unable to add tar-based phar \\\"%s\\\", alias is already in use\", fname);\n\t\t\t\t\t}\n\t\t\t\t\tzend_hash_del(&(PHAR_GLOBALS->phar_fname_map), myphar->fname, fname_len);\n\t\t\t\t\treturn FAILURE;\n\t\t\t\t}\n\t\t\t}\n\t\t\tzend_hash_add(&(PHAR_GLOBALS->phar_alias_map), alias, alias_len, (void*)&myphar, sizeof(phar_archive_data*), NULL);\n\t\t\tmyphar->alias = pestrndup(alias, alias_len, myphar->is_persistent);\n\t\t\tmyphar->alias_len = alias_len;\n\t\t} else {\n\t\t\tmyphar->alias = pestrndup(myphar->fname, fname_len, myphar->is_persistent);\n\t\t\tmyphar->alias_len = fname_len;\n\t\t}\n\n\t\tmyphar->is_temporary_alias = 1;\n\t}\n\n\tif (pphar) {\n\t\t*pphar = myphar;\n\t}\n\n\treturn SUCCESS;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -152,7 +152,7 @@\n \t\t\tentry.filename_len = entry.uncompressed_filesize;\n \n \t\t\t/* Check for overflow - bug 61065 */\n-\t\t\tif (entry.filename_len == UINT_MAX) {\n+\t\t\tif (entry.filename_len == UINT_MAX || entry.filename_len == 0) {\n \t\t\t\tif (error) {\n \t\t\t\t\tspprintf(error, 4096, \"phar error: \\\"%s\\\" is a corrupted tar file (invalid entry size)\", fname);\n \t\t\t\t}",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\tif (entry.filename_len == UINT_MAX) {"
            ],
            "added_lines": [
                "\t\t\tif (entry.filename_len == UINT_MAX || entry.filename_len == 0) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-4343",
        "func_name": "php/php-src/phar_make_dirstream",
        "description": "The phar_make_dirstream function in ext/phar/dirstream.c in PHP before 5.6.18 and 7.x before 7.0.3 mishandles zero-size ././@LongLink files, which allows remote attackers to cause a denial of service (uninitialized pointer dereference) or possibly have unspecified other impact via a crafted TAR archive.",
        "git_url": "https://github.com/php/php-src/commit/9649ca1630433473a307d015ba1a79a4a7a779f5",
        "commit_title": "Fixed bug #71331 - Uninitialized pointer in phar_make_dirstream()",
        "commit_text": "",
        "func_before": "static php_stream *phar_make_dirstream(char *dir, HashTable *manifest TSRMLS_DC) /* {{{ */\n{\n\tHashTable *data;\n\tint dirlen = strlen(dir);\n\tphar_zstr key;\n\tchar *entry, *found, *save, *str_key;\n\tuint keylen;\n\tulong unused;\n\n\tALLOC_HASHTABLE(data);\n\tzend_hash_init(data, 64, zend_get_hash_value, NULL, 0);\n\n\tif ((*dir == '/' && dirlen == 1 && (manifest->nNumOfElements == 0)) || (dirlen >= sizeof(\".phar\")-1 && !memcmp(dir, \".phar\", sizeof(\".phar\")-1))) {\n\t\t/* make empty root directory for empty phar */\n\t\t/* make empty directory for .phar magic directory */\n\t\tefree(dir);\n\t\treturn php_stream_alloc(&phar_dir_ops, data, NULL, \"r\");\n\t}\n\n\tzend_hash_internal_pointer_reset(manifest);\n\n\twhile (FAILURE != zend_hash_has_more_elements(manifest)) {\n\t\tif (HASH_KEY_NON_EXISTENT == zend_hash_get_current_key_ex(manifest, &key, &keylen, &unused, 0, NULL)) {\n\t\t\tbreak;\n\t\t}\n\n\t\tPHAR_STR(key, str_key);\n\n\t\tif (keylen <= (uint)dirlen) {\n\t\t\tif (keylen < (uint)dirlen || !strncmp(str_key, dir, dirlen)) {\n\t\t\t\tPHAR_STR_FREE(str_key);\n\t\t\t\tif (SUCCESS != zend_hash_move_forward(manifest)) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t}\n\n\t\tif (*dir == '/') {\n\t\t\t/* root directory */\n\t\t\tif (keylen >= sizeof(\".phar\")-1 && !memcmp(str_key, \".phar\", sizeof(\".phar\")-1)) {\n\t\t\t\tPHAR_STR_FREE(str_key);\n\t\t\t\t/* do not add any magic entries to this directory */\n\t\t\t\tif (SUCCESS != zend_hash_move_forward(manifest)) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (NULL != (found = (char *) memchr(str_key, '/', keylen))) {\n\t\t\t\t/* the entry has a path separator and is a subdirectory */\n\t\t\t\tentry = (char *) safe_emalloc(found - str_key, 1, 1);\n\t\t\t\tmemcpy(entry, str_key, found - str_key);\n\t\t\t\tkeylen = found - str_key;\n\t\t\t\tentry[keylen] = '\\0';\n\t\t\t} else {\n\t\t\t\tentry = (char *) safe_emalloc(keylen, 1, 1);\n\t\t\t\tmemcpy(entry, str_key, keylen);\n\t\t\t\tentry[keylen] = '\\0';\n\t\t\t}\n\n\t\t\tPHAR_STR_FREE(str_key);\n\t\t\tgoto PHAR_ADD_ENTRY;\n\t\t} else {\n\t\t\tif (0 != memcmp(str_key, dir, dirlen)) {\n\t\t\t\t/* entry in directory not found */\n\t\t\t\tPHAR_STR_FREE(str_key);\n\t\t\t\tif (SUCCESS != zend_hash_move_forward(manifest)) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tcontinue;\n\t\t\t} else {\n\t\t\t\tif (str_key[dirlen] != '/') {\n\t\t\t\t\tPHAR_STR_FREE(str_key);\n\t\t\t\t\tif (SUCCESS != zend_hash_move_forward(manifest)) {\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tsave = str_key;\n\t\tsave += dirlen + 1; /* seek to just past the path separator */\n\n\t\tif (NULL != (found = (char *) memchr(save, '/', keylen - dirlen - 1))) {\n\t\t\t/* is subdirectory */\n\t\t\tsave -= dirlen + 1;\n\t\t\tentry = (char *) safe_emalloc(found - save + dirlen, 1, 1);\n\t\t\tmemcpy(entry, save + dirlen + 1, found - save - dirlen - 1);\n\t\t\tkeylen = found - save - dirlen - 1;\n\t\t\tentry[keylen] = '\\0';\n\t\t} else {\n\t\t\t/* is file */\n\t\t\tsave -= dirlen + 1;\n\t\t\tentry = (char *) safe_emalloc(keylen - dirlen, 1, 1);\n\t\t\tmemcpy(entry, save + dirlen + 1, keylen - dirlen - 1);\n\t\t\tentry[keylen - dirlen - 1] = '\\0';\n\t\t\tkeylen = keylen - dirlen - 1;\n\t\t}\n\t\tPHAR_STR_FREE(str_key);\nPHAR_ADD_ENTRY:\n\t\tif (keylen) {\n\t\t\tphar_add_empty(data, entry, keylen);\n\t\t}\n\n\t\tefree(entry);\n\n\t\tif (SUCCESS != zend_hash_move_forward(manifest)) {\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (FAILURE != zend_hash_has_more_elements(data)) {\n\t\tefree(dir);\n\t\tif (zend_hash_sort(data, zend_qsort, phar_compare_dir_name, 0 TSRMLS_CC) == FAILURE) {\n\t\t\tFREE_HASHTABLE(data);\n\t\t\treturn NULL;\n\t\t}\n\t\treturn php_stream_alloc(&phar_dir_ops, data, NULL, \"r\");\n\t} else {\n\t\tefree(dir);\n\t\treturn php_stream_alloc(&phar_dir_ops, data, NULL, \"r\");\n\t}\n}",
        "func": "static php_stream *phar_make_dirstream(char *dir, HashTable *manifest TSRMLS_DC) /* {{{ */\n{\n\tHashTable *data;\n\tint dirlen = strlen(dir);\n\tphar_zstr key;\n\tchar *entry, *found, *save, *str_key;\n\tuint keylen;\n\tulong unused;\n\n\tALLOC_HASHTABLE(data);\n\tzend_hash_init(data, 64, zend_get_hash_value, NULL, 0);\n\n\tif ((*dir == '/' && dirlen == 1 && (manifest->nNumOfElements == 0)) || (dirlen >= sizeof(\".phar\")-1 && !memcmp(dir, \".phar\", sizeof(\".phar\")-1))) {\n\t\t/* make empty root directory for empty phar */\n\t\t/* make empty directory for .phar magic directory */\n\t\tefree(dir);\n\t\treturn php_stream_alloc(&phar_dir_ops, data, NULL, \"r\");\n\t}\n\n\tzend_hash_internal_pointer_reset(manifest);\n\n\twhile (FAILURE != zend_hash_has_more_elements(manifest)) {\n\t\tkeylen = 0;\n\t\tif (HASH_KEY_NON_EXISTENT == zend_hash_get_current_key_ex(manifest, &key, &keylen, &unused, 0, NULL)) {\n\t\t\tbreak;\n\t\t}\n\n\t\tPHAR_STR(key, str_key);\n\n\t\tif (keylen <= (uint)dirlen) {\n\t\t\tif (keylen == 0 || keylen < (uint)dirlen || !strncmp(str_key, dir, dirlen)) {\n\t\t\t\tPHAR_STR_FREE(str_key);\n\t\t\t\tif (SUCCESS != zend_hash_move_forward(manifest)) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t}\n\n\t\tif (*dir == '/') {\n\t\t\t/* root directory */\n\t\t\tif (keylen >= sizeof(\".phar\")-1 && !memcmp(str_key, \".phar\", sizeof(\".phar\")-1)) {\n\t\t\t\tPHAR_STR_FREE(str_key);\n\t\t\t\t/* do not add any magic entries to this directory */\n\t\t\t\tif (SUCCESS != zend_hash_move_forward(manifest)) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (NULL != (found = (char *) memchr(str_key, '/', keylen))) {\n\t\t\t\t/* the entry has a path separator and is a subdirectory */\n\t\t\t\tentry = (char *) safe_emalloc(found - str_key, 1, 1);\n\t\t\t\tmemcpy(entry, str_key, found - str_key);\n\t\t\t\tkeylen = found - str_key;\n\t\t\t\tentry[keylen] = '\\0';\n\t\t\t} else {\n\t\t\t\tentry = (char *) safe_emalloc(keylen, 1, 1);\n\t\t\t\tmemcpy(entry, str_key, keylen);\n\t\t\t\tentry[keylen] = '\\0';\n\t\t\t}\n\n\t\t\tPHAR_STR_FREE(str_key);\n\t\t\tgoto PHAR_ADD_ENTRY;\n\t\t} else {\n\t\t\tif (0 != memcmp(str_key, dir, dirlen)) {\n\t\t\t\t/* entry in directory not found */\n\t\t\t\tPHAR_STR_FREE(str_key);\n\t\t\t\tif (SUCCESS != zend_hash_move_forward(manifest)) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tcontinue;\n\t\t\t} else {\n\t\t\t\tif (str_key[dirlen] != '/') {\n\t\t\t\t\tPHAR_STR_FREE(str_key);\n\t\t\t\t\tif (SUCCESS != zend_hash_move_forward(manifest)) {\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tsave = str_key;\n\t\tsave += dirlen + 1; /* seek to just past the path separator */\n\n\t\tif (NULL != (found = (char *) memchr(save, '/', keylen - dirlen - 1))) {\n\t\t\t/* is subdirectory */\n\t\t\tsave -= dirlen + 1;\n\t\t\tentry = (char *) safe_emalloc(found - save + dirlen, 1, 1);\n\t\t\tmemcpy(entry, save + dirlen + 1, found - save - dirlen - 1);\n\t\t\tkeylen = found - save - dirlen - 1;\n\t\t\tentry[keylen] = '\\0';\n\t\t} else {\n\t\t\t/* is file */\n\t\t\tsave -= dirlen + 1;\n\t\t\tentry = (char *) safe_emalloc(keylen - dirlen, 1, 1);\n\t\t\tmemcpy(entry, save + dirlen + 1, keylen - dirlen - 1);\n\t\t\tentry[keylen - dirlen - 1] = '\\0';\n\t\t\tkeylen = keylen - dirlen - 1;\n\t\t}\n\t\tPHAR_STR_FREE(str_key);\nPHAR_ADD_ENTRY:\n\t\tif (keylen) {\n\t\t\tphar_add_empty(data, entry, keylen);\n\t\t}\n\n\t\tefree(entry);\n\n\t\tif (SUCCESS != zend_hash_move_forward(manifest)) {\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (FAILURE != zend_hash_has_more_elements(data)) {\n\t\tefree(dir);\n\t\tif (zend_hash_sort(data, zend_qsort, phar_compare_dir_name, 0 TSRMLS_CC) == FAILURE) {\n\t\t\tFREE_HASHTABLE(data);\n\t\t\treturn NULL;\n\t\t}\n\t\treturn php_stream_alloc(&phar_dir_ops, data, NULL, \"r\");\n\t} else {\n\t\tefree(dir);\n\t\treturn php_stream_alloc(&phar_dir_ops, data, NULL, \"r\");\n\t}\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -20,6 +20,7 @@\n \tzend_hash_internal_pointer_reset(manifest);\n \n \twhile (FAILURE != zend_hash_has_more_elements(manifest)) {\n+\t\tkeylen = 0;\n \t\tif (HASH_KEY_NON_EXISTENT == zend_hash_get_current_key_ex(manifest, &key, &keylen, &unused, 0, NULL)) {\n \t\t\tbreak;\n \t\t}\n@@ -27,7 +28,7 @@\n \t\tPHAR_STR(key, str_key);\n \n \t\tif (keylen <= (uint)dirlen) {\n-\t\t\tif (keylen < (uint)dirlen || !strncmp(str_key, dir, dirlen)) {\n+\t\t\tif (keylen == 0 || keylen < (uint)dirlen || !strncmp(str_key, dir, dirlen)) {\n \t\t\t\tPHAR_STR_FREE(str_key);\n \t\t\t\tif (SUCCESS != zend_hash_move_forward(manifest)) {\n \t\t\t\t\tbreak;",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\tif (keylen < (uint)dirlen || !strncmp(str_key, dir, dirlen)) {"
            ],
            "added_lines": [
                "\t\tkeylen = 0;",
                "\t\t\tif (keylen == 0 || keylen < (uint)dirlen || !strncmp(str_key, dir, dirlen)) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-11498",
        "func_name": "dbry/WavPack/ParseDsdiffHeaderConfig",
        "description": "WavpackSetConfiguration64 in pack_utils.c in libwavpack.a in WavPack through 5.1.0 has a \"Conditional jump or move depends on uninitialised value\" condition, which might allow attackers to cause a denial of service (application crash) via a DFF file that lacks valid sample-rate data.",
        "git_url": "https://github.com/dbry/WavPack/commit/bc6cba3f552c44565f7f1e66dc1580189addb2b4",
        "commit_title": "issue #67: make sure sample rate is specified and non-zero in DFF files",
        "commit_text": "",
        "func_before": "int ParseDsdiffHeaderConfig (FILE *infile, char *infilename, char *fourcc, WavpackContext *wpc, WavpackConfig *config)\n{\n    int64_t infilesize, total_samples;\n    DFFFileHeader dff_file_header;\n    DFFChunkHeader dff_chunk_header;\n    uint32_t bcount;\n\n    infilesize = DoGetFileSize (infile);\n    memcpy (&dff_file_header, fourcc, 4);\n\n    if ((!DoReadFile (infile, ((char *) &dff_file_header) + 4, sizeof (DFFFileHeader) - 4, &bcount) ||\n        bcount != sizeof (DFFFileHeader) - 4) || strncmp (dff_file_header.formType, \"DSD \", 4)) {\n            error_line (\"%s is not a valid .DFF file!\", infilename);\n            return WAVPACK_SOFT_ERROR;\n    }\n    else if (!(config->qmode & QMODE_NO_STORE_WRAPPER) &&\n        !WavpackAddWrapper (wpc, &dff_file_header, sizeof (DFFFileHeader))) {\n            error_line (\"%s\", WavpackGetErrorMessage (wpc));\n            return WAVPACK_SOFT_ERROR;\n    }\n\n#if 1   // this might be a little too picky...\n    WavpackBigEndianToNative (&dff_file_header, DFFFileHeaderFormat);\n\n    if (infilesize && !(config->qmode & QMODE_IGNORE_LENGTH) &&\n        dff_file_header.ckDataSize && dff_file_header.ckDataSize + 1 && dff_file_header.ckDataSize + 12 != infilesize) {\n            error_line (\"%s is not a valid .DFF file (by total size)!\", infilename);\n            return WAVPACK_SOFT_ERROR;\n    }\n\n    if (debug_logging_mode)\n        error_line (\"file header indicated length = %lld\", dff_file_header.ckDataSize);\n\n#endif\n\n    // loop through all elements of the DSDIFF header\n    // (until the data chuck) and copy them to the output file\n\n    while (1) {\n        if (!DoReadFile (infile, &dff_chunk_header, sizeof (DFFChunkHeader), &bcount) ||\n            bcount != sizeof (DFFChunkHeader)) {\n                error_line (\"%s is not a valid .DFF file!\", infilename);\n                return WAVPACK_SOFT_ERROR;\n        }\n        else if (!(config->qmode & QMODE_NO_STORE_WRAPPER) &&\n            !WavpackAddWrapper (wpc, &dff_chunk_header, sizeof (DFFChunkHeader))) {\n                error_line (\"%s\", WavpackGetErrorMessage (wpc));\n                return WAVPACK_SOFT_ERROR;\n        }\n\n        WavpackBigEndianToNative (&dff_chunk_header, DFFChunkHeaderFormat);\n\n        if (debug_logging_mode)\n            error_line (\"chunk header indicated length = %lld\", dff_chunk_header.ckDataSize);\n\n        if (!strncmp (dff_chunk_header.ckID, \"FVER\", 4)) {\n            uint32_t version;\n\n            if (dff_chunk_header.ckDataSize != sizeof (version) ||\n                !DoReadFile (infile, &version, sizeof (version), &bcount) ||\n                bcount != sizeof (version)) {\n                    error_line (\"%s is not a valid .DFF file!\", infilename);\n                    return WAVPACK_SOFT_ERROR;\n            }\n            else if (!(config->qmode & QMODE_NO_STORE_WRAPPER) &&\n                !WavpackAddWrapper (wpc, &version, sizeof (version))) {\n                    error_line (\"%s\", WavpackGetErrorMessage (wpc));\n                    return WAVPACK_SOFT_ERROR;\n            }\n\n            WavpackBigEndianToNative (&version, \"L\");\n\n            if (debug_logging_mode)\n                error_line (\"dsdiff file version = 0x%08x\", version);\n        }\n        else if (!strncmp (dff_chunk_header.ckID, \"PROP\", 4)) {\n            char *prop_chunk;\n\n            if (dff_chunk_header.ckDataSize < 4 || dff_chunk_header.ckDataSize > 1024) {\n                error_line (\"%s is not a valid .DFF file!\", infilename);\n                return WAVPACK_SOFT_ERROR;\n            }\n\n            if (debug_logging_mode)\n                error_line (\"got PROP chunk of %d bytes total\", (int) dff_chunk_header.ckDataSize);\n\n            prop_chunk = malloc ((size_t) dff_chunk_header.ckDataSize);\n\n            if (!DoReadFile (infile, prop_chunk, (uint32_t) dff_chunk_header.ckDataSize, &bcount) ||\n                bcount != dff_chunk_header.ckDataSize) {\n                    error_line (\"%s is not a valid .DFF file!\", infilename);\n                    free (prop_chunk);\n                    return WAVPACK_SOFT_ERROR;\n            }\n            else if (!(config->qmode & QMODE_NO_STORE_WRAPPER) &&\n                !WavpackAddWrapper (wpc, prop_chunk, (uint32_t) dff_chunk_header.ckDataSize)) {\n                    error_line (\"%s\", WavpackGetErrorMessage (wpc));\n                    free (prop_chunk);\n                    return WAVPACK_SOFT_ERROR;\n            }\n\n            if (!strncmp (prop_chunk, \"SND \", 4)) {\n                char *cptr = prop_chunk + 4, *eptr = prop_chunk + dff_chunk_header.ckDataSize;\n                uint16_t numChannels = 0, chansSpecified, chanMask = 0;\n                uint32_t sampleRate;\n\n                while (eptr - cptr >= sizeof (dff_chunk_header)) {\n                    memcpy (&dff_chunk_header, cptr, sizeof (dff_chunk_header));\n                    cptr += sizeof (dff_chunk_header);\n                    WavpackBigEndianToNative (&dff_chunk_header, DFFChunkHeaderFormat);\n\n                    if (dff_chunk_header.ckDataSize > 0 && dff_chunk_header.ckDataSize <= eptr - cptr) {\n                        if (!strncmp (dff_chunk_header.ckID, \"FS  \", 4) && dff_chunk_header.ckDataSize == 4) {\n                            memcpy (&sampleRate, cptr, sizeof (sampleRate));\n                            WavpackBigEndianToNative (&sampleRate, \"L\");\n                            cptr += dff_chunk_header.ckDataSize;\n\n                            if (debug_logging_mode)\n                                error_line (\"got sample rate of %u Hz\", sampleRate);\n                        }\n                        else if (!strncmp (dff_chunk_header.ckID, \"CHNL\", 4) && dff_chunk_header.ckDataSize >= 2) {\n                            memcpy (&numChannels, cptr, sizeof (numChannels));\n                            WavpackBigEndianToNative (&numChannels, \"S\");\n                            cptr += sizeof (numChannels);\n\n                            chansSpecified = (int)(dff_chunk_header.ckDataSize - sizeof (numChannels)) / 4;\n\n                            if (numChannels < chansSpecified || numChannels < 1 || numChannels > 256) {\n                                error_line (\"%s is not a valid .DFF file!\", infilename);\n                                free (prop_chunk);\n                                return WAVPACK_SOFT_ERROR;\n                            }\n\n                            while (chansSpecified--) {\n                                if (!strncmp (cptr, \"SLFT\", 4) || !strncmp (cptr, \"MLFT\", 4))\n                                    chanMask |= 0x1;\n                                else if (!strncmp (cptr, \"SRGT\", 4) || !strncmp (cptr, \"MRGT\", 4))\n                                    chanMask |= 0x2;\n                                else if (!strncmp (cptr, \"LS  \", 4))\n                                    chanMask |= 0x10;\n                                else if (!strncmp (cptr, \"RS  \", 4))\n                                    chanMask |= 0x20;\n                                else if (!strncmp (cptr, \"C   \", 4))\n                                    chanMask |= 0x4;\n                                else if (!strncmp (cptr, \"LFE \", 4))\n                                    chanMask |= 0x8;\n                                else\n                                    if (debug_logging_mode)\n                                        error_line (\"undefined channel ID %c%c%c%c\", cptr [0], cptr [1], cptr [2], cptr [3]);\n\n                                cptr += 4;\n                            }\n\n                            if (debug_logging_mode)\n                                error_line (\"%d channels, mask = 0x%08x\", numChannels, chanMask);\n                        }\n                        else if (!strncmp (dff_chunk_header.ckID, \"CMPR\", 4) && dff_chunk_header.ckDataSize >= 4) {\n                            if (strncmp (cptr, \"DSD \", 4)) {\n                                error_line (\"DSDIFF files must be uncompressed, not \\\"%c%c%c%c\\\"!\",\n                                    cptr [0], cptr [1], cptr [2], cptr [3]);\n                                free (prop_chunk);\n                                return WAVPACK_SOFT_ERROR;\n                            }\n\n                            cptr += dff_chunk_header.ckDataSize;\n                        }\n                        else {\n                            if (debug_logging_mode)\n                                error_line (\"got PROP/SND chunk type \\\"%c%c%c%c\\\" of %d bytes\", dff_chunk_header.ckID [0],\n                                    dff_chunk_header.ckID [1], dff_chunk_header.ckID [2], dff_chunk_header.ckID [3], dff_chunk_header.ckDataSize);\n\n                            cptr += dff_chunk_header.ckDataSize;\n                        }\n                    }\n                    else {\n                        error_line (\"%s is not a valid .DFF file!\", infilename);\n                        free (prop_chunk);\n                        return WAVPACK_SOFT_ERROR;\n                    }\n                }\n\n                if (chanMask && (config->channel_mask || (config->qmode & QMODE_CHANS_UNASSIGNED))) {\n                    error_line (\"this DSDIFF file already has channel order information!\");\n                    free (prop_chunk);\n                    return WAVPACK_SOFT_ERROR;\n                }\n                else if (chanMask)\n                    config->channel_mask = chanMask;\n\n                config->bits_per_sample = 8;\n                config->bytes_per_sample = 1;\n                config->num_channels = numChannels;\n                config->sample_rate = sampleRate / 8;\n                config->qmode |= QMODE_DSD_MSB_FIRST;\n            }\n            else if (debug_logging_mode)\n                error_line (\"got unknown PROP chunk type \\\"%c%c%c%c\\\" of %d bytes\",\n                    prop_chunk [0], prop_chunk [1], prop_chunk [2], prop_chunk [3], dff_chunk_header.ckDataSize);\n\n            free (prop_chunk);\n        }\n        else if (!strncmp (dff_chunk_header.ckID, \"DSD \", 4)) {\n\n            if (!config->num_channels) {\n                error_line (\"%s is not a valid .DFF file!\", infilename);\n                return WAVPACK_SOFT_ERROR;\n            }\n\n            total_samples = dff_chunk_header.ckDataSize / config->num_channels;\n            break;\n        }\n        else {          // just copy unknown chunks to output file\n\n            int bytes_to_copy = (int)(((dff_chunk_header.ckDataSize) + 1) & ~(int64_t)1);\n            char *buff;\n\n            if (bytes_to_copy < 0 || bytes_to_copy > 4194304) {\n                error_line (\"%s is not a valid .DFF file!\", infilename);\n                return WAVPACK_SOFT_ERROR;\n            }\n\n            buff = malloc (bytes_to_copy);\n\n            if (debug_logging_mode)\n                error_line (\"extra unknown chunk \\\"%c%c%c%c\\\" of %d bytes\",\n                    dff_chunk_header.ckID [0], dff_chunk_header.ckID [1], dff_chunk_header.ckID [2],\n                    dff_chunk_header.ckID [3], dff_chunk_header.ckDataSize);\n\n            if (!DoReadFile (infile, buff, bytes_to_copy, &bcount) ||\n                bcount != bytes_to_copy ||\n                (!(config->qmode & QMODE_NO_STORE_WRAPPER) &&\n                !WavpackAddWrapper (wpc, buff, bytes_to_copy))) {\n                    error_line (\"%s\", WavpackGetErrorMessage (wpc));\n                    free (buff);\n                    return WAVPACK_SOFT_ERROR;\n            }\n\n            free (buff);\n        }\n    }\n\n    if (debug_logging_mode)\n        error_line (\"setting configuration with %lld samples\", total_samples);\n\n    if (!WavpackSetConfiguration64 (wpc, config, total_samples, NULL)) {\n        error_line (\"%s: %s\", infilename, WavpackGetErrorMessage (wpc));\n        return WAVPACK_SOFT_ERROR;\n    }\n\n    return WAVPACK_NO_ERROR;\n}",
        "func": "int ParseDsdiffHeaderConfig (FILE *infile, char *infilename, char *fourcc, WavpackContext *wpc, WavpackConfig *config)\n{\n    int64_t infilesize, total_samples;\n    DFFFileHeader dff_file_header;\n    DFFChunkHeader dff_chunk_header;\n    uint32_t bcount;\n\n    infilesize = DoGetFileSize (infile);\n    memcpy (&dff_file_header, fourcc, 4);\n\n    if ((!DoReadFile (infile, ((char *) &dff_file_header) + 4, sizeof (DFFFileHeader) - 4, &bcount) ||\n        bcount != sizeof (DFFFileHeader) - 4) || strncmp (dff_file_header.formType, \"DSD \", 4)) {\n            error_line (\"%s is not a valid .DFF file!\", infilename);\n            return WAVPACK_SOFT_ERROR;\n    }\n    else if (!(config->qmode & QMODE_NO_STORE_WRAPPER) &&\n        !WavpackAddWrapper (wpc, &dff_file_header, sizeof (DFFFileHeader))) {\n            error_line (\"%s\", WavpackGetErrorMessage (wpc));\n            return WAVPACK_SOFT_ERROR;\n    }\n\n#if 1   // this might be a little too picky...\n    WavpackBigEndianToNative (&dff_file_header, DFFFileHeaderFormat);\n\n    if (infilesize && !(config->qmode & QMODE_IGNORE_LENGTH) &&\n        dff_file_header.ckDataSize && dff_file_header.ckDataSize + 1 && dff_file_header.ckDataSize + 12 != infilesize) {\n            error_line (\"%s is not a valid .DFF file (by total size)!\", infilename);\n            return WAVPACK_SOFT_ERROR;\n    }\n\n    if (debug_logging_mode)\n        error_line (\"file header indicated length = %lld\", dff_file_header.ckDataSize);\n\n#endif\n\n    // loop through all elements of the DSDIFF header\n    // (until the data chuck) and copy them to the output file\n\n    while (1) {\n        if (!DoReadFile (infile, &dff_chunk_header, sizeof (DFFChunkHeader), &bcount) ||\n            bcount != sizeof (DFFChunkHeader)) {\n                error_line (\"%s is not a valid .DFF file!\", infilename);\n                return WAVPACK_SOFT_ERROR;\n        }\n        else if (!(config->qmode & QMODE_NO_STORE_WRAPPER) &&\n            !WavpackAddWrapper (wpc, &dff_chunk_header, sizeof (DFFChunkHeader))) {\n                error_line (\"%s\", WavpackGetErrorMessage (wpc));\n                return WAVPACK_SOFT_ERROR;\n        }\n\n        WavpackBigEndianToNative (&dff_chunk_header, DFFChunkHeaderFormat);\n\n        if (debug_logging_mode)\n            error_line (\"chunk header indicated length = %lld\", dff_chunk_header.ckDataSize);\n\n        if (!strncmp (dff_chunk_header.ckID, \"FVER\", 4)) {\n            uint32_t version;\n\n            if (dff_chunk_header.ckDataSize != sizeof (version) ||\n                !DoReadFile (infile, &version, sizeof (version), &bcount) ||\n                bcount != sizeof (version)) {\n                    error_line (\"%s is not a valid .DFF file!\", infilename);\n                    return WAVPACK_SOFT_ERROR;\n            }\n            else if (!(config->qmode & QMODE_NO_STORE_WRAPPER) &&\n                !WavpackAddWrapper (wpc, &version, sizeof (version))) {\n                    error_line (\"%s\", WavpackGetErrorMessage (wpc));\n                    return WAVPACK_SOFT_ERROR;\n            }\n\n            WavpackBigEndianToNative (&version, \"L\");\n\n            if (debug_logging_mode)\n                error_line (\"dsdiff file version = 0x%08x\", version);\n        }\n        else if (!strncmp (dff_chunk_header.ckID, \"PROP\", 4)) {\n            char *prop_chunk;\n\n            if (dff_chunk_header.ckDataSize < 4 || dff_chunk_header.ckDataSize > 1024) {\n                error_line (\"%s is not a valid .DFF file!\", infilename);\n                return WAVPACK_SOFT_ERROR;\n            }\n\n            if (debug_logging_mode)\n                error_line (\"got PROP chunk of %d bytes total\", (int) dff_chunk_header.ckDataSize);\n\n            prop_chunk = malloc ((size_t) dff_chunk_header.ckDataSize);\n\n            if (!DoReadFile (infile, prop_chunk, (uint32_t) dff_chunk_header.ckDataSize, &bcount) ||\n                bcount != dff_chunk_header.ckDataSize) {\n                    error_line (\"%s is not a valid .DFF file!\", infilename);\n                    free (prop_chunk);\n                    return WAVPACK_SOFT_ERROR;\n            }\n            else if (!(config->qmode & QMODE_NO_STORE_WRAPPER) &&\n                !WavpackAddWrapper (wpc, prop_chunk, (uint32_t) dff_chunk_header.ckDataSize)) {\n                    error_line (\"%s\", WavpackGetErrorMessage (wpc));\n                    free (prop_chunk);\n                    return WAVPACK_SOFT_ERROR;\n            }\n\n            if (!strncmp (prop_chunk, \"SND \", 4)) {\n                char *cptr = prop_chunk + 4, *eptr = prop_chunk + dff_chunk_header.ckDataSize;\n                uint16_t numChannels = 0, chansSpecified, chanMask = 0;\n                uint32_t sampleRate = 0;\n\n                while (eptr - cptr >= sizeof (dff_chunk_header)) {\n                    memcpy (&dff_chunk_header, cptr, sizeof (dff_chunk_header));\n                    cptr += sizeof (dff_chunk_header);\n                    WavpackBigEndianToNative (&dff_chunk_header, DFFChunkHeaderFormat);\n\n                    if (dff_chunk_header.ckDataSize > 0 && dff_chunk_header.ckDataSize <= eptr - cptr) {\n                        if (!strncmp (dff_chunk_header.ckID, \"FS  \", 4) && dff_chunk_header.ckDataSize == 4) {\n                            memcpy (&sampleRate, cptr, sizeof (sampleRate));\n                            WavpackBigEndianToNative (&sampleRate, \"L\");\n                            cptr += dff_chunk_header.ckDataSize;\n\n                            if (debug_logging_mode)\n                                error_line (\"got sample rate of %u Hz\", sampleRate);\n                        }\n                        else if (!strncmp (dff_chunk_header.ckID, \"CHNL\", 4) && dff_chunk_header.ckDataSize >= 2) {\n                            memcpy (&numChannels, cptr, sizeof (numChannels));\n                            WavpackBigEndianToNative (&numChannels, \"S\");\n                            cptr += sizeof (numChannels);\n\n                            chansSpecified = (int)(dff_chunk_header.ckDataSize - sizeof (numChannels)) / 4;\n\n                            if (numChannels < chansSpecified || numChannels < 1 || numChannels > 256) {\n                                error_line (\"%s is not a valid .DFF file!\", infilename);\n                                free (prop_chunk);\n                                return WAVPACK_SOFT_ERROR;\n                            }\n\n                            while (chansSpecified--) {\n                                if (!strncmp (cptr, \"SLFT\", 4) || !strncmp (cptr, \"MLFT\", 4))\n                                    chanMask |= 0x1;\n                                else if (!strncmp (cptr, \"SRGT\", 4) || !strncmp (cptr, \"MRGT\", 4))\n                                    chanMask |= 0x2;\n                                else if (!strncmp (cptr, \"LS  \", 4))\n                                    chanMask |= 0x10;\n                                else if (!strncmp (cptr, \"RS  \", 4))\n                                    chanMask |= 0x20;\n                                else if (!strncmp (cptr, \"C   \", 4))\n                                    chanMask |= 0x4;\n                                else if (!strncmp (cptr, \"LFE \", 4))\n                                    chanMask |= 0x8;\n                                else\n                                    if (debug_logging_mode)\n                                        error_line (\"undefined channel ID %c%c%c%c\", cptr [0], cptr [1], cptr [2], cptr [3]);\n\n                                cptr += 4;\n                            }\n\n                            if (debug_logging_mode)\n                                error_line (\"%d channels, mask = 0x%08x\", numChannels, chanMask);\n                        }\n                        else if (!strncmp (dff_chunk_header.ckID, \"CMPR\", 4) && dff_chunk_header.ckDataSize >= 4) {\n                            if (strncmp (cptr, \"DSD \", 4)) {\n                                error_line (\"DSDIFF files must be uncompressed, not \\\"%c%c%c%c\\\"!\",\n                                    cptr [0], cptr [1], cptr [2], cptr [3]);\n                                free (prop_chunk);\n                                return WAVPACK_SOFT_ERROR;\n                            }\n\n                            cptr += dff_chunk_header.ckDataSize;\n                        }\n                        else {\n                            if (debug_logging_mode)\n                                error_line (\"got PROP/SND chunk type \\\"%c%c%c%c\\\" of %d bytes\", dff_chunk_header.ckID [0],\n                                    dff_chunk_header.ckID [1], dff_chunk_header.ckID [2], dff_chunk_header.ckID [3], dff_chunk_header.ckDataSize);\n\n                            cptr += dff_chunk_header.ckDataSize;\n                        }\n                    }\n                    else {\n                        error_line (\"%s is not a valid .DFF file!\", infilename);\n                        free (prop_chunk);\n                        return WAVPACK_SOFT_ERROR;\n                    }\n                }\n\n                if (chanMask && (config->channel_mask || (config->qmode & QMODE_CHANS_UNASSIGNED))) {\n                    error_line (\"this DSDIFF file already has channel order information!\");\n                    free (prop_chunk);\n                    return WAVPACK_SOFT_ERROR;\n                }\n                else if (chanMask)\n                    config->channel_mask = chanMask;\n\n                config->bits_per_sample = 8;\n                config->bytes_per_sample = 1;\n                config->num_channels = numChannels;\n                config->sample_rate = sampleRate / 8;\n                config->qmode |= QMODE_DSD_MSB_FIRST;\n            }\n            else if (debug_logging_mode)\n                error_line (\"got unknown PROP chunk type \\\"%c%c%c%c\\\" of %d bytes\",\n                    prop_chunk [0], prop_chunk [1], prop_chunk [2], prop_chunk [3], dff_chunk_header.ckDataSize);\n\n            free (prop_chunk);\n        }\n        else if (!strncmp (dff_chunk_header.ckID, \"DSD \", 4)) {\n\n            if (!config->num_channels || !config->sample_rate) {\n                error_line (\"%s is not a valid .DFF file!\", infilename);\n                return WAVPACK_SOFT_ERROR;\n            }\n\n            total_samples = dff_chunk_header.ckDataSize / config->num_channels;\n            break;\n        }\n        else {          // just copy unknown chunks to output file\n\n            int bytes_to_copy = (int)(((dff_chunk_header.ckDataSize) + 1) & ~(int64_t)1);\n            char *buff;\n\n            if (bytes_to_copy < 0 || bytes_to_copy > 4194304) {\n                error_line (\"%s is not a valid .DFF file!\", infilename);\n                return WAVPACK_SOFT_ERROR;\n            }\n\n            buff = malloc (bytes_to_copy);\n\n            if (debug_logging_mode)\n                error_line (\"extra unknown chunk \\\"%c%c%c%c\\\" of %d bytes\",\n                    dff_chunk_header.ckID [0], dff_chunk_header.ckID [1], dff_chunk_header.ckID [2],\n                    dff_chunk_header.ckID [3], dff_chunk_header.ckDataSize);\n\n            if (!DoReadFile (infile, buff, bytes_to_copy, &bcount) ||\n                bcount != bytes_to_copy ||\n                (!(config->qmode & QMODE_NO_STORE_WRAPPER) &&\n                !WavpackAddWrapper (wpc, buff, bytes_to_copy))) {\n                    error_line (\"%s\", WavpackGetErrorMessage (wpc));\n                    free (buff);\n                    return WAVPACK_SOFT_ERROR;\n            }\n\n            free (buff);\n        }\n    }\n\n    if (debug_logging_mode)\n        error_line (\"setting configuration with %lld samples\", total_samples);\n\n    if (!WavpackSetConfiguration64 (wpc, config, total_samples, NULL)) {\n        error_line (\"%s: %s\", infilename, WavpackGetErrorMessage (wpc));\n        return WAVPACK_SOFT_ERROR;\n    }\n\n    return WAVPACK_NO_ERROR;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -102,7 +102,7 @@\n             if (!strncmp (prop_chunk, \"SND \", 4)) {\n                 char *cptr = prop_chunk + 4, *eptr = prop_chunk + dff_chunk_header.ckDataSize;\n                 uint16_t numChannels = 0, chansSpecified, chanMask = 0;\n-                uint32_t sampleRate;\n+                uint32_t sampleRate = 0;\n \n                 while (eptr - cptr >= sizeof (dff_chunk_header)) {\n                     memcpy (&dff_chunk_header, cptr, sizeof (dff_chunk_header));\n@@ -201,7 +201,7 @@\n         }\n         else if (!strncmp (dff_chunk_header.ckID, \"DSD \", 4)) {\n \n-            if (!config->num_channels) {\n+            if (!config->num_channels || !config->sample_rate) {\n                 error_line (\"%s is not a valid .DFF file!\", infilename);\n                 return WAVPACK_SOFT_ERROR;\n             }",
        "diff_line_info": {
            "deleted_lines": [
                "                uint32_t sampleRate;",
                "            if (!config->num_channels) {"
            ],
            "added_lines": [
                "                uint32_t sampleRate = 0;",
                "            if (!config->num_channels || !config->sample_rate) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-38205",
        "func_name": "torvalds/linux/xemaclite_of_probe",
        "description": "drivers/net/ethernet/xilinx/xilinx_emaclite.c in the Linux kernel before 5.13.3 makes it easier for attackers to defeat an ASLR protection mechanism because it prints a kernel pointer (i.e., the real IOMEM pointer).",
        "git_url": "https://github.com/torvalds/linux/commit/d0d62baa7f505bd4c59cd169692ff07ec49dde37",
        "commit_title": "net: xilinx_emaclite: Do not print real IOMEM pointer",
        "commit_text": " Printing kernel pointers is discouraged because they might leak kernel memory layout.  This fixes smatch warning:  drivers/net/ethernet/xilinx/xilinx_emaclite.c:1191 xemaclite_of_probe() warn:  argument 4 to %08lX specifier is cast from pointer ",
        "func_before": "static int xemaclite_of_probe(struct platform_device *ofdev)\n{\n\tstruct resource *res;\n\tstruct net_device *ndev = NULL;\n\tstruct net_local *lp = NULL;\n\tstruct device *dev = &ofdev->dev;\n\n\tint rc = 0;\n\n\tdev_info(dev, \"Device Tree Probing\\n\");\n\n\t/* Create an ethernet device instance */\n\tndev = alloc_etherdev(sizeof(struct net_local));\n\tif (!ndev)\n\t\treturn -ENOMEM;\n\n\tdev_set_drvdata(dev, ndev);\n\tSET_NETDEV_DEV(ndev, &ofdev->dev);\n\n\tlp = netdev_priv(ndev);\n\tlp->ndev = ndev;\n\n\t/* Get IRQ for the device */\n\tres = platform_get_resource(ofdev, IORESOURCE_IRQ, 0);\n\tif (!res) {\n\t\tdev_err(dev, \"no IRQ found\\n\");\n\t\trc = -ENXIO;\n\t\tgoto error;\n\t}\n\n\tndev->irq = res->start;\n\n\tres = platform_get_resource(ofdev, IORESOURCE_MEM, 0);\n\tlp->base_addr = devm_ioremap_resource(&ofdev->dev, res);\n\tif (IS_ERR(lp->base_addr)) {\n\t\trc = PTR_ERR(lp->base_addr);\n\t\tgoto error;\n\t}\n\n\tndev->mem_start = res->start;\n\tndev->mem_end = res->end;\n\n\tspin_lock_init(&lp->reset_lock);\n\tlp->next_tx_buf_to_use = 0x0;\n\tlp->next_rx_buf_to_use = 0x0;\n\tlp->tx_ping_pong = get_bool(ofdev, \"xlnx,tx-ping-pong\");\n\tlp->rx_ping_pong = get_bool(ofdev, \"xlnx,rx-ping-pong\");\n\n\trc = of_get_mac_address(ofdev->dev.of_node, ndev->dev_addr);\n\tif (rc) {\n\t\tdev_warn(dev, \"No MAC address found, using random\\n\");\n\t\teth_hw_addr_random(ndev);\n\t}\n\n\t/* Clear the Tx CSR's in case this is a restart */\n\txemaclite_writel(0, lp->base_addr + XEL_TSR_OFFSET);\n\txemaclite_writel(0, lp->base_addr + XEL_BUFFER_OFFSET + XEL_TSR_OFFSET);\n\n\t/* Set the MAC address in the EmacLite device */\n\txemaclite_update_address(lp, ndev->dev_addr);\n\n\tlp->phy_node = of_parse_phandle(ofdev->dev.of_node, \"phy-handle\", 0);\n\txemaclite_mdio_setup(lp, &ofdev->dev);\n\n\tdev_info(dev, \"MAC address is now %pM\\n\", ndev->dev_addr);\n\n\tndev->netdev_ops = &xemaclite_netdev_ops;\n\tndev->ethtool_ops = &xemaclite_ethtool_ops;\n\tndev->flags &= ~IFF_MULTICAST;\n\tndev->watchdog_timeo = TX_TIMEOUT;\n\n\t/* Finally, register the device */\n\trc = register_netdev(ndev);\n\tif (rc) {\n\t\tdev_err(dev,\n\t\t\t\"Cannot register network device, aborting\\n\");\n\t\tgoto error;\n\t}\n\n\tdev_info(dev,\n\t\t \"Xilinx EmacLite at 0x%08lX mapped to 0x%08lX, irq=%d\\n\",\n\t\t (unsigned long __force)ndev->mem_start,\n\t\t (unsigned long __force)lp->base_addr, ndev->irq);\n\treturn 0;\n\nerror:\n\tfree_netdev(ndev);\n\treturn rc;\n}",
        "func": "static int xemaclite_of_probe(struct platform_device *ofdev)\n{\n\tstruct resource *res;\n\tstruct net_device *ndev = NULL;\n\tstruct net_local *lp = NULL;\n\tstruct device *dev = &ofdev->dev;\n\n\tint rc = 0;\n\n\tdev_info(dev, \"Device Tree Probing\\n\");\n\n\t/* Create an ethernet device instance */\n\tndev = alloc_etherdev(sizeof(struct net_local));\n\tif (!ndev)\n\t\treturn -ENOMEM;\n\n\tdev_set_drvdata(dev, ndev);\n\tSET_NETDEV_DEV(ndev, &ofdev->dev);\n\n\tlp = netdev_priv(ndev);\n\tlp->ndev = ndev;\n\n\t/* Get IRQ for the device */\n\tres = platform_get_resource(ofdev, IORESOURCE_IRQ, 0);\n\tif (!res) {\n\t\tdev_err(dev, \"no IRQ found\\n\");\n\t\trc = -ENXIO;\n\t\tgoto error;\n\t}\n\n\tndev->irq = res->start;\n\n\tres = platform_get_resource(ofdev, IORESOURCE_MEM, 0);\n\tlp->base_addr = devm_ioremap_resource(&ofdev->dev, res);\n\tif (IS_ERR(lp->base_addr)) {\n\t\trc = PTR_ERR(lp->base_addr);\n\t\tgoto error;\n\t}\n\n\tndev->mem_start = res->start;\n\tndev->mem_end = res->end;\n\n\tspin_lock_init(&lp->reset_lock);\n\tlp->next_tx_buf_to_use = 0x0;\n\tlp->next_rx_buf_to_use = 0x0;\n\tlp->tx_ping_pong = get_bool(ofdev, \"xlnx,tx-ping-pong\");\n\tlp->rx_ping_pong = get_bool(ofdev, \"xlnx,rx-ping-pong\");\n\n\trc = of_get_mac_address(ofdev->dev.of_node, ndev->dev_addr);\n\tif (rc) {\n\t\tdev_warn(dev, \"No MAC address found, using random\\n\");\n\t\teth_hw_addr_random(ndev);\n\t}\n\n\t/* Clear the Tx CSR's in case this is a restart */\n\txemaclite_writel(0, lp->base_addr + XEL_TSR_OFFSET);\n\txemaclite_writel(0, lp->base_addr + XEL_BUFFER_OFFSET + XEL_TSR_OFFSET);\n\n\t/* Set the MAC address in the EmacLite device */\n\txemaclite_update_address(lp, ndev->dev_addr);\n\n\tlp->phy_node = of_parse_phandle(ofdev->dev.of_node, \"phy-handle\", 0);\n\txemaclite_mdio_setup(lp, &ofdev->dev);\n\n\tdev_info(dev, \"MAC address is now %pM\\n\", ndev->dev_addr);\n\n\tndev->netdev_ops = &xemaclite_netdev_ops;\n\tndev->ethtool_ops = &xemaclite_ethtool_ops;\n\tndev->flags &= ~IFF_MULTICAST;\n\tndev->watchdog_timeo = TX_TIMEOUT;\n\n\t/* Finally, register the device */\n\trc = register_netdev(ndev);\n\tif (rc) {\n\t\tdev_err(dev,\n\t\t\t\"Cannot register network device, aborting\\n\");\n\t\tgoto error;\n\t}\n\n\tdev_info(dev,\n\t\t \"Xilinx EmacLite at 0x%08lX mapped to 0x%p, irq=%d\\n\",\n\t\t (unsigned long __force)ndev->mem_start, lp->base_addr, ndev->irq);\n\treturn 0;\n\nerror:\n\tfree_netdev(ndev);\n\treturn rc;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -78,9 +78,8 @@\n \t}\n \n \tdev_info(dev,\n-\t\t \"Xilinx EmacLite at 0x%08lX mapped to 0x%08lX, irq=%d\\n\",\n-\t\t (unsigned long __force)ndev->mem_start,\n-\t\t (unsigned long __force)lp->base_addr, ndev->irq);\n+\t\t \"Xilinx EmacLite at 0x%08lX mapped to 0x%p, irq=%d\\n\",\n+\t\t (unsigned long __force)ndev->mem_start, lp->base_addr, ndev->irq);\n \treturn 0;\n \n error:",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t \"Xilinx EmacLite at 0x%08lX mapped to 0x%08lX, irq=%d\\n\",",
                "\t\t (unsigned long __force)ndev->mem_start,",
                "\t\t (unsigned long __force)lp->base_addr, ndev->irq);"
            ],
            "added_lines": [
                "\t\t \"Xilinx EmacLite at 0x%08lX mapped to 0x%p, irq=%d\\n\",",
                "\t\t (unsigned long __force)ndev->mem_start, lp->base_addr, ndev->irq);"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-37656",
        "func_name": "tensorflow/Compute",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions an attacker can cause undefined behavior via binding a reference to null pointer in `tf.raw_ops.RaggedTensorToSparse`. The [implementation](https://github.com/tensorflow/tensorflow/blob/f24faa153ad31a4b51578f8181d3aaab77a1ddeb/tensorflow/core/kernels/ragged_tensor_to_sparse_kernel.cc#L30) has an incomplete validation of the splits values: it does not check that they are in increasing order. We have patched the issue in GitHub commit 1071f554dbd09f7e101324d366eec5f4fe5a3ece. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/1071f554dbd09f7e101324d366eec5f4fe5a3ece",
        "commit_title": "Add missing validation to `RaggedTensorToSparse`.",
        "commit_text": " There needs to be a check that the splits allow for valid ragged tensors.  PiperOrigin-RevId: 387712169",
        "func_before": "void Compute(OpKernelContext* context) override {\n    // Read the `rt_nested_splits` input & convert to Eigen tensors.\n    OpInputList rt_nested_splits_in;\n    OP_REQUIRES_OK(\n        context, context->input_list(\"rt_nested_splits\", &rt_nested_splits_in));\n    const int rt_nested_splits_len = rt_nested_splits_in.size();\n    DCHECK_GT(rt_nested_splits_len, 0);  // Enforced by REGISTER_OP.\n    std::vector<ConstFlatSplits> rt_nested_splits;\n    rt_nested_splits.reserve(rt_nested_splits_len);\n    for (int i = 0; i < rt_nested_splits_len; ++i) {\n      rt_nested_splits.push_back(rt_nested_splits_in[i].flat<SPLITS_TYPE>());\n    }\n\n    // Read the `rt_dense_values` input.\n    const Tensor& rt_dense_values_in = context->input(rt_nested_splits_len);\n    OP_REQUIRES_OK(context,\n                   ValidateInputs(rt_nested_splits, rt_dense_values_in));\n\n    // Assemble each value in `sparse_indices` using three parts:\n    // - `index_prefix` is the index in dimensions up through the last ragged\n    //   dimension.\n    // - `index_middle` is the index in the last ragged dimension.\n    // - `index_suffix` is the index in the dense value dimensions.\n    std::vector<int64> index_prefix(rt_nested_splits_len);\n    std::vector<std::vector<int64>> index_suffixes =\n        MakeIndexSuffixes(rt_dense_values_in.shape());\n\n    // Allocate the `sparse_indices` output tensor.\n    const int64_t nvals =\n        (rt_nested_splits.back()(rt_nested_splits.back().size() - 1) *\n         index_suffixes.size());\n    const int64_t indices_len =\n        rt_nested_splits_len + rt_dense_values_in.dims();\n    Tensor* sparse_indices_out = nullptr;\n    OP_REQUIRES_OK(\n        context, context->allocate_output(0, TensorShape({nvals, indices_len}),\n                                          &sparse_indices_out));\n    auto sparse_indices = sparse_indices_out->tensor<int64, 2>();\n\n    // pos[i] is the current position in rt_nested_splits[i].  final_pos is a\n    // reference to make it easier to refer to pos[-1].\n    std::vector<int64> pos(rt_nested_splits_len);\n    int64& final_pos = pos[rt_nested_splits_len - 1];\n\n    // Each iteration through the loop, we increment pos[-1], and add indices\n    // for all the values corresponding to\n    // rt_nested_splits[-1][pos[-1]:pos[-1]+1].\n    int next_index = 0;\n    int max_final_pos = rt_nested_splits.back().size() - 1;\n    for (; final_pos < max_final_pos; ++final_pos) {\n      // Update `pos` to skip over completed elements (i.e., elements where\n      // we have already generated indices for all contained values).\n      for (int dim = rt_nested_splits_len - 2; dim >= 0; --dim) {\n        while (IsCompleted(pos, dim, rt_nested_splits)) {\n          pos[dim] += 1;\n        }\n      }\n\n      // Update index_prefix.\n      for (int dim = 0; dim < index_prefix.size(); ++dim) {\n        int start = dim > 0 ? rt_nested_splits[dim - 1](pos[dim - 1]) : 0;\n        index_prefix[dim] = pos[dim] - start;\n      }\n\n      // Get length of the final-ragged-dimension slice.\n      const auto& final_splits = rt_nested_splits[rt_nested_splits_len - 1];\n      int64_t slice_len = final_splits(final_pos + 1) - final_splits(final_pos);\n\n      // Add sparse_indices for this slice.\n      for (int64_t i = 0; i < slice_len; ++i) {\n        for (const auto& index_suffix : index_suffixes) {\n          int dim = 0;\n          for (int64_t index : index_prefix) {  // index_prefix\n            sparse_indices(next_index, dim++) = index;\n          }\n          sparse_indices(next_index, dim++) = i;  // index_middle\n          for (int64_t index : index_suffix) {    // index_suffix\n            sparse_indices(next_index, dim++) = index;\n          }\n          DCHECK_EQ(dim, indices_len);\n          ++next_index;\n        }\n      }\n    }\n    DCHECK_EQ(next_index, nvals);\n\n    // Output the `sparse_values` Tensor.\n    if (rt_dense_values_in.dims() == 1) {\n      context->set_output(1, rt_dense_values_in);\n    } else {\n      Tensor sparse_values_out(rt_dense_values_in.dtype());\n      bool shapes_match = sparse_values_out.CopyFrom(\n          rt_dense_values_in, {rt_dense_values_in.NumElements()});\n      DCHECK(shapes_match);\n      context->set_output(1, sparse_values_out);\n    }\n\n    // Output the `sparse_dense_shape` Tensor.\n    int64_t ndims = rt_nested_splits_len + rt_dense_values_in.dims();\n    Tensor* sparse_dense_shape_out = nullptr;\n    OP_REQUIRES_OK(context, context->allocate_output(2, TensorShape({ndims}),\n                                                     &sparse_dense_shape_out));\n    auto sparse_dense_shape = sparse_dense_shape_out->vec<int64>();\n    sparse_dense_shape(0) = rt_nested_splits_in[0].dim_size(0) - 1;\n    for (int dim = 0; dim < rt_nested_splits_len; ++dim) {\n      const auto& splits = rt_nested_splits[dim];\n      SPLITS_TYPE max_width = 0;\n      for (int i = 1; i < splits.size(); ++i) {\n        max_width = std::max(max_width, splits(i) - splits(i - 1));\n      }\n      sparse_dense_shape(dim + 1) = max_width;\n    }\n    for (int dim = 1; dim < rt_dense_values_in.dims(); ++dim) {\n      sparse_dense_shape(dim + rt_nested_splits_len) =\n          rt_dense_values_in.dim_size(dim);\n    }\n  }",
        "func": "void Compute(OpKernelContext* context) override {\n    // Read the `rt_nested_splits` input & convert to Eigen tensors.\n    OpInputList rt_nested_splits_in;\n    OP_REQUIRES_OK(\n        context, context->input_list(\"rt_nested_splits\", &rt_nested_splits_in));\n    const int rt_nested_splits_len = rt_nested_splits_in.size();\n    OP_REQUIRES(context, rt_nested_splits_len > 0,\n                errors::InvalidArgument(\"rt_nested_splits must be non empty\"));\n    std::vector<ConstFlatSplits> rt_nested_splits;\n    rt_nested_splits.reserve(rt_nested_splits_len);\n    for (int i = 0; i < rt_nested_splits_len; ++i) {\n      rt_nested_splits.push_back(rt_nested_splits_in[i].flat<SPLITS_TYPE>());\n    }\n\n    // Read the `rt_dense_values` input.\n    const Tensor& rt_dense_values_in = context->input(rt_nested_splits_len);\n    OP_REQUIRES_OK(context,\n                   ValidateInputs(rt_nested_splits, rt_dense_values_in));\n\n    // Assemble each value in `sparse_indices` using three parts:\n    // - `index_prefix` is the index in dimensions up through the last ragged\n    //   dimension.\n    // - `index_middle` is the index in the last ragged dimension.\n    // - `index_suffix` is the index in the dense value dimensions.\n    std::vector<int64> index_prefix(rt_nested_splits_len);\n    std::vector<std::vector<int64>> index_suffixes =\n        MakeIndexSuffixes(rt_dense_values_in.shape());\n\n    // Allocate the `sparse_indices` output tensor.\n    const int64_t nvals =\n        (rt_nested_splits.back()(rt_nested_splits.back().size() - 1) *\n         index_suffixes.size());\n    const int64_t indices_len =\n        rt_nested_splits_len + rt_dense_values_in.dims();\n    Tensor* sparse_indices_out = nullptr;\n    OP_REQUIRES_OK(\n        context, context->allocate_output(0, TensorShape({nvals, indices_len}),\n                                          &sparse_indices_out));\n    auto sparse_indices = sparse_indices_out->tensor<int64, 2>();\n\n    // pos[i] is the current position in rt_nested_splits[i].  final_pos is a\n    // reference to make it easier to refer to pos[-1].\n    std::vector<int64> pos(rt_nested_splits_len);\n    int64& final_pos = pos[rt_nested_splits_len - 1];\n\n    // Each iteration through the loop, we increment pos[-1], and add indices\n    // for all the values corresponding to\n    // rt_nested_splits[-1][pos[-1]:pos[-1]+1].\n    int next_index = 0;\n    int max_final_pos = rt_nested_splits.back().size() - 1;\n    for (; final_pos < max_final_pos; ++final_pos) {\n      // Update `pos` to skip over completed elements (i.e., elements where\n      // we have already generated indices for all contained values).\n      for (int dim = rt_nested_splits_len - 2; dim >= 0; --dim) {\n        while (IsCompleted(pos, dim, rt_nested_splits)) {\n          pos[dim] += 1;\n        }\n      }\n\n      // Update index_prefix.\n      for (int dim = 0; dim < index_prefix.size(); ++dim) {\n        int start = dim > 0 ? rt_nested_splits[dim - 1](pos[dim - 1]) : 0;\n        index_prefix[dim] = pos[dim] - start;\n      }\n\n      // Get length of the final-ragged-dimension slice.\n      const auto& final_splits = rt_nested_splits[rt_nested_splits_len - 1];\n      int64_t slice_len = final_splits(final_pos + 1) - final_splits(final_pos);\n\n      // Add sparse_indices for this slice.\n      for (int64_t i = 0; i < slice_len; ++i) {\n        for (const auto& index_suffix : index_suffixes) {\n          int dim = 0;\n          for (int64_t index : index_prefix) {  // index_prefix\n            sparse_indices(next_index, dim++) = index;\n          }\n          sparse_indices(next_index, dim++) = i;  // index_middle\n          for (int64_t index : index_suffix) {    // index_suffix\n            sparse_indices(next_index, dim++) = index;\n          }\n          DCHECK_EQ(dim, indices_len);\n          ++next_index;\n        }\n      }\n    }\n    DCHECK_EQ(next_index, nvals);\n\n    // Output the `sparse_values` Tensor.\n    if (rt_dense_values_in.dims() == 1) {\n      context->set_output(1, rt_dense_values_in);\n    } else {\n      Tensor sparse_values_out(rt_dense_values_in.dtype());\n      bool shapes_match = sparse_values_out.CopyFrom(\n          rt_dense_values_in, {rt_dense_values_in.NumElements()});\n      DCHECK(shapes_match);\n      context->set_output(1, sparse_values_out);\n    }\n\n    // Output the `sparse_dense_shape` Tensor.\n    int64_t ndims = rt_nested_splits_len + rt_dense_values_in.dims();\n    Tensor* sparse_dense_shape_out = nullptr;\n    OP_REQUIRES_OK(context, context->allocate_output(2, TensorShape({ndims}),\n                                                     &sparse_dense_shape_out));\n    auto sparse_dense_shape = sparse_dense_shape_out->vec<int64>();\n    sparse_dense_shape(0) = rt_nested_splits_in[0].dim_size(0) - 1;\n    for (int dim = 0; dim < rt_nested_splits_len; ++dim) {\n      const auto& splits = rt_nested_splits[dim];\n      SPLITS_TYPE max_width = 0;\n      for (int i = 1; i < splits.size(); ++i) {\n        max_width = std::max(max_width, splits(i) - splits(i - 1));\n      }\n      sparse_dense_shape(dim + 1) = max_width;\n    }\n    for (int dim = 1; dim < rt_dense_values_in.dims(); ++dim) {\n      sparse_dense_shape(dim + rt_nested_splits_len) =\n          rt_dense_values_in.dim_size(dim);\n    }\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,7 +4,8 @@\n     OP_REQUIRES_OK(\n         context, context->input_list(\"rt_nested_splits\", &rt_nested_splits_in));\n     const int rt_nested_splits_len = rt_nested_splits_in.size();\n-    DCHECK_GT(rt_nested_splits_len, 0);  // Enforced by REGISTER_OP.\n+    OP_REQUIRES(context, rt_nested_splits_len > 0,\n+                errors::InvalidArgument(\"rt_nested_splits must be non empty\"));\n     std::vector<ConstFlatSplits> rt_nested_splits;\n     rt_nested_splits.reserve(rt_nested_splits_len);\n     for (int i = 0; i < rt_nested_splits_len; ++i) {",
        "diff_line_info": {
            "deleted_lines": [
                "    DCHECK_GT(rt_nested_splits_len, 0);  // Enforced by REGISTER_OP."
            ],
            "added_lines": [
                "    OP_REQUIRES(context, rt_nested_splits_len > 0,",
                "                errors::InvalidArgument(\"rt_nested_splits must be non empty\"));"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-37656",
        "func_name": "tensorflow/ValidateInputs",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions an attacker can cause undefined behavior via binding a reference to null pointer in `tf.raw_ops.RaggedTensorToSparse`. The [implementation](https://github.com/tensorflow/tensorflow/blob/f24faa153ad31a4b51578f8181d3aaab77a1ddeb/tensorflow/core/kernels/ragged_tensor_to_sparse_kernel.cc#L30) has an incomplete validation of the splits values: it does not check that they are in increasing order. We have patched the issue in GitHub commit 1071f554dbd09f7e101324d366eec5f4fe5a3ece. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/1071f554dbd09f7e101324d366eec5f4fe5a3ece",
        "commit_title": "Add missing validation to `RaggedTensorToSparse`.",
        "commit_text": " There needs to be a check that the splits allow for valid ragged tensors.  PiperOrigin-RevId: 387712169",
        "func_before": "static ::tensorflow::Status ValidateInputs(\n      std::vector<ConstFlatSplits> rt_nested_splits,\n      const Tensor& rt_dense_values_in) {\n    for (int i = 0; i < rt_nested_splits.size(); ++i) {\n      if (rt_nested_splits[i].size() == 0) {\n        return InvalidArgument(\"ragged splits may not be empty.\");\n      }\n      if (rt_nested_splits[i](0) != 0) {\n        return InvalidArgument(\"First value of ragged splits must be 0.\");\n      }\n      if (i > 0) {\n        SPLITS_TYPE last_split =\n            rt_nested_splits[i - 1](rt_nested_splits[i - 1].size() - 1);\n        if (rt_nested_splits[i].size() != last_split + 1) {\n          return InvalidArgument(\n              \"Final value of ragged splits must match the length \"\n              \"the corresponding ragged values.\");\n        }\n      }\n    }\n    if (rt_dense_values_in.dim_size(0) !=\n        rt_nested_splits.back()(rt_nested_splits.back().size() - 1)) {\n      return InvalidArgument(\n          \"Final value of ragged splits must match the length \"\n          \"the corresponding ragged values.\");\n    }\n    return ::tensorflow::Status::OK();\n  }",
        "func": "static ::tensorflow::Status ValidateInputs(\n      std::vector<ConstFlatSplits> rt_nested_splits,\n      const Tensor& rt_dense_values_in) {\n    for (int i = 0; i < rt_nested_splits.size(); ++i) {\n      if (rt_nested_splits[i].size() == 0) {\n        return InvalidArgument(\"ragged splits may not be empty.\");\n      }\n      if (rt_nested_splits[i](0) != 0) {\n        return InvalidArgument(\"First value of ragged splits must be 0.\");\n      }\n      for (int j = 1; j < rt_nested_splits[i].size(); ++j) {\n        if (rt_nested_splits[i](j) < rt_nested_splits[i](j - 1)) {\n          return InvalidArgument(\n              \"Ragged splits should be non decreasing, but we got \",\n              rt_nested_splits[i](j - 1), \" followed by \",\n              rt_nested_splits[i](j));\n        }\n      }\n      if (i > 0) {\n        SPLITS_TYPE last_split =\n            rt_nested_splits[i - 1](rt_nested_splits[i - 1].size() - 1);\n        if (rt_nested_splits[i].size() != last_split + 1) {\n          return InvalidArgument(\n              \"Final value of ragged splits must match the length \"\n              \"the corresponding ragged values.\");\n        }\n      }\n    }\n    if (rt_dense_values_in.dim_size(0) !=\n        rt_nested_splits.back()(rt_nested_splits.back().size() - 1)) {\n      return InvalidArgument(\n          \"Final value of ragged splits must match the length \"\n          \"the corresponding ragged values.\");\n    }\n    return ::tensorflow::Status::OK();\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -7,6 +7,14 @@\n       }\n       if (rt_nested_splits[i](0) != 0) {\n         return InvalidArgument(\"First value of ragged splits must be 0.\");\n+      }\n+      for (int j = 1; j < rt_nested_splits[i].size(); ++j) {\n+        if (rt_nested_splits[i](j) < rt_nested_splits[i](j - 1)) {\n+          return InvalidArgument(\n+              \"Ragged splits should be non decreasing, but we got \",\n+              rt_nested_splits[i](j - 1), \" followed by \",\n+              rt_nested_splits[i](j));\n+        }\n       }\n       if (i > 0) {\n         SPLITS_TYPE last_split =",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "      }",
                "      for (int j = 1; j < rt_nested_splits[i].size(); ++j) {",
                "        if (rt_nested_splits[i](j) < rt_nested_splits[i](j - 1)) {",
                "          return InvalidArgument(",
                "              \"Ragged splits should be non decreasing, but we got \",",
                "              rt_nested_splits[i](j - 1), \" followed by \",",
                "              rt_nested_splits[i](j));",
                "        }"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-37657",
        "func_name": "tensorflow/Compute",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions an attacker can cause undefined behavior via binding a reference to null pointer in all operations of type `tf.raw_ops.MatrixDiagV*`. The [implementation](https://github.com/tensorflow/tensorflow/blob/84d053187cb80d975ef2b9684d4b61981bca0c41/tensorflow/core/kernels/linalg/matrix_diag_op.cc) has incomplete validation that the value of `k` is a valid tensor. We have check that this value is either a scalar or a vector, but there is no check for the number of elements. If this is an empty tensor, then code that accesses the first element of the tensor is wrong. We have patched the issue in GitHub commit f2a673bd34f0d64b8e40a551ac78989d16daad09. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/f2a673bd34f0d64b8e40a551ac78989d16daad09",
        "commit_title": "Add missing validation to `matrix_diag_op.cc`",
        "commit_text": " PiperOrigin-RevId: 387923533",
        "func_before": "void Compute(OpKernelContext* context) override {\n    const Tensor& diagonal = context->input(0);\n\n    // MatrixDiag and MatrixDiagV2 both use this OpKernel. MatrixDiag only has\n    // one input, so we have to check the number of inputs before reading\n    // additional parameters in MatrixDiagV2.\n    int32_t lower_diag_index = 0;\n    int32_t upper_diag_index = 0;\n    int32_t num_rows = -1;\n    int32_t num_cols = -1;\n    T padding_value(0);\n\n    // MatrixDiagOpV2-specific.\n    if (context->num_inputs() > kNumV1Inputs) {\n      auto& diag_index = context->input(1);\n      OP_REQUIRES(context,\n                  TensorShapeUtils::IsScalar(diag_index.shape()) ||\n                      TensorShapeUtils::IsVector(diag_index.shape()),\n                  errors::InvalidArgument(\n                      \"diag_index must be a scalar or vector, received shape: \",\n                      diag_index.shape().DebugString()));\n      lower_diag_index = diag_index.flat<int32>()(0);\n      upper_diag_index = lower_diag_index;\n      if (TensorShapeUtils::IsVector(diag_index.shape())) {\n        auto diag_index_size = diag_index.dim_size(0);\n        OP_REQUIRES(\n            context, 0 < diag_index_size && diag_index_size <= 2,\n            errors::InvalidArgument(\n                \"diag_index must have only one or two elements, received \",\n                diag_index_size, \" elements.\"));\n        if (diag_index_size > 1) {\n          upper_diag_index = diag_index.flat<int32>()(1);\n        }\n      }\n\n      auto& num_rows_tensor = context->input(2);\n      OP_REQUIRES(context, TensorShapeUtils::IsScalar(num_rows_tensor.shape()),\n                  errors::InvalidArgument(\"num_rows must be a scalar\"));\n      num_rows = num_rows_tensor.flat<int32>()(0);\n\n      auto& num_cols_tensor = context->input(3);\n      OP_REQUIRES(context, TensorShapeUtils::IsScalar(num_cols_tensor.shape()),\n                  errors::InvalidArgument(\"num_cols must be a scalar\"));\n      num_cols = num_cols_tensor.flat<int32>()(0);\n\n      auto& padding_value_tensor = context->input(4);\n      OP_REQUIRES(context,\n                  TensorShapeUtils::IsScalar(padding_value_tensor.shape()),\n                  errors::InvalidArgument(\"padding_value must be a scalar\"));\n      padding_value = padding_value_tensor.flat<T>()(0);\n    }\n\n    // Size validations.\n    const TensorShape& diagonal_shape = diagonal.shape();\n    const int diag_rank = diagonal_shape.dims();\n    const Eigen::Index num_diags = upper_diag_index - lower_diag_index + 1;\n    OP_REQUIRES(context, TensorShapeUtils::IsVectorOrHigher(diagonal_shape),\n                errors::InvalidArgument(\n                    \"diagonal must be at least 1-dim, received shape: \",\n                    diagonal.shape().DebugString()));\n    OP_REQUIRES(\n        context, lower_diag_index <= upper_diag_index,\n        errors::InvalidArgument(\n            \"lower_diag_index must not be larger than upper_diag_index: \",\n            lower_diag_index, \" > \", upper_diag_index));\n    OP_REQUIRES(context,\n                lower_diag_index == upper_diag_index ||\n                    diagonal_shape.dim_size(diag_rank - 2) == num_diags,\n                errors::InvalidArgument(\n                    \"The number of diagonals provided in the input does not \"\n                    \"match the lower_diag_index and upper_diag_index range.\"));\n\n    const Eigen::Index max_diag_len = diagonal_shape.dim_size(diag_rank - 1);\n    const int32_t min_num_rows = max_diag_len - std::min(upper_diag_index, 0);\n    const int32_t min_num_cols = max_diag_len + std::max(lower_diag_index, 0);\n    OP_REQUIRES(context, num_rows == -1 || num_rows >= min_num_rows,\n                errors::InvalidArgument(\"The number of rows is too small.\"));\n    OP_REQUIRES(context, num_cols == -1 || num_cols >= min_num_cols,\n                errors::InvalidArgument(\"The number of columns is too small.\"));\n\n    // If both num_rows and num_cols are unknown, assume that output is square.\n    // Otherwise, use smallest possible values.\n    if (num_rows == -1 && num_cols == -1) {\n      num_rows = std::max(min_num_rows, min_num_cols);\n      num_cols = num_rows;\n    } else if (num_rows == -1) {\n      num_rows = min_num_rows;\n    } else if (num_cols == -1) {\n      num_cols = min_num_cols;\n    }\n    OP_REQUIRES(context, num_rows == min_num_rows || num_cols == min_num_cols,\n                errors::InvalidArgument(\n                    \"The number of rows or columns is not consistent with \"\n                    \"the specified d_lower, d_upper, and diagonal.\"));\n\n    TensorShape output_shape = diagonal_shape;\n    if (num_diags == 1) {  // Output has rank `rank+1`.\n      output_shape.set_dim(diag_rank - 1, num_rows);\n      output_shape.AddDim(num_cols);\n    } else {  // Output has rank `rank`.\n      output_shape.set_dim(diag_rank - 2, num_rows);\n      output_shape.set_dim(diag_rank - 1, num_cols);\n    }\n\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(context, context->allocate_output(0, output_shape, &output));\n    auto output_reshaped = output->flat_inner_dims<T, 3>();\n    auto diag_reshaped = diagonal.flat<T>();\n    functor::MatrixDiag<Device, T>::Compute(\n        context, context->eigen_device<Device>(), diag_reshaped,\n        output_reshaped, lower_diag_index, upper_diag_index, max_diag_len,\n        padding_value, left_align_superdiagonal_, left_align_subdiagonal_);\n  }",
        "func": "void Compute(OpKernelContext* context) override {\n    const Tensor& diagonal = context->input(0);\n\n    // MatrixDiag and MatrixDiagV2 both use this OpKernel. MatrixDiag only has\n    // one input, so we have to check the number of inputs before reading\n    // additional parameters in MatrixDiagV2.\n    int32_t lower_diag_index = 0;\n    int32_t upper_diag_index = 0;\n    int32_t num_rows = -1;\n    int32_t num_cols = -1;\n    T padding_value(0);\n\n    // MatrixDiagOpV2-specific.\n    if (context->num_inputs() > kNumV1Inputs) {\n      auto& diag_index = context->input(1);\n      OP_REQUIRES(context,\n                  TensorShapeUtils::IsScalar(diag_index.shape()) ||\n                      TensorShapeUtils::IsVector(diag_index.shape()),\n                  errors::InvalidArgument(\n                      \"diag_index must be a scalar or vector, received shape: \",\n                      diag_index.shape().DebugString()));\n      OP_REQUIRES(context, diag_index.NumElements() > 0,\n                  errors::InvalidArgument(\n                      \"Expected diag_index to have at least 1 element\"));\n      lower_diag_index = diag_index.flat<int32>()(0);\n      upper_diag_index = lower_diag_index;\n      if (TensorShapeUtils::IsVector(diag_index.shape())) {\n        auto diag_index_size = diag_index.dim_size(0);\n        OP_REQUIRES(\n            context, 0 < diag_index_size && diag_index_size <= 2,\n            errors::InvalidArgument(\n                \"diag_index must have only one or two elements, received \",\n                diag_index_size, \" elements.\"));\n        if (diag_index_size > 1) {\n          upper_diag_index = diag_index.flat<int32>()(1);\n        }\n      }\n\n      auto& num_rows_tensor = context->input(2);\n      OP_REQUIRES(context, TensorShapeUtils::IsScalar(num_rows_tensor.shape()),\n                  errors::InvalidArgument(\"num_rows must be a scalar\"));\n      num_rows = num_rows_tensor.flat<int32>()(0);\n\n      auto& num_cols_tensor = context->input(3);\n      OP_REQUIRES(context, TensorShapeUtils::IsScalar(num_cols_tensor.shape()),\n                  errors::InvalidArgument(\"num_cols must be a scalar\"));\n      num_cols = num_cols_tensor.flat<int32>()(0);\n\n      auto& padding_value_tensor = context->input(4);\n      OP_REQUIRES(context,\n                  TensorShapeUtils::IsScalar(padding_value_tensor.shape()),\n                  errors::InvalidArgument(\"padding_value must be a scalar\"));\n      padding_value = padding_value_tensor.flat<T>()(0);\n    }\n\n    // Size validations.\n    const TensorShape& diagonal_shape = diagonal.shape();\n    const int diag_rank = diagonal_shape.dims();\n    const Eigen::Index num_diags = upper_diag_index - lower_diag_index + 1;\n    OP_REQUIRES(context, TensorShapeUtils::IsVectorOrHigher(diagonal_shape),\n                errors::InvalidArgument(\n                    \"diagonal must be at least 1-dim, received shape: \",\n                    diagonal.shape().DebugString()));\n    OP_REQUIRES(\n        context, lower_diag_index <= upper_diag_index,\n        errors::InvalidArgument(\n            \"lower_diag_index must not be larger than upper_diag_index: \",\n            lower_diag_index, \" > \", upper_diag_index));\n    OP_REQUIRES(context,\n                lower_diag_index == upper_diag_index ||\n                    diagonal_shape.dim_size(diag_rank - 2) == num_diags,\n                errors::InvalidArgument(\n                    \"The number of diagonals provided in the input does not \"\n                    \"match the lower_diag_index and upper_diag_index range.\"));\n\n    const Eigen::Index max_diag_len = diagonal_shape.dim_size(diag_rank - 1);\n    const int32_t min_num_rows = max_diag_len - std::min(upper_diag_index, 0);\n    const int32_t min_num_cols = max_diag_len + std::max(lower_diag_index, 0);\n    OP_REQUIRES(context, num_rows == -1 || num_rows >= min_num_rows,\n                errors::InvalidArgument(\"The number of rows is too small.\"));\n    OP_REQUIRES(context, num_cols == -1 || num_cols >= min_num_cols,\n                errors::InvalidArgument(\"The number of columns is too small.\"));\n\n    // If both num_rows and num_cols are unknown, assume that output is square.\n    // Otherwise, use smallest possible values.\n    if (num_rows == -1 && num_cols == -1) {\n      num_rows = std::max(min_num_rows, min_num_cols);\n      num_cols = num_rows;\n    } else if (num_rows == -1) {\n      num_rows = min_num_rows;\n    } else if (num_cols == -1) {\n      num_cols = min_num_cols;\n    }\n    OP_REQUIRES(context, num_rows == min_num_rows || num_cols == min_num_cols,\n                errors::InvalidArgument(\n                    \"The number of rows or columns is not consistent with \"\n                    \"the specified d_lower, d_upper, and diagonal.\"));\n\n    TensorShape output_shape = diagonal_shape;\n    if (num_diags == 1) {  // Output has rank `rank+1`.\n      output_shape.set_dim(diag_rank - 1, num_rows);\n      output_shape.AddDim(num_cols);\n    } else {  // Output has rank `rank`.\n      output_shape.set_dim(diag_rank - 2, num_rows);\n      output_shape.set_dim(diag_rank - 1, num_cols);\n    }\n\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(context, context->allocate_output(0, output_shape, &output));\n    auto output_reshaped = output->flat_inner_dims<T, 3>();\n    auto diag_reshaped = diagonal.flat<T>();\n    functor::MatrixDiag<Device, T>::Compute(\n        context, context->eigen_device<Device>(), diag_reshaped,\n        output_reshaped, lower_diag_index, upper_diag_index, max_diag_len,\n        padding_value, left_align_superdiagonal_, left_align_subdiagonal_);\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -19,6 +19,9 @@\n                   errors::InvalidArgument(\n                       \"diag_index must be a scalar or vector, received shape: \",\n                       diag_index.shape().DebugString()));\n+      OP_REQUIRES(context, diag_index.NumElements() > 0,\n+                  errors::InvalidArgument(\n+                      \"Expected diag_index to have at least 1 element\"));\n       lower_diag_index = diag_index.flat<int32>()(0);\n       upper_diag_index = lower_diag_index;\n       if (TensorShapeUtils::IsVector(diag_index.shape())) {",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "      OP_REQUIRES(context, diag_index.NumElements() > 0,",
                "                  errors::InvalidArgument(",
                "                      \"Expected diag_index to have at least 1 element\"));"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-37658",
        "func_name": "tensorflow/Compute",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions an attacker can cause undefined behavior via binding a reference to null pointer in all operations of type `tf.raw_ops.MatrixSetDiagV*`. The [implementation](https://github.com/tensorflow/tensorflow/blob/84d053187cb80d975ef2b9684d4b61981bca0c41/tensorflow/core/kernels/linalg/matrix_diag_op.cc) has incomplete validation that the value of `k` is a valid tensor. We have check that this value is either a scalar or a vector, but there is no check for the number of elements. If this is an empty tensor, then code that accesses the first element of the tensor is wrong. We have patched the issue in GitHub commit ff8894044dfae5568ecbf2ed514c1a37dc394f1b. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/ff8894044dfae5568ecbf2ed514c1a37dc394f1b",
        "commit_title": "Add one missing valdiation to `matrix_set_diag_op.cc`",
        "commit_text": " PiperOrigin-RevId: 387923408",
        "func_before": "void Compute(OpKernelContext* context) override {\n    const Tensor& input = context->input(0);\n    const Tensor& diag = context->input(1);\n\n    // MatrixSetDiag and MatrixSetDiagV2 both use this OpKernel. MatrixSetDiag\n    // only has two inputs, so we have to check the number of inputs before\n    // reading additional parameters in MatrixSetDiagV2.\n    int32_t lower_diag_index = 0;\n    int32_t upper_diag_index = 0;\n\n    // MatrixSetDiagV2-specific.\n    if (context->num_inputs() > kNumV1Inputs) {\n      auto& diag_index = context->input(2);\n      OP_REQUIRES(context,\n                  TensorShapeUtils::IsScalar(diag_index.shape()) ||\n                      TensorShapeUtils::IsVector(diag_index.shape()),\n                  errors::InvalidArgument(\n                      \"diag_index must be a scalar or vector, received shape: \",\n                      diag_index.shape().DebugString()));\n      lower_diag_index = diag_index.flat<int32>()(0);\n      upper_diag_index = lower_diag_index;\n      if (TensorShapeUtils::IsVector(diag_index.shape())) {\n        auto diag_index_size = diag_index.dim_size(0);\n        OP_REQUIRES(\n            context, 0 < diag_index_size && diag_index_size <= 2,\n            errors::InvalidArgument(\n                \"diag_index must have only one or two elements, received \",\n                diag_index_size, \" elements.\"));\n        if (diag_index_size > 1) {\n          upper_diag_index = diag_index.flat<int32>()(1);\n        }\n      }\n    }\n\n    const TensorShape& input_shape = input.shape();\n    const TensorShape& diag_shape = diag.shape();\n    const int input_rank = input_shape.dims();\n\n    // Preliminary validation of sizes.\n    OP_REQUIRES(context, TensorShapeUtils::IsMatrixOrHigher(input_shape),\n                errors::InvalidArgument(\n                    \"input must be at least 2-dim, received shape: \",\n                    input.shape().DebugString()));\n    OP_REQUIRES(context, TensorShapeUtils::IsVectorOrHigher(diag_shape),\n                errors::InvalidArgument(\n                    \"diagonal must be at least 1-dim, received shape: \",\n                    diag_shape.DebugString()));\n\n    // Make sure lower_diag_index and upper_diag_index is valid.\n    const Eigen::Index num_rows = input_shape.dim_size(input_rank - 2);\n    const Eigen::Index num_cols = input_shape.dim_size(input_rank - 1);\n    OP_REQUIRES(  // Checks lower_diag_index == 0 for when matrix shape = 0.\n        context,\n        (-num_rows < lower_diag_index && lower_diag_index < num_cols) ||\n            lower_diag_index == 0,\n        errors::InvalidArgument(\n            \"lower_diag_index is out of bound: \", lower_diag_index,\n            \" It must be between \", -num_rows, \" and \", num_cols));\n    OP_REQUIRES(context,\n                (-num_rows < upper_diag_index && upper_diag_index < num_cols) ||\n                    upper_diag_index == 0,\n                errors::InvalidArgument(\n                    \"upper_diag_index is out of bound: \", upper_diag_index,\n                    \" It must be between \", -num_rows, \" and \", num_cols));\n    OP_REQUIRES(\n        context, lower_diag_index <= upper_diag_index,\n        errors::InvalidArgument(\n            \"lower_diag_index must not be larger than upper_diag_index: \",\n            lower_diag_index, \" > \", upper_diag_index));\n\n    // Check if diag size is consistent with input.\n    const Eigen::Index num_diags = upper_diag_index - lower_diag_index + 1;\n    OP_REQUIRES(\n        context,\n        lower_diag_index == upper_diag_index ||\n            (diag_shape.dim_size(input_rank - 2) == num_diags),\n        errors::InvalidArgument(\"The number of diagonals provided in `diag` \"\n                                \"is not consistent with `lower_diag_index` and \"\n                                \"`upper_diag_index`\"));\n\n    TensorShape expected_diag_shape = input_shape;\n    expected_diag_shape.RemoveLastDims(2);\n    if (num_diags > 1) expected_diag_shape.AddDim(num_diags);\n    const int32_t max_diag_len =\n        std::min(num_rows + std::min(upper_diag_index, 0),\n                 num_cols - std::max(lower_diag_index, 0));\n    expected_diag_shape.AddDim(max_diag_len);\n    OP_REQUIRES(\n        context, expected_diag_shape == diag_shape,\n        errors::InvalidArgument(\n            \"Either first dimensions of diagonal don't match input.shape[:-2], \"\n            \"or diagonal.shape[:-1] is not equal to the longests diagonal in \"\n            \"range [lower_diag_index:upper_diag_index].\\nInput shape: \",\n            input_shape.DebugString(),\n            \"\\nDiagonal shape: \", diag_shape.DebugString(),\n            \"\\nExpected diagonal shape: \", expected_diag_shape.DebugString()));\n\n    if (input.NumElements() == 0) {\n      // This is a no-op.\n      context->set_output(0, input);\n      return;\n    }\n\n    auto input_reshaped = input.flat_inner_dims<T, 3>();\n    auto diag_reshaped = diag.flat<T>();\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(context, context->forward_input_or_allocate_output(\n                                {0}, 0, input_shape, &output));\n    auto output_reshaped = output->flat_inner_dims<T, 3>();\n    functor::MatrixSetDiag<Device, T>::Compute(\n        context, context->eigen_device<Device>(), input_reshaped, diag_reshaped,\n        output_reshaped, lower_diag_index, upper_diag_index, max_diag_len,\n        left_align_superdiagonal_, left_align_subdiagonal_);\n  }",
        "func": "void Compute(OpKernelContext* context) override {\n    const Tensor& input = context->input(0);\n    const Tensor& diag = context->input(1);\n\n    // MatrixSetDiag and MatrixSetDiagV2 both use this OpKernel. MatrixSetDiag\n    // only has two inputs, so we have to check the number of inputs before\n    // reading additional parameters in MatrixSetDiagV2.\n    int32_t lower_diag_index = 0;\n    int32_t upper_diag_index = 0;\n\n    // MatrixSetDiagV2-specific.\n    if (context->num_inputs() > kNumV1Inputs) {\n      auto& diag_index = context->input(2);\n      OP_REQUIRES(context,\n                  TensorShapeUtils::IsScalar(diag_index.shape()) ||\n                      TensorShapeUtils::IsVector(diag_index.shape()),\n                  errors::InvalidArgument(\n                      \"diag_index must be a scalar or vector, received shape: \",\n                      diag_index.shape().DebugString()));\n      OP_REQUIRES(\n          context, diag_index.NumElements() > 0,\n          errors::InvalidArgument(\"diag_index must have at least one element\"));\n      lower_diag_index = diag_index.flat<int32>()(0);\n      upper_diag_index = lower_diag_index;\n      if (TensorShapeUtils::IsVector(diag_index.shape())) {\n        auto diag_index_size = diag_index.dim_size(0);\n        OP_REQUIRES(\n            context, 0 < diag_index_size && diag_index_size <= 2,\n            errors::InvalidArgument(\n                \"diag_index must have only one or two elements, received \",\n                diag_index_size, \" elements.\"));\n        if (diag_index_size > 1) {\n          upper_diag_index = diag_index.flat<int32>()(1);\n        }\n      }\n    }\n\n    const TensorShape& input_shape = input.shape();\n    const TensorShape& diag_shape = diag.shape();\n    const int input_rank = input_shape.dims();\n\n    // Preliminary validation of sizes.\n    OP_REQUIRES(context, TensorShapeUtils::IsMatrixOrHigher(input_shape),\n                errors::InvalidArgument(\n                    \"input must be at least 2-dim, received shape: \",\n                    input.shape().DebugString()));\n    OP_REQUIRES(context, TensorShapeUtils::IsVectorOrHigher(diag_shape),\n                errors::InvalidArgument(\n                    \"diagonal must be at least 1-dim, received shape: \",\n                    diag_shape.DebugString()));\n\n    // Make sure lower_diag_index and upper_diag_index is valid.\n    const Eigen::Index num_rows = input_shape.dim_size(input_rank - 2);\n    const Eigen::Index num_cols = input_shape.dim_size(input_rank - 1);\n    OP_REQUIRES(  // Checks lower_diag_index == 0 for when matrix shape = 0.\n        context,\n        (-num_rows < lower_diag_index && lower_diag_index < num_cols) ||\n            lower_diag_index == 0,\n        errors::InvalidArgument(\n            \"lower_diag_index is out of bound: \", lower_diag_index,\n            \" It must be between \", -num_rows, \" and \", num_cols));\n    OP_REQUIRES(context,\n                (-num_rows < upper_diag_index && upper_diag_index < num_cols) ||\n                    upper_diag_index == 0,\n                errors::InvalidArgument(\n                    \"upper_diag_index is out of bound: \", upper_diag_index,\n                    \" It must be between \", -num_rows, \" and \", num_cols));\n    OP_REQUIRES(\n        context, lower_diag_index <= upper_diag_index,\n        errors::InvalidArgument(\n            \"lower_diag_index must not be larger than upper_diag_index: \",\n            lower_diag_index, \" > \", upper_diag_index));\n\n    // Check if diag size is consistent with input.\n    const Eigen::Index num_diags = upper_diag_index - lower_diag_index + 1;\n    OP_REQUIRES(\n        context,\n        lower_diag_index == upper_diag_index ||\n            (diag_shape.dim_size(input_rank - 2) == num_diags),\n        errors::InvalidArgument(\"The number of diagonals provided in `diag` \"\n                                \"is not consistent with `lower_diag_index` and \"\n                                \"`upper_diag_index`\"));\n\n    TensorShape expected_diag_shape = input_shape;\n    expected_diag_shape.RemoveLastDims(2);\n    if (num_diags > 1) expected_diag_shape.AddDim(num_diags);\n    const int32_t max_diag_len =\n        std::min(num_rows + std::min(upper_diag_index, 0),\n                 num_cols - std::max(lower_diag_index, 0));\n    expected_diag_shape.AddDim(max_diag_len);\n    OP_REQUIRES(\n        context, expected_diag_shape == diag_shape,\n        errors::InvalidArgument(\n            \"Either first dimensions of diagonal don't match input.shape[:-2], \"\n            \"or diagonal.shape[:-1] is not equal to the longests diagonal in \"\n            \"range [lower_diag_index:upper_diag_index].\\nInput shape: \",\n            input_shape.DebugString(),\n            \"\\nDiagonal shape: \", diag_shape.DebugString(),\n            \"\\nExpected diagonal shape: \", expected_diag_shape.DebugString()));\n\n    if (input.NumElements() == 0) {\n      // This is a no-op.\n      context->set_output(0, input);\n      return;\n    }\n\n    auto input_reshaped = input.flat_inner_dims<T, 3>();\n    auto diag_reshaped = diag.flat<T>();\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(context, context->forward_input_or_allocate_output(\n                                {0}, 0, input_shape, &output));\n    auto output_reshaped = output->flat_inner_dims<T, 3>();\n    functor::MatrixSetDiag<Device, T>::Compute(\n        context, context->eigen_device<Device>(), input_reshaped, diag_reshaped,\n        output_reshaped, lower_diag_index, upper_diag_index, max_diag_len,\n        left_align_superdiagonal_, left_align_subdiagonal_);\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -17,6 +17,9 @@\n                   errors::InvalidArgument(\n                       \"diag_index must be a scalar or vector, received shape: \",\n                       diag_index.shape().DebugString()));\n+      OP_REQUIRES(\n+          context, diag_index.NumElements() > 0,\n+          errors::InvalidArgument(\"diag_index must have at least one element\"));\n       lower_diag_index = diag_index.flat<int32>()(0);\n       upper_diag_index = lower_diag_index;\n       if (TensorShapeUtils::IsVector(diag_index.shape())) {",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "      OP_REQUIRES(",
                "          context, diag_index.NumElements() > 0,",
                "          errors::InvalidArgument(\"diag_index must have at least one element\"));"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-37667",
        "func_name": "tensorflow/Compute",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions an attacker can cause undefined behavior via binding a reference to null pointer in `tf.raw_ops.UnicodeEncode`. The [implementation](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/core/kernels/unicode_ops.cc#L533-L539) reads the first dimension of the `input_splits` tensor before validating that this tensor is not empty. We have patched the issue in GitHub commit 2e0ee46f1a47675152d3d865797a18358881d7a6. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/2e0ee46f1a47675152d3d865797a18358881d7a6",
        "commit_title": "Ensure non-empty input_splits in tf.raw_ops.UnicodeEncode",
        "commit_text": " PiperOrigin-RevId: 387170080",
        "func_before": "void Compute(OpKernelContext* context) override {\n    // Get inputs\n    const Tensor& input_tensor = context->input(0);\n    const auto input_tensor_flat = input_tensor.flat<int32>();\n    const Tensor& input_splits = context->input(1);\n    const auto input_splits_flat = input_splits.flat<SPLITS_TYPE>();\n\n    // Operation will treat first argument in input_splits as if it were zero\n    // regardless of its actual value since splits should begin with zero and\n    // end with the length of the input values vector.\n    OP_REQUIRES(\n        context, input_splits_flat(0) == 0,\n        errors::InvalidArgument(\"First value in input_splits must be zero.\"));\n    OP_REQUIRES(context,\n                input_splits_flat(input_splits_flat.size() - 1) ==\n                    input_tensor_flat.size(),\n                errors::InvalidArgument(\"Last value in input_splits must be \"\n                                        \"equal to length of input_tensor.\"));\n    // Since we limit to a 2-D input (flat_values of rank 1 and a single splits\n    // tensor), our output dimension will be 1 with it's size equal to the\n    // number of splits (outer dimension or ragged tensor).\n    TensorShape output_shape({input_splits.dim_size(0) - 1});\n    Tensor* output_tensor;\n    OP_REQUIRES_OK(context, context->allocate_output(\"output\", output_shape,\n                                                     &output_tensor));\n    auto output_tensor_flat = output_tensor->flat<tstring>();\n\n    // Use a single index over the flattened input values tensor.\n    int idx = 0;\n    // Loop through our split dimension to create a new string at each split.\n    for (int i = 1; i < input_splits_flat.size(); ++i) {\n      icu::UnicodeString unicode_string;\n      icu::UnicodeStringAppendable appendable_unicode_string(unicode_string);\n      OP_REQUIRES(\n          context, input_splits_flat(i - 1) <= input_splits_flat(i),\n          errors::InvalidArgument(\n              \"Values in input_splits must be equal or in ascending order.\"));\n      OP_REQUIRES(\n          context, input_splits_flat(i) <= input_tensor_flat.size(),\n          errors::InvalidArgument(\"Values in input_splits must be less than or \"\n                                  \"equal to input_tensor length.\"));\n      for (; idx < input_splits_flat(i); ++idx) {\n        int32_t code_point = input_tensor_flat(idx);\n        // Check for invalid code point\n        if (!U_IS_UNICODE_CHAR(code_point)) {\n          if (error_options_.error_on_malformatting) {\n            context->CtxFailure(errors::InvalidArgument(\n                \"Code point is out of range for Unicode, or a noncharacter.\"));\n            return;\n          } else if (!error_options_.elide_replacement) {\n            code_point = error_options_.subst;\n          }\n        }\n        appendable_unicode_string.appendCodePoint(code_point);\n      }\n      // Encode our string and save in the output.\n      tstring result;\n      Encode(encoding_, unicode_string, &result);\n      output_tensor_flat(i - 1) = std::move(result);\n    }\n  }",
        "func": "void Compute(OpKernelContext* context) override {\n    // Get inputs\n    const Tensor& input_tensor = context->input(0);\n    const auto input_tensor_flat = input_tensor.flat<int32>();\n    const Tensor& input_splits = context->input(1);\n    const auto input_splits_flat = input_splits.flat<SPLITS_TYPE>();\n\n    OP_REQUIRES(\n        context, input_splits.NumElements() > 0,\n        errors::InvalidArgument(\"Input_splits should contain elements, but \"\n                                \"given input_values has 0 elements\"));\n    // Operation will treat first argument in input_splits as if it were zero\n    // regardless of its actual value since splits should begin with zero and\n    // end with the length of the input values vector.\n    OP_REQUIRES(\n        context, input_splits_flat(0) == 0,\n        errors::InvalidArgument(\"First value in input_splits must be zero.\"));\n    OP_REQUIRES(context,\n                input_splits_flat(input_splits_flat.size() - 1) ==\n                    input_tensor_flat.size(),\n                errors::InvalidArgument(\"Last value in input_splits must be \"\n                                        \"equal to length of input_tensor.\"));\n    // Since we limit to a 2-D input (flat_values of rank 1 and a single splits\n    // tensor), our output dimension will be 1 with it's size equal to the\n    // number of splits (outer dimension or ragged tensor).\n    TensorShape output_shape({input_splits.dim_size(0) - 1});\n    Tensor* output_tensor;\n    OP_REQUIRES_OK(context, context->allocate_output(\"output\", output_shape,\n                                                     &output_tensor));\n    auto output_tensor_flat = output_tensor->flat<tstring>();\n\n    // Use a single index over the flattened input values tensor.\n    int idx = 0;\n    // Loop through our split dimension to create a new string at each split.\n    for (int i = 1; i < input_splits_flat.size(); ++i) {\n      icu::UnicodeString unicode_string;\n      icu::UnicodeStringAppendable appendable_unicode_string(unicode_string);\n      OP_REQUIRES(\n          context, input_splits_flat(i - 1) <= input_splits_flat(i),\n          errors::InvalidArgument(\n              \"Values in input_splits must be equal or in ascending order.\"));\n      OP_REQUIRES(\n          context, input_splits_flat(i) <= input_tensor_flat.size(),\n          errors::InvalidArgument(\"Values in input_splits must be less than or \"\n                                  \"equal to input_tensor length.\"));\n      for (; idx < input_splits_flat(i); ++idx) {\n        int32_t code_point = input_tensor_flat(idx);\n        // Check for invalid code point\n        if (!U_IS_UNICODE_CHAR(code_point)) {\n          if (error_options_.error_on_malformatting) {\n            context->CtxFailure(errors::InvalidArgument(\n                \"Code point is out of range for Unicode, or a noncharacter.\"));\n            return;\n          } else if (!error_options_.elide_replacement) {\n            code_point = error_options_.subst;\n          }\n        }\n        appendable_unicode_string.appendCodePoint(code_point);\n      }\n      // Encode our string and save in the output.\n      tstring result;\n      Encode(encoding_, unicode_string, &result);\n      output_tensor_flat(i - 1) = std::move(result);\n    }\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,6 +5,10 @@\n     const Tensor& input_splits = context->input(1);\n     const auto input_splits_flat = input_splits.flat<SPLITS_TYPE>();\n \n+    OP_REQUIRES(\n+        context, input_splits.NumElements() > 0,\n+        errors::InvalidArgument(\"Input_splits should contain elements, but \"\n+                                \"given input_values has 0 elements\"));\n     // Operation will treat first argument in input_splits as if it were zero\n     // regardless of its actual value since splits should begin with zero and\n     // end with the length of the input values vector.",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    OP_REQUIRES(",
                "        context, input_splits.NumElements() > 0,",
                "        errors::InvalidArgument(\"Input_splits should contain elements, but \"",
                "                                \"given input_values has 0 elements\"));"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-37671",
        "func_name": "tensorflow/check_index_ordering",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions an attacker can cause undefined behavior via binding a reference to null pointer in `tf.raw_ops.Map*` and `tf.raw_ops.OrderedMap*` operations. The [implementation](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/core/kernels/map_stage_op.cc#L222-L248) has a check in place to ensure that `indices` is in ascending order, but does not check that `indices` is not empty. We have patched the issue in GitHub commit 532f5c5a547126c634fefd43bbad1dc6417678ac. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/532f5c5a547126c634fefd43bbad1dc6417678ac",
        "commit_title": "Prevent nullptr deref in validation of indexes in map ops.",
        "commit_text": " PiperOrigin-RevId: 387738023",
        "func_before": "Status check_index_ordering(const Tensor& indices) {\n    auto findices = indices.flat<int>();\n\n    for (std::size_t i = 0; i < findices.dimension(0) - 1; ++i) {\n      if (findices(i) < findices(i + 1)) {\n        continue;\n      }\n\n      return Status(\n          errors::InvalidArgument(\"Indices are not strictly ordered\"));\n    }\n\n    return Status::OK();\n  }",
        "func": "Status check_index_ordering(const Tensor& indices) {\n    if (indices.NumElements() == 0) {\n      return errors::InvalidArgument(\"Indices are empty\");\n    }\n\n    auto findices = indices.flat<int>();\n\n    for (std::size_t i = 0; i < findices.dimension(0) - 1; ++i) {\n      if (findices(i) < findices(i + 1)) {\n        continue;\n      }\n\n      return errors::InvalidArgument(\"Indices are not strictly ordered\");\n    }\n\n    return Status::OK();\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,4 +1,8 @@\n Status check_index_ordering(const Tensor& indices) {\n+    if (indices.NumElements() == 0) {\n+      return errors::InvalidArgument(\"Indices are empty\");\n+    }\n+\n     auto findices = indices.flat<int>();\n \n     for (std::size_t i = 0; i < findices.dimension(0) - 1; ++i) {\n@@ -6,8 +10,7 @@\n         continue;\n       }\n \n-      return Status(\n-          errors::InvalidArgument(\"Indices are not strictly ordered\"));\n+      return errors::InvalidArgument(\"Indices are not strictly ordered\");\n     }\n \n     return Status::OK();",
        "diff_line_info": {
            "deleted_lines": [
                "      return Status(",
                "          errors::InvalidArgument(\"Indices are not strictly ordered\"));"
            ],
            "added_lines": [
                "    if (indices.NumElements() == 0) {",
                "      return errors::InvalidArgument(\"Indices are empty\");",
                "    }",
                "",
                "      return errors::InvalidArgument(\"Indices are not strictly ordered\");"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-1809",
        "func_name": "radareorg/radare2/r_anal_list_vtables",
        "description": "Access of Uninitialized Pointer in GitHub repository radareorg/radare2 prior to 5.7.0.",
        "git_url": "https://github.com/radareorg/radare2/commit/919e3ac1a13f753c73e7a8e8d8bb4a143218732d",
        "commit_title": "Fix crash in vtable analysis on UB ##crash",
        "commit_text": " * Reported by @greatergoodest via huntrdev * BountyID 0730a95e-c485-4ff2-9a5d-bb3abfda0b17 * Reproducer: minified_crash",
        "func_before": "R_API void r_anal_list_vtables(RAnal *anal, int rad) {\n\tRVTableContext context;\n\tr_anal_vtable_begin (anal, &context);\n\n\tconst char *noMethodName = \"No Name found\";\n\tRVTableMethodInfo *curMethod;\n\tRListIter *vtableIter;\n\tRVTableInfo *table;\n\n\tRList *vtables = r_anal_vtable_search (&context);\n\n\tif (rad == 'j') {\n\t\tPJ *pj = pj_new ();\n\t\tif (!pj) {\n\t\t\treturn;\n\t\t}\n\t\tpj_a (pj);\n\t\tr_list_foreach (vtables, vtableIter, table) {\n\t\t\tpj_o (pj);\n\t\t\tpj_kN (pj, \"offset\", table->saddr);\n\t\t\tpj_ka (pj, \"methods\");\n\t\t\tr_vector_foreach (&table->methods, curMethod) {\n\t\t\t\tRAnalFunction *fcn = r_anal_get_fcn_in (anal, curMethod->addr, 0);\n\t\t\t\tconst char *const name = fcn ? fcn->name : NULL;\n\t\t\t\tpj_o (pj);\n\t\t\t\tpj_kN (pj, \"offset\", curMethod->addr);\n\t\t\t\tpj_ks (pj, \"name\", r_str_get_fail (name, noMethodName));\n\t\t\t\tpj_end (pj);\n\t\t\t}\n\t\t\tpj_end (pj);\n\t\t\tpj_end (pj);\n\t\t}\n\t\tpj_end (pj);\n\t\tr_cons_println (pj_string (pj));\n\t\tpj_free (pj);\n\t} else if (rad == '*') {\n\t\tr_list_foreach (vtables, vtableIter, table) {\n\t\t\tr_cons_printf (\"f vtable.0x%08\"PFMT64x\" %\"PFMT64d\" @ 0x%08\"PFMT64x\"\\n\",\n\t\t\t\t\t\t   table->saddr,\n\t\t\t\t\t\t   r_anal_vtable_info_get_size (&context, table),\n\t\t\t\t\t\t   table->saddr);\n\t\t\tr_vector_foreach (&table->methods, curMethod) {\n\t\t\t\tr_cons_printf (\"Cd %d @ 0x%08\"PFMT64x\"\\n\", context.word_size, table->saddr + curMethod->vtable_offset);\n\t\t\t\tRAnalFunction *fcn = r_anal_get_fcn_in (anal, curMethod->addr, 0);\n\t\t\t\tconst char *const name = fcn ? fcn->name : NULL;\n\t\t\t\tif (name) {\n\t\t\t\t\tr_cons_printf (\"f %s=0x%08\"PFMT64x\"\\n\", name, curMethod->addr);\n\t\t\t\t} else {\n\t\t\t\t\tr_cons_printf (\"f method.virtual.0x%08\"PFMT64x\"=0x%08\"PFMT64x\"\\n\", curMethod->addr, curMethod->addr);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t} else {\n\t\tr_list_foreach (vtables, vtableIter, table) {\n\t\t\tut64 vtableStartAddress = table->saddr;\n\t\t\tr_cons_printf (\"\\nVtable Found at 0x%08\"PFMT64x\"\\n\", vtableStartAddress);\n\t\t\tr_vector_foreach (&table->methods, curMethod) {\n\t\t\t\tRAnalFunction *fcn = r_anal_get_fcn_in (anal, curMethod->addr, 0);\n\t\t\t\tconst char *const name = fcn ? fcn->name : NULL;\n\t\t\t\tr_cons_printf (\"0x%08\"PFMT64x\" : %s\\n\", vtableStartAddress, r_str_get_fail (name, noMethodName));\n\t\t\t\tvtableStartAddress += context.word_size;\n\t\t\t}\n\t\t\tr_cons_newline ();\n\t\t}\n\t}\n\tr_list_free (vtables);\n}",
        "func": "R_API void r_anal_list_vtables(RAnal *anal, int rad) {\n\tRVTableContext context = {0};\n\tr_anal_vtable_begin (anal, &context);\n\n\tconst char *noMethodName = \"No Name found\";\n\tRVTableMethodInfo *curMethod;\n\tRListIter *vtableIter;\n\tRVTableInfo *table;\n\n\tRList *vtables = r_anal_vtable_search (&context);\n\n\tif (rad == 'j') {\n\t\tPJ *pj = pj_new ();\n\t\tif (!pj) {\n\t\t\treturn;\n\t\t}\n\t\tpj_a (pj);\n\t\tr_list_foreach (vtables, vtableIter, table) {\n\t\t\tpj_o (pj);\n\t\t\tpj_kN (pj, \"offset\", table->saddr);\n\t\t\tpj_ka (pj, \"methods\");\n\t\t\tr_vector_foreach (&table->methods, curMethod) {\n\t\t\t\tRAnalFunction *fcn = r_anal_get_fcn_in (anal, curMethod->addr, 0);\n\t\t\t\tconst char *const name = fcn ? fcn->name : NULL;\n\t\t\t\tpj_o (pj);\n\t\t\t\tpj_kN (pj, \"offset\", curMethod->addr);\n\t\t\t\tpj_ks (pj, \"name\", r_str_get_fail (name, noMethodName));\n\t\t\t\tpj_end (pj);\n\t\t\t}\n\t\t\tpj_end (pj);\n\t\t\tpj_end (pj);\n\t\t}\n\t\tpj_end (pj);\n\t\tr_cons_println (pj_string (pj));\n\t\tpj_free (pj);\n\t} else if (rad == '*') {\n\t\tr_list_foreach (vtables, vtableIter, table) {\n\t\t\tr_cons_printf (\"f vtable.0x%08\"PFMT64x\" %\"PFMT64d\" @ 0x%08\"PFMT64x\"\\n\",\n\t\t\t\t\t\t   table->saddr,\n\t\t\t\t\t\t   r_anal_vtable_info_get_size (&context, table),\n\t\t\t\t\t\t   table->saddr);\n\t\t\tr_vector_foreach (&table->methods, curMethod) {\n\t\t\t\tr_cons_printf (\"Cd %d @ 0x%08\"PFMT64x\"\\n\", context.word_size, table->saddr + curMethod->vtable_offset);\n\t\t\t\tRAnalFunction *fcn = r_anal_get_fcn_in (anal, curMethod->addr, 0);\n\t\t\t\tconst char *const name = fcn ? fcn->name : NULL;\n\t\t\t\tif (name) {\n\t\t\t\t\tr_cons_printf (\"f %s=0x%08\"PFMT64x\"\\n\", name, curMethod->addr);\n\t\t\t\t} else {\n\t\t\t\t\tr_cons_printf (\"f method.virtual.0x%08\"PFMT64x\"=0x%08\"PFMT64x\"\\n\", curMethod->addr, curMethod->addr);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t} else {\n\t\tr_list_foreach (vtables, vtableIter, table) {\n\t\t\tut64 vtableStartAddress = table->saddr;\n\t\t\tr_cons_printf (\"\\nVtable Found at 0x%08\"PFMT64x\"\\n\", vtableStartAddress);\n\t\t\tr_vector_foreach (&table->methods, curMethod) {\n\t\t\t\tRAnalFunction *fcn = r_anal_get_fcn_in (anal, curMethod->addr, 0);\n\t\t\t\tconst char *const name = fcn ? fcn->name : NULL;\n\t\t\t\tr_cons_printf (\"0x%08\"PFMT64x\" : %s\\n\", vtableStartAddress, r_str_get_fail (name, noMethodName));\n\t\t\t\tvtableStartAddress += context.word_size;\n\t\t\t}\n\t\t\tr_cons_newline ();\n\t\t}\n\t}\n\tr_list_free (vtables);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,5 @@\n R_API void r_anal_list_vtables(RAnal *anal, int rad) {\n-\tRVTableContext context;\n+\tRVTableContext context = {0};\n \tr_anal_vtable_begin (anal, &context);\n \n \tconst char *noMethodName = \"No Name found\";",
        "diff_line_info": {
            "deleted_lines": [
                "\tRVTableContext context;"
            ],
            "added_lines": [
                "\tRVTableContext context = {0};"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-1809",
        "func_name": "radareorg/radare2/vtable_is_addr_vtable_start_msvc",
        "description": "Access of Uninitialized Pointer in GitHub repository radareorg/radare2 prior to 5.7.0.",
        "git_url": "https://github.com/radareorg/radare2/commit/919e3ac1a13f753c73e7a8e8d8bb4a143218732d",
        "commit_title": "Fix crash in vtable analysis on UB ##crash",
        "commit_text": " * Reported by @greatergoodest via huntrdev * BountyID 0730a95e-c485-4ff2-9a5d-bb3abfda0b17 * Reproducer: minified_crash",
        "func_before": "static bool vtable_is_addr_vtable_start_msvc(RVTableContext *context, ut64 curAddress) {\n\tRAnalRef *xref;\n\tRListIter *xrefIter;\n\n\tif (!curAddress || curAddress == UT64_MAX) {\n\t\treturn false;\n\t}\n\tif (curAddress && !vtable_is_value_in_text_section (context, curAddress, NULL)) {\n\t\treturn false;\n\t}\n\t// total xref's to curAddress\n\tRList *xrefs = r_anal_xrefs_get (context->anal, curAddress);\n\tif (r_list_empty (xrefs)) {\n\t\tr_list_free (xrefs);\n\t\treturn false;\n\t}\n\tr_list_foreach (xrefs, xrefIter, xref) {\n\t\t// section in which currenct xref lies\n\t\tif (vtable_addr_in_text_section (context, xref->addr)) {\n\t\t\tut8 buf[VTABLE_BUFF_SIZE];\n\t\t\tcontext->anal->iob.read_at (context->anal->iob.io, xref->addr, buf, sizeof(buf));\n\n\t\t\tRAnalOp analop = {0};\n\t\t\tr_anal_op (context->anal, &analop, xref->addr, buf, sizeof(buf), R_ANAL_OP_MASK_BASIC);\n\n\t\t\tif (analop.type == R_ANAL_OP_TYPE_MOV\n\t\t\t\t|| analop.type == R_ANAL_OP_TYPE_LEA) {\n\t\t\t\tr_list_free (xrefs);\n\t\t\t\tr_anal_op_fini (&analop);\n\t\t\t\treturn true;\n\t\t\t}\n\n\t\t\tr_anal_op_fini (&analop);\n\t\t}\n\t}\n\tr_list_free (xrefs);\n\treturn false;\n}",
        "func": "static bool vtable_is_addr_vtable_start_msvc(RVTableContext *context, ut64 curAddress) {\n\tut8 buf[VTABLE_BUFF_SIZE];\n\tRAnalRef *xref;\n\tRListIter *xrefIter;\n\n\tif (!curAddress || curAddress == UT64_MAX) {\n\t\treturn false;\n\t}\n\tif (curAddress && !vtable_is_value_in_text_section (context, curAddress, NULL)) {\n\t\treturn false;\n\t}\n\t// total xref's to curAddress\n\tRList *xrefs = r_anal_xrefs_get (context->anal, curAddress);\n\tif (r_list_empty (xrefs)) {\n\t\tr_list_free (xrefs);\n\t\treturn false;\n\t}\n\tr_list_foreach (xrefs, xrefIter, xref) {\n\t\t// section in which currenct xref lies\n\t\tif (vtable_addr_in_text_section (context, xref->addr)) {\n\t\t\tcontext->anal->iob.read_at (context->anal->iob.io, xref->addr, buf, sizeof (buf));\n\t\t\tRAnalOp analop = {0};\n\t\t\tr_anal_op (context->anal, &analop, xref->addr, buf, sizeof (buf), R_ANAL_OP_MASK_BASIC);\n\t\t\tif (analop.type == R_ANAL_OP_TYPE_MOV || analop.type == R_ANAL_OP_TYPE_LEA) {\n\t\t\t\tr_list_free (xrefs);\n\t\t\t\tr_anal_op_fini (&analop);\n\t\t\t\treturn true;\n\t\t\t}\n\t\t\tr_anal_op_fini (&analop);\n\t\t}\n\t}\n\tr_list_free (xrefs);\n\treturn false;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,4 +1,5 @@\n static bool vtable_is_addr_vtable_start_msvc(RVTableContext *context, ut64 curAddress) {\n+\tut8 buf[VTABLE_BUFF_SIZE];\n \tRAnalRef *xref;\n \tRListIter *xrefIter;\n \n@@ -17,19 +18,14 @@\n \tr_list_foreach (xrefs, xrefIter, xref) {\n \t\t// section in which currenct xref lies\n \t\tif (vtable_addr_in_text_section (context, xref->addr)) {\n-\t\t\tut8 buf[VTABLE_BUFF_SIZE];\n-\t\t\tcontext->anal->iob.read_at (context->anal->iob.io, xref->addr, buf, sizeof(buf));\n-\n+\t\t\tcontext->anal->iob.read_at (context->anal->iob.io, xref->addr, buf, sizeof (buf));\n \t\t\tRAnalOp analop = {0};\n-\t\t\tr_anal_op (context->anal, &analop, xref->addr, buf, sizeof(buf), R_ANAL_OP_MASK_BASIC);\n-\n-\t\t\tif (analop.type == R_ANAL_OP_TYPE_MOV\n-\t\t\t\t|| analop.type == R_ANAL_OP_TYPE_LEA) {\n+\t\t\tr_anal_op (context->anal, &analop, xref->addr, buf, sizeof (buf), R_ANAL_OP_MASK_BASIC);\n+\t\t\tif (analop.type == R_ANAL_OP_TYPE_MOV || analop.type == R_ANAL_OP_TYPE_LEA) {\n \t\t\t\tr_list_free (xrefs);\n \t\t\t\tr_anal_op_fini (&analop);\n \t\t\t\treturn true;\n \t\t\t}\n-\n \t\t\tr_anal_op_fini (&analop);\n \t\t}\n \t}",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\tut8 buf[VTABLE_BUFF_SIZE];",
                "\t\t\tcontext->anal->iob.read_at (context->anal->iob.io, xref->addr, buf, sizeof(buf));",
                "",
                "\t\t\tr_anal_op (context->anal, &analop, xref->addr, buf, sizeof(buf), R_ANAL_OP_MASK_BASIC);",
                "",
                "\t\t\tif (analop.type == R_ANAL_OP_TYPE_MOV",
                "\t\t\t\t|| analop.type == R_ANAL_OP_TYPE_LEA) {",
                ""
            ],
            "added_lines": [
                "\tut8 buf[VTABLE_BUFF_SIZE];",
                "\t\t\tcontext->anal->iob.read_at (context->anal->iob.io, xref->addr, buf, sizeof (buf));",
                "\t\t\tr_anal_op (context->anal, &analop, xref->addr, buf, sizeof (buf), R_ANAL_OP_MASK_BASIC);",
                "\t\t\tif (analop.type == R_ANAL_OP_TYPE_MOV || analop.type == R_ANAL_OP_TYPE_LEA) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-1809",
        "func_name": "radareorg/radare2/vtable_is_value_in_text_section",
        "description": "Access of Uninitialized Pointer in GitHub repository radareorg/radare2 prior to 5.7.0.",
        "git_url": "https://github.com/radareorg/radare2/commit/919e3ac1a13f753c73e7a8e8d8bb4a143218732d",
        "commit_title": "Fix crash in vtable analysis on UB ##crash",
        "commit_text": " * Reported by @greatergoodest via huntrdev * BountyID 0730a95e-c485-4ff2-9a5d-bb3abfda0b17 * Reproducer: minified_crash",
        "func_before": "static bool vtable_is_value_in_text_section(RVTableContext *context, ut64 curAddress, ut64 *value) {\n\t//value at the current address\n\tut64 curAddressValue;\n\tif (!context->read_addr (context->anal, curAddress, &curAddressValue)) {\n\t\treturn false;\n\t}\n\t//if the value is in text section\n\tbool ret = vtable_addr_in_text_section (context, curAddressValue);\n\tif (value) {\n\t\t*value = curAddressValue;\n\t}\n\treturn ret;\n}",
        "func": "static bool vtable_is_value_in_text_section(RVTableContext *context, ut64 curAddress, ut64 *value) {\n\t//value at the current address\n\tut64 curAddressValue = UT64_MAX;\n\tif (!context->read_addr (context->anal, curAddress, &curAddressValue)) {\n\t\treturn false;\n\t}\n\t//if the value is in text section\n\tbool ret = vtable_addr_in_text_section (context, curAddressValue);\n\tif (value) {\n\t\t*value = curAddressValue;\n\t}\n\treturn ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,6 @@\n static bool vtable_is_value_in_text_section(RVTableContext *context, ut64 curAddress, ut64 *value) {\n \t//value at the current address\n-\tut64 curAddressValue;\n+\tut64 curAddressValue = UT64_MAX;\n \tif (!context->read_addr (context->anal, curAddress, &curAddressValue)) {\n \t\treturn false;\n \t}",
        "diff_line_info": {
            "deleted_lines": [
                "\tut64 curAddressValue;"
            ],
            "added_lines": [
                "\tut64 curAddressValue = UT64_MAX;"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-1809",
        "func_name": "radareorg/radare2/r_anal_vtable_begin",
        "description": "Access of Uninitialized Pointer in GitHub repository radareorg/radare2 prior to 5.7.0.",
        "git_url": "https://github.com/radareorg/radare2/commit/919e3ac1a13f753c73e7a8e8d8bb4a143218732d",
        "commit_title": "Fix crash in vtable analysis on UB ##crash",
        "commit_text": " * Reported by @greatergoodest via huntrdev * BountyID 0730a95e-c485-4ff2-9a5d-bb3abfda0b17 * Reproducer: minified_crash",
        "func_before": "R_API bool r_anal_vtable_begin(RAnal *anal, RVTableContext *context) {\n\tcontext->anal = anal;\n\tcontext->abi = anal->cxxabi;\n\tcontext->word_size = (ut8) (anal->config->bits / 8);\n\tconst bool is_arm = anal->cur->arch && r_str_startswith (anal->cur->arch, \"arm\");\n\tif (is_arm && context->word_size < 4) {\n\t\tcontext->word_size = 4;\n\t}\n\tconst bool be = anal->config->big_endian;\n\tswitch (context->word_size) {\n\tcase 1:\n\t\tcontext->read_addr = be? vtable_read_addr_be8 : vtable_read_addr_le8;\n\t\tbreak;\n\tcase 2:\n\t\tcontext->read_addr = be? vtable_read_addr_be16 : vtable_read_addr_le16;\n\t\tbreak;\n\tcase 4:\n\t\tcontext->read_addr = be? vtable_read_addr_be32 : vtable_read_addr_le32;\n\t\tbreak;\n\tcase 8:\n\t\tcontext->read_addr = be? vtable_read_addr_be64 : vtable_read_addr_le64;\n\t\tbreak;\n\tdefault:\n\t\treturn false;\n\t}\n\treturn true;\n}",
        "func": "R_API bool r_anal_vtable_begin(RAnal *anal, RVTableContext *context) {\n\tcontext->anal = anal;\n\tcontext->abi = anal->cxxabi;\n\tcontext->word_size = (ut8) (anal->config->bits / 8);\n\tconst bool is_arm = anal->cur->arch && r_str_startswith (anal->cur->arch, \"arm\");\n\tif (is_arm && context->word_size < 4) {\n\t\tcontext->word_size = 4;\n\t}\n\tconst bool be = anal->config->big_endian;\n\tswitch (context->word_size) {\n\tcase 1:\n\t\tcontext->read_addr = be? vtable_read_addr_be8 : vtable_read_addr_le8;\n\t\tbreak;\n\tcase 2:\n\t\tcontext->read_addr = be? vtable_read_addr_be16 : vtable_read_addr_le16;\n\t\tbreak;\n\tcase 4:\n\t\tcontext->read_addr = be? vtable_read_addr_be32 : vtable_read_addr_le32;\n\t\tbreak;\n\tcase 8:\n\t\tcontext->read_addr = be? vtable_read_addr_be64 : vtable_read_addr_le64;\n\t\tbreak;\n\tdefault:\n\t\t// cant be null. assume 32bit \"->read_addr = NULL;\n\t\tcontext->read_addr = be? vtable_read_addr_be32 : vtable_read_addr_le32;\n\t\treturn false;\n\t}\n\treturn true;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -21,6 +21,8 @@\n \t\tcontext->read_addr = be? vtable_read_addr_be64 : vtable_read_addr_le64;\n \t\tbreak;\n \tdefault:\n+\t\t// cant be null. assume 32bit \"->read_addr = NULL;\n+\t\tcontext->read_addr = be? vtable_read_addr_be32 : vtable_read_addr_le32;\n \t\treturn false;\n \t}\n \treturn true;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t\t// cant be null. assume 32bit \"->read_addr = NULL;",
                "\t\tcontext->read_addr = be? vtable_read_addr_be32 : vtable_read_addr_le32;"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-9274",
        "func_name": "jedisct1/pure-ftpd/init_aliases",
        "description": "An issue was discovered in Pure-FTPd 1.0.49. An uninitialized pointer vulnerability has been detected in the diraliases linked list. When the *lookup_alias(const char alias) or print_aliases(void) function is called, they fail to correctly detect the end of the linked list and try to access a non-existent list member. This is related to init_aliases in diraliases.c.",
        "git_url": "https://github.com/jedisct1/pure-ftpd/commit/8d0d42542e2cb7a56d645fbe4d0ef436e38bcefa",
        "commit_title": "diraliases: always set the tail of the list to NULL",
        "commit_text": " Spotted and reported by Antonio Norales from GitHub Security Labs. Thanks!",
        "func_before": "int init_aliases(void)\n{\n    FILE *fp;\n    char alias[MAXALIASLEN + 1U];\n    char dir[PATH_MAX + 1U];\n\n    if ((fp = fopen(ALIASES_FILE, \"r\")) == NULL) {\n        return 0;\n    }\n    while (fgets(alias, sizeof alias, fp) != NULL) {\n        if (*alias == '#' || *alias == '\\n' || *alias == 0) {\n            continue;\n        }\n        {\n            char * const z = alias + strlen(alias) - 1U;\n\n            if (*z != '\\n') {\n                goto bad;\n            }\n            *z = 0;\n        }\n        do {\n            if (fgets(dir, sizeof dir, fp) == NULL || *dir == 0) {\n                goto bad;\n            }\n            {\n                char * const z = dir + strlen(dir) - 1U;\n\n                if (*z == '\\n') {\n                    *z = 0;\n                }\n            }\n        } while (*dir == '#' || *dir == 0);\n        if (head == NULL) {\n            if ((head = tail = malloc(sizeof *head)) == NULL ||\n                (tail->alias = strdup(alias)) == NULL ||\n                (tail->dir = strdup(dir)) == NULL) {\n                die_mem();\n            }\n            tail->next = NULL;\n        } else {\n            DirAlias *curr;\n\n            if ((curr = malloc(sizeof *curr)) == NULL ||\n                (curr->alias = strdup(alias)) == NULL ||\n                (curr->dir = strdup(dir)) == NULL) {\n                die_mem();\n            }\n            tail->next = curr;\n            tail = curr;\n        }\n    }\n    fclose(fp);\n    aliases_up++;\n\n    return 0;\n\n    bad:\n    fclose(fp);\n    logfile(LOG_ERR, MSG_ALIASES_BROKEN_FILE \" [\" ALIASES_FILE \"]\");\n\n    return -1;\n}",
        "func": "int init_aliases(void)\n{\n    FILE *fp;\n    char alias[MAXALIASLEN + 1U];\n    char dir[PATH_MAX + 1U];\n\n    if ((fp = fopen(ALIASES_FILE, \"r\")) == NULL) {\n        return 0;\n    }\n    while (fgets(alias, sizeof alias, fp) != NULL) {\n        if (*alias == '#' || *alias == '\\n' || *alias == 0) {\n            continue;\n        }\n        {\n            char * const z = alias + strlen(alias) - 1U;\n\n            if (*z != '\\n') {\n                goto bad;\n            }\n            *z = 0;\n        }\n        do {\n            if (fgets(dir, sizeof dir, fp) == NULL || *dir == 0) {\n                goto bad;\n            }\n            {\n                char * const z = dir + strlen(dir) - 1U;\n\n                if (*z == '\\n') {\n                    *z = 0;\n                }\n            }\n        } while (*dir == '#' || *dir == 0);\n        if (head == NULL) {\n            if ((head = tail = malloc(sizeof *head)) == NULL ||\n                (tail->alias = strdup(alias)) == NULL ||\n                (tail->dir = strdup(dir)) == NULL) {\n                die_mem();\n            }\n        } else {\n            DirAlias *curr;\n\n            if ((curr = malloc(sizeof *curr)) == NULL ||\n                (curr->alias = strdup(alias)) == NULL ||\n                (curr->dir = strdup(dir)) == NULL) {\n                die_mem();\n            }\n            tail->next = curr;\n            tail = curr;\n        }\n        tail->next = NULL;\n    }\n    fclose(fp);\n    aliases_up++;\n\n    return 0;\n\n    bad:\n    fclose(fp);\n    logfile(LOG_ERR, MSG_ALIASES_BROKEN_FILE \" [\" ALIASES_FILE \"]\");\n\n    return -1;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -37,7 +37,6 @@\n                 (tail->dir = strdup(dir)) == NULL) {\n                 die_mem();\n             }\n-            tail->next = NULL;\n         } else {\n             DirAlias *curr;\n \n@@ -49,6 +48,7 @@\n             tail->next = curr;\n             tail = curr;\n         }\n+        tail->next = NULL;\n     }\n     fclose(fp);\n     aliases_up++;",
        "diff_line_info": {
            "deleted_lines": [
                "            tail->next = NULL;"
            ],
            "added_lines": [
                "        tail->next = NULL;"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-14356",
        "func_name": "neomutt/fetch_uidl",
        "description": "An issue was discovered in Mutt before 1.10.1 and NeoMutt before 2018-07-16. pop.c mishandles a zero-length UID.",
        "git_url": "https://github.com/neomutt/neomutt/commit/93b8ac558752d09e1c56d4f1bc82631316fa9c82",
        "commit_title": "Ensure UID in fetch_uidl",
        "commit_text": "",
        "func_before": "static int fetch_uidl(char *line, void *data)\n{\n  int i, index;\n  struct Context *ctx = (struct Context *) data;\n  struct PopData *pop_data = (struct PopData *) ctx->data;\n  char *endp = NULL;\n\n  errno = 0;\n  index = strtol(line, &endp, 10);\n  if (errno)\n    return -1;\n  while (*endp == ' ')\n    endp++;\n  memmove(line, endp, strlen(endp) + 1);\n\n  for (i = 0; i < ctx->msgcount; i++)\n    if (mutt_str_strcmp(line, ctx->hdrs[i]->data) == 0)\n      break;\n\n  if (i == ctx->msgcount)\n  {\n    mutt_debug(1, \"new header %d %s\\n\", index, line);\n\n    if (i >= ctx->hdrmax)\n      mx_alloc_memory(ctx);\n\n    ctx->msgcount++;\n    ctx->hdrs[i] = mutt_header_new();\n    ctx->hdrs[i]->data = mutt_str_strdup(line);\n  }\n  else if (ctx->hdrs[i]->index != index - 1)\n    pop_data->clear_cache = true;\n\n  ctx->hdrs[i]->refno = index;\n  ctx->hdrs[i]->index = index - 1;\n\n  return 0;\n}",
        "func": "static int fetch_uidl(char *line, void *data)\n{\n  int i, index;\n  struct Context *ctx = (struct Context *) data;\n  struct PopData *pop_data = (struct PopData *) ctx->data;\n  char *endp = NULL;\n\n  errno = 0;\n  index = strtol(line, &endp, 10);\n  if (errno)\n    return -1;\n  while (*endp == ' ')\n    endp++;\n  memmove(line, endp, strlen(endp) + 1);\n\n  /* uid must be at least be 1 byte */\n  if (strlen(line) == 0)\n    return -1;\n\n  for (i = 0; i < ctx->msgcount; i++)\n    if (mutt_str_strcmp(line, ctx->hdrs[i]->data) == 0)\n      break;\n\n  if (i == ctx->msgcount)\n  {\n    mutt_debug(1, \"new header %d %s\\n\", index, line);\n\n    if (i >= ctx->hdrmax)\n      mx_alloc_memory(ctx);\n\n    ctx->msgcount++;\n    ctx->hdrs[i] = mutt_header_new();\n    ctx->hdrs[i]->data = mutt_str_strdup(line);\n  }\n  else if (ctx->hdrs[i]->index != index - 1)\n    pop_data->clear_cache = true;\n\n  ctx->hdrs[i]->refno = index;\n  ctx->hdrs[i]->index = index - 1;\n\n  return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -12,6 +12,10 @@\n   while (*endp == ' ')\n     endp++;\n   memmove(line, endp, strlen(endp) + 1);\n+\n+  /* uid must be at least be 1 byte */\n+  if (strlen(line) == 0)\n+    return -1;\n \n   for (i = 0; i < ctx->msgcount; i++)\n     if (mutt_str_strcmp(line, ctx->hdrs[i]->data) == 0)",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "  /* uid must be at least be 1 byte */",
                "  if (strlen(line) == 0)",
                "    return -1;"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-42895",
        "func_name": "torvalds/linux/l2cap_parse_conf_req",
        "description": "There is an infoleak vulnerability in the Linux kernel's net/bluetooth/l2cap_core.c's l2cap_parse_conf_req function which can be used to leak kernel pointers remotely.\nWe recommend upgrading past commit https://github.com/torvalds/linux/commit/b1a2cd50c0357f243b7435a732b4e62ba3157a2e https://www.google.com/url \n\n",
        "git_url": "https://github.com/torvalds/linux/commit/b1a2cd50c0357f243b7435a732b4e62ba3157a2e",
        "commit_title": "Bluetooth: L2CAP: Fix attempting to access uninitialized memory",
        "commit_text": " On l2cap_parse_conf_req the variable efs is only initialized if remote_efs has been set.  CVE: CVE-2022-42895",
        "func_before": "static int l2cap_parse_conf_req(struct l2cap_chan *chan, void *data, size_t data_size)\n{\n\tstruct l2cap_conf_rsp *rsp = data;\n\tvoid *ptr = rsp->data;\n\tvoid *endptr = data + data_size;\n\tvoid *req = chan->conf_req;\n\tint len = chan->conf_len;\n\tint type, hint, olen;\n\tunsigned long val;\n\tstruct l2cap_conf_rfc rfc = { .mode = L2CAP_MODE_BASIC };\n\tstruct l2cap_conf_efs efs;\n\tu8 remote_efs = 0;\n\tu16 mtu = L2CAP_DEFAULT_MTU;\n\tu16 result = L2CAP_CONF_SUCCESS;\n\tu16 size;\n\n\tBT_DBG(\"chan %p\", chan);\n\n\twhile (len >= L2CAP_CONF_OPT_SIZE) {\n\t\tlen -= l2cap_get_conf_opt(&req, &type, &olen, &val);\n\t\tif (len < 0)\n\t\t\tbreak;\n\n\t\thint  = type & L2CAP_CONF_HINT;\n\t\ttype &= L2CAP_CONF_MASK;\n\n\t\tswitch (type) {\n\t\tcase L2CAP_CONF_MTU:\n\t\t\tif (olen != 2)\n\t\t\t\tbreak;\n\t\t\tmtu = val;\n\t\t\tbreak;\n\n\t\tcase L2CAP_CONF_FLUSH_TO:\n\t\t\tif (olen != 2)\n\t\t\t\tbreak;\n\t\t\tchan->flush_to = val;\n\t\t\tbreak;\n\n\t\tcase L2CAP_CONF_QOS:\n\t\t\tbreak;\n\n\t\tcase L2CAP_CONF_RFC:\n\t\t\tif (olen != sizeof(rfc))\n\t\t\t\tbreak;\n\t\t\tmemcpy(&rfc, (void *) val, olen);\n\t\t\tbreak;\n\n\t\tcase L2CAP_CONF_FCS:\n\t\t\tif (olen != 1)\n\t\t\t\tbreak;\n\t\t\tif (val == L2CAP_FCS_NONE)\n\t\t\t\tset_bit(CONF_RECV_NO_FCS, &chan->conf_state);\n\t\t\tbreak;\n\n\t\tcase L2CAP_CONF_EFS:\n\t\t\tif (olen != sizeof(efs))\n\t\t\t\tbreak;\n\t\t\tremote_efs = 1;\n\t\t\tmemcpy(&efs, (void *) val, olen);\n\t\t\tbreak;\n\n\t\tcase L2CAP_CONF_EWS:\n\t\t\tif (olen != 2)\n\t\t\t\tbreak;\n\t\t\tif (!(chan->conn->local_fixed_chan & L2CAP_FC_A2MP))\n\t\t\t\treturn -ECONNREFUSED;\n\t\t\tset_bit(FLAG_EXT_CTRL, &chan->flags);\n\t\t\tset_bit(CONF_EWS_RECV, &chan->conf_state);\n\t\t\tchan->tx_win_max = L2CAP_DEFAULT_EXT_WINDOW;\n\t\t\tchan->remote_tx_win = val;\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tif (hint)\n\t\t\t\tbreak;\n\t\t\tresult = L2CAP_CONF_UNKNOWN;\n\t\t\tl2cap_add_conf_opt(&ptr, (u8)type, sizeof(u8), type, endptr - ptr);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (chan->num_conf_rsp || chan->num_conf_req > 1)\n\t\tgoto done;\n\n\tswitch (chan->mode) {\n\tcase L2CAP_MODE_STREAMING:\n\tcase L2CAP_MODE_ERTM:\n\t\tif (!test_bit(CONF_STATE2_DEVICE, &chan->conf_state)) {\n\t\t\tchan->mode = l2cap_select_mode(rfc.mode,\n\t\t\t\t\t\t       chan->conn->feat_mask);\n\t\t\tbreak;\n\t\t}\n\n\t\tif (remote_efs) {\n\t\t\tif (__l2cap_efs_supported(chan->conn))\n\t\t\t\tset_bit(FLAG_EFS_ENABLE, &chan->flags);\n\t\t\telse\n\t\t\t\treturn -ECONNREFUSED;\n\t\t}\n\n\t\tif (chan->mode != rfc.mode)\n\t\t\treturn -ECONNREFUSED;\n\n\t\tbreak;\n\t}\n\ndone:\n\tif (chan->mode != rfc.mode) {\n\t\tresult = L2CAP_CONF_UNACCEPT;\n\t\trfc.mode = chan->mode;\n\n\t\tif (chan->num_conf_rsp == 1)\n\t\t\treturn -ECONNREFUSED;\n\n\t\tl2cap_add_conf_opt(&ptr, L2CAP_CONF_RFC, sizeof(rfc),\n\t\t\t\t   (unsigned long) &rfc, endptr - ptr);\n\t}\n\n\tif (result == L2CAP_CONF_SUCCESS) {\n\t\t/* Configure output options and let the other side know\n\t\t * which ones we don't like. */\n\n\t\tif (mtu < L2CAP_DEFAULT_MIN_MTU)\n\t\t\tresult = L2CAP_CONF_UNACCEPT;\n\t\telse {\n\t\t\tchan->omtu = mtu;\n\t\t\tset_bit(CONF_MTU_DONE, &chan->conf_state);\n\t\t}\n\t\tl2cap_add_conf_opt(&ptr, L2CAP_CONF_MTU, 2, chan->omtu, endptr - ptr);\n\n\t\tif (remote_efs) {\n\t\t\tif (chan->local_stype != L2CAP_SERV_NOTRAFIC &&\n\t\t\t    efs.stype != L2CAP_SERV_NOTRAFIC &&\n\t\t\t    efs.stype != chan->local_stype) {\n\n\t\t\t\tresult = L2CAP_CONF_UNACCEPT;\n\n\t\t\t\tif (chan->num_conf_req >= 1)\n\t\t\t\t\treturn -ECONNREFUSED;\n\n\t\t\t\tl2cap_add_conf_opt(&ptr, L2CAP_CONF_EFS,\n\t\t\t\t\t\t   sizeof(efs),\n\t\t\t\t\t\t   (unsigned long) &efs, endptr - ptr);\n\t\t\t} else {\n\t\t\t\t/* Send PENDING Conf Rsp */\n\t\t\t\tresult = L2CAP_CONF_PENDING;\n\t\t\t\tset_bit(CONF_LOC_CONF_PEND, &chan->conf_state);\n\t\t\t}\n\t\t}\n\n\t\tswitch (rfc.mode) {\n\t\tcase L2CAP_MODE_BASIC:\n\t\t\tchan->fcs = L2CAP_FCS_NONE;\n\t\t\tset_bit(CONF_MODE_DONE, &chan->conf_state);\n\t\t\tbreak;\n\n\t\tcase L2CAP_MODE_ERTM:\n\t\t\tif (!test_bit(CONF_EWS_RECV, &chan->conf_state))\n\t\t\t\tchan->remote_tx_win = rfc.txwin_size;\n\t\t\telse\n\t\t\t\trfc.txwin_size = L2CAP_DEFAULT_TX_WINDOW;\n\n\t\t\tchan->remote_max_tx = rfc.max_transmit;\n\n\t\t\tsize = min_t(u16, le16_to_cpu(rfc.max_pdu_size),\n\t\t\t\t     chan->conn->mtu - L2CAP_EXT_HDR_SIZE -\n\t\t\t\t     L2CAP_SDULEN_SIZE - L2CAP_FCS_SIZE);\n\t\t\trfc.max_pdu_size = cpu_to_le16(size);\n\t\t\tchan->remote_mps = size;\n\n\t\t\t__l2cap_set_ertm_timeouts(chan, &rfc);\n\n\t\t\tset_bit(CONF_MODE_DONE, &chan->conf_state);\n\n\t\t\tl2cap_add_conf_opt(&ptr, L2CAP_CONF_RFC,\n\t\t\t\t\t   sizeof(rfc), (unsigned long) &rfc, endptr - ptr);\n\n\t\t\tif (test_bit(FLAG_EFS_ENABLE, &chan->flags)) {\n\t\t\t\tchan->remote_id = efs.id;\n\t\t\t\tchan->remote_stype = efs.stype;\n\t\t\t\tchan->remote_msdu = le16_to_cpu(efs.msdu);\n\t\t\t\tchan->remote_flush_to =\n\t\t\t\t\tle32_to_cpu(efs.flush_to);\n\t\t\t\tchan->remote_acc_lat =\n\t\t\t\t\tle32_to_cpu(efs.acc_lat);\n\t\t\t\tchan->remote_sdu_itime =\n\t\t\t\t\tle32_to_cpu(efs.sdu_itime);\n\t\t\t\tl2cap_add_conf_opt(&ptr, L2CAP_CONF_EFS,\n\t\t\t\t\t\t   sizeof(efs),\n\t\t\t\t\t\t   (unsigned long) &efs, endptr - ptr);\n\t\t\t}\n\t\t\tbreak;\n\n\t\tcase L2CAP_MODE_STREAMING:\n\t\t\tsize = min_t(u16, le16_to_cpu(rfc.max_pdu_size),\n\t\t\t\t     chan->conn->mtu - L2CAP_EXT_HDR_SIZE -\n\t\t\t\t     L2CAP_SDULEN_SIZE - L2CAP_FCS_SIZE);\n\t\t\trfc.max_pdu_size = cpu_to_le16(size);\n\t\t\tchan->remote_mps = size;\n\n\t\t\tset_bit(CONF_MODE_DONE, &chan->conf_state);\n\n\t\t\tl2cap_add_conf_opt(&ptr, L2CAP_CONF_RFC, sizeof(rfc),\n\t\t\t\t\t   (unsigned long) &rfc, endptr - ptr);\n\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tresult = L2CAP_CONF_UNACCEPT;\n\n\t\t\tmemset(&rfc, 0, sizeof(rfc));\n\t\t\trfc.mode = chan->mode;\n\t\t}\n\n\t\tif (result == L2CAP_CONF_SUCCESS)\n\t\t\tset_bit(CONF_OUTPUT_DONE, &chan->conf_state);\n\t}\n\trsp->scid   = cpu_to_le16(chan->dcid);\n\trsp->result = cpu_to_le16(result);\n\trsp->flags  = cpu_to_le16(0);\n\n\treturn ptr - data;\n}",
        "func": "static int l2cap_parse_conf_req(struct l2cap_chan *chan, void *data, size_t data_size)\n{\n\tstruct l2cap_conf_rsp *rsp = data;\n\tvoid *ptr = rsp->data;\n\tvoid *endptr = data + data_size;\n\tvoid *req = chan->conf_req;\n\tint len = chan->conf_len;\n\tint type, hint, olen;\n\tunsigned long val;\n\tstruct l2cap_conf_rfc rfc = { .mode = L2CAP_MODE_BASIC };\n\tstruct l2cap_conf_efs efs;\n\tu8 remote_efs = 0;\n\tu16 mtu = L2CAP_DEFAULT_MTU;\n\tu16 result = L2CAP_CONF_SUCCESS;\n\tu16 size;\n\n\tBT_DBG(\"chan %p\", chan);\n\n\twhile (len >= L2CAP_CONF_OPT_SIZE) {\n\t\tlen -= l2cap_get_conf_opt(&req, &type, &olen, &val);\n\t\tif (len < 0)\n\t\t\tbreak;\n\n\t\thint  = type & L2CAP_CONF_HINT;\n\t\ttype &= L2CAP_CONF_MASK;\n\n\t\tswitch (type) {\n\t\tcase L2CAP_CONF_MTU:\n\t\t\tif (olen != 2)\n\t\t\t\tbreak;\n\t\t\tmtu = val;\n\t\t\tbreak;\n\n\t\tcase L2CAP_CONF_FLUSH_TO:\n\t\t\tif (olen != 2)\n\t\t\t\tbreak;\n\t\t\tchan->flush_to = val;\n\t\t\tbreak;\n\n\t\tcase L2CAP_CONF_QOS:\n\t\t\tbreak;\n\n\t\tcase L2CAP_CONF_RFC:\n\t\t\tif (olen != sizeof(rfc))\n\t\t\t\tbreak;\n\t\t\tmemcpy(&rfc, (void *) val, olen);\n\t\t\tbreak;\n\n\t\tcase L2CAP_CONF_FCS:\n\t\t\tif (olen != 1)\n\t\t\t\tbreak;\n\t\t\tif (val == L2CAP_FCS_NONE)\n\t\t\t\tset_bit(CONF_RECV_NO_FCS, &chan->conf_state);\n\t\t\tbreak;\n\n\t\tcase L2CAP_CONF_EFS:\n\t\t\tif (olen != sizeof(efs))\n\t\t\t\tbreak;\n\t\t\tremote_efs = 1;\n\t\t\tmemcpy(&efs, (void *) val, olen);\n\t\t\tbreak;\n\n\t\tcase L2CAP_CONF_EWS:\n\t\t\tif (olen != 2)\n\t\t\t\tbreak;\n\t\t\tif (!(chan->conn->local_fixed_chan & L2CAP_FC_A2MP))\n\t\t\t\treturn -ECONNREFUSED;\n\t\t\tset_bit(FLAG_EXT_CTRL, &chan->flags);\n\t\t\tset_bit(CONF_EWS_RECV, &chan->conf_state);\n\t\t\tchan->tx_win_max = L2CAP_DEFAULT_EXT_WINDOW;\n\t\t\tchan->remote_tx_win = val;\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tif (hint)\n\t\t\t\tbreak;\n\t\t\tresult = L2CAP_CONF_UNKNOWN;\n\t\t\tl2cap_add_conf_opt(&ptr, (u8)type, sizeof(u8), type, endptr - ptr);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (chan->num_conf_rsp || chan->num_conf_req > 1)\n\t\tgoto done;\n\n\tswitch (chan->mode) {\n\tcase L2CAP_MODE_STREAMING:\n\tcase L2CAP_MODE_ERTM:\n\t\tif (!test_bit(CONF_STATE2_DEVICE, &chan->conf_state)) {\n\t\t\tchan->mode = l2cap_select_mode(rfc.mode,\n\t\t\t\t\t\t       chan->conn->feat_mask);\n\t\t\tbreak;\n\t\t}\n\n\t\tif (remote_efs) {\n\t\t\tif (__l2cap_efs_supported(chan->conn))\n\t\t\t\tset_bit(FLAG_EFS_ENABLE, &chan->flags);\n\t\t\telse\n\t\t\t\treturn -ECONNREFUSED;\n\t\t}\n\n\t\tif (chan->mode != rfc.mode)\n\t\t\treturn -ECONNREFUSED;\n\n\t\tbreak;\n\t}\n\ndone:\n\tif (chan->mode != rfc.mode) {\n\t\tresult = L2CAP_CONF_UNACCEPT;\n\t\trfc.mode = chan->mode;\n\n\t\tif (chan->num_conf_rsp == 1)\n\t\t\treturn -ECONNREFUSED;\n\n\t\tl2cap_add_conf_opt(&ptr, L2CAP_CONF_RFC, sizeof(rfc),\n\t\t\t\t   (unsigned long) &rfc, endptr - ptr);\n\t}\n\n\tif (result == L2CAP_CONF_SUCCESS) {\n\t\t/* Configure output options and let the other side know\n\t\t * which ones we don't like. */\n\n\t\tif (mtu < L2CAP_DEFAULT_MIN_MTU)\n\t\t\tresult = L2CAP_CONF_UNACCEPT;\n\t\telse {\n\t\t\tchan->omtu = mtu;\n\t\t\tset_bit(CONF_MTU_DONE, &chan->conf_state);\n\t\t}\n\t\tl2cap_add_conf_opt(&ptr, L2CAP_CONF_MTU, 2, chan->omtu, endptr - ptr);\n\n\t\tif (remote_efs) {\n\t\t\tif (chan->local_stype != L2CAP_SERV_NOTRAFIC &&\n\t\t\t    efs.stype != L2CAP_SERV_NOTRAFIC &&\n\t\t\t    efs.stype != chan->local_stype) {\n\n\t\t\t\tresult = L2CAP_CONF_UNACCEPT;\n\n\t\t\t\tif (chan->num_conf_req >= 1)\n\t\t\t\t\treturn -ECONNREFUSED;\n\n\t\t\t\tl2cap_add_conf_opt(&ptr, L2CAP_CONF_EFS,\n\t\t\t\t\t\t   sizeof(efs),\n\t\t\t\t\t\t   (unsigned long) &efs, endptr - ptr);\n\t\t\t} else {\n\t\t\t\t/* Send PENDING Conf Rsp */\n\t\t\t\tresult = L2CAP_CONF_PENDING;\n\t\t\t\tset_bit(CONF_LOC_CONF_PEND, &chan->conf_state);\n\t\t\t}\n\t\t}\n\n\t\tswitch (rfc.mode) {\n\t\tcase L2CAP_MODE_BASIC:\n\t\t\tchan->fcs = L2CAP_FCS_NONE;\n\t\t\tset_bit(CONF_MODE_DONE, &chan->conf_state);\n\t\t\tbreak;\n\n\t\tcase L2CAP_MODE_ERTM:\n\t\t\tif (!test_bit(CONF_EWS_RECV, &chan->conf_state))\n\t\t\t\tchan->remote_tx_win = rfc.txwin_size;\n\t\t\telse\n\t\t\t\trfc.txwin_size = L2CAP_DEFAULT_TX_WINDOW;\n\n\t\t\tchan->remote_max_tx = rfc.max_transmit;\n\n\t\t\tsize = min_t(u16, le16_to_cpu(rfc.max_pdu_size),\n\t\t\t\t     chan->conn->mtu - L2CAP_EXT_HDR_SIZE -\n\t\t\t\t     L2CAP_SDULEN_SIZE - L2CAP_FCS_SIZE);\n\t\t\trfc.max_pdu_size = cpu_to_le16(size);\n\t\t\tchan->remote_mps = size;\n\n\t\t\t__l2cap_set_ertm_timeouts(chan, &rfc);\n\n\t\t\tset_bit(CONF_MODE_DONE, &chan->conf_state);\n\n\t\t\tl2cap_add_conf_opt(&ptr, L2CAP_CONF_RFC,\n\t\t\t\t\t   sizeof(rfc), (unsigned long) &rfc, endptr - ptr);\n\n\t\t\tif (remote_efs &&\n\t\t\t    test_bit(FLAG_EFS_ENABLE, &chan->flags)) {\n\t\t\t\tchan->remote_id = efs.id;\n\t\t\t\tchan->remote_stype = efs.stype;\n\t\t\t\tchan->remote_msdu = le16_to_cpu(efs.msdu);\n\t\t\t\tchan->remote_flush_to =\n\t\t\t\t\tle32_to_cpu(efs.flush_to);\n\t\t\t\tchan->remote_acc_lat =\n\t\t\t\t\tle32_to_cpu(efs.acc_lat);\n\t\t\t\tchan->remote_sdu_itime =\n\t\t\t\t\tle32_to_cpu(efs.sdu_itime);\n\t\t\t\tl2cap_add_conf_opt(&ptr, L2CAP_CONF_EFS,\n\t\t\t\t\t\t   sizeof(efs),\n\t\t\t\t\t\t   (unsigned long) &efs, endptr - ptr);\n\t\t\t}\n\t\t\tbreak;\n\n\t\tcase L2CAP_MODE_STREAMING:\n\t\t\tsize = min_t(u16, le16_to_cpu(rfc.max_pdu_size),\n\t\t\t\t     chan->conn->mtu - L2CAP_EXT_HDR_SIZE -\n\t\t\t\t     L2CAP_SDULEN_SIZE - L2CAP_FCS_SIZE);\n\t\t\trfc.max_pdu_size = cpu_to_le16(size);\n\t\t\tchan->remote_mps = size;\n\n\t\t\tset_bit(CONF_MODE_DONE, &chan->conf_state);\n\n\t\t\tl2cap_add_conf_opt(&ptr, L2CAP_CONF_RFC, sizeof(rfc),\n\t\t\t\t\t   (unsigned long) &rfc, endptr - ptr);\n\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tresult = L2CAP_CONF_UNACCEPT;\n\n\t\t\tmemset(&rfc, 0, sizeof(rfc));\n\t\t\trfc.mode = chan->mode;\n\t\t}\n\n\t\tif (result == L2CAP_CONF_SUCCESS)\n\t\t\tset_bit(CONF_OUTPUT_DONE, &chan->conf_state);\n\t}\n\trsp->scid   = cpu_to_le16(chan->dcid);\n\trsp->result = cpu_to_le16(result);\n\trsp->flags  = cpu_to_le16(0);\n\n\treturn ptr - data;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -176,7 +176,8 @@\n \t\t\tl2cap_add_conf_opt(&ptr, L2CAP_CONF_RFC,\n \t\t\t\t\t   sizeof(rfc), (unsigned long) &rfc, endptr - ptr);\n \n-\t\t\tif (test_bit(FLAG_EFS_ENABLE, &chan->flags)) {\n+\t\t\tif (remote_efs &&\n+\t\t\t    test_bit(FLAG_EFS_ENABLE, &chan->flags)) {\n \t\t\t\tchan->remote_id = efs.id;\n \t\t\t\tchan->remote_stype = efs.stype;\n \t\t\t\tchan->remote_msdu = le16_to_cpu(efs.msdu);",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\tif (test_bit(FLAG_EFS_ENABLE, &chan->flags)) {"
            ],
            "added_lines": [
                "\t\t\tif (remote_efs &&",
                "\t\t\t    test_bit(FLAG_EFS_ENABLE, &chan->flags)) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-41201",
        "func_name": "tensorflow/ParseEquation",
        "description": "TensorFlow is an open source platform for machine learning. In affeced versions during execution, `EinsumHelper::ParseEquation()` is supposed to set the flags in `input_has_ellipsis` vector and `*output_has_ellipsis` boolean to indicate whether there is ellipsis in the corresponding inputs and output. However, the code only changes these flags to `true` and never assigns `false`. This results in unitialized variable access if callers assume that `EinsumHelper::ParseEquation()` always sets these flags. The fix will be included in TensorFlow 2.7.0. We will also cherrypick this commit on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/f09caa532b6e1ac8d2aa61b7832c78c5b79300c6",
        "commit_title": "Fix EinsumHelper::ParseEquation to avoid uninitialized accesses.",
        "commit_text": " EinsumHelper::ParseEquation is supposed to return true or false in input_has_ellipsis and output_has_ellipsis to indicate whether there is ellipsis in the inputs and output. Previously, when there is no ellipsis in the inputs or output, the routine doesn't assign false to the variables. This change initializes the two variables with false to fix the problem. PiperOrigin-RevId: 391772004",
        "func_before": "static Status ParseEquation(const string& equation,\n                              OperandLabels* input_labels,\n                              Labels* output_labels,\n                              std::vector<DimensionType>* label_types,\n                              OperandLabelCounts* input_label_counts,\n                              LabelCounts* output_label_counts,\n                              gtl::InlinedVector<bool, 2>* input_has_ellipsis,\n                              bool* output_has_ellipsis) {\n    gtl::InlinedVector<string, 2> input_str;\n    string output_str;\n    TF_RETURN_IF_ERROR(ParseEinsumEquation(equation, &input_str, &output_str));\n\n    // Temporary map from single character labels to (consecutive) integer\n    // labels.\n    absl::flat_hash_map<char, int> label_mapping;\n    int num_inputs = input_str.size();\n    input_labels->resize(num_inputs);\n\n    // Map from single characters to integer labels.\n    for (int i = 0; i < num_inputs; ++i) {\n      MapToLabels(input_str[i], &input_labels->at(i), &label_mapping);\n    }\n    MapToLabels(output_str, output_labels, &label_mapping);\n\n    // Compute counts for input and output labels.\n    int num_labels = label_mapping.size();\n    input_label_counts->resize(num_inputs);\n    input_has_ellipsis->resize(num_inputs);\n    for (int i = 0; i < num_inputs; ++i) {\n      input_label_counts->at(i).resize(num_labels);\n      for (const int label : input_labels->at(i)) {\n        if (label != kEllipsisLabel)\n          input_label_counts->at(i)[label] += 1;\n        else\n          input_has_ellipsis->at(i) = true;\n      }\n    }\n    output_label_counts->resize(num_labels);\n    for (const int label : *output_labels) {\n      if (label != kEllipsisLabel)\n        output_label_counts->at(label) += 1;\n      else\n        *output_has_ellipsis = true;\n    }\n\n    // Map each label to a unique DimensionType.\n    label_types->resize(num_labels);\n    for (int label = 0; label < num_labels; ++label) {\n      if (label == kEllipsisLabel) continue;\n      bool removed = (*output_label_counts)[label] == 0;\n      bool unique = num_inputs == 1 || (*input_label_counts)[0][label] == 0 ||\n                    (*input_label_counts)[1][label] == 0;\n      (*label_types)[label] = GetDimensionType(removed, unique);\n    }\n    return Status::OK();\n  }",
        "func": "static Status ParseEquation(const string& equation,\n                              OperandLabels* input_labels,\n                              Labels* output_labels,\n                              std::vector<DimensionType>* label_types,\n                              OperandLabelCounts* input_label_counts,\n                              LabelCounts* output_label_counts,\n                              gtl::InlinedVector<bool, 2>* input_has_ellipsis,\n                              bool* output_has_ellipsis) {\n    gtl::InlinedVector<string, 2> input_str;\n    string output_str;\n    TF_RETURN_IF_ERROR(ParseEinsumEquation(equation, &input_str, &output_str));\n\n    // Temporary map from single character labels to (consecutive) integer\n    // labels.\n    absl::flat_hash_map<char, int> label_mapping;\n    int num_inputs = input_str.size();\n    input_labels->resize(num_inputs);\n\n    // Map from single characters to integer labels.\n    for (int i = 0; i < num_inputs; ++i) {\n      MapToLabels(input_str[i], &input_labels->at(i), &label_mapping);\n    }\n    MapToLabels(output_str, output_labels, &label_mapping);\n\n    // Compute counts for input and output labels.\n    int num_labels = label_mapping.size();\n    input_label_counts->resize(num_inputs);\n    input_has_ellipsis->resize(num_inputs);\n    for (int i = 0; i < num_inputs; ++i) {\n      input_label_counts->at(i).resize(num_labels);\n      input_has_ellipsis->at(i) = false;\n      for (const int label : input_labels->at(i)) {\n        if (label != kEllipsisLabel)\n          input_label_counts->at(i)[label] += 1;\n        else\n          input_has_ellipsis->at(i) = true;\n      }\n    }\n    output_label_counts->resize(num_labels);\n    *output_has_ellipsis = false;\n    for (const int label : *output_labels) {\n      if (label != kEllipsisLabel)\n        output_label_counts->at(label) += 1;\n      else\n        *output_has_ellipsis = true;\n    }\n\n    // Map each label to a unique DimensionType.\n    label_types->resize(num_labels);\n    for (int label = 0; label < num_labels; ++label) {\n      if (label == kEllipsisLabel) continue;\n      bool removed = (*output_label_counts)[label] == 0;\n      bool unique = num_inputs == 1 || (*input_label_counts)[0][label] == 0 ||\n                    (*input_label_counts)[1][label] == 0;\n      (*label_types)[label] = GetDimensionType(removed, unique);\n    }\n    return Status::OK();\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -28,6 +28,7 @@\n     input_has_ellipsis->resize(num_inputs);\n     for (int i = 0; i < num_inputs; ++i) {\n       input_label_counts->at(i).resize(num_labels);\n+      input_has_ellipsis->at(i) = false;\n       for (const int label : input_labels->at(i)) {\n         if (label != kEllipsisLabel)\n           input_label_counts->at(i)[label] += 1;\n@@ -36,6 +37,7 @@\n       }\n     }\n     output_label_counts->resize(num_labels);\n+    *output_has_ellipsis = false;\n     for (const int label : *output_labels) {\n       if (label != kEllipsisLabel)\n         output_label_counts->at(label) += 1;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "      input_has_ellipsis->at(i) = false;",
                "    *output_has_ellipsis = false;"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-41204",
        "func_name": "tensorflow/IsConstantFoldable",
        "description": "TensorFlow is an open source platform for machine learning. In affected versions during TensorFlow's Grappler optimizer phase, constant folding might attempt to deep copy a resource tensor. This results in a segfault, as these tensors are supposed to not change. The fix will be included in TensorFlow 2.7.0. We will also cherrypick this commit on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/7731e8dfbe4a56773be5dc94d631611211156659",
        "commit_title": "Don't constant-fold DT_RESOURCE constants.",
        "commit_text": " PiperOrigin-RevId: 391803952",
        "func_before": "bool IsConstantFoldable(\n    const Node* n,\n    const std::unordered_map<string, std::vector<PartialTensorShape>>*\n        shape_map,\n    const std::function<bool(const Node*)>& consider,\n    int64_t max_constant_size_in_bytes,\n    std::unordered_map<const Node*, std::vector<Tensor>>*\n        shape_replacement_map) {\n  if (n->IsConstant()) {\n    return true;\n  }\n  if (MaybeReplaceShapeOp(n, shape_map, shape_replacement_map)) {\n    return true;\n  }\n  if (n->op_def().is_stateful()) {\n    return false;\n  }\n  if (consider && !consider(n)) {\n    return false;\n  }\n  if (shape_map != nullptr) {\n    // We can skip the node if an output is known to be oversized.\n    auto shape_it = shape_map->find(n->name());\n    if (shape_it != shape_map->end()) {\n      for (int64_t i = 0; i < shape_it->second.size(); ++i) {\n        const auto& out_shape = shape_it->second[i];\n        if (out_shape.IsFullyDefined() &&\n            out_shape.num_elements() * DataTypeSize(n->output_type(i)) >\n                max_constant_size_in_bytes) {\n          return false;\n        }\n      }\n    }\n  }\n  if (n->IsControlFlow() || n->IsSend() || n->IsRecv()) {\n    return false;\n  }\n  // TODO(yuanbyu): For now disable these session handle operations.\n  if (n->IsGetSessionHandle() || n->IsGetSessionTensor() ||\n      n->IsDeleteSessionTensor()) {\n    return false;\n  }\n  if (n->IsSource()) {\n    return false;\n  }\n  if (n->IsSink()) {\n    return false;\n  }\n  if (n->IsFakeParam()) {\n    return false;\n  }\n  // Since constant-folding runs on the CPU, do not attempt to constant-fold\n  // operators that have no CPU kernel. Also implies that we will not\n  // constant-fold functions.\n  // TODO(phawkins): allow constant-folding for functions; functions may\n  // be arbitrarily expensive to execute.\n  if (!KernelDefAvailable(DeviceType(DEVICE_CPU), n->def())) {\n    return false;\n  }\n  // Do not constant fold nodes which will be allocated by ScopedAllocator.\n  // This is because the constant-folding graph will not contain the\n  // `_ScopedAllocator` node, and that is necessary to be able to run a node\n  // that will use this allocator.\n  if (n->attrs().Find(kScopedAllocatorAttrName) != nullptr) {\n    VLOG(2) << \"Skip node [\" << n->DebugString()\n            << \"] for constant folding due to scoped allocator\";\n    return false;\n  }\n  return true;\n}",
        "func": "bool IsConstantFoldable(\n    const Node* n,\n    const std::unordered_map<string, std::vector<PartialTensorShape>>*\n        shape_map,\n    const std::function<bool(const Node*)>& consider,\n    int64_t max_constant_size_in_bytes,\n    std::unordered_map<const Node*, std::vector<Tensor>>*\n        shape_replacement_map) {\n  if (n->IsConstant()) {\n    // Skip constant folding resources as they cannot be deep copied.\n    return n->output_type(0) != DT_RESOURCE;\n  }\n  if (MaybeReplaceShapeOp(n, shape_map, shape_replacement_map)) {\n    return true;\n  }\n  if (n->op_def().is_stateful()) {\n    return false;\n  }\n  if (consider && !consider(n)) {\n    return false;\n  }\n  if (shape_map != nullptr) {\n    // We can skip the node if an output is known to be oversized.\n    auto shape_it = shape_map->find(n->name());\n    if (shape_it != shape_map->end()) {\n      for (int64_t i = 0; i < shape_it->second.size(); ++i) {\n        const auto& out_shape = shape_it->second[i];\n        if (out_shape.IsFullyDefined() &&\n            out_shape.num_elements() * DataTypeSize(n->output_type(i)) >\n                max_constant_size_in_bytes) {\n          return false;\n        }\n      }\n    }\n  }\n  if (n->IsControlFlow() || n->IsSend() || n->IsRecv()) {\n    return false;\n  }\n  // TODO(yuanbyu): For now disable these session handle operations.\n  if (n->IsGetSessionHandle() || n->IsGetSessionTensor() ||\n      n->IsDeleteSessionTensor()) {\n    return false;\n  }\n  if (n->IsSource()) {\n    return false;\n  }\n  if (n->IsSink()) {\n    return false;\n  }\n  if (n->IsFakeParam()) {\n    return false;\n  }\n  // Since constant-folding runs on the CPU, do not attempt to constant-fold\n  // operators that have no CPU kernel. Also implies that we will not\n  // constant-fold functions.\n  // TODO(phawkins): allow constant-folding for functions; functions may\n  // be arbitrarily expensive to execute.\n  if (!KernelDefAvailable(DeviceType(DEVICE_CPU), n->def())) {\n    return false;\n  }\n  // Do not constant fold nodes which will be allocated by ScopedAllocator.\n  // This is because the constant-folding graph will not contain the\n  // `_ScopedAllocator` node, and that is necessary to be able to run a node\n  // that will use this allocator.\n  if (n->attrs().Find(kScopedAllocatorAttrName) != nullptr) {\n    VLOG(2) << \"Skip node [\" << n->DebugString()\n            << \"] for constant folding due to scoped allocator\";\n    return false;\n  }\n  return true;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -7,7 +7,8 @@\n     std::unordered_map<const Node*, std::vector<Tensor>>*\n         shape_replacement_map) {\n   if (n->IsConstant()) {\n-    return true;\n+    // Skip constant folding resources as they cannot be deep copied.\n+    return n->output_type(0) != DT_RESOURCE;\n   }\n   if (MaybeReplaceShapeOp(n, shape_map, shape_replacement_map)) {\n     return true;",
        "diff_line_info": {
            "deleted_lines": [
                "    return true;"
            ],
            "added_lines": [
                "    // Skip constant folding resources as they cannot be deep copied.",
                "    return n->output_type(0) != DT_RESOURCE;"
            ]
        }
    },
    {
        "cve_id": "CVE-2009-2768",
        "func_name": "torvalds/linux/load_flat_shared_library",
        "description": "The load_flat_shared_library function in fs/binfmt_flat.c in the flat subsystem in the Linux kernel before 2.6.31-rc6 allows local users to cause a denial of service (NULL pointer dereference and system crash) or possibly have unspecified other impact by executing a shared flat binary, which triggers an access of an \"uninitialized cred pointer.\"",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=3440625d78711bee41a84cf29c3d8c579b522666",
        "commit_title": "The new credentials code broke load_flat_shared_library() as it now uses",
        "commit_text": "an uninitialized cred pointer.  Cc: Mike Frysinger <vapier@gentoo.org> Cc: David Howells <dhowells@redhat.com> Cc: <stable@kernel.org> ",
        "func_before": "static int load_flat_shared_library(int id, struct lib_info *libs)\n{\n\tstruct linux_binprm bprm;\n\tint res;\n\tchar buf[16];\n\n\t/* Create the file name */\n\tsprintf(buf, \"/lib/lib%d.so\", id);\n\n\t/* Open the file up */\n\tbprm.filename = buf;\n\tbprm.file = open_exec(bprm.filename);\n\tres = PTR_ERR(bprm.file);\n\tif (IS_ERR(bprm.file))\n\t\treturn res;\n\n\tres = prepare_binprm(&bprm);\n\n\tif (res <= (unsigned long)-4096)\n\t\tres = load_flat_file(&bprm, libs, id, NULL);\n\tif (bprm.file) {\n\t\tallow_write_access(bprm.file);\n\t\tfput(bprm.file);\n\t\tbprm.file = NULL;\n\t}\n\treturn(res);\n}",
        "func": "static int load_flat_shared_library(int id, struct lib_info *libs)\n{\n\tstruct linux_binprm bprm;\n\tint res;\n\tchar buf[16];\n\n\t/* Create the file name */\n\tsprintf(buf, \"/lib/lib%d.so\", id);\n\n\t/* Open the file up */\n\tbprm.filename = buf;\n\tbprm.file = open_exec(bprm.filename);\n\tres = PTR_ERR(bprm.file);\n\tif (IS_ERR(bprm.file))\n\t\treturn res;\n\n\tbprm.cred = prepare_exec_creds();\n\tres = -ENOMEM;\n\tif (!bprm.cred)\n\t\tgoto out;\n\n\tres = prepare_binprm(&bprm);\n\n\tif (res <= (unsigned long)-4096)\n\t\tres = load_flat_file(&bprm, libs, id, NULL);\n\n\tabort_creds(bprm.cred);\n\nout:\n\tallow_write_access(bprm.file);\n\tfput(bprm.file);\n\n\treturn(res);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -14,14 +14,21 @@\n \tif (IS_ERR(bprm.file))\n \t\treturn res;\n \n+\tbprm.cred = prepare_exec_creds();\n+\tres = -ENOMEM;\n+\tif (!bprm.cred)\n+\t\tgoto out;\n+\n \tres = prepare_binprm(&bprm);\n \n \tif (res <= (unsigned long)-4096)\n \t\tres = load_flat_file(&bprm, libs, id, NULL);\n-\tif (bprm.file) {\n-\t\tallow_write_access(bprm.file);\n-\t\tfput(bprm.file);\n-\t\tbprm.file = NULL;\n-\t}\n+\n+\tabort_creds(bprm.cred);\n+\n+out:\n+\tallow_write_access(bprm.file);\n+\tfput(bprm.file);\n+\n \treturn(res);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (bprm.file) {",
                "\t\tallow_write_access(bprm.file);",
                "\t\tfput(bprm.file);",
                "\t\tbprm.file = NULL;",
                "\t}"
            ],
            "added_lines": [
                "\tbprm.cred = prepare_exec_creds();",
                "\tres = -ENOMEM;",
                "\tif (!bprm.cred)",
                "\t\tgoto out;",
                "",
                "",
                "\tabort_creds(bprm.cred);",
                "",
                "out:",
                "\tallow_write_access(bprm.file);",
                "\tfput(bprm.file);",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2023-36054",
        "func_name": "krb5/_xdr_kadm5_principal_ent_rec",
        "description": "lib/kadm5/kadm_rpc_xdr.c in MIT Kerberos 5 (aka krb5) before 1.20.2 and 1.21.x before 1.21.1 frees an uninitialized pointer. A remote authenticated user can trigger a kadmind crash. This occurs because _xdr_kadm5_principal_ent_rec does not validate the relationship between n_key_data and the key_data array count.",
        "git_url": "https://github.com/krb5/krb5/commit/ef08b09c9459551aabbe7924fb176f1583053cdd",
        "commit_title": "Ensure array count consistency in kadm5 RPC",
        "commit_text": " In _xdr_kadm5_principal_ent_rec(), ensure that n_key_data matches the key_data array count when decoding.  Otherwise when the structure is later freed, xdr_array() could iterate over the wrong number of elements, either leaking some memory or freeing uninitialized pointers.  Reported by Robert Morris.  CVE-2023-36054:  An authenticated attacker can cause a kadmind process to crash by freeing uninitialized pointers.  Remote code execution is unlikely. An attacker with control of a kadmin server can cause a kadmin client to crash by freeing uninitialized pointers.  ticket: 9099 (new) tags: pullup target_version: 1.21-next target_version: 1.20-next",
        "func_before": "static bool_t\n_xdr_kadm5_principal_ent_rec(XDR *xdrs, kadm5_principal_ent_rec *objp,\n\t\t\t     int v)\n{\n\tunsigned int n;\n\n\tif (!xdr_krb5_principal(xdrs, &objp->principal)) {\n\t\treturn (FALSE);\n\t}\n\tif (!xdr_krb5_timestamp(xdrs, &objp->princ_expire_time)) {\n\t\treturn (FALSE);\n\t}\n\tif (!xdr_krb5_timestamp(xdrs, &objp->last_pwd_change)) {\n\t\treturn (FALSE);\n\t}\n\tif (!xdr_krb5_timestamp(xdrs, &objp->pw_expiration)) {\n\t\treturn (FALSE);\n\t}\n\tif (!xdr_krb5_deltat(xdrs, &objp->max_life)) {\n\t\treturn (FALSE);\n\t}\n\tif (!xdr_nulltype(xdrs, (void **) &objp->mod_name,\n\t\t\t  xdr_krb5_principal)) {\n\t\treturn (FALSE);\n\t}\n\tif (!xdr_krb5_timestamp(xdrs, &objp->mod_date)) {\n\t\treturn (FALSE);\n\t}\n\tif (!xdr_krb5_flags(xdrs, &objp->attributes)) {\n\t\treturn (FALSE);\n\t}\n\tif (!xdr_krb5_kvno(xdrs, &objp->kvno)) {\n\t\treturn (FALSE);\n\t}\n\tif (!xdr_krb5_kvno(xdrs, &objp->mkvno)) {\n\t\treturn (FALSE);\n\t}\n\tif (!xdr_nullstring(xdrs, &objp->policy)) {\n\t\treturn (FALSE);\n\t}\n\tif (!xdr_long(xdrs, &objp->aux_attributes)) {\n\t\treturn (FALSE);\n\t}\n\tif (!xdr_krb5_deltat(xdrs, &objp->max_renewable_life)) {\n\t\treturn (FALSE);\n\t}\n\tif (!xdr_krb5_timestamp(xdrs, &objp->last_success)) {\n\t\treturn (FALSE);\n\t}\n\tif (!xdr_krb5_timestamp(xdrs, &objp->last_failed)) {\n\t\treturn (FALSE);\n\t}\n\tif (!xdr_krb5_kvno(xdrs, &objp->fail_auth_count)) {\n\t\treturn (FALSE);\n\t}\n\tif (!xdr_krb5_int16(xdrs, &objp->n_key_data)) {\n\t\treturn (FALSE);\n\t}\n\tif (!xdr_krb5_int16(xdrs, &objp->n_tl_data)) {\n\t\treturn (FALSE);\n\t}\n\tif (!xdr_nulltype(xdrs, (void **) &objp->tl_data,\n\t\t\t  xdr_krb5_tl_data)) {\n\t\treturn FALSE;\n\t}\n\tn = objp->n_key_data;\n\tif (!xdr_array(xdrs, (caddr_t *) &objp->key_data,\n\t\t       &n, ~0, sizeof(krb5_key_data),\n\t\t       xdr_krb5_key_data_nocontents)) {\n\t\treturn (FALSE);\n\t}\n\n\treturn (TRUE);\n}",
        "func": "static bool_t\n_xdr_kadm5_principal_ent_rec(XDR *xdrs, kadm5_principal_ent_rec *objp,\n\t\t\t     int v)\n{\n\tunsigned int n;\n\tbool_t r;\n\n\tif (!xdr_krb5_principal(xdrs, &objp->principal)) {\n\t\treturn (FALSE);\n\t}\n\tif (!xdr_krb5_timestamp(xdrs, &objp->princ_expire_time)) {\n\t\treturn (FALSE);\n\t}\n\tif (!xdr_krb5_timestamp(xdrs, &objp->last_pwd_change)) {\n\t\treturn (FALSE);\n\t}\n\tif (!xdr_krb5_timestamp(xdrs, &objp->pw_expiration)) {\n\t\treturn (FALSE);\n\t}\n\tif (!xdr_krb5_deltat(xdrs, &objp->max_life)) {\n\t\treturn (FALSE);\n\t}\n\tif (!xdr_nulltype(xdrs, (void **) &objp->mod_name,\n\t\t\t  xdr_krb5_principal)) {\n\t\treturn (FALSE);\n\t}\n\tif (!xdr_krb5_timestamp(xdrs, &objp->mod_date)) {\n\t\treturn (FALSE);\n\t}\n\tif (!xdr_krb5_flags(xdrs, &objp->attributes)) {\n\t\treturn (FALSE);\n\t}\n\tif (!xdr_krb5_kvno(xdrs, &objp->kvno)) {\n\t\treturn (FALSE);\n\t}\n\tif (!xdr_krb5_kvno(xdrs, &objp->mkvno)) {\n\t\treturn (FALSE);\n\t}\n\tif (!xdr_nullstring(xdrs, &objp->policy)) {\n\t\treturn (FALSE);\n\t}\n\tif (!xdr_long(xdrs, &objp->aux_attributes)) {\n\t\treturn (FALSE);\n\t}\n\tif (!xdr_krb5_deltat(xdrs, &objp->max_renewable_life)) {\n\t\treturn (FALSE);\n\t}\n\tif (!xdr_krb5_timestamp(xdrs, &objp->last_success)) {\n\t\treturn (FALSE);\n\t}\n\tif (!xdr_krb5_timestamp(xdrs, &objp->last_failed)) {\n\t\treturn (FALSE);\n\t}\n\tif (!xdr_krb5_kvno(xdrs, &objp->fail_auth_count)) {\n\t\treturn (FALSE);\n\t}\n\tif (!xdr_krb5_int16(xdrs, &objp->n_key_data)) {\n\t\treturn (FALSE);\n\t}\n\tif (xdrs->x_op == XDR_DECODE && objp->n_key_data < 0) {\n\t\treturn (FALSE);\n\t}\n\tif (!xdr_krb5_int16(xdrs, &objp->n_tl_data)) {\n\t\treturn (FALSE);\n\t}\n\tif (!xdr_nulltype(xdrs, (void **) &objp->tl_data,\n\t\t\t  xdr_krb5_tl_data)) {\n\t\treturn FALSE;\n\t}\n\tn = objp->n_key_data;\n\tr = xdr_array(xdrs, (caddr_t *) &objp->key_data, &n, objp->n_key_data,\n\t\t      sizeof(krb5_key_data), xdr_krb5_key_data_nocontents);\n\tobjp->n_key_data = n;\n\tif (!r) {\n\t\treturn (FALSE);\n\t}\n\n\treturn (TRUE);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,6 +3,7 @@\n \t\t\t     int v)\n {\n \tunsigned int n;\n+\tbool_t r;\n \n \tif (!xdr_krb5_principal(xdrs, &objp->principal)) {\n \t\treturn (FALSE);\n@@ -56,6 +57,9 @@\n \tif (!xdr_krb5_int16(xdrs, &objp->n_key_data)) {\n \t\treturn (FALSE);\n \t}\n+\tif (xdrs->x_op == XDR_DECODE && objp->n_key_data < 0) {\n+\t\treturn (FALSE);\n+\t}\n \tif (!xdr_krb5_int16(xdrs, &objp->n_tl_data)) {\n \t\treturn (FALSE);\n \t}\n@@ -64,9 +68,10 @@\n \t\treturn FALSE;\n \t}\n \tn = objp->n_key_data;\n-\tif (!xdr_array(xdrs, (caddr_t *) &objp->key_data,\n-\t\t       &n, ~0, sizeof(krb5_key_data),\n-\t\t       xdr_krb5_key_data_nocontents)) {\n+\tr = xdr_array(xdrs, (caddr_t *) &objp->key_data, &n, objp->n_key_data,\n+\t\t      sizeof(krb5_key_data), xdr_krb5_key_data_nocontents);\n+\tobjp->n_key_data = n;\n+\tif (!r) {\n \t\treturn (FALSE);\n \t}\n ",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (!xdr_array(xdrs, (caddr_t *) &objp->key_data,",
                "\t\t       &n, ~0, sizeof(krb5_key_data),",
                "\t\t       xdr_krb5_key_data_nocontents)) {"
            ],
            "added_lines": [
                "\tbool_t r;",
                "\tif (xdrs->x_op == XDR_DECODE && objp->n_key_data < 0) {",
                "\t\treturn (FALSE);",
                "\t}",
                "\tr = xdr_array(xdrs, (caddr_t *) &objp->key_data, &n, objp->n_key_data,",
                "\t\t      sizeof(krb5_key_data), xdr_krb5_key_data_nocontents);",
                "\tobjp->n_key_data = n;",
                "\tif (!r) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2023-4508",
        "func_name": "gerbv/gerb_fclose",
        "description": "A user able to control file input to Gerbv, between versions 2.4.0 and 2.10.0, can cause a crash and cause denial-of-service with a specially crafted Gerber RS-274X file.",
        "git_url": "https://github.com/gerbv/gerbv/commit/5517e22250e935dc7f86f64ad414aeae3dbcb36a",
        "commit_title": "fix: Out-of-bounds memory access of filename.",
        "commit_text": " Put all the filename allocation and deallocation into the `gerb_fopen` and `gerb_fclose` functions so that the caller doesn't need to deal with this anymore.  Also, free includeFilename.  It was allocated as part of `gerb_fgetstring()` above but never freed properly.  Unit tests added to valgrind.",
        "func_before": "void\ngerb_fclose(gerb_file_t *fd)\n{\n    if (fd) {\n#ifdef HAVE_SYS_MMAN_H\n\tif (munmap(fd->data, fd->datalen) < 0)\n\t    GERB_FATAL_ERROR(\"munmap: %s\", strerror(errno));\n#else\n\tg_free(fd->data);\n#endif   \n\tif (fclose(fd->fd) == EOF)\n\t    GERB_FATAL_ERROR(\"fclose: %s\", strerror(errno));\n\tg_free(fd);\n    }\n\n    return;\n}",
        "func": "void\ngerb_fclose(gerb_file_t *fd)\n{\n    if (fd) {\n        g_free(fd->filename);\n\n#ifdef HAVE_SYS_MMAN_H\n\tif (munmap(fd->data, fd->datalen) < 0)\n\t    GERB_FATAL_ERROR(\"munmap: %s\", strerror(errno));\n#else\n\tg_free(fd->data);\n#endif   \n\tif (fclose(fd->fd) == EOF)\n\t    GERB_FATAL_ERROR(\"fclose: %s\", strerror(errno));\n\tg_free(fd);\n    }\n\n    return;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,6 +2,8 @@\n gerb_fclose(gerb_file_t *fd)\n {\n     if (fd) {\n+        g_free(fd->filename);\n+\n #ifdef HAVE_SYS_MMAN_H\n \tif (munmap(fd->data, fd->datalen) < 0)\n \t    GERB_FATAL_ERROR(\"munmap: %s\", strerror(errno));",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "        g_free(fd->filename);",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2023-4508",
        "func_name": "gerbv/gerb_fopen",
        "description": "A user able to control file input to Gerbv, between versions 2.4.0 and 2.10.0, can cause a crash and cause denial-of-service with a specially crafted Gerber RS-274X file.",
        "git_url": "https://github.com/gerbv/gerbv/commit/5517e22250e935dc7f86f64ad414aeae3dbcb36a",
        "commit_title": "fix: Out-of-bounds memory access of filename.",
        "commit_text": " Put all the filename allocation and deallocation into the `gerb_fopen` and `gerb_fclose` functions so that the caller doesn't need to deal with this anymore.  Also, free includeFilename.  It was allocated as part of `gerb_fgetstring()` above but never freed properly.  Unit tests added to valgrind.",
        "func_before": "gerb_file_t *\ngerb_fopen(char const * filename)\n{\n    gerb_file_t *fd;\n    struct stat statinfo;\n    \n    dprintf(\"---> Entering gerb_fopen, filename = %s\\n\", filename);\n\n    fd = g_new(gerb_file_t, 1);\n    if (fd == NULL) {\n\treturn NULL;\n    }\n\n    dprintf(\"     Doing fopen\\n\");\n    /* fopen() can't open files with non ASCII filenames on windows */\n    fd->fd = g_fopen(filename, \"rb\");\n    if (fd->fd == NULL) {\n\tg_free(fd);\n\treturn NULL;\n    }\n\n    dprintf(\"     Doing fstat\\n\");\n    fd->ptr = 0;\n    fd->fileno = fileno(fd->fd);\n    if (fstat(fd->fileno, &statinfo) < 0) {\n\tfclose(fd->fd);\n\tg_free(fd);\n\treturn NULL;\n    }\n\n    dprintf(\"     Checking S_ISREG\\n\");\n    if (!S_ISREG(statinfo.st_mode)) {\n\tfclose(fd->fd);\n\tg_free(fd);\n\terrno = EISDIR;\n\treturn NULL;\n    }\n\n    dprintf(\"     Checking statinfo.st_size\\n\");\n    if ((int)statinfo.st_size == 0) {\n\tfclose(fd->fd);\n\tg_free(fd);\n\terrno = EIO; /* More compatible with the world outside Linux */\n\treturn NULL;\n    }\n\n#ifdef HAVE_SYS_MMAN_H\n\n    dprintf(\"     Doing mmap\\n\");\n    fd->datalen = (int)statinfo.st_size;\n    fd->data = (char *)mmap(0, statinfo.st_size, PROT_READ, MAP_PRIVATE, \n\t\t\t    fd->fileno, 0);\n    if(fd->data == MAP_FAILED) {\n\tfclose(fd->fd);\n\tg_free(fd);\n\tfd = NULL;\n    }\n\n#else\n    /* all systems without mmap, not only MINGW32 */\n\n    dprintf(\"     Doing calloc\\n\");\n    fd->datalen = (int)statinfo.st_size;\n    fd->data = calloc(1, statinfo.st_size + 1);\n    if (fd->data == NULL) {\n        fclose(fd->fd);\n        g_free(fd);\n        return NULL;\n    }\n    if (fread((void*)fd->data, 1, statinfo.st_size, fd->fd) != statinfo.st_size) {\n        fclose(fd->fd);\n\tg_free(fd->data);\n        g_free(fd);\n\treturn NULL;\n    }\n    rewind (fd->fd);\n\n#endif\n\n    dprintf(\"<--- Leaving gerb_fopen\\n\");\n    return fd;\n}",
        "func": "gerb_file_t *\ngerb_fopen(char const * filename)\n{\n    gerb_file_t *fd;\n    struct stat statinfo;\n    \n    dprintf(\"---> Entering gerb_fopen, filename = %s\\n\", filename);\n\n    fd = g_new(gerb_file_t, 1);\n    if (fd == NULL) {\n\treturn NULL;\n    }\n\n    dprintf(\"     Doing fopen\\n\");\n    /* fopen() can't open files with non ASCII filenames on windows */\n    fd->fd = g_fopen(filename, \"rb\");\n    if (fd->fd == NULL) {\n\tg_free(fd);\n\treturn NULL;\n    }\n\n    dprintf(\"     Doing fstat\\n\");\n    fd->ptr = 0;\n    fd->fileno = fileno(fd->fd);\n    if (fstat(fd->fileno, &statinfo) < 0) {\n\tfclose(fd->fd);\n\tg_free(fd);\n\treturn NULL;\n    }\n\n    dprintf(\"     Checking S_ISREG\\n\");\n    if (!S_ISREG(statinfo.st_mode)) {\n\tfclose(fd->fd);\n\tg_free(fd);\n\terrno = EISDIR;\n\treturn NULL;\n    }\n\n    dprintf(\"     Checking statinfo.st_size\\n\");\n    if ((int)statinfo.st_size == 0) {\n\tfclose(fd->fd);\n\tg_free(fd);\n\terrno = EIO; /* More compatible with the world outside Linux */\n\treturn NULL;\n    }\n\n#ifdef HAVE_SYS_MMAN_H\n\n    dprintf(\"     Doing mmap\\n\");\n    fd->datalen = (int)statinfo.st_size;\n    fd->data = (char *)mmap(0, statinfo.st_size, PROT_READ, MAP_PRIVATE, \n\t\t\t    fd->fileno, 0);\n    if(fd->data == MAP_FAILED) {\n\tfclose(fd->fd);\n\tg_free(fd);\n\tfd = NULL;\n    }\n\n#else\n    /* all systems without mmap, not only MINGW32 */\n\n    dprintf(\"     Doing calloc\\n\");\n    fd->datalen = (int)statinfo.st_size;\n    fd->data = calloc(1, statinfo.st_size + 1);\n    if (fd->data == NULL) {\n        fclose(fd->fd);\n        g_free(fd);\n        return NULL;\n    }\n    if (fread((void*)fd->data, 1, statinfo.st_size, fd->fd) != statinfo.st_size) {\n        fclose(fd->fd);\n\tg_free(fd->data);\n        g_free(fd);\n\treturn NULL;\n    }\n    rewind (fd->fd);\n\n#endif\n\n    dprintf(\"     Setting filename\\n\");\n    fd->filename = g_strdup(filename);\n\n    dprintf(\"<--- Leaving gerb_fopen\\n\");\n    return fd;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -77,6 +77,9 @@\n \n #endif\n \n+    dprintf(\"     Setting filename\\n\");\n+    fd->filename = g_strdup(filename);\n+\n     dprintf(\"<--- Leaving gerb_fopen\\n\");\n     return fd;\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    dprintf(\"     Setting filename\\n\");",
                "    fd->filename = g_strdup(filename);",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2023-4508",
        "func_name": "gerbv/parse_rs274x",
        "description": "A user able to control file input to Gerbv, between versions 2.4.0 and 2.10.0, can cause a crash and cause denial-of-service with a specially crafted Gerber RS-274X file.",
        "git_url": "https://github.com/gerbv/gerbv/commit/5517e22250e935dc7f86f64ad414aeae3dbcb36a",
        "commit_title": "fix: Out-of-bounds memory access of filename.",
        "commit_text": " Put all the filename allocation and deallocation into the `gerb_fopen` and `gerb_fclose` functions so that the caller doesn't need to deal with this anymore.  Also, free includeFilename.  It was allocated as part of `gerb_fgetstring()` above but never freed properly.  Unit tests added to valgrind.",
        "func_before": "static void \nparse_rs274x(gint levelOfRecursion, gerb_file_t *fd, gerbv_image_t *image, \n\t     gerb_state_t *state, gerbv_net_t *curr_net, gerbv_stats_t *stats, \n\t     gchar *directoryPath, long int *line_num_p)\n{\n    int op[2];\n    char str[3];\n    int tmp;\n    gerbv_aperture_t *a = NULL;\n    gerbv_amacro_t *tmp_amacro;\n    int ano;\n    gdouble scale = 1.0;\n    gerbv_error_list_t *error_list = stats->error_list;\n    \n    if (state->state->unit == GERBV_UNIT_MM)\n    \tscale = 25.4;\n    \n    op[0] = gerb_fgetc(fd);\n    op[1] = gerb_fgetc(fd);\n    \n    if (op[0] == EOF || op[1] == EOF)\n\tgerbv_stats_printf(error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t_(\"Unexpected EOF found in file \\\"%s\\\"\"), fd->filename);\n\n    switch (A2I(op[0], op[1])){\n\t\n\t/* \n\t * Directive parameters \n\t */\n    case A2I('A','S'): /* Axis Select */\n\top[0] = gerb_fgetc(fd);\n\top[1] = gerb_fgetc(fd);\n\tstate->state = gerbv_image_return_new_netstate (state->state);\n\t\n\tif (op[0] == EOF || op[1] == EOF)\n\t    gerbv_stats_printf(error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t    _(\"Unexpected EOF found in file \\\"%s\\\"\"), fd->filename);\n\t\n\tif (((op[0] == 'A') && (op[1] == 'Y')) ||\n\t    ((op[0] == 'B') && (op[1] == 'X'))) {\n\t    state->state->axisSelect = GERBV_AXIS_SELECT_SWAPAB;\n\t} else {\n\t    state->state->axisSelect = GERBV_AXIS_SELECT_NOSELECT;\n\t}\n\n\top[0] = gerb_fgetc(fd);\n\top[1] = gerb_fgetc(fd);\n\t\n\tif (op[0] == EOF || op[1] == EOF)\n\t    gerbv_stats_printf(error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t    _(\"Unexpected EOF found in file \\\"%s\\\"\"), fd->filename);\n\n\tif (((op[0] == 'A') && (op[1] == 'Y')) ||\n\t    ((op[0] == 'B') && (op[1] == 'X'))) {\n\t    state->state->axisSelect = GERBV_AXIS_SELECT_SWAPAB;\n\t} else {\n\t    state->state->axisSelect = GERBV_AXIS_SELECT_NOSELECT;\n\t}\n\tbreak;\n\n    case A2I('F','S'): /* Format Statement */\n\timage->format = g_new0 (gerbv_format_t,1);\n\t\n\tswitch (gerb_fgetc(fd)) {\n\tcase 'L':\n\t    image->format->omit_zeros = GERBV_OMIT_ZEROS_LEADING;\n\t    break;\n\tcase 'T':\n\t    image->format->omit_zeros = GERBV_OMIT_ZEROS_TRAILING;\n\t    break;\n\tcase 'D':\n\t    image->format->omit_zeros = GERBV_OMIT_ZEROS_EXPLICIT;\n\t    break;\n\tdefault:\n\t    gerbv_stats_printf(error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t    _(\"EagleCad bug detected: Undefined handling of zeros \"\n\t\t\t\"in format code at line %ld in file \\\"%s\\\"\"),\n\t\t    *line_num_p, fd->filename);\n\t    gerbv_stats_printf(error_list, GERBV_MESSAGE_WARNING, -1,\n\t\t    _(\"Defaulting to omitting leading zeros\"));\n\t    gerb_ungetc(fd);\n\t    image->format->omit_zeros = GERBV_OMIT_ZEROS_LEADING;\n\t}\n\t\n\tswitch (gerb_fgetc(fd)) {\n\tcase 'A':\n\t    image->format->coordinate = GERBV_COORDINATE_ABSOLUTE;\n\t    break;\n\tcase 'I':\n\t    image->format->coordinate = GERBV_COORDINATE_INCREMENTAL;\n\t    break;\n\tdefault:\n\t    gerbv_stats_printf(error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t    _(\"Invalid coordinate type defined in format code \"\n\t\t\t\"at line %ld in file \\\"%s\\\"\"),\n\t\t    *line_num_p, fd->filename);\n\t    gerbv_stats_printf(error_list, GERBV_MESSAGE_WARNING, -1,\n\t\t    _(\"Defaulting to absolute coordinates\"));\n\t    image->format->coordinate = GERBV_COORDINATE_ABSOLUTE;\n\t}\n\top[0] = gerb_fgetc(fd);\n\twhile((op[0] != '*')&&(op[0] != EOF)) {\n\t    switch (op[0]) {\n\t    case 'N':\n\t\top[0] = (char)gerb_fgetc(fd);\n\t\timage->format->lim_seqno = op[0] - '0';\n\t\tbreak;\n\t    case 'G':\n\t\top[0] = (char)gerb_fgetc(fd);\n\t\timage->format->lim_gf = op[0] - '0';\n\t\tbreak;\n\t    case 'D':\n\t\top[0] = (char)gerb_fgetc(fd);\n\t\timage->format->lim_pf = op[0] - '0';\n\t\tbreak;\n\t    case 'M':\n\t\top[0] = (char)gerb_fgetc(fd);\n\t\timage->format->lim_mf = op[0] - '0';\n\t\tbreak;\n\t    case 'X' :\n\t\top[0] = gerb_fgetc(fd);\n\t\tif ((op[0] < '0') || (op[0] > '6')) {\n\t\t    gerbv_stats_printf(error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t\t    _(\"Illegal format size '%s' \"\n\t\t\t\t\"at line %ld in file \\\"%s\\\"\"),\n\t\t\t    gerbv_escape_char(op[0]),\n\t\t\t    *line_num_p, fd->filename);\n\t\t}\n\t\timage->format->x_int = op[0] - '0';\n\t\top[0] = gerb_fgetc(fd);\n\t\tif ((op[0] < '0') || (op[0] > '6')) {\n\t\t    gerbv_stats_printf(error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t\t    _(\"Illegal format size '%s' \"\n\t\t\t\t\"at line %ld in file \\\"%s\\\"\"),\n\t\t\t    gerbv_escape_char(op[0]),\n\t\t\t    *line_num_p, fd->filename);\n\t\t}\n\t\timage->format->x_dec = op[0] - '0';\n\t\tbreak;\n\t    case 'Y':\n\t\top[0] = gerb_fgetc(fd);\n\t\tif ((op[0] < '0') || (op[0] > '6')) {\n\t\t    gerbv_stats_printf(error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t\t    _(\"Illegal format size '%s' \"\n\t\t\t\t\"at line %ld in file \\\"%s\\\"\"),\n\t\t\t    gerbv_escape_char(op[0]),\n\t\t\t    *line_num_p, fd->filename);\n\t\t}\n\t\timage->format->y_int = op[0] - '0';\n\t\top[0] = gerb_fgetc(fd);\n\t\tif ((op[0] < '0') || (op[0] > '6')) {\n\t\t    gerbv_stats_printf(error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t\t    _(\"Illegal format size '%s' \"\n\t\t\t       \"at line %ld in file \\\"%s\\\"\"),\n\t\t\t    gerbv_escape_char(op[0]),\n\t\t\t    *line_num_p, fd->filename);\n\t\t}\n\t\timage->format->y_dec = op[0] - '0';\n\t\tbreak;\n\t    default :\n\t\tgerbv_stats_printf(error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t\t_(\"Illegal format statement '%s' \"\n\t\t\t   \"at line %ld in file \\\"%s\\\"\"),\n\t\t\tgerbv_escape_char(op[0]),\n\t\t\t*line_num_p, fd->filename);\n\t\tgerbv_stats_printf(error_list, GERBV_MESSAGE_WARNING, -1,\n\t\t\t_(\"Ignoring invalid format statement\"));\n\t    }\n\t    op[0] = gerb_fgetc(fd);\n\t}\n\tbreak;\n    case A2I('M','I'): /* Mirror Image */\n\top[0] = gerb_fgetc(fd);\n\tstate->state = gerbv_image_return_new_netstate (state->state);\n\t\n\twhile ((op[0] != '*')&&(op[0] != EOF)) {\n            gint readValue=0;\n\t    switch (op[0]) {\n\t    case 'A' :\n\t\treadValue = gerb_fgetint(fd, NULL);\n\t\tif (readValue == 1) {\n\t\t    if (state->state->mirrorState == GERBV_MIRROR_STATE_FLIPB)\n\t\t\tstate->state->mirrorState=GERBV_MIRROR_STATE_FLIPAB;\n\t\t    else\n\t\t\tstate->state->mirrorState=GERBV_MIRROR_STATE_FLIPA;\n\t\t}\n\t\tbreak;\n\t    case 'B' :\n\t\treadValue = gerb_fgetint(fd, NULL);\n\t\tif (readValue == 1) {\n\t\t    if (state->state->mirrorState == GERBV_MIRROR_STATE_FLIPA)\n\t\t\tstate->state->mirrorState=GERBV_MIRROR_STATE_FLIPAB;\n\t\t    else\n\t\t\tstate->state->mirrorState=GERBV_MIRROR_STATE_FLIPB;\n\t\t}\n\t\tbreak;\n\t    default :\n\t\tgerbv_stats_printf(error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t\t_(\"Wrong character '%s' in mirror \"\n\t\t\t    \"at line %ld in file \\\"%s\\\"\"),\n\t\t\tgerbv_escape_char(op[0]), *line_num_p, fd->filename);\n\t    }\n\t    op[0] = gerb_fgetc(fd);\n\t}\n\tbreak;  \n    case A2I('M','O'): /* Mode of Units */\n\top[0] = gerb_fgetc(fd);\n\top[1] = gerb_fgetc(fd);\n\t\n\tif (op[0] == EOF || op[1] == EOF)\n\t    gerbv_stats_printf(error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t    _(\"Unexpected EOF found in file \\\"%s\\\"\"), fd->filename);\n\n\tswitch (A2I(op[0],op[1])) {\n\tcase A2I('I','N'):\n\t    state->state = gerbv_image_return_new_netstate (state->state);\n\t    state->state->unit = GERBV_UNIT_INCH;\n\t    break;\n\tcase A2I('M','M'):\n\t    state->state = gerbv_image_return_new_netstate (state->state);\n\t    state->state->unit = GERBV_UNIT_MM;\n\t    break;\n\tdefault:\n\t    gerbv_stats_printf(error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t    _(\"Illegal unit '%s%s' at line %ld in file \\\"%s\\\"\"),\n\t\t    gerbv_escape_char(op[0]), gerbv_escape_char(op[1]),\n\t\t    *line_num_p, fd->filename);\n\t}\n\tbreak;\n    case A2I('O','F'): /* Offset */\n\top[0] = gerb_fgetc(fd);\n\t\n\twhile ((op[0] != '*')&&(op[0] != EOF)) {\n\t    switch (op[0]) {\n\t    case 'A' :\n\t\tstate->state->offsetA = gerb_fgetdouble(fd) / scale;\n\t\tbreak;\n\t    case 'B' :\n\t\tstate->state->offsetB = gerb_fgetdouble(fd) / scale;\n\t\tbreak;\n\t    default :\n\t\tgerbv_stats_printf(error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t\t_(\"Wrong character '%s' in offset \"\n\t\t\t    \"at line %ld in file \\\"%s\\\"\"),\n\t\t\tgerbv_escape_char(op[0]), *line_num_p, fd->filename);\n\t    }\n\t    op[0] = gerb_fgetc(fd);\n\t}\n\tbreak;\n    case A2I('I','F'): /* Include file */\n\t{\n\t    gchar *includeFilename = gerb_fgetstring(fd, '*');\n\t    \n\t    if (includeFilename) {\n\t\tgchar *fullPath;\n\t\tif (!g_path_is_absolute(includeFilename)) {\n\t\t    fullPath = g_build_filename (directoryPath, includeFilename, NULL);\n\t\t} else {\n\t\t    fullPath = g_strdup (includeFilename);\n\t\t}\n\t\tif (levelOfRecursion < 10) {\n\t\t    gerb_file_t *includefd = NULL;\n\t\t    \n\t\t    includefd = gerb_fopen(fullPath);\n\t\t    if (includefd) {\n\t\t\tgerber_parse_file_segment (levelOfRecursion + 1, image, state, curr_net, stats, includefd, directoryPath);\n\t\t\tgerb_fclose(includefd);\n\t\t    } else {\n\t\t\tgerbv_stats_printf(error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t\t\t_(\"Included file \\\"%s\\\" cannot be found \"\n\t\t\t\t    \"at line %ld in file \\\"%s\\\"\"),\n\t\t\t\tfullPath, *line_num_p, fd->filename);\n\t\t    }\n\t\t    g_free (fullPath);\n\t\t} else {\n\t\t    gerbv_stats_printf(error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t\t    _(\"Parser encountered more than 10 levels of \"\n\t\t\t\t\"include file recursion which is not allowed \"\n\t\t\t\t\"by the RS-274X spec\"));\n\t\t}\n\t\t\n\t    }\n\t}\n\tbreak;\n    case A2I('I','O'): /* Image offset */\n\top[0] = gerb_fgetc(fd);\n\t\n\twhile ((op[0] != '*')&&(op[0] != EOF)) {\n\t    switch (op[0]) {\n\t    case 'A' :\n\t\timage->info->offsetA = gerb_fgetdouble(fd) / scale;\n\t\tbreak;\n\t    case 'B' :\n\t\timage->info->offsetB = gerb_fgetdouble(fd) / scale;\n\t\tbreak;\n\t    default :\n\t\tgerbv_stats_printf(error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t\t_(\"Wrong character '%s' in image offset \"\n\t\t\t    \"at line %ld in file \\\"%s\\\"\"),\n\t\t\tgerbv_escape_char(op[0]), *line_num_p, fd->filename);\n\t    }\n\t    op[0] = gerb_fgetc(fd);\n\t}\n\tbreak;\n    case A2I('S','F'): /* Scale Factor */\n     state->state = gerbv_image_return_new_netstate (state->state);\n\tif (gerb_fgetc(fd) == 'A')\n\t    state->state->scaleA = gerb_fgetdouble(fd);\n\telse \n\t    gerb_ungetc(fd);\n\tif (gerb_fgetc(fd) == 'B')\n\t    state->state->scaleB = gerb_fgetdouble(fd);\n\telse \n\t    gerb_ungetc(fd);\n\tbreak;\n    case A2I('I','C'): /* Input Code */\n\t/* Thanks to Stephen Adam for providing this information. As he writes:\n\t *      btw, here's a logic puzzle for you.  If you need to\n\t * read the gerber file to see how it's encoded, then\n\t * how can you read it?\n\t */\n\top[0] = gerb_fgetc(fd);\n\top[1] = gerb_fgetc(fd);\n\t\n\tif (op[0] == EOF || op[1] == EOF)\n\t    gerbv_stats_printf(error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t    _(\"Unexpected EOF found in file \\\"%s\\\"\"), fd->filename);\n\n\tswitch (A2I(op[0],op[1])) {\n\tcase A2I('A','S'):\n\t    image->info->encoding = GERBV_ENCODING_ASCII;\n\t    break;\n\tcase A2I('E','B'):\n\t    image->info->encoding = GERBV_ENCODING_EBCDIC;\n\t    break;\n\tcase A2I('B','C'):\n\t    image->info->encoding = GERBV_ENCODING_BCD;\n\t    break;\n\tcase A2I('I','S'):\n\t    image->info->encoding = GERBV_ENCODING_ISO_ASCII;\n\t    break;\n\tcase A2I('E','I'):\n\t    image->info->encoding = GERBV_ENCODING_EIA;\n\t    break;\n\tdefault:\n\t    gerbv_stats_printf(error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t    _(\"Unknown input code (IC) '%s%s' \"\n\t\t\t\"at line %ld in file \\\"%s\\\"\"),\n\t\t    gerbv_escape_char(op[0]), gerbv_escape_char(op[1]),\n\t\t    *line_num_p, fd->filename);\n\t}\n\tbreak;\n\t\n\t/* Image parameters */\n    case A2I('I','J'): /* Image Justify */\n\top[0] = gerb_fgetc(fd);\n\timage->info->imageJustifyTypeA = GERBV_JUSTIFY_LOWERLEFT;\n\timage->info->imageJustifyTypeB = GERBV_JUSTIFY_LOWERLEFT;\n\timage->info->imageJustifyOffsetA = 0.0;\n\timage->info->imageJustifyOffsetB = 0.0;\n\twhile ((op[0] != '*')&&(op[0] != EOF)) {\n\t    switch (op[0]) {\n\t    case 'A' :\n\t    \top[0] = gerb_fgetc(fd);\n\t    \tif (op[0] == 'C') {\n\t\t    image->info->imageJustifyTypeA = GERBV_JUSTIFY_CENTERJUSTIFY;\n\t    \t} else if (op[0] == 'L') {\n\t\t    image->info->imageJustifyTypeA = GERBV_JUSTIFY_LOWERLEFT;\n\t    \t} else {\n\t\t    gerb_ungetc (fd);\n\t\t    image->info->imageJustifyOffsetA = gerb_fgetdouble(fd) / scale;\n\t    \t}\n\t\tbreak;\n\t    case 'B' :\n\t\top[0] = gerb_fgetc(fd);\n\t    \tif (op[0] == 'C') {\n\t\t    image->info->imageJustifyTypeB = GERBV_JUSTIFY_CENTERJUSTIFY;\n\t    \t} else if (op[0] == 'L') {\n\t\t    image->info->imageJustifyTypeB = GERBV_JUSTIFY_LOWERLEFT;\n\t    \t} else {\n\t\t    gerb_ungetc (fd);\n\t\t    image->info->imageJustifyOffsetB = gerb_fgetdouble(fd) / scale;\n\t    \t}\n\t\tbreak;\n\t    default :\n\t\tgerbv_stats_printf(error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t\t_(\"Wrong character '%s' in image justify \"\n\t\t\t    \"at line %ld in file \\\"%s\\\"\"),\n\t\t\tgerbv_escape_char(op[0]), *line_num_p, fd->filename);\n\t    }\n\t    op[0] = gerb_fgetc(fd);\n\t}\n\tbreak;\n    case A2I('I','N'): /* Image Name */\n\timage->info->name = gerb_fgetstring(fd, '*');\n\tbreak;\n    case A2I('I','P'): /* Image Polarity */\n\t\n\tfor (ano = 0; ano < 3; ano++) {\n\t    op[0] = gerb_fgetc(fd);\n\t    if (op[0] == EOF) {\n\t\tgerbv_stats_printf(error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t\t_(\"Unexpected EOF while reading image polarity (IP) \"\n\t\t\t    \"in file \\\"%s\\\"\"), fd->filename);\n\t    }\n\t    str[ano] = (char)op[0];\n\t}\n\t\n\tif (strncmp(str, \"POS\", 3) == 0) \n\t    image->info->polarity = GERBV_POLARITY_POSITIVE;\n\telse if (strncmp(str, \"NEG\", 3) == 0)\n\t    image->info->polarity = GERBV_POLARITY_NEGATIVE;\n\telse {\n\t    gerbv_stats_printf(error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t    _(\"Unknown polarity '%s%s%s' \"\n\t\t\t\"at line %ld in file \\\"%s\\\"\"),\n\t\t    gerbv_escape_char(str[0]), gerbv_escape_char(str[1]),\n\t\t    gerbv_escape_char(str[2]), *line_num_p, fd->filename);\n\t}\n\tbreak;\n    case A2I('I','R'): /* Image Rotation */\n\ttmp = gerb_fgetint(fd, NULL) % 360;\n\tif (tmp == 0)\n\t    image->info->imageRotation = 0.0;\n\telse if (tmp == 90)\n\t    image->info->imageRotation = M_PI_2;\n\telse if (tmp == 180)\n\t    image->info->imageRotation = M_PI;\n\telse if (tmp == 270)\n\t    image->info->imageRotation = M_PI + M_PI_2;\n\telse {\n\t    gerbv_stats_printf(error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t    _(\"Image rotation must be 0, 90, 180 or 270 \"\n\t\t\t\"(is actually %d) at line %ld in file \\\"%s\\\"\"),\n\t\t    tmp, *line_num_p, fd->filename);\n\t}\n\tbreak;\n    case A2I('P','F'): /* Plotter Film */\n\timage->info->plotterFilm = gerb_fgetstring(fd, '*');\n\tbreak;\n\t\n\t/* Aperture parameters */\n    case A2I('A','D'): /* Aperture Description */\n\ta = (gerbv_aperture_t *) g_new0 (gerbv_aperture_t,1);\n\n\tano = parse_aperture_definition(fd, a, image, scale, line_num_p);\n\tif (ano == -1) {\n\t\t/* error with line parse, so just quietly ignore */\n\t}\n\telse if ((ano >= 0) && (ano <= APERTURE_MAX)) {\n\t    a->unit = state->state->unit;\n\t    image->aperture[ano] = a;\n\t    dprintf(\"     In %s(), adding new aperture to aperture list ...\\n\",\n\t\t\t    __func__);\n\t    gerbv_stats_add_aperture(stats->aperture_list,\n\t\t\t\t    -1, ano, \n\t\t\t\t    a->type,\n\t\t\t\t    a->parameter);\n\t    gerbv_stats_add_to_D_list(stats->D_code_list,\n\t\t\t\t     ano);\n\t    if (ano < APERTURE_MIN) {\n\t\t    gerbv_stats_printf(error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t\t    _(\"Aperture number out of bounds %d \"\n\t\t\t\t\"at line %ld in file \\\"%s\\\"\"),\n\t\t\t    ano, *line_num_p, fd->filename);\n\t    }\n\t} else {\n\t    gerbv_stats_printf(error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t    _(\"Aperture number out of bounds %d \"\n\t\t       \"at line %ld in file \\\"%s\\\"\"),\n\t\t    ano, *line_num_p, fd->filename);\n\t}\n\t/* Add aperture info to stats->aperture_list here */\n\t\n\tbreak;\n    case A2I('A','M'): /* Aperture Macro */\n\ttmp_amacro = image->amacro;\n\timage->amacro = parse_aperture_macro(fd);\n\tif (image->amacro) {\n\t    image->amacro->next = tmp_amacro;\n#ifdef AMACRO_DEBUG\n\t    print_program(image->amacro);\n#endif\n\t} else {\n\t    gerbv_stats_printf(error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t    _(\"Failed to parse aperture macro \"\n\t\t       \"at line %ld in file \\\"%s\\\"\"),\n\t\t    *line_num_p, fd->filename);\n\t}\n\t// return, since we want to skip the later back-up loop\n\treturn;\n\t/* Layer */\n    case A2I('L','N'): /* Layer Name */\n\tstate->layer = gerbv_image_return_new_layer (state->layer);\n\tstate->layer->name = gerb_fgetstring(fd, '*');\n\tbreak;\n    case A2I('L','P'): /* Layer Polarity */\n\tstate->layer = gerbv_image_return_new_layer (state->layer);\n\tswitch (gerb_fgetc(fd)) {\n\tcase 'D': /* Dark Polarity (default) */\n\t    state->layer->polarity = GERBV_POLARITY_DARK;\n\t    break;\n\tcase 'C': /* Clear Polarity */\n\t    state->layer->polarity = GERBV_POLARITY_CLEAR;\n\t    break;\n\tdefault:\n\t    gerbv_stats_printf(error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t    _(\"Unknown layer polarity '%s' \"\n\t\t       \"at line %ld in file \\\"%s\\\"\"),\n\t\t    gerbv_escape_char(op[0]), *line_num_p, fd->filename);\n\t}\n\tbreak;\n    case A2I('K','O'): /* Knock Out */\n        state->layer = gerbv_image_return_new_layer (state->layer);\n        gerber_update_any_running_knockout_measurements (image);\n        /* reset any previous knockout measurements */\n        knockoutMeasure = FALSE;\n        op[0] = gerb_fgetc(fd);\n\tif (op[0] == '*') { /* Disable previous SR parameters */\n\t    state->layer->knockout.type = GERBV_KNOCKOUT_TYPE_NOKNOCKOUT;\n\t    break;\n\t} else if (op[0] == 'C') {\n\t    state->layer->knockout.polarity = GERBV_POLARITY_CLEAR;\n\t} else if (op[0] == 'D') {\n\t    state->layer->knockout.polarity = GERBV_POLARITY_DARK;\n\t} else {\n\t    gerbv_stats_printf(error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t    _(\"Knockout must supply a polarity (C, D, or *) \"\n\t\t\t\"at line %ld in file \\\"%s\\\"\"),\n\t\t    *line_num_p, fd->filename);\n\t}\n\tstate->layer->knockout.lowerLeftX = 0.0;\n\tstate->layer->knockout.lowerLeftY = 0.0;\n\tstate->layer->knockout.width = 0.0;\n\tstate->layer->knockout.height = 0.0;\n\tstate->layer->knockout.border = 0.0;\n\tstate->layer->knockout.firstInstance = TRUE;\n\top[0] = gerb_fgetc(fd);\n\twhile ((op[0] != '*')&&(op[0] != EOF)) { \n\t    switch (op[0]) {\n\t    case 'X':\n\t        state->layer->knockout.type = GERBV_KNOCKOUT_TYPE_FIXEDKNOCK;\n\t\tstate->layer->knockout.lowerLeftX = gerb_fgetdouble(fd) / scale;\n\t\tbreak;\n\t    case 'Y':\n\t        state->layer->knockout.type = GERBV_KNOCKOUT_TYPE_FIXEDKNOCK;\n\t\tstate->layer->knockout.lowerLeftY = gerb_fgetdouble(fd) / scale;\n\t\tbreak;\n\t    case 'I':\n\t        state->layer->knockout.type = GERBV_KNOCKOUT_TYPE_FIXEDKNOCK;\n\t\tstate->layer->knockout.width = gerb_fgetdouble(fd) / scale;\n\t\tbreak;\n\t    case 'J':\n\t        state->layer->knockout.type = GERBV_KNOCKOUT_TYPE_FIXEDKNOCK;\n\t\tstate->layer->knockout.height = gerb_fgetdouble(fd) / scale;\n\t\tbreak;\n\t    case 'K':\n\t        state->layer->knockout.type = GERBV_KNOCKOUT_TYPE_BORDER;\n\t        state->layer->knockout.border = gerb_fgetdouble(fd) / scale;\n\t        /* this is a bordered knockout, so we need to start measuring the\n\t           size of a square bordering all future components */\n\t        knockoutMeasure = TRUE;\n\t        knockoutLimitXmin = HUGE_VAL;\n\t        knockoutLimitYmin = HUGE_VAL;\n\t        knockoutLimitXmax = -HUGE_VAL;\n\t        knockoutLimitYmax = -HUGE_VAL;\n\t        knockoutLayer = state->layer;\n\t        break;\n\t    default:\n\t\tgerbv_stats_printf(error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t\t_(\"Unknown variable in knockout \"\n\t\t\t    \"at line %ld in file \\\"%s\\\"\"),\n\t\t\t*line_num_p, fd->filename);\n\t    }\n\t    op[0] = gerb_fgetc(fd);\n\t}\n\tbreak;\n    case A2I('S','R'): /* Step and Repeat */\n        /* start by generating a new layer (duplicating previous layer settings */\n        state->layer = gerbv_image_return_new_layer (state->layer);\n\top[0] = gerb_fgetc(fd);\n\tif (op[0] == '*') { /* Disable previous SR parameters */\n\t    state->layer->stepAndRepeat.X = 1;\n\t    state->layer->stepAndRepeat.Y = 1;\n\t    state->layer->stepAndRepeat.dist_X = 0.0;\n\t    state->layer->stepAndRepeat.dist_Y = 0.0;\n\t    break;\n\t}\n\twhile ((op[0] != '*')&&(op[0] != EOF)) {\n\t    switch (op[0]) {\n\t    case 'X':\n\t\tstate->layer->stepAndRepeat.X = gerb_fgetint(fd, NULL);\n\t\tbreak;\n\t    case 'Y':\n\t\tstate->layer->stepAndRepeat.Y = gerb_fgetint(fd, NULL);\n\t\tbreak;\n\t    case 'I':\n\t\tstate->layer->stepAndRepeat.dist_X = gerb_fgetdouble(fd) / scale;\n\t\tbreak;\n\t    case 'J':\n\t\tstate->layer->stepAndRepeat.dist_Y = gerb_fgetdouble(fd) / scale;\n\t\tbreak;\n\t    default:\n\t\tgerbv_stats_printf(error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t\t_(\"Step-and-repeat parameter error \"\n\t\t\t   \"at line %ld in file \\\"%s\\\"\"),\n\t\t\t*line_num_p, fd->filename);\n\t    }\n\t    \n\t    /*\n\t     * Repeating 0 times in any direction would disable the whole plot, and\n\t     * is probably not intended. At least one other tool (viewmate) seems\n\t     * to interpret 0-time repeating as repeating just once too.\n\t     */\n\t    if(state->layer->stepAndRepeat.X == 0)\n\t\tstate->layer->stepAndRepeat.X = 1;\n\t    if(state->layer->stepAndRepeat.Y == 0)\n\t\tstate->layer->stepAndRepeat.Y = 1;\n\t    \n\t    op[0] = gerb_fgetc(fd);\n\t}\n\tbreak;\n\t/* is this an actual RS274X command??  It isn't explainined in the spec... */\n    case A2I('R','O'):\n\tstate->layer = gerbv_image_return_new_layer (state->layer);\n\t\n\tstate->layer->rotation = DEG2RAD(gerb_fgetdouble(fd));\n\top[0] = gerb_fgetc(fd);\n\tif (op[0] != '*') {\n\t    gerbv_stats_printf(error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t    _(\"Error in layer rotation command \"\n\t\t       \"at line %ld in file \\\"%s\\\"\"),\n\t\t    *line_num_p, fd->filename);\n\t}\n\tbreak;\n    default:\n\tgerbv_stats_printf(error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t_(\"Unknown RS-274X extension found %%%s%s%% \"\n\t\t    \"at line %ld in file \\\"%s\\\"\"),\n\t\tgerbv_escape_char(op[0]), gerbv_escape_char(op[1]),\n\t\t*line_num_p, fd->filename);\n    }\n\n    // make sure we read until the trailing * character\n    // first, backspace once in case we already read the trailing *\n    gerb_ungetc(fd);\n    do {\n    \ttmp = gerb_fgetc(fd);\n    } while (tmp != EOF && tmp != '*');\n\n    return;\n}",
        "func": "static void \nparse_rs274x(gint levelOfRecursion, gerb_file_t *fd, gerbv_image_t *image, \n\t     gerb_state_t *state, gerbv_net_t *curr_net, gerbv_stats_t *stats, \n\t     gchar *directoryPath, long int *line_num_p)\n{\n    int op[2];\n    char str[3];\n    int tmp;\n    gerbv_aperture_t *a = NULL;\n    gerbv_amacro_t *tmp_amacro;\n    int ano;\n    gdouble scale = 1.0;\n    gerbv_error_list_t *error_list = stats->error_list;\n    \n    if (state->state->unit == GERBV_UNIT_MM)\n    \tscale = 25.4;\n    \n    op[0] = gerb_fgetc(fd);\n    op[1] = gerb_fgetc(fd);\n    \n    if (op[0] == EOF || op[1] == EOF)\n\tgerbv_stats_printf(error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t_(\"Unexpected EOF found in file \\\"%s\\\"\"), fd->filename);\n\n    switch (A2I(op[0], op[1])){\n\t\n\t/* \n\t * Directive parameters \n\t */\n    case A2I('A','S'): /* Axis Select */\n\top[0] = gerb_fgetc(fd);\n\top[1] = gerb_fgetc(fd);\n\tstate->state = gerbv_image_return_new_netstate (state->state);\n\t\n\tif (op[0] == EOF || op[1] == EOF)\n\t    gerbv_stats_printf(error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t    _(\"Unexpected EOF found in file \\\"%s\\\"\"), fd->filename);\n\t\n\tif (((op[0] == 'A') && (op[1] == 'Y')) ||\n\t    ((op[0] == 'B') && (op[1] == 'X'))) {\n\t    state->state->axisSelect = GERBV_AXIS_SELECT_SWAPAB;\n\t} else {\n\t    state->state->axisSelect = GERBV_AXIS_SELECT_NOSELECT;\n\t}\n\n\top[0] = gerb_fgetc(fd);\n\top[1] = gerb_fgetc(fd);\n\t\n\tif (op[0] == EOF || op[1] == EOF)\n\t    gerbv_stats_printf(error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t    _(\"Unexpected EOF found in file \\\"%s\\\"\"), fd->filename);\n\n\tif (((op[0] == 'A') && (op[1] == 'Y')) ||\n\t    ((op[0] == 'B') && (op[1] == 'X'))) {\n\t    state->state->axisSelect = GERBV_AXIS_SELECT_SWAPAB;\n\t} else {\n\t    state->state->axisSelect = GERBV_AXIS_SELECT_NOSELECT;\n\t}\n\tbreak;\n\n    case A2I('F','S'): /* Format Statement */\n\timage->format = g_new0 (gerbv_format_t,1);\n\t\n\tswitch (gerb_fgetc(fd)) {\n\tcase 'L':\n\t    image->format->omit_zeros = GERBV_OMIT_ZEROS_LEADING;\n\t    break;\n\tcase 'T':\n\t    image->format->omit_zeros = GERBV_OMIT_ZEROS_TRAILING;\n\t    break;\n\tcase 'D':\n\t    image->format->omit_zeros = GERBV_OMIT_ZEROS_EXPLICIT;\n\t    break;\n\tdefault:\n\t    gerbv_stats_printf(error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t    _(\"EagleCad bug detected: Undefined handling of zeros \"\n\t\t\t\"in format code at line %ld in file \\\"%s\\\"\"),\n\t\t    *line_num_p, fd->filename);\n\t    gerbv_stats_printf(error_list, GERBV_MESSAGE_WARNING, -1,\n\t\t    _(\"Defaulting to omitting leading zeros\"));\n\t    gerb_ungetc(fd);\n\t    image->format->omit_zeros = GERBV_OMIT_ZEROS_LEADING;\n\t}\n\t\n\tswitch (gerb_fgetc(fd)) {\n\tcase 'A':\n\t    image->format->coordinate = GERBV_COORDINATE_ABSOLUTE;\n\t    break;\n\tcase 'I':\n\t    image->format->coordinate = GERBV_COORDINATE_INCREMENTAL;\n\t    break;\n\tdefault:\n\t    gerbv_stats_printf(error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t    _(\"Invalid coordinate type defined in format code \"\n\t\t\t\"at line %ld in file \\\"%s\\\"\"),\n\t\t    *line_num_p, fd->filename);\n\t    gerbv_stats_printf(error_list, GERBV_MESSAGE_WARNING, -1,\n\t\t    _(\"Defaulting to absolute coordinates\"));\n\t    image->format->coordinate = GERBV_COORDINATE_ABSOLUTE;\n\t}\n\top[0] = gerb_fgetc(fd);\n\twhile((op[0] != '*')&&(op[0] != EOF)) {\n\t    switch (op[0]) {\n\t    case 'N':\n\t\top[0] = (char)gerb_fgetc(fd);\n\t\timage->format->lim_seqno = op[0] - '0';\n\t\tbreak;\n\t    case 'G':\n\t\top[0] = (char)gerb_fgetc(fd);\n\t\timage->format->lim_gf = op[0] - '0';\n\t\tbreak;\n\t    case 'D':\n\t\top[0] = (char)gerb_fgetc(fd);\n\t\timage->format->lim_pf = op[0] - '0';\n\t\tbreak;\n\t    case 'M':\n\t\top[0] = (char)gerb_fgetc(fd);\n\t\timage->format->lim_mf = op[0] - '0';\n\t\tbreak;\n\t    case 'X' :\n\t\top[0] = gerb_fgetc(fd);\n\t\tif ((op[0] < '0') || (op[0] > '6')) {\n\t\t    gerbv_stats_printf(error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t\t    _(\"Illegal format size '%s' \"\n\t\t\t\t\"at line %ld in file \\\"%s\\\"\"),\n\t\t\t    gerbv_escape_char(op[0]),\n\t\t\t    *line_num_p, fd->filename);\n\t\t}\n\t\timage->format->x_int = op[0] - '0';\n\t\top[0] = gerb_fgetc(fd);\n\t\tif ((op[0] < '0') || (op[0] > '6')) {\n\t\t    gerbv_stats_printf(error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t\t    _(\"Illegal format size '%s' \"\n\t\t\t\t\"at line %ld in file \\\"%s\\\"\"),\n\t\t\t    gerbv_escape_char(op[0]),\n\t\t\t    *line_num_p, fd->filename);\n\t\t}\n\t\timage->format->x_dec = op[0] - '0';\n\t\tbreak;\n\t    case 'Y':\n\t\top[0] = gerb_fgetc(fd);\n\t\tif ((op[0] < '0') || (op[0] > '6')) {\n\t\t    gerbv_stats_printf(error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t\t    _(\"Illegal format size '%s' \"\n\t\t\t\t\"at line %ld in file \\\"%s\\\"\"),\n\t\t\t    gerbv_escape_char(op[0]),\n\t\t\t    *line_num_p, fd->filename);\n\t\t}\n\t\timage->format->y_int = op[0] - '0';\n\t\top[0] = gerb_fgetc(fd);\n\t\tif ((op[0] < '0') || (op[0] > '6')) {\n\t\t    gerbv_stats_printf(error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t\t    _(\"Illegal format size '%s' \"\n\t\t\t       \"at line %ld in file \\\"%s\\\"\"),\n\t\t\t    gerbv_escape_char(op[0]),\n\t\t\t    *line_num_p, fd->filename);\n\t\t}\n\t\timage->format->y_dec = op[0] - '0';\n\t\tbreak;\n\t    default :\n\t\tgerbv_stats_printf(error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t\t_(\"Illegal format statement '%s' \"\n\t\t\t   \"at line %ld in file \\\"%s\\\"\"),\n\t\t\tgerbv_escape_char(op[0]),\n\t\t\t*line_num_p, fd->filename);\n\t\tgerbv_stats_printf(error_list, GERBV_MESSAGE_WARNING, -1,\n\t\t\t_(\"Ignoring invalid format statement\"));\n\t    }\n\t    op[0] = gerb_fgetc(fd);\n\t}\n\tbreak;\n    case A2I('M','I'): /* Mirror Image */\n\top[0] = gerb_fgetc(fd);\n\tstate->state = gerbv_image_return_new_netstate (state->state);\n\t\n\twhile ((op[0] != '*')&&(op[0] != EOF)) {\n            gint readValue=0;\n\t    switch (op[0]) {\n\t    case 'A' :\n\t\treadValue = gerb_fgetint(fd, NULL);\n\t\tif (readValue == 1) {\n\t\t    if (state->state->mirrorState == GERBV_MIRROR_STATE_FLIPB)\n\t\t\tstate->state->mirrorState=GERBV_MIRROR_STATE_FLIPAB;\n\t\t    else\n\t\t\tstate->state->mirrorState=GERBV_MIRROR_STATE_FLIPA;\n\t\t}\n\t\tbreak;\n\t    case 'B' :\n\t\treadValue = gerb_fgetint(fd, NULL);\n\t\tif (readValue == 1) {\n\t\t    if (state->state->mirrorState == GERBV_MIRROR_STATE_FLIPA)\n\t\t\tstate->state->mirrorState=GERBV_MIRROR_STATE_FLIPAB;\n\t\t    else\n\t\t\tstate->state->mirrorState=GERBV_MIRROR_STATE_FLIPB;\n\t\t}\n\t\tbreak;\n\t    default :\n\t\tgerbv_stats_printf(error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t\t_(\"Wrong character '%s' in mirror \"\n\t\t\t    \"at line %ld in file \\\"%s\\\"\"),\n\t\t\tgerbv_escape_char(op[0]), *line_num_p, fd->filename);\n\t    }\n\t    op[0] = gerb_fgetc(fd);\n\t}\n\tbreak;  \n    case A2I('M','O'): /* Mode of Units */\n\top[0] = gerb_fgetc(fd);\n\top[1] = gerb_fgetc(fd);\n\t\n\tif (op[0] == EOF || op[1] == EOF)\n\t    gerbv_stats_printf(error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t    _(\"Unexpected EOF found in file \\\"%s\\\"\"), fd->filename);\n\n\tswitch (A2I(op[0],op[1])) {\n\tcase A2I('I','N'):\n\t    state->state = gerbv_image_return_new_netstate (state->state);\n\t    state->state->unit = GERBV_UNIT_INCH;\n\t    break;\n\tcase A2I('M','M'):\n\t    state->state = gerbv_image_return_new_netstate (state->state);\n\t    state->state->unit = GERBV_UNIT_MM;\n\t    break;\n\tdefault:\n\t    gerbv_stats_printf(error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t    _(\"Illegal unit '%s%s' at line %ld in file \\\"%s\\\"\"),\n\t\t    gerbv_escape_char(op[0]), gerbv_escape_char(op[1]),\n\t\t    *line_num_p, fd->filename);\n\t}\n\tbreak;\n    case A2I('O','F'): /* Offset */\n\top[0] = gerb_fgetc(fd);\n\t\n\twhile ((op[0] != '*')&&(op[0] != EOF)) {\n\t    switch (op[0]) {\n\t    case 'A' :\n\t\tstate->state->offsetA = gerb_fgetdouble(fd) / scale;\n\t\tbreak;\n\t    case 'B' :\n\t\tstate->state->offsetB = gerb_fgetdouble(fd) / scale;\n\t\tbreak;\n\t    default :\n\t\tgerbv_stats_printf(error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t\t_(\"Wrong character '%s' in offset \"\n\t\t\t    \"at line %ld in file \\\"%s\\\"\"),\n\t\t\tgerbv_escape_char(op[0]), *line_num_p, fd->filename);\n\t    }\n\t    op[0] = gerb_fgetc(fd);\n\t}\n\tbreak;\n    case A2I('I','F'): /* Include file */\n\t{\n\t    gchar *includeFilename = gerb_fgetstring(fd, '*');\n\t    \n\t    if (includeFilename) {\n\t\tgchar *fullPath;\n\t\tif (!g_path_is_absolute(includeFilename)) {\n\t\t    fullPath = g_build_filename (directoryPath, includeFilename, NULL);\n\t\t} else {\n\t\t    fullPath = g_strdup (includeFilename);\n\t\t}\n\t\tif (levelOfRecursion < 10) {\n\t\t    gerb_file_t *includefd = NULL;\n\t\t    \n\t\t    includefd = gerb_fopen(fullPath);\n\t\t    if (includefd) {\n\t\t\tgerber_parse_file_segment (levelOfRecursion + 1, image, state, curr_net, stats, includefd, directoryPath);\n\t\t\tgerb_fclose(includefd);\n\t\t    } else {\n\t\t\tgerbv_stats_printf(error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t\t\t_(\"Included file \\\"%s\\\" cannot be found \"\n\t\t\t\t    \"at line %ld in file \\\"%s\\\"\"),\n\t\t\t\tfullPath, *line_num_p, fd->filename);\n\t\t    }\n\t\t    g_free (fullPath);\n\t\t} else {\n\t\t    gerbv_stats_printf(error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t\t    _(\"Parser encountered more than 10 levels of \"\n\t\t\t\t\"include file recursion which is not allowed \"\n\t\t\t\t\"by the RS-274X spec\"));\n\t\t}\n\t\tg_free (includeFilename);\n\t    }\n\t}\n\tbreak;\n    case A2I('I','O'): /* Image offset */\n\top[0] = gerb_fgetc(fd);\n\t\n\twhile ((op[0] != '*')&&(op[0] != EOF)) {\n\t    switch (op[0]) {\n\t    case 'A' :\n\t\timage->info->offsetA = gerb_fgetdouble(fd) / scale;\n\t\tbreak;\n\t    case 'B' :\n\t\timage->info->offsetB = gerb_fgetdouble(fd) / scale;\n\t\tbreak;\n\t    default :\n\t\tgerbv_stats_printf(error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t\t_(\"Wrong character '%s' in image offset \"\n\t\t\t    \"at line %ld in file \\\"%s\\\"\"),\n\t\t\tgerbv_escape_char(op[0]), *line_num_p, fd->filename);\n\t    }\n\t    op[0] = gerb_fgetc(fd);\n\t}\n\tbreak;\n    case A2I('S','F'): /* Scale Factor */\n     state->state = gerbv_image_return_new_netstate (state->state);\n\tif (gerb_fgetc(fd) == 'A')\n\t    state->state->scaleA = gerb_fgetdouble(fd);\n\telse \n\t    gerb_ungetc(fd);\n\tif (gerb_fgetc(fd) == 'B')\n\t    state->state->scaleB = gerb_fgetdouble(fd);\n\telse \n\t    gerb_ungetc(fd);\n\tbreak;\n    case A2I('I','C'): /* Input Code */\n\t/* Thanks to Stephen Adam for providing this information. As he writes:\n\t *      btw, here's a logic puzzle for you.  If you need to\n\t * read the gerber file to see how it's encoded, then\n\t * how can you read it?\n\t */\n\top[0] = gerb_fgetc(fd);\n\top[1] = gerb_fgetc(fd);\n\t\n\tif (op[0] == EOF || op[1] == EOF)\n\t    gerbv_stats_printf(error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t    _(\"Unexpected EOF found in file \\\"%s\\\"\"), fd->filename);\n\n\tswitch (A2I(op[0],op[1])) {\n\tcase A2I('A','S'):\n\t    image->info->encoding = GERBV_ENCODING_ASCII;\n\t    break;\n\tcase A2I('E','B'):\n\t    image->info->encoding = GERBV_ENCODING_EBCDIC;\n\t    break;\n\tcase A2I('B','C'):\n\t    image->info->encoding = GERBV_ENCODING_BCD;\n\t    break;\n\tcase A2I('I','S'):\n\t    image->info->encoding = GERBV_ENCODING_ISO_ASCII;\n\t    break;\n\tcase A2I('E','I'):\n\t    image->info->encoding = GERBV_ENCODING_EIA;\n\t    break;\n\tdefault:\n\t    gerbv_stats_printf(error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t    _(\"Unknown input code (IC) '%s%s' \"\n\t\t\t\"at line %ld in file \\\"%s\\\"\"),\n\t\t    gerbv_escape_char(op[0]), gerbv_escape_char(op[1]),\n\t\t    *line_num_p, fd->filename);\n\t}\n\tbreak;\n\t\n\t/* Image parameters */\n    case A2I('I','J'): /* Image Justify */\n\top[0] = gerb_fgetc(fd);\n\timage->info->imageJustifyTypeA = GERBV_JUSTIFY_LOWERLEFT;\n\timage->info->imageJustifyTypeB = GERBV_JUSTIFY_LOWERLEFT;\n\timage->info->imageJustifyOffsetA = 0.0;\n\timage->info->imageJustifyOffsetB = 0.0;\n\twhile ((op[0] != '*')&&(op[0] != EOF)) {\n\t    switch (op[0]) {\n\t    case 'A' :\n\t    \top[0] = gerb_fgetc(fd);\n\t    \tif (op[0] == 'C') {\n\t\t    image->info->imageJustifyTypeA = GERBV_JUSTIFY_CENTERJUSTIFY;\n\t    \t} else if (op[0] == 'L') {\n\t\t    image->info->imageJustifyTypeA = GERBV_JUSTIFY_LOWERLEFT;\n\t    \t} else {\n\t\t    gerb_ungetc (fd);\n\t\t    image->info->imageJustifyOffsetA = gerb_fgetdouble(fd) / scale;\n\t    \t}\n\t\tbreak;\n\t    case 'B' :\n\t\top[0] = gerb_fgetc(fd);\n\t    \tif (op[0] == 'C') {\n\t\t    image->info->imageJustifyTypeB = GERBV_JUSTIFY_CENTERJUSTIFY;\n\t    \t} else if (op[0] == 'L') {\n\t\t    image->info->imageJustifyTypeB = GERBV_JUSTIFY_LOWERLEFT;\n\t    \t} else {\n\t\t    gerb_ungetc (fd);\n\t\t    image->info->imageJustifyOffsetB = gerb_fgetdouble(fd) / scale;\n\t    \t}\n\t\tbreak;\n\t    default :\n\t\tgerbv_stats_printf(error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t\t_(\"Wrong character '%s' in image justify \"\n\t\t\t    \"at line %ld in file \\\"%s\\\"\"),\n\t\t\tgerbv_escape_char(op[0]), *line_num_p, fd->filename);\n\t    }\n\t    op[0] = gerb_fgetc(fd);\n\t}\n\tbreak;\n    case A2I('I','N'): /* Image Name */\n\timage->info->name = gerb_fgetstring(fd, '*');\n\tbreak;\n    case A2I('I','P'): /* Image Polarity */\n\t\n\tfor (ano = 0; ano < 3; ano++) {\n\t    op[0] = gerb_fgetc(fd);\n\t    if (op[0] == EOF) {\n\t\tgerbv_stats_printf(error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t\t_(\"Unexpected EOF while reading image polarity (IP) \"\n\t\t\t    \"in file \\\"%s\\\"\"), fd->filename);\n\t    }\n\t    str[ano] = (char)op[0];\n\t}\n\t\n\tif (strncmp(str, \"POS\", 3) == 0) \n\t    image->info->polarity = GERBV_POLARITY_POSITIVE;\n\telse if (strncmp(str, \"NEG\", 3) == 0)\n\t    image->info->polarity = GERBV_POLARITY_NEGATIVE;\n\telse {\n\t    gerbv_stats_printf(error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t    _(\"Unknown polarity '%s%s%s' \"\n\t\t\t\"at line %ld in file \\\"%s\\\"\"),\n\t\t    gerbv_escape_char(str[0]), gerbv_escape_char(str[1]),\n\t\t    gerbv_escape_char(str[2]), *line_num_p, fd->filename);\n\t}\n\tbreak;\n    case A2I('I','R'): /* Image Rotation */\n\ttmp = gerb_fgetint(fd, NULL) % 360;\n\tif (tmp == 0)\n\t    image->info->imageRotation = 0.0;\n\telse if (tmp == 90)\n\t    image->info->imageRotation = M_PI_2;\n\telse if (tmp == 180)\n\t    image->info->imageRotation = M_PI;\n\telse if (tmp == 270)\n\t    image->info->imageRotation = M_PI + M_PI_2;\n\telse {\n\t    gerbv_stats_printf(error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t    _(\"Image rotation must be 0, 90, 180 or 270 \"\n\t\t\t\"(is actually %d) at line %ld in file \\\"%s\\\"\"),\n\t\t    tmp, *line_num_p, fd->filename);\n\t}\n\tbreak;\n    case A2I('P','F'): /* Plotter Film */\n\timage->info->plotterFilm = gerb_fgetstring(fd, '*');\n\tbreak;\n\t\n\t/* Aperture parameters */\n    case A2I('A','D'): /* Aperture Description */\n\ta = (gerbv_aperture_t *) g_new0 (gerbv_aperture_t,1);\n\n\tano = parse_aperture_definition(fd, a, image, scale, line_num_p);\n\tif (ano == -1) {\n\t\t/* error with line parse, so just quietly ignore */\n\t}\n\telse if ((ano >= 0) && (ano <= APERTURE_MAX)) {\n\t    a->unit = state->state->unit;\n\t    image->aperture[ano] = a;\n\t    dprintf(\"     In %s(), adding new aperture to aperture list ...\\n\",\n\t\t\t    __func__);\n\t    gerbv_stats_add_aperture(stats->aperture_list,\n\t\t\t\t    -1, ano, \n\t\t\t\t    a->type,\n\t\t\t\t    a->parameter);\n\t    gerbv_stats_add_to_D_list(stats->D_code_list,\n\t\t\t\t     ano);\n\t    if (ano < APERTURE_MIN) {\n\t\t    gerbv_stats_printf(error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t\t    _(\"Aperture number out of bounds %d \"\n\t\t\t\t\"at line %ld in file \\\"%s\\\"\"),\n\t\t\t    ano, *line_num_p, fd->filename);\n\t    }\n\t} else {\n\t    gerbv_stats_printf(error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t    _(\"Aperture number out of bounds %d \"\n\t\t       \"at line %ld in file \\\"%s\\\"\"),\n\t\t    ano, *line_num_p, fd->filename);\n\t}\n\t/* Add aperture info to stats->aperture_list here */\n\t\n\tbreak;\n    case A2I('A','M'): /* Aperture Macro */\n\ttmp_amacro = image->amacro;\n\timage->amacro = parse_aperture_macro(fd);\n\tif (image->amacro) {\n\t    image->amacro->next = tmp_amacro;\n#ifdef AMACRO_DEBUG\n\t    print_program(image->amacro);\n#endif\n\t} else {\n\t    gerbv_stats_printf(error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t    _(\"Failed to parse aperture macro \"\n\t\t       \"at line %ld in file \\\"%s\\\"\"),\n\t\t    *line_num_p, fd->filename);\n\t}\n\t// return, since we want to skip the later back-up loop\n\treturn;\n\t/* Layer */\n    case A2I('L','N'): /* Layer Name */\n\tstate->layer = gerbv_image_return_new_layer (state->layer);\n\tstate->layer->name = gerb_fgetstring(fd, '*');\n\tbreak;\n    case A2I('L','P'): /* Layer Polarity */\n\tstate->layer = gerbv_image_return_new_layer (state->layer);\n\tswitch (gerb_fgetc(fd)) {\n\tcase 'D': /* Dark Polarity (default) */\n\t    state->layer->polarity = GERBV_POLARITY_DARK;\n\t    break;\n\tcase 'C': /* Clear Polarity */\n\t    state->layer->polarity = GERBV_POLARITY_CLEAR;\n\t    break;\n\tdefault:\n\t    gerbv_stats_printf(error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t    _(\"Unknown layer polarity '%s' \"\n\t\t       \"at line %ld in file \\\"%s\\\"\"),\n\t\t    gerbv_escape_char(op[0]), *line_num_p, fd->filename);\n\t}\n\tbreak;\n    case A2I('K','O'): /* Knock Out */\n        state->layer = gerbv_image_return_new_layer (state->layer);\n        gerber_update_any_running_knockout_measurements (image);\n        /* reset any previous knockout measurements */\n        knockoutMeasure = FALSE;\n        op[0] = gerb_fgetc(fd);\n\tif (op[0] == '*') { /* Disable previous SR parameters */\n\t    state->layer->knockout.type = GERBV_KNOCKOUT_TYPE_NOKNOCKOUT;\n\t    break;\n\t} else if (op[0] == 'C') {\n\t    state->layer->knockout.polarity = GERBV_POLARITY_CLEAR;\n\t} else if (op[0] == 'D') {\n\t    state->layer->knockout.polarity = GERBV_POLARITY_DARK;\n\t} else {\n\t    gerbv_stats_printf(error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t    _(\"Knockout must supply a polarity (C, D, or *) \"\n\t\t\t\"at line %ld in file \\\"%s\\\"\"),\n\t\t    *line_num_p, fd->filename);\n\t}\n\tstate->layer->knockout.lowerLeftX = 0.0;\n\tstate->layer->knockout.lowerLeftY = 0.0;\n\tstate->layer->knockout.width = 0.0;\n\tstate->layer->knockout.height = 0.0;\n\tstate->layer->knockout.border = 0.0;\n\tstate->layer->knockout.firstInstance = TRUE;\n\top[0] = gerb_fgetc(fd);\n\twhile ((op[0] != '*')&&(op[0] != EOF)) { \n\t    switch (op[0]) {\n\t    case 'X':\n\t        state->layer->knockout.type = GERBV_KNOCKOUT_TYPE_FIXEDKNOCK;\n\t\tstate->layer->knockout.lowerLeftX = gerb_fgetdouble(fd) / scale;\n\t\tbreak;\n\t    case 'Y':\n\t        state->layer->knockout.type = GERBV_KNOCKOUT_TYPE_FIXEDKNOCK;\n\t\tstate->layer->knockout.lowerLeftY = gerb_fgetdouble(fd) / scale;\n\t\tbreak;\n\t    case 'I':\n\t        state->layer->knockout.type = GERBV_KNOCKOUT_TYPE_FIXEDKNOCK;\n\t\tstate->layer->knockout.width = gerb_fgetdouble(fd) / scale;\n\t\tbreak;\n\t    case 'J':\n\t        state->layer->knockout.type = GERBV_KNOCKOUT_TYPE_FIXEDKNOCK;\n\t\tstate->layer->knockout.height = gerb_fgetdouble(fd) / scale;\n\t\tbreak;\n\t    case 'K':\n\t        state->layer->knockout.type = GERBV_KNOCKOUT_TYPE_BORDER;\n\t        state->layer->knockout.border = gerb_fgetdouble(fd) / scale;\n\t        /* this is a bordered knockout, so we need to start measuring the\n\t           size of a square bordering all future components */\n\t        knockoutMeasure = TRUE;\n\t        knockoutLimitXmin = HUGE_VAL;\n\t        knockoutLimitYmin = HUGE_VAL;\n\t        knockoutLimitXmax = -HUGE_VAL;\n\t        knockoutLimitYmax = -HUGE_VAL;\n\t        knockoutLayer = state->layer;\n\t        break;\n\t    default:\n\t\tgerbv_stats_printf(error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t\t_(\"Unknown variable in knockout \"\n\t\t\t    \"at line %ld in file \\\"%s\\\"\"),\n\t\t\t*line_num_p, fd->filename);\n\t    }\n\t    op[0] = gerb_fgetc(fd);\n\t}\n\tbreak;\n    case A2I('S','R'): /* Step and Repeat */\n        /* start by generating a new layer (duplicating previous layer settings */\n        state->layer = gerbv_image_return_new_layer (state->layer);\n\top[0] = gerb_fgetc(fd);\n\tif (op[0] == '*') { /* Disable previous SR parameters */\n\t    state->layer->stepAndRepeat.X = 1;\n\t    state->layer->stepAndRepeat.Y = 1;\n\t    state->layer->stepAndRepeat.dist_X = 0.0;\n\t    state->layer->stepAndRepeat.dist_Y = 0.0;\n\t    break;\n\t}\n\twhile ((op[0] != '*')&&(op[0] != EOF)) {\n\t    switch (op[0]) {\n\t    case 'X':\n\t\tstate->layer->stepAndRepeat.X = gerb_fgetint(fd, NULL);\n\t\tbreak;\n\t    case 'Y':\n\t\tstate->layer->stepAndRepeat.Y = gerb_fgetint(fd, NULL);\n\t\tbreak;\n\t    case 'I':\n\t\tstate->layer->stepAndRepeat.dist_X = gerb_fgetdouble(fd) / scale;\n\t\tbreak;\n\t    case 'J':\n\t\tstate->layer->stepAndRepeat.dist_Y = gerb_fgetdouble(fd) / scale;\n\t\tbreak;\n\t    default:\n\t\tgerbv_stats_printf(error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t\t_(\"Step-and-repeat parameter error \"\n\t\t\t   \"at line %ld in file \\\"%s\\\"\"),\n\t\t\t*line_num_p, fd->filename);\n\t    }\n\t    \n\t    /*\n\t     * Repeating 0 times in any direction would disable the whole plot, and\n\t     * is probably not intended. At least one other tool (viewmate) seems\n\t     * to interpret 0-time repeating as repeating just once too.\n\t     */\n\t    if(state->layer->stepAndRepeat.X == 0)\n\t\tstate->layer->stepAndRepeat.X = 1;\n\t    if(state->layer->stepAndRepeat.Y == 0)\n\t\tstate->layer->stepAndRepeat.Y = 1;\n\t    \n\t    op[0] = gerb_fgetc(fd);\n\t}\n\tbreak;\n\t/* is this an actual RS274X command??  It isn't explainined in the spec... */\n    case A2I('R','O'):\n\tstate->layer = gerbv_image_return_new_layer (state->layer);\n\t\n\tstate->layer->rotation = DEG2RAD(gerb_fgetdouble(fd));\n\top[0] = gerb_fgetc(fd);\n\tif (op[0] != '*') {\n\t    gerbv_stats_printf(error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t    _(\"Error in layer rotation command \"\n\t\t       \"at line %ld in file \\\"%s\\\"\"),\n\t\t    *line_num_p, fd->filename);\n\t}\n\tbreak;\n    default:\n\tgerbv_stats_printf(error_list, GERBV_MESSAGE_ERROR, -1,\n\t\t_(\"Unknown RS-274X extension found %%%s%s%% \"\n\t\t    \"at line %ld in file \\\"%s\\\"\"),\n\t\tgerbv_escape_char(op[0]), gerbv_escape_char(op[1]),\n\t\t*line_num_p, fd->filename);\n    }\n\n    // make sure we read until the trailing * character\n    // first, backspace once in case we already read the trailing *\n    gerb_ungetc(fd);\n    do {\n    \ttmp = gerb_fgetc(fd);\n    } while (tmp != EOF && tmp != '*');\n\n    return;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -278,7 +278,7 @@\n \t\t\t\t\"include file recursion which is not allowed \"\n \t\t\t\t\"by the RS-274X spec\"));\n \t\t}\n-\t\t\n+\t\tg_free (includeFilename);\n \t    }\n \t}\n \tbreak;",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t"
            ],
            "added_lines": [
                "\t\tg_free (includeFilename);"
            ]
        }
    },
    {
        "cve_id": "CVE-2023-4508",
        "func_name": "gerbv/gerbv_open_image",
        "description": "A user able to control file input to Gerbv, between versions 2.4.0 and 2.10.0, can cause a crash and cause denial-of-service with a specially crafted Gerber RS-274X file.",
        "git_url": "https://github.com/gerbv/gerbv/commit/5517e22250e935dc7f86f64ad414aeae3dbcb36a",
        "commit_title": "fix: Out-of-bounds memory access of filename.",
        "commit_text": " Put all the filename allocation and deallocation into the `gerb_fopen` and `gerb_fclose` functions so that the caller doesn't need to deal with this anymore.  Also, free includeFilename.  It was allocated as part of `gerb_fgetstring()` above but never freed properly.  Unit tests added to valgrind.",
        "func_before": "int\ngerbv_open_image(gerbv_project_t *gerbvProject, gchar const* filename, int idx, int reload,\n\t\tgerbv_HID_Attribute *fattr, int n_fattr, gboolean forceLoadFile)\n{\n    gerb_file_t *fd;\n    gerbv_image_t *parsed_image = NULL, *parsed_image2 = NULL;\n    gint retv = -1;\n    gboolean isPnpFile = FALSE, foundBinary;\n    gerbv_HID_Attribute *attr_list = NULL;\n    int n_attr = 0;\n    /* If we're reloading, we'll pass in our file format attribute list\n     * since this is our hook for letting the user override the fileformat.\n     */\n    if (reload)\n\t{\n\t    /* We're reloading so use the attribute list in memory */\n\t    attr_list =  gerbvProject->file[idx]->image->info->attr_list;\n\t    n_attr =  gerbvProject->file[idx]->image->info->n_attr;\n\t}\n    else\n\t{\n\t    /* We're not reloading so use the attribute list read from the \n\t     * project file if given or NULL otherwise.\n\t     */\n\t    attr_list = fattr;\n\t    n_attr = n_fattr;\n\t}\n    /* if we don't have enough spots, then grow the file list by 2 to account for the possible \n       loading of two images for PNP files */\n    if ((idx+1) >= gerbvProject->max_files) {\n\tgerbvProject->file = g_renew (gerbv_fileinfo_t *,\n\t\t\tgerbvProject->file, gerbvProject->max_files + 2);\n\n\tgerbvProject->file[gerbvProject->max_files] = NULL;\n\tgerbvProject->file[gerbvProject->max_files+1] = NULL;\n\tgerbvProject->max_files += 2;\n    }\n    \n    dprintf(\"In open_image, about to try opening filename = %s\\n\", filename);\n    \n    fd = gerb_fopen(filename);\n    if (fd == NULL) {\n\tGERB_COMPILE_ERROR(_(\"Trying to open \\\"%s\\\": %s\"),\n\t\t\tfilename, strerror(errno));\n\treturn -1;\n    }\n\n    /* Store filename info fd for further use */\n    fd->filename = g_strdup(filename);\n    \n    dprintf(\"In open_image, successfully opened file.  Now check its type....\\n\");\n    /* Here's where we decide what file type we have */\n    /* Note: if the file has some invalid characters in it but still appears to\n       be a valid file, we check with the user if he wants to continue (only\n       if user opens the layer from the menu...if from the command line, we go\n       ahead and try to load it anyways) */\n\n    if (gerber_is_rs274x_p(fd, &foundBinary)) {\n\tdprintf(\"Found RS-274X file\\n\");\n\tif (!foundBinary || forceLoadFile) {\n\t\t/* figure out the directory path in case parse_gerb needs to\n\t\t * load any include files */\n\t\tgchar *currentLoadDirectory = g_path_get_dirname (filename);\n\t\tparsed_image = parse_gerb(fd, currentLoadDirectory);\n\t\tg_free (currentLoadDirectory);\n\t}\n    } else if(drill_file_p(fd, &foundBinary)) {\n\tdprintf(\"Found drill file\\n\");\n\tif (!foundBinary || forceLoadFile)\n\t    parsed_image = parse_drillfile(fd, attr_list, n_attr, reload);\n\t\n    } else if (pick_and_place_check_file_type(fd, &foundBinary)) {\n\tdprintf(\"Found pick-n-place file\\n\");\n\tif (!foundBinary || forceLoadFile) {\n\t\tif (!reload) {\n\t\t\tpick_and_place_parse_file_to_images(fd, &parsed_image, &parsed_image2);\n\t\t} else {\n\t\t\tswitch (gerbvProject->file[idx]->image->layertype) {\n\t\t\tcase GERBV_LAYERTYPE_PICKANDPLACE_TOP:\n\t\t\t\t/* Non NULL pointer is used as \"not to reload\" mark */\n\t\t\t\tparsed_image2 = (void *)!NULL;\n\t\t\t\tpick_and_place_parse_file_to_images(fd, &parsed_image, &parsed_image2);\n\t\t\t\tparsed_image2 = NULL;\n\t\t\t\tbreak;\n\t\t\tcase GERBV_LAYERTYPE_PICKANDPLACE_BOT:\n\t\t\t\t/* Non NULL pointer is used as \"not to reload\" mark */\n\t\t\t\tparsed_image2 = (void *)!NULL;\n\t\t\t\tpick_and_place_parse_file_to_images(fd, &parsed_image2, &parsed_image);\n\t\t\t\tparsed_image2 = NULL;\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tGERB_COMPILE_ERROR(_(\"%s: unknown pick-and-place board side to reload\"), filename);\n\t\t\t}\n\t\t}\n\t\t\t\n\t\tisPnpFile = TRUE;\n\t}\n    } else if (gerber_is_rs274d_p(fd)) {\n\tgchar *str = g_strdup_printf(_(\"Most likely found a RS-274D file \"\n\t\t\t\"\\\"%s\\\" ... trying to open anyways\\n\"), filename);\n\tdprintf(\"%s\", str);\n\tg_warning(\"%s\", str);\n\tg_free (str);\n\n\tif (!foundBinary || forceLoadFile) {\n\t\t/* figure out the directory path in case parse_gerb needs to\n\t\t * load any include files */\n\t\tgchar *currentLoadDirectory = g_path_get_dirname (filename);\n\t\tparsed_image = parse_gerb(fd, currentLoadDirectory);\n\t\tg_free (currentLoadDirectory);\n\t}\n    } else {\n\t/* This is not a known file */\n\tdprintf(\"Unknown filetype\");\n\tGERB_COMPILE_ERROR(_(\"%s: Unknown file type.\"), filename);\n\tparsed_image = NULL;\n    }\n    \n    g_free(fd->filename);\n    gerb_fclose(fd);\n    if (parsed_image == NULL) {\n\treturn -1;\n    }\n    \n    if (parsed_image) {\n\t/* strip the filename to the base */\n\tgchar *baseName = g_path_get_basename (filename);\n\tgchar *displayedName;\n\tif (isPnpFile)\n\t\tdisplayedName = g_strconcat (baseName, _(\" (top)\"), NULL);\n\telse\n\t\tdisplayedName = g_strdup (baseName);\n    \tretv = gerbv_add_parsed_image_to_project (gerbvProject, parsed_image, filename, displayedName, idx, reload);\n    \tg_free (baseName);\n    \tg_free (displayedName);\n    }\n\n    /* Set layer_dirty flag to FALSE */\n    gerbvProject->file[idx]->layer_dirty = FALSE;\n\n    /* for PNP place files, we may need to add a second image for the other\n       board side */\n    if (parsed_image2) {\n      /* strip the filename to the base */\n\tgchar *baseName = g_path_get_basename (filename);\n\tgchar *displayedName;\n\tdisplayedName = g_strconcat (baseName, _(\" (bottom)\"), NULL);\n    \tretv = gerbv_add_parsed_image_to_project (gerbvProject, parsed_image2, filename, displayedName, idx + 1, reload);\n    \tg_free (baseName);\n    \tg_free (displayedName);\n    }\n\n    return retv;\n}",
        "func": "int\ngerbv_open_image(gerbv_project_t *gerbvProject, gchar const* filename, int idx, int reload,\n\t\tgerbv_HID_Attribute *fattr, int n_fattr, gboolean forceLoadFile)\n{\n    gerb_file_t *fd;\n    gerbv_image_t *parsed_image = NULL, *parsed_image2 = NULL;\n    gint retv = -1;\n    gboolean isPnpFile = FALSE, foundBinary;\n    gerbv_HID_Attribute *attr_list = NULL;\n    int n_attr = 0;\n    /* If we're reloading, we'll pass in our file format attribute list\n     * since this is our hook for letting the user override the fileformat.\n     */\n    if (reload)\n\t{\n\t    /* We're reloading so use the attribute list in memory */\n\t    attr_list =  gerbvProject->file[idx]->image->info->attr_list;\n\t    n_attr =  gerbvProject->file[idx]->image->info->n_attr;\n\t}\n    else\n\t{\n\t    /* We're not reloading so use the attribute list read from the \n\t     * project file if given or NULL otherwise.\n\t     */\n\t    attr_list = fattr;\n\t    n_attr = n_fattr;\n\t}\n    /* if we don't have enough spots, then grow the file list by 2 to account for the possible \n       loading of two images for PNP files */\n    if ((idx+1) >= gerbvProject->max_files) {\n\tgerbvProject->file = g_renew (gerbv_fileinfo_t *,\n\t\t\tgerbvProject->file, gerbvProject->max_files + 2);\n\n\tgerbvProject->file[gerbvProject->max_files] = NULL;\n\tgerbvProject->file[gerbvProject->max_files+1] = NULL;\n\tgerbvProject->max_files += 2;\n    }\n    \n    dprintf(\"In open_image, about to try opening filename = %s\\n\", filename);\n    \n    fd = gerb_fopen(filename);\n    if (fd == NULL) {\n\tGERB_COMPILE_ERROR(_(\"Trying to open \\\"%s\\\": %s\"),\n\t\t\tfilename, strerror(errno));\n\treturn -1;\n    }\n\n    dprintf(\"In open_image, successfully opened file.  Now check its type....\\n\");\n    /* Here's where we decide what file type we have */\n    /* Note: if the file has some invalid characters in it but still appears to\n       be a valid file, we check with the user if he wants to continue (only\n       if user opens the layer from the menu...if from the command line, we go\n       ahead and try to load it anyways) */\n\n    if (gerber_is_rs274x_p(fd, &foundBinary)) {\n\tdprintf(\"Found RS-274X file\\n\");\n\tif (!foundBinary || forceLoadFile) {\n\t\t/* figure out the directory path in case parse_gerb needs to\n\t\t * load any include files */\n\t\tgchar *currentLoadDirectory = g_path_get_dirname (filename);\n\t\tparsed_image = parse_gerb(fd, currentLoadDirectory);\n\t\tg_free (currentLoadDirectory);\n\t}\n    } else if(drill_file_p(fd, &foundBinary)) {\n\tdprintf(\"Found drill file\\n\");\n\tif (!foundBinary || forceLoadFile)\n\t    parsed_image = parse_drillfile(fd, attr_list, n_attr, reload);\n\t\n    } else if (pick_and_place_check_file_type(fd, &foundBinary)) {\n\tdprintf(\"Found pick-n-place file\\n\");\n\tif (!foundBinary || forceLoadFile) {\n\t\tif (!reload) {\n\t\t\tpick_and_place_parse_file_to_images(fd, &parsed_image, &parsed_image2);\n\t\t} else {\n\t\t\tswitch (gerbvProject->file[idx]->image->layertype) {\n\t\t\tcase GERBV_LAYERTYPE_PICKANDPLACE_TOP:\n\t\t\t\t/* Non NULL pointer is used as \"not to reload\" mark */\n\t\t\t\tparsed_image2 = (void *)!NULL;\n\t\t\t\tpick_and_place_parse_file_to_images(fd, &parsed_image, &parsed_image2);\n\t\t\t\tparsed_image2 = NULL;\n\t\t\t\tbreak;\n\t\t\tcase GERBV_LAYERTYPE_PICKANDPLACE_BOT:\n\t\t\t\t/* Non NULL pointer is used as \"not to reload\" mark */\n\t\t\t\tparsed_image2 = (void *)!NULL;\n\t\t\t\tpick_and_place_parse_file_to_images(fd, &parsed_image2, &parsed_image);\n\t\t\t\tparsed_image2 = NULL;\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tGERB_COMPILE_ERROR(_(\"%s: unknown pick-and-place board side to reload\"), filename);\n\t\t\t}\n\t\t}\n\t\t\t\n\t\tisPnpFile = TRUE;\n\t}\n    } else if (gerber_is_rs274d_p(fd)) {\n\tgchar *str = g_strdup_printf(_(\"Most likely found a RS-274D file \"\n\t\t\t\"\\\"%s\\\" ... trying to open anyways\\n\"), filename);\n\tdprintf(\"%s\", str);\n\tg_warning(\"%s\", str);\n\tg_free (str);\n\n\tif (!foundBinary || forceLoadFile) {\n\t\t/* figure out the directory path in case parse_gerb needs to\n\t\t * load any include files */\n\t\tgchar *currentLoadDirectory = g_path_get_dirname (filename);\n\t\tparsed_image = parse_gerb(fd, currentLoadDirectory);\n\t\tg_free (currentLoadDirectory);\n\t}\n    } else {\n\t/* This is not a known file */\n\tdprintf(\"Unknown filetype\");\n\tGERB_COMPILE_ERROR(_(\"%s: Unknown file type.\"), filename);\n\tparsed_image = NULL;\n    }\n    \n    gerb_fclose(fd);\n    if (parsed_image == NULL) {\n\treturn -1;\n    }\n    \n    if (parsed_image) {\n\t/* strip the filename to the base */\n\tgchar *baseName = g_path_get_basename (filename);\n\tgchar *displayedName;\n\tif (isPnpFile)\n\t\tdisplayedName = g_strconcat (baseName, _(\" (top)\"), NULL);\n\telse\n\t\tdisplayedName = g_strdup (baseName);\n    \tretv = gerbv_add_parsed_image_to_project (gerbvProject, parsed_image, filename, displayedName, idx, reload);\n    \tg_free (baseName);\n    \tg_free (displayedName);\n    }\n\n    /* Set layer_dirty flag to FALSE */\n    gerbvProject->file[idx]->layer_dirty = FALSE;\n\n    /* for PNP place files, we may need to add a second image for the other\n       board side */\n    if (parsed_image2) {\n      /* strip the filename to the base */\n\tgchar *baseName = g_path_get_basename (filename);\n\tgchar *displayedName;\n\tdisplayedName = g_strconcat (baseName, _(\" (bottom)\"), NULL);\n    \tretv = gerbv_add_parsed_image_to_project (gerbvProject, parsed_image2, filename, displayedName, idx + 1, reload);\n    \tg_free (baseName);\n    \tg_free (displayedName);\n    }\n\n    return retv;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -45,9 +45,6 @@\n \treturn -1;\n     }\n \n-    /* Store filename info fd for further use */\n-    fd->filename = g_strdup(filename);\n-    \n     dprintf(\"In open_image, successfully opened file.  Now check its type....\\n\");\n     /* Here's where we decide what file type we have */\n     /* Note: if the file has some invalid characters in it but still appears to\n@@ -116,7 +113,6 @@\n \tparsed_image = NULL;\n     }\n     \n-    g_free(fd->filename);\n     gerb_fclose(fd);\n     if (parsed_image == NULL) {\n \treturn -1;",
        "diff_line_info": {
            "deleted_lines": [
                "    /* Store filename info fd for further use */",
                "    fd->filename = g_strdup(filename);",
                "    ",
                "    g_free(fd->filename);"
            ],
            "added_lines": []
        }
    },
    {
        "cve_id": "CVE-2018-11743",
        "func_name": "mruby/init_copy",
        "description": "The init_copy function in kernel.c in mruby 1.4.1 makes initialize_copy calls for TT_ICLASS objects, which allows attackers to cause a denial of service (mrb_hash_keys uninitialized pointer and application crash) or possibly have unspecified other impact.",
        "git_url": "https://github.com/mruby/mruby/commit/b64ce17852b180dfeea81cf458660be41a78974d",
        "commit_title": "Should not call `initialize_copy` for `TT_ICLASS`; fix #4027",
        "commit_text": " Since `TT_ICLASS` is a internal object that should never be revealed to Ruby world.",
        "func_before": "static void\ninit_copy(mrb_state *mrb, mrb_value dest, mrb_value obj)\n{\n  switch (mrb_type(obj)) {\n    case MRB_TT_CLASS:\n    case MRB_TT_MODULE:\n      copy_class(mrb, dest, obj);\n      mrb_iv_copy(mrb, dest, obj);\n      mrb_iv_remove(mrb, dest, mrb_intern_lit(mrb, \"__classname__\"));\n      break;\n    case MRB_TT_OBJECT:\n    case MRB_TT_SCLASS:\n    case MRB_TT_HASH:\n    case MRB_TT_DATA:\n    case MRB_TT_EXCEPTION:\n      mrb_iv_copy(mrb, dest, obj);\n      break;\n    case MRB_TT_ISTRUCT:\n      mrb_istruct_copy(dest, obj);\n      break;\n\n    default:\n      break;\n  }\n  mrb_funcall(mrb, dest, \"initialize_copy\", 1, obj);\n}",
        "func": "static void\ninit_copy(mrb_state *mrb, mrb_value dest, mrb_value obj)\n{\n  switch (mrb_type(obj)) {\n    case MRB_TT_ICLASS:\n      copy_class(mrb, dest, obj);\n      return;\n    case MRB_TT_CLASS:\n    case MRB_TT_MODULE:\n      copy_class(mrb, dest, obj);\n      mrb_iv_copy(mrb, dest, obj);\n      mrb_iv_remove(mrb, dest, mrb_intern_lit(mrb, \"__classname__\"));\n      break;\n    case MRB_TT_OBJECT:\n    case MRB_TT_SCLASS:\n    case MRB_TT_HASH:\n    case MRB_TT_DATA:\n    case MRB_TT_EXCEPTION:\n      mrb_iv_copy(mrb, dest, obj);\n      break;\n    case MRB_TT_ISTRUCT:\n      mrb_istruct_copy(dest, obj);\n      break;\n\n    default:\n      break;\n  }\n  mrb_funcall(mrb, dest, \"initialize_copy\", 1, obj);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,6 +2,9 @@\n init_copy(mrb_state *mrb, mrb_value dest, mrb_value obj)\n {\n   switch (mrb_type(obj)) {\n+    case MRB_TT_ICLASS:\n+      copy_class(mrb, dest, obj);\n+      return;\n     case MRB_TT_CLASS:\n     case MRB_TT_MODULE:\n       copy_class(mrb, dest, obj);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    case MRB_TT_ICLASS:",
                "      copy_class(mrb, dest, obj);",
                "      return;"
            ]
        }
    }
]