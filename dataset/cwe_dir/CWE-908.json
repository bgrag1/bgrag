[
    {
        "cve_id": "CVE-2021-40608",
        "func_name": "gpac/gf_isom_text_get_encoded_tx3g",
        "description": "The gf_hinter_track_finalize function in GPAC 1.0.1 allows attackers to cause a denial of service via a crafted file in the MP4Box command.",
        "git_url": "https://github.com/gpac/gpac/commit/b09c75dc2d4bf68ac447daa71e72365aa30231a9",
        "commit_title": "fixed #1883",
        "commit_text": "",
        "func_before": "GF_Err gf_isom_text_get_encoded_tx3g(GF_ISOFile *file, u32 track, u32 sidx, u32 sidx_offset, u8 **tx3g, u32 *tx3g_size)\n{\n\tGF_BitStream *bs;\n\tGF_TrackBox *trak;\n\tGF_Tx3gSampleEntryBox *a;\n\n\ttrak = gf_isom_get_track_from_file(file, track);\n\tif (!trak) return GF_BAD_PARAM;\n\n\ta = (GF_Tx3gSampleEntryBox *) gf_list_get(trak->Media->information->sampleTable->SampleDescription->child_boxes, sidx-1);\n\tif (!a) return GF_BAD_PARAM;\n\tif ((a->type != GF_ISOM_BOX_TYPE_TX3G) && (a->type != GF_ISOM_BOX_TYPE_TEXT)) return GF_BAD_PARAM;\n\n\tbs = gf_bs_new(NULL, 0, GF_BITSTREAM_WRITE);\n\tgf_isom_write_tx3g(a, bs, sidx, sidx_offset);\n\t*tx3g = NULL;\n\t*tx3g_size = 0;\n\tgf_bs_get_content(bs, tx3g, tx3g_size);\n\tgf_bs_del(bs);\n\treturn GF_OK;\n}",
        "func": "GF_Err gf_isom_text_get_encoded_tx3g(GF_ISOFile *file, u32 track, u32 sidx, u32 sidx_offset, u8 **tx3g, u32 *tx3g_size)\n{\n\tGF_BitStream *bs;\n\tGF_TrackBox *trak;\n\tGF_Tx3gSampleEntryBox *a;\n\n\t*tx3g = NULL;\n\t*tx3g_size = 0;\n\ttrak = gf_isom_get_track_from_file(file, track);\n\tif (!trak) return GF_BAD_PARAM;\n\n\ta = (GF_Tx3gSampleEntryBox *) gf_list_get(trak->Media->information->sampleTable->SampleDescription->child_boxes, sidx-1);\n\tif (!a) return GF_BAD_PARAM;\n\tif ((a->type != GF_ISOM_BOX_TYPE_TX3G) && (a->type != GF_ISOM_BOX_TYPE_TEXT)) return GF_BAD_PARAM;\n\n\tbs = gf_bs_new(NULL, 0, GF_BITSTREAM_WRITE);\n\tgf_isom_write_tx3g(a, bs, sidx, sidx_offset);\n\tgf_bs_get_content(bs, tx3g, tx3g_size);\n\tgf_bs_del(bs);\n\treturn GF_OK;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,6 +4,8 @@\n \tGF_TrackBox *trak;\n \tGF_Tx3gSampleEntryBox *a;\n \n+\t*tx3g = NULL;\n+\t*tx3g_size = 0;\n \ttrak = gf_isom_get_track_from_file(file, track);\n \tif (!trak) return GF_BAD_PARAM;\n \n@@ -13,8 +15,6 @@\n \n \tbs = gf_bs_new(NULL, 0, GF_BITSTREAM_WRITE);\n \tgf_isom_write_tx3g(a, bs, sidx, sidx_offset);\n-\t*tx3g = NULL;\n-\t*tx3g_size = 0;\n \tgf_bs_get_content(bs, tx3g, tx3g_size);\n \tgf_bs_del(bs);\n \treturn GF_OK;",
        "diff_line_info": {
            "deleted_lines": [
                "\t*tx3g = NULL;",
                "\t*tx3g_size = 0;"
            ],
            "added_lines": [
                "\t*tx3g = NULL;",
                "\t*tx3g_size = 0;"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-40608",
        "func_name": "gpac/gf_hinter_track_finalize",
        "description": "The gf_hinter_track_finalize function in GPAC 1.0.1 allows attackers to cause a denial of service via a crafted file in the MP4Box command.",
        "git_url": "https://github.com/gpac/gpac/commit/b09c75dc2d4bf68ac447daa71e72365aa30231a9",
        "commit_title": "fixed #1883",
        "commit_text": "",
        "func_before": "GF_EXPORT\nGF_Err gf_hinter_track_finalize(GF_RTPHinter *tkHint, Bool AddSystemInfo)\n{\n\tu32 Width, Height;\n\tGF_ESD *esd;\n\tchar sdpLine[20000];\n\tchar mediaName[30], payloadName[30];\n    u32 mtype;\n\n\tWidth = Height = 0;\n\tgf_isom_sdp_clean_track(tkHint->file, tkHint->TrackNum);\n    mtype = gf_isom_get_media_type(tkHint->file, tkHint->TrackNum);\n    if (gf_isom_is_video_handler_type(mtype))\n\t\tgf_isom_get_visual_info(tkHint->file, tkHint->TrackNum, 1, &Width, &Height);\n\n\tgf_rtp_builder_get_payload_name(tkHint->rtp_p, payloadName, mediaName);\n\n\t/*TODO- extract out of rtp_p for future live tools*/\n\tsprintf(sdpLine, \"m=%s 0 RTP/%s %d\", mediaName, tkHint->rtp_p->slMap.IV_length ? \"SAVP\" : \"AVP\", tkHint->rtp_p->PayloadType);\n\tgf_isom_sdp_add_track_line(tkHint->file, tkHint->HintTrack, sdpLine);\n\tif (tkHint->bandwidth) {\n\t\tsprintf(sdpLine, \"b=AS:%d\", tkHint->bandwidth);\n\t\tgf_isom_sdp_add_track_line(tkHint->file, tkHint->HintTrack, sdpLine);\n\t}\n\tif (tkHint->nb_chan) {\n\t\tsprintf(sdpLine, \"a=rtpmap:%d %s/%d/%d\", tkHint->rtp_p->PayloadType, payloadName, tkHint->rtp_p->sl_config.timestampResolution, tkHint->nb_chan);\n\t} else {\n\t\tsprintf(sdpLine, \"a=rtpmap:%d %s/%d\", tkHint->rtp_p->PayloadType, payloadName, tkHint->rtp_p->sl_config.timestampResolution);\n\t}\n\tgf_isom_sdp_add_track_line(tkHint->file, tkHint->HintTrack, sdpLine);\n\t/*control for MPEG-4*/\n\tif (AddSystemInfo) {\n\t\tsprintf(sdpLine, \"a=mpeg4-esid:%d\", gf_isom_get_track_id(tkHint->file, tkHint->TrackNum));\n\t\tgf_isom_sdp_add_track_line(tkHint->file, tkHint->HintTrack, sdpLine);\n\t}\n\t/*control for QTSS/DSS*/\n\tsprintf(sdpLine, \"a=control:trackID=%d\", gf_isom_get_track_id(tkHint->file, tkHint->HintTrack));\n\tgf_isom_sdp_add_track_line(tkHint->file, tkHint->HintTrack, sdpLine);\n\n\t/*H263 extensions*/\n\tif (tkHint->rtp_p->rtp_payt == GF_RTP_PAYT_H263) {\n\t\tsprintf(sdpLine, \"a=cliprect:0,0,%d,%d\", Height, Width);\n\t\tgf_isom_sdp_add_track_line(tkHint->file, tkHint->HintTrack, sdpLine);\n\t}\n\t/*AMR*/\n\telse if ((tkHint->rtp_p->rtp_payt == GF_RTP_PAYT_AMR) || (tkHint->rtp_p->rtp_payt == GF_RTP_PAYT_AMR_WB)) {\n\t\tsprintf(sdpLine, \"a=fmtp:%d octet-align=1\", tkHint->rtp_p->PayloadType);\n\t\tgf_isom_sdp_add_track_line(tkHint->file, tkHint->HintTrack, sdpLine);\n\t}\n\t/*Text*/\n\telse if (tkHint->rtp_p->rtp_payt == GF_RTP_PAYT_3GPP_TEXT) {\n\t\tu32 w, h, i, m_w, m_h;\n\t\ts32 tx, ty;\n\t\ts16 l;\n\n\t\tgf_isom_get_track_layout_info(tkHint->file, tkHint->TrackNum, &w, &h, &tx, &ty, &l);\n\t\tm_w = w;\n\t\tm_h = h;\n\t\tfor (i=0; i<gf_isom_get_track_count(tkHint->file); i++) {\n\t\t\tswitch (gf_isom_get_media_type(tkHint->file, i+1)) {\n\t\t\tcase GF_ISOM_MEDIA_SCENE:\n\t\t\tcase GF_ISOM_MEDIA_VISUAL:\n\t\t\tcase GF_ISOM_MEDIA_AUXV:\n\t\t\tcase GF_ISOM_MEDIA_PICT:\n\t\t\t\tgf_isom_get_track_layout_info(tkHint->file, i+1, &w, &h, &tx, &ty, &l);\n\t\t\t\tif (w>m_w) m_w = w;\n\t\t\t\tif (h>m_h) m_h = h;\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tgf_media_format_ttxt_sdp(tkHint->rtp_p, payloadName, sdpLine, w, h, tx, ty, l, m_w, m_h, NULL);\n\n\t\tstrcat(sdpLine, \"; tx3g=\");\n\t\tfor (i=0; i<gf_isom_get_sample_description_count(tkHint->file, tkHint->TrackNum); i++) {\n\t\t\tu8 *tx3g;\n\t\t\tchar buffer[2000];\n\t\t\tu32 tx3g_len, len;\n\t\t\tgf_isom_text_get_encoded_tx3g(tkHint->file, tkHint->TrackNum, i+1, GF_RTP_TX3G_SIDX_OFFSET, &tx3g, &tx3g_len);\n\t\t\tlen = gf_base64_encode(tx3g, tx3g_len, buffer, 2000);\n\t\t\tgf_free(tx3g);\n\t\t\tbuffer[len] = 0;\n\t\t\tif (i) strcat(sdpLine, \", \");\n\t\t\tstrcat(sdpLine, buffer);\n\t\t}\n\t\tgf_isom_sdp_add_track_line(tkHint->file, tkHint->HintTrack, sdpLine);\n\t}\n\t/*EVRC/SMV in non header-free mode*/\n\telse if ((tkHint->rtp_p->rtp_payt == GF_RTP_PAYT_EVRC_SMV) && (tkHint->rtp_p->auh_size>1)) {\n\t\tsprintf(sdpLine, \"a=fmtp:%d maxptime=%d\", tkHint->rtp_p->PayloadType, tkHint->rtp_p->auh_size*20);\n\t\tgf_isom_sdp_add_track_line(tkHint->file, tkHint->HintTrack, sdpLine);\n\t}\n\t/*H264/AVC*/\n\telse if ((tkHint->rtp_p->rtp_payt == GF_RTP_PAYT_H264_AVC) || (tkHint->rtp_p->rtp_payt == GF_RTP_PAYT_H264_SVC))  {\n\t\tGF_AVCConfig *avcc = gf_isom_avc_config_get(tkHint->file, tkHint->TrackNum, 1);\n\t\tGF_AVCConfig *svcc = gf_isom_svc_config_get(tkHint->file, tkHint->TrackNum, 1);\n\t\t/*TODO - check syntax for SVC (might be some extra signaling)*/\n\n\t\tif (avcc) {\n\t\t\tsprintf(sdpLine, \"a=fmtp:%d profile-level-id=%02X%02X%02X; packetization-mode=1\", tkHint->rtp_p->PayloadType, avcc->AVCProfileIndication, avcc->profile_compatibility, avcc->AVCLevelIndication);\n\t\t} else {\n\t\t\tif (!svcc)\n\t\t\t\treturn GF_ISOM_INVALID_FILE;\n\t\t\tsprintf(sdpLine, \"a=fmtp:%d profile-level-id=%02X%02X%02X; packetization-mode=1\", tkHint->rtp_p->PayloadType, svcc->AVCProfileIndication, svcc->profile_compatibility, svcc->AVCLevelIndication);\n\t\t}\n\n\t\twrite_avc_config(sdpLine, avcc, svcc);\n\n\t\tgf_isom_sdp_add_track_line(tkHint->file, tkHint->HintTrack, sdpLine);\n\t\tgf_odf_avc_cfg_del(avcc);\n\t\tgf_odf_avc_cfg_del(svcc);\n\t}\n\t/*MPEG-4 decoder config*/\n\telse if (tkHint->rtp_p->rtp_payt==GF_RTP_PAYT_MPEG4) {\n\t\tesd = gf_isom_get_esd(tkHint->file, tkHint->TrackNum, 1);\n\n\t\tif (esd && esd->decoderConfig && esd->decoderConfig->decoderSpecificInfo && esd->decoderConfig->decoderSpecificInfo->data) {\n\t\t\tgf_rtp_builder_format_sdp(tkHint->rtp_p, payloadName, sdpLine, esd->decoderConfig->decoderSpecificInfo->data, esd->decoderConfig->decoderSpecificInfo->dataLength);\n\t\t} else {\n\t\t\tgf_rtp_builder_format_sdp(tkHint->rtp_p, payloadName, sdpLine, NULL, 0);\n\t\t}\n\t\tif (esd) gf_odf_desc_del((GF_Descriptor *)esd);\n\n\t\tif (tkHint->rtp_p->slMap.IV_length) {\n\t\t\tconst char *kms;\n\t\t\tgf_isom_get_ismacryp_info(tkHint->file, tkHint->TrackNum, 1, NULL, NULL, NULL, NULL, &kms, NULL, NULL, NULL);\n\t\t\tif (!strnicmp(kms, \"(key)\", 5) || !strnicmp(kms, \"(ipmp)\", 6) || !strnicmp(kms, \"(uri)\", 5)) {\n\t\t\t\tstrcat(sdpLine, \"; ISMACrypKey=\");\n\t\t\t} else {\n\t\t\t\tstrcat(sdpLine, \"; ISMACrypKey=(uri)\");\n\t\t\t}\n\t\t\tstrcat(sdpLine, kms);\n\t\t}\n\n\t\tgf_isom_sdp_add_track_line(tkHint->file, tkHint->HintTrack, sdpLine);\n\t}\n\t/*MPEG-4 Audio LATM*/\n\telse if (tkHint->rtp_p->rtp_payt==GF_RTP_PAYT_LATM) {\n\t\tGF_BitStream *bs;\n\t\tu8 *config_bytes;\n\t\tu32 config_size;\n\n\t\t/* form config string */\n\t\tbs = gf_bs_new(NULL, 32, GF_BITSTREAM_WRITE);\n\t\tgf_bs_write_int(bs, 0, 1); /* AudioMuxVersion */\n\t\tgf_bs_write_int(bs, 1, 1); /* all streams same time */\n\t\tgf_bs_write_int(bs, 0, 6); /* numSubFrames */\n\t\tgf_bs_write_int(bs, 0, 4); /* numPrograms */\n\t\tgf_bs_write_int(bs, 0, 3); /* numLayer */\n\n\t\t/* audio-specific config */\n\t\tesd = gf_isom_get_esd(tkHint->file, tkHint->TrackNum, 1);\n\t\tif (esd && esd->decoderConfig && esd->decoderConfig->decoderSpecificInfo) {\n\t\t\t/*PacketVideo patch: don't signal SBR and PS stuff, not allowed in LATM with audioMuxVersion=0*/\n\t\t\tgf_bs_write_data(bs, esd->decoderConfig->decoderSpecificInfo->data, MIN(esd->decoderConfig->decoderSpecificInfo->dataLength, 2) );\n\t\t}\n\t\tif (esd) gf_odf_desc_del((GF_Descriptor *)esd);\n\n\t\t/* other data */\n\t\tgf_bs_write_int(bs, 0, 3); /* frameLengthType */\n\t\tgf_bs_write_int(bs, 0xff, 8); /* latmBufferFullness */\n\t\tgf_bs_write_int(bs, 0, 1); /* otherDataPresent */\n\t\tgf_bs_write_int(bs, 0, 1); /* crcCheckPresent */\n\t\tgf_bs_get_content(bs, &config_bytes, &config_size);\n\t\tgf_bs_del(bs);\n\n\t\tgf_rtp_builder_format_sdp(tkHint->rtp_p, payloadName, sdpLine, config_bytes, config_size);\n\t\tgf_isom_sdp_add_track_line(tkHint->file, tkHint->HintTrack, sdpLine);\n\t\tgf_free(config_bytes);\n\t}\n#if GPAC_ENABLE_3GPP_DIMS_RTP\n\t/*3GPP DIMS*/\n\telse if (tkHint->rtp_p->rtp_payt==GF_RTP_PAYT_3GPP_DIMS) {\n\t\tGF_DIMSDescription dims;\n\t\tgf_isom_get_visual_info(tkHint->file, tkHint->TrackNum, 1, &Width, &Height);\n\n\t\tgf_isom_get_dims_description(tkHint->file, tkHint->TrackNum, 1, &dims);\n\t\tsprintf(sdpLine, \"a=fmtp:%d Version-profile=%d\", tkHint->rtp_p->PayloadType, dims.profile);\n\t\tif (! dims.fullRequestHost) {\n\t\t\tchar fmt[200];\n\t\t\tstrcat(sdpLine, \";useFullRequestHost=0\");\n\t\t\tsprintf(fmt, \";pathComponents=%d\", dims.pathComponents);\n\t\t\tstrcat(sdpLine, fmt);\n\t\t}\n\t\tif (!dims.streamType) strcat(sdpLine, \";stream-type=secondary\");\n\t\tif (dims.containsRedundant == 1) strcat(sdpLine, \";contains-redundant=main\");\n\t\telse if (dims.containsRedundant == 2) strcat(sdpLine, \";contains-redundant=redundant\");\n\n\t\tif (dims.textEncoding && strlen(dims.textEncoding)) {\n\t\t\tstrcat(sdpLine, \";text-encoding=\");\n\t\t\tstrcat(sdpLine, dims.textEncoding);\n\t\t}\n\t\tif (dims.contentEncoding && strlen(dims.contentEncoding)) {\n\t\t\tstrcat(sdpLine, \";content-coding=\");\n\t\t\tstrcat(sdpLine, dims.contentEncoding);\n\t\t}\n\t\tif (dims.contentEncoding && dims.content_script_types && strlen(dims.content_script_types) ) {\n\t\t\tstrcat(sdpLine, \";content-script-types=\");\n\t\t\tstrcat(sdpLine, dims.contentEncoding);\n\t\t}\n\t\tgf_isom_sdp_add_track_line(tkHint->file, tkHint->HintTrack, sdpLine);\n\t}\n#endif\n\t/*extensions for some mobile phones*/\n\tif (Width && Height) {\n\t\tsprintf(sdpLine, \"a=framesize:%d %d-%d\", tkHint->rtp_p->PayloadType, Width, Height);\n\t\tgf_isom_sdp_add_track_line(tkHint->file, tkHint->HintTrack, sdpLine);\n\t}\n\n\tesd = gf_isom_get_esd(tkHint->file, tkHint->TrackNum, 1);\n\tif (esd && esd->decoderConfig && (esd->decoderConfig->rvc_config || esd->decoderConfig->predefined_rvc_config)) {\n\t\tif (esd->decoderConfig->predefined_rvc_config) {\n\t\t\tsprintf(sdpLine, \"a=rvc-config-predef:%d\", esd->decoderConfig->predefined_rvc_config);\n\t\t} else {\n\t\t\t/*temporary ...*/\n\t\t\tif ((esd->decoderConfig->objectTypeIndication==GF_CODECID_AVC) || (esd->decoderConfig->objectTypeIndication==GF_CODECID_SVC)) {\n\t\t\t\tsprintf(sdpLine, \"a=rvc-config:%s\", \"http://download.tsi.telecom-paristech.fr/gpac/RVC/rvc_config_avc.xml\");\n\t\t\t} else {\n\t\t\t\tsprintf(sdpLine, \"a=rvc-config:%s\", \"http://download.tsi.telecom-paristech.fr/gpac/RVC/rvc_config_sp.xml\");\n\t\t\t}\n\t\t}\n\t\tgf_isom_sdp_add_track_line(tkHint->file, tkHint->HintTrack, sdpLine);\n\t}\n\tif (esd) gf_odf_desc_del((GF_Descriptor *)esd);\n\n\tgf_isom_set_track_enabled(tkHint->file, tkHint->HintTrack, GF_TRUE);\n\treturn GF_OK;\n}",
        "func": "GF_EXPORT\nGF_Err gf_hinter_track_finalize(GF_RTPHinter *tkHint, Bool AddSystemInfo)\n{\n\tu32 Width, Height;\n\tGF_ESD *esd;\n\tchar sdpLine[20000];\n\tchar mediaName[30], payloadName[30];\n    u32 mtype;\n\n\tWidth = Height = 0;\n\tgf_isom_sdp_clean_track(tkHint->file, tkHint->TrackNum);\n    mtype = gf_isom_get_media_type(tkHint->file, tkHint->TrackNum);\n    if (gf_isom_is_video_handler_type(mtype))\n\t\tgf_isom_get_visual_info(tkHint->file, tkHint->TrackNum, 1, &Width, &Height);\n\n\tgf_rtp_builder_get_payload_name(tkHint->rtp_p, payloadName, mediaName);\n\n\t/*TODO- extract out of rtp_p for future live tools*/\n\tsprintf(sdpLine, \"m=%s 0 RTP/%s %d\", mediaName, tkHint->rtp_p->slMap.IV_length ? \"SAVP\" : \"AVP\", tkHint->rtp_p->PayloadType);\n\tgf_isom_sdp_add_track_line(tkHint->file, tkHint->HintTrack, sdpLine);\n\tif (tkHint->bandwidth) {\n\t\tsprintf(sdpLine, \"b=AS:%d\", tkHint->bandwidth);\n\t\tgf_isom_sdp_add_track_line(tkHint->file, tkHint->HintTrack, sdpLine);\n\t}\n\tif (tkHint->nb_chan) {\n\t\tsprintf(sdpLine, \"a=rtpmap:%d %s/%d/%d\", tkHint->rtp_p->PayloadType, payloadName, tkHint->rtp_p->sl_config.timestampResolution, tkHint->nb_chan);\n\t} else {\n\t\tsprintf(sdpLine, \"a=rtpmap:%d %s/%d\", tkHint->rtp_p->PayloadType, payloadName, tkHint->rtp_p->sl_config.timestampResolution);\n\t}\n\tgf_isom_sdp_add_track_line(tkHint->file, tkHint->HintTrack, sdpLine);\n\t/*control for MPEG-4*/\n\tif (AddSystemInfo) {\n\t\tsprintf(sdpLine, \"a=mpeg4-esid:%d\", gf_isom_get_track_id(tkHint->file, tkHint->TrackNum));\n\t\tgf_isom_sdp_add_track_line(tkHint->file, tkHint->HintTrack, sdpLine);\n\t}\n\t/*control for QTSS/DSS*/\n\tsprintf(sdpLine, \"a=control:trackID=%d\", gf_isom_get_track_id(tkHint->file, tkHint->HintTrack));\n\tgf_isom_sdp_add_track_line(tkHint->file, tkHint->HintTrack, sdpLine);\n\n\t/*H263 extensions*/\n\tif (tkHint->rtp_p->rtp_payt == GF_RTP_PAYT_H263) {\n\t\tsprintf(sdpLine, \"a=cliprect:0,0,%d,%d\", Height, Width);\n\t\tgf_isom_sdp_add_track_line(tkHint->file, tkHint->HintTrack, sdpLine);\n\t}\n\t/*AMR*/\n\telse if ((tkHint->rtp_p->rtp_payt == GF_RTP_PAYT_AMR) || (tkHint->rtp_p->rtp_payt == GF_RTP_PAYT_AMR_WB)) {\n\t\tsprintf(sdpLine, \"a=fmtp:%d octet-align=1\", tkHint->rtp_p->PayloadType);\n\t\tgf_isom_sdp_add_track_line(tkHint->file, tkHint->HintTrack, sdpLine);\n\t}\n\t/*Text*/\n\telse if (tkHint->rtp_p->rtp_payt == GF_RTP_PAYT_3GPP_TEXT) {\n\t\tu32 w, h, i, m_w, m_h;\n\t\ts32 tx, ty;\n\t\ts16 l;\n\n\t\tgf_isom_get_track_layout_info(tkHint->file, tkHint->TrackNum, &w, &h, &tx, &ty, &l);\n\t\tm_w = w;\n\t\tm_h = h;\n\t\tfor (i=0; i<gf_isom_get_track_count(tkHint->file); i++) {\n\t\t\tswitch (gf_isom_get_media_type(tkHint->file, i+1)) {\n\t\t\tcase GF_ISOM_MEDIA_SCENE:\n\t\t\tcase GF_ISOM_MEDIA_VISUAL:\n\t\t\tcase GF_ISOM_MEDIA_AUXV:\n\t\t\tcase GF_ISOM_MEDIA_PICT:\n\t\t\t\tgf_isom_get_track_layout_info(tkHint->file, i+1, &w, &h, &tx, &ty, &l);\n\t\t\t\tif (w>m_w) m_w = w;\n\t\t\t\tif (h>m_h) m_h = h;\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tgf_media_format_ttxt_sdp(tkHint->rtp_p, payloadName, sdpLine, w, h, tx, ty, l, m_w, m_h, NULL);\n\n\t\tstrcat(sdpLine, \"; tx3g=\");\n\t\tfor (i=0; i<gf_isom_get_sample_description_count(tkHint->file, tkHint->TrackNum); i++) {\n\t\t\tu8 *tx3g;\n\t\t\tGF_Err e;\n\t\t\tchar buffer[2000];\n\t\t\tu32 tx3g_len, len;\n\t\t\te = gf_isom_text_get_encoded_tx3g(tkHint->file, tkHint->TrackNum, i+1, GF_RTP_TX3G_SIDX_OFFSET, &tx3g, &tx3g_len);\n\t\t\tif (e) {\n\t\t\t\tif (i) continue;\n\t\t\t\treturn GF_ISOM_INVALID_FILE;\n\t\t\t}\n\t\t\tlen = gf_base64_encode(tx3g, tx3g_len, buffer, 2000);\n\t\t\tgf_free(tx3g);\n\t\t\tbuffer[len] = 0;\n\t\t\tif (i) strcat(sdpLine, \", \");\n\t\t\tstrcat(sdpLine, buffer);\n\t\t}\n\t\tgf_isom_sdp_add_track_line(tkHint->file, tkHint->HintTrack, sdpLine);\n\t}\n\t/*EVRC/SMV in non header-free mode*/\n\telse if ((tkHint->rtp_p->rtp_payt == GF_RTP_PAYT_EVRC_SMV) && (tkHint->rtp_p->auh_size>1)) {\n\t\tsprintf(sdpLine, \"a=fmtp:%d maxptime=%d\", tkHint->rtp_p->PayloadType, tkHint->rtp_p->auh_size*20);\n\t\tgf_isom_sdp_add_track_line(tkHint->file, tkHint->HintTrack, sdpLine);\n\t}\n\t/*H264/AVC*/\n\telse if ((tkHint->rtp_p->rtp_payt == GF_RTP_PAYT_H264_AVC) || (tkHint->rtp_p->rtp_payt == GF_RTP_PAYT_H264_SVC))  {\n\t\tGF_AVCConfig *avcc = gf_isom_avc_config_get(tkHint->file, tkHint->TrackNum, 1);\n\t\tGF_AVCConfig *svcc = gf_isom_svc_config_get(tkHint->file, tkHint->TrackNum, 1);\n\t\t/*TODO - check syntax for SVC (might be some extra signaling)*/\n\n\t\tif (avcc) {\n\t\t\tsprintf(sdpLine, \"a=fmtp:%d profile-level-id=%02X%02X%02X; packetization-mode=1\", tkHint->rtp_p->PayloadType, avcc->AVCProfileIndication, avcc->profile_compatibility, avcc->AVCLevelIndication);\n\t\t} else {\n\t\t\tif (!svcc)\n\t\t\t\treturn GF_ISOM_INVALID_FILE;\n\t\t\tsprintf(sdpLine, \"a=fmtp:%d profile-level-id=%02X%02X%02X; packetization-mode=1\", tkHint->rtp_p->PayloadType, svcc->AVCProfileIndication, svcc->profile_compatibility, svcc->AVCLevelIndication);\n\t\t}\n\n\t\twrite_avc_config(sdpLine, avcc, svcc);\n\n\t\tgf_isom_sdp_add_track_line(tkHint->file, tkHint->HintTrack, sdpLine);\n\t\tgf_odf_avc_cfg_del(avcc);\n\t\tgf_odf_avc_cfg_del(svcc);\n\t}\n\t/*MPEG-4 decoder config*/\n\telse if (tkHint->rtp_p->rtp_payt==GF_RTP_PAYT_MPEG4) {\n\t\tesd = gf_isom_get_esd(tkHint->file, tkHint->TrackNum, 1);\n\n\t\tif (esd && esd->decoderConfig && esd->decoderConfig->decoderSpecificInfo && esd->decoderConfig->decoderSpecificInfo->data) {\n\t\t\tgf_rtp_builder_format_sdp(tkHint->rtp_p, payloadName, sdpLine, esd->decoderConfig->decoderSpecificInfo->data, esd->decoderConfig->decoderSpecificInfo->dataLength);\n\t\t} else {\n\t\t\tgf_rtp_builder_format_sdp(tkHint->rtp_p, payloadName, sdpLine, NULL, 0);\n\t\t}\n\t\tif (esd) gf_odf_desc_del((GF_Descriptor *)esd);\n\n\t\tif (tkHint->rtp_p->slMap.IV_length) {\n\t\t\tconst char *kms;\n\t\t\tgf_isom_get_ismacryp_info(tkHint->file, tkHint->TrackNum, 1, NULL, NULL, NULL, NULL, &kms, NULL, NULL, NULL);\n\t\t\tif (!strnicmp(kms, \"(key)\", 5) || !strnicmp(kms, \"(ipmp)\", 6) || !strnicmp(kms, \"(uri)\", 5)) {\n\t\t\t\tstrcat(sdpLine, \"; ISMACrypKey=\");\n\t\t\t} else {\n\t\t\t\tstrcat(sdpLine, \"; ISMACrypKey=(uri)\");\n\t\t\t}\n\t\t\tstrcat(sdpLine, kms);\n\t\t}\n\n\t\tgf_isom_sdp_add_track_line(tkHint->file, tkHint->HintTrack, sdpLine);\n\t}\n\t/*MPEG-4 Audio LATM*/\n\telse if (tkHint->rtp_p->rtp_payt==GF_RTP_PAYT_LATM) {\n\t\tGF_BitStream *bs;\n\t\tu8 *config_bytes;\n\t\tu32 config_size;\n\n\t\t/* form config string */\n\t\tbs = gf_bs_new(NULL, 32, GF_BITSTREAM_WRITE);\n\t\tgf_bs_write_int(bs, 0, 1); /* AudioMuxVersion */\n\t\tgf_bs_write_int(bs, 1, 1); /* all streams same time */\n\t\tgf_bs_write_int(bs, 0, 6); /* numSubFrames */\n\t\tgf_bs_write_int(bs, 0, 4); /* numPrograms */\n\t\tgf_bs_write_int(bs, 0, 3); /* numLayer */\n\n\t\t/* audio-specific config */\n\t\tesd = gf_isom_get_esd(tkHint->file, tkHint->TrackNum, 1);\n\t\tif (esd && esd->decoderConfig && esd->decoderConfig->decoderSpecificInfo) {\n\t\t\t/*PacketVideo patch: don't signal SBR and PS stuff, not allowed in LATM with audioMuxVersion=0*/\n\t\t\tgf_bs_write_data(bs, esd->decoderConfig->decoderSpecificInfo->data, MIN(esd->decoderConfig->decoderSpecificInfo->dataLength, 2) );\n\t\t}\n\t\tif (esd) gf_odf_desc_del((GF_Descriptor *)esd);\n\n\t\t/* other data */\n\t\tgf_bs_write_int(bs, 0, 3); /* frameLengthType */\n\t\tgf_bs_write_int(bs, 0xff, 8); /* latmBufferFullness */\n\t\tgf_bs_write_int(bs, 0, 1); /* otherDataPresent */\n\t\tgf_bs_write_int(bs, 0, 1); /* crcCheckPresent */\n\t\tgf_bs_get_content(bs, &config_bytes, &config_size);\n\t\tgf_bs_del(bs);\n\n\t\tgf_rtp_builder_format_sdp(tkHint->rtp_p, payloadName, sdpLine, config_bytes, config_size);\n\t\tgf_isom_sdp_add_track_line(tkHint->file, tkHint->HintTrack, sdpLine);\n\t\tgf_free(config_bytes);\n\t}\n#if GPAC_ENABLE_3GPP_DIMS_RTP\n\t/*3GPP DIMS*/\n\telse if (tkHint->rtp_p->rtp_payt==GF_RTP_PAYT_3GPP_DIMS) {\n\t\tGF_DIMSDescription dims;\n\t\tgf_isom_get_visual_info(tkHint->file, tkHint->TrackNum, 1, &Width, &Height);\n\n\t\tgf_isom_get_dims_description(tkHint->file, tkHint->TrackNum, 1, &dims);\n\t\tsprintf(sdpLine, \"a=fmtp:%d Version-profile=%d\", tkHint->rtp_p->PayloadType, dims.profile);\n\t\tif (! dims.fullRequestHost) {\n\t\t\tchar fmt[200];\n\t\t\tstrcat(sdpLine, \";useFullRequestHost=0\");\n\t\t\tsprintf(fmt, \";pathComponents=%d\", dims.pathComponents);\n\t\t\tstrcat(sdpLine, fmt);\n\t\t}\n\t\tif (!dims.streamType) strcat(sdpLine, \";stream-type=secondary\");\n\t\tif (dims.containsRedundant == 1) strcat(sdpLine, \";contains-redundant=main\");\n\t\telse if (dims.containsRedundant == 2) strcat(sdpLine, \";contains-redundant=redundant\");\n\n\t\tif (dims.textEncoding && strlen(dims.textEncoding)) {\n\t\t\tstrcat(sdpLine, \";text-encoding=\");\n\t\t\tstrcat(sdpLine, dims.textEncoding);\n\t\t}\n\t\tif (dims.contentEncoding && strlen(dims.contentEncoding)) {\n\t\t\tstrcat(sdpLine, \";content-coding=\");\n\t\t\tstrcat(sdpLine, dims.contentEncoding);\n\t\t}\n\t\tif (dims.contentEncoding && dims.content_script_types && strlen(dims.content_script_types) ) {\n\t\t\tstrcat(sdpLine, \";content-script-types=\");\n\t\t\tstrcat(sdpLine, dims.contentEncoding);\n\t\t}\n\t\tgf_isom_sdp_add_track_line(tkHint->file, tkHint->HintTrack, sdpLine);\n\t}\n#endif\n\t/*extensions for some mobile phones*/\n\tif (Width && Height) {\n\t\tsprintf(sdpLine, \"a=framesize:%d %d-%d\", tkHint->rtp_p->PayloadType, Width, Height);\n\t\tgf_isom_sdp_add_track_line(tkHint->file, tkHint->HintTrack, sdpLine);\n\t}\n\n\tesd = gf_isom_get_esd(tkHint->file, tkHint->TrackNum, 1);\n\tif (esd && esd->decoderConfig && (esd->decoderConfig->rvc_config || esd->decoderConfig->predefined_rvc_config)) {\n\t\tif (esd->decoderConfig->predefined_rvc_config) {\n\t\t\tsprintf(sdpLine, \"a=rvc-config-predef:%d\", esd->decoderConfig->predefined_rvc_config);\n\t\t} else {\n\t\t\t/*temporary ...*/\n\t\t\tif ((esd->decoderConfig->objectTypeIndication==GF_CODECID_AVC) || (esd->decoderConfig->objectTypeIndication==GF_CODECID_SVC)) {\n\t\t\t\tsprintf(sdpLine, \"a=rvc-config:%s\", \"http://download.tsi.telecom-paristech.fr/gpac/RVC/rvc_config_avc.xml\");\n\t\t\t} else {\n\t\t\t\tsprintf(sdpLine, \"a=rvc-config:%s\", \"http://download.tsi.telecom-paristech.fr/gpac/RVC/rvc_config_sp.xml\");\n\t\t\t}\n\t\t}\n\t\tgf_isom_sdp_add_track_line(tkHint->file, tkHint->HintTrack, sdpLine);\n\t}\n\tif (esd) gf_odf_desc_del((GF_Descriptor *)esd);\n\n\tgf_isom_set_track_enabled(tkHint->file, tkHint->HintTrack, GF_TRUE);\n\treturn GF_OK;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -76,9 +76,14 @@\n \t\tstrcat(sdpLine, \"; tx3g=\");\n \t\tfor (i=0; i<gf_isom_get_sample_description_count(tkHint->file, tkHint->TrackNum); i++) {\n \t\t\tu8 *tx3g;\n+\t\t\tGF_Err e;\n \t\t\tchar buffer[2000];\n \t\t\tu32 tx3g_len, len;\n-\t\t\tgf_isom_text_get_encoded_tx3g(tkHint->file, tkHint->TrackNum, i+1, GF_RTP_TX3G_SIDX_OFFSET, &tx3g, &tx3g_len);\n+\t\t\te = gf_isom_text_get_encoded_tx3g(tkHint->file, tkHint->TrackNum, i+1, GF_RTP_TX3G_SIDX_OFFSET, &tx3g, &tx3g_len);\n+\t\t\tif (e) {\n+\t\t\t\tif (i) continue;\n+\t\t\t\treturn GF_ISOM_INVALID_FILE;\n+\t\t\t}\n \t\t\tlen = gf_base64_encode(tx3g, tx3g_len, buffer, 2000);\n \t\t\tgf_free(tx3g);\n \t\t\tbuffer[len] = 0;",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\tgf_isom_text_get_encoded_tx3g(tkHint->file, tkHint->TrackNum, i+1, GF_RTP_TX3G_SIDX_OFFSET, &tx3g, &tx3g_len);"
            ],
            "added_lines": [
                "\t\t\tGF_Err e;",
                "\t\t\te = gf_isom_text_get_encoded_tx3g(tkHint->file, tkHint->TrackNum, i+1, GF_RTP_TX3G_SIDX_OFFSET, &tx3g, &tx3g_len);",
                "\t\t\tif (e) {",
                "\t\t\t\tif (i) continue;",
                "\t\t\t\treturn GF_ISOM_INVALID_FILE;",
                "\t\t\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-35414",
        "func_name": "qemu/address_space_translate_for_iotlb",
        "description": "softmmu/physmem.c in QEMU through 7.0.0 can perform an uninitialized read on the translate_fail path, leading to an io_readx or io_writex crash. NOTE: a third party states that the Non-virtualization Use Case in the qemu.org reference applies here, i.e., \"Bugs affecting the non-virtualization use case are not considered security bugs at this time.",
        "git_url": "https://github.com/qemu/qemu/commit/418ade7849ce7641c0f7333718caf5091a02fd4c",
        "commit_title": "softmmu: Always initialize xlat in address_space_translate_for_iotlb",
        "commit_text": " The bug is an uninitialized memory read, along the translate_fail path, which results in garbage being read from iotlb_to_section, which can lead to a crash in io_readx/io_writex.  The bug may be fixed by writing any value with zero in ~TARGET_PAGE_MASK, so that the call to iotlb_to_section using the xlat'ed address returns io_mem_unassigned, as desired by the translate_fail path.  It is most useful to record the original physical page address, which will eventually be logged by memory_region_access_valid when the access is rejected by unassigned_mem_accepts.  Resolves: https://gitlab.com/qemu-project/qemu/-/issues/1065 Message-Id: <20220621153829.366423-1-richard.henderson@linaro.org>",
        "func_before": "MemoryRegionSection *\naddress_space_translate_for_iotlb(CPUState *cpu, int asidx, hwaddr addr,\n                                  hwaddr *xlat, hwaddr *plen,\n                                  MemTxAttrs attrs, int *prot)\n{\n    MemoryRegionSection *section;\n    IOMMUMemoryRegion *iommu_mr;\n    IOMMUMemoryRegionClass *imrc;\n    IOMMUTLBEntry iotlb;\n    int iommu_idx;\n    AddressSpaceDispatch *d =\n        qatomic_rcu_read(&cpu->cpu_ases[asidx].memory_dispatch);\n\n    for (;;) {\n        section = address_space_translate_internal(d, addr, &addr, plen, false);\n\n        iommu_mr = memory_region_get_iommu(section->mr);\n        if (!iommu_mr) {\n            break;\n        }\n\n        imrc = memory_region_get_iommu_class_nocheck(iommu_mr);\n\n        iommu_idx = imrc->attrs_to_index(iommu_mr, attrs);\n        tcg_register_iommu_notifier(cpu, iommu_mr, iommu_idx);\n        /* We need all the permissions, so pass IOMMU_NONE so the IOMMU\n         * doesn't short-cut its translation table walk.\n         */\n        iotlb = imrc->translate(iommu_mr, addr, IOMMU_NONE, iommu_idx);\n        addr = ((iotlb.translated_addr & ~iotlb.addr_mask)\n                | (addr & iotlb.addr_mask));\n        /* Update the caller's prot bits to remove permissions the IOMMU\n         * is giving us a failure response for. If we get down to no\n         * permissions left at all we can give up now.\n         */\n        if (!(iotlb.perm & IOMMU_RO)) {\n            *prot &= ~(PAGE_READ | PAGE_EXEC);\n        }\n        if (!(iotlb.perm & IOMMU_WO)) {\n            *prot &= ~PAGE_WRITE;\n        }\n\n        if (!*prot) {\n            goto translate_fail;\n        }\n\n        d = flatview_to_dispatch(address_space_to_flatview(iotlb.target_as));\n    }\n\n    assert(!memory_region_is_iommu(section->mr));\n    *xlat = addr;\n    return section;\n\ntranslate_fail:\n    return &d->map.sections[PHYS_SECTION_UNASSIGNED];\n}",
        "func": "MemoryRegionSection *\naddress_space_translate_for_iotlb(CPUState *cpu, int asidx, hwaddr orig_addr,\n                                  hwaddr *xlat, hwaddr *plen,\n                                  MemTxAttrs attrs, int *prot)\n{\n    MemoryRegionSection *section;\n    IOMMUMemoryRegion *iommu_mr;\n    IOMMUMemoryRegionClass *imrc;\n    IOMMUTLBEntry iotlb;\n    int iommu_idx;\n    hwaddr addr = orig_addr;\n    AddressSpaceDispatch *d =\n        qatomic_rcu_read(&cpu->cpu_ases[asidx].memory_dispatch);\n\n    for (;;) {\n        section = address_space_translate_internal(d, addr, &addr, plen, false);\n\n        iommu_mr = memory_region_get_iommu(section->mr);\n        if (!iommu_mr) {\n            break;\n        }\n\n        imrc = memory_region_get_iommu_class_nocheck(iommu_mr);\n\n        iommu_idx = imrc->attrs_to_index(iommu_mr, attrs);\n        tcg_register_iommu_notifier(cpu, iommu_mr, iommu_idx);\n        /* We need all the permissions, so pass IOMMU_NONE so the IOMMU\n         * doesn't short-cut its translation table walk.\n         */\n        iotlb = imrc->translate(iommu_mr, addr, IOMMU_NONE, iommu_idx);\n        addr = ((iotlb.translated_addr & ~iotlb.addr_mask)\n                | (addr & iotlb.addr_mask));\n        /* Update the caller's prot bits to remove permissions the IOMMU\n         * is giving us a failure response for. If we get down to no\n         * permissions left at all we can give up now.\n         */\n        if (!(iotlb.perm & IOMMU_RO)) {\n            *prot &= ~(PAGE_READ | PAGE_EXEC);\n        }\n        if (!(iotlb.perm & IOMMU_WO)) {\n            *prot &= ~PAGE_WRITE;\n        }\n\n        if (!*prot) {\n            goto translate_fail;\n        }\n\n        d = flatview_to_dispatch(address_space_to_flatview(iotlb.target_as));\n    }\n\n    assert(!memory_region_is_iommu(section->mr));\n    *xlat = addr;\n    return section;\n\ntranslate_fail:\n    /*\n     * We should be given a page-aligned address -- certainly\n     * tlb_set_page_with_attrs() does so.  The page offset of xlat\n     * is used to index sections[], and PHYS_SECTION_UNASSIGNED = 0.\n     * The page portion of xlat will be logged by memory_region_access_valid()\n     * when this memory access is rejected, so use the original untranslated\n     * physical address.\n     */\n    assert((orig_addr & ~TARGET_PAGE_MASK) == 0);\n    *xlat = orig_addr;\n    return &d->map.sections[PHYS_SECTION_UNASSIGNED];\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,5 @@\n MemoryRegionSection *\n-address_space_translate_for_iotlb(CPUState *cpu, int asidx, hwaddr addr,\n+address_space_translate_for_iotlb(CPUState *cpu, int asidx, hwaddr orig_addr,\n                                   hwaddr *xlat, hwaddr *plen,\n                                   MemTxAttrs attrs, int *prot)\n {\n@@ -8,6 +8,7 @@\n     IOMMUMemoryRegionClass *imrc;\n     IOMMUTLBEntry iotlb;\n     int iommu_idx;\n+    hwaddr addr = orig_addr;\n     AddressSpaceDispatch *d =\n         qatomic_rcu_read(&cpu->cpu_ases[asidx].memory_dispatch);\n \n@@ -52,5 +53,15 @@\n     return section;\n \n translate_fail:\n+    /*\n+     * We should be given a page-aligned address -- certainly\n+     * tlb_set_page_with_attrs() does so.  The page offset of xlat\n+     * is used to index sections[], and PHYS_SECTION_UNASSIGNED = 0.\n+     * The page portion of xlat will be logged by memory_region_access_valid()\n+     * when this memory access is rejected, so use the original untranslated\n+     * physical address.\n+     */\n+    assert((orig_addr & ~TARGET_PAGE_MASK) == 0);\n+    *xlat = orig_addr;\n     return &d->map.sections[PHYS_SECTION_UNASSIGNED];\n }",
        "diff_line_info": {
            "deleted_lines": [
                "address_space_translate_for_iotlb(CPUState *cpu, int asidx, hwaddr addr,"
            ],
            "added_lines": [
                "address_space_translate_for_iotlb(CPUState *cpu, int asidx, hwaddr orig_addr,",
                "    hwaddr addr = orig_addr;",
                "    /*",
                "     * We should be given a page-aligned address -- certainly",
                "     * tlb_set_page_with_attrs() does so.  The page offset of xlat",
                "     * is used to index sections[], and PHYS_SECTION_UNASSIGNED = 0.",
                "     * The page portion of xlat will be logged by memory_region_access_valid()",
                "     * when this memory access is rejected, so use the original untranslated",
                "     * physical address.",
                "     */",
                "    assert((orig_addr & ~TARGET_PAGE_MASK) == 0);",
                "    *xlat = orig_addr;"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-35414",
        "func_name": "qemu/loongarch_cpu_reset",
        "description": "softmmu/physmem.c in QEMU through 7.0.0 can perform an uninitialized read on the translate_fail path, leading to an io_readx or io_writex crash. NOTE: a third party states that the Non-virtualization Use Case in the qemu.org reference applies here, i.e., \"Bugs affecting the non-virtualization use case are not considered security bugs at this time.",
        "git_url": "https://github.com/qemu/qemu/commit/3517fb726741c109cae7995f9ea46f0cab6187d6",
        "commit_title": "target/loongarch: Clean up tlb when cpu reset",
        "commit_text": " We should make sure that tlb is clean when cpu reset.  Message-Id: <20220705070950.2364243-1-gaosong@loongson.cn>",
        "func_before": "static void loongarch_cpu_reset(DeviceState *dev)\n{\n    CPUState *cs = CPU(dev);\n    LoongArchCPU *cpu = LOONGARCH_CPU(cs);\n    LoongArchCPUClass *lacc = LOONGARCH_CPU_GET_CLASS(cpu);\n    CPULoongArchState *env = &cpu->env;\n\n    lacc->parent_reset(dev);\n\n    env->fcsr0_mask = FCSR0_M1 | FCSR0_M2 | FCSR0_M3;\n    env->fcsr0 = 0x0;\n\n    int n;\n    /* Set csr registers value after reset */\n    env->CSR_CRMD = FIELD_DP64(env->CSR_CRMD, CSR_CRMD, PLV, 0);\n    env->CSR_CRMD = FIELD_DP64(env->CSR_CRMD, CSR_CRMD, IE, 0);\n    env->CSR_CRMD = FIELD_DP64(env->CSR_CRMD, CSR_CRMD, DA, 1);\n    env->CSR_CRMD = FIELD_DP64(env->CSR_CRMD, CSR_CRMD, PG, 0);\n    env->CSR_CRMD = FIELD_DP64(env->CSR_CRMD, CSR_CRMD, DATF, 1);\n    env->CSR_CRMD = FIELD_DP64(env->CSR_CRMD, CSR_CRMD, DATM, 1);\n\n    env->CSR_EUEN = FIELD_DP64(env->CSR_EUEN, CSR_EUEN, FPE, 0);\n    env->CSR_EUEN = FIELD_DP64(env->CSR_EUEN, CSR_EUEN, SXE, 0);\n    env->CSR_EUEN = FIELD_DP64(env->CSR_EUEN, CSR_EUEN, ASXE, 0);\n    env->CSR_EUEN = FIELD_DP64(env->CSR_EUEN, CSR_EUEN, BTE, 0);\n\n    env->CSR_MISC = 0;\n\n    env->CSR_ECFG = FIELD_DP64(env->CSR_ECFG, CSR_ECFG, VS, 0);\n    env->CSR_ECFG = FIELD_DP64(env->CSR_ECFG, CSR_ECFG, LIE, 0);\n\n    env->CSR_ESTAT = env->CSR_ESTAT & (~MAKE_64BIT_MASK(0, 2));\n    env->CSR_RVACFG = FIELD_DP64(env->CSR_RVACFG, CSR_RVACFG, RBITS, 0);\n    env->CSR_TCFG = FIELD_DP64(env->CSR_TCFG, CSR_TCFG, EN, 0);\n    env->CSR_LLBCTL = FIELD_DP64(env->CSR_LLBCTL, CSR_LLBCTL, KLO, 0);\n    env->CSR_TLBRERA = FIELD_DP64(env->CSR_TLBRERA, CSR_TLBRERA, ISTLBR, 0);\n    env->CSR_MERRCTL = FIELD_DP64(env->CSR_MERRCTL, CSR_MERRCTL, ISMERR, 0);\n\n    env->CSR_PRCFG3 = FIELD_DP64(env->CSR_PRCFG3, CSR_PRCFG3, TLB_TYPE, 2);\n    env->CSR_PRCFG3 = FIELD_DP64(env->CSR_PRCFG3, CSR_PRCFG3, MTLB_ENTRY, 63);\n    env->CSR_PRCFG3 = FIELD_DP64(env->CSR_PRCFG3, CSR_PRCFG3, STLB_WAYS, 7);\n    env->CSR_PRCFG3 = FIELD_DP64(env->CSR_PRCFG3, CSR_PRCFG3, STLB_SETS, 8);\n\n    for (n = 0; n < 4; n++) {\n        env->CSR_DMW[n] = FIELD_DP64(env->CSR_DMW[n], CSR_DMW, PLV0, 0);\n        env->CSR_DMW[n] = FIELD_DP64(env->CSR_DMW[n], CSR_DMW, PLV1, 0);\n        env->CSR_DMW[n] = FIELD_DP64(env->CSR_DMW[n], CSR_DMW, PLV2, 0);\n        env->CSR_DMW[n] = FIELD_DP64(env->CSR_DMW[n], CSR_DMW, PLV3, 0);\n    }\n\n#ifndef CONFIG_USER_ONLY\n    env->pc = 0x1c000000;\n#endif\n\n    restore_fp_status(env);\n    cs->exception_index = -1;\n}",
        "func": "static void loongarch_cpu_reset(DeviceState *dev)\n{\n    CPUState *cs = CPU(dev);\n    LoongArchCPU *cpu = LOONGARCH_CPU(cs);\n    LoongArchCPUClass *lacc = LOONGARCH_CPU_GET_CLASS(cpu);\n    CPULoongArchState *env = &cpu->env;\n\n    lacc->parent_reset(dev);\n\n    env->fcsr0_mask = FCSR0_M1 | FCSR0_M2 | FCSR0_M3;\n    env->fcsr0 = 0x0;\n\n    int n;\n    /* Set csr registers value after reset */\n    env->CSR_CRMD = FIELD_DP64(env->CSR_CRMD, CSR_CRMD, PLV, 0);\n    env->CSR_CRMD = FIELD_DP64(env->CSR_CRMD, CSR_CRMD, IE, 0);\n    env->CSR_CRMD = FIELD_DP64(env->CSR_CRMD, CSR_CRMD, DA, 1);\n    env->CSR_CRMD = FIELD_DP64(env->CSR_CRMD, CSR_CRMD, PG, 0);\n    env->CSR_CRMD = FIELD_DP64(env->CSR_CRMD, CSR_CRMD, DATF, 1);\n    env->CSR_CRMD = FIELD_DP64(env->CSR_CRMD, CSR_CRMD, DATM, 1);\n\n    env->CSR_EUEN = FIELD_DP64(env->CSR_EUEN, CSR_EUEN, FPE, 0);\n    env->CSR_EUEN = FIELD_DP64(env->CSR_EUEN, CSR_EUEN, SXE, 0);\n    env->CSR_EUEN = FIELD_DP64(env->CSR_EUEN, CSR_EUEN, ASXE, 0);\n    env->CSR_EUEN = FIELD_DP64(env->CSR_EUEN, CSR_EUEN, BTE, 0);\n\n    env->CSR_MISC = 0;\n\n    env->CSR_ECFG = FIELD_DP64(env->CSR_ECFG, CSR_ECFG, VS, 0);\n    env->CSR_ECFG = FIELD_DP64(env->CSR_ECFG, CSR_ECFG, LIE, 0);\n\n    env->CSR_ESTAT = env->CSR_ESTAT & (~MAKE_64BIT_MASK(0, 2));\n    env->CSR_RVACFG = FIELD_DP64(env->CSR_RVACFG, CSR_RVACFG, RBITS, 0);\n    env->CSR_TCFG = FIELD_DP64(env->CSR_TCFG, CSR_TCFG, EN, 0);\n    env->CSR_LLBCTL = FIELD_DP64(env->CSR_LLBCTL, CSR_LLBCTL, KLO, 0);\n    env->CSR_TLBRERA = FIELD_DP64(env->CSR_TLBRERA, CSR_TLBRERA, ISTLBR, 0);\n    env->CSR_MERRCTL = FIELD_DP64(env->CSR_MERRCTL, CSR_MERRCTL, ISMERR, 0);\n\n    env->CSR_PRCFG3 = FIELD_DP64(env->CSR_PRCFG3, CSR_PRCFG3, TLB_TYPE, 2);\n    env->CSR_PRCFG3 = FIELD_DP64(env->CSR_PRCFG3, CSR_PRCFG3, MTLB_ENTRY, 63);\n    env->CSR_PRCFG3 = FIELD_DP64(env->CSR_PRCFG3, CSR_PRCFG3, STLB_WAYS, 7);\n    env->CSR_PRCFG3 = FIELD_DP64(env->CSR_PRCFG3, CSR_PRCFG3, STLB_SETS, 8);\n\n    for (n = 0; n < 4; n++) {\n        env->CSR_DMW[n] = FIELD_DP64(env->CSR_DMW[n], CSR_DMW, PLV0, 0);\n        env->CSR_DMW[n] = FIELD_DP64(env->CSR_DMW[n], CSR_DMW, PLV1, 0);\n        env->CSR_DMW[n] = FIELD_DP64(env->CSR_DMW[n], CSR_DMW, PLV2, 0);\n        env->CSR_DMW[n] = FIELD_DP64(env->CSR_DMW[n], CSR_DMW, PLV3, 0);\n    }\n\n#ifndef CONFIG_USER_ONLY\n    env->pc = 0x1c000000;\n    memset(env->tlb, 0, sizeof(env->tlb));\n#endif\n\n    restore_fp_status(env);\n    cs->exception_index = -1;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -50,6 +50,7 @@\n \n #ifndef CONFIG_USER_ONLY\n     env->pc = 0x1c000000;\n+    memset(env->tlb, 0, sizeof(env->tlb));\n #endif\n \n     restore_fp_status(env);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    memset(env->tlb, 0, sizeof(env->tlb));"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-11833",
        "func_name": "torvalds/linux/ext4_ext_split",
        "description": "fs/ext4/extents.c in the Linux kernel through 5.1.2 does not zero out the unused memory region in the extent tree block, which might allow local users to obtain sensitive information by reading uninitialized data in the filesystem.",
        "git_url": "https://github.com/torvalds/linux/commit/592acbf16821288ecdc4192c47e3774a4c48bb64",
        "commit_title": "ext4: zero out the unused memory region in the extent tree block",
        "commit_text": " This commit zeroes out the unused memory region in the buffer_head corresponding to the extent metablock after writing the extent header and the corresponding extent node entries.  This is done to prevent random uninitialized data from getting into the filesystem when the extent block is synced.  This fixes CVE-2019-11833.  Cc: stable@kernel.org",
        "func_before": "static int ext4_ext_split(handle_t *handle, struct inode *inode,\n\t\t\t  unsigned int flags,\n\t\t\t  struct ext4_ext_path *path,\n\t\t\t  struct ext4_extent *newext, int at)\n{\n\tstruct buffer_head *bh = NULL;\n\tint depth = ext_depth(inode);\n\tstruct ext4_extent_header *neh;\n\tstruct ext4_extent_idx *fidx;\n\tint i = at, k, m, a;\n\text4_fsblk_t newblock, oldblock;\n\t__le32 border;\n\text4_fsblk_t *ablocks = NULL; /* array of allocated blocks */\n\tint err = 0;\n\n\t/* make decision: where to split? */\n\t/* FIXME: now decision is simplest: at current extent */\n\n\t/* if current leaf will be split, then we should use\n\t * border from split point */\n\tif (unlikely(path[depth].p_ext > EXT_MAX_EXTENT(path[depth].p_hdr))) {\n\t\tEXT4_ERROR_INODE(inode, \"p_ext > EXT_MAX_EXTENT!\");\n\t\treturn -EFSCORRUPTED;\n\t}\n\tif (path[depth].p_ext != EXT_MAX_EXTENT(path[depth].p_hdr)) {\n\t\tborder = path[depth].p_ext[1].ee_block;\n\t\text_debug(\"leaf will be split.\"\n\t\t\t\t\" next leaf starts at %d\\n\",\n\t\t\t\t  le32_to_cpu(border));\n\t} else {\n\t\tborder = newext->ee_block;\n\t\text_debug(\"leaf will be added.\"\n\t\t\t\t\" next leaf starts at %d\\n\",\n\t\t\t\tle32_to_cpu(border));\n\t}\n\n\t/*\n\t * If error occurs, then we break processing\n\t * and mark filesystem read-only. index won't\n\t * be inserted and tree will be in consistent\n\t * state. Next mount will repair buffers too.\n\t */\n\n\t/*\n\t * Get array to track all allocated blocks.\n\t * We need this to handle errors and free blocks\n\t * upon them.\n\t */\n\tablocks = kcalloc(depth, sizeof(ext4_fsblk_t), GFP_NOFS);\n\tif (!ablocks)\n\t\treturn -ENOMEM;\n\n\t/* allocate all needed blocks */\n\text_debug(\"allocate %d blocks for indexes/leaf\\n\", depth - at);\n\tfor (a = 0; a < depth - at; a++) {\n\t\tnewblock = ext4_ext_new_meta_block(handle, inode, path,\n\t\t\t\t\t\t   newext, &err, flags);\n\t\tif (newblock == 0)\n\t\t\tgoto cleanup;\n\t\tablocks[a] = newblock;\n\t}\n\n\t/* initialize new leaf */\n\tnewblock = ablocks[--a];\n\tif (unlikely(newblock == 0)) {\n\t\tEXT4_ERROR_INODE(inode, \"newblock == 0!\");\n\t\terr = -EFSCORRUPTED;\n\t\tgoto cleanup;\n\t}\n\tbh = sb_getblk_gfp(inode->i_sb, newblock, __GFP_MOVABLE | GFP_NOFS);\n\tif (unlikely(!bh)) {\n\t\terr = -ENOMEM;\n\t\tgoto cleanup;\n\t}\n\tlock_buffer(bh);\n\n\terr = ext4_journal_get_create_access(handle, bh);\n\tif (err)\n\t\tgoto cleanup;\n\n\tneh = ext_block_hdr(bh);\n\tneh->eh_entries = 0;\n\tneh->eh_max = cpu_to_le16(ext4_ext_space_block(inode, 0));\n\tneh->eh_magic = EXT4_EXT_MAGIC;\n\tneh->eh_depth = 0;\n\n\t/* move remainder of path[depth] to the new leaf */\n\tif (unlikely(path[depth].p_hdr->eh_entries !=\n\t\t     path[depth].p_hdr->eh_max)) {\n\t\tEXT4_ERROR_INODE(inode, \"eh_entries %d != eh_max %d!\",\n\t\t\t\t path[depth].p_hdr->eh_entries,\n\t\t\t\t path[depth].p_hdr->eh_max);\n\t\terr = -EFSCORRUPTED;\n\t\tgoto cleanup;\n\t}\n\t/* start copy from next extent */\n\tm = EXT_MAX_EXTENT(path[depth].p_hdr) - path[depth].p_ext++;\n\text4_ext_show_move(inode, path, newblock, depth);\n\tif (m) {\n\t\tstruct ext4_extent *ex;\n\t\tex = EXT_FIRST_EXTENT(neh);\n\t\tmemmove(ex, path[depth].p_ext, sizeof(struct ext4_extent) * m);\n\t\tle16_add_cpu(&neh->eh_entries, m);\n\t}\n\n\text4_extent_block_csum_set(inode, neh);\n\tset_buffer_uptodate(bh);\n\tunlock_buffer(bh);\n\n\terr = ext4_handle_dirty_metadata(handle, inode, bh);\n\tif (err)\n\t\tgoto cleanup;\n\tbrelse(bh);\n\tbh = NULL;\n\n\t/* correct old leaf */\n\tif (m) {\n\t\terr = ext4_ext_get_access(handle, inode, path + depth);\n\t\tif (err)\n\t\t\tgoto cleanup;\n\t\tle16_add_cpu(&path[depth].p_hdr->eh_entries, -m);\n\t\terr = ext4_ext_dirty(handle, inode, path + depth);\n\t\tif (err)\n\t\t\tgoto cleanup;\n\n\t}\n\n\t/* create intermediate indexes */\n\tk = depth - at - 1;\n\tif (unlikely(k < 0)) {\n\t\tEXT4_ERROR_INODE(inode, \"k %d < 0!\", k);\n\t\terr = -EFSCORRUPTED;\n\t\tgoto cleanup;\n\t}\n\tif (k)\n\t\text_debug(\"create %d intermediate indices\\n\", k);\n\t/* insert new index into current index block */\n\t/* current depth stored in i var */\n\ti = depth - 1;\n\twhile (k--) {\n\t\toldblock = newblock;\n\t\tnewblock = ablocks[--a];\n\t\tbh = sb_getblk(inode->i_sb, newblock);\n\t\tif (unlikely(!bh)) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto cleanup;\n\t\t}\n\t\tlock_buffer(bh);\n\n\t\terr = ext4_journal_get_create_access(handle, bh);\n\t\tif (err)\n\t\t\tgoto cleanup;\n\n\t\tneh = ext_block_hdr(bh);\n\t\tneh->eh_entries = cpu_to_le16(1);\n\t\tneh->eh_magic = EXT4_EXT_MAGIC;\n\t\tneh->eh_max = cpu_to_le16(ext4_ext_space_block_idx(inode, 0));\n\t\tneh->eh_depth = cpu_to_le16(depth - i);\n\t\tfidx = EXT_FIRST_INDEX(neh);\n\t\tfidx->ei_block = border;\n\t\text4_idx_store_pblock(fidx, oldblock);\n\n\t\text_debug(\"int.index at %d (block %llu): %u -> %llu\\n\",\n\t\t\t\ti, newblock, le32_to_cpu(border), oldblock);\n\n\t\t/* move remainder of path[i] to the new index block */\n\t\tif (unlikely(EXT_MAX_INDEX(path[i].p_hdr) !=\n\t\t\t\t\tEXT_LAST_INDEX(path[i].p_hdr))) {\n\t\t\tEXT4_ERROR_INODE(inode,\n\t\t\t\t\t \"EXT_MAX_INDEX != EXT_LAST_INDEX ee_block %d!\",\n\t\t\t\t\t le32_to_cpu(path[i].p_ext->ee_block));\n\t\t\terr = -EFSCORRUPTED;\n\t\t\tgoto cleanup;\n\t\t}\n\t\t/* start copy indexes */\n\t\tm = EXT_MAX_INDEX(path[i].p_hdr) - path[i].p_idx++;\n\t\text_debug(\"cur 0x%p, last 0x%p\\n\", path[i].p_idx,\n\t\t\t\tEXT_MAX_INDEX(path[i].p_hdr));\n\t\text4_ext_show_move(inode, path, newblock, i);\n\t\tif (m) {\n\t\t\tmemmove(++fidx, path[i].p_idx,\n\t\t\t\tsizeof(struct ext4_extent_idx) * m);\n\t\t\tle16_add_cpu(&neh->eh_entries, m);\n\t\t}\n\t\text4_extent_block_csum_set(inode, neh);\n\t\tset_buffer_uptodate(bh);\n\t\tunlock_buffer(bh);\n\n\t\terr = ext4_handle_dirty_metadata(handle, inode, bh);\n\t\tif (err)\n\t\t\tgoto cleanup;\n\t\tbrelse(bh);\n\t\tbh = NULL;\n\n\t\t/* correct old index */\n\t\tif (m) {\n\t\t\terr = ext4_ext_get_access(handle, inode, path + i);\n\t\t\tif (err)\n\t\t\t\tgoto cleanup;\n\t\t\tle16_add_cpu(&path[i].p_hdr->eh_entries, -m);\n\t\t\terr = ext4_ext_dirty(handle, inode, path + i);\n\t\t\tif (err)\n\t\t\t\tgoto cleanup;\n\t\t}\n\n\t\ti--;\n\t}\n\n\t/* insert new index */\n\terr = ext4_ext_insert_index(handle, inode, path + at,\n\t\t\t\t    le32_to_cpu(border), newblock);\n\ncleanup:\n\tif (bh) {\n\t\tif (buffer_locked(bh))\n\t\t\tunlock_buffer(bh);\n\t\tbrelse(bh);\n\t}\n\n\tif (err) {\n\t\t/* free all allocated blocks in error case */\n\t\tfor (i = 0; i < depth; i++) {\n\t\t\tif (!ablocks[i])\n\t\t\t\tcontinue;\n\t\t\text4_free_blocks(handle, inode, NULL, ablocks[i], 1,\n\t\t\t\t\t EXT4_FREE_BLOCKS_METADATA);\n\t\t}\n\t}\n\tkfree(ablocks);\n\n\treturn err;\n}",
        "func": "static int ext4_ext_split(handle_t *handle, struct inode *inode,\n\t\t\t  unsigned int flags,\n\t\t\t  struct ext4_ext_path *path,\n\t\t\t  struct ext4_extent *newext, int at)\n{\n\tstruct buffer_head *bh = NULL;\n\tint depth = ext_depth(inode);\n\tstruct ext4_extent_header *neh;\n\tstruct ext4_extent_idx *fidx;\n\tint i = at, k, m, a;\n\text4_fsblk_t newblock, oldblock;\n\t__le32 border;\n\text4_fsblk_t *ablocks = NULL; /* array of allocated blocks */\n\tint err = 0;\n\tsize_t ext_size = 0;\n\n\t/* make decision: where to split? */\n\t/* FIXME: now decision is simplest: at current extent */\n\n\t/* if current leaf will be split, then we should use\n\t * border from split point */\n\tif (unlikely(path[depth].p_ext > EXT_MAX_EXTENT(path[depth].p_hdr))) {\n\t\tEXT4_ERROR_INODE(inode, \"p_ext > EXT_MAX_EXTENT!\");\n\t\treturn -EFSCORRUPTED;\n\t}\n\tif (path[depth].p_ext != EXT_MAX_EXTENT(path[depth].p_hdr)) {\n\t\tborder = path[depth].p_ext[1].ee_block;\n\t\text_debug(\"leaf will be split.\"\n\t\t\t\t\" next leaf starts at %d\\n\",\n\t\t\t\t  le32_to_cpu(border));\n\t} else {\n\t\tborder = newext->ee_block;\n\t\text_debug(\"leaf will be added.\"\n\t\t\t\t\" next leaf starts at %d\\n\",\n\t\t\t\tle32_to_cpu(border));\n\t}\n\n\t/*\n\t * If error occurs, then we break processing\n\t * and mark filesystem read-only. index won't\n\t * be inserted and tree will be in consistent\n\t * state. Next mount will repair buffers too.\n\t */\n\n\t/*\n\t * Get array to track all allocated blocks.\n\t * We need this to handle errors and free blocks\n\t * upon them.\n\t */\n\tablocks = kcalloc(depth, sizeof(ext4_fsblk_t), GFP_NOFS);\n\tif (!ablocks)\n\t\treturn -ENOMEM;\n\n\t/* allocate all needed blocks */\n\text_debug(\"allocate %d blocks for indexes/leaf\\n\", depth - at);\n\tfor (a = 0; a < depth - at; a++) {\n\t\tnewblock = ext4_ext_new_meta_block(handle, inode, path,\n\t\t\t\t\t\t   newext, &err, flags);\n\t\tif (newblock == 0)\n\t\t\tgoto cleanup;\n\t\tablocks[a] = newblock;\n\t}\n\n\t/* initialize new leaf */\n\tnewblock = ablocks[--a];\n\tif (unlikely(newblock == 0)) {\n\t\tEXT4_ERROR_INODE(inode, \"newblock == 0!\");\n\t\terr = -EFSCORRUPTED;\n\t\tgoto cleanup;\n\t}\n\tbh = sb_getblk_gfp(inode->i_sb, newblock, __GFP_MOVABLE | GFP_NOFS);\n\tif (unlikely(!bh)) {\n\t\terr = -ENOMEM;\n\t\tgoto cleanup;\n\t}\n\tlock_buffer(bh);\n\n\terr = ext4_journal_get_create_access(handle, bh);\n\tif (err)\n\t\tgoto cleanup;\n\n\tneh = ext_block_hdr(bh);\n\tneh->eh_entries = 0;\n\tneh->eh_max = cpu_to_le16(ext4_ext_space_block(inode, 0));\n\tneh->eh_magic = EXT4_EXT_MAGIC;\n\tneh->eh_depth = 0;\n\n\t/* move remainder of path[depth] to the new leaf */\n\tif (unlikely(path[depth].p_hdr->eh_entries !=\n\t\t     path[depth].p_hdr->eh_max)) {\n\t\tEXT4_ERROR_INODE(inode, \"eh_entries %d != eh_max %d!\",\n\t\t\t\t path[depth].p_hdr->eh_entries,\n\t\t\t\t path[depth].p_hdr->eh_max);\n\t\terr = -EFSCORRUPTED;\n\t\tgoto cleanup;\n\t}\n\t/* start copy from next extent */\n\tm = EXT_MAX_EXTENT(path[depth].p_hdr) - path[depth].p_ext++;\n\text4_ext_show_move(inode, path, newblock, depth);\n\tif (m) {\n\t\tstruct ext4_extent *ex;\n\t\tex = EXT_FIRST_EXTENT(neh);\n\t\tmemmove(ex, path[depth].p_ext, sizeof(struct ext4_extent) * m);\n\t\tle16_add_cpu(&neh->eh_entries, m);\n\t}\n\n\t/* zero out unused area in the extent block */\n\text_size = sizeof(struct ext4_extent_header) +\n\t\tsizeof(struct ext4_extent) * le16_to_cpu(neh->eh_entries);\n\tmemset(bh->b_data + ext_size, 0, inode->i_sb->s_blocksize - ext_size);\n\text4_extent_block_csum_set(inode, neh);\n\tset_buffer_uptodate(bh);\n\tunlock_buffer(bh);\n\n\terr = ext4_handle_dirty_metadata(handle, inode, bh);\n\tif (err)\n\t\tgoto cleanup;\n\tbrelse(bh);\n\tbh = NULL;\n\n\t/* correct old leaf */\n\tif (m) {\n\t\terr = ext4_ext_get_access(handle, inode, path + depth);\n\t\tif (err)\n\t\t\tgoto cleanup;\n\t\tle16_add_cpu(&path[depth].p_hdr->eh_entries, -m);\n\t\terr = ext4_ext_dirty(handle, inode, path + depth);\n\t\tif (err)\n\t\t\tgoto cleanup;\n\n\t}\n\n\t/* create intermediate indexes */\n\tk = depth - at - 1;\n\tif (unlikely(k < 0)) {\n\t\tEXT4_ERROR_INODE(inode, \"k %d < 0!\", k);\n\t\terr = -EFSCORRUPTED;\n\t\tgoto cleanup;\n\t}\n\tif (k)\n\t\text_debug(\"create %d intermediate indices\\n\", k);\n\t/* insert new index into current index block */\n\t/* current depth stored in i var */\n\ti = depth - 1;\n\twhile (k--) {\n\t\toldblock = newblock;\n\t\tnewblock = ablocks[--a];\n\t\tbh = sb_getblk(inode->i_sb, newblock);\n\t\tif (unlikely(!bh)) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto cleanup;\n\t\t}\n\t\tlock_buffer(bh);\n\n\t\terr = ext4_journal_get_create_access(handle, bh);\n\t\tif (err)\n\t\t\tgoto cleanup;\n\n\t\tneh = ext_block_hdr(bh);\n\t\tneh->eh_entries = cpu_to_le16(1);\n\t\tneh->eh_magic = EXT4_EXT_MAGIC;\n\t\tneh->eh_max = cpu_to_le16(ext4_ext_space_block_idx(inode, 0));\n\t\tneh->eh_depth = cpu_to_le16(depth - i);\n\t\tfidx = EXT_FIRST_INDEX(neh);\n\t\tfidx->ei_block = border;\n\t\text4_idx_store_pblock(fidx, oldblock);\n\n\t\text_debug(\"int.index at %d (block %llu): %u -> %llu\\n\",\n\t\t\t\ti, newblock, le32_to_cpu(border), oldblock);\n\n\t\t/* move remainder of path[i] to the new index block */\n\t\tif (unlikely(EXT_MAX_INDEX(path[i].p_hdr) !=\n\t\t\t\t\tEXT_LAST_INDEX(path[i].p_hdr))) {\n\t\t\tEXT4_ERROR_INODE(inode,\n\t\t\t\t\t \"EXT_MAX_INDEX != EXT_LAST_INDEX ee_block %d!\",\n\t\t\t\t\t le32_to_cpu(path[i].p_ext->ee_block));\n\t\t\terr = -EFSCORRUPTED;\n\t\t\tgoto cleanup;\n\t\t}\n\t\t/* start copy indexes */\n\t\tm = EXT_MAX_INDEX(path[i].p_hdr) - path[i].p_idx++;\n\t\text_debug(\"cur 0x%p, last 0x%p\\n\", path[i].p_idx,\n\t\t\t\tEXT_MAX_INDEX(path[i].p_hdr));\n\t\text4_ext_show_move(inode, path, newblock, i);\n\t\tif (m) {\n\t\t\tmemmove(++fidx, path[i].p_idx,\n\t\t\t\tsizeof(struct ext4_extent_idx) * m);\n\t\t\tle16_add_cpu(&neh->eh_entries, m);\n\t\t}\n\t\t/* zero out unused area in the extent block */\n\t\text_size = sizeof(struct ext4_extent_header) +\n\t\t   (sizeof(struct ext4_extent) * le16_to_cpu(neh->eh_entries));\n\t\tmemset(bh->b_data + ext_size, 0,\n\t\t\tinode->i_sb->s_blocksize - ext_size);\n\t\text4_extent_block_csum_set(inode, neh);\n\t\tset_buffer_uptodate(bh);\n\t\tunlock_buffer(bh);\n\n\t\terr = ext4_handle_dirty_metadata(handle, inode, bh);\n\t\tif (err)\n\t\t\tgoto cleanup;\n\t\tbrelse(bh);\n\t\tbh = NULL;\n\n\t\t/* correct old index */\n\t\tif (m) {\n\t\t\terr = ext4_ext_get_access(handle, inode, path + i);\n\t\t\tif (err)\n\t\t\t\tgoto cleanup;\n\t\t\tle16_add_cpu(&path[i].p_hdr->eh_entries, -m);\n\t\t\terr = ext4_ext_dirty(handle, inode, path + i);\n\t\t\tif (err)\n\t\t\t\tgoto cleanup;\n\t\t}\n\n\t\ti--;\n\t}\n\n\t/* insert new index */\n\terr = ext4_ext_insert_index(handle, inode, path + at,\n\t\t\t\t    le32_to_cpu(border), newblock);\n\ncleanup:\n\tif (bh) {\n\t\tif (buffer_locked(bh))\n\t\t\tunlock_buffer(bh);\n\t\tbrelse(bh);\n\t}\n\n\tif (err) {\n\t\t/* free all allocated blocks in error case */\n\t\tfor (i = 0; i < depth; i++) {\n\t\t\tif (!ablocks[i])\n\t\t\t\tcontinue;\n\t\t\text4_free_blocks(handle, inode, NULL, ablocks[i], 1,\n\t\t\t\t\t EXT4_FREE_BLOCKS_METADATA);\n\t\t}\n\t}\n\tkfree(ablocks);\n\n\treturn err;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -12,6 +12,7 @@\n \t__le32 border;\n \text4_fsblk_t *ablocks = NULL; /* array of allocated blocks */\n \tint err = 0;\n+\tsize_t ext_size = 0;\n \n \t/* make decision: where to split? */\n \t/* FIXME: now decision is simplest: at current extent */\n@@ -103,6 +104,10 @@\n \t\tle16_add_cpu(&neh->eh_entries, m);\n \t}\n \n+\t/* zero out unused area in the extent block */\n+\text_size = sizeof(struct ext4_extent_header) +\n+\t\tsizeof(struct ext4_extent) * le16_to_cpu(neh->eh_entries);\n+\tmemset(bh->b_data + ext_size, 0, inode->i_sb->s_blocksize - ext_size);\n \text4_extent_block_csum_set(inode, neh);\n \tset_buffer_uptodate(bh);\n \tunlock_buffer(bh);\n@@ -182,6 +187,11 @@\n \t\t\t\tsizeof(struct ext4_extent_idx) * m);\n \t\t\tle16_add_cpu(&neh->eh_entries, m);\n \t\t}\n+\t\t/* zero out unused area in the extent block */\n+\t\text_size = sizeof(struct ext4_extent_header) +\n+\t\t   (sizeof(struct ext4_extent) * le16_to_cpu(neh->eh_entries));\n+\t\tmemset(bh->b_data + ext_size, 0,\n+\t\t\tinode->i_sb->s_blocksize - ext_size);\n \t\text4_extent_block_csum_set(inode, neh);\n \t\tset_buffer_uptodate(bh);\n \t\tunlock_buffer(bh);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tsize_t ext_size = 0;",
                "\t/* zero out unused area in the extent block */",
                "\text_size = sizeof(struct ext4_extent_header) +",
                "\t\tsizeof(struct ext4_extent) * le16_to_cpu(neh->eh_entries);",
                "\tmemset(bh->b_data + ext_size, 0, inode->i_sb->s_blocksize - ext_size);",
                "\t\t/* zero out unused area in the extent block */",
                "\t\text_size = sizeof(struct ext4_extent_header) +",
                "\t\t   (sizeof(struct ext4_extent) * le16_to_cpu(neh->eh_entries));",
                "\t\tmemset(bh->b_data + ext_size, 0,",
                "\t\t\tinode->i_sb->s_blocksize - ext_size);"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-11833",
        "func_name": "torvalds/linux/ext4_ext_grow_indepth",
        "description": "fs/ext4/extents.c in the Linux kernel through 5.1.2 does not zero out the unused memory region in the extent tree block, which might allow local users to obtain sensitive information by reading uninitialized data in the filesystem.",
        "git_url": "https://github.com/torvalds/linux/commit/592acbf16821288ecdc4192c47e3774a4c48bb64",
        "commit_title": "ext4: zero out the unused memory region in the extent tree block",
        "commit_text": " This commit zeroes out the unused memory region in the buffer_head corresponding to the extent metablock after writing the extent header and the corresponding extent node entries.  This is done to prevent random uninitialized data from getting into the filesystem when the extent block is synced.  This fixes CVE-2019-11833.  Cc: stable@kernel.org",
        "func_before": "static int ext4_ext_grow_indepth(handle_t *handle, struct inode *inode,\n\t\t\t\t unsigned int flags)\n{\n\tstruct ext4_extent_header *neh;\n\tstruct buffer_head *bh;\n\text4_fsblk_t newblock, goal = 0;\n\tstruct ext4_super_block *es = EXT4_SB(inode->i_sb)->s_es;\n\tint err = 0;\n\n\t/* Try to prepend new index to old one */\n\tif (ext_depth(inode))\n\t\tgoal = ext4_idx_pblock(EXT_FIRST_INDEX(ext_inode_hdr(inode)));\n\tif (goal > le32_to_cpu(es->s_first_data_block)) {\n\t\tflags |= EXT4_MB_HINT_TRY_GOAL;\n\t\tgoal--;\n\t} else\n\t\tgoal = ext4_inode_to_goal_block(inode);\n\tnewblock = ext4_new_meta_blocks(handle, inode, goal, flags,\n\t\t\t\t\tNULL, &err);\n\tif (newblock == 0)\n\t\treturn err;\n\n\tbh = sb_getblk_gfp(inode->i_sb, newblock, __GFP_MOVABLE | GFP_NOFS);\n\tif (unlikely(!bh))\n\t\treturn -ENOMEM;\n\tlock_buffer(bh);\n\n\terr = ext4_journal_get_create_access(handle, bh);\n\tif (err) {\n\t\tunlock_buffer(bh);\n\t\tgoto out;\n\t}\n\n\t/* move top-level index/leaf into new block */\n\tmemmove(bh->b_data, EXT4_I(inode)->i_data,\n\t\tsizeof(EXT4_I(inode)->i_data));\n\n\t/* set size of new block */\n\tneh = ext_block_hdr(bh);\n\t/* old root could have indexes or leaves\n\t * so calculate e_max right way */\n\tif (ext_depth(inode))\n\t\tneh->eh_max = cpu_to_le16(ext4_ext_space_block_idx(inode, 0));\n\telse\n\t\tneh->eh_max = cpu_to_le16(ext4_ext_space_block(inode, 0));\n\tneh->eh_magic = EXT4_EXT_MAGIC;\n\text4_extent_block_csum_set(inode, neh);\n\tset_buffer_uptodate(bh);\n\tunlock_buffer(bh);\n\n\terr = ext4_handle_dirty_metadata(handle, inode, bh);\n\tif (err)\n\t\tgoto out;\n\n\t/* Update top-level index: num,max,pointer */\n\tneh = ext_inode_hdr(inode);\n\tneh->eh_entries = cpu_to_le16(1);\n\text4_idx_store_pblock(EXT_FIRST_INDEX(neh), newblock);\n\tif (neh->eh_depth == 0) {\n\t\t/* Root extent block becomes index block */\n\t\tneh->eh_max = cpu_to_le16(ext4_ext_space_root_idx(inode, 0));\n\t\tEXT_FIRST_INDEX(neh)->ei_block =\n\t\t\tEXT_FIRST_EXTENT(neh)->ee_block;\n\t}\n\text_debug(\"new root: num %d(%d), lblock %d, ptr %llu\\n\",\n\t\t  le16_to_cpu(neh->eh_entries), le16_to_cpu(neh->eh_max),\n\t\t  le32_to_cpu(EXT_FIRST_INDEX(neh)->ei_block),\n\t\t  ext4_idx_pblock(EXT_FIRST_INDEX(neh)));\n\n\tle16_add_cpu(&neh->eh_depth, 1);\n\text4_mark_inode_dirty(handle, inode);\nout:\n\tbrelse(bh);\n\n\treturn err;\n}",
        "func": "static int ext4_ext_grow_indepth(handle_t *handle, struct inode *inode,\n\t\t\t\t unsigned int flags)\n{\n\tstruct ext4_extent_header *neh;\n\tstruct buffer_head *bh;\n\text4_fsblk_t newblock, goal = 0;\n\tstruct ext4_super_block *es = EXT4_SB(inode->i_sb)->s_es;\n\tint err = 0;\n\tsize_t ext_size = 0;\n\n\t/* Try to prepend new index to old one */\n\tif (ext_depth(inode))\n\t\tgoal = ext4_idx_pblock(EXT_FIRST_INDEX(ext_inode_hdr(inode)));\n\tif (goal > le32_to_cpu(es->s_first_data_block)) {\n\t\tflags |= EXT4_MB_HINT_TRY_GOAL;\n\t\tgoal--;\n\t} else\n\t\tgoal = ext4_inode_to_goal_block(inode);\n\tnewblock = ext4_new_meta_blocks(handle, inode, goal, flags,\n\t\t\t\t\tNULL, &err);\n\tif (newblock == 0)\n\t\treturn err;\n\n\tbh = sb_getblk_gfp(inode->i_sb, newblock, __GFP_MOVABLE | GFP_NOFS);\n\tif (unlikely(!bh))\n\t\treturn -ENOMEM;\n\tlock_buffer(bh);\n\n\terr = ext4_journal_get_create_access(handle, bh);\n\tif (err) {\n\t\tunlock_buffer(bh);\n\t\tgoto out;\n\t}\n\n\text_size = sizeof(EXT4_I(inode)->i_data);\n\t/* move top-level index/leaf into new block */\n\tmemmove(bh->b_data, EXT4_I(inode)->i_data, ext_size);\n\t/* zero out unused area in the extent block */\n\tmemset(bh->b_data + ext_size, 0, inode->i_sb->s_blocksize - ext_size);\n\n\t/* set size of new block */\n\tneh = ext_block_hdr(bh);\n\t/* old root could have indexes or leaves\n\t * so calculate e_max right way */\n\tif (ext_depth(inode))\n\t\tneh->eh_max = cpu_to_le16(ext4_ext_space_block_idx(inode, 0));\n\telse\n\t\tneh->eh_max = cpu_to_le16(ext4_ext_space_block(inode, 0));\n\tneh->eh_magic = EXT4_EXT_MAGIC;\n\text4_extent_block_csum_set(inode, neh);\n\tset_buffer_uptodate(bh);\n\tunlock_buffer(bh);\n\n\terr = ext4_handle_dirty_metadata(handle, inode, bh);\n\tif (err)\n\t\tgoto out;\n\n\t/* Update top-level index: num,max,pointer */\n\tneh = ext_inode_hdr(inode);\n\tneh->eh_entries = cpu_to_le16(1);\n\text4_idx_store_pblock(EXT_FIRST_INDEX(neh), newblock);\n\tif (neh->eh_depth == 0) {\n\t\t/* Root extent block becomes index block */\n\t\tneh->eh_max = cpu_to_le16(ext4_ext_space_root_idx(inode, 0));\n\t\tEXT_FIRST_INDEX(neh)->ei_block =\n\t\t\tEXT_FIRST_EXTENT(neh)->ee_block;\n\t}\n\text_debug(\"new root: num %d(%d), lblock %d, ptr %llu\\n\",\n\t\t  le16_to_cpu(neh->eh_entries), le16_to_cpu(neh->eh_max),\n\t\t  le32_to_cpu(EXT_FIRST_INDEX(neh)->ei_block),\n\t\t  ext4_idx_pblock(EXT_FIRST_INDEX(neh)));\n\n\tle16_add_cpu(&neh->eh_depth, 1);\n\text4_mark_inode_dirty(handle, inode);\nout:\n\tbrelse(bh);\n\n\treturn err;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -6,6 +6,7 @@\n \text4_fsblk_t newblock, goal = 0;\n \tstruct ext4_super_block *es = EXT4_SB(inode->i_sb)->s_es;\n \tint err = 0;\n+\tsize_t ext_size = 0;\n \n \t/* Try to prepend new index to old one */\n \tif (ext_depth(inode))\n@@ -31,9 +32,11 @@\n \t\tgoto out;\n \t}\n \n+\text_size = sizeof(EXT4_I(inode)->i_data);\n \t/* move top-level index/leaf into new block */\n-\tmemmove(bh->b_data, EXT4_I(inode)->i_data,\n-\t\tsizeof(EXT4_I(inode)->i_data));\n+\tmemmove(bh->b_data, EXT4_I(inode)->i_data, ext_size);\n+\t/* zero out unused area in the extent block */\n+\tmemset(bh->b_data + ext_size, 0, inode->i_sb->s_blocksize - ext_size);\n \n \t/* set size of new block */\n \tneh = ext_block_hdr(bh);",
        "diff_line_info": {
            "deleted_lines": [
                "\tmemmove(bh->b_data, EXT4_I(inode)->i_data,",
                "\t\tsizeof(EXT4_I(inode)->i_data));"
            ],
            "added_lines": [
                "\tsize_t ext_size = 0;",
                "\text_size = sizeof(EXT4_I(inode)->i_data);",
                "\tmemmove(bh->b_data, EXT4_I(inode)->i_data, ext_size);",
                "\t/* zero out unused area in the extent block */",
                "\tmemset(bh->b_data + ext_size, 0, inode->i_sb->s_blocksize - ext_size);"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-12730",
        "func_name": "ffmpeg/aa_read_header",
        "description": "aa_read_header in libavformat/aadec.c in FFmpeg before 3.2.14 and 4.x before 4.1.4 does not check for sscanf failure and consequently allows use of uninitialized variables.",
        "git_url": "https://github.com/FFmpeg/FFmpeg/commit/ed188f6dcdf0935c939ed813cf8745d50742014b",
        "commit_title": "avformat/aadec: Check for scanf() failure",
        "commit_text": " ",
        "func_before": "static int aa_read_header(AVFormatContext *s)\n{\n    int i, j, idx, largest_idx = -1;\n    uint32_t nkey, nval, toc_size, npairs, header_seed = 0, start;\n    char key[128], val[128], codec_name[64] = {0};\n    uint8_t output[24], dst[8], src[8];\n    int64_t largest_size = -1, current_size = -1, chapter_pos;\n    struct toc_entry {\n        uint32_t offset;\n        uint32_t size;\n    } TOC[MAX_TOC_ENTRIES];\n    uint32_t header_key_part[4];\n    uint8_t header_key[16] = {0};\n    AADemuxContext *c = s->priv_data;\n    AVIOContext *pb = s->pb;\n    AVStream *st;\n\n    /* parse .aa header */\n    avio_skip(pb, 4); // file size\n    avio_skip(pb, 4); // magic string\n    toc_size = avio_rb32(pb); // TOC size\n    avio_skip(pb, 4); // unidentified integer\n    if (toc_size > MAX_TOC_ENTRIES)\n        return AVERROR_INVALIDDATA;\n    for (i = 0; i < toc_size; i++) { // read TOC\n        avio_skip(pb, 4); // TOC entry index\n        TOC[i].offset = avio_rb32(pb); // block offset\n        TOC[i].size = avio_rb32(pb); // block size\n    }\n    avio_skip(pb, 24); // header termination block (ignored)\n    npairs = avio_rb32(pb); // read dictionary entries\n    if (npairs > MAX_DICTIONARY_ENTRIES)\n        return AVERROR_INVALIDDATA;\n    for (i = 0; i < npairs; i++) {\n        memset(val, 0, sizeof(val));\n        memset(key, 0, sizeof(key));\n        avio_skip(pb, 1); // unidentified integer\n        nkey = avio_rb32(pb); // key string length\n        nval = avio_rb32(pb); // value string length\n        avio_get_str(pb, nkey, key, sizeof(key));\n        avio_get_str(pb, nval, val, sizeof(val));\n        if (!strcmp(key, \"codec\")) {\n            av_log(s, AV_LOG_DEBUG, \"Codec is <%s>\\n\", val);\n            strncpy(codec_name, val, sizeof(codec_name) - 1);\n        } else if (!strcmp(key, \"HeaderSeed\")) {\n            av_log(s, AV_LOG_DEBUG, \"HeaderSeed is <%s>\\n\", val);\n            header_seed = atoi(val);\n        } else if (!strcmp(key, \"HeaderKey\")) { // this looks like \"1234567890 1234567890 1234567890 1234567890\"\n            av_log(s, AV_LOG_DEBUG, \"HeaderKey is <%s>\\n\", val);\n            sscanf(val, \"%\"SCNu32\"%\"SCNu32\"%\"SCNu32\"%\"SCNu32,\n                   &header_key_part[0], &header_key_part[1], &header_key_part[2], &header_key_part[3]);\n            for (idx = 0; idx < 4; idx++) {\n                AV_WB32(&header_key[idx * 4], header_key_part[idx]); // convert each part to BE!\n            }\n            av_log(s, AV_LOG_DEBUG, \"Processed HeaderKey is \");\n            for (i = 0; i < 16; i++)\n                av_log(s, AV_LOG_DEBUG, \"%02x\", header_key[i]);\n            av_log(s, AV_LOG_DEBUG, \"\\n\");\n        } else {\n            av_dict_set(&s->metadata, key, val, 0);\n        }\n    }\n\n    /* verify fixed key */\n    if (c->aa_fixed_key_len != 16) {\n        av_log(s, AV_LOG_ERROR, \"aa_fixed_key value needs to be 16 bytes!\\n\");\n        return AVERROR(EINVAL);\n    }\n\n    /* verify codec */\n    if ((c->codec_second_size = get_second_size(codec_name)) == -1) {\n        av_log(s, AV_LOG_ERROR, \"unknown codec <%s>!\\n\", codec_name);\n        return AVERROR(EINVAL);\n    }\n\n    /* decryption key derivation */\n    c->tea_ctx = av_tea_alloc();\n    if (!c->tea_ctx)\n        return AVERROR(ENOMEM);\n    av_tea_init(c->tea_ctx, c->aa_fixed_key, 16);\n    output[0] = output[1] = 0; // purely for padding purposes\n    memcpy(output + 2, header_key, 16);\n    idx = 0;\n    for (i = 0; i < 3; i++) { // TEA CBC with weird mixed endianness\n        AV_WB32(src, header_seed);\n        AV_WB32(src + 4, header_seed + 1);\n        header_seed += 2;\n        av_tea_crypt(c->tea_ctx, dst, src, 1, NULL, 0); // TEA ECB encrypt\n        for (j = 0; j < TEA_BLOCK_SIZE && idx < 18; j+=1, idx+=1) {\n            output[idx] = output[idx] ^ dst[j];\n        }\n    }\n    memcpy(c->file_key, output + 2, 16); // skip first 2 bytes of output\n    av_log(s, AV_LOG_DEBUG, \"File key is \");\n    for (i = 0; i < 16; i++)\n        av_log(s, AV_LOG_DEBUG, \"%02x\", c->file_key[i]);\n    av_log(s, AV_LOG_DEBUG, \"\\n\");\n\n    /* decoder setup */\n    st = avformat_new_stream(s, NULL);\n    if (!st) {\n        av_freep(&c->tea_ctx);\n        return AVERROR(ENOMEM);\n    }\n    st->codecpar->codec_type = AVMEDIA_TYPE_AUDIO;\n    if (!strcmp(codec_name, \"mp332\")) {\n        st->codecpar->codec_id = AV_CODEC_ID_MP3;\n        st->codecpar->sample_rate = 22050;\n        st->need_parsing = AVSTREAM_PARSE_FULL_RAW;\n        avpriv_set_pts_info(st, 64, 8, 32000 * TIMEPREC);\n        // encoded audio frame is MP3_FRAME_SIZE bytes (+1 with padding, unlikely)\n    } else if (!strcmp(codec_name, \"acelp85\")) {\n        st->codecpar->codec_id = AV_CODEC_ID_SIPR;\n        st->codecpar->block_align = 19;\n        st->codecpar->channels = 1;\n        st->codecpar->sample_rate = 8500;\n        st->codecpar->bit_rate = 8500;\n        st->need_parsing = AVSTREAM_PARSE_FULL_RAW;\n        avpriv_set_pts_info(st, 64, 8, 8500 * TIMEPREC);\n    } else if (!strcmp(codec_name, \"acelp16\")) {\n        st->codecpar->codec_id = AV_CODEC_ID_SIPR;\n        st->codecpar->block_align = 20;\n        st->codecpar->channels = 1;\n        st->codecpar->sample_rate = 16000;\n        st->codecpar->bit_rate = 16000;\n        st->need_parsing = AVSTREAM_PARSE_FULL_RAW;\n        avpriv_set_pts_info(st, 64, 8, 16000 * TIMEPREC);\n    }\n\n    /* determine, and jump to audio start offset */\n    for (i = 1; i < toc_size; i++) { // skip the first entry!\n        current_size = TOC[i].size;\n        if (current_size > largest_size) {\n            largest_idx = i;\n            largest_size = current_size;\n        }\n    }\n    start = TOC[largest_idx].offset;\n    avio_seek(pb, start, SEEK_SET);\n\n    // extract chapter positions. since all formats have constant bit rate, use it\n    // as time base in bytes/s, for easy stream position <-> timestamp conversion\n    st->start_time = 0;\n    c->content_start = start;\n    c->content_end = start + largest_size;\n\n    while ((chapter_pos = avio_tell(pb)) >= 0 && chapter_pos < c->content_end) {\n        int chapter_idx = s->nb_chapters;\n        uint32_t chapter_size = avio_rb32(pb);\n        if (chapter_size == 0) break;\n        chapter_pos -= start + CHAPTER_HEADER_SIZE * chapter_idx;\n        avio_skip(pb, 4 + chapter_size);\n        if (!avpriv_new_chapter(s, chapter_idx, st->time_base,\n            chapter_pos * TIMEPREC, (chapter_pos + chapter_size) * TIMEPREC, NULL))\n                return AVERROR(ENOMEM);\n    }\n\n    st->duration = (largest_size - CHAPTER_HEADER_SIZE * s->nb_chapters) * TIMEPREC;\n\n    ff_update_cur_dts(s, st, 0);\n    avio_seek(pb, start, SEEK_SET);\n    c->current_chapter_size = 0;\n    c->seek_offset = 0;\n\n    return 0;\n}",
        "func": "static int aa_read_header(AVFormatContext *s)\n{\n    int i, j, idx, largest_idx = -1;\n    uint32_t nkey, nval, toc_size, npairs, header_seed = 0, start;\n    char key[128], val[128], codec_name[64] = {0};\n    uint8_t output[24], dst[8], src[8];\n    int64_t largest_size = -1, current_size = -1, chapter_pos;\n    struct toc_entry {\n        uint32_t offset;\n        uint32_t size;\n    } TOC[MAX_TOC_ENTRIES];\n    uint32_t header_key_part[4];\n    uint8_t header_key[16] = {0};\n    AADemuxContext *c = s->priv_data;\n    AVIOContext *pb = s->pb;\n    AVStream *st;\n    int ret;\n\n    /* parse .aa header */\n    avio_skip(pb, 4); // file size\n    avio_skip(pb, 4); // magic string\n    toc_size = avio_rb32(pb); // TOC size\n    avio_skip(pb, 4); // unidentified integer\n    if (toc_size > MAX_TOC_ENTRIES)\n        return AVERROR_INVALIDDATA;\n    for (i = 0; i < toc_size; i++) { // read TOC\n        avio_skip(pb, 4); // TOC entry index\n        TOC[i].offset = avio_rb32(pb); // block offset\n        TOC[i].size = avio_rb32(pb); // block size\n    }\n    avio_skip(pb, 24); // header termination block (ignored)\n    npairs = avio_rb32(pb); // read dictionary entries\n    if (npairs > MAX_DICTIONARY_ENTRIES)\n        return AVERROR_INVALIDDATA;\n    for (i = 0; i < npairs; i++) {\n        memset(val, 0, sizeof(val));\n        memset(key, 0, sizeof(key));\n        avio_skip(pb, 1); // unidentified integer\n        nkey = avio_rb32(pb); // key string length\n        nval = avio_rb32(pb); // value string length\n        avio_get_str(pb, nkey, key, sizeof(key));\n        avio_get_str(pb, nval, val, sizeof(val));\n        if (!strcmp(key, \"codec\")) {\n            av_log(s, AV_LOG_DEBUG, \"Codec is <%s>\\n\", val);\n            strncpy(codec_name, val, sizeof(codec_name) - 1);\n        } else if (!strcmp(key, \"HeaderSeed\")) {\n            av_log(s, AV_LOG_DEBUG, \"HeaderSeed is <%s>\\n\", val);\n            header_seed = atoi(val);\n        } else if (!strcmp(key, \"HeaderKey\")) { // this looks like \"1234567890 1234567890 1234567890 1234567890\"\n            av_log(s, AV_LOG_DEBUG, \"HeaderKey is <%s>\\n\", val);\n\n            ret = sscanf(val, \"%\"SCNu32\"%\"SCNu32\"%\"SCNu32\"%\"SCNu32,\n                   &header_key_part[0], &header_key_part[1], &header_key_part[2], &header_key_part[3]);\n            if (ret != 4)\n                return AVERROR_INVALIDDATA;\n\n            for (idx = 0; idx < 4; idx++) {\n                AV_WB32(&header_key[idx * 4], header_key_part[idx]); // convert each part to BE!\n            }\n            av_log(s, AV_LOG_DEBUG, \"Processed HeaderKey is \");\n            for (i = 0; i < 16; i++)\n                av_log(s, AV_LOG_DEBUG, \"%02x\", header_key[i]);\n            av_log(s, AV_LOG_DEBUG, \"\\n\");\n        } else {\n            av_dict_set(&s->metadata, key, val, 0);\n        }\n    }\n\n    /* verify fixed key */\n    if (c->aa_fixed_key_len != 16) {\n        av_log(s, AV_LOG_ERROR, \"aa_fixed_key value needs to be 16 bytes!\\n\");\n        return AVERROR(EINVAL);\n    }\n\n    /* verify codec */\n    if ((c->codec_second_size = get_second_size(codec_name)) == -1) {\n        av_log(s, AV_LOG_ERROR, \"unknown codec <%s>!\\n\", codec_name);\n        return AVERROR(EINVAL);\n    }\n\n    /* decryption key derivation */\n    c->tea_ctx = av_tea_alloc();\n    if (!c->tea_ctx)\n        return AVERROR(ENOMEM);\n    av_tea_init(c->tea_ctx, c->aa_fixed_key, 16);\n    output[0] = output[1] = 0; // purely for padding purposes\n    memcpy(output + 2, header_key, 16);\n    idx = 0;\n    for (i = 0; i < 3; i++) { // TEA CBC with weird mixed endianness\n        AV_WB32(src, header_seed);\n        AV_WB32(src + 4, header_seed + 1);\n        header_seed += 2;\n        av_tea_crypt(c->tea_ctx, dst, src, 1, NULL, 0); // TEA ECB encrypt\n        for (j = 0; j < TEA_BLOCK_SIZE && idx < 18; j+=1, idx+=1) {\n            output[idx] = output[idx] ^ dst[j];\n        }\n    }\n    memcpy(c->file_key, output + 2, 16); // skip first 2 bytes of output\n    av_log(s, AV_LOG_DEBUG, \"File key is \");\n    for (i = 0; i < 16; i++)\n        av_log(s, AV_LOG_DEBUG, \"%02x\", c->file_key[i]);\n    av_log(s, AV_LOG_DEBUG, \"\\n\");\n\n    /* decoder setup */\n    st = avformat_new_stream(s, NULL);\n    if (!st) {\n        av_freep(&c->tea_ctx);\n        return AVERROR(ENOMEM);\n    }\n    st->codecpar->codec_type = AVMEDIA_TYPE_AUDIO;\n    if (!strcmp(codec_name, \"mp332\")) {\n        st->codecpar->codec_id = AV_CODEC_ID_MP3;\n        st->codecpar->sample_rate = 22050;\n        st->need_parsing = AVSTREAM_PARSE_FULL_RAW;\n        avpriv_set_pts_info(st, 64, 8, 32000 * TIMEPREC);\n        // encoded audio frame is MP3_FRAME_SIZE bytes (+1 with padding, unlikely)\n    } else if (!strcmp(codec_name, \"acelp85\")) {\n        st->codecpar->codec_id = AV_CODEC_ID_SIPR;\n        st->codecpar->block_align = 19;\n        st->codecpar->channels = 1;\n        st->codecpar->sample_rate = 8500;\n        st->codecpar->bit_rate = 8500;\n        st->need_parsing = AVSTREAM_PARSE_FULL_RAW;\n        avpriv_set_pts_info(st, 64, 8, 8500 * TIMEPREC);\n    } else if (!strcmp(codec_name, \"acelp16\")) {\n        st->codecpar->codec_id = AV_CODEC_ID_SIPR;\n        st->codecpar->block_align = 20;\n        st->codecpar->channels = 1;\n        st->codecpar->sample_rate = 16000;\n        st->codecpar->bit_rate = 16000;\n        st->need_parsing = AVSTREAM_PARSE_FULL_RAW;\n        avpriv_set_pts_info(st, 64, 8, 16000 * TIMEPREC);\n    }\n\n    /* determine, and jump to audio start offset */\n    for (i = 1; i < toc_size; i++) { // skip the first entry!\n        current_size = TOC[i].size;\n        if (current_size > largest_size) {\n            largest_idx = i;\n            largest_size = current_size;\n        }\n    }\n    start = TOC[largest_idx].offset;\n    avio_seek(pb, start, SEEK_SET);\n\n    // extract chapter positions. since all formats have constant bit rate, use it\n    // as time base in bytes/s, for easy stream position <-> timestamp conversion\n    st->start_time = 0;\n    c->content_start = start;\n    c->content_end = start + largest_size;\n\n    while ((chapter_pos = avio_tell(pb)) >= 0 && chapter_pos < c->content_end) {\n        int chapter_idx = s->nb_chapters;\n        uint32_t chapter_size = avio_rb32(pb);\n        if (chapter_size == 0) break;\n        chapter_pos -= start + CHAPTER_HEADER_SIZE * chapter_idx;\n        avio_skip(pb, 4 + chapter_size);\n        if (!avpriv_new_chapter(s, chapter_idx, st->time_base,\n            chapter_pos * TIMEPREC, (chapter_pos + chapter_size) * TIMEPREC, NULL))\n                return AVERROR(ENOMEM);\n    }\n\n    st->duration = (largest_size - CHAPTER_HEADER_SIZE * s->nb_chapters) * TIMEPREC;\n\n    ff_update_cur_dts(s, st, 0);\n    avio_seek(pb, start, SEEK_SET);\n    c->current_chapter_size = 0;\n    c->seek_offset = 0;\n\n    return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -14,6 +14,7 @@\n     AADemuxContext *c = s->priv_data;\n     AVIOContext *pb = s->pb;\n     AVStream *st;\n+    int ret;\n \n     /* parse .aa header */\n     avio_skip(pb, 4); // file size\n@@ -47,8 +48,12 @@\n             header_seed = atoi(val);\n         } else if (!strcmp(key, \"HeaderKey\")) { // this looks like \"1234567890 1234567890 1234567890 1234567890\"\n             av_log(s, AV_LOG_DEBUG, \"HeaderKey is <%s>\\n\", val);\n-            sscanf(val, \"%\"SCNu32\"%\"SCNu32\"%\"SCNu32\"%\"SCNu32,\n+\n+            ret = sscanf(val, \"%\"SCNu32\"%\"SCNu32\"%\"SCNu32\"%\"SCNu32,\n                    &header_key_part[0], &header_key_part[1], &header_key_part[2], &header_key_part[3]);\n+            if (ret != 4)\n+                return AVERROR_INVALIDDATA;\n+\n             for (idx = 0; idx < 4; idx++) {\n                 AV_WB32(&header_key[idx * 4], header_key_part[idx]); // convert each part to BE!\n             }",
        "diff_line_info": {
            "deleted_lines": [
                "            sscanf(val, \"%\"SCNu32\"%\"SCNu32\"%\"SCNu32\"%\"SCNu32,"
            ],
            "added_lines": [
                "    int ret;",
                "",
                "            ret = sscanf(val, \"%\"SCNu32\"%\"SCNu32\"%\"SCNu32\"%\"SCNu32,",
                "            if (ret != 4)",
                "                return AVERROR_INVALIDDATA;",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2019-11038",
        "func_name": "php/php-src/gdImageCreateFromXbm",
        "description": "When using the gdImageCreateFromXbm() function in the GD Graphics Library (aka LibGD) 2.2.5, as used in the PHP GD extension in PHP versions 7.1.x below 7.1.30, 7.2.x below 7.2.19 and 7.3.x below 7.3.6, it is possible to supply data that will cause the function to use the value of uninitialized variable. This may lead to disclosing contents of the stack that has been left there by previous code.",
        "git_url": "https://github.com/php/php-src/commit/903b1828dcd68f7cf8b9177a3fe6f481bf627ba9",
        "commit_title": "Fix #77973: Uninitialized read in gdImageCreateFromXbm",
        "commit_text": " We have to ensure that `sscanf()` does indeed read a hex value here, and bail out otherwise.  (cherry picked from commit ed6dee9a198c904ad5e03113e58a2d2c200f5184)",
        "func_before": "gdImagePtr gdImageCreateFromXbm(FILE * fd)\n{\n\tchar fline[MAX_XBM_LINE_SIZE];\n\tchar iname[MAX_XBM_LINE_SIZE];\n\tchar *type;\n\tint value;\n\tunsigned int width = 0, height = 0;\n\tint fail = 0;\n\tint max_bit = 0;\n\n\tgdImagePtr im;\n\tint bytes = 0, i;\n\tint bit, x = 0, y = 0;\n\tint ch;\n\tchar h[8];\n\tunsigned int b;\n\n\trewind(fd);\n\twhile (fgets(fline, MAX_XBM_LINE_SIZE, fd)) {\n\t\tfline[MAX_XBM_LINE_SIZE-1] = '\\0';\n\t\tif (strlen(fline) == MAX_XBM_LINE_SIZE-1) {\n\t\t\treturn 0;\n\t\t}\n\t\tif (sscanf(fline, \"#define %s %d\", iname, &value) == 2) {\n\t\t\tif (!(type = strrchr(iname, '_'))) {\n\t\t\t\ttype = iname;\n\t\t\t} else {\n\t\t\t\ttype++;\n\t\t\t}\n\n\t\t\tif (!strcmp(\"width\", type)) {\n\t\t\t\twidth = (unsigned int) value;\n\t\t\t}\n\t\t\tif (!strcmp(\"height\", type)) {\n\t\t\t\theight = (unsigned int) value;\n\t\t\t}\n\t\t} else {\n\t\t\tif ( sscanf(fline, \"static unsigned char %s = {\", iname) == 1\n\t\t\t  || sscanf(fline, \"static char %s = {\", iname) == 1)\n\t\t\t{\n\t\t\t\tmax_bit = 128;\n\t\t\t} else if (sscanf(fline, \"static unsigned short %s = {\", iname) == 1\n\t\t\t\t\t|| sscanf(fline, \"static short %s = {\", iname) == 1)\n\t\t\t{\n\t\t\t\tmax_bit = 32768;\n\t\t\t}\n\t\t\tif (max_bit) {\n\t\t\t\tbytes = (width + 7) / 8 * height;\n\t\t\t\tif (!bytes) {\n\t\t\t\t\treturn 0;\n\t\t\t\t}\n\t\t\t\tif (!(type = strrchr(iname, '_'))) {\n\t\t\t\t\ttype = iname;\n\t\t\t\t} else {\n\t\t\t\t\ttype++;\n\t\t\t\t}\n\t\t\t\tif (!strcmp(\"bits[]\", type)) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n \t\t}\n\t}\n\tif (!bytes || !max_bit) {\n\t\treturn 0;\n\t}\n\n\tif(!(im = gdImageCreate(width, height))) {\n\t\treturn 0;\n\t}\n\tgdImageColorAllocate(im, 255, 255, 255);\n\tgdImageColorAllocate(im, 0, 0, 0);\n\th[2] = '\\0';\n\th[4] = '\\0';\n\tfor (i = 0; i < bytes; i++) {\n\t\twhile (1) {\n\t\t\tif ((ch=getc(fd)) == EOF) {\n\t\t\t\tfail = 1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (ch == 'x') {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tif (fail) {\n\t\t\tbreak;\n\t\t}\n\t\t/* Get hex value */\n\t\tif ((ch=getc(fd)) == EOF) {\n\t\t\tbreak;\n\t\t}\n\t\th[0] = ch;\n\t\tif ((ch=getc(fd)) == EOF) {\n\t\t\tbreak;\n\t\t}\n\t\th[1] = ch;\n\t\tif (max_bit == 32768) {\n\t\t\tif ((ch=getc(fd)) == EOF) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\th[2] = ch;\n\t\t\tif ((ch=getc(fd)) == EOF) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\th[3] = ch;\n\t\t}\n\t\tsscanf(h, \"%x\", &b);\n\t\tfor (bit = 1; bit <= max_bit; bit = bit << 1) {\n\t\t\tgdImageSetPixel(im, x++, y, (b & bit) ? 1 : 0);\n\t\t\tif (x == im->sx) {\n\t\t\t\tx = 0;\n\t\t\t\ty++;\n\t\t\t\tif (y == im->sy) {\n\t\t\t\t\treturn im;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\tgd_error(\"EOF before image was complete\");\n\tgdImageDestroy(im);\n\treturn 0;\n}",
        "func": "gdImagePtr gdImageCreateFromXbm(FILE * fd)\n{\n\tchar fline[MAX_XBM_LINE_SIZE];\n\tchar iname[MAX_XBM_LINE_SIZE];\n\tchar *type;\n\tint value;\n\tunsigned int width = 0, height = 0;\n\tint fail = 0;\n\tint max_bit = 0;\n\n\tgdImagePtr im;\n\tint bytes = 0, i;\n\tint bit, x = 0, y = 0;\n\tint ch;\n\tchar h[8];\n\tunsigned int b;\n\n\trewind(fd);\n\twhile (fgets(fline, MAX_XBM_LINE_SIZE, fd)) {\n\t\tfline[MAX_XBM_LINE_SIZE-1] = '\\0';\n\t\tif (strlen(fline) == MAX_XBM_LINE_SIZE-1) {\n\t\t\treturn 0;\n\t\t}\n\t\tif (sscanf(fline, \"#define %s %d\", iname, &value) == 2) {\n\t\t\tif (!(type = strrchr(iname, '_'))) {\n\t\t\t\ttype = iname;\n\t\t\t} else {\n\t\t\t\ttype++;\n\t\t\t}\n\n\t\t\tif (!strcmp(\"width\", type)) {\n\t\t\t\twidth = (unsigned int) value;\n\t\t\t}\n\t\t\tif (!strcmp(\"height\", type)) {\n\t\t\t\theight = (unsigned int) value;\n\t\t\t}\n\t\t} else {\n\t\t\tif ( sscanf(fline, \"static unsigned char %s = {\", iname) == 1\n\t\t\t  || sscanf(fline, \"static char %s = {\", iname) == 1)\n\t\t\t{\n\t\t\t\tmax_bit = 128;\n\t\t\t} else if (sscanf(fline, \"static unsigned short %s = {\", iname) == 1\n\t\t\t\t\t|| sscanf(fline, \"static short %s = {\", iname) == 1)\n\t\t\t{\n\t\t\t\tmax_bit = 32768;\n\t\t\t}\n\t\t\tif (max_bit) {\n\t\t\t\tbytes = (width + 7) / 8 * height;\n\t\t\t\tif (!bytes) {\n\t\t\t\t\treturn 0;\n\t\t\t\t}\n\t\t\t\tif (!(type = strrchr(iname, '_'))) {\n\t\t\t\t\ttype = iname;\n\t\t\t\t} else {\n\t\t\t\t\ttype++;\n\t\t\t\t}\n\t\t\t\tif (!strcmp(\"bits[]\", type)) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n \t\t}\n\t}\n\tif (!bytes || !max_bit) {\n\t\treturn 0;\n\t}\n\n\tif(!(im = gdImageCreate(width, height))) {\n\t\treturn 0;\n\t}\n\tgdImageColorAllocate(im, 255, 255, 255);\n\tgdImageColorAllocate(im, 0, 0, 0);\n\th[2] = '\\0';\n\th[4] = '\\0';\n\tfor (i = 0; i < bytes; i++) {\n\t\twhile (1) {\n\t\t\tif ((ch=getc(fd)) == EOF) {\n\t\t\t\tfail = 1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (ch == 'x') {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tif (fail) {\n\t\t\tbreak;\n\t\t}\n\t\t/* Get hex value */\n\t\tif ((ch=getc(fd)) == EOF) {\n\t\t\tbreak;\n\t\t}\n\t\th[0] = ch;\n\t\tif ((ch=getc(fd)) == EOF) {\n\t\t\tbreak;\n\t\t}\n\t\th[1] = ch;\n\t\tif (max_bit == 32768) {\n\t\t\tif ((ch=getc(fd)) == EOF) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\th[2] = ch;\n\t\t\tif ((ch=getc(fd)) == EOF) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\th[3] = ch;\n\t\t}\n\t\tif (sscanf(h, \"%x\", &b) != 1) {\n\t\t\tgd_error(\"invalid XBM\");\n\t\t\tgdImageDestroy(im);\n\t\t\treturn 0;\n\t\t}\n\t\tfor (bit = 1; bit <= max_bit; bit = bit << 1) {\n\t\t\tgdImageSetPixel(im, x++, y, (b & bit) ? 1 : 0);\n\t\t\tif (x == im->sx) {\n\t\t\t\tx = 0;\n\t\t\t\ty++;\n\t\t\t\tif (y == im->sy) {\n\t\t\t\t\treturn im;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\tgd_error(\"EOF before image was complete\");\n\tgdImageDestroy(im);\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -103,7 +103,11 @@\n \t\t\t}\n \t\t\th[3] = ch;\n \t\t}\n-\t\tsscanf(h, \"%x\", &b);\n+\t\tif (sscanf(h, \"%x\", &b) != 1) {\n+\t\t\tgd_error(\"invalid XBM\");\n+\t\t\tgdImageDestroy(im);\n+\t\t\treturn 0;\n+\t\t}\n \t\tfor (bit = 1; bit <= max_bit; bit = bit << 1) {\n \t\t\tgdImageSetPixel(im, x++, y, (b & bit) ? 1 : 0);\n \t\t\tif (x == im->sx) {",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tsscanf(h, \"%x\", &b);"
            ],
            "added_lines": [
                "\t\tif (sscanf(h, \"%x\", &b) != 1) {",
                "\t\t\tgd_error(\"invalid XBM\");",
                "\t\t\tgdImageDestroy(im);",
                "\t\t\treturn 0;",
                "\t\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-11038",
        "func_name": "libgd/gdImageCreateFromXbm",
        "description": "When using the gdImageCreateFromXbm() function in the GD Graphics Library (aka LibGD) 2.2.5, as used in the PHP GD extension in PHP versions 7.1.x below 7.1.30, 7.2.x below 7.2.19 and 7.3.x below 7.3.6, it is possible to supply data that will cause the function to use the value of uninitialized variable. This may lead to disclosing contents of the stack that has been left there by previous code.",
        "git_url": "https://github.com/libgd/libgd/commit/e13a342c079aeb73e31dfa19eaca119761bac3f3",
        "commit_title": "Fix #501: Uninitialized read in gdImageCreateFromXbm (CVE-2019-11038)",
        "commit_text": " Bug-Debian-Security: https://security-tracker.debian.org/tracker/CVE-2019-11038 Bug-Debian: https://bugs.debian.org/929821 Bug: https://github.com/libgd/libgd/issues/501  We have to ensure that `sscanf()` does indeed read a hex value here, and bail out otherwise.  Original patch by Christoph M. Becker <cmbecker69@gmx.de> for PHP libgd ext. https://git.php.net/?p=php-src.git;a=commit;h=ed6dee9a198c904ad5e03113e58a2d2c200f5184",
        "func_before": "BGD_DECLARE(gdImagePtr) gdImageCreateFromXbm(FILE * fd)\n{\n\tchar fline[MAX_XBM_LINE_SIZE];\n\tchar iname[MAX_XBM_LINE_SIZE];\n\tchar *type;\n\tint value;\n\tunsigned int width = 0, height = 0;\n\tint fail = 0;\n\tint max_bit = 0;\n\n\tgdImagePtr im;\n\tint bytes = 0, i;\n\tint bit, x = 0, y = 0;\n\tint ch;\n\tchar h[8];\n\tunsigned int b;\n\n\trewind(fd);\n\twhile (fgets(fline, MAX_XBM_LINE_SIZE, fd)) {\n\t\tfline[MAX_XBM_LINE_SIZE-1] = '\\0';\n\t\tif (strlen(fline) == MAX_XBM_LINE_SIZE-1) {\n\t\t\treturn 0;\n\t\t}\n\t\tif (sscanf(fline, \"#define %s %d\", iname, &value) == 2) {\n\t\t\tif (!(type = strrchr(iname, '_'))) {\n\t\t\t\ttype = iname;\n\t\t\t} else {\n\t\t\t\ttype++;\n\t\t\t}\n\n\t\t\tif (!strcmp(\"width\", type)) {\n\t\t\t\twidth = (unsigned int) value;\n\t\t\t}\n\t\t\tif (!strcmp(\"height\", type)) {\n\t\t\t\theight = (unsigned int) value;\n\t\t\t}\n\t\t} else {\n\t\t\tif ( sscanf(fline, \"static unsigned char %s = {\", iname) == 1\n\t\t\t  || sscanf(fline, \"static char %s = {\", iname) == 1)\n\t\t\t{\n\t\t\t\tmax_bit = 128;\n\t\t\t} else if (sscanf(fline, \"static unsigned short %s = {\", iname) == 1\n\t\t\t\t\t|| sscanf(fline, \"static short %s = {\", iname) == 1)\n\t\t\t{\n\t\t\t\tmax_bit = 32768;\n\t\t\t}\n\t\t\tif (max_bit) {\n                bytes = (width + 7) / 8 * height;\n\t\t\t\tif (!bytes) {\n\t\t\t\t\treturn 0;\n\t\t\t\t}\n\t\t\t\tif (!(type = strrchr(iname, '_'))) {\n\t\t\t\t\ttype = iname;\n\t\t\t\t} else {\n\t\t\t\t\ttype++;\n\t\t\t\t}\n\t\t\t\tif (!strcmp(\"bits[]\", type)) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n \t\t}\n\t}\n\tif (!bytes || !max_bit) {\n\t\treturn 0;\n\t}\n\n\tif(!(im = gdImageCreate(width, height))) {\n\t\treturn 0;\n\t}\n\tgdImageColorAllocate(im, 255, 255, 255);\n\tgdImageColorAllocate(im, 0, 0, 0);\n\th[2] = '\\0';\n\th[4] = '\\0';\n\tfor (i = 0; i < bytes; i++) {\n\t\twhile (1) {\n\t\t\tif ((ch=getc(fd)) == EOF) {\n\t\t\t\tfail = 1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (ch == 'x') {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tif (fail) {\n\t\t\tbreak;\n\t\t}\n\t\t/* Get hex value */\n\t\tif ((ch=getc(fd)) == EOF) {\n\t\t\tbreak;\n\t\t}\n\t\th[0] = ch;\n\t\tif ((ch=getc(fd)) == EOF) {\n\t\t\tbreak;\n\t\t}\n\t\th[1] = ch;\n\t\tif (max_bit == 32768) {\n\t\t\tif ((ch=getc(fd)) == EOF) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\th[2] = ch;\n\t\t\tif ((ch=getc(fd)) == EOF) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\th[3] = ch;\n\t\t}\n\t\tsscanf(h, \"%x\", &b);\n\t\tfor (bit = 1; bit <= max_bit; bit = bit << 1) {\n\t\t\tgdImageSetPixel(im, x++, y, (b & bit) ? 1 : 0);\n\t\t\tif (x == im->sx) {\n\t\t\t\tx = 0;\n\t\t\t\ty++;\n\t\t\t\tif (y == im->sy) {\n\t\t\t\t\treturn im;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\tgd_error(\"EOF before image was complete\");\n\tgdImageDestroy(im);\n\treturn 0;\n}",
        "func": "BGD_DECLARE(gdImagePtr) gdImageCreateFromXbm(FILE * fd)\n{\n\tchar fline[MAX_XBM_LINE_SIZE];\n\tchar iname[MAX_XBM_LINE_SIZE];\n\tchar *type;\n\tint value;\n\tunsigned int width = 0, height = 0;\n\tint fail = 0;\n\tint max_bit = 0;\n\n\tgdImagePtr im;\n\tint bytes = 0, i;\n\tint bit, x = 0, y = 0;\n\tint ch;\n\tchar h[8];\n\tunsigned int b;\n\n\trewind(fd);\n\twhile (fgets(fline, MAX_XBM_LINE_SIZE, fd)) {\n\t\tfline[MAX_XBM_LINE_SIZE-1] = '\\0';\n\t\tif (strlen(fline) == MAX_XBM_LINE_SIZE-1) {\n\t\t\treturn 0;\n\t\t}\n\t\tif (sscanf(fline, \"#define %s %d\", iname, &value) == 2) {\n\t\t\tif (!(type = strrchr(iname, '_'))) {\n\t\t\t\ttype = iname;\n\t\t\t} else {\n\t\t\t\ttype++;\n\t\t\t}\n\n\t\t\tif (!strcmp(\"width\", type)) {\n\t\t\t\twidth = (unsigned int) value;\n\t\t\t}\n\t\t\tif (!strcmp(\"height\", type)) {\n\t\t\t\theight = (unsigned int) value;\n\t\t\t}\n\t\t} else {\n\t\t\tif ( sscanf(fline, \"static unsigned char %s = {\", iname) == 1\n\t\t\t  || sscanf(fline, \"static char %s = {\", iname) == 1)\n\t\t\t{\n\t\t\t\tmax_bit = 128;\n\t\t\t} else if (sscanf(fline, \"static unsigned short %s = {\", iname) == 1\n\t\t\t\t\t|| sscanf(fline, \"static short %s = {\", iname) == 1)\n\t\t\t{\n\t\t\t\tmax_bit = 32768;\n\t\t\t}\n\t\t\tif (max_bit) {\n                bytes = (width + 7) / 8 * height;\n\t\t\t\tif (!bytes) {\n\t\t\t\t\treturn 0;\n\t\t\t\t}\n\t\t\t\tif (!(type = strrchr(iname, '_'))) {\n\t\t\t\t\ttype = iname;\n\t\t\t\t} else {\n\t\t\t\t\ttype++;\n\t\t\t\t}\n\t\t\t\tif (!strcmp(\"bits[]\", type)) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n \t\t}\n\t}\n\tif (!bytes || !max_bit) {\n\t\treturn 0;\n\t}\n\n\tif(!(im = gdImageCreate(width, height))) {\n\t\treturn 0;\n\t}\n\tgdImageColorAllocate(im, 255, 255, 255);\n\tgdImageColorAllocate(im, 0, 0, 0);\n\th[2] = '\\0';\n\th[4] = '\\0';\n\tfor (i = 0; i < bytes; i++) {\n\t\twhile (1) {\n\t\t\tif ((ch=getc(fd)) == EOF) {\n\t\t\t\tfail = 1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (ch == 'x') {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tif (fail) {\n\t\t\tbreak;\n\t\t}\n\t\t/* Get hex value */\n\t\tif ((ch=getc(fd)) == EOF) {\n\t\t\tbreak;\n\t\t}\n\t\th[0] = ch;\n\t\tif ((ch=getc(fd)) == EOF) {\n\t\t\tbreak;\n\t\t}\n\t\th[1] = ch;\n\t\tif (max_bit == 32768) {\n\t\t\tif ((ch=getc(fd)) == EOF) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\th[2] = ch;\n\t\t\tif ((ch=getc(fd)) == EOF) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\th[3] = ch;\n\t\t}\n\t\tif (sscanf(h, \"%x\", &b) != 1) {\n\t\t\tgd_error(\"invalid XBM\");\n\t\t\tgdImageDestroy(im);\n\t\t\treturn 0;\n\t\t}\n\t\tfor (bit = 1; bit <= max_bit; bit = bit << 1) {\n\t\t\tgdImageSetPixel(im, x++, y, (b & bit) ? 1 : 0);\n\t\t\tif (x == im->sx) {\n\t\t\t\tx = 0;\n\t\t\t\ty++;\n\t\t\t\tif (y == im->sy) {\n\t\t\t\t\treturn im;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\tgd_error(\"EOF before image was complete\");\n\tgdImageDestroy(im);\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -103,7 +103,11 @@\n \t\t\t}\n \t\t\th[3] = ch;\n \t\t}\n-\t\tsscanf(h, \"%x\", &b);\n+\t\tif (sscanf(h, \"%x\", &b) != 1) {\n+\t\t\tgd_error(\"invalid XBM\");\n+\t\t\tgdImageDestroy(im);\n+\t\t\treturn 0;\n+\t\t}\n \t\tfor (bit = 1; bit <= max_bit; bit = bit << 1) {\n \t\t\tgdImageSetPixel(im, x++, y, (b & bit) ? 1 : 0);\n \t\t\tif (x == im->sx) {",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tsscanf(h, \"%x\", &b);"
            ],
            "added_lines": [
                "\t\tif (sscanf(h, \"%x\", &b) != 1) {",
                "\t\t\tgd_error(\"invalid XBM\");",
                "\t\t\tgdImageDestroy(im);",
                "\t\t\treturn 0;",
                "\t\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-11038",
        "func_name": "php/php-src/gdImageCreateFromXbm",
        "description": "When using the gdImageCreateFromXbm() function in the GD Graphics Library (aka LibGD) 2.2.5, as used in the PHP GD extension in PHP versions 7.1.x below 7.1.30, 7.2.x below 7.2.19 and 7.3.x below 7.3.6, it is possible to supply data that will cause the function to use the value of uninitialized variable. This may lead to disclosing contents of the stack that has been left there by previous code.",
        "git_url": "https://github.com/php/php-src/commit/ed6dee9a198c904ad5e03113e58a2d2c200f5184",
        "commit_title": "Fix #77973: Uninitialized read in gdImageCreateFromXbm",
        "commit_text": " We have to ensure that `sscanf()` does indeed read a hex value here, and bail out otherwise.",
        "func_before": "gdImagePtr gdImageCreateFromXbm(FILE * fd)\n{\n\tchar fline[MAX_XBM_LINE_SIZE];\n\tchar iname[MAX_XBM_LINE_SIZE];\n\tchar *type;\n\tint value;\n\tunsigned int width = 0, height = 0;\n\tint fail = 0;\n\tint max_bit = 0;\n\n\tgdImagePtr im;\n\tint bytes = 0, i;\n\tint bit, x = 0, y = 0;\n\tint ch;\n\tchar h[8];\n\tunsigned int b;\n\n\trewind(fd);\n\twhile (fgets(fline, MAX_XBM_LINE_SIZE, fd)) {\n\t\tfline[MAX_XBM_LINE_SIZE-1] = '\\0';\n\t\tif (strlen(fline) == MAX_XBM_LINE_SIZE-1) {\n\t\t\treturn 0;\n\t\t}\n\t\tif (sscanf(fline, \"#define %s %d\", iname, &value) == 2) {\n\t\t\tif (!(type = strrchr(iname, '_'))) {\n\t\t\t\ttype = iname;\n\t\t\t} else {\n\t\t\t\ttype++;\n\t\t\t}\n\n\t\t\tif (!strcmp(\"width\", type)) {\n\t\t\t\twidth = (unsigned int) value;\n\t\t\t}\n\t\t\tif (!strcmp(\"height\", type)) {\n\t\t\t\theight = (unsigned int) value;\n\t\t\t}\n\t\t} else {\n\t\t\tif ( sscanf(fline, \"static unsigned char %s = {\", iname) == 1\n\t\t\t  || sscanf(fline, \"static char %s = {\", iname) == 1)\n\t\t\t{\n\t\t\t\tmax_bit = 128;\n\t\t\t} else if (sscanf(fline, \"static unsigned short %s = {\", iname) == 1\n\t\t\t\t\t|| sscanf(fline, \"static short %s = {\", iname) == 1)\n\t\t\t{\n\t\t\t\tmax_bit = 32768;\n\t\t\t}\n\t\t\tif (max_bit) {\n\t\t\t\tbytes = (width + 7) / 8 * height;\n\t\t\t\tif (!bytes) {\n\t\t\t\t\treturn 0;\n\t\t\t\t}\n\t\t\t\tif (!(type = strrchr(iname, '_'))) {\n\t\t\t\t\ttype = iname;\n\t\t\t\t} else {\n\t\t\t\t\ttype++;\n\t\t\t\t}\n\t\t\t\tif (!strcmp(\"bits[]\", type)) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n \t\t}\n\t}\n\tif (!bytes || !max_bit) {\n\t\treturn 0;\n\t}\n\n\tif(!(im = gdImageCreate(width, height))) {\n\t\treturn 0;\n\t}\n\tgdImageColorAllocate(im, 255, 255, 255);\n\tgdImageColorAllocate(im, 0, 0, 0);\n\th[2] = '\\0';\n\th[4] = '\\0';\n\tfor (i = 0; i < bytes; i++) {\n\t\twhile (1) {\n\t\t\tif ((ch=getc(fd)) == EOF) {\n\t\t\t\tfail = 1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (ch == 'x') {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tif (fail) {\n\t\t\tbreak;\n\t\t}\n\t\t/* Get hex value */\n\t\tif ((ch=getc(fd)) == EOF) {\n\t\t\tbreak;\n\t\t}\n\t\th[0] = ch;\n\t\tif ((ch=getc(fd)) == EOF) {\n\t\t\tbreak;\n\t\t}\n\t\th[1] = ch;\n\t\tif (max_bit == 32768) {\n\t\t\tif ((ch=getc(fd)) == EOF) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\th[2] = ch;\n\t\t\tif ((ch=getc(fd)) == EOF) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\th[3] = ch;\n\t\t}\n\t\tsscanf(h, \"%x\", &b);\n\t\tfor (bit = 1; bit <= max_bit; bit = bit << 1) {\n\t\t\tgdImageSetPixel(im, x++, y, (b & bit) ? 1 : 0);\n\t\t\tif (x == im->sx) {\n\t\t\t\tx = 0;\n\t\t\t\ty++;\n\t\t\t\tif (y == im->sy) {\n\t\t\t\t\treturn im;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\tphp_gd_error(\"EOF before image was complete\");\n\tgdImageDestroy(im);\n\treturn 0;\n}",
        "func": "gdImagePtr gdImageCreateFromXbm(FILE * fd)\n{\n\tchar fline[MAX_XBM_LINE_SIZE];\n\tchar iname[MAX_XBM_LINE_SIZE];\n\tchar *type;\n\tint value;\n\tunsigned int width = 0, height = 0;\n\tint fail = 0;\n\tint max_bit = 0;\n\n\tgdImagePtr im;\n\tint bytes = 0, i;\n\tint bit, x = 0, y = 0;\n\tint ch;\n\tchar h[8];\n\tunsigned int b;\n\n\trewind(fd);\n\twhile (fgets(fline, MAX_XBM_LINE_SIZE, fd)) {\n\t\tfline[MAX_XBM_LINE_SIZE-1] = '\\0';\n\t\tif (strlen(fline) == MAX_XBM_LINE_SIZE-1) {\n\t\t\treturn 0;\n\t\t}\n\t\tif (sscanf(fline, \"#define %s %d\", iname, &value) == 2) {\n\t\t\tif (!(type = strrchr(iname, '_'))) {\n\t\t\t\ttype = iname;\n\t\t\t} else {\n\t\t\t\ttype++;\n\t\t\t}\n\n\t\t\tif (!strcmp(\"width\", type)) {\n\t\t\t\twidth = (unsigned int) value;\n\t\t\t}\n\t\t\tif (!strcmp(\"height\", type)) {\n\t\t\t\theight = (unsigned int) value;\n\t\t\t}\n\t\t} else {\n\t\t\tif ( sscanf(fline, \"static unsigned char %s = {\", iname) == 1\n\t\t\t  || sscanf(fline, \"static char %s = {\", iname) == 1)\n\t\t\t{\n\t\t\t\tmax_bit = 128;\n\t\t\t} else if (sscanf(fline, \"static unsigned short %s = {\", iname) == 1\n\t\t\t\t\t|| sscanf(fline, \"static short %s = {\", iname) == 1)\n\t\t\t{\n\t\t\t\tmax_bit = 32768;\n\t\t\t}\n\t\t\tif (max_bit) {\n\t\t\t\tbytes = (width + 7) / 8 * height;\n\t\t\t\tif (!bytes) {\n\t\t\t\t\treturn 0;\n\t\t\t\t}\n\t\t\t\tif (!(type = strrchr(iname, '_'))) {\n\t\t\t\t\ttype = iname;\n\t\t\t\t} else {\n\t\t\t\t\ttype++;\n\t\t\t\t}\n\t\t\t\tif (!strcmp(\"bits[]\", type)) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n \t\t}\n\t}\n\tif (!bytes || !max_bit) {\n\t\treturn 0;\n\t}\n\n\tif(!(im = gdImageCreate(width, height))) {\n\t\treturn 0;\n\t}\n\tgdImageColorAllocate(im, 255, 255, 255);\n\tgdImageColorAllocate(im, 0, 0, 0);\n\th[2] = '\\0';\n\th[4] = '\\0';\n\tfor (i = 0; i < bytes; i++) {\n\t\twhile (1) {\n\t\t\tif ((ch=getc(fd)) == EOF) {\n\t\t\t\tfail = 1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (ch == 'x') {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tif (fail) {\n\t\t\tbreak;\n\t\t}\n\t\t/* Get hex value */\n\t\tif ((ch=getc(fd)) == EOF) {\n\t\t\tbreak;\n\t\t}\n\t\th[0] = ch;\n\t\tif ((ch=getc(fd)) == EOF) {\n\t\t\tbreak;\n\t\t}\n\t\th[1] = ch;\n\t\tif (max_bit == 32768) {\n\t\t\tif ((ch=getc(fd)) == EOF) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\th[2] = ch;\n\t\t\tif ((ch=getc(fd)) == EOF) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\th[3] = ch;\n\t\t}\n\t\tif (sscanf(h, \"%x\", &b) != 1) {\n\t\t\tphp_gd_error(\"invalid XBM\");\n\t\t\tgdImageDestroy(im);\n\t\t\treturn 0;\n\t\t}\n\t\tfor (bit = 1; bit <= max_bit; bit = bit << 1) {\n\t\t\tgdImageSetPixel(im, x++, y, (b & bit) ? 1 : 0);\n\t\t\tif (x == im->sx) {\n\t\t\t\tx = 0;\n\t\t\t\ty++;\n\t\t\t\tif (y == im->sy) {\n\t\t\t\t\treturn im;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\tphp_gd_error(\"EOF before image was complete\");\n\tgdImageDestroy(im);\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -103,7 +103,11 @@\n \t\t\t}\n \t\t\th[3] = ch;\n \t\t}\n-\t\tsscanf(h, \"%x\", &b);\n+\t\tif (sscanf(h, \"%x\", &b) != 1) {\n+\t\t\tphp_gd_error(\"invalid XBM\");\n+\t\t\tgdImageDestroy(im);\n+\t\t\treturn 0;\n+\t\t}\n \t\tfor (bit = 1; bit <= max_bit; bit = bit << 1) {\n \t\t\tgdImageSetPixel(im, x++, y, (b & bit) ? 1 : 0);\n \t\t\tif (x == im->sx) {",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tsscanf(h, \"%x\", &b);"
            ],
            "added_lines": [
                "\t\tif (sscanf(h, \"%x\", &b) != 1) {",
                "\t\t\tphp_gd_error(\"invalid XBM\");",
                "\t\t\tgdImageDestroy(im);",
                "\t\t\treturn 0;",
                "\t\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-13117",
        "func_name": "GNOME/libxslt/xsltNumberFormatTokenize",
        "description": "In numbers.c in libxslt 1.1.33, an xsl:number with certain format strings could lead to a uninitialized read in xsltNumberFormatInsertNumbers. This could allow an attacker to discern whether a byte on the stack contains the characters A, a, I, i, or 0, or any other character.",
        "git_url": "https://github.com/GNOME/libxslt/commit/c5eb6cf3aba0af048596106ed839b4ae17ecbcb1",
        "commit_title": "Fix uninitialized read of xsl:number token",
        "commit_text": " Found by OSS-Fuzz.",
        "func_before": "static void\nxsltNumberFormatTokenize(const xmlChar *format,\n\t\t\t xsltFormatPtr tokens)\n{\n    int ix = 0;\n    int j;\n    int val;\n    int len;\n\n    default_token.token = DEFAULT_TOKEN;\n    default_token.width = 1;\n    default_token.separator = BAD_CAST(DEFAULT_SEPARATOR);\n\n\n    tokens->start = NULL;\n    tokens->tokens[0].separator = NULL;\n    tokens->end = NULL;\n\n    /*\n     * Insert initial non-alphanumeric token.\n     * There is always such a token in the list, even if NULL\n     */\n    while (! (IS_LETTER(val=xmlStringCurrentChar(NULL, format+ix, &len)) ||\n\t      IS_DIGIT(val)) ) {\n\tif (format[ix] == 0)\t\t/* if end of format string */\n\t    break; /* while */\n\tix += len;\n    }\n    if (ix > 0)\n\ttokens->start = xmlStrndup(format, ix);\n\n\n    for (tokens->nTokens = 0; tokens->nTokens < MAX_TOKENS;\n\t tokens->nTokens++) {\n\tif (format[ix] == 0)\n\t    break; /* for */\n\n\t/*\n\t * separator has already been parsed (except for the first\n\t * number) in tokens->end, recover it.\n\t */\n\tif (tokens->nTokens > 0) {\n\t    tokens->tokens[tokens->nTokens].separator = tokens->end;\n\t    tokens->end = NULL;\n\t}\n\n\tval = xmlStringCurrentChar(NULL, format+ix, &len);\n\tif (IS_DIGIT_ONE(val) ||\n\t\t IS_DIGIT_ZERO(val)) {\n\t    tokens->tokens[tokens->nTokens].width = 1;\n\t    while (IS_DIGIT_ZERO(val)) {\n\t\ttokens->tokens[tokens->nTokens].width++;\n\t\tix += len;\n\t\tval = xmlStringCurrentChar(NULL, format+ix, &len);\n\t    }\n\t    if (IS_DIGIT_ONE(val)) {\n\t\ttokens->tokens[tokens->nTokens].token = val - 1;\n\t\tix += len;\n\t\tval = xmlStringCurrentChar(NULL, format+ix, &len);\n\t    }\n\t} else if ( (val == (xmlChar)'A') ||\n\t\t    (val == (xmlChar)'a') ||\n\t\t    (val == (xmlChar)'I') ||\n\t\t    (val == (xmlChar)'i') ) {\n\t    tokens->tokens[tokens->nTokens].token = val;\n\t    ix += len;\n\t    val = xmlStringCurrentChar(NULL, format+ix, &len);\n\t} else {\n\t    /* XSLT section 7.7\n\t     * \"Any other format token indicates a numbering sequence\n\t     *  that starts with that token. If an implementation does\n\t     *  not support a numbering sequence that starts with that\n\t     *  token, it must use a format token of 1.\"\n\t     */\n\t    tokens->tokens[tokens->nTokens].token = (xmlChar)'0';\n\t    tokens->tokens[tokens->nTokens].width = 1;\n\t}\n\t/*\n\t * Skip over remaining alphanumeric characters from the Nd\n\t * (Number, decimal digit), Nl (Number, letter), No (Number,\n\t * other), Lu (Letter, uppercase), Ll (Letter, lowercase), Lt\n\t * (Letters, titlecase), Lm (Letters, modifiers), and Lo\n\t * (Letters, other (uncased)) Unicode categories. This happens\n\t * to correspond to the Letter and Digit classes from XML (and\n\t * one wonders why XSLT doesn't refer to these instead).\n\t */\n\twhile (IS_LETTER(val) || IS_DIGIT(val)) {\n\t    ix += len;\n\t    val = xmlStringCurrentChar(NULL, format+ix, &len);\n\t}\n\n\t/*\n\t * Insert temporary non-alphanumeric final tooken.\n\t */\n\tj = ix;\n\twhile (! (IS_LETTER(val) || IS_DIGIT(val))) {\n\t    if (val == 0)\n\t\tbreak; /* while */\n\t    ix += len;\n\t    val = xmlStringCurrentChar(NULL, format+ix, &len);\n\t}\n\tif (ix > j)\n\t    tokens->end = xmlStrndup(&format[j], ix - j);\n    }\n}",
        "func": "static void\nxsltNumberFormatTokenize(const xmlChar *format,\n\t\t\t xsltFormatPtr tokens)\n{\n    int ix = 0;\n    int j;\n    int val;\n    int len;\n\n    default_token.token = DEFAULT_TOKEN;\n    default_token.width = 1;\n    default_token.separator = BAD_CAST(DEFAULT_SEPARATOR);\n\n\n    tokens->start = NULL;\n    tokens->tokens[0].separator = NULL;\n    tokens->end = NULL;\n\n    /*\n     * Insert initial non-alphanumeric token.\n     * There is always such a token in the list, even if NULL\n     */\n    while (! (IS_LETTER(val=xmlStringCurrentChar(NULL, format+ix, &len)) ||\n\t      IS_DIGIT(val)) ) {\n\tif (format[ix] == 0)\t\t/* if end of format string */\n\t    break; /* while */\n\tix += len;\n    }\n    if (ix > 0)\n\ttokens->start = xmlStrndup(format, ix);\n\n\n    for (tokens->nTokens = 0; tokens->nTokens < MAX_TOKENS;\n\t tokens->nTokens++) {\n\tif (format[ix] == 0)\n\t    break; /* for */\n\n\t/*\n\t * separator has already been parsed (except for the first\n\t * number) in tokens->end, recover it.\n\t */\n\tif (tokens->nTokens > 0) {\n\t    tokens->tokens[tokens->nTokens].separator = tokens->end;\n\t    tokens->end = NULL;\n\t}\n\n\tval = xmlStringCurrentChar(NULL, format+ix, &len);\n\tif (IS_DIGIT_ONE(val) ||\n\t\t IS_DIGIT_ZERO(val)) {\n\t    tokens->tokens[tokens->nTokens].width = 1;\n\t    while (IS_DIGIT_ZERO(val)) {\n\t\ttokens->tokens[tokens->nTokens].width++;\n\t\tix += len;\n\t\tval = xmlStringCurrentChar(NULL, format+ix, &len);\n\t    }\n\t    if (IS_DIGIT_ONE(val)) {\n\t\ttokens->tokens[tokens->nTokens].token = val - 1;\n\t\tix += len;\n\t\tval = xmlStringCurrentChar(NULL, format+ix, &len);\n\t    } else {\n                tokens->tokens[tokens->nTokens].token = (xmlChar)'0';\n                tokens->tokens[tokens->nTokens].width = 1;\n            }\n\t} else if ( (val == (xmlChar)'A') ||\n\t\t    (val == (xmlChar)'a') ||\n\t\t    (val == (xmlChar)'I') ||\n\t\t    (val == (xmlChar)'i') ) {\n\t    tokens->tokens[tokens->nTokens].token = val;\n\t    ix += len;\n\t    val = xmlStringCurrentChar(NULL, format+ix, &len);\n\t} else {\n\t    /* XSLT section 7.7\n\t     * \"Any other format token indicates a numbering sequence\n\t     *  that starts with that token. If an implementation does\n\t     *  not support a numbering sequence that starts with that\n\t     *  token, it must use a format token of 1.\"\n\t     */\n\t    tokens->tokens[tokens->nTokens].token = (xmlChar)'0';\n\t    tokens->tokens[tokens->nTokens].width = 1;\n\t}\n\t/*\n\t * Skip over remaining alphanumeric characters from the Nd\n\t * (Number, decimal digit), Nl (Number, letter), No (Number,\n\t * other), Lu (Letter, uppercase), Ll (Letter, lowercase), Lt\n\t * (Letters, titlecase), Lm (Letters, modifiers), and Lo\n\t * (Letters, other (uncased)) Unicode categories. This happens\n\t * to correspond to the Letter and Digit classes from XML (and\n\t * one wonders why XSLT doesn't refer to these instead).\n\t */\n\twhile (IS_LETTER(val) || IS_DIGIT(val)) {\n\t    ix += len;\n\t    val = xmlStringCurrentChar(NULL, format+ix, &len);\n\t}\n\n\t/*\n\t * Insert temporary non-alphanumeric final tooken.\n\t */\n\tj = ix;\n\twhile (! (IS_LETTER(val) || IS_DIGIT(val))) {\n\t    if (val == 0)\n\t\tbreak; /* while */\n\t    ix += len;\n\t    val = xmlStringCurrentChar(NULL, format+ix, &len);\n\t}\n\tif (ix > j)\n\t    tokens->end = xmlStrndup(&format[j], ix - j);\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -57,7 +57,10 @@\n \t\ttokens->tokens[tokens->nTokens].token = val - 1;\n \t\tix += len;\n \t\tval = xmlStringCurrentChar(NULL, format+ix, &len);\n-\t    }\n+\t    } else {\n+                tokens->tokens[tokens->nTokens].token = (xmlChar)'0';\n+                tokens->tokens[tokens->nTokens].width = 1;\n+            }\n \t} else if ( (val == (xmlChar)'A') ||\n \t\t    (val == (xmlChar)'a') ||\n \t\t    (val == (xmlChar)'I') ||",
        "diff_line_info": {
            "deleted_lines": [
                "\t    }"
            ],
            "added_lines": [
                "\t    } else {",
                "                tokens->tokens[tokens->nTokens].token = (xmlChar)'0';",
                "                tokens->tokens[tokens->nTokens].width = 1;",
                "            }"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-13135",
        "func_name": "ImageMagick/ImageMagick6/ReadCUTImage",
        "description": "ImageMagick before 7.0.8-50 has a \"use of uninitialized value\" vulnerability in the function ReadCUTImage in coders/cut.c.",
        "git_url": "https://github.com/ImageMagick/ImageMagick6/commit/1e59b29e520d2beab73e8c78aacd5f1c0d76196d",
        "commit_title": "https://github.com/ImageMagick/ImageMagick/issues/1599",
        "commit_text": "",
        "func_before": "static Image *ReadCUTImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n#define ThrowCUTReaderException(severity,tag) \\\n{ \\\n  if (palette != NULL) \\\n    palette=DestroyImage(palette); \\\n  if (clone_info != NULL) \\\n    clone_info=DestroyImageInfo(clone_info); \\\n  ThrowReaderException(severity,tag); \\\n}\n\n  Image *image,*palette;\n  ImageInfo *clone_info;\n  MagickBooleanType status;\n\n  MagickOffsetType\n    offset;\n\n  size_t EncodedByte;\n  unsigned char RunCount,RunValue,RunCountMasked;\n  CUTHeader  Header;\n  CUTPalHeader PalHeader;\n  ssize_t depth;\n  ssize_t i,j;\n  ssize_t ldblk;\n  unsigned char *BImgBuff=NULL,*ptrB;\n  PixelPacket *q;\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  image=AcquireImage(image_info);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n    Read CUT image.\n  */\n  palette=NULL;\n  clone_info=NULL;\n  Header.Width=ReadBlobLSBShort(image);\n  Header.Height=ReadBlobLSBShort(image);\n  Header.Reserved=ReadBlobLSBShort(image);\n\n  if (Header.Width==0 || Header.Height==0 || Header.Reserved!=0)\n    CUT_KO:  ThrowCUTReaderException(CorruptImageError,\"ImproperImageHeader\");\n\n  /*---This code checks first line of image---*/\n  EncodedByte=ReadBlobLSBShort(image);\n  RunCount=(unsigned char) ReadBlobByte(image);\n  RunCountMasked=RunCount & 0x7F;\n  ldblk=0;\n  while((int) RunCountMasked!=0)  /*end of line?*/\n    {\n      i=1;\n      if((int) RunCount<0x80) i=(ssize_t) RunCountMasked;\n      offset=SeekBlob(image,TellBlob(image)+i,SEEK_SET);\n      if (offset < 0)\n        ThrowCUTReaderException(CorruptImageError,\"ImproperImageHeader\");\n      if(EOFBlob(image) != MagickFalse) goto CUT_KO;  /*wrong data*/\n      EncodedByte-=i+1;\n      ldblk+=(ssize_t) RunCountMasked;\n\n      RunCount=(unsigned char) ReadBlobByte(image);\n      if(EOFBlob(image) != MagickFalse)  goto CUT_KO;  /*wrong data: unexpected eof in line*/\n      RunCountMasked=RunCount & 0x7F;\n    }\n  if(EncodedByte!=1) goto CUT_KO;  /*wrong data: size incorrect*/\n  i=0;        /*guess a number of bit planes*/\n  if(ldblk==(int) Header.Width)   i=8;\n  if(2*ldblk==(int) Header.Width) i=4;\n  if(8*ldblk==(int) Header.Width) i=1;\n  if(i==0) goto CUT_KO;    /*wrong data: incorrect bit planes*/\n  depth=i;\n\n  image->columns=Header.Width;\n  image->rows=Header.Height;\n  image->depth=8;\n  image->colors=(size_t) (GetQuantumRange(1UL*i)+1);\n\n  if (image_info->ping != MagickFalse) goto Finish;\n  status=SetImageExtent(image,image->columns,image->rows);\n  if (status == MagickFalse)\n    {\n      InheritException(exception,&image->exception);\n      return(DestroyImageList(image));\n    }\n\n  /* ----- Do something with palette ----- */\n  if ((clone_info=CloneImageInfo(image_info)) == NULL) goto NoPalette;\n\n\n  i=(ssize_t) strlen(clone_info->filename);\n  j=i;\n  while(--i>0)\n    {\n      if(clone_info->filename[i]=='.')\n        {\n          break;\n        }\n      if(clone_info->filename[i]=='/' || clone_info->filename[i]=='\\\\' ||\n         clone_info->filename[i]==':' )\n        {\n          i=j;\n          break;\n        }\n    }\n\n  (void) CopyMagickString(clone_info->filename+i,\".PAL\",(size_t)\n    (MaxTextExtent-i));\n  if((clone_info->file=fopen_utf8(clone_info->filename,\"rb\"))==NULL)\n    {\n      (void) CopyMagickString(clone_info->filename+i,\".pal\",(size_t)\n        (MaxTextExtent-i));\n      if((clone_info->file=fopen_utf8(clone_info->filename,\"rb\"))==NULL)\n        {\n          clone_info->filename[i]='\\0';\n          if((clone_info->file=fopen_utf8(clone_info->filename,\"rb\"))==NULL)\n            {\n              clone_info=DestroyImageInfo(clone_info);\n              clone_info=NULL;\n              goto NoPalette;\n            }\n        }\n    }\n\n  if( (palette=AcquireImage(clone_info))==NULL ) goto NoPalette;\n  status=OpenBlob(clone_info,palette,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n    ErasePalette:\n      palette=DestroyImage(palette);\n      palette=NULL;\n      goto NoPalette;\n    }\n\n\n  if(palette!=NULL)\n    {\n      (void) ReadBlob(palette,2,(unsigned char *) PalHeader.FileId);\n      if(strncmp(PalHeader.FileId,\"AH\",2) != 0) goto ErasePalette;\n      PalHeader.Version=ReadBlobLSBShort(palette);\n      PalHeader.Size=ReadBlobLSBShort(palette);\n      PalHeader.FileType=(char) ReadBlobByte(palette);\n      PalHeader.SubType=(char) ReadBlobByte(palette);\n      PalHeader.BoardID=ReadBlobLSBShort(palette);\n      PalHeader.GraphicsMode=ReadBlobLSBShort(palette);\n      PalHeader.MaxIndex=ReadBlobLSBShort(palette);\n      PalHeader.MaxRed=ReadBlobLSBShort(palette);\n      PalHeader.MaxGreen=ReadBlobLSBShort(palette);\n      PalHeader.MaxBlue=ReadBlobLSBShort(palette);\n      (void) ReadBlob(palette,20,(unsigned char *) PalHeader.PaletteId);\n      if (EOFBlob(image))\n        ThrowCUTReaderException(CorruptImageError,\"UnexpectedEndOfFile\");\n\n      if(PalHeader.MaxIndex<1) goto ErasePalette;\n      image->colors=PalHeader.MaxIndex+1;\n      if (AcquireImageColormap(image,image->colors) == MagickFalse) goto NoMemory;\n\n      if(PalHeader.MaxRed==0) PalHeader.MaxRed=(unsigned int) QuantumRange;  /*avoid division by 0*/\n      if(PalHeader.MaxGreen==0) PalHeader.MaxGreen=(unsigned int) QuantumRange;\n      if(PalHeader.MaxBlue==0) PalHeader.MaxBlue=(unsigned int) QuantumRange;\n\n      for(i=0;i<=(int) PalHeader.MaxIndex;i++)\n        {      /*this may be wrong- I don't know why is palette such strange*/\n          j=(ssize_t) TellBlob(palette);\n          if((j % 512)>512-6)\n            {\n              j=((j / 512)+1)*512;\n              offset=SeekBlob(palette,j,SEEK_SET);\n              if (offset < 0)\n                ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n            }\n          image->colormap[i].red=(Quantum) ReadBlobLSBShort(palette);\n          if (QuantumRange != (Quantum) PalHeader.MaxRed)\n            {\n              image->colormap[i].red=ClampToQuantum(((double)\n                image->colormap[i].red*QuantumRange+(PalHeader.MaxRed>>1))/\n                PalHeader.MaxRed);\n            }\n          image->colormap[i].green=(Quantum) ReadBlobLSBShort(palette);\n          if (QuantumRange != (Quantum) PalHeader.MaxGreen)\n            {\n              image->colormap[i].green=ClampToQuantum\n                (((double) image->colormap[i].green*QuantumRange+(PalHeader.MaxGreen>>1))/PalHeader.MaxGreen);\n            }\n          image->colormap[i].blue=(Quantum) ReadBlobLSBShort(palette);\n          if (QuantumRange != (Quantum) PalHeader.MaxBlue)\n            {\n              image->colormap[i].blue=ClampToQuantum\n                (((double)image->colormap[i].blue*QuantumRange+(PalHeader.MaxBlue>>1))/PalHeader.MaxBlue);\n            }\n\n        }\n      if (EOFBlob(image))\n        ThrowCUTReaderException(CorruptImageError,\"UnexpectedEndOfFile\");\n    }\n\n\n\n NoPalette:\n  if(palette==NULL)\n    {\n\n      image->colors=256;\n      if (AcquireImageColormap(image,image->colors) == MagickFalse)\n        {\n        NoMemory:\n          ThrowCUTReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n            }\n\n      for (i=0; i < (ssize_t)image->colors; i++)\n        {\n          image->colormap[i].red=ScaleCharToQuantum((unsigned char) i);\n          image->colormap[i].green=ScaleCharToQuantum((unsigned char) i);\n          image->colormap[i].blue=ScaleCharToQuantum((unsigned char) i);\n        }\n    }\n\n\n  /* ----- Load RLE compressed raster ----- */\n  BImgBuff=(unsigned char *) AcquireQuantumMemory((size_t) ldblk,\n    sizeof(*BImgBuff));  /*Ldblk was set in the check phase*/\n  if(BImgBuff==NULL) goto NoMemory;\n\n  offset=SeekBlob(image,6 /*sizeof(Header)*/,SEEK_SET);\n  if (offset < 0)\n    {\n      if (palette != NULL)\n        palette=DestroyImage(palette);\n      if (clone_info != NULL)\n        clone_info=DestroyImageInfo(clone_info);\n      BImgBuff=(unsigned char *) RelinquishMagickMemory(BImgBuff);\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    }\n  for (i=0; i < (int) Header.Height; i++)\n  {\n      EncodedByte=ReadBlobLSBShort(image);\n\n      ptrB=BImgBuff;\n      j=ldblk;\n\n      RunCount=(unsigned char) ReadBlobByte(image);\n      RunCountMasked=RunCount & 0x7F;\n\n      while ((int) RunCountMasked != 0)\n      {\n          if((ssize_t) RunCountMasked>j)\n            {    /*Wrong Data*/\n              RunCountMasked=(unsigned char) j;\n              if(j==0)\n                {\n                  break;\n                }\n            }\n\n          if((int) RunCount>0x80)\n            {\n              RunValue=(unsigned char) ReadBlobByte(image);\n              (void) memset(ptrB,(int) RunValue,(size_t) RunCountMasked);\n            }\n          else {\n            (void) ReadBlob(image,(size_t) RunCountMasked,ptrB);\n          }\n\n          ptrB+=(int) RunCountMasked;\n          j-=(int) RunCountMasked;\n\n          if (EOFBlob(image) != MagickFalse) goto Finish;  /* wrong data: unexpected eof in line */\n          RunCount=(unsigned char) ReadBlobByte(image);\n          RunCountMasked=RunCount & 0x7F;\n        }\n\n      InsertRow(depth,BImgBuff,i,image);\n    }\n  (void) SyncImage(image);\n\n\n  /*detect monochrome image*/\n\n  if(palette==NULL)\n    {    /*attempt to detect binary (black&white) images*/\n      if ((image->storage_class == PseudoClass) &&\n          (SetImageGray(image,&image->exception) != MagickFalse))\n        {\n          if(GetCutColors(image)==2)\n            {\n              for (i=0; i < (ssize_t)image->colors; i++)\n                {\n                  register Quantum\n                    sample;\n                  sample=ScaleCharToQuantum((unsigned char) i);\n                  if(image->colormap[i].red!=sample) goto Finish;\n                  if(image->colormap[i].green!=sample) goto Finish;\n                  if(image->colormap[i].blue!=sample) goto Finish;\n                }\n\n              image->colormap[1].red=image->colormap[1].green=\n                image->colormap[1].blue=QuantumRange;\n              for (i=0; i < (ssize_t)image->rows; i++)\n                {\n                  q=QueueAuthenticPixels(image,0,i,image->columns,1,exception);\n                  if (q == (PixelPacket *) NULL)\n                    break;\n                  for (j=0; j < (ssize_t)image->columns; j++)\n                    {\n                      if (GetPixelRed(q) == ScaleCharToQuantum(1))\n                        {\n                          SetPixelRed(q,QuantumRange);\n                          SetPixelGreen(q,QuantumRange);\n                          SetPixelBlue(q,QuantumRange);\n                        }\n                      q++;\n                    }\n                  if (SyncAuthenticPixels(image,exception) == MagickFalse) goto Finish;\n                }\n            }\n        }\n    }\n\n Finish:\n  if (BImgBuff != NULL)\n    BImgBuff=(unsigned char *) RelinquishMagickMemory(BImgBuff);\n  if (palette != NULL)\n    palette=DestroyImage(palette);\n  if (clone_info != NULL)\n    clone_info=DestroyImageInfo(clone_info);\n  if (EOFBlob(image) != MagickFalse)\n    ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n      image->filename);\n  (void) CloseBlob(image);\n  return(GetFirstImageInList(image));\n}",
        "func": "static Image *ReadCUTImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n#define ThrowCUTReaderException(severity,tag) \\\n{ \\\n  if (palette != NULL) \\\n    palette=DestroyImage(palette); \\\n  if (clone_info != NULL) \\\n    clone_info=DestroyImageInfo(clone_info); \\\n  ThrowReaderException(severity,tag); \\\n}\n\n  Image *image,*palette;\n  ImageInfo *clone_info;\n  MagickBooleanType status;\n\n  MagickOffsetType\n    offset;\n\n  size_t EncodedByte;\n  unsigned char RunCount,RunValue,RunCountMasked;\n  CUTHeader  Header;\n  CUTPalHeader PalHeader;\n  ssize_t depth;\n  ssize_t i,j;\n  ssize_t ldblk;\n  unsigned char *BImgBuff=NULL,*ptrB;\n  PixelPacket *q;\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  image=AcquireImage(image_info);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n    Read CUT image.\n  */\n  palette=NULL;\n  clone_info=NULL;\n  Header.Width=ReadBlobLSBShort(image);\n  Header.Height=ReadBlobLSBShort(image);\n  Header.Reserved=ReadBlobLSBShort(image);\n\n  if (Header.Width==0 || Header.Height==0 || Header.Reserved!=0)\n    CUT_KO:  ThrowCUTReaderException(CorruptImageError,\"ImproperImageHeader\");\n\n  /*---This code checks first line of image---*/\n  EncodedByte=ReadBlobLSBShort(image);\n  RunCount=(unsigned char) ReadBlobByte(image);\n  RunCountMasked=RunCount & 0x7F;\n  ldblk=0;\n  while((int) RunCountMasked!=0)  /*end of line?*/\n    {\n      i=1;\n      if((int) RunCount<0x80) i=(ssize_t) RunCountMasked;\n      offset=SeekBlob(image,TellBlob(image)+i,SEEK_SET);\n      if (offset < 0)\n        ThrowCUTReaderException(CorruptImageError,\"ImproperImageHeader\");\n      if(EOFBlob(image) != MagickFalse) goto CUT_KO;  /*wrong data*/\n      EncodedByte-=i+1;\n      ldblk+=(ssize_t) RunCountMasked;\n\n      RunCount=(unsigned char) ReadBlobByte(image);\n      if(EOFBlob(image) != MagickFalse)  goto CUT_KO;  /*wrong data: unexpected eof in line*/\n      RunCountMasked=RunCount & 0x7F;\n    }\n  if(EncodedByte!=1) goto CUT_KO;  /*wrong data: size incorrect*/\n  i=0;        /*guess a number of bit planes*/\n  if(ldblk==(int) Header.Width)   i=8;\n  if(2*ldblk==(int) Header.Width) i=4;\n  if(8*ldblk==(int) Header.Width) i=1;\n  if(i==0) goto CUT_KO;    /*wrong data: incorrect bit planes*/\n  depth=i;\n\n  image->columns=Header.Width;\n  image->rows=Header.Height;\n  image->depth=8;\n  image->colors=(size_t) (GetQuantumRange(1UL*i)+1);\n\n  if (image_info->ping != MagickFalse) goto Finish;\n  status=SetImageExtent(image,image->columns,image->rows);\n  if (status == MagickFalse)\n    {\n      InheritException(exception,&image->exception);\n      return(DestroyImageList(image));\n    }\n\n  /* ----- Do something with palette ----- */\n  if ((clone_info=CloneImageInfo(image_info)) == NULL) goto NoPalette;\n\n\n  i=(ssize_t) strlen(clone_info->filename);\n  j=i;\n  while(--i>0)\n    {\n      if(clone_info->filename[i]=='.')\n        {\n          break;\n        }\n      if(clone_info->filename[i]=='/' || clone_info->filename[i]=='\\\\' ||\n         clone_info->filename[i]==':' )\n        {\n          i=j;\n          break;\n        }\n    }\n\n  (void) CopyMagickString(clone_info->filename+i,\".PAL\",(size_t)\n    (MaxTextExtent-i));\n  if((clone_info->file=fopen_utf8(clone_info->filename,\"rb\"))==NULL)\n    {\n      (void) CopyMagickString(clone_info->filename+i,\".pal\",(size_t)\n        (MaxTextExtent-i));\n      if((clone_info->file=fopen_utf8(clone_info->filename,\"rb\"))==NULL)\n        {\n          clone_info->filename[i]='\\0';\n          if((clone_info->file=fopen_utf8(clone_info->filename,\"rb\"))==NULL)\n            {\n              clone_info=DestroyImageInfo(clone_info);\n              clone_info=NULL;\n              goto NoPalette;\n            }\n        }\n    }\n\n  if( (palette=AcquireImage(clone_info))==NULL ) goto NoPalette;\n  status=OpenBlob(clone_info,palette,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n    ErasePalette:\n      palette=DestroyImage(palette);\n      palette=NULL;\n      goto NoPalette;\n    }\n\n\n  if(palette!=NULL)\n    {\n      (void) ReadBlob(palette,2,(unsigned char *) PalHeader.FileId);\n      if(strncmp(PalHeader.FileId,\"AH\",2) != 0) goto ErasePalette;\n      PalHeader.Version=ReadBlobLSBShort(palette);\n      PalHeader.Size=ReadBlobLSBShort(palette);\n      PalHeader.FileType=(char) ReadBlobByte(palette);\n      PalHeader.SubType=(char) ReadBlobByte(palette);\n      PalHeader.BoardID=ReadBlobLSBShort(palette);\n      PalHeader.GraphicsMode=ReadBlobLSBShort(palette);\n      PalHeader.MaxIndex=ReadBlobLSBShort(palette);\n      PalHeader.MaxRed=ReadBlobLSBShort(palette);\n      PalHeader.MaxGreen=ReadBlobLSBShort(palette);\n      PalHeader.MaxBlue=ReadBlobLSBShort(palette);\n      (void) ReadBlob(palette,20,(unsigned char *) PalHeader.PaletteId);\n      if (EOFBlob(image))\n        ThrowCUTReaderException(CorruptImageError,\"UnexpectedEndOfFile\");\n\n      if(PalHeader.MaxIndex<1) goto ErasePalette;\n      image->colors=PalHeader.MaxIndex+1;\n      if (AcquireImageColormap(image,image->colors) == MagickFalse) goto NoMemory;\n\n      if(PalHeader.MaxRed==0) PalHeader.MaxRed=(unsigned int) QuantumRange;  /*avoid division by 0*/\n      if(PalHeader.MaxGreen==0) PalHeader.MaxGreen=(unsigned int) QuantumRange;\n      if(PalHeader.MaxBlue==0) PalHeader.MaxBlue=(unsigned int) QuantumRange;\n\n      for(i=0;i<=(int) PalHeader.MaxIndex;i++)\n        {      /*this may be wrong- I don't know why is palette such strange*/\n          j=(ssize_t) TellBlob(palette);\n          if((j % 512)>512-6)\n            {\n              j=((j / 512)+1)*512;\n              offset=SeekBlob(palette,j,SEEK_SET);\n              if (offset < 0)\n                ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n            }\n          image->colormap[i].red=(Quantum) ReadBlobLSBShort(palette);\n          if (QuantumRange != (Quantum) PalHeader.MaxRed)\n            {\n              image->colormap[i].red=ClampToQuantum(((double)\n                image->colormap[i].red*QuantumRange+(PalHeader.MaxRed>>1))/\n                PalHeader.MaxRed);\n            }\n          image->colormap[i].green=(Quantum) ReadBlobLSBShort(palette);\n          if (QuantumRange != (Quantum) PalHeader.MaxGreen)\n            {\n              image->colormap[i].green=ClampToQuantum\n                (((double) image->colormap[i].green*QuantumRange+(PalHeader.MaxGreen>>1))/PalHeader.MaxGreen);\n            }\n          image->colormap[i].blue=(Quantum) ReadBlobLSBShort(palette);\n          if (QuantumRange != (Quantum) PalHeader.MaxBlue)\n            {\n              image->colormap[i].blue=ClampToQuantum\n                (((double)image->colormap[i].blue*QuantumRange+(PalHeader.MaxBlue>>1))/PalHeader.MaxBlue);\n            }\n\n        }\n      if (EOFBlob(image))\n        ThrowCUTReaderException(CorruptImageError,\"UnexpectedEndOfFile\");\n    }\n\n\n\n NoPalette:\n  if(palette==NULL)\n    {\n\n      image->colors=256;\n      if (AcquireImageColormap(image,image->colors) == MagickFalse)\n        {\n        NoMemory:\n          ThrowCUTReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n            }\n\n      for (i=0; i < (ssize_t)image->colors; i++)\n        {\n          image->colormap[i].red=ScaleCharToQuantum((unsigned char) i);\n          image->colormap[i].green=ScaleCharToQuantum((unsigned char) i);\n          image->colormap[i].blue=ScaleCharToQuantum((unsigned char) i);\n        }\n    }\n\n\n  /* ----- Load RLE compressed raster ----- */\n  BImgBuff=(unsigned char *) AcquireQuantumMemory((size_t) ldblk,\n    sizeof(*BImgBuff));  /*Ldblk was set in the check phase*/\n  if(BImgBuff==NULL) goto NoMemory;\n  (void) memset(BImgBuff,0,(size_t) ldblk*sizeof(*BImgBuff));\n\n  offset=SeekBlob(image,6 /*sizeof(Header)*/,SEEK_SET);\n  if (offset < 0)\n    {\n      if (palette != NULL)\n        palette=DestroyImage(palette);\n      if (clone_info != NULL)\n        clone_info=DestroyImageInfo(clone_info);\n      BImgBuff=(unsigned char *) RelinquishMagickMemory(BImgBuff);\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    }\n  for (i=0; i < (int) Header.Height; i++)\n  {\n      EncodedByte=ReadBlobLSBShort(image);\n\n      ptrB=BImgBuff;\n      j=ldblk;\n\n      RunCount=(unsigned char) ReadBlobByte(image);\n      RunCountMasked=RunCount & 0x7F;\n\n      while ((int) RunCountMasked != 0)\n      {\n          if((ssize_t) RunCountMasked>j)\n            {    /*Wrong Data*/\n              RunCountMasked=(unsigned char) j;\n              if(j==0)\n                {\n                  break;\n                }\n            }\n\n          if((int) RunCount>0x80)\n            {\n              RunValue=(unsigned char) ReadBlobByte(image);\n              (void) memset(ptrB,(int) RunValue,(size_t) RunCountMasked);\n            }\n          else {\n            (void) ReadBlob(image,(size_t) RunCountMasked,ptrB);\n          }\n\n          ptrB+=(int) RunCountMasked;\n          j-=(int) RunCountMasked;\n\n          if (EOFBlob(image) != MagickFalse) goto Finish;  /* wrong data: unexpected eof in line */\n          RunCount=(unsigned char) ReadBlobByte(image);\n          RunCountMasked=RunCount & 0x7F;\n        }\n\n      InsertRow(depth,BImgBuff,i,image);\n    }\n  (void) SyncImage(image);\n\n\n  /*detect monochrome image*/\n\n  if(palette==NULL)\n    {    /*attempt to detect binary (black&white) images*/\n      if ((image->storage_class == PseudoClass) &&\n          (SetImageGray(image,&image->exception) != MagickFalse))\n        {\n          if(GetCutColors(image)==2)\n            {\n              for (i=0; i < (ssize_t)image->colors; i++)\n                {\n                  register Quantum\n                    sample;\n                  sample=ScaleCharToQuantum((unsigned char) i);\n                  if(image->colormap[i].red!=sample) goto Finish;\n                  if(image->colormap[i].green!=sample) goto Finish;\n                  if(image->colormap[i].blue!=sample) goto Finish;\n                }\n\n              image->colormap[1].red=image->colormap[1].green=\n                image->colormap[1].blue=QuantumRange;\n              for (i=0; i < (ssize_t)image->rows; i++)\n                {\n                  q=QueueAuthenticPixels(image,0,i,image->columns,1,exception);\n                  if (q == (PixelPacket *) NULL)\n                    break;\n                  for (j=0; j < (ssize_t)image->columns; j++)\n                    {\n                      if (GetPixelRed(q) == ScaleCharToQuantum(1))\n                        {\n                          SetPixelRed(q,QuantumRange);\n                          SetPixelGreen(q,QuantumRange);\n                          SetPixelBlue(q,QuantumRange);\n                        }\n                      q++;\n                    }\n                  if (SyncAuthenticPixels(image,exception) == MagickFalse) goto Finish;\n                }\n            }\n        }\n    }\n\n Finish:\n  if (BImgBuff != NULL)\n    BImgBuff=(unsigned char *) RelinquishMagickMemory(BImgBuff);\n  if (palette != NULL)\n    palette=DestroyImage(palette);\n  if (clone_info != NULL)\n    clone_info=DestroyImageInfo(clone_info);\n  if (EOFBlob(image) != MagickFalse)\n    ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n      image->filename);\n  (void) CloseBlob(image);\n  return(GetFirstImageInList(image));\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -232,6 +232,7 @@\n   BImgBuff=(unsigned char *) AcquireQuantumMemory((size_t) ldblk,\n     sizeof(*BImgBuff));  /*Ldblk was set in the check phase*/\n   if(BImgBuff==NULL) goto NoMemory;\n+  (void) memset(BImgBuff,0,(size_t) ldblk*sizeof(*BImgBuff));\n \n   offset=SeekBlob(image,6 /*sizeof(Header)*/,SEEK_SET);\n   if (offset < 0)",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "  (void) memset(BImgBuff,0,(size_t) ldblk*sizeof(*BImgBuff));"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-1010317",
        "func_name": "dbry/WavPack/ParseCaffHeaderConfig",
        "description": "WavPack 5.1.0 and earlier is affected by: CWE-457: Use of Uninitialized Variable. The impact is: Unexpected control flow, crashes, and segfaults. The component is: ParseCaffHeaderConfig (caff.c:486). The attack vector is: Maliciously crafted .wav file. The fixed version is: After commit https://github.com/dbry/WavPack/commit/f68a9555b548306c5b1ee45199ccdc4a16a6101b.",
        "git_url": "https://github.com/dbry/WavPack/commit/f68a9555b548306c5b1ee45199ccdc4a16a6101b",
        "commit_title": "issue #66: make sure CAF files have a \"desc\" chunk",
        "commit_text": "",
        "func_before": "int ParseCaffHeaderConfig (FILE *infile, char *infilename, char *fourcc, WavpackContext *wpc, WavpackConfig *config)\n{\n    uint32_t chan_chunk = 0, channel_layout = 0, bcount;\n    unsigned char *channel_identities = NULL;\n    unsigned char *channel_reorder = NULL;\n    int64_t total_samples = 0, infilesize;\n    CAFFileHeader caf_file_header;\n    CAFChunkHeader caf_chunk_header;\n    CAFAudioFormat caf_audio_format;\n    int i;\n\n    infilesize = DoGetFileSize (infile);\n    memcpy (&caf_file_header, fourcc, 4);\n\n    if ((!DoReadFile (infile, ((char *) &caf_file_header) + 4, sizeof (CAFFileHeader) - 4, &bcount) ||\n        bcount != sizeof (CAFFileHeader) - 4)) {\n            error_line (\"%s is not a valid .CAF file!\", infilename);\n            return WAVPACK_SOFT_ERROR;\n    }\n    else if (!(config->qmode & QMODE_NO_STORE_WRAPPER) &&\n        !WavpackAddWrapper (wpc, &caf_file_header, sizeof (CAFFileHeader))) {\n            error_line (\"%s\", WavpackGetErrorMessage (wpc));\n            return WAVPACK_SOFT_ERROR;\n    }\n\n    WavpackBigEndianToNative (&caf_file_header, CAFFileHeaderFormat);\n\n    if (caf_file_header.mFileVersion != 1) {\n        error_line (\"%s: can't handle version %d .CAF files!\", infilename, caf_file_header.mFileVersion);\n        return WAVPACK_SOFT_ERROR;\n    }\n\n    // loop through all elements of the RIFF wav header\n    // (until the data chuck) and copy them to the output file\n\n    while (1) {\n        if (!DoReadFile (infile, &caf_chunk_header, sizeof (CAFChunkHeader), &bcount) ||\n            bcount != sizeof (CAFChunkHeader)) {\n                error_line (\"%s is not a valid .CAF file!\", infilename);\n                return WAVPACK_SOFT_ERROR;\n        }\n        else if (!(config->qmode & QMODE_NO_STORE_WRAPPER) &&\n            !WavpackAddWrapper (wpc, &caf_chunk_header, sizeof (CAFChunkHeader))) {\n                error_line (\"%s\", WavpackGetErrorMessage (wpc));\n                return WAVPACK_SOFT_ERROR;\n        }\n\n        WavpackBigEndianToNative (&caf_chunk_header, CAFChunkHeaderFormat);\n\n        // if it's the format chunk, we want to get some info out of there and\n        // make sure it's a .caf file we can handle\n\n        if (!strncmp (caf_chunk_header.mChunkType, \"desc\", 4)) {\n            int supported = TRUE;\n\n            if (caf_chunk_header.mChunkSize != sizeof (CAFAudioFormat) ||\n                !DoReadFile (infile, &caf_audio_format, (uint32_t) caf_chunk_header.mChunkSize, &bcount) ||\n                bcount != caf_chunk_header.mChunkSize) {\n                    error_line (\"%s is not a valid .CAF file!\", infilename);\n                    return WAVPACK_SOFT_ERROR;\n            }\n            else if (!(config->qmode & QMODE_NO_STORE_WRAPPER) &&\n                !WavpackAddWrapper (wpc, &caf_audio_format, (uint32_t) caf_chunk_header.mChunkSize)) {\n                    error_line (\"%s\", WavpackGetErrorMessage (wpc));\n                    return WAVPACK_SOFT_ERROR;\n            }\n\n            WavpackBigEndianToNative (&caf_audio_format, CAFAudioFormatFormat);\n\n            if (debug_logging_mode) {\n                char formatstr [5];\n\n                memcpy (formatstr, caf_audio_format.mFormatID, 4);\n                formatstr [4] = 0;\n                error_line (\"format = %s, flags = %x, sampling rate = %g\",\n                    formatstr, caf_audio_format.mFormatFlags, caf_audio_format.mSampleRate);\n                error_line (\"packet = %d bytes and %d frames\",\n                    caf_audio_format.mBytesPerPacket, caf_audio_format.mFramesPerPacket);\n                error_line (\"channels per frame = %d, bits per channel = %d\",\n                    caf_audio_format.mChannelsPerFrame, caf_audio_format.mBitsPerChannel);\n            }\n\n            if (strncmp (caf_audio_format.mFormatID, \"lpcm\", 4) || (caf_audio_format.mFormatFlags & ~3))\n                supported = FALSE;\n            else if (caf_audio_format.mSampleRate < 1.0 || caf_audio_format.mSampleRate > 16777215.0 ||\n                caf_audio_format.mSampleRate != floor (caf_audio_format.mSampleRate))\n                    supported = FALSE;\n            else if (!caf_audio_format.mChannelsPerFrame || caf_audio_format.mChannelsPerFrame > 256)\n                supported = FALSE;\n            else if (caf_audio_format.mBitsPerChannel < 1 || caf_audio_format.mBitsPerChannel > 32 ||\n                ((caf_audio_format.mFormatFlags & CAF_FORMAT_FLOAT) && caf_audio_format.mBitsPerChannel != 32))\n                    supported = FALSE;\n            else if (caf_audio_format.mFramesPerPacket != 1 ||\n                caf_audio_format.mBytesPerPacket / caf_audio_format.mChannelsPerFrame < (caf_audio_format.mBitsPerChannel + 7) / 8 ||\n                caf_audio_format.mBytesPerPacket / caf_audio_format.mChannelsPerFrame > 4 ||\n                caf_audio_format.mBytesPerPacket % caf_audio_format.mChannelsPerFrame)\n                    supported = FALSE;\n\n            if (!supported) {\n                error_line (\"%s is an unsupported .CAF format!\", infilename);\n                return WAVPACK_SOFT_ERROR;\n            }\n\n            config->bytes_per_sample = caf_audio_format.mBytesPerPacket / caf_audio_format.mChannelsPerFrame;\n            config->float_norm_exp = (caf_audio_format.mFormatFlags & CAF_FORMAT_FLOAT) ? 127 : 0;\n            config->bits_per_sample = caf_audio_format.mBitsPerChannel;\n            config->num_channels = caf_audio_format.mChannelsPerFrame;\n            config->sample_rate = (int) caf_audio_format.mSampleRate;\n\n            if (!(caf_audio_format.mFormatFlags & CAF_FORMAT_LITTLE_ENDIAN) && config->bytes_per_sample > 1)\n                config->qmode |= QMODE_BIG_ENDIAN;\n\n            if (config->bytes_per_sample == 1)\n                config->qmode |= QMODE_SIGNED_BYTES;\n\n            if (debug_logging_mode) {\n                if (config->float_norm_exp == 127)\n                    error_line (\"data format: 32-bit %s-endian floating point\", (config->qmode & QMODE_BIG_ENDIAN) ? \"big\" : \"little\");\n                else\n                    error_line (\"data format: %d-bit %s-endian integers stored in %d byte(s)\",\n                        config->bits_per_sample, (config->qmode & QMODE_BIG_ENDIAN) ? \"big\" : \"little\", config->bytes_per_sample);\n            }\n        }\n        else if (!strncmp (caf_chunk_header.mChunkType, \"chan\", 4)) {\n            CAFChannelLayout *caf_channel_layout;\n\n            if (caf_chunk_header.mChunkSize < 0 || caf_chunk_header.mChunkSize > 1024 ||\n                caf_chunk_header.mChunkSize < sizeof (CAFChannelLayout)) {\n                    error_line (\"this .CAF file has an invalid 'chan' chunk!\");\n                    return WAVPACK_SOFT_ERROR;\n            }\n\n            if (debug_logging_mode)\n                error_line (\"'chan' chunk is %d bytes\", (int) caf_chunk_header.mChunkSize);\n\n            caf_channel_layout = malloc ((size_t) caf_chunk_header.mChunkSize);\n\n            if (!DoReadFile (infile, caf_channel_layout, (uint32_t) caf_chunk_header.mChunkSize, &bcount) ||\n                bcount != caf_chunk_header.mChunkSize) {\n                    error_line (\"%s is not a valid .CAF file!\", infilename);\n                    free (caf_channel_layout);\n                    return WAVPACK_SOFT_ERROR;\n            }\n            else if (!(config->qmode & QMODE_NO_STORE_WRAPPER) &&\n                !WavpackAddWrapper (wpc, caf_channel_layout, (uint32_t) caf_chunk_header.mChunkSize)) {\n                    error_line (\"%s\", WavpackGetErrorMessage (wpc));\n                    free (caf_channel_layout);\n                    return WAVPACK_SOFT_ERROR;\n            }\n\n            WavpackBigEndianToNative (caf_channel_layout, CAFChannelLayoutFormat);\n            chan_chunk = 1;\n\n            if (config->channel_mask || (config->qmode & QMODE_CHANS_UNASSIGNED)) {\n                error_line (\"this CAF file already has channel order information!\");\n                free (caf_channel_layout);\n                return WAVPACK_SOFT_ERROR;\n            }\n\n            switch (caf_channel_layout->mChannelLayoutTag) {\n                case kCAFChannelLayoutTag_UseChannelDescriptions:\n                    {\n                        CAFChannelDescription *descriptions = (CAFChannelDescription *) (caf_channel_layout + 1);\n                        int num_descriptions = caf_channel_layout->mNumberChannelDescriptions;\n                        int label, cindex = 0, idents = 0;\n\n                        if (caf_chunk_header.mChunkSize != sizeof (CAFChannelLayout) + sizeof (CAFChannelDescription) * num_descriptions ||\n                            num_descriptions != config->num_channels) {\n                                error_line (\"channel descriptions in 'chan' chunk are the wrong size!\");\n                                free (caf_channel_layout);\n                                return WAVPACK_SOFT_ERROR;\n                        }\n\n                        if (num_descriptions >= 256) {\n                            error_line (\"%d channel descriptions is more than we can handle...ignoring!\");\n                            break;\n                        }\n\n                        // we allocate (and initialize to invalid values) a channel reorder array\n                        // (even though we might not end up doing any reordering) and a string for\n                        // any non-Microsoft channels we encounter\n\n                        channel_reorder = malloc (num_descriptions);\n                        memset (channel_reorder, -1, num_descriptions);\n                        channel_identities = malloc (num_descriptions+1);\n\n                        // convert the descriptions array to our native endian so it's easy to access\n\n                        for (i = 0; i < num_descriptions; ++i) {\n                            WavpackBigEndianToNative (descriptions + i, CAFChannelDescriptionFormat);\n\n                            if (debug_logging_mode)\n                                error_line (\"chan %d --> %d\", i + 1, descriptions [i].mChannelLabel);\n                        }\n\n                        // first, we go though and find any MS channels present, and move those to the beginning\n\n                        for (label = 1; label <= 18; ++label)\n                            for (i = 0; i < num_descriptions; ++i)\n                                if (descriptions [i].mChannelLabel == label) {\n                                    config->channel_mask |= 1 << (label - 1);\n                                    channel_reorder [i] = cindex++;\n                                    break;\n                                }\n\n                        // next, we go though the channels again assigning any we haven't done\n\n                        for (i = 0; i < num_descriptions; ++i)\n                            if (channel_reorder [i] == (unsigned char) -1) {\n                                uint32_t clabel = descriptions [i].mChannelLabel;\n\n                                if (clabel == 0 || clabel == 0xffffffff || clabel == 100)\n                                    channel_identities [idents++] = 0xff;\n                                else if ((clabel >= 33 && clabel <= 44) || (clabel >= 200 && clabel <= 207) || (clabel >= 301 && clabel <= 305))\n                                    channel_identities [idents++] = clabel >= 301 ? clabel - 80 : clabel;\n                                else {\n                                    error_line (\"warning: unknown channel descriptions label: %d\", clabel);\n                                    channel_identities [idents++] = 0xff;\n                                }\n\n                                channel_reorder [i] = cindex++;\n                            }\n\n                        // then, go through the reordering array and see if we really have to reorder\n\n                        for (i = 0; i < num_descriptions; ++i)\n                            if (channel_reorder [i] != i)\n                                break;\n\n                        if (i == num_descriptions) {\n                            free (channel_reorder);                 // no reordering required, so don't\n                            channel_reorder = NULL;\n                        }\n                        else {\n                            config->qmode |= QMODE_REORDERED_CHANS; // reordering required, put channel count into layout\n                            channel_layout = num_descriptions;\n                        }\n\n                        if (!idents) {                              // if no non-MS channels, free the identities string\n                            free (channel_identities);\n                            channel_identities = NULL;\n                        }\n                        else\n                            channel_identities [idents] = 0;        // otherwise NULL terminate it\n\n                        if (debug_logging_mode) {\n                            error_line (\"layout_tag = 0x%08x, so generated bitmap of 0x%08x from %d descriptions, %d non-MS\",\n                                caf_channel_layout->mChannelLayoutTag, config->channel_mask,\n                                caf_channel_layout->mNumberChannelDescriptions, idents);\n\n                            // if debugging, display the reordering as a string (but only little ones)\n\n                            if (channel_reorder && num_descriptions <= 8) {\n                                char reorder_string [] = \"12345678\";\n\n                                for (i = 0; i < num_descriptions; ++i)\n                                    reorder_string [i] = channel_reorder [i] + '1';\n\n                                reorder_string [i] = 0;\n                                error_line (\"reordering string = \\\"%s\\\"\\n\", reorder_string);\n                            }\n                        }\n                    }\n\n                    break;\n\n                case kCAFChannelLayoutTag_UseChannelBitmap:\n                    config->channel_mask = caf_channel_layout->mChannelBitmap;\n\n                    if (debug_logging_mode)\n                        error_line (\"layout_tag = 0x%08x, so using supplied bitmap of 0x%08x\",\n                            caf_channel_layout->mChannelLayoutTag, caf_channel_layout->mChannelBitmap);\n\n                    break;\n\n                default:\n                    for (i = 0; i < NUM_LAYOUTS; ++i)\n                        if (caf_channel_layout->mChannelLayoutTag == layouts [i].mChannelLayoutTag) {\n                            config->channel_mask = layouts [i].mChannelBitmap;\n                            channel_layout = layouts [i].mChannelLayoutTag;\n\n                            if (layouts [i].mChannelReorder) {\n                                channel_reorder = (unsigned char *) strdup (layouts [i].mChannelReorder);\n                                config->qmode |= QMODE_REORDERED_CHANS;\n                            }\n\n                            if (layouts [i].mChannelIdentities)\n                                channel_identities = (unsigned char *) strdup (layouts [i].mChannelIdentities);\n\n                            if (debug_logging_mode)\n                                error_line (\"layout_tag 0x%08x found in table, bitmap = 0x%08x, reorder = %s, identities = %s\",\n                                    channel_layout, config->channel_mask, channel_reorder ? \"yes\" : \"no\", channel_identities ? \"yes\" : \"no\");\n\n                            break;\n                        }\n\n                    if (i == NUM_LAYOUTS && debug_logging_mode)\n                        error_line (\"layout_tag 0x%08x not found in table...all channels unassigned\",\n                            caf_channel_layout->mChannelLayoutTag);\n\n                    break;\n            }\n\n            free (caf_channel_layout);\n        }\n        else if (!strncmp (caf_chunk_header.mChunkType, \"data\", 4)) {     // on the data chunk, get size and exit loop\n            uint32_t mEditCount;\n\n            if (!DoReadFile (infile, &mEditCount, sizeof (mEditCount), &bcount) ||\n                bcount != sizeof (mEditCount)) {\n                    error_line (\"%s is not a valid .CAF file!\", infilename);\n                    return WAVPACK_SOFT_ERROR;\n            }\n            else if (!(config->qmode & QMODE_NO_STORE_WRAPPER) &&\n                !WavpackAddWrapper (wpc, &mEditCount, sizeof (mEditCount))) {\n                    error_line (\"%s\", WavpackGetErrorMessage (wpc));\n                    return WAVPACK_SOFT_ERROR;\n            }\n\n            if ((config->qmode & QMODE_IGNORE_LENGTH) || caf_chunk_header.mChunkSize == -1) {\n                config->qmode |= QMODE_IGNORE_LENGTH;\n\n                if (infilesize && DoGetFilePosition (infile) != -1)\n                    total_samples = (infilesize - DoGetFilePosition (infile)) / caf_audio_format.mBytesPerPacket;\n                else\n                    total_samples = -1;\n            }\n            else {\n                if (infilesize && infilesize - caf_chunk_header.mChunkSize > 16777216) {\n                    error_line (\".CAF file %s has over 16 MB of extra CAFF data, probably is corrupt!\", infilename);\n                    return WAVPACK_SOFT_ERROR;\n                }\n\n                if ((caf_chunk_header.mChunkSize - 4) % caf_audio_format.mBytesPerPacket) {\n                    error_line (\".CAF file %s has an invalid data chunk size, probably is corrupt!\", infilename);\n                    return WAVPACK_SOFT_ERROR;\n                }\n\n                total_samples = (caf_chunk_header.mChunkSize - 4) / caf_audio_format.mBytesPerPacket;\n\n                if (!total_samples) {\n                    error_line (\"this .CAF file has no audio samples, probably is corrupt!\");\n                    return WAVPACK_SOFT_ERROR;\n                }\n\n                if (total_samples > MAX_WAVPACK_SAMPLES) {\n                    error_line (\"%s has too many samples for WavPack!\", infilename);\n                    return WAVPACK_SOFT_ERROR;\n                }\n            }\n\n            break;\n        }\n        else {          // just copy unknown chunks to output file\n\n            uint32_t bytes_to_copy = (uint32_t) caf_chunk_header.mChunkSize;\n            char *buff;\n\n            if (caf_chunk_header.mChunkSize < 0 || caf_chunk_header.mChunkSize > 1048576) {\n                error_line (\"%s is not a valid .CAF file!\", infilename);\n                return WAVPACK_SOFT_ERROR;\n            }\n\n            buff = malloc (bytes_to_copy);\n\n            if (debug_logging_mode)\n                error_line (\"extra unknown chunk \\\"%c%c%c%c\\\" of %d bytes\",\n                    caf_chunk_header.mChunkType [0], caf_chunk_header.mChunkType [1], caf_chunk_header.mChunkType [2],\n                    caf_chunk_header.mChunkType [3], caf_chunk_header.mChunkSize);\n\n            if (!DoReadFile (infile, buff, bytes_to_copy, &bcount) ||\n                bcount != bytes_to_copy ||\n                (!(config->qmode & QMODE_NO_STORE_WRAPPER) &&\n                !WavpackAddWrapper (wpc, buff, bytes_to_copy))) {\n                    error_line (\"%s\", WavpackGetErrorMessage (wpc));\n                    free (buff);\n                    return WAVPACK_SOFT_ERROR;\n            }\n\n            free (buff);\n        }\n    }\n\n    if (!chan_chunk && !config->channel_mask && config->num_channels <= 2 && !(config->qmode & QMODE_CHANS_UNASSIGNED))\n        config->channel_mask = 0x5 - config->num_channels;\n\n    if (!WavpackSetConfiguration64 (wpc, config, total_samples, channel_identities)) {\n        error_line (\"%s\", WavpackGetErrorMessage (wpc));\n        return WAVPACK_SOFT_ERROR;\n    }\n\n    if (channel_identities)\n        free (channel_identities);\n\n    if (channel_layout || channel_reorder) {\n        if (!WavpackSetChannelLayout (wpc, channel_layout, channel_reorder)) {\n            error_line (\"problem with setting channel layout (should not happen)\");\n            return WAVPACK_SOFT_ERROR;\n        }\n\n        if (channel_reorder)\n            free (channel_reorder);\n    }\n\n    return WAVPACK_NO_ERROR;\n}",
        "func": "int ParseCaffHeaderConfig (FILE *infile, char *infilename, char *fourcc, WavpackContext *wpc, WavpackConfig *config)\n{\n    uint32_t chan_chunk = 0, desc_chunk = 0, channel_layout = 0, bcount;\n    unsigned char *channel_identities = NULL;\n    unsigned char *channel_reorder = NULL;\n    int64_t total_samples = 0, infilesize;\n    CAFFileHeader caf_file_header;\n    CAFChunkHeader caf_chunk_header;\n    CAFAudioFormat caf_audio_format;\n    int i;\n\n    infilesize = DoGetFileSize (infile);\n    memcpy (&caf_file_header, fourcc, 4);\n\n    if ((!DoReadFile (infile, ((char *) &caf_file_header) + 4, sizeof (CAFFileHeader) - 4, &bcount) ||\n        bcount != sizeof (CAFFileHeader) - 4)) {\n            error_line (\"%s is not a valid .CAF file!\", infilename);\n            return WAVPACK_SOFT_ERROR;\n    }\n    else if (!(config->qmode & QMODE_NO_STORE_WRAPPER) &&\n        !WavpackAddWrapper (wpc, &caf_file_header, sizeof (CAFFileHeader))) {\n            error_line (\"%s\", WavpackGetErrorMessage (wpc));\n            return WAVPACK_SOFT_ERROR;\n    }\n\n    WavpackBigEndianToNative (&caf_file_header, CAFFileHeaderFormat);\n\n    if (caf_file_header.mFileVersion != 1) {\n        error_line (\"%s: can't handle version %d .CAF files!\", infilename, caf_file_header.mFileVersion);\n        return WAVPACK_SOFT_ERROR;\n    }\n\n    // loop through all elements of the RIFF wav header\n    // (until the data chuck) and copy them to the output file\n\n    while (1) {\n        if (!DoReadFile (infile, &caf_chunk_header, sizeof (CAFChunkHeader), &bcount) ||\n            bcount != sizeof (CAFChunkHeader)) {\n                error_line (\"%s is not a valid .CAF file!\", infilename);\n                return WAVPACK_SOFT_ERROR;\n        }\n        else if (!(config->qmode & QMODE_NO_STORE_WRAPPER) &&\n            !WavpackAddWrapper (wpc, &caf_chunk_header, sizeof (CAFChunkHeader))) {\n                error_line (\"%s\", WavpackGetErrorMessage (wpc));\n                return WAVPACK_SOFT_ERROR;\n        }\n\n        WavpackBigEndianToNative (&caf_chunk_header, CAFChunkHeaderFormat);\n\n        // if it's the format chunk, we want to get some info out of there and\n        // make sure it's a .caf file we can handle\n\n        if (!strncmp (caf_chunk_header.mChunkType, \"desc\", 4)) {\n            int supported = TRUE;\n\n            if (caf_chunk_header.mChunkSize != sizeof (CAFAudioFormat) ||\n                !DoReadFile (infile, &caf_audio_format, (uint32_t) caf_chunk_header.mChunkSize, &bcount) ||\n                bcount != caf_chunk_header.mChunkSize) {\n                    error_line (\"%s is not a valid .CAF file!\", infilename);\n                    return WAVPACK_SOFT_ERROR;\n            }\n            else if (!(config->qmode & QMODE_NO_STORE_WRAPPER) &&\n                !WavpackAddWrapper (wpc, &caf_audio_format, (uint32_t) caf_chunk_header.mChunkSize)) {\n                    error_line (\"%s\", WavpackGetErrorMessage (wpc));\n                    return WAVPACK_SOFT_ERROR;\n            }\n\n            WavpackBigEndianToNative (&caf_audio_format, CAFAudioFormatFormat);\n            desc_chunk = 1;\n\n            if (debug_logging_mode) {\n                char formatstr [5];\n\n                memcpy (formatstr, caf_audio_format.mFormatID, 4);\n                formatstr [4] = 0;\n                error_line (\"format = %s, flags = %x, sampling rate = %g\",\n                    formatstr, caf_audio_format.mFormatFlags, caf_audio_format.mSampleRate);\n                error_line (\"packet = %d bytes and %d frames\",\n                    caf_audio_format.mBytesPerPacket, caf_audio_format.mFramesPerPacket);\n                error_line (\"channels per frame = %d, bits per channel = %d\",\n                    caf_audio_format.mChannelsPerFrame, caf_audio_format.mBitsPerChannel);\n            }\n\n            if (strncmp (caf_audio_format.mFormatID, \"lpcm\", 4) || (caf_audio_format.mFormatFlags & ~3))\n                supported = FALSE;\n            else if (caf_audio_format.mSampleRate < 1.0 || caf_audio_format.mSampleRate > 16777215.0 ||\n                caf_audio_format.mSampleRate != floor (caf_audio_format.mSampleRate))\n                    supported = FALSE;\n            else if (!caf_audio_format.mChannelsPerFrame || caf_audio_format.mChannelsPerFrame > 256)\n                supported = FALSE;\n            else if (caf_audio_format.mBitsPerChannel < 1 || caf_audio_format.mBitsPerChannel > 32 ||\n                ((caf_audio_format.mFormatFlags & CAF_FORMAT_FLOAT) && caf_audio_format.mBitsPerChannel != 32))\n                    supported = FALSE;\n            else if (caf_audio_format.mFramesPerPacket != 1 ||\n                caf_audio_format.mBytesPerPacket / caf_audio_format.mChannelsPerFrame < (caf_audio_format.mBitsPerChannel + 7) / 8 ||\n                caf_audio_format.mBytesPerPacket / caf_audio_format.mChannelsPerFrame > 4 ||\n                caf_audio_format.mBytesPerPacket % caf_audio_format.mChannelsPerFrame)\n                    supported = FALSE;\n\n            if (!supported) {\n                error_line (\"%s is an unsupported .CAF format!\", infilename);\n                return WAVPACK_SOFT_ERROR;\n            }\n\n            config->bytes_per_sample = caf_audio_format.mBytesPerPacket / caf_audio_format.mChannelsPerFrame;\n            config->float_norm_exp = (caf_audio_format.mFormatFlags & CAF_FORMAT_FLOAT) ? 127 : 0;\n            config->bits_per_sample = caf_audio_format.mBitsPerChannel;\n            config->num_channels = caf_audio_format.mChannelsPerFrame;\n            config->sample_rate = (int) caf_audio_format.mSampleRate;\n\n            if (!(caf_audio_format.mFormatFlags & CAF_FORMAT_LITTLE_ENDIAN) && config->bytes_per_sample > 1)\n                config->qmode |= QMODE_BIG_ENDIAN;\n\n            if (config->bytes_per_sample == 1)\n                config->qmode |= QMODE_SIGNED_BYTES;\n\n            if (debug_logging_mode) {\n                if (config->float_norm_exp == 127)\n                    error_line (\"data format: 32-bit %s-endian floating point\", (config->qmode & QMODE_BIG_ENDIAN) ? \"big\" : \"little\");\n                else\n                    error_line (\"data format: %d-bit %s-endian integers stored in %d byte(s)\",\n                        config->bits_per_sample, (config->qmode & QMODE_BIG_ENDIAN) ? \"big\" : \"little\", config->bytes_per_sample);\n            }\n        }\n        else if (!strncmp (caf_chunk_header.mChunkType, \"chan\", 4)) {\n            CAFChannelLayout *caf_channel_layout;\n\n            if (caf_chunk_header.mChunkSize < 0 || caf_chunk_header.mChunkSize > 1024 ||\n                caf_chunk_header.mChunkSize < sizeof (CAFChannelLayout)) {\n                    error_line (\"this .CAF file has an invalid 'chan' chunk!\");\n                    return WAVPACK_SOFT_ERROR;\n            }\n\n            if (debug_logging_mode)\n                error_line (\"'chan' chunk is %d bytes\", (int) caf_chunk_header.mChunkSize);\n\n            caf_channel_layout = malloc ((size_t) caf_chunk_header.mChunkSize);\n\n            if (!DoReadFile (infile, caf_channel_layout, (uint32_t) caf_chunk_header.mChunkSize, &bcount) ||\n                bcount != caf_chunk_header.mChunkSize) {\n                    error_line (\"%s is not a valid .CAF file!\", infilename);\n                    free (caf_channel_layout);\n                    return WAVPACK_SOFT_ERROR;\n            }\n            else if (!(config->qmode & QMODE_NO_STORE_WRAPPER) &&\n                !WavpackAddWrapper (wpc, caf_channel_layout, (uint32_t) caf_chunk_header.mChunkSize)) {\n                    error_line (\"%s\", WavpackGetErrorMessage (wpc));\n                    free (caf_channel_layout);\n                    return WAVPACK_SOFT_ERROR;\n            }\n\n            WavpackBigEndianToNative (caf_channel_layout, CAFChannelLayoutFormat);\n            chan_chunk = 1;\n\n            if (config->channel_mask || (config->qmode & QMODE_CHANS_UNASSIGNED)) {\n                error_line (\"this CAF file already has channel order information!\");\n                free (caf_channel_layout);\n                return WAVPACK_SOFT_ERROR;\n            }\n\n            switch (caf_channel_layout->mChannelLayoutTag) {\n                case kCAFChannelLayoutTag_UseChannelDescriptions:\n                    {\n                        CAFChannelDescription *descriptions = (CAFChannelDescription *) (caf_channel_layout + 1);\n                        int num_descriptions = caf_channel_layout->mNumberChannelDescriptions;\n                        int label, cindex = 0, idents = 0;\n\n                        if (caf_chunk_header.mChunkSize != sizeof (CAFChannelLayout) + sizeof (CAFChannelDescription) * num_descriptions ||\n                            num_descriptions != config->num_channels) {\n                                error_line (\"channel descriptions in 'chan' chunk are the wrong size!\");\n                                free (caf_channel_layout);\n                                return WAVPACK_SOFT_ERROR;\n                        }\n\n                        if (num_descriptions >= 256) {\n                            error_line (\"%d channel descriptions is more than we can handle...ignoring!\");\n                            break;\n                        }\n\n                        // we allocate (and initialize to invalid values) a channel reorder array\n                        // (even though we might not end up doing any reordering) and a string for\n                        // any non-Microsoft channels we encounter\n\n                        channel_reorder = malloc (num_descriptions);\n                        memset (channel_reorder, -1, num_descriptions);\n                        channel_identities = malloc (num_descriptions+1);\n\n                        // convert the descriptions array to our native endian so it's easy to access\n\n                        for (i = 0; i < num_descriptions; ++i) {\n                            WavpackBigEndianToNative (descriptions + i, CAFChannelDescriptionFormat);\n\n                            if (debug_logging_mode)\n                                error_line (\"chan %d --> %d\", i + 1, descriptions [i].mChannelLabel);\n                        }\n\n                        // first, we go though and find any MS channels present, and move those to the beginning\n\n                        for (label = 1; label <= 18; ++label)\n                            for (i = 0; i < num_descriptions; ++i)\n                                if (descriptions [i].mChannelLabel == label) {\n                                    config->channel_mask |= 1 << (label - 1);\n                                    channel_reorder [i] = cindex++;\n                                    break;\n                                }\n\n                        // next, we go though the channels again assigning any we haven't done\n\n                        for (i = 0; i < num_descriptions; ++i)\n                            if (channel_reorder [i] == (unsigned char) -1) {\n                                uint32_t clabel = descriptions [i].mChannelLabel;\n\n                                if (clabel == 0 || clabel == 0xffffffff || clabel == 100)\n                                    channel_identities [idents++] = 0xff;\n                                else if ((clabel >= 33 && clabel <= 44) || (clabel >= 200 && clabel <= 207) || (clabel >= 301 && clabel <= 305))\n                                    channel_identities [idents++] = clabel >= 301 ? clabel - 80 : clabel;\n                                else {\n                                    error_line (\"warning: unknown channel descriptions label: %d\", clabel);\n                                    channel_identities [idents++] = 0xff;\n                                }\n\n                                channel_reorder [i] = cindex++;\n                            }\n\n                        // then, go through the reordering array and see if we really have to reorder\n\n                        for (i = 0; i < num_descriptions; ++i)\n                            if (channel_reorder [i] != i)\n                                break;\n\n                        if (i == num_descriptions) {\n                            free (channel_reorder);                 // no reordering required, so don't\n                            channel_reorder = NULL;\n                        }\n                        else {\n                            config->qmode |= QMODE_REORDERED_CHANS; // reordering required, put channel count into layout\n                            channel_layout = num_descriptions;\n                        }\n\n                        if (!idents) {                              // if no non-MS channels, free the identities string\n                            free (channel_identities);\n                            channel_identities = NULL;\n                        }\n                        else\n                            channel_identities [idents] = 0;        // otherwise NULL terminate it\n\n                        if (debug_logging_mode) {\n                            error_line (\"layout_tag = 0x%08x, so generated bitmap of 0x%08x from %d descriptions, %d non-MS\",\n                                caf_channel_layout->mChannelLayoutTag, config->channel_mask,\n                                caf_channel_layout->mNumberChannelDescriptions, idents);\n\n                            // if debugging, display the reordering as a string (but only little ones)\n\n                            if (channel_reorder && num_descriptions <= 8) {\n                                char reorder_string [] = \"12345678\";\n\n                                for (i = 0; i < num_descriptions; ++i)\n                                    reorder_string [i] = channel_reorder [i] + '1';\n\n                                reorder_string [i] = 0;\n                                error_line (\"reordering string = \\\"%s\\\"\\n\", reorder_string);\n                            }\n                        }\n                    }\n\n                    break;\n\n                case kCAFChannelLayoutTag_UseChannelBitmap:\n                    config->channel_mask = caf_channel_layout->mChannelBitmap;\n\n                    if (debug_logging_mode)\n                        error_line (\"layout_tag = 0x%08x, so using supplied bitmap of 0x%08x\",\n                            caf_channel_layout->mChannelLayoutTag, caf_channel_layout->mChannelBitmap);\n\n                    break;\n\n                default:\n                    for (i = 0; i < NUM_LAYOUTS; ++i)\n                        if (caf_channel_layout->mChannelLayoutTag == layouts [i].mChannelLayoutTag) {\n                            config->channel_mask = layouts [i].mChannelBitmap;\n                            channel_layout = layouts [i].mChannelLayoutTag;\n\n                            if (layouts [i].mChannelReorder) {\n                                channel_reorder = (unsigned char *) strdup (layouts [i].mChannelReorder);\n                                config->qmode |= QMODE_REORDERED_CHANS;\n                            }\n\n                            if (layouts [i].mChannelIdentities)\n                                channel_identities = (unsigned char *) strdup (layouts [i].mChannelIdentities);\n\n                            if (debug_logging_mode)\n                                error_line (\"layout_tag 0x%08x found in table, bitmap = 0x%08x, reorder = %s, identities = %s\",\n                                    channel_layout, config->channel_mask, channel_reorder ? \"yes\" : \"no\", channel_identities ? \"yes\" : \"no\");\n\n                            break;\n                        }\n\n                    if (i == NUM_LAYOUTS && debug_logging_mode)\n                        error_line (\"layout_tag 0x%08x not found in table...all channels unassigned\",\n                            caf_channel_layout->mChannelLayoutTag);\n\n                    break;\n            }\n\n            free (caf_channel_layout);\n        }\n        else if (!strncmp (caf_chunk_header.mChunkType, \"data\", 4)) {     // on the data chunk, get size and exit loop\n            uint32_t mEditCount;\n\n            if (!desc_chunk || !DoReadFile (infile, &mEditCount, sizeof (mEditCount), &bcount) ||\n                bcount != sizeof (mEditCount)) {\n                    error_line (\"%s is not a valid .CAF file!\", infilename);\n                    return WAVPACK_SOFT_ERROR;\n            }\n            else if (!(config->qmode & QMODE_NO_STORE_WRAPPER) &&\n                !WavpackAddWrapper (wpc, &mEditCount, sizeof (mEditCount))) {\n                    error_line (\"%s\", WavpackGetErrorMessage (wpc));\n                    return WAVPACK_SOFT_ERROR;\n            }\n\n            if ((config->qmode & QMODE_IGNORE_LENGTH) || caf_chunk_header.mChunkSize == -1) {\n                config->qmode |= QMODE_IGNORE_LENGTH;\n\n                if (infilesize && DoGetFilePosition (infile) != -1)\n                    total_samples = (infilesize - DoGetFilePosition (infile)) / caf_audio_format.mBytesPerPacket;\n                else\n                    total_samples = -1;\n            }\n            else {\n                if (infilesize && infilesize - caf_chunk_header.mChunkSize > 16777216) {\n                    error_line (\".CAF file %s has over 16 MB of extra CAFF data, probably is corrupt!\", infilename);\n                    return WAVPACK_SOFT_ERROR;\n                }\n\n                if ((caf_chunk_header.mChunkSize - 4) % caf_audio_format.mBytesPerPacket) {\n                    error_line (\".CAF file %s has an invalid data chunk size, probably is corrupt!\", infilename);\n                    return WAVPACK_SOFT_ERROR;\n                }\n\n                total_samples = (caf_chunk_header.mChunkSize - 4) / caf_audio_format.mBytesPerPacket;\n\n                if (!total_samples) {\n                    error_line (\"this .CAF file has no audio samples, probably is corrupt!\");\n                    return WAVPACK_SOFT_ERROR;\n                }\n\n                if (total_samples > MAX_WAVPACK_SAMPLES) {\n                    error_line (\"%s has too many samples for WavPack!\", infilename);\n                    return WAVPACK_SOFT_ERROR;\n                }\n            }\n\n            break;\n        }\n        else {          // just copy unknown chunks to output file\n\n            uint32_t bytes_to_copy = (uint32_t) caf_chunk_header.mChunkSize;\n            char *buff;\n\n            if (caf_chunk_header.mChunkSize < 0 || caf_chunk_header.mChunkSize > 1048576) {\n                error_line (\"%s is not a valid .CAF file!\", infilename);\n                return WAVPACK_SOFT_ERROR;\n            }\n\n            buff = malloc (bytes_to_copy);\n\n            if (debug_logging_mode)\n                error_line (\"extra unknown chunk \\\"%c%c%c%c\\\" of %d bytes\",\n                    caf_chunk_header.mChunkType [0], caf_chunk_header.mChunkType [1], caf_chunk_header.mChunkType [2],\n                    caf_chunk_header.mChunkType [3], caf_chunk_header.mChunkSize);\n\n            if (!DoReadFile (infile, buff, bytes_to_copy, &bcount) ||\n                bcount != bytes_to_copy ||\n                (!(config->qmode & QMODE_NO_STORE_WRAPPER) &&\n                !WavpackAddWrapper (wpc, buff, bytes_to_copy))) {\n                    error_line (\"%s\", WavpackGetErrorMessage (wpc));\n                    free (buff);\n                    return WAVPACK_SOFT_ERROR;\n            }\n\n            free (buff);\n        }\n    }\n\n    if (!chan_chunk && !config->channel_mask && config->num_channels <= 2 && !(config->qmode & QMODE_CHANS_UNASSIGNED))\n        config->channel_mask = 0x5 - config->num_channels;\n\n    if (!WavpackSetConfiguration64 (wpc, config, total_samples, channel_identities)) {\n        error_line (\"%s\", WavpackGetErrorMessage (wpc));\n        return WAVPACK_SOFT_ERROR;\n    }\n\n    if (channel_identities)\n        free (channel_identities);\n\n    if (channel_layout || channel_reorder) {\n        if (!WavpackSetChannelLayout (wpc, channel_layout, channel_reorder)) {\n            error_line (\"problem with setting channel layout (should not happen)\");\n            return WAVPACK_SOFT_ERROR;\n        }\n\n        if (channel_reorder)\n            free (channel_reorder);\n    }\n\n    return WAVPACK_NO_ERROR;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,6 @@\n int ParseCaffHeaderConfig (FILE *infile, char *infilename, char *fourcc, WavpackContext *wpc, WavpackConfig *config)\n {\n-    uint32_t chan_chunk = 0, channel_layout = 0, bcount;\n+    uint32_t chan_chunk = 0, desc_chunk = 0, channel_layout = 0, bcount;\n     unsigned char *channel_identities = NULL;\n     unsigned char *channel_reorder = NULL;\n     int64_t total_samples = 0, infilesize;\n@@ -66,6 +66,7 @@\n             }\n \n             WavpackBigEndianToNative (&caf_audio_format, CAFAudioFormatFormat);\n+            desc_chunk = 1;\n \n             if (debug_logging_mode) {\n                 char formatstr [5];\n@@ -306,7 +307,7 @@\n         else if (!strncmp (caf_chunk_header.mChunkType, \"data\", 4)) {     // on the data chunk, get size and exit loop\n             uint32_t mEditCount;\n \n-            if (!DoReadFile (infile, &mEditCount, sizeof (mEditCount), &bcount) ||\n+            if (!desc_chunk || !DoReadFile (infile, &mEditCount, sizeof (mEditCount), &bcount) ||\n                 bcount != sizeof (mEditCount)) {\n                     error_line (\"%s is not a valid .CAF file!\", infilename);\n                     return WAVPACK_SOFT_ERROR;",
        "diff_line_info": {
            "deleted_lines": [
                "    uint32_t chan_chunk = 0, channel_layout = 0, bcount;",
                "            if (!DoReadFile (infile, &mEditCount, sizeof (mEditCount), &bcount) ||"
            ],
            "added_lines": [
                "    uint32_t chan_chunk = 0, desc_chunk = 0, channel_layout = 0, bcount;",
                "            desc_chunk = 1;",
                "            if (!desc_chunk || !DoReadFile (infile, &mEditCount, sizeof (mEditCount), &bcount) ||"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-1010319",
        "func_name": "dbry/WavPack/ParseWave64HeaderConfig",
        "description": "WavPack 5.1.0 and earlier is affected by: CWE-457: Use of Uninitialized Variable. The impact is: Unexpected control flow, crashes, and segfaults. The component is: ParseWave64HeaderConfig (wave64.c:211). The attack vector is: Maliciously crafted .wav file. The fixed version is: After commit https://github.com/dbry/WavPack/commit/33a0025d1d63ccd05d9dbaa6923d52b1446a62fe.",
        "git_url": "https://github.com/dbry/WavPack/commit/33a0025d1d63ccd05d9dbaa6923d52b1446a62fe",
        "commit_title": "issue #68: clear WaveHeader at start to prevent uninitialized read",
        "commit_text": "",
        "func_before": "int ParseWave64HeaderConfig (FILE *infile, char *infilename, char *fourcc, WavpackContext *wpc, WavpackConfig *config)\n{\n    int64_t total_samples = 0, infilesize;\n    Wave64ChunkHeader chunk_header;\n    Wave64FileHeader filehdr;\n    WaveHeader WaveHeader;\n    int format_chunk = 0;\n    uint32_t bcount;\n\n    infilesize = DoGetFileSize (infile);\n    memcpy (&filehdr, fourcc, 4);\n\n    if (!DoReadFile (infile, ((char *) &filehdr) + 4, sizeof (Wave64FileHeader) - 4, &bcount) ||\n        bcount != sizeof (Wave64FileHeader) - 4 || memcmp (filehdr.ckID, riff_guid, sizeof (riff_guid)) ||\n        memcmp (filehdr.formType, wave_guid, sizeof (wave_guid))) {\n            error_line (\"%s is not a valid .W64 file!\", infilename);\n            return WAVPACK_SOFT_ERROR;\n    }\n    else if (!(config->qmode & QMODE_NO_STORE_WRAPPER) &&\n        !WavpackAddWrapper (wpc, &filehdr, sizeof (filehdr))) {\n            error_line (\"%s\", WavpackGetErrorMessage (wpc));\n            return WAVPACK_SOFT_ERROR;\n    }\n\n#if 1   // this might be a little too picky...\n    WavpackLittleEndianToNative (&filehdr, Wave64ChunkHeaderFormat);\n\n    if (infilesize && !(config->qmode & QMODE_IGNORE_LENGTH) &&\n        filehdr.ckSize && filehdr.ckSize + 1 && filehdr.ckSize != infilesize) {\n            error_line (\"%s is not a valid .W64 file!\", infilename);\n            return WAVPACK_SOFT_ERROR;\n    }\n#endif\n\n    // loop through all elements of the wave64 header\n    // (until the data chuck) and copy them to the output file\n\n    while (1) {\n        if (!DoReadFile (infile, &chunk_header, sizeof (Wave64ChunkHeader), &bcount) ||\n            bcount != sizeof (Wave64ChunkHeader)) {\n                error_line (\"%s is not a valid .W64 file!\", infilename);\n                return WAVPACK_SOFT_ERROR;\n        }\n        else if (!(config->qmode & QMODE_NO_STORE_WRAPPER) &&\n            !WavpackAddWrapper (wpc, &chunk_header, sizeof (Wave64ChunkHeader))) {\n                error_line (\"%s\", WavpackGetErrorMessage (wpc));\n                return WAVPACK_SOFT_ERROR;\n        }\n\n        WavpackLittleEndianToNative (&chunk_header, Wave64ChunkHeaderFormat);\n        chunk_header.ckSize -= sizeof (chunk_header);\n\n        // if it's the format chunk, we want to get some info out of there and\n        // make sure it's a .wav file we can handle\n\n        if (!memcmp (chunk_header.ckID, fmt_guid, sizeof (fmt_guid))) {\n            int supported = TRUE, format;\n\n            if (format_chunk++) {\n                error_line (\"%s is not a valid .W64 file!\", infilename);\n                return WAVPACK_SOFT_ERROR;\n            }\n\n            chunk_header.ckSize = (chunk_header.ckSize + 7) & ~7L;\n\n            if (chunk_header.ckSize < 16 || chunk_header.ckSize > sizeof (WaveHeader) ||\n                !DoReadFile (infile, &WaveHeader, (uint32_t) chunk_header.ckSize, &bcount) ||\n                bcount != chunk_header.ckSize) {\n                    error_line (\"%s is not a valid .W64 file!\", infilename);\n                    return WAVPACK_SOFT_ERROR;\n            }\n            else if (!(config->qmode & QMODE_NO_STORE_WRAPPER) &&\n                !WavpackAddWrapper (wpc, &WaveHeader, (uint32_t) chunk_header.ckSize)) {\n                    error_line (\"%s\", WavpackGetErrorMessage (wpc));\n                    return WAVPACK_SOFT_ERROR;\n            }\n\n            WavpackLittleEndianToNative (&WaveHeader, WaveHeaderFormat);\n\n            if (debug_logging_mode) {\n                error_line (\"format tag size = %d\", chunk_header.ckSize);\n                error_line (\"FormatTag = %x, NumChannels = %d, BitsPerSample = %d\",\n                    WaveHeader.FormatTag, WaveHeader.NumChannels, WaveHeader.BitsPerSample);\n                error_line (\"BlockAlign = %d, SampleRate = %d, BytesPerSecond = %d\",\n                    WaveHeader.BlockAlign, WaveHeader.SampleRate, WaveHeader.BytesPerSecond);\n\n                if (chunk_header.ckSize > 16)\n                    error_line (\"cbSize = %d, ValidBitsPerSample = %d\", WaveHeader.cbSize,\n                        WaveHeader.ValidBitsPerSample);\n\n                if (chunk_header.ckSize > 20)\n                    error_line (\"ChannelMask = %x, SubFormat = %d\",\n                        WaveHeader.ChannelMask, WaveHeader.SubFormat);\n            }\n\n            if (chunk_header.ckSize > 16 && WaveHeader.cbSize == 2)\n                config->qmode |= QMODE_ADOBE_MODE;\n\n            format = (WaveHeader.FormatTag == 0xfffe && chunk_header.ckSize == 40) ?\n                WaveHeader.SubFormat : WaveHeader.FormatTag;\n\n            config->bits_per_sample = (chunk_header.ckSize == 40 && WaveHeader.ValidBitsPerSample) ?\n                WaveHeader.ValidBitsPerSample : WaveHeader.BitsPerSample;\n\n            if (format != 1 && format != 3)\n                supported = FALSE;\n\n            if (format == 3 && config->bits_per_sample != 32)\n                supported = FALSE;\n\n            if (!WaveHeader.NumChannels || WaveHeader.NumChannels > 256 ||\n                WaveHeader.BlockAlign / WaveHeader.NumChannels < (config->bits_per_sample + 7) / 8 ||\n                WaveHeader.BlockAlign / WaveHeader.NumChannels > 4 ||\n                WaveHeader.BlockAlign % WaveHeader.NumChannels)\n                    supported = FALSE;\n\n            if (config->bits_per_sample < 1 || config->bits_per_sample > 32)\n                supported = FALSE;\n\n            if (!supported) {\n                error_line (\"%s is an unsupported .W64 format!\", infilename);\n                return WAVPACK_SOFT_ERROR;\n            }\n\n            if (chunk_header.ckSize < 40) {\n                if (!config->channel_mask && !(config->qmode & QMODE_CHANS_UNASSIGNED)) {\n                    if (WaveHeader.NumChannels <= 2)\n                        config->channel_mask = 0x5 - WaveHeader.NumChannels;\n                    else if (WaveHeader.NumChannels <= 18)\n                        config->channel_mask = (1 << WaveHeader.NumChannels) - 1;\n                    else\n                        config->channel_mask = 0x3ffff;\n                }\n            }\n            else if (WaveHeader.ChannelMask && (config->channel_mask || (config->qmode & QMODE_CHANS_UNASSIGNED))) {\n                error_line (\"this W64 file already has channel order information!\");\n                return WAVPACK_SOFT_ERROR;\n            }\n            else if (WaveHeader.ChannelMask)\n                config->channel_mask = WaveHeader.ChannelMask;\n\n            if (format == 3)\n                config->float_norm_exp = 127;\n            else if ((config->qmode & QMODE_ADOBE_MODE) &&\n                WaveHeader.BlockAlign / WaveHeader.NumChannels == 4) {\n                    if (WaveHeader.BitsPerSample == 24)\n                        config->float_norm_exp = 127 + 23;\n                    else if (WaveHeader.BitsPerSample == 32)\n                        config->float_norm_exp = 127 + 15;\n            }\n\n            if (debug_logging_mode) {\n                if (config->float_norm_exp == 127)\n                    error_line (\"data format: normalized 32-bit floating point\");\n                else\n                    error_line (\"data format: %d-bit integers stored in %d byte(s)\",\n                        config->bits_per_sample, WaveHeader.BlockAlign / WaveHeader.NumChannels);\n            }\n        }\n        else if (!memcmp (chunk_header.ckID, data_guid, sizeof (data_guid))) { // on the data chunk, get size and exit loop\n\n            if (!WaveHeader.NumChannels) {          // make sure we saw \"fmt\" chunk\n                error_line (\"%s is not a valid .W64 file!\", infilename);\n                return WAVPACK_SOFT_ERROR;\n            }\n\n            if ((config->qmode & QMODE_IGNORE_LENGTH) || chunk_header.ckSize <= 0) {\n                config->qmode |= QMODE_IGNORE_LENGTH;\n\n                if (infilesize && DoGetFilePosition (infile) != -1)\n                    total_samples = (infilesize - DoGetFilePosition (infile)) / WaveHeader.BlockAlign;\n                else\n                    total_samples = -1;\n            }\n            else {\n                if (infilesize && infilesize - chunk_header.ckSize > 16777216) {\n                    error_line (\"this .W64 file has over 16 MB of extra RIFF data, probably is corrupt!\");\n                    return WAVPACK_SOFT_ERROR;\n                }\n\n                total_samples = chunk_header.ckSize / WaveHeader.BlockAlign;\n\n                if (!total_samples) {\n                    error_line (\"this .W64 file has no audio samples, probably is corrupt!\");\n                    return WAVPACK_SOFT_ERROR;\n                }\n\n                if (total_samples > MAX_WAVPACK_SAMPLES) {\n                    error_line (\"%s has too many samples for WavPack!\", infilename);\n                    return WAVPACK_SOFT_ERROR;\n                }\n            }\n\n            config->bytes_per_sample = WaveHeader.BlockAlign / WaveHeader.NumChannels;\n            config->num_channels = WaveHeader.NumChannels;\n            config->sample_rate = WaveHeader.SampleRate;\n            break;\n        }\n        else {          // just copy unknown chunks to output file\n            int bytes_to_copy = (chunk_header.ckSize + 7) & ~7L;\n            char *buff;\n\n            if (bytes_to_copy < 0 || bytes_to_copy > 4194304) {\n                error_line (\"%s is not a valid .W64 file!\", infilename);\n                return WAVPACK_SOFT_ERROR;\n            }\n\n            buff = malloc (bytes_to_copy);\n\n            if (debug_logging_mode)\n                error_line (\"extra unknown chunk \\\"%c%c%c%c\\\" of %d bytes\",\n                    chunk_header.ckID [0], chunk_header.ckID [1], chunk_header.ckID [2],\n                    chunk_header.ckID [3], chunk_header.ckSize);\n\n            if (!DoReadFile (infile, buff, bytes_to_copy, &bcount) ||\n                bcount != bytes_to_copy ||\n                (!(config->qmode & QMODE_NO_STORE_WRAPPER) &&\n                !WavpackAddWrapper (wpc, buff, bytes_to_copy))) {\n                    error_line (\"%s\", WavpackGetErrorMessage (wpc));\n                    free (buff);\n                    return WAVPACK_SOFT_ERROR;\n            }\n\n            free (buff);\n        }\n    }\n\n    if (!WavpackSetConfiguration64 (wpc, config, total_samples, NULL)) {\n        error_line (\"%s: %s\", infilename, WavpackGetErrorMessage (wpc));\n        return WAVPACK_SOFT_ERROR;\n    }\n\n    return WAVPACK_NO_ERROR;\n}",
        "func": "int ParseWave64HeaderConfig (FILE *infile, char *infilename, char *fourcc, WavpackContext *wpc, WavpackConfig *config)\n{\n    int64_t total_samples = 0, infilesize;\n    Wave64ChunkHeader chunk_header;\n    Wave64FileHeader filehdr;\n    WaveHeader WaveHeader;\n    int format_chunk = 0;\n    uint32_t bcount;\n\n    CLEAR (WaveHeader);\n    infilesize = DoGetFileSize (infile);\n    memcpy (&filehdr, fourcc, 4);\n\n    if (!DoReadFile (infile, ((char *) &filehdr) + 4, sizeof (Wave64FileHeader) - 4, &bcount) ||\n        bcount != sizeof (Wave64FileHeader) - 4 || memcmp (filehdr.ckID, riff_guid, sizeof (riff_guid)) ||\n        memcmp (filehdr.formType, wave_guid, sizeof (wave_guid))) {\n            error_line (\"%s is not a valid .W64 file!\", infilename);\n            return WAVPACK_SOFT_ERROR;\n    }\n    else if (!(config->qmode & QMODE_NO_STORE_WRAPPER) &&\n        !WavpackAddWrapper (wpc, &filehdr, sizeof (filehdr))) {\n            error_line (\"%s\", WavpackGetErrorMessage (wpc));\n            return WAVPACK_SOFT_ERROR;\n    }\n\n#if 1   // this might be a little too picky...\n    WavpackLittleEndianToNative (&filehdr, Wave64ChunkHeaderFormat);\n\n    if (infilesize && !(config->qmode & QMODE_IGNORE_LENGTH) &&\n        filehdr.ckSize && filehdr.ckSize + 1 && filehdr.ckSize != infilesize) {\n            error_line (\"%s is not a valid .W64 file!\", infilename);\n            return WAVPACK_SOFT_ERROR;\n    }\n#endif\n\n    // loop through all elements of the wave64 header\n    // (until the data chuck) and copy them to the output file\n\n    while (1) {\n        if (!DoReadFile (infile, &chunk_header, sizeof (Wave64ChunkHeader), &bcount) ||\n            bcount != sizeof (Wave64ChunkHeader)) {\n                error_line (\"%s is not a valid .W64 file!\", infilename);\n                return WAVPACK_SOFT_ERROR;\n        }\n        else if (!(config->qmode & QMODE_NO_STORE_WRAPPER) &&\n            !WavpackAddWrapper (wpc, &chunk_header, sizeof (Wave64ChunkHeader))) {\n                error_line (\"%s\", WavpackGetErrorMessage (wpc));\n                return WAVPACK_SOFT_ERROR;\n        }\n\n        WavpackLittleEndianToNative (&chunk_header, Wave64ChunkHeaderFormat);\n        chunk_header.ckSize -= sizeof (chunk_header);\n\n        // if it's the format chunk, we want to get some info out of there and\n        // make sure it's a .wav file we can handle\n\n        if (!memcmp (chunk_header.ckID, fmt_guid, sizeof (fmt_guid))) {\n            int supported = TRUE, format;\n\n            if (format_chunk++) {\n                error_line (\"%s is not a valid .W64 file!\", infilename);\n                return WAVPACK_SOFT_ERROR;\n            }\n\n            chunk_header.ckSize = (chunk_header.ckSize + 7) & ~7L;\n\n            if (chunk_header.ckSize < 16 || chunk_header.ckSize > sizeof (WaveHeader) ||\n                !DoReadFile (infile, &WaveHeader, (uint32_t) chunk_header.ckSize, &bcount) ||\n                bcount != chunk_header.ckSize) {\n                    error_line (\"%s is not a valid .W64 file!\", infilename);\n                    return WAVPACK_SOFT_ERROR;\n            }\n            else if (!(config->qmode & QMODE_NO_STORE_WRAPPER) &&\n                !WavpackAddWrapper (wpc, &WaveHeader, (uint32_t) chunk_header.ckSize)) {\n                    error_line (\"%s\", WavpackGetErrorMessage (wpc));\n                    return WAVPACK_SOFT_ERROR;\n            }\n\n            WavpackLittleEndianToNative (&WaveHeader, WaveHeaderFormat);\n\n            if (debug_logging_mode) {\n                error_line (\"format tag size = %d\", chunk_header.ckSize);\n                error_line (\"FormatTag = %x, NumChannels = %d, BitsPerSample = %d\",\n                    WaveHeader.FormatTag, WaveHeader.NumChannels, WaveHeader.BitsPerSample);\n                error_line (\"BlockAlign = %d, SampleRate = %d, BytesPerSecond = %d\",\n                    WaveHeader.BlockAlign, WaveHeader.SampleRate, WaveHeader.BytesPerSecond);\n\n                if (chunk_header.ckSize > 16)\n                    error_line (\"cbSize = %d, ValidBitsPerSample = %d\", WaveHeader.cbSize,\n                        WaveHeader.ValidBitsPerSample);\n\n                if (chunk_header.ckSize > 20)\n                    error_line (\"ChannelMask = %x, SubFormat = %d\",\n                        WaveHeader.ChannelMask, WaveHeader.SubFormat);\n            }\n\n            if (chunk_header.ckSize > 16 && WaveHeader.cbSize == 2)\n                config->qmode |= QMODE_ADOBE_MODE;\n\n            format = (WaveHeader.FormatTag == 0xfffe && chunk_header.ckSize == 40) ?\n                WaveHeader.SubFormat : WaveHeader.FormatTag;\n\n            config->bits_per_sample = (chunk_header.ckSize == 40 && WaveHeader.ValidBitsPerSample) ?\n                WaveHeader.ValidBitsPerSample : WaveHeader.BitsPerSample;\n\n            if (format != 1 && format != 3)\n                supported = FALSE;\n\n            if (format == 3 && config->bits_per_sample != 32)\n                supported = FALSE;\n\n            if (!WaveHeader.NumChannels || WaveHeader.NumChannels > 256 ||\n                WaveHeader.BlockAlign / WaveHeader.NumChannels < (config->bits_per_sample + 7) / 8 ||\n                WaveHeader.BlockAlign / WaveHeader.NumChannels > 4 ||\n                WaveHeader.BlockAlign % WaveHeader.NumChannels)\n                    supported = FALSE;\n\n            if (config->bits_per_sample < 1 || config->bits_per_sample > 32)\n                supported = FALSE;\n\n            if (!supported) {\n                error_line (\"%s is an unsupported .W64 format!\", infilename);\n                return WAVPACK_SOFT_ERROR;\n            }\n\n            if (chunk_header.ckSize < 40) {\n                if (!config->channel_mask && !(config->qmode & QMODE_CHANS_UNASSIGNED)) {\n                    if (WaveHeader.NumChannels <= 2)\n                        config->channel_mask = 0x5 - WaveHeader.NumChannels;\n                    else if (WaveHeader.NumChannels <= 18)\n                        config->channel_mask = (1 << WaveHeader.NumChannels) - 1;\n                    else\n                        config->channel_mask = 0x3ffff;\n                }\n            }\n            else if (WaveHeader.ChannelMask && (config->channel_mask || (config->qmode & QMODE_CHANS_UNASSIGNED))) {\n                error_line (\"this W64 file already has channel order information!\");\n                return WAVPACK_SOFT_ERROR;\n            }\n            else if (WaveHeader.ChannelMask)\n                config->channel_mask = WaveHeader.ChannelMask;\n\n            if (format == 3)\n                config->float_norm_exp = 127;\n            else if ((config->qmode & QMODE_ADOBE_MODE) &&\n                WaveHeader.BlockAlign / WaveHeader.NumChannels == 4) {\n                    if (WaveHeader.BitsPerSample == 24)\n                        config->float_norm_exp = 127 + 23;\n                    else if (WaveHeader.BitsPerSample == 32)\n                        config->float_norm_exp = 127 + 15;\n            }\n\n            if (debug_logging_mode) {\n                if (config->float_norm_exp == 127)\n                    error_line (\"data format: normalized 32-bit floating point\");\n                else\n                    error_line (\"data format: %d-bit integers stored in %d byte(s)\",\n                        config->bits_per_sample, WaveHeader.BlockAlign / WaveHeader.NumChannels);\n            }\n        }\n        else if (!memcmp (chunk_header.ckID, data_guid, sizeof (data_guid))) { // on the data chunk, get size and exit loop\n\n            if (!WaveHeader.NumChannels) {          // make sure we saw \"fmt\" chunk\n                error_line (\"%s is not a valid .W64 file!\", infilename);\n                return WAVPACK_SOFT_ERROR;\n            }\n\n            if ((config->qmode & QMODE_IGNORE_LENGTH) || chunk_header.ckSize <= 0) {\n                config->qmode |= QMODE_IGNORE_LENGTH;\n\n                if (infilesize && DoGetFilePosition (infile) != -1)\n                    total_samples = (infilesize - DoGetFilePosition (infile)) / WaveHeader.BlockAlign;\n                else\n                    total_samples = -1;\n            }\n            else {\n                if (infilesize && infilesize - chunk_header.ckSize > 16777216) {\n                    error_line (\"this .W64 file has over 16 MB of extra RIFF data, probably is corrupt!\");\n                    return WAVPACK_SOFT_ERROR;\n                }\n\n                total_samples = chunk_header.ckSize / WaveHeader.BlockAlign;\n\n                if (!total_samples) {\n                    error_line (\"this .W64 file has no audio samples, probably is corrupt!\");\n                    return WAVPACK_SOFT_ERROR;\n                }\n\n                if (total_samples > MAX_WAVPACK_SAMPLES) {\n                    error_line (\"%s has too many samples for WavPack!\", infilename);\n                    return WAVPACK_SOFT_ERROR;\n                }\n            }\n\n            config->bytes_per_sample = WaveHeader.BlockAlign / WaveHeader.NumChannels;\n            config->num_channels = WaveHeader.NumChannels;\n            config->sample_rate = WaveHeader.SampleRate;\n            break;\n        }\n        else {          // just copy unknown chunks to output file\n            int bytes_to_copy = (chunk_header.ckSize + 7) & ~7L;\n            char *buff;\n\n            if (bytes_to_copy < 0 || bytes_to_copy > 4194304) {\n                error_line (\"%s is not a valid .W64 file!\", infilename);\n                return WAVPACK_SOFT_ERROR;\n            }\n\n            buff = malloc (bytes_to_copy);\n\n            if (debug_logging_mode)\n                error_line (\"extra unknown chunk \\\"%c%c%c%c\\\" of %d bytes\",\n                    chunk_header.ckID [0], chunk_header.ckID [1], chunk_header.ckID [2],\n                    chunk_header.ckID [3], chunk_header.ckSize);\n\n            if (!DoReadFile (infile, buff, bytes_to_copy, &bcount) ||\n                bcount != bytes_to_copy ||\n                (!(config->qmode & QMODE_NO_STORE_WRAPPER) &&\n                !WavpackAddWrapper (wpc, buff, bytes_to_copy))) {\n                    error_line (\"%s\", WavpackGetErrorMessage (wpc));\n                    free (buff);\n                    return WAVPACK_SOFT_ERROR;\n            }\n\n            free (buff);\n        }\n    }\n\n    if (!WavpackSetConfiguration64 (wpc, config, total_samples, NULL)) {\n        error_line (\"%s: %s\", infilename, WavpackGetErrorMessage (wpc));\n        return WAVPACK_SOFT_ERROR;\n    }\n\n    return WAVPACK_NO_ERROR;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -7,6 +7,7 @@\n     int format_chunk = 0;\n     uint32_t bcount;\n \n+    CLEAR (WaveHeader);\n     infilesize = DoGetFileSize (infile);\n     memcpy (&filehdr, fourcc, 4);\n ",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    CLEAR (WaveHeader);"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-13217",
        "func_name": "nothings/stb/start_decoder",
        "description": "A heap buffer overflow in the start_decoder function in stb_vorbis through 2019-03-04 allows an attacker to cause a denial of service or execute arbitrary code by opening a crafted Ogg Vorbis file.",
        "git_url": "https://github.com/nothings/stb/commit/98fdfc6df88b1e34a736d5e126e6c8139c8de1a6",
        "commit_title": "Fix seven bugs discovered and fixed by ForAllSecure:",
        "commit_text": " CVE-2019-13217: heap buffer overflow in start_decoder() CVE-2019-13218: stack buffer overflow in compute_codewords() CVE-2019-13219: uninitialized memory in vorbis_decode_packet_rest() CVE-2019-13220: out-of-range read in draw_line() CVE-2019-13221: issue with large 1D codebooks in lookup1_values() CVE-2019-13222: unchecked NULL returned by get_window() CVE-2019-13223: division by zero in predict_point()",
        "func_before": "static int start_decoder(vorb *f)\n{\n   uint8 header[6], x,y;\n   int len,i,j,k, max_submaps = 0;\n   int longest_floorlist=0;\n\n   // first page, first packet\n\n   if (!start_page(f))                              return FALSE;\n   // validate page flag\n   if (!(f->page_flag & PAGEFLAG_first_page))       return error(f, VORBIS_invalid_first_page);\n   if (f->page_flag & PAGEFLAG_last_page)           return error(f, VORBIS_invalid_first_page);\n   if (f->page_flag & PAGEFLAG_continued_packet)    return error(f, VORBIS_invalid_first_page);\n   // check for expected packet length\n   if (f->segment_count != 1)                       return error(f, VORBIS_invalid_first_page);\n   if (f->segments[0] != 30) {\n      // check for the Ogg skeleton fishead identifying header to refine our error\n      if (f->segments[0] == 64 &&\n          getn(f, header, 6) &&\n          header[0] == 'f' &&\n          header[1] == 'i' &&\n          header[2] == 's' &&\n          header[3] == 'h' &&\n          header[4] == 'e' &&\n          header[5] == 'a' &&\n          get8(f)   == 'd' &&\n          get8(f)   == '\\0')                        return error(f, VORBIS_ogg_skeleton_not_supported);\n      else\n                                                    return error(f, VORBIS_invalid_first_page);\n   }\n\n   // read packet\n   // check packet header\n   if (get8(f) != VORBIS_packet_id)                 return error(f, VORBIS_invalid_first_page);\n   if (!getn(f, header, 6))                         return error(f, VORBIS_unexpected_eof);\n   if (!vorbis_validate(header))                    return error(f, VORBIS_invalid_first_page);\n   // vorbis_version\n   if (get32(f) != 0)                               return error(f, VORBIS_invalid_first_page);\n   f->channels = get8(f); if (!f->channels)         return error(f, VORBIS_invalid_first_page);\n   if (f->channels > STB_VORBIS_MAX_CHANNELS)       return error(f, VORBIS_too_many_channels);\n   f->sample_rate = get32(f); if (!f->sample_rate)  return error(f, VORBIS_invalid_first_page);\n   get32(f); // bitrate_maximum\n   get32(f); // bitrate_nominal\n   get32(f); // bitrate_minimum\n   x = get8(f);\n   {\n      int log0,log1;\n      log0 = x & 15;\n      log1 = x >> 4;\n      f->blocksize_0 = 1 << log0;\n      f->blocksize_1 = 1 << log1;\n      if (log0 < 6 || log0 > 13)                       return error(f, VORBIS_invalid_setup);\n      if (log1 < 6 || log1 > 13)                       return error(f, VORBIS_invalid_setup);\n      if (log0 > log1)                                 return error(f, VORBIS_invalid_setup);\n   }\n\n   // framing_flag\n   x = get8(f);\n   if (!(x & 1))                                    return error(f, VORBIS_invalid_first_page);\n\n   // second packet!\n   if (!start_page(f))                              return FALSE;\n\n   if (!start_packet(f))                            return FALSE;\n   do {\n      len = next_segment(f);\n      skip(f, len);\n      f->bytes_in_seg = 0;\n   } while (len);\n\n   // third packet!\n   if (!start_packet(f))                            return FALSE;\n\n   #ifndef STB_VORBIS_NO_PUSHDATA_API\n   if (IS_PUSH_MODE(f)) {\n      if (!is_whole_packet_present(f, TRUE)) {\n         // convert error in ogg header to write type\n         if (f->error == VORBIS_invalid_stream)\n            f->error = VORBIS_invalid_setup;\n         return FALSE;\n      }\n   }\n   #endif\n\n   crc32_init(); // always init it, to avoid multithread race conditions\n\n   if (get8_packet(f) != VORBIS_packet_setup)       return error(f, VORBIS_invalid_setup);\n   for (i=0; i < 6; ++i) header[i] = get8_packet(f);\n   if (!vorbis_validate(header))                    return error(f, VORBIS_invalid_setup);\n\n   // codebooks\n\n   f->codebook_count = get_bits(f,8) + 1;\n   f->codebooks = (Codebook *) setup_malloc(f, sizeof(*f->codebooks) * f->codebook_count);\n   if (f->codebooks == NULL)                        return error(f, VORBIS_outofmem);\n   memset(f->codebooks, 0, sizeof(*f->codebooks) * f->codebook_count);\n   for (i=0; i < f->codebook_count; ++i) {\n      uint32 *values;\n      int ordered, sorted_count;\n      int total=0;\n      uint8 *lengths;\n      Codebook *c = f->codebooks+i;\n      CHECK(f);\n      x = get_bits(f, 8); if (x != 0x42)            return error(f, VORBIS_invalid_setup);\n      x = get_bits(f, 8); if (x != 0x43)            return error(f, VORBIS_invalid_setup);\n      x = get_bits(f, 8); if (x != 0x56)            return error(f, VORBIS_invalid_setup);\n      x = get_bits(f, 8);\n      c->dimensions = (get_bits(f, 8)<<8) + x;\n      x = get_bits(f, 8);\n      y = get_bits(f, 8);\n      c->entries = (get_bits(f, 8)<<16) + (y<<8) + x;\n      ordered = get_bits(f,1);\n      c->sparse = ordered ? 0 : get_bits(f,1);\n\n      if (c->dimensions == 0 && c->entries != 0)    return error(f, VORBIS_invalid_setup);\n\n      if (c->sparse)\n         lengths = (uint8 *) setup_temp_malloc(f, c->entries);\n      else\n         lengths = c->codeword_lengths = (uint8 *) setup_malloc(f, c->entries);\n\n      if (!lengths) return error(f, VORBIS_outofmem);\n\n      if (ordered) {\n         int current_entry = 0;\n         int current_length = get_bits(f,5) + 1;\n         while (current_entry < c->entries) {\n            int limit = c->entries - current_entry;\n            int n = get_bits(f, ilog(limit));\n            if (current_entry + n > (int) c->entries) { return error(f, VORBIS_invalid_setup); }\n            memset(lengths + current_entry, current_length, n);\n            current_entry += n;\n            ++current_length;\n         }\n      } else {\n         for (j=0; j < c->entries; ++j) {\n            int present = c->sparse ? get_bits(f,1) : 1;\n            if (present) {\n               lengths[j] = get_bits(f, 5) + 1;\n               ++total;\n               if (lengths[j] == 32)\n                  return error(f, VORBIS_invalid_setup);\n            } else {\n               lengths[j] = NO_CODE;\n            }\n         }\n      }\n\n      if (c->sparse && total >= c->entries >> 2) {\n         // convert sparse items to non-sparse!\n         if (c->entries > (int) f->setup_temp_memory_required)\n            f->setup_temp_memory_required = c->entries;\n\n         c->codeword_lengths = (uint8 *) setup_malloc(f, c->entries);\n         if (c->codeword_lengths == NULL) return error(f, VORBIS_outofmem);\n         memcpy(c->codeword_lengths, lengths, c->entries);\n         setup_temp_free(f, lengths, c->entries); // note this is only safe if there have been no intervening temp mallocs!\n         lengths = c->codeword_lengths;\n         c->sparse = 0;\n      }\n\n      // compute the size of the sorted tables\n      if (c->sparse) {\n         sorted_count = total;\n      } else {\n         sorted_count = 0;\n         #ifndef STB_VORBIS_NO_HUFFMAN_BINARY_SEARCH\n         for (j=0; j < c->entries; ++j)\n            if (lengths[j] > STB_VORBIS_FAST_HUFFMAN_LENGTH && lengths[j] != NO_CODE)\n               ++sorted_count;\n         #endif\n      }\n\n      c->sorted_entries = sorted_count;\n      values = NULL;\n\n      CHECK(f);\n      if (!c->sparse) {\n         c->codewords = (uint32 *) setup_malloc(f, sizeof(c->codewords[0]) * c->entries);\n         if (!c->codewords)                  return error(f, VORBIS_outofmem);\n      } else {\n         unsigned int size;\n         if (c->sorted_entries) {\n            c->codeword_lengths = (uint8 *) setup_malloc(f, c->sorted_entries);\n            if (!c->codeword_lengths)           return error(f, VORBIS_outofmem);\n            c->codewords = (uint32 *) setup_temp_malloc(f, sizeof(*c->codewords) * c->sorted_entries);\n            if (!c->codewords)                  return error(f, VORBIS_outofmem);\n            values = (uint32 *) setup_temp_malloc(f, sizeof(*values) * c->sorted_entries);\n            if (!values)                        return error(f, VORBIS_outofmem);\n         }\n         size = c->entries + (sizeof(*c->codewords) + sizeof(*values)) * c->sorted_entries;\n         if (size > f->setup_temp_memory_required)\n            f->setup_temp_memory_required = size;\n      }\n\n      if (!compute_codewords(c, lengths, c->entries, values)) {\n         if (c->sparse) setup_temp_free(f, values, 0);\n         return error(f, VORBIS_invalid_setup);\n      }\n\n      if (c->sorted_entries) {\n         // allocate an extra slot for sentinels\n         c->sorted_codewords = (uint32 *) setup_malloc(f, sizeof(*c->sorted_codewords) * (c->sorted_entries+1));\n         if (c->sorted_codewords == NULL) return error(f, VORBIS_outofmem);\n         // allocate an extra slot at the front so that c->sorted_values[-1] is defined\n         // so that we can catch that case without an extra if\n         c->sorted_values    = ( int   *) setup_malloc(f, sizeof(*c->sorted_values   ) * (c->sorted_entries+1));\n         if (c->sorted_values == NULL) return error(f, VORBIS_outofmem);\n         ++c->sorted_values;\n         c->sorted_values[-1] = -1;\n         compute_sorted_huffman(c, lengths, values);\n      }\n\n      if (c->sparse) {\n         setup_temp_free(f, values, sizeof(*values)*c->sorted_entries);\n         setup_temp_free(f, c->codewords, sizeof(*c->codewords)*c->sorted_entries);\n         setup_temp_free(f, lengths, c->entries);\n         c->codewords = NULL;\n      }\n\n      compute_accelerated_huffman(c);\n\n      CHECK(f);\n      c->lookup_type = get_bits(f, 4);\n      if (c->lookup_type > 2) return error(f, VORBIS_invalid_setup);\n      if (c->lookup_type > 0) {\n         uint16 *mults;\n         c->minimum_value = float32_unpack(get_bits(f, 32));\n         c->delta_value = float32_unpack(get_bits(f, 32));\n         c->value_bits = get_bits(f, 4)+1;\n         c->sequence_p = get_bits(f,1);\n         if (c->lookup_type == 1) {\n            c->lookup_values = lookup1_values(c->entries, c->dimensions);\n         } else {\n            c->lookup_values = c->entries * c->dimensions;\n         }\n         if (c->lookup_values == 0) return error(f, VORBIS_invalid_setup);\n         mults = (uint16 *) setup_temp_malloc(f, sizeof(mults[0]) * c->lookup_values);\n         if (mults == NULL) return error(f, VORBIS_outofmem);\n         for (j=0; j < (int) c->lookup_values; ++j) {\n            int q = get_bits(f, c->value_bits);\n            if (q == EOP) { setup_temp_free(f,mults,sizeof(mults[0])*c->lookup_values); return error(f, VORBIS_invalid_setup); }\n            mults[j] = q;\n         }\n\n#ifndef STB_VORBIS_DIVIDES_IN_CODEBOOK\n         if (c->lookup_type == 1) {\n            int len, sparse = c->sparse;\n            float last=0;\n            // pre-expand the lookup1-style multiplicands, to avoid a divide in the inner loop\n            if (sparse) {\n               if (c->sorted_entries == 0) goto skip;\n               c->multiplicands = (codetype *) setup_malloc(f, sizeof(c->multiplicands[0]) * c->sorted_entries * c->dimensions);\n            } else\n               c->multiplicands = (codetype *) setup_malloc(f, sizeof(c->multiplicands[0]) * c->entries        * c->dimensions);\n            if (c->multiplicands == NULL) { setup_temp_free(f,mults,sizeof(mults[0])*c->lookup_values); return error(f, VORBIS_outofmem); }\n            len = sparse ? c->sorted_entries : c->entries;\n            for (j=0; j < len; ++j) {\n               unsigned int z = sparse ? c->sorted_values[j] : j;\n               unsigned int div=1;\n               for (k=0; k < c->dimensions; ++k) {\n                  int off = (z / div) % c->lookup_values;\n                  float val = mults[off];\n                  val = mults[off]*c->delta_value + c->minimum_value + last;\n                  c->multiplicands[j*c->dimensions + k] = val;\n                  if (c->sequence_p)\n                     last = val;\n                  if (k+1 < c->dimensions) {\n                     if (div > UINT_MAX / (unsigned int) c->lookup_values) {\n                        setup_temp_free(f, mults,sizeof(mults[0])*c->lookup_values);\n                        return error(f, VORBIS_invalid_setup);\n                     }\n                     div *= c->lookup_values;\n                  }\n               }\n            }\n            c->lookup_type = 2;\n         }\n         else\n#endif\n         {\n            float last=0;\n            CHECK(f);\n            c->multiplicands = (codetype *) setup_malloc(f, sizeof(c->multiplicands[0]) * c->lookup_values);\n            if (c->multiplicands == NULL) { setup_temp_free(f, mults,sizeof(mults[0])*c->lookup_values); return error(f, VORBIS_outofmem); }\n            for (j=0; j < (int) c->lookup_values; ++j) {\n               float val = mults[j] * c->delta_value + c->minimum_value + last;\n               c->multiplicands[j] = val;\n               if (c->sequence_p)\n                  last = val;\n            }\n         }\n#ifndef STB_VORBIS_DIVIDES_IN_CODEBOOK\n        skip:;\n#endif\n         setup_temp_free(f, mults, sizeof(mults[0])*c->lookup_values);\n\n         CHECK(f);\n      }\n      CHECK(f);\n   }\n\n   // time domain transfers (notused)\n\n   x = get_bits(f, 6) + 1;\n   for (i=0; i < x; ++i) {\n      uint32 z = get_bits(f, 16);\n      if (z != 0) return error(f, VORBIS_invalid_setup);\n   }\n\n   // Floors\n   f->floor_count = get_bits(f, 6)+1;\n   f->floor_config = (Floor *)  setup_malloc(f, f->floor_count * sizeof(*f->floor_config));\n   if (f->floor_config == NULL) return error(f, VORBIS_outofmem);\n   for (i=0; i < f->floor_count; ++i) {\n      f->floor_types[i] = get_bits(f, 16);\n      if (f->floor_types[i] > 1) return error(f, VORBIS_invalid_setup);\n      if (f->floor_types[i] == 0) {\n         Floor0 *g = &f->floor_config[i].floor0;\n         g->order = get_bits(f,8);\n         g->rate = get_bits(f,16);\n         g->bark_map_size = get_bits(f,16);\n         g->amplitude_bits = get_bits(f,6);\n         g->amplitude_offset = get_bits(f,8);\n         g->number_of_books = get_bits(f,4) + 1;\n         for (j=0; j < g->number_of_books; ++j)\n            g->book_list[j] = get_bits(f,8);\n         return error(f, VORBIS_feature_not_supported);\n      } else {\n         stbv__floor_ordering p[31*8+2];\n         Floor1 *g = &f->floor_config[i].floor1;\n         int max_class = -1; \n         g->partitions = get_bits(f, 5);\n         for (j=0; j < g->partitions; ++j) {\n            g->partition_class_list[j] = get_bits(f, 4);\n            if (g->partition_class_list[j] > max_class)\n               max_class = g->partition_class_list[j];\n         }\n         for (j=0; j <= max_class; ++j) {\n            g->class_dimensions[j] = get_bits(f, 3)+1;\n            g->class_subclasses[j] = get_bits(f, 2);\n            if (g->class_subclasses[j]) {\n               g->class_masterbooks[j] = get_bits(f, 8);\n               if (g->class_masterbooks[j] >= f->codebook_count) return error(f, VORBIS_invalid_setup);\n            }\n            for (k=0; k < 1 << g->class_subclasses[j]; ++k) {\n               g->subclass_books[j][k] = get_bits(f,8)-1;\n               if (g->subclass_books[j][k] >= f->codebook_count) return error(f, VORBIS_invalid_setup);\n            }\n         }\n         g->floor1_multiplier = get_bits(f,2)+1;\n         g->rangebits = get_bits(f,4);\n         g->Xlist[0] = 0;\n         g->Xlist[1] = 1 << g->rangebits;\n         g->values = 2;\n         for (j=0; j < g->partitions; ++j) {\n            int c = g->partition_class_list[j];\n            for (k=0; k < g->class_dimensions[c]; ++k) {\n               g->Xlist[g->values] = get_bits(f, g->rangebits);\n               ++g->values;\n            }\n         }\n         // precompute the sorting\n         for (j=0; j < g->values; ++j) {\n            p[j].x = g->Xlist[j];\n            p[j].id = j;\n         }\n         qsort(p, g->values, sizeof(p[0]), point_compare);\n         for (j=0; j < g->values; ++j)\n            g->sorted_order[j] = (uint8) p[j].id;\n         // precompute the neighbors\n         for (j=2; j < g->values; ++j) {\n            int low,hi;\n            neighbors(g->Xlist, j, &low,&hi);\n            g->neighbors[j][0] = low;\n            g->neighbors[j][1] = hi;\n         }\n\n         if (g->values > longest_floorlist)\n            longest_floorlist = g->values;\n      }\n   }\n\n   // Residue\n   f->residue_count = get_bits(f, 6)+1;\n   f->residue_config = (Residue *) setup_malloc(f, f->residue_count * sizeof(f->residue_config[0]));\n   if (f->residue_config == NULL) return error(f, VORBIS_outofmem);\n   memset(f->residue_config, 0, f->residue_count * sizeof(f->residue_config[0]));\n   for (i=0; i < f->residue_count; ++i) {\n      uint8 residue_cascade[64];\n      Residue *r = f->residue_config+i;\n      f->residue_types[i] = get_bits(f, 16);\n      if (f->residue_types[i] > 2) return error(f, VORBIS_invalid_setup);\n      r->begin = get_bits(f, 24);\n      r->end = get_bits(f, 24);\n      if (r->end < r->begin) return error(f, VORBIS_invalid_setup);\n      r->part_size = get_bits(f,24)+1;\n      r->classifications = get_bits(f,6)+1;\n      r->classbook = get_bits(f,8);\n      if (r->classbook >= f->codebook_count) return error(f, VORBIS_invalid_setup);\n      for (j=0; j < r->classifications; ++j) {\n         uint8 high_bits=0;\n         uint8 low_bits=get_bits(f,3);\n         if (get_bits(f,1))\n            high_bits = get_bits(f,5);\n         residue_cascade[j] = high_bits*8 + low_bits;\n      }\n      r->residue_books = (short (*)[8]) setup_malloc(f, sizeof(r->residue_books[0]) * r->classifications);\n      if (r->residue_books == NULL) return error(f, VORBIS_outofmem);\n      for (j=0; j < r->classifications; ++j) {\n         for (k=0; k < 8; ++k) {\n            if (residue_cascade[j] & (1 << k)) {\n               r->residue_books[j][k] = get_bits(f, 8);\n               if (r->residue_books[j][k] >= f->codebook_count) return error(f, VORBIS_invalid_setup);\n            } else {\n               r->residue_books[j][k] = -1;\n            }\n         }\n      }\n      // precompute the classifications[] array to avoid inner-loop mod/divide\n      // call it 'classdata' since we already have r->classifications\n      r->classdata = (uint8 **) setup_malloc(f, sizeof(*r->classdata) * f->codebooks[r->classbook].entries);\n      if (!r->classdata) return error(f, VORBIS_outofmem);\n      memset(r->classdata, 0, sizeof(*r->classdata) * f->codebooks[r->classbook].entries);\n      for (j=0; j < f->codebooks[r->classbook].entries; ++j) {\n         int classwords = f->codebooks[r->classbook].dimensions;\n         int temp = j;\n         r->classdata[j] = (uint8 *) setup_malloc(f, sizeof(r->classdata[j][0]) * classwords);\n         if (r->classdata[j] == NULL) return error(f, VORBIS_outofmem);\n         for (k=classwords-1; k >= 0; --k) {\n            r->classdata[j][k] = temp % r->classifications;\n            temp /= r->classifications;\n         }\n      }\n   }\n\n   f->mapping_count = get_bits(f,6)+1;\n   f->mapping = (Mapping *) setup_malloc(f, f->mapping_count * sizeof(*f->mapping));\n   if (f->mapping == NULL) return error(f, VORBIS_outofmem);\n   memset(f->mapping, 0, f->mapping_count * sizeof(*f->mapping));\n   for (i=0; i < f->mapping_count; ++i) {\n      Mapping *m = f->mapping + i;      \n      int mapping_type = get_bits(f,16);\n      if (mapping_type != 0) return error(f, VORBIS_invalid_setup);\n      m->chan = (MappingChannel *) setup_malloc(f, f->channels * sizeof(*m->chan));\n      if (m->chan == NULL) return error(f, VORBIS_outofmem);\n      if (get_bits(f,1))\n         m->submaps = get_bits(f,4)+1;\n      else\n         m->submaps = 1;\n      if (m->submaps > max_submaps)\n         max_submaps = m->submaps;\n      if (get_bits(f,1)) {\n         m->coupling_steps = get_bits(f,8)+1;\n         for (k=0; k < m->coupling_steps; ++k) {\n            m->chan[k].magnitude = get_bits(f, ilog(f->channels-1));\n            m->chan[k].angle = get_bits(f, ilog(f->channels-1));\n            if (m->chan[k].magnitude >= f->channels)        return error(f, VORBIS_invalid_setup);\n            if (m->chan[k].angle     >= f->channels)        return error(f, VORBIS_invalid_setup);\n            if (m->chan[k].magnitude == m->chan[k].angle)   return error(f, VORBIS_invalid_setup);\n         }\n      } else\n         m->coupling_steps = 0;\n\n      // reserved field\n      if (get_bits(f,2)) return error(f, VORBIS_invalid_setup);\n      if (m->submaps > 1) {\n         for (j=0; j < f->channels; ++j) {\n            m->chan[j].mux = get_bits(f, 4);\n            if (m->chan[j].mux >= m->submaps)                return error(f, VORBIS_invalid_setup);\n         }\n      } else\n         // @SPECIFICATION: this case is missing from the spec\n         for (j=0; j < f->channels; ++j)\n            m->chan[j].mux = 0;\n\n      for (j=0; j < m->submaps; ++j) {\n         get_bits(f,8); // discard\n         m->submap_floor[j] = get_bits(f,8);\n         m->submap_residue[j] = get_bits(f,8);\n         if (m->submap_floor[j] >= f->floor_count)      return error(f, VORBIS_invalid_setup);\n         if (m->submap_residue[j] >= f->residue_count)  return error(f, VORBIS_invalid_setup);\n      }\n   }\n\n   // Modes\n   f->mode_count = get_bits(f, 6)+1;\n   for (i=0; i < f->mode_count; ++i) {\n      Mode *m = f->mode_config+i;\n      m->blockflag = get_bits(f,1);\n      m->windowtype = get_bits(f,16);\n      m->transformtype = get_bits(f,16);\n      m->mapping = get_bits(f,8);\n      if (m->windowtype != 0)                 return error(f, VORBIS_invalid_setup);\n      if (m->transformtype != 0)              return error(f, VORBIS_invalid_setup);\n      if (m->mapping >= f->mapping_count)     return error(f, VORBIS_invalid_setup);\n   }\n\n   flush_packet(f);\n\n   f->previous_length = 0;\n\n   for (i=0; i < f->channels; ++i) {\n      f->channel_buffers[i] = (float *) setup_malloc(f, sizeof(float) * f->blocksize_1);\n      f->previous_window[i] = (float *) setup_malloc(f, sizeof(float) * f->blocksize_1/2);\n      f->finalY[i]          = (int16 *) setup_malloc(f, sizeof(int16) * longest_floorlist);\n      if (f->channel_buffers[i] == NULL || f->previous_window[i] == NULL || f->finalY[i] == NULL) return error(f, VORBIS_outofmem);\n      memset(f->channel_buffers[i], 0, sizeof(float) * f->blocksize_1);\n      #ifdef STB_VORBIS_NO_DEFER_FLOOR\n      f->floor_buffers[i]   = (float *) setup_malloc(f, sizeof(float) * f->blocksize_1/2);\n      if (f->floor_buffers[i] == NULL) return error(f, VORBIS_outofmem);\n      #endif\n   }\n\n   if (!init_blocksize(f, 0, f->blocksize_0)) return FALSE;\n   if (!init_blocksize(f, 1, f->blocksize_1)) return FALSE;\n   f->blocksize[0] = f->blocksize_0;\n   f->blocksize[1] = f->blocksize_1;\n\n#ifdef STB_VORBIS_DIVIDE_TABLE\n   if (integer_divide_table[1][1]==0)\n      for (i=0; i < DIVTAB_NUMER; ++i)\n         for (j=1; j < DIVTAB_DENOM; ++j)\n            integer_divide_table[i][j] = i / j;\n#endif\n\n   // compute how much temporary memory is needed\n\n   // 1.\n   {\n      uint32 imdct_mem = (f->blocksize_1 * sizeof(float) >> 1);\n      uint32 classify_mem;\n      int i,max_part_read=0;\n      for (i=0; i < f->residue_count; ++i) {\n         Residue *r = f->residue_config + i;\n         unsigned int actual_size = f->blocksize_1 / 2;\n         unsigned int limit_r_begin = r->begin < actual_size ? r->begin : actual_size;\n         unsigned int limit_r_end   = r->end   < actual_size ? r->end   : actual_size;\n         int n_read = limit_r_end - limit_r_begin;\n         int part_read = n_read / r->part_size;\n         if (part_read > max_part_read)\n            max_part_read = part_read;\n      }\n      #ifndef STB_VORBIS_DIVIDES_IN_RESIDUE\n      classify_mem = f->channels * (sizeof(void*) + max_part_read * sizeof(uint8 *));\n      #else\n      classify_mem = f->channels * (sizeof(void*) + max_part_read * sizeof(int *));\n      #endif\n\n      // maximum reasonable partition size is f->blocksize_1\n\n      f->temp_memory_required = classify_mem;\n      if (imdct_mem > f->temp_memory_required)\n         f->temp_memory_required = imdct_mem;\n   }\n\n   f->first_decode = TRUE;\n\n   if (f->alloc.alloc_buffer) {\n      assert(f->temp_offset == f->alloc.alloc_buffer_length_in_bytes);\n      // check if there's enough temp memory so we don't error later\n      if (f->setup_offset + sizeof(*f) + f->temp_memory_required > (unsigned) f->temp_offset)\n         return error(f, VORBIS_outofmem);\n   }\n\n   f->first_audio_page_offset = stb_vorbis_get_file_offset(f);\n\n   return TRUE;\n}",
        "func": "static int start_decoder(vorb *f)\n{\n   uint8 header[6], x,y;\n   int len,i,j,k, max_submaps = 0;\n   int longest_floorlist=0;\n\n   // first page, first packet\n\n   if (!start_page(f))                              return FALSE;\n   // validate page flag\n   if (!(f->page_flag & PAGEFLAG_first_page))       return error(f, VORBIS_invalid_first_page);\n   if (f->page_flag & PAGEFLAG_last_page)           return error(f, VORBIS_invalid_first_page);\n   if (f->page_flag & PAGEFLAG_continued_packet)    return error(f, VORBIS_invalid_first_page);\n   // check for expected packet length\n   if (f->segment_count != 1)                       return error(f, VORBIS_invalid_first_page);\n   if (f->segments[0] != 30) {\n      // check for the Ogg skeleton fishead identifying header to refine our error\n      if (f->segments[0] == 64 &&\n          getn(f, header, 6) &&\n          header[0] == 'f' &&\n          header[1] == 'i' &&\n          header[2] == 's' &&\n          header[3] == 'h' &&\n          header[4] == 'e' &&\n          header[5] == 'a' &&\n          get8(f)   == 'd' &&\n          get8(f)   == '\\0')                        return error(f, VORBIS_ogg_skeleton_not_supported);\n      else\n                                                    return error(f, VORBIS_invalid_first_page);\n   }\n\n   // read packet\n   // check packet header\n   if (get8(f) != VORBIS_packet_id)                 return error(f, VORBIS_invalid_first_page);\n   if (!getn(f, header, 6))                         return error(f, VORBIS_unexpected_eof);\n   if (!vorbis_validate(header))                    return error(f, VORBIS_invalid_first_page);\n   // vorbis_version\n   if (get32(f) != 0)                               return error(f, VORBIS_invalid_first_page);\n   f->channels = get8(f); if (!f->channels)         return error(f, VORBIS_invalid_first_page);\n   if (f->channels > STB_VORBIS_MAX_CHANNELS)       return error(f, VORBIS_too_many_channels);\n   f->sample_rate = get32(f); if (!f->sample_rate)  return error(f, VORBIS_invalid_first_page);\n   get32(f); // bitrate_maximum\n   get32(f); // bitrate_nominal\n   get32(f); // bitrate_minimum\n   x = get8(f);\n   {\n      int log0,log1;\n      log0 = x & 15;\n      log1 = x >> 4;\n      f->blocksize_0 = 1 << log0;\n      f->blocksize_1 = 1 << log1;\n      if (log0 < 6 || log0 > 13)                       return error(f, VORBIS_invalid_setup);\n      if (log1 < 6 || log1 > 13)                       return error(f, VORBIS_invalid_setup);\n      if (log0 > log1)                                 return error(f, VORBIS_invalid_setup);\n   }\n\n   // framing_flag\n   x = get8(f);\n   if (!(x & 1))                                    return error(f, VORBIS_invalid_first_page);\n\n   // second packet!\n   if (!start_page(f))                              return FALSE;\n\n   if (!start_packet(f))                            return FALSE;\n   do {\n      len = next_segment(f);\n      skip(f, len);\n      f->bytes_in_seg = 0;\n   } while (len);\n\n   // third packet!\n   if (!start_packet(f))                            return FALSE;\n\n   #ifndef STB_VORBIS_NO_PUSHDATA_API\n   if (IS_PUSH_MODE(f)) {\n      if (!is_whole_packet_present(f, TRUE)) {\n         // convert error in ogg header to write type\n         if (f->error == VORBIS_invalid_stream)\n            f->error = VORBIS_invalid_setup;\n         return FALSE;\n      }\n   }\n   #endif\n\n   crc32_init(); // always init it, to avoid multithread race conditions\n\n   if (get8_packet(f) != VORBIS_packet_setup)       return error(f, VORBIS_invalid_setup);\n   for (i=0; i < 6; ++i) header[i] = get8_packet(f);\n   if (!vorbis_validate(header))                    return error(f, VORBIS_invalid_setup);\n\n   // codebooks\n\n   f->codebook_count = get_bits(f,8) + 1;\n   f->codebooks = (Codebook *) setup_malloc(f, sizeof(*f->codebooks) * f->codebook_count);\n   if (f->codebooks == NULL)                        return error(f, VORBIS_outofmem);\n   memset(f->codebooks, 0, sizeof(*f->codebooks) * f->codebook_count);\n   for (i=0; i < f->codebook_count; ++i) {\n      uint32 *values;\n      int ordered, sorted_count;\n      int total=0;\n      uint8 *lengths;\n      Codebook *c = f->codebooks+i;\n      CHECK(f);\n      x = get_bits(f, 8); if (x != 0x42)            return error(f, VORBIS_invalid_setup);\n      x = get_bits(f, 8); if (x != 0x43)            return error(f, VORBIS_invalid_setup);\n      x = get_bits(f, 8); if (x != 0x56)            return error(f, VORBIS_invalid_setup);\n      x = get_bits(f, 8);\n      c->dimensions = (get_bits(f, 8)<<8) + x;\n      x = get_bits(f, 8);\n      y = get_bits(f, 8);\n      c->entries = (get_bits(f, 8)<<16) + (y<<8) + x;\n      ordered = get_bits(f,1);\n      c->sparse = ordered ? 0 : get_bits(f,1);\n\n      if (c->dimensions == 0 && c->entries != 0)    return error(f, VORBIS_invalid_setup);\n\n      if (c->sparse)\n         lengths = (uint8 *) setup_temp_malloc(f, c->entries);\n      else\n         lengths = c->codeword_lengths = (uint8 *) setup_malloc(f, c->entries);\n\n      if (!lengths) return error(f, VORBIS_outofmem);\n\n      if (ordered) {\n         int current_entry = 0;\n         int current_length = get_bits(f,5) + 1;\n         while (current_entry < c->entries) {\n            int limit = c->entries - current_entry;\n            int n = get_bits(f, ilog(limit));\n            if (current_length >= 32) return error(f, VORBIS_invalid_setup);\n            if (current_entry + n > (int) c->entries) { return error(f, VORBIS_invalid_setup); }\n            memset(lengths + current_entry, current_length, n);\n            current_entry += n;\n            ++current_length;\n         }\n      } else {\n         for (j=0; j < c->entries; ++j) {\n            int present = c->sparse ? get_bits(f,1) : 1;\n            if (present) {\n               lengths[j] = get_bits(f, 5) + 1;\n               ++total;\n               if (lengths[j] == 32)\n                  return error(f, VORBIS_invalid_setup);\n            } else {\n               lengths[j] = NO_CODE;\n            }\n         }\n      }\n\n      if (c->sparse && total >= c->entries >> 2) {\n         // convert sparse items to non-sparse!\n         if (c->entries > (int) f->setup_temp_memory_required)\n            f->setup_temp_memory_required = c->entries;\n\n         c->codeword_lengths = (uint8 *) setup_malloc(f, c->entries);\n         if (c->codeword_lengths == NULL) return error(f, VORBIS_outofmem);\n         memcpy(c->codeword_lengths, lengths, c->entries);\n         setup_temp_free(f, lengths, c->entries); // note this is only safe if there have been no intervening temp mallocs!\n         lengths = c->codeword_lengths;\n         c->sparse = 0;\n      }\n\n      // compute the size of the sorted tables\n      if (c->sparse) {\n         sorted_count = total;\n      } else {\n         sorted_count = 0;\n         #ifndef STB_VORBIS_NO_HUFFMAN_BINARY_SEARCH\n         for (j=0; j < c->entries; ++j)\n            if (lengths[j] > STB_VORBIS_FAST_HUFFMAN_LENGTH && lengths[j] != NO_CODE)\n               ++sorted_count;\n         #endif\n      }\n\n      c->sorted_entries = sorted_count;\n      values = NULL;\n\n      CHECK(f);\n      if (!c->sparse) {\n         c->codewords = (uint32 *) setup_malloc(f, sizeof(c->codewords[0]) * c->entries);\n         if (!c->codewords)                  return error(f, VORBIS_outofmem);\n      } else {\n         unsigned int size;\n         if (c->sorted_entries) {\n            c->codeword_lengths = (uint8 *) setup_malloc(f, c->sorted_entries);\n            if (!c->codeword_lengths)           return error(f, VORBIS_outofmem);\n            c->codewords = (uint32 *) setup_temp_malloc(f, sizeof(*c->codewords) * c->sorted_entries);\n            if (!c->codewords)                  return error(f, VORBIS_outofmem);\n            values = (uint32 *) setup_temp_malloc(f, sizeof(*values) * c->sorted_entries);\n            if (!values)                        return error(f, VORBIS_outofmem);\n         }\n         size = c->entries + (sizeof(*c->codewords) + sizeof(*values)) * c->sorted_entries;\n         if (size > f->setup_temp_memory_required)\n            f->setup_temp_memory_required = size;\n      }\n\n      if (!compute_codewords(c, lengths, c->entries, values)) {\n         if (c->sparse) setup_temp_free(f, values, 0);\n         return error(f, VORBIS_invalid_setup);\n      }\n\n      if (c->sorted_entries) {\n         // allocate an extra slot for sentinels\n         c->sorted_codewords = (uint32 *) setup_malloc(f, sizeof(*c->sorted_codewords) * (c->sorted_entries+1));\n         if (c->sorted_codewords == NULL) return error(f, VORBIS_outofmem);\n         // allocate an extra slot at the front so that c->sorted_values[-1] is defined\n         // so that we can catch that case without an extra if\n         c->sorted_values    = ( int   *) setup_malloc(f, sizeof(*c->sorted_values   ) * (c->sorted_entries+1));\n         if (c->sorted_values == NULL) return error(f, VORBIS_outofmem);\n         ++c->sorted_values;\n         c->sorted_values[-1] = -1;\n         compute_sorted_huffman(c, lengths, values);\n      }\n\n      if (c->sparse) {\n         setup_temp_free(f, values, sizeof(*values)*c->sorted_entries);\n         setup_temp_free(f, c->codewords, sizeof(*c->codewords)*c->sorted_entries);\n         setup_temp_free(f, lengths, c->entries);\n         c->codewords = NULL;\n      }\n\n      compute_accelerated_huffman(c);\n\n      CHECK(f);\n      c->lookup_type = get_bits(f, 4);\n      if (c->lookup_type > 2) return error(f, VORBIS_invalid_setup);\n      if (c->lookup_type > 0) {\n         uint16 *mults;\n         c->minimum_value = float32_unpack(get_bits(f, 32));\n         c->delta_value = float32_unpack(get_bits(f, 32));\n         c->value_bits = get_bits(f, 4)+1;\n         c->sequence_p = get_bits(f,1);\n         if (c->lookup_type == 1) {\n            int values = lookup1_values(c->entries, c->dimensions);\n            if (values < 0) return error(f, VORBIS_invalid_setup);\n            c->lookup_values = (uint32) values;\n         } else {\n            c->lookup_values = c->entries * c->dimensions;\n         }\n         if (c->lookup_values == 0) return error(f, VORBIS_invalid_setup);\n         mults = (uint16 *) setup_temp_malloc(f, sizeof(mults[0]) * c->lookup_values);\n         if (mults == NULL) return error(f, VORBIS_outofmem);\n         for (j=0; j < (int) c->lookup_values; ++j) {\n            int q = get_bits(f, c->value_bits);\n            if (q == EOP) { setup_temp_free(f,mults,sizeof(mults[0])*c->lookup_values); return error(f, VORBIS_invalid_setup); }\n            mults[j] = q;\n         }\n\n#ifndef STB_VORBIS_DIVIDES_IN_CODEBOOK\n         if (c->lookup_type == 1) {\n            int len, sparse = c->sparse;\n            float last=0;\n            // pre-expand the lookup1-style multiplicands, to avoid a divide in the inner loop\n            if (sparse) {\n               if (c->sorted_entries == 0) goto skip;\n               c->multiplicands = (codetype *) setup_malloc(f, sizeof(c->multiplicands[0]) * c->sorted_entries * c->dimensions);\n            } else\n               c->multiplicands = (codetype *) setup_malloc(f, sizeof(c->multiplicands[0]) * c->entries        * c->dimensions);\n            if (c->multiplicands == NULL) { setup_temp_free(f,mults,sizeof(mults[0])*c->lookup_values); return error(f, VORBIS_outofmem); }\n            len = sparse ? c->sorted_entries : c->entries;\n            for (j=0; j < len; ++j) {\n               unsigned int z = sparse ? c->sorted_values[j] : j;\n               unsigned int div=1;\n               for (k=0; k < c->dimensions; ++k) {\n                  int off = (z / div) % c->lookup_values;\n                  float val = mults[off];\n                  val = mults[off]*c->delta_value + c->minimum_value + last;\n                  c->multiplicands[j*c->dimensions + k] = val;\n                  if (c->sequence_p)\n                     last = val;\n                  if (k+1 < c->dimensions) {\n                     if (div > UINT_MAX / (unsigned int) c->lookup_values) {\n                        setup_temp_free(f, mults,sizeof(mults[0])*c->lookup_values);\n                        return error(f, VORBIS_invalid_setup);\n                     }\n                     div *= c->lookup_values;\n                  }\n               }\n            }\n            c->lookup_type = 2;\n         }\n         else\n#endif\n         {\n            float last=0;\n            CHECK(f);\n            c->multiplicands = (codetype *) setup_malloc(f, sizeof(c->multiplicands[0]) * c->lookup_values);\n            if (c->multiplicands == NULL) { setup_temp_free(f, mults,sizeof(mults[0])*c->lookup_values); return error(f, VORBIS_outofmem); }\n            for (j=0; j < (int) c->lookup_values; ++j) {\n               float val = mults[j] * c->delta_value + c->minimum_value + last;\n               c->multiplicands[j] = val;\n               if (c->sequence_p)\n                  last = val;\n            }\n         }\n#ifndef STB_VORBIS_DIVIDES_IN_CODEBOOK\n        skip:;\n#endif\n         setup_temp_free(f, mults, sizeof(mults[0])*c->lookup_values);\n\n         CHECK(f);\n      }\n      CHECK(f);\n   }\n\n   // time domain transfers (notused)\n\n   x = get_bits(f, 6) + 1;\n   for (i=0; i < x; ++i) {\n      uint32 z = get_bits(f, 16);\n      if (z != 0) return error(f, VORBIS_invalid_setup);\n   }\n\n   // Floors\n   f->floor_count = get_bits(f, 6)+1;\n   f->floor_config = (Floor *)  setup_malloc(f, f->floor_count * sizeof(*f->floor_config));\n   if (f->floor_config == NULL) return error(f, VORBIS_outofmem);\n   for (i=0; i < f->floor_count; ++i) {\n      f->floor_types[i] = get_bits(f, 16);\n      if (f->floor_types[i] > 1) return error(f, VORBIS_invalid_setup);\n      if (f->floor_types[i] == 0) {\n         Floor0 *g = &f->floor_config[i].floor0;\n         g->order = get_bits(f,8);\n         g->rate = get_bits(f,16);\n         g->bark_map_size = get_bits(f,16);\n         g->amplitude_bits = get_bits(f,6);\n         g->amplitude_offset = get_bits(f,8);\n         g->number_of_books = get_bits(f,4) + 1;\n         for (j=0; j < g->number_of_books; ++j)\n            g->book_list[j] = get_bits(f,8);\n         return error(f, VORBIS_feature_not_supported);\n      } else {\n         stbv__floor_ordering p[31*8+2];\n         Floor1 *g = &f->floor_config[i].floor1;\n         int max_class = -1; \n         g->partitions = get_bits(f, 5);\n         for (j=0; j < g->partitions; ++j) {\n            g->partition_class_list[j] = get_bits(f, 4);\n            if (g->partition_class_list[j] > max_class)\n               max_class = g->partition_class_list[j];\n         }\n         for (j=0; j <= max_class; ++j) {\n            g->class_dimensions[j] = get_bits(f, 3)+1;\n            g->class_subclasses[j] = get_bits(f, 2);\n            if (g->class_subclasses[j]) {\n               g->class_masterbooks[j] = get_bits(f, 8);\n               if (g->class_masterbooks[j] >= f->codebook_count) return error(f, VORBIS_invalid_setup);\n            }\n            for (k=0; k < 1 << g->class_subclasses[j]; ++k) {\n               g->subclass_books[j][k] = get_bits(f,8)-1;\n               if (g->subclass_books[j][k] >= f->codebook_count) return error(f, VORBIS_invalid_setup);\n            }\n         }\n         g->floor1_multiplier = get_bits(f,2)+1;\n         g->rangebits = get_bits(f,4);\n         g->Xlist[0] = 0;\n         g->Xlist[1] = 1 << g->rangebits;\n         g->values = 2;\n         for (j=0; j < g->partitions; ++j) {\n            int c = g->partition_class_list[j];\n            for (k=0; k < g->class_dimensions[c]; ++k) {\n               g->Xlist[g->values] = get_bits(f, g->rangebits);\n               ++g->values;\n            }\n         }\n         // precompute the sorting\n         for (j=0; j < g->values; ++j) {\n            p[j].x = g->Xlist[j];\n            p[j].id = j;\n         }\n         qsort(p, g->values, sizeof(p[0]), point_compare);\n         for (j=0; j < g->values-1; ++j)\n            if (p[j].x == p[j+1].x)\n               return error(f, VORBIS_invalid_setup);\n         for (j=0; j < g->values; ++j)\n            g->sorted_order[j] = (uint8) p[j].id;\n         // precompute the neighbors\n         for (j=2; j < g->values; ++j) {\n            int low,hi;\n            neighbors(g->Xlist, j, &low,&hi);\n            g->neighbors[j][0] = low;\n            g->neighbors[j][1] = hi;\n         }\n\n         if (g->values > longest_floorlist)\n            longest_floorlist = g->values;\n      }\n   }\n\n   // Residue\n   f->residue_count = get_bits(f, 6)+1;\n   f->residue_config = (Residue *) setup_malloc(f, f->residue_count * sizeof(f->residue_config[0]));\n   if (f->residue_config == NULL) return error(f, VORBIS_outofmem);\n   memset(f->residue_config, 0, f->residue_count * sizeof(f->residue_config[0]));\n   for (i=0; i < f->residue_count; ++i) {\n      uint8 residue_cascade[64];\n      Residue *r = f->residue_config+i;\n      f->residue_types[i] = get_bits(f, 16);\n      if (f->residue_types[i] > 2) return error(f, VORBIS_invalid_setup);\n      r->begin = get_bits(f, 24);\n      r->end = get_bits(f, 24);\n      if (r->end < r->begin) return error(f, VORBIS_invalid_setup);\n      r->part_size = get_bits(f,24)+1;\n      r->classifications = get_bits(f,6)+1;\n      r->classbook = get_bits(f,8);\n      if (r->classbook >= f->codebook_count) return error(f, VORBIS_invalid_setup);\n      for (j=0; j < r->classifications; ++j) {\n         uint8 high_bits=0;\n         uint8 low_bits=get_bits(f,3);\n         if (get_bits(f,1))\n            high_bits = get_bits(f,5);\n         residue_cascade[j] = high_bits*8 + low_bits;\n      }\n      r->residue_books = (short (*)[8]) setup_malloc(f, sizeof(r->residue_books[0]) * r->classifications);\n      if (r->residue_books == NULL) return error(f, VORBIS_outofmem);\n      for (j=0; j < r->classifications; ++j) {\n         for (k=0; k < 8; ++k) {\n            if (residue_cascade[j] & (1 << k)) {\n               r->residue_books[j][k] = get_bits(f, 8);\n               if (r->residue_books[j][k] >= f->codebook_count) return error(f, VORBIS_invalid_setup);\n            } else {\n               r->residue_books[j][k] = -1;\n            }\n         }\n      }\n      // precompute the classifications[] array to avoid inner-loop mod/divide\n      // call it 'classdata' since we already have r->classifications\n      r->classdata = (uint8 **) setup_malloc(f, sizeof(*r->classdata) * f->codebooks[r->classbook].entries);\n      if (!r->classdata) return error(f, VORBIS_outofmem);\n      memset(r->classdata, 0, sizeof(*r->classdata) * f->codebooks[r->classbook].entries);\n      for (j=0; j < f->codebooks[r->classbook].entries; ++j) {\n         int classwords = f->codebooks[r->classbook].dimensions;\n         int temp = j;\n         r->classdata[j] = (uint8 *) setup_malloc(f, sizeof(r->classdata[j][0]) * classwords);\n         if (r->classdata[j] == NULL) return error(f, VORBIS_outofmem);\n         for (k=classwords-1; k >= 0; --k) {\n            r->classdata[j][k] = temp % r->classifications;\n            temp /= r->classifications;\n         }\n      }\n   }\n\n   f->mapping_count = get_bits(f,6)+1;\n   f->mapping = (Mapping *) setup_malloc(f, f->mapping_count * sizeof(*f->mapping));\n   if (f->mapping == NULL) return error(f, VORBIS_outofmem);\n   memset(f->mapping, 0, f->mapping_count * sizeof(*f->mapping));\n   for (i=0; i < f->mapping_count; ++i) {\n      Mapping *m = f->mapping + i;      \n      int mapping_type = get_bits(f,16);\n      if (mapping_type != 0) return error(f, VORBIS_invalid_setup);\n      m->chan = (MappingChannel *) setup_malloc(f, f->channels * sizeof(*m->chan));\n      if (m->chan == NULL) return error(f, VORBIS_outofmem);\n      if (get_bits(f,1))\n         m->submaps = get_bits(f,4)+1;\n      else\n         m->submaps = 1;\n      if (m->submaps > max_submaps)\n         max_submaps = m->submaps;\n      if (get_bits(f,1)) {\n         m->coupling_steps = get_bits(f,8)+1;\n         if (m->coupling_steps > f->channels) return error(f, VORBIS_invalid_setup);\n         for (k=0; k < m->coupling_steps; ++k) {\n            m->chan[k].magnitude = get_bits(f, ilog(f->channels-1));\n            m->chan[k].angle = get_bits(f, ilog(f->channels-1));\n            if (m->chan[k].magnitude >= f->channels)        return error(f, VORBIS_invalid_setup);\n            if (m->chan[k].angle     >= f->channels)        return error(f, VORBIS_invalid_setup);\n            if (m->chan[k].magnitude == m->chan[k].angle)   return error(f, VORBIS_invalid_setup);\n         }\n      } else\n         m->coupling_steps = 0;\n\n      // reserved field\n      if (get_bits(f,2)) return error(f, VORBIS_invalid_setup);\n      if (m->submaps > 1) {\n         for (j=0; j < f->channels; ++j) {\n            m->chan[j].mux = get_bits(f, 4);\n            if (m->chan[j].mux >= m->submaps)                return error(f, VORBIS_invalid_setup);\n         }\n      } else\n         // @SPECIFICATION: this case is missing from the spec\n         for (j=0; j < f->channels; ++j)\n            m->chan[j].mux = 0;\n\n      for (j=0; j < m->submaps; ++j) {\n         get_bits(f,8); // discard\n         m->submap_floor[j] = get_bits(f,8);\n         m->submap_residue[j] = get_bits(f,8);\n         if (m->submap_floor[j] >= f->floor_count)      return error(f, VORBIS_invalid_setup);\n         if (m->submap_residue[j] >= f->residue_count)  return error(f, VORBIS_invalid_setup);\n      }\n   }\n\n   // Modes\n   f->mode_count = get_bits(f, 6)+1;\n   for (i=0; i < f->mode_count; ++i) {\n      Mode *m = f->mode_config+i;\n      m->blockflag = get_bits(f,1);\n      m->windowtype = get_bits(f,16);\n      m->transformtype = get_bits(f,16);\n      m->mapping = get_bits(f,8);\n      if (m->windowtype != 0)                 return error(f, VORBIS_invalid_setup);\n      if (m->transformtype != 0)              return error(f, VORBIS_invalid_setup);\n      if (m->mapping >= f->mapping_count)     return error(f, VORBIS_invalid_setup);\n   }\n\n   flush_packet(f);\n\n   f->previous_length = 0;\n\n   for (i=0; i < f->channels; ++i) {\n      f->channel_buffers[i] = (float *) setup_malloc(f, sizeof(float) * f->blocksize_1);\n      f->previous_window[i] = (float *) setup_malloc(f, sizeof(float) * f->blocksize_1/2);\n      f->finalY[i]          = (int16 *) setup_malloc(f, sizeof(int16) * longest_floorlist);\n      if (f->channel_buffers[i] == NULL || f->previous_window[i] == NULL || f->finalY[i] == NULL) return error(f, VORBIS_outofmem);\n      memset(f->channel_buffers[i], 0, sizeof(float) * f->blocksize_1);\n      #ifdef STB_VORBIS_NO_DEFER_FLOOR\n      f->floor_buffers[i]   = (float *) setup_malloc(f, sizeof(float) * f->blocksize_1/2);\n      if (f->floor_buffers[i] == NULL) return error(f, VORBIS_outofmem);\n      #endif\n   }\n\n   if (!init_blocksize(f, 0, f->blocksize_0)) return FALSE;\n   if (!init_blocksize(f, 1, f->blocksize_1)) return FALSE;\n   f->blocksize[0] = f->blocksize_0;\n   f->blocksize[1] = f->blocksize_1;\n\n#ifdef STB_VORBIS_DIVIDE_TABLE\n   if (integer_divide_table[1][1]==0)\n      for (i=0; i < DIVTAB_NUMER; ++i)\n         for (j=1; j < DIVTAB_DENOM; ++j)\n            integer_divide_table[i][j] = i / j;\n#endif\n\n   // compute how much temporary memory is needed\n\n   // 1.\n   {\n      uint32 imdct_mem = (f->blocksize_1 * sizeof(float) >> 1);\n      uint32 classify_mem;\n      int i,max_part_read=0;\n      for (i=0; i < f->residue_count; ++i) {\n         Residue *r = f->residue_config + i;\n         unsigned int actual_size = f->blocksize_1 / 2;\n         unsigned int limit_r_begin = r->begin < actual_size ? r->begin : actual_size;\n         unsigned int limit_r_end   = r->end   < actual_size ? r->end   : actual_size;\n         int n_read = limit_r_end - limit_r_begin;\n         int part_read = n_read / r->part_size;\n         if (part_read > max_part_read)\n            max_part_read = part_read;\n      }\n      #ifndef STB_VORBIS_DIVIDES_IN_RESIDUE\n      classify_mem = f->channels * (sizeof(void*) + max_part_read * sizeof(uint8 *));\n      #else\n      classify_mem = f->channels * (sizeof(void*) + max_part_read * sizeof(int *));\n      #endif\n\n      // maximum reasonable partition size is f->blocksize_1\n\n      f->temp_memory_required = classify_mem;\n      if (imdct_mem > f->temp_memory_required)\n         f->temp_memory_required = imdct_mem;\n   }\n\n   f->first_decode = TRUE;\n\n   if (f->alloc.alloc_buffer) {\n      assert(f->temp_offset == f->alloc.alloc_buffer_length_in_bytes);\n      // check if there's enough temp memory so we don't error later\n      if (f->setup_offset + sizeof(*f) + f->temp_memory_required > (unsigned) f->temp_offset)\n         return error(f, VORBIS_outofmem);\n   }\n\n   f->first_audio_page_offset = stb_vorbis_get_file_offset(f);\n\n   return TRUE;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -127,6 +127,7 @@\n          while (current_entry < c->entries) {\n             int limit = c->entries - current_entry;\n             int n = get_bits(f, ilog(limit));\n+            if (current_length >= 32) return error(f, VORBIS_invalid_setup);\n             if (current_entry + n > (int) c->entries) { return error(f, VORBIS_invalid_setup); }\n             memset(lengths + current_entry, current_length, n);\n             current_entry += n;\n@@ -230,7 +231,9 @@\n          c->value_bits = get_bits(f, 4)+1;\n          c->sequence_p = get_bits(f,1);\n          if (c->lookup_type == 1) {\n-            c->lookup_values = lookup1_values(c->entries, c->dimensions);\n+            int values = lookup1_values(c->entries, c->dimensions);\n+            if (values < 0) return error(f, VORBIS_invalid_setup);\n+            c->lookup_values = (uint32) values;\n          } else {\n             c->lookup_values = c->entries * c->dimensions;\n          }\n@@ -366,6 +369,9 @@\n             p[j].id = j;\n          }\n          qsort(p, g->values, sizeof(p[0]), point_compare);\n+         for (j=0; j < g->values-1; ++j)\n+            if (p[j].x == p[j+1].x)\n+               return error(f, VORBIS_invalid_setup);\n          for (j=0; j < g->values; ++j)\n             g->sorted_order[j] = (uint8) p[j].id;\n          // precompute the neighbors\n@@ -452,6 +458,7 @@\n          max_submaps = m->submaps;\n       if (get_bits(f,1)) {\n          m->coupling_steps = get_bits(f,8)+1;\n+         if (m->coupling_steps > f->channels) return error(f, VORBIS_invalid_setup);\n          for (k=0; k < m->coupling_steps; ++k) {\n             m->chan[k].magnitude = get_bits(f, ilog(f->channels-1));\n             m->chan[k].angle = get_bits(f, ilog(f->channels-1));",
        "diff_line_info": {
            "deleted_lines": [
                "            c->lookup_values = lookup1_values(c->entries, c->dimensions);"
            ],
            "added_lines": [
                "            if (current_length >= 32) return error(f, VORBIS_invalid_setup);",
                "            int values = lookup1_values(c->entries, c->dimensions);",
                "            if (values < 0) return error(f, VORBIS_invalid_setup);",
                "            c->lookup_values = (uint32) values;",
                "         for (j=0; j < g->values-1; ++j)",
                "            if (p[j].x == p[j+1].x)",
                "               return error(f, VORBIS_invalid_setup);",
                "         if (m->coupling_steps > f->channels) return error(f, VORBIS_invalid_setup);"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-13217",
        "func_name": "nothings/stb/lookup1_values",
        "description": "A heap buffer overflow in the start_decoder function in stb_vorbis through 2019-03-04 allows an attacker to cause a denial of service or execute arbitrary code by opening a crafted Ogg Vorbis file.",
        "git_url": "https://github.com/nothings/stb/commit/98fdfc6df88b1e34a736d5e126e6c8139c8de1a6",
        "commit_title": "Fix seven bugs discovered and fixed by ForAllSecure:",
        "commit_text": " CVE-2019-13217: heap buffer overflow in start_decoder() CVE-2019-13218: stack buffer overflow in compute_codewords() CVE-2019-13219: uninitialized memory in vorbis_decode_packet_rest() CVE-2019-13220: out-of-range read in draw_line() CVE-2019-13221: issue with large 1D codebooks in lookup1_values() CVE-2019-13222: unchecked NULL returned by get_window() CVE-2019-13223: division by zero in predict_point()",
        "func_before": "static int lookup1_values(int entries, int dim)\n{\n   int r = (int) floor(exp((float) log((float) entries) / dim));\n   if ((int) floor(pow((float) r+1, dim)) <= entries)   // (int) cast for MinGW warning;\n      ++r;                                              // floor() to avoid _ftol() when non-CRT\n   assert(pow((float) r+1, dim) > entries);\n   assert((int) floor(pow((float) r, dim)) <= entries); // (int),floor() as above\n   return r;\n}",
        "func": "static int lookup1_values(int entries, int dim)\n{\n   int r = (int) floor(exp((float) log((float) entries) / dim));\n   if ((int) floor(pow((float) r+1, dim)) <= entries)   // (int) cast for MinGW warning;\n      ++r;                                              // floor() to avoid _ftol() when non-CRT\n   if (pow((float) r+1, dim) <= entries)\n      return -1;\n   if ((int) floor(pow((float) r, dim)) > entries)\n      return -1;\n   return r;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,7 +3,9 @@\n    int r = (int) floor(exp((float) log((float) entries) / dim));\n    if ((int) floor(pow((float) r+1, dim)) <= entries)   // (int) cast for MinGW warning;\n       ++r;                                              // floor() to avoid _ftol() when non-CRT\n-   assert(pow((float) r+1, dim) > entries);\n-   assert((int) floor(pow((float) r, dim)) <= entries); // (int),floor() as above\n+   if (pow((float) r+1, dim) <= entries)\n+      return -1;\n+   if ((int) floor(pow((float) r, dim)) > entries)\n+      return -1;\n    return r;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "   assert(pow((float) r+1, dim) > entries);",
                "   assert((int) floor(pow((float) r, dim)) <= entries); // (int),floor() as above"
            ],
            "added_lines": [
                "   if (pow((float) r+1, dim) <= entries)",
                "      return -1;",
                "   if ((int) floor(pow((float) r, dim)) > entries)",
                "      return -1;"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-13217",
        "func_name": "nothings/stb/vorbis_finish_frame",
        "description": "A heap buffer overflow in the start_decoder function in stb_vorbis through 2019-03-04 allows an attacker to cause a denial of service or execute arbitrary code by opening a crafted Ogg Vorbis file.",
        "git_url": "https://github.com/nothings/stb/commit/98fdfc6df88b1e34a736d5e126e6c8139c8de1a6",
        "commit_title": "Fix seven bugs discovered and fixed by ForAllSecure:",
        "commit_text": " CVE-2019-13217: heap buffer overflow in start_decoder() CVE-2019-13218: stack buffer overflow in compute_codewords() CVE-2019-13219: uninitialized memory in vorbis_decode_packet_rest() CVE-2019-13220: out-of-range read in draw_line() CVE-2019-13221: issue with large 1D codebooks in lookup1_values() CVE-2019-13222: unchecked NULL returned by get_window() CVE-2019-13223: division by zero in predict_point()",
        "func_before": "static int vorbis_finish_frame(stb_vorbis *f, int len, int left, int right)\n{\n   int prev,i,j;\n   // we use right&left (the start of the right- and left-window sin()-regions)\n   // to determine how much to return, rather than inferring from the rules\n   // (same result, clearer code); 'left' indicates where our sin() window\n   // starts, therefore where the previous window's right edge starts, and\n   // therefore where to start mixing from the previous buffer. 'right'\n   // indicates where our sin() ending-window starts, therefore that's where\n   // we start saving, and where our returned-data ends.\n\n   // mixin from previous window\n   if (f->previous_length) {\n      int i,j, n = f->previous_length;\n      float *w = get_window(f, n);\n      for (i=0; i < f->channels; ++i) {\n         for (j=0; j < n; ++j)\n            f->channel_buffers[i][left+j] =\n               f->channel_buffers[i][left+j]*w[    j] +\n               f->previous_window[i][     j]*w[n-1-j];\n      }\n   }\n\n   prev = f->previous_length;\n\n   // last half of this data becomes previous window\n   f->previous_length = len - right;\n\n   // @OPTIMIZE: could avoid this copy by double-buffering the\n   // output (flipping previous_window with channel_buffers), but\n   // then previous_window would have to be 2x as large, and\n   // channel_buffers couldn't be temp mem (although they're NOT\n   // currently temp mem, they could be (unless we want to level\n   // performance by spreading out the computation))\n   for (i=0; i < f->channels; ++i)\n      for (j=0; right+j < len; ++j)\n         f->previous_window[i][j] = f->channel_buffers[i][right+j];\n\n   if (!prev)\n      // there was no previous packet, so this data isn't valid...\n      // this isn't entirely true, only the would-have-overlapped data\n      // isn't valid, but this seems to be what the spec requires\n      return 0;\n\n   // truncate a short frame\n   if (len < right) right = len;\n\n   f->samples_output += right-left;\n\n   return right - left;\n}",
        "func": "static int vorbis_finish_frame(stb_vorbis *f, int len, int left, int right)\n{\n   int prev,i,j;\n   // we use right&left (the start of the right- and left-window sin()-regions)\n   // to determine how much to return, rather than inferring from the rules\n   // (same result, clearer code); 'left' indicates where our sin() window\n   // starts, therefore where the previous window's right edge starts, and\n   // therefore where to start mixing from the previous buffer. 'right'\n   // indicates where our sin() ending-window starts, therefore that's where\n   // we start saving, and where our returned-data ends.\n\n   // mixin from previous window\n   if (f->previous_length) {\n      int i,j, n = f->previous_length;\n      float *w = get_window(f, n);\n      if (w == NULL) return 0;\n      for (i=0; i < f->channels; ++i) {\n         for (j=0; j < n; ++j)\n            f->channel_buffers[i][left+j] =\n               f->channel_buffers[i][left+j]*w[    j] +\n               f->previous_window[i][     j]*w[n-1-j];\n      }\n   }\n\n   prev = f->previous_length;\n\n   // last half of this data becomes previous window\n   f->previous_length = len - right;\n\n   // @OPTIMIZE: could avoid this copy by double-buffering the\n   // output (flipping previous_window with channel_buffers), but\n   // then previous_window would have to be 2x as large, and\n   // channel_buffers couldn't be temp mem (although they're NOT\n   // currently temp mem, they could be (unless we want to level\n   // performance by spreading out the computation))\n   for (i=0; i < f->channels; ++i)\n      for (j=0; right+j < len; ++j)\n         f->previous_window[i][j] = f->channel_buffers[i][right+j];\n\n   if (!prev)\n      // there was no previous packet, so this data isn't valid...\n      // this isn't entirely true, only the would-have-overlapped data\n      // isn't valid, but this seems to be what the spec requires\n      return 0;\n\n   // truncate a short frame\n   if (len < right) right = len;\n\n   f->samples_output += right-left;\n\n   return right - left;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -13,6 +13,7 @@\n    if (f->previous_length) {\n       int i,j, n = f->previous_length;\n       float *w = get_window(f, n);\n+      if (w == NULL) return 0;\n       for (i=0; i < f->channels; ++i) {\n          for (j=0; j < n; ++j)\n             f->channel_buffers[i][left+j] =",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "      if (w == NULL) return 0;"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-13217",
        "func_name": "nothings/stb/get_window",
        "description": "A heap buffer overflow in the start_decoder function in stb_vorbis through 2019-03-04 allows an attacker to cause a denial of service or execute arbitrary code by opening a crafted Ogg Vorbis file.",
        "git_url": "https://github.com/nothings/stb/commit/98fdfc6df88b1e34a736d5e126e6c8139c8de1a6",
        "commit_title": "Fix seven bugs discovered and fixed by ForAllSecure:",
        "commit_text": " CVE-2019-13217: heap buffer overflow in start_decoder() CVE-2019-13218: stack buffer overflow in compute_codewords() CVE-2019-13219: uninitialized memory in vorbis_decode_packet_rest() CVE-2019-13220: out-of-range read in draw_line() CVE-2019-13221: issue with large 1D codebooks in lookup1_values() CVE-2019-13222: unchecked NULL returned by get_window() CVE-2019-13223: division by zero in predict_point()",
        "func_before": "static float *get_window(vorb *f, int len)\n{\n   len <<= 1;\n   if (len == f->blocksize_0) return f->window[0];\n   if (len == f->blocksize_1) return f->window[1];\n   assert(0);\n   return NULL;\n}",
        "func": "static float *get_window(vorb *f, int len)\n{\n   len <<= 1;\n   if (len == f->blocksize_0) return f->window[0];\n   if (len == f->blocksize_1) return f->window[1];\n   return NULL;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,6 +3,5 @@\n    len <<= 1;\n    if (len == f->blocksize_0) return f->window[0];\n    if (len == f->blocksize_1) return f->window[1];\n-   assert(0);\n    return NULL;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "   assert(0);"
            ],
            "added_lines": []
        }
    },
    {
        "cve_id": "CVE-2019-13217",
        "func_name": "nothings/stb/draw_line",
        "description": "A heap buffer overflow in the start_decoder function in stb_vorbis through 2019-03-04 allows an attacker to cause a denial of service or execute arbitrary code by opening a crafted Ogg Vorbis file.",
        "git_url": "https://github.com/nothings/stb/commit/98fdfc6df88b1e34a736d5e126e6c8139c8de1a6",
        "commit_title": "Fix seven bugs discovered and fixed by ForAllSecure:",
        "commit_text": " CVE-2019-13217: heap buffer overflow in start_decoder() CVE-2019-13218: stack buffer overflow in compute_codewords() CVE-2019-13219: uninitialized memory in vorbis_decode_packet_rest() CVE-2019-13220: out-of-range read in draw_line() CVE-2019-13221: issue with large 1D codebooks in lookup1_values() CVE-2019-13222: unchecked NULL returned by get_window() CVE-2019-13223: division by zero in predict_point()",
        "func_before": "static __forceinline void draw_line(float *output, int x0, int y0, int x1, int y1, int n)\n{\n   int dy = y1 - y0;\n   int adx = x1 - x0;\n   int ady = abs(dy);\n   int base;\n   int x=x0,y=y0;\n   int err = 0;\n   int sy;\n\n#ifdef STB_VORBIS_DIVIDE_TABLE\n   if (adx < DIVTAB_DENOM && ady < DIVTAB_NUMER) {\n      if (dy < 0) {\n         base = -integer_divide_table[ady][adx];\n         sy = base-1;\n      } else {\n         base =  integer_divide_table[ady][adx];\n         sy = base+1;\n      }\n   } else {\n      base = dy / adx;\n      if (dy < 0)\n         sy = base - 1;\n      else\n         sy = base+1;\n   }\n#else\n   base = dy / adx;\n   if (dy < 0)\n      sy = base - 1;\n   else\n      sy = base+1;\n#endif\n   ady -= abs(base) * adx;\n   if (x1 > n) x1 = n;\n   if (x < x1) {\n      LINE_OP(output[x], inverse_db_table[y]);\n      for (++x; x < x1; ++x) {\n         err += ady;\n         if (err >= adx) {\n            err -= adx;\n            y += sy;\n         } else\n            y += base;\n         LINE_OP(output[x], inverse_db_table[y]);\n      }\n   }\n}",
        "func": "static __forceinline void draw_line(float *output, int x0, int y0, int x1, int y1, int n)\n{\n   int dy = y1 - y0;\n   int adx = x1 - x0;\n   int ady = abs(dy);\n   int base;\n   int x=x0,y=y0;\n   int err = 0;\n   int sy;\n\n#ifdef STB_VORBIS_DIVIDE_TABLE\n   if (adx < DIVTAB_DENOM && ady < DIVTAB_NUMER) {\n      if (dy < 0) {\n         base = -integer_divide_table[ady][adx];\n         sy = base-1;\n      } else {\n         base =  integer_divide_table[ady][adx];\n         sy = base+1;\n      }\n   } else {\n      base = dy / adx;\n      if (dy < 0)\n         sy = base - 1;\n      else\n         sy = base+1;\n   }\n#else\n   base = dy / adx;\n   if (dy < 0)\n      sy = base - 1;\n   else\n      sy = base+1;\n#endif\n   ady -= abs(base) * adx;\n   if (x1 > n) x1 = n;\n   if (x < x1) {\n      LINE_OP(output[x], inverse_db_table[y&255]);\n      for (++x; x < x1; ++x) {\n         err += ady;\n         if (err >= adx) {\n            err -= adx;\n            y += sy;\n         } else\n            y += base;\n         LINE_OP(output[x], inverse_db_table[y&255]);\n      }\n   }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -34,7 +34,7 @@\n    ady -= abs(base) * adx;\n    if (x1 > n) x1 = n;\n    if (x < x1) {\n-      LINE_OP(output[x], inverse_db_table[y]);\n+      LINE_OP(output[x], inverse_db_table[y&255]);\n       for (++x; x < x1; ++x) {\n          err += ady;\n          if (err >= adx) {\n@@ -42,7 +42,7 @@\n             y += sy;\n          } else\n             y += base;\n-         LINE_OP(output[x], inverse_db_table[y]);\n+         LINE_OP(output[x], inverse_db_table[y&255]);\n       }\n    }\n }",
        "diff_line_info": {
            "deleted_lines": [
                "      LINE_OP(output[x], inverse_db_table[y]);",
                "         LINE_OP(output[x], inverse_db_table[y]);"
            ],
            "added_lines": [
                "      LINE_OP(output[x], inverse_db_table[y&255]);",
                "         LINE_OP(output[x], inverse_db_table[y&255]);"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-17533",
        "func_name": "tbeu/matio/Mat_VarReadNextInfo4",
        "description": "Mat_VarReadNextInfo4 in mat4.c in MATIO 1.5.17 omits a certain '\\0' character, leading to a heap-based buffer over-read in strdup_vprintf when uninitialized memory is accessed.",
        "git_url": "https://github.com/tbeu/matio/commit/651a8e28099edb5fbb9e4e1d4d3238848f446c9a",
        "commit_title": "Avoid uninitialized memory",
        "commit_text": " As reported by https://bugs.chromium.org/p/oss-fuzz/issues/detail?id=16856",
        "func_before": "matvar_t *\nMat_VarReadNextInfo4(mat_t *mat)\n{\n    int       M,O,data_type,class_type;\n    mat_int32_t tmp;\n    long      nBytes;\n    size_t    readresult;\n    matvar_t *matvar = NULL;\n    union {\n        mat_uint32_t u;\n        mat_uint8_t  c[4];\n    } endian;\n\n    if ( mat == NULL || mat->fp == NULL )\n        return NULL;\n    else if ( NULL == (matvar = Mat_VarCalloc()) )\n        return NULL;\n\n    readresult = fread(&tmp,sizeof(int),1,(FILE*)mat->fp);\n    if ( 1 != readresult ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n\n    endian.u = 0x01020304;\n\n    /* See if MOPT may need byteswapping */\n    if ( tmp < 0 || tmp > 4052 ) {\n        if ( Mat_int32Swap(&tmp) > 4052 ) {\n            Mat_VarFree(matvar);\n            return NULL;\n        }\n    }\n\n    M = (int)floor(tmp / 1000.0);\n    switch ( M ) {\n        case 0:\n            /* IEEE little endian */\n            mat->byteswap = endian.c[0] != 4;\n            break;\n        case 1:\n            /* IEEE big endian */\n            mat->byteswap = endian.c[0] != 1;\n            break;\n        default:\n            /* VAX, Cray, or bogus */\n            Mat_VarFree(matvar);\n            return NULL;\n    }\n\n    tmp -= M*1000;\n    O = (int)floor(tmp / 100.0);\n    /* O must be zero */\n    if ( 0 != O ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n\n    tmp -= O*100;\n    data_type = (int)floor(tmp / 10.0);\n    /* Convert the V4 data type */\n    switch ( data_type ) {\n        case 0:\n            matvar->data_type = MAT_T_DOUBLE;\n            break;\n        case 1:\n            matvar->data_type = MAT_T_SINGLE;\n            break;\n        case 2:\n            matvar->data_type = MAT_T_INT32;\n            break;\n        case 3:\n            matvar->data_type = MAT_T_INT16;\n            break;\n        case 4:\n            matvar->data_type = MAT_T_UINT16;\n            break;\n        case 5:\n            matvar->data_type = MAT_T_UINT8;\n            break;\n        default:\n            Mat_VarFree(matvar);\n            return NULL;\n    }\n\n    tmp -= data_type*10;\n    class_type = (int)floor(tmp / 1.0);\n    switch ( class_type ) {\n        case 0:\n            matvar->class_type = MAT_C_DOUBLE;\n            break;\n        case 1:\n            matvar->class_type = MAT_C_CHAR;\n            break;\n        case 2:\n            matvar->class_type = MAT_C_SPARSE;\n            break;\n        default:\n            Mat_VarFree(matvar);\n            return NULL;\n    }\n\n    matvar->rank = 2;\n    matvar->dims = (size_t*)calloc(2, sizeof(*matvar->dims));\n    if ( NULL == matvar->dims ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n    readresult = fread(&tmp,sizeof(int),1,(FILE*)mat->fp);\n    if ( mat->byteswap )\n        Mat_int32Swap(&tmp);\n    matvar->dims[0] = tmp;\n    if ( 1 != readresult ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n    readresult = fread(&tmp,sizeof(int),1,(FILE*)mat->fp);\n    if ( mat->byteswap )\n        Mat_int32Swap(&tmp);\n    matvar->dims[1] = tmp;\n    if ( 1 != readresult ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n\n    readresult = fread(&(matvar->isComplex),sizeof(int),1,(FILE*)mat->fp);\n    if ( 1 != readresult ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n    if ( matvar->isComplex && MAT_C_CHAR == matvar->class_type ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n    readresult = fread(&tmp,sizeof(int),1,(FILE*)mat->fp);\n    if ( 1 != readresult ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n    if ( mat->byteswap )\n        Mat_int32Swap(&tmp);\n    /* Check that the length of the variable name is at least 1 */\n    if ( tmp < 1 ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n    matvar->name = (char*)malloc(tmp);\n    if ( NULL == matvar->name ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n    readresult = fread(matvar->name,1,tmp,(FILE*)mat->fp);\n    if ( tmp != readresult ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n\n    matvar->internal->datapos = ftell((FILE*)mat->fp);\n    if ( matvar->internal->datapos == -1L ) {\n        Mat_VarFree(matvar);\n        Mat_Critical(\"Couldn't determine file position\");\n        return NULL;\n    }\n    {\n        int err;\n        size_t tmp2 = Mat_SizeOf(matvar->data_type);\n        if ( matvar->isComplex )\n            tmp2 *= 2;\n        err = SafeMulDims(matvar, &tmp2);\n        if ( err ) {\n            Mat_VarFree(matvar);\n            Mat_Critical(\"Integer multiplication overflow\");\n            return NULL;\n        }\n\n        nBytes = (long)tmp2;\n    }\n    (void)fseek((FILE*)mat->fp,nBytes,SEEK_CUR);\n\n    return matvar;\n}",
        "func": "matvar_t *\nMat_VarReadNextInfo4(mat_t *mat)\n{\n    int       M,O,data_type,class_type;\n    mat_int32_t tmp;\n    long      nBytes;\n    size_t    readresult;\n    matvar_t *matvar = NULL;\n    union {\n        mat_uint32_t u;\n        mat_uint8_t  c[4];\n    } endian;\n\n    if ( mat == NULL || mat->fp == NULL )\n        return NULL;\n    else if ( NULL == (matvar = Mat_VarCalloc()) )\n        return NULL;\n\n    readresult = fread(&tmp,sizeof(int),1,(FILE*)mat->fp);\n    if ( 1 != readresult ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n\n    endian.u = 0x01020304;\n\n    /* See if MOPT may need byteswapping */\n    if ( tmp < 0 || tmp > 4052 ) {\n        if ( Mat_int32Swap(&tmp) > 4052 ) {\n            Mat_VarFree(matvar);\n            return NULL;\n        }\n    }\n\n    M = (int)floor(tmp / 1000.0);\n    switch ( M ) {\n        case 0:\n            /* IEEE little endian */\n            mat->byteswap = endian.c[0] != 4;\n            break;\n        case 1:\n            /* IEEE big endian */\n            mat->byteswap = endian.c[0] != 1;\n            break;\n        default:\n            /* VAX, Cray, or bogus */\n            Mat_VarFree(matvar);\n            return NULL;\n    }\n\n    tmp -= M*1000;\n    O = (int)floor(tmp / 100.0);\n    /* O must be zero */\n    if ( 0 != O ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n\n    tmp -= O*100;\n    data_type = (int)floor(tmp / 10.0);\n    /* Convert the V4 data type */\n    switch ( data_type ) {\n        case 0:\n            matvar->data_type = MAT_T_DOUBLE;\n            break;\n        case 1:\n            matvar->data_type = MAT_T_SINGLE;\n            break;\n        case 2:\n            matvar->data_type = MAT_T_INT32;\n            break;\n        case 3:\n            matvar->data_type = MAT_T_INT16;\n            break;\n        case 4:\n            matvar->data_type = MAT_T_UINT16;\n            break;\n        case 5:\n            matvar->data_type = MAT_T_UINT8;\n            break;\n        default:\n            Mat_VarFree(matvar);\n            return NULL;\n    }\n\n    tmp -= data_type*10;\n    class_type = (int)floor(tmp / 1.0);\n    switch ( class_type ) {\n        case 0:\n            matvar->class_type = MAT_C_DOUBLE;\n            break;\n        case 1:\n            matvar->class_type = MAT_C_CHAR;\n            break;\n        case 2:\n            matvar->class_type = MAT_C_SPARSE;\n            break;\n        default:\n            Mat_VarFree(matvar);\n            return NULL;\n    }\n\n    matvar->rank = 2;\n    matvar->dims = (size_t*)calloc(2, sizeof(*matvar->dims));\n    if ( NULL == matvar->dims ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n    readresult = fread(&tmp,sizeof(int),1,(FILE*)mat->fp);\n    if ( mat->byteswap )\n        Mat_int32Swap(&tmp);\n    matvar->dims[0] = tmp;\n    if ( 1 != readresult ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n    readresult = fread(&tmp,sizeof(int),1,(FILE*)mat->fp);\n    if ( mat->byteswap )\n        Mat_int32Swap(&tmp);\n    matvar->dims[1] = tmp;\n    if ( 1 != readresult ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n\n    readresult = fread(&(matvar->isComplex),sizeof(int),1,(FILE*)mat->fp);\n    if ( 1 != readresult ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n    if ( matvar->isComplex && MAT_C_CHAR == matvar->class_type ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n    readresult = fread(&tmp,sizeof(int),1,(FILE*)mat->fp);\n    if ( 1 != readresult ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n    if ( mat->byteswap )\n        Mat_int32Swap(&tmp);\n    /* Check that the length of the variable name is at least 1 */\n    if ( tmp < 1 ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n    matvar->name = (char*)malloc(tmp);\n    if ( NULL == matvar->name ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n    readresult = fread(matvar->name,1,tmp,(FILE*)mat->fp);\n    if ( tmp != readresult ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    } else {\n        matvar->name[tmp - 1] = '\\0';\n    }\n\n    matvar->internal->datapos = ftell((FILE*)mat->fp);\n    if ( matvar->internal->datapos == -1L ) {\n        Mat_VarFree(matvar);\n        Mat_Critical(\"Couldn't determine file position\");\n        return NULL;\n    }\n    {\n        int err;\n        size_t tmp2 = Mat_SizeOf(matvar->data_type);\n        if ( matvar->isComplex )\n            tmp2 *= 2;\n        err = SafeMulDims(matvar, &tmp2);\n        if ( err ) {\n            Mat_VarFree(matvar);\n            Mat_Critical(\"Integer multiplication overflow\");\n            return NULL;\n        }\n\n        nBytes = (long)tmp2;\n    }\n    (void)fseek((FILE*)mat->fp,nBytes,SEEK_CUR);\n\n    return matvar;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -153,6 +153,8 @@\n     if ( tmp != readresult ) {\n         Mat_VarFree(matvar);\n         return NULL;\n+    } else {\n+        matvar->name[tmp - 1] = '\\0';\n     }\n \n     matvar->internal->datapos = ftell((FILE*)mat->fp);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    } else {",
                "        matvar->name[tmp - 1] = '\\0';"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-15900",
        "func_name": "slicer69/doas/parsegid",
        "description": "An issue was discovered in slicer69 doas before 6.2 on certain platforms other than OpenBSD. On platforms without strtonum(3), sscanf was used without checking for error cases. Instead, the uninitialized variable errstr was checked and in some cases returned success even if sscanf failed. The result was that, instead of reporting that the supplied username or group name did not exist, it would execute the command as root.",
        "git_url": "https://github.com/slicer69/doas/commit/2f83222829448e5bc4c9391d607ec265a1e06531",
        "commit_title": "Added optimization to Makefile (can be set/overruled using OPT).",
        "commit_text": "Added flag to display all warnings during compiling. Added status checks when parsing user/group IDs for Linux. Make sure Linux drops original user's groups when running as another user.",
        "func_before": "static int\nparsegid(const char *s, gid_t *gid)\n{\n\tstruct group *gr;\n\tconst char *errstr;\n\n\tif ((gr = getgrnam(s)) != NULL) {\n\t\t*gid = gr->gr_gid;\n\t\treturn 0;\n\t}\n\t#if !defined(__linux__) && !defined(__NetBSD__)\n\t*gid = strtonum(s, 0, GID_MAX, &errstr);\n\t#else\n\tsscanf(s, \"%d\", gid);\n\t#endif\n\tif (errstr)\n\t\treturn -1;\n\treturn 0;\n}",
        "func": "static int\nparsegid(const char *s, gid_t *gid)\n{\n\tstruct group *gr;\n\t#if !defined(__linux__) && !defined(__NetBSD__)\n\tconst char *errstr = NULL;\n        #else\n        int status;\n        #endif\n\n\tif ((gr = getgrnam(s)) != NULL) {\n\t\t*gid = gr->gr_gid;\n\t\treturn 0;\n\t}\n\t#if !defined(__linux__) && !defined(__NetBSD__)\n\t*gid = strtonum(s, 0, GID_MAX, &errstr);\n\tif (errstr)\n\t\treturn -1;\n\t#else\n\tstatus = sscanf(s, \"%d\", gid);\n        if (status != 1)\n            return -1;\n\t#endif\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,7 +2,11 @@\n parsegid(const char *s, gid_t *gid)\n {\n \tstruct group *gr;\n-\tconst char *errstr;\n+\t#if !defined(__linux__) && !defined(__NetBSD__)\n+\tconst char *errstr = NULL;\n+        #else\n+        int status;\n+        #endif\n \n \tif ((gr = getgrnam(s)) != NULL) {\n \t\t*gid = gr->gr_gid;\n@@ -10,10 +14,12 @@\n \t}\n \t#if !defined(__linux__) && !defined(__NetBSD__)\n \t*gid = strtonum(s, 0, GID_MAX, &errstr);\n-\t#else\n-\tsscanf(s, \"%d\", gid);\n-\t#endif\n \tif (errstr)\n \t\treturn -1;\n+\t#else\n+\tstatus = sscanf(s, \"%d\", gid);\n+        if (status != 1)\n+            return -1;\n+\t#endif\n \treturn 0;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tconst char *errstr;",
                "\t#else",
                "\tsscanf(s, \"%d\", gid);",
                "\t#endif"
            ],
            "added_lines": [
                "\t#if !defined(__linux__) && !defined(__NetBSD__)",
                "\tconst char *errstr = NULL;",
                "        #else",
                "        int status;",
                "        #endif",
                "\t#else",
                "\tstatus = sscanf(s, \"%d\", gid);",
                "        if (status != 1)",
                "            return -1;",
                "\t#endif"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-15900",
        "func_name": "slicer69/doas/parseuid",
        "description": "An issue was discovered in slicer69 doas before 6.2 on certain platforms other than OpenBSD. On platforms without strtonum(3), sscanf was used without checking for error cases. Instead, the uninitialized variable errstr was checked and in some cases returned success even if sscanf failed. The result was that, instead of reporting that the supplied username or group name did not exist, it would execute the command as root.",
        "git_url": "https://github.com/slicer69/doas/commit/2f83222829448e5bc4c9391d607ec265a1e06531",
        "commit_title": "Added optimization to Makefile (can be set/overruled using OPT).",
        "commit_text": "Added flag to display all warnings during compiling. Added status checks when parsing user/group IDs for Linux. Make sure Linux drops original user's groups when running as another user.",
        "func_before": "static int\nparseuid(const char *s, uid_t *uid)\n{\n\tstruct passwd *pw;\n\tconst char *errstr;\n\n\tif ((pw = getpwnam(s)) != NULL) {\n\t\t*uid = pw->pw_uid;\n\t\treturn 0;\n\t}\n\t#if !defined(__linux__) && !defined(__NetBSD__)\n\t*uid = strtonum(s, 0, UID_MAX, &errstr);\n\t#else\n\tsscanf(s, \"%d\", uid);\n\t#endif\n\tif (errstr)\n\t\treturn -1;\n\treturn 0;\n}",
        "func": "static int\nparseuid(const char *s, uid_t *uid)\n{\n\tstruct passwd *pw;\n\t#if !defined(__linux__) && !defined(__NetBSD__)\n\tconst char *errstr = NULL;\n        #else\n        int status;\n        #endif\n\n\tif ((pw = getpwnam(s)) != NULL) {\n\t\t*uid = pw->pw_uid;\n\t\treturn 0;\n\t}\n\t#if !defined(__linux__) && !defined(__NetBSD__)\n\t*uid = strtonum(s, 0, UID_MAX, &errstr);\n\tif (errstr)\n\t\treturn -1;\n\t#else\n\tstatus = sscanf(s, \"%d\", uid);\n        if (status != 1)\n           return -1;\n\t#endif\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,7 +2,11 @@\n parseuid(const char *s, uid_t *uid)\n {\n \tstruct passwd *pw;\n-\tconst char *errstr;\n+\t#if !defined(__linux__) && !defined(__NetBSD__)\n+\tconst char *errstr = NULL;\n+        #else\n+        int status;\n+        #endif\n \n \tif ((pw = getpwnam(s)) != NULL) {\n \t\t*uid = pw->pw_uid;\n@@ -10,10 +14,12 @@\n \t}\n \t#if !defined(__linux__) && !defined(__NetBSD__)\n \t*uid = strtonum(s, 0, UID_MAX, &errstr);\n-\t#else\n-\tsscanf(s, \"%d\", uid);\n-\t#endif\n \tif (errstr)\n \t\treturn -1;\n+\t#else\n+\tstatus = sscanf(s, \"%d\", uid);\n+        if (status != 1)\n+           return -1;\n+\t#endif\n \treturn 0;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tconst char *errstr;",
                "\t#else",
                "\tsscanf(s, \"%d\", uid);",
                "\t#endif"
            ],
            "added_lines": [
                "\t#if !defined(__linux__) && !defined(__NetBSD__)",
                "\tconst char *errstr = NULL;",
                "        #else",
                "        int status;",
                "        #endif",
                "\t#else",
                "\tstatus = sscanf(s, \"%d\", uid);",
                "        if (status != 1)",
                "           return -1;",
                "\t#endif"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-18197",
        "func_name": "GNOME/libxslt/xsltCopyText",
        "description": "In xsltCopyText in transform.c in libxslt 1.1.33, a pointer variable isn't reset under certain circumstances. If the relevant memory area happened to be freed and reused in a certain way, a bounds check could fail and memory outside a buffer could be written to, or uninitialized data could be disclosed.",
        "git_url": "https://github.com/GNOME/libxslt/commit/2232473733b7313d67de8836ea3b29eec6e8e285",
        "commit_title": "Fix dangling pointer in xsltCopyText",
        "commit_text": " xsltCopyText didn't reset ctxt->lasttext in some cases which could lead to various memory errors in relation with CDATA sections in input documents.  Found by OSS-Fuzz.",
        "func_before": "static xmlNodePtr\nxsltCopyText(xsltTransformContextPtr ctxt, xmlNodePtr target,\n\t     xmlNodePtr cur, int interned)\n{\n    xmlNodePtr copy;\n\n    if ((cur->type != XML_TEXT_NODE) &&\n\t(cur->type != XML_CDATA_SECTION_NODE))\n\treturn(NULL);\n    if (cur->content == NULL)\n\treturn(NULL);\n\n#ifdef WITH_XSLT_DEBUG_PROCESS\n    if (cur->type == XML_CDATA_SECTION_NODE) {\n\tXSLT_TRACE(ctxt,XSLT_TRACE_COPY_TEXT,xsltGenericDebug(xsltGenericDebugContext,\n\t\t\t \"xsltCopyText: copy CDATA text %s\\n\",\n\t\t\t cur->content));\n    } else if (cur->name == xmlStringTextNoenc) {\n\tXSLT_TRACE(ctxt,XSLT_TRACE_COPY_TEXT,xsltGenericDebug(xsltGenericDebugContext,\n\t\t     \"xsltCopyText: copy unescaped text %s\\n\",\n\t\t\t cur->content));\n    } else {\n\tXSLT_TRACE(ctxt,XSLT_TRACE_COPY_TEXT,xsltGenericDebug(xsltGenericDebugContext,\n\t\t\t \"xsltCopyText: copy text %s\\n\",\n\t\t\t cur->content));\n    }\n#endif\n\n    /*\n    * Play save and reset the merging mechanism for every new\n    * target node.\n    */\n    if ((target == NULL) || (target->children == NULL)) {\n\tctxt->lasttext = NULL;\n    }\n\n    if ((ctxt->style->cdataSection != NULL) &&\n\t(ctxt->type == XSLT_OUTPUT_XML) &&\n\t(target != NULL) &&\n\t(target->type == XML_ELEMENT_NODE) &&\n\t(((target->ns == NULL) &&\n\t  (xmlHashLookup2(ctxt->style->cdataSection,\n\t\t          target->name, NULL) != NULL)) ||\n\t ((target->ns != NULL) &&\n\t  (xmlHashLookup2(ctxt->style->cdataSection,\n\t                  target->name, target->ns->href) != NULL))))\n    {\n\t/*\n\t* Process \"cdata-section-elements\".\n\t*/\n\t/*\n\t* OPTIMIZE TODO: xsltCopyText() is also used for attribute content.\n\t*/\n\t/*\n\t* TODO: Since this doesn't merge adjacent CDATA-section nodes,\n\t* we'll get: <![CDATA[x]]><!CDATA[y]]>.\n\t* TODO: Reported in #321505.\n\t*/\n\tif ((target->last != NULL) &&\n\t     (target->last->type == XML_CDATA_SECTION_NODE))\n\t{\n\t    /*\n\t    * Append to existing CDATA-section node.\n\t    */\n\t    copy = xsltAddTextString(ctxt, target->last, cur->content,\n\t\txmlStrlen(cur->content));\n\t    goto exit;\n\t} else {\n\t    unsigned int len;\n\n\t    len = xmlStrlen(cur->content);\n\t    copy = xmlNewCDataBlock(ctxt->output, cur->content, len);\n\t    if (copy == NULL)\n\t\tgoto exit;\n\t    ctxt->lasttext = copy->content;\n\t    ctxt->lasttsize = len;\n\t    ctxt->lasttuse = len;\n\t}\n    } else if ((target != NULL) &&\n\t(target->last != NULL) &&\n\t/* both escaped or both non-escaped text-nodes */\n\t(((target->last->type == XML_TEXT_NODE) &&\n\t(target->last->name == cur->name)) ||\n        /* non-escaped text nodes and CDATA-section nodes */\n\t(((target->last->type == XML_CDATA_SECTION_NODE) &&\n\t(cur->name == xmlStringTextNoenc)))))\n    {\n\t/*\n\t * we are appending to an existing text node\n\t */\n\tcopy = xsltAddTextString(ctxt, target->last, cur->content,\n\t    xmlStrlen(cur->content));\n\tgoto exit;\n    } else if ((interned) && (target != NULL) &&\n\t(target->doc != NULL) &&\n\t(target->doc->dict == ctxt->dict))\n    {\n\t/*\n\t* TODO: DO we want to use this also for \"text\" output?\n\t*/\n        copy = xmlNewTextLen(NULL, 0);\n\tif (copy == NULL)\n\t    goto exit;\n\tif (cur->name == xmlStringTextNoenc)\n\t    copy->name = xmlStringTextNoenc;\n\n\t/*\n\t * Must confirm that content is in dict (bug 302821)\n\t * TODO: This check should be not needed for text coming\n\t * from the stylesheets\n\t */\n\tif (xmlDictOwns(ctxt->dict, cur->content))\n\t    copy->content = cur->content;\n\telse {\n\t    if ((copy->content = xmlStrdup(cur->content)) == NULL)\n\t\treturn NULL;\n\t}\n    } else {\n        /*\n\t * normal processing. keep counters to extend the text node\n\t * in xsltAddTextString if needed.\n\t */\n        unsigned int len;\n\n\tlen = xmlStrlen(cur->content);\n\tcopy = xmlNewTextLen(cur->content, len);\n\tif (copy == NULL)\n\t    goto exit;\n\tif (cur->name == xmlStringTextNoenc)\n\t    copy->name = xmlStringTextNoenc;\n\tctxt->lasttext = copy->content;\n\tctxt->lasttsize = len;\n\tctxt->lasttuse = len;\n    }\n    if (copy != NULL) {\n\tif (target != NULL) {\n\t    copy->doc = target->doc;\n\t    /*\n\t    * MAYBE TODO: Maybe we should reset the ctxt->lasttext here\n\t    *  to ensure that the optimized text-merging mechanism\n\t    *  won't interfere with normal node-merging in any case.\n\t    */\n\t    copy = xsltAddChild(target, copy);\n\t}\n    } else {\n\txsltTransformError(ctxt, NULL, target,\n\t\t\t \"xsltCopyText: text copy failed\\n\");\n    }\n\nexit:\n    if ((copy == NULL) || (copy->content == NULL)) {\n\txsltTransformError(ctxt, NULL, target,\n\t    \"Internal error in xsltCopyText(): \"\n\t    \"Failed to copy the string.\\n\");\n\tctxt->state = XSLT_STATE_STOPPED;\n    }\n    return(copy);\n}",
        "func": "static xmlNodePtr\nxsltCopyText(xsltTransformContextPtr ctxt, xmlNodePtr target,\n\t     xmlNodePtr cur, int interned)\n{\n    xmlNodePtr copy;\n\n    if ((cur->type != XML_TEXT_NODE) &&\n\t(cur->type != XML_CDATA_SECTION_NODE))\n\treturn(NULL);\n    if (cur->content == NULL)\n\treturn(NULL);\n\n#ifdef WITH_XSLT_DEBUG_PROCESS\n    if (cur->type == XML_CDATA_SECTION_NODE) {\n\tXSLT_TRACE(ctxt,XSLT_TRACE_COPY_TEXT,xsltGenericDebug(xsltGenericDebugContext,\n\t\t\t \"xsltCopyText: copy CDATA text %s\\n\",\n\t\t\t cur->content));\n    } else if (cur->name == xmlStringTextNoenc) {\n\tXSLT_TRACE(ctxt,XSLT_TRACE_COPY_TEXT,xsltGenericDebug(xsltGenericDebugContext,\n\t\t     \"xsltCopyText: copy unescaped text %s\\n\",\n\t\t\t cur->content));\n    } else {\n\tXSLT_TRACE(ctxt,XSLT_TRACE_COPY_TEXT,xsltGenericDebug(xsltGenericDebugContext,\n\t\t\t \"xsltCopyText: copy text %s\\n\",\n\t\t\t cur->content));\n    }\n#endif\n\n    /*\n    * Play save and reset the merging mechanism for every new\n    * target node.\n    */\n    if ((target == NULL) || (target->children == NULL)) {\n\tctxt->lasttext = NULL;\n    }\n\n    if ((ctxt->style->cdataSection != NULL) &&\n\t(ctxt->type == XSLT_OUTPUT_XML) &&\n\t(target != NULL) &&\n\t(target->type == XML_ELEMENT_NODE) &&\n\t(((target->ns == NULL) &&\n\t  (xmlHashLookup2(ctxt->style->cdataSection,\n\t\t          target->name, NULL) != NULL)) ||\n\t ((target->ns != NULL) &&\n\t  (xmlHashLookup2(ctxt->style->cdataSection,\n\t                  target->name, target->ns->href) != NULL))))\n    {\n\t/*\n\t* Process \"cdata-section-elements\".\n\t*/\n\t/*\n\t* OPTIMIZE TODO: xsltCopyText() is also used for attribute content.\n\t*/\n\t/*\n\t* TODO: Since this doesn't merge adjacent CDATA-section nodes,\n\t* we'll get: <![CDATA[x]]><!CDATA[y]]>.\n\t* TODO: Reported in #321505.\n\t*/\n\tif ((target->last != NULL) &&\n\t     (target->last->type == XML_CDATA_SECTION_NODE))\n\t{\n\t    /*\n\t    * Append to existing CDATA-section node.\n\t    */\n\t    copy = xsltAddTextString(ctxt, target->last, cur->content,\n\t\txmlStrlen(cur->content));\n\t    goto exit;\n\t} else {\n\t    unsigned int len;\n\n\t    len = xmlStrlen(cur->content);\n\t    copy = xmlNewCDataBlock(ctxt->output, cur->content, len);\n\t    if (copy == NULL)\n\t\tgoto exit;\n\t    ctxt->lasttext = copy->content;\n\t    ctxt->lasttsize = len;\n\t    ctxt->lasttuse = len;\n\t}\n    } else if ((target != NULL) &&\n\t(target->last != NULL) &&\n\t/* both escaped or both non-escaped text-nodes */\n\t(((target->last->type == XML_TEXT_NODE) &&\n\t(target->last->name == cur->name)) ||\n        /* non-escaped text nodes and CDATA-section nodes */\n\t(((target->last->type == XML_CDATA_SECTION_NODE) &&\n\t(cur->name == xmlStringTextNoenc)))))\n    {\n\t/*\n\t * we are appending to an existing text node\n\t */\n\tcopy = xsltAddTextString(ctxt, target->last, cur->content,\n\t    xmlStrlen(cur->content));\n\tgoto exit;\n    } else if ((interned) && (target != NULL) &&\n\t(target->doc != NULL) &&\n\t(target->doc->dict == ctxt->dict))\n    {\n\t/*\n\t* TODO: DO we want to use this also for \"text\" output?\n\t*/\n        copy = xmlNewTextLen(NULL, 0);\n\tif (copy == NULL)\n\t    goto exit;\n\tif (cur->name == xmlStringTextNoenc)\n\t    copy->name = xmlStringTextNoenc;\n\n\t/*\n\t * Must confirm that content is in dict (bug 302821)\n\t * TODO: This check should be not needed for text coming\n\t * from the stylesheets\n\t */\n\tif (xmlDictOwns(ctxt->dict, cur->content))\n\t    copy->content = cur->content;\n\telse {\n\t    if ((copy->content = xmlStrdup(cur->content)) == NULL)\n\t\treturn NULL;\n\t}\n\n\tctxt->lasttext = NULL;\n    } else {\n        /*\n\t * normal processing. keep counters to extend the text node\n\t * in xsltAddTextString if needed.\n\t */\n        unsigned int len;\n\n\tlen = xmlStrlen(cur->content);\n\tcopy = xmlNewTextLen(cur->content, len);\n\tif (copy == NULL)\n\t    goto exit;\n\tif (cur->name == xmlStringTextNoenc)\n\t    copy->name = xmlStringTextNoenc;\n\tctxt->lasttext = copy->content;\n\tctxt->lasttsize = len;\n\tctxt->lasttuse = len;\n    }\n    if (copy != NULL) {\n\tif (target != NULL) {\n\t    copy->doc = target->doc;\n\t    /*\n\t    * MAYBE TODO: Maybe we should reset the ctxt->lasttext here\n\t    *  to ensure that the optimized text-merging mechanism\n\t    *  won't interfere with normal node-merging in any case.\n\t    */\n\t    copy = xsltAddChild(target, copy);\n\t}\n    } else {\n\txsltTransformError(ctxt, NULL, target,\n\t\t\t \"xsltCopyText: text copy failed\\n\");\n    }\n\nexit:\n    if ((copy == NULL) || (copy->content == NULL)) {\n\txsltTransformError(ctxt, NULL, target,\n\t    \"Internal error in xsltCopyText(): \"\n\t    \"Failed to copy the string.\\n\");\n\tctxt->state = XSLT_STATE_STOPPED;\n    }\n    return(copy);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -115,6 +115,8 @@\n \t    if ((copy->content = xmlStrdup(cur->content)) == NULL)\n \t\treturn NULL;\n \t}\n+\n+\tctxt->lasttext = NULL;\n     } else {\n         /*\n \t * normal processing. keep counters to extend the text node",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "\tctxt->lasttext = NULL;"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-43848",
        "func_name": "h2o/handle_input_expect_headers",
        "description": "h2o is an open source http server. In code prior to the `8c0eca3` commit h2o may attempt to access uninitialized memory. When receiving QUIC frames in certain order, HTTP/3 server-side implementation of h2o can be misguided to treat uninitialized memory as HTTP/3 frames that have been received. When h2o is used as a reverse proxy, an attacker can abuse this vulnerability to send internal state of h2o to backend servers controlled by the attacker or third party. Also, if there is an HTTP endpoint that reflects the traffic sent from the client, an attacker can use that reflector to obtain internal state of h2o. This internal state includes traffic of other connections in unencrypted form and TLS session tickets. This vulnerability exists in h2o server with HTTP/3 support, between commit 93af138 and d1f0f65. None of the released versions of h2o are affected by this vulnerability. There are no known workarounds. Users of unreleased versions of h2o using HTTP/3 are advised to upgrade immediately.",
        "git_url": "https://github.com/h2o/h2o/commit/8c0eca3d9bc1f08e7c6bdf57645f3d54aed7d844",
        "commit_title": "postpone stream shutdown by H3 frame parsers",
        "commit_text": "",
        "func_before": "static int handle_input_expect_headers(struct st_h2o_http3_server_stream_t *stream, const uint8_t **src, const uint8_t *src_end,\n                                       const char **err_desc)\n{\n    struct st_h2o_http3_server_conn_t *conn = get_conn(stream);\n    h2o_http3_read_frame_t frame;\n    int header_exists_map = 0, ret;\n    uint8_t header_ack[H2O_HPACK_ENCODE_INT_MAX_LENGTH];\n    size_t header_ack_len;\n\n    /* read the HEADERS frame (or a frame that precedes that) */\n    if ((ret = h2o_http3_read_frame(&frame, 0, H2O_HTTP3_STREAM_TYPE_REQUEST, src, src_end, err_desc)) != 0)\n        return ret;\n    if (frame.type != H2O_HTTP3_FRAME_TYPE_HEADERS) {\n        switch (frame.type) {\n        case H2O_HTTP3_FRAME_TYPE_DATA:\n            return H2O_HTTP3_ERROR_FRAME_UNEXPECTED;\n        default:\n            break;\n        }\n        return 0;\n    }\n    stream->recvbuf.handle_input = handle_input_expect_data;\n\n    /* parse the headers, and ack */\n    if ((ret = h2o_qpack_parse_request(&stream->req.pool, get_conn(stream)->h3.qpack.dec, stream->quic->stream_id,\n                                       &stream->req.input.method, &stream->req.input.scheme, &stream->req.input.authority,\n                                       &stream->req.input.path, &stream->req.headers, &header_exists_map,\n                                       &stream->req.content_length, NULL /* TODO cache-digests */, header_ack, &header_ack_len,\n                                       frame.payload, frame.length, err_desc)) != 0 &&\n        ret != H2O_HTTP2_ERROR_INVALID_HEADER_CHAR)\n        return ret;\n    if (header_ack_len != 0)\n        h2o_http3_send_qpack_header_ack(&conn->h3, header_ack, header_ack_len);\n\n    if (stream->req.input.scheme == NULL)\n        stream->req.input.scheme = &H2O_URL_SCHEME_HTTPS;\n\n    h2o_probe_log_request(&stream->req, stream->quic->stream_id);\n\n    int is_connect = h2o_memis(stream->req.input.method.base, stream->req.input.method.len, H2O_STRLIT(\"CONNECT\"));\n\n    /* check if existence and non-existence of pseudo headers are correct */\n    int expected_map = H2O_HPACK_PARSE_HEADERS_METHOD_EXISTS | H2O_HPACK_PARSE_HEADERS_AUTHORITY_EXISTS;\n    if (!is_connect)\n        expected_map |= H2O_HPACK_PARSE_HEADERS_SCHEME_EXISTS | H2O_HPACK_PARSE_HEADERS_PATH_EXISTS;\n    if (header_exists_map != expected_map) {\n        shutdown_stream(stream, H2O_HTTP3_ERROR_GENERAL_PROTOCOL, H2O_HTTP3_ERROR_GENERAL_PROTOCOL, 0);\n        return 0;\n    }\n\n    /* send a 400 error when observing an invalid header character */\n    if (ret == H2O_HTTP2_ERROR_INVALID_HEADER_CHAR)\n        return handle_input_expect_headers_send_http_error(stream, h2o_send_error_400, \"Invalid Request\", *err_desc, err_desc);\n\n    /* check if content-length is within the permitted bounds */\n    if (stream->req.content_length != SIZE_MAX && stream->req.content_length > conn->super.ctx->globalconf->max_request_entity_size)\n        return handle_input_expect_headers_send_http_error(stream, h2o_send_error_413, \"Request Entity Too Large\",\n                                                           \"request entity is too large\", err_desc);\n\n    /* set priority */\n    assert(!h2o_linklist_is_linked(&stream->scheduler.link));\n    if (!stream->received_priority_update) {\n        ssize_t index;\n        if ((index = h2o_find_header(&stream->req.headers, H2O_TOKEN_PRIORITY, -1)) != -1) {\n            h2o_iovec_t *value = &stream->req.headers.entries[index].value;\n            h2o_absprio_parse_priority(value->base, value->len, &stream->scheduler.priority);\n        }\n    }\n\n    /* special handling of CONNECT method */\n    if (is_connect) {\n        if (stream->req.content_length != SIZE_MAX)\n            return handle_input_expect_headers_send_http_error(stream, h2o_send_error_400, \"Invalid Request\",\n                                                               \"CONNECT request cannot have request body\", err_desc);\n        set_state(stream, H2O_HTTP3_SERVER_STREAM_STATE_SEND_HEADERS, 0);\n        stream->tunnel = h2o_mem_alloc(sizeof(*stream->tunnel));\n        stream->tunnel->tunnel = NULL;\n        stream->tunnel->stream = stream;\n        stream->tunnel->up.is_inflight = 0;\n        stream->tunnel->up.delayed_write = (h2o_timer_t){.cb = tunnel_write_delayed};\n        h2o_process_request(&stream->req);\n        return 0;\n    }\n\n    /* change state */\n    set_state(stream, H2O_HTTP3_SERVER_STREAM_STATE_RECV_BODY_BEFORE_BLOCK, 0);\n\n    return 0;\n}",
        "func": "static int handle_input_expect_headers(struct st_h2o_http3_server_stream_t *stream, const uint8_t **src, const uint8_t *src_end,\n                                       int in_generator, const char **err_desc)\n{\n    assert(!in_generator); /* this function is processing headers (before generators get assigned), not trailers */\n\n    struct st_h2o_http3_server_conn_t *conn = get_conn(stream);\n    h2o_http3_read_frame_t frame;\n    int header_exists_map = 0, ret;\n    uint8_t header_ack[H2O_HPACK_ENCODE_INT_MAX_LENGTH];\n    size_t header_ack_len;\n\n    /* read the HEADERS frame (or a frame that precedes that) */\n    if ((ret = h2o_http3_read_frame(&frame, 0, H2O_HTTP3_STREAM_TYPE_REQUEST, src, src_end, err_desc)) != 0)\n        return ret;\n    if (frame.type != H2O_HTTP3_FRAME_TYPE_HEADERS) {\n        switch (frame.type) {\n        case H2O_HTTP3_FRAME_TYPE_DATA:\n            return H2O_HTTP3_ERROR_FRAME_UNEXPECTED;\n        default:\n            break;\n        }\n        return 0;\n    }\n    stream->recvbuf.handle_input = handle_input_expect_data;\n\n    /* parse the headers, and ack */\n    if ((ret = h2o_qpack_parse_request(&stream->req.pool, get_conn(stream)->h3.qpack.dec, stream->quic->stream_id,\n                                       &stream->req.input.method, &stream->req.input.scheme, &stream->req.input.authority,\n                                       &stream->req.input.path, &stream->req.headers, &header_exists_map,\n                                       &stream->req.content_length, NULL /* TODO cache-digests */, header_ack, &header_ack_len,\n                                       frame.payload, frame.length, err_desc)) != 0 &&\n        ret != H2O_HTTP2_ERROR_INVALID_HEADER_CHAR)\n        return ret;\n    if (header_ack_len != 0)\n        h2o_http3_send_qpack_header_ack(&conn->h3, header_ack, header_ack_len);\n\n    if (stream->req.input.scheme == NULL)\n        stream->req.input.scheme = &H2O_URL_SCHEME_HTTPS;\n\n    h2o_probe_log_request(&stream->req, stream->quic->stream_id);\n\n    int is_connect = h2o_memis(stream->req.input.method.base, stream->req.input.method.len, H2O_STRLIT(\"CONNECT\"));\n\n    /* check if existence and non-existence of pseudo headers are correct */\n    int expected_map = H2O_HPACK_PARSE_HEADERS_METHOD_EXISTS | H2O_HPACK_PARSE_HEADERS_AUTHORITY_EXISTS;\n    if (!is_connect)\n        expected_map |= H2O_HPACK_PARSE_HEADERS_SCHEME_EXISTS | H2O_HPACK_PARSE_HEADERS_PATH_EXISTS;\n    if (header_exists_map != expected_map) {\n        shutdown_stream(stream, H2O_HTTP3_ERROR_GENERAL_PROTOCOL, H2O_HTTP3_ERROR_GENERAL_PROTOCOL, 0);\n        return 0;\n    }\n\n    /* send a 400 error when observing an invalid header character */\n    if (ret == H2O_HTTP2_ERROR_INVALID_HEADER_CHAR)\n        return handle_input_expect_headers_send_http_error(stream, h2o_send_error_400, \"Invalid Request\", *err_desc, err_desc);\n\n    /* check if content-length is within the permitted bounds */\n    if (stream->req.content_length != SIZE_MAX && stream->req.content_length > conn->super.ctx->globalconf->max_request_entity_size)\n        return handle_input_expect_headers_send_http_error(stream, h2o_send_error_413, \"Request Entity Too Large\",\n                                                           \"request entity is too large\", err_desc);\n\n    /* set priority */\n    assert(!h2o_linklist_is_linked(&stream->scheduler.link));\n    if (!stream->received_priority_update) {\n        ssize_t index;\n        if ((index = h2o_find_header(&stream->req.headers, H2O_TOKEN_PRIORITY, -1)) != -1) {\n            h2o_iovec_t *value = &stream->req.headers.entries[index].value;\n            h2o_absprio_parse_priority(value->base, value->len, &stream->scheduler.priority);\n        }\n    }\n\n    /* special handling of CONNECT method */\n    if (is_connect) {\n        if (stream->req.content_length != SIZE_MAX)\n            return handle_input_expect_headers_send_http_error(stream, h2o_send_error_400, \"Invalid Request\",\n                                                               \"CONNECT request cannot have request body\", err_desc);\n        set_state(stream, H2O_HTTP3_SERVER_STREAM_STATE_SEND_HEADERS, 0);\n        stream->tunnel = h2o_mem_alloc(sizeof(*stream->tunnel));\n        stream->tunnel->tunnel = NULL;\n        stream->tunnel->stream = stream;\n        stream->tunnel->up.is_inflight = 0;\n        stream->tunnel->up.delayed_write = (h2o_timer_t){.cb = tunnel_write_delayed};\n        h2o_process_request(&stream->req);\n        return 0;\n    }\n\n    /* change state */\n    set_state(stream, H2O_HTTP3_SERVER_STREAM_STATE_RECV_BODY_BEFORE_BLOCK, 0);\n\n    return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,8 @@\n static int handle_input_expect_headers(struct st_h2o_http3_server_stream_t *stream, const uint8_t **src, const uint8_t *src_end,\n-                                       const char **err_desc)\n+                                       int in_generator, const char **err_desc)\n {\n+    assert(!in_generator); /* this function is processing headers (before generators get assigned), not trailers */\n+\n     struct st_h2o_http3_server_conn_t *conn = get_conn(stream);\n     h2o_http3_read_frame_t frame;\n     int header_exists_map = 0, ret;",
        "diff_line_info": {
            "deleted_lines": [
                "                                       const char **err_desc)"
            ],
            "added_lines": [
                "                                       int in_generator, const char **err_desc)",
                "    assert(!in_generator); /* this function is processing headers (before generators get assigned), not trailers */",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2021-43848",
        "func_name": "h2o/handle_input_expect_data_payload",
        "description": "h2o is an open source http server. In code prior to the `8c0eca3` commit h2o may attempt to access uninitialized memory. When receiving QUIC frames in certain order, HTTP/3 server-side implementation of h2o can be misguided to treat uninitialized memory as HTTP/3 frames that have been received. When h2o is used as a reverse proxy, an attacker can abuse this vulnerability to send internal state of h2o to backend servers controlled by the attacker or third party. Also, if there is an HTTP endpoint that reflects the traffic sent from the client, an attacker can use that reflector to obtain internal state of h2o. This internal state includes traffic of other connections in unencrypted form and TLS session tickets. This vulnerability exists in h2o server with HTTP/3 support, between commit 93af138 and d1f0f65. None of the released versions of h2o are affected by this vulnerability. There are no known workarounds. Users of unreleased versions of h2o using HTTP/3 are advised to upgrade immediately.",
        "git_url": "https://github.com/h2o/h2o/commit/8c0eca3d9bc1f08e7c6bdf57645f3d54aed7d844",
        "commit_title": "postpone stream shutdown by H3 frame parsers",
        "commit_text": "",
        "func_before": "static int handle_input_expect_data_payload(struct st_h2o_http3_server_stream_t *stream, const uint8_t **src,\n                                            const uint8_t *src_end, const char **err_desc)\n{\n    size_t bytes_avail = src_end - *src;\n\n    /* append data to body buffer */\n    if (bytes_avail > stream->recvbuf.bytes_left_in_data_frame)\n        bytes_avail = stream->recvbuf.bytes_left_in_data_frame;\n    if (stream->req_body == NULL)\n        h2o_buffer_init(&stream->req_body, &h2o_socket_buffer_prototype);\n    if (!h2o_buffer_try_append(&stream->req_body, *src, bytes_avail))\n        return H2O_HTTP3_ERROR_INTERNAL;\n    stream->req.entity = h2o_iovec_init(stream->req_body->bytes, stream->req_body->size);\n    stream->req.req_body_bytes_received += bytes_avail;\n    stream->recvbuf.bytes_left_in_data_frame -= bytes_avail;\n    *src += bytes_avail;\n\n    if (stream->recvbuf.bytes_left_in_data_frame == 0)\n        stream->recvbuf.handle_input = handle_input_expect_data;\n\n    return 0;\n}",
        "func": "static int handle_input_expect_data_payload(struct st_h2o_http3_server_stream_t *stream, const uint8_t **src,\n                                            const uint8_t *src_end, int in_generator, const char **err_desc)\n{\n    size_t bytes_avail = src_end - *src;\n\n    /* append data to body buffer */\n    if (bytes_avail > stream->recvbuf.bytes_left_in_data_frame)\n        bytes_avail = stream->recvbuf.bytes_left_in_data_frame;\n    if (stream->req_body == NULL)\n        h2o_buffer_init(&stream->req_body, &h2o_socket_buffer_prototype);\n    if (!h2o_buffer_try_append(&stream->req_body, *src, bytes_avail))\n        return H2O_HTTP3_ERROR_INTERNAL;\n    stream->req.entity = h2o_iovec_init(stream->req_body->bytes, stream->req_body->size);\n    stream->req.req_body_bytes_received += bytes_avail;\n    stream->recvbuf.bytes_left_in_data_frame -= bytes_avail;\n    *src += bytes_avail;\n\n    if (stream->recvbuf.bytes_left_in_data_frame == 0)\n        stream->recvbuf.handle_input = handle_input_expect_data;\n\n    return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,5 @@\n static int handle_input_expect_data_payload(struct st_h2o_http3_server_stream_t *stream, const uint8_t **src,\n-                                            const uint8_t *src_end, const char **err_desc)\n+                                            const uint8_t *src_end, int in_generator, const char **err_desc)\n {\n     size_t bytes_avail = src_end - *src;\n ",
        "diff_line_info": {
            "deleted_lines": [
                "                                            const uint8_t *src_end, const char **err_desc)"
            ],
            "added_lines": [
                "                                            const uint8_t *src_end, int in_generator, const char **err_desc)"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-43848",
        "func_name": "h2o/handle_input_expect_data",
        "description": "h2o is an open source http server. In code prior to the `8c0eca3` commit h2o may attempt to access uninitialized memory. When receiving QUIC frames in certain order, HTTP/3 server-side implementation of h2o can be misguided to treat uninitialized memory as HTTP/3 frames that have been received. When h2o is used as a reverse proxy, an attacker can abuse this vulnerability to send internal state of h2o to backend servers controlled by the attacker or third party. Also, if there is an HTTP endpoint that reflects the traffic sent from the client, an attacker can use that reflector to obtain internal state of h2o. This internal state includes traffic of other connections in unencrypted form and TLS session tickets. This vulnerability exists in h2o server with HTTP/3 support, between commit 93af138 and d1f0f65. None of the released versions of h2o are affected by this vulnerability. There are no known workarounds. Users of unreleased versions of h2o using HTTP/3 are advised to upgrade immediately.",
        "git_url": "https://github.com/h2o/h2o/commit/8c0eca3d9bc1f08e7c6bdf57645f3d54aed7d844",
        "commit_title": "postpone stream shutdown by H3 frame parsers",
        "commit_text": "",
        "func_before": "int handle_input_expect_data(struct st_h2o_http3_server_stream_t *stream, const uint8_t **src, const uint8_t *src_end,\n                             const char **err_desc)\n{\n    h2o_http3_read_frame_t frame;\n    int ret;\n\n    /* read frame */\n    if ((ret = h2o_http3_read_frame(&frame, 0, H2O_HTTP3_STREAM_TYPE_REQUEST, src, src_end, err_desc)) != 0)\n        return ret;\n    switch (frame.type) {\n    case H2O_HTTP3_FRAME_TYPE_HEADERS:\n        /* when in tunnel mode, trailers forbidden */\n        if (stream->tunnel != NULL) {\n            *err_desc = \"unexpected frame type\";\n            return H2O_HTTP3_ERROR_FRAME_UNEXPECTED;\n        }\n        /* trailers, ignore but disallow succeeding DATA or HEADERS frame */\n        stream->recvbuf.handle_input = handle_input_post_trailers;\n        return 0;\n    case H2O_HTTP3_FRAME_TYPE_DATA:\n        if (stream->req.content_length != SIZE_MAX &&\n            stream->req.content_length - stream->req.req_body_bytes_received < frame.length) {\n            /* The only viable option here is to reset the stream, as we might have already started streaming the request body\n             * upstream. This behavior is consistent with what we do in HTTP/2. */\n            shutdown_stream(stream, H2O_HTTP3_ERROR_EARLY_RESPONSE, H2O_HTTP3_ERROR_GENERAL_PROTOCOL, 0);\n            return 0;\n        }\n        break;\n    default:\n        return 0;\n    }\n\n    /* got a DATA frame */\n    if (frame.length != 0) {\n        stream->recvbuf.handle_input = handle_input_expect_data_payload;\n        stream->recvbuf.bytes_left_in_data_frame = frame.length;\n    }\n\n    return 0;\n}",
        "func": "int handle_input_expect_data(struct st_h2o_http3_server_stream_t *stream, const uint8_t **src, const uint8_t *src_end,\n                             int in_generator, const char **err_desc)\n{\n    h2o_http3_read_frame_t frame;\n    int ret;\n\n    /* read frame */\n    if ((ret = h2o_http3_read_frame(&frame, 0, H2O_HTTP3_STREAM_TYPE_REQUEST, src, src_end, err_desc)) != 0)\n        return ret;\n    switch (frame.type) {\n    case H2O_HTTP3_FRAME_TYPE_HEADERS:\n        /* when in tunnel mode, trailers forbidden */\n        if (stream->tunnel != NULL) {\n            *err_desc = \"unexpected frame type\";\n            return H2O_HTTP3_ERROR_FRAME_UNEXPECTED;\n        }\n        /* trailers, ignore but disallow succeeding DATA or HEADERS frame */\n        stream->recvbuf.handle_input = handle_input_post_trailers;\n        return 0;\n    case H2O_HTTP3_FRAME_TYPE_DATA:\n        if (stream->req.content_length != SIZE_MAX &&\n            stream->req.content_length - stream->req.req_body_bytes_received < frame.length) {\n            /* The only viable option here is to reset the stream, as we might have already started streaming the request body\n             * upstream. This behavior is consistent with what we do in HTTP/2. */\n            shutdown_stream(stream, H2O_HTTP3_ERROR_EARLY_RESPONSE, H2O_HTTP3_ERROR_GENERAL_PROTOCOL, in_generator);\n            return 0;\n        }\n        break;\n    default:\n        return 0;\n    }\n\n    /* got a DATA frame */\n    if (frame.length != 0) {\n        stream->recvbuf.handle_input = handle_input_expect_data_payload;\n        stream->recvbuf.bytes_left_in_data_frame = frame.length;\n    }\n\n    return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,5 @@\n int handle_input_expect_data(struct st_h2o_http3_server_stream_t *stream, const uint8_t **src, const uint8_t *src_end,\n-                             const char **err_desc)\n+                             int in_generator, const char **err_desc)\n {\n     h2o_http3_read_frame_t frame;\n     int ret;\n@@ -22,7 +22,7 @@\n             stream->req.content_length - stream->req.req_body_bytes_received < frame.length) {\n             /* The only viable option here is to reset the stream, as we might have already started streaming the request body\n              * upstream. This behavior is consistent with what we do in HTTP/2. */\n-            shutdown_stream(stream, H2O_HTTP3_ERROR_EARLY_RESPONSE, H2O_HTTP3_ERROR_GENERAL_PROTOCOL, 0);\n+            shutdown_stream(stream, H2O_HTTP3_ERROR_EARLY_RESPONSE, H2O_HTTP3_ERROR_GENERAL_PROTOCOL, in_generator);\n             return 0;\n         }\n         break;",
        "diff_line_info": {
            "deleted_lines": [
                "                             const char **err_desc)",
                "            shutdown_stream(stream, H2O_HTTP3_ERROR_EARLY_RESPONSE, H2O_HTTP3_ERROR_GENERAL_PROTOCOL, 0);"
            ],
            "added_lines": [
                "                             int in_generator, const char **err_desc)",
                "            shutdown_stream(stream, H2O_HTTP3_ERROR_EARLY_RESPONSE, H2O_HTTP3_ERROR_GENERAL_PROTOCOL, in_generator);"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-43848",
        "func_name": "h2o/handle_input_post_trailers",
        "description": "h2o is an open source http server. In code prior to the `8c0eca3` commit h2o may attempt to access uninitialized memory. When receiving QUIC frames in certain order, HTTP/3 server-side implementation of h2o can be misguided to treat uninitialized memory as HTTP/3 frames that have been received. When h2o is used as a reverse proxy, an attacker can abuse this vulnerability to send internal state of h2o to backend servers controlled by the attacker or third party. Also, if there is an HTTP endpoint that reflects the traffic sent from the client, an attacker can use that reflector to obtain internal state of h2o. This internal state includes traffic of other connections in unencrypted form and TLS session tickets. This vulnerability exists in h2o server with HTTP/3 support, between commit 93af138 and d1f0f65. None of the released versions of h2o are affected by this vulnerability. There are no known workarounds. Users of unreleased versions of h2o using HTTP/3 are advised to upgrade immediately.",
        "git_url": "https://github.com/h2o/h2o/commit/8c0eca3d9bc1f08e7c6bdf57645f3d54aed7d844",
        "commit_title": "postpone stream shutdown by H3 frame parsers",
        "commit_text": "",
        "func_before": "int handle_input_post_trailers(struct st_h2o_http3_server_stream_t *stream, const uint8_t **src, const uint8_t *src_end,\n                               const char **err_desc)\n{\n    h2o_http3_read_frame_t frame;\n    int ret;\n\n    /* read and ignore unknown frames */\n    if ((ret = h2o_http3_read_frame(&frame, 0, H2O_HTTP3_STREAM_TYPE_REQUEST, src, src_end, err_desc)) != 0)\n        return ret;\n    switch (frame.type) {\n    case H2O_HTTP3_FRAME_TYPE_HEADERS:\n    case H2O_HTTP3_FRAME_TYPE_DATA:\n        return H2O_HTTP3_ERROR_FRAME_UNEXPECTED;\n    default:\n        break;\n    }\n\n    return 0;\n}",
        "func": "int handle_input_post_trailers(struct st_h2o_http3_server_stream_t *stream, const uint8_t **src, const uint8_t *src_end,\n                               int in_generator, const char **err_desc)\n{\n    h2o_http3_read_frame_t frame;\n    int ret;\n\n    /* read and ignore unknown frames */\n    if ((ret = h2o_http3_read_frame(&frame, 0, H2O_HTTP3_STREAM_TYPE_REQUEST, src, src_end, err_desc)) != 0)\n        return ret;\n    switch (frame.type) {\n    case H2O_HTTP3_FRAME_TYPE_HEADERS:\n    case H2O_HTTP3_FRAME_TYPE_DATA:\n        return H2O_HTTP3_ERROR_FRAME_UNEXPECTED;\n    default:\n        break;\n    }\n\n    return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,5 @@\n int handle_input_post_trailers(struct st_h2o_http3_server_stream_t *stream, const uint8_t **src, const uint8_t *src_end,\n-                               const char **err_desc)\n+                               int in_generator, const char **err_desc)\n {\n     h2o_http3_read_frame_t frame;\n     int ret;",
        "diff_line_info": {
            "deleted_lines": [
                "                               const char **err_desc)"
            ],
            "added_lines": [
                "                               int in_generator, const char **err_desc)"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-43848",
        "func_name": "h2o/handle_buffered_input",
        "description": "h2o is an open source http server. In code prior to the `8c0eca3` commit h2o may attempt to access uninitialized memory. When receiving QUIC frames in certain order, HTTP/3 server-side implementation of h2o can be misguided to treat uninitialized memory as HTTP/3 frames that have been received. When h2o is used as a reverse proxy, an attacker can abuse this vulnerability to send internal state of h2o to backend servers controlled by the attacker or third party. Also, if there is an HTTP endpoint that reflects the traffic sent from the client, an attacker can use that reflector to obtain internal state of h2o. This internal state includes traffic of other connections in unencrypted form and TLS session tickets. This vulnerability exists in h2o server with HTTP/3 support, between commit 93af138 and d1f0f65. None of the released versions of h2o are affected by this vulnerability. There are no known workarounds. Users of unreleased versions of h2o using HTTP/3 are advised to upgrade immediately.",
        "git_url": "https://github.com/h2o/h2o/commit/8c0eca3d9bc1f08e7c6bdf57645f3d54aed7d844",
        "commit_title": "postpone stream shutdown by H3 frame parsers",
        "commit_text": "",
        "func_before": "static void handle_buffered_input(struct st_h2o_http3_server_stream_t *stream, int in_generator)\n{\n    struct st_h2o_http3_server_conn_t *conn = get_conn(stream);\n\n    if (stream->state >= H2O_HTTP3_SERVER_STREAM_STATE_CLOSE_WAIT)\n        return;\n\n    { /* consume contiguous bytes */\n        size_t bytes_available = quicly_recvstate_bytes_available(&stream->quic->recvstate);\n        assert(bytes_available <= stream->recvbuf.buf->size);\n        const uint8_t *src = (const uint8_t *)stream->recvbuf.buf->bytes, *src_end = src + bytes_available;\n        while (src != src_end) {\n            int err;\n            const char *err_desc = NULL;\n            if ((err = stream->recvbuf.handle_input(stream, &src, src_end, &err_desc)) != 0) {\n                if (err == H2O_HTTP3_ERROR_INCOMPLETE) {\n                    if (!quicly_recvstate_transfer_complete(&stream->quic->recvstate))\n                        break;\n                    err = H2O_HTTP3_ERROR_GENERAL_PROTOCOL;\n                    err_desc = \"incomplete frame\";\n                }\n                h2o_quic_close_connection(&conn->h3.super, err, err_desc);\n                return;\n            }\n        }\n        size_t bytes_consumed = src - (const uint8_t *)stream->recvbuf.buf->bytes;\n        h2o_buffer_consume(&stream->recvbuf.buf, bytes_consumed);\n        quicly_stream_sync_recvbuf(stream->quic, bytes_consumed);\n    }\n\n    if (stream->tunnel != NULL) {\n        if (stream->tunnel->tunnel != NULL && !stream->tunnel->up.is_inflight)\n            tunnel_write(stream);\n        return;\n    }\n\n    if (quicly_recvstate_transfer_complete(&stream->quic->recvstate)) {\n        if (stream->recvbuf.buf->size == 0 && (stream->recvbuf.handle_input == handle_input_expect_data ||\n                                               stream->recvbuf.handle_input == handle_input_post_trailers)) {\n            /* have complete request, advance the state and process the request */\n            if (stream->req.content_length != SIZE_MAX && stream->req.content_length != stream->req.req_body_bytes_received) {\n                /* the request terminated abruptly; reset the stream as we do for HTTP/2 */\n                shutdown_stream(stream, H2O_HTTP3_ERROR_NONE /* ignored */,\n                                stream->req.req_body_bytes_received < stream->req.content_length\n                                    ? H2O_HTTP3_ERROR_REQUEST_INCOMPLETE\n                                    : H2O_HTTP3_ERROR_GENERAL_PROTOCOL,\n                                in_generator);\n            } else {\n                if (stream->req.write_req.cb != NULL) {\n                    if (!h2o_linklist_is_linked(&stream->link))\n                        h2o_linklist_insert(&conn->delayed_streams.req_streaming, &stream->link);\n                    request_run_delayed(conn);\n                } else if (!stream->req.process_called && stream->state < H2O_HTTP3_SERVER_STREAM_STATE_SEND_HEADERS) {\n                    /* process the request, if we haven't called h2o_process_request nor send an error response */\n                    switch (stream->state) {\n                    case H2O_HTTP3_SERVER_STREAM_STATE_RECV_HEADERS:\n                    case H2O_HTTP3_SERVER_STREAM_STATE_RECV_BODY_BEFORE_BLOCK:\n                    case H2O_HTTP3_SERVER_STREAM_STATE_RECV_BODY_UNBLOCKED:\n                        break;\n                    default:\n                        assert(!\"unexpected state\");\n                        break;\n                    }\n                    set_state(stream, H2O_HTTP3_SERVER_STREAM_STATE_REQ_PENDING, in_generator);\n                    h2o_linklist_insert(&conn->delayed_streams.pending, &stream->link);\n                    request_run_delayed(conn);\n                }\n            }\n        } else {\n            shutdown_stream(stream, H2O_HTTP3_ERROR_NONE /* ignored */, H2O_HTTP3_ERROR_REQUEST_INCOMPLETE, in_generator);\n        }\n    } else {\n        if (stream->state == H2O_HTTP3_SERVER_STREAM_STATE_RECV_BODY_BEFORE_BLOCK && stream->req_body != NULL &&\n            stream->req_body->size >= H2O_HTTP3_REQUEST_BODY_MIN_BYTES_TO_BLOCK) {\n            /* switch to blocked state if the request body is becoming large (this limits the concurrency to the backend) */\n            stream->read_blocked = 1;\n            h2o_linklist_insert(&conn->delayed_streams.recv_body_blocked, &stream->link);\n            set_state(stream, H2O_HTTP3_SERVER_STREAM_STATE_RECV_BODY_BLOCKED, in_generator);\n            check_run_blocked(conn);\n        } else if (stream->req.write_req.cb != NULL && stream->req_body->size != 0) {\n            /* in streaming mode, let the run_delayed invoke write_req */\n            if (!h2o_linklist_is_linked(&stream->link))\n                h2o_linklist_insert(&conn->delayed_streams.req_streaming, &stream->link);\n            request_run_delayed(conn);\n        }\n    }\n}",
        "func": "static void handle_buffered_input(struct st_h2o_http3_server_stream_t *stream, int in_generator)\n{\n    struct st_h2o_http3_server_conn_t *conn = get_conn(stream);\n\n    if (stream->state >= H2O_HTTP3_SERVER_STREAM_STATE_CLOSE_WAIT)\n        return;\n\n    { /* consume contiguous bytes */\n        size_t bytes_available = quicly_recvstate_bytes_available(&stream->quic->recvstate);\n        assert(bytes_available <= stream->recvbuf.buf->size);\n        const uint8_t *src = (const uint8_t *)stream->recvbuf.buf->bytes, *src_end = src + bytes_available;\n        while (src != src_end) {\n            int err;\n            const char *err_desc = NULL;\n            if ((err = stream->recvbuf.handle_input(stream, &src, src_end, in_generator, &err_desc)) != 0) {\n                if (err == H2O_HTTP3_ERROR_INCOMPLETE) {\n                    if (!quicly_recvstate_transfer_complete(&stream->quic->recvstate))\n                        break;\n                    err = H2O_HTTP3_ERROR_GENERAL_PROTOCOL;\n                    err_desc = \"incomplete frame\";\n                }\n                h2o_quic_close_connection(&conn->h3.super, err, err_desc);\n                return;\n            }\n        }\n        size_t bytes_consumed = src - (const uint8_t *)stream->recvbuf.buf->bytes;\n        h2o_buffer_consume(&stream->recvbuf.buf, bytes_consumed);\n        quicly_stream_sync_recvbuf(stream->quic, bytes_consumed);\n    }\n\n    if (stream->tunnel != NULL) {\n        if (stream->tunnel->tunnel != NULL && !stream->tunnel->up.is_inflight)\n            tunnel_write(stream);\n        return;\n    }\n\n    if (quicly_recvstate_transfer_complete(&stream->quic->recvstate)) {\n        if (stream->recvbuf.buf->size == 0 && (stream->recvbuf.handle_input == handle_input_expect_data ||\n                                               stream->recvbuf.handle_input == handle_input_post_trailers)) {\n            /* have complete request, advance the state and process the request */\n            if (stream->req.content_length != SIZE_MAX && stream->req.content_length != stream->req.req_body_bytes_received) {\n                /* the request terminated abruptly; reset the stream as we do for HTTP/2 */\n                shutdown_stream(stream, H2O_HTTP3_ERROR_NONE /* ignored */,\n                                stream->req.req_body_bytes_received < stream->req.content_length\n                                    ? H2O_HTTP3_ERROR_REQUEST_INCOMPLETE\n                                    : H2O_HTTP3_ERROR_GENERAL_PROTOCOL,\n                                in_generator);\n            } else {\n                if (stream->req.write_req.cb != NULL) {\n                    if (!h2o_linklist_is_linked(&stream->link))\n                        h2o_linklist_insert(&conn->delayed_streams.req_streaming, &stream->link);\n                    request_run_delayed(conn);\n                } else if (!stream->req.process_called && stream->state < H2O_HTTP3_SERVER_STREAM_STATE_SEND_HEADERS) {\n                    /* process the request, if we haven't called h2o_process_request nor send an error response */\n                    switch (stream->state) {\n                    case H2O_HTTP3_SERVER_STREAM_STATE_RECV_HEADERS:\n                    case H2O_HTTP3_SERVER_STREAM_STATE_RECV_BODY_BEFORE_BLOCK:\n                    case H2O_HTTP3_SERVER_STREAM_STATE_RECV_BODY_UNBLOCKED:\n                        break;\n                    default:\n                        assert(!\"unexpected state\");\n                        break;\n                    }\n                    set_state(stream, H2O_HTTP3_SERVER_STREAM_STATE_REQ_PENDING, in_generator);\n                    h2o_linklist_insert(&conn->delayed_streams.pending, &stream->link);\n                    request_run_delayed(conn);\n                }\n            }\n        } else {\n            shutdown_stream(stream, H2O_HTTP3_ERROR_NONE /* ignored */, H2O_HTTP3_ERROR_REQUEST_INCOMPLETE, in_generator);\n        }\n    } else {\n        if (stream->state == H2O_HTTP3_SERVER_STREAM_STATE_RECV_BODY_BEFORE_BLOCK && stream->req_body != NULL &&\n            stream->req_body->size >= H2O_HTTP3_REQUEST_BODY_MIN_BYTES_TO_BLOCK) {\n            /* switch to blocked state if the request body is becoming large (this limits the concurrency to the backend) */\n            stream->read_blocked = 1;\n            h2o_linklist_insert(&conn->delayed_streams.recv_body_blocked, &stream->link);\n            set_state(stream, H2O_HTTP3_SERVER_STREAM_STATE_RECV_BODY_BLOCKED, in_generator);\n            check_run_blocked(conn);\n        } else if (stream->req.write_req.cb != NULL && stream->req_body->size != 0) {\n            /* in streaming mode, let the run_delayed invoke write_req */\n            if (!h2o_linklist_is_linked(&stream->link))\n                h2o_linklist_insert(&conn->delayed_streams.req_streaming, &stream->link);\n            request_run_delayed(conn);\n        }\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -12,7 +12,7 @@\n         while (src != src_end) {\n             int err;\n             const char *err_desc = NULL;\n-            if ((err = stream->recvbuf.handle_input(stream, &src, src_end, &err_desc)) != 0) {\n+            if ((err = stream->recvbuf.handle_input(stream, &src, src_end, in_generator, &err_desc)) != 0) {\n                 if (err == H2O_HTTP3_ERROR_INCOMPLETE) {\n                     if (!quicly_recvstate_transfer_complete(&stream->quic->recvstate))\n                         break;",
        "diff_line_info": {
            "deleted_lines": [
                "            if ((err = stream->recvbuf.handle_input(stream, &src, src_end, &err_desc)) != 0) {"
            ],
            "added_lines": [
                "            if ((err = stream->recvbuf.handle_input(stream, &src, src_end, in_generator, &err_desc)) != 0) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-24448",
        "func_name": "torvalds/linux/nfs4_file_open",
        "description": "An issue was discovered in fs/nfs/dir.c in the Linux kernel before 5.16.5. If an application sets the O_DIRECTORY flag, and tries to open a regular file, nfs_atomic_open() performs a regular lookup. If a regular file is found, ENOTDIR should occur, but the server instead returns uninitialized data in the file descriptor.",
        "git_url": "https://github.com/torvalds/linux/commit/ab0fc21bc7105b54bafd85bd8b82742f9e68898a",
        "commit_title": "Revert \"NFSv4: Handle the special Linux file open access mode\"",
        "commit_text": " This reverts commit 44942b4e457beda00981f616402a1a791e8c616e.  After secondly opening a file with O_ACCMODE|O_DIRECT flags, nfs4_valid_open_stateid() will dereference NULL nfs4_state when lseek().  Reproducer:   1. mount -t nfs -o vers=4.2 $server_ip:/ /mnt/   2. fd = open(\"/mnt/file\", O_ACCMODE|O_DIRECT|O_CREAT)   3. close(fd)   4. fd = open(\"/mnt/file\", O_ACCMODE|O_DIRECT)   5. lseek(fd) ",
        "func_before": "static int\nnfs4_file_open(struct inode *inode, struct file *filp)\n{\n\tstruct nfs_open_context *ctx;\n\tstruct dentry *dentry = file_dentry(filp);\n\tstruct dentry *parent = NULL;\n\tstruct inode *dir;\n\tunsigned openflags = filp->f_flags;\n\tstruct iattr attr;\n\tint err;\n\n\t/*\n\t * If no cached dentry exists or if it's negative, NFSv4 handled the\n\t * opens in ->lookup() or ->create().\n\t *\n\t * We only get this far for a cached positive dentry.  We skipped\n\t * revalidation, so handle it here by dropping the dentry and returning\n\t * -EOPENSTALE.  The VFS will retry the lookup/create/open.\n\t */\n\n\tdprintk(\"NFS: open file(%pd2)\\n\", dentry);\n\n\terr = nfs_check_flags(openflags);\n\tif (err)\n\t\treturn err;\n\n\tif ((openflags & O_ACCMODE) == 3)\n\t\treturn nfs_open(inode, filp);\n\n\t/* We can't create new files here */\n\topenflags &= ~(O_CREAT|O_EXCL);\n\n\tparent = dget_parent(dentry);\n\tdir = d_inode(parent);\n\n\tctx = alloc_nfs_open_context(file_dentry(filp), filp->f_mode, filp);\n\terr = PTR_ERR(ctx);\n\tif (IS_ERR(ctx))\n\t\tgoto out;\n\n\tattr.ia_valid = ATTR_OPEN;\n\tif (openflags & O_TRUNC) {\n\t\tattr.ia_valid |= ATTR_SIZE;\n\t\tattr.ia_size = 0;\n\t\tfilemap_write_and_wait(inode->i_mapping);\n\t}\n\n\tinode = NFS_PROTO(dir)->open_context(dir, ctx, openflags, &attr, NULL);\n\tif (IS_ERR(inode)) {\n\t\terr = PTR_ERR(inode);\n\t\tswitch (err) {\n\t\tdefault:\n\t\t\tgoto out_put_ctx;\n\t\tcase -ENOENT:\n\t\tcase -ESTALE:\n\t\tcase -EISDIR:\n\t\tcase -ENOTDIR:\n\t\tcase -ELOOP:\n\t\t\tgoto out_drop;\n\t\t}\n\t}\n\tif (inode != d_inode(dentry))\n\t\tgoto out_drop;\n\n\tnfs_file_set_open_context(filp, ctx);\n\tnfs_fscache_open_file(inode, filp);\n\terr = 0;\n\nout_put_ctx:\n\tput_nfs_open_context(ctx);\nout:\n\tdput(parent);\n\treturn err;\n\nout_drop:\n\td_drop(dentry);\n\terr = -EOPENSTALE;\n\tgoto out_put_ctx;\n}",
        "func": "static int\nnfs4_file_open(struct inode *inode, struct file *filp)\n{\n\tstruct nfs_open_context *ctx;\n\tstruct dentry *dentry = file_dentry(filp);\n\tstruct dentry *parent = NULL;\n\tstruct inode *dir;\n\tunsigned openflags = filp->f_flags;\n\tstruct iattr attr;\n\tint err;\n\n\t/*\n\t * If no cached dentry exists or if it's negative, NFSv4 handled the\n\t * opens in ->lookup() or ->create().\n\t *\n\t * We only get this far for a cached positive dentry.  We skipped\n\t * revalidation, so handle it here by dropping the dentry and returning\n\t * -EOPENSTALE.  The VFS will retry the lookup/create/open.\n\t */\n\n\tdprintk(\"NFS: open file(%pd2)\\n\", dentry);\n\n\terr = nfs_check_flags(openflags);\n\tif (err)\n\t\treturn err;\n\n\tif ((openflags & O_ACCMODE) == 3)\n\t\topenflags--;\n\n\t/* We can't create new files here */\n\topenflags &= ~(O_CREAT|O_EXCL);\n\n\tparent = dget_parent(dentry);\n\tdir = d_inode(parent);\n\n\tctx = alloc_nfs_open_context(file_dentry(filp), filp->f_mode, filp);\n\terr = PTR_ERR(ctx);\n\tif (IS_ERR(ctx))\n\t\tgoto out;\n\n\tattr.ia_valid = ATTR_OPEN;\n\tif (openflags & O_TRUNC) {\n\t\tattr.ia_valid |= ATTR_SIZE;\n\t\tattr.ia_size = 0;\n\t\tfilemap_write_and_wait(inode->i_mapping);\n\t}\n\n\tinode = NFS_PROTO(dir)->open_context(dir, ctx, openflags, &attr, NULL);\n\tif (IS_ERR(inode)) {\n\t\terr = PTR_ERR(inode);\n\t\tswitch (err) {\n\t\tdefault:\n\t\t\tgoto out_put_ctx;\n\t\tcase -ENOENT:\n\t\tcase -ESTALE:\n\t\tcase -EISDIR:\n\t\tcase -ENOTDIR:\n\t\tcase -ELOOP:\n\t\t\tgoto out_drop;\n\t\t}\n\t}\n\tif (inode != d_inode(dentry))\n\t\tgoto out_drop;\n\n\tnfs_file_set_open_context(filp, ctx);\n\tnfs_fscache_open_file(inode, filp);\n\terr = 0;\n\nout_put_ctx:\n\tput_nfs_open_context(ctx);\nout:\n\tdput(parent);\n\treturn err;\n\nout_drop:\n\td_drop(dentry);\n\terr = -EOPENSTALE;\n\tgoto out_put_ctx;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -25,7 +25,7 @@\n \t\treturn err;\n \n \tif ((openflags & O_ACCMODE) == 3)\n-\t\treturn nfs_open(inode, filp);\n+\t\topenflags--;\n \n \t/* We can't create new files here */\n \topenflags &= ~(O_CREAT|O_EXCL);",
        "diff_line_info": {
            "deleted_lines": [
                "\t\treturn nfs_open(inode, filp);"
            ],
            "added_lines": [
                "\t\topenflags--;"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-24448",
        "func_name": "torvalds/linux/nfs_atomic_open",
        "description": "An issue was discovered in fs/nfs/dir.c in the Linux kernel before 5.16.5. If an application sets the O_DIRECTORY flag, and tries to open a regular file, nfs_atomic_open() performs a regular lookup. If a regular file is found, ENOTDIR should occur, but the server instead returns uninitialized data in the file descriptor.",
        "git_url": "https://github.com/torvalds/linux/commit/ac795161c93699d600db16c1a8cc23a65a1eceaf",
        "commit_title": "NFSv4: Handle case where the lookup of a directory fails",
        "commit_text": " If the application sets the O_DIRECTORY flag, and tries to open a regular file, nfs_atomic_open() will punt to doing a regular lookup. If the server then returns a regular file, we will happily return a file descriptor with uninitialised open state.  The fix is to return the expected ENOTDIR error in these cases. ",
        "func_before": "int nfs_atomic_open(struct inode *dir, struct dentry *dentry,\n\t\t    struct file *file, unsigned open_flags,\n\t\t    umode_t mode)\n{\n\tDECLARE_WAIT_QUEUE_HEAD_ONSTACK(wq);\n\tstruct nfs_open_context *ctx;\n\tstruct dentry *res;\n\tstruct iattr attr = { .ia_valid = ATTR_OPEN };\n\tstruct inode *inode;\n\tunsigned int lookup_flags = 0;\n\tunsigned long dir_verifier;\n\tbool switched = false;\n\tint created = 0;\n\tint err;\n\n\t/* Expect a negative dentry */\n\tBUG_ON(d_inode(dentry));\n\n\tdfprintk(VFS, \"NFS: atomic_open(%s/%lu), %pd\\n\",\n\t\t\tdir->i_sb->s_id, dir->i_ino, dentry);\n\n\terr = nfs_check_flags(open_flags);\n\tif (err)\n\t\treturn err;\n\n\t/* NFS only supports OPEN on regular files */\n\tif ((open_flags & O_DIRECTORY)) {\n\t\tif (!d_in_lookup(dentry)) {\n\t\t\t/*\n\t\t\t * Hashed negative dentry with O_DIRECTORY: dentry was\n\t\t\t * revalidated and is fine, no need to perform lookup\n\t\t\t * again\n\t\t\t */\n\t\t\treturn -ENOENT;\n\t\t}\n\t\tlookup_flags = LOOKUP_OPEN|LOOKUP_DIRECTORY;\n\t\tgoto no_open;\n\t}\n\n\tif (dentry->d_name.len > NFS_SERVER(dir)->namelen)\n\t\treturn -ENAMETOOLONG;\n\n\tif (open_flags & O_CREAT) {\n\t\tstruct nfs_server *server = NFS_SERVER(dir);\n\n\t\tif (!(server->attr_bitmask[2] & FATTR4_WORD2_MODE_UMASK))\n\t\t\tmode &= ~current_umask();\n\n\t\tattr.ia_valid |= ATTR_MODE;\n\t\tattr.ia_mode = mode;\n\t}\n\tif (open_flags & O_TRUNC) {\n\t\tattr.ia_valid |= ATTR_SIZE;\n\t\tattr.ia_size = 0;\n\t}\n\n\tif (!(open_flags & O_CREAT) && !d_in_lookup(dentry)) {\n\t\td_drop(dentry);\n\t\tswitched = true;\n\t\tdentry = d_alloc_parallel(dentry->d_parent,\n\t\t\t\t\t  &dentry->d_name, &wq);\n\t\tif (IS_ERR(dentry))\n\t\t\treturn PTR_ERR(dentry);\n\t\tif (unlikely(!d_in_lookup(dentry)))\n\t\t\treturn finish_no_open(file, dentry);\n\t}\n\n\tctx = create_nfs_open_context(dentry, open_flags, file);\n\terr = PTR_ERR(ctx);\n\tif (IS_ERR(ctx))\n\t\tgoto out;\n\n\ttrace_nfs_atomic_open_enter(dir, ctx, open_flags);\n\tinode = NFS_PROTO(dir)->open_context(dir, ctx, open_flags, &attr, &created);\n\tif (created)\n\t\tfile->f_mode |= FMODE_CREATED;\n\tif (IS_ERR(inode)) {\n\t\terr = PTR_ERR(inode);\n\t\ttrace_nfs_atomic_open_exit(dir, ctx, open_flags, err);\n\t\tput_nfs_open_context(ctx);\n\t\td_drop(dentry);\n\t\tswitch (err) {\n\t\tcase -ENOENT:\n\t\t\td_splice_alias(NULL, dentry);\n\t\t\tif (nfs_server_capable(dir, NFS_CAP_CASE_INSENSITIVE))\n\t\t\t\tdir_verifier = inode_peek_iversion_raw(dir);\n\t\t\telse\n\t\t\t\tdir_verifier = nfs_save_change_attribute(dir);\n\t\t\tnfs_set_verifier(dentry, dir_verifier);\n\t\t\tbreak;\n\t\tcase -EISDIR:\n\t\tcase -ENOTDIR:\n\t\t\tgoto no_open;\n\t\tcase -ELOOP:\n\t\t\tif (!(open_flags & O_NOFOLLOW))\n\t\t\t\tgoto no_open;\n\t\t\tbreak;\n\t\t\t/* case -EINVAL: */\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t\tgoto out;\n\t}\n\n\terr = nfs_finish_open(ctx, ctx->dentry, file, open_flags);\n\ttrace_nfs_atomic_open_exit(dir, ctx, open_flags, err);\n\tput_nfs_open_context(ctx);\nout:\n\tif (unlikely(switched)) {\n\t\td_lookup_done(dentry);\n\t\tdput(dentry);\n\t}\n\treturn err;\n\nno_open:\n\tres = nfs_lookup(dir, dentry, lookup_flags);\n\tif (switched) {\n\t\td_lookup_done(dentry);\n\t\tif (!res)\n\t\t\tres = dentry;\n\t\telse\n\t\t\tdput(dentry);\n\t}\n\tif (IS_ERR(res))\n\t\treturn PTR_ERR(res);\n\treturn finish_no_open(file, res);\n}",
        "func": "int nfs_atomic_open(struct inode *dir, struct dentry *dentry,\n\t\t    struct file *file, unsigned open_flags,\n\t\t    umode_t mode)\n{\n\tDECLARE_WAIT_QUEUE_HEAD_ONSTACK(wq);\n\tstruct nfs_open_context *ctx;\n\tstruct dentry *res;\n\tstruct iattr attr = { .ia_valid = ATTR_OPEN };\n\tstruct inode *inode;\n\tunsigned int lookup_flags = 0;\n\tunsigned long dir_verifier;\n\tbool switched = false;\n\tint created = 0;\n\tint err;\n\n\t/* Expect a negative dentry */\n\tBUG_ON(d_inode(dentry));\n\n\tdfprintk(VFS, \"NFS: atomic_open(%s/%lu), %pd\\n\",\n\t\t\tdir->i_sb->s_id, dir->i_ino, dentry);\n\n\terr = nfs_check_flags(open_flags);\n\tif (err)\n\t\treturn err;\n\n\t/* NFS only supports OPEN on regular files */\n\tif ((open_flags & O_DIRECTORY)) {\n\t\tif (!d_in_lookup(dentry)) {\n\t\t\t/*\n\t\t\t * Hashed negative dentry with O_DIRECTORY: dentry was\n\t\t\t * revalidated and is fine, no need to perform lookup\n\t\t\t * again\n\t\t\t */\n\t\t\treturn -ENOENT;\n\t\t}\n\t\tlookup_flags = LOOKUP_OPEN|LOOKUP_DIRECTORY;\n\t\tgoto no_open;\n\t}\n\n\tif (dentry->d_name.len > NFS_SERVER(dir)->namelen)\n\t\treturn -ENAMETOOLONG;\n\n\tif (open_flags & O_CREAT) {\n\t\tstruct nfs_server *server = NFS_SERVER(dir);\n\n\t\tif (!(server->attr_bitmask[2] & FATTR4_WORD2_MODE_UMASK))\n\t\t\tmode &= ~current_umask();\n\n\t\tattr.ia_valid |= ATTR_MODE;\n\t\tattr.ia_mode = mode;\n\t}\n\tif (open_flags & O_TRUNC) {\n\t\tattr.ia_valid |= ATTR_SIZE;\n\t\tattr.ia_size = 0;\n\t}\n\n\tif (!(open_flags & O_CREAT) && !d_in_lookup(dentry)) {\n\t\td_drop(dentry);\n\t\tswitched = true;\n\t\tdentry = d_alloc_parallel(dentry->d_parent,\n\t\t\t\t\t  &dentry->d_name, &wq);\n\t\tif (IS_ERR(dentry))\n\t\t\treturn PTR_ERR(dentry);\n\t\tif (unlikely(!d_in_lookup(dentry)))\n\t\t\treturn finish_no_open(file, dentry);\n\t}\n\n\tctx = create_nfs_open_context(dentry, open_flags, file);\n\terr = PTR_ERR(ctx);\n\tif (IS_ERR(ctx))\n\t\tgoto out;\n\n\ttrace_nfs_atomic_open_enter(dir, ctx, open_flags);\n\tinode = NFS_PROTO(dir)->open_context(dir, ctx, open_flags, &attr, &created);\n\tif (created)\n\t\tfile->f_mode |= FMODE_CREATED;\n\tif (IS_ERR(inode)) {\n\t\terr = PTR_ERR(inode);\n\t\ttrace_nfs_atomic_open_exit(dir, ctx, open_flags, err);\n\t\tput_nfs_open_context(ctx);\n\t\td_drop(dentry);\n\t\tswitch (err) {\n\t\tcase -ENOENT:\n\t\t\td_splice_alias(NULL, dentry);\n\t\t\tif (nfs_server_capable(dir, NFS_CAP_CASE_INSENSITIVE))\n\t\t\t\tdir_verifier = inode_peek_iversion_raw(dir);\n\t\t\telse\n\t\t\t\tdir_verifier = nfs_save_change_attribute(dir);\n\t\t\tnfs_set_verifier(dentry, dir_verifier);\n\t\t\tbreak;\n\t\tcase -EISDIR:\n\t\tcase -ENOTDIR:\n\t\t\tgoto no_open;\n\t\tcase -ELOOP:\n\t\t\tif (!(open_flags & O_NOFOLLOW))\n\t\t\t\tgoto no_open;\n\t\t\tbreak;\n\t\t\t/* case -EINVAL: */\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t\tgoto out;\n\t}\n\n\terr = nfs_finish_open(ctx, ctx->dentry, file, open_flags);\n\ttrace_nfs_atomic_open_exit(dir, ctx, open_flags, err);\n\tput_nfs_open_context(ctx);\nout:\n\tif (unlikely(switched)) {\n\t\td_lookup_done(dentry);\n\t\tdput(dentry);\n\t}\n\treturn err;\n\nno_open:\n\tres = nfs_lookup(dir, dentry, lookup_flags);\n\tif (!res) {\n\t\tinode = d_inode(dentry);\n\t\tif ((lookup_flags & LOOKUP_DIRECTORY) && inode &&\n\t\t    !S_ISDIR(inode->i_mode))\n\t\t\tres = ERR_PTR(-ENOTDIR);\n\t} else if (!IS_ERR(res)) {\n\t\tinode = d_inode(res);\n\t\tif ((lookup_flags & LOOKUP_DIRECTORY) && inode &&\n\t\t    !S_ISDIR(inode->i_mode)) {\n\t\t\tdput(res);\n\t\t\tres = ERR_PTR(-ENOTDIR);\n\t\t}\n\t}\n\tif (switched) {\n\t\td_lookup_done(dentry);\n\t\tif (!res)\n\t\t\tres = dentry;\n\t\telse\n\t\t\tdput(dentry);\n\t}\n\tif (IS_ERR(res))\n\t\treturn PTR_ERR(res);\n\treturn finish_no_open(file, res);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -114,6 +114,19 @@\n \n no_open:\n \tres = nfs_lookup(dir, dentry, lookup_flags);\n+\tif (!res) {\n+\t\tinode = d_inode(dentry);\n+\t\tif ((lookup_flags & LOOKUP_DIRECTORY) && inode &&\n+\t\t    !S_ISDIR(inode->i_mode))\n+\t\t\tres = ERR_PTR(-ENOTDIR);\n+\t} else if (!IS_ERR(res)) {\n+\t\tinode = d_inode(res);\n+\t\tif ((lookup_flags & LOOKUP_DIRECTORY) && inode &&\n+\t\t    !S_ISDIR(inode->i_mode)) {\n+\t\t\tdput(res);\n+\t\t\tres = ERR_PTR(-ENOTDIR);\n+\t\t}\n+\t}\n \tif (switched) {\n \t\td_lookup_done(dentry);\n \t\tif (!res)",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tif (!res) {",
                "\t\tinode = d_inode(dentry);",
                "\t\tif ((lookup_flags & LOOKUP_DIRECTORY) && inode &&",
                "\t\t    !S_ISDIR(inode->i_mode))",
                "\t\t\tres = ERR_PTR(-ENOTDIR);",
                "\t} else if (!IS_ERR(res)) {",
                "\t\tinode = d_inode(res);",
                "\t\tif ((lookup_flags & LOOKUP_DIRECTORY) && inode &&",
                "\t\t    !S_ISDIR(inode->i_mode)) {",
                "\t\t\tdput(res);",
                "\t\t\tres = ERR_PTR(-ENOTDIR);",
                "\t\t}",
                "\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-23573",
        "func_name": "tensorflow/Compute",
        "description": "Tensorflow is an Open Source Machine Learning Framework. The implementation of `AssignOp` can result in copying uninitialized data to a new tensor. This later results in undefined behavior. The implementation has a check that the left hand side of the assignment is initialized (to minimize number of allocations), but does not check that the right hand side is also initialized. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/ef1d027be116f25e25bb94a60da491c2cf55bd0b",
        "commit_title": "Prevent copying uninitialized data in `AssignOp`.",
        "commit_text": " This prevents harder to debug undefined behaviors that cannot be traced back to the original tensor after assignments occur earlier in the graph execution. Several of these undefined behaviors are just reference bindings to null pointers, which are caught when running under ubsan/asan.  PiperOrigin-RevId: 408654780",
        "func_before": "void Compute(OpKernelContext* context) override {\n    const Tensor& rhs = context->input(1);\n\n    // We always return the input ref.\n    context->forward_ref_input_to_ref_output(0, 0);\n\n    // We can't always know how this value will be used downstream, so make\n    // conservative assumptions in specifying constraints on the memory\n    // allocation attributes, unless the Grappler graph analysis determined that\n    // it was safe not to.\n    AllocatorAttributes attr;\n    if (!relax_constraints_) {\n      attr.set_gpu_compatible(true);\n      attr.set_nic_compatible(true);\n    }\n\n    {\n      mutex_lock l(*context->input_ref_mutex(0));\n      const Tensor& old_lhs = context->mutable_input(0, /* lock_held */ true);\n      const bool same_shape = old_lhs.shape().IsSameSize(rhs.shape());\n      if (validate_shape_) {\n        OP_REQUIRES(context, same_shape,\n                    errors::InvalidArgument(\n                        \"Assign requires shapes of both tensors to match. \"\n                        \"lhs shape= \",\n                        old_lhs.shape().DebugString(),\n                        \" rhs shape= \", rhs.shape().DebugString()));\n      }\n\n      // In the code below we try to minimize the amount of memory allocation\n      // and copying by trying the following two shortcuts:\n      // 1. If the lhs is initialized and has the same number of elements as\n      //    the rhs we can avoid a memory allocation.\n      // 2. If we can reuse the rhs buffer we avoid both a memory allocation\n      //    and copying.\n\n      // 1. Try to copy into an existing buffer.\n      if (old_lhs.IsInitialized() &&\n          old_lhs.shape().num_elements() == rhs.shape().num_elements()) {\n        // The existing lhs tensor has already been initialized and the right\n        // hand side can fit in the underlying buffer.\n        Tensor reshaped_old_lhs;\n        if (same_shape) {\n          reshaped_old_lhs = old_lhs;\n        } else {\n          CHECK(reshaped_old_lhs.CopyFrom(old_lhs, rhs.shape()));\n          context->replace_ref_input(0, reshaped_old_lhs,\n                                     /* lock_held */ true);\n        }\n        if (use_exclusive_lock_) {\n          Copy(context, &reshaped_old_lhs, rhs);\n          return;\n        }\n      } else {\n        // 2. Try to reuse the rhs.\n        std::unique_ptr<Tensor> input_alias = context->forward_input(\n            1, OpKernelContext::Params::kNoReservation /*output_index*/,\n            rhs.dtype(), rhs.shape(), DEVICE_MEMORY, attr);\n        if (input_alias != nullptr) {\n          // Update the ref to point to the new buffer.\n          context->replace_ref_input(0, *input_alias, /* lock_held */ true);\n          return;\n        }\n\n        // Otherwise, create a new tensor whose shape matches the\n        // right hand side, hand off to lhs and copy the rhs into it.\n        Tensor copy_tensor;\n        OP_REQUIRES_OK(context,\n                       context->allocate_temp(old_lhs.dtype(), rhs.shape(),\n                                              &copy_tensor, attr));\n        // We track memory of variables in variable ops instead of in this\n        // assign op.\n        context->clear_recorded_memory();\n        context->replace_ref_input(0, copy_tensor, /* lock_held */ true);\n        if (use_exclusive_lock_) {\n          Copy(context, &copy_tensor, rhs);\n          return;\n        }\n      }\n    }\n\n    // The tensor has already been initialized and the right hand side\n    // matches the left hand side's shape. We have been told to do the\n    // copy outside the lock.\n    Tensor old_unlocked_lhs = context->mutable_input(0, /* lock_held */ false);\n    Copy(context, &old_unlocked_lhs, rhs);\n  }",
        "func": "void Compute(OpKernelContext* context) override {\n    const Tensor& rhs = context->input(1);\n\n    // We always return the input ref.\n    context->forward_ref_input_to_ref_output(0, 0);\n\n    // Prevent copying uninitialized data, to solve harder to debug undefined\n    // behaviors that cannot be traced back to the original tensor.\n    OP_REQUIRES(\n        context, rhs.IsInitialized(),\n        errors::Internal(\"Right hand side of AssignOp is not initialized\"));\n\n    // We can't always know how this value will be used downstream, so make\n    // conservative assumptions in specifying constraints on the memory\n    // allocation attributes, unless the Grappler graph analysis determined that\n    // it was safe not to.\n    AllocatorAttributes attr;\n    if (!relax_constraints_) {\n      attr.set_gpu_compatible(true);\n      attr.set_nic_compatible(true);\n    }\n\n    {\n      mutex_lock l(*context->input_ref_mutex(0));\n      const Tensor& old_lhs = context->mutable_input(0, /* lock_held */ true);\n      const bool same_shape = old_lhs.shape().IsSameSize(rhs.shape());\n      if (validate_shape_) {\n        OP_REQUIRES(context, same_shape,\n                    errors::InvalidArgument(\n                        \"Assign requires shapes of both tensors to match. \"\n                        \"lhs shape= \",\n                        old_lhs.shape().DebugString(),\n                        \" rhs shape= \", rhs.shape().DebugString()));\n      }\n\n      // In the code below we try to minimize the amount of memory allocation\n      // and copying by trying the following two shortcuts:\n      // 1. If the lhs is initialized and has the same number of elements as\n      //    the rhs we can avoid a memory allocation.\n      // 2. If we can reuse the rhs buffer we avoid both a memory allocation\n      //    and copying.\n\n      // 1. Try to copy into an existing buffer.\n      if (old_lhs.IsInitialized() &&\n          old_lhs.shape().num_elements() == rhs.shape().num_elements()) {\n        // The existing lhs tensor has already been initialized and the right\n        // hand side can fit in the underlying buffer.\n        Tensor reshaped_old_lhs;\n        if (same_shape) {\n          reshaped_old_lhs = old_lhs;\n        } else {\n          CHECK(reshaped_old_lhs.CopyFrom(old_lhs, rhs.shape()));\n          context->replace_ref_input(0, reshaped_old_lhs,\n                                     /* lock_held */ true);\n        }\n        if (use_exclusive_lock_) {\n          Copy(context, &reshaped_old_lhs, rhs);\n          return;\n        }\n      } else {\n        // 2. Try to reuse the rhs.\n        std::unique_ptr<Tensor> input_alias = context->forward_input(\n            1, OpKernelContext::Params::kNoReservation /*output_index*/,\n            rhs.dtype(), rhs.shape(), DEVICE_MEMORY, attr);\n        if (input_alias != nullptr) {\n          // Update the ref to point to the new buffer.\n          context->replace_ref_input(0, *input_alias, /* lock_held */ true);\n          return;\n        }\n\n        // Otherwise, create a new tensor whose shape matches the\n        // right hand side, hand off to lhs and copy the rhs into it.\n        Tensor copy_tensor;\n        OP_REQUIRES_OK(context,\n                       context->allocate_temp(old_lhs.dtype(), rhs.shape(),\n                                              &copy_tensor, attr));\n        // We track memory of variables in variable ops instead of in this\n        // assign op.\n        context->clear_recorded_memory();\n        context->replace_ref_input(0, copy_tensor, /* lock_held */ true);\n        if (use_exclusive_lock_) {\n          Copy(context, &copy_tensor, rhs);\n          return;\n        }\n      }\n    }\n\n    // The tensor has already been initialized and the right hand side\n    // matches the left hand side's shape. We have been told to do the\n    // copy outside the lock.\n    Tensor old_unlocked_lhs = context->mutable_input(0, /* lock_held */ false);\n    Copy(context, &old_unlocked_lhs, rhs);\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,6 +3,12 @@\n \n     // We always return the input ref.\n     context->forward_ref_input_to_ref_output(0, 0);\n+\n+    // Prevent copying uninitialized data, to solve harder to debug undefined\n+    // behaviors that cannot be traced back to the original tensor.\n+    OP_REQUIRES(\n+        context, rhs.IsInitialized(),\n+        errors::Internal(\"Right hand side of AssignOp is not initialized\"));\n \n     // We can't always know how this value will be used downstream, so make\n     // conservative assumptions in specifying constraints on the memory",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "    // Prevent copying uninitialized data, to solve harder to debug undefined",
                "    // behaviors that cannot be traced back to the original tensor.",
                "    OP_REQUIRES(",
                "        context, rhs.IsInitialized(),",
                "        errors::Internal(\"Right hand side of AssignOp is not initialized\"));"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-27795",
        "func_name": "radareorg/radare2/anal_fcn_data",
        "description": "A segmentation fault was discovered in radare2 with adf command. In libr/core/cmd_anal.c, when command \"adf\" has no or wrong argument, anal_fcn_data (core, input + 1) --> RAnalFunction *fcn = r_anal_get_fcn_in (core->anal, core->offset, -1); returns null pointer for fcn causing segmentation fault later in ensure_fcn_range (fcn).",
        "git_url": "https://github.com/radareorg/radare2/commit/4d3811681a80f92a53e795f6a64c4b0fc2c8dd22",
        "commit_title": "Fix segfault in adf  (#16230)",
        "commit_text": "",
        "func_before": "static bool anal_fcn_data (RCore *core, const char *input) {\n\tRAnalFunction *fcn = r_anal_get_fcn_in (core->anal, core->offset, -1);\n\tut32 fcn_size = r_anal_function_size_from_entry (fcn);\n\tif (fcn) {\n\t\tint i;\n\t\tbool gap = false;\n\t\tut64 gap_addr = UT64_MAX;\n\t\tchar *bitmap = calloc (1, fcn_size);\n\t\tif (bitmap) {\n\t\t\tRAnalBlock *b;\n\t\t\tRListIter *iter;\n\t\t\tr_list_foreach (fcn->bbs, iter, b) {\n\t\t\t\tint f = b->addr - fcn->addr;\n\t\t\t\tint t = R_MIN (f + b->size, fcn_size);\n\t\t\t\tif (f >= 0) {\n\t\t\t\t\twhile (f < t) {\n\t\t\t\t\t\tbitmap[f++] = 1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tfor (i = 0; i < fcn_size; i++) {\n\t\t\tut64 here = fcn->addr + i;\n\t\t\tif (bitmap && bitmap[i]) {\n\t\t\t\tif (gap) {\n\t\t\t\t\tr_cons_printf (\"Cd %d @ 0x%08\"PFMT64x\"\\n\", here - gap_addr, gap_addr);\n\t\t\t\t\tgap = false;\n\t\t\t\t}\n\t\t\t\tgap_addr = UT64_MAX;\n\t\t\t} else {\n\t\t\t\tif (!gap) {\n\t\t\t\t\tgap = true;\n\t\t\t\t\tgap_addr = here;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif (gap) {\n\t\t\tr_cons_printf (\"Cd %d @ 0x%08\"PFMT64x\"\\n\", fcn->addr + fcn_size - gap_addr, gap_addr);\n\t\t}\n\t\tfree (bitmap);\n\t\treturn true;\n\t}\n\treturn false;\n}",
        "func": "static bool anal_fcn_data (RCore *core, const char *input) {\n\tRAnalFunction *fcn = r_anal_get_fcn_in (core->anal, core->offset, R_ANAL_FCN_TYPE_ANY);\n\tif (fcn) {\n\t\tint i;\n\t\tbool gap = false;\n\t\tut64 gap_addr = UT64_MAX;\n\t\tut32 fcn_size = r_anal_function_size_from_entry (fcn);\n\t\tchar *bitmap = calloc (1, fcn_size);\n\t\tif (bitmap) {\n\t\t\tRAnalBlock *b;\n\t\t\tRListIter *iter;\n\t\t\tr_list_foreach (fcn->bbs, iter, b) {\n\t\t\t\tint f = b->addr - fcn->addr;\n\t\t\t\tint t = R_MIN (f + b->size, fcn_size);\n\t\t\t\tif (f >= 0) {\n\t\t\t\t\twhile (f < t) {\n\t\t\t\t\t\tbitmap[f++] = 1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tfor (i = 0; i < fcn_size; i++) {\n\t\t\tut64 here = fcn->addr + i;\n\t\t\tif (bitmap && bitmap[i]) {\n\t\t\t\tif (gap) {\n\t\t\t\t\tr_cons_printf (\"Cd %d @ 0x%08\"PFMT64x\"\\n\", here - gap_addr, gap_addr);\n\t\t\t\t\tgap = false;\n\t\t\t\t}\n\t\t\t\tgap_addr = UT64_MAX;\n\t\t\t} else {\n\t\t\t\tif (!gap) {\n\t\t\t\t\tgap = true;\n\t\t\t\t\tgap_addr = here;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif (gap) {\n\t\t\tr_cons_printf (\"Cd %d @ 0x%08\"PFMT64x\"\\n\", fcn->addr + fcn_size - gap_addr, gap_addr);\n\t\t}\n\t\tfree (bitmap);\n\t\treturn true;\n\t}\n\treturn false;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,10 +1,10 @@\n static bool anal_fcn_data (RCore *core, const char *input) {\n-\tRAnalFunction *fcn = r_anal_get_fcn_in (core->anal, core->offset, -1);\n-\tut32 fcn_size = r_anal_function_size_from_entry (fcn);\n+\tRAnalFunction *fcn = r_anal_get_fcn_in (core->anal, core->offset, R_ANAL_FCN_TYPE_ANY);\n \tif (fcn) {\n \t\tint i;\n \t\tbool gap = false;\n \t\tut64 gap_addr = UT64_MAX;\n+\t\tut32 fcn_size = r_anal_function_size_from_entry (fcn);\n \t\tchar *bitmap = calloc (1, fcn_size);\n \t\tif (bitmap) {\n \t\t\tRAnalBlock *b;",
        "diff_line_info": {
            "deleted_lines": [
                "\tRAnalFunction *fcn = r_anal_get_fcn_in (core->anal, core->offset, -1);",
                "\tut32 fcn_size = r_anal_function_size_from_entry (fcn);"
            ],
            "added_lines": [
                "\tRAnalFunction *fcn = r_anal_get_fcn_in (core->anal, core->offset, R_ANAL_FCN_TYPE_ANY);",
                "\t\tut32 fcn_size = r_anal_function_size_from_entry (fcn);"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-38668",
        "func_name": "CrowCpp/Crow/do_write_static",
        "description": "HTTP applications (servers) based on Crow through 1.0+4 may reveal potentially sensitive uninitialized data from stack memory when fulfilling a request for a static file smaller than 16 KB.",
        "git_url": "https://github.com/CrowCpp/Crow/commit/d17a88af696b9de62504adf2a4657d381733b9e2",
        "commit_title": "Fix stack data disclosure when returning static files smaller than",
        "commit_text": "16KiB. It could also cause to return partially incorrect file ending in case of file not being rounded up to 16KiB.  Thanks to Gynvael Coldwind and hebi for discovering and preparing report.",
        "func_before": "void do_write_static()\n        {\n            is_writing = true;\n            asio::write(adaptor_.socket(), buffers_);\n\n            if (res.file_info.statResult == 0)\n            {\n                std::ifstream is(res.file_info.path.c_str(), std::ios::in | std::ios::binary);\n                char buf[16384];\n                while (is.read(buf, sizeof(buf)).gcount() > 0)\n                {\n                    std::vector<asio::const_buffer> buffers;\n                    buffers.push_back(asio::buffer(buf));\n                    do_write_sync(buffers);\n                }\n            }\n            is_writing = false;\n            if (close_connection_)\n            {\n                adaptor_.shutdown_readwrite();\n                adaptor_.close();\n                CROW_LOG_DEBUG << this << \" from write (static)\";\n                check_destroy();\n            }\n\n            res.end();\n            res.clear();\n            buffers_.clear();\n        }",
        "func": "void do_write_static()\n        {\n            is_writing = true;\n            asio::write(adaptor_.socket(), buffers_);\n\n            if (res.file_info.statResult == 0)\n            {\n                std::ifstream is(res.file_info.path.c_str(), std::ios::in | std::ios::binary);\n                std::vector<asio::const_buffer> buffers{1};\n                char buf[16384];\n                is.read(buf, sizeof(buf));\n                while (is.gcount() > 0)\n                {\n                    buffers[0] = asio::buffer(buf, is.gcount());\n                    do_write_sync(buffers);\n                    is.read(buf, sizeof(buf));\n                }\n            }\n            is_writing = false;\n            if (close_connection_)\n            {\n                adaptor_.shutdown_readwrite();\n                adaptor_.close();\n                CROW_LOG_DEBUG << this << \" from write (static)\";\n                check_destroy();\n            }\n\n            res.end();\n            res.clear();\n            buffers_.clear();\n        }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -6,12 +6,14 @@\n             if (res.file_info.statResult == 0)\n             {\n                 std::ifstream is(res.file_info.path.c_str(), std::ios::in | std::ios::binary);\n+                std::vector<asio::const_buffer> buffers{1};\n                 char buf[16384];\n-                while (is.read(buf, sizeof(buf)).gcount() > 0)\n+                is.read(buf, sizeof(buf));\n+                while (is.gcount() > 0)\n                 {\n-                    std::vector<asio::const_buffer> buffers;\n-                    buffers.push_back(asio::buffer(buf));\n+                    buffers[0] = asio::buffer(buf, is.gcount());\n                     do_write_sync(buffers);\n+                    is.read(buf, sizeof(buf));\n                 }\n             }\n             is_writing = false;",
        "diff_line_info": {
            "deleted_lines": [
                "                while (is.read(buf, sizeof(buf)).gcount() > 0)",
                "                    std::vector<asio::const_buffer> buffers;",
                "                    buffers.push_back(asio::buffer(buf));"
            ],
            "added_lines": [
                "                std::vector<asio::const_buffer> buffers{1};",
                "                is.read(buf, sizeof(buf));",
                "                while (is.gcount() > 0)",
                "                    buffers[0] = asio::buffer(buf, is.gcount());",
                "                    is.read(buf, sizeof(buf));"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-29240",
        "func_name": "scylladb/cql_server::connection::read_and_decompress_frame",
        "description": "Scylla is a real-time big data database that is API-compatible with Apache Cassandra and Amazon DynamoDB. When decompressing CQL frame received from user, Scylla assumes that user-provided uncompressed length is correct. If user provides fake length, that is greater than the real one, part of decompression buffer won't be overwritten, and will be left uninitialized. This can be exploited in several ways, depending on the privileges of the user. 1. The main exploit is that an attacker with access to CQL port, but no user account, can bypass authentication, but only if there are other legitimate clients making connections to the cluster, and they use LZ4. 2. Attacker that already has a user account on the cluster can read parts of uninitialized memory, which can contain things like passwords of other users or fragments of other queries / results, which leads to authorization bypass and sensitive information disclosure. The bug has been patched in the following versions: Scylla Enterprise: 2020.1.14, 2021.1.12, 2022.1.0. Scylla Open Source: 4.6.7, 5.0.3. Users unable to upgrade should make sure none of their drivers connect to cluster using LZ4 compression, and that Scylla CQL port is behind firewall. Additionally make sure no untrusted client can connect to Scylla, by setting up authentication and applying workarounds from previous point (firewall, no lz4 compression).",
        "git_url": "https://github.com/scylladb/scylladb/commit/1c2eef384da439b0457b6d71c7e37d7268e471cb",
        "commit_title": "transport/server.cc: Return correct size of decompressed lz4 buffer",
        "commit_text": " An incorrect size is returned from the function, which could lead to crashes or undefined behavior. Fix by erroring out in these cases.  Fixes #11476",
        "func_before": "future<fragmented_temporary_buffer> cql_server::connection::read_and_decompress_frame(size_t length, uint8_t flags)\n{\n    using namespace compression_buffers;\n    if (flags & cql_frame_flags::compression) {\n        if (_compression == cql_compression::lz4) {\n            if (length < 4) {\n                throw std::runtime_error(fmt::format(\"CQL frame truncated: expected to have at least 4 bytes, got {}\", length));\n            }\n            return _buffer_reader.read_exactly(_read_buf, length).then([this] (fragmented_temporary_buffer buf) {\n                auto linearization_buffer = bytes_ostream();\n                int32_t uncomp_len = request_reader(buf.get_istream(), linearization_buffer).read_int();\n                if (uncomp_len < 0) {\n                    throw std::runtime_error(\"CQL frame uncompressed length is negative: \" + std::to_string(uncomp_len));\n                }\n                buf.remove_prefix(4);\n                auto in = input_buffer.get_linearized_view(fragmented_temporary_buffer::view(buf));\n                auto uncomp = output_buffer.make_fragmented_temporary_buffer(uncomp_len, fragmented_temporary_buffer::default_fragment_size, [&] (bytes_mutable_view out) {\n                    auto ret = LZ4_decompress_safe(reinterpret_cast<const char*>(in.data()), reinterpret_cast<char*>(out.data()),\n                                                   in.size(), out.size());\n                    if (ret < 0) {\n                        throw std::runtime_error(\"CQL frame LZ4 uncompression failure\");\n                    }\n                    return out.size();\n                });\n                on_compression_buffer_use();\n                return uncomp;\n            });\n        } else if (_compression == cql_compression::snappy) {\n            return _buffer_reader.read_exactly(_read_buf, length).then([this] (fragmented_temporary_buffer buf) {\n                auto in = input_buffer.get_linearized_view(fragmented_temporary_buffer::view(buf));\n                size_t uncomp_len;\n                if (snappy_uncompressed_length(reinterpret_cast<const char*>(in.data()), in.size(), &uncomp_len) != SNAPPY_OK) {\n                    throw std::runtime_error(\"CQL frame Snappy uncompressed size is unknown\");\n                }\n                auto uncomp = output_buffer.make_fragmented_temporary_buffer(uncomp_len, fragmented_temporary_buffer::default_fragment_size, [&] (bytes_mutable_view out) {\n                    size_t output_len = out.size();\n                    if (snappy_uncompress(reinterpret_cast<const char*>(in.data()), in.size(), reinterpret_cast<char*>(out.data()), &output_len) != SNAPPY_OK) {\n                        throw std::runtime_error(\"CQL frame Snappy uncompression failure\");\n                    }\n                    return output_len;\n                });\n                on_compression_buffer_use();\n                return uncomp;\n            });\n        } else {\n            throw exceptions::protocol_exception(format(\"Unknown compression algorithm\"));\n        }\n    }\n    return _buffer_reader.read_exactly(_read_buf, length);\n}",
        "func": "future<fragmented_temporary_buffer> cql_server::connection::read_and_decompress_frame(size_t length, uint8_t flags)\n{\n    using namespace compression_buffers;\n    if (flags & cql_frame_flags::compression) {\n        if (_compression == cql_compression::lz4) {\n            if (length < 4) {\n                throw std::runtime_error(fmt::format(\"CQL frame truncated: expected to have at least 4 bytes, got {}\", length));\n            }\n            return _buffer_reader.read_exactly(_read_buf, length).then([this] (fragmented_temporary_buffer buf) {\n                auto linearization_buffer = bytes_ostream();\n                int32_t uncomp_len = request_reader(buf.get_istream(), linearization_buffer).read_int();\n                if (uncomp_len < 0) {\n                    throw std::runtime_error(\"CQL frame uncompressed length is negative: \" + std::to_string(uncomp_len));\n                }\n                buf.remove_prefix(4);\n                auto in = input_buffer.get_linearized_view(fragmented_temporary_buffer::view(buf));\n                auto uncomp = output_buffer.make_fragmented_temporary_buffer(uncomp_len, fragmented_temporary_buffer::default_fragment_size, [&] (bytes_mutable_view out) {\n                    auto ret = LZ4_decompress_safe(reinterpret_cast<const char*>(in.data()), reinterpret_cast<char*>(out.data()),\n                                                   in.size(), out.size());\n                    if (ret < 0) {\n                        throw std::runtime_error(\"CQL frame LZ4 uncompression failure\");\n                    }\n                    if (ret != out.size()) {\n                        throw std::runtime_error(\"Malformed CQL frame - provided uncompressed size different than real uncompressed size\");\n                    }\n                    return static_cast<size_t>(ret);\n                });\n                on_compression_buffer_use();\n                return uncomp;\n            });\n        } else if (_compression == cql_compression::snappy) {\n            return _buffer_reader.read_exactly(_read_buf, length).then([this] (fragmented_temporary_buffer buf) {\n                auto in = input_buffer.get_linearized_view(fragmented_temporary_buffer::view(buf));\n                size_t uncomp_len;\n                if (snappy_uncompressed_length(reinterpret_cast<const char*>(in.data()), in.size(), &uncomp_len) != SNAPPY_OK) {\n                    throw std::runtime_error(\"CQL frame Snappy uncompressed size is unknown\");\n                }\n                auto uncomp = output_buffer.make_fragmented_temporary_buffer(uncomp_len, fragmented_temporary_buffer::default_fragment_size, [&] (bytes_mutable_view out) {\n                    size_t output_len = out.size();\n                    if (snappy_uncompress(reinterpret_cast<const char*>(in.data()), in.size(), reinterpret_cast<char*>(out.data()), &output_len) != SNAPPY_OK) {\n                        throw std::runtime_error(\"CQL frame Snappy uncompression failure\");\n                    }\n                    return output_len;\n                });\n                on_compression_buffer_use();\n                return uncomp;\n            });\n        } else {\n            throw exceptions::protocol_exception(format(\"Unknown compression algorithm\"));\n        }\n    }\n    return _buffer_reader.read_exactly(_read_buf, length);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -20,7 +20,10 @@\n                     if (ret < 0) {\n                         throw std::runtime_error(\"CQL frame LZ4 uncompression failure\");\n                     }\n-                    return out.size();\n+                    if (ret != out.size()) {\n+                        throw std::runtime_error(\"Malformed CQL frame - provided uncompressed size different than real uncompressed size\");\n+                    }\n+                    return static_cast<size_t>(ret);\n                 });\n                 on_compression_buffer_use();\n                 return uncomp;",
        "diff_line_info": {
            "deleted_lines": [
                "                    return out.size();"
            ],
            "added_lines": [
                "                    if (ret != out.size()) {",
                "                        throw std::runtime_error(\"Malformed CQL frame - provided uncompressed size different than real uncompressed size\");",
                "                    }",
                "                    return static_cast<size_t>(ret);"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-40768",
        "func_name": "torvalds/linux/stex_queuecommand_lck",
        "description": "drivers/scsi/stex.c in the Linux kernel through 5.19.9 allows local users to obtain sensitive information from kernel memory because stex_queuecommand_lck lacks a memset for the PASSTHRU_CMD case.",
        "git_url": "https://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/commit/?h=6022f210461fef67e6e676fd8544ca02d1bcfa7a",
        "commit_title": "The passthrough structure is declared off of the stack, so it needs to be",
        "commit_text": "set to zero before copied back to userspace to prevent any unintentional data leakage.  Switch things to be statically allocated which will fill the unused fields with 0 automatically.  Link: https://lore.kernel.org/r/YxrjN3OOw2HHl9tx@kroah.com Cc: stable@kernel.org Cc: \"James E.J. Bottomley\" <jejb@linux.ibm.com> Cc: \"Martin K. Petersen\" <martin.petersen@oracle.com> Cc: Dan Carpenter <dan.carpenter@oracle.com> ",
        "func_before": "static int stex_queuecommand_lck(struct scsi_cmnd *cmd)\n{\n\tvoid (*done)(struct scsi_cmnd *) = scsi_done;\n\tstruct st_hba *hba;\n\tstruct Scsi_Host *host;\n\tunsigned int id, lun;\n\tstruct req_msg *req;\n\tu16 tag;\n\n\thost = cmd->device->host;\n\tid = cmd->device->id;\n\tlun = cmd->device->lun;\n\thba = (struct st_hba *) &host->hostdata[0];\n\tif (hba->mu_status == MU_STATE_NOCONNECT) {\n\t\tcmd->result = DID_NO_CONNECT;\n\t\tdone(cmd);\n\t\treturn 0;\n\t}\n\tif (unlikely(hba->mu_status != MU_STATE_STARTED))\n\t\treturn SCSI_MLQUEUE_HOST_BUSY;\n\n\tswitch (cmd->cmnd[0]) {\n\tcase MODE_SENSE_10:\n\t{\n\t\tstatic char ms10_caching_page[12] =\n\t\t\t{ 0, 0x12, 0, 0, 0, 0, 0, 0, 0x8, 0xa, 0x4, 0 };\n\t\tunsigned char page;\n\n\t\tpage = cmd->cmnd[2] & 0x3f;\n\t\tif (page == 0x8 || page == 0x3f) {\n\t\t\tscsi_sg_copy_from_buffer(cmd, ms10_caching_page,\n\t\t\t\t\t\t sizeof(ms10_caching_page));\n\t\t\tcmd->result = DID_OK << 16;\n\t\t\tdone(cmd);\n\t\t} else\n\t\t\tstex_invalid_field(cmd, done);\n\t\treturn 0;\n\t}\n\tcase REPORT_LUNS:\n\t\t/*\n\t\t * The shasta firmware does not report actual luns in the\n\t\t * target, so fail the command to force sequential lun scan.\n\t\t * Also, the console device does not support this command.\n\t\t */\n\t\tif (hba->cardtype == st_shasta || id == host->max_id - 1) {\n\t\t\tstex_invalid_field(cmd, done);\n\t\t\treturn 0;\n\t\t}\n\t\tbreak;\n\tcase TEST_UNIT_READY:\n\t\tif (id == host->max_id - 1) {\n\t\t\tcmd->result = DID_OK << 16;\n\t\t\tdone(cmd);\n\t\t\treturn 0;\n\t\t}\n\t\tbreak;\n\tcase INQUIRY:\n\t\tif (lun >= host->max_lun) {\n\t\t\tcmd->result = DID_NO_CONNECT << 16;\n\t\t\tdone(cmd);\n\t\t\treturn 0;\n\t\t}\n\t\tif (id != host->max_id - 1)\n\t\t\tbreak;\n\t\tif (!lun && !cmd->device->channel &&\n\t\t\t(cmd->cmnd[1] & INQUIRY_EVPD) == 0) {\n\t\t\tscsi_sg_copy_from_buffer(cmd, (void *)console_inq_page,\n\t\t\t\t\t\t sizeof(console_inq_page));\n\t\t\tcmd->result = DID_OK << 16;\n\t\t\tdone(cmd);\n\t\t} else\n\t\t\tstex_invalid_field(cmd, done);\n\t\treturn 0;\n\tcase PASSTHRU_CMD:\n\t\tif (cmd->cmnd[1] == PASSTHRU_GET_DRVVER) {\n\t\t\tstruct st_drvver ver;\n\t\t\tsize_t cp_len = sizeof(ver);\n\n\t\t\tver.major = ST_VER_MAJOR;\n\t\t\tver.minor = ST_VER_MINOR;\n\t\t\tver.oem = ST_OEM;\n\t\t\tver.build = ST_BUILD_VER;\n\t\t\tver.signature[0] = PASSTHRU_SIGNATURE;\n\t\t\tver.console_id = host->max_id - 1;\n\t\t\tver.host_no = hba->host->host_no;\n\t\t\tcp_len = scsi_sg_copy_from_buffer(cmd, &ver, cp_len);\n\t\t\tif (sizeof(ver) == cp_len)\n\t\t\t\tcmd->result = DID_OK << 16;\n\t\t\telse\n\t\t\t\tcmd->result = DID_ERROR << 16;\n\t\t\tdone(cmd);\n\t\t\treturn 0;\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\ttag = scsi_cmd_to_rq(cmd)->tag;\n\n\tif (unlikely(tag >= host->can_queue))\n\t\treturn SCSI_MLQUEUE_HOST_BUSY;\n\n\treq = hba->alloc_rq(hba);\n\n\treq->lun = lun;\n\treq->target = id;\n\n\t/* cdb */\n\tmemcpy(req->cdb, cmd->cmnd, STEX_CDB_LENGTH);\n\n\tif (cmd->sc_data_direction == DMA_FROM_DEVICE)\n\t\treq->data_dir = MSG_DATA_DIR_IN;\n\telse if (cmd->sc_data_direction == DMA_TO_DEVICE)\n\t\treq->data_dir = MSG_DATA_DIR_OUT;\n\telse\n\t\treq->data_dir = MSG_DATA_DIR_ND;\n\n\thba->ccb[tag].cmd = cmd;\n\thba->ccb[tag].sense_bufflen = SCSI_SENSE_BUFFERSIZE;\n\thba->ccb[tag].sense_buffer = cmd->sense_buffer;\n\n\tif (!hba->map_sg(hba, req, &hba->ccb[tag])) {\n\t\thba->ccb[tag].sg_count = 0;\n\t\tmemset(&req->variable[0], 0, 8);\n\t}\n\n\thba->send(hba, req, tag);\n\treturn 0;\n}",
        "func": "static int stex_queuecommand_lck(struct scsi_cmnd *cmd)\n{\n\tvoid (*done)(struct scsi_cmnd *) = scsi_done;\n\tstruct st_hba *hba;\n\tstruct Scsi_Host *host;\n\tunsigned int id, lun;\n\tstruct req_msg *req;\n\tu16 tag;\n\n\thost = cmd->device->host;\n\tid = cmd->device->id;\n\tlun = cmd->device->lun;\n\thba = (struct st_hba *) &host->hostdata[0];\n\tif (hba->mu_status == MU_STATE_NOCONNECT) {\n\t\tcmd->result = DID_NO_CONNECT;\n\t\tdone(cmd);\n\t\treturn 0;\n\t}\n\tif (unlikely(hba->mu_status != MU_STATE_STARTED))\n\t\treturn SCSI_MLQUEUE_HOST_BUSY;\n\n\tswitch (cmd->cmnd[0]) {\n\tcase MODE_SENSE_10:\n\t{\n\t\tstatic char ms10_caching_page[12] =\n\t\t\t{ 0, 0x12, 0, 0, 0, 0, 0, 0, 0x8, 0xa, 0x4, 0 };\n\t\tunsigned char page;\n\n\t\tpage = cmd->cmnd[2] & 0x3f;\n\t\tif (page == 0x8 || page == 0x3f) {\n\t\t\tscsi_sg_copy_from_buffer(cmd, ms10_caching_page,\n\t\t\t\t\t\t sizeof(ms10_caching_page));\n\t\t\tcmd->result = DID_OK << 16;\n\t\t\tdone(cmd);\n\t\t} else\n\t\t\tstex_invalid_field(cmd, done);\n\t\treturn 0;\n\t}\n\tcase REPORT_LUNS:\n\t\t/*\n\t\t * The shasta firmware does not report actual luns in the\n\t\t * target, so fail the command to force sequential lun scan.\n\t\t * Also, the console device does not support this command.\n\t\t */\n\t\tif (hba->cardtype == st_shasta || id == host->max_id - 1) {\n\t\t\tstex_invalid_field(cmd, done);\n\t\t\treturn 0;\n\t\t}\n\t\tbreak;\n\tcase TEST_UNIT_READY:\n\t\tif (id == host->max_id - 1) {\n\t\t\tcmd->result = DID_OK << 16;\n\t\t\tdone(cmd);\n\t\t\treturn 0;\n\t\t}\n\t\tbreak;\n\tcase INQUIRY:\n\t\tif (lun >= host->max_lun) {\n\t\t\tcmd->result = DID_NO_CONNECT << 16;\n\t\t\tdone(cmd);\n\t\t\treturn 0;\n\t\t}\n\t\tif (id != host->max_id - 1)\n\t\t\tbreak;\n\t\tif (!lun && !cmd->device->channel &&\n\t\t\t(cmd->cmnd[1] & INQUIRY_EVPD) == 0) {\n\t\t\tscsi_sg_copy_from_buffer(cmd, (void *)console_inq_page,\n\t\t\t\t\t\t sizeof(console_inq_page));\n\t\t\tcmd->result = DID_OK << 16;\n\t\t\tdone(cmd);\n\t\t} else\n\t\t\tstex_invalid_field(cmd, done);\n\t\treturn 0;\n\tcase PASSTHRU_CMD:\n\t\tif (cmd->cmnd[1] == PASSTHRU_GET_DRVVER) {\n\t\t\tconst struct st_drvver ver = {\n\t\t\t\t.major = ST_VER_MAJOR,\n\t\t\t\t.minor = ST_VER_MINOR,\n\t\t\t\t.oem = ST_OEM,\n\t\t\t\t.build = ST_BUILD_VER,\n\t\t\t\t.signature[0] = PASSTHRU_SIGNATURE,\n\t\t\t\t.console_id = host->max_id - 1,\n\t\t\t\t.host_no = hba->host->host_no,\n\t\t\t};\n\t\t\tsize_t cp_len = sizeof(ver);\n\n\t\t\tcp_len = scsi_sg_copy_from_buffer(cmd, &ver, cp_len);\n\t\t\tif (sizeof(ver) == cp_len)\n\t\t\t\tcmd->result = DID_OK << 16;\n\t\t\telse\n\t\t\t\tcmd->result = DID_ERROR << 16;\n\t\t\tdone(cmd);\n\t\t\treturn 0;\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\ttag = scsi_cmd_to_rq(cmd)->tag;\n\n\tif (unlikely(tag >= host->can_queue))\n\t\treturn SCSI_MLQUEUE_HOST_BUSY;\n\n\treq = hba->alloc_rq(hba);\n\n\treq->lun = lun;\n\treq->target = id;\n\n\t/* cdb */\n\tmemcpy(req->cdb, cmd->cmnd, STEX_CDB_LENGTH);\n\n\tif (cmd->sc_data_direction == DMA_FROM_DEVICE)\n\t\treq->data_dir = MSG_DATA_DIR_IN;\n\telse if (cmd->sc_data_direction == DMA_TO_DEVICE)\n\t\treq->data_dir = MSG_DATA_DIR_OUT;\n\telse\n\t\treq->data_dir = MSG_DATA_DIR_ND;\n\n\thba->ccb[tag].cmd = cmd;\n\thba->ccb[tag].sense_bufflen = SCSI_SENSE_BUFFERSIZE;\n\thba->ccb[tag].sense_buffer = cmd->sense_buffer;\n\n\tif (!hba->map_sg(hba, req, &hba->ccb[tag])) {\n\t\thba->ccb[tag].sg_count = 0;\n\t\tmemset(&req->variable[0], 0, 8);\n\t}\n\n\thba->send(hba, req, tag);\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -73,16 +73,17 @@\n \t\treturn 0;\n \tcase PASSTHRU_CMD:\n \t\tif (cmd->cmnd[1] == PASSTHRU_GET_DRVVER) {\n-\t\t\tstruct st_drvver ver;\n+\t\t\tconst struct st_drvver ver = {\n+\t\t\t\t.major = ST_VER_MAJOR,\n+\t\t\t\t.minor = ST_VER_MINOR,\n+\t\t\t\t.oem = ST_OEM,\n+\t\t\t\t.build = ST_BUILD_VER,\n+\t\t\t\t.signature[0] = PASSTHRU_SIGNATURE,\n+\t\t\t\t.console_id = host->max_id - 1,\n+\t\t\t\t.host_no = hba->host->host_no,\n+\t\t\t};\n \t\t\tsize_t cp_len = sizeof(ver);\n \n-\t\t\tver.major = ST_VER_MAJOR;\n-\t\t\tver.minor = ST_VER_MINOR;\n-\t\t\tver.oem = ST_OEM;\n-\t\t\tver.build = ST_BUILD_VER;\n-\t\t\tver.signature[0] = PASSTHRU_SIGNATURE;\n-\t\t\tver.console_id = host->max_id - 1;\n-\t\t\tver.host_no = hba->host->host_no;\n \t\t\tcp_len = scsi_sg_copy_from_buffer(cmd, &ver, cp_len);\n \t\t\tif (sizeof(ver) == cp_len)\n \t\t\t\tcmd->result = DID_OK << 16;",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\tstruct st_drvver ver;",
                "\t\t\tver.major = ST_VER_MAJOR;",
                "\t\t\tver.minor = ST_VER_MINOR;",
                "\t\t\tver.oem = ST_OEM;",
                "\t\t\tver.build = ST_BUILD_VER;",
                "\t\t\tver.signature[0] = PASSTHRU_SIGNATURE;",
                "\t\t\tver.console_id = host->max_id - 1;",
                "\t\t\tver.host_no = hba->host->host_no;"
            ],
            "added_lines": [
                "\t\t\tconst struct st_drvver ver = {",
                "\t\t\t\t.major = ST_VER_MAJOR,",
                "\t\t\t\t.minor = ST_VER_MINOR,",
                "\t\t\t\t.oem = ST_OEM,",
                "\t\t\t\t.build = ST_BUILD_VER,",
                "\t\t\t\t.signature[0] = PASSTHRU_SIGNATURE,",
                "\t\t\t\t.console_id = host->max_id - 1,",
                "\t\t\t\t.host_no = hba->host->host_no,",
                "\t\t\t};"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-40768",
        "func_name": "torvalds/linux/scsi_sg_copy_from_buffer",
        "description": "drivers/scsi/stex.c in the Linux kernel through 5.19.9 allows local users to obtain sensitive information from kernel memory because stex_queuecommand_lck lacks a memset for the PASSTHRU_CMD case.",
        "git_url": "https://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/commit/?h=6022f210461fef67e6e676fd8544ca02d1bcfa7a",
        "commit_title": "The passthrough structure is declared off of the stack, so it needs to be",
        "commit_text": "set to zero before copied back to userspace to prevent any unintentional data leakage.  Switch things to be statically allocated which will fill the unused fields with 0 automatically.  Link: https://lore.kernel.org/r/YxrjN3OOw2HHl9tx@kroah.com Cc: stable@kernel.org Cc: \"James E.J. Bottomley\" <jejb@linux.ibm.com> Cc: \"Martin K. Petersen\" <martin.petersen@oracle.com> Cc: Dan Carpenter <dan.carpenter@oracle.com> ",
        "func_before": "static inline int scsi_sg_copy_from_buffer(struct scsi_cmnd *cmd,\n\t\t\t\t\t   void *buf, int buflen)\n{\n\treturn sg_copy_from_buffer(scsi_sglist(cmd), scsi_sg_count(cmd),\n\t\t\t\t   buf, buflen);\n}",
        "func": "static inline int scsi_sg_copy_from_buffer(struct scsi_cmnd *cmd,\n\t\t\t\t\t   const void *buf, int buflen)\n{\n\treturn sg_copy_from_buffer(scsi_sglist(cmd), scsi_sg_count(cmd),\n\t\t\t\t   buf, buflen);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,5 @@\n static inline int scsi_sg_copy_from_buffer(struct scsi_cmnd *cmd,\n-\t\t\t\t\t   void *buf, int buflen)\n+\t\t\t\t\t   const void *buf, int buflen)\n {\n \treturn sg_copy_from_buffer(scsi_sglist(cmd), scsi_sg_count(cmd),\n \t\t\t\t   buf, buflen);",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\t\t\t   void *buf, int buflen)"
            ],
            "added_lines": [
                "\t\t\t\t\t   const void *buf, int buflen)"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-6976",
        "func_name": "libvips/vips_tracked_malloc",
        "description": "libvips before 8.7.4 generates output images from uninitialized memory locations when processing corrupted input image data because iofuncs/memory.c does not zero out allocated memory. This can result in leaking raw process memory contents through the output image.",
        "git_url": "https://github.com/libvips/libvips/commit/00622428bda8d7521db8d74260b519fa41d69d0a",
        "commit_title": "zero memory on malloc",
        "commit_text": " to prevent write of uninit memory under some error conditions  thanks Balint",
        "func_before": "void *\nvips_tracked_malloc( size_t size )\n{\n        void *buf;\n\n\tvips_tracked_init(); \n\n\t/* Need an extra sizeof(size_t) bytes to track \n\t * size of this block. Ask for an extra 16 to make sure we don't break\n\t * alignment rules.\n\t */\n\tsize += 16;\n\n        if( !(buf = g_try_malloc( size )) ) {\n#ifdef DEBUG\n\t\tg_assert_not_reached();\n#endif /*DEBUG*/\n\n\t\tvips_error( \"vips_tracked\", \n\t\t\t_( \"out of memory --- size == %dMB\" ), \n\t\t\t(int) (size / (1024.0 * 1024.0))  );\n\t\tg_warning( _( \"out of memory --- size == %dMB\" ), \n\t\t\t(int) (size / (1024.0 * 1024.0))  );\n\n                return( NULL );\n\t}\n\n\tg_mutex_lock( vips_tracked_mutex );\n\n\t*((size_t *)buf) = size;\n\tbuf = (void *) ((char *)buf + 16);\n\n\tvips_tracked_mem += size;\n\tif( vips_tracked_mem > vips_tracked_mem_highwater ) \n\t\tvips_tracked_mem_highwater = vips_tracked_mem;\n\tvips_tracked_allocs += 1;\n\n#ifdef DEBUG_VERBOSE\n\tprintf( \"vips_tracked_malloc: %p, %zd bytes\\n\", buf, size ); \n#endif /*DEBUG_VERBOSE*/\n\n\tg_mutex_unlock( vips_tracked_mutex );\n\n\tVIPS_GATE_MALLOC( size ); \n\n        return( buf );\n}",
        "func": "void *\nvips_tracked_malloc( size_t size )\n{\n        void *buf;\n\n\tvips_tracked_init(); \n\n\t/* Need an extra sizeof(size_t) bytes to track \n\t * size of this block. Ask for an extra 16 to make sure we don't break\n\t * alignment rules.\n\t */\n\tsize += 16;\n\n        if( !(buf = g_try_malloc0( size )) ) {\n#ifdef DEBUG\n\t\tg_assert_not_reached();\n#endif /*DEBUG*/\n\n\t\tvips_error( \"vips_tracked\", \n\t\t\t_( \"out of memory --- size == %dMB\" ), \n\t\t\t(int) (size / (1024.0 * 1024.0))  );\n\t\tg_warning( _( \"out of memory --- size == %dMB\" ), \n\t\t\t(int) (size / (1024.0 * 1024.0))  );\n\n                return( NULL );\n\t}\n\n\tg_mutex_lock( vips_tracked_mutex );\n\n\t*((size_t *)buf) = size;\n\tbuf = (void *) ((char *)buf + 16);\n\n\tvips_tracked_mem += size;\n\tif( vips_tracked_mem > vips_tracked_mem_highwater ) \n\t\tvips_tracked_mem_highwater = vips_tracked_mem;\n\tvips_tracked_allocs += 1;\n\n#ifdef DEBUG_VERBOSE\n\tprintf( \"vips_tracked_malloc: %p, %zd bytes\\n\", buf, size ); \n#endif /*DEBUG_VERBOSE*/\n\n\tg_mutex_unlock( vips_tracked_mutex );\n\n\tVIPS_GATE_MALLOC( size ); \n\n        return( buf );\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -11,7 +11,7 @@\n \t */\n \tsize += 16;\n \n-        if( !(buf = g_try_malloc( size )) ) {\n+        if( !(buf = g_try_malloc0( size )) ) {\n #ifdef DEBUG\n \t\tg_assert_not_reached();\n #endif /*DEBUG*/",
        "diff_line_info": {
            "deleted_lines": [
                "        if( !(buf = g_try_malloc( size )) ) {"
            ],
            "added_lines": [
                "        if( !(buf = g_try_malloc0( size )) ) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-6976",
        "func_name": "libvips/vips_malloc",
        "description": "libvips before 8.7.4 generates output images from uninitialized memory locations when processing corrupted input image data because iofuncs/memory.c does not zero out allocated memory. This can result in leaking raw process memory contents through the output image.",
        "git_url": "https://github.com/libvips/libvips/commit/00622428bda8d7521db8d74260b519fa41d69d0a",
        "commit_title": "zero memory on malloc",
        "commit_text": " to prevent write of uninit memory under some error conditions  thanks Balint",
        "func_before": "void *\nvips_malloc( VipsObject *object, size_t size )\n{\n\tvoid *buf;\n\n\tbuf = g_malloc( size );\n\n        if( object ) {\n\t\tg_signal_connect( object, \"postclose\", \n\t\t\tG_CALLBACK( vips_malloc_cb ), buf );\n\t\tobject->local_memory += size;\n\t}\n\n\treturn( buf );\n}",
        "func": "void *\nvips_malloc( VipsObject *object, size_t size )\n{\n\tvoid *buf;\n\n\tbuf = g_malloc0( size );\n\n        if( object ) {\n\t\tg_signal_connect( object, \"postclose\", \n\t\t\tG_CALLBACK( vips_malloc_cb ), buf );\n\t\tobject->local_memory += size;\n\t}\n\n\treturn( buf );\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,7 +3,7 @@\n {\n \tvoid *buf;\n \n-\tbuf = g_malloc( size );\n+\tbuf = g_malloc0( size );\n \n         if( object ) {\n \t\tg_signal_connect( object, \"postclose\", ",
        "diff_line_info": {
            "deleted_lines": [
                "\tbuf = g_malloc( size );"
            ],
            "added_lines": [
                "\tbuf = g_malloc0( size );"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-9578",
        "func_name": "Yubico/libu2f-host/init_device",
        "description": "In devs.c in Yubico libu2f-host before 1.1.8, the response to init is misparsed, leaking uninitialized stack memory back to the device.",
        "git_url": "https://github.com/Yubico/libu2f-host/commit/e4bb58cc8b6202a421e65f8230217d8ae6e16eb5",
        "commit_title": "fix filling out of initresp",
        "commit_text": "",
        "func_before": "static int\ninit_device (u2fh_devs * devs, struct u2fdevice *dev)\n{\n  unsigned char resp[1024];\n  unsigned char nonce[8];\n  if (obtain_nonce(nonce) != 0)\n    {\n      return U2FH_TRANSPORT_ERROR;\n    }\n  size_t resplen = sizeof (resp);\n  dev->cid = CID_BROADCAST;\n\n  if (u2fh_sendrecv\n      (devs, dev->id, U2FHID_INIT, nonce, sizeof (nonce), resp,\n       &resplen) == U2FH_OK)\n    {\n      U2FHID_INIT_RESP initresp;\n      if (resplen > sizeof (initresp))\n\t{\n\t  return U2FH_MEMORY_ERROR;\n\t}\n      memcpy (&initresp, resp, resplen);\n      dev->cid = initresp.cid;\n      dev->versionInterface = initresp.versionInterface;\n      dev->versionMajor = initresp.versionMajor;\n      dev->versionMinor = initresp.versionMinor;\n      dev->capFlags = initresp.capFlags;\n    }\n  else\n    {\n      return U2FH_TRANSPORT_ERROR;\n    }\n  return U2FH_OK;\n}",
        "func": "static int\ninit_device (u2fh_devs * devs, struct u2fdevice *dev)\n{\n  unsigned char resp[1024];\n  unsigned char nonce[8];\n  if (obtain_nonce(nonce) != 0)\n    {\n      return U2FH_TRANSPORT_ERROR;\n    }\n  size_t resplen = sizeof (resp);\n  dev->cid = CID_BROADCAST;\n\n  if (u2fh_sendrecv\n      (devs, dev->id, U2FHID_INIT, nonce, sizeof (nonce), resp,\n       &resplen) == U2FH_OK)\n    {\n      int offs = sizeof (nonce);\n      /* the response has to be atleast 17 bytes, if it's more we discard that */\n      if (resplen < 17)\n\t{\n\t  return U2FH_SIZE_ERROR;\n\t}\n\n      /* incoming and outgoing nonce has to match */\n      if (memcmp (nonce, resp, sizeof (nonce)) != 0)\n\t{\n\t  return U2FH_TRANSPORT_ERROR;\n\t}\n\n      dev->cid =\n\tresp[offs] << 24 | resp[offs + 1] << 16 | resp[offs +\n\t\t\t\t\t\t       2] << 8 | resp[offs +\n\t\t\t\t\t\t\t\t      3];\n      offs += 4;\n      dev->versionInterface = resp[offs++];\n      dev->versionMajor = resp[offs++];\n      dev->versionMinor = resp[offs++];\n      dev->versionBuild = resp[offs++];\n      dev->capFlags = resp[offs++];\n    }\n  else\n    {\n      return U2FH_TRANSPORT_ERROR;\n    }\n  return U2FH_OK;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -14,17 +14,29 @@\n       (devs, dev->id, U2FHID_INIT, nonce, sizeof (nonce), resp,\n        &resplen) == U2FH_OK)\n     {\n-      U2FHID_INIT_RESP initresp;\n-      if (resplen > sizeof (initresp))\n+      int offs = sizeof (nonce);\n+      /* the response has to be atleast 17 bytes, if it's more we discard that */\n+      if (resplen < 17)\n \t{\n-\t  return U2FH_MEMORY_ERROR;\n+\t  return U2FH_SIZE_ERROR;\n \t}\n-      memcpy (&initresp, resp, resplen);\n-      dev->cid = initresp.cid;\n-      dev->versionInterface = initresp.versionInterface;\n-      dev->versionMajor = initresp.versionMajor;\n-      dev->versionMinor = initresp.versionMinor;\n-      dev->capFlags = initresp.capFlags;\n+\n+      /* incoming and outgoing nonce has to match */\n+      if (memcmp (nonce, resp, sizeof (nonce)) != 0)\n+\t{\n+\t  return U2FH_TRANSPORT_ERROR;\n+\t}\n+\n+      dev->cid =\n+\tresp[offs] << 24 | resp[offs + 1] << 16 | resp[offs +\n+\t\t\t\t\t\t       2] << 8 | resp[offs +\n+\t\t\t\t\t\t\t\t      3];\n+      offs += 4;\n+      dev->versionInterface = resp[offs++];\n+      dev->versionMajor = resp[offs++];\n+      dev->versionMinor = resp[offs++];\n+      dev->versionBuild = resp[offs++];\n+      dev->capFlags = resp[offs++];\n     }\n   else\n     {",
        "diff_line_info": {
            "deleted_lines": [
                "      U2FHID_INIT_RESP initresp;",
                "      if (resplen > sizeof (initresp))",
                "\t  return U2FH_MEMORY_ERROR;",
                "      memcpy (&initresp, resp, resplen);",
                "      dev->cid = initresp.cid;",
                "      dev->versionInterface = initresp.versionInterface;",
                "      dev->versionMajor = initresp.versionMajor;",
                "      dev->versionMinor = initresp.versionMinor;",
                "      dev->capFlags = initresp.capFlags;"
            ],
            "added_lines": [
                "      int offs = sizeof (nonce);",
                "      /* the response has to be atleast 17 bytes, if it's more we discard that */",
                "      if (resplen < 17)",
                "\t  return U2FH_SIZE_ERROR;",
                "",
                "      /* incoming and outgoing nonce has to match */",
                "      if (memcmp (nonce, resp, sizeof (nonce)) != 0)",
                "\t{",
                "\t  return U2FH_TRANSPORT_ERROR;",
                "\t}",
                "",
                "      dev->cid =",
                "\tresp[offs] << 24 | resp[offs + 1] << 16 | resp[offs +",
                "\t\t\t\t\t\t       2] << 8 | resp[offs +",
                "\t\t\t\t\t\t\t\t      3];",
                "      offs += 4;",
                "      dev->versionInterface = resp[offs++];",
                "      dev->versionMajor = resp[offs++];",
                "      dev->versionMinor = resp[offs++];",
                "      dev->versionBuild = resp[offs++];",
                "      dev->capFlags = resp[offs++];"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-11459",
        "func_name": "GNOME/evince/tiff_document_render",
        "description": "The tiff_document_render() and tiff_document_get_thumbnail() functions in the TIFF document backend in GNOME Evince through 3.32.0 did not handle errors from TIFFReadRGBAImageOriented(), leading to uninitialized memory use when processing certain TIFF image files.",
        "git_url": "https://github.com/GNOME/evince/commit/3e38d5ad724a042eebadcba8c2d57b0f48b7a8c7",
        "commit_title": "tiff: Handle failure from TIFFReadRGBAImageOriented",
        "commit_text": " The TIFFReadRGBAImageOriented function returns zero if it was unable to read the image. Return NULL in this case instead of displaying uninitialized memory.  Fixes #1129",
        "func_before": "static cairo_surface_t *\ntiff_document_render (EvDocument      *document,\n\t\t      EvRenderContext *rc)\n{\n\tTiffDocument *tiff_document = TIFF_DOCUMENT (document);\n\tint width, height;\n\tint scaled_width, scaled_height;\n\tfloat x_res, y_res;\n\tgint rowstride, bytes;\n\tguchar *pixels = NULL;\n\tguchar *p;\n\tint orientation;\n\tcairo_surface_t *surface;\n\tcairo_surface_t *rotated_surface;\n\tstatic const cairo_user_data_key_t key;\n\t\n\tg_return_val_if_fail (TIFF_IS_DOCUMENT (document), NULL);\n\tg_return_val_if_fail (tiff_document->tiff != NULL, NULL);\n  \n\tpush_handlers ();\n\tif (TIFFSetDirectory (tiff_document->tiff, rc->page->index) != 1) {\n\t\tpop_handlers ();\n\t\tg_warning(\"Failed to select page %d\", rc->page->index);\n\t\treturn NULL;\n\t}\n\n\tif (!TIFFGetField (tiff_document->tiff, TIFFTAG_IMAGEWIDTH, &width)) {\n\t\tpop_handlers ();\n\t\tg_warning(\"Failed to read image width\");\n\t\treturn NULL;\n\t}\n\n\tif (! TIFFGetField (tiff_document->tiff, TIFFTAG_IMAGELENGTH, &height)) {\n\t\tpop_handlers ();\n\t\tg_warning(\"Failed to read image height\");\n\t\treturn NULL;\n\t}\n\n\tif (! TIFFGetField (tiff_document->tiff, TIFFTAG_ORIENTATION, &orientation)) {\n\t\torientation = ORIENTATION_TOPLEFT;\n\t}\n\n\ttiff_document_get_resolution (tiff_document, &x_res, &y_res);\n\t\n\tpop_handlers ();\n  \n\t/* Sanity check the doc */\n\tif (width <= 0 || height <= 0) {\n\t\tg_warning(\"Invalid width or height.\");\n\t\treturn NULL;\n\t}\n\n\trowstride = cairo_format_stride_for_width (CAIRO_FORMAT_RGB24, width);\n\tif (rowstride / 4 != width) {\n\t\tg_warning(\"Overflow while rendering document.\");\n\t\t/* overflow, or cairo was changed in an unsupported way */\n\t\treturn NULL;                \n\t}\n\t\n\tif (height >= INT_MAX / rowstride) {\n\t\tg_warning(\"Overflow while rendering document.\");\n\t\t/* overflow */\n\t\treturn NULL;\n\t}\n\tbytes = height * rowstride;\n\t\n\tpixels = g_try_malloc (bytes);\n\tif (!pixels) {\n\t\tg_warning(\"Failed to allocate memory for rendering.\");\n\t\treturn NULL;\n\t}\n\t\n\tsurface = cairo_image_surface_create_for_data (pixels,\n\t\t\t\t\t\t       CAIRO_FORMAT_RGB24,\n\t\t\t\t\t\t       width, height,\n\t\t\t\t\t\t       rowstride);\n\tcairo_surface_set_user_data (surface, &key,\n\t\t\t\t     pixels, (cairo_destroy_func_t)g_free);\n\n\tTIFFReadRGBAImageOriented (tiff_document->tiff,\n\t\t\t\t   width, height,\n\t\t\t\t   (uint32 *)pixels,\n\t\t\t\t   orientation, 0);\n\tpop_handlers ();\n\n\t/* Convert the format returned by libtiff to\n\t* what cairo expects\n\t*/\n\tp = pixels;\n\twhile (p < pixels + bytes) {\n\t\tguint32 *pixel = (guint32*)p;\n\t\tguint8 r = TIFFGetR(*pixel);\n\t\tguint8 g = TIFFGetG(*pixel);\n\t\tguint8 b = TIFFGetB(*pixel);\n\t\tguint8 a = TIFFGetA(*pixel);\n\n\t\t*pixel = (a << 24) | (r << 16) | (g << 8) | b;\n\n\t\tp += 4;\n\t}\n\n\tev_render_context_compute_scaled_size (rc, width, height * (x_res / y_res),\n\t\t\t\t\t       &scaled_width, &scaled_height);\n\trotated_surface = ev_document_misc_surface_rotate_and_scale (surface,\n\t\t\t\t\t\t\t\t     scaled_width, scaled_height,\n\t\t\t\t\t\t\t\t     rc->rotation);\n\tcairo_surface_destroy (surface);\n\t\n\treturn rotated_surface;\n}",
        "func": "static cairo_surface_t *\ntiff_document_render (EvDocument      *document,\n\t\t      EvRenderContext *rc)\n{\n\tTiffDocument *tiff_document = TIFF_DOCUMENT (document);\n\tint width, height;\n\tint scaled_width, scaled_height;\n\tfloat x_res, y_res;\n\tgint rowstride, bytes;\n\tguchar *pixels = NULL;\n\tguchar *p;\n\tint orientation;\n\tcairo_surface_t *surface;\n\tcairo_surface_t *rotated_surface;\n\tstatic const cairo_user_data_key_t key;\n\t\n\tg_return_val_if_fail (TIFF_IS_DOCUMENT (document), NULL);\n\tg_return_val_if_fail (tiff_document->tiff != NULL, NULL);\n  \n\tpush_handlers ();\n\tif (TIFFSetDirectory (tiff_document->tiff, rc->page->index) != 1) {\n\t\tpop_handlers ();\n\t\tg_warning(\"Failed to select page %d\", rc->page->index);\n\t\treturn NULL;\n\t}\n\n\tif (!TIFFGetField (tiff_document->tiff, TIFFTAG_IMAGEWIDTH, &width)) {\n\t\tpop_handlers ();\n\t\tg_warning(\"Failed to read image width\");\n\t\treturn NULL;\n\t}\n\n\tif (! TIFFGetField (tiff_document->tiff, TIFFTAG_IMAGELENGTH, &height)) {\n\t\tpop_handlers ();\n\t\tg_warning(\"Failed to read image height\");\n\t\treturn NULL;\n\t}\n\n\tif (! TIFFGetField (tiff_document->tiff, TIFFTAG_ORIENTATION, &orientation)) {\n\t\torientation = ORIENTATION_TOPLEFT;\n\t}\n\n\ttiff_document_get_resolution (tiff_document, &x_res, &y_res);\n\t\n\tpop_handlers ();\n  \n\t/* Sanity check the doc */\n\tif (width <= 0 || height <= 0) {\n\t\tg_warning(\"Invalid width or height.\");\n\t\treturn NULL;\n\t}\n\n\trowstride = cairo_format_stride_for_width (CAIRO_FORMAT_RGB24, width);\n\tif (rowstride / 4 != width) {\n\t\tg_warning(\"Overflow while rendering document.\");\n\t\t/* overflow, or cairo was changed in an unsupported way */\n\t\treturn NULL;                \n\t}\n\t\n\tif (height >= INT_MAX / rowstride) {\n\t\tg_warning(\"Overflow while rendering document.\");\n\t\t/* overflow */\n\t\treturn NULL;\n\t}\n\tbytes = height * rowstride;\n\t\n\tpixels = g_try_malloc (bytes);\n\tif (!pixels) {\n\t\tg_warning(\"Failed to allocate memory for rendering.\");\n\t\treturn NULL;\n\t}\n\n\tif (!TIFFReadRGBAImageOriented (tiff_document->tiff,\n\t\t\t\t\twidth, height,\n\t\t\t\t\t(uint32 *)pixels,\n\t\t\t\t\torientation, 0)) {\n\t\tg_warning (\"Failed to read TIFF image.\");\n\t\tg_free (pixels);\n\t\treturn NULL;\n\t}\n\n\tsurface = cairo_image_surface_create_for_data (pixels,\n\t\t\t\t\t\t       CAIRO_FORMAT_RGB24,\n\t\t\t\t\t\t       width, height,\n\t\t\t\t\t\t       rowstride);\n\tcairo_surface_set_user_data (surface, &key,\n\t\t\t\t     pixels, (cairo_destroy_func_t)g_free);\n\tpop_handlers ();\n\n\t/* Convert the format returned by libtiff to\n\t* what cairo expects\n\t*/\n\tp = pixels;\n\twhile (p < pixels + bytes) {\n\t\tguint32 *pixel = (guint32*)p;\n\t\tguint8 r = TIFFGetR(*pixel);\n\t\tguint8 g = TIFFGetG(*pixel);\n\t\tguint8 b = TIFFGetB(*pixel);\n\t\tguint8 a = TIFFGetA(*pixel);\n\n\t\t*pixel = (a << 24) | (r << 16) | (g << 8) | b;\n\n\t\tp += 4;\n\t}\n\n\tev_render_context_compute_scaled_size (rc, width, height * (x_res / y_res),\n\t\t\t\t\t       &scaled_width, &scaled_height);\n\trotated_surface = ev_document_misc_surface_rotate_and_scale (surface,\n\t\t\t\t\t\t\t\t     scaled_width, scaled_height,\n\t\t\t\t\t\t\t\t     rc->rotation);\n\tcairo_surface_destroy (surface);\n\t\n\treturn rotated_surface;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -69,18 +69,22 @@\n \t\tg_warning(\"Failed to allocate memory for rendering.\");\n \t\treturn NULL;\n \t}\n-\t\n+\n+\tif (!TIFFReadRGBAImageOriented (tiff_document->tiff,\n+\t\t\t\t\twidth, height,\n+\t\t\t\t\t(uint32 *)pixels,\n+\t\t\t\t\torientation, 0)) {\n+\t\tg_warning (\"Failed to read TIFF image.\");\n+\t\tg_free (pixels);\n+\t\treturn NULL;\n+\t}\n+\n \tsurface = cairo_image_surface_create_for_data (pixels,\n \t\t\t\t\t\t       CAIRO_FORMAT_RGB24,\n \t\t\t\t\t\t       width, height,\n \t\t\t\t\t\t       rowstride);\n \tcairo_surface_set_user_data (surface, &key,\n \t\t\t\t     pixels, (cairo_destroy_func_t)g_free);\n-\n-\tTIFFReadRGBAImageOriented (tiff_document->tiff,\n-\t\t\t\t   width, height,\n-\t\t\t\t   (uint32 *)pixels,\n-\t\t\t\t   orientation, 0);\n \tpop_handlers ();\n \n \t/* Convert the format returned by libtiff to",
        "diff_line_info": {
            "deleted_lines": [
                "\t",
                "",
                "\tTIFFReadRGBAImageOriented (tiff_document->tiff,",
                "\t\t\t\t   width, height,",
                "\t\t\t\t   (uint32 *)pixels,",
                "\t\t\t\t   orientation, 0);"
            ],
            "added_lines": [
                "",
                "\tif (!TIFFReadRGBAImageOriented (tiff_document->tiff,",
                "\t\t\t\t\twidth, height,",
                "\t\t\t\t\t(uint32 *)pixels,",
                "\t\t\t\t\torientation, 0)) {",
                "\t\tg_warning (\"Failed to read TIFF image.\");",
                "\t\tg_free (pixels);",
                "\t\treturn NULL;",
                "\t}",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2019-11459",
        "func_name": "GNOME/evince/tiff_document_get_thumbnail",
        "description": "The tiff_document_render() and tiff_document_get_thumbnail() functions in the TIFF document backend in GNOME Evince through 3.32.0 did not handle errors from TIFFReadRGBAImageOriented(), leading to uninitialized memory use when processing certain TIFF image files.",
        "git_url": "https://github.com/GNOME/evince/commit/3e38d5ad724a042eebadcba8c2d57b0f48b7a8c7",
        "commit_title": "tiff: Handle failure from TIFFReadRGBAImageOriented",
        "commit_text": " The TIFFReadRGBAImageOriented function returns zero if it was unable to read the image. Return NULL in this case instead of displaying uninitialized memory.  Fixes #1129",
        "func_before": "static GdkPixbuf *\ntiff_document_get_thumbnail (EvDocument      *document,\n\t\t\t     EvRenderContext *rc)\n{\n\tTiffDocument *tiff_document = TIFF_DOCUMENT (document);\n\tint width, height;\n\tint scaled_width, scaled_height;\n\tfloat x_res, y_res;\n\tgint rowstride, bytes;\n\tguchar *pixels = NULL;\n\tGdkPixbuf *pixbuf;\n\tGdkPixbuf *scaled_pixbuf;\n\tGdkPixbuf *rotated_pixbuf;\n\t\n\tpush_handlers ();\n\tif (TIFFSetDirectory (tiff_document->tiff, rc->page->index) != 1) {\n\t\tpop_handlers ();\n\t\treturn NULL;\n\t}\n\n\tif (!TIFFGetField (tiff_document->tiff, TIFFTAG_IMAGEWIDTH, &width)) {\n\t\tpop_handlers ();\n\t\treturn NULL;\n\t}\n\n\tif (! TIFFGetField (tiff_document->tiff, TIFFTAG_IMAGELENGTH, &height)) {\n\t\tpop_handlers ();\n\t\treturn NULL;\n\t}\n\n\ttiff_document_get_resolution (tiff_document, &x_res, &y_res);\n\t\n\tpop_handlers ();\n  \n\t/* Sanity check the doc */\n\tif (width <= 0 || height <= 0)\n\t\treturn NULL;                \n\n\tif (width >= INT_MAX / 4)\n\t\t/* overflow */\n\t\treturn NULL;                \n\trowstride = width * 4;\n        \n\tif (height >= INT_MAX / rowstride)\n\t\t/* overflow */\n\t\treturn NULL;                \n\tbytes = height * rowstride;\n\t\n\tpixels = g_try_malloc (bytes);\n\tif (!pixels)\n\t\treturn NULL;\n\t\n\tpixbuf = gdk_pixbuf_new_from_data (pixels, GDK_COLORSPACE_RGB, TRUE, 8, \n\t\t\t\t\t   width, height, rowstride,\n\t\t\t\t\t   (GdkPixbufDestroyNotify) g_free, NULL);\n\tTIFFReadRGBAImageOriented (tiff_document->tiff,\n\t\t\t\t   width, height,\n\t\t\t\t   (uint32 *)pixels,\n\t\t\t\t   ORIENTATION_TOPLEFT, 0);\n\tpop_handlers ();\n\n\tev_render_context_compute_scaled_size (rc, width, height * (x_res / y_res),\n\t\t\t\t\t       &scaled_width, &scaled_height);\n\tscaled_pixbuf = gdk_pixbuf_scale_simple (pixbuf,\n\t\t\t\t\t\t scaled_width, scaled_height,\n\t\t\t\t\t\t GDK_INTERP_BILINEAR);\n\tg_object_unref (pixbuf);\n\t\n\trotated_pixbuf = gdk_pixbuf_rotate_simple (scaled_pixbuf, 360 - rc->rotation);\n\tg_object_unref (scaled_pixbuf);\n\t\n\treturn rotated_pixbuf;\n}",
        "func": "static GdkPixbuf *\ntiff_document_get_thumbnail (EvDocument      *document,\n\t\t\t     EvRenderContext *rc)\n{\n\tTiffDocument *tiff_document = TIFF_DOCUMENT (document);\n\tint width, height;\n\tint scaled_width, scaled_height;\n\tfloat x_res, y_res;\n\tgint rowstride, bytes;\n\tguchar *pixels = NULL;\n\tGdkPixbuf *pixbuf;\n\tGdkPixbuf *scaled_pixbuf;\n\tGdkPixbuf *rotated_pixbuf;\n\t\n\tpush_handlers ();\n\tif (TIFFSetDirectory (tiff_document->tiff, rc->page->index) != 1) {\n\t\tpop_handlers ();\n\t\treturn NULL;\n\t}\n\n\tif (!TIFFGetField (tiff_document->tiff, TIFFTAG_IMAGEWIDTH, &width)) {\n\t\tpop_handlers ();\n\t\treturn NULL;\n\t}\n\n\tif (! TIFFGetField (tiff_document->tiff, TIFFTAG_IMAGELENGTH, &height)) {\n\t\tpop_handlers ();\n\t\treturn NULL;\n\t}\n\n\ttiff_document_get_resolution (tiff_document, &x_res, &y_res);\n\t\n\tpop_handlers ();\n  \n\t/* Sanity check the doc */\n\tif (width <= 0 || height <= 0)\n\t\treturn NULL;                \n\n\tif (width >= INT_MAX / 4)\n\t\t/* overflow */\n\t\treturn NULL;                \n\trowstride = width * 4;\n        \n\tif (height >= INT_MAX / rowstride)\n\t\t/* overflow */\n\t\treturn NULL;                \n\tbytes = height * rowstride;\n\t\n\tpixels = g_try_malloc (bytes);\n\tif (!pixels)\n\t\treturn NULL;\n\t\n\tif (!TIFFReadRGBAImageOriented (tiff_document->tiff,\n\t\t\t\t\twidth, height,\n\t\t\t\t\t(uint32 *)pixels,\n\t\t\t\t\tORIENTATION_TOPLEFT, 0)) {\n\t\tg_free (pixels);\n\t\treturn NULL;\n\t}\n\n\tpixbuf = gdk_pixbuf_new_from_data (pixels, GDK_COLORSPACE_RGB, TRUE, 8, \n\t\t\t\t\t   width, height, rowstride,\n\t\t\t\t\t   (GdkPixbufDestroyNotify) g_free, NULL);\n\tpop_handlers ();\n\n\tev_render_context_compute_scaled_size (rc, width, height * (x_res / y_res),\n\t\t\t\t\t       &scaled_width, &scaled_height);\n\tscaled_pixbuf = gdk_pixbuf_scale_simple (pixbuf,\n\t\t\t\t\t\t scaled_width, scaled_height,\n\t\t\t\t\t\t GDK_INTERP_BILINEAR);\n\tg_object_unref (pixbuf);\n\t\n\trotated_pixbuf = gdk_pixbuf_rotate_simple (scaled_pixbuf, 360 - rc->rotation);\n\tg_object_unref (scaled_pixbuf);\n\t\n\treturn rotated_pixbuf;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -50,13 +50,17 @@\n \tif (!pixels)\n \t\treturn NULL;\n \t\n+\tif (!TIFFReadRGBAImageOriented (tiff_document->tiff,\n+\t\t\t\t\twidth, height,\n+\t\t\t\t\t(uint32 *)pixels,\n+\t\t\t\t\tORIENTATION_TOPLEFT, 0)) {\n+\t\tg_free (pixels);\n+\t\treturn NULL;\n+\t}\n+\n \tpixbuf = gdk_pixbuf_new_from_data (pixels, GDK_COLORSPACE_RGB, TRUE, 8, \n \t\t\t\t\t   width, height, rowstride,\n \t\t\t\t\t   (GdkPixbufDestroyNotify) g_free, NULL);\n-\tTIFFReadRGBAImageOriented (tiff_document->tiff,\n-\t\t\t\t   width, height,\n-\t\t\t\t   (uint32 *)pixels,\n-\t\t\t\t   ORIENTATION_TOPLEFT, 0);\n \tpop_handlers ();\n \n \tev_render_context_compute_scaled_size (rc, width, height * (x_res / y_res),",
        "diff_line_info": {
            "deleted_lines": [
                "\tTIFFReadRGBAImageOriented (tiff_document->tiff,",
                "\t\t\t\t   width, height,",
                "\t\t\t\t   (uint32 *)pixels,",
                "\t\t\t\t   ORIENTATION_TOPLEFT, 0);"
            ],
            "added_lines": [
                "\tif (!TIFFReadRGBAImageOriented (tiff_document->tiff,",
                "\t\t\t\t\twidth, height,",
                "\t\t\t\t\t(uint32 *)pixels,",
                "\t\t\t\t\tORIENTATION_TOPLEFT, 0)) {",
                "\t\tg_free (pixels);",
                "\t\treturn NULL;",
                "\t}",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2021-37682",
        "func_name": "tensorflow/Prepare",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions all TFLite operations that use quantization can be made to use unitialized values. [For example](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/lite/kernels/depthwise_conv.cc#L198-L200). The issue stems from the fact that `quantization.params` is only valid if `quantization.type` is different that `kTfLiteNoQuantization`. However, these checks are missing in large parts of the code. We have patched the issue in GitHub commits 537bc7c723439b9194a358f64d871dd326c18887, 4a91f2069f7145aab6ba2d8cfe41be8a110c18a5 and 8933b8a21280696ab119b63263babdb54c298538. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/537bc7c723439b9194a358f64d871dd326c18887",
        "commit_title": "Fix a null pointer exception caused by branching on uninitialized data.",
        "commit_text": " This is due to not checking that the params for the quantization exists. If there is no quantization, we should not access the `.params` field.  PiperOrigin-RevId: 385163909",
        "func_before": "TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n  const auto* params = reinterpret_cast<TfLiteSVDFParams*>(node->builtin_data);\n  OpData* op_data = reinterpret_cast<OpData*>(node->user_data);\n  int scratch_tensor_index = op_data->scratch_tensor_index;\n\n  // Check we have all the inputs and outputs we need.\n  TF_LITE_ENSURE_EQ(context, node->outputs->size, 1);\n  TF_LITE_ENSURE_EQ(context, node->inputs->size, 5);\n\n  const TfLiteTensor* input;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n  const TfLiteTensor* weights_feature;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kWeightsFeatureTensor,\n                                          &weights_feature));\n  const TfLiteTensor* weights_time;\n  TF_LITE_ENSURE_OK(\n      context, GetInputSafe(context, node, kWeightsTimeTensor, &weights_time));\n\n  TF_LITE_ENSURE(context,\n                 input->type == kTfLiteFloat32 || input->type == kTfLiteInt8);\n\n  // Check all the parameters of tensor match within themselves and match the\n  // input configuration.\n  const int rank = params->rank;\n  const int batch_size = input->dims->data[0];\n  const int num_filters = weights_feature->dims->data[0];\n  TF_LITE_ENSURE(context, rank != 0);\n  TF_LITE_ENSURE_EQ(context, num_filters % rank, 0);\n  const int num_units = num_filters / rank;\n  const int memory_size = weights_time->dims->data[1];\n  TF_LITE_ENSURE_EQ(context, input->dims->data[1],\n                    weights_feature->dims->data[1]);\n  TF_LITE_ENSURE_EQ(context, weights_time->dims->data[0], num_filters);\n\n  const TfLiteTensor* bias = GetOptionalInputTensor(context, node, kBiasTensor);\n  if (bias) {\n    TF_LITE_ENSURE_EQ(context, bias->dims->data[0], num_units);\n  }\n\n  const TfLiteTensor* state;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kStateTensor, &state));\n  TfLiteTensor* output;\n  TF_LITE_ENSURE_OK(context,\n                    GetOutputSafe(context, node, kOutputTensor, &output));\n\n  // Check the shape of input state tensors.\n  TF_LITE_ENSURE_EQ(context, NumDimensions(state), 2);\n  TF_LITE_ENSURE_EQ(context, SizeOfDimension(state, 0), batch_size);\n  TF_LITE_ENSURE_EQ(context, SizeOfDimension(state, 1),\n                    memory_size * num_filters);\n\n  // Resize output.\n  TfLiteIntArray* output_size_array = TfLiteIntArrayCreate(2);\n  output_size_array->data[0] = batch_size;\n  output_size_array->data[1] = num_units;\n  TF_LITE_ENSURE_OK(context,\n                    context->ResizeTensor(context, output, output_size_array));\n\n  // The weights are of consistent type, so it suffices to check one.\n  const bool is_hybrid_op = IsHybridOp(input, weights_feature);\n  const bool is_full_integer = input->type == kTfLiteInt8;\n\n  // Resize scratch.\n  TfLiteIntArrayFree(node->temporaries);\n  if (is_hybrid_op) {\n    node->temporaries = TfLiteIntArrayCreate(6);\n  } else if (is_full_integer) {\n    node->temporaries = TfLiteIntArrayCreate(2);\n  } else {\n    node->temporaries = TfLiteIntArrayCreate(1);\n  }\n  node->temporaries->data[0] = scratch_tensor_index;\n\n  TfLiteIntArray* scratch_size_array = TfLiteIntArrayCreate(2);\n  scratch_size_array->data[0] = batch_size;\n  scratch_size_array->data[1] = num_filters;\n\n  TfLiteTensor* scratch_tensor;\n  TF_LITE_ENSURE_OK(\n      context, GetTemporarySafe(context, node, /*index=*/0, &scratch_tensor));\n\n  // The scratch buffer is of type int32 for full integer svdf and it's of type\n  // float32 for hybrid and float case.\n  if (is_full_integer) {\n    scratch_tensor->type = kTfLiteInt32;\n  } else {\n    scratch_tensor->type = kTfLiteFloat32;\n  }\n  scratch_tensor->allocation_type = kTfLiteArenaRw;\n  TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, scratch_tensor,\n                                                   scratch_size_array));\n\n  if (is_hybrid_op) {\n    op_data->compute_row_sums = true;\n    // Tell interpreter to allocate temporary tensors to store quantized values\n    // of input tensors.\n    node->temporaries->data[1] = scratch_tensor_index + 1;\n    TfLiteTensor* input_quantized;\n    TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, /*index=*/1,\n                                                &input_quantized));\n    input_quantized->type = weights_feature->type;\n    input_quantized->allocation_type = kTfLiteArenaRw;\n    if (!TfLiteIntArrayEqual(input_quantized->dims, input->dims)) {\n      TfLiteIntArray* input_quantized_size = TfLiteIntArrayCopy(input->dims);\n      TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, input_quantized,\n                                                       input_quantized_size));\n    }\n\n    // Tell interpreter to allocate temporary tensors to store scaling factors.\n    node->temporaries->data[2] = scratch_tensor_index + 2;\n    TfLiteTensor* scaling_factors;\n    TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, /*index=*/2,\n                                                &scaling_factors));\n    scaling_factors->type = kTfLiteFloat32;\n    scaling_factors->allocation_type = kTfLiteArenaRw;\n    int scaling_dims[1] = {batch_size};\n    if (!TfLiteIntArrayEqualsArray(scaling_factors->dims, 1, scaling_dims)) {\n      TfLiteIntArray* scaling_factors_size = TfLiteIntArrayCreate(1);\n      scaling_factors_size->data[0] = batch_size;\n      TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, scaling_factors,\n                                                       scaling_factors_size));\n    }\n\n    // Used to store dequantized weights_time matrix for hybrid computation of\n    // matmul(state, weights_time), which occurs in floating point.\n    node->temporaries->data[3] = scratch_tensor_index + 3;\n    TfLiteTensor* float_weights_time;\n    TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, /*index=*/3,\n                                                &float_weights_time));\n    float_weights_time->type = kTfLiteFloat32;\n    // Persistent so that we can compute the dequantized weights only once.\n    float_weights_time->allocation_type = kTfLiteArenaRwPersistent;\n    if (!TfLiteIntArrayEqual(float_weights_time->dims, weights_time->dims)) {\n      TfLiteIntArray* float_weights_time_size =\n          TfLiteIntArrayCopy(weights_time->dims);\n      TF_LITE_ENSURE_OK(context,\n                        context->ResizeTensor(context, float_weights_time,\n                                              float_weights_time_size));\n    }\n\n    node->temporaries->data[4] = scratch_tensor_index + 4;\n    TfLiteTensor* zero_points;\n    TF_LITE_ENSURE_OK(\n        context, GetTemporarySafe(context, node, /*index=*/4, &zero_points));\n    zero_points->type = kTfLiteFloat32;\n    zero_points->allocation_type = kTfLiteArenaRw;\n    int zero_points_dims[1] = {batch_size};\n    if (!TfLiteIntArrayEqualsArray(zero_points->dims, 1, zero_points_dims)) {\n      TfLiteIntArray* zero_points_size = TfLiteIntArrayCreate(1);\n      zero_points_size->data[0] = zero_points_dims[0];\n      TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, zero_points,\n                                                       zero_points_size));\n    }\n\n    node->temporaries->data[5] = scratch_tensor_index + 5;\n    TfLiteTensor* row_sums;\n    TF_LITE_ENSURE_OK(context,\n                      GetTemporarySafe(context, node, /*index=*/5, &row_sums));\n    row_sums->type = kTfLiteFloat32;\n    row_sums->allocation_type = kTfLiteArenaRwPersistent;\n    int row_sums_dims[1] = {num_filters};\n    if (!TfLiteIntArrayEqualsArray(row_sums->dims, 1, row_sums_dims)) {\n      TfLiteIntArray* row_sums_size = TfLiteIntArrayCreate(1);\n      row_sums_size->data[0] = row_sums_dims[0];\n      TF_LITE_ENSURE_OK(\n          context, context->ResizeTensor(context, row_sums, row_sums_size));\n    }\n  }\n  if (is_full_integer) {\n    // Allocated one extra tensor.\n    TfLiteIntArray* output_temp_size_array = TfLiteIntArrayCreate(2);\n    output_temp_size_array->data[0] = num_units;\n    output_temp_size_array->data[1] = batch_size;\n    node->temporaries->data[1] = scratch_tensor_index + 1;\n    TfLiteTensor* output_temp;\n    TF_LITE_ENSURE_OK(\n        context, GetTemporarySafe(context, node, /*index=*/1, &output_temp));\n    output_temp->type = kTfLiteInt32;\n    output_temp->allocation_type = kTfLiteArenaRw;\n    TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, output_temp,\n                                                     output_temp_size_array));\n\n    // Calculate effective scales.\n    auto* input_params =\n        reinterpret_cast<TfLiteAffineQuantization*>(input->quantization.params);\n    auto* weights_feature_params = reinterpret_cast<TfLiteAffineQuantization*>(\n        weights_feature->quantization.params);\n    auto* state_params =\n        reinterpret_cast<TfLiteAffineQuantization*>(state->quantization.params);\n    auto* weight_time_params = reinterpret_cast<TfLiteAffineQuantization*>(\n        weights_time->quantization.params);\n    auto* output_params = reinterpret_cast<TfLiteAffineQuantization*>(\n        output->quantization.params);\n    const double effective_scale_1 = input_params->scale->data[0] *\n                                     weights_feature_params->scale->data[0] /\n                                     state_params->scale->data[0];\n    const double effective_scale_2 = state_params->scale->data[0] *\n                                     weight_time_params->scale->data[0] /\n                                     output_params->scale->data[0];\n    QuantizeMultiplier(effective_scale_1, &op_data->effective_scale_1_a,\n                       &op_data->effective_scale_1_b);\n    QuantizeMultiplier(effective_scale_2, &op_data->effective_scale_2_a,\n                       &op_data->effective_scale_2_b);\n  }\n  return kTfLiteOk;\n}",
        "func": "TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n  const auto* params = reinterpret_cast<TfLiteSVDFParams*>(node->builtin_data);\n  OpData* op_data = reinterpret_cast<OpData*>(node->user_data);\n  int scratch_tensor_index = op_data->scratch_tensor_index;\n\n  // Check we have all the inputs and outputs we need.\n  TF_LITE_ENSURE_EQ(context, node->outputs->size, 1);\n  TF_LITE_ENSURE_EQ(context, node->inputs->size, 5);\n\n  const TfLiteTensor* input;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n  const TfLiteTensor* weights_feature;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kWeightsFeatureTensor,\n                                          &weights_feature));\n  const TfLiteTensor* weights_time;\n  TF_LITE_ENSURE_OK(\n      context, GetInputSafe(context, node, kWeightsTimeTensor, &weights_time));\n\n  TF_LITE_ENSURE(context,\n                 input->type == kTfLiteFloat32 || input->type == kTfLiteInt8);\n\n  // Check all the parameters of tensor match within themselves and match the\n  // input configuration.\n  const int rank = params->rank;\n  const int batch_size = input->dims->data[0];\n  const int num_filters = weights_feature->dims->data[0];\n  TF_LITE_ENSURE(context, rank != 0);\n  TF_LITE_ENSURE_EQ(context, num_filters % rank, 0);\n  const int num_units = num_filters / rank;\n  const int memory_size = weights_time->dims->data[1];\n  TF_LITE_ENSURE_EQ(context, input->dims->data[1],\n                    weights_feature->dims->data[1]);\n  TF_LITE_ENSURE_EQ(context, weights_time->dims->data[0], num_filters);\n\n  const TfLiteTensor* bias = GetOptionalInputTensor(context, node, kBiasTensor);\n  if (bias) {\n    TF_LITE_ENSURE_EQ(context, bias->dims->data[0], num_units);\n  }\n\n  const TfLiteTensor* state;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kStateTensor, &state));\n  TfLiteTensor* output;\n  TF_LITE_ENSURE_OK(context,\n                    GetOutputSafe(context, node, kOutputTensor, &output));\n\n  // Check the shape of input state tensors.\n  TF_LITE_ENSURE_EQ(context, NumDimensions(state), 2);\n  TF_LITE_ENSURE_EQ(context, SizeOfDimension(state, 0), batch_size);\n  TF_LITE_ENSURE_EQ(context, SizeOfDimension(state, 1),\n                    memory_size * num_filters);\n\n  // Resize output.\n  TfLiteIntArray* output_size_array = TfLiteIntArrayCreate(2);\n  output_size_array->data[0] = batch_size;\n  output_size_array->data[1] = num_units;\n  TF_LITE_ENSURE_OK(context,\n                    context->ResizeTensor(context, output, output_size_array));\n\n  // The weights are of consistent type, so it suffices to check one.\n  const bool is_hybrid_op = IsHybridOp(input, weights_feature);\n  const bool is_full_integer = input->type == kTfLiteInt8;\n\n  // Resize scratch.\n  TfLiteIntArrayFree(node->temporaries);\n  if (is_hybrid_op) {\n    node->temporaries = TfLiteIntArrayCreate(6);\n  } else if (is_full_integer) {\n    node->temporaries = TfLiteIntArrayCreate(2);\n  } else {\n    node->temporaries = TfLiteIntArrayCreate(1);\n  }\n  node->temporaries->data[0] = scratch_tensor_index;\n\n  TfLiteIntArray* scratch_size_array = TfLiteIntArrayCreate(2);\n  scratch_size_array->data[0] = batch_size;\n  scratch_size_array->data[1] = num_filters;\n\n  TfLiteTensor* scratch_tensor;\n  TF_LITE_ENSURE_OK(\n      context, GetTemporarySafe(context, node, /*index=*/0, &scratch_tensor));\n\n  // The scratch buffer is of type int32 for full integer svdf and it's of type\n  // float32 for hybrid and float case.\n  if (is_full_integer) {\n    scratch_tensor->type = kTfLiteInt32;\n  } else {\n    scratch_tensor->type = kTfLiteFloat32;\n  }\n  scratch_tensor->allocation_type = kTfLiteArenaRw;\n  TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, scratch_tensor,\n                                                   scratch_size_array));\n\n  if (is_hybrid_op) {\n    op_data->compute_row_sums = true;\n    // Tell interpreter to allocate temporary tensors to store quantized values\n    // of input tensors.\n    node->temporaries->data[1] = scratch_tensor_index + 1;\n    TfLiteTensor* input_quantized;\n    TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, /*index=*/1,\n                                                &input_quantized));\n    input_quantized->type = weights_feature->type;\n    input_quantized->allocation_type = kTfLiteArenaRw;\n    if (!TfLiteIntArrayEqual(input_quantized->dims, input->dims)) {\n      TfLiteIntArray* input_quantized_size = TfLiteIntArrayCopy(input->dims);\n      TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, input_quantized,\n                                                       input_quantized_size));\n    }\n\n    // Tell interpreter to allocate temporary tensors to store scaling factors.\n    node->temporaries->data[2] = scratch_tensor_index + 2;\n    TfLiteTensor* scaling_factors;\n    TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, /*index=*/2,\n                                                &scaling_factors));\n    scaling_factors->type = kTfLiteFloat32;\n    scaling_factors->allocation_type = kTfLiteArenaRw;\n    int scaling_dims[1] = {batch_size};\n    if (!TfLiteIntArrayEqualsArray(scaling_factors->dims, 1, scaling_dims)) {\n      TfLiteIntArray* scaling_factors_size = TfLiteIntArrayCreate(1);\n      scaling_factors_size->data[0] = batch_size;\n      TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, scaling_factors,\n                                                       scaling_factors_size));\n    }\n\n    // Used to store dequantized weights_time matrix for hybrid computation of\n    // matmul(state, weights_time), which occurs in floating point.\n    node->temporaries->data[3] = scratch_tensor_index + 3;\n    TfLiteTensor* float_weights_time;\n    TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, /*index=*/3,\n                                                &float_weights_time));\n    float_weights_time->type = kTfLiteFloat32;\n    // Persistent so that we can compute the dequantized weights only once.\n    float_weights_time->allocation_type = kTfLiteArenaRwPersistent;\n    if (!TfLiteIntArrayEqual(float_weights_time->dims, weights_time->dims)) {\n      TfLiteIntArray* float_weights_time_size =\n          TfLiteIntArrayCopy(weights_time->dims);\n      TF_LITE_ENSURE_OK(context,\n                        context->ResizeTensor(context, float_weights_time,\n                                              float_weights_time_size));\n    }\n\n    node->temporaries->data[4] = scratch_tensor_index + 4;\n    TfLiteTensor* zero_points;\n    TF_LITE_ENSURE_OK(\n        context, GetTemporarySafe(context, node, /*index=*/4, &zero_points));\n    zero_points->type = kTfLiteFloat32;\n    zero_points->allocation_type = kTfLiteArenaRw;\n    int zero_points_dims[1] = {batch_size};\n    if (!TfLiteIntArrayEqualsArray(zero_points->dims, 1, zero_points_dims)) {\n      TfLiteIntArray* zero_points_size = TfLiteIntArrayCreate(1);\n      zero_points_size->data[0] = zero_points_dims[0];\n      TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, zero_points,\n                                                       zero_points_size));\n    }\n\n    node->temporaries->data[5] = scratch_tensor_index + 5;\n    TfLiteTensor* row_sums;\n    TF_LITE_ENSURE_OK(context,\n                      GetTemporarySafe(context, node, /*index=*/5, &row_sums));\n    row_sums->type = kTfLiteFloat32;\n    row_sums->allocation_type = kTfLiteArenaRwPersistent;\n    int row_sums_dims[1] = {num_filters};\n    if (!TfLiteIntArrayEqualsArray(row_sums->dims, 1, row_sums_dims)) {\n      TfLiteIntArray* row_sums_size = TfLiteIntArrayCreate(1);\n      row_sums_size->data[0] = row_sums_dims[0];\n      TF_LITE_ENSURE_OK(\n          context, context->ResizeTensor(context, row_sums, row_sums_size));\n    }\n  }\n  if (is_full_integer) {\n    // Allocated one extra tensor.\n    TfLiteIntArray* output_temp_size_array = TfLiteIntArrayCreate(2);\n    output_temp_size_array->data[0] = num_units;\n    output_temp_size_array->data[1] = batch_size;\n    node->temporaries->data[1] = scratch_tensor_index + 1;\n    TfLiteTensor* output_temp;\n    TF_LITE_ENSURE_OK(\n        context, GetTemporarySafe(context, node, /*index=*/1, &output_temp));\n    output_temp->type = kTfLiteInt32;\n    output_temp->allocation_type = kTfLiteArenaRw;\n    TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, output_temp,\n                                                     output_temp_size_array));\n\n    // Calculate effective scales.\n    TF_LITE_ENSURE(context, input->quantization.type != kTfLiteNoQuantization);\n    auto* input_params =\n        reinterpret_cast<TfLiteAffineQuantization*>(input->quantization.params);\n    TF_LITE_ENSURE(context,\n                   weights_feature->quantization.type != kTfLiteNoQuantization);\n    auto* weights_feature_params = reinterpret_cast<TfLiteAffineQuantization*>(\n        weights_feature->quantization.params);\n    TF_LITE_ENSURE(context, state->quantization.type != kTfLiteNoQuantization);\n    auto* state_params =\n        reinterpret_cast<TfLiteAffineQuantization*>(state->quantization.params);\n    TF_LITE_ENSURE(context,\n                   weights_time->quantization.type != kTfLiteNoQuantization);\n    auto* weight_time_params = reinterpret_cast<TfLiteAffineQuantization*>(\n        weights_time->quantization.params);\n    TF_LITE_ENSURE(context, output->quantization.type != kTfLiteNoQuantization);\n    auto* output_params = reinterpret_cast<TfLiteAffineQuantization*>(\n        output->quantization.params);\n    const double effective_scale_1 = input_params->scale->data[0] *\n                                     weights_feature_params->scale->data[0] /\n                                     state_params->scale->data[0];\n    const double effective_scale_2 = state_params->scale->data[0] *\n                                     weight_time_params->scale->data[0] /\n                                     output_params->scale->data[0];\n    QuantizeMultiplier(effective_scale_1, &op_data->effective_scale_1_a,\n                       &op_data->effective_scale_1_b);\n    QuantizeMultiplier(effective_scale_2, &op_data->effective_scale_2_a,\n                       &op_data->effective_scale_2_b);\n  }\n  return kTfLiteOk;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -181,14 +181,21 @@\n                                                      output_temp_size_array));\n \n     // Calculate effective scales.\n+    TF_LITE_ENSURE(context, input->quantization.type != kTfLiteNoQuantization);\n     auto* input_params =\n         reinterpret_cast<TfLiteAffineQuantization*>(input->quantization.params);\n+    TF_LITE_ENSURE(context,\n+                   weights_feature->quantization.type != kTfLiteNoQuantization);\n     auto* weights_feature_params = reinterpret_cast<TfLiteAffineQuantization*>(\n         weights_feature->quantization.params);\n+    TF_LITE_ENSURE(context, state->quantization.type != kTfLiteNoQuantization);\n     auto* state_params =\n         reinterpret_cast<TfLiteAffineQuantization*>(state->quantization.params);\n+    TF_LITE_ENSURE(context,\n+                   weights_time->quantization.type != kTfLiteNoQuantization);\n     auto* weight_time_params = reinterpret_cast<TfLiteAffineQuantization*>(\n         weights_time->quantization.params);\n+    TF_LITE_ENSURE(context, output->quantization.type != kTfLiteNoQuantization);\n     auto* output_params = reinterpret_cast<TfLiteAffineQuantization*>(\n         output->quantization.params);\n     const double effective_scale_1 = input_params->scale->data[0] *",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    TF_LITE_ENSURE(context, input->quantization.type != kTfLiteNoQuantization);",
                "    TF_LITE_ENSURE(context,",
                "                   weights_feature->quantization.type != kTfLiteNoQuantization);",
                "    TF_LITE_ENSURE(context, state->quantization.type != kTfLiteNoQuantization);",
                "    TF_LITE_ENSURE(context,",
                "                   weights_time->quantization.type != kTfLiteNoQuantization);",
                "    TF_LITE_ENSURE(context, output->quantization.type != kTfLiteNoQuantization);"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-37682",
        "func_name": "tensorflow/PopulatePrecomputedZPTimesWeightsWithBias",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions all TFLite operations that use quantization can be made to use unitialized values. [For example](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/lite/kernels/depthwise_conv.cc#L198-L200). The issue stems from the fact that `quantization.params` is only valid if `quantization.type` is different that `kTfLiteNoQuantization`. However, these checks are missing in large parts of the code. We have patched the issue in GitHub commits 537bc7c723439b9194a358f64d871dd326c18887, 4a91f2069f7145aab6ba2d8cfe41be8a110c18a5 and 8933b8a21280696ab119b63263babdb54c298538. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/4a91f2069f7145aab6ba2d8cfe41be8a110c18a5",
        "commit_title": "Fix a null pointer exception caused by branching on uninitialized data.",
        "commit_text": " This is due to not checking that the params for the quantization exists. If there is no quantization, we should not access the `.params` field.  PiperOrigin-RevId: 385168337",
        "func_before": "TfLiteStatus PopulatePrecomputedZPTimesWeightsWithBias(TfLiteContext* context,\n                                                       OpData* op_data,\n                                                       TfLiteNode* node) {\n  const TfLiteTensor* input;\n  TF_LITE_ENSURE_OK(\n      context, GetInputSafe(context, node, lstm::full::kInputTensor, &input));\n  const TfLiteTensor* output_state =\n      GetVariableInput(context, node, lstm::full::kOutputStateTensor);\n  TF_LITE_ENSURE(context, output_state != nullptr);\n\n  const int32_t input_zero_point = -input->params.zero_point;\n  const int32_t output_state_zero_point = -output_state->params.zero_point;\n\n  const TfLiteTensor* input_to_input_weights = GetOptionalInputTensor(\n      context, node, lstm::full::kInputToInputWeightsTensor);\n  const TfLiteTensor* input_to_forget_weights;\n  TF_LITE_ENSURE_OK(\n      context,\n      GetInputSafe(context, node, lstm::full::kInputToForgetWeightsTensor,\n                   &input_to_forget_weights));\n  const TfLiteTensor* input_to_cell_weights;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node,\n                                          lstm::full::kInputToCellWeightsTensor,\n                                          &input_to_cell_weights));\n  const TfLiteTensor* input_to_output_weights;\n  TF_LITE_ENSURE_OK(\n      context,\n      GetInputSafe(context, node, lstm::full::kInputToOutputWeightsTensor,\n                   &input_to_output_weights));\n\n  const TfLiteTensor* recurrent_to_input_weights = GetOptionalInputTensor(\n      context, node, lstm::full::kRecurrentToInputWeightsTensor);\n  const TfLiteTensor* recurrent_to_forget_weights;\n  TF_LITE_ENSURE_OK(\n      context,\n      GetInputSafe(context, node, lstm::full::kRecurrentToForgetWeightsTensor,\n                   &recurrent_to_forget_weights));\n  const TfLiteTensor* recurrent_to_cell_weights;\n  TF_LITE_ENSURE_OK(\n      context,\n      GetInputSafe(context, node, lstm::full::kRecurrentToCellWeightsTensor,\n                   &recurrent_to_cell_weights));\n  const TfLiteTensor* recurrent_to_output_weights;\n  TF_LITE_ENSURE_OK(\n      context,\n      GetInputSafe(context, node, lstm::full::kRecurrentToOutputWeightsTensor,\n                   &recurrent_to_output_weights));\n\n  const TfLiteTensor* projection_weights = GetOptionalInputTensor(\n      context, node, lstm::full::kProjectionWeightsTensor);\n  const TfLiteTensor* projection_bias =\n      GetOptionalInputTensor(context, node, lstm::full::kProjectionBiasTensor);\n\n  lstm_eval::IntegerLstmParameter* integer_lstm_params =\n      &op_data->integer_lstm_param;\n\n  const TfLiteTensor* intermediate =\n      &context->tensors[node->intermediates->data[4]];\n  const auto* params =\n      static_cast<TfLiteAffineQuantization*>(intermediate->quantization.params);\n  const int32_t hidden_zp = params->zero_point->data[0];\n\n  // Get bias and perform zero point calculation.\n  // When there is layer normalization, the gate bias does not apply to matmul\n  // directly:\n  //      y = ln(w * x + w * r + w * c) + b.\n  const bool is_layer_norm = op_data->use_layer_norm;\n\n  // Forget gate.\n  const TfLiteTensor* forget_gate_bias =\n      is_layer_norm\n          ? nullptr\n          : GetInput(context, node, lstm::full::kForgetGateBiasTensor);\n  TF_LITE_ENSURE_OK(\n      context,\n      PrecomputeZeroPointTimesWeightWithBias(\n          context, input_zero_point, input_to_forget_weights, forget_gate_bias,\n          &(integer_lstm_params->input_to_forget_effective_bias)));\n\n  TF_LITE_ENSURE_OK(\n      context,\n      PrecomputeZeroPointTimesWeightWithBias(\n          context, output_state_zero_point, recurrent_to_forget_weights,\n          nullptr, &(integer_lstm_params->recurrent_to_forget_effective_bias)));\n\n  // Modulation gate.\n  const TfLiteTensor* cell_gate_bias =\n      is_layer_norm ? nullptr\n                    : GetInput(context, node, lstm::full::kCellGateBiasTensor);\n  TF_LITE_ENSURE_OK(\n      context,\n      PrecomputeZeroPointTimesWeightWithBias(\n          context, input_zero_point, input_to_cell_weights, cell_gate_bias,\n          &(integer_lstm_params->input_to_cell_effective_bias)));\n  TF_LITE_ENSURE_OK(\n      context,\n      PrecomputeZeroPointTimesWeightWithBias(\n          context, output_state_zero_point, recurrent_to_cell_weights, nullptr,\n          &(integer_lstm_params->recurrent_to_cell_effective_bias)));\n\n  // Output gate.\n  const TfLiteTensor* output_gate_bias =\n      is_layer_norm\n          ? nullptr\n          : GetInput(context, node, lstm::full::kOutputGateBiasTensor);\n  TF_LITE_ENSURE_OK(\n      context,\n      PrecomputeZeroPointTimesWeightWithBias(\n          context, input_zero_point, input_to_output_weights, output_gate_bias,\n          &(integer_lstm_params->input_to_output_effective_bias)));\n\n  TF_LITE_ENSURE_OK(\n      context,\n      PrecomputeZeroPointTimesWeightWithBias(\n          context, output_state_zero_point, recurrent_to_output_weights,\n          nullptr, &(integer_lstm_params->recurrent_to_output_effective_bias)));\n\n  // Input gate. The calculation is only meaningful for non-cifg case.\n  const TfLiteTensor* input_gate_bias =\n      is_layer_norm ? nullptr\n                    : GetInput(context, node, lstm::full::kInputGateBiasTensor);\n  TF_LITE_ENSURE_OK(\n      context,\n      PrecomputeZeroPointTimesWeightWithBias(\n          context, input_zero_point, input_to_input_weights, input_gate_bias,\n          &(integer_lstm_params->input_to_input_effective_bias)));\n  TF_LITE_ENSURE_OK(\n      context,\n      PrecomputeZeroPointTimesWeightWithBias(\n          context, output_state_zero_point, recurrent_to_input_weights, nullptr,\n          &(integer_lstm_params->recurrent_to_input_effective_bias)));\n\n  // Projection bias. The calculation is only meaningful for with projection.\n  TF_LITE_ENSURE_OK(context,\n                    PrecomputeZeroPointTimesWeightWithBias(\n                        context, hidden_zp, projection_weights, projection_bias,\n                        &(integer_lstm_params->projection_effective_bias)));\n  return kTfLiteOk;\n}",
        "func": "TfLiteStatus PopulatePrecomputedZPTimesWeightsWithBias(TfLiteContext* context,\n                                                       OpData* op_data,\n                                                       TfLiteNode* node) {\n  const TfLiteTensor* input;\n  TF_LITE_ENSURE_OK(\n      context, GetInputSafe(context, node, lstm::full::kInputTensor, &input));\n  const TfLiteTensor* output_state =\n      GetVariableInput(context, node, lstm::full::kOutputStateTensor);\n  TF_LITE_ENSURE(context, output_state != nullptr);\n\n  const int32_t input_zero_point = -input->params.zero_point;\n  const int32_t output_state_zero_point = -output_state->params.zero_point;\n\n  const TfLiteTensor* input_to_input_weights = GetOptionalInputTensor(\n      context, node, lstm::full::kInputToInputWeightsTensor);\n  const TfLiteTensor* input_to_forget_weights;\n  TF_LITE_ENSURE_OK(\n      context,\n      GetInputSafe(context, node, lstm::full::kInputToForgetWeightsTensor,\n                   &input_to_forget_weights));\n  const TfLiteTensor* input_to_cell_weights;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node,\n                                          lstm::full::kInputToCellWeightsTensor,\n                                          &input_to_cell_weights));\n  const TfLiteTensor* input_to_output_weights;\n  TF_LITE_ENSURE_OK(\n      context,\n      GetInputSafe(context, node, lstm::full::kInputToOutputWeightsTensor,\n                   &input_to_output_weights));\n\n  const TfLiteTensor* recurrent_to_input_weights = GetOptionalInputTensor(\n      context, node, lstm::full::kRecurrentToInputWeightsTensor);\n  const TfLiteTensor* recurrent_to_forget_weights;\n  TF_LITE_ENSURE_OK(\n      context,\n      GetInputSafe(context, node, lstm::full::kRecurrentToForgetWeightsTensor,\n                   &recurrent_to_forget_weights));\n  const TfLiteTensor* recurrent_to_cell_weights;\n  TF_LITE_ENSURE_OK(\n      context,\n      GetInputSafe(context, node, lstm::full::kRecurrentToCellWeightsTensor,\n                   &recurrent_to_cell_weights));\n  const TfLiteTensor* recurrent_to_output_weights;\n  TF_LITE_ENSURE_OK(\n      context,\n      GetInputSafe(context, node, lstm::full::kRecurrentToOutputWeightsTensor,\n                   &recurrent_to_output_weights));\n\n  const TfLiteTensor* projection_weights = GetOptionalInputTensor(\n      context, node, lstm::full::kProjectionWeightsTensor);\n  const TfLiteTensor* projection_bias =\n      GetOptionalInputTensor(context, node, lstm::full::kProjectionBiasTensor);\n\n  lstm_eval::IntegerLstmParameter* integer_lstm_params =\n      &op_data->integer_lstm_param;\n\n  const TfLiteTensor* intermediate =\n      &context->tensors[node->intermediates->data[4]];\n  TF_LITE_ENSURE(context,\n                 intermediate->quantization.type != kTfLiteNoQuantization);\n  const auto* params =\n      static_cast<TfLiteAffineQuantization*>(intermediate->quantization.params);\n  const int32_t hidden_zp = params->zero_point->data[0];\n\n  // Get bias and perform zero point calculation.\n  // When there is layer normalization, the gate bias does not apply to matmul\n  // directly:\n  //      y = ln(w * x + w * r + w * c) + b.\n  const bool is_layer_norm = op_data->use_layer_norm;\n\n  // Forget gate.\n  const TfLiteTensor* forget_gate_bias =\n      is_layer_norm\n          ? nullptr\n          : GetInput(context, node, lstm::full::kForgetGateBiasTensor);\n  TF_LITE_ENSURE_OK(\n      context,\n      PrecomputeZeroPointTimesWeightWithBias(\n          context, input_zero_point, input_to_forget_weights, forget_gate_bias,\n          &(integer_lstm_params->input_to_forget_effective_bias)));\n\n  TF_LITE_ENSURE_OK(\n      context,\n      PrecomputeZeroPointTimesWeightWithBias(\n          context, output_state_zero_point, recurrent_to_forget_weights,\n          nullptr, &(integer_lstm_params->recurrent_to_forget_effective_bias)));\n\n  // Modulation gate.\n  const TfLiteTensor* cell_gate_bias =\n      is_layer_norm ? nullptr\n                    : GetInput(context, node, lstm::full::kCellGateBiasTensor);\n  TF_LITE_ENSURE_OK(\n      context,\n      PrecomputeZeroPointTimesWeightWithBias(\n          context, input_zero_point, input_to_cell_weights, cell_gate_bias,\n          &(integer_lstm_params->input_to_cell_effective_bias)));\n  TF_LITE_ENSURE_OK(\n      context,\n      PrecomputeZeroPointTimesWeightWithBias(\n          context, output_state_zero_point, recurrent_to_cell_weights, nullptr,\n          &(integer_lstm_params->recurrent_to_cell_effective_bias)));\n\n  // Output gate.\n  const TfLiteTensor* output_gate_bias =\n      is_layer_norm\n          ? nullptr\n          : GetInput(context, node, lstm::full::kOutputGateBiasTensor);\n  TF_LITE_ENSURE_OK(\n      context,\n      PrecomputeZeroPointTimesWeightWithBias(\n          context, input_zero_point, input_to_output_weights, output_gate_bias,\n          &(integer_lstm_params->input_to_output_effective_bias)));\n\n  TF_LITE_ENSURE_OK(\n      context,\n      PrecomputeZeroPointTimesWeightWithBias(\n          context, output_state_zero_point, recurrent_to_output_weights,\n          nullptr, &(integer_lstm_params->recurrent_to_output_effective_bias)));\n\n  // Input gate. The calculation is only meaningful for non-cifg case.\n  const TfLiteTensor* input_gate_bias =\n      is_layer_norm ? nullptr\n                    : GetInput(context, node, lstm::full::kInputGateBiasTensor);\n  TF_LITE_ENSURE_OK(\n      context,\n      PrecomputeZeroPointTimesWeightWithBias(\n          context, input_zero_point, input_to_input_weights, input_gate_bias,\n          &(integer_lstm_params->input_to_input_effective_bias)));\n  TF_LITE_ENSURE_OK(\n      context,\n      PrecomputeZeroPointTimesWeightWithBias(\n          context, output_state_zero_point, recurrent_to_input_weights, nullptr,\n          &(integer_lstm_params->recurrent_to_input_effective_bias)));\n\n  // Projection bias. The calculation is only meaningful for with projection.\n  TF_LITE_ENSURE_OK(context,\n                    PrecomputeZeroPointTimesWeightWithBias(\n                        context, hidden_zp, projection_weights, projection_bias,\n                        &(integer_lstm_params->projection_effective_bias)));\n  return kTfLiteOk;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -56,6 +56,8 @@\n \n   const TfLiteTensor* intermediate =\n       &context->tensors[node->intermediates->data[4]];\n+  TF_LITE_ENSURE(context,\n+                 intermediate->quantization.type != kTfLiteNoQuantization);\n   const auto* params =\n       static_cast<TfLiteAffineQuantization*>(intermediate->quantization.params);\n   const int32_t hidden_zp = params->zero_point->data[0];",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "  TF_LITE_ENSURE(context,",
                "                 intermediate->quantization.type != kTfLiteNoQuantization);"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-37682",
        "func_name": "tensorflow/PopulateQuantizedLstmParams8x8_16",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions all TFLite operations that use quantization can be made to use unitialized values. [For example](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/lite/kernels/depthwise_conv.cc#L198-L200). The issue stems from the fact that `quantization.params` is only valid if `quantization.type` is different that `kTfLiteNoQuantization`. However, these checks are missing in large parts of the code. We have patched the issue in GitHub commits 537bc7c723439b9194a358f64d871dd326c18887, 4a91f2069f7145aab6ba2d8cfe41be8a110c18a5 and 8933b8a21280696ab119b63263babdb54c298538. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/4a91f2069f7145aab6ba2d8cfe41be8a110c18a5",
        "commit_title": "Fix a null pointer exception caused by branching on uninitialized data.",
        "commit_text": " This is due to not checking that the params for the quantization exists. If there is no quantization, we should not access the `.params` field.  PiperOrigin-RevId: 385168337",
        "func_before": "TfLiteStatus PopulateQuantizedLstmParams8x8_16(\n    TfLiteContext* context, TfLiteNode* node,\n    lstm_eval::IntegerLstmParameter* integer_lstm_param) {\n  // Calculate quantized clip for projection and cell.\n  const auto* params =\n      static_cast<TfLiteUnidirectionalSequenceLSTMParams*>(node->builtin_data);\n  const float cell_clip = params->cell_clip;\n  const float proj_clip = params->proj_clip;\n\n  const TfLiteTensor* cell_state =\n      GetVariableInput(context, node, lstm::full::kCellStateTensor);\n  TF_LITE_ENSURE(context, cell_state != nullptr);\n  TfLiteTensor* output_tensor;\n  TF_LITE_ENSURE_OK(\n      context,\n      GetOutputSafe(context, node, lstm::full::kOutputTensor, &output_tensor));\n\n  auto* cell_state_params =\n      static_cast<TfLiteAffineQuantization*>(cell_state->quantization.params);\n  auto* proj_params = static_cast<TfLiteAffineQuantization*>(\n      output_tensor->quantization.params);\n  if (cell_clip > 0.0) {\n    integer_lstm_param->quantized_cell_clip = static_cast<int16_t>(std::min(\n        std::max(cell_clip / cell_state_params->scale->data[0], -32768.0f),\n        32767.0f));\n  } else {\n    integer_lstm_param->quantized_cell_clip = 0;\n  }\n  if (proj_clip > 0.0) {\n    integer_lstm_param->quantized_proj_clip = static_cast<int8_t>(std::min(\n        std::max(proj_clip / proj_params->scale->data[0], -128.0f), 127.0f));\n  } else {\n    integer_lstm_param->quantized_proj_clip = 0;\n  }\n\n  // Calculate effective scales.\n  OpData* op_data = static_cast<OpData*>(node->user_data);\n  const bool use_layer_norm = op_data->use_layer_norm;\n\n  const TfLiteTensor* input;\n  TF_LITE_ENSURE_OK(\n      context, GetInputSafe(context, node, lstm::full::kInputTensor, &input));\n\n  const TfLiteTensor* input_to_input_weights = GetOptionalInputTensor(\n      context, node, lstm::full::kInputToInputWeightsTensor);\n  const TfLiteTensor* input_to_forget_weights;\n  TF_LITE_ENSURE_OK(\n      context,\n      GetInputSafe(context, node, lstm::full::kInputToForgetWeightsTensor,\n                   &input_to_forget_weights));\n  const TfLiteTensor* input_to_cell_weights;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node,\n                                          lstm::full::kInputToCellWeightsTensor,\n                                          &input_to_cell_weights));\n  const TfLiteTensor* input_to_output_weights;\n  TF_LITE_ENSURE_OK(\n      context,\n      GetInputSafe(context, node, lstm::full::kInputToOutputWeightsTensor,\n                   &input_to_output_weights));\n\n  const TfLiteTensor* recurrent_to_input_weights = GetOptionalInputTensor(\n      context, node, lstm::full::kRecurrentToInputWeightsTensor);\n  const TfLiteTensor* recurrent_to_forget_weights;\n  TF_LITE_ENSURE_OK(\n      context,\n      GetInputSafe(context, node, lstm::full::kRecurrentToForgetWeightsTensor,\n                   &recurrent_to_forget_weights));\n  const TfLiteTensor* recurrent_to_cell_weights;\n  TF_LITE_ENSURE_OK(\n      context,\n      GetInputSafe(context, node, lstm::full::kRecurrentToCellWeightsTensor,\n                   &recurrent_to_cell_weights));\n  const TfLiteTensor* recurrent_to_output_weights;\n  TF_LITE_ENSURE_OK(\n      context,\n      GetInputSafe(context, node, lstm::full::kRecurrentToOutputWeightsTensor,\n                   &recurrent_to_output_weights));\n\n  const TfLiteTensor* cell_to_input_weights = GetOptionalInputTensor(\n      context, node, lstm::full::kCellToInputWeightsTensor);\n  const TfLiteTensor* cell_to_forget_weights = GetOptionalInputTensor(\n      context, node, lstm::full::kCellToForgetWeightsTensor);\n  const TfLiteTensor* cell_to_output_weights = GetOptionalInputTensor(\n      context, node, lstm::full::kCellToOutputWeightsTensor);\n\n  const TfLiteTensor* input_layer_norm_coefficients = GetOptionalInputTensor(\n      context, node, lstm::full::kInputLayerNormCoefficientsTensor);\n  const TfLiteTensor* forget_layer_norm_coefficients = GetOptionalInputTensor(\n      context, node, lstm::full::kForgetLayerNormCoefficientsTensor);\n  const TfLiteTensor* cell_layer_norm_coefficients = GetOptionalInputTensor(\n      context, node, lstm::full::kCellLayerNormCoefficientsTensor);\n  const TfLiteTensor* output_layer_norm_coefficients = GetOptionalInputTensor(\n      context, node, lstm::full::kOutputLayerNormCoefficientsTensor);\n\n  const TfLiteTensor* projection_weights = GetOptionalInputTensor(\n      context, node, lstm::full::kProjectionWeightsTensor);\n\n  TfLiteTensor* output_state =\n      GetVariableInput(context, node, lstm::full::kOutputStateTensor);\n  TF_LITE_ENSURE(context, output_state != nullptr);\n\n  // Since we have already checked that weights are all there or none, we can\n  // check the existence of only one to get the condition.\n  const bool use_cifg = (input_to_input_weights == nullptr);\n  const bool use_peephole = (cell_to_output_weights != nullptr);\n  const bool use_projection = (projection_weights != nullptr);\n\n  // Get intermediate scales and zero points.\n  std::vector<float> intermediate_scale;\n  std::vector<int32> intermediate_zp;\n  for (int i = 0; i < 4; ++i) {\n    if (use_layer_norm) {\n      TfLiteTensor* intermediate;\n      TF_LITE_ENSURE_OK(context,\n                        GetIntermediatesSafe(context, node, i, &intermediate));\n      auto* params = static_cast<TfLiteAffineQuantization*>(\n          intermediate->quantization.params);\n      intermediate_scale.push_back(params->scale->data[0]);\n      intermediate_zp.push_back(params->zero_point->data[0]);\n    } else {\n      // Q3.12 for activation functions.\n      intermediate_scale.push_back(std::pow(2, -12));\n      intermediate_zp.push_back(0);\n    }\n  }\n  // In the absence of projection, hidden becomes otuput and this intermediate\n  // is ignored.\n  TfLiteTensor* hidden;\n  TF_LITE_ENSURE_OK(context, GetIntermediatesSafe(context, node, 4, &hidden));\n  auto* hidden_params =\n      static_cast<TfLiteAffineQuantization*>(hidden->quantization.params);\n  intermediate_scale.push_back(hidden_params->scale->data[0]);\n  intermediate_zp.push_back(hidden_params->zero_point->data[0]);\n\n  // Scales.\n  const float default_scale = 1.0;\n  float input_scale = default_scale;\n  float input_to_input_weight_scale = default_scale;\n  float recurrent_to_input_weight_scale = default_scale;\n  float cell_to_input_weight_scale = default_scale;\n  float input_to_forget_weight_scale = default_scale;\n  float recurrent_to_forget_weight_scale = default_scale;\n  float cell_to_forget_weight_scale = default_scale;\n  float input_to_cell_weight_scale = default_scale;\n  float recurrent_to_cell_weight_scale = default_scale;\n  float input_to_output_weight_scale = default_scale;\n  float recurrent_to_output_weight_scale = default_scale;\n  float cell_to_output_weight_scale = default_scale;\n  float projection_weight_scale = default_scale;\n  float layer_norm_input_scale = default_scale;\n  float layer_norm_forget_scale = default_scale;\n  float layer_norm_cell_scale = default_scale;\n  float layer_norm_output_scale = default_scale;\n  float output_state_scale = default_scale;\n  int cell_scale = 1;\n\n  // Effective scales.\n  float effective_input_to_input_scale = default_scale;\n  float effective_recurrent_to_input_scale = default_scale;\n  float effective_cell_to_input_scale = default_scale;\n  float effective_input_to_forget_scale = default_scale;\n  float effective_recurrent_to_forget_scale = default_scale;\n  float effective_cell_to_forget_scale = default_scale;\n  float effective_input_to_cell_scale = default_scale;\n  float effective_recurrent_to_cell_scale = default_scale;\n  float effective_input_to_output_scale = default_scale;\n  float effective_recurrent_to_output_scale = default_scale;\n  float effective_cell_to_output_scale = default_scale;\n  float effective_proj_scale = default_scale;\n  float effective_hidden_scale = default_scale;\n\n  // Populate scales.\n  if (!use_cifg) {\n    input_to_input_weight_scale = input_to_input_weights->params.scale;\n    recurrent_to_input_weight_scale = recurrent_to_input_weights->params.scale;\n  }\n\n  if (use_peephole) {\n    if (!use_cifg) {\n      cell_to_input_weight_scale = cell_to_input_weights->params.scale;\n    }\n    cell_to_forget_weight_scale = cell_to_forget_weights->params.scale;\n    cell_to_output_weight_scale = cell_to_output_weights->params.scale;\n  }\n\n  if (use_layer_norm) {\n    if (!use_cifg) {\n      layer_norm_input_scale = input_layer_norm_coefficients->params.scale;\n    }\n    layer_norm_forget_scale = forget_layer_norm_coefficients->params.scale;\n    layer_norm_cell_scale = cell_layer_norm_coefficients->params.scale;\n    layer_norm_output_scale = output_layer_norm_coefficients->params.scale;\n  }\n\n  if (use_projection) {\n    projection_weight_scale = projection_weights->params.scale;\n  }\n  output_state_scale = output_state->params.scale;\n\n  input_to_forget_weight_scale = input_to_forget_weights->params.scale;\n  input_to_cell_weight_scale = input_to_cell_weights->params.scale;\n  input_to_output_weight_scale = input_to_output_weights->params.scale;\n  recurrent_to_forget_weight_scale = recurrent_to_forget_weights->params.scale;\n  recurrent_to_cell_weight_scale = recurrent_to_cell_weights->params.scale;\n  recurrent_to_output_weight_scale = recurrent_to_output_weights->params.scale;\n\n  // Check cell state (already used above)\n  TF_LITE_ENSURE(context, CheckedLog2(cell_state->params.scale, &cell_scale));\n  // TF_LITE_ENSURE(context, cell_scale <= -9);\n  integer_lstm_param->cell_scale = cell_scale;\n  input_scale = input->params.scale;\n\n  // Calculate effective scales.\n  if (!use_cifg) {\n    effective_input_to_input_scale =\n        input_to_input_weight_scale * input_scale / intermediate_scale[0];\n    effective_recurrent_to_input_scale = recurrent_to_input_weight_scale *\n                                         output_state_scale /\n                                         intermediate_scale[0];\n  }\n  effective_input_to_forget_scale =\n      input_to_forget_weight_scale * input_scale / intermediate_scale[1];\n  effective_recurrent_to_forget_scale = recurrent_to_forget_weight_scale *\n                                        output_state_scale /\n                                        intermediate_scale[1];\n\n  effective_input_to_cell_scale =\n      input_to_cell_weight_scale * input_scale / intermediate_scale[2];\n  effective_recurrent_to_cell_scale = recurrent_to_cell_weight_scale *\n                                      output_state_scale /\n                                      intermediate_scale[2];\n\n  effective_input_to_output_scale =\n      input_to_output_weight_scale * input_scale / intermediate_scale[3];\n  effective_recurrent_to_output_scale = recurrent_to_output_weight_scale *\n                                        output_state_scale /\n                                        intermediate_scale[3];\n\n  effective_hidden_scale =\n      std::pow(2, -15) / intermediate_scale[4] * std::pow(2, -15);\n\n  effective_proj_scale =\n      projection_weight_scale * intermediate_scale[4] / output_state_scale;\n\n  if (use_peephole) {\n    if (!use_cifg) {\n      effective_cell_to_input_scale = std::pow(2, cell_scale) *  // NOLINT\n                                      cell_to_input_weight_scale /\n                                      intermediate_scale[0];\n    }\n    effective_cell_to_forget_scale = std::pow(2, cell_scale) *  // NOLINT\n                                     cell_to_forget_weight_scale /\n                                     intermediate_scale[1];\n    effective_cell_to_output_scale = std::pow(2, cell_scale) *  // NOLINT\n                                     cell_to_output_weight_scale /\n                                     intermediate_scale[3];\n  }\n\n  // Decompose scales.\n  QuantizeMultiplier(effective_input_to_input_scale,\n                     &integer_lstm_param->effective_input_to_input_scale_a,\n                     &integer_lstm_param->effective_input_to_input_scale_b);\n  QuantizeMultiplier(effective_recurrent_to_input_scale,\n                     &integer_lstm_param->effective_recurrent_to_input_scale_a,\n                     &integer_lstm_param->effective_recurrent_to_input_scale_b);\n  QuantizeMultiplier(effective_cell_to_input_scale,\n                     &integer_lstm_param->effective_cell_to_input_scale_a,\n                     &integer_lstm_param->effective_cell_to_input_scale_b);\n  QuantizeMultiplier(effective_input_to_forget_scale,\n                     &integer_lstm_param->effective_input_to_forget_scale_a,\n                     &integer_lstm_param->effective_input_to_forget_scale_b);\n  QuantizeMultiplier(\n      effective_recurrent_to_forget_scale,\n      &integer_lstm_param->effective_recurrent_to_forget_scale_a,\n      &integer_lstm_param->effective_recurrent_to_forget_scale_b);\n  QuantizeMultiplier(effective_cell_to_forget_scale,\n                     &integer_lstm_param->effective_cell_to_forget_scale_a,\n                     &integer_lstm_param->effective_cell_to_forget_scale_b);\n  QuantizeMultiplier(effective_input_to_cell_scale,\n                     &integer_lstm_param->effective_input_to_cell_scale_a,\n                     &integer_lstm_param->effective_input_to_cell_scale_b);\n  QuantizeMultiplier(effective_recurrent_to_cell_scale,\n                     &integer_lstm_param->effective_recurrent_to_cell_scale_a,\n                     &integer_lstm_param->effective_recurrent_to_cell_scale_b);\n  QuantizeMultiplier(effective_input_to_output_scale,\n                     &integer_lstm_param->effective_input_to_output_scale_a,\n                     &integer_lstm_param->effective_input_to_output_scale_b);\n  QuantizeMultiplier(\n      effective_recurrent_to_output_scale,\n      &integer_lstm_param->effective_recurrent_to_output_scale_a,\n      &integer_lstm_param->effective_recurrent_to_output_scale_b);\n  QuantizeMultiplier(effective_cell_to_output_scale,\n                     &integer_lstm_param->effective_cell_to_output_scale_a,\n                     &integer_lstm_param->effective_cell_to_output_scale_b);\n  QuantizeMultiplier(effective_proj_scale,\n                     &integer_lstm_param->effective_proj_scale_a,\n                     &integer_lstm_param->effective_proj_scale_b);\n  QuantizeMultiplier(effective_hidden_scale,\n                     &integer_lstm_param->effective_hidden_scale_a,\n                     &integer_lstm_param->effective_hidden_scale_b);\n  QuantizeMultiplier(layer_norm_input_scale,\n                     &integer_lstm_param->layer_norm_input_scale_a,\n                     &integer_lstm_param->layer_norm_input_scale_b);\n  QuantizeMultiplier(layer_norm_forget_scale,\n                     &integer_lstm_param->layer_norm_forget_scale_a,\n                     &integer_lstm_param->layer_norm_forget_scale_b);\n  QuantizeMultiplier(layer_norm_cell_scale,\n                     &integer_lstm_param->layer_norm_cell_scale_a,\n                     &integer_lstm_param->layer_norm_cell_scale_b);\n  QuantizeMultiplier(layer_norm_output_scale,\n                     &integer_lstm_param->layer_norm_output_scale_a,\n                     &integer_lstm_param->layer_norm_output_scale_b);\n\n  integer_lstm_param->hidden_zp = intermediate_zp[4];\n\n  // 10000 is used to make sure the kernel logic does not overflow.\n  if (!use_cifg) {\n    integer_lstm_param->input_variance_guard =\n        std::max(1, static_cast<int32_t>(10000 * layer_norm_input_scale));\n  }\n  integer_lstm_param->forget_variance_guard =\n      std::max(1, static_cast<int32_t>(10000 * layer_norm_forget_scale));\n  integer_lstm_param->cell_variance_guard =\n      std::max(1, static_cast<int32_t>(10000 * layer_norm_cell_scale));\n  integer_lstm_param->output_variance_guard =\n      std::max(1, static_cast<int32_t>(10000 * layer_norm_output_scale));\n\n  return kTfLiteOk;\n}",
        "func": "TfLiteStatus PopulateQuantizedLstmParams8x8_16(\n    TfLiteContext* context, TfLiteNode* node,\n    lstm_eval::IntegerLstmParameter* integer_lstm_param) {\n  // Calculate quantized clip for projection and cell.\n  const auto* params =\n      static_cast<TfLiteUnidirectionalSequenceLSTMParams*>(node->builtin_data);\n  const float cell_clip = params->cell_clip;\n  const float proj_clip = params->proj_clip;\n\n  const TfLiteTensor* cell_state =\n      GetVariableInput(context, node, lstm::full::kCellStateTensor);\n  TF_LITE_ENSURE(context, cell_state != nullptr);\n  TfLiteTensor* output_tensor;\n  TF_LITE_ENSURE_OK(\n      context,\n      GetOutputSafe(context, node, lstm::full::kOutputTensor, &output_tensor));\n\n  TF_LITE_ENSURE(context,\n                 cell_state->quantization.type != kTfLiteNoQuantization);\n  auto* cell_state_params =\n      static_cast<TfLiteAffineQuantization*>(cell_state->quantization.params);\n  TF_LITE_ENSURE(context,\n                 output_tensor->quantization.type != kTfLiteNoQuantization);\n  auto* proj_params = static_cast<TfLiteAffineQuantization*>(\n      output_tensor->quantization.params);\n  if (cell_clip > 0.0) {\n    integer_lstm_param->quantized_cell_clip = static_cast<int16_t>(std::min(\n        std::max(cell_clip / cell_state_params->scale->data[0], -32768.0f),\n        32767.0f));\n  } else {\n    integer_lstm_param->quantized_cell_clip = 0;\n  }\n  if (proj_clip > 0.0) {\n    integer_lstm_param->quantized_proj_clip = static_cast<int8_t>(std::min(\n        std::max(proj_clip / proj_params->scale->data[0], -128.0f), 127.0f));\n  } else {\n    integer_lstm_param->quantized_proj_clip = 0;\n  }\n\n  // Calculate effective scales.\n  OpData* op_data = static_cast<OpData*>(node->user_data);\n  const bool use_layer_norm = op_data->use_layer_norm;\n\n  const TfLiteTensor* input;\n  TF_LITE_ENSURE_OK(\n      context, GetInputSafe(context, node, lstm::full::kInputTensor, &input));\n\n  const TfLiteTensor* input_to_input_weights = GetOptionalInputTensor(\n      context, node, lstm::full::kInputToInputWeightsTensor);\n  const TfLiteTensor* input_to_forget_weights;\n  TF_LITE_ENSURE_OK(\n      context,\n      GetInputSafe(context, node, lstm::full::kInputToForgetWeightsTensor,\n                   &input_to_forget_weights));\n  const TfLiteTensor* input_to_cell_weights;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node,\n                                          lstm::full::kInputToCellWeightsTensor,\n                                          &input_to_cell_weights));\n  const TfLiteTensor* input_to_output_weights;\n  TF_LITE_ENSURE_OK(\n      context,\n      GetInputSafe(context, node, lstm::full::kInputToOutputWeightsTensor,\n                   &input_to_output_weights));\n\n  const TfLiteTensor* recurrent_to_input_weights = GetOptionalInputTensor(\n      context, node, lstm::full::kRecurrentToInputWeightsTensor);\n  const TfLiteTensor* recurrent_to_forget_weights;\n  TF_LITE_ENSURE_OK(\n      context,\n      GetInputSafe(context, node, lstm::full::kRecurrentToForgetWeightsTensor,\n                   &recurrent_to_forget_weights));\n  const TfLiteTensor* recurrent_to_cell_weights;\n  TF_LITE_ENSURE_OK(\n      context,\n      GetInputSafe(context, node, lstm::full::kRecurrentToCellWeightsTensor,\n                   &recurrent_to_cell_weights));\n  const TfLiteTensor* recurrent_to_output_weights;\n  TF_LITE_ENSURE_OK(\n      context,\n      GetInputSafe(context, node, lstm::full::kRecurrentToOutputWeightsTensor,\n                   &recurrent_to_output_weights));\n\n  const TfLiteTensor* cell_to_input_weights = GetOptionalInputTensor(\n      context, node, lstm::full::kCellToInputWeightsTensor);\n  const TfLiteTensor* cell_to_forget_weights = GetOptionalInputTensor(\n      context, node, lstm::full::kCellToForgetWeightsTensor);\n  const TfLiteTensor* cell_to_output_weights = GetOptionalInputTensor(\n      context, node, lstm::full::kCellToOutputWeightsTensor);\n\n  const TfLiteTensor* input_layer_norm_coefficients = GetOptionalInputTensor(\n      context, node, lstm::full::kInputLayerNormCoefficientsTensor);\n  const TfLiteTensor* forget_layer_norm_coefficients = GetOptionalInputTensor(\n      context, node, lstm::full::kForgetLayerNormCoefficientsTensor);\n  const TfLiteTensor* cell_layer_norm_coefficients = GetOptionalInputTensor(\n      context, node, lstm::full::kCellLayerNormCoefficientsTensor);\n  const TfLiteTensor* output_layer_norm_coefficients = GetOptionalInputTensor(\n      context, node, lstm::full::kOutputLayerNormCoefficientsTensor);\n\n  const TfLiteTensor* projection_weights = GetOptionalInputTensor(\n      context, node, lstm::full::kProjectionWeightsTensor);\n\n  TfLiteTensor* output_state =\n      GetVariableInput(context, node, lstm::full::kOutputStateTensor);\n  TF_LITE_ENSURE(context, output_state != nullptr);\n\n  // Since we have already checked that weights are all there or none, we can\n  // check the existence of only one to get the condition.\n  const bool use_cifg = (input_to_input_weights == nullptr);\n  const bool use_peephole = (cell_to_output_weights != nullptr);\n  const bool use_projection = (projection_weights != nullptr);\n\n  // Get intermediate scales and zero points.\n  std::vector<float> intermediate_scale;\n  std::vector<int32> intermediate_zp;\n  for (int i = 0; i < 4; ++i) {\n    if (use_layer_norm) {\n      TfLiteTensor* intermediate;\n      TF_LITE_ENSURE_OK(context,\n                        GetIntermediatesSafe(context, node, i, &intermediate));\n      TF_LITE_ENSURE(context,\n                     intermediate->quantization.type != kTfLiteNoQuantization);\n      auto* params = static_cast<TfLiteAffineQuantization*>(\n          intermediate->quantization.params);\n      intermediate_scale.push_back(params->scale->data[0]);\n      intermediate_zp.push_back(params->zero_point->data[0]);\n    } else {\n      // Q3.12 for activation functions.\n      intermediate_scale.push_back(std::pow(2, -12));\n      intermediate_zp.push_back(0);\n    }\n  }\n  // In the absence of projection, hidden becomes otuput and this intermediate\n  // is ignored.\n  TfLiteTensor* hidden;\n  TF_LITE_ENSURE_OK(context, GetIntermediatesSafe(context, node, 4, &hidden));\n  TF_LITE_ENSURE(context, hidden->quantization.type != kTfLiteNoQuantization);\n  auto* hidden_params =\n      static_cast<TfLiteAffineQuantization*>(hidden->quantization.params);\n  intermediate_scale.push_back(hidden_params->scale->data[0]);\n  intermediate_zp.push_back(hidden_params->zero_point->data[0]);\n\n  // Scales.\n  const float default_scale = 1.0;\n  float input_scale = default_scale;\n  float input_to_input_weight_scale = default_scale;\n  float recurrent_to_input_weight_scale = default_scale;\n  float cell_to_input_weight_scale = default_scale;\n  float input_to_forget_weight_scale = default_scale;\n  float recurrent_to_forget_weight_scale = default_scale;\n  float cell_to_forget_weight_scale = default_scale;\n  float input_to_cell_weight_scale = default_scale;\n  float recurrent_to_cell_weight_scale = default_scale;\n  float input_to_output_weight_scale = default_scale;\n  float recurrent_to_output_weight_scale = default_scale;\n  float cell_to_output_weight_scale = default_scale;\n  float projection_weight_scale = default_scale;\n  float layer_norm_input_scale = default_scale;\n  float layer_norm_forget_scale = default_scale;\n  float layer_norm_cell_scale = default_scale;\n  float layer_norm_output_scale = default_scale;\n  float output_state_scale = default_scale;\n  int cell_scale = 1;\n\n  // Effective scales.\n  float effective_input_to_input_scale = default_scale;\n  float effective_recurrent_to_input_scale = default_scale;\n  float effective_cell_to_input_scale = default_scale;\n  float effective_input_to_forget_scale = default_scale;\n  float effective_recurrent_to_forget_scale = default_scale;\n  float effective_cell_to_forget_scale = default_scale;\n  float effective_input_to_cell_scale = default_scale;\n  float effective_recurrent_to_cell_scale = default_scale;\n  float effective_input_to_output_scale = default_scale;\n  float effective_recurrent_to_output_scale = default_scale;\n  float effective_cell_to_output_scale = default_scale;\n  float effective_proj_scale = default_scale;\n  float effective_hidden_scale = default_scale;\n\n  // Populate scales.\n  if (!use_cifg) {\n    input_to_input_weight_scale = input_to_input_weights->params.scale;\n    recurrent_to_input_weight_scale = recurrent_to_input_weights->params.scale;\n  }\n\n  if (use_peephole) {\n    if (!use_cifg) {\n      cell_to_input_weight_scale = cell_to_input_weights->params.scale;\n    }\n    cell_to_forget_weight_scale = cell_to_forget_weights->params.scale;\n    cell_to_output_weight_scale = cell_to_output_weights->params.scale;\n  }\n\n  if (use_layer_norm) {\n    if (!use_cifg) {\n      layer_norm_input_scale = input_layer_norm_coefficients->params.scale;\n    }\n    layer_norm_forget_scale = forget_layer_norm_coefficients->params.scale;\n    layer_norm_cell_scale = cell_layer_norm_coefficients->params.scale;\n    layer_norm_output_scale = output_layer_norm_coefficients->params.scale;\n  }\n\n  if (use_projection) {\n    projection_weight_scale = projection_weights->params.scale;\n  }\n  output_state_scale = output_state->params.scale;\n\n  input_to_forget_weight_scale = input_to_forget_weights->params.scale;\n  input_to_cell_weight_scale = input_to_cell_weights->params.scale;\n  input_to_output_weight_scale = input_to_output_weights->params.scale;\n  recurrent_to_forget_weight_scale = recurrent_to_forget_weights->params.scale;\n  recurrent_to_cell_weight_scale = recurrent_to_cell_weights->params.scale;\n  recurrent_to_output_weight_scale = recurrent_to_output_weights->params.scale;\n\n  // Check cell state (already used above)\n  TF_LITE_ENSURE(context, CheckedLog2(cell_state->params.scale, &cell_scale));\n  // TF_LITE_ENSURE(context, cell_scale <= -9);\n  integer_lstm_param->cell_scale = cell_scale;\n  input_scale = input->params.scale;\n\n  // Calculate effective scales.\n  if (!use_cifg) {\n    effective_input_to_input_scale =\n        input_to_input_weight_scale * input_scale / intermediate_scale[0];\n    effective_recurrent_to_input_scale = recurrent_to_input_weight_scale *\n                                         output_state_scale /\n                                         intermediate_scale[0];\n  }\n  effective_input_to_forget_scale =\n      input_to_forget_weight_scale * input_scale / intermediate_scale[1];\n  effective_recurrent_to_forget_scale = recurrent_to_forget_weight_scale *\n                                        output_state_scale /\n                                        intermediate_scale[1];\n\n  effective_input_to_cell_scale =\n      input_to_cell_weight_scale * input_scale / intermediate_scale[2];\n  effective_recurrent_to_cell_scale = recurrent_to_cell_weight_scale *\n                                      output_state_scale /\n                                      intermediate_scale[2];\n\n  effective_input_to_output_scale =\n      input_to_output_weight_scale * input_scale / intermediate_scale[3];\n  effective_recurrent_to_output_scale = recurrent_to_output_weight_scale *\n                                        output_state_scale /\n                                        intermediate_scale[3];\n\n  effective_hidden_scale =\n      std::pow(2, -15) / intermediate_scale[4] * std::pow(2, -15);\n\n  effective_proj_scale =\n      projection_weight_scale * intermediate_scale[4] / output_state_scale;\n\n  if (use_peephole) {\n    if (!use_cifg) {\n      effective_cell_to_input_scale = std::pow(2, cell_scale) *  // NOLINT\n                                      cell_to_input_weight_scale /\n                                      intermediate_scale[0];\n    }\n    effective_cell_to_forget_scale = std::pow(2, cell_scale) *  // NOLINT\n                                     cell_to_forget_weight_scale /\n                                     intermediate_scale[1];\n    effective_cell_to_output_scale = std::pow(2, cell_scale) *  // NOLINT\n                                     cell_to_output_weight_scale /\n                                     intermediate_scale[3];\n  }\n\n  // Decompose scales.\n  QuantizeMultiplier(effective_input_to_input_scale,\n                     &integer_lstm_param->effective_input_to_input_scale_a,\n                     &integer_lstm_param->effective_input_to_input_scale_b);\n  QuantizeMultiplier(effective_recurrent_to_input_scale,\n                     &integer_lstm_param->effective_recurrent_to_input_scale_a,\n                     &integer_lstm_param->effective_recurrent_to_input_scale_b);\n  QuantizeMultiplier(effective_cell_to_input_scale,\n                     &integer_lstm_param->effective_cell_to_input_scale_a,\n                     &integer_lstm_param->effective_cell_to_input_scale_b);\n  QuantizeMultiplier(effective_input_to_forget_scale,\n                     &integer_lstm_param->effective_input_to_forget_scale_a,\n                     &integer_lstm_param->effective_input_to_forget_scale_b);\n  QuantizeMultiplier(\n      effective_recurrent_to_forget_scale,\n      &integer_lstm_param->effective_recurrent_to_forget_scale_a,\n      &integer_lstm_param->effective_recurrent_to_forget_scale_b);\n  QuantizeMultiplier(effective_cell_to_forget_scale,\n                     &integer_lstm_param->effective_cell_to_forget_scale_a,\n                     &integer_lstm_param->effective_cell_to_forget_scale_b);\n  QuantizeMultiplier(effective_input_to_cell_scale,\n                     &integer_lstm_param->effective_input_to_cell_scale_a,\n                     &integer_lstm_param->effective_input_to_cell_scale_b);\n  QuantizeMultiplier(effective_recurrent_to_cell_scale,\n                     &integer_lstm_param->effective_recurrent_to_cell_scale_a,\n                     &integer_lstm_param->effective_recurrent_to_cell_scale_b);\n  QuantizeMultiplier(effective_input_to_output_scale,\n                     &integer_lstm_param->effective_input_to_output_scale_a,\n                     &integer_lstm_param->effective_input_to_output_scale_b);\n  QuantizeMultiplier(\n      effective_recurrent_to_output_scale,\n      &integer_lstm_param->effective_recurrent_to_output_scale_a,\n      &integer_lstm_param->effective_recurrent_to_output_scale_b);\n  QuantizeMultiplier(effective_cell_to_output_scale,\n                     &integer_lstm_param->effective_cell_to_output_scale_a,\n                     &integer_lstm_param->effective_cell_to_output_scale_b);\n  QuantizeMultiplier(effective_proj_scale,\n                     &integer_lstm_param->effective_proj_scale_a,\n                     &integer_lstm_param->effective_proj_scale_b);\n  QuantizeMultiplier(effective_hidden_scale,\n                     &integer_lstm_param->effective_hidden_scale_a,\n                     &integer_lstm_param->effective_hidden_scale_b);\n  QuantizeMultiplier(layer_norm_input_scale,\n                     &integer_lstm_param->layer_norm_input_scale_a,\n                     &integer_lstm_param->layer_norm_input_scale_b);\n  QuantizeMultiplier(layer_norm_forget_scale,\n                     &integer_lstm_param->layer_norm_forget_scale_a,\n                     &integer_lstm_param->layer_norm_forget_scale_b);\n  QuantizeMultiplier(layer_norm_cell_scale,\n                     &integer_lstm_param->layer_norm_cell_scale_a,\n                     &integer_lstm_param->layer_norm_cell_scale_b);\n  QuantizeMultiplier(layer_norm_output_scale,\n                     &integer_lstm_param->layer_norm_output_scale_a,\n                     &integer_lstm_param->layer_norm_output_scale_b);\n\n  integer_lstm_param->hidden_zp = intermediate_zp[4];\n\n  // 10000 is used to make sure the kernel logic does not overflow.\n  if (!use_cifg) {\n    integer_lstm_param->input_variance_guard =\n        std::max(1, static_cast<int32_t>(10000 * layer_norm_input_scale));\n  }\n  integer_lstm_param->forget_variance_guard =\n      std::max(1, static_cast<int32_t>(10000 * layer_norm_forget_scale));\n  integer_lstm_param->cell_variance_guard =\n      std::max(1, static_cast<int32_t>(10000 * layer_norm_cell_scale));\n  integer_lstm_param->output_variance_guard =\n      std::max(1, static_cast<int32_t>(10000 * layer_norm_output_scale));\n\n  return kTfLiteOk;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -15,8 +15,12 @@\n       context,\n       GetOutputSafe(context, node, lstm::full::kOutputTensor, &output_tensor));\n \n+  TF_LITE_ENSURE(context,\n+                 cell_state->quantization.type != kTfLiteNoQuantization);\n   auto* cell_state_params =\n       static_cast<TfLiteAffineQuantization*>(cell_state->quantization.params);\n+  TF_LITE_ENSURE(context,\n+                 output_tensor->quantization.type != kTfLiteNoQuantization);\n   auto* proj_params = static_cast<TfLiteAffineQuantization*>(\n       output_tensor->quantization.params);\n   if (cell_clip > 0.0) {\n@@ -113,6 +117,8 @@\n       TfLiteTensor* intermediate;\n       TF_LITE_ENSURE_OK(context,\n                         GetIntermediatesSafe(context, node, i, &intermediate));\n+      TF_LITE_ENSURE(context,\n+                     intermediate->quantization.type != kTfLiteNoQuantization);\n       auto* params = static_cast<TfLiteAffineQuantization*>(\n           intermediate->quantization.params);\n       intermediate_scale.push_back(params->scale->data[0]);\n@@ -127,6 +133,7 @@\n   // is ignored.\n   TfLiteTensor* hidden;\n   TF_LITE_ENSURE_OK(context, GetIntermediatesSafe(context, node, 4, &hidden));\n+  TF_LITE_ENSURE(context, hidden->quantization.type != kTfLiteNoQuantization);\n   auto* hidden_params =\n       static_cast<TfLiteAffineQuantization*>(hidden->quantization.params);\n   intermediate_scale.push_back(hidden_params->scale->data[0]);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "  TF_LITE_ENSURE(context,",
                "                 cell_state->quantization.type != kTfLiteNoQuantization);",
                "  TF_LITE_ENSURE(context,",
                "                 output_tensor->quantization.type != kTfLiteNoQuantization);",
                "      TF_LITE_ENSURE(context,",
                "                     intermediate->quantization.type != kTfLiteNoQuantization);",
                "  TF_LITE_ENSURE(context, hidden->quantization.type != kTfLiteNoQuantization);"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-37682",
        "func_name": "tensorflow/EvalHybridPerChannel",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions all TFLite operations that use quantization can be made to use unitialized values. [For example](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/lite/kernels/depthwise_conv.cc#L198-L200). The issue stems from the fact that `quantization.params` is only valid if `quantization.type` is different that `kTfLiteNoQuantization`. However, these checks are missing in large parts of the code. We have patched the issue in GitHub commits 537bc7c723439b9194a358f64d871dd326c18887, 4a91f2069f7145aab6ba2d8cfe41be8a110c18a5 and 8933b8a21280696ab119b63263babdb54c298538. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/8933b8a21280696ab119b63263babdb54c298538",
        "commit_title": "Fix a null pointer exception caused by branching on uninitialized data.",
        "commit_text": " This is due to not checking that the params for the quantization exists. If there is no quantization, we should not access the `.params` field.  PiperOrigin-RevId: 385173491",
        "func_before": "TfLiteStatus EvalHybridPerChannel(TfLiteContext* context, TfLiteNode* node,\n                                  TfLiteDepthwiseConvParams* params,\n                                  OpData* data, const TfLiteTensor* input,\n                                  const TfLiteTensor* filter,\n                                  const TfLiteTensor* bias,\n                                  TfLiteTensor* output) {\n  float output_activation_min, output_activation_max;\n  CalculateActivationRange(params->activation, &output_activation_min,\n                           &output_activation_max);\n  const int batch_size = SizeOfDimension(input, 0);\n  TF_LITE_ENSURE(context, batch_size != 0);\n  const int input_size = NumElements(input) / batch_size;\n  TfLiteTensor* input_quantized;\n  TF_LITE_ENSURE_OK(context,\n                    GetTemporarySafe(context, node, data->input_quantized_index,\n                                     &input_quantized));\n  int8_t* quantized_input_ptr_batch = input_quantized->data.int8;\n  TfLiteTensor* scaling_factors_tensor;\n  TF_LITE_ENSURE_OK(context,\n                    GetTemporarySafe(context, node, data->scaling_factors_index,\n                                     &scaling_factors_tensor));\n  float* scaling_factors_ptr = GetTensorData<float>(scaling_factors_tensor);\n  TfLiteTensor* input_offset_tensor;\n  TF_LITE_ENSURE_OK(context,\n                    GetTemporarySafe(context, node, data->input_offset_index,\n                                     &input_offset_tensor));\n  int32_t* input_offset_ptr = GetTensorData<int32_t>(input_offset_tensor);\n\n  for (int b = 0; b < batch_size; ++b) {\n    const int offset = b * input_size;\n    tensor_utils::AsymmetricQuantizeFloats(\n        GetTensorData<float>(input) + offset, input_size,\n        quantized_input_ptr_batch + offset, &scaling_factors_ptr[b],\n        &input_offset_ptr[b]);\n  }\n\n  DepthwiseParams op_params;\n  op_params.padding_type = PaddingType::kSame;\n  op_params.padding_values.width = data->padding.width;\n  op_params.padding_values.height = data->padding.height;\n  op_params.stride_width = params->stride_width;\n  op_params.stride_height = params->stride_height;\n  op_params.dilation_width_factor = params->dilation_width_factor;\n  op_params.dilation_height_factor = params->dilation_height_factor;\n  op_params.depth_multiplier = params->depth_multiplier;\n\n  op_params.weights_offset = 0;\n  op_params.float_activation_min = output_activation_min;\n  op_params.float_activation_max = output_activation_max;\n  const auto* affine_quantization =\n      reinterpret_cast<TfLiteAffineQuantization*>(filter->quantization.params);\n  if (kernel_type == kReference) {\n    reference_integer_ops::DepthwiseConvHybridPerChannel(\n        op_params, scaling_factors_ptr, GetTensorShape(input),\n        quantized_input_ptr_batch, GetTensorShape(filter),\n        GetTensorData<int8>(filter), GetTensorShape(bias),\n        GetTensorData<float>(bias), GetTensorShape(output),\n        GetTensorData<float>(output), affine_quantization->scale->data,\n        input_offset_ptr);\n  } else {\n    optimized_integer_ops::DepthwiseConvHybridPerChannel(\n        op_params, scaling_factors_ptr, GetTensorShape(input),\n        quantized_input_ptr_batch, GetTensorShape(filter),\n        GetTensorData<int8>(filter), GetTensorShape(bias),\n        GetTensorData<float>(bias), GetTensorShape(output),\n        GetTensorData<float>(output), affine_quantization->scale->data,\n        input_offset_ptr, CpuBackendContext::GetFromContext(context));\n  }\n\n  return kTfLiteOk;\n}",
        "func": "TfLiteStatus EvalHybridPerChannel(TfLiteContext* context, TfLiteNode* node,\n                                  TfLiteDepthwiseConvParams* params,\n                                  OpData* data, const TfLiteTensor* input,\n                                  const TfLiteTensor* filter,\n                                  const TfLiteTensor* bias,\n                                  TfLiteTensor* output) {\n  float output_activation_min, output_activation_max;\n  CalculateActivationRange(params->activation, &output_activation_min,\n                           &output_activation_max);\n  const int batch_size = SizeOfDimension(input, 0);\n  TF_LITE_ENSURE(context, batch_size != 0);\n  const int input_size = NumElements(input) / batch_size;\n  TfLiteTensor* input_quantized;\n  TF_LITE_ENSURE_OK(context,\n                    GetTemporarySafe(context, node, data->input_quantized_index,\n                                     &input_quantized));\n  int8_t* quantized_input_ptr_batch = input_quantized->data.int8;\n  TfLiteTensor* scaling_factors_tensor;\n  TF_LITE_ENSURE_OK(context,\n                    GetTemporarySafe(context, node, data->scaling_factors_index,\n                                     &scaling_factors_tensor));\n  float* scaling_factors_ptr = GetTensorData<float>(scaling_factors_tensor);\n  TfLiteTensor* input_offset_tensor;\n  TF_LITE_ENSURE_OK(context,\n                    GetTemporarySafe(context, node, data->input_offset_index,\n                                     &input_offset_tensor));\n  int32_t* input_offset_ptr = GetTensorData<int32_t>(input_offset_tensor);\n\n  for (int b = 0; b < batch_size; ++b) {\n    const int offset = b * input_size;\n    tensor_utils::AsymmetricQuantizeFloats(\n        GetTensorData<float>(input) + offset, input_size,\n        quantized_input_ptr_batch + offset, &scaling_factors_ptr[b],\n        &input_offset_ptr[b]);\n  }\n\n  DepthwiseParams op_params;\n  op_params.padding_type = PaddingType::kSame;\n  op_params.padding_values.width = data->padding.width;\n  op_params.padding_values.height = data->padding.height;\n  op_params.stride_width = params->stride_width;\n  op_params.stride_height = params->stride_height;\n  op_params.dilation_width_factor = params->dilation_width_factor;\n  op_params.dilation_height_factor = params->dilation_height_factor;\n  op_params.depth_multiplier = params->depth_multiplier;\n\n  op_params.weights_offset = 0;\n  op_params.float_activation_min = output_activation_min;\n  op_params.float_activation_max = output_activation_max;\n  TF_LITE_ENSURE(context, filter->quantization.type != kTfLiteNoQuantization);\n  const auto* affine_quantization =\n      reinterpret_cast<TfLiteAffineQuantization*>(filter->quantization.params);\n  if (kernel_type == kReference) {\n    reference_integer_ops::DepthwiseConvHybridPerChannel(\n        op_params, scaling_factors_ptr, GetTensorShape(input),\n        quantized_input_ptr_batch, GetTensorShape(filter),\n        GetTensorData<int8>(filter), GetTensorShape(bias),\n        GetTensorData<float>(bias), GetTensorShape(output),\n        GetTensorData<float>(output), affine_quantization->scale->data,\n        input_offset_ptr);\n  } else {\n    optimized_integer_ops::DepthwiseConvHybridPerChannel(\n        op_params, scaling_factors_ptr, GetTensorShape(input),\n        quantized_input_ptr_batch, GetTensorShape(filter),\n        GetTensorData<int8>(filter), GetTensorShape(bias),\n        GetTensorData<float>(bias), GetTensorShape(output),\n        GetTensorData<float>(output), affine_quantization->scale->data,\n        input_offset_ptr, CpuBackendContext::GetFromContext(context));\n  }\n\n  return kTfLiteOk;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -47,6 +47,7 @@\n   op_params.weights_offset = 0;\n   op_params.float_activation_min = output_activation_min;\n   op_params.float_activation_max = output_activation_max;\n+  TF_LITE_ENSURE(context, filter->quantization.type != kTfLiteNoQuantization);\n   const auto* affine_quantization =\n       reinterpret_cast<TfLiteAffineQuantization*>(filter->quantization.params);\n   if (kernel_type == kReference) {",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "  TF_LITE_ENSURE(context, filter->quantization.type != kTfLiteNoQuantization);"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-37682",
        "func_name": "tensorflow/Prepare",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions all TFLite operations that use quantization can be made to use unitialized values. [For example](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/lite/kernels/depthwise_conv.cc#L198-L200). The issue stems from the fact that `quantization.params` is only valid if `quantization.type` is different that `kTfLiteNoQuantization`. However, these checks are missing in large parts of the code. We have patched the issue in GitHub commits 537bc7c723439b9194a358f64d871dd326c18887, 4a91f2069f7145aab6ba2d8cfe41be8a110c18a5 and 8933b8a21280696ab119b63263babdb54c298538. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/8933b8a21280696ab119b63263babdb54c298538",
        "commit_title": "Fix a null pointer exception caused by branching on uninitialized data.",
        "commit_text": " This is due to not checking that the params for the quantization exists. If there is no quantization, we should not access the `.params` field.  PiperOrigin-RevId: 385173491",
        "func_before": "TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n  auto* params =\n      reinterpret_cast<TfLiteDepthwiseConvParams*>(node->builtin_data);\n  OpData* data = reinterpret_cast<OpData*>(node->user_data);\n\n  bool has_bias = NumInputs(node) == 3;\n\n  TF_LITE_ENSURE(context, has_bias || NumInputs(node) == 2);\n  const TfLiteTensor* input;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n  const TfLiteTensor* filter;\n  TF_LITE_ENSURE_OK(context,\n                    GetInputSafe(context, node, kFilterTensor, &filter));\n  const TfLiteTensor* bias = nullptr;\n\n  TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n  TfLiteTensor* output;\n  TF_LITE_ENSURE_OK(context,\n                    GetOutputSafe(context, node, kOutputTensor, &output));\n\n  TF_LITE_ENSURE_EQ(context, NumDimensions(input), 4);\n  TF_LITE_ENSURE_EQ(context, NumDimensions(filter), 4);\n\n  const TfLiteType data_type = input->type;\n\n  const TfLiteType filter_type = filter->type;\n  const bool is_hybrid =\n      data_type == kTfLiteFloat32 && filter_type == kTfLiteInt8;\n  TF_LITE_ENSURE(context,\n                 data_type == kTfLiteFloat32 || data_type == kTfLiteUInt8 ||\n                     data_type == kTfLiteInt8 || data_type == kTfLiteInt16);\n  TF_LITE_ENSURE_TYPES_EQ(context, output->type, data_type);\n  if (!is_hybrid) {\n    TF_LITE_ENSURE(context,\n                   filter->type == data_type || data_type == kTfLiteInt16);\n  }\n\n  if (data_type == kTfLiteInt16) {\n    TF_LITE_ENSURE_EQ(context, input->params.zero_point, 0);\n    TF_LITE_ENSURE_EQ(context, output->params.zero_point, 0);\n  }\n\n  // Filter in DepthwiseConv is expected to be [1, H, W, O].\n  TF_LITE_ENSURE_EQ(context, SizeOfDimension(filter, 0), 1);\n\n  if (has_bias) {\n    TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kBiasTensor, &bias));\n    if (data_type == kTfLiteUInt8 || data_type == kTfLiteInt8) {\n      TF_LITE_ENSURE_TYPES_EQ(context, bias->type, kTfLiteInt32);\n      TF_LITE_ENSURE_EQ(context, bias->params.zero_point, 0);\n    } else if (data_type == kTfLiteInt16) {\n      TF_LITE_ENSURE_TYPES_EQ(context, bias->type, kTfLiteInt64);\n      TF_LITE_ENSURE_EQ(context, bias->params.zero_point, 0);\n    } else {\n      TF_LITE_ENSURE_TYPES_EQ(context, bias->type, data_type);\n    }\n    TF_LITE_ENSURE_EQ(context, NumDimensions(bias), 1);\n    TF_LITE_ENSURE_EQ(context, SizeOfDimension(filter, 3),\n                      SizeOfDimension(bias, 0));\n  }\n\n  int channels_out = SizeOfDimension(filter, 3);\n  int width = SizeOfDimension(input, 2);\n  int height = SizeOfDimension(input, 1);\n  int filter_width = SizeOfDimension(filter, 2);\n  int filter_height = SizeOfDimension(filter, 1);\n  int batches = SizeOfDimension(input, 0);\n\n  // Matching GetWindowedOutputSize in TensorFlow.\n  auto padding = params->padding;\n  int out_width, out_height;\n\n  data->padding = ComputePaddingHeightWidth(\n      params->stride_height, params->stride_width,\n      params->dilation_height_factor, params->dilation_width_factor, height,\n      width, filter_height, filter_width, padding, &out_height, &out_width);\n\n  // Note that quantized inference requires that all tensors have their\n  // parameters set. This is usually done during quantized training or\n  // calibration.\n  if (data_type != kTfLiteFloat32) {\n    TF_LITE_ENSURE_EQ(context, filter->quantization.type,\n                      kTfLiteAffineQuantization);\n    const auto* affine_quantization =\n        reinterpret_cast<TfLiteAffineQuantization*>(\n            filter->quantization.params);\n    TF_LITE_ENSURE(context, affine_quantization);\n    TF_LITE_ENSURE(context, affine_quantization->scale);\n    TF_LITE_ENSURE(context, (affine_quantization->scale->size == 1 ||\n                             affine_quantization->scale->size == channels_out));\n\n    data->per_channel_output_multiplier.resize(channels_out);\n    data->per_channel_output_shift.resize(channels_out);\n    TF_LITE_ENSURE_STATUS(tflite::PopulateConvolutionQuantizationParams(\n        context, input, filter, bias, output, params->activation,\n        &data->output_multiplier, &data->output_shift,\n        &data->output_activation_min, &data->output_activation_max,\n        data->per_channel_output_multiplier.data(),\n        data->per_channel_output_shift.data(), channels_out));\n  }\n\n  if (is_hybrid) {\n    const auto* affine_quantization =\n        reinterpret_cast<TfLiteAffineQuantization*>(\n            filter->quantization.params);\n    TF_LITE_ENSURE(context, affine_quantization);\n    TF_LITE_ENSURE(context, affine_quantization->scale);\n    TF_LITE_ENSURE_EQ(\n        context, affine_quantization->scale->size,\n        filter->dims->data[affine_quantization->quantized_dimension]);\n\n    int temporaries_count = 0;\n    data->input_quantized_index = temporaries_count;\n    if (data->input_quantized_id == kTensorNotAllocated) {\n      TF_LITE_ENSURE_OK(\n          context, context->AddTensors(context, 1, &data->input_quantized_id));\n    }\n    ++temporaries_count;\n    data->scaling_factors_index = temporaries_count;\n    if (data->scaling_factors_id == kTensorNotAllocated) {\n      TF_LITE_ENSURE_OK(\n          context, context->AddTensors(context, 1, &data->scaling_factors_id));\n    }\n    ++temporaries_count;\n    data->input_offset_index = temporaries_count;\n    if (data->input_offset_id == kTensorNotAllocated) {\n      TF_LITE_ENSURE_OK(\n          context, context->AddTensors(context, 1, &data->input_offset_id));\n    }\n    ++temporaries_count;\n\n    TfLiteIntArrayFree(node->temporaries);\n    node->temporaries = TfLiteIntArrayCreate(temporaries_count);\n\n    node->temporaries->data[data->input_quantized_index] =\n        data->input_quantized_id;\n    TfLiteTensor* input_quantized;\n    TF_LITE_ENSURE_OK(\n        context, GetTemporarySafe(context, node, data->input_quantized_index,\n                                  &input_quantized));\n    input_quantized->type = kTfLiteInt8;\n    input_quantized->allocation_type = kTfLiteArenaRw;\n    if (!TfLiteIntArrayEqual(input_quantized->dims, input->dims)) {\n      TfLiteIntArray* input_quantized_size = TfLiteIntArrayCopy(input->dims);\n      TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, input_quantized,\n                                                       input_quantized_size));\n    }\n    node->temporaries->data[data->scaling_factors_index] =\n        data->scaling_factors_id;\n    TfLiteTensor* scaling_factors;\n    TF_LITE_ENSURE_OK(\n        context, GetTemporarySafe(context, node, data->scaling_factors_index,\n                                  &scaling_factors));\n    scaling_factors->type = kTfLiteFloat32;\n    scaling_factors->allocation_type = kTfLiteArenaRw;\n    const int batch_size = SizeOfDimension(input, 0);\n    int scaling_dims[1] = {batch_size};\n    if (!TfLiteIntArrayEqualsArray(scaling_factors->dims, 1, scaling_dims)) {\n      TfLiteIntArray* scaling_factors_size = TfLiteIntArrayCreate(1);\n      scaling_factors_size->data[0] = batch_size;\n      TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, scaling_factors,\n                                                       scaling_factors_size));\n    }\n    node->temporaries->data[data->input_offset_index] = data->input_offset_id;\n    TfLiteTensor* input_offsets;\n    TF_LITE_ENSURE_OK(context,\n                      GetTemporarySafe(context, node, data->input_offset_index,\n                                       &input_offsets));\n    input_offsets->type = kTfLiteInt32;\n    input_offsets->allocation_type = kTfLiteArenaRw;\n    if (!TfLiteIntArrayEqualsArray(input_offsets->dims, 1, scaling_dims)) {\n      TfLiteIntArray* input_offsets_size = TfLiteIntArrayCreate(1);\n      input_offsets_size->data[0] = batch_size;\n      TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, input_offsets,\n                                                       input_offsets_size));\n    }\n  }\n\n  TfLiteIntArray* outputSize = TfLiteIntArrayCreate(4);\n  outputSize->data[0] = batches;\n  outputSize->data[1] = out_height;\n  outputSize->data[2] = out_width;\n  outputSize->data[3] = channels_out;\n  return context->ResizeTensor(context, output, outputSize);\n}",
        "func": "TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n  auto* params =\n      reinterpret_cast<TfLiteDepthwiseConvParams*>(node->builtin_data);\n  OpData* data = reinterpret_cast<OpData*>(node->user_data);\n\n  bool has_bias = NumInputs(node) == 3;\n\n  TF_LITE_ENSURE(context, has_bias || NumInputs(node) == 2);\n  const TfLiteTensor* input;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n  const TfLiteTensor* filter;\n  TF_LITE_ENSURE_OK(context,\n                    GetInputSafe(context, node, kFilterTensor, &filter));\n  const TfLiteTensor* bias = nullptr;\n\n  TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n  TfLiteTensor* output;\n  TF_LITE_ENSURE_OK(context,\n                    GetOutputSafe(context, node, kOutputTensor, &output));\n\n  TF_LITE_ENSURE_EQ(context, NumDimensions(input), 4);\n  TF_LITE_ENSURE_EQ(context, NumDimensions(filter), 4);\n\n  const TfLiteType data_type = input->type;\n\n  const TfLiteType filter_type = filter->type;\n  const bool is_hybrid =\n      data_type == kTfLiteFloat32 && filter_type == kTfLiteInt8;\n  TF_LITE_ENSURE(context,\n                 data_type == kTfLiteFloat32 || data_type == kTfLiteUInt8 ||\n                     data_type == kTfLiteInt8 || data_type == kTfLiteInt16);\n  TF_LITE_ENSURE_TYPES_EQ(context, output->type, data_type);\n  if (!is_hybrid) {\n    TF_LITE_ENSURE(context,\n                   filter->type == data_type || data_type == kTfLiteInt16);\n  }\n\n  if (data_type == kTfLiteInt16) {\n    TF_LITE_ENSURE_EQ(context, input->params.zero_point, 0);\n    TF_LITE_ENSURE_EQ(context, output->params.zero_point, 0);\n  }\n\n  // Filter in DepthwiseConv is expected to be [1, H, W, O].\n  TF_LITE_ENSURE_EQ(context, SizeOfDimension(filter, 0), 1);\n\n  if (has_bias) {\n    TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kBiasTensor, &bias));\n    if (data_type == kTfLiteUInt8 || data_type == kTfLiteInt8) {\n      TF_LITE_ENSURE_TYPES_EQ(context, bias->type, kTfLiteInt32);\n      TF_LITE_ENSURE_EQ(context, bias->params.zero_point, 0);\n    } else if (data_type == kTfLiteInt16) {\n      TF_LITE_ENSURE_TYPES_EQ(context, bias->type, kTfLiteInt64);\n      TF_LITE_ENSURE_EQ(context, bias->params.zero_point, 0);\n    } else {\n      TF_LITE_ENSURE_TYPES_EQ(context, bias->type, data_type);\n    }\n    TF_LITE_ENSURE_EQ(context, NumDimensions(bias), 1);\n    TF_LITE_ENSURE_EQ(context, SizeOfDimension(filter, 3),\n                      SizeOfDimension(bias, 0));\n  }\n\n  int channels_out = SizeOfDimension(filter, 3);\n  int width = SizeOfDimension(input, 2);\n  int height = SizeOfDimension(input, 1);\n  int filter_width = SizeOfDimension(filter, 2);\n  int filter_height = SizeOfDimension(filter, 1);\n  int batches = SizeOfDimension(input, 0);\n\n  // Matching GetWindowedOutputSize in TensorFlow.\n  auto padding = params->padding;\n  int out_width, out_height;\n\n  data->padding = ComputePaddingHeightWidth(\n      params->stride_height, params->stride_width,\n      params->dilation_height_factor, params->dilation_width_factor, height,\n      width, filter_height, filter_width, padding, &out_height, &out_width);\n\n  // Note that quantized inference requires that all tensors have their\n  // parameters set. This is usually done during quantized training or\n  // calibration.\n  if (data_type != kTfLiteFloat32) {\n    TF_LITE_ENSURE_EQ(context, filter->quantization.type,\n                      kTfLiteAffineQuantization);\n    TF_LITE_ENSURE(context, filter->quantization.type != kTfLiteNoQuantization);\n    const auto* affine_quantization =\n        reinterpret_cast<TfLiteAffineQuantization*>(\n            filter->quantization.params);\n    TF_LITE_ENSURE(context, affine_quantization);\n    TF_LITE_ENSURE(context, affine_quantization->scale);\n    TF_LITE_ENSURE(context, (affine_quantization->scale->size == 1 ||\n                             affine_quantization->scale->size == channels_out));\n\n    data->per_channel_output_multiplier.resize(channels_out);\n    data->per_channel_output_shift.resize(channels_out);\n    TF_LITE_ENSURE_STATUS(tflite::PopulateConvolutionQuantizationParams(\n        context, input, filter, bias, output, params->activation,\n        &data->output_multiplier, &data->output_shift,\n        &data->output_activation_min, &data->output_activation_max,\n        data->per_channel_output_multiplier.data(),\n        data->per_channel_output_shift.data(), channels_out));\n  }\n\n  if (is_hybrid) {\n    TF_LITE_ENSURE(context, filter->quantization.type != kTfLiteNoQuantization);\n    const auto* affine_quantization =\n        reinterpret_cast<TfLiteAffineQuantization*>(\n            filter->quantization.params);\n    TF_LITE_ENSURE(context, affine_quantization);\n    TF_LITE_ENSURE(context, affine_quantization->scale);\n    TF_LITE_ENSURE_EQ(\n        context, affine_quantization->scale->size,\n        filter->dims->data[affine_quantization->quantized_dimension]);\n\n    int temporaries_count = 0;\n    data->input_quantized_index = temporaries_count;\n    if (data->input_quantized_id == kTensorNotAllocated) {\n      TF_LITE_ENSURE_OK(\n          context, context->AddTensors(context, 1, &data->input_quantized_id));\n    }\n    ++temporaries_count;\n    data->scaling_factors_index = temporaries_count;\n    if (data->scaling_factors_id == kTensorNotAllocated) {\n      TF_LITE_ENSURE_OK(\n          context, context->AddTensors(context, 1, &data->scaling_factors_id));\n    }\n    ++temporaries_count;\n    data->input_offset_index = temporaries_count;\n    if (data->input_offset_id == kTensorNotAllocated) {\n      TF_LITE_ENSURE_OK(\n          context, context->AddTensors(context, 1, &data->input_offset_id));\n    }\n    ++temporaries_count;\n\n    TfLiteIntArrayFree(node->temporaries);\n    node->temporaries = TfLiteIntArrayCreate(temporaries_count);\n\n    node->temporaries->data[data->input_quantized_index] =\n        data->input_quantized_id;\n    TfLiteTensor* input_quantized;\n    TF_LITE_ENSURE_OK(\n        context, GetTemporarySafe(context, node, data->input_quantized_index,\n                                  &input_quantized));\n    input_quantized->type = kTfLiteInt8;\n    input_quantized->allocation_type = kTfLiteArenaRw;\n    if (!TfLiteIntArrayEqual(input_quantized->dims, input->dims)) {\n      TfLiteIntArray* input_quantized_size = TfLiteIntArrayCopy(input->dims);\n      TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, input_quantized,\n                                                       input_quantized_size));\n    }\n    node->temporaries->data[data->scaling_factors_index] =\n        data->scaling_factors_id;\n    TfLiteTensor* scaling_factors;\n    TF_LITE_ENSURE_OK(\n        context, GetTemporarySafe(context, node, data->scaling_factors_index,\n                                  &scaling_factors));\n    scaling_factors->type = kTfLiteFloat32;\n    scaling_factors->allocation_type = kTfLiteArenaRw;\n    const int batch_size = SizeOfDimension(input, 0);\n    int scaling_dims[1] = {batch_size};\n    if (!TfLiteIntArrayEqualsArray(scaling_factors->dims, 1, scaling_dims)) {\n      TfLiteIntArray* scaling_factors_size = TfLiteIntArrayCreate(1);\n      scaling_factors_size->data[0] = batch_size;\n      TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, scaling_factors,\n                                                       scaling_factors_size));\n    }\n    node->temporaries->data[data->input_offset_index] = data->input_offset_id;\n    TfLiteTensor* input_offsets;\n    TF_LITE_ENSURE_OK(context,\n                      GetTemporarySafe(context, node, data->input_offset_index,\n                                       &input_offsets));\n    input_offsets->type = kTfLiteInt32;\n    input_offsets->allocation_type = kTfLiteArenaRw;\n    if (!TfLiteIntArrayEqualsArray(input_offsets->dims, 1, scaling_dims)) {\n      TfLiteIntArray* input_offsets_size = TfLiteIntArrayCreate(1);\n      input_offsets_size->data[0] = batch_size;\n      TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, input_offsets,\n                                                       input_offsets_size));\n    }\n  }\n\n  TfLiteIntArray* outputSize = TfLiteIntArrayCreate(4);\n  outputSize->data[0] = batches;\n  outputSize->data[1] = out_height;\n  outputSize->data[2] = out_width;\n  outputSize->data[3] = channels_out;\n  return context->ResizeTensor(context, output, outputSize);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -81,6 +81,7 @@\n   if (data_type != kTfLiteFloat32) {\n     TF_LITE_ENSURE_EQ(context, filter->quantization.type,\n                       kTfLiteAffineQuantization);\n+    TF_LITE_ENSURE(context, filter->quantization.type != kTfLiteNoQuantization);\n     const auto* affine_quantization =\n         reinterpret_cast<TfLiteAffineQuantization*>(\n             filter->quantization.params);\n@@ -100,6 +101,7 @@\n   }\n \n   if (is_hybrid) {\n+    TF_LITE_ENSURE(context, filter->quantization.type != kTfLiteNoQuantization);\n     const auto* affine_quantization =\n         reinterpret_cast<TfLiteAffineQuantization*>(\n             filter->quantization.params);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    TF_LITE_ENSURE(context, filter->quantization.type != kTfLiteNoQuantization);",
                "    TF_LITE_ENSURE(context, filter->quantization.type != kTfLiteNoQuantization);"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-36617",
        "func_name": "ewxrjk/sftpserver/sftp_parse_handle",
        "description": "A vulnerability was found in ewxrjk sftpserver. It has been declared as problematic. Affected by this vulnerability is the function sftp_parse_path of the file parse.c. The manipulation leads to uninitialized pointer. The real existence of this vulnerability is still doubted at the moment. The name of the patch is bf4032f34832ee11d79aa60a226cc018e7ec5eed. It is recommended to apply a patch to fix this issue. The identifier VDB-216205 was assigned to this vulnerability. NOTE: In some deployment models this would be a vulnerability. README specifically warns about avoiding such deployment models.",
        "git_url": "https://github.com/ewxrjk/sftpserver/commit/bf4032f34832ee11d79aa60a226cc018e7ec5eed",
        "commit_title": "Fix handle mis-parse",
        "commit_text": " This could lead to the server process accessing uninitialized data.  In some deployment models this would be a vulnerability. However, the README specifically warns about avoiding such deployment models, so this patch is not going to be treated as a vulnerability fix.",
        "func_before": "uint32_t sftp_parse_handle(struct sftpjob *job, struct handleid *id) {\n  uint32_t len, rc;\n\n  if((rc = sftp_parse_uint32(job, &len)) != SSH_FX_OK || len != 8 ||\n     (rc = sftp_parse_uint32(job, &id->id)) != SSH_FX_OK ||\n     (rc = sftp_parse_uint32(job, &id->tag) != SSH_FX_OK))\n    return rc;\n  return SSH_FX_OK;\n}",
        "func": "uint32_t sftp_parse_handle(struct sftpjob *job, struct handleid *id) {\n  uint32_t len, rc;\n\n  if((rc = sftp_parse_uint32(job, &len)) != SSH_FX_OK)\n    return rc;\n  if(len != 8)\n    return SSH_FX_BAD_MESSAGE;\n  if((rc = sftp_parse_uint32(job, &id->id)) != SSH_FX_OK ||\n     (rc = sftp_parse_uint32(job, &id->tag) != SSH_FX_OK))\n    return rc;\n  return SSH_FX_OK;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,8 +1,11 @@\n uint32_t sftp_parse_handle(struct sftpjob *job, struct handleid *id) {\n   uint32_t len, rc;\n \n-  if((rc = sftp_parse_uint32(job, &len)) != SSH_FX_OK || len != 8 ||\n-     (rc = sftp_parse_uint32(job, &id->id)) != SSH_FX_OK ||\n+  if((rc = sftp_parse_uint32(job, &len)) != SSH_FX_OK)\n+    return rc;\n+  if(len != 8)\n+    return SSH_FX_BAD_MESSAGE;\n+  if((rc = sftp_parse_uint32(job, &id->id)) != SSH_FX_OK ||\n      (rc = sftp_parse_uint32(job, &id->tag) != SSH_FX_OK))\n     return rc;\n   return SSH_FX_OK;",
        "diff_line_info": {
            "deleted_lines": [
                "  if((rc = sftp_parse_uint32(job, &len)) != SSH_FX_OK || len != 8 ||",
                "     (rc = sftp_parse_uint32(job, &id->id)) != SSH_FX_OK ||"
            ],
            "added_lines": [
                "  if((rc = sftp_parse_uint32(job, &len)) != SSH_FX_OK)",
                "    return rc;",
                "  if(len != 8)",
                "    return SSH_FX_BAD_MESSAGE;",
                "  if((rc = sftp_parse_uint32(job, &id->id)) != SSH_FX_OK ||"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-47012",
        "func_name": "GNS3/dynamips/netio_recv",
        "description": "Use of uninitialized variable in function gen_eth_recv in GNS3 dynamips 0.2.21.",
        "git_url": "https://github.com/GNS3/dynamips/commit/71ac4e22695e70b8c68dabcd4e671f75db010254",
        "commit_title": "Zero pkt in netio_recv.",
        "commit_text": " Closes #125 Hopefully it will make mend happy. Closes #136",
        "func_before": "ssize_t netio_recv(netio_desc_t *nio,void *pkt,size_t max_len)\n{\n   ssize_t len;\n   int res;\n\n   if (!nio)\n      return(-1);\n\n   /* Receive the packet */\n   if ((len = nio->recv(nio->dptr,pkt,max_len)) <= 0)\n      return(-1);\n\n   if (nio->debug) {\n      printf(\"NIO %s: receiving a packet of %ld bytes:\\n\",nio->name,(long)len);\n      mem_dump(stdout,pkt,len);\n   }\n\n   /* Apply the RX filter */\n   if (nio->rx_filter != NULL) {\n      res = nio->rx_filter->pkt_handler(nio,pkt,len,nio->rx_filter_data);\n\n      if (res == NETIO_FILTER_ACTION_DROP)\n         return(-1);\n   }\n\n   /* Apply the bidirectional filter */\n   if (nio->both_filter != NULL) {\n      res = nio->both_filter->pkt_handler(nio,pkt,len,nio->both_filter_data);\n\n      if (res == NETIO_FILTER_ACTION_DROP)\n         return(-1);\n   }\n\n   /* Update input statistics */\n   nio->stats_pkts_in++;\n   nio->stats_bytes_in += len;\n   return(len);\n}",
        "func": "ssize_t netio_recv(netio_desc_t *nio,void *pkt,size_t max_len)\n{\n   ssize_t len;\n   int res;\n\n   if (!nio)\n      return(-1);\n\n   /* Receive the packet */\n   memset(pkt, 0, max_len);\n   if ((len = nio->recv(nio->dptr,pkt,max_len)) <= 0)\n      return(-1);\n\n   if (nio->debug) {\n      printf(\"NIO %s: receiving a packet of %ld bytes:\\n\",nio->name,(long)len);\n      mem_dump(stdout,pkt,len);\n   }\n\n   /* Apply the RX filter */\n   if (nio->rx_filter != NULL) {\n      res = nio->rx_filter->pkt_handler(nio,pkt,len,nio->rx_filter_data);\n\n      if (res == NETIO_FILTER_ACTION_DROP)\n         return(-1);\n   }\n\n   /* Apply the bidirectional filter */\n   if (nio->both_filter != NULL) {\n      res = nio->both_filter->pkt_handler(nio,pkt,len,nio->both_filter_data);\n\n      if (res == NETIO_FILTER_ACTION_DROP)\n         return(-1);\n   }\n\n   /* Update input statistics */\n   nio->stats_pkts_in++;\n   nio->stats_bytes_in += len;\n   return(len);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -7,6 +7,7 @@\n       return(-1);\n \n    /* Receive the packet */\n+   memset(pkt, 0, max_len);\n    if ((len = nio->recv(nio->dptr,pkt,max_len)) <= 0)\n       return(-1);\n ",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "   memset(pkt, 0, max_len);"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-29205",
        "func_name": "tensorflow/SetOpAttrScalar",
        "description": "TensorFlow is an open source platform for machine learning. Prior to versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4, there is a potential for segfault / denial of service in TensorFlow by calling `tf.compat.v1.*` ops which don't yet have support for quantized types, which was added after migration to TensorFlow 2.x. In these scenarios, since the kernel is missing, a `nullptr` value is passed to `ParseDimensionValue` for the `py_value` argument. Then, this is dereferenced, resulting in segfault. Versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4 contain a patch for this issue.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/237822b59fc504dda2c564787f5d3ad9c4aa62d9",
        "commit_title": "Fix tf.compat.v1.placeholder_with_default vulnerability with quantized types.",
        "commit_text": " When iterating through the tensor to extract shape values, an underlying missing kernel (`StridedSlice` for quantized types) causes an error, which then results in a `nullptr` being passed to `ParseDimensionValue()`, causing a segfault.  The `nullptr` check allows the missing kernel error to propagate. Adding the missing kernel registrations allows the shape values to be extracted successfully.  PiperOrigin-RevId: 445045957",
        "func_before": "bool SetOpAttrScalar(TFE_Context* ctx, TFE_Op* op, const char* key,\n                     PyObject* py_value, TF_AttrType type,\n                     tensorflow::gtl::FlatMap<string, int64_t>* attr_list_sizes,\n                     TF_Status* status) {\n  if (type == TF_ATTR_STRING) {\n    tensorflow::StringPiece value;\n    if (!ParseStringValue(key, py_value, status, &value)) return false;\n    TFE_OpSetAttrString(op, key, value.data(), value.size());\n  } else if (type == TF_ATTR_INT) {\n    int64_t value;\n    if (!ParseInt64Value(key, py_value, status, &value)) return false;\n    TFE_OpSetAttrInt(op, key, value);\n    // attr_list_sizes is set for all int attributes (since at this point we are\n    // not aware if that attribute might be used to calculate the size of an\n    // output list or not).\n    if (attr_list_sizes != nullptr) (*attr_list_sizes)[key] = value;\n  } else if (type == TF_ATTR_FLOAT) {\n    float value;\n    if (!ParseFloatValue(key, py_value, status, &value)) return false;\n    TFE_OpSetAttrFloat(op, key, value);\n  } else if (type == TF_ATTR_BOOL) {\n    unsigned char value;\n    if (!ParseBoolValue(key, py_value, status, &value)) return false;\n    TFE_OpSetAttrBool(op, key, value);\n  } else if (type == TF_ATTR_TYPE) {\n    int value;\n    if (!ParseTypeValue(key, py_value, status, &value)) return false;\n    TFE_OpSetAttrType(op, key, static_cast<TF_DataType>(value));\n  } else if (type == TF_ATTR_SHAPE) {\n    if (py_value == Py_None) {\n      TFE_OpSetAttrShape(op, key, nullptr, -1, status);\n    } else {\n      if (!PySequence_Check(py_value)) {\n        TF_SetStatus(status, TF_INVALID_ARGUMENT,\n                     tensorflow::strings::StrCat(\n                         \"Expecting None or sequence value for attr\", key,\n                         \", got \", py_value->ob_type->tp_name)\n                         .c_str());\n        return false;\n      }\n      const auto num_dims = TensorShapeNumDims(py_value);\n      if (num_dims == -1) {\n        TFE_OpSetAttrShape(op, key, nullptr, -1, status);\n        return true;\n      }\n      std::unique_ptr<int64_t[]> dims(new int64_t[num_dims]);\n      for (int i = 0; i < num_dims; ++i) {\n        tensorflow::Safe_PyObjectPtr inner_py_value(\n            PySequence_ITEM(py_value, i));\n        if (inner_py_value.get() == Py_None) {\n          dims[i] = -1;\n        } else if (!ParseDimensionValue(key, inner_py_value.get(), status,\n                                        &dims[i])) {\n          return false;\n        }\n      }\n      TFE_OpSetAttrShape(op, key, dims.get(), num_dims, status);\n    }\n    if (!status->status.ok()) return false;\n  } else if (type == TF_ATTR_FUNC) {\n    // Allow:\n    // (1) String function name, OR\n    // (2) A Python object with a .name attribute\n    //     (A crude test for being a\n    //     tensorflow.python.framework.function._DefinedFunction)\n    //     (which is what the various \"defun\" or \"Defun\" decorators do).\n    // And in the future also allow an object that can encapsulate\n    // the function name and its attribute values.\n    tensorflow::StringPiece func_name;\n    if (!ParseStringValue(key, py_value, status, &func_name)) {\n      PyObject* name_attr = PyObject_GetAttrString(py_value, \"name\");\n      if (name_attr == nullptr ||\n          !ParseStringValue(key, name_attr, status, &func_name)) {\n        TF_SetStatus(\n            status, TF_INVALID_ARGUMENT,\n            tensorflow::strings::StrCat(\n                \"unable to set function value attribute from a \",\n                py_value->ob_type->tp_name,\n                \" object. If you think this is an error, please file an issue \"\n                \"at https://github.com/tensorflow/tensorflow/issues/new\")\n                .c_str());\n        return false;\n      }\n    }\n    TF_SetStatus(status, TF_OK, \"\");\n    TFE_OpSetAttrFunctionName(op, key, func_name.data(), func_name.size());\n  } else {\n    TF_SetStatus(\n        status, TF_UNIMPLEMENTED,\n        tensorflow::strings::StrCat(\"Attr \", key, \" has unhandled type \", type)\n            .c_str());\n    return false;\n  }\n  return true;\n}",
        "func": "bool SetOpAttrScalar(TFE_Context* ctx, TFE_Op* op, const char* key,\n                     PyObject* py_value, TF_AttrType type,\n                     tensorflow::gtl::FlatMap<string, int64_t>* attr_list_sizes,\n                     TF_Status* status) {\n  if (type == TF_ATTR_STRING) {\n    tensorflow::StringPiece value;\n    if (!ParseStringValue(key, py_value, status, &value)) return false;\n    TFE_OpSetAttrString(op, key, value.data(), value.size());\n  } else if (type == TF_ATTR_INT) {\n    int64_t value;\n    if (!ParseInt64Value(key, py_value, status, &value)) return false;\n    TFE_OpSetAttrInt(op, key, value);\n    // attr_list_sizes is set for all int attributes (since at this point we are\n    // not aware if that attribute might be used to calculate the size of an\n    // output list or not).\n    if (attr_list_sizes != nullptr) (*attr_list_sizes)[key] = value;\n  } else if (type == TF_ATTR_FLOAT) {\n    float value;\n    if (!ParseFloatValue(key, py_value, status, &value)) return false;\n    TFE_OpSetAttrFloat(op, key, value);\n  } else if (type == TF_ATTR_BOOL) {\n    unsigned char value;\n    if (!ParseBoolValue(key, py_value, status, &value)) return false;\n    TFE_OpSetAttrBool(op, key, value);\n  } else if (type == TF_ATTR_TYPE) {\n    int value;\n    if (!ParseTypeValue(key, py_value, status, &value)) return false;\n    TFE_OpSetAttrType(op, key, static_cast<TF_DataType>(value));\n  } else if (type == TF_ATTR_SHAPE) {\n    if (py_value == Py_None) {\n      TFE_OpSetAttrShape(op, key, nullptr, -1, status);\n    } else {\n      if (!PySequence_Check(py_value)) {\n        TF_SetStatus(status, TF_INVALID_ARGUMENT,\n                     tensorflow::strings::StrCat(\n                         \"Expecting None or sequence value for attr\", key,\n                         \", got \", py_value->ob_type->tp_name)\n                         .c_str());\n        return false;\n      }\n      const auto num_dims = TensorShapeNumDims(py_value);\n      if (num_dims == -1) {\n        TFE_OpSetAttrShape(op, key, nullptr, -1, status);\n        return true;\n      }\n      std::unique_ptr<int64_t[]> dims(new int64_t[num_dims]);\n      for (int i = 0; i < num_dims; ++i) {\n        tensorflow::Safe_PyObjectPtr inner_py_value(\n            PySequence_ITEM(py_value, i));\n        // If an error is generated when iterating through object, we can\n        // sometimes get a nullptr.\n        if (inner_py_value.get() == Py_None) {\n          dims[i] = -1;\n        } else if (inner_py_value.get() == nullptr ||\n                   !ParseDimensionValue(key, inner_py_value.get(), status,\n                                        &dims[i])) {\n          return false;\n        }\n      }\n      TFE_OpSetAttrShape(op, key, dims.get(), num_dims, status);\n    }\n    if (!status->status.ok()) return false;\n  } else if (type == TF_ATTR_FUNC) {\n    // Allow:\n    // (1) String function name, OR\n    // (2) A Python object with a .name attribute\n    //     (A crude test for being a\n    //     tensorflow.python.framework.function._DefinedFunction)\n    //     (which is what the various \"defun\" or \"Defun\" decorators do).\n    // And in the future also allow an object that can encapsulate\n    // the function name and its attribute values.\n    tensorflow::StringPiece func_name;\n    if (!ParseStringValue(key, py_value, status, &func_name)) {\n      PyObject* name_attr = PyObject_GetAttrString(py_value, \"name\");\n      if (name_attr == nullptr ||\n          !ParseStringValue(key, name_attr, status, &func_name)) {\n        TF_SetStatus(\n            status, TF_INVALID_ARGUMENT,\n            tensorflow::strings::StrCat(\n                \"unable to set function value attribute from a \",\n                py_value->ob_type->tp_name,\n                \" object. If you think this is an error, please file an issue \"\n                \"at https://github.com/tensorflow/tensorflow/issues/new\")\n                .c_str());\n        return false;\n      }\n    }\n    TF_SetStatus(status, TF_OK, \"\");\n    TFE_OpSetAttrFunctionName(op, key, func_name.data(), func_name.size());\n  } else {\n    TF_SetStatus(\n        status, TF_UNIMPLEMENTED,\n        tensorflow::strings::StrCat(\"Attr \", key, \" has unhandled type \", type)\n            .c_str());\n    return false;\n  }\n  return true;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -47,9 +47,12 @@\n       for (int i = 0; i < num_dims; ++i) {\n         tensorflow::Safe_PyObjectPtr inner_py_value(\n             PySequence_ITEM(py_value, i));\n+        // If an error is generated when iterating through object, we can\n+        // sometimes get a nullptr.\n         if (inner_py_value.get() == Py_None) {\n           dims[i] = -1;\n-        } else if (!ParseDimensionValue(key, inner_py_value.get(), status,\n+        } else if (inner_py_value.get() == nullptr ||\n+                   !ParseDimensionValue(key, inner_py_value.get(), status,\n                                         &dims[i])) {\n           return false;\n         }",
        "diff_line_info": {
            "deleted_lines": [
                "        } else if (!ParseDimensionValue(key, inner_py_value.get(), status,"
            ],
            "added_lines": [
                "        // If an error is generated when iterating through object, we can",
                "        // sometimes get a nullptr.",
                "        } else if (inner_py_value.get() == nullptr ||",
                "                   !ParseDimensionValue(key, inner_py_value.get(), status,"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-9098",
        "func_name": "ImageMagick/ReadRLEImage",
        "description": "ImageMagick before 7.0.5-2 and GraphicsMagick before 1.3.24 use uninitialized memory in the RLE decoder, allowing an attacker to leak sensitive information from process memory space, as demonstrated by remote attacks against ImageMagick code in a long-running server process that converts image data on behalf of multiple users. This is caused by a missing initialization step in the ReadRLEImage function in coders/rle.c.",
        "git_url": "https://github.com/ImageMagick/ImageMagick/commit/1c358ffe0049f768dd49a8a889c1cbf99ac9849b",
        "commit_title": "Reset memory for RLE decoder (patch provided by scarybeasts)",
        "commit_text": "",
        "func_before": "static Image *ReadRLEImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n#define SkipLinesOp  0x01\n#define SetColorOp  0x02\n#define SkipPixelsOp  0x03\n#define ByteDataOp  0x05\n#define RunDataOp  0x06\n#define EOFOp  0x07\n\n  char\n    magick[12];\n\n  Image\n    *image;\n\n  int\n    opcode,\n    operand,\n    status;\n\n  MagickStatusType\n    flags;\n\n  MagickSizeType\n    number_pixels;\n\n  MemoryInfo\n    *pixel_info;\n\n  Quantum\n    index;\n\n  register ssize_t\n    x;\n\n  register Quantum\n    *q;\n\n  register ssize_t\n    i;\n\n  register unsigned char\n    *p;\n\n  size_t\n    bits_per_pixel,\n    map_length,\n    number_colormaps,\n    number_planes,\n    number_planes_filled,\n    one,\n    pixel_info_length;\n\n  ssize_t\n    count,\n    offset,\n    y;\n\n  unsigned char\n    background_color[256],\n    *colormap,\n    pixel,\n    plane,\n    *pixels;\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  image=AcquireImage(image_info,exception);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    return(DestroyImageList(image));\n  /*\n    Determine if this a RLE file.\n  */\n  count=ReadBlob(image,2,(unsigned char *) magick);\n  if ((count != 2) || (memcmp(magick,\"\\122\\314\",2) != 0))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  do\n  {\n    /*\n      Read image header.\n    */\n    image->page.x=ReadBlobLSBShort(image);\n    image->page.y=ReadBlobLSBShort(image);\n    image->columns=ReadBlobLSBShort(image);\n    image->rows=ReadBlobLSBShort(image);\n    flags=(MagickStatusType) ReadBlobByte(image);\n    image->alpha_trait=flags & 0x04 ? BlendPixelTrait : UndefinedPixelTrait;\n    number_planes=(size_t) ReadBlobByte(image);\n    bits_per_pixel=(size_t) ReadBlobByte(image);\n    number_colormaps=(size_t) ReadBlobByte(image);\n    map_length=(unsigned char) ReadBlobByte(image);\n    if (map_length >= 22)\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    one=1;\n    map_length=one << map_length;\n    if ((number_planes == 0) || (number_planes == 2) ||\n        ((flags & 0x04) && (number_colormaps > 254)) || (bits_per_pixel != 8) ||\n        (image->columns == 0))\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    if (flags & 0x02)\n      {\n        /*\n          No background color-- initialize to black.\n        */\n        for (i=0; i < (ssize_t) number_planes; i++)\n          background_color[i]=0;\n        (void) ReadBlobByte(image);\n      }\n    else\n      {\n        /*\n          Initialize background color.\n        */\n        p=background_color;\n        for (i=0; i < (ssize_t) number_planes; i++)\n          *p++=(unsigned char) ReadBlobByte(image);\n      }\n    if ((number_planes & 0x01) == 0)\n      (void) ReadBlobByte(image);\n    if (EOFBlob(image) != MagickFalse)\n      {\n        ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n          image->filename);\n        break;\n      }\n    colormap=(unsigned char *) NULL;\n    if (number_colormaps != 0)\n      {\n        /*\n          Read image colormaps.\n        */\n        colormap=(unsigned char *) AcquireQuantumMemory(number_colormaps,\n          3*map_length*sizeof(*colormap));\n        if (colormap == (unsigned char *) NULL)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        p=colormap;\n        for (i=0; i < (ssize_t) number_colormaps; i++)\n          for (x=0; x < (ssize_t) map_length; x++)\n            *p++=(unsigned char) ScaleShortToQuantum(ReadBlobLSBShort(image));\n      }\n    if ((flags & 0x08) != 0)\n      {\n        char\n          *comment;\n\n        size_t\n          length;\n\n        /*\n          Read image comment.\n        */\n        length=ReadBlobLSBShort(image);\n        if (length != 0)\n          {\n            comment=(char *) AcquireQuantumMemory(length,sizeof(*comment));\n            if (comment == (char *) NULL)\n              ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n            count=ReadBlob(image,length-1,(unsigned char *) comment);\n            comment[length-1]='\\0';\n            (void) SetImageProperty(image,\"comment\",comment,exception);\n            comment=DestroyString(comment);\n            if ((length & 0x01) == 0)\n              (void) ReadBlobByte(image);\n          }\n      }\n    if (EOFBlob(image) != MagickFalse)\n      {\n        ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n          image->filename);\n        break;\n      }\n    if ((image_info->ping != MagickFalse) && (image_info->number_scenes != 0))\n      if (image->scene >= (image_info->scene+image_info->number_scenes-1))\n        break;\n    status=SetImageExtent(image,image->columns,image->rows,exception);\n    if (status == MagickFalse)\n      return(DestroyImageList(image));\n    /*\n      Allocate RLE pixels.\n    */\n    if (image->alpha_trait != UndefinedPixelTrait)\n      number_planes++;\n    number_pixels=(MagickSizeType) image->columns*image->rows;\n    number_planes_filled=(number_planes % 2 == 0) ? number_planes :\n      number_planes+1;\n    if ((number_pixels*number_planes_filled) != (size_t) (number_pixels*\n         number_planes_filled))\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    pixel_info=AcquireVirtualMemory(image->columns,image->rows*\n      MagickMax(number_planes_filled,4)*sizeof(*pixels));\n    if (pixel_info == (MemoryInfo *) NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    pixel_info_length=image->columns*image->rows*\n      MagickMax(number_planes_filled,4);\n    pixels=(unsigned char *) GetVirtualMemoryBlob(pixel_info);\n    if ((flags & 0x01) && !(flags & 0x02))\n      {\n        ssize_t\n          j;\n\n        /*\n          Set background color.\n        */\n        p=pixels;\n        for (i=0; i < (ssize_t) number_pixels; i++)\n        {\n          if (image->alpha_trait == UndefinedPixelTrait)\n            for (j=0; j < (ssize_t) number_planes; j++)\n              *p++=background_color[j];\n          else\n            {\n              for (j=0; j < (ssize_t) (number_planes-1); j++)\n                *p++=background_color[j];\n              *p++=0;  /* initialize matte channel */\n            }\n        }\n      }\n    /*\n      Read runlength-encoded image.\n    */\n    plane=0;\n    x=0;\n    y=0;\n    opcode=ReadBlobByte(image);\n    do\n    {\n      switch (opcode & 0x3f)\n      {\n        case SkipLinesOp:\n        {\n          operand=ReadBlobByte(image);\n          if (opcode & 0x40)\n            operand=ReadBlobLSBSignedShort(image);\n          x=0;\n          y+=operand;\n          break;\n        }\n        case SetColorOp:\n        {\n          operand=ReadBlobByte(image);\n          plane=(unsigned char) operand;\n          if (plane == 255)\n            plane=(unsigned char) (number_planes-1);\n          x=0;\n          break;\n        }\n        case SkipPixelsOp:\n        {\n          operand=ReadBlobByte(image);\n          if (opcode & 0x40)\n            operand=ReadBlobLSBSignedShort(image);\n          x+=operand;\n          break;\n        }\n        case ByteDataOp:\n        {\n          operand=ReadBlobByte(image);\n          if (opcode & 0x40)\n            operand=ReadBlobLSBSignedShort(image);\n          offset=((image->rows-y-1)*image->columns*number_planes)+x*\n            number_planes+plane;\n          operand++;\n          if ((offset < 0) ||\n              (offset+((size_t) operand*number_planes) > pixel_info_length))\n            {\n              if (number_colormaps != 0)\n                colormap=(unsigned char *) RelinquishMagickMemory(colormap);\n              pixel_info=RelinquishVirtualMemory(pixel_info);\n              ThrowReaderException(CorruptImageError,\"UnableToReadImageData\");\n            }\n          p=pixels+offset;\n          for (i=0; i < (ssize_t) operand; i++)\n          {\n            pixel=(unsigned char) ReadBlobByte(image);\n            if ((y < (ssize_t) image->rows) &&\n                ((x+i) < (ssize_t) image->columns))\n              *p=pixel;\n            p+=number_planes;\n          }\n          if (operand & 0x01)\n            (void) ReadBlobByte(image);\n          x+=operand;\n          break;\n        }\n        case RunDataOp:\n        {\n          operand=ReadBlobByte(image);\n          if (opcode & 0x40)\n            operand=ReadBlobLSBSignedShort(image);\n          pixel=(unsigned char) ReadBlobByte(image);\n          (void) ReadBlobByte(image);\n          offset=((image->rows-y-1)*image->columns*number_planes)+x*\n            number_planes+plane;\n          operand++;\n          if ((offset < 0) ||\n              (offset+((size_t) operand*number_planes) > pixel_info_length))\n            {\n              if (number_colormaps != 0)\n                colormap=(unsigned char *) RelinquishMagickMemory(colormap);\n              pixel_info=RelinquishVirtualMemory(pixel_info);\n              ThrowReaderException(CorruptImageError,\"UnableToReadImageData\");\n            }\n          p=pixels+offset;\n          for (i=0; i < (ssize_t) operand; i++)\n          {\n            if ((y < (ssize_t) image->rows) &&\n                ((x+i) < (ssize_t) image->columns))\n              *p=pixel;\n            p+=number_planes;\n          }\n          x+=operand;\n          break;\n        }\n        default:\n          break;\n      }\n      opcode=ReadBlobByte(image);\n    } while (((opcode & 0x3f) != EOFOp) && (opcode != EOF));\n    if (number_colormaps != 0)\n      {\n        MagickStatusType\n          mask;\n\n        /*\n          Apply colormap affineation to image.\n        */\n        mask=(MagickStatusType) (map_length-1);\n        p=pixels;\n        x=(ssize_t) number_planes;\n        if (number_colormaps == 1)\n          for (i=0; i < (ssize_t) number_pixels; i++)\n          {\n            ValidateColormapValue(image,*p & mask,&index,exception);\n            *p=colormap[(ssize_t) index];\n            p++;\n          }\n        else\n          if ((number_planes >= 3) && (number_colormaps >= 3))\n            for (i=0; i < (ssize_t) number_pixels; i++)\n              for (x=0; x < (ssize_t) number_planes; x++)\n              {\n                ValidateColormapValue(image,(size_t) (x*map_length+\n                    (*p & mask)),&index,exception);\n                *p=colormap[(ssize_t) index];\n                p++;\n              }\n        if ((i < (ssize_t) number_pixels) || (x < (ssize_t) number_planes))\n          {\n            colormap=(unsigned char *) RelinquishMagickMemory(colormap);\n            pixel_info=RelinquishVirtualMemory(pixel_info);\n            ThrowReaderException(CorruptImageError,\"UnableToReadImageData\");\n          }\n      }\n    /*\n      Initialize image structure.\n    */\n    if (number_planes >= 3)\n      {\n        /*\n          Convert raster image to DirectClass pixel packets.\n        */\n        p=pixels;\n        for (y=0; y < (ssize_t) image->rows; y++)\n        {\n          q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n          if (q == (Quantum *) NULL)\n            break;\n          for (x=0; x < (ssize_t) image->columns; x++)\n          {\n            SetPixelRed(image,ScaleCharToQuantum(*p++),q);\n            SetPixelGreen(image,ScaleCharToQuantum(*p++),q);\n            SetPixelBlue(image,ScaleCharToQuantum(*p++),q);\n            if (image->alpha_trait != UndefinedPixelTrait)\n              SetPixelAlpha(image,ScaleCharToQuantum(*p++),q);\n            q+=GetPixelChannels(image);\n          }\n          if (SyncAuthenticPixels(image,exception) == MagickFalse)\n            break;\n          if (image->previous == (Image *) NULL)\n            {\n              status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n                image->rows);\n              if (status == MagickFalse)\n                break;\n            }\n        }\n      }\n    else\n      {\n        /*\n          Create colormap.\n        */\n        if (number_colormaps == 0)\n          map_length=256;\n        if (AcquireImageColormap(image,map_length,exception) == MagickFalse)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        p=colormap;\n        if (number_colormaps == 1)\n          for (i=0; i < (ssize_t) image->colors; i++)\n          {\n            /*\n              Pseudocolor.\n            */\n            image->colormap[i].red=(MagickRealType)\n              ScaleCharToQuantum((unsigned char) i);\n            image->colormap[i].green=(MagickRealType)\n              ScaleCharToQuantum((unsigned char) i);\n            image->colormap[i].blue=(MagickRealType)\n              ScaleCharToQuantum((unsigned char) i);\n          }\n        else\n          if (number_colormaps > 1)\n            for (i=0; i < (ssize_t) image->colors; i++)\n            {\n              image->colormap[i].red=(MagickRealType)\n                ScaleCharToQuantum(*p);\n              image->colormap[i].green=(MagickRealType)\n                ScaleCharToQuantum(*(p+map_length));\n              image->colormap[i].blue=(MagickRealType)\n                ScaleCharToQuantum(*(p+map_length*2));\n              p++;\n            }\n        p=pixels;\n        if (image->alpha_trait == UndefinedPixelTrait)\n          {\n            /*\n              Convert raster image to PseudoClass pixel packets.\n            */\n            for (y=0; y < (ssize_t) image->rows; y++)\n            {\n              q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n              if (q == (Quantum *) NULL)\n                break;\n              for (x=0; x < (ssize_t) image->columns; x++)\n              {\n                SetPixelIndex(image,*p++,q);\n                q+=GetPixelChannels(image);\n              }\n              if (SyncAuthenticPixels(image,exception) == MagickFalse)\n                break;\n              if (image->previous == (Image *) NULL)\n                {\n                  status=SetImageProgress(image,LoadImageTag,(MagickOffsetType)\n                    y,image->rows);\n                  if (status == MagickFalse)\n                    break;\n                }\n            }\n            (void) SyncImage(image,exception);\n          }\n        else\n          {\n            /*\n              Image has a matte channel-- promote to DirectClass.\n            */\n            for (y=0; y < (ssize_t) image->rows; y++)\n            {\n              q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n              if (q == (Quantum *) NULL)\n                break;\n              for (x=0; x < (ssize_t) image->columns; x++)\n              {\n                ValidateColormapValue(image,(ssize_t) *p++,&index,exception);\n                SetPixelRed(image,ClampToQuantum(image->colormap[(ssize_t)\n                  index].red),q);\n                ValidateColormapValue(image,(ssize_t) *p++,&index,exception);\n                SetPixelGreen(image,ClampToQuantum(image->colormap[(ssize_t)\n                  index].green),q);\n                ValidateColormapValue(image,(ssize_t) *p++,&index,exception);\n                SetPixelBlue(image,ClampToQuantum(image->colormap[(ssize_t)\n                  index].blue),q);\n                SetPixelAlpha(image,ScaleCharToQuantum(*p++),q);\n                q+=GetPixelChannels(image);\n              }\n              if (x < (ssize_t) image->columns)\n                break;\n              if (SyncAuthenticPixels(image,exception) == MagickFalse)\n                break;\n              if (image->previous == (Image *) NULL)\n                {\n                  status=SetImageProgress(image,LoadImageTag,(MagickOffsetType)\n                    y,image->rows);\n                  if (status == MagickFalse)\n                    break;\n                }\n            }\n            image->colormap=(PixelInfo *) RelinquishMagickMemory(\n              image->colormap);\n            image->storage_class=DirectClass;\n            image->colors=0;\n          }\n      }\n    if (number_colormaps != 0)\n      colormap=(unsigned char *) RelinquishMagickMemory(colormap);\n    pixel_info=RelinquishVirtualMemory(pixel_info);\n    if (EOFBlob(image) != MagickFalse)\n      {\n        ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n          image->filename);\n        break;\n      }\n    /*\n      Proceed to next image.\n    */\n    if (image_info->number_scenes != 0)\n      if (image->scene >= (image_info->scene+image_info->number_scenes-1))\n        break;\n    (void) ReadBlobByte(image);\n    count=ReadBlob(image,2,(unsigned char *) magick);\n    if ((count != 0) && (memcmp(magick,\"\\122\\314\",2) == 0))\n      {\n        /*\n          Allocate next image structure.\n        */\n        AcquireNextImage(image_info,image,exception);\n        if (GetNextImageInList(image) == (Image *) NULL)\n          {\n            image=DestroyImageList(image);\n            return((Image *) NULL);\n          }\n        image=SyncNextImageInList(image);\n        status=SetImageProgress(image,LoadImagesTag,TellBlob(image),\n          GetBlobSize(image));\n        if (status == MagickFalse)\n          break;\n      }\n  } while ((count != 0) && (memcmp(magick,\"\\122\\314\",2) == 0));\n  (void) CloseBlob(image);\n  return(GetFirstImageInList(image));\n}",
        "func": "static Image *ReadRLEImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n#define SkipLinesOp  0x01\n#define SetColorOp  0x02\n#define SkipPixelsOp  0x03\n#define ByteDataOp  0x05\n#define RunDataOp  0x06\n#define EOFOp  0x07\n\n  char\n    magick[12];\n\n  Image\n    *image;\n\n  int\n    opcode,\n    operand,\n    status;\n\n  MagickStatusType\n    flags;\n\n  MagickSizeType\n    number_pixels;\n\n  MemoryInfo\n    *pixel_info;\n\n  Quantum\n    index;\n\n  register ssize_t\n    x;\n\n  register Quantum\n    *q;\n\n  register ssize_t\n    i;\n\n  register unsigned char\n    *p;\n\n  size_t\n    bits_per_pixel,\n    map_length,\n    number_colormaps,\n    number_planes,\n    number_planes_filled,\n    one,\n    pixel_info_length;\n\n  ssize_t\n    count,\n    offset,\n    y;\n\n  unsigned char\n    background_color[256],\n    *colormap,\n    pixel,\n    plane,\n    *pixels;\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  image=AcquireImage(image_info,exception);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    return(DestroyImageList(image));\n  /*\n    Determine if this a RLE file.\n  */\n  count=ReadBlob(image,2,(unsigned char *) magick);\n  if ((count != 2) || (memcmp(magick,\"\\122\\314\",2) != 0))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  do\n  {\n    /*\n      Read image header.\n    */\n    image->page.x=ReadBlobLSBShort(image);\n    image->page.y=ReadBlobLSBShort(image);\n    image->columns=ReadBlobLSBShort(image);\n    image->rows=ReadBlobLSBShort(image);\n    flags=(MagickStatusType) ReadBlobByte(image);\n    image->alpha_trait=flags & 0x04 ? BlendPixelTrait : UndefinedPixelTrait;\n    number_planes=(size_t) ReadBlobByte(image);\n    bits_per_pixel=(size_t) ReadBlobByte(image);\n    number_colormaps=(size_t) ReadBlobByte(image);\n    map_length=(unsigned char) ReadBlobByte(image);\n    if (map_length >= 22)\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    one=1;\n    map_length=one << map_length;\n    if ((number_planes == 0) || (number_planes == 2) ||\n        ((flags & 0x04) && (number_colormaps > 254)) || (bits_per_pixel != 8) ||\n        (image->columns == 0))\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    if (flags & 0x02)\n      {\n        /*\n          No background color-- initialize to black.\n        */\n        for (i=0; i < (ssize_t) number_planes; i++)\n          background_color[i]=0;\n        (void) ReadBlobByte(image);\n      }\n    else\n      {\n        /*\n          Initialize background color.\n        */\n        p=background_color;\n        for (i=0; i < (ssize_t) number_planes; i++)\n          *p++=(unsigned char) ReadBlobByte(image);\n      }\n    if ((number_planes & 0x01) == 0)\n      (void) ReadBlobByte(image);\n    if (EOFBlob(image) != MagickFalse)\n      {\n        ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n          image->filename);\n        break;\n      }\n    colormap=(unsigned char *) NULL;\n    if (number_colormaps != 0)\n      {\n        /*\n          Read image colormaps.\n        */\n        colormap=(unsigned char *) AcquireQuantumMemory(number_colormaps,\n          3*map_length*sizeof(*colormap));\n        if (colormap == (unsigned char *) NULL)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        p=colormap;\n        for (i=0; i < (ssize_t) number_colormaps; i++)\n          for (x=0; x < (ssize_t) map_length; x++)\n            *p++=(unsigned char) ScaleShortToQuantum(ReadBlobLSBShort(image));\n      }\n    if ((flags & 0x08) != 0)\n      {\n        char\n          *comment;\n\n        size_t\n          length;\n\n        /*\n          Read image comment.\n        */\n        length=ReadBlobLSBShort(image);\n        if (length != 0)\n          {\n            comment=(char *) AcquireQuantumMemory(length,sizeof(*comment));\n            if (comment == (char *) NULL)\n              ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n            count=ReadBlob(image,length-1,(unsigned char *) comment);\n            comment[length-1]='\\0';\n            (void) SetImageProperty(image,\"comment\",comment,exception);\n            comment=DestroyString(comment);\n            if ((length & 0x01) == 0)\n              (void) ReadBlobByte(image);\n          }\n      }\n    if (EOFBlob(image) != MagickFalse)\n      {\n        ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n          image->filename);\n        break;\n      }\n    if ((image_info->ping != MagickFalse) && (image_info->number_scenes != 0))\n      if (image->scene >= (image_info->scene+image_info->number_scenes-1))\n        break;\n    status=SetImageExtent(image,image->columns,image->rows,exception);\n    if (status == MagickFalse)\n      return(DestroyImageList(image));\n    /*\n      Allocate RLE pixels.\n    */\n    if (image->alpha_trait != UndefinedPixelTrait)\n      number_planes++;\n    number_pixels=(MagickSizeType) image->columns*image->rows;\n    number_planes_filled=(number_planes % 2 == 0) ? number_planes :\n      number_planes+1;\n    if ((number_pixels*number_planes_filled) != (size_t) (number_pixels*\n         number_planes_filled))\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    pixel_info=AcquireVirtualMemory(image->columns,image->rows*\n      MagickMax(number_planes_filled,4)*sizeof(*pixels));\n    if (pixel_info == (MemoryInfo *) NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    pixel_info_length=image->columns*image->rows*\n      MagickMax(number_planes_filled,4);\n    pixels=(unsigned char *) GetVirtualMemoryBlob(pixel_info);\n    (void) ResetMagickMemory(pixels,0,pixel_info_length);\n    if ((flags & 0x01) && !(flags & 0x02))\n      {\n        ssize_t\n          j;\n\n        /*\n          Set background color.\n        */\n        p=pixels;\n        for (i=0; i < (ssize_t) number_pixels; i++)\n        {\n          if (image->alpha_trait == UndefinedPixelTrait)\n            for (j=0; j < (ssize_t) number_planes; j++)\n              *p++=background_color[j];\n          else\n            {\n              for (j=0; j < (ssize_t) (number_planes-1); j++)\n                *p++=background_color[j];\n              *p++=0;  /* initialize matte channel */\n            }\n        }\n      }\n    /*\n      Read runlength-encoded image.\n    */\n    plane=0;\n    x=0;\n    y=0;\n    opcode=ReadBlobByte(image);\n    do\n    {\n      switch (opcode & 0x3f)\n      {\n        case SkipLinesOp:\n        {\n          operand=ReadBlobByte(image);\n          if (opcode & 0x40)\n            operand=ReadBlobLSBSignedShort(image);\n          x=0;\n          y+=operand;\n          break;\n        }\n        case SetColorOp:\n        {\n          operand=ReadBlobByte(image);\n          plane=(unsigned char) operand;\n          if (plane == 255)\n            plane=(unsigned char) (number_planes-1);\n          x=0;\n          break;\n        }\n        case SkipPixelsOp:\n        {\n          operand=ReadBlobByte(image);\n          if (opcode & 0x40)\n            operand=ReadBlobLSBSignedShort(image);\n          x+=operand;\n          break;\n        }\n        case ByteDataOp:\n        {\n          operand=ReadBlobByte(image);\n          if (opcode & 0x40)\n            operand=ReadBlobLSBSignedShort(image);\n          offset=((image->rows-y-1)*image->columns*number_planes)+x*\n            number_planes+plane;\n          operand++;\n          if ((offset < 0) ||\n              (offset+((size_t) operand*number_planes) > pixel_info_length))\n            {\n              if (number_colormaps != 0)\n                colormap=(unsigned char *) RelinquishMagickMemory(colormap);\n              pixel_info=RelinquishVirtualMemory(pixel_info);\n              ThrowReaderException(CorruptImageError,\"UnableToReadImageData\");\n            }\n          p=pixels+offset;\n          for (i=0; i < (ssize_t) operand; i++)\n          {\n            pixel=(unsigned char) ReadBlobByte(image);\n            if ((y < (ssize_t) image->rows) &&\n                ((x+i) < (ssize_t) image->columns))\n              *p=pixel;\n            p+=number_planes;\n          }\n          if (operand & 0x01)\n            (void) ReadBlobByte(image);\n          x+=operand;\n          break;\n        }\n        case RunDataOp:\n        {\n          operand=ReadBlobByte(image);\n          if (opcode & 0x40)\n            operand=ReadBlobLSBSignedShort(image);\n          pixel=(unsigned char) ReadBlobByte(image);\n          (void) ReadBlobByte(image);\n          offset=((image->rows-y-1)*image->columns*number_planes)+x*\n            number_planes+plane;\n          operand++;\n          if ((offset < 0) ||\n              (offset+((size_t) operand*number_planes) > pixel_info_length))\n            {\n              if (number_colormaps != 0)\n                colormap=(unsigned char *) RelinquishMagickMemory(colormap);\n              pixel_info=RelinquishVirtualMemory(pixel_info);\n              ThrowReaderException(CorruptImageError,\"UnableToReadImageData\");\n            }\n          p=pixels+offset;\n          for (i=0; i < (ssize_t) operand; i++)\n          {\n            if ((y < (ssize_t) image->rows) &&\n                ((x+i) < (ssize_t) image->columns))\n              *p=pixel;\n            p+=number_planes;\n          }\n          x+=operand;\n          break;\n        }\n        default:\n          break;\n      }\n      opcode=ReadBlobByte(image);\n    } while (((opcode & 0x3f) != EOFOp) && (opcode != EOF));\n    if (number_colormaps != 0)\n      {\n        MagickStatusType\n          mask;\n\n        /*\n          Apply colormap affineation to image.\n        */\n        mask=(MagickStatusType) (map_length-1);\n        p=pixels;\n        x=(ssize_t) number_planes;\n        if (number_colormaps == 1)\n          for (i=0; i < (ssize_t) number_pixels; i++)\n          {\n            ValidateColormapValue(image,*p & mask,&index,exception);\n            *p=colormap[(ssize_t) index];\n            p++;\n          }\n        else\n          if ((number_planes >= 3) && (number_colormaps >= 3))\n            for (i=0; i < (ssize_t) number_pixels; i++)\n              for (x=0; x < (ssize_t) number_planes; x++)\n              {\n                ValidateColormapValue(image,(size_t) (x*map_length+\n                    (*p & mask)),&index,exception);\n                *p=colormap[(ssize_t) index];\n                p++;\n              }\n        if ((i < (ssize_t) number_pixels) || (x < (ssize_t) number_planes))\n          {\n            colormap=(unsigned char *) RelinquishMagickMemory(colormap);\n            pixel_info=RelinquishVirtualMemory(pixel_info);\n            ThrowReaderException(CorruptImageError,\"UnableToReadImageData\");\n          }\n      }\n    /*\n      Initialize image structure.\n    */\n    if (number_planes >= 3)\n      {\n        /*\n          Convert raster image to DirectClass pixel packets.\n        */\n        p=pixels;\n        for (y=0; y < (ssize_t) image->rows; y++)\n        {\n          q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n          if (q == (Quantum *) NULL)\n            break;\n          for (x=0; x < (ssize_t) image->columns; x++)\n          {\n            SetPixelRed(image,ScaleCharToQuantum(*p++),q);\n            SetPixelGreen(image,ScaleCharToQuantum(*p++),q);\n            SetPixelBlue(image,ScaleCharToQuantum(*p++),q);\n            if (image->alpha_trait != UndefinedPixelTrait)\n              SetPixelAlpha(image,ScaleCharToQuantum(*p++),q);\n            q+=GetPixelChannels(image);\n          }\n          if (SyncAuthenticPixels(image,exception) == MagickFalse)\n            break;\n          if (image->previous == (Image *) NULL)\n            {\n              status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n                image->rows);\n              if (status == MagickFalse)\n                break;\n            }\n        }\n      }\n    else\n      {\n        /*\n          Create colormap.\n        */\n        if (number_colormaps == 0)\n          map_length=256;\n        if (AcquireImageColormap(image,map_length,exception) == MagickFalse)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        p=colormap;\n        if (number_colormaps == 1)\n          for (i=0; i < (ssize_t) image->colors; i++)\n          {\n            /*\n              Pseudocolor.\n            */\n            image->colormap[i].red=(MagickRealType)\n              ScaleCharToQuantum((unsigned char) i);\n            image->colormap[i].green=(MagickRealType)\n              ScaleCharToQuantum((unsigned char) i);\n            image->colormap[i].blue=(MagickRealType)\n              ScaleCharToQuantum((unsigned char) i);\n          }\n        else\n          if (number_colormaps > 1)\n            for (i=0; i < (ssize_t) image->colors; i++)\n            {\n              image->colormap[i].red=(MagickRealType)\n                ScaleCharToQuantum(*p);\n              image->colormap[i].green=(MagickRealType)\n                ScaleCharToQuantum(*(p+map_length));\n              image->colormap[i].blue=(MagickRealType)\n                ScaleCharToQuantum(*(p+map_length*2));\n              p++;\n            }\n        p=pixels;\n        if (image->alpha_trait == UndefinedPixelTrait)\n          {\n            /*\n              Convert raster image to PseudoClass pixel packets.\n            */\n            for (y=0; y < (ssize_t) image->rows; y++)\n            {\n              q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n              if (q == (Quantum *) NULL)\n                break;\n              for (x=0; x < (ssize_t) image->columns; x++)\n              {\n                SetPixelIndex(image,*p++,q);\n                q+=GetPixelChannels(image);\n              }\n              if (SyncAuthenticPixels(image,exception) == MagickFalse)\n                break;\n              if (image->previous == (Image *) NULL)\n                {\n                  status=SetImageProgress(image,LoadImageTag,(MagickOffsetType)\n                    y,image->rows);\n                  if (status == MagickFalse)\n                    break;\n                }\n            }\n            (void) SyncImage(image,exception);\n          }\n        else\n          {\n            /*\n              Image has a matte channel-- promote to DirectClass.\n            */\n            for (y=0; y < (ssize_t) image->rows; y++)\n            {\n              q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n              if (q == (Quantum *) NULL)\n                break;\n              for (x=0; x < (ssize_t) image->columns; x++)\n              {\n                ValidateColormapValue(image,(ssize_t) *p++,&index,exception);\n                SetPixelRed(image,ClampToQuantum(image->colormap[(ssize_t)\n                  index].red),q);\n                ValidateColormapValue(image,(ssize_t) *p++,&index,exception);\n                SetPixelGreen(image,ClampToQuantum(image->colormap[(ssize_t)\n                  index].green),q);\n                ValidateColormapValue(image,(ssize_t) *p++,&index,exception);\n                SetPixelBlue(image,ClampToQuantum(image->colormap[(ssize_t)\n                  index].blue),q);\n                SetPixelAlpha(image,ScaleCharToQuantum(*p++),q);\n                q+=GetPixelChannels(image);\n              }\n              if (x < (ssize_t) image->columns)\n                break;\n              if (SyncAuthenticPixels(image,exception) == MagickFalse)\n                break;\n              if (image->previous == (Image *) NULL)\n                {\n                  status=SetImageProgress(image,LoadImageTag,(MagickOffsetType)\n                    y,image->rows);\n                  if (status == MagickFalse)\n                    break;\n                }\n            }\n            image->colormap=(PixelInfo *) RelinquishMagickMemory(\n              image->colormap);\n            image->storage_class=DirectClass;\n            image->colors=0;\n          }\n      }\n    if (number_colormaps != 0)\n      colormap=(unsigned char *) RelinquishMagickMemory(colormap);\n    pixel_info=RelinquishVirtualMemory(pixel_info);\n    if (EOFBlob(image) != MagickFalse)\n      {\n        ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n          image->filename);\n        break;\n      }\n    /*\n      Proceed to next image.\n    */\n    if (image_info->number_scenes != 0)\n      if (image->scene >= (image_info->scene+image_info->number_scenes-1))\n        break;\n    (void) ReadBlobByte(image);\n    count=ReadBlob(image,2,(unsigned char *) magick);\n    if ((count != 0) && (memcmp(magick,\"\\122\\314\",2) == 0))\n      {\n        /*\n          Allocate next image structure.\n        */\n        AcquireNextImage(image_info,image,exception);\n        if (GetNextImageInList(image) == (Image *) NULL)\n          {\n            image=DestroyImageList(image);\n            return((Image *) NULL);\n          }\n        image=SyncNextImageInList(image);\n        status=SetImageProgress(image,LoadImagesTag,TellBlob(image),\n          GetBlobSize(image));\n        if (status == MagickFalse)\n          break;\n      }\n  } while ((count != 0) && (memcmp(magick,\"\\122\\314\",2) == 0));\n  (void) CloseBlob(image);\n  return(GetFirstImageInList(image));\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -202,6 +202,7 @@\n     pixel_info_length=image->columns*image->rows*\n       MagickMax(number_planes_filled,4);\n     pixels=(unsigned char *) GetVirtualMemoryBlob(pixel_info);\n+    (void) ResetMagickMemory(pixels,0,pixel_info_length);\n     if ((flags & 0x01) && !(flags & 0x02))\n       {\n         ssize_t",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    (void) ResetMagickMemory(pixels,0,pixel_info_length);"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-7042",
        "func_name": "adrienverge/openfortivpn/ssl_verify_cert",
        "description": "An issue was discovered in openfortivpn 1.11.0 when used with OpenSSL 1.0.2 or later. tunnel.c mishandles certificate validation because the hostname check operates on uninitialized memory. The outcome is that a valid certificate is never accepted (only a malformed certificate may be accepted).",
        "git_url": "https://github.com/adrienverge/openfortivpn/commit/9eee997d599a89492281fc7ffdd79d88cd61afc3",
        "commit_title": "supply proper input buffer to X509_check_host",
        "commit_text": " CVE-2020-7042 use of uninitialized memory in X509_check_host is fixed with this commit  the uninitialized buffer common_name was passed as argument to X509_check_host which prevented proper host name validation when openssl >= 1.0.2 was in use. This came in with #282 which went into openfortivpn 1.7.1. Unfortunately, this problem has stayed unnoticed because the return value was not properly checked either (which is a separate issue, with CVE-2020-7041, and which has been fixed by the previous commit)",
        "func_before": "static int ssl_verify_cert(struct tunnel *tunnel)\n{\n\tint ret = -1;\n\tint cert_valid = 0;\n\tunsigned char digest[SHA256LEN];\n\tunsigned int len;\n\tstruct x509_digest *elem;\n\tchar digest_str[SHA256STRLEN], *subject, *issuer;\n\tchar *line;\n\tint i;\n\tX509_NAME *subj;\n\tchar common_name[FIELD_SIZE + 1];\n\n\tSSL_set_verify(tunnel->ssl_handle, SSL_VERIFY_PEER, NULL);\n\n\tX509 *cert = SSL_get_peer_certificate(tunnel->ssl_handle);\n\tif (cert == NULL) {\n\t\tlog_error(\"Unable to get gateway certificate.\\n\");\n\t\treturn 1;\n\t}\n\n\tsubj = X509_get_subject_name(cert);\n\n#ifdef HAVE_X509_CHECK_HOST\n\t// Use OpenSSL native host validation if v >= 1.0.2.\n\t// correctly check return value of X509_check_host\n\tif (X509_check_host(cert, common_name, FIELD_SIZE, 0, NULL) == 1)\n\t\tcert_valid = 1;\n#else\n\t// Use explicit Common Name check if native validation not available.\n\t// Note: this will ignore Subject Alternative Name fields.\n\tif (subj\n\t    && X509_NAME_get_text_by_NID(subj, NID_commonName, common_name,\n\t                                 FIELD_SIZE) > 0\n\t    && strncasecmp(common_name, tunnel->config->gateway_host,\n\t                   FIELD_SIZE) == 0)\n\t\tcert_valid = 1;\n#endif\n\n\t// Try to validate certificate using local PKI\n\tif (cert_valid\n\t    && SSL_get_verify_result(tunnel->ssl_handle) == X509_V_OK) {\n\t\tlog_debug(\"Gateway certificate validation succeeded.\\n\");\n\t\tret = 0;\n\t\tgoto free_cert;\n\t}\n\tlog_debug(\"Gateway certificate validation failed.\\n\");\n\n\t// If validation failed, check if cert is in the white list\n\tif (X509_digest(cert, EVP_sha256(), digest, &len) <= 0\n\t    || len != SHA256LEN) {\n\t\tlog_error(\"Could not compute certificate sha256 digest.\\n\");\n\t\tgoto free_cert;\n\t}\n\t// Encode digest in base16\n\tfor (i = 0; i < SHA256LEN; i++)\n\t\tsprintf(&digest_str[2 * i], \"%02x\", digest[i]);\n\tdigest_str[SHA256STRLEN - 1] = '\\0';\n\t// Is it in whitelist?\n\tfor (elem = tunnel->config->cert_whitelist; elem != NULL;\n\t     elem = elem->next)\n\t\tif (memcmp(digest_str, elem->data, SHA256STRLEN - 1) == 0)\n\t\t\tbreak;\n\tif (elem != NULL) { // break before end of loop\n\t\tlog_debug(\"Gateway certificate digest found in white list.\\n\");\n\t\tret = 0;\n\t\tgoto free_cert;\n\t}\n\n\tsubject = X509_NAME_oneline(subj, NULL, 0);\n\tissuer = X509_NAME_oneline(X509_get_issuer_name(cert), NULL, 0);\n\n\tlog_error(\"Gateway certificate validation failed, and the certificate digest in not in the local whitelist. If you trust it, rerun with:\\n\");\n\tlog_error(\"    --trusted-cert %s\\n\", digest_str);\n\tlog_error(\"or add this line to your config file:\\n\");\n\tlog_error(\"    trusted-cert = %s\\n\", digest_str);\n\tlog_error(\"Gateway certificate:\\n\");\n\tlog_error(\"    subject:\\n\");\n\tfor (line = strtok(subject, \"/\"); line != NULL;\n\t     line = strtok(NULL, \"/\"))\n\t\tlog_error(\"        %s\\n\", line);\n\tlog_error(\"    issuer:\\n\");\n\tfor (line = strtok(issuer, \"/\"); line != NULL;\n\t     line = strtok(NULL, \"/\"))\n\t\tlog_error(\"        %s\\n\", line);\n\tlog_error(\"    sha256 digest:\\n\");\n\tlog_error(\"        %s\\n\", digest_str);\n\nfree_cert:\n\tX509_free(cert);\n\treturn ret;\n}",
        "func": "static int ssl_verify_cert(struct tunnel *tunnel)\n{\n\tint ret = -1;\n\tint cert_valid = 0;\n\tunsigned char digest[SHA256LEN];\n\tunsigned int len;\n\tstruct x509_digest *elem;\n\tchar digest_str[SHA256STRLEN], *subject, *issuer;\n\tchar *line;\n\tint i;\n\tX509_NAME *subj;\n\n\tSSL_set_verify(tunnel->ssl_handle, SSL_VERIFY_PEER, NULL);\n\n\tX509 *cert = SSL_get_peer_certificate(tunnel->ssl_handle);\n\tif (cert == NULL) {\n\t\tlog_error(\"Unable to get gateway certificate.\\n\");\n\t\treturn 1;\n\t}\n\n\tsubj = X509_get_subject_name(cert);\n\n#ifdef HAVE_X509_CHECK_HOST\n\t// Use OpenSSL native host validation if v >= 1.0.2.\n\t// compare against gateway_host and correctly check return value\n\t// to fix piror Incorrect use of X509_check_host\n\tif (X509_check_host(cert, tunnel->config->gateway_host,\n\t                    0, 0, NULL) == 1)\n\t\tcert_valid = 1;\n#else\n\tchar common_name[FIELD_SIZE + 1];\n\t// Use explicit Common Name check if native validation not available.\n\t// Note: this will ignore Subject Alternative Name fields.\n\tif (subj\n\t    && X509_NAME_get_text_by_NID(subj, NID_commonName, common_name,\n\t                                 FIELD_SIZE) > 0\n\t    && strncasecmp(common_name, tunnel->config->gateway_host,\n\t                   FIELD_SIZE) == 0)\n\t\tcert_valid = 1;\n#endif\n\n\t// Try to validate certificate using local PKI\n\tif (cert_valid\n\t    && SSL_get_verify_result(tunnel->ssl_handle) == X509_V_OK) {\n\t\tlog_debug(\"Gateway certificate validation succeeded.\\n\");\n\t\tret = 0;\n\t\tgoto free_cert;\n\t}\n\tlog_debug(\"Gateway certificate validation failed.\\n\");\n\n\t// If validation failed, check if cert is in the white list\n\tif (X509_digest(cert, EVP_sha256(), digest, &len) <= 0\n\t    || len != SHA256LEN) {\n\t\tlog_error(\"Could not compute certificate sha256 digest.\\n\");\n\t\tgoto free_cert;\n\t}\n\t// Encode digest in base16\n\tfor (i = 0; i < SHA256LEN; i++)\n\t\tsprintf(&digest_str[2 * i], \"%02x\", digest[i]);\n\tdigest_str[SHA256STRLEN - 1] = '\\0';\n\t// Is it in whitelist?\n\tfor (elem = tunnel->config->cert_whitelist; elem != NULL;\n\t     elem = elem->next)\n\t\tif (memcmp(digest_str, elem->data, SHA256STRLEN - 1) == 0)\n\t\t\tbreak;\n\tif (elem != NULL) { // break before end of loop\n\t\tlog_debug(\"Gateway certificate digest found in white list.\\n\");\n\t\tret = 0;\n\t\tgoto free_cert;\n\t}\n\n\tsubject = X509_NAME_oneline(subj, NULL, 0);\n\tissuer = X509_NAME_oneline(X509_get_issuer_name(cert), NULL, 0);\n\n\tlog_error(\"Gateway certificate validation failed, and the certificate digest in not in the local whitelist. If you trust it, rerun with:\\n\");\n\tlog_error(\"    --trusted-cert %s\\n\", digest_str);\n\tlog_error(\"or add this line to your config file:\\n\");\n\tlog_error(\"    trusted-cert = %s\\n\", digest_str);\n\tlog_error(\"Gateway certificate:\\n\");\n\tlog_error(\"    subject:\\n\");\n\tfor (line = strtok(subject, \"/\"); line != NULL;\n\t     line = strtok(NULL, \"/\"))\n\t\tlog_error(\"        %s\\n\", line);\n\tlog_error(\"    issuer:\\n\");\n\tfor (line = strtok(issuer, \"/\"); line != NULL;\n\t     line = strtok(NULL, \"/\"))\n\t\tlog_error(\"        %s\\n\", line);\n\tlog_error(\"    sha256 digest:\\n\");\n\tlog_error(\"        %s\\n\", digest_str);\n\nfree_cert:\n\tX509_free(cert);\n\treturn ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -9,7 +9,6 @@\n \tchar *line;\n \tint i;\n \tX509_NAME *subj;\n-\tchar common_name[FIELD_SIZE + 1];\n \n \tSSL_set_verify(tunnel->ssl_handle, SSL_VERIFY_PEER, NULL);\n \n@@ -23,10 +22,13 @@\n \n #ifdef HAVE_X509_CHECK_HOST\n \t// Use OpenSSL native host validation if v >= 1.0.2.\n-\t// correctly check return value of X509_check_host\n-\tif (X509_check_host(cert, common_name, FIELD_SIZE, 0, NULL) == 1)\n+\t// compare against gateway_host and correctly check return value\n+\t// to fix piror Incorrect use of X509_check_host\n+\tif (X509_check_host(cert, tunnel->config->gateway_host,\n+\t                    0, 0, NULL) == 1)\n \t\tcert_valid = 1;\n #else\n+\tchar common_name[FIELD_SIZE + 1];\n \t// Use explicit Common Name check if native validation not available.\n \t// Note: this will ignore Subject Alternative Name fields.\n \tif (subj",
        "diff_line_info": {
            "deleted_lines": [
                "\tchar common_name[FIELD_SIZE + 1];",
                "\t// correctly check return value of X509_check_host",
                "\tif (X509_check_host(cert, common_name, FIELD_SIZE, 0, NULL) == 1)"
            ],
            "added_lines": [
                "\t// compare against gateway_host and correctly check return value",
                "\t// to fix piror Incorrect use of X509_check_host",
                "\tif (X509_check_host(cert, tunnel->config->gateway_host,",
                "\t                    0, 0, NULL) == 1)",
                "\tchar common_name[FIELD_SIZE + 1];"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-19947",
        "func_name": "torvalds/linux/kvaser_usb_leaf_simple_cmd_async",
        "description": "In the Linux kernel through 5.4.6, there are information leaks of uninitialized memory to a USB device in the drivers/net/can/usb/kvaser_usb/kvaser_usb_leaf.c driver, aka CID-da2311a6385c.",
        "git_url": "https://github.com/torvalds/linux/commit/da2311a6385c3b499da2ed5d9be59ce331fa93e9",
        "commit_title": "can: kvaser_usb: kvaser_usb_leaf: Fix some info-leaks to USB devices",
        "commit_text": " Uninitialized Kernel memory can leak to USB devices.  Fix this by using kzalloc() instead of kmalloc().  Cc: linux-stable <stable@vger.kernel.org> # >= v4.19",
        "func_before": "static int kvaser_usb_leaf_simple_cmd_async(struct kvaser_usb_net_priv *priv,\n\t\t\t\t\t    u8 cmd_id)\n{\n\tstruct kvaser_cmd *cmd;\n\tint err;\n\n\tcmd = kmalloc(sizeof(*cmd), GFP_ATOMIC);\n\tif (!cmd)\n\t\treturn -ENOMEM;\n\n\tcmd->len = CMD_HEADER_LEN + sizeof(struct kvaser_cmd_simple);\n\tcmd->id = cmd_id;\n\tcmd->u.simple.channel = priv->channel;\n\n\terr = kvaser_usb_send_cmd_async(priv, cmd, cmd->len);\n\tif (err)\n\t\tkfree(cmd);\n\n\treturn err;\n}",
        "func": "static int kvaser_usb_leaf_simple_cmd_async(struct kvaser_usb_net_priv *priv,\n\t\t\t\t\t    u8 cmd_id)\n{\n\tstruct kvaser_cmd *cmd;\n\tint err;\n\n\tcmd = kzalloc(sizeof(*cmd), GFP_ATOMIC);\n\tif (!cmd)\n\t\treturn -ENOMEM;\n\n\tcmd->len = CMD_HEADER_LEN + sizeof(struct kvaser_cmd_simple);\n\tcmd->id = cmd_id;\n\tcmd->u.simple.channel = priv->channel;\n\n\terr = kvaser_usb_send_cmd_async(priv, cmd, cmd->len);\n\tif (err)\n\t\tkfree(cmd);\n\n\treturn err;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,7 +4,7 @@\n \tstruct kvaser_cmd *cmd;\n \tint err;\n \n-\tcmd = kmalloc(sizeof(*cmd), GFP_ATOMIC);\n+\tcmd = kzalloc(sizeof(*cmd), GFP_ATOMIC);\n \tif (!cmd)\n \t\treturn -ENOMEM;\n ",
        "diff_line_info": {
            "deleted_lines": [
                "\tcmd = kmalloc(sizeof(*cmd), GFP_ATOMIC);"
            ],
            "added_lines": [
                "\tcmd = kzalloc(sizeof(*cmd), GFP_ATOMIC);"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-19947",
        "func_name": "torvalds/linux/kvaser_usb_leaf_set_opt_mode",
        "description": "In the Linux kernel through 5.4.6, there are information leaks of uninitialized memory to a USB device in the drivers/net/can/usb/kvaser_usb/kvaser_usb_leaf.c driver, aka CID-da2311a6385c.",
        "git_url": "https://github.com/torvalds/linux/commit/da2311a6385c3b499da2ed5d9be59ce331fa93e9",
        "commit_title": "can: kvaser_usb: kvaser_usb_leaf: Fix some info-leaks to USB devices",
        "commit_text": " Uninitialized Kernel memory can leak to USB devices.  Fix this by using kzalloc() instead of kmalloc().  Cc: linux-stable <stable@vger.kernel.org> # >= v4.19",
        "func_before": "static int kvaser_usb_leaf_set_opt_mode(const struct kvaser_usb_net_priv *priv)\n{\n\tstruct kvaser_cmd *cmd;\n\tint rc;\n\n\tcmd = kmalloc(sizeof(*cmd), GFP_KERNEL);\n\tif (!cmd)\n\t\treturn -ENOMEM;\n\n\tcmd->id = CMD_SET_CTRL_MODE;\n\tcmd->len = CMD_HEADER_LEN + sizeof(struct kvaser_cmd_ctrl_mode);\n\tcmd->u.ctrl_mode.tid = 0xff;\n\tcmd->u.ctrl_mode.channel = priv->channel;\n\n\tif (priv->can.ctrlmode & CAN_CTRLMODE_LISTENONLY)\n\t\tcmd->u.ctrl_mode.ctrl_mode = KVASER_CTRL_MODE_SILENT;\n\telse\n\t\tcmd->u.ctrl_mode.ctrl_mode = KVASER_CTRL_MODE_NORMAL;\n\n\trc = kvaser_usb_send_cmd(priv->dev, cmd, cmd->len);\n\n\tkfree(cmd);\n\treturn rc;\n}",
        "func": "static int kvaser_usb_leaf_set_opt_mode(const struct kvaser_usb_net_priv *priv)\n{\n\tstruct kvaser_cmd *cmd;\n\tint rc;\n\n\tcmd = kzalloc(sizeof(*cmd), GFP_KERNEL);\n\tif (!cmd)\n\t\treturn -ENOMEM;\n\n\tcmd->id = CMD_SET_CTRL_MODE;\n\tcmd->len = CMD_HEADER_LEN + sizeof(struct kvaser_cmd_ctrl_mode);\n\tcmd->u.ctrl_mode.tid = 0xff;\n\tcmd->u.ctrl_mode.channel = priv->channel;\n\n\tif (priv->can.ctrlmode & CAN_CTRLMODE_LISTENONLY)\n\t\tcmd->u.ctrl_mode.ctrl_mode = KVASER_CTRL_MODE_SILENT;\n\telse\n\t\tcmd->u.ctrl_mode.ctrl_mode = KVASER_CTRL_MODE_NORMAL;\n\n\trc = kvaser_usb_send_cmd(priv->dev, cmd, cmd->len);\n\n\tkfree(cmd);\n\treturn rc;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,7 +3,7 @@\n \tstruct kvaser_cmd *cmd;\n \tint rc;\n \n-\tcmd = kmalloc(sizeof(*cmd), GFP_KERNEL);\n+\tcmd = kzalloc(sizeof(*cmd), GFP_KERNEL);\n \tif (!cmd)\n \t\treturn -ENOMEM;\n ",
        "diff_line_info": {
            "deleted_lines": [
                "\tcmd = kmalloc(sizeof(*cmd), GFP_KERNEL);"
            ],
            "added_lines": [
                "\tcmd = kzalloc(sizeof(*cmd), GFP_KERNEL);"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-19947",
        "func_name": "torvalds/linux/kvaser_usb_leaf_flush_queue",
        "description": "In the Linux kernel through 5.4.6, there are information leaks of uninitialized memory to a USB device in the drivers/net/can/usb/kvaser_usb/kvaser_usb_leaf.c driver, aka CID-da2311a6385c.",
        "git_url": "https://github.com/torvalds/linux/commit/da2311a6385c3b499da2ed5d9be59ce331fa93e9",
        "commit_title": "can: kvaser_usb: kvaser_usb_leaf: Fix some info-leaks to USB devices",
        "commit_text": " Uninitialized Kernel memory can leak to USB devices.  Fix this by using kzalloc() instead of kmalloc().  Cc: linux-stable <stable@vger.kernel.org> # >= v4.19",
        "func_before": "static int kvaser_usb_leaf_flush_queue(struct kvaser_usb_net_priv *priv)\n{\n\tstruct kvaser_cmd *cmd;\n\tint rc;\n\n\tcmd = kmalloc(sizeof(*cmd), GFP_KERNEL);\n\tif (!cmd)\n\t\treturn -ENOMEM;\n\n\tcmd->id = CMD_FLUSH_QUEUE;\n\tcmd->len = CMD_HEADER_LEN + sizeof(struct kvaser_cmd_flush_queue);\n\tcmd->u.flush_queue.channel = priv->channel;\n\tcmd->u.flush_queue.flags = 0x00;\n\n\trc = kvaser_usb_send_cmd(priv->dev, cmd, cmd->len);\n\n\tkfree(cmd);\n\treturn rc;\n}",
        "func": "static int kvaser_usb_leaf_flush_queue(struct kvaser_usb_net_priv *priv)\n{\n\tstruct kvaser_cmd *cmd;\n\tint rc;\n\n\tcmd = kzalloc(sizeof(*cmd), GFP_KERNEL);\n\tif (!cmd)\n\t\treturn -ENOMEM;\n\n\tcmd->id = CMD_FLUSH_QUEUE;\n\tcmd->len = CMD_HEADER_LEN + sizeof(struct kvaser_cmd_flush_queue);\n\tcmd->u.flush_queue.channel = priv->channel;\n\tcmd->u.flush_queue.flags = 0x00;\n\n\trc = kvaser_usb_send_cmd(priv->dev, cmd, cmd->len);\n\n\tkfree(cmd);\n\treturn rc;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,7 +3,7 @@\n \tstruct kvaser_cmd *cmd;\n \tint rc;\n \n-\tcmd = kmalloc(sizeof(*cmd), GFP_KERNEL);\n+\tcmd = kzalloc(sizeof(*cmd), GFP_KERNEL);\n \tif (!cmd)\n \t\treturn -ENOMEM;\n ",
        "diff_line_info": {
            "deleted_lines": [
                "\tcmd = kmalloc(sizeof(*cmd), GFP_KERNEL);"
            ],
            "added_lines": [
                "\tcmd = kzalloc(sizeof(*cmd), GFP_KERNEL);"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-14551",
        "func_name": "ImageMagick/ReadMATImageV4",
        "description": "The ReadMATImageV4 function in coders/mat.c in ImageMagick 7.0.8-7 uses an uninitialized variable, leading to memory corruption.",
        "git_url": "https://github.com/ImageMagick/ImageMagick/commit/389ecc365a7c61404ba078a72c3fa5a3cf1b4101",
        "commit_title": "https://github.com/ImageMagick/ImageMagick/issues/1221",
        "commit_text": "",
        "func_before": "static Image *ReadMATImageV4(const ImageInfo *image_info,Image *image,\n  ExceptionInfo *exception)\n{\n  typedef struct {\n    unsigned char Type[4];\n    unsigned int nRows;\n    unsigned int nCols;\n    unsigned int imagf;\n    unsigned int nameLen;\n  } MAT4_HDR;\n\n  long\n    ldblk;\n\n  EndianType\n    endian;\n\n  Image\n    *rotated_image;\n\n  MagickBooleanType\n    status;\n\n  MAT4_HDR\n    HDR;\n\n  QuantumInfo\n    *quantum_info;\n\n  QuantumFormatType\n    format_type;\n\n  register ssize_t\n    i;\n\n  ssize_t\n    count,\n    y;\n\n  unsigned char\n    *pixels;\n\n  unsigned int\n    depth;\n\n\n  quantum_info=(QuantumInfo *) NULL;\n  (void) SeekBlob(image,0,SEEK_SET);\n  while (EOFBlob(image) == MagickFalse)\n  {\n    /*\n     Object parser loop.\n    */\n    ldblk=ReadBlobLSBLong(image);\n    if ((ldblk > 9999) || (ldblk < 0))\n      break;\n    HDR.Type[3]=ldblk % 10; ldblk /= 10;  /* T digit */\n    HDR.Type[2]=ldblk % 10; ldblk /= 10;  /* P digit */\n    HDR.Type[1]=ldblk % 10; ldblk /= 10;  /* O digit */\n    HDR.Type[0]=ldblk;        /* M digit */\n    if (HDR.Type[3] != 0)\n      break;  /* Data format */\n    if (HDR.Type[2] != 0)\n      break;  /* Always 0 */\n    if (HDR.Type[0] == 0)\n      {\n        HDR.nRows=ReadBlobLSBLong(image);\n        HDR.nCols=ReadBlobLSBLong(image);\n        HDR.imagf=ReadBlobLSBLong(image);\n        HDR.nameLen=ReadBlobLSBLong(image);\n        endian=LSBEndian;\n      }\n    else\n      {\n        HDR.nRows=ReadBlobMSBLong(image);\n        HDR.nCols=ReadBlobMSBLong(image);\n        HDR.imagf=ReadBlobMSBLong(image);\n        HDR.nameLen=ReadBlobMSBLong(image);\n        endian=MSBEndian;\n      }\n    if ((HDR.imagf != 0) && (HDR.imagf != 1))\n      break;\n    if (HDR.nameLen > 0xFFFF)\n      return(DestroyImageList(image));\n    for (i=0; i < (ssize_t) HDR.nameLen; i++)\n    {\n      int\n        byte;\n\n      /*\n        Skip matrix name.\n      */\n      byte=ReadBlobByte(image);\n      if (byte == EOF)\n        {\n          ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n            image->filename);\n          break;\n        }\n    }\n    image->columns=(size_t) HDR.nRows;\n    image->rows=(size_t) HDR.nCols;\n    if ((image->columns == 0) || (image->rows == 0))\n      return(DestroyImageList(image));\n    if (image_info->ping != MagickFalse)\n      {\n        Swap(image->columns,image->rows);\n        if(HDR.imagf==1) ldblk *= 2;\n        SeekBlob(image, HDR.nCols*ldblk, SEEK_CUR);\n        if ((image->columns == 0) || (image->rows == 0))\n          return(image->previous == (Image *) NULL ? DestroyImageList(image)\n            : image);\n        goto skip_reading_current;\n      }\n    status=SetImageExtent(image,image->columns,image->rows,exception);\n    if (status == MagickFalse)\n      return(DestroyImageList(image));\n    (void) SetImageBackgroundColor(image,exception);\n    (void) SetImageColorspace(image,GRAYColorspace,exception);\n    quantum_info=AcquireQuantumInfo(image_info,image);\n    if (quantum_info == (QuantumInfo *) NULL)\n      return(DestroyImageList(image));\n    switch(HDR.Type[1])\n    {\n      case 0:\n        format_type=FloatingPointQuantumFormat;\n        depth=64;\n        break;\n      case 1:\n        format_type=FloatingPointQuantumFormat;\n        depth=32;\n        break;\n      case 2:\n        format_type=UnsignedQuantumFormat;\n        depth=16;\n        break;\n      case 3:\n        format_type=SignedQuantumFormat;\n        depth=16;\n        break;\n      case 4:\n        format_type=UnsignedQuantumFormat;\n        depth=8;\n        break;\n      default:\n        format_type=UnsignedQuantumFormat;\n        depth=8;\n        break;\n    }\n    image->depth=depth;\n    if (HDR.Type[0] != 0)\n      SetQuantumEndian(image,quantum_info,MSBEndian);\n    status=SetQuantumFormat(image,quantum_info,format_type);\n    status=SetQuantumDepth(image,quantum_info,depth);\n    status=SetQuantumEndian(image,quantum_info,endian);\n    SetQuantumScale(quantum_info,1.0);\n    pixels=(unsigned char *) GetQuantumPixels(quantum_info);\n    for (y=0; y < (ssize_t) image->rows; y++)\n    {\n      register Quantum\n        *magick_restrict q;\n\n      count=ReadBlob(image,depth/8*image->columns,(char *) pixels);\n      if (count == -1)\n        break;\n      q=QueueAuthenticPixels(image,0,image->rows-y-1,image->columns,1,\n        exception);\n      if (q == (Quantum *) NULL)\n        break;\n      (void) ImportQuantumPixels(image,(CacheView *) NULL,quantum_info,\n        GrayQuantum,pixels,exception);\n      if ((HDR.Type[1] == 2) || (HDR.Type[1] == 3))\n        FixSignedValues(image,q,(int) image->columns);\n      if (SyncAuthenticPixels(image,exception) == MagickFalse)\n        break;\n      if (image->previous == (Image *) NULL)\n        {\n          status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n            image->rows);\n          if (status == MagickFalse)\n            break;\n        }\n    }\n    if (HDR.imagf == 1)\n      for (y=0; y < (ssize_t) image->rows; y++)\n      {\n        /*\n          Read complex pixels.\n        */\n        count=ReadBlob(image,depth/8*image->columns,(char *) pixels);\n        if (count == -1)\n          break;\n        if (HDR.Type[1] == 0)\n          InsertComplexDoubleRow(image,(double *) pixels,y,0,0,exception);\n        else\n          InsertComplexFloatRow(image,(float *) pixels,y,0,0,exception);\n      }\n    if (quantum_info != (QuantumInfo *) NULL)\n      quantum_info=DestroyQuantumInfo(quantum_info);\n    if (EOFBlob(image) != MagickFalse)\n      {\n        ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n          image->filename);\n        break;\n      }\n    rotated_image=RotateImage(image,90.0,exception);\n    if (rotated_image != (Image *) NULL)\n      {\n        rotated_image->page.x=0;\n        rotated_image->page.y=0;\n        rotated_image->colors = image->colors;\n        DestroyBlob(rotated_image);\n        rotated_image->blob=ReferenceBlob(image->blob);\n        AppendImageToList(&image,rotated_image);\n        DeleteImageFromList(&image);\n      }\n    /*\n      Proceed to next image.\n    */\n    if (image_info->number_scenes != 0)\n      if (image->scene >= (image_info->scene+image_info->number_scenes-1))\n        break;\n    /*\n      Allocate next image structure.\n    */\nskip_reading_current:\n    AcquireNextImage(image_info,image,exception);\n    if (GetNextImageInList(image) == (Image *) NULL)\n      {\n        status=MagickFalse;\n        break;\n      }\n    image=SyncNextImageInList(image);\n    status=SetImageProgress(image,LoadImagesTag,TellBlob(image),\n      GetBlobSize(image));\n    if (status == MagickFalse)\n      break;\n  }\n  (void) CloseBlob(image);\n  if (status == MagickFalse)\n    return(DestroyImageList(image));\n  return(GetFirstImageInList(image));\n}",
        "func": "static Image *ReadMATImageV4(const ImageInfo *image_info,Image *image,\n  ExceptionInfo *exception)\n{\n  typedef struct {\n    unsigned char Type[4];\n    unsigned int nRows;\n    unsigned int nCols;\n    unsigned int imagf;\n    unsigned int nameLen;\n  } MAT4_HDR;\n\n  long\n    ldblk;\n\n  EndianType\n    endian;\n\n  Image\n    *rotated_image;\n\n  MagickBooleanType\n    status;\n\n  MAT4_HDR\n    HDR;\n\n  QuantumInfo\n    *quantum_info;\n\n  QuantumFormatType\n    format_type;\n\n  register ssize_t\n    i;\n\n  ssize_t\n    count,\n    y;\n\n  unsigned char\n    *pixels;\n\n  unsigned int\n    depth;\n\n  quantum_info=(QuantumInfo *) NULL;\n  (void) SeekBlob(image,0,SEEK_SET);\n  status=MagickTrue;\n  while (EOFBlob(image) == MagickFalse)\n  {\n    /*\n     Object parser loop.\n    */\n    ldblk=ReadBlobLSBLong(image);\n    if ((ldblk > 9999) || (ldblk < 0))\n      break;\n    HDR.Type[3]=ldblk % 10; ldblk /= 10;  /* T digit */\n    HDR.Type[2]=ldblk % 10; ldblk /= 10;  /* P digit */\n    HDR.Type[1]=ldblk % 10; ldblk /= 10;  /* O digit */\n    HDR.Type[0]=ldblk;        /* M digit */\n    if (HDR.Type[3] != 0)\n      break;  /* Data format */\n    if (HDR.Type[2] != 0)\n      break;  /* Always 0 */\n    if (HDR.Type[0] == 0)\n      {\n        HDR.nRows=ReadBlobLSBLong(image);\n        HDR.nCols=ReadBlobLSBLong(image);\n        HDR.imagf=ReadBlobLSBLong(image);\n        HDR.nameLen=ReadBlobLSBLong(image);\n        endian=LSBEndian;\n      }\n    else\n      {\n        HDR.nRows=ReadBlobMSBLong(image);\n        HDR.nCols=ReadBlobMSBLong(image);\n        HDR.imagf=ReadBlobMSBLong(image);\n        HDR.nameLen=ReadBlobMSBLong(image);\n        endian=MSBEndian;\n      }\n    if ((HDR.imagf != 0) && (HDR.imagf != 1))\n      break;\n    if (HDR.nameLen > 0xFFFF)\n      return(DestroyImageList(image));\n    for (i=0; i < (ssize_t) HDR.nameLen; i++)\n    {\n      int\n        byte;\n\n      /*\n        Skip matrix name.\n      */\n      byte=ReadBlobByte(image);\n      if (byte == EOF)\n        {\n          ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n            image->filename);\n          break;\n        }\n    }\n    image->columns=(size_t) HDR.nRows;\n    image->rows=(size_t) HDR.nCols;\n    if ((image->columns == 0) || (image->rows == 0))\n      return(DestroyImageList(image));\n    if (image_info->ping != MagickFalse)\n      {\n        Swap(image->columns,image->rows);\n        if(HDR.imagf==1) ldblk *= 2;\n        SeekBlob(image, HDR.nCols*ldblk, SEEK_CUR);\n        if ((image->columns == 0) || (image->rows == 0))\n          return(image->previous == (Image *) NULL ? DestroyImageList(image)\n            : image);\n        goto skip_reading_current;\n      }\n    status=SetImageExtent(image,image->columns,image->rows,exception);\n    if (status == MagickFalse)\n      return(DestroyImageList(image));\n    (void) SetImageBackgroundColor(image,exception);\n    (void) SetImageColorspace(image,GRAYColorspace,exception);\n    quantum_info=AcquireQuantumInfo(image_info,image);\n    if (quantum_info == (QuantumInfo *) NULL)\n      return(DestroyImageList(image));\n    switch(HDR.Type[1])\n    {\n      case 0:\n        format_type=FloatingPointQuantumFormat;\n        depth=64;\n        break;\n      case 1:\n        format_type=FloatingPointQuantumFormat;\n        depth=32;\n        break;\n      case 2:\n        format_type=UnsignedQuantumFormat;\n        depth=16;\n        break;\n      case 3:\n        format_type=SignedQuantumFormat;\n        depth=16;\n        break;\n      case 4:\n        format_type=UnsignedQuantumFormat;\n        depth=8;\n        break;\n      default:\n        format_type=UnsignedQuantumFormat;\n        depth=8;\n        break;\n    }\n    image->depth=depth;\n    if (HDR.Type[0] != 0)\n      SetQuantumEndian(image,quantum_info,MSBEndian);\n    status=SetQuantumFormat(image,quantum_info,format_type);\n    status=SetQuantumDepth(image,quantum_info,depth);\n    status=SetQuantumEndian(image,quantum_info,endian);\n    SetQuantumScale(quantum_info,1.0);\n    pixels=(unsigned char *) GetQuantumPixels(quantum_info);\n    for (y=0; y < (ssize_t) image->rows; y++)\n    {\n      register Quantum\n        *magick_restrict q;\n\n      count=ReadBlob(image,depth/8*image->columns,(char *) pixels);\n      if (count == -1)\n        break;\n      q=QueueAuthenticPixels(image,0,image->rows-y-1,image->columns,1,\n        exception);\n      if (q == (Quantum *) NULL)\n        break;\n      (void) ImportQuantumPixels(image,(CacheView *) NULL,quantum_info,\n        GrayQuantum,pixels,exception);\n      if ((HDR.Type[1] == 2) || (HDR.Type[1] == 3))\n        FixSignedValues(image,q,(int) image->columns);\n      if (SyncAuthenticPixels(image,exception) == MagickFalse)\n        break;\n      if (image->previous == (Image *) NULL)\n        {\n          status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n            image->rows);\n          if (status == MagickFalse)\n            break;\n        }\n    }\n    if (HDR.imagf == 1)\n      for (y=0; y < (ssize_t) image->rows; y++)\n      {\n        /*\n          Read complex pixels.\n        */\n        count=ReadBlob(image,depth/8*image->columns,(char *) pixels);\n        if (count == -1)\n          break;\n        if (HDR.Type[1] == 0)\n          InsertComplexDoubleRow(image,(double *) pixels,y,0,0,exception);\n        else\n          InsertComplexFloatRow(image,(float *) pixels,y,0,0,exception);\n      }\n    if (quantum_info != (QuantumInfo *) NULL)\n      quantum_info=DestroyQuantumInfo(quantum_info);\n    if (EOFBlob(image) != MagickFalse)\n      {\n        ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n          image->filename);\n        break;\n      }\n    rotated_image=RotateImage(image,90.0,exception);\n    if (rotated_image != (Image *) NULL)\n      {\n        rotated_image->page.x=0;\n        rotated_image->page.y=0;\n        rotated_image->colors = image->colors;\n        DestroyBlob(rotated_image);\n        rotated_image->blob=ReferenceBlob(image->blob);\n        AppendImageToList(&image,rotated_image);\n        DeleteImageFromList(&image);\n      }\n    /*\n      Proceed to next image.\n    */\n    if (image_info->number_scenes != 0)\n      if (image->scene >= (image_info->scene+image_info->number_scenes-1))\n        break;\n    /*\n      Allocate next image structure.\n    */\nskip_reading_current:\n    AcquireNextImage(image_info,image,exception);\n    if (GetNextImageInList(image) == (Image *) NULL)\n      {\n        status=MagickFalse;\n        break;\n      }\n    image=SyncNextImageInList(image);\n    status=SetImageProgress(image,LoadImagesTag,TellBlob(image),\n      GetBlobSize(image));\n    if (status == MagickFalse)\n      break;\n  }\n  (void) CloseBlob(image);\n  if (status == MagickFalse)\n    return(DestroyImageList(image));\n  return(GetFirstImageInList(image));\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -43,9 +43,9 @@\n   unsigned int\n     depth;\n \n-\n   quantum_info=(QuantumInfo *) NULL;\n   (void) SeekBlob(image,0,SEEK_SET);\n+  status=MagickTrue;\n   while (EOFBlob(image) == MagickFalse)\n   {\n     /*",
        "diff_line_info": {
            "deleted_lines": [
                ""
            ],
            "added_lines": [
                "  status=MagickTrue;"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-15911",
        "func_name": "ArtifexSoftware/ghostpdl/aes_crypt_ecb",
        "description": "In Artifex Ghostscript 9.23 before 2018-08-24, attackers able to supply crafted PostScript could use uninitialized memory access in the aesdecode operator to crash the interpreter or potentially execute code.",
        "git_url": "https://github.com/ArtifexSoftware/ghostpdl/commit/8e9ce5016db968b40e4ec255a3005f2786cce45f",
        "commit_title": "Bug 699665 \"memory corruption in aesdecode\"",
        "commit_text": " The specimen file calls aesdecode without specifying the key to be used, though it does manage to do enough work with the PDF interpreter routines to get access to aesdecode (which isn't normally available).  This causes us to read uninitialised memory, which can (and often does) lead to a segmentation fault.  In this commit we set the key to NULL explicitly during intialisation and then check it before we read it. If its NULL we just return.  It seems bizarre that we don't return error codes, we should probably look into that at some point, but this prevents the code trying to read uninitialised memory.",
        "func_before": "void aes_crypt_ecb( aes_context *ctx,\n                    int mode,\n                    const unsigned char input[16],\n                    unsigned char output[16] )\n{\n    int i;\n    unsigned long *RK, X0, X1, X2, X3, Y0, Y1, Y2, Y3;\n\n#if defined(XYSSL_PADLOCK_C) && defined(XYSSL_HAVE_X86)\n    if( padlock_supports( PADLOCK_ACE ) )\n    {\n        if( padlock_xcryptecb( ctx, mode, input, output ) == 0 )\n            return;\n    }\n#endif\n\n    RK = ctx->rk;\n\n    GET_ULONG_LE( X0, input,  0 ); X0 ^= *RK++;\n    GET_ULONG_LE( X1, input,  4 ); X1 ^= *RK++;\n    GET_ULONG_LE( X2, input,  8 ); X2 ^= *RK++;\n    GET_ULONG_LE( X3, input, 12 ); X3 ^= *RK++;\n\n    if( mode == AES_DECRYPT )\n    {\n        for( i = (ctx->nr >> 1) - 1; i > 0; i-- )\n        {\n            AES_RROUND( Y0, Y1, Y2, Y3, X0, X1, X2, X3 );\n            AES_RROUND( X0, X1, X2, X3, Y0, Y1, Y2, Y3 );\n        }\n\n        AES_RROUND( Y0, Y1, Y2, Y3, X0, X1, X2, X3 );\n\n        X0 = *RK++ ^ ( RSb[ ( Y0       ) & 0xFF ]       ) ^\n                     ( RSb[ ( Y3 >>  8 ) & 0xFF ] <<  8 ) ^\n                     ( RSb[ ( Y2 >> 16 ) & 0xFF ] << 16 ) ^\n                     ( ((unsigned int)RSb[ ( Y1 >> 24 ) & 0xFF ]) << 24 );\n\n        X1 = *RK++ ^ ( RSb[ ( Y1       ) & 0xFF ]       ) ^\n                     ( RSb[ ( Y0 >>  8 ) & 0xFF ] <<  8 ) ^\n                     ( RSb[ ( Y3 >> 16 ) & 0xFF ] << 16 ) ^\n                     ( ((unsigned int)RSb[ ( Y2 >> 24 ) & 0xFF ]) << 24 );\n\n        X2 = *RK++ ^ ( RSb[ ( Y2       ) & 0xFF ]       ) ^\n                     ( RSb[ ( Y1 >>  8 ) & 0xFF ] <<  8 ) ^\n                     ( RSb[ ( Y0 >> 16 ) & 0xFF ] << 16 ) ^\n                     ( ((unsigned int)RSb[ ( Y3 >> 24 ) & 0xFF ]) << 24 );\n\n        X3 = *RK++ ^ ( RSb[ ( Y3       ) & 0xFF ]       ) ^\n                     ( RSb[ ( Y2 >>  8 ) & 0xFF ] <<  8 ) ^\n                     ( RSb[ ( Y1 >> 16 ) & 0xFF ] << 16 ) ^\n                     ( ((unsigned int)RSb[ ( Y0 >> 24 ) & 0xFF ]) << 24 );\n    }\n    else /* AES_ENCRYPT */\n    {\n        for( i = (ctx->nr >> 1) - 1; i > 0; i-- )\n        {\n            AES_FROUND( Y0, Y1, Y2, Y3, X0, X1, X2, X3 );\n            AES_FROUND( X0, X1, X2, X3, Y0, Y1, Y2, Y3 );\n        }\n\n        AES_FROUND( Y0, Y1, Y2, Y3, X0, X1, X2, X3 );\n\n        X0 = *RK++ ^ ( FSb[ ( Y0       ) & 0xFF ]       ) ^\n                     ( FSb[ ( Y1 >>  8 ) & 0xFF ] <<  8 ) ^\n                     ( FSb[ ( Y2 >> 16 ) & 0xFF ] << 16 ) ^\n                     ( ((unsigned int)FSb[ ( Y3 >> 24 ) & 0xFF ]) << 24 );\n\n        X1 = *RK++ ^ ( FSb[ ( Y1       ) & 0xFF ]       ) ^\n                     ( FSb[ ( Y2 >>  8 ) & 0xFF ] <<  8 ) ^\n                     ( FSb[ ( Y3 >> 16 ) & 0xFF ] << 16 ) ^\n                     ( ((unsigned int)FSb[ ( Y0 >> 24 ) & 0xFF ]) << 24 );\n\n        X2 = *RK++ ^ ( FSb[ ( Y2       ) & 0xFF ]       ) ^\n                     ( FSb[ ( Y3 >>  8 ) & 0xFF ] <<  8 ) ^\n                     ( FSb[ ( Y0 >> 16 ) & 0xFF ] << 16 ) ^\n                     ( ((unsigned int)FSb[ ( Y1 >> 24 ) & 0xFF ]) << 24 );\n\n        X3 = *RK++ ^ ( FSb[ ( Y3       ) & 0xFF ]       ) ^\n                     ( FSb[ ( Y0 >>  8 ) & 0xFF ] <<  8 ) ^\n                     ( FSb[ ( Y1 >> 16 ) & 0xFF ] << 16 ) ^\n                     ( ((unsigned int)FSb[ ( Y2 >> 24 ) & 0xFF ]) << 24 );\n    }\n\n    PUT_ULONG_LE( X0, output,  0 );\n    PUT_ULONG_LE( X1, output,  4 );\n    PUT_ULONG_LE( X2, output,  8 );\n    PUT_ULONG_LE( X3, output, 12 );\n}",
        "func": "void aes_crypt_ecb( aes_context *ctx,\n                    int mode,\n                    const unsigned char input[16],\n                    unsigned char output[16] )\n{\n    int i;\n    unsigned long *RK, X0, X1, X2, X3, Y0, Y1, Y2, Y3;\n\n#if defined(XYSSL_PADLOCK_C) && defined(XYSSL_HAVE_X86)\n    if( padlock_supports( PADLOCK_ACE ) )\n    {\n        if( padlock_xcryptecb( ctx, mode, input, output ) == 0 )\n            return;\n    }\n#endif\n\n    if (ctx == NULL || ctx->rk == NULL)\n        return;\n\n    RK = ctx->rk;\n\n    GET_ULONG_LE( X0, input,  0 ); X0 ^= *RK++;\n    GET_ULONG_LE( X1, input,  4 ); X1 ^= *RK++;\n    GET_ULONG_LE( X2, input,  8 ); X2 ^= *RK++;\n    GET_ULONG_LE( X3, input, 12 ); X3 ^= *RK++;\n\n    if( mode == AES_DECRYPT )\n    {\n        for( i = (ctx->nr >> 1) - 1; i > 0; i-- )\n        {\n            AES_RROUND( Y0, Y1, Y2, Y3, X0, X1, X2, X3 );\n            AES_RROUND( X0, X1, X2, X3, Y0, Y1, Y2, Y3 );\n        }\n\n        AES_RROUND( Y0, Y1, Y2, Y3, X0, X1, X2, X3 );\n\n        X0 = *RK++ ^ ( RSb[ ( Y0       ) & 0xFF ]       ) ^\n                     ( RSb[ ( Y3 >>  8 ) & 0xFF ] <<  8 ) ^\n                     ( RSb[ ( Y2 >> 16 ) & 0xFF ] << 16 ) ^\n                     ( ((unsigned int)RSb[ ( Y1 >> 24 ) & 0xFF ]) << 24 );\n\n        X1 = *RK++ ^ ( RSb[ ( Y1       ) & 0xFF ]       ) ^\n                     ( RSb[ ( Y0 >>  8 ) & 0xFF ] <<  8 ) ^\n                     ( RSb[ ( Y3 >> 16 ) & 0xFF ] << 16 ) ^\n                     ( ((unsigned int)RSb[ ( Y2 >> 24 ) & 0xFF ]) << 24 );\n\n        X2 = *RK++ ^ ( RSb[ ( Y2       ) & 0xFF ]       ) ^\n                     ( RSb[ ( Y1 >>  8 ) & 0xFF ] <<  8 ) ^\n                     ( RSb[ ( Y0 >> 16 ) & 0xFF ] << 16 ) ^\n                     ( ((unsigned int)RSb[ ( Y3 >> 24 ) & 0xFF ]) << 24 );\n\n        X3 = *RK++ ^ ( RSb[ ( Y3       ) & 0xFF ]       ) ^\n                     ( RSb[ ( Y2 >>  8 ) & 0xFF ] <<  8 ) ^\n                     ( RSb[ ( Y1 >> 16 ) & 0xFF ] << 16 ) ^\n                     ( ((unsigned int)RSb[ ( Y0 >> 24 ) & 0xFF ]) << 24 );\n    }\n    else /* AES_ENCRYPT */\n    {\n        for( i = (ctx->nr >> 1) - 1; i > 0; i-- )\n        {\n            AES_FROUND( Y0, Y1, Y2, Y3, X0, X1, X2, X3 );\n            AES_FROUND( X0, X1, X2, X3, Y0, Y1, Y2, Y3 );\n        }\n\n        AES_FROUND( Y0, Y1, Y2, Y3, X0, X1, X2, X3 );\n\n        X0 = *RK++ ^ ( FSb[ ( Y0       ) & 0xFF ]       ) ^\n                     ( FSb[ ( Y1 >>  8 ) & 0xFF ] <<  8 ) ^\n                     ( FSb[ ( Y2 >> 16 ) & 0xFF ] << 16 ) ^\n                     ( ((unsigned int)FSb[ ( Y3 >> 24 ) & 0xFF ]) << 24 );\n\n        X1 = *RK++ ^ ( FSb[ ( Y1       ) & 0xFF ]       ) ^\n                     ( FSb[ ( Y2 >>  8 ) & 0xFF ] <<  8 ) ^\n                     ( FSb[ ( Y3 >> 16 ) & 0xFF ] << 16 ) ^\n                     ( ((unsigned int)FSb[ ( Y0 >> 24 ) & 0xFF ]) << 24 );\n\n        X2 = *RK++ ^ ( FSb[ ( Y2       ) & 0xFF ]       ) ^\n                     ( FSb[ ( Y3 >>  8 ) & 0xFF ] <<  8 ) ^\n                     ( FSb[ ( Y0 >> 16 ) & 0xFF ] << 16 ) ^\n                     ( ((unsigned int)FSb[ ( Y1 >> 24 ) & 0xFF ]) << 24 );\n\n        X3 = *RK++ ^ ( FSb[ ( Y3       ) & 0xFF ]       ) ^\n                     ( FSb[ ( Y0 >>  8 ) & 0xFF ] <<  8 ) ^\n                     ( FSb[ ( Y1 >> 16 ) & 0xFF ] << 16 ) ^\n                     ( ((unsigned int)FSb[ ( Y2 >> 24 ) & 0xFF ]) << 24 );\n    }\n\n    PUT_ULONG_LE( X0, output,  0 );\n    PUT_ULONG_LE( X1, output,  4 );\n    PUT_ULONG_LE( X2, output,  8 );\n    PUT_ULONG_LE( X3, output, 12 );\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -13,6 +13,9 @@\n             return;\n     }\n #endif\n+\n+    if (ctx == NULL || ctx->rk == NULL)\n+        return;\n \n     RK = ctx->rk;\n ",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "    if (ctx == NULL || ctx->rk == NULL)",
                "        return;"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-15911",
        "func_name": "ArtifexSoftware/ghostpdl/s_aes_process",
        "description": "In Artifex Ghostscript 9.23 before 2018-08-24, attackers able to supply crafted PostScript could use uninitialized memory access in the aesdecode operator to crash the interpreter or potentially execute code.",
        "git_url": "https://github.com/ArtifexSoftware/ghostpdl/commit/8e9ce5016db968b40e4ec255a3005f2786cce45f",
        "commit_title": "Bug 699665 \"memory corruption in aesdecode\"",
        "commit_text": " The specimen file calls aesdecode without specifying the key to be used, though it does manage to do enough work with the PDF interpreter routines to get access to aesdecode (which isn't normally available).  This causes us to read uninitialised memory, which can (and often does) lead to a segmentation fault.  In this commit we set the key to NULL explicitly during intialisation and then check it before we read it. If its NULL we just return.  It seems bizarre that we don't return error codes, we should probably look into that at some point, but this prevents the code trying to read uninitialised memory.",
        "func_before": "static int\ns_aes_process(stream_state * ss, stream_cursor_read * pr,\n                  stream_cursor_write * pw, bool last)\n{\n    stream_aes_state *const state = (stream_aes_state *) ss;\n    const unsigned char *limit;\n    const long in_size = pr->limit - pr->ptr;\n    const long out_size = pw->limit - pw->ptr;\n    unsigned char temp[16];\n    int status = 0;\n\n    /* figure out if we're going to run out of space */\n    if (in_size > out_size) {\n        limit = pr->ptr + out_size;\n        status = 1; /* need more output space */\n    } else {\n        limit = pr->limit;\n        status = last ? EOFC : 0; /* need more input */\n    }\n\n    /* set up state and context */\n    if (state->ctx == NULL) {\n      /* allocate the aes context. this is a public struct but it\n         contains internal pointers, so we need to store it separately\n         in immovable memory like any opaque structure. */\n      state->ctx = (aes_context *)gs_alloc_bytes_immovable(state->memory,\n                sizeof(aes_context), \"aes context structure\");\n      if (state->ctx == NULL) {\n        gs_throw(gs_error_VMerror, \"could not allocate aes context\");\n        return ERRC;\n      }\n      if (state->keylength < 1 || state->keylength > SAES_MAX_KEYLENGTH) {\n        gs_throw1(gs_error_rangecheck, \"invalid aes key length (%d bytes)\",\n                state->keylength);\n        return ERRC;\n      }\n      aes_setkey_dec(state->ctx, state->key, state->keylength * 8);\n    }\n    if (!state->initialized) {\n        /* read the initialization vector from the first 16 bytes */\n        if (in_size < 16) return 0; /* get more data */\n        memcpy(state->iv, pr->ptr + 1, 16);\n        state->initialized = 1;\n        pr->ptr += 16;\n    }\n\n    /* decrypt available blocks */\n    while (pr->ptr + 16 <= limit) {\n      aes_crypt_cbc(state->ctx, AES_DECRYPT, 16, state->iv,\n                                pr->ptr + 1, temp);\n      pr->ptr += 16;\n      if (last && pr->ptr == pr->limit) {\n        /* we're on the last block; unpad if necessary */\n        int pad;\n\n        if (state->use_padding) {\n          /* we are using RFC 1423-style padding, so the last byte of the\n             plaintext gives the number of bytes to discard */\n          pad = temp[15];\n          if (pad < 1 || pad > 16) {\n            /* Bug 692343 - don't error here, just warn. Take padding to be\n             * zero. This may give us a stream that's too long - preferable\n             * to the alternatives. */\n            gs_warn1(\"invalid aes padding byte (0x%02x)\",\n                     (unsigned char)pad);\n            pad = 0;\n          }\n        } else {\n          /* not using padding */\n          pad = 0;\n        }\n\n        memcpy(pw->ptr + 1, temp, 16 - pad);\n        pw->ptr +=  16 - pad;\n        return EOFC;\n      }\n      memcpy(pw->ptr + 1, temp, 16);\n      pw->ptr += 16;\n    }\n\n    /* if we got to the end of the file without triggering the padding\n       check, the input must not have been a multiple of 16 bytes long.\n       complain. */\n    if (status == EOFC) {\n      gs_throw(gs_error_rangecheck, \"aes stream isn't a multiple of 16 bytes\");\n      return 0;\n    }\n\n    return status;\n}",
        "func": "static int\ns_aes_process(stream_state * ss, stream_cursor_read * pr,\n                  stream_cursor_write * pw, bool last)\n{\n    stream_aes_state *const state = (stream_aes_state *) ss;\n    const unsigned char *limit;\n    const long in_size = pr->limit - pr->ptr;\n    const long out_size = pw->limit - pw->ptr;\n    unsigned char temp[16];\n    int status = 0;\n\n    /* figure out if we're going to run out of space */\n    if (in_size > out_size) {\n        limit = pr->ptr + out_size;\n        status = 1; /* need more output space */\n    } else {\n        limit = pr->limit;\n        status = last ? EOFC : 0; /* need more input */\n    }\n\n    /* set up state and context */\n    if (state->ctx == NULL) {\n      /* allocate the aes context. this is a public struct but it\n         contains internal pointers, so we need to store it separately\n         in immovable memory like any opaque structure. */\n      state->ctx = (aes_context *)gs_alloc_bytes_immovable(state->memory,\n                sizeof(aes_context), \"aes context structure\");\n      if (state->ctx == NULL) {\n        gs_throw(gs_error_VMerror, \"could not allocate aes context\");\n        return ERRC;\n      }\n      memset(state->ctx, 0x00, sizeof(aes_context));\n      if (state->keylength < 1 || state->keylength > SAES_MAX_KEYLENGTH) {\n        gs_throw1(gs_error_rangecheck, \"invalid aes key length (%d bytes)\",\n                state->keylength);\n        return ERRC;\n      }\n      aes_setkey_dec(state->ctx, state->key, state->keylength * 8);\n    }\n    if (!state->initialized) {\n        /* read the initialization vector from the first 16 bytes */\n        if (in_size < 16) return 0; /* get more data */\n        memcpy(state->iv, pr->ptr + 1, 16);\n        state->initialized = 1;\n        pr->ptr += 16;\n    }\n\n    /* decrypt available blocks */\n    while (pr->ptr + 16 <= limit) {\n      aes_crypt_cbc(state->ctx, AES_DECRYPT, 16, state->iv,\n                                pr->ptr + 1, temp);\n      pr->ptr += 16;\n      if (last && pr->ptr == pr->limit) {\n        /* we're on the last block; unpad if necessary */\n        int pad;\n\n        if (state->use_padding) {\n          /* we are using RFC 1423-style padding, so the last byte of the\n             plaintext gives the number of bytes to discard */\n          pad = temp[15];\n          if (pad < 1 || pad > 16) {\n            /* Bug 692343 - don't error here, just warn. Take padding to be\n             * zero. This may give us a stream that's too long - preferable\n             * to the alternatives. */\n            gs_warn1(\"invalid aes padding byte (0x%02x)\",\n                     (unsigned char)pad);\n            pad = 0;\n          }\n        } else {\n          /* not using padding */\n          pad = 0;\n        }\n\n        memcpy(pw->ptr + 1, temp, 16 - pad);\n        pw->ptr +=  16 - pad;\n        return EOFC;\n      }\n      memcpy(pw->ptr + 1, temp, 16);\n      pw->ptr += 16;\n    }\n\n    /* if we got to the end of the file without triggering the padding\n       check, the input must not have been a multiple of 16 bytes long.\n       complain. */\n    if (status == EOFC) {\n      gs_throw(gs_error_rangecheck, \"aes stream isn't a multiple of 16 bytes\");\n      return 0;\n    }\n\n    return status;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -29,6 +29,7 @@\n         gs_throw(gs_error_VMerror, \"could not allocate aes context\");\n         return ERRC;\n       }\n+      memset(state->ctx, 0x00, sizeof(aes_context));\n       if (state->keylength < 1 || state->keylength > SAES_MAX_KEYLENGTH) {\n         gs_throw1(gs_error_rangecheck, \"invalid aes key length (%d bytes)\",\n                 state->keylength);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "      memset(state->ctx, 0x00, sizeof(aes_context));"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-9499",
        "func_name": "android/BnCrypto::readVector",
        "description": "In readVector of iCrypto.cpp, there is a possible invalid read due to uninitialized data. This could lead to local information disclosure from the DRM server with no additional execution privileges needed. User interaction is not needed for exploitation. Product: Android Versions: Android-7.0 Android-7.1.1 Android-7.1.2 Android-8.0 Android-8.1 Android-9.0 Android ID: A-79218474",
        "git_url": "https://android.googlesource.com/platform/frameworks/av/+/bf7a67c33c0f044abeef3b9746f434b7f3295bb1",
        "commit_title": "Fix information disclosure in mediadrmserver",
        "commit_text": " Test:POC provided in bug Bug:79218474 (cherry picked from commit c1bf68a8d1321d7cdf7da6933f0b89b171d251c6) ",
        "func_before": "void BnCrypto::readVector(const Parcel &data, Vector<uint8_t> &vector) const {\n    uint32_t size = data.readInt32();\n    vector.insertAt((size_t)0, size);\n    data.read(vector.editArray(), size);\n}",
        "func": "void BnCrypto::readVector(const Parcel &data, Vector<uint8_t> &vector) const {\n    uint32_t size = data.readInt32();\n    if (vector.insertAt((size_t)0, size) < 0) {\n        vector.clear();\n    }\n    if (data.read(vector.editArray(), size) != NO_ERROR) {\n        vector.clear();\n        android_errorWriteWithInfoLog(0x534e4554, \"62872384\", -1, NULL, 0);\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,10 @@\n void BnCrypto::readVector(const Parcel &data, Vector<uint8_t> &vector) const {\n     uint32_t size = data.readInt32();\n-    vector.insertAt((size_t)0, size);\n-    data.read(vector.editArray(), size);\n+    if (vector.insertAt((size_t)0, size) < 0) {\n+        vector.clear();\n+    }\n+    if (data.read(vector.editArray(), size) != NO_ERROR) {\n+        vector.clear();\n+        android_errorWriteWithInfoLog(0x534e4554, \"62872384\", -1, NULL, 0);\n+    }\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    vector.insertAt((size_t)0, size);",
                "    data.read(vector.editArray(), size);"
            ],
            "added_lines": [
                "    if (vector.insertAt((size_t)0, size) < 0) {",
                "        vector.clear();",
                "    }",
                "    if (data.read(vector.editArray(), size) != NO_ERROR) {",
                "        vector.clear();",
                "        android_errorWriteWithInfoLog(0x534e4554, \"62872384\", -1, NULL, 0);",
                "    }"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-19626",
        "func_name": "wireshark/dissect_dcom_BSTR",
        "description": "In Wireshark 2.6.0 to 2.6.4 and 2.4.0 to 2.4.10, the DCOM dissector could crash. This was addressed in epan/dissectors/packet-dcom.c by adding '\\0' termination.",
        "git_url": "https://github.com/wireshark/wireshark/commit/c5a65115ebab55cfd5ce0a855c2256e01cab6449",
        "commit_title": "DCOM: always NUL-terminate dissect_dcom_BSTR results",
        "commit_text": " All of the six users in plugins/epan/profinet/packet-dcom-cba.c expect the string to be NUL-terminated, so ensure this to avoid reading uninitialized memory for the Info column.  Bug: 15130 (cherry picked from commit ec6ace066ae4c889d4c18a0a38a8c6053483877b)",
        "func_before": "int\ndissect_dcom_BSTR(tvbuff_t *tvb, gint offset, packet_info *pinfo,\n\t\t       proto_tree *tree, dcerpc_info *di, guint8 *drep, int hfindex,\n\t\t\t\t\t   gchar *pszStr, guint32 u32MaxStr)\n{\n\tguint32 u32MaxCount;\n\tguint32 u32ArraySize;\n\tgint strStart, subStart, realOffset;\n\tproto_item *sub_item;\n\tproto_tree *sub_tree;\n\tguint32 u32ByteLength;\n\tgboolean isPrintable;\n\n\t/* alignment of 4 needed */\n\tif (offset % 4) {\n\t\toffset += 4 - (offset % 4);\n\t}\n\n\t/* add subtree item */\n\tsub_item = proto_tree_add_string(tree, hfindex, tvb, offset, 0, \"\");\n\tsub_tree = proto_item_add_subtree(sub_item, ett_dcom_lpwstr);\n\tsubStart = offset;\n\n\toffset = dissect_dcom_DWORD(tvb, offset, pinfo, sub_tree, di, drep,\n\t\t\thf_dcom_max_count, &u32MaxCount);\n\toffset = dissect_dcom_DWORD(tvb, offset, pinfo, sub_tree, di, drep,\n\t\t\thf_dcom_byte_length, &u32ByteLength);\n\toffset = dissect_dcom_dcerpc_array_size(tvb, offset, pinfo, sub_tree, di, drep,\n\t\t\t&u32ArraySize);\n\n\tif ((guint32)offset + u32ArraySize*2 > G_MAXINT)\n\t\treturn offset;\n\n\trealOffset = offset + u32ArraySize*2;\n\n\tstrStart = offset;\n\toffset = dcom_tvb_get_nwstringz0(tvb, offset, u32ArraySize*2, pszStr, u32MaxStr, &isPrintable);\n\n\tproto_tree_add_string(sub_tree, hfindex, tvb, strStart, offset - strStart, pszStr);\n\n\t/* update subtree header */\n\tproto_item_append_text(sub_item, \"%s%s%s\",\n\tisPrintable ? \"\\\"\" : \"\", pszStr, isPrintable ? \"\\\"\" : \"\");\n\tif (realOffset <= subStart) {\n\t\t/* XXX - expert info */\n\t\treturn offset;\n\t}\n\tproto_item_set_len(sub_item, realOffset - subStart);\n\n\treturn realOffset;\n}",
        "func": "int\ndissect_dcom_BSTR(tvbuff_t *tvb, gint offset, packet_info *pinfo,\n\t\t       proto_tree *tree, dcerpc_info *di, guint8 *drep, int hfindex,\n\t\t\t\t\t   gchar *pszStr, guint32 u32MaxStr)\n{\n\tguint32 u32MaxCount;\n\tguint32 u32ArraySize;\n\tgint strStart, subStart, realOffset;\n\tproto_item *sub_item;\n\tproto_tree *sub_tree;\n\tguint32 u32ByteLength;\n\tgboolean isPrintable;\n\n\t/* alignment of 4 needed */\n\tif (offset % 4) {\n\t\toffset += 4 - (offset % 4);\n\t}\n\n\t/* add subtree item */\n\tsub_item = proto_tree_add_string(tree, hfindex, tvb, offset, 0, \"\");\n\tsub_tree = proto_item_add_subtree(sub_item, ett_dcom_lpwstr);\n\tsubStart = offset;\n\n\toffset = dissect_dcom_DWORD(tvb, offset, pinfo, sub_tree, di, drep,\n\t\t\thf_dcom_max_count, &u32MaxCount);\n\toffset = dissect_dcom_DWORD(tvb, offset, pinfo, sub_tree, di, drep,\n\t\t\thf_dcom_byte_length, &u32ByteLength);\n\toffset = dissect_dcom_dcerpc_array_size(tvb, offset, pinfo, sub_tree, di, drep,\n\t\t\t&u32ArraySize);\n\n\tif ((guint32)offset + u32ArraySize*2 > G_MAXINT) {\n\t\tpszStr[0] = 0;\n\t\treturn offset;\n\t}\n\n\trealOffset = offset + u32ArraySize*2;\n\n\tstrStart = offset;\n\toffset = dcom_tvb_get_nwstringz0(tvb, offset, u32ArraySize*2, pszStr, u32MaxStr, &isPrintable);\n\n\tproto_tree_add_string(sub_tree, hfindex, tvb, strStart, offset - strStart, pszStr);\n\n\t/* update subtree header */\n\tproto_item_append_text(sub_item, \"%s%s%s\",\n\tisPrintable ? \"\\\"\" : \"\", pszStr, isPrintable ? \"\\\"\" : \"\");\n\tif (realOffset <= subStart) {\n\t\t/* XXX - expert info */\n\t\treturn offset;\n\t}\n\tproto_item_set_len(sub_item, realOffset - subStart);\n\n\treturn realOffset;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -28,8 +28,10 @@\n \toffset = dissect_dcom_dcerpc_array_size(tvb, offset, pinfo, sub_tree, di, drep,\n \t\t\t&u32ArraySize);\n \n-\tif ((guint32)offset + u32ArraySize*2 > G_MAXINT)\n+\tif ((guint32)offset + u32ArraySize*2 > G_MAXINT) {\n+\t\tpszStr[0] = 0;\n \t\treturn offset;\n+\t}\n \n \trealOffset = offset + u32ArraySize*2;\n ",
        "diff_line_info": {
            "deleted_lines": [
                "\tif ((guint32)offset + u32ArraySize*2 > G_MAXINT)"
            ],
            "added_lines": [
                "\tif ((guint32)offset + u32ArraySize*2 > G_MAXINT) {",
                "\t\tpszStr[0] = 0;",
                "\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2023-25585",
        "func_name": "binutils-gdb/new_module",
        "description": "A flaw was found in Binutils. The use of an uninitialized field in the struct module *module may lead to application crash and local denial of service.",
        "git_url": "https://sourceware.org/git/gitweb.cgi?p=binutils-gdb.git;h=65cf035b8dc1df5d8020e0b1449514a3c42933e7",
        "commit_title": "",
        "commit_text": "PR29892, Field file_table of struct module is uninitialized  \tPR 29892 \t* vms-alphs.c (new_module): Use bfd_zmalloc to alloc file_table. \t(parse_module): Rewrite file_table reallocation code and clear. ",
        "func_before": "static struct module *\nnew_module (bfd *abfd)\n{\n  struct module *module\n    = (struct module *) bfd_zalloc (abfd, sizeof (struct module));\n  module->file_table_count = 16; /* Arbitrary.  */\n  module->file_table\n    = bfd_malloc (module->file_table_count * sizeof (struct fileinfo));\n  return module;\n}",
        "func": "static struct module *\nnew_module (bfd *abfd)\n{\n  struct module *module\n    = (struct module *) bfd_zalloc (abfd, sizeof (struct module));\n  module->file_table_count = 16; /* Arbitrary.  */\n  module->file_table\n    = bfd_zmalloc (module->file_table_count * sizeof (struct fileinfo));\n  return module;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,6 +5,6 @@\n     = (struct module *) bfd_zalloc (abfd, sizeof (struct module));\n   module->file_table_count = 16; /* Arbitrary.  */\n   module->file_table\n-    = bfd_malloc (module->file_table_count * sizeof (struct fileinfo));\n+    = bfd_zmalloc (module->file_table_count * sizeof (struct fileinfo));\n   return module;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    = bfd_malloc (module->file_table_count * sizeof (struct fileinfo));"
            ],
            "added_lines": [
                "    = bfd_zmalloc (module->file_table_count * sizeof (struct fileinfo));"
            ]
        }
    },
    {
        "cve_id": "CVE-2023-25585",
        "func_name": "binutils-gdb/parse_module",
        "description": "A flaw was found in Binutils. The use of an uninitialized field in the struct module *module may lead to application crash and local denial of service.",
        "git_url": "https://sourceware.org/git/gitweb.cgi?p=binutils-gdb.git;h=65cf035b8dc1df5d8020e0b1449514a3c42933e7",
        "commit_title": "",
        "commit_text": "PR29892, Field file_table of struct module is uninitialized  \tPR 29892 \t* vms-alphs.c (new_module): Use bfd_zmalloc to alloc file_table. \t(parse_module): Rewrite file_table reallocation code and clear. ",
        "func_before": "static bool\nparse_module (bfd *abfd, struct module *module, unsigned char *ptr,\n\t      bfd_size_type length)\n{\n  unsigned char *maxptr = ptr + length;\n  unsigned char *src_ptr, *pcl_ptr;\n  unsigned int prev_linum = 0, curr_linenum = 0;\n  bfd_vma prev_pc = 0, curr_pc = 0;\n  struct srecinfo *curr_srec, *srec;\n  struct lineinfo *curr_line, *line;\n  struct funcinfo *funcinfo;\n\n  /* Initialize tables with zero element.  */\n  curr_srec = (struct srecinfo *) bfd_zalloc (abfd, sizeof (struct srecinfo));\n  if (!curr_srec)\n    return false;\n  module->srec_table = curr_srec;\n\n  curr_line = (struct lineinfo *) bfd_zalloc (abfd, sizeof (struct lineinfo));\n  if (!curr_line)\n    return false;\n  module->line_table = curr_line;\n\n  while (ptr + 3 < maxptr)\n    {\n      /* The first byte is not counted in the recorded length.  */\n      int rec_length = bfd_getl16 (ptr) + 1;\n      int rec_type = bfd_getl16 (ptr + 2);\n\n      vms_debug2 ((2, \"DST record: leng %d, type %d\\n\", rec_length, rec_type));\n\n      if (rec_length > maxptr - ptr)\n\tbreak;\n      if (rec_type == DST__K_MODEND)\n\tbreak;\n\n      switch (rec_type)\n\t{\n\tcase DST__K_MODBEG:\n\t  if (rec_length <= DST_S_B_MODBEG_NAME)\n\t    break;\n\t  module->name\n\t    = _bfd_vms_save_counted_string (abfd, ptr + DST_S_B_MODBEG_NAME,\n\t\t\t\t\t    rec_length - DST_S_B_MODBEG_NAME);\n\n\t  curr_pc = 0;\n\t  prev_pc = 0;\n\t  curr_linenum = 0;\n\t  prev_linum = 0;\n\n\t  vms_debug2 ((3, \"module: %s\\n\", module->name));\n\t  break;\n\n\tcase DST__K_MODEND:\n\t  break;\n\n\tcase DST__K_RTNBEG:\n\t  if (rec_length <= DST_S_B_RTNBEG_NAME)\n\t    break;\n\t  funcinfo = (struct funcinfo *)\n\t    bfd_zalloc (abfd, sizeof (struct funcinfo));\n\t  if (!funcinfo)\n\t    return false;\n\t  funcinfo->name\n\t    = _bfd_vms_save_counted_string (abfd, ptr + DST_S_B_RTNBEG_NAME,\n\t\t\t\t\t    rec_length - DST_S_B_RTNBEG_NAME);\n\t  funcinfo->low = bfd_getl32 (ptr + DST_S_L_RTNBEG_ADDRESS);\n\t  funcinfo->next = module->func_table;\n\t  module->func_table = funcinfo;\n\n\t  vms_debug2 ((3, \"routine: %s at 0x%lx\\n\",\n\t\t       funcinfo->name, (unsigned long) funcinfo->low));\n\t  break;\n\n\tcase DST__K_RTNEND:\n\t  if (rec_length < DST_S_L_RTNEND_SIZE + 4)\n\t    break;\n\t  if (!module->func_table)\n\t    return false;\n\t  module->func_table->high = module->func_table->low\n\t    + bfd_getl32 (ptr + DST_S_L_RTNEND_SIZE) - 1;\n\n\t  if (module->func_table->high > module->high)\n\t    module->high = module->func_table->high;\n\n\t  vms_debug2 ((3, \"end routine\\n\"));\n\t  break;\n\n\tcase DST__K_PROLOG:\n\t  vms_debug2 ((3, \"prologue\\n\"));\n\t  break;\n\n\tcase DST__K_EPILOG:\n\t  vms_debug2 ((3, \"epilog\\n\"));\n\t  break;\n\n\tcase DST__K_BLKBEG:\n\t  vms_debug2 ((3, \"block\\n\"));\n\t  break;\n\n\tcase DST__K_BLKEND:\n\t  vms_debug2 ((3, \"end block\\n\"));\n\t  break;\n\n\tcase DST__K_SOURCE:\n\t  src_ptr = ptr + DST_S_C_SOURCE_HEADER_SIZE;\n\n\t  vms_debug2 ((3, \"source info\\n\"));\n\n\t  while (src_ptr - ptr < rec_length)\n\t    {\n\t      int cmd = src_ptr[0], cmd_length, data;\n\n\t      switch (cmd)\n\t\t{\n\t\tcase DST__K_SRC_DECLFILE:\n\t\t  if (src_ptr - ptr + DST_S_B_SRC_DF_LENGTH >= rec_length)\n\t\t    cmd_length = 0x10000;\n\t\t  else\n\t\t    cmd_length = src_ptr[DST_S_B_SRC_DF_LENGTH] + 2;\n\t\t  break;\n\n\t\tcase DST__K_SRC_DEFLINES_B:\n\t\t  cmd_length = 2;\n\t\t  break;\n\n\t\tcase DST__K_SRC_DEFLINES_W:\n\t\t  cmd_length = 3;\n\t\t  break;\n\n\t\tcase DST__K_SRC_INCRLNUM_B:\n\t\t  cmd_length = 2;\n\t\t  break;\n\n\t\tcase DST__K_SRC_SETFILE:\n\t\t  cmd_length = 3;\n\t\t  break;\n\n\t\tcase DST__K_SRC_SETLNUM_L:\n\t\t  cmd_length = 5;\n\t\t  break;\n\n\t\tcase DST__K_SRC_SETLNUM_W:\n\t\t  cmd_length = 3;\n\t\t  break;\n\n\t\tcase DST__K_SRC_SETREC_L:\n\t\t  cmd_length = 5;\n\t\t  break;\n\n\t\tcase DST__K_SRC_SETREC_W:\n\t\t  cmd_length = 3;\n\t\t  break;\n\n\t\tcase DST__K_SRC_FORMFEED:\n\t\t  cmd_length = 1;\n\t\t  break;\n\n\t\tdefault:\n\t\t  cmd_length = 2;\n\t\t  break;\n\t\t}\n\n\t      if (src_ptr - ptr + cmd_length > rec_length)\n\t\tbreak;\n\n\t      switch (cmd)\n\t\t{\n\t\tcase DST__K_SRC_DECLFILE:\n\t\t  {\n\t\t    unsigned int fileid\n\t\t      = bfd_getl16 (src_ptr + DST_S_W_SRC_DF_FILEID);\n\t\t    char *filename = _bfd_vms_save_counted_string\n\t\t      (abfd,\n\t\t       src_ptr + DST_S_B_SRC_DF_FILENAME,\n\t\t       ptr + rec_length - (src_ptr + DST_S_B_SRC_DF_FILENAME));\n\n\t\t    while (fileid >= module->file_table_count)\n\t\t      {\n\t\t\tmodule->file_table_count *= 2;\n\t\t\tmodule->file_table\n\t\t\t  = bfd_realloc_or_free (module->file_table,\n\t\t\t\t\t\t module->file_table_count\n\t\t\t\t\t\t * sizeof (struct fileinfo));\n\t\t\tif (module->file_table == NULL)\n\t\t\t  return false;\n\t\t      }\n\n\t\t    module->file_table [fileid].name = filename;\n\t\t    module->file_table [fileid].srec = 1;\n\t\t    vms_debug2 ((4, \"DST_S_C_SRC_DECLFILE: %d, %s\\n\",\n\t\t\t\t fileid, module->file_table [fileid].name));\n\t\t  }\n\t\t  break;\n\n\t\tcase DST__K_SRC_DEFLINES_B:\n\t\t  /* Perform the association and set the next higher index\n\t\t     to the limit.  */\n\t\t  data = src_ptr[DST_S_B_SRC_UNSBYTE];\n\t\t  srec = (struct srecinfo *)\n\t\t    bfd_zalloc (abfd, sizeof (struct srecinfo));\n\t\t  srec->line = curr_srec->line + data;\n\t\t  srec->srec = curr_srec->srec + data;\n\t\t  srec->sfile = curr_srec->sfile;\n\t\t  curr_srec->next = srec;\n\t\t  curr_srec = srec;\n\t\t  vms_debug2 ((4, \"DST_S_C_SRC_DEFLINES_B: %d\\n\", data));\n\t\t  break;\n\n\t\tcase DST__K_SRC_DEFLINES_W:\n\t\t  /* Perform the association and set the next higher index\n\t\t     to the limit.  */\n\t\t  data = bfd_getl16 (src_ptr + DST_S_W_SRC_UNSWORD);\n\t\t  srec = (struct srecinfo *)\n\t\t    bfd_zalloc (abfd, sizeof (struct srecinfo));\n\t\t  srec->line = curr_srec->line + data;\n\t\t  srec->srec = curr_srec->srec + data,\n\t\t  srec->sfile = curr_srec->sfile;\n\t\t  curr_srec->next = srec;\n\t\t  curr_srec = srec;\n\t\t  vms_debug2 ((4, \"DST_S_C_SRC_DEFLINES_W: %d\\n\", data));\n\t\t  break;\n\n\t\tcase DST__K_SRC_INCRLNUM_B:\n\t\t  data = src_ptr[DST_S_B_SRC_UNSBYTE];\n\t\t  curr_srec->line += data;\n\t\t  vms_debug2 ((4, \"DST_S_C_SRC_INCRLNUM_B: %d\\n\", data));\n\t\t  break;\n\n\t\tcase DST__K_SRC_SETFILE:\n\t\t  data = bfd_getl16 (src_ptr + DST_S_W_SRC_UNSWORD);\n\t\t  curr_srec->sfile = data;\n\t\t  curr_srec->srec = module->file_table[data].srec;\n\t\t  vms_debug2 ((4, \"DST_S_C_SRC_SETFILE: %d\\n\", data));\n\t\t  break;\n\n\t\tcase DST__K_SRC_SETLNUM_L:\n\t\t  data = bfd_getl32 (src_ptr + DST_S_L_SRC_UNSLONG);\n\t\t  curr_srec->line = data;\n\t\t  vms_debug2 ((4, \"DST_S_C_SRC_SETLNUM_L: %d\\n\", data));\n\t\t  break;\n\n\t\tcase DST__K_SRC_SETLNUM_W:\n\t\t  data = bfd_getl16 (src_ptr + DST_S_W_SRC_UNSWORD);\n\t\t  curr_srec->line = data;\n\t\t  vms_debug2 ((4, \"DST_S_C_SRC_SETLNUM_W: %d\\n\", data));\n\t\t  break;\n\n\t\tcase DST__K_SRC_SETREC_L:\n\t\t  data = bfd_getl32 (src_ptr + DST_S_L_SRC_UNSLONG);\n\t\t  curr_srec->srec = data;\n\t\t  module->file_table[curr_srec->sfile].srec = data;\n\t\t  vms_debug2 ((4, \"DST_S_C_SRC_SETREC_L: %d\\n\", data));\n\t\t  break;\n\n\t\tcase DST__K_SRC_SETREC_W:\n\t\t  data = bfd_getl16 (src_ptr + DST_S_W_SRC_UNSWORD);\n\t\t  curr_srec->srec = data;\n\t\t  module->file_table[curr_srec->sfile].srec = data;\n\t\t  vms_debug2 ((4, \"DST_S_C_SRC_SETREC_W: %d\\n\", data));\n\t\t  break;\n\n\t\tcase DST__K_SRC_FORMFEED:\n\t\t  vms_debug2 ((4, \"DST_S_C_SRC_FORMFEED\\n\"));\n\t\t  break;\n\n\t\tdefault:\n\t\t  _bfd_error_handler (_(\"unknown source command %d\"),\n\t\t\t\t      cmd);\n\t\t  break;\n\t\t}\n\n\t      src_ptr += cmd_length;\n\t    }\n\t  break;\n\n\tcase DST__K_LINE_NUM:\n\t  pcl_ptr = ptr + DST_S_C_LINE_NUM_HEADER_SIZE;\n\n\t  vms_debug2 ((3, \"line info\\n\"));\n\n\t  while (pcl_ptr - ptr < rec_length)\n\t    {\n\t      /* The command byte is signed so we must sign-extend it.  */\n\t      int cmd = ((signed char *)pcl_ptr)[0], cmd_length, data;\n\n\t      switch (cmd)\n\t\t{\n\t\tcase DST__K_DELTA_PC_W:\n\t\t  cmd_length = 3;\n\t\t  break;\n\n\t\tcase DST__K_DELTA_PC_L:\n\t\t  cmd_length = 5;\n\t\t  break;\n\n\t\tcase DST__K_INCR_LINUM:\n\t\t  cmd_length = 2;\n\t\t  break;\n\n\t\tcase DST__K_INCR_LINUM_W:\n\t\t  cmd_length = 3;\n\t\t  break;\n\n\t\tcase DST__K_INCR_LINUM_L:\n\t\t  cmd_length = 5;\n\t\t  break;\n\n\t\tcase DST__K_SET_LINUM_INCR:\n\t\t  cmd_length = 2;\n\t\t  break;\n\n\t\tcase DST__K_SET_LINUM_INCR_W:\n\t\t  cmd_length = 3;\n\t\t  break;\n\n\t\tcase DST__K_RESET_LINUM_INCR:\n\t\t  cmd_length = 1;\n\t\t  break;\n\n\t\tcase DST__K_BEG_STMT_MODE:\n\t\t  cmd_length = 1;\n\t\t  break;\n\n\t\tcase DST__K_END_STMT_MODE:\n\t\t  cmd_length = 1;\n\t\t  break;\n\n\t\tcase DST__K_SET_LINUM_B:\n\t\t  cmd_length = 2;\n\t\t  break;\n\n\t\tcase DST__K_SET_LINUM:\n\t\t  cmd_length = 3;\n\t\t  break;\n\n\t\tcase DST__K_SET_LINUM_L:\n\t\t  cmd_length = 5;\n\t\t  break;\n\n\t\tcase DST__K_SET_PC:\n\t\t  cmd_length = 2;\n\t\t  break;\n\n\t\tcase DST__K_SET_PC_W:\n\t\t  cmd_length = 3;\n\t\t  break;\n\n\t\tcase DST__K_SET_PC_L:\n\t\t  cmd_length = 5;\n\t\t  break;\n\n\t\tcase DST__K_SET_STMTNUM:\n\t\t  cmd_length = 2;\n\t\t  break;\n\n\t\tcase DST__K_TERM:\n\t\t  cmd_length = 2;\n\t\t  break;\n\n\t\tcase DST__K_TERM_W:\n\t\t  cmd_length = 3;\n\t\t  break;\n\n\t\tcase DST__K_TERM_L:\n\t\t  cmd_length = 5;\n\t\t  break;\n\n\t\tcase DST__K_SET_ABS_PC:\n\t\t  cmd_length = 5;\n\t\t  break;\n\n\t\tdefault:\n\t\t  if (cmd <= 0)\n\t\t    cmd_length = 1;\n\t\t  else\n\t\t    cmd_length = 2;\n\t\t  break;\n\t\t}\n\n\t      if (pcl_ptr - ptr + cmd_length > rec_length)\n\t\tbreak;\n\n\t      switch (cmd)\n\t\t{\n\t\tcase DST__K_DELTA_PC_W:\n\t\t  data = bfd_getl16 (pcl_ptr + DST_S_W_PCLINE_UNSWORD);\n\t\t  curr_pc += data;\n\t\t  curr_linenum += 1;\n\t\t  vms_debug2 ((4, \"DST__K_DELTA_PC_W: %d\\n\", data));\n\t\t  break;\n\n\t\tcase DST__K_DELTA_PC_L:\n\t\t  data = bfd_getl32 (pcl_ptr + DST_S_L_PCLINE_UNSLONG);\n\t\t  curr_pc += data;\n\t\t  curr_linenum += 1;\n\t\t  vms_debug2 ((4, \"DST__K_DELTA_PC_L: %d\\n\", data));\n\t\t  break;\n\n\t\tcase DST__K_INCR_LINUM:\n\t\t  data = pcl_ptr[DST_S_B_PCLINE_UNSBYTE];\n\t\t  curr_linenum += data;\n\t\t  vms_debug2 ((4, \"DST__K_INCR_LINUM: %d\\n\", data));\n\t\t  break;\n\n\t\tcase DST__K_INCR_LINUM_W:\n\t\t  data = bfd_getl16 (pcl_ptr + DST_S_W_PCLINE_UNSWORD);\n\t\t  curr_linenum += data;\n\t\t  vms_debug2 ((4, \"DST__K_INCR_LINUM_W: %d\\n\", data));\n\t\t  break;\n\n\t\tcase DST__K_INCR_LINUM_L:\n\t\t  data = bfd_getl32 (pcl_ptr + DST_S_L_PCLINE_UNSLONG);\n\t\t  curr_linenum += data;\n\t\t  vms_debug2 ((4, \"DST__K_INCR_LINUM_L: %d\\n\", data));\n\t\t  break;\n\n\t\tcase DST__K_SET_LINUM_INCR:\n\t\t  _bfd_error_handler\n\t\t    (_(\"%s not implemented\"), \"DST__K_SET_LINUM_INCR\");\n\t\t  break;\n\n\t\tcase DST__K_SET_LINUM_INCR_W:\n\t\t  _bfd_error_handler\n\t\t    (_(\"%s not implemented\"), \"DST__K_SET_LINUM_INCR_W\");\n\t\t  break;\n\n\t\tcase DST__K_RESET_LINUM_INCR:\n\t\t  _bfd_error_handler\n\t\t    (_(\"%s not implemented\"), \"DST__K_RESET_LINUM_INCR\");\n\t\t  break;\n\n\t\tcase DST__K_BEG_STMT_MODE:\n\t\t  _bfd_error_handler\n\t\t    (_(\"%s not implemented\"), \"DST__K_BEG_STMT_MODE\");\n\t\t  break;\n\n\t\tcase DST__K_END_STMT_MODE:\n\t\t  _bfd_error_handler\n\t\t    (_(\"%s not implemented\"), \"DST__K_END_STMT_MODE\");\n\t\t  break;\n\n\t\tcase DST__K_SET_LINUM_B:\n\t\t  data = pcl_ptr[DST_S_B_PCLINE_UNSBYTE];\n\t\t  curr_linenum = data;\n\t\t  vms_debug2 ((4, \"DST__K_SET_LINUM_B: %d\\n\", data));\n\t\t  break;\n\n\t\tcase DST__K_SET_LINUM:\n\t\t  data = bfd_getl16 (pcl_ptr + DST_S_W_PCLINE_UNSWORD);\n\t\t  curr_linenum = data;\n\t\t  vms_debug2 ((4, \"DST__K_SET_LINE_NUM: %d\\n\", data));\n\t\t  break;\n\n\t\tcase DST__K_SET_LINUM_L:\n\t\t  data = bfd_getl32 (pcl_ptr + DST_S_L_PCLINE_UNSLONG);\n\t\t  curr_linenum = data;\n\t\t  vms_debug2 ((4, \"DST__K_SET_LINUM_L: %d\\n\", data));\n\t\t  break;\n\n\t\tcase DST__K_SET_PC:\n\t\t  _bfd_error_handler\n\t\t    (_(\"%s not implemented\"), \"DST__K_SET_PC\");\n\t\t  break;\n\n\t\tcase DST__K_SET_PC_W:\n\t\t  _bfd_error_handler\n\t\t    (_(\"%s not implemented\"), \"DST__K_SET_PC_W\");\n\t\t  break;\n\n\t\tcase DST__K_SET_PC_L:\n\t\t  _bfd_error_handler\n\t\t    (_(\"%s not implemented\"), \"DST__K_SET_PC_L\");\n\t\t  break;\n\n\t\tcase DST__K_SET_STMTNUM:\n\t\t  _bfd_error_handler\n\t\t    (_(\"%s not implemented\"), \"DST__K_SET_STMTNUM\");\n\t\t  break;\n\n\t\tcase DST__K_TERM:\n\t\t  data = pcl_ptr[DST_S_B_PCLINE_UNSBYTE];\n\t\t  curr_pc += data;\n\t\t  vms_debug2 ((4, \"DST__K_TERM: %d\\n\", data));\n\t\t  break;\n\n\t\tcase DST__K_TERM_W:\n\t\t  data = bfd_getl16 (pcl_ptr + DST_S_W_PCLINE_UNSWORD);\n\t\t  curr_pc += data;\n\t\t  vms_debug2 ((4, \"DST__K_TERM_W: %d\\n\", data));\n\t\t  break;\n\n\t\tcase DST__K_TERM_L:\n\t\t  data = bfd_getl32 (pcl_ptr + DST_S_L_PCLINE_UNSLONG);\n\t\t  curr_pc += data;\n\t\t  vms_debug2 ((4, \"DST__K_TERM_L: %d\\n\", data));\n\t\t  break;\n\n\t\tcase DST__K_SET_ABS_PC:\n\t\t  data = bfd_getl32 (pcl_ptr + DST_S_L_PCLINE_UNSLONG);\n\t\t  curr_pc = data;\n\t\t  vms_debug2 ((4, \"DST__K_SET_ABS_PC: 0x%x\\n\", data));\n\t\t  break;\n\n\t\tdefault:\n\t\t  if (cmd <= 0)\n\t\t    {\n\t\t      curr_pc -= cmd;\n\t\t      curr_linenum += 1;\n\t\t      vms_debug2 ((4, \"bump pc to 0x%lx and line to %d\\n\",\n\t\t\t\t   (unsigned long)curr_pc, curr_linenum));\n\t\t    }\n\t\t  else\n\t\t    _bfd_error_handler (_(\"unknown line command %d\"), cmd);\n\t\t  break;\n\t\t}\n\n\t      if ((curr_linenum != prev_linum && curr_pc != prev_pc)\n\t\t  || cmd <= 0\n\t\t  || cmd == DST__K_DELTA_PC_L\n\t\t  || cmd == DST__K_DELTA_PC_W)\n\t\t{\n\t\t  line = (struct lineinfo *)\n\t\t    bfd_zalloc (abfd, sizeof (struct lineinfo));\n\t\t  line->address = curr_pc;\n\t\t  line->line = curr_linenum;\n\n\t\t  curr_line->next = line;\n\t\t  curr_line = line;\n\n\t\t  prev_linum = curr_linenum;\n\t\t  prev_pc = curr_pc;\n\t\t  vms_debug2 ((4, \"-> correlate pc 0x%lx with line %d\\n\",\n\t\t\t       (unsigned long)curr_pc, curr_linenum));\n\t\t}\n\n\t      pcl_ptr += cmd_length;\n\t    }\n\t  break;\n\n\tcase 0x17: /* Undocumented type used by DEC C to declare equates.  */\n\t  vms_debug2 ((3, \"undocumented type 0x17\\n\"));\n\t  break;\n\n\tdefault:\n\t  vms_debug2 ((3, \"ignoring record\\n\"));\n\t  break;\n\n\t}\n\n      ptr += rec_length;\n    }\n\n  /* Finalize tables with EOL marker.  */\n  srec = (struct srecinfo *) bfd_zalloc (abfd, sizeof (struct srecinfo));\n  srec->line = (unsigned int) -1;\n  srec->srec = (unsigned int) -1;\n  curr_srec->next = srec;\n\n  line = (struct lineinfo *) bfd_zalloc (abfd, sizeof (struct lineinfo));\n  line->line = (unsigned int) -1;\n  line->address = (bfd_vma) -1;\n  curr_line->next = line;\n\n  /* Advertise that this module has been parsed.  This is needed\n     because parsing can be either performed at module creation\n     or deferred until debug info is consumed.  */\n  SET_MODULE_PARSED (module);\n  return true;\n}",
        "func": "static bool\nparse_module (bfd *abfd, struct module *module, unsigned char *ptr,\n\t      bfd_size_type length)\n{\n  unsigned char *maxptr = ptr + length;\n  unsigned char *src_ptr, *pcl_ptr;\n  unsigned int prev_linum = 0, curr_linenum = 0;\n  bfd_vma prev_pc = 0, curr_pc = 0;\n  struct srecinfo *curr_srec, *srec;\n  struct lineinfo *curr_line, *line;\n  struct funcinfo *funcinfo;\n\n  /* Initialize tables with zero element.  */\n  curr_srec = (struct srecinfo *) bfd_zalloc (abfd, sizeof (struct srecinfo));\n  if (!curr_srec)\n    return false;\n  module->srec_table = curr_srec;\n\n  curr_line = (struct lineinfo *) bfd_zalloc (abfd, sizeof (struct lineinfo));\n  if (!curr_line)\n    return false;\n  module->line_table = curr_line;\n\n  while (ptr + 3 < maxptr)\n    {\n      /* The first byte is not counted in the recorded length.  */\n      int rec_length = bfd_getl16 (ptr) + 1;\n      int rec_type = bfd_getl16 (ptr + 2);\n\n      vms_debug2 ((2, \"DST record: leng %d, type %d\\n\", rec_length, rec_type));\n\n      if (rec_length > maxptr - ptr)\n\tbreak;\n      if (rec_type == DST__K_MODEND)\n\tbreak;\n\n      switch (rec_type)\n\t{\n\tcase DST__K_MODBEG:\n\t  if (rec_length <= DST_S_B_MODBEG_NAME)\n\t    break;\n\t  module->name\n\t    = _bfd_vms_save_counted_string (abfd, ptr + DST_S_B_MODBEG_NAME,\n\t\t\t\t\t    rec_length - DST_S_B_MODBEG_NAME);\n\n\t  curr_pc = 0;\n\t  prev_pc = 0;\n\t  curr_linenum = 0;\n\t  prev_linum = 0;\n\n\t  vms_debug2 ((3, \"module: %s\\n\", module->name));\n\t  break;\n\n\tcase DST__K_MODEND:\n\t  break;\n\n\tcase DST__K_RTNBEG:\n\t  if (rec_length <= DST_S_B_RTNBEG_NAME)\n\t    break;\n\t  funcinfo = (struct funcinfo *)\n\t    bfd_zalloc (abfd, sizeof (struct funcinfo));\n\t  if (!funcinfo)\n\t    return false;\n\t  funcinfo->name\n\t    = _bfd_vms_save_counted_string (abfd, ptr + DST_S_B_RTNBEG_NAME,\n\t\t\t\t\t    rec_length - DST_S_B_RTNBEG_NAME);\n\t  funcinfo->low = bfd_getl32 (ptr + DST_S_L_RTNBEG_ADDRESS);\n\t  funcinfo->next = module->func_table;\n\t  module->func_table = funcinfo;\n\n\t  vms_debug2 ((3, \"routine: %s at 0x%lx\\n\",\n\t\t       funcinfo->name, (unsigned long) funcinfo->low));\n\t  break;\n\n\tcase DST__K_RTNEND:\n\t  if (rec_length < DST_S_L_RTNEND_SIZE + 4)\n\t    break;\n\t  if (!module->func_table)\n\t    return false;\n\t  module->func_table->high = module->func_table->low\n\t    + bfd_getl32 (ptr + DST_S_L_RTNEND_SIZE) - 1;\n\n\t  if (module->func_table->high > module->high)\n\t    module->high = module->func_table->high;\n\n\t  vms_debug2 ((3, \"end routine\\n\"));\n\t  break;\n\n\tcase DST__K_PROLOG:\n\t  vms_debug2 ((3, \"prologue\\n\"));\n\t  break;\n\n\tcase DST__K_EPILOG:\n\t  vms_debug2 ((3, \"epilog\\n\"));\n\t  break;\n\n\tcase DST__K_BLKBEG:\n\t  vms_debug2 ((3, \"block\\n\"));\n\t  break;\n\n\tcase DST__K_BLKEND:\n\t  vms_debug2 ((3, \"end block\\n\"));\n\t  break;\n\n\tcase DST__K_SOURCE:\n\t  src_ptr = ptr + DST_S_C_SOURCE_HEADER_SIZE;\n\n\t  vms_debug2 ((3, \"source info\\n\"));\n\n\t  while (src_ptr - ptr < rec_length)\n\t    {\n\t      int cmd = src_ptr[0], cmd_length, data;\n\n\t      switch (cmd)\n\t\t{\n\t\tcase DST__K_SRC_DECLFILE:\n\t\t  if (src_ptr - ptr + DST_S_B_SRC_DF_LENGTH >= rec_length)\n\t\t    cmd_length = 0x10000;\n\t\t  else\n\t\t    cmd_length = src_ptr[DST_S_B_SRC_DF_LENGTH] + 2;\n\t\t  break;\n\n\t\tcase DST__K_SRC_DEFLINES_B:\n\t\t  cmd_length = 2;\n\t\t  break;\n\n\t\tcase DST__K_SRC_DEFLINES_W:\n\t\t  cmd_length = 3;\n\t\t  break;\n\n\t\tcase DST__K_SRC_INCRLNUM_B:\n\t\t  cmd_length = 2;\n\t\t  break;\n\n\t\tcase DST__K_SRC_SETFILE:\n\t\t  cmd_length = 3;\n\t\t  break;\n\n\t\tcase DST__K_SRC_SETLNUM_L:\n\t\t  cmd_length = 5;\n\t\t  break;\n\n\t\tcase DST__K_SRC_SETLNUM_W:\n\t\t  cmd_length = 3;\n\t\t  break;\n\n\t\tcase DST__K_SRC_SETREC_L:\n\t\t  cmd_length = 5;\n\t\t  break;\n\n\t\tcase DST__K_SRC_SETREC_W:\n\t\t  cmd_length = 3;\n\t\t  break;\n\n\t\tcase DST__K_SRC_FORMFEED:\n\t\t  cmd_length = 1;\n\t\t  break;\n\n\t\tdefault:\n\t\t  cmd_length = 2;\n\t\t  break;\n\t\t}\n\n\t      if (src_ptr - ptr + cmd_length > rec_length)\n\t\tbreak;\n\n\t      switch (cmd)\n\t\t{\n\t\tcase DST__K_SRC_DECLFILE:\n\t\t  {\n\t\t    unsigned int fileid\n\t\t      = bfd_getl16 (src_ptr + DST_S_W_SRC_DF_FILEID);\n\t\t    char *filename = _bfd_vms_save_counted_string\n\t\t      (abfd,\n\t\t       src_ptr + DST_S_B_SRC_DF_FILENAME,\n\t\t       ptr + rec_length - (src_ptr + DST_S_B_SRC_DF_FILENAME));\n\n\t\t    if (fileid >= module->file_table_count)\n\t\t      {\n\t\t\tunsigned int old_count = module->file_table_count;\n\t\t\tmodule->file_table_count += fileid;\n\t\t\tmodule->file_table\n\t\t\t  = bfd_realloc_or_free (module->file_table,\n\t\t\t\t\t\t module->file_table_count\n\t\t\t\t\t\t * sizeof (struct fileinfo));\n\t\t\tif (module->file_table == NULL)\n\t\t\t  return false;\n\t\t\tmemset (module->file_table + old_count, 0,\n\t\t\t\tfileid * sizeof (struct fileinfo));\n\t\t      }\n\n\t\t    module->file_table [fileid].name = filename;\n\t\t    module->file_table [fileid].srec = 1;\n\t\t    vms_debug2 ((4, \"DST_S_C_SRC_DECLFILE: %d, %s\\n\",\n\t\t\t\t fileid, module->file_table [fileid].name));\n\t\t  }\n\t\t  break;\n\n\t\tcase DST__K_SRC_DEFLINES_B:\n\t\t  /* Perform the association and set the next higher index\n\t\t     to the limit.  */\n\t\t  data = src_ptr[DST_S_B_SRC_UNSBYTE];\n\t\t  srec = (struct srecinfo *)\n\t\t    bfd_zalloc (abfd, sizeof (struct srecinfo));\n\t\t  srec->line = curr_srec->line + data;\n\t\t  srec->srec = curr_srec->srec + data;\n\t\t  srec->sfile = curr_srec->sfile;\n\t\t  curr_srec->next = srec;\n\t\t  curr_srec = srec;\n\t\t  vms_debug2 ((4, \"DST_S_C_SRC_DEFLINES_B: %d\\n\", data));\n\t\t  break;\n\n\t\tcase DST__K_SRC_DEFLINES_W:\n\t\t  /* Perform the association and set the next higher index\n\t\t     to the limit.  */\n\t\t  data = bfd_getl16 (src_ptr + DST_S_W_SRC_UNSWORD);\n\t\t  srec = (struct srecinfo *)\n\t\t    bfd_zalloc (abfd, sizeof (struct srecinfo));\n\t\t  srec->line = curr_srec->line + data;\n\t\t  srec->srec = curr_srec->srec + data,\n\t\t  srec->sfile = curr_srec->sfile;\n\t\t  curr_srec->next = srec;\n\t\t  curr_srec = srec;\n\t\t  vms_debug2 ((4, \"DST_S_C_SRC_DEFLINES_W: %d\\n\", data));\n\t\t  break;\n\n\t\tcase DST__K_SRC_INCRLNUM_B:\n\t\t  data = src_ptr[DST_S_B_SRC_UNSBYTE];\n\t\t  curr_srec->line += data;\n\t\t  vms_debug2 ((4, \"DST_S_C_SRC_INCRLNUM_B: %d\\n\", data));\n\t\t  break;\n\n\t\tcase DST__K_SRC_SETFILE:\n\t\t  data = bfd_getl16 (src_ptr + DST_S_W_SRC_UNSWORD);\n\t\t  curr_srec->sfile = data;\n\t\t  curr_srec->srec = module->file_table[data].srec;\n\t\t  vms_debug2 ((4, \"DST_S_C_SRC_SETFILE: %d\\n\", data));\n\t\t  break;\n\n\t\tcase DST__K_SRC_SETLNUM_L:\n\t\t  data = bfd_getl32 (src_ptr + DST_S_L_SRC_UNSLONG);\n\t\t  curr_srec->line = data;\n\t\t  vms_debug2 ((4, \"DST_S_C_SRC_SETLNUM_L: %d\\n\", data));\n\t\t  break;\n\n\t\tcase DST__K_SRC_SETLNUM_W:\n\t\t  data = bfd_getl16 (src_ptr + DST_S_W_SRC_UNSWORD);\n\t\t  curr_srec->line = data;\n\t\t  vms_debug2 ((4, \"DST_S_C_SRC_SETLNUM_W: %d\\n\", data));\n\t\t  break;\n\n\t\tcase DST__K_SRC_SETREC_L:\n\t\t  data = bfd_getl32 (src_ptr + DST_S_L_SRC_UNSLONG);\n\t\t  curr_srec->srec = data;\n\t\t  module->file_table[curr_srec->sfile].srec = data;\n\t\t  vms_debug2 ((4, \"DST_S_C_SRC_SETREC_L: %d\\n\", data));\n\t\t  break;\n\n\t\tcase DST__K_SRC_SETREC_W:\n\t\t  data = bfd_getl16 (src_ptr + DST_S_W_SRC_UNSWORD);\n\t\t  curr_srec->srec = data;\n\t\t  module->file_table[curr_srec->sfile].srec = data;\n\t\t  vms_debug2 ((4, \"DST_S_C_SRC_SETREC_W: %d\\n\", data));\n\t\t  break;\n\n\t\tcase DST__K_SRC_FORMFEED:\n\t\t  vms_debug2 ((4, \"DST_S_C_SRC_FORMFEED\\n\"));\n\t\t  break;\n\n\t\tdefault:\n\t\t  _bfd_error_handler (_(\"unknown source command %d\"),\n\t\t\t\t      cmd);\n\t\t  break;\n\t\t}\n\n\t      src_ptr += cmd_length;\n\t    }\n\t  break;\n\n\tcase DST__K_LINE_NUM:\n\t  pcl_ptr = ptr + DST_S_C_LINE_NUM_HEADER_SIZE;\n\n\t  vms_debug2 ((3, \"line info\\n\"));\n\n\t  while (pcl_ptr - ptr < rec_length)\n\t    {\n\t      /* The command byte is signed so we must sign-extend it.  */\n\t      int cmd = ((signed char *)pcl_ptr)[0], cmd_length, data;\n\n\t      switch (cmd)\n\t\t{\n\t\tcase DST__K_DELTA_PC_W:\n\t\t  cmd_length = 3;\n\t\t  break;\n\n\t\tcase DST__K_DELTA_PC_L:\n\t\t  cmd_length = 5;\n\t\t  break;\n\n\t\tcase DST__K_INCR_LINUM:\n\t\t  cmd_length = 2;\n\t\t  break;\n\n\t\tcase DST__K_INCR_LINUM_W:\n\t\t  cmd_length = 3;\n\t\t  break;\n\n\t\tcase DST__K_INCR_LINUM_L:\n\t\t  cmd_length = 5;\n\t\t  break;\n\n\t\tcase DST__K_SET_LINUM_INCR:\n\t\t  cmd_length = 2;\n\t\t  break;\n\n\t\tcase DST__K_SET_LINUM_INCR_W:\n\t\t  cmd_length = 3;\n\t\t  break;\n\n\t\tcase DST__K_RESET_LINUM_INCR:\n\t\t  cmd_length = 1;\n\t\t  break;\n\n\t\tcase DST__K_BEG_STMT_MODE:\n\t\t  cmd_length = 1;\n\t\t  break;\n\n\t\tcase DST__K_END_STMT_MODE:\n\t\t  cmd_length = 1;\n\t\t  break;\n\n\t\tcase DST__K_SET_LINUM_B:\n\t\t  cmd_length = 2;\n\t\t  break;\n\n\t\tcase DST__K_SET_LINUM:\n\t\t  cmd_length = 3;\n\t\t  break;\n\n\t\tcase DST__K_SET_LINUM_L:\n\t\t  cmd_length = 5;\n\t\t  break;\n\n\t\tcase DST__K_SET_PC:\n\t\t  cmd_length = 2;\n\t\t  break;\n\n\t\tcase DST__K_SET_PC_W:\n\t\t  cmd_length = 3;\n\t\t  break;\n\n\t\tcase DST__K_SET_PC_L:\n\t\t  cmd_length = 5;\n\t\t  break;\n\n\t\tcase DST__K_SET_STMTNUM:\n\t\t  cmd_length = 2;\n\t\t  break;\n\n\t\tcase DST__K_TERM:\n\t\t  cmd_length = 2;\n\t\t  break;\n\n\t\tcase DST__K_TERM_W:\n\t\t  cmd_length = 3;\n\t\t  break;\n\n\t\tcase DST__K_TERM_L:\n\t\t  cmd_length = 5;\n\t\t  break;\n\n\t\tcase DST__K_SET_ABS_PC:\n\t\t  cmd_length = 5;\n\t\t  break;\n\n\t\tdefault:\n\t\t  if (cmd <= 0)\n\t\t    cmd_length = 1;\n\t\t  else\n\t\t    cmd_length = 2;\n\t\t  break;\n\t\t}\n\n\t      if (pcl_ptr - ptr + cmd_length > rec_length)\n\t\tbreak;\n\n\t      switch (cmd)\n\t\t{\n\t\tcase DST__K_DELTA_PC_W:\n\t\t  data = bfd_getl16 (pcl_ptr + DST_S_W_PCLINE_UNSWORD);\n\t\t  curr_pc += data;\n\t\t  curr_linenum += 1;\n\t\t  vms_debug2 ((4, \"DST__K_DELTA_PC_W: %d\\n\", data));\n\t\t  break;\n\n\t\tcase DST__K_DELTA_PC_L:\n\t\t  data = bfd_getl32 (pcl_ptr + DST_S_L_PCLINE_UNSLONG);\n\t\t  curr_pc += data;\n\t\t  curr_linenum += 1;\n\t\t  vms_debug2 ((4, \"DST__K_DELTA_PC_L: %d\\n\", data));\n\t\t  break;\n\n\t\tcase DST__K_INCR_LINUM:\n\t\t  data = pcl_ptr[DST_S_B_PCLINE_UNSBYTE];\n\t\t  curr_linenum += data;\n\t\t  vms_debug2 ((4, \"DST__K_INCR_LINUM: %d\\n\", data));\n\t\t  break;\n\n\t\tcase DST__K_INCR_LINUM_W:\n\t\t  data = bfd_getl16 (pcl_ptr + DST_S_W_PCLINE_UNSWORD);\n\t\t  curr_linenum += data;\n\t\t  vms_debug2 ((4, \"DST__K_INCR_LINUM_W: %d\\n\", data));\n\t\t  break;\n\n\t\tcase DST__K_INCR_LINUM_L:\n\t\t  data = bfd_getl32 (pcl_ptr + DST_S_L_PCLINE_UNSLONG);\n\t\t  curr_linenum += data;\n\t\t  vms_debug2 ((4, \"DST__K_INCR_LINUM_L: %d\\n\", data));\n\t\t  break;\n\n\t\tcase DST__K_SET_LINUM_INCR:\n\t\t  _bfd_error_handler\n\t\t    (_(\"%s not implemented\"), \"DST__K_SET_LINUM_INCR\");\n\t\t  break;\n\n\t\tcase DST__K_SET_LINUM_INCR_W:\n\t\t  _bfd_error_handler\n\t\t    (_(\"%s not implemented\"), \"DST__K_SET_LINUM_INCR_W\");\n\t\t  break;\n\n\t\tcase DST__K_RESET_LINUM_INCR:\n\t\t  _bfd_error_handler\n\t\t    (_(\"%s not implemented\"), \"DST__K_RESET_LINUM_INCR\");\n\t\t  break;\n\n\t\tcase DST__K_BEG_STMT_MODE:\n\t\t  _bfd_error_handler\n\t\t    (_(\"%s not implemented\"), \"DST__K_BEG_STMT_MODE\");\n\t\t  break;\n\n\t\tcase DST__K_END_STMT_MODE:\n\t\t  _bfd_error_handler\n\t\t    (_(\"%s not implemented\"), \"DST__K_END_STMT_MODE\");\n\t\t  break;\n\n\t\tcase DST__K_SET_LINUM_B:\n\t\t  data = pcl_ptr[DST_S_B_PCLINE_UNSBYTE];\n\t\t  curr_linenum = data;\n\t\t  vms_debug2 ((4, \"DST__K_SET_LINUM_B: %d\\n\", data));\n\t\t  break;\n\n\t\tcase DST__K_SET_LINUM:\n\t\t  data = bfd_getl16 (pcl_ptr + DST_S_W_PCLINE_UNSWORD);\n\t\t  curr_linenum = data;\n\t\t  vms_debug2 ((4, \"DST__K_SET_LINE_NUM: %d\\n\", data));\n\t\t  break;\n\n\t\tcase DST__K_SET_LINUM_L:\n\t\t  data = bfd_getl32 (pcl_ptr + DST_S_L_PCLINE_UNSLONG);\n\t\t  curr_linenum = data;\n\t\t  vms_debug2 ((4, \"DST__K_SET_LINUM_L: %d\\n\", data));\n\t\t  break;\n\n\t\tcase DST__K_SET_PC:\n\t\t  _bfd_error_handler\n\t\t    (_(\"%s not implemented\"), \"DST__K_SET_PC\");\n\t\t  break;\n\n\t\tcase DST__K_SET_PC_W:\n\t\t  _bfd_error_handler\n\t\t    (_(\"%s not implemented\"), \"DST__K_SET_PC_W\");\n\t\t  break;\n\n\t\tcase DST__K_SET_PC_L:\n\t\t  _bfd_error_handler\n\t\t    (_(\"%s not implemented\"), \"DST__K_SET_PC_L\");\n\t\t  break;\n\n\t\tcase DST__K_SET_STMTNUM:\n\t\t  _bfd_error_handler\n\t\t    (_(\"%s not implemented\"), \"DST__K_SET_STMTNUM\");\n\t\t  break;\n\n\t\tcase DST__K_TERM:\n\t\t  data = pcl_ptr[DST_S_B_PCLINE_UNSBYTE];\n\t\t  curr_pc += data;\n\t\t  vms_debug2 ((4, \"DST__K_TERM: %d\\n\", data));\n\t\t  break;\n\n\t\tcase DST__K_TERM_W:\n\t\t  data = bfd_getl16 (pcl_ptr + DST_S_W_PCLINE_UNSWORD);\n\t\t  curr_pc += data;\n\t\t  vms_debug2 ((4, \"DST__K_TERM_W: %d\\n\", data));\n\t\t  break;\n\n\t\tcase DST__K_TERM_L:\n\t\t  data = bfd_getl32 (pcl_ptr + DST_S_L_PCLINE_UNSLONG);\n\t\t  curr_pc += data;\n\t\t  vms_debug2 ((4, \"DST__K_TERM_L: %d\\n\", data));\n\t\t  break;\n\n\t\tcase DST__K_SET_ABS_PC:\n\t\t  data = bfd_getl32 (pcl_ptr + DST_S_L_PCLINE_UNSLONG);\n\t\t  curr_pc = data;\n\t\t  vms_debug2 ((4, \"DST__K_SET_ABS_PC: 0x%x\\n\", data));\n\t\t  break;\n\n\t\tdefault:\n\t\t  if (cmd <= 0)\n\t\t    {\n\t\t      curr_pc -= cmd;\n\t\t      curr_linenum += 1;\n\t\t      vms_debug2 ((4, \"bump pc to 0x%lx and line to %d\\n\",\n\t\t\t\t   (unsigned long)curr_pc, curr_linenum));\n\t\t    }\n\t\t  else\n\t\t    _bfd_error_handler (_(\"unknown line command %d\"), cmd);\n\t\t  break;\n\t\t}\n\n\t      if ((curr_linenum != prev_linum && curr_pc != prev_pc)\n\t\t  || cmd <= 0\n\t\t  || cmd == DST__K_DELTA_PC_L\n\t\t  || cmd == DST__K_DELTA_PC_W)\n\t\t{\n\t\t  line = (struct lineinfo *)\n\t\t    bfd_zalloc (abfd, sizeof (struct lineinfo));\n\t\t  line->address = curr_pc;\n\t\t  line->line = curr_linenum;\n\n\t\t  curr_line->next = line;\n\t\t  curr_line = line;\n\n\t\t  prev_linum = curr_linenum;\n\t\t  prev_pc = curr_pc;\n\t\t  vms_debug2 ((4, \"-> correlate pc 0x%lx with line %d\\n\",\n\t\t\t       (unsigned long)curr_pc, curr_linenum));\n\t\t}\n\n\t      pcl_ptr += cmd_length;\n\t    }\n\t  break;\n\n\tcase 0x17: /* Undocumented type used by DEC C to declare equates.  */\n\t  vms_debug2 ((3, \"undocumented type 0x17\\n\"));\n\t  break;\n\n\tdefault:\n\t  vms_debug2 ((3, \"ignoring record\\n\"));\n\t  break;\n\n\t}\n\n      ptr += rec_length;\n    }\n\n  /* Finalize tables with EOL marker.  */\n  srec = (struct srecinfo *) bfd_zalloc (abfd, sizeof (struct srecinfo));\n  srec->line = (unsigned int) -1;\n  srec->srec = (unsigned int) -1;\n  curr_srec->next = srec;\n\n  line = (struct lineinfo *) bfd_zalloc (abfd, sizeof (struct lineinfo));\n  line->line = (unsigned int) -1;\n  line->address = (bfd_vma) -1;\n  curr_line->next = line;\n\n  /* Advertise that this module has been parsed.  This is needed\n     because parsing can be either performed at module creation\n     or deferred until debug info is consumed.  */\n  SET_MODULE_PARSED (module);\n  return true;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -175,15 +175,18 @@\n \t\t       src_ptr + DST_S_B_SRC_DF_FILENAME,\n \t\t       ptr + rec_length - (src_ptr + DST_S_B_SRC_DF_FILENAME));\n \n-\t\t    while (fileid >= module->file_table_count)\n+\t\t    if (fileid >= module->file_table_count)\n \t\t      {\n-\t\t\tmodule->file_table_count *= 2;\n+\t\t\tunsigned int old_count = module->file_table_count;\n+\t\t\tmodule->file_table_count += fileid;\n \t\t\tmodule->file_table\n \t\t\t  = bfd_realloc_or_free (module->file_table,\n \t\t\t\t\t\t module->file_table_count\n \t\t\t\t\t\t * sizeof (struct fileinfo));\n \t\t\tif (module->file_table == NULL)\n \t\t\t  return false;\n+\t\t\tmemset (module->file_table + old_count, 0,\n+\t\t\t\tfileid * sizeof (struct fileinfo));\n \t\t      }\n \n \t\t    module->file_table [fileid].name = filename;",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t    while (fileid >= module->file_table_count)",
                "\t\t\tmodule->file_table_count *= 2;"
            ],
            "added_lines": [
                "\t\t    if (fileid >= module->file_table_count)",
                "\t\t\tunsigned int old_count = module->file_table_count;",
                "\t\t\tmodule->file_table_count += fileid;",
                "\t\t\tmemset (module->file_table + old_count, 0,",
                "\t\t\t\tfileid * sizeof (struct fileinfo));"
            ]
        }
    },
    {
        "cve_id": "CVE-2023-25586",
        "func_name": "binutils-gdb/bfd_init_section_decompress_status",
        "description": "A flaw was found in Binutils. A logic fail in the bfd_init_section_decompress_status function may lead to the use of an uninitialized variable that can cause a crash and local denial of service.",
        "git_url": "https://sourceware.org/git/gitweb.cgi?p=binutils-gdb.git;h=5830876a0cca17bef3b2d54908928e72cca53502",
        "commit_title": "",
        "commit_text": "PR29855, ch_type in bfd_init_section_decompress_status can be uninitialized  \tPR 29855 \t* compress.c (bfd_init_section_decompress_status): Set ch_type \tto zero for zlib-gnu case. ",
        "func_before": "bool\nbfd_init_section_decompress_status (bfd *abfd, sec_ptr sec)\n{\n  bfd_byte header[MAX_COMPRESSION_HEADER_SIZE];\n  int compression_header_size;\n  int header_size;\n  bfd_size_type uncompressed_size;\n  unsigned int uncompressed_alignment_power = 0;\n  unsigned int ch_type;\n  z_stream strm;\n\n  compression_header_size = bfd_get_compression_header_size (abfd, sec);\n  if (compression_header_size > MAX_COMPRESSION_HEADER_SIZE)\n    abort ();\n  header_size = compression_header_size ? compression_header_size : 12;\n\n  /* Read the header.  */\n  if (sec->rawsize != 0\n      || sec->contents != NULL\n      || sec->compress_status != COMPRESS_SECTION_NONE\n      || !bfd_get_section_contents (abfd, sec, header, 0, header_size))\n    {\n      bfd_set_error (bfd_error_invalid_operation);\n      return false;\n    }\n\n  if (compression_header_size == 0)\n    {\n      /* In this case, it should be \"ZLIB\" followed by the uncompressed\n\t section size, 8 bytes in big-endian order.  */\n      if (! startswith ((char*) header, \"ZLIB\"))\n\t{\n\t  bfd_set_error (bfd_error_wrong_format);\n\t  return false;\n\t}\n      uncompressed_size = bfd_getb64 (header + 4);\n    }\n  else if (!bfd_check_compression_header (abfd, header, sec,\n\t\t\t\t\t  &ch_type,\n\t\t\t\t\t  &uncompressed_size,\n\t\t\t\t\t  &uncompressed_alignment_power))\n    {\n      bfd_set_error (bfd_error_wrong_format);\n      return false;\n    }\n\n  /* PR28530, reject sizes unsupported by decompress_contents.  */\n  strm.avail_in = sec->size;\n  strm.avail_out = uncompressed_size;\n  if (strm.avail_in != sec->size || strm.avail_out != uncompressed_size)\n    {\n      bfd_set_error (bfd_error_nonrepresentable_section);\n      return false;\n    }\n\n  sec->compressed_size = sec->size;\n  sec->size = uncompressed_size;\n  bfd_set_section_alignment (sec, uncompressed_alignment_power);\n  sec->compress_status = (ch_type == ELFCOMPRESS_ZSTD\n\t\t\t  ? DECOMPRESS_SECTION_ZSTD : DECOMPRESS_SECTION_ZLIB);\n\n  return true;\n}",
        "func": "bool\nbfd_init_section_decompress_status (bfd *abfd, sec_ptr sec)\n{\n  bfd_byte header[MAX_COMPRESSION_HEADER_SIZE];\n  int compression_header_size;\n  int header_size;\n  bfd_size_type uncompressed_size;\n  unsigned int uncompressed_alignment_power = 0;\n  unsigned int ch_type;\n  z_stream strm;\n\n  compression_header_size = bfd_get_compression_header_size (abfd, sec);\n  if (compression_header_size > MAX_COMPRESSION_HEADER_SIZE)\n    abort ();\n  header_size = compression_header_size ? compression_header_size : 12;\n\n  /* Read the header.  */\n  if (sec->rawsize != 0\n      || sec->contents != NULL\n      || sec->compress_status != COMPRESS_SECTION_NONE\n      || !bfd_get_section_contents (abfd, sec, header, 0, header_size))\n    {\n      bfd_set_error (bfd_error_invalid_operation);\n      return false;\n    }\n\n  if (compression_header_size == 0)\n    {\n      /* In this case, it should be \"ZLIB\" followed by the uncompressed\n\t section size, 8 bytes in big-endian order.  */\n      if (! startswith ((char*) header, \"ZLIB\"))\n\t{\n\t  bfd_set_error (bfd_error_wrong_format);\n\t  return false;\n\t}\n      uncompressed_size = bfd_getb64 (header + 4);\n      ch_type = 0;\n    }\n  else if (!bfd_check_compression_header (abfd, header, sec,\n\t\t\t\t\t  &ch_type,\n\t\t\t\t\t  &uncompressed_size,\n\t\t\t\t\t  &uncompressed_alignment_power))\n    {\n      bfd_set_error (bfd_error_wrong_format);\n      return false;\n    }\n\n  /* PR28530, reject sizes unsupported by decompress_contents.  */\n  strm.avail_in = sec->size;\n  strm.avail_out = uncompressed_size;\n  if (strm.avail_in != sec->size || strm.avail_out != uncompressed_size)\n    {\n      bfd_set_error (bfd_error_nonrepresentable_section);\n      return false;\n    }\n\n  sec->compressed_size = sec->size;\n  sec->size = uncompressed_size;\n  bfd_set_section_alignment (sec, uncompressed_alignment_power);\n  sec->compress_status = (ch_type == ELFCOMPRESS_ZSTD\n\t\t\t  ? DECOMPRESS_SECTION_ZSTD : DECOMPRESS_SECTION_ZLIB);\n\n  return true;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -34,6 +34,7 @@\n \t  return false;\n \t}\n       uncompressed_size = bfd_getb64 (header + 4);\n+      ch_type = 0;\n     }\n   else if (!bfd_check_compression_header (abfd, header, sec,\n \t\t\t\t\t  &ch_type,",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "      ch_type = 0;"
            ]
        }
    },
    {
        "cve_id": "CVE-2023-25588",
        "func_name": "binutils-gdb/bfd_mach_o_get_synthetic_symtab",
        "description": "A flaw was found in Binutils. The field `the_bfd` of `asymbol`struct is uninitialized in the `bfd_mach_o_get_synthetic_symtab` function, which may lead to an application crash and local denial of service.",
        "git_url": "https://sourceware.org/git/gitweb.cgi?p=binutils-gdb.git;h=d12f8998d2d086f0a6606589e5aedb7147e6f2f1",
        "commit_title": "",
        "commit_text": "PR29677, Field `the_bfd` of `asymbol` is uninitialised  Besides not initialising the_bfd of synthetic symbols, counting symbols when sizing didn't match symbols created if there were any dynsyms named \"\".  We don't want synthetic symbols without names anyway, so get rid of them.  Also, simplify and correct sanity checks.  \tPR 29677 \t* mach-o.c (bfd_mach_o_get_synthetic_symtab): Rewrite. ",
        "func_before": "long\nbfd_mach_o_get_synthetic_symtab (bfd *abfd,\n\t\t\t\t long symcount ATTRIBUTE_UNUSED,\n\t\t\t\t asymbol **syms ATTRIBUTE_UNUSED,\n\t\t\t\t long dynsymcount ATTRIBUTE_UNUSED,\n\t\t\t\t asymbol **dynsyms ATTRIBUTE_UNUSED,\n\t\t\t\t asymbol **ret)\n{\n  bfd_mach_o_data_struct *mdata = bfd_mach_o_get_data (abfd);\n  bfd_mach_o_dysymtab_command *dysymtab = mdata->dysymtab;\n  bfd_mach_o_symtab_command *symtab = mdata->symtab;\n  asymbol *s;\n  char * s_start;\n  char * s_end;\n  unsigned long count, i, j, n;\n  size_t size;\n  char *names;\n  char *nul_name;\n  const char stub [] = \"$stub\";\n\n  *ret = NULL;\n\n  /* Stop now if no symbols or no indirect symbols.  */\n  if (dysymtab == NULL || dysymtab->nindirectsyms == 0\n      || symtab == NULL || symtab->symbols == NULL)\n    return 0;\n\n  /* We need to allocate a bfd symbol for every indirect symbol and to\n     allocate the memory for its name.  */\n  count = dysymtab->nindirectsyms;\n  size = count * sizeof (asymbol) + 1;\n\n  for (j = 0; j < count; j++)\n    {\n      const char * strng;\n      unsigned int isym = dysymtab->indirect_syms[j];\n\n      /* Some indirect symbols are anonymous.  */\n      if (isym < symtab->nsyms && (strng = symtab->symbols[isym].symbol.name))\n\t/* PR 17512: file: f5b8eeba.  */\n\tsize += strnlen (strng, symtab->strsize - (strng - symtab->strtab)) + sizeof (stub);\n    }\n\n  s_start = bfd_malloc (size);\n  s = *ret = (asymbol *) s_start;\n  if (s == NULL)\n    return -1;\n  names = (char *) (s + count);\n  nul_name = names;\n  *names++ = 0;\n  s_end = s_start + size;\n\n  n = 0;\n  for (i = 0; i < mdata->nsects; i++)\n    {\n      bfd_mach_o_section *sec = mdata->sections[i];\n      unsigned int first, last;\n      bfd_vma addr;\n      unsigned int entry_size;\n\n      switch (sec->flags & BFD_MACH_O_SECTION_TYPE_MASK)\n\t{\n\tcase BFD_MACH_O_S_NON_LAZY_SYMBOL_POINTERS:\n\tcase BFD_MACH_O_S_LAZY_SYMBOL_POINTERS:\n\tcase BFD_MACH_O_S_SYMBOL_STUBS:\n\t  /* Only these sections have indirect symbols.  */\n\t  first = sec->reserved1;\n\t  last = first + bfd_mach_o_section_get_nbr_indirect (abfd, sec);\n\t  addr = sec->addr;\n\t  entry_size = bfd_mach_o_section_get_entry_size (abfd, sec);\n\n\t  /* PR 17512: file: 08e15eec.  */\n\t  if (first >= count || last >= count || first > last)\n\t    goto fail;\n\n\t  for (j = first; j < last; j++)\n\t    {\n\t      unsigned int isym = dysymtab->indirect_syms[j];\n\n\t      /* PR 17512: file: 04d64d9b.  */\n\t      if (((char *) s) + sizeof (* s) > s_end)\n\t\tgoto fail;\n\n\t      s->flags = BSF_GLOBAL | BSF_SYNTHETIC;\n\t      s->section = sec->bfdsection;\n\t      s->value = addr - sec->addr;\n\t      s->udata.p = NULL;\n\n\t      if (isym < symtab->nsyms\n\t\t  && symtab->symbols[isym].symbol.name)\n\t\t{\n\t\t  const char *sym = symtab->symbols[isym].symbol.name;\n\t\t  size_t len;\n\n\t\t  s->name = names;\n\t\t  len = strlen (sym);\n\t\t  /* PR 17512: file: 47dfd4d2.  */\n\t\t  if (names + len >= s_end)\n\t\t    goto fail;\n\t\t  memcpy (names, sym, len);\n\t\t  names += len;\n\t\t  /* PR 17512: file: 18f340a4.  */\n\t\t  if (names + sizeof (stub) >= s_end)\n\t\t    goto fail;\n\t\t  memcpy (names, stub, sizeof (stub));\n\t\t  names += sizeof (stub);\n\t\t}\n\t      else\n\t\ts->name = nul_name;\n\n\t      addr += entry_size;\n\t      s++;\n\t      n++;\n\t    }\n\t  break;\n\tdefault:\n\t  break;\n\t}\n    }\n\n  return n;\n\n fail:\n  free (s_start);\n  * ret = NULL;\n  return -1;\n}",
        "func": "long\nbfd_mach_o_get_synthetic_symtab (bfd *abfd,\n\t\t\t\t long symcount ATTRIBUTE_UNUSED,\n\t\t\t\t asymbol **syms ATTRIBUTE_UNUSED,\n\t\t\t\t long dynsymcount ATTRIBUTE_UNUSED,\n\t\t\t\t asymbol **dynsyms ATTRIBUTE_UNUSED,\n\t\t\t\t asymbol **ret)\n{\n  bfd_mach_o_data_struct *mdata = bfd_mach_o_get_data (abfd);\n  bfd_mach_o_dysymtab_command *dysymtab = mdata->dysymtab;\n  bfd_mach_o_symtab_command *symtab = mdata->symtab;\n  asymbol *s;\n  char * s_start;\n  unsigned long count, i, j, n;\n  size_t size;\n  char *names;\n  const char stub [] = \"$stub\";\n\n  *ret = NULL;\n\n  /* Stop now if no symbols or no indirect symbols.  */\n  if (dysymtab == NULL || dysymtab->nindirectsyms == 0\n      || symtab == NULL || symtab->symbols == NULL)\n    return 0;\n\n  /* We need to allocate a bfd symbol for every indirect symbol and to\n     allocate the memory for its name.  */\n  count = dysymtab->nindirectsyms;\n  size = 0;\n  for (j = 0; j < count; j++)\n    {\n      unsigned int isym = dysymtab->indirect_syms[j];\n      const char *str;\n\n      /* Some indirect symbols are anonymous.  */\n      if (isym < symtab->nsyms\n\t  && (str = symtab->symbols[isym].symbol.name) != NULL)\n\t{\n\t  /* PR 17512: file: f5b8eeba.  */\n\t  size += strnlen (str, symtab->strsize - (str - symtab->strtab));\n\t  size += sizeof (stub);\n\t}\n    }\n\n  s_start = bfd_malloc (size + count * sizeof (asymbol));\n  s = *ret = (asymbol *) s_start;\n  if (s == NULL)\n    return -1;\n  names = (char *) (s + count);\n\n  n = 0;\n  for (i = 0; i < mdata->nsects; i++)\n    {\n      bfd_mach_o_section *sec = mdata->sections[i];\n      unsigned int first, last;\n      bfd_vma addr;\n      unsigned int entry_size;\n\n      switch (sec->flags & BFD_MACH_O_SECTION_TYPE_MASK)\n\t{\n\tcase BFD_MACH_O_S_NON_LAZY_SYMBOL_POINTERS:\n\tcase BFD_MACH_O_S_LAZY_SYMBOL_POINTERS:\n\tcase BFD_MACH_O_S_SYMBOL_STUBS:\n\t  /* Only these sections have indirect symbols.  */\n\t  first = sec->reserved1;\n\t  last = first + bfd_mach_o_section_get_nbr_indirect (abfd, sec);\n\t  addr = sec->addr;\n\t  entry_size = bfd_mach_o_section_get_entry_size (abfd, sec);\n\n\t  /* PR 17512: file: 08e15eec.  */\n\t  if (first >= count || last > count || first > last)\n\t    goto fail;\n\n\t  for (j = first; j < last; j++)\n\t    {\n\t      unsigned int isym = dysymtab->indirect_syms[j];\n\t      const char *str;\n\t      size_t len;\n\n\t      if (isym < symtab->nsyms\n\t\t  && (str = symtab->symbols[isym].symbol.name) != NULL)\n\t\t{\n\t\t  /* PR 17512: file: 04d64d9b.  */\n\t\t  if (n >= count)\n\t\t    goto fail;\n\t\t  len = strnlen (str, symtab->strsize - (str - symtab->strtab));\n\t\t  /* PR 17512: file: 47dfd4d2, 18f340a4.  */\n\t\t  if (size < len + sizeof (stub))\n\t\t    goto fail;\n\t\t  memcpy (names, str, len);\n\t\t  memcpy (names + len, stub, sizeof (stub));\n\t\t  s->name = names;\n\t\t  names += len + sizeof (stub);\n\t\t  size -= len + sizeof (stub);\n\t\t  s->the_bfd = symtab->symbols[isym].symbol.the_bfd;\n\t\t  s->flags = BSF_GLOBAL | BSF_SYNTHETIC;\n\t\t  s->section = sec->bfdsection;\n\t\t  s->value = addr - sec->addr;\n\t\t  s->udata.p = NULL;\n\t\t  s++;\n\t\t  n++;\n\t\t}\n\t      addr += entry_size;\n\t    }\n\t  break;\n\tdefault:\n\t  break;\n\t}\n    }\n\n  return n;\n\n fail:\n  free (s_start);\n  * ret = NULL;\n  return -1;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -11,11 +11,9 @@\n   bfd_mach_o_symtab_command *symtab = mdata->symtab;\n   asymbol *s;\n   char * s_start;\n-  char * s_end;\n   unsigned long count, i, j, n;\n   size_t size;\n   char *names;\n-  char *nul_name;\n   const char stub [] = \"$stub\";\n \n   *ret = NULL;\n@@ -28,27 +26,27 @@\n   /* We need to allocate a bfd symbol for every indirect symbol and to\n      allocate the memory for its name.  */\n   count = dysymtab->nindirectsyms;\n-  size = count * sizeof (asymbol) + 1;\n-\n+  size = 0;\n   for (j = 0; j < count; j++)\n     {\n-      const char * strng;\n       unsigned int isym = dysymtab->indirect_syms[j];\n+      const char *str;\n \n       /* Some indirect symbols are anonymous.  */\n-      if (isym < symtab->nsyms && (strng = symtab->symbols[isym].symbol.name))\n-\t/* PR 17512: file: f5b8eeba.  */\n-\tsize += strnlen (strng, symtab->strsize - (strng - symtab->strtab)) + sizeof (stub);\n+      if (isym < symtab->nsyms\n+\t  && (str = symtab->symbols[isym].symbol.name) != NULL)\n+\t{\n+\t  /* PR 17512: file: f5b8eeba.  */\n+\t  size += strnlen (str, symtab->strsize - (str - symtab->strtab));\n+\t  size += sizeof (stub);\n+\t}\n     }\n \n-  s_start = bfd_malloc (size);\n+  s_start = bfd_malloc (size + count * sizeof (asymbol));\n   s = *ret = (asymbol *) s_start;\n   if (s == NULL)\n     return -1;\n   names = (char *) (s + count);\n-  nul_name = names;\n-  *names++ = 0;\n-  s_end = s_start + size;\n \n   n = 0;\n   for (i = 0; i < mdata->nsects; i++)\n@@ -70,47 +68,39 @@\n \t  entry_size = bfd_mach_o_section_get_entry_size (abfd, sec);\n \n \t  /* PR 17512: file: 08e15eec.  */\n-\t  if (first >= count || last >= count || first > last)\n+\t  if (first >= count || last > count || first > last)\n \t    goto fail;\n \n \t  for (j = first; j < last; j++)\n \t    {\n \t      unsigned int isym = dysymtab->indirect_syms[j];\n-\n-\t      /* PR 17512: file: 04d64d9b.  */\n-\t      if (((char *) s) + sizeof (* s) > s_end)\n-\t\tgoto fail;\n-\n-\t      s->flags = BSF_GLOBAL | BSF_SYNTHETIC;\n-\t      s->section = sec->bfdsection;\n-\t      s->value = addr - sec->addr;\n-\t      s->udata.p = NULL;\n+\t      const char *str;\n+\t      size_t len;\n \n \t      if (isym < symtab->nsyms\n-\t\t  && symtab->symbols[isym].symbol.name)\n+\t\t  && (str = symtab->symbols[isym].symbol.name) != NULL)\n \t\t{\n-\t\t  const char *sym = symtab->symbols[isym].symbol.name;\n-\t\t  size_t len;\n-\n+\t\t  /* PR 17512: file: 04d64d9b.  */\n+\t\t  if (n >= count)\n+\t\t    goto fail;\n+\t\t  len = strnlen (str, symtab->strsize - (str - symtab->strtab));\n+\t\t  /* PR 17512: file: 47dfd4d2, 18f340a4.  */\n+\t\t  if (size < len + sizeof (stub))\n+\t\t    goto fail;\n+\t\t  memcpy (names, str, len);\n+\t\t  memcpy (names + len, stub, sizeof (stub));\n \t\t  s->name = names;\n-\t\t  len = strlen (sym);\n-\t\t  /* PR 17512: file: 47dfd4d2.  */\n-\t\t  if (names + len >= s_end)\n-\t\t    goto fail;\n-\t\t  memcpy (names, sym, len);\n-\t\t  names += len;\n-\t\t  /* PR 17512: file: 18f340a4.  */\n-\t\t  if (names + sizeof (stub) >= s_end)\n-\t\t    goto fail;\n-\t\t  memcpy (names, stub, sizeof (stub));\n-\t\t  names += sizeof (stub);\n+\t\t  names += len + sizeof (stub);\n+\t\t  size -= len + sizeof (stub);\n+\t\t  s->the_bfd = symtab->symbols[isym].symbol.the_bfd;\n+\t\t  s->flags = BSF_GLOBAL | BSF_SYNTHETIC;\n+\t\t  s->section = sec->bfdsection;\n+\t\t  s->value = addr - sec->addr;\n+\t\t  s->udata.p = NULL;\n+\t\t  s++;\n+\t\t  n++;\n \t\t}\n-\t      else\n-\t\ts->name = nul_name;\n-\n \t      addr += entry_size;\n-\t      s++;\n-\t      n++;\n \t    }\n \t  break;\n \tdefault:",
        "diff_line_info": {
            "deleted_lines": [
                "  char * s_end;",
                "  char *nul_name;",
                "  size = count * sizeof (asymbol) + 1;",
                "",
                "      const char * strng;",
                "      if (isym < symtab->nsyms && (strng = symtab->symbols[isym].symbol.name))",
                "\t/* PR 17512: file: f5b8eeba.  */",
                "\tsize += strnlen (strng, symtab->strsize - (strng - symtab->strtab)) + sizeof (stub);",
                "  s_start = bfd_malloc (size);",
                "  nul_name = names;",
                "  *names++ = 0;",
                "  s_end = s_start + size;",
                "\t  if (first >= count || last >= count || first > last)",
                "",
                "\t      /* PR 17512: file: 04d64d9b.  */",
                "\t      if (((char *) s) + sizeof (* s) > s_end)",
                "\t\tgoto fail;",
                "",
                "\t      s->flags = BSF_GLOBAL | BSF_SYNTHETIC;",
                "\t      s->section = sec->bfdsection;",
                "\t      s->value = addr - sec->addr;",
                "\t      s->udata.p = NULL;",
                "\t\t  && symtab->symbols[isym].symbol.name)",
                "\t\t  const char *sym = symtab->symbols[isym].symbol.name;",
                "\t\t  size_t len;",
                "",
                "\t\t  len = strlen (sym);",
                "\t\t  /* PR 17512: file: 47dfd4d2.  */",
                "\t\t  if (names + len >= s_end)",
                "\t\t    goto fail;",
                "\t\t  memcpy (names, sym, len);",
                "\t\t  names += len;",
                "\t\t  /* PR 17512: file: 18f340a4.  */",
                "\t\t  if (names + sizeof (stub) >= s_end)",
                "\t\t    goto fail;",
                "\t\t  memcpy (names, stub, sizeof (stub));",
                "\t\t  names += sizeof (stub);",
                "\t      else",
                "\t\ts->name = nul_name;",
                "",
                "\t      s++;",
                "\t      n++;"
            ],
            "added_lines": [
                "  size = 0;",
                "      const char *str;",
                "      if (isym < symtab->nsyms",
                "\t  && (str = symtab->symbols[isym].symbol.name) != NULL)",
                "\t{",
                "\t  /* PR 17512: file: f5b8eeba.  */",
                "\t  size += strnlen (str, symtab->strsize - (str - symtab->strtab));",
                "\t  size += sizeof (stub);",
                "\t}",
                "  s_start = bfd_malloc (size + count * sizeof (asymbol));",
                "\t  if (first >= count || last > count || first > last)",
                "\t      const char *str;",
                "\t      size_t len;",
                "\t\t  && (str = symtab->symbols[isym].symbol.name) != NULL)",
                "\t\t  /* PR 17512: file: 04d64d9b.  */",
                "\t\t  if (n >= count)",
                "\t\t    goto fail;",
                "\t\t  len = strnlen (str, symtab->strsize - (str - symtab->strtab));",
                "\t\t  /* PR 17512: file: 47dfd4d2, 18f340a4.  */",
                "\t\t  if (size < len + sizeof (stub))",
                "\t\t    goto fail;",
                "\t\t  memcpy (names, str, len);",
                "\t\t  memcpy (names + len, stub, sizeof (stub));",
                "\t\t  names += len + sizeof (stub);",
                "\t\t  size -= len + sizeof (stub);",
                "\t\t  s->the_bfd = symtab->symbols[isym].symbol.the_bfd;",
                "\t\t  s->flags = BSF_GLOBAL | BSF_SYNTHETIC;",
                "\t\t  s->section = sec->bfdsection;",
                "\t\t  s->value = addr - sec->addr;",
                "\t\t  s->udata.p = NULL;",
                "\t\t  s++;",
                "\t\t  n++;"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-30027",
        "func_name": "mity/md4c/md_analyze_line",
        "description": "md_analyze_line in md4c.c in md4c 0.4.7 allows attackers to trigger use of uninitialized memory, and cause a denial of service via a malformed Markdown document.",
        "git_url": "https://github.com/mity/md4c/commit/4fc808d8fe8d8904f8525bb4231d854f45e23a19",
        "commit_title": "md_analyze_line: Avoid reading 1 byte beyond the input size.",
        "commit_text": " Fixes #155.",
        "func_before": "static int\nmd_analyze_line(MD_CTX* ctx, OFF beg, OFF* p_end,\n                const MD_LINE_ANALYSIS* pivot_line, MD_LINE_ANALYSIS* line)\n{\n    unsigned total_indent = 0;\n    int n_parents = 0;\n    int n_brothers = 0;\n    int n_children = 0;\n    MD_CONTAINER container = { 0 };\n    int prev_line_has_list_loosening_effect = ctx->last_line_has_list_loosening_effect;\n    OFF off = beg;\n    OFF hr_killer = 0;\n    int ret = 0;\n\n    line->indent = md_line_indentation(ctx, total_indent, off, &off);\n    total_indent += line->indent;\n    line->beg = off;\n\n    /* Given the indentation and block quote marks '>', determine how many of\n     * the current containers are our parents. */\n    while(n_parents < ctx->n_containers) {\n        MD_CONTAINER* c = &ctx->containers[n_parents];\n\n        if(c->ch == _T('>')  &&  line->indent < ctx->code_indent_offset  &&\n            off < ctx->size  &&  CH(off) == _T('>'))\n        {\n            /* Block quote mark. */\n            off++;\n            total_indent++;\n            line->indent = md_line_indentation(ctx, total_indent, off, &off);\n            total_indent += line->indent;\n\n            /* The optional 1st space after '>' is part of the block quote mark. */\n            if(line->indent > 0)\n                line->indent--;\n\n            line->beg = off;\n\n        } else if(c->ch != _T('>')  &&  line->indent >= c->contents_indent) {\n            /* List. */\n            line->indent -= c->contents_indent;\n        } else {\n            break;\n        }\n\n        n_parents++;\n    }\n\n    if(off >= ctx->size  ||  ISNEWLINE(off)) {\n        /* Blank line does not need any real indentation to be nested inside\n         * a list. */\n        if(n_brothers + n_children == 0) {\n            while(n_parents < ctx->n_containers  &&  ctx->containers[n_parents].ch != _T('>'))\n                n_parents++;\n        }\n    }\n\n    while(TRUE) {\n        /* Check whether we are fenced code continuation. */\n        if(pivot_line->type == MD_LINE_FENCEDCODE) {\n            line->beg = off;\n\n            /* We are another MD_LINE_FENCEDCODE unless we are closing fence\n             * which we transform into MD_LINE_BLANK. */\n            if(line->indent < ctx->code_indent_offset) {\n                if(md_is_closing_code_fence(ctx, CH(pivot_line->beg), off, &off)) {\n                    line->type = MD_LINE_BLANK;\n                    ctx->last_line_has_list_loosening_effect = FALSE;\n                    break;\n                }\n            }\n\n            /* Change indentation accordingly to the initial code fence. */\n            if(n_parents == ctx->n_containers) {\n                if(line->indent > pivot_line->indent)\n                    line->indent -= pivot_line->indent;\n                else\n                    line->indent = 0;\n\n                line->type = MD_LINE_FENCEDCODE;\n                break;\n            }\n        }\n\n        /* Check whether we are HTML block continuation. */\n        if(pivot_line->type == MD_LINE_HTML  &&  ctx->html_block_type > 0) {\n            if(n_parents < ctx->n_containers) {\n                /* HTML block is implicitly ended if the enclosing container\n                 * block ends. */\n                ctx->html_block_type = 0;\n            } else {\n                int html_block_type;\n\n                html_block_type = md_is_html_block_end_condition(ctx, off, &off);\n                if(html_block_type > 0) {\n                    MD_ASSERT(html_block_type == ctx->html_block_type);\n\n                    /* Make sure this is the last line of the block. */\n                    ctx->html_block_type = 0;\n\n                    /* Some end conditions serve as blank lines at the same time. */\n                    if(html_block_type == 6 || html_block_type == 7) {\n                        line->type = MD_LINE_BLANK;\n                        line->indent = 0;\n                        break;\n                    }\n                }\n\n                line->type = MD_LINE_HTML;\n                n_parents = ctx->n_containers;\n                break;\n            }\n        }\n\n        /* Check for blank line. */\n        if(off >= ctx->size  ||  ISNEWLINE(off)) {\n            if(pivot_line->type == MD_LINE_INDENTEDCODE  &&  n_parents == ctx->n_containers) {\n                line->type = MD_LINE_INDENTEDCODE;\n                if(line->indent > ctx->code_indent_offset)\n                    line->indent -= ctx->code_indent_offset;\n                else\n                    line->indent = 0;\n                ctx->last_line_has_list_loosening_effect = FALSE;\n            } else {\n                line->type = MD_LINE_BLANK;\n                ctx->last_line_has_list_loosening_effect = (n_parents > 0  &&\n                        n_brothers + n_children == 0  &&\n                        ctx->containers[n_parents-1].ch != _T('>'));\n\n    #if 1\n                /* See https://github.com/mity/md4c/issues/6\n                 *\n                 * This ugly checking tests we are in (yet empty) list item but\n                 * not its very first line (i.e. not the line with the list\n                 * item mark).\n                 *\n                 * If we are such a blank line, then any following non-blank\n                 * line which would be part of the list item actually has to\n                 * end the list because according to the specification, \"a list\n                 * item can begin with at most one blank line.\"\n                 */\n                if(n_parents > 0  &&  ctx->containers[n_parents-1].ch != _T('>')  &&\n                   n_brothers + n_children == 0  &&  ctx->current_block == NULL  &&\n                   ctx->n_block_bytes > (int) sizeof(MD_BLOCK))\n                {\n                    MD_BLOCK* top_block = (MD_BLOCK*) ((char*)ctx->block_bytes + ctx->n_block_bytes - sizeof(MD_BLOCK));\n                    if(top_block->type == MD_BLOCK_LI)\n                        ctx->last_list_item_starts_with_two_blank_lines = TRUE;\n                }\n    #endif\n            }\n            break;\n        } else {\n    #if 1\n            /* This is the 2nd half of the hack. If the flag is set (i.e. there\n             * was a 2nd blank line at the beginning of the list item) and if\n             * we would otherwise still belong to the list item, we enforce\n             * the end of the list. */\n            ctx->last_line_has_list_loosening_effect = FALSE;\n            if(ctx->last_list_item_starts_with_two_blank_lines) {\n                if(n_parents > 0  &&  ctx->containers[n_parents-1].ch != _T('>')  &&\n                   n_brothers + n_children == 0  &&  ctx->current_block == NULL  &&\n                   ctx->n_block_bytes > (int) sizeof(MD_BLOCK))\n                {\n                    MD_BLOCK* top_block = (MD_BLOCK*) ((char*)ctx->block_bytes + ctx->n_block_bytes - sizeof(MD_BLOCK));\n                    if(top_block->type == MD_BLOCK_LI)\n                        n_parents--;\n                }\n\n                ctx->last_list_item_starts_with_two_blank_lines = FALSE;\n            }\n    #endif\n        }\n\n        /* Check whether we are Setext underline. */\n        if(line->indent < ctx->code_indent_offset  &&  pivot_line->type == MD_LINE_TEXT\n            &&  (CH(off) == _T('=') || CH(off) == _T('-'))\n            &&  (n_parents == ctx->n_containers))\n        {\n            unsigned level;\n\n            if(md_is_setext_underline(ctx, off, &off, &level)) {\n                line->type = MD_LINE_SETEXTUNDERLINE;\n                line->data = level;\n                break;\n            }\n        }\n\n        /* Check for thematic break line. */\n        if(line->indent < ctx->code_indent_offset  &&  ISANYOF(off, _T(\"-_*\"))  &&  off >= hr_killer) {\n            if(md_is_hr_line(ctx, off, &off, &hr_killer)) {\n                line->type = MD_LINE_HR;\n                break;\n            }\n        }\n\n        /* Check for \"brother\" container. I.e. whether we are another list item\n         * in already started list. */\n        if(n_parents < ctx->n_containers  &&  n_brothers + n_children == 0) {\n            OFF tmp;\n\n            if(md_is_container_mark(ctx, line->indent, off, &tmp, &container)  &&\n               md_is_container_compatible(&ctx->containers[n_parents], &container))\n            {\n                pivot_line = &md_dummy_blank_line;\n\n                off = tmp;\n\n                total_indent += container.contents_indent - container.mark_indent;\n                line->indent = md_line_indentation(ctx, total_indent, off, &off);\n                total_indent += line->indent;\n                line->beg = off;\n\n                /* Some of the following whitespace actually still belongs to the mark. */\n                if(off >= ctx->size || ISNEWLINE(off)) {\n                    container.contents_indent++;\n                } else if(line->indent <= ctx->code_indent_offset) {\n                    container.contents_indent += line->indent;\n                    line->indent = 0;\n                } else {\n                    container.contents_indent += 1;\n                    line->indent--;\n                }\n\n                ctx->containers[n_parents].mark_indent = container.mark_indent;\n                ctx->containers[n_parents].contents_indent = container.contents_indent;\n\n                n_brothers++;\n                continue;\n            }\n        }\n\n        /* Check for indented code.\n         * Note indented code block cannot interrupt a paragraph. */\n        if(line->indent >= ctx->code_indent_offset  &&\n            (pivot_line->type == MD_LINE_BLANK || pivot_line->type == MD_LINE_INDENTEDCODE))\n        {\n            line->type = MD_LINE_INDENTEDCODE;\n            MD_ASSERT(line->indent >= ctx->code_indent_offset);\n            line->indent -= ctx->code_indent_offset;\n            line->data = 0;\n            break;\n        }\n\n        /* Check for start of a new container block. */\n        if(line->indent < ctx->code_indent_offset  &&\n           md_is_container_mark(ctx, line->indent, off, &off, &container))\n        {\n            if(pivot_line->type == MD_LINE_TEXT  &&  n_parents == ctx->n_containers  &&\n                        (off >= ctx->size || ISNEWLINE(off))  &&  container.ch != _T('>'))\n            {\n                /* Noop. List mark followed by a blank line cannot interrupt a paragraph. */\n            } else if(pivot_line->type == MD_LINE_TEXT  &&  n_parents == ctx->n_containers  &&\n                        (container.ch == _T('.') || container.ch == _T(')'))  &&  container.start != 1)\n            {\n                /* Noop. Ordered list cannot interrupt a paragraph unless the start index is 1. */\n            } else {\n                total_indent += container.contents_indent - container.mark_indent;\n                line->indent = md_line_indentation(ctx, total_indent, off, &off);\n                total_indent += line->indent;\n\n                line->beg = off;\n                line->data = container.ch;\n\n                /* Some of the following whitespace actually still belongs to the mark. */\n                if(off >= ctx->size || ISNEWLINE(off)) {\n                    container.contents_indent++;\n                } else if(line->indent <= ctx->code_indent_offset) {\n                    container.contents_indent += line->indent;\n                    line->indent = 0;\n                } else {\n                    container.contents_indent += 1;\n                    line->indent--;\n                }\n\n                if(n_brothers + n_children == 0)\n                    pivot_line = &md_dummy_blank_line;\n\n                if(n_children == 0)\n                    MD_CHECK(md_leave_child_containers(ctx, n_parents + n_brothers));\n\n                n_children++;\n                MD_CHECK(md_push_container(ctx, &container));\n                continue;\n            }\n        }\n\n        /* Check whether we are table continuation. */\n        if(pivot_line->type == MD_LINE_TABLE  &&  n_parents == ctx->n_containers) {\n            line->type = MD_LINE_TABLE;\n            break;\n        }\n\n        /* Check for ATX header. */\n        if(line->indent < ctx->code_indent_offset  &&  CH(off) == _T('#')) {\n            unsigned level;\n\n            if(md_is_atxheader_line(ctx, off, &line->beg, &off, &level)) {\n                line->type = MD_LINE_ATXHEADER;\n                line->data = level;\n                break;\n            }\n        }\n\n        /* Check whether we are starting code fence. */\n        if(CH(off) == _T('`') || CH(off) == _T('~')) {\n            if(md_is_opening_code_fence(ctx, off, &off)) {\n                line->type = MD_LINE_FENCEDCODE;\n                line->data = 1;\n                break;\n            }\n        }\n\n        /* Check for start of raw HTML block. */\n        if(CH(off) == _T('<')  &&  !(ctx->parser.flags & MD_FLAG_NOHTMLBLOCKS))\n        {\n            ctx->html_block_type = md_is_html_block_start_condition(ctx, off);\n\n            /* HTML block type 7 cannot interrupt paragraph. */\n            if(ctx->html_block_type == 7  &&  pivot_line->type == MD_LINE_TEXT)\n                ctx->html_block_type = 0;\n\n            if(ctx->html_block_type > 0) {\n                /* The line itself also may immediately close the block. */\n                if(md_is_html_block_end_condition(ctx, off, &off) == ctx->html_block_type) {\n                    /* Make sure this is the last line of the block. */\n                    ctx->html_block_type = 0;\n                }\n\n                line->type = MD_LINE_HTML;\n                break;\n            }\n        }\n\n        /* Check for table underline. */\n        if((ctx->parser.flags & MD_FLAG_TABLES)  &&  pivot_line->type == MD_LINE_TEXT  &&\n           (CH(off) == _T('|') || CH(off) == _T('-') || CH(off) == _T(':'))  &&\n           n_parents == ctx->n_containers)\n        {\n            unsigned col_count;\n\n            if(ctx->current_block != NULL  &&  ctx->current_block->n_lines == 1  &&\n                md_is_table_underline(ctx, off, &off, &col_count))\n            {\n                line->data = col_count;\n                line->type = MD_LINE_TABLEUNDERLINE;\n                break;\n            }\n        }\n\n        /* By default, we are normal text line. */\n        line->type = MD_LINE_TEXT;\n        if(pivot_line->type == MD_LINE_TEXT  &&  n_brothers + n_children == 0) {\n            /* Lazy continuation. */\n            n_parents = ctx->n_containers;\n        }\n\n        /* Check for task mark. */\n        if((ctx->parser.flags & MD_FLAG_TASKLISTS)  &&  n_brothers + n_children > 0  &&\n           ISANYOF_(ctx->containers[ctx->n_containers-1].ch, _T(\"-+*.)\")))\n        {\n            OFF tmp = off;\n\n            while(tmp < ctx->size  &&  tmp < off + 3  &&  ISBLANK(tmp))\n                tmp++;\n            if(tmp + 2 < ctx->size  &&  CH(tmp) == _T('[')  &&\n               ISANYOF(tmp+1, _T(\"xX \"))  &&  CH(tmp+2) == _T(']')  &&\n               (tmp + 3 == ctx->size  ||  ISBLANK(tmp+3)  ||  ISNEWLINE(tmp+3)))\n            {\n                MD_CONTAINER* task_container = (n_children > 0 ? &ctx->containers[ctx->n_containers-1] : &container);\n                task_container->is_task = TRUE;\n                task_container->task_mark_off = tmp + 1;\n                off = tmp + 3;\n                while(ISWHITESPACE(off))\n                    off++;\n                line->beg = off;\n            }\n        }\n\n        break;\n    }\n\n    /* Scan for end of the line.\n     *\n     * Note this is quite a bottleneck of the parsing as we here iterate almost\n     * over compete document.\n     */\n#if defined __linux__ && !defined MD4C_USE_UTF16\n    /* Recent glibc versions have superbly optimized strcspn(), even using\n     * vectorization if available. */\n    if(ctx->doc_ends_with_newline  &&  off < ctx->size) {\n        while(TRUE) {\n            off += (OFF) strcspn(STR(off), \"\\r\\n\");\n\n            /* strcspn() can stop on zero terminator; but that can appear\n             * anywhere in the Markfown input... */\n            if(CH(off) == _T('\\0'))\n                off++;\n            else\n                break;\n        }\n    } else\n#endif\n    {\n        /* Optimization: Use some loop unrolling. */\n        while(off + 3 < ctx->size  &&  !ISNEWLINE(off+0)  &&  !ISNEWLINE(off+1)\n                                   &&  !ISNEWLINE(off+2)  &&  !ISNEWLINE(off+3))\n            off += 4;\n        while(off < ctx->size  &&  !ISNEWLINE(off))\n            off++;\n    }\n\n    /* Set end of the line. */\n    line->end = off;\n\n    /* But for ATX header, we should exclude the optional trailing mark. */\n    if(line->type == MD_LINE_ATXHEADER) {\n        OFF tmp = line->end;\n        while(tmp > line->beg && CH(tmp-1) == _T(' '))\n            tmp--;\n        while(tmp > line->beg && CH(tmp-1) == _T('#'))\n            tmp--;\n        if(tmp == line->beg || CH(tmp-1) == _T(' ') || (ctx->parser.flags & MD_FLAG_PERMISSIVEATXHEADERS))\n            line->end = tmp;\n    }\n\n    /* Trim trailing spaces. */\n    if(line->type != MD_LINE_INDENTEDCODE  &&  line->type != MD_LINE_FENCEDCODE) {\n        while(line->end > line->beg && CH(line->end-1) == _T(' '))\n            line->end--;\n    }\n\n    /* Eat also the new line. */\n    if(off < ctx->size && CH(off) == _T('\\r'))\n        off++;\n    if(off < ctx->size && CH(off) == _T('\\n'))\n        off++;\n\n    *p_end = off;\n\n    /* If we belong to a list after seeing a blank line, the list is loose. */\n    if(prev_line_has_list_loosening_effect  &&  line->type != MD_LINE_BLANK  &&  n_parents + n_brothers > 0) {\n        MD_CONTAINER* c = &ctx->containers[n_parents + n_brothers - 1];\n        if(c->ch != _T('>')) {\n            MD_BLOCK* block = (MD_BLOCK*) (((char*)ctx->block_bytes) + c->block_byte_off);\n            block->flags |= MD_BLOCK_LOOSE_LIST;\n        }\n    }\n\n    /* Leave any containers we are not part of anymore. */\n    if(n_children == 0  &&  n_parents + n_brothers < ctx->n_containers)\n        MD_CHECK(md_leave_child_containers(ctx, n_parents + n_brothers));\n\n    /* Enter any container we found a mark for. */\n    if(n_brothers > 0) {\n        MD_ASSERT(n_brothers == 1);\n        MD_CHECK(md_push_container_bytes(ctx, MD_BLOCK_LI,\n                    ctx->containers[n_parents].task_mark_off,\n                    (ctx->containers[n_parents].is_task ? CH(ctx->containers[n_parents].task_mark_off) : 0),\n                    MD_BLOCK_CONTAINER_CLOSER));\n        MD_CHECK(md_push_container_bytes(ctx, MD_BLOCK_LI,\n                    container.task_mark_off,\n                    (container.is_task ? CH(container.task_mark_off) : 0),\n                    MD_BLOCK_CONTAINER_OPENER));\n        ctx->containers[n_parents].is_task = container.is_task;\n        ctx->containers[n_parents].task_mark_off = container.task_mark_off;\n    }\n\n    if(n_children > 0)\n        MD_CHECK(md_enter_child_containers(ctx, n_children));\n\nabort:\n    return ret;\n}",
        "func": "static int\nmd_analyze_line(MD_CTX* ctx, OFF beg, OFF* p_end,\n                const MD_LINE_ANALYSIS* pivot_line, MD_LINE_ANALYSIS* line)\n{\n    unsigned total_indent = 0;\n    int n_parents = 0;\n    int n_brothers = 0;\n    int n_children = 0;\n    MD_CONTAINER container = { 0 };\n    int prev_line_has_list_loosening_effect = ctx->last_line_has_list_loosening_effect;\n    OFF off = beg;\n    OFF hr_killer = 0;\n    int ret = 0;\n\n    line->indent = md_line_indentation(ctx, total_indent, off, &off);\n    total_indent += line->indent;\n    line->beg = off;\n\n    /* Given the indentation and block quote marks '>', determine how many of\n     * the current containers are our parents. */\n    while(n_parents < ctx->n_containers) {\n        MD_CONTAINER* c = &ctx->containers[n_parents];\n\n        if(c->ch == _T('>')  &&  line->indent < ctx->code_indent_offset  &&\n            off < ctx->size  &&  CH(off) == _T('>'))\n        {\n            /* Block quote mark. */\n            off++;\n            total_indent++;\n            line->indent = md_line_indentation(ctx, total_indent, off, &off);\n            total_indent += line->indent;\n\n            /* The optional 1st space after '>' is part of the block quote mark. */\n            if(line->indent > 0)\n                line->indent--;\n\n            line->beg = off;\n\n        } else if(c->ch != _T('>')  &&  line->indent >= c->contents_indent) {\n            /* List. */\n            line->indent -= c->contents_indent;\n        } else {\n            break;\n        }\n\n        n_parents++;\n    }\n\n    if(off >= ctx->size  ||  ISNEWLINE(off)) {\n        /* Blank line does not need any real indentation to be nested inside\n         * a list. */\n        if(n_brothers + n_children == 0) {\n            while(n_parents < ctx->n_containers  &&  ctx->containers[n_parents].ch != _T('>'))\n                n_parents++;\n        }\n    }\n\n    while(TRUE) {\n        /* Check whether we are fenced code continuation. */\n        if(pivot_line->type == MD_LINE_FENCEDCODE) {\n            line->beg = off;\n\n            /* We are another MD_LINE_FENCEDCODE unless we are closing fence\n             * which we transform into MD_LINE_BLANK. */\n            if(line->indent < ctx->code_indent_offset) {\n                if(md_is_closing_code_fence(ctx, CH(pivot_line->beg), off, &off)) {\n                    line->type = MD_LINE_BLANK;\n                    ctx->last_line_has_list_loosening_effect = FALSE;\n                    break;\n                }\n            }\n\n            /* Change indentation accordingly to the initial code fence. */\n            if(n_parents == ctx->n_containers) {\n                if(line->indent > pivot_line->indent)\n                    line->indent -= pivot_line->indent;\n                else\n                    line->indent = 0;\n\n                line->type = MD_LINE_FENCEDCODE;\n                break;\n            }\n        }\n\n        /* Check whether we are HTML block continuation. */\n        if(pivot_line->type == MD_LINE_HTML  &&  ctx->html_block_type > 0) {\n            if(n_parents < ctx->n_containers) {\n                /* HTML block is implicitly ended if the enclosing container\n                 * block ends. */\n                ctx->html_block_type = 0;\n            } else {\n                int html_block_type;\n\n                html_block_type = md_is_html_block_end_condition(ctx, off, &off);\n                if(html_block_type > 0) {\n                    MD_ASSERT(html_block_type == ctx->html_block_type);\n\n                    /* Make sure this is the last line of the block. */\n                    ctx->html_block_type = 0;\n\n                    /* Some end conditions serve as blank lines at the same time. */\n                    if(html_block_type == 6 || html_block_type == 7) {\n                        line->type = MD_LINE_BLANK;\n                        line->indent = 0;\n                        break;\n                    }\n                }\n\n                line->type = MD_LINE_HTML;\n                n_parents = ctx->n_containers;\n                break;\n            }\n        }\n\n        /* Check for blank line. */\n        if(off >= ctx->size  ||  ISNEWLINE(off)) {\n            if(pivot_line->type == MD_LINE_INDENTEDCODE  &&  n_parents == ctx->n_containers) {\n                line->type = MD_LINE_INDENTEDCODE;\n                if(line->indent > ctx->code_indent_offset)\n                    line->indent -= ctx->code_indent_offset;\n                else\n                    line->indent = 0;\n                ctx->last_line_has_list_loosening_effect = FALSE;\n            } else {\n                line->type = MD_LINE_BLANK;\n                ctx->last_line_has_list_loosening_effect = (n_parents > 0  &&\n                        n_brothers + n_children == 0  &&\n                        ctx->containers[n_parents-1].ch != _T('>'));\n\n    #if 1\n                /* See https://github.com/mity/md4c/issues/6\n                 *\n                 * This ugly checking tests we are in (yet empty) list item but\n                 * not its very first line (i.e. not the line with the list\n                 * item mark).\n                 *\n                 * If we are such a blank line, then any following non-blank\n                 * line which would be part of the list item actually has to\n                 * end the list because according to the specification, \"a list\n                 * item can begin with at most one blank line.\"\n                 */\n                if(n_parents > 0  &&  ctx->containers[n_parents-1].ch != _T('>')  &&\n                   n_brothers + n_children == 0  &&  ctx->current_block == NULL  &&\n                   ctx->n_block_bytes > (int) sizeof(MD_BLOCK))\n                {\n                    MD_BLOCK* top_block = (MD_BLOCK*) ((char*)ctx->block_bytes + ctx->n_block_bytes - sizeof(MD_BLOCK));\n                    if(top_block->type == MD_BLOCK_LI)\n                        ctx->last_list_item_starts_with_two_blank_lines = TRUE;\n                }\n    #endif\n            }\n            break;\n        } else {\n    #if 1\n            /* This is the 2nd half of the hack. If the flag is set (i.e. there\n             * was a 2nd blank line at the beginning of the list item) and if\n             * we would otherwise still belong to the list item, we enforce\n             * the end of the list. */\n            ctx->last_line_has_list_loosening_effect = FALSE;\n            if(ctx->last_list_item_starts_with_two_blank_lines) {\n                if(n_parents > 0  &&  ctx->containers[n_parents-1].ch != _T('>')  &&\n                   n_brothers + n_children == 0  &&  ctx->current_block == NULL  &&\n                   ctx->n_block_bytes > (int) sizeof(MD_BLOCK))\n                {\n                    MD_BLOCK* top_block = (MD_BLOCK*) ((char*)ctx->block_bytes + ctx->n_block_bytes - sizeof(MD_BLOCK));\n                    if(top_block->type == MD_BLOCK_LI)\n                        n_parents--;\n                }\n\n                ctx->last_list_item_starts_with_two_blank_lines = FALSE;\n            }\n    #endif\n        }\n\n        /* Check whether we are Setext underline. */\n        if(line->indent < ctx->code_indent_offset  &&  pivot_line->type == MD_LINE_TEXT\n            &&  off < ctx->size  &&  ISANYOF2(off, _T('='), _T('-'))\n            &&  (n_parents == ctx->n_containers))\n        {\n            unsigned level;\n\n            if(md_is_setext_underline(ctx, off, &off, &level)) {\n                line->type = MD_LINE_SETEXTUNDERLINE;\n                line->data = level;\n                break;\n            }\n        }\n\n        /* Check for thematic break line. */\n        if(line->indent < ctx->code_indent_offset\n            &&  off < ctx->size  &&  off >= hr_killer\n            &&  ISANYOF(off, _T(\"-_*\")))\n        {\n            if(md_is_hr_line(ctx, off, &off, &hr_killer)) {\n                line->type = MD_LINE_HR;\n                break;\n            }\n        }\n\n        /* Check for \"brother\" container. I.e. whether we are another list item\n         * in already started list. */\n        if(n_parents < ctx->n_containers  &&  n_brothers + n_children == 0) {\n            OFF tmp;\n\n            if(md_is_container_mark(ctx, line->indent, off, &tmp, &container)  &&\n               md_is_container_compatible(&ctx->containers[n_parents], &container))\n            {\n                pivot_line = &md_dummy_blank_line;\n\n                off = tmp;\n\n                total_indent += container.contents_indent - container.mark_indent;\n                line->indent = md_line_indentation(ctx, total_indent, off, &off);\n                total_indent += line->indent;\n                line->beg = off;\n\n                /* Some of the following whitespace actually still belongs to the mark. */\n                if(off >= ctx->size || ISNEWLINE(off)) {\n                    container.contents_indent++;\n                } else if(line->indent <= ctx->code_indent_offset) {\n                    container.contents_indent += line->indent;\n                    line->indent = 0;\n                } else {\n                    container.contents_indent += 1;\n                    line->indent--;\n                }\n\n                ctx->containers[n_parents].mark_indent = container.mark_indent;\n                ctx->containers[n_parents].contents_indent = container.contents_indent;\n\n                n_brothers++;\n                continue;\n            }\n        }\n\n        /* Check for indented code.\n         * Note indented code block cannot interrupt a paragraph. */\n        if(line->indent >= ctx->code_indent_offset  &&\n            (pivot_line->type == MD_LINE_BLANK || pivot_line->type == MD_LINE_INDENTEDCODE))\n        {\n            line->type = MD_LINE_INDENTEDCODE;\n            MD_ASSERT(line->indent >= ctx->code_indent_offset);\n            line->indent -= ctx->code_indent_offset;\n            line->data = 0;\n            break;\n        }\n\n        /* Check for start of a new container block. */\n        if(line->indent < ctx->code_indent_offset  &&\n           md_is_container_mark(ctx, line->indent, off, &off, &container))\n        {\n            if(pivot_line->type == MD_LINE_TEXT  &&  n_parents == ctx->n_containers  &&\n                        (off >= ctx->size || ISNEWLINE(off))  &&  container.ch != _T('>'))\n            {\n                /* Noop. List mark followed by a blank line cannot interrupt a paragraph. */\n            } else if(pivot_line->type == MD_LINE_TEXT  &&  n_parents == ctx->n_containers  &&\n                        ISANYOF2_(container.ch, _T('.'), _T(')'))  &&  container.start != 1)\n            {\n                /* Noop. Ordered list cannot interrupt a paragraph unless the start index is 1. */\n            } else {\n                total_indent += container.contents_indent - container.mark_indent;\n                line->indent = md_line_indentation(ctx, total_indent, off, &off);\n                total_indent += line->indent;\n\n                line->beg = off;\n                line->data = container.ch;\n\n                /* Some of the following whitespace actually still belongs to the mark. */\n                if(off >= ctx->size || ISNEWLINE(off)) {\n                    container.contents_indent++;\n                } else if(line->indent <= ctx->code_indent_offset) {\n                    container.contents_indent += line->indent;\n                    line->indent = 0;\n                } else {\n                    container.contents_indent += 1;\n                    line->indent--;\n                }\n\n                if(n_brothers + n_children == 0)\n                    pivot_line = &md_dummy_blank_line;\n\n                if(n_children == 0)\n                    MD_CHECK(md_leave_child_containers(ctx, n_parents + n_brothers));\n\n                n_children++;\n                MD_CHECK(md_push_container(ctx, &container));\n                continue;\n            }\n        }\n\n        /* Check whether we are table continuation. */\n        if(pivot_line->type == MD_LINE_TABLE  &&  n_parents == ctx->n_containers) {\n            line->type = MD_LINE_TABLE;\n            break;\n        }\n\n        /* Check for ATX header. */\n        if(line->indent < ctx->code_indent_offset  &&\n                off < ctx->size  &&  CH(off) == _T('#'))\n        {\n            unsigned level;\n\n            if(md_is_atxheader_line(ctx, off, &line->beg, &off, &level)) {\n                line->type = MD_LINE_ATXHEADER;\n                line->data = level;\n                break;\n            }\n        }\n\n        /* Check whether we are starting code fence. */\n        if(off < ctx->size  &&  ISANYOF2(off, _T('`'), _T('~'))) {\n            if(md_is_opening_code_fence(ctx, off, &off)) {\n                line->type = MD_LINE_FENCEDCODE;\n                line->data = 1;\n                break;\n            }\n        }\n\n        /* Check for start of raw HTML block. */\n        if(off < ctx->size  &&  CH(off) == _T('<')\n            &&  !(ctx->parser.flags & MD_FLAG_NOHTMLBLOCKS))\n        {\n            ctx->html_block_type = md_is_html_block_start_condition(ctx, off);\n\n            /* HTML block type 7 cannot interrupt paragraph. */\n            if(ctx->html_block_type == 7  &&  pivot_line->type == MD_LINE_TEXT)\n                ctx->html_block_type = 0;\n\n            if(ctx->html_block_type > 0) {\n                /* The line itself also may immediately close the block. */\n                if(md_is_html_block_end_condition(ctx, off, &off) == ctx->html_block_type) {\n                    /* Make sure this is the last line of the block. */\n                    ctx->html_block_type = 0;\n                }\n\n                line->type = MD_LINE_HTML;\n                break;\n            }\n        }\n\n        /* Check for table underline. */\n        if((ctx->parser.flags & MD_FLAG_TABLES)  &&  pivot_line->type == MD_LINE_TEXT\n            &&  off < ctx->size  &&  ISANYOF3(off, _T('|'), _T('-'), _T(':'))\n            &&  n_parents == ctx->n_containers)\n        {\n            unsigned col_count;\n\n            if(ctx->current_block != NULL  &&  ctx->current_block->n_lines == 1  &&\n                md_is_table_underline(ctx, off, &off, &col_count))\n            {\n                line->data = col_count;\n                line->type = MD_LINE_TABLEUNDERLINE;\n                break;\n            }\n        }\n\n        /* By default, we are normal text line. */\n        line->type = MD_LINE_TEXT;\n        if(pivot_line->type == MD_LINE_TEXT  &&  n_brothers + n_children == 0) {\n            /* Lazy continuation. */\n            n_parents = ctx->n_containers;\n        }\n\n        /* Check for task mark. */\n        if((ctx->parser.flags & MD_FLAG_TASKLISTS)  &&  n_brothers + n_children > 0  &&\n           ISANYOF_(ctx->containers[ctx->n_containers-1].ch, _T(\"-+*.)\")))\n        {\n            OFF tmp = off;\n\n            while(tmp < ctx->size  &&  tmp < off + 3  &&  ISBLANK(tmp))\n                tmp++;\n            if(tmp + 2 < ctx->size  &&  CH(tmp) == _T('[')  &&\n               ISANYOF(tmp+1, _T(\"xX \"))  &&  CH(tmp+2) == _T(']')  &&\n               (tmp + 3 == ctx->size  ||  ISBLANK(tmp+3)  ||  ISNEWLINE(tmp+3)))\n            {\n                MD_CONTAINER* task_container = (n_children > 0 ? &ctx->containers[ctx->n_containers-1] : &container);\n                task_container->is_task = TRUE;\n                task_container->task_mark_off = tmp + 1;\n                off = tmp + 3;\n                while(ISWHITESPACE(off))\n                    off++;\n                line->beg = off;\n            }\n        }\n\n        break;\n    }\n\n    /* Scan for end of the line.\n     *\n     * Note this is quite a bottleneck of the parsing as we here iterate almost\n     * over compete document.\n     */\n#if defined __linux__ && !defined MD4C_USE_UTF16\n    /* Recent glibc versions have superbly optimized strcspn(), even using\n     * vectorization if available. */\n    if(ctx->doc_ends_with_newline  &&  off < ctx->size) {\n        while(TRUE) {\n            off += (OFF) strcspn(STR(off), \"\\r\\n\");\n\n            /* strcspn() can stop on zero terminator; but that can appear\n             * anywhere in the Markfown input... */\n            if(CH(off) == _T('\\0'))\n                off++;\n            else\n                break;\n        }\n    } else\n#endif\n    {\n        /* Optimization: Use some loop unrolling. */\n        while(off + 3 < ctx->size  &&  !ISNEWLINE(off+0)  &&  !ISNEWLINE(off+1)\n                                   &&  !ISNEWLINE(off+2)  &&  !ISNEWLINE(off+3))\n            off += 4;\n        while(off < ctx->size  &&  !ISNEWLINE(off))\n            off++;\n    }\n\n    /* Set end of the line. */\n    line->end = off;\n\n    /* But for ATX header, we should exclude the optional trailing mark. */\n    if(line->type == MD_LINE_ATXHEADER) {\n        OFF tmp = line->end;\n        while(tmp > line->beg && CH(tmp-1) == _T(' '))\n            tmp--;\n        while(tmp > line->beg && CH(tmp-1) == _T('#'))\n            tmp--;\n        if(tmp == line->beg || CH(tmp-1) == _T(' ') || (ctx->parser.flags & MD_FLAG_PERMISSIVEATXHEADERS))\n            line->end = tmp;\n    }\n\n    /* Trim trailing spaces. */\n    if(line->type != MD_LINE_INDENTEDCODE  &&  line->type != MD_LINE_FENCEDCODE) {\n        while(line->end > line->beg && CH(line->end-1) == _T(' '))\n            line->end--;\n    }\n\n    /* Eat also the new line. */\n    if(off < ctx->size && CH(off) == _T('\\r'))\n        off++;\n    if(off < ctx->size && CH(off) == _T('\\n'))\n        off++;\n\n    *p_end = off;\n\n    /* If we belong to a list after seeing a blank line, the list is loose. */\n    if(prev_line_has_list_loosening_effect  &&  line->type != MD_LINE_BLANK  &&  n_parents + n_brothers > 0) {\n        MD_CONTAINER* c = &ctx->containers[n_parents + n_brothers - 1];\n        if(c->ch != _T('>')) {\n            MD_BLOCK* block = (MD_BLOCK*) (((char*)ctx->block_bytes) + c->block_byte_off);\n            block->flags |= MD_BLOCK_LOOSE_LIST;\n        }\n    }\n\n    /* Leave any containers we are not part of anymore. */\n    if(n_children == 0  &&  n_parents + n_brothers < ctx->n_containers)\n        MD_CHECK(md_leave_child_containers(ctx, n_parents + n_brothers));\n\n    /* Enter any container we found a mark for. */\n    if(n_brothers > 0) {\n        MD_ASSERT(n_brothers == 1);\n        MD_CHECK(md_push_container_bytes(ctx, MD_BLOCK_LI,\n                    ctx->containers[n_parents].task_mark_off,\n                    (ctx->containers[n_parents].is_task ? CH(ctx->containers[n_parents].task_mark_off) : 0),\n                    MD_BLOCK_CONTAINER_CLOSER));\n        MD_CHECK(md_push_container_bytes(ctx, MD_BLOCK_LI,\n                    container.task_mark_off,\n                    (container.is_task ? CH(container.task_mark_off) : 0),\n                    MD_BLOCK_CONTAINER_OPENER));\n        ctx->containers[n_parents].is_task = container.is_task;\n        ctx->containers[n_parents].task_mark_off = container.task_mark_off;\n    }\n\n    if(n_children > 0)\n        MD_CHECK(md_enter_child_containers(ctx, n_children));\n\nabort:\n    return ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -174,7 +174,7 @@\n \n         /* Check whether we are Setext underline. */\n         if(line->indent < ctx->code_indent_offset  &&  pivot_line->type == MD_LINE_TEXT\n-            &&  (CH(off) == _T('=') || CH(off) == _T('-'))\n+            &&  off < ctx->size  &&  ISANYOF2(off, _T('='), _T('-'))\n             &&  (n_parents == ctx->n_containers))\n         {\n             unsigned level;\n@@ -187,7 +187,10 @@\n         }\n \n         /* Check for thematic break line. */\n-        if(line->indent < ctx->code_indent_offset  &&  ISANYOF(off, _T(\"-_*\"))  &&  off >= hr_killer) {\n+        if(line->indent < ctx->code_indent_offset\n+            &&  off < ctx->size  &&  off >= hr_killer\n+            &&  ISANYOF(off, _T(\"-_*\")))\n+        {\n             if(md_is_hr_line(ctx, off, &off, &hr_killer)) {\n                 line->type = MD_LINE_HR;\n                 break;\n@@ -251,7 +254,7 @@\n             {\n                 /* Noop. List mark followed by a blank line cannot interrupt a paragraph. */\n             } else if(pivot_line->type == MD_LINE_TEXT  &&  n_parents == ctx->n_containers  &&\n-                        (container.ch == _T('.') || container.ch == _T(')'))  &&  container.start != 1)\n+                        ISANYOF2_(container.ch, _T('.'), _T(')'))  &&  container.start != 1)\n             {\n                 /* Noop. Ordered list cannot interrupt a paragraph unless the start index is 1. */\n             } else {\n@@ -292,7 +295,9 @@\n         }\n \n         /* Check for ATX header. */\n-        if(line->indent < ctx->code_indent_offset  &&  CH(off) == _T('#')) {\n+        if(line->indent < ctx->code_indent_offset  &&\n+                off < ctx->size  &&  CH(off) == _T('#'))\n+        {\n             unsigned level;\n \n             if(md_is_atxheader_line(ctx, off, &line->beg, &off, &level)) {\n@@ -303,7 +308,7 @@\n         }\n \n         /* Check whether we are starting code fence. */\n-        if(CH(off) == _T('`') || CH(off) == _T('~')) {\n+        if(off < ctx->size  &&  ISANYOF2(off, _T('`'), _T('~'))) {\n             if(md_is_opening_code_fence(ctx, off, &off)) {\n                 line->type = MD_LINE_FENCEDCODE;\n                 line->data = 1;\n@@ -312,7 +317,8 @@\n         }\n \n         /* Check for start of raw HTML block. */\n-        if(CH(off) == _T('<')  &&  !(ctx->parser.flags & MD_FLAG_NOHTMLBLOCKS))\n+        if(off < ctx->size  &&  CH(off) == _T('<')\n+            &&  !(ctx->parser.flags & MD_FLAG_NOHTMLBLOCKS))\n         {\n             ctx->html_block_type = md_is_html_block_start_condition(ctx, off);\n \n@@ -333,9 +339,9 @@\n         }\n \n         /* Check for table underline. */\n-        if((ctx->parser.flags & MD_FLAG_TABLES)  &&  pivot_line->type == MD_LINE_TEXT  &&\n-           (CH(off) == _T('|') || CH(off) == _T('-') || CH(off) == _T(':'))  &&\n-           n_parents == ctx->n_containers)\n+        if((ctx->parser.flags & MD_FLAG_TABLES)  &&  pivot_line->type == MD_LINE_TEXT\n+            &&  off < ctx->size  &&  ISANYOF3(off, _T('|'), _T('-'), _T(':'))\n+            &&  n_parents == ctx->n_containers)\n         {\n             unsigned col_count;\n ",
        "diff_line_info": {
            "deleted_lines": [
                "            &&  (CH(off) == _T('=') || CH(off) == _T('-'))",
                "        if(line->indent < ctx->code_indent_offset  &&  ISANYOF(off, _T(\"-_*\"))  &&  off >= hr_killer) {",
                "                        (container.ch == _T('.') || container.ch == _T(')'))  &&  container.start != 1)",
                "        if(line->indent < ctx->code_indent_offset  &&  CH(off) == _T('#')) {",
                "        if(CH(off) == _T('`') || CH(off) == _T('~')) {",
                "        if(CH(off) == _T('<')  &&  !(ctx->parser.flags & MD_FLAG_NOHTMLBLOCKS))",
                "        if((ctx->parser.flags & MD_FLAG_TABLES)  &&  pivot_line->type == MD_LINE_TEXT  &&",
                "           (CH(off) == _T('|') || CH(off) == _T('-') || CH(off) == _T(':'))  &&",
                "           n_parents == ctx->n_containers)"
            ],
            "added_lines": [
                "            &&  off < ctx->size  &&  ISANYOF2(off, _T('='), _T('-'))",
                "        if(line->indent < ctx->code_indent_offset",
                "            &&  off < ctx->size  &&  off >= hr_killer",
                "            &&  ISANYOF(off, _T(\"-_*\")))",
                "        {",
                "                        ISANYOF2_(container.ch, _T('.'), _T(')'))  &&  container.start != 1)",
                "        if(line->indent < ctx->code_indent_offset  &&",
                "                off < ctx->size  &&  CH(off) == _T('#'))",
                "        {",
                "        if(off < ctx->size  &&  ISANYOF2(off, _T('`'), _T('~'))) {",
                "        if(off < ctx->size  &&  CH(off) == _T('<')",
                "            &&  !(ctx->parser.flags & MD_FLAG_NOHTMLBLOCKS))",
                "        if((ctx->parser.flags & MD_FLAG_TABLES)  &&  pivot_line->type == MD_LINE_TEXT",
                "            &&  off < ctx->size  &&  ISANYOF3(off, _T('|'), _T('-'), _T(':'))",
                "            &&  n_parents == ctx->n_containers)"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-29623",
        "func_name": "Exiv2/exiv2/isWebPType",
        "description": "Exiv2 is a C++ library and a command-line utility to read, write, delete and modify Exif, IPTC, XMP and ICC image metadata. A read of uninitialized memory was found in Exiv2 versions v0.27.3 and earlier. Exiv2 is a command-line utility and C++ library for reading, writing, deleting, and modifying the metadata of image files. The read of uninitialized memory is triggered when Exiv2 is used to read the metadata of a crafted image file. An attacker could potentially exploit the vulnerability to leak a few bytes of stack memory, if they can trick the victim into running Exiv2 on a crafted image file. The bug is fixed in version v0.27.4.",
        "git_url": "https://github.com/Exiv2/exiv2/commit/82e46b5524fb904e6660dadd2c6d8e5e47375a1a",
        "commit_title": "Use readOrThrow to check error conditions of iIo.read().",
        "commit_text": "",
        "func_before": "bool isWebPType(BasicIo& iIo, bool /*advance*/)\n    {\n        if (iIo.size() < 12) {\n          return false;\n        }\n        const int32_t len = 4;\n        const unsigned char RiffImageId[4] = { 'R', 'I', 'F' ,'F'};\n        const unsigned char WebPImageId[4] = { 'W', 'E', 'B' ,'P'};\n        byte webp[len];\n        byte data[len];\n        byte riff[len];\n        iIo.read(riff, len);\n        iIo.read(data, len);\n        iIo.read(webp, len);\n        bool matched_riff = (memcmp(riff, RiffImageId, len) == 0);\n        bool matched_webp = (memcmp(webp, WebPImageId, len) == 0);\n        iIo.seek(-12, BasicIo::cur);\n        return matched_riff && matched_webp;\n    }",
        "func": "bool isWebPType(BasicIo& iIo, bool /*advance*/)\n    {\n        if (iIo.size() < 12) {\n          return false;\n        }\n        const int32_t len = 4;\n        const unsigned char RiffImageId[4] = { 'R', 'I', 'F' ,'F'};\n        const unsigned char WebPImageId[4] = { 'W', 'E', 'B' ,'P'};\n        byte webp[len];\n        byte data[len];\n        byte riff[len];\n        readOrThrow(iIo, riff, len, Exiv2::kerCorruptedMetadata);\n        readOrThrow(iIo, data, len, Exiv2::kerCorruptedMetadata);\n        readOrThrow(iIo, webp, len, Exiv2::kerCorruptedMetadata);\n        bool matched_riff = (memcmp(riff, RiffImageId, len) == 0);\n        bool matched_webp = (memcmp(webp, WebPImageId, len) == 0);\n        iIo.seek(-12, BasicIo::cur);\n        return matched_riff && matched_webp;\n    }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -9,9 +9,9 @@\n         byte webp[len];\n         byte data[len];\n         byte riff[len];\n-        iIo.read(riff, len);\n-        iIo.read(data, len);\n-        iIo.read(webp, len);\n+        readOrThrow(iIo, riff, len, Exiv2::kerCorruptedMetadata);\n+        readOrThrow(iIo, data, len, Exiv2::kerCorruptedMetadata);\n+        readOrThrow(iIo, webp, len, Exiv2::kerCorruptedMetadata);\n         bool matched_riff = (memcmp(riff, RiffImageId, len) == 0);\n         bool matched_webp = (memcmp(webp, WebPImageId, len) == 0);\n         iIo.seek(-12, BasicIo::cur);",
        "diff_line_info": {
            "deleted_lines": [
                "        iIo.read(riff, len);",
                "        iIo.read(data, len);",
                "        iIo.read(webp, len);"
            ],
            "added_lines": [
                "        readOrThrow(iIo, riff, len, Exiv2::kerCorruptedMetadata);",
                "        readOrThrow(iIo, data, len, Exiv2::kerCorruptedMetadata);",
                "        readOrThrow(iIo, webp, len, Exiv2::kerCorruptedMetadata);"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-29580",
        "func_name": "tensorflow/Compute",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. The implementation of `tf.raw_ops.FractionalMaxPoolGrad` triggers an undefined behavior if one of the input tensors is empty. The code is also vulnerable to a denial of service attack as a `CHECK` condition becomes false and aborts the process. The implementation(https://github.com/tensorflow/tensorflow/blob/169054888d50ce488dfde9ca55d91d6325efbd5b/tensorflow/core/kernels/fractional_max_pool_op.cc#L215) fails to validate that input and output tensors are not empty and are of the same rank. Each of these unchecked assumptions is responsible for the above issues. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/32fdcbff9d06d010d908fcc4bd4b36eb3ce15925",
        "commit_title": "Validate arguments of `FractionalMaxPoolGrad`",
        "commit_text": " PiperOrigin-RevId: 372274982",
        "func_before": "void Compute(OpKernelContext* context) override {\n    // There are two steps when calculating gradient for FractionalMaxPool.\n    // 1) Walk through the process of calculating fractional pooling given\n    //    pooling region; however, in the process, keep track of where the max\n    //    element comes from. (arg_max)\n    // 2) Populate the value of out_backprop to where arg_max indicates. If\n    //    we support overlapping, it is likely to have multiple out_backprop[i]\n    //    propagates back to the same arg_max value.\n    typedef Eigen::Map<const Eigen::Matrix<T, Eigen::Dynamic, Eigen::Dynamic>>\n        ConstEigenMatrixMap;\n    typedef Eigen::Map<Eigen::Matrix<T, Eigen::Dynamic, Eigen::Dynamic>>\n        EigenMatrixMap;\n    typedef Eigen::Map<Eigen::Matrix<int64, Eigen::Dynamic, Eigen::Dynamic>>\n        EigenIndexMatrixMap;\n\n    const Tensor& tensor_in = context->input(0);\n    const Tensor& tensor_out = context->input(1);\n    const Tensor& out_backprop = context->input(2);\n    const Tensor& height_seq_tensor = context->input(3);\n    const Tensor& width_seq_tensor = context->input(4);\n\n    // Just to make it similar to FractionalMaxPoolOp.\n    constexpr int tensor_in_and_out_dims = 4;\n    std::vector<int64> input_size(tensor_in_and_out_dims);\n    std::vector<int64> output_size(tensor_in_and_out_dims);\n    for (int i = 0; i < tensor_in_and_out_dims; ++i) {\n      input_size[i] = tensor_in.dim_size(i);\n    }\n    for (int i = 0; i < tensor_in_and_out_dims; ++i) {\n      output_size[i] = tensor_out.dim_size(i);\n    }\n\n    // ---------\n    // Step 1\n    // ---------\n    Tensor tensor_out_dup;\n    OP_REQUIRES_OK(context, context->forward_input_or_allocate_temp(\n                                {1}, DataTypeToEnum<T>::v(), tensor_out.shape(),\n                                &tensor_out_dup));\n    Tensor tensor_out_arg_max;\n    OP_REQUIRES_OK(context, context->allocate_temp(DataTypeToEnum<int64>::v(),\n                                                   tensor_out.shape(),\n                                                   &tensor_out_arg_max));\n    // Find arg_max for each tensor_out\n    ConstEigenMatrixMap tensor_in_mat(\n        tensor_in.flat<T>().data(), input_size[3],\n        input_size[2] * input_size[1] * input_size[0]);\n    EigenMatrixMap tensor_out_dup_mat(\n        tensor_out_dup.flat<T>().data(), output_size[3],\n        output_size[2] * output_size[1] * output_size[0]);\n    EigenIndexMatrixMap tensor_out_arg_max_mat(\n        tensor_out_arg_max.flat<int64>().data(), output_size[3],\n        output_size[2] * output_size[1] * output_size[0]);\n\n    tensor_out_arg_max.flat<int64>().setConstant(kInvalidMaxPoolingIndex);\n    // Initializes the duplicate output tensor with MIN<T>.\n    tensor_out_dup.flat<T>().setConstant(Eigen::NumTraits<T>::lowest());\n\n    auto height_seq_tensor_flat = height_seq_tensor.flat<int64>();\n    auto width_seq_tensor_flat = width_seq_tensor.flat<int64>();\n\n    // Now walk through the process of fractional max pooling again.\n    // For both input and output,\n    // 0: batch\n    // 1: height / row\n    // 2: width / col\n    // 3: depth / channel\n    const int64 height_max = input_size[1] - 1;\n    const int64 width_max = input_size[2] - 1;\n    for (int64 b = 0; b < input_size[0]; ++b) {\n      // height sequence.\n      for (int64 hs = 0; hs < height_seq_tensor.dim_size(0) - 1; ++hs) {\n        // height start and end.\n        const int64 height_start = height_seq_tensor_flat(hs);\n        int64 height_end = overlapping_ ? height_seq_tensor_flat(hs + 1)\n                                        : height_seq_tensor_flat(hs + 1) - 1;\n        height_end = std::min(height_end, height_max);\n\n        // width sequence.\n        for (int64 ws = 0; ws < width_seq_tensor.dim_size(0) - 1; ++ws) {\n          const int64 out_index =\n              (b * output_size[1] + hs) * output_size[2] + ws;\n          // width start and end.\n          const int64 width_start = width_seq_tensor_flat(ws);\n          int64 width_end = overlapping_ ? width_seq_tensor_flat(ws + 1)\n                                         : width_seq_tensor_flat(ws + 1) - 1;\n          width_end = std::min(width_end, width_max);\n          for (int64 h = height_start; h <= height_end; ++h) {\n            for (int64 w = width_start; w <= width_end; ++w) {\n              const int64 in_index =\n                  (b * input_size[1] + h) * input_size[2] + w;\n              // Walk through each channel (depth).\n              for (int64 d = 0; d < input_size[3]; ++d) {\n                const T& input_ref = tensor_in_mat.coeffRef(d, in_index);\n                T& output_ref = tensor_out_dup_mat.coeffRef(d, out_index);\n                int64& out_arg_max_ref =\n                    tensor_out_arg_max_mat.coeffRef(d, out_index);\n                if (output_ref < input_ref ||\n                    out_arg_max_ref == kInvalidMaxPoolingIndex) {\n                  output_ref = input_ref;\n                  int input_offset = in_index * input_size[3] + d;\n                  out_arg_max_ref = input_offset;\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n\n    // Check tensor_out_dup is the same as tensor_out.\n    ConstEigenMatrixMap tensor_out_mat(\n        tensor_out.flat<T>().data(), output_size[3],\n        output_size[2] * output_size[1] * output_size[0]);\n    const int64 num_reshaped_cols =\n        output_size[2] * output_size[1] * output_size[0];\n    for (int64 i = 0; i < num_reshaped_cols; ++i) {\n      for (int64 j = 0; j < output_size[3]; ++j) {\n        DCHECK_EQ(tensor_out_dup_mat(j, i), tensor_out_mat(j, i));\n      }\n    }\n\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(context, context->forward_input_or_allocate_output(\n                                {0}, 0, tensor_in.shape(), &output));\n    output->flat<T>().setZero();\n\n    auto out_backprop_flat = out_backprop.flat<T>();\n    auto input_backprop_flat = output->flat<T>();\n    auto out_arg_max_flat = tensor_out_arg_max.flat<int64>();\n    int num_total_outputs = out_backprop_flat.size();\n    int num_total_inputs = input_backprop_flat.size();\n\n    for (int index = 0; index < num_total_outputs; ++index) {\n      int input_backprop_index = out_arg_max_flat(index);\n      // According to maxpooling_op.cc, the performance impact below is small.\n      CHECK(input_backprop_index >= 0 &&\n            input_backprop_index < num_total_inputs)\n          << \"Invalid input backprop index: \" << input_backprop_index << \", \"\n          << num_total_inputs;\n      input_backprop_flat(input_backprop_index) += out_backprop_flat(index);\n    }\n  }",
        "func": "void Compute(OpKernelContext* context) override {\n    // There are two steps when calculating gradient for FractionalMaxPool.\n    // 1) Walk through the process of calculating fractional pooling given\n    //    pooling region; however, in the process, keep track of where the max\n    //    element comes from. (arg_max)\n    // 2) Populate the value of out_backprop to where arg_max indicates. If\n    //    we support overlapping, it is likely to have multiple out_backprop[i]\n    //    propagates back to the same arg_max value.\n    typedef Eigen::Map<const Eigen::Matrix<T, Eigen::Dynamic, Eigen::Dynamic>>\n        ConstEigenMatrixMap;\n    typedef Eigen::Map<Eigen::Matrix<T, Eigen::Dynamic, Eigen::Dynamic>>\n        EigenMatrixMap;\n    typedef Eigen::Map<Eigen::Matrix<int64, Eigen::Dynamic, Eigen::Dynamic>>\n        EigenIndexMatrixMap;\n\n    const Tensor& tensor_in = context->input(0);\n    const Tensor& tensor_out = context->input(1);\n    const Tensor& out_backprop = context->input(2);\n    const Tensor& height_seq_tensor = context->input(3);\n    const Tensor& width_seq_tensor = context->input(4);\n\n    // Just to make it similar to FractionalMaxPoolOp.\n    constexpr int tensor_in_and_out_dims = 4;\n    OP_REQUIRES(\n        context, tensor_in.dims() == tensor_in_and_out_dims,\n        errors::InvalidArgument(\"orig_input should be a tensor of rank 4, got \",\n                                tensor_in.DebugString()));\n    OP_REQUIRES(context, tensor_in.NumElements() > 0,\n                errors::InvalidArgument(\"orig_input must not be empty, got \",\n                                        tensor_in.DebugString()));\n    OP_REQUIRES(context, tensor_out.dims() == tensor_in_and_out_dims,\n                errors::InvalidArgument(\n                    \"orig_output should be a tensor of rank 4, got \",\n                    tensor_out.DebugString()));\n    OP_REQUIRES(context, tensor_out.NumElements() > 0,\n                errors::InvalidArgument(\"orig_output must not be empty, got \",\n                                        tensor_out.DebugString()));\n    std::vector<int64> input_size(tensor_in_and_out_dims);\n    std::vector<int64> output_size(tensor_in_and_out_dims);\n    for (int i = 0; i < tensor_in_and_out_dims; ++i) {\n      input_size[i] = tensor_in.dim_size(i);\n    }\n    for (int i = 0; i < tensor_in_and_out_dims; ++i) {\n      output_size[i] = tensor_out.dim_size(i);\n    }\n\n    // ---------\n    // Step 1\n    // ---------\n    Tensor tensor_out_dup;\n    OP_REQUIRES_OK(context, context->forward_input_or_allocate_temp(\n                                {1}, DataTypeToEnum<T>::v(), tensor_out.shape(),\n                                &tensor_out_dup));\n    Tensor tensor_out_arg_max;\n    OP_REQUIRES_OK(context, context->allocate_temp(DataTypeToEnum<int64>::v(),\n                                                   tensor_out.shape(),\n                                                   &tensor_out_arg_max));\n    // Find arg_max for each tensor_out\n    ConstEigenMatrixMap tensor_in_mat(\n        tensor_in.flat<T>().data(), input_size[3],\n        input_size[2] * input_size[1] * input_size[0]);\n    EigenMatrixMap tensor_out_dup_mat(\n        tensor_out_dup.flat<T>().data(), output_size[3],\n        output_size[2] * output_size[1] * output_size[0]);\n    EigenIndexMatrixMap tensor_out_arg_max_mat(\n        tensor_out_arg_max.flat<int64>().data(), output_size[3],\n        output_size[2] * output_size[1] * output_size[0]);\n\n    tensor_out_arg_max.flat<int64>().setConstant(kInvalidMaxPoolingIndex);\n    // Initializes the duplicate output tensor with MIN<T>.\n    tensor_out_dup.flat<T>().setConstant(Eigen::NumTraits<T>::lowest());\n\n    auto height_seq_tensor_flat = height_seq_tensor.flat<int64>();\n    auto width_seq_tensor_flat = width_seq_tensor.flat<int64>();\n\n    // Now walk through the process of fractional max pooling again.\n    // For both input and output,\n    // 0: batch\n    // 1: height / row\n    // 2: width / col\n    // 3: depth / channel\n    const int64 height_max = input_size[1] - 1;\n    const int64 width_max = input_size[2] - 1;\n    for (int64 b = 0; b < input_size[0]; ++b) {\n      // height sequence.\n      for (int64 hs = 0; hs < height_seq_tensor.dim_size(0) - 1; ++hs) {\n        // height start and end.\n        const int64 height_start = height_seq_tensor_flat(hs);\n        int64 height_end = overlapping_ ? height_seq_tensor_flat(hs + 1)\n                                        : height_seq_tensor_flat(hs + 1) - 1;\n        height_end = std::min(height_end, height_max);\n\n        // width sequence.\n        for (int64 ws = 0; ws < width_seq_tensor.dim_size(0) - 1; ++ws) {\n          const int64 out_index =\n              (b * output_size[1] + hs) * output_size[2] + ws;\n          // width start and end.\n          const int64 width_start = width_seq_tensor_flat(ws);\n          int64 width_end = overlapping_ ? width_seq_tensor_flat(ws + 1)\n                                         : width_seq_tensor_flat(ws + 1) - 1;\n          width_end = std::min(width_end, width_max);\n          for (int64 h = height_start; h <= height_end; ++h) {\n            for (int64 w = width_start; w <= width_end; ++w) {\n              const int64 in_index =\n                  (b * input_size[1] + h) * input_size[2] + w;\n              // Walk through each channel (depth).\n              for (int64 d = 0; d < input_size[3]; ++d) {\n                const T& input_ref = tensor_in_mat.coeffRef(d, in_index);\n                T& output_ref = tensor_out_dup_mat.coeffRef(d, out_index);\n                int64& out_arg_max_ref =\n                    tensor_out_arg_max_mat.coeffRef(d, out_index);\n                if (output_ref < input_ref ||\n                    out_arg_max_ref == kInvalidMaxPoolingIndex) {\n                  output_ref = input_ref;\n                  int input_offset = in_index * input_size[3] + d;\n                  out_arg_max_ref = input_offset;\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n\n    // Check tensor_out_dup is the same as tensor_out.\n    ConstEigenMatrixMap tensor_out_mat(\n        tensor_out.flat<T>().data(), output_size[3],\n        output_size[2] * output_size[1] * output_size[0]);\n    const int64 num_reshaped_cols =\n        output_size[2] * output_size[1] * output_size[0];\n    for (int64 i = 0; i < num_reshaped_cols; ++i) {\n      for (int64 j = 0; j < output_size[3]; ++j) {\n        DCHECK_EQ(tensor_out_dup_mat(j, i), tensor_out_mat(j, i));\n      }\n    }\n\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(context, context->forward_input_or_allocate_output(\n                                {0}, 0, tensor_in.shape(), &output));\n    output->flat<T>().setZero();\n\n    auto out_backprop_flat = out_backprop.flat<T>();\n    auto input_backprop_flat = output->flat<T>();\n    auto out_arg_max_flat = tensor_out_arg_max.flat<int64>();\n    int num_total_outputs = out_backprop_flat.size();\n    int num_total_inputs = input_backprop_flat.size();\n\n    for (int index = 0; index < num_total_outputs; ++index) {\n      int input_backprop_index = out_arg_max_flat(index);\n      // According to maxpooling_op.cc, the performance impact below is small.\n      CHECK(input_backprop_index >= 0 &&\n            input_backprop_index < num_total_inputs)\n          << \"Invalid input backprop index: \" << input_backprop_index << \", \"\n          << num_total_inputs;\n      input_backprop_flat(input_backprop_index) += out_backprop_flat(index);\n    }\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -21,6 +21,20 @@\n \n     // Just to make it similar to FractionalMaxPoolOp.\n     constexpr int tensor_in_and_out_dims = 4;\n+    OP_REQUIRES(\n+        context, tensor_in.dims() == tensor_in_and_out_dims,\n+        errors::InvalidArgument(\"orig_input should be a tensor of rank 4, got \",\n+                                tensor_in.DebugString()));\n+    OP_REQUIRES(context, tensor_in.NumElements() > 0,\n+                errors::InvalidArgument(\"orig_input must not be empty, got \",\n+                                        tensor_in.DebugString()));\n+    OP_REQUIRES(context, tensor_out.dims() == tensor_in_and_out_dims,\n+                errors::InvalidArgument(\n+                    \"orig_output should be a tensor of rank 4, got \",\n+                    tensor_out.DebugString()));\n+    OP_REQUIRES(context, tensor_out.NumElements() > 0,\n+                errors::InvalidArgument(\"orig_output must not be empty, got \",\n+                                        tensor_out.DebugString()));\n     std::vector<int64> input_size(tensor_in_and_out_dims);\n     std::vector<int64> output_size(tensor_in_and_out_dims);\n     for (int i = 0; i < tensor_in_and_out_dims; ++i) {",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    OP_REQUIRES(",
                "        context, tensor_in.dims() == tensor_in_and_out_dims,",
                "        errors::InvalidArgument(\"orig_input should be a tensor of rank 4, got \",",
                "                                tensor_in.DebugString()));",
                "    OP_REQUIRES(context, tensor_in.NumElements() > 0,",
                "                errors::InvalidArgument(\"orig_input must not be empty, got \",",
                "                                        tensor_in.DebugString()));",
                "    OP_REQUIRES(context, tensor_out.dims() == tensor_in_and_out_dims,",
                "                errors::InvalidArgument(",
                "                    \"orig_output should be a tensor of rank 4, got \",",
                "                    tensor_out.DebugString()));",
                "    OP_REQUIRES(context, tensor_out.NumElements() > 0,",
                "                errors::InvalidArgument(\"orig_output must not be empty, got \",",
                "                                        tensor_out.DebugString()));"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-29581",
        "func_name": "tensorflow/ValidateInputsGenerateOutputs",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. Due to lack of validation in `tf.raw_ops.CTCBeamSearchDecoder`, an attacker can trigger denial of service via segmentation faults. The implementation(https://github.com/tensorflow/tensorflow/blob/a74768f8e4efbda4def9f16ee7e13cf3922ac5f7/tensorflow/core/kernels/ctc_decoder_ops.cc#L68-L79) fails to detect cases when the input tensor is empty and proceeds to read data from a null buffer. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/b1b323042264740c398140da32e93fb9c2c9f33e",
        "commit_title": "Fix SEGV in CTC ops",
        "commit_text": " PiperOrigin-RevId: 372430279",
        "func_before": "Status ValidateInputsGenerateOutputs(\n      OpKernelContext* ctx, const Tensor** inputs, const Tensor** seq_len,\n      Tensor** log_prob, OpOutputList* decoded_indices,\n      OpOutputList* decoded_values, OpOutputList* decoded_shape) const {\n    Status status = ctx->input(\"inputs\", inputs);\n    if (!status.ok()) return status;\n    status = ctx->input(\"sequence_length\", seq_len);\n    if (!status.ok()) return status;\n\n    const TensorShape& inputs_shape = (*inputs)->shape();\n\n    if (inputs_shape.dims() != 3) {\n      return errors::InvalidArgument(\"inputs is not a 3-Tensor\");\n    }\n\n    const int64 max_time = inputs_shape.dim_size(0);\n    const int64 batch_size = inputs_shape.dim_size(1);\n\n    if (max_time == 0) {\n      return errors::InvalidArgument(\"max_time is 0\");\n    }\n    if (!TensorShapeUtils::IsVector((*seq_len)->shape())) {\n      return errors::InvalidArgument(\"sequence_length is not a vector\");\n    }\n\n    if (!(batch_size == (*seq_len)->dim_size(0))) {\n      return errors::FailedPrecondition(\n          \"len(sequence_length) != batch_size.  \",\n          \"len(sequence_length):  \", (*seq_len)->dim_size(0),\n          \" batch_size: \", batch_size);\n    }\n\n    auto seq_len_t = (*seq_len)->vec<int32>();\n\n    for (int b = 0; b < batch_size; ++b) {\n      if (!(seq_len_t(b) <= max_time)) {\n        return errors::FailedPrecondition(\"sequence_length(\", b,\n                                          \") <= \", max_time);\n      }\n    }\n\n    Status s = ctx->allocate_output(\n        \"log_probability\", TensorShape({batch_size, top_paths_}), log_prob);\n    if (!s.ok()) return s;\n\n    s = ctx->output_list(\"decoded_indices\", decoded_indices);\n    if (!s.ok()) return s;\n    s = ctx->output_list(\"decoded_values\", decoded_values);\n    if (!s.ok()) return s;\n    s = ctx->output_list(\"decoded_shape\", decoded_shape);\n    if (!s.ok()) return s;\n\n    return Status::OK();\n  }",
        "func": "Status ValidateInputsGenerateOutputs(\n      OpKernelContext* ctx, const Tensor** inputs, const Tensor** seq_len,\n      Tensor** log_prob, OpOutputList* decoded_indices,\n      OpOutputList* decoded_values, OpOutputList* decoded_shape) const {\n    Status status = ctx->input(\"inputs\", inputs);\n    if (!status.ok()) return status;\n    status = ctx->input(\"sequence_length\", seq_len);\n    if (!status.ok()) return status;\n\n    const TensorShape& inputs_shape = (*inputs)->shape();\n\n    if (inputs_shape.dims() != 3) {\n      return errors::InvalidArgument(\"inputs is not a 3-Tensor\");\n    }\n    if (inputs_shape.num_elements() == 0) {\n      return errors::InvalidArgument(\"inputs must not be empty\");\n    }\n\n    const int64 max_time = inputs_shape.dim_size(0);\n    const int64 batch_size = inputs_shape.dim_size(1);\n\n    if (max_time == 0) {\n      return errors::InvalidArgument(\"max_time is 0\");\n    }\n    if (!TensorShapeUtils::IsVector((*seq_len)->shape())) {\n      return errors::InvalidArgument(\"sequence_length is not a vector\");\n    }\n\n    if (!(batch_size == (*seq_len)->dim_size(0))) {\n      return errors::FailedPrecondition(\n          \"len(sequence_length) != batch_size.  \",\n          \"len(sequence_length):  \", (*seq_len)->dim_size(0),\n          \" batch_size: \", batch_size);\n    }\n\n    auto seq_len_t = (*seq_len)->vec<int32>();\n\n    for (int b = 0; b < batch_size; ++b) {\n      if (!(seq_len_t(b) <= max_time)) {\n        return errors::FailedPrecondition(\"sequence_length(\", b,\n                                          \") <= \", max_time);\n      }\n    }\n\n    Status s = ctx->allocate_output(\n        \"log_probability\", TensorShape({batch_size, top_paths_}), log_prob);\n    if (!s.ok()) return s;\n\n    s = ctx->output_list(\"decoded_indices\", decoded_indices);\n    if (!s.ok()) return s;\n    s = ctx->output_list(\"decoded_values\", decoded_values);\n    if (!s.ok()) return s;\n    s = ctx->output_list(\"decoded_shape\", decoded_shape);\n    if (!s.ok()) return s;\n\n    return Status::OK();\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -11,6 +11,9 @@\n \n     if (inputs_shape.dims() != 3) {\n       return errors::InvalidArgument(\"inputs is not a 3-Tensor\");\n+    }\n+    if (inputs_shape.num_elements() == 0) {\n+      return errors::InvalidArgument(\"inputs must not be empty\");\n     }\n \n     const int64 max_time = inputs_shape.dim_size(0);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    }",
                "    if (inputs_shape.num_elements() == 0) {",
                "      return errors::InvalidArgument(\"inputs must not be empty\");"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-19535",
        "func_name": "torvalds/linux/pcan_usb_fd_init",
        "description": "In the Linux kernel before 5.2.9, there is an info-leak bug that can be caused by a malicious USB device in the drivers/net/can/usb/peak_usb/pcan_usb_fd.c driver, aka CID-30a8beeb3042.",
        "git_url": "https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?h=30a8beeb3042f49d0537b7050fd21b490166a3d9",
        "commit_title": "Uninitialized Kernel memory can leak to USB devices.",
        "commit_text": " Fix by using kzalloc() instead of kmalloc() on the affected buffers.  Cc: linux-stable <stable@vger.kernel.org> ",
        "func_before": "static int pcan_usb_fd_init(struct peak_usb_device *dev)\n{\n\tstruct pcan_usb_fd_device *pdev =\n\t\t\tcontainer_of(dev, struct pcan_usb_fd_device, dev);\n\tint i, err = -ENOMEM;\n\n\t/* do this for 1st channel only */\n\tif (!dev->prev_siblings) {\n\t\t/* allocate netdevices common structure attached to first one */\n\t\tpdev->usb_if = kzalloc(sizeof(*pdev->usb_if), GFP_KERNEL);\n\t\tif (!pdev->usb_if)\n\t\t\tgoto err_out;\n\n\t\t/* allocate command buffer once for all for the interface */\n\t\tpdev->cmd_buffer_addr = kmalloc(PCAN_UFD_CMD_BUFFER_SIZE,\n\t\t\t\t\t\tGFP_KERNEL);\n\t\tif (!pdev->cmd_buffer_addr)\n\t\t\tgoto err_out_1;\n\n\t\t/* number of ts msgs to ignore before taking one into account */\n\t\tpdev->usb_if->cm_ignore_count = 5;\n\n\t\terr = pcan_usb_pro_send_req(dev, PCAN_USBPRO_REQ_INFO,\n\t\t\t\t\t    PCAN_USBPRO_INFO_FW,\n\t\t\t\t\t    &pdev->usb_if->fw_info,\n\t\t\t\t\t    sizeof(pdev->usb_if->fw_info));\n\t\tif (err) {\n\t\t\tdev_err(dev->netdev->dev.parent,\n\t\t\t\t\"unable to read %s firmware info (err %d)\\n\",\n\t\t\t\tdev->adapter->name, err);\n\t\t\tgoto err_out_2;\n\t\t}\n\n\t\t/* explicit use of dev_xxx() instead of netdev_xxx() here:\n\t\t * information displayed are related to the device itself, not\n\t\t * to the canx (channel) device.\n\t\t */\n\t\tdev_info(dev->netdev->dev.parent,\n\t\t\t \"PEAK-System %s v%u fw v%u.%u.%u (%u channels)\\n\",\n\t\t\t dev->adapter->name, pdev->usb_if->fw_info.hw_version,\n\t\t\t pdev->usb_if->fw_info.fw_version[0],\n\t\t\t pdev->usb_if->fw_info.fw_version[1],\n\t\t\t pdev->usb_if->fw_info.fw_version[2],\n\t\t\t dev->adapter->ctrl_count);\n\n\t\t/* check for ability to switch between ISO/non-ISO modes */\n\t\tif (pdev->usb_if->fw_info.fw_version[0] >= 2) {\n\t\t\t/* firmware >= 2.x supports ISO/non-ISO switching */\n\t\t\tdev->can.ctrlmode_supported |= CAN_CTRLMODE_FD_NON_ISO;\n\t\t} else {\n\t\t\t/* firmware < 2.x only supports fixed(!) non-ISO */\n\t\t\tdev->can.ctrlmode |= CAN_CTRLMODE_FD_NON_ISO;\n\t\t}\n\n\t\t/* tell the hardware the can driver is running */\n\t\terr = pcan_usb_fd_drv_loaded(dev, 1);\n\t\tif (err) {\n\t\t\tdev_err(dev->netdev->dev.parent,\n\t\t\t\t\"unable to tell %s driver is loaded (err %d)\\n\",\n\t\t\t\tdev->adapter->name, err);\n\t\t\tgoto err_out_2;\n\t\t}\n\t} else {\n\t\t/* otherwise, simply copy previous sibling's values */\n\t\tstruct pcan_usb_fd_device *ppdev =\n\t\t\tcontainer_of(dev->prev_siblings,\n\t\t\t\t     struct pcan_usb_fd_device, dev);\n\n\t\tpdev->usb_if = ppdev->usb_if;\n\t\tpdev->cmd_buffer_addr = ppdev->cmd_buffer_addr;\n\n\t\t/* do a copy of the ctrlmode[_supported] too */\n\t\tdev->can.ctrlmode = ppdev->dev.can.ctrlmode;\n\t\tdev->can.ctrlmode_supported = ppdev->dev.can.ctrlmode_supported;\n\t}\n\n\tpdev->usb_if->dev[dev->ctrl_idx] = dev;\n\tdev->device_number =\n\t\tle32_to_cpu(pdev->usb_if->fw_info.dev_id[dev->ctrl_idx]);\n\n\t/* set clock domain */\n\tfor (i = 0; i < ARRAY_SIZE(pcan_usb_fd_clk_freq); i++)\n\t\tif (dev->adapter->clock.freq == pcan_usb_fd_clk_freq[i])\n\t\t\tbreak;\n\n\tif (i >= ARRAY_SIZE(pcan_usb_fd_clk_freq)) {\n\t\tdev_warn(dev->netdev->dev.parent,\n\t\t\t \"incompatible clock frequencies\\n\");\n\t\terr = -EINVAL;\n\t\tgoto err_out_2;\n\t}\n\n\tpcan_usb_fd_set_clock_domain(dev, i);\n\n\t/* set LED in default state (end of init phase) */\n\tpcan_usb_fd_set_can_led(dev, PCAN_UFD_LED_DEF);\n\n\treturn 0;\n\nerr_out_2:\n\tkfree(pdev->cmd_buffer_addr);\nerr_out_1:\n\tkfree(pdev->usb_if);\nerr_out:\n\treturn err;\n}",
        "func": "static int pcan_usb_fd_init(struct peak_usb_device *dev)\n{\n\tstruct pcan_usb_fd_device *pdev =\n\t\t\tcontainer_of(dev, struct pcan_usb_fd_device, dev);\n\tint i, err = -ENOMEM;\n\n\t/* do this for 1st channel only */\n\tif (!dev->prev_siblings) {\n\t\t/* allocate netdevices common structure attached to first one */\n\t\tpdev->usb_if = kzalloc(sizeof(*pdev->usb_if), GFP_KERNEL);\n\t\tif (!pdev->usb_if)\n\t\t\tgoto err_out;\n\n\t\t/* allocate command buffer once for all for the interface */\n\t\tpdev->cmd_buffer_addr = kzalloc(PCAN_UFD_CMD_BUFFER_SIZE,\n\t\t\t\t\t\tGFP_KERNEL);\n\t\tif (!pdev->cmd_buffer_addr)\n\t\t\tgoto err_out_1;\n\n\t\t/* number of ts msgs to ignore before taking one into account */\n\t\tpdev->usb_if->cm_ignore_count = 5;\n\n\t\terr = pcan_usb_pro_send_req(dev, PCAN_USBPRO_REQ_INFO,\n\t\t\t\t\t    PCAN_USBPRO_INFO_FW,\n\t\t\t\t\t    &pdev->usb_if->fw_info,\n\t\t\t\t\t    sizeof(pdev->usb_if->fw_info));\n\t\tif (err) {\n\t\t\tdev_err(dev->netdev->dev.parent,\n\t\t\t\t\"unable to read %s firmware info (err %d)\\n\",\n\t\t\t\tdev->adapter->name, err);\n\t\t\tgoto err_out_2;\n\t\t}\n\n\t\t/* explicit use of dev_xxx() instead of netdev_xxx() here:\n\t\t * information displayed are related to the device itself, not\n\t\t * to the canx (channel) device.\n\t\t */\n\t\tdev_info(dev->netdev->dev.parent,\n\t\t\t \"PEAK-System %s v%u fw v%u.%u.%u (%u channels)\\n\",\n\t\t\t dev->adapter->name, pdev->usb_if->fw_info.hw_version,\n\t\t\t pdev->usb_if->fw_info.fw_version[0],\n\t\t\t pdev->usb_if->fw_info.fw_version[1],\n\t\t\t pdev->usb_if->fw_info.fw_version[2],\n\t\t\t dev->adapter->ctrl_count);\n\n\t\t/* check for ability to switch between ISO/non-ISO modes */\n\t\tif (pdev->usb_if->fw_info.fw_version[0] >= 2) {\n\t\t\t/* firmware >= 2.x supports ISO/non-ISO switching */\n\t\t\tdev->can.ctrlmode_supported |= CAN_CTRLMODE_FD_NON_ISO;\n\t\t} else {\n\t\t\t/* firmware < 2.x only supports fixed(!) non-ISO */\n\t\t\tdev->can.ctrlmode |= CAN_CTRLMODE_FD_NON_ISO;\n\t\t}\n\n\t\t/* tell the hardware the can driver is running */\n\t\terr = pcan_usb_fd_drv_loaded(dev, 1);\n\t\tif (err) {\n\t\t\tdev_err(dev->netdev->dev.parent,\n\t\t\t\t\"unable to tell %s driver is loaded (err %d)\\n\",\n\t\t\t\tdev->adapter->name, err);\n\t\t\tgoto err_out_2;\n\t\t}\n\t} else {\n\t\t/* otherwise, simply copy previous sibling's values */\n\t\tstruct pcan_usb_fd_device *ppdev =\n\t\t\tcontainer_of(dev->prev_siblings,\n\t\t\t\t     struct pcan_usb_fd_device, dev);\n\n\t\tpdev->usb_if = ppdev->usb_if;\n\t\tpdev->cmd_buffer_addr = ppdev->cmd_buffer_addr;\n\n\t\t/* do a copy of the ctrlmode[_supported] too */\n\t\tdev->can.ctrlmode = ppdev->dev.can.ctrlmode;\n\t\tdev->can.ctrlmode_supported = ppdev->dev.can.ctrlmode_supported;\n\t}\n\n\tpdev->usb_if->dev[dev->ctrl_idx] = dev;\n\tdev->device_number =\n\t\tle32_to_cpu(pdev->usb_if->fw_info.dev_id[dev->ctrl_idx]);\n\n\t/* set clock domain */\n\tfor (i = 0; i < ARRAY_SIZE(pcan_usb_fd_clk_freq); i++)\n\t\tif (dev->adapter->clock.freq == pcan_usb_fd_clk_freq[i])\n\t\t\tbreak;\n\n\tif (i >= ARRAY_SIZE(pcan_usb_fd_clk_freq)) {\n\t\tdev_warn(dev->netdev->dev.parent,\n\t\t\t \"incompatible clock frequencies\\n\");\n\t\terr = -EINVAL;\n\t\tgoto err_out_2;\n\t}\n\n\tpcan_usb_fd_set_clock_domain(dev, i);\n\n\t/* set LED in default state (end of init phase) */\n\tpcan_usb_fd_set_can_led(dev, PCAN_UFD_LED_DEF);\n\n\treturn 0;\n\nerr_out_2:\n\tkfree(pdev->cmd_buffer_addr);\nerr_out_1:\n\tkfree(pdev->usb_if);\nerr_out:\n\treturn err;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -12,7 +12,7 @@\n \t\t\tgoto err_out;\n \n \t\t/* allocate command buffer once for all for the interface */\n-\t\tpdev->cmd_buffer_addr = kmalloc(PCAN_UFD_CMD_BUFFER_SIZE,\n+\t\tpdev->cmd_buffer_addr = kzalloc(PCAN_UFD_CMD_BUFFER_SIZE,\n \t\t\t\t\t\tGFP_KERNEL);\n \t\tif (!pdev->cmd_buffer_addr)\n \t\t\tgoto err_out_1;",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tpdev->cmd_buffer_addr = kmalloc(PCAN_UFD_CMD_BUFFER_SIZE,"
            ],
            "added_lines": [
                "\t\tpdev->cmd_buffer_addr = kzalloc(PCAN_UFD_CMD_BUFFER_SIZE,"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-41225",
        "func_name": "tensorflow/AutoParallel::Initialize",
        "description": "TensorFlow is an open source platform for machine learning. In affected versions TensorFlow's Grappler optimizer has a use of unitialized variable. If the `train_nodes` vector (obtained from the saved model that gets optimized) does not contain a `Dequeue` node, then `dequeue_node` is left unitialized. The fix will be included in TensorFlow 2.7.0. We will also cherrypick this commit on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/68867bf01239d9e1048f98cbad185bf4761bedd3",
        "commit_title": "Prevent unitialized variable use in grappler.",
        "commit_text": " PiperOrigin-RevId: 399702928",
        "func_before": "Status AutoParallel::Initialize(const GrapplerItem& item) {\n  num_gpus_ = GetNumAvailableGPUs();\n  LOG(INFO) << \"Number of GPUs: \" << num_gpus_;\n  item_ = &item;\n  graph_ = item.graph;\n  LOG(INFO) << \"Original graph size: \" << graph_.node_size();\n  if (item.fetch.empty()) {\n    return Status(error::INVALID_ARGUMENT, \"No fetch nodes provided.\");\n  }\n\n  if (item.MainVariables().empty()) {\n    return Status(error::INVALID_ARGUMENT, \"No variables provided.\");\n  }\n\n  for (const auto& init : item.init_ops) {\n    VLOG(1) << \"Init node: \" << init;\n  }\n\n  for (const auto& fetch : item.fetch) {\n    VLOG(1) << \"Fetch node: \" << fetch;\n  }\n\n  for (const auto& var : item.MainVariables()) {\n    VLOG(2) << \"Variable: \" << var->name();\n  }\n\n  const std::set<string> apply_gradients_ops = {\"ApplyGradientDescent\",\n                                                \"ApplyProximalGradientDescent\",\n                                                \"ApplyAdadelta\",\n                                                \"ApplyAdagrad\",\n                                                \"ApplyProximalAdagrad\",\n                                                \"ApplyAdagradDA\",\n                                                \"ApplyFtrl\",\n                                                \"ApplyMomentum\",\n                                                \"ApplyAdam\",\n                                                \"ApplyRMSProp\",\n                                                \"ApplyCenteredRMSProp\"};\n  for (int i = 0; i < graph_.node_size(); i++) {\n    all_nodes_.insert(\n        std::make_pair(graph_.node(i).name(), graph_.mutable_node(i)));\n    if (apply_gradients_ops.find(graph_.node(i).op()) !=\n        apply_gradients_ops.end()) {\n      apply_gradients_nodes_.insert(graph_.node(i).name());\n      VLOG(2) << \"Apply gradients node: \" << graph_.node(i).name();\n    }\n  }\n\n  auto div_const_node = AddNodeDivConst();\n  all_nodes_.insert(std::make_pair(div_const_node->name(), div_const_node));\n  std::map<string, int> gradient_pos = {{\"ApplyGradientDescent\", 2},\n                                        {\"ApplyProximalGradientDescent\", 4},\n                                        {\"ApplyAdadelta\", 6},\n                                        {\"ApplyAdagrad\", 3},\n                                        {\"ApplyProximalAdagrad\", 5},\n                                        {\"ApplyAdagradDA\", 3},\n                                        {\"ApplyFtrl\", 3},\n                                        {\"ApplyMomentum\", 3},\n                                        {\"ApplyAdam\", 9},\n                                        {\"ApplyRMSProp\", 7},\n                                        {\"ApplyCenteredRMSProp\", 8}};\n  for (const auto& apply_gradient_node_name : apply_gradients_nodes_) {\n    auto apply_gradients_op = all_nodes_[apply_gradient_node_name]->op();\n    auto apply_gradients_node = all_nodes_[apply_gradient_node_name];\n\n    auto div_node = AddNodeDiv(\n        apply_gradient_node_name,\n        apply_gradients_node->input(gradient_pos[apply_gradients_op]),\n        div_const_node->name());\n    all_nodes_.insert(std::make_pair(div_node->name(), div_node));\n    *apply_gradients_node->mutable_input(gradient_pos[apply_gradients_op]) =\n        div_node->name();\n  }\n  LOG(INFO) << \"Graph size after adding div nodes: \" << all_nodes_.size();\n\n  std::vector<const NodeDef*> train_nodes;\n  TF_RETURN_IF_ERROR(ComputeTransitiveFanin(graph_, item.fetch, &train_nodes));\n  LOG(INFO) << \"Number of training nodes: \" << train_nodes.size();\n\n  const NodeDef* dequeue_node;\n  for (const auto& train_node : train_nodes) {\n    if (IsDequeueOp(*train_node)) {\n      dequeue_node = train_node;\n      break;\n    }\n  }\n\n  std::vector<const NodeDef*> input_nodes;\n  if (dequeue_node) {\n    LOG(INFO) << \"Dequeue node: \" << dequeue_node->name();\n    TF_RETURN_IF_ERROR(ComputeTransitiveFanin(graph_, {dequeue_node->name()},\n                                              {}, &input_nodes));\n  }\n  LOG(INFO) << \"Number of input nodes: \" << input_nodes.size();\n\n  std::set<string> dont_replicate_nodes;\n  for (const auto& variable : item.MainVariables()) {\n    dont_replicate_nodes.insert(variable->name());\n  }\n\n  for (const auto& init : item.init_ops) {\n    dont_replicate_nodes.insert(NodeName(init));\n  }\n\n  // Don't replicate all input nodes, except the dequeue node.\n  for (const auto& input_node : input_nodes) {\n    if (input_node->name() != dequeue_node->name()) {\n      dont_replicate_nodes.insert(input_node->name());\n    }\n  }\n\n  for (const auto& node : train_nodes) {\n    if (dont_replicate_nodes.find(node->name()) == dont_replicate_nodes.end()) {\n      replica_nodes_.insert(node->name());\n    }\n  }\n  LOG(INFO) << \"Number of replica nodes: \" << replica_nodes_.size();\n\n  for (const auto& node : all_nodes_) {\n    if (replica_nodes_.find(node.first) == replica_nodes_.end()) {\n      shared_nodes_.insert(node.first);\n    }\n  }\n  LOG(INFO) << \"Number of shared nodes: \" << shared_nodes_.size();\n  return Status::OK();\n}",
        "func": "Status AutoParallel::Initialize(const GrapplerItem& item) {\n  num_gpus_ = GetNumAvailableGPUs();\n  LOG(INFO) << \"Number of GPUs: \" << num_gpus_;\n  item_ = &item;\n  graph_ = item.graph;\n  LOG(INFO) << \"Original graph size: \" << graph_.node_size();\n  if (item.fetch.empty()) {\n    return Status(error::INVALID_ARGUMENT, \"No fetch nodes provided.\");\n  }\n\n  if (item.MainVariables().empty()) {\n    return Status(error::INVALID_ARGUMENT, \"No variables provided.\");\n  }\n\n  for (const auto& init : item.init_ops) {\n    VLOG(1) << \"Init node: \" << init;\n  }\n\n  for (const auto& fetch : item.fetch) {\n    VLOG(1) << \"Fetch node: \" << fetch;\n  }\n\n  for (const auto& var : item.MainVariables()) {\n    VLOG(2) << \"Variable: \" << var->name();\n  }\n\n  const std::set<string> apply_gradients_ops = {\"ApplyGradientDescent\",\n                                                \"ApplyProximalGradientDescent\",\n                                                \"ApplyAdadelta\",\n                                                \"ApplyAdagrad\",\n                                                \"ApplyProximalAdagrad\",\n                                                \"ApplyAdagradDA\",\n                                                \"ApplyFtrl\",\n                                                \"ApplyMomentum\",\n                                                \"ApplyAdam\",\n                                                \"ApplyRMSProp\",\n                                                \"ApplyCenteredRMSProp\"};\n  for (int i = 0; i < graph_.node_size(); i++) {\n    all_nodes_.insert(\n        std::make_pair(graph_.node(i).name(), graph_.mutable_node(i)));\n    if (apply_gradients_ops.find(graph_.node(i).op()) !=\n        apply_gradients_ops.end()) {\n      apply_gradients_nodes_.insert(graph_.node(i).name());\n      VLOG(2) << \"Apply gradients node: \" << graph_.node(i).name();\n    }\n  }\n\n  auto div_const_node = AddNodeDivConst();\n  all_nodes_.insert(std::make_pair(div_const_node->name(), div_const_node));\n  std::map<string, int> gradient_pos = {{\"ApplyGradientDescent\", 2},\n                                        {\"ApplyProximalGradientDescent\", 4},\n                                        {\"ApplyAdadelta\", 6},\n                                        {\"ApplyAdagrad\", 3},\n                                        {\"ApplyProximalAdagrad\", 5},\n                                        {\"ApplyAdagradDA\", 3},\n                                        {\"ApplyFtrl\", 3},\n                                        {\"ApplyMomentum\", 3},\n                                        {\"ApplyAdam\", 9},\n                                        {\"ApplyRMSProp\", 7},\n                                        {\"ApplyCenteredRMSProp\", 8}};\n  for (const auto& apply_gradient_node_name : apply_gradients_nodes_) {\n    auto apply_gradients_op = all_nodes_[apply_gradient_node_name]->op();\n    auto apply_gradients_node = all_nodes_[apply_gradient_node_name];\n\n    auto div_node = AddNodeDiv(\n        apply_gradient_node_name,\n        apply_gradients_node->input(gradient_pos[apply_gradients_op]),\n        div_const_node->name());\n    all_nodes_.insert(std::make_pair(div_node->name(), div_node));\n    *apply_gradients_node->mutable_input(gradient_pos[apply_gradients_op]) =\n        div_node->name();\n  }\n  LOG(INFO) << \"Graph size after adding div nodes: \" << all_nodes_.size();\n\n  std::vector<const NodeDef*> train_nodes;\n  TF_RETURN_IF_ERROR(ComputeTransitiveFanin(graph_, item.fetch, &train_nodes));\n  LOG(INFO) << \"Number of training nodes: \" << train_nodes.size();\n\n  const NodeDef* dequeue_node = nullptr;\n  for (const auto& train_node : train_nodes) {\n    if (IsDequeueOp(*train_node)) {\n      dequeue_node = train_node;\n      break;\n    }\n  }\n\n  std::vector<const NodeDef*> input_nodes;\n  if (dequeue_node) {\n    LOG(INFO) << \"Dequeue node: \" << dequeue_node->name();\n    TF_RETURN_IF_ERROR(ComputeTransitiveFanin(graph_, {dequeue_node->name()},\n                                              {}, &input_nodes));\n  }\n  LOG(INFO) << \"Number of input nodes: \" << input_nodes.size();\n\n  std::set<string> dont_replicate_nodes;\n  for (const auto& variable : item.MainVariables()) {\n    dont_replicate_nodes.insert(variable->name());\n  }\n\n  for (const auto& init : item.init_ops) {\n    dont_replicate_nodes.insert(NodeName(init));\n  }\n\n  // Don't replicate all input nodes, except the dequeue node.\n  for (const auto& input_node : input_nodes) {\n    if (input_node->name() != dequeue_node->name()) {\n      dont_replicate_nodes.insert(input_node->name());\n    }\n  }\n\n  for (const auto& node : train_nodes) {\n    if (dont_replicate_nodes.find(node->name()) == dont_replicate_nodes.end()) {\n      replica_nodes_.insert(node->name());\n    }\n  }\n  LOG(INFO) << \"Number of replica nodes: \" << replica_nodes_.size();\n\n  for (const auto& node : all_nodes_) {\n    if (replica_nodes_.find(node.first) == replica_nodes_.end()) {\n      shared_nodes_.insert(node.first);\n    }\n  }\n  LOG(INFO) << \"Number of shared nodes: \" << shared_nodes_.size();\n  return Status::OK();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -76,7 +76,7 @@\n   TF_RETURN_IF_ERROR(ComputeTransitiveFanin(graph_, item.fetch, &train_nodes));\n   LOG(INFO) << \"Number of training nodes: \" << train_nodes.size();\n \n-  const NodeDef* dequeue_node;\n+  const NodeDef* dequeue_node = nullptr;\n   for (const auto& train_node : train_nodes) {\n     if (IsDequeueOp(*train_node)) {\n       dequeue_node = train_node;",
        "diff_line_info": {
            "deleted_lines": [
                "  const NodeDef* dequeue_node;"
            ],
            "added_lines": [
                "  const NodeDef* dequeue_node = nullptr;"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-41253",
        "func_name": "zyantific/zydis/ZydisFormatterBufferInitTokenized",
        "description": "Zydis is an x86/x86-64 disassembler library. Users of Zydis versions v3.2.0 and older that use the string functions provided in `zycore` in order to append untrusted user data to the formatter buffer within their custom formatter hooks can run into heap buffer overflows. Older versions of Zydis failed to properly initialize the string object within the formatter buffer, forgetting to initialize a few fields, leaving their value to chance. This could then in turn cause zycore functions like `ZyanStringAppend` to make incorrect calculations for the new target size, resulting in heap memory corruption. This does not affect the regular uncustomized Zydis formatter, because Zydis internally doesn't use the string functions in zycore that act upon these fields. However, because the zycore string functions are the intended way to work with the formatter buffer for users of the library that wish to extend the formatter, we still consider this to be a vulnerability in Zydis. This bug is patched starting in version 3.2.1. As a workaround, users may refrain from using zycore string functions in their formatter hooks until updating to a patched version.",
        "git_url": "https://github.com/zyantific/zydis/commit/55dd08c210722aed81b38132f5fd4a04ec1943b5",
        "commit_title": "Fix struct initialization in formatter",
        "commit_text": "",
        "func_before": "void ZydisFormatterBufferInitTokenized(ZydisFormatterBuffer* buffer,\n    ZydisFormatterToken** first_token, void* user_buffer, ZyanUSize length)\n{\n    ZYAN_ASSERT(buffer);\n    ZYAN_ASSERT(first_token);\n    ZYAN_ASSERT(user_buffer);\n    ZYAN_ASSERT(length);\n\n    *first_token = user_buffer;\n    (*first_token)->type = ZYDIS_TOKEN_INVALID;\n    (*first_token)->next = 0;\n\n    user_buffer = (ZyanU8*)user_buffer + sizeof(ZydisFormatterToken);\n    length -= sizeof(ZydisFormatterToken);\n\n    buffer->is_token_list              = ZYAN_TRUE;\n    buffer->capacity                   = length;\n    buffer->string.flags               = ZYAN_STRING_HAS_FIXED_CAPACITY;\n    buffer->string.vector.allocator    = ZYAN_NULL;\n    buffer->string.vector.element_size = sizeof(char);\n    buffer->string.vector.size         = 1;\n    buffer->string.vector.capacity     = length;\n    buffer->string.vector.data         = user_buffer;\n    *(char*)user_buffer = '\\0';\n}",
        "func": "void ZydisFormatterBufferInitTokenized(ZydisFormatterBuffer* buffer,\n    ZydisFormatterToken** first_token, void* user_buffer, ZyanUSize length)\n{\n    ZYAN_ASSERT(buffer);\n    ZYAN_ASSERT(first_token);\n    ZYAN_ASSERT(user_buffer);\n    ZYAN_ASSERT(length);\n\n    *first_token = user_buffer;\n    (*first_token)->type = ZYDIS_TOKEN_INVALID;\n    (*first_token)->next = 0;\n\n    user_buffer = (ZyanU8*)user_buffer + sizeof(ZydisFormatterToken);\n    length -= sizeof(ZydisFormatterToken);\n\n    buffer->is_token_list                  = ZYAN_TRUE;\n    buffer->capacity                       = length;\n    buffer->string.flags                   = ZYAN_STRING_HAS_FIXED_CAPACITY;\n    buffer->string.vector.allocator        = ZYAN_NULL;\n    buffer->string.vector.growth_factor    = 1;\n    buffer->string.vector.shrink_threshold = 0;\n    buffer->string.vector.destructor       = ZYAN_NULL;\n    buffer->string.vector.element_size     = sizeof(char);\n    buffer->string.vector.size             = 1;\n    buffer->string.vector.capacity         = length;\n    buffer->string.vector.data             = user_buffer;\n\n    *(char*)user_buffer = '\\0';\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -13,13 +13,17 @@\n     user_buffer = (ZyanU8*)user_buffer + sizeof(ZydisFormatterToken);\n     length -= sizeof(ZydisFormatterToken);\n \n-    buffer->is_token_list              = ZYAN_TRUE;\n-    buffer->capacity                   = length;\n-    buffer->string.flags               = ZYAN_STRING_HAS_FIXED_CAPACITY;\n-    buffer->string.vector.allocator    = ZYAN_NULL;\n-    buffer->string.vector.element_size = sizeof(char);\n-    buffer->string.vector.size         = 1;\n-    buffer->string.vector.capacity     = length;\n-    buffer->string.vector.data         = user_buffer;\n+    buffer->is_token_list                  = ZYAN_TRUE;\n+    buffer->capacity                       = length;\n+    buffer->string.flags                   = ZYAN_STRING_HAS_FIXED_CAPACITY;\n+    buffer->string.vector.allocator        = ZYAN_NULL;\n+    buffer->string.vector.growth_factor    = 1;\n+    buffer->string.vector.shrink_threshold = 0;\n+    buffer->string.vector.destructor       = ZYAN_NULL;\n+    buffer->string.vector.element_size     = sizeof(char);\n+    buffer->string.vector.size             = 1;\n+    buffer->string.vector.capacity         = length;\n+    buffer->string.vector.data             = user_buffer;\n+\n     *(char*)user_buffer = '\\0';\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    buffer->is_token_list              = ZYAN_TRUE;",
                "    buffer->capacity                   = length;",
                "    buffer->string.flags               = ZYAN_STRING_HAS_FIXED_CAPACITY;",
                "    buffer->string.vector.allocator    = ZYAN_NULL;",
                "    buffer->string.vector.element_size = sizeof(char);",
                "    buffer->string.vector.size         = 1;",
                "    buffer->string.vector.capacity     = length;",
                "    buffer->string.vector.data         = user_buffer;"
            ],
            "added_lines": [
                "    buffer->is_token_list                  = ZYAN_TRUE;",
                "    buffer->capacity                       = length;",
                "    buffer->string.flags                   = ZYAN_STRING_HAS_FIXED_CAPACITY;",
                "    buffer->string.vector.allocator        = ZYAN_NULL;",
                "    buffer->string.vector.growth_factor    = 1;",
                "    buffer->string.vector.shrink_threshold = 0;",
                "    buffer->string.vector.destructor       = ZYAN_NULL;",
                "    buffer->string.vector.element_size     = sizeof(char);",
                "    buffer->string.vector.size             = 1;",
                "    buffer->string.vector.capacity         = length;",
                "    buffer->string.vector.data             = user_buffer;",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2021-41253",
        "func_name": "zyantific/zydis/ZydisFormatterBufferInit",
        "description": "Zydis is an x86/x86-64 disassembler library. Users of Zydis versions v3.2.0 and older that use the string functions provided in `zycore` in order to append untrusted user data to the formatter buffer within their custom formatter hooks can run into heap buffer overflows. Older versions of Zydis failed to properly initialize the string object within the formatter buffer, forgetting to initialize a few fields, leaving their value to chance. This could then in turn cause zycore functions like `ZyanStringAppend` to make incorrect calculations for the new target size, resulting in heap memory corruption. This does not affect the regular uncustomized Zydis formatter, because Zydis internally doesn't use the string functions in zycore that act upon these fields. However, because the zycore string functions are the intended way to work with the formatter buffer for users of the library that wish to extend the formatter, we still consider this to be a vulnerability in Zydis. This bug is patched starting in version 3.2.1. As a workaround, users may refrain from using zycore string functions in their formatter hooks until updating to a patched version.",
        "git_url": "https://github.com/zyantific/zydis/commit/55dd08c210722aed81b38132f5fd4a04ec1943b5",
        "commit_title": "Fix struct initialization in formatter",
        "commit_text": "",
        "func_before": "void ZydisFormatterBufferInit(ZydisFormatterBuffer* buffer, char* user_buffer,\n    ZyanUSize length)\n{\n    ZYAN_ASSERT(buffer);\n    ZYAN_ASSERT(user_buffer);\n    ZYAN_ASSERT(length);\n\n    buffer->is_token_list              = ZYAN_FALSE;\n    buffer->string.flags               = ZYAN_STRING_HAS_FIXED_CAPACITY;\n    buffer->string.vector.allocator    = ZYAN_NULL;\n    buffer->string.vector.element_size = sizeof(char);\n    buffer->string.vector.size         = 1;\n    buffer->string.vector.capacity     = length;\n    buffer->string.vector.data         = user_buffer;\n    *user_buffer = '\\0';\n}",
        "func": "void ZydisFormatterBufferInit(ZydisFormatterBuffer* buffer, char* user_buffer,\n    ZyanUSize length)\n{\n    ZYAN_ASSERT(buffer);\n    ZYAN_ASSERT(user_buffer);\n    ZYAN_ASSERT(length);\n\n    buffer->is_token_list                   = ZYAN_FALSE;\n    buffer->capacity                        = 0;\n    buffer->string.flags                    = ZYAN_STRING_HAS_FIXED_CAPACITY;\n    buffer->string.vector.allocator         = ZYAN_NULL;\n    buffer->string.vector.growth_factor     = 1;\n    buffer->string.vector.shrink_threshold  = 0;\n    buffer->string.vector.destructor        = ZYAN_NULL;\n    buffer->string.vector.element_size      = sizeof(char);\n    buffer->string.vector.size              = 1;\n    buffer->string.vector.capacity          = length;\n    buffer->string.vector.data              = user_buffer;\n\n    *user_buffer = '\\0';\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,12 +5,17 @@\n     ZYAN_ASSERT(user_buffer);\n     ZYAN_ASSERT(length);\n \n-    buffer->is_token_list              = ZYAN_FALSE;\n-    buffer->string.flags               = ZYAN_STRING_HAS_FIXED_CAPACITY;\n-    buffer->string.vector.allocator    = ZYAN_NULL;\n-    buffer->string.vector.element_size = sizeof(char);\n-    buffer->string.vector.size         = 1;\n-    buffer->string.vector.capacity     = length;\n-    buffer->string.vector.data         = user_buffer;\n+    buffer->is_token_list                   = ZYAN_FALSE;\n+    buffer->capacity                        = 0;\n+    buffer->string.flags                    = ZYAN_STRING_HAS_FIXED_CAPACITY;\n+    buffer->string.vector.allocator         = ZYAN_NULL;\n+    buffer->string.vector.growth_factor     = 1;\n+    buffer->string.vector.shrink_threshold  = 0;\n+    buffer->string.vector.destructor        = ZYAN_NULL;\n+    buffer->string.vector.element_size      = sizeof(char);\n+    buffer->string.vector.size              = 1;\n+    buffer->string.vector.capacity          = length;\n+    buffer->string.vector.data              = user_buffer;\n+\n     *user_buffer = '\\0';\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    buffer->is_token_list              = ZYAN_FALSE;",
                "    buffer->string.flags               = ZYAN_STRING_HAS_FIXED_CAPACITY;",
                "    buffer->string.vector.allocator    = ZYAN_NULL;",
                "    buffer->string.vector.element_size = sizeof(char);",
                "    buffer->string.vector.size         = 1;",
                "    buffer->string.vector.capacity     = length;",
                "    buffer->string.vector.data         = user_buffer;"
            ],
            "added_lines": [
                "    buffer->is_token_list                   = ZYAN_FALSE;",
                "    buffer->capacity                        = 0;",
                "    buffer->string.flags                    = ZYAN_STRING_HAS_FIXED_CAPACITY;",
                "    buffer->string.vector.allocator         = ZYAN_NULL;",
                "    buffer->string.vector.growth_factor     = 1;",
                "    buffer->string.vector.shrink_threshold  = 0;",
                "    buffer->string.vector.destructor        = ZYAN_NULL;",
                "    buffer->string.vector.element_size      = sizeof(char);",
                "    buffer->string.vector.size              = 1;",
                "    buffer->string.vector.capacity          = length;",
                "    buffer->string.vector.data              = user_buffer;",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2009-2692",
        "func_name": "torvalds/linux/sock_sendpage",
        "description": "The Linux kernel 2.6.0 through 2.6.30.4, and 2.4.4 through 2.4.37.4, does not initialize all function pointers for socket operations in proto_ops structures, which allows local users to trigger a NULL pointer dereference and gain privileges by using mmap to map page zero, placing arbitrary code on this page, and then invoking an unavailable operation, as demonstrated by the sendpage operation (sock_sendpage function) on a PF_PPPOX socket.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=e694958388c50148389b0e9b9e9e8945cf0f1b98",
        "commit_title": "kernel_sendpage() does the proper default case handling for when the",
        "commit_text": "socket doesn't have a native sendpage implementation.  Now, arguably this might be something that we could instead solve by just specifying that all protocols should do it themselves at the protocol level, but we really only care about the common protocols. Does anybody really care about sendpage on something like Appletalk? Not likely.  Cc: stable@kernel.org ",
        "func_before": "static ssize_t sock_sendpage(struct file *file, struct page *page,\n\t\t\t     int offset, size_t size, loff_t *ppos, int more)\n{\n\tstruct socket *sock;\n\tint flags;\n\n\tsock = file->private_data;\n\n\tflags = !(file->f_flags & O_NONBLOCK) ? 0 : MSG_DONTWAIT;\n\tif (more)\n\t\tflags |= MSG_MORE;\n\n\treturn sock->ops->sendpage(sock, page, offset, size, flags);\n}",
        "func": "static ssize_t sock_sendpage(struct file *file, struct page *page,\n\t\t\t     int offset, size_t size, loff_t *ppos, int more)\n{\n\tstruct socket *sock;\n\tint flags;\n\n\tsock = file->private_data;\n\n\tflags = !(file->f_flags & O_NONBLOCK) ? 0 : MSG_DONTWAIT;\n\tif (more)\n\t\tflags |= MSG_MORE;\n\n\treturn kernel_sendpage(sock, page, offset, size, flags);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -10,5 +10,5 @@\n \tif (more)\n \t\tflags |= MSG_MORE;\n \n-\treturn sock->ops->sendpage(sock, page, offset, size, flags);\n+\treturn kernel_sendpage(sock, page, offset, size, flags);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\treturn sock->ops->sendpage(sock, page, offset, size, flags);"
            ],
            "added_lines": [
                "\treturn kernel_sendpage(sock, page, offset, size, flags);"
            ]
        }
    },
    {
        "cve_id": "CVE-2009-3620",
        "func_name": "torvalds/linux/r128_cce_idle",
        "description": "The ATI Rage 128 (aka r128) driver in the Linux kernel before 2.6.31-git11 does not properly verify Concurrent Command Engine (CCE) state initialization, which allows local users to cause a denial of service (NULL pointer dereference and system crash) or possibly gain privileges via unspecified ioctl calls.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=7dc482dfeeeefcfd000d4271c4626937406756d7",
        "commit_title": "Almost all r128's private ioctls require that the CCE state has",
        "commit_text": "already been initialised.  However, most do not test that this has been done, and will proceed to dereference a null pointer.  This may result in a security vulnerability, since some ioctls are unprivileged.  This adds a macro for the common initialisation test and changes all ioctl implementations that require prior initialisation to use that macro.  Also, r128_do_init_cce() does not test that the CCE state has not been initialised already.  Repeated initialisation may lead to a crash or resource leak.  This adds that test.  ",
        "func_before": "int r128_cce_idle(struct drm_device *dev, void *data, struct drm_file *file_priv)\n{\n\tdrm_r128_private_t *dev_priv = dev->dev_private;\n\tDRM_DEBUG(\"\\n\");\n\n\tLOCK_TEST_WITH_RETURN(dev, file_priv);\n\n\tif (dev_priv->cce_running) {\n\t\tr128_do_cce_flush(dev_priv);\n\t}\n\n\treturn r128_do_cce_idle(dev_priv);\n}",
        "func": "int r128_cce_idle(struct drm_device *dev, void *data, struct drm_file *file_priv)\n{\n\tdrm_r128_private_t *dev_priv = dev->dev_private;\n\tDRM_DEBUG(\"\\n\");\n\n\tLOCK_TEST_WITH_RETURN(dev, file_priv);\n\n\tDEV_INIT_TEST_WITH_RETURN(dev_priv);\n\n\tif (dev_priv->cce_running) {\n\t\tr128_do_cce_flush(dev_priv);\n\t}\n\n\treturn r128_do_cce_idle(dev_priv);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,6 +5,8 @@\n \n \tLOCK_TEST_WITH_RETURN(dev, file_priv);\n \n+\tDEV_INIT_TEST_WITH_RETURN(dev_priv);\n+\n \tif (dev_priv->cce_running) {\n \t\tr128_do_cce_flush(dev_priv);\n \t}",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tDEV_INIT_TEST_WITH_RETURN(dev_priv);",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2009-3620",
        "func_name": "torvalds/linux/r128_cce_reset",
        "description": "The ATI Rage 128 (aka r128) driver in the Linux kernel before 2.6.31-git11 does not properly verify Concurrent Command Engine (CCE) state initialization, which allows local users to cause a denial of service (NULL pointer dereference and system crash) or possibly gain privileges via unspecified ioctl calls.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=7dc482dfeeeefcfd000d4271c4626937406756d7",
        "commit_title": "Almost all r128's private ioctls require that the CCE state has",
        "commit_text": "already been initialised.  However, most do not test that this has been done, and will proceed to dereference a null pointer.  This may result in a security vulnerability, since some ioctls are unprivileged.  This adds a macro for the common initialisation test and changes all ioctl implementations that require prior initialisation to use that macro.  Also, r128_do_init_cce() does not test that the CCE state has not been initialised already.  Repeated initialisation may lead to a crash or resource leak.  This adds that test.  ",
        "func_before": "int r128_cce_reset(struct drm_device *dev, void *data, struct drm_file *file_priv)\n{\n\tdrm_r128_private_t *dev_priv = dev->dev_private;\n\tDRM_DEBUG(\"\\n\");\n\n\tLOCK_TEST_WITH_RETURN(dev, file_priv);\n\n\tif (!dev_priv) {\n\t\tDRM_DEBUG(\"called before init done\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tr128_do_cce_reset(dev_priv);\n\n\t/* The CCE is no longer running after an engine reset */\n\tdev_priv->cce_running = 0;\n\n\treturn 0;\n}",
        "func": "int r128_cce_reset(struct drm_device *dev, void *data, struct drm_file *file_priv)\n{\n\tdrm_r128_private_t *dev_priv = dev->dev_private;\n\tDRM_DEBUG(\"\\n\");\n\n\tLOCK_TEST_WITH_RETURN(dev, file_priv);\n\n\tDEV_INIT_TEST_WITH_RETURN(dev_priv);\n\n\tr128_do_cce_reset(dev_priv);\n\n\t/* The CCE is no longer running after an engine reset */\n\tdev_priv->cce_running = 0;\n\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,10 +5,7 @@\n \n \tLOCK_TEST_WITH_RETURN(dev, file_priv);\n \n-\tif (!dev_priv) {\n-\t\tDRM_DEBUG(\"called before init done\\n\");\n-\t\treturn -EINVAL;\n-\t}\n+\tDEV_INIT_TEST_WITH_RETURN(dev_priv);\n \n \tr128_do_cce_reset(dev_priv);\n ",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (!dev_priv) {",
                "\t\tDRM_DEBUG(\"called before init done\\n\");",
                "\t\treturn -EINVAL;",
                "\t}"
            ],
            "added_lines": [
                "\tDEV_INIT_TEST_WITH_RETURN(dev_priv);"
            ]
        }
    },
    {
        "cve_id": "CVE-2009-3620",
        "func_name": "torvalds/linux/r128_cce_stop",
        "description": "The ATI Rage 128 (aka r128) driver in the Linux kernel before 2.6.31-git11 does not properly verify Concurrent Command Engine (CCE) state initialization, which allows local users to cause a denial of service (NULL pointer dereference and system crash) or possibly gain privileges via unspecified ioctl calls.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=7dc482dfeeeefcfd000d4271c4626937406756d7",
        "commit_title": "Almost all r128's private ioctls require that the CCE state has",
        "commit_text": "already been initialised.  However, most do not test that this has been done, and will proceed to dereference a null pointer.  This may result in a security vulnerability, since some ioctls are unprivileged.  This adds a macro for the common initialisation test and changes all ioctl implementations that require prior initialisation to use that macro.  Also, r128_do_init_cce() does not test that the CCE state has not been initialised already.  Repeated initialisation may lead to a crash or resource leak.  This adds that test.  ",
        "func_before": "int r128_cce_stop(struct drm_device *dev, void *data, struct drm_file *file_priv)\n{\n\tdrm_r128_private_t *dev_priv = dev->dev_private;\n\tdrm_r128_cce_stop_t *stop = data;\n\tint ret;\n\tDRM_DEBUG(\"\\n\");\n\n\tLOCK_TEST_WITH_RETURN(dev, file_priv);\n\n\t/* Flush any pending CCE commands.  This ensures any outstanding\n\t * commands are exectuted by the engine before we turn it off.\n\t */\n\tif (stop->flush) {\n\t\tr128_do_cce_flush(dev_priv);\n\t}\n\n\t/* If we fail to make the engine go idle, we return an error\n\t * code so that the DRM ioctl wrapper can try again.\n\t */\n\tif (stop->idle) {\n\t\tret = r128_do_cce_idle(dev_priv);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\t/* Finally, we can turn off the CCE.  If the engine isn't idle,\n\t * we will get some dropped triangles as they won't be fully\n\t * rendered before the CCE is shut down.\n\t */\n\tr128_do_cce_stop(dev_priv);\n\n\t/* Reset the engine */\n\tr128_do_engine_reset(dev);\n\n\treturn 0;\n}",
        "func": "int r128_cce_stop(struct drm_device *dev, void *data, struct drm_file *file_priv)\n{\n\tdrm_r128_private_t *dev_priv = dev->dev_private;\n\tdrm_r128_cce_stop_t *stop = data;\n\tint ret;\n\tDRM_DEBUG(\"\\n\");\n\n\tLOCK_TEST_WITH_RETURN(dev, file_priv);\n\n\tDEV_INIT_TEST_WITH_RETURN(dev_priv);\n\n\t/* Flush any pending CCE commands.  This ensures any outstanding\n\t * commands are exectuted by the engine before we turn it off.\n\t */\n\tif (stop->flush) {\n\t\tr128_do_cce_flush(dev_priv);\n\t}\n\n\t/* If we fail to make the engine go idle, we return an error\n\t * code so that the DRM ioctl wrapper can try again.\n\t */\n\tif (stop->idle) {\n\t\tret = r128_do_cce_idle(dev_priv);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\t/* Finally, we can turn off the CCE.  If the engine isn't idle,\n\t * we will get some dropped triangles as they won't be fully\n\t * rendered before the CCE is shut down.\n\t */\n\tr128_do_cce_stop(dev_priv);\n\n\t/* Reset the engine */\n\tr128_do_engine_reset(dev);\n\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -6,6 +6,8 @@\n \tDRM_DEBUG(\"\\n\");\n \n \tLOCK_TEST_WITH_RETURN(dev, file_priv);\n+\n+\tDEV_INIT_TEST_WITH_RETURN(dev_priv);\n \n \t/* Flush any pending CCE commands.  This ensures any outstanding\n \t * commands are exectuted by the engine before we turn it off.",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "\tDEV_INIT_TEST_WITH_RETURN(dev_priv);"
            ]
        }
    },
    {
        "cve_id": "CVE-2009-3620",
        "func_name": "torvalds/linux/r128_cce_start",
        "description": "The ATI Rage 128 (aka r128) driver in the Linux kernel before 2.6.31-git11 does not properly verify Concurrent Command Engine (CCE) state initialization, which allows local users to cause a denial of service (NULL pointer dereference and system crash) or possibly gain privileges via unspecified ioctl calls.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=7dc482dfeeeefcfd000d4271c4626937406756d7",
        "commit_title": "Almost all r128's private ioctls require that the CCE state has",
        "commit_text": "already been initialised.  However, most do not test that this has been done, and will proceed to dereference a null pointer.  This may result in a security vulnerability, since some ioctls are unprivileged.  This adds a macro for the common initialisation test and changes all ioctl implementations that require prior initialisation to use that macro.  Also, r128_do_init_cce() does not test that the CCE state has not been initialised already.  Repeated initialisation may lead to a crash or resource leak.  This adds that test.  ",
        "func_before": "int r128_cce_start(struct drm_device *dev, void *data, struct drm_file *file_priv)\n{\n\tdrm_r128_private_t *dev_priv = dev->dev_private;\n\tDRM_DEBUG(\"\\n\");\n\n\tLOCK_TEST_WITH_RETURN(dev, file_priv);\n\n\tif (dev_priv->cce_running || dev_priv->cce_mode == R128_PM4_NONPM4) {\n\t\tDRM_DEBUG(\"while CCE running\\n\");\n\t\treturn 0;\n\t}\n\n\tr128_do_cce_start(dev_priv);\n\n\treturn 0;\n}",
        "func": "int r128_cce_start(struct drm_device *dev, void *data, struct drm_file *file_priv)\n{\n\tdrm_r128_private_t *dev_priv = dev->dev_private;\n\tDRM_DEBUG(\"\\n\");\n\n\tLOCK_TEST_WITH_RETURN(dev, file_priv);\n\n\tDEV_INIT_TEST_WITH_RETURN(dev_priv);\n\n\tif (dev_priv->cce_running || dev_priv->cce_mode == R128_PM4_NONPM4) {\n\t\tDRM_DEBUG(\"while CCE running\\n\");\n\t\treturn 0;\n\t}\n\n\tr128_do_cce_start(dev_priv);\n\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,6 +4,8 @@\n \tDRM_DEBUG(\"\\n\");\n \n \tLOCK_TEST_WITH_RETURN(dev, file_priv);\n+\n+\tDEV_INIT_TEST_WITH_RETURN(dev_priv);\n \n \tif (dev_priv->cce_running || dev_priv->cce_mode == R128_PM4_NONPM4) {\n \t\tDRM_DEBUG(\"while CCE running\\n\");",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "\tDEV_INIT_TEST_WITH_RETURN(dev_priv);"
            ]
        }
    },
    {
        "cve_id": "CVE-2009-3620",
        "func_name": "torvalds/linux/r128_engine_reset",
        "description": "The ATI Rage 128 (aka r128) driver in the Linux kernel before 2.6.31-git11 does not properly verify Concurrent Command Engine (CCE) state initialization, which allows local users to cause a denial of service (NULL pointer dereference and system crash) or possibly gain privileges via unspecified ioctl calls.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=7dc482dfeeeefcfd000d4271c4626937406756d7",
        "commit_title": "Almost all r128's private ioctls require that the CCE state has",
        "commit_text": "already been initialised.  However, most do not test that this has been done, and will proceed to dereference a null pointer.  This may result in a security vulnerability, since some ioctls are unprivileged.  This adds a macro for the common initialisation test and changes all ioctl implementations that require prior initialisation to use that macro.  Also, r128_do_init_cce() does not test that the CCE state has not been initialised already.  Repeated initialisation may lead to a crash or resource leak.  This adds that test.  ",
        "func_before": "int r128_engine_reset(struct drm_device *dev, void *data, struct drm_file *file_priv)\n{\n\tDRM_DEBUG(\"\\n\");\n\n\tLOCK_TEST_WITH_RETURN(dev, file_priv);\n\n\treturn r128_do_engine_reset(dev);\n}",
        "func": "int r128_engine_reset(struct drm_device *dev, void *data, struct drm_file *file_priv)\n{\n\tDRM_DEBUG(\"\\n\");\n\n\tLOCK_TEST_WITH_RETURN(dev, file_priv);\n\n\tDEV_INIT_TEST_WITH_RETURN(dev->dev_private);\n\n\treturn r128_do_engine_reset(dev);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,5 +4,7 @@\n \n \tLOCK_TEST_WITH_RETURN(dev, file_priv);\n \n+\tDEV_INIT_TEST_WITH_RETURN(dev->dev_private);\n+\n \treturn r128_do_engine_reset(dev);\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tDEV_INIT_TEST_WITH_RETURN(dev->dev_private);",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2009-3620",
        "func_name": "torvalds/linux/r128_do_init_cce",
        "description": "The ATI Rage 128 (aka r128) driver in the Linux kernel before 2.6.31-git11 does not properly verify Concurrent Command Engine (CCE) state initialization, which allows local users to cause a denial of service (NULL pointer dereference and system crash) or possibly gain privileges via unspecified ioctl calls.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=7dc482dfeeeefcfd000d4271c4626937406756d7",
        "commit_title": "Almost all r128's private ioctls require that the CCE state has",
        "commit_text": "already been initialised.  However, most do not test that this has been done, and will proceed to dereference a null pointer.  This may result in a security vulnerability, since some ioctls are unprivileged.  This adds a macro for the common initialisation test and changes all ioctl implementations that require prior initialisation to use that macro.  Also, r128_do_init_cce() does not test that the CCE state has not been initialised already.  Repeated initialisation may lead to a crash or resource leak.  This adds that test.  ",
        "func_before": "static int r128_do_init_cce(struct drm_device * dev, drm_r128_init_t * init)\n{\n\tdrm_r128_private_t *dev_priv;\n\tint rc;\n\n\tDRM_DEBUG(\"\\n\");\n\n\tdev_priv = kzalloc(sizeof(drm_r128_private_t), GFP_KERNEL);\n\tif (dev_priv == NULL)\n\t\treturn -ENOMEM;\n\n\tdev_priv->is_pci = init->is_pci;\n\n\tif (dev_priv->is_pci && !dev->sg) {\n\t\tDRM_ERROR(\"PCI GART memory not allocated!\\n\");\n\t\tdev->dev_private = (void *)dev_priv;\n\t\tr128_do_cleanup_cce(dev);\n\t\treturn -EINVAL;\n\t}\n\n\tdev_priv->usec_timeout = init->usec_timeout;\n\tif (dev_priv->usec_timeout < 1 ||\n\t    dev_priv->usec_timeout > R128_MAX_USEC_TIMEOUT) {\n\t\tDRM_DEBUG(\"TIMEOUT problem!\\n\");\n\t\tdev->dev_private = (void *)dev_priv;\n\t\tr128_do_cleanup_cce(dev);\n\t\treturn -EINVAL;\n\t}\n\n\tdev_priv->cce_mode = init->cce_mode;\n\n\t/* GH: Simple idle check.\n\t */\n\tatomic_set(&dev_priv->idle_count, 0);\n\n\t/* We don't support anything other than bus-mastering ring mode,\n\t * but the ring can be in either AGP or PCI space for the ring\n\t * read pointer.\n\t */\n\tif ((init->cce_mode != R128_PM4_192BM) &&\n\t    (init->cce_mode != R128_PM4_128BM_64INDBM) &&\n\t    (init->cce_mode != R128_PM4_64BM_128INDBM) &&\n\t    (init->cce_mode != R128_PM4_64BM_64VCBM_64INDBM)) {\n\t\tDRM_DEBUG(\"Bad cce_mode!\\n\");\n\t\tdev->dev_private = (void *)dev_priv;\n\t\tr128_do_cleanup_cce(dev);\n\t\treturn -EINVAL;\n\t}\n\n\tswitch (init->cce_mode) {\n\tcase R128_PM4_NONPM4:\n\t\tdev_priv->cce_fifo_size = 0;\n\t\tbreak;\n\tcase R128_PM4_192PIO:\n\tcase R128_PM4_192BM:\n\t\tdev_priv->cce_fifo_size = 192;\n\t\tbreak;\n\tcase R128_PM4_128PIO_64INDBM:\n\tcase R128_PM4_128BM_64INDBM:\n\t\tdev_priv->cce_fifo_size = 128;\n\t\tbreak;\n\tcase R128_PM4_64PIO_128INDBM:\n\tcase R128_PM4_64BM_128INDBM:\n\tcase R128_PM4_64PIO_64VCBM_64INDBM:\n\tcase R128_PM4_64BM_64VCBM_64INDBM:\n\tcase R128_PM4_64PIO_64VCPIO_64INDPIO:\n\t\tdev_priv->cce_fifo_size = 64;\n\t\tbreak;\n\t}\n\n\tswitch (init->fb_bpp) {\n\tcase 16:\n\t\tdev_priv->color_fmt = R128_DATATYPE_RGB565;\n\t\tbreak;\n\tcase 32:\n\tdefault:\n\t\tdev_priv->color_fmt = R128_DATATYPE_ARGB8888;\n\t\tbreak;\n\t}\n\tdev_priv->front_offset = init->front_offset;\n\tdev_priv->front_pitch = init->front_pitch;\n\tdev_priv->back_offset = init->back_offset;\n\tdev_priv->back_pitch = init->back_pitch;\n\n\tswitch (init->depth_bpp) {\n\tcase 16:\n\t\tdev_priv->depth_fmt = R128_DATATYPE_RGB565;\n\t\tbreak;\n\tcase 24:\n\tcase 32:\n\tdefault:\n\t\tdev_priv->depth_fmt = R128_DATATYPE_ARGB8888;\n\t\tbreak;\n\t}\n\tdev_priv->depth_offset = init->depth_offset;\n\tdev_priv->depth_pitch = init->depth_pitch;\n\tdev_priv->span_offset = init->span_offset;\n\n\tdev_priv->front_pitch_offset_c = (((dev_priv->front_pitch / 8) << 21) |\n\t\t\t\t\t  (dev_priv->front_offset >> 5));\n\tdev_priv->back_pitch_offset_c = (((dev_priv->back_pitch / 8) << 21) |\n\t\t\t\t\t (dev_priv->back_offset >> 5));\n\tdev_priv->depth_pitch_offset_c = (((dev_priv->depth_pitch / 8) << 21) |\n\t\t\t\t\t  (dev_priv->depth_offset >> 5) |\n\t\t\t\t\t  R128_DST_TILE);\n\tdev_priv->span_pitch_offset_c = (((dev_priv->depth_pitch / 8) << 21) |\n\t\t\t\t\t (dev_priv->span_offset >> 5));\n\n\tdev_priv->sarea = drm_getsarea(dev);\n\tif (!dev_priv->sarea) {\n\t\tDRM_ERROR(\"could not find sarea!\\n\");\n\t\tdev->dev_private = (void *)dev_priv;\n\t\tr128_do_cleanup_cce(dev);\n\t\treturn -EINVAL;\n\t}\n\n\tdev_priv->mmio = drm_core_findmap(dev, init->mmio_offset);\n\tif (!dev_priv->mmio) {\n\t\tDRM_ERROR(\"could not find mmio region!\\n\");\n\t\tdev->dev_private = (void *)dev_priv;\n\t\tr128_do_cleanup_cce(dev);\n\t\treturn -EINVAL;\n\t}\n\tdev_priv->cce_ring = drm_core_findmap(dev, init->ring_offset);\n\tif (!dev_priv->cce_ring) {\n\t\tDRM_ERROR(\"could not find cce ring region!\\n\");\n\t\tdev->dev_private = (void *)dev_priv;\n\t\tr128_do_cleanup_cce(dev);\n\t\treturn -EINVAL;\n\t}\n\tdev_priv->ring_rptr = drm_core_findmap(dev, init->ring_rptr_offset);\n\tif (!dev_priv->ring_rptr) {\n\t\tDRM_ERROR(\"could not find ring read pointer!\\n\");\n\t\tdev->dev_private = (void *)dev_priv;\n\t\tr128_do_cleanup_cce(dev);\n\t\treturn -EINVAL;\n\t}\n\tdev->agp_buffer_token = init->buffers_offset;\n\tdev->agp_buffer_map = drm_core_findmap(dev, init->buffers_offset);\n\tif (!dev->agp_buffer_map) {\n\t\tDRM_ERROR(\"could not find dma buffer region!\\n\");\n\t\tdev->dev_private = (void *)dev_priv;\n\t\tr128_do_cleanup_cce(dev);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!dev_priv->is_pci) {\n\t\tdev_priv->agp_textures =\n\t\t    drm_core_findmap(dev, init->agp_textures_offset);\n\t\tif (!dev_priv->agp_textures) {\n\t\t\tDRM_ERROR(\"could not find agp texture region!\\n\");\n\t\t\tdev->dev_private = (void *)dev_priv;\n\t\t\tr128_do_cleanup_cce(dev);\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\tdev_priv->sarea_priv =\n\t    (drm_r128_sarea_t *) ((u8 *) dev_priv->sarea->handle +\n\t\t\t\t  init->sarea_priv_offset);\n\n#if __OS_HAS_AGP\n\tif (!dev_priv->is_pci) {\n\t\tdrm_core_ioremap_wc(dev_priv->cce_ring, dev);\n\t\tdrm_core_ioremap_wc(dev_priv->ring_rptr, dev);\n\t\tdrm_core_ioremap_wc(dev->agp_buffer_map, dev);\n\t\tif (!dev_priv->cce_ring->handle ||\n\t\t    !dev_priv->ring_rptr->handle ||\n\t\t    !dev->agp_buffer_map->handle) {\n\t\t\tDRM_ERROR(\"Could not ioremap agp regions!\\n\");\n\t\t\tdev->dev_private = (void *)dev_priv;\n\t\t\tr128_do_cleanup_cce(dev);\n\t\t\treturn -ENOMEM;\n\t\t}\n\t} else\n#endif\n\t{\n\t\tdev_priv->cce_ring->handle =\n\t\t\t(void *)(unsigned long)dev_priv->cce_ring->offset;\n\t\tdev_priv->ring_rptr->handle =\n\t\t\t(void *)(unsigned long)dev_priv->ring_rptr->offset;\n\t\tdev->agp_buffer_map->handle =\n\t\t\t(void *)(unsigned long)dev->agp_buffer_map->offset;\n\t}\n\n#if __OS_HAS_AGP\n\tif (!dev_priv->is_pci)\n\t\tdev_priv->cce_buffers_offset = dev->agp->base;\n\telse\n#endif\n\t\tdev_priv->cce_buffers_offset = (unsigned long)dev->sg->virtual;\n\n\tdev_priv->ring.start = (u32 *) dev_priv->cce_ring->handle;\n\tdev_priv->ring.end = ((u32 *) dev_priv->cce_ring->handle\n\t\t\t      + init->ring_size / sizeof(u32));\n\tdev_priv->ring.size = init->ring_size;\n\tdev_priv->ring.size_l2qw = drm_order(init->ring_size / 8);\n\n\tdev_priv->ring.tail_mask = (dev_priv->ring.size / sizeof(u32)) - 1;\n\n\tdev_priv->ring.high_mark = 128;\n\n\tdev_priv->sarea_priv->last_frame = 0;\n\tR128_WRITE(R128_LAST_FRAME_REG, dev_priv->sarea_priv->last_frame);\n\n\tdev_priv->sarea_priv->last_dispatch = 0;\n\tR128_WRITE(R128_LAST_DISPATCH_REG, dev_priv->sarea_priv->last_dispatch);\n\n#if __OS_HAS_AGP\n\tif (dev_priv->is_pci) {\n#endif\n\t\tdev_priv->gart_info.table_mask = DMA_BIT_MASK(32);\n\t\tdev_priv->gart_info.gart_table_location = DRM_ATI_GART_MAIN;\n\t\tdev_priv->gart_info.table_size = R128_PCIGART_TABLE_SIZE;\n\t\tdev_priv->gart_info.addr = NULL;\n\t\tdev_priv->gart_info.bus_addr = 0;\n\t\tdev_priv->gart_info.gart_reg_if = DRM_ATI_GART_PCI;\n\t\tif (!drm_ati_pcigart_init(dev, &dev_priv->gart_info)) {\n\t\t\tDRM_ERROR(\"failed to init PCI GART!\\n\");\n\t\t\tdev->dev_private = (void *)dev_priv;\n\t\t\tr128_do_cleanup_cce(dev);\n\t\t\treturn -ENOMEM;\n\t\t}\n\t\tR128_WRITE(R128_PCI_GART_PAGE, dev_priv->gart_info.bus_addr);\n#if __OS_HAS_AGP\n\t}\n#endif\n\n\tr128_cce_init_ring_buffer(dev, dev_priv);\n\trc = r128_cce_load_microcode(dev_priv);\n\n\tdev->dev_private = (void *)dev_priv;\n\n\tr128_do_engine_reset(dev);\n\n\tif (rc) {\n\t\tDRM_ERROR(\"Failed to load firmware!\\n\");\n\t\tr128_do_cleanup_cce(dev);\n\t}\n\n\treturn rc;\n}",
        "func": "static int r128_do_init_cce(struct drm_device * dev, drm_r128_init_t * init)\n{\n\tdrm_r128_private_t *dev_priv;\n\tint rc;\n\n\tDRM_DEBUG(\"\\n\");\n\n\tif (dev->dev_private) {\n\t\tDRM_DEBUG(\"called when already initialized\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tdev_priv = kzalloc(sizeof(drm_r128_private_t), GFP_KERNEL);\n\tif (dev_priv == NULL)\n\t\treturn -ENOMEM;\n\n\tdev_priv->is_pci = init->is_pci;\n\n\tif (dev_priv->is_pci && !dev->sg) {\n\t\tDRM_ERROR(\"PCI GART memory not allocated!\\n\");\n\t\tdev->dev_private = (void *)dev_priv;\n\t\tr128_do_cleanup_cce(dev);\n\t\treturn -EINVAL;\n\t}\n\n\tdev_priv->usec_timeout = init->usec_timeout;\n\tif (dev_priv->usec_timeout < 1 ||\n\t    dev_priv->usec_timeout > R128_MAX_USEC_TIMEOUT) {\n\t\tDRM_DEBUG(\"TIMEOUT problem!\\n\");\n\t\tdev->dev_private = (void *)dev_priv;\n\t\tr128_do_cleanup_cce(dev);\n\t\treturn -EINVAL;\n\t}\n\n\tdev_priv->cce_mode = init->cce_mode;\n\n\t/* GH: Simple idle check.\n\t */\n\tatomic_set(&dev_priv->idle_count, 0);\n\n\t/* We don't support anything other than bus-mastering ring mode,\n\t * but the ring can be in either AGP or PCI space for the ring\n\t * read pointer.\n\t */\n\tif ((init->cce_mode != R128_PM4_192BM) &&\n\t    (init->cce_mode != R128_PM4_128BM_64INDBM) &&\n\t    (init->cce_mode != R128_PM4_64BM_128INDBM) &&\n\t    (init->cce_mode != R128_PM4_64BM_64VCBM_64INDBM)) {\n\t\tDRM_DEBUG(\"Bad cce_mode!\\n\");\n\t\tdev->dev_private = (void *)dev_priv;\n\t\tr128_do_cleanup_cce(dev);\n\t\treturn -EINVAL;\n\t}\n\n\tswitch (init->cce_mode) {\n\tcase R128_PM4_NONPM4:\n\t\tdev_priv->cce_fifo_size = 0;\n\t\tbreak;\n\tcase R128_PM4_192PIO:\n\tcase R128_PM4_192BM:\n\t\tdev_priv->cce_fifo_size = 192;\n\t\tbreak;\n\tcase R128_PM4_128PIO_64INDBM:\n\tcase R128_PM4_128BM_64INDBM:\n\t\tdev_priv->cce_fifo_size = 128;\n\t\tbreak;\n\tcase R128_PM4_64PIO_128INDBM:\n\tcase R128_PM4_64BM_128INDBM:\n\tcase R128_PM4_64PIO_64VCBM_64INDBM:\n\tcase R128_PM4_64BM_64VCBM_64INDBM:\n\tcase R128_PM4_64PIO_64VCPIO_64INDPIO:\n\t\tdev_priv->cce_fifo_size = 64;\n\t\tbreak;\n\t}\n\n\tswitch (init->fb_bpp) {\n\tcase 16:\n\t\tdev_priv->color_fmt = R128_DATATYPE_RGB565;\n\t\tbreak;\n\tcase 32:\n\tdefault:\n\t\tdev_priv->color_fmt = R128_DATATYPE_ARGB8888;\n\t\tbreak;\n\t}\n\tdev_priv->front_offset = init->front_offset;\n\tdev_priv->front_pitch = init->front_pitch;\n\tdev_priv->back_offset = init->back_offset;\n\tdev_priv->back_pitch = init->back_pitch;\n\n\tswitch (init->depth_bpp) {\n\tcase 16:\n\t\tdev_priv->depth_fmt = R128_DATATYPE_RGB565;\n\t\tbreak;\n\tcase 24:\n\tcase 32:\n\tdefault:\n\t\tdev_priv->depth_fmt = R128_DATATYPE_ARGB8888;\n\t\tbreak;\n\t}\n\tdev_priv->depth_offset = init->depth_offset;\n\tdev_priv->depth_pitch = init->depth_pitch;\n\tdev_priv->span_offset = init->span_offset;\n\n\tdev_priv->front_pitch_offset_c = (((dev_priv->front_pitch / 8) << 21) |\n\t\t\t\t\t  (dev_priv->front_offset >> 5));\n\tdev_priv->back_pitch_offset_c = (((dev_priv->back_pitch / 8) << 21) |\n\t\t\t\t\t (dev_priv->back_offset >> 5));\n\tdev_priv->depth_pitch_offset_c = (((dev_priv->depth_pitch / 8) << 21) |\n\t\t\t\t\t  (dev_priv->depth_offset >> 5) |\n\t\t\t\t\t  R128_DST_TILE);\n\tdev_priv->span_pitch_offset_c = (((dev_priv->depth_pitch / 8) << 21) |\n\t\t\t\t\t (dev_priv->span_offset >> 5));\n\n\tdev_priv->sarea = drm_getsarea(dev);\n\tif (!dev_priv->sarea) {\n\t\tDRM_ERROR(\"could not find sarea!\\n\");\n\t\tdev->dev_private = (void *)dev_priv;\n\t\tr128_do_cleanup_cce(dev);\n\t\treturn -EINVAL;\n\t}\n\n\tdev_priv->mmio = drm_core_findmap(dev, init->mmio_offset);\n\tif (!dev_priv->mmio) {\n\t\tDRM_ERROR(\"could not find mmio region!\\n\");\n\t\tdev->dev_private = (void *)dev_priv;\n\t\tr128_do_cleanup_cce(dev);\n\t\treturn -EINVAL;\n\t}\n\tdev_priv->cce_ring = drm_core_findmap(dev, init->ring_offset);\n\tif (!dev_priv->cce_ring) {\n\t\tDRM_ERROR(\"could not find cce ring region!\\n\");\n\t\tdev->dev_private = (void *)dev_priv;\n\t\tr128_do_cleanup_cce(dev);\n\t\treturn -EINVAL;\n\t}\n\tdev_priv->ring_rptr = drm_core_findmap(dev, init->ring_rptr_offset);\n\tif (!dev_priv->ring_rptr) {\n\t\tDRM_ERROR(\"could not find ring read pointer!\\n\");\n\t\tdev->dev_private = (void *)dev_priv;\n\t\tr128_do_cleanup_cce(dev);\n\t\treturn -EINVAL;\n\t}\n\tdev->agp_buffer_token = init->buffers_offset;\n\tdev->agp_buffer_map = drm_core_findmap(dev, init->buffers_offset);\n\tif (!dev->agp_buffer_map) {\n\t\tDRM_ERROR(\"could not find dma buffer region!\\n\");\n\t\tdev->dev_private = (void *)dev_priv;\n\t\tr128_do_cleanup_cce(dev);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!dev_priv->is_pci) {\n\t\tdev_priv->agp_textures =\n\t\t    drm_core_findmap(dev, init->agp_textures_offset);\n\t\tif (!dev_priv->agp_textures) {\n\t\t\tDRM_ERROR(\"could not find agp texture region!\\n\");\n\t\t\tdev->dev_private = (void *)dev_priv;\n\t\t\tr128_do_cleanup_cce(dev);\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\tdev_priv->sarea_priv =\n\t    (drm_r128_sarea_t *) ((u8 *) dev_priv->sarea->handle +\n\t\t\t\t  init->sarea_priv_offset);\n\n#if __OS_HAS_AGP\n\tif (!dev_priv->is_pci) {\n\t\tdrm_core_ioremap_wc(dev_priv->cce_ring, dev);\n\t\tdrm_core_ioremap_wc(dev_priv->ring_rptr, dev);\n\t\tdrm_core_ioremap_wc(dev->agp_buffer_map, dev);\n\t\tif (!dev_priv->cce_ring->handle ||\n\t\t    !dev_priv->ring_rptr->handle ||\n\t\t    !dev->agp_buffer_map->handle) {\n\t\t\tDRM_ERROR(\"Could not ioremap agp regions!\\n\");\n\t\t\tdev->dev_private = (void *)dev_priv;\n\t\t\tr128_do_cleanup_cce(dev);\n\t\t\treturn -ENOMEM;\n\t\t}\n\t} else\n#endif\n\t{\n\t\tdev_priv->cce_ring->handle =\n\t\t\t(void *)(unsigned long)dev_priv->cce_ring->offset;\n\t\tdev_priv->ring_rptr->handle =\n\t\t\t(void *)(unsigned long)dev_priv->ring_rptr->offset;\n\t\tdev->agp_buffer_map->handle =\n\t\t\t(void *)(unsigned long)dev->agp_buffer_map->offset;\n\t}\n\n#if __OS_HAS_AGP\n\tif (!dev_priv->is_pci)\n\t\tdev_priv->cce_buffers_offset = dev->agp->base;\n\telse\n#endif\n\t\tdev_priv->cce_buffers_offset = (unsigned long)dev->sg->virtual;\n\n\tdev_priv->ring.start = (u32 *) dev_priv->cce_ring->handle;\n\tdev_priv->ring.end = ((u32 *) dev_priv->cce_ring->handle\n\t\t\t      + init->ring_size / sizeof(u32));\n\tdev_priv->ring.size = init->ring_size;\n\tdev_priv->ring.size_l2qw = drm_order(init->ring_size / 8);\n\n\tdev_priv->ring.tail_mask = (dev_priv->ring.size / sizeof(u32)) - 1;\n\n\tdev_priv->ring.high_mark = 128;\n\n\tdev_priv->sarea_priv->last_frame = 0;\n\tR128_WRITE(R128_LAST_FRAME_REG, dev_priv->sarea_priv->last_frame);\n\n\tdev_priv->sarea_priv->last_dispatch = 0;\n\tR128_WRITE(R128_LAST_DISPATCH_REG, dev_priv->sarea_priv->last_dispatch);\n\n#if __OS_HAS_AGP\n\tif (dev_priv->is_pci) {\n#endif\n\t\tdev_priv->gart_info.table_mask = DMA_BIT_MASK(32);\n\t\tdev_priv->gart_info.gart_table_location = DRM_ATI_GART_MAIN;\n\t\tdev_priv->gart_info.table_size = R128_PCIGART_TABLE_SIZE;\n\t\tdev_priv->gart_info.addr = NULL;\n\t\tdev_priv->gart_info.bus_addr = 0;\n\t\tdev_priv->gart_info.gart_reg_if = DRM_ATI_GART_PCI;\n\t\tif (!drm_ati_pcigart_init(dev, &dev_priv->gart_info)) {\n\t\t\tDRM_ERROR(\"failed to init PCI GART!\\n\");\n\t\t\tdev->dev_private = (void *)dev_priv;\n\t\t\tr128_do_cleanup_cce(dev);\n\t\t\treturn -ENOMEM;\n\t\t}\n\t\tR128_WRITE(R128_PCI_GART_PAGE, dev_priv->gart_info.bus_addr);\n#if __OS_HAS_AGP\n\t}\n#endif\n\n\tr128_cce_init_ring_buffer(dev, dev_priv);\n\trc = r128_cce_load_microcode(dev_priv);\n\n\tdev->dev_private = (void *)dev_priv;\n\n\tr128_do_engine_reset(dev);\n\n\tif (rc) {\n\t\tDRM_ERROR(\"Failed to load firmware!\\n\");\n\t\tr128_do_cleanup_cce(dev);\n\t}\n\n\treturn rc;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,6 +4,11 @@\n \tint rc;\n \n \tDRM_DEBUG(\"\\n\");\n+\n+\tif (dev->dev_private) {\n+\t\tDRM_DEBUG(\"called when already initialized\\n\");\n+\t\treturn -EINVAL;\n+\t}\n \n \tdev_priv = kzalloc(sizeof(drm_r128_private_t), GFP_KERNEL);\n \tif (dev_priv == NULL)",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "\tif (dev->dev_private) {",
                "\t\tDRM_DEBUG(\"called when already initialized\\n\");",
                "\t\treturn -EINVAL;",
                "\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2009-3620",
        "func_name": "torvalds/linux/r128_cce_indices",
        "description": "The ATI Rage 128 (aka r128) driver in the Linux kernel before 2.6.31-git11 does not properly verify Concurrent Command Engine (CCE) state initialization, which allows local users to cause a denial of service (NULL pointer dereference and system crash) or possibly gain privileges via unspecified ioctl calls.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=7dc482dfeeeefcfd000d4271c4626937406756d7",
        "commit_title": "Almost all r128's private ioctls require that the CCE state has",
        "commit_text": "already been initialised.  However, most do not test that this has been done, and will proceed to dereference a null pointer.  This may result in a security vulnerability, since some ioctls are unprivileged.  This adds a macro for the common initialisation test and changes all ioctl implementations that require prior initialisation to use that macro.  Also, r128_do_init_cce() does not test that the CCE state has not been initialised already.  Repeated initialisation may lead to a crash or resource leak.  This adds that test.  ",
        "func_before": "static int r128_cce_indices(struct drm_device *dev, void *data, struct drm_file *file_priv)\n{\n\tdrm_r128_private_t *dev_priv = dev->dev_private;\n\tstruct drm_device_dma *dma = dev->dma;\n\tstruct drm_buf *buf;\n\tdrm_r128_buf_priv_t *buf_priv;\n\tdrm_r128_indices_t *elts = data;\n\tint count;\n\n\tLOCK_TEST_WITH_RETURN(dev, file_priv);\n\n\tif (!dev_priv) {\n\t\tDRM_ERROR(\"called with no initialization\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tDRM_DEBUG(\"pid=%d buf=%d s=%d e=%d d=%d\\n\", DRM_CURRENTPID,\n\t\t  elts->idx, elts->start, elts->end, elts->discard);\n\n\tif (elts->idx < 0 || elts->idx >= dma->buf_count) {\n\t\tDRM_ERROR(\"buffer index %d (of %d max)\\n\",\n\t\t\t  elts->idx, dma->buf_count - 1);\n\t\treturn -EINVAL;\n\t}\n\tif (elts->prim < 0 ||\n\t    elts->prim > R128_CCE_VC_CNTL_PRIM_TYPE_TRI_TYPE2) {\n\t\tDRM_ERROR(\"buffer prim %d\\n\", elts->prim);\n\t\treturn -EINVAL;\n\t}\n\n\tRING_SPACE_TEST_WITH_RETURN(dev_priv);\n\tVB_AGE_TEST_WITH_RETURN(dev_priv);\n\n\tbuf = dma->buflist[elts->idx];\n\tbuf_priv = buf->dev_private;\n\n\tif (buf->file_priv != file_priv) {\n\t\tDRM_ERROR(\"process %d using buffer owned by %p\\n\",\n\t\t\t  DRM_CURRENTPID, buf->file_priv);\n\t\treturn -EINVAL;\n\t}\n\tif (buf->pending) {\n\t\tDRM_ERROR(\"sending pending buffer %d\\n\", elts->idx);\n\t\treturn -EINVAL;\n\t}\n\n\tcount = (elts->end - elts->start) / sizeof(u16);\n\telts->start -= R128_INDEX_PRIM_OFFSET;\n\n\tif (elts->start & 0x7) {\n\t\tDRM_ERROR(\"misaligned buffer 0x%x\\n\", elts->start);\n\t\treturn -EINVAL;\n\t}\n\tif (elts->start < buf->used) {\n\t\tDRM_ERROR(\"no header 0x%x - 0x%x\\n\", elts->start, buf->used);\n\t\treturn -EINVAL;\n\t}\n\n\tbuf->used = elts->end;\n\tbuf_priv->prim = elts->prim;\n\tbuf_priv->discard = elts->discard;\n\n\tr128_cce_dispatch_indices(dev, buf, elts->start, elts->end, count);\n\n\tCOMMIT_RING();\n\treturn 0;\n}",
        "func": "static int r128_cce_indices(struct drm_device *dev, void *data, struct drm_file *file_priv)\n{\n\tdrm_r128_private_t *dev_priv = dev->dev_private;\n\tstruct drm_device_dma *dma = dev->dma;\n\tstruct drm_buf *buf;\n\tdrm_r128_buf_priv_t *buf_priv;\n\tdrm_r128_indices_t *elts = data;\n\tint count;\n\n\tLOCK_TEST_WITH_RETURN(dev, file_priv);\n\n\tDEV_INIT_TEST_WITH_RETURN(dev_priv);\n\n\tDRM_DEBUG(\"pid=%d buf=%d s=%d e=%d d=%d\\n\", DRM_CURRENTPID,\n\t\t  elts->idx, elts->start, elts->end, elts->discard);\n\n\tif (elts->idx < 0 || elts->idx >= dma->buf_count) {\n\t\tDRM_ERROR(\"buffer index %d (of %d max)\\n\",\n\t\t\t  elts->idx, dma->buf_count - 1);\n\t\treturn -EINVAL;\n\t}\n\tif (elts->prim < 0 ||\n\t    elts->prim > R128_CCE_VC_CNTL_PRIM_TYPE_TRI_TYPE2) {\n\t\tDRM_ERROR(\"buffer prim %d\\n\", elts->prim);\n\t\treturn -EINVAL;\n\t}\n\n\tRING_SPACE_TEST_WITH_RETURN(dev_priv);\n\tVB_AGE_TEST_WITH_RETURN(dev_priv);\n\n\tbuf = dma->buflist[elts->idx];\n\tbuf_priv = buf->dev_private;\n\n\tif (buf->file_priv != file_priv) {\n\t\tDRM_ERROR(\"process %d using buffer owned by %p\\n\",\n\t\t\t  DRM_CURRENTPID, buf->file_priv);\n\t\treturn -EINVAL;\n\t}\n\tif (buf->pending) {\n\t\tDRM_ERROR(\"sending pending buffer %d\\n\", elts->idx);\n\t\treturn -EINVAL;\n\t}\n\n\tcount = (elts->end - elts->start) / sizeof(u16);\n\telts->start -= R128_INDEX_PRIM_OFFSET;\n\n\tif (elts->start & 0x7) {\n\t\tDRM_ERROR(\"misaligned buffer 0x%x\\n\", elts->start);\n\t\treturn -EINVAL;\n\t}\n\tif (elts->start < buf->used) {\n\t\tDRM_ERROR(\"no header 0x%x - 0x%x\\n\", elts->start, buf->used);\n\t\treturn -EINVAL;\n\t}\n\n\tbuf->used = elts->end;\n\tbuf_priv->prim = elts->prim;\n\tbuf_priv->discard = elts->discard;\n\n\tr128_cce_dispatch_indices(dev, buf, elts->start, elts->end, count);\n\n\tCOMMIT_RING();\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -9,10 +9,7 @@\n \n \tLOCK_TEST_WITH_RETURN(dev, file_priv);\n \n-\tif (!dev_priv) {\n-\t\tDRM_ERROR(\"called with no initialization\\n\");\n-\t\treturn -EINVAL;\n-\t}\n+\tDEV_INIT_TEST_WITH_RETURN(dev_priv);\n \n \tDRM_DEBUG(\"pid=%d buf=%d s=%d e=%d d=%d\\n\", DRM_CURRENTPID,\n \t\t  elts->idx, elts->start, elts->end, elts->discard);",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (!dev_priv) {",
                "\t\tDRM_ERROR(\"called with no initialization\\n\");",
                "\t\treturn -EINVAL;",
                "\t}"
            ],
            "added_lines": [
                "\tDEV_INIT_TEST_WITH_RETURN(dev_priv);"
            ]
        }
    },
    {
        "cve_id": "CVE-2009-3620",
        "func_name": "torvalds/linux/r128_cce_vertex",
        "description": "The ATI Rage 128 (aka r128) driver in the Linux kernel before 2.6.31-git11 does not properly verify Concurrent Command Engine (CCE) state initialization, which allows local users to cause a denial of service (NULL pointer dereference and system crash) or possibly gain privileges via unspecified ioctl calls.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=7dc482dfeeeefcfd000d4271c4626937406756d7",
        "commit_title": "Almost all r128's private ioctls require that the CCE state has",
        "commit_text": "already been initialised.  However, most do not test that this has been done, and will proceed to dereference a null pointer.  This may result in a security vulnerability, since some ioctls are unprivileged.  This adds a macro for the common initialisation test and changes all ioctl implementations that require prior initialisation to use that macro.  Also, r128_do_init_cce() does not test that the CCE state has not been initialised already.  Repeated initialisation may lead to a crash or resource leak.  This adds that test.  ",
        "func_before": "static int r128_cce_vertex(struct drm_device *dev, void *data, struct drm_file *file_priv)\n{\n\tdrm_r128_private_t *dev_priv = dev->dev_private;\n\tstruct drm_device_dma *dma = dev->dma;\n\tstruct drm_buf *buf;\n\tdrm_r128_buf_priv_t *buf_priv;\n\tdrm_r128_vertex_t *vertex = data;\n\n\tLOCK_TEST_WITH_RETURN(dev, file_priv);\n\n\tif (!dev_priv) {\n\t\tDRM_ERROR(\"called with no initialization\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tDRM_DEBUG(\"pid=%d index=%d count=%d discard=%d\\n\",\n\t\t  DRM_CURRENTPID, vertex->idx, vertex->count, vertex->discard);\n\n\tif (vertex->idx < 0 || vertex->idx >= dma->buf_count) {\n\t\tDRM_ERROR(\"buffer index %d (of %d max)\\n\",\n\t\t\t  vertex->idx, dma->buf_count - 1);\n\t\treturn -EINVAL;\n\t}\n\tif (vertex->prim < 0 ||\n\t    vertex->prim > R128_CCE_VC_CNTL_PRIM_TYPE_TRI_TYPE2) {\n\t\tDRM_ERROR(\"buffer prim %d\\n\", vertex->prim);\n\t\treturn -EINVAL;\n\t}\n\n\tRING_SPACE_TEST_WITH_RETURN(dev_priv);\n\tVB_AGE_TEST_WITH_RETURN(dev_priv);\n\n\tbuf = dma->buflist[vertex->idx];\n\tbuf_priv = buf->dev_private;\n\n\tif (buf->file_priv != file_priv) {\n\t\tDRM_ERROR(\"process %d using buffer owned by %p\\n\",\n\t\t\t  DRM_CURRENTPID, buf->file_priv);\n\t\treturn -EINVAL;\n\t}\n\tif (buf->pending) {\n\t\tDRM_ERROR(\"sending pending buffer %d\\n\", vertex->idx);\n\t\treturn -EINVAL;\n\t}\n\n\tbuf->used = vertex->count;\n\tbuf_priv->prim = vertex->prim;\n\tbuf_priv->discard = vertex->discard;\n\n\tr128_cce_dispatch_vertex(dev, buf);\n\n\tCOMMIT_RING();\n\treturn 0;\n}",
        "func": "static int r128_cce_vertex(struct drm_device *dev, void *data, struct drm_file *file_priv)\n{\n\tdrm_r128_private_t *dev_priv = dev->dev_private;\n\tstruct drm_device_dma *dma = dev->dma;\n\tstruct drm_buf *buf;\n\tdrm_r128_buf_priv_t *buf_priv;\n\tdrm_r128_vertex_t *vertex = data;\n\n\tLOCK_TEST_WITH_RETURN(dev, file_priv);\n\n\tDEV_INIT_TEST_WITH_RETURN(dev_priv);\n\n\tDRM_DEBUG(\"pid=%d index=%d count=%d discard=%d\\n\",\n\t\t  DRM_CURRENTPID, vertex->idx, vertex->count, vertex->discard);\n\n\tif (vertex->idx < 0 || vertex->idx >= dma->buf_count) {\n\t\tDRM_ERROR(\"buffer index %d (of %d max)\\n\",\n\t\t\t  vertex->idx, dma->buf_count - 1);\n\t\treturn -EINVAL;\n\t}\n\tif (vertex->prim < 0 ||\n\t    vertex->prim > R128_CCE_VC_CNTL_PRIM_TYPE_TRI_TYPE2) {\n\t\tDRM_ERROR(\"buffer prim %d\\n\", vertex->prim);\n\t\treturn -EINVAL;\n\t}\n\n\tRING_SPACE_TEST_WITH_RETURN(dev_priv);\n\tVB_AGE_TEST_WITH_RETURN(dev_priv);\n\n\tbuf = dma->buflist[vertex->idx];\n\tbuf_priv = buf->dev_private;\n\n\tif (buf->file_priv != file_priv) {\n\t\tDRM_ERROR(\"process %d using buffer owned by %p\\n\",\n\t\t\t  DRM_CURRENTPID, buf->file_priv);\n\t\treturn -EINVAL;\n\t}\n\tif (buf->pending) {\n\t\tDRM_ERROR(\"sending pending buffer %d\\n\", vertex->idx);\n\t\treturn -EINVAL;\n\t}\n\n\tbuf->used = vertex->count;\n\tbuf_priv->prim = vertex->prim;\n\tbuf_priv->discard = vertex->discard;\n\n\tr128_cce_dispatch_vertex(dev, buf);\n\n\tCOMMIT_RING();\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -8,10 +8,7 @@\n \n \tLOCK_TEST_WITH_RETURN(dev, file_priv);\n \n-\tif (!dev_priv) {\n-\t\tDRM_ERROR(\"called with no initialization\\n\");\n-\t\treturn -EINVAL;\n-\t}\n+\tDEV_INIT_TEST_WITH_RETURN(dev_priv);\n \n \tDRM_DEBUG(\"pid=%d index=%d count=%d discard=%d\\n\",\n \t\t  DRM_CURRENTPID, vertex->idx, vertex->count, vertex->discard);",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (!dev_priv) {",
                "\t\tDRM_ERROR(\"called with no initialization\\n\");",
                "\t\treturn -EINVAL;",
                "\t}"
            ],
            "added_lines": [
                "\tDEV_INIT_TEST_WITH_RETURN(dev_priv);"
            ]
        }
    },
    {
        "cve_id": "CVE-2009-3620",
        "func_name": "torvalds/linux/r128_cce_blit",
        "description": "The ATI Rage 128 (aka r128) driver in the Linux kernel before 2.6.31-git11 does not properly verify Concurrent Command Engine (CCE) state initialization, which allows local users to cause a denial of service (NULL pointer dereference and system crash) or possibly gain privileges via unspecified ioctl calls.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=7dc482dfeeeefcfd000d4271c4626937406756d7",
        "commit_title": "Almost all r128's private ioctls require that the CCE state has",
        "commit_text": "already been initialised.  However, most do not test that this has been done, and will proceed to dereference a null pointer.  This may result in a security vulnerability, since some ioctls are unprivileged.  This adds a macro for the common initialisation test and changes all ioctl implementations that require prior initialisation to use that macro.  Also, r128_do_init_cce() does not test that the CCE state has not been initialised already.  Repeated initialisation may lead to a crash or resource leak.  This adds that test.  ",
        "func_before": "static int r128_cce_blit(struct drm_device *dev, void *data, struct drm_file *file_priv)\n{\n\tstruct drm_device_dma *dma = dev->dma;\n\tdrm_r128_private_t *dev_priv = dev->dev_private;\n\tdrm_r128_blit_t *blit = data;\n\tint ret;\n\n\tLOCK_TEST_WITH_RETURN(dev, file_priv);\n\n\tDRM_DEBUG(\"pid=%d index=%d\\n\", DRM_CURRENTPID, blit->idx);\n\n\tif (blit->idx < 0 || blit->idx >= dma->buf_count) {\n\t\tDRM_ERROR(\"buffer index %d (of %d max)\\n\",\n\t\t\t  blit->idx, dma->buf_count - 1);\n\t\treturn -EINVAL;\n\t}\n\n\tRING_SPACE_TEST_WITH_RETURN(dev_priv);\n\tVB_AGE_TEST_WITH_RETURN(dev_priv);\n\n\tret = r128_cce_dispatch_blit(dev, file_priv, blit);\n\n\tCOMMIT_RING();\n\treturn ret;\n}",
        "func": "static int r128_cce_blit(struct drm_device *dev, void *data, struct drm_file *file_priv)\n{\n\tstruct drm_device_dma *dma = dev->dma;\n\tdrm_r128_private_t *dev_priv = dev->dev_private;\n\tdrm_r128_blit_t *blit = data;\n\tint ret;\n\n\tLOCK_TEST_WITH_RETURN(dev, file_priv);\n\n\tDEV_INIT_TEST_WITH_RETURN(dev_priv);\n\n\tDRM_DEBUG(\"pid=%d index=%d\\n\", DRM_CURRENTPID, blit->idx);\n\n\tif (blit->idx < 0 || blit->idx >= dma->buf_count) {\n\t\tDRM_ERROR(\"buffer index %d (of %d max)\\n\",\n\t\t\t  blit->idx, dma->buf_count - 1);\n\t\treturn -EINVAL;\n\t}\n\n\tRING_SPACE_TEST_WITH_RETURN(dev_priv);\n\tVB_AGE_TEST_WITH_RETURN(dev_priv);\n\n\tret = r128_cce_dispatch_blit(dev, file_priv, blit);\n\n\tCOMMIT_RING();\n\treturn ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -6,6 +6,8 @@\n \tint ret;\n \n \tLOCK_TEST_WITH_RETURN(dev, file_priv);\n+\n+\tDEV_INIT_TEST_WITH_RETURN(dev_priv);\n \n \tDRM_DEBUG(\"pid=%d index=%d\\n\", DRM_CURRENTPID, blit->idx);\n ",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "\tDEV_INIT_TEST_WITH_RETURN(dev_priv);"
            ]
        }
    },
    {
        "cve_id": "CVE-2009-3620",
        "func_name": "torvalds/linux/r128_cce_stipple",
        "description": "The ATI Rage 128 (aka r128) driver in the Linux kernel before 2.6.31-git11 does not properly verify Concurrent Command Engine (CCE) state initialization, which allows local users to cause a denial of service (NULL pointer dereference and system crash) or possibly gain privileges via unspecified ioctl calls.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=7dc482dfeeeefcfd000d4271c4626937406756d7",
        "commit_title": "Almost all r128's private ioctls require that the CCE state has",
        "commit_text": "already been initialised.  However, most do not test that this has been done, and will proceed to dereference a null pointer.  This may result in a security vulnerability, since some ioctls are unprivileged.  This adds a macro for the common initialisation test and changes all ioctl implementations that require prior initialisation to use that macro.  Also, r128_do_init_cce() does not test that the CCE state has not been initialised already.  Repeated initialisation may lead to a crash or resource leak.  This adds that test.  ",
        "func_before": "static int r128_cce_stipple(struct drm_device *dev, void *data, struct drm_file *file_priv)\n{\n\tdrm_r128_private_t *dev_priv = dev->dev_private;\n\tdrm_r128_stipple_t *stipple = data;\n\tu32 mask[32];\n\n\tLOCK_TEST_WITH_RETURN(dev, file_priv);\n\n\tif (DRM_COPY_FROM_USER(&mask, stipple->mask, 32 * sizeof(u32)))\n\t\treturn -EFAULT;\n\n\tRING_SPACE_TEST_WITH_RETURN(dev_priv);\n\n\tr128_cce_dispatch_stipple(dev, mask);\n\n\tCOMMIT_RING();\n\treturn 0;\n}",
        "func": "static int r128_cce_stipple(struct drm_device *dev, void *data, struct drm_file *file_priv)\n{\n\tdrm_r128_private_t *dev_priv = dev->dev_private;\n\tdrm_r128_stipple_t *stipple = data;\n\tu32 mask[32];\n\n\tLOCK_TEST_WITH_RETURN(dev, file_priv);\n\n\tDEV_INIT_TEST_WITH_RETURN(dev_priv);\n\n\tif (DRM_COPY_FROM_USER(&mask, stipple->mask, 32 * sizeof(u32)))\n\t\treturn -EFAULT;\n\n\tRING_SPACE_TEST_WITH_RETURN(dev_priv);\n\n\tr128_cce_dispatch_stipple(dev, mask);\n\n\tCOMMIT_RING();\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,6 +5,8 @@\n \tu32 mask[32];\n \n \tLOCK_TEST_WITH_RETURN(dev, file_priv);\n+\n+\tDEV_INIT_TEST_WITH_RETURN(dev_priv);\n \n \tif (DRM_COPY_FROM_USER(&mask, stipple->mask, 32 * sizeof(u32)))\n \t\treturn -EFAULT;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "\tDEV_INIT_TEST_WITH_RETURN(dev_priv);"
            ]
        }
    },
    {
        "cve_id": "CVE-2009-3620",
        "func_name": "torvalds/linux/r128_cce_depth",
        "description": "The ATI Rage 128 (aka r128) driver in the Linux kernel before 2.6.31-git11 does not properly verify Concurrent Command Engine (CCE) state initialization, which allows local users to cause a denial of service (NULL pointer dereference and system crash) or possibly gain privileges via unspecified ioctl calls.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=7dc482dfeeeefcfd000d4271c4626937406756d7",
        "commit_title": "Almost all r128's private ioctls require that the CCE state has",
        "commit_text": "already been initialised.  However, most do not test that this has been done, and will proceed to dereference a null pointer.  This may result in a security vulnerability, since some ioctls are unprivileged.  This adds a macro for the common initialisation test and changes all ioctl implementations that require prior initialisation to use that macro.  Also, r128_do_init_cce() does not test that the CCE state has not been initialised already.  Repeated initialisation may lead to a crash or resource leak.  This adds that test.  ",
        "func_before": "static int r128_cce_depth(struct drm_device *dev, void *data, struct drm_file *file_priv)\n{\n\tdrm_r128_private_t *dev_priv = dev->dev_private;\n\tdrm_r128_depth_t *depth = data;\n\tint ret;\n\n\tLOCK_TEST_WITH_RETURN(dev, file_priv);\n\n\tRING_SPACE_TEST_WITH_RETURN(dev_priv);\n\n\tret = -EINVAL;\n\tswitch (depth->func) {\n\tcase R128_WRITE_SPAN:\n\t\tret = r128_cce_dispatch_write_span(dev, depth);\n\t\tbreak;\n\tcase R128_WRITE_PIXELS:\n\t\tret = r128_cce_dispatch_write_pixels(dev, depth);\n\t\tbreak;\n\tcase R128_READ_SPAN:\n\t\tret = r128_cce_dispatch_read_span(dev, depth);\n\t\tbreak;\n\tcase R128_READ_PIXELS:\n\t\tret = r128_cce_dispatch_read_pixels(dev, depth);\n\t\tbreak;\n\t}\n\n\tCOMMIT_RING();\n\treturn ret;\n}",
        "func": "static int r128_cce_depth(struct drm_device *dev, void *data, struct drm_file *file_priv)\n{\n\tdrm_r128_private_t *dev_priv = dev->dev_private;\n\tdrm_r128_depth_t *depth = data;\n\tint ret;\n\n\tLOCK_TEST_WITH_RETURN(dev, file_priv);\n\n\tDEV_INIT_TEST_WITH_RETURN(dev_priv);\n\n\tRING_SPACE_TEST_WITH_RETURN(dev_priv);\n\n\tret = -EINVAL;\n\tswitch (depth->func) {\n\tcase R128_WRITE_SPAN:\n\t\tret = r128_cce_dispatch_write_span(dev, depth);\n\t\tbreak;\n\tcase R128_WRITE_PIXELS:\n\t\tret = r128_cce_dispatch_write_pixels(dev, depth);\n\t\tbreak;\n\tcase R128_READ_SPAN:\n\t\tret = r128_cce_dispatch_read_span(dev, depth);\n\t\tbreak;\n\tcase R128_READ_PIXELS:\n\t\tret = r128_cce_dispatch_read_pixels(dev, depth);\n\t\tbreak;\n\t}\n\n\tCOMMIT_RING();\n\treturn ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,6 +5,8 @@\n \tint ret;\n \n \tLOCK_TEST_WITH_RETURN(dev, file_priv);\n+\n+\tDEV_INIT_TEST_WITH_RETURN(dev_priv);\n \n \tRING_SPACE_TEST_WITH_RETURN(dev_priv);\n ",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "\tDEV_INIT_TEST_WITH_RETURN(dev_priv);"
            ]
        }
    },
    {
        "cve_id": "CVE-2009-3620",
        "func_name": "torvalds/linux/r128_cce_clear",
        "description": "The ATI Rage 128 (aka r128) driver in the Linux kernel before 2.6.31-git11 does not properly verify Concurrent Command Engine (CCE) state initialization, which allows local users to cause a denial of service (NULL pointer dereference and system crash) or possibly gain privileges via unspecified ioctl calls.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=7dc482dfeeeefcfd000d4271c4626937406756d7",
        "commit_title": "Almost all r128's private ioctls require that the CCE state has",
        "commit_text": "already been initialised.  However, most do not test that this has been done, and will proceed to dereference a null pointer.  This may result in a security vulnerability, since some ioctls are unprivileged.  This adds a macro for the common initialisation test and changes all ioctl implementations that require prior initialisation to use that macro.  Also, r128_do_init_cce() does not test that the CCE state has not been initialised already.  Repeated initialisation may lead to a crash or resource leak.  This adds that test.  ",
        "func_before": "static int r128_cce_clear(struct drm_device *dev, void *data, struct drm_file *file_priv)\n{\n\tdrm_r128_private_t *dev_priv = dev->dev_private;\n\tdrm_r128_sarea_t *sarea_priv = dev_priv->sarea_priv;\n\tdrm_r128_clear_t *clear = data;\n\tDRM_DEBUG(\"\\n\");\n\n\tLOCK_TEST_WITH_RETURN(dev, file_priv);\n\n\tRING_SPACE_TEST_WITH_RETURN(dev_priv);\n\n\tif (sarea_priv->nbox > R128_NR_SAREA_CLIPRECTS)\n\t\tsarea_priv->nbox = R128_NR_SAREA_CLIPRECTS;\n\n\tr128_cce_dispatch_clear(dev, clear);\n\tCOMMIT_RING();\n\n\t/* Make sure we restore the 3D state next time.\n\t */\n\tdev_priv->sarea_priv->dirty |= R128_UPLOAD_CONTEXT | R128_UPLOAD_MASKS;\n\n\treturn 0;\n}",
        "func": "static int r128_cce_clear(struct drm_device *dev, void *data, struct drm_file *file_priv)\n{\n\tdrm_r128_private_t *dev_priv = dev->dev_private;\n\tdrm_r128_sarea_t *sarea_priv;\n\tdrm_r128_clear_t *clear = data;\n\tDRM_DEBUG(\"\\n\");\n\n\tLOCK_TEST_WITH_RETURN(dev, file_priv);\n\n\tDEV_INIT_TEST_WITH_RETURN(dev_priv);\n\n\tRING_SPACE_TEST_WITH_RETURN(dev_priv);\n\n\tsarea_priv = dev_priv->sarea_priv;\n\n\tif (sarea_priv->nbox > R128_NR_SAREA_CLIPRECTS)\n\t\tsarea_priv->nbox = R128_NR_SAREA_CLIPRECTS;\n\n\tr128_cce_dispatch_clear(dev, clear);\n\tCOMMIT_RING();\n\n\t/* Make sure we restore the 3D state next time.\n\t */\n\tdev_priv->sarea_priv->dirty |= R128_UPLOAD_CONTEXT | R128_UPLOAD_MASKS;\n\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,13 +1,17 @@\n static int r128_cce_clear(struct drm_device *dev, void *data, struct drm_file *file_priv)\n {\n \tdrm_r128_private_t *dev_priv = dev->dev_private;\n-\tdrm_r128_sarea_t *sarea_priv = dev_priv->sarea_priv;\n+\tdrm_r128_sarea_t *sarea_priv;\n \tdrm_r128_clear_t *clear = data;\n \tDRM_DEBUG(\"\\n\");\n \n \tLOCK_TEST_WITH_RETURN(dev, file_priv);\n \n+\tDEV_INIT_TEST_WITH_RETURN(dev_priv);\n+\n \tRING_SPACE_TEST_WITH_RETURN(dev_priv);\n+\n+\tsarea_priv = dev_priv->sarea_priv;\n \n \tif (sarea_priv->nbox > R128_NR_SAREA_CLIPRECTS)\n \t\tsarea_priv->nbox = R128_NR_SAREA_CLIPRECTS;",
        "diff_line_info": {
            "deleted_lines": [
                "\tdrm_r128_sarea_t *sarea_priv = dev_priv->sarea_priv;"
            ],
            "added_lines": [
                "\tdrm_r128_sarea_t *sarea_priv;",
                "\tDEV_INIT_TEST_WITH_RETURN(dev_priv);",
                "",
                "",
                "\tsarea_priv = dev_priv->sarea_priv;"
            ]
        }
    },
    {
        "cve_id": "CVE-2009-3620",
        "func_name": "torvalds/linux/r128_cce_swap",
        "description": "The ATI Rage 128 (aka r128) driver in the Linux kernel before 2.6.31-git11 does not properly verify Concurrent Command Engine (CCE) state initialization, which allows local users to cause a denial of service (NULL pointer dereference and system crash) or possibly gain privileges via unspecified ioctl calls.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=7dc482dfeeeefcfd000d4271c4626937406756d7",
        "commit_title": "Almost all r128's private ioctls require that the CCE state has",
        "commit_text": "already been initialised.  However, most do not test that this has been done, and will proceed to dereference a null pointer.  This may result in a security vulnerability, since some ioctls are unprivileged.  This adds a macro for the common initialisation test and changes all ioctl implementations that require prior initialisation to use that macro.  Also, r128_do_init_cce() does not test that the CCE state has not been initialised already.  Repeated initialisation may lead to a crash or resource leak.  This adds that test.  ",
        "func_before": "static int r128_cce_swap(struct drm_device *dev, void *data, struct drm_file *file_priv)\n{\n\tdrm_r128_private_t *dev_priv = dev->dev_private;\n\tdrm_r128_sarea_t *sarea_priv = dev_priv->sarea_priv;\n\tDRM_DEBUG(\"\\n\");\n\n\tLOCK_TEST_WITH_RETURN(dev, file_priv);\n\n\tRING_SPACE_TEST_WITH_RETURN(dev_priv);\n\n\tif (sarea_priv->nbox > R128_NR_SAREA_CLIPRECTS)\n\t\tsarea_priv->nbox = R128_NR_SAREA_CLIPRECTS;\n\n\tr128_cce_dispatch_swap(dev);\n\tdev_priv->sarea_priv->dirty |= (R128_UPLOAD_CONTEXT |\n\t\t\t\t\tR128_UPLOAD_MASKS);\n\n\tCOMMIT_RING();\n\treturn 0;\n}",
        "func": "static int r128_cce_swap(struct drm_device *dev, void *data, struct drm_file *file_priv)\n{\n\tdrm_r128_private_t *dev_priv = dev->dev_private;\n\tdrm_r128_sarea_t *sarea_priv = dev_priv->sarea_priv;\n\tDRM_DEBUG(\"\\n\");\n\n\tLOCK_TEST_WITH_RETURN(dev, file_priv);\n\n\tDEV_INIT_TEST_WITH_RETURN(dev_priv);\n\n\tRING_SPACE_TEST_WITH_RETURN(dev_priv);\n\n\tif (sarea_priv->nbox > R128_NR_SAREA_CLIPRECTS)\n\t\tsarea_priv->nbox = R128_NR_SAREA_CLIPRECTS;\n\n\tr128_cce_dispatch_swap(dev);\n\tdev_priv->sarea_priv->dirty |= (R128_UPLOAD_CONTEXT |\n\t\t\t\t\tR128_UPLOAD_MASKS);\n\n\tCOMMIT_RING();\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,6 +5,8 @@\n \tDRM_DEBUG(\"\\n\");\n \n \tLOCK_TEST_WITH_RETURN(dev, file_priv);\n+\n+\tDEV_INIT_TEST_WITH_RETURN(dev_priv);\n \n \tRING_SPACE_TEST_WITH_RETURN(dev_priv);\n ",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "\tDEV_INIT_TEST_WITH_RETURN(dev_priv);"
            ]
        }
    },
    {
        "cve_id": "CVE-2009-3620",
        "func_name": "torvalds/linux/r128_cce_indirect",
        "description": "The ATI Rage 128 (aka r128) driver in the Linux kernel before 2.6.31-git11 does not properly verify Concurrent Command Engine (CCE) state initialization, which allows local users to cause a denial of service (NULL pointer dereference and system crash) or possibly gain privileges via unspecified ioctl calls.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=7dc482dfeeeefcfd000d4271c4626937406756d7",
        "commit_title": "Almost all r128's private ioctls require that the CCE state has",
        "commit_text": "already been initialised.  However, most do not test that this has been done, and will proceed to dereference a null pointer.  This may result in a security vulnerability, since some ioctls are unprivileged.  This adds a macro for the common initialisation test and changes all ioctl implementations that require prior initialisation to use that macro.  Also, r128_do_init_cce() does not test that the CCE state has not been initialised already.  Repeated initialisation may lead to a crash or resource leak.  This adds that test.  ",
        "func_before": "static int r128_cce_indirect(struct drm_device *dev, void *data, struct drm_file *file_priv)\n{\n\tdrm_r128_private_t *dev_priv = dev->dev_private;\n\tstruct drm_device_dma *dma = dev->dma;\n\tstruct drm_buf *buf;\n\tdrm_r128_buf_priv_t *buf_priv;\n\tdrm_r128_indirect_t *indirect = data;\n#if 0\n\tRING_LOCALS;\n#endif\n\n\tLOCK_TEST_WITH_RETURN(dev, file_priv);\n\n\tif (!dev_priv) {\n\t\tDRM_ERROR(\"called with no initialization\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tDRM_DEBUG(\"idx=%d s=%d e=%d d=%d\\n\",\n\t\t  indirect->idx, indirect->start, indirect->end,\n\t\t  indirect->discard);\n\n\tif (indirect->idx < 0 || indirect->idx >= dma->buf_count) {\n\t\tDRM_ERROR(\"buffer index %d (of %d max)\\n\",\n\t\t\t  indirect->idx, dma->buf_count - 1);\n\t\treturn -EINVAL;\n\t}\n\n\tbuf = dma->buflist[indirect->idx];\n\tbuf_priv = buf->dev_private;\n\n\tif (buf->file_priv != file_priv) {\n\t\tDRM_ERROR(\"process %d using buffer owned by %p\\n\",\n\t\t\t  DRM_CURRENTPID, buf->file_priv);\n\t\treturn -EINVAL;\n\t}\n\tif (buf->pending) {\n\t\tDRM_ERROR(\"sending pending buffer %d\\n\", indirect->idx);\n\t\treturn -EINVAL;\n\t}\n\n\tif (indirect->start < buf->used) {\n\t\tDRM_ERROR(\"reusing indirect: start=0x%x actual=0x%x\\n\",\n\t\t\t  indirect->start, buf->used);\n\t\treturn -EINVAL;\n\t}\n\n\tRING_SPACE_TEST_WITH_RETURN(dev_priv);\n\tVB_AGE_TEST_WITH_RETURN(dev_priv);\n\n\tbuf->used = indirect->end;\n\tbuf_priv->discard = indirect->discard;\n\n#if 0\n\t/* Wait for the 3D stream to idle before the indirect buffer\n\t * containing 2D acceleration commands is processed.\n\t */\n\tBEGIN_RING(2);\n\tRADEON_WAIT_UNTIL_3D_IDLE();\n\tADVANCE_RING();\n#endif\n\n\t/* Dispatch the indirect buffer full of commands from the\n\t * X server.  This is insecure and is thus only available to\n\t * privileged clients.\n\t */\n\tr128_cce_dispatch_indirect(dev, buf, indirect->start, indirect->end);\n\n\tCOMMIT_RING();\n\treturn 0;\n}",
        "func": "static int r128_cce_indirect(struct drm_device *dev, void *data, struct drm_file *file_priv)\n{\n\tdrm_r128_private_t *dev_priv = dev->dev_private;\n\tstruct drm_device_dma *dma = dev->dma;\n\tstruct drm_buf *buf;\n\tdrm_r128_buf_priv_t *buf_priv;\n\tdrm_r128_indirect_t *indirect = data;\n#if 0\n\tRING_LOCALS;\n#endif\n\n\tLOCK_TEST_WITH_RETURN(dev, file_priv);\n\n\tDEV_INIT_TEST_WITH_RETURN(dev_priv);\n\n\tDRM_DEBUG(\"idx=%d s=%d e=%d d=%d\\n\",\n\t\t  indirect->idx, indirect->start, indirect->end,\n\t\t  indirect->discard);\n\n\tif (indirect->idx < 0 || indirect->idx >= dma->buf_count) {\n\t\tDRM_ERROR(\"buffer index %d (of %d max)\\n\",\n\t\t\t  indirect->idx, dma->buf_count - 1);\n\t\treturn -EINVAL;\n\t}\n\n\tbuf = dma->buflist[indirect->idx];\n\tbuf_priv = buf->dev_private;\n\n\tif (buf->file_priv != file_priv) {\n\t\tDRM_ERROR(\"process %d using buffer owned by %p\\n\",\n\t\t\t  DRM_CURRENTPID, buf->file_priv);\n\t\treturn -EINVAL;\n\t}\n\tif (buf->pending) {\n\t\tDRM_ERROR(\"sending pending buffer %d\\n\", indirect->idx);\n\t\treturn -EINVAL;\n\t}\n\n\tif (indirect->start < buf->used) {\n\t\tDRM_ERROR(\"reusing indirect: start=0x%x actual=0x%x\\n\",\n\t\t\t  indirect->start, buf->used);\n\t\treturn -EINVAL;\n\t}\n\n\tRING_SPACE_TEST_WITH_RETURN(dev_priv);\n\tVB_AGE_TEST_WITH_RETURN(dev_priv);\n\n\tbuf->used = indirect->end;\n\tbuf_priv->discard = indirect->discard;\n\n#if 0\n\t/* Wait for the 3D stream to idle before the indirect buffer\n\t * containing 2D acceleration commands is processed.\n\t */\n\tBEGIN_RING(2);\n\tRADEON_WAIT_UNTIL_3D_IDLE();\n\tADVANCE_RING();\n#endif\n\n\t/* Dispatch the indirect buffer full of commands from the\n\t * X server.  This is insecure and is thus only available to\n\t * privileged clients.\n\t */\n\tr128_cce_dispatch_indirect(dev, buf, indirect->start, indirect->end);\n\n\tCOMMIT_RING();\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -11,10 +11,7 @@\n \n \tLOCK_TEST_WITH_RETURN(dev, file_priv);\n \n-\tif (!dev_priv) {\n-\t\tDRM_ERROR(\"called with no initialization\\n\");\n-\t\treturn -EINVAL;\n-\t}\n+\tDEV_INIT_TEST_WITH_RETURN(dev_priv);\n \n \tDRM_DEBUG(\"idx=%d s=%d e=%d d=%d\\n\",\n \t\t  indirect->idx, indirect->start, indirect->end,",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (!dev_priv) {",
                "\t\tDRM_ERROR(\"called with no initialization\\n\");",
                "\t\treturn -EINVAL;",
                "\t}"
            ],
            "added_lines": [
                "\tDEV_INIT_TEST_WITH_RETURN(dev_priv);"
            ]
        }
    },
    {
        "cve_id": "CVE-2009-3620",
        "func_name": "torvalds/linux/r128_getparam",
        "description": "The ATI Rage 128 (aka r128) driver in the Linux kernel before 2.6.31-git11 does not properly verify Concurrent Command Engine (CCE) state initialization, which allows local users to cause a denial of service (NULL pointer dereference and system crash) or possibly gain privileges via unspecified ioctl calls.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=7dc482dfeeeefcfd000d4271c4626937406756d7",
        "commit_title": "Almost all r128's private ioctls require that the CCE state has",
        "commit_text": "already been initialised.  However, most do not test that this has been done, and will proceed to dereference a null pointer.  This may result in a security vulnerability, since some ioctls are unprivileged.  This adds a macro for the common initialisation test and changes all ioctl implementations that require prior initialisation to use that macro.  Also, r128_do_init_cce() does not test that the CCE state has not been initialised already.  Repeated initialisation may lead to a crash or resource leak.  This adds that test.  ",
        "func_before": "static int r128_getparam(struct drm_device *dev, void *data, struct drm_file *file_priv)\n{\n\tdrm_r128_private_t *dev_priv = dev->dev_private;\n\tdrm_r128_getparam_t *param = data;\n\tint value;\n\n\tif (!dev_priv) {\n\t\tDRM_ERROR(\"called with no initialization\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tDRM_DEBUG(\"pid=%d\\n\", DRM_CURRENTPID);\n\n\tswitch (param->param) {\n\tcase R128_PARAM_IRQ_NR:\n\t\tvalue = drm_dev_to_irq(dev);\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\tif (DRM_COPY_TO_USER(param->value, &value, sizeof(int))) {\n\t\tDRM_ERROR(\"copy_to_user\\n\");\n\t\treturn -EFAULT;\n\t}\n\n\treturn 0;\n}",
        "func": "static int r128_getparam(struct drm_device *dev, void *data, struct drm_file *file_priv)\n{\n\tdrm_r128_private_t *dev_priv = dev->dev_private;\n\tdrm_r128_getparam_t *param = data;\n\tint value;\n\n\tDEV_INIT_TEST_WITH_RETURN(dev_priv);\n\n\tDRM_DEBUG(\"pid=%d\\n\", DRM_CURRENTPID);\n\n\tswitch (param->param) {\n\tcase R128_PARAM_IRQ_NR:\n\t\tvalue = drm_dev_to_irq(dev);\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\tif (DRM_COPY_TO_USER(param->value, &value, sizeof(int))) {\n\t\tDRM_ERROR(\"copy_to_user\\n\");\n\t\treturn -EFAULT;\n\t}\n\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,10 +4,7 @@\n \tdrm_r128_getparam_t *param = data;\n \tint value;\n \n-\tif (!dev_priv) {\n-\t\tDRM_ERROR(\"called with no initialization\\n\");\n-\t\treturn -EINVAL;\n-\t}\n+\tDEV_INIT_TEST_WITH_RETURN(dev_priv);\n \n \tDRM_DEBUG(\"pid=%d\\n\", DRM_CURRENTPID);\n ",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (!dev_priv) {",
                "\t\tDRM_ERROR(\"called with no initialization\\n\");",
                "\t\treturn -EINVAL;",
                "\t}"
            ],
            "added_lines": [
                "\tDEV_INIT_TEST_WITH_RETURN(dev_priv);"
            ]
        }
    },
    {
        "cve_id": "CVE-2009-3620",
        "func_name": "torvalds/linux/r128_cce_flip",
        "description": "The ATI Rage 128 (aka r128) driver in the Linux kernel before 2.6.31-git11 does not properly verify Concurrent Command Engine (CCE) state initialization, which allows local users to cause a denial of service (NULL pointer dereference and system crash) or possibly gain privileges via unspecified ioctl calls.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=7dc482dfeeeefcfd000d4271c4626937406756d7",
        "commit_title": "Almost all r128's private ioctls require that the CCE state has",
        "commit_text": "already been initialised.  However, most do not test that this has been done, and will proceed to dereference a null pointer.  This may result in a security vulnerability, since some ioctls are unprivileged.  This adds a macro for the common initialisation test and changes all ioctl implementations that require prior initialisation to use that macro.  Also, r128_do_init_cce() does not test that the CCE state has not been initialised already.  Repeated initialisation may lead to a crash or resource leak.  This adds that test.  ",
        "func_before": "static int r128_cce_flip(struct drm_device *dev, void *data, struct drm_file *file_priv)\n{\n\tdrm_r128_private_t *dev_priv = dev->dev_private;\n\tDRM_DEBUG(\"\\n\");\n\n\tLOCK_TEST_WITH_RETURN(dev, file_priv);\n\n\tRING_SPACE_TEST_WITH_RETURN(dev_priv);\n\n\tif (!dev_priv->page_flipping)\n\t\tr128_do_init_pageflip(dev);\n\n\tr128_cce_dispatch_flip(dev);\n\n\tCOMMIT_RING();\n\treturn 0;\n}",
        "func": "static int r128_cce_flip(struct drm_device *dev, void *data, struct drm_file *file_priv)\n{\n\tdrm_r128_private_t *dev_priv = dev->dev_private;\n\tDRM_DEBUG(\"\\n\");\n\n\tLOCK_TEST_WITH_RETURN(dev, file_priv);\n\n\tDEV_INIT_TEST_WITH_RETURN(dev_priv);\n\n\tRING_SPACE_TEST_WITH_RETURN(dev_priv);\n\n\tif (!dev_priv->page_flipping)\n\t\tr128_do_init_pageflip(dev);\n\n\tr128_cce_dispatch_flip(dev);\n\n\tCOMMIT_RING();\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,6 +4,8 @@\n \tDRM_DEBUG(\"\\n\");\n \n \tLOCK_TEST_WITH_RETURN(dev, file_priv);\n+\n+\tDEV_INIT_TEST_WITH_RETURN(dev_priv);\n \n \tRING_SPACE_TEST_WITH_RETURN(dev_priv);\n ",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "\tDEV_INIT_TEST_WITH_RETURN(dev_priv);"
            ]
        }
    },
    {
        "cve_id": "CVE-2023-35847",
        "func_name": "virtualsquare/picotcp/pico_tcp_open",
        "description": "VirtualSquare picoTCP (aka PicoTCP-NG) through 2.1 does not have an MSS lower bound (e.g., it could be zero).",
        "git_url": "https://github.com/virtualsquare/picotcp/commit/eaf166009e44641e6570c576ba071217f100fd99",
        "commit_title": "TCP: Fixed MSS size calculation. Set MSS lower bound.",
        "commit_text": "",
        "func_before": "struct pico_socket *pico_tcp_open(struct pico_stack *S, uint16_t family)\n{\n    struct pico_socket_tcp *t = PICO_ZALLOC(sizeof(struct pico_socket_tcp));\n    if (!t)\n        return NULL;\n\n    t->sock.stack = S;\n    t->sock.timestamp = TCP_TIME;\n    pico_socket_set_family(&t->sock, family);\n    t->mss = (uint16_t)(pico_socket_get_mss(&t->sock) - PICO_SIZE_TCPHDR);\n    t->tcpq_in.pool.root = t->tcpq_hold.pool.root = t->tcpq_out.pool.root = &LEAF;\n    t->tcpq_hold.pool.compare = t->tcpq_out.pool.compare = segment_compare;\n    t->tcpq_in.pool.compare = input_segment_compare;\n    t->tcpq_in.max_size = PICO_DEFAULT_SOCKETQ;\n    t->tcpq_out.max_size = PICO_DEFAULT_SOCKETQ;\n    t->tcpq_hold.max_size = 2u * t->mss;\n    rto_set(t, PICO_TCP_RTO_MIN);\n\n    /* Uncomment next line and disable Nagle by default */\n    t->sock.opt_flags |= (1 << PICO_SOCKET_OPT_TCPNODELAY);\n\n    /* Uncomment next line and Nagle is enabled by default */\n    /* t->sock.opt_flags &= (uint16_t) ~(1 << PICO_SOCKET_OPT_TCPNODELAY); */\n\n    /* Set default linger for the socket */\n    t->linger_timeout = PICO_SOCKET_LINGER_TIMEOUT;\n\n\n#ifdef PICO_TCP_SUPPORT_SOCKET_STATS\n    if (!pico_timer_add(t->sock.stack, 2000, sock_stats, t)) {\n        tcp_dbg(\"TCP: Failed to start socket statistics timer\\n\");\n        PICO_FREE(t);\n        return NULL;\n    }\n#endif\n\n    t->keepalive_tmr = pico_timer_add(t->sock.stack, 1000, pico_tcp_keepalive, t);\n    if (!t->keepalive_tmr) {\n        tcp_dbg(\"TCP: Failed to start keepalive timer\\n\");\n        PICO_FREE(t);\n        return NULL;\n    }\n    tcp_set_space(t);\n    return &t->sock;\n}",
        "func": "struct pico_socket *pico_tcp_open(struct pico_stack *S, uint16_t family)\n{\n    struct pico_socket_tcp *t = PICO_ZALLOC(sizeof(struct pico_socket_tcp));\n    if (!t)\n        return NULL;\n\n    t->sock.stack = S;\n    t->sock.timestamp = TCP_TIME;\n    pico_socket_set_family(&t->sock, family);\n    t->mss = (uint16_t)(pico_socket_get_mss(&t->sock));\n    if (t->mss > PICO_SIZE_TCPHDR + PICO_TCP_MIN_MSS)\n        t->mss -= (uint16_t)PICO_SIZE_TCPHDR;\n    else\n        t->mss = PICO_TCP_MIN_MSS;\n    t->tcpq_in.pool.root = t->tcpq_hold.pool.root = t->tcpq_out.pool.root = &LEAF;\n    t->tcpq_hold.pool.compare = t->tcpq_out.pool.compare = segment_compare;\n    t->tcpq_in.pool.compare = input_segment_compare;\n    t->tcpq_in.max_size = PICO_DEFAULT_SOCKETQ;\n    t->tcpq_out.max_size = PICO_DEFAULT_SOCKETQ;\n    t->tcpq_hold.max_size = 2u * t->mss;\n    rto_set(t, PICO_TCP_RTO_MIN);\n\n    /* Uncomment next line and disable Nagle by default */\n    t->sock.opt_flags |= (1 << PICO_SOCKET_OPT_TCPNODELAY);\n\n    /* Uncomment next line and Nagle is enabled by default */\n    /* t->sock.opt_flags &= (uint16_t) ~(1 << PICO_SOCKET_OPT_TCPNODELAY); */\n\n    /* Set default linger for the socket */\n    t->linger_timeout = PICO_SOCKET_LINGER_TIMEOUT;\n\n\n#ifdef PICO_TCP_SUPPORT_SOCKET_STATS\n    if (!pico_timer_add(t->sock.stack, 2000, sock_stats, t)) {\n        tcp_dbg(\"TCP: Failed to start socket statistics timer\\n\");\n        PICO_FREE(t);\n        return NULL;\n    }\n#endif\n\n    t->keepalive_tmr = pico_timer_add(t->sock.stack, 1000, pico_tcp_keepalive, t);\n    if (!t->keepalive_tmr) {\n        tcp_dbg(\"TCP: Failed to start keepalive timer\\n\");\n        PICO_FREE(t);\n        return NULL;\n    }\n    tcp_set_space(t);\n    return &t->sock;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -7,7 +7,11 @@\n     t->sock.stack = S;\n     t->sock.timestamp = TCP_TIME;\n     pico_socket_set_family(&t->sock, family);\n-    t->mss = (uint16_t)(pico_socket_get_mss(&t->sock) - PICO_SIZE_TCPHDR);\n+    t->mss = (uint16_t)(pico_socket_get_mss(&t->sock));\n+    if (t->mss > PICO_SIZE_TCPHDR + PICO_TCP_MIN_MSS)\n+        t->mss -= (uint16_t)PICO_SIZE_TCPHDR;\n+    else\n+        t->mss = PICO_TCP_MIN_MSS;\n     t->tcpq_in.pool.root = t->tcpq_hold.pool.root = t->tcpq_out.pool.root = &LEAF;\n     t->tcpq_hold.pool.compare = t->tcpq_out.pool.compare = segment_compare;\n     t->tcpq_in.pool.compare = input_segment_compare;",
        "diff_line_info": {
            "deleted_lines": [
                "    t->mss = (uint16_t)(pico_socket_get_mss(&t->sock) - PICO_SIZE_TCPHDR);"
            ],
            "added_lines": [
                "    t->mss = (uint16_t)(pico_socket_get_mss(&t->sock));",
                "    if (t->mss > PICO_SIZE_TCPHDR + PICO_TCP_MIN_MSS)",
                "        t->mss -= (uint16_t)PICO_SIZE_TCPHDR;",
                "    else",
                "        t->mss = PICO_TCP_MIN_MSS;"
            ]
        }
    },
    {
        "cve_id": "CVE-2023-35847",
        "func_name": "virtualsquare/picotcp/pico_tcp_initconn",
        "description": "VirtualSquare picoTCP (aka PicoTCP-NG) through 2.1 does not have an MSS lower bound (e.g., it could be zero).",
        "git_url": "https://github.com/virtualsquare/picotcp/commit/eaf166009e44641e6570c576ba071217f100fd99",
        "commit_title": "TCP: Fixed MSS size calculation. Set MSS lower bound.",
        "commit_text": "",
        "func_before": "int pico_tcp_initconn(struct pico_socket *s)\n{\n    struct pico_socket_tcp *ts = TCP_SOCK(s);\n    struct pico_frame *syn;\n    struct pico_tcp_hdr *hdr;\n    uint16_t mtu, opt_len = tcp_options_size(ts, PICO_TCP_SYN);\n\n    syn = s->net->alloc(s->stack, s->net, NULL, (uint16_t)(PICO_SIZE_TCPHDR + opt_len));\n    if (!syn)\n        return -1;\n\n    hdr = (struct pico_tcp_hdr *) syn->transport_hdr;\n\n    if (!ts->snd_nxt)\n        ts->snd_nxt = long_be(pico_paws());\n\n    ts->snd_last = ts->snd_nxt;\n    ts->cwnd = PICO_TCP_IW;\n    mtu = (uint16_t)pico_socket_get_mss(s);\n    ts->mss = (uint16_t)(mtu - PICO_SIZE_TCPHDR);\n    ts->ssthresh = (uint16_t)((uint16_t)(PICO_DEFAULT_SOCKETQ / ts->mss) -  (((uint16_t)(PICO_DEFAULT_SOCKETQ / ts->mss)) >> 3u));\n    syn->sock = s;\n    hdr->seq = long_be(ts->snd_nxt);\n    hdr->len = (uint8_t)((PICO_SIZE_TCPHDR + opt_len) << 2);\n    hdr->flags = PICO_TCP_SYN;\n    tcp_set_space(ts);\n    hdr->rwnd = short_be(ts->wnd);\n    tcp_add_options(ts, syn, PICO_TCP_SYN, opt_len);\n    hdr->trans.sport = ts->sock.local_port;\n    hdr->trans.dport = ts->sock.remote_port;\n\n    hdr->crc = 0;\n    hdr->crc = short_be(pico_tcp_checksum(syn));\n\n    /* TCP: ENQUEUE to PROTO ( SYN ) */\n    tcp_dbg(\"Sending SYN... (ports: %d - %d) size: %d\\n\", short_be(ts->sock.local_port), short_be(ts->sock.remote_port), syn->buffer_len);\n    ts->retrans_tmr = pico_timer_add(s->stack, PICO_TCP_SYN_TO << ts->backoff, initconn_retry, ts);\n    if (!ts->retrans_tmr) {\n        tcp_dbg(\"TCP: Failed to start initconn_retry timer\\n\");\n        PICO_FREE(syn);\n        return -1;\n    }\n    pico_enqueue(&s->stack->q_tcp.out, syn);\n    return 0;\n}",
        "func": "int pico_tcp_initconn(struct pico_socket *s)\n{\n    struct pico_socket_tcp *ts = TCP_SOCK(s);\n    struct pico_frame *syn;\n    struct pico_tcp_hdr *hdr;\n    uint16_t mtu, opt_len = tcp_options_size(ts, PICO_TCP_SYN);\n\n    syn = s->net->alloc(s->stack, s->net, NULL, (uint16_t)(PICO_SIZE_TCPHDR + opt_len));\n    if (!syn)\n        return -1;\n\n    hdr = (struct pico_tcp_hdr *) syn->transport_hdr;\n\n    if (!ts->snd_nxt)\n        ts->snd_nxt = long_be(pico_paws());\n\n    ts->snd_last = ts->snd_nxt;\n    ts->cwnd = PICO_TCP_IW;\n    mtu = (uint16_t)pico_socket_get_mss(s);\n    if (mtu > PICO_SIZE_TCPHDR + PICO_TCP_MIN_MSS)\n        ts->mss = (uint16_t)(mtu - PICO_SIZE_TCPHDR);\n    else\n        ts->mss = PICO_TCP_MIN_MSS;\n    ts->ssthresh = (uint16_t)((uint16_t)(PICO_DEFAULT_SOCKETQ / ts->mss) -  (((uint16_t)(PICO_DEFAULT_SOCKETQ / ts->mss)) >> 3u));\n    syn->sock = s;\n    hdr->seq = long_be(ts->snd_nxt);\n    hdr->len = (uint8_t)((PICO_SIZE_TCPHDR + opt_len) << 2);\n    hdr->flags = PICO_TCP_SYN;\n    tcp_set_space(ts);\n    hdr->rwnd = short_be(ts->wnd);\n    tcp_add_options(ts, syn, PICO_TCP_SYN, opt_len);\n    hdr->trans.sport = ts->sock.local_port;\n    hdr->trans.dport = ts->sock.remote_port;\n\n    hdr->crc = 0;\n    hdr->crc = short_be(pico_tcp_checksum(syn));\n\n    /* TCP: ENQUEUE to PROTO ( SYN ) */\n    tcp_dbg(\"Sending SYN... (ports: %d - %d) size: %d\\n\", short_be(ts->sock.local_port), short_be(ts->sock.remote_port), syn->buffer_len);\n    ts->retrans_tmr = pico_timer_add(s->stack, PICO_TCP_SYN_TO << ts->backoff, initconn_retry, ts);\n    if (!ts->retrans_tmr) {\n        tcp_dbg(\"TCP: Failed to start initconn_retry timer\\n\");\n        PICO_FREE(syn);\n        return -1;\n    }\n    pico_enqueue(&s->stack->q_tcp.out, syn);\n    return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -17,7 +17,10 @@\n     ts->snd_last = ts->snd_nxt;\n     ts->cwnd = PICO_TCP_IW;\n     mtu = (uint16_t)pico_socket_get_mss(s);\n-    ts->mss = (uint16_t)(mtu - PICO_SIZE_TCPHDR);\n+    if (mtu > PICO_SIZE_TCPHDR + PICO_TCP_MIN_MSS)\n+        ts->mss = (uint16_t)(mtu - PICO_SIZE_TCPHDR);\n+    else\n+        ts->mss = PICO_TCP_MIN_MSS;\n     ts->ssthresh = (uint16_t)((uint16_t)(PICO_DEFAULT_SOCKETQ / ts->mss) -  (((uint16_t)(PICO_DEFAULT_SOCKETQ / ts->mss)) >> 3u));\n     syn->sock = s;\n     hdr->seq = long_be(ts->snd_nxt);",
        "diff_line_info": {
            "deleted_lines": [
                "    ts->mss = (uint16_t)(mtu - PICO_SIZE_TCPHDR);"
            ],
            "added_lines": [
                "    if (mtu > PICO_SIZE_TCPHDR + PICO_TCP_MIN_MSS)",
                "        ts->mss = (uint16_t)(mtu - PICO_SIZE_TCPHDR);",
                "    else",
                "        ts->mss = PICO_TCP_MIN_MSS;"
            ]
        }
    },
    {
        "cve_id": "CVE-2023-35847",
        "func_name": "virtualsquare/picotcp/tcp_syn",
        "description": "VirtualSquare picoTCP (aka PicoTCP-NG) through 2.1 does not have an MSS lower bound (e.g., it could be zero).",
        "git_url": "https://github.com/virtualsquare/picotcp/commit/eaf166009e44641e6570c576ba071217f100fd99",
        "commit_title": "TCP: Fixed MSS size calculation. Set MSS lower bound.",
        "commit_text": "",
        "func_before": "static int tcp_syn(struct pico_socket *s, struct pico_frame *f)\n{\n    struct pico_socket_tcp *new = NULL;\n    struct pico_tcp_hdr *hdr = NULL;\n    uint16_t mtu;\n    if(s->number_of_pending_conn >= s->max_backlog)\n        return -1;\n\n    new = (struct pico_socket_tcp *)pico_socket_clone(s);\n    hdr = (struct pico_tcp_hdr *)f->transport_hdr;\n    if (!new)\n        return -1;\n\n#ifdef PICO_TCP_SUPPORT_SOCKET_STATS\n    if (!pico_timer_add(t->sock.stack, 2000, sock_stats, s)) {\n        tcp_dbg(\"TCP: Failed to start socket statistics timer\\n\");\n        return -1;\n    }\n#endif\n\n    new->sock.remote_port = ((struct pico_trans *)f->transport_hdr)->sport;\n#ifdef PICO_SUPPORT_IPV4\n    if (IS_IPV4(f)) {\n        new->sock.remote_addr.ip4.addr = ((struct pico_ipv4_hdr *)(f->net_hdr))->src.addr;\n        new->sock.local_addr.ip4.addr = ((struct pico_ipv4_hdr *)(f->net_hdr))->dst.addr;\n    }\n\n#endif\n#ifdef PICO_SUPPORT_IPV6\n    if (IS_IPV6(f)) {\n        new->sock.remote_addr.ip6 = ((struct pico_ipv6_hdr *)(f->net_hdr))->src;\n        new->sock.local_addr.ip6 = ((struct pico_ipv6_hdr *)(f->net_hdr))->dst;\n    }\n\n#endif\n    f->sock = &new->sock;\n    mtu = (uint16_t)pico_socket_get_mss(&new->sock);\n    new->mss = (uint16_t)(mtu - PICO_SIZE_TCPHDR);\n    if (tcp_parse_options(f) < 0)\n        return -1;\n    new->sock.stack = s->stack;\n    new->tcpq_in.max_size = PICO_DEFAULT_SOCKETQ;\n    new->tcpq_out.max_size = PICO_DEFAULT_SOCKETQ;\n    new->tcpq_hold.max_size = 2u * mtu;\n    new->rcv_nxt = long_be(hdr->seq) + 1;\n    new->snd_nxt = long_be(pico_paws());\n    new->snd_last = new->snd_nxt;\n    new->cwnd = PICO_TCP_IW;\n    new->ssthresh = (uint16_t)((uint16_t)(PICO_DEFAULT_SOCKETQ / new->mss) -  (((uint16_t)(PICO_DEFAULT_SOCKETQ / new->mss)) >> 3u));\n    new->recv_wnd = short_be(hdr->rwnd);\n    new->linger_timeout = PICO_SOCKET_LINGER_TIMEOUT;\n    s->number_of_pending_conn++;\n    new->sock.parent = s;\n    new->sock.wakeup = s->wakeup;\n    rto_set(new, PICO_TCP_RTO_MIN);\n    /* Initialize timestamp values */\n    new->sock.state = PICO_SOCKET_STATE_BOUND | PICO_SOCKET_STATE_CONNECTED | PICO_SOCKET_STATE_TCP_SYN_RECV;\n    pico_socket_add(&new->sock);\n    tcp_send_synack(&new->sock);\n    tcp_dbg(\"SYNACK sent, socket added. snd_nxt is %08x\\n\", new->snd_nxt);\n    return 0;\n}",
        "func": "static int tcp_syn(struct pico_socket *s, struct pico_frame *f)\n{\n    struct pico_socket_tcp *new = NULL;\n    struct pico_tcp_hdr *hdr = NULL;\n    uint16_t mtu;\n    if(s->number_of_pending_conn >= s->max_backlog)\n        return -1;\n\n    new = (struct pico_socket_tcp *)pico_socket_clone(s);\n    hdr = (struct pico_tcp_hdr *)f->transport_hdr;\n    if (!new)\n        return -1;\n\n#ifdef PICO_TCP_SUPPORT_SOCKET_STATS\n    if (!pico_timer_add(t->sock.stack, 2000, sock_stats, s)) {\n        tcp_dbg(\"TCP: Failed to start socket statistics timer\\n\");\n        return -1;\n    }\n#endif\n\n    new->sock.remote_port = ((struct pico_trans *)f->transport_hdr)->sport;\n#ifdef PICO_SUPPORT_IPV4\n    if (IS_IPV4(f)) {\n        new->sock.remote_addr.ip4.addr = ((struct pico_ipv4_hdr *)(f->net_hdr))->src.addr;\n        new->sock.local_addr.ip4.addr = ((struct pico_ipv4_hdr *)(f->net_hdr))->dst.addr;\n    }\n\n#endif\n#ifdef PICO_SUPPORT_IPV6\n    if (IS_IPV6(f)) {\n        new->sock.remote_addr.ip6 = ((struct pico_ipv6_hdr *)(f->net_hdr))->src;\n        new->sock.local_addr.ip6 = ((struct pico_ipv6_hdr *)(f->net_hdr))->dst;\n    }\n\n#endif\n    f->sock = &new->sock;\n    mtu = (uint16_t)pico_socket_get_mss(&new->sock);\n    if (mtu > PICO_SIZE_TCPHDR + PICO_TCP_MIN_MSS)\n        new->mss = (uint16_t)(mtu - PICO_SIZE_TCPHDR);\n    else\n        new->mss = PICO_TCP_MIN_MSS;\n    if (tcp_parse_options(f) < 0)\n        return -1;\n    new->sock.stack = s->stack;\n    new->tcpq_in.max_size = PICO_DEFAULT_SOCKETQ;\n    new->tcpq_out.max_size = PICO_DEFAULT_SOCKETQ;\n    new->tcpq_hold.max_size = 2u * mtu;\n    new->rcv_nxt = long_be(hdr->seq) + 1;\n    new->snd_nxt = long_be(pico_paws());\n    new->snd_last = new->snd_nxt;\n    new->cwnd = PICO_TCP_IW;\n    new->ssthresh = (uint16_t)((uint16_t)(PICO_DEFAULT_SOCKETQ / new->mss) -  (((uint16_t)(PICO_DEFAULT_SOCKETQ / new->mss)) >> 3u));\n    new->recv_wnd = short_be(hdr->rwnd);\n    new->linger_timeout = PICO_SOCKET_LINGER_TIMEOUT;\n    s->number_of_pending_conn++;\n    new->sock.parent = s;\n    new->sock.wakeup = s->wakeup;\n    rto_set(new, PICO_TCP_RTO_MIN);\n    /* Initialize timestamp values */\n    new->sock.state = PICO_SOCKET_STATE_BOUND | PICO_SOCKET_STATE_CONNECTED | PICO_SOCKET_STATE_TCP_SYN_RECV;\n    pico_socket_add(&new->sock);\n    tcp_send_synack(&new->sock);\n    tcp_dbg(\"SYNACK sent, socket added. snd_nxt is %08x\\n\", new->snd_nxt);\n    return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -35,7 +35,10 @@\n #endif\n     f->sock = &new->sock;\n     mtu = (uint16_t)pico_socket_get_mss(&new->sock);\n-    new->mss = (uint16_t)(mtu - PICO_SIZE_TCPHDR);\n+    if (mtu > PICO_SIZE_TCPHDR + PICO_TCP_MIN_MSS)\n+        new->mss = (uint16_t)(mtu - PICO_SIZE_TCPHDR);\n+    else\n+        new->mss = PICO_TCP_MIN_MSS;\n     if (tcp_parse_options(f) < 0)\n         return -1;\n     new->sock.stack = s->stack;",
        "diff_line_info": {
            "deleted_lines": [
                "    new->mss = (uint16_t)(mtu - PICO_SIZE_TCPHDR);"
            ],
            "added_lines": [
                "    if (mtu > PICO_SIZE_TCPHDR + PICO_TCP_MIN_MSS)",
                "        new->mss = (uint16_t)(mtu - PICO_SIZE_TCPHDR);",
                "    else",
                "        new->mss = PICO_TCP_MIN_MSS;"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-24753",
        "func_name": "objsys/oocborrt/cbor2json",
        "description": "A memory corruption vulnerability in Objective Open CBOR Run-time (oocborrt) in versions before 2020-08-12 could allow an attacker to execute code via crafted Concise Binary Object Representation (CBOR) input to the cbor2json decoder. An uncaught error while decoding CBOR Major Type 3 text strings leads to the use of an attacker-controllable uninitialized stack value. This can be used to modify memory, causing a crash or potentially exploitable heap corruption.",
        "git_url": "https://github.com/objsys/oocborrt/commit/539851c66778f68a244633985f6f8d0df94ea3b3",
        "commit_title": "fixed missing return status test error",
        "commit_text": "",
        "func_before": "static int cbor2json (OSCTXT* pCborCtxt, OSCTXT* pJsonCtxt)\n{\n   int ret = 0;\n   OSOCTET tag, ub;\n\n   /* Read byte from stream */\n   ret = rtxReadBytes (pCborCtxt, &ub, 1);\n   if (0 != ret) return LOG_RTERR (pCborCtxt, ret);\n   tag = ub >> 5;\n\n   /* Switch on tag value */\n   switch (tag) {\n   case OSRTCBOR_UINT: {\n      OSUINTTYPE value;\n      ret = rtCborDecUInt (pCborCtxt, ub, &value);\n      if (0 != ret) return LOG_RTERR (pCborCtxt, ret);\n\n      /* Encode JSON */\n#ifndef _NO_INT64_SUPPORT\n      ret = rtJsonEncUInt64Value (pJsonCtxt, value);\n#else\n      ret = rtJsonEncUIntValue (pJsonCtxt, value);\n#endif\n      if (0 != ret) return LOG_RTERR (pJsonCtxt, ret);\n      break;\n   }\n   case OSRTCBOR_NEGINT: {\n      OSINTTYPE value;\n      ret = rtCborDecInt (pCborCtxt, ub, &value);\n      if (0 != ret) return LOG_RTERR (pCborCtxt, ret);\n\n      /* Encode JSON */\n#ifndef _NO_INT64_SUPPORT\n      ret = rtJsonEncInt64Value (pJsonCtxt, value);\n#else\n      ret = rtJsonEncIntValue (pJsonCtxt, value);\n#endif\n      if (0 != ret) return LOG_RTERR (pJsonCtxt, ret);\n      break;\n   }\n   case OSRTCBOR_BYTESTR: {\n      OSDynOctStr64 byteStr;\n      ret = rtCborDecDynByteStr (pCborCtxt, ub, &byteStr);\n      if (0 != ret) return LOG_RTERR (pCborCtxt, ret);\n\n      /* Encode JSON */\n      ret = rtJsonEncHexStr (pJsonCtxt, byteStr.numocts, byteStr.data);\n      rtxMemFreePtr (pCborCtxt, byteStr.data);\n      if (0 != ret) return LOG_RTERR (pJsonCtxt, ret);\n\n      break;\n   }\n   case OSRTCBOR_UTF8STR: {\n      OSUTF8CHAR* utf8str;\n      ret = rtCborDecDynUTF8Str (pCborCtxt, ub, (char**)&utf8str);\n\n      ret = rtJsonEncStringValue (pJsonCtxt, utf8str);\n      rtxMemFreePtr (pCborCtxt, utf8str);\n      if (0 != ret) return LOG_RTERR (pJsonCtxt, ret);\n\n      break;\n   }\n   case OSRTCBOR_ARRAY: \n   case OSRTCBOR_MAP: {\n      OSOCTET len = ub & 0x1F;\n      char startChar = (tag == OSRTCBOR_ARRAY) ? '[' : '{';\n      char endChar = (tag == OSRTCBOR_ARRAY) ? ']' : '}';\n\n      OSRTSAFEPUTCHAR (pJsonCtxt, startChar);\n\n      if (len == OSRTCBOR_INDEF) {\n         OSBOOL first = TRUE;\n         for (;;) {\n            if (OSRTCBOR_MATCHEOC (pCborCtxt)) {\n               pCborCtxt->buffer.byteIndex++;\n               break;\n            }\n\n            if (!first) \n               OSRTSAFEPUTCHAR (pJsonCtxt, ',');\n            else\n               first = FALSE;\n\n            /* If map, decode object name */\n            if (tag == OSRTCBOR_MAP) {\n               ret = cborElemNameToJson (pCborCtxt, pJsonCtxt);\n            }\n\n            /* Make recursive call */\n            if (0 == ret)\n               ret = cbor2json (pCborCtxt, pJsonCtxt);\n            if (0 != ret) {\n               OSCTXT* pctxt = \n                  (rtxErrGetErrorCnt(pJsonCtxt) > 0) ? pJsonCtxt : pCborCtxt;\n               return LOG_RTERR (pctxt, ret);\n            }\n         }\n      }\n      else { /* definite length */\n         OSSIZE nitems;\n\n         /* Decode tag and number of items */\n         ret = rtCborDecSize (pCborCtxt, len, &nitems);\n         if (0 == ret) {\n            OSSIZE i;\n\n            /* Loop to decode array items */\n            for (i = 0; i < nitems; i++) {\n               if (0 != i) OSRTSAFEPUTCHAR (pJsonCtxt, ',');\n\n               /* If map, decode object name */\n               if (tag == OSRTCBOR_MAP) {\n                  ret = cborElemNameToJson (pCborCtxt, pJsonCtxt);\n               }\n\n               /* Make recursive call */\n               if (0 == ret)\n                  ret = cbor2json (pCborCtxt, pJsonCtxt);\n               if (0 != ret) {\n                  OSCTXT* pctxt = \n                  (rtxErrGetErrorCnt(pJsonCtxt) > 0) ? pJsonCtxt : pCborCtxt;\n                  return LOG_RTERR (pctxt, ret);\n               }\n            }\n         }\n      }\n      OSRTSAFEPUTCHAR (pJsonCtxt, endChar);\n      break;\n   }\n\n   case OSRTCBOR_FLOAT:\n      if (tag == OSRTCBOR_FALSEENC || tag == OSRTCBOR_TRUEENC) {\n         OSBOOL boolval = (ub == OSRTCBOR_TRUEENC) ? TRUE : FALSE;\n         ret = rtJsonEncBoolValue (pJsonCtxt, boolval);\n         if (0 != ret) return LOG_RTERR (pJsonCtxt, ret);\n      }\n      else if (tag == OSRTCBOR_FLT16ENC ||\n               tag == OSRTCBOR_FLT32ENC ||\n               tag == OSRTCBOR_FLT64ENC) {\n         OSDOUBLE fltval;\n         ret = rtCborDecFloat (pCborCtxt, ub, &fltval);\n         if (0 != ret) return LOG_RTERR (pCborCtxt, ret);\n\n         /* Encode JSON */\n         ret = rtJsonEncDoubleValue (pJsonCtxt, fltval, 0);\n         if (0 != ret) return LOG_RTERR (pJsonCtxt, ret);\n      }\n      else {\n         ret = cborTagNotSupp (pCborCtxt, tag);\n      }\n      break;\n\n   default:\n      ret = cborTagNotSupp (pCborCtxt, tag);\n   }\n\n   return ret;\n}",
        "func": "static int cbor2json (OSCTXT* pCborCtxt, OSCTXT* pJsonCtxt)\n{\n   int ret = 0;\n   OSOCTET tag, ub;\n\n   /* Read byte from stream */\n   ret = rtxReadBytes (pCborCtxt, &ub, 1);\n   if (0 != ret) return LOG_RTERR (pCborCtxt, ret);\n   tag = ub >> 5;\n\n   /* Switch on tag value */\n   switch (tag) {\n   case OSRTCBOR_UINT: {\n      OSUINTTYPE value;\n      ret = rtCborDecUInt (pCborCtxt, ub, &value);\n      if (0 != ret) return LOG_RTERR (pCborCtxt, ret);\n\n      /* Encode JSON */\n#ifndef _NO_INT64_SUPPORT\n      ret = rtJsonEncUInt64Value (pJsonCtxt, value);\n#else\n      ret = rtJsonEncUIntValue (pJsonCtxt, value);\n#endif\n      if (0 != ret) return LOG_RTERR (pJsonCtxt, ret);\n      break;\n   }\n   case OSRTCBOR_NEGINT: {\n      OSINTTYPE value;\n      ret = rtCborDecInt (pCborCtxt, ub, &value);\n      if (0 != ret) return LOG_RTERR (pCborCtxt, ret);\n\n      /* Encode JSON */\n#ifndef _NO_INT64_SUPPORT\n      ret = rtJsonEncInt64Value (pJsonCtxt, value);\n#else\n      ret = rtJsonEncIntValue (pJsonCtxt, value);\n#endif\n      if (0 != ret) return LOG_RTERR (pJsonCtxt, ret);\n      break;\n   }\n   case OSRTCBOR_BYTESTR: {\n      OSDynOctStr64 byteStr;\n      ret = rtCborDecDynByteStr (pCborCtxt, ub, &byteStr);\n      if (0 != ret) return LOG_RTERR (pCborCtxt, ret);\n\n      /* Encode JSON */\n      ret = rtJsonEncHexStr (pJsonCtxt, byteStr.numocts, byteStr.data);\n      rtxMemFreePtr (pCborCtxt, byteStr.data);\n      if (0 != ret) return LOG_RTERR (pJsonCtxt, ret);\n\n      break;\n   }\n   case OSRTCBOR_UTF8STR: {\n      OSUTF8CHAR* utf8str;\n      ret = rtCborDecDynUTF8Str (pCborCtxt, ub, (char**)&utf8str);\n      if (0 != ret) return LOG_RTERR (pCborCtxt, ret);\n\n      ret = rtJsonEncStringValue (pJsonCtxt, utf8str);\n      rtxMemFreePtr (pCborCtxt, utf8str);\n      if (0 != ret) return LOG_RTERR (pJsonCtxt, ret);\n\n      break;\n   }\n   case OSRTCBOR_ARRAY: \n   case OSRTCBOR_MAP: {\n      OSOCTET len = ub & 0x1F;\n      char startChar = (tag == OSRTCBOR_ARRAY) ? '[' : '{';\n      char endChar = (tag == OSRTCBOR_ARRAY) ? ']' : '}';\n\n      OSRTSAFEPUTCHAR (pJsonCtxt, startChar);\n\n      if (len == OSRTCBOR_INDEF) {\n         OSBOOL first = TRUE;\n         for (;;) {\n            if (OSRTCBOR_MATCHEOC (pCborCtxt)) {\n               pCborCtxt->buffer.byteIndex++;\n               break;\n            }\n\n            if (!first) \n               OSRTSAFEPUTCHAR (pJsonCtxt, ',');\n            else\n               first = FALSE;\n\n            /* If map, decode object name */\n            if (tag == OSRTCBOR_MAP) {\n               ret = cborElemNameToJson (pCborCtxt, pJsonCtxt);\n            }\n\n            /* Make recursive call */\n            if (0 == ret)\n               ret = cbor2json (pCborCtxt, pJsonCtxt);\n            if (0 != ret) {\n               OSCTXT* pctxt = \n                  (rtxErrGetErrorCnt(pJsonCtxt) > 0) ? pJsonCtxt : pCborCtxt;\n               return LOG_RTERR (pctxt, ret);\n            }\n         }\n      }\n      else { /* definite length */\n         OSSIZE nitems;\n\n         /* Decode tag and number of items */\n         ret = rtCborDecSize (pCborCtxt, len, &nitems);\n         if (0 == ret) {\n            OSSIZE i;\n\n            /* Loop to decode array items */\n            for (i = 0; i < nitems; i++) {\n               if (0 != i) OSRTSAFEPUTCHAR (pJsonCtxt, ',');\n\n               /* If map, decode object name */\n               if (tag == OSRTCBOR_MAP) {\n                  ret = cborElemNameToJson (pCborCtxt, pJsonCtxt);\n               }\n\n               /* Make recursive call */\n               if (0 == ret)\n                  ret = cbor2json (pCborCtxt, pJsonCtxt);\n               if (0 != ret) {\n                  OSCTXT* pctxt = \n                  (rtxErrGetErrorCnt(pJsonCtxt) > 0) ? pJsonCtxt : pCborCtxt;\n                  return LOG_RTERR (pctxt, ret);\n               }\n            }\n         }\n      }\n      OSRTSAFEPUTCHAR (pJsonCtxt, endChar);\n      break;\n   }\n\n   case OSRTCBOR_FLOAT:\n      if (tag == OSRTCBOR_FALSEENC || tag == OSRTCBOR_TRUEENC) {\n         OSBOOL boolval = (ub == OSRTCBOR_TRUEENC) ? TRUE : FALSE;\n         ret = rtJsonEncBoolValue (pJsonCtxt, boolval);\n         if (0 != ret) return LOG_RTERR (pJsonCtxt, ret);\n      }\n      else if (tag == OSRTCBOR_FLT16ENC ||\n               tag == OSRTCBOR_FLT32ENC ||\n               tag == OSRTCBOR_FLT64ENC) {\n         OSDOUBLE fltval;\n         ret = rtCborDecFloat (pCborCtxt, ub, &fltval);\n         if (0 != ret) return LOG_RTERR (pCborCtxt, ret);\n\n         /* Encode JSON */\n         ret = rtJsonEncDoubleValue (pJsonCtxt, fltval, 0);\n         if (0 != ret) return LOG_RTERR (pJsonCtxt, ret);\n      }\n      else {\n         ret = cborTagNotSupp (pCborCtxt, tag);\n      }\n      break;\n\n   default:\n      ret = cborTagNotSupp (pCborCtxt, tag);\n   }\n\n   return ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -53,6 +53,7 @@\n    case OSRTCBOR_UTF8STR: {\n       OSUTF8CHAR* utf8str;\n       ret = rtCborDecDynUTF8Str (pCborCtxt, ub, (char**)&utf8str);\n+      if (0 != ret) return LOG_RTERR (pCborCtxt, ret);\n \n       ret = rtJsonEncStringValue (pJsonCtxt, utf8str);\n       rtxMemFreePtr (pCborCtxt, utf8str);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "      if (0 != ret) return LOG_RTERR (pCborCtxt, ret);"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-15191",
        "func_name": "tensorflow/TFE_HandleToDLPack",
        "description": "In Tensorflow before versions 2.2.1 and 2.3.1, if a user passes an invalid argument to `dlpack.to_dlpack` the expected validations will cause variables to bind to `nullptr` while setting a `status` variable to the error condition. However, this `status` argument is not properly checked. Hence, code following these methods will bind references to null pointers. This is undefined behavior and reported as an error if compiling with `-fsanitize=null`. The issue is patched in commit 22e07fb204386768e5bcbea563641ea11f96ceb8 and is released in TensorFlow versions 2.2.1, or 2.3.1.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/22e07fb204386768e5bcbea563641ea11f96ceb8",
        "commit_title": "Fix multiple vulnerabilities in `tf.experimental.dlpack.to_dlpack`.",
        "commit_text": " We have a use after free caused by memory coruption, a segmentation fault caused by memory corruption, several memory leaks and an undefined behavior when taking the reference of a nullptr.  PiperOrigin-RevId: 332568894",
        "func_before": "void* TFE_HandleToDLPack(TFE_TensorHandle* h, TF_Status* status) {\n  const Tensor* tensor = GetTensorFromHandle(h, status);\n  TF_DataType data_type = static_cast<TF_DataType>(tensor->dtype());\n  TensorReference tensor_ref(*tensor);  // This will call buf_->Ref()\n\n  auto* tf_dlm_tensor_ctx = new TfDlManagedTensorCtx(tensor_ref);\n  tf_dlm_tensor_ctx->reference = tensor_ref;\n\n  DLManagedTensor* dlm_tensor = &tf_dlm_tensor_ctx->tensor;\n  dlm_tensor->manager_ctx = tf_dlm_tensor_ctx;\n  dlm_tensor->deleter = &DLManagedTensorDeleter;\n  dlm_tensor->dl_tensor.ctx = GetDlContext(h, status);\n  int ndim = tensor->dims();\n  dlm_tensor->dl_tensor.ndim = ndim;\n  dlm_tensor->dl_tensor.data = TFE_TensorHandleDevicePointer(h, status);\n  dlm_tensor->dl_tensor.dtype = GetDlDataType(data_type, status);\n\n  std::vector<int64_t>* shape_arr = &tf_dlm_tensor_ctx->shape;\n  std::vector<int64_t>* stride_arr = &tf_dlm_tensor_ctx->strides;\n  shape_arr->resize(ndim);\n  stride_arr->resize(ndim, 1);\n  for (int i = 0; i < ndim; i++) {\n    (*shape_arr)[i] = tensor->dim_size(i);\n  }\n  for (int i = ndim - 2; i >= 0; --i) {\n    (*stride_arr)[i] = (*shape_arr)[i + 1] * (*stride_arr)[i + 1];\n  }\n\n  dlm_tensor->dl_tensor.shape = &(*shape_arr)[0];\n  // There are two ways to represent compact row-major data\n  // 1) nullptr indicates tensor is compact and row-majored.\n  // 2) fill in the strides array as the real case for compact row-major data.\n  // Here we choose option 2, since some frameworks didn't handle the strides\n  // argument properly.\n  dlm_tensor->dl_tensor.strides = &(*stride_arr)[0];\n  dlm_tensor->dl_tensor.byte_offset =\n      0;  // TF doesn't handle the strides and byte_offsets here\n  return static_cast<void*>(dlm_tensor);\n}",
        "func": "void* TFE_HandleToDLPack(TFE_TensorHandle* h, TF_Status* status) {\n  auto tf_dlm_context = GetDlContext(h, status);\n  if (!status->status.ok()) {\n    return nullptr;\n  }\n\n  auto* tf_dlm_data = TFE_TensorHandleDevicePointer(h, status);\n  if (!status->status.ok()) {\n    return nullptr;\n  }\n\n  const Tensor* tensor = GetTensorFromHandle(h, status);\n  TF_DataType data_type = static_cast<TF_DataType>(tensor->dtype());\n\n  auto tf_dlm_type = GetDlDataType(data_type, status);\n  if (!status->status.ok()) {\n    return nullptr;\n  }\n\n  TensorReference tensor_ref(*tensor);  // This will call buf_->Ref()\n  auto* tf_dlm_tensor_ctx = new TfDlManagedTensorCtx(tensor_ref);\n  tf_dlm_tensor_ctx->reference = tensor_ref;\n\n  DLManagedTensor* dlm_tensor = &tf_dlm_tensor_ctx->tensor;\n  dlm_tensor->manager_ctx = tf_dlm_tensor_ctx;\n  dlm_tensor->deleter = &DLManagedTensorDeleter;\n  dlm_tensor->dl_tensor.ctx = tf_dlm_context;\n  int ndim = tensor->dims();\n  dlm_tensor->dl_tensor.ndim = ndim;\n  dlm_tensor->dl_tensor.data = tf_dlm_data;\n  dlm_tensor->dl_tensor.dtype = tf_dlm_type;\n\n  std::vector<int64_t>* shape_arr = &tf_dlm_tensor_ctx->shape;\n  std::vector<int64_t>* stride_arr = &tf_dlm_tensor_ctx->strides;\n  shape_arr->resize(ndim);\n  stride_arr->resize(ndim, 1);\n  for (int i = 0; i < ndim; i++) {\n    (*shape_arr)[i] = tensor->dim_size(i);\n  }\n  for (int i = ndim - 2; i >= 0; --i) {\n    (*stride_arr)[i] = (*shape_arr)[i + 1] * (*stride_arr)[i + 1];\n  }\n\n  dlm_tensor->dl_tensor.shape = shape_arr->data();\n  // There are two ways to represent compact row-major data\n  // 1) nullptr indicates tensor is compact and row-majored.\n  // 2) fill in the strides array as the real case for compact row-major data.\n  // Here we choose option 2, since some frameworks didn't handle the strides\n  // argument properly.\n  dlm_tensor->dl_tensor.strides = stride_arr->data();\n\n  dlm_tensor->dl_tensor.byte_offset =\n      0;  // TF doesn't handle the strides and byte_offsets here\n  return static_cast<void*>(dlm_tensor);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,19 +1,34 @@\n void* TFE_HandleToDLPack(TFE_TensorHandle* h, TF_Status* status) {\n+  auto tf_dlm_context = GetDlContext(h, status);\n+  if (!status->status.ok()) {\n+    return nullptr;\n+  }\n+\n+  auto* tf_dlm_data = TFE_TensorHandleDevicePointer(h, status);\n+  if (!status->status.ok()) {\n+    return nullptr;\n+  }\n+\n   const Tensor* tensor = GetTensorFromHandle(h, status);\n   TF_DataType data_type = static_cast<TF_DataType>(tensor->dtype());\n+\n+  auto tf_dlm_type = GetDlDataType(data_type, status);\n+  if (!status->status.ok()) {\n+    return nullptr;\n+  }\n+\n   TensorReference tensor_ref(*tensor);  // This will call buf_->Ref()\n-\n   auto* tf_dlm_tensor_ctx = new TfDlManagedTensorCtx(tensor_ref);\n   tf_dlm_tensor_ctx->reference = tensor_ref;\n \n   DLManagedTensor* dlm_tensor = &tf_dlm_tensor_ctx->tensor;\n   dlm_tensor->manager_ctx = tf_dlm_tensor_ctx;\n   dlm_tensor->deleter = &DLManagedTensorDeleter;\n-  dlm_tensor->dl_tensor.ctx = GetDlContext(h, status);\n+  dlm_tensor->dl_tensor.ctx = tf_dlm_context;\n   int ndim = tensor->dims();\n   dlm_tensor->dl_tensor.ndim = ndim;\n-  dlm_tensor->dl_tensor.data = TFE_TensorHandleDevicePointer(h, status);\n-  dlm_tensor->dl_tensor.dtype = GetDlDataType(data_type, status);\n+  dlm_tensor->dl_tensor.data = tf_dlm_data;\n+  dlm_tensor->dl_tensor.dtype = tf_dlm_type;\n \n   std::vector<int64_t>* shape_arr = &tf_dlm_tensor_ctx->shape;\n   std::vector<int64_t>* stride_arr = &tf_dlm_tensor_ctx->strides;\n@@ -26,13 +41,14 @@\n     (*stride_arr)[i] = (*shape_arr)[i + 1] * (*stride_arr)[i + 1];\n   }\n \n-  dlm_tensor->dl_tensor.shape = &(*shape_arr)[0];\n+  dlm_tensor->dl_tensor.shape = shape_arr->data();\n   // There are two ways to represent compact row-major data\n   // 1) nullptr indicates tensor is compact and row-majored.\n   // 2) fill in the strides array as the real case for compact row-major data.\n   // Here we choose option 2, since some frameworks didn't handle the strides\n   // argument properly.\n-  dlm_tensor->dl_tensor.strides = &(*stride_arr)[0];\n+  dlm_tensor->dl_tensor.strides = stride_arr->data();\n+\n   dlm_tensor->dl_tensor.byte_offset =\n       0;  // TF doesn't handle the strides and byte_offsets here\n   return static_cast<void*>(dlm_tensor);",
        "diff_line_info": {
            "deleted_lines": [
                "",
                "  dlm_tensor->dl_tensor.ctx = GetDlContext(h, status);",
                "  dlm_tensor->dl_tensor.data = TFE_TensorHandleDevicePointer(h, status);",
                "  dlm_tensor->dl_tensor.dtype = GetDlDataType(data_type, status);",
                "  dlm_tensor->dl_tensor.shape = &(*shape_arr)[0];",
                "  dlm_tensor->dl_tensor.strides = &(*stride_arr)[0];"
            ],
            "added_lines": [
                "  auto tf_dlm_context = GetDlContext(h, status);",
                "  if (!status->status.ok()) {",
                "    return nullptr;",
                "  }",
                "",
                "  auto* tf_dlm_data = TFE_TensorHandleDevicePointer(h, status);",
                "  if (!status->status.ok()) {",
                "    return nullptr;",
                "  }",
                "",
                "",
                "  auto tf_dlm_type = GetDlDataType(data_type, status);",
                "  if (!status->status.ok()) {",
                "    return nullptr;",
                "  }",
                "",
                "  dlm_tensor->dl_tensor.ctx = tf_dlm_context;",
                "  dlm_tensor->dl_tensor.data = tf_dlm_data;",
                "  dlm_tensor->dl_tensor.dtype = tf_dlm_type;",
                "  dlm_tensor->dl_tensor.shape = shape_arr->data();",
                "  dlm_tensor->dl_tensor.strides = stride_arr->data();",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2020-29371",
        "func_name": "torvalds/linux/romfs_dev_read",
        "description": "An issue was discovered in romfs_dev_read in fs/romfs/storage.c in the Linux kernel before 5.8.4. Uninitialized memory leaks to userspace, aka CID-bcf85fcedfdd.",
        "git_url": "https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?h=2935e0a3cec1ffa558eea90db6279cff83aa3592",
        "commit_title": "commit bcf85fcedfdd17911982a3e3564fcfec7b01eebd upstream.",
        "commit_text": " romfs has a superblock field that limits the size of the filesystem; data beyond that limit is never accessed.  romfs_dev_read() fetches a caller-supplied number of bytes from the backing device.  It returns 0 on success or an error code on failure; therefore, its API can't represent short reads, it's all-or-nothing.  However, when romfs_dev_read() detects that the requested operation would cross the filesystem size limit, it currently silently truncates the requested number of bytes.  This e.g.  means that when the content of a file with size 0x1000 starts one byte before the filesystem size limit, ->readpage() will only fill a single byte of the supplied page while leaving the rest uninitialized, leaking that uninitialized memory to userspace.  Fix it by returning an error code instead of truncating the read when the requested read operation would go beyond the end of the filesystem.  Cc: David Howells <dhowells@redhat.com> Cc: <stable@vger.kernel.org> Link: http://lkml.kernel.org/r/20200818013202.2246365-1-jannh@google.com  ",
        "func_before": "int romfs_dev_read(struct super_block *sb, unsigned long pos,\n\t\t   void *buf, size_t buflen)\n{\n\tsize_t limit;\n\n\tlimit = romfs_maxsize(sb);\n\tif (pos >= limit)\n\t\treturn -EIO;\n\tif (buflen > limit - pos)\n\t\tbuflen = limit - pos;\n\n#ifdef CONFIG_ROMFS_ON_MTD\n\tif (sb->s_mtd)\n\t\treturn romfs_mtd_read(sb, pos, buf, buflen);\n#endif\n#ifdef CONFIG_ROMFS_ON_BLOCK\n\tif (sb->s_bdev)\n\t\treturn romfs_blk_read(sb, pos, buf, buflen);\n#endif\n\treturn -EIO;\n}",
        "func": "int romfs_dev_read(struct super_block *sb, unsigned long pos,\n\t\t   void *buf, size_t buflen)\n{\n\tsize_t limit;\n\n\tlimit = romfs_maxsize(sb);\n\tif (pos >= limit || buflen > limit - pos)\n\t\treturn -EIO;\n\n#ifdef CONFIG_ROMFS_ON_MTD\n\tif (sb->s_mtd)\n\t\treturn romfs_mtd_read(sb, pos, buf, buflen);\n#endif\n#ifdef CONFIG_ROMFS_ON_BLOCK\n\tif (sb->s_bdev)\n\t\treturn romfs_blk_read(sb, pos, buf, buflen);\n#endif\n\treturn -EIO;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,10 +4,8 @@\n \tsize_t limit;\n \n \tlimit = romfs_maxsize(sb);\n-\tif (pos >= limit)\n+\tif (pos >= limit || buflen > limit - pos)\n \t\treturn -EIO;\n-\tif (buflen > limit - pos)\n-\t\tbuflen = limit - pos;\n \n #ifdef CONFIG_ROMFS_ON_MTD\n \tif (sb->s_mtd)",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (pos >= limit)",
                "\tif (buflen > limit - pos)",
                "\t\tbuflen = limit - pos;"
            ],
            "added_lines": [
                "\tif (pos >= limit || buflen > limit - pos)"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-26271",
        "func_name": "tensorflow/GraphConstructor::MakeEdge",
        "description": "In affected versions of TensorFlow under certain cases, loading a saved model can result in accessing uninitialized memory while building the computation graph. The MakeEdge function creates an edge between one output tensor of the src node (given by output_index) and the input slot of the dst node (given by input_index). This is only possible if the types of the tensors on both sides coincide, so the function begins by obtaining the corresponding DataType values and comparing these for equality. However, there is no check that the indices point to inside of the arrays they index into. Thus, this can result in accessing data out of bounds of the corresponding heap allocated arrays. In most scenarios, this can manifest as unitialized data access, but if the index points far away from the boundaries of the arrays this can be used to leak addresses from the library. This is fixed in versions 1.15.5, 2.0.4, 2.1.3, 2.2.2, 2.3.2, and 2.4.0.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/0cc38aaa4064fd9e79101994ce9872c6d91f816b",
        "commit_title": "Prevent unitialized memory access in `GraphConstructor::MakeEdge`",
        "commit_text": " The `MakeEdge` implementation assumes that there exists an output at `output_index` of `src` node and an input at `input_index` of `dst` node. However, if this is not the case this results in accessing data out of bounds. Because we are accessing an array that is a private member of a class and only in read only mode, this usually results only in unitialized memory access. However, it is reasonable to think that malicious users could manipulate these indexes to actually read data outside the class, thus resulting in information leakage and further exploits.  PiperOrigin-RevId: 346343288",
        "func_before": "Status GraphConstructor::MakeEdge(Node* src, int output_index, Node* dst,\n                                  int input_index) {\n  DataType src_out = src->output_type(output_index);\n  DataType dst_in = dst->input_type(input_index);\n  if (!TypesCompatible(dst_in, src_out)) {\n    return errors::InvalidArgument(\n        \"Input \", input_index, \" of node \", dst->name(), \" was passed \",\n        DataTypeString(src_out), \" from \", src->name(), \":\", output_index,\n        \" incompatible with expected \", DataTypeString(dst_in), \".\");\n  }\n  g_->AddEdge(src, output_index, dst, input_index);\n  return Status::OK();\n}",
        "func": "Status GraphConstructor::MakeEdge(Node* src, int output_index, Node* dst,\n                                  int input_index) {\n  if (output_index >= src->num_outputs()) {\n    return errors::InvalidArgument(\n        \"Output \", output_index, \" of node \", src->name(),\n        \" does not exist. Node only has \", src->num_outputs(), \" outputs.\");\n  }\n  if (input_index >= dst->num_inputs()) {\n    return errors::InvalidArgument(\n        \"Input \", input_index, \" of node \", dst->name(),\n        \" does not exist. Node only has \", dst->num_inputs(), \" inputs.\");\n  }\n\n  DataType src_out = src->output_type(output_index);\n  DataType dst_in = dst->input_type(input_index);\n  if (!TypesCompatible(dst_in, src_out)) {\n    return errors::InvalidArgument(\n        \"Input \", input_index, \" of node \", dst->name(), \" was passed \",\n        DataTypeString(src_out), \" from \", src->name(), \":\", output_index,\n        \" incompatible with expected \", DataTypeString(dst_in), \".\");\n  }\n  g_->AddEdge(src, output_index, dst, input_index);\n  return Status::OK();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,16 @@\n Status GraphConstructor::MakeEdge(Node* src, int output_index, Node* dst,\n                                   int input_index) {\n+  if (output_index >= src->num_outputs()) {\n+    return errors::InvalidArgument(\n+        \"Output \", output_index, \" of node \", src->name(),\n+        \" does not exist. Node only has \", src->num_outputs(), \" outputs.\");\n+  }\n+  if (input_index >= dst->num_inputs()) {\n+    return errors::InvalidArgument(\n+        \"Input \", input_index, \" of node \", dst->name(),\n+        \" does not exist. Node only has \", dst->num_inputs(), \" inputs.\");\n+  }\n+\n   DataType src_out = src->output_type(output_index);\n   DataType dst_in = dst->input_type(input_index);\n   if (!TypesCompatible(dst_in, src_out)) {",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "  if (output_index >= src->num_outputs()) {",
                "    return errors::InvalidArgument(",
                "        \"Output \", output_index, \" of node \", src->name(),",
                "        \" does not exist. Node only has \", src->num_outputs(), \" outputs.\");",
                "  }",
                "  if (input_index >= dst->num_inputs()) {",
                "    return errors::InvalidArgument(",
                "        \"Input \", input_index, \" of node \", dst->name(),",
                "        \" does not exist. Node only has \", dst->num_inputs(), \" inputs.\");",
                "  }",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2020-26266",
        "func_name": "tensorflow/QUInt16",
        "description": "In affected versions of TensorFlow under certain cases a saved model can trigger use of uninitialized values during code execution. This is caused by having tensor buffers be filled with the default value of the type but forgetting to default initialize the quantized floating point types in Eigen. This is fixed in versions 1.15.5, 2.0.4, 2.1.3, 2.2.2, 2.3.2, and 2.4.0.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/ace0c15a22f7f054abcc1f53eabbcb0a1239a9e2",
        "commit_title": "Default initialize fixed point Eigen types.",
        "commit_text": " In certain cases, tensors are filled with default values of the type. But, for these fixed point types, these values were uninitialized. Thus, we would have uninitialized memory access bugs, some of which were caught by MSAN.  PiperOrigin-RevId: 344101137",
        "func_before": "QUInt16() {}",
        "func": "QUInt16() : value(0) {}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1 +1 @@\n-QUInt16() {}\n+QUInt16() : value(0) {}",
        "diff_line_info": {
            "deleted_lines": [
                "QUInt16() {}"
            ],
            "added_lines": [
                "QUInt16() : value(0) {}"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-26266",
        "func_name": "tensorflow/QUInt8",
        "description": "In affected versions of TensorFlow under certain cases a saved model can trigger use of uninitialized values during code execution. This is caused by having tensor buffers be filled with the default value of the type but forgetting to default initialize the quantized floating point types in Eigen. This is fixed in versions 1.15.5, 2.0.4, 2.1.3, 2.2.2, 2.3.2, and 2.4.0.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/ace0c15a22f7f054abcc1f53eabbcb0a1239a9e2",
        "commit_title": "Default initialize fixed point Eigen types.",
        "commit_text": " In certain cases, tensors are filled with default values of the type. But, for these fixed point types, these values were uninitialized. Thus, we would have uninitialized memory access bugs, some of which were caught by MSAN.  PiperOrigin-RevId: 344101137",
        "func_before": "QUInt8() {}",
        "func": "QUInt8() : value(0) {}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1 +1 @@\n-QUInt8() {}\n+QUInt8() : value(0) {}",
        "diff_line_info": {
            "deleted_lines": [
                "QUInt8() {}"
            ],
            "added_lines": [
                "QUInt8() : value(0) {}"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-26266",
        "func_name": "tensorflow/QInt32",
        "description": "In affected versions of TensorFlow under certain cases a saved model can trigger use of uninitialized values during code execution. This is caused by having tensor buffers be filled with the default value of the type but forgetting to default initialize the quantized floating point types in Eigen. This is fixed in versions 1.15.5, 2.0.4, 2.1.3, 2.2.2, 2.3.2, and 2.4.0.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/ace0c15a22f7f054abcc1f53eabbcb0a1239a9e2",
        "commit_title": "Default initialize fixed point Eigen types.",
        "commit_text": " In certain cases, tensors are filled with default values of the type. But, for these fixed point types, these values were uninitialized. Thus, we would have uninitialized memory access bugs, some of which were caught by MSAN.  PiperOrigin-RevId: 344101137",
        "func_before": "QInt32() {}",
        "func": "QInt32() : value(0) {}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1 +1 @@\n-QInt32() {}\n+QInt32() : value(0) {}",
        "diff_line_info": {
            "deleted_lines": [
                "QInt32() {}"
            ],
            "added_lines": [
                "QInt32() : value(0) {}"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-26266",
        "func_name": "tensorflow/QInt8",
        "description": "In affected versions of TensorFlow under certain cases a saved model can trigger use of uninitialized values during code execution. This is caused by having tensor buffers be filled with the default value of the type but forgetting to default initialize the quantized floating point types in Eigen. This is fixed in versions 1.15.5, 2.0.4, 2.1.3, 2.2.2, 2.3.2, and 2.4.0.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/ace0c15a22f7f054abcc1f53eabbcb0a1239a9e2",
        "commit_title": "Default initialize fixed point Eigen types.",
        "commit_text": " In certain cases, tensors are filled with default values of the type. But, for these fixed point types, these values were uninitialized. Thus, we would have uninitialized memory access bugs, some of which were caught by MSAN.  PiperOrigin-RevId: 344101137",
        "func_before": "QInt8() {}",
        "func": "QInt8() : value(0) {}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1 +1 @@\n-QInt8() {}\n+QInt8() : value(0) {}",
        "diff_line_info": {
            "deleted_lines": [
                "QInt8() {}"
            ],
            "added_lines": [
                "QInt8() : value(0) {}"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-26266",
        "func_name": "tensorflow/QInt16",
        "description": "In affected versions of TensorFlow under certain cases a saved model can trigger use of uninitialized values during code execution. This is caused by having tensor buffers be filled with the default value of the type but forgetting to default initialize the quantized floating point types in Eigen. This is fixed in versions 1.15.5, 2.0.4, 2.1.3, 2.2.2, 2.3.2, and 2.4.0.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/ace0c15a22f7f054abcc1f53eabbcb0a1239a9e2",
        "commit_title": "Default initialize fixed point Eigen types.",
        "commit_text": " In certain cases, tensors are filled with default values of the type. But, for these fixed point types, these values were uninitialized. Thus, we would have uninitialized memory access bugs, some of which were caught by MSAN.  PiperOrigin-RevId: 344101137",
        "func_before": "QInt16() {}",
        "func": "QInt16() : value(0) {}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1 +1 @@\n-QInt16() {}\n+QInt16() : value(0) {}",
        "diff_line_info": {
            "deleted_lines": [
                "QInt16() {}"
            ],
            "added_lines": [
                "QInt16() : value(0) {}"
            ]
        }
    },
    {
        "cve_id": "CVE-2023-21276",
        "func_name": "android/CursorWindow::writeToParcel",
        "description": "In writeToParcel of CursorWindow.cpp, there is a possible information disclosure due to uninitialized data. This could lead to local information disclosure with no additional execution privileges needed. User interaction is not needed for exploitation.\n\n",
        "git_url": "https://android.googlesource.com/platform/frameworks/base/+/1272eec833fb49c30a4d8bdc432765e7c4413b3f",
        "commit_title": "Remove unnecessary padding code",
        "commit_text": " Bug: 213170822  Remove the code that CursorWindow::writeToParcel() uses to ensure slot data is 4-byte aligned.  Because mAllocOffset and mSlotsOffset are already 4-byte aligned, the alignment step here is unnecessary.  CursorWindow::spaceInUse() returns the total space used.  The tests verify that the total space used is always a multiple of 4 bytes.  Test: atest  * libandroidfw_tests (cherry picked from https://googleplex-android-review.googlesource.com/q/commit:5d4afa0986cbc440f458b4b8db05fd176ef3e6d2) (cherry picked from https://googleplex-android-review.googlesource.com/q/commit:5b0232d7e1c2087839d9bc029943c8780b2484ab) Merged-In: I720699093d5c5a584283e5b76851938f449ffa21 ",
        "func_before": "status_t CursorWindow::writeToParcel(Parcel* parcel) {\n    LOG(DEBUG) << \"Writing to parcel: \" << this->toString();\n\n    if (parcel->writeString8(mName)) goto fail;\n    if (parcel->writeUint32(mNumRows)) goto fail;\n    if (parcel->writeUint32(mNumColumns)) goto fail;\n    if (mAshmemFd != -1) {\n        if (parcel->writeUint32(mSize)) goto fail;\n        if (parcel->writeBool(true)) goto fail;\n        if (parcel->writeDupFileDescriptor(mAshmemFd)) goto fail;\n    } else {\n        // Since we know we're going to be read-only on the remote side,\n        // we can compact ourselves on the wire, with just enough padding\n        // to ensure our slots stay aligned\n        size_t slotsSize = mSize - mSlotsOffset;\n        size_t compactedSize = mAllocOffset + slotsSize;\n        compactedSize = (compactedSize + 3) & ~3;\n        if (parcel->writeUint32(compactedSize)) goto fail;\n        if (parcel->writeBool(false)) goto fail;\n        void* dest = parcel->writeInplace(compactedSize);\n        if (!dest) goto fail;\n        memcpy(static_cast<uint8_t*>(dest),\n                static_cast<uint8_t*>(mData), mAllocOffset);\n        memcpy(static_cast<uint8_t*>(dest) + compactedSize - slotsSize,\n                static_cast<uint8_t*>(mData) + mSlotsOffset, slotsSize);\n    }\n    return OK;\n\nfail:\n    LOG(ERROR) << \"Failed writeToParcel\";\nfail_silent:\n    return UNKNOWN_ERROR;\n}",
        "func": "status_t CursorWindow::writeToParcel(Parcel* parcel) {\n    LOG(DEBUG) << \"Writing to parcel: \" << this->toString();\n\n    if (parcel->writeString8(mName)) goto fail;\n    if (parcel->writeUint32(mNumRows)) goto fail;\n    if (parcel->writeUint32(mNumColumns)) goto fail;\n    if (mAshmemFd != -1) {\n        if (parcel->writeUint32(mSize)) goto fail;\n        if (parcel->writeBool(true)) goto fail;\n        if (parcel->writeDupFileDescriptor(mAshmemFd)) goto fail;\n    } else {\n        // Since we know we're going to be read-only on the remote side,\n        // we can compact ourselves on the wire.\n        size_t slotsSize = sizeOfSlots();\n        size_t compactedSize = sizeInUse();\n        if (parcel->writeUint32(compactedSize)) goto fail;\n        if (parcel->writeBool(false)) goto fail;\n        void* dest = parcel->writeInplace(compactedSize);\n        if (!dest) goto fail;\n        memcpy(static_cast<uint8_t*>(dest),\n                static_cast<uint8_t*>(mData), mAllocOffset);\n        memcpy(static_cast<uint8_t*>(dest) + compactedSize - slotsSize,\n                static_cast<uint8_t*>(mData) + mSlotsOffset, slotsSize);\n    }\n    return OK;\n\nfail:\n    LOG(ERROR) << \"Failed writeToParcel\";\nfail_silent:\n    return UNKNOWN_ERROR;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -10,11 +10,9 @@\n         if (parcel->writeDupFileDescriptor(mAshmemFd)) goto fail;\n     } else {\n         // Since we know we're going to be read-only on the remote side,\n-        // we can compact ourselves on the wire, with just enough padding\n-        // to ensure our slots stay aligned\n-        size_t slotsSize = mSize - mSlotsOffset;\n-        size_t compactedSize = mAllocOffset + slotsSize;\n-        compactedSize = (compactedSize + 3) & ~3;\n+        // we can compact ourselves on the wire.\n+        size_t slotsSize = sizeOfSlots();\n+        size_t compactedSize = sizeInUse();\n         if (parcel->writeUint32(compactedSize)) goto fail;\n         if (parcel->writeBool(false)) goto fail;\n         void* dest = parcel->writeInplace(compactedSize);",
        "diff_line_info": {
            "deleted_lines": [
                "        // we can compact ourselves on the wire, with just enough padding",
                "        // to ensure our slots stay aligned",
                "        size_t slotsSize = mSize - mSlotsOffset;",
                "        size_t compactedSize = mAllocOffset + slotsSize;",
                "        compactedSize = (compactedSize + 3) & ~3;"
            ],
            "added_lines": [
                "        // we can compact ourselves on the wire.",
                "        size_t slotsSize = sizeOfSlots();",
                "        size_t compactedSize = sizeInUse();"
            ]
        }
    },
    {
        "cve_id": "CVE-2023-21276",
        "func_name": "android/CursorWindow::maybeInflate",
        "description": "In writeToParcel of CursorWindow.cpp, there is a possible information disclosure due to uninitialized data. This could lead to local information disclosure with no additional execution privileges needed. User interaction is not needed for exploitation.\n\n",
        "git_url": "https://android.googlesource.com/platform/frameworks/base/+/1272eec833fb49c30a4d8bdc432765e7c4413b3f",
        "commit_title": "Remove unnecessary padding code",
        "commit_text": " Bug: 213170822  Remove the code that CursorWindow::writeToParcel() uses to ensure slot data is 4-byte aligned.  Because mAllocOffset and mSlotsOffset are already 4-byte aligned, the alignment step here is unnecessary.  CursorWindow::spaceInUse() returns the total space used.  The tests verify that the total space used is always a multiple of 4 bytes.  Test: atest  * libandroidfw_tests (cherry picked from https://googleplex-android-review.googlesource.com/q/commit:5d4afa0986cbc440f458b4b8db05fd176ef3e6d2) (cherry picked from https://googleplex-android-review.googlesource.com/q/commit:5b0232d7e1c2087839d9bc029943c8780b2484ab) Merged-In: I720699093d5c5a584283e5b76851938f449ffa21 ",
        "func_before": "status_t CursorWindow::maybeInflate() {\n    int ashmemFd = 0;\n    void* newData = nullptr;\n\n    // Bail early when we can't expand any further\n    if (mReadOnly || mSize == mInflatedSize) {\n        return INVALID_OPERATION;\n    }\n\n    String8 ashmemName(\"CursorWindow: \");\n    ashmemName.append(mName);\n\n    ashmemFd = ashmem_create_region(ashmemName.string(), mInflatedSize);\n    if (ashmemFd < 0) {\n        PLOG(ERROR) << \"Failed ashmem_create_region\";\n        goto fail_silent;\n    }\n\n    if (ashmem_set_prot_region(ashmemFd, PROT_READ | PROT_WRITE) < 0) {\n        PLOG(ERROR) << \"Failed ashmem_set_prot_region\";\n        goto fail_silent;\n    }\n\n    newData = ::mmap(nullptr, mInflatedSize, PROT_READ | PROT_WRITE, MAP_SHARED, ashmemFd, 0);\n    if (newData == MAP_FAILED) {\n        PLOG(ERROR) << \"Failed mmap\";\n        goto fail_silent;\n    }\n\n    if (ashmem_set_prot_region(ashmemFd, PROT_READ) < 0) {\n        PLOG(ERROR) << \"Failed ashmem_set_prot_region\";\n        goto fail_silent;\n    }\n\n    {\n        // Migrate existing contents into new ashmem region\n        uint32_t slotsSize = mSize - mSlotsOffset;\n        uint32_t newSlotsOffset = mInflatedSize - slotsSize;\n        memcpy(static_cast<uint8_t*>(newData),\n                static_cast<uint8_t*>(mData), mAllocOffset);\n        memcpy(static_cast<uint8_t*>(newData) + newSlotsOffset,\n                static_cast<uint8_t*>(mData) + mSlotsOffset, slotsSize);\n\n        free(mData);\n        mAshmemFd = ashmemFd;\n        mData = newData;\n        mSize = mInflatedSize;\n        mSlotsOffset = newSlotsOffset;\n\n        updateSlotsData();\n    }\n\n    LOG(DEBUG) << \"Inflated: \" << this->toString();\n    return OK;\n\nfail:\n    LOG(ERROR) << \"Failed maybeInflate\";\nfail_silent:\n    ::munmap(newData, mInflatedSize);\n    ::close(ashmemFd);\n    return UNKNOWN_ERROR;\n}",
        "func": "status_t CursorWindow::maybeInflate() {\n    int ashmemFd = 0;\n    void* newData = nullptr;\n\n    // Bail early when we can't expand any further\n    if (mReadOnly || mSize == mInflatedSize) {\n        return INVALID_OPERATION;\n    }\n\n    String8 ashmemName(\"CursorWindow: \");\n    ashmemName.append(mName);\n\n    ashmemFd = ashmem_create_region(ashmemName.string(), mInflatedSize);\n    if (ashmemFd < 0) {\n        PLOG(ERROR) << \"Failed ashmem_create_region\";\n        goto fail_silent;\n    }\n\n    if (ashmem_set_prot_region(ashmemFd, PROT_READ | PROT_WRITE) < 0) {\n        PLOG(ERROR) << \"Failed ashmem_set_prot_region\";\n        goto fail_silent;\n    }\n\n    newData = ::mmap(nullptr, mInflatedSize, PROT_READ | PROT_WRITE, MAP_SHARED, ashmemFd, 0);\n    if (newData == MAP_FAILED) {\n        PLOG(ERROR) << \"Failed mmap\";\n        goto fail_silent;\n    }\n\n    if (ashmem_set_prot_region(ashmemFd, PROT_READ) < 0) {\n        PLOG(ERROR) << \"Failed ashmem_set_prot_region\";\n        goto fail_silent;\n    }\n\n    {\n        // Migrate existing contents into new ashmem region\n        uint32_t slotsSize = sizeOfSlots();\n        uint32_t newSlotsOffset = mInflatedSize - slotsSize;\n        memcpy(static_cast<uint8_t*>(newData),\n                static_cast<uint8_t*>(mData), mAllocOffset);\n        memcpy(static_cast<uint8_t*>(newData) + newSlotsOffset,\n                static_cast<uint8_t*>(mData) + mSlotsOffset, slotsSize);\n\n        free(mData);\n        mAshmemFd = ashmemFd;\n        mData = newData;\n        mSize = mInflatedSize;\n        mSlotsOffset = newSlotsOffset;\n\n        updateSlotsData();\n    }\n\n    LOG(DEBUG) << \"Inflated: \" << this->toString();\n    return OK;\n\nfail:\n    LOG(ERROR) << \"Failed maybeInflate\";\nfail_silent:\n    ::munmap(newData, mInflatedSize);\n    ::close(ashmemFd);\n    return UNKNOWN_ERROR;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -34,7 +34,7 @@\n \n     {\n         // Migrate existing contents into new ashmem region\n-        uint32_t slotsSize = mSize - mSlotsOffset;\n+        uint32_t slotsSize = sizeOfSlots();\n         uint32_t newSlotsOffset = mInflatedSize - slotsSize;\n         memcpy(static_cast<uint8_t*>(newData),\n                 static_cast<uint8_t*>(mData), mAllocOffset);",
        "diff_line_info": {
            "deleted_lines": [
                "        uint32_t slotsSize = mSize - mSlotsOffset;"
            ],
            "added_lines": [
                "        uint32_t slotsSize = sizeOfSlots();"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-11383",
        "func_name": "radareorg/radare2/cmd_anal_esil",
        "description": "The r_strbuf_fini() function in radare2 2.5.0 allows remote attackers to cause a denial of service (invalid free and application crash) via a crafted ELF file because of an uninitialized variable in the CPSE handler in libr/anal/p/anal_avr.c.",
        "git_url": "https://github.com/radareorg/radare2/commit/9d348bcc2c4bbd3805e7eec97b594be9febbdf9a",
        "commit_title": "Fix #9943 - Invalid free on RAnal.avr",
        "commit_text": "",
        "func_before": "static void cmd_anal_esil(RCore *core, const char *input) {\n\tRAnalEsil *esil = core->anal->esil;\n\tut64 addr = core->offset;\n\tut64 adr ;\n\tchar *n, *n1;\n\tint off;\n\tint stacksize = r_config_get_i (core->config, \"esil.stack.depth\");\n\tint iotrap = r_config_get_i (core->config, \"esil.iotrap\");\n\tint romem = r_config_get_i (core->config, \"esil.romem\");\n\tint stats = r_config_get_i (core->config, \"esil.stats\");\n\tint noNULL = r_config_get_i (core->config, \"esil.noNULL\");\n\tut64 until_addr = UT64_MAX;\n\tunsigned int addrsize = r_config_get_i (core->config, \"esil.addr.size\");\n\n\tconst char *until_expr = NULL;\n\tRAnalOp *op;\n\n\tswitch (input[0]) {\n\tcase 'p': // \"aep\"\n\t\tswitch (input[1]) {\n\t\tcase 'c':\n\t\t\tif (input[2] == ' ') {\n\t\t\t\t// seek to this address\n\t\t\t\tr_core_cmdf (core, \"ar PC=%s\", input + 3);\n\t\t\t\tr_core_cmd0 (core, \".ar*\");\n\t\t\t} else {\n\t\t\t\teprintf (\"Missing argument\\n\");\n\t\t\t}\n\t\t\tbreak;\n\t\tcase 0:\n\t\t\tr_anal_pin_list (core->anal);\n\t\t\tbreak;\n\t\tcase '-':\n\t\t\tif (input[2])\n\t\t\t\taddr = r_num_math (core->num, input + 2);\n\t\t\tr_anal_pin_unset (core->anal, addr);\n\t\t\tbreak;\n\t\tcase ' ':\n\t\t\tr_anal_pin (core->anal, addr, input + 2);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tr_core_cmd_help (core, help_msg_aep);\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\tcase 'r': // \"aer\"\n\t\t// 'aer' is an alias for 'ar'\n\t\tcmd_anal_reg (core, input + 1);\n\t\tbreak;\n\tcase '*':\n\t\t// XXX: this is wip, not working atm\n\t\tif (core->anal->esil) {\n\t\t\tr_cons_printf (\"trap: %d\\n\", core->anal->esil->trap);\n\t\t\tr_cons_printf (\"trap-code: %d\\n\", core->anal->esil->trap_code);\n\t\t} else {\n\t\t\teprintf (\"esil vm not initialized. run `aei`\\n\");\n\t\t}\n\t\tbreak;\n\tcase ' ':\n\t\t//r_anal_esil_eval (core->anal, input+1);\n\t\tif (!esil) {\n\t\t\tif (!(core->anal->esil = esil = r_anal_esil_new (stacksize, iotrap, addrsize)))\n\t\t\t\treturn;\n\t\t}\n\t\tr_anal_esil_setup (esil, core->anal, romem, stats, noNULL); // setup io\n\t\tr_anal_esil_set_pc (esil, core->offset);\n\t\tr_anal_esil_parse (esil, input + 1);\n\t\tr_anal_esil_dumpstack (esil);\n\t\tr_anal_esil_stack_free (esil);\n\t\tbreak;\n\tcase 's': // \"aes\"\n\t\t// \"aes\" \"aeso\" \"aesu\" \"aesue\"\n\t\t// aes -> single step\n\t\t// aesb -> single step back\n\t\t// aeso -> single step over\n\t\t// aesu -> until address\n\t\t// aesue -> until esil expression\n\t\tswitch (input[1]) {\n\t\tcase '?':\n\t\t\teprintf (\"See: ae?~aes\\n\");\n\t\t\tbreak;\n\t\tcase 'l': // \"aesl\"\n\t\t{\n\t\t\tut64 pc = r_debug_reg_get (core->dbg, \"PC\");\n\t\t\tRAnalOp *op = r_core_anal_op (core, pc);\n// TODO: honor hint\n\t\t\tif (!op) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tr_core_esil_step (core, UT64_MAX, NULL, NULL);\n\t\t\tr_debug_reg_set (core->dbg, \"PC\", pc + op->size);\n\t\t\tr_anal_esil_set_pc (esil, pc + op->size);\n\t\t\tr_core_cmd0 (core, \".ar*\");\n\t\t} break;\n\t\tcase 'b': // \"aesb\"\n\t\t\tif (!r_core_esil_step_back (core)) {\n\t\t\t\teprintf (\"cannnot step back\\n\");\n\t\t\t}\n\t\t\tr_core_cmd0 (core, \".ar*\");\n\t\t\tbreak;\n\t\tcase 'u': // \"aesu\"\n\t\t\tif (input[2] == 'e') {\n\t\t\t\tuntil_expr = input + 3;\n\t\t\t} else {\n\t\t\t\tuntil_addr = r_num_math (core->num, input + 2);\n\t\t\t}\n\t\t\tr_core_esil_step (core, until_addr, until_expr, NULL);\n\t\t\tr_core_cmd0 (core, \".ar*\");\n\t\t\tbreak;\n\t\tcase 'o': // \"aeso\"\n\t\t\t// step over\n\t\t\top = r_core_anal_op (core, r_reg_getv (core->anal->reg,\n\t\t\t\tr_reg_get_name (core->anal->reg, R_REG_NAME_PC)));\n\t\t\tif (op && op->type == R_ANAL_OP_TYPE_CALL) {\n\t\t\t\tuntil_addr = op->addr + op->size;\n\t\t\t}\n\t\t\tr_core_esil_step (core, until_addr, until_expr, NULL);\n\t\t\tr_anal_op_free (op);\n\t\t\tr_core_cmd0 (core, \".ar*\");\n\t\t\tbreak;\n\t\tcase 'p': //\"aesp\"\n\t\t\tn = strchr (input, ' ');\n\t\t\tn1 = n ? strchr (n + 1, ' ') : NULL;\n\t\t\tif ((!n || !n1) || (!(n + 1) || !(n1 + 1))) {\n\t\t\t\teprintf (\"aesp [offset] [num]\\n\");\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tadr = r_num_math (core->num, n + 1);\n\t\t\toff = r_num_math (core->num, n1 + 1);\n\t\t\tcmd_aespc (core, adr, off);\n\t\t\tbreak;\n\t\tcase ' ':\n\t\t\tn = strchr (input, ' ');\n\t\t\tif (!(n + 1)) {\n\t\t\t\tr_core_esil_step (core, until_addr, until_expr, NULL);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\toff = r_num_math (core->num, n + 1);\n\t\t\tcmd_aespc (core, -1, off);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tr_core_esil_step (core, until_addr, until_expr, NULL);\n\t\t\tr_core_cmd0 (core, \".ar*\");\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\tcase 'c': // \"aec\"\n\t\tif (input[1] == '?') { // \"aec?\"\n\t\t\tr_core_cmd_help (core, help_msg_aec);\n\t\t} else if (input[1] == 's') { // \"aecs\"\n\t\t\tconst char *pc = r_reg_get_name (core->anal->reg, R_REG_NAME_PC);\n\t\t\tut64 newaddr;\n\t\t\tint ret;\n\t\t\tfor (;;) {\n\t\t\t\top = r_core_anal_op (core, addr);\n\t\t\t\tif (!op) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tif (op->type == R_ANAL_OP_TYPE_SWI) {\n\t\t\t\t\teprintf (\"syscall at 0x%08\" PFMT64x \"\\n\", addr);\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tif (op->type == R_ANAL_OP_TYPE_TRAP) {\n\t\t\t\t\teprintf (\"trap at 0x%08\" PFMT64x \"\\n\", addr);\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tret = r_core_esil_step (core, UT64_MAX, NULL, NULL);\n\t\t\t\tr_anal_op_free (op);\n\t\t\t\top = NULL;\n\t\t\t\tif (core->anal->esil->trap || core->anal->esil->trap_code) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tif (!ret)\n\t\t\t\t\tbreak;\n\t\t\t\tr_core_cmd0 (core, \".ar*\");\n\t\t\t\tnewaddr = r_num_get (core->num, pc);\n\t\t\t\tif (addr == newaddr) {\n\t\t\t\t\taddr++;\n\t\t\t\t\tbreak;\n\t\t\t\t} else {\n\t\t\t\t\taddr = newaddr;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (op) {\n\t\t\t\tr_anal_op_free (op);\n\t\t\t}\n\t\t} else {\n\t\t\t// \"aec\"  -> continue until ^C\n\t\t\t// \"aecu\" -> until address\n\t\t\t// \"aecue\" -> until esil expression\n\t\t\tif (input[1] == 'u' && input[2] == 'e')\n\t\t\t\tuntil_expr = input + 3;\n\t\t\telse if (input[1] == 'u')\n\t\t\t\tuntil_addr = r_num_math (core->num, input + 2);\n\t\t\telse until_expr = \"0\";\n\t\t\tr_core_esil_step (core, until_addr, until_expr, NULL);\n\t\t\tr_core_cmd0 (core, \".ar*\");\n\t\t}\n\t\tbreak;\n\tcase 'i': // \"aei\"\n\t\tswitch (input[1]) {\n\t\tcase 's':\n\t\tcase 'm': // \"aeim\"\n\t\t\tcmd_esil_mem (core, input + 2);\n\t\t\tbreak;\n\t\tcase 'p': // initialize pc = $$\n\t\t\tr_core_cmd0 (core, \"ar PC=$$\");\n\t\t\tbreak;\n\t\tcase '?':\n\t\t\tcmd_esil_mem (core, \"?\");\n\t\t\tbreak;\n\t\tcase '-':\n\t\t\tif (esil) {\n\t\t\t\tsdb_reset (esil->stats);\n\t\t\t}\n\t\t\tr_anal_esil_free (esil);\n\t\t\tcore->anal->esil = NULL;\n\t\t\tbreak;\n\t\tcase 0:\t\t\t\t//lolololol\n\t\t\tr_anal_esil_free (esil);\n\t\t\t// reinitialize\n\t\t\t{\n\t\t\t\tconst char *pc = r_reg_get_name (core->anal->reg, R_REG_NAME_PC);\n\t\t\t\tif (r_reg_getv (core->anal->reg, pc) == 0LL) {\n\t\t\t\t\tr_core_cmd0 (core, \"ar PC=$$\");\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (!(esil = core->anal->esil = r_anal_esil_new (stacksize, iotrap, addrsize))) {\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tr_anal_esil_setup (esil, core->anal, romem, stats, noNULL); // setup io\n\t\t\tesil->verbose = (int)r_config_get_i (core->config, \"esil.verbose\");\n\t\t\t/* restore user settings for interrupt handling */\n\t\t\t{\n\t\t\t\tconst char *s = r_config_get (core->config, \"cmd.esil.intr\");\n\t\t\t\tif (s) {\n\t\t\t\t\tchar *my = strdup (s);\n\t\t\t\t\tif (my) {\n\t\t\t\t\t\tr_config_set (core->config, \"cmd.esil.intr\", my);\n\t\t\t\t\t\tfree (my);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\tcase 'k': // \"aek\"\n\t\tswitch (input[1]) {\n\t\tcase '\\0':\n\t\t\tinput = \"123*\";\n\t\t\t/* fall through */\n\t\tcase ' ':\n\t\t\tif (esil && esil->stats) {\n\t\t\t\tchar *out = sdb_querys (esil->stats, NULL, 0, input + 2);\n\t\t\t\tif (out) {\n\t\t\t\t\tr_cons_println (out);\n\t\t\t\t\tfree (out);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\teprintf (\"esil.stats is empty. Run 'aei'\\n\");\n\t\t\t}\n\t\t\tbreak;\n\t\tcase '-':\n\t\t\tif (esil) {\n\t\t\t\tsdb_reset (esil->stats);\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\tcase 'f': // \"aef\"\n\t{\n\t\tRListIter *iter;\n\t\tRAnalBlock *bb;\n\t\tRAnalFunction *fcn = r_anal_get_fcn_in (core->anal,\n\t\t\t\t\t\t\tcore->offset, R_ANAL_FCN_TYPE_FCN | R_ANAL_FCN_TYPE_SYM);\n\t\tif (fcn) {\n\t\t\t// emulate every instruction in the function recursively across all the basic blocks\n\t\t\tr_list_foreach (fcn->bbs, iter, bb) {\n\t\t\t\tut64 pc = bb->addr;\n\t\t\t\tut64 end = bb->addr + bb->size;\n\t\t\t\tRAnalOp op;\n\t\t\t\tut8 *buf;\n\t\t\t\tint ret, bbs = end - pc;\n\t\t\t\tif (bbs < 1 || bbs > 0xfffff) {\n\t\t\t\t\teprintf (\"Invalid block size\\n\");\n\t\t\t\t}\n\t\t//\t\teprintf (\"[*] Emulating 0x%08\"PFMT64x\" basic block 0x%08\" PFMT64x \" - 0x%08\" PFMT64x \"\\r[\", fcn->addr, pc, end);\n\t\t\t\tbuf = calloc (1, bbs + 1);\n\t\t\t\tr_io_read_at (core->io, pc, buf, bbs);\n\t\t\t\tint left;\n\t\t\t\twhile (pc < end) {\n\t\t\t\t\tleft = R_MIN (end - pc, 32);\n\t\t\t\t\tr_asm_set_pc (core->assembler, pc);\n\t\t\t\t\tret = r_anal_op (core->anal, &op, addr, buf, left, R_ANAL_OP_MASK_ALL); // read overflow\n\t\t\t\t\tif (ret) {\n\t\t\t\t\t\tr_reg_set_value_by_role (core->anal->reg, R_REG_NAME_PC, pc);\n\t\t\t\t\t\tr_anal_esil_parse (esil, R_STRBUF_SAFEGET (&op.esil));\n\t\t\t\t\t\tr_anal_esil_dumpstack (esil);\n\t\t\t\t\t\tr_anal_esil_stack_free (esil);\n\t\t\t\t\t\tpc += op.size;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tpc += 4; // XXX\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\teprintf (\"Cannot find function at 0x%08\" PFMT64x \"\\n\", core->offset);\n\t\t}\n\t} break;\n\tcase 't': // \"aet\"\n\t\tswitch (input[1]) {\n\t\tcase 'r': // \"aetr\"\n\t\t{\n\t\t\t// anal ESIL to REIL.\n\t\t\tRAnalEsil *esil = r_anal_esil_new (stacksize, iotrap, addrsize);\n\t\t\tif (!esil)\n\t\t\t\treturn;\n\t\t\tr_anal_esil_to_reil_setup (esil, core->anal, romem, stats);\n\t\t\tr_anal_esil_set_pc (esil, core->offset);\n\t\t\tr_anal_esil_parse (esil, input + 2);\n\t\t\tr_anal_esil_dumpstack (esil);\n\t\t\tr_anal_esil_free (esil);\n\t\t\tbreak;\n\t\t}\n\t\tcase 's': // \"aets\"\n\t\t\tswitch (input[2]) {\n\t\t\tcase 0:\n\t\t\t\tr_anal_esil_session_list (esil);\n\t\t\t\tbreak;\n\t\t\tcase '+':\n\t\t\t\tr_anal_esil_session_add (esil);\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tr_core_cmd_help (core, help_msg_aets);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tbreak;\n\t\tdefault:\n\t\t\teprintf (\"Unknown command. Use `aetr`.\\n\");\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\tcase 'A': // \"aeA\"\n\t\tif (input[1] == '?') {\n\t\t\tr_core_cmd_help (core, help_msg_aea);\n\t\t} else if (input[1] == 'r') {\n\t\t\tcmd_aea (core, 1 + (1<<1), core->offset, r_num_math (core->num, input+2));\n\t\t} else if (input[1] == 'w') {\n\t\t\tcmd_aea (core, 1 + (1<<2), core->offset, r_num_math (core->num, input+2));\n\t\t} else if (input[1] == 'n') {\n\t\t\tcmd_aea (core, 1 + (1<<3), core->offset, r_num_math (core->num, input+2));\n\t\t} else if (input[1] == 'j') {\n\t\t\tcmd_aea (core, 1 + (1<<4), core->offset, r_num_math (core->num, input+2));\n\t\t} else if (input[1] == '*') {\n\t\t\tcmd_aea (core, 1 + (1<<5), core->offset, r_num_math (core->num, input+2));\n\t\t} else if (input[1] == 'f') {\n\t\t\tRAnalFunction *fcn = r_anal_get_fcn_in (core->anal, core->offset, -1);\n\t\t\tif (fcn) {\n\t\t\t\tcmd_aea (core, 1, fcn->addr, r_anal_fcn_size (fcn));\n\t\t\t}\n\t\t} else {\n\t\t\tcmd_aea (core, 1, core->offset, (int)r_num_math (core->num, input+2));\n\t\t}\n\t\tbreak;\n\tcase 'a': // \"aea\"\n\t\tif (input[1] == '?') {\n\t\t\tr_core_cmd_help (core, help_msg_aea);\n\t\t} else if (input[1] == 'r') {\n\t\t\tcmd_aea (core, 1<<1, core->offset, r_num_math (core->num, input+2));\n\t\t} else if (input[1] == 'w') {\n\t\t\tcmd_aea (core, 1<<2, core->offset, r_num_math (core->num, input+2));\n\t\t} else if (input[1] == 'n') {\n\t\t\tcmd_aea (core, 1<<3, core->offset, r_num_math (core->num, input+2));\n\t\t} else if (input[1] == 'j') {\n\t\t\tcmd_aea (core, 1<<4, core->offset, r_num_math (core->num, input+2));\n\t\t} else if (input[1] == '*') {\n\t\t\tcmd_aea (core, 1<<5, core->offset, r_num_math (core->num, input+2));\n\t\t} else if (input[1] == 'f') {\n\t\t\tRAnalFunction *fcn = r_anal_get_fcn_in (core->anal, core->offset, -1);\n                        // \"aeafj\"\n\t\t\tif (fcn) {\n\t\t\t\tswitch (input[2]) {\n\t\t\t\tcase 'j': // \"aeafj\"\n\t\t\t\t\tcmd_aea (core, 1<<4, fcn->addr, r_anal_fcn_size (fcn));\n\t\t\t\t\tbreak;\n\t\t\t\tdefault:\n\t\t\t\t\tcmd_aea (core, 1, fcn->addr, r_anal_fcn_size (fcn));\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t}\n\t\t} else {\n\t\t\tconst char *arg = input[1]? input + 2: \"\";\n\t\t\tut64 len = r_num_math (core->num, arg);\n\t\t\tcmd_aea (core, 0, core->offset, len);\n\t\t}\n\t\tbreak;\n\tcase 'x': { // \"aex\"\n\t\tchar *hex;\n\t\tint ret, bufsz;\n\n\t\tinput = r_str_trim_ro (input + 1);\n\t\thex = strdup (input);\n\t\tif (!hex) {\n\t\t\tbreak;\n\t\t}\n\n\t\tRAnalOp aop = R_EMPTY;\n\t\tbufsz = r_hex_str2bin (hex, (ut8*)hex);\n\t\tret = r_anal_op (core->anal, &aop, core->offset,\n\t\t\t(const ut8*)hex, bufsz, R_ANAL_OP_MASK_ALL);\n\t\tif (ret>0) {\n\t\t\tconst char *str = R_STRBUF_SAFEGET (&aop.esil);\n\t\t\tchar *str2 = r_str_newf (\" %s\", str);\n\t\t\tcmd_anal_esil (core, str2);\n\t\t\tfree (str2);\n\t\t}\n\t\tr_anal_op_fini (&aop);\n\t\tbreak;\n\t}\n\tcase '?': // \"ae?\"\n\t\tif (input[1] == '?') {\n\t\t\tr_core_cmd_help (core, help_detail_ae);\n\t\t\tbreak;\n\t\t}\n\t\t/* fallthrough */\n\tdefault:\n\t\tr_core_cmd_help (core, help_msg_ae);\n\t\tbreak;\n\t}\n}",
        "func": "static void cmd_anal_esil(RCore *core, const char *input) {\n\tRAnalEsil *esil = core->anal->esil;\n\tut64 addr = core->offset;\n\tut64 adr ;\n\tchar *n, *n1;\n\tint off;\n\tint stacksize = r_config_get_i (core->config, \"esil.stack.depth\");\n\tint iotrap = r_config_get_i (core->config, \"esil.iotrap\");\n\tint romem = r_config_get_i (core->config, \"esil.romem\");\n\tint stats = r_config_get_i (core->config, \"esil.stats\");\n\tint noNULL = r_config_get_i (core->config, \"esil.noNULL\");\n\tut64 until_addr = UT64_MAX;\n\tunsigned int addrsize = r_config_get_i (core->config, \"esil.addr.size\");\n\n\tconst char *until_expr = NULL;\n\tRAnalOp *op;\n\n\tswitch (input[0]) {\n\tcase 'p': // \"aep\"\n\t\tswitch (input[1]) {\n\t\tcase 'c':\n\t\t\tif (input[2] == ' ') {\n\t\t\t\t// seek to this address\n\t\t\t\tr_core_cmdf (core, \"ar PC=%s\", input + 3);\n\t\t\t\tr_core_cmd0 (core, \".ar*\");\n\t\t\t} else {\n\t\t\t\teprintf (\"Missing argument\\n\");\n\t\t\t}\n\t\t\tbreak;\n\t\tcase 0:\n\t\t\tr_anal_pin_list (core->anal);\n\t\t\tbreak;\n\t\tcase '-':\n\t\t\tif (input[2])\n\t\t\t\taddr = r_num_math (core->num, input + 2);\n\t\t\tr_anal_pin_unset (core->anal, addr);\n\t\t\tbreak;\n\t\tcase ' ':\n\t\t\tr_anal_pin (core->anal, addr, input + 2);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tr_core_cmd_help (core, help_msg_aep);\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\tcase 'r': // \"aer\"\n\t\t// 'aer' is an alias for 'ar'\n\t\tcmd_anal_reg (core, input + 1);\n\t\tbreak;\n\tcase '*':\n\t\t// XXX: this is wip, not working atm\n\t\tif (core->anal->esil) {\n\t\t\tr_cons_printf (\"trap: %d\\n\", core->anal->esil->trap);\n\t\t\tr_cons_printf (\"trap-code: %d\\n\", core->anal->esil->trap_code);\n\t\t} else {\n\t\t\teprintf (\"esil vm not initialized. run `aei`\\n\");\n\t\t}\n\t\tbreak;\n\tcase ' ':\n\t\t//r_anal_esil_eval (core->anal, input+1);\n\t\tif (!esil) {\n\t\t\tif (!(core->anal->esil = esil = r_anal_esil_new (stacksize, iotrap, addrsize)))\n\t\t\t\treturn;\n\t\t}\n\t\tr_anal_esil_setup (esil, core->anal, romem, stats, noNULL); // setup io\n\t\tr_anal_esil_set_pc (esil, core->offset);\n\t\tr_anal_esil_parse (esil, input + 1);\n\t\tr_anal_esil_dumpstack (esil);\n\t\tr_anal_esil_stack_free (esil);\n\t\tbreak;\n\tcase 's': // \"aes\"\n\t\t// \"aes\" \"aeso\" \"aesu\" \"aesue\"\n\t\t// aes -> single step\n\t\t// aesb -> single step back\n\t\t// aeso -> single step over\n\t\t// aesu -> until address\n\t\t// aesue -> until esil expression\n\t\tswitch (input[1]) {\n\t\tcase '?':\n\t\t\teprintf (\"See: ae?~aes\\n\");\n\t\t\tbreak;\n\t\tcase 'l': // \"aesl\"\n\t\t{\n\t\t\tut64 pc = r_debug_reg_get (core->dbg, \"PC\");\n\t\t\tRAnalOp *op = r_core_anal_op (core, pc);\n// TODO: honor hint\n\t\t\tif (!op) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tr_core_esil_step (core, UT64_MAX, NULL, NULL);\n\t\t\tr_debug_reg_set (core->dbg, \"PC\", pc + op->size);\n\t\t\tr_anal_esil_set_pc (esil, pc + op->size);\n\t\t\tr_core_cmd0 (core, \".ar*\");\n\t\t} break;\n\t\tcase 'b': // \"aesb\"\n\t\t\tif (!r_core_esil_step_back (core)) {\n\t\t\t\teprintf (\"cannnot step back\\n\");\n\t\t\t}\n\t\t\tr_core_cmd0 (core, \".ar*\");\n\t\t\tbreak;\n\t\tcase 'u': // \"aesu\"\n\t\t\tif (input[2] == 'e') {\n\t\t\t\tuntil_expr = input + 3;\n\t\t\t} else {\n\t\t\t\tuntil_addr = r_num_math (core->num, input + 2);\n\t\t\t}\n\t\t\tr_core_esil_step (core, until_addr, until_expr, NULL);\n\t\t\tr_core_cmd0 (core, \".ar*\");\n\t\t\tbreak;\n\t\tcase 'o': // \"aeso\"\n\t\t\t// step over\n\t\t\top = r_core_anal_op (core, r_reg_getv (core->anal->reg,\n\t\t\t\tr_reg_get_name (core->anal->reg, R_REG_NAME_PC)));\n\t\t\tif (op && op->type == R_ANAL_OP_TYPE_CALL) {\n\t\t\t\tuntil_addr = op->addr + op->size;\n\t\t\t}\n\t\t\tr_core_esil_step (core, until_addr, until_expr, NULL);\n\t\t\tr_anal_op_free (op);\n\t\t\tr_core_cmd0 (core, \".ar*\");\n\t\t\tbreak;\n\t\tcase 'p': //\"aesp\"\n\t\t\tn = strchr (input, ' ');\n\t\t\tn1 = n ? strchr (n + 1, ' ') : NULL;\n\t\t\tif ((!n || !n1) || (!(n + 1) || !(n1 + 1))) {\n\t\t\t\teprintf (\"aesp [offset] [num]\\n\");\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tadr = r_num_math (core->num, n + 1);\n\t\t\toff = r_num_math (core->num, n1 + 1);\n\t\t\tcmd_aespc (core, adr, off);\n\t\t\tbreak;\n\t\tcase ' ':\n\t\t\tn = strchr (input, ' ');\n\t\t\tif (!(n + 1)) {\n\t\t\t\tr_core_esil_step (core, until_addr, until_expr, NULL);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\toff = r_num_math (core->num, n + 1);\n\t\t\tcmd_aespc (core, -1, off);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tr_core_esil_step (core, until_addr, until_expr, NULL);\n\t\t\tr_core_cmd0 (core, \".ar*\");\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\tcase 'c': // \"aec\"\n\t\tif (input[1] == '?') { // \"aec?\"\n\t\t\tr_core_cmd_help (core, help_msg_aec);\n\t\t} else if (input[1] == 's') { // \"aecs\"\n\t\t\tconst char *pc = r_reg_get_name (core->anal->reg, R_REG_NAME_PC);\n\t\t\tut64 newaddr;\n\t\t\tint ret;\n\t\t\tfor (;;) {\n\t\t\t\top = r_core_anal_op (core, addr);\n\t\t\t\tif (!op) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tif (op->type == R_ANAL_OP_TYPE_SWI) {\n\t\t\t\t\teprintf (\"syscall at 0x%08\" PFMT64x \"\\n\", addr);\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tif (op->type == R_ANAL_OP_TYPE_TRAP) {\n\t\t\t\t\teprintf (\"trap at 0x%08\" PFMT64x \"\\n\", addr);\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tret = r_core_esil_step (core, UT64_MAX, NULL, NULL);\n\t\t\t\tr_anal_op_free (op);\n\t\t\t\top = NULL;\n\t\t\t\tif (core->anal->esil->trap || core->anal->esil->trap_code) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tif (!ret)\n\t\t\t\t\tbreak;\n\t\t\t\tr_core_cmd0 (core, \".ar*\");\n\t\t\t\tnewaddr = r_num_get (core->num, pc);\n\t\t\t\tif (addr == newaddr) {\n\t\t\t\t\taddr++;\n\t\t\t\t\tbreak;\n\t\t\t\t} else {\n\t\t\t\t\taddr = newaddr;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (op) {\n\t\t\t\tr_anal_op_free (op);\n\t\t\t}\n\t\t} else {\n\t\t\t// \"aec\"  -> continue until ^C\n\t\t\t// \"aecu\" -> until address\n\t\t\t// \"aecue\" -> until esil expression\n\t\t\tif (input[1] == 'u' && input[2] == 'e')\n\t\t\t\tuntil_expr = input + 3;\n\t\t\telse if (input[1] == 'u')\n\t\t\t\tuntil_addr = r_num_math (core->num, input + 2);\n\t\t\telse until_expr = \"0\";\n\t\t\tr_core_esil_step (core, until_addr, until_expr, NULL);\n\t\t\tr_core_cmd0 (core, \".ar*\");\n\t\t}\n\t\tbreak;\n\tcase 'i': // \"aei\"\n\t\tswitch (input[1]) {\n\t\tcase 's':\n\t\tcase 'm': // \"aeim\"\n\t\t\tcmd_esil_mem (core, input + 2);\n\t\t\tbreak;\n\t\tcase 'p': // initialize pc = $$\n\t\t\tr_core_cmd0 (core, \"ar PC=$$\");\n\t\t\tbreak;\n\t\tcase '?':\n\t\t\tcmd_esil_mem (core, \"?\");\n\t\t\tbreak;\n\t\tcase '-':\n\t\t\tif (esil) {\n\t\t\t\tsdb_reset (esil->stats);\n\t\t\t}\n\t\t\tr_anal_esil_free (esil);\n\t\t\tcore->anal->esil = NULL;\n\t\t\tbreak;\n\t\tcase 0:\t\t\t\t//lolololol\n\t\t\tr_anal_esil_free (esil);\n\t\t\t// reinitialize\n\t\t\t{\n\t\t\t\tconst char *pc = r_reg_get_name (core->anal->reg, R_REG_NAME_PC);\n\t\t\t\tif (r_reg_getv (core->anal->reg, pc) == 0LL) {\n\t\t\t\t\tr_core_cmd0 (core, \"ar PC=$$\");\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (!(esil = core->anal->esil = r_anal_esil_new (stacksize, iotrap, addrsize))) {\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tr_anal_esil_setup (esil, core->anal, romem, stats, noNULL); // setup io\n\t\t\tesil->verbose = (int)r_config_get_i (core->config, \"esil.verbose\");\n\t\t\t/* restore user settings for interrupt handling */\n\t\t\t{\n\t\t\t\tconst char *s = r_config_get (core->config, \"cmd.esil.intr\");\n\t\t\t\tif (s) {\n\t\t\t\t\tchar *my = strdup (s);\n\t\t\t\t\tif (my) {\n\t\t\t\t\t\tr_config_set (core->config, \"cmd.esil.intr\", my);\n\t\t\t\t\t\tfree (my);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\tcase 'k': // \"aek\"\n\t\tswitch (input[1]) {\n\t\tcase '\\0':\n\t\t\tinput = \"123*\";\n\t\t\t/* fall through */\n\t\tcase ' ':\n\t\t\tif (esil && esil->stats) {\n\t\t\t\tchar *out = sdb_querys (esil->stats, NULL, 0, input + 2);\n\t\t\t\tif (out) {\n\t\t\t\t\tr_cons_println (out);\n\t\t\t\t\tfree (out);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\teprintf (\"esil.stats is empty. Run 'aei'\\n\");\n\t\t\t}\n\t\t\tbreak;\n\t\tcase '-':\n\t\t\tif (esil) {\n\t\t\t\tsdb_reset (esil->stats);\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\tcase 'f': // \"aef\"\n\t{\n\t\tRListIter *iter;\n\t\tRAnalBlock *bb;\n\t\tRAnalFunction *fcn = r_anal_get_fcn_in (core->anal,\n\t\t\t\t\t\t\tcore->offset, R_ANAL_FCN_TYPE_FCN | R_ANAL_FCN_TYPE_SYM);\n\t\tif (fcn) {\n\t\t\t// emulate every instruction in the function recursively across all the basic blocks\n\t\t\tr_list_foreach (fcn->bbs, iter, bb) {\n\t\t\t\tut64 pc = bb->addr;\n\t\t\t\tut64 end = bb->addr + bb->size;\n\t\t\t\tRAnalOp op;\n\t\t\t\tut8 *buf;\n\t\t\t\tint ret, bbs = end - pc;\n\t\t\t\tif (bbs < 1 || bbs > 0xfffff) {\n\t\t\t\t\teprintf (\"Invalid block size\\n\");\n\t\t\t\t}\n\t\t//\t\teprintf (\"[*] Emulating 0x%08\"PFMT64x\" basic block 0x%08\" PFMT64x \" - 0x%08\" PFMT64x \"\\r[\", fcn->addr, pc, end);\n\t\t\t\tbuf = calloc (1, bbs + 1);\n\t\t\t\tr_io_read_at (core->io, pc, buf, bbs);\n\t\t\t\tint left;\n\t\t\t\twhile (pc < end) {\n\t\t\t\t\tleft = R_MIN (end - pc, 32);\n\t\t\t\t\tr_asm_set_pc (core->assembler, pc);\n\t\t\t\t\tret = r_anal_op (core->anal, &op, addr, buf, left, R_ANAL_OP_MASK_ALL); // read overflow\n\t\t\t\t\tif (ret) {\n\t\t\t\t\t\tr_reg_set_value_by_role (core->anal->reg, R_REG_NAME_PC, pc);\n\t\t\t\t\t\tr_anal_esil_parse (esil, R_STRBUF_SAFEGET (&op.esil));\n\t\t\t\t\t\tr_anal_esil_dumpstack (esil);\n\t\t\t\t\t\tr_anal_esil_stack_free (esil);\n\t\t\t\t\t\tpc += op.size;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tpc += 4; // XXX\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\teprintf (\"Cannot find function at 0x%08\" PFMT64x \"\\n\", core->offset);\n\t\t}\n\t} break;\n\tcase 't': // \"aet\"\n\t\tswitch (input[1]) {\n\t\tcase 'r': // \"aetr\"\n\t\t{\n\t\t\t// anal ESIL to REIL.\n\t\t\tRAnalEsil *esil = r_anal_esil_new (stacksize, iotrap, addrsize);\n\t\t\tif (!esil) {\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tr_anal_esil_to_reil_setup (esil, core->anal, romem, stats);\n\t\t\tr_anal_esil_set_pc (esil, core->offset);\n\t\t\tr_anal_esil_parse (esil, input + 2);\n\t\t\tr_anal_esil_dumpstack (esil);\n\t\t\tr_anal_esil_free (esil);\n\t\t\tbreak;\n\t\t}\n\t\tcase 's': // \"aets\"\n\t\t\tswitch (input[2]) {\n\t\t\tcase 0:\n\t\t\t\tr_anal_esil_session_list (esil);\n\t\t\t\tbreak;\n\t\t\tcase '+':\n\t\t\t\tr_anal_esil_session_add (esil);\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tr_core_cmd_help (core, help_msg_aets);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tbreak;\n\t\tdefault:\n\t\t\teprintf (\"Unknown command. Use `aetr`.\\n\");\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\tcase 'A': // \"aeA\"\n\t\tif (input[1] == '?') {\n\t\t\tr_core_cmd_help (core, help_msg_aea);\n\t\t} else if (input[1] == 'r') {\n\t\t\tcmd_aea (core, 1 + (1<<1), core->offset, r_num_math (core->num, input+2));\n\t\t} else if (input[1] == 'w') {\n\t\t\tcmd_aea (core, 1 + (1<<2), core->offset, r_num_math (core->num, input+2));\n\t\t} else if (input[1] == 'n') {\n\t\t\tcmd_aea (core, 1 + (1<<3), core->offset, r_num_math (core->num, input+2));\n\t\t} else if (input[1] == 'j') {\n\t\t\tcmd_aea (core, 1 + (1<<4), core->offset, r_num_math (core->num, input+2));\n\t\t} else if (input[1] == '*') {\n\t\t\tcmd_aea (core, 1 + (1<<5), core->offset, r_num_math (core->num, input+2));\n\t\t} else if (input[1] == 'f') {\n\t\t\tRAnalFunction *fcn = r_anal_get_fcn_in (core->anal, core->offset, -1);\n\t\t\tif (fcn) {\n\t\t\t\tcmd_aea (core, 1, fcn->addr, r_anal_fcn_size (fcn));\n\t\t\t}\n\t\t} else {\n\t\t\tcmd_aea (core, 1, core->offset, (int)r_num_math (core->num, input+2));\n\t\t}\n\t\tbreak;\n\tcase 'a': // \"aea\"\n\t\tif (input[1] == '?') {\n\t\t\tr_core_cmd_help (core, help_msg_aea);\n\t\t} else if (input[1] == 'r') {\n\t\t\tcmd_aea (core, 1<<1, core->offset, r_num_math (core->num, input+2));\n\t\t} else if (input[1] == 'w') {\n\t\t\tcmd_aea (core, 1<<2, core->offset, r_num_math (core->num, input+2));\n\t\t} else if (input[1] == 'n') {\n\t\t\tcmd_aea (core, 1<<3, core->offset, r_num_math (core->num, input+2));\n\t\t} else if (input[1] == 'j') {\n\t\t\tcmd_aea (core, 1<<4, core->offset, r_num_math (core->num, input+2));\n\t\t} else if (input[1] == '*') {\n\t\t\tcmd_aea (core, 1<<5, core->offset, r_num_math (core->num, input+2));\n\t\t} else if (input[1] == 'f') {\n\t\t\tRAnalFunction *fcn = r_anal_get_fcn_in (core->anal, core->offset, -1);\n                        // \"aeafj\"\n\t\t\tif (fcn) {\n\t\t\t\tswitch (input[2]) {\n\t\t\t\tcase 'j': // \"aeafj\"\n\t\t\t\t\tcmd_aea (core, 1<<4, fcn->addr, r_anal_fcn_size (fcn));\n\t\t\t\t\tbreak;\n\t\t\t\tdefault:\n\t\t\t\t\tcmd_aea (core, 1, fcn->addr, r_anal_fcn_size (fcn));\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t}\n\t\t} else {\n\t\t\tconst char *arg = input[1]? input + 2: \"\";\n\t\t\tut64 len = r_num_math (core->num, arg);\n\t\t\tcmd_aea (core, 0, core->offset, len);\n\t\t}\n\t\tbreak;\n\tcase 'x': { // \"aex\"\n\t\tchar *hex;\n\t\tint ret, bufsz;\n\n\t\tinput = r_str_trim_ro (input + 1);\n\t\thex = strdup (input);\n\t\tif (!hex) {\n\t\t\tbreak;\n\t\t}\n\n\t\tRAnalOp aop = R_EMPTY;\n\t\tbufsz = r_hex_str2bin (hex, (ut8*)hex);\n\t\tret = r_anal_op (core->anal, &aop, core->offset,\n\t\t\t(const ut8*)hex, bufsz, R_ANAL_OP_MASK_ALL);\n\t\tif (ret>0) {\n\t\t\tconst char *str = R_STRBUF_SAFEGET (&aop.esil);\n\t\t\tchar *str2 = r_str_newf (\" %s\", str);\n\t\t\tcmd_anal_esil (core, str2);\n\t\t\tfree (str2);\n\t\t}\n\t\tr_anal_op_fini (&aop);\n\t\tbreak;\n\t}\n\tcase '?': // \"ae?\"\n\t\tif (input[1] == '?') {\n\t\t\tr_core_cmd_help (core, help_detail_ae);\n\t\t\tbreak;\n\t\t}\n\t\t/* fallthrough */\n\tdefault:\n\t\tr_core_cmd_help (core, help_msg_ae);\n\t\tbreak;\n\t}\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -313,8 +313,9 @@\n \t\t{\n \t\t\t// anal ESIL to REIL.\n \t\t\tRAnalEsil *esil = r_anal_esil_new (stacksize, iotrap, addrsize);\n-\t\t\tif (!esil)\n+\t\t\tif (!esil) {\n \t\t\t\treturn;\n+\t\t\t}\n \t\t\tr_anal_esil_to_reil_setup (esil, core->anal, romem, stats);\n \t\t\tr_anal_esil_set_pc (esil, core->offset);\n \t\t\tr_anal_esil_parse (esil, input + 2);",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\tif (!esil)"
            ],
            "added_lines": [
                "\t\t\tif (!esil) {",
                "\t\t\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-11494",
        "func_name": "kernel/git/tip/tip/slc_bump",
        "description": "An issue was discovered in slc_bump in drivers/net/can/slcan.c in the Linux kernel 3.16 through 5.6.2. It allows attackers to read uninitialized can_frame data, potentially containing sensitive information from kernel stack memory, if the configuration lacks CONFIG_INIT_STACK_ALL, aka CID-b9258a2cece4.",
        "git_url": "https://git.kernel.org/pub/scm/linux/kernel/git/tip/tip.git/commit/?h=08fadc32ce6239dc75fd5e869590e29bc62bbc28",
        "commit_title": "commit b9258a2cece4ec1f020715fe3554bc2e360f6264 upstream.",
        "commit_text": " struct can_frame contains some padding which is not explicitly zeroed in slc_bump. This uninitialized data will then be transmitted if the stack initialization hardening feature is not enabled (CONFIG_INIT_STACK_ALL).  This commit just zeroes the whole struct including the padding.  Cc: linux-can@vger.kernel.org Cc: netdev@vger.kernel.org Cc: security@kernel.org Cc: wg@grandegger.com Cc: mkl@pengutronix.de Cc: davem@davemloft.net ",
        "func_before": "static void slc_bump(struct slcan *sl)\n{\n\tstruct sk_buff *skb;\n\tstruct can_frame cf;\n\tint i, tmp;\n\tu32 tmpid;\n\tchar *cmd = sl->rbuff;\n\n\tcf.can_id = 0;\n\n\tswitch (*cmd) {\n\tcase 'r':\n\t\tcf.can_id = CAN_RTR_FLAG;\n\t\t/* fallthrough */\n\tcase 't':\n\t\t/* store dlc ASCII value and terminate SFF CAN ID string */\n\t\tcf.can_dlc = sl->rbuff[SLC_CMD_LEN + SLC_SFF_ID_LEN];\n\t\tsl->rbuff[SLC_CMD_LEN + SLC_SFF_ID_LEN] = 0;\n\t\t/* point to payload data behind the dlc */\n\t\tcmd += SLC_CMD_LEN + SLC_SFF_ID_LEN + 1;\n\t\tbreak;\n\tcase 'R':\n\t\tcf.can_id = CAN_RTR_FLAG;\n\t\t/* fallthrough */\n\tcase 'T':\n\t\tcf.can_id |= CAN_EFF_FLAG;\n\t\t/* store dlc ASCII value and terminate EFF CAN ID string */\n\t\tcf.can_dlc = sl->rbuff[SLC_CMD_LEN + SLC_EFF_ID_LEN];\n\t\tsl->rbuff[SLC_CMD_LEN + SLC_EFF_ID_LEN] = 0;\n\t\t/* point to payload data behind the dlc */\n\t\tcmd += SLC_CMD_LEN + SLC_EFF_ID_LEN + 1;\n\t\tbreak;\n\tdefault:\n\t\treturn;\n\t}\n\n\tif (kstrtou32(sl->rbuff + SLC_CMD_LEN, 16, &tmpid))\n\t\treturn;\n\n\tcf.can_id |= tmpid;\n\n\t/* get can_dlc from sanitized ASCII value */\n\tif (cf.can_dlc >= '0' && cf.can_dlc < '9')\n\t\tcf.can_dlc -= '0';\n\telse\n\t\treturn;\n\n\t*(u64 *) (&cf.data) = 0; /* clear payload */\n\n\t/* RTR frames may have a dlc > 0 but they never have any data bytes */\n\tif (!(cf.can_id & CAN_RTR_FLAG)) {\n\t\tfor (i = 0; i < cf.can_dlc; i++) {\n\t\t\ttmp = hex_to_bin(*cmd++);\n\t\t\tif (tmp < 0)\n\t\t\t\treturn;\n\t\t\tcf.data[i] = (tmp << 4);\n\t\t\ttmp = hex_to_bin(*cmd++);\n\t\t\tif (tmp < 0)\n\t\t\t\treturn;\n\t\t\tcf.data[i] |= tmp;\n\t\t}\n\t}\n\n\tskb = dev_alloc_skb(sizeof(struct can_frame) +\n\t\t\t    sizeof(struct can_skb_priv));\n\tif (!skb)\n\t\treturn;\n\n\tskb->dev = sl->dev;\n\tskb->protocol = htons(ETH_P_CAN);\n\tskb->pkt_type = PACKET_BROADCAST;\n\tskb->ip_summed = CHECKSUM_UNNECESSARY;\n\n\tcan_skb_reserve(skb);\n\tcan_skb_prv(skb)->ifindex = sl->dev->ifindex;\n\n\tmemcpy(skb_put(skb, sizeof(struct can_frame)),\n\t       &cf, sizeof(struct can_frame));\n\tnetif_rx_ni(skb);\n\n\tsl->dev->stats.rx_packets++;\n\tsl->dev->stats.rx_bytes += cf.can_dlc;\n}",
        "func": "static void slc_bump(struct slcan *sl)\n{\n\tstruct sk_buff *skb;\n\tstruct can_frame cf;\n\tint i, tmp;\n\tu32 tmpid;\n\tchar *cmd = sl->rbuff;\n\n\tmemset(&cf, 0, sizeof(cf));\n\n\tswitch (*cmd) {\n\tcase 'r':\n\t\tcf.can_id = CAN_RTR_FLAG;\n\t\t/* fallthrough */\n\tcase 't':\n\t\t/* store dlc ASCII value and terminate SFF CAN ID string */\n\t\tcf.can_dlc = sl->rbuff[SLC_CMD_LEN + SLC_SFF_ID_LEN];\n\t\tsl->rbuff[SLC_CMD_LEN + SLC_SFF_ID_LEN] = 0;\n\t\t/* point to payload data behind the dlc */\n\t\tcmd += SLC_CMD_LEN + SLC_SFF_ID_LEN + 1;\n\t\tbreak;\n\tcase 'R':\n\t\tcf.can_id = CAN_RTR_FLAG;\n\t\t/* fallthrough */\n\tcase 'T':\n\t\tcf.can_id |= CAN_EFF_FLAG;\n\t\t/* store dlc ASCII value and terminate EFF CAN ID string */\n\t\tcf.can_dlc = sl->rbuff[SLC_CMD_LEN + SLC_EFF_ID_LEN];\n\t\tsl->rbuff[SLC_CMD_LEN + SLC_EFF_ID_LEN] = 0;\n\t\t/* point to payload data behind the dlc */\n\t\tcmd += SLC_CMD_LEN + SLC_EFF_ID_LEN + 1;\n\t\tbreak;\n\tdefault:\n\t\treturn;\n\t}\n\n\tif (kstrtou32(sl->rbuff + SLC_CMD_LEN, 16, &tmpid))\n\t\treturn;\n\n\tcf.can_id |= tmpid;\n\n\t/* get can_dlc from sanitized ASCII value */\n\tif (cf.can_dlc >= '0' && cf.can_dlc < '9')\n\t\tcf.can_dlc -= '0';\n\telse\n\t\treturn;\n\n\t/* RTR frames may have a dlc > 0 but they never have any data bytes */\n\tif (!(cf.can_id & CAN_RTR_FLAG)) {\n\t\tfor (i = 0; i < cf.can_dlc; i++) {\n\t\t\ttmp = hex_to_bin(*cmd++);\n\t\t\tif (tmp < 0)\n\t\t\t\treturn;\n\t\t\tcf.data[i] = (tmp << 4);\n\t\t\ttmp = hex_to_bin(*cmd++);\n\t\t\tif (tmp < 0)\n\t\t\t\treturn;\n\t\t\tcf.data[i] |= tmp;\n\t\t}\n\t}\n\n\tskb = dev_alloc_skb(sizeof(struct can_frame) +\n\t\t\t    sizeof(struct can_skb_priv));\n\tif (!skb)\n\t\treturn;\n\n\tskb->dev = sl->dev;\n\tskb->protocol = htons(ETH_P_CAN);\n\tskb->pkt_type = PACKET_BROADCAST;\n\tskb->ip_summed = CHECKSUM_UNNECESSARY;\n\n\tcan_skb_reserve(skb);\n\tcan_skb_prv(skb)->ifindex = sl->dev->ifindex;\n\n\tmemcpy(skb_put(skb, sizeof(struct can_frame)),\n\t       &cf, sizeof(struct can_frame));\n\tnetif_rx_ni(skb);\n\n\tsl->dev->stats.rx_packets++;\n\tsl->dev->stats.rx_bytes += cf.can_dlc;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -6,7 +6,7 @@\n \tu32 tmpid;\n \tchar *cmd = sl->rbuff;\n \n-\tcf.can_id = 0;\n+\tmemset(&cf, 0, sizeof(cf));\n \n \tswitch (*cmd) {\n \tcase 'r':\n@@ -45,8 +45,6 @@\n \telse\n \t\treturn;\n \n-\t*(u64 *) (&cf.data) = 0; /* clear payload */\n-\n \t/* RTR frames may have a dlc > 0 but they never have any data bytes */\n \tif (!(cf.can_id & CAN_RTR_FLAG)) {\n \t\tfor (i = 0; i < cf.can_dlc; i++) {",
        "diff_line_info": {
            "deleted_lines": [
                "\tcf.can_id = 0;",
                "\t*(u64 *) (&cf.data) = 0; /* clear payload */",
                ""
            ],
            "added_lines": [
                "\tmemset(&cf, 0, sizeof(cf));"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-13113",
        "func_name": "libexif/exif_mnote_data_pentax_load",
        "description": "An issue was discovered in libexif before 0.6.22. Use of uninitialized memory in EXIF Makernote handling could lead to crashes and potential use-after-free conditions.",
        "git_url": "https://github.com/libexif/libexif/commit/ec412aa4583ad71ecabb967d3c77162760169d1f",
        "commit_title": "Ensure the MakerNote data pointers are initialized with NULL.",
        "commit_text": " This ensures that an uninitialized pointer isn't dereferenced later in the case where the number of components (and therefore size) is 0.  This fixes the second issue reported at https://sourceforge.net/p/libexif/bugs/125/  CVE-2020-13113",
        "func_before": "static void\nexif_mnote_data_pentax_load (ExifMnoteData *en,\n\t\tconst unsigned char *buf, unsigned int buf_size)\n{\n\tExifMnoteDataPentax *n = (ExifMnoteDataPentax *) en;\n\tsize_t i, tcount, o, datao, base = 0;\n\tExifShort c;\n\n\tif (!n || !buf || !buf_size) {\n\t\texif_log (en->log, EXIF_LOG_CODE_CORRUPT_DATA,\n\t\t\t  \"ExifMnoteDataPentax\", \"Short MakerNote\");\n\t\treturn;\n\t}\n\tdatao = 6 + n->offset;\n\tif (CHECKOVERFLOW(datao, buf_size, 8)) {\n\t\texif_log (en->log, EXIF_LOG_CODE_CORRUPT_DATA,\n\t\t\t  \"ExifMnoteDataPentax\", \"Short MakerNote\");\n\t\treturn;\n\t}\n\n\t/* Detect variant of Pentax/Casio MakerNote found */\n\tif (!memcmp(buf + datao, \"AOC\", 4)) {\n\t\tif ((buf[datao + 4] == 'I') && (buf[datao + 5] == 'I')) {\n\t\t\tn->version = pentaxV3;\n\t\t\tn->order = EXIF_BYTE_ORDER_INTEL;\n\t\t} else if ((buf[datao + 4] == 'M') && (buf[datao + 5] == 'M')) {\n\t\t\tn->version = pentaxV3;\n\t\t\tn->order = EXIF_BYTE_ORDER_MOTOROLA;\n\t\t} else {\n\t\t\t/* Uses Casio v2 tags */\n\t\t\tn->version = pentaxV2;\n\t\t}\n\t\texif_log (en->log, EXIF_LOG_CODE_DEBUG, \"ExifMnoteDataPentax\",\n\t\t\t\"Parsing Pentax maker note v%d...\", (int)n->version);\n\t\tdatao += 4 + 2;\n\t\tbase = MNOTE_PENTAX2_TAG_BASE;\n\t} else if (!memcmp(buf + datao, \"QVC\", 4)) {\n\t\texif_log (en->log, EXIF_LOG_CODE_DEBUG, \"ExifMnoteDataPentax\",\n\t\t\t\"Parsing Casio maker note v2...\");\n\t\tn->version = casioV2;\n\t\tbase = MNOTE_CASIO2_TAG_BASE;\n\t\tdatao += 4 + 2;\n\t} else {\n\t\t/* probably assert(!memcmp(buf + datao, \"\\x00\\x1b\", 2)) */\n\t\texif_log (en->log, EXIF_LOG_CODE_DEBUG, \"ExifMnoteDataPentax\",\n\t\t\t\"Parsing Pentax maker note v1...\");\n\t\tn->version = pentaxV1;\n\t}\n\n\t/* Read the number of tags */\n\tc = exif_get_short (buf + datao, n->order);\n\tdatao += 2;\n\n\t/* Remove any old entries */\n\texif_mnote_data_pentax_clear (n);\n\n\t/* Reserve enough space for all the possible MakerNote tags */\n\tn->entries = exif_mem_alloc (en->mem, sizeof (MnotePentaxEntry) * c);\n\tif (!n->entries) {\n\t\tEXIF_LOG_NO_MEMORY(en->log, \"ExifMnoteDataPentax\", sizeof (MnotePentaxEntry) * c);\n\t\treturn;\n\t}\n\n\t/* Parse all c entries, storing ones that are successfully parsed */\n\ttcount = 0;\n\tfor (i = c, o = datao; i; --i, o += 12) {\n\t\tsize_t s;\n\n\t\tif (CHECKOVERFLOW(o,buf_size,12)) {\n\t\t\texif_log (en->log, EXIF_LOG_CODE_CORRUPT_DATA,\n\t\t\t\t  \"ExifMnoteDataPentax\", \"Short MakerNote\");\n\t\t\tbreak;\n\t\t}\n\n\t\tn->entries[tcount].tag        = exif_get_short (buf + o + 0, n->order) + base;\n\t\tn->entries[tcount].format     = exif_get_short (buf + o + 2, n->order);\n\t\tn->entries[tcount].components = exif_get_long  (buf + o + 4, n->order);\n\t\tn->entries[tcount].order      = n->order;\n\n\t\texif_log (en->log, EXIF_LOG_CODE_DEBUG, \"ExifMnotePentax\",\n\t\t\t  \"Loading entry 0x%x ('%s')...\", n->entries[tcount].tag,\n\t\t\t  mnote_pentax_tag_get_name (n->entries[tcount].tag));\n\n\t\t/* Check if we overflow the multiplication. Use buf_size as the max size for integer overflow detection,\n\t\t * we will check the buffer sizes closer later. */\n\t\tif (\texif_format_get_size (n->entries[tcount].format) &&\n\t\t\tbuf_size / exif_format_get_size (n->entries[tcount].format) < n->entries[tcount].components\n\t\t) {\n\t\t\texif_log (en->log, EXIF_LOG_CODE_CORRUPT_DATA,\n\t\t\t\t  \"ExifMnoteDataPentax\", \"Tag size overflow detected (%u * %lu)\", exif_format_get_size (n->entries[tcount].format), n->entries[tcount].components);\n\t\t\tbreak;\n\t\t}\n\t\t/*\n\t\t * Size? If bigger than 4 bytes, the actual data is not\n\t\t * in the entry but somewhere else (offset).\n\t\t */\n\t\ts = exif_format_get_size (n->entries[tcount].format) *\n                                      n->entries[tcount].components;\n\t\tn->entries[tcount].size = s;\n\t\tif (s) {\n\t\t\tsize_t dataofs = o + 8;\n\t\t\tif (s > 4)\n\t\t\t\t/* The data in this case is merely a pointer */\n\t\t\t   \tdataofs = exif_get_long (buf + dataofs, n->order) + 6;\n\n\t\t\tif (CHECKOVERFLOW(dataofs, buf_size, s)) {\n\t\t\t\texif_log (en->log, EXIF_LOG_CODE_DEBUG,\n\t\t\t\t\t\t  \"ExifMnoteDataPentax\", \"Tag data past end \"\n\t\t\t\t\t  \"of buffer (%u > %u)\", (unsigned)(dataofs + s), buf_size);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tn->entries[tcount].data = exif_mem_alloc (en->mem, s);\n\t\t\tif (!n->entries[tcount].data) {\n\t\t\t\tEXIF_LOG_NO_MEMORY(en->log, \"ExifMnoteDataPentax\", s);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tmemcpy (n->entries[tcount].data, buf + dataofs, s);\n\t\t}\n\n\t\t/* Tag was successfully parsed */\n\t\t++tcount;\n\t}\n\t/* Store the count of successfully parsed tags */\n\tn->count = tcount;\n}",
        "func": "static void\nexif_mnote_data_pentax_load (ExifMnoteData *en,\n\t\tconst unsigned char *buf, unsigned int buf_size)\n{\n\tExifMnoteDataPentax *n = (ExifMnoteDataPentax *) en;\n\tsize_t i, tcount, o, datao, base = 0;\n\tExifShort c;\n\n\tif (!n || !buf || !buf_size) {\n\t\texif_log (en->log, EXIF_LOG_CODE_CORRUPT_DATA,\n\t\t\t  \"ExifMnoteDataPentax\", \"Short MakerNote\");\n\t\treturn;\n\t}\n\tdatao = 6 + n->offset;\n\tif (CHECKOVERFLOW(datao, buf_size, 8)) {\n\t\texif_log (en->log, EXIF_LOG_CODE_CORRUPT_DATA,\n\t\t\t  \"ExifMnoteDataPentax\", \"Short MakerNote\");\n\t\treturn;\n\t}\n\n\t/* Detect variant of Pentax/Casio MakerNote found */\n\tif (!memcmp(buf + datao, \"AOC\", 4)) {\n\t\tif ((buf[datao + 4] == 'I') && (buf[datao + 5] == 'I')) {\n\t\t\tn->version = pentaxV3;\n\t\t\tn->order = EXIF_BYTE_ORDER_INTEL;\n\t\t} else if ((buf[datao + 4] == 'M') && (buf[datao + 5] == 'M')) {\n\t\t\tn->version = pentaxV3;\n\t\t\tn->order = EXIF_BYTE_ORDER_MOTOROLA;\n\t\t} else {\n\t\t\t/* Uses Casio v2 tags */\n\t\t\tn->version = pentaxV2;\n\t\t}\n\t\texif_log (en->log, EXIF_LOG_CODE_DEBUG, \"ExifMnoteDataPentax\",\n\t\t\t\"Parsing Pentax maker note v%d...\", (int)n->version);\n\t\tdatao += 4 + 2;\n\t\tbase = MNOTE_PENTAX2_TAG_BASE;\n\t} else if (!memcmp(buf + datao, \"QVC\", 4)) {\n\t\texif_log (en->log, EXIF_LOG_CODE_DEBUG, \"ExifMnoteDataPentax\",\n\t\t\t\"Parsing Casio maker note v2...\");\n\t\tn->version = casioV2;\n\t\tbase = MNOTE_CASIO2_TAG_BASE;\n\t\tdatao += 4 + 2;\n\t} else {\n\t\t/* probably assert(!memcmp(buf + datao, \"\\x00\\x1b\", 2)) */\n\t\texif_log (en->log, EXIF_LOG_CODE_DEBUG, \"ExifMnoteDataPentax\",\n\t\t\t\"Parsing Pentax maker note v1...\");\n\t\tn->version = pentaxV1;\n\t}\n\n\t/* Read the number of tags */\n\tc = exif_get_short (buf + datao, n->order);\n\tdatao += 2;\n\n\t/* Remove any old entries */\n\texif_mnote_data_pentax_clear (n);\n\n\t/* Reserve enough space for all the possible MakerNote tags */\n\tn->entries = exif_mem_alloc (en->mem, sizeof (MnotePentaxEntry) * c);\n\tif (!n->entries) {\n\t\tEXIF_LOG_NO_MEMORY(en->log, \"ExifMnoteDataPentax\", sizeof (MnotePentaxEntry) * c);\n\t\treturn;\n\t}\n\n\t/* Parse all c entries, storing ones that are successfully parsed */\n\ttcount = 0;\n\tfor (i = c, o = datao; i; --i, o += 12) {\n\t\tsize_t s;\n\n\t\tmemset(&n->entries[tcount], 0, sizeof(MnotePentaxEntry));\n\t\tif (CHECKOVERFLOW(o,buf_size,12)) {\n\t\t\texif_log (en->log, EXIF_LOG_CODE_CORRUPT_DATA,\n\t\t\t\t  \"ExifMnoteDataPentax\", \"Short MakerNote\");\n\t\t\tbreak;\n\t\t}\n\n\t\tn->entries[tcount].tag        = exif_get_short (buf + o + 0, n->order) + base;\n\t\tn->entries[tcount].format     = exif_get_short (buf + o + 2, n->order);\n\t\tn->entries[tcount].components = exif_get_long  (buf + o + 4, n->order);\n\t\tn->entries[tcount].order      = n->order;\n\n\t\texif_log (en->log, EXIF_LOG_CODE_DEBUG, \"ExifMnotePentax\",\n\t\t\t  \"Loading entry 0x%x ('%s')...\", n->entries[tcount].tag,\n\t\t\t  mnote_pentax_tag_get_name (n->entries[tcount].tag));\n\n\t\t/* Check if we overflow the multiplication. Use buf_size as the max size for integer overflow detection,\n\t\t * we will check the buffer sizes closer later. */\n\t\tif (\texif_format_get_size (n->entries[tcount].format) &&\n\t\t\tbuf_size / exif_format_get_size (n->entries[tcount].format) < n->entries[tcount].components\n\t\t) {\n\t\t\texif_log (en->log, EXIF_LOG_CODE_CORRUPT_DATA,\n\t\t\t\t  \"ExifMnoteDataPentax\", \"Tag size overflow detected (%u * %lu)\", exif_format_get_size (n->entries[tcount].format), n->entries[tcount].components);\n\t\t\tbreak;\n\t\t}\n\t\t/*\n\t\t * Size? If bigger than 4 bytes, the actual data is not\n\t\t * in the entry but somewhere else (offset).\n\t\t */\n\t\ts = exif_format_get_size (n->entries[tcount].format) *\n                                      n->entries[tcount].components;\n\t\tn->entries[tcount].size = s;\n\t\tif (s) {\n\t\t\tsize_t dataofs = o + 8;\n\t\t\tif (s > 4)\n\t\t\t\t/* The data in this case is merely a pointer */\n\t\t\t   \tdataofs = exif_get_long (buf + dataofs, n->order) + 6;\n\n\t\t\tif (CHECKOVERFLOW(dataofs, buf_size, s)) {\n\t\t\t\texif_log (en->log, EXIF_LOG_CODE_DEBUG,\n\t\t\t\t\t\t  \"ExifMnoteDataPentax\", \"Tag data past end \"\n\t\t\t\t\t  \"of buffer (%u > %u)\", (unsigned)(dataofs + s), buf_size);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tn->entries[tcount].data = exif_mem_alloc (en->mem, s);\n\t\t\tif (!n->entries[tcount].data) {\n\t\t\t\tEXIF_LOG_NO_MEMORY(en->log, \"ExifMnoteDataPentax\", s);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tmemcpy (n->entries[tcount].data, buf + dataofs, s);\n\t\t}\n\n\t\t/* Tag was successfully parsed */\n\t\t++tcount;\n\t}\n\t/* Store the count of successfully parsed tags */\n\tn->count = tcount;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -66,6 +66,7 @@\n \tfor (i = c, o = datao; i; --i, o += 12) {\n \t\tsize_t s;\n \n+\t\tmemset(&n->entries[tcount], 0, sizeof(MnotePentaxEntry));\n \t\tif (CHECKOVERFLOW(o,buf_size,12)) {\n \t\t\texif_log (en->log, EXIF_LOG_CODE_CORRUPT_DATA,\n \t\t\t\t  \"ExifMnoteDataPentax\", \"Short MakerNote\");",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t\tmemset(&n->entries[tcount], 0, sizeof(MnotePentaxEntry));"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-13113",
        "func_name": "libexif/exif_mnote_data_fuji_load",
        "description": "An issue was discovered in libexif before 0.6.22. Use of uninitialized memory in EXIF Makernote handling could lead to crashes and potential use-after-free conditions.",
        "git_url": "https://github.com/libexif/libexif/commit/ec412aa4583ad71ecabb967d3c77162760169d1f",
        "commit_title": "Ensure the MakerNote data pointers are initialized with NULL.",
        "commit_text": " This ensures that an uninitialized pointer isn't dereferenced later in the case where the number of components (and therefore size) is 0.  This fixes the second issue reported at https://sourceforge.net/p/libexif/bugs/125/  CVE-2020-13113",
        "func_before": "static void\nexif_mnote_data_fuji_load (ExifMnoteData *en,\n\tconst unsigned char *buf, unsigned int buf_size)\n{\n\tExifMnoteDataFuji *n = (ExifMnoteDataFuji*) en;\n\tExifLong c;\n\tsize_t i, tcount, o, datao;\n\n\tif (!n || !buf || !buf_size) {\n\t\texif_log (en->log, EXIF_LOG_CODE_CORRUPT_DATA,\n\t\t\t  \"ExifMnoteDataFuji\", \"Short MakerNote\");\n\t\treturn;\n\t}\n\tdatao = 6 + n->offset;\n\tif (CHECKOVERFLOW(datao, buf_size, 12)) {\n\t\texif_log (en->log, EXIF_LOG_CODE_CORRUPT_DATA,\n\t\t\t  \"ExifMnoteDataFuji\", \"Short MakerNote\");\n\t\treturn;\n\t}\n\n\tn->order = EXIF_BYTE_ORDER_INTEL;\n\n\tdatao += exif_get_long (buf + datao + 8, EXIF_BYTE_ORDER_INTEL);\n\tif (CHECKOVERFLOW(datao, buf_size, 2)) {\n\t\texif_log (en->log, EXIF_LOG_CODE_CORRUPT_DATA,\n\t\t\t  \"ExifMnoteDataFuji\", \"Short MakerNote\");\n\t\treturn;\n\t}\n\n\t/* Read the number of tags */\n\tc = exif_get_short (buf + datao, EXIF_BYTE_ORDER_INTEL);\n\tdatao += 2;\n\n\t/* Remove any old entries */\n\texif_mnote_data_fuji_clear (n);\n\n\t/* Reserve enough space for all the possible MakerNote tags */\n\tn->entries = exif_mem_alloc (en->mem, sizeof (MnoteFujiEntry) * c);\n\tif (!n->entries) {\n\t\tEXIF_LOG_NO_MEMORY(en->log, \"ExifMnoteDataFuji\", sizeof (MnoteFujiEntry) * c);\n\t\treturn;\n\t}\n\n\t/* Parse all c entries, storing ones that are successfully parsed */\n\ttcount = 0;\n\tfor (i = c, o = datao; i; --i, o += 12) {\n\t\tsize_t s;\n\n\t\tif (CHECKOVERFLOW(o, buf_size, 12)) {\n\t\t\texif_log (en->log, EXIF_LOG_CODE_CORRUPT_DATA,\n\t\t\t\t  \"ExifMnoteDataFuji\", \"Short MakerNote\");\n\t\t\tbreak;\n\t\t}\n\n\t\tn->entries[tcount].tag        = exif_get_short (buf + o, n->order);\n\t\tn->entries[tcount].format     = exif_get_short (buf + o + 2, n->order);\n\t\tn->entries[tcount].components = exif_get_long (buf + o + 4, n->order);\n\t\tn->entries[tcount].order      = n->order;\n\n\t\texif_log (en->log, EXIF_LOG_CODE_DEBUG, \"ExifMnoteDataFuji\",\n\t\t\t  \"Loading entry 0x%x ('%s')...\", n->entries[tcount].tag,\n\t\t\t  mnote_fuji_tag_get_name (n->entries[tcount].tag));\n\n\t\t/* Check if we overflow the multiplication. Use buf_size as the max size for integer overflow detection,\n\t\t * we will check the buffer sizes closer later. */\n\t\tif (\texif_format_get_size (n->entries[tcount].format) &&\n\t\t\tbuf_size / exif_format_get_size (n->entries[tcount].format) < n->entries[tcount].components\n\t\t) {\n\t\t\texif_log (en->log, EXIF_LOG_CODE_CORRUPT_DATA,\n\t\t\t\t\t  \"ExifMnoteDataFuji\", \"Tag size overflow detected (%u * %lu)\", exif_format_get_size (n->entries[tcount].format), n->entries[tcount].components);\n\t\t\tcontinue;\n\t\t}\n\t\t/*\n\t\t * Size? If bigger than 4 bytes, the actual data is not\n\t\t * in the entry but somewhere else (offset).\n\t\t */\n\t\ts = exif_format_get_size (n->entries[tcount].format) * n->entries[tcount].components;\n\t\tn->entries[tcount].size = s;\n\t\tif (s) {\n\t\t\tsize_t dataofs = o + 8;\n\t\t\tif (s > 4)\n\t\t\t\t/* The data in this case is merely a pointer */\n\t\t\t\tdataofs = exif_get_long (buf + dataofs, n->order) + 6 + n->offset;\n\n\t\t\tif (CHECKOVERFLOW(dataofs, buf_size, s)) {\n\t\t\t\texif_log (en->log, EXIF_LOG_CODE_CORRUPT_DATA,\n\t\t\t\t\t\t  \"ExifMnoteDataFuji\", \"Tag data past end of \"\n\t\t\t\t\t  \"buffer (%u >= %u)\", (unsigned)(dataofs + s), buf_size);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tn->entries[tcount].data = exif_mem_alloc (en->mem, s);\n\t\t\tif (!n->entries[tcount].data) {\n\t\t\t\tEXIF_LOG_NO_MEMORY(en->log, \"ExifMnoteDataFuji\", s);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tmemcpy (n->entries[tcount].data, buf + dataofs, s);\n\t\t}\n\n\t\t/* Tag was successfully parsed */\n\t\t++tcount;\n\t}\n\t/* Store the count of successfully parsed tags */\n\tn->count = tcount;\n}",
        "func": "static void\nexif_mnote_data_fuji_load (ExifMnoteData *en,\n\tconst unsigned char *buf, unsigned int buf_size)\n{\n\tExifMnoteDataFuji *n = (ExifMnoteDataFuji*) en;\n\tExifLong c;\n\tsize_t i, tcount, o, datao;\n\n\tif (!n || !buf || !buf_size) {\n\t\texif_log (en->log, EXIF_LOG_CODE_CORRUPT_DATA,\n\t\t\t  \"ExifMnoteDataFuji\", \"Short MakerNote\");\n\t\treturn;\n\t}\n\tdatao = 6 + n->offset;\n\tif (CHECKOVERFLOW(datao, buf_size, 12)) {\n\t\texif_log (en->log, EXIF_LOG_CODE_CORRUPT_DATA,\n\t\t\t  \"ExifMnoteDataFuji\", \"Short MakerNote\");\n\t\treturn;\n\t}\n\n\tn->order = EXIF_BYTE_ORDER_INTEL;\n\n\tdatao += exif_get_long (buf + datao + 8, EXIF_BYTE_ORDER_INTEL);\n\tif (CHECKOVERFLOW(datao, buf_size, 2)) {\n\t\texif_log (en->log, EXIF_LOG_CODE_CORRUPT_DATA,\n\t\t\t  \"ExifMnoteDataFuji\", \"Short MakerNote\");\n\t\treturn;\n\t}\n\n\t/* Read the number of tags */\n\tc = exif_get_short (buf + datao, EXIF_BYTE_ORDER_INTEL);\n\tdatao += 2;\n\n\t/* Remove any old entries */\n\texif_mnote_data_fuji_clear (n);\n\n\t/* Reserve enough space for all the possible MakerNote tags */\n\tn->entries = exif_mem_alloc (en->mem, sizeof (MnoteFujiEntry) * c);\n\tif (!n->entries) {\n\t\tEXIF_LOG_NO_MEMORY(en->log, \"ExifMnoteDataFuji\", sizeof (MnoteFujiEntry) * c);\n\t\treturn;\n\t}\n\n\t/* Parse all c entries, storing ones that are successfully parsed */\n\ttcount = 0;\n\tfor (i = c, o = datao; i; --i, o += 12) {\n\t\tsize_t s;\n\n\t\tmemset(&n->entries[tcount], 0, sizeof(MnoteFujiEntry));\n\t\tif (CHECKOVERFLOW(o, buf_size, 12)) {\n\t\t\texif_log (en->log, EXIF_LOG_CODE_CORRUPT_DATA,\n\t\t\t\t  \"ExifMnoteDataFuji\", \"Short MakerNote\");\n\t\t\tbreak;\n\t\t}\n\n\t\tn->entries[tcount].tag        = exif_get_short (buf + o, n->order);\n\t\tn->entries[tcount].format     = exif_get_short (buf + o + 2, n->order);\n\t\tn->entries[tcount].components = exif_get_long (buf + o + 4, n->order);\n\t\tn->entries[tcount].order      = n->order;\n\n\t\texif_log (en->log, EXIF_LOG_CODE_DEBUG, \"ExifMnoteDataFuji\",\n\t\t\t  \"Loading entry 0x%x ('%s')...\", n->entries[tcount].tag,\n\t\t\t  mnote_fuji_tag_get_name (n->entries[tcount].tag));\n\n\t\t/* Check if we overflow the multiplication. Use buf_size as the max size for integer overflow detection,\n\t\t * we will check the buffer sizes closer later. */\n\t\tif (\texif_format_get_size (n->entries[tcount].format) &&\n\t\t\tbuf_size / exif_format_get_size (n->entries[tcount].format) < n->entries[tcount].components\n\t\t) {\n\t\t\texif_log (en->log, EXIF_LOG_CODE_CORRUPT_DATA,\n\t\t\t\t\t  \"ExifMnoteDataFuji\", \"Tag size overflow detected (%u * %lu)\", exif_format_get_size (n->entries[tcount].format), n->entries[tcount].components);\n\t\t\tcontinue;\n\t\t}\n\t\t/*\n\t\t * Size? If bigger than 4 bytes, the actual data is not\n\t\t * in the entry but somewhere else (offset).\n\t\t */\n\t\ts = exif_format_get_size (n->entries[tcount].format) * n->entries[tcount].components;\n\t\tn->entries[tcount].size = s;\n\t\tif (s) {\n\t\t\tsize_t dataofs = o + 8;\n\t\t\tif (s > 4)\n\t\t\t\t/* The data in this case is merely a pointer */\n\t\t\t\tdataofs = exif_get_long (buf + dataofs, n->order) + 6 + n->offset;\n\n\t\t\tif (CHECKOVERFLOW(dataofs, buf_size, s)) {\n\t\t\t\texif_log (en->log, EXIF_LOG_CODE_CORRUPT_DATA,\n\t\t\t\t\t\t  \"ExifMnoteDataFuji\", \"Tag data past end of \"\n\t\t\t\t\t  \"buffer (%u >= %u)\", (unsigned)(dataofs + s), buf_size);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tn->entries[tcount].data = exif_mem_alloc (en->mem, s);\n\t\t\tif (!n->entries[tcount].data) {\n\t\t\t\tEXIF_LOG_NO_MEMORY(en->log, \"ExifMnoteDataFuji\", s);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tmemcpy (n->entries[tcount].data, buf + dataofs, s);\n\t\t}\n\n\t\t/* Tag was successfully parsed */\n\t\t++tcount;\n\t}\n\t/* Store the count of successfully parsed tags */\n\tn->count = tcount;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -46,6 +46,7 @@\n \tfor (i = c, o = datao; i; --i, o += 12) {\n \t\tsize_t s;\n \n+\t\tmemset(&n->entries[tcount], 0, sizeof(MnoteFujiEntry));\n \t\tif (CHECKOVERFLOW(o, buf_size, 12)) {\n \t\t\texif_log (en->log, EXIF_LOG_CODE_CORRUPT_DATA,\n \t\t\t\t  \"ExifMnoteDataFuji\", \"Short MakerNote\");",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t\tmemset(&n->entries[tcount], 0, sizeof(MnoteFujiEntry));"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-13113",
        "func_name": "libexif/exif_mnote_data_olympus_load",
        "description": "An issue was discovered in libexif before 0.6.22. Use of uninitialized memory in EXIF Makernote handling could lead to crashes and potential use-after-free conditions.",
        "git_url": "https://github.com/libexif/libexif/commit/ec412aa4583ad71ecabb967d3c77162760169d1f",
        "commit_title": "Ensure the MakerNote data pointers are initialized with NULL.",
        "commit_text": " This ensures that an uninitialized pointer isn't dereferenced later in the case where the number of components (and therefore size) is 0.  This fixes the second issue reported at https://sourceforge.net/p/libexif/bugs/125/  CVE-2020-13113",
        "func_before": "static void\nexif_mnote_data_olympus_load (ExifMnoteData *en,\n\t\t\t      const unsigned char *buf, unsigned int buf_size)\n{\n\tExifMnoteDataOlympus *n = (ExifMnoteDataOlympus *) en;\n\tExifShort c;\n\tsize_t i, tcount, o, o2, datao = 6, base = 0;\n\n\tif (!n || !buf || !buf_size) {\n\t\texif_log (en->log, EXIF_LOG_CODE_CORRUPT_DATA,\n\t\t\t  \"ExifMnoteDataOlympus\", \"Short MakerNote\");\n\t\treturn;\n\t}\n\to2 = 6 + n->offset; /* Start of interesting data */\n\tif (CHECKOVERFLOW(o2,buf_size,10)) {\n\t\texif_log (en->log, EXIF_LOG_CODE_CORRUPT_DATA,\n\t\t\t  \"ExifMnoteDataOlympus\", \"Short MakerNote\");\n\t\treturn;\n\t}\n\n\t/*\n\t * Olympus headers start with \"OLYMP\" and need to have at least\n\t * a size of 22 bytes (6 for 'OLYMP', 2 other bytes, 2 for the\n\t * number of entries, and 12 for one entry.\n\t *\n\t * Sanyo format is identical and uses identical tags except that\n\t * header starts with \"SANYO\".\n\t *\n\t * Epson format is identical and uses identical tags except that\n\t * header starts with \"EPSON\".\n\t *\n\t * Nikon headers start with \"Nikon\" (6 bytes including '\\0'), \n\t * version number (1 or 2).\n\t * \n\t * Version 1 continues with 0, 1, 0, number_of_tags,\n\t * or just with number_of_tags (models D1H, D1X...).\n\t * \n\t * Version 2 continues with an unknown byte (0 or 10),\n\t * two unknown bytes (0), \"MM\" or \"II\", another byte 0 and \n\t * lastly 0x2A.\n\t */\n\tn->version = exif_mnote_data_olympus_identify_variant(buf+o2, buf_size-o2);\n\tswitch (n->version) {\n\tcase olympusV1:\n\tcase sanyoV1:\n\tcase epsonV1:\n\t\texif_log (en->log, EXIF_LOG_CODE_DEBUG, \"ExifMnoteDataOlympus\",\n\t\t\t\"Parsing Olympus/Sanyo/Epson maker note v1...\");\n\n\t\t/* The number of entries is at position 8. */\n\t\tif (buf[o2 + 6] == 1)\n\t\t\tn->order = EXIF_BYTE_ORDER_INTEL;\n\t\telse if (buf[o2 + 6 + 1] == 1)\n\t\t\tn->order = EXIF_BYTE_ORDER_MOTOROLA;\n\t\to2 += 8;\n\t\tc = exif_get_short (buf + o2, n->order);\n\t\tif ((!(c & 0xFF)) && (c > 0x500)) {\n\t\t\tif (n->order == EXIF_BYTE_ORDER_INTEL) {\n\t\t\t\tn->order = EXIF_BYTE_ORDER_MOTOROLA;\n\t\t\t} else {\n\t\t\t\tn->order = EXIF_BYTE_ORDER_INTEL;\n\t\t\t}\n\t\t}\n\t\tbreak;\n\n\tcase olympusV2:\n\t\t/* Olympus S760, S770 */\n\t\tdatao = o2;\n\t\to2 += 8;\n\t\tif (CHECKOVERFLOW(o2,buf_size,4)) return;\n\t\texif_log (en->log, EXIF_LOG_CODE_DEBUG, \"ExifMnoteDataOlympus\",\n\t\t\t\"Parsing Olympus maker note v2 (0x%02x, %02x, %02x, %02x)...\",\n\t\t\tbuf[o2 + 0], buf[o2 + 1], buf[o2 + 2], buf[o2 + 3]);\n\n\t\tif ((buf[o2] == 'I') && (buf[o2 + 1] == 'I'))\n\t\t\tn->order = EXIF_BYTE_ORDER_INTEL;\n\t\telse if ((buf[o2] == 'M') && (buf[o2 + 1] == 'M'))\n\t\t\tn->order = EXIF_BYTE_ORDER_MOTOROLA;\n\n\t\t/* The number of entries is at position 8+4. */\n\t\to2 += 4;\n\t\tbreak;\n\n\tcase nikonV1:\n\t\to2 += 6;\n\t\texif_log (en->log, EXIF_LOG_CODE_DEBUG, \"ExifMnoteDataOlympus\",\n\t\t\t\"Parsing Nikon maker note v1 (0x%02x, %02x, %02x, \"\n\t\t\t\"%02x)...\",\n\t\t\tbuf[o2 + 0], buf[o2 + 1], buf[o2 + 2], buf[o2 + 3]);\n\n\t\t/* Skip version number */\n\t\to2 += 1;\n\n\t\t/* Skip an unknown byte (00 or 0A). */\n\t\to2 += 1;\n\n\t\tbase = MNOTE_NIKON1_TAG_BASE;\n\t\t/* Fix endianness, if needed */\n\t\tc = exif_get_short (buf + o2, n->order);\n\t\tif ((!(c & 0xFF)) && (c > 0x500)) {\n\t\t\tif (n->order == EXIF_BYTE_ORDER_INTEL) {\n\t\t\t\tn->order = EXIF_BYTE_ORDER_MOTOROLA;\n\t\t\t} else {\n\t\t\t\tn->order = EXIF_BYTE_ORDER_INTEL;\n\t\t\t}\n\t\t}\n\t\tbreak;\n\n\tcase nikonV2:\n\t\to2 += 6;\n\t\tif (CHECKOVERFLOW(o2,buf_size,12)) return;\n\t\texif_log (en->log, EXIF_LOG_CODE_DEBUG, \"ExifMnoteDataOlympus\",\n\t\t\t\"Parsing Nikon maker note v2 (0x%02x, %02x, %02x, \"\n\t\t\t\"%02x, %02x, %02x, %02x, %02x)...\",\n\t\t\tbuf[o2 + 0], buf[o2 + 1], buf[o2 + 2], buf[o2 + 3],\n\t\t\tbuf[o2 + 4], buf[o2 + 5], buf[o2 + 6], buf[o2 + 7]);\n\n\t\t/* Skip version number */\n\t\to2 += 1;\n\n\t\t/* Skip an unknown byte (00 or 0A). */\n\t\to2 += 1;\n\n\t\t/* Skip 2 unknown bytes (00 00). */\n\t\to2 += 2;\n\n\t\t/*\n\t\t * Byte order. From here the data offset\n\t\t * gets calculated.\n\t\t */\n\t\tdatao = o2;\n\t\tif (!strncmp ((char *)&buf[o2], \"II\", 2))\n\t\t\tn->order = EXIF_BYTE_ORDER_INTEL;\n\t\telse if (!strncmp ((char *)&buf[o2], \"MM\", 2))\n\t\t\tn->order = EXIF_BYTE_ORDER_MOTOROLA;\n\t\telse {\n\t\t\texif_log (en->log, EXIF_LOG_CODE_DEBUG,\n\t\t\t\t\"ExifMnoteDataOlympus\", \"Unknown \"\n\t\t\t\t\"byte order '%c%c'\", buf[o2],\n\t\t\t\tbuf[o2 + 1]);\n\t\t\treturn;\n\t\t}\n\t\to2 += 2;\n\n\t\t/* Skip 2 unknown bytes (00 2A). */\n\t\to2 += 2;\n\n\t\t/* Go to where the number of entries is. */\n\t\to2 = datao + exif_get_long (buf + o2, n->order);\n\t\tbreak;\n\n\tcase nikonV0:\n\t\texif_log (en->log, EXIF_LOG_CODE_DEBUG, \"ExifMnoteDataOlympus\",\n\t\t\t\"Parsing Nikon maker note v0 (0x%02x, %02x, %02x, \"\n\t\t\t\"%02x, %02x, %02x, %02x, %02x)...\",\n\t\t\tbuf[o2 + 0], buf[o2 + 1], buf[o2 + 2], buf[o2 + 3], \n\t\t\tbuf[o2 + 4], buf[o2 + 5], buf[o2 + 6], buf[o2 + 7]);\n\t\t/* 00 1b is # of entries in Motorola order - the rest should also be in MM order */\n\t\tn->order = EXIF_BYTE_ORDER_MOTOROLA;\n\t\tbreak;\n\n\tdefault:\n\t\texif_log (en->log, EXIF_LOG_CODE_DEBUG, \"ExifMnoteDataOlympus\",\n\t\t\t\"Unknown Olympus variant %i.\", n->version);\n\t\treturn;\n\t}\n\n\t/* Sanity check the offset */\n\tif (CHECKOVERFLOW(o2,buf_size,2)) {\n\t\texif_log (en->log, EXIF_LOG_CODE_CORRUPT_DATA,\n\t\t\t  \"ExifMnoteOlympus\", \"Short MakerNote\");\n\t\treturn;\n\t}\n\n\t/* Read the number of tags */\n\tc = exif_get_short (buf + o2, n->order);\n\to2 += 2;\n\n\t/* Remove any old entries */\n\texif_mnote_data_olympus_clear (n);\n\n\t/* Reserve enough space for all the possible MakerNote tags */\n\tn->entries = exif_mem_alloc (en->mem, sizeof (MnoteOlympusEntry) * c);\n\tif (!n->entries) {\n\t\tEXIF_LOG_NO_MEMORY(en->log, \"ExifMnoteOlympus\", sizeof (MnoteOlympusEntry) * c);\n\t\treturn;\n\t}\n\n\t/* Parse all c entries, storing ones that are successfully parsed */\n\ttcount = 0;\n\tfor (i = c, o = o2; i; --i, o += 12) {\n\t\tsize_t s;\n\t\tif (CHECKOVERFLOW(o, buf_size, 12)) {\n\t\t\texif_log (en->log, EXIF_LOG_CODE_CORRUPT_DATA,\n\t\t\t\t  \"ExifMnoteOlympus\", \"Short MakerNote\");\n\t\t\tbreak;\n\t\t}\n\n\t    n->entries[tcount].tag        = exif_get_short (buf + o, n->order) + base;\n\t    n->entries[tcount].format     = exif_get_short (buf + o + 2, n->order);\n\t    n->entries[tcount].components = exif_get_long (buf + o + 4, n->order);\n\t    n->entries[tcount].order      = n->order;\n\n\t    exif_log (en->log, EXIF_LOG_CODE_DEBUG, \"ExifMnoteOlympus\",\n\t\t      \"Loading entry 0x%x ('%s')...\", n->entries[tcount].tag,\n\t\t      mnote_olympus_tag_get_name (n->entries[tcount].tag));\n/*\t    exif_log (en->log, EXIF_LOG_CODE_DEBUG, \"ExifMnoteOlympus\",\n\t\t\t    \"0x%x %d %ld*(%d)\",\n\t\t    n->entries[tcount].tag,\n\t\t    n->entries[tcount].format,\n\t\t    n->entries[tcount].components,\n\t\t    (int)exif_format_get_size(n->entries[tcount].format)); */\n\n\t    /* Check if we overflow the multiplication. Use buf_size as the max size for integer overflow detection,\n\t     * we will check the buffer sizes closer later. */\n\t    if (exif_format_get_size (n->entries[tcount].format) &&\n\t\tbuf_size / exif_format_get_size (n->entries[tcount].format) < n->entries[tcount].components\n\t    ) {\n\t\texif_log (en->log, EXIF_LOG_CODE_CORRUPT_DATA, \"ExifMnoteOlympus\", \"Tag size overflow detected (%u * %lu)\", exif_format_get_size (n->entries[tcount].format), n->entries[tcount].components);\n\t\tcontinue;\n\t    }\n\t    /*\n\t     * Size? If bigger than 4 bytes, the actual data is not\n\t     * in the entry but somewhere else (offset).\n\t     */\n\t    s = exif_format_get_size (n->entries[tcount].format) *\n\t\t   \t\t\t n->entries[tcount].components;\n\t\tn->entries[tcount].size = s;\n\t\tif (s) {\n\t\t\tsize_t dataofs = o + 8;\n\t\t\tif (s > 4) {\n\t\t\t\t/* The data in this case is merely a pointer */\n\t\t\t\tdataofs = exif_get_long (buf + dataofs, n->order) + datao;\n#ifdef EXIF_OVERCOME_SANYO_OFFSET_BUG\n\t\t\t\t/* Some Sanyo models (e.g. VPC-C5, C40) suffer from a bug when\n\t\t\t\t * writing the offset for the MNOTE_OLYMPUS_TAG_THUMBNAILIMAGE\n\t\t\t\t * tag in its MakerNote. The offset is actually the absolute\n\t\t\t\t * position in the file instead of the position within the IFD.\n\t\t\t\t */\n\t\t\t    if (dataofs > (buf_size - s) && n->version == sanyoV1) {\n\t\t\t\t\t/* fix pointer */\n\t\t\t\t\tdataofs -= datao + 6;\n\t\t\t\t\texif_log (en->log, EXIF_LOG_CODE_DEBUG,\n\t\t\t\t\t\t  \"ExifMnoteOlympus\",\n\t\t\t\t\t\t  \"Inconsistent thumbnail tag offset; attempting to recover\");\n\t\t\t    }\n#endif\n\t\t\t}\n\t\t\tif (CHECKOVERFLOW(dataofs, buf_size, s)) {\n\t\t\t\texif_log (en->log, EXIF_LOG_CODE_DEBUG,\n\t\t\t\t\t  \"ExifMnoteOlympus\",\n\t\t\t\t\t  \"Tag data past end of buffer (%u > %u)\",\n\t\t\t\t\t  (unsigned)(dataofs + s), buf_size);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tn->entries[tcount].data = exif_mem_alloc (en->mem, s);\n\t\t\tif (!n->entries[tcount].data) {\n\t\t\t\tEXIF_LOG_NO_MEMORY(en->log, \"ExifMnoteOlympus\", s);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tmemcpy (n->entries[tcount].data, buf + dataofs, s);\n\t\t}\n\n\t\t/* Tag was successfully parsed */\n\t\t++tcount;\n\t}\n\t/* Store the count of successfully parsed tags */\n\tn->count = tcount;\n}",
        "func": "static void\nexif_mnote_data_olympus_load (ExifMnoteData *en,\n\t\t\t      const unsigned char *buf, unsigned int buf_size)\n{\n\tExifMnoteDataOlympus *n = (ExifMnoteDataOlympus *) en;\n\tExifShort c;\n\tsize_t i, tcount, o, o2, datao = 6, base = 0;\n\n\tif (!n || !buf || !buf_size) {\n\t\texif_log (en->log, EXIF_LOG_CODE_CORRUPT_DATA,\n\t\t\t  \"ExifMnoteDataOlympus\", \"Short MakerNote\");\n\t\treturn;\n\t}\n\to2 = 6 + n->offset; /* Start of interesting data */\n\tif (CHECKOVERFLOW(o2,buf_size,10)) {\n\t\texif_log (en->log, EXIF_LOG_CODE_CORRUPT_DATA,\n\t\t\t  \"ExifMnoteDataOlympus\", \"Short MakerNote\");\n\t\treturn;\n\t}\n\n\t/*\n\t * Olympus headers start with \"OLYMP\" and need to have at least\n\t * a size of 22 bytes (6 for 'OLYMP', 2 other bytes, 2 for the\n\t * number of entries, and 12 for one entry.\n\t *\n\t * Sanyo format is identical and uses identical tags except that\n\t * header starts with \"SANYO\".\n\t *\n\t * Epson format is identical and uses identical tags except that\n\t * header starts with \"EPSON\".\n\t *\n\t * Nikon headers start with \"Nikon\" (6 bytes including '\\0'), \n\t * version number (1 or 2).\n\t * \n\t * Version 1 continues with 0, 1, 0, number_of_tags,\n\t * or just with number_of_tags (models D1H, D1X...).\n\t * \n\t * Version 2 continues with an unknown byte (0 or 10),\n\t * two unknown bytes (0), \"MM\" or \"II\", another byte 0 and \n\t * lastly 0x2A.\n\t */\n\tn->version = exif_mnote_data_olympus_identify_variant(buf+o2, buf_size-o2);\n\tswitch (n->version) {\n\tcase olympusV1:\n\tcase sanyoV1:\n\tcase epsonV1:\n\t\texif_log (en->log, EXIF_LOG_CODE_DEBUG, \"ExifMnoteDataOlympus\",\n\t\t\t\"Parsing Olympus/Sanyo/Epson maker note v1...\");\n\n\t\t/* The number of entries is at position 8. */\n\t\tif (buf[o2 + 6] == 1)\n\t\t\tn->order = EXIF_BYTE_ORDER_INTEL;\n\t\telse if (buf[o2 + 6 + 1] == 1)\n\t\t\tn->order = EXIF_BYTE_ORDER_MOTOROLA;\n\t\to2 += 8;\n\t\tc = exif_get_short (buf + o2, n->order);\n\t\tif ((!(c & 0xFF)) && (c > 0x500)) {\n\t\t\tif (n->order == EXIF_BYTE_ORDER_INTEL) {\n\t\t\t\tn->order = EXIF_BYTE_ORDER_MOTOROLA;\n\t\t\t} else {\n\t\t\t\tn->order = EXIF_BYTE_ORDER_INTEL;\n\t\t\t}\n\t\t}\n\t\tbreak;\n\n\tcase olympusV2:\n\t\t/* Olympus S760, S770 */\n\t\tdatao = o2;\n\t\to2 += 8;\n\t\tif (CHECKOVERFLOW(o2,buf_size,4)) return;\n\t\texif_log (en->log, EXIF_LOG_CODE_DEBUG, \"ExifMnoteDataOlympus\",\n\t\t\t\"Parsing Olympus maker note v2 (0x%02x, %02x, %02x, %02x)...\",\n\t\t\tbuf[o2 + 0], buf[o2 + 1], buf[o2 + 2], buf[o2 + 3]);\n\n\t\tif ((buf[o2] == 'I') && (buf[o2 + 1] == 'I'))\n\t\t\tn->order = EXIF_BYTE_ORDER_INTEL;\n\t\telse if ((buf[o2] == 'M') && (buf[o2 + 1] == 'M'))\n\t\t\tn->order = EXIF_BYTE_ORDER_MOTOROLA;\n\n\t\t/* The number of entries is at position 8+4. */\n\t\to2 += 4;\n\t\tbreak;\n\n\tcase nikonV1:\n\t\to2 += 6;\n\t\texif_log (en->log, EXIF_LOG_CODE_DEBUG, \"ExifMnoteDataOlympus\",\n\t\t\t\"Parsing Nikon maker note v1 (0x%02x, %02x, %02x, \"\n\t\t\t\"%02x)...\",\n\t\t\tbuf[o2 + 0], buf[o2 + 1], buf[o2 + 2], buf[o2 + 3]);\n\n\t\t/* Skip version number */\n\t\to2 += 1;\n\n\t\t/* Skip an unknown byte (00 or 0A). */\n\t\to2 += 1;\n\n\t\tbase = MNOTE_NIKON1_TAG_BASE;\n\t\t/* Fix endianness, if needed */\n\t\tc = exif_get_short (buf + o2, n->order);\n\t\tif ((!(c & 0xFF)) && (c > 0x500)) {\n\t\t\tif (n->order == EXIF_BYTE_ORDER_INTEL) {\n\t\t\t\tn->order = EXIF_BYTE_ORDER_MOTOROLA;\n\t\t\t} else {\n\t\t\t\tn->order = EXIF_BYTE_ORDER_INTEL;\n\t\t\t}\n\t\t}\n\t\tbreak;\n\n\tcase nikonV2:\n\t\to2 += 6;\n\t\tif (CHECKOVERFLOW(o2,buf_size,12)) return;\n\t\texif_log (en->log, EXIF_LOG_CODE_DEBUG, \"ExifMnoteDataOlympus\",\n\t\t\t\"Parsing Nikon maker note v2 (0x%02x, %02x, %02x, \"\n\t\t\t\"%02x, %02x, %02x, %02x, %02x)...\",\n\t\t\tbuf[o2 + 0], buf[o2 + 1], buf[o2 + 2], buf[o2 + 3],\n\t\t\tbuf[o2 + 4], buf[o2 + 5], buf[o2 + 6], buf[o2 + 7]);\n\n\t\t/* Skip version number */\n\t\to2 += 1;\n\n\t\t/* Skip an unknown byte (00 or 0A). */\n\t\to2 += 1;\n\n\t\t/* Skip 2 unknown bytes (00 00). */\n\t\to2 += 2;\n\n\t\t/*\n\t\t * Byte order. From here the data offset\n\t\t * gets calculated.\n\t\t */\n\t\tdatao = o2;\n\t\tif (!strncmp ((char *)&buf[o2], \"II\", 2))\n\t\t\tn->order = EXIF_BYTE_ORDER_INTEL;\n\t\telse if (!strncmp ((char *)&buf[o2], \"MM\", 2))\n\t\t\tn->order = EXIF_BYTE_ORDER_MOTOROLA;\n\t\telse {\n\t\t\texif_log (en->log, EXIF_LOG_CODE_DEBUG,\n\t\t\t\t\"ExifMnoteDataOlympus\", \"Unknown \"\n\t\t\t\t\"byte order '%c%c'\", buf[o2],\n\t\t\t\tbuf[o2 + 1]);\n\t\t\treturn;\n\t\t}\n\t\to2 += 2;\n\n\t\t/* Skip 2 unknown bytes (00 2A). */\n\t\to2 += 2;\n\n\t\t/* Go to where the number of entries is. */\n\t\to2 = datao + exif_get_long (buf + o2, n->order);\n\t\tbreak;\n\n\tcase nikonV0:\n\t\texif_log (en->log, EXIF_LOG_CODE_DEBUG, \"ExifMnoteDataOlympus\",\n\t\t\t\"Parsing Nikon maker note v0 (0x%02x, %02x, %02x, \"\n\t\t\t\"%02x, %02x, %02x, %02x, %02x)...\",\n\t\t\tbuf[o2 + 0], buf[o2 + 1], buf[o2 + 2], buf[o2 + 3], \n\t\t\tbuf[o2 + 4], buf[o2 + 5], buf[o2 + 6], buf[o2 + 7]);\n\t\t/* 00 1b is # of entries in Motorola order - the rest should also be in MM order */\n\t\tn->order = EXIF_BYTE_ORDER_MOTOROLA;\n\t\tbreak;\n\n\tdefault:\n\t\texif_log (en->log, EXIF_LOG_CODE_DEBUG, \"ExifMnoteDataOlympus\",\n\t\t\t\"Unknown Olympus variant %i.\", n->version);\n\t\treturn;\n\t}\n\n\t/* Sanity check the offset */\n\tif (CHECKOVERFLOW(o2,buf_size,2)) {\n\t\texif_log (en->log, EXIF_LOG_CODE_CORRUPT_DATA,\n\t\t\t  \"ExifMnoteOlympus\", \"Short MakerNote\");\n\t\treturn;\n\t}\n\n\t/* Read the number of tags */\n\tc = exif_get_short (buf + o2, n->order);\n\to2 += 2;\n\n\t/* Remove any old entries */\n\texif_mnote_data_olympus_clear (n);\n\n\t/* Reserve enough space for all the possible MakerNote tags */\n\tn->entries = exif_mem_alloc (en->mem, sizeof (MnoteOlympusEntry) * c);\n\tif (!n->entries) {\n\t\tEXIF_LOG_NO_MEMORY(en->log, \"ExifMnoteOlympus\", sizeof (MnoteOlympusEntry) * c);\n\t\treturn;\n\t}\n\n\t/* Parse all c entries, storing ones that are successfully parsed */\n\ttcount = 0;\n\tfor (i = c, o = o2; i; --i, o += 12) {\n\t\tsize_t s;\n\t\tmemset(&n->entries[tcount], 0, sizeof(MnoteOlympusEntry));\n\t\tif (CHECKOVERFLOW(o, buf_size, 12)) {\n\t\t\texif_log (en->log, EXIF_LOG_CODE_CORRUPT_DATA,\n\t\t\t\t  \"ExifMnoteOlympus\", \"Short MakerNote\");\n\t\t\tbreak;\n\t\t}\n\n\t    n->entries[tcount].tag        = exif_get_short (buf + o, n->order) + base;\n\t    n->entries[tcount].format     = exif_get_short (buf + o + 2, n->order);\n\t    n->entries[tcount].components = exif_get_long (buf + o + 4, n->order);\n\t    n->entries[tcount].order      = n->order;\n\n\t    exif_log (en->log, EXIF_LOG_CODE_DEBUG, \"ExifMnoteOlympus\",\n\t\t      \"Loading entry 0x%x ('%s')...\", n->entries[tcount].tag,\n\t\t      mnote_olympus_tag_get_name (n->entries[tcount].tag));\n/*\t    exif_log (en->log, EXIF_LOG_CODE_DEBUG, \"ExifMnoteOlympus\",\n\t\t\t    \"0x%x %d %ld*(%d)\",\n\t\t    n->entries[tcount].tag,\n\t\t    n->entries[tcount].format,\n\t\t    n->entries[tcount].components,\n\t\t    (int)exif_format_get_size(n->entries[tcount].format)); */\n\n\t    /* Check if we overflow the multiplication. Use buf_size as the max size for integer overflow detection,\n\t     * we will check the buffer sizes closer later. */\n\t    if (exif_format_get_size (n->entries[tcount].format) &&\n\t\tbuf_size / exif_format_get_size (n->entries[tcount].format) < n->entries[tcount].components\n\t    ) {\n\t\texif_log (en->log, EXIF_LOG_CODE_CORRUPT_DATA, \"ExifMnoteOlympus\", \"Tag size overflow detected (%u * %lu)\", exif_format_get_size (n->entries[tcount].format), n->entries[tcount].components);\n\t\tcontinue;\n\t    }\n\t    /*\n\t     * Size? If bigger than 4 bytes, the actual data is not\n\t     * in the entry but somewhere else (offset).\n\t     */\n\t    s = exif_format_get_size (n->entries[tcount].format) *\n\t\t   \t\t\t n->entries[tcount].components;\n\t\tn->entries[tcount].size = s;\n\t\tif (s) {\n\t\t\tsize_t dataofs = o + 8;\n\t\t\tif (s > 4) {\n\t\t\t\t/* The data in this case is merely a pointer */\n\t\t\t\tdataofs = exif_get_long (buf + dataofs, n->order) + datao;\n#ifdef EXIF_OVERCOME_SANYO_OFFSET_BUG\n\t\t\t\t/* Some Sanyo models (e.g. VPC-C5, C40) suffer from a bug when\n\t\t\t\t * writing the offset for the MNOTE_OLYMPUS_TAG_THUMBNAILIMAGE\n\t\t\t\t * tag in its MakerNote. The offset is actually the absolute\n\t\t\t\t * position in the file instead of the position within the IFD.\n\t\t\t\t */\n\t\t\t    if (dataofs > (buf_size - s) && n->version == sanyoV1) {\n\t\t\t\t\t/* fix pointer */\n\t\t\t\t\tdataofs -= datao + 6;\n\t\t\t\t\texif_log (en->log, EXIF_LOG_CODE_DEBUG,\n\t\t\t\t\t\t  \"ExifMnoteOlympus\",\n\t\t\t\t\t\t  \"Inconsistent thumbnail tag offset; attempting to recover\");\n\t\t\t    }\n#endif\n\t\t\t}\n\t\t\tif (CHECKOVERFLOW(dataofs, buf_size, s)) {\n\t\t\t\texif_log (en->log, EXIF_LOG_CODE_DEBUG,\n\t\t\t\t\t  \"ExifMnoteOlympus\",\n\t\t\t\t\t  \"Tag data past end of buffer (%u > %u)\",\n\t\t\t\t\t  (unsigned)(dataofs + s), buf_size);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tn->entries[tcount].data = exif_mem_alloc (en->mem, s);\n\t\t\tif (!n->entries[tcount].data) {\n\t\t\t\tEXIF_LOG_NO_MEMORY(en->log, \"ExifMnoteOlympus\", s);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tmemcpy (n->entries[tcount].data, buf + dataofs, s);\n\t\t}\n\n\t\t/* Tag was successfully parsed */\n\t\t++tcount;\n\t}\n\t/* Store the count of successfully parsed tags */\n\tn->count = tcount;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -190,6 +190,7 @@\n \ttcount = 0;\n \tfor (i = c, o = o2; i; --i, o += 12) {\n \t\tsize_t s;\n+\t\tmemset(&n->entries[tcount], 0, sizeof(MnoteOlympusEntry));\n \t\tif (CHECKOVERFLOW(o, buf_size, 12)) {\n \t\t\texif_log (en->log, EXIF_LOG_CODE_CORRUPT_DATA,\n \t\t\t\t  \"ExifMnoteOlympus\", \"Short MakerNote\");",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t\tmemset(&n->entries[tcount], 0, sizeof(MnoteOlympusEntry));"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-13113",
        "func_name": "libexif/exif_mnote_data_canon_load",
        "description": "An issue was discovered in libexif before 0.6.22. Use of uninitialized memory in EXIF Makernote handling could lead to crashes and potential use-after-free conditions.",
        "git_url": "https://github.com/libexif/libexif/commit/ec412aa4583ad71ecabb967d3c77162760169d1f",
        "commit_title": "Ensure the MakerNote data pointers are initialized with NULL.",
        "commit_text": " This ensures that an uninitialized pointer isn't dereferenced later in the case where the number of components (and therefore size) is 0.  This fixes the second issue reported at https://sourceforge.net/p/libexif/bugs/125/  CVE-2020-13113",
        "func_before": "static void\nexif_mnote_data_canon_load (ExifMnoteData *ne,\n\tconst unsigned char *buf, unsigned int buf_size)\n{\n\tExifMnoteDataCanon *n = (ExifMnoteDataCanon *) ne;\n\tExifShort c;\n\tsize_t i, tcount, o, datao;\n\n\tif (!n || !buf || !buf_size) {\n\t\texif_log (ne->log, EXIF_LOG_CODE_CORRUPT_DATA,\n\t\t\t  \"ExifMnoteCanon\", \"Short MakerNote\");\n\t\treturn;\n\t}\n\tdatao = 6 + n->offset;\n\tif (CHECKOVERFLOW(datao, buf_size, 2)) {\n\t\texif_log (ne->log, EXIF_LOG_CODE_CORRUPT_DATA,\n\t\t\t  \"ExifMnoteCanon\", \"Short MakerNote\");\n\t\treturn;\n\t}\n\n\t/* Read the number of tags */\n\tc = exif_get_short (buf + datao, n->order);\n\tdatao += 2;\n\n\t/* Remove any old entries */\n\texif_mnote_data_canon_clear (n);\n\n\t/* Reserve enough space for all the possible MakerNote tags */\n\tn->entries = exif_mem_alloc (ne->mem, sizeof (MnoteCanonEntry) * c);\n\tif (!n->entries) {\n\t\tEXIF_LOG_NO_MEMORY(ne->log, \"ExifMnoteCanon\", sizeof (MnoteCanonEntry) * c);\n\t\treturn;\n\t}\n\n\t/* Parse the entries */\n\ttcount = 0;\n\tfor (i = c, o = datao; i; --i, o += 12) {\n\t\tsize_t s;\n\n\t\tif (CHECKOVERFLOW(o,buf_size,12)) {\n\t\t\texif_log (ne->log, EXIF_LOG_CODE_CORRUPT_DATA,\n\t\t\t\t\"ExifMnoteCanon\", \"Short MakerNote\");\n\t\t\tbreak;\n\t\t}\n\n\t\tn->entries[tcount].tag        = exif_get_short (buf + o, n->order);\n\t\tn->entries[tcount].format     = exif_get_short (buf + o + 2, n->order);\n\t\tn->entries[tcount].components = exif_get_long (buf + o + 4, n->order);\n\t\tn->entries[tcount].order      = n->order;\n\n\t\texif_log (ne->log, EXIF_LOG_CODE_DEBUG, \"ExifMnoteCanon\",\n\t\t\t\"Loading entry 0x%x ('%s')...\", n->entries[tcount].tag,\n\t\t\t mnote_canon_tag_get_name (n->entries[tcount].tag));\n\n\t\t/* Check if we overflow the multiplication. Use buf_size as the max size for integer overflow detection,\n\t\t * we will check the buffer sizes closer later. */\n\t\tif (\texif_format_get_size (n->entries[tcount].format) &&\n\t\t\tbuf_size / exif_format_get_size (n->entries[tcount].format) < n->entries[tcount].components\n\t\t) {\n\t\t\texif_log (ne->log, EXIF_LOG_CODE_CORRUPT_DATA,\n\t\t\t\t  \"ExifMnoteCanon\", \"Tag size overflow detected (%u * %lu)\", exif_format_get_size (n->entries[tcount].format), n->entries[tcount].components);\n\t\t\tcontinue;\n\t\t}\n\n\t\t/*\n\t\t * Size? If bigger than 4 bytes, the actual data is not\n\t\t * in the entry but somewhere else (offset).\n\t\t */\n\t\ts = exif_format_get_size (n->entries[tcount].format) * \n\t\t\t\t\t\t\t\t  n->entries[tcount].components;\n\t\tn->entries[tcount].size = s;\n\t\tif (!s) {\n\t\t\texif_log (ne->log, EXIF_LOG_CODE_CORRUPT_DATA,\n\t\t\t\t  \"ExifMnoteCanon\",\n\t\t\t\t  \"Invalid zero-length tag size\");\n\t\t\tcontinue;\n\n\t\t} else {\n\t\t\tsize_t dataofs = o + 8;\n\t\t\tif (s > 4) dataofs = exif_get_long (buf + dataofs, n->order) + 6;\n\n\t\t\tif (CHECKOVERFLOW(dataofs, buf_size, s)) {\n\t\t\t\texif_log (ne->log, EXIF_LOG_CODE_DEBUG,\n\t\t\t\t\t\"ExifMnoteCanon\",\n\t\t\t\t\t\"Tag data past end of buffer (%u > %u)\",\n\t\t\t\t\t(unsigned)(dataofs + s), buf_size);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tn->entries[tcount].data = exif_mem_alloc (ne->mem, s);\n\t\t\tif (!n->entries[tcount].data) {\n\t\t\t\tEXIF_LOG_NO_MEMORY(ne->log, \"ExifMnoteCanon\", s);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tmemcpy (n->entries[tcount].data, buf + dataofs, s);\n\t\t}\n\n\t\t/* Tag was successfully parsed */\n\t\t++tcount;\n\t}\n\t/* Store the count of successfully parsed tags */\n\tn->count = tcount;\n}",
        "func": "static void\nexif_mnote_data_canon_load (ExifMnoteData *ne,\n\tconst unsigned char *buf, unsigned int buf_size)\n{\n\tExifMnoteDataCanon *n = (ExifMnoteDataCanon *) ne;\n\tExifShort c;\n\tsize_t i, tcount, o, datao;\n\n\tif (!n || !buf || !buf_size) {\n\t\texif_log (ne->log, EXIF_LOG_CODE_CORRUPT_DATA,\n\t\t\t  \"ExifMnoteCanon\", \"Short MakerNote\");\n\t\treturn;\n\t}\n\tdatao = 6 + n->offset;\n\tif (CHECKOVERFLOW(datao, buf_size, 2)) {\n\t\texif_log (ne->log, EXIF_LOG_CODE_CORRUPT_DATA,\n\t\t\t  \"ExifMnoteCanon\", \"Short MakerNote\");\n\t\treturn;\n\t}\n\n\t/* Read the number of tags */\n\tc = exif_get_short (buf + datao, n->order);\n\tdatao += 2;\n\n\t/* Remove any old entries */\n\texif_mnote_data_canon_clear (n);\n\n\t/* Reserve enough space for all the possible MakerNote tags */\n\tn->entries = exif_mem_alloc (ne->mem, sizeof (MnoteCanonEntry) * c);\n\tif (!n->entries) {\n\t\tEXIF_LOG_NO_MEMORY(ne->log, \"ExifMnoteCanon\", sizeof (MnoteCanonEntry) * c);\n\t\treturn;\n\t}\n\n\t/* Parse the entries */\n\ttcount = 0;\n\tfor (i = c, o = datao; i; --i, o += 12) {\n\t\tsize_t s;\n\n\t\tmemset(&n->entries[tcount], 0, sizeof(MnoteCanonEntry));\n\t\tif (CHECKOVERFLOW(o,buf_size,12)) {\n\t\t\texif_log (ne->log, EXIF_LOG_CODE_CORRUPT_DATA,\n\t\t\t\t\"ExifMnoteCanon\", \"Short MakerNote\");\n\t\t\tbreak;\n\t\t}\n\n\t\tn->entries[tcount].tag        = exif_get_short (buf + o, n->order);\n\t\tn->entries[tcount].format     = exif_get_short (buf + o + 2, n->order);\n\t\tn->entries[tcount].components = exif_get_long (buf + o + 4, n->order);\n\t\tn->entries[tcount].order      = n->order;\n\n\t\texif_log (ne->log, EXIF_LOG_CODE_DEBUG, \"ExifMnoteCanon\",\n\t\t\t\"Loading entry 0x%x ('%s')...\", n->entries[tcount].tag,\n\t\t\t mnote_canon_tag_get_name (n->entries[tcount].tag));\n\n\t\t/* Check if we overflow the multiplication. Use buf_size as the max size for integer overflow detection,\n\t\t * we will check the buffer sizes closer later. */\n\t\tif (\texif_format_get_size (n->entries[tcount].format) &&\n\t\t\tbuf_size / exif_format_get_size (n->entries[tcount].format) < n->entries[tcount].components\n\t\t) {\n\t\t\texif_log (ne->log, EXIF_LOG_CODE_CORRUPT_DATA,\n\t\t\t\t  \"ExifMnoteCanon\", \"Tag size overflow detected (%u * %lu)\", exif_format_get_size (n->entries[tcount].format), n->entries[tcount].components);\n\t\t\tcontinue;\n\t\t}\n\n\t\t/*\n\t\t * Size? If bigger than 4 bytes, the actual data is not\n\t\t * in the entry but somewhere else (offset).\n\t\t */\n\t\ts = exif_format_get_size (n->entries[tcount].format) * \n\t\t\t\t\t\t\t\t  n->entries[tcount].components;\n\t\tn->entries[tcount].size = s;\n\t\tif (!s) {\n\t\t\texif_log (ne->log, EXIF_LOG_CODE_CORRUPT_DATA,\n\t\t\t\t  \"ExifMnoteCanon\",\n\t\t\t\t  \"Invalid zero-length tag size\");\n\t\t\tcontinue;\n\n\t\t} else {\n\t\t\tsize_t dataofs = o + 8;\n\t\t\tif (s > 4) dataofs = exif_get_long (buf + dataofs, n->order) + 6;\n\n\t\t\tif (CHECKOVERFLOW(dataofs, buf_size, s)) {\n\t\t\t\texif_log (ne->log, EXIF_LOG_CODE_DEBUG,\n\t\t\t\t\t\"ExifMnoteCanon\",\n\t\t\t\t\t\"Tag data past end of buffer (%u > %u)\",\n\t\t\t\t\t(unsigned)(dataofs + s), buf_size);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tn->entries[tcount].data = exif_mem_alloc (ne->mem, s);\n\t\t\tif (!n->entries[tcount].data) {\n\t\t\t\tEXIF_LOG_NO_MEMORY(ne->log, \"ExifMnoteCanon\", s);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tmemcpy (n->entries[tcount].data, buf + dataofs, s);\n\t\t}\n\n\t\t/* Tag was successfully parsed */\n\t\t++tcount;\n\t}\n\t/* Store the count of successfully parsed tags */\n\tn->count = tcount;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -37,6 +37,7 @@\n \tfor (i = c, o = datao; i; --i, o += 12) {\n \t\tsize_t s;\n \n+\t\tmemset(&n->entries[tcount], 0, sizeof(MnoteCanonEntry));\n \t\tif (CHECKOVERFLOW(o,buf_size,12)) {\n \t\t\texif_log (ne->log, EXIF_LOG_CODE_CORRUPT_DATA,\n \t\t\t\t\"ExifMnoteCanon\", \"Short MakerNote\");",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t\tmemset(&n->entries[tcount], 0, sizeof(MnoteCanonEntry));"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-10732",
        "func_name": "torvalds/linux/fill_thread_core_info",
        "description": "A flaw was found in the Linux kernel's implementation of Userspace core dumps. This flaw allows an attacker with a local account to crash a trivial program and exfiltrate private kernel data.",
        "git_url": "https://git.kernel.org/pub/scm/linux/kernel/git/next/linux-next.git/commit/?h=aca969cacf07f41070d788ce2b8ca71f09d5207d",
        "commit_title": "KMSAN reported uninitialized data being written to disk when dumping core.",
        "commit_text": "As a result, several kilobytes of kmalloc memory may be written to the core file and then read by a non-privileged user.  Link: http://lkml.kernel.org/r/20200419100848.63472-1-glider@google.com Link: https://github.com/google/kmsan/issues/76 Cc: Alexey Dobriyan <adobriyan@gmail.com> Cc: <stable@vger.kernel.org> ",
        "func_before": "static int fill_thread_core_info(struct elf_thread_core_info *t,\n\t\t\t\t const struct user_regset_view *view,\n\t\t\t\t long signr, size_t *total)\n{\n\tunsigned int i;\n\tunsigned int regset0_size = regset_size(t->task, &view->regsets[0]);\n\n\t/*\n\t * NT_PRSTATUS is the one special case, because the regset data\n\t * goes into the pr_reg field inside the note contents, rather\n\t * than being the whole note contents.  We fill the reset in here.\n\t * We assume that regset 0 is NT_PRSTATUS.\n\t */\n\tfill_prstatus(&t->prstatus, t->task, signr);\n\t(void) view->regsets[0].get(t->task, &view->regsets[0], 0, regset0_size,\n\t\t\t\t    &t->prstatus.pr_reg, NULL);\n\n\tfill_note(&t->notes[0], \"CORE\", NT_PRSTATUS,\n\t\t  PRSTATUS_SIZE(t->prstatus, regset0_size), &t->prstatus);\n\t*total += notesize(&t->notes[0]);\n\n\tdo_thread_regset_writeback(t->task, &view->regsets[0]);\n\n\t/*\n\t * Each other regset might generate a note too.  For each regset\n\t * that has no core_note_type or is inactive, we leave t->notes[i]\n\t * all zero and we'll know to skip writing it later.\n\t */\n\tfor (i = 1; i < view->n; ++i) {\n\t\tconst struct user_regset *regset = &view->regsets[i];\n\t\tdo_thread_regset_writeback(t->task, regset);\n\t\tif (regset->core_note_type && regset->get &&\n\t\t    (!regset->active || regset->active(t->task, regset) > 0)) {\n\t\t\tint ret;\n\t\t\tsize_t size = regset_size(t->task, regset);\n\t\t\tvoid *data = kmalloc(size, GFP_KERNEL);\n\t\t\tif (unlikely(!data))\n\t\t\t\treturn 0;\n\t\t\tret = regset->get(t->task, regset,\n\t\t\t\t\t  0, size, data, NULL);\n\t\t\tif (unlikely(ret))\n\t\t\t\tkfree(data);\n\t\t\telse {\n\t\t\t\tif (regset->core_note_type != NT_PRFPREG)\n\t\t\t\t\tfill_note(&t->notes[i], \"LINUX\",\n\t\t\t\t\t\t  regset->core_note_type,\n\t\t\t\t\t\t  size, data);\n\t\t\t\telse {\n\t\t\t\t\tSET_PR_FPVALID(&t->prstatus,\n\t\t\t\t\t\t\t1, regset0_size);\n\t\t\t\t\tfill_note(&t->notes[i], \"CORE\",\n\t\t\t\t\t\t  NT_PRFPREG, size, data);\n\t\t\t\t}\n\t\t\t\t*total += notesize(&t->notes[i]);\n\t\t\t}\n\t\t}\n\t}\n\n\treturn 1;\n}",
        "func": "static int fill_thread_core_info(struct elf_thread_core_info *t,\n\t\t\t\t const struct user_regset_view *view,\n\t\t\t\t long signr, size_t *total)\n{\n\tunsigned int i;\n\tunsigned int regset0_size = regset_size(t->task, &view->regsets[0]);\n\n\t/*\n\t * NT_PRSTATUS is the one special case, because the regset data\n\t * goes into the pr_reg field inside the note contents, rather\n\t * than being the whole note contents.  We fill the reset in here.\n\t * We assume that regset 0 is NT_PRSTATUS.\n\t */\n\tfill_prstatus(&t->prstatus, t->task, signr);\n\t(void) view->regsets[0].get(t->task, &view->regsets[0], 0, regset0_size,\n\t\t\t\t    &t->prstatus.pr_reg, NULL);\n\n\tfill_note(&t->notes[0], \"CORE\", NT_PRSTATUS,\n\t\t  PRSTATUS_SIZE(t->prstatus, regset0_size), &t->prstatus);\n\t*total += notesize(&t->notes[0]);\n\n\tdo_thread_regset_writeback(t->task, &view->regsets[0]);\n\n\t/*\n\t * Each other regset might generate a note too.  For each regset\n\t * that has no core_note_type or is inactive, we leave t->notes[i]\n\t * all zero and we'll know to skip writing it later.\n\t */\n\tfor (i = 1; i < view->n; ++i) {\n\t\tconst struct user_regset *regset = &view->regsets[i];\n\t\tdo_thread_regset_writeback(t->task, regset);\n\t\tif (regset->core_note_type && regset->get &&\n\t\t    (!regset->active || regset->active(t->task, regset) > 0)) {\n\t\t\tint ret;\n\t\t\tsize_t size = regset_size(t->task, regset);\n\t\t\tvoid *data = kzalloc(size, GFP_KERNEL);\n\t\t\tif (unlikely(!data))\n\t\t\t\treturn 0;\n\t\t\tret = regset->get(t->task, regset,\n\t\t\t\t\t  0, size, data, NULL);\n\t\t\tif (unlikely(ret))\n\t\t\t\tkfree(data);\n\t\t\telse {\n\t\t\t\tif (regset->core_note_type != NT_PRFPREG)\n\t\t\t\t\tfill_note(&t->notes[i], \"LINUX\",\n\t\t\t\t\t\t  regset->core_note_type,\n\t\t\t\t\t\t  size, data);\n\t\t\t\telse {\n\t\t\t\t\tSET_PR_FPVALID(&t->prstatus,\n\t\t\t\t\t\t\t1, regset0_size);\n\t\t\t\t\tfill_note(&t->notes[i], \"CORE\",\n\t\t\t\t\t\t  NT_PRFPREG, size, data);\n\t\t\t\t}\n\t\t\t\t*total += notesize(&t->notes[i]);\n\t\t\t}\n\t\t}\n\t}\n\n\treturn 1;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -33,7 +33,7 @@\n \t\t    (!regset->active || regset->active(t->task, regset) > 0)) {\n \t\t\tint ret;\n \t\t\tsize_t size = regset_size(t->task, regset);\n-\t\t\tvoid *data = kmalloc(size, GFP_KERNEL);\n+\t\t\tvoid *data = kzalloc(size, GFP_KERNEL);\n \t\t\tif (unlikely(!data))\n \t\t\t\treturn 0;\n \t\t\tret = regset->get(t->task, regset,",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\tvoid *data = kmalloc(size, GFP_KERNEL);"
            ],
            "added_lines": [
                "\t\t\tvoid *data = kzalloc(size, GFP_KERNEL);"
            ]
        }
    }
]