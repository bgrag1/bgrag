[
    {
        "cve_id": "CVE-2019-13272",
        "func_name": "torvalds/linux/ptrace_link",
        "description": "In the Linux kernel before 5.1.17, ptrace_link in kernel/ptrace.c mishandles the recording of the credentials of a process that wants to create a ptrace relationship, which allows local users to obtain root access by leveraging certain scenarios with a parent-child process relationship, where a parent drops privileges and calls execve (potentially allowing control by an attacker). One contributing factor is an object lifetime issue (which can also cause a panic). Another contributing factor is incorrect marking of a ptrace relationship as privileged, which is exploitable through (for example) Polkit's pkexec helper with PTRACE_TRACEME. NOTE: SELinux deny_ptrace might be a usable workaround in some environments.",
        "git_url": "https://github.com/torvalds/linux/commit/6994eefb0053799d2e07cd140df6c2ea106c41ee",
        "commit_title": "ptrace: Fix ->ptracer_cred handling for PTRACE_TRACEME",
        "commit_text": " Fix two issues:  When called for PTRACE_TRACEME, ptrace_link() would obtain an RCU reference to the parent's objective credentials, then give that pointer to get_cred().  However, the object lifetime rules for things like struct cred do not permit unconditionally turning an RCU reference into a stable reference.  PTRACE_TRACEME records the parent's credentials as if the parent was acting as the subject, but that's not the case.  If a malicious unprivileged child uses PTRACE_TRACEME and the parent is privileged, and at a later point, the parent process becomes attacker-controlled (because it drops privileges and calls execve()), the attacker ends up with control over two processes with a privileged ptrace relationship, which can be abused to ptrace a suid binary and obtain root privileges.  Fix both of these by always recording the credentials of the process that is requesting the creation of the ptrace relationship: current_cred() can't change under us, and current is the proper subject for access control.  This change is theoretically userspace-visible, but I am not aware of any code that it will actually break.  Cc: stable@vger.kernel.org",
        "func_before": "static void ptrace_link(struct task_struct *child, struct task_struct *new_parent)\n{\n\trcu_read_lock();\n\t__ptrace_link(child, new_parent, __task_cred(new_parent));\n\trcu_read_unlock();\n}",
        "func": "static void ptrace_link(struct task_struct *child, struct task_struct *new_parent)\n{\n\t__ptrace_link(child, new_parent, current_cred());\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,4 @@\n static void ptrace_link(struct task_struct *child, struct task_struct *new_parent)\n {\n-\trcu_read_lock();\n-\t__ptrace_link(child, new_parent, __task_cred(new_parent));\n-\trcu_read_unlock();\n+\t__ptrace_link(child, new_parent, current_cred());\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\trcu_read_lock();",
                "\t__ptrace_link(child, new_parent, __task_cred(new_parent));",
                "\trcu_read_unlock();"
            ],
            "added_lines": [
                "\t__ptrace_link(child, new_parent, current_cred());"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-15901",
        "func_name": "slicer69/doas/main",
        "description": "An issue was discovered in slicer69 doas before 6.2 on certain platforms other than OpenBSD. A setusercontext(3) call with flags to change the UID, primary GID, and secondary GIDs was replaced (on certain platforms: Linux and possibly NetBSD) with a single setuid(2) call. This resulted in neither changing the group id nor initializing secondary group ids.",
        "git_url": "https://github.com/slicer69/doas/commit/6cf0236184ff6304bf5e267ccf7ef02874069697",
        "commit_title": "fix the setusercontext(3) workaround",
        "commit_text": " Seeing this being used on even more system like Illumos with this ugly and security critical bug open makes me cringe every time I check if it was finally fixed.  I reported it directly to the maintainer in 2017. I reported it to pkgsrc-security@netbsd.org without a response.",
        "func_before": "int\nmain(int argc, char **argv)\n{\n\tconst char *safepath = SAFE_PATH;\n\tconst char *confpath = NULL;\n\tchar *shargv[] = { NULL, NULL };\n\tchar *sh;\n\tconst char *cmd;\n\tchar cmdline[LINE_MAX];\n\tchar myname[_PW_NAME_LEN + 1];\n\tstruct passwd *original_pw, *target_pw;\n\tstruct rule *rule;\n\tuid_t uid;\n\tuid_t target = 0;\n\tgid_t groups[NGROUPS_MAX + 1];\n\tint ngroups;\n\tint i, ch;\n\tint sflag = 0;\n\tint nflag = 0;\n\tchar cwdpath[PATH_MAX];\n\tconst char *cwd;\n\tchar *login_style = NULL;\n\tchar **envp;\n\n\t#ifndef linux\n\tsetprogname(\"doas\");\n\t#endif\n\n\t#ifndef linux\n\tclosefrom(STDERR_FILENO + 1);\n\t#endif\n\n\tuid = getuid();\n\n\twhile ((ch = getopt(argc, argv, \"a:C:nsu:\")) != -1) {\n/*\twhile ((ch = getopt(argc, argv, \"a:C:Lnsu:\")) != -1) { */\n\t\tswitch (ch) {\n\t\tcase 'a':\n\t\t\tlogin_style = optarg;\n\t\t\tbreak;\n\t\tcase 'C':\n\t\t\tconfpath = optarg;\n\t\t\tbreak;\n/*\t\tcase 'L':\n\t\t\ti = open(\"/dev/tty\", O_RDWR);\n\t\t\tif (i != -1)\n\t\t\t\tioctl(i, TIOCCLRVERAUTH);\n\t\t\texit(i != -1);\n*/\n\t\tcase 'u':\n\t\t\tif (parseuid(optarg, &target) != 0)\n\t\t\t\terrx(1, \"unknown user\");\n\t\t\tbreak;\n\t\tcase 'n':\n\t\t\tnflag = 1;\n\t\t\tbreak;\n\t\tcase 's':\n\t\t\tsflag = 1;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tusage();\n\t\t\tbreak;\n\t\t}\n\t}\n\targv += optind;\n\targc -= optind;\n\n\tif (confpath) {\n\t\tif (sflag)\n\t\t\tusage();\n\t} else if ((!sflag && !argc) || (sflag && argc))\n\t\tusage();\n\n\toriginal_pw = getpwuid(uid);\n\tif (! original_pw)\n\t\terr(1, \"getpwuid failed\");\n\tif (strlcpy(myname, original_pw->pw_name, sizeof(myname)) >= sizeof(myname))\n\t\terrx(1, \"pw_name too long\");\n\n\tngroups = getgroups(NGROUPS_MAX, groups);\n\tif (ngroups == -1)\n\t\terr(1, \"can't get groups\");\n\tgroups[ngroups++] = getgid();\n\n\tif (sflag) {\n\t\tsh = getenv(\"SHELL\");\n\t\tif (sh == NULL || *sh == '\\0') {\n\t\t\tshargv[0] = strdup(original_pw->pw_shell);\n\t\t\tif (shargv[0] == NULL)\n\t\t\t\terr(1, NULL);\n\t\t} else\n\t\t\tshargv[0] = sh;\n\t\targv = shargv;\n\t\targc = 1;\n\t}\n\n\tif (confpath) {\n\t\tcheckconfig(confpath, argc, argv, uid, groups, ngroups,\n\t\t    target);\n\t\texit(1);\t/* fail safe */\n\t}\n\n\tif (geteuid())\n\t\terrx(1, \"not installed setuid\");\n\n\tparseconfig(DOAS_CONF, 1);\n\n\t/* cmdline is used only for logging, no need to abort on truncate */\n\t(void)strlcpy(cmdline, argv[0], sizeof(cmdline));\n\tfor (i = 1; i < argc; i++) {\n\t\tif (strlcat(cmdline, \" \", sizeof(cmdline)) >= sizeof(cmdline))\n\t\t\tbreak;\n\t\tif (strlcat(cmdline, argv[i], sizeof(cmdline)) >= sizeof(cmdline))\n\t\t\tbreak;\n\t}\n\n\tcmd = argv[0];\n\tif (!permit(uid, groups, ngroups, &rule, target, cmd,\n\t    (const char **)argv + 1)) {\n\t\tsyslog(LOG_AUTHPRIV | LOG_NOTICE,\n\t\t    \"failed command for %s: %s\", myname, cmdline);\n\t\terrc(1, EPERM, NULL);\n\t}\n\n\tif (!(rule->options & NOPASS)) {\n\t\tif (nflag)\n\t\t\terrx(1, \"Authorization required\");\n\n#if defined(USE_BSD_AUTH) \n\t\tauthuser(myname, login_style, rule->options & PERSIST);\n#elif defined(USE_PAM)\n#define PAM_END(msg) do { \t\t\t\t\t\t\\\n\tsyslog(LOG_ERR, \"%s: %s\", msg, pam_strerror(pamh, pam_err)); \t\\\n\twarnx(\"%s: %s\", msg, pam_strerror(pamh, pam_err));\t\t\\\n\tpam_end(pamh, pam_err);\t\t\t\t\t\t\\\n\texit(EXIT_FAILURE);\t\t\t\t\t\t\\\n} while (/*CONSTCOND*/0)\n\t\tpam_handle_t *pamh = NULL;\n\t\tint pam_err;\n\n/* #ifndef linux */\n\t\tint temp_stdin;\n\n\t\t/* openpam_ttyconv checks if stdin is a terminal and\n\t\t * if it is then does not bother to open /dev/tty.\n\t\t * The result is that PAM writes the password prompt\n\t\t * directly to stdout.  In scenarios where stdin is a\n\t\t * terminal, but stdout is redirected to a file\n\t\t * e.g. by running doas ls &> ls.out interactively,\n\t\t * the password prompt gets written to ls.out as well.\n\t\t * By closing stdin first we forces PAM to read/write\n\t\t * to/from the terminal directly.  We restore stdin\n\t\t * after authenticating. */\n\t\ttemp_stdin = dup(STDIN_FILENO);\n\t\tif (temp_stdin == -1)\n\t\t\terr(1, \"dup\");\n\t\tclose(STDIN_FILENO);\n/* #else */\n\t\t/* force password prompt to display on stderr, not stdout */\n\t\tint temp_stdout = dup(1);\n\t\tif (temp_stdout == -1)\n\t\t\terr(1, \"dup\");\n\t\tclose(1);\n\t\tif (dup2(2, 1) == -1)\n\t\t\terr(1, \"dup2\");\n/* #endif */\n\n\t\tpam_err = pam_start(\"doas\", myname, &pamc, &pamh);\n\t\tif (pam_err != PAM_SUCCESS) {\n\t\t\tif (pamh != NULL)\n\t\t\t\tPAM_END(\"pam_start\");\n\t\t\tsyslog(LOG_ERR, \"pam_start failed: %s\",\n\t\t\t    pam_strerror(pamh, pam_err));\n\t\t\terrx(EXIT_FAILURE, \"pam_start failed\");\n\t\t}\n\n\t\tswitch (pam_err = pam_authenticate(pamh, PAM_SILENT)) {\n\t\tcase PAM_SUCCESS:\n\t\t\tswitch (pam_err = pam_acct_mgmt(pamh, PAM_SILENT)) {\n\t\t\tcase PAM_SUCCESS:\n\t\t\t\tbreak;\n\n\t\t\tcase PAM_NEW_AUTHTOK_REQD:\n\t\t\t\tpam_err = pam_chauthtok(pamh,\n\t\t\t\t    PAM_SILENT|PAM_CHANGE_EXPIRED_AUTHTOK);\n\t\t\t\tif (pam_err != PAM_SUCCESS)\n\t\t\t\t\tPAM_END(\"pam_chauthtok\");\n\t\t\t\tbreak;\n\n\t\t\tcase PAM_AUTH_ERR:\n\t\t\tcase PAM_USER_UNKNOWN:\n\t\t\tcase PAM_MAXTRIES:\n\t\t\t\tsyslog(LOG_AUTHPRIV | LOG_NOTICE,\n\t\t\t\t    \"failed auth for %s\", myname);\n                                errx(EXIT_FAILURE, \"second authentication failed\");\n\t\t\t\tbreak;\n\n\t\t\tdefault:\n\t\t\t\tPAM_END(\"pam_acct_mgmt\");\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tbreak;\n\n\t\tcase PAM_AUTH_ERR:\n\t\tcase PAM_USER_UNKNOWN:\n\t\tcase PAM_MAXTRIES:\n\t\t\tsyslog(LOG_AUTHPRIV | LOG_NOTICE,\n\t\t\t    \"failed auth for %s\", myname);\n                        errx(EXIT_FAILURE, \"authentication failed\");\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tPAM_END(\"pam_authenticate\");\n\t\t\tbreak;\n\t\t}\n\t\tpam_end(pamh, pam_err);\n\n#ifndef linux\n\t\t/* Re-establish stdin */\n\t\tif (dup2(temp_stdin, STDIN_FILENO) == -1)\n\t\t\terr(1, \"dup2\");\n\t\tclose(temp_stdin);\n#else \n\t\t/* Re-establish stdout */\n\t\tclose(1);\n\t\tif (dup2(temp_stdout, 1) == -1)\n\t\t\terr(1, \"dup2\");\n#endif\n#else\n#error\tNo auth module!\n#endif\n\t}\n\n        /*\n\tif (pledge(\"stdio rpath getpw exec id\", NULL) == -1)\n\t\terr(1, \"pledge\");\n        */\n\ttarget_pw = getpwuid(target);\n\tif (! target_pw)\n\t\terrx(1, \"no passwd entry for target\");\n\n#if defined(HAVE_LOGIN_CAP_H)\n\tif (setusercontext(NULL, target_pw, target, LOGIN_SETGROUP |\n\t    LOGIN_SETPRIORITY | LOGIN_SETRESOURCES | LOGIN_SETUMASK |\n\t    LOGIN_SETUSER) != 0)\n\t\terrx(1, \"failed to set user context for target\");\n#endif\n        /*\n\tif (pledge(\"stdio rpath exec\", NULL) == -1)\n\t\terr(1, \"pledge\");\n        */\n\n\tif (getcwd(cwdpath, sizeof(cwdpath)) == NULL)\n\t\tcwd = \"(failed)\";\n\telse\n\t\tcwd = cwdpath;\n\n\t/*\n        if (pledge(\"stdio exec\", NULL) == -1)\n\t\terr(1, \"pledge\");\n        */\n#ifndef HAVE_LOGIN_CAP_H\n        /* If we effectively are root, set the UID to actually be root to avoid\n           permission errors. */\n        if (target != 0)\n           setuid(target);\n        if ( geteuid() == ROOT_UID )\n           setuid(ROOT_UID);\n#endif\n\n\tsyslog(LOG_AUTHPRIV | LOG_INFO, \"%s ran command %s as %s from %s\",\n\t    myname, cmdline, target_pw->pw_name, cwd);\n\n\tenvp = prepenv(rule, original_pw, target_pw);\n\n\tif (rule->cmd) {\n\t\tif (setenv(\"PATH\", safepath, 1) == -1)\n\t\t\terr(1, \"failed to set PATH '%s'\", safepath);\n\t}\n\texecvpe(cmd, argv, envp);\n\tif (errno == ENOENT)\n\t\terrx(1, \"%s: command not found\", cmd);\n\terr(1, \"%s\", cmd);\n}",
        "func": "int\nmain(int argc, char **argv)\n{\n\tconst char *safepath = SAFE_PATH;\n\tconst char *confpath = NULL;\n\tchar *shargv[] = { NULL, NULL };\n\tchar *sh;\n\tconst char *cmd;\n\tchar cmdline[LINE_MAX];\n\tchar myname[_PW_NAME_LEN + 1];\n\tstruct passwd *original_pw, *target_pw;\n\tstruct rule *rule;\n\tuid_t uid;\n\tuid_t target = 0;\n\tgid_t groups[NGROUPS_MAX + 1];\n\tint ngroups;\n\tint i, ch;\n\tint sflag = 0;\n\tint nflag = 0;\n\tchar cwdpath[PATH_MAX];\n\tconst char *cwd;\n\tchar *login_style = NULL;\n\tchar **envp;\n\n\t#ifndef linux\n\tsetprogname(\"doas\");\n\t#endif\n\n\t#ifndef linux\n\tclosefrom(STDERR_FILENO + 1);\n\t#endif\n\n\tuid = getuid();\n\n\twhile ((ch = getopt(argc, argv, \"a:C:nsu:\")) != -1) {\n/*\twhile ((ch = getopt(argc, argv, \"a:C:Lnsu:\")) != -1) { */\n\t\tswitch (ch) {\n\t\tcase 'a':\n\t\t\tlogin_style = optarg;\n\t\t\tbreak;\n\t\tcase 'C':\n\t\t\tconfpath = optarg;\n\t\t\tbreak;\n/*\t\tcase 'L':\n\t\t\ti = open(\"/dev/tty\", O_RDWR);\n\t\t\tif (i != -1)\n\t\t\t\tioctl(i, TIOCCLRVERAUTH);\n\t\t\texit(i != -1);\n*/\n\t\tcase 'u':\n\t\t\tif (parseuid(optarg, &target) != 0)\n\t\t\t\terrx(1, \"unknown user\");\n\t\t\tbreak;\n\t\tcase 'n':\n\t\t\tnflag = 1;\n\t\t\tbreak;\n\t\tcase 's':\n\t\t\tsflag = 1;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tusage();\n\t\t\tbreak;\n\t\t}\n\t}\n\targv += optind;\n\targc -= optind;\n\n\tif (confpath) {\n\t\tif (sflag)\n\t\t\tusage();\n\t} else if ((!sflag && !argc) || (sflag && argc))\n\t\tusage();\n\n\toriginal_pw = getpwuid(uid);\n\tif (! original_pw)\n\t\terr(1, \"getpwuid failed\");\n\tif (strlcpy(myname, original_pw->pw_name, sizeof(myname)) >= sizeof(myname))\n\t\terrx(1, \"pw_name too long\");\n\n\tngroups = getgroups(NGROUPS_MAX, groups);\n\tif (ngroups == -1)\n\t\terr(1, \"can't get groups\");\n\tgroups[ngroups++] = getgid();\n\n\tif (sflag) {\n\t\tsh = getenv(\"SHELL\");\n\t\tif (sh == NULL || *sh == '\\0') {\n\t\t\tshargv[0] = strdup(original_pw->pw_shell);\n\t\t\tif (shargv[0] == NULL)\n\t\t\t\terr(1, NULL);\n\t\t} else\n\t\t\tshargv[0] = sh;\n\t\targv = shargv;\n\t\targc = 1;\n\t}\n\n\tif (confpath) {\n\t\tcheckconfig(confpath, argc, argv, uid, groups, ngroups,\n\t\t    target);\n\t\texit(1);\t/* fail safe */\n\t}\n\n\tif (geteuid())\n\t\terrx(1, \"not installed setuid\");\n\n\tparseconfig(DOAS_CONF, 1);\n\n\t/* cmdline is used only for logging, no need to abort on truncate */\n\t(void)strlcpy(cmdline, argv[0], sizeof(cmdline));\n\tfor (i = 1; i < argc; i++) {\n\t\tif (strlcat(cmdline, \" \", sizeof(cmdline)) >= sizeof(cmdline))\n\t\t\tbreak;\n\t\tif (strlcat(cmdline, argv[i], sizeof(cmdline)) >= sizeof(cmdline))\n\t\t\tbreak;\n\t}\n\n\tcmd = argv[0];\n\tif (!permit(uid, groups, ngroups, &rule, target, cmd,\n\t    (const char **)argv + 1)) {\n\t\tsyslog(LOG_AUTHPRIV | LOG_NOTICE,\n\t\t    \"failed command for %s: %s\", myname, cmdline);\n\t\terrc(1, EPERM, NULL);\n\t}\n\n\tif (!(rule->options & NOPASS)) {\n\t\tif (nflag)\n\t\t\terrx(1, \"Authorization required\");\n\n#if defined(USE_BSD_AUTH) \n\t\tauthuser(myname, login_style, rule->options & PERSIST);\n#elif defined(USE_PAM)\n#define PAM_END(msg) do { \t\t\t\t\t\t\\\n\tsyslog(LOG_ERR, \"%s: %s\", msg, pam_strerror(pamh, pam_err)); \t\\\n\twarnx(\"%s: %s\", msg, pam_strerror(pamh, pam_err));\t\t\\\n\tpam_end(pamh, pam_err);\t\t\t\t\t\t\\\n\texit(EXIT_FAILURE);\t\t\t\t\t\t\\\n} while (/*CONSTCOND*/0)\n\t\tpam_handle_t *pamh = NULL;\n\t\tint pam_err;\n\n/* #ifndef linux */\n\t\tint temp_stdin;\n\n\t\t/* openpam_ttyconv checks if stdin is a terminal and\n\t\t * if it is then does not bother to open /dev/tty.\n\t\t * The result is that PAM writes the password prompt\n\t\t * directly to stdout.  In scenarios where stdin is a\n\t\t * terminal, but stdout is redirected to a file\n\t\t * e.g. by running doas ls &> ls.out interactively,\n\t\t * the password prompt gets written to ls.out as well.\n\t\t * By closing stdin first we forces PAM to read/write\n\t\t * to/from the terminal directly.  We restore stdin\n\t\t * after authenticating. */\n\t\ttemp_stdin = dup(STDIN_FILENO);\n\t\tif (temp_stdin == -1)\n\t\t\terr(1, \"dup\");\n\t\tclose(STDIN_FILENO);\n/* #else */\n\t\t/* force password prompt to display on stderr, not stdout */\n\t\tint temp_stdout = dup(1);\n\t\tif (temp_stdout == -1)\n\t\t\terr(1, \"dup\");\n\t\tclose(1);\n\t\tif (dup2(2, 1) == -1)\n\t\t\terr(1, \"dup2\");\n/* #endif */\n\n\t\tpam_err = pam_start(\"doas\", myname, &pamc, &pamh);\n\t\tif (pam_err != PAM_SUCCESS) {\n\t\t\tif (pamh != NULL)\n\t\t\t\tPAM_END(\"pam_start\");\n\t\t\tsyslog(LOG_ERR, \"pam_start failed: %s\",\n\t\t\t    pam_strerror(pamh, pam_err));\n\t\t\terrx(EXIT_FAILURE, \"pam_start failed\");\n\t\t}\n\n\t\tswitch (pam_err = pam_authenticate(pamh, PAM_SILENT)) {\n\t\tcase PAM_SUCCESS:\n\t\t\tswitch (pam_err = pam_acct_mgmt(pamh, PAM_SILENT)) {\n\t\t\tcase PAM_SUCCESS:\n\t\t\t\tbreak;\n\n\t\t\tcase PAM_NEW_AUTHTOK_REQD:\n\t\t\t\tpam_err = pam_chauthtok(pamh,\n\t\t\t\t    PAM_SILENT|PAM_CHANGE_EXPIRED_AUTHTOK);\n\t\t\t\tif (pam_err != PAM_SUCCESS)\n\t\t\t\t\tPAM_END(\"pam_chauthtok\");\n\t\t\t\tbreak;\n\n\t\t\tcase PAM_AUTH_ERR:\n\t\t\tcase PAM_USER_UNKNOWN:\n\t\t\tcase PAM_MAXTRIES:\n\t\t\t\tsyslog(LOG_AUTHPRIV | LOG_NOTICE,\n\t\t\t\t    \"failed auth for %s\", myname);\n                                errx(EXIT_FAILURE, \"second authentication failed\");\n\t\t\t\tbreak;\n\n\t\t\tdefault:\n\t\t\t\tPAM_END(\"pam_acct_mgmt\");\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tbreak;\n\n\t\tcase PAM_AUTH_ERR:\n\t\tcase PAM_USER_UNKNOWN:\n\t\tcase PAM_MAXTRIES:\n\t\t\tsyslog(LOG_AUTHPRIV | LOG_NOTICE,\n\t\t\t    \"failed auth for %s\", myname);\n                        errx(EXIT_FAILURE, \"authentication failed\");\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tPAM_END(\"pam_authenticate\");\n\t\t\tbreak;\n\t\t}\n\t\tpam_end(pamh, pam_err);\n\n#ifndef linux\n\t\t/* Re-establish stdin */\n\t\tif (dup2(temp_stdin, STDIN_FILENO) == -1)\n\t\t\terr(1, \"dup2\");\n\t\tclose(temp_stdin);\n#else \n\t\t/* Re-establish stdout */\n\t\tclose(1);\n\t\tif (dup2(temp_stdout, 1) == -1)\n\t\t\terr(1, \"dup2\");\n#endif\n#else\n#error\tNo auth module!\n#endif\n\t}\n\n        /*\n\tif (pledge(\"stdio rpath getpw exec id\", NULL) == -1)\n\t\terr(1, \"pledge\");\n        */\n\ttarget_pw = getpwuid(target);\n\tif (! target_pw)\n\t\terrx(1, \"no passwd entry for target\");\n\n#if defined(HAVE_LOGIN_CAP_H)\n\tif (setusercontext(NULL, target_pw, target, LOGIN_SETGROUP |\n\t    LOGIN_SETPRIORITY | LOGIN_SETRESOURCES | LOGIN_SETUMASK |\n\t    LOGIN_SETUSER) != 0)\n\t\terrx(1, \"failed to set user context for target\");\n#else\n\t#if defined(__linux__) || defined(__FreeBSD__) || defined(__NetBSD__)\n\tif (setresgid(target_pw->pw_gid, target_pw->pw_gid, target_pw->pw_gid) == -1)\n\t\terr(1, \"setresgid\");\n\t#else\n\tif (setregid(target_pw->pw_gid, target_pw->pw_gid) == -1)\n\t\terr(1, \"setregid\");\n\t#endif\n\tif (initgroups(target_pw->pw_name, target_pw->pw_gid) == -1)\n\t\terr(1, \"initgroups\");\n\t#if defined(__linux__) || defined(__FreeBSD__) || defined(__NetBSD__)\n\tif (setresuid(target, target, target) == -1)\n\t\terr(1, \"setresuid\");\n\t#else\n\tif (setreuid(target, target) == -1)\n\t\terr(1, \"setreuid\");\n\t#endif\n#endif\n        /*\n\tif (pledge(\"stdio rpath exec\", NULL) == -1)\n\t\terr(1, \"pledge\");\n        */\n\n\tif (getcwd(cwdpath, sizeof(cwdpath)) == NULL)\n\t\tcwd = \"(failed)\";\n\telse\n\t\tcwd = cwdpath;\n\n\t/*\n        if (pledge(\"stdio exec\", NULL) == -1)\n\t\terr(1, \"pledge\");\n        */\n\n\tsyslog(LOG_AUTHPRIV | LOG_INFO, \"%s ran command %s as %s from %s\",\n\t    myname, cmdline, target_pw->pw_name, cwd);\n\n\tenvp = prepenv(rule, original_pw, target_pw);\n\n\tif (rule->cmd) {\n\t\tif (setenv(\"PATH\", safepath, 1) == -1)\n\t\t\terr(1, \"failed to set PATH '%s'\", safepath);\n\t}\n\texecvpe(cmd, argv, envp);\n\tif (errno == ENOENT)\n\t\terrx(1, \"%s: command not found\", cmd);\n\terr(1, \"%s\", cmd);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -244,6 +244,23 @@\n \t    LOGIN_SETPRIORITY | LOGIN_SETRESOURCES | LOGIN_SETUMASK |\n \t    LOGIN_SETUSER) != 0)\n \t\terrx(1, \"failed to set user context for target\");\n+#else\n+\t#if defined(__linux__) || defined(__FreeBSD__) || defined(__NetBSD__)\n+\tif (setresgid(target_pw->pw_gid, target_pw->pw_gid, target_pw->pw_gid) == -1)\n+\t\terr(1, \"setresgid\");\n+\t#else\n+\tif (setregid(target_pw->pw_gid, target_pw->pw_gid) == -1)\n+\t\terr(1, \"setregid\");\n+\t#endif\n+\tif (initgroups(target_pw->pw_name, target_pw->pw_gid) == -1)\n+\t\terr(1, \"initgroups\");\n+\t#if defined(__linux__) || defined(__FreeBSD__) || defined(__NetBSD__)\n+\tif (setresuid(target, target, target) == -1)\n+\t\terr(1, \"setresuid\");\n+\t#else\n+\tif (setreuid(target, target) == -1)\n+\t\terr(1, \"setreuid\");\n+\t#endif\n #endif\n         /*\n \tif (pledge(\"stdio rpath exec\", NULL) == -1)\n@@ -259,14 +276,6 @@\n         if (pledge(\"stdio exec\", NULL) == -1)\n \t\terr(1, \"pledge\");\n         */\n-#ifndef HAVE_LOGIN_CAP_H\n-        /* If we effectively are root, set the UID to actually be root to avoid\n-           permission errors. */\n-        if (target != 0)\n-           setuid(target);\n-        if ( geteuid() == ROOT_UID )\n-           setuid(ROOT_UID);\n-#endif\n \n \tsyslog(LOG_AUTHPRIV | LOG_INFO, \"%s ran command %s as %s from %s\",\n \t    myname, cmdline, target_pw->pw_name, cwd);",
        "diff_line_info": {
            "deleted_lines": [
                "#ifndef HAVE_LOGIN_CAP_H",
                "        /* If we effectively are root, set the UID to actually be root to avoid",
                "           permission errors. */",
                "        if (target != 0)",
                "           setuid(target);",
                "        if ( geteuid() == ROOT_UID )",
                "           setuid(ROOT_UID);",
                "#endif"
            ],
            "added_lines": [
                "#else",
                "\t#if defined(__linux__) || defined(__FreeBSD__) || defined(__NetBSD__)",
                "\tif (setresgid(target_pw->pw_gid, target_pw->pw_gid, target_pw->pw_gid) == -1)",
                "\t\terr(1, \"setresgid\");",
                "\t#else",
                "\tif (setregid(target_pw->pw_gid, target_pw->pw_gid) == -1)",
                "\t\terr(1, \"setregid\");",
                "\t#endif",
                "\tif (initgroups(target_pw->pw_name, target_pw->pw_gid) == -1)",
                "\t\terr(1, \"initgroups\");",
                "\t#if defined(__linux__) || defined(__FreeBSD__) || defined(__NetBSD__)",
                "\tif (setresuid(target, target, target) == -1)",
                "\t\terr(1, \"setresuid\");",
                "\t#else",
                "\tif (setreuid(target, target) == -1)",
                "\t\terr(1, \"setreuid\");",
                "\t#endif"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-18425",
        "func_name": "xen-project/xen/pv_emul_read_descriptor",
        "description": "An issue was discovered in Xen through 4.12.x allowing 32-bit PV guest OS users to gain guest OS privileges by installing and using descriptors. There is missing descriptor table limit checking in x86 PV emulation. When emulating certain PV guest operations, descriptor table accesses are performed by the emulating code. Such accesses should respect the guest specified limits, unless otherwise guaranteed to fail in such a case. Without this, emulation of 32-bit guest user mode calls through call gates would allow guest user mode to install and then use descriptors of their choice, as long as the guest kernel did not itself install an LDT. (Most OSes don't install any LDT by default). 32-bit PV guest user mode can elevate its privileges to that of the guest kernel. Xen versions from at least 3.2 onwards are affected. Only 32-bit PV guest user mode can leverage this vulnerability. HVM, PVH, as well as 64-bit PV guests cannot leverage this vulnerability. Arm systems are unaffected.",
        "git_url": "https://github.com/xen-project/xen/commit/93021cbe880a8013691a48d0febef8ed7d3e3ebd",
        "commit_title": "x86/PV: check GDT/LDT limits during emulation",
        "commit_text": " Accesses beyond the LDT limit originating from emulation would trigger the ASSERT() in pv_map_ldt_shadow_page(). On production builds such accesses would cause an attempt to promote the touched page (offset from the present LDT base address) to a segment descriptor one. If this happens to succeed, guest user mode would be able to elevate its privileges to that of the guest kernel. This is particularly easy when there's no LDT at all, in which case the LDT base stored internally to Xen is simply zero.  Also adjust the ASSERT() that was triggering: It was off by one to begin with, and for production builds we also better use ASSERT_UNREACHABLE() instead with suitable recovery code afterwards.  This is XSA-298. ",
        "func_before": "int pv_emul_read_descriptor(unsigned int sel, const struct vcpu *v,\n                            unsigned long *base, unsigned long *limit,\n                            unsigned int *ar, bool insn_fetch)\n{\n    seg_desc_t desc;\n\n    if ( sel < 4)\n        desc.b = desc.a = 0;\n    else if ( __get_user(desc, gdt_ldt_desc_ptr(sel)) )\n        return 0;\n    if ( !insn_fetch )\n        desc.b &= ~_SEGMENT_L;\n\n    *ar = desc.b & 0x00f0ff00;\n    if ( !(desc.b & _SEGMENT_L) )\n    {\n        *base = ((desc.a >> 16) + ((desc.b & 0xff) << 16) +\n                 (desc.b & 0xff000000));\n        *limit = (desc.a & 0xffff) | (desc.b & 0x000f0000);\n        if ( desc.b & _SEGMENT_G )\n            *limit = ((*limit + 1) << 12) - 1;\n#ifndef NDEBUG\n        if ( sel > 3 )\n        {\n            unsigned int a, l;\n            unsigned char valid;\n\n            asm volatile (\n                \"larl %2,%0 ; setz %1\"\n                : \"=r\" (a), \"=qm\" (valid) : \"rm\" (sel));\n            BUG_ON(valid && ((a & 0x00f0ff00) != *ar));\n            asm volatile (\n                \"lsll %2,%0 ; setz %1\"\n                : \"=r\" (l), \"=qm\" (valid) : \"rm\" (sel));\n            BUG_ON(valid && (l != *limit));\n        }\n#endif\n    }\n    else\n    {\n        *base = 0UL;\n        *limit = ~0UL;\n    }\n\n    return 1;\n}",
        "func": "int pv_emul_read_descriptor(unsigned int sel, const struct vcpu *v,\n                            unsigned long *base, unsigned long *limit,\n                            unsigned int *ar, bool insn_fetch)\n{\n    seg_desc_t desc;\n\n    if ( sel < 4 ||\n         /*\n          * Don't apply the GDT limit here, as the selector may be a Xen\n          * provided one. __get_user() will fail (without taking further\n          * action) for ones falling in the gap between guest populated\n          * and Xen ones.\n          */\n         ((sel & 4) && (sel >> 3) >= v->arch.pv.ldt_ents) )\n        desc.b = desc.a = 0;\n    else if ( __get_user(desc, gdt_ldt_desc_ptr(sel)) )\n        return 0;\n    if ( !insn_fetch )\n        desc.b &= ~_SEGMENT_L;\n\n    *ar = desc.b & 0x00f0ff00;\n    if ( !(desc.b & _SEGMENT_L) )\n    {\n        *base = ((desc.a >> 16) + ((desc.b & 0xff) << 16) +\n                 (desc.b & 0xff000000));\n        *limit = (desc.a & 0xffff) | (desc.b & 0x000f0000);\n        if ( desc.b & _SEGMENT_G )\n            *limit = ((*limit + 1) << 12) - 1;\n#ifndef NDEBUG\n        if ( sel > 3 )\n        {\n            unsigned int a, l;\n            unsigned char valid;\n\n            asm volatile (\n                \"larl %2,%0 ; setz %1\"\n                : \"=r\" (a), \"=qm\" (valid) : \"rm\" (sel));\n            BUG_ON(valid && ((a & 0x00f0ff00) != *ar));\n            asm volatile (\n                \"lsll %2,%0 ; setz %1\"\n                : \"=r\" (l), \"=qm\" (valid) : \"rm\" (sel));\n            BUG_ON(valid && (l != *limit));\n        }\n#endif\n    }\n    else\n    {\n        *base = 0UL;\n        *limit = ~0UL;\n    }\n\n    return 1;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,7 +4,14 @@\n {\n     seg_desc_t desc;\n \n-    if ( sel < 4)\n+    if ( sel < 4 ||\n+         /*\n+          * Don't apply the GDT limit here, as the selector may be a Xen\n+          * provided one. __get_user() will fail (without taking further\n+          * action) for ones falling in the gap between guest populated\n+          * and Xen ones.\n+          */\n+         ((sel & 4) && (sel >> 3) >= v->arch.pv.ldt_ents) )\n         desc.b = desc.a = 0;\n     else if ( __get_user(desc, gdt_ldt_desc_ptr(sel)) )\n         return 0;",
        "diff_line_info": {
            "deleted_lines": [
                "    if ( sel < 4)"
            ],
            "added_lines": [
                "    if ( sel < 4 ||",
                "         /*",
                "          * Don't apply the GDT limit here, as the selector may be a Xen",
                "          * provided one. __get_user() will fail (without taking further",
                "          * action) for ones falling in the gap between guest populated",
                "          * and Xen ones.",
                "          */",
                "         ((sel & 4) && (sel >> 3) >= v->arch.pv.ldt_ents) )"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-18425",
        "func_name": "xen-project/xen/pv_map_ldt_shadow_page",
        "description": "An issue was discovered in Xen through 4.12.x allowing 32-bit PV guest OS users to gain guest OS privileges by installing and using descriptors. There is missing descriptor table limit checking in x86 PV emulation. When emulating certain PV guest operations, descriptor table accesses are performed by the emulating code. Such accesses should respect the guest specified limits, unless otherwise guaranteed to fail in such a case. Without this, emulation of 32-bit guest user mode calls through call gates would allow guest user mode to install and then use descriptors of their choice, as long as the guest kernel did not itself install an LDT. (Most OSes don't install any LDT by default). 32-bit PV guest user mode can elevate its privileges to that of the guest kernel. Xen versions from at least 3.2 onwards are affected. Only 32-bit PV guest user mode can leverage this vulnerability. HVM, PVH, as well as 64-bit PV guests cannot leverage this vulnerability. Arm systems are unaffected.",
        "git_url": "https://github.com/xen-project/xen/commit/93021cbe880a8013691a48d0febef8ed7d3e3ebd",
        "commit_title": "x86/PV: check GDT/LDT limits during emulation",
        "commit_text": " Accesses beyond the LDT limit originating from emulation would trigger the ASSERT() in pv_map_ldt_shadow_page(). On production builds such accesses would cause an attempt to promote the touched page (offset from the present LDT base address) to a segment descriptor one. If this happens to succeed, guest user mode would be able to elevate its privileges to that of the guest kernel. This is particularly easy when there's no LDT at all, in which case the LDT base stored internally to Xen is simply zero.  Also adjust the ASSERT() that was triggering: It was off by one to begin with, and for production builds we also better use ASSERT_UNREACHABLE() instead with suitable recovery code afterwards.  This is XSA-298. ",
        "func_before": "bool pv_map_ldt_shadow_page(unsigned int offset)\n{\n    struct vcpu *curr = current;\n    struct domain *currd = curr->domain;\n    struct page_info *page;\n    l1_pgentry_t gl1e, *pl1e;\n    unsigned long linear = curr->arch.pv.ldt_base + offset;\n\n    BUG_ON(unlikely(in_irq()));\n\n    /*\n     * Hardware limit checking should guarantee this property.  NB. This is\n     * safe as updates to the LDT can only be made by MMUEXT_SET_LDT to the\n     * current vcpu, and vcpu_reset() will block until this vcpu has been\n     * descheduled before continuing.\n     */\n    ASSERT((offset >> 3) <= curr->arch.pv.ldt_ents);\n\n    if ( is_pv_32bit_domain(currd) )\n        linear = (uint32_t)linear;\n\n    gl1e = guest_get_eff_kern_l1e(linear);\n    if ( unlikely(!(l1e_get_flags(gl1e) & _PAGE_PRESENT)) )\n        return false;\n\n    page = get_page_from_gfn(currd, l1e_get_pfn(gl1e), NULL, P2M_ALLOC);\n    if ( unlikely(!page) )\n        return false;\n\n    if ( unlikely(!get_page_type(page, PGT_seg_desc_page)) )\n    {\n        put_page(page);\n        return false;\n    }\n\n    pl1e = &pv_ldt_ptes(curr)[offset >> PAGE_SHIFT];\n    l1e_add_flags(gl1e, _PAGE_RW);\n\n#ifdef CONFIG_PV_LDT_PAGING\n    spin_lock(&curr->arch.pv.shadow_ldt_lock);\n#endif\n\n    l1e_write(pl1e, gl1e);\n\n#ifdef CONFIG_PV_LDT_PAGING\n    curr->arch.pv.shadow_ldt_mapcnt++;\n    spin_unlock(&curr->arch.pv.shadow_ldt_lock);\n#endif\n\n    return true;\n}",
        "func": "bool pv_map_ldt_shadow_page(unsigned int offset)\n{\n    struct vcpu *curr = current;\n    struct domain *currd = curr->domain;\n    struct page_info *page;\n    l1_pgentry_t gl1e, *pl1e;\n    unsigned long linear = curr->arch.pv.ldt_base + offset;\n\n    BUG_ON(unlikely(in_irq()));\n\n    /*\n     * Prior limit checking should guarantee this property.  NB. This is\n     * safe as updates to the LDT can only be made by MMUEXT_SET_LDT to the\n     * current vcpu, and vcpu_reset() will block until this vcpu has been\n     * descheduled before continuing.\n     */\n    if ( unlikely((offset >> 3) >= curr->arch.pv.ldt_ents) )\n    {\n        ASSERT_UNREACHABLE();\n        return false;\n    }\n\n    if ( is_pv_32bit_domain(currd) )\n        linear = (uint32_t)linear;\n\n    gl1e = guest_get_eff_kern_l1e(linear);\n    if ( unlikely(!(l1e_get_flags(gl1e) & _PAGE_PRESENT)) )\n        return false;\n\n    page = get_page_from_gfn(currd, l1e_get_pfn(gl1e), NULL, P2M_ALLOC);\n    if ( unlikely(!page) )\n        return false;\n\n    if ( unlikely(!get_page_type(page, PGT_seg_desc_page)) )\n    {\n        put_page(page);\n        return false;\n    }\n\n    pl1e = &pv_ldt_ptes(curr)[offset >> PAGE_SHIFT];\n    l1e_add_flags(gl1e, _PAGE_RW);\n\n#ifdef CONFIG_PV_LDT_PAGING\n    spin_lock(&curr->arch.pv.shadow_ldt_lock);\n#endif\n\n    l1e_write(pl1e, gl1e);\n\n#ifdef CONFIG_PV_LDT_PAGING\n    curr->arch.pv.shadow_ldt_mapcnt++;\n    spin_unlock(&curr->arch.pv.shadow_ldt_lock);\n#endif\n\n    return true;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -9,12 +9,16 @@\n     BUG_ON(unlikely(in_irq()));\n \n     /*\n-     * Hardware limit checking should guarantee this property.  NB. This is\n+     * Prior limit checking should guarantee this property.  NB. This is\n      * safe as updates to the LDT can only be made by MMUEXT_SET_LDT to the\n      * current vcpu, and vcpu_reset() will block until this vcpu has been\n      * descheduled before continuing.\n      */\n-    ASSERT((offset >> 3) <= curr->arch.pv.ldt_ents);\n+    if ( unlikely((offset >> 3) >= curr->arch.pv.ldt_ents) )\n+    {\n+        ASSERT_UNREACHABLE();\n+        return false;\n+    }\n \n     if ( is_pv_32bit_domain(currd) )\n         linear = (uint32_t)linear;",
        "diff_line_info": {
            "deleted_lines": [
                "     * Hardware limit checking should guarantee this property.  NB. This is",
                "    ASSERT((offset >> 3) <= curr->arch.pv.ldt_ents);"
            ],
            "added_lines": [
                "     * Prior limit checking should guarantee this property.  NB. This is",
                "    if ( unlikely((offset >> 3) >= curr->arch.pv.ldt_ents) )",
                "    {",
                "        ASSERT_UNREACHABLE();",
                "        return false;",
                "    }"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-18425",
        "func_name": "xen-project/xen/read_gate_descriptor",
        "description": "An issue was discovered in Xen through 4.12.x allowing 32-bit PV guest OS users to gain guest OS privileges by installing and using descriptors. There is missing descriptor table limit checking in x86 PV emulation. When emulating certain PV guest operations, descriptor table accesses are performed by the emulating code. Such accesses should respect the guest specified limits, unless otherwise guaranteed to fail in such a case. Without this, emulation of 32-bit guest user mode calls through call gates would allow guest user mode to install and then use descriptors of their choice, as long as the guest kernel did not itself install an LDT. (Most OSes don't install any LDT by default). 32-bit PV guest user mode can elevate its privileges to that of the guest kernel. Xen versions from at least 3.2 onwards are affected. Only 32-bit PV guest user mode can leverage this vulnerability. HVM, PVH, as well as 64-bit PV guests cannot leverage this vulnerability. Arm systems are unaffected.",
        "git_url": "https://github.com/xen-project/xen/commit/93021cbe880a8013691a48d0febef8ed7d3e3ebd",
        "commit_title": "x86/PV: check GDT/LDT limits during emulation",
        "commit_text": " Accesses beyond the LDT limit originating from emulation would trigger the ASSERT() in pv_map_ldt_shadow_page(). On production builds such accesses would cause an attempt to promote the touched page (offset from the present LDT base address) to a segment descriptor one. If this happens to succeed, guest user mode would be able to elevate its privileges to that of the guest kernel. This is particularly easy when there's no LDT at all, in which case the LDT base stored internally to Xen is simply zero.  Also adjust the ASSERT() that was triggering: It was off by one to begin with, and for production builds we also better use ASSERT_UNREACHABLE() instead with suitable recovery code afterwards.  This is XSA-298. ",
        "func_before": "static int read_gate_descriptor(unsigned int gate_sel,\n                                const struct vcpu *v,\n                                unsigned int *sel,\n                                unsigned long *off,\n                                unsigned int *ar)\n{\n    seg_desc_t desc;\n    const seg_desc_t *pdesc = gdt_ldt_desc_ptr(gate_sel);\n\n    if ( (gate_sel < 4) ||\n         ((gate_sel >= FIRST_RESERVED_GDT_BYTE) && !(gate_sel & 4)) ||\n         __get_user(desc, pdesc) )\n        return 0;\n\n    *sel = (desc.a >> 16) & 0x0000fffc;\n    *off = (desc.a & 0x0000ffff) | (desc.b & 0xffff0000);\n    *ar = desc.b & 0x0000ffff;\n\n    /*\n     * check_descriptor() clears the DPL field and stores the\n     * guest requested DPL in the selector's RPL field.\n     */\n    if ( *ar & _SEGMENT_DPL )\n        return 0;\n    *ar |= (desc.a >> (16 - 13)) & _SEGMENT_DPL;\n\n    if ( !is_pv_32bit_vcpu(v) )\n    {\n        if ( (*ar & 0x1f00) != 0x0c00 ||\n             (gate_sel >= FIRST_RESERVED_GDT_BYTE - 8 && !(gate_sel & 4)) ||\n             __get_user(desc, pdesc + 1) ||\n             (desc.b & 0x1f00) )\n            return 0;\n\n        *off |= (unsigned long)desc.a << 32;\n        return 1;\n    }\n\n    switch ( *ar & 0x1f00 )\n    {\n    case 0x0400:\n        *off &= 0xffff;\n        break;\n    case 0x0c00:\n        break;\n    default:\n        return 0;\n    }\n\n    return 1;\n}",
        "func": "static int read_gate_descriptor(unsigned int gate_sel,\n                                const struct vcpu *v,\n                                unsigned int *sel,\n                                unsigned long *off,\n                                unsigned int *ar)\n{\n    seg_desc_t desc;\n    const seg_desc_t *pdesc = gdt_ldt_desc_ptr(gate_sel);\n\n    if ( (gate_sel < 4) ||\n         /*\n          * We're interested in call gates only, which occupy a single\n          * seg_desc_t for 32-bit and a consecutive pair of them for 64-bit.\n          */\n         ((gate_sel >> 3) + !is_pv_32bit_vcpu(v) >=\n          (gate_sel & 4 ? v->arch.pv.ldt_ents\n                        : v->arch.pv.gdt_ents)) ||\n         __get_user(desc, pdesc) )\n        return 0;\n\n    *sel = (desc.a >> 16) & 0x0000fffc;\n    *off = (desc.a & 0x0000ffff) | (desc.b & 0xffff0000);\n    *ar = desc.b & 0x0000ffff;\n\n    /*\n     * check_descriptor() clears the DPL field and stores the\n     * guest requested DPL in the selector's RPL field.\n     */\n    if ( *ar & _SEGMENT_DPL )\n        return 0;\n    *ar |= (desc.a >> (16 - 13)) & _SEGMENT_DPL;\n\n    if ( !is_pv_32bit_vcpu(v) )\n    {\n        if ( (*ar & 0x1f00) != 0x0c00 ||\n             /* Limit check done above already. */\n             __get_user(desc, pdesc + 1) ||\n             (desc.b & 0x1f00) )\n            return 0;\n\n        *off |= (unsigned long)desc.a << 32;\n        return 1;\n    }\n\n    switch ( *ar & 0x1f00 )\n    {\n    case 0x0400:\n        *off &= 0xffff;\n        break;\n    case 0x0c00:\n        break;\n    default:\n        return 0;\n    }\n\n    return 1;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -8,7 +8,13 @@\n     const seg_desc_t *pdesc = gdt_ldt_desc_ptr(gate_sel);\n \n     if ( (gate_sel < 4) ||\n-         ((gate_sel >= FIRST_RESERVED_GDT_BYTE) && !(gate_sel & 4)) ||\n+         /*\n+          * We're interested in call gates only, which occupy a single\n+          * seg_desc_t for 32-bit and a consecutive pair of them for 64-bit.\n+          */\n+         ((gate_sel >> 3) + !is_pv_32bit_vcpu(v) >=\n+          (gate_sel & 4 ? v->arch.pv.ldt_ents\n+                        : v->arch.pv.gdt_ents)) ||\n          __get_user(desc, pdesc) )\n         return 0;\n \n@@ -27,7 +33,7 @@\n     if ( !is_pv_32bit_vcpu(v) )\n     {\n         if ( (*ar & 0x1f00) != 0x0c00 ||\n-             (gate_sel >= FIRST_RESERVED_GDT_BYTE - 8 && !(gate_sel & 4)) ||\n+             /* Limit check done above already. */\n              __get_user(desc, pdesc + 1) ||\n              (desc.b & 0x1f00) )\n             return 0;",
        "diff_line_info": {
            "deleted_lines": [
                "         ((gate_sel >= FIRST_RESERVED_GDT_BYTE) && !(gate_sel & 4)) ||",
                "             (gate_sel >= FIRST_RESERVED_GDT_BYTE - 8 && !(gate_sel & 4)) ||"
            ],
            "added_lines": [
                "         /*",
                "          * We're interested in call gates only, which occupy a single",
                "          * seg_desc_t for 32-bit and a consecutive pair of them for 64-bit.",
                "          */",
                "         ((gate_sel >> 3) + !is_pv_32bit_vcpu(v) >=",
                "          (gate_sel & 4 ? v->arch.pv.ldt_ents",
                "                        : v->arch.pv.gdt_ents)) ||",
                "             /* Limit check done above already. */"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-13721",
        "func_name": "xorg/xserver/ProcShmCreateSegment",
        "description": "In X.Org Server (aka xserver and xorg-server) before 1.19.4, an attacker authenticated to an X server with the X shared memory extension enabled can cause aborts of the X server or replace shared memory segments of other X clients in the same session.",
        "git_url": "https://cgit.freedesktop.org/xorg/xserver/commit/?id=b95f25af141d33a65f6f821ea9c003f66a01e1f1",
        "commit_title": "Otherwise it can belong to a non-existing client and abort X server with",
        "commit_text": "FatalError \"client not in use\", or overwrite existing segment of another existing client.  ",
        "func_before": "static int\nProcShmCreateSegment(ClientPtr client)\n{\n    int fd;\n    ShmDescPtr shmdesc;\n    REQUEST(xShmCreateSegmentReq);\n    xShmCreateSegmentReply rep = {\n        .type = X_Reply,\n        .nfd = 1,\n        .sequenceNumber = client->sequence,\n        .length = 0,\n    };\n\n    REQUEST_SIZE_MATCH(xShmCreateSegmentReq);\n    if ((stuff->readOnly != xTrue) && (stuff->readOnly != xFalse)) {\n        client->errorValue = stuff->readOnly;\n        return BadValue;\n    }\n    fd = shm_tmpfile();\n    if (fd < 0)\n        return BadAlloc;\n    if (ftruncate(fd, stuff->size) < 0) {\n        close(fd);\n        return BadAlloc;\n    }\n    shmdesc = malloc(sizeof(ShmDescRec));\n    if (!shmdesc) {\n        close(fd);\n        return BadAlloc;\n    }\n    shmdesc->is_fd = TRUE;\n    shmdesc->addr = mmap(NULL, stuff->size,\n                         stuff->readOnly ? PROT_READ : PROT_READ|PROT_WRITE,\n                         MAP_SHARED,\n                         fd, 0);\n\n    if (shmdesc->addr == ((char *) -1)) {\n        close(fd);\n        free(shmdesc);\n        return BadAccess;\n    }\n\n    shmdesc->refcnt = 1;\n    shmdesc->writable = !stuff->readOnly;\n    shmdesc->size = stuff->size;\n\n    shmdesc->busfault = busfault_register_mmap(shmdesc->addr, shmdesc->size, ShmBusfaultNotify, shmdesc);\n    if (!shmdesc->busfault) {\n        close(fd);\n        munmap(shmdesc->addr, shmdesc->size);\n        free(shmdesc);\n        return BadAlloc;\n    }\n\n    shmdesc->next = Shmsegs;\n    Shmsegs = shmdesc;\n\n    if (!AddResource(stuff->shmseg, ShmSegType, (void *) shmdesc)) {\n        close(fd);\n        return BadAlloc;\n    }\n\n    if (WriteFdToClient(client, fd, TRUE) < 0) {\n        FreeResource(stuff->shmseg, RT_NONE);\n        close(fd);\n        return BadAlloc;\n    }\n    WriteToClient(client, sizeof (xShmCreateSegmentReply), &rep);\n    return Success;\n}",
        "func": "static int\nProcShmCreateSegment(ClientPtr client)\n{\n    int fd;\n    ShmDescPtr shmdesc;\n    REQUEST(xShmCreateSegmentReq);\n    xShmCreateSegmentReply rep = {\n        .type = X_Reply,\n        .nfd = 1,\n        .sequenceNumber = client->sequence,\n        .length = 0,\n    };\n\n    REQUEST_SIZE_MATCH(xShmCreateSegmentReq);\n    LEGAL_NEW_RESOURCE(stuff->shmseg, client);\n    if ((stuff->readOnly != xTrue) && (stuff->readOnly != xFalse)) {\n        client->errorValue = stuff->readOnly;\n        return BadValue;\n    }\n    fd = shm_tmpfile();\n    if (fd < 0)\n        return BadAlloc;\n    if (ftruncate(fd, stuff->size) < 0) {\n        close(fd);\n        return BadAlloc;\n    }\n    shmdesc = malloc(sizeof(ShmDescRec));\n    if (!shmdesc) {\n        close(fd);\n        return BadAlloc;\n    }\n    shmdesc->is_fd = TRUE;\n    shmdesc->addr = mmap(NULL, stuff->size,\n                         stuff->readOnly ? PROT_READ : PROT_READ|PROT_WRITE,\n                         MAP_SHARED,\n                         fd, 0);\n\n    if (shmdesc->addr == ((char *) -1)) {\n        close(fd);\n        free(shmdesc);\n        return BadAccess;\n    }\n\n    shmdesc->refcnt = 1;\n    shmdesc->writable = !stuff->readOnly;\n    shmdesc->size = stuff->size;\n\n    shmdesc->busfault = busfault_register_mmap(shmdesc->addr, shmdesc->size, ShmBusfaultNotify, shmdesc);\n    if (!shmdesc->busfault) {\n        close(fd);\n        munmap(shmdesc->addr, shmdesc->size);\n        free(shmdesc);\n        return BadAlloc;\n    }\n\n    shmdesc->next = Shmsegs;\n    Shmsegs = shmdesc;\n\n    if (!AddResource(stuff->shmseg, ShmSegType, (void *) shmdesc)) {\n        close(fd);\n        return BadAlloc;\n    }\n\n    if (WriteFdToClient(client, fd, TRUE) < 0) {\n        FreeResource(stuff->shmseg, RT_NONE);\n        close(fd);\n        return BadAlloc;\n    }\n    WriteToClient(client, sizeof (xShmCreateSegmentReply), &rep);\n    return Success;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -12,6 +12,7 @@\n     };\n \n     REQUEST_SIZE_MATCH(xShmCreateSegmentReq);\n+    LEGAL_NEW_RESOURCE(stuff->shmseg, client);\n     if ((stuff->readOnly != xTrue) && (stuff->readOnly != xFalse)) {\n         client->errorValue = stuff->readOnly;\n         return BadValue;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    LEGAL_NEW_RESOURCE(stuff->shmseg, client);"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-0185",
        "func_name": "php/php-src/fpm_unix_resolve_socket_premissions",
        "description": "sapi/fpm/fpm/fpm_unix.c in the FastCGI Process Manager (FPM) in PHP before 5.4.28 and 5.5.x before 5.5.12 uses 0666 permissions for the UNIX socket, which allows local users to gain privileges via a crafted FastCGI client.",
        "git_url": "https://github.com/php/php-src/commit/35ceea928b12373a3b1e3eecdc32ed323223a40d",
        "commit_title": "Fix bug #67060: use default mode of 660",
        "commit_text": "",
        "func_before": "int fpm_unix_resolve_socket_premissions(struct fpm_worker_pool_s *wp) /* {{{ */\n{\n\tstruct fpm_worker_pool_config_s *c = wp->config;\n\n\t/* uninitialized */\n\twp->socket_uid = -1;\n\twp->socket_gid = -1;\n\twp->socket_mode = 0666;\n\n\tif (!c) {\n\t\treturn 0;\n\t}\n\n\tif (c->listen_owner && *c->listen_owner) {\n\t\tstruct passwd *pwd;\n\n\t\tpwd = getpwnam(c->listen_owner);\n\t\tif (!pwd) {\n\t\t\tzlog(ZLOG_SYSERROR, \"[pool %s] cannot get uid for user '%s'\", wp->config->name, c->listen_owner);\n\t\t\treturn -1;\n\t\t}\n\n\t\twp->socket_uid = pwd->pw_uid;\n\t\twp->socket_gid = pwd->pw_gid;\n\t}\n\n\tif (c->listen_group && *c->listen_group) {\n\t\tstruct group *grp;\n\n\t\tgrp = getgrnam(c->listen_group);\n\t\tif (!grp) {\n\t\t\tzlog(ZLOG_SYSERROR, \"[pool %s] cannot get gid for group '%s'\", wp->config->name, c->listen_group);\n\t\t\treturn -1;\n\t\t}\n\t\twp->socket_gid = grp->gr_gid;\n\t}\n\n\tif (c->listen_mode && *c->listen_mode) {\n\t\twp->socket_mode = strtoul(c->listen_mode, 0, 8);\n\t}\n\treturn 0;\n}",
        "func": "int fpm_unix_resolve_socket_premissions(struct fpm_worker_pool_s *wp) /* {{{ */\n{\n\tstruct fpm_worker_pool_config_s *c = wp->config;\n\n\t/* uninitialized */\n\twp->socket_uid = -1;\n\twp->socket_gid = -1;\n\twp->socket_mode = 0660;\n\n\tif (!c) {\n\t\treturn 0;\n\t}\n\n\tif (c->listen_owner && *c->listen_owner) {\n\t\tstruct passwd *pwd;\n\n\t\tpwd = getpwnam(c->listen_owner);\n\t\tif (!pwd) {\n\t\t\tzlog(ZLOG_SYSERROR, \"[pool %s] cannot get uid for user '%s'\", wp->config->name, c->listen_owner);\n\t\t\treturn -1;\n\t\t}\n\n\t\twp->socket_uid = pwd->pw_uid;\n\t\twp->socket_gid = pwd->pw_gid;\n\t}\n\n\tif (c->listen_group && *c->listen_group) {\n\t\tstruct group *grp;\n\n\t\tgrp = getgrnam(c->listen_group);\n\t\tif (!grp) {\n\t\t\tzlog(ZLOG_SYSERROR, \"[pool %s] cannot get gid for group '%s'\", wp->config->name, c->listen_group);\n\t\t\treturn -1;\n\t\t}\n\t\twp->socket_gid = grp->gr_gid;\n\t}\n\n\tif (c->listen_mode && *c->listen_mode) {\n\t\twp->socket_mode = strtoul(c->listen_mode, 0, 8);\n\t}\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,7 +5,7 @@\n \t/* uninitialized */\n \twp->socket_uid = -1;\n \twp->socket_gid = -1;\n-\twp->socket_mode = 0666;\n+\twp->socket_mode = 0660;\n \n \tif (!c) {\n \t\treturn 0;",
        "diff_line_info": {
            "deleted_lines": [
                "\twp->socket_mode = 0666;"
            ],
            "added_lines": [
                "\twp->socket_mode = 0660;"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-4943",
        "func_name": "torvalds/linux/pppol2tp_getsockopt",
        "description": "The PPPoL2TP feature in net/l2tp/l2tp_ppp.c in the Linux kernel through 3.15.6 allows local users to gain privileges by leveraging data-structure differences between an l2tp socket and an inet socket.",
        "git_url": "https://github.com/torvalds/linux/commit/3cf521f7dc87c031617fd47e4b7aa2593c2f3daf",
        "commit_title": "net/l2tp: don't fall back on UDP [get|set]sockopt",
        "commit_text": " The l2tp [get|set]sockopt() code has fallen back to the UDP functions for socket option levels != SOL_PPPOL2TP since day one, but that has never actually worked, since the l2tp socket isn't an inet socket.  As David Miller points out:    \"If we wanted this to work, it'd have to look up the tunnel and then    use tunnel->sk, but I wonder how useful that would be\"  Since this can never have worked so nobody could possibly have depended on that functionality, just remove the broken code and return -EINVAL.  Cc: Phil Turnbull <phil.turnbull@oracle.com> Cc: Vegard Nossum <vegard.nossum@oracle.com> Cc: Willy Tarreau <w@1wt.eu> Cc: stable@vger.kernel.org",
        "func_before": "static int pppol2tp_getsockopt(struct socket *sock, int level, int optname,\n\t\t\t       char __user *optval, int __user *optlen)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct l2tp_session *session;\n\tstruct l2tp_tunnel *tunnel;\n\tint val, len;\n\tint err;\n\tstruct pppol2tp_session *ps;\n\n\tif (level != SOL_PPPOL2TP)\n\t\treturn udp_prot.getsockopt(sk, level, optname, optval, optlen);\n\n\tif (get_user(len, optlen))\n\t\treturn -EFAULT;\n\n\tlen = min_t(unsigned int, len, sizeof(int));\n\n\tif (len < 0)\n\t\treturn -EINVAL;\n\n\terr = -ENOTCONN;\n\tif (sk->sk_user_data == NULL)\n\t\tgoto end;\n\n\t/* Get the session context */\n\terr = -EBADF;\n\tsession = pppol2tp_sock_to_session(sk);\n\tif (session == NULL)\n\t\tgoto end;\n\n\t/* Special case: if session_id == 0x0000, treat as operation on tunnel */\n\tps = l2tp_session_priv(session);\n\tif ((session->session_id == 0) &&\n\t    (session->peer_session_id == 0)) {\n\t\terr = -EBADF;\n\t\ttunnel = l2tp_sock_to_tunnel(ps->tunnel_sock);\n\t\tif (tunnel == NULL)\n\t\t\tgoto end_put_sess;\n\n\t\terr = pppol2tp_tunnel_getsockopt(sk, tunnel, optname, &val);\n\t\tsock_put(ps->tunnel_sock);\n\t} else\n\t\terr = pppol2tp_session_getsockopt(sk, session, optname, &val);\n\n\terr = -EFAULT;\n\tif (put_user(len, optlen))\n\t\tgoto end_put_sess;\n\n\tif (copy_to_user((void __user *) optval, &val, len))\n\t\tgoto end_put_sess;\n\n\terr = 0;\n\nend_put_sess:\n\tsock_put(sk);\nend:\n\treturn err;\n}",
        "func": "static int pppol2tp_getsockopt(struct socket *sock, int level, int optname,\n\t\t\t       char __user *optval, int __user *optlen)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct l2tp_session *session;\n\tstruct l2tp_tunnel *tunnel;\n\tint val, len;\n\tint err;\n\tstruct pppol2tp_session *ps;\n\n\tif (level != SOL_PPPOL2TP)\n\t\treturn -EINVAL;\n\n\tif (get_user(len, optlen))\n\t\treturn -EFAULT;\n\n\tlen = min_t(unsigned int, len, sizeof(int));\n\n\tif (len < 0)\n\t\treturn -EINVAL;\n\n\terr = -ENOTCONN;\n\tif (sk->sk_user_data == NULL)\n\t\tgoto end;\n\n\t/* Get the session context */\n\terr = -EBADF;\n\tsession = pppol2tp_sock_to_session(sk);\n\tif (session == NULL)\n\t\tgoto end;\n\n\t/* Special case: if session_id == 0x0000, treat as operation on tunnel */\n\tps = l2tp_session_priv(session);\n\tif ((session->session_id == 0) &&\n\t    (session->peer_session_id == 0)) {\n\t\terr = -EBADF;\n\t\ttunnel = l2tp_sock_to_tunnel(ps->tunnel_sock);\n\t\tif (tunnel == NULL)\n\t\t\tgoto end_put_sess;\n\n\t\terr = pppol2tp_tunnel_getsockopt(sk, tunnel, optname, &val);\n\t\tsock_put(ps->tunnel_sock);\n\t} else\n\t\terr = pppol2tp_session_getsockopt(sk, session, optname, &val);\n\n\terr = -EFAULT;\n\tif (put_user(len, optlen))\n\t\tgoto end_put_sess;\n\n\tif (copy_to_user((void __user *) optval, &val, len))\n\t\tgoto end_put_sess;\n\n\terr = 0;\n\nend_put_sess:\n\tsock_put(sk);\nend:\n\treturn err;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -9,7 +9,7 @@\n \tstruct pppol2tp_session *ps;\n \n \tif (level != SOL_PPPOL2TP)\n-\t\treturn udp_prot.getsockopt(sk, level, optname, optval, optlen);\n+\t\treturn -EINVAL;\n \n \tif (get_user(len, optlen))\n \t\treturn -EFAULT;",
        "diff_line_info": {
            "deleted_lines": [
                "\t\treturn udp_prot.getsockopt(sk, level, optname, optval, optlen);"
            ],
            "added_lines": [
                "\t\treturn -EINVAL;"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-4943",
        "func_name": "torvalds/linux/pppol2tp_setsockopt",
        "description": "The PPPoL2TP feature in net/l2tp/l2tp_ppp.c in the Linux kernel through 3.15.6 allows local users to gain privileges by leveraging data-structure differences between an l2tp socket and an inet socket.",
        "git_url": "https://github.com/torvalds/linux/commit/3cf521f7dc87c031617fd47e4b7aa2593c2f3daf",
        "commit_title": "net/l2tp: don't fall back on UDP [get|set]sockopt",
        "commit_text": " The l2tp [get|set]sockopt() code has fallen back to the UDP functions for socket option levels != SOL_PPPOL2TP since day one, but that has never actually worked, since the l2tp socket isn't an inet socket.  As David Miller points out:    \"If we wanted this to work, it'd have to look up the tunnel and then    use tunnel->sk, but I wonder how useful that would be\"  Since this can never have worked so nobody could possibly have depended on that functionality, just remove the broken code and return -EINVAL.  Cc: Phil Turnbull <phil.turnbull@oracle.com> Cc: Vegard Nossum <vegard.nossum@oracle.com> Cc: Willy Tarreau <w@1wt.eu> Cc: stable@vger.kernel.org",
        "func_before": "static int pppol2tp_setsockopt(struct socket *sock, int level, int optname,\n\t\t\t       char __user *optval, unsigned int optlen)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct l2tp_session *session;\n\tstruct l2tp_tunnel *tunnel;\n\tstruct pppol2tp_session *ps;\n\tint val;\n\tint err;\n\n\tif (level != SOL_PPPOL2TP)\n\t\treturn udp_prot.setsockopt(sk, level, optname, optval, optlen);\n\n\tif (optlen < sizeof(int))\n\t\treturn -EINVAL;\n\n\tif (get_user(val, (int __user *)optval))\n\t\treturn -EFAULT;\n\n\terr = -ENOTCONN;\n\tif (sk->sk_user_data == NULL)\n\t\tgoto end;\n\n\t/* Get session context from the socket */\n\terr = -EBADF;\n\tsession = pppol2tp_sock_to_session(sk);\n\tif (session == NULL)\n\t\tgoto end;\n\n\t/* Special case: if session_id == 0x0000, treat as operation on tunnel\n\t */\n\tps = l2tp_session_priv(session);\n\tif ((session->session_id == 0) &&\n\t    (session->peer_session_id == 0)) {\n\t\terr = -EBADF;\n\t\ttunnel = l2tp_sock_to_tunnel(ps->tunnel_sock);\n\t\tif (tunnel == NULL)\n\t\t\tgoto end_put_sess;\n\n\t\terr = pppol2tp_tunnel_setsockopt(sk, tunnel, optname, val);\n\t\tsock_put(ps->tunnel_sock);\n\t} else\n\t\terr = pppol2tp_session_setsockopt(sk, session, optname, val);\n\n\terr = 0;\n\nend_put_sess:\n\tsock_put(sk);\nend:\n\treturn err;\n}",
        "func": "static int pppol2tp_setsockopt(struct socket *sock, int level, int optname,\n\t\t\t       char __user *optval, unsigned int optlen)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct l2tp_session *session;\n\tstruct l2tp_tunnel *tunnel;\n\tstruct pppol2tp_session *ps;\n\tint val;\n\tint err;\n\n\tif (level != SOL_PPPOL2TP)\n\t\treturn -EINVAL;\n\n\tif (optlen < sizeof(int))\n\t\treturn -EINVAL;\n\n\tif (get_user(val, (int __user *)optval))\n\t\treturn -EFAULT;\n\n\terr = -ENOTCONN;\n\tif (sk->sk_user_data == NULL)\n\t\tgoto end;\n\n\t/* Get session context from the socket */\n\terr = -EBADF;\n\tsession = pppol2tp_sock_to_session(sk);\n\tif (session == NULL)\n\t\tgoto end;\n\n\t/* Special case: if session_id == 0x0000, treat as operation on tunnel\n\t */\n\tps = l2tp_session_priv(session);\n\tif ((session->session_id == 0) &&\n\t    (session->peer_session_id == 0)) {\n\t\terr = -EBADF;\n\t\ttunnel = l2tp_sock_to_tunnel(ps->tunnel_sock);\n\t\tif (tunnel == NULL)\n\t\t\tgoto end_put_sess;\n\n\t\terr = pppol2tp_tunnel_setsockopt(sk, tunnel, optname, val);\n\t\tsock_put(ps->tunnel_sock);\n\t} else\n\t\terr = pppol2tp_session_setsockopt(sk, session, optname, val);\n\n\terr = 0;\n\nend_put_sess:\n\tsock_put(sk);\nend:\n\treturn err;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -9,7 +9,7 @@\n \tint err;\n \n \tif (level != SOL_PPPOL2TP)\n-\t\treturn udp_prot.setsockopt(sk, level, optname, optval, optlen);\n+\t\treturn -EINVAL;\n \n \tif (optlen < sizeof(int))\n \t\treturn -EINVAL;",
        "diff_line_info": {
            "deleted_lines": [
                "\t\treturn udp_prot.setsockopt(sk, level, optname, optval, optlen);"
            ],
            "added_lines": [
                "\t\treturn -EINVAL;"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-15862",
        "func_name": "net-snmp/handle_nsExtendConfigTable",
        "description": "Net-SNMP through 5.8 has Improper Privilege Management because SNMP WRITE access to the EXTEND MIB provides the ability to run arbitrary commands as root.",
        "git_url": "https://github.com/net-snmp/net-snmp/commit/77f6c60f57dba0aaea5d8ef1dd94bcd0c8e6d205",
        "commit_title": "make the extend mib read-only by default",
        "commit_text": "",
        "func_before": "int\nhandle_nsExtendConfigTable(netsnmp_mib_handler          *handler,\n                     netsnmp_handler_registration *reginfo,\n                     netsnmp_agent_request_info   *reqinfo,\n                     netsnmp_request_info         *requests)\n{\n    netsnmp_request_info       *request;\n    netsnmp_table_request_info *table_info;\n    netsnmp_extend             *extension;\n    extend_registration_block  *eptr;\n    int  i;\n    int  need_to_validate = 0;\n\n    for ( request=requests; request; request=request->next ) {\n        if (request->processed)\n            continue;\n        table_info = netsnmp_extract_table_info( request );\n        extension  = (netsnmp_extend*)netsnmp_extract_table_row_data( request );\n\n        DEBUGMSGTL(( \"nsExtendTable:config\", \"varbind: \"));\n        DEBUGMSGOID((\"nsExtendTable:config\", request->requestvb->name,\n                                             request->requestvb->name_length));\n        DEBUGMSG((   \"nsExtendTable:config\", \" (%s)\\n\",\n                      se_find_label_in_slist(\"agent_mode\", reqinfo->mode)));\n\n        switch (reqinfo->mode) {\n        case MODE_GET:\n            switch (table_info->colnum) {\n            case COLUMN_EXTCFG_COMMAND:\n                snmp_set_var_typed_value(\n                     request->requestvb, ASN_OCTET_STR,\n                     extension->command,\n                    (extension->command)?strlen(extension->command):0);\n                break;\n            case COLUMN_EXTCFG_ARGS:\n                snmp_set_var_typed_value(\n                     request->requestvb, ASN_OCTET_STR,\n                     extension->args,\n                    (extension->args)?strlen(extension->args):0);\n                break;\n            case COLUMN_EXTCFG_INPUT:\n                snmp_set_var_typed_value(\n                     request->requestvb, ASN_OCTET_STR,\n                     extension->input,\n                    (extension->input)?strlen(extension->input):0);\n                break;\n            case COLUMN_EXTCFG_CACHETIME:\n                snmp_set_var_typed_value(\n                     request->requestvb, ASN_INTEGER,\n                    (u_char*)&extension->cache->timeout, sizeof(int));\n                break;\n            case COLUMN_EXTCFG_EXECTYPE:\n                i = ((extension->flags & NS_EXTEND_FLAGS_SHELL) ?\n                                         NS_EXTEND_ETYPE_SHELL :\n                                         NS_EXTEND_ETYPE_EXEC);\n                snmp_set_var_typed_value(\n                     request->requestvb, ASN_INTEGER,\n                    (u_char*)&i, sizeof(i));\n                break;\n            case COLUMN_EXTCFG_RUNTYPE:\n                i = ((extension->flags & NS_EXTEND_FLAGS_WRITEABLE) ?\n                                         NS_EXTEND_RTYPE_RWRITE :\n                                         NS_EXTEND_RTYPE_RONLY);\n                snmp_set_var_typed_value(\n                     request->requestvb, ASN_INTEGER,\n                    (u_char*)&i, sizeof(i));\n                break;\n\n            case COLUMN_EXTCFG_STORAGE:\n                i = ((extension->flags & NS_EXTEND_FLAGS_CONFIG) ?\n                                         ST_PERMANENT : ST_VOLATILE);\n                snmp_set_var_typed_value(\n                     request->requestvb, ASN_INTEGER,\n                    (u_char*)&i, sizeof(i));\n                break;\n            case COLUMN_EXTCFG_STATUS:\n                i = ((extension->flags & NS_EXTEND_FLAGS_ACTIVE) ?\n                                         RS_ACTIVE :\n                                         RS_NOTINSERVICE);\n                snmp_set_var_typed_value(\n                     request->requestvb, ASN_INTEGER,\n                    (u_char*)&i, sizeof(i));\n                break;\n\n            default:\n                netsnmp_set_request_error(reqinfo, request, SNMP_NOSUCHOBJECT);\n                continue;\n            }\n            break;\n\n        /**********\n         *\n         * Start of SET handling\n         *\n         *   All config objects are potentially writable except\n         *     nsExtendStorage which is fixed as either 'permanent'\n         *     (if read from a config file) or 'volatile' (if set via SNMP)\n         *   The string-based settings of a 'permanent' entry cannot \n         *     be changed - neither can the execution or run type.\n         *   Such entries can be (temporarily) marked as inactive,\n         *     and the cache timeout adjusted, but these changes are\n         *     not persistent.\n         *\n         **********/\n\n#ifndef NETSNMP_NO_WRITE_SUPPORT\n        case MODE_SET_RESERVE1:\n            /*\n             * Validate the new assignments\n             */\n            switch (table_info->colnum) {\n            case COLUMN_EXTCFG_COMMAND:\n                if (request->requestvb->type != ASN_OCTET_STR) {\n                    netsnmp_set_request_error(reqinfo, request,\n                                              SNMP_ERR_WRONGTYPE);\n                    return SNMP_ERR_WRONGTYPE;\n                }\n                /*\n                 * Must have a full path to the command\n                 * XXX - Assumes Unix-style paths\n                 */\n                if (request->requestvb->val_len == 0 ||\n                    request->requestvb->val.string[0] != '/') {\n                    netsnmp_set_request_error(reqinfo, request,\n                                              SNMP_ERR_WRONGVALUE);\n                    return SNMP_ERR_WRONGVALUE;\n                }\n                /*\n                 * XXX - need to check this file exists\n                 *       (and is executable)\n                 */\n\n                if (extension && extension->flags & NS_EXTEND_FLAGS_CONFIG) {\n                    /*\n                     * config entries are \"permanent\" so can't be changed\n                     */\n                    netsnmp_set_request_error(reqinfo, request,\n                                              SNMP_ERR_NOTWRITABLE);\n                    return SNMP_ERR_NOTWRITABLE;\n                }\n                break;\n\n            case COLUMN_EXTCFG_ARGS:\n            case COLUMN_EXTCFG_INPUT:\n                if (request->requestvb->type != ASN_OCTET_STR) {\n                    netsnmp_set_request_error(reqinfo, request,\n                                              SNMP_ERR_WRONGTYPE);\n                    return SNMP_ERR_WRONGTYPE;\n                }\n\n                if (extension && extension->flags & NS_EXTEND_FLAGS_CONFIG) {\n                    /*\n                     * config entries are \"permanent\" so can't be changed\n                     */\n                    netsnmp_set_request_error(reqinfo, request,\n                                              SNMP_ERR_NOTWRITABLE);\n                    return SNMP_ERR_NOTWRITABLE;\n                }\n                break;\n\n            case COLUMN_EXTCFG_CACHETIME:\n                if (request->requestvb->type != ASN_INTEGER) {\n                    netsnmp_set_request_error(reqinfo, request,\n                                              SNMP_ERR_WRONGTYPE);\n                    return SNMP_ERR_WRONGTYPE;\n                }\n                i = *request->requestvb->val.integer;\n                /*\n                 * -1 is a special value indicating \"don't cache\"\n                 *    [[ XXX - should this be 0 ?? ]]\n                 * Otherwise, cache times must be non-negative\n                 */\n                if (i < -1 ) {\n                    netsnmp_set_request_error(reqinfo, request,\n                                              SNMP_ERR_WRONGVALUE);\n                    return SNMP_ERR_WRONGVALUE;\n                }\n                break;\n\n            case COLUMN_EXTCFG_EXECTYPE:\n                if (request->requestvb->type != ASN_INTEGER) {\n                    netsnmp_set_request_error(reqinfo, request,\n                                              SNMP_ERR_WRONGTYPE);\n                    return SNMP_ERR_WRONGTYPE;\n                }\n                i = *request->requestvb->val.integer;\n                if (i<1 || i>2) {  /* 'exec(1)' or 'shell(2)' only */\n                    netsnmp_set_request_error(reqinfo, request,\n                                              SNMP_ERR_WRONGVALUE);\n                    return SNMP_ERR_WRONGVALUE;\n                }\n                if (extension && extension->flags & NS_EXTEND_FLAGS_CONFIG) {\n                    /*\n                     * config entries are \"permanent\" so can't be changed\n                     */\n                    netsnmp_set_request_error(reqinfo, request,\n                                              SNMP_ERR_NOTWRITABLE);\n                    return SNMP_ERR_NOTWRITABLE;\n                }\n                break;\n\n            case COLUMN_EXTCFG_RUNTYPE:\n                if (request->requestvb->type != ASN_INTEGER) {\n                    netsnmp_set_request_error(reqinfo, request,\n                                              SNMP_ERR_WRONGTYPE);\n                    return SNMP_ERR_WRONGTYPE;\n                }\n                /*\n                 * 'run-on-read(1)', 'run-on-set(2)'\n                 *  or 'run-command(3)' only\n                 */\n                i = *request->requestvb->val.integer;\n                if (i<1 || i>3) {\n                    netsnmp_set_request_error(reqinfo, request,\n                                              SNMP_ERR_WRONGVALUE);\n                    return SNMP_ERR_WRONGVALUE;\n                }\n                /*\n                 * 'run-command(3)' can only be used with\n                 *  a pre-existing 'run-on-set(2)' entry.\n                 */\n                if (i==3 && !(extension && (extension->flags & NS_EXTEND_FLAGS_WRITEABLE))) {\n                    netsnmp_set_request_error(reqinfo, request,\n                                              SNMP_ERR_INCONSISTENTVALUE);\n                    return SNMP_ERR_INCONSISTENTVALUE;\n                }\n                /*\n                 * 'run-command(3)' is the only valid assignment\n                 *  for permanent (i.e. config) entries\n                 */\n                if ((extension && extension->flags & NS_EXTEND_FLAGS_CONFIG)\n                    && i!=3 ) {\n                    netsnmp_set_request_error(reqinfo, request,\n                                              SNMP_ERR_INCONSISTENTVALUE);\n                    return SNMP_ERR_INCONSISTENTVALUE;\n                }\n                break;\n\n            case COLUMN_EXTCFG_STATUS:\n                if (request->requestvb->type != ASN_INTEGER) {\n                    netsnmp_set_request_error(reqinfo, request,\n                                              SNMP_ERR_WRONGTYPE);\n                    return SNMP_ERR_WRONGTYPE;\n                }\n                i = *request->requestvb->val.integer;\n                switch (i) {\n                case RS_ACTIVE:\n                case RS_NOTINSERVICE:\n                    if (!extension) {\n                        /* Must be used with existing rows */\n                        netsnmp_set_request_error(reqinfo, request,\n                                                  SNMP_ERR_INCONSISTENTVALUE);\n                        return SNMP_ERR_INCONSISTENTVALUE;\n                    }\n                    break;    /* OK */\n                case RS_CREATEANDGO:\n                case RS_CREATEANDWAIT:\n                    if (extension) {\n                        /* Can only be used to create new rows */\n                        netsnmp_set_request_error(reqinfo, request,\n                                                  SNMP_ERR_INCONSISTENTVALUE);\n                        return SNMP_ERR_INCONSISTENTVALUE;\n                    }\n                    break;\n                case RS_DESTROY:\n                    break;\n                default:\n                    netsnmp_set_request_error(reqinfo, request,\n                                              SNMP_ERR_WRONGVALUE);\n                    return SNMP_ERR_WRONGVALUE;\n                }\n                break;\n\n            default:\n                netsnmp_set_request_error(reqinfo, request,\n                                          SNMP_ERR_NOTWRITABLE);\n                return SNMP_ERR_NOTWRITABLE;\n            }\n            break;\n\n        case MODE_SET_RESERVE2:\n            switch (table_info->colnum) {\n            case COLUMN_EXTCFG_STATUS:\n                i = *request->requestvb->val.integer;\n                switch (i) {\n                case RS_CREATEANDGO:\n                case RS_CREATEANDWAIT:\n                    eptr = _find_extension_block( request->requestvb->name,\n                                                  request->requestvb->name_length );\n                    extension = _new_extension( (char *) table_info->indexes->val.string,\n                                                0, eptr );\n                    if (!extension) {  /* failed */\n                        netsnmp_set_request_error(reqinfo, request,\n                                                  SNMP_ERR_RESOURCEUNAVAILABLE);\n                        return SNMP_ERR_RESOURCEUNAVAILABLE;\n                    }\n                    netsnmp_insert_table_row( request, extension->row );\n                }\n            }\n            break;\n\n        case MODE_SET_FREE:\n            switch (table_info->colnum) {\n            case COLUMN_EXTCFG_STATUS:\n                i = *request->requestvb->val.integer;\n                switch (i) {\n                case RS_CREATEANDGO:\n                case RS_CREATEANDWAIT:\n                    eptr = _find_extension_block( request->requestvb->name,\n                                                  request->requestvb->name_length );\n                    _free_extension( extension, eptr );\n                }\n            }\n            break;\n\n        case MODE_SET_ACTION:\n            switch (table_info->colnum) {\n            case COLUMN_EXTCFG_COMMAND:\n                extension->old_command = extension->command;\n                extension->command = netsnmp_strdup_and_null(\n                    request->requestvb->val.string,\n                    request->requestvb->val_len);\n                break;\n            case COLUMN_EXTCFG_ARGS:\n                extension->old_args = extension->args;\n                extension->args = netsnmp_strdup_and_null(\n                    request->requestvb->val.string,\n                    request->requestvb->val_len);\n                break;\n            case COLUMN_EXTCFG_INPUT:\n                extension->old_input = extension->input;\n                extension->input = netsnmp_strdup_and_null(\n                    request->requestvb->val.string,\n                    request->requestvb->val_len);\n                break;\n            case COLUMN_EXTCFG_STATUS:\n                i = *request->requestvb->val.integer;\n                switch (i) {\n                case RS_ACTIVE:\n                case RS_CREATEANDGO:\n                    need_to_validate = 1;\n                }\n                break;\n            }\n            break;\n\n        case MODE_SET_UNDO:\n            switch (table_info->colnum) {\n            case COLUMN_EXTCFG_COMMAND:\n                if ( extension && extension->old_command ) {\n                    SNMP_FREE(extension->command);\n                    extension->command     = extension->old_command;\n                    extension->old_command = NULL;\n                }\n                break;\n            case COLUMN_EXTCFG_ARGS:\n                if ( extension && extension->old_args ) {\n                    SNMP_FREE(extension->args);\n                    extension->args     = extension->old_args;\n                    extension->old_args = NULL;\n                }\n                break;\n            case COLUMN_EXTCFG_INPUT:\n                if ( extension && extension->old_input ) {\n                    SNMP_FREE(extension->input);\n                    extension->input     = extension->old_input;\n                    extension->old_input = NULL;\n                }\n                break;\n            case COLUMN_EXTCFG_STATUS:\n                i = *request->requestvb->val.integer;\n                switch (i) {\n                case RS_CREATEANDGO:\n                case RS_CREATEANDWAIT:\n                    eptr = _find_extension_block( request->requestvb->name,\n                                                  request->requestvb->name_length );\n                    _free_extension( extension, eptr );\n                }\n                break;\n            }\n            break;\n\n        case MODE_SET_COMMIT:\n            switch (table_info->colnum) {\n            case COLUMN_EXTCFG_CACHETIME:\n                i = *request->requestvb->val.integer;\n                extension->cache->timeout = i;\n                break;\n\n            case COLUMN_EXTCFG_RUNTYPE:\n                i = *request->requestvb->val.integer;\n                switch (i) {\n                case 1:\n                    extension->flags &= ~NS_EXTEND_FLAGS_WRITEABLE;\n                    break;\n                case 2:\n                    extension->flags |=  NS_EXTEND_FLAGS_WRITEABLE;\n                    break;\n                case 3:\n                    (void)netsnmp_cache_check_and_reload( extension->cache );\n                    break;\n                }\n                break;\n\n            case COLUMN_EXTCFG_EXECTYPE:\n                i = *request->requestvb->val.integer;\n                if ( i == NS_EXTEND_ETYPE_SHELL )\n                    extension->flags |=  NS_EXTEND_FLAGS_SHELL;\n                else\n                    extension->flags &= ~NS_EXTEND_FLAGS_SHELL;\n                break;\n\n            case COLUMN_EXTCFG_STATUS:\n                i = *request->requestvb->val.integer;\n                switch (i) {\n                case RS_ACTIVE:\n                case RS_CREATEANDGO:\n                    extension->flags |= NS_EXTEND_FLAGS_ACTIVE;\n                    break;\n                case RS_NOTINSERVICE:\n                case RS_CREATEANDWAIT:\n                    extension->flags &= ~NS_EXTEND_FLAGS_ACTIVE;\n                    break;\n                case RS_DESTROY:\n                    eptr = _find_extension_block( request->requestvb->name,\n                                                  request->requestvb->name_length );\n                    _free_extension( extension, eptr );\n                    break;\n                }\n            }\n            break;\n#endif /* !NETSNMP_NO_WRITE_SUPPORT */ \n\n        default:\n            netsnmp_set_request_error(reqinfo, request, SNMP_ERR_GENERR);\n            return SNMP_ERR_GENERR;\n        }\n    }\n\n#ifndef NETSNMP_NO_WRITE_SUPPORT\n    /*\n     * If we're marking a given row as active,\n     *  then we need to check that it's ready.\n     */\n    if (need_to_validate) {\n        for ( request=requests; request; request=request->next ) {\n            if (request->processed)\n                continue;\n            table_info = netsnmp_extract_table_info( request );\n            extension  = (netsnmp_extend*)netsnmp_extract_table_row_data( request );\n            switch (table_info->colnum) {\n            case COLUMN_EXTCFG_STATUS:\n                i = *request->requestvb->val.integer;\n                if (( i == RS_ACTIVE || i == RS_CREATEANDGO ) &&\n                    !(extension && extension->command &&\n                      extension->command[0] == '/' /* &&\n                      is_executable(extension->command) */)) {\n                    netsnmp_set_request_error(reqinfo, request,\n                                              SNMP_ERR_INCONSISTENTVALUE);\n                    return SNMP_ERR_INCONSISTENTVALUE;\n                }\n            }\n        }\n    }\n#endif /* !NETSNMP_NO_WRITE_SUPPORT */\n    \n    return SNMP_ERR_NOERROR;\n}",
        "func": "int\nhandle_nsExtendConfigTable(netsnmp_mib_handler          *handler,\n                     netsnmp_handler_registration *reginfo,\n                     netsnmp_agent_request_info   *reqinfo,\n                     netsnmp_request_info         *requests)\n{\n    netsnmp_request_info       *request;\n    netsnmp_table_request_info *table_info;\n    netsnmp_extend             *extension;\n    extend_registration_block  *eptr;\n    int  i;\n    int  need_to_validate = 0;\n\n    for ( request=requests; request; request=request->next ) {\n        if (request->processed)\n            continue;\n        table_info = netsnmp_extract_table_info( request );\n        extension  = (netsnmp_extend*)netsnmp_extract_table_row_data( request );\n\n        DEBUGMSGTL(( \"nsExtendTable:config\", \"varbind: \"));\n        DEBUGMSGOID((\"nsExtendTable:config\", request->requestvb->name,\n                                             request->requestvb->name_length));\n        DEBUGMSG((   \"nsExtendTable:config\", \" (%s)\\n\",\n                      se_find_label_in_slist(\"agent_mode\", reqinfo->mode)));\n\n        switch (reqinfo->mode) {\n        case MODE_GET:\n            switch (table_info->colnum) {\n            case COLUMN_EXTCFG_COMMAND:\n                snmp_set_var_typed_value(\n                     request->requestvb, ASN_OCTET_STR,\n                     extension->command,\n                    (extension->command)?strlen(extension->command):0);\n                break;\n            case COLUMN_EXTCFG_ARGS:\n                snmp_set_var_typed_value(\n                     request->requestvb, ASN_OCTET_STR,\n                     extension->args,\n                    (extension->args)?strlen(extension->args):0);\n                break;\n            case COLUMN_EXTCFG_INPUT:\n                snmp_set_var_typed_value(\n                     request->requestvb, ASN_OCTET_STR,\n                     extension->input,\n                    (extension->input)?strlen(extension->input):0);\n                break;\n            case COLUMN_EXTCFG_CACHETIME:\n                snmp_set_var_typed_value(\n                     request->requestvb, ASN_INTEGER,\n                    (u_char*)&extension->cache->timeout, sizeof(int));\n                break;\n            case COLUMN_EXTCFG_EXECTYPE:\n                i = ((extension->flags & NS_EXTEND_FLAGS_SHELL) ?\n                                         NS_EXTEND_ETYPE_SHELL :\n                                         NS_EXTEND_ETYPE_EXEC);\n                snmp_set_var_typed_value(\n                     request->requestvb, ASN_INTEGER,\n                    (u_char*)&i, sizeof(i));\n                break;\n            case COLUMN_EXTCFG_RUNTYPE:\n                i = ((extension->flags & NS_EXTEND_FLAGS_WRITEABLE) ?\n                                         NS_EXTEND_RTYPE_RWRITE :\n                                         NS_EXTEND_RTYPE_RONLY);\n                snmp_set_var_typed_value(\n                     request->requestvb, ASN_INTEGER,\n                    (u_char*)&i, sizeof(i));\n                break;\n\n            case COLUMN_EXTCFG_STORAGE:\n                i = ((extension->flags & NS_EXTEND_FLAGS_CONFIG) ?\n                                         ST_PERMANENT : ST_VOLATILE);\n                snmp_set_var_typed_value(\n                     request->requestvb, ASN_INTEGER,\n                    (u_char*)&i, sizeof(i));\n                break;\n            case COLUMN_EXTCFG_STATUS:\n                i = ((extension->flags & NS_EXTEND_FLAGS_ACTIVE) ?\n                                         RS_ACTIVE :\n                                         RS_NOTINSERVICE);\n                snmp_set_var_typed_value(\n                     request->requestvb, ASN_INTEGER,\n                    (u_char*)&i, sizeof(i));\n                break;\n\n            default:\n                netsnmp_set_request_error(reqinfo, request, SNMP_NOSUCHOBJECT);\n                continue;\n            }\n            break;\n\n        /**********\n         *\n         * Start of SET handling\n         *\n         *   All config objects are potentially writable except\n         *     nsExtendStorage which is fixed as either 'permanent'\n         *     (if read from a config file) or 'volatile' (if set via SNMP)\n         *   The string-based settings of a 'permanent' entry cannot \n         *     be changed - neither can the execution or run type.\n         *   Such entries can be (temporarily) marked as inactive,\n         *     and the cache timeout adjusted, but these changes are\n         *     not persistent.\n         *\n         **********/\n\n#if !defined(NETSNMP_NO_WRITE_SUPPORT) && ENABLE_EXTEND_WRITE_ACCESS\n        case MODE_SET_RESERVE1:\n            /*\n             * Validate the new assignments\n             */\n            switch (table_info->colnum) {\n            case COLUMN_EXTCFG_COMMAND:\n                if (request->requestvb->type != ASN_OCTET_STR) {\n                    netsnmp_set_request_error(reqinfo, request,\n                                              SNMP_ERR_WRONGTYPE);\n                    return SNMP_ERR_WRONGTYPE;\n                }\n                /*\n                 * Must have a full path to the command\n                 * XXX - Assumes Unix-style paths\n                 */\n                if (request->requestvb->val_len == 0 ||\n                    request->requestvb->val.string[0] != '/') {\n                    netsnmp_set_request_error(reqinfo, request,\n                                              SNMP_ERR_WRONGVALUE);\n                    return SNMP_ERR_WRONGVALUE;\n                }\n                /*\n                 * XXX - need to check this file exists\n                 *       (and is executable)\n                 */\n\n                if (extension && extension->flags & NS_EXTEND_FLAGS_CONFIG) {\n                    /*\n                     * config entries are \"permanent\" so can't be changed\n                     */\n                    netsnmp_set_request_error(reqinfo, request,\n                                              SNMP_ERR_NOTWRITABLE);\n                    return SNMP_ERR_NOTWRITABLE;\n                }\n                break;\n\n            case COLUMN_EXTCFG_ARGS:\n            case COLUMN_EXTCFG_INPUT:\n                if (request->requestvb->type != ASN_OCTET_STR) {\n                    netsnmp_set_request_error(reqinfo, request,\n                                              SNMP_ERR_WRONGTYPE);\n                    return SNMP_ERR_WRONGTYPE;\n                }\n\n                if (extension && extension->flags & NS_EXTEND_FLAGS_CONFIG) {\n                    /*\n                     * config entries are \"permanent\" so can't be changed\n                     */\n                    netsnmp_set_request_error(reqinfo, request,\n                                              SNMP_ERR_NOTWRITABLE);\n                    return SNMP_ERR_NOTWRITABLE;\n                }\n                break;\n\n            case COLUMN_EXTCFG_CACHETIME:\n                if (request->requestvb->type != ASN_INTEGER) {\n                    netsnmp_set_request_error(reqinfo, request,\n                                              SNMP_ERR_WRONGTYPE);\n                    return SNMP_ERR_WRONGTYPE;\n                }\n                i = *request->requestvb->val.integer;\n                /*\n                 * -1 is a special value indicating \"don't cache\"\n                 *    [[ XXX - should this be 0 ?? ]]\n                 * Otherwise, cache times must be non-negative\n                 */\n                if (i < -1 ) {\n                    netsnmp_set_request_error(reqinfo, request,\n                                              SNMP_ERR_WRONGVALUE);\n                    return SNMP_ERR_WRONGVALUE;\n                }\n                break;\n\n            case COLUMN_EXTCFG_EXECTYPE:\n                if (request->requestvb->type != ASN_INTEGER) {\n                    netsnmp_set_request_error(reqinfo, request,\n                                              SNMP_ERR_WRONGTYPE);\n                    return SNMP_ERR_WRONGTYPE;\n                }\n                i = *request->requestvb->val.integer;\n                if (i<1 || i>2) {  /* 'exec(1)' or 'shell(2)' only */\n                    netsnmp_set_request_error(reqinfo, request,\n                                              SNMP_ERR_WRONGVALUE);\n                    return SNMP_ERR_WRONGVALUE;\n                }\n                if (extension && extension->flags & NS_EXTEND_FLAGS_CONFIG) {\n                    /*\n                     * config entries are \"permanent\" so can't be changed\n                     */\n                    netsnmp_set_request_error(reqinfo, request,\n                                              SNMP_ERR_NOTWRITABLE);\n                    return SNMP_ERR_NOTWRITABLE;\n                }\n                break;\n\n            case COLUMN_EXTCFG_RUNTYPE:\n                if (request->requestvb->type != ASN_INTEGER) {\n                    netsnmp_set_request_error(reqinfo, request,\n                                              SNMP_ERR_WRONGTYPE);\n                    return SNMP_ERR_WRONGTYPE;\n                }\n                /*\n                 * 'run-on-read(1)', 'run-on-set(2)'\n                 *  or 'run-command(3)' only\n                 */\n                i = *request->requestvb->val.integer;\n                if (i<1 || i>3) {\n                    netsnmp_set_request_error(reqinfo, request,\n                                              SNMP_ERR_WRONGVALUE);\n                    return SNMP_ERR_WRONGVALUE;\n                }\n                /*\n                 * 'run-command(3)' can only be used with\n                 *  a pre-existing 'run-on-set(2)' entry.\n                 */\n                if (i==3 && !(extension && (extension->flags & NS_EXTEND_FLAGS_WRITEABLE))) {\n                    netsnmp_set_request_error(reqinfo, request,\n                                              SNMP_ERR_INCONSISTENTVALUE);\n                    return SNMP_ERR_INCONSISTENTVALUE;\n                }\n                /*\n                 * 'run-command(3)' is the only valid assignment\n                 *  for permanent (i.e. config) entries\n                 */\n                if ((extension && extension->flags & NS_EXTEND_FLAGS_CONFIG)\n                    && i!=3 ) {\n                    netsnmp_set_request_error(reqinfo, request,\n                                              SNMP_ERR_INCONSISTENTVALUE);\n                    return SNMP_ERR_INCONSISTENTVALUE;\n                }\n                break;\n\n            case COLUMN_EXTCFG_STATUS:\n                if (request->requestvb->type != ASN_INTEGER) {\n                    netsnmp_set_request_error(reqinfo, request,\n                                              SNMP_ERR_WRONGTYPE);\n                    return SNMP_ERR_WRONGTYPE;\n                }\n                i = *request->requestvb->val.integer;\n                switch (i) {\n                case RS_ACTIVE:\n                case RS_NOTINSERVICE:\n                    if (!extension) {\n                        /* Must be used with existing rows */\n                        netsnmp_set_request_error(reqinfo, request,\n                                                  SNMP_ERR_INCONSISTENTVALUE);\n                        return SNMP_ERR_INCONSISTENTVALUE;\n                    }\n                    break;    /* OK */\n                case RS_CREATEANDGO:\n                case RS_CREATEANDWAIT:\n                    if (extension) {\n                        /* Can only be used to create new rows */\n                        netsnmp_set_request_error(reqinfo, request,\n                                                  SNMP_ERR_INCONSISTENTVALUE);\n                        return SNMP_ERR_INCONSISTENTVALUE;\n                    }\n                    break;\n                case RS_DESTROY:\n                    break;\n                default:\n                    netsnmp_set_request_error(reqinfo, request,\n                                              SNMP_ERR_WRONGVALUE);\n                    return SNMP_ERR_WRONGVALUE;\n                }\n                break;\n\n            default:\n                netsnmp_set_request_error(reqinfo, request,\n                                          SNMP_ERR_NOTWRITABLE);\n                return SNMP_ERR_NOTWRITABLE;\n            }\n            break;\n\n        case MODE_SET_RESERVE2:\n            switch (table_info->colnum) {\n            case COLUMN_EXTCFG_STATUS:\n                i = *request->requestvb->val.integer;\n                switch (i) {\n                case RS_CREATEANDGO:\n                case RS_CREATEANDWAIT:\n                    eptr = _find_extension_block( request->requestvb->name,\n                                                  request->requestvb->name_length );\n                    extension = _new_extension( (char *) table_info->indexes->val.string,\n                                                0, eptr );\n                    if (!extension) {  /* failed */\n                        netsnmp_set_request_error(reqinfo, request,\n                                                  SNMP_ERR_RESOURCEUNAVAILABLE);\n                        return SNMP_ERR_RESOURCEUNAVAILABLE;\n                    }\n                    netsnmp_insert_table_row( request, extension->row );\n                }\n            }\n            break;\n\n        case MODE_SET_FREE:\n            switch (table_info->colnum) {\n            case COLUMN_EXTCFG_STATUS:\n                i = *request->requestvb->val.integer;\n                switch (i) {\n                case RS_CREATEANDGO:\n                case RS_CREATEANDWAIT:\n                    eptr = _find_extension_block( request->requestvb->name,\n                                                  request->requestvb->name_length );\n                    _free_extension( extension, eptr );\n                }\n            }\n            break;\n\n        case MODE_SET_ACTION:\n            switch (table_info->colnum) {\n            case COLUMN_EXTCFG_COMMAND:\n                extension->old_command = extension->command;\n                extension->command = netsnmp_strdup_and_null(\n                    request->requestvb->val.string,\n                    request->requestvb->val_len);\n                break;\n            case COLUMN_EXTCFG_ARGS:\n                extension->old_args = extension->args;\n                extension->args = netsnmp_strdup_and_null(\n                    request->requestvb->val.string,\n                    request->requestvb->val_len);\n                break;\n            case COLUMN_EXTCFG_INPUT:\n                extension->old_input = extension->input;\n                extension->input = netsnmp_strdup_and_null(\n                    request->requestvb->val.string,\n                    request->requestvb->val_len);\n                break;\n            case COLUMN_EXTCFG_STATUS:\n                i = *request->requestvb->val.integer;\n                switch (i) {\n                case RS_ACTIVE:\n                case RS_CREATEANDGO:\n                    need_to_validate = 1;\n                }\n                break;\n            }\n            break;\n\n        case MODE_SET_UNDO:\n            switch (table_info->colnum) {\n            case COLUMN_EXTCFG_COMMAND:\n                if ( extension && extension->old_command ) {\n                    SNMP_FREE(extension->command);\n                    extension->command     = extension->old_command;\n                    extension->old_command = NULL;\n                }\n                break;\n            case COLUMN_EXTCFG_ARGS:\n                if ( extension && extension->old_args ) {\n                    SNMP_FREE(extension->args);\n                    extension->args     = extension->old_args;\n                    extension->old_args = NULL;\n                }\n                break;\n            case COLUMN_EXTCFG_INPUT:\n                if ( extension && extension->old_input ) {\n                    SNMP_FREE(extension->input);\n                    extension->input     = extension->old_input;\n                    extension->old_input = NULL;\n                }\n                break;\n            case COLUMN_EXTCFG_STATUS:\n                i = *request->requestvb->val.integer;\n                switch (i) {\n                case RS_CREATEANDGO:\n                case RS_CREATEANDWAIT:\n                    eptr = _find_extension_block( request->requestvb->name,\n                                                  request->requestvb->name_length );\n                    _free_extension( extension, eptr );\n                }\n                break;\n            }\n            break;\n\n        case MODE_SET_COMMIT:\n            switch (table_info->colnum) {\n            case COLUMN_EXTCFG_CACHETIME:\n                i = *request->requestvb->val.integer;\n                extension->cache->timeout = i;\n                break;\n\n            case COLUMN_EXTCFG_RUNTYPE:\n                i = *request->requestvb->val.integer;\n                switch (i) {\n                case 1:\n                    extension->flags &= ~NS_EXTEND_FLAGS_WRITEABLE;\n                    break;\n                case 2:\n                    extension->flags |=  NS_EXTEND_FLAGS_WRITEABLE;\n                    break;\n                case 3:\n                    (void)netsnmp_cache_check_and_reload( extension->cache );\n                    break;\n                }\n                break;\n\n            case COLUMN_EXTCFG_EXECTYPE:\n                i = *request->requestvb->val.integer;\n                if ( i == NS_EXTEND_ETYPE_SHELL )\n                    extension->flags |=  NS_EXTEND_FLAGS_SHELL;\n                else\n                    extension->flags &= ~NS_EXTEND_FLAGS_SHELL;\n                break;\n\n            case COLUMN_EXTCFG_STATUS:\n                i = *request->requestvb->val.integer;\n                switch (i) {\n                case RS_ACTIVE:\n                case RS_CREATEANDGO:\n                    extension->flags |= NS_EXTEND_FLAGS_ACTIVE;\n                    break;\n                case RS_NOTINSERVICE:\n                case RS_CREATEANDWAIT:\n                    extension->flags &= ~NS_EXTEND_FLAGS_ACTIVE;\n                    break;\n                case RS_DESTROY:\n                    eptr = _find_extension_block( request->requestvb->name,\n                                                  request->requestvb->name_length );\n                    _free_extension( extension, eptr );\n                    break;\n                }\n            }\n            break;\n#endif /* !NETSNMP_NO_WRITE_SUPPORT and ENABLE_EXTEND_WRITE_ACCESS */\n\n        default:\n            netsnmp_set_request_error(reqinfo, request, SNMP_ERR_GENERR);\n            return SNMP_ERR_GENERR;\n        }\n    }\n\n#if !defined(NETSNMP_NO_WRITE_SUPPORT) && ENABLE_EXTEND_WRITE_ACCESS\n    /*\n     * If we're marking a given row as active,\n     *  then we need to check that it's ready.\n     */\n    if (need_to_validate) {\n        for ( request=requests; request; request=request->next ) {\n            if (request->processed)\n                continue;\n            table_info = netsnmp_extract_table_info( request );\n            extension  = (netsnmp_extend*)netsnmp_extract_table_row_data( request );\n            switch (table_info->colnum) {\n            case COLUMN_EXTCFG_STATUS:\n                i = *request->requestvb->val.integer;\n                if (( i == RS_ACTIVE || i == RS_CREATEANDGO ) &&\n                    !(extension && extension->command &&\n                      extension->command[0] == '/' /* &&\n                      is_executable(extension->command) */)) {\n                    netsnmp_set_request_error(reqinfo, request,\n                                              SNMP_ERR_INCONSISTENTVALUE);\n                    return SNMP_ERR_INCONSISTENTVALUE;\n                }\n            }\n        }\n    }\n#endif /* !NETSNMP_NO_WRITE_SUPPORT && ENABLE_EXTEND_WRITE_ACCESS */\n    \n    return SNMP_ERR_NOERROR;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -103,7 +103,7 @@\n          *\n          **********/\n \n-#ifndef NETSNMP_NO_WRITE_SUPPORT\n+#if !defined(NETSNMP_NO_WRITE_SUPPORT) && ENABLE_EXTEND_WRITE_ACCESS\n         case MODE_SET_RESERVE1:\n             /*\n              * Validate the new assignments\n@@ -429,7 +429,7 @@\n                 }\n             }\n             break;\n-#endif /* !NETSNMP_NO_WRITE_SUPPORT */ \n+#endif /* !NETSNMP_NO_WRITE_SUPPORT and ENABLE_EXTEND_WRITE_ACCESS */\n \n         default:\n             netsnmp_set_request_error(reqinfo, request, SNMP_ERR_GENERR);\n@@ -437,7 +437,7 @@\n         }\n     }\n \n-#ifndef NETSNMP_NO_WRITE_SUPPORT\n+#if !defined(NETSNMP_NO_WRITE_SUPPORT) && ENABLE_EXTEND_WRITE_ACCESS\n     /*\n      * If we're marking a given row as active,\n      *  then we need to check that it's ready.\n@@ -462,7 +462,7 @@\n             }\n         }\n     }\n-#endif /* !NETSNMP_NO_WRITE_SUPPORT */\n+#endif /* !NETSNMP_NO_WRITE_SUPPORT && ENABLE_EXTEND_WRITE_ACCESS */\n     \n     return SNMP_ERR_NOERROR;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "#ifndef NETSNMP_NO_WRITE_SUPPORT",
                "#endif /* !NETSNMP_NO_WRITE_SUPPORT */ ",
                "#ifndef NETSNMP_NO_WRITE_SUPPORT",
                "#endif /* !NETSNMP_NO_WRITE_SUPPORT */"
            ],
            "added_lines": [
                "#if !defined(NETSNMP_NO_WRITE_SUPPORT) && ENABLE_EXTEND_WRITE_ACCESS",
                "#endif /* !NETSNMP_NO_WRITE_SUPPORT and ENABLE_EXTEND_WRITE_ACCESS */",
                "#if !defined(NETSNMP_NO_WRITE_SUPPORT) && ENABLE_EXTEND_WRITE_ACCESS",
                "#endif /* !NETSNMP_NO_WRITE_SUPPORT && ENABLE_EXTEND_WRITE_ACCESS */"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-15862",
        "func_name": "net-snmp/fixExec2Error",
        "description": "Net-SNMP through 5.8 has Improper Privilege Management because SNMP WRITE access to the EXTEND MIB provides the ability to run arbitrary commands as root.",
        "git_url": "https://github.com/net-snmp/net-snmp/commit/77f6c60f57dba0aaea5d8ef1dd94bcd0c8e6d205",
        "commit_title": "make the extend mib read-only by default",
        "commit_text": "",
        "func_before": "int\nfixExec2Error(int action,\n             u_char * var_val,\n             u_char var_val_type,\n             size_t var_val_len,\n             u_char * statP, oid * name, size_t name_len)\n{\n    netsnmp_old_extend *exten = NULL;\n    unsigned int idx;\n\n    idx = name[name_len-1] -1;\n    exten = &compatability_entries[ idx ];\n\n#ifndef NETSNMP_NO_WRITE_SUPPORT\n    switch (action) {\n    case MODE_SET_RESERVE1:\n        if (var_val_type != ASN_INTEGER) {\n            snmp_log(LOG_ERR, \"Wrong type != int\\n\");\n            return SNMP_ERR_WRONGTYPE;\n        }\n        idx = *((long *) var_val);\n        if (idx != 1) {\n            snmp_log(LOG_ERR, \"Wrong value != 1\\n\");\n            return SNMP_ERR_WRONGVALUE;\n        }\n        if (!exten || !exten->efix_entry) {\n            snmp_log(LOG_ERR, \"No command to run\\n\");\n            return SNMP_ERR_GENERR;\n        }\n        return SNMP_ERR_NOERROR;\n\n    case MODE_SET_COMMIT:\n        netsnmp_cache_check_and_reload( exten->efix_entry->cache );\n    }\n#endif /* !NETSNMP_NO_WRITE_SUPPORT */\n    return SNMP_ERR_NOERROR;\n}",
        "func": "int\nfixExec2Error(int action,\n             u_char * var_val,\n             u_char var_val_type,\n             size_t var_val_len,\n             u_char * statP, oid * name, size_t name_len)\n{\n    netsnmp_old_extend *exten = NULL;\n    unsigned int idx;\n\n    idx = name[name_len-1] -1;\n    exten = &compatability_entries[ idx ];\n\n#if !defined(NETSNMP_NO_WRITE_SUPPORT) && ENABLE_EXTEND_WRITE_ACCESS\n    switch (action) {\n    case MODE_SET_RESERVE1:\n        if (var_val_type != ASN_INTEGER) {\n            snmp_log(LOG_ERR, \"Wrong type != int\\n\");\n            return SNMP_ERR_WRONGTYPE;\n        }\n        idx = *((long *) var_val);\n        if (idx != 1) {\n            snmp_log(LOG_ERR, \"Wrong value != 1\\n\");\n            return SNMP_ERR_WRONGVALUE;\n        }\n        if (!exten || !exten->efix_entry) {\n            snmp_log(LOG_ERR, \"No command to run\\n\");\n            return SNMP_ERR_GENERR;\n        }\n        return SNMP_ERR_NOERROR;\n\n    case MODE_SET_COMMIT:\n        netsnmp_cache_check_and_reload( exten->efix_entry->cache );\n    }\n#endif /* !NETSNMP_NO_WRITE_SUPPORT && ENABLE_EXTEND_WRITE_ACCESS */\n    return SNMP_ERR_NOERROR;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -11,7 +11,7 @@\n     idx = name[name_len-1] -1;\n     exten = &compatability_entries[ idx ];\n \n-#ifndef NETSNMP_NO_WRITE_SUPPORT\n+#if !defined(NETSNMP_NO_WRITE_SUPPORT) && ENABLE_EXTEND_WRITE_ACCESS\n     switch (action) {\n     case MODE_SET_RESERVE1:\n         if (var_val_type != ASN_INTEGER) {\n@@ -32,6 +32,6 @@\n     case MODE_SET_COMMIT:\n         netsnmp_cache_check_and_reload( exten->efix_entry->cache );\n     }\n-#endif /* !NETSNMP_NO_WRITE_SUPPORT */\n+#endif /* !NETSNMP_NO_WRITE_SUPPORT && ENABLE_EXTEND_WRITE_ACCESS */\n     return SNMP_ERR_NOERROR;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "#ifndef NETSNMP_NO_WRITE_SUPPORT",
                "#endif /* !NETSNMP_NO_WRITE_SUPPORT */"
            ],
            "added_lines": [
                "#if !defined(NETSNMP_NO_WRITE_SUPPORT) && ENABLE_EXTEND_WRITE_ACCESS",
                "#endif /* !NETSNMP_NO_WRITE_SUPPORT && ENABLE_EXTEND_WRITE_ACCESS */"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-1575",
        "func_name": "torvalds/linux/ovl_cleanup_whiteouts",
        "description": "The overlayfs implementation in the Linux kernel through 4.5.2 does not properly maintain POSIX ACL xattr data, which allows local users to gain privileges by leveraging a group-writable setgid directory.",
        "git_url": "http://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/commit/?h=e9f57ebcba563e0cd532926cab83c92bb4d79360",
        "commit_title": "Pull overlayfs updates from Miklos Szeredi:",
        "commit_text": " \"This contains several bug fixes and a new mount option   'default_permissions' that allows read-only exported NFS   filesystems to be used as lower layer\"  * 'overlayfs-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mszeredi/vfs:   ovl: check dentry positiveness in ovl_cleanup_whiteouts()   ovl: setattr: check permissions before copy-up   ovl: root: copy attr   ovl: move super block magic number to magic.h   ovl: use a minimal buffer in ovl_copy_xattr   ovl: allow zero size xattr   ovl: default permissions ",
        "func_before": "void ovl_cleanup_whiteouts(struct dentry *upper, struct list_head *list)\n{\n\tstruct ovl_cache_entry *p;\n\n\tmutex_lock_nested(&upper->d_inode->i_mutex, I_MUTEX_CHILD);\n\tlist_for_each_entry(p, list, l_node) {\n\t\tstruct dentry *dentry;\n\n\t\tif (!p->is_whiteout)\n\t\t\tcontinue;\n\n\t\tdentry = lookup_one_len(p->name, upper, p->len);\n\t\tif (IS_ERR(dentry)) {\n\t\t\tpr_err(\"overlayfs: lookup '%s/%.*s' failed (%i)\\n\",\n\t\t\t       upper->d_name.name, p->len, p->name,\n\t\t\t       (int) PTR_ERR(dentry));\n\t\t\tcontinue;\n\t\t}\n\t\tovl_cleanup(upper->d_inode, dentry);\n\t\tdput(dentry);\n\t}\n\tmutex_unlock(&upper->d_inode->i_mutex);\n}",
        "func": "void ovl_cleanup_whiteouts(struct dentry *upper, struct list_head *list)\n{\n\tstruct ovl_cache_entry *p;\n\n\tmutex_lock_nested(&upper->d_inode->i_mutex, I_MUTEX_CHILD);\n\tlist_for_each_entry(p, list, l_node) {\n\t\tstruct dentry *dentry;\n\n\t\tif (!p->is_whiteout)\n\t\t\tcontinue;\n\n\t\tdentry = lookup_one_len(p->name, upper, p->len);\n\t\tif (IS_ERR(dentry)) {\n\t\t\tpr_err(\"overlayfs: lookup '%s/%.*s' failed (%i)\\n\",\n\t\t\t       upper->d_name.name, p->len, p->name,\n\t\t\t       (int) PTR_ERR(dentry));\n\t\t\tcontinue;\n\t\t}\n\t\tif (dentry->d_inode)\n\t\t\tovl_cleanup(upper->d_inode, dentry);\n\t\tdput(dentry);\n\t}\n\tmutex_unlock(&upper->d_inode->i_mutex);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -16,7 +16,8 @@\n \t\t\t       (int) PTR_ERR(dentry));\n \t\t\tcontinue;\n \t\t}\n-\t\tovl_cleanup(upper->d_inode, dentry);\n+\t\tif (dentry->d_inode)\n+\t\t\tovl_cleanup(upper->d_inode, dentry);\n \t\tdput(dentry);\n \t}\n \tmutex_unlock(&upper->d_inode->i_mutex);",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tovl_cleanup(upper->d_inode, dentry);"
            ],
            "added_lines": [
                "\t\tif (dentry->d_inode)",
                "\t\t\tovl_cleanup(upper->d_inode, dentry);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-1575",
        "func_name": "torvalds/linux/ovl_show_options",
        "description": "The overlayfs implementation in the Linux kernel through 4.5.2 does not properly maintain POSIX ACL xattr data, which allows local users to gain privileges by leveraging a group-writable setgid directory.",
        "git_url": "http://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/commit/?h=e9f57ebcba563e0cd532926cab83c92bb4d79360",
        "commit_title": "Pull overlayfs updates from Miklos Szeredi:",
        "commit_text": " \"This contains several bug fixes and a new mount option   'default_permissions' that allows read-only exported NFS   filesystems to be used as lower layer\"  * 'overlayfs-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mszeredi/vfs:   ovl: check dentry positiveness in ovl_cleanup_whiteouts()   ovl: setattr: check permissions before copy-up   ovl: root: copy attr   ovl: move super block magic number to magic.h   ovl: use a minimal buffer in ovl_copy_xattr   ovl: allow zero size xattr   ovl: default permissions ",
        "func_before": "static int ovl_show_options(struct seq_file *m, struct dentry *dentry)\n{\n\tstruct super_block *sb = dentry->d_sb;\n\tstruct ovl_fs *ufs = sb->s_fs_info;\n\n\tseq_show_option(m, \"lowerdir\", ufs->config.lowerdir);\n\tif (ufs->config.upperdir) {\n\t\tseq_show_option(m, \"upperdir\", ufs->config.upperdir);\n\t\tseq_show_option(m, \"workdir\", ufs->config.workdir);\n\t}\n\treturn 0;\n}",
        "func": "static int ovl_show_options(struct seq_file *m, struct dentry *dentry)\n{\n\tstruct super_block *sb = dentry->d_sb;\n\tstruct ovl_fs *ufs = sb->s_fs_info;\n\n\tseq_show_option(m, \"lowerdir\", ufs->config.lowerdir);\n\tif (ufs->config.upperdir) {\n\t\tseq_show_option(m, \"upperdir\", ufs->config.upperdir);\n\t\tseq_show_option(m, \"workdir\", ufs->config.workdir);\n\t}\n\tif (ufs->config.default_permissions)\n\t\tseq_puts(m, \",default_permissions\");\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -8,5 +8,7 @@\n \t\tseq_show_option(m, \"upperdir\", ufs->config.upperdir);\n \t\tseq_show_option(m, \"workdir\", ufs->config.workdir);\n \t}\n+\tif (ufs->config.default_permissions)\n+\t\tseq_puts(m, \",default_permissions\");\n \treturn 0;\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tif (ufs->config.default_permissions)",
                "\t\tseq_puts(m, \",default_permissions\");"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-1575",
        "func_name": "torvalds/linux/ovl_parse_opt",
        "description": "The overlayfs implementation in the Linux kernel through 4.5.2 does not properly maintain POSIX ACL xattr data, which allows local users to gain privileges by leveraging a group-writable setgid directory.",
        "git_url": "http://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/commit/?h=e9f57ebcba563e0cd532926cab83c92bb4d79360",
        "commit_title": "Pull overlayfs updates from Miklos Szeredi:",
        "commit_text": " \"This contains several bug fixes and a new mount option   'default_permissions' that allows read-only exported NFS   filesystems to be used as lower layer\"  * 'overlayfs-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mszeredi/vfs:   ovl: check dentry positiveness in ovl_cleanup_whiteouts()   ovl: setattr: check permissions before copy-up   ovl: root: copy attr   ovl: move super block magic number to magic.h   ovl: use a minimal buffer in ovl_copy_xattr   ovl: allow zero size xattr   ovl: default permissions ",
        "func_before": "static int ovl_parse_opt(char *opt, struct ovl_config *config)\n{\n\tchar *p;\n\n\twhile ((p = ovl_next_opt(&opt)) != NULL) {\n\t\tint token;\n\t\tsubstring_t args[MAX_OPT_ARGS];\n\n\t\tif (!*p)\n\t\t\tcontinue;\n\n\t\ttoken = match_token(p, ovl_tokens, args);\n\t\tswitch (token) {\n\t\tcase OPT_UPPERDIR:\n\t\t\tkfree(config->upperdir);\n\t\t\tconfig->upperdir = match_strdup(&args[0]);\n\t\t\tif (!config->upperdir)\n\t\t\t\treturn -ENOMEM;\n\t\t\tbreak;\n\n\t\tcase OPT_LOWERDIR:\n\t\t\tkfree(config->lowerdir);\n\t\t\tconfig->lowerdir = match_strdup(&args[0]);\n\t\t\tif (!config->lowerdir)\n\t\t\t\treturn -ENOMEM;\n\t\t\tbreak;\n\n\t\tcase OPT_WORKDIR:\n\t\t\tkfree(config->workdir);\n\t\t\tconfig->workdir = match_strdup(&args[0]);\n\t\t\tif (!config->workdir)\n\t\t\t\treturn -ENOMEM;\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tpr_err(\"overlayfs: unrecognized mount option \\\"%s\\\" or missing value\\n\", p);\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\t/* Workdir is useless in non-upper mount */\n\tif (!config->upperdir && config->workdir) {\n\t\tpr_info(\"overlayfs: option \\\"workdir=%s\\\" is useless in a non-upper mount, ignore\\n\",\n\t\t\tconfig->workdir);\n\t\tkfree(config->workdir);\n\t\tconfig->workdir = NULL;\n\t}\n\n\treturn 0;\n}",
        "func": "static int ovl_parse_opt(char *opt, struct ovl_config *config)\n{\n\tchar *p;\n\n\twhile ((p = ovl_next_opt(&opt)) != NULL) {\n\t\tint token;\n\t\tsubstring_t args[MAX_OPT_ARGS];\n\n\t\tif (!*p)\n\t\t\tcontinue;\n\n\t\ttoken = match_token(p, ovl_tokens, args);\n\t\tswitch (token) {\n\t\tcase OPT_UPPERDIR:\n\t\t\tkfree(config->upperdir);\n\t\t\tconfig->upperdir = match_strdup(&args[0]);\n\t\t\tif (!config->upperdir)\n\t\t\t\treturn -ENOMEM;\n\t\t\tbreak;\n\n\t\tcase OPT_LOWERDIR:\n\t\t\tkfree(config->lowerdir);\n\t\t\tconfig->lowerdir = match_strdup(&args[0]);\n\t\t\tif (!config->lowerdir)\n\t\t\t\treturn -ENOMEM;\n\t\t\tbreak;\n\n\t\tcase OPT_WORKDIR:\n\t\t\tkfree(config->workdir);\n\t\t\tconfig->workdir = match_strdup(&args[0]);\n\t\t\tif (!config->workdir)\n\t\t\t\treturn -ENOMEM;\n\t\t\tbreak;\n\n\t\tcase OPT_DEFAULT_PERMISSIONS:\n\t\t\tconfig->default_permissions = true;\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tpr_err(\"overlayfs: unrecognized mount option \\\"%s\\\" or missing value\\n\", p);\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\t/* Workdir is useless in non-upper mount */\n\tif (!config->upperdir && config->workdir) {\n\t\tpr_info(\"overlayfs: option \\\"workdir=%s\\\" is useless in a non-upper mount, ignore\\n\",\n\t\t\tconfig->workdir);\n\t\tkfree(config->workdir);\n\t\tconfig->workdir = NULL;\n\t}\n\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -32,6 +32,10 @@\n \t\t\t\treturn -ENOMEM;\n \t\t\tbreak;\n \n+\t\tcase OPT_DEFAULT_PERMISSIONS:\n+\t\t\tconfig->default_permissions = true;\n+\t\t\tbreak;\n+\n \t\tdefault:\n \t\t\tpr_err(\"overlayfs: unrecognized mount option \\\"%s\\\" or missing value\\n\", p);\n \t\t\treturn -EINVAL;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t\tcase OPT_DEFAULT_PERMISSIONS:",
                "\t\t\tconfig->default_permissions = true;",
                "\t\t\tbreak;",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2016-1575",
        "func_name": "torvalds/linux/ovl_fill_super",
        "description": "The overlayfs implementation in the Linux kernel through 4.5.2 does not properly maintain POSIX ACL xattr data, which allows local users to gain privileges by leveraging a group-writable setgid directory.",
        "git_url": "http://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/commit/?h=e9f57ebcba563e0cd532926cab83c92bb4d79360",
        "commit_title": "Pull overlayfs updates from Miklos Szeredi:",
        "commit_text": " \"This contains several bug fixes and a new mount option   'default_permissions' that allows read-only exported NFS   filesystems to be used as lower layer\"  * 'overlayfs-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mszeredi/vfs:   ovl: check dentry positiveness in ovl_cleanup_whiteouts()   ovl: setattr: check permissions before copy-up   ovl: root: copy attr   ovl: move super block magic number to magic.h   ovl: use a minimal buffer in ovl_copy_xattr   ovl: allow zero size xattr   ovl: default permissions ",
        "func_before": "static int ovl_fill_super(struct super_block *sb, void *data, int silent)\n{\n\tstruct path upperpath = { NULL, NULL };\n\tstruct path workpath = { NULL, NULL };\n\tstruct dentry *root_dentry;\n\tstruct ovl_entry *oe;\n\tstruct ovl_fs *ufs;\n\tstruct path *stack = NULL;\n\tchar *lowertmp;\n\tchar *lower;\n\tunsigned int numlower;\n\tunsigned int stacklen = 0;\n\tunsigned int i;\n\tbool remote = false;\n\tint err;\n\n\terr = -ENOMEM;\n\tufs = kzalloc(sizeof(struct ovl_fs), GFP_KERNEL);\n\tif (!ufs)\n\t\tgoto out;\n\n\terr = ovl_parse_opt((char *) data, &ufs->config);\n\tif (err)\n\t\tgoto out_free_config;\n\n\terr = -EINVAL;\n\tif (!ufs->config.lowerdir) {\n\t\tpr_err(\"overlayfs: missing 'lowerdir'\\n\");\n\t\tgoto out_free_config;\n\t}\n\n\tsb->s_stack_depth = 0;\n\tif (ufs->config.upperdir) {\n\t\tif (!ufs->config.workdir) {\n\t\t\tpr_err(\"overlayfs: missing 'workdir'\\n\");\n\t\t\tgoto out_free_config;\n\t\t}\n\n\t\terr = ovl_mount_dir(ufs->config.upperdir, &upperpath);\n\t\tif (err)\n\t\t\tgoto out_free_config;\n\n\t\t/* Upper fs should not be r/o */\n\t\tif (upperpath.mnt->mnt_sb->s_flags & MS_RDONLY) {\n\t\t\tpr_err(\"overlayfs: upper fs is r/o, try multi-lower layers mount\\n\");\n\t\t\terr = -EINVAL;\n\t\t\tgoto out_put_upperpath;\n\t\t}\n\n\t\terr = ovl_mount_dir(ufs->config.workdir, &workpath);\n\t\tif (err)\n\t\t\tgoto out_put_upperpath;\n\n\t\terr = -EINVAL;\n\t\tif (upperpath.mnt != workpath.mnt) {\n\t\t\tpr_err(\"overlayfs: workdir and upperdir must reside under the same mount\\n\");\n\t\t\tgoto out_put_workpath;\n\t\t}\n\t\tif (!ovl_workdir_ok(workpath.dentry, upperpath.dentry)) {\n\t\t\tpr_err(\"overlayfs: workdir and upperdir must be separate subtrees\\n\");\n\t\t\tgoto out_put_workpath;\n\t\t}\n\t\tsb->s_stack_depth = upperpath.mnt->mnt_sb->s_stack_depth;\n\t}\n\terr = -ENOMEM;\n\tlowertmp = kstrdup(ufs->config.lowerdir, GFP_KERNEL);\n\tif (!lowertmp)\n\t\tgoto out_put_workpath;\n\n\terr = -EINVAL;\n\tstacklen = ovl_split_lowerdirs(lowertmp);\n\tif (stacklen > OVL_MAX_STACK) {\n\t\tpr_err(\"overlayfs: too many lower directries, limit is %d\\n\",\n\t\t       OVL_MAX_STACK);\n\t\tgoto out_free_lowertmp;\n\t} else if (!ufs->config.upperdir && stacklen == 1) {\n\t\tpr_err(\"overlayfs: at least 2 lowerdir are needed while upperdir nonexistent\\n\");\n\t\tgoto out_free_lowertmp;\n\t}\n\n\tstack = kcalloc(stacklen, sizeof(struct path), GFP_KERNEL);\n\tif (!stack)\n\t\tgoto out_free_lowertmp;\n\n\tlower = lowertmp;\n\tfor (numlower = 0; numlower < stacklen; numlower++) {\n\t\terr = ovl_lower_dir(lower, &stack[numlower],\n\t\t\t\t    &ufs->lower_namelen, &sb->s_stack_depth,\n\t\t\t\t    &remote);\n\t\tif (err)\n\t\t\tgoto out_put_lowerpath;\n\n\t\tlower = strchr(lower, '\\0') + 1;\n\t}\n\n\terr = -EINVAL;\n\tsb->s_stack_depth++;\n\tif (sb->s_stack_depth > FILESYSTEM_MAX_STACK_DEPTH) {\n\t\tpr_err(\"overlayfs: maximum fs stacking depth exceeded\\n\");\n\t\tgoto out_put_lowerpath;\n\t}\n\n\tif (ufs->config.upperdir) {\n\t\tufs->upper_mnt = clone_private_mount(&upperpath);\n\t\terr = PTR_ERR(ufs->upper_mnt);\n\t\tif (IS_ERR(ufs->upper_mnt)) {\n\t\t\tpr_err(\"overlayfs: failed to clone upperpath\\n\");\n\t\t\tgoto out_put_lowerpath;\n\t\t}\n\n\t\tufs->workdir = ovl_workdir_create(ufs->upper_mnt, workpath.dentry);\n\t\terr = PTR_ERR(ufs->workdir);\n\t\tif (IS_ERR(ufs->workdir)) {\n\t\t\tpr_warn(\"overlayfs: failed to create directory %s/%s (errno: %i); mounting read-only\\n\",\n\t\t\t\tufs->config.workdir, OVL_WORKDIR_NAME, -err);\n\t\t\tsb->s_flags |= MS_RDONLY;\n\t\t\tufs->workdir = NULL;\n\t\t}\n\t}\n\n\terr = -ENOMEM;\n\tufs->lower_mnt = kcalloc(numlower, sizeof(struct vfsmount *), GFP_KERNEL);\n\tif (ufs->lower_mnt == NULL)\n\t\tgoto out_put_workdir;\n\tfor (i = 0; i < numlower; i++) {\n\t\tstruct vfsmount *mnt = clone_private_mount(&stack[i]);\n\n\t\terr = PTR_ERR(mnt);\n\t\tif (IS_ERR(mnt)) {\n\t\t\tpr_err(\"overlayfs: failed to clone lowerpath\\n\");\n\t\t\tgoto out_put_lower_mnt;\n\t\t}\n\t\t/*\n\t\t * Make lower_mnt R/O.  That way fchmod/fchown on lower file\n\t\t * will fail instead of modifying lower fs.\n\t\t */\n\t\tmnt->mnt_flags |= MNT_READONLY;\n\n\t\tufs->lower_mnt[ufs->numlower] = mnt;\n\t\tufs->numlower++;\n\t}\n\n\t/* If the upper fs is nonexistent, we mark overlayfs r/o too */\n\tif (!ufs->upper_mnt)\n\t\tsb->s_flags |= MS_RDONLY;\n\n\tif (remote)\n\t\tsb->s_d_op = &ovl_reval_dentry_operations;\n\telse\n\t\tsb->s_d_op = &ovl_dentry_operations;\n\n\terr = -ENOMEM;\n\toe = ovl_alloc_entry(numlower);\n\tif (!oe)\n\t\tgoto out_put_lower_mnt;\n\n\troot_dentry = d_make_root(ovl_new_inode(sb, S_IFDIR, oe));\n\tif (!root_dentry)\n\t\tgoto out_free_oe;\n\n\tmntput(upperpath.mnt);\n\tfor (i = 0; i < numlower; i++)\n\t\tmntput(stack[i].mnt);\n\tpath_put(&workpath);\n\tkfree(lowertmp);\n\n\toe->__upperdentry = upperpath.dentry;\n\tfor (i = 0; i < numlower; i++) {\n\t\toe->lowerstack[i].dentry = stack[i].dentry;\n\t\toe->lowerstack[i].mnt = ufs->lower_mnt[i];\n\t}\n\tkfree(stack);\n\n\troot_dentry->d_fsdata = oe;\n\n\tsb->s_magic = OVERLAYFS_SUPER_MAGIC;\n\tsb->s_op = &ovl_super_operations;\n\tsb->s_root = root_dentry;\n\tsb->s_fs_info = ufs;\n\n\treturn 0;\n\nout_free_oe:\n\tkfree(oe);\nout_put_lower_mnt:\n\tfor (i = 0; i < ufs->numlower; i++)\n\t\tmntput(ufs->lower_mnt[i]);\n\tkfree(ufs->lower_mnt);\nout_put_workdir:\n\tdput(ufs->workdir);\n\tmntput(ufs->upper_mnt);\nout_put_lowerpath:\n\tfor (i = 0; i < numlower; i++)\n\t\tpath_put(&stack[i]);\n\tkfree(stack);\nout_free_lowertmp:\n\tkfree(lowertmp);\nout_put_workpath:\n\tpath_put(&workpath);\nout_put_upperpath:\n\tpath_put(&upperpath);\nout_free_config:\n\tkfree(ufs->config.lowerdir);\n\tkfree(ufs->config.upperdir);\n\tkfree(ufs->config.workdir);\n\tkfree(ufs);\nout:\n\treturn err;\n}",
        "func": "static int ovl_fill_super(struct super_block *sb, void *data, int silent)\n{\n\tstruct path upperpath = { NULL, NULL };\n\tstruct path workpath = { NULL, NULL };\n\tstruct dentry *root_dentry;\n\tstruct ovl_entry *oe;\n\tstruct ovl_fs *ufs;\n\tstruct path *stack = NULL;\n\tchar *lowertmp;\n\tchar *lower;\n\tunsigned int numlower;\n\tunsigned int stacklen = 0;\n\tunsigned int i;\n\tbool remote = false;\n\tint err;\n\n\terr = -ENOMEM;\n\tufs = kzalloc(sizeof(struct ovl_fs), GFP_KERNEL);\n\tif (!ufs)\n\t\tgoto out;\n\n\terr = ovl_parse_opt((char *) data, &ufs->config);\n\tif (err)\n\t\tgoto out_free_config;\n\n\terr = -EINVAL;\n\tif (!ufs->config.lowerdir) {\n\t\tpr_err(\"overlayfs: missing 'lowerdir'\\n\");\n\t\tgoto out_free_config;\n\t}\n\n\tsb->s_stack_depth = 0;\n\tsb->s_maxbytes = MAX_LFS_FILESIZE;\n\tif (ufs->config.upperdir) {\n\t\tif (!ufs->config.workdir) {\n\t\t\tpr_err(\"overlayfs: missing 'workdir'\\n\");\n\t\t\tgoto out_free_config;\n\t\t}\n\n\t\terr = ovl_mount_dir(ufs->config.upperdir, &upperpath);\n\t\tif (err)\n\t\t\tgoto out_free_config;\n\n\t\t/* Upper fs should not be r/o */\n\t\tif (upperpath.mnt->mnt_sb->s_flags & MS_RDONLY) {\n\t\t\tpr_err(\"overlayfs: upper fs is r/o, try multi-lower layers mount\\n\");\n\t\t\terr = -EINVAL;\n\t\t\tgoto out_put_upperpath;\n\t\t}\n\n\t\terr = ovl_mount_dir(ufs->config.workdir, &workpath);\n\t\tif (err)\n\t\t\tgoto out_put_upperpath;\n\n\t\terr = -EINVAL;\n\t\tif (upperpath.mnt != workpath.mnt) {\n\t\t\tpr_err(\"overlayfs: workdir and upperdir must reside under the same mount\\n\");\n\t\t\tgoto out_put_workpath;\n\t\t}\n\t\tif (!ovl_workdir_ok(workpath.dentry, upperpath.dentry)) {\n\t\t\tpr_err(\"overlayfs: workdir and upperdir must be separate subtrees\\n\");\n\t\t\tgoto out_put_workpath;\n\t\t}\n\t\tsb->s_stack_depth = upperpath.mnt->mnt_sb->s_stack_depth;\n\t}\n\terr = -ENOMEM;\n\tlowertmp = kstrdup(ufs->config.lowerdir, GFP_KERNEL);\n\tif (!lowertmp)\n\t\tgoto out_put_workpath;\n\n\terr = -EINVAL;\n\tstacklen = ovl_split_lowerdirs(lowertmp);\n\tif (stacklen > OVL_MAX_STACK) {\n\t\tpr_err(\"overlayfs: too many lower directries, limit is %d\\n\",\n\t\t       OVL_MAX_STACK);\n\t\tgoto out_free_lowertmp;\n\t} else if (!ufs->config.upperdir && stacklen == 1) {\n\t\tpr_err(\"overlayfs: at least 2 lowerdir are needed while upperdir nonexistent\\n\");\n\t\tgoto out_free_lowertmp;\n\t}\n\n\tstack = kcalloc(stacklen, sizeof(struct path), GFP_KERNEL);\n\tif (!stack)\n\t\tgoto out_free_lowertmp;\n\n\tlower = lowertmp;\n\tfor (numlower = 0; numlower < stacklen; numlower++) {\n\t\terr = ovl_lower_dir(lower, &stack[numlower],\n\t\t\t\t    &ufs->lower_namelen, &sb->s_stack_depth,\n\t\t\t\t    &remote);\n\t\tif (err)\n\t\t\tgoto out_put_lowerpath;\n\n\t\tlower = strchr(lower, '\\0') + 1;\n\t}\n\n\terr = -EINVAL;\n\tsb->s_stack_depth++;\n\tif (sb->s_stack_depth > FILESYSTEM_MAX_STACK_DEPTH) {\n\t\tpr_err(\"overlayfs: maximum fs stacking depth exceeded\\n\");\n\t\tgoto out_put_lowerpath;\n\t}\n\n\tif (ufs->config.upperdir) {\n\t\tufs->upper_mnt = clone_private_mount(&upperpath);\n\t\terr = PTR_ERR(ufs->upper_mnt);\n\t\tif (IS_ERR(ufs->upper_mnt)) {\n\t\t\tpr_err(\"overlayfs: failed to clone upperpath\\n\");\n\t\t\tgoto out_put_lowerpath;\n\t\t}\n\n\t\tufs->workdir = ovl_workdir_create(ufs->upper_mnt, workpath.dentry);\n\t\terr = PTR_ERR(ufs->workdir);\n\t\tif (IS_ERR(ufs->workdir)) {\n\t\t\tpr_warn(\"overlayfs: failed to create directory %s/%s (errno: %i); mounting read-only\\n\",\n\t\t\t\tufs->config.workdir, OVL_WORKDIR_NAME, -err);\n\t\t\tsb->s_flags |= MS_RDONLY;\n\t\t\tufs->workdir = NULL;\n\t\t}\n\t}\n\n\terr = -ENOMEM;\n\tufs->lower_mnt = kcalloc(numlower, sizeof(struct vfsmount *), GFP_KERNEL);\n\tif (ufs->lower_mnt == NULL)\n\t\tgoto out_put_workdir;\n\tfor (i = 0; i < numlower; i++) {\n\t\tstruct vfsmount *mnt = clone_private_mount(&stack[i]);\n\n\t\terr = PTR_ERR(mnt);\n\t\tif (IS_ERR(mnt)) {\n\t\t\tpr_err(\"overlayfs: failed to clone lowerpath\\n\");\n\t\t\tgoto out_put_lower_mnt;\n\t\t}\n\t\t/*\n\t\t * Make lower_mnt R/O.  That way fchmod/fchown on lower file\n\t\t * will fail instead of modifying lower fs.\n\t\t */\n\t\tmnt->mnt_flags |= MNT_READONLY;\n\n\t\tufs->lower_mnt[ufs->numlower] = mnt;\n\t\tufs->numlower++;\n\t}\n\n\t/* If the upper fs is nonexistent, we mark overlayfs r/o too */\n\tif (!ufs->upper_mnt)\n\t\tsb->s_flags |= MS_RDONLY;\n\n\tif (remote)\n\t\tsb->s_d_op = &ovl_reval_dentry_operations;\n\telse\n\t\tsb->s_d_op = &ovl_dentry_operations;\n\n\terr = -ENOMEM;\n\toe = ovl_alloc_entry(numlower);\n\tif (!oe)\n\t\tgoto out_put_lower_mnt;\n\n\troot_dentry = d_make_root(ovl_new_inode(sb, S_IFDIR, oe));\n\tif (!root_dentry)\n\t\tgoto out_free_oe;\n\n\tmntput(upperpath.mnt);\n\tfor (i = 0; i < numlower; i++)\n\t\tmntput(stack[i].mnt);\n\tpath_put(&workpath);\n\tkfree(lowertmp);\n\n\toe->__upperdentry = upperpath.dentry;\n\tfor (i = 0; i < numlower; i++) {\n\t\toe->lowerstack[i].dentry = stack[i].dentry;\n\t\toe->lowerstack[i].mnt = ufs->lower_mnt[i];\n\t}\n\tkfree(stack);\n\n\troot_dentry->d_fsdata = oe;\n\n\tovl_copyattr(ovl_dentry_real(root_dentry)->d_inode,\n\t\t     root_dentry->d_inode);\n\n\tsb->s_magic = OVERLAYFS_SUPER_MAGIC;\n\tsb->s_op = &ovl_super_operations;\n\tsb->s_root = root_dentry;\n\tsb->s_fs_info = ufs;\n\n\treturn 0;\n\nout_free_oe:\n\tkfree(oe);\nout_put_lower_mnt:\n\tfor (i = 0; i < ufs->numlower; i++)\n\t\tmntput(ufs->lower_mnt[i]);\n\tkfree(ufs->lower_mnt);\nout_put_workdir:\n\tdput(ufs->workdir);\n\tmntput(ufs->upper_mnt);\nout_put_lowerpath:\n\tfor (i = 0; i < numlower; i++)\n\t\tpath_put(&stack[i]);\n\tkfree(stack);\nout_free_lowertmp:\n\tkfree(lowertmp);\nout_put_workpath:\n\tpath_put(&workpath);\nout_put_upperpath:\n\tpath_put(&upperpath);\nout_free_config:\n\tkfree(ufs->config.lowerdir);\n\tkfree(ufs->config.upperdir);\n\tkfree(ufs->config.workdir);\n\tkfree(ufs);\nout:\n\treturn err;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -30,6 +30,7 @@\n \t}\n \n \tsb->s_stack_depth = 0;\n+\tsb->s_maxbytes = MAX_LFS_FILESIZE;\n \tif (ufs->config.upperdir) {\n \t\tif (!ufs->config.workdir) {\n \t\t\tpr_err(\"overlayfs: missing 'workdir'\\n\");\n@@ -172,6 +173,9 @@\n \tkfree(stack);\n \n \troot_dentry->d_fsdata = oe;\n+\n+\tovl_copyattr(ovl_dentry_real(root_dentry)->d_inode,\n+\t\t     root_dentry->d_inode);\n \n \tsb->s_magic = OVERLAYFS_SUPER_MAGIC;\n \tsb->s_op = &ovl_super_operations;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tsb->s_maxbytes = MAX_LFS_FILESIZE;",
                "",
                "\tovl_copyattr(ovl_dentry_real(root_dentry)->d_inode,",
                "\t\t     root_dentry->d_inode);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-1575",
        "func_name": "torvalds/linux/ovl_copy_xattr",
        "description": "The overlayfs implementation in the Linux kernel through 4.5.2 does not properly maintain POSIX ACL xattr data, which allows local users to gain privileges by leveraging a group-writable setgid directory.",
        "git_url": "http://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/commit/?h=e9f57ebcba563e0cd532926cab83c92bb4d79360",
        "commit_title": "Pull overlayfs updates from Miklos Szeredi:",
        "commit_text": " \"This contains several bug fixes and a new mount option   'default_permissions' that allows read-only exported NFS   filesystems to be used as lower layer\"  * 'overlayfs-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mszeredi/vfs:   ovl: check dentry positiveness in ovl_cleanup_whiteouts()   ovl: setattr: check permissions before copy-up   ovl: root: copy attr   ovl: move super block magic number to magic.h   ovl: use a minimal buffer in ovl_copy_xattr   ovl: allow zero size xattr   ovl: default permissions ",
        "func_before": "int ovl_copy_xattr(struct dentry *old, struct dentry *new)\n{\n\tssize_t list_size, size;\n\tchar *buf, *name, *value;\n\tint error;\n\n\tif (!old->d_inode->i_op->getxattr ||\n\t    !new->d_inode->i_op->getxattr)\n\t\treturn 0;\n\n\tlist_size = vfs_listxattr(old, NULL, 0);\n\tif (list_size <= 0) {\n\t\tif (list_size == -EOPNOTSUPP)\n\t\t\treturn 0;\n\t\treturn list_size;\n\t}\n\n\tbuf = kzalloc(list_size, GFP_KERNEL);\n\tif (!buf)\n\t\treturn -ENOMEM;\n\n\terror = -ENOMEM;\n\tvalue = kmalloc(XATTR_SIZE_MAX, GFP_KERNEL);\n\tif (!value)\n\t\tgoto out;\n\n\tlist_size = vfs_listxattr(old, buf, list_size);\n\tif (list_size <= 0) {\n\t\terror = list_size;\n\t\tgoto out_free_value;\n\t}\n\n\tfor (name = buf; name < (buf + list_size); name += strlen(name) + 1) {\n\t\tsize = vfs_getxattr(old, name, value, XATTR_SIZE_MAX);\n\t\tif (size <= 0) {\n\t\t\terror = size;\n\t\t\tgoto out_free_value;\n\t\t}\n\t\terror = vfs_setxattr(new, name, value, size, 0);\n\t\tif (error)\n\t\t\tgoto out_free_value;\n\t}\n\nout_free_value:\n\tkfree(value);\nout:\n\tkfree(buf);\n\treturn error;\n}",
        "func": "int ovl_copy_xattr(struct dentry *old, struct dentry *new)\n{\n\tssize_t list_size, size, value_size = 0;\n\tchar *buf, *name, *value = NULL;\n\tint uninitialized_var(error);\n\n\tif (!old->d_inode->i_op->getxattr ||\n\t    !new->d_inode->i_op->getxattr)\n\t\treturn 0;\n\n\tlist_size = vfs_listxattr(old, NULL, 0);\n\tif (list_size <= 0) {\n\t\tif (list_size == -EOPNOTSUPP)\n\t\t\treturn 0;\n\t\treturn list_size;\n\t}\n\n\tbuf = kzalloc(list_size, GFP_KERNEL);\n\tif (!buf)\n\t\treturn -ENOMEM;\n\n\tlist_size = vfs_listxattr(old, buf, list_size);\n\tif (list_size <= 0) {\n\t\terror = list_size;\n\t\tgoto out;\n\t}\n\n\tfor (name = buf; name < (buf + list_size); name += strlen(name) + 1) {\nretry:\n\t\tsize = vfs_getxattr(old, name, value, value_size);\n\t\tif (size == -ERANGE)\n\t\t\tsize = vfs_getxattr(old, name, NULL, 0);\n\n\t\tif (size < 0) {\n\t\t\terror = size;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (size > value_size) {\n\t\t\tvoid *new;\n\n\t\t\tnew = krealloc(value, size, GFP_KERNEL);\n\t\t\tif (!new) {\n\t\t\t\terror = -ENOMEM;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tvalue = new;\n\t\t\tvalue_size = size;\n\t\t\tgoto retry;\n\t\t}\n\n\t\terror = vfs_setxattr(new, name, value, size, 0);\n\t\tif (error)\n\t\t\tbreak;\n\t}\n\tkfree(value);\nout:\n\tkfree(buf);\n\treturn error;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,8 +1,8 @@\n int ovl_copy_xattr(struct dentry *old, struct dentry *new)\n {\n-\tssize_t list_size, size;\n-\tchar *buf, *name, *value;\n-\tint error;\n+\tssize_t list_size, size, value_size = 0;\n+\tchar *buf, *name, *value = NULL;\n+\tint uninitialized_var(error);\n \n \tif (!old->d_inode->i_op->getxattr ||\n \t    !new->d_inode->i_op->getxattr)\n@@ -19,29 +19,40 @@\n \tif (!buf)\n \t\treturn -ENOMEM;\n \n-\terror = -ENOMEM;\n-\tvalue = kmalloc(XATTR_SIZE_MAX, GFP_KERNEL);\n-\tif (!value)\n-\t\tgoto out;\n-\n \tlist_size = vfs_listxattr(old, buf, list_size);\n \tif (list_size <= 0) {\n \t\terror = list_size;\n-\t\tgoto out_free_value;\n+\t\tgoto out;\n \t}\n \n \tfor (name = buf; name < (buf + list_size); name += strlen(name) + 1) {\n-\t\tsize = vfs_getxattr(old, name, value, XATTR_SIZE_MAX);\n-\t\tif (size <= 0) {\n+retry:\n+\t\tsize = vfs_getxattr(old, name, value, value_size);\n+\t\tif (size == -ERANGE)\n+\t\t\tsize = vfs_getxattr(old, name, NULL, 0);\n+\n+\t\tif (size < 0) {\n \t\t\terror = size;\n-\t\t\tgoto out_free_value;\n+\t\t\tbreak;\n \t\t}\n+\n+\t\tif (size > value_size) {\n+\t\t\tvoid *new;\n+\n+\t\t\tnew = krealloc(value, size, GFP_KERNEL);\n+\t\t\tif (!new) {\n+\t\t\t\terror = -ENOMEM;\n+\t\t\t\tbreak;\n+\t\t\t}\n+\t\t\tvalue = new;\n+\t\t\tvalue_size = size;\n+\t\t\tgoto retry;\n+\t\t}\n+\n \t\terror = vfs_setxattr(new, name, value, size, 0);\n \t\tif (error)\n-\t\t\tgoto out_free_value;\n+\t\t\tbreak;\n \t}\n-\n-out_free_value:\n \tkfree(value);\n out:\n \tkfree(buf);",
        "diff_line_info": {
            "deleted_lines": [
                "\tssize_t list_size, size;",
                "\tchar *buf, *name, *value;",
                "\tint error;",
                "\terror = -ENOMEM;",
                "\tvalue = kmalloc(XATTR_SIZE_MAX, GFP_KERNEL);",
                "\tif (!value)",
                "\t\tgoto out;",
                "",
                "\t\tgoto out_free_value;",
                "\t\tsize = vfs_getxattr(old, name, value, XATTR_SIZE_MAX);",
                "\t\tif (size <= 0) {",
                "\t\t\tgoto out_free_value;",
                "\t\t\tgoto out_free_value;",
                "",
                "out_free_value:"
            ],
            "added_lines": [
                "\tssize_t list_size, size, value_size = 0;",
                "\tchar *buf, *name, *value = NULL;",
                "\tint uninitialized_var(error);",
                "\t\tgoto out;",
                "retry:",
                "\t\tsize = vfs_getxattr(old, name, value, value_size);",
                "\t\tif (size == -ERANGE)",
                "\t\t\tsize = vfs_getxattr(old, name, NULL, 0);",
                "",
                "\t\tif (size < 0) {",
                "\t\t\tbreak;",
                "",
                "\t\tif (size > value_size) {",
                "\t\t\tvoid *new;",
                "",
                "\t\t\tnew = krealloc(value, size, GFP_KERNEL);",
                "\t\t\tif (!new) {",
                "\t\t\t\terror = -ENOMEM;",
                "\t\t\t\tbreak;",
                "\t\t\t}",
                "\t\t\tvalue = new;",
                "\t\t\tvalue_size = size;",
                "\t\t\tgoto retry;",
                "\t\t}",
                "",
                "\t\t\tbreak;"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-1575",
        "func_name": "torvalds/linux/ovl_permission",
        "description": "The overlayfs implementation in the Linux kernel through 4.5.2 does not properly maintain POSIX ACL xattr data, which allows local users to gain privileges by leveraging a group-writable setgid directory.",
        "git_url": "http://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/commit/?h=e9f57ebcba563e0cd532926cab83c92bb4d79360",
        "commit_title": "Pull overlayfs updates from Miklos Szeredi:",
        "commit_text": " \"This contains several bug fixes and a new mount option   'default_permissions' that allows read-only exported NFS   filesystems to be used as lower layer\"  * 'overlayfs-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mszeredi/vfs:   ovl: check dentry positiveness in ovl_cleanup_whiteouts()   ovl: setattr: check permissions before copy-up   ovl: root: copy attr   ovl: move super block magic number to magic.h   ovl: use a minimal buffer in ovl_copy_xattr   ovl: allow zero size xattr   ovl: default permissions ",
        "func_before": "int ovl_permission(struct inode *inode, int mask)\n{\n\tstruct ovl_entry *oe;\n\tstruct dentry *alias = NULL;\n\tstruct inode *realinode;\n\tstruct dentry *realdentry;\n\tbool is_upper;\n\tint err;\n\n\tif (S_ISDIR(inode->i_mode)) {\n\t\toe = inode->i_private;\n\t} else if (mask & MAY_NOT_BLOCK) {\n\t\treturn -ECHILD;\n\t} else {\n\t\t/*\n\t\t * For non-directories find an alias and get the info\n\t\t * from there.\n\t\t */\n\t\talias = d_find_any_alias(inode);\n\t\tif (WARN_ON(!alias))\n\t\t\treturn -ENOENT;\n\n\t\toe = alias->d_fsdata;\n\t}\n\n\trealdentry = ovl_entry_real(oe, &is_upper);\n\n\t/* Careful in RCU walk mode */\n\trealinode = ACCESS_ONCE(realdentry->d_inode);\n\tif (!realinode) {\n\t\tWARN_ON(!(mask & MAY_NOT_BLOCK));\n\t\terr = -ENOENT;\n\t\tgoto out_dput;\n\t}\n\n\tif (mask & MAY_WRITE) {\n\t\tumode_t mode = realinode->i_mode;\n\n\t\t/*\n\t\t * Writes will always be redirected to upper layer, so\n\t\t * ignore lower layer being read-only.\n\t\t *\n\t\t * If the overlay itself is read-only then proceed\n\t\t * with the permission check, don't return EROFS.\n\t\t * This will only happen if this is the lower layer of\n\t\t * another overlayfs.\n\t\t *\n\t\t * If upper fs becomes read-only after the overlay was\n\t\t * constructed return EROFS to prevent modification of\n\t\t * upper layer.\n\t\t */\n\t\terr = -EROFS;\n\t\tif (is_upper && !IS_RDONLY(inode) && IS_RDONLY(realinode) &&\n\t\t    (S_ISREG(mode) || S_ISDIR(mode) || S_ISLNK(mode)))\n\t\t\tgoto out_dput;\n\t}\n\n\terr = __inode_permission(realinode, mask);\nout_dput:\n\tdput(alias);\n\treturn err;\n}",
        "func": "int ovl_permission(struct inode *inode, int mask)\n{\n\tstruct ovl_entry *oe;\n\tstruct dentry *alias = NULL;\n\tstruct inode *realinode;\n\tstruct dentry *realdentry;\n\tbool is_upper;\n\tint err;\n\n\tif (S_ISDIR(inode->i_mode)) {\n\t\toe = inode->i_private;\n\t} else if (mask & MAY_NOT_BLOCK) {\n\t\treturn -ECHILD;\n\t} else {\n\t\t/*\n\t\t * For non-directories find an alias and get the info\n\t\t * from there.\n\t\t */\n\t\talias = d_find_any_alias(inode);\n\t\tif (WARN_ON(!alias))\n\t\t\treturn -ENOENT;\n\n\t\toe = alias->d_fsdata;\n\t}\n\n\trealdentry = ovl_entry_real(oe, &is_upper);\n\n\tif (ovl_is_default_permissions(inode)) {\n\t\tstruct kstat stat;\n\t\tstruct path realpath = { .dentry = realdentry };\n\n\t\tif (mask & MAY_NOT_BLOCK)\n\t\t\treturn -ECHILD;\n\n\t\trealpath.mnt = ovl_entry_mnt_real(oe, inode, is_upper);\n\n\t\terr = vfs_getattr(&realpath, &stat);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tif ((stat.mode ^ inode->i_mode) & S_IFMT)\n\t\t\treturn -ESTALE;\n\n\t\tinode->i_mode = stat.mode;\n\t\tinode->i_uid = stat.uid;\n\t\tinode->i_gid = stat.gid;\n\n\t\treturn generic_permission(inode, mask);\n\t}\n\n\t/* Careful in RCU walk mode */\n\trealinode = ACCESS_ONCE(realdentry->d_inode);\n\tif (!realinode) {\n\t\tWARN_ON(!(mask & MAY_NOT_BLOCK));\n\t\terr = -ENOENT;\n\t\tgoto out_dput;\n\t}\n\n\tif (mask & MAY_WRITE) {\n\t\tumode_t mode = realinode->i_mode;\n\n\t\t/*\n\t\t * Writes will always be redirected to upper layer, so\n\t\t * ignore lower layer being read-only.\n\t\t *\n\t\t * If the overlay itself is read-only then proceed\n\t\t * with the permission check, don't return EROFS.\n\t\t * This will only happen if this is the lower layer of\n\t\t * another overlayfs.\n\t\t *\n\t\t * If upper fs becomes read-only after the overlay was\n\t\t * constructed return EROFS to prevent modification of\n\t\t * upper layer.\n\t\t */\n\t\terr = -EROFS;\n\t\tif (is_upper && !IS_RDONLY(inode) && IS_RDONLY(realinode) &&\n\t\t    (S_ISREG(mode) || S_ISDIR(mode) || S_ISLNK(mode)))\n\t\t\tgoto out_dput;\n\t}\n\n\terr = __inode_permission(realinode, mask);\nout_dput:\n\tdput(alias);\n\treturn err;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -24,6 +24,29 @@\n \t}\n \n \trealdentry = ovl_entry_real(oe, &is_upper);\n+\n+\tif (ovl_is_default_permissions(inode)) {\n+\t\tstruct kstat stat;\n+\t\tstruct path realpath = { .dentry = realdentry };\n+\n+\t\tif (mask & MAY_NOT_BLOCK)\n+\t\t\treturn -ECHILD;\n+\n+\t\trealpath.mnt = ovl_entry_mnt_real(oe, inode, is_upper);\n+\n+\t\terr = vfs_getattr(&realpath, &stat);\n+\t\tif (err)\n+\t\t\treturn err;\n+\n+\t\tif ((stat.mode ^ inode->i_mode) & S_IFMT)\n+\t\t\treturn -ESTALE;\n+\n+\t\tinode->i_mode = stat.mode;\n+\t\tinode->i_uid = stat.uid;\n+\t\tinode->i_gid = stat.gid;\n+\n+\t\treturn generic_permission(inode, mask);\n+\t}\n \n \t/* Careful in RCU walk mode */\n \trealinode = ACCESS_ONCE(realdentry->d_inode);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "\tif (ovl_is_default_permissions(inode)) {",
                "\t\tstruct kstat stat;",
                "\t\tstruct path realpath = { .dentry = realdentry };",
                "",
                "\t\tif (mask & MAY_NOT_BLOCK)",
                "\t\t\treturn -ECHILD;",
                "",
                "\t\trealpath.mnt = ovl_entry_mnt_real(oe, inode, is_upper);",
                "",
                "\t\terr = vfs_getattr(&realpath, &stat);",
                "\t\tif (err)",
                "\t\t\treturn err;",
                "",
                "\t\tif ((stat.mode ^ inode->i_mode) & S_IFMT)",
                "\t\t\treturn -ESTALE;",
                "",
                "\t\tinode->i_mode = stat.mode;",
                "\t\tinode->i_uid = stat.uid;",
                "\t\tinode->i_gid = stat.gid;",
                "",
                "\t\treturn generic_permission(inode, mask);",
                "\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-1575",
        "func_name": "torvalds/linux/ovl_setattr",
        "description": "The overlayfs implementation in the Linux kernel through 4.5.2 does not properly maintain POSIX ACL xattr data, which allows local users to gain privileges by leveraging a group-writable setgid directory.",
        "git_url": "http://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/commit/?h=e9f57ebcba563e0cd532926cab83c92bb4d79360",
        "commit_title": "Pull overlayfs updates from Miklos Szeredi:",
        "commit_text": " \"This contains several bug fixes and a new mount option   'default_permissions' that allows read-only exported NFS   filesystems to be used as lower layer\"  * 'overlayfs-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/mszeredi/vfs:   ovl: check dentry positiveness in ovl_cleanup_whiteouts()   ovl: setattr: check permissions before copy-up   ovl: root: copy attr   ovl: move super block magic number to magic.h   ovl: use a minimal buffer in ovl_copy_xattr   ovl: allow zero size xattr   ovl: default permissions ",
        "func_before": "int ovl_setattr(struct dentry *dentry, struct iattr *attr)\n{\n\tint err;\n\tstruct dentry *upperdentry;\n\n\terr = ovl_want_write(dentry);\n\tif (err)\n\t\tgoto out;\n\n\terr = ovl_copy_up(dentry);\n\tif (!err) {\n\t\tupperdentry = ovl_dentry_upper(dentry);\n\n\t\tmutex_lock(&upperdentry->d_inode->i_mutex);\n\t\terr = notify_change(upperdentry, attr, NULL);\n\t\tmutex_unlock(&upperdentry->d_inode->i_mutex);\n\t}\n\tovl_drop_write(dentry);\nout:\n\treturn err;\n}",
        "func": "int ovl_setattr(struct dentry *dentry, struct iattr *attr)\n{\n\tint err;\n\tstruct dentry *upperdentry;\n\n\t/*\n\t * Check for permissions before trying to copy-up.  This is redundant\n\t * since it will be rechecked later by ->setattr() on upper dentry.  But\n\t * without this, copy-up can be triggered by just about anybody.\n\t *\n\t * We don't initialize inode->size, which just means that\n\t * inode_newsize_ok() will always check against MAX_LFS_FILESIZE and not\n\t * check for a swapfile (which this won't be anyway).\n\t */\n\terr = inode_change_ok(dentry->d_inode, attr);\n\tif (err)\n\t\treturn err;\n\n\terr = ovl_want_write(dentry);\n\tif (err)\n\t\tgoto out;\n\n\terr = ovl_copy_up(dentry);\n\tif (!err) {\n\t\tupperdentry = ovl_dentry_upper(dentry);\n\n\t\tmutex_lock(&upperdentry->d_inode->i_mutex);\n\t\terr = notify_change(upperdentry, attr, NULL);\n\t\tmutex_unlock(&upperdentry->d_inode->i_mutex);\n\t}\n\tovl_drop_write(dentry);\nout:\n\treturn err;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,6 +2,19 @@\n {\n \tint err;\n \tstruct dentry *upperdentry;\n+\n+\t/*\n+\t * Check for permissions before trying to copy-up.  This is redundant\n+\t * since it will be rechecked later by ->setattr() on upper dentry.  But\n+\t * without this, copy-up can be triggered by just about anybody.\n+\t *\n+\t * We don't initialize inode->size, which just means that\n+\t * inode_newsize_ok() will always check against MAX_LFS_FILESIZE and not\n+\t * check for a swapfile (which this won't be anyway).\n+\t */\n+\terr = inode_change_ok(dentry->d_inode, attr);\n+\tif (err)\n+\t\treturn err;\n \n \terr = ovl_want_write(dentry);\n \tif (err)",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "\t/*",
                "\t * Check for permissions before trying to copy-up.  This is redundant",
                "\t * since it will be rechecked later by ->setattr() on upper dentry.  But",
                "\t * without this, copy-up can be triggered by just about anybody.",
                "\t *",
                "\t * We don't initialize inode->size, which just means that",
                "\t * inode_newsize_ok() will always check against MAX_LFS_FILESIZE and not",
                "\t * check for a swapfile (which this won't be anyway).",
                "\t */",
                "\terr = inode_change_ok(dentry->d_inode, attr);",
                "\tif (err)",
                "\t\treturn err;"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-3534",
        "func_name": "torvalds/linux/__poke_user",
        "description": "arch/s390/kernel/ptrace.c in the Linux kernel before 3.15.8 on the s390 platform does not properly restrict address-space control operations in PTRACE_POKEUSR_AREA requests, which allows local users to obtain read and write access to kernel memory locations, and consequently gain privileges, via a crafted application that makes a ptrace system call.",
        "git_url": "https://github.com/torvalds/linux/commit/dab6cf55f81a6e16b8147aed9a843e1691dcd318",
        "commit_title": "s390/ptrace: fix PSW mask check",
        "commit_text": " The PSW mask check of the PTRACE_POKEUSR_AREA command is incorrect. The PSW_MASK_USER define contains the PSW_MASK_ASC bits, the ptrace interface accepts all combinations for the address-space-control bits. To protect the kernel space the PSW mask check in ptrace needs to reject the address-space-control bit combination for home space.  Fixes CVE-2014-3534  Cc: stable@vger.kernel.org",
        "func_before": "static int __poke_user(struct task_struct *child, addr_t addr, addr_t data)\n{\n\tstruct user *dummy = NULL;\n\taddr_t offset;\n\n\tif (addr < (addr_t) &dummy->regs.acrs) {\n\t\t/*\n\t\t * psw and gprs are stored on the stack\n\t\t */\n\t\tif (addr == (addr_t) &dummy->regs.psw.mask) {\n\t\t\tunsigned long mask = PSW_MASK_USER;\n\n\t\t\tmask |= is_ri_task(child) ? PSW_MASK_RI : 0;\n\t\t\tif ((data & ~mask) != PSW_USER_BITS)\n\t\t\t\treturn -EINVAL;\n\t\t\tif ((data & PSW_MASK_EA) && !(data & PSW_MASK_BA))\n\t\t\t\treturn -EINVAL;\n\t\t}\n\t\t*(addr_t *)((addr_t) &task_pt_regs(child)->psw + addr) = data;\n\n\t} else if (addr < (addr_t) (&dummy->regs.orig_gpr2)) {\n\t\t/*\n\t\t * access registers are stored in the thread structure\n\t\t */\n\t\toffset = addr - (addr_t) &dummy->regs.acrs;\n#ifdef CONFIG_64BIT\n\t\t/*\n\t\t * Very special case: old & broken 64 bit gdb writing\n\t\t * to acrs[15] with a 64 bit value. Ignore the lower\n\t\t * half of the value and write the upper 32 bit to\n\t\t * acrs[15]. Sick...\n\t\t */\n\t\tif (addr == (addr_t) &dummy->regs.acrs[15])\n\t\t\tchild->thread.acrs[15] = (unsigned int) (data >> 32);\n\t\telse\n#endif\n\t\t*(addr_t *)((addr_t) &child->thread.acrs + offset) = data;\n\n\t} else if (addr == (addr_t) &dummy->regs.orig_gpr2) {\n\t\t/*\n\t\t * orig_gpr2 is stored on the kernel stack\n\t\t */\n\t\ttask_pt_regs(child)->orig_gpr2 = data;\n\n\t} else if (addr < (addr_t) &dummy->regs.fp_regs) {\n\t\t/*\n\t\t * prevent writes of padding hole between\n\t\t * orig_gpr2 and fp_regs on s390.\n\t\t */\n\t\treturn 0;\n\n\t} else if (addr < (addr_t) (&dummy->regs.fp_regs + 1)) {\n\t\t/*\n\t\t * floating point regs. are stored in the thread structure\n\t\t */\n\t\tif (addr == (addr_t) &dummy->regs.fp_regs.fpc)\n\t\t\tif ((unsigned int) data != 0 ||\n\t\t\t    test_fp_ctl(data >> (BITS_PER_LONG - 32)))\n\t\t\t\treturn -EINVAL;\n\t\toffset = addr - (addr_t) &dummy->regs.fp_regs;\n\t\t*(addr_t *)((addr_t) &child->thread.fp_regs + offset) = data;\n\n\t} else if (addr < (addr_t) (&dummy->regs.per_info + 1)) {\n\t\t/*\n\t\t * Handle access to the per_info structure.\n\t\t */\n\t\taddr -= (addr_t) &dummy->regs.per_info;\n\t\t__poke_user_per(child, addr, data);\n\n\t}\n\n\treturn 0;\n}",
        "func": "static int __poke_user(struct task_struct *child, addr_t addr, addr_t data)\n{\n\tstruct user *dummy = NULL;\n\taddr_t offset;\n\n\tif (addr < (addr_t) &dummy->regs.acrs) {\n\t\t/*\n\t\t * psw and gprs are stored on the stack\n\t\t */\n\t\tif (addr == (addr_t) &dummy->regs.psw.mask) {\n\t\t\tunsigned long mask = PSW_MASK_USER;\n\n\t\t\tmask |= is_ri_task(child) ? PSW_MASK_RI : 0;\n\t\t\tif ((data ^ PSW_USER_BITS) & ~mask)\n\t\t\t\t/* Invalid psw mask. */\n\t\t\t\treturn -EINVAL;\n\t\t\tif ((data & PSW_MASK_ASC) == PSW_ASC_HOME)\n\t\t\t\t/* Invalid address-space-control bits */\n\t\t\t\treturn -EINVAL;\n\t\t\tif ((data & PSW_MASK_EA) && !(data & PSW_MASK_BA))\n\t\t\t\t/* Invalid addressing mode bits */\n\t\t\t\treturn -EINVAL;\n\t\t}\n\t\t*(addr_t *)((addr_t) &task_pt_regs(child)->psw + addr) = data;\n\n\t} else if (addr < (addr_t) (&dummy->regs.orig_gpr2)) {\n\t\t/*\n\t\t * access registers are stored in the thread structure\n\t\t */\n\t\toffset = addr - (addr_t) &dummy->regs.acrs;\n#ifdef CONFIG_64BIT\n\t\t/*\n\t\t * Very special case: old & broken 64 bit gdb writing\n\t\t * to acrs[15] with a 64 bit value. Ignore the lower\n\t\t * half of the value and write the upper 32 bit to\n\t\t * acrs[15]. Sick...\n\t\t */\n\t\tif (addr == (addr_t) &dummy->regs.acrs[15])\n\t\t\tchild->thread.acrs[15] = (unsigned int) (data >> 32);\n\t\telse\n#endif\n\t\t*(addr_t *)((addr_t) &child->thread.acrs + offset) = data;\n\n\t} else if (addr == (addr_t) &dummy->regs.orig_gpr2) {\n\t\t/*\n\t\t * orig_gpr2 is stored on the kernel stack\n\t\t */\n\t\ttask_pt_regs(child)->orig_gpr2 = data;\n\n\t} else if (addr < (addr_t) &dummy->regs.fp_regs) {\n\t\t/*\n\t\t * prevent writes of padding hole between\n\t\t * orig_gpr2 and fp_regs on s390.\n\t\t */\n\t\treturn 0;\n\n\t} else if (addr < (addr_t) (&dummy->regs.fp_regs + 1)) {\n\t\t/*\n\t\t * floating point regs. are stored in the thread structure\n\t\t */\n\t\tif (addr == (addr_t) &dummy->regs.fp_regs.fpc)\n\t\t\tif ((unsigned int) data != 0 ||\n\t\t\t    test_fp_ctl(data >> (BITS_PER_LONG - 32)))\n\t\t\t\treturn -EINVAL;\n\t\toffset = addr - (addr_t) &dummy->regs.fp_regs;\n\t\t*(addr_t *)((addr_t) &child->thread.fp_regs + offset) = data;\n\n\t} else if (addr < (addr_t) (&dummy->regs.per_info + 1)) {\n\t\t/*\n\t\t * Handle access to the per_info structure.\n\t\t */\n\t\taddr -= (addr_t) &dummy->regs.per_info;\n\t\t__poke_user_per(child, addr, data);\n\n\t}\n\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -11,9 +11,14 @@\n \t\t\tunsigned long mask = PSW_MASK_USER;\n \n \t\t\tmask |= is_ri_task(child) ? PSW_MASK_RI : 0;\n-\t\t\tif ((data & ~mask) != PSW_USER_BITS)\n+\t\t\tif ((data ^ PSW_USER_BITS) & ~mask)\n+\t\t\t\t/* Invalid psw mask. */\n+\t\t\t\treturn -EINVAL;\n+\t\t\tif ((data & PSW_MASK_ASC) == PSW_ASC_HOME)\n+\t\t\t\t/* Invalid address-space-control bits */\n \t\t\t\treturn -EINVAL;\n \t\t\tif ((data & PSW_MASK_EA) && !(data & PSW_MASK_BA))\n+\t\t\t\t/* Invalid addressing mode bits */\n \t\t\t\treturn -EINVAL;\n \t\t}\n \t\t*(addr_t *)((addr_t) &task_pt_regs(child)->psw + addr) = data;",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\tif ((data & ~mask) != PSW_USER_BITS)"
            ],
            "added_lines": [
                "\t\t\tif ((data ^ PSW_USER_BITS) & ~mask)",
                "\t\t\t\t/* Invalid psw mask. */",
                "\t\t\t\treturn -EINVAL;",
                "\t\t\tif ((data & PSW_MASK_ASC) == PSW_ASC_HOME)",
                "\t\t\t\t/* Invalid address-space-control bits */",
                "\t\t\t\t/* Invalid addressing mode bits */"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-3534",
        "func_name": "torvalds/linux/__poke_user_compat",
        "description": "arch/s390/kernel/ptrace.c in the Linux kernel before 3.15.8 on the s390 platform does not properly restrict address-space control operations in PTRACE_POKEUSR_AREA requests, which allows local users to obtain read and write access to kernel memory locations, and consequently gain privileges, via a crafted application that makes a ptrace system call.",
        "git_url": "https://github.com/torvalds/linux/commit/dab6cf55f81a6e16b8147aed9a843e1691dcd318",
        "commit_title": "s390/ptrace: fix PSW mask check",
        "commit_text": " The PSW mask check of the PTRACE_POKEUSR_AREA command is incorrect. The PSW_MASK_USER define contains the PSW_MASK_ASC bits, the ptrace interface accepts all combinations for the address-space-control bits. To protect the kernel space the PSW mask check in ptrace needs to reject the address-space-control bit combination for home space.  Fixes CVE-2014-3534  Cc: stable@vger.kernel.org",
        "func_before": "static int __poke_user_compat(struct task_struct *child,\n\t\t\t      addr_t addr, addr_t data)\n{\n\tstruct compat_user *dummy32 = NULL;\n\t__u32 tmp = (__u32) data;\n\taddr_t offset;\n\n\tif (addr < (addr_t) &dummy32->regs.acrs) {\n\t\tstruct pt_regs *regs = task_pt_regs(child);\n\t\t/*\n\t\t * psw, gprs, acrs and orig_gpr2 are stored on the stack\n\t\t */\n\t\tif (addr == (addr_t) &dummy32->regs.psw.mask) {\n\t\t\t__u32 mask = PSW32_MASK_USER;\n\n\t\t\tmask |= is_ri_task(child) ? PSW32_MASK_RI : 0;\n\t\t\t/* Build a 64 bit psw mask from 31 bit mask. */\n\t\t\tif ((tmp & ~mask) != PSW32_USER_BITS)\n\t\t\t\t/* Invalid psw mask. */\n\t\t\t\treturn -EINVAL;\n\t\t\tregs->psw.mask = (regs->psw.mask & ~PSW_MASK_USER) |\n\t\t\t\t(regs->psw.mask & PSW_MASK_BA) |\n\t\t\t\t(__u64)(tmp & mask) << 32;\n\t\t} else if (addr == (addr_t) &dummy32->regs.psw.addr) {\n\t\t\t/* Build a 64 bit psw address from 31 bit address. */\n\t\t\tregs->psw.addr = (__u64) tmp & PSW32_ADDR_INSN;\n\t\t\t/* Transfer 31 bit amode bit to psw mask. */\n\t\t\tregs->psw.mask = (regs->psw.mask & ~PSW_MASK_BA) |\n\t\t\t\t(__u64)(tmp & PSW32_ADDR_AMODE);\n\t\t} else {\n\t\t\t/* gpr 0-15 */\n\t\t\t*(__u32*)((addr_t) &regs->psw + addr*2 + 4) = tmp;\n\t\t}\n\t} else if (addr < (addr_t) (&dummy32->regs.orig_gpr2)) {\n\t\t/*\n\t\t * access registers are stored in the thread structure\n\t\t */\n\t\toffset = addr - (addr_t) &dummy32->regs.acrs;\n\t\t*(__u32*)((addr_t) &child->thread.acrs + offset) = tmp;\n\n\t} else if (addr == (addr_t) (&dummy32->regs.orig_gpr2)) {\n\t\t/*\n\t\t * orig_gpr2 is stored on the kernel stack\n\t\t */\n\t\t*(__u32*)((addr_t) &task_pt_regs(child)->orig_gpr2 + 4) = tmp;\n\n\t} else if (addr < (addr_t) &dummy32->regs.fp_regs) {\n\t\t/*\n\t\t * prevent writess of padding hole between\n\t\t * orig_gpr2 and fp_regs on s390.\n\t\t */\n\t\treturn 0;\n\n\t} else if (addr < (addr_t) (&dummy32->regs.fp_regs + 1)) {\n\t\t/*\n\t\t * floating point regs. are stored in the thread structure \n\t\t */\n\t\tif (addr == (addr_t) &dummy32->regs.fp_regs.fpc &&\n\t\t    test_fp_ctl(tmp))\n\t\t\treturn -EINVAL;\n\t        offset = addr - (addr_t) &dummy32->regs.fp_regs;\n\t\t*(__u32 *)((addr_t) &child->thread.fp_regs + offset) = tmp;\n\n\t} else if (addr < (addr_t) (&dummy32->regs.per_info + 1)) {\n\t\t/*\n\t\t * Handle access to the per_info structure.\n\t\t */\n\t\taddr -= (addr_t) &dummy32->regs.per_info;\n\t\t__poke_user_per_compat(child, addr, data);\n\t}\n\n\treturn 0;\n}",
        "func": "static int __poke_user_compat(struct task_struct *child,\n\t\t\t      addr_t addr, addr_t data)\n{\n\tstruct compat_user *dummy32 = NULL;\n\t__u32 tmp = (__u32) data;\n\taddr_t offset;\n\n\tif (addr < (addr_t) &dummy32->regs.acrs) {\n\t\tstruct pt_regs *regs = task_pt_regs(child);\n\t\t/*\n\t\t * psw, gprs, acrs and orig_gpr2 are stored on the stack\n\t\t */\n\t\tif (addr == (addr_t) &dummy32->regs.psw.mask) {\n\t\t\t__u32 mask = PSW32_MASK_USER;\n\n\t\t\tmask |= is_ri_task(child) ? PSW32_MASK_RI : 0;\n\t\t\t/* Build a 64 bit psw mask from 31 bit mask. */\n\t\t\tif ((tmp ^ PSW32_USER_BITS) & ~mask)\n\t\t\t\t/* Invalid psw mask. */\n\t\t\t\treturn -EINVAL;\n\t\t\tif ((data & PSW32_MASK_ASC) == PSW32_ASC_HOME)\n\t\t\t\t/* Invalid address-space-control bits */\n\t\t\t\treturn -EINVAL;\n\t\t\tregs->psw.mask = (regs->psw.mask & ~PSW_MASK_USER) |\n\t\t\t\t(regs->psw.mask & PSW_MASK_BA) |\n\t\t\t\t(__u64)(tmp & mask) << 32;\n\t\t} else if (addr == (addr_t) &dummy32->regs.psw.addr) {\n\t\t\t/* Build a 64 bit psw address from 31 bit address. */\n\t\t\tregs->psw.addr = (__u64) tmp & PSW32_ADDR_INSN;\n\t\t\t/* Transfer 31 bit amode bit to psw mask. */\n\t\t\tregs->psw.mask = (regs->psw.mask & ~PSW_MASK_BA) |\n\t\t\t\t(__u64)(tmp & PSW32_ADDR_AMODE);\n\t\t} else {\n\t\t\t/* gpr 0-15 */\n\t\t\t*(__u32*)((addr_t) &regs->psw + addr*2 + 4) = tmp;\n\t\t}\n\t} else if (addr < (addr_t) (&dummy32->regs.orig_gpr2)) {\n\t\t/*\n\t\t * access registers are stored in the thread structure\n\t\t */\n\t\toffset = addr - (addr_t) &dummy32->regs.acrs;\n\t\t*(__u32*)((addr_t) &child->thread.acrs + offset) = tmp;\n\n\t} else if (addr == (addr_t) (&dummy32->regs.orig_gpr2)) {\n\t\t/*\n\t\t * orig_gpr2 is stored on the kernel stack\n\t\t */\n\t\t*(__u32*)((addr_t) &task_pt_regs(child)->orig_gpr2 + 4) = tmp;\n\n\t} else if (addr < (addr_t) &dummy32->regs.fp_regs) {\n\t\t/*\n\t\t * prevent writess of padding hole between\n\t\t * orig_gpr2 and fp_regs on s390.\n\t\t */\n\t\treturn 0;\n\n\t} else if (addr < (addr_t) (&dummy32->regs.fp_regs + 1)) {\n\t\t/*\n\t\t * floating point regs. are stored in the thread structure \n\t\t */\n\t\tif (addr == (addr_t) &dummy32->regs.fp_regs.fpc &&\n\t\t    test_fp_ctl(tmp))\n\t\t\treturn -EINVAL;\n\t        offset = addr - (addr_t) &dummy32->regs.fp_regs;\n\t\t*(__u32 *)((addr_t) &child->thread.fp_regs + offset) = tmp;\n\n\t} else if (addr < (addr_t) (&dummy32->regs.per_info + 1)) {\n\t\t/*\n\t\t * Handle access to the per_info structure.\n\t\t */\n\t\taddr -= (addr_t) &dummy32->regs.per_info;\n\t\t__poke_user_per_compat(child, addr, data);\n\t}\n\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -15,8 +15,11 @@\n \n \t\t\tmask |= is_ri_task(child) ? PSW32_MASK_RI : 0;\n \t\t\t/* Build a 64 bit psw mask from 31 bit mask. */\n-\t\t\tif ((tmp & ~mask) != PSW32_USER_BITS)\n+\t\t\tif ((tmp ^ PSW32_USER_BITS) & ~mask)\n \t\t\t\t/* Invalid psw mask. */\n+\t\t\t\treturn -EINVAL;\n+\t\t\tif ((data & PSW32_MASK_ASC) == PSW32_ASC_HOME)\n+\t\t\t\t/* Invalid address-space-control bits */\n \t\t\t\treturn -EINVAL;\n \t\t\tregs->psw.mask = (regs->psw.mask & ~PSW_MASK_USER) |\n \t\t\t\t(regs->psw.mask & PSW_MASK_BA) |",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\tif ((tmp & ~mask) != PSW32_USER_BITS)"
            ],
            "added_lines": [
                "\t\t\tif ((tmp ^ PSW32_USER_BITS) & ~mask)",
                "\t\t\t\treturn -EINVAL;",
                "\t\t\tif ((data & PSW32_MASK_ASC) == PSW32_ASC_HOME)",
                "\t\t\t\t/* Invalid address-space-control bits */"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-5206",
        "func_name": "torvalds/linux/do_remount",
        "description": "The do_remount function in fs/namespace.c in the Linux kernel through 3.16.1 does not maintain the MNT_LOCK_READONLY bit across a remount of a bind mount, which allows local users to bypass an intended read-only restriction and defeat certain sandbox protection mechanisms via a \"mount -o remount\" command within a user namespace.",
        "git_url": "https://github.com/torvalds/linux/commit/a6138db815df5ee542d848318e5dae681590fccd",
        "commit_title": "mnt: Only change user settable mount flags in remount",
        "commit_text": " Kenton Varda <kenton@sandstorm.io> discovered that by remounting a read-only bind mount read-only in a user namespace the MNT_LOCK_READONLY bit would be cleared, allowing an unprivileged user to the remount a read-only mount read-write.  Correct this by replacing the mask of mount flags to preserve with a mask of mount flags that may be changed, and preserve all others.   This ensures that any future bugs with this mask and remount will fail in an easy to detect way where new mount flags simply won't change.  Cc: stable@vger.kernel.org",
        "func_before": "static int do_remount(struct path *path, int flags, int mnt_flags,\n\t\t      void *data)\n{\n\tint err;\n\tstruct super_block *sb = path->mnt->mnt_sb;\n\tstruct mount *mnt = real_mount(path->mnt);\n\n\tif (!check_mnt(mnt))\n\t\treturn -EINVAL;\n\n\tif (path->dentry != path->mnt->mnt_root)\n\t\treturn -EINVAL;\n\n\terr = security_sb_remount(sb, data);\n\tif (err)\n\t\treturn err;\n\n\tdown_write(&sb->s_umount);\n\tif (flags & MS_BIND)\n\t\terr = change_mount_flags(path->mnt, flags);\n\telse if (!capable(CAP_SYS_ADMIN))\n\t\terr = -EPERM;\n\telse\n\t\terr = do_remount_sb(sb, flags, data, 0);\n\tif (!err) {\n\t\tlock_mount_hash();\n\t\tmnt_flags |= mnt->mnt.mnt_flags & MNT_PROPAGATION_MASK;\n\t\tmnt->mnt.mnt_flags = mnt_flags;\n\t\ttouch_mnt_namespace(mnt->mnt_ns);\n\t\tunlock_mount_hash();\n\t}\n\tup_write(&sb->s_umount);\n\treturn err;\n}",
        "func": "static int do_remount(struct path *path, int flags, int mnt_flags,\n\t\t      void *data)\n{\n\tint err;\n\tstruct super_block *sb = path->mnt->mnt_sb;\n\tstruct mount *mnt = real_mount(path->mnt);\n\n\tif (!check_mnt(mnt))\n\t\treturn -EINVAL;\n\n\tif (path->dentry != path->mnt->mnt_root)\n\t\treturn -EINVAL;\n\n\terr = security_sb_remount(sb, data);\n\tif (err)\n\t\treturn err;\n\n\tdown_write(&sb->s_umount);\n\tif (flags & MS_BIND)\n\t\terr = change_mount_flags(path->mnt, flags);\n\telse if (!capable(CAP_SYS_ADMIN))\n\t\terr = -EPERM;\n\telse\n\t\terr = do_remount_sb(sb, flags, data, 0);\n\tif (!err) {\n\t\tlock_mount_hash();\n\t\tmnt_flags |= mnt->mnt.mnt_flags & ~MNT_USER_SETTABLE_MASK;\n\t\tmnt->mnt.mnt_flags = mnt_flags;\n\t\ttouch_mnt_namespace(mnt->mnt_ns);\n\t\tunlock_mount_hash();\n\t}\n\tup_write(&sb->s_umount);\n\treturn err;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -24,7 +24,7 @@\n \t\terr = do_remount_sb(sb, flags, data, 0);\n \tif (!err) {\n \t\tlock_mount_hash();\n-\t\tmnt_flags |= mnt->mnt.mnt_flags & MNT_PROPAGATION_MASK;\n+\t\tmnt_flags |= mnt->mnt.mnt_flags & ~MNT_USER_SETTABLE_MASK;\n \t\tmnt->mnt.mnt_flags = mnt_flags;\n \t\ttouch_mnt_namespace(mnt->mnt_ns);\n \t\tunlock_mount_hash();",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tmnt_flags |= mnt->mnt.mnt_flags & MNT_PROPAGATION_MASK;"
            ],
            "added_lines": [
                "\t\tmnt_flags |= mnt->mnt.mnt_flags & ~MNT_USER_SETTABLE_MASK;"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-5207",
        "func_name": "torvalds/linux/clone_mnt",
        "description": "fs/namespace.c in the Linux kernel through 3.16.1 does not properly restrict clearing MNT_NODEV, MNT_NOSUID, and MNT_NOEXEC and changing MNT_ATIME_MASK during a remount of a bind mount, which allows local users to gain privileges, interfere with backups and auditing on systems that had atime enabled, or cause a denial of service (excessive filesystem updating) on systems that had atime disabled via a \"mount -o remount\" command within a user namespace.",
        "git_url": "https://github.com/torvalds/linux/commit/9566d6742852c527bf5af38af5cbb878dad75705",
        "commit_title": "mnt: Correct permission checks in do_remount",
        "commit_text": " While invesgiating the issue where in \"mount --bind -oremount,ro ...\" would result in later \"mount --bind -oremount,rw\" succeeding even if the mount started off locked I realized that there are several additional mount flags that should be locked and are not.  In particular MNT_NOSUID, MNT_NODEV, MNT_NOEXEC, and the atime flags in addition to MNT_READONLY should all be locked.  These flags are all per superblock, can all be changed with MS_BIND, and should not be changable if set by a more privileged user.  The following additions to the current logic are added in this patch. - nosuid may not be clearable by a less privileged user. - nodev  may not be clearable by a less privielged user. - noexec may not be clearable by a less privileged user. - atime flags may not be changeable by a less privileged user.  The logic with atime is that always setting atime on access is a global policy and backup software and auditing software could break if atime bits are not updated (when they are configured to be updated), and serious performance degradation could result (DOS attack) if atime updates happen when they have been explicitly disabled.  Therefore an unprivileged user should not be able to mess with the atime bits set by a more privileged user.  The additional restrictions are implemented with the addition of MNT_LOCK_NOSUID, MNT_LOCK_NODEV, MNT_LOCK_NOEXEC, and MNT_LOCK_ATIME mnt flags.  Taken together these changes and the fixes for MNT_LOCK_READONLY should make it safe for an unprivileged user to create a user namespace and to call \"mount --bind -o remount,... ...\" without the danger of mount flags being changed maliciously.  Cc: stable@vger.kernel.org",
        "func_before": "static struct mount *clone_mnt(struct mount *old, struct dentry *root,\n\t\t\t\t\tint flag)\n{\n\tstruct super_block *sb = old->mnt.mnt_sb;\n\tstruct mount *mnt;\n\tint err;\n\n\tmnt = alloc_vfsmnt(old->mnt_devname);\n\tif (!mnt)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tif (flag & (CL_SLAVE | CL_PRIVATE | CL_SHARED_TO_SLAVE))\n\t\tmnt->mnt_group_id = 0; /* not a peer of original */\n\telse\n\t\tmnt->mnt_group_id = old->mnt_group_id;\n\n\tif ((flag & CL_MAKE_SHARED) && !mnt->mnt_group_id) {\n\t\terr = mnt_alloc_group_id(mnt);\n\t\tif (err)\n\t\t\tgoto out_free;\n\t}\n\n\tmnt->mnt.mnt_flags = old->mnt.mnt_flags & ~(MNT_WRITE_HOLD|MNT_MARKED);\n\t/* Don't allow unprivileged users to change mount flags */\n\tif ((flag & CL_UNPRIVILEGED) && (mnt->mnt.mnt_flags & MNT_READONLY))\n\t\tmnt->mnt.mnt_flags |= MNT_LOCK_READONLY;\n\n\t/* Don't allow unprivileged users to reveal what is under a mount */\n\tif ((flag & CL_UNPRIVILEGED) && list_empty(&old->mnt_expire))\n\t\tmnt->mnt.mnt_flags |= MNT_LOCKED;\n\n\tatomic_inc(&sb->s_active);\n\tmnt->mnt.mnt_sb = sb;\n\tmnt->mnt.mnt_root = dget(root);\n\tmnt->mnt_mountpoint = mnt->mnt.mnt_root;\n\tmnt->mnt_parent = mnt;\n\tlock_mount_hash();\n\tlist_add_tail(&mnt->mnt_instance, &sb->s_mounts);\n\tunlock_mount_hash();\n\n\tif ((flag & CL_SLAVE) ||\n\t    ((flag & CL_SHARED_TO_SLAVE) && IS_MNT_SHARED(old))) {\n\t\tlist_add(&mnt->mnt_slave, &old->mnt_slave_list);\n\t\tmnt->mnt_master = old;\n\t\tCLEAR_MNT_SHARED(mnt);\n\t} else if (!(flag & CL_PRIVATE)) {\n\t\tif ((flag & CL_MAKE_SHARED) || IS_MNT_SHARED(old))\n\t\t\tlist_add(&mnt->mnt_share, &old->mnt_share);\n\t\tif (IS_MNT_SLAVE(old))\n\t\t\tlist_add(&mnt->mnt_slave, &old->mnt_slave);\n\t\tmnt->mnt_master = old->mnt_master;\n\t}\n\tif (flag & CL_MAKE_SHARED)\n\t\tset_mnt_shared(mnt);\n\n\t/* stick the duplicate mount on the same expiry list\n\t * as the original if that was on one */\n\tif (flag & CL_EXPIRE) {\n\t\tif (!list_empty(&old->mnt_expire))\n\t\t\tlist_add(&mnt->mnt_expire, &old->mnt_expire);\n\t}\n\n\treturn mnt;\n\n out_free:\n\tmnt_free_id(mnt);\n\tfree_vfsmnt(mnt);\n\treturn ERR_PTR(err);\n}",
        "func": "static struct mount *clone_mnt(struct mount *old, struct dentry *root,\n\t\t\t\t\tint flag)\n{\n\tstruct super_block *sb = old->mnt.mnt_sb;\n\tstruct mount *mnt;\n\tint err;\n\n\tmnt = alloc_vfsmnt(old->mnt_devname);\n\tif (!mnt)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tif (flag & (CL_SLAVE | CL_PRIVATE | CL_SHARED_TO_SLAVE))\n\t\tmnt->mnt_group_id = 0; /* not a peer of original */\n\telse\n\t\tmnt->mnt_group_id = old->mnt_group_id;\n\n\tif ((flag & CL_MAKE_SHARED) && !mnt->mnt_group_id) {\n\t\terr = mnt_alloc_group_id(mnt);\n\t\tif (err)\n\t\t\tgoto out_free;\n\t}\n\n\tmnt->mnt.mnt_flags = old->mnt.mnt_flags & ~(MNT_WRITE_HOLD|MNT_MARKED);\n\t/* Don't allow unprivileged users to change mount flags */\n\tif (flag & CL_UNPRIVILEGED) {\n\t\tmnt->mnt.mnt_flags |= MNT_LOCK_ATIME;\n\n\t\tif (mnt->mnt.mnt_flags & MNT_READONLY)\n\t\t\tmnt->mnt.mnt_flags |= MNT_LOCK_READONLY;\n\n\t\tif (mnt->mnt.mnt_flags & MNT_NODEV)\n\t\t\tmnt->mnt.mnt_flags |= MNT_LOCK_NODEV;\n\n\t\tif (mnt->mnt.mnt_flags & MNT_NOSUID)\n\t\t\tmnt->mnt.mnt_flags |= MNT_LOCK_NOSUID;\n\n\t\tif (mnt->mnt.mnt_flags & MNT_NOEXEC)\n\t\t\tmnt->mnt.mnt_flags |= MNT_LOCK_NOEXEC;\n\t}\n\n\t/* Don't allow unprivileged users to reveal what is under a mount */\n\tif ((flag & CL_UNPRIVILEGED) && list_empty(&old->mnt_expire))\n\t\tmnt->mnt.mnt_flags |= MNT_LOCKED;\n\n\tatomic_inc(&sb->s_active);\n\tmnt->mnt.mnt_sb = sb;\n\tmnt->mnt.mnt_root = dget(root);\n\tmnt->mnt_mountpoint = mnt->mnt.mnt_root;\n\tmnt->mnt_parent = mnt;\n\tlock_mount_hash();\n\tlist_add_tail(&mnt->mnt_instance, &sb->s_mounts);\n\tunlock_mount_hash();\n\n\tif ((flag & CL_SLAVE) ||\n\t    ((flag & CL_SHARED_TO_SLAVE) && IS_MNT_SHARED(old))) {\n\t\tlist_add(&mnt->mnt_slave, &old->mnt_slave_list);\n\t\tmnt->mnt_master = old;\n\t\tCLEAR_MNT_SHARED(mnt);\n\t} else if (!(flag & CL_PRIVATE)) {\n\t\tif ((flag & CL_MAKE_SHARED) || IS_MNT_SHARED(old))\n\t\t\tlist_add(&mnt->mnt_share, &old->mnt_share);\n\t\tif (IS_MNT_SLAVE(old))\n\t\t\tlist_add(&mnt->mnt_slave, &old->mnt_slave);\n\t\tmnt->mnt_master = old->mnt_master;\n\t}\n\tif (flag & CL_MAKE_SHARED)\n\t\tset_mnt_shared(mnt);\n\n\t/* stick the duplicate mount on the same expiry list\n\t * as the original if that was on one */\n\tif (flag & CL_EXPIRE) {\n\t\tif (!list_empty(&old->mnt_expire))\n\t\t\tlist_add(&mnt->mnt_expire, &old->mnt_expire);\n\t}\n\n\treturn mnt;\n\n out_free:\n\tmnt_free_id(mnt);\n\tfree_vfsmnt(mnt);\n\treturn ERR_PTR(err);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -22,8 +22,21 @@\n \n \tmnt->mnt.mnt_flags = old->mnt.mnt_flags & ~(MNT_WRITE_HOLD|MNT_MARKED);\n \t/* Don't allow unprivileged users to change mount flags */\n-\tif ((flag & CL_UNPRIVILEGED) && (mnt->mnt.mnt_flags & MNT_READONLY))\n-\t\tmnt->mnt.mnt_flags |= MNT_LOCK_READONLY;\n+\tif (flag & CL_UNPRIVILEGED) {\n+\t\tmnt->mnt.mnt_flags |= MNT_LOCK_ATIME;\n+\n+\t\tif (mnt->mnt.mnt_flags & MNT_READONLY)\n+\t\t\tmnt->mnt.mnt_flags |= MNT_LOCK_READONLY;\n+\n+\t\tif (mnt->mnt.mnt_flags & MNT_NODEV)\n+\t\t\tmnt->mnt.mnt_flags |= MNT_LOCK_NODEV;\n+\n+\t\tif (mnt->mnt.mnt_flags & MNT_NOSUID)\n+\t\t\tmnt->mnt.mnt_flags |= MNT_LOCK_NOSUID;\n+\n+\t\tif (mnt->mnt.mnt_flags & MNT_NOEXEC)\n+\t\t\tmnt->mnt.mnt_flags |= MNT_LOCK_NOEXEC;\n+\t}\n \n \t/* Don't allow unprivileged users to reveal what is under a mount */\n \tif ((flag & CL_UNPRIVILEGED) && list_empty(&old->mnt_expire))",
        "diff_line_info": {
            "deleted_lines": [
                "\tif ((flag & CL_UNPRIVILEGED) && (mnt->mnt.mnt_flags & MNT_READONLY))",
                "\t\tmnt->mnt.mnt_flags |= MNT_LOCK_READONLY;"
            ],
            "added_lines": [
                "\tif (flag & CL_UNPRIVILEGED) {",
                "\t\tmnt->mnt.mnt_flags |= MNT_LOCK_ATIME;",
                "",
                "\t\tif (mnt->mnt.mnt_flags & MNT_READONLY)",
                "\t\t\tmnt->mnt.mnt_flags |= MNT_LOCK_READONLY;",
                "",
                "\t\tif (mnt->mnt.mnt_flags & MNT_NODEV)",
                "\t\t\tmnt->mnt.mnt_flags |= MNT_LOCK_NODEV;",
                "",
                "\t\tif (mnt->mnt.mnt_flags & MNT_NOSUID)",
                "\t\t\tmnt->mnt.mnt_flags |= MNT_LOCK_NOSUID;",
                "",
                "\t\tif (mnt->mnt.mnt_flags & MNT_NOEXEC)",
                "\t\t\tmnt->mnt.mnt_flags |= MNT_LOCK_NOEXEC;",
                "\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-5207",
        "func_name": "torvalds/linux/do_remount",
        "description": "fs/namespace.c in the Linux kernel through 3.16.1 does not properly restrict clearing MNT_NODEV, MNT_NOSUID, and MNT_NOEXEC and changing MNT_ATIME_MASK during a remount of a bind mount, which allows local users to gain privileges, interfere with backups and auditing on systems that had atime enabled, or cause a denial of service (excessive filesystem updating) on systems that had atime disabled via a \"mount -o remount\" command within a user namespace.",
        "git_url": "https://github.com/torvalds/linux/commit/9566d6742852c527bf5af38af5cbb878dad75705",
        "commit_title": "mnt: Correct permission checks in do_remount",
        "commit_text": " While invesgiating the issue where in \"mount --bind -oremount,ro ...\" would result in later \"mount --bind -oremount,rw\" succeeding even if the mount started off locked I realized that there are several additional mount flags that should be locked and are not.  In particular MNT_NOSUID, MNT_NODEV, MNT_NOEXEC, and the atime flags in addition to MNT_READONLY should all be locked.  These flags are all per superblock, can all be changed with MS_BIND, and should not be changable if set by a more privileged user.  The following additions to the current logic are added in this patch. - nosuid may not be clearable by a less privileged user. - nodev  may not be clearable by a less privielged user. - noexec may not be clearable by a less privileged user. - atime flags may not be changeable by a less privileged user.  The logic with atime is that always setting atime on access is a global policy and backup software and auditing software could break if atime bits are not updated (when they are configured to be updated), and serious performance degradation could result (DOS attack) if atime updates happen when they have been explicitly disabled.  Therefore an unprivileged user should not be able to mess with the atime bits set by a more privileged user.  The additional restrictions are implemented with the addition of MNT_LOCK_NOSUID, MNT_LOCK_NODEV, MNT_LOCK_NOEXEC, and MNT_LOCK_ATIME mnt flags.  Taken together these changes and the fixes for MNT_LOCK_READONLY should make it safe for an unprivileged user to create a user namespace and to call \"mount --bind -o remount,... ...\" without the danger of mount flags being changed maliciously.  Cc: stable@vger.kernel.org",
        "func_before": "static int do_remount(struct path *path, int flags, int mnt_flags,\n\t\t      void *data)\n{\n\tint err;\n\tstruct super_block *sb = path->mnt->mnt_sb;\n\tstruct mount *mnt = real_mount(path->mnt);\n\n\tif (!check_mnt(mnt))\n\t\treturn -EINVAL;\n\n\tif (path->dentry != path->mnt->mnt_root)\n\t\treturn -EINVAL;\n\n\t/* Don't allow changing of locked mnt flags.\n\t *\n\t * No locks need to be held here while testing the various\n\t * MNT_LOCK flags because those flags can never be cleared\n\t * once they are set.\n\t */\n\tif ((mnt->mnt.mnt_flags & MNT_LOCK_READONLY) &&\n\t    !(mnt_flags & MNT_READONLY)) {\n\t\treturn -EPERM;\n\t}\n\terr = security_sb_remount(sb, data);\n\tif (err)\n\t\treturn err;\n\n\tdown_write(&sb->s_umount);\n\tif (flags & MS_BIND)\n\t\terr = change_mount_flags(path->mnt, flags);\n\telse if (!capable(CAP_SYS_ADMIN))\n\t\terr = -EPERM;\n\telse\n\t\terr = do_remount_sb(sb, flags, data, 0);\n\tif (!err) {\n\t\tlock_mount_hash();\n\t\tmnt_flags |= mnt->mnt.mnt_flags & ~MNT_USER_SETTABLE_MASK;\n\t\tmnt->mnt.mnt_flags = mnt_flags;\n\t\ttouch_mnt_namespace(mnt->mnt_ns);\n\t\tunlock_mount_hash();\n\t}\n\tup_write(&sb->s_umount);\n\treturn err;\n}",
        "func": "static int do_remount(struct path *path, int flags, int mnt_flags,\n\t\t      void *data)\n{\n\tint err;\n\tstruct super_block *sb = path->mnt->mnt_sb;\n\tstruct mount *mnt = real_mount(path->mnt);\n\n\tif (!check_mnt(mnt))\n\t\treturn -EINVAL;\n\n\tif (path->dentry != path->mnt->mnt_root)\n\t\treturn -EINVAL;\n\n\t/* Don't allow changing of locked mnt flags.\n\t *\n\t * No locks need to be held here while testing the various\n\t * MNT_LOCK flags because those flags can never be cleared\n\t * once they are set.\n\t */\n\tif ((mnt->mnt.mnt_flags & MNT_LOCK_READONLY) &&\n\t    !(mnt_flags & MNT_READONLY)) {\n\t\treturn -EPERM;\n\t}\n\tif ((mnt->mnt.mnt_flags & MNT_LOCK_NODEV) &&\n\t    !(mnt_flags & MNT_NODEV)) {\n\t\treturn -EPERM;\n\t}\n\tif ((mnt->mnt.mnt_flags & MNT_LOCK_NOSUID) &&\n\t    !(mnt_flags & MNT_NOSUID)) {\n\t\treturn -EPERM;\n\t}\n\tif ((mnt->mnt.mnt_flags & MNT_LOCK_NOEXEC) &&\n\t    !(mnt_flags & MNT_NOEXEC)) {\n\t\treturn -EPERM;\n\t}\n\tif ((mnt->mnt.mnt_flags & MNT_LOCK_ATIME) &&\n\t    ((mnt->mnt.mnt_flags & MNT_ATIME_MASK) != (mnt_flags & MNT_ATIME_MASK))) {\n\t\treturn -EPERM;\n\t}\n\n\terr = security_sb_remount(sb, data);\n\tif (err)\n\t\treturn err;\n\n\tdown_write(&sb->s_umount);\n\tif (flags & MS_BIND)\n\t\terr = change_mount_flags(path->mnt, flags);\n\telse if (!capable(CAP_SYS_ADMIN))\n\t\terr = -EPERM;\n\telse\n\t\terr = do_remount_sb(sb, flags, data, 0);\n\tif (!err) {\n\t\tlock_mount_hash();\n\t\tmnt_flags |= mnt->mnt.mnt_flags & ~MNT_USER_SETTABLE_MASK;\n\t\tmnt->mnt.mnt_flags = mnt_flags;\n\t\ttouch_mnt_namespace(mnt->mnt_ns);\n\t\tunlock_mount_hash();\n\t}\n\tup_write(&sb->s_umount);\n\treturn err;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -21,6 +21,23 @@\n \t    !(mnt_flags & MNT_READONLY)) {\n \t\treturn -EPERM;\n \t}\n+\tif ((mnt->mnt.mnt_flags & MNT_LOCK_NODEV) &&\n+\t    !(mnt_flags & MNT_NODEV)) {\n+\t\treturn -EPERM;\n+\t}\n+\tif ((mnt->mnt.mnt_flags & MNT_LOCK_NOSUID) &&\n+\t    !(mnt_flags & MNT_NOSUID)) {\n+\t\treturn -EPERM;\n+\t}\n+\tif ((mnt->mnt.mnt_flags & MNT_LOCK_NOEXEC) &&\n+\t    !(mnt_flags & MNT_NOEXEC)) {\n+\t\treturn -EPERM;\n+\t}\n+\tif ((mnt->mnt.mnt_flags & MNT_LOCK_ATIME) &&\n+\t    ((mnt->mnt.mnt_flags & MNT_ATIME_MASK) != (mnt_flags & MNT_ATIME_MASK))) {\n+\t\treturn -EPERM;\n+\t}\n+\n \terr = security_sb_remount(sb, data);\n \tif (err)\n \t\treturn err;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tif ((mnt->mnt.mnt_flags & MNT_LOCK_NODEV) &&",
                "\t    !(mnt_flags & MNT_NODEV)) {",
                "\t\treturn -EPERM;",
                "\t}",
                "\tif ((mnt->mnt.mnt_flags & MNT_LOCK_NOSUID) &&",
                "\t    !(mnt_flags & MNT_NOSUID)) {",
                "\t\treturn -EPERM;",
                "\t}",
                "\tif ((mnt->mnt.mnt_flags & MNT_LOCK_NOEXEC) &&",
                "\t    !(mnt_flags & MNT_NOEXEC)) {",
                "\t\treturn -EPERM;",
                "\t}",
                "\tif ((mnt->mnt.mnt_flags & MNT_LOCK_ATIME) &&",
                "\t    ((mnt->mnt.mnt_flags & MNT_ATIME_MASK) != (mnt_flags & MNT_ATIME_MASK))) {",
                "\t\treturn -EPERM;",
                "\t}",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2014-5207",
        "func_name": "torvalds/linux/do_new_mount",
        "description": "fs/namespace.c in the Linux kernel through 3.16.1 does not properly restrict clearing MNT_NODEV, MNT_NOSUID, and MNT_NOEXEC and changing MNT_ATIME_MASK during a remount of a bind mount, which allows local users to gain privileges, interfere with backups and auditing on systems that had atime enabled, or cause a denial of service (excessive filesystem updating) on systems that had atime disabled via a \"mount -o remount\" command within a user namespace.",
        "git_url": "https://github.com/torvalds/linux/commit/9566d6742852c527bf5af38af5cbb878dad75705",
        "commit_title": "mnt: Correct permission checks in do_remount",
        "commit_text": " While invesgiating the issue where in \"mount --bind -oremount,ro ...\" would result in later \"mount --bind -oremount,rw\" succeeding even if the mount started off locked I realized that there are several additional mount flags that should be locked and are not.  In particular MNT_NOSUID, MNT_NODEV, MNT_NOEXEC, and the atime flags in addition to MNT_READONLY should all be locked.  These flags are all per superblock, can all be changed with MS_BIND, and should not be changable if set by a more privileged user.  The following additions to the current logic are added in this patch. - nosuid may not be clearable by a less privileged user. - nodev  may not be clearable by a less privielged user. - noexec may not be clearable by a less privileged user. - atime flags may not be changeable by a less privileged user.  The logic with atime is that always setting atime on access is a global policy and backup software and auditing software could break if atime bits are not updated (when they are configured to be updated), and serious performance degradation could result (DOS attack) if atime updates happen when they have been explicitly disabled.  Therefore an unprivileged user should not be able to mess with the atime bits set by a more privileged user.  The additional restrictions are implemented with the addition of MNT_LOCK_NOSUID, MNT_LOCK_NODEV, MNT_LOCK_NOEXEC, and MNT_LOCK_ATIME mnt flags.  Taken together these changes and the fixes for MNT_LOCK_READONLY should make it safe for an unprivileged user to create a user namespace and to call \"mount --bind -o remount,... ...\" without the danger of mount flags being changed maliciously.  Cc: stable@vger.kernel.org",
        "func_before": "static int do_new_mount(struct path *path, const char *fstype, int flags,\n\t\t\tint mnt_flags, const char *name, void *data)\n{\n\tstruct file_system_type *type;\n\tstruct user_namespace *user_ns = current->nsproxy->mnt_ns->user_ns;\n\tstruct vfsmount *mnt;\n\tint err;\n\n\tif (!fstype)\n\t\treturn -EINVAL;\n\n\ttype = get_fs_type(fstype);\n\tif (!type)\n\t\treturn -ENODEV;\n\n\tif (user_ns != &init_user_ns) {\n\t\tif (!(type->fs_flags & FS_USERNS_MOUNT)) {\n\t\t\tput_filesystem(type);\n\t\t\treturn -EPERM;\n\t\t}\n\t\t/* Only in special cases allow devices from mounts\n\t\t * created outside the initial user namespace.\n\t\t */\n\t\tif (!(type->fs_flags & FS_USERNS_DEV_MOUNT)) {\n\t\t\tflags |= MS_NODEV;\n\t\t\tmnt_flags |= MNT_NODEV;\n\t\t}\n\t}\n\n\tmnt = vfs_kern_mount(type, flags, name, data);\n\tif (!IS_ERR(mnt) && (type->fs_flags & FS_HAS_SUBTYPE) &&\n\t    !mnt->mnt_sb->s_subtype)\n\t\tmnt = fs_set_subtype(mnt, fstype);\n\n\tput_filesystem(type);\n\tif (IS_ERR(mnt))\n\t\treturn PTR_ERR(mnt);\n\n\terr = do_add_mount(real_mount(mnt), path, mnt_flags);\n\tif (err)\n\t\tmntput(mnt);\n\treturn err;\n}",
        "func": "static int do_new_mount(struct path *path, const char *fstype, int flags,\n\t\t\tint mnt_flags, const char *name, void *data)\n{\n\tstruct file_system_type *type;\n\tstruct user_namespace *user_ns = current->nsproxy->mnt_ns->user_ns;\n\tstruct vfsmount *mnt;\n\tint err;\n\n\tif (!fstype)\n\t\treturn -EINVAL;\n\n\ttype = get_fs_type(fstype);\n\tif (!type)\n\t\treturn -ENODEV;\n\n\tif (user_ns != &init_user_ns) {\n\t\tif (!(type->fs_flags & FS_USERNS_MOUNT)) {\n\t\t\tput_filesystem(type);\n\t\t\treturn -EPERM;\n\t\t}\n\t\t/* Only in special cases allow devices from mounts\n\t\t * created outside the initial user namespace.\n\t\t */\n\t\tif (!(type->fs_flags & FS_USERNS_DEV_MOUNT)) {\n\t\t\tflags |= MS_NODEV;\n\t\t\tmnt_flags |= MNT_NODEV | MNT_LOCK_NODEV;\n\t\t}\n\t}\n\n\tmnt = vfs_kern_mount(type, flags, name, data);\n\tif (!IS_ERR(mnt) && (type->fs_flags & FS_HAS_SUBTYPE) &&\n\t    !mnt->mnt_sb->s_subtype)\n\t\tmnt = fs_set_subtype(mnt, fstype);\n\n\tput_filesystem(type);\n\tif (IS_ERR(mnt))\n\t\treturn PTR_ERR(mnt);\n\n\terr = do_add_mount(real_mount(mnt), path, mnt_flags);\n\tif (err)\n\t\tmntput(mnt);\n\treturn err;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -23,7 +23,7 @@\n \t\t */\n \t\tif (!(type->fs_flags & FS_USERNS_DEV_MOUNT)) {\n \t\t\tflags |= MS_NODEV;\n-\t\t\tmnt_flags |= MNT_NODEV;\n+\t\t\tmnt_flags |= MNT_NODEV | MNT_LOCK_NODEV;\n \t\t}\n \t}\n ",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\tmnt_flags |= MNT_NODEV;"
            ],
            "added_lines": [
                "\t\t\tmnt_flags |= MNT_NODEV | MNT_LOCK_NODEV;"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-9644",
        "func_name": "torvalds/linux/crypto_lookup_template",
        "description": "The Crypto API in the Linux kernel before 3.18.5 allows local users to load arbitrary kernel modules via a bind system call for an AF_ALG socket with a parenthesized module template expression in the salg_name field, as demonstrated by the vfat(aes) expression, a different vulnerability than CVE-2013-7421.",
        "git_url": "https://github.com/torvalds/linux/commit/4943ba16bbc2db05115707b3ff7b4874e9e3c560",
        "commit_title": "crypto: include crypto- module prefix in template",
        "commit_text": " This adds the module loading prefix \"crypto-\" to the template lookup as well.  For example, attempting to load 'vfat(blowfish)' via AF_ALG now correctly includes the \"crypto-\" prefix at every level, correctly rejecting \"vfat\":  \tnet-pf-38 \talgif-hash \tcrypto-vfat(blowfish) \tcrypto-vfat(blowfish)-all \tcrypto-vfat ",
        "func_before": "struct crypto_template *crypto_lookup_template(const char *name)\n{\n\treturn try_then_request_module(__crypto_lookup_template(name), \"%s\",\n\t\t\t\t       name);\n}",
        "func": "struct crypto_template *crypto_lookup_template(const char *name)\n{\n\treturn try_then_request_module(__crypto_lookup_template(name),\n\t\t\t\t       \"crypto-%s\", name);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,5 @@\n struct crypto_template *crypto_lookup_template(const char *name)\n {\n-\treturn try_then_request_module(__crypto_lookup_template(name), \"%s\",\n-\t\t\t\t       name);\n+\treturn try_then_request_module(__crypto_lookup_template(name),\n+\t\t\t\t       \"crypto-%s\", name);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\treturn try_then_request_module(__crypto_lookup_template(name), \"%s\",",
                "\t\t\t\t       name);"
            ],
            "added_lines": [
                "\treturn try_then_request_module(__crypto_lookup_template(name),",
                "\t\t\t\t       \"crypto-%s\", name);"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-9644",
        "func_name": "torvalds/linux/hmac_setkey",
        "description": "The Crypto API in the Linux kernel before 3.18.5 allows local users to load arbitrary kernel modules via a bind system call for an AF_ALG socket with a parenthesized module template expression in the salg_name field, as demonstrated by the vfat(aes) expression, a different vulnerability than CVE-2013-7421.",
        "git_url": "https://github.com/torvalds/linux/commit/4943ba16bbc2db05115707b3ff7b4874e9e3c560",
        "commit_title": "crypto: include crypto- module prefix in template",
        "commit_text": " This adds the module loading prefix \"crypto-\" to the template lookup as well.  For example, attempting to load 'vfat(blowfish)' via AF_ALG now correctly includes the \"crypto-\" prefix at every level, correctly rejecting \"vfat\":  \tnet-pf-38 \talgif-hash \tcrypto-vfat(blowfish) \tcrypto-vfat(blowfish)-all \tcrypto-vfat ",
        "func_before": "static int hmac_setkey(struct crypto_shash *parent,\n\t\t       const u8 *inkey, unsigned int keylen)\n{\n\tint bs = crypto_shash_blocksize(parent);\n\tint ds = crypto_shash_digestsize(parent);\n\tint ss = crypto_shash_statesize(parent);\n\tchar *ipad = crypto_shash_ctx_aligned(parent);\n\tchar *opad = ipad + ss;\n\tstruct hmac_ctx *ctx = align_ptr(opad + ss,\n\t\t\t\t\t crypto_tfm_ctx_alignment());\n\tstruct crypto_shash *hash = ctx->hash;\n\tSHASH_DESC_ON_STACK(shash, hash);\n\tunsigned int i;\n\n\tshash->tfm = hash;\n\tshash->flags = crypto_shash_get_flags(parent)\n\t\t& CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\tif (keylen > bs) {\n\t\tint err;\n\n\t\terr = crypto_shash_digest(shash, inkey, keylen, ipad);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tkeylen = ds;\n\t} else\n\t\tmemcpy(ipad, inkey, keylen);\n\n\tmemset(ipad + keylen, 0, bs - keylen);\n\tmemcpy(opad, ipad, bs);\n\n\tfor (i = 0; i < bs; i++) {\n\t\tipad[i] ^= 0x36;\n\t\topad[i] ^= 0x5c;\n\t}\n\n\treturn crypto_shash_init(shash) ?:\n\t       crypto_shash_update(shash, ipad, bs) ?:\n\t       crypto_shash_export(shash, ipad) ?:\n\t       crypto_shash_init(shash) ?:\n\t       crypto_shash_update(shash, opad, bs) ?:\n\t       crypto_shash_export(shash, opad);\n}\n\nstatic int hmac_export(struct shash_desc *pdesc, void *out)\n{\n\tstruct shash_desc *desc = shash_desc_ctx(pdesc);\n\n\tdesc->flags = pdesc->flags & CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\treturn crypto_shash_export(desc, out);\n}\n\nstatic int hmac_import(struct shash_desc *pdesc, const void *in)\n{\n\tstruct shash_desc *desc = shash_desc_ctx(pdesc);\n\tstruct hmac_ctx *ctx = hmac_ctx(pdesc->tfm);\n\n\tdesc->tfm = ctx->hash;\n\tdesc->flags = pdesc->flags & CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\treturn crypto_shash_import(desc, in);\n}\n\nstatic int hmac_init(struct shash_desc *pdesc)\n{\n\treturn hmac_import(pdesc, crypto_shash_ctx_aligned(pdesc->tfm));\n}\n\nstatic int hmac_update(struct shash_desc *pdesc,\n\t\t       const u8 *data, unsigned int nbytes)\n{\n\tstruct shash_desc *desc = shash_desc_ctx(pdesc);\n\n\tdesc->flags = pdesc->flags & CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\treturn crypto_shash_update(desc, data, nbytes);\n}\n\nstatic int hmac_final(struct shash_desc *pdesc, u8 *out)\n{\n\tstruct crypto_shash *parent = pdesc->tfm;\n\tint ds = crypto_shash_digestsize(parent);\n\tint ss = crypto_shash_statesize(parent);\n\tchar *opad = crypto_shash_ctx_aligned(parent) + ss;\n\tstruct shash_desc *desc = shash_desc_ctx(pdesc);\n\n\tdesc->flags = pdesc->flags & CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\treturn crypto_shash_final(desc, out) ?:\n\t       crypto_shash_import(desc, opad) ?:\n\t       crypto_shash_finup(desc, out, ds, out);\n}\n\nstatic int hmac_finup(struct shash_desc *pdesc, const u8 *data,\n\t\t      unsigned int nbytes, u8 *out)\n{\n\n\tstruct crypto_shash *parent = pdesc->tfm;\n\tint ds = crypto_shash_digestsize(parent);\n\tint ss = crypto_shash_statesize(parent);\n\tchar *opad = crypto_shash_ctx_aligned(parent) + ss;\n\tstruct shash_desc *desc = shash_desc_ctx(pdesc);\n\n\tdesc->flags = pdesc->flags & CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\treturn crypto_shash_finup(desc, data, nbytes, out) ?:\n\t       crypto_shash_import(desc, opad) ?:\n\t       crypto_shash_finup(desc, out, ds, out);\n}\n\nstatic int hmac_init_tfm(struct crypto_tfm *tfm)\n{\n\tstruct crypto_shash *parent = __crypto_shash_cast(tfm);\n\tstruct crypto_shash *hash;\n\tstruct crypto_instance *inst = (void *)tfm->__crt_alg;\n\tstruct crypto_shash_spawn *spawn = crypto_instance_ctx(inst);\n\tstruct hmac_ctx *ctx = hmac_ctx(parent);\n\n\thash = crypto_spawn_shash(spawn);\n\tif (IS_ERR(hash))\n\t\treturn PTR_ERR(hash);\n\n\tparent->descsize = sizeof(struct shash_desc) +\n\t\t\t   crypto_shash_descsize(hash);\n\n\tctx->hash = hash;\n\treturn 0;\n}\n\nstatic void hmac_exit_tfm(struct crypto_tfm *tfm)\n{\n\tstruct hmac_ctx *ctx = hmac_ctx(__crypto_shash_cast(tfm));\n\tcrypto_free_shash(ctx->hash);\n}\n\nstatic int hmac_create(struct crypto_template *tmpl, struct rtattr **tb)\n{\n\tstruct shash_instance *inst;\n\tstruct crypto_alg *alg;\n\tstruct shash_alg *salg;\n\tint err;\n\tint ds;\n\tint ss;\n\n\terr = crypto_check_attr_type(tb, CRYPTO_ALG_TYPE_SHASH);\n\tif (err)\n\t\treturn err;\n\n\tsalg = shash_attr_alg(tb[1], 0, 0);\n\tif (IS_ERR(salg))\n\t\treturn PTR_ERR(salg);\n\n\terr = -EINVAL;\n\tds = salg->digestsize;\n\tss = salg->statesize;\n\talg = &salg->base;\n\tif (ds > alg->cra_blocksize ||\n\t    ss < alg->cra_blocksize)\n\t\tgoto out_put_alg;\n\n\tinst = shash_alloc_instance(\"hmac\", alg);\n\terr = PTR_ERR(inst);\n\tif (IS_ERR(inst))\n\t\tgoto out_put_alg;\n\n\terr = crypto_init_shash_spawn(shash_instance_ctx(inst), salg,\n\t\t\t\t      shash_crypto_instance(inst));\n\tif (err)\n\t\tgoto out_free_inst;\n\n\tinst->alg.base.cra_priority = alg->cra_priority;\n\tinst->alg.base.cra_blocksize = alg->cra_blocksize;\n\tinst->alg.base.cra_alignmask = alg->cra_alignmask;\n\n\tss = ALIGN(ss, alg->cra_alignmask + 1);\n\tinst->alg.digestsize = ds;\n\tinst->alg.statesize = ss;\n\n\tinst->alg.base.cra_ctxsize = sizeof(struct hmac_ctx) +\n\t\t\t\t     ALIGN(ss * 2, crypto_tfm_ctx_alignment());\n\n\tinst->alg.base.cra_init = hmac_init_tfm;\n\tinst->alg.base.cra_exit = hmac_exit_tfm;\n\n\tinst->alg.init = hmac_init;\n\tinst->alg.update = hmac_update;\n\tinst->alg.final = hmac_final;\n\tinst->alg.finup = hmac_finup;\n\tinst->alg.export = hmac_export;\n\tinst->alg.import = hmac_import;\n\tinst->alg.setkey = hmac_setkey;\n\n\terr = shash_register_instance(tmpl, inst);\n\tif (err) {\nout_free_inst:\n\t\tshash_free_instance(shash_crypto_instance(inst));\n\t}\n\nout_put_alg:\n\tcrypto_mod_put(alg);\n\treturn err;\n}\n\nstatic struct crypto_template hmac_tmpl = {\n\t.name = \"hmac\",\n\t.create = hmac_create,\n\t.free = shash_free_instance,\n\t.module = THIS_MODULE,\n};\n\nstatic int __init hmac_module_init(void)\n{\n\treturn crypto_register_template(&hmac_tmpl);\n}\n\nstatic void __exit hmac_module_exit(void)\n{\n\tcrypto_unregister_template(&hmac_tmpl);\n}\n\nmodule_init(hmac_module_init);\nmodule_exit(hmac_module_exit);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"HMAC hash algorithm\");",
        "func": "static int hmac_setkey(struct crypto_shash *parent,\n\t\t       const u8 *inkey, unsigned int keylen)\n{\n\tint bs = crypto_shash_blocksize(parent);\n\tint ds = crypto_shash_digestsize(parent);\n\tint ss = crypto_shash_statesize(parent);\n\tchar *ipad = crypto_shash_ctx_aligned(parent);\n\tchar *opad = ipad + ss;\n\tstruct hmac_ctx *ctx = align_ptr(opad + ss,\n\t\t\t\t\t crypto_tfm_ctx_alignment());\n\tstruct crypto_shash *hash = ctx->hash;\n\tSHASH_DESC_ON_STACK(shash, hash);\n\tunsigned int i;\n\n\tshash->tfm = hash;\n\tshash->flags = crypto_shash_get_flags(parent)\n\t\t& CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\tif (keylen > bs) {\n\t\tint err;\n\n\t\terr = crypto_shash_digest(shash, inkey, keylen, ipad);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tkeylen = ds;\n\t} else\n\t\tmemcpy(ipad, inkey, keylen);\n\n\tmemset(ipad + keylen, 0, bs - keylen);\n\tmemcpy(opad, ipad, bs);\n\n\tfor (i = 0; i < bs; i++) {\n\t\tipad[i] ^= 0x36;\n\t\topad[i] ^= 0x5c;\n\t}\n\n\treturn crypto_shash_init(shash) ?:\n\t       crypto_shash_update(shash, ipad, bs) ?:\n\t       crypto_shash_export(shash, ipad) ?:\n\t       crypto_shash_init(shash) ?:\n\t       crypto_shash_update(shash, opad, bs) ?:\n\t       crypto_shash_export(shash, opad);\n}\n\nstatic int hmac_export(struct shash_desc *pdesc, void *out)\n{\n\tstruct shash_desc *desc = shash_desc_ctx(pdesc);\n\n\tdesc->flags = pdesc->flags & CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\treturn crypto_shash_export(desc, out);\n}\n\nstatic int hmac_import(struct shash_desc *pdesc, const void *in)\n{\n\tstruct shash_desc *desc = shash_desc_ctx(pdesc);\n\tstruct hmac_ctx *ctx = hmac_ctx(pdesc->tfm);\n\n\tdesc->tfm = ctx->hash;\n\tdesc->flags = pdesc->flags & CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\treturn crypto_shash_import(desc, in);\n}\n\nstatic int hmac_init(struct shash_desc *pdesc)\n{\n\treturn hmac_import(pdesc, crypto_shash_ctx_aligned(pdesc->tfm));\n}\n\nstatic int hmac_update(struct shash_desc *pdesc,\n\t\t       const u8 *data, unsigned int nbytes)\n{\n\tstruct shash_desc *desc = shash_desc_ctx(pdesc);\n\n\tdesc->flags = pdesc->flags & CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\treturn crypto_shash_update(desc, data, nbytes);\n}\n\nstatic int hmac_final(struct shash_desc *pdesc, u8 *out)\n{\n\tstruct crypto_shash *parent = pdesc->tfm;\n\tint ds = crypto_shash_digestsize(parent);\n\tint ss = crypto_shash_statesize(parent);\n\tchar *opad = crypto_shash_ctx_aligned(parent) + ss;\n\tstruct shash_desc *desc = shash_desc_ctx(pdesc);\n\n\tdesc->flags = pdesc->flags & CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\treturn crypto_shash_final(desc, out) ?:\n\t       crypto_shash_import(desc, opad) ?:\n\t       crypto_shash_finup(desc, out, ds, out);\n}\n\nstatic int hmac_finup(struct shash_desc *pdesc, const u8 *data,\n\t\t      unsigned int nbytes, u8 *out)\n{\n\n\tstruct crypto_shash *parent = pdesc->tfm;\n\tint ds = crypto_shash_digestsize(parent);\n\tint ss = crypto_shash_statesize(parent);\n\tchar *opad = crypto_shash_ctx_aligned(parent) + ss;\n\tstruct shash_desc *desc = shash_desc_ctx(pdesc);\n\n\tdesc->flags = pdesc->flags & CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\treturn crypto_shash_finup(desc, data, nbytes, out) ?:\n\t       crypto_shash_import(desc, opad) ?:\n\t       crypto_shash_finup(desc, out, ds, out);\n}\n\nstatic int hmac_init_tfm(struct crypto_tfm *tfm)\n{\n\tstruct crypto_shash *parent = __crypto_shash_cast(tfm);\n\tstruct crypto_shash *hash;\n\tstruct crypto_instance *inst = (void *)tfm->__crt_alg;\n\tstruct crypto_shash_spawn *spawn = crypto_instance_ctx(inst);\n\tstruct hmac_ctx *ctx = hmac_ctx(parent);\n\n\thash = crypto_spawn_shash(spawn);\n\tif (IS_ERR(hash))\n\t\treturn PTR_ERR(hash);\n\n\tparent->descsize = sizeof(struct shash_desc) +\n\t\t\t   crypto_shash_descsize(hash);\n\n\tctx->hash = hash;\n\treturn 0;\n}\n\nstatic void hmac_exit_tfm(struct crypto_tfm *tfm)\n{\n\tstruct hmac_ctx *ctx = hmac_ctx(__crypto_shash_cast(tfm));\n\tcrypto_free_shash(ctx->hash);\n}\n\nstatic int hmac_create(struct crypto_template *tmpl, struct rtattr **tb)\n{\n\tstruct shash_instance *inst;\n\tstruct crypto_alg *alg;\n\tstruct shash_alg *salg;\n\tint err;\n\tint ds;\n\tint ss;\n\n\terr = crypto_check_attr_type(tb, CRYPTO_ALG_TYPE_SHASH);\n\tif (err)\n\t\treturn err;\n\n\tsalg = shash_attr_alg(tb[1], 0, 0);\n\tif (IS_ERR(salg))\n\t\treturn PTR_ERR(salg);\n\n\terr = -EINVAL;\n\tds = salg->digestsize;\n\tss = salg->statesize;\n\talg = &salg->base;\n\tif (ds > alg->cra_blocksize ||\n\t    ss < alg->cra_blocksize)\n\t\tgoto out_put_alg;\n\n\tinst = shash_alloc_instance(\"hmac\", alg);\n\terr = PTR_ERR(inst);\n\tif (IS_ERR(inst))\n\t\tgoto out_put_alg;\n\n\terr = crypto_init_shash_spawn(shash_instance_ctx(inst), salg,\n\t\t\t\t      shash_crypto_instance(inst));\n\tif (err)\n\t\tgoto out_free_inst;\n\n\tinst->alg.base.cra_priority = alg->cra_priority;\n\tinst->alg.base.cra_blocksize = alg->cra_blocksize;\n\tinst->alg.base.cra_alignmask = alg->cra_alignmask;\n\n\tss = ALIGN(ss, alg->cra_alignmask + 1);\n\tinst->alg.digestsize = ds;\n\tinst->alg.statesize = ss;\n\n\tinst->alg.base.cra_ctxsize = sizeof(struct hmac_ctx) +\n\t\t\t\t     ALIGN(ss * 2, crypto_tfm_ctx_alignment());\n\n\tinst->alg.base.cra_init = hmac_init_tfm;\n\tinst->alg.base.cra_exit = hmac_exit_tfm;\n\n\tinst->alg.init = hmac_init;\n\tinst->alg.update = hmac_update;\n\tinst->alg.final = hmac_final;\n\tinst->alg.finup = hmac_finup;\n\tinst->alg.export = hmac_export;\n\tinst->alg.import = hmac_import;\n\tinst->alg.setkey = hmac_setkey;\n\n\terr = shash_register_instance(tmpl, inst);\n\tif (err) {\nout_free_inst:\n\t\tshash_free_instance(shash_crypto_instance(inst));\n\t}\n\nout_put_alg:\n\tcrypto_mod_put(alg);\n\treturn err;\n}\n\nstatic struct crypto_template hmac_tmpl = {\n\t.name = \"hmac\",\n\t.create = hmac_create,\n\t.free = shash_free_instance,\n\t.module = THIS_MODULE,\n};\n\nstatic int __init hmac_module_init(void)\n{\n\treturn crypto_register_template(&hmac_tmpl);\n}\n\nstatic void __exit hmac_module_exit(void)\n{\n\tcrypto_unregister_template(&hmac_tmpl);\n}\n\nmodule_init(hmac_module_init);\nmodule_exit(hmac_module_exit);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_DESCRIPTION(\"HMAC hash algorithm\");\nMODULE_ALIAS_CRYPTO(\"hmac\");",
        "diff_func": "--- func_before\n+++ func_after\n@@ -225,3 +225,4 @@\n \n MODULE_LICENSE(\"GPL\");\n MODULE_DESCRIPTION(\"HMAC hash algorithm\");\n+MODULE_ALIAS_CRYPTO(\"hmac\");",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "MODULE_ALIAS_CRYPTO(\"hmac\");"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-0239",
        "func_name": "torvalds/linux/em_sysenter",
        "description": "The em_sysenter function in arch/x86/kvm/emulate.c in the Linux kernel before 3.18.5, when the guest OS lacks SYSENTER MSR initialization, allows guest OS users to gain guest OS privileges or cause a denial of service (guest OS crash) by triggering use of a 16-bit code segment for emulation of a SYSENTER instruction.",
        "git_url": "https://github.com/torvalds/linux/commit/f3747379accba8e95d70cec0eae0582c8c182050",
        "commit_title": "KVM: x86: SYSENTER emulation is broken",
        "commit_text": " SYSENTER emulation is broken in several ways: 1. It misses the case of 16-bit code segments completely (CVE-2015-0239). 2. MSR_IA32_SYSENTER_CS is checked in 64-bit mode incorrectly (bits 0 and 1 can    still be set without causing #GP). 3. MSR_IA32_SYSENTER_EIP and MSR_IA32_SYSENTER_ESP are not masked in    legacy-mode. 4. There is some unneeded code.  Fix it.  Cc: stable@vger.linux.org",
        "func_before": "static int em_sysenter(struct x86_emulate_ctxt *ctxt)\n{\n\tconst struct x86_emulate_ops *ops = ctxt->ops;\n\tstruct desc_struct cs, ss;\n\tu64 msr_data;\n\tu16 cs_sel, ss_sel;\n\tu64 efer = 0;\n\n\tops->get_msr(ctxt, MSR_EFER, &efer);\n\t/* inject #GP if in real mode */\n\tif (ctxt->mode == X86EMUL_MODE_REAL)\n\t\treturn emulate_gp(ctxt, 0);\n\n\t/*\n\t * Not recognized on AMD in compat mode (but is recognized in legacy\n\t * mode).\n\t */\n\tif ((ctxt->mode == X86EMUL_MODE_PROT32) && (efer & EFER_LMA)\n\t    && !vendor_intel(ctxt))\n\t\treturn emulate_ud(ctxt);\n\n\t/* sysenter/sysexit have not been tested in 64bit mode. */\n\tif (ctxt->mode == X86EMUL_MODE_PROT64)\n\t\treturn X86EMUL_UNHANDLEABLE;\n\n\tsetup_syscalls_segments(ctxt, &cs, &ss);\n\n\tops->get_msr(ctxt, MSR_IA32_SYSENTER_CS, &msr_data);\n\tswitch (ctxt->mode) {\n\tcase X86EMUL_MODE_PROT32:\n\t\tif ((msr_data & 0xfffc) == 0x0)\n\t\t\treturn emulate_gp(ctxt, 0);\n\t\tbreak;\n\tcase X86EMUL_MODE_PROT64:\n\t\tif (msr_data == 0x0)\n\t\t\treturn emulate_gp(ctxt, 0);\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tctxt->eflags &= ~(EFLG_VM | EFLG_IF);\n\tcs_sel = (u16)msr_data;\n\tcs_sel &= ~SELECTOR_RPL_MASK;\n\tss_sel = cs_sel + 8;\n\tss_sel &= ~SELECTOR_RPL_MASK;\n\tif (ctxt->mode == X86EMUL_MODE_PROT64 || (efer & EFER_LMA)) {\n\t\tcs.d = 0;\n\t\tcs.l = 1;\n\t}\n\n\tops->set_segment(ctxt, cs_sel, &cs, 0, VCPU_SREG_CS);\n\tops->set_segment(ctxt, ss_sel, &ss, 0, VCPU_SREG_SS);\n\n\tops->get_msr(ctxt, MSR_IA32_SYSENTER_EIP, &msr_data);\n\tctxt->_eip = msr_data;\n\n\tops->get_msr(ctxt, MSR_IA32_SYSENTER_ESP, &msr_data);\n\t*reg_write(ctxt, VCPU_REGS_RSP) = msr_data;\n\n\treturn X86EMUL_CONTINUE;\n}",
        "func": "static int em_sysenter(struct x86_emulate_ctxt *ctxt)\n{\n\tconst struct x86_emulate_ops *ops = ctxt->ops;\n\tstruct desc_struct cs, ss;\n\tu64 msr_data;\n\tu16 cs_sel, ss_sel;\n\tu64 efer = 0;\n\n\tops->get_msr(ctxt, MSR_EFER, &efer);\n\t/* inject #GP if in real mode */\n\tif (ctxt->mode == X86EMUL_MODE_REAL)\n\t\treturn emulate_gp(ctxt, 0);\n\n\t/*\n\t * Not recognized on AMD in compat mode (but is recognized in legacy\n\t * mode).\n\t */\n\tif ((ctxt->mode != X86EMUL_MODE_PROT64) && (efer & EFER_LMA)\n\t    && !vendor_intel(ctxt))\n\t\treturn emulate_ud(ctxt);\n\n\t/* sysenter/sysexit have not been tested in 64bit mode. */\n\tif (ctxt->mode == X86EMUL_MODE_PROT64)\n\t\treturn X86EMUL_UNHANDLEABLE;\n\n\tsetup_syscalls_segments(ctxt, &cs, &ss);\n\n\tops->get_msr(ctxt, MSR_IA32_SYSENTER_CS, &msr_data);\n\tif ((msr_data & 0xfffc) == 0x0)\n\t\treturn emulate_gp(ctxt, 0);\n\n\tctxt->eflags &= ~(EFLG_VM | EFLG_IF);\n\tcs_sel = (u16)msr_data & ~SELECTOR_RPL_MASK;\n\tss_sel = cs_sel + 8;\n\tif (efer & EFER_LMA) {\n\t\tcs.d = 0;\n\t\tcs.l = 1;\n\t}\n\n\tops->set_segment(ctxt, cs_sel, &cs, 0, VCPU_SREG_CS);\n\tops->set_segment(ctxt, ss_sel, &ss, 0, VCPU_SREG_SS);\n\n\tops->get_msr(ctxt, MSR_IA32_SYSENTER_EIP, &msr_data);\n\tctxt->_eip = (efer & EFER_LMA) ? msr_data : (u32)msr_data;\n\n\tops->get_msr(ctxt, MSR_IA32_SYSENTER_ESP, &msr_data);\n\t*reg_write(ctxt, VCPU_REGS_RSP) = (efer & EFER_LMA) ? msr_data :\n\t\t\t\t\t\t\t      (u32)msr_data;\n\n\treturn X86EMUL_CONTINUE;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -15,7 +15,7 @@\n \t * Not recognized on AMD in compat mode (but is recognized in legacy\n \t * mode).\n \t */\n-\tif ((ctxt->mode == X86EMUL_MODE_PROT32) && (efer & EFER_LMA)\n+\tif ((ctxt->mode != X86EMUL_MODE_PROT64) && (efer & EFER_LMA)\n \t    && !vendor_intel(ctxt))\n \t\treturn emulate_ud(ctxt);\n \n@@ -26,25 +26,13 @@\n \tsetup_syscalls_segments(ctxt, &cs, &ss);\n \n \tops->get_msr(ctxt, MSR_IA32_SYSENTER_CS, &msr_data);\n-\tswitch (ctxt->mode) {\n-\tcase X86EMUL_MODE_PROT32:\n-\t\tif ((msr_data & 0xfffc) == 0x0)\n-\t\t\treturn emulate_gp(ctxt, 0);\n-\t\tbreak;\n-\tcase X86EMUL_MODE_PROT64:\n-\t\tif (msr_data == 0x0)\n-\t\t\treturn emulate_gp(ctxt, 0);\n-\t\tbreak;\n-\tdefault:\n-\t\tbreak;\n-\t}\n+\tif ((msr_data & 0xfffc) == 0x0)\n+\t\treturn emulate_gp(ctxt, 0);\n \n \tctxt->eflags &= ~(EFLG_VM | EFLG_IF);\n-\tcs_sel = (u16)msr_data;\n-\tcs_sel &= ~SELECTOR_RPL_MASK;\n+\tcs_sel = (u16)msr_data & ~SELECTOR_RPL_MASK;\n \tss_sel = cs_sel + 8;\n-\tss_sel &= ~SELECTOR_RPL_MASK;\n-\tif (ctxt->mode == X86EMUL_MODE_PROT64 || (efer & EFER_LMA)) {\n+\tif (efer & EFER_LMA) {\n \t\tcs.d = 0;\n \t\tcs.l = 1;\n \t}\n@@ -53,10 +41,11 @@\n \tops->set_segment(ctxt, ss_sel, &ss, 0, VCPU_SREG_SS);\n \n \tops->get_msr(ctxt, MSR_IA32_SYSENTER_EIP, &msr_data);\n-\tctxt->_eip = msr_data;\n+\tctxt->_eip = (efer & EFER_LMA) ? msr_data : (u32)msr_data;\n \n \tops->get_msr(ctxt, MSR_IA32_SYSENTER_ESP, &msr_data);\n-\t*reg_write(ctxt, VCPU_REGS_RSP) = msr_data;\n+\t*reg_write(ctxt, VCPU_REGS_RSP) = (efer & EFER_LMA) ? msr_data :\n+\t\t\t\t\t\t\t      (u32)msr_data;\n \n \treturn X86EMUL_CONTINUE;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tif ((ctxt->mode == X86EMUL_MODE_PROT32) && (efer & EFER_LMA)",
                "\tswitch (ctxt->mode) {",
                "\tcase X86EMUL_MODE_PROT32:",
                "\t\tif ((msr_data & 0xfffc) == 0x0)",
                "\t\t\treturn emulate_gp(ctxt, 0);",
                "\t\tbreak;",
                "\tcase X86EMUL_MODE_PROT64:",
                "\t\tif (msr_data == 0x0)",
                "\t\t\treturn emulate_gp(ctxt, 0);",
                "\t\tbreak;",
                "\tdefault:",
                "\t\tbreak;",
                "\t}",
                "\tcs_sel = (u16)msr_data;",
                "\tcs_sel &= ~SELECTOR_RPL_MASK;",
                "\tss_sel &= ~SELECTOR_RPL_MASK;",
                "\tif (ctxt->mode == X86EMUL_MODE_PROT64 || (efer & EFER_LMA)) {",
                "\tctxt->_eip = msr_data;",
                "\t*reg_write(ctxt, VCPU_REGS_RSP) = msr_data;"
            ],
            "added_lines": [
                "\tif ((ctxt->mode != X86EMUL_MODE_PROT64) && (efer & EFER_LMA)",
                "\tif ((msr_data & 0xfffc) == 0x0)",
                "\t\treturn emulate_gp(ctxt, 0);",
                "\tcs_sel = (u16)msr_data & ~SELECTOR_RPL_MASK;",
                "\tif (efer & EFER_LMA) {",
                "\tctxt->_eip = (efer & EFER_LMA) ? msr_data : (u32)msr_data;",
                "\t*reg_write(ctxt, VCPU_REGS_RSP) = (efer & EFER_LMA) ? msr_data :",
                "\t\t\t\t\t\t\t      (u32)msr_data;"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-1000028",
        "func_name": "torvalds/linux/nfsd_setuser",
        "description": "Linux kernel version after commit bdcf0a423ea1 - 4.15-rc4+, 4.14.8+, 4.9.76+, 4.4.111+ contains a Incorrect Access Control vulnerability in NFS server (nfsd) that can result in remote users reading or writing files they should not be able to via NFS. This attack appear to be exploitable via NFS server must export a filesystem with the \"rootsquash\" options enabled. This vulnerability appears to have been fixed in after commit 1995266727fa.",
        "git_url": "https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?h=1995266727fa8143897e89b55f5d3c79aa828420",
        "commit_title": "Commit bdcf0a423ea1 (\"kernel: make groups_sort calling a responsibility",
        "commit_text": "group_info allocators\") appears to break nfsd rootsquash in a pretty major way.  It adds a call to groups_sort() inside the loop that copies/squashes gids, which means the valid gids are sorted along with the following garbage.  The net result is that the highest numbered valid gids are replaced with any lower-valued garbage gids, possibly including 0.  We should sort only once, after filling in all the gids.  ",
        "func_before": "int nfsd_setuser(struct svc_rqst *rqstp, struct svc_export *exp)\n{\n\tstruct group_info *rqgi;\n\tstruct group_info *gi;\n\tstruct cred *new;\n\tint i;\n\tint flags = nfsexp_flags(rqstp, exp);\n\n\tvalidate_process_creds();\n\n\t/* discard any old override before preparing the new set */\n\trevert_creds(get_cred(current_real_cred()));\n\tnew = prepare_creds();\n\tif (!new)\n\t\treturn -ENOMEM;\n\n\tnew->fsuid = rqstp->rq_cred.cr_uid;\n\tnew->fsgid = rqstp->rq_cred.cr_gid;\n\n\trqgi = rqstp->rq_cred.cr_group_info;\n\n\tif (flags & NFSEXP_ALLSQUASH) {\n\t\tnew->fsuid = exp->ex_anon_uid;\n\t\tnew->fsgid = exp->ex_anon_gid;\n\t\tgi = groups_alloc(0);\n\t\tif (!gi)\n\t\t\tgoto oom;\n\t} else if (flags & NFSEXP_ROOTSQUASH) {\n\t\tif (uid_eq(new->fsuid, GLOBAL_ROOT_UID))\n\t\t\tnew->fsuid = exp->ex_anon_uid;\n\t\tif (gid_eq(new->fsgid, GLOBAL_ROOT_GID))\n\t\t\tnew->fsgid = exp->ex_anon_gid;\n\n\t\tgi = groups_alloc(rqgi->ngroups);\n\t\tif (!gi)\n\t\t\tgoto oom;\n\n\t\tfor (i = 0; i < rqgi->ngroups; i++) {\n\t\t\tif (gid_eq(GLOBAL_ROOT_GID, rqgi->gid[i]))\n\t\t\t\tgi->gid[i] = exp->ex_anon_gid;\n\t\t\telse\n\t\t\t\tgi->gid[i] = rqgi->gid[i];\n\n\t\t\t/* Each thread allocates its own gi, no race */\n\t\t\tgroups_sort(gi);\n\t\t}\n\t} else {\n\t\tgi = get_group_info(rqgi);\n\t}\n\n\tif (uid_eq(new->fsuid, INVALID_UID))\n\t\tnew->fsuid = exp->ex_anon_uid;\n\tif (gid_eq(new->fsgid, INVALID_GID))\n\t\tnew->fsgid = exp->ex_anon_gid;\n\n\tset_groups(new, gi);\n\tput_group_info(gi);\n\n\tif (!uid_eq(new->fsuid, GLOBAL_ROOT_UID))\n\t\tnew->cap_effective = cap_drop_nfsd_set(new->cap_effective);\n\telse\n\t\tnew->cap_effective = cap_raise_nfsd_set(new->cap_effective,\n\t\t\t\t\t\t\tnew->cap_permitted);\n\tvalidate_process_creds();\n\tput_cred(override_creds(new));\n\tput_cred(new);\n\tvalidate_process_creds();\n\treturn 0;\n\noom:\n\tabort_creds(new);\n\treturn -ENOMEM;\n}",
        "func": "int nfsd_setuser(struct svc_rqst *rqstp, struct svc_export *exp)\n{\n\tstruct group_info *rqgi;\n\tstruct group_info *gi;\n\tstruct cred *new;\n\tint i;\n\tint flags = nfsexp_flags(rqstp, exp);\n\n\tvalidate_process_creds();\n\n\t/* discard any old override before preparing the new set */\n\trevert_creds(get_cred(current_real_cred()));\n\tnew = prepare_creds();\n\tif (!new)\n\t\treturn -ENOMEM;\n\n\tnew->fsuid = rqstp->rq_cred.cr_uid;\n\tnew->fsgid = rqstp->rq_cred.cr_gid;\n\n\trqgi = rqstp->rq_cred.cr_group_info;\n\n\tif (flags & NFSEXP_ALLSQUASH) {\n\t\tnew->fsuid = exp->ex_anon_uid;\n\t\tnew->fsgid = exp->ex_anon_gid;\n\t\tgi = groups_alloc(0);\n\t\tif (!gi)\n\t\t\tgoto oom;\n\t} else if (flags & NFSEXP_ROOTSQUASH) {\n\t\tif (uid_eq(new->fsuid, GLOBAL_ROOT_UID))\n\t\t\tnew->fsuid = exp->ex_anon_uid;\n\t\tif (gid_eq(new->fsgid, GLOBAL_ROOT_GID))\n\t\t\tnew->fsgid = exp->ex_anon_gid;\n\n\t\tgi = groups_alloc(rqgi->ngroups);\n\t\tif (!gi)\n\t\t\tgoto oom;\n\n\t\tfor (i = 0; i < rqgi->ngroups; i++) {\n\t\t\tif (gid_eq(GLOBAL_ROOT_GID, rqgi->gid[i]))\n\t\t\t\tgi->gid[i] = exp->ex_anon_gid;\n\t\t\telse\n\t\t\t\tgi->gid[i] = rqgi->gid[i];\n\t\t}\n\n\t\t/* Each thread allocates its own gi, no race */\n\t\tgroups_sort(gi);\n\t} else {\n\t\tgi = get_group_info(rqgi);\n\t}\n\n\tif (uid_eq(new->fsuid, INVALID_UID))\n\t\tnew->fsuid = exp->ex_anon_uid;\n\tif (gid_eq(new->fsgid, INVALID_GID))\n\t\tnew->fsgid = exp->ex_anon_gid;\n\n\tset_groups(new, gi);\n\tput_group_info(gi);\n\n\tif (!uid_eq(new->fsuid, GLOBAL_ROOT_UID))\n\t\tnew->cap_effective = cap_drop_nfsd_set(new->cap_effective);\n\telse\n\t\tnew->cap_effective = cap_raise_nfsd_set(new->cap_effective,\n\t\t\t\t\t\t\tnew->cap_permitted);\n\tvalidate_process_creds();\n\tput_cred(override_creds(new));\n\tput_cred(new);\n\tvalidate_process_creds();\n\treturn 0;\n\noom:\n\tabort_creds(new);\n\treturn -ENOMEM;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -40,10 +40,10 @@\n \t\t\t\tgi->gid[i] = exp->ex_anon_gid;\n \t\t\telse\n \t\t\t\tgi->gid[i] = rqgi->gid[i];\n+\t\t}\n \n-\t\t\t/* Each thread allocates its own gi, no race */\n-\t\t\tgroups_sort(gi);\n-\t\t}\n+\t\t/* Each thread allocates its own gi, no race */\n+\t\tgroups_sort(gi);\n \t} else {\n \t\tgi = get_group_info(rqgi);\n \t}",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\t/* Each thread allocates its own gi, no race */",
                "\t\t\tgroups_sort(gi);",
                "\t\t}"
            ],
            "added_lines": [
                "\t\t}",
                "\t\t/* Each thread allocates its own gi, no race */",
                "\t\tgroups_sort(gi);"
            ]
        }
    },
    {
        "cve_id": "CVE-2023-25149",
        "func_name": "timescale/timescaledb/tsl_subscription_exec",
        "description": "TimescaleDB, an open-source time-series SQL database, has a privilege escalation vulnerability in versions 2.8.0 through 2.9.2. During installation, TimescaleDB creates a telemetry job that is runs as the installation user. The queries run as part of the telemetry data collection were not run with a locked down `search_path`, allowing malicious users to create functions that would be executed by the telemetry job, leading to privilege escalation. In order to be able to take advantage of this vulnerability, a user would need to be able to create objects in a database and then get a superuser to install TimescaleDB into their database. When TimescaleDB is installed as trusted extension, non-superusers can install the extension without help from a superuser.\n\nVersion 2.9.3 fixes this issue. As a mitigation, the `search_path` of the user running the telemetry job can be locked down to not include schemas writable by other users. The vulnerability is not exploitable on instances in Timescale Cloud and Managed Service for TimescaleDB due to additional security provisions in place on those platforms.",
        "git_url": "https://github.com/timescale/timescaledb/commit/014b40fb7e8d59087cf1c1988a68dd1979f86cb3",
        "commit_title": "Lock down search_path in SPI calls",
        "commit_text": "",
        "func_before": "Datum\ntsl_subscription_exec(PG_FUNCTION_ARGS)\n{\n\tOid save_userid;\n\tint save_sec_context;\n\tconst char *subscription_cmd = PG_ARGISNULL(0) ? NULL : text_to_cstring(PG_GETARG_TEXT_P(0));\n\tint res;\n\tList *parsetree_list;\n\tListCell *parsetree_item;\n\n\tif (!subscription_cmd)\n\t\tPG_RETURN_VOID();\n\n\t/*\n\t * Subscription command needs a superuser\n\t * so switch to that context. But first check that the passed in user has atleast\n\t * REPLICATION privileges to justify the use of this function\n\t */\n\tif (!superuser() && !has_rolreplication(GetUserId()))\n\t\tereport(ERROR,\n\t\t\t\t(errcode(ERRCODE_INSUFFICIENT_PRIVILEGE),\n\t\t\t\t (errmsg(\"must be superuser or replication role to use this function\"))));\n\n\tGetUserIdAndSecContext(&save_userid, &save_sec_context);\n\tSetUserIdAndSecContext(BOOTSTRAP_SUPERUSERID, save_sec_context | SECURITY_LOCAL_USERID_CHANGE);\n\n\t/*\n\t * Parse the SQL string into a list of raw parse trees.\n\t */\n\tparsetree_list = pg_parse_query(subscription_cmd);\n\n\t/*\n\t * Check that we have received a \"SUBSCRIPTION\" related command only. Anything else\n\t * needs to error out\n\t */\n\tforeach (parsetree_item, parsetree_list)\n\t{\n\t\tRawStmt *parsetree = lfirst_node(RawStmt, parsetree_item);\n\n\t\t/* We are only interested in \"CREATE/DROP SUBSCRIPTION\" and \"ALTER SUBSCRIPTION\" stmts */\n\t\tswitch (nodeTag(parsetree->stmt))\n\t\t{\n\t\t\tcase T_CreateSubscriptionStmt:\n\t\t\t\tbreak;\n\n\t\t\tcase T_AlterSubscriptionStmt:\n\t\t\t\tbreak;\n\n\t\t\tcase T_DropSubscriptionStmt:\n\t\t\t\tbreak;\n\n\t\t\tdefault:\n\t\t\t\tereport(ERROR,\n\t\t\t\t\t\t(errcode(ERRCODE_FEATURE_NOT_SUPPORTED),\n\t\t\t\t\t\t errmsg(\"this function only accepts SUBSCRIPTION commands\")));\n\t\t}\n\t}\n\n\tif (SPI_connect() != SPI_OK_CONNECT)\n\t\telog(ERROR, \"could not connect to SPI\");\n\n\tres = SPI_execute(subscription_cmd, false /* read_only */, 0 /*count*/);\n\n\tif (res < 0)\n\t\tereport(ERROR,\n\t\t\t\t(errcode(ERRCODE_INTERNAL_ERROR),\n\t\t\t\t (errmsg(\"error in subscription cmd \\\"%s\\\"\", subscription_cmd))));\n\n\tif ((res = SPI_finish()) != SPI_OK_FINISH)\n\t\telog(ERROR, \"SPI_finish failed: %s\", SPI_result_code_string(res));\n\n\t/* Restore the earlier user */\n\tSetUserIdAndSecContext(save_userid, save_sec_context);\n\n\tPG_RETURN_VOID();\n}",
        "func": "Datum\ntsl_subscription_exec(PG_FUNCTION_ARGS)\n{\n\tOid save_userid;\n\tint save_sec_context;\n\tconst char *subscription_cmd = PG_ARGISNULL(0) ? NULL : text_to_cstring(PG_GETARG_TEXT_P(0));\n\tint res;\n\tList *parsetree_list;\n\tListCell *parsetree_item;\n\n\tif (!subscription_cmd)\n\t\tPG_RETURN_VOID();\n\n\t/*\n\t * Subscription command needs a superuser\n\t * so switch to that context. But first check that the passed in user has atleast\n\t * REPLICATION privileges to justify the use of this function\n\t */\n\tif (!superuser() && !has_rolreplication(GetUserId()))\n\t\tereport(ERROR,\n\t\t\t\t(errcode(ERRCODE_INSUFFICIENT_PRIVILEGE),\n\t\t\t\t (errmsg(\"must be superuser or replication role to use this function\"))));\n\n\tGetUserIdAndSecContext(&save_userid, &save_sec_context);\n\tSetUserIdAndSecContext(BOOTSTRAP_SUPERUSERID, save_sec_context | SECURITY_LOCAL_USERID_CHANGE);\n\n\t/*\n\t * Parse the SQL string into a list of raw parse trees.\n\t */\n\tparsetree_list = pg_parse_query(subscription_cmd);\n\n\t/*\n\t * Check that we have received a \"SUBSCRIPTION\" related command only. Anything else\n\t * needs to error out\n\t */\n\tforeach (parsetree_item, parsetree_list)\n\t{\n\t\tRawStmt *parsetree = lfirst_node(RawStmt, parsetree_item);\n\n\t\t/* We are only interested in \"CREATE/DROP SUBSCRIPTION\" and \"ALTER SUBSCRIPTION\" stmts */\n\t\tswitch (nodeTag(parsetree->stmt))\n\t\t{\n\t\t\tcase T_CreateSubscriptionStmt:\n\t\t\t\tbreak;\n\n\t\t\tcase T_AlterSubscriptionStmt:\n\t\t\t\tbreak;\n\n\t\t\tcase T_DropSubscriptionStmt:\n\t\t\t\tbreak;\n\n\t\t\tdefault:\n\t\t\t\tereport(ERROR,\n\t\t\t\t\t\t(errcode(ERRCODE_FEATURE_NOT_SUPPORTED),\n\t\t\t\t\t\t errmsg(\"this function only accepts SUBSCRIPTION commands\")));\n\t\t}\n\t}\n\n\tif (SPI_connect() != SPI_OK_CONNECT)\n\t\telog(ERROR, \"could not connect to SPI\");\n\n\t/* Lock down search_path */\n\tres = SPI_exec(\"SET LOCAL search_path TO pg_catalog, pg_temp\", 0);\n\tif (res < 0)\n\t\tereport(ERROR, (errcode(ERRCODE_INTERNAL_ERROR), (errmsg(\"could not set search_path\"))));\n\n\tres = SPI_execute(subscription_cmd, false /* read_only */, 0 /*count*/);\n\n\tif (res < 0)\n\t\tereport(ERROR,\n\t\t\t\t(errcode(ERRCODE_INTERNAL_ERROR),\n\t\t\t\t (errmsg(\"error in subscription cmd \\\"%s\\\"\", subscription_cmd))));\n\n\tif ((res = SPI_finish()) != SPI_OK_FINISH)\n\t\telog(ERROR, \"SPI_finish failed: %s\", SPI_result_code_string(res));\n\n\t/* Restore the earlier user */\n\tSetUserIdAndSecContext(save_userid, save_sec_context);\n\n\tPG_RETURN_VOID();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -59,6 +59,11 @@\n \tif (SPI_connect() != SPI_OK_CONNECT)\n \t\telog(ERROR, \"could not connect to SPI\");\n \n+\t/* Lock down search_path */\n+\tres = SPI_exec(\"SET LOCAL search_path TO pg_catalog, pg_temp\", 0);\n+\tif (res < 0)\n+\t\tereport(ERROR, (errcode(ERRCODE_INTERNAL_ERROR), (errmsg(\"could not set search_path\"))));\n+\n \tres = SPI_execute(subscription_cmd, false /* read_only */, 0 /*count*/);\n \n \tif (res < 0)",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t/* Lock down search_path */",
                "\tres = SPI_exec(\"SET LOCAL search_path TO pg_catalog, pg_temp\", 0);",
                "\tif (res < 0)",
                "\t\tereport(ERROR, (errcode(ERRCODE_INTERNAL_ERROR), (errmsg(\"could not set search_path\"))));",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2023-25149",
        "func_name": "timescale/timescaledb/tsl_copy_chunk_cleanup_proc",
        "description": "TimescaleDB, an open-source time-series SQL database, has a privilege escalation vulnerability in versions 2.8.0 through 2.9.2. During installation, TimescaleDB creates a telemetry job that is runs as the installation user. The queries run as part of the telemetry data collection were not run with a locked down `search_path`, allowing malicious users to create functions that would be executed by the telemetry job, leading to privilege escalation. In order to be able to take advantage of this vulnerability, a user would need to be able to create objects in a database and then get a superuser to install TimescaleDB into their database. When TimescaleDB is installed as trusted extension, non-superusers can install the extension without help from a superuser.\n\nVersion 2.9.3 fixes this issue. As a mitigation, the `search_path` of the user running the telemetry job can be locked down to not include schemas writable by other users. The vulnerability is not exploitable on instances in Timescale Cloud and Managed Service for TimescaleDB due to additional security provisions in place on those platforms.",
        "git_url": "https://github.com/timescale/timescaledb/commit/014b40fb7e8d59087cf1c1988a68dd1979f86cb3",
        "commit_title": "Lock down search_path in SPI calls",
        "commit_text": "",
        "func_before": "Datum\ntsl_copy_chunk_cleanup_proc(PG_FUNCTION_ARGS)\n{\n\tconst char *operation_id = PG_ARGISNULL(0) ? NULL : NameStr(*PG_GETARG_NAME(0));\n\tint rc;\n\tbool nonatomic = fcinfo->context && IsA(fcinfo->context, CallContext) &&\n\t\t\t\t\t !castNode(CallContext, fcinfo->context)->atomic;\n\n\tTS_PREVENT_FUNC_IF_READ_ONLY();\n\n\tPreventInTransactionBlock(true, get_func_name(FC_FN_OID(fcinfo)));\n\n\t/* valid input has to be provided */\n\tif (operation_id == NULL)\n\t\tereport(ERROR,\n\t\t\t\t(errcode(ERRCODE_INVALID_PARAMETER_VALUE),\n\t\t\t\t errmsg(\"invalid chunk copy operation id\")));\n\n\tif ((rc = SPI_connect_ext(nonatomic ? SPI_OPT_NONATOMIC : 0)) != SPI_OK_CONNECT)\n\t\telog(ERROR, \"SPI_connect failed: %s\", SPI_result_code_string(rc));\n\n\t/* perform the cleanup/repair depending on the stage */\n\tchunk_copy_cleanup(operation_id);\n\n\tif ((rc = SPI_finish()) != SPI_OK_FINISH)\n\t\telog(ERROR, \"SPI_finish failed: %s\", SPI_result_code_string(rc));\n\n\tPG_RETURN_VOID();\n}",
        "func": "Datum\ntsl_copy_chunk_cleanup_proc(PG_FUNCTION_ARGS)\n{\n\tconst char *operation_id = PG_ARGISNULL(0) ? NULL : NameStr(*PG_GETARG_NAME(0));\n\tint rc;\n\tbool nonatomic = fcinfo->context && IsA(fcinfo->context, CallContext) &&\n\t\t\t\t\t !castNode(CallContext, fcinfo->context)->atomic;\n\n\tTS_PREVENT_FUNC_IF_READ_ONLY();\n\n\tPreventInTransactionBlock(true, get_func_name(FC_FN_OID(fcinfo)));\n\n\t/* valid input has to be provided */\n\tif (operation_id == NULL)\n\t\tereport(ERROR,\n\t\t\t\t(errcode(ERRCODE_INVALID_PARAMETER_VALUE),\n\t\t\t\t errmsg(\"invalid chunk copy operation id\")));\n\n\tif ((rc = SPI_connect_ext(nonatomic ? SPI_OPT_NONATOMIC : 0)) != SPI_OK_CONNECT)\n\t\telog(ERROR, \"SPI_connect failed: %s\", SPI_result_code_string(rc));\n\n\t/* Lock down search_path */\n\trc = SPI_exec(\"SET LOCAL search_path TO pg_catalog, pg_temp\", 0);\n\tif (rc < 0)\n\t\tereport(ERROR, (errcode(ERRCODE_INTERNAL_ERROR), (errmsg(\"could not set search_path\"))));\n\n\t/* perform the cleanup/repair depending on the stage */\n\tchunk_copy_cleanup(operation_id);\n\n\tif ((rc = SPI_finish()) != SPI_OK_FINISH)\n\t\telog(ERROR, \"SPI_finish failed: %s\", SPI_result_code_string(rc));\n\n\tPG_RETURN_VOID();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -19,6 +19,11 @@\n \tif ((rc = SPI_connect_ext(nonatomic ? SPI_OPT_NONATOMIC : 0)) != SPI_OK_CONNECT)\n \t\telog(ERROR, \"SPI_connect failed: %s\", SPI_result_code_string(rc));\n \n+\t/* Lock down search_path */\n+\trc = SPI_exec(\"SET LOCAL search_path TO pg_catalog, pg_temp\", 0);\n+\tif (rc < 0)\n+\t\tereport(ERROR, (errcode(ERRCODE_INTERNAL_ERROR), (errmsg(\"could not set search_path\"))));\n+\n \t/* perform the cleanup/repair depending on the stage */\n \tchunk_copy_cleanup(operation_id);\n ",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t/* Lock down search_path */",
                "\trc = SPI_exec(\"SET LOCAL search_path TO pg_catalog, pg_temp\", 0);",
                "\tif (rc < 0)",
                "\t\tereport(ERROR, (errcode(ERRCODE_INTERNAL_ERROR), (errmsg(\"could not set search_path\"))));",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2023-25149",
        "func_name": "timescale/timescaledb/tsl_copy_or_move_chunk_proc",
        "description": "TimescaleDB, an open-source time-series SQL database, has a privilege escalation vulnerability in versions 2.8.0 through 2.9.2. During installation, TimescaleDB creates a telemetry job that is runs as the installation user. The queries run as part of the telemetry data collection were not run with a locked down `search_path`, allowing malicious users to create functions that would be executed by the telemetry job, leading to privilege escalation. In order to be able to take advantage of this vulnerability, a user would need to be able to create objects in a database and then get a superuser to install TimescaleDB into their database. When TimescaleDB is installed as trusted extension, non-superusers can install the extension without help from a superuser.\n\nVersion 2.9.3 fixes this issue. As a mitigation, the `search_path` of the user running the telemetry job can be locked down to not include schemas writable by other users. The vulnerability is not exploitable on instances in Timescale Cloud and Managed Service for TimescaleDB due to additional security provisions in place on those platforms.",
        "git_url": "https://github.com/timescale/timescaledb/commit/014b40fb7e8d59087cf1c1988a68dd1979f86cb3",
        "commit_title": "Lock down search_path in SPI calls",
        "commit_text": "",
        "func_before": "static void\ntsl_copy_or_move_chunk_proc(FunctionCallInfo fcinfo, bool delete_on_src_node)\n{\n\tOid chunk_id = PG_ARGISNULL(0) ? InvalidOid : PG_GETARG_OID(0);\n\tconst char *src_node_name = PG_ARGISNULL(1) ? NULL : NameStr(*PG_GETARG_NAME(1));\n\tconst char *dst_node_name = PG_ARGISNULL(2) ? NULL : NameStr(*PG_GETARG_NAME(2));\n\tconst char *op_id = PG_ARGISNULL(3) ? NULL : NameStr(*PG_GETARG_NAME(3));\n\tint rc;\n\tbool nonatomic = fcinfo->context && IsA(fcinfo->context, CallContext) &&\n\t\t\t\t\t !castNode(CallContext, fcinfo->context)->atomic;\n\n\tTS_PREVENT_FUNC_IF_READ_ONLY();\n\n\tPreventInTransactionBlock(true, get_func_name(FC_FN_OID(fcinfo)));\n\n\t/* src_node and dst_node both have to be non-NULL */\n\tif (src_node_name == NULL || dst_node_name == NULL)\n\t\tereport(ERROR,\n\t\t\t\t(errcode(ERRCODE_INVALID_PARAMETER_VALUE),\n\t\t\t\t errmsg(\"invalid source or destination node\")));\n\n\tif (!OidIsValid(chunk_id))\n\t\tereport(ERROR, (errcode(ERRCODE_INVALID_PARAMETER_VALUE), errmsg(\"invalid chunk\")));\n\n\tif ((rc = SPI_connect_ext(nonatomic ? SPI_OPT_NONATOMIC : 0)) != SPI_OK_CONNECT)\n\t\telog(ERROR, \"SPI_connect failed: %s\", SPI_result_code_string(rc));\n\n\t/* perform the actual distributed chunk move after a few sanity checks */\n\tchunk_copy(chunk_id, src_node_name, dst_node_name, op_id, delete_on_src_node);\n\n\tif ((rc = SPI_finish()) != SPI_OK_FINISH)\n\t\telog(ERROR, \"SPI_finish failed: %s\", SPI_result_code_string(rc));\n}",
        "func": "static void\ntsl_copy_or_move_chunk_proc(FunctionCallInfo fcinfo, bool delete_on_src_node)\n{\n\tOid chunk_id = PG_ARGISNULL(0) ? InvalidOid : PG_GETARG_OID(0);\n\tconst char *src_node_name = PG_ARGISNULL(1) ? NULL : NameStr(*PG_GETARG_NAME(1));\n\tconst char *dst_node_name = PG_ARGISNULL(2) ? NULL : NameStr(*PG_GETARG_NAME(2));\n\tconst char *op_id = PG_ARGISNULL(3) ? NULL : NameStr(*PG_GETARG_NAME(3));\n\tint rc;\n\tbool nonatomic = fcinfo->context && IsA(fcinfo->context, CallContext) &&\n\t\t\t\t\t !castNode(CallContext, fcinfo->context)->atomic;\n\n\tTS_PREVENT_FUNC_IF_READ_ONLY();\n\n\tPreventInTransactionBlock(true, get_func_name(FC_FN_OID(fcinfo)));\n\n\t/* src_node and dst_node both have to be non-NULL */\n\tif (src_node_name == NULL || dst_node_name == NULL)\n\t\tereport(ERROR,\n\t\t\t\t(errcode(ERRCODE_INVALID_PARAMETER_VALUE),\n\t\t\t\t errmsg(\"invalid source or destination node\")));\n\n\tif (!OidIsValid(chunk_id))\n\t\tereport(ERROR, (errcode(ERRCODE_INVALID_PARAMETER_VALUE), errmsg(\"invalid chunk\")));\n\n\tif ((rc = SPI_connect_ext(nonatomic ? SPI_OPT_NONATOMIC : 0)) != SPI_OK_CONNECT)\n\t\telog(ERROR, \"SPI_connect failed: %s\", SPI_result_code_string(rc));\n\n\t/* Lock down search_path */\n\trc = SPI_exec(\"SET LOCAL search_path TO pg_catalog, pg_temp\", 0);\n\tif (rc < 0)\n\t\tereport(ERROR, (errcode(ERRCODE_INTERNAL_ERROR), (errmsg(\"could not set search_path\"))));\n\n\t/* perform the actual distributed chunk move after a few sanity checks */\n\tchunk_copy(chunk_id, src_node_name, dst_node_name, op_id, delete_on_src_node);\n\n\tif ((rc = SPI_finish()) != SPI_OK_FINISH)\n\t\telog(ERROR, \"SPI_finish failed: %s\", SPI_result_code_string(rc));\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -25,6 +25,11 @@\n \tif ((rc = SPI_connect_ext(nonatomic ? SPI_OPT_NONATOMIC : 0)) != SPI_OK_CONNECT)\n \t\telog(ERROR, \"SPI_connect failed: %s\", SPI_result_code_string(rc));\n \n+\t/* Lock down search_path */\n+\trc = SPI_exec(\"SET LOCAL search_path TO pg_catalog, pg_temp\", 0);\n+\tif (rc < 0)\n+\t\tereport(ERROR, (errcode(ERRCODE_INTERNAL_ERROR), (errmsg(\"could not set search_path\"))));\n+\n \t/* perform the actual distributed chunk move after a few sanity checks */\n \tchunk_copy(chunk_id, src_node_name, dst_node_name, op_id, delete_on_src_node);\n ",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t/* Lock down search_path */",
                "\trc = SPI_exec(\"SET LOCAL search_path TO pg_catalog, pg_temp\", 0);",
                "\tif (rc < 0)",
                "\t\tereport(ERROR, (errcode(ERRCODE_INTERNAL_ERROR), (errmsg(\"could not set search_path\"))));",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2023-25149",
        "func_name": "timescale/timescaledb/continuous_agg_refresh_internal",
        "description": "TimescaleDB, an open-source time-series SQL database, has a privilege escalation vulnerability in versions 2.8.0 through 2.9.2. During installation, TimescaleDB creates a telemetry job that is runs as the installation user. The queries run as part of the telemetry data collection were not run with a locked down `search_path`, allowing malicious users to create functions that would be executed by the telemetry job, leading to privilege escalation. In order to be able to take advantage of this vulnerability, a user would need to be able to create objects in a database and then get a superuser to install TimescaleDB into their database. When TimescaleDB is installed as trusted extension, non-superusers can install the extension without help from a superuser.\n\nVersion 2.9.3 fixes this issue. As a mitigation, the `search_path` of the user running the telemetry job can be locked down to not include schemas writable by other users. The vulnerability is not exploitable on instances in Timescale Cloud and Managed Service for TimescaleDB due to additional security provisions in place on those platforms.",
        "git_url": "https://github.com/timescale/timescaledb/commit/014b40fb7e8d59087cf1c1988a68dd1979f86cb3",
        "commit_title": "Lock down search_path in SPI calls",
        "commit_text": "",
        "func_before": "void\ncontinuous_agg_refresh_internal(const ContinuousAgg *cagg,\n\t\t\t\t\t\t\t\tconst InternalTimeRange *refresh_window_arg,\n\t\t\t\t\t\t\t\tconst CaggRefreshCallContext callctx, const bool start_isnull,\n\t\t\t\t\t\t\t\tconst bool end_isnull)\n{\n\tCatalog *catalog = ts_catalog_get();\n\tint32 mat_id = cagg->data.mat_hypertable_id;\n\tInternalTimeRange refresh_window = *refresh_window_arg;\n\tint64 computed_invalidation_threshold;\n\tint64 invalidation_threshold;\n\tbool is_raw_ht_distributed;\n\tint rc;\n\n\t/* Connect to SPI manager due to the underlying SPI calls */\n\tif ((rc = SPI_connect_ext(SPI_OPT_NONATOMIC) != SPI_OK_CONNECT))\n\t\telog(ERROR, \"SPI_connect failed: %s\", SPI_result_code_string(rc));\n\n\t/* Like regular materialized views, require owner to refresh. */\n\tif (!pg_class_ownercheck(cagg->relid, GetUserId()))\n\t\taclcheck_error(ACLCHECK_NOT_OWNER,\n\t\t\t\t\t   get_relkind_objtype(get_rel_relkind(cagg->relid)),\n\t\t\t\t\t   get_rel_name(cagg->relid));\n\n\tPreventCommandIfReadOnly(REFRESH_FUNCTION_NAME);\n\n\t/* Prevent running refresh if we're in a transaction block since a refresh\n\t * can run two transactions and might take a long time to release locks if\n\t * there's a lot to materialize. Strictly, it is optional to prohibit\n\t * transaction blocks since there will be only one transaction if the\n\t * invalidation threshold needs no update. However, materialization might\n\t * still take a long time and it is probably best for consistency to always\n\t * prevent transaction blocks.  */\n\tPreventInTransactionBlock(true, REFRESH_FUNCTION_NAME);\n\n\tHypertable *ht = cagg_get_hypertable_or_fail(cagg->data.raw_hypertable_id);\n\tis_raw_ht_distributed = hypertable_is_distributed(ht);\n\n\t/* No bucketing when open ended */\n\tif (!(start_isnull && end_isnull))\n\t{\n\t\tif (ts_continuous_agg_bucket_width_variable(cagg))\n\t\t{\n\t\t\trefresh_window = *refresh_window_arg;\n\t\t\tts_compute_inscribed_bucketed_refresh_window_variable(&refresh_window.start,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  &refresh_window.end,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  cagg->bucket_function);\n\t\t}\n\t\telse\n\t\t{\n\t\t\trefresh_window =\n\t\t\t\tcompute_inscribed_bucketed_refresh_window(refresh_window_arg,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t  ts_continuous_agg_bucket_width(cagg));\n\t\t}\n\t}\n\n\tif (refresh_window.start >= refresh_window.end)\n\t\tereport(ERROR,\n\t\t\t\t(errcode(ERRCODE_INVALID_PARAMETER_VALUE),\n\t\t\t\t errmsg(\"refresh window too small\"),\n\t\t\t\t errdetail(\"The refresh window must cover at least one bucket of data.\"),\n\t\t\t\t errhint(\"Align the refresh window with the bucket\"\n\t\t\t\t\t\t \" time zone or use at least two buckets.\")));\n\n\tlog_refresh_window(callctx == CAGG_REFRESH_POLICY ? LOG : DEBUG1,\n\t\t\t\t\t   cagg,\n\t\t\t\t\t   &refresh_window,\n\t\t\t\t\t   \"refreshing continuous aggregate\");\n\n\t/* Perform the refresh across two transactions.\n\t *\n\t * The first transaction moves the invalidation threshold (if needed) and\n\t * copies over invalidations from the hypertable log to the cagg\n\t * invalidation log. Doing the threshold and copying as part of the first\n\t * transaction ensures that the threshold and new invalidations will be\n\t * visible as soon as possible to concurrent refreshes and that we keep\n\t * locks for only a short period. Note that the first transaction\n\t * serializes around the threshold table lock, which protects both the\n\t * threshold and the invalidation processing against concurrent refreshes.\n\t *\n\t * The second transaction processes the cagg invalidation log and then\n\t * performs the actual refresh (materialization of data). This transaction\n\t * serializes around a lock on the materialized hypertable for the\n\t * continuous aggregate that gets refreshed.\n\t */\n\tLockRelationOid(catalog_get_table_id(catalog, CONTINUOUS_AGGS_INVALIDATION_THRESHOLD),\n\t\t\t\t\tAccessExclusiveLock);\n\n\t/* Compute new invalidation threshold. Note that this computation caps the\n\t * threshold at the end of the last bucket that holds data in the\n\t * underlying hypertable. */\n\tcomputed_invalidation_threshold = invalidation_threshold_compute(cagg, &refresh_window);\n\n\t/* Set the new invalidation threshold. Note that this only updates the\n\t * threshold if the new value is greater than the old one. Otherwise, the\n\t * existing threshold is returned. */\n\tinvalidation_threshold = invalidation_threshold_set_or_get(cagg->data.raw_hypertable_id,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   computed_invalidation_threshold);\n\n\t/* We must also cap the refresh window at the invalidation threshold. If\n\t * we process invalidations after the threshold, the continuous aggregates\n\t * won't be refreshed when the threshold is moved forward in the\n\t * future. The invalidation threshold should already be aligned on bucket\n\t * boundary. */\n\tif (refresh_window.end > invalidation_threshold)\n\t\trefresh_window.end = invalidation_threshold;\n\n\t/* Capping the end might have made the window 0, or negative, so\n\t * nothing to refresh in that case */\n\tif (refresh_window.start >= refresh_window.end)\n\t{\n\t\temit_up_to_date_notice(cagg, callctx);\n\n\t\tif ((rc = SPI_finish()) != SPI_OK_FINISH)\n\t\t\telog(ERROR, \"SPI_finish failed: %s\", SPI_result_code_string(rc));\n\n\t\treturn;\n\t}\n\n\t/* Process invalidations in the hypertable invalidation log */\n\tconst CaggsInfo all_caggs_info =\n\t\tts_continuous_agg_get_all_caggs_info(cagg->data.raw_hypertable_id);\n\tif (is_raw_ht_distributed)\n\t{\n\t\tremote_invalidation_process_hypertable_log(cagg->data.mat_hypertable_id,\n\t\t\t\t\t\t\t\t\t\t\t\t   cagg->data.raw_hypertable_id,\n\t\t\t\t\t\t\t\t\t\t\t\t   refresh_window.type,\n\t\t\t\t\t\t\t\t\t\t\t\t   &all_caggs_info);\n\t}\n\telse\n\t{\n\t\tinvalidation_process_hypertable_log(cagg->data.mat_hypertable_id,\n\t\t\t\t\t\t\t\t\t\t\tcagg->data.raw_hypertable_id,\n\t\t\t\t\t\t\t\t\t\t\trefresh_window.type,\n\t\t\t\t\t\t\t\t\t\t\t&all_caggs_info);\n\t}\n\n\t/* Commit and Start a new transaction */\n\tSPI_commit_and_chain();\n\n\tcagg = ts_continuous_agg_find_by_mat_hypertable_id(mat_id);\n\n\tif (!process_cagg_invalidations_and_refresh(cagg, &refresh_window, callctx, INVALID_CHUNK_ID))\n\t\temit_up_to_date_notice(cagg, callctx);\n\n\tif ((rc = SPI_finish()) != SPI_OK_FINISH)\n\t\telog(ERROR, \"SPI_finish failed: %s\", SPI_result_code_string(rc));\n}",
        "func": "void\ncontinuous_agg_refresh_internal(const ContinuousAgg *cagg,\n\t\t\t\t\t\t\t\tconst InternalTimeRange *refresh_window_arg,\n\t\t\t\t\t\t\t\tconst CaggRefreshCallContext callctx, const bool start_isnull,\n\t\t\t\t\t\t\t\tconst bool end_isnull)\n{\n\tCatalog *catalog = ts_catalog_get();\n\tint32 mat_id = cagg->data.mat_hypertable_id;\n\tInternalTimeRange refresh_window = *refresh_window_arg;\n\tint64 computed_invalidation_threshold;\n\tint64 invalidation_threshold;\n\tbool is_raw_ht_distributed;\n\tint rc;\n\n\t/* Connect to SPI manager due to the underlying SPI calls */\n\tif ((rc = SPI_connect_ext(SPI_OPT_NONATOMIC) != SPI_OK_CONNECT))\n\t\telog(ERROR, \"SPI_connect failed: %s\", SPI_result_code_string(rc));\n\n\t/* Lock down search_path */\n\trc = SPI_exec(\"SET LOCAL search_path TO pg_catalog, pg_temp\", 0);\n\tif (rc < 0)\n\t\tereport(ERROR, (errcode(ERRCODE_INTERNAL_ERROR), (errmsg(\"could not set search_path\"))));\n\n\t/* Like regular materialized views, require owner to refresh. */\n\tif (!pg_class_ownercheck(cagg->relid, GetUserId()))\n\t\taclcheck_error(ACLCHECK_NOT_OWNER,\n\t\t\t\t\t   get_relkind_objtype(get_rel_relkind(cagg->relid)),\n\t\t\t\t\t   get_rel_name(cagg->relid));\n\n\tPreventCommandIfReadOnly(REFRESH_FUNCTION_NAME);\n\n\t/* Prevent running refresh if we're in a transaction block since a refresh\n\t * can run two transactions and might take a long time to release locks if\n\t * there's a lot to materialize. Strictly, it is optional to prohibit\n\t * transaction blocks since there will be only one transaction if the\n\t * invalidation threshold needs no update. However, materialization might\n\t * still take a long time and it is probably best for consistency to always\n\t * prevent transaction blocks.  */\n\tPreventInTransactionBlock(true, REFRESH_FUNCTION_NAME);\n\n\tHypertable *ht = cagg_get_hypertable_or_fail(cagg->data.raw_hypertable_id);\n\tis_raw_ht_distributed = hypertable_is_distributed(ht);\n\n\t/* No bucketing when open ended */\n\tif (!(start_isnull && end_isnull))\n\t{\n\t\tif (ts_continuous_agg_bucket_width_variable(cagg))\n\t\t{\n\t\t\trefresh_window = *refresh_window_arg;\n\t\t\tts_compute_inscribed_bucketed_refresh_window_variable(&refresh_window.start,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  &refresh_window.end,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  cagg->bucket_function);\n\t\t}\n\t\telse\n\t\t{\n\t\t\trefresh_window =\n\t\t\t\tcompute_inscribed_bucketed_refresh_window(refresh_window_arg,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t  ts_continuous_agg_bucket_width(cagg));\n\t\t}\n\t}\n\n\tif (refresh_window.start >= refresh_window.end)\n\t\tereport(ERROR,\n\t\t\t\t(errcode(ERRCODE_INVALID_PARAMETER_VALUE),\n\t\t\t\t errmsg(\"refresh window too small\"),\n\t\t\t\t errdetail(\"The refresh window must cover at least one bucket of data.\"),\n\t\t\t\t errhint(\"Align the refresh window with the bucket\"\n\t\t\t\t\t\t \" time zone or use at least two buckets.\")));\n\n\tlog_refresh_window(callctx == CAGG_REFRESH_POLICY ? LOG : DEBUG1,\n\t\t\t\t\t   cagg,\n\t\t\t\t\t   &refresh_window,\n\t\t\t\t\t   \"refreshing continuous aggregate\");\n\n\t/* Perform the refresh across two transactions.\n\t *\n\t * The first transaction moves the invalidation threshold (if needed) and\n\t * copies over invalidations from the hypertable log to the cagg\n\t * invalidation log. Doing the threshold and copying as part of the first\n\t * transaction ensures that the threshold and new invalidations will be\n\t * visible as soon as possible to concurrent refreshes and that we keep\n\t * locks for only a short period. Note that the first transaction\n\t * serializes around the threshold table lock, which protects both the\n\t * threshold and the invalidation processing against concurrent refreshes.\n\t *\n\t * The second transaction processes the cagg invalidation log and then\n\t * performs the actual refresh (materialization of data). This transaction\n\t * serializes around a lock on the materialized hypertable for the\n\t * continuous aggregate that gets refreshed.\n\t */\n\tLockRelationOid(catalog_get_table_id(catalog, CONTINUOUS_AGGS_INVALIDATION_THRESHOLD),\n\t\t\t\t\tAccessExclusiveLock);\n\n\t/* Compute new invalidation threshold. Note that this computation caps the\n\t * threshold at the end of the last bucket that holds data in the\n\t * underlying hypertable. */\n\tcomputed_invalidation_threshold = invalidation_threshold_compute(cagg, &refresh_window);\n\n\t/* Set the new invalidation threshold. Note that this only updates the\n\t * threshold if the new value is greater than the old one. Otherwise, the\n\t * existing threshold is returned. */\n\tinvalidation_threshold = invalidation_threshold_set_or_get(cagg->data.raw_hypertable_id,\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   computed_invalidation_threshold);\n\n\t/* We must also cap the refresh window at the invalidation threshold. If\n\t * we process invalidations after the threshold, the continuous aggregates\n\t * won't be refreshed when the threshold is moved forward in the\n\t * future. The invalidation threshold should already be aligned on bucket\n\t * boundary. */\n\tif (refresh_window.end > invalidation_threshold)\n\t\trefresh_window.end = invalidation_threshold;\n\n\t/* Capping the end might have made the window 0, or negative, so\n\t * nothing to refresh in that case */\n\tif (refresh_window.start >= refresh_window.end)\n\t{\n\t\temit_up_to_date_notice(cagg, callctx);\n\n\t\tif ((rc = SPI_finish()) != SPI_OK_FINISH)\n\t\t\telog(ERROR, \"SPI_finish failed: %s\", SPI_result_code_string(rc));\n\n\t\treturn;\n\t}\n\n\t/* Process invalidations in the hypertable invalidation log */\n\tconst CaggsInfo all_caggs_info =\n\t\tts_continuous_agg_get_all_caggs_info(cagg->data.raw_hypertable_id);\n\tif (is_raw_ht_distributed)\n\t{\n\t\tremote_invalidation_process_hypertable_log(cagg->data.mat_hypertable_id,\n\t\t\t\t\t\t\t\t\t\t\t\t   cagg->data.raw_hypertable_id,\n\t\t\t\t\t\t\t\t\t\t\t\t   refresh_window.type,\n\t\t\t\t\t\t\t\t\t\t\t\t   &all_caggs_info);\n\t}\n\telse\n\t{\n\t\tinvalidation_process_hypertable_log(cagg->data.mat_hypertable_id,\n\t\t\t\t\t\t\t\t\t\t\tcagg->data.raw_hypertable_id,\n\t\t\t\t\t\t\t\t\t\t\trefresh_window.type,\n\t\t\t\t\t\t\t\t\t\t\t&all_caggs_info);\n\t}\n\n\t/* Commit and Start a new transaction */\n\tSPI_commit_and_chain();\n\n\tcagg = ts_continuous_agg_find_by_mat_hypertable_id(mat_id);\n\n\tif (!process_cagg_invalidations_and_refresh(cagg, &refresh_window, callctx, INVALID_CHUNK_ID))\n\t\temit_up_to_date_notice(cagg, callctx);\n\n\tif ((rc = SPI_finish()) != SPI_OK_FINISH)\n\t\telog(ERROR, \"SPI_finish failed: %s\", SPI_result_code_string(rc));\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -15,6 +15,11 @@\n \t/* Connect to SPI manager due to the underlying SPI calls */\n \tif ((rc = SPI_connect_ext(SPI_OPT_NONATOMIC) != SPI_OK_CONNECT))\n \t\telog(ERROR, \"SPI_connect failed: %s\", SPI_result_code_string(rc));\n+\n+\t/* Lock down search_path */\n+\trc = SPI_exec(\"SET LOCAL search_path TO pg_catalog, pg_temp\", 0);\n+\tif (rc < 0)\n+\t\tereport(ERROR, (errcode(ERRCODE_INTERNAL_ERROR), (errmsg(\"could not set search_path\"))));\n \n \t/* Like regular materialized views, require owner to refresh. */\n \tif (!pg_class_ownercheck(cagg->relid, GetUserId()))",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "\t/* Lock down search_path */",
                "\trc = SPI_exec(\"SET LOCAL search_path TO pg_catalog, pg_temp\", 0);",
                "\tif (rc < 0)",
                "\t\tereport(ERROR, (errcode(ERRCODE_INTERNAL_ERROR), (errmsg(\"could not set search_path\"))));"
            ]
        }
    },
    {
        "cve_id": "CVE-2023-25149",
        "func_name": "timescale/timescaledb/ts_hypertable_get_open_dim_max_value",
        "description": "TimescaleDB, an open-source time-series SQL database, has a privilege escalation vulnerability in versions 2.8.0 through 2.9.2. During installation, TimescaleDB creates a telemetry job that is runs as the installation user. The queries run as part of the telemetry data collection were not run with a locked down `search_path`, allowing malicious users to create functions that would be executed by the telemetry job, leading to privilege escalation. In order to be able to take advantage of this vulnerability, a user would need to be able to create objects in a database and then get a superuser to install TimescaleDB into their database. When TimescaleDB is installed as trusted extension, non-superusers can install the extension without help from a superuser.\n\nVersion 2.9.3 fixes this issue. As a mitigation, the `search_path` of the user running the telemetry job can be locked down to not include schemas writable by other users. The vulnerability is not exploitable on instances in Timescale Cloud and Managed Service for TimescaleDB due to additional security provisions in place on those platforms.",
        "git_url": "https://github.com/timescale/timescaledb/commit/014b40fb7e8d59087cf1c1988a68dd1979f86cb3",
        "commit_title": "Lock down search_path in SPI calls",
        "commit_text": "",
        "func_before": "Datum\nts_hypertable_get_open_dim_max_value(const Hypertable *ht, int dimension_index, bool *isnull)\n{\n\tStringInfo command;\n\tconst Dimension *dim;\n\tint res;\n\tbool max_isnull;\n\tDatum maxdat;\n\n\tdim = hyperspace_get_open_dimension(ht->space, dimension_index);\n\n\tif (NULL == dim)\n\t\telog(ERROR, \"invalid open dimension index %d\", dimension_index);\n\n\t/* Query for the last bucket in the materialized hypertable */\n\tcommand = makeStringInfo();\n\tappendStringInfo(command,\n\t\t\t\t\t \"SELECT max(%s) FROM %s.%s\",\n\t\t\t\t\t quote_identifier(NameStr(dim->fd.column_name)),\n\t\t\t\t\t quote_identifier(NameStr(ht->fd.schema_name)),\n\t\t\t\t\t quote_identifier(NameStr(ht->fd.table_name)));\n\n\tif (SPI_connect() != SPI_OK_CONNECT)\n\t\telog(ERROR, \"could not connect to SPI\");\n\n\tres = SPI_execute(command->data, true /* read_only */, 0 /*count*/);\n\n\tif (res < 0)\n\t\tereport(ERROR,\n\t\t\t\t(errcode(ERRCODE_INTERNAL_ERROR),\n\t\t\t\t (errmsg(\"could not find the maximum time value for hypertable \\\"%s\\\"\",\n\t\t\t\t\t\t get_rel_name(ht->main_table_relid)))));\n\n\tEnsure(SPI_gettypeid(SPI_tuptable->tupdesc, 1) == ts_dimension_get_partition_type(dim),\n\t\t   \"partition types for result (%d) and dimension (%d) do not match\",\n\t\t   SPI_gettypeid(SPI_tuptable->tupdesc, 1),\n\t\t   ts_dimension_get_partition_type(dim));\n\tmaxdat = SPI_getbinval(SPI_tuptable->vals[0], SPI_tuptable->tupdesc, 1, &max_isnull);\n\n\tif (isnull)\n\t\t*isnull = max_isnull;\n\n\tif ((res = SPI_finish()) != SPI_OK_FINISH)\n\t\telog(ERROR, \"SPI_finish failed: %s\", SPI_result_code_string(res));\n\n\treturn maxdat;\n}",
        "func": "Datum\nts_hypertable_get_open_dim_max_value(const Hypertable *ht, int dimension_index, bool *isnull)\n{\n\tStringInfo command;\n\tconst Dimension *dim;\n\tint res;\n\tbool max_isnull;\n\tDatum maxdat;\n\n\tdim = hyperspace_get_open_dimension(ht->space, dimension_index);\n\n\tif (NULL == dim)\n\t\telog(ERROR, \"invalid open dimension index %d\", dimension_index);\n\n\t/*\n\t * Query for the last bucket in the materialized hypertable.\n\t * Since this might be run as part of a parallel operation\n\t * we cannot use SET search_path here to lock down the\n\t * search_path and instead have to fully schema-qualify\n\t * everything.\n\t */\n\tcommand = makeStringInfo();\n\tappendStringInfo(command,\n\t\t\t\t\t \"SELECT pg_catalog.max(%s) FROM %s.%s\",\n\t\t\t\t\t quote_identifier(NameStr(dim->fd.column_name)),\n\t\t\t\t\t quote_identifier(NameStr(ht->fd.schema_name)),\n\t\t\t\t\t quote_identifier(NameStr(ht->fd.table_name)));\n\n\tif (SPI_connect() != SPI_OK_CONNECT)\n\t\telog(ERROR, \"could not connect to SPI\");\n\n\tres = SPI_execute(command->data, true /* read_only */, 0 /*count*/);\n\n\tif (res < 0)\n\t\tereport(ERROR,\n\t\t\t\t(errcode(ERRCODE_INTERNAL_ERROR),\n\t\t\t\t (errmsg(\"could not find the maximum time value for hypertable \\\"%s\\\"\",\n\t\t\t\t\t\t get_rel_name(ht->main_table_relid)))));\n\n\tEnsure(SPI_gettypeid(SPI_tuptable->tupdesc, 1) == ts_dimension_get_partition_type(dim),\n\t\t   \"partition types for result (%d) and dimension (%d) do not match\",\n\t\t   SPI_gettypeid(SPI_tuptable->tupdesc, 1),\n\t\t   ts_dimension_get_partition_type(dim));\n\tmaxdat = SPI_getbinval(SPI_tuptable->vals[0], SPI_tuptable->tupdesc, 1, &max_isnull);\n\n\tif (isnull)\n\t\t*isnull = max_isnull;\n\n\tif ((res = SPI_finish()) != SPI_OK_FINISH)\n\t\telog(ERROR, \"SPI_finish failed: %s\", SPI_result_code_string(res));\n\n\treturn maxdat;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -12,10 +12,16 @@\n \tif (NULL == dim)\n \t\telog(ERROR, \"invalid open dimension index %d\", dimension_index);\n \n-\t/* Query for the last bucket in the materialized hypertable */\n+\t/*\n+\t * Query for the last bucket in the materialized hypertable.\n+\t * Since this might be run as part of a parallel operation\n+\t * we cannot use SET search_path here to lock down the\n+\t * search_path and instead have to fully schema-qualify\n+\t * everything.\n+\t */\n \tcommand = makeStringInfo();\n \tappendStringInfo(command,\n-\t\t\t\t\t \"SELECT max(%s) FROM %s.%s\",\n+\t\t\t\t\t \"SELECT pg_catalog.max(%s) FROM %s.%s\",\n \t\t\t\t\t quote_identifier(NameStr(dim->fd.column_name)),\n \t\t\t\t\t quote_identifier(NameStr(ht->fd.schema_name)),\n \t\t\t\t\t quote_identifier(NameStr(ht->fd.table_name)));",
        "diff_line_info": {
            "deleted_lines": [
                "\t/* Query for the last bucket in the materialized hypertable */",
                "\t\t\t\t\t \"SELECT max(%s) FROM %s.%s\","
            ],
            "added_lines": [
                "\t/*",
                "\t * Query for the last bucket in the materialized hypertable.",
                "\t * Since this might be run as part of a parallel operation",
                "\t * we cannot use SET search_path here to lock down the",
                "\t * search_path and instead have to fully schema-qualify",
                "\t * everything.",
                "\t */",
                "\t\t\t\t\t \"SELECT pg_catalog.max(%s) FROM %s.%s\","
            ]
        }
    },
    {
        "cve_id": "CVE-2023-25149",
        "func_name": "timescale/timescaledb/continuous_agg_update_materialization",
        "description": "TimescaleDB, an open-source time-series SQL database, has a privilege escalation vulnerability in versions 2.8.0 through 2.9.2. During installation, TimescaleDB creates a telemetry job that is runs as the installation user. The queries run as part of the telemetry data collection were not run with a locked down `search_path`, allowing malicious users to create functions that would be executed by the telemetry job, leading to privilege escalation. In order to be able to take advantage of this vulnerability, a user would need to be able to create objects in a database and then get a superuser to install TimescaleDB into their database. When TimescaleDB is installed as trusted extension, non-superusers can install the extension without help from a superuser.\n\nVersion 2.9.3 fixes this issue. As a mitigation, the `search_path` of the user running the telemetry job can be locked down to not include schemas writable by other users. The vulnerability is not exploitable on instances in Timescale Cloud and Managed Service for TimescaleDB due to additional security provisions in place on those platforms.",
        "git_url": "https://github.com/timescale/timescaledb/commit/014b40fb7e8d59087cf1c1988a68dd1979f86cb3",
        "commit_title": "Lock down search_path in SPI calls",
        "commit_text": "",
        "func_before": "void\ncontinuous_agg_update_materialization(SchemaAndName partial_view,\n\t\t\t\t\t\t\t\t\t  SchemaAndName materialization_table,\n\t\t\t\t\t\t\t\t\t  const NameData *time_column_name,\n\t\t\t\t\t\t\t\t\t  InternalTimeRange new_materialization_range,\n\t\t\t\t\t\t\t\t\t  InternalTimeRange invalidation_range, int32 chunk_id)\n{\n\tInternalTimeRange combined_materialization_range = new_materialization_range;\n\tbool materialize_invalidations_separately = range_length(invalidation_range) > 0;\n\tint res = SPI_connect();\n\tif (res != SPI_OK_CONNECT)\n\t\telog(ERROR, \"could not connect to SPI in materializer\");\n\n\t/* pin the start of new_materialization to the end of new_materialization,\n\t * we are not allowed to materialize beyond that point\n\t */\n\tif (new_materialization_range.start > new_materialization_range.end)\n\t\tnew_materialization_range.start = new_materialization_range.end;\n\n\tif (range_length(invalidation_range) > 0)\n\t{\n\t\tAssert(invalidation_range.start <= invalidation_range.end);\n\n\t\t/* we never materialize beyond the new materialization range */\n\t\tif (invalidation_range.start >= new_materialization_range.end ||\n\t\t\tinvalidation_range.end > new_materialization_range.end)\n\t\t\telog(ERROR, \"internal error: invalidation range ahead of new materialization range\");\n\n\t\t/* If the invalidation and new materialization ranges overlap, materialize in one go */\n\t\tmaterialize_invalidations_separately =\n\t\t\t!ranges_overlap(invalidation_range, new_materialization_range);\n\n\t\tcombined_materialization_range.start =\n\t\t\tint64_min(invalidation_range.start, new_materialization_range.start);\n\t}\n\n\t/* Then insert the materializations.\n\t * We insert them in two groups:\n\t * [lowest_invalidated, greatest_invalidated] and\n\t * [start_of_new_materialization, end_of_new_materialization]\n\t * eventually, we may want more precise deletions and insertions for the invalidated ranges.\n\t * if greatest_invalidated == end_of_new_materialization then we only perform 1 insertion.\n\t * to prevent values from being inserted multiple times.\n\t */\n\tif (range_length(invalidation_range) == 0 || !materialize_invalidations_separately)\n\t{\n\t\tspi_update_materializations(partial_view,\n\t\t\t\t\t\t\t\t\tmaterialization_table,\n\t\t\t\t\t\t\t\t\ttime_column_name,\n\t\t\t\t\t\t\t\t\tinternal_time_range_to_time_range(\n\t\t\t\t\t\t\t\t\t\tcombined_materialization_range),\n\t\t\t\t\t\t\t\t\tchunk_id);\n\t}\n\telse\n\t{\n\t\tspi_update_materializations(partial_view,\n\t\t\t\t\t\t\t\t\tmaterialization_table,\n\t\t\t\t\t\t\t\t\ttime_column_name,\n\t\t\t\t\t\t\t\t\tinternal_time_range_to_time_range(invalidation_range),\n\t\t\t\t\t\t\t\t\tchunk_id);\n\n\t\tspi_update_materializations(partial_view,\n\t\t\t\t\t\t\t\t\tmaterialization_table,\n\t\t\t\t\t\t\t\t\ttime_column_name,\n\t\t\t\t\t\t\t\t\tinternal_time_range_to_time_range(new_materialization_range),\n\t\t\t\t\t\t\t\t\tchunk_id);\n\t}\n\n\tif ((res = SPI_finish()) != SPI_OK_FINISH)\n\t\telog(ERROR, \"SPI_finish failed: %s\", SPI_result_code_string(res));\n}",
        "func": "void\ncontinuous_agg_update_materialization(SchemaAndName partial_view,\n\t\t\t\t\t\t\t\t\t  SchemaAndName materialization_table,\n\t\t\t\t\t\t\t\t\t  const NameData *time_column_name,\n\t\t\t\t\t\t\t\t\t  InternalTimeRange new_materialization_range,\n\t\t\t\t\t\t\t\t\t  InternalTimeRange invalidation_range, int32 chunk_id)\n{\n\tInternalTimeRange combined_materialization_range = new_materialization_range;\n\tbool materialize_invalidations_separately = range_length(invalidation_range) > 0;\n\tint res = SPI_connect();\n\tif (res != SPI_OK_CONNECT)\n\t\telog(ERROR, \"could not connect to SPI in materializer\");\n\n\t/* Lock down search_path */\n\tres = SPI_exec(\"SET LOCAL search_path TO pg_catalog, pg_temp\", 0);\n\tif (res < 0)\n\t\tereport(ERROR, (errcode(ERRCODE_INTERNAL_ERROR), (errmsg(\"could not set search_path\"))));\n\n\t/* pin the start of new_materialization to the end of new_materialization,\n\t * we are not allowed to materialize beyond that point\n\t */\n\tif (new_materialization_range.start > new_materialization_range.end)\n\t\tnew_materialization_range.start = new_materialization_range.end;\n\n\tif (range_length(invalidation_range) > 0)\n\t{\n\t\tAssert(invalidation_range.start <= invalidation_range.end);\n\n\t\t/* we never materialize beyond the new materialization range */\n\t\tif (invalidation_range.start >= new_materialization_range.end ||\n\t\t\tinvalidation_range.end > new_materialization_range.end)\n\t\t\telog(ERROR, \"internal error: invalidation range ahead of new materialization range\");\n\n\t\t/* If the invalidation and new materialization ranges overlap, materialize in one go */\n\t\tmaterialize_invalidations_separately =\n\t\t\t!ranges_overlap(invalidation_range, new_materialization_range);\n\n\t\tcombined_materialization_range.start =\n\t\t\tint64_min(invalidation_range.start, new_materialization_range.start);\n\t}\n\n\t/* Then insert the materializations.\n\t * We insert them in two groups:\n\t * [lowest_invalidated, greatest_invalidated] and\n\t * [start_of_new_materialization, end_of_new_materialization]\n\t * eventually, we may want more precise deletions and insertions for the invalidated ranges.\n\t * if greatest_invalidated == end_of_new_materialization then we only perform 1 insertion.\n\t * to prevent values from being inserted multiple times.\n\t */\n\tif (range_length(invalidation_range) == 0 || !materialize_invalidations_separately)\n\t{\n\t\tspi_update_materializations(partial_view,\n\t\t\t\t\t\t\t\t\tmaterialization_table,\n\t\t\t\t\t\t\t\t\ttime_column_name,\n\t\t\t\t\t\t\t\t\tinternal_time_range_to_time_range(\n\t\t\t\t\t\t\t\t\t\tcombined_materialization_range),\n\t\t\t\t\t\t\t\t\tchunk_id);\n\t}\n\telse\n\t{\n\t\tspi_update_materializations(partial_view,\n\t\t\t\t\t\t\t\t\tmaterialization_table,\n\t\t\t\t\t\t\t\t\ttime_column_name,\n\t\t\t\t\t\t\t\t\tinternal_time_range_to_time_range(invalidation_range),\n\t\t\t\t\t\t\t\t\tchunk_id);\n\n\t\tspi_update_materializations(partial_view,\n\t\t\t\t\t\t\t\t\tmaterialization_table,\n\t\t\t\t\t\t\t\t\ttime_column_name,\n\t\t\t\t\t\t\t\t\tinternal_time_range_to_time_range(new_materialization_range),\n\t\t\t\t\t\t\t\t\tchunk_id);\n\t}\n\n\tif ((res = SPI_finish()) != SPI_OK_FINISH)\n\t\telog(ERROR, \"SPI_finish failed: %s\", SPI_result_code_string(res));\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -10,6 +10,11 @@\n \tint res = SPI_connect();\n \tif (res != SPI_OK_CONNECT)\n \t\telog(ERROR, \"could not connect to SPI in materializer\");\n+\n+\t/* Lock down search_path */\n+\tres = SPI_exec(\"SET LOCAL search_path TO pg_catalog, pg_temp\", 0);\n+\tif (res < 0)\n+\t\tereport(ERROR, (errcode(ERRCODE_INTERNAL_ERROR), (errmsg(\"could not set search_path\"))));\n \n \t/* pin the start of new_materialization to the end of new_materialization,\n \t * we are not allowed to materialize beyond that point",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "\t/* Lock down search_path */",
                "\tres = SPI_exec(\"SET LOCAL search_path TO pg_catalog, pg_temp\", 0);",
                "\tif (res < 0)",
                "\t\tereport(ERROR, (errcode(ERRCODE_INTERNAL_ERROR), (errmsg(\"could not set search_path\"))));"
            ]
        }
    },
    {
        "cve_id": "CVE-2023-25149",
        "func_name": "timescale/timescaledb/add_errors_by_sqlerrcode",
        "description": "TimescaleDB, an open-source time-series SQL database, has a privilege escalation vulnerability in versions 2.8.0 through 2.9.2. During installation, TimescaleDB creates a telemetry job that is runs as the installation user. The queries run as part of the telemetry data collection were not run with a locked down `search_path`, allowing malicious users to create functions that would be executed by the telemetry job, leading to privilege escalation. In order to be able to take advantage of this vulnerability, a user would need to be able to create objects in a database and then get a superuser to install TimescaleDB into their database. When TimescaleDB is installed as trusted extension, non-superusers can install the extension without help from a superuser.\n\nVersion 2.9.3 fixes this issue. As a mitigation, the `search_path` of the user running the telemetry job can be locked down to not include schemas writable by other users. The vulnerability is not exploitable on instances in Timescale Cloud and Managed Service for TimescaleDB due to additional security provisions in place on those platforms.",
        "git_url": "https://github.com/timescale/timescaledb/commit/014b40fb7e8d59087cf1c1988a68dd1979f86cb3",
        "commit_title": "Lock down search_path in SPI calls",
        "commit_text": "",
        "func_before": "static void\nadd_errors_by_sqlerrcode(JsonbParseState *parse_state)\n{\n\tint res;\n\tStringInfo command;\n\tMemoryContext old_context = CurrentMemoryContext, spi_context;\n\n\tconst char *command_string =\n\t\t\"SELECT \"\n\t\t\"job_type, jsonb_object_agg(sqlerrcode, count) \"\n\t\t\"FROM\"\n\t\t\"(\"\n\t\t\"\tSELECT (\"\n\t\t\"\t\tCASE \"\n\t\t\"\t\t\tWHEN error_data ->> \\'proc_schema\\' = \\'_timescaledb_internal\\'\"\n\t\t\" \t\t\tAND error_data ->> \\'proc_name\\' ~ \"\n\t\t\"\\'^policy_(retention|compression|reorder|refresh_continuous_\"\n\t\t\"aggregate|telemetry|job_error_retention)$\\' \"\n\t\t\"\t\t\tTHEN error_data ->> \\'proc_name\\' \"\n\t\t\"\t\t\tELSE \\'user_defined_action\\'\"\n\t\t\"\t\tEND\"\n\t\t\"\t) as job_type, \"\n\t\t\"\terror_data ->> \\'sqlerrcode\\' as sqlerrcode, \"\n\t\t\"\tpg_catalog.COUNT(*) \"\n\t\t\"\tFROM \"\n\t\t\"\t_timescaledb_internal.job_errors \"\n\t\t\"\tWHERE error_data ->> \\'sqlerrcode\\' IS NOT NULL \"\n\t\t\"\tGROUP BY job_type, error_data->> \\'sqlerrcode\\' \"\n\t\t\"\tORDER BY job_type\"\n\t\t\") q \"\n\t\t\"GROUP BY q.job_type\";\n\n\tif (SPI_connect() != SPI_OK_CONNECT)\n\t\telog(ERROR, \"could not connect to SPI\");\n\n\t/* SPI calls must be qualified otherwise they are unsafe */\n\tres = SPI_exec(\"SET search_path TO pg_catalog, pg_temp\", 0);\n\tif (res < 0)\n\t\tereport(ERROR, (errcode(ERRCODE_INTERNAL_ERROR), (errmsg(\"could not set search_path\"))));\n\n\tcommand = makeStringInfo();\n\n\tappendStringInfoString(command, command_string);\n\tres = SPI_execute(command->data, true /*read only*/, 0 /* count */);\n\tif (res < 0)\n\t\tereport(ERROR,\n\t\t\t\t(errcode(ERRCODE_INTERNAL_ERROR),\n\t\t\t\t (errmsg(\"could not get errors by sqlerrcode and job type\"))));\n\n\t/* we expect about 6 rows returned, each row is a record (TEXT, JSONB) */\n\tfor (uint64 i = 0; i < SPI_processed; i++)\n\t{\n\t\tDatum record_jobtype, record_jsonb;\n\t\tbool isnull_jobtype, isnull_jsonb;\n\n\t\trecord_jobtype =\n\t\t\tSPI_getbinval(SPI_tuptable->vals[i], SPI_tuptable->tupdesc, 1, &isnull_jobtype);\n\t\tif (isnull_jobtype)\n\t\t\telog(ERROR, \"null job type returned\");\n\t\trecord_jsonb =\n\t\t\tSPI_getbinval(SPI_tuptable->vals[i], SPI_tuptable->tupdesc, 2, &isnull_jsonb);\n\t\t/* this jsonb looks like {\"P0001\": 32, \"42883\": 6} */\n\t\tJsonb *sqlerrs_jsonb = isnull_jsonb ? NULL : DatumGetJsonbP(record_jsonb);\n\n\t\tif (sqlerrs_jsonb == NULL)\n\t\t\tcontinue;\n\t\t/* the jsonb object cannot be created in the SPI context or it will be lost */\n\t\tspi_context = MemoryContextSwitchTo(old_context);\n\t\tadd_errors_by_sqlerrcode_internal(parse_state,\n\t\t\t\t\t\t\t\t\t\t  TextDatumGetCString(record_jobtype),\n\t\t\t\t\t\t\t\t\t\t  sqlerrs_jsonb);\n\t\told_context = MemoryContextSwitchTo(spi_context);\n\t}\n\n\tres = SPI_exec(\"RESET search_path\", 0);\n\tres = SPI_finish();\n\n\tAssert(res == SPI_OK_FINISH);\n}",
        "func": "static void\nadd_errors_by_sqlerrcode(JsonbParseState *parse_state)\n{\n\tint res;\n\tStringInfo command;\n\tMemoryContext old_context = CurrentMemoryContext, spi_context;\n\n\tconst char *command_string =\n\t\t\"SELECT \"\n\t\t\"job_type, jsonb_object_agg(sqlerrcode, count) \"\n\t\t\"FROM\"\n\t\t\"(\"\n\t\t\"\tSELECT (\"\n\t\t\"\t\tCASE \"\n\t\t\"\t\t\tWHEN error_data ->> \\'proc_schema\\' = \\'_timescaledb_internal\\'\"\n\t\t\" \t\t\tAND error_data ->> \\'proc_name\\' ~ \"\n\t\t\"\\'^policy_(retention|compression|reorder|refresh_continuous_\"\n\t\t\"aggregate|telemetry|job_error_retention)$\\' \"\n\t\t\"\t\t\tTHEN error_data ->> \\'proc_name\\' \"\n\t\t\"\t\t\tELSE \\'user_defined_action\\'\"\n\t\t\"\t\tEND\"\n\t\t\"\t) as job_type, \"\n\t\t\"\terror_data ->> \\'sqlerrcode\\' as sqlerrcode, \"\n\t\t\"\tpg_catalog.COUNT(*) \"\n\t\t\"\tFROM \"\n\t\t\"\t_timescaledb_internal.job_errors \"\n\t\t\"\tWHERE error_data ->> \\'sqlerrcode\\' IS NOT NULL \"\n\t\t\"\tGROUP BY job_type, error_data->> \\'sqlerrcode\\' \"\n\t\t\"\tORDER BY job_type\"\n\t\t\") q \"\n\t\t\"GROUP BY q.job_type\";\n\n\tif (SPI_connect() != SPI_OK_CONNECT)\n\t\telog(ERROR, \"could not connect to SPI\");\n\n\t/* Lock down search_path */\n\tres = SPI_exec(\"SET LOCAL search_path TO pg_catalog, pg_temp\", 0);\n\tif (res < 0)\n\t\tereport(ERROR, (errcode(ERRCODE_INTERNAL_ERROR), (errmsg(\"could not set search_path\"))));\n\n\tcommand = makeStringInfo();\n\n\tappendStringInfoString(command, command_string);\n\tres = SPI_execute(command->data, true /*read only*/, 0 /* count */);\n\tif (res < 0)\n\t\tereport(ERROR,\n\t\t\t\t(errcode(ERRCODE_INTERNAL_ERROR),\n\t\t\t\t (errmsg(\"could not get errors by sqlerrcode and job type\"))));\n\n\t/* we expect about 6 rows returned, each row is a record (TEXT, JSONB) */\n\tfor (uint64 i = 0; i < SPI_processed; i++)\n\t{\n\t\tDatum record_jobtype, record_jsonb;\n\t\tbool isnull_jobtype, isnull_jsonb;\n\n\t\trecord_jobtype =\n\t\t\tSPI_getbinval(SPI_tuptable->vals[i], SPI_tuptable->tupdesc, 1, &isnull_jobtype);\n\t\tif (isnull_jobtype)\n\t\t\telog(ERROR, \"null job type returned\");\n\t\trecord_jsonb =\n\t\t\tSPI_getbinval(SPI_tuptable->vals[i], SPI_tuptable->tupdesc, 2, &isnull_jsonb);\n\t\t/* this jsonb looks like {\"P0001\": 32, \"42883\": 6} */\n\t\tJsonb *sqlerrs_jsonb = isnull_jsonb ? NULL : DatumGetJsonbP(record_jsonb);\n\n\t\tif (sqlerrs_jsonb == NULL)\n\t\t\tcontinue;\n\t\t/* the jsonb object cannot be created in the SPI context or it will be lost */\n\t\tspi_context = MemoryContextSwitchTo(old_context);\n\t\tadd_errors_by_sqlerrcode_internal(parse_state,\n\t\t\t\t\t\t\t\t\t\t  TextDatumGetCString(record_jobtype),\n\t\t\t\t\t\t\t\t\t\t  sqlerrs_jsonb);\n\t\told_context = MemoryContextSwitchTo(spi_context);\n\t}\n\n\tres = SPI_finish();\n\n\tAssert(res == SPI_OK_FINISH);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -33,8 +33,8 @@\n \tif (SPI_connect() != SPI_OK_CONNECT)\n \t\telog(ERROR, \"could not connect to SPI\");\n \n-\t/* SPI calls must be qualified otherwise they are unsafe */\n-\tres = SPI_exec(\"SET search_path TO pg_catalog, pg_temp\", 0);\n+\t/* Lock down search_path */\n+\tres = SPI_exec(\"SET LOCAL search_path TO pg_catalog, pg_temp\", 0);\n \tif (res < 0)\n \t\tereport(ERROR, (errcode(ERRCODE_INTERNAL_ERROR), (errmsg(\"could not set search_path\"))));\n \n@@ -72,7 +72,6 @@\n \t\told_context = MemoryContextSwitchTo(spi_context);\n \t}\n \n-\tres = SPI_exec(\"RESET search_path\", 0);\n \tres = SPI_finish();\n \n \tAssert(res == SPI_OK_FINISH);",
        "diff_line_info": {
            "deleted_lines": [
                "\t/* SPI calls must be qualified otherwise they are unsafe */",
                "\tres = SPI_exec(\"SET search_path TO pg_catalog, pg_temp\", 0);",
                "\tres = SPI_exec(\"RESET search_path\", 0);"
            ],
            "added_lines": [
                "\t/* Lock down search_path */",
                "\tres = SPI_exec(\"SET LOCAL search_path TO pg_catalog, pg_temp\", 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2023-25149",
        "func_name": "timescale/timescaledb/add_job_stats_by_job_type",
        "description": "TimescaleDB, an open-source time-series SQL database, has a privilege escalation vulnerability in versions 2.8.0 through 2.9.2. During installation, TimescaleDB creates a telemetry job that is runs as the installation user. The queries run as part of the telemetry data collection were not run with a locked down `search_path`, allowing malicious users to create functions that would be executed by the telemetry job, leading to privilege escalation. In order to be able to take advantage of this vulnerability, a user would need to be able to create objects in a database and then get a superuser to install TimescaleDB into their database. When TimescaleDB is installed as trusted extension, non-superusers can install the extension without help from a superuser.\n\nVersion 2.9.3 fixes this issue. As a mitigation, the `search_path` of the user running the telemetry job can be locked down to not include schemas writable by other users. The vulnerability is not exploitable on instances in Timescale Cloud and Managed Service for TimescaleDB due to additional security provisions in place on those platforms.",
        "git_url": "https://github.com/timescale/timescaledb/commit/014b40fb7e8d59087cf1c1988a68dd1979f86cb3",
        "commit_title": "Lock down search_path in SPI calls",
        "commit_text": "",
        "func_before": "static void\nadd_job_stats_by_job_type(JsonbParseState *parse_state)\n{\n\tStringInfo command;\n\tint res;\n\tMemoryContext old_context = CurrentMemoryContext, spi_context;\n\tSPITupleTable *tuptable = NULL;\n\n\tconst char *command_string =\n\t\t\"SELECT (\"\n\t\t\"\tCASE \"\n\t\t\"\t\tWHEN j.proc_schema = \\'_timescaledb_internal\\' AND j.proc_name ~ \"\n\t\t\"\\'^policy_(retention|compression|reorder|refresh_continuous_aggregate|telemetry|job_error_\"\n\t\t\"retention)$\\' \"\n\t\t\"\t\tTHEN j.proc_name::TEXT \"\n\t\t\"\t\tELSE \\'user_defined_action\\' \"\n\t\t\"\tEND\"\n\t\t\")  AS job_type, \"\n\t\t\"\tSUM(total_runs)::BIGINT AS total_runs, \"\n\t\t\"\tSUM(total_successes)::BIGINT AS total_successes, \"\n\t\t\"\tSUM(total_failures)::BIGINT AS total_failures, \"\n\t\t\"\tSUM(total_crashes)::BIGINT AS total_crashes, \"\n\t\t\"\tSUM(total_duration) AS total_duration, \"\n\t\t\"\tSUM(total_duration_failures) AS total_duration_failures, \"\n\t\t\"\tMAX(consecutive_failures) AS max_consecutive_failures, \"\n\t\t\"\tMAX(consecutive_crashes) AS max_consecutive_crashes \"\n\t\t\"FROM \"\n\t\t\"\t_timescaledb_internal.bgw_job_stat s \"\n\t\t\"\tJOIN _timescaledb_config.bgw_job j on j.id = s.job_id \"\n\t\t\"GROUP BY \"\n\t\t\"job_type\";\n\n\tif (SPI_connect() != SPI_OK_CONNECT)\n\t\telog(ERROR, \"could not connect to SPI\");\n\n\t/* SPI calls must be qualified otherwise they are unsafe */\n\tres = SPI_exec(\"SET search_path TO pg_catalog, pg_temp\", 0);\n\tif (res < 0)\n\t\tereport(ERROR, (errcode(ERRCODE_INTERNAL_ERROR), (errmsg(\"could not set search_path\"))));\n\n\tcommand = makeStringInfo();\n\n\tappendStringInfoString(command, command_string);\n\tres = SPI_execute(command->data, true /* read_only */, 0 /*count*/);\n\tif (res < 0)\n\t\tereport(ERROR,\n\t\t\t\t(errcode(ERRCODE_INTERNAL_ERROR),\n\t\t\t\t (errmsg(\"could not get job statistics by job type\"))));\n\t/*\n\t * a row returned looks like this:\n\t * (job_type, total_runs, total_successes, total_failures, total_crashes, total_duration,\n\t * total_duration_failures, max_consec_fails, max_consec_crashes)\n\t * (\"policy_telemetry\", 12, 10, 1, 1, 00:00:11, 00:00:01, 1, 1)\n\t */\n\tfor (uint64 i = 0; i < SPI_processed; i++)\n\t{\n\t\ttuptable = SPI_tuptable;\n\t\tTupleDesc tupdesc = tuptable->tupdesc;\n\t\tDatum jobtype_datum;\n\t\tDatum total_runs, total_successes, total_failures, total_crashes;\n\t\tDatum total_duration, total_duration_failures, max_consec_crashes, max_consec_fails;\n\n\t\tbool isnull_jobtype, isnull_runs, isnull_successes, isnull_failures, isnull_crashes;\n\t\tbool isnull_duration, isnull_duration_failures, isnull_consec_crashes, isnull_consec_fails;\n\n\t\tjobtype_datum =\n\t\t\tSPI_getbinval(SPI_tuptable->vals[i], SPI_tuptable->tupdesc, 1, &isnull_jobtype);\n\t\tif (isnull_jobtype)\n\t\t\telog(ERROR, \"null job type returned\");\n\t\ttotal_runs = SPI_getbinval(tuptable->vals[i], tupdesc, 2, &isnull_runs);\n\t\ttotal_successes = SPI_getbinval(tuptable->vals[i], tupdesc, 3, &isnull_successes);\n\t\ttotal_failures = SPI_getbinval(tuptable->vals[i], tupdesc, 4, &isnull_failures);\n\t\ttotal_crashes = SPI_getbinval(tuptable->vals[i], tupdesc, 5, &isnull_crashes);\n\t\ttotal_duration = SPI_getbinval(tuptable->vals[i], tupdesc, 6, &isnull_duration);\n\t\ttotal_duration_failures =\n\t\t\tSPI_getbinval(tuptable->vals[i], tupdesc, 7, &isnull_duration_failures);\n\t\tmax_consec_fails = SPI_getbinval(tuptable->vals[i], tupdesc, 8, &isnull_consec_fails);\n\t\tmax_consec_crashes = SPI_getbinval(tuptable->vals[i], tupdesc, 9, &isnull_consec_crashes);\n\n\t\tif (isnull_jobtype || isnull_runs || isnull_successes || isnull_failures ||\n\t\t\tisnull_crashes || isnull_duration || isnull_consec_crashes || isnull_consec_fails)\n\t\t{\n\t\t\telog(ERROR, \"null record field returned\");\n\t\t}\n\n\t\tspi_context = MemoryContextSwitchTo(old_context);\n\t\tTelemetryJobStats stats = { .total_runs = DatumGetInt64(total_runs),\n\t\t\t\t\t\t\t\t\t.total_successes = DatumGetInt64(total_successes),\n\t\t\t\t\t\t\t\t\t.total_failures = DatumGetInt64(total_failures),\n\t\t\t\t\t\t\t\t\t.total_crashes = DatumGetInt64(total_crashes),\n\t\t\t\t\t\t\t\t\t.max_consecutive_failures = DatumGetInt32(max_consec_fails),\n\t\t\t\t\t\t\t\t\t.max_consecutive_crashes = DatumGetInt32(max_consec_crashes),\n\t\t\t\t\t\t\t\t\t.total_duration = DatumGetIntervalP(total_duration),\n\t\t\t\t\t\t\t\t\t.total_duration_failures =\n\t\t\t\t\t\t\t\t\t\tDatumGetIntervalP(total_duration_failures) };\n\t\tadd_job_stats_internal(parse_state, TextDatumGetCString(jobtype_datum), &stats);\n\t\told_context = MemoryContextSwitchTo(spi_context);\n\t}\n\tres = SPI_exec(\"RESET search_path\", 0);\n\tres = SPI_finish();\n\tAssert(res == SPI_OK_FINISH);\n}",
        "func": "static void\nadd_job_stats_by_job_type(JsonbParseState *parse_state)\n{\n\tStringInfo command;\n\tint res;\n\tMemoryContext old_context = CurrentMemoryContext, spi_context;\n\tSPITupleTable *tuptable = NULL;\n\n\tconst char *command_string =\n\t\t\"SELECT (\"\n\t\t\"\tCASE \"\n\t\t\"\t\tWHEN j.proc_schema = \\'_timescaledb_internal\\' AND j.proc_name ~ \"\n\t\t\"\\'^policy_(retention|compression|reorder|refresh_continuous_aggregate|telemetry|job_error_\"\n\t\t\"retention)$\\' \"\n\t\t\"\t\tTHEN j.proc_name::TEXT \"\n\t\t\"\t\tELSE \\'user_defined_action\\' \"\n\t\t\"\tEND\"\n\t\t\")  AS job_type, \"\n\t\t\"\tSUM(total_runs)::BIGINT AS total_runs, \"\n\t\t\"\tSUM(total_successes)::BIGINT AS total_successes, \"\n\t\t\"\tSUM(total_failures)::BIGINT AS total_failures, \"\n\t\t\"\tSUM(total_crashes)::BIGINT AS total_crashes, \"\n\t\t\"\tSUM(total_duration) AS total_duration, \"\n\t\t\"\tSUM(total_duration_failures) AS total_duration_failures, \"\n\t\t\"\tMAX(consecutive_failures) AS max_consecutive_failures, \"\n\t\t\"\tMAX(consecutive_crashes) AS max_consecutive_crashes \"\n\t\t\"FROM \"\n\t\t\"\t_timescaledb_internal.bgw_job_stat s \"\n\t\t\"\tJOIN _timescaledb_config.bgw_job j on j.id = s.job_id \"\n\t\t\"GROUP BY \"\n\t\t\"job_type\";\n\n\tif (SPI_connect() != SPI_OK_CONNECT)\n\t\telog(ERROR, \"could not connect to SPI\");\n\n\t/* Lock down search_path */\n\tres = SPI_exec(\"SET LOCAL search_path TO pg_catalog, pg_temp\", 0);\n\tif (res < 0)\n\t\tereport(ERROR, (errcode(ERRCODE_INTERNAL_ERROR), (errmsg(\"could not set search_path\"))));\n\n\tcommand = makeStringInfo();\n\n\tappendStringInfoString(command, command_string);\n\tres = SPI_execute(command->data, true /* read_only */, 0 /*count*/);\n\tif (res < 0)\n\t\tereport(ERROR,\n\t\t\t\t(errcode(ERRCODE_INTERNAL_ERROR),\n\t\t\t\t (errmsg(\"could not get job statistics by job type\"))));\n\t/*\n\t * a row returned looks like this:\n\t * (job_type, total_runs, total_successes, total_failures, total_crashes, total_duration,\n\t * total_duration_failures, max_consec_fails, max_consec_crashes)\n\t * (\"policy_telemetry\", 12, 10, 1, 1, 00:00:11, 00:00:01, 1, 1)\n\t */\n\tfor (uint64 i = 0; i < SPI_processed; i++)\n\t{\n\t\ttuptable = SPI_tuptable;\n\t\tTupleDesc tupdesc = tuptable->tupdesc;\n\t\tDatum jobtype_datum;\n\t\tDatum total_runs, total_successes, total_failures, total_crashes;\n\t\tDatum total_duration, total_duration_failures, max_consec_crashes, max_consec_fails;\n\n\t\tbool isnull_jobtype, isnull_runs, isnull_successes, isnull_failures, isnull_crashes;\n\t\tbool isnull_duration, isnull_duration_failures, isnull_consec_crashes, isnull_consec_fails;\n\n\t\tjobtype_datum =\n\t\t\tSPI_getbinval(SPI_tuptable->vals[i], SPI_tuptable->tupdesc, 1, &isnull_jobtype);\n\t\tif (isnull_jobtype)\n\t\t\telog(ERROR, \"null job type returned\");\n\t\ttotal_runs = SPI_getbinval(tuptable->vals[i], tupdesc, 2, &isnull_runs);\n\t\ttotal_successes = SPI_getbinval(tuptable->vals[i], tupdesc, 3, &isnull_successes);\n\t\ttotal_failures = SPI_getbinval(tuptable->vals[i], tupdesc, 4, &isnull_failures);\n\t\ttotal_crashes = SPI_getbinval(tuptable->vals[i], tupdesc, 5, &isnull_crashes);\n\t\ttotal_duration = SPI_getbinval(tuptable->vals[i], tupdesc, 6, &isnull_duration);\n\t\ttotal_duration_failures =\n\t\t\tSPI_getbinval(tuptable->vals[i], tupdesc, 7, &isnull_duration_failures);\n\t\tmax_consec_fails = SPI_getbinval(tuptable->vals[i], tupdesc, 8, &isnull_consec_fails);\n\t\tmax_consec_crashes = SPI_getbinval(tuptable->vals[i], tupdesc, 9, &isnull_consec_crashes);\n\n\t\tif (isnull_jobtype || isnull_runs || isnull_successes || isnull_failures ||\n\t\t\tisnull_crashes || isnull_duration || isnull_consec_crashes || isnull_consec_fails)\n\t\t{\n\t\t\telog(ERROR, \"null record field returned\");\n\t\t}\n\n\t\tspi_context = MemoryContextSwitchTo(old_context);\n\t\tTelemetryJobStats stats = { .total_runs = DatumGetInt64(total_runs),\n\t\t\t\t\t\t\t\t\t.total_successes = DatumGetInt64(total_successes),\n\t\t\t\t\t\t\t\t\t.total_failures = DatumGetInt64(total_failures),\n\t\t\t\t\t\t\t\t\t.total_crashes = DatumGetInt64(total_crashes),\n\t\t\t\t\t\t\t\t\t.max_consecutive_failures = DatumGetInt32(max_consec_fails),\n\t\t\t\t\t\t\t\t\t.max_consecutive_crashes = DatumGetInt32(max_consec_crashes),\n\t\t\t\t\t\t\t\t\t.total_duration = DatumGetIntervalP(total_duration),\n\t\t\t\t\t\t\t\t\t.total_duration_failures =\n\t\t\t\t\t\t\t\t\t\tDatumGetIntervalP(total_duration_failures) };\n\t\tadd_job_stats_internal(parse_state, TextDatumGetCString(jobtype_datum), &stats);\n\t\told_context = MemoryContextSwitchTo(spi_context);\n\t}\n\tres = SPI_finish();\n\tAssert(res == SPI_OK_FINISH);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -33,8 +33,8 @@\n \tif (SPI_connect() != SPI_OK_CONNECT)\n \t\telog(ERROR, \"could not connect to SPI\");\n \n-\t/* SPI calls must be qualified otherwise they are unsafe */\n-\tres = SPI_exec(\"SET search_path TO pg_catalog, pg_temp\", 0);\n+\t/* Lock down search_path */\n+\tres = SPI_exec(\"SET LOCAL search_path TO pg_catalog, pg_temp\", 0);\n \tif (res < 0)\n \t\tereport(ERROR, (errcode(ERRCODE_INTERNAL_ERROR), (errmsg(\"could not set search_path\"))));\n \n@@ -96,7 +96,6 @@\n \t\tadd_job_stats_internal(parse_state, TextDatumGetCString(jobtype_datum), &stats);\n \t\told_context = MemoryContextSwitchTo(spi_context);\n \t}\n-\tres = SPI_exec(\"RESET search_path\", 0);\n \tres = SPI_finish();\n \tAssert(res == SPI_OK_FINISH);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\t/* SPI calls must be qualified otherwise they are unsafe */",
                "\tres = SPI_exec(\"SET search_path TO pg_catalog, pg_temp\", 0);",
                "\tres = SPI_exec(\"RESET search_path\", 0);"
            ],
            "added_lines": [
                "\t/* Lock down search_path */",
                "\tres = SPI_exec(\"SET LOCAL search_path TO pg_catalog, pg_temp\", 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2023-25149",
        "func_name": "timescale/timescaledb/ts_telemetry_replication_info_gather",
        "description": "TimescaleDB, an open-source time-series SQL database, has a privilege escalation vulnerability in versions 2.8.0 through 2.9.2. During installation, TimescaleDB creates a telemetry job that is runs as the installation user. The queries run as part of the telemetry data collection were not run with a locked down `search_path`, allowing malicious users to create functions that would be executed by the telemetry job, leading to privilege escalation. In order to be able to take advantage of this vulnerability, a user would need to be able to create objects in a database and then get a superuser to install TimescaleDB into their database. When TimescaleDB is installed as trusted extension, non-superusers can install the extension without help from a superuser.\n\nVersion 2.9.3 fixes this issue. As a mitigation, the `search_path` of the user running the telemetry job can be locked down to not include schemas writable by other users. The vulnerability is not exploitable on instances in Timescale Cloud and Managed Service for TimescaleDB due to additional security provisions in place on those platforms.",
        "git_url": "https://github.com/timescale/timescaledb/commit/014b40fb7e8d59087cf1c1988a68dd1979f86cb3",
        "commit_title": "Lock down search_path in SPI calls",
        "commit_text": "",
        "func_before": "ReplicationInfo\nts_telemetry_replication_info_gather(void)\n{\n\tint res;\n\tbool isnull;\n\tDatum data;\n\tReplicationInfo info = {\n\t\t.got_num_wal_senders = false,\n\t\t.got_is_wal_receiver = false,\n\t};\n\n\tif (SPI_connect() != SPI_OK_CONNECT)\n\t\treturn info;\n\n\tres = SPI_execute(\"SELECT cast(count(pid) as int) from pg_catalog.pg_stat_get_wal_senders() \"\n\t\t\t\t\t  \"WHERE pid is not null\",\n\t\t\t\t\t  true, /* read_only */\n\t\t\t\t\t  0\t\t/*count*/\n\t);\n\n\tif (res >= 0)\n\t{\n\t\tdata = SPI_getbinval(SPI_tuptable->vals[0], SPI_tuptable->tupdesc, 1, &isnull);\n\t\tinfo.num_wal_senders = DatumGetInt32(data);\n\t\tinfo.got_num_wal_senders = true;\n\t}\n\n\t/* use count() > 0 in case they start having pg_stat_get_wal_receiver()\n\t * return no rows when the DB isn't a replica */\n\tres = SPI_execute(\"SELECT count(pid) > 0 from pg_catalog.pg_stat_get_wal_receiver() WHERE pid \"\n\t\t\t\t\t  \"is not null\",\n\t\t\t\t\t  true, /* read_only */\n\t\t\t\t\t  0\t\t/*count*/\n\t);\n\tif (res >= 0)\n\t{\n\t\tdata = SPI_getbinval(SPI_tuptable->vals[0], SPI_tuptable->tupdesc, 1, &isnull);\n\t\tinfo.is_wal_receiver = DatumGetBool(data);\n\t\tinfo.got_is_wal_receiver = true;\n\t}\n\n\tif ((res = SPI_finish()) != SPI_OK_FINISH)\n\t\telog(ERROR, \"SPI_finish failed: %s\", SPI_result_code_string(res));\n\n\treturn info;\n}",
        "func": "ReplicationInfo\nts_telemetry_replication_info_gather(void)\n{\n\tint res;\n\tbool isnull;\n\tDatum data;\n\tReplicationInfo info = {\n\t\t.got_num_wal_senders = false,\n\t\t.got_is_wal_receiver = false,\n\t};\n\n\tif (SPI_connect() != SPI_OK_CONNECT)\n\t\treturn info;\n\n\t/* Lock down search_path */\n\tres = SPI_exec(\"SET LOCAL search_path TO pg_catalog, pg_temp\", 0);\n\tif (res < 0)\n\t\tereport(ERROR, (errcode(ERRCODE_INTERNAL_ERROR), (errmsg(\"could not set search_path\"))));\n\n\tres = SPI_execute(\"SELECT cast(count(pid) as int) from pg_catalog.pg_stat_get_wal_senders() \"\n\t\t\t\t\t  \"WHERE pid is not null\",\n\t\t\t\t\t  true, /* read_only */\n\t\t\t\t\t  0\t\t/*count*/\n\t);\n\n\tif (res >= 0)\n\t{\n\t\tdata = SPI_getbinval(SPI_tuptable->vals[0], SPI_tuptable->tupdesc, 1, &isnull);\n\t\tinfo.num_wal_senders = DatumGetInt32(data);\n\t\tinfo.got_num_wal_senders = true;\n\t}\n\n\t/* use count() > 0 in case they start having pg_stat_get_wal_receiver()\n\t * return no rows when the DB isn't a replica */\n\tres = SPI_execute(\"SELECT count(pid) > 0 from pg_catalog.pg_stat_get_wal_receiver() WHERE pid \"\n\t\t\t\t\t  \"is not null\",\n\t\t\t\t\t  true, /* read_only */\n\t\t\t\t\t  0\t\t/*count*/\n\t);\n\tif (res >= 0)\n\t{\n\t\tdata = SPI_getbinval(SPI_tuptable->vals[0], SPI_tuptable->tupdesc, 1, &isnull);\n\t\tinfo.is_wal_receiver = DatumGetBool(data);\n\t\tinfo.got_is_wal_receiver = true;\n\t}\n\n\tif ((res = SPI_finish()) != SPI_OK_FINISH)\n\t\telog(ERROR, \"SPI_finish failed: %s\", SPI_result_code_string(res));\n\n\treturn info;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -11,6 +11,11 @@\n \n \tif (SPI_connect() != SPI_OK_CONNECT)\n \t\treturn info;\n+\n+\t/* Lock down search_path */\n+\tres = SPI_exec(\"SET LOCAL search_path TO pg_catalog, pg_temp\", 0);\n+\tif (res < 0)\n+\t\tereport(ERROR, (errcode(ERRCODE_INTERNAL_ERROR), (errmsg(\"could not set search_path\"))));\n \n \tres = SPI_execute(\"SELECT cast(count(pid) as int) from pg_catalog.pg_stat_get_wal_senders() \"\n \t\t\t\t\t  \"WHERE pid is not null\",",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "\t/* Lock down search_path */",
                "\tres = SPI_exec(\"SET LOCAL search_path TO pg_catalog, pg_temp\", 0);",
                "\tif (res < 0)",
                "\t\tereport(ERROR, (errcode(ERRCODE_INTERNAL_ERROR), (errmsg(\"could not set search_path\"))));"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-25636",
        "func_name": "kernel/git/netfilter/nf/nft_flow_rule_create",
        "description": "net/netfilter/nf_dup_netdev.c in the Linux kernel 5.4 through 5.6.10 allows local users to gain privileges because of a heap out-of-bounds write. This is related to nf_tables_offload.",
        "git_url": "https://git.kernel.org/pub/scm/linux/kernel/git/netfilter/nf.git/commit/?h=b1a5983f56e371046dcf164f90bfaf704d2b89f6",
        "commit_title": "immediate verdict expression needs to allocate one slot in the flow offload",
        "commit_text": "action array, however, immediate data expression does not need to do so.  fwd and dup expression need to allocate one slot, this is missing.  Add a new offload_action interface to report if this expression needs to allocate one slot in the flow offload action array.  Reported-and-tested-by: Nick Gregory <Nick.Gregory@Sophos.com> ",
        "func_before": "struct nft_flow_rule *nft_flow_rule_create(struct net *net,\n\t\t\t\t\t   const struct nft_rule *rule)\n{\n\tstruct nft_offload_ctx *ctx;\n\tstruct nft_flow_rule *flow;\n\tint num_actions = 0, err;\n\tstruct nft_expr *expr;\n\n\texpr = nft_expr_first(rule);\n\twhile (nft_expr_more(rule, expr)) {\n\t\tif (expr->ops->offload_flags & NFT_OFFLOAD_F_ACTION)\n\t\t\tnum_actions++;\n\n\t\texpr = nft_expr_next(expr);\n\t}\n\n\tif (num_actions == 0)\n\t\treturn ERR_PTR(-EOPNOTSUPP);\n\n\tflow = nft_flow_rule_alloc(num_actions);\n\tif (!flow)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\texpr = nft_expr_first(rule);\n\n\tctx = kzalloc(sizeof(struct nft_offload_ctx), GFP_KERNEL);\n\tif (!ctx) {\n\t\terr = -ENOMEM;\n\t\tgoto err_out;\n\t}\n\tctx->net = net;\n\tctx->dep.type = NFT_OFFLOAD_DEP_UNSPEC;\n\n\twhile (nft_expr_more(rule, expr)) {\n\t\tif (!expr->ops->offload) {\n\t\t\terr = -EOPNOTSUPP;\n\t\t\tgoto err_out;\n\t\t}\n\t\terr = expr->ops->offload(ctx, flow, expr);\n\t\tif (err < 0)\n\t\t\tgoto err_out;\n\n\t\texpr = nft_expr_next(expr);\n\t}\n\tnft_flow_rule_transfer_vlan(ctx, flow);\n\n\tflow->proto = ctx->dep.l3num;\n\tkfree(ctx);\n\n\treturn flow;\nerr_out:\n\tkfree(ctx);\n\tnft_flow_rule_destroy(flow);\n\n\treturn ERR_PTR(err);\n}",
        "func": "struct nft_flow_rule *nft_flow_rule_create(struct net *net,\n\t\t\t\t\t   const struct nft_rule *rule)\n{\n\tstruct nft_offload_ctx *ctx;\n\tstruct nft_flow_rule *flow;\n\tint num_actions = 0, err;\n\tstruct nft_expr *expr;\n\n\texpr = nft_expr_first(rule);\n\twhile (nft_expr_more(rule, expr)) {\n\t\tif (expr->ops->offload_action &&\n\t\t    expr->ops->offload_action(expr))\n\t\t\tnum_actions++;\n\n\t\texpr = nft_expr_next(expr);\n\t}\n\n\tif (num_actions == 0)\n\t\treturn ERR_PTR(-EOPNOTSUPP);\n\n\tflow = nft_flow_rule_alloc(num_actions);\n\tif (!flow)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\texpr = nft_expr_first(rule);\n\n\tctx = kzalloc(sizeof(struct nft_offload_ctx), GFP_KERNEL);\n\tif (!ctx) {\n\t\terr = -ENOMEM;\n\t\tgoto err_out;\n\t}\n\tctx->net = net;\n\tctx->dep.type = NFT_OFFLOAD_DEP_UNSPEC;\n\n\twhile (nft_expr_more(rule, expr)) {\n\t\tif (!expr->ops->offload) {\n\t\t\terr = -EOPNOTSUPP;\n\t\t\tgoto err_out;\n\t\t}\n\t\terr = expr->ops->offload(ctx, flow, expr);\n\t\tif (err < 0)\n\t\t\tgoto err_out;\n\n\t\texpr = nft_expr_next(expr);\n\t}\n\tnft_flow_rule_transfer_vlan(ctx, flow);\n\n\tflow->proto = ctx->dep.l3num;\n\tkfree(ctx);\n\n\treturn flow;\nerr_out:\n\tkfree(ctx);\n\tnft_flow_rule_destroy(flow);\n\n\treturn ERR_PTR(err);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -8,7 +8,8 @@\n \n \texpr = nft_expr_first(rule);\n \twhile (nft_expr_more(rule, expr)) {\n-\t\tif (expr->ops->offload_flags & NFT_OFFLOAD_F_ACTION)\n+\t\tif (expr->ops->offload_action &&\n+\t\t    expr->ops->offload_action(expr))\n \t\t\tnum_actions++;\n \n \t\texpr = nft_expr_next(expr);",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tif (expr->ops->offload_flags & NFT_OFFLOAD_F_ACTION)"
            ],
            "added_lines": [
                "\t\tif (expr->ops->offload_action &&",
                "\t\t    expr->ops->offload_action(expr))"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-2584",
        "func_name": "torvalds/linux/em_fxrstor",
        "description": "arch/x86/kvm/emulate.c in the Linux kernel through 4.9.3 allows local users to obtain sensitive information from kernel memory or cause a denial of service (use-after-free) via a crafted application that leverages instruction emulation for fxrstor, fxsave, sgdt, and sidt.",
        "git_url": "https://github.com/torvalds/linux/commit/129a72a0d3c8e139a04512325384fe5ac119e74d",
        "commit_title": "KVM: x86: Introduce segmented_write_std",
        "commit_text": " Introduces segemented_write_std.  Switches from emulated reads/writes to standard read/writes in fxsave, fxrstor, sgdt, and sidt.  This fixes CVE-2017-2584, a longstanding kernel memory leak.  Since commit 283c95d0e389 (\"KVM: x86: emulate FXSAVE and FXRSTOR\", 2016-11-09), which is luckily not yet in any final release, this would also be an exploitable kernel memory *write*!  Cc: stable@vger.kernel.org Suggested-by: Paolo Bonzini <pbonzini@redhat.com>",
        "func_before": "static int em_fxrstor(struct x86_emulate_ctxt *ctxt)\n{\n\tstruct fxregs_state fx_state;\n\tint rc;\n\n\trc = check_fxsr(ctxt);\n\tif (rc != X86EMUL_CONTINUE)\n\t\treturn rc;\n\n\trc = segmented_read(ctxt, ctxt->memop.addr.mem, &fx_state, 512);\n\tif (rc != X86EMUL_CONTINUE)\n\t\treturn rc;\n\n\tif (fx_state.mxcsr >> 16)\n\t\treturn emulate_gp(ctxt, 0);\n\n\tctxt->ops->get_fpu(ctxt);\n\n\tif (ctxt->mode < X86EMUL_MODE_PROT64)\n\t\trc = fxrstor_fixup(ctxt, &fx_state);\n\n\tif (rc == X86EMUL_CONTINUE)\n\t\trc = asm_safe(\"fxrstor %[fx]\", : [fx] \"m\"(fx_state));\n\n\tctxt->ops->put_fpu(ctxt);\n\n\treturn rc;\n}",
        "func": "static int em_fxrstor(struct x86_emulate_ctxt *ctxt)\n{\n\tstruct fxregs_state fx_state;\n\tint rc;\n\n\trc = check_fxsr(ctxt);\n\tif (rc != X86EMUL_CONTINUE)\n\t\treturn rc;\n\n\trc = segmented_read_std(ctxt, ctxt->memop.addr.mem, &fx_state, 512);\n\tif (rc != X86EMUL_CONTINUE)\n\t\treturn rc;\n\n\tif (fx_state.mxcsr >> 16)\n\t\treturn emulate_gp(ctxt, 0);\n\n\tctxt->ops->get_fpu(ctxt);\n\n\tif (ctxt->mode < X86EMUL_MODE_PROT64)\n\t\trc = fxrstor_fixup(ctxt, &fx_state);\n\n\tif (rc == X86EMUL_CONTINUE)\n\t\trc = asm_safe(\"fxrstor %[fx]\", : [fx] \"m\"(fx_state));\n\n\tctxt->ops->put_fpu(ctxt);\n\n\treturn rc;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -7,7 +7,7 @@\n \tif (rc != X86EMUL_CONTINUE)\n \t\treturn rc;\n \n-\trc = segmented_read(ctxt, ctxt->memop.addr.mem, &fx_state, 512);\n+\trc = segmented_read_std(ctxt, ctxt->memop.addr.mem, &fx_state, 512);\n \tif (rc != X86EMUL_CONTINUE)\n \t\treturn rc;\n ",
        "diff_line_info": {
            "deleted_lines": [
                "\trc = segmented_read(ctxt, ctxt->memop.addr.mem, &fx_state, 512);"
            ],
            "added_lines": [
                "\trc = segmented_read_std(ctxt, ctxt->memop.addr.mem, &fx_state, 512);"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-2584",
        "func_name": "torvalds/linux/em_fxsave",
        "description": "arch/x86/kvm/emulate.c in the Linux kernel through 4.9.3 allows local users to obtain sensitive information from kernel memory or cause a denial of service (use-after-free) via a crafted application that leverages instruction emulation for fxrstor, fxsave, sgdt, and sidt.",
        "git_url": "https://github.com/torvalds/linux/commit/129a72a0d3c8e139a04512325384fe5ac119e74d",
        "commit_title": "KVM: x86: Introduce segmented_write_std",
        "commit_text": " Introduces segemented_write_std.  Switches from emulated reads/writes to standard read/writes in fxsave, fxrstor, sgdt, and sidt.  This fixes CVE-2017-2584, a longstanding kernel memory leak.  Since commit 283c95d0e389 (\"KVM: x86: emulate FXSAVE and FXRSTOR\", 2016-11-09), which is luckily not yet in any final release, this would also be an exploitable kernel memory *write*!  Cc: stable@vger.kernel.org Suggested-by: Paolo Bonzini <pbonzini@redhat.com>",
        "func_before": "static int em_fxsave(struct x86_emulate_ctxt *ctxt)\n{\n\tstruct fxregs_state fx_state;\n\tsize_t size;\n\tint rc;\n\n\trc = check_fxsr(ctxt);\n\tif (rc != X86EMUL_CONTINUE)\n\t\treturn rc;\n\n\tctxt->ops->get_fpu(ctxt);\n\n\trc = asm_safe(\"fxsave %[fx]\", , [fx] \"+m\"(fx_state));\n\n\tctxt->ops->put_fpu(ctxt);\n\n\tif (rc != X86EMUL_CONTINUE)\n\t\treturn rc;\n\n\tif (ctxt->ops->get_cr(ctxt, 4) & X86_CR4_OSFXSR)\n\t\tsize = offsetof(struct fxregs_state, xmm_space[8 * 16/4]);\n\telse\n\t\tsize = offsetof(struct fxregs_state, xmm_space[0]);\n\n\treturn segmented_write(ctxt, ctxt->memop.addr.mem, &fx_state, size);\n}",
        "func": "static int em_fxsave(struct x86_emulate_ctxt *ctxt)\n{\n\tstruct fxregs_state fx_state;\n\tsize_t size;\n\tint rc;\n\n\trc = check_fxsr(ctxt);\n\tif (rc != X86EMUL_CONTINUE)\n\t\treturn rc;\n\n\tctxt->ops->get_fpu(ctxt);\n\n\trc = asm_safe(\"fxsave %[fx]\", , [fx] \"+m\"(fx_state));\n\n\tctxt->ops->put_fpu(ctxt);\n\n\tif (rc != X86EMUL_CONTINUE)\n\t\treturn rc;\n\n\tif (ctxt->ops->get_cr(ctxt, 4) & X86_CR4_OSFXSR)\n\t\tsize = offsetof(struct fxregs_state, xmm_space[8 * 16/4]);\n\telse\n\t\tsize = offsetof(struct fxregs_state, xmm_space[0]);\n\n\treturn segmented_write_std(ctxt, ctxt->memop.addr.mem, &fx_state, size);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -22,5 +22,5 @@\n \telse\n \t\tsize = offsetof(struct fxregs_state, xmm_space[0]);\n \n-\treturn segmented_write(ctxt, ctxt->memop.addr.mem, &fx_state, size);\n+\treturn segmented_write_std(ctxt, ctxt->memop.addr.mem, &fx_state, size);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\treturn segmented_write(ctxt, ctxt->memop.addr.mem, &fx_state, size);"
            ],
            "added_lines": [
                "\treturn segmented_write_std(ctxt, ctxt->memop.addr.mem, &fx_state, size);"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-2584",
        "func_name": "torvalds/linux/emulate_store_desc_ptr",
        "description": "arch/x86/kvm/emulate.c in the Linux kernel through 4.9.3 allows local users to obtain sensitive information from kernel memory or cause a denial of service (use-after-free) via a crafted application that leverages instruction emulation for fxrstor, fxsave, sgdt, and sidt.",
        "git_url": "https://github.com/torvalds/linux/commit/129a72a0d3c8e139a04512325384fe5ac119e74d",
        "commit_title": "KVM: x86: Introduce segmented_write_std",
        "commit_text": " Introduces segemented_write_std.  Switches from emulated reads/writes to standard read/writes in fxsave, fxrstor, sgdt, and sidt.  This fixes CVE-2017-2584, a longstanding kernel memory leak.  Since commit 283c95d0e389 (\"KVM: x86: emulate FXSAVE and FXRSTOR\", 2016-11-09), which is luckily not yet in any final release, this would also be an exploitable kernel memory *write*!  Cc: stable@vger.kernel.org Suggested-by: Paolo Bonzini <pbonzini@redhat.com>",
        "func_before": "static int emulate_store_desc_ptr(struct x86_emulate_ctxt *ctxt,\n\t\t\t\t  void (*get)(struct x86_emulate_ctxt *ctxt,\n\t\t\t\t\t      struct desc_ptr *ptr))\n{\n\tstruct desc_ptr desc_ptr;\n\n\tif (ctxt->mode == X86EMUL_MODE_PROT64)\n\t\tctxt->op_bytes = 8;\n\tget(ctxt, &desc_ptr);\n\tif (ctxt->op_bytes == 2) {\n\t\tctxt->op_bytes = 4;\n\t\tdesc_ptr.address &= 0x00ffffff;\n\t}\n\t/* Disable writeback. */\n\tctxt->dst.type = OP_NONE;\n\treturn segmented_write(ctxt, ctxt->dst.addr.mem,\n\t\t\t       &desc_ptr, 2 + ctxt->op_bytes);\n}",
        "func": "static int emulate_store_desc_ptr(struct x86_emulate_ctxt *ctxt,\n\t\t\t\t  void (*get)(struct x86_emulate_ctxt *ctxt,\n\t\t\t\t\t      struct desc_ptr *ptr))\n{\n\tstruct desc_ptr desc_ptr;\n\n\tif (ctxt->mode == X86EMUL_MODE_PROT64)\n\t\tctxt->op_bytes = 8;\n\tget(ctxt, &desc_ptr);\n\tif (ctxt->op_bytes == 2) {\n\t\tctxt->op_bytes = 4;\n\t\tdesc_ptr.address &= 0x00ffffff;\n\t}\n\t/* Disable writeback. */\n\tctxt->dst.type = OP_NONE;\n\treturn segmented_write_std(ctxt, ctxt->dst.addr.mem,\n\t\t\t\t   &desc_ptr, 2 + ctxt->op_bytes);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -13,6 +13,6 @@\n \t}\n \t/* Disable writeback. */\n \tctxt->dst.type = OP_NONE;\n-\treturn segmented_write(ctxt, ctxt->dst.addr.mem,\n-\t\t\t       &desc_ptr, 2 + ctxt->op_bytes);\n+\treturn segmented_write_std(ctxt, ctxt->dst.addr.mem,\n+\t\t\t\t   &desc_ptr, 2 + ctxt->op_bytes);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\treturn segmented_write(ctxt, ctxt->dst.addr.mem,",
                "\t\t\t       &desc_ptr, 2 + ctxt->op_bytes);"
            ],
            "added_lines": [
                "\treturn segmented_write_std(ctxt, ctxt->dst.addr.mem,",
                "\t\t\t\t   &desc_ptr, 2 + ctxt->op_bytes);"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-8539",
        "func_name": "torvalds/linux/trusted_update",
        "description": "The KEYS subsystem in the Linux kernel before 4.4 allows local users to gain privileges or cause a denial of service (BUG) via crafted keyctl commands that negatively instantiate a key, related to security/keys/encrypted-keys/encrypted.c, security/keys/trusted.c, and security/keys/user_defined.c.",
        "git_url": "https://github.com/torvalds/linux/commit/096fe9eaea40a17e125569f9e657e34cdb6d73bd",
        "commit_title": "KEYS: Fix handling of stored error in a negatively instantiated user key",
        "commit_text": " If a user key gets negatively instantiated, an error code is cached in the payload area.  A negatively instantiated key may be then be positively instantiated by updating it with valid data.  However, the ->update key type method must be aware that the error code may be there.  The following may be used to trigger the bug in the user key type:      keyctl request2 user user \"\" @u     keyctl add user user \"a\" @u  which manifests itself as:  \tBUG: unable to handle kernel paging request at 00000000ffffff8a \tIP: [<ffffffff810a376f>] __call_rcu.constprop.76+0x1f/0x280 kernel/rcu/tree.c:3046 \tPGD 7cc30067 PUD 0 \tOops: 0002 [#1] SMP \tModules linked in: \tCPU: 3 PID: 2644 Comm: a.out Not tainted 4.3.0+ #49 \tHardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS Bochs 01/01/2011 \ttask: ffff88003ddea700 ti: ffff88003dd88000 task.ti: ffff88003dd88000 \tRIP: 0010:[<ffffffff810a376f>]  [<ffffffff810a376f>] __call_rcu.constprop.76+0x1f/0x280 \t [<ffffffff810a376f>] __call_rcu.constprop.76+0x1f/0x280 kernel/rcu/tree.c:3046 \tRSP: 0018:ffff88003dd8bdb0  EFLAGS: 00010246 \tRAX: 00000000ffffff82 RBX: 0000000000000000 RCX: 0000000000000001 \tRDX: ffffffff81e3fe40 RSI: 0000000000000000 RDI: 00000000ffffff82 \tRBP: ffff88003dd8bde0 R08: ffff88007d2d2da0 R09: 0000000000000000 \tR10: 0000000000000000 R11: ffff88003e8073c0 R12: 00000000ffffff82 \tR13: ffff88003dd8be68 R14: ffff88007d027600 R15: ffff88003ddea700 \tFS:  0000000000b92880(0063) GS:ffff88007fd00000(0000) knlGS:0000000000000000 \tCS:  0010 DS: 0000 ES: 0000 CR0: 000000008005003b \tCR2: 00000000ffffff8a CR3: 000000007cc5f000 CR4: 00000000000006e0 \tStack: \t ffff88003dd8bdf0 ffffffff81160a8a 0000000000000000 00000000ffffff82 \t ffff88003dd8be68 ffff88007d027600 ffff88003dd8bdf0 ffffffff810a39e5 \t ffff88003dd8be20 ffffffff812a31ab ffff88007d027600 ffff88007d027620 \tCall Trace: \t [<ffffffff810a39e5>] kfree_call_rcu+0x15/0x20 kernel/rcu/tree.c:3136 \t [<ffffffff812a31ab>] user_update+0x8b/0xb0 security/keys/user_defined.c:129 \t [<     inline     >] __key_update security/keys/key.c:730 \t [<ffffffff8129e5c1>] key_create_or_update+0x291/0x440 security/keys/key.c:908 \t [<     inline     >] SYSC_add_key security/keys/keyctl.c:125 \t [<ffffffff8129fc21>] SyS_add_key+0x101/0x1e0 security/keys/keyctl.c:60 \t [<ffffffff8185f617>] entry_SYSCALL_64_fastpath+0x12/0x6a arch/x86/entry/entry_64.S:185  Note the error code (-ENOKEY) in EDX.  A similar bug can be tripped by:      keyctl request2 trusted user \"\" @u     keyctl add trusted user \"a\" @u  This should also affect encrypted keys - but that has to be correctly parameterised or it will fail with EINVAL before getting to the bit that will crashes. ",
        "func_before": "static int trusted_update(struct key *key, struct key_preparsed_payload *prep)\n{\n\tstruct trusted_key_payload *p = key->payload.data[0];\n\tstruct trusted_key_payload *new_p;\n\tstruct trusted_key_options *new_o;\n\tsize_t datalen = prep->datalen;\n\tchar *datablob;\n\tint ret = 0;\n\n\tif (!p->migratable)\n\t\treturn -EPERM;\n\tif (datalen <= 0 || datalen > 32767 || !prep->data)\n\t\treturn -EINVAL;\n\n\tdatablob = kmalloc(datalen + 1, GFP_KERNEL);\n\tif (!datablob)\n\t\treturn -ENOMEM;\n\tnew_o = trusted_options_alloc();\n\tif (!new_o) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\tnew_p = trusted_payload_alloc(key);\n\tif (!new_p) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tmemcpy(datablob, prep->data, datalen);\n\tdatablob[datalen] = '\\0';\n\tret = datablob_parse(datablob, new_p, new_o);\n\tif (ret != Opt_update) {\n\t\tret = -EINVAL;\n\t\tkfree(new_p);\n\t\tgoto out;\n\t}\n\n\tif (!new_o->keyhandle) {\n\t\tret = -EINVAL;\n\t\tkfree(new_p);\n\t\tgoto out;\n\t}\n\n\t/* copy old key values, and reseal with new pcrs */\n\tnew_p->migratable = p->migratable;\n\tnew_p->key_len = p->key_len;\n\tmemcpy(new_p->key, p->key, p->key_len);\n\tdump_payload(p);\n\tdump_payload(new_p);\n\n\tret = key_seal(new_p, new_o);\n\tif (ret < 0) {\n\t\tpr_info(\"trusted_key: key_seal failed (%d)\\n\", ret);\n\t\tkfree(new_p);\n\t\tgoto out;\n\t}\n\tif (new_o->pcrlock) {\n\t\tret = pcrlock(new_o->pcrlock);\n\t\tif (ret < 0) {\n\t\t\tpr_info(\"trusted_key: pcrlock failed (%d)\\n\", ret);\n\t\t\tkfree(new_p);\n\t\t\tgoto out;\n\t\t}\n\t}\n\trcu_assign_keypointer(key, new_p);\n\tcall_rcu(&p->rcu, trusted_rcu_free);\nout:\n\tkfree(datablob);\n\tkfree(new_o);\n\treturn ret;\n}",
        "func": "static int trusted_update(struct key *key, struct key_preparsed_payload *prep)\n{\n\tstruct trusted_key_payload *p;\n\tstruct trusted_key_payload *new_p;\n\tstruct trusted_key_options *new_o;\n\tsize_t datalen = prep->datalen;\n\tchar *datablob;\n\tint ret = 0;\n\n\tif (test_bit(KEY_FLAG_NEGATIVE, &key->flags))\n\t\treturn -ENOKEY;\n\tp = key->payload.data[0];\n\tif (!p->migratable)\n\t\treturn -EPERM;\n\tif (datalen <= 0 || datalen > 32767 || !prep->data)\n\t\treturn -EINVAL;\n\n\tdatablob = kmalloc(datalen + 1, GFP_KERNEL);\n\tif (!datablob)\n\t\treturn -ENOMEM;\n\tnew_o = trusted_options_alloc();\n\tif (!new_o) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\tnew_p = trusted_payload_alloc(key);\n\tif (!new_p) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tmemcpy(datablob, prep->data, datalen);\n\tdatablob[datalen] = '\\0';\n\tret = datablob_parse(datablob, new_p, new_o);\n\tif (ret != Opt_update) {\n\t\tret = -EINVAL;\n\t\tkfree(new_p);\n\t\tgoto out;\n\t}\n\n\tif (!new_o->keyhandle) {\n\t\tret = -EINVAL;\n\t\tkfree(new_p);\n\t\tgoto out;\n\t}\n\n\t/* copy old key values, and reseal with new pcrs */\n\tnew_p->migratable = p->migratable;\n\tnew_p->key_len = p->key_len;\n\tmemcpy(new_p->key, p->key, p->key_len);\n\tdump_payload(p);\n\tdump_payload(new_p);\n\n\tret = key_seal(new_p, new_o);\n\tif (ret < 0) {\n\t\tpr_info(\"trusted_key: key_seal failed (%d)\\n\", ret);\n\t\tkfree(new_p);\n\t\tgoto out;\n\t}\n\tif (new_o->pcrlock) {\n\t\tret = pcrlock(new_o->pcrlock);\n\t\tif (ret < 0) {\n\t\t\tpr_info(\"trusted_key: pcrlock failed (%d)\\n\", ret);\n\t\t\tkfree(new_p);\n\t\t\tgoto out;\n\t\t}\n\t}\n\trcu_assign_keypointer(key, new_p);\n\tcall_rcu(&p->rcu, trusted_rcu_free);\nout:\n\tkfree(datablob);\n\tkfree(new_o);\n\treturn ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,12 +1,15 @@\n static int trusted_update(struct key *key, struct key_preparsed_payload *prep)\n {\n-\tstruct trusted_key_payload *p = key->payload.data[0];\n+\tstruct trusted_key_payload *p;\n \tstruct trusted_key_payload *new_p;\n \tstruct trusted_key_options *new_o;\n \tsize_t datalen = prep->datalen;\n \tchar *datablob;\n \tint ret = 0;\n \n+\tif (test_bit(KEY_FLAG_NEGATIVE, &key->flags))\n+\t\treturn -ENOKEY;\n+\tp = key->payload.data[0];\n \tif (!p->migratable)\n \t\treturn -EPERM;\n \tif (datalen <= 0 || datalen > 32767 || !prep->data)",
        "diff_line_info": {
            "deleted_lines": [
                "\tstruct trusted_key_payload *p = key->payload.data[0];"
            ],
            "added_lines": [
                "\tstruct trusted_key_payload *p;",
                "\tif (test_bit(KEY_FLAG_NEGATIVE, &key->flags))",
                "\t\treturn -ENOKEY;",
                "\tp = key->payload.data[0];"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-8539",
        "func_name": "torvalds/linux/encrypted_update",
        "description": "The KEYS subsystem in the Linux kernel before 4.4 allows local users to gain privileges or cause a denial of service (BUG) via crafted keyctl commands that negatively instantiate a key, related to security/keys/encrypted-keys/encrypted.c, security/keys/trusted.c, and security/keys/user_defined.c.",
        "git_url": "https://github.com/torvalds/linux/commit/096fe9eaea40a17e125569f9e657e34cdb6d73bd",
        "commit_title": "KEYS: Fix handling of stored error in a negatively instantiated user key",
        "commit_text": " If a user key gets negatively instantiated, an error code is cached in the payload area.  A negatively instantiated key may be then be positively instantiated by updating it with valid data.  However, the ->update key type method must be aware that the error code may be there.  The following may be used to trigger the bug in the user key type:      keyctl request2 user user \"\" @u     keyctl add user user \"a\" @u  which manifests itself as:  \tBUG: unable to handle kernel paging request at 00000000ffffff8a \tIP: [<ffffffff810a376f>] __call_rcu.constprop.76+0x1f/0x280 kernel/rcu/tree.c:3046 \tPGD 7cc30067 PUD 0 \tOops: 0002 [#1] SMP \tModules linked in: \tCPU: 3 PID: 2644 Comm: a.out Not tainted 4.3.0+ #49 \tHardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS Bochs 01/01/2011 \ttask: ffff88003ddea700 ti: ffff88003dd88000 task.ti: ffff88003dd88000 \tRIP: 0010:[<ffffffff810a376f>]  [<ffffffff810a376f>] __call_rcu.constprop.76+0x1f/0x280 \t [<ffffffff810a376f>] __call_rcu.constprop.76+0x1f/0x280 kernel/rcu/tree.c:3046 \tRSP: 0018:ffff88003dd8bdb0  EFLAGS: 00010246 \tRAX: 00000000ffffff82 RBX: 0000000000000000 RCX: 0000000000000001 \tRDX: ffffffff81e3fe40 RSI: 0000000000000000 RDI: 00000000ffffff82 \tRBP: ffff88003dd8bde0 R08: ffff88007d2d2da0 R09: 0000000000000000 \tR10: 0000000000000000 R11: ffff88003e8073c0 R12: 00000000ffffff82 \tR13: ffff88003dd8be68 R14: ffff88007d027600 R15: ffff88003ddea700 \tFS:  0000000000b92880(0063) GS:ffff88007fd00000(0000) knlGS:0000000000000000 \tCS:  0010 DS: 0000 ES: 0000 CR0: 000000008005003b \tCR2: 00000000ffffff8a CR3: 000000007cc5f000 CR4: 00000000000006e0 \tStack: \t ffff88003dd8bdf0 ffffffff81160a8a 0000000000000000 00000000ffffff82 \t ffff88003dd8be68 ffff88007d027600 ffff88003dd8bdf0 ffffffff810a39e5 \t ffff88003dd8be20 ffffffff812a31ab ffff88007d027600 ffff88007d027620 \tCall Trace: \t [<ffffffff810a39e5>] kfree_call_rcu+0x15/0x20 kernel/rcu/tree.c:3136 \t [<ffffffff812a31ab>] user_update+0x8b/0xb0 security/keys/user_defined.c:129 \t [<     inline     >] __key_update security/keys/key.c:730 \t [<ffffffff8129e5c1>] key_create_or_update+0x291/0x440 security/keys/key.c:908 \t [<     inline     >] SYSC_add_key security/keys/keyctl.c:125 \t [<ffffffff8129fc21>] SyS_add_key+0x101/0x1e0 security/keys/keyctl.c:60 \t [<ffffffff8185f617>] entry_SYSCALL_64_fastpath+0x12/0x6a arch/x86/entry/entry_64.S:185  Note the error code (-ENOKEY) in EDX.  A similar bug can be tripped by:      keyctl request2 trusted user \"\" @u     keyctl add trusted user \"a\" @u  This should also affect encrypted keys - but that has to be correctly parameterised or it will fail with EINVAL before getting to the bit that will crashes. ",
        "func_before": "static int encrypted_update(struct key *key, struct key_preparsed_payload *prep)\n{\n\tstruct encrypted_key_payload *epayload = key->payload.data[0];\n\tstruct encrypted_key_payload *new_epayload;\n\tchar *buf;\n\tchar *new_master_desc = NULL;\n\tconst char *format = NULL;\n\tsize_t datalen = prep->datalen;\n\tint ret = 0;\n\n\tif (datalen <= 0 || datalen > 32767 || !prep->data)\n\t\treturn -EINVAL;\n\n\tbuf = kmalloc(datalen + 1, GFP_KERNEL);\n\tif (!buf)\n\t\treturn -ENOMEM;\n\n\tbuf[datalen] = 0;\n\tmemcpy(buf, prep->data, datalen);\n\tret = datablob_parse(buf, &format, &new_master_desc, NULL, NULL);\n\tif (ret < 0)\n\t\tgoto out;\n\n\tret = valid_master_desc(new_master_desc, epayload->master_desc);\n\tif (ret < 0)\n\t\tgoto out;\n\n\tnew_epayload = encrypted_key_alloc(key, epayload->format,\n\t\t\t\t\t   new_master_desc, epayload->datalen);\n\tif (IS_ERR(new_epayload)) {\n\t\tret = PTR_ERR(new_epayload);\n\t\tgoto out;\n\t}\n\n\t__ekey_init(new_epayload, epayload->format, new_master_desc,\n\t\t    epayload->datalen);\n\n\tmemcpy(new_epayload->iv, epayload->iv, ivsize);\n\tmemcpy(new_epayload->payload_data, epayload->payload_data,\n\t       epayload->payload_datalen);\n\n\trcu_assign_keypointer(key, new_epayload);\n\tcall_rcu(&epayload->rcu, encrypted_rcu_free);\nout:\n\tkfree(buf);\n\treturn ret;\n}",
        "func": "static int encrypted_update(struct key *key, struct key_preparsed_payload *prep)\n{\n\tstruct encrypted_key_payload *epayload = key->payload.data[0];\n\tstruct encrypted_key_payload *new_epayload;\n\tchar *buf;\n\tchar *new_master_desc = NULL;\n\tconst char *format = NULL;\n\tsize_t datalen = prep->datalen;\n\tint ret = 0;\n\n\tif (test_bit(KEY_FLAG_NEGATIVE, &key->flags))\n\t\treturn -ENOKEY;\n\tif (datalen <= 0 || datalen > 32767 || !prep->data)\n\t\treturn -EINVAL;\n\n\tbuf = kmalloc(datalen + 1, GFP_KERNEL);\n\tif (!buf)\n\t\treturn -ENOMEM;\n\n\tbuf[datalen] = 0;\n\tmemcpy(buf, prep->data, datalen);\n\tret = datablob_parse(buf, &format, &new_master_desc, NULL, NULL);\n\tif (ret < 0)\n\t\tgoto out;\n\n\tret = valid_master_desc(new_master_desc, epayload->master_desc);\n\tif (ret < 0)\n\t\tgoto out;\n\n\tnew_epayload = encrypted_key_alloc(key, epayload->format,\n\t\t\t\t\t   new_master_desc, epayload->datalen);\n\tif (IS_ERR(new_epayload)) {\n\t\tret = PTR_ERR(new_epayload);\n\t\tgoto out;\n\t}\n\n\t__ekey_init(new_epayload, epayload->format, new_master_desc,\n\t\t    epayload->datalen);\n\n\tmemcpy(new_epayload->iv, epayload->iv, ivsize);\n\tmemcpy(new_epayload->payload_data, epayload->payload_data,\n\t       epayload->payload_datalen);\n\n\trcu_assign_keypointer(key, new_epayload);\n\tcall_rcu(&epayload->rcu, encrypted_rcu_free);\nout:\n\tkfree(buf);\n\treturn ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -8,6 +8,8 @@\n \tsize_t datalen = prep->datalen;\n \tint ret = 0;\n \n+\tif (test_bit(KEY_FLAG_NEGATIVE, &key->flags))\n+\t\treturn -ENOKEY;\n \tif (datalen <= 0 || datalen > 32767 || !prep->data)\n \t\treturn -EINVAL;\n ",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tif (test_bit(KEY_FLAG_NEGATIVE, &key->flags))",
                "\t\treturn -ENOKEY;"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-8539",
        "func_name": "torvalds/linux/user_update",
        "description": "The KEYS subsystem in the Linux kernel before 4.4 allows local users to gain privileges or cause a denial of service (BUG) via crafted keyctl commands that negatively instantiate a key, related to security/keys/encrypted-keys/encrypted.c, security/keys/trusted.c, and security/keys/user_defined.c.",
        "git_url": "https://github.com/torvalds/linux/commit/096fe9eaea40a17e125569f9e657e34cdb6d73bd",
        "commit_title": "KEYS: Fix handling of stored error in a negatively instantiated user key",
        "commit_text": " If a user key gets negatively instantiated, an error code is cached in the payload area.  A negatively instantiated key may be then be positively instantiated by updating it with valid data.  However, the ->update key type method must be aware that the error code may be there.  The following may be used to trigger the bug in the user key type:      keyctl request2 user user \"\" @u     keyctl add user user \"a\" @u  which manifests itself as:  \tBUG: unable to handle kernel paging request at 00000000ffffff8a \tIP: [<ffffffff810a376f>] __call_rcu.constprop.76+0x1f/0x280 kernel/rcu/tree.c:3046 \tPGD 7cc30067 PUD 0 \tOops: 0002 [#1] SMP \tModules linked in: \tCPU: 3 PID: 2644 Comm: a.out Not tainted 4.3.0+ #49 \tHardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS Bochs 01/01/2011 \ttask: ffff88003ddea700 ti: ffff88003dd88000 task.ti: ffff88003dd88000 \tRIP: 0010:[<ffffffff810a376f>]  [<ffffffff810a376f>] __call_rcu.constprop.76+0x1f/0x280 \t [<ffffffff810a376f>] __call_rcu.constprop.76+0x1f/0x280 kernel/rcu/tree.c:3046 \tRSP: 0018:ffff88003dd8bdb0  EFLAGS: 00010246 \tRAX: 00000000ffffff82 RBX: 0000000000000000 RCX: 0000000000000001 \tRDX: ffffffff81e3fe40 RSI: 0000000000000000 RDI: 00000000ffffff82 \tRBP: ffff88003dd8bde0 R08: ffff88007d2d2da0 R09: 0000000000000000 \tR10: 0000000000000000 R11: ffff88003e8073c0 R12: 00000000ffffff82 \tR13: ffff88003dd8be68 R14: ffff88007d027600 R15: ffff88003ddea700 \tFS:  0000000000b92880(0063) GS:ffff88007fd00000(0000) knlGS:0000000000000000 \tCS:  0010 DS: 0000 ES: 0000 CR0: 000000008005003b \tCR2: 00000000ffffff8a CR3: 000000007cc5f000 CR4: 00000000000006e0 \tStack: \t ffff88003dd8bdf0 ffffffff81160a8a 0000000000000000 00000000ffffff82 \t ffff88003dd8be68 ffff88007d027600 ffff88003dd8bdf0 ffffffff810a39e5 \t ffff88003dd8be20 ffffffff812a31ab ffff88007d027600 ffff88007d027620 \tCall Trace: \t [<ffffffff810a39e5>] kfree_call_rcu+0x15/0x20 kernel/rcu/tree.c:3136 \t [<ffffffff812a31ab>] user_update+0x8b/0xb0 security/keys/user_defined.c:129 \t [<     inline     >] __key_update security/keys/key.c:730 \t [<ffffffff8129e5c1>] key_create_or_update+0x291/0x440 security/keys/key.c:908 \t [<     inline     >] SYSC_add_key security/keys/keyctl.c:125 \t [<ffffffff8129fc21>] SyS_add_key+0x101/0x1e0 security/keys/keyctl.c:60 \t [<ffffffff8185f617>] entry_SYSCALL_64_fastpath+0x12/0x6a arch/x86/entry/entry_64.S:185  Note the error code (-ENOKEY) in EDX.  A similar bug can be tripped by:      keyctl request2 trusted user \"\" @u     keyctl add trusted user \"a\" @u  This should also affect encrypted keys - but that has to be correctly parameterised or it will fail with EINVAL before getting to the bit that will crashes. ",
        "func_before": "int user_update(struct key *key, struct key_preparsed_payload *prep)\n{\n\tstruct user_key_payload *upayload, *zap;\n\tsize_t datalen = prep->datalen;\n\tint ret;\n\n\tret = -EINVAL;\n\tif (datalen <= 0 || datalen > 32767 || !prep->data)\n\t\tgoto error;\n\n\t/* construct a replacement payload */\n\tret = -ENOMEM;\n\tupayload = kmalloc(sizeof(*upayload) + datalen, GFP_KERNEL);\n\tif (!upayload)\n\t\tgoto error;\n\n\tupayload->datalen = datalen;\n\tmemcpy(upayload->data, prep->data, datalen);\n\n\t/* check the quota and attach the new data */\n\tzap = upayload;\n\n\tret = key_payload_reserve(key, datalen);\n\n\tif (ret == 0) {\n\t\t/* attach the new data, displacing the old */\n\t\tzap = key->payload.data[0];\n\t\trcu_assign_keypointer(key, upayload);\n\t\tkey->expiry = 0;\n\t}\n\n\tif (zap)\n\t\tkfree_rcu(zap, rcu);\n\nerror:\n\treturn ret;\n}",
        "func": "int user_update(struct key *key, struct key_preparsed_payload *prep)\n{\n\tstruct user_key_payload *upayload, *zap;\n\tsize_t datalen = prep->datalen;\n\tint ret;\n\n\tret = -EINVAL;\n\tif (datalen <= 0 || datalen > 32767 || !prep->data)\n\t\tgoto error;\n\n\t/* construct a replacement payload */\n\tret = -ENOMEM;\n\tupayload = kmalloc(sizeof(*upayload) + datalen, GFP_KERNEL);\n\tif (!upayload)\n\t\tgoto error;\n\n\tupayload->datalen = datalen;\n\tmemcpy(upayload->data, prep->data, datalen);\n\n\t/* check the quota and attach the new data */\n\tzap = upayload;\n\n\tret = key_payload_reserve(key, datalen);\n\n\tif (ret == 0) {\n\t\t/* attach the new data, displacing the old */\n\t\tif (!test_bit(KEY_FLAG_NEGATIVE, &key->flags))\n\t\t\tzap = key->payload.data[0];\n\t\telse\n\t\t\tzap = NULL;\n\t\trcu_assign_keypointer(key, upayload);\n\t\tkey->expiry = 0;\n\t}\n\n\tif (zap)\n\t\tkfree_rcu(zap, rcu);\n\nerror:\n\treturn ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -24,7 +24,10 @@\n \n \tif (ret == 0) {\n \t\t/* attach the new data, displacing the old */\n-\t\tzap = key->payload.data[0];\n+\t\tif (!test_bit(KEY_FLAG_NEGATIVE, &key->flags))\n+\t\t\tzap = key->payload.data[0];\n+\t\telse\n+\t\t\tzap = NULL;\n \t\trcu_assign_keypointer(key, upayload);\n \t\tkey->expiry = 0;\n \t}",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tzap = key->payload.data[0];"
            ],
            "added_lines": [
                "\t\tif (!test_bit(KEY_FLAG_NEGATIVE, &key->flags))",
                "\t\t\tzap = key->payload.data[0];",
                "\t\telse",
                "\t\t\tzap = NULL;"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-9090",
        "func_name": "torvalds/linux/trap_init",
        "description": "The do_double_fault function in arch/x86/kernel/traps.c in the Linux kernel through 3.17.4 does not properly handle faults associated with the Stack Segment (SS) segment register, which allows local users to cause a denial of service (panic) via a modify_ldt system call, as demonstrated by sigreturn_32 in the linux-clock-tests test suite.",
        "git_url": "https://github.com/torvalds/linux/commit/6f442be2fb22be02cafa606f1769fa1e6f894441",
        "commit_title": "x86_64, traps: Stop using IST for #SS",
        "commit_text": " On a 32-bit kernel, this has no effect, since there are no IST stacks.  On a 64-bit kernel, #SS can only happen in user code, on a failed iret to user space, a canonical violation on access via RSP or RBP, or a genuine stack segment violation in 32-bit kernel code.  The first two cases don't need IST, and the latter two cases are unlikely fatal bugs, and promoting them to double faults would be fine.  This fixes a bug in which the espfix64 code mishandles a stack segment violation.  This saves 4k of memory per CPU and a tiny bit of code.  Cc: stable@vger.kernel.org",
        "func_before": "void __init trap_init(void)\n{\n\tint i;\n\n#ifdef CONFIG_EISA\n\tvoid __iomem *p = early_ioremap(0x0FFFD9, 4);\n\n\tif (readl(p) == 'E' + ('I'<<8) + ('S'<<16) + ('A'<<24))\n\t\tEISA_bus = 1;\n\tearly_iounmap(p, 4);\n#endif\n\n\tset_intr_gate(X86_TRAP_DE, divide_error);\n\tset_intr_gate_ist(X86_TRAP_NMI, &nmi, NMI_STACK);\n\t/* int4 can be called from all */\n\tset_system_intr_gate(X86_TRAP_OF, &overflow);\n\tset_intr_gate(X86_TRAP_BR, bounds);\n\tset_intr_gate(X86_TRAP_UD, invalid_op);\n\tset_intr_gate(X86_TRAP_NM, device_not_available);\n#ifdef CONFIG_X86_32\n\tset_task_gate(X86_TRAP_DF, GDT_ENTRY_DOUBLEFAULT_TSS);\n#else\n\tset_intr_gate_ist(X86_TRAP_DF, &double_fault, DOUBLEFAULT_STACK);\n#endif\n\tset_intr_gate(X86_TRAP_OLD_MF, coprocessor_segment_overrun);\n\tset_intr_gate(X86_TRAP_TS, invalid_TSS);\n\tset_intr_gate(X86_TRAP_NP, segment_not_present);\n\tset_intr_gate_ist(X86_TRAP_SS, &stack_segment, STACKFAULT_STACK);\n\tset_intr_gate(X86_TRAP_GP, general_protection);\n\tset_intr_gate(X86_TRAP_SPURIOUS, spurious_interrupt_bug);\n\tset_intr_gate(X86_TRAP_MF, coprocessor_error);\n\tset_intr_gate(X86_TRAP_AC, alignment_check);\n#ifdef CONFIG_X86_MCE\n\tset_intr_gate_ist(X86_TRAP_MC, &machine_check, MCE_STACK);\n#endif\n\tset_intr_gate(X86_TRAP_XF, simd_coprocessor_error);\n\n\t/* Reserve all the builtin and the syscall vector: */\n\tfor (i = 0; i < FIRST_EXTERNAL_VECTOR; i++)\n\t\tset_bit(i, used_vectors);\n\n#ifdef CONFIG_IA32_EMULATION\n\tset_system_intr_gate(IA32_SYSCALL_VECTOR, ia32_syscall);\n\tset_bit(IA32_SYSCALL_VECTOR, used_vectors);\n#endif\n\n#ifdef CONFIG_X86_32\n\tset_system_trap_gate(SYSCALL_VECTOR, &system_call);\n\tset_bit(SYSCALL_VECTOR, used_vectors);\n#endif\n\n\t/*\n\t * Set the IDT descriptor to a fixed read-only location, so that the\n\t * \"sidt\" instruction will not leak the location of the kernel, and\n\t * to defend the IDT against arbitrary memory write vulnerabilities.\n\t * It will be reloaded in cpu_init() */\n\t__set_fixmap(FIX_RO_IDT, __pa_symbol(idt_table), PAGE_KERNEL_RO);\n\tidt_descr.address = fix_to_virt(FIX_RO_IDT);\n\n\t/*\n\t * Should be a barrier for any external CPU state:\n\t */\n\tcpu_init();\n\n\tx86_init.irqs.trap_init();\n\n#ifdef CONFIG_X86_64\n\tmemcpy(&debug_idt_table, &idt_table, IDT_ENTRIES * 16);\n\tset_nmi_gate(X86_TRAP_DB, &debug);\n\tset_nmi_gate(X86_TRAP_BP, &int3);\n#endif\n}",
        "func": "void __init trap_init(void)\n{\n\tint i;\n\n#ifdef CONFIG_EISA\n\tvoid __iomem *p = early_ioremap(0x0FFFD9, 4);\n\n\tif (readl(p) == 'E' + ('I'<<8) + ('S'<<16) + ('A'<<24))\n\t\tEISA_bus = 1;\n\tearly_iounmap(p, 4);\n#endif\n\n\tset_intr_gate(X86_TRAP_DE, divide_error);\n\tset_intr_gate_ist(X86_TRAP_NMI, &nmi, NMI_STACK);\n\t/* int4 can be called from all */\n\tset_system_intr_gate(X86_TRAP_OF, &overflow);\n\tset_intr_gate(X86_TRAP_BR, bounds);\n\tset_intr_gate(X86_TRAP_UD, invalid_op);\n\tset_intr_gate(X86_TRAP_NM, device_not_available);\n#ifdef CONFIG_X86_32\n\tset_task_gate(X86_TRAP_DF, GDT_ENTRY_DOUBLEFAULT_TSS);\n#else\n\tset_intr_gate_ist(X86_TRAP_DF, &double_fault, DOUBLEFAULT_STACK);\n#endif\n\tset_intr_gate(X86_TRAP_OLD_MF, coprocessor_segment_overrun);\n\tset_intr_gate(X86_TRAP_TS, invalid_TSS);\n\tset_intr_gate(X86_TRAP_NP, segment_not_present);\n\tset_intr_gate(X86_TRAP_SS, stack_segment);\n\tset_intr_gate(X86_TRAP_GP, general_protection);\n\tset_intr_gate(X86_TRAP_SPURIOUS, spurious_interrupt_bug);\n\tset_intr_gate(X86_TRAP_MF, coprocessor_error);\n\tset_intr_gate(X86_TRAP_AC, alignment_check);\n#ifdef CONFIG_X86_MCE\n\tset_intr_gate_ist(X86_TRAP_MC, &machine_check, MCE_STACK);\n#endif\n\tset_intr_gate(X86_TRAP_XF, simd_coprocessor_error);\n\n\t/* Reserve all the builtin and the syscall vector: */\n\tfor (i = 0; i < FIRST_EXTERNAL_VECTOR; i++)\n\t\tset_bit(i, used_vectors);\n\n#ifdef CONFIG_IA32_EMULATION\n\tset_system_intr_gate(IA32_SYSCALL_VECTOR, ia32_syscall);\n\tset_bit(IA32_SYSCALL_VECTOR, used_vectors);\n#endif\n\n#ifdef CONFIG_X86_32\n\tset_system_trap_gate(SYSCALL_VECTOR, &system_call);\n\tset_bit(SYSCALL_VECTOR, used_vectors);\n#endif\n\n\t/*\n\t * Set the IDT descriptor to a fixed read-only location, so that the\n\t * \"sidt\" instruction will not leak the location of the kernel, and\n\t * to defend the IDT against arbitrary memory write vulnerabilities.\n\t * It will be reloaded in cpu_init() */\n\t__set_fixmap(FIX_RO_IDT, __pa_symbol(idt_table), PAGE_KERNEL_RO);\n\tidt_descr.address = fix_to_virt(FIX_RO_IDT);\n\n\t/*\n\t * Should be a barrier for any external CPU state:\n\t */\n\tcpu_init();\n\n\tx86_init.irqs.trap_init();\n\n#ifdef CONFIG_X86_64\n\tmemcpy(&debug_idt_table, &idt_table, IDT_ENTRIES * 16);\n\tset_nmi_gate(X86_TRAP_DB, &debug);\n\tset_nmi_gate(X86_TRAP_BP, &int3);\n#endif\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -25,7 +25,7 @@\n \tset_intr_gate(X86_TRAP_OLD_MF, coprocessor_segment_overrun);\n \tset_intr_gate(X86_TRAP_TS, invalid_TSS);\n \tset_intr_gate(X86_TRAP_NP, segment_not_present);\n-\tset_intr_gate_ist(X86_TRAP_SS, &stack_segment, STACKFAULT_STACK);\n+\tset_intr_gate(X86_TRAP_SS, stack_segment);\n \tset_intr_gate(X86_TRAP_GP, general_protection);\n \tset_intr_gate(X86_TRAP_SPURIOUS, spurious_interrupt_bug);\n \tset_intr_gate(X86_TRAP_MF, coprocessor_error);",
        "diff_line_info": {
            "deleted_lines": [
                "\tset_intr_gate_ist(X86_TRAP_SS, &stack_segment, STACKFAULT_STACK);"
            ],
            "added_lines": [
                "\tset_intr_gate(X86_TRAP_SS, stack_segment);"
            ]
        }
    },
    {
        "cve_id": "CVE-2010-4347",
        "func_name": "torvalds/linux/acpi_debugfs_init",
        "description": "The ACPI subsystem in the Linux kernel before 2.6.36.2 uses 0222 permissions for the debugfs custom_method file, which allows local users to gain privileges by placing a custom ACPI method in the ACPI interpreter tables, related to the acpi_debugfs_init function in drivers/acpi/debugfs.c.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=ed3aada1bf34c5a9e98af167f125f8a740fc726a",
        "commit_title": "Currently we have:",
        "commit_text": "   --w--w--w-. 1 root root 0 2010-11-11 14:56 /sys/kernel/debug/acpi/custom_method  which is just crazy. Change this to --w-------.  Cc: stable@kernel.org (for 2.6.36) ",
        "func_before": "int __init acpi_debugfs_init(void)\n{\n\tstruct dentry *acpi_dir, *cm_dentry;\n\n\tacpi_dir = debugfs_create_dir(\"acpi\", NULL);\n\tif (!acpi_dir)\n\t\tgoto err;\n\n\tcm_dentry = debugfs_create_file(\"custom_method\", S_IWUGO,\n\t\t\t\t\tacpi_dir, NULL, &cm_fops);\n\tif (!cm_dentry)\n\t\tgoto err;\n\n\treturn 0;\n\nerr:\n\tif (acpi_dir)\n\t\tdebugfs_remove(acpi_dir);\n\treturn -EINVAL;\n}",
        "func": "int __init acpi_debugfs_init(void)\n{\n\tstruct dentry *acpi_dir, *cm_dentry;\n\n\tacpi_dir = debugfs_create_dir(\"acpi\", NULL);\n\tif (!acpi_dir)\n\t\tgoto err;\n\n\tcm_dentry = debugfs_create_file(\"custom_method\", S_IWUSR,\n\t\t\t\t\tacpi_dir, NULL, &cm_fops);\n\tif (!cm_dentry)\n\t\tgoto err;\n\n\treturn 0;\n\nerr:\n\tif (acpi_dir)\n\t\tdebugfs_remove(acpi_dir);\n\treturn -EINVAL;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -6,7 +6,7 @@\n \tif (!acpi_dir)\n \t\tgoto err;\n \n-\tcm_dentry = debugfs_create_file(\"custom_method\", S_IWUGO,\n+\tcm_dentry = debugfs_create_file(\"custom_method\", S_IWUSR,\n \t\t\t\t\tacpi_dir, NULL, &cm_fops);\n \tif (!cm_dentry)\n \t\tgoto err;",
        "diff_line_info": {
            "deleted_lines": [
                "\tcm_dentry = debugfs_create_file(\"custom_method\", S_IWUGO,"
            ],
            "added_lines": [
                "\tcm_dentry = debugfs_create_file(\"custom_method\", S_IWUSR,"
            ]
        }
    },
    {
        "cve_id": "CVE-2010-4258",
        "func_name": "torvalds/linux/do_exit",
        "description": "The do_exit function in kernel/exit.c in the Linux kernel before 2.6.36.2 does not properly handle a KERNEL_DS get_fs value, which allows local users to bypass intended access_ok restrictions, overwrite arbitrary kernel memory locations, and gain privileges by leveraging a (1) BUG, (2) NULL pointer dereference, or (3) page fault, as demonstrated by vectors involving the clear_child_tid feature and the splice system call.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=33dd94ae1ccbfb7bf0fb6c692bc3d1c4269e6177",
        "commit_title": "If a user manages to trigger an oops with fs set to KERNEL_DS, fs is not",
        "commit_text": "otherwise reset before do_exit().  do_exit may later (via mm_release in fork.c) do a put_user to a user-controlled address, potentially allowing a user to leverage an oops into a controlled write into kernel memory.  This is only triggerable in the presence of another bug, but this potentially turns a lot of DoS bugs into privilege escalations, so it's worth fixing.  I have proof-of-concept code which uses this bug along with CVE-2010-3849 to write a zero to an arbitrary kernel address, so I've tested that this is not theoretical.  A more logical place to put this fix might be when we know an oops has occurred, before we call do_exit(), but that would involve changing every architecture, in multiple places.  Let's just stick it in do_exit instead.  [akpm@linux-foundation.org: update code comment] Cc: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com> Cc: <stable@kernel.org> ",
        "func_before": "NORET_TYPE void do_exit(long code)\n{\n\tstruct task_struct *tsk = current;\n\tint group_dead;\n\n\tprofile_task_exit(tsk);\n\n\tWARN_ON(atomic_read(&tsk->fs_excl));\n\n\tif (unlikely(in_interrupt()))\n\t\tpanic(\"Aiee, killing interrupt handler!\");\n\tif (unlikely(!tsk->pid))\n\t\tpanic(\"Attempted to kill the idle task!\");\n\n\ttracehook_report_exit(&code);\n\n\tvalidate_creds_for_do_exit(tsk);\n\n\t/*\n\t * We're taking recursive faults here in do_exit. Safest is to just\n\t * leave this task alone and wait for reboot.\n\t */\n\tif (unlikely(tsk->flags & PF_EXITING)) {\n\t\tprintk(KERN_ALERT\n\t\t\t\"Fixing recursive fault but reboot is needed!\\n\");\n\t\t/*\n\t\t * We can do this unlocked here. The futex code uses\n\t\t * this flag just to verify whether the pi state\n\t\t * cleanup has been done or not. In the worst case it\n\t\t * loops once more. We pretend that the cleanup was\n\t\t * done as there is no way to return. Either the\n\t\t * OWNER_DIED bit is set by now or we push the blocked\n\t\t * task into the wait for ever nirwana as well.\n\t\t */\n\t\ttsk->flags |= PF_EXITPIDONE;\n\t\tset_current_state(TASK_UNINTERRUPTIBLE);\n\t\tschedule();\n\t}\n\n\texit_irq_thread();\n\n\texit_signals(tsk);  /* sets PF_EXITING */\n\t/*\n\t * tsk->flags are checked in the futex code to protect against\n\t * an exiting task cleaning up the robust pi futexes.\n\t */\n\tsmp_mb();\n\traw_spin_unlock_wait(&tsk->pi_lock);\n\n\tif (unlikely(in_atomic()))\n\t\tprintk(KERN_INFO \"note: %s[%d] exited with preempt_count %d\\n\",\n\t\t\t\tcurrent->comm, task_pid_nr(current),\n\t\t\t\tpreempt_count());\n\n\tacct_update_integrals(tsk);\n\t/* sync mm's RSS info before statistics gathering */\n\tif (tsk->mm)\n\t\tsync_mm_rss(tsk, tsk->mm);\n\tgroup_dead = atomic_dec_and_test(&tsk->signal->live);\n\tif (group_dead) {\n\t\thrtimer_cancel(&tsk->signal->real_timer);\n\t\texit_itimers(tsk->signal);\n\t\tif (tsk->mm)\n\t\t\tsetmax_mm_hiwater_rss(&tsk->signal->maxrss, tsk->mm);\n\t}\n\tacct_collect(code, group_dead);\n\tif (group_dead)\n\t\ttty_audit_exit();\n\tif (unlikely(tsk->audit_context))\n\t\taudit_free(tsk);\n\n\ttsk->exit_code = code;\n\ttaskstats_exit(tsk, group_dead);\n\n\texit_mm(tsk);\n\n\tif (group_dead)\n\t\tacct_process();\n\ttrace_sched_process_exit(tsk);\n\n\texit_sem(tsk);\n\texit_files(tsk);\n\texit_fs(tsk);\n\tcheck_stack_usage();\n\texit_thread();\n\tcgroup_exit(tsk, 1);\n\n\tif (group_dead)\n\t\tdisassociate_ctty(1);\n\n\tmodule_put(task_thread_info(tsk)->exec_domain->module);\n\n\tproc_exit_connector(tsk);\n\n\t/*\n\t * FIXME: do that only when needed, using sched_exit tracepoint\n\t */\n\tflush_ptrace_hw_breakpoint(tsk);\n\t/*\n\t * Flush inherited counters to the parent - before the parent\n\t * gets woken up by child-exit notifications.\n\t */\n\tperf_event_exit_task(tsk);\n\n\texit_notify(tsk, group_dead);\n#ifdef CONFIG_NUMA\n\ttask_lock(tsk);\n\tmpol_put(tsk->mempolicy);\n\ttsk->mempolicy = NULL;\n\ttask_unlock(tsk);\n#endif\n#ifdef CONFIG_FUTEX\n\tif (unlikely(current->pi_state_cache))\n\t\tkfree(current->pi_state_cache);\n#endif\n\t/*\n\t * Make sure we are holding no locks:\n\t */\n\tdebug_check_no_locks_held(tsk);\n\t/*\n\t * We can do this unlocked here. The futex code uses this flag\n\t * just to verify whether the pi state cleanup has been done\n\t * or not. In the worst case it loops once more.\n\t */\n\ttsk->flags |= PF_EXITPIDONE;\n\n\tif (tsk->io_context)\n\t\texit_io_context(tsk);\n\n\tif (tsk->splice_pipe)\n\t\t__free_pipe_info(tsk->splice_pipe);\n\n\tvalidate_creds_for_do_exit(tsk);\n\n\tpreempt_disable();\n\texit_rcu();\n\t/* causes final put_task_struct in finish_task_switch(). */\n\ttsk->state = TASK_DEAD;\n\tschedule();\n\tBUG();\n\t/* Avoid \"noreturn function does return\".  */\n\tfor (;;)\n\t\tcpu_relax();\t/* For when BUG is null */\n}",
        "func": "NORET_TYPE void do_exit(long code)\n{\n\tstruct task_struct *tsk = current;\n\tint group_dead;\n\n\tprofile_task_exit(tsk);\n\n\tWARN_ON(atomic_read(&tsk->fs_excl));\n\n\tif (unlikely(in_interrupt()))\n\t\tpanic(\"Aiee, killing interrupt handler!\");\n\tif (unlikely(!tsk->pid))\n\t\tpanic(\"Attempted to kill the idle task!\");\n\n\t/*\n\t * If do_exit is called because this processes oopsed, it's possible\n\t * that get_fs() was left as KERNEL_DS, so reset it to USER_DS before\n\t * continuing. Amongst other possible reasons, this is to prevent\n\t * mm_release()->clear_child_tid() from writing to a user-controlled\n\t * kernel address.\n\t */\n\tset_fs(USER_DS);\n\n\ttracehook_report_exit(&code);\n\n\tvalidate_creds_for_do_exit(tsk);\n\n\t/*\n\t * We're taking recursive faults here in do_exit. Safest is to just\n\t * leave this task alone and wait for reboot.\n\t */\n\tif (unlikely(tsk->flags & PF_EXITING)) {\n\t\tprintk(KERN_ALERT\n\t\t\t\"Fixing recursive fault but reboot is needed!\\n\");\n\t\t/*\n\t\t * We can do this unlocked here. The futex code uses\n\t\t * this flag just to verify whether the pi state\n\t\t * cleanup has been done or not. In the worst case it\n\t\t * loops once more. We pretend that the cleanup was\n\t\t * done as there is no way to return. Either the\n\t\t * OWNER_DIED bit is set by now or we push the blocked\n\t\t * task into the wait for ever nirwana as well.\n\t\t */\n\t\ttsk->flags |= PF_EXITPIDONE;\n\t\tset_current_state(TASK_UNINTERRUPTIBLE);\n\t\tschedule();\n\t}\n\n\texit_irq_thread();\n\n\texit_signals(tsk);  /* sets PF_EXITING */\n\t/*\n\t * tsk->flags are checked in the futex code to protect against\n\t * an exiting task cleaning up the robust pi futexes.\n\t */\n\tsmp_mb();\n\traw_spin_unlock_wait(&tsk->pi_lock);\n\n\tif (unlikely(in_atomic()))\n\t\tprintk(KERN_INFO \"note: %s[%d] exited with preempt_count %d\\n\",\n\t\t\t\tcurrent->comm, task_pid_nr(current),\n\t\t\t\tpreempt_count());\n\n\tacct_update_integrals(tsk);\n\t/* sync mm's RSS info before statistics gathering */\n\tif (tsk->mm)\n\t\tsync_mm_rss(tsk, tsk->mm);\n\tgroup_dead = atomic_dec_and_test(&tsk->signal->live);\n\tif (group_dead) {\n\t\thrtimer_cancel(&tsk->signal->real_timer);\n\t\texit_itimers(tsk->signal);\n\t\tif (tsk->mm)\n\t\t\tsetmax_mm_hiwater_rss(&tsk->signal->maxrss, tsk->mm);\n\t}\n\tacct_collect(code, group_dead);\n\tif (group_dead)\n\t\ttty_audit_exit();\n\tif (unlikely(tsk->audit_context))\n\t\taudit_free(tsk);\n\n\ttsk->exit_code = code;\n\ttaskstats_exit(tsk, group_dead);\n\n\texit_mm(tsk);\n\n\tif (group_dead)\n\t\tacct_process();\n\ttrace_sched_process_exit(tsk);\n\n\texit_sem(tsk);\n\texit_files(tsk);\n\texit_fs(tsk);\n\tcheck_stack_usage();\n\texit_thread();\n\tcgroup_exit(tsk, 1);\n\n\tif (group_dead)\n\t\tdisassociate_ctty(1);\n\n\tmodule_put(task_thread_info(tsk)->exec_domain->module);\n\n\tproc_exit_connector(tsk);\n\n\t/*\n\t * FIXME: do that only when needed, using sched_exit tracepoint\n\t */\n\tflush_ptrace_hw_breakpoint(tsk);\n\t/*\n\t * Flush inherited counters to the parent - before the parent\n\t * gets woken up by child-exit notifications.\n\t */\n\tperf_event_exit_task(tsk);\n\n\texit_notify(tsk, group_dead);\n#ifdef CONFIG_NUMA\n\ttask_lock(tsk);\n\tmpol_put(tsk->mempolicy);\n\ttsk->mempolicy = NULL;\n\ttask_unlock(tsk);\n#endif\n#ifdef CONFIG_FUTEX\n\tif (unlikely(current->pi_state_cache))\n\t\tkfree(current->pi_state_cache);\n#endif\n\t/*\n\t * Make sure we are holding no locks:\n\t */\n\tdebug_check_no_locks_held(tsk);\n\t/*\n\t * We can do this unlocked here. The futex code uses this flag\n\t * just to verify whether the pi state cleanup has been done\n\t * or not. In the worst case it loops once more.\n\t */\n\ttsk->flags |= PF_EXITPIDONE;\n\n\tif (tsk->io_context)\n\t\texit_io_context(tsk);\n\n\tif (tsk->splice_pipe)\n\t\t__free_pipe_info(tsk->splice_pipe);\n\n\tvalidate_creds_for_do_exit(tsk);\n\n\tpreempt_disable();\n\texit_rcu();\n\t/* causes final put_task_struct in finish_task_switch(). */\n\ttsk->state = TASK_DEAD;\n\tschedule();\n\tBUG();\n\t/* Avoid \"noreturn function does return\".  */\n\tfor (;;)\n\t\tcpu_relax();\t/* For when BUG is null */\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -11,6 +11,15 @@\n \t\tpanic(\"Aiee, killing interrupt handler!\");\n \tif (unlikely(!tsk->pid))\n \t\tpanic(\"Attempted to kill the idle task!\");\n+\n+\t/*\n+\t * If do_exit is called because this processes oopsed, it's possible\n+\t * that get_fs() was left as KERNEL_DS, so reset it to USER_DS before\n+\t * continuing. Amongst other possible reasons, this is to prevent\n+\t * mm_release()->clear_child_tid() from writing to a user-controlled\n+\t * kernel address.\n+\t */\n+\tset_fs(USER_DS);\n \n \ttracehook_report_exit(&code);\n ",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "\t/*",
                "\t * If do_exit is called because this processes oopsed, it's possible",
                "\t * that get_fs() was left as KERNEL_DS, so reset it to USER_DS before",
                "\t * continuing. Amongst other possible reasons, this is to prevent",
                "\t * mm_release()->clear_child_tid() from writing to a user-controlled",
                "\t * kernel address.",
                "\t */",
                "\tset_fs(USER_DS);"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-5207",
        "func_name": "netblue30/firejail/bandwidth_pid",
        "description": "Firejail before 0.9.44.4, when running a bandwidth command, allows local users to gain root privileges via the --shell argument.",
        "git_url": "https://github.com/netblue30/firejail/commit/5d43fdcd215203868d440ffc42036f5f5ffc89fc",
        "commit_title": "security fix",
        "commit_text": "",
        "func_before": "void bandwidth_pid(pid_t pid, const char *command, const char *dev, int down, int up) {\n\tEUID_ASSERT();\n\t//************************\n\t// verify sandbox\n\t//************************\n\tEUID_ROOT();\n\tchar *comm = pid_proc_comm(pid);\n\tEUID_USER();\n\tif (!comm) {\n\t\tfprintf(stderr, \"Error: cannot find sandbox\\n\");\n\t\texit(1);\n\t}\n\n\t// check for firejail sandbox\n\tif (strcmp(comm, \"firejail\") != 0) {\n\t\tfprintf(stderr, \"Error: cannot find sandbox\\n\");\n\t\texit(1);\n\t}\n\tfree(comm);\n\t\n\t// check network namespace\n\tchar *name;\n\tif (asprintf(&name, \"/run/firejail/network/%d-netmap\", pid) == -1)\n\t\terrExit(\"asprintf\");\n\tstruct stat s;\n\tif (stat(name, &s) == -1) {\n\t\tfprintf(stderr, \"Error: the sandbox doesn't use a new network namespace\\n\");\n\t\texit(1);\n\t}\n\n\t//************************\n\t// join the network namespace\n\t//************************\n\tpid_t child;\n\tif (find_child(pid, &child) == -1) {\n\t\tfprintf(stderr, \"Error: cannot join the network namespace\\n\");\n\t\texit(1);\n\t}\n\n\tEUID_ROOT();\n\tif (join_namespace(child, \"net\")) {\n\t\tfprintf(stderr, \"Error: cannot join the network namespace\\n\");\n\t\texit(1);\n\t}\n\n\t// set run file\n\tif (strcmp(command, \"set\") == 0)\n\t\tbandwidth_set(pid, dev, down, up);\n\telse if (strcmp(command, \"clear\") == 0)\n\t\tbandwidth_remove(pid, dev);\n\n\t//************************\n\t// build command\n\t//************************\n\tchar *devname = NULL;\n\tif (dev) {\n\t\t// read network map file\n\t\tchar *fname;\n\t\tif (asprintf(&fname, \"%s/%d-netmap\", RUN_FIREJAIL_NETWORK_DIR, (int) pid) == -1)\n\t\t\terrExit(\"asprintf\");\n\t\tFILE *fp = fopen(fname, \"r\");\n\t\tif (!fp) {\n\t\t\tfprintf(stderr, \"Error: cannot read network map file %s\\n\", fname);\n\t\t\texit(1);\n\t\t}\n\t\t\n\t\tchar buf[1024];\n\t\tint len = strlen(dev);\n\t\twhile (fgets(buf, 1024, fp)) {\n\t\t\t// remove '\\n'\n\t\t\tchar *ptr = strchr(buf, '\\n');\n\t\t\tif (ptr)\n\t\t\t\t*ptr = '\\0';\n\t\t\tif (*buf == '\\0')\n\t\t\t\tbreak;\n\n\t\t\tif (strncmp(buf, dev, len) == 0  && buf[len] == ':') {\n\t\t\t\tdevname = strdup(buf + len + 1);\n\t\t\t\tif (!devname)\n\t\t\t\t\terrExit(\"strdup\");\n\t\t\t\t// check device in namespace\n\t\t\t\tif (if_nametoindex(devname) == 0) {\n\t\t\t\t\tfprintf(stderr, \"Error: cannot find network device %s\\n\", devname);\n\t\t\t\t\texit(1);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tfree(fname);\n\t\tfclose(fp);\n\t}\n\t\n\t// build fshaper.sh command\n\tchar *cmd = NULL;\n\tif (devname) {\n\t\tif (strcmp(command, \"set\") == 0) {\n\t\t\tif (asprintf(&cmd, \"%s/firejail/fshaper.sh --%s %s %d %d\",\n\t\t\t\tLIBDIR, command, devname, down, up) == -1)\n\t\t\t\terrExit(\"asprintf\");\n\t\t}\n\t\telse {\n\t\t\tif (asprintf(&cmd, \"%s/firejail/fshaper.sh --%s %s\",\n\t\t\t\tLIBDIR, command, devname) == -1)\n\t\t\t\terrExit(\"asprintf\");\n\t\t}\n\t}\n\telse {\n\t\tif (asprintf(&cmd, \"%s/firejail/fshaper.sh --%s\", LIBDIR, command) == -1)\n\t\t\terrExit(\"asprintf\");\n\t}\n\tassert(cmd);\n\n\t// wipe out environment variables\n\tenviron = NULL;\n\n\t//************************\n\t// build command\n\t//************************\n\t// elevate privileges\n\tif (setreuid(0, 0))\n\t\terrExit(\"setreuid\");\n\tif (setregid(0, 0))\n\t\terrExit(\"setregid\");\n\n\tif (!cfg.shell)\n\t\tcfg.shell = guess_shell();\n\tif (!cfg.shell) {\n\t\tfprintf(stderr, \"Error: no POSIX shell found, please use --shell command line option\\n\");\n\t\texit(1);\n\t}\n\n\tchar *arg[4];\n\targ[0] = cfg.shell;\n\targ[1] = \"-c\";\n\targ[2] = cmd;\n\targ[3] = NULL;\n\tclearenv();\n\texecvp(arg[0], arg);\n\t\n\t// it will never get here\n\terrExit(\"execvp\");\n}",
        "func": "void bandwidth_pid(pid_t pid, const char *command, const char *dev, int down, int up) {\n\tEUID_ASSERT();\n\t//************************\n\t// verify sandbox\n\t//************************\n\tEUID_ROOT();\n\tchar *comm = pid_proc_comm(pid);\n\tEUID_USER();\n\tif (!comm) {\n\t\tfprintf(stderr, \"Error: cannot find sandbox\\n\");\n\t\texit(1);\n\t}\n\n\t// check for firejail sandbox\n\tif (strcmp(comm, \"firejail\") != 0) {\n\t\tfprintf(stderr, \"Error: cannot find sandbox\\n\");\n\t\texit(1);\n\t}\n\tfree(comm);\n\t\n\t// check network namespace\n\tchar *name;\n\tif (asprintf(&name, \"/run/firejail/network/%d-netmap\", pid) == -1)\n\t\terrExit(\"asprintf\");\n\tstruct stat s;\n\tif (stat(name, &s) == -1) {\n\t\tfprintf(stderr, \"Error: the sandbox doesn't use a new network namespace\\n\");\n\t\texit(1);\n\t}\n\n\t//************************\n\t// join the network namespace\n\t//************************\n\tpid_t child;\n\tif (find_child(pid, &child) == -1) {\n\t\tfprintf(stderr, \"Error: cannot join the network namespace\\n\");\n\t\texit(1);\n\t}\n\n\tEUID_ROOT();\n\tif (join_namespace(child, \"net\")) {\n\t\tfprintf(stderr, \"Error: cannot join the network namespace\\n\");\n\t\texit(1);\n\t}\n\n\t// set run file\n\tif (strcmp(command, \"set\") == 0)\n\t\tbandwidth_set(pid, dev, down, up);\n\telse if (strcmp(command, \"clear\") == 0)\n\t\tbandwidth_remove(pid, dev);\n\n\t//************************\n\t// build command\n\t//************************\n\tchar *devname = NULL;\n\tif (dev) {\n\t\t// read network map file\n\t\tchar *fname;\n\t\tif (asprintf(&fname, \"%s/%d-netmap\", RUN_FIREJAIL_NETWORK_DIR, (int) pid) == -1)\n\t\t\terrExit(\"asprintf\");\n\t\tFILE *fp = fopen(fname, \"r\");\n\t\tif (!fp) {\n\t\t\tfprintf(stderr, \"Error: cannot read network map file %s\\n\", fname);\n\t\t\texit(1);\n\t\t}\n\t\t\n\t\tchar buf[1024];\n\t\tint len = strlen(dev);\n\t\twhile (fgets(buf, 1024, fp)) {\n\t\t\t// remove '\\n'\n\t\t\tchar *ptr = strchr(buf, '\\n');\n\t\t\tif (ptr)\n\t\t\t\t*ptr = '\\0';\n\t\t\tif (*buf == '\\0')\n\t\t\t\tbreak;\n\n\t\t\tif (strncmp(buf, dev, len) == 0  && buf[len] == ':') {\n\t\t\t\tdevname = strdup(buf + len + 1);\n\t\t\t\tif (!devname)\n\t\t\t\t\terrExit(\"strdup\");\n\t\t\t\t// check device in namespace\n\t\t\t\tif (if_nametoindex(devname) == 0) {\n\t\t\t\t\tfprintf(stderr, \"Error: cannot find network device %s\\n\", devname);\n\t\t\t\t\texit(1);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tfree(fname);\n\t\tfclose(fp);\n\t}\n\t\n\t// build fshaper.sh command\n\tchar *cmd = NULL;\n\tif (devname) {\n\t\tif (strcmp(command, \"set\") == 0) {\n\t\t\tif (asprintf(&cmd, \"%s/firejail/fshaper.sh --%s %s %d %d\",\n\t\t\t\tLIBDIR, command, devname, down, up) == -1)\n\t\t\t\terrExit(\"asprintf\");\n\t\t}\n\t\telse {\n\t\t\tif (asprintf(&cmd, \"%s/firejail/fshaper.sh --%s %s\",\n\t\t\t\tLIBDIR, command, devname) == -1)\n\t\t\t\terrExit(\"asprintf\");\n\t\t}\n\t}\n\telse {\n\t\tif (asprintf(&cmd, \"%s/firejail/fshaper.sh --%s\", LIBDIR, command) == -1)\n\t\t\terrExit(\"asprintf\");\n\t}\n\tassert(cmd);\n\n\t// wipe out environment variables\n\tenviron = NULL;\n\n\t//************************\n\t// build command\n\t//************************\n\t// elevate privileges\n\tif (setreuid(0, 0))\n\t\terrExit(\"setreuid\");\n\tif (setregid(0, 0))\n\t\terrExit(\"setregid\");\n\n\tchar *arg[4];\n\targ[0] = \"/bin/sh\";\n\targ[1] = \"-c\";\n\targ[2] = cmd;\n\targ[3] = NULL;\n\tclearenv();\n\texecvp(arg[0], arg);\n\t\n\t// it will never get here\n\terrExit(\"execvp\");\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -122,15 +122,8 @@\n \tif (setregid(0, 0))\n \t\terrExit(\"setregid\");\n \n-\tif (!cfg.shell)\n-\t\tcfg.shell = guess_shell();\n-\tif (!cfg.shell) {\n-\t\tfprintf(stderr, \"Error: no POSIX shell found, please use --shell command line option\\n\");\n-\t\texit(1);\n-\t}\n-\n \tchar *arg[4];\n-\targ[0] = cfg.shell;\n+\targ[0] = \"/bin/sh\";\n \targ[1] = \"-c\";\n \targ[2] = cmd;\n \targ[3] = NULL;",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (!cfg.shell)",
                "\t\tcfg.shell = guess_shell();",
                "\tif (!cfg.shell) {",
                "\t\tfprintf(stderr, \"Error: no POSIX shell found, please use --shell command line option\\n\");",
                "\t\texit(1);",
                "\t}",
                "",
                "\targ[0] = cfg.shell;"
            ],
            "added_lines": [
                "\targ[0] = \"/bin/sh\";"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-2016",
        "func_name": "qemu/virtio_config_readb",
        "description": "A flaw was found in the way qemu v1.3.0 and later (virtio-rng) validates addresses when guest accesses the config space of a virtio device. If the virtio device has zero/small sized config space, such as virtio-rng, a privileged guest user could use this flaw to access the matching host's qemu address space and thus increase their privileges on the host.",
        "git_url": "https://github.com/qemu/qemu/commit/5f5a1318653c08e435cfa52f60b6a712815b659d",
        "commit_title": "virtio: properly validate address before accessing config",
        "commit_text": " There are several several issues in the current checking:  - The check was based on the minus of unsigned values which can overflow - It was done after .{set|get}_config() which can lead crash when config_len   is zero since vdev->config is NULL  Fix this by:  - Validate the address in virtio_pci_config_{read|write}() before   .{set|get}_config - Use addition instead minus to do the validation  Cc: Michael S. Tsirkin <mst@redhat.com> Cc: Petr Matousek <pmatouse@redhat.com>",
        "func_before": "uint32_t virtio_config_readb(VirtIODevice *vdev, uint32_t addr)\n{\n    VirtioDeviceClass *k = VIRTIO_DEVICE_GET_CLASS(vdev);\n    uint8_t val;\n\n    k->get_config(vdev, vdev->config);\n\n    if (addr > (vdev->config_len - sizeof(val)))\n        return (uint32_t)-1;\n\n    val = ldub_p(vdev->config + addr);\n    return val;\n}",
        "func": "uint32_t virtio_config_readb(VirtIODevice *vdev, uint32_t addr)\n{\n    VirtioDeviceClass *k = VIRTIO_DEVICE_GET_CLASS(vdev);\n    uint8_t val;\n\n    if (addr + sizeof(val) > vdev->config_len) {\n        return (uint32_t)-1;\n    }\n\n    k->get_config(vdev, vdev->config);\n\n    val = ldub_p(vdev->config + addr);\n    return val;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,10 +3,11 @@\n     VirtioDeviceClass *k = VIRTIO_DEVICE_GET_CLASS(vdev);\n     uint8_t val;\n \n+    if (addr + sizeof(val) > vdev->config_len) {\n+        return (uint32_t)-1;\n+    }\n+\n     k->get_config(vdev, vdev->config);\n-\n-    if (addr > (vdev->config_len - sizeof(val)))\n-        return (uint32_t)-1;\n \n     val = ldub_p(vdev->config + addr);\n     return val;",
        "diff_line_info": {
            "deleted_lines": [
                "",
                "    if (addr > (vdev->config_len - sizeof(val)))",
                "        return (uint32_t)-1;"
            ],
            "added_lines": [
                "    if (addr + sizeof(val) > vdev->config_len) {",
                "        return (uint32_t)-1;",
                "    }",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2013-2016",
        "func_name": "qemu/virtio_config_writew",
        "description": "A flaw was found in the way qemu v1.3.0 and later (virtio-rng) validates addresses when guest accesses the config space of a virtio device. If the virtio device has zero/small sized config space, such as virtio-rng, a privileged guest user could use this flaw to access the matching host's qemu address space and thus increase their privileges on the host.",
        "git_url": "https://github.com/qemu/qemu/commit/5f5a1318653c08e435cfa52f60b6a712815b659d",
        "commit_title": "virtio: properly validate address before accessing config",
        "commit_text": " There are several several issues in the current checking:  - The check was based on the minus of unsigned values which can overflow - It was done after .{set|get}_config() which can lead crash when config_len   is zero since vdev->config is NULL  Fix this by:  - Validate the address in virtio_pci_config_{read|write}() before   .{set|get}_config - Use addition instead minus to do the validation  Cc: Michael S. Tsirkin <mst@redhat.com> Cc: Petr Matousek <pmatouse@redhat.com>",
        "func_before": "void virtio_config_writew(VirtIODevice *vdev, uint32_t addr, uint32_t data)\n{\n    VirtioDeviceClass *k = VIRTIO_DEVICE_GET_CLASS(vdev);\n    uint16_t val = data;\n\n    if (addr > (vdev->config_len - sizeof(val)))\n        return;\n\n    stw_p(vdev->config + addr, val);\n\n    if (k->set_config) {\n        k->set_config(vdev, vdev->config);\n    }\n}",
        "func": "void virtio_config_writew(VirtIODevice *vdev, uint32_t addr, uint32_t data)\n{\n    VirtioDeviceClass *k = VIRTIO_DEVICE_GET_CLASS(vdev);\n    uint16_t val = data;\n\n    if (addr + sizeof(val) > vdev->config_len) {\n        return;\n    }\n\n    stw_p(vdev->config + addr, val);\n\n    if (k->set_config) {\n        k->set_config(vdev, vdev->config);\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,8 +3,9 @@\n     VirtioDeviceClass *k = VIRTIO_DEVICE_GET_CLASS(vdev);\n     uint16_t val = data;\n \n-    if (addr > (vdev->config_len - sizeof(val)))\n+    if (addr + sizeof(val) > vdev->config_len) {\n         return;\n+    }\n \n     stw_p(vdev->config + addr, val);\n ",
        "diff_line_info": {
            "deleted_lines": [
                "    if (addr > (vdev->config_len - sizeof(val)))"
            ],
            "added_lines": [
                "    if (addr + sizeof(val) > vdev->config_len) {",
                "    }"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-2016",
        "func_name": "qemu/virtio_config_readl",
        "description": "A flaw was found in the way qemu v1.3.0 and later (virtio-rng) validates addresses when guest accesses the config space of a virtio device. If the virtio device has zero/small sized config space, such as virtio-rng, a privileged guest user could use this flaw to access the matching host's qemu address space and thus increase their privileges on the host.",
        "git_url": "https://github.com/qemu/qemu/commit/5f5a1318653c08e435cfa52f60b6a712815b659d",
        "commit_title": "virtio: properly validate address before accessing config",
        "commit_text": " There are several several issues in the current checking:  - The check was based on the minus of unsigned values which can overflow - It was done after .{set|get}_config() which can lead crash when config_len   is zero since vdev->config is NULL  Fix this by:  - Validate the address in virtio_pci_config_{read|write}() before   .{set|get}_config - Use addition instead minus to do the validation  Cc: Michael S. Tsirkin <mst@redhat.com> Cc: Petr Matousek <pmatouse@redhat.com>",
        "func_before": "uint32_t virtio_config_readl(VirtIODevice *vdev, uint32_t addr)\n{\n    VirtioDeviceClass *k = VIRTIO_DEVICE_GET_CLASS(vdev);\n    uint32_t val;\n\n    k->get_config(vdev, vdev->config);\n\n    if (addr > (vdev->config_len - sizeof(val)))\n        return (uint32_t)-1;\n\n    val = ldl_p(vdev->config + addr);\n    return val;\n}",
        "func": "uint32_t virtio_config_readl(VirtIODevice *vdev, uint32_t addr)\n{\n    VirtioDeviceClass *k = VIRTIO_DEVICE_GET_CLASS(vdev);\n    uint32_t val;\n\n    if (addr + sizeof(val) > vdev->config_len) {\n        return (uint32_t)-1;\n    }\n\n    k->get_config(vdev, vdev->config);\n\n    val = ldl_p(vdev->config + addr);\n    return val;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,10 +3,11 @@\n     VirtioDeviceClass *k = VIRTIO_DEVICE_GET_CLASS(vdev);\n     uint32_t val;\n \n+    if (addr + sizeof(val) > vdev->config_len) {\n+        return (uint32_t)-1;\n+    }\n+\n     k->get_config(vdev, vdev->config);\n-\n-    if (addr > (vdev->config_len - sizeof(val)))\n-        return (uint32_t)-1;\n \n     val = ldl_p(vdev->config + addr);\n     return val;",
        "diff_line_info": {
            "deleted_lines": [
                "",
                "    if (addr > (vdev->config_len - sizeof(val)))",
                "        return (uint32_t)-1;"
            ],
            "added_lines": [
                "    if (addr + sizeof(val) > vdev->config_len) {",
                "        return (uint32_t)-1;",
                "    }",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2013-2016",
        "func_name": "qemu/virtio_config_writeb",
        "description": "A flaw was found in the way qemu v1.3.0 and later (virtio-rng) validates addresses when guest accesses the config space of a virtio device. If the virtio device has zero/small sized config space, such as virtio-rng, a privileged guest user could use this flaw to access the matching host's qemu address space and thus increase their privileges on the host.",
        "git_url": "https://github.com/qemu/qemu/commit/5f5a1318653c08e435cfa52f60b6a712815b659d",
        "commit_title": "virtio: properly validate address before accessing config",
        "commit_text": " There are several several issues in the current checking:  - The check was based on the minus of unsigned values which can overflow - It was done after .{set|get}_config() which can lead crash when config_len   is zero since vdev->config is NULL  Fix this by:  - Validate the address in virtio_pci_config_{read|write}() before   .{set|get}_config - Use addition instead minus to do the validation  Cc: Michael S. Tsirkin <mst@redhat.com> Cc: Petr Matousek <pmatouse@redhat.com>",
        "func_before": "void virtio_config_writeb(VirtIODevice *vdev, uint32_t addr, uint32_t data)\n{\n    VirtioDeviceClass *k = VIRTIO_DEVICE_GET_CLASS(vdev);\n    uint8_t val = data;\n\n    if (addr > (vdev->config_len - sizeof(val)))\n        return;\n\n    stb_p(vdev->config + addr, val);\n\n    if (k->set_config) {\n        k->set_config(vdev, vdev->config);\n    }\n}",
        "func": "void virtio_config_writeb(VirtIODevice *vdev, uint32_t addr, uint32_t data)\n{\n    VirtioDeviceClass *k = VIRTIO_DEVICE_GET_CLASS(vdev);\n    uint8_t val = data;\n\n    if (addr + sizeof(val) > vdev->config_len) {\n        return;\n    }\n\n    stb_p(vdev->config + addr, val);\n\n    if (k->set_config) {\n        k->set_config(vdev, vdev->config);\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,8 +3,9 @@\n     VirtioDeviceClass *k = VIRTIO_DEVICE_GET_CLASS(vdev);\n     uint8_t val = data;\n \n-    if (addr > (vdev->config_len - sizeof(val)))\n+    if (addr + sizeof(val) > vdev->config_len) {\n         return;\n+    }\n \n     stb_p(vdev->config + addr, val);\n ",
        "diff_line_info": {
            "deleted_lines": [
                "    if (addr > (vdev->config_len - sizeof(val)))"
            ],
            "added_lines": [
                "    if (addr + sizeof(val) > vdev->config_len) {",
                "    }"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-2016",
        "func_name": "qemu/virtio_config_readw",
        "description": "A flaw was found in the way qemu v1.3.0 and later (virtio-rng) validates addresses when guest accesses the config space of a virtio device. If the virtio device has zero/small sized config space, such as virtio-rng, a privileged guest user could use this flaw to access the matching host's qemu address space and thus increase their privileges on the host.",
        "git_url": "https://github.com/qemu/qemu/commit/5f5a1318653c08e435cfa52f60b6a712815b659d",
        "commit_title": "virtio: properly validate address before accessing config",
        "commit_text": " There are several several issues in the current checking:  - The check was based on the minus of unsigned values which can overflow - It was done after .{set|get}_config() which can lead crash when config_len   is zero since vdev->config is NULL  Fix this by:  - Validate the address in virtio_pci_config_{read|write}() before   .{set|get}_config - Use addition instead minus to do the validation  Cc: Michael S. Tsirkin <mst@redhat.com> Cc: Petr Matousek <pmatouse@redhat.com>",
        "func_before": "uint32_t virtio_config_readw(VirtIODevice *vdev, uint32_t addr)\n{\n    VirtioDeviceClass *k = VIRTIO_DEVICE_GET_CLASS(vdev);\n    uint16_t val;\n\n    k->get_config(vdev, vdev->config);\n\n    if (addr > (vdev->config_len - sizeof(val)))\n        return (uint32_t)-1;\n\n    val = lduw_p(vdev->config + addr);\n    return val;\n}",
        "func": "uint32_t virtio_config_readw(VirtIODevice *vdev, uint32_t addr)\n{\n    VirtioDeviceClass *k = VIRTIO_DEVICE_GET_CLASS(vdev);\n    uint16_t val;\n\n    if (addr + sizeof(val) > vdev->config_len) {\n        return (uint32_t)-1;\n    }\n\n    k->get_config(vdev, vdev->config);\n\n    val = lduw_p(vdev->config + addr);\n    return val;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,10 +3,11 @@\n     VirtioDeviceClass *k = VIRTIO_DEVICE_GET_CLASS(vdev);\n     uint16_t val;\n \n+    if (addr + sizeof(val) > vdev->config_len) {\n+        return (uint32_t)-1;\n+    }\n+\n     k->get_config(vdev, vdev->config);\n-\n-    if (addr > (vdev->config_len - sizeof(val)))\n-        return (uint32_t)-1;\n \n     val = lduw_p(vdev->config + addr);\n     return val;",
        "diff_line_info": {
            "deleted_lines": [
                "",
                "    if (addr > (vdev->config_len - sizeof(val)))",
                "        return (uint32_t)-1;"
            ],
            "added_lines": [
                "    if (addr + sizeof(val) > vdev->config_len) {",
                "        return (uint32_t)-1;",
                "    }",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2013-2016",
        "func_name": "qemu/virtio_config_writel",
        "description": "A flaw was found in the way qemu v1.3.0 and later (virtio-rng) validates addresses when guest accesses the config space of a virtio device. If the virtio device has zero/small sized config space, such as virtio-rng, a privileged guest user could use this flaw to access the matching host's qemu address space and thus increase their privileges on the host.",
        "git_url": "https://github.com/qemu/qemu/commit/5f5a1318653c08e435cfa52f60b6a712815b659d",
        "commit_title": "virtio: properly validate address before accessing config",
        "commit_text": " There are several several issues in the current checking:  - The check was based on the minus of unsigned values which can overflow - It was done after .{set|get}_config() which can lead crash when config_len   is zero since vdev->config is NULL  Fix this by:  - Validate the address in virtio_pci_config_{read|write}() before   .{set|get}_config - Use addition instead minus to do the validation  Cc: Michael S. Tsirkin <mst@redhat.com> Cc: Petr Matousek <pmatouse@redhat.com>",
        "func_before": "void virtio_config_writel(VirtIODevice *vdev, uint32_t addr, uint32_t data)\n{\n    VirtioDeviceClass *k = VIRTIO_DEVICE_GET_CLASS(vdev);\n    uint32_t val = data;\n\n    if (addr > (vdev->config_len - sizeof(val)))\n        return;\n\n    stl_p(vdev->config + addr, val);\n\n    if (k->set_config) {\n        k->set_config(vdev, vdev->config);\n    }\n}",
        "func": "void virtio_config_writel(VirtIODevice *vdev, uint32_t addr, uint32_t data)\n{\n    VirtioDeviceClass *k = VIRTIO_DEVICE_GET_CLASS(vdev);\n    uint32_t val = data;\n\n    if (addr + sizeof(val) > vdev->config_len) {\n        return;\n    }\n\n    stl_p(vdev->config + addr, val);\n\n    if (k->set_config) {\n        k->set_config(vdev, vdev->config);\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,8 +3,9 @@\n     VirtioDeviceClass *k = VIRTIO_DEVICE_GET_CLASS(vdev);\n     uint32_t val = data;\n \n-    if (addr > (vdev->config_len - sizeof(val)))\n+    if (addr + sizeof(val) > vdev->config_len) {\n         return;\n+    }\n \n     stl_p(vdev->config + addr, val);\n ",
        "diff_line_info": {
            "deleted_lines": [
                "    if (addr > (vdev->config_len - sizeof(val)))"
            ],
            "added_lines": [
                "    if (addr + sizeof(val) > vdev->config_len) {",
                "    }"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-13405",
        "func_name": "kernel/git/tip/tip/inode_init_owner",
        "description": "The inode_init_owner function in fs/inode.c in the Linux kernel through 3.16 allows local users to create files with an unintended group ownership, in a scenario where a directory is SGID to a certain group and is writable by a user who is not a member of that group. Here, the non-member can trigger creation of a plain file whose group ownership is that group. The intended behavior was that the non-member can trigger creation of a directory (but not a plain file) whose group ownership is that group. The non-member can escalate privileges by making the plain file executable and SGID.",
        "git_url": "https://git.kernel.org/pub/scm/linux/kernel/git/tip/tip.git/commit/?h=0b3369840cd61c23e2b9241093737b4c395cb406",
        "commit_title": "commit 0fa3ecd87848c9c93c2c828ef4c3a8ca36ce46c7 upstream.",
        "commit_text": " sgid directories have special semantics, making newly created files in the directory belong to the group of the directory, and newly created subdirectories will also become sgid.  This is historically used for group-shared directories.  But group directories writable by non-group members should not imply that such non-group members can magically join the group, so make sure to clear the sgid bit on non-directories for non-members (but remember that sgid without group execute means \"mandatory locking\", just to confuse things even more).  Cc: Andy Lutomirski <luto@kernel.org> Cc: Al Viro <viro@zeniv.linux.org.uk> ",
        "func_before": "void inode_init_owner(struct inode *inode, const struct inode *dir,\n\t\t\tumode_t mode)\n{\n\tinode->i_uid = current_fsuid();\n\tif (dir && dir->i_mode & S_ISGID) {\n\t\tinode->i_gid = dir->i_gid;\n\t\tif (S_ISDIR(mode))\n\t\t\tmode |= S_ISGID;\n\t} else\n\t\tinode->i_gid = current_fsgid();\n\tinode->i_mode = mode;\n}",
        "func": "void inode_init_owner(struct inode *inode, const struct inode *dir,\n\t\t\tumode_t mode)\n{\n\tinode->i_uid = current_fsuid();\n\tif (dir && dir->i_mode & S_ISGID) {\n\t\tinode->i_gid = dir->i_gid;\n\n\t\t/* Directories are special, and always inherit S_ISGID */\n\t\tif (S_ISDIR(mode))\n\t\t\tmode |= S_ISGID;\n\t\telse if ((mode & (S_ISGID | S_IXGRP)) == (S_ISGID | S_IXGRP) &&\n\t\t\t !in_group_p(inode->i_gid) &&\n\t\t\t !capable_wrt_inode_uidgid(dir, CAP_FSETID))\n\t\t\tmode &= ~S_ISGID;\n\t} else\n\t\tinode->i_gid = current_fsgid();\n\tinode->i_mode = mode;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,8 +4,14 @@\n \tinode->i_uid = current_fsuid();\n \tif (dir && dir->i_mode & S_ISGID) {\n \t\tinode->i_gid = dir->i_gid;\n+\n+\t\t/* Directories are special, and always inherit S_ISGID */\n \t\tif (S_ISDIR(mode))\n \t\t\tmode |= S_ISGID;\n+\t\telse if ((mode & (S_ISGID | S_IXGRP)) == (S_ISGID | S_IXGRP) &&\n+\t\t\t !in_group_p(inode->i_gid) &&\n+\t\t\t !capable_wrt_inode_uidgid(dir, CAP_FSETID))\n+\t\t\tmode &= ~S_ISGID;\n \t} else\n \t\tinode->i_gid = current_fsgid();\n \tinode->i_mode = mode;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "\t\t/* Directories are special, and always inherit S_ISGID */",
                "\t\telse if ((mode & (S_ISGID | S_IXGRP)) == (S_ISGID | S_IXGRP) &&",
                "\t\t\t !in_group_p(inode->i_gid) &&",
                "\t\t\t !capable_wrt_inode_uidgid(dir, CAP_FSETID))",
                "\t\t\tmode &= ~S_ISGID;"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-10853",
        "func_name": "torvalds/linux/emulator_write_std",
        "description": "A flaw was found in the way Linux kernel KVM hypervisor before 4.18 emulated instructions such as sgdt/sidt/fxsave/fxrstor. It did not check current privilege(CPL) level while emulating unprivileged instructions. An unprivileged guest user/process could use this flaw to potentially escalate privileges inside guest.",
        "git_url": "https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?h=3c9fa24ca7c9c47605672916491f79e8ccacb9e6",
        "commit_title": "The functions that were used in the emulation of fxrstor, fxsave, sgdt and",
        "commit_text": "sidt were originally meant for task switching, and as such they did not check privilege levels.  This is very bad when the same functions are used in the emulation of unprivileged instructions.  This is CVE-2018-10853.  The obvious fix is to add a new argument to ops->read_std and ops->write_std, which decides whether the access is a \"system\" access or should use the processor's CPL.  ",
        "func_before": "static int emulator_write_std(struct x86_emulate_ctxt *ctxt, gva_t addr, void *val,\n\t\t\t      unsigned int bytes, struct x86_exception *exception)\n{\n\tstruct kvm_vcpu *vcpu = emul_to_vcpu(ctxt);\n\n\treturn kvm_write_guest_virt_helper(addr, val, bytes, vcpu,\n\t\t\t\t\t   PFERR_WRITE_MASK, exception);\n}",
        "func": "static int emulator_write_std(struct x86_emulate_ctxt *ctxt, gva_t addr, void *val,\n\t\t\t      unsigned int bytes, struct x86_exception *exception,\n\t\t\t      bool system)\n{\n\tstruct kvm_vcpu *vcpu = emul_to_vcpu(ctxt);\n\tu32 access = PFERR_WRITE_MASK;\n\n\tif (!system && kvm_x86_ops->get_cpl(vcpu) == 3)\n\t\taccess |= PFERR_USER_MASK;\n\n\treturn kvm_write_guest_virt_helper(addr, val, bytes, vcpu,\n\t\t\t\t\t   access, exception);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,8 +1,13 @@\n static int emulator_write_std(struct x86_emulate_ctxt *ctxt, gva_t addr, void *val,\n-\t\t\t      unsigned int bytes, struct x86_exception *exception)\n+\t\t\t      unsigned int bytes, struct x86_exception *exception,\n+\t\t\t      bool system)\n {\n \tstruct kvm_vcpu *vcpu = emul_to_vcpu(ctxt);\n+\tu32 access = PFERR_WRITE_MASK;\n+\n+\tif (!system && kvm_x86_ops->get_cpl(vcpu) == 3)\n+\t\taccess |= PFERR_USER_MASK;\n \n \treturn kvm_write_guest_virt_helper(addr, val, bytes, vcpu,\n-\t\t\t\t\t   PFERR_WRITE_MASK, exception);\n+\t\t\t\t\t   access, exception);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\t      unsigned int bytes, struct x86_exception *exception)",
                "\t\t\t\t\t   PFERR_WRITE_MASK, exception);"
            ],
            "added_lines": [
                "\t\t\t      unsigned int bytes, struct x86_exception *exception,",
                "\t\t\t      bool system)",
                "\tu32 access = PFERR_WRITE_MASK;",
                "",
                "\tif (!system && kvm_x86_ops->get_cpl(vcpu) == 3)",
                "\t\taccess |= PFERR_USER_MASK;",
                "\t\t\t\t\t   access, exception);"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-10853",
        "func_name": "torvalds/linux/emulator_read_std",
        "description": "A flaw was found in the way Linux kernel KVM hypervisor before 4.18 emulated instructions such as sgdt/sidt/fxsave/fxrstor. It did not check current privilege(CPL) level while emulating unprivileged instructions. An unprivileged guest user/process could use this flaw to potentially escalate privileges inside guest.",
        "git_url": "https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?h=3c9fa24ca7c9c47605672916491f79e8ccacb9e6",
        "commit_title": "The functions that were used in the emulation of fxrstor, fxsave, sgdt and",
        "commit_text": "sidt were originally meant for task switching, and as such they did not check privilege levels.  This is very bad when the same functions are used in the emulation of unprivileged instructions.  This is CVE-2018-10853.  The obvious fix is to add a new argument to ops->read_std and ops->write_std, which decides whether the access is a \"system\" access or should use the processor's CPL.  ",
        "func_before": "static int emulator_read_std(struct x86_emulate_ctxt *ctxt,\n\t\t\t     gva_t addr, void *val, unsigned int bytes,\n\t\t\t     struct x86_exception *exception)\n{\n\tstruct kvm_vcpu *vcpu = emul_to_vcpu(ctxt);\n\treturn kvm_read_guest_virt_helper(addr, val, bytes, vcpu, 0, exception);\n}",
        "func": "static int emulator_read_std(struct x86_emulate_ctxt *ctxt,\n\t\t\t     gva_t addr, void *val, unsigned int bytes,\n\t\t\t     struct x86_exception *exception, bool system)\n{\n\tstruct kvm_vcpu *vcpu = emul_to_vcpu(ctxt);\n\tu32 access = 0;\n\n\tif (!system && kvm_x86_ops->get_cpl(vcpu) == 3)\n\t\taccess |= PFERR_USER_MASK;\n\n\treturn kvm_read_guest_virt_helper(addr, val, bytes, vcpu, access, exception);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,7 +1,12 @@\n static int emulator_read_std(struct x86_emulate_ctxt *ctxt,\n \t\t\t     gva_t addr, void *val, unsigned int bytes,\n-\t\t\t     struct x86_exception *exception)\n+\t\t\t     struct x86_exception *exception, bool system)\n {\n \tstruct kvm_vcpu *vcpu = emul_to_vcpu(ctxt);\n-\treturn kvm_read_guest_virt_helper(addr, val, bytes, vcpu, 0, exception);\n+\tu32 access = 0;\n+\n+\tif (!system && kvm_x86_ops->get_cpl(vcpu) == 3)\n+\t\taccess |= PFERR_USER_MASK;\n+\n+\treturn kvm_read_guest_virt_helper(addr, val, bytes, vcpu, access, exception);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\t     struct x86_exception *exception)",
                "\treturn kvm_read_guest_virt_helper(addr, val, bytes, vcpu, 0, exception);"
            ],
            "added_lines": [
                "\t\t\t     struct x86_exception *exception, bool system)",
                "\tu32 access = 0;",
                "",
                "\tif (!system && kvm_x86_ops->get_cpl(vcpu) == 3)",
                "\t\taccess |= PFERR_USER_MASK;",
                "",
                "\treturn kvm_read_guest_virt_helper(addr, val, bytes, vcpu, access, exception);"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-10853",
        "func_name": "torvalds/linux/handle_ud",
        "description": "A flaw was found in the way Linux kernel KVM hypervisor before 4.18 emulated instructions such as sgdt/sidt/fxsave/fxrstor. It did not check current privilege(CPL) level while emulating unprivileged instructions. An unprivileged guest user/process could use this flaw to potentially escalate privileges inside guest.",
        "git_url": "https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?h=3c9fa24ca7c9c47605672916491f79e8ccacb9e6",
        "commit_title": "The functions that were used in the emulation of fxrstor, fxsave, sgdt and",
        "commit_text": "sidt were originally meant for task switching, and as such they did not check privilege levels.  This is very bad when the same functions are used in the emulation of unprivileged instructions.  This is CVE-2018-10853.  The obvious fix is to add a new argument to ops->read_std and ops->write_std, which decides whether the access is a \"system\" access or should use the processor's CPL.  ",
        "func_before": "int handle_ud(struct kvm_vcpu *vcpu)\n{\n\tint emul_type = EMULTYPE_TRAP_UD;\n\tenum emulation_result er;\n\tchar sig[5]; /* ud2; .ascii \"kvm\" */\n\tstruct x86_exception e;\n\n\tif (force_emulation_prefix &&\n\t    kvm_read_guest_virt(&vcpu->arch.emulate_ctxt,\n\t\t\t\tkvm_get_linear_rip(vcpu), sig, sizeof(sig), &e) == 0 &&\n\t    memcmp(sig, \"\\xf\\xbkvm\", sizeof(sig)) == 0) {\n\t\tkvm_rip_write(vcpu, kvm_rip_read(vcpu) + sizeof(sig));\n\t\temul_type = 0;\n\t}\n\n\ter = emulate_instruction(vcpu, emul_type);\n\tif (er == EMULATE_USER_EXIT)\n\t\treturn 0;\n\tif (er != EMULATE_DONE)\n\t\tkvm_queue_exception(vcpu, UD_VECTOR);\n\treturn 1;\n}",
        "func": "int handle_ud(struct kvm_vcpu *vcpu)\n{\n\tint emul_type = EMULTYPE_TRAP_UD;\n\tenum emulation_result er;\n\tchar sig[5]; /* ud2; .ascii \"kvm\" */\n\tstruct x86_exception e;\n\n\tif (force_emulation_prefix &&\n\t    kvm_read_guest_virt(vcpu, kvm_get_linear_rip(vcpu),\n\t\t\t\tsig, sizeof(sig), &e) == 0 &&\n\t    memcmp(sig, \"\\xf\\xbkvm\", sizeof(sig)) == 0) {\n\t\tkvm_rip_write(vcpu, kvm_rip_read(vcpu) + sizeof(sig));\n\t\temul_type = 0;\n\t}\n\n\ter = emulate_instruction(vcpu, emul_type);\n\tif (er == EMULATE_USER_EXIT)\n\t\treturn 0;\n\tif (er != EMULATE_DONE)\n\t\tkvm_queue_exception(vcpu, UD_VECTOR);\n\treturn 1;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -6,8 +6,8 @@\n \tstruct x86_exception e;\n \n \tif (force_emulation_prefix &&\n-\t    kvm_read_guest_virt(&vcpu->arch.emulate_ctxt,\n-\t\t\t\tkvm_get_linear_rip(vcpu), sig, sizeof(sig), &e) == 0 &&\n+\t    kvm_read_guest_virt(vcpu, kvm_get_linear_rip(vcpu),\n+\t\t\t\tsig, sizeof(sig), &e) == 0 &&\n \t    memcmp(sig, \"\\xf\\xbkvm\", sizeof(sig)) == 0) {\n \t\tkvm_rip_write(vcpu, kvm_rip_read(vcpu) + sizeof(sig));\n \t\temul_type = 0;",
        "diff_line_info": {
            "deleted_lines": [
                "\t    kvm_read_guest_virt(&vcpu->arch.emulate_ctxt,",
                "\t\t\t\tkvm_get_linear_rip(vcpu), sig, sizeof(sig), &e) == 0 &&"
            ],
            "added_lines": [
                "\t    kvm_read_guest_virt(vcpu, kvm_get_linear_rip(vcpu),",
                "\t\t\t\tsig, sizeof(sig), &e) == 0 &&"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-10853",
        "func_name": "torvalds/linux/linear_read_system",
        "description": "A flaw was found in the way Linux kernel KVM hypervisor before 4.18 emulated instructions such as sgdt/sidt/fxsave/fxrstor. It did not check current privilege(CPL) level while emulating unprivileged instructions. An unprivileged guest user/process could use this flaw to potentially escalate privileges inside guest.",
        "git_url": "https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?h=3c9fa24ca7c9c47605672916491f79e8ccacb9e6",
        "commit_title": "The functions that were used in the emulation of fxrstor, fxsave, sgdt and",
        "commit_text": "sidt were originally meant for task switching, and as such they did not check privilege levels.  This is very bad when the same functions are used in the emulation of unprivileged instructions.  This is CVE-2018-10853.  The obvious fix is to add a new argument to ops->read_std and ops->write_std, which decides whether the access is a \"system\" access or should use the processor's CPL.  ",
        "func_before": "static int linear_read_system(struct x86_emulate_ctxt *ctxt, ulong linear,\n\t\t\t      void *data, unsigned size)\n{\n\treturn ctxt->ops->read_std(ctxt, linear, data, size, &ctxt->exception);\n}",
        "func": "static int linear_read_system(struct x86_emulate_ctxt *ctxt, ulong linear,\n\t\t\t      void *data, unsigned size)\n{\n\treturn ctxt->ops->read_std(ctxt, linear, data, size, &ctxt->exception, true);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,5 @@\n static int linear_read_system(struct x86_emulate_ctxt *ctxt, ulong linear,\n \t\t\t      void *data, unsigned size)\n {\n-\treturn ctxt->ops->read_std(ctxt, linear, data, size, &ctxt->exception);\n+\treturn ctxt->ops->read_std(ctxt, linear, data, size, &ctxt->exception, true);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\treturn ctxt->ops->read_std(ctxt, linear, data, size, &ctxt->exception);"
            ],
            "added_lines": [
                "\treturn ctxt->ops->read_std(ctxt, linear, data, size, &ctxt->exception, true);"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-10853",
        "func_name": "torvalds/linux/segmented_write_std",
        "description": "A flaw was found in the way Linux kernel KVM hypervisor before 4.18 emulated instructions such as sgdt/sidt/fxsave/fxrstor. It did not check current privilege(CPL) level while emulating unprivileged instructions. An unprivileged guest user/process could use this flaw to potentially escalate privileges inside guest.",
        "git_url": "https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?h=3c9fa24ca7c9c47605672916491f79e8ccacb9e6",
        "commit_title": "The functions that were used in the emulation of fxrstor, fxsave, sgdt and",
        "commit_text": "sidt were originally meant for task switching, and as such they did not check privilege levels.  This is very bad when the same functions are used in the emulation of unprivileged instructions.  This is CVE-2018-10853.  The obvious fix is to add a new argument to ops->read_std and ops->write_std, which decides whether the access is a \"system\" access or should use the processor's CPL.  ",
        "func_before": "static int segmented_write_std(struct x86_emulate_ctxt *ctxt,\n\t\t\t       struct segmented_address addr,\n\t\t\t       void *data,\n\t\t\t       unsigned int size)\n{\n\tint rc;\n\tulong linear;\n\n\trc = linearize(ctxt, addr, size, true, &linear);\n\tif (rc != X86EMUL_CONTINUE)\n\t\treturn rc;\n\treturn ctxt->ops->write_std(ctxt, linear, data, size, &ctxt->exception);\n}",
        "func": "static int segmented_write_std(struct x86_emulate_ctxt *ctxt,\n\t\t\t       struct segmented_address addr,\n\t\t\t       void *data,\n\t\t\t       unsigned int size)\n{\n\tint rc;\n\tulong linear;\n\n\trc = linearize(ctxt, addr, size, true, &linear);\n\tif (rc != X86EMUL_CONTINUE)\n\t\treturn rc;\n\treturn ctxt->ops->write_std(ctxt, linear, data, size, &ctxt->exception, false);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -9,5 +9,5 @@\n \trc = linearize(ctxt, addr, size, true, &linear);\n \tif (rc != X86EMUL_CONTINUE)\n \t\treturn rc;\n-\treturn ctxt->ops->write_std(ctxt, linear, data, size, &ctxt->exception);\n+\treturn ctxt->ops->write_std(ctxt, linear, data, size, &ctxt->exception, false);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\treturn ctxt->ops->write_std(ctxt, linear, data, size, &ctxt->exception);"
            ],
            "added_lines": [
                "\treturn ctxt->ops->write_std(ctxt, linear, data, size, &ctxt->exception, false);"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-10853",
        "func_name": "torvalds/linux/segmented_read_std",
        "description": "A flaw was found in the way Linux kernel KVM hypervisor before 4.18 emulated instructions such as sgdt/sidt/fxsave/fxrstor. It did not check current privilege(CPL) level while emulating unprivileged instructions. An unprivileged guest user/process could use this flaw to potentially escalate privileges inside guest.",
        "git_url": "https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?h=3c9fa24ca7c9c47605672916491f79e8ccacb9e6",
        "commit_title": "The functions that were used in the emulation of fxrstor, fxsave, sgdt and",
        "commit_text": "sidt were originally meant for task switching, and as such they did not check privilege levels.  This is very bad when the same functions are used in the emulation of unprivileged instructions.  This is CVE-2018-10853.  The obvious fix is to add a new argument to ops->read_std and ops->write_std, which decides whether the access is a \"system\" access or should use the processor's CPL.  ",
        "func_before": "static int segmented_read_std(struct x86_emulate_ctxt *ctxt,\n\t\t\t      struct segmented_address addr,\n\t\t\t      void *data,\n\t\t\t      unsigned size)\n{\n\tint rc;\n\tulong linear;\n\n\trc = linearize(ctxt, addr, size, false, &linear);\n\tif (rc != X86EMUL_CONTINUE)\n\t\treturn rc;\n\treturn ctxt->ops->read_std(ctxt, linear, data, size, &ctxt->exception);\n}",
        "func": "static int segmented_read_std(struct x86_emulate_ctxt *ctxt,\n\t\t\t      struct segmented_address addr,\n\t\t\t      void *data,\n\t\t\t      unsigned size)\n{\n\tint rc;\n\tulong linear;\n\n\trc = linearize(ctxt, addr, size, false, &linear);\n\tif (rc != X86EMUL_CONTINUE)\n\t\treturn rc;\n\treturn ctxt->ops->read_std(ctxt, linear, data, size, &ctxt->exception, false);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -9,5 +9,5 @@\n \trc = linearize(ctxt, addr, size, false, &linear);\n \tif (rc != X86EMUL_CONTINUE)\n \t\treturn rc;\n-\treturn ctxt->ops->read_std(ctxt, linear, data, size, &ctxt->exception);\n+\treturn ctxt->ops->read_std(ctxt, linear, data, size, &ctxt->exception, false);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\treturn ctxt->ops->read_std(ctxt, linear, data, size, &ctxt->exception);"
            ],
            "added_lines": [
                "\treturn ctxt->ops->read_std(ctxt, linear, data, size, &ctxt->exception, false);"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-10853",
        "func_name": "torvalds/linux/emulator_io_port_access_allowed",
        "description": "A flaw was found in the way Linux kernel KVM hypervisor before 4.18 emulated instructions such as sgdt/sidt/fxsave/fxrstor. It did not check current privilege(CPL) level while emulating unprivileged instructions. An unprivileged guest user/process could use this flaw to potentially escalate privileges inside guest.",
        "git_url": "https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?h=3c9fa24ca7c9c47605672916491f79e8ccacb9e6",
        "commit_title": "The functions that were used in the emulation of fxrstor, fxsave, sgdt and",
        "commit_text": "sidt were originally meant for task switching, and as such they did not check privilege levels.  This is very bad when the same functions are used in the emulation of unprivileged instructions.  This is CVE-2018-10853.  The obvious fix is to add a new argument to ops->read_std and ops->write_std, which decides whether the access is a \"system\" access or should use the processor's CPL.  ",
        "func_before": "static bool emulator_io_port_access_allowed(struct x86_emulate_ctxt *ctxt,\n\t\t\t\t\t    u16 port, u16 len)\n{\n\tconst struct x86_emulate_ops *ops = ctxt->ops;\n\tstruct desc_struct tr_seg;\n\tu32 base3;\n\tint r;\n\tu16 tr, io_bitmap_ptr, perm, bit_idx = port & 0x7;\n\tunsigned mask = (1 << len) - 1;\n\tunsigned long base;\n\n\t/*\n\t * VMware allows access to these ports even if denied\n\t * by TSS I/O permission bitmap. Mimic behavior.\n\t */\n\tif (enable_vmware_backdoor &&\n\t    ((port == VMWARE_PORT_VMPORT) || (port == VMWARE_PORT_VMRPC)))\n\t\treturn true;\n\n\tops->get_segment(ctxt, &tr, &tr_seg, &base3, VCPU_SREG_TR);\n\tif (!tr_seg.p)\n\t\treturn false;\n\tif (desc_limit_scaled(&tr_seg) < 103)\n\t\treturn false;\n\tbase = get_desc_base(&tr_seg);\n#ifdef CONFIG_X86_64\n\tbase |= ((u64)base3) << 32;\n#endif\n\tr = ops->read_std(ctxt, base + 102, &io_bitmap_ptr, 2, NULL);\n\tif (r != X86EMUL_CONTINUE)\n\t\treturn false;\n\tif (io_bitmap_ptr + port/8 > desc_limit_scaled(&tr_seg))\n\t\treturn false;\n\tr = ops->read_std(ctxt, base + io_bitmap_ptr + port/8, &perm, 2, NULL);\n\tif (r != X86EMUL_CONTINUE)\n\t\treturn false;\n\tif ((perm >> bit_idx) & mask)\n\t\treturn false;\n\treturn true;\n}",
        "func": "static bool emulator_io_port_access_allowed(struct x86_emulate_ctxt *ctxt,\n\t\t\t\t\t    u16 port, u16 len)\n{\n\tconst struct x86_emulate_ops *ops = ctxt->ops;\n\tstruct desc_struct tr_seg;\n\tu32 base3;\n\tint r;\n\tu16 tr, io_bitmap_ptr, perm, bit_idx = port & 0x7;\n\tunsigned mask = (1 << len) - 1;\n\tunsigned long base;\n\n\t/*\n\t * VMware allows access to these ports even if denied\n\t * by TSS I/O permission bitmap. Mimic behavior.\n\t */\n\tif (enable_vmware_backdoor &&\n\t    ((port == VMWARE_PORT_VMPORT) || (port == VMWARE_PORT_VMRPC)))\n\t\treturn true;\n\n\tops->get_segment(ctxt, &tr, &tr_seg, &base3, VCPU_SREG_TR);\n\tif (!tr_seg.p)\n\t\treturn false;\n\tif (desc_limit_scaled(&tr_seg) < 103)\n\t\treturn false;\n\tbase = get_desc_base(&tr_seg);\n#ifdef CONFIG_X86_64\n\tbase |= ((u64)base3) << 32;\n#endif\n\tr = ops->read_std(ctxt, base + 102, &io_bitmap_ptr, 2, NULL, true);\n\tif (r != X86EMUL_CONTINUE)\n\t\treturn false;\n\tif (io_bitmap_ptr + port/8 > desc_limit_scaled(&tr_seg))\n\t\treturn false;\n\tr = ops->read_std(ctxt, base + io_bitmap_ptr + port/8, &perm, 2, NULL, true);\n\tif (r != X86EMUL_CONTINUE)\n\t\treturn false;\n\tif ((perm >> bit_idx) & mask)\n\t\treturn false;\n\treturn true;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -26,12 +26,12 @@\n #ifdef CONFIG_X86_64\n \tbase |= ((u64)base3) << 32;\n #endif\n-\tr = ops->read_std(ctxt, base + 102, &io_bitmap_ptr, 2, NULL);\n+\tr = ops->read_std(ctxt, base + 102, &io_bitmap_ptr, 2, NULL, true);\n \tif (r != X86EMUL_CONTINUE)\n \t\treturn false;\n \tif (io_bitmap_ptr + port/8 > desc_limit_scaled(&tr_seg))\n \t\treturn false;\n-\tr = ops->read_std(ctxt, base + io_bitmap_ptr + port/8, &perm, 2, NULL);\n+\tr = ops->read_std(ctxt, base + io_bitmap_ptr + port/8, &perm, 2, NULL, true);\n \tif (r != X86EMUL_CONTINUE)\n \t\treturn false;\n \tif ((perm >> bit_idx) & mask)",
        "diff_line_info": {
            "deleted_lines": [
                "\tr = ops->read_std(ctxt, base + 102, &io_bitmap_ptr, 2, NULL);",
                "\tr = ops->read_std(ctxt, base + io_bitmap_ptr + port/8, &perm, 2, NULL);"
            ],
            "added_lines": [
                "\tr = ops->read_std(ctxt, base + 102, &io_bitmap_ptr, 2, NULL, true);",
                "\tr = ops->read_std(ctxt, base + io_bitmap_ptr + port/8, &perm, 2, NULL, true);"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-10853",
        "func_name": "torvalds/linux/linear_write_system",
        "description": "A flaw was found in the way Linux kernel KVM hypervisor before 4.18 emulated instructions such as sgdt/sidt/fxsave/fxrstor. It did not check current privilege(CPL) level while emulating unprivileged instructions. An unprivileged guest user/process could use this flaw to potentially escalate privileges inside guest.",
        "git_url": "https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?h=3c9fa24ca7c9c47605672916491f79e8ccacb9e6",
        "commit_title": "The functions that were used in the emulation of fxrstor, fxsave, sgdt and",
        "commit_text": "sidt were originally meant for task switching, and as such they did not check privilege levels.  This is very bad when the same functions are used in the emulation of unprivileged instructions.  This is CVE-2018-10853.  The obvious fix is to add a new argument to ops->read_std and ops->write_std, which decides whether the access is a \"system\" access or should use the processor's CPL.  ",
        "func_before": "static int linear_write_system(struct x86_emulate_ctxt *ctxt,\n\t\t\t       ulong linear, void *data,\n\t\t\t       unsigned int size)\n{\n\treturn ctxt->ops->write_std(ctxt, linear, data, size, &ctxt->exception);\n}",
        "func": "static int linear_write_system(struct x86_emulate_ctxt *ctxt,\n\t\t\t       ulong linear, void *data,\n\t\t\t       unsigned int size)\n{\n\treturn ctxt->ops->write_std(ctxt, linear, data, size, &ctxt->exception, true);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,5 +2,5 @@\n \t\t\t       ulong linear, void *data,\n \t\t\t       unsigned int size)\n {\n-\treturn ctxt->ops->write_std(ctxt, linear, data, size, &ctxt->exception);\n+\treturn ctxt->ops->write_std(ctxt, linear, data, size, &ctxt->exception, true);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\treturn ctxt->ops->write_std(ctxt, linear, data, size, &ctxt->exception);"
            ],
            "added_lines": [
                "\treturn ctxt->ops->write_std(ctxt, linear, data, size, &ctxt->exception, true);"
            ]
        }
    },
    {
        "cve_id": "CVE-2023-41053",
        "func_name": "redis/sortROGetKeys",
        "description": "Redis is an in-memory database that persists on disk. Redis does not correctly identify keys accessed by `SORT_RO` and as a result may grant users executing this command access to keys that are not explicitly authorized by the ACL configuration. The problem exists in Redis 7.0 or newer and has been fixed in Redis 7.0.13 and 7.2.1. Users are advised to upgrade. There are no known workarounds for this vulnerability.",
        "git_url": "https://github.com/redis/redis/commit/9e505e6cd842338424e05883521ca1fb7d0f47f6",
        "commit_title": "Fix sort_ro get-keys function return wrong key number (#12522)",
        "commit_text": " Before ``` 127.0.0.1:6379> command getkeys sort_ro key (empty array) 127.0.0.1:6379> ``` After: ``` 127.0.0.1:6379> command getkeys sort_ro key 1) \"key\" 127.0.0.1:6379> ```  (cherry picked from commit b59f53efb31b36d0a307809f5d33bf66d66a4447)",
        "func_before": "int sortROGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    keyReference *keys;\n    UNUSED(cmd);\n    UNUSED(argv);\n    UNUSED(argc);\n\n    keys = getKeysPrepareResult(result, 1);\n    keys[0].pos = 1; /* <sort-key> is always present. */\n    keys[0].flags = CMD_KEY_RO | CMD_KEY_ACCESS;\n    return 1;\n}",
        "func": "int sortROGetKeys(struct redisCommand *cmd, robj **argv, int argc, getKeysResult *result) {\n    keyReference *keys;\n    UNUSED(cmd);\n    UNUSED(argv);\n    UNUSED(argc);\n\n    keys = getKeysPrepareResult(result, 1);\n    keys[0].pos = 1; /* <sort-key> is always present. */\n    keys[0].flags = CMD_KEY_RO | CMD_KEY_ACCESS;\n    result->numkeys = 1;\n    return result->numkeys;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -7,5 +7,6 @@\n     keys = getKeysPrepareResult(result, 1);\n     keys[0].pos = 1; /* <sort-key> is always present. */\n     keys[0].flags = CMD_KEY_RO | CMD_KEY_ACCESS;\n-    return 1;\n+    result->numkeys = 1;\n+    return result->numkeys;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    return 1;"
            ],
            "added_lines": [
                "    result->numkeys = 1;",
                "    return result->numkeys;"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-11747",
        "func_name": "tinyproxy/main",
        "description": "main.c in Tinyproxy 1.8.4 and earlier creates a /run/tinyproxy/tinyproxy.pid file after dropping privileges to a non-root account, which might allow local users to kill arbitrary processes by leveraging access to this non-root account for tinyproxy.pid modification before a root script executes a \"kill `cat /run/tinyproxy/tinyproxy.pid`\" command.",
        "git_url": "https://github.com/tinyproxy/tinyproxy/commit/fe4d29888306e62f3bbf964b3fdb8126ddbe8f6e",
        "commit_title": "Fix CVE-2017-11747: Create PID file before dropping privileges.",
        "commit_text": " Resolves #106 ",
        "func_before": "int\nmain (int argc, char **argv)\n{\n        /* Only allow u+rw bits. This may be required for some versions\n         * of glibc so that mkstemp() doesn't make us vulnerable.\n         */\n        umask (0177);\n\n        log_message (LOG_INFO, \"Initializing \" PACKAGE \" ...\");\n\n        if (config_compile_regex()) {\n                exit (EX_SOFTWARE);\n        }\n\n        initialize_config_defaults (&config_defaults);\n        process_cmdline (argc, argv, &config_defaults);\n\n        if (reload_config_file (config_defaults.config_file,\n                                &config,\n                                &config_defaults)) {\n                exit (EX_SOFTWARE);\n        }\n\n        init_stats ();\n\n        /* If ANONYMOUS is turned on, make sure that Content-Length is\n         * in the list of allowed headers, since it is required in a\n         * HTTP/1.0 request. Also add the Content-Type header since it\n         * goes hand in hand with Content-Length. */\n        if (is_anonymous_enabled ()) {\n                anonymous_insert (\"Content-Length\");\n                anonymous_insert (\"Content-Type\");\n        }\n\n        if (config.godaemon == TRUE)\n                makedaemon ();\n\n        if (set_signal_handler (SIGPIPE, SIG_IGN) == SIG_ERR) {\n                fprintf (stderr, \"%s: Could not set the \\\"SIGPIPE\\\" signal.\\n\",\n                         argv[0]);\n                exit (EX_OSERR);\n        }\n\n#ifdef FILTER_ENABLE\n        if (config.filter)\n                filter_init ();\n#endif /* FILTER_ENABLE */\n\n        /* Start listening on the selected port. */\n        if (child_listening_sockets(config.listen_addrs, config.port) < 0) {\n                fprintf (stderr, \"%s: Could not create listening sockets.\\n\",\n                         argv[0]);\n                exit (EX_OSERR);\n        }\n\n        /* Switch to a different user if we're running as root */\n        if (geteuid () == 0)\n                change_user (argv[0]);\n        else\n                log_message (LOG_WARNING,\n                             \"Not running as root, so not changing UID/GID.\");\n\n        /* Create log file after we drop privileges */\n        if (setup_logging ()) {\n                exit (EX_SOFTWARE);\n        }\n\n        /* Create pid file after we drop privileges */\n        if (config.pidpath) {\n                if (pidfile_create (config.pidpath) < 0) {\n                        fprintf (stderr, \"%s: Could not create PID file.\\n\",\n                                 argv[0]);\n                        exit (EX_OSERR);\n                }\n        }\n\n        if (child_pool_create () < 0) {\n                fprintf (stderr,\n                         \"%s: Could not create the pool of children.\\n\",\n                         argv[0]);\n                exit (EX_SOFTWARE);\n        }\n\n        /* These signals are only for the parent process. */\n        log_message (LOG_INFO, \"Setting the various signals.\");\n\n        if (set_signal_handler (SIGCHLD, takesig) == SIG_ERR) {\n                fprintf (stderr, \"%s: Could not set the \\\"SIGCHLD\\\" signal.\\n\",\n                         argv[0]);\n                exit (EX_OSERR);\n        }\n\n        if (set_signal_handler (SIGTERM, takesig) == SIG_ERR) {\n                fprintf (stderr, \"%s: Could not set the \\\"SIGTERM\\\" signal.\\n\",\n                         argv[0]);\n                exit (EX_OSERR);\n        }\n\n        if (set_signal_handler (SIGHUP, takesig) == SIG_ERR) {\n                fprintf (stderr, \"%s: Could not set the \\\"SIGHUP\\\" signal.\\n\",\n                         argv[0]);\n                exit (EX_OSERR);\n        }\n\n        /* Start the main loop */\n        log_message (LOG_INFO, \"Starting main loop. Accepting connections.\");\n\n        child_main_loop ();\n\n        log_message (LOG_INFO, \"Shutting down.\");\n\n        child_kill_children (SIGTERM);\n        child_close_sock ();\n\n        /* Remove the PID file */\n        if (unlink (config.pidpath) < 0) {\n                log_message (LOG_WARNING,\n                             \"Could not remove PID file \\\"%s\\\": %s.\",\n                             config.pidpath, strerror (errno));\n        }\n\n#ifdef FILTER_ENABLE\n        if (config.filter)\n                filter_destroy ();\n#endif /* FILTER_ENABLE */\n\n        shutdown_logging ();\n\n        return EXIT_SUCCESS;\n}",
        "func": "int\nmain (int argc, char **argv)\n{\n        /* Only allow u+rw bits. This may be required for some versions\n         * of glibc so that mkstemp() doesn't make us vulnerable.\n         */\n        umask (0177);\n\n        log_message (LOG_INFO, \"Initializing \" PACKAGE \" ...\");\n\n        if (config_compile_regex()) {\n                exit (EX_SOFTWARE);\n        }\n\n        initialize_config_defaults (&config_defaults);\n        process_cmdline (argc, argv, &config_defaults);\n\n        if (reload_config_file (config_defaults.config_file,\n                                &config,\n                                &config_defaults)) {\n                exit (EX_SOFTWARE);\n        }\n\n        init_stats ();\n\n        /* If ANONYMOUS is turned on, make sure that Content-Length is\n         * in the list of allowed headers, since it is required in a\n         * HTTP/1.0 request. Also add the Content-Type header since it\n         * goes hand in hand with Content-Length. */\n        if (is_anonymous_enabled ()) {\n                anonymous_insert (\"Content-Length\");\n                anonymous_insert (\"Content-Type\");\n        }\n\n        if (config.godaemon == TRUE)\n                makedaemon ();\n\n        if (set_signal_handler (SIGPIPE, SIG_IGN) == SIG_ERR) {\n                fprintf (stderr, \"%s: Could not set the \\\"SIGPIPE\\\" signal.\\n\",\n                         argv[0]);\n                exit (EX_OSERR);\n        }\n\n#ifdef FILTER_ENABLE\n        if (config.filter)\n                filter_init ();\n#endif /* FILTER_ENABLE */\n\n        /* Start listening on the selected port. */\n        if (child_listening_sockets(config.listen_addrs, config.port) < 0) {\n                fprintf (stderr, \"%s: Could not create listening sockets.\\n\",\n                         argv[0]);\n                exit (EX_OSERR);\n        }\n\n        /* Create pid file before we drop privileges */\n        if (config.pidpath) {\n                if (pidfile_create (config.pidpath) < 0) {\n                        fprintf (stderr, \"%s: Could not create PID file.\\n\",\n                                 argv[0]);\n                        exit (EX_OSERR);\n                }\n        }\n\n        /* Switch to a different user if we're running as root */\n        if (geteuid () == 0)\n                change_user (argv[0]);\n        else\n                log_message (LOG_WARNING,\n                             \"Not running as root, so not changing UID/GID.\");\n\n        /* Create log file after we drop privileges */\n        if (setup_logging ()) {\n                exit (EX_SOFTWARE);\n        }\n\n        if (child_pool_create () < 0) {\n                fprintf (stderr,\n                         \"%s: Could not create the pool of children.\\n\",\n                         argv[0]);\n                exit (EX_SOFTWARE);\n        }\n\n        /* These signals are only for the parent process. */\n        log_message (LOG_INFO, \"Setting the various signals.\");\n\n        if (set_signal_handler (SIGCHLD, takesig) == SIG_ERR) {\n                fprintf (stderr, \"%s: Could not set the \\\"SIGCHLD\\\" signal.\\n\",\n                         argv[0]);\n                exit (EX_OSERR);\n        }\n\n        if (set_signal_handler (SIGTERM, takesig) == SIG_ERR) {\n                fprintf (stderr, \"%s: Could not set the \\\"SIGTERM\\\" signal.\\n\",\n                         argv[0]);\n                exit (EX_OSERR);\n        }\n\n        if (set_signal_handler (SIGHUP, takesig) == SIG_ERR) {\n                fprintf (stderr, \"%s: Could not set the \\\"SIGHUP\\\" signal.\\n\",\n                         argv[0]);\n                exit (EX_OSERR);\n        }\n\n        /* Start the main loop */\n        log_message (LOG_INFO, \"Starting main loop. Accepting connections.\");\n\n        child_main_loop ();\n\n        log_message (LOG_INFO, \"Shutting down.\");\n\n        child_kill_children (SIGTERM);\n        child_close_sock ();\n\n        /* Remove the PID file */\n        if (unlink (config.pidpath) < 0) {\n                log_message (LOG_WARNING,\n                             \"Could not remove PID file \\\"%s\\\": %s.\",\n                             config.pidpath, strerror (errno));\n        }\n\n#ifdef FILTER_ENABLE\n        if (config.filter)\n                filter_destroy ();\n#endif /* FILTER_ENABLE */\n\n        shutdown_logging ();\n\n        return EXIT_SUCCESS;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -53,6 +53,15 @@\n                 exit (EX_OSERR);\n         }\n \n+        /* Create pid file before we drop privileges */\n+        if (config.pidpath) {\n+                if (pidfile_create (config.pidpath) < 0) {\n+                        fprintf (stderr, \"%s: Could not create PID file.\\n\",\n+                                 argv[0]);\n+                        exit (EX_OSERR);\n+                }\n+        }\n+\n         /* Switch to a different user if we're running as root */\n         if (geteuid () == 0)\n                 change_user (argv[0]);\n@@ -63,15 +72,6 @@\n         /* Create log file after we drop privileges */\n         if (setup_logging ()) {\n                 exit (EX_SOFTWARE);\n-        }\n-\n-        /* Create pid file after we drop privileges */\n-        if (config.pidpath) {\n-                if (pidfile_create (config.pidpath) < 0) {\n-                        fprintf (stderr, \"%s: Could not create PID file.\\n\",\n-                                 argv[0]);\n-                        exit (EX_OSERR);\n-                }\n         }\n \n         if (child_pool_create () < 0) {",
        "diff_line_info": {
            "deleted_lines": [
                "        }",
                "",
                "        /* Create pid file after we drop privileges */",
                "        if (config.pidpath) {",
                "                if (pidfile_create (config.pidpath) < 0) {",
                "                        fprintf (stderr, \"%s: Could not create PID file.\\n\",",
                "                                 argv[0]);",
                "                        exit (EX_OSERR);",
                "                }"
            ],
            "added_lines": [
                "        /* Create pid file before we drop privileges */",
                "        if (config.pidpath) {",
                "                if (pidfile_create (config.pidpath) < 0) {",
                "                        fprintf (stderr, \"%s: Could not create PID file.\\n\",",
                "                                 argv[0]);",
                "                        exit (EX_OSERR);",
                "                }",
                "        }",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2008-2931",
        "func_name": "torvalds/linux/do_change_type",
        "description": "The do_change_type function in fs/namespace.c in the Linux kernel before 2.6.22 does not verify that the caller has the CAP_SYS_ADMIN capability, which allows local users to gain privileges or cause a denial of service by modifying the properties of a mountpoint.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commitdiff;h=ee6f958291e2a768fd727e7a67badfff0b67711a",
        "commit_title": "There's a missing check for CAP_SYS_ADMIN in do_change_type().",
        "commit_text": " Cc: Al Viro <viro@zeniv.linux.org.uk> Cc: Christoph Hellwig <hch@lst.de> ",
        "func_before": "static int do_change_type(struct nameidata *nd, int flag)\n{\n\tstruct vfsmount *m, *mnt = nd->mnt;\n\tint recurse = flag & MS_REC;\n\tint type = flag & ~MS_REC;\n\n\tif (nd->dentry != nd->mnt->mnt_root)\n\t\treturn -EINVAL;\n\n\tdown_write(&namespace_sem);\n\tspin_lock(&vfsmount_lock);\n\tfor (m = mnt; m; m = (recurse ? next_mnt(m, mnt) : NULL))\n\t\tchange_mnt_propagation(m, type);\n\tspin_unlock(&vfsmount_lock);\n\tup_write(&namespace_sem);\n\treturn 0;\n}",
        "func": "static int do_change_type(struct nameidata *nd, int flag)\n{\n\tstruct vfsmount *m, *mnt = nd->mnt;\n\tint recurse = flag & MS_REC;\n\tint type = flag & ~MS_REC;\n\n\tif (!capable(CAP_SYS_ADMIN))\n\t\treturn -EPERM;\n\n\tif (nd->dentry != nd->mnt->mnt_root)\n\t\treturn -EINVAL;\n\n\tdown_write(&namespace_sem);\n\tspin_lock(&vfsmount_lock);\n\tfor (m = mnt; m; m = (recurse ? next_mnt(m, mnt) : NULL))\n\t\tchange_mnt_propagation(m, type);\n\tspin_unlock(&vfsmount_lock);\n\tup_write(&namespace_sem);\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,6 +3,9 @@\n \tstruct vfsmount *m, *mnt = nd->mnt;\n \tint recurse = flag & MS_REC;\n \tint type = flag & ~MS_REC;\n+\n+\tif (!capable(CAP_SYS_ADMIN))\n+\t\treturn -EPERM;\n \n \tif (nd->dentry != nd->mnt->mnt_root)\n \t\treturn -EINVAL;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "\tif (!capable(CAP_SYS_ADMIN))",
                "\t\treturn -EPERM;"
            ]
        }
    },
    {
        "cve_id": "CVE-2023-6507",
        "func_name": "python/cpython/child_exec",
        "description": "An issue was found in CPython 3.12.0 `subprocess` module on POSIX platforms. The issue was fixed in CPython 3.12.1 and does not affect other stable releases.\n\nWhen using the `extra_groups=` parameter with an empty list as a value (ie `extra_groups=[]`) the logic regressed to not call `setgroups(0, NULL)` before calling `exec()`, thus not dropping the original processes' groups before starting the new process. There is no issue when the parameter isn't used or when any value is used besides an empty list.\n\nThis issue only impacts CPython processes run with sufficient privilege to make the `setgroups` system call (typically `root`).\n\n",
        "git_url": "https://github.com/python/cpython/commit/7a896fc464a6bceb9b95268b0141667645b2a8da",
        "commit_title": "gh-112334: Restore subprocess's use of `vfork()` & fix `extra_groups=[]`.",
        "commit_text": " Fixed a performance regression in 3.12's :mod:`subprocess` on Linux where it would no longer use the fast-path ``vfork()`` system call when it could have due to a logic bug, instead falling back to the safe but slower ``fork()``.  Also fixed a second 3.12.0 potential security bug.  If a value of ``extra_groups=[]`` was passed to :mod:`subprocess.Popen` or related APIs, the underlying ``setgroups(0, NULL)`` system call to clear the groups list would not be made in the child process prior to ``exec()``.  The security issue was identified via code inspection in the process of fixing the first bug.  Thanks to @vain for the detailed report and analysis in the initial bug on Github.   * [ ] A regression test is desirable. I'm pondering a test that runs when    `strace` is available and permitted which and confirms use of `vfork()`    vs `clone()`...",
        "func_before": "Py_NO_INLINE static void\nchild_exec(char *const exec_array[],\n           char *const argv[],\n           char *const envp[],\n           const char *cwd,\n           int p2cread, int p2cwrite,\n           int c2pread, int c2pwrite,\n           int errread, int errwrite,\n           int errpipe_read, int errpipe_write,\n           int close_fds, int restore_signals,\n           int call_setsid, pid_t pgid_to_set,\n           gid_t gid,\n           Py_ssize_t extra_group_size, const gid_t *extra_groups,\n           uid_t uid, int child_umask,\n           const void *child_sigmask,\n           int *fds_to_keep, Py_ssize_t fds_to_keep_len,\n           PyObject *preexec_fn,\n           PyObject *preexec_fn_args_tuple)\n{\n    int i, saved_errno, reached_preexec = 0;\n    PyObject *result;\n    const char* err_msg = \"\";\n    /* Buffer large enough to hold a hex integer.  We can't malloc. */\n    char hex_errno[sizeof(saved_errno)*2+1];\n\n    if (make_inheritable(fds_to_keep, fds_to_keep_len, errpipe_write) < 0)\n        goto error;\n\n    /* Close parent's pipe ends. */\n    if (p2cwrite != -1)\n        POSIX_CALL(close(p2cwrite));\n    if (c2pread != -1)\n        POSIX_CALL(close(c2pread));\n    if (errread != -1)\n        POSIX_CALL(close(errread));\n    POSIX_CALL(close(errpipe_read));\n\n    /* When duping fds, if there arises a situation where one of the fds is\n       either 0, 1 or 2, it is possible that it is overwritten (#12607). */\n    if (c2pwrite == 0) {\n        POSIX_CALL(c2pwrite = dup(c2pwrite));\n        /* issue32270 */\n        if (_Py_set_inheritable_async_safe(c2pwrite, 0, NULL) < 0) {\n            goto error;\n        }\n    }\n    while (errwrite == 0 || errwrite == 1) {\n        POSIX_CALL(errwrite = dup(errwrite));\n        /* issue32270 */\n        if (_Py_set_inheritable_async_safe(errwrite, 0, NULL) < 0) {\n            goto error;\n        }\n    }\n\n    /* Dup fds for child.\n       dup2() removes the CLOEXEC flag but we must do it ourselves if dup2()\n       would be a no-op (issue #10806). */\n    if (p2cread == 0) {\n        if (_Py_set_inheritable_async_safe(p2cread, 1, NULL) < 0)\n            goto error;\n    }\n    else if (p2cread != -1)\n        POSIX_CALL(dup2(p2cread, 0));  /* stdin */\n\n    if (c2pwrite == 1) {\n        if (_Py_set_inheritable_async_safe(c2pwrite, 1, NULL) < 0)\n            goto error;\n    }\n    else if (c2pwrite != -1)\n        POSIX_CALL(dup2(c2pwrite, 1));  /* stdout */\n\n    if (errwrite == 2) {\n        if (_Py_set_inheritable_async_safe(errwrite, 1, NULL) < 0)\n            goto error;\n    }\n    else if (errwrite != -1)\n        POSIX_CALL(dup2(errwrite, 2));  /* stderr */\n\n    /* We no longer manually close p2cread, c2pwrite, and errwrite here as\n     * _close_open_fds takes care when it is not already non-inheritable. */\n\n    if (cwd)\n        POSIX_CALL(chdir(cwd));\n\n    if (child_umask >= 0)\n        umask(child_umask);  /* umask() always succeeds. */\n\n    if (restore_signals) {\n        _Py_RestoreSignals();\n    }\n\n#ifdef VFORK_USABLE\n    if (child_sigmask) {\n        reset_signal_handlers(child_sigmask);\n        if ((errno = pthread_sigmask(SIG_SETMASK, child_sigmask, NULL))) {\n            goto error;\n        }\n    }\n#endif\n\n#ifdef HAVE_SETSID\n    if (call_setsid)\n        POSIX_CALL(setsid());\n#endif\n\n#ifdef HAVE_SETPGID\n    static_assert(_Py_IS_TYPE_SIGNED(pid_t), \"pid_t is unsigned\");\n    if (pgid_to_set >= 0) {\n        POSIX_CALL(setpgid(0, pgid_to_set));\n    }\n#endif\n\n#ifdef HAVE_SETGROUPS\n    if (extra_group_size > 0)\n        POSIX_CALL(setgroups(extra_group_size, extra_groups));\n#endif /* HAVE_SETGROUPS */\n\n#ifdef HAVE_SETREGID\n    if (gid != (gid_t)-1)\n        POSIX_CALL(setregid(gid, gid));\n#endif /* HAVE_SETREGID */\n\n#ifdef HAVE_SETREUID\n    if (uid != (uid_t)-1)\n        POSIX_CALL(setreuid(uid, uid));\n#endif /* HAVE_SETREUID */\n\n\n    reached_preexec = 1;\n    if (preexec_fn != Py_None && preexec_fn_args_tuple) {\n        /* This is where the user has asked us to deadlock their program. */\n        result = PyObject_Call(preexec_fn, preexec_fn_args_tuple, NULL);\n        if (result == NULL) {\n            /* Stringifying the exception or traceback would involve\n             * memory allocation and thus potential for deadlock.\n             * We've already faced potential deadlock by calling back\n             * into Python in the first place, so it probably doesn't\n             * matter but we avoid it to minimize the possibility. */\n            err_msg = \"Exception occurred in preexec_fn.\";\n            errno = 0;  /* We don't want to report an OSError. */\n            goto error;\n        }\n        /* Py_DECREF(result); - We're about to exec so why bother? */\n    }\n\n    /* close FDs after executing preexec_fn, which might open FDs */\n    if (close_fds) {\n        /* TODO HP-UX could use pstat_getproc() if anyone cares about it. */\n        _close_open_fds(3, fds_to_keep, fds_to_keep_len);\n    }\n\n    /* This loop matches the Lib/os.py _execvpe()'s PATH search when */\n    /* given the executable_list generated by Lib/subprocess.py.     */\n    saved_errno = 0;\n    for (i = 0; exec_array[i] != NULL; ++i) {\n        const char *executable = exec_array[i];\n        if (envp) {\n            execve(executable, argv, envp);\n        } else {\n            execv(executable, argv);\n        }\n        if (errno != ENOENT && errno != ENOTDIR && saved_errno == 0) {\n            saved_errno = errno;\n        }\n    }\n    /* Report the first exec error, not the last. */\n    if (saved_errno)\n        errno = saved_errno;\n\nerror:\n    saved_errno = errno;\n    /* Report the posix error to our parent process. */\n    /* We ignore all write() return values as the total size of our writes is\n       less than PIPEBUF and we cannot do anything about an error anyways.\n       Use _Py_write_noraise() to retry write() if it is interrupted by a\n       signal (fails with EINTR). */\n    if (saved_errno) {\n        char *cur;\n        _Py_write_noraise(errpipe_write, \"OSError:\", 8);\n        cur = hex_errno + sizeof(hex_errno);\n        while (saved_errno != 0 && cur != hex_errno) {\n            *--cur = Py_hexdigits[saved_errno % 16];\n            saved_errno /= 16;\n        }\n        _Py_write_noraise(errpipe_write, cur, hex_errno + sizeof(hex_errno) - cur);\n        _Py_write_noraise(errpipe_write, \":\", 1);\n        if (!reached_preexec) {\n            /* Indicate to the parent that the error happened before exec(). */\n            _Py_write_noraise(errpipe_write, \"noexec\", 6);\n        }\n        /* We can't call strerror(saved_errno).  It is not async signal safe.\n         * The parent process will look the error message up. */\n    } else {\n        _Py_write_noraise(errpipe_write, \"SubprocessError:0:\", 18);\n        _Py_write_noraise(errpipe_write, err_msg, strlen(err_msg));\n    }\n}",
        "func": "Py_NO_INLINE static void\nchild_exec(char *const exec_array[],\n           char *const argv[],\n           char *const envp[],\n           const char *cwd,\n           int p2cread, int p2cwrite,\n           int c2pread, int c2pwrite,\n           int errread, int errwrite,\n           int errpipe_read, int errpipe_write,\n           int close_fds, int restore_signals,\n           int call_setsid, pid_t pgid_to_set,\n           gid_t gid,\n           Py_ssize_t extra_group_size, const gid_t *extra_groups,\n           uid_t uid, int child_umask,\n           const void *child_sigmask,\n           int *fds_to_keep, Py_ssize_t fds_to_keep_len,\n           PyObject *preexec_fn,\n           PyObject *preexec_fn_args_tuple)\n{\n    int i, saved_errno, reached_preexec = 0;\n    PyObject *result;\n    const char* err_msg = \"\";\n    /* Buffer large enough to hold a hex integer.  We can't malloc. */\n    char hex_errno[sizeof(saved_errno)*2+1];\n\n    if (make_inheritable(fds_to_keep, fds_to_keep_len, errpipe_write) < 0)\n        goto error;\n\n    /* Close parent's pipe ends. */\n    if (p2cwrite != -1)\n        POSIX_CALL(close(p2cwrite));\n    if (c2pread != -1)\n        POSIX_CALL(close(c2pread));\n    if (errread != -1)\n        POSIX_CALL(close(errread));\n    POSIX_CALL(close(errpipe_read));\n\n    /* When duping fds, if there arises a situation where one of the fds is\n       either 0, 1 or 2, it is possible that it is overwritten (#12607). */\n    if (c2pwrite == 0) {\n        POSIX_CALL(c2pwrite = dup(c2pwrite));\n        /* issue32270 */\n        if (_Py_set_inheritable_async_safe(c2pwrite, 0, NULL) < 0) {\n            goto error;\n        }\n    }\n    while (errwrite == 0 || errwrite == 1) {\n        POSIX_CALL(errwrite = dup(errwrite));\n        /* issue32270 */\n        if (_Py_set_inheritable_async_safe(errwrite, 0, NULL) < 0) {\n            goto error;\n        }\n    }\n\n    /* Dup fds for child.\n       dup2() removes the CLOEXEC flag but we must do it ourselves if dup2()\n       would be a no-op (issue #10806). */\n    if (p2cread == 0) {\n        if (_Py_set_inheritable_async_safe(p2cread, 1, NULL) < 0)\n            goto error;\n    }\n    else if (p2cread != -1)\n        POSIX_CALL(dup2(p2cread, 0));  /* stdin */\n\n    if (c2pwrite == 1) {\n        if (_Py_set_inheritable_async_safe(c2pwrite, 1, NULL) < 0)\n            goto error;\n    }\n    else if (c2pwrite != -1)\n        POSIX_CALL(dup2(c2pwrite, 1));  /* stdout */\n\n    if (errwrite == 2) {\n        if (_Py_set_inheritable_async_safe(errwrite, 1, NULL) < 0)\n            goto error;\n    }\n    else if (errwrite != -1)\n        POSIX_CALL(dup2(errwrite, 2));  /* stderr */\n\n    /* We no longer manually close p2cread, c2pwrite, and errwrite here as\n     * _close_open_fds takes care when it is not already non-inheritable. */\n\n    if (cwd)\n        POSIX_CALL(chdir(cwd));\n\n    if (child_umask >= 0)\n        umask(child_umask);  /* umask() always succeeds. */\n\n    if (restore_signals) {\n        _Py_RestoreSignals();\n    }\n\n#ifdef VFORK_USABLE\n    if (child_sigmask) {\n        reset_signal_handlers(child_sigmask);\n        if ((errno = pthread_sigmask(SIG_SETMASK, child_sigmask, NULL))) {\n            goto error;\n        }\n    }\n#endif\n\n#ifdef HAVE_SETSID\n    if (call_setsid)\n        POSIX_CALL(setsid());\n#endif\n\n#ifdef HAVE_SETPGID\n    static_assert(_Py_IS_TYPE_SIGNED(pid_t), \"pid_t is unsigned\");\n    if (pgid_to_set >= 0) {\n        POSIX_CALL(setpgid(0, pgid_to_set));\n    }\n#endif\n\n#ifdef HAVE_SETGROUPS\n    if (extra_group_size >= 0) {\n        assert(extra_group_size == 0 && extra_groups == NULL || extra_group_size);\n        POSIX_CALL(setgroups(extra_group_size, extra_groups));\n    }\n#endif /* HAVE_SETGROUPS */\n\n#ifdef HAVE_SETREGID\n    if (gid != (gid_t)-1)\n        POSIX_CALL(setregid(gid, gid));\n#endif /* HAVE_SETREGID */\n\n#ifdef HAVE_SETREUID\n    if (uid != (uid_t)-1)\n        POSIX_CALL(setreuid(uid, uid));\n#endif /* HAVE_SETREUID */\n\n\n    reached_preexec = 1;\n    if (preexec_fn != Py_None && preexec_fn_args_tuple) {\n        /* This is where the user has asked us to deadlock their program. */\n        result = PyObject_Call(preexec_fn, preexec_fn_args_tuple, NULL);\n        if (result == NULL) {\n            /* Stringifying the exception or traceback would involve\n             * memory allocation and thus potential for deadlock.\n             * We've already faced potential deadlock by calling back\n             * into Python in the first place, so it probably doesn't\n             * matter but we avoid it to minimize the possibility. */\n            err_msg = \"Exception occurred in preexec_fn.\";\n            errno = 0;  /* We don't want to report an OSError. */\n            goto error;\n        }\n        /* Py_DECREF(result); - We're about to exec so why bother? */\n    }\n\n    /* close FDs after executing preexec_fn, which might open FDs */\n    if (close_fds) {\n        /* TODO HP-UX could use pstat_getproc() if anyone cares about it. */\n        _close_open_fds(3, fds_to_keep, fds_to_keep_len);\n    }\n\n    /* This loop matches the Lib/os.py _execvpe()'s PATH search when */\n    /* given the executable_list generated by Lib/subprocess.py.     */\n    saved_errno = 0;\n    for (i = 0; exec_array[i] != NULL; ++i) {\n        const char *executable = exec_array[i];\n        if (envp) {\n            execve(executable, argv, envp);\n        } else {\n            execv(executable, argv);\n        }\n        if (errno != ENOENT && errno != ENOTDIR && saved_errno == 0) {\n            saved_errno = errno;\n        }\n    }\n    /* Report the first exec error, not the last. */\n    if (saved_errno)\n        errno = saved_errno;\n\nerror:\n    saved_errno = errno;\n    /* Report the posix error to our parent process. */\n    /* We ignore all write() return values as the total size of our writes is\n       less than PIPEBUF and we cannot do anything about an error anyways.\n       Use _Py_write_noraise() to retry write() if it is interrupted by a\n       signal (fails with EINTR). */\n    if (saved_errno) {\n        char *cur;\n        _Py_write_noraise(errpipe_write, \"OSError:\", 8);\n        cur = hex_errno + sizeof(hex_errno);\n        while (saved_errno != 0 && cur != hex_errno) {\n            *--cur = Py_hexdigits[saved_errno % 16];\n            saved_errno /= 16;\n        }\n        _Py_write_noraise(errpipe_write, cur, hex_errno + sizeof(hex_errno) - cur);\n        _Py_write_noraise(errpipe_write, \":\", 1);\n        if (!reached_preexec) {\n            /* Indicate to the parent that the error happened before exec(). */\n            _Py_write_noraise(errpipe_write, \"noexec\", 6);\n        }\n        /* We can't call strerror(saved_errno).  It is not async signal safe.\n         * The parent process will look the error message up. */\n    } else {\n        _Py_write_noraise(errpipe_write, \"SubprocessError:0:\", 18);\n        _Py_write_noraise(errpipe_write, err_msg, strlen(err_msg));\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -111,8 +111,10 @@\n #endif\n \n #ifdef HAVE_SETGROUPS\n-    if (extra_group_size > 0)\n+    if (extra_group_size >= 0) {\n+        assert(extra_group_size == 0 && extra_groups == NULL || extra_group_size);\n         POSIX_CALL(setgroups(extra_group_size, extra_groups));\n+    }\n #endif /* HAVE_SETGROUPS */\n \n #ifdef HAVE_SETREGID",
        "diff_line_info": {
            "deleted_lines": [
                "    if (extra_group_size > 0)"
            ],
            "added_lines": [
                "    if (extra_group_size >= 0) {",
                "        assert(extra_group_size == 0 && extra_groups == NULL || extra_group_size);",
                "    }"
            ]
        }
    },
    {
        "cve_id": "CVE-2023-6507",
        "func_name": "python/cpython/subprocess_fork_exec_impl",
        "description": "An issue was found in CPython 3.12.0 `subprocess` module on POSIX platforms. The issue was fixed in CPython 3.12.1 and does not affect other stable releases.\n\nWhen using the `extra_groups=` parameter with an empty list as a value (ie `extra_groups=[]`) the logic regressed to not call `setgroups(0, NULL)` before calling `exec()`, thus not dropping the original processes' groups before starting the new process. There is no issue when the parameter isn't used or when any value is used besides an empty list.\n\nThis issue only impacts CPython processes run with sufficient privilege to make the `setgroups` system call (typically `root`).\n\n",
        "git_url": "https://github.com/python/cpython/commit/7a896fc464a6bceb9b95268b0141667645b2a8da",
        "commit_title": "gh-112334: Restore subprocess's use of `vfork()` & fix `extra_groups=[]`.",
        "commit_text": " Fixed a performance regression in 3.12's :mod:`subprocess` on Linux where it would no longer use the fast-path ``vfork()`` system call when it could have due to a logic bug, instead falling back to the safe but slower ``fork()``.  Also fixed a second 3.12.0 potential security bug.  If a value of ``extra_groups=[]`` was passed to :mod:`subprocess.Popen` or related APIs, the underlying ``setgroups(0, NULL)`` system call to clear the groups list would not be made in the child process prior to ``exec()``.  The security issue was identified via code inspection in the process of fixing the first bug.  Thanks to @vain for the detailed report and analysis in the initial bug on Github.   * [ ] A regression test is desirable. I'm pondering a test that runs when    `strace` is available and permitted which and confirms use of `vfork()`    vs `clone()`...",
        "func_before": "static PyObject *\nsubprocess_fork_exec_impl(PyObject *module, PyObject *process_args,\n                          PyObject *executable_list, int close_fds,\n                          PyObject *py_fds_to_keep, PyObject *cwd_obj,\n                          PyObject *env_list, int p2cread, int p2cwrite,\n                          int c2pread, int c2pwrite, int errread,\n                          int errwrite, int errpipe_read, int errpipe_write,\n                          int restore_signals, int call_setsid,\n                          pid_t pgid_to_set, PyObject *gid_object,\n                          PyObject *extra_groups_packed,\n                          PyObject *uid_object, int child_umask,\n                          PyObject *preexec_fn, int allow_vfork)\n/*[clinic end generated code: output=7ee4f6ee5cf22b5b input=51757287ef266ffa]*/\n{\n    PyObject *converted_args = NULL, *fast_args = NULL;\n    PyObject *preexec_fn_args_tuple = NULL;\n    gid_t *extra_groups = NULL;\n    PyObject *cwd_obj2 = NULL;\n    const char *cwd = NULL;\n    pid_t pid = -1;\n    int need_to_reenable_gc = 0;\n    char *const *argv = NULL, *const *envp = NULL;\n    Py_ssize_t extra_group_size = 0;\n    int need_after_fork = 0;\n    int saved_errno = 0;\n    int *c_fds_to_keep = NULL;\n    Py_ssize_t fds_to_keep_len = PyTuple_GET_SIZE(py_fds_to_keep);\n\n    PyInterpreterState *interp = _PyInterpreterState_GET();\n    if ((preexec_fn != Py_None) && interp->finalizing) {\n        PyErr_SetString(PyExc_RuntimeError,\n                        \"preexec_fn not supported at interpreter shutdown\");\n        return NULL;\n    }\n    if ((preexec_fn != Py_None) && (interp != PyInterpreterState_Main())) {\n        PyErr_SetString(PyExc_RuntimeError,\n                        \"preexec_fn not supported within subinterpreters\");\n        return NULL;\n    }\n\n    if (close_fds && errpipe_write < 3) {  /* precondition */\n        PyErr_SetString(PyExc_ValueError, \"errpipe_write must be >= 3\");\n        return NULL;\n    }\n    if (_sanity_check_python_fd_sequence(py_fds_to_keep)) {\n        PyErr_SetString(PyExc_ValueError, \"bad value(s) in fds_to_keep\");\n        return NULL;\n    }\n\n    /* We need to call gc.disable() when we'll be calling preexec_fn */\n    if (preexec_fn != Py_None) {\n        need_to_reenable_gc = PyGC_Disable();\n    }\n\n    char *const *exec_array = _PySequence_BytesToCharpArray(executable_list);\n    if (!exec_array)\n        goto cleanup;\n\n    /* Convert args and env into appropriate arguments for exec() */\n    /* These conversions are done in the parent process to avoid allocating\n       or freeing memory in the child process. */\n    if (process_args != Py_None) {\n        Py_ssize_t num_args;\n        /* Equivalent to:  */\n        /*  tuple(PyUnicode_FSConverter(arg) for arg in process_args)  */\n        fast_args = PySequence_Fast(process_args, \"argv must be a tuple\");\n        if (fast_args == NULL)\n            goto cleanup;\n        num_args = PySequence_Fast_GET_SIZE(fast_args);\n        converted_args = PyTuple_New(num_args);\n        if (converted_args == NULL)\n            goto cleanup;\n        for (Py_ssize_t arg_num = 0; arg_num < num_args; ++arg_num) {\n            PyObject *borrowed_arg, *converted_arg;\n            if (PySequence_Fast_GET_SIZE(fast_args) != num_args) {\n                PyErr_SetString(PyExc_RuntimeError, \"args changed during iteration\");\n                goto cleanup;\n            }\n            borrowed_arg = PySequence_Fast_GET_ITEM(fast_args, arg_num);\n            if (PyUnicode_FSConverter(borrowed_arg, &converted_arg) == 0)\n                goto cleanup;\n            PyTuple_SET_ITEM(converted_args, arg_num, converted_arg);\n        }\n\n        argv = _PySequence_BytesToCharpArray(converted_args);\n        Py_CLEAR(converted_args);\n        Py_CLEAR(fast_args);\n        if (!argv)\n            goto cleanup;\n    }\n\n    if (env_list != Py_None) {\n        envp = _PySequence_BytesToCharpArray(env_list);\n        if (!envp)\n            goto cleanup;\n    }\n\n    if (cwd_obj != Py_None) {\n        if (PyUnicode_FSConverter(cwd_obj, &cwd_obj2) == 0)\n            goto cleanup;\n        cwd = PyBytes_AsString(cwd_obj2);\n    }\n\n    if (extra_groups_packed != Py_None) {\n#ifdef HAVE_SETGROUPS\n        if (!PyList_Check(extra_groups_packed)) {\n            PyErr_SetString(PyExc_TypeError,\n                    \"setgroups argument must be a list\");\n            goto cleanup;\n        }\n        extra_group_size = PySequence_Size(extra_groups_packed);\n\n        if (extra_group_size < 0)\n            goto cleanup;\n\n        if (extra_group_size > MAX_GROUPS) {\n            PyErr_SetString(PyExc_ValueError, \"too many extra_groups\");\n            goto cleanup;\n        }\n\n        /* Deliberately keep extra_groups == NULL for extra_group_size == 0 */\n        if (extra_group_size > 0) {\n            extra_groups = PyMem_RawMalloc(extra_group_size * sizeof(gid_t));\n            if (extra_groups == NULL) {\n                PyErr_SetString(PyExc_MemoryError,\n                        \"failed to allocate memory for group list\");\n                goto cleanup;\n            }\n        }\n\n        for (Py_ssize_t i = 0; i < extra_group_size; i++) {\n            PyObject *elem;\n            elem = PySequence_GetItem(extra_groups_packed, i);\n            if (!elem)\n                goto cleanup;\n            if (!PyLong_Check(elem)) {\n                PyErr_SetString(PyExc_TypeError,\n                                \"extra_groups must be integers\");\n                Py_DECREF(elem);\n                goto cleanup;\n            } else {\n                gid_t gid;\n                if (!_Py_Gid_Converter(elem, &gid)) {\n                    Py_DECREF(elem);\n                    PyErr_SetString(PyExc_ValueError, \"invalid group id\");\n                    goto cleanup;\n                }\n                extra_groups[i] = gid;\n            }\n            Py_DECREF(elem);\n        }\n\n#else /* HAVE_SETGROUPS */\n        PyErr_BadInternalCall();\n        goto cleanup;\n#endif /* HAVE_SETGROUPS */\n    }\n\n    gid_t gid = (gid_t)-1;\n    if (gid_object != Py_None) {\n#ifdef HAVE_SETREGID\n        if (!_Py_Gid_Converter(gid_object, &gid))\n            goto cleanup;\n\n#else /* HAVE_SETREGID */\n        PyErr_BadInternalCall();\n        goto cleanup;\n#endif /* HAVE_SETREUID */\n    }\n\n    uid_t uid = (uid_t)-1;\n    if (uid_object != Py_None) {\n#ifdef HAVE_SETREUID\n        if (!_Py_Uid_Converter(uid_object, &uid))\n            goto cleanup;\n\n#else /* HAVE_SETREUID */\n        PyErr_BadInternalCall();\n        goto cleanup;\n#endif /* HAVE_SETREUID */\n    }\n\n    c_fds_to_keep = PyMem_Malloc(fds_to_keep_len * sizeof(int));\n    if (c_fds_to_keep == NULL) {\n        PyErr_SetString(PyExc_MemoryError, \"failed to malloc c_fds_to_keep\");\n        goto cleanup;\n    }\n    if (convert_fds_to_keep_to_c(py_fds_to_keep, c_fds_to_keep) < 0) {\n        goto cleanup;\n    }\n\n    /* This must be the last thing done before fork() because we do not\n     * want to call PyOS_BeforeFork() if there is any chance of another\n     * error leading to the cleanup: code without calling fork(). */\n    if (preexec_fn != Py_None) {\n        preexec_fn_args_tuple = PyTuple_New(0);\n        if (!preexec_fn_args_tuple)\n            goto cleanup;\n        PyOS_BeforeFork();\n        need_after_fork = 1;\n    }\n\n    /* NOTE: When old_sigmask is non-NULL, do_fork_exec() may use vfork(). */\n    const void *old_sigmask = NULL;\n#ifdef VFORK_USABLE\n    /* Use vfork() only if it's safe. See the comment above child_exec(). */\n    sigset_t old_sigs;\n    if (preexec_fn == Py_None && allow_vfork &&\n        uid == (uid_t)-1 && gid == (gid_t)-1 && extra_group_size < 0) {\n        /* Block all signals to ensure that no signal handlers are run in the\n         * child process while it shares memory with us. Note that signals\n         * used internally by C libraries won't be blocked by\n         * pthread_sigmask(), but signal handlers installed by C libraries\n         * normally service only signals originating from *within the process*,\n         * so it should be sufficient to consider any library function that\n         * might send such a signal to be vfork-unsafe and do not call it in\n         * the child.\n         */\n        sigset_t all_sigs;\n        sigfillset(&all_sigs);\n        if ((saved_errno = pthread_sigmask(SIG_BLOCK, &all_sigs, &old_sigs))) {\n            goto cleanup;\n        }\n        old_sigmask = &old_sigs;\n    }\n#endif\n\n    pid = do_fork_exec(exec_array, argv, envp, cwd,\n                       p2cread, p2cwrite, c2pread, c2pwrite,\n                       errread, errwrite, errpipe_read, errpipe_write,\n                       close_fds, restore_signals, call_setsid, pgid_to_set,\n                       gid, extra_group_size, extra_groups,\n                       uid, child_umask, old_sigmask,\n                       c_fds_to_keep, fds_to_keep_len,\n                       preexec_fn, preexec_fn_args_tuple);\n\n    /* Parent (original) process */\n    if (pid == (pid_t)-1) {\n        /* Capture errno for the exception. */\n        saved_errno = errno;\n    }\n\n#ifdef VFORK_USABLE\n    if (old_sigmask) {\n        /* vfork() semantics guarantees that the parent is blocked\n         * until the child performs _exit() or execve(), so it is safe\n         * to unblock signals once we're here.\n         * Note that in environments where vfork() is implemented as fork(),\n         * such as QEMU user-mode emulation, the parent won't be blocked,\n         * but it won't share the address space with the child,\n         * so it's still safe to unblock the signals.\n         *\n         * We don't handle errors here because this call can't fail\n         * if valid arguments are given, and because there is no good\n         * way for the caller to deal with a failure to restore\n         * the thread signal mask. */\n        (void) pthread_sigmask(SIG_SETMASK, old_sigmask, NULL);\n    }\n#endif\n\n    if (need_after_fork)\n        PyOS_AfterFork_Parent();\n\ncleanup:\n    if (c_fds_to_keep != NULL) {\n        PyMem_Free(c_fds_to_keep);\n    }\n\n    if (saved_errno != 0) {\n        errno = saved_errno;\n        /* We can't call this above as PyOS_AfterFork_Parent() calls back\n         * into Python code which would see the unreturned error. */\n        PyErr_SetFromErrno(PyExc_OSError);\n    }\n\n    Py_XDECREF(preexec_fn_args_tuple);\n    PyMem_RawFree(extra_groups);\n    Py_XDECREF(cwd_obj2);\n    if (envp)\n        _Py_FreeCharPArray(envp);\n    Py_XDECREF(converted_args);\n    Py_XDECREF(fast_args);\n    if (argv)\n        _Py_FreeCharPArray(argv);\n    if (exec_array)\n        _Py_FreeCharPArray(exec_array);\n\n    if (need_to_reenable_gc) {\n        PyGC_Enable();\n    }\n\n    return pid == -1 ? NULL : PyLong_FromPid(pid);\n}",
        "func": "static PyObject *\nsubprocess_fork_exec_impl(PyObject *module, PyObject *process_args,\n                          PyObject *executable_list, int close_fds,\n                          PyObject *py_fds_to_keep, PyObject *cwd_obj,\n                          PyObject *env_list, int p2cread, int p2cwrite,\n                          int c2pread, int c2pwrite, int errread,\n                          int errwrite, int errpipe_read, int errpipe_write,\n                          int restore_signals, int call_setsid,\n                          pid_t pgid_to_set, PyObject *gid_object,\n                          PyObject *extra_groups_packed,\n                          PyObject *uid_object, int child_umask,\n                          PyObject *preexec_fn, int allow_vfork)\n/*[clinic end generated code: output=7ee4f6ee5cf22b5b input=51757287ef266ffa]*/\n{\n    PyObject *converted_args = NULL, *fast_args = NULL;\n    PyObject *preexec_fn_args_tuple = NULL;\n    gid_t *extra_groups = NULL;\n    PyObject *cwd_obj2 = NULL;\n    const char *cwd = NULL;\n    pid_t pid = -1;\n    int need_to_reenable_gc = 0;\n    char *const *argv = NULL, *const *envp = NULL;\n    int need_after_fork = 0;\n    int saved_errno = 0;\n    int *c_fds_to_keep = NULL;\n    Py_ssize_t fds_to_keep_len = PyTuple_GET_SIZE(py_fds_to_keep);\n\n    PyInterpreterState *interp = _PyInterpreterState_GET();\n    if ((preexec_fn != Py_None) && interp->finalizing) {\n        PyErr_SetString(PyExc_RuntimeError,\n                        \"preexec_fn not supported at interpreter shutdown\");\n        return NULL;\n    }\n    if ((preexec_fn != Py_None) && (interp != PyInterpreterState_Main())) {\n        PyErr_SetString(PyExc_RuntimeError,\n                        \"preexec_fn not supported within subinterpreters\");\n        return NULL;\n    }\n\n    if (close_fds && errpipe_write < 3) {  /* precondition */\n        PyErr_SetString(PyExc_ValueError, \"errpipe_write must be >= 3\");\n        return NULL;\n    }\n    if (_sanity_check_python_fd_sequence(py_fds_to_keep)) {\n        PyErr_SetString(PyExc_ValueError, \"bad value(s) in fds_to_keep\");\n        return NULL;\n    }\n\n    /* We need to call gc.disable() when we'll be calling preexec_fn */\n    if (preexec_fn != Py_None) {\n        need_to_reenable_gc = PyGC_Disable();\n    }\n\n    char *const *exec_array = _PySequence_BytesToCharpArray(executable_list);\n    if (!exec_array)\n        goto cleanup;\n\n    /* Convert args and env into appropriate arguments for exec() */\n    /* These conversions are done in the parent process to avoid allocating\n       or freeing memory in the child process. */\n    if (process_args != Py_None) {\n        Py_ssize_t num_args;\n        /* Equivalent to:  */\n        /*  tuple(PyUnicode_FSConverter(arg) for arg in process_args)  */\n        fast_args = PySequence_Fast(process_args, \"argv must be a tuple\");\n        if (fast_args == NULL)\n            goto cleanup;\n        num_args = PySequence_Fast_GET_SIZE(fast_args);\n        converted_args = PyTuple_New(num_args);\n        if (converted_args == NULL)\n            goto cleanup;\n        for (Py_ssize_t arg_num = 0; arg_num < num_args; ++arg_num) {\n            PyObject *borrowed_arg, *converted_arg;\n            if (PySequence_Fast_GET_SIZE(fast_args) != num_args) {\n                PyErr_SetString(PyExc_RuntimeError, \"args changed during iteration\");\n                goto cleanup;\n            }\n            borrowed_arg = PySequence_Fast_GET_ITEM(fast_args, arg_num);\n            if (PyUnicode_FSConverter(borrowed_arg, &converted_arg) == 0)\n                goto cleanup;\n            PyTuple_SET_ITEM(converted_args, arg_num, converted_arg);\n        }\n\n        argv = _PySequence_BytesToCharpArray(converted_args);\n        Py_CLEAR(converted_args);\n        Py_CLEAR(fast_args);\n        if (!argv)\n            goto cleanup;\n    }\n\n    if (env_list != Py_None) {\n        envp = _PySequence_BytesToCharpArray(env_list);\n        if (!envp)\n            goto cleanup;\n    }\n\n    if (cwd_obj != Py_None) {\n        if (PyUnicode_FSConverter(cwd_obj, &cwd_obj2) == 0)\n            goto cleanup;\n        cwd = PyBytes_AsString(cwd_obj2);\n    }\n\n    // Special initial value meaning that subprocess API was called with\n    // extra_groups=None leading to _posixsubprocess.fork_exec(gids=None).\n    // We use this to differentiate between code desiring a setgroups(0, NULL)\n    // call vs no call at all.  The fast vfork() code path could be used when\n    // there is no setgroups call.\n    Py_ssize_t extra_group_size = -2;\n\n    if (extra_groups_packed != Py_None) {\n#ifdef HAVE_SETGROUPS\n        if (!PyList_Check(extra_groups_packed)) {\n            PyErr_SetString(PyExc_TypeError,\n                    \"setgroups argument must be a list\");\n            goto cleanup;\n        }\n        extra_group_size = PySequence_Size(extra_groups_packed);\n\n        if (extra_group_size < 0)\n            goto cleanup;\n\n        if (extra_group_size > MAX_GROUPS) {\n            PyErr_SetString(PyExc_ValueError, \"too many extra_groups\");\n            goto cleanup;\n        }\n\n        /* Deliberately keep extra_groups == NULL for extra_group_size == 0 */\n        if (extra_group_size > 0) {\n            extra_groups = PyMem_RawMalloc(extra_group_size * sizeof(gid_t));\n            if (extra_groups == NULL) {\n                PyErr_SetString(PyExc_MemoryError,\n                        \"failed to allocate memory for group list\");\n                goto cleanup;\n            }\n        }\n\n        for (Py_ssize_t i = 0; i < extra_group_size; i++) {\n            PyObject *elem;\n            elem = PySequence_GetItem(extra_groups_packed, i);\n            if (!elem)\n                goto cleanup;\n            if (!PyLong_Check(elem)) {\n                PyErr_SetString(PyExc_TypeError,\n                                \"extra_groups must be integers\");\n                Py_DECREF(elem);\n                goto cleanup;\n            } else {\n                gid_t gid;\n                if (!_Py_Gid_Converter(elem, &gid)) {\n                    Py_DECREF(elem);\n                    PyErr_SetString(PyExc_ValueError, \"invalid group id\");\n                    goto cleanup;\n                }\n                extra_groups[i] = gid;\n            }\n            Py_DECREF(elem);\n        }\n\n#else /* HAVE_SETGROUPS */\n        PyErr_BadInternalCall();\n        goto cleanup;\n#endif /* HAVE_SETGROUPS */\n    }\n\n    gid_t gid = (gid_t)-1;\n    if (gid_object != Py_None) {\n#ifdef HAVE_SETREGID\n        if (!_Py_Gid_Converter(gid_object, &gid))\n            goto cleanup;\n\n#else /* HAVE_SETREGID */\n        PyErr_BadInternalCall();\n        goto cleanup;\n#endif /* HAVE_SETREUID */\n    }\n\n    uid_t uid = (uid_t)-1;\n    if (uid_object != Py_None) {\n#ifdef HAVE_SETREUID\n        if (!_Py_Uid_Converter(uid_object, &uid))\n            goto cleanup;\n\n#else /* HAVE_SETREUID */\n        PyErr_BadInternalCall();\n        goto cleanup;\n#endif /* HAVE_SETREUID */\n    }\n\n    c_fds_to_keep = PyMem_Malloc(fds_to_keep_len * sizeof(int));\n    if (c_fds_to_keep == NULL) {\n        PyErr_SetString(PyExc_MemoryError, \"failed to malloc c_fds_to_keep\");\n        goto cleanup;\n    }\n    if (convert_fds_to_keep_to_c(py_fds_to_keep, c_fds_to_keep) < 0) {\n        goto cleanup;\n    }\n\n    /* This must be the last thing done before fork() because we do not\n     * want to call PyOS_BeforeFork() if there is any chance of another\n     * error leading to the cleanup: code without calling fork(). */\n    if (preexec_fn != Py_None) {\n        preexec_fn_args_tuple = PyTuple_New(0);\n        if (!preexec_fn_args_tuple)\n            goto cleanup;\n        PyOS_BeforeFork();\n        need_after_fork = 1;\n    }\n\n    /* NOTE: When old_sigmask is non-NULL, do_fork_exec() may use vfork(). */\n    const void *old_sigmask = NULL;\n#ifdef VFORK_USABLE\n    /* Use vfork() only if it's safe. See the comment above child_exec(). */\n    sigset_t old_sigs;\n    if (preexec_fn == Py_None && allow_vfork &&\n        uid == (uid_t)-1 && gid == (gid_t)-1 && extra_group_size < 0) {\n        /* Block all signals to ensure that no signal handlers are run in the\n         * child process while it shares memory with us. Note that signals\n         * used internally by C libraries won't be blocked by\n         * pthread_sigmask(), but signal handlers installed by C libraries\n         * normally service only signals originating from *within the process*,\n         * so it should be sufficient to consider any library function that\n         * might send such a signal to be vfork-unsafe and do not call it in\n         * the child.\n         */\n        sigset_t all_sigs;\n        sigfillset(&all_sigs);\n        if ((saved_errno = pthread_sigmask(SIG_BLOCK, &all_sigs, &old_sigs))) {\n            goto cleanup;\n        }\n        old_sigmask = &old_sigs;\n    }\n#endif\n\n    pid = do_fork_exec(exec_array, argv, envp, cwd,\n                       p2cread, p2cwrite, c2pread, c2pwrite,\n                       errread, errwrite, errpipe_read, errpipe_write,\n                       close_fds, restore_signals, call_setsid, pgid_to_set,\n                       gid, extra_group_size, extra_groups,\n                       uid, child_umask, old_sigmask,\n                       c_fds_to_keep, fds_to_keep_len,\n                       preexec_fn, preexec_fn_args_tuple);\n\n    /* Parent (original) process */\n    if (pid == (pid_t)-1) {\n        /* Capture errno for the exception. */\n        saved_errno = errno;\n    }\n\n#ifdef VFORK_USABLE\n    if (old_sigmask) {\n        /* vfork() semantics guarantees that the parent is blocked\n         * until the child performs _exit() or execve(), so it is safe\n         * to unblock signals once we're here.\n         * Note that in environments where vfork() is implemented as fork(),\n         * such as QEMU user-mode emulation, the parent won't be blocked,\n         * but it won't share the address space with the child,\n         * so it's still safe to unblock the signals.\n         *\n         * We don't handle errors here because this call can't fail\n         * if valid arguments are given, and because there is no good\n         * way for the caller to deal with a failure to restore\n         * the thread signal mask. */\n        (void) pthread_sigmask(SIG_SETMASK, old_sigmask, NULL);\n    }\n#endif\n\n    if (need_after_fork)\n        PyOS_AfterFork_Parent();\n\ncleanup:\n    if (c_fds_to_keep != NULL) {\n        PyMem_Free(c_fds_to_keep);\n    }\n\n    if (saved_errno != 0) {\n        errno = saved_errno;\n        /* We can't call this above as PyOS_AfterFork_Parent() calls back\n         * into Python code which would see the unreturned error. */\n        PyErr_SetFromErrno(PyExc_OSError);\n    }\n\n    Py_XDECREF(preexec_fn_args_tuple);\n    PyMem_RawFree(extra_groups);\n    Py_XDECREF(cwd_obj2);\n    if (envp)\n        _Py_FreeCharPArray(envp);\n    Py_XDECREF(converted_args);\n    Py_XDECREF(fast_args);\n    if (argv)\n        _Py_FreeCharPArray(argv);\n    if (exec_array)\n        _Py_FreeCharPArray(exec_array);\n\n    if (need_to_reenable_gc) {\n        PyGC_Enable();\n    }\n\n    return pid == -1 ? NULL : PyLong_FromPid(pid);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -20,7 +20,6 @@\n     pid_t pid = -1;\n     int need_to_reenable_gc = 0;\n     char *const *argv = NULL, *const *envp = NULL;\n-    Py_ssize_t extra_group_size = 0;\n     int need_after_fork = 0;\n     int saved_errno = 0;\n     int *c_fds_to_keep = NULL;\n@@ -100,6 +99,13 @@\n             goto cleanup;\n         cwd = PyBytes_AsString(cwd_obj2);\n     }\n+\n+    // Special initial value meaning that subprocess API was called with\n+    // extra_groups=None leading to _posixsubprocess.fork_exec(gids=None).\n+    // We use this to differentiate between code desiring a setgroups(0, NULL)\n+    // call vs no call at all.  The fast vfork() code path could be used when\n+    // there is no setgroups call.\n+    Py_ssize_t extra_group_size = -2;\n \n     if (extra_groups_packed != Py_None) {\n #ifdef HAVE_SETGROUPS",
        "diff_line_info": {
            "deleted_lines": [
                "    Py_ssize_t extra_group_size = 0;"
            ],
            "added_lines": [
                "",
                "    // Special initial value meaning that subprocess API was called with",
                "    // extra_groups=None leading to _posixsubprocess.fork_exec(gids=None).",
                "    // We use this to differentiate between code desiring a setgroups(0, NULL)",
                "    // call vs no call at all.  The fast vfork() code path could be used when",
                "    // there is no setgroups call.",
                "    Py_ssize_t extra_group_size = -2;"
            ]
        }
    },
    {
        "cve_id": "CVE-2023-6507",
        "func_name": "python/cpython/child_exec",
        "description": "An issue was found in CPython 3.12.0 `subprocess` module on POSIX platforms. The issue was fixed in CPython 3.12.1 and does not affect other stable releases.\n\nWhen using the `extra_groups=` parameter with an empty list as a value (ie `extra_groups=[]`) the logic regressed to not call `setgroups(0, NULL)` before calling `exec()`, thus not dropping the original processes' groups before starting the new process. There is no issue when the parameter isn't used or when any value is used besides an empty list.\n\nThis issue only impacts CPython processes run with sufficient privilege to make the `setgroups` system call (typically `root`).\n\n",
        "git_url": "https://github.com/python/cpython/commit/84d060f0af01c5e6e3392095e62be621f95704f3",
        "commit_title": "Code Health (remove a compiler warning).",
        "commit_text": "",
        "func_before": "Py_NO_INLINE static void\nchild_exec(char *const exec_array[],\n           char *const argv[],\n           char *const envp[],\n           const char *cwd,\n           int p2cread, int p2cwrite,\n           int c2pread, int c2pwrite,\n           int errread, int errwrite,\n           int errpipe_read, int errpipe_write,\n           int close_fds, int restore_signals,\n           int call_setsid, pid_t pgid_to_set,\n           gid_t gid,\n           Py_ssize_t extra_group_size, const gid_t *extra_groups,\n           uid_t uid, int child_umask,\n           const void *child_sigmask,\n           int *fds_to_keep, Py_ssize_t fds_to_keep_len,\n           PyObject *preexec_fn,\n           PyObject *preexec_fn_args_tuple)\n{\n    int i, saved_errno, reached_preexec = 0;\n    PyObject *result;\n    const char* err_msg = \"\";\n    /* Buffer large enough to hold a hex integer.  We can't malloc. */\n    char hex_errno[sizeof(saved_errno)*2+1];\n\n    if (make_inheritable(fds_to_keep, fds_to_keep_len, errpipe_write) < 0)\n        goto error;\n\n    /* Close parent's pipe ends. */\n    if (p2cwrite != -1)\n        POSIX_CALL(close(p2cwrite));\n    if (c2pread != -1)\n        POSIX_CALL(close(c2pread));\n    if (errread != -1)\n        POSIX_CALL(close(errread));\n    POSIX_CALL(close(errpipe_read));\n\n    /* When duping fds, if there arises a situation where one of the fds is\n       either 0, 1 or 2, it is possible that it is overwritten (#12607). */\n    if (c2pwrite == 0) {\n        POSIX_CALL(c2pwrite = dup(c2pwrite));\n        /* issue32270 */\n        if (_Py_set_inheritable_async_safe(c2pwrite, 0, NULL) < 0) {\n            goto error;\n        }\n    }\n    while (errwrite == 0 || errwrite == 1) {\n        POSIX_CALL(errwrite = dup(errwrite));\n        /* issue32270 */\n        if (_Py_set_inheritable_async_safe(errwrite, 0, NULL) < 0) {\n            goto error;\n        }\n    }\n\n    /* Dup fds for child.\n       dup2() removes the CLOEXEC flag but we must do it ourselves if dup2()\n       would be a no-op (issue #10806). */\n    if (p2cread == 0) {\n        if (_Py_set_inheritable_async_safe(p2cread, 1, NULL) < 0)\n            goto error;\n    }\n    else if (p2cread != -1)\n        POSIX_CALL(dup2(p2cread, 0));  /* stdin */\n\n    if (c2pwrite == 1) {\n        if (_Py_set_inheritable_async_safe(c2pwrite, 1, NULL) < 0)\n            goto error;\n    }\n    else if (c2pwrite != -1)\n        POSIX_CALL(dup2(c2pwrite, 1));  /* stdout */\n\n    if (errwrite == 2) {\n        if (_Py_set_inheritable_async_safe(errwrite, 1, NULL) < 0)\n            goto error;\n    }\n    else if (errwrite != -1)\n        POSIX_CALL(dup2(errwrite, 2));  /* stderr */\n\n    /* We no longer manually close p2cread, c2pwrite, and errwrite here as\n     * _close_open_fds takes care when it is not already non-inheritable. */\n\n    if (cwd)\n        POSIX_CALL(chdir(cwd));\n\n    if (child_umask >= 0)\n        umask(child_umask);  /* umask() always succeeds. */\n\n    if (restore_signals) {\n        _Py_RestoreSignals();\n    }\n\n#ifdef VFORK_USABLE\n    if (child_sigmask) {\n        reset_signal_handlers(child_sigmask);\n        if ((errno = pthread_sigmask(SIG_SETMASK, child_sigmask, NULL))) {\n            goto error;\n        }\n    }\n#endif\n\n#ifdef HAVE_SETSID\n    if (call_setsid)\n        POSIX_CALL(setsid());\n#endif\n\n#ifdef HAVE_SETPGID\n    static_assert(_Py_IS_TYPE_SIGNED(pid_t), \"pid_t is unsigned\");\n    if (pgid_to_set >= 0) {\n        POSIX_CALL(setpgid(0, pgid_to_set));\n    }\n#endif\n\n#ifdef HAVE_SETGROUPS\n    if (extra_group_size >= 0) {\n        assert(extra_group_size == 0 && extra_groups == NULL || extra_group_size);\n        POSIX_CALL(setgroups(extra_group_size, extra_groups));\n    }\n#endif /* HAVE_SETGROUPS */\n\n#ifdef HAVE_SETREGID\n    if (gid != (gid_t)-1)\n        POSIX_CALL(setregid(gid, gid));\n#endif /* HAVE_SETREGID */\n\n#ifdef HAVE_SETREUID\n    if (uid != (uid_t)-1)\n        POSIX_CALL(setreuid(uid, uid));\n#endif /* HAVE_SETREUID */\n\n\n    reached_preexec = 1;\n    if (preexec_fn != Py_None && preexec_fn_args_tuple) {\n        /* This is where the user has asked us to deadlock their program. */\n        result = PyObject_Call(preexec_fn, preexec_fn_args_tuple, NULL);\n        if (result == NULL) {\n            /* Stringifying the exception or traceback would involve\n             * memory allocation and thus potential for deadlock.\n             * We've already faced potential deadlock by calling back\n             * into Python in the first place, so it probably doesn't\n             * matter but we avoid it to minimize the possibility. */\n            err_msg = \"Exception occurred in preexec_fn.\";\n            errno = 0;  /* We don't want to report an OSError. */\n            goto error;\n        }\n        /* Py_DECREF(result); - We're about to exec so why bother? */\n    }\n\n    /* close FDs after executing preexec_fn, which might open FDs */\n    if (close_fds) {\n        /* TODO HP-UX could use pstat_getproc() if anyone cares about it. */\n        _close_open_fds(3, fds_to_keep, fds_to_keep_len);\n    }\n\n    /* This loop matches the Lib/os.py _execvpe()'s PATH search when */\n    /* given the executable_list generated by Lib/subprocess.py.     */\n    saved_errno = 0;\n    for (i = 0; exec_array[i] != NULL; ++i) {\n        const char *executable = exec_array[i];\n        if (envp) {\n            execve(executable, argv, envp);\n        } else {\n            execv(executable, argv);\n        }\n        if (errno != ENOENT && errno != ENOTDIR && saved_errno == 0) {\n            saved_errno = errno;\n        }\n    }\n    /* Report the first exec error, not the last. */\n    if (saved_errno)\n        errno = saved_errno;\n\nerror:\n    saved_errno = errno;\n    /* Report the posix error to our parent process. */\n    /* We ignore all write() return values as the total size of our writes is\n       less than PIPEBUF and we cannot do anything about an error anyways.\n       Use _Py_write_noraise() to retry write() if it is interrupted by a\n       signal (fails with EINTR). */\n    if (saved_errno) {\n        char *cur;\n        _Py_write_noraise(errpipe_write, \"OSError:\", 8);\n        cur = hex_errno + sizeof(hex_errno);\n        while (saved_errno != 0 && cur != hex_errno) {\n            *--cur = Py_hexdigits[saved_errno % 16];\n            saved_errno /= 16;\n        }\n        _Py_write_noraise(errpipe_write, cur, hex_errno + sizeof(hex_errno) - cur);\n        _Py_write_noraise(errpipe_write, \":\", 1);\n        if (!reached_preexec) {\n            /* Indicate to the parent that the error happened before exec(). */\n            _Py_write_noraise(errpipe_write, \"noexec\", 6);\n        }\n        /* We can't call strerror(saved_errno).  It is not async signal safe.\n         * The parent process will look the error message up. */\n    } else {\n        _Py_write_noraise(errpipe_write, \"SubprocessError:0:\", 18);\n        _Py_write_noraise(errpipe_write, err_msg, strlen(err_msg));\n    }\n}",
        "func": "Py_NO_INLINE static void\nchild_exec(char *const exec_array[],\n           char *const argv[],\n           char *const envp[],\n           const char *cwd,\n           int p2cread, int p2cwrite,\n           int c2pread, int c2pwrite,\n           int errread, int errwrite,\n           int errpipe_read, int errpipe_write,\n           int close_fds, int restore_signals,\n           int call_setsid, pid_t pgid_to_set,\n           gid_t gid,\n           Py_ssize_t extra_group_size, const gid_t *extra_groups,\n           uid_t uid, int child_umask,\n           const void *child_sigmask,\n           int *fds_to_keep, Py_ssize_t fds_to_keep_len,\n           PyObject *preexec_fn,\n           PyObject *preexec_fn_args_tuple)\n{\n    int i, saved_errno, reached_preexec = 0;\n    PyObject *result;\n    const char* err_msg = \"\";\n    /* Buffer large enough to hold a hex integer.  We can't malloc. */\n    char hex_errno[sizeof(saved_errno)*2+1];\n\n    if (make_inheritable(fds_to_keep, fds_to_keep_len, errpipe_write) < 0)\n        goto error;\n\n    /* Close parent's pipe ends. */\n    if (p2cwrite != -1)\n        POSIX_CALL(close(p2cwrite));\n    if (c2pread != -1)\n        POSIX_CALL(close(c2pread));\n    if (errread != -1)\n        POSIX_CALL(close(errread));\n    POSIX_CALL(close(errpipe_read));\n\n    /* When duping fds, if there arises a situation where one of the fds is\n       either 0, 1 or 2, it is possible that it is overwritten (#12607). */\n    if (c2pwrite == 0) {\n        POSIX_CALL(c2pwrite = dup(c2pwrite));\n        /* issue32270 */\n        if (_Py_set_inheritable_async_safe(c2pwrite, 0, NULL) < 0) {\n            goto error;\n        }\n    }\n    while (errwrite == 0 || errwrite == 1) {\n        POSIX_CALL(errwrite = dup(errwrite));\n        /* issue32270 */\n        if (_Py_set_inheritable_async_safe(errwrite, 0, NULL) < 0) {\n            goto error;\n        }\n    }\n\n    /* Dup fds for child.\n       dup2() removes the CLOEXEC flag but we must do it ourselves if dup2()\n       would be a no-op (issue #10806). */\n    if (p2cread == 0) {\n        if (_Py_set_inheritable_async_safe(p2cread, 1, NULL) < 0)\n            goto error;\n    }\n    else if (p2cread != -1)\n        POSIX_CALL(dup2(p2cread, 0));  /* stdin */\n\n    if (c2pwrite == 1) {\n        if (_Py_set_inheritable_async_safe(c2pwrite, 1, NULL) < 0)\n            goto error;\n    }\n    else if (c2pwrite != -1)\n        POSIX_CALL(dup2(c2pwrite, 1));  /* stdout */\n\n    if (errwrite == 2) {\n        if (_Py_set_inheritable_async_safe(errwrite, 1, NULL) < 0)\n            goto error;\n    }\n    else if (errwrite != -1)\n        POSIX_CALL(dup2(errwrite, 2));  /* stderr */\n\n    /* We no longer manually close p2cread, c2pwrite, and errwrite here as\n     * _close_open_fds takes care when it is not already non-inheritable. */\n\n    if (cwd)\n        POSIX_CALL(chdir(cwd));\n\n    if (child_umask >= 0)\n        umask(child_umask);  /* umask() always succeeds. */\n\n    if (restore_signals) {\n        _Py_RestoreSignals();\n    }\n\n#ifdef VFORK_USABLE\n    if (child_sigmask) {\n        reset_signal_handlers(child_sigmask);\n        if ((errno = pthread_sigmask(SIG_SETMASK, child_sigmask, NULL))) {\n            goto error;\n        }\n    }\n#endif\n\n#ifdef HAVE_SETSID\n    if (call_setsid)\n        POSIX_CALL(setsid());\n#endif\n\n#ifdef HAVE_SETPGID\n    static_assert(_Py_IS_TYPE_SIGNED(pid_t), \"pid_t is unsigned\");\n    if (pgid_to_set >= 0) {\n        POSIX_CALL(setpgid(0, pgid_to_set));\n    }\n#endif\n\n#ifdef HAVE_SETGROUPS\n    if (extra_group_size >= 0) {\n        assert((extra_group_size == 0 && extra_groups == NULL) || extra_group_size);\n        POSIX_CALL(setgroups(extra_group_size, extra_groups));\n    }\n#endif /* HAVE_SETGROUPS */\n\n#ifdef HAVE_SETREGID\n    if (gid != (gid_t)-1)\n        POSIX_CALL(setregid(gid, gid));\n#endif /* HAVE_SETREGID */\n\n#ifdef HAVE_SETREUID\n    if (uid != (uid_t)-1)\n        POSIX_CALL(setreuid(uid, uid));\n#endif /* HAVE_SETREUID */\n\n\n    reached_preexec = 1;\n    if (preexec_fn != Py_None && preexec_fn_args_tuple) {\n        /* This is where the user has asked us to deadlock their program. */\n        result = PyObject_Call(preexec_fn, preexec_fn_args_tuple, NULL);\n        if (result == NULL) {\n            /* Stringifying the exception or traceback would involve\n             * memory allocation and thus potential for deadlock.\n             * We've already faced potential deadlock by calling back\n             * into Python in the first place, so it probably doesn't\n             * matter but we avoid it to minimize the possibility. */\n            err_msg = \"Exception occurred in preexec_fn.\";\n            errno = 0;  /* We don't want to report an OSError. */\n            goto error;\n        }\n        /* Py_DECREF(result); - We're about to exec so why bother? */\n    }\n\n    /* close FDs after executing preexec_fn, which might open FDs */\n    if (close_fds) {\n        /* TODO HP-UX could use pstat_getproc() if anyone cares about it. */\n        _close_open_fds(3, fds_to_keep, fds_to_keep_len);\n    }\n\n    /* This loop matches the Lib/os.py _execvpe()'s PATH search when */\n    /* given the executable_list generated by Lib/subprocess.py.     */\n    saved_errno = 0;\n    for (i = 0; exec_array[i] != NULL; ++i) {\n        const char *executable = exec_array[i];\n        if (envp) {\n            execve(executable, argv, envp);\n        } else {\n            execv(executable, argv);\n        }\n        if (errno != ENOENT && errno != ENOTDIR && saved_errno == 0) {\n            saved_errno = errno;\n        }\n    }\n    /* Report the first exec error, not the last. */\n    if (saved_errno)\n        errno = saved_errno;\n\nerror:\n    saved_errno = errno;\n    /* Report the posix error to our parent process. */\n    /* We ignore all write() return values as the total size of our writes is\n       less than PIPEBUF and we cannot do anything about an error anyways.\n       Use _Py_write_noraise() to retry write() if it is interrupted by a\n       signal (fails with EINTR). */\n    if (saved_errno) {\n        char *cur;\n        _Py_write_noraise(errpipe_write, \"OSError:\", 8);\n        cur = hex_errno + sizeof(hex_errno);\n        while (saved_errno != 0 && cur != hex_errno) {\n            *--cur = Py_hexdigits[saved_errno % 16];\n            saved_errno /= 16;\n        }\n        _Py_write_noraise(errpipe_write, cur, hex_errno + sizeof(hex_errno) - cur);\n        _Py_write_noraise(errpipe_write, \":\", 1);\n        if (!reached_preexec) {\n            /* Indicate to the parent that the error happened before exec(). */\n            _Py_write_noraise(errpipe_write, \"noexec\", 6);\n        }\n        /* We can't call strerror(saved_errno).  It is not async signal safe.\n         * The parent process will look the error message up. */\n    } else {\n        _Py_write_noraise(errpipe_write, \"SubprocessError:0:\", 18);\n        _Py_write_noraise(errpipe_write, err_msg, strlen(err_msg));\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -112,7 +112,7 @@\n \n #ifdef HAVE_SETGROUPS\n     if (extra_group_size >= 0) {\n-        assert(extra_group_size == 0 && extra_groups == NULL || extra_group_size);\n+        assert((extra_group_size == 0 && extra_groups == NULL) || extra_group_size);\n         POSIX_CALL(setgroups(extra_group_size, extra_groups));\n     }\n #endif /* HAVE_SETGROUPS */",
        "diff_line_info": {
            "deleted_lines": [
                "        assert(extra_group_size == 0 && extra_groups == NULL || extra_group_size);"
            ],
            "added_lines": [
                "        assert((extra_group_size == 0 && extra_groups == NULL) || extra_group_size);"
            ]
        }
    },
    {
        "cve_id": "CVE-2023-6507",
        "func_name": "python/cpython/child_exec",
        "description": "An issue was found in CPython 3.12.0 `subprocess` module on POSIX platforms. The issue was fixed in CPython 3.12.1 and does not affect other stable releases.\n\nWhen using the `extra_groups=` parameter with an empty list as a value (ie `extra_groups=[]`) the logic regressed to not call `setgroups(0, NULL)` before calling `exec()`, thus not dropping the original processes' groups before starting the new process. There is no issue when the parameter isn't used or when any value is used besides an empty list.\n\nThis issue only impacts CPython processes run with sufficient privilege to make the `setgroups` system call (typically `root`).\n\n",
        "git_url": "https://github.com/python/cpython/commit/52a475c4ec770a05286189a14970686e61bc0f24",
        "commit_title": "Improve the assertion.",
        "commit_text": " Co-authored-by: Serhiy Storchaka <storchaka@gmail.com>",
        "func_before": "Py_NO_INLINE static void\nchild_exec(char *const exec_array[],\n           char *const argv[],\n           char *const envp[],\n           const char *cwd,\n           int p2cread, int p2cwrite,\n           int c2pread, int c2pwrite,\n           int errread, int errwrite,\n           int errpipe_read, int errpipe_write,\n           int close_fds, int restore_signals,\n           int call_setsid, pid_t pgid_to_set,\n           gid_t gid,\n           Py_ssize_t extra_group_size, const gid_t *extra_groups,\n           uid_t uid, int child_umask,\n           const void *child_sigmask,\n           int *fds_to_keep, Py_ssize_t fds_to_keep_len,\n           PyObject *preexec_fn,\n           PyObject *preexec_fn_args_tuple)\n{\n    int i, saved_errno, reached_preexec = 0;\n    PyObject *result;\n    const char* err_msg = \"\";\n    /* Buffer large enough to hold a hex integer.  We can't malloc. */\n    char hex_errno[sizeof(saved_errno)*2+1];\n\n    if (make_inheritable(fds_to_keep, fds_to_keep_len, errpipe_write) < 0)\n        goto error;\n\n    /* Close parent's pipe ends. */\n    if (p2cwrite != -1)\n        POSIX_CALL(close(p2cwrite));\n    if (c2pread != -1)\n        POSIX_CALL(close(c2pread));\n    if (errread != -1)\n        POSIX_CALL(close(errread));\n    POSIX_CALL(close(errpipe_read));\n\n    /* When duping fds, if there arises a situation where one of the fds is\n       either 0, 1 or 2, it is possible that it is overwritten (#12607). */\n    if (c2pwrite == 0) {\n        POSIX_CALL(c2pwrite = dup(c2pwrite));\n        /* issue32270 */\n        if (_Py_set_inheritable_async_safe(c2pwrite, 0, NULL) < 0) {\n            goto error;\n        }\n    }\n    while (errwrite == 0 || errwrite == 1) {\n        POSIX_CALL(errwrite = dup(errwrite));\n        /* issue32270 */\n        if (_Py_set_inheritable_async_safe(errwrite, 0, NULL) < 0) {\n            goto error;\n        }\n    }\n\n    /* Dup fds for child.\n       dup2() removes the CLOEXEC flag but we must do it ourselves if dup2()\n       would be a no-op (issue #10806). */\n    if (p2cread == 0) {\n        if (_Py_set_inheritable_async_safe(p2cread, 1, NULL) < 0)\n            goto error;\n    }\n    else if (p2cread != -1)\n        POSIX_CALL(dup2(p2cread, 0));  /* stdin */\n\n    if (c2pwrite == 1) {\n        if (_Py_set_inheritable_async_safe(c2pwrite, 1, NULL) < 0)\n            goto error;\n    }\n    else if (c2pwrite != -1)\n        POSIX_CALL(dup2(c2pwrite, 1));  /* stdout */\n\n    if (errwrite == 2) {\n        if (_Py_set_inheritable_async_safe(errwrite, 1, NULL) < 0)\n            goto error;\n    }\n    else if (errwrite != -1)\n        POSIX_CALL(dup2(errwrite, 2));  /* stderr */\n\n    /* We no longer manually close p2cread, c2pwrite, and errwrite here as\n     * _close_open_fds takes care when it is not already non-inheritable. */\n\n    if (cwd)\n        POSIX_CALL(chdir(cwd));\n\n    if (child_umask >= 0)\n        umask(child_umask);  /* umask() always succeeds. */\n\n    if (restore_signals) {\n        _Py_RestoreSignals();\n    }\n\n#ifdef VFORK_USABLE\n    if (child_sigmask) {\n        reset_signal_handlers(child_sigmask);\n        if ((errno = pthread_sigmask(SIG_SETMASK, child_sigmask, NULL))) {\n            goto error;\n        }\n    }\n#endif\n\n#ifdef HAVE_SETSID\n    if (call_setsid)\n        POSIX_CALL(setsid());\n#endif\n\n#ifdef HAVE_SETPGID\n    static_assert(_Py_IS_TYPE_SIGNED(pid_t), \"pid_t is unsigned\");\n    if (pgid_to_set >= 0) {\n        POSIX_CALL(setpgid(0, pgid_to_set));\n    }\n#endif\n\n#ifdef HAVE_SETGROUPS\n    if (extra_group_size >= 0) {\n        assert((extra_group_size == 0 && extra_groups == NULL) || extra_group_size);\n        POSIX_CALL(setgroups(extra_group_size, extra_groups));\n    }\n#endif /* HAVE_SETGROUPS */\n\n#ifdef HAVE_SETREGID\n    if (gid != (gid_t)-1)\n        POSIX_CALL(setregid(gid, gid));\n#endif /* HAVE_SETREGID */\n\n#ifdef HAVE_SETREUID\n    if (uid != (uid_t)-1)\n        POSIX_CALL(setreuid(uid, uid));\n#endif /* HAVE_SETREUID */\n\n\n    reached_preexec = 1;\n    if (preexec_fn != Py_None && preexec_fn_args_tuple) {\n        /* This is where the user has asked us to deadlock their program. */\n        result = PyObject_Call(preexec_fn, preexec_fn_args_tuple, NULL);\n        if (result == NULL) {\n            /* Stringifying the exception or traceback would involve\n             * memory allocation and thus potential for deadlock.\n             * We've already faced potential deadlock by calling back\n             * into Python in the first place, so it probably doesn't\n             * matter but we avoid it to minimize the possibility. */\n            err_msg = \"Exception occurred in preexec_fn.\";\n            errno = 0;  /* We don't want to report an OSError. */\n            goto error;\n        }\n        /* Py_DECREF(result); - We're about to exec so why bother? */\n    }\n\n    /* close FDs after executing preexec_fn, which might open FDs */\n    if (close_fds) {\n        /* TODO HP-UX could use pstat_getproc() if anyone cares about it. */\n        _close_open_fds(3, fds_to_keep, fds_to_keep_len);\n    }\n\n    /* This loop matches the Lib/os.py _execvpe()'s PATH search when */\n    /* given the executable_list generated by Lib/subprocess.py.     */\n    saved_errno = 0;\n    for (i = 0; exec_array[i] != NULL; ++i) {\n        const char *executable = exec_array[i];\n        if (envp) {\n            execve(executable, argv, envp);\n        } else {\n            execv(executable, argv);\n        }\n        if (errno != ENOENT && errno != ENOTDIR && saved_errno == 0) {\n            saved_errno = errno;\n        }\n    }\n    /* Report the first exec error, not the last. */\n    if (saved_errno)\n        errno = saved_errno;\n\nerror:\n    saved_errno = errno;\n    /* Report the posix error to our parent process. */\n    /* We ignore all write() return values as the total size of our writes is\n       less than PIPEBUF and we cannot do anything about an error anyways.\n       Use _Py_write_noraise() to retry write() if it is interrupted by a\n       signal (fails with EINTR). */\n    if (saved_errno) {\n        char *cur;\n        _Py_write_noraise(errpipe_write, \"OSError:\", 8);\n        cur = hex_errno + sizeof(hex_errno);\n        while (saved_errno != 0 && cur != hex_errno) {\n            *--cur = Py_hexdigits[saved_errno % 16];\n            saved_errno /= 16;\n        }\n        _Py_write_noraise(errpipe_write, cur, hex_errno + sizeof(hex_errno) - cur);\n        _Py_write_noraise(errpipe_write, \":\", 1);\n        if (!reached_preexec) {\n            /* Indicate to the parent that the error happened before exec(). */\n            _Py_write_noraise(errpipe_write, \"noexec\", 6);\n        }\n        /* We can't call strerror(saved_errno).  It is not async signal safe.\n         * The parent process will look the error message up. */\n    } else {\n        _Py_write_noraise(errpipe_write, \"SubprocessError:0:\", 18);\n        _Py_write_noraise(errpipe_write, err_msg, strlen(err_msg));\n    }\n}",
        "func": "Py_NO_INLINE static void\nchild_exec(char *const exec_array[],\n           char *const argv[],\n           char *const envp[],\n           const char *cwd,\n           int p2cread, int p2cwrite,\n           int c2pread, int c2pwrite,\n           int errread, int errwrite,\n           int errpipe_read, int errpipe_write,\n           int close_fds, int restore_signals,\n           int call_setsid, pid_t pgid_to_set,\n           gid_t gid,\n           Py_ssize_t extra_group_size, const gid_t *extra_groups,\n           uid_t uid, int child_umask,\n           const void *child_sigmask,\n           int *fds_to_keep, Py_ssize_t fds_to_keep_len,\n           PyObject *preexec_fn,\n           PyObject *preexec_fn_args_tuple)\n{\n    int i, saved_errno, reached_preexec = 0;\n    PyObject *result;\n    const char* err_msg = \"\";\n    /* Buffer large enough to hold a hex integer.  We can't malloc. */\n    char hex_errno[sizeof(saved_errno)*2+1];\n\n    if (make_inheritable(fds_to_keep, fds_to_keep_len, errpipe_write) < 0)\n        goto error;\n\n    /* Close parent's pipe ends. */\n    if (p2cwrite != -1)\n        POSIX_CALL(close(p2cwrite));\n    if (c2pread != -1)\n        POSIX_CALL(close(c2pread));\n    if (errread != -1)\n        POSIX_CALL(close(errread));\n    POSIX_CALL(close(errpipe_read));\n\n    /* When duping fds, if there arises a situation where one of the fds is\n       either 0, 1 or 2, it is possible that it is overwritten (#12607). */\n    if (c2pwrite == 0) {\n        POSIX_CALL(c2pwrite = dup(c2pwrite));\n        /* issue32270 */\n        if (_Py_set_inheritable_async_safe(c2pwrite, 0, NULL) < 0) {\n            goto error;\n        }\n    }\n    while (errwrite == 0 || errwrite == 1) {\n        POSIX_CALL(errwrite = dup(errwrite));\n        /* issue32270 */\n        if (_Py_set_inheritable_async_safe(errwrite, 0, NULL) < 0) {\n            goto error;\n        }\n    }\n\n    /* Dup fds for child.\n       dup2() removes the CLOEXEC flag but we must do it ourselves if dup2()\n       would be a no-op (issue #10806). */\n    if (p2cread == 0) {\n        if (_Py_set_inheritable_async_safe(p2cread, 1, NULL) < 0)\n            goto error;\n    }\n    else if (p2cread != -1)\n        POSIX_CALL(dup2(p2cread, 0));  /* stdin */\n\n    if (c2pwrite == 1) {\n        if (_Py_set_inheritable_async_safe(c2pwrite, 1, NULL) < 0)\n            goto error;\n    }\n    else if (c2pwrite != -1)\n        POSIX_CALL(dup2(c2pwrite, 1));  /* stdout */\n\n    if (errwrite == 2) {\n        if (_Py_set_inheritable_async_safe(errwrite, 1, NULL) < 0)\n            goto error;\n    }\n    else if (errwrite != -1)\n        POSIX_CALL(dup2(errwrite, 2));  /* stderr */\n\n    /* We no longer manually close p2cread, c2pwrite, and errwrite here as\n     * _close_open_fds takes care when it is not already non-inheritable. */\n\n    if (cwd)\n        POSIX_CALL(chdir(cwd));\n\n    if (child_umask >= 0)\n        umask(child_umask);  /* umask() always succeeds. */\n\n    if (restore_signals) {\n        _Py_RestoreSignals();\n    }\n\n#ifdef VFORK_USABLE\n    if (child_sigmask) {\n        reset_signal_handlers(child_sigmask);\n        if ((errno = pthread_sigmask(SIG_SETMASK, child_sigmask, NULL))) {\n            goto error;\n        }\n    }\n#endif\n\n#ifdef HAVE_SETSID\n    if (call_setsid)\n        POSIX_CALL(setsid());\n#endif\n\n#ifdef HAVE_SETPGID\n    static_assert(_Py_IS_TYPE_SIGNED(pid_t), \"pid_t is unsigned\");\n    if (pgid_to_set >= 0) {\n        POSIX_CALL(setpgid(0, pgid_to_set));\n    }\n#endif\n\n#ifdef HAVE_SETGROUPS\n    if (extra_group_size >= 0) {\n        assert((extra_group_size == 0) == (extra_groups == NULL));\n        POSIX_CALL(setgroups(extra_group_size, extra_groups));\n    }\n#endif /* HAVE_SETGROUPS */\n\n#ifdef HAVE_SETREGID\n    if (gid != (gid_t)-1)\n        POSIX_CALL(setregid(gid, gid));\n#endif /* HAVE_SETREGID */\n\n#ifdef HAVE_SETREUID\n    if (uid != (uid_t)-1)\n        POSIX_CALL(setreuid(uid, uid));\n#endif /* HAVE_SETREUID */\n\n\n    reached_preexec = 1;\n    if (preexec_fn != Py_None && preexec_fn_args_tuple) {\n        /* This is where the user has asked us to deadlock their program. */\n        result = PyObject_Call(preexec_fn, preexec_fn_args_tuple, NULL);\n        if (result == NULL) {\n            /* Stringifying the exception or traceback would involve\n             * memory allocation and thus potential for deadlock.\n             * We've already faced potential deadlock by calling back\n             * into Python in the first place, so it probably doesn't\n             * matter but we avoid it to minimize the possibility. */\n            err_msg = \"Exception occurred in preexec_fn.\";\n            errno = 0;  /* We don't want to report an OSError. */\n            goto error;\n        }\n        /* Py_DECREF(result); - We're about to exec so why bother? */\n    }\n\n    /* close FDs after executing preexec_fn, which might open FDs */\n    if (close_fds) {\n        /* TODO HP-UX could use pstat_getproc() if anyone cares about it. */\n        _close_open_fds(3, fds_to_keep, fds_to_keep_len);\n    }\n\n    /* This loop matches the Lib/os.py _execvpe()'s PATH search when */\n    /* given the executable_list generated by Lib/subprocess.py.     */\n    saved_errno = 0;\n    for (i = 0; exec_array[i] != NULL; ++i) {\n        const char *executable = exec_array[i];\n        if (envp) {\n            execve(executable, argv, envp);\n        } else {\n            execv(executable, argv);\n        }\n        if (errno != ENOENT && errno != ENOTDIR && saved_errno == 0) {\n            saved_errno = errno;\n        }\n    }\n    /* Report the first exec error, not the last. */\n    if (saved_errno)\n        errno = saved_errno;\n\nerror:\n    saved_errno = errno;\n    /* Report the posix error to our parent process. */\n    /* We ignore all write() return values as the total size of our writes is\n       less than PIPEBUF and we cannot do anything about an error anyways.\n       Use _Py_write_noraise() to retry write() if it is interrupted by a\n       signal (fails with EINTR). */\n    if (saved_errno) {\n        char *cur;\n        _Py_write_noraise(errpipe_write, \"OSError:\", 8);\n        cur = hex_errno + sizeof(hex_errno);\n        while (saved_errno != 0 && cur != hex_errno) {\n            *--cur = Py_hexdigits[saved_errno % 16];\n            saved_errno /= 16;\n        }\n        _Py_write_noraise(errpipe_write, cur, hex_errno + sizeof(hex_errno) - cur);\n        _Py_write_noraise(errpipe_write, \":\", 1);\n        if (!reached_preexec) {\n            /* Indicate to the parent that the error happened before exec(). */\n            _Py_write_noraise(errpipe_write, \"noexec\", 6);\n        }\n        /* We can't call strerror(saved_errno).  It is not async signal safe.\n         * The parent process will look the error message up. */\n    } else {\n        _Py_write_noraise(errpipe_write, \"SubprocessError:0:\", 18);\n        _Py_write_noraise(errpipe_write, err_msg, strlen(err_msg));\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -112,7 +112,7 @@\n \n #ifdef HAVE_SETGROUPS\n     if (extra_group_size >= 0) {\n-        assert((extra_group_size == 0 && extra_groups == NULL) || extra_group_size);\n+        assert((extra_group_size == 0) == (extra_groups == NULL));\n         POSIX_CALL(setgroups(extra_group_size, extra_groups));\n     }\n #endif /* HAVE_SETGROUPS */",
        "diff_line_info": {
            "deleted_lines": [
                "        assert((extra_group_size == 0 && extra_groups == NULL) || extra_group_size);"
            ],
            "added_lines": [
                "        assert((extra_group_size == 0) == (extra_groups == NULL));"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-25595",
        "func_name": "xen-project/xen/_pci_cleanup_msix",
        "description": "An issue was discovered in Xen through 4.14.x. The PCI passthrough code improperly uses register data. Code paths in Xen's MSI handling have been identified that act on unsanitized values read back from device hardware registers. While devices strictly compliant with PCI specifications shouldn't be able to affect these registers, experience shows that it's very common for devices to have out-of-spec \"backdoor\" operations that can affect the result of these reads. A not fully trusted guest may be able to crash Xen, leading to a Denial of Service (DoS) for the entire system. Privilege escalation and information leaks cannot be excluded. All versions of Xen supporting PCI passthrough are affected. Only x86 systems are vulnerable. Arm systems are not vulnerable. Only guests with passed through PCI devices may be able to leverage the vulnerability. Only systems passing through devices with out-of-spec (\"backdoor\") functionality can cause issues. Experience shows that such out-of-spec functionality is common; unless you have reason to believe that your device does not have such functionality, it's better to assume that it does.",
        "git_url": "https://github.com/xen-project/xen/commit/beb54596cfdaf15f6a86d7b1bf84ca8a0b9c6b9b",
        "commit_title": "x86/MSI-X: restrict reading of table/PBA bases from BARs",
        "commit_text": " When assigned to less trusted or un-trusted guests, devices may change state behind our backs (they may e.g. get reset by means we may not know about). Therefore we should avoid reading BARs from hardware once a device is no longer owned by Dom0. Furthermore when we can't read a BAR, or when we read zero, we shouldn't instead use the caller provided address unless that caller can be trusted.  Re-arrange the logic in msix_capability_init() such that only Dom0 (and only if the device isn't DomU-owned yet) or calls through PHYSDEVOP_prepare_msix will actually result in the reading of the respective BAR register(s). Additionally do so only as long as in-use table entries are known (note that invocation of PHYSDEVOP_prepare_msix counts as a \"pseudo\" entry). In all other uses the value already recorded will get used instead.  Clear the recorded values in _pci_cleanup_msix() as well as on the one affected error path. (Adjust this error path to also avoid blindly disabling MSI-X when it was enabled on entry to the function.)  While moving around variable declarations (in many cases to reduce their scopes), also adjust some of their types.  This is part of XSA-337. ",
        "func_before": "static void _pci_cleanup_msix(struct arch_msix *msix)\n{\n    if ( !--msix->used_entries )\n    {\n        if ( rangeset_remove_range(mmio_ro_ranges, msix->table.first,\n                                   msix->table.last) )\n            WARN();\n        if ( rangeset_remove_range(mmio_ro_ranges, msix->pba.first,\n                                   msix->pba.last) )\n            WARN();\n    }\n}",
        "func": "static void _pci_cleanup_msix(struct arch_msix *msix)\n{\n    if ( !--msix->used_entries )\n    {\n        if ( rangeset_remove_range(mmio_ro_ranges, msix->table.first,\n                                   msix->table.last) )\n            WARN();\n        msix->table.first = 0;\n        msix->table.last = 0;\n\n        if ( rangeset_remove_range(mmio_ro_ranges, msix->pba.first,\n                                   msix->pba.last) )\n            WARN();\n        msix->pba.first = 0;\n        msix->pba.last = 0;\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,8 +5,13 @@\n         if ( rangeset_remove_range(mmio_ro_ranges, msix->table.first,\n                                    msix->table.last) )\n             WARN();\n+        msix->table.first = 0;\n+        msix->table.last = 0;\n+\n         if ( rangeset_remove_range(mmio_ro_ranges, msix->pba.first,\n                                    msix->pba.last) )\n             WARN();\n+        msix->pba.first = 0;\n+        msix->pba.last = 0;\n     }\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "        msix->table.first = 0;",
                "        msix->table.last = 0;",
                "",
                "        msix->pba.first = 0;",
                "        msix->pba.last = 0;"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-25595",
        "func_name": "xen-project/xen/msix_capability_init",
        "description": "An issue was discovered in Xen through 4.14.x. The PCI passthrough code improperly uses register data. Code paths in Xen's MSI handling have been identified that act on unsanitized values read back from device hardware registers. While devices strictly compliant with PCI specifications shouldn't be able to affect these registers, experience shows that it's very common for devices to have out-of-spec \"backdoor\" operations that can affect the result of these reads. A not fully trusted guest may be able to crash Xen, leading to a Denial of Service (DoS) for the entire system. Privilege escalation and information leaks cannot be excluded. All versions of Xen supporting PCI passthrough are affected. Only x86 systems are vulnerable. Arm systems are not vulnerable. Only guests with passed through PCI devices may be able to leverage the vulnerability. Only systems passing through devices with out-of-spec (\"backdoor\") functionality can cause issues. Experience shows that such out-of-spec functionality is common; unless you have reason to believe that your device does not have such functionality, it's better to assume that it does.",
        "git_url": "https://github.com/xen-project/xen/commit/beb54596cfdaf15f6a86d7b1bf84ca8a0b9c6b9b",
        "commit_title": "x86/MSI-X: restrict reading of table/PBA bases from BARs",
        "commit_text": " When assigned to less trusted or un-trusted guests, devices may change state behind our backs (they may e.g. get reset by means we may not know about). Therefore we should avoid reading BARs from hardware once a device is no longer owned by Dom0. Furthermore when we can't read a BAR, or when we read zero, we shouldn't instead use the caller provided address unless that caller can be trusted.  Re-arrange the logic in msix_capability_init() such that only Dom0 (and only if the device isn't DomU-owned yet) or calls through PHYSDEVOP_prepare_msix will actually result in the reading of the respective BAR register(s). Additionally do so only as long as in-use table entries are known (note that invocation of PHYSDEVOP_prepare_msix counts as a \"pseudo\" entry). In all other uses the value already recorded will get used instead.  Clear the recorded values in _pci_cleanup_msix() as well as on the one affected error path. (Adjust this error path to also avoid blindly disabling MSI-X when it was enabled on entry to the function.)  While moving around variable declarations (in many cases to reduce their scopes), also adjust some of their types.  This is part of XSA-337. ",
        "func_before": "static int msix_capability_init(struct pci_dev *dev,\n                                struct msi_info *msi,\n                                struct msi_desc **desc)\n{\n    struct arch_msix *msix = dev->msix;\n    struct msi_desc *entry = NULL;\n    int vf;\n    u16 control;\n    u64 table_paddr;\n    u32 table_offset;\n    u8 bir, pbus, pslot, pfunc;\n    u16 seg = dev->seg;\n    u8 bus = dev->bus;\n    u8 slot = PCI_SLOT(dev->devfn);\n    u8 func = PCI_FUNC(dev->devfn);\n    bool maskall = msix->host_maskall;\n    unsigned int pos = pci_find_cap_offset(seg, bus, slot, func,\n                                           PCI_CAP_ID_MSIX);\n\n    if ( !pos )\n        return -ENODEV;\n\n    ASSERT(pcidevs_locked());\n\n    control = pci_conf_read16(dev->sbdf, msix_control_reg(pos));\n    /*\n     * Ensure MSI-X interrupts are masked during setup. Some devices require\n     * MSI-X to be enabled before we can touch the MSI-X registers. We need\n     * to mask all the vectors to prevent interrupts coming in before they're\n     * fully set up.\n     */\n    msix->host_maskall = 1;\n    pci_conf_write16(dev->sbdf, msix_control_reg(pos),\n                     control | (PCI_MSIX_FLAGS_ENABLE |\n                                PCI_MSIX_FLAGS_MASKALL));\n\n    if ( unlikely(!memory_decoded(dev)) )\n    {\n        pci_conf_write16(dev->sbdf, msix_control_reg(pos),\n                         control & ~PCI_MSIX_FLAGS_ENABLE);\n        return -ENXIO;\n    }\n\n    if ( desc )\n    {\n        entry = alloc_msi_entry(1);\n        if ( !entry )\n        {\n            pci_conf_write16(dev->sbdf, msix_control_reg(pos),\n                             control & ~PCI_MSIX_FLAGS_ENABLE);\n            return -ENOMEM;\n        }\n        ASSERT(msi);\n    }\n\n    /* Locate MSI-X table region */\n    table_offset = pci_conf_read32(dev->sbdf, msix_table_offset_reg(pos));\n    bir = (u8)(table_offset & PCI_MSIX_BIRMASK);\n    table_offset &= ~PCI_MSIX_BIRMASK;\n\n    if ( !dev->info.is_virtfn )\n    {\n        pbus = bus;\n        pslot = slot;\n        pfunc = func;\n        vf = -1;\n    }\n    else\n    {\n        pbus = dev->info.physfn.bus;\n        pslot = PCI_SLOT(dev->info.physfn.devfn);\n        pfunc = PCI_FUNC(dev->info.physfn.devfn);\n        vf = PCI_BDF2(dev->bus, dev->devfn);\n    }\n\n    table_paddr = read_pci_mem_bar(seg, pbus, pslot, pfunc, bir, vf);\n    WARN_ON(msi && msi->table_base != table_paddr);\n    if ( !table_paddr )\n    {\n        if ( !msi || !msi->table_base )\n        {\n            pci_conf_write16(dev->sbdf, msix_control_reg(pos),\n                             control & ~PCI_MSIX_FLAGS_ENABLE);\n            xfree(entry);\n            return -ENXIO;\n        }\n        table_paddr = msi->table_base;\n    }\n    table_paddr += table_offset;\n\n    if ( !msix->used_entries )\n    {\n        u64 pba_paddr;\n        u32 pba_offset;\n\n        msix->table.first = PFN_DOWN(table_paddr);\n        msix->table.last = PFN_DOWN(table_paddr +\n                                    msix->nr_entries * PCI_MSIX_ENTRY_SIZE - 1);\n        WARN_ON(rangeset_overlaps_range(mmio_ro_ranges, msix->table.first,\n                                        msix->table.last));\n\n        pba_offset = pci_conf_read32(dev->sbdf, msix_pba_offset_reg(pos));\n        bir = (u8)(pba_offset & PCI_MSIX_BIRMASK);\n        pba_paddr = read_pci_mem_bar(seg, pbus, pslot, pfunc, bir, vf);\n        WARN_ON(!pba_paddr);\n        pba_paddr += pba_offset & ~PCI_MSIX_BIRMASK;\n\n        msix->pba.first = PFN_DOWN(pba_paddr);\n        msix->pba.last = PFN_DOWN(pba_paddr +\n                                  BITS_TO_LONGS(msix->nr_entries) - 1);\n        WARN_ON(rangeset_overlaps_range(mmio_ro_ranges, msix->pba.first,\n                                        msix->pba.last));\n    }\n\n    if ( entry )\n    {\n        /* Map MSI-X table region */\n        u64 entry_paddr = table_paddr + msi->entry_nr * PCI_MSIX_ENTRY_SIZE;\n        int idx = msix_get_fixmap(msix, table_paddr, entry_paddr);\n        void __iomem *base;\n\n        if ( idx < 0 )\n        {\n            pci_conf_write16(dev->sbdf, msix_control_reg(pos),\n                             control & ~PCI_MSIX_FLAGS_ENABLE);\n            xfree(entry);\n            return idx;\n        }\n        base = fix_to_virt(idx) + (entry_paddr & (PAGE_SIZE - 1));\n\n        /* Mask interrupt here */\n        writel(1, base + PCI_MSIX_ENTRY_VECTOR_CTRL_OFFSET);\n\n        entry->msi_attrib.type = PCI_CAP_ID_MSIX;\n        entry->msi_attrib.is_64 = 1;\n        entry->msi_attrib.entry_nr = msi->entry_nr;\n        entry->msi_attrib.maskbit = 1;\n        entry->msi_attrib.host_masked = 1;\n        entry->msi_attrib.guest_masked = 1;\n        entry->msi_attrib.pos = pos;\n        entry->irq = msi->irq;\n        entry->dev = dev;\n        entry->mask_base = base;\n\n        list_add_tail(&entry->list, &dev->msi_list);\n        *desc = entry;\n    }\n\n    if ( !msix->used_entries )\n    {\n        maskall = false;\n        if ( !msix->guest_maskall )\n            control &= ~PCI_MSIX_FLAGS_MASKALL;\n        else\n            control |= PCI_MSIX_FLAGS_MASKALL;\n\n        if ( rangeset_add_range(mmio_ro_ranges, msix->table.first,\n                                msix->table.last) )\n            WARN();\n        if ( rangeset_add_range(mmio_ro_ranges, msix->pba.first,\n                                msix->pba.last) )\n            WARN();\n\n        if ( desc )\n        {\n            struct domain *currd = current->domain;\n            struct domain *d = dev->domain ?: currd;\n\n            if ( !is_hardware_domain(currd) || d != currd )\n                printk(\"%s use of MSI-X on %pp by %pd\\n\",\n                       is_hardware_domain(currd)\n                       ? XENLOG_WARNING \"Potentially insecure\"\n                       : XENLOG_ERR \"Insecure\",\n                       &dev->sbdf, d);\n            if ( !is_hardware_domain(d) &&\n                 /* Assume a domain without memory has no mappings yet. */\n                 (!is_hardware_domain(currd) || domain_tot_pages(d)) )\n                domain_crash(d);\n            /* XXX How to deal with existing mappings? */\n        }\n    }\n    WARN_ON(msix->table.first != (table_paddr >> PAGE_SHIFT));\n    ++msix->used_entries;\n\n    /* Restore MSI-X enabled bits */\n    if ( !hardware_domain )\n    {\n        /*\n         * ..., except for internal requests (before Dom0 starts), in which\n         * case we rather need to behave \"normally\", i.e. not follow the split\n         * brain model where Dom0 actually enables MSI (and disables INTx).\n         */\n        pci_intx(dev, false);\n        control |= PCI_MSIX_FLAGS_ENABLE;\n        control &= ~PCI_MSIX_FLAGS_MASKALL;\n        maskall = 0;\n    }\n    msix->host_maskall = maskall;\n    pci_conf_write16(dev->sbdf, msix_control_reg(pos), control);\n\n    return 0;\n}",
        "func": "static int msix_capability_init(struct pci_dev *dev,\n                                struct msi_info *msi,\n                                struct msi_desc **desc)\n{\n    struct arch_msix *msix = dev->msix;\n    struct msi_desc *entry = NULL;\n    u16 control;\n    u64 table_paddr;\n    u32 table_offset;\n    u16 seg = dev->seg;\n    u8 bus = dev->bus;\n    u8 slot = PCI_SLOT(dev->devfn);\n    u8 func = PCI_FUNC(dev->devfn);\n    bool maskall = msix->host_maskall, zap_on_error = false;\n    unsigned int pos = pci_find_cap_offset(seg, bus, slot, func,\n                                           PCI_CAP_ID_MSIX);\n\n    if ( !pos )\n        return -ENODEV;\n\n    ASSERT(pcidevs_locked());\n\n    control = pci_conf_read16(dev->sbdf, msix_control_reg(pos));\n    /*\n     * Ensure MSI-X interrupts are masked during setup. Some devices require\n     * MSI-X to be enabled before we can touch the MSI-X registers. We need\n     * to mask all the vectors to prevent interrupts coming in before they're\n     * fully set up.\n     */\n    msix->host_maskall = 1;\n    pci_conf_write16(dev->sbdf, msix_control_reg(pos),\n                     control | (PCI_MSIX_FLAGS_ENABLE |\n                                PCI_MSIX_FLAGS_MASKALL));\n\n    if ( unlikely(!memory_decoded(dev)) )\n    {\n        pci_conf_write16(dev->sbdf, msix_control_reg(pos),\n                         control & ~PCI_MSIX_FLAGS_ENABLE);\n        return -ENXIO;\n    }\n\n    if ( desc )\n    {\n        entry = alloc_msi_entry(1);\n        if ( !entry )\n        {\n            pci_conf_write16(dev->sbdf, msix_control_reg(pos),\n                             control & ~PCI_MSIX_FLAGS_ENABLE);\n            return -ENOMEM;\n        }\n        ASSERT(msi);\n    }\n\n    /* Locate MSI-X table region */\n    table_offset = pci_conf_read32(dev->sbdf, msix_table_offset_reg(pos));\n    if ( !msix->used_entries &&\n         (!msi ||\n          (is_hardware_domain(current->domain) &&\n           (dev->domain == current->domain || dev->domain == dom_io))) )\n    {\n        unsigned int bir = table_offset & PCI_MSIX_BIRMASK, pbus, pslot, pfunc;\n        int vf;\n        paddr_t pba_paddr;\n        unsigned int pba_offset;\n\n        if ( !dev->info.is_virtfn )\n        {\n            pbus = bus;\n            pslot = slot;\n            pfunc = func;\n            vf = -1;\n        }\n        else\n        {\n            pbus = dev->info.physfn.bus;\n            pslot = PCI_SLOT(dev->info.physfn.devfn);\n            pfunc = PCI_FUNC(dev->info.physfn.devfn);\n            vf = PCI_BDF2(dev->bus, dev->devfn);\n        }\n\n        table_paddr = read_pci_mem_bar(seg, pbus, pslot, pfunc, bir, vf);\n        WARN_ON(msi && msi->table_base != table_paddr);\n        if ( !table_paddr )\n        {\n            if ( !msi || !msi->table_base )\n            {\n                pci_conf_write16(dev->sbdf, msix_control_reg(pos),\n                                 control & ~PCI_MSIX_FLAGS_ENABLE);\n                xfree(entry);\n                return -ENXIO;\n            }\n            table_paddr = msi->table_base;\n        }\n        table_paddr += table_offset & ~PCI_MSIX_BIRMASK;\n\n        msix->table.first = PFN_DOWN(table_paddr);\n        msix->table.last = PFN_DOWN(table_paddr +\n                                    msix->nr_entries * PCI_MSIX_ENTRY_SIZE - 1);\n        WARN_ON(rangeset_overlaps_range(mmio_ro_ranges, msix->table.first,\n                                        msix->table.last));\n\n        pba_offset = pci_conf_read32(dev->sbdf, msix_pba_offset_reg(pos));\n        bir = (u8)(pba_offset & PCI_MSIX_BIRMASK);\n        pba_paddr = read_pci_mem_bar(seg, pbus, pslot, pfunc, bir, vf);\n        WARN_ON(!pba_paddr);\n        pba_paddr += pba_offset & ~PCI_MSIX_BIRMASK;\n\n        msix->pba.first = PFN_DOWN(pba_paddr);\n        msix->pba.last = PFN_DOWN(pba_paddr +\n                                  BITS_TO_LONGS(msix->nr_entries) - 1);\n        WARN_ON(rangeset_overlaps_range(mmio_ro_ranges, msix->pba.first,\n                                        msix->pba.last));\n\n        zap_on_error = true;\n    }\n    else if ( !msix->table.first )\n    {\n        pci_conf_write16(dev->sbdf, msix_control_reg(pos), control);\n        xfree(entry);\n        return -ENODATA;\n    }\n    else\n        table_paddr = (msix->table.first << PAGE_SHIFT) +\n                      PAGE_OFFSET(table_offset & ~PCI_MSIX_BIRMASK);\n\n    if ( entry )\n    {\n        /* Map MSI-X table region */\n        u64 entry_paddr = table_paddr + msi->entry_nr * PCI_MSIX_ENTRY_SIZE;\n        int idx = msix_get_fixmap(msix, table_paddr, entry_paddr);\n        void __iomem *base;\n\n        if ( idx < 0 )\n        {\n            if ( zap_on_error )\n            {\n                msix->table.first = 0;\n                msix->pba.first = 0;\n\n                control &= ~PCI_MSIX_FLAGS_ENABLE;\n            }\n\n            pci_conf_write16(dev->sbdf, msix_control_reg(pos), control);\n            xfree(entry);\n            return idx;\n        }\n        base = fix_to_virt(idx) + (entry_paddr & (PAGE_SIZE - 1));\n\n        /* Mask interrupt here */\n        writel(1, base + PCI_MSIX_ENTRY_VECTOR_CTRL_OFFSET);\n\n        entry->msi_attrib.type = PCI_CAP_ID_MSIX;\n        entry->msi_attrib.is_64 = 1;\n        entry->msi_attrib.entry_nr = msi->entry_nr;\n        entry->msi_attrib.maskbit = 1;\n        entry->msi_attrib.host_masked = 1;\n        entry->msi_attrib.guest_masked = 1;\n        entry->msi_attrib.pos = pos;\n        entry->irq = msi->irq;\n        entry->dev = dev;\n        entry->mask_base = base;\n\n        list_add_tail(&entry->list, &dev->msi_list);\n        *desc = entry;\n    }\n\n    if ( !msix->used_entries )\n    {\n        maskall = false;\n        if ( !msix->guest_maskall )\n            control &= ~PCI_MSIX_FLAGS_MASKALL;\n        else\n            control |= PCI_MSIX_FLAGS_MASKALL;\n\n        if ( rangeset_add_range(mmio_ro_ranges, msix->table.first,\n                                msix->table.last) )\n            WARN();\n        if ( rangeset_add_range(mmio_ro_ranges, msix->pba.first,\n                                msix->pba.last) )\n            WARN();\n\n        if ( desc )\n        {\n            struct domain *currd = current->domain;\n            struct domain *d = dev->domain ?: currd;\n\n            if ( !is_hardware_domain(currd) || d != currd )\n                printk(\"%s use of MSI-X on %pp by %pd\\n\",\n                       is_hardware_domain(currd)\n                       ? XENLOG_WARNING \"Potentially insecure\"\n                       : XENLOG_ERR \"Insecure\",\n                       &dev->sbdf, d);\n            if ( !is_hardware_domain(d) &&\n                 /* Assume a domain without memory has no mappings yet. */\n                 (!is_hardware_domain(currd) || domain_tot_pages(d)) )\n                domain_crash(d);\n            /* XXX How to deal with existing mappings? */\n        }\n    }\n    WARN_ON(msix->table.first != (table_paddr >> PAGE_SHIFT));\n    ++msix->used_entries;\n\n    /* Restore MSI-X enabled bits */\n    if ( !hardware_domain )\n    {\n        /*\n         * ..., except for internal requests (before Dom0 starts), in which\n         * case we rather need to behave \"normally\", i.e. not follow the split\n         * brain model where Dom0 actually enables MSI (and disables INTx).\n         */\n        pci_intx(dev, false);\n        control |= PCI_MSIX_FLAGS_ENABLE;\n        control &= ~PCI_MSIX_FLAGS_MASKALL;\n        maskall = 0;\n    }\n    msix->host_maskall = maskall;\n    pci_conf_write16(dev->sbdf, msix_control_reg(pos), control);\n\n    return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,16 +4,14 @@\n {\n     struct arch_msix *msix = dev->msix;\n     struct msi_desc *entry = NULL;\n-    int vf;\n     u16 control;\n     u64 table_paddr;\n     u32 table_offset;\n-    u8 bir, pbus, pslot, pfunc;\n     u16 seg = dev->seg;\n     u8 bus = dev->bus;\n     u8 slot = PCI_SLOT(dev->devfn);\n     u8 func = PCI_FUNC(dev->devfn);\n-    bool maskall = msix->host_maskall;\n+    bool maskall = msix->host_maskall, zap_on_error = false;\n     unsigned int pos = pci_find_cap_offset(seg, bus, slot, func,\n                                            PCI_CAP_ID_MSIX);\n \n@@ -55,43 +53,45 @@\n \n     /* Locate MSI-X table region */\n     table_offset = pci_conf_read32(dev->sbdf, msix_table_offset_reg(pos));\n-    bir = (u8)(table_offset & PCI_MSIX_BIRMASK);\n-    table_offset &= ~PCI_MSIX_BIRMASK;\n-\n-    if ( !dev->info.is_virtfn )\n-    {\n-        pbus = bus;\n-        pslot = slot;\n-        pfunc = func;\n-        vf = -1;\n-    }\n-    else\n-    {\n-        pbus = dev->info.physfn.bus;\n-        pslot = PCI_SLOT(dev->info.physfn.devfn);\n-        pfunc = PCI_FUNC(dev->info.physfn.devfn);\n-        vf = PCI_BDF2(dev->bus, dev->devfn);\n-    }\n-\n-    table_paddr = read_pci_mem_bar(seg, pbus, pslot, pfunc, bir, vf);\n-    WARN_ON(msi && msi->table_base != table_paddr);\n-    if ( !table_paddr )\n-    {\n-        if ( !msi || !msi->table_base )\n-        {\n-            pci_conf_write16(dev->sbdf, msix_control_reg(pos),\n-                             control & ~PCI_MSIX_FLAGS_ENABLE);\n-            xfree(entry);\n-            return -ENXIO;\n-        }\n-        table_paddr = msi->table_base;\n-    }\n-    table_paddr += table_offset;\n-\n-    if ( !msix->used_entries )\n-    {\n-        u64 pba_paddr;\n-        u32 pba_offset;\n+    if ( !msix->used_entries &&\n+         (!msi ||\n+          (is_hardware_domain(current->domain) &&\n+           (dev->domain == current->domain || dev->domain == dom_io))) )\n+    {\n+        unsigned int bir = table_offset & PCI_MSIX_BIRMASK, pbus, pslot, pfunc;\n+        int vf;\n+        paddr_t pba_paddr;\n+        unsigned int pba_offset;\n+\n+        if ( !dev->info.is_virtfn )\n+        {\n+            pbus = bus;\n+            pslot = slot;\n+            pfunc = func;\n+            vf = -1;\n+        }\n+        else\n+        {\n+            pbus = dev->info.physfn.bus;\n+            pslot = PCI_SLOT(dev->info.physfn.devfn);\n+            pfunc = PCI_FUNC(dev->info.physfn.devfn);\n+            vf = PCI_BDF2(dev->bus, dev->devfn);\n+        }\n+\n+        table_paddr = read_pci_mem_bar(seg, pbus, pslot, pfunc, bir, vf);\n+        WARN_ON(msi && msi->table_base != table_paddr);\n+        if ( !table_paddr )\n+        {\n+            if ( !msi || !msi->table_base )\n+            {\n+                pci_conf_write16(dev->sbdf, msix_control_reg(pos),\n+                                 control & ~PCI_MSIX_FLAGS_ENABLE);\n+                xfree(entry);\n+                return -ENXIO;\n+            }\n+            table_paddr = msi->table_base;\n+        }\n+        table_paddr += table_offset & ~PCI_MSIX_BIRMASK;\n \n         msix->table.first = PFN_DOWN(table_paddr);\n         msix->table.last = PFN_DOWN(table_paddr +\n@@ -110,7 +110,18 @@\n                                   BITS_TO_LONGS(msix->nr_entries) - 1);\n         WARN_ON(rangeset_overlaps_range(mmio_ro_ranges, msix->pba.first,\n                                         msix->pba.last));\n-    }\n+\n+        zap_on_error = true;\n+    }\n+    else if ( !msix->table.first )\n+    {\n+        pci_conf_write16(dev->sbdf, msix_control_reg(pos), control);\n+        xfree(entry);\n+        return -ENODATA;\n+    }\n+    else\n+        table_paddr = (msix->table.first << PAGE_SHIFT) +\n+                      PAGE_OFFSET(table_offset & ~PCI_MSIX_BIRMASK);\n \n     if ( entry )\n     {\n@@ -121,8 +132,15 @@\n \n         if ( idx < 0 )\n         {\n-            pci_conf_write16(dev->sbdf, msix_control_reg(pos),\n-                             control & ~PCI_MSIX_FLAGS_ENABLE);\n+            if ( zap_on_error )\n+            {\n+                msix->table.first = 0;\n+                msix->pba.first = 0;\n+\n+                control &= ~PCI_MSIX_FLAGS_ENABLE;\n+            }\n+\n+            pci_conf_write16(dev->sbdf, msix_control_reg(pos), control);\n             xfree(entry);\n             return idx;\n         }",
        "diff_line_info": {
            "deleted_lines": [
                "    int vf;",
                "    u8 bir, pbus, pslot, pfunc;",
                "    bool maskall = msix->host_maskall;",
                "    bir = (u8)(table_offset & PCI_MSIX_BIRMASK);",
                "    table_offset &= ~PCI_MSIX_BIRMASK;",
                "",
                "    if ( !dev->info.is_virtfn )",
                "    {",
                "        pbus = bus;",
                "        pslot = slot;",
                "        pfunc = func;",
                "        vf = -1;",
                "    }",
                "    else",
                "    {",
                "        pbus = dev->info.physfn.bus;",
                "        pslot = PCI_SLOT(dev->info.physfn.devfn);",
                "        pfunc = PCI_FUNC(dev->info.physfn.devfn);",
                "        vf = PCI_BDF2(dev->bus, dev->devfn);",
                "    }",
                "",
                "    table_paddr = read_pci_mem_bar(seg, pbus, pslot, pfunc, bir, vf);",
                "    WARN_ON(msi && msi->table_base != table_paddr);",
                "    if ( !table_paddr )",
                "    {",
                "        if ( !msi || !msi->table_base )",
                "        {",
                "            pci_conf_write16(dev->sbdf, msix_control_reg(pos),",
                "                             control & ~PCI_MSIX_FLAGS_ENABLE);",
                "            xfree(entry);",
                "            return -ENXIO;",
                "        }",
                "        table_paddr = msi->table_base;",
                "    }",
                "    table_paddr += table_offset;",
                "",
                "    if ( !msix->used_entries )",
                "    {",
                "        u64 pba_paddr;",
                "        u32 pba_offset;",
                "    }",
                "            pci_conf_write16(dev->sbdf, msix_control_reg(pos),",
                "                             control & ~PCI_MSIX_FLAGS_ENABLE);"
            ],
            "added_lines": [
                "    bool maskall = msix->host_maskall, zap_on_error = false;",
                "    if ( !msix->used_entries &&",
                "         (!msi ||",
                "          (is_hardware_domain(current->domain) &&",
                "           (dev->domain == current->domain || dev->domain == dom_io))) )",
                "    {",
                "        unsigned int bir = table_offset & PCI_MSIX_BIRMASK, pbus, pslot, pfunc;",
                "        int vf;",
                "        paddr_t pba_paddr;",
                "        unsigned int pba_offset;",
                "",
                "        if ( !dev->info.is_virtfn )",
                "        {",
                "            pbus = bus;",
                "            pslot = slot;",
                "            pfunc = func;",
                "            vf = -1;",
                "        }",
                "        else",
                "        {",
                "            pbus = dev->info.physfn.bus;",
                "            pslot = PCI_SLOT(dev->info.physfn.devfn);",
                "            pfunc = PCI_FUNC(dev->info.physfn.devfn);",
                "            vf = PCI_BDF2(dev->bus, dev->devfn);",
                "        }",
                "",
                "        table_paddr = read_pci_mem_bar(seg, pbus, pslot, pfunc, bir, vf);",
                "        WARN_ON(msi && msi->table_base != table_paddr);",
                "        if ( !table_paddr )",
                "        {",
                "            if ( !msi || !msi->table_base )",
                "            {",
                "                pci_conf_write16(dev->sbdf, msix_control_reg(pos),",
                "                                 control & ~PCI_MSIX_FLAGS_ENABLE);",
                "                xfree(entry);",
                "                return -ENXIO;",
                "            }",
                "            table_paddr = msi->table_base;",
                "        }",
                "        table_paddr += table_offset & ~PCI_MSIX_BIRMASK;",
                "",
                "        zap_on_error = true;",
                "    }",
                "    else if ( !msix->table.first )",
                "    {",
                "        pci_conf_write16(dev->sbdf, msix_control_reg(pos), control);",
                "        xfree(entry);",
                "        return -ENODATA;",
                "    }",
                "    else",
                "        table_paddr = (msix->table.first << PAGE_SHIFT) +",
                "                      PAGE_OFFSET(table_offset & ~PCI_MSIX_BIRMASK);",
                "            if ( zap_on_error )",
                "            {",
                "                msix->table.first = 0;",
                "                msix->pba.first = 0;",
                "",
                "                control &= ~PCI_MSIX_FLAGS_ENABLE;",
                "            }",
                "",
                "            pci_conf_write16(dev->sbdf, msix_control_reg(pos), control);"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-25595",
        "func_name": "xen-project/xen/set_msi_affinity",
        "description": "An issue was discovered in Xen through 4.14.x. The PCI passthrough code improperly uses register data. Code paths in Xen's MSI handling have been identified that act on unsanitized values read back from device hardware registers. While devices strictly compliant with PCI specifications shouldn't be able to affect these registers, experience shows that it's very common for devices to have out-of-spec \"backdoor\" operations that can affect the result of these reads. A not fully trusted guest may be able to crash Xen, leading to a Denial of Service (DoS) for the entire system. Privilege escalation and information leaks cannot be excluded. All versions of Xen supporting PCI passthrough are affected. Only x86 systems are vulnerable. Arm systems are not vulnerable. Only guests with passed through PCI devices may be able to leverage the vulnerability. Only systems passing through devices with out-of-spec (\"backdoor\") functionality can cause issues. Experience shows that such out-of-spec functionality is common; unless you have reason to believe that your device does not have such functionality, it's better to assume that it does.",
        "git_url": "https://github.com/xen-project/xen/commit/cb5e9730862ba0c99e81d3fbd8f65010707245e4",
        "commit_title": "x86/msi: get rid of read_msi_msg",
        "commit_text": " It's safer and faster to just use the cached last written (untranslated) MSI message stored in msi_desc for the single user that calls read_msi_msg.  This also prevents relying on the data read from the device MSI registers in order to figure out the index into the IOMMU interrupt remapping table, which is not safe.  This is part of XSA-337.  Requested-by: Andrew Cooper <andrew.cooper3@citrix.com>",
        "func_before": "void set_msi_affinity(struct irq_desc *desc, const cpumask_t *mask)\n{\n    struct msi_msg msg;\n    unsigned int dest;\n    struct msi_desc *msi_desc = desc->msi_desc;\n\n    dest = set_desc_affinity(desc, mask);\n    if ( dest == BAD_APICID || !msi_desc )\n        return;\n\n    ASSERT(spin_is_locked(&desc->lock));\n\n    memset(&msg, 0, sizeof(msg));\n    if ( !read_msi_msg(msi_desc, &msg) )\n        return;\n\n    msg.data &= ~MSI_DATA_VECTOR_MASK;\n    msg.data |= MSI_DATA_VECTOR(desc->arch.vector);\n    msg.address_lo &= ~MSI_ADDR_DEST_ID_MASK;\n    msg.address_lo |= MSI_ADDR_DEST_ID(dest);\n    msg.dest32 = dest;\n\n    write_msi_msg(msi_desc, &msg);\n}",
        "func": "void set_msi_affinity(struct irq_desc *desc, const cpumask_t *mask)\n{\n    struct msi_msg msg;\n    unsigned int dest;\n    struct msi_desc *msi_desc = desc->msi_desc;\n\n    dest = set_desc_affinity(desc, mask);\n    if ( dest == BAD_APICID || !msi_desc )\n        return;\n\n    ASSERT(spin_is_locked(&desc->lock));\n\n    msg = msi_desc->msg;\n    msg.data &= ~MSI_DATA_VECTOR_MASK;\n    msg.data |= MSI_DATA_VECTOR(desc->arch.vector);\n    msg.address_lo &= ~MSI_ADDR_DEST_ID_MASK;\n    msg.address_lo |= MSI_ADDR_DEST_ID(dest);\n    msg.dest32 = dest;\n\n    write_msi_msg(msi_desc, &msg);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -10,10 +10,7 @@\n \n     ASSERT(spin_is_locked(&desc->lock));\n \n-    memset(&msg, 0, sizeof(msg));\n-    if ( !read_msi_msg(msi_desc, &msg) )\n-        return;\n-\n+    msg = msi_desc->msg;\n     msg.data &= ~MSI_DATA_VECTOR_MASK;\n     msg.data |= MSI_DATA_VECTOR(desc->arch.vector);\n     msg.address_lo &= ~MSI_ADDR_DEST_ID_MASK;",
        "diff_line_info": {
            "deleted_lines": [
                "    memset(&msg, 0, sizeof(msg));",
                "    if ( !read_msi_msg(msi_desc, &msg) )",
                "        return;",
                ""
            ],
            "added_lines": [
                "    msg = msi_desc->msg;"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-26880",
        "func_name": "sympa-community/sympa/main",
        "description": "Sympa through 6.2.57b.2 allows a local privilege escalation from the sympa user account to full root access by modifying the sympa.conf configuration file (which is owned by sympa) and parsing it through the setuid sympa_newaliases-wrapper executable.",
        "git_url": "https://github.com/sympa-community/sympa/commit/3f8449c647e5ab32cf6f8837cb600c1756b6189c",
        "commit_title": "Sympa SA 2020-002 (candidate): Setuid wrappers should clear environment variables to avoid exploits.",
        "commit_text": "",
        "func_before": "int main(int argn, char **argv, char **envp) {\n    setreuid(geteuid(),geteuid());\n    setregid(getegid(),getegid());\n    argv[0] = SYMPASOAP;\n    return execve(SYMPASOAP,argv,envp);\n}",
        "func": "int main(int argn, char **argv, char **envp) {\n    char *myenvp[] = { \"IFS= \\t\\n\", \"PATH=/bin:/usr/bin\", NULL };\n\n    setreuid(geteuid(),geteuid());\n    setregid(getegid(),getegid());\n    argv[0] = SYMPASOAP;\n    return execve(SYMPASOAP, argv, myenvp);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,8 @@\n int main(int argn, char **argv, char **envp) {\n+    char *myenvp[] = { \"IFS= \\t\\n\", \"PATH=/bin:/usr/bin\", NULL };\n+\n     setreuid(geteuid(),geteuid());\n     setregid(getegid(),getegid());\n     argv[0] = SYMPASOAP;\n-    return execve(SYMPASOAP,argv,envp);\n+    return execve(SYMPASOAP, argv, myenvp);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    return execve(SYMPASOAP,argv,envp);"
            ],
            "added_lines": [
                "    char *myenvp[] = { \"IFS= \\t\\n\", \"PATH=/bin:/usr/bin\", NULL };",
                "",
                "    return execve(SYMPASOAP, argv, myenvp);"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-26880",
        "func_name": "sympa-community/sympa/main",
        "description": "Sympa through 6.2.57b.2 allows a local privilege escalation from the sympa user account to full root access by modifying the sympa.conf configuration file (which is owned by sympa) and parsing it through the setuid sympa_newaliases-wrapper executable.",
        "git_url": "https://github.com/sympa-community/sympa/commit/3f8449c647e5ab32cf6f8837cb600c1756b6189c",
        "commit_title": "Sympa SA 2020-002 (candidate): Setuid wrappers should clear environment variables to avoid exploits.",
        "commit_text": "",
        "func_before": "int main(int argn, char **argv, char **envp) {\n    setreuid(geteuid(),geteuid()); // Added to fix the segfault\n    setregid(getegid(),getegid()); // Added to fix the segfault\n    argv[0] = WWSYMPA;\n    return execve(WWSYMPA,argv,envp);\n}",
        "func": "int main(int argn, char **argv, char **envp) {\n    char *myenvp[] = { \"IFS= \\t\\n\", \"PATH=/bin:/usr/bin\", NULL };\n\n    setreuid(geteuid(),geteuid()); // Added to fix the segfault\n    setregid(getegid(),getegid()); // Added to fix the segfault\n    argv[0] = WWSYMPA;\n    return execve(WWSYMPA, argv, myenvp);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,8 @@\n int main(int argn, char **argv, char **envp) {\n+    char *myenvp[] = { \"IFS= \\t\\n\", \"PATH=/bin:/usr/bin\", NULL };\n+\n     setreuid(geteuid(),geteuid()); // Added to fix the segfault\n     setregid(getegid(),getegid()); // Added to fix the segfault\n     argv[0] = WWSYMPA;\n-    return execve(WWSYMPA,argv,envp);\n+    return execve(WWSYMPA, argv, myenvp);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    return execve(WWSYMPA,argv,envp);"
            ],
            "added_lines": [
                "    char *myenvp[] = { \"IFS= \\t\\n\", \"PATH=/bin:/usr/bin\", NULL };",
                "",
                "    return execve(WWSYMPA, argv, myenvp);"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-26880",
        "func_name": "sympa-community/sympa/main",
        "description": "Sympa through 6.2.57b.2 allows a local privilege escalation from the sympa user account to full root access by modifying the sympa.conf configuration file (which is owned by sympa) and parsing it through the setuid sympa_newaliases-wrapper executable.",
        "git_url": "https://github.com/sympa-community/sympa/commit/3f8449c647e5ab32cf6f8837cb600c1756b6189c",
        "commit_title": "Sympa SA 2020-002 (candidate): Setuid wrappers should clear environment variables to avoid exploits.",
        "commit_text": "",
        "func_before": "int main(int argn, char **argv, char **envp) {\n    setreuid(geteuid(),geteuid());\n    setregid(getegid(),getegid());\n    argv[0] = SYMPA_NEWALIASES;\n    return execve(SYMPA_NEWALIASES, argv, envp);\n}",
        "func": "int main(int argn, char **argv, char **envp) {\n    char *myenvp[] = { \"IFS= \\t\\n\", \"PATH=/bin:/usr/bin\", NULL };\n\n    setreuid(geteuid(),geteuid());\n    setregid(getegid(),getegid());\n    argv[0] = SYMPA_NEWALIASES;\n    return execve(SYMPA_NEWALIASES, argv, myenvp);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,8 @@\n int main(int argn, char **argv, char **envp) {\n+    char *myenvp[] = { \"IFS= \\t\\n\", \"PATH=/bin:/usr/bin\", NULL };\n+\n     setreuid(geteuid(),geteuid());\n     setregid(getegid(),getegid());\n     argv[0] = SYMPA_NEWALIASES;\n-    return execve(SYMPA_NEWALIASES, argv, envp);\n+    return execve(SYMPA_NEWALIASES, argv, myenvp);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    return execve(SYMPA_NEWALIASES, argv, envp);"
            ],
            "added_lines": [
                "    char *myenvp[] = { \"IFS= \\t\\n\", \"PATH=/bin:/usr/bin\", NULL };",
                "",
                "    return execve(SYMPA_NEWALIASES, argv, myenvp);"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-35517",
        "func_name": "qemu/setup_namespaces",
        "description": "A flaw was found in qemu. A host privilege escalation issue was found in the virtio-fs shared file system daemon where a privileged guest user is able to create a device special file in the shared directory and use it to r/w access host devices.",
        "git_url": "https://github.com/qemu/qemu/commit/ebf101955ce8f8d72fba103b5151115a4335de2c",
        "commit_title": "virtiofsd: avoid /proc/self/fd tempdir",
        "commit_text": " In order to prevent /proc/self/fd escapes a temporary directory is created where /proc/self/fd is bind-mounted. This doesn't work on read-only file systems.  Avoid the temporary directory by bind-mounting /proc/self/fd over /proc. This does not affect other processes since we remounted / with MS_REC | MS_SLAVE. /proc must exist and virtiofsd does not use it so it's safe to do this.  Path traversal can be tested with the following function:    static void test_proc_fd_escape(struct lo_data *lo)   {       int fd;       int level = 0;       ino_t last_ino = 0;        fd = lo->proc_self_fd;       for (;;) {           struct stat st;            if (fstat(fd, &st) != 0) {               perror(\"fstat\");               return;           }           if (last_ino && st.st_ino == last_ino) {               fprintf(stderr, \"inode number unchanged, stopping\\n\");               return;           }           last_ino = st.st_ino;            fprintf(stderr, \"Level %d dev %lu ino %lu\\n\", level,                   (unsigned long)st.st_dev,                   (unsigned long)last_ino);           fd = openat(fd, \"..\", O_PATH | O_DIRECTORY | O_NOFOLLOW);           level++;       }   }  Before and after this patch only Level 0 is displayed. Without /proc/self/fd bind-mount protection it is possible to traverse parent directories.  Cc: Miklos Szeredi <mszeredi@redhat.com> Cc: Jens Freimann <jfreimann@redhat.com> Message-Id: <20201006095826.59813-1-stefanha@redhat.com>",
        "func_before": "static void setup_namespaces(struct lo_data *lo, struct fuse_session *se)\n{\n    pid_t child;\n    char template[] = \"virtiofsd-XXXXXX\";\n    char *tmpdir;\n\n    /*\n     * Create a new pid namespace for *child* processes.  We'll have to\n     * fork in order to enter the new pid namespace.  A new mount namespace\n     * is also needed so that we can remount /proc for the new pid\n     * namespace.\n     *\n     * Our UNIX domain sockets have been created.  Now we can move to\n     * an empty network namespace to prevent TCP/IP and other network\n     * activity in case this process is compromised.\n     */\n    if (unshare(CLONE_NEWPID | CLONE_NEWNS | CLONE_NEWNET) != 0) {\n        fuse_log(FUSE_LOG_ERR, \"unshare(CLONE_NEWPID | CLONE_NEWNS): %m\\n\");\n        exit(1);\n    }\n\n    child = fork();\n    if (child < 0) {\n        fuse_log(FUSE_LOG_ERR, \"fork() failed: %m\\n\");\n        exit(1);\n    }\n    if (child > 0) {\n        pid_t waited;\n        int wstatus;\n\n        setup_wait_parent_capabilities();\n\n        /* The parent waits for the child */\n        do {\n            waited = waitpid(child, &wstatus, 0);\n        } while (waited < 0 && errno == EINTR && !se->exited);\n\n        /* We were terminated by a signal, see fuse_signals.c */\n        if (se->exited) {\n            exit(0);\n        }\n\n        if (WIFEXITED(wstatus)) {\n            exit(WEXITSTATUS(wstatus));\n        }\n\n        exit(1);\n    }\n\n    /* Send us SIGTERM when the parent thread terminates, see prctl(2) */\n    prctl(PR_SET_PDEATHSIG, SIGTERM);\n\n    /*\n     * If the mounts have shared propagation then we want to opt out so our\n     * mount changes don't affect the parent mount namespace.\n     */\n    if (mount(NULL, \"/\", NULL, MS_REC | MS_SLAVE, NULL) < 0) {\n        fuse_log(FUSE_LOG_ERR, \"mount(/, MS_REC|MS_SLAVE): %m\\n\");\n        exit(1);\n    }\n\n    /* The child must remount /proc to use the new pid namespace */\n    if (mount(\"proc\", \"/proc\", \"proc\",\n              MS_NODEV | MS_NOEXEC | MS_NOSUID | MS_RELATIME, NULL) < 0) {\n        fuse_log(FUSE_LOG_ERR, \"mount(/proc): %m\\n\");\n        exit(1);\n    }\n\n    tmpdir = mkdtemp(template);\n    if (!tmpdir) {\n        fuse_log(FUSE_LOG_ERR, \"tmpdir(%s): %m\\n\", template);\n        exit(1);\n    }\n\n    if (mount(\"/proc/self/fd\", tmpdir, NULL, MS_BIND, NULL) < 0) {\n        fuse_log(FUSE_LOG_ERR, \"mount(/proc/self/fd, %s, MS_BIND): %m\\n\",\n                 tmpdir);\n        exit(1);\n    }\n\n    /* Now we can get our /proc/self/fd directory file descriptor */\n    lo->proc_self_fd = open(tmpdir, O_PATH);\n    if (lo->proc_self_fd == -1) {\n        fuse_log(FUSE_LOG_ERR, \"open(%s, O_PATH): %m\\n\", tmpdir);\n        exit(1);\n    }\n\n    if (umount2(tmpdir, MNT_DETACH) < 0) {\n        fuse_log(FUSE_LOG_ERR, \"umount2(%s, MNT_DETACH): %m\\n\", tmpdir);\n        exit(1);\n    }\n\n    if (rmdir(tmpdir) < 0) {\n        fuse_log(FUSE_LOG_ERR, \"rmdir(%s): %m\\n\", tmpdir);\n    }\n}",
        "func": "static void setup_namespaces(struct lo_data *lo, struct fuse_session *se)\n{\n    pid_t child;\n\n    /*\n     * Create a new pid namespace for *child* processes.  We'll have to\n     * fork in order to enter the new pid namespace.  A new mount namespace\n     * is also needed so that we can remount /proc for the new pid\n     * namespace.\n     *\n     * Our UNIX domain sockets have been created.  Now we can move to\n     * an empty network namespace to prevent TCP/IP and other network\n     * activity in case this process is compromised.\n     */\n    if (unshare(CLONE_NEWPID | CLONE_NEWNS | CLONE_NEWNET) != 0) {\n        fuse_log(FUSE_LOG_ERR, \"unshare(CLONE_NEWPID | CLONE_NEWNS): %m\\n\");\n        exit(1);\n    }\n\n    child = fork();\n    if (child < 0) {\n        fuse_log(FUSE_LOG_ERR, \"fork() failed: %m\\n\");\n        exit(1);\n    }\n    if (child > 0) {\n        pid_t waited;\n        int wstatus;\n\n        setup_wait_parent_capabilities();\n\n        /* The parent waits for the child */\n        do {\n            waited = waitpid(child, &wstatus, 0);\n        } while (waited < 0 && errno == EINTR && !se->exited);\n\n        /* We were terminated by a signal, see fuse_signals.c */\n        if (se->exited) {\n            exit(0);\n        }\n\n        if (WIFEXITED(wstatus)) {\n            exit(WEXITSTATUS(wstatus));\n        }\n\n        exit(1);\n    }\n\n    /* Send us SIGTERM when the parent thread terminates, see prctl(2) */\n    prctl(PR_SET_PDEATHSIG, SIGTERM);\n\n    /*\n     * If the mounts have shared propagation then we want to opt out so our\n     * mount changes don't affect the parent mount namespace.\n     */\n    if (mount(NULL, \"/\", NULL, MS_REC | MS_SLAVE, NULL) < 0) {\n        fuse_log(FUSE_LOG_ERR, \"mount(/, MS_REC|MS_SLAVE): %m\\n\");\n        exit(1);\n    }\n\n    /* The child must remount /proc to use the new pid namespace */\n    if (mount(\"proc\", \"/proc\", \"proc\",\n              MS_NODEV | MS_NOEXEC | MS_NOSUID | MS_RELATIME, NULL) < 0) {\n        fuse_log(FUSE_LOG_ERR, \"mount(/proc): %m\\n\");\n        exit(1);\n    }\n\n    /*\n     * We only need /proc/self/fd. Prevent \"..\" from accessing parent\n     * directories of /proc/self/fd by bind-mounting it over /proc. Since / was\n     * previously remounted with MS_REC | MS_SLAVE this mount change only\n     * affects our process.\n     */\n    if (mount(\"/proc/self/fd\", \"/proc\", NULL, MS_BIND, NULL) < 0) {\n        fuse_log(FUSE_LOG_ERR, \"mount(/proc/self/fd, MS_BIND): %m\\n\");\n        exit(1);\n    }\n\n    /* Get the /proc (actually /proc/self/fd, see above) file descriptor */\n    lo->proc_self_fd = open(\"/proc\", O_PATH);\n    if (lo->proc_self_fd == -1) {\n        fuse_log(FUSE_LOG_ERR, \"open(/proc, O_PATH): %m\\n\");\n        exit(1);\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,8 +1,6 @@\n static void setup_namespaces(struct lo_data *lo, struct fuse_session *se)\n {\n     pid_t child;\n-    char template[] = \"virtiofsd-XXXXXX\";\n-    char *tmpdir;\n \n     /*\n      * Create a new pid namespace for *child* processes.  We'll have to\n@@ -66,31 +64,21 @@\n         exit(1);\n     }\n \n-    tmpdir = mkdtemp(template);\n-    if (!tmpdir) {\n-        fuse_log(FUSE_LOG_ERR, \"tmpdir(%s): %m\\n\", template);\n+    /*\n+     * We only need /proc/self/fd. Prevent \"..\" from accessing parent\n+     * directories of /proc/self/fd by bind-mounting it over /proc. Since / was\n+     * previously remounted with MS_REC | MS_SLAVE this mount change only\n+     * affects our process.\n+     */\n+    if (mount(\"/proc/self/fd\", \"/proc\", NULL, MS_BIND, NULL) < 0) {\n+        fuse_log(FUSE_LOG_ERR, \"mount(/proc/self/fd, MS_BIND): %m\\n\");\n         exit(1);\n     }\n \n-    if (mount(\"/proc/self/fd\", tmpdir, NULL, MS_BIND, NULL) < 0) {\n-        fuse_log(FUSE_LOG_ERR, \"mount(/proc/self/fd, %s, MS_BIND): %m\\n\",\n-                 tmpdir);\n+    /* Get the /proc (actually /proc/self/fd, see above) file descriptor */\n+    lo->proc_self_fd = open(\"/proc\", O_PATH);\n+    if (lo->proc_self_fd == -1) {\n+        fuse_log(FUSE_LOG_ERR, \"open(/proc, O_PATH): %m\\n\");\n         exit(1);\n     }\n-\n-    /* Now we can get our /proc/self/fd directory file descriptor */\n-    lo->proc_self_fd = open(tmpdir, O_PATH);\n-    if (lo->proc_self_fd == -1) {\n-        fuse_log(FUSE_LOG_ERR, \"open(%s, O_PATH): %m\\n\", tmpdir);\n-        exit(1);\n-    }\n-\n-    if (umount2(tmpdir, MNT_DETACH) < 0) {\n-        fuse_log(FUSE_LOG_ERR, \"umount2(%s, MNT_DETACH): %m\\n\", tmpdir);\n-        exit(1);\n-    }\n-\n-    if (rmdir(tmpdir) < 0) {\n-        fuse_log(FUSE_LOG_ERR, \"rmdir(%s): %m\\n\", tmpdir);\n-    }\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    char template[] = \"virtiofsd-XXXXXX\";",
                "    char *tmpdir;",
                "    tmpdir = mkdtemp(template);",
                "    if (!tmpdir) {",
                "        fuse_log(FUSE_LOG_ERR, \"tmpdir(%s): %m\\n\", template);",
                "    if (mount(\"/proc/self/fd\", tmpdir, NULL, MS_BIND, NULL) < 0) {",
                "        fuse_log(FUSE_LOG_ERR, \"mount(/proc/self/fd, %s, MS_BIND): %m\\n\",",
                "                 tmpdir);",
                "",
                "    /* Now we can get our /proc/self/fd directory file descriptor */",
                "    lo->proc_self_fd = open(tmpdir, O_PATH);",
                "    if (lo->proc_self_fd == -1) {",
                "        fuse_log(FUSE_LOG_ERR, \"open(%s, O_PATH): %m\\n\", tmpdir);",
                "        exit(1);",
                "    }",
                "",
                "    if (umount2(tmpdir, MNT_DETACH) < 0) {",
                "        fuse_log(FUSE_LOG_ERR, \"umount2(%s, MNT_DETACH): %m\\n\", tmpdir);",
                "        exit(1);",
                "    }",
                "",
                "    if (rmdir(tmpdir) < 0) {",
                "        fuse_log(FUSE_LOG_ERR, \"rmdir(%s): %m\\n\", tmpdir);",
                "    }"
            ],
            "added_lines": [
                "    /*",
                "     * We only need /proc/self/fd. Prevent \"..\" from accessing parent",
                "     * directories of /proc/self/fd by bind-mounting it over /proc. Since / was",
                "     * previously remounted with MS_REC | MS_SLAVE this mount change only",
                "     * affects our process.",
                "     */",
                "    if (mount(\"/proc/self/fd\", \"/proc\", NULL, MS_BIND, NULL) < 0) {",
                "        fuse_log(FUSE_LOG_ERR, \"mount(/proc/self/fd, MS_BIND): %m\\n\");",
                "    /* Get the /proc (actually /proc/self/fd, see above) file descriptor */",
                "    lo->proc_self_fd = open(\"/proc\", O_PATH);",
                "    if (lo->proc_self_fd == -1) {",
                "        fuse_log(FUSE_LOG_ERR, \"open(/proc, O_PATH): %m\\n\");"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-13776",
        "func_name": "systemd/parse_uid",
        "description": "systemd through v245 mishandles numerical usernames such as ones composed of decimal digits or 0x followed by hex digits, as demonstrated by use of root privileges when privileges of the 0x0 user account were intended. NOTE: this issue exists because of an incomplete fix for CVE-2017-1000082.",
        "git_url": "https://github.com/systemd/systemd/commit/156a5fd297b61bce31630d7a52c15614bf784843",
        "commit_title": "basic/user-util: always use base 10 for user/group numbers",
        "commit_text": " We would parse numbers with base prefixes as user identifiers. For example, \"0x2b3bfa0\" would be interpreted as UID==45334432 and \"01750\" would be interpreted as UID==1000. This parsing was used also in cases where either a user/group name or number may be specified. This means that names like 0x2b3bfa0 would be ambiguous: they are a valid user name according to our documented relaxed rules, but they would also be parsed as numeric uids.  This behaviour is definitely not expected by users, since tools generally only accept decimal numbers (e.g. id, getent passwd), while other tools only accept user names and thus will interpret such strings as user names without even attempting to convert them to numbers (su, ssh). So let's follow suit and only accept numbers in decimal notation. Effectively this means that we will reject such strings as a username/uid/groupname/gid where strict mode is used, and try to look up a user/group with such a name in relaxed mode.  Since the function changed is fairly low-level and fairly widely used, this affects multiple tools: loginctl show-user/enable-linger/disable-linger foo', the third argument in sysusers.d, fourth and fifth arguments in tmpfiles.d, etc.  Fixes #15985.",
        "func_before": "int parse_uid(const char *s, uid_t *ret) {\n        uint32_t uid = 0;\n        int r;\n\n        assert(s);\n\n        assert_cc(sizeof(uid_t) == sizeof(uint32_t));\n        r = safe_atou32(s, &uid);\n        if (r < 0)\n                return r;\n\n        if (!uid_is_valid(uid))\n                return -ENXIO; /* we return ENXIO instead of EINVAL\n                                * here, to make it easy to distinguish\n                                * invalid numeric uids from invalid\n                                * strings. */\n\n        if (ret)\n                *ret = uid;\n\n        return 0;\n}",
        "func": "int parse_uid(const char *s, uid_t *ret) {\n        uint32_t uid = 0;\n        int r;\n\n        assert(s);\n\n        assert_cc(sizeof(uid_t) == sizeof(uint32_t));\n        r = safe_atou32_full(s, 10, &uid);\n        if (r < 0)\n                return r;\n\n        if (!uid_is_valid(uid))\n                return -ENXIO; /* we return ENXIO instead of EINVAL\n                                * here, to make it easy to distinguish\n                                * invalid numeric uids from invalid\n                                * strings. */\n\n        if (ret)\n                *ret = uid;\n\n        return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,7 +5,7 @@\n         assert(s);\n \n         assert_cc(sizeof(uid_t) == sizeof(uint32_t));\n-        r = safe_atou32(s, &uid);\n+        r = safe_atou32_full(s, 10, &uid);\n         if (r < 0)\n                 return r;\n ",
        "diff_line_info": {
            "deleted_lines": [
                "        r = safe_atou32(s, &uid);"
            ],
            "added_lines": [
                "        r = safe_atou32_full(s, 10, &uid);"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-14976",
        "func_name": "GNS3/ubridge/iniparser_load",
        "description": "GNS3 ubridge through 0.9.18 on macOS, as used in GNS3 server before 2.1.17, allows a local attacker to read arbitrary files because it handles configuration-file errors by printing the configuration file while executing in a setuid root context.",
        "git_url": "https://github.com/GNS3/ubridge/commit/2eb0d1dab6a6de76cf3556130a2d52af101077db",
        "commit_title": "Hide errored line content during parsing configuration INI file on default",
        "commit_text": "",
        "func_before": "dictionary * iniparser_load(const char * ininame)\n{\n    FILE * in ;\n\n    char line    [ASCIILINESZ+1] ;\n    char section [ASCIILINESZ+1] ;\n    char key     [ASCIILINESZ+1] ;\n    char tmp     [(ASCIILINESZ * 2) + 1] ;\n    char val     [ASCIILINESZ+1] ;\n\n    int  last=0 ;\n    int  len ;\n    int  lineno=0 ;\n    int  errs=0;\n\n    dictionary * dict ;\n\n    if ((in=fopen(ininame, \"r\"))==NULL) {\n        fprintf(stderr, \"iniparser: cannot open %s\\n\", ininame);\n        return NULL ;\n    }\n\n    dict = dictionary_new(0) ;\n    if (!dict) {\n        fclose(in);\n        return NULL ;\n    }\n\n    memset(line,    0, ASCIILINESZ);\n    memset(section, 0, ASCIILINESZ);\n    memset(key,     0, ASCIILINESZ);\n    memset(val,     0, ASCIILINESZ);\n    last=0 ;\n\n    while (fgets(line+last, ASCIILINESZ-last, in)!=NULL) {\n        lineno++ ;\n        len = (int)strlen(line)-1;\n        if (len==0)\n            continue;\n        /* Safety check against buffer overflows */\n        if (line[len]!='\\n' && !feof(in)) {\n            fprintf(stderr,\n                    \"iniparser: input line too long in %s (%d)\\n\",\n                    ininame,\n                    lineno);\n            dictionary_del(dict);\n            fclose(in);\n            return NULL ;\n        }\n        /* Get rid of \\n and spaces at end of line */\n        while ((len>=0) &&\n                ((line[len]=='\\n') || (isspace(line[len])))) {\n            line[len]=0 ;\n            len-- ;\n        }\n        if (len < 0) { /* Line was entirely \\n and/or spaces */\n            len = 0;\n        }\n        /* Detect multi-line */\n        if (line[len]=='\\\\') {\n            /* Multi-line value */\n            last=len ;\n            continue ;\n        } else {\n            last=0 ;\n        }\n        switch (iniparser_line(line, section, key, val)) {\n            case LINE_EMPTY:\n            case LINE_COMMENT:\n            break ;\n\n            case LINE_SECTION:\n            errs = dictionary_set(dict, section, NULL);\n            break ;\n\n            case LINE_VALUE:\n            sprintf(tmp, \"%s:%s\", section, key);\n            errs = dictionary_set(dict, tmp, val) ;\n            break ;\n\n            case LINE_ERROR:\n            fprintf(stderr, \"iniparser: syntax error in %s (%d):\\n\",\n                    ininame,\n                    lineno);\n            fprintf(stderr, \"-> %s\\n\", line);\n            errs++ ;\n            break;\n\n            default:\n            break ;\n        }\n        memset(line, 0, ASCIILINESZ);\n        last=0;\n        if (errs<0) {\n            fprintf(stderr, \"iniparser: memory allocation failure\\n\");\n            break ;\n        }\n    }\n    if (errs) {\n        dictionary_del(dict);\n        dict = NULL ;\n    }\n    fclose(in);\n    return dict ;\n}",
        "func": "dictionary * iniparser_load(const char * ininame, load_options options)\n{\n    FILE * in ;\n\n    char line    [ASCIILINESZ+1] ;\n    char section [ASCIILINESZ+1] ;\n    char key     [ASCIILINESZ+1] ;\n    char tmp     [(ASCIILINESZ * 2) + 1] ;\n    char val     [ASCIILINESZ+1] ;\n\n    int  last=0 ;\n    int  len ;\n    int  lineno=0 ;\n    int  errs=0;\n\n    dictionary * dict ;\n\n    if ((in=fopen(ininame, \"r\"))==NULL) {\n        fprintf(stderr, \"iniparser: cannot open %s\\n\", ininame);\n        return NULL ;\n    }\n\n    dict = dictionary_new(0) ;\n    if (!dict) {\n        fclose(in);\n        return NULL ;\n    }\n\n    memset(line,    0, ASCIILINESZ);\n    memset(section, 0, ASCIILINESZ);\n    memset(key,     0, ASCIILINESZ);\n    memset(val,     0, ASCIILINESZ);\n    last=0 ;\n\n    while (fgets(line+last, ASCIILINESZ-last, in)!=NULL) {\n        lineno++ ;\n        len = (int)strlen(line)-1;\n        if (len==0)\n            continue;\n        /* Safety check against buffer overflows */\n        if (line[len]!='\\n' && !feof(in)) {\n            fprintf(stderr,\n                    \"iniparser: input line too long in %s (%d)\\n\",\n                    ininame,\n                    lineno);\n            dictionary_del(dict);\n            fclose(in);\n            return NULL ;\n        }\n        /* Get rid of \\n and spaces at end of line */\n        while ((len>=0) &&\n                ((line[len]=='\\n') || (isspace(line[len])))) {\n            line[len]=0 ;\n            len-- ;\n        }\n        if (len < 0) { /* Line was entirely \\n and/or spaces */\n            len = 0;\n        }\n        /* Detect multi-line */\n        if (line[len]=='\\\\') {\n            /* Multi-line value */\n            last=len ;\n            continue ;\n        } else {\n            last=0 ;\n        }\n        switch (iniparser_line(line, section, key, val)) {\n            case LINE_EMPTY:\n            case LINE_COMMENT:\n            break ;\n\n            case LINE_SECTION:\n            errs = dictionary_set(dict, section, NULL);\n            break ;\n\n            case LINE_VALUE:\n            sprintf(tmp, \"%s:%s\", section, key);\n            errs = dictionary_set(dict, tmp, val) ;\n            break ;\n\n            case LINE_ERROR:\n\n            if(options & HIDE_ERRORED_LINE_CONTENT) {\n              fprintf(stderr, \"iniparser: syntax error in %s (%d)\\n\",\n                      ininame,\n                      lineno);\n            }\n            else {\n              fprintf(stderr, \"iniparser: syntax error in %s (%d):\\n\",\n                      ininame,\n                      lineno);\n              fprintf(stderr, \"-> %s\\n\", line);\n            }\n            errs++ ;\n            break;\n\n            default:\n            break ;\n        }\n        memset(line, 0, ASCIILINESZ);\n        last=0;\n        if (errs<0) {\n            fprintf(stderr, \"iniparser: memory allocation failure\\n\");\n            break ;\n        }\n    }\n    if (errs) {\n        dictionary_del(dict);\n        dict = NULL ;\n    }\n    fclose(in);\n    return dict ;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,4 +1,4 @@\n-dictionary * iniparser_load(const char * ininame)\n+dictionary * iniparser_load(const char * ininame, load_options options)\n {\n     FILE * in ;\n \n@@ -79,10 +79,18 @@\n             break ;\n \n             case LINE_ERROR:\n-            fprintf(stderr, \"iniparser: syntax error in %s (%d):\\n\",\n-                    ininame,\n-                    lineno);\n-            fprintf(stderr, \"-> %s\\n\", line);\n+\n+            if(options & HIDE_ERRORED_LINE_CONTENT) {\n+              fprintf(stderr, \"iniparser: syntax error in %s (%d)\\n\",\n+                      ininame,\n+                      lineno);\n+            }\n+            else {\n+              fprintf(stderr, \"iniparser: syntax error in %s (%d):\\n\",\n+                      ininame,\n+                      lineno);\n+              fprintf(stderr, \"-> %s\\n\", line);\n+            }\n             errs++ ;\n             break;\n ",
        "diff_line_info": {
            "deleted_lines": [
                "dictionary * iniparser_load(const char * ininame)",
                "            fprintf(stderr, \"iniparser: syntax error in %s (%d):\\n\",",
                "                    ininame,",
                "                    lineno);",
                "            fprintf(stderr, \"-> %s\\n\", line);"
            ],
            "added_lines": [
                "dictionary * iniparser_load(const char * ininame, load_options options)",
                "",
                "            if(options & HIDE_ERRORED_LINE_CONTENT) {",
                "              fprintf(stderr, \"iniparser: syntax error in %s (%d)\\n\",",
                "                      ininame,",
                "                      lineno);",
                "            }",
                "            else {",
                "              fprintf(stderr, \"iniparser: syntax error in %s (%d):\\n\",",
                "                      ininame,",
                "                      lineno);",
                "              fprintf(stderr, \"-> %s\\n\", line);",
                "            }"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-14976",
        "func_name": "GNS3/ubridge/parse_config",
        "description": "GNS3 ubridge through 0.9.18 on macOS, as used in GNS3 server before 2.1.17, allows a local attacker to read arbitrary files because it handles configuration-file errors by printing the configuration file while executing in a setuid root context.",
        "git_url": "https://github.com/GNS3/ubridge/commit/2eb0d1dab6a6de76cf3556130a2d52af101077db",
        "commit_title": "Hide errored line content during parsing configuration INI file on default",
        "commit_text": "",
        "func_before": "int parse_config(char *filename, bridge_t **bridges)\n{\n    dictionary *ubridge_config = NULL;\n    const char *value;\n    const char *bridge_name;\n    int i, nsec;\n\n    if ((ubridge_config = iniparser_load(filename)) == NULL) {\n       return FALSE;\n    }\n\n    nsec = iniparser_getnsec(ubridge_config);\n    for (i = 0; i < nsec; i++) {\n        bridge_t *bridge;\n        nio_t *source_nio = NULL;\n        nio_t *destination_nio = NULL;\n\n        bridge_name = iniparser_getsecname(ubridge_config, i);\n        printf(\"Parsing %s\\n\", bridge_name);\n        if (getstr(ubridge_config, bridge_name, \"source_udp\", &value))\n           source_nio = create_udp_tunnel(value);\n        else if (getstr(ubridge_config, bridge_name, \"source_unix\", &value))\n           source_nio = create_unix_socket(value);\n        else if (getstr(ubridge_config, bridge_name, \"source_ethernet\", &value))\n           source_nio = open_ethernet_device(value);\n        else if (getstr(ubridge_config, bridge_name, \"source_tap\", &value))\n           source_nio = open_tap_device(value);\n#ifdef LINUX_RAW\n        else if (getstr(ubridge_config, bridge_name, \"source_linux_raw\", &value))\n           source_nio = open_linux_raw(value);\n#endif\n#ifdef __APPLE__\n        else if (getstr(ubridge_config, bridge_name, \"source_fusion_vmnet\", &value))\n           source_nio = open_fusion_vmnet(value);\n#endif\n        else\n           fprintf(stderr, \"source NIO not found\\n\");\n\n        if (getstr(ubridge_config, bridge_name, \"destination_udp\", &value))\n           destination_nio = create_udp_tunnel(value);\n        else if (getstr(ubridge_config, bridge_name, \"destination_unix\", &value))\n           destination_nio = create_unix_socket(value);\n        else if (getstr(ubridge_config, bridge_name, \"destination_ethernet\", &value))\n           destination_nio = open_ethernet_device(value);\n        else if (getstr(ubridge_config, bridge_name, \"destination_tap\", &value))\n           destination_nio = open_tap_device(value);\n#ifdef LINUX_RAW\n        else if (getstr(ubridge_config, bridge_name, \"destination_linux_raw\", &value))\n           source_nio = open_linux_raw(value);\n#endif\n#ifdef __APPLE__\n        else if (getstr(ubridge_config, bridge_name, \"destination_fusion_vmnet\", &value))\n           destination_nio = open_fusion_vmnet(value);\n#endif\n        else\n           fprintf(stderr, \"destination NIO not found\\n\");\n\n        if (source_nio && destination_nio) {\n           bridge = add_bridge(bridges);\n           bridge->source_nio = source_nio;\n           bridge->destination_nio = destination_nio;\n           if (!(bridge->name = strdup(bridge_name))) {\n              fprintf(stderr, \"bridge creation: insufficient memory\\n\");\n              return FALSE;\n           }\n           parse_capture(ubridge_config, bridge_name, bridge);\n           parse_filter(ubridge_config, bridge_name, bridge);\n        }\n        else if (source_nio != NULL)\n           free_nio(source_nio);\n        else if (destination_nio != NULL)\n           free_nio(destination_nio);\n    }\n    iniparser_freedict(ubridge_config);\n    return TRUE;\n}",
        "func": "int parse_config(char *filename, bridge_t **bridges)\n{\n    dictionary *ubridge_config = NULL;\n    const char *value;\n    const char *bridge_name;\n    int i, nsec;\n\n    if ((ubridge_config = iniparser_load(filename, HIDE_ERRORED_LINE_CONTENT)) == NULL) {\n       return FALSE;\n    }\n\n    nsec = iniparser_getnsec(ubridge_config);\n    for (i = 0; i < nsec; i++) {\n        bridge_t *bridge;\n        nio_t *source_nio = NULL;\n        nio_t *destination_nio = NULL;\n\n        bridge_name = iniparser_getsecname(ubridge_config, i);\n        printf(\"Parsing %s\\n\", bridge_name);\n        if (getstr(ubridge_config, bridge_name, \"source_udp\", &value))\n           source_nio = create_udp_tunnel(value);\n        else if (getstr(ubridge_config, bridge_name, \"source_unix\", &value))\n           source_nio = create_unix_socket(value);\n        else if (getstr(ubridge_config, bridge_name, \"source_ethernet\", &value))\n           source_nio = open_ethernet_device(value);\n        else if (getstr(ubridge_config, bridge_name, \"source_tap\", &value))\n           source_nio = open_tap_device(value);\n#ifdef LINUX_RAW\n        else if (getstr(ubridge_config, bridge_name, \"source_linux_raw\", &value))\n           source_nio = open_linux_raw(value);\n#endif\n#ifdef __APPLE__\n        else if (getstr(ubridge_config, bridge_name, \"source_fusion_vmnet\", &value))\n           source_nio = open_fusion_vmnet(value);\n#endif\n        else\n           fprintf(stderr, \"source NIO not found\\n\");\n\n        if (getstr(ubridge_config, bridge_name, \"destination_udp\", &value))\n           destination_nio = create_udp_tunnel(value);\n        else if (getstr(ubridge_config, bridge_name, \"destination_unix\", &value))\n           destination_nio = create_unix_socket(value);\n        else if (getstr(ubridge_config, bridge_name, \"destination_ethernet\", &value))\n           destination_nio = open_ethernet_device(value);\n        else if (getstr(ubridge_config, bridge_name, \"destination_tap\", &value))\n           destination_nio = open_tap_device(value);\n#ifdef LINUX_RAW\n        else if (getstr(ubridge_config, bridge_name, \"destination_linux_raw\", &value))\n           source_nio = open_linux_raw(value);\n#endif\n#ifdef __APPLE__\n        else if (getstr(ubridge_config, bridge_name, \"destination_fusion_vmnet\", &value))\n           destination_nio = open_fusion_vmnet(value);\n#endif\n        else\n           fprintf(stderr, \"destination NIO not found\\n\");\n\n        if (source_nio && destination_nio) {\n           bridge = add_bridge(bridges);\n           bridge->source_nio = source_nio;\n           bridge->destination_nio = destination_nio;\n           if (!(bridge->name = strdup(bridge_name))) {\n              fprintf(stderr, \"bridge creation: insufficient memory\\n\");\n              return FALSE;\n           }\n           parse_capture(ubridge_config, bridge_name, bridge);\n           parse_filter(ubridge_config, bridge_name, bridge);\n        }\n        else if (source_nio != NULL)\n           free_nio(source_nio);\n        else if (destination_nio != NULL)\n           free_nio(destination_nio);\n    }\n    iniparser_freedict(ubridge_config);\n    return TRUE;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,7 +5,7 @@\n     const char *bridge_name;\n     int i, nsec;\n \n-    if ((ubridge_config = iniparser_load(filename)) == NULL) {\n+    if ((ubridge_config = iniparser_load(filename, HIDE_ERRORED_LINE_CONTENT)) == NULL) {\n        return FALSE;\n     }\n ",
        "diff_line_info": {
            "deleted_lines": [
                "    if ((ubridge_config = iniparser_load(filename)) == NULL) {"
            ],
            "added_lines": [
                "    if ((ubridge_config = iniparser_load(filename, HIDE_ERRORED_LINE_CONTENT)) == NULL) {"
            ]
        }
    }
]