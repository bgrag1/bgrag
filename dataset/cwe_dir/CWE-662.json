[
    {
        "cve_id": "CVE-2019-15031",
        "func_name": "torvalds/linux/restore_fp",
        "description": "In the Linux kernel through 5.2.14 on the powerpc platform, a local user can read vector registers of other users' processes via an interrupt. To exploit the venerability, a local user starts a transaction (via the hardware transactional memory instruction tbegin) and then accesses vector registers. At some point, the vector registers will be corrupted with the values from a different local Linux process, because MSR_TM_ACTIVE is misused in arch/powerpc/kernel/process.c.",
        "git_url": "https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?h=a8318c13e79badb92bc6640704a64cc022a6eb97",
        "commit_title": "When in userspace and MSR FP=0 the hardware FP state is unrelated to",
        "commit_text": "the current process. This is extended for transactions where if tbegin is run with FP=0, the hardware checkpoint FP state will also be unrelated to the current process. Due to this, we need to ensure this hardware checkpoint is updated with the correct state before we enable FP for this process.  Unfortunately we get this wrong when returning to a process from a hardware interrupt. A process that starts a transaction with FP=0 can take an interrupt. When the kernel returns back to that process, we change to FP=1 but with hardware checkpoint FP state not updated. If this transaction is then rolled back, the FP registers now contain the wrong state.  The process looks like this:    Userspace:                      Kernel                 Start userspace                 with MSR FP=0 TM=1                   < -----    ...    tbegin    bne                Hardware interrupt                    ---- >                                     <do_IRQ...>                                     ....                                     ret_from_except                                       restore_math() \t\t\t\t        /* sees FP=0 */                                         restore_fp()                                           tm_active_with_fp() \t\t\t\t\t    /* sees FP=1 (Incorrect) */                                           load_fp_state()                                         FP = 0 -> 1                   < -----                Return to userspace                  with MSR TM=1 FP=1                  with junk in the FP TM checkpoint    TM rollback    reads FP junk  When returning from the hardware exception, tm_active_with_fp() is incorrectly making restore_fp() call load_fp_state() which is setting FP=1.  The fix is to remove tm_active_with_fp().  tm_active_with_fp() is attempting to handle the case where FP state has been changed inside a transaction. In this case the checkpointed and transactional FP state is different and hence we must restore the FP state (ie. we can't do lazy FP restore inside a transaction that's used FP). It's safe to remove tm_active_with_fp() as this case is handled by restore_tm_state(). restore_tm_state() detects if FP has been using inside a transaction and will set load_fp and call restore_math() to ensure the FP state (checkpoint and transaction) is restored.  This is a data integrity problem for the current process as the FP registers are corrupted. It's also a security problem as the FP registers from one process may be leaked to another.  Similarly for VMX.  A simple testcase to replicate this will be posted to tools/testing/selftests/powerpc/tm/tm-poison.c  This fixes CVE-2019-15031.  Cc: stable@vger.kernel.org # 4.15+ Link: https://lore.kernel.org/r/20190904045529.23002-2-gromero@linux.vnet.ibm.com ",
        "func_before": "static int restore_fp(struct task_struct *tsk)\n{\n\tif (tsk->thread.load_fp || tm_active_with_fp(tsk)) {\n\t\tload_fp_state(&current->thread.fp_state);\n\t\tcurrent->thread.load_fp++;\n\t\treturn 1;\n\t}\n\treturn 0;\n}",
        "func": "static int restore_fp(struct task_struct *tsk)\n{\n\tif (tsk->thread.load_fp) {\n\t\tload_fp_state(&current->thread.fp_state);\n\t\tcurrent->thread.load_fp++;\n\t\treturn 1;\n\t}\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,6 @@\n static int restore_fp(struct task_struct *tsk)\n {\n-\tif (tsk->thread.load_fp || tm_active_with_fp(tsk)) {\n+\tif (tsk->thread.load_fp) {\n \t\tload_fp_state(&current->thread.fp_state);\n \t\tcurrent->thread.load_fp++;\n \t\treturn 1;",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (tsk->thread.load_fp || tm_active_with_fp(tsk)) {"
            ],
            "added_lines": [
                "\tif (tsk->thread.load_fp) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-15031",
        "func_name": "torvalds/linux/restore_altivec",
        "description": "In the Linux kernel through 5.2.14 on the powerpc platform, a local user can read vector registers of other users' processes via an interrupt. To exploit the venerability, a local user starts a transaction (via the hardware transactional memory instruction tbegin) and then accesses vector registers. At some point, the vector registers will be corrupted with the values from a different local Linux process, because MSR_TM_ACTIVE is misused in arch/powerpc/kernel/process.c.",
        "git_url": "https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?h=a8318c13e79badb92bc6640704a64cc022a6eb97",
        "commit_title": "When in userspace and MSR FP=0 the hardware FP state is unrelated to",
        "commit_text": "the current process. This is extended for transactions where if tbegin is run with FP=0, the hardware checkpoint FP state will also be unrelated to the current process. Due to this, we need to ensure this hardware checkpoint is updated with the correct state before we enable FP for this process.  Unfortunately we get this wrong when returning to a process from a hardware interrupt. A process that starts a transaction with FP=0 can take an interrupt. When the kernel returns back to that process, we change to FP=1 but with hardware checkpoint FP state not updated. If this transaction is then rolled back, the FP registers now contain the wrong state.  The process looks like this:    Userspace:                      Kernel                 Start userspace                 with MSR FP=0 TM=1                   < -----    ...    tbegin    bne                Hardware interrupt                    ---- >                                     <do_IRQ...>                                     ....                                     ret_from_except                                       restore_math() \t\t\t\t        /* sees FP=0 */                                         restore_fp()                                           tm_active_with_fp() \t\t\t\t\t    /* sees FP=1 (Incorrect) */                                           load_fp_state()                                         FP = 0 -> 1                   < -----                Return to userspace                  with MSR TM=1 FP=1                  with junk in the FP TM checkpoint    TM rollback    reads FP junk  When returning from the hardware exception, tm_active_with_fp() is incorrectly making restore_fp() call load_fp_state() which is setting FP=1.  The fix is to remove tm_active_with_fp().  tm_active_with_fp() is attempting to handle the case where FP state has been changed inside a transaction. In this case the checkpointed and transactional FP state is different and hence we must restore the FP state (ie. we can't do lazy FP restore inside a transaction that's used FP). It's safe to remove tm_active_with_fp() as this case is handled by restore_tm_state(). restore_tm_state() detects if FP has been using inside a transaction and will set load_fp and call restore_math() to ensure the FP state (checkpoint and transaction) is restored.  This is a data integrity problem for the current process as the FP registers are corrupted. It's also a security problem as the FP registers from one process may be leaked to another.  Similarly for VMX.  A simple testcase to replicate this will be posted to tools/testing/selftests/powerpc/tm/tm-poison.c  This fixes CVE-2019-15031.  Cc: stable@vger.kernel.org # 4.15+ Link: https://lore.kernel.org/r/20190904045529.23002-2-gromero@linux.vnet.ibm.com ",
        "func_before": "static int restore_altivec(struct task_struct *tsk)\n{\n\tif (cpu_has_feature(CPU_FTR_ALTIVEC) &&\n\t\t(tsk->thread.load_vec || tm_active_with_altivec(tsk))) {\n\t\tload_vr_state(&tsk->thread.vr_state);\n\t\ttsk->thread.used_vr = 1;\n\t\ttsk->thread.load_vec++;\n\n\t\treturn 1;\n\t}\n\treturn 0;\n}",
        "func": "static int restore_altivec(struct task_struct *tsk)\n{\n\tif (cpu_has_feature(CPU_FTR_ALTIVEC) && (tsk->thread.load_vec)) {\n\t\tload_vr_state(&tsk->thread.vr_state);\n\t\ttsk->thread.used_vr = 1;\n\t\ttsk->thread.load_vec++;\n\n\t\treturn 1;\n\t}\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,7 +1,6 @@\n static int restore_altivec(struct task_struct *tsk)\n {\n-\tif (cpu_has_feature(CPU_FTR_ALTIVEC) &&\n-\t\t(tsk->thread.load_vec || tm_active_with_altivec(tsk))) {\n+\tif (cpu_has_feature(CPU_FTR_ALTIVEC) && (tsk->thread.load_vec)) {\n \t\tload_vr_state(&tsk->thread.vr_state);\n \t\ttsk->thread.used_vr = 1;\n \t\ttsk->thread.load_vec++;",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (cpu_has_feature(CPU_FTR_ALTIVEC) &&",
                "\t\t(tsk->thread.load_vec || tm_active_with_altivec(tsk))) {"
            ],
            "added_lines": [
                "\tif (cpu_has_feature(CPU_FTR_ALTIVEC) && (tsk->thread.load_vec)) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-2962",
        "func_name": "qemu-project/qemu/tulip_desc_write",
        "description": "A DMA reentrancy issue was found in the Tulip device emulation in QEMU. When Tulip reads or writes to the rx/tx descriptor or copies the rx/tx frame, it doesn't check whether the destination address is its own MMIO address. This can cause the device to trigger MMIO handlers multiple times, possibly leading to a stack or heap overflow. A malicious guest could use this flaw to crash the QEMU process on the host, resulting in a denial of service condition.",
        "git_url": "https://gitlab.com/qemu-project/qemu/-/commit/36a894aeb64a2e02871016da1c37d4a4ca109182",
        "commit_title": "net: tulip: Restrict DMA engine to memories",
        "commit_text": " The DMA engine is started by I/O access and then itself accesses the I/O registers, triggering a reentrancy bug.  The following log can reveal it: ==5637==ERROR: AddressSanitizer: stack-overflow     #0 0x5595435f6078 in tulip_xmit_list_update qemu/hw/net/tulip.c:673     #1 0x5595435f204a in tulip_write qemu/hw/net/tulip.c:805:13     #2 0x559544637f86 in memory_region_write_accessor qemu/softmmu/memory.c:492:5     #3 0x5595446379fa in access_with_adjusted_size qemu/softmmu/memory.c:554:18     #4 0x5595446372fa in memory_region_dispatch_write qemu/softmmu/memory.c     #5 0x55954468b74c in flatview_write_continue qemu/softmmu/physmem.c:2825:23     #6 0x559544683662 in flatview_write qemu/softmmu/physmem.c:2867:12     #7 0x5595446833f3 in address_space_write qemu/softmmu/physmem.c:2963:18     #8 0x5595435fb082 in dma_memory_rw_relaxed qemu/include/sysemu/dma.h:87:12     #9 0x5595435fb082 in dma_memory_rw qemu/include/sysemu/dma.h:130:12     #10 0x5595435fb082 in dma_memory_write qemu/include/sysemu/dma.h:171:12     #11 0x5595435fb082 in stl_le_dma qemu/include/sysemu/dma.h:272:1     #12 0x5595435fb082 in stl_le_pci_dma qemu/include/hw/pci/pci.h:910:1     #13 0x5595435fb082 in tulip_desc_write qemu/hw/net/tulip.c:101:9     #14 0x5595435f7e3d in tulip_xmit_list_update qemu/hw/net/tulip.c:706:9     #15 0x5595435f204a in tulip_write qemu/hw/net/tulip.c:805:13  Fix this bug by restricting the DMA engine to memories regions.  ",
        "func_before": "static void tulip_desc_write(TULIPState *s, hwaddr p,\n        struct tulip_descriptor *desc)\n{\n    const MemTxAttrs attrs = MEMTXATTRS_UNSPECIFIED;\n\n    if (s->csr[0] & CSR0_DBO) {\n        stl_be_pci_dma(&s->dev, p, desc->status, attrs);\n        stl_be_pci_dma(&s->dev, p + 4, desc->control, attrs);\n        stl_be_pci_dma(&s->dev, p + 8, desc->buf_addr1, attrs);\n        stl_be_pci_dma(&s->dev, p + 12, desc->buf_addr2, attrs);\n    } else {\n        stl_le_pci_dma(&s->dev, p, desc->status, attrs);\n        stl_le_pci_dma(&s->dev, p + 4, desc->control, attrs);\n        stl_le_pci_dma(&s->dev, p + 8, desc->buf_addr1, attrs);\n        stl_le_pci_dma(&s->dev, p + 12, desc->buf_addr2, attrs);\n    }\n}",
        "func": "static void tulip_desc_write(TULIPState *s, hwaddr p,\n        struct tulip_descriptor *desc)\n{\n    const MemTxAttrs attrs = { .memory = true };\n\n    if (s->csr[0] & CSR0_DBO) {\n        stl_be_pci_dma(&s->dev, p, desc->status, attrs);\n        stl_be_pci_dma(&s->dev, p + 4, desc->control, attrs);\n        stl_be_pci_dma(&s->dev, p + 8, desc->buf_addr1, attrs);\n        stl_be_pci_dma(&s->dev, p + 12, desc->buf_addr2, attrs);\n    } else {\n        stl_le_pci_dma(&s->dev, p, desc->status, attrs);\n        stl_le_pci_dma(&s->dev, p + 4, desc->control, attrs);\n        stl_le_pci_dma(&s->dev, p + 8, desc->buf_addr1, attrs);\n        stl_le_pci_dma(&s->dev, p + 12, desc->buf_addr2, attrs);\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,7 +1,7 @@\n static void tulip_desc_write(TULIPState *s, hwaddr p,\n         struct tulip_descriptor *desc)\n {\n-    const MemTxAttrs attrs = MEMTXATTRS_UNSPECIFIED;\n+    const MemTxAttrs attrs = { .memory = true };\n \n     if (s->csr[0] & CSR0_DBO) {\n         stl_be_pci_dma(&s->dev, p, desc->status, attrs);",
        "diff_line_info": {
            "deleted_lines": [
                "    const MemTxAttrs attrs = MEMTXATTRS_UNSPECIFIED;"
            ],
            "added_lines": [
                "    const MemTxAttrs attrs = { .memory = true };"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-2962",
        "func_name": "qemu-project/qemu/tulip_desc_read",
        "description": "A DMA reentrancy issue was found in the Tulip device emulation in QEMU. When Tulip reads or writes to the rx/tx descriptor or copies the rx/tx frame, it doesn't check whether the destination address is its own MMIO address. This can cause the device to trigger MMIO handlers multiple times, possibly leading to a stack or heap overflow. A malicious guest could use this flaw to crash the QEMU process on the host, resulting in a denial of service condition.",
        "git_url": "https://gitlab.com/qemu-project/qemu/-/commit/36a894aeb64a2e02871016da1c37d4a4ca109182",
        "commit_title": "net: tulip: Restrict DMA engine to memories",
        "commit_text": " The DMA engine is started by I/O access and then itself accesses the I/O registers, triggering a reentrancy bug.  The following log can reveal it: ==5637==ERROR: AddressSanitizer: stack-overflow     #0 0x5595435f6078 in tulip_xmit_list_update qemu/hw/net/tulip.c:673     #1 0x5595435f204a in tulip_write qemu/hw/net/tulip.c:805:13     #2 0x559544637f86 in memory_region_write_accessor qemu/softmmu/memory.c:492:5     #3 0x5595446379fa in access_with_adjusted_size qemu/softmmu/memory.c:554:18     #4 0x5595446372fa in memory_region_dispatch_write qemu/softmmu/memory.c     #5 0x55954468b74c in flatview_write_continue qemu/softmmu/physmem.c:2825:23     #6 0x559544683662 in flatview_write qemu/softmmu/physmem.c:2867:12     #7 0x5595446833f3 in address_space_write qemu/softmmu/physmem.c:2963:18     #8 0x5595435fb082 in dma_memory_rw_relaxed qemu/include/sysemu/dma.h:87:12     #9 0x5595435fb082 in dma_memory_rw qemu/include/sysemu/dma.h:130:12     #10 0x5595435fb082 in dma_memory_write qemu/include/sysemu/dma.h:171:12     #11 0x5595435fb082 in stl_le_dma qemu/include/sysemu/dma.h:272:1     #12 0x5595435fb082 in stl_le_pci_dma qemu/include/hw/pci/pci.h:910:1     #13 0x5595435fb082 in tulip_desc_write qemu/hw/net/tulip.c:101:9     #14 0x5595435f7e3d in tulip_xmit_list_update qemu/hw/net/tulip.c:706:9     #15 0x5595435f204a in tulip_write qemu/hw/net/tulip.c:805:13  Fix this bug by restricting the DMA engine to memories regions.  ",
        "func_before": "static void tulip_desc_read(TULIPState *s, hwaddr p,\n        struct tulip_descriptor *desc)\n{\n    const MemTxAttrs attrs = MEMTXATTRS_UNSPECIFIED;\n\n    if (s->csr[0] & CSR0_DBO) {\n        ldl_be_pci_dma(&s->dev, p, &desc->status, attrs);\n        ldl_be_pci_dma(&s->dev, p + 4, &desc->control, attrs);\n        ldl_be_pci_dma(&s->dev, p + 8, &desc->buf_addr1, attrs);\n        ldl_be_pci_dma(&s->dev, p + 12, &desc->buf_addr2, attrs);\n    } else {\n        ldl_le_pci_dma(&s->dev, p, &desc->status, attrs);\n        ldl_le_pci_dma(&s->dev, p + 4, &desc->control, attrs);\n        ldl_le_pci_dma(&s->dev, p + 8, &desc->buf_addr1, attrs);\n        ldl_le_pci_dma(&s->dev, p + 12, &desc->buf_addr2, attrs);\n    }\n}",
        "func": "static void tulip_desc_read(TULIPState *s, hwaddr p,\n        struct tulip_descriptor *desc)\n{\n    const MemTxAttrs attrs = { .memory = true };\n\n    if (s->csr[0] & CSR0_DBO) {\n        ldl_be_pci_dma(&s->dev, p, &desc->status, attrs);\n        ldl_be_pci_dma(&s->dev, p + 4, &desc->control, attrs);\n        ldl_be_pci_dma(&s->dev, p + 8, &desc->buf_addr1, attrs);\n        ldl_be_pci_dma(&s->dev, p + 12, &desc->buf_addr2, attrs);\n    } else {\n        ldl_le_pci_dma(&s->dev, p, &desc->status, attrs);\n        ldl_le_pci_dma(&s->dev, p + 4, &desc->control, attrs);\n        ldl_le_pci_dma(&s->dev, p + 8, &desc->buf_addr1, attrs);\n        ldl_le_pci_dma(&s->dev, p + 12, &desc->buf_addr2, attrs);\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,7 +1,7 @@\n static void tulip_desc_read(TULIPState *s, hwaddr p,\n         struct tulip_descriptor *desc)\n {\n-    const MemTxAttrs attrs = MEMTXATTRS_UNSPECIFIED;\n+    const MemTxAttrs attrs = { .memory = true };\n \n     if (s->csr[0] & CSR0_DBO) {\n         ldl_be_pci_dma(&s->dev, p, &desc->status, attrs);",
        "diff_line_info": {
            "deleted_lines": [
                "    const MemTxAttrs attrs = MEMTXATTRS_UNSPECIFIED;"
            ],
            "added_lines": [
                "    const MemTxAttrs attrs = { .memory = true };"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-3565",
        "func_name": "kernel/git/bluetooth/bluetooth-next/l1oip_socket_send",
        "description": "A vulnerability, which was classified as critical, has been found in Linux Kernel. Affected by this issue is the function del_timer of the file drivers/isdn/mISDN/l1oip_core.c of the component Bluetooth. The manipulation leads to use after free. It is recommended to apply a patch to fix this issue. The identifier of this vulnerability is VDB-211088.",
        "git_url": "https://git.kernel.org/pub/scm/linux/kernel/git/bluetooth/bluetooth-next.git/commit/?h=2568a7e0832ee30b0a351016d03062ab4e0e0a3f",
        "commit_title": "The l1oip_cleanup() traverses the l1oip_ilist and calls",
        "commit_text": "release_card() to cleanup module and stack. However, release_card() calls del_timer() to delete the timers such as keep_tl and timeout_tl. If the timer handler is running, the del_timer() will not stop it and result in UAF bugs. One of the processes is shown below:      (cleanup routine)          |        (timer handler) release_card()                 | l1oip_timeout()  ...                           |  del_timer()                   | ...  ...                           |  kfree(hc) //FREE              |                                | hc->timeout_on = 0 //USE  Fix by calling del_timer_sync() in release_card(), which makes sure the timer handlers have finished before the resources, such as l1oip and so on, have been deallocated.  What's more, the hc->workq and hc->socket_thread can kick those timers right back in. We add a bool flag to show if card is released. Then, check this flag in hc->workq and hc->socket_thread.  ",
        "func_before": "static int\nl1oip_socket_send(struct l1oip *hc, u8 localcodec, u8 channel, u32 chanmask,\n\t\t  u16 timebase, u8 *buf, int len)\n{\n\tu8 *p;\n\tu8 frame[MAX_DFRAME_LEN_L1 + 32];\n\tstruct socket *socket = NULL;\n\n\tif (debug & DEBUG_L1OIP_MSG)\n\t\tprintk(KERN_DEBUG \"%s: sending data to socket (len = %d)\\n\",\n\t\t       __func__, len);\n\n\tp = frame;\n\n\t/* restart timer */\n\tif (time_before(hc->keep_tl.expires, jiffies + 5 * HZ))\n\t\tmod_timer(&hc->keep_tl, jiffies + L1OIP_KEEPALIVE * HZ);\n\telse\n\t\thc->keep_tl.expires = jiffies + L1OIP_KEEPALIVE * HZ;\n\n\tif (debug & DEBUG_L1OIP_MSG)\n\t\tprintk(KERN_DEBUG \"%s: resetting timer\\n\", __func__);\n\n\t/* drop if we have no remote ip or port */\n\tif (!hc->sin_remote.sin_addr.s_addr || !hc->sin_remote.sin_port) {\n\t\tif (debug & DEBUG_L1OIP_MSG)\n\t\t\tprintk(KERN_DEBUG \"%s: dropping frame, because remote \"\n\t\t\t       \"IP is not set.\\n\", __func__);\n\t\treturn len;\n\t}\n\n\t/* assemble frame */\n\t*p++ = (L1OIP_VERSION << 6) /* version and coding */\n\t\t| (hc->pri ? 0x20 : 0x00) /* type */\n\t\t| (hc->id ? 0x10 : 0x00) /* id */\n\t\t| localcodec;\n\tif (hc->id) {\n\t\t*p++ = hc->id >> 24; /* id */\n\t\t*p++ = hc->id >> 16;\n\t\t*p++ = hc->id >> 8;\n\t\t*p++ = hc->id;\n\t}\n\t*p++ =  0x00 + channel; /* m-flag, channel */\n\t*p++ = timebase >> 8; /* time base */\n\t*p++ = timebase;\n\n\tif (buf && len) { /* add data to frame */\n\t\tif (localcodec == 1 && ulaw)\n\t\t\tl1oip_ulaw_to_alaw(buf, len, p);\n\t\telse if (localcodec == 2 && !ulaw)\n\t\t\tl1oip_alaw_to_ulaw(buf, len, p);\n\t\telse if (localcodec == 3)\n\t\t\tlen = l1oip_law_to_4bit(buf, len, p,\n\t\t\t\t\t\t&hc->chan[channel].codecstate);\n\t\telse\n\t\t\tmemcpy(p, buf, len);\n\t}\n\tlen += p - frame;\n\n\t/* check for socket in safe condition */\n\tspin_lock(&hc->socket_lock);\n\tif (!hc->socket) {\n\t\tspin_unlock(&hc->socket_lock);\n\t\treturn 0;\n\t}\n\t/* seize socket */\n\tsocket = hc->socket;\n\thc->socket = NULL;\n\tspin_unlock(&hc->socket_lock);\n\t/* send packet */\n\tif (debug & DEBUG_L1OIP_MSG)\n\t\tprintk(KERN_DEBUG \"%s: sending packet to socket (len \"\n\t\t       \"= %d)\\n\", __func__, len);\n\thc->sendiov.iov_base = frame;\n\thc->sendiov.iov_len  = len;\n\tlen = kernel_sendmsg(socket, &hc->sendmsg, &hc->sendiov, 1, len);\n\t/* give socket back */\n\thc->socket = socket; /* no locking required */\n\n\treturn len;\n}",
        "func": "static int\nl1oip_socket_send(struct l1oip *hc, u8 localcodec, u8 channel, u32 chanmask,\n\t\t  u16 timebase, u8 *buf, int len)\n{\n\tu8 *p;\n\tu8 frame[MAX_DFRAME_LEN_L1 + 32];\n\tstruct socket *socket = NULL;\n\n\tif (debug & DEBUG_L1OIP_MSG)\n\t\tprintk(KERN_DEBUG \"%s: sending data to socket (len = %d)\\n\",\n\t\t       __func__, len);\n\n\tp = frame;\n\n\t/* restart timer */\n\tif (time_before(hc->keep_tl.expires, jiffies + 5 * HZ) && !hc->shutdown)\n\t\tmod_timer(&hc->keep_tl, jiffies + L1OIP_KEEPALIVE * HZ);\n\telse\n\t\thc->keep_tl.expires = jiffies + L1OIP_KEEPALIVE * HZ;\n\n\tif (debug & DEBUG_L1OIP_MSG)\n\t\tprintk(KERN_DEBUG \"%s: resetting timer\\n\", __func__);\n\n\t/* drop if we have no remote ip or port */\n\tif (!hc->sin_remote.sin_addr.s_addr || !hc->sin_remote.sin_port) {\n\t\tif (debug & DEBUG_L1OIP_MSG)\n\t\t\tprintk(KERN_DEBUG \"%s: dropping frame, because remote \"\n\t\t\t       \"IP is not set.\\n\", __func__);\n\t\treturn len;\n\t}\n\n\t/* assemble frame */\n\t*p++ = (L1OIP_VERSION << 6) /* version and coding */\n\t\t| (hc->pri ? 0x20 : 0x00) /* type */\n\t\t| (hc->id ? 0x10 : 0x00) /* id */\n\t\t| localcodec;\n\tif (hc->id) {\n\t\t*p++ = hc->id >> 24; /* id */\n\t\t*p++ = hc->id >> 16;\n\t\t*p++ = hc->id >> 8;\n\t\t*p++ = hc->id;\n\t}\n\t*p++ =  0x00 + channel; /* m-flag, channel */\n\t*p++ = timebase >> 8; /* time base */\n\t*p++ = timebase;\n\n\tif (buf && len) { /* add data to frame */\n\t\tif (localcodec == 1 && ulaw)\n\t\t\tl1oip_ulaw_to_alaw(buf, len, p);\n\t\telse if (localcodec == 2 && !ulaw)\n\t\t\tl1oip_alaw_to_ulaw(buf, len, p);\n\t\telse if (localcodec == 3)\n\t\t\tlen = l1oip_law_to_4bit(buf, len, p,\n\t\t\t\t\t\t&hc->chan[channel].codecstate);\n\t\telse\n\t\t\tmemcpy(p, buf, len);\n\t}\n\tlen += p - frame;\n\n\t/* check for socket in safe condition */\n\tspin_lock(&hc->socket_lock);\n\tif (!hc->socket) {\n\t\tspin_unlock(&hc->socket_lock);\n\t\treturn 0;\n\t}\n\t/* seize socket */\n\tsocket = hc->socket;\n\thc->socket = NULL;\n\tspin_unlock(&hc->socket_lock);\n\t/* send packet */\n\tif (debug & DEBUG_L1OIP_MSG)\n\t\tprintk(KERN_DEBUG \"%s: sending packet to socket (len \"\n\t\t       \"= %d)\\n\", __func__, len);\n\thc->sendiov.iov_base = frame;\n\thc->sendiov.iov_len  = len;\n\tlen = kernel_sendmsg(socket, &hc->sendmsg, &hc->sendiov, 1, len);\n\t/* give socket back */\n\thc->socket = socket; /* no locking required */\n\n\treturn len;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -13,7 +13,7 @@\n \tp = frame;\n \n \t/* restart timer */\n-\tif (time_before(hc->keep_tl.expires, jiffies + 5 * HZ))\n+\tif (time_before(hc->keep_tl.expires, jiffies + 5 * HZ) && !hc->shutdown)\n \t\tmod_timer(&hc->keep_tl, jiffies + L1OIP_KEEPALIVE * HZ);\n \telse\n \t\thc->keep_tl.expires = jiffies + L1OIP_KEEPALIVE * HZ;",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (time_before(hc->keep_tl.expires, jiffies + 5 * HZ))"
            ],
            "added_lines": [
                "\tif (time_before(hc->keep_tl.expires, jiffies + 5 * HZ) && !hc->shutdown)"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-3565",
        "func_name": "kernel/git/bluetooth/bluetooth-next/release_card",
        "description": "A vulnerability, which was classified as critical, has been found in Linux Kernel. Affected by this issue is the function del_timer of the file drivers/isdn/mISDN/l1oip_core.c of the component Bluetooth. The manipulation leads to use after free. It is recommended to apply a patch to fix this issue. The identifier of this vulnerability is VDB-211088.",
        "git_url": "https://git.kernel.org/pub/scm/linux/kernel/git/bluetooth/bluetooth-next.git/commit/?h=2568a7e0832ee30b0a351016d03062ab4e0e0a3f",
        "commit_title": "The l1oip_cleanup() traverses the l1oip_ilist and calls",
        "commit_text": "release_card() to cleanup module and stack. However, release_card() calls del_timer() to delete the timers such as keep_tl and timeout_tl. If the timer handler is running, the del_timer() will not stop it and result in UAF bugs. One of the processes is shown below:      (cleanup routine)          |        (timer handler) release_card()                 | l1oip_timeout()  ...                           |  del_timer()                   | ...  ...                           |  kfree(hc) //FREE              |                                | hc->timeout_on = 0 //USE  Fix by calling del_timer_sync() in release_card(), which makes sure the timer handlers have finished before the resources, such as l1oip and so on, have been deallocated.  What's more, the hc->workq and hc->socket_thread can kick those timers right back in. We add a bool flag to show if card is released. Then, check this flag in hc->workq and hc->socket_thread.  ",
        "func_before": "static void\nrelease_card(struct l1oip *hc)\n{\n\tint\tch;\n\n\tif (timer_pending(&hc->keep_tl))\n\t\tdel_timer(&hc->keep_tl);\n\n\tif (timer_pending(&hc->timeout_tl))\n\t\tdel_timer(&hc->timeout_tl);\n\n\tcancel_work_sync(&hc->workq);\n\n\tif (hc->socket_thread)\n\t\tl1oip_socket_close(hc);\n\n\tif (hc->registered && hc->chan[hc->d_idx].dch)\n\t\tmISDN_unregister_device(&hc->chan[hc->d_idx].dch->dev);\n\tfor (ch = 0; ch < 128; ch++) {\n\t\tif (hc->chan[ch].dch) {\n\t\t\tmISDN_freedchannel(hc->chan[ch].dch);\n\t\t\tkfree(hc->chan[ch].dch);\n\t\t}\n\t\tif (hc->chan[ch].bch) {\n\t\t\tmISDN_freebchannel(hc->chan[ch].bch);\n\t\t\tkfree(hc->chan[ch].bch);\n#ifdef REORDER_DEBUG\n\t\t\tdev_kfree_skb(hc->chan[ch].disorder_skb);\n#endif\n\t\t}\n\t}\n\n\tspin_lock(&l1oip_lock);\n\tlist_del(&hc->list);\n\tspin_unlock(&l1oip_lock);\n\n\tkfree(hc);\n}",
        "func": "static void\nrelease_card(struct l1oip *hc)\n{\n\tint\tch;\n\n\thc->shutdown = true;\n\n\tdel_timer_sync(&hc->keep_tl);\n\tdel_timer_sync(&hc->timeout_tl);\n\n\tcancel_work_sync(&hc->workq);\n\n\tif (hc->socket_thread)\n\t\tl1oip_socket_close(hc);\n\n\tif (hc->registered && hc->chan[hc->d_idx].dch)\n\t\tmISDN_unregister_device(&hc->chan[hc->d_idx].dch->dev);\n\tfor (ch = 0; ch < 128; ch++) {\n\t\tif (hc->chan[ch].dch) {\n\t\t\tmISDN_freedchannel(hc->chan[ch].dch);\n\t\t\tkfree(hc->chan[ch].dch);\n\t\t}\n\t\tif (hc->chan[ch].bch) {\n\t\t\tmISDN_freebchannel(hc->chan[ch].bch);\n\t\t\tkfree(hc->chan[ch].bch);\n#ifdef REORDER_DEBUG\n\t\t\tdev_kfree_skb(hc->chan[ch].disorder_skb);\n#endif\n\t\t}\n\t}\n\n\tspin_lock(&l1oip_lock);\n\tlist_del(&hc->list);\n\tspin_unlock(&l1oip_lock);\n\n\tkfree(hc);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,11 +3,10 @@\n {\n \tint\tch;\n \n-\tif (timer_pending(&hc->keep_tl))\n-\t\tdel_timer(&hc->keep_tl);\n+\thc->shutdown = true;\n \n-\tif (timer_pending(&hc->timeout_tl))\n-\t\tdel_timer(&hc->timeout_tl);\n+\tdel_timer_sync(&hc->keep_tl);\n+\tdel_timer_sync(&hc->timeout_tl);\n \n \tcancel_work_sync(&hc->workq);\n ",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (timer_pending(&hc->keep_tl))",
                "\t\tdel_timer(&hc->keep_tl);",
                "\tif (timer_pending(&hc->timeout_tl))",
                "\t\tdel_timer(&hc->timeout_tl);"
            ],
            "added_lines": [
                "\thc->shutdown = true;",
                "\tdel_timer_sync(&hc->keep_tl);",
                "\tdel_timer_sync(&hc->timeout_tl);"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-3565",
        "func_name": "kernel/git/bluetooth/bluetooth-next/l1oip_socket_parse",
        "description": "A vulnerability, which was classified as critical, has been found in Linux Kernel. Affected by this issue is the function del_timer of the file drivers/isdn/mISDN/l1oip_core.c of the component Bluetooth. The manipulation leads to use after free. It is recommended to apply a patch to fix this issue. The identifier of this vulnerability is VDB-211088.",
        "git_url": "https://git.kernel.org/pub/scm/linux/kernel/git/bluetooth/bluetooth-next.git/commit/?h=2568a7e0832ee30b0a351016d03062ab4e0e0a3f",
        "commit_title": "The l1oip_cleanup() traverses the l1oip_ilist and calls",
        "commit_text": "release_card() to cleanup module and stack. However, release_card() calls del_timer() to delete the timers such as keep_tl and timeout_tl. If the timer handler is running, the del_timer() will not stop it and result in UAF bugs. One of the processes is shown below:      (cleanup routine)          |        (timer handler) release_card()                 | l1oip_timeout()  ...                           |  del_timer()                   | ...  ...                           |  kfree(hc) //FREE              |                                | hc->timeout_on = 0 //USE  Fix by calling del_timer_sync() in release_card(), which makes sure the timer handlers have finished before the resources, such as l1oip and so on, have been deallocated.  What's more, the hc->workq and hc->socket_thread can kick those timers right back in. We add a bool flag to show if card is released. Then, check this flag in hc->workq and hc->socket_thread.  ",
        "func_before": "static void\nl1oip_socket_parse(struct l1oip *hc, struct sockaddr_in *sin, u8 *buf, int len)\n{\n\tu32\t\t\tpacket_id;\n\tu8\t\t\tchannel;\n\tu8\t\t\tremotecodec;\n\tu16\t\t\ttimebase;\n\tint\t\t\tm, mlen;\n\tint\t\t\tlen_start = len; /* initial frame length */\n\tstruct dchannel\t\t*dch = hc->chan[hc->d_idx].dch;\n\n\tif (debug & DEBUG_L1OIP_MSG)\n\t\tprintk(KERN_DEBUG \"%s: received frame, parsing... (%d)\\n\",\n\t\t       __func__, len);\n\n\t/* check length */\n\tif (len < 1 + 1 + 2) {\n\t\tprintk(KERN_WARNING \"%s: packet error - length %d below \"\n\t\t       \"4 bytes\\n\", __func__, len);\n\t\treturn;\n\t}\n\n\t/* check version */\n\tif (((*buf) >> 6) != L1OIP_VERSION) {\n\t\tprintk(KERN_WARNING \"%s: packet error - unknown version %d\\n\",\n\t\t       __func__, buf[0]>>6);\n\t\treturn;\n\t}\n\n\t/* check type */\n\tif (((*buf) & 0x20) && !hc->pri) {\n\t\tprintk(KERN_WARNING \"%s: packet error - received E1 packet \"\n\t\t       \"on S0 interface\\n\", __func__);\n\t\treturn;\n\t}\n\tif (!((*buf) & 0x20) && hc->pri) {\n\t\tprintk(KERN_WARNING \"%s: packet error - received S0 packet \"\n\t\t       \"on E1 interface\\n\", __func__);\n\t\treturn;\n\t}\n\n\t/* get id flag */\n\tpacket_id = (*buf >> 4) & 1;\n\n\t/* check coding */\n\tremotecodec = (*buf) & 0x0f;\n\tif (remotecodec > 3) {\n\t\tprintk(KERN_WARNING \"%s: packet error - remotecodec %d \"\n\t\t       \"unsupported\\n\", __func__, remotecodec);\n\t\treturn;\n\t}\n\tbuf++;\n\tlen--;\n\n\t/* check packet_id */\n\tif (packet_id) {\n\t\tif (!hc->id) {\n\t\t\tprintk(KERN_WARNING \"%s: packet error - packet has id \"\n\t\t\t       \"0x%x, but we have not\\n\", __func__, packet_id);\n\t\t\treturn;\n\t\t}\n\t\tif (len < 4) {\n\t\t\tprintk(KERN_WARNING \"%s: packet error - packet too \"\n\t\t\t       \"short for ID value\\n\", __func__);\n\t\t\treturn;\n\t\t}\n\t\tpacket_id = (*buf++) << 24;\n\t\tpacket_id += (*buf++) << 16;\n\t\tpacket_id += (*buf++) << 8;\n\t\tpacket_id += (*buf++);\n\t\tlen -= 4;\n\n\t\tif (packet_id != hc->id) {\n\t\t\tprintk(KERN_WARNING \"%s: packet error - ID mismatch, \"\n\t\t\t       \"got 0x%x, we 0x%x\\n\",\n\t\t\t       __func__, packet_id, hc->id);\n\t\t\treturn;\n\t\t}\n\t} else {\n\t\tif (hc->id) {\n\t\t\tprintk(KERN_WARNING \"%s: packet error - packet has no \"\n\t\t\t       \"ID, but we have\\n\", __func__);\n\t\t\treturn;\n\t\t}\n\t}\n\nmultiframe:\n\tif (len < 1) {\n\t\tprintk(KERN_WARNING \"%s: packet error - packet too short, \"\n\t\t       \"channel expected at position %d.\\n\",\n\t\t       __func__, len-len_start + 1);\n\t\treturn;\n\t}\n\n\t/* get channel and multiframe flag */\n\tchannel = *buf & 0x7f;\n\tm = *buf >> 7;\n\tbuf++;\n\tlen--;\n\n\t/* check length on multiframe */\n\tif (m) {\n\t\tif (len < 1) {\n\t\t\tprintk(KERN_WARNING \"%s: packet error - packet too \"\n\t\t\t       \"short, length expected at position %d.\\n\",\n\t\t\t       __func__, len_start - len - 1);\n\t\t\treturn;\n\t\t}\n\n\t\tmlen = *buf++;\n\t\tlen--;\n\t\tif (mlen == 0)\n\t\t\tmlen = 256;\n\t\tif (len < mlen + 3) {\n\t\t\tprintk(KERN_WARNING \"%s: packet error - length %d at \"\n\t\t\t       \"position %d exceeds total length %d.\\n\",\n\t\t\t       __func__, mlen, len_start-len - 1, len_start);\n\t\t\treturn;\n\t\t}\n\t\tif (len == mlen + 3) {\n\t\t\tprintk(KERN_WARNING \"%s: packet error - length %d at \"\n\t\t\t       \"position %d will not allow additional \"\n\t\t\t       \"packet.\\n\",\n\t\t\t       __func__, mlen, len_start-len + 1);\n\t\t\treturn;\n\t\t}\n\t} else\n\t\tmlen = len - 2; /* single frame, subtract timebase */\n\n\tif (len < 2) {\n\t\tprintk(KERN_WARNING \"%s: packet error - packet too short, time \"\n\t\t       \"base expected at position %d.\\n\",\n\t\t       __func__, len-len_start + 1);\n\t\treturn;\n\t}\n\n\t/* get time base */\n\ttimebase = (*buf++) << 8;\n\ttimebase |= (*buf++);\n\tlen -= 2;\n\n\t/* if inactive, we send up a PH_ACTIVATE and activate */\n\tif (!test_bit(FLG_ACTIVE, &dch->Flags)) {\n\t\tif (debug & (DEBUG_L1OIP_MSG | DEBUG_L1OIP_SOCKET))\n\t\t\tprintk(KERN_DEBUG \"%s: interface become active due to \"\n\t\t\t       \"received packet\\n\", __func__);\n\t\ttest_and_set_bit(FLG_ACTIVE, &dch->Flags);\n\t\t_queue_data(&dch->dev.D, PH_ACTIVATE_IND, MISDN_ID_ANY, 0,\n\t\t\t    NULL, GFP_ATOMIC);\n\t}\n\n\t/* distribute packet */\n\tl1oip_socket_recv(hc, remotecodec, channel, timebase, buf, mlen);\n\tbuf += mlen;\n\tlen -= mlen;\n\n\t/* multiframe */\n\tif (m)\n\t\tgoto multiframe;\n\n\t/* restart timer */\n\tif (time_before(hc->timeout_tl.expires, jiffies + 5 * HZ) || !hc->timeout_on) {\n\t\thc->timeout_on = 1;\n\t\tmod_timer(&hc->timeout_tl, jiffies + L1OIP_TIMEOUT * HZ);\n\t} else /* only adjust timer */\n\t\thc->timeout_tl.expires = jiffies + L1OIP_TIMEOUT * HZ;\n\n\t/* if ip or source port changes */\n\tif ((hc->sin_remote.sin_addr.s_addr != sin->sin_addr.s_addr)\n\t    || (hc->sin_remote.sin_port != sin->sin_port)) {\n\t\tif (debug & DEBUG_L1OIP_SOCKET)\n\t\t\tprintk(KERN_DEBUG \"%s: remote address changes from \"\n\t\t\t       \"0x%08x to 0x%08x (port %d to %d)\\n\", __func__,\n\t\t\t       ntohl(hc->sin_remote.sin_addr.s_addr),\n\t\t\t       ntohl(sin->sin_addr.s_addr),\n\t\t\t       ntohs(hc->sin_remote.sin_port),\n\t\t\t       ntohs(sin->sin_port));\n\t\thc->sin_remote.sin_addr.s_addr = sin->sin_addr.s_addr;\n\t\thc->sin_remote.sin_port = sin->sin_port;\n\t}\n}",
        "func": "static void\nl1oip_socket_parse(struct l1oip *hc, struct sockaddr_in *sin, u8 *buf, int len)\n{\n\tu32\t\t\tpacket_id;\n\tu8\t\t\tchannel;\n\tu8\t\t\tremotecodec;\n\tu16\t\t\ttimebase;\n\tint\t\t\tm, mlen;\n\tint\t\t\tlen_start = len; /* initial frame length */\n\tstruct dchannel\t\t*dch = hc->chan[hc->d_idx].dch;\n\n\tif (debug & DEBUG_L1OIP_MSG)\n\t\tprintk(KERN_DEBUG \"%s: received frame, parsing... (%d)\\n\",\n\t\t       __func__, len);\n\n\t/* check length */\n\tif (len < 1 + 1 + 2) {\n\t\tprintk(KERN_WARNING \"%s: packet error - length %d below \"\n\t\t       \"4 bytes\\n\", __func__, len);\n\t\treturn;\n\t}\n\n\t/* check version */\n\tif (((*buf) >> 6) != L1OIP_VERSION) {\n\t\tprintk(KERN_WARNING \"%s: packet error - unknown version %d\\n\",\n\t\t       __func__, buf[0]>>6);\n\t\treturn;\n\t}\n\n\t/* check type */\n\tif (((*buf) & 0x20) && !hc->pri) {\n\t\tprintk(KERN_WARNING \"%s: packet error - received E1 packet \"\n\t\t       \"on S0 interface\\n\", __func__);\n\t\treturn;\n\t}\n\tif (!((*buf) & 0x20) && hc->pri) {\n\t\tprintk(KERN_WARNING \"%s: packet error - received S0 packet \"\n\t\t       \"on E1 interface\\n\", __func__);\n\t\treturn;\n\t}\n\n\t/* get id flag */\n\tpacket_id = (*buf >> 4) & 1;\n\n\t/* check coding */\n\tremotecodec = (*buf) & 0x0f;\n\tif (remotecodec > 3) {\n\t\tprintk(KERN_WARNING \"%s: packet error - remotecodec %d \"\n\t\t       \"unsupported\\n\", __func__, remotecodec);\n\t\treturn;\n\t}\n\tbuf++;\n\tlen--;\n\n\t/* check packet_id */\n\tif (packet_id) {\n\t\tif (!hc->id) {\n\t\t\tprintk(KERN_WARNING \"%s: packet error - packet has id \"\n\t\t\t       \"0x%x, but we have not\\n\", __func__, packet_id);\n\t\t\treturn;\n\t\t}\n\t\tif (len < 4) {\n\t\t\tprintk(KERN_WARNING \"%s: packet error - packet too \"\n\t\t\t       \"short for ID value\\n\", __func__);\n\t\t\treturn;\n\t\t}\n\t\tpacket_id = (*buf++) << 24;\n\t\tpacket_id += (*buf++) << 16;\n\t\tpacket_id += (*buf++) << 8;\n\t\tpacket_id += (*buf++);\n\t\tlen -= 4;\n\n\t\tif (packet_id != hc->id) {\n\t\t\tprintk(KERN_WARNING \"%s: packet error - ID mismatch, \"\n\t\t\t       \"got 0x%x, we 0x%x\\n\",\n\t\t\t       __func__, packet_id, hc->id);\n\t\t\treturn;\n\t\t}\n\t} else {\n\t\tif (hc->id) {\n\t\t\tprintk(KERN_WARNING \"%s: packet error - packet has no \"\n\t\t\t       \"ID, but we have\\n\", __func__);\n\t\t\treturn;\n\t\t}\n\t}\n\nmultiframe:\n\tif (len < 1) {\n\t\tprintk(KERN_WARNING \"%s: packet error - packet too short, \"\n\t\t       \"channel expected at position %d.\\n\",\n\t\t       __func__, len-len_start + 1);\n\t\treturn;\n\t}\n\n\t/* get channel and multiframe flag */\n\tchannel = *buf & 0x7f;\n\tm = *buf >> 7;\n\tbuf++;\n\tlen--;\n\n\t/* check length on multiframe */\n\tif (m) {\n\t\tif (len < 1) {\n\t\t\tprintk(KERN_WARNING \"%s: packet error - packet too \"\n\t\t\t       \"short, length expected at position %d.\\n\",\n\t\t\t       __func__, len_start - len - 1);\n\t\t\treturn;\n\t\t}\n\n\t\tmlen = *buf++;\n\t\tlen--;\n\t\tif (mlen == 0)\n\t\t\tmlen = 256;\n\t\tif (len < mlen + 3) {\n\t\t\tprintk(KERN_WARNING \"%s: packet error - length %d at \"\n\t\t\t       \"position %d exceeds total length %d.\\n\",\n\t\t\t       __func__, mlen, len_start-len - 1, len_start);\n\t\t\treturn;\n\t\t}\n\t\tif (len == mlen + 3) {\n\t\t\tprintk(KERN_WARNING \"%s: packet error - length %d at \"\n\t\t\t       \"position %d will not allow additional \"\n\t\t\t       \"packet.\\n\",\n\t\t\t       __func__, mlen, len_start-len + 1);\n\t\t\treturn;\n\t\t}\n\t} else\n\t\tmlen = len - 2; /* single frame, subtract timebase */\n\n\tif (len < 2) {\n\t\tprintk(KERN_WARNING \"%s: packet error - packet too short, time \"\n\t\t       \"base expected at position %d.\\n\",\n\t\t       __func__, len-len_start + 1);\n\t\treturn;\n\t}\n\n\t/* get time base */\n\ttimebase = (*buf++) << 8;\n\ttimebase |= (*buf++);\n\tlen -= 2;\n\n\t/* if inactive, we send up a PH_ACTIVATE and activate */\n\tif (!test_bit(FLG_ACTIVE, &dch->Flags)) {\n\t\tif (debug & (DEBUG_L1OIP_MSG | DEBUG_L1OIP_SOCKET))\n\t\t\tprintk(KERN_DEBUG \"%s: interface become active due to \"\n\t\t\t       \"received packet\\n\", __func__);\n\t\ttest_and_set_bit(FLG_ACTIVE, &dch->Flags);\n\t\t_queue_data(&dch->dev.D, PH_ACTIVATE_IND, MISDN_ID_ANY, 0,\n\t\t\t    NULL, GFP_ATOMIC);\n\t}\n\n\t/* distribute packet */\n\tl1oip_socket_recv(hc, remotecodec, channel, timebase, buf, mlen);\n\tbuf += mlen;\n\tlen -= mlen;\n\n\t/* multiframe */\n\tif (m)\n\t\tgoto multiframe;\n\n\t/* restart timer */\n\tif ((time_before(hc->timeout_tl.expires, jiffies + 5 * HZ) ||\n\t     !hc->timeout_on) &&\n\t    !hc->shutdown) {\n\t\thc->timeout_on = 1;\n\t\tmod_timer(&hc->timeout_tl, jiffies + L1OIP_TIMEOUT * HZ);\n\t} else /* only adjust timer */\n\t\thc->timeout_tl.expires = jiffies + L1OIP_TIMEOUT * HZ;\n\n\t/* if ip or source port changes */\n\tif ((hc->sin_remote.sin_addr.s_addr != sin->sin_addr.s_addr)\n\t    || (hc->sin_remote.sin_port != sin->sin_port)) {\n\t\tif (debug & DEBUG_L1OIP_SOCKET)\n\t\t\tprintk(KERN_DEBUG \"%s: remote address changes from \"\n\t\t\t       \"0x%08x to 0x%08x (port %d to %d)\\n\", __func__,\n\t\t\t       ntohl(hc->sin_remote.sin_addr.s_addr),\n\t\t\t       ntohl(sin->sin_addr.s_addr),\n\t\t\t       ntohs(hc->sin_remote.sin_port),\n\t\t\t       ntohs(sin->sin_port));\n\t\thc->sin_remote.sin_addr.s_addr = sin->sin_addr.s_addr;\n\t\thc->sin_remote.sin_port = sin->sin_port;\n\t}\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -159,7 +159,9 @@\n \t\tgoto multiframe;\n \n \t/* restart timer */\n-\tif (time_before(hc->timeout_tl.expires, jiffies + 5 * HZ) || !hc->timeout_on) {\n+\tif ((time_before(hc->timeout_tl.expires, jiffies + 5 * HZ) ||\n+\t     !hc->timeout_on) &&\n+\t    !hc->shutdown) {\n \t\thc->timeout_on = 1;\n \t\tmod_timer(&hc->timeout_tl, jiffies + L1OIP_TIMEOUT * HZ);\n \t} else /* only adjust timer */",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (time_before(hc->timeout_tl.expires, jiffies + 5 * HZ) || !hc->timeout_on) {"
            ],
            "added_lines": [
                "\tif ((time_before(hc->timeout_tl.expires, jiffies + 5 * HZ) ||",
                "\t     !hc->timeout_on) &&",
                "\t    !hc->shutdown) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-19577",
        "func_name": "xen-project/xen/amd_iommu_domain_init",
        "description": "An issue was discovered in Xen through 4.12.x allowing x86 AMD HVM guest OS users to cause a denial of service or possibly gain privileges by triggering data-structure access during pagetable-height updates. When running on AMD systems with an IOMMU, Xen attempted to dynamically adapt the number of levels of pagetables (the pagetable height) in the IOMMU according to the guest's address space size. The code to select and update the height had several bugs. Notably, the update was done without taking a lock which is necessary for safe operation. A malicious guest administrator can cause Xen to access data structures while they are being modified, causing Xen to crash. Privilege escalation is thought to be very difficult but cannot be ruled out. Additionally, there is a potential memory leak of 4kb per guest boot, under memory pressure. Only Xen on AMD CPUs is vulnerable. Xen running on Intel CPUs is not vulnerable. ARM systems are not vulnerable. Only systems where guests are given direct access to physical devices are vulnerable. Systems which do not use PCI pass-through are not vulnerable. Only HVM guests can exploit the vulnerability. PV and PVH guests cannot. All versions of Xen with IOMMU support are vulnerable.",
        "git_url": "https://github.com/xen-project/xen/commit/b4f042236ae0bb6725b3e8dd40af5a2466a6f971",
        "commit_title": "AMD/IOMMU: Cease using a dynamic height for the IOMMU pagetables",
        "commit_text": " update_paging_mode() has multiple bugs:   1) Booting with iommu=debug will cause it to inform you that that it called     without the pdev_list lock held.  2) When growing by more than a single level, it leaks the newly allocated     table(s) in the case of a further error.  Furthermore, the choice of default level for a domain has issues:   1) All HVM guests grow from 2 to 3 levels during construction because of the     position of the VRAM just below the 4G boundary, so defaulting to 2 is a     waste of effort.  2) The limit for PV guests doesn't take memory hotplug into account, and     isn't dynamic at runtime like HVM guests.  This means that a PV guest may     get RAM which it can't map in the IOMMU.  The dynamic height is a property unique to AMD, and adds a substantial quantity of complexity for what is a marginal performance improvement.  Remove the complexity by removing the dynamic height.  PV guests now get 3 or 4 levels based on any hotplug regions in the host. This only makes a difference for hardware which previously had all RAM below the 512G boundary, and a hotplug region above.  HVM guests now get 4 levels (which will be sufficient until 256TB guests become a thing), because we don't currently have the information to know when 3 would be safe to use.  The overhead of this extra level is not expected to be noticeable.  It costs one page (4k) per domain, and one extra IO-TLB paging structure cache entry which is very hot and less likely to be evicted.  This is XSA-311. ",
        "func_before": "static int amd_iommu_domain_init(struct domain *d)\n{\n    struct domain_iommu *hd = dom_iommu(d);\n\n    /* For pv and dom0, stick with get_paging_mode(max_page)\n     * For HVM dom0, use 2 level page table at first */\n    hd->arch.paging_mode = is_hvm_domain(d) ?\n        2 : amd_iommu_get_paging_mode(max_page);\n    return 0;\n}",
        "func": "static int amd_iommu_domain_init(struct domain *d)\n{\n    struct domain_iommu *hd = dom_iommu(d);\n\n    /*\n     * Choose the number of levels for the IOMMU page tables.\n     * - PV needs 3 or 4, depending on whether there is RAM (including hotplug\n     *   RAM) above the 512G boundary.\n     * - HVM could in principle use 3 or 4 depending on how much guest\n     *   physical address space we give it, but this isn't known yet so use 4\n     *   unilaterally.\n     */\n    hd->arch.paging_mode = is_hvm_domain(d)\n        ? 4 : amd_iommu_get_paging_mode(get_upper_mfn_bound());\n\n    return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,9 +2,16 @@\n {\n     struct domain_iommu *hd = dom_iommu(d);\n \n-    /* For pv and dom0, stick with get_paging_mode(max_page)\n-     * For HVM dom0, use 2 level page table at first */\n-    hd->arch.paging_mode = is_hvm_domain(d) ?\n-        2 : amd_iommu_get_paging_mode(max_page);\n+    /*\n+     * Choose the number of levels for the IOMMU page tables.\n+     * - PV needs 3 or 4, depending on whether there is RAM (including hotplug\n+     *   RAM) above the 512G boundary.\n+     * - HVM could in principle use 3 or 4 depending on how much guest\n+     *   physical address space we give it, but this isn't known yet so use 4\n+     *   unilaterally.\n+     */\n+    hd->arch.paging_mode = is_hvm_domain(d)\n+        ? 4 : amd_iommu_get_paging_mode(get_upper_mfn_bound());\n+\n     return 0;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    /* For pv and dom0, stick with get_paging_mode(max_page)",
                "     * For HVM dom0, use 2 level page table at first */",
                "    hd->arch.paging_mode = is_hvm_domain(d) ?",
                "        2 : amd_iommu_get_paging_mode(max_page);"
            ],
            "added_lines": [
                "    /*",
                "     * Choose the number of levels for the IOMMU page tables.",
                "     * - PV needs 3 or 4, depending on whether there is RAM (including hotplug",
                "     *   RAM) above the 512G boundary.",
                "     * - HVM could in principle use 3 or 4 depending on how much guest",
                "     *   physical address space we give it, but this isn't known yet so use 4",
                "     *   unilaterally.",
                "     */",
                "    hd->arch.paging_mode = is_hvm_domain(d)",
                "        ? 4 : amd_iommu_get_paging_mode(get_upper_mfn_bound());",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2019-19577",
        "func_name": "xen-project/xen/amd_iommu_map_page",
        "description": "An issue was discovered in Xen through 4.12.x allowing x86 AMD HVM guest OS users to cause a denial of service or possibly gain privileges by triggering data-structure access during pagetable-height updates. When running on AMD systems with an IOMMU, Xen attempted to dynamically adapt the number of levels of pagetables (the pagetable height) in the IOMMU according to the guest's address space size. The code to select and update the height had several bugs. Notably, the update was done without taking a lock which is necessary for safe operation. A malicious guest administrator can cause Xen to access data structures while they are being modified, causing Xen to crash. Privilege escalation is thought to be very difficult but cannot be ruled out. Additionally, there is a potential memory leak of 4kb per guest boot, under memory pressure. Only Xen on AMD CPUs is vulnerable. Xen running on Intel CPUs is not vulnerable. ARM systems are not vulnerable. Only systems where guests are given direct access to physical devices are vulnerable. Systems which do not use PCI pass-through are not vulnerable. Only HVM guests can exploit the vulnerability. PV and PVH guests cannot. All versions of Xen with IOMMU support are vulnerable.",
        "git_url": "https://github.com/xen-project/xen/commit/b4f042236ae0bb6725b3e8dd40af5a2466a6f971",
        "commit_title": "AMD/IOMMU: Cease using a dynamic height for the IOMMU pagetables",
        "commit_text": " update_paging_mode() has multiple bugs:   1) Booting with iommu=debug will cause it to inform you that that it called     without the pdev_list lock held.  2) When growing by more than a single level, it leaks the newly allocated     table(s) in the case of a further error.  Furthermore, the choice of default level for a domain has issues:   1) All HVM guests grow from 2 to 3 levels during construction because of the     position of the VRAM just below the 4G boundary, so defaulting to 2 is a     waste of effort.  2) The limit for PV guests doesn't take memory hotplug into account, and     isn't dynamic at runtime like HVM guests.  This means that a PV guest may     get RAM which it can't map in the IOMMU.  The dynamic height is a property unique to AMD, and adds a substantial quantity of complexity for what is a marginal performance improvement.  Remove the complexity by removing the dynamic height.  PV guests now get 3 or 4 levels based on any hotplug regions in the host. This only makes a difference for hardware which previously had all RAM below the 512G boundary, and a hotplug region above.  HVM guests now get 4 levels (which will be sufficient until 256TB guests become a thing), because we don't currently have the information to know when 3 would be safe to use.  The overhead of this extra level is not expected to be noticeable.  It costs one page (4k) per domain, and one extra IO-TLB paging structure cache entry which is very hot and less likely to be evicted.  This is XSA-311. ",
        "func_before": "int amd_iommu_map_page(struct domain *d, dfn_t dfn, mfn_t mfn,\n                       unsigned int flags, unsigned int *flush_flags)\n{\n    struct domain_iommu *hd = dom_iommu(d);\n    int rc;\n    unsigned long pt_mfn[7];\n\n    memset(pt_mfn, 0, sizeof(pt_mfn));\n\n    spin_lock(&hd->arch.mapping_lock);\n\n    rc = amd_iommu_alloc_root(hd);\n    if ( rc )\n    {\n        spin_unlock(&hd->arch.mapping_lock);\n        AMD_IOMMU_DEBUG(\"Root table alloc failed, dfn = %\"PRI_dfn\"\\n\",\n                        dfn_x(dfn));\n        domain_crash(d);\n        return rc;\n    }\n\n    /* Since HVM domain is initialized with 2 level IO page table,\n     * we might need a deeper page table for wider dfn now */\n    if ( is_hvm_domain(d) )\n    {\n        if ( update_paging_mode(d, dfn_x(dfn)) )\n        {\n            spin_unlock(&hd->arch.mapping_lock);\n            AMD_IOMMU_DEBUG(\"Update page mode failed dfn = %\"PRI_dfn\"\\n\",\n                            dfn_x(dfn));\n            domain_crash(d);\n            return -EFAULT;\n        }\n    }\n\n    if ( iommu_pde_from_dfn(d, dfn_x(dfn), pt_mfn, true) || (pt_mfn[1] == 0) )\n    {\n        spin_unlock(&hd->arch.mapping_lock);\n        AMD_IOMMU_DEBUG(\"Invalid IO pagetable entry dfn = %\"PRI_dfn\"\\n\",\n                        dfn_x(dfn));\n        domain_crash(d);\n        return -EFAULT;\n    }\n\n    /* Install 4k mapping */\n    *flush_flags |= set_iommu_pte_present(pt_mfn[1], dfn_x(dfn), mfn_x(mfn),\n                                          1, (flags & IOMMUF_writable),\n                                          (flags & IOMMUF_readable));\n\n    spin_unlock(&hd->arch.mapping_lock);\n\n    return 0;\n}",
        "func": "int amd_iommu_map_page(struct domain *d, dfn_t dfn, mfn_t mfn,\n                       unsigned int flags, unsigned int *flush_flags)\n{\n    struct domain_iommu *hd = dom_iommu(d);\n    int rc;\n    unsigned long pt_mfn[7];\n\n    memset(pt_mfn, 0, sizeof(pt_mfn));\n\n    spin_lock(&hd->arch.mapping_lock);\n\n    rc = amd_iommu_alloc_root(hd);\n    if ( rc )\n    {\n        spin_unlock(&hd->arch.mapping_lock);\n        AMD_IOMMU_DEBUG(\"Root table alloc failed, dfn = %\"PRI_dfn\"\\n\",\n                        dfn_x(dfn));\n        domain_crash(d);\n        return rc;\n    }\n\n    if ( iommu_pde_from_dfn(d, dfn_x(dfn), pt_mfn, true) || (pt_mfn[1] == 0) )\n    {\n        spin_unlock(&hd->arch.mapping_lock);\n        AMD_IOMMU_DEBUG(\"Invalid IO pagetable entry dfn = %\"PRI_dfn\"\\n\",\n                        dfn_x(dfn));\n        domain_crash(d);\n        return -EFAULT;\n    }\n\n    /* Install 4k mapping */\n    *flush_flags |= set_iommu_pte_present(pt_mfn[1], dfn_x(dfn), mfn_x(mfn),\n                                          1, (flags & IOMMUF_writable),\n                                          (flags & IOMMUF_readable));\n\n    spin_unlock(&hd->arch.mapping_lock);\n\n    return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -19,20 +19,6 @@\n         return rc;\n     }\n \n-    /* Since HVM domain is initialized with 2 level IO page table,\n-     * we might need a deeper page table for wider dfn now */\n-    if ( is_hvm_domain(d) )\n-    {\n-        if ( update_paging_mode(d, dfn_x(dfn)) )\n-        {\n-            spin_unlock(&hd->arch.mapping_lock);\n-            AMD_IOMMU_DEBUG(\"Update page mode failed dfn = %\"PRI_dfn\"\\n\",\n-                            dfn_x(dfn));\n-            domain_crash(d);\n-            return -EFAULT;\n-        }\n-    }\n-\n     if ( iommu_pde_from_dfn(d, dfn_x(dfn), pt_mfn, true) || (pt_mfn[1] == 0) )\n     {\n         spin_unlock(&hd->arch.mapping_lock);",
        "diff_line_info": {
            "deleted_lines": [
                "    /* Since HVM domain is initialized with 2 level IO page table,",
                "     * we might need a deeper page table for wider dfn now */",
                "    if ( is_hvm_domain(d) )",
                "    {",
                "        if ( update_paging_mode(d, dfn_x(dfn)) )",
                "        {",
                "            spin_unlock(&hd->arch.mapping_lock);",
                "            AMD_IOMMU_DEBUG(\"Update page mode failed dfn = %\"PRI_dfn\"\\n\",",
                "                            dfn_x(dfn));",
                "            domain_crash(d);",
                "            return -EFAULT;",
                "        }",
                "    }",
                ""
            ],
            "added_lines": []
        }
    },
    {
        "cve_id": "CVE-2020-25668",
        "func_name": "torvalds/linux/compat_fontx_ioctl",
        "description": "A flaw was found in Linux Kernel because access to the global variable fg_console is not properly synchronized leading to a use after free in con_font_op.",
        "git_url": "https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit?h=90bfdeef83f1d6c696039b6a917190dcbbad3220",
        "commit_title": "Some of the font tty ioctl's always used the current foreground VC for",
        "commit_text": "their operations.  Don't do that then.  This fixes a data race on fg_console.  Side note: both Michael Ellerman and Jiri Slaby point out that all these ioctls are deprecated, and should probably have been removed long ago, and everything seems to be using the KDFONTOP ioctl instead.  In fact, Michael points out that it looks like busybox's loadfont program seems to have switched over to using KDFONTOP exactly _because_ of this bug (ahem.. 12 years ago ;-).  Cc: Greg KH <greg@kroah.com> ",
        "func_before": "static inline int\ncompat_fontx_ioctl(int cmd, struct compat_consolefontdesc __user *user_cfd,\n\t\t\t int perm, struct console_font_op *op)\n{\n\tstruct compat_consolefontdesc cfdarg;\n\tint i;\n\n\tif (copy_from_user(&cfdarg, user_cfd, sizeof(struct compat_consolefontdesc)))\n\t\treturn -EFAULT;\n\n\tswitch (cmd) {\n\tcase PIO_FONTX:\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\t\top->op = KD_FONT_OP_SET;\n\t\top->flags = KD_FONT_FLAG_OLD;\n\t\top->width = 8;\n\t\top->height = cfdarg.charheight;\n\t\top->charcount = cfdarg.charcount;\n\t\top->data = compat_ptr(cfdarg.chardata);\n\t\treturn con_font_op(vc_cons[fg_console].d, op);\n\tcase GIO_FONTX:\n\t\top->op = KD_FONT_OP_GET;\n\t\top->flags = KD_FONT_FLAG_OLD;\n\t\top->width = 8;\n\t\top->height = cfdarg.charheight;\n\t\top->charcount = cfdarg.charcount;\n\t\top->data = compat_ptr(cfdarg.chardata);\n\t\ti = con_font_op(vc_cons[fg_console].d, op);\n\t\tif (i)\n\t\t\treturn i;\n\t\tcfdarg.charheight = op->height;\n\t\tcfdarg.charcount = op->charcount;\n\t\tif (copy_to_user(user_cfd, &cfdarg, sizeof(struct compat_consolefontdesc)))\n\t\t\treturn -EFAULT;\n\t\treturn 0;\n\t}\n\treturn -EINVAL;\n}",
        "func": "static inline int\ncompat_fontx_ioctl(struct vc_data *vc, int cmd,\n\t\t   struct compat_consolefontdesc __user *user_cfd,\n\t\t   int perm, struct console_font_op *op)\n{\n\tstruct compat_consolefontdesc cfdarg;\n\tint i;\n\n\tif (copy_from_user(&cfdarg, user_cfd, sizeof(struct compat_consolefontdesc)))\n\t\treturn -EFAULT;\n\n\tswitch (cmd) {\n\tcase PIO_FONTX:\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\t\top->op = KD_FONT_OP_SET;\n\t\top->flags = KD_FONT_FLAG_OLD;\n\t\top->width = 8;\n\t\top->height = cfdarg.charheight;\n\t\top->charcount = cfdarg.charcount;\n\t\top->data = compat_ptr(cfdarg.chardata);\n\t\treturn con_font_op(vc, op);\n\n\tcase GIO_FONTX:\n\t\top->op = KD_FONT_OP_GET;\n\t\top->flags = KD_FONT_FLAG_OLD;\n\t\top->width = 8;\n\t\top->height = cfdarg.charheight;\n\t\top->charcount = cfdarg.charcount;\n\t\top->data = compat_ptr(cfdarg.chardata);\n\t\ti = con_font_op(vc, op);\n\t\tif (i)\n\t\t\treturn i;\n\t\tcfdarg.charheight = op->height;\n\t\tcfdarg.charcount = op->charcount;\n\t\tif (copy_to_user(user_cfd, &cfdarg, sizeof(struct compat_consolefontdesc)))\n\t\t\treturn -EFAULT;\n\t\treturn 0;\n\t}\n\treturn -EINVAL;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,7 @@\n static inline int\n-compat_fontx_ioctl(int cmd, struct compat_consolefontdesc __user *user_cfd,\n-\t\t\t int perm, struct console_font_op *op)\n+compat_fontx_ioctl(struct vc_data *vc, int cmd,\n+\t\t   struct compat_consolefontdesc __user *user_cfd,\n+\t\t   int perm, struct console_font_op *op)\n {\n \tstruct compat_consolefontdesc cfdarg;\n \tint i;\n@@ -18,7 +19,8 @@\n \t\top->height = cfdarg.charheight;\n \t\top->charcount = cfdarg.charcount;\n \t\top->data = compat_ptr(cfdarg.chardata);\n-\t\treturn con_font_op(vc_cons[fg_console].d, op);\n+\t\treturn con_font_op(vc, op);\n+\n \tcase GIO_FONTX:\n \t\top->op = KD_FONT_OP_GET;\n \t\top->flags = KD_FONT_FLAG_OLD;\n@@ -26,7 +28,7 @@\n \t\top->height = cfdarg.charheight;\n \t\top->charcount = cfdarg.charcount;\n \t\top->data = compat_ptr(cfdarg.chardata);\n-\t\ti = con_font_op(vc_cons[fg_console].d, op);\n+\t\ti = con_font_op(vc, op);\n \t\tif (i)\n \t\t\treturn i;\n \t\tcfdarg.charheight = op->height;",
        "diff_line_info": {
            "deleted_lines": [
                "compat_fontx_ioctl(int cmd, struct compat_consolefontdesc __user *user_cfd,",
                "\t\t\t int perm, struct console_font_op *op)",
                "\t\treturn con_font_op(vc_cons[fg_console].d, op);",
                "\t\ti = con_font_op(vc_cons[fg_console].d, op);"
            ],
            "added_lines": [
                "compat_fontx_ioctl(struct vc_data *vc, int cmd,",
                "\t\t   struct compat_consolefontdesc __user *user_cfd,",
                "\t\t   int perm, struct console_font_op *op)",
                "\t\treturn con_font_op(vc, op);",
                "",
                "\t\ti = con_font_op(vc, op);"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-25668",
        "func_name": "torvalds/linux/vt_io_ioctl",
        "description": "A flaw was found in Linux Kernel because access to the global variable fg_console is not properly synchronized leading to a use after free in con_font_op.",
        "git_url": "https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit?h=90bfdeef83f1d6c696039b6a917190dcbbad3220",
        "commit_title": "Some of the font tty ioctl's always used the current foreground VC for",
        "commit_text": "their operations.  Don't do that then.  This fixes a data race on fg_console.  Side note: both Michael Ellerman and Jiri Slaby point out that all these ioctls are deprecated, and should probably have been removed long ago, and everything seems to be using the KDFONTOP ioctl instead.  In fact, Michael points out that it looks like busybox's loadfont program seems to have switched over to using KDFONTOP exactly _because_ of this bug (ahem.. 12 years ago ;-).  Cc: Greg KH <greg@kroah.com> ",
        "func_before": "static int vt_io_ioctl(struct vc_data *vc, unsigned int cmd, void __user *up,\n\t\tbool perm)\n{\n\tstruct console_font_op op;\t/* used in multiple places here */\n\n\tswitch (cmd) {\n\tcase PIO_FONT:\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\t\top.op = KD_FONT_OP_SET;\n\t\top.flags = KD_FONT_FLAG_OLD | KD_FONT_FLAG_DONT_RECALC;\t/* Compatibility */\n\t\top.width = 8;\n\t\top.height = 0;\n\t\top.charcount = 256;\n\t\top.data = up;\n\t\treturn con_font_op(vc_cons[fg_console].d, &op);\n\n\tcase GIO_FONT:\n\t\top.op = KD_FONT_OP_GET;\n\t\top.flags = KD_FONT_FLAG_OLD;\n\t\top.width = 8;\n\t\top.height = 32;\n\t\top.charcount = 256;\n\t\top.data = up;\n\t\treturn con_font_op(vc_cons[fg_console].d, &op);\n\n\tcase PIO_CMAP:\n                if (!perm)\n\t\t\treturn -EPERM;\n\t\treturn con_set_cmap(up);\n\n\tcase GIO_CMAP:\n                return con_get_cmap(up);\n\n\tcase PIO_FONTX:\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\n\t\tfallthrough;\n\tcase GIO_FONTX:\n\t\treturn do_fontx_ioctl(cmd, up, &op);\n\n\tcase PIO_FONTRESET:\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\n\t\treturn vt_io_fontreset(&op);\n\n\tcase PIO_SCRNMAP:\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\t\treturn con_set_trans_old(up);\n\n\tcase GIO_SCRNMAP:\n\t\treturn con_get_trans_old(up);\n\n\tcase PIO_UNISCRNMAP:\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\t\treturn con_set_trans_new(up);\n\n\tcase GIO_UNISCRNMAP:\n\t\treturn con_get_trans_new(up);\n\n\tcase PIO_UNIMAPCLR:\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\t\tcon_clear_unimap(vc);\n\t\tbreak;\n\n\tcase PIO_UNIMAP:\n\tcase GIO_UNIMAP:\n\t\treturn do_unimap_ioctl(cmd, up, perm, vc);\n\n\tdefault:\n\t\treturn -ENOIOCTLCMD;\n\t}\n\n\treturn 0;\n}",
        "func": "static int vt_io_ioctl(struct vc_data *vc, unsigned int cmd, void __user *up,\n\t\tbool perm)\n{\n\tstruct console_font_op op;\t/* used in multiple places here */\n\n\tswitch (cmd) {\n\tcase PIO_FONT:\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\t\top.op = KD_FONT_OP_SET;\n\t\top.flags = KD_FONT_FLAG_OLD | KD_FONT_FLAG_DONT_RECALC;\t/* Compatibility */\n\t\top.width = 8;\n\t\top.height = 0;\n\t\top.charcount = 256;\n\t\top.data = up;\n\t\treturn con_font_op(vc, &op);\n\n\tcase GIO_FONT:\n\t\top.op = KD_FONT_OP_GET;\n\t\top.flags = KD_FONT_FLAG_OLD;\n\t\top.width = 8;\n\t\top.height = 32;\n\t\top.charcount = 256;\n\t\top.data = up;\n\t\treturn con_font_op(vc, &op);\n\n\tcase PIO_CMAP:\n                if (!perm)\n\t\t\treturn -EPERM;\n\t\treturn con_set_cmap(up);\n\n\tcase GIO_CMAP:\n                return con_get_cmap(up);\n\n\tcase PIO_FONTX:\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\n\t\tfallthrough;\n\tcase GIO_FONTX:\n\t\treturn do_fontx_ioctl(vc, cmd, up, &op);\n\n\tcase PIO_FONTRESET:\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\n\t\treturn vt_io_fontreset(vc, &op);\n\n\tcase PIO_SCRNMAP:\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\t\treturn con_set_trans_old(up);\n\n\tcase GIO_SCRNMAP:\n\t\treturn con_get_trans_old(up);\n\n\tcase PIO_UNISCRNMAP:\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\t\treturn con_set_trans_new(up);\n\n\tcase GIO_UNISCRNMAP:\n\t\treturn con_get_trans_new(up);\n\n\tcase PIO_UNIMAPCLR:\n\t\tif (!perm)\n\t\t\treturn -EPERM;\n\t\tcon_clear_unimap(vc);\n\t\tbreak;\n\n\tcase PIO_UNIMAP:\n\tcase GIO_UNIMAP:\n\t\treturn do_unimap_ioctl(cmd, up, perm, vc);\n\n\tdefault:\n\t\treturn -ENOIOCTLCMD;\n\t}\n\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -13,7 +13,7 @@\n \t\top.height = 0;\n \t\top.charcount = 256;\n \t\top.data = up;\n-\t\treturn con_font_op(vc_cons[fg_console].d, &op);\n+\t\treturn con_font_op(vc, &op);\n \n \tcase GIO_FONT:\n \t\top.op = KD_FONT_OP_GET;\n@@ -22,7 +22,7 @@\n \t\top.height = 32;\n \t\top.charcount = 256;\n \t\top.data = up;\n-\t\treturn con_font_op(vc_cons[fg_console].d, &op);\n+\t\treturn con_font_op(vc, &op);\n \n \tcase PIO_CMAP:\n                 if (!perm)\n@@ -38,13 +38,13 @@\n \n \t\tfallthrough;\n \tcase GIO_FONTX:\n-\t\treturn do_fontx_ioctl(cmd, up, &op);\n+\t\treturn do_fontx_ioctl(vc, cmd, up, &op);\n \n \tcase PIO_FONTRESET:\n \t\tif (!perm)\n \t\t\treturn -EPERM;\n \n-\t\treturn vt_io_fontreset(&op);\n+\t\treturn vt_io_fontreset(vc, &op);\n \n \tcase PIO_SCRNMAP:\n \t\tif (!perm)",
        "diff_line_info": {
            "deleted_lines": [
                "\t\treturn con_font_op(vc_cons[fg_console].d, &op);",
                "\t\treturn con_font_op(vc_cons[fg_console].d, &op);",
                "\t\treturn do_fontx_ioctl(cmd, up, &op);",
                "\t\treturn vt_io_fontreset(&op);"
            ],
            "added_lines": [
                "\t\treturn con_font_op(vc, &op);",
                "\t\treturn con_font_op(vc, &op);",
                "\t\treturn do_fontx_ioctl(vc, cmd, up, &op);",
                "\t\treturn vt_io_fontreset(vc, &op);"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-25668",
        "func_name": "torvalds/linux/vt_io_fontreset",
        "description": "A flaw was found in Linux Kernel because access to the global variable fg_console is not properly synchronized leading to a use after free in con_font_op.",
        "git_url": "https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit?h=90bfdeef83f1d6c696039b6a917190dcbbad3220",
        "commit_title": "Some of the font tty ioctl's always used the current foreground VC for",
        "commit_text": "their operations.  Don't do that then.  This fixes a data race on fg_console.  Side note: both Michael Ellerman and Jiri Slaby point out that all these ioctls are deprecated, and should probably have been removed long ago, and everything seems to be using the KDFONTOP ioctl instead.  In fact, Michael points out that it looks like busybox's loadfont program seems to have switched over to using KDFONTOP exactly _because_ of this bug (ahem.. 12 years ago ;-).  Cc: Greg KH <greg@kroah.com> ",
        "func_before": "static int vt_io_fontreset(struct console_font_op *op)\n{\n\tint ret;\n\n\tif (__is_defined(BROKEN_GRAPHICS_PROGRAMS)) {\n\t\t/*\n\t\t * With BROKEN_GRAPHICS_PROGRAMS defined, the default font is\n\t\t * not saved.\n\t\t */\n\t\treturn -ENOSYS;\n\t}\n\n\top->op = KD_FONT_OP_SET_DEFAULT;\n\top->data = NULL;\n\tret = con_font_op(vc_cons[fg_console].d, op);\n\tif (ret)\n\t\treturn ret;\n\n\tconsole_lock();\n\tcon_set_default_unimap(vc_cons[fg_console].d);\n\tconsole_unlock();\n\n\treturn 0;\n}",
        "func": "static int vt_io_fontreset(struct vc_data *vc, struct console_font_op *op)\n{\n\tint ret;\n\n\tif (__is_defined(BROKEN_GRAPHICS_PROGRAMS)) {\n\t\t/*\n\t\t * With BROKEN_GRAPHICS_PROGRAMS defined, the default font is\n\t\t * not saved.\n\t\t */\n\t\treturn -ENOSYS;\n\t}\n\n\top->op = KD_FONT_OP_SET_DEFAULT;\n\top->data = NULL;\n\tret = con_font_op(vc, op);\n\tif (ret)\n\t\treturn ret;\n\n\tconsole_lock();\n\tcon_set_default_unimap(vc);\n\tconsole_unlock();\n\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,4 +1,4 @@\n-static int vt_io_fontreset(struct console_font_op *op)\n+static int vt_io_fontreset(struct vc_data *vc, struct console_font_op *op)\n {\n \tint ret;\n \n@@ -12,12 +12,12 @@\n \n \top->op = KD_FONT_OP_SET_DEFAULT;\n \top->data = NULL;\n-\tret = con_font_op(vc_cons[fg_console].d, op);\n+\tret = con_font_op(vc, op);\n \tif (ret)\n \t\treturn ret;\n \n \tconsole_lock();\n-\tcon_set_default_unimap(vc_cons[fg_console].d);\n+\tcon_set_default_unimap(vc);\n \tconsole_unlock();\n \n \treturn 0;",
        "diff_line_info": {
            "deleted_lines": [
                "static int vt_io_fontreset(struct console_font_op *op)",
                "\tret = con_font_op(vc_cons[fg_console].d, op);",
                "\tcon_set_default_unimap(vc_cons[fg_console].d);"
            ],
            "added_lines": [
                "static int vt_io_fontreset(struct vc_data *vc, struct console_font_op *op)",
                "\tret = con_font_op(vc, op);",
                "\tcon_set_default_unimap(vc);"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-25668",
        "func_name": "torvalds/linux/vt_compat_ioctl",
        "description": "A flaw was found in Linux Kernel because access to the global variable fg_console is not properly synchronized leading to a use after free in con_font_op.",
        "git_url": "https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit?h=90bfdeef83f1d6c696039b6a917190dcbbad3220",
        "commit_title": "Some of the font tty ioctl's always used the current foreground VC for",
        "commit_text": "their operations.  Don't do that then.  This fixes a data race on fg_console.  Side note: both Michael Ellerman and Jiri Slaby point out that all these ioctls are deprecated, and should probably have been removed long ago, and everything seems to be using the KDFONTOP ioctl instead.  In fact, Michael points out that it looks like busybox's loadfont program seems to have switched over to using KDFONTOP exactly _because_ of this bug (ahem.. 12 years ago ;-).  Cc: Greg KH <greg@kroah.com> ",
        "func_before": "long vt_compat_ioctl(struct tty_struct *tty,\n\t     unsigned int cmd, unsigned long arg)\n{\n\tstruct vc_data *vc = tty->driver_data;\n\tstruct console_font_op op;\t/* used in multiple places here */\n\tvoid __user *up = compat_ptr(arg);\n\tint perm;\n\n\t/*\n\t * To have permissions to do most of the vt ioctls, we either have\n\t * to be the owner of the tty, or have CAP_SYS_TTY_CONFIG.\n\t */\n\tperm = 0;\n\tif (current->signal->tty == tty || capable(CAP_SYS_TTY_CONFIG))\n\t\tperm = 1;\n\n\tswitch (cmd) {\n\t/*\n\t * these need special handlers for incompatible data structures\n\t */\n\tcase PIO_FONTX:\n\tcase GIO_FONTX:\n\t\treturn compat_fontx_ioctl(cmd, up, perm, &op);\n\n\tcase KDFONTOP:\n\t\treturn compat_kdfontop_ioctl(up, perm, &op, vc);\n\n\tcase PIO_UNIMAP:\n\tcase GIO_UNIMAP:\n\t\treturn compat_unimap_ioctl(cmd, up, perm, vc);\n\n\t/*\n\t * all these treat 'arg' as an integer\n\t */\n\tcase KIOCSOUND:\n\tcase KDMKTONE:\n#ifdef CONFIG_X86\n\tcase KDADDIO:\n\tcase KDDELIO:\n#endif\n\tcase KDSETMODE:\n\tcase KDMAPDISP:\n\tcase KDUNMAPDISP:\n\tcase KDSKBMODE:\n\tcase KDSKBMETA:\n\tcase KDSKBLED:\n\tcase KDSETLED:\n\tcase KDSIGACCEPT:\n\tcase VT_ACTIVATE:\n\tcase VT_WAITACTIVE:\n\tcase VT_RELDISP:\n\tcase VT_DISALLOCATE:\n\tcase VT_RESIZE:\n\tcase VT_RESIZEX:\n\t\treturn vt_ioctl(tty, cmd, arg);\n\n\t/*\n\t * the rest has a compatible data structure behind arg,\n\t * but we have to convert it to a proper 64 bit pointer.\n\t */\n\tdefault:\n\t\treturn vt_ioctl(tty, cmd, (unsigned long)up);\n\t}\n}",
        "func": "long vt_compat_ioctl(struct tty_struct *tty,\n\t     unsigned int cmd, unsigned long arg)\n{\n\tstruct vc_data *vc = tty->driver_data;\n\tstruct console_font_op op;\t/* used in multiple places here */\n\tvoid __user *up = compat_ptr(arg);\n\tint perm;\n\n\t/*\n\t * To have permissions to do most of the vt ioctls, we either have\n\t * to be the owner of the tty, or have CAP_SYS_TTY_CONFIG.\n\t */\n\tperm = 0;\n\tif (current->signal->tty == tty || capable(CAP_SYS_TTY_CONFIG))\n\t\tperm = 1;\n\n\tswitch (cmd) {\n\t/*\n\t * these need special handlers for incompatible data structures\n\t */\n\tcase PIO_FONTX:\n\tcase GIO_FONTX:\n\t\treturn compat_fontx_ioctl(vc, cmd, up, perm, &op);\n\n\tcase KDFONTOP:\n\t\treturn compat_kdfontop_ioctl(up, perm, &op, vc);\n\n\tcase PIO_UNIMAP:\n\tcase GIO_UNIMAP:\n\t\treturn compat_unimap_ioctl(cmd, up, perm, vc);\n\n\t/*\n\t * all these treat 'arg' as an integer\n\t */\n\tcase KIOCSOUND:\n\tcase KDMKTONE:\n#ifdef CONFIG_X86\n\tcase KDADDIO:\n\tcase KDDELIO:\n#endif\n\tcase KDSETMODE:\n\tcase KDMAPDISP:\n\tcase KDUNMAPDISP:\n\tcase KDSKBMODE:\n\tcase KDSKBMETA:\n\tcase KDSKBLED:\n\tcase KDSETLED:\n\tcase KDSIGACCEPT:\n\tcase VT_ACTIVATE:\n\tcase VT_WAITACTIVE:\n\tcase VT_RELDISP:\n\tcase VT_DISALLOCATE:\n\tcase VT_RESIZE:\n\tcase VT_RESIZEX:\n\t\treturn vt_ioctl(tty, cmd, arg);\n\n\t/*\n\t * the rest has a compatible data structure behind arg,\n\t * but we have to convert it to a proper 64 bit pointer.\n\t */\n\tdefault:\n\t\treturn vt_ioctl(tty, cmd, (unsigned long)up);\n\t}\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -20,7 +20,7 @@\n \t */\n \tcase PIO_FONTX:\n \tcase GIO_FONTX:\n-\t\treturn compat_fontx_ioctl(cmd, up, perm, &op);\n+\t\treturn compat_fontx_ioctl(vc, cmd, up, perm, &op);\n \n \tcase KDFONTOP:\n \t\treturn compat_kdfontop_ioctl(up, perm, &op, vc);",
        "diff_line_info": {
            "deleted_lines": [
                "\t\treturn compat_fontx_ioctl(cmd, up, perm, &op);"
            ],
            "added_lines": [
                "\t\treturn compat_fontx_ioctl(vc, cmd, up, perm, &op);"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-25668",
        "func_name": "torvalds/linux/do_fontx_ioctl",
        "description": "A flaw was found in Linux Kernel because access to the global variable fg_console is not properly synchronized leading to a use after free in con_font_op.",
        "git_url": "https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit?h=90bfdeef83f1d6c696039b6a917190dcbbad3220",
        "commit_title": "Some of the font tty ioctl's always used the current foreground VC for",
        "commit_text": "their operations.  Don't do that then.  This fixes a data race on fg_console.  Side note: both Michael Ellerman and Jiri Slaby point out that all these ioctls are deprecated, and should probably have been removed long ago, and everything seems to be using the KDFONTOP ioctl instead.  In fact, Michael points out that it looks like busybox's loadfont program seems to have switched over to using KDFONTOP exactly _because_ of this bug (ahem.. 12 years ago ;-).  Cc: Greg KH <greg@kroah.com> ",
        "func_before": "static inline int do_fontx_ioctl(int cmd,\n\t\tstruct consolefontdesc __user *user_cfd,\n\t\tstruct console_font_op *op)\n{\n\tstruct consolefontdesc cfdarg;\n\tint i;\n\n\tif (copy_from_user(&cfdarg, user_cfd, sizeof(struct consolefontdesc)))\n\t\treturn -EFAULT;\n\n\tswitch (cmd) {\n\tcase PIO_FONTX:\n\t\top->op = KD_FONT_OP_SET;\n\t\top->flags = KD_FONT_FLAG_OLD;\n\t\top->width = 8;\n\t\top->height = cfdarg.charheight;\n\t\top->charcount = cfdarg.charcount;\n\t\top->data = cfdarg.chardata;\n\t\treturn con_font_op(vc_cons[fg_console].d, op);\n\tcase GIO_FONTX: {\n\t\top->op = KD_FONT_OP_GET;\n\t\top->flags = KD_FONT_FLAG_OLD;\n\t\top->width = 8;\n\t\top->height = cfdarg.charheight;\n\t\top->charcount = cfdarg.charcount;\n\t\top->data = cfdarg.chardata;\n\t\ti = con_font_op(vc_cons[fg_console].d, op);\n\t\tif (i)\n\t\t\treturn i;\n\t\tcfdarg.charheight = op->height;\n\t\tcfdarg.charcount = op->charcount;\n\t\tif (copy_to_user(user_cfd, &cfdarg, sizeof(struct consolefontdesc)))\n\t\t\treturn -EFAULT;\n\t\treturn 0;\n\t\t}\n\t}\n\treturn -EINVAL;\n}",
        "func": "static inline int do_fontx_ioctl(struct vc_data *vc, int cmd,\n\t\tstruct consolefontdesc __user *user_cfd,\n\t\tstruct console_font_op *op)\n{\n\tstruct consolefontdesc cfdarg;\n\tint i;\n\n\tif (copy_from_user(&cfdarg, user_cfd, sizeof(struct consolefontdesc)))\n\t\treturn -EFAULT;\n\n\tswitch (cmd) {\n\tcase PIO_FONTX:\n\t\top->op = KD_FONT_OP_SET;\n\t\top->flags = KD_FONT_FLAG_OLD;\n\t\top->width = 8;\n\t\top->height = cfdarg.charheight;\n\t\top->charcount = cfdarg.charcount;\n\t\top->data = cfdarg.chardata;\n\t\treturn con_font_op(vc, op);\n\n\tcase GIO_FONTX:\n\t\top->op = KD_FONT_OP_GET;\n\t\top->flags = KD_FONT_FLAG_OLD;\n\t\top->width = 8;\n\t\top->height = cfdarg.charheight;\n\t\top->charcount = cfdarg.charcount;\n\t\top->data = cfdarg.chardata;\n\t\ti = con_font_op(vc, op);\n\t\tif (i)\n\t\t\treturn i;\n\t\tcfdarg.charheight = op->height;\n\t\tcfdarg.charcount = op->charcount;\n\t\tif (copy_to_user(user_cfd, &cfdarg, sizeof(struct consolefontdesc)))\n\t\t\treturn -EFAULT;\n\t\treturn 0;\n\t}\n\treturn -EINVAL;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,4 +1,4 @@\n-static inline int do_fontx_ioctl(int cmd,\n+static inline int do_fontx_ioctl(struct vc_data *vc, int cmd,\n \t\tstruct consolefontdesc __user *user_cfd,\n \t\tstruct console_font_op *op)\n {\n@@ -16,15 +16,16 @@\n \t\top->height = cfdarg.charheight;\n \t\top->charcount = cfdarg.charcount;\n \t\top->data = cfdarg.chardata;\n-\t\treturn con_font_op(vc_cons[fg_console].d, op);\n-\tcase GIO_FONTX: {\n+\t\treturn con_font_op(vc, op);\n+\n+\tcase GIO_FONTX:\n \t\top->op = KD_FONT_OP_GET;\n \t\top->flags = KD_FONT_FLAG_OLD;\n \t\top->width = 8;\n \t\top->height = cfdarg.charheight;\n \t\top->charcount = cfdarg.charcount;\n \t\top->data = cfdarg.chardata;\n-\t\ti = con_font_op(vc_cons[fg_console].d, op);\n+\t\ti = con_font_op(vc, op);\n \t\tif (i)\n \t\t\treturn i;\n \t\tcfdarg.charheight = op->height;\n@@ -32,7 +33,6 @@\n \t\tif (copy_to_user(user_cfd, &cfdarg, sizeof(struct consolefontdesc)))\n \t\t\treturn -EFAULT;\n \t\treturn 0;\n-\t\t}\n \t}\n \treturn -EINVAL;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "static inline int do_fontx_ioctl(int cmd,",
                "\t\treturn con_font_op(vc_cons[fg_console].d, op);",
                "\tcase GIO_FONTX: {",
                "\t\ti = con_font_op(vc_cons[fg_console].d, op);",
                "\t\t}"
            ],
            "added_lines": [
                "static inline int do_fontx_ioctl(struct vc_data *vc, int cmd,",
                "\t\treturn con_font_op(vc, op);",
                "",
                "\tcase GIO_FONTX:",
                "\t\ti = con_font_op(vc, op);"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-12769",
        "func_name": "torvalds/linux/dw_reader",
        "description": "An issue was discovered in the Linux kernel before 5.4.17. drivers/spi/spi-dw.c allows attackers to cause a panic via concurrent calls to dw_spi_irq and dw_spi_transfer_one, aka CID-19b61392c5a8.",
        "git_url": "https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?h=19b61392c5a852b4e8a0bf35aecb969983c5932d",
        "commit_title": "dw_spi_irq() and dw_spi_transfer_one concurrent calls.",
        "commit_text": " I find a panic in dw_writer(): txw = *(u8 *)(dws->tx), when dw->tx==null, dw->len==4, and dw->tx_end==1.  When tpm driver's message overtime dw_spi_irq() and dw_spi_transfer_one may concurrent visit dw_spi, so I think dw_spi structure lack of protection.  Otherwise dw_spi_transfer_one set dw rx/tx buffer and then open irq, store dw rx/tx instructions and other cores handle irq load dw rx/tx instructions may out of order.  \t[ 1025.321302] Call trace: \t... \t[ 1025.321319]  __crash_kexec+0x98/0x148 \t[ 1025.321323]  panic+0x17c/0x314 \t[ 1025.321329]  die+0x29c/0x2e8 \t[ 1025.321334]  die_kernel_fault+0x68/0x78 \t[ 1025.321337]  __do_kernel_fault+0x90/0xb0 \t[ 1025.321346]  do_page_fault+0x88/0x500 \t[ 1025.321347]  do_translation_fault+0xa8/0xb8 \t[ 1025.321349]  do_mem_abort+0x68/0x118 \t[ 1025.321351]  el1_da+0x20/0x8c \t[ 1025.321362]  dw_writer+0xc8/0xd0 \t[ 1025.321364]  interrupt_transfer+0x60/0x110 \t[ 1025.321365]  dw_spi_irq+0x48/0x70 \t...  Link: https://lore.kernel.org/r/1577849981-31489-1-git-send-email-wuxu.wu@huawei.com ",
        "func_before": "static void dw_reader(struct dw_spi *dws)\n{\n\tu32 max = rx_max(dws);\n\tu16 rxw;\n\n\twhile (max--) {\n\t\trxw = dw_read_io_reg(dws, DW_SPI_DR);\n\t\t/* Care rx only if the transfer's original \"rx\" is not null */\n\t\tif (dws->rx_end - dws->len) {\n\t\t\tif (dws->n_bytes == 1)\n\t\t\t\t*(u8 *)(dws->rx) = rxw;\n\t\t\telse\n\t\t\t\t*(u16 *)(dws->rx) = rxw;\n\t\t}\n\t\tdws->rx += dws->n_bytes;\n\t}\n}",
        "func": "static void dw_reader(struct dw_spi *dws)\n{\n\tu32 max;\n\tu16 rxw;\n\n\tspin_lock(&dws->buf_lock);\n\tmax = rx_max(dws);\n\twhile (max--) {\n\t\trxw = dw_read_io_reg(dws, DW_SPI_DR);\n\t\t/* Care rx only if the transfer's original \"rx\" is not null */\n\t\tif (dws->rx_end - dws->len) {\n\t\t\tif (dws->n_bytes == 1)\n\t\t\t\t*(u8 *)(dws->rx) = rxw;\n\t\t\telse\n\t\t\t\t*(u16 *)(dws->rx) = rxw;\n\t\t}\n\t\tdws->rx += dws->n_bytes;\n\t}\n\tspin_unlock(&dws->buf_lock);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,8 +1,10 @@\n static void dw_reader(struct dw_spi *dws)\n {\n-\tu32 max = rx_max(dws);\n+\tu32 max;\n \tu16 rxw;\n \n+\tspin_lock(&dws->buf_lock);\n+\tmax = rx_max(dws);\n \twhile (max--) {\n \t\trxw = dw_read_io_reg(dws, DW_SPI_DR);\n \t\t/* Care rx only if the transfer's original \"rx\" is not null */\n@@ -14,4 +16,5 @@\n \t\t}\n \t\tdws->rx += dws->n_bytes;\n \t}\n+\tspin_unlock(&dws->buf_lock);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tu32 max = rx_max(dws);"
            ],
            "added_lines": [
                "\tu32 max;",
                "\tspin_lock(&dws->buf_lock);",
                "\tmax = rx_max(dws);",
                "\tspin_unlock(&dws->buf_lock);"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-12769",
        "func_name": "torvalds/linux/dw_spi_add_host",
        "description": "An issue was discovered in the Linux kernel before 5.4.17. drivers/spi/spi-dw.c allows attackers to cause a panic via concurrent calls to dw_spi_irq and dw_spi_transfer_one, aka CID-19b61392c5a8.",
        "git_url": "https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?h=19b61392c5a852b4e8a0bf35aecb969983c5932d",
        "commit_title": "dw_spi_irq() and dw_spi_transfer_one concurrent calls.",
        "commit_text": " I find a panic in dw_writer(): txw = *(u8 *)(dws->tx), when dw->tx==null, dw->len==4, and dw->tx_end==1.  When tpm driver's message overtime dw_spi_irq() and dw_spi_transfer_one may concurrent visit dw_spi, so I think dw_spi structure lack of protection.  Otherwise dw_spi_transfer_one set dw rx/tx buffer and then open irq, store dw rx/tx instructions and other cores handle irq load dw rx/tx instructions may out of order.  \t[ 1025.321302] Call trace: \t... \t[ 1025.321319]  __crash_kexec+0x98/0x148 \t[ 1025.321323]  panic+0x17c/0x314 \t[ 1025.321329]  die+0x29c/0x2e8 \t[ 1025.321334]  die_kernel_fault+0x68/0x78 \t[ 1025.321337]  __do_kernel_fault+0x90/0xb0 \t[ 1025.321346]  do_page_fault+0x88/0x500 \t[ 1025.321347]  do_translation_fault+0xa8/0xb8 \t[ 1025.321349]  do_mem_abort+0x68/0x118 \t[ 1025.321351]  el1_da+0x20/0x8c \t[ 1025.321362]  dw_writer+0xc8/0xd0 \t[ 1025.321364]  interrupt_transfer+0x60/0x110 \t[ 1025.321365]  dw_spi_irq+0x48/0x70 \t...  Link: https://lore.kernel.org/r/1577849981-31489-1-git-send-email-wuxu.wu@huawei.com ",
        "func_before": "int dw_spi_add_host(struct device *dev, struct dw_spi *dws)\n{\n\tstruct spi_controller *master;\n\tint ret;\n\n\tBUG_ON(dws == NULL);\n\n\tmaster = spi_alloc_master(dev, 0);\n\tif (!master)\n\t\treturn -ENOMEM;\n\n\tdws->master = master;\n\tdws->type = SSI_MOTO_SPI;\n\tdws->dma_inited = 0;\n\tdws->dma_addr = (dma_addr_t)(dws->paddr + DW_SPI_DR);\n\n\tspi_controller_set_devdata(master, dws);\n\n\tret = request_irq(dws->irq, dw_spi_irq, IRQF_SHARED, dev_name(dev),\n\t\t\t  master);\n\tif (ret < 0) {\n\t\tdev_err(dev, \"can not get IRQ\\n\");\n\t\tgoto err_free_master;\n\t}\n\n\tmaster->use_gpio_descriptors = true;\n\tmaster->mode_bits = SPI_CPOL | SPI_CPHA | SPI_LOOP;\n\tmaster->bits_per_word_mask =  SPI_BPW_RANGE_MASK(4, 16);\n\tmaster->bus_num = dws->bus_num;\n\tmaster->num_chipselect = dws->num_cs;\n\tmaster->setup = dw_spi_setup;\n\tmaster->cleanup = dw_spi_cleanup;\n\tmaster->set_cs = dw_spi_set_cs;\n\tmaster->transfer_one = dw_spi_transfer_one;\n\tmaster->handle_err = dw_spi_handle_err;\n\tmaster->max_speed_hz = dws->max_freq;\n\tmaster->dev.of_node = dev->of_node;\n\tmaster->dev.fwnode = dev->fwnode;\n\tmaster->flags = SPI_MASTER_GPIO_SS;\n\tmaster->auto_runtime_pm = true;\n\n\tif (dws->set_cs)\n\t\tmaster->set_cs = dws->set_cs;\n\n\t/* Basic HW init */\n\tspi_hw_init(dev, dws);\n\n\tif (dws->dma_ops && dws->dma_ops->dma_init) {\n\t\tret = dws->dma_ops->dma_init(dws);\n\t\tif (ret) {\n\t\t\tdev_warn(dev, \"DMA init failed\\n\");\n\t\t\tdws->dma_inited = 0;\n\t\t} else {\n\t\t\tmaster->can_dma = dws->dma_ops->can_dma;\n\t\t}\n\t}\n\n\tret = devm_spi_register_controller(dev, master);\n\tif (ret) {\n\t\tdev_err(&master->dev, \"problem registering spi master\\n\");\n\t\tgoto err_dma_exit;\n\t}\n\n\tdw_spi_debugfs_init(dws);\n\treturn 0;\n\nerr_dma_exit:\n\tif (dws->dma_ops && dws->dma_ops->dma_exit)\n\t\tdws->dma_ops->dma_exit(dws);\n\tspi_enable_chip(dws, 0);\n\tfree_irq(dws->irq, master);\nerr_free_master:\n\tspi_controller_put(master);\n\treturn ret;\n}",
        "func": "int dw_spi_add_host(struct device *dev, struct dw_spi *dws)\n{\n\tstruct spi_controller *master;\n\tint ret;\n\n\tBUG_ON(dws == NULL);\n\n\tmaster = spi_alloc_master(dev, 0);\n\tif (!master)\n\t\treturn -ENOMEM;\n\n\tdws->master = master;\n\tdws->type = SSI_MOTO_SPI;\n\tdws->dma_inited = 0;\n\tdws->dma_addr = (dma_addr_t)(dws->paddr + DW_SPI_DR);\n\tspin_lock_init(&dws->buf_lock);\n\n\tspi_controller_set_devdata(master, dws);\n\n\tret = request_irq(dws->irq, dw_spi_irq, IRQF_SHARED, dev_name(dev),\n\t\t\t  master);\n\tif (ret < 0) {\n\t\tdev_err(dev, \"can not get IRQ\\n\");\n\t\tgoto err_free_master;\n\t}\n\n\tmaster->use_gpio_descriptors = true;\n\tmaster->mode_bits = SPI_CPOL | SPI_CPHA | SPI_LOOP;\n\tmaster->bits_per_word_mask =  SPI_BPW_RANGE_MASK(4, 16);\n\tmaster->bus_num = dws->bus_num;\n\tmaster->num_chipselect = dws->num_cs;\n\tmaster->setup = dw_spi_setup;\n\tmaster->cleanup = dw_spi_cleanup;\n\tmaster->set_cs = dw_spi_set_cs;\n\tmaster->transfer_one = dw_spi_transfer_one;\n\tmaster->handle_err = dw_spi_handle_err;\n\tmaster->max_speed_hz = dws->max_freq;\n\tmaster->dev.of_node = dev->of_node;\n\tmaster->dev.fwnode = dev->fwnode;\n\tmaster->flags = SPI_MASTER_GPIO_SS;\n\tmaster->auto_runtime_pm = true;\n\n\tif (dws->set_cs)\n\t\tmaster->set_cs = dws->set_cs;\n\n\t/* Basic HW init */\n\tspi_hw_init(dev, dws);\n\n\tif (dws->dma_ops && dws->dma_ops->dma_init) {\n\t\tret = dws->dma_ops->dma_init(dws);\n\t\tif (ret) {\n\t\t\tdev_warn(dev, \"DMA init failed\\n\");\n\t\t\tdws->dma_inited = 0;\n\t\t} else {\n\t\t\tmaster->can_dma = dws->dma_ops->can_dma;\n\t\t}\n\t}\n\n\tret = devm_spi_register_controller(dev, master);\n\tif (ret) {\n\t\tdev_err(&master->dev, \"problem registering spi master\\n\");\n\t\tgoto err_dma_exit;\n\t}\n\n\tdw_spi_debugfs_init(dws);\n\treturn 0;\n\nerr_dma_exit:\n\tif (dws->dma_ops && dws->dma_ops->dma_exit)\n\t\tdws->dma_ops->dma_exit(dws);\n\tspi_enable_chip(dws, 0);\n\tfree_irq(dws->irq, master);\nerr_free_master:\n\tspi_controller_put(master);\n\treturn ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -13,6 +13,7 @@\n \tdws->type = SSI_MOTO_SPI;\n \tdws->dma_inited = 0;\n \tdws->dma_addr = (dma_addr_t)(dws->paddr + DW_SPI_DR);\n+\tspin_lock_init(&dws->buf_lock);\n \n \tspi_controller_set_devdata(master, dws);\n ",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tspin_lock_init(&dws->buf_lock);"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-12769",
        "func_name": "torvalds/linux/dw_writer",
        "description": "An issue was discovered in the Linux kernel before 5.4.17. drivers/spi/spi-dw.c allows attackers to cause a panic via concurrent calls to dw_spi_irq and dw_spi_transfer_one, aka CID-19b61392c5a8.",
        "git_url": "https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?h=19b61392c5a852b4e8a0bf35aecb969983c5932d",
        "commit_title": "dw_spi_irq() and dw_spi_transfer_one concurrent calls.",
        "commit_text": " I find a panic in dw_writer(): txw = *(u8 *)(dws->tx), when dw->tx==null, dw->len==4, and dw->tx_end==1.  When tpm driver's message overtime dw_spi_irq() and dw_spi_transfer_one may concurrent visit dw_spi, so I think dw_spi structure lack of protection.  Otherwise dw_spi_transfer_one set dw rx/tx buffer and then open irq, store dw rx/tx instructions and other cores handle irq load dw rx/tx instructions may out of order.  \t[ 1025.321302] Call trace: \t... \t[ 1025.321319]  __crash_kexec+0x98/0x148 \t[ 1025.321323]  panic+0x17c/0x314 \t[ 1025.321329]  die+0x29c/0x2e8 \t[ 1025.321334]  die_kernel_fault+0x68/0x78 \t[ 1025.321337]  __do_kernel_fault+0x90/0xb0 \t[ 1025.321346]  do_page_fault+0x88/0x500 \t[ 1025.321347]  do_translation_fault+0xa8/0xb8 \t[ 1025.321349]  do_mem_abort+0x68/0x118 \t[ 1025.321351]  el1_da+0x20/0x8c \t[ 1025.321362]  dw_writer+0xc8/0xd0 \t[ 1025.321364]  interrupt_transfer+0x60/0x110 \t[ 1025.321365]  dw_spi_irq+0x48/0x70 \t...  Link: https://lore.kernel.org/r/1577849981-31489-1-git-send-email-wuxu.wu@huawei.com ",
        "func_before": "static void dw_writer(struct dw_spi *dws)\n{\n\tu32 max = tx_max(dws);\n\tu16 txw = 0;\n\n\twhile (max--) {\n\t\t/* Set the tx word if the transfer's original \"tx\" is not null */\n\t\tif (dws->tx_end - dws->len) {\n\t\t\tif (dws->n_bytes == 1)\n\t\t\t\ttxw = *(u8 *)(dws->tx);\n\t\t\telse\n\t\t\t\ttxw = *(u16 *)(dws->tx);\n\t\t}\n\t\tdw_write_io_reg(dws, DW_SPI_DR, txw);\n\t\tdws->tx += dws->n_bytes;\n\t}\n}",
        "func": "static void dw_writer(struct dw_spi *dws)\n{\n\tu32 max;\n\tu16 txw = 0;\n\n\tspin_lock(&dws->buf_lock);\n\tmax = tx_max(dws);\n\twhile (max--) {\n\t\t/* Set the tx word if the transfer's original \"tx\" is not null */\n\t\tif (dws->tx_end - dws->len) {\n\t\t\tif (dws->n_bytes == 1)\n\t\t\t\ttxw = *(u8 *)(dws->tx);\n\t\t\telse\n\t\t\t\ttxw = *(u16 *)(dws->tx);\n\t\t}\n\t\tdw_write_io_reg(dws, DW_SPI_DR, txw);\n\t\tdws->tx += dws->n_bytes;\n\t}\n\tspin_unlock(&dws->buf_lock);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,8 +1,10 @@\n static void dw_writer(struct dw_spi *dws)\n {\n-\tu32 max = tx_max(dws);\n+\tu32 max;\n \tu16 txw = 0;\n \n+\tspin_lock(&dws->buf_lock);\n+\tmax = tx_max(dws);\n \twhile (max--) {\n \t\t/* Set the tx word if the transfer's original \"tx\" is not null */\n \t\tif (dws->tx_end - dws->len) {\n@@ -14,4 +16,5 @@\n \t\tdw_write_io_reg(dws, DW_SPI_DR, txw);\n \t\tdws->tx += dws->n_bytes;\n \t}\n+\tspin_unlock(&dws->buf_lock);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tu32 max = tx_max(dws);"
            ],
            "added_lines": [
                "\tu32 max;",
                "\tspin_lock(&dws->buf_lock);",
                "\tmax = tx_max(dws);",
                "\tspin_unlock(&dws->buf_lock);"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-12769",
        "func_name": "torvalds/linux/dw_spi_transfer_one",
        "description": "An issue was discovered in the Linux kernel before 5.4.17. drivers/spi/spi-dw.c allows attackers to cause a panic via concurrent calls to dw_spi_irq and dw_spi_transfer_one, aka CID-19b61392c5a8.",
        "git_url": "https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?h=19b61392c5a852b4e8a0bf35aecb969983c5932d",
        "commit_title": "dw_spi_irq() and dw_spi_transfer_one concurrent calls.",
        "commit_text": " I find a panic in dw_writer(): txw = *(u8 *)(dws->tx), when dw->tx==null, dw->len==4, and dw->tx_end==1.  When tpm driver's message overtime dw_spi_irq() and dw_spi_transfer_one may concurrent visit dw_spi, so I think dw_spi structure lack of protection.  Otherwise dw_spi_transfer_one set dw rx/tx buffer and then open irq, store dw rx/tx instructions and other cores handle irq load dw rx/tx instructions may out of order.  \t[ 1025.321302] Call trace: \t... \t[ 1025.321319]  __crash_kexec+0x98/0x148 \t[ 1025.321323]  panic+0x17c/0x314 \t[ 1025.321329]  die+0x29c/0x2e8 \t[ 1025.321334]  die_kernel_fault+0x68/0x78 \t[ 1025.321337]  __do_kernel_fault+0x90/0xb0 \t[ 1025.321346]  do_page_fault+0x88/0x500 \t[ 1025.321347]  do_translation_fault+0xa8/0xb8 \t[ 1025.321349]  do_mem_abort+0x68/0x118 \t[ 1025.321351]  el1_da+0x20/0x8c \t[ 1025.321362]  dw_writer+0xc8/0xd0 \t[ 1025.321364]  interrupt_transfer+0x60/0x110 \t[ 1025.321365]  dw_spi_irq+0x48/0x70 \t...  Link: https://lore.kernel.org/r/1577849981-31489-1-git-send-email-wuxu.wu@huawei.com ",
        "func_before": "static int dw_spi_transfer_one(struct spi_controller *master,\n\t\tstruct spi_device *spi, struct spi_transfer *transfer)\n{\n\tstruct dw_spi *dws = spi_controller_get_devdata(master);\n\tstruct chip_data *chip = spi_get_ctldata(spi);\n\tu8 imask = 0;\n\tu16 txlevel = 0;\n\tu32 cr0;\n\tint ret;\n\n\tdws->dma_mapped = 0;\n\n\tdws->tx = (void *)transfer->tx_buf;\n\tdws->tx_end = dws->tx + transfer->len;\n\tdws->rx = transfer->rx_buf;\n\tdws->rx_end = dws->rx + transfer->len;\n\tdws->len = transfer->len;\n\n\tspi_enable_chip(dws, 0);\n\n\t/* Handle per transfer options for bpw and speed */\n\tif (transfer->speed_hz != dws->current_freq) {\n\t\tif (transfer->speed_hz != chip->speed_hz) {\n\t\t\t/* clk_div doesn't support odd number */\n\t\t\tchip->clk_div = (DIV_ROUND_UP(dws->max_freq, transfer->speed_hz) + 1) & 0xfffe;\n\t\t\tchip->speed_hz = transfer->speed_hz;\n\t\t}\n\t\tdws->current_freq = transfer->speed_hz;\n\t\tspi_set_clk(dws, chip->clk_div);\n\t}\n\n\tdws->n_bytes = DIV_ROUND_UP(transfer->bits_per_word, BITS_PER_BYTE);\n\tdws->dma_width = DIV_ROUND_UP(transfer->bits_per_word, BITS_PER_BYTE);\n\n\t/* Default SPI mode is SCPOL = 0, SCPH = 0 */\n\tcr0 = (transfer->bits_per_word - 1)\n\t\t| (chip->type << SPI_FRF_OFFSET)\n\t\t| ((((spi->mode & SPI_CPOL) ? 1 : 0) << SPI_SCOL_OFFSET) |\n\t\t\t(((spi->mode & SPI_CPHA) ? 1 : 0) << SPI_SCPH_OFFSET))\n\t\t| (chip->tmode << SPI_TMOD_OFFSET);\n\n\t/*\n\t * Adjust transfer mode if necessary. Requires platform dependent\n\t * chipselect mechanism.\n\t */\n\tif (chip->cs_control) {\n\t\tif (dws->rx && dws->tx)\n\t\t\tchip->tmode = SPI_TMOD_TR;\n\t\telse if (dws->rx)\n\t\t\tchip->tmode = SPI_TMOD_RO;\n\t\telse\n\t\t\tchip->tmode = SPI_TMOD_TO;\n\n\t\tcr0 &= ~SPI_TMOD_MASK;\n\t\tcr0 |= (chip->tmode << SPI_TMOD_OFFSET);\n\t}\n\n\tdw_writel(dws, DW_SPI_CTRL0, cr0);\n\n\t/* Check if current transfer is a DMA transaction */\n\tif (master->can_dma && master->can_dma(master, spi, transfer))\n\t\tdws->dma_mapped = master->cur_msg_mapped;\n\n\t/* For poll mode just disable all interrupts */\n\tspi_mask_intr(dws, 0xff);\n\n\t/*\n\t * Interrupt mode\n\t * we only need set the TXEI IRQ, as TX/RX always happen syncronizely\n\t */\n\tif (dws->dma_mapped) {\n\t\tret = dws->dma_ops->dma_setup(dws, transfer);\n\t\tif (ret < 0) {\n\t\t\tspi_enable_chip(dws, 1);\n\t\t\treturn ret;\n\t\t}\n\t} else if (!chip->poll_mode) {\n\t\ttxlevel = min_t(u16, dws->fifo_len / 2, dws->len / dws->n_bytes);\n\t\tdw_writel(dws, DW_SPI_TXFLTR, txlevel);\n\n\t\t/* Set the interrupt mask */\n\t\timask |= SPI_INT_TXEI | SPI_INT_TXOI |\n\t\t\t SPI_INT_RXUI | SPI_INT_RXOI;\n\t\tspi_umask_intr(dws, imask);\n\n\t\tdws->transfer_handler = interrupt_transfer;\n\t}\n\n\tspi_enable_chip(dws, 1);\n\n\tif (dws->dma_mapped) {\n\t\tret = dws->dma_ops->dma_transfer(dws, transfer);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t}\n\n\tif (chip->poll_mode)\n\t\treturn poll_transfer(dws);\n\n\treturn 1;\n}",
        "func": "static int dw_spi_transfer_one(struct spi_controller *master,\n\t\tstruct spi_device *spi, struct spi_transfer *transfer)\n{\n\tstruct dw_spi *dws = spi_controller_get_devdata(master);\n\tstruct chip_data *chip = spi_get_ctldata(spi);\n\tunsigned long flags;\n\tu8 imask = 0;\n\tu16 txlevel = 0;\n\tu32 cr0;\n\tint ret;\n\n\tdws->dma_mapped = 0;\n\tspin_lock_irqsave(&dws->buf_lock, flags);\n\tdws->tx = (void *)transfer->tx_buf;\n\tdws->tx_end = dws->tx + transfer->len;\n\tdws->rx = transfer->rx_buf;\n\tdws->rx_end = dws->rx + transfer->len;\n\tdws->len = transfer->len;\n\tspin_unlock_irqrestore(&dws->buf_lock, flags);\n\n\tspi_enable_chip(dws, 0);\n\n\t/* Handle per transfer options for bpw and speed */\n\tif (transfer->speed_hz != dws->current_freq) {\n\t\tif (transfer->speed_hz != chip->speed_hz) {\n\t\t\t/* clk_div doesn't support odd number */\n\t\t\tchip->clk_div = (DIV_ROUND_UP(dws->max_freq, transfer->speed_hz) + 1) & 0xfffe;\n\t\t\tchip->speed_hz = transfer->speed_hz;\n\t\t}\n\t\tdws->current_freq = transfer->speed_hz;\n\t\tspi_set_clk(dws, chip->clk_div);\n\t}\n\n\tdws->n_bytes = DIV_ROUND_UP(transfer->bits_per_word, BITS_PER_BYTE);\n\tdws->dma_width = DIV_ROUND_UP(transfer->bits_per_word, BITS_PER_BYTE);\n\n\t/* Default SPI mode is SCPOL = 0, SCPH = 0 */\n\tcr0 = (transfer->bits_per_word - 1)\n\t\t| (chip->type << SPI_FRF_OFFSET)\n\t\t| ((((spi->mode & SPI_CPOL) ? 1 : 0) << SPI_SCOL_OFFSET) |\n\t\t\t(((spi->mode & SPI_CPHA) ? 1 : 0) << SPI_SCPH_OFFSET))\n\t\t| (chip->tmode << SPI_TMOD_OFFSET);\n\n\t/*\n\t * Adjust transfer mode if necessary. Requires platform dependent\n\t * chipselect mechanism.\n\t */\n\tif (chip->cs_control) {\n\t\tif (dws->rx && dws->tx)\n\t\t\tchip->tmode = SPI_TMOD_TR;\n\t\telse if (dws->rx)\n\t\t\tchip->tmode = SPI_TMOD_RO;\n\t\telse\n\t\t\tchip->tmode = SPI_TMOD_TO;\n\n\t\tcr0 &= ~SPI_TMOD_MASK;\n\t\tcr0 |= (chip->tmode << SPI_TMOD_OFFSET);\n\t}\n\n\tdw_writel(dws, DW_SPI_CTRL0, cr0);\n\n\t/* Check if current transfer is a DMA transaction */\n\tif (master->can_dma && master->can_dma(master, spi, transfer))\n\t\tdws->dma_mapped = master->cur_msg_mapped;\n\n\t/* For poll mode just disable all interrupts */\n\tspi_mask_intr(dws, 0xff);\n\n\t/*\n\t * Interrupt mode\n\t * we only need set the TXEI IRQ, as TX/RX always happen syncronizely\n\t */\n\tif (dws->dma_mapped) {\n\t\tret = dws->dma_ops->dma_setup(dws, transfer);\n\t\tif (ret < 0) {\n\t\t\tspi_enable_chip(dws, 1);\n\t\t\treturn ret;\n\t\t}\n\t} else if (!chip->poll_mode) {\n\t\ttxlevel = min_t(u16, dws->fifo_len / 2, dws->len / dws->n_bytes);\n\t\tdw_writel(dws, DW_SPI_TXFLTR, txlevel);\n\n\t\t/* Set the interrupt mask */\n\t\timask |= SPI_INT_TXEI | SPI_INT_TXOI |\n\t\t\t SPI_INT_RXUI | SPI_INT_RXOI;\n\t\tspi_umask_intr(dws, imask);\n\n\t\tdws->transfer_handler = interrupt_transfer;\n\t}\n\n\tspi_enable_chip(dws, 1);\n\n\tif (dws->dma_mapped) {\n\t\tret = dws->dma_ops->dma_transfer(dws, transfer);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t}\n\n\tif (chip->poll_mode)\n\t\treturn poll_transfer(dws);\n\n\treturn 1;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,18 +3,20 @@\n {\n \tstruct dw_spi *dws = spi_controller_get_devdata(master);\n \tstruct chip_data *chip = spi_get_ctldata(spi);\n+\tunsigned long flags;\n \tu8 imask = 0;\n \tu16 txlevel = 0;\n \tu32 cr0;\n \tint ret;\n \n \tdws->dma_mapped = 0;\n-\n+\tspin_lock_irqsave(&dws->buf_lock, flags);\n \tdws->tx = (void *)transfer->tx_buf;\n \tdws->tx_end = dws->tx + transfer->len;\n \tdws->rx = transfer->rx_buf;\n \tdws->rx_end = dws->rx + transfer->len;\n \tdws->len = transfer->len;\n+\tspin_unlock_irqrestore(&dws->buf_lock, flags);\n \n \tspi_enable_chip(dws, 0);\n ",
        "diff_line_info": {
            "deleted_lines": [
                ""
            ],
            "added_lines": [
                "\tunsigned long flags;",
                "\tspin_lock_irqsave(&dws->buf_lock, flags);",
                "\tspin_unlock_irqrestore(&dws->buf_lock, flags);"
            ]
        }
    }
]