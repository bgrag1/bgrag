[
    {
        "cve_id": "CVE-2012-2390",
        "func_name": "torvalds/linux/hugetlb_reserve_pages",
        "description": "Memory leak in mm/hugetlb.c in the Linux kernel before 3.4.2 allows local users to cause a denial of service (memory consumption or system crash) via invalid MAP_HUGETLB mmap operations.",
        "git_url": "https://github.com/torvalds/linux/commit/c50ac050811d6485616a193eb0f37bfbd191cc89",
        "commit_title": "hugetlb: fix resv_map leak in error path",
        "commit_text": " When called for anonymous (non-shared) mappings, hugetlb_reserve_pages() does a resv_map_alloc().  It depends on code in hugetlbfs's vm_ops->close() to release that allocation.  However, in the mmap() failure path, we do a plain unmap_region() without the remove_vma() which actually calls vm_ops->close().  This is a decent fix.  This leak could get reintroduced if new code (say, after hugetlb_reserve_pages() in hugetlbfs_file_mmap()) decides to return an error.  But, I think it would have to unroll the reservation anyway.  Christoph's test case:  \thttp://marc.info/?l=linux-mm&m=133728900729735  This patch applies to 3.4 and later.  A version for earlier kernels is at https://lkml.org/lkml/2012/5/22/418.  Cc: Andrea Arcangeli <aarcange@redhat.com> Cc: <stable@vger.kernel.org>\t[2.6.32+]",
        "func_before": "int hugetlb_reserve_pages(struct inode *inode,\n\t\t\t\t\tlong from, long to,\n\t\t\t\t\tstruct vm_area_struct *vma,\n\t\t\t\t\tvm_flags_t vm_flags)\n{\n\tlong ret, chg;\n\tstruct hstate *h = hstate_inode(inode);\n\tstruct hugepage_subpool *spool = subpool_inode(inode);\n\n\t/*\n\t * Only apply hugepage reservation if asked. At fault time, an\n\t * attempt will be made for VM_NORESERVE to allocate a page\n\t * without using reserves\n\t */\n\tif (vm_flags & VM_NORESERVE)\n\t\treturn 0;\n\n\t/*\n\t * Shared mappings base their reservation on the number of pages that\n\t * are already allocated on behalf of the file. Private mappings need\n\t * to reserve the full area even if read-only as mprotect() may be\n\t * called to make the mapping read-write. Assume !vma is a shm mapping\n\t */\n\tif (!vma || vma->vm_flags & VM_MAYSHARE)\n\t\tchg = region_chg(&inode->i_mapping->private_list, from, to);\n\telse {\n\t\tstruct resv_map *resv_map = resv_map_alloc();\n\t\tif (!resv_map)\n\t\t\treturn -ENOMEM;\n\n\t\tchg = to - from;\n\n\t\tset_vma_resv_map(vma, resv_map);\n\t\tset_vma_resv_flags(vma, HPAGE_RESV_OWNER);\n\t}\n\n\tif (chg < 0)\n\t\treturn chg;\n\n\t/* There must be enough pages in the subpool for the mapping */\n\tif (hugepage_subpool_get_pages(spool, chg))\n\t\treturn -ENOSPC;\n\n\t/*\n\t * Check enough hugepages are available for the reservation.\n\t * Hand the pages back to the subpool if there are not\n\t */\n\tret = hugetlb_acct_memory(h, chg);\n\tif (ret < 0) {\n\t\thugepage_subpool_put_pages(spool, chg);\n\t\treturn ret;\n\t}\n\n\t/*\n\t * Account for the reservations made. Shared mappings record regions\n\t * that have reservations as they are shared by multiple VMAs.\n\t * When the last VMA disappears, the region map says how much\n\t * the reservation was and the page cache tells how much of\n\t * the reservation was consumed. Private mappings are per-VMA and\n\t * only the consumed reservations are tracked. When the VMA\n\t * disappears, the original reservation is the VMA size and the\n\t * consumed reservations are stored in the map. Hence, nothing\n\t * else has to be done for private mappings here\n\t */\n\tif (!vma || vma->vm_flags & VM_MAYSHARE)\n\t\tregion_add(&inode->i_mapping->private_list, from, to);\n\treturn 0;\n}",
        "func": "int hugetlb_reserve_pages(struct inode *inode,\n\t\t\t\t\tlong from, long to,\n\t\t\t\t\tstruct vm_area_struct *vma,\n\t\t\t\t\tvm_flags_t vm_flags)\n{\n\tlong ret, chg;\n\tstruct hstate *h = hstate_inode(inode);\n\tstruct hugepage_subpool *spool = subpool_inode(inode);\n\n\t/*\n\t * Only apply hugepage reservation if asked. At fault time, an\n\t * attempt will be made for VM_NORESERVE to allocate a page\n\t * without using reserves\n\t */\n\tif (vm_flags & VM_NORESERVE)\n\t\treturn 0;\n\n\t/*\n\t * Shared mappings base their reservation on the number of pages that\n\t * are already allocated on behalf of the file. Private mappings need\n\t * to reserve the full area even if read-only as mprotect() may be\n\t * called to make the mapping read-write. Assume !vma is a shm mapping\n\t */\n\tif (!vma || vma->vm_flags & VM_MAYSHARE)\n\t\tchg = region_chg(&inode->i_mapping->private_list, from, to);\n\telse {\n\t\tstruct resv_map *resv_map = resv_map_alloc();\n\t\tif (!resv_map)\n\t\t\treturn -ENOMEM;\n\n\t\tchg = to - from;\n\n\t\tset_vma_resv_map(vma, resv_map);\n\t\tset_vma_resv_flags(vma, HPAGE_RESV_OWNER);\n\t}\n\n\tif (chg < 0) {\n\t\tret = chg;\n\t\tgoto out_err;\n\t}\n\n\t/* There must be enough pages in the subpool for the mapping */\n\tif (hugepage_subpool_get_pages(spool, chg)) {\n\t\tret = -ENOSPC;\n\t\tgoto out_err;\n\t}\n\n\t/*\n\t * Check enough hugepages are available for the reservation.\n\t * Hand the pages back to the subpool if there are not\n\t */\n\tret = hugetlb_acct_memory(h, chg);\n\tif (ret < 0) {\n\t\thugepage_subpool_put_pages(spool, chg);\n\t\tgoto out_err;\n\t}\n\n\t/*\n\t * Account for the reservations made. Shared mappings record regions\n\t * that have reservations as they are shared by multiple VMAs.\n\t * When the last VMA disappears, the region map says how much\n\t * the reservation was and the page cache tells how much of\n\t * the reservation was consumed. Private mappings are per-VMA and\n\t * only the consumed reservations are tracked. When the VMA\n\t * disappears, the original reservation is the VMA size and the\n\t * consumed reservations are stored in the map. Hence, nothing\n\t * else has to be done for private mappings here\n\t */\n\tif (!vma || vma->vm_flags & VM_MAYSHARE)\n\t\tregion_add(&inode->i_mapping->private_list, from, to);\n\treturn 0;\nout_err:\n\tresv_map_put(vma);\n\treturn ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -34,12 +34,16 @@\n \t\tset_vma_resv_flags(vma, HPAGE_RESV_OWNER);\n \t}\n \n-\tif (chg < 0)\n-\t\treturn chg;\n+\tif (chg < 0) {\n+\t\tret = chg;\n+\t\tgoto out_err;\n+\t}\n \n \t/* There must be enough pages in the subpool for the mapping */\n-\tif (hugepage_subpool_get_pages(spool, chg))\n-\t\treturn -ENOSPC;\n+\tif (hugepage_subpool_get_pages(spool, chg)) {\n+\t\tret = -ENOSPC;\n+\t\tgoto out_err;\n+\t}\n \n \t/*\n \t * Check enough hugepages are available for the reservation.\n@@ -48,7 +52,7 @@\n \tret = hugetlb_acct_memory(h, chg);\n \tif (ret < 0) {\n \t\thugepage_subpool_put_pages(spool, chg);\n-\t\treturn ret;\n+\t\tgoto out_err;\n \t}\n \n \t/*\n@@ -65,4 +69,7 @@\n \tif (!vma || vma->vm_flags & VM_MAYSHARE)\n \t\tregion_add(&inode->i_mapping->private_list, from, to);\n \treturn 0;\n+out_err:\n+\tresv_map_put(vma);\n+\treturn ret;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (chg < 0)",
                "\t\treturn chg;",
                "\tif (hugepage_subpool_get_pages(spool, chg))",
                "\t\treturn -ENOSPC;",
                "\t\treturn ret;"
            ],
            "added_lines": [
                "\tif (chg < 0) {",
                "\t\tret = chg;",
                "\t\tgoto out_err;",
                "\t}",
                "\tif (hugepage_subpool_get_pages(spool, chg)) {",
                "\t\tret = -ENOSPC;",
                "\t\tgoto out_err;",
                "\t}",
                "\t\tgoto out_err;",
                "out_err:",
                "\tresv_map_put(vma);",
                "\treturn ret;"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-2390",
        "func_name": "torvalds/linux/hugetlb_vm_op_close",
        "description": "Memory leak in mm/hugetlb.c in the Linux kernel before 3.4.2 allows local users to cause a denial of service (memory consumption or system crash) via invalid MAP_HUGETLB mmap operations.",
        "git_url": "https://github.com/torvalds/linux/commit/c50ac050811d6485616a193eb0f37bfbd191cc89",
        "commit_title": "hugetlb: fix resv_map leak in error path",
        "commit_text": " When called for anonymous (non-shared) mappings, hugetlb_reserve_pages() does a resv_map_alloc().  It depends on code in hugetlbfs's vm_ops->close() to release that allocation.  However, in the mmap() failure path, we do a plain unmap_region() without the remove_vma() which actually calls vm_ops->close().  This is a decent fix.  This leak could get reintroduced if new code (say, after hugetlb_reserve_pages() in hugetlbfs_file_mmap()) decides to return an error.  But, I think it would have to unroll the reservation anyway.  Christoph's test case:  \thttp://marc.info/?l=linux-mm&m=133728900729735  This patch applies to 3.4 and later.  A version for earlier kernels is at https://lkml.org/lkml/2012/5/22/418.  Cc: Andrea Arcangeli <aarcange@redhat.com> Cc: <stable@vger.kernel.org>\t[2.6.32+]",
        "func_before": "static void hugetlb_vm_op_close(struct vm_area_struct *vma)\n{\n\tstruct hstate *h = hstate_vma(vma);\n\tstruct resv_map *reservations = vma_resv_map(vma);\n\tstruct hugepage_subpool *spool = subpool_vma(vma);\n\tunsigned long reserve;\n\tunsigned long start;\n\tunsigned long end;\n\n\tif (reservations) {\n\t\tstart = vma_hugecache_offset(h, vma, vma->vm_start);\n\t\tend = vma_hugecache_offset(h, vma, vma->vm_end);\n\n\t\treserve = (end - start) -\n\t\t\tregion_count(&reservations->regions, start, end);\n\n\t\tkref_put(&reservations->refs, resv_map_release);\n\n\t\tif (reserve) {\n\t\t\thugetlb_acct_memory(h, -reserve);\n\t\t\thugepage_subpool_put_pages(spool, reserve);\n\t\t}\n\t}\n}",
        "func": "static void hugetlb_vm_op_close(struct vm_area_struct *vma)\n{\n\tstruct hstate *h = hstate_vma(vma);\n\tstruct resv_map *reservations = vma_resv_map(vma);\n\tstruct hugepage_subpool *spool = subpool_vma(vma);\n\tunsigned long reserve;\n\tunsigned long start;\n\tunsigned long end;\n\n\tif (reservations) {\n\t\tstart = vma_hugecache_offset(h, vma, vma->vm_start);\n\t\tend = vma_hugecache_offset(h, vma, vma->vm_end);\n\n\t\treserve = (end - start) -\n\t\t\tregion_count(&reservations->regions, start, end);\n\n\t\tresv_map_put(vma);\n\n\t\tif (reserve) {\n\t\t\thugetlb_acct_memory(h, -reserve);\n\t\t\thugepage_subpool_put_pages(spool, reserve);\n\t\t}\n\t}\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -14,7 +14,7 @@\n \t\treserve = (end - start) -\n \t\t\tregion_count(&reservations->regions, start, end);\n \n-\t\tkref_put(&reservations->refs, resv_map_release);\n+\t\tresv_map_put(vma);\n \n \t\tif (reserve) {\n \t\t\thugetlb_acct_memory(h, -reserve);",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tkref_put(&reservations->refs, resv_map_release);"
            ],
            "added_lines": [
                "\t\tresv_map_put(vma);"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-1583",
        "func_name": "torvalds/linux/xfrm6_tunnel_rcv",
        "description": "Double free vulnerability in the xfrm6_tunnel_rcv function in net/ipv6/xfrm6_tunnel.c in the Linux kernel before 2.6.22, when the xfrm6_tunnel module is enabled, allows remote attackers to cause a denial of service (panic) via crafted IPv6 packets.",
        "git_url": "https://github.com/torvalds/linux/commit/d0772b70faaf8e9f2013b6c4273d94d5eac8047a",
        "commit_title": "[IPV6]: Fix slab corruption running ip6sic",
        "commit_text": " From: Eric Sesterhenn <snakebyte@gmx.de> ",
        "func_before": "static int xfrm6_tunnel_rcv(struct sk_buff *skb)\n{\n\tstruct ipv6hdr *iph = ipv6_hdr(skb);\n\t__be32 spi;\n\n\tspi = xfrm6_tunnel_spi_lookup((xfrm_address_t *)&iph->saddr);\n\treturn xfrm6_rcv_spi(skb, spi);\n}",
        "func": "static int xfrm6_tunnel_rcv(struct sk_buff *skb)\n{\n\tstruct ipv6hdr *iph = ipv6_hdr(skb);\n\t__be32 spi;\n\n\tspi = xfrm6_tunnel_spi_lookup((xfrm_address_t *)&iph->saddr);\n\treturn xfrm6_rcv_spi(skb, spi) > 0 ? : 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,5 +4,5 @@\n \t__be32 spi;\n \n \tspi = xfrm6_tunnel_spi_lookup((xfrm_address_t *)&iph->saddr);\n-\treturn xfrm6_rcv_spi(skb, spi);\n+\treturn xfrm6_rcv_spi(skb, spi) > 0 ? : 0;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\treturn xfrm6_rcv_spi(skb, spi);"
            ],
            "added_lines": [
                "\treturn xfrm6_rcv_spi(skb, spi) > 0 ? : 0;"
            ]
        }
    },
    {
        "cve_id": "CVE-2011-0716",
        "func_name": "torvalds/linux/br_multicast_add_group",
        "description": "The br_multicast_add_group function in net/bridge/br_multicast.c in the Linux kernel before 2.6.38, when a certain Ethernet bridge configuration is used, allows local users to cause a denial of service (memory corruption and system crash) by sending IGMP packets to a local interface.",
        "git_url": "https://github.com/torvalds/linux/commit/6b0d6a9b4296fa16a28d10d416db7a770fc03287",
        "commit_title": "bridge: Fix mglist corruption that leads to memory corruption",
        "commit_text": " The list mp->mglist is used to indicate whether a multicast group is active on the bridge interface itself as opposed to one of the constituent interfaces in the bridge.  Unfortunately the operation that adds the mp->mglist node to the list neglected to check whether it has already been added.  This leads to list corruption in the form of nodes pointing to itself.  Normally this would be quite obvious as it would cause an infinite loop when walking the list.  However, as this list is never actually walked (which means that we don't really need it, I'll get rid of it in a subsequent patch), this instead is hidden until we perform a delete operation on the affected nodes.  As the same node may now be pointed to by more than one node, the delete operations can then cause modification of freed memory.  This was observed in practice to cause corruption in 512-byte slabs, most commonly leading to crashes in jbd2.  Thanks to Josef Bacik for pointing me in the right direction. ",
        "func_before": "static int br_multicast_add_group(struct net_bridge *br,\n\t\t\t\t  struct net_bridge_port *port,\n\t\t\t\t  struct br_ip *group)\n{\n\tstruct net_bridge_mdb_entry *mp;\n\tstruct net_bridge_port_group *p;\n\tstruct net_bridge_port_group __rcu **pp;\n\tunsigned long now = jiffies;\n\tint err;\n\n\tspin_lock(&br->multicast_lock);\n\tif (!netif_running(br->dev) ||\n\t    (port && port->state == BR_STATE_DISABLED))\n\t\tgoto out;\n\n\tmp = br_multicast_new_group(br, port, group);\n\terr = PTR_ERR(mp);\n\tif (IS_ERR(mp))\n\t\tgoto err;\n\n\tif (!port) {\n\t\thlist_add_head(&mp->mglist, &br->mglist);\n\t\tmod_timer(&mp->timer, now + br->multicast_membership_interval);\n\t\tgoto out;\n\t}\n\n\tfor (pp = &mp->ports;\n\t     (p = mlock_dereference(*pp, br)) != NULL;\n\t     pp = &p->next) {\n\t\tif (p->port == port)\n\t\t\tgoto found;\n\t\tif ((unsigned long)p->port < (unsigned long)port)\n\t\t\tbreak;\n\t}\n\n\tp = kzalloc(sizeof(*p), GFP_ATOMIC);\n\terr = -ENOMEM;\n\tif (unlikely(!p))\n\t\tgoto err;\n\n\tp->addr = *group;\n\tp->port = port;\n\tp->next = *pp;\n\thlist_add_head(&p->mglist, &port->mglist);\n\tsetup_timer(&p->timer, br_multicast_port_group_expired,\n\t\t    (unsigned long)p);\n\tsetup_timer(&p->query_timer, br_multicast_port_group_query_expired,\n\t\t    (unsigned long)p);\n\n\trcu_assign_pointer(*pp, p);\n\nfound:\n\tmod_timer(&p->timer, now + br->multicast_membership_interval);\nout:\n\terr = 0;\n\nerr:\n\tspin_unlock(&br->multicast_lock);\n\treturn err;\n}",
        "func": "static int br_multicast_add_group(struct net_bridge *br,\n\t\t\t\t  struct net_bridge_port *port,\n\t\t\t\t  struct br_ip *group)\n{\n\tstruct net_bridge_mdb_entry *mp;\n\tstruct net_bridge_port_group *p;\n\tstruct net_bridge_port_group __rcu **pp;\n\tunsigned long now = jiffies;\n\tint err;\n\n\tspin_lock(&br->multicast_lock);\n\tif (!netif_running(br->dev) ||\n\t    (port && port->state == BR_STATE_DISABLED))\n\t\tgoto out;\n\n\tmp = br_multicast_new_group(br, port, group);\n\terr = PTR_ERR(mp);\n\tif (IS_ERR(mp))\n\t\tgoto err;\n\n\tif (!port) {\n\t\tif (hlist_unhashed(&mp->mglist))\n\t\t\thlist_add_head(&mp->mglist, &br->mglist);\n\t\tmod_timer(&mp->timer, now + br->multicast_membership_interval);\n\t\tgoto out;\n\t}\n\n\tfor (pp = &mp->ports;\n\t     (p = mlock_dereference(*pp, br)) != NULL;\n\t     pp = &p->next) {\n\t\tif (p->port == port)\n\t\t\tgoto found;\n\t\tif ((unsigned long)p->port < (unsigned long)port)\n\t\t\tbreak;\n\t}\n\n\tp = kzalloc(sizeof(*p), GFP_ATOMIC);\n\terr = -ENOMEM;\n\tif (unlikely(!p))\n\t\tgoto err;\n\n\tp->addr = *group;\n\tp->port = port;\n\tp->next = *pp;\n\thlist_add_head(&p->mglist, &port->mglist);\n\tsetup_timer(&p->timer, br_multicast_port_group_expired,\n\t\t    (unsigned long)p);\n\tsetup_timer(&p->query_timer, br_multicast_port_group_query_expired,\n\t\t    (unsigned long)p);\n\n\trcu_assign_pointer(*pp, p);\n\nfound:\n\tmod_timer(&p->timer, now + br->multicast_membership_interval);\nout:\n\terr = 0;\n\nerr:\n\tspin_unlock(&br->multicast_lock);\n\treturn err;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -19,7 +19,8 @@\n \t\tgoto err;\n \n \tif (!port) {\n-\t\thlist_add_head(&mp->mglist, &br->mglist);\n+\t\tif (hlist_unhashed(&mp->mglist))\n+\t\t\thlist_add_head(&mp->mglist, &br->mglist);\n \t\tmod_timer(&mp->timer, now + br->multicast_membership_interval);\n \t\tgoto out;\n \t}",
        "diff_line_info": {
            "deleted_lines": [
                "\t\thlist_add_head(&mp->mglist, &br->mglist);"
            ],
            "added_lines": [
                "\t\tif (hlist_unhashed(&mp->mglist))",
                "\t\t\thlist_add_head(&mp->mglist, &br->mglist);"
            ]
        }
    },
    {
        "cve_id": "CVE-2011-1479",
        "func_name": "torvalds/linux/inotify_free_group_priv",
        "description": "Double free vulnerability in the inotify subsystem in the Linux kernel before 2.6.39 allows local users to cause a denial of service (system crash) via vectors involving failed attempts to create files.  NOTE: this vulnerability exists because of an incorrect fix for CVE-2010-4250.",
        "git_url": "https://github.com/torvalds/linux/commit/d0de4dc584ec6aa3b26fffea320a8457827768fc",
        "commit_title": "inotify: fix double free/corruption of stuct user",
        "commit_text": " On an error path in inotify_init1 a normal user can trigger a double free of struct user.  This is a regression introduced by a2ae4cc9a16e (\"inotify: stop kernel memory leak on file creation failure\").  We fix this by making sure that if a group exists the user reference is dropped when the group is cleaned up.  We should not explictly drop the reference on error and also drop the reference when the group is cleaned up.  The new lifetime rules are that an inotify group lives from inotify_new_group to the last fsnotify_put_group.  Since the struct user and inotify_devs are directly tied to this lifetime they are only changed/updated in those two locations.  We get rid of all special casing of struct user or user->inotify_devs.  Cc: stable@kernel.org (2.6.37 and up)",
        "func_before": "static void inotify_free_group_priv(struct fsnotify_group *group)\n{\n\t/* ideally the idr is empty and we won't hit the BUG in teh callback */\n\tidr_for_each(&group->inotify_data.idr, idr_callback, group);\n\tidr_remove_all(&group->inotify_data.idr);\n\tidr_destroy(&group->inotify_data.idr);\n\tfree_uid(group->inotify_data.user);\n}",
        "func": "static void inotify_free_group_priv(struct fsnotify_group *group)\n{\n\t/* ideally the idr is empty and we won't hit the BUG in teh callback */\n\tidr_for_each(&group->inotify_data.idr, idr_callback, group);\n\tidr_remove_all(&group->inotify_data.idr);\n\tidr_destroy(&group->inotify_data.idr);\n\tatomic_dec(&group->inotify_data.user->inotify_devs);\n\tfree_uid(group->inotify_data.user);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,5 +4,6 @@\n \tidr_for_each(&group->inotify_data.idr, idr_callback, group);\n \tidr_remove_all(&group->inotify_data.idr);\n \tidr_destroy(&group->inotify_data.idr);\n+\tatomic_dec(&group->inotify_data.user->inotify_devs);\n \tfree_uid(group->inotify_data.user);\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tatomic_dec(&group->inotify_data.user->inotify_devs);"
            ]
        }
    },
    {
        "cve_id": "CVE-2011-1479",
        "func_name": "torvalds/linux/inotify_release",
        "description": "Double free vulnerability in the inotify subsystem in the Linux kernel before 2.6.39 allows local users to cause a denial of service (system crash) via vectors involving failed attempts to create files.  NOTE: this vulnerability exists because of an incorrect fix for CVE-2010-4250.",
        "git_url": "https://github.com/torvalds/linux/commit/d0de4dc584ec6aa3b26fffea320a8457827768fc",
        "commit_title": "inotify: fix double free/corruption of stuct user",
        "commit_text": " On an error path in inotify_init1 a normal user can trigger a double free of struct user.  This is a regression introduced by a2ae4cc9a16e (\"inotify: stop kernel memory leak on file creation failure\").  We fix this by making sure that if a group exists the user reference is dropped when the group is cleaned up.  We should not explictly drop the reference on error and also drop the reference when the group is cleaned up.  The new lifetime rules are that an inotify group lives from inotify_new_group to the last fsnotify_put_group.  Since the struct user and inotify_devs are directly tied to this lifetime they are only changed/updated in those two locations.  We get rid of all special casing of struct user or user->inotify_devs.  Cc: stable@kernel.org (2.6.37 and up)",
        "func_before": "static int inotify_release(struct inode *ignored, struct file *file)\n{\n\tstruct fsnotify_group *group = file->private_data;\n\tstruct user_struct *user = group->inotify_data.user;\n\n\tpr_debug(\"%s: group=%p\\n\", __func__, group);\n\n\tfsnotify_clear_marks_by_group(group);\n\n\t/* free this group, matching get was inotify_init->fsnotify_obtain_group */\n\tfsnotify_put_group(group);\n\n\tatomic_dec(&user->inotify_devs);\n\n\treturn 0;\n}",
        "func": "static int inotify_release(struct inode *ignored, struct file *file)\n{\n\tstruct fsnotify_group *group = file->private_data;\n\n\tpr_debug(\"%s: group=%p\\n\", __func__, group);\n\n\tfsnotify_clear_marks_by_group(group);\n\n\t/* free this group, matching get was inotify_init->fsnotify_obtain_group */\n\tfsnotify_put_group(group);\n\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,7 +1,6 @@\n static int inotify_release(struct inode *ignored, struct file *file)\n {\n \tstruct fsnotify_group *group = file->private_data;\n-\tstruct user_struct *user = group->inotify_data.user;\n \n \tpr_debug(\"%s: group=%p\\n\", __func__, group);\n \n@@ -10,7 +9,5 @@\n \t/* free this group, matching get was inotify_init->fsnotify_obtain_group */\n \tfsnotify_put_group(group);\n \n-\tatomic_dec(&user->inotify_devs);\n-\n \treturn 0;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tstruct user_struct *user = group->inotify_data.user;",
                "\tatomic_dec(&user->inotify_devs);",
                ""
            ],
            "added_lines": []
        }
    },
    {
        "cve_id": "CVE-2011-1479",
        "func_name": "torvalds/linux/inotify_new_group",
        "description": "Double free vulnerability in the inotify subsystem in the Linux kernel before 2.6.39 allows local users to cause a denial of service (system crash) via vectors involving failed attempts to create files.  NOTE: this vulnerability exists because of an incorrect fix for CVE-2010-4250.",
        "git_url": "https://github.com/torvalds/linux/commit/d0de4dc584ec6aa3b26fffea320a8457827768fc",
        "commit_title": "inotify: fix double free/corruption of stuct user",
        "commit_text": " On an error path in inotify_init1 a normal user can trigger a double free of struct user.  This is a regression introduced by a2ae4cc9a16e (\"inotify: stop kernel memory leak on file creation failure\").  We fix this by making sure that if a group exists the user reference is dropped when the group is cleaned up.  We should not explictly drop the reference on error and also drop the reference when the group is cleaned up.  The new lifetime rules are that an inotify group lives from inotify_new_group to the last fsnotify_put_group.  Since the struct user and inotify_devs are directly tied to this lifetime they are only changed/updated in those two locations.  We get rid of all special casing of struct user or user->inotify_devs.  Cc: stable@kernel.org (2.6.37 and up)",
        "func_before": "static struct fsnotify_group *inotify_new_group(struct user_struct *user, unsigned int max_events)\n{\n\tstruct fsnotify_group *group;\n\n\tgroup = fsnotify_alloc_group(&inotify_fsnotify_ops);\n\tif (IS_ERR(group))\n\t\treturn group;\n\n\tgroup->max_events = max_events;\n\n\tspin_lock_init(&group->inotify_data.idr_lock);\n\tidr_init(&group->inotify_data.idr);\n\tgroup->inotify_data.last_wd = 0;\n\tgroup->inotify_data.user = user;\n\tgroup->inotify_data.fa = NULL;\n\n\treturn group;\n}",
        "func": "static struct fsnotify_group *inotify_new_group(unsigned int max_events)\n{\n\tstruct fsnotify_group *group;\n\n\tgroup = fsnotify_alloc_group(&inotify_fsnotify_ops);\n\tif (IS_ERR(group))\n\t\treturn group;\n\n\tgroup->max_events = max_events;\n\n\tspin_lock_init(&group->inotify_data.idr_lock);\n\tidr_init(&group->inotify_data.idr);\n\tgroup->inotify_data.last_wd = 0;\n\tgroup->inotify_data.fa = NULL;\n\tgroup->inotify_data.user = get_current_user();\n\n\tif (atomic_inc_return(&group->inotify_data.user->inotify_devs) >\n\t    inotify_max_user_instances) {\n\t\tfsnotify_put_group(group);\n\t\treturn ERR_PTR(-EMFILE);\n\t}\n\n\treturn group;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,4 +1,4 @@\n-static struct fsnotify_group *inotify_new_group(struct user_struct *user, unsigned int max_events)\n+static struct fsnotify_group *inotify_new_group(unsigned int max_events)\n {\n \tstruct fsnotify_group *group;\n \n@@ -11,8 +11,14 @@\n \tspin_lock_init(&group->inotify_data.idr_lock);\n \tidr_init(&group->inotify_data.idr);\n \tgroup->inotify_data.last_wd = 0;\n-\tgroup->inotify_data.user = user;\n \tgroup->inotify_data.fa = NULL;\n+\tgroup->inotify_data.user = get_current_user();\n+\n+\tif (atomic_inc_return(&group->inotify_data.user->inotify_devs) >\n+\t    inotify_max_user_instances) {\n+\t\tfsnotify_put_group(group);\n+\t\treturn ERR_PTR(-EMFILE);\n+\t}\n \n \treturn group;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "static struct fsnotify_group *inotify_new_group(struct user_struct *user, unsigned int max_events)",
                "\tgroup->inotify_data.user = user;"
            ],
            "added_lines": [
                "static struct fsnotify_group *inotify_new_group(unsigned int max_events)",
                "\tgroup->inotify_data.user = get_current_user();",
                "",
                "\tif (atomic_inc_return(&group->inotify_data.user->inotify_devs) >",
                "\t    inotify_max_user_instances) {",
                "\t\tfsnotify_put_group(group);",
                "\t\treturn ERR_PTR(-EMFILE);",
                "\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-2385",
        "func_name": "mobile-shell/mosh/Dispatcher::getparam",
        "description": "The terminal dispatcher in mosh before 1.2.1 allows remote authenticated users to cause a denial of service (long loop and CPU consumption) via an escape sequence with a large repeat count value.",
        "git_url": "https://github.com/mobile-shell/mosh/commit/9791768705528e911bfca6c4d8aa88139035060e",
        "commit_title": "Cap escape sequence parameters to prevent long loops.",
        "commit_text": " Fixes #271 github issue.",
        "func_before": "int Dispatcher::getparam( size_t N, int defaultval )\n{\n  int ret = defaultval;\n  if ( !parsed ) {\n    parse_params();\n  }\n\n  if ( parsed_params.size() > N ) {\n    ret = parsed_params[ N ];\n  }\n  if ( ret < 1 ) ret = defaultval;\n\n  return ret;\n}",
        "func": "int Dispatcher::getparam( size_t N, int defaultval )\n{\n  int ret = defaultval;\n  if ( !parsed ) {\n    parse_params();\n  }\n\n  if ( parsed_params.size() > N ) {\n    ret = parsed_params[ N ];\n  }\n\n  if ( ret > PARAM_MAX ) {\n    ret = defaultval;\n  }\n\n  if ( ret < 1 ) ret = defaultval;\n\n  return ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -8,6 +8,11 @@\n   if ( parsed_params.size() > N ) {\n     ret = parsed_params[ N ];\n   }\n+\n+  if ( ret > PARAM_MAX ) {\n+    ret = defaultval;\n+  }\n+\n   if ( ret < 1 ) ret = defaultval;\n \n   return ret;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "  if ( ret > PARAM_MAX ) {",
                "    ret = defaultval;",
                "  }",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2012-2133",
        "func_name": "torvalds/linux/free_huge_page",
        "description": "Use-after-free vulnerability in the Linux kernel before 3.3.6, when huge pages are enabled, allows local users to cause a denial of service (system crash) or possibly gain privileges by interacting with a hugetlbfs filesystem, as demonstrated by a umount operation that triggers improper handling of quota data.",
        "git_url": "https://github.com/torvalds/linux/commit/90481622d75715bfcb68501280a917dbfe516029",
        "commit_title": "hugepages: fix use after free bug in \"quota\" handling",
        "commit_text": " hugetlbfs_{get,put}_quota() are badly named.  They don't interact with the general quota handling code, and they don't much resemble its behaviour. Rather than being about maintaining limits on on-disk block usage by particular users, they are instead about maintaining limits on in-memory page usage (including anonymous MAP_PRIVATE copied-on-write pages) associated with a particular hugetlbfs filesystem instance.  Worse, they work by having callbacks to the hugetlbfs filesystem code from the low-level page handling code, in particular from free_huge_page(). This is a layering violation of itself, but more importantly, if the kernel does a get_user_pages() on hugepages (which can happen from KVM amongst others), then the free_huge_page() can be delayed until after the associated inode has already been freed.  If an unmount occurs at the wrong time, even the hugetlbfs superblock where the \"quota\" limits are stored may have been freed.  Andrew Barry proposed a patch to fix this by having hugepages, instead of storing a pointer to their address_space and reaching the superblock from there, had the hugepages store pointers directly to the superblock, bumping the reference count as appropriate to avoid it being freed. Andrew Morton rejected that version, however, on the grounds that it made the existing layering violation worse.  This is a reworked version of Andrew's patch, which removes the extra, and some of the existing, layering violation.  It works by introducing the concept of a hugepage \"subpool\" at the lower hugepage mm layer - that is a finite logical pool of hugepages to allocate from.  hugetlbfs now creates a subpool for each filesystem instance with a page limit set, and a pointer to the subpool gets added to each allocated hugepage, instead of the address_space pointer used now.  The subpool has its own lifetime and is only freed once all pages in it _and_ all other references to it (i.e. superblocks) are gone.  subpools are optional - a NULL subpool pointer is taken by the code to mean that no subpool limits are in effect.  Previous discussion of this bug found in:  \"Fix refcounting in hugetlbfs quota handling.\". See:  https://lkml.org/lkml/2011/8/11/28 or http://marc.info/?l=linux-mm&m=126928970510627&w=1  v2: Fixed a bug spotted by Hillf Danton, and removed the extra parameter to alloc_huge_page() - since it already takes the vma, it is not necessary.  Cc: Hugh Dickins <hughd@google.com> Cc: Mel Gorman <mgorman@suse.de> Cc: Minchan Kim <minchan.kim@gmail.com> Cc: Hillf Danton <dhillf@gmail.com> Cc: Paul Mackerras <paulus@samba.org>",
        "func_before": "static void free_huge_page(struct page *page)\n{\n\t/*\n\t * Can't pass hstate in here because it is called from the\n\t * compound page destructor.\n\t */\n\tstruct hstate *h = page_hstate(page);\n\tint nid = page_to_nid(page);\n\tstruct address_space *mapping;\n\n\tmapping = (struct address_space *) page_private(page);\n\tset_page_private(page, 0);\n\tpage->mapping = NULL;\n\tBUG_ON(page_count(page));\n\tBUG_ON(page_mapcount(page));\n\tINIT_LIST_HEAD(&page->lru);\n\n\tspin_lock(&hugetlb_lock);\n\tif (h->surplus_huge_pages_node[nid] && huge_page_order(h) < MAX_ORDER) {\n\t\tupdate_and_free_page(h, page);\n\t\th->surplus_huge_pages--;\n\t\th->surplus_huge_pages_node[nid]--;\n\t} else {\n\t\tenqueue_huge_page(h, page);\n\t}\n\tspin_unlock(&hugetlb_lock);\n\tif (mapping)\n\t\thugetlb_put_quota(mapping, 1);\n}",
        "func": "static void free_huge_page(struct page *page)\n{\n\t/*\n\t * Can't pass hstate in here because it is called from the\n\t * compound page destructor.\n\t */\n\tstruct hstate *h = page_hstate(page);\n\tint nid = page_to_nid(page);\n\tstruct hugepage_subpool *spool =\n\t\t(struct hugepage_subpool *)page_private(page);\n\n\tset_page_private(page, 0);\n\tpage->mapping = NULL;\n\tBUG_ON(page_count(page));\n\tBUG_ON(page_mapcount(page));\n\tINIT_LIST_HEAD(&page->lru);\n\n\tspin_lock(&hugetlb_lock);\n\tif (h->surplus_huge_pages_node[nid] && huge_page_order(h) < MAX_ORDER) {\n\t\tupdate_and_free_page(h, page);\n\t\th->surplus_huge_pages--;\n\t\th->surplus_huge_pages_node[nid]--;\n\t} else {\n\t\tenqueue_huge_page(h, page);\n\t}\n\tspin_unlock(&hugetlb_lock);\n\thugepage_subpool_put_pages(spool, 1);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -6,9 +6,9 @@\n \t */\n \tstruct hstate *h = page_hstate(page);\n \tint nid = page_to_nid(page);\n-\tstruct address_space *mapping;\n+\tstruct hugepage_subpool *spool =\n+\t\t(struct hugepage_subpool *)page_private(page);\n \n-\tmapping = (struct address_space *) page_private(page);\n \tset_page_private(page, 0);\n \tpage->mapping = NULL;\n \tBUG_ON(page_count(page));\n@@ -24,6 +24,5 @@\n \t\tenqueue_huge_page(h, page);\n \t}\n \tspin_unlock(&hugetlb_lock);\n-\tif (mapping)\n-\t\thugetlb_put_quota(mapping, 1);\n+\thugepage_subpool_put_pages(spool, 1);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tstruct address_space *mapping;",
                "\tmapping = (struct address_space *) page_private(page);",
                "\tif (mapping)",
                "\t\thugetlb_put_quota(mapping, 1);"
            ],
            "added_lines": [
                "\tstruct hugepage_subpool *spool =",
                "\t\t(struct hugepage_subpool *)page_private(page);",
                "\thugepage_subpool_put_pages(spool, 1);"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-2133",
        "func_name": "torvalds/linux/hugetlb_reserve_pages",
        "description": "Use-after-free vulnerability in the Linux kernel before 3.3.6, when huge pages are enabled, allows local users to cause a denial of service (system crash) or possibly gain privileges by interacting with a hugetlbfs filesystem, as demonstrated by a umount operation that triggers improper handling of quota data.",
        "git_url": "https://github.com/torvalds/linux/commit/90481622d75715bfcb68501280a917dbfe516029",
        "commit_title": "hugepages: fix use after free bug in \"quota\" handling",
        "commit_text": " hugetlbfs_{get,put}_quota() are badly named.  They don't interact with the general quota handling code, and they don't much resemble its behaviour. Rather than being about maintaining limits on on-disk block usage by particular users, they are instead about maintaining limits on in-memory page usage (including anonymous MAP_PRIVATE copied-on-write pages) associated with a particular hugetlbfs filesystem instance.  Worse, they work by having callbacks to the hugetlbfs filesystem code from the low-level page handling code, in particular from free_huge_page(). This is a layering violation of itself, but more importantly, if the kernel does a get_user_pages() on hugepages (which can happen from KVM amongst others), then the free_huge_page() can be delayed until after the associated inode has already been freed.  If an unmount occurs at the wrong time, even the hugetlbfs superblock where the \"quota\" limits are stored may have been freed.  Andrew Barry proposed a patch to fix this by having hugepages, instead of storing a pointer to their address_space and reaching the superblock from there, had the hugepages store pointers directly to the superblock, bumping the reference count as appropriate to avoid it being freed. Andrew Morton rejected that version, however, on the grounds that it made the existing layering violation worse.  This is a reworked version of Andrew's patch, which removes the extra, and some of the existing, layering violation.  It works by introducing the concept of a hugepage \"subpool\" at the lower hugepage mm layer - that is a finite logical pool of hugepages to allocate from.  hugetlbfs now creates a subpool for each filesystem instance with a page limit set, and a pointer to the subpool gets added to each allocated hugepage, instead of the address_space pointer used now.  The subpool has its own lifetime and is only freed once all pages in it _and_ all other references to it (i.e. superblocks) are gone.  subpools are optional - a NULL subpool pointer is taken by the code to mean that no subpool limits are in effect.  Previous discussion of this bug found in:  \"Fix refcounting in hugetlbfs quota handling.\". See:  https://lkml.org/lkml/2011/8/11/28 or http://marc.info/?l=linux-mm&m=126928970510627&w=1  v2: Fixed a bug spotted by Hillf Danton, and removed the extra parameter to alloc_huge_page() - since it already takes the vma, it is not necessary.  Cc: Hugh Dickins <hughd@google.com> Cc: Mel Gorman <mgorman@suse.de> Cc: Minchan Kim <minchan.kim@gmail.com> Cc: Hillf Danton <dhillf@gmail.com> Cc: Paul Mackerras <paulus@samba.org>",
        "func_before": "int hugetlb_reserve_pages(struct inode *inode,\n\t\t\t\t\tlong from, long to,\n\t\t\t\t\tstruct vm_area_struct *vma,\n\t\t\t\t\tvm_flags_t vm_flags)\n{\n\tlong ret, chg;\n\tstruct hstate *h = hstate_inode(inode);\n\n\t/*\n\t * Only apply hugepage reservation if asked. At fault time, an\n\t * attempt will be made for VM_NORESERVE to allocate a page\n\t * and filesystem quota without using reserves\n\t */\n\tif (vm_flags & VM_NORESERVE)\n\t\treturn 0;\n\n\t/*\n\t * Shared mappings base their reservation on the number of pages that\n\t * are already allocated on behalf of the file. Private mappings need\n\t * to reserve the full area even if read-only as mprotect() may be\n\t * called to make the mapping read-write. Assume !vma is a shm mapping\n\t */\n\tif (!vma || vma->vm_flags & VM_MAYSHARE)\n\t\tchg = region_chg(&inode->i_mapping->private_list, from, to);\n\telse {\n\t\tstruct resv_map *resv_map = resv_map_alloc();\n\t\tif (!resv_map)\n\t\t\treturn -ENOMEM;\n\n\t\tchg = to - from;\n\n\t\tset_vma_resv_map(vma, resv_map);\n\t\tset_vma_resv_flags(vma, HPAGE_RESV_OWNER);\n\t}\n\n\tif (chg < 0)\n\t\treturn chg;\n\n\t/* There must be enough filesystem quota for the mapping */\n\tif (hugetlb_get_quota(inode->i_mapping, chg))\n\t\treturn -ENOSPC;\n\n\t/*\n\t * Check enough hugepages are available for the reservation.\n\t * Hand back the quota if there are not\n\t */\n\tret = hugetlb_acct_memory(h, chg);\n\tif (ret < 0) {\n\t\thugetlb_put_quota(inode->i_mapping, chg);\n\t\treturn ret;\n\t}\n\n\t/*\n\t * Account for the reservations made. Shared mappings record regions\n\t * that have reservations as they are shared by multiple VMAs.\n\t * When the last VMA disappears, the region map says how much\n\t * the reservation was and the page cache tells how much of\n\t * the reservation was consumed. Private mappings are per-VMA and\n\t * only the consumed reservations are tracked. When the VMA\n\t * disappears, the original reservation is the VMA size and the\n\t * consumed reservations are stored in the map. Hence, nothing\n\t * else has to be done for private mappings here\n\t */\n\tif (!vma || vma->vm_flags & VM_MAYSHARE)\n\t\tregion_add(&inode->i_mapping->private_list, from, to);\n\treturn 0;\n}",
        "func": "int hugetlb_reserve_pages(struct inode *inode,\n\t\t\t\t\tlong from, long to,\n\t\t\t\t\tstruct vm_area_struct *vma,\n\t\t\t\t\tvm_flags_t vm_flags)\n{\n\tlong ret, chg;\n\tstruct hstate *h = hstate_inode(inode);\n\tstruct hugepage_subpool *spool = subpool_inode(inode);\n\n\t/*\n\t * Only apply hugepage reservation if asked. At fault time, an\n\t * attempt will be made for VM_NORESERVE to allocate a page\n\t * without using reserves\n\t */\n\tif (vm_flags & VM_NORESERVE)\n\t\treturn 0;\n\n\t/*\n\t * Shared mappings base their reservation on the number of pages that\n\t * are already allocated on behalf of the file. Private mappings need\n\t * to reserve the full area even if read-only as mprotect() may be\n\t * called to make the mapping read-write. Assume !vma is a shm mapping\n\t */\n\tif (!vma || vma->vm_flags & VM_MAYSHARE)\n\t\tchg = region_chg(&inode->i_mapping->private_list, from, to);\n\telse {\n\t\tstruct resv_map *resv_map = resv_map_alloc();\n\t\tif (!resv_map)\n\t\t\treturn -ENOMEM;\n\n\t\tchg = to - from;\n\n\t\tset_vma_resv_map(vma, resv_map);\n\t\tset_vma_resv_flags(vma, HPAGE_RESV_OWNER);\n\t}\n\n\tif (chg < 0)\n\t\treturn chg;\n\n\t/* There must be enough pages in the subpool for the mapping */\n\tif (hugepage_subpool_get_pages(spool, chg))\n\t\treturn -ENOSPC;\n\n\t/*\n\t * Check enough hugepages are available for the reservation.\n\t * Hand the pages back to the subpool if there are not\n\t */\n\tret = hugetlb_acct_memory(h, chg);\n\tif (ret < 0) {\n\t\thugepage_subpool_put_pages(spool, chg);\n\t\treturn ret;\n\t}\n\n\t/*\n\t * Account for the reservations made. Shared mappings record regions\n\t * that have reservations as they are shared by multiple VMAs.\n\t * When the last VMA disappears, the region map says how much\n\t * the reservation was and the page cache tells how much of\n\t * the reservation was consumed. Private mappings are per-VMA and\n\t * only the consumed reservations are tracked. When the VMA\n\t * disappears, the original reservation is the VMA size and the\n\t * consumed reservations are stored in the map. Hence, nothing\n\t * else has to be done for private mappings here\n\t */\n\tif (!vma || vma->vm_flags & VM_MAYSHARE)\n\t\tregion_add(&inode->i_mapping->private_list, from, to);\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,11 +5,12 @@\n {\n \tlong ret, chg;\n \tstruct hstate *h = hstate_inode(inode);\n+\tstruct hugepage_subpool *spool = subpool_inode(inode);\n \n \t/*\n \t * Only apply hugepage reservation if asked. At fault time, an\n \t * attempt will be made for VM_NORESERVE to allocate a page\n-\t * and filesystem quota without using reserves\n+\t * without using reserves\n \t */\n \tif (vm_flags & VM_NORESERVE)\n \t\treturn 0;\n@@ -36,17 +37,17 @@\n \tif (chg < 0)\n \t\treturn chg;\n \n-\t/* There must be enough filesystem quota for the mapping */\n-\tif (hugetlb_get_quota(inode->i_mapping, chg))\n+\t/* There must be enough pages in the subpool for the mapping */\n+\tif (hugepage_subpool_get_pages(spool, chg))\n \t\treturn -ENOSPC;\n \n \t/*\n \t * Check enough hugepages are available for the reservation.\n-\t * Hand back the quota if there are not\n+\t * Hand the pages back to the subpool if there are not\n \t */\n \tret = hugetlb_acct_memory(h, chg);\n \tif (ret < 0) {\n-\t\thugetlb_put_quota(inode->i_mapping, chg);\n+\t\thugepage_subpool_put_pages(spool, chg);\n \t\treturn ret;\n \t}\n ",
        "diff_line_info": {
            "deleted_lines": [
                "\t * and filesystem quota without using reserves",
                "\t/* There must be enough filesystem quota for the mapping */",
                "\tif (hugetlb_get_quota(inode->i_mapping, chg))",
                "\t * Hand back the quota if there are not",
                "\t\thugetlb_put_quota(inode->i_mapping, chg);"
            ],
            "added_lines": [
                "\tstruct hugepage_subpool *spool = subpool_inode(inode);",
                "\t * without using reserves",
                "\t/* There must be enough pages in the subpool for the mapping */",
                "\tif (hugepage_subpool_get_pages(spool, chg))",
                "\t * Hand the pages back to the subpool if there are not",
                "\t\thugepage_subpool_put_pages(spool, chg);"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-2133",
        "func_name": "torvalds/linux/hugetlb_vm_op_close",
        "description": "Use-after-free vulnerability in the Linux kernel before 3.3.6, when huge pages are enabled, allows local users to cause a denial of service (system crash) or possibly gain privileges by interacting with a hugetlbfs filesystem, as demonstrated by a umount operation that triggers improper handling of quota data.",
        "git_url": "https://github.com/torvalds/linux/commit/90481622d75715bfcb68501280a917dbfe516029",
        "commit_title": "hugepages: fix use after free bug in \"quota\" handling",
        "commit_text": " hugetlbfs_{get,put}_quota() are badly named.  They don't interact with the general quota handling code, and they don't much resemble its behaviour. Rather than being about maintaining limits on on-disk block usage by particular users, they are instead about maintaining limits on in-memory page usage (including anonymous MAP_PRIVATE copied-on-write pages) associated with a particular hugetlbfs filesystem instance.  Worse, they work by having callbacks to the hugetlbfs filesystem code from the low-level page handling code, in particular from free_huge_page(). This is a layering violation of itself, but more importantly, if the kernel does a get_user_pages() on hugepages (which can happen from KVM amongst others), then the free_huge_page() can be delayed until after the associated inode has already been freed.  If an unmount occurs at the wrong time, even the hugetlbfs superblock where the \"quota\" limits are stored may have been freed.  Andrew Barry proposed a patch to fix this by having hugepages, instead of storing a pointer to their address_space and reaching the superblock from there, had the hugepages store pointers directly to the superblock, bumping the reference count as appropriate to avoid it being freed. Andrew Morton rejected that version, however, on the grounds that it made the existing layering violation worse.  This is a reworked version of Andrew's patch, which removes the extra, and some of the existing, layering violation.  It works by introducing the concept of a hugepage \"subpool\" at the lower hugepage mm layer - that is a finite logical pool of hugepages to allocate from.  hugetlbfs now creates a subpool for each filesystem instance with a page limit set, and a pointer to the subpool gets added to each allocated hugepage, instead of the address_space pointer used now.  The subpool has its own lifetime and is only freed once all pages in it _and_ all other references to it (i.e. superblocks) are gone.  subpools are optional - a NULL subpool pointer is taken by the code to mean that no subpool limits are in effect.  Previous discussion of this bug found in:  \"Fix refcounting in hugetlbfs quota handling.\". See:  https://lkml.org/lkml/2011/8/11/28 or http://marc.info/?l=linux-mm&m=126928970510627&w=1  v2: Fixed a bug spotted by Hillf Danton, and removed the extra parameter to alloc_huge_page() - since it already takes the vma, it is not necessary.  Cc: Hugh Dickins <hughd@google.com> Cc: Mel Gorman <mgorman@suse.de> Cc: Minchan Kim <minchan.kim@gmail.com> Cc: Hillf Danton <dhillf@gmail.com> Cc: Paul Mackerras <paulus@samba.org>",
        "func_before": "static void hugetlb_vm_op_close(struct vm_area_struct *vma)\n{\n\tstruct hstate *h = hstate_vma(vma);\n\tstruct resv_map *reservations = vma_resv_map(vma);\n\tunsigned long reserve;\n\tunsigned long start;\n\tunsigned long end;\n\n\tif (reservations) {\n\t\tstart = vma_hugecache_offset(h, vma, vma->vm_start);\n\t\tend = vma_hugecache_offset(h, vma, vma->vm_end);\n\n\t\treserve = (end - start) -\n\t\t\tregion_count(&reservations->regions, start, end);\n\n\t\tkref_put(&reservations->refs, resv_map_release);\n\n\t\tif (reserve) {\n\t\t\thugetlb_acct_memory(h, -reserve);\n\t\t\thugetlb_put_quota(vma->vm_file->f_mapping, reserve);\n\t\t}\n\t}\n}",
        "func": "static void hugetlb_vm_op_close(struct vm_area_struct *vma)\n{\n\tstruct hstate *h = hstate_vma(vma);\n\tstruct resv_map *reservations = vma_resv_map(vma);\n\tstruct hugepage_subpool *spool = subpool_vma(vma);\n\tunsigned long reserve;\n\tunsigned long start;\n\tunsigned long end;\n\n\tif (reservations) {\n\t\tstart = vma_hugecache_offset(h, vma, vma->vm_start);\n\t\tend = vma_hugecache_offset(h, vma, vma->vm_end);\n\n\t\treserve = (end - start) -\n\t\t\tregion_count(&reservations->regions, start, end);\n\n\t\tkref_put(&reservations->refs, resv_map_release);\n\n\t\tif (reserve) {\n\t\t\thugetlb_acct_memory(h, -reserve);\n\t\t\thugepage_subpool_put_pages(spool, reserve);\n\t\t}\n\t}\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,6 +2,7 @@\n {\n \tstruct hstate *h = hstate_vma(vma);\n \tstruct resv_map *reservations = vma_resv_map(vma);\n+\tstruct hugepage_subpool *spool = subpool_vma(vma);\n \tunsigned long reserve;\n \tunsigned long start;\n \tunsigned long end;\n@@ -17,7 +18,7 @@\n \n \t\tif (reserve) {\n \t\t\thugetlb_acct_memory(h, -reserve);\n-\t\t\thugetlb_put_quota(vma->vm_file->f_mapping, reserve);\n+\t\t\thugepage_subpool_put_pages(spool, reserve);\n \t\t}\n \t}\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\thugetlb_put_quota(vma->vm_file->f_mapping, reserve);"
            ],
            "added_lines": [
                "\tstruct hugepage_subpool *spool = subpool_vma(vma);",
                "\t\t\thugepage_subpool_put_pages(spool, reserve);"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-2133",
        "func_name": "torvalds/linux/unmap_ref_private",
        "description": "Use-after-free vulnerability in the Linux kernel before 3.3.6, when huge pages are enabled, allows local users to cause a denial of service (system crash) or possibly gain privileges by interacting with a hugetlbfs filesystem, as demonstrated by a umount operation that triggers improper handling of quota data.",
        "git_url": "https://github.com/torvalds/linux/commit/90481622d75715bfcb68501280a917dbfe516029",
        "commit_title": "hugepages: fix use after free bug in \"quota\" handling",
        "commit_text": " hugetlbfs_{get,put}_quota() are badly named.  They don't interact with the general quota handling code, and they don't much resemble its behaviour. Rather than being about maintaining limits on on-disk block usage by particular users, they are instead about maintaining limits on in-memory page usage (including anonymous MAP_PRIVATE copied-on-write pages) associated with a particular hugetlbfs filesystem instance.  Worse, they work by having callbacks to the hugetlbfs filesystem code from the low-level page handling code, in particular from free_huge_page(). This is a layering violation of itself, but more importantly, if the kernel does a get_user_pages() on hugepages (which can happen from KVM amongst others), then the free_huge_page() can be delayed until after the associated inode has already been freed.  If an unmount occurs at the wrong time, even the hugetlbfs superblock where the \"quota\" limits are stored may have been freed.  Andrew Barry proposed a patch to fix this by having hugepages, instead of storing a pointer to their address_space and reaching the superblock from there, had the hugepages store pointers directly to the superblock, bumping the reference count as appropriate to avoid it being freed. Andrew Morton rejected that version, however, on the grounds that it made the existing layering violation worse.  This is a reworked version of Andrew's patch, which removes the extra, and some of the existing, layering violation.  It works by introducing the concept of a hugepage \"subpool\" at the lower hugepage mm layer - that is a finite logical pool of hugepages to allocate from.  hugetlbfs now creates a subpool for each filesystem instance with a page limit set, and a pointer to the subpool gets added to each allocated hugepage, instead of the address_space pointer used now.  The subpool has its own lifetime and is only freed once all pages in it _and_ all other references to it (i.e. superblocks) are gone.  subpools are optional - a NULL subpool pointer is taken by the code to mean that no subpool limits are in effect.  Previous discussion of this bug found in:  \"Fix refcounting in hugetlbfs quota handling.\". See:  https://lkml.org/lkml/2011/8/11/28 or http://marc.info/?l=linux-mm&m=126928970510627&w=1  v2: Fixed a bug spotted by Hillf Danton, and removed the extra parameter to alloc_huge_page() - since it already takes the vma, it is not necessary.  Cc: Hugh Dickins <hughd@google.com> Cc: Mel Gorman <mgorman@suse.de> Cc: Minchan Kim <minchan.kim@gmail.com> Cc: Hillf Danton <dhillf@gmail.com> Cc: Paul Mackerras <paulus@samba.org>",
        "func_before": "static int unmap_ref_private(struct mm_struct *mm, struct vm_area_struct *vma,\n\t\t\t\tstruct page *page, unsigned long address)\n{\n\tstruct hstate *h = hstate_vma(vma);\n\tstruct vm_area_struct *iter_vma;\n\tstruct address_space *mapping;\n\tstruct prio_tree_iter iter;\n\tpgoff_t pgoff;\n\n\t/*\n\t * vm_pgoff is in PAGE_SIZE units, hence the different calculation\n\t * from page cache lookup which is in HPAGE_SIZE units.\n\t */\n\taddress = address & huge_page_mask(h);\n\tpgoff = vma_hugecache_offset(h, vma, address);\n\tmapping = (struct address_space *)page_private(page);\n\n\t/*\n\t * Take the mapping lock for the duration of the table walk. As\n\t * this mapping should be shared between all the VMAs,\n\t * __unmap_hugepage_range() is called as the lock is already held\n\t */\n\tmutex_lock(&mapping->i_mmap_mutex);\n\tvma_prio_tree_foreach(iter_vma, &iter, &mapping->i_mmap, pgoff, pgoff) {\n\t\t/* Do not unmap the current VMA */\n\t\tif (iter_vma == vma)\n\t\t\tcontinue;\n\n\t\t/*\n\t\t * Unmap the page from other VMAs without their own reserves.\n\t\t * They get marked to be SIGKILLed if they fault in these\n\t\t * areas. This is because a future no-page fault on this VMA\n\t\t * could insert a zeroed page instead of the data existing\n\t\t * from the time of fork. This would look like data corruption\n\t\t */\n\t\tif (!is_vma_resv_set(iter_vma, HPAGE_RESV_OWNER))\n\t\t\t__unmap_hugepage_range(iter_vma,\n\t\t\t\taddress, address + huge_page_size(h),\n\t\t\t\tpage);\n\t}\n\tmutex_unlock(&mapping->i_mmap_mutex);\n\n\treturn 1;\n}",
        "func": "static int unmap_ref_private(struct mm_struct *mm, struct vm_area_struct *vma,\n\t\t\t\tstruct page *page, unsigned long address)\n{\n\tstruct hstate *h = hstate_vma(vma);\n\tstruct vm_area_struct *iter_vma;\n\tstruct address_space *mapping;\n\tstruct prio_tree_iter iter;\n\tpgoff_t pgoff;\n\n\t/*\n\t * vm_pgoff is in PAGE_SIZE units, hence the different calculation\n\t * from page cache lookup which is in HPAGE_SIZE units.\n\t */\n\taddress = address & huge_page_mask(h);\n\tpgoff = vma_hugecache_offset(h, vma, address);\n\tmapping = vma->vm_file->f_dentry->d_inode->i_mapping;\n\n\t/*\n\t * Take the mapping lock for the duration of the table walk. As\n\t * this mapping should be shared between all the VMAs,\n\t * __unmap_hugepage_range() is called as the lock is already held\n\t */\n\tmutex_lock(&mapping->i_mmap_mutex);\n\tvma_prio_tree_foreach(iter_vma, &iter, &mapping->i_mmap, pgoff, pgoff) {\n\t\t/* Do not unmap the current VMA */\n\t\tif (iter_vma == vma)\n\t\t\tcontinue;\n\n\t\t/*\n\t\t * Unmap the page from other VMAs without their own reserves.\n\t\t * They get marked to be SIGKILLed if they fault in these\n\t\t * areas. This is because a future no-page fault on this VMA\n\t\t * could insert a zeroed page instead of the data existing\n\t\t * from the time of fork. This would look like data corruption\n\t\t */\n\t\tif (!is_vma_resv_set(iter_vma, HPAGE_RESV_OWNER))\n\t\t\t__unmap_hugepage_range(iter_vma,\n\t\t\t\taddress, address + huge_page_size(h),\n\t\t\t\tpage);\n\t}\n\tmutex_unlock(&mapping->i_mmap_mutex);\n\n\treturn 1;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -13,7 +13,7 @@\n \t */\n \taddress = address & huge_page_mask(h);\n \tpgoff = vma_hugecache_offset(h, vma, address);\n-\tmapping = (struct address_space *)page_private(page);\n+\tmapping = vma->vm_file->f_dentry->d_inode->i_mapping;\n \n \t/*\n \t * Take the mapping lock for the duration of the table walk. As",
        "diff_line_info": {
            "deleted_lines": [
                "\tmapping = (struct address_space *)page_private(page);"
            ],
            "added_lines": [
                "\tmapping = vma->vm_file->f_dentry->d_inode->i_mapping;"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-2133",
        "func_name": "torvalds/linux/alloc_huge_page",
        "description": "Use-after-free vulnerability in the Linux kernel before 3.3.6, when huge pages are enabled, allows local users to cause a denial of service (system crash) or possibly gain privileges by interacting with a hugetlbfs filesystem, as demonstrated by a umount operation that triggers improper handling of quota data.",
        "git_url": "https://github.com/torvalds/linux/commit/90481622d75715bfcb68501280a917dbfe516029",
        "commit_title": "hugepages: fix use after free bug in \"quota\" handling",
        "commit_text": " hugetlbfs_{get,put}_quota() are badly named.  They don't interact with the general quota handling code, and they don't much resemble its behaviour. Rather than being about maintaining limits on on-disk block usage by particular users, they are instead about maintaining limits on in-memory page usage (including anonymous MAP_PRIVATE copied-on-write pages) associated with a particular hugetlbfs filesystem instance.  Worse, they work by having callbacks to the hugetlbfs filesystem code from the low-level page handling code, in particular from free_huge_page(). This is a layering violation of itself, but more importantly, if the kernel does a get_user_pages() on hugepages (which can happen from KVM amongst others), then the free_huge_page() can be delayed until after the associated inode has already been freed.  If an unmount occurs at the wrong time, even the hugetlbfs superblock where the \"quota\" limits are stored may have been freed.  Andrew Barry proposed a patch to fix this by having hugepages, instead of storing a pointer to their address_space and reaching the superblock from there, had the hugepages store pointers directly to the superblock, bumping the reference count as appropriate to avoid it being freed. Andrew Morton rejected that version, however, on the grounds that it made the existing layering violation worse.  This is a reworked version of Andrew's patch, which removes the extra, and some of the existing, layering violation.  It works by introducing the concept of a hugepage \"subpool\" at the lower hugepage mm layer - that is a finite logical pool of hugepages to allocate from.  hugetlbfs now creates a subpool for each filesystem instance with a page limit set, and a pointer to the subpool gets added to each allocated hugepage, instead of the address_space pointer used now.  The subpool has its own lifetime and is only freed once all pages in it _and_ all other references to it (i.e. superblocks) are gone.  subpools are optional - a NULL subpool pointer is taken by the code to mean that no subpool limits are in effect.  Previous discussion of this bug found in:  \"Fix refcounting in hugetlbfs quota handling.\". See:  https://lkml.org/lkml/2011/8/11/28 or http://marc.info/?l=linux-mm&m=126928970510627&w=1  v2: Fixed a bug spotted by Hillf Danton, and removed the extra parameter to alloc_huge_page() - since it already takes the vma, it is not necessary.  Cc: Hugh Dickins <hughd@google.com> Cc: Mel Gorman <mgorman@suse.de> Cc: Minchan Kim <minchan.kim@gmail.com> Cc: Hillf Danton <dhillf@gmail.com> Cc: Paul Mackerras <paulus@samba.org>",
        "func_before": "static struct page *alloc_huge_page(struct vm_area_struct *vma,\n\t\t\t\t    unsigned long addr, int avoid_reserve)\n{\n\tstruct hstate *h = hstate_vma(vma);\n\tstruct page *page;\n\tstruct address_space *mapping = vma->vm_file->f_mapping;\n\tstruct inode *inode = mapping->host;\n\tlong chg;\n\n\t/*\n\t * Processes that did not create the mapping will have no reserves and\n\t * will not have accounted against quota. Check that the quota can be\n\t * made before satisfying the allocation\n\t * MAP_NORESERVE mappings may also need pages and quota allocated\n\t * if no reserve mapping overlaps.\n\t */\n\tchg = vma_needs_reservation(h, vma, addr);\n\tif (chg < 0)\n\t\treturn ERR_PTR(-VM_FAULT_OOM);\n\tif (chg)\n\t\tif (hugetlb_get_quota(inode->i_mapping, chg))\n\t\t\treturn ERR_PTR(-VM_FAULT_SIGBUS);\n\n\tspin_lock(&hugetlb_lock);\n\tpage = dequeue_huge_page_vma(h, vma, addr, avoid_reserve);\n\tspin_unlock(&hugetlb_lock);\n\n\tif (!page) {\n\t\tpage = alloc_buddy_huge_page(h, NUMA_NO_NODE);\n\t\tif (!page) {\n\t\t\thugetlb_put_quota(inode->i_mapping, chg);\n\t\t\treturn ERR_PTR(-VM_FAULT_SIGBUS);\n\t\t}\n\t}\n\n\tset_page_private(page, (unsigned long) mapping);\n\n\tvma_commit_reservation(h, vma, addr);\n\n\treturn page;\n}",
        "func": "static struct page *alloc_huge_page(struct vm_area_struct *vma,\n\t\t\t\t    unsigned long addr, int avoid_reserve)\n{\n\tstruct hugepage_subpool *spool = subpool_vma(vma);\n\tstruct hstate *h = hstate_vma(vma);\n\tstruct page *page;\n\tlong chg;\n\n\t/*\n\t * Processes that did not create the mapping will have no\n\t * reserves and will not have accounted against subpool\n\t * limit. Check that the subpool limit can be made before\n\t * satisfying the allocation MAP_NORESERVE mappings may also\n\t * need pages and subpool limit allocated allocated if no reserve\n\t * mapping overlaps.\n\t */\n\tchg = vma_needs_reservation(h, vma, addr);\n\tif (chg < 0)\n\t\treturn ERR_PTR(-VM_FAULT_OOM);\n\tif (chg)\n\t\tif (hugepage_subpool_get_pages(spool, chg))\n\t\t\treturn ERR_PTR(-VM_FAULT_SIGBUS);\n\n\tspin_lock(&hugetlb_lock);\n\tpage = dequeue_huge_page_vma(h, vma, addr, avoid_reserve);\n\tspin_unlock(&hugetlb_lock);\n\n\tif (!page) {\n\t\tpage = alloc_buddy_huge_page(h, NUMA_NO_NODE);\n\t\tif (!page) {\n\t\t\thugepage_subpool_put_pages(spool, chg);\n\t\t\treturn ERR_PTR(-VM_FAULT_SIGBUS);\n\t\t}\n\t}\n\n\tset_page_private(page, (unsigned long)spool);\n\n\tvma_commit_reservation(h, vma, addr);\n\n\treturn page;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,24 +1,24 @@\n static struct page *alloc_huge_page(struct vm_area_struct *vma,\n \t\t\t\t    unsigned long addr, int avoid_reserve)\n {\n+\tstruct hugepage_subpool *spool = subpool_vma(vma);\n \tstruct hstate *h = hstate_vma(vma);\n \tstruct page *page;\n-\tstruct address_space *mapping = vma->vm_file->f_mapping;\n-\tstruct inode *inode = mapping->host;\n \tlong chg;\n \n \t/*\n-\t * Processes that did not create the mapping will have no reserves and\n-\t * will not have accounted against quota. Check that the quota can be\n-\t * made before satisfying the allocation\n-\t * MAP_NORESERVE mappings may also need pages and quota allocated\n-\t * if no reserve mapping overlaps.\n+\t * Processes that did not create the mapping will have no\n+\t * reserves and will not have accounted against subpool\n+\t * limit. Check that the subpool limit can be made before\n+\t * satisfying the allocation MAP_NORESERVE mappings may also\n+\t * need pages and subpool limit allocated allocated if no reserve\n+\t * mapping overlaps.\n \t */\n \tchg = vma_needs_reservation(h, vma, addr);\n \tif (chg < 0)\n \t\treturn ERR_PTR(-VM_FAULT_OOM);\n \tif (chg)\n-\t\tif (hugetlb_get_quota(inode->i_mapping, chg))\n+\t\tif (hugepage_subpool_get_pages(spool, chg))\n \t\t\treturn ERR_PTR(-VM_FAULT_SIGBUS);\n \n \tspin_lock(&hugetlb_lock);\n@@ -28,12 +28,12 @@\n \tif (!page) {\n \t\tpage = alloc_buddy_huge_page(h, NUMA_NO_NODE);\n \t\tif (!page) {\n-\t\t\thugetlb_put_quota(inode->i_mapping, chg);\n+\t\t\thugepage_subpool_put_pages(spool, chg);\n \t\t\treturn ERR_PTR(-VM_FAULT_SIGBUS);\n \t\t}\n \t}\n \n-\tset_page_private(page, (unsigned long) mapping);\n+\tset_page_private(page, (unsigned long)spool);\n \n \tvma_commit_reservation(h, vma, addr);\n ",
        "diff_line_info": {
            "deleted_lines": [
                "\tstruct address_space *mapping = vma->vm_file->f_mapping;",
                "\tstruct inode *inode = mapping->host;",
                "\t * Processes that did not create the mapping will have no reserves and",
                "\t * will not have accounted against quota. Check that the quota can be",
                "\t * made before satisfying the allocation",
                "\t * MAP_NORESERVE mappings may also need pages and quota allocated",
                "\t * if no reserve mapping overlaps.",
                "\t\tif (hugetlb_get_quota(inode->i_mapping, chg))",
                "\t\t\thugetlb_put_quota(inode->i_mapping, chg);",
                "\tset_page_private(page, (unsigned long) mapping);"
            ],
            "added_lines": [
                "\tstruct hugepage_subpool *spool = subpool_vma(vma);",
                "\t * Processes that did not create the mapping will have no",
                "\t * reserves and will not have accounted against subpool",
                "\t * limit. Check that the subpool limit can be made before",
                "\t * satisfying the allocation MAP_NORESERVE mappings may also",
                "\t * need pages and subpool limit allocated allocated if no reserve",
                "\t * mapping overlaps.",
                "\t\tif (hugepage_subpool_get_pages(spool, chg))",
                "\t\t\thugepage_subpool_put_pages(spool, chg);",
                "\tset_page_private(page, (unsigned long)spool);"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-2133",
        "func_name": "torvalds/linux/hugetlb_unreserve_pages",
        "description": "Use-after-free vulnerability in the Linux kernel before 3.3.6, when huge pages are enabled, allows local users to cause a denial of service (system crash) or possibly gain privileges by interacting with a hugetlbfs filesystem, as demonstrated by a umount operation that triggers improper handling of quota data.",
        "git_url": "https://github.com/torvalds/linux/commit/90481622d75715bfcb68501280a917dbfe516029",
        "commit_title": "hugepages: fix use after free bug in \"quota\" handling",
        "commit_text": " hugetlbfs_{get,put}_quota() are badly named.  They don't interact with the general quota handling code, and they don't much resemble its behaviour. Rather than being about maintaining limits on on-disk block usage by particular users, they are instead about maintaining limits on in-memory page usage (including anonymous MAP_PRIVATE copied-on-write pages) associated with a particular hugetlbfs filesystem instance.  Worse, they work by having callbacks to the hugetlbfs filesystem code from the low-level page handling code, in particular from free_huge_page(). This is a layering violation of itself, but more importantly, if the kernel does a get_user_pages() on hugepages (which can happen from KVM amongst others), then the free_huge_page() can be delayed until after the associated inode has already been freed.  If an unmount occurs at the wrong time, even the hugetlbfs superblock where the \"quota\" limits are stored may have been freed.  Andrew Barry proposed a patch to fix this by having hugepages, instead of storing a pointer to their address_space and reaching the superblock from there, had the hugepages store pointers directly to the superblock, bumping the reference count as appropriate to avoid it being freed. Andrew Morton rejected that version, however, on the grounds that it made the existing layering violation worse.  This is a reworked version of Andrew's patch, which removes the extra, and some of the existing, layering violation.  It works by introducing the concept of a hugepage \"subpool\" at the lower hugepage mm layer - that is a finite logical pool of hugepages to allocate from.  hugetlbfs now creates a subpool for each filesystem instance with a page limit set, and a pointer to the subpool gets added to each allocated hugepage, instead of the address_space pointer used now.  The subpool has its own lifetime and is only freed once all pages in it _and_ all other references to it (i.e. superblocks) are gone.  subpools are optional - a NULL subpool pointer is taken by the code to mean that no subpool limits are in effect.  Previous discussion of this bug found in:  \"Fix refcounting in hugetlbfs quota handling.\". See:  https://lkml.org/lkml/2011/8/11/28 or http://marc.info/?l=linux-mm&m=126928970510627&w=1  v2: Fixed a bug spotted by Hillf Danton, and removed the extra parameter to alloc_huge_page() - since it already takes the vma, it is not necessary.  Cc: Hugh Dickins <hughd@google.com> Cc: Mel Gorman <mgorman@suse.de> Cc: Minchan Kim <minchan.kim@gmail.com> Cc: Hillf Danton <dhillf@gmail.com> Cc: Paul Mackerras <paulus@samba.org>",
        "func_before": "void hugetlb_unreserve_pages(struct inode *inode, long offset, long freed)\n{\n\tstruct hstate *h = hstate_inode(inode);\n\tlong chg = region_truncate(&inode->i_mapping->private_list, offset);\n\n\tspin_lock(&inode->i_lock);\n\tinode->i_blocks -= (blocks_per_huge_page(h) * freed);\n\tspin_unlock(&inode->i_lock);\n\n\thugetlb_put_quota(inode->i_mapping, (chg - freed));\n\thugetlb_acct_memory(h, -(chg - freed));\n}",
        "func": "void hugetlb_unreserve_pages(struct inode *inode, long offset, long freed)\n{\n\tstruct hstate *h = hstate_inode(inode);\n\tlong chg = region_truncate(&inode->i_mapping->private_list, offset);\n\tstruct hugepage_subpool *spool = subpool_inode(inode);\n\n\tspin_lock(&inode->i_lock);\n\tinode->i_blocks -= (blocks_per_huge_page(h) * freed);\n\tspin_unlock(&inode->i_lock);\n\n\thugepage_subpool_put_pages(spool, (chg - freed));\n\thugetlb_acct_memory(h, -(chg - freed));\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,11 +2,12 @@\n {\n \tstruct hstate *h = hstate_inode(inode);\n \tlong chg = region_truncate(&inode->i_mapping->private_list, offset);\n+\tstruct hugepage_subpool *spool = subpool_inode(inode);\n \n \tspin_lock(&inode->i_lock);\n \tinode->i_blocks -= (blocks_per_huge_page(h) * freed);\n \tspin_unlock(&inode->i_lock);\n \n-\thugetlb_put_quota(inode->i_mapping, (chg - freed));\n+\thugepage_subpool_put_pages(spool, (chg - freed));\n \thugetlb_acct_memory(h, -(chg - freed));\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\thugetlb_put_quota(inode->i_mapping, (chg - freed));"
            ],
            "added_lines": [
                "\tstruct hugepage_subpool *spool = subpool_inode(inode);",
                "\thugepage_subpool_put_pages(spool, (chg - freed));"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-2133",
        "func_name": "torvalds/linux/hugetlbfs_put_super",
        "description": "Use-after-free vulnerability in the Linux kernel before 3.3.6, when huge pages are enabled, allows local users to cause a denial of service (system crash) or possibly gain privileges by interacting with a hugetlbfs filesystem, as demonstrated by a umount operation that triggers improper handling of quota data.",
        "git_url": "https://github.com/torvalds/linux/commit/90481622d75715bfcb68501280a917dbfe516029",
        "commit_title": "hugepages: fix use after free bug in \"quota\" handling",
        "commit_text": " hugetlbfs_{get,put}_quota() are badly named.  They don't interact with the general quota handling code, and they don't much resemble its behaviour. Rather than being about maintaining limits on on-disk block usage by particular users, they are instead about maintaining limits on in-memory page usage (including anonymous MAP_PRIVATE copied-on-write pages) associated with a particular hugetlbfs filesystem instance.  Worse, they work by having callbacks to the hugetlbfs filesystem code from the low-level page handling code, in particular from free_huge_page(). This is a layering violation of itself, but more importantly, if the kernel does a get_user_pages() on hugepages (which can happen from KVM amongst others), then the free_huge_page() can be delayed until after the associated inode has already been freed.  If an unmount occurs at the wrong time, even the hugetlbfs superblock where the \"quota\" limits are stored may have been freed.  Andrew Barry proposed a patch to fix this by having hugepages, instead of storing a pointer to their address_space and reaching the superblock from there, had the hugepages store pointers directly to the superblock, bumping the reference count as appropriate to avoid it being freed. Andrew Morton rejected that version, however, on the grounds that it made the existing layering violation worse.  This is a reworked version of Andrew's patch, which removes the extra, and some of the existing, layering violation.  It works by introducing the concept of a hugepage \"subpool\" at the lower hugepage mm layer - that is a finite logical pool of hugepages to allocate from.  hugetlbfs now creates a subpool for each filesystem instance with a page limit set, and a pointer to the subpool gets added to each allocated hugepage, instead of the address_space pointer used now.  The subpool has its own lifetime and is only freed once all pages in it _and_ all other references to it (i.e. superblocks) are gone.  subpools are optional - a NULL subpool pointer is taken by the code to mean that no subpool limits are in effect.  Previous discussion of this bug found in:  \"Fix refcounting in hugetlbfs quota handling.\". See:  https://lkml.org/lkml/2011/8/11/28 or http://marc.info/?l=linux-mm&m=126928970510627&w=1  v2: Fixed a bug spotted by Hillf Danton, and removed the extra parameter to alloc_huge_page() - since it already takes the vma, it is not necessary.  Cc: Hugh Dickins <hughd@google.com> Cc: Mel Gorman <mgorman@suse.de> Cc: Minchan Kim <minchan.kim@gmail.com> Cc: Hillf Danton <dhillf@gmail.com> Cc: Paul Mackerras <paulus@samba.org>",
        "func_before": "static void hugetlbfs_put_super(struct super_block *sb)\n{\n\tstruct hugetlbfs_sb_info *sbi = HUGETLBFS_SB(sb);\n\n\tif (sbi) {\n\t\tsb->s_fs_info = NULL;\n\t\tkfree(sbi);\n\t}\n}",
        "func": "static void hugetlbfs_put_super(struct super_block *sb)\n{\n\tstruct hugetlbfs_sb_info *sbi = HUGETLBFS_SB(sb);\n\n\tif (sbi) {\n\t\tsb->s_fs_info = NULL;\n\n\t\tif (sbi->spool)\n\t\t\thugepage_put_subpool(sbi->spool);\n\n\t\tkfree(sbi);\n\t}\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,6 +4,10 @@\n \n \tif (sbi) {\n \t\tsb->s_fs_info = NULL;\n+\n+\t\tif (sbi->spool)\n+\t\t\thugepage_put_subpool(sbi->spool);\n+\n \t\tkfree(sbi);\n \t}\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "\t\tif (sbi->spool)",
                "\t\t\thugepage_put_subpool(sbi->spool);",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2012-2133",
        "func_name": "torvalds/linux/hugetlbfs_statfs",
        "description": "Use-after-free vulnerability in the Linux kernel before 3.3.6, when huge pages are enabled, allows local users to cause a denial of service (system crash) or possibly gain privileges by interacting with a hugetlbfs filesystem, as demonstrated by a umount operation that triggers improper handling of quota data.",
        "git_url": "https://github.com/torvalds/linux/commit/90481622d75715bfcb68501280a917dbfe516029",
        "commit_title": "hugepages: fix use after free bug in \"quota\" handling",
        "commit_text": " hugetlbfs_{get,put}_quota() are badly named.  They don't interact with the general quota handling code, and they don't much resemble its behaviour. Rather than being about maintaining limits on on-disk block usage by particular users, they are instead about maintaining limits on in-memory page usage (including anonymous MAP_PRIVATE copied-on-write pages) associated with a particular hugetlbfs filesystem instance.  Worse, they work by having callbacks to the hugetlbfs filesystem code from the low-level page handling code, in particular from free_huge_page(). This is a layering violation of itself, but more importantly, if the kernel does a get_user_pages() on hugepages (which can happen from KVM amongst others), then the free_huge_page() can be delayed until after the associated inode has already been freed.  If an unmount occurs at the wrong time, even the hugetlbfs superblock where the \"quota\" limits are stored may have been freed.  Andrew Barry proposed a patch to fix this by having hugepages, instead of storing a pointer to their address_space and reaching the superblock from there, had the hugepages store pointers directly to the superblock, bumping the reference count as appropriate to avoid it being freed. Andrew Morton rejected that version, however, on the grounds that it made the existing layering violation worse.  This is a reworked version of Andrew's patch, which removes the extra, and some of the existing, layering violation.  It works by introducing the concept of a hugepage \"subpool\" at the lower hugepage mm layer - that is a finite logical pool of hugepages to allocate from.  hugetlbfs now creates a subpool for each filesystem instance with a page limit set, and a pointer to the subpool gets added to each allocated hugepage, instead of the address_space pointer used now.  The subpool has its own lifetime and is only freed once all pages in it _and_ all other references to it (i.e. superblocks) are gone.  subpools are optional - a NULL subpool pointer is taken by the code to mean that no subpool limits are in effect.  Previous discussion of this bug found in:  \"Fix refcounting in hugetlbfs quota handling.\". See:  https://lkml.org/lkml/2011/8/11/28 or http://marc.info/?l=linux-mm&m=126928970510627&w=1  v2: Fixed a bug spotted by Hillf Danton, and removed the extra parameter to alloc_huge_page() - since it already takes the vma, it is not necessary.  Cc: Hugh Dickins <hughd@google.com> Cc: Mel Gorman <mgorman@suse.de> Cc: Minchan Kim <minchan.kim@gmail.com> Cc: Hillf Danton <dhillf@gmail.com> Cc: Paul Mackerras <paulus@samba.org>",
        "func_before": "static int hugetlbfs_statfs(struct dentry *dentry, struct kstatfs *buf)\n{\n\tstruct hugetlbfs_sb_info *sbinfo = HUGETLBFS_SB(dentry->d_sb);\n\tstruct hstate *h = hstate_inode(dentry->d_inode);\n\n\tbuf->f_type = HUGETLBFS_MAGIC;\n\tbuf->f_bsize = huge_page_size(h);\n\tif (sbinfo) {\n\t\tspin_lock(&sbinfo->stat_lock);\n\t\t/* If no limits set, just report 0 for max/free/used\n\t\t * blocks, like simple_statfs() */\n\t\tif (sbinfo->max_blocks >= 0) {\n\t\t\tbuf->f_blocks = sbinfo->max_blocks;\n\t\t\tbuf->f_bavail = buf->f_bfree = sbinfo->free_blocks;\n\t\t\tbuf->f_files = sbinfo->max_inodes;\n\t\t\tbuf->f_ffree = sbinfo->free_inodes;\n\t\t}\n\t\tspin_unlock(&sbinfo->stat_lock);\n\t}\n\tbuf->f_namelen = NAME_MAX;\n\treturn 0;\n}",
        "func": "static int hugetlbfs_statfs(struct dentry *dentry, struct kstatfs *buf)\n{\n\tstruct hugetlbfs_sb_info *sbinfo = HUGETLBFS_SB(dentry->d_sb);\n\tstruct hstate *h = hstate_inode(dentry->d_inode);\n\n\tbuf->f_type = HUGETLBFS_MAGIC;\n\tbuf->f_bsize = huge_page_size(h);\n\tif (sbinfo) {\n\t\tspin_lock(&sbinfo->stat_lock);\n\t\t/* If no limits set, just report 0 for max/free/used\n\t\t * blocks, like simple_statfs() */\n\t\tif (sbinfo->spool) {\n\t\t\tlong free_pages;\n\n\t\t\tspin_lock(&sbinfo->spool->lock);\n\t\t\tbuf->f_blocks = sbinfo->spool->max_hpages;\n\t\t\tfree_pages = sbinfo->spool->max_hpages\n\t\t\t\t- sbinfo->spool->used_hpages;\n\t\t\tbuf->f_bavail = buf->f_bfree = free_pages;\n\t\t\tspin_unlock(&sbinfo->spool->lock);\n\t\t\tbuf->f_files = sbinfo->max_inodes;\n\t\t\tbuf->f_ffree = sbinfo->free_inodes;\n\t\t}\n\t\tspin_unlock(&sbinfo->stat_lock);\n\t}\n\tbuf->f_namelen = NAME_MAX;\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -9,9 +9,15 @@\n \t\tspin_lock(&sbinfo->stat_lock);\n \t\t/* If no limits set, just report 0 for max/free/used\n \t\t * blocks, like simple_statfs() */\n-\t\tif (sbinfo->max_blocks >= 0) {\n-\t\t\tbuf->f_blocks = sbinfo->max_blocks;\n-\t\t\tbuf->f_bavail = buf->f_bfree = sbinfo->free_blocks;\n+\t\tif (sbinfo->spool) {\n+\t\t\tlong free_pages;\n+\n+\t\t\tspin_lock(&sbinfo->spool->lock);\n+\t\t\tbuf->f_blocks = sbinfo->spool->max_hpages;\n+\t\t\tfree_pages = sbinfo->spool->max_hpages\n+\t\t\t\t- sbinfo->spool->used_hpages;\n+\t\t\tbuf->f_bavail = buf->f_bfree = free_pages;\n+\t\t\tspin_unlock(&sbinfo->spool->lock);\n \t\t\tbuf->f_files = sbinfo->max_inodes;\n \t\t\tbuf->f_ffree = sbinfo->free_inodes;\n \t\t}",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tif (sbinfo->max_blocks >= 0) {",
                "\t\t\tbuf->f_blocks = sbinfo->max_blocks;",
                "\t\t\tbuf->f_bavail = buf->f_bfree = sbinfo->free_blocks;"
            ],
            "added_lines": [
                "\t\tif (sbinfo->spool) {",
                "\t\t\tlong free_pages;",
                "",
                "\t\t\tspin_lock(&sbinfo->spool->lock);",
                "\t\t\tbuf->f_blocks = sbinfo->spool->max_hpages;",
                "\t\t\tfree_pages = sbinfo->spool->max_hpages",
                "\t\t\t\t- sbinfo->spool->used_hpages;",
                "\t\t\tbuf->f_bavail = buf->f_bfree = free_pages;",
                "\t\t\tspin_unlock(&sbinfo->spool->lock);"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-2133",
        "func_name": "torvalds/linux/hugetlbfs_fill_super",
        "description": "Use-after-free vulnerability in the Linux kernel before 3.3.6, when huge pages are enabled, allows local users to cause a denial of service (system crash) or possibly gain privileges by interacting with a hugetlbfs filesystem, as demonstrated by a umount operation that triggers improper handling of quota data.",
        "git_url": "https://github.com/torvalds/linux/commit/90481622d75715bfcb68501280a917dbfe516029",
        "commit_title": "hugepages: fix use after free bug in \"quota\" handling",
        "commit_text": " hugetlbfs_{get,put}_quota() are badly named.  They don't interact with the general quota handling code, and they don't much resemble its behaviour. Rather than being about maintaining limits on on-disk block usage by particular users, they are instead about maintaining limits on in-memory page usage (including anonymous MAP_PRIVATE copied-on-write pages) associated with a particular hugetlbfs filesystem instance.  Worse, they work by having callbacks to the hugetlbfs filesystem code from the low-level page handling code, in particular from free_huge_page(). This is a layering violation of itself, but more importantly, if the kernel does a get_user_pages() on hugepages (which can happen from KVM amongst others), then the free_huge_page() can be delayed until after the associated inode has already been freed.  If an unmount occurs at the wrong time, even the hugetlbfs superblock where the \"quota\" limits are stored may have been freed.  Andrew Barry proposed a patch to fix this by having hugepages, instead of storing a pointer to their address_space and reaching the superblock from there, had the hugepages store pointers directly to the superblock, bumping the reference count as appropriate to avoid it being freed. Andrew Morton rejected that version, however, on the grounds that it made the existing layering violation worse.  This is a reworked version of Andrew's patch, which removes the extra, and some of the existing, layering violation.  It works by introducing the concept of a hugepage \"subpool\" at the lower hugepage mm layer - that is a finite logical pool of hugepages to allocate from.  hugetlbfs now creates a subpool for each filesystem instance with a page limit set, and a pointer to the subpool gets added to each allocated hugepage, instead of the address_space pointer used now.  The subpool has its own lifetime and is only freed once all pages in it _and_ all other references to it (i.e. superblocks) are gone.  subpools are optional - a NULL subpool pointer is taken by the code to mean that no subpool limits are in effect.  Previous discussion of this bug found in:  \"Fix refcounting in hugetlbfs quota handling.\". See:  https://lkml.org/lkml/2011/8/11/28 or http://marc.info/?l=linux-mm&m=126928970510627&w=1  v2: Fixed a bug spotted by Hillf Danton, and removed the extra parameter to alloc_huge_page() - since it already takes the vma, it is not necessary.  Cc: Hugh Dickins <hughd@google.com> Cc: Mel Gorman <mgorman@suse.de> Cc: Minchan Kim <minchan.kim@gmail.com> Cc: Hillf Danton <dhillf@gmail.com> Cc: Paul Mackerras <paulus@samba.org>",
        "func_before": "static int\nhugetlbfs_fill_super(struct super_block *sb, void *data, int silent)\n{\n\tstruct inode * inode;\n\tstruct dentry * root;\n\tint ret;\n\tstruct hugetlbfs_config config;\n\tstruct hugetlbfs_sb_info *sbinfo;\n\n\tsave_mount_options(sb, data);\n\n\tconfig.nr_blocks = -1; /* No limit on size by default */\n\tconfig.nr_inodes = -1; /* No limit on number of inodes by default */\n\tconfig.uid = current_fsuid();\n\tconfig.gid = current_fsgid();\n\tconfig.mode = 0755;\n\tconfig.hstate = &default_hstate;\n\tret = hugetlbfs_parse_options(data, &config);\n\tif (ret)\n\t\treturn ret;\n\n\tsbinfo = kmalloc(sizeof(struct hugetlbfs_sb_info), GFP_KERNEL);\n\tif (!sbinfo)\n\t\treturn -ENOMEM;\n\tsb->s_fs_info = sbinfo;\n\tsbinfo->hstate = config.hstate;\n\tspin_lock_init(&sbinfo->stat_lock);\n\tsbinfo->max_blocks = config.nr_blocks;\n\tsbinfo->free_blocks = config.nr_blocks;\n\tsbinfo->max_inodes = config.nr_inodes;\n\tsbinfo->free_inodes = config.nr_inodes;\n\tsb->s_maxbytes = MAX_LFS_FILESIZE;\n\tsb->s_blocksize = huge_page_size(config.hstate);\n\tsb->s_blocksize_bits = huge_page_shift(config.hstate);\n\tsb->s_magic = HUGETLBFS_MAGIC;\n\tsb->s_op = &hugetlbfs_ops;\n\tsb->s_time_gran = 1;\n\tinode = hugetlbfs_get_root(sb, &config);\n\tif (!inode)\n\t\tgoto out_free;\n\n\troot = d_alloc_root(inode);\n\tif (!root) {\n\t\tiput(inode);\n\t\tgoto out_free;\n\t}\n\tsb->s_root = root;\n\treturn 0;\nout_free:\n\tkfree(sbinfo);\n\treturn -ENOMEM;\n}",
        "func": "static int\nhugetlbfs_fill_super(struct super_block *sb, void *data, int silent)\n{\n\tstruct inode * inode;\n\tstruct dentry * root;\n\tint ret;\n\tstruct hugetlbfs_config config;\n\tstruct hugetlbfs_sb_info *sbinfo;\n\n\tsave_mount_options(sb, data);\n\n\tconfig.nr_blocks = -1; /* No limit on size by default */\n\tconfig.nr_inodes = -1; /* No limit on number of inodes by default */\n\tconfig.uid = current_fsuid();\n\tconfig.gid = current_fsgid();\n\tconfig.mode = 0755;\n\tconfig.hstate = &default_hstate;\n\tret = hugetlbfs_parse_options(data, &config);\n\tif (ret)\n\t\treturn ret;\n\n\tsbinfo = kmalloc(sizeof(struct hugetlbfs_sb_info), GFP_KERNEL);\n\tif (!sbinfo)\n\t\treturn -ENOMEM;\n\tsb->s_fs_info = sbinfo;\n\tsbinfo->hstate = config.hstate;\n\tspin_lock_init(&sbinfo->stat_lock);\n\tsbinfo->max_inodes = config.nr_inodes;\n\tsbinfo->free_inodes = config.nr_inodes;\n\tsbinfo->spool = NULL;\n\tif (config.nr_blocks != -1) {\n\t\tsbinfo->spool = hugepage_new_subpool(config.nr_blocks);\n\t\tif (!sbinfo->spool)\n\t\t\tgoto out_free;\n\t}\n\tsb->s_maxbytes = MAX_LFS_FILESIZE;\n\tsb->s_blocksize = huge_page_size(config.hstate);\n\tsb->s_blocksize_bits = huge_page_shift(config.hstate);\n\tsb->s_magic = HUGETLBFS_MAGIC;\n\tsb->s_op = &hugetlbfs_ops;\n\tsb->s_time_gran = 1;\n\tinode = hugetlbfs_get_root(sb, &config);\n\tif (!inode)\n\t\tgoto out_free;\n\n\troot = d_alloc_root(inode);\n\tif (!root) {\n\t\tiput(inode);\n\t\tgoto out_free;\n\t}\n\tsb->s_root = root;\n\treturn 0;\nout_free:\n\tif (sbinfo->spool)\n\t\tkfree(sbinfo->spool);\n\tkfree(sbinfo);\n\treturn -ENOMEM;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -25,10 +25,14 @@\n \tsb->s_fs_info = sbinfo;\n \tsbinfo->hstate = config.hstate;\n \tspin_lock_init(&sbinfo->stat_lock);\n-\tsbinfo->max_blocks = config.nr_blocks;\n-\tsbinfo->free_blocks = config.nr_blocks;\n \tsbinfo->max_inodes = config.nr_inodes;\n \tsbinfo->free_inodes = config.nr_inodes;\n+\tsbinfo->spool = NULL;\n+\tif (config.nr_blocks != -1) {\n+\t\tsbinfo->spool = hugepage_new_subpool(config.nr_blocks);\n+\t\tif (!sbinfo->spool)\n+\t\t\tgoto out_free;\n+\t}\n \tsb->s_maxbytes = MAX_LFS_FILESIZE;\n \tsb->s_blocksize = huge_page_size(config.hstate);\n \tsb->s_blocksize_bits = huge_page_shift(config.hstate);\n@@ -47,6 +51,8 @@\n \tsb->s_root = root;\n \treturn 0;\n out_free:\n+\tif (sbinfo->spool)\n+\t\tkfree(sbinfo->spool);\n \tkfree(sbinfo);\n \treturn -ENOMEM;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tsbinfo->max_blocks = config.nr_blocks;",
                "\tsbinfo->free_blocks = config.nr_blocks;"
            ],
            "added_lines": [
                "\tsbinfo->spool = NULL;",
                "\tif (config.nr_blocks != -1) {",
                "\t\tsbinfo->spool = hugepage_new_subpool(config.nr_blocks);",
                "\t\tif (!sbinfo->spool)",
                "\t\t\tgoto out_free;",
                "\t}",
                "\tif (sbinfo->spool)",
                "\t\tkfree(sbinfo->spool);"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-0858",
        "func_name": "ffmpeg/shorten_decode_close",
        "description": "The Shorten codec (shorten.c) in libavcodec in FFmpeg 0.7.x before 0.7.12 and 0.8.x before 0.8.11, and in Libav 0.5.x before 0.5.9, 0.6.x before 0.6.6, 0.7.x before 0.7.5, and 0.8.x before 0.8.1, allows remote attackers to cause a denial of service (application crash) and possibly execute arbitrary code via a crafted Shorten file, related to an \"invalid free\".",
        "git_url": "http://git.videolan.org/?p=ffmpeg.git;a=commit;h=204cb29b3c84a74cbcd059d353c70c8bdc567d98",
        "commit_title": "",
        "commit_text": "shorten: Use separate pointers for the allocated memory for decoded samples.  Fixes invalid free() if any of the buffers are not allocated due to either not decoding a header or an error prior to allocating all buffers.  Fixes CVE-2012-0858 ",
        "func_before": "static av_cold int shorten_decode_close(AVCodecContext *avctx)\n{\n    ShortenContext *s = avctx->priv_data;\n    int i;\n\n    for (i = 0; i < s->channels; i++) {\n        s->decoded[i] -= s->nwrap;\n        av_freep(&s->decoded[i]);\n        av_freep(&s->offset[i]);\n    }\n    av_freep(&s->bitstream);\n    av_freep(&s->coeffs);\n\n    return 0;\n}",
        "func": "static av_cold int shorten_decode_close(AVCodecContext *avctx)\n{\n    ShortenContext *s = avctx->priv_data;\n    int i;\n\n    for (i = 0; i < s->channels; i++) {\n        s->decoded[i] = NULL;\n        av_freep(&s->decoded_base[i]);\n        av_freep(&s->offset[i]);\n    }\n    av_freep(&s->bitstream);\n    av_freep(&s->coeffs);\n\n    return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,8 +4,8 @@\n     int i;\n \n     for (i = 0; i < s->channels; i++) {\n-        s->decoded[i] -= s->nwrap;\n-        av_freep(&s->decoded[i]);\n+        s->decoded[i] = NULL;\n+        av_freep(&s->decoded_base[i]);\n         av_freep(&s->offset[i]);\n     }\n     av_freep(&s->bitstream);",
        "diff_line_info": {
            "deleted_lines": [
                "        s->decoded[i] -= s->nwrap;",
                "        av_freep(&s->decoded[i]);"
            ],
            "added_lines": [
                "        s->decoded[i] = NULL;",
                "        av_freep(&s->decoded_base[i]);"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-0858",
        "func_name": "ffmpeg/allocate_buffers",
        "description": "The Shorten codec (shorten.c) in libavcodec in FFmpeg 0.7.x before 0.7.12 and 0.8.x before 0.8.11, and in Libav 0.5.x before 0.5.9, 0.6.x before 0.6.6, 0.7.x before 0.7.5, and 0.8.x before 0.8.1, allows remote attackers to cause a denial of service (application crash) and possibly execute arbitrary code via a crafted Shorten file, related to an \"invalid free\".",
        "git_url": "http://git.videolan.org/?p=ffmpeg.git;a=commit;h=204cb29b3c84a74cbcd059d353c70c8bdc567d98",
        "commit_title": "",
        "commit_text": "shorten: Use separate pointers for the allocated memory for decoded samples.  Fixes invalid free() if any of the buffers are not allocated due to either not decoding a header or an error prior to allocating all buffers.  Fixes CVE-2012-0858 ",
        "func_before": "static int allocate_buffers(ShortenContext *s)\n{\n    int i, chan;\n    int *coeffs;\n    void *tmp_ptr;\n\n    for (chan=0; chan<s->channels; chan++) {\n        if(FFMAX(1, s->nmean) >= UINT_MAX/sizeof(int32_t)){\n            av_log(s->avctx, AV_LOG_ERROR, \"nmean too large\\n\");\n            return -1;\n        }\n        if(s->blocksize + s->nwrap >= UINT_MAX/sizeof(int32_t) || s->blocksize + s->nwrap <= (unsigned)s->nwrap){\n            av_log(s->avctx, AV_LOG_ERROR, \"s->blocksize + s->nwrap too large\\n\");\n            return -1;\n        }\n\n        tmp_ptr = av_realloc(s->offset[chan], sizeof(int32_t)*FFMAX(1, s->nmean));\n        if (!tmp_ptr)\n            return AVERROR(ENOMEM);\n        s->offset[chan] = tmp_ptr;\n\n        tmp_ptr = av_realloc(s->decoded[chan], sizeof(int32_t)*(s->blocksize + s->nwrap));\n        if (!tmp_ptr)\n            return AVERROR(ENOMEM);\n        s->decoded[chan] = tmp_ptr;\n        for (i=0; i<s->nwrap; i++)\n            s->decoded[chan][i] = 0;\n        s->decoded[chan] += s->nwrap;\n    }\n\n    coeffs = av_realloc(s->coeffs, s->nwrap * sizeof(*s->coeffs));\n    if (!coeffs)\n        return AVERROR(ENOMEM);\n    s->coeffs = coeffs;\n\n    return 0;\n}",
        "func": "static int allocate_buffers(ShortenContext *s)\n{\n    int i, chan;\n    int *coeffs;\n    void *tmp_ptr;\n\n    for (chan=0; chan<s->channels; chan++) {\n        if(FFMAX(1, s->nmean) >= UINT_MAX/sizeof(int32_t)){\n            av_log(s->avctx, AV_LOG_ERROR, \"nmean too large\\n\");\n            return -1;\n        }\n        if(s->blocksize + s->nwrap >= UINT_MAX/sizeof(int32_t) || s->blocksize + s->nwrap <= (unsigned)s->nwrap){\n            av_log(s->avctx, AV_LOG_ERROR, \"s->blocksize + s->nwrap too large\\n\");\n            return -1;\n        }\n\n        tmp_ptr = av_realloc(s->offset[chan], sizeof(int32_t)*FFMAX(1, s->nmean));\n        if (!tmp_ptr)\n            return AVERROR(ENOMEM);\n        s->offset[chan] = tmp_ptr;\n\n        tmp_ptr = av_realloc(s->decoded_base[chan], (s->blocksize + s->nwrap) *\n                             sizeof(s->decoded_base[0][0]));\n        if (!tmp_ptr)\n            return AVERROR(ENOMEM);\n        s->decoded_base[chan] = tmp_ptr;\n        for (i=0; i<s->nwrap; i++)\n            s->decoded_base[chan][i] = 0;\n        s->decoded[chan] = s->decoded_base[chan] + s->nwrap;\n    }\n\n    coeffs = av_realloc(s->coeffs, s->nwrap * sizeof(*s->coeffs));\n    if (!coeffs)\n        return AVERROR(ENOMEM);\n    s->coeffs = coeffs;\n\n    return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -19,13 +19,14 @@\n             return AVERROR(ENOMEM);\n         s->offset[chan] = tmp_ptr;\n \n-        tmp_ptr = av_realloc(s->decoded[chan], sizeof(int32_t)*(s->blocksize + s->nwrap));\n+        tmp_ptr = av_realloc(s->decoded_base[chan], (s->blocksize + s->nwrap) *\n+                             sizeof(s->decoded_base[0][0]));\n         if (!tmp_ptr)\n             return AVERROR(ENOMEM);\n-        s->decoded[chan] = tmp_ptr;\n+        s->decoded_base[chan] = tmp_ptr;\n         for (i=0; i<s->nwrap; i++)\n-            s->decoded[chan][i] = 0;\n-        s->decoded[chan] += s->nwrap;\n+            s->decoded_base[chan][i] = 0;\n+        s->decoded[chan] = s->decoded_base[chan] + s->nwrap;\n     }\n \n     coeffs = av_realloc(s->coeffs, s->nwrap * sizeof(*s->coeffs));",
        "diff_line_info": {
            "deleted_lines": [
                "        tmp_ptr = av_realloc(s->decoded[chan], sizeof(int32_t)*(s->blocksize + s->nwrap));",
                "        s->decoded[chan] = tmp_ptr;",
                "            s->decoded[chan][i] = 0;",
                "        s->decoded[chan] += s->nwrap;"
            ],
            "added_lines": [
                "        tmp_ptr = av_realloc(s->decoded_base[chan], (s->blocksize + s->nwrap) *",
                "                             sizeof(s->decoded_base[0][0]));",
                "        s->decoded_base[chan] = tmp_ptr;",
                "            s->decoded_base[chan][i] = 0;",
                "        s->decoded[chan] = s->decoded_base[chan] + s->nwrap;"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-2870",
        "func_name": "chromium/xsltGenerateIdFunction",
        "description": "libxslt 1.1.26 and earlier, as used in Google Chrome before 21.0.1180.89, does not properly manage memory, which might allow remote attackers to cause a denial of service (application crash) via a crafted XSLT expression that is not properly identified during XPath navigation, related to (1) the xsltCompileLocationPathPattern function in libxslt/pattern.c and (2) the xsltGenerateIdFunction function in libxslt/functions.c.",
        "git_url": "https://github.com/chromium/chromium/commit/e741149a6b7872a2bf1f2b6cc0a56e836592fb77",
        "commit_title": "Fix harmless memory error in generate-id.",
        "commit_text": " ",
        "func_before": "void\nxsltGenerateIdFunction(xmlXPathParserContextPtr ctxt, int nargs){\n    xmlNodePtr cur = NULL;\n    long val;\n    xmlChar str[30];\n    xmlDocPtr doc;\n\n    if (nargs == 0) {\n\tcur = ctxt->context->node;\n    } else if (nargs == 1) {\n\txmlXPathObjectPtr obj;\n\txmlNodeSetPtr nodelist;\n\tint i, ret;\n\n\tif ((ctxt->value == NULL) || (ctxt->value->type != XPATH_NODESET)) {\n\t    ctxt->error = XPATH_INVALID_TYPE;\n\t    xsltTransformError(xsltXPathGetTransformContext(ctxt), NULL, NULL,\n\t\t\"generate-id() : invalid arg expecting a node-set\\n\");\n\t    return;\n\t}\n\tobj = valuePop(ctxt);\n\tnodelist = obj->nodesetval;\n\tif ((nodelist == NULL) || (nodelist->nodeNr <= 0)) {\n\t    xmlXPathFreeObject(obj);\n\t    valuePush(ctxt, xmlXPathNewCString(\"\"));\n\t    return;\n\t}\n\tcur = nodelist->nodeTab[0];\n\tfor (i = 1;i < nodelist->nodeNr;i++) {\n\t    ret = xmlXPathCmpNodes(cur, nodelist->nodeTab[i]);\n\t    if (ret == -1)\n\t        cur = nodelist->nodeTab[i];\n\t}\n\txmlXPathFreeObject(obj);\n    } else {\n\txsltTransformError(xsltXPathGetTransformContext(ctxt), NULL, NULL,\n\t\t\"generate-id() : invalid number of args %d\\n\", nargs);\n\tctxt->error = XPATH_INVALID_ARITY;\n\treturn;\n    }\n    /*\n     * Okay this is ugly but should work, use the NodePtr address\n     * to forge the ID\n     */\n    if (cur->type != XML_NAMESPACE_DECL)\n        doc = cur->doc;\n    else {\n        xmlNsPtr ns = (xmlNsPtr) cur;\n\n        if (ns->context != NULL)\n            doc = ns->context;\n        else\n            doc = ctxt->context->doc;\n\n    }\n\n    val = (long)((char *)cur - (char *)doc);\n    if (val >= 0) {\n      sprintf((char *)str, \"idp%ld\", val);\n    } else {\n      sprintf((char *)str, \"idm%ld\", -val);\n    }\n    valuePush(ctxt, xmlXPathNewString(str));\n}",
        "func": "void\nxsltGenerateIdFunction(xmlXPathParserContextPtr ctxt, int nargs){\n    xmlNodePtr cur = NULL;\n    xmlXPathObjectPtr obj = NULL;\n    long val;\n    xmlChar str[30];\n    xmlDocPtr doc;\n\n    if (nargs == 0) {\n\tcur = ctxt->context->node;\n    } else if (nargs == 1) {\n\txmlNodeSetPtr nodelist;\n\tint i, ret;\n\n\tif ((ctxt->value == NULL) || (ctxt->value->type != XPATH_NODESET)) {\n\t    ctxt->error = XPATH_INVALID_TYPE;\n\t    xsltTransformError(xsltXPathGetTransformContext(ctxt), NULL, NULL,\n\t\t\"generate-id() : invalid arg expecting a node-set\\n\");\n\t    return;\n\t}\n\tobj = valuePop(ctxt);\n\tnodelist = obj->nodesetval;\n\tif ((nodelist == NULL) || (nodelist->nodeNr <= 0)) {\n\t    xmlXPathFreeObject(obj);\n\t    valuePush(ctxt, xmlXPathNewCString(\"\"));\n\t    return;\n\t}\n\tcur = nodelist->nodeTab[0];\n\tfor (i = 1;i < nodelist->nodeNr;i++) {\n\t    ret = xmlXPathCmpNodes(cur, nodelist->nodeTab[i]);\n\t    if (ret == -1)\n\t        cur = nodelist->nodeTab[i];\n\t}\n    } else {\n\txsltTransformError(xsltXPathGetTransformContext(ctxt), NULL, NULL,\n\t\t\"generate-id() : invalid number of args %d\\n\", nargs);\n\tctxt->error = XPATH_INVALID_ARITY;\n\treturn;\n    }\n    /*\n     * Okay this is ugly but should work, use the NodePtr address\n     * to forge the ID\n     */\n    if (cur->type != XML_NAMESPACE_DECL)\n        doc = cur->doc;\n    else {\n        xmlNsPtr ns = (xmlNsPtr) cur;\n\n        if (ns->context != NULL)\n            doc = ns->context;\n        else\n            doc = ctxt->context->doc;\n\n    }\n\n    if (obj)\n        xmlXPathFreeObject(obj);\n\n    val = (long)((char *)cur - (char *)doc);\n    if (val >= 0) {\n      sprintf((char *)str, \"idp%ld\", val);\n    } else {\n      sprintf((char *)str, \"idm%ld\", -val);\n    }\n    valuePush(ctxt, xmlXPathNewString(str));\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,7 @@\n void\n xsltGenerateIdFunction(xmlXPathParserContextPtr ctxt, int nargs){\n     xmlNodePtr cur = NULL;\n+    xmlXPathObjectPtr obj = NULL;\n     long val;\n     xmlChar str[30];\n     xmlDocPtr doc;\n@@ -8,7 +9,6 @@\n     if (nargs == 0) {\n \tcur = ctxt->context->node;\n     } else if (nargs == 1) {\n-\txmlXPathObjectPtr obj;\n \txmlNodeSetPtr nodelist;\n \tint i, ret;\n \n@@ -31,7 +31,6 @@\n \t    if (ret == -1)\n \t        cur = nodelist->nodeTab[i];\n \t}\n-\txmlXPathFreeObject(obj);\n     } else {\n \txsltTransformError(xsltXPathGetTransformContext(ctxt), NULL, NULL,\n \t\t\"generate-id() : invalid number of args %d\\n\", nargs);\n@@ -54,6 +53,9 @@\n \n     }\n \n+    if (obj)\n+        xmlXPathFreeObject(obj);\n+\n     val = (long)((char *)cur - (char *)doc);\n     if (val >= 0) {\n       sprintf((char *)str, \"idp%ld\", val);",
        "diff_line_info": {
            "deleted_lines": [
                "\txmlXPathObjectPtr obj;",
                "\txmlXPathFreeObject(obj);"
            ],
            "added_lines": [
                "    xmlXPathObjectPtr obj = NULL;",
                "    if (obj)",
                "        xmlXPathFreeObject(obj);",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2012-2870",
        "func_name": "chromium/xsltCompileLocationPathPattern",
        "description": "libxslt 1.1.26 and earlier, as used in Google Chrome before 21.0.1180.89, does not properly manage memory, which might allow remote attackers to cause a denial of service (application crash) via a crafted XSLT expression that is not properly identified during XPath navigation, related to (1) the xsltCompileLocationPathPattern function in libxslt/pattern.c and (2) the xsltGenerateIdFunction function in libxslt/functions.c.",
        "git_url": "https://github.com/chromium/chromium/commit/9939d35f9827ed0929646607cbdb071af627ac38",
        "commit_title": "Handle a bad XSLT expression better.",
        "commit_text": " ",
        "func_before": "static void\nxsltCompileLocationPathPattern(xsltParserContextPtr ctxt, int novar) {\n    SKIP_BLANKS;\n    if ((CUR == '/') && (NXT(1) == '/')) {\n\t/*\n\t * since we reverse the query\n\t * a leading // can be safely ignored\n\t */\n\tNEXT;\n\tNEXT;\n\tctxt->comp->priority = 0.5;\t/* '//' means not 0 priority */\n\txsltCompileRelativePathPattern(ctxt, NULL, novar);\n    } else if (CUR == '/') {\n\t/*\n\t * We need to find root as the parent\n\t */\n\tNEXT;\n\tSKIP_BLANKS;\n\tPUSH(XSLT_OP_ROOT, NULL, NULL, novar);\n\tif ((CUR != 0) && (CUR != '|')) {\n\t    PUSH(XSLT_OP_PARENT, NULL, NULL, novar);\n\t    xsltCompileRelativePathPattern(ctxt, NULL, novar);\n\t}\n    } else if (CUR == '*') {\n\txsltCompileRelativePathPattern(ctxt, NULL, novar);\n    } else if (CUR == '@') {\n\txsltCompileRelativePathPattern(ctxt, NULL, novar);\n    } else {\n\txmlChar *name;\n\tname = xsltScanNCName(ctxt);\n\tif (name == NULL) {\n\t    xsltTransformError(NULL, NULL, NULL,\n\t\t    \"xsltCompileLocationPathPattern : Name expected\\n\");\n\t    ctxt->error = 1;\n\t    return;\n\t}\n\tSKIP_BLANKS;\n\tif ((CUR == '(') && !xmlXPathIsNodeType(name)) {\n\t    xsltCompileIdKeyPattern(ctxt, name, 1, novar, 0);\n\t    if ((CUR == '/') && (NXT(1) == '/')) {\n\t\tPUSH(XSLT_OP_ANCESTOR, NULL, NULL, novar);\n\t\tNEXT;\n\t\tNEXT;\n\t\tSKIP_BLANKS;\n\t\txsltCompileRelativePathPattern(ctxt, NULL, novar);\n\t    } else if (CUR == '/') {\n\t\tPUSH(XSLT_OP_PARENT, NULL, NULL, novar);\n\t\tNEXT;\n\t\tSKIP_BLANKS;\n\t\txsltCompileRelativePathPattern(ctxt, NULL, novar);\n\t    }\n\t    return;\n\t}\n\txsltCompileRelativePathPattern(ctxt, name, novar);\n    }\nerror:\n    return;\n}",
        "func": "static void\nxsltCompileLocationPathPattern(xsltParserContextPtr ctxt, int novar) {\n    SKIP_BLANKS;\n    if ((CUR == '/') && (NXT(1) == '/')) {\n\t/*\n\t * since we reverse the query\n\t * a leading // can be safely ignored\n\t */\n\tNEXT;\n\tNEXT;\n\tctxt->comp->priority = 0.5;\t/* '//' means not 0 priority */\n\txsltCompileRelativePathPattern(ctxt, NULL, novar);\n    } else if (CUR == '/') {\n\t/*\n\t * We need to find root as the parent\n\t */\n\tNEXT;\n\tSKIP_BLANKS;\n\tPUSH(XSLT_OP_ROOT, NULL, NULL, novar);\n\tif ((CUR != 0) && (CUR != '|')) {\n\t    PUSH(XSLT_OP_PARENT, NULL, NULL, novar);\n\t    xsltCompileRelativePathPattern(ctxt, NULL, novar);\n\t}\n    } else if (CUR == '*') {\n\txsltCompileRelativePathPattern(ctxt, NULL, novar);\n    } else if (CUR == '@') {\n\txsltCompileRelativePathPattern(ctxt, NULL, novar);\n    } else {\n\txmlChar *name;\n\tname = xsltScanNCName(ctxt);\n\tif (name == NULL) {\n\t    xsltTransformError(NULL, NULL, NULL,\n\t\t    \"xsltCompileLocationPathPattern : Name expected\\n\");\n\t    ctxt->error = 1;\n\t    return;\n\t}\n\tSKIP_BLANKS;\n\tif ((CUR == '(') && !xmlXPathIsNodeType(name)) {\n\t    xsltCompileIdKeyPattern(ctxt, name, 1, novar, 0);\n\t    if (ctxt->error)\n\t\treturn;\n\t    if ((CUR == '/') && (NXT(1) == '/')) {\n\t\tPUSH(XSLT_OP_ANCESTOR, NULL, NULL, novar);\n\t\tNEXT;\n\t\tNEXT;\n\t\tSKIP_BLANKS;\n\t\txsltCompileRelativePathPattern(ctxt, NULL, novar);\n\t    } else if (CUR == '/') {\n\t\tPUSH(XSLT_OP_PARENT, NULL, NULL, novar);\n\t\tNEXT;\n\t\tSKIP_BLANKS;\n\t\txsltCompileRelativePathPattern(ctxt, NULL, novar);\n\t    }\n\t    return;\n\t}\n\txsltCompileRelativePathPattern(ctxt, name, novar);\n    }\nerror:\n    return;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -37,6 +37,8 @@\n \tSKIP_BLANKS;\n \tif ((CUR == '(') && !xmlXPathIsNodeType(name)) {\n \t    xsltCompileIdKeyPattern(ctxt, name, 1, novar, 0);\n+\t    if (ctxt->error)\n+\t\treturn;\n \t    if ((CUR == '/') && (NXT(1) == '/')) {\n \t\tPUSH(XSLT_OP_ANCESTOR, NULL, NULL, novar);\n \t\tNEXT;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t    if (ctxt->error)",
                "\t\treturn;"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-2803",
        "func_name": "ffmpeg/mpeg_decode_frame",
        "description": "Double free vulnerability in the mpeg_decode_frame function in libavcodec/mpeg12.c in FFmpeg before 0.11, and Libav 0.7.x before 0.7.7 and 0.8.x before 0.8.5, has unknown impact and attack vectors, related to resetting the data size value.",
        "git_url": "http://git.videolan.org/?p=ffmpeg.git;a=commit;h=951cbea56fdc03ef96d07fbd7e5bed755d42ac8a",
        "commit_title": "",
        "commit_text": "mpeg12dec: reset data size after parsing extradata.  This ended up corrupting data structures and may possibly lead to a double free.  ",
        "func_before": "static int mpeg_decode_frame(AVCodecContext *avctx,\n                             void *data, int *data_size,\n                             AVPacket *avpkt)\n{\n    const uint8_t *buf = avpkt->data;\n    int buf_size = avpkt->size;\n    Mpeg1Context *s = avctx->priv_data;\n    AVFrame *picture = data;\n    MpegEncContext *s2 = &s->mpeg_enc_ctx;\n    av_dlog(avctx, \"fill_buffer\\n\");\n\n    if (buf_size == 0 || (buf_size == 4 && AV_RB32(buf) == SEQ_END_CODE)) {\n        /* special case for last picture */\n        if (s2->low_delay == 0 && s2->next_picture_ptr) {\n            *picture = s2->next_picture_ptr->f;\n            s2->next_picture_ptr = NULL;\n\n            *data_size = sizeof(AVFrame);\n        }\n        return buf_size;\n    }\n\n    if (s2->flags & CODEC_FLAG_TRUNCATED) {\n        int next = ff_mpeg1_find_frame_end(&s2->parse_context, buf, buf_size, NULL);\n\n        if (ff_combine_frame(&s2->parse_context, next, (const uint8_t **)&buf, &buf_size) < 0)\n            return buf_size;\n    }\n\n    s2->codec_tag = avpriv_toupper4(avctx->codec_tag);\n    if (s->mpeg_enc_ctx_allocated == 0 && (   s2->codec_tag == AV_RL32(\"VCR2\")\n                                           || s2->codec_tag == AV_RL32(\"BW10\")\n                                          ))\n        vcr2_init_sequence(avctx);\n\n    s->slice_count = 0;\n\n    if (avctx->extradata && !avctx->frame_number) {\n        int ret = decode_chunks(avctx, picture, data_size, avctx->extradata, avctx->extradata_size);\n        if (ret < 0 && (avctx->err_recognition & AV_EF_EXPLODE))\n            return ret;\n    }\n\n    return decode_chunks(avctx, picture, data_size, buf, buf_size);\n}",
        "func": "static int mpeg_decode_frame(AVCodecContext *avctx,\n                             void *data, int *data_size,\n                             AVPacket *avpkt)\n{\n    const uint8_t *buf = avpkt->data;\n    int buf_size = avpkt->size;\n    Mpeg1Context *s = avctx->priv_data;\n    AVFrame *picture = data;\n    MpegEncContext *s2 = &s->mpeg_enc_ctx;\n    av_dlog(avctx, \"fill_buffer\\n\");\n\n    if (buf_size == 0 || (buf_size == 4 && AV_RB32(buf) == SEQ_END_CODE)) {\n        /* special case for last picture */\n        if (s2->low_delay == 0 && s2->next_picture_ptr) {\n            *picture = s2->next_picture_ptr->f;\n            s2->next_picture_ptr = NULL;\n\n            *data_size = sizeof(AVFrame);\n        }\n        return buf_size;\n    }\n\n    if (s2->flags & CODEC_FLAG_TRUNCATED) {\n        int next = ff_mpeg1_find_frame_end(&s2->parse_context, buf, buf_size, NULL);\n\n        if (ff_combine_frame(&s2->parse_context, next, (const uint8_t **)&buf, &buf_size) < 0)\n            return buf_size;\n    }\n\n    s2->codec_tag = avpriv_toupper4(avctx->codec_tag);\n    if (s->mpeg_enc_ctx_allocated == 0 && (   s2->codec_tag == AV_RL32(\"VCR2\")\n                                           || s2->codec_tag == AV_RL32(\"BW10\")\n                                          ))\n        vcr2_init_sequence(avctx);\n\n    s->slice_count = 0;\n\n    if (avctx->extradata && !avctx->frame_number) {\n        int ret = decode_chunks(avctx, picture, data_size, avctx->extradata, avctx->extradata_size);\n        *data_size = 0;\n        if (ret < 0 && (avctx->err_recognition & AV_EF_EXPLODE))\n            return ret;\n    }\n\n    return decode_chunks(avctx, picture, data_size, buf, buf_size);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -37,6 +37,7 @@\n \n     if (avctx->extradata && !avctx->frame_number) {\n         int ret = decode_chunks(avctx, picture, data_size, avctx->extradata, avctx->extradata_size);\n+        *data_size = 0;\n         if (ret < 0 && (avctx->err_recognition & AV_EF_EXPLODE))\n             return ret;\n     }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "        *data_size = 0;"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-2893",
        "func_name": "chromium/xsltAttrTemplateProcess",
        "description": "Double free vulnerability in libxslt, as used in Google Chrome before 22.0.1229.79, allows remote attackers to cause a denial of service or possibly have unspecified other impact via vectors related to XSL transforms.",
        "git_url": "https://github.com/chromium/chromium/commit/2de493f4a1d48952e09230a0c32ccbd45db973b2",
        "commit_title": "Fix dictionary string usage.",
        "commit_text": " ",
        "func_before": "xmlAttrPtr\nxsltAttrTemplateProcess(xsltTransformContextPtr ctxt, xmlNodePtr target,\n\t                xmlAttrPtr attr)\n{\n    const xmlChar *value;\n    xmlAttrPtr ret;\n\n    if ((ctxt == NULL) || (attr == NULL) || (target == NULL))\n\treturn(NULL);\n    \n    if (attr->type != XML_ATTRIBUTE_NODE)\n\treturn(NULL);\n\n    /*\n    * Skip all XSLT attributes.\n    */\n#ifdef XSLT_REFACTORED    \n    if (attr->psvi == xsltXSLTAttrMarker)\n\treturn(NULL);\n#else\n    if ((attr->ns != NULL) && xmlStrEqual(attr->ns->href, XSLT_NAMESPACE))\n\treturn(NULL);\n#endif\n    /*\n    * Get the value.\n    */\n    if (attr->children != NULL) {\n\tif ((attr->children->type != XML_TEXT_NODE) ||\n\t    (attr->children->next != NULL))\n\t{\n\t    xsltTransformError(ctxt, NULL, attr->parent,\n\t\t\"Internal error: The children of an attribute node of a \"\n\t\t\"literal result element are not in the expected form.\\n\");\n\t    return(NULL);\n\t}\n\tvalue = attr->children->content;\n\tif (value == NULL)\n\t    value = xmlDictLookup(ctxt->dict, BAD_CAST \"\", 0);\n    } else\n\tvalue = xmlDictLookup(ctxt->dict, BAD_CAST \"\", 0);\n    /*\n    * Overwrite duplicates.\n    */\n    ret = target->properties;\n    while (ret != NULL) {\n        if (((attr->ns != NULL) == (ret->ns != NULL)) &&\n\t    xmlStrEqual(ret->name, attr->name) &&\n\t    ((attr->ns == NULL) || xmlStrEqual(ret->ns->href, attr->ns->href)))\n\t{\n\t    break;\n\t}\n        ret = ret->next;\n    }\n    if (ret != NULL) {\t\n        /* free the existing value */\n\txmlFreeNodeList(ret->children);\n\tret->children = ret->last = NULL;\n\t/*\n\t* Adjust ns-prefix if needed.\n\t*/\n\tif ((ret->ns != NULL) &&\n\t    (! xmlStrEqual(ret->ns->prefix, attr->ns->prefix)))\n\t{\n\t    ret->ns = xsltGetNamespace(ctxt, attr->parent, attr->ns, target);\n\t}\n    } else {\n        /* create a new attribute */\n\tif (attr->ns != NULL)\n\t    ret = xmlNewNsProp(target,\n\t\txsltGetNamespace(ctxt, attr->parent, attr->ns, target),\n\t\t    attr->name, NULL);\n\telse\n\t    ret = xmlNewNsProp(target, NULL, attr->name, NULL);\t\n    }\n    /*\n    * Set the value.\n    */\n    if (ret != NULL) {\n        xmlNodePtr text;\n\n        text = xmlNewText(NULL);\n\tif (text != NULL) {\n\t    ret->last = ret->children = text;\n\t    text->parent = (xmlNodePtr) ret;\n\t    text->doc = ret->doc;\n\n\t    if (attr->psvi != NULL) {\n\t\t/*\n\t\t* Evaluate the Attribute Value Template.\n\t\t*/\n\t\txmlChar *val;\n\t\tval = xsltEvalAVT(ctxt, attr->psvi, attr->parent);\n\t\tif (val == NULL) {\n\t\t    /*\n\t\t    * TODO: Damn, we need an easy mechanism to report\n\t\t    * qualified names!\n\t\t    */\n\t\t    if (attr->ns) {\n\t\t\txsltTransformError(ctxt, NULL, attr->parent,\n\t\t\t    \"Internal error: Failed to evaluate the AVT \"\n\t\t\t    \"of attribute '{%s}%s'.\\n\",\n\t\t\t    attr->ns->href, attr->name);\n\t\t    } else {\n\t\t\txsltTransformError(ctxt, NULL, attr->parent,\n\t\t\t    \"Internal error: Failed to evaluate the AVT \"\n\t\t\t    \"of attribute '%s'.\\n\",\n\t\t\t    attr->name);\n\t\t    }\n\t\t    text->content = xmlStrdup(BAD_CAST \"\");\n\t\t} else {\n\t\t    text->content = val;\n\t\t}\n\t    } else if ((ctxt->internalized) && (target != NULL) &&\n\t               (target->doc != NULL) &&\n\t\t       (target->doc->dict == ctxt->dict)) {\n\t\ttext->content = (xmlChar *) value;\n\t    } else {\n\t\ttext->content = xmlStrdup(value);\n\t    }\n\t}\n    } else {\n\tif (attr->ns) {\n\t    xsltTransformError(ctxt, NULL, attr->parent,\n\t    \t\"Internal error: Failed to create attribute '{%s}%s'.\\n\",\n\t\tattr->ns->href, attr->name);\n\t} else {\n\t    xsltTransformError(ctxt, NULL, attr->parent,\n\t    \t\"Internal error: Failed to create attribute '%s'.\\n\",\n\t\tattr->name);\n\t}\n    }\n    return(ret);\n}",
        "func": "xmlAttrPtr\nxsltAttrTemplateProcess(xsltTransformContextPtr ctxt, xmlNodePtr target,\n\t                xmlAttrPtr attr)\n{\n    const xmlChar *value;\n    xmlAttrPtr ret;\n\n    if ((ctxt == NULL) || (attr == NULL) || (target == NULL))\n\treturn(NULL);\n    \n    if (attr->type != XML_ATTRIBUTE_NODE)\n\treturn(NULL);\n\n    /*\n    * Skip all XSLT attributes.\n    */\n#ifdef XSLT_REFACTORED    \n    if (attr->psvi == xsltXSLTAttrMarker)\n\treturn(NULL);\n#else\n    if ((attr->ns != NULL) && xmlStrEqual(attr->ns->href, XSLT_NAMESPACE))\n\treturn(NULL);\n#endif\n    /*\n    * Get the value.\n    */\n    if (attr->children != NULL) {\n\tif ((attr->children->type != XML_TEXT_NODE) ||\n\t    (attr->children->next != NULL))\n\t{\n\t    xsltTransformError(ctxt, NULL, attr->parent,\n\t\t\"Internal error: The children of an attribute node of a \"\n\t\t\"literal result element are not in the expected form.\\n\");\n\t    return(NULL);\n\t}\n\tvalue = attr->children->content;\n\tif (value == NULL)\n\t    value = xmlDictLookup(ctxt->dict, BAD_CAST \"\", 0);\n    } else\n\tvalue = xmlDictLookup(ctxt->dict, BAD_CAST \"\", 0);\n    /*\n    * Overwrite duplicates.\n    */\n    ret = target->properties;\n    while (ret != NULL) {\n        if (((attr->ns != NULL) == (ret->ns != NULL)) &&\n\t    xmlStrEqual(ret->name, attr->name) &&\n\t    ((attr->ns == NULL) || xmlStrEqual(ret->ns->href, attr->ns->href)))\n\t{\n\t    break;\n\t}\n        ret = ret->next;\n    }\n    if (ret != NULL) {\t\n        /* free the existing value */\n\txmlFreeNodeList(ret->children);\n\tret->children = ret->last = NULL;\n\t/*\n\t* Adjust ns-prefix if needed.\n\t*/\n\tif ((ret->ns != NULL) &&\n\t    (! xmlStrEqual(ret->ns->prefix, attr->ns->prefix)))\n\t{\n\t    ret->ns = xsltGetNamespace(ctxt, attr->parent, attr->ns, target);\n\t}\n    } else {\n        /* create a new attribute */\n\tif (attr->ns != NULL)\n\t    ret = xmlNewNsProp(target,\n\t\txsltGetNamespace(ctxt, attr->parent, attr->ns, target),\n\t\t    attr->name, NULL);\n\telse\n\t    ret = xmlNewNsProp(target, NULL, attr->name, NULL);\t\n    }\n    /*\n    * Set the value.\n    */\n    if (ret != NULL) {\n        xmlNodePtr text;\n\n        text = xmlNewText(NULL);\n\tif (text != NULL) {\n\t    ret->last = ret->children = text;\n\t    text->parent = (xmlNodePtr) ret;\n\t    text->doc = ret->doc;\n\n\t    if (attr->psvi != NULL) {\n\t\t/*\n\t\t* Evaluate the Attribute Value Template.\n\t\t*/\n\t\txmlChar *val;\n\t\tval = xsltEvalAVT(ctxt, attr->psvi, attr->parent);\n\t\tif (val == NULL) {\n\t\t    /*\n\t\t    * TODO: Damn, we need an easy mechanism to report\n\t\t    * qualified names!\n\t\t    */\n\t\t    if (attr->ns) {\n\t\t\txsltTransformError(ctxt, NULL, attr->parent,\n\t\t\t    \"Internal error: Failed to evaluate the AVT \"\n\t\t\t    \"of attribute '{%s}%s'.\\n\",\n\t\t\t    attr->ns->href, attr->name);\n\t\t    } else {\n\t\t\txsltTransformError(ctxt, NULL, attr->parent,\n\t\t\t    \"Internal error: Failed to evaluate the AVT \"\n\t\t\t    \"of attribute '%s'.\\n\",\n\t\t\t    attr->name);\n\t\t    }\n\t\t    text->content = xmlStrdup(BAD_CAST \"\");\n\t\t} else {\n\t\t    text->content = val;\n\t\t}\n\t    } else if ((ctxt->internalized) && (target != NULL) &&\n\t               (target->doc != NULL) &&\n\t\t       (target->doc->dict == ctxt->dict) &&\n\t\t       xmlDictOwns(ctxt->dict, value)) {\n\t\ttext->content = (xmlChar *) value;\n\t    } else {\n\t\ttext->content = xmlStrdup(value);\n\t    }\n\t}\n    } else {\n\tif (attr->ns) {\n\t    xsltTransformError(ctxt, NULL, attr->parent,\n\t    \t\"Internal error: Failed to create attribute '{%s}%s'.\\n\",\n\t\tattr->ns->href, attr->name);\n\t} else {\n\t    xsltTransformError(ctxt, NULL, attr->parent,\n\t    \t\"Internal error: Failed to create attribute '%s'.\\n\",\n\t\tattr->name);\n\t}\n    }\n    return(ret);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -112,7 +112,8 @@\n \t\t}\n \t    } else if ((ctxt->internalized) && (target != NULL) &&\n \t               (target->doc != NULL) &&\n-\t\t       (target->doc->dict == ctxt->dict)) {\n+\t\t       (target->doc->dict == ctxt->dict) &&\n+\t\t       xmlDictOwns(ctxt->dict, value)) {\n \t\ttext->content = (xmlChar *) value;\n \t    } else {\n \t\ttext->content = xmlStrdup(value);",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t       (target->doc->dict == ctxt->dict)) {"
            ],
            "added_lines": [
                "\t\t       (target->doc->dict == ctxt->dict) &&",
                "\t\t       xmlDictOwns(ctxt->dict, value)) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-2893",
        "func_name": "chromium/xsltAttrListTemplateProcess",
        "description": "Double free vulnerability in libxslt, as used in Google Chrome before 22.0.1229.79, allows remote attackers to cause a denial of service or possibly have unspecified other impact via vectors related to XSL transforms.",
        "git_url": "https://github.com/chromium/chromium/commit/2de493f4a1d48952e09230a0c32ccbd45db973b2",
        "commit_title": "Fix dictionary string usage.",
        "commit_text": " ",
        "func_before": "xmlAttrPtr\nxsltAttrListTemplateProcess(xsltTransformContextPtr ctxt, \n\t                    xmlNodePtr target, xmlAttrPtr attrs)\n{\n    xmlAttrPtr attr, copy, last;\n    xmlNodePtr oldInsert, text;\n    xmlNsPtr origNs = NULL, copyNs = NULL;\n    const xmlChar *value;\n    xmlChar *valueAVT;\n\n    if ((ctxt == NULL) || (target == NULL) || (attrs == NULL))\n\treturn(NULL);\n\n    oldInsert = ctxt->insert;\n    ctxt->insert = target;        \n\n    /*\n    * Instantiate LRE-attributes.\n    */\n    if (target->properties) {\n\tlast = target->properties;\n\twhile (last->next != NULL)\n\t    last = last->next;\n    } else {\n\tlast = NULL;\n    }\n    attr = attrs;\n    do {\n\t/*\n\t* Skip XSLT attributes.\n\t*/\n#ifdef XSLT_REFACTORED\n\tif (attr->psvi == xsltXSLTAttrMarker) {\n\t    goto next_attribute;\n\t}\n#else\n\tif ((attr->ns != NULL) &&\n\t    xmlStrEqual(attr->ns->href, XSLT_NAMESPACE))\n\t{\n\t    goto next_attribute;\n\t}\n#endif\n\t/*\n\t* Get the value.\n\t*/\n\tif (attr->children != NULL) {\n\t    if ((attr->children->type != XML_TEXT_NODE) ||\n\t\t(attr->children->next != NULL))\n\t    {\n\t\txsltTransformError(ctxt, NULL, attr->parent,\n\t\t    \"Internal error: The children of an attribute node of a \"\n\t\t    \"literal result element are not in the expected form.\\n\");\n\t\tgoto error;\n\t    }\n\t    value = attr->children->content;\n\t    if (value == NULL)\n\t\tvalue = xmlDictLookup(ctxt->dict, BAD_CAST \"\", 0);\n\t} else\n\t    value = xmlDictLookup(ctxt->dict, BAD_CAST \"\", 0);\n\n\t/*\n\t* Create a new attribute.\n\t*/\n\tcopy = xmlNewDocProp(target->doc, attr->name, NULL);\n\tif (copy == NULL) {\n\t    if (attr->ns) {\n\t\txsltTransformError(ctxt, NULL, attr->parent,\n\t\t    \"Internal error: Failed to create attribute '{%s}%s'.\\n\",\n\t\t    attr->ns->href, attr->name);\n\t    } else {\n\t\txsltTransformError(ctxt, NULL, attr->parent,\n\t\t    \"Internal error: Failed to create attribute '%s'.\\n\",\n\t\t    attr->name);\n\t    }\n\t    goto error;\n\t}\n\t/*\n\t* Attach it to the target element.\n\t*/\n\tcopy->parent = target;\n\tif (last == NULL) {\n\t    target->properties = copy;\n\t    last = copy;\n\t} else {\n\t    last->next = copy;\n\t    copy->prev = last;\n\t    last = copy;\n\t}\n\t/*\n\t* Set the namespace. Avoid lookups of same namespaces.\n\t*/\n\tif (attr->ns != origNs) {\n\t    origNs = attr->ns;\n\t    if (attr->ns != NULL) {\n#ifdef XSLT_REFACTORED\n\t\tcopyNs = xsltGetSpecialNamespace(ctxt, attr->parent,\n\t\t    attr->ns->href, attr->ns->prefix, target);\n#else\n\t\tcopyNs = xsltGetNamespace(ctxt, attr->parent,\n\t\t    attr->ns, target);\n#endif\n\t\tif (copyNs == NULL)\n\t\t    goto error;\n\t    } else\n\t\tcopyNs = NULL;\n\t}\n\tcopy->ns = copyNs;\n\n\t/*\n\t* Set the value.\n\t*/\n\ttext = xmlNewText(NULL);\n\tif (text != NULL) {\n\t    copy->last = copy->children = text;\n\t    text->parent = (xmlNodePtr) copy;\n\t    text->doc = copy->doc;\n\n\t    if (attr->psvi != NULL) {\n\t\t/*\n\t\t* Evaluate the Attribute Value Template.\n\t\t*/\n\t\tvalueAVT = xsltEvalAVT(ctxt, attr->psvi, attr->parent);\n\t\tif (valueAVT == NULL) {\n\t\t    /*\n\t\t    * TODO: Damn, we need an easy mechanism to report\n\t\t    * qualified names!\n\t\t    */\n\t\t    if (attr->ns) {\n\t\t\txsltTransformError(ctxt, NULL, attr->parent,\n\t\t\t    \"Internal error: Failed to evaluate the AVT \"\n\t\t\t    \"of attribute '{%s}%s'.\\n\",\n\t\t\t    attr->ns->href, attr->name);\n\t\t    } else {\n\t\t\txsltTransformError(ctxt, NULL, attr->parent,\n\t\t\t    \"Internal error: Failed to evaluate the AVT \"\n\t\t\t    \"of attribute '%s'.\\n\",\n\t\t\t    attr->name);\n\t\t    }\n\t\t    text->content = xmlStrdup(BAD_CAST \"\");\n\t\t    goto error;\n\t\t} else {\n\t\t    text->content = valueAVT;\n\t\t}\n\t    } else if ((ctxt->internalized) &&\n\t\t(target->doc != NULL) &&\n\t\t(target->doc->dict == ctxt->dict))\n\t    {\n\t\ttext->content = (xmlChar *) value;\n\t    } else {\n\t\ttext->content = xmlStrdup(value);\n\t    }\n            if ((copy != NULL) && (text != NULL) &&\n                (xmlIsID(copy->doc, copy->parent, copy)))\n                xmlAddID(NULL, copy->doc, text->content, copy);\n\t}\n\nnext_attribute:\n\tattr = attr->next;\n    } while (attr != NULL);\n\n    /*\n    * Apply attribute-sets.\n    * The creation of such attributes will not overwrite any existing\n    * attribute.\n    */\n    attr = attrs;\n    do {\n#ifdef XSLT_REFACTORED\n\tif ((attr->psvi == xsltXSLTAttrMarker) &&\n\t    xmlStrEqual(attr->name, (const xmlChar *)\"use-attribute-sets\"))\n\t{\n\t    xsltApplyAttributeSet(ctxt, ctxt->node, (xmlNodePtr) attr, NULL);\n\t}\n#else\n\tif ((attr->ns != NULL) &&\n\t    xmlStrEqual(attr->name, (const xmlChar *)\"use-attribute-sets\") &&\n\t    xmlStrEqual(attr->ns->href, XSLT_NAMESPACE))\n\t{\n\t    xsltApplyAttributeSet(ctxt, ctxt->node, (xmlNodePtr) attr, NULL);\n\t}\n#endif\n\tattr = attr->next;\n    } while (attr != NULL);\n\n    ctxt->insert = oldInsert;\n    return(target->properties);\n\nerror:\n    ctxt->insert = oldInsert;\n    return(NULL);\n}",
        "func": "xmlAttrPtr\nxsltAttrListTemplateProcess(xsltTransformContextPtr ctxt, \n\t                    xmlNodePtr target, xmlAttrPtr attrs)\n{\n    xmlAttrPtr attr, copy, last;\n    xmlNodePtr oldInsert, text;\n    xmlNsPtr origNs = NULL, copyNs = NULL;\n    const xmlChar *value;\n    xmlChar *valueAVT;\n\n    if ((ctxt == NULL) || (target == NULL) || (attrs == NULL))\n\treturn(NULL);\n\n    oldInsert = ctxt->insert;\n    ctxt->insert = target;        \n\n    /*\n    * Instantiate LRE-attributes.\n    */\n    if (target->properties) {\n\tlast = target->properties;\n\twhile (last->next != NULL)\n\t    last = last->next;\n    } else {\n\tlast = NULL;\n    }\n    attr = attrs;\n    do {\n\t/*\n\t* Skip XSLT attributes.\n\t*/\n#ifdef XSLT_REFACTORED\n\tif (attr->psvi == xsltXSLTAttrMarker) {\n\t    goto next_attribute;\n\t}\n#else\n\tif ((attr->ns != NULL) &&\n\t    xmlStrEqual(attr->ns->href, XSLT_NAMESPACE))\n\t{\n\t    goto next_attribute;\n\t}\n#endif\n\t/*\n\t* Get the value.\n\t*/\n\tif (attr->children != NULL) {\n\t    if ((attr->children->type != XML_TEXT_NODE) ||\n\t\t(attr->children->next != NULL))\n\t    {\n\t\txsltTransformError(ctxt, NULL, attr->parent,\n\t\t    \"Internal error: The children of an attribute node of a \"\n\t\t    \"literal result element are not in the expected form.\\n\");\n\t\tgoto error;\n\t    }\n\t    value = attr->children->content;\n\t    if (value == NULL)\n\t\tvalue = xmlDictLookup(ctxt->dict, BAD_CAST \"\", 0);\n\t} else\n\t    value = xmlDictLookup(ctxt->dict, BAD_CAST \"\", 0);\n\n\t/*\n\t* Create a new attribute.\n\t*/\n\tcopy = xmlNewDocProp(target->doc, attr->name, NULL);\n\tif (copy == NULL) {\n\t    if (attr->ns) {\n\t\txsltTransformError(ctxt, NULL, attr->parent,\n\t\t    \"Internal error: Failed to create attribute '{%s}%s'.\\n\",\n\t\t    attr->ns->href, attr->name);\n\t    } else {\n\t\txsltTransformError(ctxt, NULL, attr->parent,\n\t\t    \"Internal error: Failed to create attribute '%s'.\\n\",\n\t\t    attr->name);\n\t    }\n\t    goto error;\n\t}\n\t/*\n\t* Attach it to the target element.\n\t*/\n\tcopy->parent = target;\n\tif (last == NULL) {\n\t    target->properties = copy;\n\t    last = copy;\n\t} else {\n\t    last->next = copy;\n\t    copy->prev = last;\n\t    last = copy;\n\t}\n\t/*\n\t* Set the namespace. Avoid lookups of same namespaces.\n\t*/\n\tif (attr->ns != origNs) {\n\t    origNs = attr->ns;\n\t    if (attr->ns != NULL) {\n#ifdef XSLT_REFACTORED\n\t\tcopyNs = xsltGetSpecialNamespace(ctxt, attr->parent,\n\t\t    attr->ns->href, attr->ns->prefix, target);\n#else\n\t\tcopyNs = xsltGetNamespace(ctxt, attr->parent,\n\t\t    attr->ns, target);\n#endif\n\t\tif (copyNs == NULL)\n\t\t    goto error;\n\t    } else\n\t\tcopyNs = NULL;\n\t}\n\tcopy->ns = copyNs;\n\n\t/*\n\t* Set the value.\n\t*/\n\ttext = xmlNewText(NULL);\n\tif (text != NULL) {\n\t    copy->last = copy->children = text;\n\t    text->parent = (xmlNodePtr) copy;\n\t    text->doc = copy->doc;\n\n\t    if (attr->psvi != NULL) {\n\t\t/*\n\t\t* Evaluate the Attribute Value Template.\n\t\t*/\n\t\tvalueAVT = xsltEvalAVT(ctxt, attr->psvi, attr->parent);\n\t\tif (valueAVT == NULL) {\n\t\t    /*\n\t\t    * TODO: Damn, we need an easy mechanism to report\n\t\t    * qualified names!\n\t\t    */\n\t\t    if (attr->ns) {\n\t\t\txsltTransformError(ctxt, NULL, attr->parent,\n\t\t\t    \"Internal error: Failed to evaluate the AVT \"\n\t\t\t    \"of attribute '{%s}%s'.\\n\",\n\t\t\t    attr->ns->href, attr->name);\n\t\t    } else {\n\t\t\txsltTransformError(ctxt, NULL, attr->parent,\n\t\t\t    \"Internal error: Failed to evaluate the AVT \"\n\t\t\t    \"of attribute '%s'.\\n\",\n\t\t\t    attr->name);\n\t\t    }\n\t\t    text->content = xmlStrdup(BAD_CAST \"\");\n\t\t    goto error;\n\t\t} else {\n\t\t    text->content = valueAVT;\n\t\t}\n\t    } else if ((ctxt->internalized) &&\n\t\t(target->doc != NULL) &&\n\t\t(target->doc->dict == ctxt->dict) &&\n\t\txmlDictOwns(ctxt->dict, value))\n\t    {\n\t\ttext->content = (xmlChar *) value;\n\t    } else {\n\t\ttext->content = xmlStrdup(value);\n\t    }\n            if ((copy != NULL) && (text != NULL) &&\n                (xmlIsID(copy->doc, copy->parent, copy)))\n                xmlAddID(NULL, copy->doc, text->content, copy);\n\t}\n\nnext_attribute:\n\tattr = attr->next;\n    } while (attr != NULL);\n\n    /*\n    * Apply attribute-sets.\n    * The creation of such attributes will not overwrite any existing\n    * attribute.\n    */\n    attr = attrs;\n    do {\n#ifdef XSLT_REFACTORED\n\tif ((attr->psvi == xsltXSLTAttrMarker) &&\n\t    xmlStrEqual(attr->name, (const xmlChar *)\"use-attribute-sets\"))\n\t{\n\t    xsltApplyAttributeSet(ctxt, ctxt->node, (xmlNodePtr) attr, NULL);\n\t}\n#else\n\tif ((attr->ns != NULL) &&\n\t    xmlStrEqual(attr->name, (const xmlChar *)\"use-attribute-sets\") &&\n\t    xmlStrEqual(attr->ns->href, XSLT_NAMESPACE))\n\t{\n\t    xsltApplyAttributeSet(ctxt, ctxt->node, (xmlNodePtr) attr, NULL);\n\t}\n#endif\n\tattr = attr->next;\n    } while (attr != NULL);\n\n    ctxt->insert = oldInsert;\n    return(target->properties);\n\nerror:\n    ctxt->insert = oldInsert;\n    return(NULL);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -143,7 +143,8 @@\n \t\t}\n \t    } else if ((ctxt->internalized) &&\n \t\t(target->doc != NULL) &&\n-\t\t(target->doc->dict == ctxt->dict))\n+\t\t(target->doc->dict == ctxt->dict) &&\n+\t\txmlDictOwns(ctxt->dict, value))\n \t    {\n \t\ttext->content = (xmlChar *) value;\n \t    } else {",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t(target->doc->dict == ctxt->dict))"
            ],
            "added_lines": [
                "\t\t(target->doc->dict == ctxt->dict) &&",
                "\t\txmlDictOwns(ctxt->dict, value))"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-3510",
        "func_name": "torvalds/linux/xacct_add_tsk",
        "description": "Use-after-free vulnerability in the xacct_add_tsk function in kernel/tsacct.c in the Linux kernel before 2.6.19 allows local users to obtain potentially sensitive information from kernel memory or cause a denial of service (system crash) via a taskstats TASKSTATS_CMD_ATTR_PID command.",
        "git_url": "https://github.com/torvalds/linux/commit/f0ec1aaf54caddd21c259aea8b2ecfbde4ee4fb9",
        "commit_title": "[PATCH] xacct_add_tsk: fix pure theoretical ->mm use-after-free",
        "commit_text": " Paranoid fix. The task can free its ->mm after the 'if (p->mm)' check.  Cc: Shailabh Nagar <nagar@watson.ibm.com> Cc: Balbir Singh <balbir@in.ibm.com> Cc: Jay Lan <jlan@sgi.com>",
        "func_before": "void xacct_add_tsk(struct taskstats *stats, struct task_struct *p)\n{\n\t/* convert pages-jiffies to Mbyte-usec */\n\tstats->coremem = jiffies_to_usecs(p->acct_rss_mem1) * PAGE_SIZE / MB;\n\tstats->virtmem = jiffies_to_usecs(p->acct_vm_mem1) * PAGE_SIZE / MB;\n\tif (p->mm) {\n\t\t/* adjust to KB unit */\n\t\tstats->hiwater_rss   = p->mm->hiwater_rss * PAGE_SIZE / KB;\n\t\tstats->hiwater_vm    = p->mm->hiwater_vm * PAGE_SIZE / KB;\n\t}\n\tstats->read_char\t= p->rchar;\n\tstats->write_char\t= p->wchar;\n\tstats->read_syscalls\t= p->syscr;\n\tstats->write_syscalls\t= p->syscw;\n}",
        "func": "void xacct_add_tsk(struct taskstats *stats, struct task_struct *p)\n{\n\tstruct mm_struct *mm;\n\n\t/* convert pages-jiffies to Mbyte-usec */\n\tstats->coremem = jiffies_to_usecs(p->acct_rss_mem1) * PAGE_SIZE / MB;\n\tstats->virtmem = jiffies_to_usecs(p->acct_vm_mem1) * PAGE_SIZE / MB;\n\tmm = get_task_mm(p);\n\tif (mm) {\n\t\t/* adjust to KB unit */\n\t\tstats->hiwater_rss   = mm->hiwater_rss * PAGE_SIZE / KB;\n\t\tstats->hiwater_vm    = mm->hiwater_vm * PAGE_SIZE / KB;\n\t\tmmput(mm);\n\t}\n\tstats->read_char\t= p->rchar;\n\tstats->write_char\t= p->wchar;\n\tstats->read_syscalls\t= p->syscr;\n\tstats->write_syscalls\t= p->syscw;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,12 +1,16 @@\n void xacct_add_tsk(struct taskstats *stats, struct task_struct *p)\n {\n+\tstruct mm_struct *mm;\n+\n \t/* convert pages-jiffies to Mbyte-usec */\n \tstats->coremem = jiffies_to_usecs(p->acct_rss_mem1) * PAGE_SIZE / MB;\n \tstats->virtmem = jiffies_to_usecs(p->acct_vm_mem1) * PAGE_SIZE / MB;\n-\tif (p->mm) {\n+\tmm = get_task_mm(p);\n+\tif (mm) {\n \t\t/* adjust to KB unit */\n-\t\tstats->hiwater_rss   = p->mm->hiwater_rss * PAGE_SIZE / KB;\n-\t\tstats->hiwater_vm    = p->mm->hiwater_vm * PAGE_SIZE / KB;\n+\t\tstats->hiwater_rss   = mm->hiwater_rss * PAGE_SIZE / KB;\n+\t\tstats->hiwater_vm    = mm->hiwater_vm * PAGE_SIZE / KB;\n+\t\tmmput(mm);\n \t}\n \tstats->read_char\t= p->rchar;\n \tstats->write_char\t= p->wchar;",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (p->mm) {",
                "\t\tstats->hiwater_rss   = p->mm->hiwater_rss * PAGE_SIZE / KB;",
                "\t\tstats->hiwater_vm    = p->mm->hiwater_vm * PAGE_SIZE / KB;"
            ],
            "added_lines": [
                "\tstruct mm_struct *mm;",
                "",
                "\tmm = get_task_mm(p);",
                "\tif (mm) {",
                "\t\tstats->hiwater_rss   = mm->hiwater_rss * PAGE_SIZE / KB;",
                "\t\tstats->hiwater_vm    = mm->hiwater_vm * PAGE_SIZE / KB;",
                "\t\tmmput(mm);"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-4467",
        "func_name": "torvalds/linux/do_siocgstampns",
        "description": "The (1) do_siocgstamp and (2) do_siocgstampns functions in net/socket.c in the Linux kernel before 3.5.4 use an incorrect argument order, which allows local users to obtain sensitive information from kernel memory or cause a denial of service (system crash) via a crafted ioctl call.",
        "git_url": "https://github.com/torvalds/linux/commit/ed6fe9d614fc1bca95eb8c0ccd0e92db00ef9d5d",
        "commit_title": "Fix order of arguments to compat_put_time[spec|val]",
        "commit_text": " Commit 644595f89620 (\"compat: Handle COMPAT_USE_64BIT_TIME in net/socket.c\") introduced a bug where the helper functions to take either a 64-bit or compat time[spec|val] got the arguments in the wrong order, passing the kernel stack pointer off as a user pointer (and vice versa).  Because of the user address range check, that in turn then causes an EFAULT due to the user pointer range checking failing for the kernel address.  Incorrectly resuling in a failed system call for 32-bit processes with a 64-bit kernel.  On odder architectures like HP-PA (with separate user/kernel address spaces), it can be used read kernel memory.  Cc: stable@vger.kernel.org",
        "func_before": "static int do_siocgstampns(struct net *net, struct socket *sock,\n\t\t\t   unsigned int cmd, void __user *up)\n{\n\tmm_segment_t old_fs = get_fs();\n\tstruct timespec kts;\n\tint err;\n\n\tset_fs(KERNEL_DS);\n\terr = sock_do_ioctl(net, sock, cmd, (unsigned long)&kts);\n\tset_fs(old_fs);\n\tif (!err)\n\t\terr = compat_put_timespec(up, &kts);\n\n\treturn err;\n}",
        "func": "static int do_siocgstampns(struct net *net, struct socket *sock,\n\t\t\t   unsigned int cmd, void __user *up)\n{\n\tmm_segment_t old_fs = get_fs();\n\tstruct timespec kts;\n\tint err;\n\n\tset_fs(KERNEL_DS);\n\terr = sock_do_ioctl(net, sock, cmd, (unsigned long)&kts);\n\tset_fs(old_fs);\n\tif (!err)\n\t\terr = compat_put_timespec(&kts, up);\n\n\treturn err;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -9,7 +9,7 @@\n \terr = sock_do_ioctl(net, sock, cmd, (unsigned long)&kts);\n \tset_fs(old_fs);\n \tif (!err)\n-\t\terr = compat_put_timespec(up, &kts);\n+\t\terr = compat_put_timespec(&kts, up);\n \n \treturn err;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\t\terr = compat_put_timespec(up, &kts);"
            ],
            "added_lines": [
                "\t\terr = compat_put_timespec(&kts, up);"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-4467",
        "func_name": "torvalds/linux/do_siocgstamp",
        "description": "The (1) do_siocgstamp and (2) do_siocgstampns functions in net/socket.c in the Linux kernel before 3.5.4 use an incorrect argument order, which allows local users to obtain sensitive information from kernel memory or cause a denial of service (system crash) via a crafted ioctl call.",
        "git_url": "https://github.com/torvalds/linux/commit/ed6fe9d614fc1bca95eb8c0ccd0e92db00ef9d5d",
        "commit_title": "Fix order of arguments to compat_put_time[spec|val]",
        "commit_text": " Commit 644595f89620 (\"compat: Handle COMPAT_USE_64BIT_TIME in net/socket.c\") introduced a bug where the helper functions to take either a 64-bit or compat time[spec|val] got the arguments in the wrong order, passing the kernel stack pointer off as a user pointer (and vice versa).  Because of the user address range check, that in turn then causes an EFAULT due to the user pointer range checking failing for the kernel address.  Incorrectly resuling in a failed system call for 32-bit processes with a 64-bit kernel.  On odder architectures like HP-PA (with separate user/kernel address spaces), it can be used read kernel memory.  Cc: stable@vger.kernel.org",
        "func_before": "static int do_siocgstamp(struct net *net, struct socket *sock,\n\t\t\t unsigned int cmd, void __user *up)\n{\n\tmm_segment_t old_fs = get_fs();\n\tstruct timeval ktv;\n\tint err;\n\n\tset_fs(KERNEL_DS);\n\terr = sock_do_ioctl(net, sock, cmd, (unsigned long)&ktv);\n\tset_fs(old_fs);\n\tif (!err)\n\t\terr = compat_put_timeval(up, &ktv);\n\n\treturn err;\n}",
        "func": "static int do_siocgstamp(struct net *net, struct socket *sock,\n\t\t\t unsigned int cmd, void __user *up)\n{\n\tmm_segment_t old_fs = get_fs();\n\tstruct timeval ktv;\n\tint err;\n\n\tset_fs(KERNEL_DS);\n\terr = sock_do_ioctl(net, sock, cmd, (unsigned long)&ktv);\n\tset_fs(old_fs);\n\tif (!err)\n\t\terr = compat_put_timeval(&ktv, up);\n\n\treturn err;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -9,7 +9,7 @@\n \terr = sock_do_ioctl(net, sock, cmd, (unsigned long)&ktv);\n \tset_fs(old_fs);\n \tif (!err)\n-\t\terr = compat_put_timeval(up, &ktv);\n+\t\terr = compat_put_timeval(&ktv, up);\n \n \treturn err;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\t\terr = compat_put_timeval(up, &ktv);"
            ],
            "added_lines": [
                "\t\terr = compat_put_timeval(&ktv, up);"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-0841",
        "func_name": "GNOME/libxml2/xmlDictCreate",
        "description": "libxml2 before 2.8.0 computes hash values without restricting the ability to trigger hash collisions predictably, which allows context-dependent attackers to cause a denial of service (CPU consumption) via crafted XML data.",
        "git_url": "https://github.com/GNOME/libxml2/commit/8973d58b7498fa5100a876815476b81fd1a2412a",
        "commit_title": "Add hash randomization to hash and dict structures",
        "commit_text": " Following http://www.ocert.org/advisories/ocert-2011-003.html it seems that having hash randomization might be a good idea when using XML with untrusted data * configure.in: lookup for rand, srand and time * dict.c: add randomization to dictionaries hash tables * hash.c: add randomization to normal hash tables",
        "func_before": "xmlDictPtr\nxmlDictCreate(void) {\n    xmlDictPtr dict;\n\n    if (!xmlDictInitialized)\n        if (!xmlInitializeDict())\n            return(NULL);\n\n#ifdef DICT_DEBUG_PATTERNS\n    fprintf(stderr, \"C\");\n#endif\n\n    dict = xmlMalloc(sizeof(xmlDict));\n    if (dict) {\n        dict->ref_counter = 1;\n\n        dict->size = MIN_DICT_SIZE;\n\tdict->nbElems = 0;\n        dict->dict = xmlMalloc(MIN_DICT_SIZE * sizeof(xmlDictEntry));\n\tdict->strings = NULL;\n\tdict->subdict = NULL;\n        if (dict->dict) {\n\t    memset(dict->dict, 0, MIN_DICT_SIZE * sizeof(xmlDictEntry));\n\t    return(dict);\n        }\n        xmlFree(dict);\n    }\n    return(NULL);\n}",
        "func": "xmlDictPtr\nxmlDictCreate(void) {\n    xmlDictPtr dict;\n\n    if (!xmlDictInitialized)\n        if (!xmlInitializeDict())\n            return(NULL);\n\n#ifdef DICT_DEBUG_PATTERNS\n    fprintf(stderr, \"C\");\n#endif\n\n    dict = xmlMalloc(sizeof(xmlDict));\n    if (dict) {\n        dict->ref_counter = 1;\n\n        dict->size = MIN_DICT_SIZE;\n\tdict->nbElems = 0;\n        dict->dict = xmlMalloc(MIN_DICT_SIZE * sizeof(xmlDictEntry));\n\tdict->strings = NULL;\n\tdict->subdict = NULL;\n        if (dict->dict) {\n\t    memset(dict->dict, 0, MIN_DICT_SIZE * sizeof(xmlDictEntry));\n#ifdef DICT_RANDOMIZATION\n            dict->seed = rand();\n#else\n            dict->seed = 0;\n#endif\n\t    return(dict);\n        }\n        xmlFree(dict);\n    }\n    return(NULL);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -21,6 +21,11 @@\n \tdict->subdict = NULL;\n         if (dict->dict) {\n \t    memset(dict->dict, 0, MIN_DICT_SIZE * sizeof(xmlDictEntry));\n+#ifdef DICT_RANDOMIZATION\n+            dict->seed = rand();\n+#else\n+            dict->seed = 0;\n+#endif\n \t    return(dict);\n         }\n         xmlFree(dict);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "#ifdef DICT_RANDOMIZATION",
                "            dict->seed = rand();",
                "#else",
                "            dict->seed = 0;",
                "#endif"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-0841",
        "func_name": "GNOME/libxml2/xmlDictComputeFastKey",
        "description": "libxml2 before 2.8.0 computes hash values without restricting the ability to trigger hash collisions predictably, which allows context-dependent attackers to cause a denial of service (CPU consumption) via crafted XML data.",
        "git_url": "https://github.com/GNOME/libxml2/commit/8973d58b7498fa5100a876815476b81fd1a2412a",
        "commit_title": "Add hash randomization to hash and dict structures",
        "commit_text": " Following http://www.ocert.org/advisories/ocert-2011-003.html it seems that having hash randomization might be a good idea when using XML with untrusted data * configure.in: lookup for rand, srand and time * dict.c: add randomization to dictionaries hash tables * hash.c: add randomization to normal hash tables",
        "func_before": "static unsigned long\nxmlDictComputeFastKey(const xmlChar *name, int namelen) {\n    unsigned long value = 0L;\n\n    if (name == NULL) return(0);\n    value = *name;\n    value <<= 5;\n    if (namelen > 10) {\n        value += name[namelen - 1];\n        namelen = 10;\n    }\n    switch (namelen) {\n        case 10: value += name[9];\n        case 9: value += name[8];\n        case 8: value += name[7];\n        case 7: value += name[6];\n        case 6: value += name[5];\n        case 5: value += name[4];\n        case 4: value += name[3];\n        case 3: value += name[2];\n        case 2: value += name[1];\n        default: break;\n    }\n    return(value);\n}",
        "func": "static unsigned long\nxmlDictComputeFastKey(const xmlChar *name, int namelen, int seed) {\n    unsigned long value = seed;\n\n    if (name == NULL) return(0);\n    value = *name;\n    value <<= 5;\n    if (namelen > 10) {\n        value += name[namelen - 1];\n        namelen = 10;\n    }\n    switch (namelen) {\n        case 10: value += name[9];\n        case 9: value += name[8];\n        case 8: value += name[7];\n        case 7: value += name[6];\n        case 6: value += name[5];\n        case 5: value += name[4];\n        case 4: value += name[3];\n        case 3: value += name[2];\n        case 2: value += name[1];\n        default: break;\n    }\n    return(value);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,6 @@\n static unsigned long\n-xmlDictComputeFastKey(const xmlChar *name, int namelen) {\n-    unsigned long value = 0L;\n+xmlDictComputeFastKey(const xmlChar *name, int namelen, int seed) {\n+    unsigned long value = seed;\n \n     if (name == NULL) return(0);\n     value = *name;",
        "diff_line_info": {
            "deleted_lines": [
                "xmlDictComputeFastKey(const xmlChar *name, int namelen) {",
                "    unsigned long value = 0L;"
            ],
            "added_lines": [
                "xmlDictComputeFastKey(const xmlChar *name, int namelen, int seed) {",
                "    unsigned long value = seed;"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-0841",
        "func_name": "GNOME/libxml2/xmlInitializeDict",
        "description": "libxml2 before 2.8.0 computes hash values without restricting the ability to trigger hash collisions predictably, which allows context-dependent attackers to cause a denial of service (CPU consumption) via crafted XML data.",
        "git_url": "https://github.com/GNOME/libxml2/commit/8973d58b7498fa5100a876815476b81fd1a2412a",
        "commit_title": "Add hash randomization to hash and dict structures",
        "commit_text": " Following http://www.ocert.org/advisories/ocert-2011-003.html it seems that having hash randomization might be a good idea when using XML with untrusted data * configure.in: lookup for rand, srand and time * dict.c: add randomization to dictionaries hash tables * hash.c: add randomization to normal hash tables",
        "func_before": "static int xmlInitializeDict(void) {\n    if (xmlDictInitialized)\n        return(1);\n\n    if ((xmlDictMutex = xmlNewRMutex()) == NULL)\n        return(0);\n\n    xmlDictInitialized = 1;\n    return(1);\n}",
        "func": "static int xmlInitializeDict(void) {\n    if (xmlDictInitialized)\n        return(1);\n\n    if ((xmlDictMutex = xmlNewRMutex()) == NULL)\n        return(0);\n\n#ifdef DICT_RANDOMIZATION\n    srand(time(NULL));\n#endif\n    xmlDictInitialized = 1;\n    return(1);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,6 +5,9 @@\n     if ((xmlDictMutex = xmlNewRMutex()) == NULL)\n         return(0);\n \n+#ifdef DICT_RANDOMIZATION\n+    srand(time(NULL));\n+#endif\n     xmlDictInitialized = 1;\n     return(1);\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "#ifdef DICT_RANDOMIZATION",
                "    srand(time(NULL));",
                "#endif"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-0841",
        "func_name": "GNOME/libxml2/xmlDictComputeBigKey",
        "description": "libxml2 before 2.8.0 computes hash values without restricting the ability to trigger hash collisions predictably, which allows context-dependent attackers to cause a denial of service (CPU consumption) via crafted XML data.",
        "git_url": "https://github.com/GNOME/libxml2/commit/8973d58b7498fa5100a876815476b81fd1a2412a",
        "commit_title": "Add hash randomization to hash and dict structures",
        "commit_text": " Following http://www.ocert.org/advisories/ocert-2011-003.html it seems that having hash randomization might be a good idea when using XML with untrusted data * configure.in: lookup for rand, srand and time * dict.c: add randomization to dictionaries hash tables * hash.c: add randomization to normal hash tables",
        "func_before": "static uint32_t\nxmlDictComputeBigKey(const xmlChar* data, int namelen) {\n    uint32_t hash;\n    int i;\n\n    if (namelen <= 0 || data == NULL) return(0);\n\n    hash = 0;\n\n    for (i = 0;i < namelen; i++) {\n        hash += data[i];\n\thash += (hash << 10);\n\thash ^= (hash >> 6);\n    }\n    hash += (hash << 3);\n    hash ^= (hash >> 11);\n    hash += (hash << 15);\n\n    return hash;\n}",
        "func": "static uint32_t\nxmlDictComputeBigKey(const xmlChar* data, int namelen, int seed) {\n    uint32_t hash;\n    int i;\n\n    if (namelen <= 0 || data == NULL) return(0);\n\n    hash = seed;\n\n    for (i = 0;i < namelen; i++) {\n        hash += data[i];\n\thash += (hash << 10);\n\thash ^= (hash >> 6);\n    }\n    hash += (hash << 3);\n    hash ^= (hash >> 11);\n    hash += (hash << 15);\n\n    return hash;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,11 +1,11 @@\n static uint32_t\n-xmlDictComputeBigKey(const xmlChar* data, int namelen) {\n+xmlDictComputeBigKey(const xmlChar* data, int namelen, int seed) {\n     uint32_t hash;\n     int i;\n \n     if (namelen <= 0 || data == NULL) return(0);\n \n-    hash = 0;\n+    hash = seed;\n \n     for (i = 0;i < namelen; i++) {\n         hash += data[i];",
        "diff_line_info": {
            "deleted_lines": [
                "xmlDictComputeBigKey(const xmlChar* data, int namelen) {",
                "    hash = 0;"
            ],
            "added_lines": [
                "xmlDictComputeBigKey(const xmlChar* data, int namelen, int seed) {",
                "    hash = seed;"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-0841",
        "func_name": "GNOME/libxml2/xmlDictComputeFastQKey",
        "description": "libxml2 before 2.8.0 computes hash values without restricting the ability to trigger hash collisions predictably, which allows context-dependent attackers to cause a denial of service (CPU consumption) via crafted XML data.",
        "git_url": "https://github.com/GNOME/libxml2/commit/8973d58b7498fa5100a876815476b81fd1a2412a",
        "commit_title": "Add hash randomization to hash and dict structures",
        "commit_text": " Following http://www.ocert.org/advisories/ocert-2011-003.html it seems that having hash randomization might be a good idea when using XML with untrusted data * configure.in: lookup for rand, srand and time * dict.c: add randomization to dictionaries hash tables * hash.c: add randomization to normal hash tables",
        "func_before": "static unsigned long\nxmlDictComputeFastQKey(const xmlChar *prefix, int plen,\n                       const xmlChar *name, int len)\n{\n    unsigned long value = 0L;\n\n    if (plen == 0)\n\tvalue += 30 * (unsigned long) ':';\n    else\n\tvalue += 30 * (*prefix);\n\n    if (len > 10) {\n        value += name[len - (plen + 1 + 1)];\n        len = 10;\n\tif (plen > 10)\n\t    plen = 10;\n    }\n    switch (plen) {\n        case 10: value += prefix[9];\n        case 9: value += prefix[8];\n        case 8: value += prefix[7];\n        case 7: value += prefix[6];\n        case 6: value += prefix[5];\n        case 5: value += prefix[4];\n        case 4: value += prefix[3];\n        case 3: value += prefix[2];\n        case 2: value += prefix[1];\n        case 1: value += prefix[0];\n        default: break;\n    }\n    len -= plen;\n    if (len > 0) {\n        value += (unsigned long) ':';\n\tlen--;\n    }\n    switch (len) {\n        case 10: value += name[9];\n        case 9: value += name[8];\n        case 8: value += name[7];\n        case 7: value += name[6];\n        case 6: value += name[5];\n        case 5: value += name[4];\n        case 4: value += name[3];\n        case 3: value += name[2];\n        case 2: value += name[1];\n        case 1: value += name[0];\n        default: break;\n    }\n    return(value);\n}",
        "func": "static unsigned long\nxmlDictComputeFastQKey(const xmlChar *prefix, int plen,\n                       const xmlChar *name, int len, int seed)\n{\n    unsigned long value = (unsigned long) seed;\n\n    if (plen == 0)\n\tvalue += 30 * (unsigned long) ':';\n    else\n\tvalue += 30 * (*prefix);\n\n    if (len > 10) {\n        value += name[len - (plen + 1 + 1)];\n        len = 10;\n\tif (plen > 10)\n\t    plen = 10;\n    }\n    switch (plen) {\n        case 10: value += prefix[9];\n        case 9: value += prefix[8];\n        case 8: value += prefix[7];\n        case 7: value += prefix[6];\n        case 6: value += prefix[5];\n        case 5: value += prefix[4];\n        case 4: value += prefix[3];\n        case 3: value += prefix[2];\n        case 2: value += prefix[1];\n        case 1: value += prefix[0];\n        default: break;\n    }\n    len -= plen;\n    if (len > 0) {\n        value += (unsigned long) ':';\n\tlen--;\n    }\n    switch (len) {\n        case 10: value += name[9];\n        case 9: value += name[8];\n        case 8: value += name[7];\n        case 7: value += name[6];\n        case 6: value += name[5];\n        case 5: value += name[4];\n        case 4: value += name[3];\n        case 3: value += name[2];\n        case 2: value += name[1];\n        case 1: value += name[0];\n        default: break;\n    }\n    return(value);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,8 +1,8 @@\n static unsigned long\n xmlDictComputeFastQKey(const xmlChar *prefix, int plen,\n-                       const xmlChar *name, int len)\n+                       const xmlChar *name, int len, int seed)\n {\n-    unsigned long value = 0L;\n+    unsigned long value = (unsigned long) seed;\n \n     if (plen == 0)\n \tvalue += 30 * (unsigned long) ':';",
        "diff_line_info": {
            "deleted_lines": [
                "                       const xmlChar *name, int len)",
                "    unsigned long value = 0L;"
            ],
            "added_lines": [
                "                       const xmlChar *name, int len, int seed)",
                "    unsigned long value = (unsigned long) seed;"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-0841",
        "func_name": "GNOME/libxml2/xmlDictCreateSub",
        "description": "libxml2 before 2.8.0 computes hash values without restricting the ability to trigger hash collisions predictably, which allows context-dependent attackers to cause a denial of service (CPU consumption) via crafted XML data.",
        "git_url": "https://github.com/GNOME/libxml2/commit/8973d58b7498fa5100a876815476b81fd1a2412a",
        "commit_title": "Add hash randomization to hash and dict structures",
        "commit_text": " Following http://www.ocert.org/advisories/ocert-2011-003.html it seems that having hash randomization might be a good idea when using XML with untrusted data * configure.in: lookup for rand, srand and time * dict.c: add randomization to dictionaries hash tables * hash.c: add randomization to normal hash tables",
        "func_before": "xmlDictPtr\nxmlDictCreateSub(xmlDictPtr sub) {\n    xmlDictPtr dict = xmlDictCreate();\n\n    if ((dict != NULL) && (sub != NULL)) {\n#ifdef DICT_DEBUG_PATTERNS\n        fprintf(stderr, \"R\");\n#endif\n        dict->subdict = sub;\n\txmlDictReference(dict->subdict);\n    }\n    return(dict);\n}",
        "func": "xmlDictPtr\nxmlDictCreateSub(xmlDictPtr sub) {\n    xmlDictPtr dict = xmlDictCreate();\n\n    if ((dict != NULL) && (sub != NULL)) {\n#ifdef DICT_DEBUG_PATTERNS\n        fprintf(stderr, \"R\");\n#endif\n        dict->seed = sub->seed;\n        dict->subdict = sub;\n\txmlDictReference(dict->subdict);\n    }\n    return(dict);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -6,6 +6,7 @@\n #ifdef DICT_DEBUG_PATTERNS\n         fprintf(stderr, \"R\");\n #endif\n+        dict->seed = sub->seed;\n         dict->subdict = sub;\n \txmlDictReference(dict->subdict);\n     }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "        dict->seed = sub->seed;"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-0841",
        "func_name": "GNOME/libxml2/xmlDictComputeBigQKey",
        "description": "libxml2 before 2.8.0 computes hash values without restricting the ability to trigger hash collisions predictably, which allows context-dependent attackers to cause a denial of service (CPU consumption) via crafted XML data.",
        "git_url": "https://github.com/GNOME/libxml2/commit/8973d58b7498fa5100a876815476b81fd1a2412a",
        "commit_title": "Add hash randomization to hash and dict structures",
        "commit_text": " Following http://www.ocert.org/advisories/ocert-2011-003.html it seems that having hash randomization might be a good idea when using XML with untrusted data * configure.in: lookup for rand, srand and time * dict.c: add randomization to dictionaries hash tables * hash.c: add randomization to normal hash tables",
        "func_before": "static unsigned long\nxmlDictComputeBigQKey(const xmlChar *prefix, int plen,\n                      const xmlChar *name, int len)\n{\n    uint32_t hash;\n    int i;\n\n    hash = 0;\n\n    for (i = 0;i < plen; i++) {\n        hash += prefix[i];\n\thash += (hash << 10);\n\thash ^= (hash >> 6);\n    }\n    hash += ':';\n    hash += (hash << 10);\n    hash ^= (hash >> 6);\n\n    for (i = 0;i < len; i++) {\n        hash += name[i];\n\thash += (hash << 10);\n\thash ^= (hash >> 6);\n    }\n    hash += (hash << 3);\n    hash ^= (hash >> 11);\n    hash += (hash << 15);\n\n    return hash;\n}",
        "func": "static unsigned long\nxmlDictComputeBigQKey(const xmlChar *prefix, int plen,\n                      const xmlChar *name, int len, int seed)\n{\n    uint32_t hash;\n    int i;\n\n    hash = seed;\n\n    for (i = 0;i < plen; i++) {\n        hash += prefix[i];\n\thash += (hash << 10);\n\thash ^= (hash >> 6);\n    }\n    hash += ':';\n    hash += (hash << 10);\n    hash ^= (hash >> 6);\n\n    for (i = 0;i < len; i++) {\n        hash += name[i];\n\thash += (hash << 10);\n\thash ^= (hash >> 6);\n    }\n    hash += (hash << 3);\n    hash ^= (hash >> 11);\n    hash += (hash << 15);\n\n    return hash;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,11 +1,11 @@\n static unsigned long\n xmlDictComputeBigQKey(const xmlChar *prefix, int plen,\n-                      const xmlChar *name, int len)\n+                      const xmlChar *name, int len, int seed)\n {\n     uint32_t hash;\n     int i;\n \n-    hash = 0;\n+    hash = seed;\n \n     for (i = 0;i < plen; i++) {\n         hash += prefix[i];",
        "diff_line_info": {
            "deleted_lines": [
                "                      const xmlChar *name, int len)",
                "    hash = 0;"
            ],
            "added_lines": [
                "                      const xmlChar *name, int len, int seed)",
                "    hash = seed;"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-0841",
        "func_name": "GNOME/libxml2/xmlHashCreate",
        "description": "libxml2 before 2.8.0 computes hash values without restricting the ability to trigger hash collisions predictably, which allows context-dependent attackers to cause a denial of service (CPU consumption) via crafted XML data.",
        "git_url": "https://github.com/GNOME/libxml2/commit/8973d58b7498fa5100a876815476b81fd1a2412a",
        "commit_title": "Add hash randomization to hash and dict structures",
        "commit_text": " Following http://www.ocert.org/advisories/ocert-2011-003.html it seems that having hash randomization might be a good idea when using XML with untrusted data * configure.in: lookup for rand, srand and time * dict.c: add randomization to dictionaries hash tables * hash.c: add randomization to normal hash tables",
        "func_before": "xmlHashTablePtr\nxmlHashCreate(int size) {\n    xmlHashTablePtr table;\n  \n    if (size <= 0)\n        size = 256;\n  \n    table = xmlMalloc(sizeof(xmlHashTable));\n    if (table) {\n        table->dict = NULL;\n        table->size = size;\n\ttable->nbElems = 0;\n        table->table = xmlMalloc(size * sizeof(xmlHashEntry));\n        if (table->table) {\n  \t    memset(table->table, 0, size * sizeof(xmlHashEntry));\n  \t    return(table);\n        }\n        xmlFree(table);\n    }\n    return(NULL);\n}",
        "func": "xmlHashTablePtr\nxmlHashCreate(int size) {\n    xmlHashTablePtr table;\n  \n    if (size <= 0)\n        size = 256;\n  \n    table = xmlMalloc(sizeof(xmlHashTable));\n    if (table) {\n        table->dict = NULL;\n        table->size = size;\n\ttable->nbElems = 0;\n        table->table = xmlMalloc(size * sizeof(xmlHashEntry));\n        if (table->table) {\n  \t    memset(table->table, 0, size * sizeof(xmlHashEntry));\n#ifdef HASH_RANDOMIZATION\n            if (!hash_initialized) {\n                srand(time(NULL));\n                hash_initialized = 1;\n            }\n            table->random_seed = rand();\n#endif\n  \t    return(table);\n        }\n        xmlFree(table);\n    }\n    return(NULL);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -13,6 +13,13 @@\n         table->table = xmlMalloc(size * sizeof(xmlHashEntry));\n         if (table->table) {\n   \t    memset(table->table, 0, size * sizeof(xmlHashEntry));\n+#ifdef HASH_RANDOMIZATION\n+            if (!hash_initialized) {\n+                srand(time(NULL));\n+                hash_initialized = 1;\n+            }\n+            table->random_seed = rand();\n+#endif\n   \t    return(table);\n         }\n         xmlFree(table);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "#ifdef HASH_RANDOMIZATION",
                "            if (!hash_initialized) {",
                "                srand(time(NULL));",
                "                hash_initialized = 1;",
                "            }",
                "            table->random_seed = rand();",
                "#endif"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-0841",
        "func_name": "GNOME/libxml2/xmlHashComputeKey",
        "description": "libxml2 before 2.8.0 computes hash values without restricting the ability to trigger hash collisions predictably, which allows context-dependent attackers to cause a denial of service (CPU consumption) via crafted XML data.",
        "git_url": "https://github.com/GNOME/libxml2/commit/8973d58b7498fa5100a876815476b81fd1a2412a",
        "commit_title": "Add hash randomization to hash and dict structures",
        "commit_text": " Following http://www.ocert.org/advisories/ocert-2011-003.html it seems that having hash randomization might be a good idea when using XML with untrusted data * configure.in: lookup for rand, srand and time * dict.c: add randomization to dictionaries hash tables * hash.c: add randomization to normal hash tables",
        "func_before": "static unsigned long\nxmlHashComputeKey(xmlHashTablePtr table, const xmlChar *name,\n\t          const xmlChar *name2, const xmlChar *name3) {\n    unsigned long value = 0L;\n    char ch;\n    \n    if (name != NULL) {\n\tvalue += 30 * (*name);\n\twhile ((ch = *name++) != 0) {\n\t    value = value ^ ((value << 5) + (value >> 3) + (unsigned long)ch);\n\t}\n    }\n    if (name2 != NULL) {\n\twhile ((ch = *name2++) != 0) {\n\t    value = value ^ ((value << 5) + (value >> 3) + (unsigned long)ch);\n\t}\n    }\n    if (name3 != NULL) {\n\twhile ((ch = *name3++) != 0) {\n\t    value = value ^ ((value << 5) + (value >> 3) + (unsigned long)ch);\n\t}\n    }\n    return (value % table->size);\n}",
        "func": "static unsigned long\nxmlHashComputeKey(xmlHashTablePtr table, const xmlChar *name,\n\t          const xmlChar *name2, const xmlChar *name3) {\n    unsigned long value = 0L;\n    char ch;\n    \n#ifdef HASH_RANDOMIZATION\n    value = table->random_seed;\n#endif\n    if (name != NULL) {\n\tvalue += 30 * (*name);\n\twhile ((ch = *name++) != 0) {\n\t    value = value ^ ((value << 5) + (value >> 3) + (unsigned long)ch);\n\t}\n    }\n    if (name2 != NULL) {\n\twhile ((ch = *name2++) != 0) {\n\t    value = value ^ ((value << 5) + (value >> 3) + (unsigned long)ch);\n\t}\n    }\n    if (name3 != NULL) {\n\twhile ((ch = *name3++) != 0) {\n\t    value = value ^ ((value << 5) + (value >> 3) + (unsigned long)ch);\n\t}\n    }\n    return (value % table->size);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,6 +4,9 @@\n     unsigned long value = 0L;\n     char ch;\n     \n+#ifdef HASH_RANDOMIZATION\n+    value = table->random_seed;\n+#endif\n     if (name != NULL) {\n \tvalue += 30 * (*name);\n \twhile ((ch = *name++) != 0) {",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "#ifdef HASH_RANDOMIZATION",
                "    value = table->random_seed;",
                "#endif"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-0841",
        "func_name": "GNOME/libxml2/xmlHashComputeQKey",
        "description": "libxml2 before 2.8.0 computes hash values without restricting the ability to trigger hash collisions predictably, which allows context-dependent attackers to cause a denial of service (CPU consumption) via crafted XML data.",
        "git_url": "https://github.com/GNOME/libxml2/commit/8973d58b7498fa5100a876815476b81fd1a2412a",
        "commit_title": "Add hash randomization to hash and dict structures",
        "commit_text": " Following http://www.ocert.org/advisories/ocert-2011-003.html it seems that having hash randomization might be a good idea when using XML with untrusted data * configure.in: lookup for rand, srand and time * dict.c: add randomization to dictionaries hash tables * hash.c: add randomization to normal hash tables",
        "func_before": "static unsigned long\nxmlHashComputeQKey(xmlHashTablePtr table,\n\t\t   const xmlChar *prefix, const xmlChar *name,\n\t\t   const xmlChar *prefix2, const xmlChar *name2,\n\t\t   const xmlChar *prefix3, const xmlChar *name3) {\n    unsigned long value = 0L;\n    char ch;\n    \n    if (prefix != NULL)\n\tvalue += 30 * (*prefix);\n    else\n\tvalue += 30 * (*name);\n\n    if (prefix != NULL) {\n\twhile ((ch = *prefix++) != 0) {\n\t    value = value ^ ((value << 5) + (value >> 3) + (unsigned long)ch);\n\t}\n\tvalue = value ^ ((value << 5) + (value >> 3) + (unsigned long)':');\n    }\n    if (name != NULL) {\n\twhile ((ch = *name++) != 0) {\n\t    value = value ^ ((value << 5) + (value >> 3) + (unsigned long)ch);\n\t}\n    }\n    if (prefix2 != NULL) {\n\twhile ((ch = *prefix2++) != 0) {\n\t    value = value ^ ((value << 5) + (value >> 3) + (unsigned long)ch);\n\t}\n\tvalue = value ^ ((value << 5) + (value >> 3) + (unsigned long)':');\n    }\n    if (name2 != NULL) {\n\twhile ((ch = *name2++) != 0) {\n\t    value = value ^ ((value << 5) + (value >> 3) + (unsigned long)ch);\n\t}\n    }\n    if (prefix3 != NULL) {\n\twhile ((ch = *prefix3++) != 0) {\n\t    value = value ^ ((value << 5) + (value >> 3) + (unsigned long)ch);\n\t}\n\tvalue = value ^ ((value << 5) + (value >> 3) + (unsigned long)':');\n    }\n    if (name3 != NULL) {\n\twhile ((ch = *name3++) != 0) {\n\t    value = value ^ ((value << 5) + (value >> 3) + (unsigned long)ch);\n\t}\n    }\n    return (value % table->size);\n}",
        "func": "static unsigned long\nxmlHashComputeQKey(xmlHashTablePtr table,\n\t\t   const xmlChar *prefix, const xmlChar *name,\n\t\t   const xmlChar *prefix2, const xmlChar *name2,\n\t\t   const xmlChar *prefix3, const xmlChar *name3) {\n    unsigned long value = 0L;\n    char ch;\n    \n#ifdef HASH_RANDOMIZATION\n    value = table->random_seed;\n#endif\n    if (prefix != NULL)\n\tvalue += 30 * (*prefix);\n    else\n\tvalue += 30 * (*name);\n\n    if (prefix != NULL) {\n\twhile ((ch = *prefix++) != 0) {\n\t    value = value ^ ((value << 5) + (value >> 3) + (unsigned long)ch);\n\t}\n\tvalue = value ^ ((value << 5) + (value >> 3) + (unsigned long)':');\n    }\n    if (name != NULL) {\n\twhile ((ch = *name++) != 0) {\n\t    value = value ^ ((value << 5) + (value >> 3) + (unsigned long)ch);\n\t}\n    }\n    if (prefix2 != NULL) {\n\twhile ((ch = *prefix2++) != 0) {\n\t    value = value ^ ((value << 5) + (value >> 3) + (unsigned long)ch);\n\t}\n\tvalue = value ^ ((value << 5) + (value >> 3) + (unsigned long)':');\n    }\n    if (name2 != NULL) {\n\twhile ((ch = *name2++) != 0) {\n\t    value = value ^ ((value << 5) + (value >> 3) + (unsigned long)ch);\n\t}\n    }\n    if (prefix3 != NULL) {\n\twhile ((ch = *prefix3++) != 0) {\n\t    value = value ^ ((value << 5) + (value >> 3) + (unsigned long)ch);\n\t}\n\tvalue = value ^ ((value << 5) + (value >> 3) + (unsigned long)':');\n    }\n    if (name3 != NULL) {\n\twhile ((ch = *name3++) != 0) {\n\t    value = value ^ ((value << 5) + (value >> 3) + (unsigned long)ch);\n\t}\n    }\n    return (value % table->size);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -6,6 +6,9 @@\n     unsigned long value = 0L;\n     char ch;\n     \n+#ifdef HASH_RANDOMIZATION\n+    value = table->random_seed;\n+#endif\n     if (prefix != NULL)\n \tvalue += 30 * (*prefix);\n     else",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "#ifdef HASH_RANDOMIZATION",
                "    value = table->random_seed;",
                "#endif"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-0217",
        "func_name": "torvalds/linux/xen_netbk_idx_release",
        "description": "Memory leak in drivers/net/xen-netback/netback.c in the Xen netback functionality in the Linux kernel before 3.7.8 allows guest OS users to cause a denial of service (memory consumption) by triggering certain error conditions.",
        "git_url": "https://github.com/torvalds/linux/commit/7d5145d8eb2b9791533ffe4dc003b129b9696c48",
        "commit_title": "xen/netback: don't leak pages on failure in xen_netbk_tx_check_gop.",
        "commit_text": "",
        "func_before": "static void xen_netbk_idx_release(struct xen_netbk *netbk, u16 pending_idx)\n{\n\tstruct xenvif *vif;\n\tstruct pending_tx_info *pending_tx_info;\n\tpending_ring_idx_t index;\n\n\t/* Already complete? */\n\tif (netbk->mmap_pages[pending_idx] == NULL)\n\t\treturn;\n\n\tpending_tx_info = &netbk->pending_tx_info[pending_idx];\n\n\tvif = pending_tx_info->vif;\n\n\tmake_tx_response(vif, &pending_tx_info->req, XEN_NETIF_RSP_OKAY);\n\n\tindex = pending_index(netbk->pending_prod++);\n\tnetbk->pending_ring[index] = pending_idx;\n\n\txenvif_put(vif);\n\n\tnetbk->mmap_pages[pending_idx]->mapping = 0;\n\tput_page(netbk->mmap_pages[pending_idx]);\n\tnetbk->mmap_pages[pending_idx] = NULL;\n}",
        "func": "static void xen_netbk_idx_release(struct xen_netbk *netbk, u16 pending_idx,\n\t\t\t\t  u8 status)\n{\n\tstruct xenvif *vif;\n\tstruct pending_tx_info *pending_tx_info;\n\tpending_ring_idx_t index;\n\n\t/* Already complete? */\n\tif (netbk->mmap_pages[pending_idx] == NULL)\n\t\treturn;\n\n\tpending_tx_info = &netbk->pending_tx_info[pending_idx];\n\n\tvif = pending_tx_info->vif;\n\n\tmake_tx_response(vif, &pending_tx_info->req, status);\n\n\tindex = pending_index(netbk->pending_prod++);\n\tnetbk->pending_ring[index] = pending_idx;\n\n\txenvif_put(vif);\n\n\tnetbk->mmap_pages[pending_idx]->mapping = 0;\n\tput_page(netbk->mmap_pages[pending_idx]);\n\tnetbk->mmap_pages[pending_idx] = NULL;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,4 +1,5 @@\n-static void xen_netbk_idx_release(struct xen_netbk *netbk, u16 pending_idx)\n+static void xen_netbk_idx_release(struct xen_netbk *netbk, u16 pending_idx,\n+\t\t\t\t  u8 status)\n {\n \tstruct xenvif *vif;\n \tstruct pending_tx_info *pending_tx_info;\n@@ -12,7 +13,7 @@\n \n \tvif = pending_tx_info->vif;\n \n-\tmake_tx_response(vif, &pending_tx_info->req, XEN_NETIF_RSP_OKAY);\n+\tmake_tx_response(vif, &pending_tx_info->req, status);\n \n \tindex = pending_index(netbk->pending_prod++);\n \tnetbk->pending_ring[index] = pending_idx;",
        "diff_line_info": {
            "deleted_lines": [
                "static void xen_netbk_idx_release(struct xen_netbk *netbk, u16 pending_idx)",
                "\tmake_tx_response(vif, &pending_tx_info->req, XEN_NETIF_RSP_OKAY);"
            ],
            "added_lines": [
                "static void xen_netbk_idx_release(struct xen_netbk *netbk, u16 pending_idx,",
                "\t\t\t\t  u8 status)",
                "\tmake_tx_response(vif, &pending_tx_info->req, status);"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-0217",
        "func_name": "torvalds/linux/xen_netbk_tx_submit",
        "description": "Memory leak in drivers/net/xen-netback/netback.c in the Xen netback functionality in the Linux kernel before 3.7.8 allows guest OS users to cause a denial of service (memory consumption) by triggering certain error conditions.",
        "git_url": "https://github.com/torvalds/linux/commit/7d5145d8eb2b9791533ffe4dc003b129b9696c48",
        "commit_title": "xen/netback: don't leak pages on failure in xen_netbk_tx_check_gop.",
        "commit_text": "",
        "func_before": "static void xen_netbk_tx_submit(struct xen_netbk *netbk)\n{\n\tstruct gnttab_copy *gop = netbk->tx_copy_ops;\n\tstruct sk_buff *skb;\n\n\twhile ((skb = __skb_dequeue(&netbk->tx_queue)) != NULL) {\n\t\tstruct xen_netif_tx_request *txp;\n\t\tstruct xenvif *vif;\n\t\tu16 pending_idx;\n\t\tunsigned data_len;\n\n\t\tpending_idx = *((u16 *)skb->data);\n\t\tvif = netbk->pending_tx_info[pending_idx].vif;\n\t\ttxp = &netbk->pending_tx_info[pending_idx].req;\n\n\t\t/* Check the remap error code. */\n\t\tif (unlikely(xen_netbk_tx_check_gop(netbk, skb, &gop))) {\n\t\t\tnetdev_dbg(vif->dev, \"netback grant failed.\\n\");\n\t\t\tskb_shinfo(skb)->nr_frags = 0;\n\t\t\tkfree_skb(skb);\n\t\t\tcontinue;\n\t\t}\n\n\t\tdata_len = skb->len;\n\t\tmemcpy(skb->data,\n\t\t       (void *)(idx_to_kaddr(netbk, pending_idx)|txp->offset),\n\t\t       data_len);\n\t\tif (data_len < txp->size) {\n\t\t\t/* Append the packet payload as a fragment. */\n\t\t\ttxp->offset += data_len;\n\t\t\ttxp->size -= data_len;\n\t\t} else {\n\t\t\t/* Schedule a response immediately. */\n\t\t\txen_netbk_idx_release(netbk, pending_idx);\n\t\t}\n\n\t\tif (txp->flags & XEN_NETTXF_csum_blank)\n\t\t\tskb->ip_summed = CHECKSUM_PARTIAL;\n\t\telse if (txp->flags & XEN_NETTXF_data_validated)\n\t\t\tskb->ip_summed = CHECKSUM_UNNECESSARY;\n\n\t\txen_netbk_fill_frags(netbk, skb);\n\n\t\t/*\n\t\t * If the initial fragment was < PKT_PROT_LEN then\n\t\t * pull through some bytes from the other fragments to\n\t\t * increase the linear region to PKT_PROT_LEN bytes.\n\t\t */\n\t\tif (skb_headlen(skb) < PKT_PROT_LEN && skb_is_nonlinear(skb)) {\n\t\t\tint target = min_t(int, skb->len, PKT_PROT_LEN);\n\t\t\t__pskb_pull_tail(skb, target - skb_headlen(skb));\n\t\t}\n\n\t\tskb->dev      = vif->dev;\n\t\tskb->protocol = eth_type_trans(skb, skb->dev);\n\n\t\tif (checksum_setup(vif, skb)) {\n\t\t\tnetdev_dbg(vif->dev,\n\t\t\t\t   \"Can't setup checksum in net_tx_action\\n\");\n\t\t\tkfree_skb(skb);\n\t\t\tcontinue;\n\t\t}\n\n\t\tvif->dev->stats.rx_bytes += skb->len;\n\t\tvif->dev->stats.rx_packets++;\n\n\t\txenvif_receive_skb(vif, skb);\n\t}\n}",
        "func": "static void xen_netbk_tx_submit(struct xen_netbk *netbk)\n{\n\tstruct gnttab_copy *gop = netbk->tx_copy_ops;\n\tstruct sk_buff *skb;\n\n\twhile ((skb = __skb_dequeue(&netbk->tx_queue)) != NULL) {\n\t\tstruct xen_netif_tx_request *txp;\n\t\tstruct xenvif *vif;\n\t\tu16 pending_idx;\n\t\tunsigned data_len;\n\n\t\tpending_idx = *((u16 *)skb->data);\n\t\tvif = netbk->pending_tx_info[pending_idx].vif;\n\t\ttxp = &netbk->pending_tx_info[pending_idx].req;\n\n\t\t/* Check the remap error code. */\n\t\tif (unlikely(xen_netbk_tx_check_gop(netbk, skb, &gop))) {\n\t\t\tnetdev_dbg(vif->dev, \"netback grant failed.\\n\");\n\t\t\tskb_shinfo(skb)->nr_frags = 0;\n\t\t\tkfree_skb(skb);\n\t\t\tcontinue;\n\t\t}\n\n\t\tdata_len = skb->len;\n\t\tmemcpy(skb->data,\n\t\t       (void *)(idx_to_kaddr(netbk, pending_idx)|txp->offset),\n\t\t       data_len);\n\t\tif (data_len < txp->size) {\n\t\t\t/* Append the packet payload as a fragment. */\n\t\t\ttxp->offset += data_len;\n\t\t\ttxp->size -= data_len;\n\t\t} else {\n\t\t\t/* Schedule a response immediately. */\n\t\t\txen_netbk_idx_release(netbk, pending_idx, XEN_NETIF_RSP_OKAY);\n\t\t}\n\n\t\tif (txp->flags & XEN_NETTXF_csum_blank)\n\t\t\tskb->ip_summed = CHECKSUM_PARTIAL;\n\t\telse if (txp->flags & XEN_NETTXF_data_validated)\n\t\t\tskb->ip_summed = CHECKSUM_UNNECESSARY;\n\n\t\txen_netbk_fill_frags(netbk, skb);\n\n\t\t/*\n\t\t * If the initial fragment was < PKT_PROT_LEN then\n\t\t * pull through some bytes from the other fragments to\n\t\t * increase the linear region to PKT_PROT_LEN bytes.\n\t\t */\n\t\tif (skb_headlen(skb) < PKT_PROT_LEN && skb_is_nonlinear(skb)) {\n\t\t\tint target = min_t(int, skb->len, PKT_PROT_LEN);\n\t\t\t__pskb_pull_tail(skb, target - skb_headlen(skb));\n\t\t}\n\n\t\tskb->dev      = vif->dev;\n\t\tskb->protocol = eth_type_trans(skb, skb->dev);\n\n\t\tif (checksum_setup(vif, skb)) {\n\t\t\tnetdev_dbg(vif->dev,\n\t\t\t\t   \"Can't setup checksum in net_tx_action\\n\");\n\t\t\tkfree_skb(skb);\n\t\t\tcontinue;\n\t\t}\n\n\t\tvif->dev->stats.rx_bytes += skb->len;\n\t\tvif->dev->stats.rx_packets++;\n\n\t\txenvif_receive_skb(vif, skb);\n\t}\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -31,7 +31,7 @@\n \t\t\ttxp->size -= data_len;\n \t\t} else {\n \t\t\t/* Schedule a response immediately. */\n-\t\t\txen_netbk_idx_release(netbk, pending_idx);\n+\t\t\txen_netbk_idx_release(netbk, pending_idx, XEN_NETIF_RSP_OKAY);\n \t\t}\n \n \t\tif (txp->flags & XEN_NETTXF_csum_blank)",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\txen_netbk_idx_release(netbk, pending_idx);"
            ],
            "added_lines": [
                "\t\t\txen_netbk_idx_release(netbk, pending_idx, XEN_NETIF_RSP_OKAY);"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-0217",
        "func_name": "torvalds/linux/xen_netbk_tx_check_gop",
        "description": "Memory leak in drivers/net/xen-netback/netback.c in the Xen netback functionality in the Linux kernel before 3.7.8 allows guest OS users to cause a denial of service (memory consumption) by triggering certain error conditions.",
        "git_url": "https://github.com/torvalds/linux/commit/7d5145d8eb2b9791533ffe4dc003b129b9696c48",
        "commit_title": "xen/netback: don't leak pages on failure in xen_netbk_tx_check_gop.",
        "commit_text": "",
        "func_before": "static int xen_netbk_tx_check_gop(struct xen_netbk *netbk,\n\t\t\t\t  struct sk_buff *skb,\n\t\t\t\t  struct gnttab_copy **gopp)\n{\n\tstruct gnttab_copy *gop = *gopp;\n\tu16 pending_idx = *((u16 *)skb->data);\n\tstruct pending_tx_info *pending_tx_info = netbk->pending_tx_info;\n\tstruct xenvif *vif = pending_tx_info[pending_idx].vif;\n\tstruct xen_netif_tx_request *txp;\n\tstruct skb_shared_info *shinfo = skb_shinfo(skb);\n\tint nr_frags = shinfo->nr_frags;\n\tint i, err, start;\n\n\t/* Check status of header. */\n\terr = gop->status;\n\tif (unlikely(err)) {\n\t\tpending_ring_idx_t index;\n\t\tindex = pending_index(netbk->pending_prod++);\n\t\ttxp = &pending_tx_info[pending_idx].req;\n\t\tmake_tx_response(vif, txp, XEN_NETIF_RSP_ERROR);\n\t\tnetbk->pending_ring[index] = pending_idx;\n\t\txenvif_put(vif);\n\t}\n\n\t/* Skip first skb fragment if it is on same page as header fragment. */\n\tstart = (frag_get_pending_idx(&shinfo->frags[0]) == pending_idx);\n\n\tfor (i = start; i < nr_frags; i++) {\n\t\tint j, newerr;\n\t\tpending_ring_idx_t index;\n\n\t\tpending_idx = frag_get_pending_idx(&shinfo->frags[i]);\n\n\t\t/* Check error status: if okay then remember grant handle. */\n\t\tnewerr = (++gop)->status;\n\t\tif (likely(!newerr)) {\n\t\t\t/* Had a previous error? Invalidate this fragment. */\n\t\t\tif (unlikely(err))\n\t\t\t\txen_netbk_idx_release(netbk, pending_idx);\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* Error on this fragment: respond to client with an error. */\n\t\ttxp = &netbk->pending_tx_info[pending_idx].req;\n\t\tmake_tx_response(vif, txp, XEN_NETIF_RSP_ERROR);\n\t\tindex = pending_index(netbk->pending_prod++);\n\t\tnetbk->pending_ring[index] = pending_idx;\n\t\txenvif_put(vif);\n\n\t\t/* Not the first error? Preceding frags already invalidated. */\n\t\tif (err)\n\t\t\tcontinue;\n\n\t\t/* First error: invalidate header and preceding fragments. */\n\t\tpending_idx = *((u16 *)skb->data);\n\t\txen_netbk_idx_release(netbk, pending_idx);\n\t\tfor (j = start; j < i; j++) {\n\t\t\tpending_idx = frag_get_pending_idx(&shinfo->frags[j]);\n\t\t\txen_netbk_idx_release(netbk, pending_idx);\n\t\t}\n\n\t\t/* Remember the error: invalidate all subsequent fragments. */\n\t\terr = newerr;\n\t}\n\n\t*gopp = gop + 1;\n\treturn err;\n}",
        "func": "static int xen_netbk_tx_check_gop(struct xen_netbk *netbk,\n\t\t\t\t  struct sk_buff *skb,\n\t\t\t\t  struct gnttab_copy **gopp)\n{\n\tstruct gnttab_copy *gop = *gopp;\n\tu16 pending_idx = *((u16 *)skb->data);\n\tstruct skb_shared_info *shinfo = skb_shinfo(skb);\n\tint nr_frags = shinfo->nr_frags;\n\tint i, err, start;\n\n\t/* Check status of header. */\n\terr = gop->status;\n\tif (unlikely(err))\n\t\txen_netbk_idx_release(netbk, pending_idx, XEN_NETIF_RSP_ERROR);\n\n\t/* Skip first skb fragment if it is on same page as header fragment. */\n\tstart = (frag_get_pending_idx(&shinfo->frags[0]) == pending_idx);\n\n\tfor (i = start; i < nr_frags; i++) {\n\t\tint j, newerr;\n\n\t\tpending_idx = frag_get_pending_idx(&shinfo->frags[i]);\n\n\t\t/* Check error status: if okay then remember grant handle. */\n\t\tnewerr = (++gop)->status;\n\t\tif (likely(!newerr)) {\n\t\t\t/* Had a previous error? Invalidate this fragment. */\n\t\t\tif (unlikely(err))\n\t\t\t\txen_netbk_idx_release(netbk, pending_idx, XEN_NETIF_RSP_OKAY);\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* Error on this fragment: respond to client with an error. */\n\t\txen_netbk_idx_release(netbk, pending_idx, XEN_NETIF_RSP_ERROR);\n\n\t\t/* Not the first error? Preceding frags already invalidated. */\n\t\tif (err)\n\t\t\tcontinue;\n\n\t\t/* First error: invalidate header and preceding fragments. */\n\t\tpending_idx = *((u16 *)skb->data);\n\t\txen_netbk_idx_release(netbk, pending_idx, XEN_NETIF_RSP_OKAY);\n\t\tfor (j = start; j < i; j++) {\n\t\t\tpending_idx = frag_get_pending_idx(&shinfo->frags[j]);\n\t\t\txen_netbk_idx_release(netbk, pending_idx, XEN_NETIF_RSP_OKAY);\n\t\t}\n\n\t\t/* Remember the error: invalidate all subsequent fragments. */\n\t\terr = newerr;\n\t}\n\n\t*gopp = gop + 1;\n\treturn err;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,30 +4,20 @@\n {\n \tstruct gnttab_copy *gop = *gopp;\n \tu16 pending_idx = *((u16 *)skb->data);\n-\tstruct pending_tx_info *pending_tx_info = netbk->pending_tx_info;\n-\tstruct xenvif *vif = pending_tx_info[pending_idx].vif;\n-\tstruct xen_netif_tx_request *txp;\n \tstruct skb_shared_info *shinfo = skb_shinfo(skb);\n \tint nr_frags = shinfo->nr_frags;\n \tint i, err, start;\n \n \t/* Check status of header. */\n \terr = gop->status;\n-\tif (unlikely(err)) {\n-\t\tpending_ring_idx_t index;\n-\t\tindex = pending_index(netbk->pending_prod++);\n-\t\ttxp = &pending_tx_info[pending_idx].req;\n-\t\tmake_tx_response(vif, txp, XEN_NETIF_RSP_ERROR);\n-\t\tnetbk->pending_ring[index] = pending_idx;\n-\t\txenvif_put(vif);\n-\t}\n+\tif (unlikely(err))\n+\t\txen_netbk_idx_release(netbk, pending_idx, XEN_NETIF_RSP_ERROR);\n \n \t/* Skip first skb fragment if it is on same page as header fragment. */\n \tstart = (frag_get_pending_idx(&shinfo->frags[0]) == pending_idx);\n \n \tfor (i = start; i < nr_frags; i++) {\n \t\tint j, newerr;\n-\t\tpending_ring_idx_t index;\n \n \t\tpending_idx = frag_get_pending_idx(&shinfo->frags[i]);\n \n@@ -36,16 +26,12 @@\n \t\tif (likely(!newerr)) {\n \t\t\t/* Had a previous error? Invalidate this fragment. */\n \t\t\tif (unlikely(err))\n-\t\t\t\txen_netbk_idx_release(netbk, pending_idx);\n+\t\t\t\txen_netbk_idx_release(netbk, pending_idx, XEN_NETIF_RSP_OKAY);\n \t\t\tcontinue;\n \t\t}\n \n \t\t/* Error on this fragment: respond to client with an error. */\n-\t\ttxp = &netbk->pending_tx_info[pending_idx].req;\n-\t\tmake_tx_response(vif, txp, XEN_NETIF_RSP_ERROR);\n-\t\tindex = pending_index(netbk->pending_prod++);\n-\t\tnetbk->pending_ring[index] = pending_idx;\n-\t\txenvif_put(vif);\n+\t\txen_netbk_idx_release(netbk, pending_idx, XEN_NETIF_RSP_ERROR);\n \n \t\t/* Not the first error? Preceding frags already invalidated. */\n \t\tif (err)\n@@ -53,10 +39,10 @@\n \n \t\t/* First error: invalidate header and preceding fragments. */\n \t\tpending_idx = *((u16 *)skb->data);\n-\t\txen_netbk_idx_release(netbk, pending_idx);\n+\t\txen_netbk_idx_release(netbk, pending_idx, XEN_NETIF_RSP_OKAY);\n \t\tfor (j = start; j < i; j++) {\n \t\t\tpending_idx = frag_get_pending_idx(&shinfo->frags[j]);\n-\t\t\txen_netbk_idx_release(netbk, pending_idx);\n+\t\t\txen_netbk_idx_release(netbk, pending_idx, XEN_NETIF_RSP_OKAY);\n \t\t}\n \n \t\t/* Remember the error: invalidate all subsequent fragments. */",
        "diff_line_info": {
            "deleted_lines": [
                "\tstruct pending_tx_info *pending_tx_info = netbk->pending_tx_info;",
                "\tstruct xenvif *vif = pending_tx_info[pending_idx].vif;",
                "\tstruct xen_netif_tx_request *txp;",
                "\tif (unlikely(err)) {",
                "\t\tpending_ring_idx_t index;",
                "\t\tindex = pending_index(netbk->pending_prod++);",
                "\t\ttxp = &pending_tx_info[pending_idx].req;",
                "\t\tmake_tx_response(vif, txp, XEN_NETIF_RSP_ERROR);",
                "\t\tnetbk->pending_ring[index] = pending_idx;",
                "\t\txenvif_put(vif);",
                "\t}",
                "\t\tpending_ring_idx_t index;",
                "\t\t\t\txen_netbk_idx_release(netbk, pending_idx);",
                "\t\ttxp = &netbk->pending_tx_info[pending_idx].req;",
                "\t\tmake_tx_response(vif, txp, XEN_NETIF_RSP_ERROR);",
                "\t\tindex = pending_index(netbk->pending_prod++);",
                "\t\tnetbk->pending_ring[index] = pending_idx;",
                "\t\txenvif_put(vif);",
                "\t\txen_netbk_idx_release(netbk, pending_idx);",
                "\t\t\txen_netbk_idx_release(netbk, pending_idx);"
            ],
            "added_lines": [
                "\tif (unlikely(err))",
                "\t\txen_netbk_idx_release(netbk, pending_idx, XEN_NETIF_RSP_ERROR);",
                "\t\t\t\txen_netbk_idx_release(netbk, pending_idx, XEN_NETIF_RSP_OKAY);",
                "\t\txen_netbk_idx_release(netbk, pending_idx, XEN_NETIF_RSP_ERROR);",
                "\t\txen_netbk_idx_release(netbk, pending_idx, XEN_NETIF_RSP_OKAY);",
                "\t\t\txen_netbk_idx_release(netbk, pending_idx, XEN_NETIF_RSP_OKAY);"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-0217",
        "func_name": "torvalds/linux/xen_netbk_fill_frags",
        "description": "Memory leak in drivers/net/xen-netback/netback.c in the Xen netback functionality in the Linux kernel before 3.7.8 allows guest OS users to cause a denial of service (memory consumption) by triggering certain error conditions.",
        "git_url": "https://github.com/torvalds/linux/commit/7d5145d8eb2b9791533ffe4dc003b129b9696c48",
        "commit_title": "xen/netback: don't leak pages on failure in xen_netbk_tx_check_gop.",
        "commit_text": "",
        "func_before": "static void xen_netbk_fill_frags(struct xen_netbk *netbk, struct sk_buff *skb)\n{\n\tstruct skb_shared_info *shinfo = skb_shinfo(skb);\n\tint nr_frags = shinfo->nr_frags;\n\tint i;\n\n\tfor (i = 0; i < nr_frags; i++) {\n\t\tskb_frag_t *frag = shinfo->frags + i;\n\t\tstruct xen_netif_tx_request *txp;\n\t\tstruct page *page;\n\t\tu16 pending_idx;\n\n\t\tpending_idx = frag_get_pending_idx(frag);\n\n\t\ttxp = &netbk->pending_tx_info[pending_idx].req;\n\t\tpage = virt_to_page(idx_to_kaddr(netbk, pending_idx));\n\t\t__skb_fill_page_desc(skb, i, page, txp->offset, txp->size);\n\t\tskb->len += txp->size;\n\t\tskb->data_len += txp->size;\n\t\tskb->truesize += txp->size;\n\n\t\t/* Take an extra reference to offset xen_netbk_idx_release */\n\t\tget_page(netbk->mmap_pages[pending_idx]);\n\t\txen_netbk_idx_release(netbk, pending_idx);\n\t}\n}",
        "func": "static void xen_netbk_fill_frags(struct xen_netbk *netbk, struct sk_buff *skb)\n{\n\tstruct skb_shared_info *shinfo = skb_shinfo(skb);\n\tint nr_frags = shinfo->nr_frags;\n\tint i;\n\n\tfor (i = 0; i < nr_frags; i++) {\n\t\tskb_frag_t *frag = shinfo->frags + i;\n\t\tstruct xen_netif_tx_request *txp;\n\t\tstruct page *page;\n\t\tu16 pending_idx;\n\n\t\tpending_idx = frag_get_pending_idx(frag);\n\n\t\ttxp = &netbk->pending_tx_info[pending_idx].req;\n\t\tpage = virt_to_page(idx_to_kaddr(netbk, pending_idx));\n\t\t__skb_fill_page_desc(skb, i, page, txp->offset, txp->size);\n\t\tskb->len += txp->size;\n\t\tskb->data_len += txp->size;\n\t\tskb->truesize += txp->size;\n\n\t\t/* Take an extra reference to offset xen_netbk_idx_release */\n\t\tget_page(netbk->mmap_pages[pending_idx]);\n\t\txen_netbk_idx_release(netbk, pending_idx, XEN_NETIF_RSP_OKAY);\n\t}\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -21,6 +21,6 @@\n \n \t\t/* Take an extra reference to offset xen_netbk_idx_release */\n \t\tget_page(netbk->mmap_pages[pending_idx]);\n-\t\txen_netbk_idx_release(netbk, pending_idx);\n+\t\txen_netbk_idx_release(netbk, pending_idx, XEN_NETIF_RSP_OKAY);\n \t}\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\t\txen_netbk_idx_release(netbk, pending_idx);"
            ],
            "added_lines": [
                "\t\txen_netbk_idx_release(netbk, pending_idx, XEN_NETIF_RSP_OKAY);"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-1767",
        "func_name": "torvalds/linux/shmem_remount_fs",
        "description": "Use-after-free vulnerability in the shmem_remount_fs function in mm/shmem.c in the Linux kernel before 3.7.10 allows local users to gain privileges or cause a denial of service (system crash) by remounting a tmpfs filesystem without specifying a required mpol (aka mempolicy) mount option.",
        "git_url": "https://github.com/torvalds/linux/commit/5f00110f7273f9ff04ac69a5f85bb535a4fd0987",
        "commit_title": "tmpfs: fix use-after-free of mempolicy object",
        "commit_text": " The tmpfs remount logic preserves filesystem mempolicy if the mpol=M option is not specified in the remount request.  A new policy can be specified if mpol=M is given.  Before this patch remounting an mpol bound tmpfs without specifying mpol= mount option in the remount request would set the filesystem's mempolicy object to a freed mempolicy object.  To reproduce the problem boot a DEBUG_PAGEALLOC kernel and run:     # mkdir /tmp/x      # mount -t tmpfs -o size=100M,mpol=interleave nodev /tmp/x      # grep /tmp/x /proc/mounts     nodev /tmp/x tmpfs rw,relatime,size=102400k,mpol=interleave:0-3 0 0      # mount -o remount,size=200M nodev /tmp/x      # grep /tmp/x /proc/mounts     nodev /tmp/x tmpfs rw,relatime,size=204800k,mpol=??? 0 0         # note ? garbage in mpol=... output above      # dd if=/dev/zero of=/tmp/x/f count=1         # panic here  Panic:     BUG: unable to handle kernel NULL pointer dereference at           (null)     IP: [<          (null)>]           (null)     [...]     Oops: 0010 [#1] SMP DEBUG_PAGEALLOC     Call Trace:       mpol_shared_policy_init+0xa5/0x160       shmem_get_inode+0x209/0x270       shmem_mknod+0x3e/0xf0       shmem_create+0x18/0x20       vfs_create+0xb5/0x130       do_last+0x9a1/0xea0       path_openat+0xb3/0x4d0       do_filp_open+0x42/0xa0       do_sys_open+0xfe/0x1e0       compat_sys_open+0x1b/0x20       cstar_dispatch+0x7/0x1f  Non-debug kernels will not crash immediately because referencing the dangling mpol will not cause a fault.  Instead the filesystem will reference a freed mempolicy object, which will cause unpredictable behavior.  The problem boils down to a dropped mpol reference below if shmem_parse_options() does not allocate a new mpol:      config = *sbinfo     shmem_parse_options(data, &config, true)     mpol_put(sbinfo->mpol)     sbinfo->mpol = config.mpol  /* BUG: saves unreferenced mpol */  This patch avoids the crash by not releasing the mempolicy if shmem_parse_options() doesn't create a new mpol.  How far back does this issue go? I see it in both 2.6.36 and 3.3.  I did not look back further.  Cc: <stable@vger.kernel.org>",
        "func_before": "static int shmem_remount_fs(struct super_block *sb, int *flags, char *data)\n{\n\tstruct shmem_sb_info *sbinfo = SHMEM_SB(sb);\n\tstruct shmem_sb_info config = *sbinfo;\n\tunsigned long inodes;\n\tint error = -EINVAL;\n\n\tif (shmem_parse_options(data, &config, true))\n\t\treturn error;\n\n\tspin_lock(&sbinfo->stat_lock);\n\tinodes = sbinfo->max_inodes - sbinfo->free_inodes;\n\tif (percpu_counter_compare(&sbinfo->used_blocks, config.max_blocks) > 0)\n\t\tgoto out;\n\tif (config.max_inodes < inodes)\n\t\tgoto out;\n\t/*\n\t * Those tests disallow limited->unlimited while any are in use;\n\t * but we must separately disallow unlimited->limited, because\n\t * in that case we have no record of how much is already in use.\n\t */\n\tif (config.max_blocks && !sbinfo->max_blocks)\n\t\tgoto out;\n\tif (config.max_inodes && !sbinfo->max_inodes)\n\t\tgoto out;\n\n\terror = 0;\n\tsbinfo->max_blocks  = config.max_blocks;\n\tsbinfo->max_inodes  = config.max_inodes;\n\tsbinfo->free_inodes = config.max_inodes - inodes;\n\n\tmpol_put(sbinfo->mpol);\n\tsbinfo->mpol        = config.mpol;\t/* transfers initial ref */\nout:\n\tspin_unlock(&sbinfo->stat_lock);\n\treturn error;\n}",
        "func": "static int shmem_remount_fs(struct super_block *sb, int *flags, char *data)\n{\n\tstruct shmem_sb_info *sbinfo = SHMEM_SB(sb);\n\tstruct shmem_sb_info config = *sbinfo;\n\tunsigned long inodes;\n\tint error = -EINVAL;\n\n\tconfig.mpol = NULL;\n\tif (shmem_parse_options(data, &config, true))\n\t\treturn error;\n\n\tspin_lock(&sbinfo->stat_lock);\n\tinodes = sbinfo->max_inodes - sbinfo->free_inodes;\n\tif (percpu_counter_compare(&sbinfo->used_blocks, config.max_blocks) > 0)\n\t\tgoto out;\n\tif (config.max_inodes < inodes)\n\t\tgoto out;\n\t/*\n\t * Those tests disallow limited->unlimited while any are in use;\n\t * but we must separately disallow unlimited->limited, because\n\t * in that case we have no record of how much is already in use.\n\t */\n\tif (config.max_blocks && !sbinfo->max_blocks)\n\t\tgoto out;\n\tif (config.max_inodes && !sbinfo->max_inodes)\n\t\tgoto out;\n\n\terror = 0;\n\tsbinfo->max_blocks  = config.max_blocks;\n\tsbinfo->max_inodes  = config.max_inodes;\n\tsbinfo->free_inodes = config.max_inodes - inodes;\n\n\t/*\n\t * Preserve previous mempolicy unless mpol remount option was specified.\n\t */\n\tif (config.mpol) {\n\t\tmpol_put(sbinfo->mpol);\n\t\tsbinfo->mpol = config.mpol;\t/* transfers initial ref */\n\t}\nout:\n\tspin_unlock(&sbinfo->stat_lock);\n\treturn error;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,6 +5,7 @@\n \tunsigned long inodes;\n \tint error = -EINVAL;\n \n+\tconfig.mpol = NULL;\n \tif (shmem_parse_options(data, &config, true))\n \t\treturn error;\n \n@@ -29,8 +30,13 @@\n \tsbinfo->max_inodes  = config.max_inodes;\n \tsbinfo->free_inodes = config.max_inodes - inodes;\n \n-\tmpol_put(sbinfo->mpol);\n-\tsbinfo->mpol        = config.mpol;\t/* transfers initial ref */\n+\t/*\n+\t * Preserve previous mempolicy unless mpol remount option was specified.\n+\t */\n+\tif (config.mpol) {\n+\t\tmpol_put(sbinfo->mpol);\n+\t\tsbinfo->mpol = config.mpol;\t/* transfers initial ref */\n+\t}\n out:\n \tspin_unlock(&sbinfo->stat_lock);\n \treturn error;",
        "diff_line_info": {
            "deleted_lines": [
                "\tmpol_put(sbinfo->mpol);",
                "\tsbinfo->mpol        = config.mpol;\t/* transfers initial ref */"
            ],
            "added_lines": [
                "\tconfig.mpol = NULL;",
                "\t/*",
                "\t * Preserve previous mempolicy unless mpol remount option was specified.",
                "\t */",
                "\tif (config.mpol) {",
                "\t\tmpol_put(sbinfo->mpol);",
                "\t\tsbinfo->mpol = config.mpol;\t/* transfers initial ref */",
                "\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2011-2479",
        "func_name": "torvalds/linux/collapse_huge_page",
        "description": "The Linux kernel before 2.6.39 does not properly create transparent huge pages in response to a MAP_PRIVATE mmap system call on /dev/zero, which allows local users to cause a denial of service (system crash) via a crafted application.",
        "git_url": "https://github.com/torvalds/linux/commit/78f11a255749d09025f54d4e2df4fbcb031530e2",
        "commit_title": "mm: thp: fix /dev/zero MAP_PRIVATE and vm_flags cleanups",
        "commit_text": " The huge_memory.c THP page fault was allowed to run if vm_ops was null (which would succeed for /dev/zero MAP_PRIVATE, as the f_op->mmap wouldn't setup a special vma->vm_ops and it would fallback to regular anonymous memory) but other THP logics weren't fully activated for vmas with vm_file not NULL (/dev/zero has a not NULL vma->vm_file).  So this removes the vm_file checks so that /dev/zero also can safely use THP (the other albeit safer approach to fix this bug would have been to prevent the THP initial page fault to run if vm_file was set).  After removing the vm_file checks, this also makes huge_memory.c stricter in khugepaged for the DEBUG_VM=y case.  It doesn't replace the vm_file check with a is_pfn_mapping check (but it keeps checking for VM_PFNMAP under VM_BUG_ON) because for a is_cow_mapping() mapping VM_PFNMAP should only be allowed to exist before the first page fault, and in turn when vma->anon_vma is null (so preventing khugepaged registration).  So I tend to think the previous comment saying if vm_file was set, VM_PFNMAP might have been set and we could still be registered in khugepaged (despite anon_vma was not NULL to be registered in khugepaged) was too paranoid. The is_linear_pfn_mapping check is also I think superfluous (as described by comment) but under DEBUG_VM it is safe to stay.  Addresses https://bugzilla.kernel.org/show_bug.cgi?id=33682  Cc: <stable@kernel.org>\t\t[2.6.38.x]",
        "func_before": "static void collapse_huge_page(struct mm_struct *mm,\n\t\t\t       unsigned long address,\n\t\t\t       struct page **hpage,\n\t\t\t       struct vm_area_struct *vma,\n\t\t\t       int node)\n{\n\tpgd_t *pgd;\n\tpud_t *pud;\n\tpmd_t *pmd, _pmd;\n\tpte_t *pte;\n\tpgtable_t pgtable;\n\tstruct page *new_page;\n\tspinlock_t *ptl;\n\tint isolated;\n\tunsigned long hstart, hend;\n\n\tVM_BUG_ON(address & ~HPAGE_PMD_MASK);\n#ifndef CONFIG_NUMA\n\tVM_BUG_ON(!*hpage);\n\tnew_page = *hpage;\n\tif (unlikely(mem_cgroup_newpage_charge(new_page, mm, GFP_KERNEL))) {\n\t\tup_read(&mm->mmap_sem);\n\t\treturn;\n\t}\n#else\n\tVM_BUG_ON(*hpage);\n\t/*\n\t * Allocate the page while the vma is still valid and under\n\t * the mmap_sem read mode so there is no memory allocation\n\t * later when we take the mmap_sem in write mode. This is more\n\t * friendly behavior (OTOH it may actually hide bugs) to\n\t * filesystems in userland with daemons allocating memory in\n\t * the userland I/O paths.  Allocating memory with the\n\t * mmap_sem in read mode is good idea also to allow greater\n\t * scalability.\n\t */\n\tnew_page = alloc_hugepage_vma(khugepaged_defrag(), vma, address,\n\t\t\t\t      node, __GFP_OTHER_NODE);\n\tif (unlikely(!new_page)) {\n\t\tup_read(&mm->mmap_sem);\n\t\tcount_vm_event(THP_COLLAPSE_ALLOC_FAILED);\n\t\t*hpage = ERR_PTR(-ENOMEM);\n\t\treturn;\n\t}\n\tcount_vm_event(THP_COLLAPSE_ALLOC);\n\tif (unlikely(mem_cgroup_newpage_charge(new_page, mm, GFP_KERNEL))) {\n\t\tup_read(&mm->mmap_sem);\n\t\tput_page(new_page);\n\t\treturn;\n\t}\n#endif\n\n\t/* after allocating the hugepage upgrade to mmap_sem write mode */\n\tup_read(&mm->mmap_sem);\n\n\t/*\n\t * Prevent all access to pagetables with the exception of\n\t * gup_fast later hanlded by the ptep_clear_flush and the VM\n\t * handled by the anon_vma lock + PG_lock.\n\t */\n\tdown_write(&mm->mmap_sem);\n\tif (unlikely(khugepaged_test_exit(mm)))\n\t\tgoto out;\n\n\tvma = find_vma(mm, address);\n\thstart = (vma->vm_start + ~HPAGE_PMD_MASK) & HPAGE_PMD_MASK;\n\thend = vma->vm_end & HPAGE_PMD_MASK;\n\tif (address < hstart || address + HPAGE_PMD_SIZE > hend)\n\t\tgoto out;\n\n\tif ((!(vma->vm_flags & VM_HUGEPAGE) && !khugepaged_always()) ||\n\t    (vma->vm_flags & VM_NOHUGEPAGE))\n\t\tgoto out;\n\n\t/* VM_PFNMAP vmas may have vm_ops null but vm_file set */\n\tif (!vma->anon_vma || vma->vm_ops || vma->vm_file)\n\t\tgoto out;\n\tif (is_vma_temporary_stack(vma))\n\t\tgoto out;\n\tVM_BUG_ON(is_linear_pfn_mapping(vma) || is_pfn_mapping(vma));\n\n\tpgd = pgd_offset(mm, address);\n\tif (!pgd_present(*pgd))\n\t\tgoto out;\n\n\tpud = pud_offset(pgd, address);\n\tif (!pud_present(*pud))\n\t\tgoto out;\n\n\tpmd = pmd_offset(pud, address);\n\t/* pmd can't go away or become huge under us */\n\tif (!pmd_present(*pmd) || pmd_trans_huge(*pmd))\n\t\tgoto out;\n\n\tanon_vma_lock(vma->anon_vma);\n\n\tpte = pte_offset_map(pmd, address);\n\tptl = pte_lockptr(mm, pmd);\n\n\tspin_lock(&mm->page_table_lock); /* probably unnecessary */\n\t/*\n\t * After this gup_fast can't run anymore. This also removes\n\t * any huge TLB entry from the CPU so we won't allow\n\t * huge and small TLB entries for the same virtual address\n\t * to avoid the risk of CPU bugs in that area.\n\t */\n\t_pmd = pmdp_clear_flush_notify(vma, address, pmd);\n\tspin_unlock(&mm->page_table_lock);\n\n\tspin_lock(ptl);\n\tisolated = __collapse_huge_page_isolate(vma, address, pte);\n\tspin_unlock(ptl);\n\n\tif (unlikely(!isolated)) {\n\t\tpte_unmap(pte);\n\t\tspin_lock(&mm->page_table_lock);\n\t\tBUG_ON(!pmd_none(*pmd));\n\t\tset_pmd_at(mm, address, pmd, _pmd);\n\t\tspin_unlock(&mm->page_table_lock);\n\t\tanon_vma_unlock(vma->anon_vma);\n\t\tgoto out;\n\t}\n\n\t/*\n\t * All pages are isolated and locked so anon_vma rmap\n\t * can't run anymore.\n\t */\n\tanon_vma_unlock(vma->anon_vma);\n\n\t__collapse_huge_page_copy(pte, new_page, vma, address, ptl);\n\tpte_unmap(pte);\n\t__SetPageUptodate(new_page);\n\tpgtable = pmd_pgtable(_pmd);\n\tVM_BUG_ON(page_count(pgtable) != 1);\n\tVM_BUG_ON(page_mapcount(pgtable) != 0);\n\n\t_pmd = mk_pmd(new_page, vma->vm_page_prot);\n\t_pmd = maybe_pmd_mkwrite(pmd_mkdirty(_pmd), vma);\n\t_pmd = pmd_mkhuge(_pmd);\n\n\t/*\n\t * spin_lock() below is not the equivalent of smp_wmb(), so\n\t * this is needed to avoid the copy_huge_page writes to become\n\t * visible after the set_pmd_at() write.\n\t */\n\tsmp_wmb();\n\n\tspin_lock(&mm->page_table_lock);\n\tBUG_ON(!pmd_none(*pmd));\n\tpage_add_new_anon_rmap(new_page, vma, address);\n\tset_pmd_at(mm, address, pmd, _pmd);\n\tupdate_mmu_cache(vma, address, entry);\n\tprepare_pmd_huge_pte(pgtable, mm);\n\tmm->nr_ptes--;\n\tspin_unlock(&mm->page_table_lock);\n\n#ifndef CONFIG_NUMA\n\t*hpage = NULL;\n#endif\n\tkhugepaged_pages_collapsed++;\nout_up_write:\n\tup_write(&mm->mmap_sem);\n\treturn;\n\nout:\n\tmem_cgroup_uncharge_page(new_page);\n#ifdef CONFIG_NUMA\n\tput_page(new_page);\n#endif\n\tgoto out_up_write;\n}",
        "func": "static void collapse_huge_page(struct mm_struct *mm,\n\t\t\t       unsigned long address,\n\t\t\t       struct page **hpage,\n\t\t\t       struct vm_area_struct *vma,\n\t\t\t       int node)\n{\n\tpgd_t *pgd;\n\tpud_t *pud;\n\tpmd_t *pmd, _pmd;\n\tpte_t *pte;\n\tpgtable_t pgtable;\n\tstruct page *new_page;\n\tspinlock_t *ptl;\n\tint isolated;\n\tunsigned long hstart, hend;\n\n\tVM_BUG_ON(address & ~HPAGE_PMD_MASK);\n#ifndef CONFIG_NUMA\n\tVM_BUG_ON(!*hpage);\n\tnew_page = *hpage;\n\tif (unlikely(mem_cgroup_newpage_charge(new_page, mm, GFP_KERNEL))) {\n\t\tup_read(&mm->mmap_sem);\n\t\treturn;\n\t}\n#else\n\tVM_BUG_ON(*hpage);\n\t/*\n\t * Allocate the page while the vma is still valid and under\n\t * the mmap_sem read mode so there is no memory allocation\n\t * later when we take the mmap_sem in write mode. This is more\n\t * friendly behavior (OTOH it may actually hide bugs) to\n\t * filesystems in userland with daemons allocating memory in\n\t * the userland I/O paths.  Allocating memory with the\n\t * mmap_sem in read mode is good idea also to allow greater\n\t * scalability.\n\t */\n\tnew_page = alloc_hugepage_vma(khugepaged_defrag(), vma, address,\n\t\t\t\t      node, __GFP_OTHER_NODE);\n\tif (unlikely(!new_page)) {\n\t\tup_read(&mm->mmap_sem);\n\t\tcount_vm_event(THP_COLLAPSE_ALLOC_FAILED);\n\t\t*hpage = ERR_PTR(-ENOMEM);\n\t\treturn;\n\t}\n\tcount_vm_event(THP_COLLAPSE_ALLOC);\n\tif (unlikely(mem_cgroup_newpage_charge(new_page, mm, GFP_KERNEL))) {\n\t\tup_read(&mm->mmap_sem);\n\t\tput_page(new_page);\n\t\treturn;\n\t}\n#endif\n\n\t/* after allocating the hugepage upgrade to mmap_sem write mode */\n\tup_read(&mm->mmap_sem);\n\n\t/*\n\t * Prevent all access to pagetables with the exception of\n\t * gup_fast later hanlded by the ptep_clear_flush and the VM\n\t * handled by the anon_vma lock + PG_lock.\n\t */\n\tdown_write(&mm->mmap_sem);\n\tif (unlikely(khugepaged_test_exit(mm)))\n\t\tgoto out;\n\n\tvma = find_vma(mm, address);\n\thstart = (vma->vm_start + ~HPAGE_PMD_MASK) & HPAGE_PMD_MASK;\n\thend = vma->vm_end & HPAGE_PMD_MASK;\n\tif (address < hstart || address + HPAGE_PMD_SIZE > hend)\n\t\tgoto out;\n\n\tif ((!(vma->vm_flags & VM_HUGEPAGE) && !khugepaged_always()) ||\n\t    (vma->vm_flags & VM_NOHUGEPAGE))\n\t\tgoto out;\n\n\tif (!vma->anon_vma || vma->vm_ops)\n\t\tgoto out;\n\tif (is_vma_temporary_stack(vma))\n\t\tgoto out;\n\t/*\n\t * If is_pfn_mapping() is true is_learn_pfn_mapping() must be\n\t * true too, verify it here.\n\t */\n\tVM_BUG_ON(is_linear_pfn_mapping(vma) || vma->vm_flags & VM_NO_THP);\n\n\tpgd = pgd_offset(mm, address);\n\tif (!pgd_present(*pgd))\n\t\tgoto out;\n\n\tpud = pud_offset(pgd, address);\n\tif (!pud_present(*pud))\n\t\tgoto out;\n\n\tpmd = pmd_offset(pud, address);\n\t/* pmd can't go away or become huge under us */\n\tif (!pmd_present(*pmd) || pmd_trans_huge(*pmd))\n\t\tgoto out;\n\n\tanon_vma_lock(vma->anon_vma);\n\n\tpte = pte_offset_map(pmd, address);\n\tptl = pte_lockptr(mm, pmd);\n\n\tspin_lock(&mm->page_table_lock); /* probably unnecessary */\n\t/*\n\t * After this gup_fast can't run anymore. This also removes\n\t * any huge TLB entry from the CPU so we won't allow\n\t * huge and small TLB entries for the same virtual address\n\t * to avoid the risk of CPU bugs in that area.\n\t */\n\t_pmd = pmdp_clear_flush_notify(vma, address, pmd);\n\tspin_unlock(&mm->page_table_lock);\n\n\tspin_lock(ptl);\n\tisolated = __collapse_huge_page_isolate(vma, address, pte);\n\tspin_unlock(ptl);\n\n\tif (unlikely(!isolated)) {\n\t\tpte_unmap(pte);\n\t\tspin_lock(&mm->page_table_lock);\n\t\tBUG_ON(!pmd_none(*pmd));\n\t\tset_pmd_at(mm, address, pmd, _pmd);\n\t\tspin_unlock(&mm->page_table_lock);\n\t\tanon_vma_unlock(vma->anon_vma);\n\t\tgoto out;\n\t}\n\n\t/*\n\t * All pages are isolated and locked so anon_vma rmap\n\t * can't run anymore.\n\t */\n\tanon_vma_unlock(vma->anon_vma);\n\n\t__collapse_huge_page_copy(pte, new_page, vma, address, ptl);\n\tpte_unmap(pte);\n\t__SetPageUptodate(new_page);\n\tpgtable = pmd_pgtable(_pmd);\n\tVM_BUG_ON(page_count(pgtable) != 1);\n\tVM_BUG_ON(page_mapcount(pgtable) != 0);\n\n\t_pmd = mk_pmd(new_page, vma->vm_page_prot);\n\t_pmd = maybe_pmd_mkwrite(pmd_mkdirty(_pmd), vma);\n\t_pmd = pmd_mkhuge(_pmd);\n\n\t/*\n\t * spin_lock() below is not the equivalent of smp_wmb(), so\n\t * this is needed to avoid the copy_huge_page writes to become\n\t * visible after the set_pmd_at() write.\n\t */\n\tsmp_wmb();\n\n\tspin_lock(&mm->page_table_lock);\n\tBUG_ON(!pmd_none(*pmd));\n\tpage_add_new_anon_rmap(new_page, vma, address);\n\tset_pmd_at(mm, address, pmd, _pmd);\n\tupdate_mmu_cache(vma, address, entry);\n\tprepare_pmd_huge_pte(pgtable, mm);\n\tmm->nr_ptes--;\n\tspin_unlock(&mm->page_table_lock);\n\n#ifndef CONFIG_NUMA\n\t*hpage = NULL;\n#endif\n\tkhugepaged_pages_collapsed++;\nout_up_write:\n\tup_write(&mm->mmap_sem);\n\treturn;\n\nout:\n\tmem_cgroup_uncharge_page(new_page);\n#ifdef CONFIG_NUMA\n\tput_page(new_page);\n#endif\n\tgoto out_up_write;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -72,12 +72,15 @@\n \t    (vma->vm_flags & VM_NOHUGEPAGE))\n \t\tgoto out;\n \n-\t/* VM_PFNMAP vmas may have vm_ops null but vm_file set */\n-\tif (!vma->anon_vma || vma->vm_ops || vma->vm_file)\n+\tif (!vma->anon_vma || vma->vm_ops)\n \t\tgoto out;\n \tif (is_vma_temporary_stack(vma))\n \t\tgoto out;\n-\tVM_BUG_ON(is_linear_pfn_mapping(vma) || is_pfn_mapping(vma));\n+\t/*\n+\t * If is_pfn_mapping() is true is_learn_pfn_mapping() must be\n+\t * true too, verify it here.\n+\t */\n+\tVM_BUG_ON(is_linear_pfn_mapping(vma) || vma->vm_flags & VM_NO_THP);\n \n \tpgd = pgd_offset(mm, address);\n \tif (!pgd_present(*pgd))",
        "diff_line_info": {
            "deleted_lines": [
                "\t/* VM_PFNMAP vmas may have vm_ops null but vm_file set */",
                "\tif (!vma->anon_vma || vma->vm_ops || vma->vm_file)",
                "\tVM_BUG_ON(is_linear_pfn_mapping(vma) || is_pfn_mapping(vma));"
            ],
            "added_lines": [
                "\tif (!vma->anon_vma || vma->vm_ops)",
                "\t/*",
                "\t * If is_pfn_mapping() is true is_learn_pfn_mapping() must be",
                "\t * true too, verify it here.",
                "\t */",
                "\tVM_BUG_ON(is_linear_pfn_mapping(vma) || vma->vm_flags & VM_NO_THP);"
            ]
        }
    },
    {
        "cve_id": "CVE-2011-2479",
        "func_name": "torvalds/linux/khugepaged_enter_vma_merge",
        "description": "The Linux kernel before 2.6.39 does not properly create transparent huge pages in response to a MAP_PRIVATE mmap system call on /dev/zero, which allows local users to cause a denial of service (system crash) via a crafted application.",
        "git_url": "https://github.com/torvalds/linux/commit/78f11a255749d09025f54d4e2df4fbcb031530e2",
        "commit_title": "mm: thp: fix /dev/zero MAP_PRIVATE and vm_flags cleanups",
        "commit_text": " The huge_memory.c THP page fault was allowed to run if vm_ops was null (which would succeed for /dev/zero MAP_PRIVATE, as the f_op->mmap wouldn't setup a special vma->vm_ops and it would fallback to regular anonymous memory) but other THP logics weren't fully activated for vmas with vm_file not NULL (/dev/zero has a not NULL vma->vm_file).  So this removes the vm_file checks so that /dev/zero also can safely use THP (the other albeit safer approach to fix this bug would have been to prevent the THP initial page fault to run if vm_file was set).  After removing the vm_file checks, this also makes huge_memory.c stricter in khugepaged for the DEBUG_VM=y case.  It doesn't replace the vm_file check with a is_pfn_mapping check (but it keeps checking for VM_PFNMAP under VM_BUG_ON) because for a is_cow_mapping() mapping VM_PFNMAP should only be allowed to exist before the first page fault, and in turn when vma->anon_vma is null (so preventing khugepaged registration).  So I tend to think the previous comment saying if vm_file was set, VM_PFNMAP might have been set and we could still be registered in khugepaged (despite anon_vma was not NULL to be registered in khugepaged) was too paranoid. The is_linear_pfn_mapping check is also I think superfluous (as described by comment) but under DEBUG_VM it is safe to stay.  Addresses https://bugzilla.kernel.org/show_bug.cgi?id=33682  Cc: <stable@kernel.org>\t\t[2.6.38.x]",
        "func_before": "int khugepaged_enter_vma_merge(struct vm_area_struct *vma)\n{\n\tunsigned long hstart, hend;\n\tif (!vma->anon_vma)\n\t\t/*\n\t\t * Not yet faulted in so we will register later in the\n\t\t * page fault if needed.\n\t\t */\n\t\treturn 0;\n\tif (vma->vm_file || vma->vm_ops)\n\t\t/* khugepaged not yet working on file or special mappings */\n\t\treturn 0;\n\tVM_BUG_ON(is_linear_pfn_mapping(vma) || is_pfn_mapping(vma));\n\thstart = (vma->vm_start + ~HPAGE_PMD_MASK) & HPAGE_PMD_MASK;\n\thend = vma->vm_end & HPAGE_PMD_MASK;\n\tif (hstart < hend)\n\t\treturn khugepaged_enter(vma);\n\treturn 0;\n}",
        "func": "int khugepaged_enter_vma_merge(struct vm_area_struct *vma)\n{\n\tunsigned long hstart, hend;\n\tif (!vma->anon_vma)\n\t\t/*\n\t\t * Not yet faulted in so we will register later in the\n\t\t * page fault if needed.\n\t\t */\n\t\treturn 0;\n\tif (vma->vm_ops)\n\t\t/* khugepaged not yet working on file or special mappings */\n\t\treturn 0;\n\t/*\n\t * If is_pfn_mapping() is true is_learn_pfn_mapping() must be\n\t * true too, verify it here.\n\t */\n\tVM_BUG_ON(is_linear_pfn_mapping(vma) || vma->vm_flags & VM_NO_THP);\n\thstart = (vma->vm_start + ~HPAGE_PMD_MASK) & HPAGE_PMD_MASK;\n\thend = vma->vm_end & HPAGE_PMD_MASK;\n\tif (hstart < hend)\n\t\treturn khugepaged_enter(vma);\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -7,10 +7,14 @@\n \t\t * page fault if needed.\n \t\t */\n \t\treturn 0;\n-\tif (vma->vm_file || vma->vm_ops)\n+\tif (vma->vm_ops)\n \t\t/* khugepaged not yet working on file or special mappings */\n \t\treturn 0;\n-\tVM_BUG_ON(is_linear_pfn_mapping(vma) || is_pfn_mapping(vma));\n+\t/*\n+\t * If is_pfn_mapping() is true is_learn_pfn_mapping() must be\n+\t * true too, verify it here.\n+\t */\n+\tVM_BUG_ON(is_linear_pfn_mapping(vma) || vma->vm_flags & VM_NO_THP);\n \thstart = (vma->vm_start + ~HPAGE_PMD_MASK) & HPAGE_PMD_MASK;\n \thend = vma->vm_end & HPAGE_PMD_MASK;\n \tif (hstart < hend)",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (vma->vm_file || vma->vm_ops)",
                "\tVM_BUG_ON(is_linear_pfn_mapping(vma) || is_pfn_mapping(vma));"
            ],
            "added_lines": [
                "\tif (vma->vm_ops)",
                "\t/*",
                "\t * If is_pfn_mapping() is true is_learn_pfn_mapping() must be",
                "\t * true too, verify it here.",
                "\t */",
                "\tVM_BUG_ON(is_linear_pfn_mapping(vma) || vma->vm_flags & VM_NO_THP);"
            ]
        }
    },
    {
        "cve_id": "CVE-2011-2479",
        "func_name": "torvalds/linux/khugepaged_scan_mm_slot",
        "description": "The Linux kernel before 2.6.39 does not properly create transparent huge pages in response to a MAP_PRIVATE mmap system call on /dev/zero, which allows local users to cause a denial of service (system crash) via a crafted application.",
        "git_url": "https://github.com/torvalds/linux/commit/78f11a255749d09025f54d4e2df4fbcb031530e2",
        "commit_title": "mm: thp: fix /dev/zero MAP_PRIVATE and vm_flags cleanups",
        "commit_text": " The huge_memory.c THP page fault was allowed to run if vm_ops was null (which would succeed for /dev/zero MAP_PRIVATE, as the f_op->mmap wouldn't setup a special vma->vm_ops and it would fallback to regular anonymous memory) but other THP logics weren't fully activated for vmas with vm_file not NULL (/dev/zero has a not NULL vma->vm_file).  So this removes the vm_file checks so that /dev/zero also can safely use THP (the other albeit safer approach to fix this bug would have been to prevent the THP initial page fault to run if vm_file was set).  After removing the vm_file checks, this also makes huge_memory.c stricter in khugepaged for the DEBUG_VM=y case.  It doesn't replace the vm_file check with a is_pfn_mapping check (but it keeps checking for VM_PFNMAP under VM_BUG_ON) because for a is_cow_mapping() mapping VM_PFNMAP should only be allowed to exist before the first page fault, and in turn when vma->anon_vma is null (so preventing khugepaged registration).  So I tend to think the previous comment saying if vm_file was set, VM_PFNMAP might have been set and we could still be registered in khugepaged (despite anon_vma was not NULL to be registered in khugepaged) was too paranoid. The is_linear_pfn_mapping check is also I think superfluous (as described by comment) but under DEBUG_VM it is safe to stay.  Addresses https://bugzilla.kernel.org/show_bug.cgi?id=33682  Cc: <stable@kernel.org>\t\t[2.6.38.x]",
        "func_before": "static unsigned int khugepaged_scan_mm_slot(unsigned int pages,\n\t\t\t\t\t    struct page **hpage)\n{\n\tstruct mm_slot *mm_slot;\n\tstruct mm_struct *mm;\n\tstruct vm_area_struct *vma;\n\tint progress = 0;\n\n\tVM_BUG_ON(!pages);\n\tVM_BUG_ON(!spin_is_locked(&khugepaged_mm_lock));\n\n\tif (khugepaged_scan.mm_slot)\n\t\tmm_slot = khugepaged_scan.mm_slot;\n\telse {\n\t\tmm_slot = list_entry(khugepaged_scan.mm_head.next,\n\t\t\t\t     struct mm_slot, mm_node);\n\t\tkhugepaged_scan.address = 0;\n\t\tkhugepaged_scan.mm_slot = mm_slot;\n\t}\n\tspin_unlock(&khugepaged_mm_lock);\n\n\tmm = mm_slot->mm;\n\tdown_read(&mm->mmap_sem);\n\tif (unlikely(khugepaged_test_exit(mm)))\n\t\tvma = NULL;\n\telse\n\t\tvma = find_vma(mm, khugepaged_scan.address);\n\n\tprogress++;\n\tfor (; vma; vma = vma->vm_next) {\n\t\tunsigned long hstart, hend;\n\n\t\tcond_resched();\n\t\tif (unlikely(khugepaged_test_exit(mm))) {\n\t\t\tprogress++;\n\t\t\tbreak;\n\t\t}\n\n\t\tif ((!(vma->vm_flags & VM_HUGEPAGE) &&\n\t\t     !khugepaged_always()) ||\n\t\t    (vma->vm_flags & VM_NOHUGEPAGE)) {\n\t\tskip:\n\t\t\tprogress++;\n\t\t\tcontinue;\n\t\t}\n\t\t/* VM_PFNMAP vmas may have vm_ops null but vm_file set */\n\t\tif (!vma->anon_vma || vma->vm_ops || vma->vm_file)\n\t\t\tgoto skip;\n\t\tif (is_vma_temporary_stack(vma))\n\t\t\tgoto skip;\n\n\t\tVM_BUG_ON(is_linear_pfn_mapping(vma) || is_pfn_mapping(vma));\n\n\t\thstart = (vma->vm_start + ~HPAGE_PMD_MASK) & HPAGE_PMD_MASK;\n\t\thend = vma->vm_end & HPAGE_PMD_MASK;\n\t\tif (hstart >= hend)\n\t\t\tgoto skip;\n\t\tif (khugepaged_scan.address > hend)\n\t\t\tgoto skip;\n\t\tif (khugepaged_scan.address < hstart)\n\t\t\tkhugepaged_scan.address = hstart;\n\t\tVM_BUG_ON(khugepaged_scan.address & ~HPAGE_PMD_MASK);\n\n\t\twhile (khugepaged_scan.address < hend) {\n\t\t\tint ret;\n\t\t\tcond_resched();\n\t\t\tif (unlikely(khugepaged_test_exit(mm)))\n\t\t\t\tgoto breakouterloop;\n\n\t\t\tVM_BUG_ON(khugepaged_scan.address < hstart ||\n\t\t\t\t  khugepaged_scan.address + HPAGE_PMD_SIZE >\n\t\t\t\t  hend);\n\t\t\tret = khugepaged_scan_pmd(mm, vma,\n\t\t\t\t\t\t  khugepaged_scan.address,\n\t\t\t\t\t\t  hpage);\n\t\t\t/* move to next address */\n\t\t\tkhugepaged_scan.address += HPAGE_PMD_SIZE;\n\t\t\tprogress += HPAGE_PMD_NR;\n\t\t\tif (ret)\n\t\t\t\t/* we released mmap_sem so break loop */\n\t\t\t\tgoto breakouterloop_mmap_sem;\n\t\t\tif (progress >= pages)\n\t\t\t\tgoto breakouterloop;\n\t\t}\n\t}\nbreakouterloop:\n\tup_read(&mm->mmap_sem); /* exit_mmap will destroy ptes after this */\nbreakouterloop_mmap_sem:\n\n\tspin_lock(&khugepaged_mm_lock);\n\tVM_BUG_ON(khugepaged_scan.mm_slot != mm_slot);\n\t/*\n\t * Release the current mm_slot if this mm is about to die, or\n\t * if we scanned all vmas of this mm.\n\t */\n\tif (khugepaged_test_exit(mm) || !vma) {\n\t\t/*\n\t\t * Make sure that if mm_users is reaching zero while\n\t\t * khugepaged runs here, khugepaged_exit will find\n\t\t * mm_slot not pointing to the exiting mm.\n\t\t */\n\t\tif (mm_slot->mm_node.next != &khugepaged_scan.mm_head) {\n\t\t\tkhugepaged_scan.mm_slot = list_entry(\n\t\t\t\tmm_slot->mm_node.next,\n\t\t\t\tstruct mm_slot, mm_node);\n\t\t\tkhugepaged_scan.address = 0;\n\t\t} else {\n\t\t\tkhugepaged_scan.mm_slot = NULL;\n\t\t\tkhugepaged_full_scans++;\n\t\t}\n\n\t\tcollect_mm_slot(mm_slot);\n\t}\n\n\treturn progress;\n}",
        "func": "static unsigned int khugepaged_scan_mm_slot(unsigned int pages,\n\t\t\t\t\t    struct page **hpage)\n{\n\tstruct mm_slot *mm_slot;\n\tstruct mm_struct *mm;\n\tstruct vm_area_struct *vma;\n\tint progress = 0;\n\n\tVM_BUG_ON(!pages);\n\tVM_BUG_ON(!spin_is_locked(&khugepaged_mm_lock));\n\n\tif (khugepaged_scan.mm_slot)\n\t\tmm_slot = khugepaged_scan.mm_slot;\n\telse {\n\t\tmm_slot = list_entry(khugepaged_scan.mm_head.next,\n\t\t\t\t     struct mm_slot, mm_node);\n\t\tkhugepaged_scan.address = 0;\n\t\tkhugepaged_scan.mm_slot = mm_slot;\n\t}\n\tspin_unlock(&khugepaged_mm_lock);\n\n\tmm = mm_slot->mm;\n\tdown_read(&mm->mmap_sem);\n\tif (unlikely(khugepaged_test_exit(mm)))\n\t\tvma = NULL;\n\telse\n\t\tvma = find_vma(mm, khugepaged_scan.address);\n\n\tprogress++;\n\tfor (; vma; vma = vma->vm_next) {\n\t\tunsigned long hstart, hend;\n\n\t\tcond_resched();\n\t\tif (unlikely(khugepaged_test_exit(mm))) {\n\t\t\tprogress++;\n\t\t\tbreak;\n\t\t}\n\n\t\tif ((!(vma->vm_flags & VM_HUGEPAGE) &&\n\t\t     !khugepaged_always()) ||\n\t\t    (vma->vm_flags & VM_NOHUGEPAGE)) {\n\t\tskip:\n\t\t\tprogress++;\n\t\t\tcontinue;\n\t\t}\n\t\tif (!vma->anon_vma || vma->vm_ops)\n\t\t\tgoto skip;\n\t\tif (is_vma_temporary_stack(vma))\n\t\t\tgoto skip;\n\t\t/*\n\t\t * If is_pfn_mapping() is true is_learn_pfn_mapping()\n\t\t * must be true too, verify it here.\n\t\t */\n\t\tVM_BUG_ON(is_linear_pfn_mapping(vma) ||\n\t\t\t  vma->vm_flags & VM_NO_THP);\n\n\t\thstart = (vma->vm_start + ~HPAGE_PMD_MASK) & HPAGE_PMD_MASK;\n\t\thend = vma->vm_end & HPAGE_PMD_MASK;\n\t\tif (hstart >= hend)\n\t\t\tgoto skip;\n\t\tif (khugepaged_scan.address > hend)\n\t\t\tgoto skip;\n\t\tif (khugepaged_scan.address < hstart)\n\t\t\tkhugepaged_scan.address = hstart;\n\t\tVM_BUG_ON(khugepaged_scan.address & ~HPAGE_PMD_MASK);\n\n\t\twhile (khugepaged_scan.address < hend) {\n\t\t\tint ret;\n\t\t\tcond_resched();\n\t\t\tif (unlikely(khugepaged_test_exit(mm)))\n\t\t\t\tgoto breakouterloop;\n\n\t\t\tVM_BUG_ON(khugepaged_scan.address < hstart ||\n\t\t\t\t  khugepaged_scan.address + HPAGE_PMD_SIZE >\n\t\t\t\t  hend);\n\t\t\tret = khugepaged_scan_pmd(mm, vma,\n\t\t\t\t\t\t  khugepaged_scan.address,\n\t\t\t\t\t\t  hpage);\n\t\t\t/* move to next address */\n\t\t\tkhugepaged_scan.address += HPAGE_PMD_SIZE;\n\t\t\tprogress += HPAGE_PMD_NR;\n\t\t\tif (ret)\n\t\t\t\t/* we released mmap_sem so break loop */\n\t\t\t\tgoto breakouterloop_mmap_sem;\n\t\t\tif (progress >= pages)\n\t\t\t\tgoto breakouterloop;\n\t\t}\n\t}\nbreakouterloop:\n\tup_read(&mm->mmap_sem); /* exit_mmap will destroy ptes after this */\nbreakouterloop_mmap_sem:\n\n\tspin_lock(&khugepaged_mm_lock);\n\tVM_BUG_ON(khugepaged_scan.mm_slot != mm_slot);\n\t/*\n\t * Release the current mm_slot if this mm is about to die, or\n\t * if we scanned all vmas of this mm.\n\t */\n\tif (khugepaged_test_exit(mm) || !vma) {\n\t\t/*\n\t\t * Make sure that if mm_users is reaching zero while\n\t\t * khugepaged runs here, khugepaged_exit will find\n\t\t * mm_slot not pointing to the exiting mm.\n\t\t */\n\t\tif (mm_slot->mm_node.next != &khugepaged_scan.mm_head) {\n\t\t\tkhugepaged_scan.mm_slot = list_entry(\n\t\t\t\tmm_slot->mm_node.next,\n\t\t\t\tstruct mm_slot, mm_node);\n\t\t\tkhugepaged_scan.address = 0;\n\t\t} else {\n\t\t\tkhugepaged_scan.mm_slot = NULL;\n\t\t\tkhugepaged_full_scans++;\n\t\t}\n\n\t\tcollect_mm_slot(mm_slot);\n\t}\n\n\treturn progress;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -43,13 +43,16 @@\n \t\t\tprogress++;\n \t\t\tcontinue;\n \t\t}\n-\t\t/* VM_PFNMAP vmas may have vm_ops null but vm_file set */\n-\t\tif (!vma->anon_vma || vma->vm_ops || vma->vm_file)\n+\t\tif (!vma->anon_vma || vma->vm_ops)\n \t\t\tgoto skip;\n \t\tif (is_vma_temporary_stack(vma))\n \t\t\tgoto skip;\n-\n-\t\tVM_BUG_ON(is_linear_pfn_mapping(vma) || is_pfn_mapping(vma));\n+\t\t/*\n+\t\t * If is_pfn_mapping() is true is_learn_pfn_mapping()\n+\t\t * must be true too, verify it here.\n+\t\t */\n+\t\tVM_BUG_ON(is_linear_pfn_mapping(vma) ||\n+\t\t\t  vma->vm_flags & VM_NO_THP);\n \n \t\thstart = (vma->vm_start + ~HPAGE_PMD_MASK) & HPAGE_PMD_MASK;\n \t\thend = vma->vm_end & HPAGE_PMD_MASK;",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t/* VM_PFNMAP vmas may have vm_ops null but vm_file set */",
                "\t\tif (!vma->anon_vma || vma->vm_ops || vma->vm_file)",
                "",
                "\t\tVM_BUG_ON(is_linear_pfn_mapping(vma) || is_pfn_mapping(vma));"
            ],
            "added_lines": [
                "\t\tif (!vma->anon_vma || vma->vm_ops)",
                "\t\t/*",
                "\t\t * If is_pfn_mapping() is true is_learn_pfn_mapping()",
                "\t\t * must be true too, verify it here.",
                "\t\t */",
                "\t\tVM_BUG_ON(is_linear_pfn_mapping(vma) ||",
                "\t\t\t  vma->vm_flags & VM_NO_THP);"
            ]
        }
    },
    {
        "cve_id": "CVE-2011-2479",
        "func_name": "torvalds/linux/hugepage_madvise",
        "description": "The Linux kernel before 2.6.39 does not properly create transparent huge pages in response to a MAP_PRIVATE mmap system call on /dev/zero, which allows local users to cause a denial of service (system crash) via a crafted application.",
        "git_url": "https://github.com/torvalds/linux/commit/78f11a255749d09025f54d4e2df4fbcb031530e2",
        "commit_title": "mm: thp: fix /dev/zero MAP_PRIVATE and vm_flags cleanups",
        "commit_text": " The huge_memory.c THP page fault was allowed to run if vm_ops was null (which would succeed for /dev/zero MAP_PRIVATE, as the f_op->mmap wouldn't setup a special vma->vm_ops and it would fallback to regular anonymous memory) but other THP logics weren't fully activated for vmas with vm_file not NULL (/dev/zero has a not NULL vma->vm_file).  So this removes the vm_file checks so that /dev/zero also can safely use THP (the other albeit safer approach to fix this bug would have been to prevent the THP initial page fault to run if vm_file was set).  After removing the vm_file checks, this also makes huge_memory.c stricter in khugepaged for the DEBUG_VM=y case.  It doesn't replace the vm_file check with a is_pfn_mapping check (but it keeps checking for VM_PFNMAP under VM_BUG_ON) because for a is_cow_mapping() mapping VM_PFNMAP should only be allowed to exist before the first page fault, and in turn when vma->anon_vma is null (so preventing khugepaged registration).  So I tend to think the previous comment saying if vm_file was set, VM_PFNMAP might have been set and we could still be registered in khugepaged (despite anon_vma was not NULL to be registered in khugepaged) was too paranoid. The is_linear_pfn_mapping check is also I think superfluous (as described by comment) but under DEBUG_VM it is safe to stay.  Addresses https://bugzilla.kernel.org/show_bug.cgi?id=33682  Cc: <stable@kernel.org>\t\t[2.6.38.x]",
        "func_before": "int hugepage_madvise(struct vm_area_struct *vma,\n\t\t     unsigned long *vm_flags, int advice)\n{\n\tswitch (advice) {\n\tcase MADV_HUGEPAGE:\n\t\t/*\n\t\t * Be somewhat over-protective like KSM for now!\n\t\t */\n\t\tif (*vm_flags & (VM_HUGEPAGE |\n\t\t\t\t VM_SHARED   | VM_MAYSHARE   |\n\t\t\t\t VM_PFNMAP   | VM_IO      | VM_DONTEXPAND |\n\t\t\t\t VM_RESERVED | VM_HUGETLB | VM_INSERTPAGE |\n\t\t\t\t VM_MIXEDMAP | VM_SAO))\n\t\t\treturn -EINVAL;\n\t\t*vm_flags &= ~VM_NOHUGEPAGE;\n\t\t*vm_flags |= VM_HUGEPAGE;\n\t\t/*\n\t\t * If the vma become good for khugepaged to scan,\n\t\t * register it here without waiting a page fault that\n\t\t * may not happen any time soon.\n\t\t */\n\t\tif (unlikely(khugepaged_enter_vma_merge(vma)))\n\t\t\treturn -ENOMEM;\n\t\tbreak;\n\tcase MADV_NOHUGEPAGE:\n\t\t/*\n\t\t * Be somewhat over-protective like KSM for now!\n\t\t */\n\t\tif (*vm_flags & (VM_NOHUGEPAGE |\n\t\t\t\t VM_SHARED   | VM_MAYSHARE   |\n\t\t\t\t VM_PFNMAP   | VM_IO      | VM_DONTEXPAND |\n\t\t\t\t VM_RESERVED | VM_HUGETLB | VM_INSERTPAGE |\n\t\t\t\t VM_MIXEDMAP | VM_SAO))\n\t\t\treturn -EINVAL;\n\t\t*vm_flags &= ~VM_HUGEPAGE;\n\t\t*vm_flags |= VM_NOHUGEPAGE;\n\t\t/*\n\t\t * Setting VM_NOHUGEPAGE will prevent khugepaged from scanning\n\t\t * this vma even if we leave the mm registered in khugepaged if\n\t\t * it got registered before VM_NOHUGEPAGE was set.\n\t\t */\n\t\tbreak;\n\t}\n\n\treturn 0;\n}",
        "func": "int hugepage_madvise(struct vm_area_struct *vma,\n\t\t     unsigned long *vm_flags, int advice)\n{\n\tswitch (advice) {\n\tcase MADV_HUGEPAGE:\n\t\t/*\n\t\t * Be somewhat over-protective like KSM for now!\n\t\t */\n\t\tif (*vm_flags & (VM_HUGEPAGE | VM_NO_THP))\n\t\t\treturn -EINVAL;\n\t\t*vm_flags &= ~VM_NOHUGEPAGE;\n\t\t*vm_flags |= VM_HUGEPAGE;\n\t\t/*\n\t\t * If the vma become good for khugepaged to scan,\n\t\t * register it here without waiting a page fault that\n\t\t * may not happen any time soon.\n\t\t */\n\t\tif (unlikely(khugepaged_enter_vma_merge(vma)))\n\t\t\treturn -ENOMEM;\n\t\tbreak;\n\tcase MADV_NOHUGEPAGE:\n\t\t/*\n\t\t * Be somewhat over-protective like KSM for now!\n\t\t */\n\t\tif (*vm_flags & (VM_NOHUGEPAGE | VM_NO_THP))\n\t\t\treturn -EINVAL;\n\t\t*vm_flags &= ~VM_HUGEPAGE;\n\t\t*vm_flags |= VM_NOHUGEPAGE;\n\t\t/*\n\t\t * Setting VM_NOHUGEPAGE will prevent khugepaged from scanning\n\t\t * this vma even if we leave the mm registered in khugepaged if\n\t\t * it got registered before VM_NOHUGEPAGE was set.\n\t\t */\n\t\tbreak;\n\t}\n\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -6,11 +6,7 @@\n \t\t/*\n \t\t * Be somewhat over-protective like KSM for now!\n \t\t */\n-\t\tif (*vm_flags & (VM_HUGEPAGE |\n-\t\t\t\t VM_SHARED   | VM_MAYSHARE   |\n-\t\t\t\t VM_PFNMAP   | VM_IO      | VM_DONTEXPAND |\n-\t\t\t\t VM_RESERVED | VM_HUGETLB | VM_INSERTPAGE |\n-\t\t\t\t VM_MIXEDMAP | VM_SAO))\n+\t\tif (*vm_flags & (VM_HUGEPAGE | VM_NO_THP))\n \t\t\treturn -EINVAL;\n \t\t*vm_flags &= ~VM_NOHUGEPAGE;\n \t\t*vm_flags |= VM_HUGEPAGE;\n@@ -26,11 +22,7 @@\n \t\t/*\n \t\t * Be somewhat over-protective like KSM for now!\n \t\t */\n-\t\tif (*vm_flags & (VM_NOHUGEPAGE |\n-\t\t\t\t VM_SHARED   | VM_MAYSHARE   |\n-\t\t\t\t VM_PFNMAP   | VM_IO      | VM_DONTEXPAND |\n-\t\t\t\t VM_RESERVED | VM_HUGETLB | VM_INSERTPAGE |\n-\t\t\t\t VM_MIXEDMAP | VM_SAO))\n+\t\tif (*vm_flags & (VM_NOHUGEPAGE | VM_NO_THP))\n \t\t\treturn -EINVAL;\n \t\t*vm_flags &= ~VM_HUGEPAGE;\n \t\t*vm_flags |= VM_NOHUGEPAGE;",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tif (*vm_flags & (VM_HUGEPAGE |",
                "\t\t\t\t VM_SHARED   | VM_MAYSHARE   |",
                "\t\t\t\t VM_PFNMAP   | VM_IO      | VM_DONTEXPAND |",
                "\t\t\t\t VM_RESERVED | VM_HUGETLB | VM_INSERTPAGE |",
                "\t\t\t\t VM_MIXEDMAP | VM_SAO))",
                "\t\tif (*vm_flags & (VM_NOHUGEPAGE |",
                "\t\t\t\t VM_SHARED   | VM_MAYSHARE   |",
                "\t\t\t\t VM_PFNMAP   | VM_IO      | VM_DONTEXPAND |",
                "\t\t\t\t VM_RESERVED | VM_HUGETLB | VM_INSERTPAGE |",
                "\t\t\t\t VM_MIXEDMAP | VM_SAO))"
            ],
            "added_lines": [
                "\t\tif (*vm_flags & (VM_HUGEPAGE | VM_NO_THP))",
                "\t\tif (*vm_flags & (VM_NOHUGEPAGE | VM_NO_THP))"
            ]
        }
    },
    {
        "cve_id": "CVE-2011-2479",
        "func_name": "torvalds/linux/vma_adjust_trans_huge",
        "description": "The Linux kernel before 2.6.39 does not properly create transparent huge pages in response to a MAP_PRIVATE mmap system call on /dev/zero, which allows local users to cause a denial of service (system crash) via a crafted application.",
        "git_url": "https://github.com/torvalds/linux/commit/78f11a255749d09025f54d4e2df4fbcb031530e2",
        "commit_title": "mm: thp: fix /dev/zero MAP_PRIVATE and vm_flags cleanups",
        "commit_text": " The huge_memory.c THP page fault was allowed to run if vm_ops was null (which would succeed for /dev/zero MAP_PRIVATE, as the f_op->mmap wouldn't setup a special vma->vm_ops and it would fallback to regular anonymous memory) but other THP logics weren't fully activated for vmas with vm_file not NULL (/dev/zero has a not NULL vma->vm_file).  So this removes the vm_file checks so that /dev/zero also can safely use THP (the other albeit safer approach to fix this bug would have been to prevent the THP initial page fault to run if vm_file was set).  After removing the vm_file checks, this also makes huge_memory.c stricter in khugepaged for the DEBUG_VM=y case.  It doesn't replace the vm_file check with a is_pfn_mapping check (but it keeps checking for VM_PFNMAP under VM_BUG_ON) because for a is_cow_mapping() mapping VM_PFNMAP should only be allowed to exist before the first page fault, and in turn when vma->anon_vma is null (so preventing khugepaged registration).  So I tend to think the previous comment saying if vm_file was set, VM_PFNMAP might have been set and we could still be registered in khugepaged (despite anon_vma was not NULL to be registered in khugepaged) was too paranoid. The is_linear_pfn_mapping check is also I think superfluous (as described by comment) but under DEBUG_VM it is safe to stay.  Addresses https://bugzilla.kernel.org/show_bug.cgi?id=33682  Cc: <stable@kernel.org>\t\t[2.6.38.x]",
        "func_before": "static inline void vma_adjust_trans_huge(struct vm_area_struct *vma,\n\t\t\t\t\t unsigned long start,\n\t\t\t\t\t unsigned long end,\n\t\t\t\t\t long adjust_next)\n{\n\tif (!vma->anon_vma || vma->vm_ops || vma->vm_file)\n\t\treturn;\n\t__vma_adjust_trans_huge(vma, start, end, adjust_next);\n}",
        "func": "static inline void vma_adjust_trans_huge(struct vm_area_struct *vma,\n\t\t\t\t\t unsigned long start,\n\t\t\t\t\t unsigned long end,\n\t\t\t\t\t long adjust_next)\n{\n\tif (!vma->anon_vma || vma->vm_ops)\n\t\treturn;\n\t__vma_adjust_trans_huge(vma, start, end, adjust_next);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,7 +3,7 @@\n \t\t\t\t\t unsigned long end,\n \t\t\t\t\t long adjust_next)\n {\n-\tif (!vma->anon_vma || vma->vm_ops || vma->vm_file)\n+\tif (!vma->anon_vma || vma->vm_ops)\n \t\treturn;\n \t__vma_adjust_trans_huge(vma, start, end, adjust_next);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (!vma->anon_vma || vma->vm_ops || vma->vm_file)"
            ],
            "added_lines": [
                "\tif (!vma->anon_vma || vma->vm_ops)"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-1797",
        "func_name": "torvalds/linux/kvm_set_guest_paused",
        "description": "Use-after-free vulnerability in arch/x86/kvm/x86.c in the Linux kernel through 3.8.4 allows guest OS users to cause a denial of service (host OS memory corruption) or possibly have unspecified other impact via a crafted application that triggers use of a guest physical address (GPA) in (1) movable or (2) removable memory during an MSR_KVM_SYSTEM_TIME kvm_set_msr_common operation.",
        "git_url": "https://github.com/torvalds/linux/commit/0b79459b482e85cb7426aa7da683a9f2c97aeae1",
        "commit_title": "KVM: x86: Convert MSR_KVM_SYSTEM_TIME to use gfn_to_hva_cache functions (CVE-2013-1797)",
        "commit_text": " There is a potential use after free issue with the handling of MSR_KVM_SYSTEM_TIME.  If the guest specifies a GPA in a movable or removable memory such as frame buffers then KVM might continue to write to that address even after it's removed via KVM_SET_USER_MEMORY_REGION.  KVM pins the page in memory so it's unlikely to cause an issue, but if the user space component re-purposes the memory previously used for the guest, then the guest will be able to corrupt that memory.  Tested: Tested against kvmclock unit test ",
        "func_before": "static int kvm_set_guest_paused(struct kvm_vcpu *vcpu)\n{\n\tif (!vcpu->arch.time_page)\n\t\treturn -EINVAL;\n\tvcpu->arch.pvclock_set_guest_stopped_request = true;\n\tkvm_make_request(KVM_REQ_CLOCK_UPDATE, vcpu);\n\treturn 0;\n}",
        "func": "static int kvm_set_guest_paused(struct kvm_vcpu *vcpu)\n{\n\tif (!vcpu->arch.pv_time_enabled)\n\t\treturn -EINVAL;\n\tvcpu->arch.pvclock_set_guest_stopped_request = true;\n\tkvm_make_request(KVM_REQ_CLOCK_UPDATE, vcpu);\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,6 @@\n static int kvm_set_guest_paused(struct kvm_vcpu *vcpu)\n {\n-\tif (!vcpu->arch.time_page)\n+\tif (!vcpu->arch.pv_time_enabled)\n \t\treturn -EINVAL;\n \tvcpu->arch.pvclock_set_guest_stopped_request = true;\n \tkvm_make_request(KVM_REQ_CLOCK_UPDATE, vcpu);",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (!vcpu->arch.time_page)"
            ],
            "added_lines": [
                "\tif (!vcpu->arch.pv_time_enabled)"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-1797",
        "func_name": "torvalds/linux/kvmclock_reset",
        "description": "Use-after-free vulnerability in arch/x86/kvm/x86.c in the Linux kernel through 3.8.4 allows guest OS users to cause a denial of service (host OS memory corruption) or possibly have unspecified other impact via a crafted application that triggers use of a guest physical address (GPA) in (1) movable or (2) removable memory during an MSR_KVM_SYSTEM_TIME kvm_set_msr_common operation.",
        "git_url": "https://github.com/torvalds/linux/commit/0b79459b482e85cb7426aa7da683a9f2c97aeae1",
        "commit_title": "KVM: x86: Convert MSR_KVM_SYSTEM_TIME to use gfn_to_hva_cache functions (CVE-2013-1797)",
        "commit_text": " There is a potential use after free issue with the handling of MSR_KVM_SYSTEM_TIME.  If the guest specifies a GPA in a movable or removable memory such as frame buffers then KVM might continue to write to that address even after it's removed via KVM_SET_USER_MEMORY_REGION.  KVM pins the page in memory so it's unlikely to cause an issue, but if the user space component re-purposes the memory previously used for the guest, then the guest will be able to corrupt that memory.  Tested: Tested against kvmclock unit test ",
        "func_before": "static void kvmclock_reset(struct kvm_vcpu *vcpu)\n{\n\tif (vcpu->arch.time_page) {\n\t\tkvm_release_page_dirty(vcpu->arch.time_page);\n\t\tvcpu->arch.time_page = NULL;\n\t}\n}",
        "func": "static void kvmclock_reset(struct kvm_vcpu *vcpu)\n{\n\tvcpu->arch.pv_time_enabled = false;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,7 +1,4 @@\n static void kvmclock_reset(struct kvm_vcpu *vcpu)\n {\n-\tif (vcpu->arch.time_page) {\n-\t\tkvm_release_page_dirty(vcpu->arch.time_page);\n-\t\tvcpu->arch.time_page = NULL;\n-\t}\n+\tvcpu->arch.pv_time_enabled = false;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (vcpu->arch.time_page) {",
                "\t\tkvm_release_page_dirty(vcpu->arch.time_page);",
                "\t\tvcpu->arch.time_page = NULL;",
                "\t}"
            ],
            "added_lines": [
                "\tvcpu->arch.pv_time_enabled = false;"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-1797",
        "func_name": "torvalds/linux/kvm_set_msr_common",
        "description": "Use-after-free vulnerability in arch/x86/kvm/x86.c in the Linux kernel through 3.8.4 allows guest OS users to cause a denial of service (host OS memory corruption) or possibly have unspecified other impact via a crafted application that triggers use of a guest physical address (GPA) in (1) movable or (2) removable memory during an MSR_KVM_SYSTEM_TIME kvm_set_msr_common operation.",
        "git_url": "https://github.com/torvalds/linux/commit/0b79459b482e85cb7426aa7da683a9f2c97aeae1",
        "commit_title": "KVM: x86: Convert MSR_KVM_SYSTEM_TIME to use gfn_to_hva_cache functions (CVE-2013-1797)",
        "commit_text": " There is a potential use after free issue with the handling of MSR_KVM_SYSTEM_TIME.  If the guest specifies a GPA in a movable or removable memory such as frame buffers then KVM might continue to write to that address even after it's removed via KVM_SET_USER_MEMORY_REGION.  KVM pins the page in memory so it's unlikely to cause an issue, but if the user space component re-purposes the memory previously used for the guest, then the guest will be able to corrupt that memory.  Tested: Tested against kvmclock unit test ",
        "func_before": "int kvm_set_msr_common(struct kvm_vcpu *vcpu, struct msr_data *msr_info)\n{\n\tbool pr = false;\n\tu32 msr = msr_info->index;\n\tu64 data = msr_info->data;\n\n\tswitch (msr) {\n\tcase MSR_AMD64_NB_CFG:\n\tcase MSR_IA32_UCODE_REV:\n\tcase MSR_IA32_UCODE_WRITE:\n\tcase MSR_VM_HSAVE_PA:\n\tcase MSR_AMD64_PATCH_LOADER:\n\tcase MSR_AMD64_BU_CFG2:\n\t\tbreak;\n\n\tcase MSR_EFER:\n\t\treturn set_efer(vcpu, data);\n\tcase MSR_K7_HWCR:\n\t\tdata &= ~(u64)0x40;\t/* ignore flush filter disable */\n\t\tdata &= ~(u64)0x100;\t/* ignore ignne emulation enable */\n\t\tdata &= ~(u64)0x8;\t/* ignore TLB cache disable */\n\t\tif (data != 0) {\n\t\t\tvcpu_unimpl(vcpu, \"unimplemented HWCR wrmsr: 0x%llx\\n\",\n\t\t\t\t    data);\n\t\t\treturn 1;\n\t\t}\n\t\tbreak;\n\tcase MSR_FAM10H_MMIO_CONF_BASE:\n\t\tif (data != 0) {\n\t\t\tvcpu_unimpl(vcpu, \"unimplemented MMIO_CONF_BASE wrmsr: \"\n\t\t\t\t    \"0x%llx\\n\", data);\n\t\t\treturn 1;\n\t\t}\n\t\tbreak;\n\tcase MSR_IA32_DEBUGCTLMSR:\n\t\tif (!data) {\n\t\t\t/* We support the non-activated case already */\n\t\t\tbreak;\n\t\t} else if (data & ~(DEBUGCTLMSR_LBR | DEBUGCTLMSR_BTF)) {\n\t\t\t/* Values other than LBR and BTF are vendor-specific,\n\t\t\t   thus reserved and should throw a #GP */\n\t\t\treturn 1;\n\t\t}\n\t\tvcpu_unimpl(vcpu, \"%s: MSR_IA32_DEBUGCTLMSR 0x%llx, nop\\n\",\n\t\t\t    __func__, data);\n\t\tbreak;\n\tcase 0x200 ... 0x2ff:\n\t\treturn set_msr_mtrr(vcpu, msr, data);\n\tcase MSR_IA32_APICBASE:\n\t\tkvm_set_apic_base(vcpu, data);\n\t\tbreak;\n\tcase APIC_BASE_MSR ... APIC_BASE_MSR + 0x3ff:\n\t\treturn kvm_x2apic_msr_write(vcpu, msr, data);\n\tcase MSR_IA32_TSCDEADLINE:\n\t\tkvm_set_lapic_tscdeadline_msr(vcpu, data);\n\t\tbreak;\n\tcase MSR_IA32_TSC_ADJUST:\n\t\tif (guest_cpuid_has_tsc_adjust(vcpu)) {\n\t\t\tif (!msr_info->host_initiated) {\n\t\t\t\tu64 adj = data - vcpu->arch.ia32_tsc_adjust_msr;\n\t\t\t\tkvm_x86_ops->adjust_tsc_offset(vcpu, adj, true);\n\t\t\t}\n\t\t\tvcpu->arch.ia32_tsc_adjust_msr = data;\n\t\t}\n\t\tbreak;\n\tcase MSR_IA32_MISC_ENABLE:\n\t\tvcpu->arch.ia32_misc_enable_msr = data;\n\t\tbreak;\n\tcase MSR_KVM_WALL_CLOCK_NEW:\n\tcase MSR_KVM_WALL_CLOCK:\n\t\tvcpu->kvm->arch.wall_clock = data;\n\t\tkvm_write_wall_clock(vcpu->kvm, data);\n\t\tbreak;\n\tcase MSR_KVM_SYSTEM_TIME_NEW:\n\tcase MSR_KVM_SYSTEM_TIME: {\n\t\tkvmclock_reset(vcpu);\n\n\t\tvcpu->arch.time = data;\n\t\tkvm_make_request(KVM_REQ_CLOCK_UPDATE, vcpu);\n\n\t\t/* we verify if the enable bit is set... */\n\t\tif (!(data & 1))\n\t\t\tbreak;\n\n\t\t/* ...but clean it before doing the actual write */\n\t\tvcpu->arch.time_offset = data & ~(PAGE_MASK | 1);\n\n\t\t/* Check that the address is 32-byte aligned. */\n\t\tif (vcpu->arch.time_offset &\n\t\t\t\t(sizeof(struct pvclock_vcpu_time_info) - 1))\n\t\t\tbreak;\n\n\t\tvcpu->arch.time_page =\n\t\t\t\tgfn_to_page(vcpu->kvm, data >> PAGE_SHIFT);\n\n\t\tif (is_error_page(vcpu->arch.time_page))\n\t\t\tvcpu->arch.time_page = NULL;\n\n\t\tbreak;\n\t}\n\tcase MSR_KVM_ASYNC_PF_EN:\n\t\tif (kvm_pv_enable_async_pf(vcpu, data))\n\t\t\treturn 1;\n\t\tbreak;\n\tcase MSR_KVM_STEAL_TIME:\n\n\t\tif (unlikely(!sched_info_on()))\n\t\t\treturn 1;\n\n\t\tif (data & KVM_STEAL_RESERVED_MASK)\n\t\t\treturn 1;\n\n\t\tif (kvm_gfn_to_hva_cache_init(vcpu->kvm, &vcpu->arch.st.stime,\n\t\t\t\t\t\t\tdata & KVM_STEAL_VALID_BITS))\n\t\t\treturn 1;\n\n\t\tvcpu->arch.st.msr_val = data;\n\n\t\tif (!(data & KVM_MSR_ENABLED))\n\t\t\tbreak;\n\n\t\tvcpu->arch.st.last_steal = current->sched_info.run_delay;\n\n\t\tpreempt_disable();\n\t\taccumulate_steal_time(vcpu);\n\t\tpreempt_enable();\n\n\t\tkvm_make_request(KVM_REQ_STEAL_UPDATE, vcpu);\n\n\t\tbreak;\n\tcase MSR_KVM_PV_EOI_EN:\n\t\tif (kvm_lapic_enable_pv_eoi(vcpu, data))\n\t\t\treturn 1;\n\t\tbreak;\n\n\tcase MSR_IA32_MCG_CTL:\n\tcase MSR_IA32_MCG_STATUS:\n\tcase MSR_IA32_MC0_CTL ... MSR_IA32_MC0_CTL + 4 * KVM_MAX_MCE_BANKS - 1:\n\t\treturn set_msr_mce(vcpu, msr, data);\n\n\t/* Performance counters are not protected by a CPUID bit,\n\t * so we should check all of them in the generic path for the sake of\n\t * cross vendor migration.\n\t * Writing a zero into the event select MSRs disables them,\n\t * which we perfectly emulate ;-). Any other value should be at least\n\t * reported, some guests depend on them.\n\t */\n\tcase MSR_K7_EVNTSEL0:\n\tcase MSR_K7_EVNTSEL1:\n\tcase MSR_K7_EVNTSEL2:\n\tcase MSR_K7_EVNTSEL3:\n\t\tif (data != 0)\n\t\t\tvcpu_unimpl(vcpu, \"unimplemented perfctr wrmsr: \"\n\t\t\t\t    \"0x%x data 0x%llx\\n\", msr, data);\n\t\tbreak;\n\t/* at least RHEL 4 unconditionally writes to the perfctr registers,\n\t * so we ignore writes to make it happy.\n\t */\n\tcase MSR_K7_PERFCTR0:\n\tcase MSR_K7_PERFCTR1:\n\tcase MSR_K7_PERFCTR2:\n\tcase MSR_K7_PERFCTR3:\n\t\tvcpu_unimpl(vcpu, \"unimplemented perfctr wrmsr: \"\n\t\t\t    \"0x%x data 0x%llx\\n\", msr, data);\n\t\tbreak;\n\tcase MSR_P6_PERFCTR0:\n\tcase MSR_P6_PERFCTR1:\n\t\tpr = true;\n\tcase MSR_P6_EVNTSEL0:\n\tcase MSR_P6_EVNTSEL1:\n\t\tif (kvm_pmu_msr(vcpu, msr))\n\t\t\treturn kvm_pmu_set_msr(vcpu, msr, data);\n\n\t\tif (pr || data != 0)\n\t\t\tvcpu_unimpl(vcpu, \"disabled perfctr wrmsr: \"\n\t\t\t\t    \"0x%x data 0x%llx\\n\", msr, data);\n\t\tbreak;\n\tcase MSR_K7_CLK_CTL:\n\t\t/*\n\t\t * Ignore all writes to this no longer documented MSR.\n\t\t * Writes are only relevant for old K7 processors,\n\t\t * all pre-dating SVM, but a recommended workaround from\n\t\t * AMD for these chips. It is possible to specify the\n\t\t * affected processor models on the command line, hence\n\t\t * the need to ignore the workaround.\n\t\t */\n\t\tbreak;\n\tcase HV_X64_MSR_GUEST_OS_ID ... HV_X64_MSR_SINT15:\n\t\tif (kvm_hv_msr_partition_wide(msr)) {\n\t\t\tint r;\n\t\t\tmutex_lock(&vcpu->kvm->lock);\n\t\t\tr = set_msr_hyperv_pw(vcpu, msr, data);\n\t\t\tmutex_unlock(&vcpu->kvm->lock);\n\t\t\treturn r;\n\t\t} else\n\t\t\treturn set_msr_hyperv(vcpu, msr, data);\n\t\tbreak;\n\tcase MSR_IA32_BBL_CR_CTL3:\n\t\t/* Drop writes to this legacy MSR -- see rdmsr\n\t\t * counterpart for further detail.\n\t\t */\n\t\tvcpu_unimpl(vcpu, \"ignored wrmsr: 0x%x data %llx\\n\", msr, data);\n\t\tbreak;\n\tcase MSR_AMD64_OSVW_ID_LENGTH:\n\t\tif (!guest_cpuid_has_osvw(vcpu))\n\t\t\treturn 1;\n\t\tvcpu->arch.osvw.length = data;\n\t\tbreak;\n\tcase MSR_AMD64_OSVW_STATUS:\n\t\tif (!guest_cpuid_has_osvw(vcpu))\n\t\t\treturn 1;\n\t\tvcpu->arch.osvw.status = data;\n\t\tbreak;\n\tdefault:\n\t\tif (msr && (msr == vcpu->kvm->arch.xen_hvm_config.msr))\n\t\t\treturn xen_hvm_config(vcpu, data);\n\t\tif (kvm_pmu_msr(vcpu, msr))\n\t\t\treturn kvm_pmu_set_msr(vcpu, msr, data);\n\t\tif (!ignore_msrs) {\n\t\t\tvcpu_unimpl(vcpu, \"unhandled wrmsr: 0x%x data %llx\\n\",\n\t\t\t\t    msr, data);\n\t\t\treturn 1;\n\t\t} else {\n\t\t\tvcpu_unimpl(vcpu, \"ignored wrmsr: 0x%x data %llx\\n\",\n\t\t\t\t    msr, data);\n\t\t\tbreak;\n\t\t}\n\t}\n\treturn 0;\n}",
        "func": "int kvm_set_msr_common(struct kvm_vcpu *vcpu, struct msr_data *msr_info)\n{\n\tbool pr = false;\n\tu32 msr = msr_info->index;\n\tu64 data = msr_info->data;\n\n\tswitch (msr) {\n\tcase MSR_AMD64_NB_CFG:\n\tcase MSR_IA32_UCODE_REV:\n\tcase MSR_IA32_UCODE_WRITE:\n\tcase MSR_VM_HSAVE_PA:\n\tcase MSR_AMD64_PATCH_LOADER:\n\tcase MSR_AMD64_BU_CFG2:\n\t\tbreak;\n\n\tcase MSR_EFER:\n\t\treturn set_efer(vcpu, data);\n\tcase MSR_K7_HWCR:\n\t\tdata &= ~(u64)0x40;\t/* ignore flush filter disable */\n\t\tdata &= ~(u64)0x100;\t/* ignore ignne emulation enable */\n\t\tdata &= ~(u64)0x8;\t/* ignore TLB cache disable */\n\t\tif (data != 0) {\n\t\t\tvcpu_unimpl(vcpu, \"unimplemented HWCR wrmsr: 0x%llx\\n\",\n\t\t\t\t    data);\n\t\t\treturn 1;\n\t\t}\n\t\tbreak;\n\tcase MSR_FAM10H_MMIO_CONF_BASE:\n\t\tif (data != 0) {\n\t\t\tvcpu_unimpl(vcpu, \"unimplemented MMIO_CONF_BASE wrmsr: \"\n\t\t\t\t    \"0x%llx\\n\", data);\n\t\t\treturn 1;\n\t\t}\n\t\tbreak;\n\tcase MSR_IA32_DEBUGCTLMSR:\n\t\tif (!data) {\n\t\t\t/* We support the non-activated case already */\n\t\t\tbreak;\n\t\t} else if (data & ~(DEBUGCTLMSR_LBR | DEBUGCTLMSR_BTF)) {\n\t\t\t/* Values other than LBR and BTF are vendor-specific,\n\t\t\t   thus reserved and should throw a #GP */\n\t\t\treturn 1;\n\t\t}\n\t\tvcpu_unimpl(vcpu, \"%s: MSR_IA32_DEBUGCTLMSR 0x%llx, nop\\n\",\n\t\t\t    __func__, data);\n\t\tbreak;\n\tcase 0x200 ... 0x2ff:\n\t\treturn set_msr_mtrr(vcpu, msr, data);\n\tcase MSR_IA32_APICBASE:\n\t\tkvm_set_apic_base(vcpu, data);\n\t\tbreak;\n\tcase APIC_BASE_MSR ... APIC_BASE_MSR + 0x3ff:\n\t\treturn kvm_x2apic_msr_write(vcpu, msr, data);\n\tcase MSR_IA32_TSCDEADLINE:\n\t\tkvm_set_lapic_tscdeadline_msr(vcpu, data);\n\t\tbreak;\n\tcase MSR_IA32_TSC_ADJUST:\n\t\tif (guest_cpuid_has_tsc_adjust(vcpu)) {\n\t\t\tif (!msr_info->host_initiated) {\n\t\t\t\tu64 adj = data - vcpu->arch.ia32_tsc_adjust_msr;\n\t\t\t\tkvm_x86_ops->adjust_tsc_offset(vcpu, adj, true);\n\t\t\t}\n\t\t\tvcpu->arch.ia32_tsc_adjust_msr = data;\n\t\t}\n\t\tbreak;\n\tcase MSR_IA32_MISC_ENABLE:\n\t\tvcpu->arch.ia32_misc_enable_msr = data;\n\t\tbreak;\n\tcase MSR_KVM_WALL_CLOCK_NEW:\n\tcase MSR_KVM_WALL_CLOCK:\n\t\tvcpu->kvm->arch.wall_clock = data;\n\t\tkvm_write_wall_clock(vcpu->kvm, data);\n\t\tbreak;\n\tcase MSR_KVM_SYSTEM_TIME_NEW:\n\tcase MSR_KVM_SYSTEM_TIME: {\n\t\tu64 gpa_offset;\n\t\tkvmclock_reset(vcpu);\n\n\t\tvcpu->arch.time = data;\n\t\tkvm_make_request(KVM_REQ_CLOCK_UPDATE, vcpu);\n\n\t\t/* we verify if the enable bit is set... */\n\t\tif (!(data & 1))\n\t\t\tbreak;\n\n\t\tgpa_offset = data & ~(PAGE_MASK | 1);\n\n\t\t/* Check that the address is 32-byte aligned. */\n\t\tif (gpa_offset & (sizeof(struct pvclock_vcpu_time_info) - 1))\n\t\t\tbreak;\n\n\t\tif (kvm_gfn_to_hva_cache_init(vcpu->kvm,\n\t\t     &vcpu->arch.pv_time, data & ~1ULL))\n\t\t\tvcpu->arch.pv_time_enabled = false;\n\t\telse\n\t\t\tvcpu->arch.pv_time_enabled = true;\n\n\t\tbreak;\n\t}\n\tcase MSR_KVM_ASYNC_PF_EN:\n\t\tif (kvm_pv_enable_async_pf(vcpu, data))\n\t\t\treturn 1;\n\t\tbreak;\n\tcase MSR_KVM_STEAL_TIME:\n\n\t\tif (unlikely(!sched_info_on()))\n\t\t\treturn 1;\n\n\t\tif (data & KVM_STEAL_RESERVED_MASK)\n\t\t\treturn 1;\n\n\t\tif (kvm_gfn_to_hva_cache_init(vcpu->kvm, &vcpu->arch.st.stime,\n\t\t\t\t\t\t\tdata & KVM_STEAL_VALID_BITS))\n\t\t\treturn 1;\n\n\t\tvcpu->arch.st.msr_val = data;\n\n\t\tif (!(data & KVM_MSR_ENABLED))\n\t\t\tbreak;\n\n\t\tvcpu->arch.st.last_steal = current->sched_info.run_delay;\n\n\t\tpreempt_disable();\n\t\taccumulate_steal_time(vcpu);\n\t\tpreempt_enable();\n\n\t\tkvm_make_request(KVM_REQ_STEAL_UPDATE, vcpu);\n\n\t\tbreak;\n\tcase MSR_KVM_PV_EOI_EN:\n\t\tif (kvm_lapic_enable_pv_eoi(vcpu, data))\n\t\t\treturn 1;\n\t\tbreak;\n\n\tcase MSR_IA32_MCG_CTL:\n\tcase MSR_IA32_MCG_STATUS:\n\tcase MSR_IA32_MC0_CTL ... MSR_IA32_MC0_CTL + 4 * KVM_MAX_MCE_BANKS - 1:\n\t\treturn set_msr_mce(vcpu, msr, data);\n\n\t/* Performance counters are not protected by a CPUID bit,\n\t * so we should check all of them in the generic path for the sake of\n\t * cross vendor migration.\n\t * Writing a zero into the event select MSRs disables them,\n\t * which we perfectly emulate ;-). Any other value should be at least\n\t * reported, some guests depend on them.\n\t */\n\tcase MSR_K7_EVNTSEL0:\n\tcase MSR_K7_EVNTSEL1:\n\tcase MSR_K7_EVNTSEL2:\n\tcase MSR_K7_EVNTSEL3:\n\t\tif (data != 0)\n\t\t\tvcpu_unimpl(vcpu, \"unimplemented perfctr wrmsr: \"\n\t\t\t\t    \"0x%x data 0x%llx\\n\", msr, data);\n\t\tbreak;\n\t/* at least RHEL 4 unconditionally writes to the perfctr registers,\n\t * so we ignore writes to make it happy.\n\t */\n\tcase MSR_K7_PERFCTR0:\n\tcase MSR_K7_PERFCTR1:\n\tcase MSR_K7_PERFCTR2:\n\tcase MSR_K7_PERFCTR3:\n\t\tvcpu_unimpl(vcpu, \"unimplemented perfctr wrmsr: \"\n\t\t\t    \"0x%x data 0x%llx\\n\", msr, data);\n\t\tbreak;\n\tcase MSR_P6_PERFCTR0:\n\tcase MSR_P6_PERFCTR1:\n\t\tpr = true;\n\tcase MSR_P6_EVNTSEL0:\n\tcase MSR_P6_EVNTSEL1:\n\t\tif (kvm_pmu_msr(vcpu, msr))\n\t\t\treturn kvm_pmu_set_msr(vcpu, msr, data);\n\n\t\tif (pr || data != 0)\n\t\t\tvcpu_unimpl(vcpu, \"disabled perfctr wrmsr: \"\n\t\t\t\t    \"0x%x data 0x%llx\\n\", msr, data);\n\t\tbreak;\n\tcase MSR_K7_CLK_CTL:\n\t\t/*\n\t\t * Ignore all writes to this no longer documented MSR.\n\t\t * Writes are only relevant for old K7 processors,\n\t\t * all pre-dating SVM, but a recommended workaround from\n\t\t * AMD for these chips. It is possible to specify the\n\t\t * affected processor models on the command line, hence\n\t\t * the need to ignore the workaround.\n\t\t */\n\t\tbreak;\n\tcase HV_X64_MSR_GUEST_OS_ID ... HV_X64_MSR_SINT15:\n\t\tif (kvm_hv_msr_partition_wide(msr)) {\n\t\t\tint r;\n\t\t\tmutex_lock(&vcpu->kvm->lock);\n\t\t\tr = set_msr_hyperv_pw(vcpu, msr, data);\n\t\t\tmutex_unlock(&vcpu->kvm->lock);\n\t\t\treturn r;\n\t\t} else\n\t\t\treturn set_msr_hyperv(vcpu, msr, data);\n\t\tbreak;\n\tcase MSR_IA32_BBL_CR_CTL3:\n\t\t/* Drop writes to this legacy MSR -- see rdmsr\n\t\t * counterpart for further detail.\n\t\t */\n\t\tvcpu_unimpl(vcpu, \"ignored wrmsr: 0x%x data %llx\\n\", msr, data);\n\t\tbreak;\n\tcase MSR_AMD64_OSVW_ID_LENGTH:\n\t\tif (!guest_cpuid_has_osvw(vcpu))\n\t\t\treturn 1;\n\t\tvcpu->arch.osvw.length = data;\n\t\tbreak;\n\tcase MSR_AMD64_OSVW_STATUS:\n\t\tif (!guest_cpuid_has_osvw(vcpu))\n\t\t\treturn 1;\n\t\tvcpu->arch.osvw.status = data;\n\t\tbreak;\n\tdefault:\n\t\tif (msr && (msr == vcpu->kvm->arch.xen_hvm_config.msr))\n\t\t\treturn xen_hvm_config(vcpu, data);\n\t\tif (kvm_pmu_msr(vcpu, msr))\n\t\t\treturn kvm_pmu_set_msr(vcpu, msr, data);\n\t\tif (!ignore_msrs) {\n\t\t\tvcpu_unimpl(vcpu, \"unhandled wrmsr: 0x%x data %llx\\n\",\n\t\t\t\t    msr, data);\n\t\t\treturn 1;\n\t\t} else {\n\t\t\tvcpu_unimpl(vcpu, \"ignored wrmsr: 0x%x data %llx\\n\",\n\t\t\t\t    msr, data);\n\t\t\tbreak;\n\t\t}\n\t}\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -73,6 +73,7 @@\n \t\tbreak;\n \tcase MSR_KVM_SYSTEM_TIME_NEW:\n \tcase MSR_KVM_SYSTEM_TIME: {\n+\t\tu64 gpa_offset;\n \t\tkvmclock_reset(vcpu);\n \n \t\tvcpu->arch.time = data;\n@@ -82,19 +83,17 @@\n \t\tif (!(data & 1))\n \t\t\tbreak;\n \n-\t\t/* ...but clean it before doing the actual write */\n-\t\tvcpu->arch.time_offset = data & ~(PAGE_MASK | 1);\n+\t\tgpa_offset = data & ~(PAGE_MASK | 1);\n \n \t\t/* Check that the address is 32-byte aligned. */\n-\t\tif (vcpu->arch.time_offset &\n-\t\t\t\t(sizeof(struct pvclock_vcpu_time_info) - 1))\n-\t\t\tbreak;\n-\n-\t\tvcpu->arch.time_page =\n-\t\t\t\tgfn_to_page(vcpu->kvm, data >> PAGE_SHIFT);\n-\n-\t\tif (is_error_page(vcpu->arch.time_page))\n-\t\t\tvcpu->arch.time_page = NULL;\n+\t\tif (gpa_offset & (sizeof(struct pvclock_vcpu_time_info) - 1))\n+\t\t\tbreak;\n+\n+\t\tif (kvm_gfn_to_hva_cache_init(vcpu->kvm,\n+\t\t     &vcpu->arch.pv_time, data & ~1ULL))\n+\t\t\tvcpu->arch.pv_time_enabled = false;\n+\t\telse\n+\t\t\tvcpu->arch.pv_time_enabled = true;\n \n \t\tbreak;\n \t}",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t/* ...but clean it before doing the actual write */",
                "\t\tvcpu->arch.time_offset = data & ~(PAGE_MASK | 1);",
                "\t\tif (vcpu->arch.time_offset &",
                "\t\t\t\t(sizeof(struct pvclock_vcpu_time_info) - 1))",
                "\t\t\tbreak;",
                "",
                "\t\tvcpu->arch.time_page =",
                "\t\t\t\tgfn_to_page(vcpu->kvm, data >> PAGE_SHIFT);",
                "",
                "\t\tif (is_error_page(vcpu->arch.time_page))",
                "\t\t\tvcpu->arch.time_page = NULL;"
            ],
            "added_lines": [
                "\t\tu64 gpa_offset;",
                "\t\tgpa_offset = data & ~(PAGE_MASK | 1);",
                "\t\tif (gpa_offset & (sizeof(struct pvclock_vcpu_time_info) - 1))",
                "\t\t\tbreak;",
                "",
                "\t\tif (kvm_gfn_to_hva_cache_init(vcpu->kvm,",
                "\t\t     &vcpu->arch.pv_time, data & ~1ULL))",
                "\t\t\tvcpu->arch.pv_time_enabled = false;",
                "\t\telse",
                "\t\t\tvcpu->arch.pv_time_enabled = true;"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-1797",
        "func_name": "torvalds/linux/kvm_arch_vcpu_init",
        "description": "Use-after-free vulnerability in arch/x86/kvm/x86.c in the Linux kernel through 3.8.4 allows guest OS users to cause a denial of service (host OS memory corruption) or possibly have unspecified other impact via a crafted application that triggers use of a guest physical address (GPA) in (1) movable or (2) removable memory during an MSR_KVM_SYSTEM_TIME kvm_set_msr_common operation.",
        "git_url": "https://github.com/torvalds/linux/commit/0b79459b482e85cb7426aa7da683a9f2c97aeae1",
        "commit_title": "KVM: x86: Convert MSR_KVM_SYSTEM_TIME to use gfn_to_hva_cache functions (CVE-2013-1797)",
        "commit_text": " There is a potential use after free issue with the handling of MSR_KVM_SYSTEM_TIME.  If the guest specifies a GPA in a movable or removable memory such as frame buffers then KVM might continue to write to that address even after it's removed via KVM_SET_USER_MEMORY_REGION.  KVM pins the page in memory so it's unlikely to cause an issue, but if the user space component re-purposes the memory previously used for the guest, then the guest will be able to corrupt that memory.  Tested: Tested against kvmclock unit test ",
        "func_before": "int kvm_arch_vcpu_init(struct kvm_vcpu *vcpu)\n{\n\tstruct page *page;\n\tstruct kvm *kvm;\n\tint r;\n\n\tBUG_ON(vcpu->kvm == NULL);\n\tkvm = vcpu->kvm;\n\n\tvcpu->arch.emulate_ctxt.ops = &emulate_ops;\n\tif (!irqchip_in_kernel(kvm) || kvm_vcpu_is_bsp(vcpu))\n\t\tvcpu->arch.mp_state = KVM_MP_STATE_RUNNABLE;\n\telse\n\t\tvcpu->arch.mp_state = KVM_MP_STATE_UNINITIALIZED;\n\n\tpage = alloc_page(GFP_KERNEL | __GFP_ZERO);\n\tif (!page) {\n\t\tr = -ENOMEM;\n\t\tgoto fail;\n\t}\n\tvcpu->arch.pio_data = page_address(page);\n\n\tkvm_set_tsc_khz(vcpu, max_tsc_khz);\n\n\tr = kvm_mmu_create(vcpu);\n\tif (r < 0)\n\t\tgoto fail_free_pio_data;\n\n\tif (irqchip_in_kernel(kvm)) {\n\t\tr = kvm_create_lapic(vcpu);\n\t\tif (r < 0)\n\t\t\tgoto fail_mmu_destroy;\n\t} else\n\t\tstatic_key_slow_inc(&kvm_no_apic_vcpu);\n\n\tvcpu->arch.mce_banks = kzalloc(KVM_MAX_MCE_BANKS * sizeof(u64) * 4,\n\t\t\t\t       GFP_KERNEL);\n\tif (!vcpu->arch.mce_banks) {\n\t\tr = -ENOMEM;\n\t\tgoto fail_free_lapic;\n\t}\n\tvcpu->arch.mcg_cap = KVM_MAX_MCE_BANKS;\n\n\tif (!zalloc_cpumask_var(&vcpu->arch.wbinvd_dirty_mask, GFP_KERNEL))\n\t\tgoto fail_free_mce_banks;\n\n\tr = fx_init(vcpu);\n\tif (r)\n\t\tgoto fail_free_wbinvd_dirty_mask;\n\n\tvcpu->arch.ia32_tsc_adjust_msr = 0x0;\n\tkvm_async_pf_hash_reset(vcpu);\n\tkvm_pmu_init(vcpu);\n\n\treturn 0;\nfail_free_wbinvd_dirty_mask:\n\tfree_cpumask_var(vcpu->arch.wbinvd_dirty_mask);\nfail_free_mce_banks:\n\tkfree(vcpu->arch.mce_banks);\nfail_free_lapic:\n\tkvm_free_lapic(vcpu);\nfail_mmu_destroy:\n\tkvm_mmu_destroy(vcpu);\nfail_free_pio_data:\n\tfree_page((unsigned long)vcpu->arch.pio_data);\nfail:\n\treturn r;\n}",
        "func": "int kvm_arch_vcpu_init(struct kvm_vcpu *vcpu)\n{\n\tstruct page *page;\n\tstruct kvm *kvm;\n\tint r;\n\n\tBUG_ON(vcpu->kvm == NULL);\n\tkvm = vcpu->kvm;\n\n\tvcpu->arch.emulate_ctxt.ops = &emulate_ops;\n\tif (!irqchip_in_kernel(kvm) || kvm_vcpu_is_bsp(vcpu))\n\t\tvcpu->arch.mp_state = KVM_MP_STATE_RUNNABLE;\n\telse\n\t\tvcpu->arch.mp_state = KVM_MP_STATE_UNINITIALIZED;\n\n\tpage = alloc_page(GFP_KERNEL | __GFP_ZERO);\n\tif (!page) {\n\t\tr = -ENOMEM;\n\t\tgoto fail;\n\t}\n\tvcpu->arch.pio_data = page_address(page);\n\n\tkvm_set_tsc_khz(vcpu, max_tsc_khz);\n\n\tr = kvm_mmu_create(vcpu);\n\tif (r < 0)\n\t\tgoto fail_free_pio_data;\n\n\tif (irqchip_in_kernel(kvm)) {\n\t\tr = kvm_create_lapic(vcpu);\n\t\tif (r < 0)\n\t\t\tgoto fail_mmu_destroy;\n\t} else\n\t\tstatic_key_slow_inc(&kvm_no_apic_vcpu);\n\n\tvcpu->arch.mce_banks = kzalloc(KVM_MAX_MCE_BANKS * sizeof(u64) * 4,\n\t\t\t\t       GFP_KERNEL);\n\tif (!vcpu->arch.mce_banks) {\n\t\tr = -ENOMEM;\n\t\tgoto fail_free_lapic;\n\t}\n\tvcpu->arch.mcg_cap = KVM_MAX_MCE_BANKS;\n\n\tif (!zalloc_cpumask_var(&vcpu->arch.wbinvd_dirty_mask, GFP_KERNEL))\n\t\tgoto fail_free_mce_banks;\n\n\tr = fx_init(vcpu);\n\tif (r)\n\t\tgoto fail_free_wbinvd_dirty_mask;\n\n\tvcpu->arch.ia32_tsc_adjust_msr = 0x0;\n\tvcpu->arch.pv_time_enabled = false;\n\tkvm_async_pf_hash_reset(vcpu);\n\tkvm_pmu_init(vcpu);\n\n\treturn 0;\nfail_free_wbinvd_dirty_mask:\n\tfree_cpumask_var(vcpu->arch.wbinvd_dirty_mask);\nfail_free_mce_banks:\n\tkfree(vcpu->arch.mce_banks);\nfail_free_lapic:\n\tkvm_free_lapic(vcpu);\nfail_mmu_destroy:\n\tkvm_mmu_destroy(vcpu);\nfail_free_pio_data:\n\tfree_page((unsigned long)vcpu->arch.pio_data);\nfail:\n\treturn r;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -49,6 +49,7 @@\n \t\tgoto fail_free_wbinvd_dirty_mask;\n \n \tvcpu->arch.ia32_tsc_adjust_msr = 0x0;\n+\tvcpu->arch.pv_time_enabled = false;\n \tkvm_async_pf_hash_reset(vcpu);\n \tkvm_pmu_init(vcpu);\n ",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tvcpu->arch.pv_time_enabled = false;"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-1797",
        "func_name": "torvalds/linux/kvm_guest_time_update",
        "description": "Use-after-free vulnerability in arch/x86/kvm/x86.c in the Linux kernel through 3.8.4 allows guest OS users to cause a denial of service (host OS memory corruption) or possibly have unspecified other impact via a crafted application that triggers use of a guest physical address (GPA) in (1) movable or (2) removable memory during an MSR_KVM_SYSTEM_TIME kvm_set_msr_common operation.",
        "git_url": "https://github.com/torvalds/linux/commit/0b79459b482e85cb7426aa7da683a9f2c97aeae1",
        "commit_title": "KVM: x86: Convert MSR_KVM_SYSTEM_TIME to use gfn_to_hva_cache functions (CVE-2013-1797)",
        "commit_text": " There is a potential use after free issue with the handling of MSR_KVM_SYSTEM_TIME.  If the guest specifies a GPA in a movable or removable memory such as frame buffers then KVM might continue to write to that address even after it's removed via KVM_SET_USER_MEMORY_REGION.  KVM pins the page in memory so it's unlikely to cause an issue, but if the user space component re-purposes the memory previously used for the guest, then the guest will be able to corrupt that memory.  Tested: Tested against kvmclock unit test ",
        "func_before": "static int kvm_guest_time_update(struct kvm_vcpu *v)\n{\n\tunsigned long flags, this_tsc_khz;\n\tstruct kvm_vcpu_arch *vcpu = &v->arch;\n\tstruct kvm_arch *ka = &v->kvm->arch;\n\tvoid *shared_kaddr;\n\ts64 kernel_ns, max_kernel_ns;\n\tu64 tsc_timestamp, host_tsc;\n\tstruct pvclock_vcpu_time_info *guest_hv_clock;\n\tu8 pvclock_flags;\n\tbool use_master_clock;\n\n\tkernel_ns = 0;\n\thost_tsc = 0;\n\n\t/*\n\t * If the host uses TSC clock, then passthrough TSC as stable\n\t * to the guest.\n\t */\n\tspin_lock(&ka->pvclock_gtod_sync_lock);\n\tuse_master_clock = ka->use_master_clock;\n\tif (use_master_clock) {\n\t\thost_tsc = ka->master_cycle_now;\n\t\tkernel_ns = ka->master_kernel_ns;\n\t}\n\tspin_unlock(&ka->pvclock_gtod_sync_lock);\n\n\t/* Keep irq disabled to prevent changes to the clock */\n\tlocal_irq_save(flags);\n\tthis_tsc_khz = __get_cpu_var(cpu_tsc_khz);\n\tif (unlikely(this_tsc_khz == 0)) {\n\t\tlocal_irq_restore(flags);\n\t\tkvm_make_request(KVM_REQ_CLOCK_UPDATE, v);\n\t\treturn 1;\n\t}\n\tif (!use_master_clock) {\n\t\thost_tsc = native_read_tsc();\n\t\tkernel_ns = get_kernel_ns();\n\t}\n\n\ttsc_timestamp = kvm_x86_ops->read_l1_tsc(v, host_tsc);\n\n\t/*\n\t * We may have to catch up the TSC to match elapsed wall clock\n\t * time for two reasons, even if kvmclock is used.\n\t *   1) CPU could have been running below the maximum TSC rate\n\t *   2) Broken TSC compensation resets the base at each VCPU\n\t *      entry to avoid unknown leaps of TSC even when running\n\t *      again on the same CPU.  This may cause apparent elapsed\n\t *      time to disappear, and the guest to stand still or run\n\t *\tvery slowly.\n\t */\n\tif (vcpu->tsc_catchup) {\n\t\tu64 tsc = compute_guest_tsc(v, kernel_ns);\n\t\tif (tsc > tsc_timestamp) {\n\t\t\tadjust_tsc_offset_guest(v, tsc - tsc_timestamp);\n\t\t\ttsc_timestamp = tsc;\n\t\t}\n\t}\n\n\tlocal_irq_restore(flags);\n\n\tif (!vcpu->time_page)\n\t\treturn 0;\n\n\t/*\n\t * Time as measured by the TSC may go backwards when resetting the base\n\t * tsc_timestamp.  The reason for this is that the TSC resolution is\n\t * higher than the resolution of the other clock scales.  Thus, many\n\t * possible measurments of the TSC correspond to one measurement of any\n\t * other clock, and so a spread of values is possible.  This is not a\n\t * problem for the computation of the nanosecond clock; with TSC rates\n\t * around 1GHZ, there can only be a few cycles which correspond to one\n\t * nanosecond value, and any path through this code will inevitably\n\t * take longer than that.  However, with the kernel_ns value itself,\n\t * the precision may be much lower, down to HZ granularity.  If the\n\t * first sampling of TSC against kernel_ns ends in the low part of the\n\t * range, and the second in the high end of the range, we can get:\n\t *\n\t * (TSC - offset_low) * S + kns_old > (TSC - offset_high) * S + kns_new\n\t *\n\t * As the sampling errors potentially range in the thousands of cycles,\n\t * it is possible such a time value has already been observed by the\n\t * guest.  To protect against this, we must compute the system time as\n\t * observed by the guest and ensure the new system time is greater.\n\t */\n\tmax_kernel_ns = 0;\n\tif (vcpu->hv_clock.tsc_timestamp) {\n\t\tmax_kernel_ns = vcpu->last_guest_tsc -\n\t\t\t\tvcpu->hv_clock.tsc_timestamp;\n\t\tmax_kernel_ns = pvclock_scale_delta(max_kernel_ns,\n\t\t\t\t    vcpu->hv_clock.tsc_to_system_mul,\n\t\t\t\t    vcpu->hv_clock.tsc_shift);\n\t\tmax_kernel_ns += vcpu->last_kernel_ns;\n\t}\n\n\tif (unlikely(vcpu->hw_tsc_khz != this_tsc_khz)) {\n\t\tkvm_get_time_scale(NSEC_PER_SEC / 1000, this_tsc_khz,\n\t\t\t\t   &vcpu->hv_clock.tsc_shift,\n\t\t\t\t   &vcpu->hv_clock.tsc_to_system_mul);\n\t\tvcpu->hw_tsc_khz = this_tsc_khz;\n\t}\n\n\t/* with a master <monotonic time, tsc value> tuple,\n\t * pvclock clock reads always increase at the (scaled) rate\n\t * of guest TSC - no need to deal with sampling errors.\n\t */\n\tif (!use_master_clock) {\n\t\tif (max_kernel_ns > kernel_ns)\n\t\t\tkernel_ns = max_kernel_ns;\n\t}\n\t/* With all the info we got, fill in the values */\n\tvcpu->hv_clock.tsc_timestamp = tsc_timestamp;\n\tvcpu->hv_clock.system_time = kernel_ns + v->kvm->arch.kvmclock_offset;\n\tvcpu->last_kernel_ns = kernel_ns;\n\tvcpu->last_guest_tsc = tsc_timestamp;\n\n\t/*\n\t * The interface expects us to write an even number signaling that the\n\t * update is finished. Since the guest won't see the intermediate\n\t * state, we just increase by 2 at the end.\n\t */\n\tvcpu->hv_clock.version += 2;\n\n\tshared_kaddr = kmap_atomic(vcpu->time_page);\n\n\tguest_hv_clock = shared_kaddr + vcpu->time_offset;\n\n\t/* retain PVCLOCK_GUEST_STOPPED if set in guest copy */\n\tpvclock_flags = (guest_hv_clock->flags & PVCLOCK_GUEST_STOPPED);\n\n\tif (vcpu->pvclock_set_guest_stopped_request) {\n\t\tpvclock_flags |= PVCLOCK_GUEST_STOPPED;\n\t\tvcpu->pvclock_set_guest_stopped_request = false;\n\t}\n\n\t/* If the host uses TSC clocksource, then it is stable */\n\tif (use_master_clock)\n\t\tpvclock_flags |= PVCLOCK_TSC_STABLE_BIT;\n\n\tvcpu->hv_clock.flags = pvclock_flags;\n\n\tmemcpy(shared_kaddr + vcpu->time_offset, &vcpu->hv_clock,\n\t       sizeof(vcpu->hv_clock));\n\n\tkunmap_atomic(shared_kaddr);\n\n\tmark_page_dirty(v->kvm, vcpu->time >> PAGE_SHIFT);\n\treturn 0;\n}",
        "func": "static int kvm_guest_time_update(struct kvm_vcpu *v)\n{\n\tunsigned long flags, this_tsc_khz;\n\tstruct kvm_vcpu_arch *vcpu = &v->arch;\n\tstruct kvm_arch *ka = &v->kvm->arch;\n\ts64 kernel_ns, max_kernel_ns;\n\tu64 tsc_timestamp, host_tsc;\n\tstruct pvclock_vcpu_time_info guest_hv_clock;\n\tu8 pvclock_flags;\n\tbool use_master_clock;\n\n\tkernel_ns = 0;\n\thost_tsc = 0;\n\n\t/*\n\t * If the host uses TSC clock, then passthrough TSC as stable\n\t * to the guest.\n\t */\n\tspin_lock(&ka->pvclock_gtod_sync_lock);\n\tuse_master_clock = ka->use_master_clock;\n\tif (use_master_clock) {\n\t\thost_tsc = ka->master_cycle_now;\n\t\tkernel_ns = ka->master_kernel_ns;\n\t}\n\tspin_unlock(&ka->pvclock_gtod_sync_lock);\n\n\t/* Keep irq disabled to prevent changes to the clock */\n\tlocal_irq_save(flags);\n\tthis_tsc_khz = __get_cpu_var(cpu_tsc_khz);\n\tif (unlikely(this_tsc_khz == 0)) {\n\t\tlocal_irq_restore(flags);\n\t\tkvm_make_request(KVM_REQ_CLOCK_UPDATE, v);\n\t\treturn 1;\n\t}\n\tif (!use_master_clock) {\n\t\thost_tsc = native_read_tsc();\n\t\tkernel_ns = get_kernel_ns();\n\t}\n\n\ttsc_timestamp = kvm_x86_ops->read_l1_tsc(v, host_tsc);\n\n\t/*\n\t * We may have to catch up the TSC to match elapsed wall clock\n\t * time for two reasons, even if kvmclock is used.\n\t *   1) CPU could have been running below the maximum TSC rate\n\t *   2) Broken TSC compensation resets the base at each VCPU\n\t *      entry to avoid unknown leaps of TSC even when running\n\t *      again on the same CPU.  This may cause apparent elapsed\n\t *      time to disappear, and the guest to stand still or run\n\t *\tvery slowly.\n\t */\n\tif (vcpu->tsc_catchup) {\n\t\tu64 tsc = compute_guest_tsc(v, kernel_ns);\n\t\tif (tsc > tsc_timestamp) {\n\t\t\tadjust_tsc_offset_guest(v, tsc - tsc_timestamp);\n\t\t\ttsc_timestamp = tsc;\n\t\t}\n\t}\n\n\tlocal_irq_restore(flags);\n\n\tif (!vcpu->pv_time_enabled)\n\t\treturn 0;\n\n\t/*\n\t * Time as measured by the TSC may go backwards when resetting the base\n\t * tsc_timestamp.  The reason for this is that the TSC resolution is\n\t * higher than the resolution of the other clock scales.  Thus, many\n\t * possible measurments of the TSC correspond to one measurement of any\n\t * other clock, and so a spread of values is possible.  This is not a\n\t * problem for the computation of the nanosecond clock; with TSC rates\n\t * around 1GHZ, there can only be a few cycles which correspond to one\n\t * nanosecond value, and any path through this code will inevitably\n\t * take longer than that.  However, with the kernel_ns value itself,\n\t * the precision may be much lower, down to HZ granularity.  If the\n\t * first sampling of TSC against kernel_ns ends in the low part of the\n\t * range, and the second in the high end of the range, we can get:\n\t *\n\t * (TSC - offset_low) * S + kns_old > (TSC - offset_high) * S + kns_new\n\t *\n\t * As the sampling errors potentially range in the thousands of cycles,\n\t * it is possible such a time value has already been observed by the\n\t * guest.  To protect against this, we must compute the system time as\n\t * observed by the guest and ensure the new system time is greater.\n\t */\n\tmax_kernel_ns = 0;\n\tif (vcpu->hv_clock.tsc_timestamp) {\n\t\tmax_kernel_ns = vcpu->last_guest_tsc -\n\t\t\t\tvcpu->hv_clock.tsc_timestamp;\n\t\tmax_kernel_ns = pvclock_scale_delta(max_kernel_ns,\n\t\t\t\t    vcpu->hv_clock.tsc_to_system_mul,\n\t\t\t\t    vcpu->hv_clock.tsc_shift);\n\t\tmax_kernel_ns += vcpu->last_kernel_ns;\n\t}\n\n\tif (unlikely(vcpu->hw_tsc_khz != this_tsc_khz)) {\n\t\tkvm_get_time_scale(NSEC_PER_SEC / 1000, this_tsc_khz,\n\t\t\t\t   &vcpu->hv_clock.tsc_shift,\n\t\t\t\t   &vcpu->hv_clock.tsc_to_system_mul);\n\t\tvcpu->hw_tsc_khz = this_tsc_khz;\n\t}\n\n\t/* with a master <monotonic time, tsc value> tuple,\n\t * pvclock clock reads always increase at the (scaled) rate\n\t * of guest TSC - no need to deal with sampling errors.\n\t */\n\tif (!use_master_clock) {\n\t\tif (max_kernel_ns > kernel_ns)\n\t\t\tkernel_ns = max_kernel_ns;\n\t}\n\t/* With all the info we got, fill in the values */\n\tvcpu->hv_clock.tsc_timestamp = tsc_timestamp;\n\tvcpu->hv_clock.system_time = kernel_ns + v->kvm->arch.kvmclock_offset;\n\tvcpu->last_kernel_ns = kernel_ns;\n\tvcpu->last_guest_tsc = tsc_timestamp;\n\n\t/*\n\t * The interface expects us to write an even number signaling that the\n\t * update is finished. Since the guest won't see the intermediate\n\t * state, we just increase by 2 at the end.\n\t */\n\tvcpu->hv_clock.version += 2;\n\n\tif (unlikely(kvm_read_guest_cached(v->kvm, &vcpu->pv_time,\n\t\t&guest_hv_clock, sizeof(guest_hv_clock))))\n\t\treturn 0;\n\n\t/* retain PVCLOCK_GUEST_STOPPED if set in guest copy */\n\tpvclock_flags = (guest_hv_clock.flags & PVCLOCK_GUEST_STOPPED);\n\n\tif (vcpu->pvclock_set_guest_stopped_request) {\n\t\tpvclock_flags |= PVCLOCK_GUEST_STOPPED;\n\t\tvcpu->pvclock_set_guest_stopped_request = false;\n\t}\n\n\t/* If the host uses TSC clocksource, then it is stable */\n\tif (use_master_clock)\n\t\tpvclock_flags |= PVCLOCK_TSC_STABLE_BIT;\n\n\tvcpu->hv_clock.flags = pvclock_flags;\n\n\tkvm_write_guest_cached(v->kvm, &vcpu->pv_time,\n\t\t\t\t&vcpu->hv_clock,\n\t\t\t\tsizeof(vcpu->hv_clock));\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,10 +3,9 @@\n \tunsigned long flags, this_tsc_khz;\n \tstruct kvm_vcpu_arch *vcpu = &v->arch;\n \tstruct kvm_arch *ka = &v->kvm->arch;\n-\tvoid *shared_kaddr;\n \ts64 kernel_ns, max_kernel_ns;\n \tu64 tsc_timestamp, host_tsc;\n-\tstruct pvclock_vcpu_time_info *guest_hv_clock;\n+\tstruct pvclock_vcpu_time_info guest_hv_clock;\n \tu8 pvclock_flags;\n \tbool use_master_clock;\n \n@@ -60,7 +59,7 @@\n \n \tlocal_irq_restore(flags);\n \n-\tif (!vcpu->time_page)\n+\tif (!vcpu->pv_time_enabled)\n \t\treturn 0;\n \n \t/*\n@@ -122,12 +121,12 @@\n \t */\n \tvcpu->hv_clock.version += 2;\n \n-\tshared_kaddr = kmap_atomic(vcpu->time_page);\n-\n-\tguest_hv_clock = shared_kaddr + vcpu->time_offset;\n+\tif (unlikely(kvm_read_guest_cached(v->kvm, &vcpu->pv_time,\n+\t\t&guest_hv_clock, sizeof(guest_hv_clock))))\n+\t\treturn 0;\n \n \t/* retain PVCLOCK_GUEST_STOPPED if set in guest copy */\n-\tpvclock_flags = (guest_hv_clock->flags & PVCLOCK_GUEST_STOPPED);\n+\tpvclock_flags = (guest_hv_clock.flags & PVCLOCK_GUEST_STOPPED);\n \n \tif (vcpu->pvclock_set_guest_stopped_request) {\n \t\tpvclock_flags |= PVCLOCK_GUEST_STOPPED;\n@@ -140,11 +139,8 @@\n \n \tvcpu->hv_clock.flags = pvclock_flags;\n \n-\tmemcpy(shared_kaddr + vcpu->time_offset, &vcpu->hv_clock,\n-\t       sizeof(vcpu->hv_clock));\n-\n-\tkunmap_atomic(shared_kaddr);\n-\n-\tmark_page_dirty(v->kvm, vcpu->time >> PAGE_SHIFT);\n+\tkvm_write_guest_cached(v->kvm, &vcpu->pv_time,\n+\t\t\t\t&vcpu->hv_clock,\n+\t\t\t\tsizeof(vcpu->hv_clock));\n \treturn 0;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tvoid *shared_kaddr;",
                "\tstruct pvclock_vcpu_time_info *guest_hv_clock;",
                "\tif (!vcpu->time_page)",
                "\tshared_kaddr = kmap_atomic(vcpu->time_page);",
                "",
                "\tguest_hv_clock = shared_kaddr + vcpu->time_offset;",
                "\tpvclock_flags = (guest_hv_clock->flags & PVCLOCK_GUEST_STOPPED);",
                "\tmemcpy(shared_kaddr + vcpu->time_offset, &vcpu->hv_clock,",
                "\t       sizeof(vcpu->hv_clock));",
                "",
                "\tkunmap_atomic(shared_kaddr);",
                "",
                "\tmark_page_dirty(v->kvm, vcpu->time >> PAGE_SHIFT);"
            ],
            "added_lines": [
                "\tstruct pvclock_vcpu_time_info guest_hv_clock;",
                "\tif (!vcpu->pv_time_enabled)",
                "\tif (unlikely(kvm_read_guest_cached(v->kvm, &vcpu->pv_time,",
                "\t\t&guest_hv_clock, sizeof(guest_hv_clock))))",
                "\t\treturn 0;",
                "\tpvclock_flags = (guest_hv_clock.flags & PVCLOCK_GUEST_STOPPED);",
                "\tkvm_write_guest_cached(v->kvm, &vcpu->pv_time,",
                "\t\t\t\t&vcpu->hv_clock,",
                "\t\t\t\tsizeof(vcpu->hv_clock));"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-2634",
        "func_name": "torvalds/linux/dcbnl_cee_fill",
        "description": "net/dcb/dcbnl.c in the Linux kernel before 3.8.4 does not initialize certain structures, which allows local users to obtain sensitive information from kernel stack memory via a crafted application.",
        "git_url": "https://github.com/torvalds/linux/commit/29cd8ae0e1a39e239a3a7b67da1986add1199fc0",
        "commit_title": "dcbnl: fix various netlink info leaks",
        "commit_text": " The dcb netlink interface leaks stack memory in various places: * perm_addr[] buffer is only filled at max with 12 of the 32 bytes but   copied completely, * no in-kernel driver fills all fields of an IEEE 802.1Qaz subcommand,   so we're leaking up to 58 bytes for ieee_ets structs, up to 136 bytes   for ieee_pfc structs, etc., * the same is true for CEE -- no in-kernel driver fills the whole   struct,  Prevent all of the above stack info leaks by properly initializing the buffers/structures involved. ",
        "func_before": "static int dcbnl_cee_fill(struct sk_buff *skb, struct net_device *netdev)\n{\n\tstruct nlattr *cee, *app;\n\tstruct dcb_app_type *itr;\n\tconst struct dcbnl_rtnl_ops *ops = netdev->dcbnl_ops;\n\tint dcbx, i, err = -EMSGSIZE;\n\tu8 value;\n\n\tif (nla_put_string(skb, DCB_ATTR_IFNAME, netdev->name))\n\t\tgoto nla_put_failure;\n\tcee = nla_nest_start(skb, DCB_ATTR_CEE);\n\tif (!cee)\n\t\tgoto nla_put_failure;\n\n\t/* local pg */\n\tif (ops->getpgtccfgtx && ops->getpgbwgcfgtx) {\n\t\terr = dcbnl_cee_pg_fill(skb, netdev, 1);\n\t\tif (err)\n\t\t\tgoto nla_put_failure;\n\t}\n\n\tif (ops->getpgtccfgrx && ops->getpgbwgcfgrx) {\n\t\terr = dcbnl_cee_pg_fill(skb, netdev, 0);\n\t\tif (err)\n\t\t\tgoto nla_put_failure;\n\t}\n\n\t/* local pfc */\n\tif (ops->getpfccfg) {\n\t\tstruct nlattr *pfc_nest = nla_nest_start(skb, DCB_ATTR_CEE_PFC);\n\n\t\tif (!pfc_nest)\n\t\t\tgoto nla_put_failure;\n\n\t\tfor (i = DCB_PFC_UP_ATTR_0; i <= DCB_PFC_UP_ATTR_7; i++) {\n\t\t\tops->getpfccfg(netdev, i - DCB_PFC_UP_ATTR_0, &value);\n\t\t\tif (nla_put_u8(skb, i, value))\n\t\t\t\tgoto nla_put_failure;\n\t\t}\n\t\tnla_nest_end(skb, pfc_nest);\n\t}\n\n\t/* local app */\n\tspin_lock(&dcb_lock);\n\tapp = nla_nest_start(skb, DCB_ATTR_CEE_APP_TABLE);\n\tif (!app)\n\t\tgoto dcb_unlock;\n\n\tlist_for_each_entry(itr, &dcb_app_list, list) {\n\t\tif (itr->ifindex == netdev->ifindex) {\n\t\t\tstruct nlattr *app_nest = nla_nest_start(skb,\n\t\t\t\t\t\t\t\t DCB_ATTR_APP);\n\t\t\tif (!app_nest)\n\t\t\t\tgoto dcb_unlock;\n\n\t\t\terr = nla_put_u8(skb, DCB_APP_ATTR_IDTYPE,\n\t\t\t\t\t itr->app.selector);\n\t\t\tif (err)\n\t\t\t\tgoto dcb_unlock;\n\n\t\t\terr = nla_put_u16(skb, DCB_APP_ATTR_ID,\n\t\t\t\t\t  itr->app.protocol);\n\t\t\tif (err)\n\t\t\t\tgoto dcb_unlock;\n\n\t\t\terr = nla_put_u8(skb, DCB_APP_ATTR_PRIORITY,\n\t\t\t\t\t itr->app.priority);\n\t\t\tif (err)\n\t\t\t\tgoto dcb_unlock;\n\n\t\t\tnla_nest_end(skb, app_nest);\n\t\t}\n\t}\n\tnla_nest_end(skb, app);\n\n\tif (netdev->dcbnl_ops->getdcbx)\n\t\tdcbx = netdev->dcbnl_ops->getdcbx(netdev);\n\telse\n\t\tdcbx = -EOPNOTSUPP;\n\n\tspin_unlock(&dcb_lock);\n\n\t/* features flags */\n\tif (ops->getfeatcfg) {\n\t\tstruct nlattr *feat = nla_nest_start(skb, DCB_ATTR_CEE_FEAT);\n\t\tif (!feat)\n\t\t\tgoto nla_put_failure;\n\n\t\tfor (i = DCB_FEATCFG_ATTR_ALL + 1; i <= DCB_FEATCFG_ATTR_MAX;\n\t\t     i++)\n\t\t\tif (!ops->getfeatcfg(netdev, i, &value) &&\n\t\t\t    nla_put_u8(skb, i, value))\n\t\t\t\tgoto nla_put_failure;\n\n\t\tnla_nest_end(skb, feat);\n\t}\n\n\t/* peer info if available */\n\tif (ops->cee_peer_getpg) {\n\t\tstruct cee_pg pg;\n\t\terr = ops->cee_peer_getpg(netdev, &pg);\n\t\tif (!err &&\n\t\t    nla_put(skb, DCB_ATTR_CEE_PEER_PG, sizeof(pg), &pg))\n\t\t\tgoto nla_put_failure;\n\t}\n\n\tif (ops->cee_peer_getpfc) {\n\t\tstruct cee_pfc pfc;\n\t\terr = ops->cee_peer_getpfc(netdev, &pfc);\n\t\tif (!err &&\n\t\t    nla_put(skb, DCB_ATTR_CEE_PEER_PFC, sizeof(pfc), &pfc))\n\t\t\tgoto nla_put_failure;\n\t}\n\n\tif (ops->peer_getappinfo && ops->peer_getapptable) {\n\t\terr = dcbnl_build_peer_app(netdev, skb,\n\t\t\t\t\t   DCB_ATTR_CEE_PEER_APP_TABLE,\n\t\t\t\t\t   DCB_ATTR_CEE_PEER_APP_INFO,\n\t\t\t\t\t   DCB_ATTR_CEE_PEER_APP);\n\t\tif (err)\n\t\t\tgoto nla_put_failure;\n\t}\n\tnla_nest_end(skb, cee);\n\n\t/* DCBX state */\n\tif (dcbx >= 0) {\n\t\terr = nla_put_u8(skb, DCB_ATTR_DCBX, dcbx);\n\t\tif (err)\n\t\t\tgoto nla_put_failure;\n\t}\n\treturn 0;\n\ndcb_unlock:\n\tspin_unlock(&dcb_lock);\nnla_put_failure:\n\treturn err;\n}",
        "func": "static int dcbnl_cee_fill(struct sk_buff *skb, struct net_device *netdev)\n{\n\tstruct nlattr *cee, *app;\n\tstruct dcb_app_type *itr;\n\tconst struct dcbnl_rtnl_ops *ops = netdev->dcbnl_ops;\n\tint dcbx, i, err = -EMSGSIZE;\n\tu8 value;\n\n\tif (nla_put_string(skb, DCB_ATTR_IFNAME, netdev->name))\n\t\tgoto nla_put_failure;\n\tcee = nla_nest_start(skb, DCB_ATTR_CEE);\n\tif (!cee)\n\t\tgoto nla_put_failure;\n\n\t/* local pg */\n\tif (ops->getpgtccfgtx && ops->getpgbwgcfgtx) {\n\t\terr = dcbnl_cee_pg_fill(skb, netdev, 1);\n\t\tif (err)\n\t\t\tgoto nla_put_failure;\n\t}\n\n\tif (ops->getpgtccfgrx && ops->getpgbwgcfgrx) {\n\t\terr = dcbnl_cee_pg_fill(skb, netdev, 0);\n\t\tif (err)\n\t\t\tgoto nla_put_failure;\n\t}\n\n\t/* local pfc */\n\tif (ops->getpfccfg) {\n\t\tstruct nlattr *pfc_nest = nla_nest_start(skb, DCB_ATTR_CEE_PFC);\n\n\t\tif (!pfc_nest)\n\t\t\tgoto nla_put_failure;\n\n\t\tfor (i = DCB_PFC_UP_ATTR_0; i <= DCB_PFC_UP_ATTR_7; i++) {\n\t\t\tops->getpfccfg(netdev, i - DCB_PFC_UP_ATTR_0, &value);\n\t\t\tif (nla_put_u8(skb, i, value))\n\t\t\t\tgoto nla_put_failure;\n\t\t}\n\t\tnla_nest_end(skb, pfc_nest);\n\t}\n\n\t/* local app */\n\tspin_lock(&dcb_lock);\n\tapp = nla_nest_start(skb, DCB_ATTR_CEE_APP_TABLE);\n\tif (!app)\n\t\tgoto dcb_unlock;\n\n\tlist_for_each_entry(itr, &dcb_app_list, list) {\n\t\tif (itr->ifindex == netdev->ifindex) {\n\t\t\tstruct nlattr *app_nest = nla_nest_start(skb,\n\t\t\t\t\t\t\t\t DCB_ATTR_APP);\n\t\t\tif (!app_nest)\n\t\t\t\tgoto dcb_unlock;\n\n\t\t\terr = nla_put_u8(skb, DCB_APP_ATTR_IDTYPE,\n\t\t\t\t\t itr->app.selector);\n\t\t\tif (err)\n\t\t\t\tgoto dcb_unlock;\n\n\t\t\terr = nla_put_u16(skb, DCB_APP_ATTR_ID,\n\t\t\t\t\t  itr->app.protocol);\n\t\t\tif (err)\n\t\t\t\tgoto dcb_unlock;\n\n\t\t\terr = nla_put_u8(skb, DCB_APP_ATTR_PRIORITY,\n\t\t\t\t\t itr->app.priority);\n\t\t\tif (err)\n\t\t\t\tgoto dcb_unlock;\n\n\t\t\tnla_nest_end(skb, app_nest);\n\t\t}\n\t}\n\tnla_nest_end(skb, app);\n\n\tif (netdev->dcbnl_ops->getdcbx)\n\t\tdcbx = netdev->dcbnl_ops->getdcbx(netdev);\n\telse\n\t\tdcbx = -EOPNOTSUPP;\n\n\tspin_unlock(&dcb_lock);\n\n\t/* features flags */\n\tif (ops->getfeatcfg) {\n\t\tstruct nlattr *feat = nla_nest_start(skb, DCB_ATTR_CEE_FEAT);\n\t\tif (!feat)\n\t\t\tgoto nla_put_failure;\n\n\t\tfor (i = DCB_FEATCFG_ATTR_ALL + 1; i <= DCB_FEATCFG_ATTR_MAX;\n\t\t     i++)\n\t\t\tif (!ops->getfeatcfg(netdev, i, &value) &&\n\t\t\t    nla_put_u8(skb, i, value))\n\t\t\t\tgoto nla_put_failure;\n\n\t\tnla_nest_end(skb, feat);\n\t}\n\n\t/* peer info if available */\n\tif (ops->cee_peer_getpg) {\n\t\tstruct cee_pg pg;\n\t\tmemset(&pg, 0, sizeof(pg));\n\t\terr = ops->cee_peer_getpg(netdev, &pg);\n\t\tif (!err &&\n\t\t    nla_put(skb, DCB_ATTR_CEE_PEER_PG, sizeof(pg), &pg))\n\t\t\tgoto nla_put_failure;\n\t}\n\n\tif (ops->cee_peer_getpfc) {\n\t\tstruct cee_pfc pfc;\n\t\tmemset(&pfc, 0, sizeof(pfc));\n\t\terr = ops->cee_peer_getpfc(netdev, &pfc);\n\t\tif (!err &&\n\t\t    nla_put(skb, DCB_ATTR_CEE_PEER_PFC, sizeof(pfc), &pfc))\n\t\t\tgoto nla_put_failure;\n\t}\n\n\tif (ops->peer_getappinfo && ops->peer_getapptable) {\n\t\terr = dcbnl_build_peer_app(netdev, skb,\n\t\t\t\t\t   DCB_ATTR_CEE_PEER_APP_TABLE,\n\t\t\t\t\t   DCB_ATTR_CEE_PEER_APP_INFO,\n\t\t\t\t\t   DCB_ATTR_CEE_PEER_APP);\n\t\tif (err)\n\t\t\tgoto nla_put_failure;\n\t}\n\tnla_nest_end(skb, cee);\n\n\t/* DCBX state */\n\tif (dcbx >= 0) {\n\t\terr = nla_put_u8(skb, DCB_ATTR_DCBX, dcbx);\n\t\tif (err)\n\t\t\tgoto nla_put_failure;\n\t}\n\treturn 0;\n\ndcb_unlock:\n\tspin_unlock(&dcb_lock);\nnla_put_failure:\n\treturn err;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -98,6 +98,7 @@\n \t/* peer info if available */\n \tif (ops->cee_peer_getpg) {\n \t\tstruct cee_pg pg;\n+\t\tmemset(&pg, 0, sizeof(pg));\n \t\terr = ops->cee_peer_getpg(netdev, &pg);\n \t\tif (!err &&\n \t\t    nla_put(skb, DCB_ATTR_CEE_PEER_PG, sizeof(pg), &pg))\n@@ -106,6 +107,7 @@\n \n \tif (ops->cee_peer_getpfc) {\n \t\tstruct cee_pfc pfc;\n+\t\tmemset(&pfc, 0, sizeof(pfc));\n \t\terr = ops->cee_peer_getpfc(netdev, &pfc);\n \t\tif (!err &&\n \t\t    nla_put(skb, DCB_ATTR_CEE_PEER_PFC, sizeof(pfc), &pfc))",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t\tmemset(&pg, 0, sizeof(pg));",
                "\t\tmemset(&pfc, 0, sizeof(pfc));"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-2634",
        "func_name": "torvalds/linux/dcbnl_ieee_fill",
        "description": "net/dcb/dcbnl.c in the Linux kernel before 3.8.4 does not initialize certain structures, which allows local users to obtain sensitive information from kernel stack memory via a crafted application.",
        "git_url": "https://github.com/torvalds/linux/commit/29cd8ae0e1a39e239a3a7b67da1986add1199fc0",
        "commit_title": "dcbnl: fix various netlink info leaks",
        "commit_text": " The dcb netlink interface leaks stack memory in various places: * perm_addr[] buffer is only filled at max with 12 of the 32 bytes but   copied completely, * no in-kernel driver fills all fields of an IEEE 802.1Qaz subcommand,   so we're leaking up to 58 bytes for ieee_ets structs, up to 136 bytes   for ieee_pfc structs, etc., * the same is true for CEE -- no in-kernel driver fills the whole   struct,  Prevent all of the above stack info leaks by properly initializing the buffers/structures involved. ",
        "func_before": "static int dcbnl_ieee_fill(struct sk_buff *skb, struct net_device *netdev)\n{\n\tstruct nlattr *ieee, *app;\n\tstruct dcb_app_type *itr;\n\tconst struct dcbnl_rtnl_ops *ops = netdev->dcbnl_ops;\n\tint dcbx;\n\tint err;\n\n\tif (nla_put_string(skb, DCB_ATTR_IFNAME, netdev->name))\n\t\treturn -EMSGSIZE;\n\n\tieee = nla_nest_start(skb, DCB_ATTR_IEEE);\n\tif (!ieee)\n\t\treturn -EMSGSIZE;\n\n\tif (ops->ieee_getets) {\n\t\tstruct ieee_ets ets;\n\t\terr = ops->ieee_getets(netdev, &ets);\n\t\tif (!err &&\n\t\t    nla_put(skb, DCB_ATTR_IEEE_ETS, sizeof(ets), &ets))\n\t\t\treturn -EMSGSIZE;\n\t}\n\n\tif (ops->ieee_getmaxrate) {\n\t\tstruct ieee_maxrate maxrate;\n\t\terr = ops->ieee_getmaxrate(netdev, &maxrate);\n\t\tif (!err) {\n\t\t\terr = nla_put(skb, DCB_ATTR_IEEE_MAXRATE,\n\t\t\t\t      sizeof(maxrate), &maxrate);\n\t\t\tif (err)\n\t\t\t\treturn -EMSGSIZE;\n\t\t}\n\t}\n\n\tif (ops->ieee_getpfc) {\n\t\tstruct ieee_pfc pfc;\n\t\terr = ops->ieee_getpfc(netdev, &pfc);\n\t\tif (!err &&\n\t\t    nla_put(skb, DCB_ATTR_IEEE_PFC, sizeof(pfc), &pfc))\n\t\t\treturn -EMSGSIZE;\n\t}\n\n\tapp = nla_nest_start(skb, DCB_ATTR_IEEE_APP_TABLE);\n\tif (!app)\n\t\treturn -EMSGSIZE;\n\n\tspin_lock(&dcb_lock);\n\tlist_for_each_entry(itr, &dcb_app_list, list) {\n\t\tif (itr->ifindex == netdev->ifindex) {\n\t\t\terr = nla_put(skb, DCB_ATTR_IEEE_APP, sizeof(itr->app),\n\t\t\t\t\t &itr->app);\n\t\t\tif (err) {\n\t\t\t\tspin_unlock(&dcb_lock);\n\t\t\t\treturn -EMSGSIZE;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (netdev->dcbnl_ops->getdcbx)\n\t\tdcbx = netdev->dcbnl_ops->getdcbx(netdev);\n\telse\n\t\tdcbx = -EOPNOTSUPP;\n\n\tspin_unlock(&dcb_lock);\n\tnla_nest_end(skb, app);\n\n\t/* get peer info if available */\n\tif (ops->ieee_peer_getets) {\n\t\tstruct ieee_ets ets;\n\t\terr = ops->ieee_peer_getets(netdev, &ets);\n\t\tif (!err &&\n\t\t    nla_put(skb, DCB_ATTR_IEEE_PEER_ETS, sizeof(ets), &ets))\n\t\t\treturn -EMSGSIZE;\n\t}\n\n\tif (ops->ieee_peer_getpfc) {\n\t\tstruct ieee_pfc pfc;\n\t\terr = ops->ieee_peer_getpfc(netdev, &pfc);\n\t\tif (!err &&\n\t\t    nla_put(skb, DCB_ATTR_IEEE_PEER_PFC, sizeof(pfc), &pfc))\n\t\t\treturn -EMSGSIZE;\n\t}\n\n\tif (ops->peer_getappinfo && ops->peer_getapptable) {\n\t\terr = dcbnl_build_peer_app(netdev, skb,\n\t\t\t\t\t   DCB_ATTR_IEEE_PEER_APP,\n\t\t\t\t\t   DCB_ATTR_IEEE_APP_UNSPEC,\n\t\t\t\t\t   DCB_ATTR_IEEE_APP);\n\t\tif (err)\n\t\t\treturn -EMSGSIZE;\n\t}\n\n\tnla_nest_end(skb, ieee);\n\tif (dcbx >= 0) {\n\t\terr = nla_put_u8(skb, DCB_ATTR_DCBX, dcbx);\n\t\tif (err)\n\t\t\treturn -EMSGSIZE;\n\t}\n\n\treturn 0;\n}",
        "func": "static int dcbnl_ieee_fill(struct sk_buff *skb, struct net_device *netdev)\n{\n\tstruct nlattr *ieee, *app;\n\tstruct dcb_app_type *itr;\n\tconst struct dcbnl_rtnl_ops *ops = netdev->dcbnl_ops;\n\tint dcbx;\n\tint err;\n\n\tif (nla_put_string(skb, DCB_ATTR_IFNAME, netdev->name))\n\t\treturn -EMSGSIZE;\n\n\tieee = nla_nest_start(skb, DCB_ATTR_IEEE);\n\tif (!ieee)\n\t\treturn -EMSGSIZE;\n\n\tif (ops->ieee_getets) {\n\t\tstruct ieee_ets ets;\n\t\tmemset(&ets, 0, sizeof(ets));\n\t\terr = ops->ieee_getets(netdev, &ets);\n\t\tif (!err &&\n\t\t    nla_put(skb, DCB_ATTR_IEEE_ETS, sizeof(ets), &ets))\n\t\t\treturn -EMSGSIZE;\n\t}\n\n\tif (ops->ieee_getmaxrate) {\n\t\tstruct ieee_maxrate maxrate;\n\t\tmemset(&maxrate, 0, sizeof(maxrate));\n\t\terr = ops->ieee_getmaxrate(netdev, &maxrate);\n\t\tif (!err) {\n\t\t\terr = nla_put(skb, DCB_ATTR_IEEE_MAXRATE,\n\t\t\t\t      sizeof(maxrate), &maxrate);\n\t\t\tif (err)\n\t\t\t\treturn -EMSGSIZE;\n\t\t}\n\t}\n\n\tif (ops->ieee_getpfc) {\n\t\tstruct ieee_pfc pfc;\n\t\tmemset(&pfc, 0, sizeof(pfc));\n\t\terr = ops->ieee_getpfc(netdev, &pfc);\n\t\tif (!err &&\n\t\t    nla_put(skb, DCB_ATTR_IEEE_PFC, sizeof(pfc), &pfc))\n\t\t\treturn -EMSGSIZE;\n\t}\n\n\tapp = nla_nest_start(skb, DCB_ATTR_IEEE_APP_TABLE);\n\tif (!app)\n\t\treturn -EMSGSIZE;\n\n\tspin_lock(&dcb_lock);\n\tlist_for_each_entry(itr, &dcb_app_list, list) {\n\t\tif (itr->ifindex == netdev->ifindex) {\n\t\t\terr = nla_put(skb, DCB_ATTR_IEEE_APP, sizeof(itr->app),\n\t\t\t\t\t &itr->app);\n\t\t\tif (err) {\n\t\t\t\tspin_unlock(&dcb_lock);\n\t\t\t\treturn -EMSGSIZE;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (netdev->dcbnl_ops->getdcbx)\n\t\tdcbx = netdev->dcbnl_ops->getdcbx(netdev);\n\telse\n\t\tdcbx = -EOPNOTSUPP;\n\n\tspin_unlock(&dcb_lock);\n\tnla_nest_end(skb, app);\n\n\t/* get peer info if available */\n\tif (ops->ieee_peer_getets) {\n\t\tstruct ieee_ets ets;\n\t\tmemset(&ets, 0, sizeof(ets));\n\t\terr = ops->ieee_peer_getets(netdev, &ets);\n\t\tif (!err &&\n\t\t    nla_put(skb, DCB_ATTR_IEEE_PEER_ETS, sizeof(ets), &ets))\n\t\t\treturn -EMSGSIZE;\n\t}\n\n\tif (ops->ieee_peer_getpfc) {\n\t\tstruct ieee_pfc pfc;\n\t\tmemset(&pfc, 0, sizeof(pfc));\n\t\terr = ops->ieee_peer_getpfc(netdev, &pfc);\n\t\tif (!err &&\n\t\t    nla_put(skb, DCB_ATTR_IEEE_PEER_PFC, sizeof(pfc), &pfc))\n\t\t\treturn -EMSGSIZE;\n\t}\n\n\tif (ops->peer_getappinfo && ops->peer_getapptable) {\n\t\terr = dcbnl_build_peer_app(netdev, skb,\n\t\t\t\t\t   DCB_ATTR_IEEE_PEER_APP,\n\t\t\t\t\t   DCB_ATTR_IEEE_APP_UNSPEC,\n\t\t\t\t\t   DCB_ATTR_IEEE_APP);\n\t\tif (err)\n\t\t\treturn -EMSGSIZE;\n\t}\n\n\tnla_nest_end(skb, ieee);\n\tif (dcbx >= 0) {\n\t\terr = nla_put_u8(skb, DCB_ATTR_DCBX, dcbx);\n\t\tif (err)\n\t\t\treturn -EMSGSIZE;\n\t}\n\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -15,6 +15,7 @@\n \n \tif (ops->ieee_getets) {\n \t\tstruct ieee_ets ets;\n+\t\tmemset(&ets, 0, sizeof(ets));\n \t\terr = ops->ieee_getets(netdev, &ets);\n \t\tif (!err &&\n \t\t    nla_put(skb, DCB_ATTR_IEEE_ETS, sizeof(ets), &ets))\n@@ -23,6 +24,7 @@\n \n \tif (ops->ieee_getmaxrate) {\n \t\tstruct ieee_maxrate maxrate;\n+\t\tmemset(&maxrate, 0, sizeof(maxrate));\n \t\terr = ops->ieee_getmaxrate(netdev, &maxrate);\n \t\tif (!err) {\n \t\t\terr = nla_put(skb, DCB_ATTR_IEEE_MAXRATE,\n@@ -34,6 +36,7 @@\n \n \tif (ops->ieee_getpfc) {\n \t\tstruct ieee_pfc pfc;\n+\t\tmemset(&pfc, 0, sizeof(pfc));\n \t\terr = ops->ieee_getpfc(netdev, &pfc);\n \t\tif (!err &&\n \t\t    nla_put(skb, DCB_ATTR_IEEE_PFC, sizeof(pfc), &pfc))\n@@ -67,6 +70,7 @@\n \t/* get peer info if available */\n \tif (ops->ieee_peer_getets) {\n \t\tstruct ieee_ets ets;\n+\t\tmemset(&ets, 0, sizeof(ets));\n \t\terr = ops->ieee_peer_getets(netdev, &ets);\n \t\tif (!err &&\n \t\t    nla_put(skb, DCB_ATTR_IEEE_PEER_ETS, sizeof(ets), &ets))\n@@ -75,6 +79,7 @@\n \n \tif (ops->ieee_peer_getpfc) {\n \t\tstruct ieee_pfc pfc;\n+\t\tmemset(&pfc, 0, sizeof(pfc));\n \t\terr = ops->ieee_peer_getpfc(netdev, &pfc);\n \t\tif (!err &&\n \t\t    nla_put(skb, DCB_ATTR_IEEE_PEER_PFC, sizeof(pfc), &pfc))",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t\tmemset(&ets, 0, sizeof(ets));",
                "\t\tmemset(&maxrate, 0, sizeof(maxrate));",
                "\t\tmemset(&pfc, 0, sizeof(pfc));",
                "\t\tmemset(&ets, 0, sizeof(ets));",
                "\t\tmemset(&pfc, 0, sizeof(pfc));"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-2634",
        "func_name": "torvalds/linux/dcbnl_getperm_hwaddr",
        "description": "net/dcb/dcbnl.c in the Linux kernel before 3.8.4 does not initialize certain structures, which allows local users to obtain sensitive information from kernel stack memory via a crafted application.",
        "git_url": "https://github.com/torvalds/linux/commit/29cd8ae0e1a39e239a3a7b67da1986add1199fc0",
        "commit_title": "dcbnl: fix various netlink info leaks",
        "commit_text": " The dcb netlink interface leaks stack memory in various places: * perm_addr[] buffer is only filled at max with 12 of the 32 bytes but   copied completely, * no in-kernel driver fills all fields of an IEEE 802.1Qaz subcommand,   so we're leaking up to 58 bytes for ieee_ets structs, up to 136 bytes   for ieee_pfc structs, etc., * the same is true for CEE -- no in-kernel driver fills the whole   struct,  Prevent all of the above stack info leaks by properly initializing the buffers/structures involved. ",
        "func_before": "static int dcbnl_getperm_hwaddr(struct net_device *netdev, struct nlmsghdr *nlh,\n\t\t\t\tu32 seq, struct nlattr **tb, struct sk_buff *skb)\n{\n\tu8 perm_addr[MAX_ADDR_LEN];\n\n\tif (!netdev->dcbnl_ops->getpermhwaddr)\n\t\treturn -EOPNOTSUPP;\n\n\tnetdev->dcbnl_ops->getpermhwaddr(netdev, perm_addr);\n\n\treturn nla_put(skb, DCB_ATTR_PERM_HWADDR, sizeof(perm_addr), perm_addr);\n}",
        "func": "static int dcbnl_getperm_hwaddr(struct net_device *netdev, struct nlmsghdr *nlh,\n\t\t\t\tu32 seq, struct nlattr **tb, struct sk_buff *skb)\n{\n\tu8 perm_addr[MAX_ADDR_LEN];\n\n\tif (!netdev->dcbnl_ops->getpermhwaddr)\n\t\treturn -EOPNOTSUPP;\n\n\tmemset(perm_addr, 0, sizeof(perm_addr));\n\tnetdev->dcbnl_ops->getpermhwaddr(netdev, perm_addr);\n\n\treturn nla_put(skb, DCB_ATTR_PERM_HWADDR, sizeof(perm_addr), perm_addr);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -6,6 +6,7 @@\n \tif (!netdev->dcbnl_ops->getpermhwaddr)\n \t\treturn -EOPNOTSUPP;\n \n+\tmemset(perm_addr, 0, sizeof(perm_addr));\n \tnetdev->dcbnl_ops->getpermhwaddr(netdev, perm_addr);\n \n \treturn nla_put(skb, DCB_ATTR_PERM_HWADDR, sizeof(perm_addr), perm_addr);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tmemset(perm_addr, 0, sizeof(perm_addr));"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-2635",
        "func_name": "torvalds/linux/rtnl_fill_ifinfo",
        "description": "The rtnl_fill_ifinfo function in net/core/rtnetlink.c in the Linux kernel before 3.8.4 does not initialize a certain structure member, which allows local users to obtain sensitive information from kernel stack memory via a crafted application.",
        "git_url": "https://github.com/torvalds/linux/commit/84d73cd3fb142bf1298a8c13fd4ca50fd2432372",
        "commit_title": "rtnl: fix info leak on RTM_GETLINK request for VF devices",
        "commit_text": " Initialize the mac address buffer with 0 as the driver specific function will probably not fill the whole buffer. In fact, all in-kernel drivers fill only ETH_ALEN of the MAX_ADDR_LEN bytes, i.e. 6 of the 32 possible bytes. Therefore we currently leak 26 bytes of stack memory to userland via the netlink interface. ",
        "func_before": "static int rtnl_fill_ifinfo(struct sk_buff *skb, struct net_device *dev,\n\t\t\t    int type, u32 pid, u32 seq, u32 change,\n\t\t\t    unsigned int flags, u32 ext_filter_mask)\n{\n\tstruct ifinfomsg *ifm;\n\tstruct nlmsghdr *nlh;\n\tstruct rtnl_link_stats64 temp;\n\tconst struct rtnl_link_stats64 *stats;\n\tstruct nlattr *attr, *af_spec;\n\tstruct rtnl_af_ops *af_ops;\n\tstruct net_device *upper_dev = netdev_master_upper_dev_get(dev);\n\n\tASSERT_RTNL();\n\tnlh = nlmsg_put(skb, pid, seq, type, sizeof(*ifm), flags);\n\tif (nlh == NULL)\n\t\treturn -EMSGSIZE;\n\n\tifm = nlmsg_data(nlh);\n\tifm->ifi_family = AF_UNSPEC;\n\tifm->__ifi_pad = 0;\n\tifm->ifi_type = dev->type;\n\tifm->ifi_index = dev->ifindex;\n\tifm->ifi_flags = dev_get_flags(dev);\n\tifm->ifi_change = change;\n\n\tif (nla_put_string(skb, IFLA_IFNAME, dev->name) ||\n\t    nla_put_u32(skb, IFLA_TXQLEN, dev->tx_queue_len) ||\n\t    nla_put_u8(skb, IFLA_OPERSTATE,\n\t\t       netif_running(dev) ? dev->operstate : IF_OPER_DOWN) ||\n\t    nla_put_u8(skb, IFLA_LINKMODE, dev->link_mode) ||\n\t    nla_put_u32(skb, IFLA_MTU, dev->mtu) ||\n\t    nla_put_u32(skb, IFLA_GROUP, dev->group) ||\n\t    nla_put_u32(skb, IFLA_PROMISCUITY, dev->promiscuity) ||\n\t    nla_put_u32(skb, IFLA_NUM_TX_QUEUES, dev->num_tx_queues) ||\n#ifdef CONFIG_RPS\n\t    nla_put_u32(skb, IFLA_NUM_RX_QUEUES, dev->num_rx_queues) ||\n#endif\n\t    (dev->ifindex != dev->iflink &&\n\t     nla_put_u32(skb, IFLA_LINK, dev->iflink)) ||\n\t    (upper_dev &&\n\t     nla_put_u32(skb, IFLA_MASTER, upper_dev->ifindex)) ||\n\t    nla_put_u8(skb, IFLA_CARRIER, netif_carrier_ok(dev)) ||\n\t    (dev->qdisc &&\n\t     nla_put_string(skb, IFLA_QDISC, dev->qdisc->ops->id)) ||\n\t    (dev->ifalias &&\n\t     nla_put_string(skb, IFLA_IFALIAS, dev->ifalias)))\n\t\tgoto nla_put_failure;\n\n\tif (1) {\n\t\tstruct rtnl_link_ifmap map = {\n\t\t\t.mem_start   = dev->mem_start,\n\t\t\t.mem_end     = dev->mem_end,\n\t\t\t.base_addr   = dev->base_addr,\n\t\t\t.irq         = dev->irq,\n\t\t\t.dma         = dev->dma,\n\t\t\t.port        = dev->if_port,\n\t\t};\n\t\tif (nla_put(skb, IFLA_MAP, sizeof(map), &map))\n\t\t\tgoto nla_put_failure;\n\t}\n\n\tif (dev->addr_len) {\n\t\tif (nla_put(skb, IFLA_ADDRESS, dev->addr_len, dev->dev_addr) ||\n\t\t    nla_put(skb, IFLA_BROADCAST, dev->addr_len, dev->broadcast))\n\t\t\tgoto nla_put_failure;\n\t}\n\n\tattr = nla_reserve(skb, IFLA_STATS,\n\t\t\tsizeof(struct rtnl_link_stats));\n\tif (attr == NULL)\n\t\tgoto nla_put_failure;\n\n\tstats = dev_get_stats(dev, &temp);\n\tcopy_rtnl_link_stats(nla_data(attr), stats);\n\n\tattr = nla_reserve(skb, IFLA_STATS64,\n\t\t\tsizeof(struct rtnl_link_stats64));\n\tif (attr == NULL)\n\t\tgoto nla_put_failure;\n\tcopy_rtnl_link_stats64(nla_data(attr), stats);\n\n\tif (dev->dev.parent && (ext_filter_mask & RTEXT_FILTER_VF) &&\n\t    nla_put_u32(skb, IFLA_NUM_VF, dev_num_vf(dev->dev.parent)))\n\t\tgoto nla_put_failure;\n\n\tif (dev->netdev_ops->ndo_get_vf_config && dev->dev.parent\n\t    && (ext_filter_mask & RTEXT_FILTER_VF)) {\n\t\tint i;\n\n\t\tstruct nlattr *vfinfo, *vf;\n\t\tint num_vfs = dev_num_vf(dev->dev.parent);\n\n\t\tvfinfo = nla_nest_start(skb, IFLA_VFINFO_LIST);\n\t\tif (!vfinfo)\n\t\t\tgoto nla_put_failure;\n\t\tfor (i = 0; i < num_vfs; i++) {\n\t\t\tstruct ifla_vf_info ivi;\n\t\t\tstruct ifla_vf_mac vf_mac;\n\t\t\tstruct ifla_vf_vlan vf_vlan;\n\t\t\tstruct ifla_vf_tx_rate vf_tx_rate;\n\t\t\tstruct ifla_vf_spoofchk vf_spoofchk;\n\n\t\t\t/*\n\t\t\t * Not all SR-IOV capable drivers support the\n\t\t\t * spoofcheck query.  Preset to -1 so the user\n\t\t\t * space tool can detect that the driver didn't\n\t\t\t * report anything.\n\t\t\t */\n\t\t\tivi.spoofchk = -1;\n\t\t\tif (dev->netdev_ops->ndo_get_vf_config(dev, i, &ivi))\n\t\t\t\tbreak;\n\t\t\tvf_mac.vf =\n\t\t\t\tvf_vlan.vf =\n\t\t\t\tvf_tx_rate.vf =\n\t\t\t\tvf_spoofchk.vf = ivi.vf;\n\n\t\t\tmemcpy(vf_mac.mac, ivi.mac, sizeof(ivi.mac));\n\t\t\tvf_vlan.vlan = ivi.vlan;\n\t\t\tvf_vlan.qos = ivi.qos;\n\t\t\tvf_tx_rate.rate = ivi.tx_rate;\n\t\t\tvf_spoofchk.setting = ivi.spoofchk;\n\t\t\tvf = nla_nest_start(skb, IFLA_VF_INFO);\n\t\t\tif (!vf) {\n\t\t\t\tnla_nest_cancel(skb, vfinfo);\n\t\t\t\tgoto nla_put_failure;\n\t\t\t}\n\t\t\tif (nla_put(skb, IFLA_VF_MAC, sizeof(vf_mac), &vf_mac) ||\n\t\t\t    nla_put(skb, IFLA_VF_VLAN, sizeof(vf_vlan), &vf_vlan) ||\n\t\t\t    nla_put(skb, IFLA_VF_TX_RATE, sizeof(vf_tx_rate),\n\t\t\t\t    &vf_tx_rate) ||\n\t\t\t    nla_put(skb, IFLA_VF_SPOOFCHK, sizeof(vf_spoofchk),\n\t\t\t\t    &vf_spoofchk))\n\t\t\t\tgoto nla_put_failure;\n\t\t\tnla_nest_end(skb, vf);\n\t\t}\n\t\tnla_nest_end(skb, vfinfo);\n\t}\n\n\tif (rtnl_port_fill(skb, dev))\n\t\tgoto nla_put_failure;\n\n\tif (dev->rtnl_link_ops) {\n\t\tif (rtnl_link_fill(skb, dev) < 0)\n\t\t\tgoto nla_put_failure;\n\t}\n\n\tif (!(af_spec = nla_nest_start(skb, IFLA_AF_SPEC)))\n\t\tgoto nla_put_failure;\n\n\tlist_for_each_entry(af_ops, &rtnl_af_ops, list) {\n\t\tif (af_ops->fill_link_af) {\n\t\t\tstruct nlattr *af;\n\t\t\tint err;\n\n\t\t\tif (!(af = nla_nest_start(skb, af_ops->family)))\n\t\t\t\tgoto nla_put_failure;\n\n\t\t\terr = af_ops->fill_link_af(skb, dev);\n\n\t\t\t/*\n\t\t\t * Caller may return ENODATA to indicate that there\n\t\t\t * was no data to be dumped. This is not an error, it\n\t\t\t * means we should trim the attribute header and\n\t\t\t * continue.\n\t\t\t */\n\t\t\tif (err == -ENODATA)\n\t\t\t\tnla_nest_cancel(skb, af);\n\t\t\telse if (err < 0)\n\t\t\t\tgoto nla_put_failure;\n\n\t\t\tnla_nest_end(skb, af);\n\t\t}\n\t}\n\n\tnla_nest_end(skb, af_spec);\n\n\treturn nlmsg_end(skb, nlh);\n\nnla_put_failure:\n\tnlmsg_cancel(skb, nlh);\n\treturn -EMSGSIZE;\n}",
        "func": "static int rtnl_fill_ifinfo(struct sk_buff *skb, struct net_device *dev,\n\t\t\t    int type, u32 pid, u32 seq, u32 change,\n\t\t\t    unsigned int flags, u32 ext_filter_mask)\n{\n\tstruct ifinfomsg *ifm;\n\tstruct nlmsghdr *nlh;\n\tstruct rtnl_link_stats64 temp;\n\tconst struct rtnl_link_stats64 *stats;\n\tstruct nlattr *attr, *af_spec;\n\tstruct rtnl_af_ops *af_ops;\n\tstruct net_device *upper_dev = netdev_master_upper_dev_get(dev);\n\n\tASSERT_RTNL();\n\tnlh = nlmsg_put(skb, pid, seq, type, sizeof(*ifm), flags);\n\tif (nlh == NULL)\n\t\treturn -EMSGSIZE;\n\n\tifm = nlmsg_data(nlh);\n\tifm->ifi_family = AF_UNSPEC;\n\tifm->__ifi_pad = 0;\n\tifm->ifi_type = dev->type;\n\tifm->ifi_index = dev->ifindex;\n\tifm->ifi_flags = dev_get_flags(dev);\n\tifm->ifi_change = change;\n\n\tif (nla_put_string(skb, IFLA_IFNAME, dev->name) ||\n\t    nla_put_u32(skb, IFLA_TXQLEN, dev->tx_queue_len) ||\n\t    nla_put_u8(skb, IFLA_OPERSTATE,\n\t\t       netif_running(dev) ? dev->operstate : IF_OPER_DOWN) ||\n\t    nla_put_u8(skb, IFLA_LINKMODE, dev->link_mode) ||\n\t    nla_put_u32(skb, IFLA_MTU, dev->mtu) ||\n\t    nla_put_u32(skb, IFLA_GROUP, dev->group) ||\n\t    nla_put_u32(skb, IFLA_PROMISCUITY, dev->promiscuity) ||\n\t    nla_put_u32(skb, IFLA_NUM_TX_QUEUES, dev->num_tx_queues) ||\n#ifdef CONFIG_RPS\n\t    nla_put_u32(skb, IFLA_NUM_RX_QUEUES, dev->num_rx_queues) ||\n#endif\n\t    (dev->ifindex != dev->iflink &&\n\t     nla_put_u32(skb, IFLA_LINK, dev->iflink)) ||\n\t    (upper_dev &&\n\t     nla_put_u32(skb, IFLA_MASTER, upper_dev->ifindex)) ||\n\t    nla_put_u8(skb, IFLA_CARRIER, netif_carrier_ok(dev)) ||\n\t    (dev->qdisc &&\n\t     nla_put_string(skb, IFLA_QDISC, dev->qdisc->ops->id)) ||\n\t    (dev->ifalias &&\n\t     nla_put_string(skb, IFLA_IFALIAS, dev->ifalias)))\n\t\tgoto nla_put_failure;\n\n\tif (1) {\n\t\tstruct rtnl_link_ifmap map = {\n\t\t\t.mem_start   = dev->mem_start,\n\t\t\t.mem_end     = dev->mem_end,\n\t\t\t.base_addr   = dev->base_addr,\n\t\t\t.irq         = dev->irq,\n\t\t\t.dma         = dev->dma,\n\t\t\t.port        = dev->if_port,\n\t\t};\n\t\tif (nla_put(skb, IFLA_MAP, sizeof(map), &map))\n\t\t\tgoto nla_put_failure;\n\t}\n\n\tif (dev->addr_len) {\n\t\tif (nla_put(skb, IFLA_ADDRESS, dev->addr_len, dev->dev_addr) ||\n\t\t    nla_put(skb, IFLA_BROADCAST, dev->addr_len, dev->broadcast))\n\t\t\tgoto nla_put_failure;\n\t}\n\n\tattr = nla_reserve(skb, IFLA_STATS,\n\t\t\tsizeof(struct rtnl_link_stats));\n\tif (attr == NULL)\n\t\tgoto nla_put_failure;\n\n\tstats = dev_get_stats(dev, &temp);\n\tcopy_rtnl_link_stats(nla_data(attr), stats);\n\n\tattr = nla_reserve(skb, IFLA_STATS64,\n\t\t\tsizeof(struct rtnl_link_stats64));\n\tif (attr == NULL)\n\t\tgoto nla_put_failure;\n\tcopy_rtnl_link_stats64(nla_data(attr), stats);\n\n\tif (dev->dev.parent && (ext_filter_mask & RTEXT_FILTER_VF) &&\n\t    nla_put_u32(skb, IFLA_NUM_VF, dev_num_vf(dev->dev.parent)))\n\t\tgoto nla_put_failure;\n\n\tif (dev->netdev_ops->ndo_get_vf_config && dev->dev.parent\n\t    && (ext_filter_mask & RTEXT_FILTER_VF)) {\n\t\tint i;\n\n\t\tstruct nlattr *vfinfo, *vf;\n\t\tint num_vfs = dev_num_vf(dev->dev.parent);\n\n\t\tvfinfo = nla_nest_start(skb, IFLA_VFINFO_LIST);\n\t\tif (!vfinfo)\n\t\t\tgoto nla_put_failure;\n\t\tfor (i = 0; i < num_vfs; i++) {\n\t\t\tstruct ifla_vf_info ivi;\n\t\t\tstruct ifla_vf_mac vf_mac;\n\t\t\tstruct ifla_vf_vlan vf_vlan;\n\t\t\tstruct ifla_vf_tx_rate vf_tx_rate;\n\t\t\tstruct ifla_vf_spoofchk vf_spoofchk;\n\n\t\t\t/*\n\t\t\t * Not all SR-IOV capable drivers support the\n\t\t\t * spoofcheck query.  Preset to -1 so the user\n\t\t\t * space tool can detect that the driver didn't\n\t\t\t * report anything.\n\t\t\t */\n\t\t\tivi.spoofchk = -1;\n\t\t\tmemset(ivi.mac, 0, sizeof(ivi.mac));\n\t\t\tif (dev->netdev_ops->ndo_get_vf_config(dev, i, &ivi))\n\t\t\t\tbreak;\n\t\t\tvf_mac.vf =\n\t\t\t\tvf_vlan.vf =\n\t\t\t\tvf_tx_rate.vf =\n\t\t\t\tvf_spoofchk.vf = ivi.vf;\n\n\t\t\tmemcpy(vf_mac.mac, ivi.mac, sizeof(ivi.mac));\n\t\t\tvf_vlan.vlan = ivi.vlan;\n\t\t\tvf_vlan.qos = ivi.qos;\n\t\t\tvf_tx_rate.rate = ivi.tx_rate;\n\t\t\tvf_spoofchk.setting = ivi.spoofchk;\n\t\t\tvf = nla_nest_start(skb, IFLA_VF_INFO);\n\t\t\tif (!vf) {\n\t\t\t\tnla_nest_cancel(skb, vfinfo);\n\t\t\t\tgoto nla_put_failure;\n\t\t\t}\n\t\t\tif (nla_put(skb, IFLA_VF_MAC, sizeof(vf_mac), &vf_mac) ||\n\t\t\t    nla_put(skb, IFLA_VF_VLAN, sizeof(vf_vlan), &vf_vlan) ||\n\t\t\t    nla_put(skb, IFLA_VF_TX_RATE, sizeof(vf_tx_rate),\n\t\t\t\t    &vf_tx_rate) ||\n\t\t\t    nla_put(skb, IFLA_VF_SPOOFCHK, sizeof(vf_spoofchk),\n\t\t\t\t    &vf_spoofchk))\n\t\t\t\tgoto nla_put_failure;\n\t\t\tnla_nest_end(skb, vf);\n\t\t}\n\t\tnla_nest_end(skb, vfinfo);\n\t}\n\n\tif (rtnl_port_fill(skb, dev))\n\t\tgoto nla_put_failure;\n\n\tif (dev->rtnl_link_ops) {\n\t\tif (rtnl_link_fill(skb, dev) < 0)\n\t\t\tgoto nla_put_failure;\n\t}\n\n\tif (!(af_spec = nla_nest_start(skb, IFLA_AF_SPEC)))\n\t\tgoto nla_put_failure;\n\n\tlist_for_each_entry(af_ops, &rtnl_af_ops, list) {\n\t\tif (af_ops->fill_link_af) {\n\t\t\tstruct nlattr *af;\n\t\t\tint err;\n\n\t\t\tif (!(af = nla_nest_start(skb, af_ops->family)))\n\t\t\t\tgoto nla_put_failure;\n\n\t\t\terr = af_ops->fill_link_af(skb, dev);\n\n\t\t\t/*\n\t\t\t * Caller may return ENODATA to indicate that there\n\t\t\t * was no data to be dumped. This is not an error, it\n\t\t\t * means we should trim the attribute header and\n\t\t\t * continue.\n\t\t\t */\n\t\t\tif (err == -ENODATA)\n\t\t\t\tnla_nest_cancel(skb, af);\n\t\t\telse if (err < 0)\n\t\t\t\tgoto nla_put_failure;\n\n\t\t\tnla_nest_end(skb, af);\n\t\t}\n\t}\n\n\tnla_nest_end(skb, af_spec);\n\n\treturn nlmsg_end(skb, nlh);\n\nnla_put_failure:\n\tnlmsg_cancel(skb, nlh);\n\treturn -EMSGSIZE;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -107,6 +107,7 @@\n \t\t\t * report anything.\n \t\t\t */\n \t\t\tivi.spoofchk = -1;\n+\t\t\tmemset(ivi.mac, 0, sizeof(ivi.mac));\n \t\t\tif (dev->netdev_ops->ndo_get_vf_config(dev, i, &ivi))\n \t\t\t\tbreak;\n \t\t\tvf_mac.vf =",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t\t\tmemset(ivi.mac, 0, sizeof(ivi.mac));"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-2636",
        "func_name": "torvalds/linux/nlmsg_populate_mdb_fill",
        "description": "net/bridge/br_mdb.c in the Linux kernel before 3.8.4 does not initialize certain structures, which allows local users to obtain sensitive information from kernel memory via a crafted application.",
        "git_url": "https://github.com/torvalds/linux/commit/c085c49920b2f900ba716b4ca1c1a55ece9872cc",
        "commit_title": "bridge: fix mdb info leaks",
        "commit_text": " The bridging code discloses heap and stack bytes via the RTM_GETMDB netlink interface and via the notify messages send to group RTNLGRP_MDB afer a successful add/del.  Fix both cases by initializing all unset members/padding bytes with memset(0).  Cc: Stephen Hemminger <stephen@networkplumber.org>",
        "func_before": "static int nlmsg_populate_mdb_fill(struct sk_buff *skb,\n\t\t\t\t   struct net_device *dev,\n\t\t\t\t   struct br_mdb_entry *entry, u32 pid,\n\t\t\t\t   u32 seq, int type, unsigned int flags)\n{\n\tstruct nlmsghdr *nlh;\n\tstruct br_port_msg *bpm;\n\tstruct nlattr *nest, *nest2;\n\n\tnlh = nlmsg_put(skb, pid, seq, type, sizeof(*bpm), NLM_F_MULTI);\n\tif (!nlh)\n\t\treturn -EMSGSIZE;\n\n\tbpm = nlmsg_data(nlh);\n\tbpm->family  = AF_BRIDGE;\n\tbpm->ifindex = dev->ifindex;\n\tnest = nla_nest_start(skb, MDBA_MDB);\n\tif (nest == NULL)\n\t\tgoto cancel;\n\tnest2 = nla_nest_start(skb, MDBA_MDB_ENTRY);\n\tif (nest2 == NULL)\n\t\tgoto end;\n\n\tif (nla_put(skb, MDBA_MDB_ENTRY_INFO, sizeof(*entry), entry))\n\t\tgoto end;\n\n\tnla_nest_end(skb, nest2);\n\tnla_nest_end(skb, nest);\n\treturn nlmsg_end(skb, nlh);\n\nend:\n\tnla_nest_end(skb, nest);\ncancel:\n\tnlmsg_cancel(skb, nlh);\n\treturn -EMSGSIZE;\n}",
        "func": "static int nlmsg_populate_mdb_fill(struct sk_buff *skb,\n\t\t\t\t   struct net_device *dev,\n\t\t\t\t   struct br_mdb_entry *entry, u32 pid,\n\t\t\t\t   u32 seq, int type, unsigned int flags)\n{\n\tstruct nlmsghdr *nlh;\n\tstruct br_port_msg *bpm;\n\tstruct nlattr *nest, *nest2;\n\n\tnlh = nlmsg_put(skb, pid, seq, type, sizeof(*bpm), NLM_F_MULTI);\n\tif (!nlh)\n\t\treturn -EMSGSIZE;\n\n\tbpm = nlmsg_data(nlh);\n\tmemset(bpm, 0, sizeof(*bpm));\n\tbpm->family  = AF_BRIDGE;\n\tbpm->ifindex = dev->ifindex;\n\tnest = nla_nest_start(skb, MDBA_MDB);\n\tif (nest == NULL)\n\t\tgoto cancel;\n\tnest2 = nla_nest_start(skb, MDBA_MDB_ENTRY);\n\tif (nest2 == NULL)\n\t\tgoto end;\n\n\tif (nla_put(skb, MDBA_MDB_ENTRY_INFO, sizeof(*entry), entry))\n\t\tgoto end;\n\n\tnla_nest_end(skb, nest2);\n\tnla_nest_end(skb, nest);\n\treturn nlmsg_end(skb, nlh);\n\nend:\n\tnla_nest_end(skb, nest);\ncancel:\n\tnlmsg_cancel(skb, nlh);\n\treturn -EMSGSIZE;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -12,6 +12,7 @@\n \t\treturn -EMSGSIZE;\n \n \tbpm = nlmsg_data(nlh);\n+\tmemset(bpm, 0, sizeof(*bpm));\n \tbpm->family  = AF_BRIDGE;\n \tbpm->ifindex = dev->ifindex;\n \tnest = nla_nest_start(skb, MDBA_MDB);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tmemset(bpm, 0, sizeof(*bpm));"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-2636",
        "func_name": "torvalds/linux/br_mdb_notify",
        "description": "net/bridge/br_mdb.c in the Linux kernel before 3.8.4 does not initialize certain structures, which allows local users to obtain sensitive information from kernel memory via a crafted application.",
        "git_url": "https://github.com/torvalds/linux/commit/c085c49920b2f900ba716b4ca1c1a55ece9872cc",
        "commit_title": "bridge: fix mdb info leaks",
        "commit_text": " The bridging code discloses heap and stack bytes via the RTM_GETMDB netlink interface and via the notify messages send to group RTNLGRP_MDB afer a successful add/del.  Fix both cases by initializing all unset members/padding bytes with memset(0).  Cc: Stephen Hemminger <stephen@networkplumber.org>",
        "func_before": "void br_mdb_notify(struct net_device *dev, struct net_bridge_port *port,\n\t\t   struct br_ip *group, int type)\n{\n\tstruct br_mdb_entry entry;\n\n\tentry.ifindex = port->dev->ifindex;\n\tentry.addr.proto = group->proto;\n\tentry.addr.u.ip4 = group->u.ip4;\n#if IS_ENABLED(CONFIG_IPV6)\n\tentry.addr.u.ip6 = group->u.ip6;\n#endif\n\t__br_mdb_notify(dev, &entry, type);\n}",
        "func": "void br_mdb_notify(struct net_device *dev, struct net_bridge_port *port,\n\t\t   struct br_ip *group, int type)\n{\n\tstruct br_mdb_entry entry;\n\n\tmemset(&entry, 0, sizeof(entry));\n\tentry.ifindex = port->dev->ifindex;\n\tentry.addr.proto = group->proto;\n\tentry.addr.u.ip4 = group->u.ip4;\n#if IS_ENABLED(CONFIG_IPV6)\n\tentry.addr.u.ip6 = group->u.ip6;\n#endif\n\t__br_mdb_notify(dev, &entry, type);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,6 +3,7 @@\n {\n \tstruct br_mdb_entry entry;\n \n+\tmemset(&entry, 0, sizeof(entry));\n \tentry.ifindex = port->dev->ifindex;\n \tentry.addr.proto = group->proto;\n \tentry.addr.u.ip4 = group->u.ip4;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tmemset(&entry, 0, sizeof(entry));"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-2636",
        "func_name": "torvalds/linux/br_mdb_fill_info",
        "description": "net/bridge/br_mdb.c in the Linux kernel before 3.8.4 does not initialize certain structures, which allows local users to obtain sensitive information from kernel memory via a crafted application.",
        "git_url": "https://github.com/torvalds/linux/commit/c085c49920b2f900ba716b4ca1c1a55ece9872cc",
        "commit_title": "bridge: fix mdb info leaks",
        "commit_text": " The bridging code discloses heap and stack bytes via the RTM_GETMDB netlink interface and via the notify messages send to group RTNLGRP_MDB afer a successful add/del.  Fix both cases by initializing all unset members/padding bytes with memset(0).  Cc: Stephen Hemminger <stephen@networkplumber.org>",
        "func_before": "static int br_mdb_fill_info(struct sk_buff *skb, struct netlink_callback *cb,\n\t\t\t    struct net_device *dev)\n{\n\tstruct net_bridge *br = netdev_priv(dev);\n\tstruct net_bridge_mdb_htable *mdb;\n\tstruct nlattr *nest, *nest2;\n\tint i, err = 0;\n\tint idx = 0, s_idx = cb->args[1];\n\n\tif (br->multicast_disabled)\n\t\treturn 0;\n\n\tmdb = rcu_dereference(br->mdb);\n\tif (!mdb)\n\t\treturn 0;\n\n\tnest = nla_nest_start(skb, MDBA_MDB);\n\tif (nest == NULL)\n\t\treturn -EMSGSIZE;\n\n\tfor (i = 0; i < mdb->max; i++) {\n\t\tstruct net_bridge_mdb_entry *mp;\n\t\tstruct net_bridge_port_group *p, **pp;\n\t\tstruct net_bridge_port *port;\n\n\t\thlist_for_each_entry_rcu(mp, &mdb->mhash[i], hlist[mdb->ver]) {\n\t\t\tif (idx < s_idx)\n\t\t\t\tgoto skip;\n\n\t\t\tnest2 = nla_nest_start(skb, MDBA_MDB_ENTRY);\n\t\t\tif (nest2 == NULL) {\n\t\t\t\terr = -EMSGSIZE;\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\tfor (pp = &mp->ports;\n\t\t\t     (p = rcu_dereference(*pp)) != NULL;\n\t\t\t      pp = &p->next) {\n\t\t\t\tport = p->port;\n\t\t\t\tif (port) {\n\t\t\t\t\tstruct br_mdb_entry e;\n\t\t\t\t\te.ifindex = port->dev->ifindex;\n\t\t\t\t\te.state = p->state;\n\t\t\t\t\tif (p->addr.proto == htons(ETH_P_IP))\n\t\t\t\t\t\te.addr.u.ip4 = p->addr.u.ip4;\n#if IS_ENABLED(CONFIG_IPV6)\n\t\t\t\t\tif (p->addr.proto == htons(ETH_P_IPV6))\n\t\t\t\t\t\te.addr.u.ip6 = p->addr.u.ip6;\n#endif\n\t\t\t\t\te.addr.proto = p->addr.proto;\n\t\t\t\t\tif (nla_put(skb, MDBA_MDB_ENTRY_INFO, sizeof(e), &e)) {\n\t\t\t\t\t\tnla_nest_cancel(skb, nest2);\n\t\t\t\t\t\terr = -EMSGSIZE;\n\t\t\t\t\t\tgoto out;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tnla_nest_end(skb, nest2);\n\t\tskip:\n\t\t\tidx++;\n\t\t}\n\t}\n\nout:\n\tcb->args[1] = idx;\n\tnla_nest_end(skb, nest);\n\treturn err;\n}",
        "func": "static int br_mdb_fill_info(struct sk_buff *skb, struct netlink_callback *cb,\n\t\t\t    struct net_device *dev)\n{\n\tstruct net_bridge *br = netdev_priv(dev);\n\tstruct net_bridge_mdb_htable *mdb;\n\tstruct nlattr *nest, *nest2;\n\tint i, err = 0;\n\tint idx = 0, s_idx = cb->args[1];\n\n\tif (br->multicast_disabled)\n\t\treturn 0;\n\n\tmdb = rcu_dereference(br->mdb);\n\tif (!mdb)\n\t\treturn 0;\n\n\tnest = nla_nest_start(skb, MDBA_MDB);\n\tif (nest == NULL)\n\t\treturn -EMSGSIZE;\n\n\tfor (i = 0; i < mdb->max; i++) {\n\t\tstruct net_bridge_mdb_entry *mp;\n\t\tstruct net_bridge_port_group *p, **pp;\n\t\tstruct net_bridge_port *port;\n\n\t\thlist_for_each_entry_rcu(mp, &mdb->mhash[i], hlist[mdb->ver]) {\n\t\t\tif (idx < s_idx)\n\t\t\t\tgoto skip;\n\n\t\t\tnest2 = nla_nest_start(skb, MDBA_MDB_ENTRY);\n\t\t\tif (nest2 == NULL) {\n\t\t\t\terr = -EMSGSIZE;\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\tfor (pp = &mp->ports;\n\t\t\t     (p = rcu_dereference(*pp)) != NULL;\n\t\t\t      pp = &p->next) {\n\t\t\t\tport = p->port;\n\t\t\t\tif (port) {\n\t\t\t\t\tstruct br_mdb_entry e;\n\t\t\t\t\tmemset(&e, 0, sizeof(e));\n\t\t\t\t\te.ifindex = port->dev->ifindex;\n\t\t\t\t\te.state = p->state;\n\t\t\t\t\tif (p->addr.proto == htons(ETH_P_IP))\n\t\t\t\t\t\te.addr.u.ip4 = p->addr.u.ip4;\n#if IS_ENABLED(CONFIG_IPV6)\n\t\t\t\t\tif (p->addr.proto == htons(ETH_P_IPV6))\n\t\t\t\t\t\te.addr.u.ip6 = p->addr.u.ip6;\n#endif\n\t\t\t\t\te.addr.proto = p->addr.proto;\n\t\t\t\t\tif (nla_put(skb, MDBA_MDB_ENTRY_INFO, sizeof(e), &e)) {\n\t\t\t\t\t\tnla_nest_cancel(skb, nest2);\n\t\t\t\t\t\terr = -EMSGSIZE;\n\t\t\t\t\t\tgoto out;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tnla_nest_end(skb, nest2);\n\t\tskip:\n\t\t\tidx++;\n\t\t}\n\t}\n\nout:\n\tcb->args[1] = idx;\n\tnla_nest_end(skb, nest);\n\treturn err;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -39,6 +39,7 @@\n \t\t\t\tport = p->port;\n \t\t\t\tif (port) {\n \t\t\t\t\tstruct br_mdb_entry e;\n+\t\t\t\t\tmemset(&e, 0, sizeof(e));\n \t\t\t\t\te.ifindex = port->dev->ifindex;\n \t\t\t\t\te.state = p->state;\n \t\t\t\t\tif (p->addr.proto == htons(ETH_P_IP))",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t\t\t\t\tmemset(&e, 0, sizeof(e));"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-2636",
        "func_name": "torvalds/linux/br_mdb_dump",
        "description": "net/bridge/br_mdb.c in the Linux kernel before 3.8.4 does not initialize certain structures, which allows local users to obtain sensitive information from kernel memory via a crafted application.",
        "git_url": "https://github.com/torvalds/linux/commit/c085c49920b2f900ba716b4ca1c1a55ece9872cc",
        "commit_title": "bridge: fix mdb info leaks",
        "commit_text": " The bridging code discloses heap and stack bytes via the RTM_GETMDB netlink interface and via the notify messages send to group RTNLGRP_MDB afer a successful add/del.  Fix both cases by initializing all unset members/padding bytes with memset(0).  Cc: Stephen Hemminger <stephen@networkplumber.org>",
        "func_before": "static int br_mdb_dump(struct sk_buff *skb, struct netlink_callback *cb)\n{\n\tstruct net_device *dev;\n\tstruct net *net = sock_net(skb->sk);\n\tstruct nlmsghdr *nlh = NULL;\n\tint idx = 0, s_idx;\n\n\ts_idx = cb->args[0];\n\n\trcu_read_lock();\n\n\t/* In theory this could be wrapped to 0... */\n\tcb->seq = net->dev_base_seq + br_mdb_rehash_seq;\n\n\tfor_each_netdev_rcu(net, dev) {\n\t\tif (dev->priv_flags & IFF_EBRIDGE) {\n\t\t\tstruct br_port_msg *bpm;\n\n\t\t\tif (idx < s_idx)\n\t\t\t\tgoto skip;\n\n\t\t\tnlh = nlmsg_put(skb, NETLINK_CB(cb->skb).portid,\n\t\t\t\t\tcb->nlh->nlmsg_seq, RTM_GETMDB,\n\t\t\t\t\tsizeof(*bpm), NLM_F_MULTI);\n\t\t\tif (nlh == NULL)\n\t\t\t\tbreak;\n\n\t\t\tbpm = nlmsg_data(nlh);\n\t\t\tbpm->ifindex = dev->ifindex;\n\t\t\tif (br_mdb_fill_info(skb, cb, dev) < 0)\n\t\t\t\tgoto out;\n\t\t\tif (br_rports_fill_info(skb, cb, dev) < 0)\n\t\t\t\tgoto out;\n\n\t\t\tcb->args[1] = 0;\n\t\t\tnlmsg_end(skb, nlh);\n\t\tskip:\n\t\t\tidx++;\n\t\t}\n\t}\n\nout:\n\tif (nlh)\n\t\tnlmsg_end(skb, nlh);\n\trcu_read_unlock();\n\tcb->args[0] = idx;\n\treturn skb->len;\n}",
        "func": "static int br_mdb_dump(struct sk_buff *skb, struct netlink_callback *cb)\n{\n\tstruct net_device *dev;\n\tstruct net *net = sock_net(skb->sk);\n\tstruct nlmsghdr *nlh = NULL;\n\tint idx = 0, s_idx;\n\n\ts_idx = cb->args[0];\n\n\trcu_read_lock();\n\n\t/* In theory this could be wrapped to 0... */\n\tcb->seq = net->dev_base_seq + br_mdb_rehash_seq;\n\n\tfor_each_netdev_rcu(net, dev) {\n\t\tif (dev->priv_flags & IFF_EBRIDGE) {\n\t\t\tstruct br_port_msg *bpm;\n\n\t\t\tif (idx < s_idx)\n\t\t\t\tgoto skip;\n\n\t\t\tnlh = nlmsg_put(skb, NETLINK_CB(cb->skb).portid,\n\t\t\t\t\tcb->nlh->nlmsg_seq, RTM_GETMDB,\n\t\t\t\t\tsizeof(*bpm), NLM_F_MULTI);\n\t\t\tif (nlh == NULL)\n\t\t\t\tbreak;\n\n\t\t\tbpm = nlmsg_data(nlh);\n\t\t\tmemset(bpm, 0, sizeof(*bpm));\n\t\t\tbpm->ifindex = dev->ifindex;\n\t\t\tif (br_mdb_fill_info(skb, cb, dev) < 0)\n\t\t\t\tgoto out;\n\t\t\tif (br_rports_fill_info(skb, cb, dev) < 0)\n\t\t\t\tgoto out;\n\n\t\t\tcb->args[1] = 0;\n\t\t\tnlmsg_end(skb, nlh);\n\t\tskip:\n\t\t\tidx++;\n\t\t}\n\t}\n\nout:\n\tif (nlh)\n\t\tnlmsg_end(skb, nlh);\n\trcu_read_unlock();\n\tcb->args[0] = idx;\n\treturn skb->len;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -26,6 +26,7 @@\n \t\t\t\tbreak;\n \n \t\t\tbpm = nlmsg_data(nlh);\n+\t\t\tmemset(bpm, 0, sizeof(*bpm));\n \t\t\tbpm->ifindex = dev->ifindex;\n \t\t\tif (br_mdb_fill_info(skb, cb, dev) < 0)\n \t\t\t\tgoto out;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t\t\tmemset(bpm, 0, sizeof(*bpm));"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-1969",
        "func_name": "GNOME/libxml2/xmlParseChunk",
        "description": "Multiple use-after-free vulnerabilities in libxml2 2.9.0 and possibly other versions might allow context-dependent attackers to cause a denial of service (crash) and possibly execute arbitrary code via vectors related to the (1) htmlParseChunk and (2) xmldecl_done functions, as demonstrated by a buffer overflow in the xmlBufGetInputBase function.",
        "git_url": "https://github.com/GNOME/libxml2/commit/de0cc20c29cb3f056062925395e0f68d2250a46f",
        "commit_title": "Fix some buffer conversion issues",
        "commit_text": " https://bugzilla.gnome.org/show_bug.cgi?id=690202  Buffer overflow errors originating from xmlBufGetInputBase in 2.9.0 The pointers from the context input were not properly reset after that call which can do reallocations.",
        "func_before": "int\nxmlParseChunk(xmlParserCtxtPtr ctxt, const char *chunk, int size,\n              int terminate) {\n    int end_in_lf = 0;\n    int remain = 0;\n    size_t old_avail = 0;\n    size_t avail = 0;\n\n    if (ctxt == NULL)\n        return(XML_ERR_INTERNAL_ERROR);\n    if ((ctxt->errNo != XML_ERR_OK) && (ctxt->disableSAX == 1))\n        return(ctxt->errNo);\n    if (ctxt->instate == XML_PARSER_EOF)\n        return(-1);\n    if (ctxt->instate == XML_PARSER_START)\n        xmlDetectSAX2(ctxt);\n    if ((size > 0) && (chunk != NULL) && (!terminate) &&\n        (chunk[size - 1] == '\\r')) {\n\tend_in_lf = 1;\n\tsize--;\n    }\n\nxmldecl_done:\n\n    if ((size > 0) && (chunk != NULL) && (ctxt->input != NULL) &&\n        (ctxt->input->buf != NULL) && (ctxt->instate != XML_PARSER_EOF))  {\n\tsize_t base = xmlBufGetInputBase(ctxt->input->buf->buffer, ctxt->input);\n\tsize_t cur = ctxt->input->cur - ctxt->input->base;\n\tint res;\n\n        old_avail = xmlBufUse(ctxt->input->buf->buffer);\n        /*\n         * Specific handling if we autodetected an encoding, we should not\n         * push more than the first line ... which depend on the encoding\n         * And only push the rest once the final encoding was detected\n         */\n        if ((ctxt->instate == XML_PARSER_START) && (ctxt->input != NULL) &&\n            (ctxt->input->buf != NULL) && (ctxt->input->buf->encoder != NULL)) {\n            unsigned int len = 45;\n\n            if ((xmlStrcasestr(BAD_CAST ctxt->input->buf->encoder->name,\n                               BAD_CAST \"UTF-16\")) ||\n                (xmlStrcasestr(BAD_CAST ctxt->input->buf->encoder->name,\n                               BAD_CAST \"UTF16\")))\n                len = 90;\n            else if ((xmlStrcasestr(BAD_CAST ctxt->input->buf->encoder->name,\n                                    BAD_CAST \"UCS-4\")) ||\n                     (xmlStrcasestr(BAD_CAST ctxt->input->buf->encoder->name,\n                                    BAD_CAST \"UCS4\")))\n                len = 180;\n\n            if (ctxt->input->buf->rawconsumed < len)\n                len -= ctxt->input->buf->rawconsumed;\n\n            /*\n             * Change size for reading the initial declaration only\n             * if size is greater than len. Otherwise, memmove in xmlBufferAdd\n             * will blindly copy extra bytes from memory.\n             */\n            if ((unsigned int) size > len) {\n                remain = size - len;\n                size = len;\n            } else {\n                remain = 0;\n            }\n        }\n\tres =xmlParserInputBufferPush(ctxt->input->buf, size, chunk);\n\tif (res < 0) {\n\t    ctxt->errNo = XML_PARSER_EOF;\n\t    ctxt->disableSAX = 1;\n\t    return (XML_PARSER_EOF);\n\t}\n        xmlBufSetInputBaseCur(ctxt->input->buf->buffer, ctxt->input, base, cur);\n#ifdef DEBUG_PUSH\n\txmlGenericError(xmlGenericErrorContext, \"PP: pushed %d\\n\", size);\n#endif\n\n    } else if (ctxt->instate != XML_PARSER_EOF) {\n\tif ((ctxt->input != NULL) && ctxt->input->buf != NULL) {\n\t    xmlParserInputBufferPtr in = ctxt->input->buf;\n\t    if ((in->encoder != NULL) && (in->buffer != NULL) &&\n\t\t    (in->raw != NULL)) {\n\t\tint nbchars;\n\n\t\tnbchars = xmlCharEncInput(in);\n\t\tif (nbchars < 0) {\n\t\t    /* TODO 2.6.0 */\n\t\t    xmlGenericError(xmlGenericErrorContext,\n\t\t\t\t    \"xmlParseChunk: encoder error\\n\");\n\t\t    return(XML_ERR_INVALID_ENCODING);\n\t\t}\n\t    }\n\t}\n    }\n    if (remain != 0) {\n        xmlParseTryOrFinish(ctxt, 0);\n    } else {\n        if ((ctxt->input != NULL) && (ctxt->input->buf != NULL))\n            avail = xmlBufUse(ctxt->input->buf->buffer);\n        /*\n         * Depending on the current state it may not be such\n         * a good idea to try parsing if there is nothing in the chunk\n         * which would be worth doing a parser state transition and we\n         * need to wait for more data\n         */\n        if ((terminate) || (avail > XML_MAX_TEXT_LENGTH) ||\n            (old_avail == 0) || (avail == 0) ||\n            (xmlParseCheckTransition(ctxt,\n                       (const char *)&ctxt->input->base[old_avail],\n                                     avail - old_avail)))\n            xmlParseTryOrFinish(ctxt, terminate);\n    }\n    if ((ctxt->input != NULL) &&\n         (((ctxt->input->end - ctxt->input->cur) > XML_MAX_LOOKUP_LIMIT) ||\n         ((ctxt->input->cur - ctxt->input->base) > XML_MAX_LOOKUP_LIMIT)) &&\n        ((ctxt->options & XML_PARSE_HUGE) == 0)) {\n        xmlFatalErr(ctxt, XML_ERR_INTERNAL_ERROR, \"Huge input lookup\");\n        ctxt->instate = XML_PARSER_EOF;\n    }\n    if ((ctxt->errNo != XML_ERR_OK) && (ctxt->disableSAX == 1))\n        return(ctxt->errNo);\n\n    if (remain != 0) {\n        chunk += size;\n        size = remain;\n        remain = 0;\n        goto xmldecl_done;\n    }\n    if ((end_in_lf == 1) && (ctxt->input != NULL) &&\n        (ctxt->input->buf != NULL)) {\n\txmlParserInputBufferPush(ctxt->input->buf, 1, \"\\r\");\n    }\n    if (terminate) {\n\t/*\n\t * Check for termination\n\t */\n\tint cur_avail = 0;\n\n\tif (ctxt->input != NULL) {\n\t    if (ctxt->input->buf == NULL)\n\t\tcur_avail = ctxt->input->length -\n\t\t\t    (ctxt->input->cur - ctxt->input->base);\n\t    else\n\t\tcur_avail = xmlBufUse(ctxt->input->buf->buffer) -\n\t\t\t              (ctxt->input->cur - ctxt->input->base);\n\t}\n\n\tif ((ctxt->instate != XML_PARSER_EOF) &&\n\t    (ctxt->instate != XML_PARSER_EPILOG)) {\n\t    xmlFatalErr(ctxt, XML_ERR_DOCUMENT_END, NULL);\n\t}\n\tif ((ctxt->instate == XML_PARSER_EPILOG) && (cur_avail > 0)) {\n\t    xmlFatalErr(ctxt, XML_ERR_DOCUMENT_END, NULL);\n\t}\n\tif (ctxt->instate != XML_PARSER_EOF) {\n\t    if ((ctxt->sax) && (ctxt->sax->endDocument != NULL))\n\t\tctxt->sax->endDocument(ctxt->userData);\n\t}\n\tctxt->instate = XML_PARSER_EOF;\n    }\n    if (ctxt->wellFormed == 0)\n\treturn((xmlParserErrors) ctxt->errNo);\n    else\n        return(0);\n}",
        "func": "int\nxmlParseChunk(xmlParserCtxtPtr ctxt, const char *chunk, int size,\n              int terminate) {\n    int end_in_lf = 0;\n    int remain = 0;\n    size_t old_avail = 0;\n    size_t avail = 0;\n\n    if (ctxt == NULL)\n        return(XML_ERR_INTERNAL_ERROR);\n    if ((ctxt->errNo != XML_ERR_OK) && (ctxt->disableSAX == 1))\n        return(ctxt->errNo);\n    if (ctxt->instate == XML_PARSER_EOF)\n        return(-1);\n    if (ctxt->instate == XML_PARSER_START)\n        xmlDetectSAX2(ctxt);\n    if ((size > 0) && (chunk != NULL) && (!terminate) &&\n        (chunk[size - 1] == '\\r')) {\n\tend_in_lf = 1;\n\tsize--;\n    }\n\nxmldecl_done:\n\n    if ((size > 0) && (chunk != NULL) && (ctxt->input != NULL) &&\n        (ctxt->input->buf != NULL) && (ctxt->instate != XML_PARSER_EOF))  {\n\tsize_t base = xmlBufGetInputBase(ctxt->input->buf->buffer, ctxt->input);\n\tsize_t cur = ctxt->input->cur - ctxt->input->base;\n\tint res;\n\n        old_avail = xmlBufUse(ctxt->input->buf->buffer);\n        /*\n         * Specific handling if we autodetected an encoding, we should not\n         * push more than the first line ... which depend on the encoding\n         * And only push the rest once the final encoding was detected\n         */\n        if ((ctxt->instate == XML_PARSER_START) && (ctxt->input != NULL) &&\n            (ctxt->input->buf != NULL) && (ctxt->input->buf->encoder != NULL)) {\n            unsigned int len = 45;\n\n            if ((xmlStrcasestr(BAD_CAST ctxt->input->buf->encoder->name,\n                               BAD_CAST \"UTF-16\")) ||\n                (xmlStrcasestr(BAD_CAST ctxt->input->buf->encoder->name,\n                               BAD_CAST \"UTF16\")))\n                len = 90;\n            else if ((xmlStrcasestr(BAD_CAST ctxt->input->buf->encoder->name,\n                                    BAD_CAST \"UCS-4\")) ||\n                     (xmlStrcasestr(BAD_CAST ctxt->input->buf->encoder->name,\n                                    BAD_CAST \"UCS4\")))\n                len = 180;\n\n            if (ctxt->input->buf->rawconsumed < len)\n                len -= ctxt->input->buf->rawconsumed;\n\n            /*\n             * Change size for reading the initial declaration only\n             * if size is greater than len. Otherwise, memmove in xmlBufferAdd\n             * will blindly copy extra bytes from memory.\n             */\n            if ((unsigned int) size > len) {\n                remain = size - len;\n                size = len;\n            } else {\n                remain = 0;\n            }\n        }\n\tres = xmlParserInputBufferPush(ctxt->input->buf, size, chunk);\n\tif (res < 0) {\n\t    ctxt->errNo = XML_PARSER_EOF;\n\t    ctxt->disableSAX = 1;\n\t    return (XML_PARSER_EOF);\n\t}\n        xmlBufSetInputBaseCur(ctxt->input->buf->buffer, ctxt->input, base, cur);\n#ifdef DEBUG_PUSH\n\txmlGenericError(xmlGenericErrorContext, \"PP: pushed %d\\n\", size);\n#endif\n\n    } else if (ctxt->instate != XML_PARSER_EOF) {\n\tif ((ctxt->input != NULL) && ctxt->input->buf != NULL) {\n\t    xmlParserInputBufferPtr in = ctxt->input->buf;\n\t    if ((in->encoder != NULL) && (in->buffer != NULL) &&\n\t\t    (in->raw != NULL)) {\n\t\tint nbchars;\n\t\tsize_t base = xmlBufGetInputBase(in->buffer, ctxt->input);\n\t\tsize_t current = ctxt->input->cur - ctxt->input->base;\n\n\t\tnbchars = xmlCharEncInput(in);\n\t\tif (nbchars < 0) {\n\t\t    /* TODO 2.6.0 */\n\t\t    xmlGenericError(xmlGenericErrorContext,\n\t\t\t\t    \"xmlParseChunk: encoder error\\n\");\n\t\t    return(XML_ERR_INVALID_ENCODING);\n\t\t}\n\t\txmlBufSetInputBaseCur(in->buffer, ctxt->input, base, current);\n\t    }\n\t}\n    }\n    if (remain != 0) {\n        xmlParseTryOrFinish(ctxt, 0);\n    } else {\n        if ((ctxt->input != NULL) && (ctxt->input->buf != NULL))\n            avail = xmlBufUse(ctxt->input->buf->buffer);\n        /*\n         * Depending on the current state it may not be such\n         * a good idea to try parsing if there is nothing in the chunk\n         * which would be worth doing a parser state transition and we\n         * need to wait for more data\n         */\n        if ((terminate) || (avail > XML_MAX_TEXT_LENGTH) ||\n            (old_avail == 0) || (avail == 0) ||\n            (xmlParseCheckTransition(ctxt,\n                       (const char *)&ctxt->input->base[old_avail],\n                                     avail - old_avail)))\n            xmlParseTryOrFinish(ctxt, terminate);\n    }\n    if ((ctxt->input != NULL) &&\n         (((ctxt->input->end - ctxt->input->cur) > XML_MAX_LOOKUP_LIMIT) ||\n         ((ctxt->input->cur - ctxt->input->base) > XML_MAX_LOOKUP_LIMIT)) &&\n        ((ctxt->options & XML_PARSE_HUGE) == 0)) {\n        xmlFatalErr(ctxt, XML_ERR_INTERNAL_ERROR, \"Huge input lookup\");\n        ctxt->instate = XML_PARSER_EOF;\n    }\n    if ((ctxt->errNo != XML_ERR_OK) && (ctxt->disableSAX == 1))\n        return(ctxt->errNo);\n\n    if (remain != 0) {\n        chunk += size;\n        size = remain;\n        remain = 0;\n        goto xmldecl_done;\n    }\n    if ((end_in_lf == 1) && (ctxt->input != NULL) &&\n        (ctxt->input->buf != NULL)) {\n\tsize_t base = xmlBufGetInputBase(ctxt->input->buf->buffer,\n\t\t\t\t\t ctxt->input);\n\tsize_t current = ctxt->input->cur - ctxt->input->base;\n\n\txmlParserInputBufferPush(ctxt->input->buf, 1, \"\\r\");\n\n\txmlBufSetInputBaseCur(ctxt->input->buf->buffer, ctxt->input,\n\t\t\t      base, current);\n    }\n    if (terminate) {\n\t/*\n\t * Check for termination\n\t */\n\tint cur_avail = 0;\n\n\tif (ctxt->input != NULL) {\n\t    if (ctxt->input->buf == NULL)\n\t\tcur_avail = ctxt->input->length -\n\t\t\t    (ctxt->input->cur - ctxt->input->base);\n\t    else\n\t\tcur_avail = xmlBufUse(ctxt->input->buf->buffer) -\n\t\t\t              (ctxt->input->cur - ctxt->input->base);\n\t}\n\n\tif ((ctxt->instate != XML_PARSER_EOF) &&\n\t    (ctxt->instate != XML_PARSER_EPILOG)) {\n\t    xmlFatalErr(ctxt, XML_ERR_DOCUMENT_END, NULL);\n\t}\n\tif ((ctxt->instate == XML_PARSER_EPILOG) && (cur_avail > 0)) {\n\t    xmlFatalErr(ctxt, XML_ERR_DOCUMENT_END, NULL);\n\t}\n\tif (ctxt->instate != XML_PARSER_EOF) {\n\t    if ((ctxt->sax) && (ctxt->sax->endDocument != NULL))\n\t\tctxt->sax->endDocument(ctxt->userData);\n\t}\n\tctxt->instate = XML_PARSER_EOF;\n    }\n    if (ctxt->wellFormed == 0)\n\treturn((xmlParserErrors) ctxt->errNo);\n    else\n        return(0);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -64,7 +64,7 @@\n                 remain = 0;\n             }\n         }\n-\tres =xmlParserInputBufferPush(ctxt->input->buf, size, chunk);\n+\tres = xmlParserInputBufferPush(ctxt->input->buf, size, chunk);\n \tif (res < 0) {\n \t    ctxt->errNo = XML_PARSER_EOF;\n \t    ctxt->disableSAX = 1;\n@@ -81,6 +81,8 @@\n \t    if ((in->encoder != NULL) && (in->buffer != NULL) &&\n \t\t    (in->raw != NULL)) {\n \t\tint nbchars;\n+\t\tsize_t base = xmlBufGetInputBase(in->buffer, ctxt->input);\n+\t\tsize_t current = ctxt->input->cur - ctxt->input->base;\n \n \t\tnbchars = xmlCharEncInput(in);\n \t\tif (nbchars < 0) {\n@@ -89,6 +91,7 @@\n \t\t\t\t    \"xmlParseChunk: encoder error\\n\");\n \t\t    return(XML_ERR_INVALID_ENCODING);\n \t\t}\n+\t\txmlBufSetInputBaseCur(in->buffer, ctxt->input, base, current);\n \t    }\n \t}\n     }\n@@ -128,7 +131,14 @@\n     }\n     if ((end_in_lf == 1) && (ctxt->input != NULL) &&\n         (ctxt->input->buf != NULL)) {\n+\tsize_t base = xmlBufGetInputBase(ctxt->input->buf->buffer,\n+\t\t\t\t\t ctxt->input);\n+\tsize_t current = ctxt->input->cur - ctxt->input->base;\n+\n \txmlParserInputBufferPush(ctxt->input->buf, 1, \"\\r\");\n+\n+\txmlBufSetInputBaseCur(ctxt->input->buf->buffer, ctxt->input,\n+\t\t\t      base, current);\n     }\n     if (terminate) {\n \t/*",
        "diff_line_info": {
            "deleted_lines": [
                "\tres =xmlParserInputBufferPush(ctxt->input->buf, size, chunk);"
            ],
            "added_lines": [
                "\tres = xmlParserInputBufferPush(ctxt->input->buf, size, chunk);",
                "\t\tsize_t base = xmlBufGetInputBase(in->buffer, ctxt->input);",
                "\t\tsize_t current = ctxt->input->cur - ctxt->input->base;",
                "\t\txmlBufSetInputBaseCur(in->buffer, ctxt->input, base, current);",
                "\tsize_t base = xmlBufGetInputBase(ctxt->input->buf->buffer,",
                "\t\t\t\t\t ctxt->input);",
                "\tsize_t current = ctxt->input->cur - ctxt->input->base;",
                "",
                "",
                "\txmlBufSetInputBaseCur(ctxt->input->buf->buffer, ctxt->input,",
                "\t\t\t      base, current);"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-2017",
        "func_name": "torvalds/linux/veth_xmit",
        "description": "The veth (aka virtual Ethernet) driver in the Linux kernel before 2.6.34 does not properly manage skbs during congestion, which allows remote attackers to cause a denial of service (system crash) by leveraging lack of skb consumption in conjunction with a double-free error.",
        "git_url": "https://github.com/torvalds/linux/commit/6ec82562ffc6f297d0de36d65776cff8e5704867",
        "commit_title": "veth: Dont kfree_skb() after dev_forward_skb()",
        "commit_text": " In case of congestion, netif_rx() frees the skb, so we must assume dev_forward_skb() also consume skb.  Bug introduced by commit 445409602c092 (veth: move loopback logic to common location)  We must change dev_forward_skb() to always consume skb, and veth to not double free it.  Bug report : http://marc.info/?l=linux-netdev&m=127310770900442&w=3 ",
        "func_before": "static netdev_tx_t veth_xmit(struct sk_buff *skb, struct net_device *dev)\n{\n\tstruct net_device *rcv = NULL;\n\tstruct veth_priv *priv, *rcv_priv;\n\tstruct veth_net_stats *stats, *rcv_stats;\n\tint length;\n\n\tpriv = netdev_priv(dev);\n\trcv = priv->peer;\n\trcv_priv = netdev_priv(rcv);\n\n\tstats = this_cpu_ptr(priv->stats);\n\trcv_stats = this_cpu_ptr(rcv_priv->stats);\n\n\tif (!(rcv->flags & IFF_UP))\n\t\tgoto tx_drop;\n\n\tif (dev->features & NETIF_F_NO_CSUM)\n\t\tskb->ip_summed = rcv_priv->ip_summed;\n\n\tlength = skb->len + ETH_HLEN;\n\tif (dev_forward_skb(rcv, skb) != NET_RX_SUCCESS)\n\t\tgoto rx_drop;\n\n\tstats->tx_bytes += length;\n\tstats->tx_packets++;\n\n\trcv_stats->rx_bytes += length;\n\trcv_stats->rx_packets++;\n\n\treturn NETDEV_TX_OK;\n\ntx_drop:\n\tkfree_skb(skb);\n\tstats->tx_dropped++;\n\treturn NETDEV_TX_OK;\n\nrx_drop:\n\tkfree_skb(skb);\n\trcv_stats->rx_dropped++;\n\treturn NETDEV_TX_OK;\n}",
        "func": "static netdev_tx_t veth_xmit(struct sk_buff *skb, struct net_device *dev)\n{\n\tstruct net_device *rcv = NULL;\n\tstruct veth_priv *priv, *rcv_priv;\n\tstruct veth_net_stats *stats, *rcv_stats;\n\tint length;\n\n\tpriv = netdev_priv(dev);\n\trcv = priv->peer;\n\trcv_priv = netdev_priv(rcv);\n\n\tstats = this_cpu_ptr(priv->stats);\n\trcv_stats = this_cpu_ptr(rcv_priv->stats);\n\n\tif (!(rcv->flags & IFF_UP))\n\t\tgoto tx_drop;\n\n\tif (dev->features & NETIF_F_NO_CSUM)\n\t\tskb->ip_summed = rcv_priv->ip_summed;\n\n\tlength = skb->len + ETH_HLEN;\n\tif (dev_forward_skb(rcv, skb) != NET_RX_SUCCESS)\n\t\tgoto rx_drop;\n\n\tstats->tx_bytes += length;\n\tstats->tx_packets++;\n\n\trcv_stats->rx_bytes += length;\n\trcv_stats->rx_packets++;\n\n\treturn NETDEV_TX_OK;\n\ntx_drop:\n\tkfree_skb(skb);\n\tstats->tx_dropped++;\n\treturn NETDEV_TX_OK;\n\nrx_drop:\n\trcv_stats->rx_dropped++;\n\treturn NETDEV_TX_OK;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -36,7 +36,6 @@\n \treturn NETDEV_TX_OK;\n \n rx_drop:\n-\tkfree_skb(skb);\n \trcv_stats->rx_dropped++;\n \treturn NETDEV_TX_OK;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tkfree_skb(skb);"
            ],
            "added_lines": []
        }
    },
    {
        "cve_id": "CVE-2013-2017",
        "func_name": "torvalds/linux/dev_forward_skb",
        "description": "The veth (aka virtual Ethernet) driver in the Linux kernel before 2.6.34 does not properly manage skbs during congestion, which allows remote attackers to cause a denial of service (system crash) by leveraging lack of skb consumption in conjunction with a double-free error.",
        "git_url": "https://github.com/torvalds/linux/commit/6ec82562ffc6f297d0de36d65776cff8e5704867",
        "commit_title": "veth: Dont kfree_skb() after dev_forward_skb()",
        "commit_text": " In case of congestion, netif_rx() frees the skb, so we must assume dev_forward_skb() also consume skb.  Bug introduced by commit 445409602c092 (veth: move loopback logic to common location)  We must change dev_forward_skb() to always consume skb, and veth to not double free it.  Bug report : http://marc.info/?l=linux-netdev&m=127310770900442&w=3 ",
        "func_before": "int dev_forward_skb(struct net_device *dev, struct sk_buff *skb)\n{\n\tskb_orphan(skb);\n\n\tif (!(dev->flags & IFF_UP))\n\t\treturn NET_RX_DROP;\n\n\tif (skb->len > (dev->mtu + dev->hard_header_len))\n\t\treturn NET_RX_DROP;\n\n\tskb_set_dev(skb, dev);\n\tskb->tstamp.tv64 = 0;\n\tskb->pkt_type = PACKET_HOST;\n\tskb->protocol = eth_type_trans(skb, dev);\n\treturn netif_rx(skb);\n}",
        "func": "int dev_forward_skb(struct net_device *dev, struct sk_buff *skb)\n{\n\tskb_orphan(skb);\n\n\tif (!(dev->flags & IFF_UP) ||\n\t    (skb->len > (dev->mtu + dev->hard_header_len))) {\n\t\tkfree_skb(skb);\n\t\treturn NET_RX_DROP;\n\t}\n\tskb_set_dev(skb, dev);\n\tskb->tstamp.tv64 = 0;\n\tskb->pkt_type = PACKET_HOST;\n\tskb->protocol = eth_type_trans(skb, dev);\n\treturn netif_rx(skb);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,12 +2,11 @@\n {\n \tskb_orphan(skb);\n \n-\tif (!(dev->flags & IFF_UP))\n+\tif (!(dev->flags & IFF_UP) ||\n+\t    (skb->len > (dev->mtu + dev->hard_header_len))) {\n+\t\tkfree_skb(skb);\n \t\treturn NET_RX_DROP;\n-\n-\tif (skb->len > (dev->mtu + dev->hard_header_len))\n-\t\treturn NET_RX_DROP;\n-\n+\t}\n \tskb_set_dev(skb, dev);\n \tskb->tstamp.tv64 = 0;\n \tskb->pkt_type = PACKET_HOST;",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (!(dev->flags & IFF_UP))",
                "",
                "\tif (skb->len > (dev->mtu + dev->hard_header_len))",
                "\t\treturn NET_RX_DROP;",
                ""
            ],
            "added_lines": [
                "\tif (!(dev->flags & IFF_UP) ||",
                "\t    (skb->len > (dev->mtu + dev->hard_header_len))) {",
                "\t\tkfree_skb(skb);",
                "\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-2141",
        "func_name": "torvalds/linux/do_tkill",
        "description": "The do_tkill function in kernel/signal.c in the Linux kernel before 3.8.9 does not initialize a certain data structure, which allows local users to obtain sensitive information from kernel memory via a crafted application that makes a (1) tkill or (2) tgkill system call.",
        "git_url": "https://github.com/torvalds/linux/commit/b9e146d8eb3b9ecae5086d373b50fa0c1f3e7f0f",
        "commit_title": "kernel/signal.c: stop info leak via the tkill and the tgkill syscalls",
        "commit_text": " This fixes a kernel memory contents leak via the tkill and tgkill syscalls for compat processes.  This is visible in the siginfo_t->_sifields._rt.si_sigval.sival_ptr field when handling signals delivered from tkill.  The place of the infoleak:  int copy_siginfo_to_user32(compat_siginfo_t __user *to, siginfo_t *from) {         ...         put_user_ex(ptr_to_compat(from->si_ptr), &to->si_ptr);         ... }  Cc: Al Viro <viro@zeniv.linux.org.uk> Cc: Oleg Nesterov <oleg@redhat.com> Cc: \"Eric W. Biederman\" <ebiederm@xmission.com> Cc: Serge Hallyn <serge.hallyn@canonical.com> Cc: <stable@vger.kernel.org>",
        "func_before": "static int do_tkill(pid_t tgid, pid_t pid, int sig)\n{\n\tstruct siginfo info;\n\n\tinfo.si_signo = sig;\n\tinfo.si_errno = 0;\n\tinfo.si_code = SI_TKILL;\n\tinfo.si_pid = task_tgid_vnr(current);\n\tinfo.si_uid = from_kuid_munged(current_user_ns(), current_uid());\n\n\treturn do_send_specific(tgid, pid, sig, &info);\n}",
        "func": "static int do_tkill(pid_t tgid, pid_t pid, int sig)\n{\n\tstruct siginfo info = {};\n\n\tinfo.si_signo = sig;\n\tinfo.si_errno = 0;\n\tinfo.si_code = SI_TKILL;\n\tinfo.si_pid = task_tgid_vnr(current);\n\tinfo.si_uid = from_kuid_munged(current_user_ns(), current_uid());\n\n\treturn do_send_specific(tgid, pid, sig, &info);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,6 @@\n static int do_tkill(pid_t tgid, pid_t pid, int sig)\n {\n-\tstruct siginfo info;\n+\tstruct siginfo info = {};\n \n \tinfo.si_signo = sig;\n \tinfo.si_errno = 0;",
        "diff_line_info": {
            "deleted_lines": [
                "\tstruct siginfo info;"
            ],
            "added_lines": [
                "\tstruct siginfo info = {};"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-4125",
        "func_name": "torvalds/linux/fib6_add_rt2node",
        "description": "The fib6_add_rt2node function in net/ipv6/ip6_fib.c in the IPv6 stack in the Linux kernel through 3.10.1 does not properly handle Router Advertisement (RA) messages in certain circumstances involving three routes that initially qualified for membership in an ECMP route set until a change occurred for one of the first two routes, which allows remote attackers to cause a denial of service (system crash) via a crafted sequence of messages.",
        "git_url": "https://github.com/torvalds/linux/commit/307f2fb95e9b96b3577916e73d92e104f8f26494",
        "commit_title": "ipv6: only static routes qualify for equal cost multipathing",
        "commit_text": " Static routes in this case are non-expiring routes which did not get configured by autoconf or by icmpv6 redirects.  To make sure we actually get an ecmp route while searching for the first one in this fib6_node's leafs, also make sure it matches the ecmp route assumptions.  v2: a) Removed RTF_EXPIRE check in dst.from chain. The check of RTF_ADDRCONF    already ensures that this route, even if added again without    RTF_EXPIRES (in case of a RA announcement with infinite timeout),    does not cause the rt6i_nsiblings logic to go wrong if a later RA    updates the expiration time later.  v3: a) Allow RTF_EXPIRES routes to enter the ecmp route set. We have to do so,    because an pmtu event could update the RTF_EXPIRES flag and we would    not count this route, if another route joins this set. We now filter    only for RTF_GATEWAY|RTF_ADDRCONF|RTF_DYNAMIC, which are flags that    don't get changed after rt6_info construction.  Cc: Nicolas Dichtel <nicolas.dichtel@6wind.com>",
        "func_before": "static int fib6_add_rt2node(struct fib6_node *fn, struct rt6_info *rt,\n\t\t\t    struct nl_info *info)\n{\n\tstruct rt6_info *iter = NULL;\n\tstruct rt6_info **ins;\n\tint replace = (info->nlh &&\n\t\t       (info->nlh->nlmsg_flags & NLM_F_REPLACE));\n\tint add = (!info->nlh ||\n\t\t   (info->nlh->nlmsg_flags & NLM_F_CREATE));\n\tint found = 0;\n\n\tins = &fn->leaf;\n\n\tfor (iter = fn->leaf; iter; iter = iter->dst.rt6_next) {\n\t\t/*\n\t\t *\tSearch for duplicates\n\t\t */\n\n\t\tif (iter->rt6i_metric == rt->rt6i_metric) {\n\t\t\t/*\n\t\t\t *\tSame priority level\n\t\t\t */\n\t\t\tif (info->nlh &&\n\t\t\t    (info->nlh->nlmsg_flags & NLM_F_EXCL))\n\t\t\t\treturn -EEXIST;\n\t\t\tif (replace) {\n\t\t\t\tfound++;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tif (iter->dst.dev == rt->dst.dev &&\n\t\t\t    iter->rt6i_idev == rt->rt6i_idev &&\n\t\t\t    ipv6_addr_equal(&iter->rt6i_gateway,\n\t\t\t\t\t    &rt->rt6i_gateway)) {\n\t\t\t\tif (rt->rt6i_nsiblings)\n\t\t\t\t\trt->rt6i_nsiblings = 0;\n\t\t\t\tif (!(iter->rt6i_flags & RTF_EXPIRES))\n\t\t\t\t\treturn -EEXIST;\n\t\t\t\tif (!(rt->rt6i_flags & RTF_EXPIRES))\n\t\t\t\t\trt6_clean_expires(iter);\n\t\t\t\telse\n\t\t\t\t\trt6_set_expires(iter, rt->dst.expires);\n\t\t\t\treturn -EEXIST;\n\t\t\t}\n\t\t\t/* If we have the same destination and the same metric,\n\t\t\t * but not the same gateway, then the route we try to\n\t\t\t * add is sibling to this route, increment our counter\n\t\t\t * of siblings, and later we will add our route to the\n\t\t\t * list.\n\t\t\t * Only static routes (which don't have flag\n\t\t\t * RTF_EXPIRES) are used for ECMPv6.\n\t\t\t *\n\t\t\t * To avoid long list, we only had siblings if the\n\t\t\t * route have a gateway.\n\t\t\t */\n\t\t\tif (rt->rt6i_flags & RTF_GATEWAY &&\n\t\t\t    !(rt->rt6i_flags & RTF_EXPIRES) &&\n\t\t\t    !(iter->rt6i_flags & RTF_EXPIRES))\n\t\t\t\trt->rt6i_nsiblings++;\n\t\t}\n\n\t\tif (iter->rt6i_metric > rt->rt6i_metric)\n\t\t\tbreak;\n\n\t\tins = &iter->dst.rt6_next;\n\t}\n\n\t/* Reset round-robin state, if necessary */\n\tif (ins == &fn->leaf)\n\t\tfn->rr_ptr = NULL;\n\n\t/* Link this route to others same route. */\n\tif (rt->rt6i_nsiblings) {\n\t\tunsigned int rt6i_nsiblings;\n\t\tstruct rt6_info *sibling, *temp_sibling;\n\n\t\t/* Find the first route that have the same metric */\n\t\tsibling = fn->leaf;\n\t\twhile (sibling) {\n\t\t\tif (sibling->rt6i_metric == rt->rt6i_metric) {\n\t\t\t\tlist_add_tail(&rt->rt6i_siblings,\n\t\t\t\t\t      &sibling->rt6i_siblings);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tsibling = sibling->dst.rt6_next;\n\t\t}\n\t\t/* For each sibling in the list, increment the counter of\n\t\t * siblings. BUG() if counters does not match, list of siblings\n\t\t * is broken!\n\t\t */\n\t\trt6i_nsiblings = 0;\n\t\tlist_for_each_entry_safe(sibling, temp_sibling,\n\t\t\t\t\t &rt->rt6i_siblings, rt6i_siblings) {\n\t\t\tsibling->rt6i_nsiblings++;\n\t\t\tBUG_ON(sibling->rt6i_nsiblings != rt->rt6i_nsiblings);\n\t\t\trt6i_nsiblings++;\n\t\t}\n\t\tBUG_ON(rt6i_nsiblings != rt->rt6i_nsiblings);\n\t}\n\n\t/*\n\t *\tinsert node\n\t */\n\tif (!replace) {\n\t\tif (!add)\n\t\t\tpr_warn(\"NLM_F_CREATE should be set when creating new route\\n\");\n\nadd:\n\t\trt->dst.rt6_next = iter;\n\t\t*ins = rt;\n\t\trt->rt6i_node = fn;\n\t\tatomic_inc(&rt->rt6i_ref);\n\t\tinet6_rt_notify(RTM_NEWROUTE, rt, info);\n\t\tinfo->nl_net->ipv6.rt6_stats->fib_rt_entries++;\n\n\t\tif (!(fn->fn_flags & RTN_RTINFO)) {\n\t\t\tinfo->nl_net->ipv6.rt6_stats->fib_route_nodes++;\n\t\t\tfn->fn_flags |= RTN_RTINFO;\n\t\t}\n\n\t} else {\n\t\tif (!found) {\n\t\t\tif (add)\n\t\t\t\tgoto add;\n\t\t\tpr_warn(\"NLM_F_REPLACE set, but no existing node found!\\n\");\n\t\t\treturn -ENOENT;\n\t\t}\n\t\t*ins = rt;\n\t\trt->rt6i_node = fn;\n\t\trt->dst.rt6_next = iter->dst.rt6_next;\n\t\tatomic_inc(&rt->rt6i_ref);\n\t\tinet6_rt_notify(RTM_NEWROUTE, rt, info);\n\t\trt6_release(iter);\n\t\tif (!(fn->fn_flags & RTN_RTINFO)) {\n\t\t\tinfo->nl_net->ipv6.rt6_stats->fib_route_nodes++;\n\t\t\tfn->fn_flags |= RTN_RTINFO;\n\t\t}\n\t}\n\n\treturn 0;\n}",
        "func": "static int fib6_add_rt2node(struct fib6_node *fn, struct rt6_info *rt,\n\t\t\t    struct nl_info *info)\n{\n\tstruct rt6_info *iter = NULL;\n\tstruct rt6_info **ins;\n\tint replace = (info->nlh &&\n\t\t       (info->nlh->nlmsg_flags & NLM_F_REPLACE));\n\tint add = (!info->nlh ||\n\t\t   (info->nlh->nlmsg_flags & NLM_F_CREATE));\n\tint found = 0;\n\tbool rt_can_ecmp = rt6_qualify_for_ecmp(rt);\n\n\tins = &fn->leaf;\n\n\tfor (iter = fn->leaf; iter; iter = iter->dst.rt6_next) {\n\t\t/*\n\t\t *\tSearch for duplicates\n\t\t */\n\n\t\tif (iter->rt6i_metric == rt->rt6i_metric) {\n\t\t\t/*\n\t\t\t *\tSame priority level\n\t\t\t */\n\t\t\tif (info->nlh &&\n\t\t\t    (info->nlh->nlmsg_flags & NLM_F_EXCL))\n\t\t\t\treturn -EEXIST;\n\t\t\tif (replace) {\n\t\t\t\tfound++;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tif (iter->dst.dev == rt->dst.dev &&\n\t\t\t    iter->rt6i_idev == rt->rt6i_idev &&\n\t\t\t    ipv6_addr_equal(&iter->rt6i_gateway,\n\t\t\t\t\t    &rt->rt6i_gateway)) {\n\t\t\t\tif (rt->rt6i_nsiblings)\n\t\t\t\t\trt->rt6i_nsiblings = 0;\n\t\t\t\tif (!(iter->rt6i_flags & RTF_EXPIRES))\n\t\t\t\t\treturn -EEXIST;\n\t\t\t\tif (!(rt->rt6i_flags & RTF_EXPIRES))\n\t\t\t\t\trt6_clean_expires(iter);\n\t\t\t\telse\n\t\t\t\t\trt6_set_expires(iter, rt->dst.expires);\n\t\t\t\treturn -EEXIST;\n\t\t\t}\n\t\t\t/* If we have the same destination and the same metric,\n\t\t\t * but not the same gateway, then the route we try to\n\t\t\t * add is sibling to this route, increment our counter\n\t\t\t * of siblings, and later we will add our route to the\n\t\t\t * list.\n\t\t\t * Only static routes (which don't have flag\n\t\t\t * RTF_EXPIRES) are used for ECMPv6.\n\t\t\t *\n\t\t\t * To avoid long list, we only had siblings if the\n\t\t\t * route have a gateway.\n\t\t\t */\n\t\t\tif (rt_can_ecmp &&\n\t\t\t    rt6_qualify_for_ecmp(iter))\n\t\t\t\trt->rt6i_nsiblings++;\n\t\t}\n\n\t\tif (iter->rt6i_metric > rt->rt6i_metric)\n\t\t\tbreak;\n\n\t\tins = &iter->dst.rt6_next;\n\t}\n\n\t/* Reset round-robin state, if necessary */\n\tif (ins == &fn->leaf)\n\t\tfn->rr_ptr = NULL;\n\n\t/* Link this route to others same route. */\n\tif (rt->rt6i_nsiblings) {\n\t\tunsigned int rt6i_nsiblings;\n\t\tstruct rt6_info *sibling, *temp_sibling;\n\n\t\t/* Find the first route that have the same metric */\n\t\tsibling = fn->leaf;\n\t\twhile (sibling) {\n\t\t\tif (sibling->rt6i_metric == rt->rt6i_metric &&\n\t\t\t    rt6_qualify_for_ecmp(sibling)) {\n\t\t\t\tlist_add_tail(&rt->rt6i_siblings,\n\t\t\t\t\t      &sibling->rt6i_siblings);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tsibling = sibling->dst.rt6_next;\n\t\t}\n\t\t/* For each sibling in the list, increment the counter of\n\t\t * siblings. BUG() if counters does not match, list of siblings\n\t\t * is broken!\n\t\t */\n\t\trt6i_nsiblings = 0;\n\t\tlist_for_each_entry_safe(sibling, temp_sibling,\n\t\t\t\t\t &rt->rt6i_siblings, rt6i_siblings) {\n\t\t\tsibling->rt6i_nsiblings++;\n\t\t\tBUG_ON(sibling->rt6i_nsiblings != rt->rt6i_nsiblings);\n\t\t\trt6i_nsiblings++;\n\t\t}\n\t\tBUG_ON(rt6i_nsiblings != rt->rt6i_nsiblings);\n\t}\n\n\t/*\n\t *\tinsert node\n\t */\n\tif (!replace) {\n\t\tif (!add)\n\t\t\tpr_warn(\"NLM_F_CREATE should be set when creating new route\\n\");\n\nadd:\n\t\trt->dst.rt6_next = iter;\n\t\t*ins = rt;\n\t\trt->rt6i_node = fn;\n\t\tatomic_inc(&rt->rt6i_ref);\n\t\tinet6_rt_notify(RTM_NEWROUTE, rt, info);\n\t\tinfo->nl_net->ipv6.rt6_stats->fib_rt_entries++;\n\n\t\tif (!(fn->fn_flags & RTN_RTINFO)) {\n\t\t\tinfo->nl_net->ipv6.rt6_stats->fib_route_nodes++;\n\t\t\tfn->fn_flags |= RTN_RTINFO;\n\t\t}\n\n\t} else {\n\t\tif (!found) {\n\t\t\tif (add)\n\t\t\t\tgoto add;\n\t\t\tpr_warn(\"NLM_F_REPLACE set, but no existing node found!\\n\");\n\t\t\treturn -ENOENT;\n\t\t}\n\t\t*ins = rt;\n\t\trt->rt6i_node = fn;\n\t\trt->dst.rt6_next = iter->dst.rt6_next;\n\t\tatomic_inc(&rt->rt6i_ref);\n\t\tinet6_rt_notify(RTM_NEWROUTE, rt, info);\n\t\trt6_release(iter);\n\t\tif (!(fn->fn_flags & RTN_RTINFO)) {\n\t\t\tinfo->nl_net->ipv6.rt6_stats->fib_route_nodes++;\n\t\t\tfn->fn_flags |= RTN_RTINFO;\n\t\t}\n\t}\n\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -8,6 +8,7 @@\n \tint add = (!info->nlh ||\n \t\t   (info->nlh->nlmsg_flags & NLM_F_CREATE));\n \tint found = 0;\n+\tbool rt_can_ecmp = rt6_qualify_for_ecmp(rt);\n \n \tins = &fn->leaf;\n \n@@ -53,9 +54,8 @@\n \t\t\t * To avoid long list, we only had siblings if the\n \t\t\t * route have a gateway.\n \t\t\t */\n-\t\t\tif (rt->rt6i_flags & RTF_GATEWAY &&\n-\t\t\t    !(rt->rt6i_flags & RTF_EXPIRES) &&\n-\t\t\t    !(iter->rt6i_flags & RTF_EXPIRES))\n+\t\t\tif (rt_can_ecmp &&\n+\t\t\t    rt6_qualify_for_ecmp(iter))\n \t\t\t\trt->rt6i_nsiblings++;\n \t\t}\n \n@@ -77,7 +77,8 @@\n \t\t/* Find the first route that have the same metric */\n \t\tsibling = fn->leaf;\n \t\twhile (sibling) {\n-\t\t\tif (sibling->rt6i_metric == rt->rt6i_metric) {\n+\t\t\tif (sibling->rt6i_metric == rt->rt6i_metric &&\n+\t\t\t    rt6_qualify_for_ecmp(sibling)) {\n \t\t\t\tlist_add_tail(&rt->rt6i_siblings,\n \t\t\t\t\t      &sibling->rt6i_siblings);\n \t\t\t\tbreak;",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\tif (rt->rt6i_flags & RTF_GATEWAY &&",
                "\t\t\t    !(rt->rt6i_flags & RTF_EXPIRES) &&",
                "\t\t\t    !(iter->rt6i_flags & RTF_EXPIRES))",
                "\t\t\tif (sibling->rt6i_metric == rt->rt6i_metric) {"
            ],
            "added_lines": [
                "\tbool rt_can_ecmp = rt6_qualify_for_ecmp(rt);",
                "\t\t\tif (rt_can_ecmp &&",
                "\t\t\t    rt6_qualify_for_ecmp(iter))",
                "\t\t\tif (sibling->rt6i_metric == rt->rt6i_metric &&",
                "\t\t\t    rt6_qualify_for_ecmp(sibling)) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-4127",
        "func_name": "torvalds/linux/vhost_net_ubuf_put_and_wait",
        "description": "Use-after-free vulnerability in the vhost_net_set_backend function in drivers/vhost/net.c in the Linux kernel through 3.10.3 allows local users to cause a denial of service (OOPS and system crash) via vectors involving powering on a virtual machine.",
        "git_url": "https://github.com/torvalds/linux/commit/dd7633ecd553a5e304d349aa6f8eb8a0417098c5",
        "commit_title": "vhost-net: fix use-after-free in vhost_net_flush",
        "commit_text": " vhost_net_ubuf_put_and_wait has a confusing name: it will actually also free it's argument. Thus since commit 1280c27f8e29acf4af2da914e80ec27c3dbd5c01     \"vhost-net: flush outstanding DMAs on memory change\" vhost_net_flush tries to use the argument after passing it to vhost_net_ubuf_put_and_wait, this results in use after free. To fix, don't free the argument in vhost_net_ubuf_put_and_wait, add an new API for callers that want to free ubufs. ",
        "func_before": "static void vhost_net_ubuf_put_and_wait(struct vhost_net_ubuf_ref *ubufs)\n{\n\tkref_put(&ubufs->kref, vhost_net_zerocopy_done_signal);\n\twait_event(ubufs->wait, !atomic_read(&ubufs->kref.refcount));\n\tkfree(ubufs);\n}",
        "func": "static void vhost_net_ubuf_put_and_wait(struct vhost_net_ubuf_ref *ubufs)\n{\n\tkref_put(&ubufs->kref, vhost_net_zerocopy_done_signal);\n\twait_event(ubufs->wait, !atomic_read(&ubufs->kref.refcount));\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,5 +2,4 @@\n {\n \tkref_put(&ubufs->kref, vhost_net_zerocopy_done_signal);\n \twait_event(ubufs->wait, !atomic_read(&ubufs->kref.refcount));\n-\tkfree(ubufs);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tkfree(ubufs);"
            ],
            "added_lines": []
        }
    },
    {
        "cve_id": "CVE-2013-4127",
        "func_name": "torvalds/linux/vhost_net_set_backend",
        "description": "Use-after-free vulnerability in the vhost_net_set_backend function in drivers/vhost/net.c in the Linux kernel through 3.10.3 allows local users to cause a denial of service (OOPS and system crash) via vectors involving powering on a virtual machine.",
        "git_url": "https://github.com/torvalds/linux/commit/dd7633ecd553a5e304d349aa6f8eb8a0417098c5",
        "commit_title": "vhost-net: fix use-after-free in vhost_net_flush",
        "commit_text": " vhost_net_ubuf_put_and_wait has a confusing name: it will actually also free it's argument. Thus since commit 1280c27f8e29acf4af2da914e80ec27c3dbd5c01     \"vhost-net: flush outstanding DMAs on memory change\" vhost_net_flush tries to use the argument after passing it to vhost_net_ubuf_put_and_wait, this results in use after free. To fix, don't free the argument in vhost_net_ubuf_put_and_wait, add an new API for callers that want to free ubufs. ",
        "func_before": "static long vhost_net_set_backend(struct vhost_net *n, unsigned index, int fd)\n{\n\tstruct socket *sock, *oldsock;\n\tstruct vhost_virtqueue *vq;\n\tstruct vhost_net_virtqueue *nvq;\n\tstruct vhost_net_ubuf_ref *ubufs, *oldubufs = NULL;\n\tint r;\n\n\tmutex_lock(&n->dev.mutex);\n\tr = vhost_dev_check_owner(&n->dev);\n\tif (r)\n\t\tgoto err;\n\n\tif (index >= VHOST_NET_VQ_MAX) {\n\t\tr = -ENOBUFS;\n\t\tgoto err;\n\t}\n\tvq = &n->vqs[index].vq;\n\tnvq = &n->vqs[index];\n\tmutex_lock(&vq->mutex);\n\n\t/* Verify that ring has been setup correctly. */\n\tif (!vhost_vq_access_ok(vq)) {\n\t\tr = -EFAULT;\n\t\tgoto err_vq;\n\t}\n\tsock = get_socket(fd);\n\tif (IS_ERR(sock)) {\n\t\tr = PTR_ERR(sock);\n\t\tgoto err_vq;\n\t}\n\n\t/* start polling new socket */\n\toldsock = rcu_dereference_protected(vq->private_data,\n\t\t\t\t\t    lockdep_is_held(&vq->mutex));\n\tif (sock != oldsock) {\n\t\tubufs = vhost_net_ubuf_alloc(vq,\n\t\t\t\t\t     sock && vhost_sock_zcopy(sock));\n\t\tif (IS_ERR(ubufs)) {\n\t\t\tr = PTR_ERR(ubufs);\n\t\t\tgoto err_ubufs;\n\t\t}\n\n\t\tvhost_net_disable_vq(n, vq);\n\t\trcu_assign_pointer(vq->private_data, sock);\n\t\tr = vhost_init_used(vq);\n\t\tif (r)\n\t\t\tgoto err_used;\n\t\tr = vhost_net_enable_vq(n, vq);\n\t\tif (r)\n\t\t\tgoto err_used;\n\n\t\toldubufs = nvq->ubufs;\n\t\tnvq->ubufs = ubufs;\n\n\t\tn->tx_packets = 0;\n\t\tn->tx_zcopy_err = 0;\n\t\tn->tx_flush = false;\n\t}\n\n\tmutex_unlock(&vq->mutex);\n\n\tif (oldubufs) {\n\t\tvhost_net_ubuf_put_and_wait(oldubufs);\n\t\tmutex_lock(&vq->mutex);\n\t\tvhost_zerocopy_signal_used(n, vq);\n\t\tmutex_unlock(&vq->mutex);\n\t}\n\n\tif (oldsock) {\n\t\tvhost_net_flush_vq(n, index);\n\t\tfput(oldsock->file);\n\t}\n\n\tmutex_unlock(&n->dev.mutex);\n\treturn 0;\n\nerr_used:\n\trcu_assign_pointer(vq->private_data, oldsock);\n\tvhost_net_enable_vq(n, vq);\n\tif (ubufs)\n\t\tvhost_net_ubuf_put_and_wait(ubufs);\nerr_ubufs:\n\tfput(sock->file);\nerr_vq:\n\tmutex_unlock(&vq->mutex);\nerr:\n\tmutex_unlock(&n->dev.mutex);\n\treturn r;\n}",
        "func": "static long vhost_net_set_backend(struct vhost_net *n, unsigned index, int fd)\n{\n\tstruct socket *sock, *oldsock;\n\tstruct vhost_virtqueue *vq;\n\tstruct vhost_net_virtqueue *nvq;\n\tstruct vhost_net_ubuf_ref *ubufs, *oldubufs = NULL;\n\tint r;\n\n\tmutex_lock(&n->dev.mutex);\n\tr = vhost_dev_check_owner(&n->dev);\n\tif (r)\n\t\tgoto err;\n\n\tif (index >= VHOST_NET_VQ_MAX) {\n\t\tr = -ENOBUFS;\n\t\tgoto err;\n\t}\n\tvq = &n->vqs[index].vq;\n\tnvq = &n->vqs[index];\n\tmutex_lock(&vq->mutex);\n\n\t/* Verify that ring has been setup correctly. */\n\tif (!vhost_vq_access_ok(vq)) {\n\t\tr = -EFAULT;\n\t\tgoto err_vq;\n\t}\n\tsock = get_socket(fd);\n\tif (IS_ERR(sock)) {\n\t\tr = PTR_ERR(sock);\n\t\tgoto err_vq;\n\t}\n\n\t/* start polling new socket */\n\toldsock = rcu_dereference_protected(vq->private_data,\n\t\t\t\t\t    lockdep_is_held(&vq->mutex));\n\tif (sock != oldsock) {\n\t\tubufs = vhost_net_ubuf_alloc(vq,\n\t\t\t\t\t     sock && vhost_sock_zcopy(sock));\n\t\tif (IS_ERR(ubufs)) {\n\t\t\tr = PTR_ERR(ubufs);\n\t\t\tgoto err_ubufs;\n\t\t}\n\n\t\tvhost_net_disable_vq(n, vq);\n\t\trcu_assign_pointer(vq->private_data, sock);\n\t\tr = vhost_init_used(vq);\n\t\tif (r)\n\t\t\tgoto err_used;\n\t\tr = vhost_net_enable_vq(n, vq);\n\t\tif (r)\n\t\t\tgoto err_used;\n\n\t\toldubufs = nvq->ubufs;\n\t\tnvq->ubufs = ubufs;\n\n\t\tn->tx_packets = 0;\n\t\tn->tx_zcopy_err = 0;\n\t\tn->tx_flush = false;\n\t}\n\n\tmutex_unlock(&vq->mutex);\n\n\tif (oldubufs) {\n\t\tvhost_net_ubuf_put_wait_and_free(oldubufs);\n\t\tmutex_lock(&vq->mutex);\n\t\tvhost_zerocopy_signal_used(n, vq);\n\t\tmutex_unlock(&vq->mutex);\n\t}\n\n\tif (oldsock) {\n\t\tvhost_net_flush_vq(n, index);\n\t\tfput(oldsock->file);\n\t}\n\n\tmutex_unlock(&n->dev.mutex);\n\treturn 0;\n\nerr_used:\n\trcu_assign_pointer(vq->private_data, oldsock);\n\tvhost_net_enable_vq(n, vq);\n\tif (ubufs)\n\t\tvhost_net_ubuf_put_wait_and_free(ubufs);\nerr_ubufs:\n\tfput(sock->file);\nerr_vq:\n\tmutex_unlock(&vq->mutex);\nerr:\n\tmutex_unlock(&n->dev.mutex);\n\treturn r;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -61,7 +61,7 @@\n \tmutex_unlock(&vq->mutex);\n \n \tif (oldubufs) {\n-\t\tvhost_net_ubuf_put_and_wait(oldubufs);\n+\t\tvhost_net_ubuf_put_wait_and_free(oldubufs);\n \t\tmutex_lock(&vq->mutex);\n \t\tvhost_zerocopy_signal_used(n, vq);\n \t\tmutex_unlock(&vq->mutex);\n@@ -79,7 +79,7 @@\n \trcu_assign_pointer(vq->private_data, oldsock);\n \tvhost_net_enable_vq(n, vq);\n \tif (ubufs)\n-\t\tvhost_net_ubuf_put_and_wait(ubufs);\n+\t\tvhost_net_ubuf_put_wait_and_free(ubufs);\n err_ubufs:\n \tfput(sock->file);\n err_vq:",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tvhost_net_ubuf_put_and_wait(oldubufs);",
                "\t\tvhost_net_ubuf_put_and_wait(ubufs);"
            ],
            "added_lines": [
                "\t\tvhost_net_ubuf_put_wait_and_free(oldubufs);",
                "\t\tvhost_net_ubuf_put_wait_and_free(ubufs);"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-4162",
        "func_name": "torvalds/linux/udp_push_pending_frames",
        "description": "The udp_v6_push_pending_frames function in net/ipv6/udp.c in the IPv6 implementation in the Linux kernel through 3.10.3 makes an incorrect function call for pending data, which allows local users to cause a denial of service (BUG and system crash) via a crafted application that uses the UDP_CORK option in a setsockopt system call.",
        "git_url": "https://github.com/torvalds/linux/commit/8822b64a0fa64a5dd1dfcf837c5b0be83f8c05d1",
        "commit_title": "ipv6: call udp_push_pending_frames when uncorking a socket with AF_INET pending data",
        "commit_text": " We accidentally call down to ip6_push_pending_frames when uncorking pending AF_INET data on a ipv6 socket. This results in the following splat (from Dave Jones):  skbuff: skb_under_panic: text:ffffffff816765f6 len:48 put:40 head:ffff88013deb6df0 data:ffff88013deb6dec tail:0x2c end:0xc0 dev:<NULL> ------------[ cut here ]------------ kernel BUG at net/core/skbuff.c:126! invalid opcode: 0000 [#1] PREEMPT SMP DEBUG_PAGEALLOC Modules linked in: dccp_ipv4 dccp 8021q garp bridge stp dlci mpoa snd_seq_dummy sctp fuse hidp tun bnep nfnetlink scsi_transport_iscsi rfcomm can_raw can_bcm af_802154 appletalk caif_socket can caif ipt_ULOG x25 rose af_key pppoe pppox ipx phonet irda llc2 ppp_generic slhc p8023 psnap p8022 llc crc_ccitt atm bluetooth +netrom ax25 nfc rfkill rds af_rxrpc coretemp hwmon kvm_intel kvm crc32c_intel snd_hda_codec_realtek ghash_clmulni_intel microcode pcspkr snd_hda_codec_hdmi snd_hda_intel snd_hda_codec snd_hwdep usb_debug snd_seq snd_seq_device snd_pcm e1000e snd_page_alloc snd_timer ptp snd pps_core soundcore xfs libcrc32c CPU: 2 PID: 8095 Comm: trinity-child2 Not tainted 3.10.0-rc7+ #37 task: ffff8801f52c2520 ti: ffff8801e6430000 task.ti: ffff8801e6430000 RIP: 0010:[<ffffffff816e759c>]  [<ffffffff816e759c>] skb_panic+0x63/0x65 RSP: 0018:ffff8801e6431de8  EFLAGS: 00010282 RAX: 0000000000000086 RBX: ffff8802353d3cc0 RCX: 0000000000000006 RDX: 0000000000003b90 RSI: ffff8801f52c2ca0 RDI: ffff8801f52c2520 RBP: ffff8801e6431e08 R08: 0000000000000000 R09: 0000000000000000 R10: 0000000000000001 R11: 0000000000000001 R12: ffff88022ea0c800 R13: ffff88022ea0cdf8 R14: ffff8802353ecb40 R15: ffffffff81cc7800 FS:  00007f5720a10740(0000) GS:ffff880244c00000(0000) knlGS:0000000000000000 CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033 CR2: 0000000005862000 CR3: 000000022843c000 CR4: 00000000001407e0 DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000 DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000600 Stack:  ffff88013deb6dec 000000000000002c 00000000000000c0 ffffffff81a3f6e4  ffff8801e6431e18 ffffffff8159a9aa ffff8801e6431e90 ffffffff816765f6  ffffffff810b756b 0000000700000002 ffff8801e6431e40 0000fea9292aa8c0 Call Trace:  [<ffffffff8159a9aa>] skb_push+0x3a/0x40  [<ffffffff816765f6>] ip6_push_pending_frames+0x1f6/0x4d0  [<ffffffff810b756b>] ? mark_held_locks+0xbb/0x140  [<ffffffff81694919>] udp_v6_push_pending_frames+0x2b9/0x3d0  [<ffffffff81694660>] ? udplite_getfrag+0x20/0x20  [<ffffffff8162092a>] udp_lib_setsockopt+0x1aa/0x1f0  [<ffffffff811cc5e7>] ? fget_light+0x387/0x4f0  [<ffffffff816958a4>] udpv6_setsockopt+0x34/0x40  [<ffffffff815949f4>] sock_common_setsockopt+0x14/0x20  [<ffffffff81593c31>] SyS_setsockopt+0x71/0xd0  [<ffffffff816f5d54>] tracesys+0xdd/0xe2 Code: 00 00 48 89 44 24 10 8b 87 d8 00 00 00 48 89 44 24 08 48 8b 87 e8 00 00 00 48 c7 c7 c0 04 aa 81 48 89 04 24 31 c0 e8 e1 7e ff ff <0f> 0b 55 48 89 e5 0f 0b 55 48 89 e5 0f 0b 55 48 89 e5 0f 0b 55 RIP  [<ffffffff816e759c>] skb_panic+0x63/0x65  RSP <ffff8801e6431de8>  This patch adds a check if the pending data is of address family AF_INET and directly calls udp_push_ending_frames from udp_v6_push_pending_frames if that is the case.  This bug was found by Dave Jones with trinity.  (Also move the initialization of fl6 below the AF_INET check, even if not strictly necessary.)  Cc: Dave Jones <davej@redhat.com> Cc: YOSHIFUJI Hideaki <yoshfuji@linux-ipv6.org>",
        "func_before": "static int udp_push_pending_frames(struct sock *sk)\n{\n\tstruct udp_sock  *up = udp_sk(sk);\n\tstruct inet_sock *inet = inet_sk(sk);\n\tstruct flowi4 *fl4 = &inet->cork.fl.u.ip4;\n\tstruct sk_buff *skb;\n\tint err = 0;\n\n\tskb = ip_finish_skb(sk, fl4);\n\tif (!skb)\n\t\tgoto out;\n\n\terr = udp_send_skb(skb, fl4);\n\nout:\n\tup->len = 0;\n\tup->pending = 0;\n\treturn err;\n}",
        "func": "int udp_push_pending_frames(struct sock *sk)\n{\n\tstruct udp_sock  *up = udp_sk(sk);\n\tstruct inet_sock *inet = inet_sk(sk);\n\tstruct flowi4 *fl4 = &inet->cork.fl.u.ip4;\n\tstruct sk_buff *skb;\n\tint err = 0;\n\n\tskb = ip_finish_skb(sk, fl4);\n\tif (!skb)\n\t\tgoto out;\n\n\terr = udp_send_skb(skb, fl4);\n\nout:\n\tup->len = 0;\n\tup->pending = 0;\n\treturn err;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,4 +1,4 @@\n-static int udp_push_pending_frames(struct sock *sk)\n+int udp_push_pending_frames(struct sock *sk)\n {\n \tstruct udp_sock  *up = udp_sk(sk);\n \tstruct inet_sock *inet = inet_sk(sk);",
        "diff_line_info": {
            "deleted_lines": [
                "static int udp_push_pending_frames(struct sock *sk)"
            ],
            "added_lines": [
                "int udp_push_pending_frames(struct sock *sk)"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-4162",
        "func_name": "torvalds/linux/udp_push_pending_frames",
        "description": "The udp_v6_push_pending_frames function in net/ipv6/udp.c in the IPv6 implementation in the Linux kernel through 3.10.3 makes an incorrect function call for pending data, which allows local users to cause a denial of service (BUG and system crash) via a crafted application that uses the UDP_CORK option in a setsockopt system call.",
        "git_url": "https://github.com/torvalds/linux/commit/8822b64a0fa64a5dd1dfcf837c5b0be83f8c05d1",
        "commit_title": "ipv6: call udp_push_pending_frames when uncorking a socket with AF_INET pending data",
        "commit_text": " We accidentally call down to ip6_push_pending_frames when uncorking pending AF_INET data on a ipv6 socket. This results in the following splat (from Dave Jones):  skbuff: skb_under_panic: text:ffffffff816765f6 len:48 put:40 head:ffff88013deb6df0 data:ffff88013deb6dec tail:0x2c end:0xc0 dev:<NULL> ------------[ cut here ]------------ kernel BUG at net/core/skbuff.c:126! invalid opcode: 0000 [#1] PREEMPT SMP DEBUG_PAGEALLOC Modules linked in: dccp_ipv4 dccp 8021q garp bridge stp dlci mpoa snd_seq_dummy sctp fuse hidp tun bnep nfnetlink scsi_transport_iscsi rfcomm can_raw can_bcm af_802154 appletalk caif_socket can caif ipt_ULOG x25 rose af_key pppoe pppox ipx phonet irda llc2 ppp_generic slhc p8023 psnap p8022 llc crc_ccitt atm bluetooth +netrom ax25 nfc rfkill rds af_rxrpc coretemp hwmon kvm_intel kvm crc32c_intel snd_hda_codec_realtek ghash_clmulni_intel microcode pcspkr snd_hda_codec_hdmi snd_hda_intel snd_hda_codec snd_hwdep usb_debug snd_seq snd_seq_device snd_pcm e1000e snd_page_alloc snd_timer ptp snd pps_core soundcore xfs libcrc32c CPU: 2 PID: 8095 Comm: trinity-child2 Not tainted 3.10.0-rc7+ #37 task: ffff8801f52c2520 ti: ffff8801e6430000 task.ti: ffff8801e6430000 RIP: 0010:[<ffffffff816e759c>]  [<ffffffff816e759c>] skb_panic+0x63/0x65 RSP: 0018:ffff8801e6431de8  EFLAGS: 00010282 RAX: 0000000000000086 RBX: ffff8802353d3cc0 RCX: 0000000000000006 RDX: 0000000000003b90 RSI: ffff8801f52c2ca0 RDI: ffff8801f52c2520 RBP: ffff8801e6431e08 R08: 0000000000000000 R09: 0000000000000000 R10: 0000000000000001 R11: 0000000000000001 R12: ffff88022ea0c800 R13: ffff88022ea0cdf8 R14: ffff8802353ecb40 R15: ffffffff81cc7800 FS:  00007f5720a10740(0000) GS:ffff880244c00000(0000) knlGS:0000000000000000 CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033 CR2: 0000000005862000 CR3: 000000022843c000 CR4: 00000000001407e0 DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000 DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000600 Stack:  ffff88013deb6dec 000000000000002c 00000000000000c0 ffffffff81a3f6e4  ffff8801e6431e18 ffffffff8159a9aa ffff8801e6431e90 ffffffff816765f6  ffffffff810b756b 0000000700000002 ffff8801e6431e40 0000fea9292aa8c0 Call Trace:  [<ffffffff8159a9aa>] skb_push+0x3a/0x40  [<ffffffff816765f6>] ip6_push_pending_frames+0x1f6/0x4d0  [<ffffffff810b756b>] ? mark_held_locks+0xbb/0x140  [<ffffffff81694919>] udp_v6_push_pending_frames+0x2b9/0x3d0  [<ffffffff81694660>] ? udplite_getfrag+0x20/0x20  [<ffffffff8162092a>] udp_lib_setsockopt+0x1aa/0x1f0  [<ffffffff811cc5e7>] ? fget_light+0x387/0x4f0  [<ffffffff816958a4>] udpv6_setsockopt+0x34/0x40  [<ffffffff815949f4>] sock_common_setsockopt+0x14/0x20  [<ffffffff81593c31>] SyS_setsockopt+0x71/0xd0  [<ffffffff816f5d54>] tracesys+0xdd/0xe2 Code: 00 00 48 89 44 24 10 8b 87 d8 00 00 00 48 89 44 24 08 48 8b 87 e8 00 00 00 48 c7 c7 c0 04 aa 81 48 89 04 24 31 c0 e8 e1 7e ff ff <0f> 0b 55 48 89 e5 0f 0b 55 48 89 e5 0f 0b 55 48 89 e5 0f 0b 55 RIP  [<ffffffff816e759c>] skb_panic+0x63/0x65  RSP <ffff8801e6431de8>  This patch adds a check if the pending data is of address family AF_INET and directly calls udp_push_ending_frames from udp_v6_push_pending_frames if that is the case.  This bug was found by Dave Jones with trinity.  (Also move the initialization of fl6 below the AF_INET check, even if not strictly necessary.)  Cc: Dave Jones <davej@redhat.com> Cc: YOSHIFUJI Hideaki <yoshfuji@linux-ipv6.org>",
        "func_before": "static int udp_push_pending_frames(struct sock *sk)\n{\n\tstruct udp_sock  *up = udp_sk(sk);\n\tstruct inet_sock *inet = inet_sk(sk);\n\tstruct flowi4 *fl4 = &inet->cork.fl.u.ip4;\n\tstruct sk_buff *skb;\n\tint err = 0;\n\n\tskb = ip_finish_skb(sk, fl4);\n\tif (!skb)\n\t\tgoto out;\n\n\terr = udp_send_skb(skb, fl4);\n\nout:\n\tup->len = 0;\n\tup->pending = 0;\n\treturn err;\n}",
        "func": "int udp_push_pending_frames(struct sock *sk)\n{\n\tstruct udp_sock  *up = udp_sk(sk);\n\tstruct inet_sock *inet = inet_sk(sk);\n\tstruct flowi4 *fl4 = &inet->cork.fl.u.ip4;\n\tstruct sk_buff *skb;\n\tint err = 0;\n\n\tskb = ip_finish_skb(sk, fl4);\n\tif (!skb)\n\t\tgoto out;\n\n\terr = udp_send_skb(skb, fl4);\n\nout:\n\tup->len = 0;\n\tup->pending = 0;\n\treturn err;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,4 +1,4 @@\n-static int udp_push_pending_frames(struct sock *sk)\n+int udp_push_pending_frames(struct sock *sk)\n {\n \tstruct udp_sock  *up = udp_sk(sk);\n \tstruct inet_sock *inet = inet_sk(sk);",
        "diff_line_info": {
            "deleted_lines": [
                "static int udp_push_pending_frames(struct sock *sk)"
            ],
            "added_lines": [
                "int udp_push_pending_frames(struct sock *sk)"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-4163",
        "func_name": "torvalds/linux/ip6_append_data",
        "description": "The ip6_append_data_mtu function in net/ipv6/ip6_output.c in the IPv6 implementation in the Linux kernel through 3.10.3 does not properly maintain information about whether the IPV6_MTU setsockopt option had been specified, which allows local users to cause a denial of service (BUG and system crash) via a crafted application that uses the UDP_CORK option in a setsockopt system call.",
        "git_url": "https://github.com/torvalds/linux/commit/75a493e60ac4bbe2e977e7129d6d8cbb0dd236be",
        "commit_title": "ipv6: ip6_append_data_mtu did not care about pmtudisc and frag_size",
        "commit_text": " If the socket had an IPV6_MTU value set, ip6_append_data_mtu lost track of this when appending the second frame on a corked socket. This results in the following splat:  [37598.993962] ------------[ cut here ]------------ [37598.994008] kernel BUG at net/core/skbuff.c:2064! [37598.994008] invalid opcode: 0000 [#1] SMP [37598.994008] Modules linked in: tcp_lp uvcvideo videobuf2_vmalloc videobuf2_memops videobuf2_core videodev media vfat fat usb_storage fuse ebtable_nat xt_CHECKSUM bridge stp llc ipt_MASQUERADE nf_conntrack_netbios_ns nf_conntrack_broadcast ip6table_mangle ip6t_REJECT nf_conntrack_ipv6 nf_defrag_ipv6 iptable_nat +nf_nat_ipv4 nf_nat iptable_mangle nf_conntrack_ipv4 nf_defrag_ipv4 xt_conntrack nf_conntrack ebtable_filter ebtables ip6table_filter ip6_tables be2iscsi iscsi_boot_sysfs bnx2i cnic uio cxgb4i cxgb4 cxgb3i cxgb3 mdio libcxgbi ib_iser rdma_cm ib_addr iw_cm ib_cm ib_sa ib_mad ib_core iscsi_tcp libiscsi_tcp libiscsi +scsi_transport_iscsi rfcomm bnep iTCO_wdt iTCO_vendor_support snd_hda_codec_conexant arc4 iwldvm mac80211 snd_hda_intel acpi_cpufreq mperf coretemp snd_hda_codec microcode cdc_wdm cdc_acm [37598.994008]  snd_hwdep cdc_ether snd_seq snd_seq_device usbnet mii joydev btusb snd_pcm bluetooth i2c_i801 e1000e lpc_ich mfd_core ptp iwlwifi pps_core snd_page_alloc mei cfg80211 snd_timer thinkpad_acpi snd tpm_tis soundcore rfkill tpm tpm_bios vhost_net tun macvtap macvlan kvm_intel kvm uinput binfmt_misc +dm_crypt i915 i2c_algo_bit drm_kms_helper drm i2c_core wmi video [37598.994008] CPU 0 [37598.994008] Pid: 27320, comm: t2 Not tainted 3.9.6-200.fc18.x86_64 #1 LENOVO 27744PG/27744PG [37598.994008] RIP: 0010:[<ffffffff815443a5>]  [<ffffffff815443a5>] skb_copy_and_csum_bits+0x325/0x330 [37598.994008] RSP: 0018:ffff88003670da18  EFLAGS: 00010202 [37598.994008] RAX: ffff88018105c018 RBX: 0000000000000004 RCX: 00000000000006c0 [37598.994008] RDX: ffff88018105a6c0 RSI: ffff88018105a000 RDI: ffff8801e1b0aa00 [37598.994008] RBP: ffff88003670da78 R08: 0000000000000000 R09: ffff88018105c040 [37598.994008] R10: ffff8801e1b0aa00 R11: 0000000000000000 R12: 000000000000fff8 [37598.994008] R13: 00000000000004fc R14: 00000000ffff0504 R15: 0000000000000000 [37598.994008] FS:  00007f28eea59740(0000) GS:ffff88023bc00000(0000) knlGS:0000000000000000 [37598.994008] CS:  0010 DS: 0000 ES: 0000 CR0: 000000008005003b [37598.994008] CR2: 0000003d935789e0 CR3: 00000000365cb000 CR4: 00000000000407f0 [37598.994008] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000 [37598.994008] DR3: 0000000000000000 DR6: 00000000ffff0ff0 DR7: 0000000000000400 [37598.994008] Process t2 (pid: 27320, threadinfo ffff88003670c000, task ffff88022c162ee0) [37598.994008] Stack: [37598.994008]  ffff88022e098a00 ffff88020f973fc0 0000000000000008 00000000000004c8 [37598.994008]  ffff88020f973fc0 00000000000004c4 ffff88003670da78 ffff8801e1b0a200 [37598.994008]  0000000000000018 00000000000004c8 ffff88020f973fc0 00000000000004c4 [37598.994008] Call Trace: [37598.994008]  [<ffffffff815fc21f>] ip6_append_data+0xccf/0xfe0 [37598.994008]  [<ffffffff8158d9f0>] ? ip_copy_metadata+0x1a0/0x1a0 [37598.994008]  [<ffffffff81661f66>] ? _raw_spin_lock_bh+0x16/0x40 [37598.994008]  [<ffffffff8161548d>] udpv6_sendmsg+0x1ed/0xc10 [37598.994008]  [<ffffffff812a2845>] ? sock_has_perm+0x75/0x90 [37598.994008]  [<ffffffff815c3693>] inet_sendmsg+0x63/0xb0 [37598.994008]  [<ffffffff812a2973>] ? selinux_socket_sendmsg+0x23/0x30 [37598.994008]  [<ffffffff8153a450>] sock_sendmsg+0xb0/0xe0 [37598.994008]  [<ffffffff810135d1>] ? __switch_to+0x181/0x4a0 [37598.994008]  [<ffffffff8153d97d>] sys_sendto+0x12d/0x180 [37598.994008]  [<ffffffff810dfb64>] ? __audit_syscall_entry+0x94/0xf0 [37598.994008]  [<ffffffff81020ed1>] ? syscall_trace_enter+0x231/0x240 [37598.994008]  [<ffffffff8166a7e7>] tracesys+0xdd/0xe2 [37598.994008] Code: fe 07 00 00 48 c7 c7 04 28 a6 81 89 45 a0 4c 89 4d b8 44 89 5d a8 e8 1b ac b1 ff 44 8b 5d a8 4c 8b 4d b8 8b 45 a0 e9 cf fe ff ff <0f> 0b 66 0f 1f 84 00 00 00 00 00 66 66 66 66 90 55 48 89 e5 48 [37598.994008] RIP  [<ffffffff815443a5>] skb_copy_and_csum_bits+0x325/0x330 [37598.994008]  RSP <ffff88003670da18> [37599.007323] ---[ end trace d69f6a17f8ac8eee ]---  While there, also check if path mtu discovery is activated for this socket. The logic was adapted from ip6_append_data when first writing on the corked socket.  This bug was introduced with commit 0c1833797a5a6ec23ea9261d979aa18078720b74 (\"ipv6: fix incorrect ipsec fragment\").  v2: a) Replace IPV6_PMTU_DISC_DO with IPV6_PMTUDISC_PROBE. b) Don't pass ipv6_pinfo to ip6_append_data_mtu (suggestion by Gao    feng, thanks!). c) Change mtu to unsigned int, else we get a warning about    non-matching types because of the min()-macro type-check.  Cc: YOSHIFUJI Hideaki <yoshfuji@linux-ipv6.org>",
        "func_before": "int ip6_append_data(struct sock *sk, int getfrag(void *from, char *to,\n\tint offset, int len, int odd, struct sk_buff *skb),\n\tvoid *from, int length, int transhdrlen,\n\tint hlimit, int tclass, struct ipv6_txoptions *opt, struct flowi6 *fl6,\n\tstruct rt6_info *rt, unsigned int flags, int dontfrag)\n{\n\tstruct inet_sock *inet = inet_sk(sk);\n\tstruct ipv6_pinfo *np = inet6_sk(sk);\n\tstruct inet_cork *cork;\n\tstruct sk_buff *skb, *skb_prev = NULL;\n\tunsigned int maxfraglen, fragheaderlen;\n\tint exthdrlen;\n\tint dst_exthdrlen;\n\tint hh_len;\n\tint mtu;\n\tint copy;\n\tint err;\n\tint offset = 0;\n\t__u8 tx_flags = 0;\n\n\tif (flags&MSG_PROBE)\n\t\treturn 0;\n\tcork = &inet->cork.base;\n\tif (skb_queue_empty(&sk->sk_write_queue)) {\n\t\t/*\n\t\t * setup for corking\n\t\t */\n\t\tif (opt) {\n\t\t\tif (WARN_ON(np->cork.opt))\n\t\t\t\treturn -EINVAL;\n\n\t\t\tnp->cork.opt = kzalloc(opt->tot_len, sk->sk_allocation);\n\t\t\tif (unlikely(np->cork.opt == NULL))\n\t\t\t\treturn -ENOBUFS;\n\n\t\t\tnp->cork.opt->tot_len = opt->tot_len;\n\t\t\tnp->cork.opt->opt_flen = opt->opt_flen;\n\t\t\tnp->cork.opt->opt_nflen = opt->opt_nflen;\n\n\t\t\tnp->cork.opt->dst0opt = ip6_opt_dup(opt->dst0opt,\n\t\t\t\t\t\t\t    sk->sk_allocation);\n\t\t\tif (opt->dst0opt && !np->cork.opt->dst0opt)\n\t\t\t\treturn -ENOBUFS;\n\n\t\t\tnp->cork.opt->dst1opt = ip6_opt_dup(opt->dst1opt,\n\t\t\t\t\t\t\t    sk->sk_allocation);\n\t\t\tif (opt->dst1opt && !np->cork.opt->dst1opt)\n\t\t\t\treturn -ENOBUFS;\n\n\t\t\tnp->cork.opt->hopopt = ip6_opt_dup(opt->hopopt,\n\t\t\t\t\t\t\t   sk->sk_allocation);\n\t\t\tif (opt->hopopt && !np->cork.opt->hopopt)\n\t\t\t\treturn -ENOBUFS;\n\n\t\t\tnp->cork.opt->srcrt = ip6_rthdr_dup(opt->srcrt,\n\t\t\t\t\t\t\t    sk->sk_allocation);\n\t\t\tif (opt->srcrt && !np->cork.opt->srcrt)\n\t\t\t\treturn -ENOBUFS;\n\n\t\t\t/* need source address above miyazawa*/\n\t\t}\n\t\tdst_hold(&rt->dst);\n\t\tcork->dst = &rt->dst;\n\t\tinet->cork.fl.u.ip6 = *fl6;\n\t\tnp->cork.hop_limit = hlimit;\n\t\tnp->cork.tclass = tclass;\n\t\tif (rt->dst.flags & DST_XFRM_TUNNEL)\n\t\t\tmtu = np->pmtudisc == IPV6_PMTUDISC_PROBE ?\n\t\t\t      rt->dst.dev->mtu : dst_mtu(&rt->dst);\n\t\telse\n\t\t\tmtu = np->pmtudisc == IPV6_PMTUDISC_PROBE ?\n\t\t\t      rt->dst.dev->mtu : dst_mtu(rt->dst.path);\n\t\tif (np->frag_size < mtu) {\n\t\t\tif (np->frag_size)\n\t\t\t\tmtu = np->frag_size;\n\t\t}\n\t\tcork->fragsize = mtu;\n\t\tif (dst_allfrag(rt->dst.path))\n\t\t\tcork->flags |= IPCORK_ALLFRAG;\n\t\tcork->length = 0;\n\t\texthdrlen = (opt ? opt->opt_flen : 0);\n\t\tlength += exthdrlen;\n\t\ttranshdrlen += exthdrlen;\n\t\tdst_exthdrlen = rt->dst.header_len - rt->rt6i_nfheader_len;\n\t} else {\n\t\trt = (struct rt6_info *)cork->dst;\n\t\tfl6 = &inet->cork.fl.u.ip6;\n\t\topt = np->cork.opt;\n\t\ttranshdrlen = 0;\n\t\texthdrlen = 0;\n\t\tdst_exthdrlen = 0;\n\t\tmtu = cork->fragsize;\n\t}\n\n\thh_len = LL_RESERVED_SPACE(rt->dst.dev);\n\n\tfragheaderlen = sizeof(struct ipv6hdr) + rt->rt6i_nfheader_len +\n\t\t\t(opt ? opt->opt_nflen : 0);\n\tmaxfraglen = ((mtu - fragheaderlen) & ~7) + fragheaderlen - sizeof(struct frag_hdr);\n\n\tif (mtu <= sizeof(struct ipv6hdr) + IPV6_MAXPLEN) {\n\t\tif (cork->length + length > sizeof(struct ipv6hdr) + IPV6_MAXPLEN - fragheaderlen) {\n\t\t\tipv6_local_error(sk, EMSGSIZE, fl6, mtu-exthdrlen);\n\t\t\treturn -EMSGSIZE;\n\t\t}\n\t}\n\n\t/* For UDP, check if TX timestamp is enabled */\n\tif (sk->sk_type == SOCK_DGRAM)\n\t\tsock_tx_timestamp(sk, &tx_flags);\n\n\t/*\n\t * Let's try using as much space as possible.\n\t * Use MTU if total length of the message fits into the MTU.\n\t * Otherwise, we need to reserve fragment header and\n\t * fragment alignment (= 8-15 octects, in total).\n\t *\n\t * Note that we may need to \"move\" the data from the tail of\n\t * of the buffer to the new fragment when we split\n\t * the message.\n\t *\n\t * FIXME: It may be fragmented into multiple chunks\n\t *        at once if non-fragmentable extension headers\n\t *        are too large.\n\t * --yoshfuji\n\t */\n\n\tcork->length += length;\n\tif (length > mtu) {\n\t\tint proto = sk->sk_protocol;\n\t\tif (dontfrag && (proto == IPPROTO_UDP || proto == IPPROTO_RAW)){\n\t\t\tipv6_local_rxpmtu(sk, fl6, mtu-exthdrlen);\n\t\t\treturn -EMSGSIZE;\n\t\t}\n\n\t\tif (proto == IPPROTO_UDP &&\n\t\t    (rt->dst.dev->features & NETIF_F_UFO)) {\n\n\t\t\terr = ip6_ufo_append_data(sk, getfrag, from, length,\n\t\t\t\t\t\t  hh_len, fragheaderlen,\n\t\t\t\t\t\t  transhdrlen, mtu, flags, rt);\n\t\t\tif (err)\n\t\t\t\tgoto error;\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\tif ((skb = skb_peek_tail(&sk->sk_write_queue)) == NULL)\n\t\tgoto alloc_new_skb;\n\n\twhile (length > 0) {\n\t\t/* Check if the remaining data fits into current packet. */\n\t\tcopy = (cork->length <= mtu && !(cork->flags & IPCORK_ALLFRAG) ? mtu : maxfraglen) - skb->len;\n\t\tif (copy < length)\n\t\t\tcopy = maxfraglen - skb->len;\n\n\t\tif (copy <= 0) {\n\t\t\tchar *data;\n\t\t\tunsigned int datalen;\n\t\t\tunsigned int fraglen;\n\t\t\tunsigned int fraggap;\n\t\t\tunsigned int alloclen;\nalloc_new_skb:\n\t\t\t/* There's no room in the current skb */\n\t\t\tif (skb)\n\t\t\t\tfraggap = skb->len - maxfraglen;\n\t\t\telse\n\t\t\t\tfraggap = 0;\n\t\t\t/* update mtu and maxfraglen if necessary */\n\t\t\tif (skb == NULL || skb_prev == NULL)\n\t\t\t\tip6_append_data_mtu(&mtu, &maxfraglen,\n\t\t\t\t\t\t    fragheaderlen, skb, rt);\n\n\t\t\tskb_prev = skb;\n\n\t\t\t/*\n\t\t\t * If remaining data exceeds the mtu,\n\t\t\t * we know we need more fragment(s).\n\t\t\t */\n\t\t\tdatalen = length + fraggap;\n\n\t\t\tif (datalen > (cork->length <= mtu && !(cork->flags & IPCORK_ALLFRAG) ? mtu : maxfraglen) - fragheaderlen)\n\t\t\t\tdatalen = maxfraglen - fragheaderlen - rt->dst.trailer_len;\n\t\t\tif ((flags & MSG_MORE) &&\n\t\t\t    !(rt->dst.dev->features&NETIF_F_SG))\n\t\t\t\talloclen = mtu;\n\t\t\telse\n\t\t\t\talloclen = datalen + fragheaderlen;\n\n\t\t\talloclen += dst_exthdrlen;\n\n\t\t\tif (datalen != length + fraggap) {\n\t\t\t\t/*\n\t\t\t\t * this is not the last fragment, the trailer\n\t\t\t\t * space is regarded as data space.\n\t\t\t\t */\n\t\t\t\tdatalen += rt->dst.trailer_len;\n\t\t\t}\n\n\t\t\talloclen += rt->dst.trailer_len;\n\t\t\tfraglen = datalen + fragheaderlen;\n\n\t\t\t/*\n\t\t\t * We just reserve space for fragment header.\n\t\t\t * Note: this may be overallocation if the message\n\t\t\t * (without MSG_MORE) fits into the MTU.\n\t\t\t */\n\t\t\talloclen += sizeof(struct frag_hdr);\n\n\t\t\tif (transhdrlen) {\n\t\t\t\tskb = sock_alloc_send_skb(sk,\n\t\t\t\t\t\talloclen + hh_len,\n\t\t\t\t\t\t(flags & MSG_DONTWAIT), &err);\n\t\t\t} else {\n\t\t\t\tskb = NULL;\n\t\t\t\tif (atomic_read(&sk->sk_wmem_alloc) <=\n\t\t\t\t    2 * sk->sk_sndbuf)\n\t\t\t\t\tskb = sock_wmalloc(sk,\n\t\t\t\t\t\t\t   alloclen + hh_len, 1,\n\t\t\t\t\t\t\t   sk->sk_allocation);\n\t\t\t\tif (unlikely(skb == NULL))\n\t\t\t\t\terr = -ENOBUFS;\n\t\t\t\telse {\n\t\t\t\t\t/* Only the initial fragment\n\t\t\t\t\t * is time stamped.\n\t\t\t\t\t */\n\t\t\t\t\ttx_flags = 0;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (skb == NULL)\n\t\t\t\tgoto error;\n\t\t\t/*\n\t\t\t *\tFill in the control structures\n\t\t\t */\n\t\t\tskb->ip_summed = CHECKSUM_NONE;\n\t\t\tskb->csum = 0;\n\t\t\t/* reserve for fragmentation and ipsec header */\n\t\t\tskb_reserve(skb, hh_len + sizeof(struct frag_hdr) +\n\t\t\t\t    dst_exthdrlen);\n\n\t\t\tif (sk->sk_type == SOCK_DGRAM)\n\t\t\t\tskb_shinfo(skb)->tx_flags = tx_flags;\n\n\t\t\t/*\n\t\t\t *\tFind where to start putting bytes\n\t\t\t */\n\t\t\tdata = skb_put(skb, fraglen);\n\t\t\tskb_set_network_header(skb, exthdrlen);\n\t\t\tdata += fragheaderlen;\n\t\t\tskb->transport_header = (skb->network_header +\n\t\t\t\t\t\t fragheaderlen);\n\t\t\tif (fraggap) {\n\t\t\t\tskb->csum = skb_copy_and_csum_bits(\n\t\t\t\t\tskb_prev, maxfraglen,\n\t\t\t\t\tdata + transhdrlen, fraggap, 0);\n\t\t\t\tskb_prev->csum = csum_sub(skb_prev->csum,\n\t\t\t\t\t\t\t  skb->csum);\n\t\t\t\tdata += fraggap;\n\t\t\t\tpskb_trim_unique(skb_prev, maxfraglen);\n\t\t\t}\n\t\t\tcopy = datalen - transhdrlen - fraggap;\n\n\t\t\tif (copy < 0) {\n\t\t\t\terr = -EINVAL;\n\t\t\t\tkfree_skb(skb);\n\t\t\t\tgoto error;\n\t\t\t} else if (copy > 0 && getfrag(from, data + transhdrlen, offset, copy, fraggap, skb) < 0) {\n\t\t\t\terr = -EFAULT;\n\t\t\t\tkfree_skb(skb);\n\t\t\t\tgoto error;\n\t\t\t}\n\n\t\t\toffset += copy;\n\t\t\tlength -= datalen - fraggap;\n\t\t\ttranshdrlen = 0;\n\t\t\texthdrlen = 0;\n\t\t\tdst_exthdrlen = 0;\n\n\t\t\t/*\n\t\t\t * Put the packet on the pending queue\n\t\t\t */\n\t\t\t__skb_queue_tail(&sk->sk_write_queue, skb);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (copy > length)\n\t\t\tcopy = length;\n\n\t\tif (!(rt->dst.dev->features&NETIF_F_SG)) {\n\t\t\tunsigned int off;\n\n\t\t\toff = skb->len;\n\t\t\tif (getfrag(from, skb_put(skb, copy),\n\t\t\t\t\t\toffset, copy, off, skb) < 0) {\n\t\t\t\t__skb_trim(skb, off);\n\t\t\t\terr = -EFAULT;\n\t\t\t\tgoto error;\n\t\t\t}\n\t\t} else {\n\t\t\tint i = skb_shinfo(skb)->nr_frags;\n\t\t\tstruct page_frag *pfrag = sk_page_frag(sk);\n\n\t\t\terr = -ENOMEM;\n\t\t\tif (!sk_page_frag_refill(sk, pfrag))\n\t\t\t\tgoto error;\n\n\t\t\tif (!skb_can_coalesce(skb, i, pfrag->page,\n\t\t\t\t\t      pfrag->offset)) {\n\t\t\t\terr = -EMSGSIZE;\n\t\t\t\tif (i == MAX_SKB_FRAGS)\n\t\t\t\t\tgoto error;\n\n\t\t\t\t__skb_fill_page_desc(skb, i, pfrag->page,\n\t\t\t\t\t\t     pfrag->offset, 0);\n\t\t\t\tskb_shinfo(skb)->nr_frags = ++i;\n\t\t\t\tget_page(pfrag->page);\n\t\t\t}\n\t\t\tcopy = min_t(int, copy, pfrag->size - pfrag->offset);\n\t\t\tif (getfrag(from,\n\t\t\t\t    page_address(pfrag->page) + pfrag->offset,\n\t\t\t\t    offset, copy, skb->len, skb) < 0)\n\t\t\t\tgoto error_efault;\n\n\t\t\tpfrag->offset += copy;\n\t\t\tskb_frag_size_add(&skb_shinfo(skb)->frags[i - 1], copy);\n\t\t\tskb->len += copy;\n\t\t\tskb->data_len += copy;\n\t\t\tskb->truesize += copy;\n\t\t\tatomic_add(copy, &sk->sk_wmem_alloc);\n\t\t}\n\t\toffset += copy;\n\t\tlength -= copy;\n\t}\n\n\treturn 0;\n\nerror_efault:\n\terr = -EFAULT;\nerror:\n\tcork->length -= length;\n\tIP6_INC_STATS(sock_net(sk), rt->rt6i_idev, IPSTATS_MIB_OUTDISCARDS);\n\treturn err;\n}",
        "func": "int ip6_append_data(struct sock *sk, int getfrag(void *from, char *to,\n\tint offset, int len, int odd, struct sk_buff *skb),\n\tvoid *from, int length, int transhdrlen,\n\tint hlimit, int tclass, struct ipv6_txoptions *opt, struct flowi6 *fl6,\n\tstruct rt6_info *rt, unsigned int flags, int dontfrag)\n{\n\tstruct inet_sock *inet = inet_sk(sk);\n\tstruct ipv6_pinfo *np = inet6_sk(sk);\n\tstruct inet_cork *cork;\n\tstruct sk_buff *skb, *skb_prev = NULL;\n\tunsigned int maxfraglen, fragheaderlen, mtu;\n\tint exthdrlen;\n\tint dst_exthdrlen;\n\tint hh_len;\n\tint copy;\n\tint err;\n\tint offset = 0;\n\t__u8 tx_flags = 0;\n\n\tif (flags&MSG_PROBE)\n\t\treturn 0;\n\tcork = &inet->cork.base;\n\tif (skb_queue_empty(&sk->sk_write_queue)) {\n\t\t/*\n\t\t * setup for corking\n\t\t */\n\t\tif (opt) {\n\t\t\tif (WARN_ON(np->cork.opt))\n\t\t\t\treturn -EINVAL;\n\n\t\t\tnp->cork.opt = kzalloc(opt->tot_len, sk->sk_allocation);\n\t\t\tif (unlikely(np->cork.opt == NULL))\n\t\t\t\treturn -ENOBUFS;\n\n\t\t\tnp->cork.opt->tot_len = opt->tot_len;\n\t\t\tnp->cork.opt->opt_flen = opt->opt_flen;\n\t\t\tnp->cork.opt->opt_nflen = opt->opt_nflen;\n\n\t\t\tnp->cork.opt->dst0opt = ip6_opt_dup(opt->dst0opt,\n\t\t\t\t\t\t\t    sk->sk_allocation);\n\t\t\tif (opt->dst0opt && !np->cork.opt->dst0opt)\n\t\t\t\treturn -ENOBUFS;\n\n\t\t\tnp->cork.opt->dst1opt = ip6_opt_dup(opt->dst1opt,\n\t\t\t\t\t\t\t    sk->sk_allocation);\n\t\t\tif (opt->dst1opt && !np->cork.opt->dst1opt)\n\t\t\t\treturn -ENOBUFS;\n\n\t\t\tnp->cork.opt->hopopt = ip6_opt_dup(opt->hopopt,\n\t\t\t\t\t\t\t   sk->sk_allocation);\n\t\t\tif (opt->hopopt && !np->cork.opt->hopopt)\n\t\t\t\treturn -ENOBUFS;\n\n\t\t\tnp->cork.opt->srcrt = ip6_rthdr_dup(opt->srcrt,\n\t\t\t\t\t\t\t    sk->sk_allocation);\n\t\t\tif (opt->srcrt && !np->cork.opt->srcrt)\n\t\t\t\treturn -ENOBUFS;\n\n\t\t\t/* need source address above miyazawa*/\n\t\t}\n\t\tdst_hold(&rt->dst);\n\t\tcork->dst = &rt->dst;\n\t\tinet->cork.fl.u.ip6 = *fl6;\n\t\tnp->cork.hop_limit = hlimit;\n\t\tnp->cork.tclass = tclass;\n\t\tif (rt->dst.flags & DST_XFRM_TUNNEL)\n\t\t\tmtu = np->pmtudisc == IPV6_PMTUDISC_PROBE ?\n\t\t\t      rt->dst.dev->mtu : dst_mtu(&rt->dst);\n\t\telse\n\t\t\tmtu = np->pmtudisc == IPV6_PMTUDISC_PROBE ?\n\t\t\t      rt->dst.dev->mtu : dst_mtu(rt->dst.path);\n\t\tif (np->frag_size < mtu) {\n\t\t\tif (np->frag_size)\n\t\t\t\tmtu = np->frag_size;\n\t\t}\n\t\tcork->fragsize = mtu;\n\t\tif (dst_allfrag(rt->dst.path))\n\t\t\tcork->flags |= IPCORK_ALLFRAG;\n\t\tcork->length = 0;\n\t\texthdrlen = (opt ? opt->opt_flen : 0);\n\t\tlength += exthdrlen;\n\t\ttranshdrlen += exthdrlen;\n\t\tdst_exthdrlen = rt->dst.header_len - rt->rt6i_nfheader_len;\n\t} else {\n\t\trt = (struct rt6_info *)cork->dst;\n\t\tfl6 = &inet->cork.fl.u.ip6;\n\t\topt = np->cork.opt;\n\t\ttranshdrlen = 0;\n\t\texthdrlen = 0;\n\t\tdst_exthdrlen = 0;\n\t\tmtu = cork->fragsize;\n\t}\n\n\thh_len = LL_RESERVED_SPACE(rt->dst.dev);\n\n\tfragheaderlen = sizeof(struct ipv6hdr) + rt->rt6i_nfheader_len +\n\t\t\t(opt ? opt->opt_nflen : 0);\n\tmaxfraglen = ((mtu - fragheaderlen) & ~7) + fragheaderlen - sizeof(struct frag_hdr);\n\n\tif (mtu <= sizeof(struct ipv6hdr) + IPV6_MAXPLEN) {\n\t\tif (cork->length + length > sizeof(struct ipv6hdr) + IPV6_MAXPLEN - fragheaderlen) {\n\t\t\tipv6_local_error(sk, EMSGSIZE, fl6, mtu-exthdrlen);\n\t\t\treturn -EMSGSIZE;\n\t\t}\n\t}\n\n\t/* For UDP, check if TX timestamp is enabled */\n\tif (sk->sk_type == SOCK_DGRAM)\n\t\tsock_tx_timestamp(sk, &tx_flags);\n\n\t/*\n\t * Let's try using as much space as possible.\n\t * Use MTU if total length of the message fits into the MTU.\n\t * Otherwise, we need to reserve fragment header and\n\t * fragment alignment (= 8-15 octects, in total).\n\t *\n\t * Note that we may need to \"move\" the data from the tail of\n\t * of the buffer to the new fragment when we split\n\t * the message.\n\t *\n\t * FIXME: It may be fragmented into multiple chunks\n\t *        at once if non-fragmentable extension headers\n\t *        are too large.\n\t * --yoshfuji\n\t */\n\n\tcork->length += length;\n\tif (length > mtu) {\n\t\tint proto = sk->sk_protocol;\n\t\tif (dontfrag && (proto == IPPROTO_UDP || proto == IPPROTO_RAW)){\n\t\t\tipv6_local_rxpmtu(sk, fl6, mtu-exthdrlen);\n\t\t\treturn -EMSGSIZE;\n\t\t}\n\n\t\tif (proto == IPPROTO_UDP &&\n\t\t    (rt->dst.dev->features & NETIF_F_UFO)) {\n\n\t\t\terr = ip6_ufo_append_data(sk, getfrag, from, length,\n\t\t\t\t\t\t  hh_len, fragheaderlen,\n\t\t\t\t\t\t  transhdrlen, mtu, flags, rt);\n\t\t\tif (err)\n\t\t\t\tgoto error;\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\tif ((skb = skb_peek_tail(&sk->sk_write_queue)) == NULL)\n\t\tgoto alloc_new_skb;\n\n\twhile (length > 0) {\n\t\t/* Check if the remaining data fits into current packet. */\n\t\tcopy = (cork->length <= mtu && !(cork->flags & IPCORK_ALLFRAG) ? mtu : maxfraglen) - skb->len;\n\t\tif (copy < length)\n\t\t\tcopy = maxfraglen - skb->len;\n\n\t\tif (copy <= 0) {\n\t\t\tchar *data;\n\t\t\tunsigned int datalen;\n\t\t\tunsigned int fraglen;\n\t\t\tunsigned int fraggap;\n\t\t\tunsigned int alloclen;\nalloc_new_skb:\n\t\t\t/* There's no room in the current skb */\n\t\t\tif (skb)\n\t\t\t\tfraggap = skb->len - maxfraglen;\n\t\t\telse\n\t\t\t\tfraggap = 0;\n\t\t\t/* update mtu and maxfraglen if necessary */\n\t\t\tif (skb == NULL || skb_prev == NULL)\n\t\t\t\tip6_append_data_mtu(&mtu, &maxfraglen,\n\t\t\t\t\t\t    fragheaderlen, skb, rt,\n\t\t\t\t\t\t    np->pmtudisc ==\n\t\t\t\t\t\t    IPV6_PMTUDISC_PROBE);\n\n\t\t\tskb_prev = skb;\n\n\t\t\t/*\n\t\t\t * If remaining data exceeds the mtu,\n\t\t\t * we know we need more fragment(s).\n\t\t\t */\n\t\t\tdatalen = length + fraggap;\n\n\t\t\tif (datalen > (cork->length <= mtu && !(cork->flags & IPCORK_ALLFRAG) ? mtu : maxfraglen) - fragheaderlen)\n\t\t\t\tdatalen = maxfraglen - fragheaderlen - rt->dst.trailer_len;\n\t\t\tif ((flags & MSG_MORE) &&\n\t\t\t    !(rt->dst.dev->features&NETIF_F_SG))\n\t\t\t\talloclen = mtu;\n\t\t\telse\n\t\t\t\talloclen = datalen + fragheaderlen;\n\n\t\t\talloclen += dst_exthdrlen;\n\n\t\t\tif (datalen != length + fraggap) {\n\t\t\t\t/*\n\t\t\t\t * this is not the last fragment, the trailer\n\t\t\t\t * space is regarded as data space.\n\t\t\t\t */\n\t\t\t\tdatalen += rt->dst.trailer_len;\n\t\t\t}\n\n\t\t\talloclen += rt->dst.trailer_len;\n\t\t\tfraglen = datalen + fragheaderlen;\n\n\t\t\t/*\n\t\t\t * We just reserve space for fragment header.\n\t\t\t * Note: this may be overallocation if the message\n\t\t\t * (without MSG_MORE) fits into the MTU.\n\t\t\t */\n\t\t\talloclen += sizeof(struct frag_hdr);\n\n\t\t\tif (transhdrlen) {\n\t\t\t\tskb = sock_alloc_send_skb(sk,\n\t\t\t\t\t\talloclen + hh_len,\n\t\t\t\t\t\t(flags & MSG_DONTWAIT), &err);\n\t\t\t} else {\n\t\t\t\tskb = NULL;\n\t\t\t\tif (atomic_read(&sk->sk_wmem_alloc) <=\n\t\t\t\t    2 * sk->sk_sndbuf)\n\t\t\t\t\tskb = sock_wmalloc(sk,\n\t\t\t\t\t\t\t   alloclen + hh_len, 1,\n\t\t\t\t\t\t\t   sk->sk_allocation);\n\t\t\t\tif (unlikely(skb == NULL))\n\t\t\t\t\terr = -ENOBUFS;\n\t\t\t\telse {\n\t\t\t\t\t/* Only the initial fragment\n\t\t\t\t\t * is time stamped.\n\t\t\t\t\t */\n\t\t\t\t\ttx_flags = 0;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (skb == NULL)\n\t\t\t\tgoto error;\n\t\t\t/*\n\t\t\t *\tFill in the control structures\n\t\t\t */\n\t\t\tskb->ip_summed = CHECKSUM_NONE;\n\t\t\tskb->csum = 0;\n\t\t\t/* reserve for fragmentation and ipsec header */\n\t\t\tskb_reserve(skb, hh_len + sizeof(struct frag_hdr) +\n\t\t\t\t    dst_exthdrlen);\n\n\t\t\tif (sk->sk_type == SOCK_DGRAM)\n\t\t\t\tskb_shinfo(skb)->tx_flags = tx_flags;\n\n\t\t\t/*\n\t\t\t *\tFind where to start putting bytes\n\t\t\t */\n\t\t\tdata = skb_put(skb, fraglen);\n\t\t\tskb_set_network_header(skb, exthdrlen);\n\t\t\tdata += fragheaderlen;\n\t\t\tskb->transport_header = (skb->network_header +\n\t\t\t\t\t\t fragheaderlen);\n\t\t\tif (fraggap) {\n\t\t\t\tskb->csum = skb_copy_and_csum_bits(\n\t\t\t\t\tskb_prev, maxfraglen,\n\t\t\t\t\tdata + transhdrlen, fraggap, 0);\n\t\t\t\tskb_prev->csum = csum_sub(skb_prev->csum,\n\t\t\t\t\t\t\t  skb->csum);\n\t\t\t\tdata += fraggap;\n\t\t\t\tpskb_trim_unique(skb_prev, maxfraglen);\n\t\t\t}\n\t\t\tcopy = datalen - transhdrlen - fraggap;\n\n\t\t\tif (copy < 0) {\n\t\t\t\terr = -EINVAL;\n\t\t\t\tkfree_skb(skb);\n\t\t\t\tgoto error;\n\t\t\t} else if (copy > 0 && getfrag(from, data + transhdrlen, offset, copy, fraggap, skb) < 0) {\n\t\t\t\terr = -EFAULT;\n\t\t\t\tkfree_skb(skb);\n\t\t\t\tgoto error;\n\t\t\t}\n\n\t\t\toffset += copy;\n\t\t\tlength -= datalen - fraggap;\n\t\t\ttranshdrlen = 0;\n\t\t\texthdrlen = 0;\n\t\t\tdst_exthdrlen = 0;\n\n\t\t\t/*\n\t\t\t * Put the packet on the pending queue\n\t\t\t */\n\t\t\t__skb_queue_tail(&sk->sk_write_queue, skb);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (copy > length)\n\t\t\tcopy = length;\n\n\t\tif (!(rt->dst.dev->features&NETIF_F_SG)) {\n\t\t\tunsigned int off;\n\n\t\t\toff = skb->len;\n\t\t\tif (getfrag(from, skb_put(skb, copy),\n\t\t\t\t\t\toffset, copy, off, skb) < 0) {\n\t\t\t\t__skb_trim(skb, off);\n\t\t\t\terr = -EFAULT;\n\t\t\t\tgoto error;\n\t\t\t}\n\t\t} else {\n\t\t\tint i = skb_shinfo(skb)->nr_frags;\n\t\t\tstruct page_frag *pfrag = sk_page_frag(sk);\n\n\t\t\terr = -ENOMEM;\n\t\t\tif (!sk_page_frag_refill(sk, pfrag))\n\t\t\t\tgoto error;\n\n\t\t\tif (!skb_can_coalesce(skb, i, pfrag->page,\n\t\t\t\t\t      pfrag->offset)) {\n\t\t\t\terr = -EMSGSIZE;\n\t\t\t\tif (i == MAX_SKB_FRAGS)\n\t\t\t\t\tgoto error;\n\n\t\t\t\t__skb_fill_page_desc(skb, i, pfrag->page,\n\t\t\t\t\t\t     pfrag->offset, 0);\n\t\t\t\tskb_shinfo(skb)->nr_frags = ++i;\n\t\t\t\tget_page(pfrag->page);\n\t\t\t}\n\t\t\tcopy = min_t(int, copy, pfrag->size - pfrag->offset);\n\t\t\tif (getfrag(from,\n\t\t\t\t    page_address(pfrag->page) + pfrag->offset,\n\t\t\t\t    offset, copy, skb->len, skb) < 0)\n\t\t\t\tgoto error_efault;\n\n\t\t\tpfrag->offset += copy;\n\t\t\tskb_frag_size_add(&skb_shinfo(skb)->frags[i - 1], copy);\n\t\t\tskb->len += copy;\n\t\t\tskb->data_len += copy;\n\t\t\tskb->truesize += copy;\n\t\t\tatomic_add(copy, &sk->sk_wmem_alloc);\n\t\t}\n\t\toffset += copy;\n\t\tlength -= copy;\n\t}\n\n\treturn 0;\n\nerror_efault:\n\terr = -EFAULT;\nerror:\n\tcork->length -= length;\n\tIP6_INC_STATS(sock_net(sk), rt->rt6i_idev, IPSTATS_MIB_OUTDISCARDS);\n\treturn err;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -8,11 +8,10 @@\n \tstruct ipv6_pinfo *np = inet6_sk(sk);\n \tstruct inet_cork *cork;\n \tstruct sk_buff *skb, *skb_prev = NULL;\n-\tunsigned int maxfraglen, fragheaderlen;\n+\tunsigned int maxfraglen, fragheaderlen, mtu;\n \tint exthdrlen;\n \tint dst_exthdrlen;\n \tint hh_len;\n-\tint mtu;\n \tint copy;\n \tint err;\n \tint offset = 0;\n@@ -169,7 +168,9 @@\n \t\t\t/* update mtu and maxfraglen if necessary */\n \t\t\tif (skb == NULL || skb_prev == NULL)\n \t\t\t\tip6_append_data_mtu(&mtu, &maxfraglen,\n-\t\t\t\t\t\t    fragheaderlen, skb, rt);\n+\t\t\t\t\t\t    fragheaderlen, skb, rt,\n+\t\t\t\t\t\t    np->pmtudisc ==\n+\t\t\t\t\t\t    IPV6_PMTUDISC_PROBE);\n \n \t\t\tskb_prev = skb;\n ",
        "diff_line_info": {
            "deleted_lines": [
                "\tunsigned int maxfraglen, fragheaderlen;",
                "\tint mtu;",
                "\t\t\t\t\t\t    fragheaderlen, skb, rt);"
            ],
            "added_lines": [
                "\tunsigned int maxfraglen, fragheaderlen, mtu;",
                "\t\t\t\t\t\t    fragheaderlen, skb, rt,",
                "\t\t\t\t\t\t    np->pmtudisc ==",
                "\t\t\t\t\t\t    IPV6_PMTUDISC_PROBE);"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-4163",
        "func_name": "torvalds/linux/ip6_append_data_mtu",
        "description": "The ip6_append_data_mtu function in net/ipv6/ip6_output.c in the IPv6 implementation in the Linux kernel through 3.10.3 does not properly maintain information about whether the IPV6_MTU setsockopt option had been specified, which allows local users to cause a denial of service (BUG and system crash) via a crafted application that uses the UDP_CORK option in a setsockopt system call.",
        "git_url": "https://github.com/torvalds/linux/commit/75a493e60ac4bbe2e977e7129d6d8cbb0dd236be",
        "commit_title": "ipv6: ip6_append_data_mtu did not care about pmtudisc and frag_size",
        "commit_text": " If the socket had an IPV6_MTU value set, ip6_append_data_mtu lost track of this when appending the second frame on a corked socket. This results in the following splat:  [37598.993962] ------------[ cut here ]------------ [37598.994008] kernel BUG at net/core/skbuff.c:2064! [37598.994008] invalid opcode: 0000 [#1] SMP [37598.994008] Modules linked in: tcp_lp uvcvideo videobuf2_vmalloc videobuf2_memops videobuf2_core videodev media vfat fat usb_storage fuse ebtable_nat xt_CHECKSUM bridge stp llc ipt_MASQUERADE nf_conntrack_netbios_ns nf_conntrack_broadcast ip6table_mangle ip6t_REJECT nf_conntrack_ipv6 nf_defrag_ipv6 iptable_nat +nf_nat_ipv4 nf_nat iptable_mangle nf_conntrack_ipv4 nf_defrag_ipv4 xt_conntrack nf_conntrack ebtable_filter ebtables ip6table_filter ip6_tables be2iscsi iscsi_boot_sysfs bnx2i cnic uio cxgb4i cxgb4 cxgb3i cxgb3 mdio libcxgbi ib_iser rdma_cm ib_addr iw_cm ib_cm ib_sa ib_mad ib_core iscsi_tcp libiscsi_tcp libiscsi +scsi_transport_iscsi rfcomm bnep iTCO_wdt iTCO_vendor_support snd_hda_codec_conexant arc4 iwldvm mac80211 snd_hda_intel acpi_cpufreq mperf coretemp snd_hda_codec microcode cdc_wdm cdc_acm [37598.994008]  snd_hwdep cdc_ether snd_seq snd_seq_device usbnet mii joydev btusb snd_pcm bluetooth i2c_i801 e1000e lpc_ich mfd_core ptp iwlwifi pps_core snd_page_alloc mei cfg80211 snd_timer thinkpad_acpi snd tpm_tis soundcore rfkill tpm tpm_bios vhost_net tun macvtap macvlan kvm_intel kvm uinput binfmt_misc +dm_crypt i915 i2c_algo_bit drm_kms_helper drm i2c_core wmi video [37598.994008] CPU 0 [37598.994008] Pid: 27320, comm: t2 Not tainted 3.9.6-200.fc18.x86_64 #1 LENOVO 27744PG/27744PG [37598.994008] RIP: 0010:[<ffffffff815443a5>]  [<ffffffff815443a5>] skb_copy_and_csum_bits+0x325/0x330 [37598.994008] RSP: 0018:ffff88003670da18  EFLAGS: 00010202 [37598.994008] RAX: ffff88018105c018 RBX: 0000000000000004 RCX: 00000000000006c0 [37598.994008] RDX: ffff88018105a6c0 RSI: ffff88018105a000 RDI: ffff8801e1b0aa00 [37598.994008] RBP: ffff88003670da78 R08: 0000000000000000 R09: ffff88018105c040 [37598.994008] R10: ffff8801e1b0aa00 R11: 0000000000000000 R12: 000000000000fff8 [37598.994008] R13: 00000000000004fc R14: 00000000ffff0504 R15: 0000000000000000 [37598.994008] FS:  00007f28eea59740(0000) GS:ffff88023bc00000(0000) knlGS:0000000000000000 [37598.994008] CS:  0010 DS: 0000 ES: 0000 CR0: 000000008005003b [37598.994008] CR2: 0000003d935789e0 CR3: 00000000365cb000 CR4: 00000000000407f0 [37598.994008] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000 [37598.994008] DR3: 0000000000000000 DR6: 00000000ffff0ff0 DR7: 0000000000000400 [37598.994008] Process t2 (pid: 27320, threadinfo ffff88003670c000, task ffff88022c162ee0) [37598.994008] Stack: [37598.994008]  ffff88022e098a00 ffff88020f973fc0 0000000000000008 00000000000004c8 [37598.994008]  ffff88020f973fc0 00000000000004c4 ffff88003670da78 ffff8801e1b0a200 [37598.994008]  0000000000000018 00000000000004c8 ffff88020f973fc0 00000000000004c4 [37598.994008] Call Trace: [37598.994008]  [<ffffffff815fc21f>] ip6_append_data+0xccf/0xfe0 [37598.994008]  [<ffffffff8158d9f0>] ? ip_copy_metadata+0x1a0/0x1a0 [37598.994008]  [<ffffffff81661f66>] ? _raw_spin_lock_bh+0x16/0x40 [37598.994008]  [<ffffffff8161548d>] udpv6_sendmsg+0x1ed/0xc10 [37598.994008]  [<ffffffff812a2845>] ? sock_has_perm+0x75/0x90 [37598.994008]  [<ffffffff815c3693>] inet_sendmsg+0x63/0xb0 [37598.994008]  [<ffffffff812a2973>] ? selinux_socket_sendmsg+0x23/0x30 [37598.994008]  [<ffffffff8153a450>] sock_sendmsg+0xb0/0xe0 [37598.994008]  [<ffffffff810135d1>] ? __switch_to+0x181/0x4a0 [37598.994008]  [<ffffffff8153d97d>] sys_sendto+0x12d/0x180 [37598.994008]  [<ffffffff810dfb64>] ? __audit_syscall_entry+0x94/0xf0 [37598.994008]  [<ffffffff81020ed1>] ? syscall_trace_enter+0x231/0x240 [37598.994008]  [<ffffffff8166a7e7>] tracesys+0xdd/0xe2 [37598.994008] Code: fe 07 00 00 48 c7 c7 04 28 a6 81 89 45 a0 4c 89 4d b8 44 89 5d a8 e8 1b ac b1 ff 44 8b 5d a8 4c 8b 4d b8 8b 45 a0 e9 cf fe ff ff <0f> 0b 66 0f 1f 84 00 00 00 00 00 66 66 66 66 90 55 48 89 e5 48 [37598.994008] RIP  [<ffffffff815443a5>] skb_copy_and_csum_bits+0x325/0x330 [37598.994008]  RSP <ffff88003670da18> [37599.007323] ---[ end trace d69f6a17f8ac8eee ]---  While there, also check if path mtu discovery is activated for this socket. The logic was adapted from ip6_append_data when first writing on the corked socket.  This bug was introduced with commit 0c1833797a5a6ec23ea9261d979aa18078720b74 (\"ipv6: fix incorrect ipsec fragment\").  v2: a) Replace IPV6_PMTU_DISC_DO with IPV6_PMTUDISC_PROBE. b) Don't pass ipv6_pinfo to ip6_append_data_mtu (suggestion by Gao    feng, thanks!). c) Change mtu to unsigned int, else we get a warning about    non-matching types because of the min()-macro type-check.  Cc: YOSHIFUJI Hideaki <yoshfuji@linux-ipv6.org>",
        "func_before": "static void ip6_append_data_mtu(int *mtu,\n\t\t\t\tint *maxfraglen,\n\t\t\t\tunsigned int fragheaderlen,\n\t\t\t\tstruct sk_buff *skb,\n\t\t\t\tstruct rt6_info *rt)\n{\n\tif (!(rt->dst.flags & DST_XFRM_TUNNEL)) {\n\t\tif (skb == NULL) {\n\t\t\t/* first fragment, reserve header_len */\n\t\t\t*mtu = *mtu - rt->dst.header_len;\n\n\t\t} else {\n\t\t\t/*\n\t\t\t * this fragment is not first, the headers\n\t\t\t * space is regarded as data space.\n\t\t\t */\n\t\t\t*mtu = dst_mtu(rt->dst.path);\n\t\t}\n\t\t*maxfraglen = ((*mtu - fragheaderlen) & ~7)\n\t\t\t      + fragheaderlen - sizeof(struct frag_hdr);\n\t}\n}",
        "func": "static void ip6_append_data_mtu(unsigned int *mtu,\n\t\t\t\tint *maxfraglen,\n\t\t\t\tunsigned int fragheaderlen,\n\t\t\t\tstruct sk_buff *skb,\n\t\t\t\tstruct rt6_info *rt,\n\t\t\t\tbool pmtuprobe)\n{\n\tif (!(rt->dst.flags & DST_XFRM_TUNNEL)) {\n\t\tif (skb == NULL) {\n\t\t\t/* first fragment, reserve header_len */\n\t\t\t*mtu = *mtu - rt->dst.header_len;\n\n\t\t} else {\n\t\t\t/*\n\t\t\t * this fragment is not first, the headers\n\t\t\t * space is regarded as data space.\n\t\t\t */\n\t\t\t*mtu = min(*mtu, pmtuprobe ?\n\t\t\t\t   rt->dst.dev->mtu :\n\t\t\t\t   dst_mtu(rt->dst.path));\n\t\t}\n\t\t*maxfraglen = ((*mtu - fragheaderlen) & ~7)\n\t\t\t      + fragheaderlen - sizeof(struct frag_hdr);\n\t}\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,8 +1,9 @@\n-static void ip6_append_data_mtu(int *mtu,\n+static void ip6_append_data_mtu(unsigned int *mtu,\n \t\t\t\tint *maxfraglen,\n \t\t\t\tunsigned int fragheaderlen,\n \t\t\t\tstruct sk_buff *skb,\n-\t\t\t\tstruct rt6_info *rt)\n+\t\t\t\tstruct rt6_info *rt,\n+\t\t\t\tbool pmtuprobe)\n {\n \tif (!(rt->dst.flags & DST_XFRM_TUNNEL)) {\n \t\tif (skb == NULL) {\n@@ -14,7 +15,9 @@\n \t\t\t * this fragment is not first, the headers\n \t\t\t * space is regarded as data space.\n \t\t\t */\n-\t\t\t*mtu = dst_mtu(rt->dst.path);\n+\t\t\t*mtu = min(*mtu, pmtuprobe ?\n+\t\t\t\t   rt->dst.dev->mtu :\n+\t\t\t\t   dst_mtu(rt->dst.path));\n \t\t}\n \t\t*maxfraglen = ((*mtu - fragheaderlen) & ~7)\n \t\t\t      + fragheaderlen - sizeof(struct frag_hdr);",
        "diff_line_info": {
            "deleted_lines": [
                "static void ip6_append_data_mtu(int *mtu,",
                "\t\t\t\tstruct rt6_info *rt)",
                "\t\t\t*mtu = dst_mtu(rt->dst.path);"
            ],
            "added_lines": [
                "static void ip6_append_data_mtu(unsigned int *mtu,",
                "\t\t\t\tstruct rt6_info *rt,",
                "\t\t\t\tbool pmtuprobe)",
                "\t\t\t*mtu = min(*mtu, pmtuprobe ?",
                "\t\t\t\t   rt->dst.dev->mtu :",
                "\t\t\t\t   dst_mtu(rt->dst.path));"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-2883",
        "func_name": "chromium/Node::unregisterMutationObserver",
        "description": "Use-after-free vulnerability in Google Chrome before 28.0.1500.95 allows remote attackers to cause a denial of service or possibly have unspecified other impact via vectors related to deleting the registration of a MutationObserver object.",
        "git_url": "https://github.com/chromium/chromium/commit/afea522e2f80f56fed7e54bd3d2070da358f42f2",
        "commit_title": "Fix crash due to unexpected Node deletion during MutationObserver registration book-keeping",
        "commit_text": "  ",
        "func_before": "void Node::unregisterMutationObserver(MutationObserverRegistration* registration)\n{\n    Vector<OwnPtr<MutationObserverRegistration> >* registry = mutationObserverRegistry();\n    ASSERT(registry);\n    if (!registry)\n        return;\n\n    size_t index = registry->find(registration);\n    ASSERT(index != notFound);\n    if (index == notFound)\n        return;\n\n    registry->remove(index);\n}",
        "func": "void Node::unregisterMutationObserver(MutationObserverRegistration* registration)\n{\n    Vector<OwnPtr<MutationObserverRegistration> >* registry = mutationObserverRegistry();\n    ASSERT(registry);\n    if (!registry)\n        return;\n\n    size_t index = registry->find(registration);\n    ASSERT(index != notFound);\n    if (index == notFound)\n        return;\n\n    // Deleting the registration may cause this node to be derefed, so we must make sure the Vector operation completes\n    // before that, in case |this| is destroyed (see MutationObserverRegistration::m_registrationNodeKeepAlive).\n    // FIXME: Simplify the registration/transient registration logic to make this understandable by humans.\n    RefPtr<Node> protect(this);\n    registry->remove(index);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -10,5 +10,9 @@\n     if (index == notFound)\n         return;\n \n+    // Deleting the registration may cause this node to be derefed, so we must make sure the Vector operation completes\n+    // before that, in case |this| is destroyed (see MutationObserverRegistration::m_registrationNodeKeepAlive).\n+    // FIXME: Simplify the registration/transient registration logic to make this understandable by humans.\n+    RefPtr<Node> protect(this);\n     registry->remove(index);\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    // Deleting the registration may cause this node to be derefed, so we must make sure the Vector operation completes",
                "    // before that, in case |this| is destroyed (see MutationObserverRegistration::m_registrationNodeKeepAlive).",
                "    // FIXME: Simplify the registration/transient registration logic to make this understandable by humans.",
                "    RefPtr<Node> protect(this);"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-2884",
        "func_name": "chromium/Element::setAttributeNode",
        "description": "Use-after-free vulnerability in the DOM implementation in Google Chrome before 28.0.1500.95 allows remote attackers to cause a denial of service or possibly have unspecified other impact via vectors related to improper tracking of which document owns an Attr object.",
        "git_url": "https://github.com/chromium/chromium/commit/4ac8bc08e3306f38a5ab3e551aef6ad43753579c",
        "commit_title": "Set Attr.ownerDocument in Element#setAttributeNode()",
        "commit_text": " Attr objects can move across documents by setAttributeNode(). So It needs to reset ownerDocument through TreeScopeAdoptr::adoptIfNeeded().   ",
        "func_before": "PassRefPtr<Attr> Element::setAttributeNode(Attr* attrNode, ExceptionCode& ec)\n{\n    if (!attrNode) {\n        ec = TYPE_MISMATCH_ERR;\n        return 0;\n    }\n\n    RefPtr<Attr> oldAttrNode = attrIfExists(attrNode->qualifiedName());\n    if (oldAttrNode.get() == attrNode)\n        return attrNode; // This Attr is already attached to the element.\n\n    // INUSE_ATTRIBUTE_ERR: Raised if node is an Attr that is already an attribute of another Element object.\n    // The DOM user must explicitly clone Attr nodes to re-use them in other elements.\n    if (attrNode->ownerElement()) {\n        ec = INUSE_ATTRIBUTE_ERR;\n        return 0;\n    }\n\n    synchronizeAllAttributes();\n    UniqueElementData* elementData = ensureUniqueElementData();\n\n    size_t index = elementData->getAttributeItemIndex(attrNode->qualifiedName());\n    if (index != notFound) {\n        if (oldAttrNode)\n            detachAttrNodeFromElementWithValue(oldAttrNode.get(), elementData->attributeItem(index)->value());\n        else\n            oldAttrNode = Attr::create(document(), attrNode->qualifiedName(), elementData->attributeItem(index)->value());\n    }\n\n    setAttributeInternal(index, attrNode->qualifiedName(), attrNode->value(), NotInSynchronizationOfLazyAttribute);\n\n    attrNode->attachToElement(this);\n    ensureAttrNodeListForElement(this)->append(attrNode);\n\n    return oldAttrNode.release();\n}",
        "func": "PassRefPtr<Attr> Element::setAttributeNode(Attr* attrNode, ExceptionCode& ec)\n{\n    if (!attrNode) {\n        ec = TYPE_MISMATCH_ERR;\n        return 0;\n    }\n\n    RefPtr<Attr> oldAttrNode = attrIfExists(attrNode->qualifiedName());\n    if (oldAttrNode.get() == attrNode)\n        return attrNode; // This Attr is already attached to the element.\n\n    // INUSE_ATTRIBUTE_ERR: Raised if node is an Attr that is already an attribute of another Element object.\n    // The DOM user must explicitly clone Attr nodes to re-use them in other elements.\n    if (attrNode->ownerElement()) {\n        ec = INUSE_ATTRIBUTE_ERR;\n        return 0;\n    }\n\n    synchronizeAllAttributes();\n    UniqueElementData* elementData = ensureUniqueElementData();\n\n    size_t index = elementData->getAttributeItemIndex(attrNode->qualifiedName());\n    if (index != notFound) {\n        if (oldAttrNode)\n            detachAttrNodeFromElementWithValue(oldAttrNode.get(), elementData->attributeItem(index)->value());\n        else\n            oldAttrNode = Attr::create(document(), attrNode->qualifiedName(), elementData->attributeItem(index)->value());\n    }\n\n    setAttributeInternal(index, attrNode->qualifiedName(), attrNode->value(), NotInSynchronizationOfLazyAttribute);\n\n    attrNode->attachToElement(this);\n    treeScope()->adoptIfNeeded(attrNode);\n    ensureAttrNodeListForElement(this)->append(attrNode);\n\n    return oldAttrNode.release();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -30,6 +30,7 @@\n     setAttributeInternal(index, attrNode->qualifiedName(), attrNode->value(), NotInSynchronizationOfLazyAttribute);\n \n     attrNode->attachToElement(this);\n+    treeScope()->adoptIfNeeded(attrNode);\n     ensureAttrNodeListForElement(this)->append(attrNode);\n \n     return oldAttrNode.release();",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    treeScope()->adoptIfNeeded(attrNode);"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-2126",
        "func_name": "LibRaw/LibRaw::unpack",
        "description": "Multiple double free vulnerabilities in the LibRaw::unpack function in libraw_cxx.cpp in LibRaw before 0.15.2 allow context-dependent attackers to cause a denial of service (application crash) and possibly execute arbitrary code via a malformed full-color (1) Foveon or (2) sRAW image file.",
        "git_url": "https://github.com/LibRaw/LibRaw/commit/19ffddb0fe1a4ffdb459b797ffcf7f490d28b5a6",
        "commit_title": "prevent double-free() on broken full-color images error handling",
        "commit_text": "",
        "func_before": "int LibRaw::unpack(void)\n{\n    CHECK_ORDER_HIGH(LIBRAW_PROGRESS_LOAD_RAW);\n    CHECK_ORDER_LOW(LIBRAW_PROGRESS_IDENTIFY);\n    try {\n\n\t\tif(!libraw_internal_data.internal_data.input)\n\t\t\treturn LIBRAW_INPUT_CLOSED;\n\n        RUN_CALLBACK(LIBRAW_PROGRESS_LOAD_RAW,0,2);\n        if (O.shot_select >= P1.raw_count)\n            return LIBRAW_REQUEST_FOR_NONEXISTENT_IMAGE;\n        \n        if(!load_raw)\n            return LIBRAW_UNSPECIFIED_ERROR;\n        \n        if (O.use_camera_matrix && C.cmatrix[0][0] > 0.25) \n            {\n                memcpy (C.rgb_cam, C.cmatrix, sizeof (C.cmatrix));\n                IO.raw_color = 0;\n            }\n        // already allocated ?\n        if(imgdata.image)\n            {\n                free(imgdata.image);\n                imgdata.image = 0;\n            }\n        if(imgdata.rawdata.raw_alloc)\n          {\n            free(imgdata.rawdata.raw_alloc);\n            imgdata.rawdata.raw_alloc = 0;\n          }\n        if (libraw_internal_data.unpacker_data.meta_length) \n            {\n                libraw_internal_data.internal_data.meta_data = \n                    (char *) malloc (libraw_internal_data.unpacker_data.meta_length);\n                merror (libraw_internal_data.internal_data.meta_data, \"LibRaw::unpack()\");\n            }\n\n        libraw_decoder_info_t decoder_info;\n        get_decoder_info(&decoder_info);\n\n        int save_iwidth = S.iwidth, save_iheight = S.iheight, save_shrink = IO.shrink;\n\n        int rwidth = S.raw_width, rheight = S.raw_height;\n        if( !IO.fuji_width)\n            {\n                // adjust non-Fuji allocation\n                if(rwidth < S.width + S.left_margin)\n                    rwidth = S.width + S.left_margin;\n                if(rheight < S.height + S.top_margin)\n                    rheight = S.height + S.top_margin;\n            }\n        S.raw_pitch = S.raw_width*2;\n        imgdata.rawdata.raw_image = 0;\n        imgdata.rawdata.color4_image = 0;\n\timgdata.rawdata.color3_image = 0;\n#ifdef USE_RAWSPEED\n        // RawSpeed Supported, \n        if(O.use_rawspeed && (decoder_info.decoder_flags & LIBRAW_DECODER_TRYRAWSPEED) && _rawspeed_camerameta)\n          {\n            INT64 spos = ID.input->tell();\n            try \n              {\n                //                printf(\"Using rawspeed\\n\");\n                ID.input->seek(0,SEEK_SET);\n                INT64 _rawspeed_buffer_sz = ID.input->size()+32;\n                void *_rawspeed_buffer = malloc(_rawspeed_buffer_sz);\n                if(!_rawspeed_buffer) throw LIBRAW_EXCEPTION_ALLOC;\n                ID.input->read(_rawspeed_buffer,_rawspeed_buffer_sz,1);\n                FileMap map((uchar8*)_rawspeed_buffer,_rawspeed_buffer_sz);\n                RawParser t(&map);\n                RawDecoder *d = 0;\n                CameraMetaDataLR *meta = static_cast<CameraMetaDataLR*>(_rawspeed_camerameta);\n                d = t.getDecoder();\n                try {\n                  d->checkSupport(meta);\n                }\n                catch (const RawDecoderException& e)\n                  {\n                    imgdata.process_warnings |= LIBRAW_WARN_RAWSPEED_UNSUPPORTED;\n                    throw e;\n                  }\n                d->decodeRaw();\n                d->decodeMetaData(meta);\n                RawImage r = d->mRaw;\n                if (r->isCFA) {\n                  // Save pointer to decoder\n                  _rawspeed_decoder = static_cast<void*>(d);\n                  imgdata.rawdata.raw_image = (ushort*) r->getDataUncropped(0,0);\n                  S.raw_pitch = r->pitch;\n                  fix_after_rawspeed(r->blackLevel);\n                } else if(r->getCpp()==4) {\n                  _rawspeed_decoder = static_cast<void*>(d);\n                  imgdata.rawdata.color4_image = (ushort(*)[4]) r->getDataUncropped(0,0);\n                  S.raw_pitch = r->pitch;\n                  C.maximum = r->whitePoint;\n                  fix_after_rawspeed(r->blackLevel);\n                } else if(r->getCpp() == 3)\n                  {\n                    _rawspeed_decoder = static_cast<void*>(d);\n                    imgdata.rawdata.color3_image = (ushort(*)[3]) r->getDataUncropped(0,0);\n                    S.raw_pitch = r->pitch;\n                    C.maximum = r->whitePoint;\n                    fix_after_rawspeed(r->blackLevel);\n                  }\n                else\n                  {\n                    delete d;\n                  }\n                free(_rawspeed_buffer);\n              imgdata.process_warnings |= LIBRAW_WARN_RAWSPEED_PROCESSED;\n              } catch (...) {\n              imgdata.process_warnings |= LIBRAW_WARN_RAWSPEED_PROBLEM;\n              // no other actions: if raw_image is not set we'll try usual load_raw call\n            }\n            ID.input->seek(spos,SEEK_SET);\n          }\n#endif\n        if(!imgdata.rawdata.raw_image && !imgdata.rawdata.color4_image && !imgdata.rawdata.color3_image) // RawSpeed failed!\n          {\n            // Not allocated on RawSpeed call, try call LibRaw\n            if(decoder_info.decoder_flags &  LIBRAW_DECODER_FLATFIELD)\n              {\n                imgdata.rawdata.raw_alloc = malloc(rwidth*(rheight+7)*sizeof(imgdata.rawdata.raw_image[0]));\n                imgdata.rawdata.raw_image = (ushort*) imgdata.rawdata.raw_alloc;\n              }\n            else if (decoder_info.decoder_flags & LIBRAW_DECODER_LEGACY)\n              {\n                // sRAW and Foveon only, so extra buffer size is just 1/4\n                // Legacy converters does not supports half mode!\n                S.iwidth = S.width;\n                S.iheight= S.height;\n                IO.shrink = 0;\n\t\t\t\tS.raw_pitch = S.width*8;\n                // allocate image as temporary buffer, size \n                imgdata.rawdata.raw_alloc = calloc(S.iwidth*S.iheight,sizeof(*imgdata.image));\n                imgdata.image = (ushort (*)[4]) imgdata.rawdata.raw_alloc;\n              }\n            ID.input->seek(libraw_internal_data.unpacker_data.data_offset, SEEK_SET);\n\n\t\t\tunsigned m_save = C.maximum;\n\t\t\tif(load_raw == &LibRaw::unpacked_load_raw && !strcasecmp(imgdata.idata.make,\"Nikon\"))\n\t\t\t\tC.maximum=65535;\n            (this->*load_raw)();\n\t\t\tif(load_raw == &LibRaw::unpacked_load_raw && !strcasecmp(imgdata.idata.make,\"Nikon\"))\n\t\t\t\tC.maximum = m_save;\n          }\n\n        if(imgdata.rawdata.raw_image)\n          crop_masked_pixels(); // calculate black levels\n\n        // recover saved\n        if( (decoder_info.decoder_flags & LIBRAW_DECODER_LEGACY) && !imgdata.rawdata.color4_image)\n            {\n                imgdata.image = 0; \n                imgdata.rawdata.color4_image = (ushort (*)[4]) imgdata.rawdata.raw_alloc;\n            }\n\n        // recover image sizes\n        S.iwidth = save_iwidth;\n        S.iheight = save_iheight;\n        IO.shrink = save_shrink;\n\n        // adjust black to possible maximum\n        unsigned int i = C.cblack[3];\n        unsigned int c;\n        for(c=0;c<3;c++)\n            if (i > C.cblack[c]) i = C.cblack[c];\n        for (c=0;c<4;c++)\n            C.cblack[c] -= i;\n        C.black += i;\n\n        // Save color,sizes and internal data into raw_image fields\n        memmove(&imgdata.rawdata.color,&imgdata.color,sizeof(imgdata.color));\n        memmove(&imgdata.rawdata.sizes,&imgdata.sizes,sizeof(imgdata.sizes));\n        memmove(&imgdata.rawdata.iparams,&imgdata.idata,sizeof(imgdata.idata));\n        memmove(&imgdata.rawdata.ioparams,&libraw_internal_data.internal_output_params,sizeof(libraw_internal_data.internal_output_params));\n\n        SET_PROC_FLAG(LIBRAW_PROGRESS_LOAD_RAW);\n        RUN_CALLBACK(LIBRAW_PROGRESS_LOAD_RAW,1,2);\n        \n        return 0;\n    }\n    catch ( LibRaw_exceptions err) {\n        EXCEPTION_HANDLER(err);\n    }\n    catch (std::exception ee) {\n        EXCEPTION_HANDLER(LIBRAW_EXCEPTION_IO_CORRUPT);\n    }\n}",
        "func": "int LibRaw::unpack(void)\n{\n    CHECK_ORDER_HIGH(LIBRAW_PROGRESS_LOAD_RAW);\n    CHECK_ORDER_LOW(LIBRAW_PROGRESS_IDENTIFY);\n    try {\n\n\t\tif(!libraw_internal_data.internal_data.input)\n\t\t\treturn LIBRAW_INPUT_CLOSED;\n\n        RUN_CALLBACK(LIBRAW_PROGRESS_LOAD_RAW,0,2);\n        if (O.shot_select >= P1.raw_count)\n            return LIBRAW_REQUEST_FOR_NONEXISTENT_IMAGE;\n        \n        if(!load_raw)\n            return LIBRAW_UNSPECIFIED_ERROR;\n        \n        if (O.use_camera_matrix && C.cmatrix[0][0] > 0.25) \n            {\n                memcpy (C.rgb_cam, C.cmatrix, sizeof (C.cmatrix));\n                IO.raw_color = 0;\n            }\n        // already allocated ?\n        if(imgdata.image)\n            {\n                free(imgdata.image);\n                imgdata.image = 0;\n            }\n        if(imgdata.rawdata.raw_alloc)\n          {\n            free(imgdata.rawdata.raw_alloc);\n            imgdata.rawdata.raw_alloc = 0;\n          }\n        if (libraw_internal_data.unpacker_data.meta_length) \n            {\n                libraw_internal_data.internal_data.meta_data = \n                    (char *) malloc (libraw_internal_data.unpacker_data.meta_length);\n                merror (libraw_internal_data.internal_data.meta_data, \"LibRaw::unpack()\");\n            }\n\n        libraw_decoder_info_t decoder_info;\n        get_decoder_info(&decoder_info);\n\n        int save_iwidth = S.iwidth, save_iheight = S.iheight, save_shrink = IO.shrink;\n\n        int rwidth = S.raw_width, rheight = S.raw_height;\n        if( !IO.fuji_width)\n            {\n                // adjust non-Fuji allocation\n                if(rwidth < S.width + S.left_margin)\n                    rwidth = S.width + S.left_margin;\n                if(rheight < S.height + S.top_margin)\n                    rheight = S.height + S.top_margin;\n            }\n        S.raw_pitch = S.raw_width*2;\n        imgdata.rawdata.raw_image = 0;\n        imgdata.rawdata.color4_image = 0;\n\timgdata.rawdata.color3_image = 0;\n#ifdef USE_RAWSPEED\n        // RawSpeed Supported, \n        if(O.use_rawspeed && (decoder_info.decoder_flags & LIBRAW_DECODER_TRYRAWSPEED) && _rawspeed_camerameta)\n          {\n            INT64 spos = ID.input->tell();\n            try \n              {\n                //                printf(\"Using rawspeed\\n\");\n                ID.input->seek(0,SEEK_SET);\n                INT64 _rawspeed_buffer_sz = ID.input->size()+32;\n                void *_rawspeed_buffer = malloc(_rawspeed_buffer_sz);\n                if(!_rawspeed_buffer) throw LIBRAW_EXCEPTION_ALLOC;\n                ID.input->read(_rawspeed_buffer,_rawspeed_buffer_sz,1);\n                FileMap map((uchar8*)_rawspeed_buffer,_rawspeed_buffer_sz);\n                RawParser t(&map);\n                RawDecoder *d = 0;\n                CameraMetaDataLR *meta = static_cast<CameraMetaDataLR*>(_rawspeed_camerameta);\n                d = t.getDecoder();\n                try {\n                  d->checkSupport(meta);\n                }\n                catch (const RawDecoderException& e)\n                  {\n                    imgdata.process_warnings |= LIBRAW_WARN_RAWSPEED_UNSUPPORTED;\n                    throw e;\n                  }\n                d->decodeRaw();\n                d->decodeMetaData(meta);\n                RawImage r = d->mRaw;\n                if (r->isCFA) {\n                  // Save pointer to decoder\n                  _rawspeed_decoder = static_cast<void*>(d);\n                  imgdata.rawdata.raw_image = (ushort*) r->getDataUncropped(0,0);\n                  S.raw_pitch = r->pitch;\n                  fix_after_rawspeed(r->blackLevel);\n                } else if(r->getCpp()==4) {\n                  _rawspeed_decoder = static_cast<void*>(d);\n                  imgdata.rawdata.color4_image = (ushort(*)[4]) r->getDataUncropped(0,0);\n                  S.raw_pitch = r->pitch;\n                  C.maximum = r->whitePoint;\n                  fix_after_rawspeed(r->blackLevel);\n                } else if(r->getCpp() == 3)\n                  {\n                    _rawspeed_decoder = static_cast<void*>(d);\n                    imgdata.rawdata.color3_image = (ushort(*)[3]) r->getDataUncropped(0,0);\n                    S.raw_pitch = r->pitch;\n                    C.maximum = r->whitePoint;\n                    fix_after_rawspeed(r->blackLevel);\n                  }\n                else\n                  {\n                    delete d;\n                  }\n                free(_rawspeed_buffer);\n              imgdata.process_warnings |= LIBRAW_WARN_RAWSPEED_PROCESSED;\n              } catch (...) {\n              imgdata.process_warnings |= LIBRAW_WARN_RAWSPEED_PROBLEM;\n              // no other actions: if raw_image is not set we'll try usual load_raw call\n            }\n            ID.input->seek(spos,SEEK_SET);\n          }\n#endif\n        if(!imgdata.rawdata.raw_image && !imgdata.rawdata.color4_image && !imgdata.rawdata.color3_image) // RawSpeed failed!\n          {\n            // Not allocated on RawSpeed call, try call LibRaw\n            if(decoder_info.decoder_flags &  LIBRAW_DECODER_FLATFIELD)\n              {\n                imgdata.rawdata.raw_alloc = malloc(rwidth*(rheight+7)*sizeof(imgdata.rawdata.raw_image[0]));\n                imgdata.rawdata.raw_image = (ushort*) imgdata.rawdata.raw_alloc;\n              }\n            else if (decoder_info.decoder_flags & LIBRAW_DECODER_LEGACY)\n              {\n                // sRAW and Foveon only, so extra buffer size is just 1/4\n                // Legacy converters does not supports half mode!\n                S.iwidth = S.width;\n                S.iheight= S.height;\n                IO.shrink = 0;\n\t\t\t\tS.raw_pitch = S.width*8;\n                // allocate image as temporary buffer, size \n                imgdata.rawdata.raw_alloc = 0;\n                imgdata.image = (ushort (*)[4]) calloc(S.iwidth*S.iheight,sizeof(*imgdata.image));\n              }\n            ID.input->seek(libraw_internal_data.unpacker_data.data_offset, SEEK_SET);\n\n\t\t\tunsigned m_save = C.maximum;\n\t\t\tif(load_raw == &LibRaw::unpacked_load_raw && !strcasecmp(imgdata.idata.make,\"Nikon\"))\n\t\t\t\tC.maximum=65535;\n            (this->*load_raw)();\n\t\t\tif(load_raw == &LibRaw::unpacked_load_raw && !strcasecmp(imgdata.idata.make,\"Nikon\"))\n\t\t\t\tC.maximum = m_save;\n\t\t\tif (decoder_info.decoder_flags & LIBRAW_DECODER_LEGACY)\n\t\t\t{\n\t\t\t\t// successfully decoded legacy image, attach image to raw_alloc\n\t\t\t\timgdata.rawdata.raw_alloc = imgdata.image;\n\t\t\t\timgdata.image = 0; \n\t\t\t}\n          }\n\n        if(imgdata.rawdata.raw_image)\n          crop_masked_pixels(); // calculate black levels\n\n        // recover saved\n        if( (decoder_info.decoder_flags & LIBRAW_DECODER_LEGACY) && !imgdata.rawdata.color4_image)\n            {\n                imgdata.image = 0; \n                imgdata.rawdata.color4_image = (ushort (*)[4]) imgdata.rawdata.raw_alloc;\n            }\n\n        // recover image sizes\n        S.iwidth = save_iwidth;\n        S.iheight = save_iheight;\n        IO.shrink = save_shrink;\n\n        // adjust black to possible maximum\n        unsigned int i = C.cblack[3];\n        unsigned int c;\n        for(c=0;c<3;c++)\n            if (i > C.cblack[c]) i = C.cblack[c];\n        for (c=0;c<4;c++)\n            C.cblack[c] -= i;\n        C.black += i;\n\n        // Save color,sizes and internal data into raw_image fields\n        memmove(&imgdata.rawdata.color,&imgdata.color,sizeof(imgdata.color));\n        memmove(&imgdata.rawdata.sizes,&imgdata.sizes,sizeof(imgdata.sizes));\n        memmove(&imgdata.rawdata.iparams,&imgdata.idata,sizeof(imgdata.idata));\n        memmove(&imgdata.rawdata.ioparams,&libraw_internal_data.internal_output_params,sizeof(libraw_internal_data.internal_output_params));\n\n        SET_PROC_FLAG(LIBRAW_PROGRESS_LOAD_RAW);\n        RUN_CALLBACK(LIBRAW_PROGRESS_LOAD_RAW,1,2);\n        \n        return 0;\n    }\n    catch ( LibRaw_exceptions err) {\n        EXCEPTION_HANDLER(err);\n    }\n    catch (std::exception ee) {\n        EXCEPTION_HANDLER(LIBRAW_EXCEPTION_IO_CORRUPT);\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -134,8 +134,8 @@\n                 IO.shrink = 0;\n \t\t\t\tS.raw_pitch = S.width*8;\n                 // allocate image as temporary buffer, size \n-                imgdata.rawdata.raw_alloc = calloc(S.iwidth*S.iheight,sizeof(*imgdata.image));\n-                imgdata.image = (ushort (*)[4]) imgdata.rawdata.raw_alloc;\n+                imgdata.rawdata.raw_alloc = 0;\n+                imgdata.image = (ushort (*)[4]) calloc(S.iwidth*S.iheight,sizeof(*imgdata.image));\n               }\n             ID.input->seek(libraw_internal_data.unpacker_data.data_offset, SEEK_SET);\n \n@@ -145,6 +145,12 @@\n             (this->*load_raw)();\n \t\t\tif(load_raw == &LibRaw::unpacked_load_raw && !strcasecmp(imgdata.idata.make,\"Nikon\"))\n \t\t\t\tC.maximum = m_save;\n+\t\t\tif (decoder_info.decoder_flags & LIBRAW_DECODER_LEGACY)\n+\t\t\t{\n+\t\t\t\t// successfully decoded legacy image, attach image to raw_alloc\n+\t\t\t\timgdata.rawdata.raw_alloc = imgdata.image;\n+\t\t\t\timgdata.image = 0; \n+\t\t\t}\n           }\n \n         if(imgdata.rawdata.raw_image)",
        "diff_line_info": {
            "deleted_lines": [
                "                imgdata.rawdata.raw_alloc = calloc(S.iwidth*S.iheight,sizeof(*imgdata.image));",
                "                imgdata.image = (ushort (*)[4]) imgdata.rawdata.raw_alloc;"
            ],
            "added_lines": [
                "                imgdata.rawdata.raw_alloc = 0;",
                "                imgdata.image = (ushort (*)[4]) calloc(S.iwidth*S.iheight,sizeof(*imgdata.image));",
                "\t\t\tif (decoder_info.decoder_flags & LIBRAW_DECODER_LEGACY)",
                "\t\t\t{",
                "\t\t\t\t// successfully decoded legacy image, attach image to raw_alloc",
                "\t\t\t\timgdata.rawdata.raw_alloc = imgdata.image;",
                "\t\t\t\timgdata.image = 0; ",
                "\t\t\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-4130",
        "func_name": "spice/red_channel_pipes_add_type",
        "description": "The (1) red_channel_pipes_add_type and (2) red_channel_pipes_add_empty_msg functions in server/red_channel.c in SPICE before 0.12.4 do not properly perform ring loops, which might allow remote attackers to cause a denial of service (reachable assertion and server exit) by triggering a network error.",
        "git_url": "http://cgit.freedesktop.org/spice/spice/commit/?id=53488f0275d6c8a121af49f7ac817d09ce68090d",
        "commit_title": "Currently, both red_channel_pipes_add_type() and",
        "commit_text": "red_channel_pipes_add_empty_msg() use plaing RING_FOREACH() which is not safe versus removals from the ring within the loop body.  Although it's rare, such a removal can occur in both cases.  In the case of red_channel_pipes_add_type() we have:     red_channel_pipes_add_type()     -> red_channel_client_pipe_add_type()         -> red_channel_client_push()  And in the case of red_channel_client_pipes_add_empty_msg() we have:     red_channel_client_pipes_add_empty_msg()     -> red_channel_client_pipe_add_empty_msg()         -> red_channel_client_push()  But red_channel_client_push() can cause a removal from the clients ring if a network error occurs:     red_channel_client_push()     -> red_channel_client_send()         -> red_peer_handle_outgoing()             -> handler->cb->on_error callback             =  red_channel_client_default_peer_on_error()                 -> red_channel_client_disconnect()                     -> red_channel_remove_client()                         -> ring_remove()  When this error path does occur, the assertion in RING_FOREACH()'s ring_next() trips, and the process containing the spice server is aborted. i.e. your whole VM dies, as a result of an unfortunately timed network error on the spice channel.  Please apply.  ",
        "func_before": "void red_channel_pipes_add_type(RedChannel *channel, int pipe_item_type)\n{\n    RingItem *link;\n\n    RING_FOREACH(link, &channel->clients) {\n        red_channel_client_pipe_add_type(\n            SPICE_CONTAINEROF(link, RedChannelClient, channel_link),\n            pipe_item_type);\n    }\n}",
        "func": "void red_channel_pipes_add_type(RedChannel *channel, int pipe_item_type)\n{\n    RingItem *link, *next;\n\n    RING_FOREACH_SAFE(link, next, &channel->clients) {\n        red_channel_client_pipe_add_type(\n            SPICE_CONTAINEROF(link, RedChannelClient, channel_link),\n            pipe_item_type);\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,8 +1,8 @@\n void red_channel_pipes_add_type(RedChannel *channel, int pipe_item_type)\n {\n-    RingItem *link;\n+    RingItem *link, *next;\n \n-    RING_FOREACH(link, &channel->clients) {\n+    RING_FOREACH_SAFE(link, next, &channel->clients) {\n         red_channel_client_pipe_add_type(\n             SPICE_CONTAINEROF(link, RedChannelClient, channel_link),\n             pipe_item_type);",
        "diff_line_info": {
            "deleted_lines": [
                "    RingItem *link;",
                "    RING_FOREACH(link, &channel->clients) {"
            ],
            "added_lines": [
                "    RingItem *link, *next;",
                "    RING_FOREACH_SAFE(link, next, &channel->clients) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-4130",
        "func_name": "spice/red_channel_pipes_add_empty_msg",
        "description": "The (1) red_channel_pipes_add_type and (2) red_channel_pipes_add_empty_msg functions in server/red_channel.c in SPICE before 0.12.4 do not properly perform ring loops, which might allow remote attackers to cause a denial of service (reachable assertion and server exit) by triggering a network error.",
        "git_url": "http://cgit.freedesktop.org/spice/spice/commit/?id=53488f0275d6c8a121af49f7ac817d09ce68090d",
        "commit_title": "Currently, both red_channel_pipes_add_type() and",
        "commit_text": "red_channel_pipes_add_empty_msg() use plaing RING_FOREACH() which is not safe versus removals from the ring within the loop body.  Although it's rare, such a removal can occur in both cases.  In the case of red_channel_pipes_add_type() we have:     red_channel_pipes_add_type()     -> red_channel_client_pipe_add_type()         -> red_channel_client_push()  And in the case of red_channel_client_pipes_add_empty_msg() we have:     red_channel_client_pipes_add_empty_msg()     -> red_channel_client_pipe_add_empty_msg()         -> red_channel_client_push()  But red_channel_client_push() can cause a removal from the clients ring if a network error occurs:     red_channel_client_push()     -> red_channel_client_send()         -> red_peer_handle_outgoing()             -> handler->cb->on_error callback             =  red_channel_client_default_peer_on_error()                 -> red_channel_client_disconnect()                     -> red_channel_remove_client()                         -> ring_remove()  When this error path does occur, the assertion in RING_FOREACH()'s ring_next() trips, and the process containing the spice server is aborted. i.e. your whole VM dies, as a result of an unfortunately timed network error on the spice channel.  Please apply.  ",
        "func_before": "void red_channel_pipes_add_empty_msg(RedChannel *channel, int msg_type)\n{\n    RingItem *link;\n\n    RING_FOREACH(link, &channel->clients) {\n        red_channel_client_pipe_add_empty_msg(\n            SPICE_CONTAINEROF(link, RedChannelClient, channel_link),\n            msg_type);\n    }\n}",
        "func": "void red_channel_pipes_add_empty_msg(RedChannel *channel, int msg_type)\n{\n    RingItem *link, *next;\n\n    RING_FOREACH_SAFE(link, next, &channel->clients) {\n        red_channel_client_pipe_add_empty_msg(\n            SPICE_CONTAINEROF(link, RedChannelClient, channel_link),\n            msg_type);\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,8 +1,8 @@\n void red_channel_pipes_add_empty_msg(RedChannel *channel, int msg_type)\n {\n-    RingItem *link;\n+    RingItem *link, *next;\n \n-    RING_FOREACH(link, &channel->clients) {\n+    RING_FOREACH_SAFE(link, next, &channel->clients) {\n         red_channel_client_pipe_add_empty_msg(\n             SPICE_CONTAINEROF(link, RedChannelClient, channel_link),\n             msg_type);",
        "diff_line_info": {
            "deleted_lines": [
                "    RingItem *link;",
                "    RING_FOREACH(link, &channel->clients) {"
            ],
            "added_lines": [
                "    RingItem *link, *next;",
                "    RING_FOREACH_SAFE(link, next, &channel->clients) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-2902",
        "func_name": "chromium/StyleSheetCollection::collectStyleSheets",
        "description": "Use-after-free vulnerability in the XSLT ProcessingInstruction implementation in Blink, as used in Google Chrome before 29.0.1547.57, allows remote attackers to cause a denial of service or possibly have unspecified other impact via vectors related to an applyXSLTransform call involving (1) an HTML document or (2) an xsl:processing-instruction element that is still in the process of loading.",
        "git_url": "https://github.com/chromium/chromium/commit/aca6327545556b90a9efe385594e38b8fc9530b4",
        "commit_title": "applyXSLTransform is too eager",
        "commit_text": " There's nothing that stops ProcessingInstruction from applying XSL Transforms to HTML documents or from applying incompletely loaded XSL Transforms. This CL adds a couple checks to avoid these cases.  The XSL Transform system is a bundle of insanity. So much of the system makes so little sense it's hard to know where to start fixing it. Eric Seidel's opinion is that we shouldn't drive the XSL transform process from style resolution. Instead, we should kick off the transform either from DOMContentLoaded or from the XSL sheet's load event. We tried a couple approaches along those lines, but we didn't finish them for this CL. Maybe we'll get that working for a future CL.   ",
        "func_before": "void StyleSheetCollection::collectStyleSheets(DocumentStyleSheetCollection* collections, Vector<RefPtr<StyleSheet> >& styleSheets, Vector<RefPtr<CSSStyleSheet> >& activeSheets)\n{\n    if (document()->settings() && !document()->settings()->authorAndUserStylesEnabled())\n        return;\n\n    DocumentOrderedList::iterator begin = m_styleSheetCandidateNodes.begin();\n    DocumentOrderedList::iterator end = m_styleSheetCandidateNodes.end();\n    for (DocumentOrderedList::iterator it = begin; it != end; ++it) {\n        Node* n = *it;\n        StyleSheet* sheet = 0;\n        CSSStyleSheet* activeSheet = 0;\n        if (n->nodeType() == Node::PROCESSING_INSTRUCTION_NODE) {\n            // Processing instruction (XML documents only).\n            // We don't support linking to embedded CSS stylesheets, see <https://bugs.webkit.org/show_bug.cgi?id=49281> for discussion.\n            ProcessingInstruction* pi = static_cast<ProcessingInstruction*>(n);\n            // Don't apply XSL transforms to already transformed documents -- <rdar://problem/4132806>\n            if (pi->isXSL() && !document()->transformSourceDocument()) {\n                // Don't apply XSL transforms until loading is finished.\n                if (!document()->parsing())\n                    document()->applyXSLTransform(pi);\n                return;\n            }\n            sheet = pi->sheet();\n            if (sheet && !sheet->disabled() && sheet->isCSSStyleSheet())\n                activeSheet = static_cast<CSSStyleSheet*>(sheet);\n        } else if ((n->isHTMLElement() && (n->hasTagName(linkTag) || n->hasTagName(styleTag))) || (n->isSVGElement() && n->hasTagName(SVGNames::styleTag))) {\n            Element* e = toElement(n);\n            AtomicString title = e->getAttribute(titleAttr);\n            bool enabledViaScript = false;\n            if (e->hasLocalName(linkTag)) {\n                // <LINK> element\n                HTMLLinkElement* linkElement = toHTMLLinkElement(n);\n                enabledViaScript = linkElement->isEnabledViaScript();\n                if (!linkElement->isDisabled() && linkElement->styleSheetIsLoading()) {\n                    // it is loading but we should still decide which style sheet set to use\n                    if (!enabledViaScript && !title.isEmpty() && collections->preferredStylesheetSetName().isEmpty()) {\n                        const AtomicString& rel = e->getAttribute(relAttr);\n                        if (!rel.contains(\"alternate\")) {\n                            collections->setPreferredStylesheetSetName(title);\n                            collections->setSelectedStylesheetSetName(title);\n                        }\n                    }\n\n                    continue;\n                }\n                sheet = linkElement->sheet();\n                if (!sheet)\n                    title = nullAtom;\n            } else if (n->isSVGElement() && n->hasTagName(SVGNames::styleTag)) {\n                sheet = static_cast<SVGStyleElement*>(n)->sheet();\n            } else {\n                sheet = static_cast<HTMLStyleElement*>(n)->sheet();\n            }\n\n            if (sheet && !sheet->disabled() && sheet->isCSSStyleSheet())\n                activeSheet = static_cast<CSSStyleSheet*>(sheet);\n\n            // Check to see if this sheet belongs to a styleset\n            // (thus making it PREFERRED or ALTERNATE rather than\n            // PERSISTENT).\n            AtomicString rel = e->getAttribute(relAttr);\n            if (!enabledViaScript && sheet && !title.isEmpty()) {\n                // Yes, we have a title.\n                if (collections->preferredStylesheetSetName().isEmpty()) {\n                    // No preferred set has been established. If\n                    // we are NOT an alternate sheet, then establish\n                    // us as the preferred set. Otherwise, just ignore\n                    // this sheet.\n                    if (e->hasLocalName(styleTag) || !rel.contains(\"alternate\")) {\n                        collections->setPreferredStylesheetSetName(title);\n                        collections->setSelectedStylesheetSetName(title);\n                    }\n                }\n                if (title != collections->preferredStylesheetSetName())\n                    activeSheet = 0;\n            }\n\n            if (rel.contains(\"alternate\") && title.isEmpty())\n                activeSheet = 0;\n        }\n        if (sheet)\n            styleSheets.append(sheet);\n        if (activeSheet)\n            activeSheets.append(activeSheet);\n    }\n}",
        "func": "void StyleSheetCollection::collectStyleSheets(DocumentStyleSheetCollection* collections, Vector<RefPtr<StyleSheet> >& styleSheets, Vector<RefPtr<CSSStyleSheet> >& activeSheets)\n{\n    if (document()->settings() && !document()->settings()->authorAndUserStylesEnabled())\n        return;\n\n    DocumentOrderedList::iterator begin = m_styleSheetCandidateNodes.begin();\n    DocumentOrderedList::iterator end = m_styleSheetCandidateNodes.end();\n    for (DocumentOrderedList::iterator it = begin; it != end; ++it) {\n        Node* n = *it;\n        StyleSheet* sheet = 0;\n        CSSStyleSheet* activeSheet = 0;\n        if (n->nodeType() == Node::PROCESSING_INSTRUCTION_NODE && !document()->isHTMLDocument()) {\n            // Processing instruction (XML documents only).\n            // We don't support linking to embedded CSS stylesheets, see <https://bugs.webkit.org/show_bug.cgi?id=49281> for discussion.\n            ProcessingInstruction* pi = static_cast<ProcessingInstruction*>(n);\n            // Don't apply XSL transforms to already transformed documents -- <rdar://problem/4132806>\n            if (pi->isXSL() && !document()->transformSourceDocument()) {\n                // Don't apply XSL transforms until loading is finished.\n                if (!document()->parsing() && !pi->isLoading())\n                    document()->applyXSLTransform(pi);\n                return;\n            }\n            sheet = pi->sheet();\n            if (sheet && !sheet->disabled() && sheet->isCSSStyleSheet())\n                activeSheet = static_cast<CSSStyleSheet*>(sheet);\n        } else if ((n->isHTMLElement() && (n->hasTagName(linkTag) || n->hasTagName(styleTag))) || (n->isSVGElement() && n->hasTagName(SVGNames::styleTag))) {\n            Element* e = toElement(n);\n            AtomicString title = e->getAttribute(titleAttr);\n            bool enabledViaScript = false;\n            if (e->hasLocalName(linkTag)) {\n                // <LINK> element\n                HTMLLinkElement* linkElement = toHTMLLinkElement(n);\n                enabledViaScript = linkElement->isEnabledViaScript();\n                if (!linkElement->isDisabled() && linkElement->styleSheetIsLoading()) {\n                    // it is loading but we should still decide which style sheet set to use\n                    if (!enabledViaScript && !title.isEmpty() && collections->preferredStylesheetSetName().isEmpty()) {\n                        const AtomicString& rel = e->getAttribute(relAttr);\n                        if (!rel.contains(\"alternate\")) {\n                            collections->setPreferredStylesheetSetName(title);\n                            collections->setSelectedStylesheetSetName(title);\n                        }\n                    }\n\n                    continue;\n                }\n                sheet = linkElement->sheet();\n                if (!sheet)\n                    title = nullAtom;\n            } else if (n->isSVGElement() && n->hasTagName(SVGNames::styleTag)) {\n                sheet = static_cast<SVGStyleElement*>(n)->sheet();\n            } else {\n                sheet = static_cast<HTMLStyleElement*>(n)->sheet();\n            }\n\n            if (sheet && !sheet->disabled() && sheet->isCSSStyleSheet())\n                activeSheet = static_cast<CSSStyleSheet*>(sheet);\n\n            // Check to see if this sheet belongs to a styleset\n            // (thus making it PREFERRED or ALTERNATE rather than\n            // PERSISTENT).\n            AtomicString rel = e->getAttribute(relAttr);\n            if (!enabledViaScript && sheet && !title.isEmpty()) {\n                // Yes, we have a title.\n                if (collections->preferredStylesheetSetName().isEmpty()) {\n                    // No preferred set has been established. If\n                    // we are NOT an alternate sheet, then establish\n                    // us as the preferred set. Otherwise, just ignore\n                    // this sheet.\n                    if (e->hasLocalName(styleTag) || !rel.contains(\"alternate\")) {\n                        collections->setPreferredStylesheetSetName(title);\n                        collections->setSelectedStylesheetSetName(title);\n                    }\n                }\n                if (title != collections->preferredStylesheetSetName())\n                    activeSheet = 0;\n            }\n\n            if (rel.contains(\"alternate\") && title.isEmpty())\n                activeSheet = 0;\n        }\n        if (sheet)\n            styleSheets.append(sheet);\n        if (activeSheet)\n            activeSheets.append(activeSheet);\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -9,14 +9,14 @@\n         Node* n = *it;\n         StyleSheet* sheet = 0;\n         CSSStyleSheet* activeSheet = 0;\n-        if (n->nodeType() == Node::PROCESSING_INSTRUCTION_NODE) {\n+        if (n->nodeType() == Node::PROCESSING_INSTRUCTION_NODE && !document()->isHTMLDocument()) {\n             // Processing instruction (XML documents only).\n             // We don't support linking to embedded CSS stylesheets, see <https://bugs.webkit.org/show_bug.cgi?id=49281> for discussion.\n             ProcessingInstruction* pi = static_cast<ProcessingInstruction*>(n);\n             // Don't apply XSL transforms to already transformed documents -- <rdar://problem/4132806>\n             if (pi->isXSL() && !document()->transformSourceDocument()) {\n                 // Don't apply XSL transforms until loading is finished.\n-                if (!document()->parsing())\n+                if (!document()->parsing() && !pi->isLoading())\n                     document()->applyXSLTransform(pi);\n                 return;\n             }",
        "diff_line_info": {
            "deleted_lines": [
                "        if (n->nodeType() == Node::PROCESSING_INSTRUCTION_NODE) {",
                "                if (!document()->parsing())"
            ],
            "added_lines": [
                "        if (n->nodeType() == Node::PROCESSING_INSTRUCTION_NODE && !document()->isHTMLDocument()) {",
                "                if (!document()->parsing() && !pi->isLoading())"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-2902",
        "func_name": "chromium/Document::applyXSLTransform",
        "description": "Use-after-free vulnerability in the XSLT ProcessingInstruction implementation in Blink, as used in Google Chrome before 29.0.1547.57, allows remote attackers to cause a denial of service or possibly have unspecified other impact via vectors related to an applyXSLTransform call involving (1) an HTML document or (2) an xsl:processing-instruction element that is still in the process of loading.",
        "git_url": "https://github.com/chromium/chromium/commit/aca6327545556b90a9efe385594e38b8fc9530b4",
        "commit_title": "applyXSLTransform is too eager",
        "commit_text": " There's nothing that stops ProcessingInstruction from applying XSL Transforms to HTML documents or from applying incompletely loaded XSL Transforms. This CL adds a couple checks to avoid these cases.  The XSL Transform system is a bundle of insanity. So much of the system makes so little sense it's hard to know where to start fixing it. Eric Seidel's opinion is that we shouldn't drive the XSL transform process from style resolution. Instead, we should kick off the transform either from DOMContentLoaded or from the XSL sheet's load event. We tried a couple approaches along those lines, but we didn't finish them for this CL. Maybe we'll get that working for a future CL.   ",
        "func_before": "void Document::applyXSLTransform(ProcessingInstruction* pi)\n{\n    UseCounter::count(this, UseCounter::XSLProcessingInstruction);\n    RefPtr<XSLTProcessor> processor = XSLTProcessor::create();\n    processor->setXSLStyleSheet(static_cast<XSLStyleSheet*>(pi->sheet()));\n    String resultMIMEType;\n    String newSource;\n    String resultEncoding;\n    if (!processor->transformToString(this, resultMIMEType, newSource, resultEncoding))\n        return;\n    // FIXME: If the transform failed we should probably report an error (like Mozilla does).\n    Frame* ownerFrame = frame();\n    processor->createDocumentFromSource(newSource, resultEncoding, resultMIMEType, this, ownerFrame);\n    InspectorInstrumentation::frameDocumentUpdated(ownerFrame);\n}",
        "func": "void Document::applyXSLTransform(ProcessingInstruction* pi)\n{\n    ASSERT(!pi->isLoading());\n    UseCounter::count(this, UseCounter::XSLProcessingInstruction);\n    RefPtr<XSLTProcessor> processor = XSLTProcessor::create();\n    processor->setXSLStyleSheet(static_cast<XSLStyleSheet*>(pi->sheet()));\n    String resultMIMEType;\n    String newSource;\n    String resultEncoding;\n    if (!processor->transformToString(this, resultMIMEType, newSource, resultEncoding))\n        return;\n    // FIXME: If the transform failed we should probably report an error (like Mozilla does).\n    Frame* ownerFrame = frame();\n    processor->createDocumentFromSource(newSource, resultEncoding, resultMIMEType, this, ownerFrame);\n    InspectorInstrumentation::frameDocumentUpdated(ownerFrame);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,6 @@\n void Document::applyXSLTransform(ProcessingInstruction* pi)\n {\n+    ASSERT(!pi->isLoading());\n     UseCounter::count(this, UseCounter::XSLProcessingInstruction);\n     RefPtr<XSLTProcessor> processor = XSLTProcessor::create();\n     processor->setXSLStyleSheet(static_cast<XSLStyleSheet*>(pi->sheet()));",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    ASSERT(!pi->isLoading());"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-2903",
        "func_name": "chromium/HTMLMediaElement::didMoveToNewDocument",
        "description": "Use-after-free vulnerability in the HTMLMediaElement::didMoveToNewDocument function in core/html/HTMLMediaElement.cpp in Blink, as used in Google Chrome before 29.0.1547.57, allows remote attackers to cause a denial of service or possibly have unspecified other impact via vectors involving moving a (1) AUDIO or (2) VIDEO element between documents.",
        "git_url": "https://github.com/chromium/chromium/commit/f4d0ee00fa66b781d5b8c5dad488a2ffba7abf2b",
        "commit_title": "Prevent WebMediaPlayerImpl from dereferencing stale Frame pointers on Document changes.",
        "commit_text": " Temporary fix to prevent dereferencing stale Frame pointers when an HTMLMediaElement is moved from one document to another. (e.g., Lifting it out of an iframe into the main document.)   ",
        "func_before": "void HTMLMediaElement::didMoveToNewDocument(Document* oldDocument)\n{\n    if (m_shouldDelayLoadEvent) {\n        if (oldDocument)\n            oldDocument->decrementLoadEventDelayCount();\n        document()->incrementLoadEventDelayCount();\n    }\n\n    if (oldDocument)\n        removeElementFromDocumentMap(this, oldDocument);\n\n    addElementToDocumentMap(this, document());\n\n    HTMLElement::didMoveToNewDocument(oldDocument);\n}",
        "func": "void HTMLMediaElement::didMoveToNewDocument(Document* oldDocument)\n{\n    LOG(Media, \"HTMLMediaElement::didMoveToNewDocument\");\n\n    if (m_shouldDelayLoadEvent) {\n        if (oldDocument)\n            oldDocument->decrementLoadEventDelayCount();\n        document()->incrementLoadEventDelayCount();\n    }\n\n    if (oldDocument)\n        removeElementFromDocumentMap(this, oldDocument);\n\n    addElementToDocumentMap(this, document());\n\n    // FIXME: This is a temporary fix to prevent this object from causing the\n    // MediaPlayer to dereference Frame and FrameLoader pointers from the\n    // previous document. A proper fix would provide a mechanism to allow this\n    // object to refresh the MediaPlayer's Frame and FrameLoader references on\n    // document changes so that playback can be resumed properly.\n    userCancelledLoad();\n\n    HTMLElement::didMoveToNewDocument(oldDocument);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,7 @@\n void HTMLMediaElement::didMoveToNewDocument(Document* oldDocument)\n {\n+    LOG(Media, \"HTMLMediaElement::didMoveToNewDocument\");\n+\n     if (m_shouldDelayLoadEvent) {\n         if (oldDocument)\n             oldDocument->decrementLoadEventDelayCount();\n@@ -11,5 +13,12 @@\n \n     addElementToDocumentMap(this, document());\n \n+    // FIXME: This is a temporary fix to prevent this object from causing the\n+    // MediaPlayer to dereference Frame and FrameLoader pointers from the\n+    // previous document. A proper fix would provide a mechanism to allow this\n+    // object to refresh the MediaPlayer's Frame and FrameLoader references on\n+    // document changes so that playback can be resumed properly.\n+    userCancelledLoad();\n+\n     HTMLElement::didMoveToNewDocument(oldDocument);\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    LOG(Media, \"HTMLMediaElement::didMoveToNewDocument\");",
                "",
                "    // FIXME: This is a temporary fix to prevent this object from causing the",
                "    // MediaPlayer to dereference Frame and FrameLoader pointers from the",
                "    // previous document. A proper fix would provide a mechanism to allow this",
                "    // object to refresh the MediaPlayer's Frame and FrameLoader references on",
                "    // document changes so that playback can be resumed properly.",
                "    userCancelledLoad();",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2013-2904",
        "func_name": "chromium/Document::finishedParsing",
        "description": "Use-after-free vulnerability in the Document::finishedParsing function in core/dom/Document.cpp in Blink, as used in Google Chrome before 29.0.1547.57, allows remote attackers to cause a denial of service or possibly have unspecified other impact via an onload event that changes an IFRAME element so that its src attribute is no longer an XML document, leading to unintended garbage collection of this document.",
        "git_url": "https://github.com/chromium/chromium/commit/81d421ae7b33771dfd64bcf3208e856724b4a39e",
        "commit_title": "Protect documents from deletion when their onload removes them",
        "commit_text": " When an XML document is the src of an iframe, and the onload method changes the src to something else, the XML document may be garbage collected before the original load is completed. Bad things result.  In this patch we protect the document in Document::finishedParsing.   ",
        "func_before": "void Document::finishedParsing()\n{\n    ASSERT(!scriptableDocumentParser() || !m_parser->isParsing());\n    ASSERT(!scriptableDocumentParser() || m_readyState != Loading);\n    setParsing(false);\n    if (!m_documentTiming.domContentLoadedEventStart)\n        m_documentTiming.domContentLoadedEventStart = monotonicallyIncreasingTime();\n    dispatchEvent(Event::create(eventNames().DOMContentLoadedEvent, true, false));\n    if (!m_documentTiming.domContentLoadedEventEnd)\n        m_documentTiming.domContentLoadedEventEnd = monotonicallyIncreasingTime();\n\n    if (RefPtr<Frame> f = frame()) {\n        // FrameLoader::finishedParsing() might end up calling Document::implicitClose() if all\n        // resource loads are complete. HTMLObjectElements can start loading their resources from\n        // post attach callbacks triggered by recalcStyle().  This means if we parse out an <object>\n        // tag and then reach the end of the document without updating styles, we might not have yet\n        // started the resource load and might fire the window load event too early.  To avoid this\n        // we force the styles to be up to date before calling FrameLoader::finishedParsing().\n        // See https://bugs.webkit.org/show_bug.cgi?id=36864 starting around comment 35.\n        updateStyleIfNeeded();\n\n        f->loader()->finishedParsing();\n\n        InspectorInstrumentation::domContentLoadedEventFired(f.get());\n    }\n\n    // Schedule dropping of the DocumentSharedObjectPool. We keep it alive for a while after parsing finishes\n    // so that dynamically inserted content can also benefit from sharing optimizations.\n    // Note that we don't refresh the timer on pool access since that could lead to huge caches being kept\n    // alive indefinitely by something innocuous like JS setting .innerHTML repeatedly on a timer.\n    static const int timeToKeepSharedObjectPoolAliveAfterParsingFinishedInSeconds = 10;\n    m_sharedObjectPoolClearTimer.startOneShot(timeToKeepSharedObjectPoolAliveAfterParsingFinishedInSeconds);\n\n    // Parser should have picked up all preloads by now\n    m_cachedResourceLoader->clearPreloads();\n}",
        "func": "void Document::finishedParsing()\n{\n    ASSERT(!scriptableDocumentParser() || !m_parser->isParsing());\n    ASSERT(!scriptableDocumentParser() || m_readyState != Loading);\n    setParsing(false);\n    if (!m_documentTiming.domContentLoadedEventStart)\n        m_documentTiming.domContentLoadedEventStart = monotonicallyIncreasingTime();\n    dispatchEvent(Event::create(eventNames().DOMContentLoadedEvent, true, false));\n    if (!m_documentTiming.domContentLoadedEventEnd)\n        m_documentTiming.domContentLoadedEventEnd = monotonicallyIncreasingTime();\n\n    // The loader's finishedParsing() method may invoke script that causes this object to\n    // be dereferenced (when this document is in an iframe and the onload causes the iframe's src to change).\n    // Keep it alive until we are done.\n    RefPtr<Document> protect(this);\n\n    if (RefPtr<Frame> f = frame()) {\n        // FrameLoader::finishedParsing() might end up calling Document::implicitClose() if all\n        // resource loads are complete. HTMLObjectElements can start loading their resources from\n        // post attach callbacks triggered by recalcStyle().  This means if we parse out an <object>\n        // tag and then reach the end of the document without updating styles, we might not have yet\n        // started the resource load and might fire the window load event too early.  To avoid this\n        // we force the styles to be up to date before calling FrameLoader::finishedParsing().\n        // See https://bugs.webkit.org/show_bug.cgi?id=36864 starting around comment 35.\n        updateStyleIfNeeded();\n\n        f->loader()->finishedParsing();\n\n        InspectorInstrumentation::domContentLoadedEventFired(f.get());\n    }\n\n    // Schedule dropping of the DocumentSharedObjectPool. We keep it alive for a while after parsing finishes\n    // so that dynamically inserted content can also benefit from sharing optimizations.\n    // Note that we don't refresh the timer on pool access since that could lead to huge caches being kept\n    // alive indefinitely by something innocuous like JS setting .innerHTML repeatedly on a timer.\n    static const int timeToKeepSharedObjectPoolAliveAfterParsingFinishedInSeconds = 10;\n    m_sharedObjectPoolClearTimer.startOneShot(timeToKeepSharedObjectPoolAliveAfterParsingFinishedInSeconds);\n\n    // Parser should have picked up all preloads by now\n    m_cachedResourceLoader->clearPreloads();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -8,6 +8,11 @@\n     dispatchEvent(Event::create(eventNames().DOMContentLoadedEvent, true, false));\n     if (!m_documentTiming.domContentLoadedEventEnd)\n         m_documentTiming.domContentLoadedEventEnd = monotonicallyIncreasingTime();\n+\n+    // The loader's finishedParsing() method may invoke script that causes this object to\n+    // be dereferenced (when this document is in an iframe and the onload causes the iframe's src to change).\n+    // Keep it alive until we are done.\n+    RefPtr<Document> protect(this);\n \n     if (RefPtr<Frame> f = frame()) {\n         // FrameLoader::finishedParsing() might end up calling Document::implicitClose() if all",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "    // The loader's finishedParsing() method may invoke script that causes this object to",
                "    // be dereferenced (when this document is in an iframe and the onload causes the iframe's src to change).",
                "    // Keep it alive until we are done.",
                "    RefPtr<Document> protect(this);"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-4205",
        "func_name": "torvalds/linux/unshare_userns",
        "description": "Memory leak in the unshare_userns function in kernel/user_namespace.c in the Linux kernel before 3.10.6 allows local users to cause a denial of service (memory consumption) via an invalid CLONE_NEWUSER unshare call.",
        "git_url": "https://github.com/torvalds/linux/commit/6160968cee8b90a5dd95318d716e31d7775c4ef3",
        "commit_title": "userns: unshare_userns(&cred) should not populate cred on failure",
        "commit_text": " unshare_userns(new_cred) does *new_cred = prepare_creds() before create_user_ns() which can fail. However, the caller expects that it doesn't need to take care of new_cred if unshare_userns() fails.  We could change the single caller, sys_unshare(), but I think it would be more clean to avoid the side effects on failure, so with this patch unshare_userns() does put_cred() itself and initializes *new_cred only if create_user_ns() succeeeds.  Cc: stable@vger.kernel.org",
        "func_before": "int unshare_userns(unsigned long unshare_flags, struct cred **new_cred)\n{\n\tstruct cred *cred;\n\n\tif (!(unshare_flags & CLONE_NEWUSER))\n\t\treturn 0;\n\n\tcred = prepare_creds();\n\tif (!cred)\n\t\treturn -ENOMEM;\n\n\t*new_cred = cred;\n\treturn create_user_ns(cred);\n}",
        "func": "int unshare_userns(unsigned long unshare_flags, struct cred **new_cred)\n{\n\tstruct cred *cred;\n\tint err = -ENOMEM;\n\n\tif (!(unshare_flags & CLONE_NEWUSER))\n\t\treturn 0;\n\n\tcred = prepare_creds();\n\tif (cred) {\n\t\terr = create_user_ns(cred);\n\t\tif (err)\n\t\t\tput_cred(cred);\n\t\telse\n\t\t\t*new_cred = cred;\n\t}\n\n\treturn err;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,14 +1,19 @@\n int unshare_userns(unsigned long unshare_flags, struct cred **new_cred)\n {\n \tstruct cred *cred;\n+\tint err = -ENOMEM;\n \n \tif (!(unshare_flags & CLONE_NEWUSER))\n \t\treturn 0;\n \n \tcred = prepare_creds();\n-\tif (!cred)\n-\t\treturn -ENOMEM;\n+\tif (cred) {\n+\t\terr = create_user_ns(cred);\n+\t\tif (err)\n+\t\t\tput_cred(cred);\n+\t\telse\n+\t\t\t*new_cred = cred;\n+\t}\n \n-\t*new_cred = cred;\n-\treturn create_user_ns(cred);\n+\treturn err;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (!cred)",
                "\t\treturn -ENOMEM;",
                "\t*new_cred = cred;",
                "\treturn create_user_ns(cred);"
            ],
            "added_lines": [
                "\tint err = -ENOMEM;",
                "\tif (cred) {",
                "\t\terr = create_user_ns(cred);",
                "\t\tif (err)",
                "\t\t\tput_cred(cred);",
                "\t\telse",
                "\t\t\t*new_cred = cred;",
                "\t}",
                "\treturn err;"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-5634",
        "func_name": "torvalds/linux/kvm_arch_vcpu_ioctl_run",
        "description": "arch/arm/kvm/arm.c in the Linux kernel before 3.10 on the ARM platform, when KVM is used, allows host OS users to cause a denial of service (NULL pointer dereference, OOPS, and host OS crash) or possibly have unspecified other impact by omitting vCPU initialization before a KVM_GET_REG_LIST ioctl call.",
        "git_url": "https://github.com/torvalds/linux/commit/e8180dcaa8470ceca21109f143876fdcd9fe050a",
        "commit_title": "ARM: KVM: prevent NULL pointer dereferences with KVM VCPU ioctl",
        "commit_text": " Some ARM KVM VCPU ioctls require the vCPU to be properly initialized with the KVM_ARM_VCPU_INIT ioctl before being used with further requests. KVM_RUN checks whether this initialization has been done, but other ioctls do not. Namely KVM_GET_REG_LIST will dereference an array with index -1 without initialization and thus leads to a kernel oops. Fix this by adding checks before executing the ioctl handlers.   [ Removed superflous comment from static function - Christoffer ]  Changes from v1:  * moved check into a static function with a meaningful name ",
        "func_before": "int kvm_arch_vcpu_ioctl_run(struct kvm_vcpu *vcpu, struct kvm_run *run)\n{\n\tint ret;\n\tsigset_t sigsaved;\n\n\t/* Make sure they initialize the vcpu with KVM_ARM_VCPU_INIT */\n\tif (unlikely(vcpu->arch.target < 0))\n\t\treturn -ENOEXEC;\n\n\tret = kvm_vcpu_first_run_init(vcpu);\n\tif (ret)\n\t\treturn ret;\n\n\tif (run->exit_reason == KVM_EXIT_MMIO) {\n\t\tret = kvm_handle_mmio_return(vcpu, vcpu->run);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tif (vcpu->sigset_active)\n\t\tsigprocmask(SIG_SETMASK, &vcpu->sigset, &sigsaved);\n\n\tret = 1;\n\trun->exit_reason = KVM_EXIT_UNKNOWN;\n\twhile (ret > 0) {\n\t\t/*\n\t\t * Check conditions before entering the guest\n\t\t */\n\t\tcond_resched();\n\n\t\tupdate_vttbr(vcpu->kvm);\n\n\t\tif (vcpu->arch.pause)\n\t\t\tvcpu_pause(vcpu);\n\n\t\tkvm_vgic_flush_hwstate(vcpu);\n\t\tkvm_timer_flush_hwstate(vcpu);\n\n\t\tlocal_irq_disable();\n\n\t\t/*\n\t\t * Re-check atomic conditions\n\t\t */\n\t\tif (signal_pending(current)) {\n\t\t\tret = -EINTR;\n\t\t\trun->exit_reason = KVM_EXIT_INTR;\n\t\t}\n\n\t\tif (ret <= 0 || need_new_vmid_gen(vcpu->kvm)) {\n\t\t\tlocal_irq_enable();\n\t\t\tkvm_timer_sync_hwstate(vcpu);\n\t\t\tkvm_vgic_sync_hwstate(vcpu);\n\t\t\tcontinue;\n\t\t}\n\n\t\t/**************************************************************\n\t\t * Enter the guest\n\t\t */\n\t\ttrace_kvm_entry(*vcpu_pc(vcpu));\n\t\tkvm_guest_enter();\n\t\tvcpu->mode = IN_GUEST_MODE;\n\n\t\tret = kvm_call_hyp(__kvm_vcpu_run, vcpu);\n\n\t\tvcpu->mode = OUTSIDE_GUEST_MODE;\n\t\tvcpu->arch.last_pcpu = smp_processor_id();\n\t\tkvm_guest_exit();\n\t\ttrace_kvm_exit(*vcpu_pc(vcpu));\n\t\t/*\n\t\t * We may have taken a host interrupt in HYP mode (ie\n\t\t * while executing the guest). This interrupt is still\n\t\t * pending, as we haven't serviced it yet!\n\t\t *\n\t\t * We're now back in SVC mode, with interrupts\n\t\t * disabled.  Enabling the interrupts now will have\n\t\t * the effect of taking the interrupt again, in SVC\n\t\t * mode this time.\n\t\t */\n\t\tlocal_irq_enable();\n\n\t\t/*\n\t\t * Back from guest\n\t\t *************************************************************/\n\n\t\tkvm_timer_sync_hwstate(vcpu);\n\t\tkvm_vgic_sync_hwstate(vcpu);\n\n\t\tret = handle_exit(vcpu, run, ret);\n\t}\n\n\tif (vcpu->sigset_active)\n\t\tsigprocmask(SIG_SETMASK, &sigsaved, NULL);\n\treturn ret;\n}",
        "func": "int kvm_arch_vcpu_ioctl_run(struct kvm_vcpu *vcpu, struct kvm_run *run)\n{\n\tint ret;\n\tsigset_t sigsaved;\n\n\tif (unlikely(!kvm_vcpu_initialized(vcpu)))\n\t\treturn -ENOEXEC;\n\n\tret = kvm_vcpu_first_run_init(vcpu);\n\tif (ret)\n\t\treturn ret;\n\n\tif (run->exit_reason == KVM_EXIT_MMIO) {\n\t\tret = kvm_handle_mmio_return(vcpu, vcpu->run);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tif (vcpu->sigset_active)\n\t\tsigprocmask(SIG_SETMASK, &vcpu->sigset, &sigsaved);\n\n\tret = 1;\n\trun->exit_reason = KVM_EXIT_UNKNOWN;\n\twhile (ret > 0) {\n\t\t/*\n\t\t * Check conditions before entering the guest\n\t\t */\n\t\tcond_resched();\n\n\t\tupdate_vttbr(vcpu->kvm);\n\n\t\tif (vcpu->arch.pause)\n\t\t\tvcpu_pause(vcpu);\n\n\t\tkvm_vgic_flush_hwstate(vcpu);\n\t\tkvm_timer_flush_hwstate(vcpu);\n\n\t\tlocal_irq_disable();\n\n\t\t/*\n\t\t * Re-check atomic conditions\n\t\t */\n\t\tif (signal_pending(current)) {\n\t\t\tret = -EINTR;\n\t\t\trun->exit_reason = KVM_EXIT_INTR;\n\t\t}\n\n\t\tif (ret <= 0 || need_new_vmid_gen(vcpu->kvm)) {\n\t\t\tlocal_irq_enable();\n\t\t\tkvm_timer_sync_hwstate(vcpu);\n\t\t\tkvm_vgic_sync_hwstate(vcpu);\n\t\t\tcontinue;\n\t\t}\n\n\t\t/**************************************************************\n\t\t * Enter the guest\n\t\t */\n\t\ttrace_kvm_entry(*vcpu_pc(vcpu));\n\t\tkvm_guest_enter();\n\t\tvcpu->mode = IN_GUEST_MODE;\n\n\t\tret = kvm_call_hyp(__kvm_vcpu_run, vcpu);\n\n\t\tvcpu->mode = OUTSIDE_GUEST_MODE;\n\t\tvcpu->arch.last_pcpu = smp_processor_id();\n\t\tkvm_guest_exit();\n\t\ttrace_kvm_exit(*vcpu_pc(vcpu));\n\t\t/*\n\t\t * We may have taken a host interrupt in HYP mode (ie\n\t\t * while executing the guest). This interrupt is still\n\t\t * pending, as we haven't serviced it yet!\n\t\t *\n\t\t * We're now back in SVC mode, with interrupts\n\t\t * disabled.  Enabling the interrupts now will have\n\t\t * the effect of taking the interrupt again, in SVC\n\t\t * mode this time.\n\t\t */\n\t\tlocal_irq_enable();\n\n\t\t/*\n\t\t * Back from guest\n\t\t *************************************************************/\n\n\t\tkvm_timer_sync_hwstate(vcpu);\n\t\tkvm_vgic_sync_hwstate(vcpu);\n\n\t\tret = handle_exit(vcpu, run, ret);\n\t}\n\n\tif (vcpu->sigset_active)\n\t\tsigprocmask(SIG_SETMASK, &sigsaved, NULL);\n\treturn ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,8 +3,7 @@\n \tint ret;\n \tsigset_t sigsaved;\n \n-\t/* Make sure they initialize the vcpu with KVM_ARM_VCPU_INIT */\n-\tif (unlikely(vcpu->arch.target < 0))\n+\tif (unlikely(!kvm_vcpu_initialized(vcpu)))\n \t\treturn -ENOEXEC;\n \n \tret = kvm_vcpu_first_run_init(vcpu);",
        "diff_line_info": {
            "deleted_lines": [
                "\t/* Make sure they initialize the vcpu with KVM_ARM_VCPU_INIT */",
                "\tif (unlikely(vcpu->arch.target < 0))"
            ],
            "added_lines": [
                "\tif (unlikely(!kvm_vcpu_initialized(vcpu)))"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-5634",
        "func_name": "torvalds/linux/kvm_arch_vcpu_ioctl",
        "description": "arch/arm/kvm/arm.c in the Linux kernel before 3.10 on the ARM platform, when KVM is used, allows host OS users to cause a denial of service (NULL pointer dereference, OOPS, and host OS crash) or possibly have unspecified other impact by omitting vCPU initialization before a KVM_GET_REG_LIST ioctl call.",
        "git_url": "https://github.com/torvalds/linux/commit/e8180dcaa8470ceca21109f143876fdcd9fe050a",
        "commit_title": "ARM: KVM: prevent NULL pointer dereferences with KVM VCPU ioctl",
        "commit_text": " Some ARM KVM VCPU ioctls require the vCPU to be properly initialized with the KVM_ARM_VCPU_INIT ioctl before being used with further requests. KVM_RUN checks whether this initialization has been done, but other ioctls do not. Namely KVM_GET_REG_LIST will dereference an array with index -1 without initialization and thus leads to a kernel oops. Fix this by adding checks before executing the ioctl handlers.   [ Removed superflous comment from static function - Christoffer ]  Changes from v1:  * moved check into a static function with a meaningful name ",
        "func_before": "long kvm_arch_vcpu_ioctl(struct file *filp,\n\t\t\t unsigned int ioctl, unsigned long arg)\n{\n\tstruct kvm_vcpu *vcpu = filp->private_data;\n\tvoid __user *argp = (void __user *)arg;\n\n\tswitch (ioctl) {\n\tcase KVM_ARM_VCPU_INIT: {\n\t\tstruct kvm_vcpu_init init;\n\n\t\tif (copy_from_user(&init, argp, sizeof(init)))\n\t\t\treturn -EFAULT;\n\n\t\treturn kvm_vcpu_set_target(vcpu, &init);\n\n\t}\n\tcase KVM_SET_ONE_REG:\n\tcase KVM_GET_ONE_REG: {\n\t\tstruct kvm_one_reg reg;\n\t\tif (copy_from_user(&reg, argp, sizeof(reg)))\n\t\t\treturn -EFAULT;\n\t\tif (ioctl == KVM_SET_ONE_REG)\n\t\t\treturn kvm_arm_set_reg(vcpu, &reg);\n\t\telse\n\t\t\treturn kvm_arm_get_reg(vcpu, &reg);\n\t}\n\tcase KVM_GET_REG_LIST: {\n\t\tstruct kvm_reg_list __user *user_list = argp;\n\t\tstruct kvm_reg_list reg_list;\n\t\tunsigned n;\n\n\t\tif (copy_from_user(&reg_list, user_list, sizeof(reg_list)))\n\t\t\treturn -EFAULT;\n\t\tn = reg_list.n;\n\t\treg_list.n = kvm_arm_num_regs(vcpu);\n\t\tif (copy_to_user(user_list, &reg_list, sizeof(reg_list)))\n\t\t\treturn -EFAULT;\n\t\tif (n < reg_list.n)\n\t\t\treturn -E2BIG;\n\t\treturn kvm_arm_copy_reg_indices(vcpu, user_list->reg);\n\t}\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n}",
        "func": "long kvm_arch_vcpu_ioctl(struct file *filp,\n\t\t\t unsigned int ioctl, unsigned long arg)\n{\n\tstruct kvm_vcpu *vcpu = filp->private_data;\n\tvoid __user *argp = (void __user *)arg;\n\n\tswitch (ioctl) {\n\tcase KVM_ARM_VCPU_INIT: {\n\t\tstruct kvm_vcpu_init init;\n\n\t\tif (copy_from_user(&init, argp, sizeof(init)))\n\t\t\treturn -EFAULT;\n\n\t\treturn kvm_vcpu_set_target(vcpu, &init);\n\n\t}\n\tcase KVM_SET_ONE_REG:\n\tcase KVM_GET_ONE_REG: {\n\t\tstruct kvm_one_reg reg;\n\n\t\tif (unlikely(!kvm_vcpu_initialized(vcpu)))\n\t\t\treturn -ENOEXEC;\n\n\t\tif (copy_from_user(&reg, argp, sizeof(reg)))\n\t\t\treturn -EFAULT;\n\t\tif (ioctl == KVM_SET_ONE_REG)\n\t\t\treturn kvm_arm_set_reg(vcpu, &reg);\n\t\telse\n\t\t\treturn kvm_arm_get_reg(vcpu, &reg);\n\t}\n\tcase KVM_GET_REG_LIST: {\n\t\tstruct kvm_reg_list __user *user_list = argp;\n\t\tstruct kvm_reg_list reg_list;\n\t\tunsigned n;\n\n\t\tif (unlikely(!kvm_vcpu_initialized(vcpu)))\n\t\t\treturn -ENOEXEC;\n\n\t\tif (copy_from_user(&reg_list, user_list, sizeof(reg_list)))\n\t\t\treturn -EFAULT;\n\t\tn = reg_list.n;\n\t\treg_list.n = kvm_arm_num_regs(vcpu);\n\t\tif (copy_to_user(user_list, &reg_list, sizeof(reg_list)))\n\t\t\treturn -EFAULT;\n\t\tif (n < reg_list.n)\n\t\t\treturn -E2BIG;\n\t\treturn kvm_arm_copy_reg_indices(vcpu, user_list->reg);\n\t}\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -17,6 +17,10 @@\n \tcase KVM_SET_ONE_REG:\n \tcase KVM_GET_ONE_REG: {\n \t\tstruct kvm_one_reg reg;\n+\n+\t\tif (unlikely(!kvm_vcpu_initialized(vcpu)))\n+\t\t\treturn -ENOEXEC;\n+\n \t\tif (copy_from_user(&reg, argp, sizeof(reg)))\n \t\t\treturn -EFAULT;\n \t\tif (ioctl == KVM_SET_ONE_REG)\n@@ -28,6 +32,9 @@\n \t\tstruct kvm_reg_list __user *user_list = argp;\n \t\tstruct kvm_reg_list reg_list;\n \t\tunsigned n;\n+\n+\t\tif (unlikely(!kvm_vcpu_initialized(vcpu)))\n+\t\t\treturn -ENOEXEC;\n \n \t\tif (copy_from_user(&reg_list, user_list, sizeof(reg_list)))\n \t\t\treturn -EFAULT;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "\t\tif (unlikely(!kvm_vcpu_initialized(vcpu)))",
                "\t\t\treturn -ENOEXEC;",
                "",
                "",
                "\t\tif (unlikely(!kvm_vcpu_initialized(vcpu)))",
                "\t\t\treturn -ENOEXEC;"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-2910",
        "func_name": "chromium/AudioScheduledSourceNode::notifyEndedDispatch",
        "description": "Use-after-free vulnerability in modules/webaudio/AudioScheduledSourceNode.cpp in the Web Audio implementation in Blink, as used in Google Chrome before 30.0.1599.66, allows remote attackers to cause a denial of service or possibly have unspecified other impact via unknown vectors.",
        "git_url": "https://github.com/chromium/chromium/commit/c8d45a61036403b019bb604e3bea388f0eacae65",
        "commit_title": "Keep AudioScheduledSourceNode alive until onended is called.",
        "commit_text": " Also, if the document has already gone away, we want to avoid firing the event at all. This is similar to what ScriptProcessorNode does with events.   ",
        "func_before": "void AudioScheduledSourceNode::notifyEndedDispatch(void* userData)\n{\n    static_cast<AudioScheduledSourceNode*>(userData)->notifyEnded();\n}",
        "func": "void AudioScheduledSourceNode::notifyEndedDispatch(void* userData)\n{\n    OwnPtr<NotifyEndedTask> task = adoptPtr(static_cast<NotifyEndedTask*>(userData));\n\n    task->notifyEnded();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,4 +1,6 @@\n void AudioScheduledSourceNode::notifyEndedDispatch(void* userData)\n {\n-    static_cast<AudioScheduledSourceNode*>(userData)->notifyEnded();\n+    OwnPtr<NotifyEndedTask> task = adoptPtr(static_cast<NotifyEndedTask*>(userData));\n+\n+    task->notifyEnded();\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    static_cast<AudioScheduledSourceNode*>(userData)->notifyEnded();"
            ],
            "added_lines": [
                "    OwnPtr<NotifyEndedTask> task = adoptPtr(static_cast<NotifyEndedTask*>(userData));",
                "",
                "    task->notifyEnded();"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-2910",
        "func_name": "chromium/AudioScheduledSourceNode::finish",
        "description": "Use-after-free vulnerability in modules/webaudio/AudioScheduledSourceNode.cpp in the Web Audio implementation in Blink, as used in Google Chrome before 30.0.1599.66, allows remote attackers to cause a denial of service or possibly have unspecified other impact via unknown vectors.",
        "git_url": "https://github.com/chromium/chromium/commit/c8d45a61036403b019bb604e3bea388f0eacae65",
        "commit_title": "Keep AudioScheduledSourceNode alive until onended is called.",
        "commit_text": " Also, if the document has already gone away, we want to avoid firing the event at all. This is similar to what ScriptProcessorNode does with events.   ",
        "func_before": "void AudioScheduledSourceNode::finish()\n{\n    if (m_playbackState != FINISHED_STATE) {\n        // Let the context dereference this AudioNode.\n        context()->notifyNodeFinishedProcessing(this);\n        m_playbackState = FINISHED_STATE;\n        context()->decrementActiveSourceCount();\n    }\n\n    if (m_hasEndedListener)\n        callOnMainThread(&AudioScheduledSourceNode::notifyEndedDispatch, this);\n}",
        "func": "void AudioScheduledSourceNode::finish()\n{\n    if (m_playbackState != FINISHED_STATE) {\n        // Let the context dereference this AudioNode.\n        context()->notifyNodeFinishedProcessing(this);\n        m_playbackState = FINISHED_STATE;\n        context()->decrementActiveSourceCount();\n    }\n\n    if (m_hasEndedListener) {\n        // |task| will keep the AudioScheduledSourceNode alive until the listener has been handled.\n        OwnPtr<NotifyEndedTask> task = adoptPtr(new NotifyEndedTask(this));\n        callOnMainThread(&AudioScheduledSourceNode::notifyEndedDispatch, task.leakPtr());\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -7,6 +7,9 @@\n         context()->decrementActiveSourceCount();\n     }\n \n-    if (m_hasEndedListener)\n-        callOnMainThread(&AudioScheduledSourceNode::notifyEndedDispatch, this);\n+    if (m_hasEndedListener) {\n+        // |task| will keep the AudioScheduledSourceNode alive until the listener has been handled.\n+        OwnPtr<NotifyEndedTask> task = adoptPtr(new NotifyEndedTask(this));\n+        callOnMainThread(&AudioScheduledSourceNode::notifyEndedDispatch, task.leakPtr());\n+    }\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    if (m_hasEndedListener)",
                "        callOnMainThread(&AudioScheduledSourceNode::notifyEndedDispatch, this);"
            ],
            "added_lines": [
                "    if (m_hasEndedListener) {",
                "        // |task| will keep the AudioScheduledSourceNode alive until the listener has been handled.",
                "        OwnPtr<NotifyEndedTask> task = adoptPtr(new NotifyEndedTask(this));",
                "        callOnMainThread(&AudioScheduledSourceNode::notifyEndedDispatch, task.leakPtr());",
                "    }"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-2911",
        "func_name": "chromium/XSLStyleSheet::compileStyleSheet",
        "description": "Use-after-free vulnerability in the XSLStyleSheet::compileStyleSheet function in core/xml/XSLStyleSheetLibxslt.cpp in Blink, as used in Google Chrome before 30.0.1599.66, allows remote attackers to cause a denial of service or possibly have unspecified other impact by leveraging improper handling of post-failure recompilation in unspecified libxslt versions.",
        "git_url": "https://github.com/chromium/chromium/commit/0220f39fac21d169a834ef91de362f4169f2eef5",
        "commit_title": "Avoid reparsing an XSLT stylesheet after the first failure.",
        "commit_text": " Certain libxslt versions appear to leave the doc in an invalid state when parsing fails. We should cache this result and avoid re-parsing.  (The test cannot be converted to text-only due to its invalid stylesheet).   ",
        "func_before": "xsltStylesheetPtr XSLStyleSheet::compileStyleSheet()\n{\n    // FIXME: Hook up error reporting for the stylesheet compilation process.\n    if (m_embedded)\n        return xsltLoadStylesheetPI(document());\n\n    // xsltParseStylesheetDoc makes the document part of the stylesheet\n    // so we have to release our pointer to it.\n    ASSERT(!m_stylesheetDocTaken);\n    xsltStylesheetPtr result = xsltParseStylesheetDoc(m_stylesheetDoc);\n    if (result)\n        m_stylesheetDocTaken = true;\n    return result;\n}",
        "func": "xsltStylesheetPtr XSLStyleSheet::compileStyleSheet()\n{\n    // FIXME: Hook up error reporting for the stylesheet compilation process.\n    if (m_embedded)\n        return xsltLoadStylesheetPI(document());\n\n    // Certain libxslt versions are corrupting the xmlDoc on compilation failures -\n    // hence attempting to recompile after a failure is unsafe.\n    if (m_compilationFailed)\n        return 0;\n\n    // xsltParseStylesheetDoc makes the document part of the stylesheet\n    // so we have to release our pointer to it.\n    ASSERT(!m_stylesheetDocTaken);\n    xsltStylesheetPtr result = xsltParseStylesheetDoc(m_stylesheetDoc);\n    if (result)\n        m_stylesheetDocTaken = true;\n    else\n        m_compilationFailed = true;\n    return result;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,6 +3,11 @@\n     // FIXME: Hook up error reporting for the stylesheet compilation process.\n     if (m_embedded)\n         return xsltLoadStylesheetPI(document());\n+\n+    // Certain libxslt versions are corrupting the xmlDoc on compilation failures -\n+    // hence attempting to recompile after a failure is unsafe.\n+    if (m_compilationFailed)\n+        return 0;\n \n     // xsltParseStylesheetDoc makes the document part of the stylesheet\n     // so we have to release our pointer to it.\n@@ -10,5 +15,7 @@\n     xsltStylesheetPtr result = xsltParseStylesheetDoc(m_stylesheetDoc);\n     if (result)\n         m_stylesheetDocTaken = true;\n+    else\n+        m_compilationFailed = true;\n     return result;\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "    // Certain libxslt versions are corrupting the xmlDoc on compilation failures -",
                "    // hence attempting to recompile after a failure is unsafe.",
                "    if (m_compilationFailed)",
                "        return 0;",
                "    else",
                "        m_compilationFailed = true;"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-2911",
        "func_name": "chromium/XSLStyleSheet::XSLStyleSheet",
        "description": "Use-after-free vulnerability in the XSLStyleSheet::compileStyleSheet function in core/xml/XSLStyleSheetLibxslt.cpp in Blink, as used in Google Chrome before 30.0.1599.66, allows remote attackers to cause a denial of service or possibly have unspecified other impact by leveraging improper handling of post-failure recompilation in unspecified libxslt versions.",
        "git_url": "https://github.com/chromium/chromium/commit/0220f39fac21d169a834ef91de362f4169f2eef5",
        "commit_title": "Avoid reparsing an XSLT stylesheet after the first failure.",
        "commit_text": " Certain libxslt versions appear to leave the doc in an invalid state when parsing fails. We should cache this result and avoid re-parsing.  (The test cannot be converted to text-only due to its invalid stylesheet).   ",
        "func_before": "XSLStyleSheet::XSLStyleSheet(XSLImportRule* parentRule, const String& originalURL, const KURL& finalURL)\n    : m_ownerNode(0)\n    , m_originalURL(originalURL)\n    , m_finalURL(finalURL)\n    , m_isDisabled(false)\n    , m_embedded(false)\n    , m_processed(false) // Child sheets get marked as processed when the libxslt engine has finally seen them.\n    , m_stylesheetDoc(0)\n    , m_stylesheetDocTaken(false)\n    , m_parentStyleSheet(parentRule ? parentRule->parentStyleSheet() : 0)\n{\n}",
        "func": "XSLStyleSheet::XSLStyleSheet(XSLImportRule* parentRule, const String& originalURL, const KURL& finalURL)\n    : m_ownerNode(0)\n    , m_originalURL(originalURL)\n    , m_finalURL(finalURL)\n    , m_isDisabled(false)\n    , m_embedded(false)\n    , m_processed(false) // Child sheets get marked as processed when the libxslt engine has finally seen them.\n    , m_stylesheetDoc(0)\n    , m_stylesheetDocTaken(false)\n    , m_compilationFailed(false)\n    , m_parentStyleSheet(parentRule ? parentRule->parentStyleSheet() : 0)\n{\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -7,6 +7,7 @@\n     , m_processed(false) // Child sheets get marked as processed when the libxslt engine has finally seen them.\n     , m_stylesheetDoc(0)\n     , m_stylesheetDocTaken(false)\n+    , m_compilationFailed(false)\n     , m_parentStyleSheet(parentRule ? parentRule->parentStyleSheet() : 0)\n {\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    , m_compilationFailed(false)"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-2911",
        "func_name": "chromium/XSLStyleSheet::XSLStyleSheet",
        "description": "Use-after-free vulnerability in the XSLStyleSheet::compileStyleSheet function in core/xml/XSLStyleSheetLibxslt.cpp in Blink, as used in Google Chrome before 30.0.1599.66, allows remote attackers to cause a denial of service or possibly have unspecified other impact by leveraging improper handling of post-failure recompilation in unspecified libxslt versions.",
        "git_url": "https://github.com/chromium/chromium/commit/0220f39fac21d169a834ef91de362f4169f2eef5",
        "commit_title": "Avoid reparsing an XSLT stylesheet after the first failure.",
        "commit_text": " Certain libxslt versions appear to leave the doc in an invalid state when parsing fails. We should cache this result and avoid re-parsing.  (The test cannot be converted to text-only due to its invalid stylesheet).   ",
        "func_before": "XSLStyleSheet::XSLStyleSheet(Node* parentNode, const String& originalURL, const KURL& finalURL,  bool embedded)\n    : m_ownerNode(parentNode)\n    , m_originalURL(originalURL)\n    , m_finalURL(finalURL)\n    , m_isDisabled(false)\n    , m_embedded(embedded)\n    , m_processed(true) // The root sheet starts off processed.\n    , m_stylesheetDoc(0)\n    , m_stylesheetDocTaken(false)\n    , m_parentStyleSheet(0)\n{\n}",
        "func": "XSLStyleSheet::XSLStyleSheet(Node* parentNode, const String& originalURL, const KURL& finalURL,  bool embedded)\n    : m_ownerNode(parentNode)\n    , m_originalURL(originalURL)\n    , m_finalURL(finalURL)\n    , m_isDisabled(false)\n    , m_embedded(embedded)\n    , m_processed(true) // The root sheet starts off processed.\n    , m_stylesheetDoc(0)\n    , m_stylesheetDocTaken(false)\n    , m_compilationFailed(false)\n    , m_parentStyleSheet(0)\n{\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -7,6 +7,7 @@\n     , m_processed(true) // The root sheet starts off processed.\n     , m_stylesheetDoc(0)\n     , m_stylesheetDocTaken(false)\n+    , m_compilationFailed(false)\n     , m_parentStyleSheet(0)\n {\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    , m_compilationFailed(false)"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-2913",
        "func_name": "chromium/XMLDocumentParser::append",
        "description": "Use-after-free vulnerability in the XMLDocumentParser::append function in core/xml/parser/XMLDocumentParser.cpp in Blink, as used in Google Chrome before 30.0.1599.66, allows remote attackers to cause a denial of service or possibly have unspecified other impact via vectors involving an XML document.",
        "git_url": "https://github.com/chromium/chromium/commit/f3a93852bb05e19ac912c9e42f829c859a78dfc4",
        "commit_title": "Prevent crash due to XMLDocumentParser destruction",
        "commit_text": " This patch prevents a crash in XMLDocumentParser::append due to the parser being destructed through doWrite. Destructing the parser can lead to the subsequent isStopped() check to fail to return, but by keeping the parser alive we ensure isStopped() correctly exits.   ",
        "func_before": "void XMLDocumentParser::append(PassRefPtr<StringImpl> inputSource)\n{\n    SegmentedString source(inputSource);\n    if (m_sawXSLTransform || !m_sawFirstElement)\n        m_originalSourceForTransform.append(source);\n\n    if (isStopped() || m_sawXSLTransform)\n        return;\n\n    if (m_parserPaused) {\n        m_pendingSrc.append(source);\n        return;\n    }\n\n    doWrite(source.toString());\n\n    if (isStopped())\n        return;\n\n    if (document()->frame() && document()->frame()->script()->canExecuteScripts(NotAboutToExecuteScript))\n        ImageLoader::dispatchPendingBeforeLoadEvents();\n}",
        "func": "void XMLDocumentParser::append(PassRefPtr<StringImpl> inputSource)\n{\n    SegmentedString source(inputSource);\n    if (m_sawXSLTransform || !m_sawFirstElement)\n        m_originalSourceForTransform.append(source);\n\n    if (isStopped() || m_sawXSLTransform)\n        return;\n\n    if (m_parserPaused) {\n        m_pendingSrc.append(source);\n        return;\n    }\n\n    // JavaScript can detach the parser. Make sure this is not released\n    // before the end of this method.\n    RefPtr<XMLDocumentParser> protect(this);\n\n    doWrite(source.toString());\n\n    if (isStopped())\n        return;\n\n    if (document()->frame() && document()->frame()->script()->canExecuteScripts(NotAboutToExecuteScript))\n        ImageLoader::dispatchPendingBeforeLoadEvents();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -12,6 +12,10 @@\n         return;\n     }\n \n+    // JavaScript can detach the parser. Make sure this is not released\n+    // before the end of this method.\n+    RefPtr<XMLDocumentParser> protect(this);\n+\n     doWrite(source.toString());\n \n     if (isStopped())",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    // JavaScript can detach the parser. Make sure this is not released",
                "    // before the end of this method.",
                "    RefPtr<XMLDocumentParser> protect(this);",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2013-2914",
        "func_name": "chromium/ColorChooserDialog::DidCloseDialog",
        "description": "Use-after-free vulnerability in the color-chooser dialog in Google Chrome before 30.0.1599.66 on Windows allows remote attackers to cause a denial of service or possibly have unspecified other impact via vectors related to color_chooser_dialog.cc and color_chooser_win.cc in browser/ui/views/.",
        "git_url": "https://github.com/chromium/chromium/commit/5ecc8d42ff888ff8b459df566208e7e01a3be5ba",
        "commit_title": "ColorChooserWin::End should act like the dialog has closed",
        "commit_text": " This is only a problem on Windows.  When the page closes itself while the color chooser dialog is open, ColorChooserDialog::DidCloseDialog was called after the listener has been destroyed.  ColorChooserWin::End() will not actually close the color chooser dialog (because we can't) but act like it did so we can do the necessary cleanup.   ",
        "func_before": "void ColorChooserDialog::DidCloseDialog(bool chose_color,\n                                        SkColor color,\n                                        RunState run_state) {\n  if (!listener_)\n    return;\n  EndRun(run_state);\n  CopyCustomColors(custom_colors_, g_custom_colors);\n  if (chose_color)\n    listener_->OnColorChosen(color);\n  listener_->OnColorChooserDialogClosed();\n}",
        "func": "void ColorChooserDialog::DidCloseDialog(bool chose_color,\n                                        SkColor color,\n                                        RunState run_state) {\n  EndRun(run_state);\n  CopyCustomColors(custom_colors_, g_custom_colors);\n  if (listener_) {\n    if (chose_color)\n      listener_->OnColorChosen(color);\n    listener_->OnColorChooserDialogClosed();\n  }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,11 +1,11 @@\n void ColorChooserDialog::DidCloseDialog(bool chose_color,\n                                         SkColor color,\n                                         RunState run_state) {\n-  if (!listener_)\n-    return;\n   EndRun(run_state);\n   CopyCustomColors(custom_colors_, g_custom_colors);\n-  if (chose_color)\n-    listener_->OnColorChosen(color);\n-  listener_->OnColorChooserDialogClosed();\n+  if (listener_) {\n+    if (chose_color)\n+      listener_->OnColorChosen(color);\n+    listener_->OnColorChooserDialogClosed();\n+  }\n }",
        "diff_line_info": {
            "deleted_lines": [
                "  if (!listener_)",
                "    return;",
                "  if (chose_color)",
                "    listener_->OnColorChosen(color);",
                "  listener_->OnColorChooserDialogClosed();"
            ],
            "added_lines": [
                "  if (listener_) {",
                "    if (chose_color)",
                "      listener_->OnColorChosen(color);",
                "    listener_->OnColorChooserDialogClosed();",
                "  }"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-2918",
        "func_name": "chromium/RenderBlock::removeChild",
        "description": "Use-after-free vulnerability in the RenderBlock::collapseAnonymousBlockChild function in core/rendering/RenderBlock.cpp in the DOM implementation in Blink, as used in Google Chrome before 30.0.1599.66, allows remote attackers to cause a denial of service or possibly have unspecified other impact by leveraging incorrect handling of parent-child relationships for anonymous blocks.",
        "git_url": "https://github.com/chromium/chromium/commit/1b7ff2a8799dd3f0365b3c3358c97fe99a4287dc",
        "commit_title": "Avoid collapsing anonymous block children already being destroyed",
        "commit_text": " When normalizing a block with anonymous blocks for first-letter, before content, and contained text, a collapsing anonymous block cascade is triggered that attempts to collapse the contained text's anonymous block within its destruction method. To avoid this, adding logic to bail early if we're already destroying the child anonymous block we're trying to collapse.  While in the function, doing a little cleanup to make it more obvious that it only operates on RenderBlocks, not RenderBoxes, and updating some of the comments to hopefully be more useful.   ",
        "func_before": "void RenderBlock::removeChild(RenderObject* oldChild)\n{\n    // No need to waste time in merging or removing empty anonymous blocks.\n    // We can just bail out if our document is getting destroyed.\n    if (documentBeingDestroyed()) {\n        RenderBox::removeChild(oldChild);\n        return;\n    }\n\n    // This protects against column split flows when anonymous blocks are getting merged.\n    TemporaryChange<bool> columnFlowSplitEnabled(gColumnFlowSplitEnabled, false);\n\n    // If this child is a block, and if our previous and next siblings are\n    // both anonymous blocks with inline content, then we can go ahead and\n    // fold the inline content back together.\n    RenderObject* prev = oldChild->previousSibling();\n    RenderObject* next = oldChild->nextSibling();\n    bool canMergeAnonymousBlocks = canMergeContiguousAnonymousBlocks(oldChild, prev, next);\n    if (canMergeAnonymousBlocks && prev && next) {\n        prev->setNeedsLayoutAndPrefWidthsRecalc();\n        RenderBlock* nextBlock = toRenderBlock(next);\n        RenderBlock* prevBlock = toRenderBlock(prev);\n\n        if (prev->childrenInline() != next->childrenInline()) {\n            RenderBlock* inlineChildrenBlock = prev->childrenInline() ? prevBlock : nextBlock;\n            RenderBlock* blockChildrenBlock = prev->childrenInline() ? nextBlock : prevBlock;\n\n            // Place the inline children block inside of the block children block instead of deleting it.\n            // In order to reuse it, we have to reset it to just be a generic anonymous block.  Make sure\n            // to clear out inherited column properties by just making a new style, and to also clear the\n            // column span flag if it is set.\n            ASSERT(!inlineChildrenBlock->continuation());\n            RefPtr<RenderStyle> newStyle = RenderStyle::createAnonymousStyleWithDisplay(style(), BLOCK);\n            // Cache this value as it might get changed in setStyle() call.\n            bool inlineChildrenBlockHasLayer = inlineChildrenBlock->hasLayer();\n            inlineChildrenBlock->setStyle(newStyle);\n            children()->removeChildNode(this, inlineChildrenBlock, inlineChildrenBlockHasLayer);\n\n            // Now just put the inlineChildrenBlock inside the blockChildrenBlock.\n            blockChildrenBlock->children()->insertChildNode(blockChildrenBlock, inlineChildrenBlock, prev == inlineChildrenBlock ? blockChildrenBlock->firstChild() : 0,\n                                                            inlineChildrenBlockHasLayer || blockChildrenBlock->hasLayer());\n            next->setNeedsLayoutAndPrefWidthsRecalc();\n\n            // inlineChildrenBlock got reparented to blockChildrenBlock, so it is no longer a child\n            // of \"this\". we null out prev or next so that is not used later in the function.\n            if (inlineChildrenBlock == prevBlock)\n                prev = 0;\n            else\n                next = 0;\n        } else {\n            // Take all the children out of the |next| block and put them in\n            // the |prev| block.\n            nextBlock->moveAllChildrenIncludingFloatsTo(prevBlock, nextBlock->hasLayer() || prevBlock->hasLayer());\n\n            // Delete the now-empty block's lines and nuke it.\n            nextBlock->deleteLineBoxTree();\n            nextBlock->destroy();\n            next = 0;\n        }\n    }\n\n    RenderBox::removeChild(oldChild);\n\n    RenderObject* child = prev ? prev : next;\n    if (canMergeAnonymousBlocks && child && !child->previousSibling() && !child->nextSibling() && canCollapseAnonymousBlockChild()) {\n        // The removal has knocked us down to containing only a single anonymous\n        // box.  We can go ahead and pull the content right back up into our\n        // box.\n        collapseAnonymousBoxChild(this, child);\n    } else if (((prev && prev->isAnonymousBlock()) || (next && next->isAnonymousBlock())) && canCollapseAnonymousBlockChild()) {\n        // It's possible that the removal has knocked us down to a single anonymous\n        // block with pseudo-style element siblings (e.g. first-letter). If these\n        // are floating, then we need to pull the content up also.\n        RenderBlock* anonBlock = toRenderBlock((prev && prev->isAnonymousBlock()) ? prev : next);\n        if ((anonBlock->previousSibling() || anonBlock->nextSibling())\n            && (!anonBlock->previousSibling() || (anonBlock->previousSibling()->style()->styleType() != NOPSEUDO && anonBlock->previousSibling()->isFloating() && !anonBlock->previousSibling()->previousSibling()))\n            && (!anonBlock->nextSibling() || (anonBlock->nextSibling()->style()->styleType() != NOPSEUDO && anonBlock->nextSibling()->isFloating() && !anonBlock->nextSibling()->nextSibling()))) {\n            collapseAnonymousBoxChild(this, anonBlock);\n        }\n    }\n\n    if (!firstChild()) {\n        // If this was our last child be sure to clear out our line boxes.\n        if (childrenInline())\n            deleteLineBoxTree();\n\n        // If we are an empty anonymous block in the continuation chain,\n        // we need to remove ourself and fix the continuation chain.\n        if (!beingDestroyed() && isAnonymousBlockContinuation() && !oldChild->isListMarker()) {\n            RenderObject* containingBlockIgnoringAnonymous = containingBlock();\n            while (containingBlockIgnoringAnonymous && containingBlockIgnoringAnonymous->isAnonymousBlock())\n                containingBlockIgnoringAnonymous = containingBlockIgnoringAnonymous->containingBlock();\n            for (RenderObject* curr = this; curr; curr = curr->previousInPreOrder(containingBlockIgnoringAnonymous)) {\n                if (curr->virtualContinuation() != this)\n                    continue;\n\n                // Found our previous continuation. We just need to point it to\n                // |this|'s next continuation.\n                RenderBoxModelObject* nextContinuation = continuation();\n                if (curr->isRenderInline())\n                    toRenderInline(curr)->setContinuation(nextContinuation);\n                else if (curr->isRenderBlock())\n                    toRenderBlock(curr)->setContinuation(nextContinuation);\n                else\n                    ASSERT_NOT_REACHED();\n\n                break;\n            }\n            setContinuation(0);\n            destroy();\n        }\n    }\n}",
        "func": "void RenderBlock::removeChild(RenderObject* oldChild)\n{\n    // No need to waste time in merging or removing empty anonymous blocks.\n    // We can just bail out if our document is getting destroyed.\n    if (documentBeingDestroyed()) {\n        RenderBox::removeChild(oldChild);\n        return;\n    }\n\n    // This protects against column split flows when anonymous blocks are getting merged.\n    TemporaryChange<bool> columnFlowSplitEnabled(gColumnFlowSplitEnabled, false);\n\n    // If this child is a block, and if our previous and next siblings are\n    // both anonymous blocks with inline content, then we can go ahead and\n    // fold the inline content back together.\n    RenderObject* prev = oldChild->previousSibling();\n    RenderObject* next = oldChild->nextSibling();\n    bool canMergeAnonymousBlocks = canMergeContiguousAnonymousBlocks(oldChild, prev, next);\n    if (canMergeAnonymousBlocks && prev && next) {\n        prev->setNeedsLayoutAndPrefWidthsRecalc();\n        RenderBlock* nextBlock = toRenderBlock(next);\n        RenderBlock* prevBlock = toRenderBlock(prev);\n\n        if (prev->childrenInline() != next->childrenInline()) {\n            RenderBlock* inlineChildrenBlock = prev->childrenInline() ? prevBlock : nextBlock;\n            RenderBlock* blockChildrenBlock = prev->childrenInline() ? nextBlock : prevBlock;\n\n            // Place the inline children block inside of the block children block instead of deleting it.\n            // In order to reuse it, we have to reset it to just be a generic anonymous block.  Make sure\n            // to clear out inherited column properties by just making a new style, and to also clear the\n            // column span flag if it is set.\n            ASSERT(!inlineChildrenBlock->continuation());\n            RefPtr<RenderStyle> newStyle = RenderStyle::createAnonymousStyleWithDisplay(style(), BLOCK);\n            // Cache this value as it might get changed in setStyle() call.\n            bool inlineChildrenBlockHasLayer = inlineChildrenBlock->hasLayer();\n            inlineChildrenBlock->setStyle(newStyle);\n            children()->removeChildNode(this, inlineChildrenBlock, inlineChildrenBlockHasLayer);\n\n            // Now just put the inlineChildrenBlock inside the blockChildrenBlock.\n            blockChildrenBlock->children()->insertChildNode(blockChildrenBlock, inlineChildrenBlock, prev == inlineChildrenBlock ? blockChildrenBlock->firstChild() : 0,\n                                                            inlineChildrenBlockHasLayer || blockChildrenBlock->hasLayer());\n            next->setNeedsLayoutAndPrefWidthsRecalc();\n\n            // inlineChildrenBlock got reparented to blockChildrenBlock, so it is no longer a child\n            // of \"this\". we null out prev or next so that is not used later in the function.\n            if (inlineChildrenBlock == prevBlock)\n                prev = 0;\n            else\n                next = 0;\n        } else {\n            // Take all the children out of the |next| block and put them in\n            // the |prev| block.\n            nextBlock->moveAllChildrenIncludingFloatsTo(prevBlock, nextBlock->hasLayer() || prevBlock->hasLayer());\n\n            // Delete the now-empty block's lines and nuke it.\n            nextBlock->deleteLineBoxTree();\n            nextBlock->destroy();\n            next = 0;\n        }\n    }\n\n    RenderBox::removeChild(oldChild);\n\n    RenderObject* child = prev ? prev : next;\n    if (canMergeAnonymousBlocks && child && !child->previousSibling() && !child->nextSibling() && canCollapseAnonymousBlockChild()) {\n        // The removal has knocked us down to containing only a single anonymous\n        // box.  We can go ahead and pull the content right back up into our\n        // box.\n        collapseAnonymousBlockChild(this, toRenderBlock(child));\n    } else if (((prev && prev->isAnonymousBlock()) || (next && next->isAnonymousBlock())) && canCollapseAnonymousBlockChild()) {\n        // It's possible that the removal has knocked us down to a single anonymous\n        // block with pseudo-style element siblings (e.g. first-letter). If these\n        // are floating, then we need to pull the content up also.\n        RenderBlock* anonymousBlock = toRenderBlock((prev && prev->isAnonymousBlock()) ? prev : next);\n        if ((anonymousBlock->previousSibling() || anonymousBlock->nextSibling())\n            && (!anonymousBlock->previousSibling() || (anonymousBlock->previousSibling()->style()->styleType() != NOPSEUDO && anonymousBlock->previousSibling()->isFloating() && !anonymousBlock->previousSibling()->previousSibling()))\n            && (!anonymousBlock->nextSibling() || (anonymousBlock->nextSibling()->style()->styleType() != NOPSEUDO && anonymousBlock->nextSibling()->isFloating() && !anonymousBlock->nextSibling()->nextSibling()))) {\n            collapseAnonymousBlockChild(this, anonymousBlock);\n        }\n    }\n\n    if (!firstChild()) {\n        // If this was our last child be sure to clear out our line boxes.\n        if (childrenInline())\n            deleteLineBoxTree();\n\n        // If we are an empty anonymous block in the continuation chain,\n        // we need to remove ourself and fix the continuation chain.\n        if (!beingDestroyed() && isAnonymousBlockContinuation() && !oldChild->isListMarker()) {\n            RenderObject* containingBlockIgnoringAnonymous = containingBlock();\n            while (containingBlockIgnoringAnonymous && containingBlockIgnoringAnonymous->isAnonymousBlock())\n                containingBlockIgnoringAnonymous = containingBlockIgnoringAnonymous->containingBlock();\n            for (RenderObject* curr = this; curr; curr = curr->previousInPreOrder(containingBlockIgnoringAnonymous)) {\n                if (curr->virtualContinuation() != this)\n                    continue;\n\n                // Found our previous continuation. We just need to point it to\n                // |this|'s next continuation.\n                RenderBoxModelObject* nextContinuation = continuation();\n                if (curr->isRenderInline())\n                    toRenderInline(curr)->setContinuation(nextContinuation);\n                else if (curr->isRenderBlock())\n                    toRenderBlock(curr)->setContinuation(nextContinuation);\n                else\n                    ASSERT_NOT_REACHED();\n\n                break;\n            }\n            setContinuation(0);\n            destroy();\n        }\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -66,16 +66,16 @@\n         // The removal has knocked us down to containing only a single anonymous\n         // box.  We can go ahead and pull the content right back up into our\n         // box.\n-        collapseAnonymousBoxChild(this, child);\n+        collapseAnonymousBlockChild(this, toRenderBlock(child));\n     } else if (((prev && prev->isAnonymousBlock()) || (next && next->isAnonymousBlock())) && canCollapseAnonymousBlockChild()) {\n         // It's possible that the removal has knocked us down to a single anonymous\n         // block with pseudo-style element siblings (e.g. first-letter). If these\n         // are floating, then we need to pull the content up also.\n-        RenderBlock* anonBlock = toRenderBlock((prev && prev->isAnonymousBlock()) ? prev : next);\n-        if ((anonBlock->previousSibling() || anonBlock->nextSibling())\n-            && (!anonBlock->previousSibling() || (anonBlock->previousSibling()->style()->styleType() != NOPSEUDO && anonBlock->previousSibling()->isFloating() && !anonBlock->previousSibling()->previousSibling()))\n-            && (!anonBlock->nextSibling() || (anonBlock->nextSibling()->style()->styleType() != NOPSEUDO && anonBlock->nextSibling()->isFloating() && !anonBlock->nextSibling()->nextSibling()))) {\n-            collapseAnonymousBoxChild(this, anonBlock);\n+        RenderBlock* anonymousBlock = toRenderBlock((prev && prev->isAnonymousBlock()) ? prev : next);\n+        if ((anonymousBlock->previousSibling() || anonymousBlock->nextSibling())\n+            && (!anonymousBlock->previousSibling() || (anonymousBlock->previousSibling()->style()->styleType() != NOPSEUDO && anonymousBlock->previousSibling()->isFloating() && !anonymousBlock->previousSibling()->previousSibling()))\n+            && (!anonymousBlock->nextSibling() || (anonymousBlock->nextSibling()->style()->styleType() != NOPSEUDO && anonymousBlock->nextSibling()->isFloating() && !anonymousBlock->nextSibling()->nextSibling()))) {\n+            collapseAnonymousBlockChild(this, anonymousBlock);\n         }\n     }\n ",
        "diff_line_info": {
            "deleted_lines": [
                "        collapseAnonymousBoxChild(this, child);",
                "        RenderBlock* anonBlock = toRenderBlock((prev && prev->isAnonymousBlock()) ? prev : next);",
                "        if ((anonBlock->previousSibling() || anonBlock->nextSibling())",
                "            && (!anonBlock->previousSibling() || (anonBlock->previousSibling()->style()->styleType() != NOPSEUDO && anonBlock->previousSibling()->isFloating() && !anonBlock->previousSibling()->previousSibling()))",
                "            && (!anonBlock->nextSibling() || (anonBlock->nextSibling()->style()->styleType() != NOPSEUDO && anonBlock->nextSibling()->isFloating() && !anonBlock->nextSibling()->nextSibling()))) {",
                "            collapseAnonymousBoxChild(this, anonBlock);"
            ],
            "added_lines": [
                "        collapseAnonymousBlockChild(this, toRenderBlock(child));",
                "        RenderBlock* anonymousBlock = toRenderBlock((prev && prev->isAnonymousBlock()) ? prev : next);",
                "        if ((anonymousBlock->previousSibling() || anonymousBlock->nextSibling())",
                "            && (!anonymousBlock->previousSibling() || (anonymousBlock->previousSibling()->style()->styleType() != NOPSEUDO && anonymousBlock->previousSibling()->isFloating() && !anonymousBlock->previousSibling()->previousSibling()))",
                "            && (!anonymousBlock->nextSibling() || (anonymousBlock->nextSibling()->style()->styleType() != NOPSEUDO && anonymousBlock->nextSibling()->isFloating() && !anonymousBlock->nextSibling()->nextSibling()))) {",
                "            collapseAnonymousBlockChild(this, anonymousBlock);"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-2921",
        "func_name": "chromium/ResourceFetcher::didLoadResource",
        "description": "Double free vulnerability in the ResourceFetcher::didLoadResource function in core/fetch/ResourceFetcher.cpp in the resource loader in Blink, as used in Google Chrome before 30.0.1599.66, allows remote attackers to cause a denial of service or possibly have unspecified other impact by triggering certain callback processing during the reporting of a resource entry.",
        "git_url": "https://github.com/chromium/chromium/commit/739caf62f8354c90010c385e73218f2dc6d66e2f",
        "commit_title": "[Resource Timing] Fix potential double free problem",
        "commit_text": "   Currently, ResourceTimingInfoMap in ResourceFetcher releases a  ResourceTimingInfo after a resource is reported.   If when blink is in reporting a resource entry, which lead to buffer full and  immediately invoke \"window.stop()\" as callback, it will dive into  ResourceFetcher::didLoadResource again, and release the memory in a nested.  After that,the outer double free the memory as it just report the entry.   This patch remove ResourceTiming from map ealier and prevent the double free case.  Contributed by lifeasageek@gmail.com and pan.deng@intel.com   ",
        "func_before": "void ResourceFetcher::didLoadResource(Resource* resource)\n{\n    RefPtr<DocumentLoader> protectDocumentLoader(m_documentLoader);\n    RefPtr<Document> protectDocument(m_document);\n\n    if (resource && resource->response().isHTTP() && ((!resource->errorOccurred() && !resource->wasCanceled()) || resource->response().httpStatusCode() == 304) && document()) {\n        ResourceTimingInfoMap::iterator it = m_resourceTimingInfoMap.find(resource);\n        if (it != m_resourceTimingInfoMap.end()) {\n            Document* initiatorDocument = document();\n            if (resource->type() == Resource::MainResource)\n                initiatorDocument = document()->parentDocument();\n            ASSERT(initiatorDocument);\n            RefPtr<ResourceTimingInfo> info = it->value;\n            info->setInitialRequest(resource->resourceRequest());\n            info->setFinalResponse(resource->response());\n            info->setLoadFinishTime(resource->loadFinishTime());\n            if (DOMWindow* initiatorWindow = initiatorDocument->domWindow())\n                initiatorWindow->performance()->addResourceTiming(*info, initiatorDocument);\n            m_resourceTimingInfoMap.remove(it);\n        }\n    }\n\n    if (frame())\n        frame()->loader()->loadDone();\n    performPostLoadActions();\n\n    if (!m_garbageCollectDocumentResourcesTimer.isActive())\n        m_garbageCollectDocumentResourcesTimer.startOneShot(0);\n}",
        "func": "void ResourceFetcher::didLoadResource(Resource* resource)\n{\n    RefPtr<DocumentLoader> protectDocumentLoader(m_documentLoader);\n    RefPtr<Document> protectDocument(m_document);\n\n    if (resource && resource->response().isHTTP() && ((!resource->errorOccurred() && !resource->wasCanceled()) || resource->response().httpStatusCode() == 304) && document()) {\n        ResourceTimingInfoMap::iterator it = m_resourceTimingInfoMap.find(resource);\n        if (it != m_resourceTimingInfoMap.end()) {\n            Document* initiatorDocument = document();\n            if (resource->type() == Resource::MainResource)\n                initiatorDocument = document()->parentDocument();\n            ASSERT(initiatorDocument);\n            RefPtr<ResourceTimingInfo> info = it->value;\n            m_resourceTimingInfoMap.remove(it);\n            info->setInitialRequest(resource->resourceRequest());\n            info->setFinalResponse(resource->response());\n            info->setLoadFinishTime(resource->loadFinishTime());\n            if (DOMWindow* initiatorWindow = initiatorDocument->domWindow())\n                initiatorWindow->performance()->addResourceTiming(*info, initiatorDocument);\n        }\n    }\n\n    if (frame())\n        frame()->loader()->loadDone();\n    performPostLoadActions();\n\n    if (!m_garbageCollectDocumentResourcesTimer.isActive())\n        m_garbageCollectDocumentResourcesTimer.startOneShot(0);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -11,12 +11,12 @@\n                 initiatorDocument = document()->parentDocument();\n             ASSERT(initiatorDocument);\n             RefPtr<ResourceTimingInfo> info = it->value;\n+            m_resourceTimingInfoMap.remove(it);\n             info->setInitialRequest(resource->resourceRequest());\n             info->setFinalResponse(resource->response());\n             info->setLoadFinishTime(resource->loadFinishTime());\n             if (DOMWindow* initiatorWindow = initiatorDocument->domWindow())\n                 initiatorWindow->performance()->addResourceTiming(*info, initiatorDocument);\n-            m_resourceTimingInfoMap.remove(it);\n         }\n     }\n ",
        "diff_line_info": {
            "deleted_lines": [
                "            m_resourceTimingInfoMap.remove(it);"
            ],
            "added_lines": [
                "            m_resourceTimingInfoMap.remove(it);"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-2922",
        "func_name": "chromium/HTMLTemplateElement::~HTMLTemplateElement",
        "description": "Use-after-free vulnerability in core/html/HTMLTemplateElement.cpp in Blink, as used in Google Chrome before 30.0.1599.66, allows remote attackers to cause a denial of service or possibly have unspecified other impact via crafted JavaScript code that operates on a TEMPLATE element.",
        "git_url": "https://github.com/chromium/chromium/commit/c168f9a06914e190a96e376544e93cf286a71fba",
        "commit_title": "Clear TemplateContentDocumentFragment::m_host when HTMLTemplateElement is destroyed",
        "commit_text": " Note that the included test only crashes reliably in an asan build.   ",
        "func_before": "HTMLTemplateElement::~HTMLTemplateElement()\n{\n}",
        "func": "HTMLTemplateElement::~HTMLTemplateElement()\n{\n    if (m_content)\n        m_content->clearHost();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,3 +1,5 @@\n HTMLTemplateElement::~HTMLTemplateElement()\n {\n+    if (m_content)\n+        m_content->clearHost();\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    if (m_content)",
                "        m_content->clearHost();"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-2925",
        "func_name": "chromium/XMLHttpRequest::createRequest",
        "description": "Use-after-free vulnerability in core/xml/XMLHttpRequest.cpp in Blink, as used in Google Chrome before 30.0.1599.101, allows remote attackers to cause a denial of service or possibly have unspecified other impact via vectors that trigger multiple conflicting uses of the same XMLHttpRequest object.",
        "git_url": "https://github.com/chromium/chromium/commit/a276a009de874306899f9c88edb722ae58d313f9",
        "commit_title": "[XHR] Abort method execution when m_loader->cancel() in internalAbort() caused reentry",
        "commit_text": " Calling cancel() on DocumentThreadableLoader may results in calling window.onload synchronously. If open(), send(), etc. are called on the same XMLHttpRequest object, it'll be hard to resolve conflict of states without losing spec conformance. This CL avoids that by just aborting execution of code for the outer method that calls internalAbort() if it returns false.   ",
        "func_before": "void XMLHttpRequest::createRequest(ExceptionState& es)\n{\n    // Only GET request is supported for blob URL.\n    if (m_url.protocolIs(\"blob\") && m_method != \"GET\") {\n        es.throwDOMException(NetworkError, ExceptionMessages::failedToExecute(\"send\", \"XMLHttpRequest\", \"'GET' is the only method allowed for 'blob:' URLs.\"));\n        return;\n    }\n\n    // The presence of upload event listeners forces us to use preflighting because POSTing to an URL that does not\n    // permit cross origin requests should look exactly like POSTing to an URL that does not respond at all.\n    // Also, only async requests support upload progress events.\n    bool uploadEvents = false;\n    if (m_async) {\n        m_progressEventThrottle.dispatchEvent(XMLHttpRequestProgressEvent::create(eventNames().loadstartEvent));\n        if (m_requestEntityBody && m_upload) {\n            uploadEvents = m_upload->hasEventListeners();\n            m_upload->dispatchEvent(XMLHttpRequestProgressEvent::create(eventNames().loadstartEvent));\n        }\n    }\n\n    m_sameOriginRequest = securityOrigin()->canRequest(m_url);\n\n    // We also remember whether upload events should be allowed for this request in case the upload listeners are\n    // added after the request is started.\n    m_uploadEventsAllowed = m_sameOriginRequest || uploadEvents || !isSimpleCrossOriginAccessRequest(m_method, m_requestHeaders);\n\n    ResourceRequest request(m_url);\n    request.setHTTPMethod(m_method);\n    request.setTargetType(ResourceRequest::TargetIsXHR);\n\n    InspectorInstrumentation::willLoadXHR(scriptExecutionContext(), this, m_method, m_url, m_async, m_requestEntityBody ? m_requestEntityBody->deepCopy() : 0, m_requestHeaders, m_includeCredentials);\n\n    if (m_requestEntityBody) {\n        ASSERT(m_method != \"GET\");\n        ASSERT(m_method != \"HEAD\");\n        request.setHTTPBody(m_requestEntityBody.release());\n    }\n\n    if (m_requestHeaders.size() > 0)\n        request.addHTTPHeaderFields(m_requestHeaders);\n\n    ThreadableLoaderOptions options;\n    options.sendLoadCallbacks = SendCallbacks;\n    options.sniffContent = DoNotSniffContent;\n    options.preflightPolicy = uploadEvents ? ForcePreflight : ConsiderPreflight;\n    options.allowCredentials = (m_sameOriginRequest || m_includeCredentials) ? AllowStoredCredentials : DoNotAllowStoredCredentials;\n    options.credentialsRequested = m_includeCredentials ? ClientRequestedCredentials : ClientDidNotRequestCredentials;\n    options.crossOriginRequestPolicy = UseAccessControl;\n    options.securityOrigin = securityOrigin();\n    options.initiator = FetchInitiatorTypeNames::xmlhttprequest;\n    options.contentSecurityPolicyEnforcement = ContentSecurityPolicy::shouldBypassMainWorld(scriptExecutionContext()) ? DoNotEnforceContentSecurityPolicy : EnforceConnectSrcDirective;\n    options.mixedContentBlockingTreatment = TreatAsActiveContent;\n    options.timeoutMilliseconds = m_timeoutMilliseconds;\n\n    m_exceptionCode = 0;\n    m_error = false;\n\n    if (m_async) {\n        if (m_upload)\n            request.setReportUploadProgress(true);\n\n        // ThreadableLoader::create can return null here, for example if we're no longer attached to a page.\n        // This is true while running onunload handlers.\n        // FIXME: Maybe we need to be able to send XMLHttpRequests from onunload, <http://bugs.webkit.org/show_bug.cgi?id=10904>.\n        // FIXME: Maybe create() can return null for other reasons too?\n        ASSERT(!m_loader);\n        m_loader = ThreadableLoader::create(scriptExecutionContext(), this, request, options);\n        if (m_loader) {\n            // Neither this object nor the JavaScript wrapper should be deleted while\n            // a request is in progress because we need to keep the listeners alive,\n            // and they are referenced by the JavaScript wrapper.\n\n            // m_loader was null, so there should be no pending activity at this point.\n            ASSERT(!hasPendingActivity());\n            setPendingActivity(this);\n        }\n    } else {\n        ThreadableLoader::loadResourceSynchronously(scriptExecutionContext(), request, *this, options);\n    }\n\n    if (!m_exceptionCode && m_error)\n        m_exceptionCode = NetworkError;\n    if (m_exceptionCode)\n        es.throwDOMException(m_exceptionCode);\n}",
        "func": "void XMLHttpRequest::createRequest(ExceptionState& es)\n{\n    // Only GET request is supported for blob URL.\n    if (m_url.protocolIs(\"blob\") && m_method != \"GET\") {\n        es.throwDOMException(NetworkError, ExceptionMessages::failedToExecute(\"send\", \"XMLHttpRequest\", \"'GET' is the only method allowed for 'blob:' URLs.\"));\n        return;\n    }\n\n    // The presence of upload event listeners forces us to use preflighting because POSTing to an URL that does not\n    // permit cross origin requests should look exactly like POSTing to an URL that does not respond at all.\n    // Also, only async requests support upload progress events.\n    bool uploadEvents = false;\n    if (m_async) {\n        m_progressEventThrottle.dispatchEvent(XMLHttpRequestProgressEvent::create(eventNames().loadstartEvent));\n        if (m_requestEntityBody && m_upload) {\n            uploadEvents = m_upload->hasEventListeners();\n            m_upload->dispatchEvent(XMLHttpRequestProgressEvent::create(eventNames().loadstartEvent));\n        }\n    }\n\n    m_sameOriginRequest = securityOrigin()->canRequest(m_url);\n\n    // We also remember whether upload events should be allowed for this request in case the upload listeners are\n    // added after the request is started.\n    m_uploadEventsAllowed = m_sameOriginRequest || uploadEvents || !isSimpleCrossOriginAccessRequest(m_method, m_requestHeaders);\n\n    ResourceRequest request(m_url);\n    request.setHTTPMethod(m_method);\n    request.setTargetType(ResourceRequest::TargetIsXHR);\n\n    InspectorInstrumentation::willLoadXHR(scriptExecutionContext(), this, m_method, m_url, m_async, m_requestEntityBody ? m_requestEntityBody->deepCopy() : 0, m_requestHeaders, m_includeCredentials);\n\n    if (m_requestEntityBody) {\n        ASSERT(m_method != \"GET\");\n        ASSERT(m_method != \"HEAD\");\n        request.setHTTPBody(m_requestEntityBody.release());\n    }\n\n    if (m_requestHeaders.size() > 0)\n        request.addHTTPHeaderFields(m_requestHeaders);\n\n    ThreadableLoaderOptions options;\n    options.sendLoadCallbacks = SendCallbacks;\n    options.sniffContent = DoNotSniffContent;\n    options.preflightPolicy = uploadEvents ? ForcePreflight : ConsiderPreflight;\n    options.allowCredentials = (m_sameOriginRequest || m_includeCredentials) ? AllowStoredCredentials : DoNotAllowStoredCredentials;\n    options.credentialsRequested = m_includeCredentials ? ClientRequestedCredentials : ClientDidNotRequestCredentials;\n    options.crossOriginRequestPolicy = UseAccessControl;\n    options.securityOrigin = securityOrigin();\n    options.initiator = FetchInitiatorTypeNames::xmlhttprequest;\n    options.contentSecurityPolicyEnforcement = ContentSecurityPolicy::shouldBypassMainWorld(scriptExecutionContext()) ? DoNotEnforceContentSecurityPolicy : EnforceConnectSrcDirective;\n    options.mixedContentBlockingTreatment = TreatAsActiveContent;\n    options.timeoutMilliseconds = m_timeoutMilliseconds;\n\n    m_exceptionCode = 0;\n    m_error = false;\n\n    if (m_async) {\n        if (m_upload)\n            request.setReportUploadProgress(true);\n\n        // ThreadableLoader::create can return null here, for example if we're no longer attached to a page.\n        // This is true while running onunload handlers.\n        // FIXME: Maybe we need to be able to send XMLHttpRequests from onunload, <http://bugs.webkit.org/show_bug.cgi?id=10904>.\n        // FIXME: Maybe create() can return null for other reasons too?\n        ASSERT(!m_loader);\n        m_loader = ThreadableLoader::create(scriptExecutionContext(), this, request, options);\n        if (m_loader) {\n            // Neither this object nor the JavaScript wrapper should be deleted while\n            // a request is in progress because we need to keep the listeners alive,\n            // and they are referenced by the JavaScript wrapper.\n            setPendingActivity(this);\n        }\n    } else {\n        ThreadableLoader::loadResourceSynchronously(scriptExecutionContext(), request, *this, options);\n    }\n\n    if (!m_exceptionCode && m_error)\n        m_exceptionCode = NetworkError;\n    if (m_exceptionCode)\n        es.throwDOMException(m_exceptionCode);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -69,9 +69,6 @@\n             // Neither this object nor the JavaScript wrapper should be deleted while\n             // a request is in progress because we need to keep the listeners alive,\n             // and they are referenced by the JavaScript wrapper.\n-\n-            // m_loader was null, so there should be no pending activity at this point.\n-            ASSERT(!hasPendingActivity());\n             setPendingActivity(this);\n         }\n     } else {",
        "diff_line_info": {
            "deleted_lines": [
                "",
                "            // m_loader was null, so there should be no pending activity at this point.",
                "            ASSERT(!hasPendingActivity());"
            ],
            "added_lines": []
        }
    },
    {
        "cve_id": "CVE-2013-2925",
        "func_name": "chromium/XMLHttpRequest::open",
        "description": "Use-after-free vulnerability in core/xml/XMLHttpRequest.cpp in Blink, as used in Google Chrome before 30.0.1599.101, allows remote attackers to cause a denial of service or possibly have unspecified other impact via vectors that trigger multiple conflicting uses of the same XMLHttpRequest object.",
        "git_url": "https://github.com/chromium/chromium/commit/a276a009de874306899f9c88edb722ae58d313f9",
        "commit_title": "[XHR] Abort method execution when m_loader->cancel() in internalAbort() caused reentry",
        "commit_text": " Calling cancel() on DocumentThreadableLoader may results in calling window.onload synchronously. If open(), send(), etc. are called on the same XMLHttpRequest object, it'll be hard to resolve conflict of states without losing spec conformance. This CL avoids that by just aborting execution of code for the outer method that calls internalAbort() if it returns false.   ",
        "func_before": "void XMLHttpRequest::open(const String& method, const KURL& url, bool async, ExceptionState& es)\n{\n    internalAbort();\n    State previousState = m_state;\n    m_state = UNSENT;\n    m_error = false;\n    m_uploadComplete = false;\n\n    // clear stuff from possible previous load\n    clearResponse();\n    clearRequest();\n\n    ASSERT(m_state == UNSENT);\n\n    if (!isValidHTTPToken(method)) {\n        es.throwDOMException(SyntaxError, ExceptionMessages::failedToExecute(\"open\", \"XMLHttpRequest\", \"'\" + method + \"' is not a valid HTTP method.\"));\n        return;\n    }\n\n    if (!isAllowedHTTPMethod(method)) {\n        es.throwSecurityError(ExceptionMessages::failedToExecute(\"open\", \"XMLHttpRequest\", \"'\" + method + \"' HTTP method is unsupported.\"));\n        return;\n    }\n\n    if (!ContentSecurityPolicy::shouldBypassMainWorld(scriptExecutionContext()) && !scriptExecutionContext()->contentSecurityPolicy()->allowConnectToSource(url)) {\n        // We can safely expose the URL to JavaScript, as these checks happen synchronously before redirection. JavaScript receives no new information.\n        es.throwSecurityError(\"Refused to connect to '\" + url.elidedString() + \"' because it violates the document's Content Security Policy.\");\n        return;\n    }\n\n    if (!async && scriptExecutionContext()->isDocument()) {\n        if (document()->settings() && !document()->settings()->syncXHRInDocumentsEnabled()) {\n            es.throwDOMException(InvalidAccessError, ExceptionMessages::failedToExecute(\"open\", \"XMLHttpRequest\", \"synchronous requests are disabled for this page.\"));\n            return;\n        }\n\n        // Newer functionality is not available to synchronous requests in window contexts, as a spec-mandated\n        // attempt to discourage synchronous XHR use. responseType is one such piece of functionality.\n        // We'll only disable this functionality for HTTP(S) requests since sync requests for local protocols\n        // such as file: and data: still make sense to allow.\n        if (url.protocolIsInHTTPFamily() && m_responseTypeCode != ResponseTypeDefault) {\n            es.throwDOMException(InvalidAccessError, ExceptionMessages::failedToExecute(\"open\", \"XMLHttpRequest\", \"synchronous HTTP requests from a document must not set a response type.\"));\n            return;\n        }\n\n        // Similarly, timeouts are disabled for synchronous requests as well.\n        if (m_timeoutMilliseconds > 0) {\n            es.throwDOMException(InvalidAccessError, ExceptionMessages::failedToExecute(\"open\", \"XMLHttpRequest\", \"synchronous requests must not set a timeout.\"));\n            return;\n        }\n    }\n\n    m_method = uppercaseKnownHTTPMethod(method);\n\n    m_url = url;\n\n    m_async = async;\n\n    ASSERT(!m_loader);\n\n    // Check previous state to avoid dispatching readyState event\n    // when calling open several times in a row.\n    if (previousState != OPENED)\n        changeState(OPENED);\n    else\n        m_state = OPENED;\n}",
        "func": "void XMLHttpRequest::open(const String& method, const KURL& url, bool async, ExceptionState& es)\n{\n    if (!internalAbort())\n        return;\n\n    State previousState = m_state;\n    m_state = UNSENT;\n    m_error = false;\n    m_uploadComplete = false;\n\n    // clear stuff from possible previous load\n    clearResponse();\n    clearRequest();\n\n    ASSERT(m_state == UNSENT);\n\n    if (!isValidHTTPToken(method)) {\n        es.throwDOMException(SyntaxError, ExceptionMessages::failedToExecute(\"open\", \"XMLHttpRequest\", \"'\" + method + \"' is not a valid HTTP method.\"));\n        return;\n    }\n\n    if (!isAllowedHTTPMethod(method)) {\n        es.throwSecurityError(ExceptionMessages::failedToExecute(\"open\", \"XMLHttpRequest\", \"'\" + method + \"' HTTP method is unsupported.\"));\n        return;\n    }\n\n    if (!ContentSecurityPolicy::shouldBypassMainWorld(scriptExecutionContext()) && !scriptExecutionContext()->contentSecurityPolicy()->allowConnectToSource(url)) {\n        // We can safely expose the URL to JavaScript, as these checks happen synchronously before redirection. JavaScript receives no new information.\n        es.throwSecurityError(\"Refused to connect to '\" + url.elidedString() + \"' because it violates the document's Content Security Policy.\");\n        return;\n    }\n\n    if (!async && scriptExecutionContext()->isDocument()) {\n        if (document()->settings() && !document()->settings()->syncXHRInDocumentsEnabled()) {\n            es.throwDOMException(InvalidAccessError, ExceptionMessages::failedToExecute(\"open\", \"XMLHttpRequest\", \"synchronous requests are disabled for this page.\"));\n            return;\n        }\n\n        // Newer functionality is not available to synchronous requests in window contexts, as a spec-mandated\n        // attempt to discourage synchronous XHR use. responseType is one such piece of functionality.\n        // We'll only disable this functionality for HTTP(S) requests since sync requests for local protocols\n        // such as file: and data: still make sense to allow.\n        if (url.protocolIsInHTTPFamily() && m_responseTypeCode != ResponseTypeDefault) {\n            es.throwDOMException(InvalidAccessError, ExceptionMessages::failedToExecute(\"open\", \"XMLHttpRequest\", \"synchronous HTTP requests from a document must not set a response type.\"));\n            return;\n        }\n\n        // Similarly, timeouts are disabled for synchronous requests as well.\n        if (m_timeoutMilliseconds > 0) {\n            es.throwDOMException(InvalidAccessError, ExceptionMessages::failedToExecute(\"open\", \"XMLHttpRequest\", \"synchronous requests must not set a timeout.\"));\n            return;\n        }\n    }\n\n    m_method = uppercaseKnownHTTPMethod(method);\n\n    m_url = url;\n\n    m_async = async;\n\n    ASSERT(!m_loader);\n\n    // Check previous state to avoid dispatching readyState event\n    // when calling open several times in a row.\n    if (previousState != OPENED)\n        changeState(OPENED);\n    else\n        m_state = OPENED;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,8 @@\n void XMLHttpRequest::open(const String& method, const KURL& url, bool async, ExceptionState& es)\n {\n-    internalAbort();\n+    if (!internalAbort())\n+        return;\n+\n     State previousState = m_state;\n     m_state = UNSENT;\n     m_error = false;",
        "diff_line_info": {
            "deleted_lines": [
                "    internalAbort();"
            ],
            "added_lines": [
                "    if (!internalAbort())",
                "        return;",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2013-2925",
        "func_name": "chromium/XMLHttpRequest::abort",
        "description": "Use-after-free vulnerability in core/xml/XMLHttpRequest.cpp in Blink, as used in Google Chrome before 30.0.1599.101, allows remote attackers to cause a denial of service or possibly have unspecified other impact via vectors that trigger multiple conflicting uses of the same XMLHttpRequest object.",
        "git_url": "https://github.com/chromium/chromium/commit/a276a009de874306899f9c88edb722ae58d313f9",
        "commit_title": "[XHR] Abort method execution when m_loader->cancel() in internalAbort() caused reentry",
        "commit_text": " Calling cancel() on DocumentThreadableLoader may results in calling window.onload synchronously. If open(), send(), etc. are called on the same XMLHttpRequest object, it'll be hard to resolve conflict of states without losing spec conformance. This CL avoids that by just aborting execution of code for the outer method that calls internalAbort() if it returns false.   ",
        "func_before": "void XMLHttpRequest::abort()\n{\n    // internalAbort() calls dropProtection(), which may release the last reference.\n    RefPtr<XMLHttpRequest> protect(this);\n\n    bool sendFlag = m_loader;\n\n    internalAbort();\n\n    clearResponseBuffers();\n\n    // Clear headers as required by the spec\n    m_requestHeaders.clear();\n\n    if ((m_state <= OPENED && !sendFlag) || m_state == DONE)\n        m_state = UNSENT;\n    else {\n        ASSERT(!m_loader);\n        changeState(DONE);\n        m_state = UNSENT;\n    }\n\n    m_progressEventThrottle.dispatchEventAndLoadEnd(XMLHttpRequestProgressEvent::create(eventNames().abortEvent));\n    if (!m_uploadComplete) {\n        m_uploadComplete = true;\n        if (m_upload && m_uploadEventsAllowed)\n            m_upload->dispatchEventAndLoadEnd(XMLHttpRequestProgressEvent::create(eventNames().abortEvent));\n    }\n}",
        "func": "void XMLHttpRequest::abort()\n{\n    // internalAbort() calls dropProtection(), which may release the last reference.\n    RefPtr<XMLHttpRequest> protect(this);\n\n    bool sendFlag = m_loader;\n\n    if (!internalAbort())\n        return;\n\n    clearResponseBuffers();\n\n    // Clear headers as required by the spec\n    m_requestHeaders.clear();\n\n    if ((m_state <= OPENED && !sendFlag) || m_state == DONE)\n        m_state = UNSENT;\n    else {\n        ASSERT(!m_loader);\n        changeState(DONE);\n        m_state = UNSENT;\n    }\n\n    m_progressEventThrottle.dispatchEventAndLoadEnd(XMLHttpRequestProgressEvent::create(eventNames().abortEvent));\n    if (!m_uploadComplete) {\n        m_uploadComplete = true;\n        if (m_upload && m_uploadEventsAllowed)\n            m_upload->dispatchEventAndLoadEnd(XMLHttpRequestProgressEvent::create(eventNames().abortEvent));\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,7 +5,8 @@\n \n     bool sendFlag = m_loader;\n \n-    internalAbort();\n+    if (!internalAbort())\n+        return;\n \n     clearResponseBuffers();\n ",
        "diff_line_info": {
            "deleted_lines": [
                "    internalAbort();"
            ],
            "added_lines": [
                "    if (!internalAbort())",
                "        return;"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-2925",
        "func_name": "chromium/XMLHttpRequest::internalAbort",
        "description": "Use-after-free vulnerability in core/xml/XMLHttpRequest.cpp in Blink, as used in Google Chrome before 30.0.1599.101, allows remote attackers to cause a denial of service or possibly have unspecified other impact via vectors that trigger multiple conflicting uses of the same XMLHttpRequest object.",
        "git_url": "https://github.com/chromium/chromium/commit/a276a009de874306899f9c88edb722ae58d313f9",
        "commit_title": "[XHR] Abort method execution when m_loader->cancel() in internalAbort() caused reentry",
        "commit_text": " Calling cancel() on DocumentThreadableLoader may results in calling window.onload synchronously. If open(), send(), etc. are called on the same XMLHttpRequest object, it'll be hard to resolve conflict of states without losing spec conformance. This CL avoids that by just aborting execution of code for the outer method that calls internalAbort() if it returns false.   ",
        "func_before": "void XMLHttpRequest::internalAbort(DropProtection async)\n{\n    m_error = true;\n\n    // FIXME: when we add the support for multi-part XHR, we will have to think be careful with this initialization.\n    m_receivedLength = 0;\n    m_decoder = 0;\n\n    InspectorInstrumentation::didFailXHRLoading(scriptExecutionContext(), this);\n\n    if (m_responseStream && m_state != DONE)\n        m_responseStream->abort();\n\n    if (!m_loader)\n        return;\n\n    m_loader->cancel();\n    m_loader = 0;\n\n    if (async == DropProtectionAsync)\n        dropProtectionSoon();\n    else\n        dropProtection();\n}",
        "func": "bool XMLHttpRequest::internalAbort(DropProtection async)\n{\n    m_error = true;\n\n    // FIXME: when we add the support for multi-part XHR, we will have to think be careful with this initialization.\n    m_receivedLength = 0;\n    m_decoder = 0;\n\n    InspectorInstrumentation::didFailXHRLoading(scriptExecutionContext(), this);\n\n    if (m_responseStream && m_state != DONE)\n        m_responseStream->abort();\n\n    if (!m_loader)\n        return true;\n\n    // Cancelling the ThreadableLoader m_loader may result in calling\n    // window.onload synchronously. If such an onload handler contains open()\n    // call on the same XMLHttpRequest object, reentry happens. If m_loader\n    // is left to be non 0, internalAbort() call for the inner open() makes\n    // an extra dropProtection() call (when we're back to the outer open(),\n    // we'll call dropProtection()). To avoid that, clears m_loader before\n    // calling cancel.\n    //\n    // If, window.onload contains open() and send(), m_loader will be set to\n    // non 0 value. So, we cannot continue the outer open(). In such case,\n    // just abort the outer open() by returning false.\n    RefPtr<ThreadableLoader> loader = m_loader.release();\n    loader->cancel();\n\n    // Save to a local variable since we're going to drop protection.\n    bool newLoadStarted = m_loader;\n\n    if (async == DropProtectionAsync)\n        dropProtectionSoon();\n    else\n        dropProtection();\n\n    return !newLoadStarted;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,4 +1,4 @@\n-void XMLHttpRequest::internalAbort(DropProtection async)\n+bool XMLHttpRequest::internalAbort(DropProtection async)\n {\n     m_error = true;\n \n@@ -12,13 +12,29 @@\n         m_responseStream->abort();\n \n     if (!m_loader)\n-        return;\n+        return true;\n \n-    m_loader->cancel();\n-    m_loader = 0;\n+    // Cancelling the ThreadableLoader m_loader may result in calling\n+    // window.onload synchronously. If such an onload handler contains open()\n+    // call on the same XMLHttpRequest object, reentry happens. If m_loader\n+    // is left to be non 0, internalAbort() call for the inner open() makes\n+    // an extra dropProtection() call (when we're back to the outer open(),\n+    // we'll call dropProtection()). To avoid that, clears m_loader before\n+    // calling cancel.\n+    //\n+    // If, window.onload contains open() and send(), m_loader will be set to\n+    // non 0 value. So, we cannot continue the outer open(). In such case,\n+    // just abort the outer open() by returning false.\n+    RefPtr<ThreadableLoader> loader = m_loader.release();\n+    loader->cancel();\n+\n+    // Save to a local variable since we're going to drop protection.\n+    bool newLoadStarted = m_loader;\n \n     if (async == DropProtectionAsync)\n         dropProtectionSoon();\n     else\n         dropProtection();\n+\n+    return !newLoadStarted;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "void XMLHttpRequest::internalAbort(DropProtection async)",
                "        return;",
                "    m_loader->cancel();",
                "    m_loader = 0;"
            ],
            "added_lines": [
                "bool XMLHttpRequest::internalAbort(DropProtection async)",
                "        return true;",
                "    // Cancelling the ThreadableLoader m_loader may result in calling",
                "    // window.onload synchronously. If such an onload handler contains open()",
                "    // call on the same XMLHttpRequest object, reentry happens. If m_loader",
                "    // is left to be non 0, internalAbort() call for the inner open() makes",
                "    // an extra dropProtection() call (when we're back to the outer open(),",
                "    // we'll call dropProtection()). To avoid that, clears m_loader before",
                "    // calling cancel.",
                "    //",
                "    // If, window.onload contains open() and send(), m_loader will be set to",
                "    // non 0 value. So, we cannot continue the outer open(). In such case,",
                "    // just abort the outer open() by returning false.",
                "    RefPtr<ThreadableLoader> loader = m_loader.release();",
                "    loader->cancel();",
                "",
                "    // Save to a local variable since we're going to drop protection.",
                "    bool newLoadStarted = m_loader;",
                "",
                "    return !newLoadStarted;"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-2925",
        "func_name": "chromium/XMLHttpRequest::handleDidTimeout",
        "description": "Use-after-free vulnerability in core/xml/XMLHttpRequest.cpp in Blink, as used in Google Chrome before 30.0.1599.101, allows remote attackers to cause a denial of service or possibly have unspecified other impact via vectors that trigger multiple conflicting uses of the same XMLHttpRequest object.",
        "git_url": "https://github.com/chromium/chromium/commit/a276a009de874306899f9c88edb722ae58d313f9",
        "commit_title": "[XHR] Abort method execution when m_loader->cancel() in internalAbort() caused reentry",
        "commit_text": " Calling cancel() on DocumentThreadableLoader may results in calling window.onload synchronously. If open(), send(), etc. are called on the same XMLHttpRequest object, it'll be hard to resolve conflict of states without losing spec conformance. This CL avoids that by just aborting execution of code for the outer method that calls internalAbort() if it returns false.   ",
        "func_before": "void XMLHttpRequest::handleDidTimeout()\n{\n    // internalAbort() calls dropProtection(), which may release the last reference.\n    RefPtr<XMLHttpRequest> protect(this);\n    internalAbort();\n\n    m_exceptionCode = TimeoutError;\n\n    handleDidFailGeneric();\n\n    if (!m_async) {\n        m_state = DONE;\n        return;\n    }\n    changeState(DONE);\n\n    dispatchEventAndLoadEnd(eventNames().timeoutEvent);\n}",
        "func": "void XMLHttpRequest::handleDidTimeout()\n{\n    // internalAbort() calls dropProtection(), which may release the last reference.\n    RefPtr<XMLHttpRequest> protect(this);\n\n    if (!internalAbort())\n        return;\n\n    m_exceptionCode = TimeoutError;\n\n    handleDidFailGeneric();\n\n    if (!m_async) {\n        m_state = DONE;\n        return;\n    }\n    changeState(DONE);\n\n    dispatchEventAndLoadEnd(eventNames().timeoutEvent);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,7 +2,9 @@\n {\n     // internalAbort() calls dropProtection(), which may release the last reference.\n     RefPtr<XMLHttpRequest> protect(this);\n-    internalAbort();\n+\n+    if (!internalAbort())\n+        return;\n \n     m_exceptionCode = TimeoutError;\n ",
        "diff_line_info": {
            "deleted_lines": [
                "    internalAbort();"
            ],
            "added_lines": [
                "",
                "    if (!internalAbort())",
                "        return;"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-2926",
        "func_name": "chromium/IndentOutdentCommand::tryIndentingAsListItem",
        "description": "Use-after-free vulnerability in the IndentOutdentCommand::tryIndentingAsListItem function in core/editing/IndentOutdentCommand.cpp in Blink, as used in Google Chrome before 30.0.1599.101, allows user-assisted remote attackers to cause a denial of service or possibly have unspecified other impact via vectors related to list elements.",
        "git_url": "https://github.com/chromium/chromium/commit/24c7296e95a3f2518d9a84d262d806a87a07099a",
        "commit_title": "Protect DOM nodes in IndentOutdentCommand::tryIndentingAsListItem()",
        "commit_text": " This patch changes IndentOutdentCommand::tryIndentingAsListItem() to use RefPtr<T> instead of raw pointer for Node and Element not to remove during insertNodeBefore() and moveParagraphWIthClones() calls, which can execute user script to remove DOM nodes.  Note: When I tried to run a test case created by cluster fuzz, content_shell doesn't fail. It is hard to create a test case by hand.   ",
        "func_before": "bool IndentOutdentCommand::tryIndentingAsListItem(const Position& start, const Position& end)\n{\n    // If our selection is not inside a list, bail out.\n    Node* lastNodeInSelectedParagraph = start.deprecatedNode();\n    RefPtr<Element> listNode = enclosingList(lastNodeInSelectedParagraph);\n    if (!listNode)\n        return false;\n\n    // Find the block that we want to indent.  If it's not a list item (e.g., a div inside a list item), we bail out.\n    Element* selectedListItem = enclosingBlock(lastNodeInSelectedParagraph);\n\n    // FIXME: we need to deal with the case where there is no li (malformed HTML)\n    if (!selectedListItem->hasTagName(liTag))\n        return false;\n\n    // FIXME: previousElementSibling does not ignore non-rendered content like <span></span>.  Should we?\n    Element* previousList = selectedListItem->previousElementSibling();\n    Element* nextList = selectedListItem->nextElementSibling();\n\n    RefPtr<Element> newList = document().createElement(listNode->tagQName(), false);\n    insertNodeBefore(newList, selectedListItem);\n\n    moveParagraphWithClones(start, end, newList.get(), selectedListItem);\n\n    if (canMergeLists(previousList, newList.get()))\n        mergeIdenticalElements(previousList, newList);\n    if (canMergeLists(newList.get(), nextList))\n        mergeIdenticalElements(newList, nextList);\n\n    return true;\n}",
        "func": "bool IndentOutdentCommand::tryIndentingAsListItem(const Position& start, const Position& end)\n{\n    // If our selection is not inside a list, bail out.\n    RefPtr<Node> lastNodeInSelectedParagraph = start.deprecatedNode();\n    RefPtr<Element> listNode = enclosingList(lastNodeInSelectedParagraph.get());\n    if (!listNode)\n        return false;\n\n    // Find the block that we want to indent.  If it's not a list item (e.g., a div inside a list item), we bail out.\n    RefPtr<Element> selectedListItem = enclosingBlock(lastNodeInSelectedParagraph.get());\n\n    // FIXME: we need to deal with the case where there is no li (malformed HTML)\n    if (!selectedListItem->hasTagName(liTag))\n        return false;\n\n    // FIXME: previousElementSibling does not ignore non-rendered content like <span></span>.  Should we?\n    RefPtr<Element> previousList = selectedListItem->previousElementSibling();\n    RefPtr<Element> nextList = selectedListItem->nextElementSibling();\n\n    RefPtr<Element> newList = document().createElement(listNode->tagQName(), false);\n    insertNodeBefore(newList, selectedListItem.get());\n\n    moveParagraphWithClones(start, end, newList.get(), selectedListItem.get());\n\n    if (canMergeLists(previousList.get(), newList.get()))\n        mergeIdenticalElements(previousList.get(), newList.get());\n    if (canMergeLists(newList.get(), nextList.get()))\n        mergeIdenticalElements(newList.get(), nextList.get());\n\n    return true;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,31 +1,31 @@\n bool IndentOutdentCommand::tryIndentingAsListItem(const Position& start, const Position& end)\n {\n     // If our selection is not inside a list, bail out.\n-    Node* lastNodeInSelectedParagraph = start.deprecatedNode();\n-    RefPtr<Element> listNode = enclosingList(lastNodeInSelectedParagraph);\n+    RefPtr<Node> lastNodeInSelectedParagraph = start.deprecatedNode();\n+    RefPtr<Element> listNode = enclosingList(lastNodeInSelectedParagraph.get());\n     if (!listNode)\n         return false;\n \n     // Find the block that we want to indent.  If it's not a list item (e.g., a div inside a list item), we bail out.\n-    Element* selectedListItem = enclosingBlock(lastNodeInSelectedParagraph);\n+    RefPtr<Element> selectedListItem = enclosingBlock(lastNodeInSelectedParagraph.get());\n \n     // FIXME: we need to deal with the case where there is no li (malformed HTML)\n     if (!selectedListItem->hasTagName(liTag))\n         return false;\n \n     // FIXME: previousElementSibling does not ignore non-rendered content like <span></span>.  Should we?\n-    Element* previousList = selectedListItem->previousElementSibling();\n-    Element* nextList = selectedListItem->nextElementSibling();\n+    RefPtr<Element> previousList = selectedListItem->previousElementSibling();\n+    RefPtr<Element> nextList = selectedListItem->nextElementSibling();\n \n     RefPtr<Element> newList = document().createElement(listNode->tagQName(), false);\n-    insertNodeBefore(newList, selectedListItem);\n+    insertNodeBefore(newList, selectedListItem.get());\n \n-    moveParagraphWithClones(start, end, newList.get(), selectedListItem);\n+    moveParagraphWithClones(start, end, newList.get(), selectedListItem.get());\n \n-    if (canMergeLists(previousList, newList.get()))\n-        mergeIdenticalElements(previousList, newList);\n-    if (canMergeLists(newList.get(), nextList))\n-        mergeIdenticalElements(newList, nextList);\n+    if (canMergeLists(previousList.get(), newList.get()))\n+        mergeIdenticalElements(previousList.get(), newList.get());\n+    if (canMergeLists(newList.get(), nextList.get()))\n+        mergeIdenticalElements(newList.get(), nextList.get());\n \n     return true;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    Node* lastNodeInSelectedParagraph = start.deprecatedNode();",
                "    RefPtr<Element> listNode = enclosingList(lastNodeInSelectedParagraph);",
                "    Element* selectedListItem = enclosingBlock(lastNodeInSelectedParagraph);",
                "    Element* previousList = selectedListItem->previousElementSibling();",
                "    Element* nextList = selectedListItem->nextElementSibling();",
                "    insertNodeBefore(newList, selectedListItem);",
                "    moveParagraphWithClones(start, end, newList.get(), selectedListItem);",
                "    if (canMergeLists(previousList, newList.get()))",
                "        mergeIdenticalElements(previousList, newList);",
                "    if (canMergeLists(newList.get(), nextList))",
                "        mergeIdenticalElements(newList, nextList);"
            ],
            "added_lines": [
                "    RefPtr<Node> lastNodeInSelectedParagraph = start.deprecatedNode();",
                "    RefPtr<Element> listNode = enclosingList(lastNodeInSelectedParagraph.get());",
                "    RefPtr<Element> selectedListItem = enclosingBlock(lastNodeInSelectedParagraph.get());",
                "    RefPtr<Element> previousList = selectedListItem->previousElementSibling();",
                "    RefPtr<Element> nextList = selectedListItem->nextElementSibling();",
                "    insertNodeBefore(newList, selectedListItem.get());",
                "    moveParagraphWithClones(start, end, newList.get(), selectedListItem.get());",
                "    if (canMergeLists(previousList.get(), newList.get()))",
                "        mergeIdenticalElements(previousList.get(), newList.get());",
                "    if (canMergeLists(newList.get(), nextList.get()))",
                "        mergeIdenticalElements(newList.get(), nextList.get());"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-2927",
        "func_name": "chromium/HTMLFormElement::prepareForSubmission",
        "description": "Use-after-free vulnerability in the HTMLFormElement::prepareForSubmission function in core/html/HTMLFormElement.cpp in Blink, as used in Google Chrome before 30.0.1599.101, allows remote attackers to cause a denial of service or possibly have unspecified other impact via vectors related to submission for FORM elements.",
        "git_url": "https://github.com/chromium/chromium/commit/4d77eed905ce1d00361282e8822a2a3be61d25c0",
        "commit_title": "Fix a crash in HTMLFormElement::prepareForSubmission.",
        "commit_text": "  ",
        "func_before": "bool HTMLFormElement::prepareForSubmission(Event* event)\n{\n    Frame* frame = document().frame();\n    if (m_isSubmittingOrPreparingForSubmission || !frame)\n        return m_isSubmittingOrPreparingForSubmission;\n\n    m_isSubmittingOrPreparingForSubmission = true;\n    m_shouldSubmit = false;\n\n    // Interactive validation must be done before dispatching the submit event.\n    if (!validateInteractively(event)) {\n        m_isSubmittingOrPreparingForSubmission = false;\n        return false;\n    }\n\n    StringPairVector controlNamesAndValues;\n    getTextFieldValues(controlNamesAndValues);\n    RefPtr<FormState> formState = FormState::create(this, controlNamesAndValues, &document(), NotSubmittedByJavaScript);\n    frame->loader()->client()->dispatchWillSendSubmitEvent(formState.release());\n\n    if (dispatchEvent(Event::createCancelableBubble(eventNames().submitEvent)))\n        m_shouldSubmit = true;\n\n    m_isSubmittingOrPreparingForSubmission = false;\n\n    if (m_shouldSubmit)\n        submit(event, true, true, NotSubmittedByJavaScript);\n\n    return m_shouldSubmit;\n}",
        "func": "bool HTMLFormElement::prepareForSubmission(Event* event)\n{\n    RefPtr<HTMLFormElement> protector(this);\n    Frame* frame = document().frame();\n    if (m_isSubmittingOrPreparingForSubmission || !frame)\n        return m_isSubmittingOrPreparingForSubmission;\n\n    m_isSubmittingOrPreparingForSubmission = true;\n    m_shouldSubmit = false;\n\n    // Interactive validation must be done before dispatching the submit event.\n    if (!validateInteractively(event)) {\n        m_isSubmittingOrPreparingForSubmission = false;\n        return false;\n    }\n\n    StringPairVector controlNamesAndValues;\n    getTextFieldValues(controlNamesAndValues);\n    RefPtr<FormState> formState = FormState::create(this, controlNamesAndValues, &document(), NotSubmittedByJavaScript);\n    frame->loader()->client()->dispatchWillSendSubmitEvent(formState.release());\n\n    if (dispatchEvent(Event::createCancelableBubble(eventNames().submitEvent)))\n        m_shouldSubmit = true;\n\n    m_isSubmittingOrPreparingForSubmission = false;\n\n    if (m_shouldSubmit)\n        submit(event, true, true, NotSubmittedByJavaScript);\n\n    return m_shouldSubmit;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,6 @@\n bool HTMLFormElement::prepareForSubmission(Event* event)\n {\n+    RefPtr<HTMLFormElement> protector(this);\n     Frame* frame = document().frame();\n     if (m_isSubmittingOrPreparingForSubmission || !frame)\n         return m_isSubmittingOrPreparingForSubmission;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    RefPtr<HTMLFormElement> protector(this);"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-4348",
        "func_name": "kernel/git/netdev/net/skb_flow_dissect",
        "description": "The skb_flow_dissect function in net/core/flow_dissector.c in the Linux kernel through 3.12 allows remote attackers to cause a denial of service (infinite loop) via a small value in the IHL field of a packet with IPIP encapsulation.",
        "git_url": "https://git.kernel.org/cgit/linux/kernel/git/davem/net.git/commit/?h=6f092343855a71e03b8d209815d8c45bf3a27fcd",
        "commit_title": "We don't validate iph->ihl which may lead a dead loop if we meet a IPIP",
        "commit_text": "skb whose iph->ihl is zero. Fix this by failing immediately when iph->ihl is evil (less than 5).  This issue were introduced by commit ec5efe7946280d1e84603389a1030ccec0a767ae (rps: support IPIP encapsulation).  Cc: Eric Dumazet <edumazet@google.com> Cc: Petr Matousek <pmatouse@redhat.com> Cc: Michael S. Tsirkin <mst@redhat.com> Cc: Daniel Borkmann <dborkman@redhat.com> ",
        "func_before": "bool skb_flow_dissect(const struct sk_buff *skb, struct flow_keys *flow)\n{\n\tint poff, nhoff = skb_network_offset(skb);\n\tu8 ip_proto;\n\t__be16 proto = skb->protocol;\n\n\tmemset(flow, 0, sizeof(*flow));\n\nagain:\n\tswitch (proto) {\n\tcase __constant_htons(ETH_P_IP): {\n\t\tconst struct iphdr *iph;\n\t\tstruct iphdr _iph;\nip:\n\t\tiph = skb_header_pointer(skb, nhoff, sizeof(_iph), &_iph);\n\t\tif (!iph)\n\t\t\treturn false;\n\n\t\tif (ip_is_fragment(iph))\n\t\t\tip_proto = 0;\n\t\telse\n\t\t\tip_proto = iph->protocol;\n\t\tiph_to_flow_copy_addrs(flow, iph);\n\t\tnhoff += iph->ihl * 4;\n\t\tbreak;\n\t}\n\tcase __constant_htons(ETH_P_IPV6): {\n\t\tconst struct ipv6hdr *iph;\n\t\tstruct ipv6hdr _iph;\nipv6:\n\t\tiph = skb_header_pointer(skb, nhoff, sizeof(_iph), &_iph);\n\t\tif (!iph)\n\t\t\treturn false;\n\n\t\tip_proto = iph->nexthdr;\n\t\tflow->src = (__force __be32)ipv6_addr_hash(&iph->saddr);\n\t\tflow->dst = (__force __be32)ipv6_addr_hash(&iph->daddr);\n\t\tnhoff += sizeof(struct ipv6hdr);\n\t\tbreak;\n\t}\n\tcase __constant_htons(ETH_P_8021AD):\n\tcase __constant_htons(ETH_P_8021Q): {\n\t\tconst struct vlan_hdr *vlan;\n\t\tstruct vlan_hdr _vlan;\n\n\t\tvlan = skb_header_pointer(skb, nhoff, sizeof(_vlan), &_vlan);\n\t\tif (!vlan)\n\t\t\treturn false;\n\n\t\tproto = vlan->h_vlan_encapsulated_proto;\n\t\tnhoff += sizeof(*vlan);\n\t\tgoto again;\n\t}\n\tcase __constant_htons(ETH_P_PPP_SES): {\n\t\tstruct {\n\t\t\tstruct pppoe_hdr hdr;\n\t\t\t__be16 proto;\n\t\t} *hdr, _hdr;\n\t\thdr = skb_header_pointer(skb, nhoff, sizeof(_hdr), &_hdr);\n\t\tif (!hdr)\n\t\t\treturn false;\n\t\tproto = hdr->proto;\n\t\tnhoff += PPPOE_SES_HLEN;\n\t\tswitch (proto) {\n\t\tcase __constant_htons(PPP_IP):\n\t\t\tgoto ip;\n\t\tcase __constant_htons(PPP_IPV6):\n\t\t\tgoto ipv6;\n\t\tdefault:\n\t\t\treturn false;\n\t\t}\n\t}\n\tdefault:\n\t\treturn false;\n\t}\n\n\tswitch (ip_proto) {\n\tcase IPPROTO_GRE: {\n\t\tstruct gre_hdr {\n\t\t\t__be16 flags;\n\t\t\t__be16 proto;\n\t\t} *hdr, _hdr;\n\n\t\thdr = skb_header_pointer(skb, nhoff, sizeof(_hdr), &_hdr);\n\t\tif (!hdr)\n\t\t\treturn false;\n\t\t/*\n\t\t * Only look inside GRE if version zero and no\n\t\t * routing\n\t\t */\n\t\tif (!(hdr->flags & (GRE_VERSION|GRE_ROUTING))) {\n\t\t\tproto = hdr->proto;\n\t\t\tnhoff += 4;\n\t\t\tif (hdr->flags & GRE_CSUM)\n\t\t\t\tnhoff += 4;\n\t\t\tif (hdr->flags & GRE_KEY)\n\t\t\t\tnhoff += 4;\n\t\t\tif (hdr->flags & GRE_SEQ)\n\t\t\t\tnhoff += 4;\n\t\t\tif (proto == htons(ETH_P_TEB)) {\n\t\t\t\tconst struct ethhdr *eth;\n\t\t\t\tstruct ethhdr _eth;\n\n\t\t\t\teth = skb_header_pointer(skb, nhoff,\n\t\t\t\t\t\t\t sizeof(_eth), &_eth);\n\t\t\t\tif (!eth)\n\t\t\t\t\treturn false;\n\t\t\t\tproto = eth->h_proto;\n\t\t\t\tnhoff += sizeof(*eth);\n\t\t\t}\n\t\t\tgoto again;\n\t\t}\n\t\tbreak;\n\t}\n\tcase IPPROTO_IPIP:\n\t\tproto = htons(ETH_P_IP);\n\t\tgoto ip;\n\tcase IPPROTO_IPV6:\n\t\tproto = htons(ETH_P_IPV6);\n\t\tgoto ipv6;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tflow->ip_proto = ip_proto;\n\tpoff = proto_ports_offset(ip_proto);\n\tif (poff >= 0) {\n\t\t__be32 *ports, _ports;\n\n\t\tports = skb_header_pointer(skb, nhoff + poff,\n\t\t\t\t\t   sizeof(_ports), &_ports);\n\t\tif (ports)\n\t\t\tflow->ports = *ports;\n\t}\n\n\tflow->thoff = (u16) nhoff;\n\n\treturn true;\n}",
        "func": "bool skb_flow_dissect(const struct sk_buff *skb, struct flow_keys *flow)\n{\n\tint poff, nhoff = skb_network_offset(skb);\n\tu8 ip_proto;\n\t__be16 proto = skb->protocol;\n\n\tmemset(flow, 0, sizeof(*flow));\n\nagain:\n\tswitch (proto) {\n\tcase __constant_htons(ETH_P_IP): {\n\t\tconst struct iphdr *iph;\n\t\tstruct iphdr _iph;\nip:\n\t\tiph = skb_header_pointer(skb, nhoff, sizeof(_iph), &_iph);\n\t\tif (!iph || iph->ihl < 5)\n\t\t\treturn false;\n\n\t\tif (ip_is_fragment(iph))\n\t\t\tip_proto = 0;\n\t\telse\n\t\t\tip_proto = iph->protocol;\n\t\tiph_to_flow_copy_addrs(flow, iph);\n\t\tnhoff += iph->ihl * 4;\n\t\tbreak;\n\t}\n\tcase __constant_htons(ETH_P_IPV6): {\n\t\tconst struct ipv6hdr *iph;\n\t\tstruct ipv6hdr _iph;\nipv6:\n\t\tiph = skb_header_pointer(skb, nhoff, sizeof(_iph), &_iph);\n\t\tif (!iph)\n\t\t\treturn false;\n\n\t\tip_proto = iph->nexthdr;\n\t\tflow->src = (__force __be32)ipv6_addr_hash(&iph->saddr);\n\t\tflow->dst = (__force __be32)ipv6_addr_hash(&iph->daddr);\n\t\tnhoff += sizeof(struct ipv6hdr);\n\t\tbreak;\n\t}\n\tcase __constant_htons(ETH_P_8021AD):\n\tcase __constant_htons(ETH_P_8021Q): {\n\t\tconst struct vlan_hdr *vlan;\n\t\tstruct vlan_hdr _vlan;\n\n\t\tvlan = skb_header_pointer(skb, nhoff, sizeof(_vlan), &_vlan);\n\t\tif (!vlan)\n\t\t\treturn false;\n\n\t\tproto = vlan->h_vlan_encapsulated_proto;\n\t\tnhoff += sizeof(*vlan);\n\t\tgoto again;\n\t}\n\tcase __constant_htons(ETH_P_PPP_SES): {\n\t\tstruct {\n\t\t\tstruct pppoe_hdr hdr;\n\t\t\t__be16 proto;\n\t\t} *hdr, _hdr;\n\t\thdr = skb_header_pointer(skb, nhoff, sizeof(_hdr), &_hdr);\n\t\tif (!hdr)\n\t\t\treturn false;\n\t\tproto = hdr->proto;\n\t\tnhoff += PPPOE_SES_HLEN;\n\t\tswitch (proto) {\n\t\tcase __constant_htons(PPP_IP):\n\t\t\tgoto ip;\n\t\tcase __constant_htons(PPP_IPV6):\n\t\t\tgoto ipv6;\n\t\tdefault:\n\t\t\treturn false;\n\t\t}\n\t}\n\tdefault:\n\t\treturn false;\n\t}\n\n\tswitch (ip_proto) {\n\tcase IPPROTO_GRE: {\n\t\tstruct gre_hdr {\n\t\t\t__be16 flags;\n\t\t\t__be16 proto;\n\t\t} *hdr, _hdr;\n\n\t\thdr = skb_header_pointer(skb, nhoff, sizeof(_hdr), &_hdr);\n\t\tif (!hdr)\n\t\t\treturn false;\n\t\t/*\n\t\t * Only look inside GRE if version zero and no\n\t\t * routing\n\t\t */\n\t\tif (!(hdr->flags & (GRE_VERSION|GRE_ROUTING))) {\n\t\t\tproto = hdr->proto;\n\t\t\tnhoff += 4;\n\t\t\tif (hdr->flags & GRE_CSUM)\n\t\t\t\tnhoff += 4;\n\t\t\tif (hdr->flags & GRE_KEY)\n\t\t\t\tnhoff += 4;\n\t\t\tif (hdr->flags & GRE_SEQ)\n\t\t\t\tnhoff += 4;\n\t\t\tif (proto == htons(ETH_P_TEB)) {\n\t\t\t\tconst struct ethhdr *eth;\n\t\t\t\tstruct ethhdr _eth;\n\n\t\t\t\teth = skb_header_pointer(skb, nhoff,\n\t\t\t\t\t\t\t sizeof(_eth), &_eth);\n\t\t\t\tif (!eth)\n\t\t\t\t\treturn false;\n\t\t\t\tproto = eth->h_proto;\n\t\t\t\tnhoff += sizeof(*eth);\n\t\t\t}\n\t\t\tgoto again;\n\t\t}\n\t\tbreak;\n\t}\n\tcase IPPROTO_IPIP:\n\t\tproto = htons(ETH_P_IP);\n\t\tgoto ip;\n\tcase IPPROTO_IPV6:\n\t\tproto = htons(ETH_P_IPV6);\n\t\tgoto ipv6;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tflow->ip_proto = ip_proto;\n\tpoff = proto_ports_offset(ip_proto);\n\tif (poff >= 0) {\n\t\t__be32 *ports, _ports;\n\n\t\tports = skb_header_pointer(skb, nhoff + poff,\n\t\t\t\t\t   sizeof(_ports), &_ports);\n\t\tif (ports)\n\t\t\tflow->ports = *ports;\n\t}\n\n\tflow->thoff = (u16) nhoff;\n\n\treturn true;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -13,7 +13,7 @@\n \t\tstruct iphdr _iph;\n ip:\n \t\tiph = skb_header_pointer(skb, nhoff, sizeof(_iph), &_iph);\n-\t\tif (!iph)\n+\t\tif (!iph || iph->ihl < 5)\n \t\t\treturn false;\n \n \t\tif (ip_is_fragment(iph))",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tif (!iph)"
            ],
            "added_lines": [
                "\t\tif (!iph || iph->ihl < 5)"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-4592",
        "func_name": "torvalds/linux/__kvm_set_memory_region",
        "description": "Memory leak in the __kvm_set_memory_region function in virt/kvm/kvm_main.c in the Linux kernel before 3.9 allows local users to cause a denial of service (memory consumption) by leveraging certain device access to trigger movement of memory slots.",
        "git_url": "https://github.com/torvalds/linux/commit/e40f193f5bb022e927a57a4f5d5194e4f12ddb74",
        "commit_title": "KVM: Fix iommu map/unmap to handle memory slot moves",
        "commit_text": " The iommu integration into memory slots expects memory slots to be added or removed and doesn't handle the move case.  We can unmap slots from the iommu after we mark them invalid and map them before installing the final memslot array.  Also re-order the kmemdup vs map so we don't leave iommu mappings if we get ENOMEM. ",
        "func_before": "int __kvm_set_memory_region(struct kvm *kvm,\n\t\t\t    struct kvm_userspace_memory_region *mem,\n\t\t\t    int user_alloc)\n{\n\tint r;\n\tgfn_t base_gfn;\n\tunsigned long npages;\n\tstruct kvm_memory_slot *memslot, *slot;\n\tstruct kvm_memory_slot old, new;\n\tstruct kvm_memslots *slots, *old_memslots;\n\n\tr = check_memory_region_flags(mem);\n\tif (r)\n\t\tgoto out;\n\n\tr = -EINVAL;\n\t/* General sanity checks */\n\tif (mem->memory_size & (PAGE_SIZE - 1))\n\t\tgoto out;\n\tif (mem->guest_phys_addr & (PAGE_SIZE - 1))\n\t\tgoto out;\n\t/* We can read the guest memory with __xxx_user() later on. */\n\tif (user_alloc &&\n\t    ((mem->userspace_addr & (PAGE_SIZE - 1)) ||\n\t     !access_ok(VERIFY_WRITE,\n\t\t\t(void __user *)(unsigned long)mem->userspace_addr,\n\t\t\tmem->memory_size)))\n\t\tgoto out;\n\tif (mem->slot >= KVM_MEM_SLOTS_NUM)\n\t\tgoto out;\n\tif (mem->guest_phys_addr + mem->memory_size < mem->guest_phys_addr)\n\t\tgoto out;\n\n\tmemslot = id_to_memslot(kvm->memslots, mem->slot);\n\tbase_gfn = mem->guest_phys_addr >> PAGE_SHIFT;\n\tnpages = mem->memory_size >> PAGE_SHIFT;\n\n\tr = -EINVAL;\n\tif (npages > KVM_MEM_MAX_NR_PAGES)\n\t\tgoto out;\n\n\tif (!npages)\n\t\tmem->flags &= ~KVM_MEM_LOG_DIRTY_PAGES;\n\n\tnew = old = *memslot;\n\n\tnew.id = mem->slot;\n\tnew.base_gfn = base_gfn;\n\tnew.npages = npages;\n\tnew.flags = mem->flags;\n\n\t/*\n\t * Disallow changing a memory slot's size or changing anything about\n\t * zero sized slots that doesn't involve making them non-zero.\n\t */\n\tr = -EINVAL;\n\tif (npages && old.npages && npages != old.npages)\n\t\tgoto out_free;\n\tif (!npages && !old.npages)\n\t\tgoto out_free;\n\n\t/* Check for overlaps */\n\tr = -EEXIST;\n\tkvm_for_each_memslot(slot, kvm->memslots) {\n\t\tif (slot->id >= KVM_MEMORY_SLOTS || slot == memslot)\n\t\t\tcontinue;\n\t\tif (!((base_gfn + npages <= slot->base_gfn) ||\n\t\t      (base_gfn >= slot->base_gfn + slot->npages)))\n\t\t\tgoto out_free;\n\t}\n\n\t/* Free page dirty bitmap if unneeded */\n\tif (!(new.flags & KVM_MEM_LOG_DIRTY_PAGES))\n\t\tnew.dirty_bitmap = NULL;\n\n\tr = -ENOMEM;\n\n\t/*\n\t * Allocate if a slot is being created.  If modifying a slot,\n\t * the userspace_addr cannot change.\n\t */\n\tif (!old.npages) {\n\t\tnew.user_alloc = user_alloc;\n\t\tnew.userspace_addr = mem->userspace_addr;\n\n\t\tif (kvm_arch_create_memslot(&new, npages))\n\t\t\tgoto out_free;\n\t} else if (npages && mem->userspace_addr != old.userspace_addr) {\n\t\tr = -EINVAL;\n\t\tgoto out_free;\n\t}\n\n\t/* Allocate page dirty bitmap if needed */\n\tif ((new.flags & KVM_MEM_LOG_DIRTY_PAGES) && !new.dirty_bitmap) {\n\t\tif (kvm_create_dirty_bitmap(&new) < 0)\n\t\t\tgoto out_free;\n\t\t/* destroy any largepage mappings for dirty tracking */\n\t}\n\n\tif (!npages || base_gfn != old.base_gfn) {\n\t\tstruct kvm_memory_slot *slot;\n\n\t\tr = -ENOMEM;\n\t\tslots = kmemdup(kvm->memslots, sizeof(struct kvm_memslots),\n\t\t\t\tGFP_KERNEL);\n\t\tif (!slots)\n\t\t\tgoto out_free;\n\t\tslot = id_to_memslot(slots, mem->slot);\n\t\tslot->flags |= KVM_MEMSLOT_INVALID;\n\n\t\tupdate_memslots(slots, NULL);\n\n\t\told_memslots = kvm->memslots;\n\t\trcu_assign_pointer(kvm->memslots, slots);\n\t\tsynchronize_srcu_expedited(&kvm->srcu);\n\t\t/* From this point no new shadow pages pointing to a deleted,\n\t\t * or moved, memslot will be created.\n\t\t *\n\t\t * validation of sp->gfn happens in:\n\t\t * \t- gfn_to_hva (kvm_read_guest, gfn_to_pfn)\n\t\t * \t- kvm_is_visible_gfn (mmu_check_roots)\n\t\t */\n\t\tkvm_arch_flush_shadow_memslot(kvm, slot);\n\t\tkfree(old_memslots);\n\t}\n\n\tr = kvm_arch_prepare_memory_region(kvm, &new, old, mem, user_alloc);\n\tif (r)\n\t\tgoto out_free;\n\n\t/* map/unmap the pages in iommu page table */\n\tif (npages) {\n\t\tr = kvm_iommu_map_pages(kvm, &new);\n\t\tif (r)\n\t\t\tgoto out_free;\n\t} else\n\t\tkvm_iommu_unmap_pages(kvm, &old);\n\n\tr = -ENOMEM;\n\tslots = kmemdup(kvm->memslots, sizeof(struct kvm_memslots),\n\t\t\tGFP_KERNEL);\n\tif (!slots)\n\t\tgoto out_free;\n\n\t/* actual memory is freed via old in kvm_free_physmem_slot below */\n\tif (!npages) {\n\t\tnew.dirty_bitmap = NULL;\n\t\tmemset(&new.arch, 0, sizeof(new.arch));\n\t}\n\n\tupdate_memslots(slots, &new);\n\told_memslots = kvm->memslots;\n\trcu_assign_pointer(kvm->memslots, slots);\n\tsynchronize_srcu_expedited(&kvm->srcu);\n\n\tkvm_arch_commit_memory_region(kvm, mem, old, user_alloc);\n\n\tkvm_free_physmem_slot(&old, &new);\n\tkfree(old_memslots);\n\n\treturn 0;\n\nout_free:\n\tkvm_free_physmem_slot(&new, &old);\nout:\n\treturn r;\n\n}",
        "func": "int __kvm_set_memory_region(struct kvm *kvm,\n\t\t\t    struct kvm_userspace_memory_region *mem,\n\t\t\t    int user_alloc)\n{\n\tint r;\n\tgfn_t base_gfn;\n\tunsigned long npages;\n\tstruct kvm_memory_slot *memslot, *slot;\n\tstruct kvm_memory_slot old, new;\n\tstruct kvm_memslots *slots, *old_memslots;\n\n\tr = check_memory_region_flags(mem);\n\tif (r)\n\t\tgoto out;\n\n\tr = -EINVAL;\n\t/* General sanity checks */\n\tif (mem->memory_size & (PAGE_SIZE - 1))\n\t\tgoto out;\n\tif (mem->guest_phys_addr & (PAGE_SIZE - 1))\n\t\tgoto out;\n\t/* We can read the guest memory with __xxx_user() later on. */\n\tif (user_alloc &&\n\t    ((mem->userspace_addr & (PAGE_SIZE - 1)) ||\n\t     !access_ok(VERIFY_WRITE,\n\t\t\t(void __user *)(unsigned long)mem->userspace_addr,\n\t\t\tmem->memory_size)))\n\t\tgoto out;\n\tif (mem->slot >= KVM_MEM_SLOTS_NUM)\n\t\tgoto out;\n\tif (mem->guest_phys_addr + mem->memory_size < mem->guest_phys_addr)\n\t\tgoto out;\n\n\tmemslot = id_to_memslot(kvm->memslots, mem->slot);\n\tbase_gfn = mem->guest_phys_addr >> PAGE_SHIFT;\n\tnpages = mem->memory_size >> PAGE_SHIFT;\n\n\tr = -EINVAL;\n\tif (npages > KVM_MEM_MAX_NR_PAGES)\n\t\tgoto out;\n\n\tif (!npages)\n\t\tmem->flags &= ~KVM_MEM_LOG_DIRTY_PAGES;\n\n\tnew = old = *memslot;\n\n\tnew.id = mem->slot;\n\tnew.base_gfn = base_gfn;\n\tnew.npages = npages;\n\tnew.flags = mem->flags;\n\n\t/*\n\t * Disallow changing a memory slot's size or changing anything about\n\t * zero sized slots that doesn't involve making them non-zero.\n\t */\n\tr = -EINVAL;\n\tif (npages && old.npages && npages != old.npages)\n\t\tgoto out_free;\n\tif (!npages && !old.npages)\n\t\tgoto out_free;\n\n\t/* Check for overlaps */\n\tr = -EEXIST;\n\tkvm_for_each_memslot(slot, kvm->memslots) {\n\t\tif (slot->id >= KVM_MEMORY_SLOTS || slot == memslot)\n\t\t\tcontinue;\n\t\tif (!((base_gfn + npages <= slot->base_gfn) ||\n\t\t      (base_gfn >= slot->base_gfn + slot->npages)))\n\t\t\tgoto out_free;\n\t}\n\n\t/* Free page dirty bitmap if unneeded */\n\tif (!(new.flags & KVM_MEM_LOG_DIRTY_PAGES))\n\t\tnew.dirty_bitmap = NULL;\n\n\tr = -ENOMEM;\n\n\t/*\n\t * Allocate if a slot is being created.  If modifying a slot,\n\t * the userspace_addr cannot change.\n\t */\n\tif (!old.npages) {\n\t\tnew.user_alloc = user_alloc;\n\t\tnew.userspace_addr = mem->userspace_addr;\n\n\t\tif (kvm_arch_create_memslot(&new, npages))\n\t\t\tgoto out_free;\n\t} else if (npages && mem->userspace_addr != old.userspace_addr) {\n\t\tr = -EINVAL;\n\t\tgoto out_free;\n\t}\n\n\t/* Allocate page dirty bitmap if needed */\n\tif ((new.flags & KVM_MEM_LOG_DIRTY_PAGES) && !new.dirty_bitmap) {\n\t\tif (kvm_create_dirty_bitmap(&new) < 0)\n\t\t\tgoto out_free;\n\t\t/* destroy any largepage mappings for dirty tracking */\n\t}\n\n\tif (!npages || base_gfn != old.base_gfn) {\n\t\tstruct kvm_memory_slot *slot;\n\n\t\tr = -ENOMEM;\n\t\tslots = kmemdup(kvm->memslots, sizeof(struct kvm_memslots),\n\t\t\t\tGFP_KERNEL);\n\t\tif (!slots)\n\t\t\tgoto out_free;\n\t\tslot = id_to_memslot(slots, mem->slot);\n\t\tslot->flags |= KVM_MEMSLOT_INVALID;\n\n\t\tupdate_memslots(slots, NULL);\n\n\t\told_memslots = kvm->memslots;\n\t\trcu_assign_pointer(kvm->memslots, slots);\n\t\tsynchronize_srcu_expedited(&kvm->srcu);\n\t\t/* slot was deleted or moved, clear iommu mapping */\n\t\tkvm_iommu_unmap_pages(kvm, &old);\n\t\t/* From this point no new shadow pages pointing to a deleted,\n\t\t * or moved, memslot will be created.\n\t\t *\n\t\t * validation of sp->gfn happens in:\n\t\t * \t- gfn_to_hva (kvm_read_guest, gfn_to_pfn)\n\t\t * \t- kvm_is_visible_gfn (mmu_check_roots)\n\t\t */\n\t\tkvm_arch_flush_shadow_memslot(kvm, slot);\n\t\tkfree(old_memslots);\n\t}\n\n\tr = kvm_arch_prepare_memory_region(kvm, &new, old, mem, user_alloc);\n\tif (r)\n\t\tgoto out_free;\n\n\tr = -ENOMEM;\n\tslots = kmemdup(kvm->memslots, sizeof(struct kvm_memslots),\n\t\t\tGFP_KERNEL);\n\tif (!slots)\n\t\tgoto out_free;\n\n\t/* map new memory slot into the iommu */\n\tif (npages) {\n\t\tr = kvm_iommu_map_pages(kvm, &new);\n\t\tif (r)\n\t\t\tgoto out_slots;\n\t}\n\n\t/* actual memory is freed via old in kvm_free_physmem_slot below */\n\tif (!npages) {\n\t\tnew.dirty_bitmap = NULL;\n\t\tmemset(&new.arch, 0, sizeof(new.arch));\n\t}\n\n\tupdate_memslots(slots, &new);\n\told_memslots = kvm->memslots;\n\trcu_assign_pointer(kvm->memslots, slots);\n\tsynchronize_srcu_expedited(&kvm->srcu);\n\n\tkvm_arch_commit_memory_region(kvm, mem, old, user_alloc);\n\n\tkvm_free_physmem_slot(&old, &new);\n\tkfree(old_memslots);\n\n\treturn 0;\n\nout_slots:\n\tkfree(slots);\nout_free:\n\tkvm_free_physmem_slot(&new, &old);\nout:\n\treturn r;\n\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -113,6 +113,8 @@\n \t\told_memslots = kvm->memslots;\n \t\trcu_assign_pointer(kvm->memslots, slots);\n \t\tsynchronize_srcu_expedited(&kvm->srcu);\n+\t\t/* slot was deleted or moved, clear iommu mapping */\n+\t\tkvm_iommu_unmap_pages(kvm, &old);\n \t\t/* From this point no new shadow pages pointing to a deleted,\n \t\t * or moved, memslot will be created.\n \t\t *\n@@ -128,19 +130,18 @@\n \tif (r)\n \t\tgoto out_free;\n \n-\t/* map/unmap the pages in iommu page table */\n-\tif (npages) {\n-\t\tr = kvm_iommu_map_pages(kvm, &new);\n-\t\tif (r)\n-\t\t\tgoto out_free;\n-\t} else\n-\t\tkvm_iommu_unmap_pages(kvm, &old);\n-\n \tr = -ENOMEM;\n \tslots = kmemdup(kvm->memslots, sizeof(struct kvm_memslots),\n \t\t\tGFP_KERNEL);\n \tif (!slots)\n \t\tgoto out_free;\n+\n+\t/* map new memory slot into the iommu */\n+\tif (npages) {\n+\t\tr = kvm_iommu_map_pages(kvm, &new);\n+\t\tif (r)\n+\t\t\tgoto out_slots;\n+\t}\n \n \t/* actual memory is freed via old in kvm_free_physmem_slot below */\n \tif (!npages) {\n@@ -160,6 +161,8 @@\n \n \treturn 0;\n \n+out_slots:\n+\tkfree(slots);\n out_free:\n \tkvm_free_physmem_slot(&new, &old);\n out:",
        "diff_line_info": {
            "deleted_lines": [
                "\t/* map/unmap the pages in iommu page table */",
                "\tif (npages) {",
                "\t\tr = kvm_iommu_map_pages(kvm, &new);",
                "\t\tif (r)",
                "\t\t\tgoto out_free;",
                "\t} else",
                "\t\tkvm_iommu_unmap_pages(kvm, &old);",
                ""
            ],
            "added_lines": [
                "\t\t/* slot was deleted or moved, clear iommu mapping */",
                "\t\tkvm_iommu_unmap_pages(kvm, &old);",
                "",
                "\t/* map new memory slot into the iommu */",
                "\tif (npages) {",
                "\t\tr = kvm_iommu_map_pages(kvm, &new);",
                "\t\tif (r)",
                "\t\t\tgoto out_slots;",
                "\t}",
                "out_slots:",
                "\tkfree(slots);"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-4592",
        "func_name": "torvalds/linux/__kvm_set_memory_region",
        "description": "Memory leak in the __kvm_set_memory_region function in virt/kvm/kvm_main.c in the Linux kernel before 3.9 allows local users to cause a denial of service (memory consumption) by leveraging certain device access to trigger movement of memory slots.",
        "git_url": "https://github.com/torvalds/linux/commit/12d6e7538e2d418c08f082b1b44ffa5fb7270ed8",
        "commit_title": "KVM: perform an invalid memslot step for gpa base change",
        "commit_text": " PPC must flush all translations before the new memory slot is visible. ",
        "func_before": "int __kvm_set_memory_region(struct kvm *kvm,\n\t\t\t    struct kvm_userspace_memory_region *mem,\n\t\t\t    int user_alloc)\n{\n\tint r;\n\tgfn_t base_gfn;\n\tunsigned long npages;\n\tunsigned long i;\n\tstruct kvm_memory_slot *memslot;\n\tstruct kvm_memory_slot old, new;\n\tstruct kvm_memslots *slots, *old_memslots;\n\n\tr = check_memory_region_flags(mem);\n\tif (r)\n\t\tgoto out;\n\n\tr = -EINVAL;\n\t/* General sanity checks */\n\tif (mem->memory_size & (PAGE_SIZE - 1))\n\t\tgoto out;\n\tif (mem->guest_phys_addr & (PAGE_SIZE - 1))\n\t\tgoto out;\n\t/* We can read the guest memory with __xxx_user() later on. */\n\tif (user_alloc &&\n\t    ((mem->userspace_addr & (PAGE_SIZE - 1)) ||\n\t     !access_ok(VERIFY_WRITE,\n\t\t\t(void __user *)(unsigned long)mem->userspace_addr,\n\t\t\tmem->memory_size)))\n\t\tgoto out;\n\tif (mem->slot >= KVM_MEM_SLOTS_NUM)\n\t\tgoto out;\n\tif (mem->guest_phys_addr + mem->memory_size < mem->guest_phys_addr)\n\t\tgoto out;\n\n\tmemslot = id_to_memslot(kvm->memslots, mem->slot);\n\tbase_gfn = mem->guest_phys_addr >> PAGE_SHIFT;\n\tnpages = mem->memory_size >> PAGE_SHIFT;\n\n\tr = -EINVAL;\n\tif (npages > KVM_MEM_MAX_NR_PAGES)\n\t\tgoto out;\n\n\tif (!npages)\n\t\tmem->flags &= ~KVM_MEM_LOG_DIRTY_PAGES;\n\n\tnew = old = *memslot;\n\n\tnew.id = mem->slot;\n\tnew.base_gfn = base_gfn;\n\tnew.npages = npages;\n\tnew.flags = mem->flags;\n\n\t/* Disallow changing a memory slot's size. */\n\tr = -EINVAL;\n\tif (npages && old.npages && npages != old.npages)\n\t\tgoto out_free;\n\n\t/* Check for overlaps */\n\tr = -EEXIST;\n\tfor (i = 0; i < KVM_MEMORY_SLOTS; ++i) {\n\t\tstruct kvm_memory_slot *s = &kvm->memslots->memslots[i];\n\n\t\tif (s == memslot || !s->npages)\n\t\t\tcontinue;\n\t\tif (!((base_gfn + npages <= s->base_gfn) ||\n\t\t      (base_gfn >= s->base_gfn + s->npages)))\n\t\t\tgoto out_free;\n\t}\n\n\t/* Free page dirty bitmap if unneeded */\n\tif (!(new.flags & KVM_MEM_LOG_DIRTY_PAGES))\n\t\tnew.dirty_bitmap = NULL;\n\n\tr = -ENOMEM;\n\n\t/* Allocate if a slot is being created */\n\tif (npages && !old.npages) {\n\t\tnew.user_alloc = user_alloc;\n\t\tnew.userspace_addr = mem->userspace_addr;\n\n\t\tif (kvm_arch_create_memslot(&new, npages))\n\t\t\tgoto out_free;\n\t}\n\n\t/* Allocate page dirty bitmap if needed */\n\tif ((new.flags & KVM_MEM_LOG_DIRTY_PAGES) && !new.dirty_bitmap) {\n\t\tif (kvm_create_dirty_bitmap(&new) < 0)\n\t\t\tgoto out_free;\n\t\t/* destroy any largepage mappings for dirty tracking */\n\t}\n\n\tif (!npages) {\n\t\tstruct kvm_memory_slot *slot;\n\n\t\tr = -ENOMEM;\n\t\tslots = kmemdup(kvm->memslots, sizeof(struct kvm_memslots),\n\t\t\t\tGFP_KERNEL);\n\t\tif (!slots)\n\t\t\tgoto out_free;\n\t\tslot = id_to_memslot(slots, mem->slot);\n\t\tslot->flags |= KVM_MEMSLOT_INVALID;\n\n\t\tupdate_memslots(slots, NULL);\n\n\t\told_memslots = kvm->memslots;\n\t\trcu_assign_pointer(kvm->memslots, slots);\n\t\tsynchronize_srcu_expedited(&kvm->srcu);\n\t\t/* From this point no new shadow pages pointing to a deleted\n\t\t * memslot will be created.\n\t\t *\n\t\t * validation of sp->gfn happens in:\n\t\t * \t- gfn_to_hva (kvm_read_guest, gfn_to_pfn)\n\t\t * \t- kvm_is_visible_gfn (mmu_check_roots)\n\t\t */\n\t\tkvm_arch_flush_shadow_memslot(kvm, slot);\n\t\tkfree(old_memslots);\n\t}\n\n\tr = kvm_arch_prepare_memory_region(kvm, &new, old, mem, user_alloc);\n\tif (r)\n\t\tgoto out_free;\n\n\t/* map/unmap the pages in iommu page table */\n\tif (npages) {\n\t\tr = kvm_iommu_map_pages(kvm, &new);\n\t\tif (r)\n\t\t\tgoto out_free;\n\t} else\n\t\tkvm_iommu_unmap_pages(kvm, &old);\n\n\tr = -ENOMEM;\n\tslots = kmemdup(kvm->memslots, sizeof(struct kvm_memslots),\n\t\t\tGFP_KERNEL);\n\tif (!slots)\n\t\tgoto out_free;\n\n\t/* actual memory is freed via old in kvm_free_physmem_slot below */\n\tif (!npages) {\n\t\tnew.dirty_bitmap = NULL;\n\t\tmemset(&new.arch, 0, sizeof(new.arch));\n\t}\n\n\tupdate_memslots(slots, &new);\n\told_memslots = kvm->memslots;\n\trcu_assign_pointer(kvm->memslots, slots);\n\tsynchronize_srcu_expedited(&kvm->srcu);\n\n\tkvm_arch_commit_memory_region(kvm, mem, old, user_alloc);\n\n\t/*\n\t * If the new memory slot is created, we need to clear all\n\t * mmio sptes.\n\t */\n\tif (npages && old.base_gfn != mem->guest_phys_addr >> PAGE_SHIFT)\n\t\tkvm_arch_flush_shadow_all(kvm);\n\n\tkvm_free_physmem_slot(&old, &new);\n\tkfree(old_memslots);\n\n\treturn 0;\n\nout_free:\n\tkvm_free_physmem_slot(&new, &old);\nout:\n\treturn r;\n\n}",
        "func": "int __kvm_set_memory_region(struct kvm *kvm,\n\t\t\t    struct kvm_userspace_memory_region *mem,\n\t\t\t    int user_alloc)\n{\n\tint r;\n\tgfn_t base_gfn;\n\tunsigned long npages;\n\tunsigned long i;\n\tstruct kvm_memory_slot *memslot;\n\tstruct kvm_memory_slot old, new;\n\tstruct kvm_memslots *slots, *old_memslots;\n\n\tr = check_memory_region_flags(mem);\n\tif (r)\n\t\tgoto out;\n\n\tr = -EINVAL;\n\t/* General sanity checks */\n\tif (mem->memory_size & (PAGE_SIZE - 1))\n\t\tgoto out;\n\tif (mem->guest_phys_addr & (PAGE_SIZE - 1))\n\t\tgoto out;\n\t/* We can read the guest memory with __xxx_user() later on. */\n\tif (user_alloc &&\n\t    ((mem->userspace_addr & (PAGE_SIZE - 1)) ||\n\t     !access_ok(VERIFY_WRITE,\n\t\t\t(void __user *)(unsigned long)mem->userspace_addr,\n\t\t\tmem->memory_size)))\n\t\tgoto out;\n\tif (mem->slot >= KVM_MEM_SLOTS_NUM)\n\t\tgoto out;\n\tif (mem->guest_phys_addr + mem->memory_size < mem->guest_phys_addr)\n\t\tgoto out;\n\n\tmemslot = id_to_memslot(kvm->memslots, mem->slot);\n\tbase_gfn = mem->guest_phys_addr >> PAGE_SHIFT;\n\tnpages = mem->memory_size >> PAGE_SHIFT;\n\n\tr = -EINVAL;\n\tif (npages > KVM_MEM_MAX_NR_PAGES)\n\t\tgoto out;\n\n\tif (!npages)\n\t\tmem->flags &= ~KVM_MEM_LOG_DIRTY_PAGES;\n\n\tnew = old = *memslot;\n\n\tnew.id = mem->slot;\n\tnew.base_gfn = base_gfn;\n\tnew.npages = npages;\n\tnew.flags = mem->flags;\n\n\t/* Disallow changing a memory slot's size. */\n\tr = -EINVAL;\n\tif (npages && old.npages && npages != old.npages)\n\t\tgoto out_free;\n\n\t/* Check for overlaps */\n\tr = -EEXIST;\n\tfor (i = 0; i < KVM_MEMORY_SLOTS; ++i) {\n\t\tstruct kvm_memory_slot *s = &kvm->memslots->memslots[i];\n\n\t\tif (s == memslot || !s->npages)\n\t\t\tcontinue;\n\t\tif (!((base_gfn + npages <= s->base_gfn) ||\n\t\t      (base_gfn >= s->base_gfn + s->npages)))\n\t\t\tgoto out_free;\n\t}\n\n\t/* Free page dirty bitmap if unneeded */\n\tif (!(new.flags & KVM_MEM_LOG_DIRTY_PAGES))\n\t\tnew.dirty_bitmap = NULL;\n\n\tr = -ENOMEM;\n\n\t/* Allocate if a slot is being created */\n\tif (npages && !old.npages) {\n\t\tnew.user_alloc = user_alloc;\n\t\tnew.userspace_addr = mem->userspace_addr;\n\n\t\tif (kvm_arch_create_memslot(&new, npages))\n\t\t\tgoto out_free;\n\t}\n\n\t/* Allocate page dirty bitmap if needed */\n\tif ((new.flags & KVM_MEM_LOG_DIRTY_PAGES) && !new.dirty_bitmap) {\n\t\tif (kvm_create_dirty_bitmap(&new) < 0)\n\t\t\tgoto out_free;\n\t\t/* destroy any largepage mappings for dirty tracking */\n\t}\n\n\tif (!npages || base_gfn != old.base_gfn) {\n\t\tstruct kvm_memory_slot *slot;\n\n\t\tr = -ENOMEM;\n\t\tslots = kmemdup(kvm->memslots, sizeof(struct kvm_memslots),\n\t\t\t\tGFP_KERNEL);\n\t\tif (!slots)\n\t\t\tgoto out_free;\n\t\tslot = id_to_memslot(slots, mem->slot);\n\t\tslot->flags |= KVM_MEMSLOT_INVALID;\n\n\t\tupdate_memslots(slots, NULL);\n\n\t\told_memslots = kvm->memslots;\n\t\trcu_assign_pointer(kvm->memslots, slots);\n\t\tsynchronize_srcu_expedited(&kvm->srcu);\n\t\t/* From this point no new shadow pages pointing to a deleted,\n\t\t * or moved, memslot will be created.\n\t\t *\n\t\t * validation of sp->gfn happens in:\n\t\t * \t- gfn_to_hva (kvm_read_guest, gfn_to_pfn)\n\t\t * \t- kvm_is_visible_gfn (mmu_check_roots)\n\t\t */\n\t\tkvm_arch_flush_shadow_memslot(kvm, slot);\n\t\tkfree(old_memslots);\n\t}\n\n\tr = kvm_arch_prepare_memory_region(kvm, &new, old, mem, user_alloc);\n\tif (r)\n\t\tgoto out_free;\n\n\t/* map/unmap the pages in iommu page table */\n\tif (npages) {\n\t\tr = kvm_iommu_map_pages(kvm, &new);\n\t\tif (r)\n\t\t\tgoto out_free;\n\t} else\n\t\tkvm_iommu_unmap_pages(kvm, &old);\n\n\tr = -ENOMEM;\n\tslots = kmemdup(kvm->memslots, sizeof(struct kvm_memslots),\n\t\t\tGFP_KERNEL);\n\tif (!slots)\n\t\tgoto out_free;\n\n\t/* actual memory is freed via old in kvm_free_physmem_slot below */\n\tif (!npages) {\n\t\tnew.dirty_bitmap = NULL;\n\t\tmemset(&new.arch, 0, sizeof(new.arch));\n\t}\n\n\tupdate_memslots(slots, &new);\n\told_memslots = kvm->memslots;\n\trcu_assign_pointer(kvm->memslots, slots);\n\tsynchronize_srcu_expedited(&kvm->srcu);\n\n\tkvm_arch_commit_memory_region(kvm, mem, old, user_alloc);\n\n\t/*\n\t * If the new memory slot is created, we need to clear all\n\t * mmio sptes.\n\t */\n\tif (npages && old.base_gfn != mem->guest_phys_addr >> PAGE_SHIFT)\n\t\tkvm_arch_flush_shadow_all(kvm);\n\n\tkvm_free_physmem_slot(&old, &new);\n\tkfree(old_memslots);\n\n\treturn 0;\n\nout_free:\n\tkvm_free_physmem_slot(&new, &old);\nout:\n\treturn r;\n\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -89,7 +89,7 @@\n \t\t/* destroy any largepage mappings for dirty tracking */\n \t}\n \n-\tif (!npages) {\n+\tif (!npages || base_gfn != old.base_gfn) {\n \t\tstruct kvm_memory_slot *slot;\n \n \t\tr = -ENOMEM;\n@@ -105,8 +105,8 @@\n \t\told_memslots = kvm->memslots;\n \t\trcu_assign_pointer(kvm->memslots, slots);\n \t\tsynchronize_srcu_expedited(&kvm->srcu);\n-\t\t/* From this point no new shadow pages pointing to a deleted\n-\t\t * memslot will be created.\n+\t\t/* From this point no new shadow pages pointing to a deleted,\n+\t\t * or moved, memslot will be created.\n \t\t *\n \t\t * validation of sp->gfn happens in:\n \t\t * \t- gfn_to_hva (kvm_read_guest, gfn_to_pfn)",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (!npages) {",
                "\t\t/* From this point no new shadow pages pointing to a deleted",
                "\t\t * memslot will be created."
            ],
            "added_lines": [
                "\tif (!npages || base_gfn != old.base_gfn) {",
                "\t\t/* From this point no new shadow pages pointing to a deleted,",
                "\t\t * or moved, memslot will be created."
            ]
        }
    },
    {
        "cve_id": "CVE-2013-6635",
        "func_name": "chromium/CompositeEditCommand::cloneParagraphUnderNewElement",
        "description": "Use-after-free vulnerability in the editing implementation in Blink, as used in Google Chrome before 31.0.1650.63, allows remote attackers to cause a denial of service or possibly have unspecified other impact via JavaScript code that triggers removal of a node during processing of the DOM tree, related to CompositeEditCommand.cpp and ReplaceSelectionCommand.cpp.",
        "git_url": "https://github.com/chromium/chromium/commit/787c37304814f96e37345ffcab8509b4c7569da3",
        "commit_title": "Make \"InsertHTML\" and \"Indent\" commands to handle DOM tree modification during processing",
        "commit_text": " This patch makes \"InsertHTML\" and \"Indent\" commands to handle DOM tree modification during processing. When calling Node::insertBefore(), JavaScript may be executed, e.g. <iframe src=\"javascript:...\">, and it modifies DOM tree.  On issue 314469, use-after-free is caused at |startBlock| variable which holds raw Node pointer removed during script execution in ReplaceSelectionCommand::doApply().  Changes for CompositeEditCommand::cloneParagraphUnderNewElement() is similar to ReplaceSelectionCommand::doApply(). |outerNode| is removed during CompositeEditCommand::appendNode(), which inserts <iframe src=\"javascript:...\">.   ",
        "func_before": "void CompositeEditCommand::cloneParagraphUnderNewElement(Position& start, Position& end, Node* passedOuterNode, Element* blockElement)\n{\n    // First we clone the outerNode\n    RefPtr<Node> lastNode;\n    RefPtr<Node> outerNode = passedOuterNode;\n\n    if (outerNode->isRootEditableElement()) {\n        lastNode = blockElement;\n    } else {\n        lastNode = outerNode->cloneNode(isTableElement(outerNode.get()));\n        appendNode(lastNode, blockElement);\n    }\n\n    if (start.deprecatedNode() != outerNode && lastNode->isElementNode()) {\n        Vector<RefPtr<Node> > ancestors;\n\n        // Insert each node from innerNode to outerNode (excluded) in a list.\n        for (Node* n = start.deprecatedNode(); n && n != outerNode; n = n->parentNode())\n            ancestors.append(n);\n\n        // Clone every node between start.deprecatedNode() and outerBlock.\n\n        for (size_t i = ancestors.size(); i != 0; --i) {\n            Node* item = ancestors[i - 1].get();\n            RefPtr<Node> child = item->cloneNode(isTableElement(item));\n            appendNode(child, toElement(lastNode));\n            lastNode = child.release();\n        }\n    }\n\n    // Handle the case of paragraphs with more than one node,\n    // cloning all the siblings until end.deprecatedNode() is reached.\n\n    if (start.deprecatedNode() != end.deprecatedNode() && !start.deprecatedNode()->isDescendantOf(end.deprecatedNode())) {\n        // If end is not a descendant of outerNode we need to\n        // find the first common ancestor to increase the scope\n        // of our nextSibling traversal.\n        while (!end.deprecatedNode()->isDescendantOf(outerNode.get())) {\n            outerNode = outerNode->parentNode();\n        }\n\n        RefPtr<Node> startNode = start.deprecatedNode();\n        for (RefPtr<Node> node = NodeTraversal::nextSkippingChildren(startNode.get(), outerNode.get()); node; node = NodeTraversal::nextSkippingChildren(node.get(), outerNode.get())) {\n            // Move lastNode up in the tree as much as node was moved up in the\n            // tree by NodeTraversal::nextSkippingChildren, so that the relative depth between\n            // node and the original start node is maintained in the clone.\n            while (startNode->parentNode() != node->parentNode()) {\n                startNode = startNode->parentNode();\n                lastNode = lastNode->parentNode();\n            }\n\n            RefPtr<Node> clonedNode = node->cloneNode(true);\n            insertNodeAfter(clonedNode, lastNode);\n            lastNode = clonedNode.release();\n            if (node == end.deprecatedNode() || end.deprecatedNode()->isDescendantOf(node.get()))\n                break;\n        }\n    }\n}",
        "func": "void CompositeEditCommand::cloneParagraphUnderNewElement(Position& start, Position& end, Node* passedOuterNode, Element* blockElement)\n{\n    // First we clone the outerNode\n    RefPtr<Node> lastNode;\n    RefPtr<Node> outerNode = passedOuterNode;\n\n    if (outerNode->isRootEditableElement()) {\n        lastNode = blockElement;\n    } else {\n        lastNode = outerNode->cloneNode(isTableElement(outerNode.get()));\n        appendNode(lastNode, blockElement);\n    }\n\n    if (start.deprecatedNode() != outerNode && lastNode->isElementNode()) {\n        Vector<RefPtr<Node> > ancestors;\n\n        // Insert each node from innerNode to outerNode (excluded) in a list.\n        for (Node* n = start.deprecatedNode(); n && n != outerNode; n = n->parentNode())\n            ancestors.append(n);\n\n        // Clone every node between start.deprecatedNode() and outerBlock.\n\n        for (size_t i = ancestors.size(); i != 0; --i) {\n            Node* item = ancestors[i - 1].get();\n            RefPtr<Node> child = item->cloneNode(isTableElement(item));\n            appendNode(child, toElement(lastNode));\n            lastNode = child.release();\n        }\n    }\n\n    // Scripts specified in javascript protocol may remove |outerNode|\n    // during insertion, e.g. <iframe src=\"javascript:...\">\n    if (!outerNode->inDocument())\n        return;\n\n    // Handle the case of paragraphs with more than one node,\n    // cloning all the siblings until end.deprecatedNode() is reached.\n\n    if (start.deprecatedNode() != end.deprecatedNode() && !start.deprecatedNode()->isDescendantOf(end.deprecatedNode())) {\n        // If end is not a descendant of outerNode we need to\n        // find the first common ancestor to increase the scope\n        // of our nextSibling traversal.\n        while (!end.deprecatedNode()->isDescendantOf(outerNode.get())) {\n            outerNode = outerNode->parentNode();\n        }\n\n        RefPtr<Node> startNode = start.deprecatedNode();\n        for (RefPtr<Node> node = NodeTraversal::nextSkippingChildren(startNode.get(), outerNode.get()); node; node = NodeTraversal::nextSkippingChildren(node.get(), outerNode.get())) {\n            // Move lastNode up in the tree as much as node was moved up in the\n            // tree by NodeTraversal::nextSkippingChildren, so that the relative depth between\n            // node and the original start node is maintained in the clone.\n            while (startNode->parentNode() != node->parentNode()) {\n                startNode = startNode->parentNode();\n                lastNode = lastNode->parentNode();\n            }\n\n            RefPtr<Node> clonedNode = node->cloneNode(true);\n            insertNodeAfter(clonedNode, lastNode);\n            lastNode = clonedNode.release();\n            if (node == end.deprecatedNode() || end.deprecatedNode()->isDescendantOf(node.get()))\n                break;\n        }\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -28,6 +28,11 @@\n         }\n     }\n \n+    // Scripts specified in javascript protocol may remove |outerNode|\n+    // during insertion, e.g. <iframe src=\"javascript:...\">\n+    if (!outerNode->inDocument())\n+        return;\n+\n     // Handle the case of paragraphs with more than one node,\n     // cloning all the siblings until end.deprecatedNode() is reached.\n ",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    // Scripts specified in javascript protocol may remove |outerNode|",
                "    // during insertion, e.g. <iframe src=\"javascript:...\">",
                "    if (!outerNode->inDocument())",
                "        return;",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2013-6635",
        "func_name": "chromium/ReplaceSelectionCommand::doApply",
        "description": "Use-after-free vulnerability in the editing implementation in Blink, as used in Google Chrome before 31.0.1650.63, allows remote attackers to cause a denial of service or possibly have unspecified other impact via JavaScript code that triggers removal of a node during processing of the DOM tree, related to CompositeEditCommand.cpp and ReplaceSelectionCommand.cpp.",
        "git_url": "https://github.com/chromium/chromium/commit/787c37304814f96e37345ffcab8509b4c7569da3",
        "commit_title": "Make \"InsertHTML\" and \"Indent\" commands to handle DOM tree modification during processing",
        "commit_text": " This patch makes \"InsertHTML\" and \"Indent\" commands to handle DOM tree modification during processing. When calling Node::insertBefore(), JavaScript may be executed, e.g. <iframe src=\"javascript:...\">, and it modifies DOM tree.  On issue 314469, use-after-free is caused at |startBlock| variable which holds raw Node pointer removed during script execution in ReplaceSelectionCommand::doApply().  Changes for CompositeEditCommand::cloneParagraphUnderNewElement() is similar to ReplaceSelectionCommand::doApply(). |outerNode| is removed during CompositeEditCommand::appendNode(), which inserts <iframe src=\"javascript:...\">.   ",
        "func_before": "void ReplaceSelectionCommand::doApply()\n{\n    VisibleSelection selection = endingSelection();\n    ASSERT(selection.isCaretOrRange());\n    ASSERT(selection.start().deprecatedNode());\n    if (!selection.isNonOrphanedCaretOrRange() || !selection.start().deprecatedNode())\n        return;\n\n    if (!selection.rootEditableElement())\n        return;\n\n    ReplacementFragment fragment(&document(), m_documentFragment.get(), selection);\n    if (performTrivialReplace(fragment))\n        return;\n\n    // We can skip matching the style if the selection is plain text.\n    if ((selection.start().deprecatedNode()->renderer() && selection.start().deprecatedNode()->renderer()->style()->userModify() == READ_WRITE_PLAINTEXT_ONLY)\n        && (selection.end().deprecatedNode()->renderer() && selection.end().deprecatedNode()->renderer()->style()->userModify() == READ_WRITE_PLAINTEXT_ONLY))\n        m_matchStyle = false;\n\n    if (m_matchStyle) {\n        m_insertionStyle = EditingStyle::create(selection.start());\n        m_insertionStyle->mergeTypingStyle(&document());\n    }\n\n    VisiblePosition visibleStart = selection.visibleStart();\n    VisiblePosition visibleEnd = selection.visibleEnd();\n\n    bool selectionEndWasEndOfParagraph = isEndOfParagraph(visibleEnd);\n    bool selectionStartWasStartOfParagraph = isStartOfParagraph(visibleStart);\n\n    Node* startBlock = enclosingBlock(visibleStart.deepEquivalent().deprecatedNode());\n\n    Position insertionPos = selection.start();\n    bool startIsInsideMailBlockquote = enclosingNodeOfType(insertionPos, isMailBlockquote, CanCrossEditingBoundary);\n    bool selectionIsPlainText = !selection.isContentRichlyEditable();\n    Element* currentRoot = selection.rootEditableElement();\n\n    if ((selectionStartWasStartOfParagraph && selectionEndWasEndOfParagraph && !startIsInsideMailBlockquote) ||\n        startBlock == currentRoot || isListItem(startBlock) || selectionIsPlainText)\n        m_preventNesting = false;\n\n    if (selection.isRange()) {\n        // When the end of the selection being pasted into is at the end of a paragraph, and that selection\n        // spans multiple blocks, not merging may leave an empty line.\n        // When the start of the selection being pasted into is at the start of a block, not merging\n        // will leave hanging block(s).\n        // Merge blocks if the start of the selection was in a Mail blockquote, since we handle\n        // that case specially to prevent nesting.\n        bool mergeBlocksAfterDelete = startIsInsideMailBlockquote || isEndOfParagraph(visibleEnd) || isStartOfBlock(visibleStart);\n        // FIXME: We should only expand to include fully selected special elements if we are copying a\n        // selection and pasting it on top of itself.\n        deleteSelection(false, mergeBlocksAfterDelete, true, false);\n        visibleStart = endingSelection().visibleStart();\n        if (fragment.hasInterchangeNewlineAtStart()) {\n            if (isEndOfParagraph(visibleStart) && !isStartOfParagraph(visibleStart)) {\n                if (!isEndOfEditableOrNonEditableContent(visibleStart))\n                    setEndingSelection(visibleStart.next());\n            } else\n                insertParagraphSeparator();\n        }\n        insertionPos = endingSelection().start();\n    } else {\n        ASSERT(selection.isCaret());\n        if (fragment.hasInterchangeNewlineAtStart()) {\n            VisiblePosition next = visibleStart.next(CannotCrossEditingBoundary);\n            if (isEndOfParagraph(visibleStart) && !isStartOfParagraph(visibleStart) && next.isNotNull())\n                setEndingSelection(next);\n            else  {\n                insertParagraphSeparator();\n                visibleStart = endingSelection().visibleStart();\n            }\n        }\n        // We split the current paragraph in two to avoid nesting the blocks from the fragment inside the current block.\n        // For example paste <div>foo</div><div>bar</div><div>baz</div> into <div>x^x</div>, where ^ is the caret.\n        // As long as the  div styles are the same, visually you'd expect: <div>xbar</div><div>bar</div><div>bazx</div>,\n        // not <div>xbar<div>bar</div><div>bazx</div></div>.\n        // Don't do this if the selection started in a Mail blockquote.\n        if (m_preventNesting && !startIsInsideMailBlockquote && !isEndOfParagraph(visibleStart) && !isStartOfParagraph(visibleStart)) {\n            insertParagraphSeparator();\n            setEndingSelection(endingSelection().visibleStart().previous());\n        }\n        insertionPos = endingSelection().start();\n    }\n\n    // We don't want any of the pasted content to end up nested in a Mail blockquote, so first break\n    // out of any surrounding Mail blockquotes. Unless we're inserting in a table, in which case\n    // breaking the blockquote will prevent the content from actually being inserted in the table.\n    if (startIsInsideMailBlockquote && m_preventNesting && !(enclosingNodeOfType(insertionPos, &isTableStructureNode))) {\n        applyCommandToComposite(BreakBlockquoteCommand::create(document()));\n        // This will leave a br between the split.\n        Node* br = endingSelection().start().deprecatedNode();\n        ASSERT(br->hasTagName(brTag));\n        // Insert content between the two blockquotes, but remove the br (since it was just a placeholder).\n        insertionPos = positionInParentBeforeNode(br);\n        removeNode(br);\n    }\n\n    // Inserting content could cause whitespace to collapse, e.g. inserting <div>foo</div> into hello^ world.\n    prepareWhitespaceAtPositionForSplit(insertionPos);\n\n    // If the downstream node has been removed there's no point in continuing.\n    if (!insertionPos.downstream().deprecatedNode())\n      return;\n\n    // NOTE: This would be an incorrect usage of downstream() if downstream() were changed to mean the last position after\n    // p that maps to the same visible position as p (since in the case where a br is at the end of a block and collapsed\n    // away, there are positions after the br which map to the same visible position as [br, 0]).\n    Node* endBR = insertionPos.downstream().deprecatedNode()->hasTagName(brTag) ? insertionPos.downstream().deprecatedNode() : 0;\n    VisiblePosition originalVisPosBeforeEndBR;\n    if (endBR)\n        originalVisPosBeforeEndBR = VisiblePosition(positionBeforeNode(endBR), DOWNSTREAM).previous();\n\n    startBlock = enclosingBlock(insertionPos.deprecatedNode());\n\n    // Adjust insertionPos to prevent nesting.\n    // If the start was in a Mail blockquote, we will have already handled adjusting insertionPos above.\n    if (m_preventNesting && startBlock && !isTableCell(startBlock) && !startIsInsideMailBlockquote) {\n        ASSERT(startBlock != currentRoot);\n        VisiblePosition visibleInsertionPos(insertionPos);\n        if (isEndOfBlock(visibleInsertionPos) && !(isStartOfBlock(visibleInsertionPos) && fragment.hasInterchangeNewlineAtEnd()))\n            insertionPos = positionInParentAfterNode(startBlock);\n        else if (isStartOfBlock(visibleInsertionPos))\n            insertionPos = positionInParentBeforeNode(startBlock);\n    }\n\n    // Paste at start or end of link goes outside of link.\n    insertionPos = positionAvoidingSpecialElementBoundary(insertionPos);\n\n    // FIXME: Can this wait until after the operation has been performed?  There doesn't seem to be\n    // any work performed after this that queries or uses the typing style.\n    if (Frame* frame = document().frame())\n        frame->selection().clearTypingStyle();\n\n    removeHeadContents(fragment);\n\n    // We don't want the destination to end up inside nodes that weren't selected.  To avoid that, we move the\n    // position forward without changing the visible position so we're still at the same visible location, but\n    // outside of preceding tags.\n    insertionPos = positionAvoidingPrecedingNodes(insertionPos);\n\n    // Paste into run of tabs splits the tab span.\n    insertionPos = positionOutsideTabSpan(insertionPos);\n\n    bool handledStyleSpans = handleStyleSpansBeforeInsertion(fragment, insertionPos);\n\n    // We're finished if there is nothing to add.\n    if (fragment.isEmpty() || !fragment.firstChild())\n        return;\n\n    // If we are not trying to match the destination style we prefer a position\n    // that is outside inline elements that provide style.\n    // This way we can produce a less verbose markup.\n    // We can skip this optimization for fragments not wrapped in one of\n    // our style spans and for positions inside list items\n    // since insertAsListItems already does the right thing.\n    if (!m_matchStyle && !enclosingList(insertionPos.containerNode())) {\n        if (insertionPos.containerNode()->isTextNode() && insertionPos.offsetInContainerNode() && !insertionPos.atLastEditingPositionForNode()) {\n            splitTextNode(insertionPos.containerText(), insertionPos.offsetInContainerNode());\n            insertionPos = firstPositionInNode(insertionPos.containerNode());\n        }\n\n        if (RefPtr<Node> nodeToSplitTo = nodeToSplitToAvoidPastingIntoInlineNodesWithStyle(insertionPos)) {\n            if (insertionPos.containerNode() != nodeToSplitTo->parentNode()) {\n                Node* splitStart = insertionPos.computeNodeAfterPosition();\n                if (!splitStart)\n                    splitStart = insertionPos.containerNode();\n                nodeToSplitTo = splitTreeToNode(splitStart, nodeToSplitTo->parentNode()).get();\n                insertionPos = positionInParentBeforeNode(nodeToSplitTo.get());\n            }\n        }\n    }\n\n    // FIXME: When pasting rich content we're often prevented from heading down the fast path by style spans.  Try\n    // again here if they've been removed.\n\n    // 1) Insert the content.\n    // 2) Remove redundant styles and style tags, this inner <b> for example: <b>foo <b>bar</b> baz</b>.\n    // 3) Merge the start of the added content with the content before the position being pasted into.\n    // 4) Do one of the following: a) expand the last br if the fragment ends with one and it collapsed,\n    // b) merge the last paragraph of the incoming fragment with the paragraph that contained the\n    // end of the selection that was pasted into, or c) handle an interchange newline at the end of the\n    // incoming fragment.\n    // 5) Add spaces for smart replace.\n    // 6) Select the replacement if requested, and match style if requested.\n\n    InsertedNodes insertedNodes;\n    RefPtr<Node> refNode = fragment.firstChild();\n    ASSERT(refNode);\n    RefPtr<Node> node = refNode->nextSibling();\n\n    fragment.removeNode(refNode);\n\n    Node* blockStart = enclosingBlock(insertionPos.deprecatedNode());\n    if ((isListElement(refNode.get()) || (isLegacyAppleStyleSpan(refNode.get()) && isListElement(refNode->firstChild())))\n        && blockStart && blockStart->renderer()->isListItem())\n        refNode = insertAsListItems(toHTMLElement(refNode), blockStart, insertionPos, insertedNodes);\n    else {\n        insertNodeAt(refNode, insertionPos);\n        insertedNodes.respondToNodeInsertion(*refNode);\n    }\n\n    // Mutation events (bug 22634) may have already removed the inserted content\n    if (!refNode->inDocument())\n        return;\n\n    bool plainTextFragment = isPlainTextMarkup(refNode.get());\n\n    while (node) {\n        RefPtr<Node> next = node->nextSibling();\n        fragment.removeNode(node.get());\n        insertNodeAfter(node, refNode);\n        insertedNodes.respondToNodeInsertion(*node);\n\n        // Mutation events (bug 22634) may have already removed the inserted content\n        if (!node->inDocument())\n            return;\n\n        refNode = node;\n        if (node && plainTextFragment)\n            plainTextFragment = isPlainTextMarkup(node.get());\n        node = next;\n    }\n\n    removeUnrenderedTextNodesAtEnds(insertedNodes);\n\n    if (!handledStyleSpans)\n        handleStyleSpans(insertedNodes);\n\n    // Mutation events (bug 20161) may have already removed the inserted content\n    if (!insertedNodes.firstNodeInserted() || !insertedNodes.firstNodeInserted()->inDocument())\n        return;\n\n    VisiblePosition startOfInsertedContent = firstPositionInOrBeforeNode(insertedNodes.firstNodeInserted());\n\n    // We inserted before the startBlock to prevent nesting, and the content before the startBlock wasn't in its own block and\n    // didn't have a br after it, so the inserted content ended up in the same paragraph.\n    if (startBlock && insertionPos.deprecatedNode() == startBlock->parentNode() && (unsigned)insertionPos.deprecatedEditingOffset() < startBlock->nodeIndex() && !isStartOfParagraph(startOfInsertedContent))\n        insertNodeAt(createBreakElement(document()).get(), startOfInsertedContent.deepEquivalent());\n\n    if (endBR && (plainTextFragment || shouldRemoveEndBR(endBR, originalVisPosBeforeEndBR))) {\n        RefPtr<Node> parent = endBR->parentNode();\n        insertedNodes.willRemoveNode(*endBR);\n        removeNode(endBR);\n        if (Node* nodeToRemove = highestNodeToRemoveInPruning(parent.get())) {\n            insertedNodes.willRemoveNode(*nodeToRemove);\n            removeNode(nodeToRemove);\n        }\n    }\n\n    makeInsertedContentRoundTrippableWithHTMLTreeBuilder(insertedNodes);\n\n    removeRedundantStylesAndKeepStyleSpanInline(insertedNodes);\n\n    if (m_sanitizeFragment)\n        applyCommandToComposite(SimplifyMarkupCommand::create(document(), insertedNodes.firstNodeInserted(), insertedNodes.pastLastLeaf()));\n\n    // Setup m_startOfInsertedContent and m_endOfInsertedContent. This should be the last two lines of code that access insertedNodes.\n    m_startOfInsertedContent = firstPositionInOrBeforeNode(insertedNodes.firstNodeInserted());\n    m_endOfInsertedContent = lastPositionInOrAfterNode(&insertedNodes.lastLeafInserted());\n\n    // Determine whether or not we should merge the end of inserted content with what's after it before we do\n    // the start merge so that the start merge doesn't effect our decision.\n    m_shouldMergeEnd = shouldMergeEnd(selectionEndWasEndOfParagraph);\n\n    if (shouldMergeStart(selectionStartWasStartOfParagraph, fragment.hasInterchangeNewlineAtStart(), startIsInsideMailBlockquote)) {\n        VisiblePosition startOfParagraphToMove = positionAtStartOfInsertedContent();\n        VisiblePosition destination = startOfParagraphToMove.previous();\n        // We need to handle the case where we need to merge the end\n        // but our destination node is inside an inline that is the last in the block.\n        // We insert a placeholder before the newly inserted content to avoid being merged into the inline.\n        Node* destinationNode = destination.deepEquivalent().deprecatedNode();\n        if (m_shouldMergeEnd && destinationNode != enclosingInline(destinationNode) && enclosingInline(destinationNode)->nextSibling())\n            insertNodeBefore(createBreakElement(document()), refNode.get());\n\n        // Merging the the first paragraph of inserted content with the content that came\n        // before the selection that was pasted into would also move content after\n        // the selection that was pasted into if: only one paragraph was being pasted,\n        // and it was not wrapped in a block, the selection that was pasted into ended\n        // at the end of a block and the next paragraph didn't start at the start of a block.\n        // Insert a line break just after the inserted content to separate it from what\n        // comes after and prevent that from happening.\n        VisiblePosition endOfInsertedContent = positionAtEndOfInsertedContent();\n        if (startOfParagraph(endOfInsertedContent) == startOfParagraphToMove) {\n            insertNodeAt(createBreakElement(document()).get(), endOfInsertedContent.deepEquivalent());\n            // Mutation events (bug 22634) triggered by inserting the <br> might have removed the content we're about to move\n            if (!startOfParagraphToMove.deepEquivalent().inDocument())\n                return;\n        }\n\n        // FIXME: Maintain positions for the start and end of inserted content instead of keeping nodes.  The nodes are\n        // only ever used to create positions where inserted content starts/ends.\n        moveParagraph(startOfParagraphToMove, endOfParagraph(startOfParagraphToMove), destination);\n        m_startOfInsertedContent = endingSelection().visibleStart().deepEquivalent().downstream();\n        if (m_endOfInsertedContent.isOrphan())\n            m_endOfInsertedContent = endingSelection().visibleEnd().deepEquivalent().upstream();\n    }\n\n    Position lastPositionToSelect;\n    if (fragment.hasInterchangeNewlineAtEnd()) {\n        VisiblePosition endOfInsertedContent = positionAtEndOfInsertedContent();\n        VisiblePosition next = endOfInsertedContent.next(CannotCrossEditingBoundary);\n\n        if (selectionEndWasEndOfParagraph || !isEndOfParagraph(endOfInsertedContent) || next.isNull()) {\n            if (!isStartOfParagraph(endOfInsertedContent)) {\n                setEndingSelection(endOfInsertedContent);\n                Node* enclosingNode = enclosingBlock(endOfInsertedContent.deepEquivalent().deprecatedNode());\n                if (isListItem(enclosingNode)) {\n                    RefPtr<Node> newListItem = createListItemElement(document());\n                    insertNodeAfter(newListItem, enclosingNode);\n                    setEndingSelection(VisiblePosition(firstPositionInNode(newListItem.get())));\n                } else {\n                    // Use a default paragraph element (a plain div) for the empty paragraph, using the last paragraph\n                    // block's style seems to annoy users.\n                    insertParagraphSeparator(true, !startIsInsideMailBlockquote && highestEnclosingNodeOfType(endOfInsertedContent.deepEquivalent(),\n                        isMailBlockquote, CannotCrossEditingBoundary, insertedNodes.firstNodeInserted()->parentNode()));\n                }\n\n                // Select up to the paragraph separator that was added.\n                lastPositionToSelect = endingSelection().visibleStart().deepEquivalent();\n                updateNodesInserted(lastPositionToSelect.deprecatedNode());\n            }\n        } else {\n            // Select up to the beginning of the next paragraph.\n            lastPositionToSelect = next.deepEquivalent().downstream();\n        }\n\n    } else\n        mergeEndIfNeeded();\n\n    if (Node* mailBlockquote = enclosingNodeOfType(positionAtStartOfInsertedContent().deepEquivalent(), isMailPasteAsQuotationNode))\n        removeNodeAttribute(toElement(mailBlockquote), classAttr);\n\n    if (shouldPerformSmartReplace())\n        addSpacesForSmartReplace();\n\n    // If we are dealing with a fragment created from plain text\n    // no style matching is necessary.\n    if (plainTextFragment)\n        m_matchStyle = false;\n\n    completeHTMLReplacement(lastPositionToSelect);\n}",
        "func": "void ReplaceSelectionCommand::doApply()\n{\n    VisibleSelection selection = endingSelection();\n    ASSERT(selection.isCaretOrRange());\n    ASSERT(selection.start().deprecatedNode());\n    if (!selection.isNonOrphanedCaretOrRange() || !selection.start().deprecatedNode())\n        return;\n\n    if (!selection.rootEditableElement())\n        return;\n\n    ReplacementFragment fragment(&document(), m_documentFragment.get(), selection);\n    if (performTrivialReplace(fragment))\n        return;\n\n    // We can skip matching the style if the selection is plain text.\n    if ((selection.start().deprecatedNode()->renderer() && selection.start().deprecatedNode()->renderer()->style()->userModify() == READ_WRITE_PLAINTEXT_ONLY)\n        && (selection.end().deprecatedNode()->renderer() && selection.end().deprecatedNode()->renderer()->style()->userModify() == READ_WRITE_PLAINTEXT_ONLY))\n        m_matchStyle = false;\n\n    if (m_matchStyle) {\n        m_insertionStyle = EditingStyle::create(selection.start());\n        m_insertionStyle->mergeTypingStyle(&document());\n    }\n\n    VisiblePosition visibleStart = selection.visibleStart();\n    VisiblePosition visibleEnd = selection.visibleEnd();\n\n    bool selectionEndWasEndOfParagraph = isEndOfParagraph(visibleEnd);\n    bool selectionStartWasStartOfParagraph = isStartOfParagraph(visibleStart);\n\n    Node* startBlock = enclosingBlock(visibleStart.deepEquivalent().deprecatedNode());\n\n    Position insertionPos = selection.start();\n    bool startIsInsideMailBlockquote = enclosingNodeOfType(insertionPos, isMailBlockquote, CanCrossEditingBoundary);\n    bool selectionIsPlainText = !selection.isContentRichlyEditable();\n    Element* currentRoot = selection.rootEditableElement();\n\n    if ((selectionStartWasStartOfParagraph && selectionEndWasEndOfParagraph && !startIsInsideMailBlockquote) ||\n        startBlock == currentRoot || isListItem(startBlock) || selectionIsPlainText)\n        m_preventNesting = false;\n\n    if (selection.isRange()) {\n        // When the end of the selection being pasted into is at the end of a paragraph, and that selection\n        // spans multiple blocks, not merging may leave an empty line.\n        // When the start of the selection being pasted into is at the start of a block, not merging\n        // will leave hanging block(s).\n        // Merge blocks if the start of the selection was in a Mail blockquote, since we handle\n        // that case specially to prevent nesting.\n        bool mergeBlocksAfterDelete = startIsInsideMailBlockquote || isEndOfParagraph(visibleEnd) || isStartOfBlock(visibleStart);\n        // FIXME: We should only expand to include fully selected special elements if we are copying a\n        // selection and pasting it on top of itself.\n        deleteSelection(false, mergeBlocksAfterDelete, true, false);\n        visibleStart = endingSelection().visibleStart();\n        if (fragment.hasInterchangeNewlineAtStart()) {\n            if (isEndOfParagraph(visibleStart) && !isStartOfParagraph(visibleStart)) {\n                if (!isEndOfEditableOrNonEditableContent(visibleStart))\n                    setEndingSelection(visibleStart.next());\n            } else\n                insertParagraphSeparator();\n        }\n        insertionPos = endingSelection().start();\n    } else {\n        ASSERT(selection.isCaret());\n        if (fragment.hasInterchangeNewlineAtStart()) {\n            VisiblePosition next = visibleStart.next(CannotCrossEditingBoundary);\n            if (isEndOfParagraph(visibleStart) && !isStartOfParagraph(visibleStart) && next.isNotNull())\n                setEndingSelection(next);\n            else  {\n                insertParagraphSeparator();\n                visibleStart = endingSelection().visibleStart();\n            }\n        }\n        // We split the current paragraph in two to avoid nesting the blocks from the fragment inside the current block.\n        // For example paste <div>foo</div><div>bar</div><div>baz</div> into <div>x^x</div>, where ^ is the caret.\n        // As long as the  div styles are the same, visually you'd expect: <div>xbar</div><div>bar</div><div>bazx</div>,\n        // not <div>xbar<div>bar</div><div>bazx</div></div>.\n        // Don't do this if the selection started in a Mail blockquote.\n        if (m_preventNesting && !startIsInsideMailBlockquote && !isEndOfParagraph(visibleStart) && !isStartOfParagraph(visibleStart)) {\n            insertParagraphSeparator();\n            setEndingSelection(endingSelection().visibleStart().previous());\n        }\n        insertionPos = endingSelection().start();\n    }\n\n    // We don't want any of the pasted content to end up nested in a Mail blockquote, so first break\n    // out of any surrounding Mail blockquotes. Unless we're inserting in a table, in which case\n    // breaking the blockquote will prevent the content from actually being inserted in the table.\n    if (startIsInsideMailBlockquote && m_preventNesting && !(enclosingNodeOfType(insertionPos, &isTableStructureNode))) {\n        applyCommandToComposite(BreakBlockquoteCommand::create(document()));\n        // This will leave a br between the split.\n        Node* br = endingSelection().start().deprecatedNode();\n        ASSERT(br->hasTagName(brTag));\n        // Insert content between the two blockquotes, but remove the br (since it was just a placeholder).\n        insertionPos = positionInParentBeforeNode(br);\n        removeNode(br);\n    }\n\n    // Inserting content could cause whitespace to collapse, e.g. inserting <div>foo</div> into hello^ world.\n    prepareWhitespaceAtPositionForSplit(insertionPos);\n\n    // If the downstream node has been removed there's no point in continuing.\n    if (!insertionPos.downstream().deprecatedNode())\n      return;\n\n    // NOTE: This would be an incorrect usage of downstream() if downstream() were changed to mean the last position after\n    // p that maps to the same visible position as p (since in the case where a br is at the end of a block and collapsed\n    // away, there are positions after the br which map to the same visible position as [br, 0]).\n    Node* endBR = insertionPos.downstream().deprecatedNode()->hasTagName(brTag) ? insertionPos.downstream().deprecatedNode() : 0;\n    VisiblePosition originalVisPosBeforeEndBR;\n    if (endBR)\n        originalVisPosBeforeEndBR = VisiblePosition(positionBeforeNode(endBR), DOWNSTREAM).previous();\n\n    RefPtr<Node> insertionBlock = enclosingBlock(insertionPos.deprecatedNode());\n\n    // Adjust insertionPos to prevent nesting.\n    // If the start was in a Mail blockquote, we will have already handled adjusting insertionPos above.\n    if (m_preventNesting && insertionBlock && !isTableCell(insertionBlock.get()) && !startIsInsideMailBlockquote) {\n        ASSERT(insertionBlock != currentRoot);\n        VisiblePosition visibleInsertionPos(insertionPos);\n        if (isEndOfBlock(visibleInsertionPos) && !(isStartOfBlock(visibleInsertionPos) && fragment.hasInterchangeNewlineAtEnd()))\n            insertionPos = positionInParentAfterNode(insertionBlock.get());\n        else if (isStartOfBlock(visibleInsertionPos))\n            insertionPos = positionInParentBeforeNode(insertionBlock.get());\n    }\n\n    // Paste at start or end of link goes outside of link.\n    insertionPos = positionAvoidingSpecialElementBoundary(insertionPos);\n\n    // FIXME: Can this wait until after the operation has been performed?  There doesn't seem to be\n    // any work performed after this that queries or uses the typing style.\n    if (Frame* frame = document().frame())\n        frame->selection().clearTypingStyle();\n\n    removeHeadContents(fragment);\n\n    // We don't want the destination to end up inside nodes that weren't selected.  To avoid that, we move the\n    // position forward without changing the visible position so we're still at the same visible location, but\n    // outside of preceding tags.\n    insertionPos = positionAvoidingPrecedingNodes(insertionPos);\n\n    // Paste into run of tabs splits the tab span.\n    insertionPos = positionOutsideTabSpan(insertionPos);\n\n    bool handledStyleSpans = handleStyleSpansBeforeInsertion(fragment, insertionPos);\n\n    // We're finished if there is nothing to add.\n    if (fragment.isEmpty() || !fragment.firstChild())\n        return;\n\n    // If we are not trying to match the destination style we prefer a position\n    // that is outside inline elements that provide style.\n    // This way we can produce a less verbose markup.\n    // We can skip this optimization for fragments not wrapped in one of\n    // our style spans and for positions inside list items\n    // since insertAsListItems already does the right thing.\n    if (!m_matchStyle && !enclosingList(insertionPos.containerNode())) {\n        if (insertionPos.containerNode()->isTextNode() && insertionPos.offsetInContainerNode() && !insertionPos.atLastEditingPositionForNode()) {\n            splitTextNode(insertionPos.containerText(), insertionPos.offsetInContainerNode());\n            insertionPos = firstPositionInNode(insertionPos.containerNode());\n        }\n\n        if (RefPtr<Node> nodeToSplitTo = nodeToSplitToAvoidPastingIntoInlineNodesWithStyle(insertionPos)) {\n            if (insertionPos.containerNode() != nodeToSplitTo->parentNode()) {\n                Node* splitStart = insertionPos.computeNodeAfterPosition();\n                if (!splitStart)\n                    splitStart = insertionPos.containerNode();\n                nodeToSplitTo = splitTreeToNode(splitStart, nodeToSplitTo->parentNode()).get();\n                insertionPos = positionInParentBeforeNode(nodeToSplitTo.get());\n            }\n        }\n    }\n\n    // FIXME: When pasting rich content we're often prevented from heading down the fast path by style spans.  Try\n    // again here if they've been removed.\n\n    // 1) Insert the content.\n    // 2) Remove redundant styles and style tags, this inner <b> for example: <b>foo <b>bar</b> baz</b>.\n    // 3) Merge the start of the added content with the content before the position being pasted into.\n    // 4) Do one of the following: a) expand the last br if the fragment ends with one and it collapsed,\n    // b) merge the last paragraph of the incoming fragment with the paragraph that contained the\n    // end of the selection that was pasted into, or c) handle an interchange newline at the end of the\n    // incoming fragment.\n    // 5) Add spaces for smart replace.\n    // 6) Select the replacement if requested, and match style if requested.\n\n    InsertedNodes insertedNodes;\n    RefPtr<Node> refNode = fragment.firstChild();\n    ASSERT(refNode);\n    RefPtr<Node> node = refNode->nextSibling();\n\n    fragment.removeNode(refNode);\n\n    Node* blockStart = enclosingBlock(insertionPos.deprecatedNode());\n    if ((isListElement(refNode.get()) || (isLegacyAppleStyleSpan(refNode.get()) && isListElement(refNode->firstChild())))\n        && blockStart && blockStart->renderer()->isListItem())\n        refNode = insertAsListItems(toHTMLElement(refNode), blockStart, insertionPos, insertedNodes);\n    else {\n        insertNodeAt(refNode, insertionPos);\n        insertedNodes.respondToNodeInsertion(*refNode);\n    }\n\n    // Mutation events (bug 22634) may have already removed the inserted content\n    if (!refNode->inDocument())\n        return;\n\n    bool plainTextFragment = isPlainTextMarkup(refNode.get());\n\n    while (node) {\n        RefPtr<Node> next = node->nextSibling();\n        fragment.removeNode(node.get());\n        insertNodeAfter(node, refNode);\n        insertedNodes.respondToNodeInsertion(*node);\n\n        // Mutation events (bug 22634) may have already removed the inserted content\n        if (!node->inDocument())\n            return;\n\n        refNode = node;\n        if (node && plainTextFragment)\n            plainTextFragment = isPlainTextMarkup(node.get());\n        node = next;\n    }\n\n    removeUnrenderedTextNodesAtEnds(insertedNodes);\n\n    if (!handledStyleSpans)\n        handleStyleSpans(insertedNodes);\n\n    // Mutation events (bug 20161) may have already removed the inserted content\n    if (!insertedNodes.firstNodeInserted() || !insertedNodes.firstNodeInserted()->inDocument())\n        return;\n\n    // Scripts specified in javascript protocol may remove |insertionBlock|\n    // during insertion, e.g. <iframe src=\"javascript:...\">\n    if (insertionBlock && !insertionBlock->inDocument())\n        insertionBlock = 0;\n\n    VisiblePosition startOfInsertedContent = firstPositionInOrBeforeNode(insertedNodes.firstNodeInserted());\n\n    // We inserted before the insertionBlock to prevent nesting, and the content before the insertionBlock wasn't in its own block and\n    // didn't have a br after it, so the inserted content ended up in the same paragraph.\n    if (insertionBlock && insertionPos.deprecatedNode() == insertionBlock->parentNode() && (unsigned)insertionPos.deprecatedEditingOffset() < insertionBlock->nodeIndex() && !isStartOfParagraph(startOfInsertedContent))\n        insertNodeAt(createBreakElement(document()).get(), startOfInsertedContent.deepEquivalent());\n\n    if (endBR && (plainTextFragment || shouldRemoveEndBR(endBR, originalVisPosBeforeEndBR))) {\n        RefPtr<Node> parent = endBR->parentNode();\n        insertedNodes.willRemoveNode(*endBR);\n        removeNode(endBR);\n        if (Node* nodeToRemove = highestNodeToRemoveInPruning(parent.get())) {\n            insertedNodes.willRemoveNode(*nodeToRemove);\n            removeNode(nodeToRemove);\n        }\n    }\n\n    makeInsertedContentRoundTrippableWithHTMLTreeBuilder(insertedNodes);\n\n    removeRedundantStylesAndKeepStyleSpanInline(insertedNodes);\n\n    if (m_sanitizeFragment)\n        applyCommandToComposite(SimplifyMarkupCommand::create(document(), insertedNodes.firstNodeInserted(), insertedNodes.pastLastLeaf()));\n\n    // Setup m_startOfInsertedContent and m_endOfInsertedContent. This should be the last two lines of code that access insertedNodes.\n    m_startOfInsertedContent = firstPositionInOrBeforeNode(insertedNodes.firstNodeInserted());\n    m_endOfInsertedContent = lastPositionInOrAfterNode(&insertedNodes.lastLeafInserted());\n\n    // Determine whether or not we should merge the end of inserted content with what's after it before we do\n    // the start merge so that the start merge doesn't effect our decision.\n    m_shouldMergeEnd = shouldMergeEnd(selectionEndWasEndOfParagraph);\n\n    if (shouldMergeStart(selectionStartWasStartOfParagraph, fragment.hasInterchangeNewlineAtStart(), startIsInsideMailBlockquote)) {\n        VisiblePosition startOfParagraphToMove = positionAtStartOfInsertedContent();\n        VisiblePosition destination = startOfParagraphToMove.previous();\n        // We need to handle the case where we need to merge the end\n        // but our destination node is inside an inline that is the last in the block.\n        // We insert a placeholder before the newly inserted content to avoid being merged into the inline.\n        Node* destinationNode = destination.deepEquivalent().deprecatedNode();\n        if (m_shouldMergeEnd && destinationNode != enclosingInline(destinationNode) && enclosingInline(destinationNode)->nextSibling())\n            insertNodeBefore(createBreakElement(document()), refNode.get());\n\n        // Merging the the first paragraph of inserted content with the content that came\n        // before the selection that was pasted into would also move content after\n        // the selection that was pasted into if: only one paragraph was being pasted,\n        // and it was not wrapped in a block, the selection that was pasted into ended\n        // at the end of a block and the next paragraph didn't start at the start of a block.\n        // Insert a line break just after the inserted content to separate it from what\n        // comes after and prevent that from happening.\n        VisiblePosition endOfInsertedContent = positionAtEndOfInsertedContent();\n        if (startOfParagraph(endOfInsertedContent) == startOfParagraphToMove) {\n            insertNodeAt(createBreakElement(document()).get(), endOfInsertedContent.deepEquivalent());\n            // Mutation events (bug 22634) triggered by inserting the <br> might have removed the content we're about to move\n            if (!startOfParagraphToMove.deepEquivalent().inDocument())\n                return;\n        }\n\n        // FIXME: Maintain positions for the start and end of inserted content instead of keeping nodes.  The nodes are\n        // only ever used to create positions where inserted content starts/ends.\n        moveParagraph(startOfParagraphToMove, endOfParagraph(startOfParagraphToMove), destination);\n        m_startOfInsertedContent = endingSelection().visibleStart().deepEquivalent().downstream();\n        if (m_endOfInsertedContent.isOrphan())\n            m_endOfInsertedContent = endingSelection().visibleEnd().deepEquivalent().upstream();\n    }\n\n    Position lastPositionToSelect;\n    if (fragment.hasInterchangeNewlineAtEnd()) {\n        VisiblePosition endOfInsertedContent = positionAtEndOfInsertedContent();\n        VisiblePosition next = endOfInsertedContent.next(CannotCrossEditingBoundary);\n\n        if (selectionEndWasEndOfParagraph || !isEndOfParagraph(endOfInsertedContent) || next.isNull()) {\n            if (!isStartOfParagraph(endOfInsertedContent)) {\n                setEndingSelection(endOfInsertedContent);\n                Node* enclosingNode = enclosingBlock(endOfInsertedContent.deepEquivalent().deprecatedNode());\n                if (isListItem(enclosingNode)) {\n                    RefPtr<Node> newListItem = createListItemElement(document());\n                    insertNodeAfter(newListItem, enclosingNode);\n                    setEndingSelection(VisiblePosition(firstPositionInNode(newListItem.get())));\n                } else {\n                    // Use a default paragraph element (a plain div) for the empty paragraph, using the last paragraph\n                    // block's style seems to annoy users.\n                    insertParagraphSeparator(true, !startIsInsideMailBlockquote && highestEnclosingNodeOfType(endOfInsertedContent.deepEquivalent(),\n                        isMailBlockquote, CannotCrossEditingBoundary, insertedNodes.firstNodeInserted()->parentNode()));\n                }\n\n                // Select up to the paragraph separator that was added.\n                lastPositionToSelect = endingSelection().visibleStart().deepEquivalent();\n                updateNodesInserted(lastPositionToSelect.deprecatedNode());\n            }\n        } else {\n            // Select up to the beginning of the next paragraph.\n            lastPositionToSelect = next.deepEquivalent().downstream();\n        }\n\n    } else\n        mergeEndIfNeeded();\n\n    if (Node* mailBlockquote = enclosingNodeOfType(positionAtStartOfInsertedContent().deepEquivalent(), isMailPasteAsQuotationNode))\n        removeNodeAttribute(toElement(mailBlockquote), classAttr);\n\n    if (shouldPerformSmartReplace())\n        addSpacesForSmartReplace();\n\n    // If we are dealing with a fragment created from plain text\n    // no style matching is necessary.\n    if (plainTextFragment)\n        m_matchStyle = false;\n\n    completeHTMLReplacement(lastPositionToSelect);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -111,17 +111,17 @@\n     if (endBR)\n         originalVisPosBeforeEndBR = VisiblePosition(positionBeforeNode(endBR), DOWNSTREAM).previous();\n \n-    startBlock = enclosingBlock(insertionPos.deprecatedNode());\n+    RefPtr<Node> insertionBlock = enclosingBlock(insertionPos.deprecatedNode());\n \n     // Adjust insertionPos to prevent nesting.\n     // If the start was in a Mail blockquote, we will have already handled adjusting insertionPos above.\n-    if (m_preventNesting && startBlock && !isTableCell(startBlock) && !startIsInsideMailBlockquote) {\n-        ASSERT(startBlock != currentRoot);\n+    if (m_preventNesting && insertionBlock && !isTableCell(insertionBlock.get()) && !startIsInsideMailBlockquote) {\n+        ASSERT(insertionBlock != currentRoot);\n         VisiblePosition visibleInsertionPos(insertionPos);\n         if (isEndOfBlock(visibleInsertionPos) && !(isStartOfBlock(visibleInsertionPos) && fragment.hasInterchangeNewlineAtEnd()))\n-            insertionPos = positionInParentAfterNode(startBlock);\n+            insertionPos = positionInParentAfterNode(insertionBlock.get());\n         else if (isStartOfBlock(visibleInsertionPos))\n-            insertionPos = positionInParentBeforeNode(startBlock);\n+            insertionPos = positionInParentBeforeNode(insertionBlock.get());\n     }\n \n     // Paste at start or end of link goes outside of link.\n@@ -231,11 +231,16 @@\n     if (!insertedNodes.firstNodeInserted() || !insertedNodes.firstNodeInserted()->inDocument())\n         return;\n \n+    // Scripts specified in javascript protocol may remove |insertionBlock|\n+    // during insertion, e.g. <iframe src=\"javascript:...\">\n+    if (insertionBlock && !insertionBlock->inDocument())\n+        insertionBlock = 0;\n+\n     VisiblePosition startOfInsertedContent = firstPositionInOrBeforeNode(insertedNodes.firstNodeInserted());\n \n-    // We inserted before the startBlock to prevent nesting, and the content before the startBlock wasn't in its own block and\n+    // We inserted before the insertionBlock to prevent nesting, and the content before the insertionBlock wasn't in its own block and\n     // didn't have a br after it, so the inserted content ended up in the same paragraph.\n-    if (startBlock && insertionPos.deprecatedNode() == startBlock->parentNode() && (unsigned)insertionPos.deprecatedEditingOffset() < startBlock->nodeIndex() && !isStartOfParagraph(startOfInsertedContent))\n+    if (insertionBlock && insertionPos.deprecatedNode() == insertionBlock->parentNode() && (unsigned)insertionPos.deprecatedEditingOffset() < insertionBlock->nodeIndex() && !isStartOfParagraph(startOfInsertedContent))\n         insertNodeAt(createBreakElement(document()).get(), startOfInsertedContent.deepEquivalent());\n \n     if (endBR && (plainTextFragment || shouldRemoveEndBR(endBR, originalVisPosBeforeEndBR))) {",
        "diff_line_info": {
            "deleted_lines": [
                "    startBlock = enclosingBlock(insertionPos.deprecatedNode());",
                "    if (m_preventNesting && startBlock && !isTableCell(startBlock) && !startIsInsideMailBlockquote) {",
                "        ASSERT(startBlock != currentRoot);",
                "            insertionPos = positionInParentAfterNode(startBlock);",
                "            insertionPos = positionInParentBeforeNode(startBlock);",
                "    // We inserted before the startBlock to prevent nesting, and the content before the startBlock wasn't in its own block and",
                "    if (startBlock && insertionPos.deprecatedNode() == startBlock->parentNode() && (unsigned)insertionPos.deprecatedEditingOffset() < startBlock->nodeIndex() && !isStartOfParagraph(startOfInsertedContent))"
            ],
            "added_lines": [
                "    RefPtr<Node> insertionBlock = enclosingBlock(insertionPos.deprecatedNode());",
                "    if (m_preventNesting && insertionBlock && !isTableCell(insertionBlock.get()) && !startIsInsideMailBlockquote) {",
                "        ASSERT(insertionBlock != currentRoot);",
                "            insertionPos = positionInParentAfterNode(insertionBlock.get());",
                "            insertionPos = positionInParentBeforeNode(insertionBlock.get());",
                "    // Scripts specified in javascript protocol may remove |insertionBlock|",
                "    // during insertion, e.g. <iframe src=\"javascript:...\">",
                "    if (insertionBlock && !insertionBlock->inDocument())",
                "        insertionBlock = 0;",
                "",
                "    // We inserted before the insertionBlock to prevent nesting, and the content before the insertionBlock wasn't in its own block and",
                "    if (insertionBlock && insertionPos.deprecatedNode() == insertionBlock->parentNode() && (unsigned)insertionPos.deprecatedEditingOffset() < insertionBlock->nodeIndex() && !isStartOfParagraph(startOfInsertedContent))"
            ]
        }
    },
    {
        "cve_id": "CVE-2011-3934",
        "func_name": "ffmpeg/vp3_update_thread_context",
        "description": "Double free vulnerability in the vp3_update_thread_context function in libavcodec/vp3.c in FFmpeg before 0.10 allows remote attackers to have an unspecified impact via crafted vp3 data.",
        "git_url": "http://git.videolan.org/?p=ffmpeg.git;a=commit;h=247d30a7dba6684ccce4508424f35fd58465e535",
        "commit_title": "",
        "commit_text": "vp3: Copy all 3 frames for thread updates.  This fixes a double release of the current frame on deinit. Fixes CVE-2011-3934  ",
        "func_before": "static int vp3_update_thread_context(AVCodecContext *dst, const AVCodecContext *src)\n{\n    Vp3DecodeContext *s = dst->priv_data, *s1 = src->priv_data;\n    int qps_changed = 0, i, err;\n\n#define copy_fields(to, from, start_field, end_field) memcpy(&to->start_field, &from->start_field, (char*)&to->end_field - (char*)&to->start_field)\n\n    if (!s1->current_frame.data[0]\n        ||s->width != s1->width\n        ||s->height!= s1->height) {\n        if (s != s1)\n            copy_fields(s, s1, golden_frame, current_frame);\n        return -1;\n    }\n\n    if (s != s1) {\n        // init tables if the first frame hasn't been decoded\n        if (!s->current_frame.data[0]) {\n            int y_fragment_count, c_fragment_count;\n            s->avctx = dst;\n            err = allocate_tables(dst);\n            if (err)\n                return err;\n            y_fragment_count = s->fragment_width[0] * s->fragment_height[0];\n            c_fragment_count = s->fragment_width[1] * s->fragment_height[1];\n            memcpy(s->motion_val[0], s1->motion_val[0], y_fragment_count * sizeof(*s->motion_val[0]));\n            memcpy(s->motion_val[1], s1->motion_val[1], c_fragment_count * sizeof(*s->motion_val[1]));\n        }\n\n        // copy previous frame data\n        copy_fields(s, s1, golden_frame, dsp);\n\n        // copy qscale data if necessary\n        for (i = 0; i < 3; i++) {\n            if (s->qps[i] != s1->qps[1]) {\n                qps_changed = 1;\n                memcpy(&s->qmat[i], &s1->qmat[i], sizeof(s->qmat[i]));\n            }\n        }\n\n        if (s->qps[0] != s1->qps[0])\n            memcpy(&s->bounding_values_array, &s1->bounding_values_array, sizeof(s->bounding_values_array));\n\n        if (qps_changed)\n            copy_fields(s, s1, qps, superblock_count);\n#undef copy_fields\n    }\n\n    update_frames(dst);\n\n    return 0;\n}",
        "func": "static int vp3_update_thread_context(AVCodecContext *dst, const AVCodecContext *src)\n{\n    Vp3DecodeContext *s = dst->priv_data, *s1 = src->priv_data;\n    int qps_changed = 0, i, err;\n\n#define copy_fields(to, from, start_field, end_field) memcpy(&to->start_field, &from->start_field, (char*)&to->end_field - (char*)&to->start_field)\n\n    if (!s1->current_frame.data[0]\n        ||s->width != s1->width\n        ||s->height!= s1->height) {\n        if (s != s1)\n            copy_fields(s, s1, golden_frame, keyframe);\n        return -1;\n    }\n\n    if (s != s1) {\n        // init tables if the first frame hasn't been decoded\n        if (!s->current_frame.data[0]) {\n            int y_fragment_count, c_fragment_count;\n            s->avctx = dst;\n            err = allocate_tables(dst);\n            if (err)\n                return err;\n            y_fragment_count = s->fragment_width[0] * s->fragment_height[0];\n            c_fragment_count = s->fragment_width[1] * s->fragment_height[1];\n            memcpy(s->motion_val[0], s1->motion_val[0], y_fragment_count * sizeof(*s->motion_val[0]));\n            memcpy(s->motion_val[1], s1->motion_val[1], c_fragment_count * sizeof(*s->motion_val[1]));\n        }\n\n        // copy previous frame data\n        copy_fields(s, s1, golden_frame, dsp);\n\n        // copy qscale data if necessary\n        for (i = 0; i < 3; i++) {\n            if (s->qps[i] != s1->qps[1]) {\n                qps_changed = 1;\n                memcpy(&s->qmat[i], &s1->qmat[i], sizeof(s->qmat[i]));\n            }\n        }\n\n        if (s->qps[0] != s1->qps[0])\n            memcpy(&s->bounding_values_array, &s1->bounding_values_array, sizeof(s->bounding_values_array));\n\n        if (qps_changed)\n            copy_fields(s, s1, qps, superblock_count);\n#undef copy_fields\n    }\n\n    update_frames(dst);\n\n    return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -9,7 +9,7 @@\n         ||s->width != s1->width\n         ||s->height!= s1->height) {\n         if (s != s1)\n-            copy_fields(s, s1, golden_frame, current_frame);\n+            copy_fields(s, s1, golden_frame, keyframe);\n         return -1;\n     }\n ",
        "diff_line_info": {
            "deleted_lines": [
                "            copy_fields(s, s1, golden_frame, current_frame);"
            ],
            "added_lines": [
                "            copy_fields(s, s1, golden_frame, keyframe);"
            ]
        }
    },
    {
        "cve_id": "CVE-2011-3946",
        "func_name": "ffmpeg/ff_h264_decode_sei",
        "description": "The ff_h264_decode_sei function in libavcodec/h264_sei.c in FFmpeg before 0.10 allows remote attackers to have an unspecified impact via crafted Supplemental enhancement information (SEI) data, which triggers an infinite loop.",
        "git_url": "http://git.videolan.org/?p=ffmpeg.git;a=commit;h=9decfc17bb76da34734296048d390b176abf404c",
        "commit_title": "",
        "commit_text": "h264_sei: Fix infinite loop.  Fixes not yet fixed parts of CVE-2011-3946.  ",
        "func_before": "int ff_h264_decode_sei(H264Context *h){\n    MpegEncContext * const s = &h->s;\n\n    while(get_bits_count(&s->gb) + 16 < s->gb.size_in_bits){\n        int size, type;\n\n        type=0;\n        do{\n            type+= show_bits(&s->gb, 8);\n        }while(get_bits(&s->gb, 8) == 255);\n\n        size=0;\n        do{\n            size+= show_bits(&s->gb, 8);\n        }while(get_bits(&s->gb, 8) == 255);\n\n        if(s->avctx->debug&FF_DEBUG_STARTCODE)\n            av_log(h->s.avctx, AV_LOG_DEBUG, \"SEI %d len:%d\\n\", type, size);\n\n        switch(type){\n        case SEI_TYPE_PIC_TIMING: // Picture timing SEI\n            if(decode_picture_timing(h) < 0)\n                return -1;\n            break;\n        case SEI_TYPE_USER_DATA_UNREGISTERED:\n            if(decode_unregistered_user_data(h, size) < 0)\n                return -1;\n            break;\n        case SEI_TYPE_RECOVERY_POINT:\n            if(decode_recovery_point(h) < 0)\n                return -1;\n            break;\n        case SEI_BUFFERING_PERIOD:\n            if(decode_buffering_period(h) < 0)\n                return -1;\n            break;\n        default:\n            skip_bits(&s->gb, 8*size);\n        }\n\n        //FIXME check bits here\n        align_get_bits(&s->gb);\n    }\n\n    return 0;\n}",
        "func": "int ff_h264_decode_sei(H264Context *h){\n    MpegEncContext * const s = &h->s;\n\n    while(get_bits_count(&s->gb) + 16 < s->gb.size_in_bits){\n        int size, type;\n\n        type=0;\n        do{\n            if (get_bits_left(&s->gb) < 8)\n                return -1;\n            type+= show_bits(&s->gb, 8);\n        }while(get_bits(&s->gb, 8) == 255);\n\n        size=0;\n        do{\n            if (get_bits_left(&s->gb) < 8)\n                return -1;\n            size+= show_bits(&s->gb, 8);\n        }while(get_bits(&s->gb, 8) == 255);\n\n        if(s->avctx->debug&FF_DEBUG_STARTCODE)\n            av_log(h->s.avctx, AV_LOG_DEBUG, \"SEI %d len:%d\\n\", type, size);\n\n        switch(type){\n        case SEI_TYPE_PIC_TIMING: // Picture timing SEI\n            if(decode_picture_timing(h) < 0)\n                return -1;\n            break;\n        case SEI_TYPE_USER_DATA_UNREGISTERED:\n            if(decode_unregistered_user_data(h, size) < 0)\n                return -1;\n            break;\n        case SEI_TYPE_RECOVERY_POINT:\n            if(decode_recovery_point(h) < 0)\n                return -1;\n            break;\n        case SEI_BUFFERING_PERIOD:\n            if(decode_buffering_period(h) < 0)\n                return -1;\n            break;\n        default:\n            skip_bits(&s->gb, 8*size);\n        }\n\n        //FIXME check bits here\n        align_get_bits(&s->gb);\n    }\n\n    return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -6,11 +6,15 @@\n \n         type=0;\n         do{\n+            if (get_bits_left(&s->gb) < 8)\n+                return -1;\n             type+= show_bits(&s->gb, 8);\n         }while(get_bits(&s->gb, 8) == 255);\n \n         size=0;\n         do{\n+            if (get_bits_left(&s->gb) < 8)\n+                return -1;\n             size+= show_bits(&s->gb, 8);\n         }while(get_bits(&s->gb, 8) == 255);\n ",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "            if (get_bits_left(&s->gb) < 8)",
                "                return -1;",
                "            if (get_bits_left(&s->gb) < 8)",
                "                return -1;"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-7021",
        "func_name": "ffmpeg/filter_frame",
        "description": "The filter_frame function in libavfilter/vf_fps.c in FFmpeg before 2.1 does not properly ensure the availability of FIFO content, which allows remote attackers to cause a denial of service (double free) or possibly have unspecified other impact via crafted data.",
        "git_url": "https://github.com/FFmpeg/FFmpeg/commit/cdd5df8189ff1537f7abe8defe971f80602cc2d2",
        "commit_title": "avfilter/vf_fps: make sure the fifo is not empty before using it",
        "commit_text": " Fixes Ticket2905 ",
        "func_before": "static int filter_frame(AVFilterLink *inlink, AVFrame *buf)\n{\n    AVFilterContext    *ctx = inlink->dst;\n    FPSContext           *s = ctx->priv;\n    AVFilterLink   *outlink = ctx->outputs[0];\n    int64_t delta;\n    int i, ret;\n\n    s->frames_in++;\n    /* discard frames until we get the first timestamp */\n    if (s->pts == AV_NOPTS_VALUE) {\n        if (buf->pts != AV_NOPTS_VALUE) {\n            ret = write_to_fifo(s->fifo, buf);\n            if (ret < 0)\n                return ret;\n\n            if (s->start_time != DBL_MAX && s->start_time != AV_NOPTS_VALUE) {\n                double first_pts = s->start_time * AV_TIME_BASE;\n                first_pts = FFMIN(FFMAX(first_pts, INT64_MIN), INT64_MAX);\n                s->first_pts = s->pts = av_rescale_q(first_pts, AV_TIME_BASE_Q,\n                                                     inlink->time_base);\n                av_log(ctx, AV_LOG_VERBOSE, \"Set first pts to (in:%\"PRId64\" out:%\"PRId64\")\\n\",\n                       s->first_pts, av_rescale_q(first_pts, AV_TIME_BASE_Q,\n                                                  outlink->time_base));\n            } else {\n                s->first_pts = s->pts = buf->pts;\n            }\n        } else {\n            av_log(ctx, AV_LOG_WARNING, \"Discarding initial frame(s) with no \"\n                   \"timestamp.\\n\");\n            av_frame_free(&buf);\n            s->drop++;\n        }\n        return 0;\n    }\n\n    /* now wait for the next timestamp */\n    if (buf->pts == AV_NOPTS_VALUE) {\n        return write_to_fifo(s->fifo, buf);\n    }\n\n    /* number of output frames */\n    delta = av_rescale_q_rnd(buf->pts - s->pts, inlink->time_base,\n                             outlink->time_base, s->rounding);\n\n    if (delta < 1) {\n        /* drop the frame and everything buffered except the first */\n        AVFrame *tmp;\n        int drop = av_fifo_size(s->fifo)/sizeof(AVFrame*);\n\n        av_log(ctx, AV_LOG_DEBUG, \"Dropping %d frame(s).\\n\", drop);\n        s->drop += drop;\n\n        av_fifo_generic_read(s->fifo, &tmp, sizeof(tmp), NULL);\n        flush_fifo(s->fifo);\n        ret = write_to_fifo(s->fifo, tmp);\n\n        av_frame_free(&buf);\n        return ret;\n    }\n\n    /* can output >= 1 frames */\n    for (i = 0; i < delta; i++) {\n        AVFrame *buf_out;\n        av_fifo_generic_read(s->fifo, &buf_out, sizeof(buf_out), NULL);\n\n        /* duplicate the frame if needed */\n        if (!av_fifo_size(s->fifo) && i < delta - 1) {\n            AVFrame *dup = av_frame_clone(buf_out);\n\n            av_log(ctx, AV_LOG_DEBUG, \"Duplicating frame.\\n\");\n            if (dup)\n                ret = write_to_fifo(s->fifo, dup);\n            else\n                ret = AVERROR(ENOMEM);\n\n            if (ret < 0) {\n                av_frame_free(&buf_out);\n                av_frame_free(&buf);\n                return ret;\n            }\n\n            s->dup++;\n        }\n\n        buf_out->pts = av_rescale_q(s->first_pts, inlink->time_base,\n                                    outlink->time_base) + s->frames_out;\n\n        if ((ret = ff_filter_frame(outlink, buf_out)) < 0) {\n            av_frame_free(&buf);\n            return ret;\n        }\n\n        s->frames_out++;\n    }\n    flush_fifo(s->fifo);\n\n    ret = write_to_fifo(s->fifo, buf);\n    s->pts = s->first_pts + av_rescale_q(s->frames_out, outlink->time_base, inlink->time_base);\n\n    return ret;\n}",
        "func": "static int filter_frame(AVFilterLink *inlink, AVFrame *buf)\n{\n    AVFilterContext    *ctx = inlink->dst;\n    FPSContext           *s = ctx->priv;\n    AVFilterLink   *outlink = ctx->outputs[0];\n    int64_t delta;\n    int i, ret;\n\n    s->frames_in++;\n    /* discard frames until we get the first timestamp */\n    if (s->pts == AV_NOPTS_VALUE) {\n        if (buf->pts != AV_NOPTS_VALUE) {\n            ret = write_to_fifo(s->fifo, buf);\n            if (ret < 0)\n                return ret;\n\n            if (s->start_time != DBL_MAX && s->start_time != AV_NOPTS_VALUE) {\n                double first_pts = s->start_time * AV_TIME_BASE;\n                first_pts = FFMIN(FFMAX(first_pts, INT64_MIN), INT64_MAX);\n                s->first_pts = s->pts = av_rescale_q(first_pts, AV_TIME_BASE_Q,\n                                                     inlink->time_base);\n                av_log(ctx, AV_LOG_VERBOSE, \"Set first pts to (in:%\"PRId64\" out:%\"PRId64\")\\n\",\n                       s->first_pts, av_rescale_q(first_pts, AV_TIME_BASE_Q,\n                                                  outlink->time_base));\n            } else {\n                s->first_pts = s->pts = buf->pts;\n            }\n        } else {\n            av_log(ctx, AV_LOG_WARNING, \"Discarding initial frame(s) with no \"\n                   \"timestamp.\\n\");\n            av_frame_free(&buf);\n            s->drop++;\n        }\n        return 0;\n    }\n\n    /* now wait for the next timestamp */\n    if (buf->pts == AV_NOPTS_VALUE || av_fifo_size(s->fifo) <= 0) {\n        return write_to_fifo(s->fifo, buf);\n    }\n\n    /* number of output frames */\n    delta = av_rescale_q_rnd(buf->pts - s->pts, inlink->time_base,\n                             outlink->time_base, s->rounding);\n\n    if (delta < 1) {\n        /* drop the frame and everything buffered except the first */\n        AVFrame *tmp;\n        int drop = av_fifo_size(s->fifo)/sizeof(AVFrame*);\n\n        av_log(ctx, AV_LOG_DEBUG, \"Dropping %d frame(s).\\n\", drop);\n        s->drop += drop;\n\n        av_fifo_generic_read(s->fifo, &tmp, sizeof(tmp), NULL);\n        flush_fifo(s->fifo);\n        ret = write_to_fifo(s->fifo, tmp);\n\n        av_frame_free(&buf);\n        return ret;\n    }\n\n    /* can output >= 1 frames */\n    for (i = 0; i < delta; i++) {\n        AVFrame *buf_out;\n        av_fifo_generic_read(s->fifo, &buf_out, sizeof(buf_out), NULL);\n\n        /* duplicate the frame if needed */\n        if (!av_fifo_size(s->fifo) && i < delta - 1) {\n            AVFrame *dup = av_frame_clone(buf_out);\n\n            av_log(ctx, AV_LOG_DEBUG, \"Duplicating frame.\\n\");\n            if (dup)\n                ret = write_to_fifo(s->fifo, dup);\n            else\n                ret = AVERROR(ENOMEM);\n\n            if (ret < 0) {\n                av_frame_free(&buf_out);\n                av_frame_free(&buf);\n                return ret;\n            }\n\n            s->dup++;\n        }\n\n        buf_out->pts = av_rescale_q(s->first_pts, inlink->time_base,\n                                    outlink->time_base) + s->frames_out;\n\n        if ((ret = ff_filter_frame(outlink, buf_out)) < 0) {\n            av_frame_free(&buf);\n            return ret;\n        }\n\n        s->frames_out++;\n    }\n    flush_fifo(s->fifo);\n\n    ret = write_to_fifo(s->fifo, buf);\n    s->pts = s->first_pts + av_rescale_q(s->frames_out, outlink->time_base, inlink->time_base);\n\n    return ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -35,7 +35,7 @@\n     }\n \n     /* now wait for the next timestamp */\n-    if (buf->pts == AV_NOPTS_VALUE) {\n+    if (buf->pts == AV_NOPTS_VALUE || av_fifo_size(s->fifo) <= 0) {\n         return write_to_fifo(s->fifo, buf);\n     }\n ",
        "diff_line_info": {
            "deleted_lines": [
                "    if (buf->pts == AV_NOPTS_VALUE) {"
            ],
            "added_lines": [
                "    if (buf->pts == AV_NOPTS_VALUE || av_fifo_size(s->fifo) <= 0) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-1444",
        "func_name": "torvalds/linux/fst_get_iface",
        "description": "The fst_get_iface function in drivers/net/wan/farsync.c in the Linux kernel before 3.11.7 does not properly initialize a certain data structure, which allows local users to obtain sensitive information from kernel memory by leveraging the CAP_NET_ADMIN capability for an SIOCWANDEV ioctl call.",
        "git_url": "https://github.com/torvalds/linux/commit/96b340406724d87e4621284ebac5e059d67b2194",
        "commit_title": "farsync: fix info leak in ioctl",
        "commit_text": " The fst_get_iface() code fails to initialize the two padding bytes of struct sync_serial_settings after the ->loopback member. Add an explicit memset(0) before filling the structure to avoid the info leak. ",
        "func_before": "static int\nfst_get_iface(struct fst_card_info *card, struct fst_port_info *port,\n\t      struct ifreq *ifr)\n{\n\tsync_serial_settings sync;\n\tint i;\n\n\t/* First check what line type is set, we'll default to reporting X.21\n\t * if nothing is set as IF_IFACE_SYNC_SERIAL implies it can't be\n\t * changed\n\t */\n\tswitch (port->hwif) {\n\tcase E1:\n\t\tifr->ifr_settings.type = IF_IFACE_E1;\n\t\tbreak;\n\tcase T1:\n\t\tifr->ifr_settings.type = IF_IFACE_T1;\n\t\tbreak;\n\tcase V35:\n\t\tifr->ifr_settings.type = IF_IFACE_V35;\n\t\tbreak;\n\tcase V24:\n\t\tifr->ifr_settings.type = IF_IFACE_V24;\n\t\tbreak;\n\tcase X21D:\n\t\tifr->ifr_settings.type = IF_IFACE_X21D;\n\t\tbreak;\n\tcase X21:\n\tdefault:\n\t\tifr->ifr_settings.type = IF_IFACE_X21;\n\t\tbreak;\n\t}\n\tif (ifr->ifr_settings.size == 0) {\n\t\treturn 0;\t/* only type requested */\n\t}\n\tif (ifr->ifr_settings.size < sizeof (sync)) {\n\t\treturn -ENOMEM;\n\t}\n\n\ti = port->index;\n\tsync.clock_rate = FST_RDL(card, portConfig[i].lineSpeed);\n\t/* Lucky card and linux use same encoding here */\n\tsync.clock_type = FST_RDB(card, portConfig[i].internalClock) ==\n\t    INTCLK ? CLOCK_INT : CLOCK_EXT;\n\tsync.loopback = 0;\n\n\tif (copy_to_user(ifr->ifr_settings.ifs_ifsu.sync, &sync, sizeof (sync))) {\n\t\treturn -EFAULT;\n\t}\n\n\tifr->ifr_settings.size = sizeof (sync);\n\treturn 0;\n}",
        "func": "static int\nfst_get_iface(struct fst_card_info *card, struct fst_port_info *port,\n\t      struct ifreq *ifr)\n{\n\tsync_serial_settings sync;\n\tint i;\n\n\t/* First check what line type is set, we'll default to reporting X.21\n\t * if nothing is set as IF_IFACE_SYNC_SERIAL implies it can't be\n\t * changed\n\t */\n\tswitch (port->hwif) {\n\tcase E1:\n\t\tifr->ifr_settings.type = IF_IFACE_E1;\n\t\tbreak;\n\tcase T1:\n\t\tifr->ifr_settings.type = IF_IFACE_T1;\n\t\tbreak;\n\tcase V35:\n\t\tifr->ifr_settings.type = IF_IFACE_V35;\n\t\tbreak;\n\tcase V24:\n\t\tifr->ifr_settings.type = IF_IFACE_V24;\n\t\tbreak;\n\tcase X21D:\n\t\tifr->ifr_settings.type = IF_IFACE_X21D;\n\t\tbreak;\n\tcase X21:\n\tdefault:\n\t\tifr->ifr_settings.type = IF_IFACE_X21;\n\t\tbreak;\n\t}\n\tif (ifr->ifr_settings.size == 0) {\n\t\treturn 0;\t/* only type requested */\n\t}\n\tif (ifr->ifr_settings.size < sizeof (sync)) {\n\t\treturn -ENOMEM;\n\t}\n\n\ti = port->index;\n\tmemset(&sync, 0, sizeof(sync));\n\tsync.clock_rate = FST_RDL(card, portConfig[i].lineSpeed);\n\t/* Lucky card and linux use same encoding here */\n\tsync.clock_type = FST_RDB(card, portConfig[i].internalClock) ==\n\t    INTCLK ? CLOCK_INT : CLOCK_EXT;\n\tsync.loopback = 0;\n\n\tif (copy_to_user(ifr->ifr_settings.ifs_ifsu.sync, &sync, sizeof (sync))) {\n\t\treturn -EFAULT;\n\t}\n\n\tifr->ifr_settings.size = sizeof (sync);\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -38,6 +38,7 @@\n \t}\n \n \ti = port->index;\n+\tmemset(&sync, 0, sizeof(sync));\n \tsync.clock_rate = FST_RDL(card, portConfig[i].lineSpeed);\n \t/* Lucky card and linux use same encoding here */\n \tsync.clock_type = FST_RDB(card, portConfig[i].internalClock) ==",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tmemset(&sync, 0, sizeof(sync));"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-1445",
        "func_name": "torvalds/linux/wanxl_ioctl",
        "description": "The wanxl_ioctl function in drivers/net/wan/wanxl.c in the Linux kernel before 3.11.7 does not properly initialize a certain data structure, which allows local users to obtain sensitive information from kernel memory via an ioctl call.",
        "git_url": "https://github.com/torvalds/linux/commit/2b13d06c9584b4eb773f1e80bbaedab9a1c344e1",
        "commit_title": "wanxl: fix info leak in ioctl",
        "commit_text": " The wanxl_ioctl() code fails to initialize the two padding bytes of struct sync_serial_settings after the ->loopback member. Add an explicit memset(0) before filling the structure to avoid the info leak. ",
        "func_before": "static int wanxl_ioctl(struct net_device *dev, struct ifreq *ifr, int cmd)\n{\n\tconst size_t size = sizeof(sync_serial_settings);\n\tsync_serial_settings line;\n\tport_t *port = dev_to_port(dev);\n\n\tif (cmd != SIOCWANDEV)\n\t\treturn hdlc_ioctl(dev, ifr, cmd);\n\n\tswitch (ifr->ifr_settings.type) {\n\tcase IF_GET_IFACE:\n\t\tifr->ifr_settings.type = IF_IFACE_SYNC_SERIAL;\n\t\tif (ifr->ifr_settings.size < size) {\n\t\t\tifr->ifr_settings.size = size; /* data size wanted */\n\t\t\treturn -ENOBUFS;\n\t\t}\n\t\tline.clock_type = get_status(port)->clocking;\n\t\tline.clock_rate = 0;\n\t\tline.loopback = 0;\n\n\t\tif (copy_to_user(ifr->ifr_settings.ifs_ifsu.sync, &line, size))\n\t\t\treturn -EFAULT;\n\t\treturn 0;\n\n\tcase IF_IFACE_SYNC_SERIAL:\n\t\tif (!capable(CAP_NET_ADMIN))\n\t\t\treturn -EPERM;\n\t\tif (dev->flags & IFF_UP)\n\t\t\treturn -EBUSY;\n\n\t\tif (copy_from_user(&line, ifr->ifr_settings.ifs_ifsu.sync,\n\t\t\t\t   size))\n\t\t\treturn -EFAULT;\n\n\t\tif (line.clock_type != CLOCK_EXT &&\n\t\t    line.clock_type != CLOCK_TXFROMRX)\n\t\t\treturn -EINVAL; /* No such clock setting */\n\n\t\tif (line.loopback != 0)\n\t\t\treturn -EINVAL;\n\n\t\tget_status(port)->clocking = line.clock_type;\n\t\treturn 0;\n\n\tdefault:\n\t\treturn hdlc_ioctl(dev, ifr, cmd);\n        }\n}",
        "func": "static int wanxl_ioctl(struct net_device *dev, struct ifreq *ifr, int cmd)\n{\n\tconst size_t size = sizeof(sync_serial_settings);\n\tsync_serial_settings line;\n\tport_t *port = dev_to_port(dev);\n\n\tif (cmd != SIOCWANDEV)\n\t\treturn hdlc_ioctl(dev, ifr, cmd);\n\n\tswitch (ifr->ifr_settings.type) {\n\tcase IF_GET_IFACE:\n\t\tifr->ifr_settings.type = IF_IFACE_SYNC_SERIAL;\n\t\tif (ifr->ifr_settings.size < size) {\n\t\t\tifr->ifr_settings.size = size; /* data size wanted */\n\t\t\treturn -ENOBUFS;\n\t\t}\n\t\tmemset(&line, 0, sizeof(line));\n\t\tline.clock_type = get_status(port)->clocking;\n\t\tline.clock_rate = 0;\n\t\tline.loopback = 0;\n\n\t\tif (copy_to_user(ifr->ifr_settings.ifs_ifsu.sync, &line, size))\n\t\t\treturn -EFAULT;\n\t\treturn 0;\n\n\tcase IF_IFACE_SYNC_SERIAL:\n\t\tif (!capable(CAP_NET_ADMIN))\n\t\t\treturn -EPERM;\n\t\tif (dev->flags & IFF_UP)\n\t\t\treturn -EBUSY;\n\n\t\tif (copy_from_user(&line, ifr->ifr_settings.ifs_ifsu.sync,\n\t\t\t\t   size))\n\t\t\treturn -EFAULT;\n\n\t\tif (line.clock_type != CLOCK_EXT &&\n\t\t    line.clock_type != CLOCK_TXFROMRX)\n\t\t\treturn -EINVAL; /* No such clock setting */\n\n\t\tif (line.loopback != 0)\n\t\t\treturn -EINVAL;\n\n\t\tget_status(port)->clocking = line.clock_type;\n\t\treturn 0;\n\n\tdefault:\n\t\treturn hdlc_ioctl(dev, ifr, cmd);\n        }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -14,6 +14,7 @@\n \t\t\tifr->ifr_settings.size = size; /* data size wanted */\n \t\t\treturn -ENOBUFS;\n \t\t}\n+\t\tmemset(&line, 0, sizeof(line));\n \t\tline.clock_type = get_status(port)->clocking;\n \t\tline.clock_rate = 0;\n \t\tline.loopback = 0;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t\tmemset(&line, 0, sizeof(line));"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-1446",
        "func_name": "torvalds/linux/yam_ioctl",
        "description": "The yam_ioctl function in drivers/net/hamradio/yam.c in the Linux kernel before 3.12.8 does not initialize a certain structure member, which allows local users to obtain sensitive information from kernel memory by leveraging the CAP_NET_ADMIN capability for an SIOCYAMGCFG ioctl call.",
        "git_url": "https://github.com/torvalds/linux/commit/8e3fbf870481eb53b2d3a322d1fc395ad8b367ed",
        "commit_title": "hamradio/yam: fix info leak in ioctl",
        "commit_text": " The yam_ioctl() code fails to initialise the cmd field of the struct yamdrv_ioctl_cfg. Add an explicit memset(0) before filling the structure to avoid the 4-byte info leak. ",
        "func_before": "static int yam_ioctl(struct net_device *dev, struct ifreq *ifr, int cmd)\n{\n\tstruct yam_port *yp = netdev_priv(dev);\n\tstruct yamdrv_ioctl_cfg yi;\n\tstruct yamdrv_ioctl_mcs *ym;\n\tint ioctl_cmd;\n\n\tif (copy_from_user(&ioctl_cmd, ifr->ifr_data, sizeof(int)))\n\t\t return -EFAULT;\n\n\tif (yp->magic != YAM_MAGIC)\n\t\treturn -EINVAL;\n\n\tif (!capable(CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tif (cmd != SIOCDEVPRIVATE)\n\t\treturn -EINVAL;\n\n\tswitch (ioctl_cmd) {\n\n\tcase SIOCYAMRESERVED:\n\t\treturn -EINVAL;\t\t\t/* unused */\n\n\tcase SIOCYAMSMCS:\n\t\tif (netif_running(dev))\n\t\t\treturn -EINVAL;\t\t/* Cannot change this parameter when up */\n\t\tif ((ym = kmalloc(sizeof(struct yamdrv_ioctl_mcs), GFP_KERNEL)) == NULL)\n\t\t\treturn -ENOBUFS;\n\t\tif (copy_from_user(ym, ifr->ifr_data, sizeof(struct yamdrv_ioctl_mcs))) {\n\t\t\tkfree(ym);\n\t\t\treturn -EFAULT;\n\t\t}\n\t\tif (ym->bitrate > YAM_MAXBITRATE) {\n\t\t\tkfree(ym);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\t/* setting predef as 0 for loading userdefined mcs data */\n\t\tadd_mcs(ym->bits, ym->bitrate, 0);\n\t\tkfree(ym);\n\t\tbreak;\n\n\tcase SIOCYAMSCFG:\n\t\tif (!capable(CAP_SYS_RAWIO))\n\t\t\treturn -EPERM;\n\t\tif (copy_from_user(&yi, ifr->ifr_data, sizeof(struct yamdrv_ioctl_cfg)))\n\t\t\t return -EFAULT;\n\n\t\tif ((yi.cfg.mask & YAM_IOBASE) && netif_running(dev))\n\t\t\treturn -EINVAL;\t\t/* Cannot change this parameter when up */\n\t\tif ((yi.cfg.mask & YAM_IRQ) && netif_running(dev))\n\t\t\treturn -EINVAL;\t\t/* Cannot change this parameter when up */\n\t\tif ((yi.cfg.mask & YAM_BITRATE) && netif_running(dev))\n\t\t\treturn -EINVAL;\t\t/* Cannot change this parameter when up */\n\t\tif ((yi.cfg.mask & YAM_BAUDRATE) && netif_running(dev))\n\t\t\treturn -EINVAL;\t\t/* Cannot change this parameter when up */\n\n\t\tif (yi.cfg.mask & YAM_IOBASE) {\n\t\t\typ->iobase = yi.cfg.iobase;\n\t\t\tdev->base_addr = yi.cfg.iobase;\n\t\t}\n\t\tif (yi.cfg.mask & YAM_IRQ) {\n\t\t\tif (yi.cfg.irq > 15)\n\t\t\t\treturn -EINVAL;\n\t\t\typ->irq = yi.cfg.irq;\n\t\t\tdev->irq = yi.cfg.irq;\n\t\t}\n\t\tif (yi.cfg.mask & YAM_BITRATE) {\n\t\t\tif (yi.cfg.bitrate > YAM_MAXBITRATE)\n\t\t\t\treturn -EINVAL;\n\t\t\typ->bitrate = yi.cfg.bitrate;\n\t\t}\n\t\tif (yi.cfg.mask & YAM_BAUDRATE) {\n\t\t\tif (yi.cfg.baudrate > YAM_MAXBAUDRATE)\n\t\t\t\treturn -EINVAL;\n\t\t\typ->baudrate = yi.cfg.baudrate;\n\t\t}\n\t\tif (yi.cfg.mask & YAM_MODE) {\n\t\t\tif (yi.cfg.mode > YAM_MAXMODE)\n\t\t\t\treturn -EINVAL;\n\t\t\typ->dupmode = yi.cfg.mode;\n\t\t}\n\t\tif (yi.cfg.mask & YAM_HOLDDLY) {\n\t\t\tif (yi.cfg.holddly > YAM_MAXHOLDDLY)\n\t\t\t\treturn -EINVAL;\n\t\t\typ->holdd = yi.cfg.holddly;\n\t\t}\n\t\tif (yi.cfg.mask & YAM_TXDELAY) {\n\t\t\tif (yi.cfg.txdelay > YAM_MAXTXDELAY)\n\t\t\t\treturn -EINVAL;\n\t\t\typ->txd = yi.cfg.txdelay;\n\t\t}\n\t\tif (yi.cfg.mask & YAM_TXTAIL) {\n\t\t\tif (yi.cfg.txtail > YAM_MAXTXTAIL)\n\t\t\t\treturn -EINVAL;\n\t\t\typ->txtail = yi.cfg.txtail;\n\t\t}\n\t\tif (yi.cfg.mask & YAM_PERSIST) {\n\t\t\tif (yi.cfg.persist > YAM_MAXPERSIST)\n\t\t\t\treturn -EINVAL;\n\t\t\typ->pers = yi.cfg.persist;\n\t\t}\n\t\tif (yi.cfg.mask & YAM_SLOTTIME) {\n\t\t\tif (yi.cfg.slottime > YAM_MAXSLOTTIME)\n\t\t\t\treturn -EINVAL;\n\t\t\typ->slot = yi.cfg.slottime;\n\t\t\typ->slotcnt = yp->slot / 10;\n\t\t}\n\t\tbreak;\n\n\tcase SIOCYAMGCFG:\n\t\tyi.cfg.mask = 0xffffffff;\n\t\tyi.cfg.iobase = yp->iobase;\n\t\tyi.cfg.irq = yp->irq;\n\t\tyi.cfg.bitrate = yp->bitrate;\n\t\tyi.cfg.baudrate = yp->baudrate;\n\t\tyi.cfg.mode = yp->dupmode;\n\t\tyi.cfg.txdelay = yp->txd;\n\t\tyi.cfg.holddly = yp->holdd;\n\t\tyi.cfg.txtail = yp->txtail;\n\t\tyi.cfg.persist = yp->pers;\n\t\tyi.cfg.slottime = yp->slot;\n\t\tif (copy_to_user(ifr->ifr_data, &yi, sizeof(struct yamdrv_ioctl_cfg)))\n\t\t\t return -EFAULT;\n\t\tbreak;\n\n\tdefault:\n\t\treturn -EINVAL;\n\n\t}\n\n\treturn 0;\n}",
        "func": "static int yam_ioctl(struct net_device *dev, struct ifreq *ifr, int cmd)\n{\n\tstruct yam_port *yp = netdev_priv(dev);\n\tstruct yamdrv_ioctl_cfg yi;\n\tstruct yamdrv_ioctl_mcs *ym;\n\tint ioctl_cmd;\n\n\tif (copy_from_user(&ioctl_cmd, ifr->ifr_data, sizeof(int)))\n\t\t return -EFAULT;\n\n\tif (yp->magic != YAM_MAGIC)\n\t\treturn -EINVAL;\n\n\tif (!capable(CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tif (cmd != SIOCDEVPRIVATE)\n\t\treturn -EINVAL;\n\n\tswitch (ioctl_cmd) {\n\n\tcase SIOCYAMRESERVED:\n\t\treturn -EINVAL;\t\t\t/* unused */\n\n\tcase SIOCYAMSMCS:\n\t\tif (netif_running(dev))\n\t\t\treturn -EINVAL;\t\t/* Cannot change this parameter when up */\n\t\tif ((ym = kmalloc(sizeof(struct yamdrv_ioctl_mcs), GFP_KERNEL)) == NULL)\n\t\t\treturn -ENOBUFS;\n\t\tif (copy_from_user(ym, ifr->ifr_data, sizeof(struct yamdrv_ioctl_mcs))) {\n\t\t\tkfree(ym);\n\t\t\treturn -EFAULT;\n\t\t}\n\t\tif (ym->bitrate > YAM_MAXBITRATE) {\n\t\t\tkfree(ym);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\t/* setting predef as 0 for loading userdefined mcs data */\n\t\tadd_mcs(ym->bits, ym->bitrate, 0);\n\t\tkfree(ym);\n\t\tbreak;\n\n\tcase SIOCYAMSCFG:\n\t\tif (!capable(CAP_SYS_RAWIO))\n\t\t\treturn -EPERM;\n\t\tif (copy_from_user(&yi, ifr->ifr_data, sizeof(struct yamdrv_ioctl_cfg)))\n\t\t\t return -EFAULT;\n\n\t\tif ((yi.cfg.mask & YAM_IOBASE) && netif_running(dev))\n\t\t\treturn -EINVAL;\t\t/* Cannot change this parameter when up */\n\t\tif ((yi.cfg.mask & YAM_IRQ) && netif_running(dev))\n\t\t\treturn -EINVAL;\t\t/* Cannot change this parameter when up */\n\t\tif ((yi.cfg.mask & YAM_BITRATE) && netif_running(dev))\n\t\t\treturn -EINVAL;\t\t/* Cannot change this parameter when up */\n\t\tif ((yi.cfg.mask & YAM_BAUDRATE) && netif_running(dev))\n\t\t\treturn -EINVAL;\t\t/* Cannot change this parameter when up */\n\n\t\tif (yi.cfg.mask & YAM_IOBASE) {\n\t\t\typ->iobase = yi.cfg.iobase;\n\t\t\tdev->base_addr = yi.cfg.iobase;\n\t\t}\n\t\tif (yi.cfg.mask & YAM_IRQ) {\n\t\t\tif (yi.cfg.irq > 15)\n\t\t\t\treturn -EINVAL;\n\t\t\typ->irq = yi.cfg.irq;\n\t\t\tdev->irq = yi.cfg.irq;\n\t\t}\n\t\tif (yi.cfg.mask & YAM_BITRATE) {\n\t\t\tif (yi.cfg.bitrate > YAM_MAXBITRATE)\n\t\t\t\treturn -EINVAL;\n\t\t\typ->bitrate = yi.cfg.bitrate;\n\t\t}\n\t\tif (yi.cfg.mask & YAM_BAUDRATE) {\n\t\t\tif (yi.cfg.baudrate > YAM_MAXBAUDRATE)\n\t\t\t\treturn -EINVAL;\n\t\t\typ->baudrate = yi.cfg.baudrate;\n\t\t}\n\t\tif (yi.cfg.mask & YAM_MODE) {\n\t\t\tif (yi.cfg.mode > YAM_MAXMODE)\n\t\t\t\treturn -EINVAL;\n\t\t\typ->dupmode = yi.cfg.mode;\n\t\t}\n\t\tif (yi.cfg.mask & YAM_HOLDDLY) {\n\t\t\tif (yi.cfg.holddly > YAM_MAXHOLDDLY)\n\t\t\t\treturn -EINVAL;\n\t\t\typ->holdd = yi.cfg.holddly;\n\t\t}\n\t\tif (yi.cfg.mask & YAM_TXDELAY) {\n\t\t\tif (yi.cfg.txdelay > YAM_MAXTXDELAY)\n\t\t\t\treturn -EINVAL;\n\t\t\typ->txd = yi.cfg.txdelay;\n\t\t}\n\t\tif (yi.cfg.mask & YAM_TXTAIL) {\n\t\t\tif (yi.cfg.txtail > YAM_MAXTXTAIL)\n\t\t\t\treturn -EINVAL;\n\t\t\typ->txtail = yi.cfg.txtail;\n\t\t}\n\t\tif (yi.cfg.mask & YAM_PERSIST) {\n\t\t\tif (yi.cfg.persist > YAM_MAXPERSIST)\n\t\t\t\treturn -EINVAL;\n\t\t\typ->pers = yi.cfg.persist;\n\t\t}\n\t\tif (yi.cfg.mask & YAM_SLOTTIME) {\n\t\t\tif (yi.cfg.slottime > YAM_MAXSLOTTIME)\n\t\t\t\treturn -EINVAL;\n\t\t\typ->slot = yi.cfg.slottime;\n\t\t\typ->slotcnt = yp->slot / 10;\n\t\t}\n\t\tbreak;\n\n\tcase SIOCYAMGCFG:\n\t\tmemset(&yi, 0, sizeof(yi));\n\t\tyi.cfg.mask = 0xffffffff;\n\t\tyi.cfg.iobase = yp->iobase;\n\t\tyi.cfg.irq = yp->irq;\n\t\tyi.cfg.bitrate = yp->bitrate;\n\t\tyi.cfg.baudrate = yp->baudrate;\n\t\tyi.cfg.mode = yp->dupmode;\n\t\tyi.cfg.txdelay = yp->txd;\n\t\tyi.cfg.holddly = yp->holdd;\n\t\tyi.cfg.txtail = yp->txtail;\n\t\tyi.cfg.persist = yp->pers;\n\t\tyi.cfg.slottime = yp->slot;\n\t\tif (copy_to_user(ifr->ifr_data, &yi, sizeof(struct yamdrv_ioctl_cfg)))\n\t\t\t return -EFAULT;\n\t\tbreak;\n\n\tdefault:\n\t\treturn -EINVAL;\n\n\t}\n\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -109,6 +109,7 @@\n \t\tbreak;\n \n \tcase SIOCYAMGCFG:\n+\t\tmemset(&yi, 0, sizeof(yi));\n \t\tyi.cfg.mask = 0xffffffff;\n \t\tyi.cfg.iobase = yp->iobase;\n \t\tyi.cfg.irq = yp->irq;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t\tmemset(&yi, 0, sizeof(yi));"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-1642",
        "func_name": "xen-project/xen/pirq_guest_bind",
        "description": "The IRQ setup in Xen 4.2.x and 4.3.x, when using device passthrough and configured to support a large number of CPUs, frees certain memory that may still be intended for use, which allows local guest administrators to cause a denial of service (memory corruption and hypervisor crash) and possibly execute arbitrary code via vectors related to an out-of-memory error that triggers a (1) use-after-free or (2) double free.",
        "git_url": "https://github.com/xen-project/xen/commit/650fc2f76d0a156e23703683d0c18fa262ecea36",
        "commit_title": "x86/irq: avoid use-after-free on error path in pirq_guest_bind()",
        "commit_text": " This is XSA-83.  Coverity-ID: 1146952 ",
        "func_before": "int pirq_guest_bind(struct vcpu *v, struct pirq *pirq, int will_share)\n{\n    unsigned int        irq;\n    struct irq_desc         *desc;\n    irq_guest_action_t *action, *newaction = NULL;\n    int                 rc = 0;\n\n    WARN_ON(!spin_is_locked(&v->domain->event_lock));\n    BUG_ON(!local_irq_is_enabled());\n\n retry:\n    desc = pirq_spin_lock_irq_desc(pirq, NULL);\n    if ( desc == NULL )\n    {\n        rc = -EINVAL;\n        goto out;\n    }\n\n    action = (irq_guest_action_t *)desc->action;\n    irq = desc - irq_desc;\n\n    if ( !(desc->status & IRQ_GUEST) )\n    {\n        if ( desc->action != NULL )\n        {\n            printk(XENLOG_G_INFO\n                   \"Cannot bind IRQ%d to dom%d. In use by '%s'.\\n\",\n                   pirq->pirq, v->domain->domain_id, desc->action->name);\n            rc = -EBUSY;\n            goto unlock_out;\n        }\n\n        if ( newaction == NULL )\n        {\n            spin_unlock_irq(&desc->lock);\n            if ( (newaction = xmalloc(irq_guest_action_t)) != NULL &&\n                 zalloc_cpumask_var(&newaction->cpu_eoi_map) )\n                goto retry;\n            xfree(newaction);\n            printk(XENLOG_G_INFO\n                   \"Cannot bind IRQ%d to dom%d. Out of memory.\\n\",\n                   pirq->pirq, v->domain->domain_id);\n            rc = -ENOMEM;\n            goto out;\n        }\n\n        action = newaction;\n        desc->action = (struct irqaction *)action;\n        newaction = NULL;\n\n        action->nr_guests   = 0;\n        action->in_flight   = 0;\n        action->shareable   = will_share;\n        action->ack_type    = pirq_acktype(v->domain, pirq->pirq);\n        init_timer(&action->eoi_timer, irq_guest_eoi_timer_fn, desc, 0);\n\n        desc->status |= IRQ_GUEST;\n        desc->status &= ~IRQ_DISABLED;\n        desc->handler->startup(desc);\n\n        /* Attempt to bind the interrupt target to the correct CPU. */\n        if ( !opt_noirqbalance && (desc->handler->set_affinity != NULL) )\n            desc->handler->set_affinity(desc, cpumask_of(v->processor));\n    }\n    else if ( !will_share || !action->shareable )\n    {\n        printk(XENLOG_G_INFO \"Cannot bind IRQ%d to dom%d. %s.\\n\",\n               pirq->pirq, v->domain->domain_id,\n               will_share ? \"Others do not share\"\n                          : \"Will not share with others\");\n        rc = -EBUSY;\n        goto unlock_out;\n    }\n    else if ( action->nr_guests == 0 )\n    {\n        /*\n         * Indicates that an ACKTYPE_EOI interrupt is being released.\n         * Wait for that to happen before continuing.\n         */\n        ASSERT(action->ack_type == ACKTYPE_EOI);\n        ASSERT(desc->status & IRQ_DISABLED);\n        spin_unlock_irq(&desc->lock);\n        cpu_relax();\n        goto retry;\n    }\n\n    if ( action->nr_guests == IRQ_MAX_GUESTS )\n    {\n        printk(XENLOG_G_INFO \"Cannot bind IRQ%d to dom%d. \"\n               \"Already at max share.\\n\",\n               pirq->pirq, v->domain->domain_id);\n        rc = -EBUSY;\n        goto unlock_out;\n    }\n\n    action->guest[action->nr_guests++] = v->domain;\n\n    if ( action->ack_type != ACKTYPE_NONE )\n        set_pirq_eoi(v->domain, pirq->pirq);\n    else\n        clear_pirq_eoi(v->domain, pirq->pirq);\n\n unlock_out:\n    spin_unlock_irq(&desc->lock);\n out:\n    if ( newaction != NULL )\n    {\n        free_cpumask_var(newaction->cpu_eoi_map);\n        xfree(newaction);\n    }\n    return rc;\n}",
        "func": "int pirq_guest_bind(struct vcpu *v, struct pirq *pirq, int will_share)\n{\n    unsigned int        irq;\n    struct irq_desc         *desc;\n    irq_guest_action_t *action, *newaction = NULL;\n    int                 rc = 0;\n\n    WARN_ON(!spin_is_locked(&v->domain->event_lock));\n    BUG_ON(!local_irq_is_enabled());\n\n retry:\n    desc = pirq_spin_lock_irq_desc(pirq, NULL);\n    if ( desc == NULL )\n    {\n        rc = -EINVAL;\n        goto out;\n    }\n\n    action = (irq_guest_action_t *)desc->action;\n    irq = desc - irq_desc;\n\n    if ( !(desc->status & IRQ_GUEST) )\n    {\n        if ( desc->action != NULL )\n        {\n            printk(XENLOG_G_INFO\n                   \"Cannot bind IRQ%d to dom%d. In use by '%s'.\\n\",\n                   pirq->pirq, v->domain->domain_id, desc->action->name);\n            rc = -EBUSY;\n            goto unlock_out;\n        }\n\n        if ( newaction == NULL )\n        {\n            spin_unlock_irq(&desc->lock);\n            if ( (newaction = xmalloc(irq_guest_action_t)) != NULL &&\n                 zalloc_cpumask_var(&newaction->cpu_eoi_map) )\n                goto retry;\n            xfree(newaction);\n            printk(XENLOG_G_INFO\n                   \"Cannot bind IRQ%d to dom%d. Out of memory.\\n\",\n                   pirq->pirq, v->domain->domain_id);\n            return -ENOMEM;\n        }\n\n        action = newaction;\n        desc->action = (struct irqaction *)action;\n        newaction = NULL;\n\n        action->nr_guests   = 0;\n        action->in_flight   = 0;\n        action->shareable   = will_share;\n        action->ack_type    = pirq_acktype(v->domain, pirq->pirq);\n        init_timer(&action->eoi_timer, irq_guest_eoi_timer_fn, desc, 0);\n\n        desc->status |= IRQ_GUEST;\n        desc->status &= ~IRQ_DISABLED;\n        desc->handler->startup(desc);\n\n        /* Attempt to bind the interrupt target to the correct CPU. */\n        if ( !opt_noirqbalance && (desc->handler->set_affinity != NULL) )\n            desc->handler->set_affinity(desc, cpumask_of(v->processor));\n    }\n    else if ( !will_share || !action->shareable )\n    {\n        printk(XENLOG_G_INFO \"Cannot bind IRQ%d to dom%d. %s.\\n\",\n               pirq->pirq, v->domain->domain_id,\n               will_share ? \"Others do not share\"\n                          : \"Will not share with others\");\n        rc = -EBUSY;\n        goto unlock_out;\n    }\n    else if ( action->nr_guests == 0 )\n    {\n        /*\n         * Indicates that an ACKTYPE_EOI interrupt is being released.\n         * Wait for that to happen before continuing.\n         */\n        ASSERT(action->ack_type == ACKTYPE_EOI);\n        ASSERT(desc->status & IRQ_DISABLED);\n        spin_unlock_irq(&desc->lock);\n        cpu_relax();\n        goto retry;\n    }\n\n    if ( action->nr_guests == IRQ_MAX_GUESTS )\n    {\n        printk(XENLOG_G_INFO \"Cannot bind IRQ%d to dom%d. \"\n               \"Already at max share.\\n\",\n               pirq->pirq, v->domain->domain_id);\n        rc = -EBUSY;\n        goto unlock_out;\n    }\n\n    action->guest[action->nr_guests++] = v->domain;\n\n    if ( action->ack_type != ACKTYPE_NONE )\n        set_pirq_eoi(v->domain, pirq->pirq);\n    else\n        clear_pirq_eoi(v->domain, pirq->pirq);\n\n unlock_out:\n    spin_unlock_irq(&desc->lock);\n out:\n    if ( newaction != NULL )\n    {\n        free_cpumask_var(newaction->cpu_eoi_map);\n        xfree(newaction);\n    }\n    return rc;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -40,8 +40,7 @@\n             printk(XENLOG_G_INFO\n                    \"Cannot bind IRQ%d to dom%d. Out of memory.\\n\",\n                    pirq->pirq, v->domain->domain_id);\n-            rc = -ENOMEM;\n-            goto out;\n+            return -ENOMEM;\n         }\n \n         action = newaction;",
        "diff_line_info": {
            "deleted_lines": [
                "            rc = -ENOMEM;",
                "            goto out;"
            ],
            "added_lines": [
                "            return -ENOMEM;"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-6649",
        "func_name": "chromium/RenderSVGImage::paint",
        "description": "Use-after-free vulnerability in the RenderSVGImage::paint function in core/rendering/svg/RenderSVGImage.cpp in Blink, as used in Google Chrome before 32.0.1700.102, allows remote attackers to cause a denial of service or possibly have unspecified other impact via vectors involving a zero-size SVG image.",
        "git_url": "https://github.com/chromium/chromium/commit/70bcb6b3396a395e871e10b2ff883d92b8218e9f",
        "commit_title": "Avoid drawing SVG image content when the image is of zero size.",
        "commit_text": "  ",
        "func_before": "void RenderSVGImage::paint(PaintInfo& paintInfo, const LayoutPoint&)\n{\n    ANNOTATE_GRAPHICS_CONTEXT(paintInfo, this);\n\n    if (paintInfo.context->paintingDisabled() || style()->visibility() == HIDDEN || !m_imageResource->hasImage())\n        return;\n\n    FloatRect boundingBox = repaintRectInLocalCoordinates();\n    if (!SVGRenderSupport::paintInfoIntersectsRepaintRect(boundingBox, m_localTransform, paintInfo))\n        return;\n\n    PaintInfo childPaintInfo(paintInfo);\n    bool drawsOutline = style()->outlineWidth() && (childPaintInfo.phase == PaintPhaseOutline || childPaintInfo.phase == PaintPhaseSelfOutline);\n    if (drawsOutline || childPaintInfo.phase == PaintPhaseForeground) {\n        GraphicsContextStateSaver stateSaver(*childPaintInfo.context);\n        childPaintInfo.applyTransform(m_localTransform);\n\n        if (childPaintInfo.phase == PaintPhaseForeground) {\n            SVGRenderingContext renderingContext(this, childPaintInfo);\n\n            if (renderingContext.isRenderingPrepared()) {\n                if (style()->svgStyle()->bufferedRendering() == BR_STATIC  && renderingContext.bufferForeground(m_bufferedForeground))\n                    return;\n\n                paintForeground(childPaintInfo);\n            }\n        }\n\n        if (drawsOutline)\n            paintOutline(childPaintInfo, IntRect(boundingBox));\n    }\n}",
        "func": "void RenderSVGImage::paint(PaintInfo& paintInfo, const LayoutPoint&)\n{\n    ANNOTATE_GRAPHICS_CONTEXT(paintInfo, this);\n\n    if (paintInfo.context->paintingDisabled() || style()->visibility() == HIDDEN || !m_imageResource->hasImage())\n        return;\n\n    FloatRect boundingBox = repaintRectInLocalCoordinates();\n    if (!SVGRenderSupport::paintInfoIntersectsRepaintRect(boundingBox, m_localTransform, paintInfo))\n        return;\n\n    PaintInfo childPaintInfo(paintInfo);\n    bool drawsOutline = style()->outlineWidth() && (childPaintInfo.phase == PaintPhaseOutline || childPaintInfo.phase == PaintPhaseSelfOutline);\n    if (drawsOutline || childPaintInfo.phase == PaintPhaseForeground) {\n        GraphicsContextStateSaver stateSaver(*childPaintInfo.context);\n        childPaintInfo.applyTransform(m_localTransform);\n\n        if (childPaintInfo.phase == PaintPhaseForeground && !m_objectBoundingBox.isEmpty()) {\n            SVGRenderingContext renderingContext(this, childPaintInfo);\n\n            if (renderingContext.isRenderingPrepared()) {\n                if (style()->svgStyle()->bufferedRendering() == BR_STATIC && renderingContext.bufferForeground(m_bufferedForeground))\n                    return;\n\n                paintForeground(childPaintInfo);\n            }\n        }\n\n        if (drawsOutline)\n            paintOutline(childPaintInfo, IntRect(boundingBox));\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -15,11 +15,11 @@\n         GraphicsContextStateSaver stateSaver(*childPaintInfo.context);\n         childPaintInfo.applyTransform(m_localTransform);\n \n-        if (childPaintInfo.phase == PaintPhaseForeground) {\n+        if (childPaintInfo.phase == PaintPhaseForeground && !m_objectBoundingBox.isEmpty()) {\n             SVGRenderingContext renderingContext(this, childPaintInfo);\n \n             if (renderingContext.isRenderingPrepared()) {\n-                if (style()->svgStyle()->bufferedRendering() == BR_STATIC  && renderingContext.bufferForeground(m_bufferedForeground))\n+                if (style()->svgStyle()->bufferedRendering() == BR_STATIC && renderingContext.bufferForeground(m_bufferedForeground))\n                     return;\n \n                 paintForeground(childPaintInfo);",
        "diff_line_info": {
            "deleted_lines": [
                "        if (childPaintInfo.phase == PaintPhaseForeground) {",
                "                if (style()->svgStyle()->bufferedRendering() == BR_STATIC  && renderingContext.bufferForeground(m_bufferedForeground))"
            ],
            "added_lines": [
                "        if (childPaintInfo.phase == PaintPhaseForeground && !m_objectBoundingBox.isEmpty()) {",
                "                if (style()->svgStyle()->bufferedRendering() == BR_STATIC && renderingContext.bufferForeground(m_bufferedForeground))"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-1950",
        "func_name": "xen-project/xen/xc_cpupool_getinfo",
        "description": "Use-after-free vulnerability in the xc_cpupool_getinfo function in Xen 4.1.x through 4.3.x, when using a multithreaded toolstack, does not properly handle a failure by the xc_cpumap_alloc function, which allows local users with access to management functions to cause a denial of service (heap corruption) and possibly gain privileges via unspecified vectors.",
        "git_url": "https://github.com/xen-project/xen/commit/d883c179a74111a6804baf8cb8224235242a88fc",
        "commit_title": "libxc: Fix out-of-memory error handling in xc_cpupool_getinfo()",
        "commit_text": " Avoid freeing info then returning it to the caller.  This is XSA-88.  Coverity-ID: 1056192",
        "func_before": "xc_cpupoolinfo_t *xc_cpupool_getinfo(xc_interface *xch, \n                       uint32_t poolid)\n{\n    int err = 0;\n    xc_cpupoolinfo_t *info = NULL;\n    int local_size;\n    DECLARE_SYSCTL;\n    DECLARE_HYPERCALL_BUFFER(uint8_t, local);\n\n    local_size = xc_get_cpumap_size(xch);\n    if (local_size <= 0)\n    {\n        PERROR(\"Could not get number of cpus\");\n        return NULL;\n    }\n\n    local = xc_hypercall_buffer_alloc(xch, local, local_size);\n    if ( local == NULL ) {\n        PERROR(\"Could not allocate locked memory for xc_cpupool_getinfo\");\n        return NULL;\n    }\n\n    sysctl.cmd = XEN_SYSCTL_cpupool_op;\n    sysctl.u.cpupool_op.op = XEN_SYSCTL_CPUPOOL_OP_INFO;\n    sysctl.u.cpupool_op.cpupool_id = poolid;\n    set_xen_guest_handle(sysctl.u.cpupool_op.cpumap.bitmap, local);\n    sysctl.u.cpupool_op.cpumap.nr_bits = local_size * 8;\n\n    err = do_sysctl_save(xch, &sysctl);\n\n    if ( err < 0 )\n\tgoto out;\n\n    info = calloc(1, sizeof(xc_cpupoolinfo_t));\n    if ( !info )\n\tgoto out;\n\n    info->cpumap = xc_cpumap_alloc(xch);\n    if (!info->cpumap) {\n        free(info);\n        goto out;\n    }\n    info->cpupool_id = sysctl.u.cpupool_op.cpupool_id;\n    info->sched_id = sysctl.u.cpupool_op.sched_id;\n    info->n_dom = sysctl.u.cpupool_op.n_dom;\n    memcpy(info->cpumap, local, local_size);\n\nout:\n    xc_hypercall_buffer_free(xch, local);\n\n    return info;\n}",
        "func": "xc_cpupoolinfo_t *xc_cpupool_getinfo(xc_interface *xch, \n                       uint32_t poolid)\n{\n    int err = 0;\n    xc_cpupoolinfo_t *info = NULL;\n    int local_size;\n    DECLARE_SYSCTL;\n    DECLARE_HYPERCALL_BUFFER(uint8_t, local);\n\n    local_size = xc_get_cpumap_size(xch);\n    if (local_size <= 0)\n    {\n        PERROR(\"Could not get number of cpus\");\n        return NULL;\n    }\n\n    local = xc_hypercall_buffer_alloc(xch, local, local_size);\n    if ( local == NULL ) {\n        PERROR(\"Could not allocate locked memory for xc_cpupool_getinfo\");\n        return NULL;\n    }\n\n    sysctl.cmd = XEN_SYSCTL_cpupool_op;\n    sysctl.u.cpupool_op.op = XEN_SYSCTL_CPUPOOL_OP_INFO;\n    sysctl.u.cpupool_op.cpupool_id = poolid;\n    set_xen_guest_handle(sysctl.u.cpupool_op.cpumap.bitmap, local);\n    sysctl.u.cpupool_op.cpumap.nr_bits = local_size * 8;\n\n    err = do_sysctl_save(xch, &sysctl);\n\n    if ( err < 0 )\n\tgoto out;\n\n    info = calloc(1, sizeof(xc_cpupoolinfo_t));\n    if ( !info )\n\tgoto out;\n\n    info->cpumap = xc_cpumap_alloc(xch);\n    if (!info->cpumap) {\n        free(info);\n        info = NULL;\n        goto out;\n    }\n    info->cpupool_id = sysctl.u.cpupool_op.cpupool_id;\n    info->sched_id = sysctl.u.cpupool_op.sched_id;\n    info->n_dom = sysctl.u.cpupool_op.n_dom;\n    memcpy(info->cpumap, local, local_size);\n\nout:\n    xc_hypercall_buffer_free(xch, local);\n\n    return info;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -38,6 +38,7 @@\n     info->cpumap = xc_cpumap_alloc(xch);\n     if (!info->cpumap) {\n         free(info);\n+        info = NULL;\n         goto out;\n     }\n     info->cpupool_id = sysctl.u.cpupool_op.cpupool_id;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "        info = NULL;"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-6653",
        "func_name": "chromium/ColorChooserWin::Open",
        "description": "Use-after-free vulnerability in the web contents implementation in Google Chrome before 33.0.1750.117 allows remote attackers to cause a denial of service or possibly have unspecified other impact via vectors involving attempted conflicting access to the color chooser.",
        "git_url": "https://github.com/chromium/chromium/commit/820957a3386e960334be3b93b48636e749d38ea3",
        "commit_title": "Make WebContentsDelegate::OpenColorChooser return NULL on failure",
        "commit_text": " Changing WebContentsDelegate::OpenColorChooser to return NULL on failure so we don't put the same ColorChooser into two scoped_ptrs(WebContentsImpl::color_chooser_)   ",
        "func_before": "ColorChooserWin* ColorChooserWin::Open(content::WebContents* web_contents,\n                                       SkColor initial_color) {\n  if (!current_color_chooser_)\n    current_color_chooser_ = new ColorChooserWin(web_contents, initial_color);\n  return current_color_chooser_;\n}",
        "func": "ColorChooserWin* ColorChooserWin::Open(content::WebContents* web_contents,\n                                       SkColor initial_color) {\n  if (current_color_chooser_)\n    return NULL;\n  current_color_chooser_ = new ColorChooserWin(web_contents, initial_color);\n  return current_color_chooser_;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,7 @@\n ColorChooserWin* ColorChooserWin::Open(content::WebContents* web_contents,\n                                        SkColor initial_color) {\n-  if (!current_color_chooser_)\n-    current_color_chooser_ = new ColorChooserWin(web_contents, initial_color);\n+  if (current_color_chooser_)\n+    return NULL;\n+  current_color_chooser_ = new ColorChooserWin(web_contents, initial_color);\n   return current_color_chooser_;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "  if (!current_color_chooser_)",
                "    current_color_chooser_ = new ColorChooserWin(web_contents, initial_color);"
            ],
            "added_lines": [
                "  if (current_color_chooser_)",
                "    return NULL;",
                "  current_color_chooser_ = new ColorChooserWin(web_contents, initial_color);"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-6653",
        "func_name": "chromium/WebContentsImpl::OnOpenColorChooser",
        "description": "Use-after-free vulnerability in the web contents implementation in Google Chrome before 33.0.1750.117 allows remote attackers to cause a denial of service or possibly have unspecified other impact via vectors involving attempted conflicting access to the color chooser.",
        "git_url": "https://github.com/chromium/chromium/commit/820957a3386e960334be3b93b48636e749d38ea3",
        "commit_title": "Make WebContentsDelegate::OpenColorChooser return NULL on failure",
        "commit_text": " Changing WebContentsDelegate::OpenColorChooser to return NULL on failure so we don't put the same ColorChooser into two scoped_ptrs(WebContentsImpl::color_chooser_)   ",
        "func_before": "void WebContentsImpl::OnOpenColorChooser(\n      int color_chooser_id,\n      SkColor color,\n      const std::vector<ColorSuggestion>& suggestions) {\n  ColorChooser* new_color_chooser =\n      delegate_->OpenColorChooser(this, color, suggestions);\n  if (color_chooser_ == new_color_chooser)\n    return;\n  color_chooser_.reset(new_color_chooser);\n  color_chooser_identifier_ = color_chooser_id;\n}",
        "func": "void WebContentsImpl::OnOpenColorChooser(\n      int color_chooser_id,\n      SkColor color,\n      const std::vector<ColorSuggestion>& suggestions) {\n  ColorChooser* new_color_chooser =\n      delegate_->OpenColorChooser(this, color, suggestions);\n  if (!new_color_chooser)\n    return;\n  if (color_chooser_)\n    color_chooser_->End();\n  color_chooser_.reset(new_color_chooser);\n  color_chooser_identifier_ = color_chooser_id;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,8 +4,10 @@\n       const std::vector<ColorSuggestion>& suggestions) {\n   ColorChooser* new_color_chooser =\n       delegate_->OpenColorChooser(this, color, suggestions);\n-  if (color_chooser_ == new_color_chooser)\n+  if (!new_color_chooser)\n     return;\n+  if (color_chooser_)\n+    color_chooser_->End();\n   color_chooser_.reset(new_color_chooser);\n   color_chooser_identifier_ = color_chooser_id;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "  if (color_chooser_ == new_color_chooser)"
            ],
            "added_lines": [
                "  if (!new_color_chooser)",
                "  if (color_chooser_)",
                "    color_chooser_->End();"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-6655",
        "func_name": "chromium/FrameView::sendResizeEventIfNeeded",
        "description": "Use-after-free vulnerability in Blink, as used in Google Chrome before 33.0.1750.117, allows remote attackers to cause a denial of service or possibly have unspecified other impact via vectors related to improper handling of overflowchanged DOM events during interaction between JavaScript and layout.",
        "git_url": "https://github.com/chromium/chromium/commit/5d37b543df5ddecfd6f1d89335f37f29dc86f80d",
        "commit_title": "Fire overflowchanged events at raf timing",
        "commit_text": " Running script inside layout leads to nasty security bugs and crashes, instead we should defer overflowchanged events until raf time. This still lets the author take an action before the paint preventing blinking and jumpiness which was the reason we ran it inside layout, while avoiding the pitfalls of synchronous script.  Unfortunately this patch makes us start firing overflowchanged even when a node has been removed from the tree, but the old protection against it was bad since it only checked inDocument() so removing a node and putting it in another document would still let the event fire. Instead I plan to fix the detach problem in a future patch since scroll events shouldn't fire for detached nodes either.  This patch also lets us remove the paused-event-dispatch.html test which was testing the suspend/resume logic I removed and for crashes that happen with synchronous script inside layout which doesn't apply after this patch.   ",
        "func_before": "void FrameView::sendResizeEventIfNeeded()\n{\n    ASSERT(m_frame);\n\n    RenderView* renderView = this->renderView();\n    if (!renderView || renderView->document().printing())\n        return;\n\n    IntSize currentSize = layoutSize(IncludeScrollbars);\n    float currentZoomFactor = renderView->style()->zoom();\n\n    bool shouldSendResizeEvent = currentSize != m_lastViewportSize || currentZoomFactor != m_lastZoomFactor;\n\n    m_lastViewportSize = currentSize;\n    m_lastZoomFactor = currentZoomFactor;\n\n    if (!shouldSendResizeEvent)\n        return;\n\n    m_frame->eventHandler().sendResizeEvent();\n\n    if (isMainFrame())\n        InspectorInstrumentation::didResizeMainFrame(m_frame->page());\n}",
        "func": "void FrameView::sendResizeEventIfNeeded()\n{\n    ASSERT(m_frame);\n\n    RenderView* renderView = this->renderView();\n    if (!renderView || renderView->document().printing())\n        return;\n\n    IntSize currentSize = layoutSize(IncludeScrollbars);\n    float currentZoomFactor = renderView->style()->zoom();\n\n    bool shouldSendResizeEvent = currentSize != m_lastViewportSize || currentZoomFactor != m_lastZoomFactor;\n\n    m_lastViewportSize = currentSize;\n    m_lastZoomFactor = currentZoomFactor;\n\n    if (!shouldSendResizeEvent)\n        return;\n\n    m_frame->document()->enqueueResizeEvent();\n\n    if (isMainFrame())\n        InspectorInstrumentation::didResizeMainFrame(m_frame->page());\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -17,7 +17,7 @@\n     if (!shouldSendResizeEvent)\n         return;\n \n-    m_frame->eventHandler().sendResizeEvent();\n+    m_frame->document()->enqueueResizeEvent();\n \n     if (isMainFrame())\n         InspectorInstrumentation::didResizeMainFrame(m_frame->page());",
        "diff_line_info": {
            "deleted_lines": [
                "    m_frame->eventHandler().sendResizeEvent();"
            ],
            "added_lines": [
                "    m_frame->document()->enqueueResizeEvent();"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-6655",
        "func_name": "chromium/FrameView::performPostLayoutTasks",
        "description": "Use-after-free vulnerability in Blink, as used in Google Chrome before 33.0.1750.117, allows remote attackers to cause a denial of service or possibly have unspecified other impact via vectors related to improper handling of overflowchanged DOM events during interaction between JavaScript and layout.",
        "git_url": "https://github.com/chromium/chromium/commit/5d37b543df5ddecfd6f1d89335f37f29dc86f80d",
        "commit_title": "Fire overflowchanged events at raf timing",
        "commit_text": " Running script inside layout leads to nasty security bugs and crashes, instead we should defer overflowchanged events until raf time. This still lets the author take an action before the paint preventing blinking and jumpiness which was the reason we ran it inside layout, while avoiding the pitfalls of synchronous script.  Unfortunately this patch makes us start firing overflowchanged even when a node has been removed from the tree, but the old protection against it was bad since it only checked inDocument() so removing a node and putting it in another document would still let the event fire. Instead I plan to fix the detach problem in a future patch since scroll events shouldn't fire for detached nodes either.  This patch also lets us remove the paused-event-dispatch.html test which was testing the suspend/resume logic I removed and for crashes that happen with synchronous script inside layout which doesn't apply after this patch.   ",
        "func_before": "void FrameView::performPostLayoutTasks()\n{\n    TRACE_EVENT0(\"webkit\", \"FrameView::performPostLayoutTasks\");\n    // FontFaceSet::didLayout() and resumeOverflowEvents() calls below can blow\n    // us away from underneath.\n    // FIXME: We should not run any JavaScript code in this function.\n    RefPtr<FrameView> protect(this);\n\n    m_postLayoutTasksTimer.stop();\n\n    m_frame->selection().setCaretRectNeedsUpdate();\n    m_frame->selection().updateAppearance();\n\n    if (m_nestedLayoutCount <= 1) {\n        if (m_firstLayoutCallbackPending) {\n            m_firstLayoutCallbackPending = false;\n            m_frame->loader().didFirstLayout();\n        }\n\n        // Ensure that we always send this eventually.\n        if (!m_frame->document()->parsing() && m_frame->loader().stateMachine()->committedFirstRealDocumentLoad())\n            m_isVisuallyNonEmpty = true;\n\n        // If the layout was done with pending sheets, we are not in fact visually non-empty yet.\n        if (m_isVisuallyNonEmpty && !m_frame->document()->didLayoutWithPendingStylesheets() && m_firstVisuallyNonEmptyLayoutCallbackPending) {\n            m_firstVisuallyNonEmptyLayoutCallbackPending = false;\n            // FIXME: This callback is probably not needed, but is currently used\n            // by android for setting the background color.\n            m_frame->loader().client()->dispatchDidFirstVisuallyNonEmptyLayout();\n        }\n    }\n\n    FontFaceSet::didLayout(m_frame->document());\n\n    RenderView* renderView = this->renderView();\n    if (renderView)\n        renderView->updateWidgetPositions();\n\n    m_updateWidgetsTimer.startOneShot(0);\n\n    if (Page* page = m_frame->page()) {\n        if (ScrollingCoordinator* scrollingCoordinator = page->scrollingCoordinator())\n            scrollingCoordinator->notifyLayoutUpdated();\n    }\n\n    scrollToAnchor();\n\n    resumeOverflowEvents();\n\n    sendResizeEventIfNeeded();\n}",
        "func": "void FrameView::performPostLayoutTasks()\n{\n    TRACE_EVENT0(\"webkit\", \"FrameView::performPostLayoutTasks\");\n    // FontFaceSet::didLayout() calls below can blow us away from underneath.\n    // FIXME: We should not run any JavaScript code in this function.\n    RefPtr<FrameView> protect(this);\n\n    m_postLayoutTasksTimer.stop();\n\n    m_frame->selection().setCaretRectNeedsUpdate();\n    m_frame->selection().updateAppearance();\n\n    if (m_nestedLayoutCount <= 1) {\n        if (m_firstLayoutCallbackPending) {\n            m_firstLayoutCallbackPending = false;\n            m_frame->loader().didFirstLayout();\n        }\n\n        // Ensure that we always send this eventually.\n        if (!m_frame->document()->parsing() && m_frame->loader().stateMachine()->committedFirstRealDocumentLoad())\n            m_isVisuallyNonEmpty = true;\n\n        // If the layout was done with pending sheets, we are not in fact visually non-empty yet.\n        if (m_isVisuallyNonEmpty && !m_frame->document()->didLayoutWithPendingStylesheets() && m_firstVisuallyNonEmptyLayoutCallbackPending) {\n            m_firstVisuallyNonEmptyLayoutCallbackPending = false;\n            // FIXME: This callback is probably not needed, but is currently used\n            // by android for setting the background color.\n            m_frame->loader().client()->dispatchDidFirstVisuallyNonEmptyLayout();\n        }\n    }\n\n    FontFaceSet::didLayout(m_frame->document());\n\n    RenderView* renderView = this->renderView();\n    if (renderView)\n        renderView->updateWidgetPositions();\n\n    m_updateWidgetsTimer.startOneShot(0);\n\n    if (Page* page = m_frame->page()) {\n        if (ScrollingCoordinator* scrollingCoordinator = page->scrollingCoordinator())\n            scrollingCoordinator->notifyLayoutUpdated();\n    }\n\n    scrollToAnchor();\n\n    sendResizeEventIfNeeded();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,8 +1,7 @@\n void FrameView::performPostLayoutTasks()\n {\n     TRACE_EVENT0(\"webkit\", \"FrameView::performPostLayoutTasks\");\n-    // FontFaceSet::didLayout() and resumeOverflowEvents() calls below can blow\n-    // us away from underneath.\n+    // FontFaceSet::didLayout() calls below can blow us away from underneath.\n     // FIXME: We should not run any JavaScript code in this function.\n     RefPtr<FrameView> protect(this);\n \n@@ -45,7 +44,5 @@\n \n     scrollToAnchor();\n \n-    resumeOverflowEvents();\n-\n     sendResizeEventIfNeeded();\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    // FontFaceSet::didLayout() and resumeOverflowEvents() calls below can blow",
                "    // us away from underneath.",
                "    resumeOverflowEvents();",
                ""
            ],
            "added_lines": [
                "    // FontFaceSet::didLayout() calls below can blow us away from underneath."
            ]
        }
    },
    {
        "cve_id": "CVE-2013-6655",
        "func_name": "chromium/FrameView::updateOverflowStatus",
        "description": "Use-after-free vulnerability in Blink, as used in Google Chrome before 33.0.1750.117, allows remote attackers to cause a denial of service or possibly have unspecified other impact via vectors related to improper handling of overflowchanged DOM events during interaction between JavaScript and layout.",
        "git_url": "https://github.com/chromium/chromium/commit/5d37b543df5ddecfd6f1d89335f37f29dc86f80d",
        "commit_title": "Fire overflowchanged events at raf timing",
        "commit_text": " Running script inside layout leads to nasty security bugs and crashes, instead we should defer overflowchanged events until raf time. This still lets the author take an action before the paint preventing blinking and jumpiness which was the reason we ran it inside layout, while avoiding the pitfalls of synchronous script.  Unfortunately this patch makes us start firing overflowchanged even when a node has been removed from the tree, but the old protection against it was bad since it only checked inDocument() so removing a node and putting it in another document would still let the event fire. Instead I plan to fix the detach problem in a future patch since scroll events shouldn't fire for detached nodes either.  This patch also lets us remove the paused-event-dispatch.html test which was testing the suspend/resume logic I removed and for crashes that happen with synchronous script inside layout which doesn't apply after this patch.   ",
        "func_before": "void FrameView::updateOverflowStatus(bool horizontalOverflow, bool verticalOverflow)\n{\n    if (!m_viewportRenderer)\n        return;\n\n    if (m_overflowStatusDirty) {\n        m_horizontalOverflow = horizontalOverflow;\n        m_verticalOverflow = verticalOverflow;\n        m_overflowStatusDirty = false;\n        return;\n    }\n\n    bool horizontalOverflowChanged = (m_horizontalOverflow != horizontalOverflow);\n    bool verticalOverflowChanged = (m_verticalOverflow != verticalOverflow);\n\n    if (horizontalOverflowChanged || verticalOverflowChanged) {\n        m_horizontalOverflow = horizontalOverflow;\n        m_verticalOverflow = verticalOverflow;\n\n        RefPtr<OverflowEvent> event = OverflowEvent::create(horizontalOverflowChanged, horizontalOverflow, verticalOverflowChanged, verticalOverflow);\n        event->setTarget(m_viewportRenderer->node());\n        scheduleOverflowEvent(event);\n    }\n\n}",
        "func": "void FrameView::updateOverflowStatus(bool horizontalOverflow, bool verticalOverflow)\n{\n    if (!m_viewportRenderer)\n        return;\n\n    if (m_overflowStatusDirty) {\n        m_horizontalOverflow = horizontalOverflow;\n        m_verticalOverflow = verticalOverflow;\n        m_overflowStatusDirty = false;\n        return;\n    }\n\n    bool horizontalOverflowChanged = (m_horizontalOverflow != horizontalOverflow);\n    bool verticalOverflowChanged = (m_verticalOverflow != verticalOverflow);\n\n    if (horizontalOverflowChanged || verticalOverflowChanged) {\n        m_horizontalOverflow = horizontalOverflow;\n        m_verticalOverflow = verticalOverflow;\n\n        RefPtr<OverflowEvent> event = OverflowEvent::create(horizontalOverflowChanged, horizontalOverflow, verticalOverflowChanged, verticalOverflow);\n        event->setTarget(m_viewportRenderer->node());\n        m_frame->document()->enqueueAnimationFrameEvent(event.release());\n    }\n\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -19,7 +19,7 @@\n \n         RefPtr<OverflowEvent> event = OverflowEvent::create(horizontalOverflowChanged, horizontalOverflow, verticalOverflowChanged, verticalOverflow);\n         event->setTarget(m_viewportRenderer->node());\n-        scheduleOverflowEvent(event);\n+        m_frame->document()->enqueueAnimationFrameEvent(event.release());\n     }\n \n }",
        "diff_line_info": {
            "deleted_lines": [
                "        scheduleOverflowEvent(event);"
            ],
            "added_lines": [
                "        m_frame->document()->enqueueAnimationFrameEvent(event.release());"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-6655",
        "func_name": "chromium/FrameView::scheduleOrPerformPostLayoutTasks",
        "description": "Use-after-free vulnerability in Blink, as used in Google Chrome before 33.0.1750.117, allows remote attackers to cause a denial of service or possibly have unspecified other impact via vectors related to improper handling of overflowchanged DOM events during interaction between JavaScript and layout.",
        "git_url": "https://github.com/chromium/chromium/commit/5d37b543df5ddecfd6f1d89335f37f29dc86f80d",
        "commit_title": "Fire overflowchanged events at raf timing",
        "commit_text": " Running script inside layout leads to nasty security bugs and crashes, instead we should defer overflowchanged events until raf time. This still lets the author take an action before the paint preventing blinking and jumpiness which was the reason we ran it inside layout, while avoiding the pitfalls of synchronous script.  Unfortunately this patch makes us start firing overflowchanged even when a node has been removed from the tree, but the old protection against it was bad since it only checked inDocument() so removing a node and putting it in another document would still let the event fire. Instead I plan to fix the detach problem in a future patch since scroll events shouldn't fire for detached nodes either.  This patch also lets us remove the paused-event-dispatch.html test which was testing the suspend/resume logic I removed and for crashes that happen with synchronous script inside layout which doesn't apply after this patch.   ",
        "func_before": "void FrameView::scheduleOrPerformPostLayoutTasks()\n{\n    if (m_postLayoutTasksTimer.isActive()) {\n        resumeOverflowEvents();\n        return;\n    }\n\n    // Partial layouts should not happen with synchronous post layouts.\n    ASSERT(!(m_inSynchronousPostLayout && partialLayout().isStopping()));\n\n    if (!m_inSynchronousPostLayout) {\n        if (frame().document()->shouldDisplaySeamlesslyWithParent()) {\n            if (RenderView* renderView = this->renderView())\n                renderView->updateWidgetPositions();\n        } else {\n            m_inSynchronousPostLayout = true;\n            // Calls resumeScheduledEvents()\n            performPostLayoutTasks();\n            m_inSynchronousPostLayout = false;\n        }\n    }\n\n    if (!m_postLayoutTasksTimer.isActive() && (needsLayout() || m_inSynchronousPostLayout || frame().document()->shouldDisplaySeamlesslyWithParent())) {\n        // If we need layout or are already in a synchronous call to postLayoutTasks(),\n        // defer widget updates and event dispatch until after we return. postLayoutTasks()\n        // can make us need to update again, and we can get stuck in a nasty cycle unless\n        // we call it through the timer here.\n        m_postLayoutTasksTimer.startOneShot(0);\n        if (!partialLayout().isStopping() && needsLayout()) {\n            suspendOverflowEvents();\n            layout();\n        }\n    }\n}",
        "func": "void FrameView::scheduleOrPerformPostLayoutTasks()\n{\n    if (m_postLayoutTasksTimer.isActive())\n        return;\n\n    // Partial layouts should not happen with synchronous post layouts.\n    ASSERT(!(m_inSynchronousPostLayout && partialLayout().isStopping()));\n\n    if (!m_inSynchronousPostLayout) {\n        if (frame().document()->shouldDisplaySeamlesslyWithParent()) {\n            if (RenderView* renderView = this->renderView())\n                renderView->updateWidgetPositions();\n        } else {\n            m_inSynchronousPostLayout = true;\n            // Calls resumeScheduledEvents()\n            performPostLayoutTasks();\n            m_inSynchronousPostLayout = false;\n        }\n    }\n\n    if (!m_postLayoutTasksTimer.isActive() && (needsLayout() || m_inSynchronousPostLayout || frame().document()->shouldDisplaySeamlesslyWithParent())) {\n        // If we need layout or are already in a synchronous call to postLayoutTasks(),\n        // defer widget updates and event dispatch until after we return. postLayoutTasks()\n        // can make us need to update again, and we can get stuck in a nasty cycle unless\n        // we call it through the timer here.\n        m_postLayoutTasksTimer.startOneShot(0);\n        if (!partialLayout().isStopping() && needsLayout())\n            layout();\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,9 +1,7 @@\n void FrameView::scheduleOrPerformPostLayoutTasks()\n {\n-    if (m_postLayoutTasksTimer.isActive()) {\n-        resumeOverflowEvents();\n+    if (m_postLayoutTasksTimer.isActive())\n         return;\n-    }\n \n     // Partial layouts should not happen with synchronous post layouts.\n     ASSERT(!(m_inSynchronousPostLayout && partialLayout().isStopping()));\n@@ -26,9 +24,7 @@\n         // can make us need to update again, and we can get stuck in a nasty cycle unless\n         // we call it through the timer here.\n         m_postLayoutTasksTimer.startOneShot(0);\n-        if (!partialLayout().isStopping() && needsLayout()) {\n-            suspendOverflowEvents();\n+        if (!partialLayout().isStopping() && needsLayout())\n             layout();\n-        }\n     }\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    if (m_postLayoutTasksTimer.isActive()) {",
                "        resumeOverflowEvents();",
                "    }",
                "        if (!partialLayout().isStopping() && needsLayout()) {",
                "            suspendOverflowEvents();",
                "        }"
            ],
            "added_lines": [
                "    if (m_postLayoutTasksTimer.isActive())",
                "        if (!partialLayout().isStopping() && needsLayout())"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-6655",
        "func_name": "chromium/FrameView::~FrameView",
        "description": "Use-after-free vulnerability in Blink, as used in Google Chrome before 33.0.1750.117, allows remote attackers to cause a denial of service or possibly have unspecified other impact via vectors related to improper handling of overflowchanged DOM events during interaction between JavaScript and layout.",
        "git_url": "https://github.com/chromium/chromium/commit/5d37b543df5ddecfd6f1d89335f37f29dc86f80d",
        "commit_title": "Fire overflowchanged events at raf timing",
        "commit_text": " Running script inside layout leads to nasty security bugs and crashes, instead we should defer overflowchanged events until raf time. This still lets the author take an action before the paint preventing blinking and jumpiness which was the reason we ran it inside layout, while avoiding the pitfalls of synchronous script.  Unfortunately this patch makes us start firing overflowchanged even when a node has been removed from the tree, but the old protection against it was bad since it only checked inDocument() so removing a node and putting it in another document would still let the event fire. Instead I plan to fix the detach problem in a future patch since scroll events shouldn't fire for detached nodes either.  This patch also lets us remove the paused-event-dispatch.html test which was testing the suspend/resume logic I removed and for crashes that happen with synchronous script inside layout which doesn't apply after this patch.   ",
        "func_before": "FrameView::~FrameView()\n{\n    if (m_postLayoutTasksTimer.isActive()) {\n        m_postLayoutTasksTimer.stop();\n        m_overflowEventQueue.clear();\n    }\n\n    removeFromAXObjectCache();\n    resetScrollbars();\n\n    // Custom scrollbars should already be destroyed at this point\n    ASSERT(!horizontalScrollbar() || !horizontalScrollbar()->isCustomScrollbar());\n    ASSERT(!verticalScrollbar() || !verticalScrollbar()->isCustomScrollbar());\n\n    setHasHorizontalScrollbar(false); // Remove native scrollbars now before we lose the connection to the HostWindow.\n    setHasVerticalScrollbar(false);\n\n    ASSERT(!m_scrollCorner);\n    ASSERT(m_overflowEventQueue.isEmpty());\n\n    ASSERT(m_frame);\n    ASSERT(m_frame->view() != this || !m_frame->contentRenderer());\n    RenderPart* renderer = m_frame->ownerRenderer();\n    if (renderer && renderer->widget() == this)\n        renderer->setWidget(0);\n}",
        "func": "FrameView::~FrameView()\n{\n    if (m_postLayoutTasksTimer.isActive())\n        m_postLayoutTasksTimer.stop();\n\n    removeFromAXObjectCache();\n    resetScrollbars();\n\n    // Custom scrollbars should already be destroyed at this point\n    ASSERT(!horizontalScrollbar() || !horizontalScrollbar()->isCustomScrollbar());\n    ASSERT(!verticalScrollbar() || !verticalScrollbar()->isCustomScrollbar());\n\n    setHasHorizontalScrollbar(false); // Remove native scrollbars now before we lose the connection to the HostWindow.\n    setHasVerticalScrollbar(false);\n\n    ASSERT(!m_scrollCorner);\n\n    ASSERT(m_frame);\n    ASSERT(m_frame->view() != this || !m_frame->contentRenderer());\n    RenderPart* renderer = m_frame->ownerRenderer();\n    if (renderer && renderer->widget() == this)\n        renderer->setWidget(0);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,9 +1,7 @@\n FrameView::~FrameView()\n {\n-    if (m_postLayoutTasksTimer.isActive()) {\n+    if (m_postLayoutTasksTimer.isActive())\n         m_postLayoutTasksTimer.stop();\n-        m_overflowEventQueue.clear();\n-    }\n \n     removeFromAXObjectCache();\n     resetScrollbars();\n@@ -16,7 +14,6 @@\n     setHasVerticalScrollbar(false);\n \n     ASSERT(!m_scrollCorner);\n-    ASSERT(m_overflowEventQueue.isEmpty());\n \n     ASSERT(m_frame);\n     ASSERT(m_frame->view() != this || !m_frame->contentRenderer());",
        "diff_line_info": {
            "deleted_lines": [
                "    if (m_postLayoutTasksTimer.isActive()) {",
                "        m_overflowEventQueue.clear();",
                "    }",
                "    ASSERT(m_overflowEventQueue.isEmpty());"
            ],
            "added_lines": [
                "    if (m_postLayoutTasksTimer.isActive())"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-6655",
        "func_name": "chromium/FrameView::layout",
        "description": "Use-after-free vulnerability in Blink, as used in Google Chrome before 33.0.1750.117, allows remote attackers to cause a denial of service or possibly have unspecified other impact via vectors related to improper handling of overflowchanged DOM events during interaction between JavaScript and layout.",
        "git_url": "https://github.com/chromium/chromium/commit/5d37b543df5ddecfd6f1d89335f37f29dc86f80d",
        "commit_title": "Fire overflowchanged events at raf timing",
        "commit_text": " Running script inside layout leads to nasty security bugs and crashes, instead we should defer overflowchanged events until raf time. This still lets the author take an action before the paint preventing blinking and jumpiness which was the reason we ran it inside layout, while avoiding the pitfalls of synchronous script.  Unfortunately this patch makes us start firing overflowchanged even when a node has been removed from the tree, but the old protection against it was bad since it only checked inDocument() so removing a node and putting it in another document would still let the event fire. Instead I plan to fix the detach problem in a future patch since scroll events shouldn't fire for detached nodes either.  This patch also lets us remove the paused-event-dispatch.html test which was testing the suspend/resume logic I removed and for crashes that happen with synchronous script inside layout which doesn't apply after this patch.   ",
        "func_before": "void FrameView::layout(bool allowSubtree)\n{\n    // We should never layout a Document which is not in a Frame.\n    ASSERT(m_frame);\n    ASSERT(m_frame->view() == this);\n    ASSERT(m_frame->page());\n\n    if (m_inLayout)\n        return;\n\n    ASSERT(!partialLayout().isStopping());\n\n    TRACE_EVENT0(\"webkit\", \"FrameView::layout\");\n    TRACE_EVENT_SCOPED_SAMPLING_STATE(\"Blink\", \"Layout\");\n\n    // Protect the view from being deleted during layout (in recalcStyle)\n    RefPtr<FrameView> protector(this);\n\n    // Every scroll that happens during layout is programmatic.\n    TemporaryChange<bool> changeInProgrammaticScroll(m_inProgrammaticScroll, true);\n\n    m_layoutTimer.stop();\n    m_delayedLayout = false;\n    m_setNeedsLayoutWasDeferred = false;\n\n    // we shouldn't enter layout() while painting\n    ASSERT(!isPainting());\n    if (isPainting())\n        return;\n\n    InspectorInstrumentationCookie cookie = InspectorInstrumentation::willLayout(m_frame.get());\n\n    if (!allowSubtree && m_layoutRoot) {\n        m_layoutRoot->markContainingBlocksForLayout(false);\n        m_layoutRoot = 0;\n    }\n\n    performPreLayoutTasks();\n\n    // If there is only one ref to this view left, then its going to be destroyed as soon as we exit,\n    // so there's no point to continuing to layout\n    if (protector->hasOneRef())\n        return;\n\n    Document* document = m_frame->document();\n    bool inSubtreeLayout = m_layoutRoot;\n    RenderObject* rootForThisLayout = inSubtreeLayout ? m_layoutRoot : document->renderer();\n    if (!rootForThisLayout) {\n        // FIXME: Do we need to set m_size here?\n        ASSERT_NOT_REACHED();\n        return;\n    }\n\n    bool isPartialLayout = partialLayout().isPartialLayout();\n\n    FontCachePurgePreventer fontCachePurgePreventer;\n    RenderLayer* layer;\n    {\n        TemporaryChange<bool> changeSchedulingEnabled(m_layoutSchedulingEnabled, false);\n\n        m_nestedLayoutCount++;\n        if (!m_layoutRoot) {\n            Document* document = m_frame->document();\n            Node* body = document->body();\n            if (body && body->renderer()) {\n                if (body->hasTagName(framesetTag)) {\n                    body->renderer()->setChildNeedsLayout();\n                } else if (body->hasTagName(bodyTag)) {\n                    if (!m_firstLayout && m_size.height() != layoutSize().height() && body->renderer()->enclosingBox()->stretchesToViewport())\n                        body->renderer()->setChildNeedsLayout();\n                }\n            }\n        }\n        updateCounters();\n        autoSizeIfEnabled();\n\n        ScrollbarMode hMode;\n        ScrollbarMode vMode;\n        calculateScrollbarModesForLayout(hMode, vMode);\n\n        m_doFullRepaint = !inSubtreeLayout && !isPartialLayout && (m_firstLayout || toRenderView(rootForThisLayout)->document().printing());\n\n        if (!inSubtreeLayout && !isPartialLayout) {\n            // Now set our scrollbar state for the layout.\n            ScrollbarMode currentHMode = horizontalScrollbarMode();\n            ScrollbarMode currentVMode = verticalScrollbarMode();\n\n            if (m_firstLayout || (hMode != currentHMode || vMode != currentVMode)) {\n                if (m_firstLayout) {\n                    setScrollbarsSuppressed(true);\n\n                    m_firstLayout = false;\n                    m_firstLayoutCallbackPending = true;\n                    m_lastViewportSize = layoutSize(IncludeScrollbars);\n                    m_lastZoomFactor = rootForThisLayout->style()->zoom();\n\n                    // Set the initial vMode to AlwaysOn if we're auto.\n                    if (vMode == ScrollbarAuto)\n                        setVerticalScrollbarMode(ScrollbarAlwaysOn); // This causes a vertical scrollbar to appear.\n                    // Set the initial hMode to AlwaysOff if we're auto.\n                    if (hMode == ScrollbarAuto)\n                        setHorizontalScrollbarMode(ScrollbarAlwaysOff); // This causes a horizontal scrollbar to disappear.\n\n                    setScrollbarModes(hMode, vMode);\n                    setScrollbarsSuppressed(false, true);\n                } else\n                    setScrollbarModes(hMode, vMode);\n            }\n\n            LayoutSize oldSize = m_size;\n\n            m_size = LayoutSize(layoutSize().width(), layoutSize().height());\n\n            if (oldSize != m_size) {\n                m_doFullRepaint = true;\n                if (!m_firstLayout) {\n                    RenderBox* rootRenderer = document->documentElement() ? document->documentElement()->renderBox() : 0;\n                    RenderBox* bodyRenderer = rootRenderer && document->body() ? document->body()->renderBox() : 0;\n                    if (bodyRenderer && bodyRenderer->stretchesToViewport())\n                        bodyRenderer->setChildNeedsLayout();\n                    else if (rootRenderer && rootRenderer->stretchesToViewport())\n                        rootRenderer->setChildNeedsLayout();\n                }\n            }\n        }\n\n        layer = rootForThisLayout->enclosingLayer();\n\n        suspendOverflowEvents();\n\n        performLayout(rootForThisLayout, inSubtreeLayout);\n\n        m_layoutRoot = 0;\n    } // Reset m_layoutSchedulingEnabled to its previous value.\n\n    bool neededFullRepaint = m_doFullRepaint;\n\n    if (!inSubtreeLayout && !isPartialLayout && !toRenderView(rootForThisLayout)->document().printing())\n        adjustViewSize();\n\n    m_doFullRepaint = neededFullRepaint;\n\n    {\n        // FIXME: Can this scope just encompass this entire function?\n        FrameView::DeferredRepaintScope deferRepaints(*this);\n\n        if (m_doFullRepaint) {\n            // FIXME: This isn't really right, since the RenderView doesn't fully encompass\n            // the visibleContentRect(). It just happens to work out most of the time,\n            // since first layouts and printing don't have you scrolled anywhere.\n            rootForThisLayout->view()->repaint();\n\n        } else if (RuntimeEnabledFeatures::repaintAfterLayoutEnabled() && !partialLayout().isStopping()) {\n            repaintTree(rootForThisLayout);\n        }\n\n        layer->updateLayerPositionsAfterLayout(renderView()->layer(), updateLayerPositionFlags(layer, inSubtreeLayout, m_doFullRepaint));\n    }\n\n    updateCompositingLayersAfterLayout();\n\n    m_layoutCount++;\n\n    if (AXObjectCache* cache = rootForThisLayout->document().existingAXObjectCache())\n        cache->postNotification(rootForThisLayout, AXObjectCache::AXLayoutComplete, true);\n    updateAnnotatedRegions();\n\n    ASSERT(partialLayout().isStopping() || !rootForThisLayout->needsLayout());\n\n    updateCanBlitOnScrollRecursively();\n\n    if (document->hasListenerType(Document::OVERFLOWCHANGED_LISTENER))\n        updateOverflowStatus(layoutSize().width() < contentsWidth(), layoutSize().height() < contentsHeight());\n\n    scheduleOrPerformPostLayoutTasks();\n\n    InspectorInstrumentation::didLayout(cookie, rootForThisLayout);\n\n    m_nestedLayoutCount--;\n    if (m_nestedLayoutCount)\n        return;\n\n    if (partialLayout().isStopping())\n        return;\n\n#ifndef NDEBUG\n    // Post-layout assert that nobody was re-marked as needing layout during layout.\n    document->renderer()->assertSubtreeIsLaidOut();\n#endif\n\n    // FIXME: It should be not possible to remove the FrameView from the frame/page during layout\n    // however m_inLayout is not set for most of this function, so none of our RELEASE_ASSERTS\n    // in Frame/Page will fire. One of the post-layout tasks is disconnecting the Frame from\n    // the page in fast/frames/crash-remove-iframe-during-object-beforeload-2.html\n    // necessitating this check here.\n    // ASSERT(frame()->page());\n    if (frame().page())\n        frame().page()->chrome().client().layoutUpdated(m_frame.get());\n}",
        "func": "void FrameView::layout(bool allowSubtree)\n{\n    // We should never layout a Document which is not in a Frame.\n    ASSERT(m_frame);\n    ASSERT(m_frame->view() == this);\n    ASSERT(m_frame->page());\n\n    if (m_inLayout)\n        return;\n\n    ASSERT(!partialLayout().isStopping());\n\n    TRACE_EVENT0(\"webkit\", \"FrameView::layout\");\n    TRACE_EVENT_SCOPED_SAMPLING_STATE(\"Blink\", \"Layout\");\n\n    // Protect the view from being deleted during layout (in recalcStyle)\n    RefPtr<FrameView> protector(this);\n\n    // Every scroll that happens during layout is programmatic.\n    TemporaryChange<bool> changeInProgrammaticScroll(m_inProgrammaticScroll, true);\n\n    m_layoutTimer.stop();\n    m_delayedLayout = false;\n    m_setNeedsLayoutWasDeferred = false;\n\n    // we shouldn't enter layout() while painting\n    ASSERT(!isPainting());\n    if (isPainting())\n        return;\n\n    InspectorInstrumentationCookie cookie = InspectorInstrumentation::willLayout(m_frame.get());\n\n    if (!allowSubtree && m_layoutRoot) {\n        m_layoutRoot->markContainingBlocksForLayout(false);\n        m_layoutRoot = 0;\n    }\n\n    performPreLayoutTasks();\n\n    // If there is only one ref to this view left, then its going to be destroyed as soon as we exit,\n    // so there's no point to continuing to layout\n    if (protector->hasOneRef())\n        return;\n\n    Document* document = m_frame->document();\n    bool inSubtreeLayout = m_layoutRoot;\n    RenderObject* rootForThisLayout = inSubtreeLayout ? m_layoutRoot : document->renderer();\n    if (!rootForThisLayout) {\n        // FIXME: Do we need to set m_size here?\n        ASSERT_NOT_REACHED();\n        return;\n    }\n\n    bool isPartialLayout = partialLayout().isPartialLayout();\n\n    FontCachePurgePreventer fontCachePurgePreventer;\n    RenderLayer* layer;\n    {\n        TemporaryChange<bool> changeSchedulingEnabled(m_layoutSchedulingEnabled, false);\n\n        m_nestedLayoutCount++;\n        if (!m_layoutRoot) {\n            Document* document = m_frame->document();\n            Node* body = document->body();\n            if (body && body->renderer()) {\n                if (body->hasTagName(framesetTag)) {\n                    body->renderer()->setChildNeedsLayout();\n                } else if (body->hasTagName(bodyTag)) {\n                    if (!m_firstLayout && m_size.height() != layoutSize().height() && body->renderer()->enclosingBox()->stretchesToViewport())\n                        body->renderer()->setChildNeedsLayout();\n                }\n            }\n        }\n        updateCounters();\n        autoSizeIfEnabled();\n\n        ScrollbarMode hMode;\n        ScrollbarMode vMode;\n        calculateScrollbarModesForLayout(hMode, vMode);\n\n        m_doFullRepaint = !inSubtreeLayout && !isPartialLayout && (m_firstLayout || toRenderView(rootForThisLayout)->document().printing());\n\n        if (!inSubtreeLayout && !isPartialLayout) {\n            // Now set our scrollbar state for the layout.\n            ScrollbarMode currentHMode = horizontalScrollbarMode();\n            ScrollbarMode currentVMode = verticalScrollbarMode();\n\n            if (m_firstLayout || (hMode != currentHMode || vMode != currentVMode)) {\n                if (m_firstLayout) {\n                    setScrollbarsSuppressed(true);\n\n                    m_firstLayout = false;\n                    m_firstLayoutCallbackPending = true;\n                    m_lastViewportSize = layoutSize(IncludeScrollbars);\n                    m_lastZoomFactor = rootForThisLayout->style()->zoom();\n\n                    // Set the initial vMode to AlwaysOn if we're auto.\n                    if (vMode == ScrollbarAuto)\n                        setVerticalScrollbarMode(ScrollbarAlwaysOn); // This causes a vertical scrollbar to appear.\n                    // Set the initial hMode to AlwaysOff if we're auto.\n                    if (hMode == ScrollbarAuto)\n                        setHorizontalScrollbarMode(ScrollbarAlwaysOff); // This causes a horizontal scrollbar to disappear.\n\n                    setScrollbarModes(hMode, vMode);\n                    setScrollbarsSuppressed(false, true);\n                } else\n                    setScrollbarModes(hMode, vMode);\n            }\n\n            LayoutSize oldSize = m_size;\n\n            m_size = LayoutSize(layoutSize().width(), layoutSize().height());\n\n            if (oldSize != m_size) {\n                m_doFullRepaint = true;\n                if (!m_firstLayout) {\n                    RenderBox* rootRenderer = document->documentElement() ? document->documentElement()->renderBox() : 0;\n                    RenderBox* bodyRenderer = rootRenderer && document->body() ? document->body()->renderBox() : 0;\n                    if (bodyRenderer && bodyRenderer->stretchesToViewport())\n                        bodyRenderer->setChildNeedsLayout();\n                    else if (rootRenderer && rootRenderer->stretchesToViewport())\n                        rootRenderer->setChildNeedsLayout();\n                }\n            }\n        }\n\n        layer = rootForThisLayout->enclosingLayer();\n\n        performLayout(rootForThisLayout, inSubtreeLayout);\n\n        m_layoutRoot = 0;\n    } // Reset m_layoutSchedulingEnabled to its previous value.\n\n    bool neededFullRepaint = m_doFullRepaint;\n\n    if (!inSubtreeLayout && !isPartialLayout && !toRenderView(rootForThisLayout)->document().printing())\n        adjustViewSize();\n\n    m_doFullRepaint = neededFullRepaint;\n\n    {\n        // FIXME: Can this scope just encompass this entire function?\n        FrameView::DeferredRepaintScope deferRepaints(*this);\n\n        if (m_doFullRepaint) {\n            // FIXME: This isn't really right, since the RenderView doesn't fully encompass\n            // the visibleContentRect(). It just happens to work out most of the time,\n            // since first layouts and printing don't have you scrolled anywhere.\n            rootForThisLayout->view()->repaint();\n\n        } else if (RuntimeEnabledFeatures::repaintAfterLayoutEnabled() && !partialLayout().isStopping()) {\n            repaintTree(rootForThisLayout);\n        }\n\n        layer->updateLayerPositionsAfterLayout(renderView()->layer(), updateLayerPositionFlags(layer, inSubtreeLayout, m_doFullRepaint));\n    }\n\n    updateCompositingLayersAfterLayout();\n\n    m_layoutCount++;\n\n    if (AXObjectCache* cache = rootForThisLayout->document().existingAXObjectCache())\n        cache->postNotification(rootForThisLayout, AXObjectCache::AXLayoutComplete, true);\n    updateAnnotatedRegions();\n\n    ASSERT(partialLayout().isStopping() || !rootForThisLayout->needsLayout());\n\n    updateCanBlitOnScrollRecursively();\n\n    if (document->hasListenerType(Document::OVERFLOWCHANGED_LISTENER))\n        updateOverflowStatus(layoutSize().width() < contentsWidth(), layoutSize().height() < contentsHeight());\n\n    scheduleOrPerformPostLayoutTasks();\n\n    InspectorInstrumentation::didLayout(cookie, rootForThisLayout);\n\n    m_nestedLayoutCount--;\n    if (m_nestedLayoutCount)\n        return;\n\n    if (partialLayout().isStopping())\n        return;\n\n#ifndef NDEBUG\n    // Post-layout assert that nobody was re-marked as needing layout during layout.\n    document->renderer()->assertSubtreeIsLaidOut();\n#endif\n\n    // FIXME: It should be not possible to remove the FrameView from the frame/page during layout\n    // however m_inLayout is not set for most of this function, so none of our RELEASE_ASSERTS\n    // in Frame/Page will fire. One of the post-layout tasks is disconnecting the Frame from\n    // the page in fast/frames/crash-remove-iframe-during-object-beforeload-2.html\n    // necessitating this check here.\n    // ASSERT(frame()->page());\n    if (frame().page())\n        frame().page()->chrome().client().layoutUpdated(m_frame.get());\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -126,8 +126,6 @@\n \n         layer = rootForThisLayout->enclosingLayer();\n \n-        suspendOverflowEvents();\n-\n         performLayout(rootForThisLayout, inSubtreeLayout);\n \n         m_layoutRoot = 0;",
        "diff_line_info": {
            "deleted_lines": [
                "        suspendOverflowEvents();",
                ""
            ],
            "added_lines": []
        }
    },
    {
        "cve_id": "CVE-2013-6655",
        "func_name": "chromium/FrameView::FrameView",
        "description": "Use-after-free vulnerability in Blink, as used in Google Chrome before 33.0.1750.117, allows remote attackers to cause a denial of service or possibly have unspecified other impact via vectors related to improper handling of overflowchanged DOM events during interaction between JavaScript and layout.",
        "git_url": "https://github.com/chromium/chromium/commit/5d37b543df5ddecfd6f1d89335f37f29dc86f80d",
        "commit_title": "Fire overflowchanged events at raf timing",
        "commit_text": " Running script inside layout leads to nasty security bugs and crashes, instead we should defer overflowchanged events until raf time. This still lets the author take an action before the paint preventing blinking and jumpiness which was the reason we ran it inside layout, while avoiding the pitfalls of synchronous script.  Unfortunately this patch makes us start firing overflowchanged even when a node has been removed from the tree, but the old protection against it was bad since it only checked inDocument() so removing a node and putting it in another document would still let the event fire. Instead I plan to fix the detach problem in a future patch since scroll events shouldn't fire for detached nodes either.  This patch also lets us remove the paused-event-dispatch.html test which was testing the suspend/resume logic I removed and for crashes that happen with synchronous script inside layout which doesn't apply after this patch.   ",
        "func_before": "FrameView::FrameView(Frame* frame)\n    : m_frame(frame)\n    , m_canHaveScrollbars(true)\n    , m_slowRepaintObjectCount(0)\n    , m_layoutTimer(this, &FrameView::layoutTimerFired)\n    , m_layoutRoot(0)\n    , m_inSynchronousPostLayout(false)\n    , m_postLayoutTasksTimer(this, &FrameView::postLayoutTimerFired)\n    , m_updateWidgetsTimer(this, &FrameView::updateWidgetsTimerFired)\n    , m_isTransparent(false)\n    , m_baseBackgroundColor(Color::white)\n    , m_mediaType(\"screen\")\n    , m_overflowEventSuspendCount(0)\n    , m_overflowStatusDirty(true)\n    , m_viewportRenderer(0)\n    , m_wasScrolledByUser(false)\n    , m_inProgrammaticScroll(false)\n    , m_safeToPropagateScrollToParent(true)\n    , m_deferredRepaintTimer(this, &FrameView::deferredRepaintTimerFired)\n    , m_isTrackingRepaints(false)\n    , m_shouldUpdateWhileOffscreen(true)\n    , m_deferSetNeedsLayouts(0)\n    , m_setNeedsLayoutWasDeferred(false)\n    , m_scrollCorner(0)\n    , m_shouldAutoSize(false)\n    , m_inAutoSize(false)\n    , m_didRunAutosize(false)\n    , m_hasSoftwareFilters(false)\n    , m_visibleContentScaleFactor(1)\n    , m_inputEventsScaleFactorForEmulation(1)\n    , m_partialLayout()\n    , m_layoutSizeFixedToFrameSize(true)\n{\n    ASSERT(m_frame);\n    init();\n\n    if (!isMainFrame())\n        return;\n\n    ScrollableArea::setVerticalScrollElasticity(ScrollElasticityAllowed);\n    ScrollableArea::setHorizontalScrollElasticity(ScrollElasticityAllowed);\n}",
        "func": "FrameView::FrameView(Frame* frame)\n    : m_frame(frame)\n    , m_canHaveScrollbars(true)\n    , m_slowRepaintObjectCount(0)\n    , m_layoutTimer(this, &FrameView::layoutTimerFired)\n    , m_layoutRoot(0)\n    , m_inSynchronousPostLayout(false)\n    , m_postLayoutTasksTimer(this, &FrameView::postLayoutTimerFired)\n    , m_updateWidgetsTimer(this, &FrameView::updateWidgetsTimerFired)\n    , m_isTransparent(false)\n    , m_baseBackgroundColor(Color::white)\n    , m_mediaType(\"screen\")\n    , m_overflowStatusDirty(true)\n    , m_viewportRenderer(0)\n    , m_wasScrolledByUser(false)\n    , m_inProgrammaticScroll(false)\n    , m_safeToPropagateScrollToParent(true)\n    , m_deferredRepaintTimer(this, &FrameView::deferredRepaintTimerFired)\n    , m_isTrackingRepaints(false)\n    , m_shouldUpdateWhileOffscreen(true)\n    , m_deferSetNeedsLayouts(0)\n    , m_setNeedsLayoutWasDeferred(false)\n    , m_scrollCorner(0)\n    , m_shouldAutoSize(false)\n    , m_inAutoSize(false)\n    , m_didRunAutosize(false)\n    , m_hasSoftwareFilters(false)\n    , m_visibleContentScaleFactor(1)\n    , m_inputEventsScaleFactorForEmulation(1)\n    , m_partialLayout()\n    , m_layoutSizeFixedToFrameSize(true)\n{\n    ASSERT(m_frame);\n    init();\n\n    if (!isMainFrame())\n        return;\n\n    ScrollableArea::setVerticalScrollElasticity(ScrollElasticityAllowed);\n    ScrollableArea::setHorizontalScrollElasticity(ScrollElasticityAllowed);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -10,7 +10,6 @@\n     , m_isTransparent(false)\n     , m_baseBackgroundColor(Color::white)\n     , m_mediaType(\"screen\")\n-    , m_overflowEventSuspendCount(0)\n     , m_overflowStatusDirty(true)\n     , m_viewportRenderer(0)\n     , m_wasScrolledByUser(false)",
        "diff_line_info": {
            "deleted_lines": [
                "    , m_overflowEventSuspendCount(0)"
            ],
            "added_lines": []
        }
    },
    {
        "cve_id": "CVE-2013-6655",
        "func_name": "chromium/~OverflowEventDispatcher",
        "description": "Use-after-free vulnerability in Blink, as used in Google Chrome before 33.0.1750.117, allows remote attackers to cause a denial of service or possibly have unspecified other impact via vectors related to improper handling of overflowchanged DOM events during interaction between JavaScript and layout.",
        "git_url": "https://github.com/chromium/chromium/commit/5d37b543df5ddecfd6f1d89335f37f29dc86f80d",
        "commit_title": "Fire overflowchanged events at raf timing",
        "commit_text": " Running script inside layout leads to nasty security bugs and crashes, instead we should defer overflowchanged events until raf time. This still lets the author take an action before the paint preventing blinking and jumpiness which was the reason we ran it inside layout, while avoiding the pitfalls of synchronous script.  Unfortunately this patch makes us start firing overflowchanged even when a node has been removed from the tree, but the old protection against it was bad since it only checked inDocument() so removing a node and putting it in another document would still let the event fire. Instead I plan to fix the detach problem in a future patch since scroll events shouldn't fire for detached nodes either.  This patch also lets us remove the paused-event-dispatch.html test which was testing the suspend/resume logic I removed and for crashes that happen with synchronous script inside layout which doesn't apply after this patch.   ",
        "func_before": "~OverflowEventDispatcher()\n    {\n        if (!m_shouldDispatchEvent)\n            return;\n\n        bool hasHorizontalLayoutOverflow = m_block->hasHorizontalLayoutOverflow();\n        bool hasVerticalLayoutOverflow = m_block->hasVerticalLayoutOverflow();\n\n        bool horizontalLayoutOverflowChanged = hasHorizontalLayoutOverflow != m_hadHorizontalLayoutOverflow;\n        bool verticalLayoutOverflowChanged = hasVerticalLayoutOverflow != m_hadVerticalLayoutOverflow;\n\n        if (!horizontalLayoutOverflowChanged && !verticalLayoutOverflowChanged)\n            return;\n\n        if (FrameView* frameView = m_block->frameView()) {\n            RefPtr<OverflowEvent> event = OverflowEvent::create(horizontalLayoutOverflowChanged, hasHorizontalLayoutOverflow, verticalLayoutOverflowChanged, hasVerticalLayoutOverflow);\n            event->setTarget(m_block->node());\n            frameView->scheduleOverflowEvent(event);\n        }\n    }",
        "func": "~OverflowEventDispatcher()\n    {\n        if (!m_shouldDispatchEvent)\n            return;\n\n        bool hasHorizontalLayoutOverflow = m_block->hasHorizontalLayoutOverflow();\n        bool hasVerticalLayoutOverflow = m_block->hasVerticalLayoutOverflow();\n\n        bool horizontalLayoutOverflowChanged = hasHorizontalLayoutOverflow != m_hadHorizontalLayoutOverflow;\n        bool verticalLayoutOverflowChanged = hasVerticalLayoutOverflow != m_hadVerticalLayoutOverflow;\n\n        if (!horizontalLayoutOverflowChanged && !verticalLayoutOverflowChanged)\n            return;\n\n        RefPtr<OverflowEvent> event = OverflowEvent::create(horizontalLayoutOverflowChanged, hasHorizontalLayoutOverflow, verticalLayoutOverflowChanged, hasVerticalLayoutOverflow);\n        event->setTarget(m_block->node());\n        m_block->document().enqueueAnimationFrameEvent(event.release());\n    }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -12,9 +12,7 @@\n         if (!horizontalLayoutOverflowChanged && !verticalLayoutOverflowChanged)\n             return;\n \n-        if (FrameView* frameView = m_block->frameView()) {\n-            RefPtr<OverflowEvent> event = OverflowEvent::create(horizontalLayoutOverflowChanged, hasHorizontalLayoutOverflow, verticalLayoutOverflowChanged, hasVerticalLayoutOverflow);\n-            event->setTarget(m_block->node());\n-            frameView->scheduleOverflowEvent(event);\n-        }\n+        RefPtr<OverflowEvent> event = OverflowEvent::create(horizontalLayoutOverflowChanged, hasHorizontalLayoutOverflow, verticalLayoutOverflowChanged, hasVerticalLayoutOverflow);\n+        event->setTarget(m_block->node());\n+        m_block->document().enqueueAnimationFrameEvent(event.release());\n     }",
        "diff_line_info": {
            "deleted_lines": [
                "        if (FrameView* frameView = m_block->frameView()) {",
                "            RefPtr<OverflowEvent> event = OverflowEvent::create(horizontalLayoutOverflowChanged, hasHorizontalLayoutOverflow, verticalLayoutOverflowChanged, hasVerticalLayoutOverflow);",
                "            event->setTarget(m_block->node());",
                "            frameView->scheduleOverflowEvent(event);",
                "        }"
            ],
            "added_lines": [
                "        RefPtr<OverflowEvent> event = OverflowEvent::create(horizontalLayoutOverflowChanged, hasHorizontalLayoutOverflow, verticalLayoutOverflowChanged, hasVerticalLayoutOverflow);",
                "        event->setTarget(m_block->node());",
                "        m_block->document().enqueueAnimationFrameEvent(event.release());"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-6655",
        "func_name": "chromium/ScriptedAnimationController::dispatchEvents",
        "description": "Use-after-free vulnerability in Blink, as used in Google Chrome before 33.0.1750.117, allows remote attackers to cause a denial of service or possibly have unspecified other impact via vectors related to improper handling of overflowchanged DOM events during interaction between JavaScript and layout.",
        "git_url": "https://github.com/chromium/chromium/commit/5d37b543df5ddecfd6f1d89335f37f29dc86f80d",
        "commit_title": "Fire overflowchanged events at raf timing",
        "commit_text": " Running script inside layout leads to nasty security bugs and crashes, instead we should defer overflowchanged events until raf time. This still lets the author take an action before the paint preventing blinking and jumpiness which was the reason we ran it inside layout, while avoiding the pitfalls of synchronous script.  Unfortunately this patch makes us start firing overflowchanged even when a node has been removed from the tree, but the old protection against it was bad since it only checked inDocument() so removing a node and putting it in another document would still let the event fire. Instead I plan to fix the detach problem in a future patch since scroll events shouldn't fire for detached nodes either.  This patch also lets us remove the paused-event-dispatch.html test which was testing the suspend/resume logic I removed and for crashes that happen with synchronous script inside layout which doesn't apply after this patch.   ",
        "func_before": "void ScriptedAnimationController::dispatchEvents()\n{\n    Vector<RefPtr<Event> > events;\n    events.swap(m_eventQueue);\n    m_scheduledEventTargets.clear();\n\n    for (size_t i = 0; i < events.size(); ++i) {\n        EventTarget* eventTarget = events[i]->target();\n        // FIXME: we should figure out how to make dispatchEvent properly virtual to avoid this.\n        if (DOMWindow* window = eventTarget->toDOMWindow())\n            window->dispatchEvent(events[i], 0);\n        else\n            eventTarget->dispatchEvent(events[i]);\n    }\n}",
        "func": "void ScriptedAnimationController::dispatchEvents()\n{\n    Vector<RefPtr<Event> > events;\n    events.swap(m_eventQueue);\n    m_perFrameEvents.clear();\n\n    for (size_t i = 0; i < events.size(); ++i) {\n        EventTarget* eventTarget = events[i]->target();\n        // FIXME: we should figure out how to make dispatchEvent properly virtual to avoid\n        // special casting window.\n        // FIXME: We should not fire events for nodes that are no longer in the tree.\n        if (DOMWindow* window = eventTarget->toDOMWindow())\n            window->dispatchEvent(events[i], 0);\n        else\n            eventTarget->dispatchEvent(events[i]);\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,11 +2,13 @@\n {\n     Vector<RefPtr<Event> > events;\n     events.swap(m_eventQueue);\n-    m_scheduledEventTargets.clear();\n+    m_perFrameEvents.clear();\n \n     for (size_t i = 0; i < events.size(); ++i) {\n         EventTarget* eventTarget = events[i]->target();\n-        // FIXME: we should figure out how to make dispatchEvent properly virtual to avoid this.\n+        // FIXME: we should figure out how to make dispatchEvent properly virtual to avoid\n+        // special casting window.\n+        // FIXME: We should not fire events for nodes that are no longer in the tree.\n         if (DOMWindow* window = eventTarget->toDOMWindow())\n             window->dispatchEvent(events[i], 0);\n         else",
        "diff_line_info": {
            "deleted_lines": [
                "    m_scheduledEventTargets.clear();",
                "        // FIXME: we should figure out how to make dispatchEvent properly virtual to avoid this."
            ],
            "added_lines": [
                "    m_perFrameEvents.clear();",
                "        // FIXME: we should figure out how to make dispatchEvent properly virtual to avoid",
                "        // special casting window.",
                "        // FIXME: We should not fire events for nodes that are no longer in the tree."
            ]
        }
    },
    {
        "cve_id": "CVE-2013-6655",
        "func_name": "chromium/WebViewImpl::sendResizeEventAndRepaint",
        "description": "Use-after-free vulnerability in Blink, as used in Google Chrome before 33.0.1750.117, allows remote attackers to cause a denial of service or possibly have unspecified other impact via vectors related to improper handling of overflowchanged DOM events during interaction between JavaScript and layout.",
        "git_url": "https://github.com/chromium/chromium/commit/5d37b543df5ddecfd6f1d89335f37f29dc86f80d",
        "commit_title": "Fire overflowchanged events at raf timing",
        "commit_text": " Running script inside layout leads to nasty security bugs and crashes, instead we should defer overflowchanged events until raf time. This still lets the author take an action before the paint preventing blinking and jumpiness which was the reason we ran it inside layout, while avoiding the pitfalls of synchronous script.  Unfortunately this patch makes us start firing overflowchanged even when a node has been removed from the tree, but the old protection against it was bad since it only checked inDocument() so removing a node and putting it in another document would still let the event fire. Instead I plan to fix the detach problem in a future patch since scroll events shouldn't fire for detached nodes either.  This patch also lets us remove the paused-event-dispatch.html test which was testing the suspend/resume logic I removed and for crashes that happen with synchronous script inside layout which doesn't apply after this patch.   ",
        "func_before": "void WebViewImpl::sendResizeEventAndRepaint()\n{\n    // FIXME: This is wrong. The FrameView is responsible sending a resizeEvent\n    // as part of layout. Layout is also responsible for sending invalidations\n    // to the embedder. This method and all callers may be wrong. -- eseidel.\n    if (mainFrameImpl()->frameView()) {\n        // Enqueues the resize event.\n        mainFrameImpl()->frame()->eventHandler().sendResizeEvent();\n    }\n\n    if (m_client) {\n        if (isAcceleratedCompositingActive()) {\n            updateLayerTreeViewport();\n        } else {\n            WebRect damagedRect(0, 0, m_size.width, m_size.height);\n            m_client->didInvalidateRect(damagedRect);\n        }\n    }\n    if (m_pageOverlays)\n        m_pageOverlays->update();\n}",
        "func": "void WebViewImpl::sendResizeEventAndRepaint()\n{\n    // FIXME: This is wrong. The FrameView is responsible sending a resizeEvent\n    // as part of layout. Layout is also responsible for sending invalidations\n    // to the embedder. This method and all callers may be wrong. -- eseidel.\n    if (mainFrameImpl()->frameView()) {\n        // Enqueues the resize event.\n        mainFrameImpl()->frame()->document()->enqueueResizeEvent();\n    }\n\n    if (m_client) {\n        if (isAcceleratedCompositingActive()) {\n            updateLayerTreeViewport();\n        } else {\n            WebRect damagedRect(0, 0, m_size.width, m_size.height);\n            m_client->didInvalidateRect(damagedRect);\n        }\n    }\n    if (m_pageOverlays)\n        m_pageOverlays->update();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,7 +5,7 @@\n     // to the embedder. This method and all callers may be wrong. -- eseidel.\n     if (mainFrameImpl()->frameView()) {\n         // Enqueues the resize event.\n-        mainFrameImpl()->frame()->eventHandler().sendResizeEvent();\n+        mainFrameImpl()->frame()->document()->enqueueResizeEvent();\n     }\n \n     if (m_client) {",
        "diff_line_info": {
            "deleted_lines": [
                "        mainFrameImpl()->frame()->eventHandler().sendResizeEvent();"
            ],
            "added_lines": [
                "        mainFrameImpl()->frame()->document()->enqueueResizeEvent();"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-6655",
        "func_name": "chromium/Document::enqueueScrollEventForNode",
        "description": "Use-after-free vulnerability in Blink, as used in Google Chrome before 33.0.1750.117, allows remote attackers to cause a denial of service or possibly have unspecified other impact via vectors related to improper handling of overflowchanged DOM events during interaction between JavaScript and layout.",
        "git_url": "https://github.com/chromium/chromium/commit/5d37b543df5ddecfd6f1d89335f37f29dc86f80d",
        "commit_title": "Fire overflowchanged events at raf timing",
        "commit_text": " Running script inside layout leads to nasty security bugs and crashes, instead we should defer overflowchanged events until raf time. This still lets the author take an action before the paint preventing blinking and jumpiness which was the reason we ran it inside layout, while avoiding the pitfalls of synchronous script.  Unfortunately this patch makes us start firing overflowchanged even when a node has been removed from the tree, but the old protection against it was bad since it only checked inDocument() so removing a node and putting it in another document would still let the event fire. Instead I plan to fix the detach problem in a future patch since scroll events shouldn't fire for detached nodes either.  This patch also lets us remove the paused-event-dispatch.html test which was testing the suspend/resume logic I removed and for crashes that happen with synchronous script inside layout which doesn't apply after this patch.   ",
        "func_before": "void Document::enqueueScrollEventForNode(Node* target)\n{\n    // Per the W3C CSSOM View Module only scroll events fired at the document should bubble.\n    RefPtr<Event> scrollEvent = target->isDocumentNode() ? Event::createBubble(EventTypeNames::scroll) : Event::create(EventTypeNames::scroll);\n    scrollEvent->setTarget(target);\n    scheduleAnimationFrameEvent(scrollEvent.release());\n}",
        "func": "void Document::enqueueScrollEventForNode(Node* target)\n{\n    // Per the W3C CSSOM View Module only scroll events fired at the document should bubble.\n    RefPtr<Event> scrollEvent = target->isDocumentNode() ? Event::createBubble(EventTypeNames::scroll) : Event::create(EventTypeNames::scroll);\n    scrollEvent->setTarget(target);\n    ensureScriptedAnimationController().enqueuePerFrameEvent(scrollEvent.release());\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,5 +3,5 @@\n     // Per the W3C CSSOM View Module only scroll events fired at the document should bubble.\n     RefPtr<Event> scrollEvent = target->isDocumentNode() ? Event::createBubble(EventTypeNames::scroll) : Event::create(EventTypeNames::scroll);\n     scrollEvent->setTarget(target);\n-    scheduleAnimationFrameEvent(scrollEvent.release());\n+    ensureScriptedAnimationController().enqueuePerFrameEvent(scrollEvent.release());\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    scheduleAnimationFrameEvent(scrollEvent.release());"
            ],
            "added_lines": [
                "    ensureScriptedAnimationController().enqueuePerFrameEvent(scrollEvent.release());"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-6658",
        "func_name": "chromium/RenderLayerScrollableArea::setScrollOffset",
        "description": "Multiple use-after-free vulnerabilities in the layout implementation in Blink, as used in Google Chrome before 33.0.1750.117, allow remote attackers to cause a denial of service or possibly have unspecified other impact via vectors involving (1) running JavaScript code during execution of the updateWidgetPositions function or (2) making a call into a plugin during execution of the updateWidgetPositions function.",
        "git_url": "https://github.com/chromium/chromium/commit/fe24110c2b904cbeeab1fe15b20bf7fb7b2b6a55",
        "commit_title": "Harden the machinery around updateWidgetPositions()",
        "commit_text": " updateWidgetPositions() can blow away the RenderView by running script or calling into plugins. This patch moves it from RenderView to FrameView since having this method on RenderView which might destroy itself is not safe. It also switches to using normal RefPtr instead of manually managing the refcount and finally adds RefPtr to callers of updateWidgetPositions() to avoid use-after-frees.  There's one final call inside RenderLayerScrollableArea::setScrollOffset which is not safe but is difficult to mitigate since we're way down a callstack by the time this call is made which can destroy the render tree and the RenderLayerScrollableArea. This patch adds a RELEASE_ASSERT to kill the renderer in case we get into a sitaution where this happens. In the future we should detangle this concept entirely so such an ASSERT isn't needed and so that the render tree can never destroy itself from the inside.  It's not clear how to write a test for this since you need to get us to go into the scrolling code with a dirty tree or have a plugin that does something nefarious.   ",
        "func_before": "void RenderLayerScrollableArea::setScrollOffset(const IntPoint& newScrollOffset)\n{\n    if (!m_box->isMarquee()) {\n        // Ensure that the dimensions will be computed if they need to be (for overflow:hidden blocks).\n        if (m_scrollDimensionsDirty)\n            computeScrollDimensions();\n    }\n\n    if (scrollOffset() == toIntSize(newScrollOffset))\n        return;\n\n    setScrollOffset(toIntSize(newScrollOffset));\n\n    Frame* frame = m_box->frame();\n    InspectorInstrumentation::willScrollLayer(m_box);\n\n    RenderView* view = m_box->view();\n\n    // We should have a RenderView if we're trying to scroll.\n    ASSERT(view);\n\n    // Update the positions of our child layers (if needed as only fixed layers should be impacted by a scroll).\n    // We don't update compositing layers, because we need to do a deep update from the compositing ancestor.\n    bool inLayout = view ? view->frameView()->isInLayout() : false;\n    if (!inLayout) {\n        // If we're in the middle of layout, we'll just update layers once layout has finished.\n        layer()->updateLayerPositionsAfterOverflowScroll();\n        if (view) {\n            // Update regions, scrolling may change the clip of a particular region.\n            view->frameView()->updateAnnotatedRegions();\n            view->updateWidgetPositions();\n        }\n\n        updateCompositingLayersAfterScroll();\n    }\n\n    RenderLayerModelObject* repaintContainer = m_box->containerForRepaint();\n    if (frame) {\n        // The caret rect needs to be invalidated after scrolling\n        frame->selection().setCaretRectNeedsUpdate();\n\n        FloatQuad quadForFakeMouseMoveEvent = FloatQuad(layer()->repainter().repaintRect());\n        if (repaintContainer)\n            quadForFakeMouseMoveEvent = repaintContainer->localToAbsoluteQuad(quadForFakeMouseMoveEvent);\n        frame->eventHandler().dispatchFakeMouseMoveEventSoonInQuad(quadForFakeMouseMoveEvent);\n    }\n\n    bool requiresRepaint = true;\n\n    if (m_box->view()->compositor()->inCompositingMode()) {\n        bool onlyScrolledCompositedLayers = scrollsOverflow()\n            && !layer()->hasVisibleNonLayerContent()\n            && !layer()->hasNonCompositedChild()\n            && !layer()->hasBlockSelectionGapBounds()\n            && !m_box->isMarquee();\n\n        if (usesCompositedScrolling() || onlyScrolledCompositedLayers)\n            requiresRepaint = false;\n    }\n\n    // Just schedule a full repaint of our object.\n    if (view && requiresRepaint)\n        m_box->repaintUsingContainer(repaintContainer, pixelSnappedIntRect(layer()->repainter().repaintRect()));\n\n    // Schedule the scroll DOM event.\n    if (m_box->node())\n        m_box->node()->document().enqueueScrollEventForNode(m_box->node());\n\n    InspectorInstrumentation::didScrollLayer(m_box);\n}",
        "func": "void RenderLayerScrollableArea::setScrollOffset(const IntPoint& newScrollOffset)\n{\n    if (!m_box->isMarquee()) {\n        // Ensure that the dimensions will be computed if they need to be (for overflow:hidden blocks).\n        if (m_scrollDimensionsDirty)\n            computeScrollDimensions();\n    }\n\n    if (scrollOffset() == toIntSize(newScrollOffset))\n        return;\n\n    setScrollOffset(toIntSize(newScrollOffset));\n\n    Frame* frame = m_box->frame();\n    ASSERT(frame);\n\n    RefPtr<FrameView> frameView = m_box->frameView();\n\n    InspectorInstrumentation::willScrollLayer(m_box);\n\n    // Update the positions of our child layers (if needed as only fixed layers should be impacted by a scroll).\n    // We don't update compositing layers, because we need to do a deep update from the compositing ancestor.\n    if (!frameView->isInLayout()) {\n        // If we're in the middle of layout, we'll just update layers once layout has finished.\n        layer()->updateLayerPositionsAfterOverflowScroll();\n        // Update regions, scrolling may change the clip of a particular region.\n        frameView->updateAnnotatedRegions();\n        // FIXME: We shouldn't call updateWidgetPositions() here since it might tear down the render tree,\n        // for now we just crash to avoid allowing an attacker to use after free.\n        frameView->updateWidgetPositions();\n        RELEASE_ASSERT(frameView->renderView());\n        updateCompositingLayersAfterScroll();\n    }\n\n    RenderLayerModelObject* repaintContainer = m_box->containerForRepaint();\n    // The caret rect needs to be invalidated after scrolling\n    frame->selection().setCaretRectNeedsUpdate();\n\n    FloatQuad quadForFakeMouseMoveEvent = FloatQuad(layer()->repainter().repaintRect());\n    if (repaintContainer)\n        quadForFakeMouseMoveEvent = repaintContainer->localToAbsoluteQuad(quadForFakeMouseMoveEvent);\n    frame->eventHandler().dispatchFakeMouseMoveEventSoonInQuad(quadForFakeMouseMoveEvent);\n\n    bool requiresRepaint = true;\n\n    if (m_box->view()->compositor()->inCompositingMode()) {\n        bool onlyScrolledCompositedLayers = scrollsOverflow()\n            && !layer()->hasVisibleNonLayerContent()\n            && !layer()->hasNonCompositedChild()\n            && !layer()->hasBlockSelectionGapBounds()\n            && !m_box->isMarquee();\n\n        if (usesCompositedScrolling() || onlyScrolledCompositedLayers)\n            requiresRepaint = false;\n    }\n\n    // Just schedule a full repaint of our object.\n    if (requiresRepaint)\n        m_box->repaintUsingContainer(repaintContainer, pixelSnappedIntRect(layer()->repainter().repaintRect()));\n\n    // Schedule the scroll DOM event.\n    if (m_box->node())\n        m_box->node()->document().enqueueScrollEventForNode(m_box->node());\n\n    InspectorInstrumentation::didScrollLayer(m_box);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -12,38 +12,34 @@\n     setScrollOffset(toIntSize(newScrollOffset));\n \n     Frame* frame = m_box->frame();\n+    ASSERT(frame);\n+\n+    RefPtr<FrameView> frameView = m_box->frameView();\n+\n     InspectorInstrumentation::willScrollLayer(m_box);\n-\n-    RenderView* view = m_box->view();\n-\n-    // We should have a RenderView if we're trying to scroll.\n-    ASSERT(view);\n \n     // Update the positions of our child layers (if needed as only fixed layers should be impacted by a scroll).\n     // We don't update compositing layers, because we need to do a deep update from the compositing ancestor.\n-    bool inLayout = view ? view->frameView()->isInLayout() : false;\n-    if (!inLayout) {\n+    if (!frameView->isInLayout()) {\n         // If we're in the middle of layout, we'll just update layers once layout has finished.\n         layer()->updateLayerPositionsAfterOverflowScroll();\n-        if (view) {\n-            // Update regions, scrolling may change the clip of a particular region.\n-            view->frameView()->updateAnnotatedRegions();\n-            view->updateWidgetPositions();\n-        }\n-\n+        // Update regions, scrolling may change the clip of a particular region.\n+        frameView->updateAnnotatedRegions();\n+        // FIXME: We shouldn't call updateWidgetPositions() here since it might tear down the render tree,\n+        // for now we just crash to avoid allowing an attacker to use after free.\n+        frameView->updateWidgetPositions();\n+        RELEASE_ASSERT(frameView->renderView());\n         updateCompositingLayersAfterScroll();\n     }\n \n     RenderLayerModelObject* repaintContainer = m_box->containerForRepaint();\n-    if (frame) {\n-        // The caret rect needs to be invalidated after scrolling\n-        frame->selection().setCaretRectNeedsUpdate();\n+    // The caret rect needs to be invalidated after scrolling\n+    frame->selection().setCaretRectNeedsUpdate();\n \n-        FloatQuad quadForFakeMouseMoveEvent = FloatQuad(layer()->repainter().repaintRect());\n-        if (repaintContainer)\n-            quadForFakeMouseMoveEvent = repaintContainer->localToAbsoluteQuad(quadForFakeMouseMoveEvent);\n-        frame->eventHandler().dispatchFakeMouseMoveEventSoonInQuad(quadForFakeMouseMoveEvent);\n-    }\n+    FloatQuad quadForFakeMouseMoveEvent = FloatQuad(layer()->repainter().repaintRect());\n+    if (repaintContainer)\n+        quadForFakeMouseMoveEvent = repaintContainer->localToAbsoluteQuad(quadForFakeMouseMoveEvent);\n+    frame->eventHandler().dispatchFakeMouseMoveEventSoonInQuad(quadForFakeMouseMoveEvent);\n \n     bool requiresRepaint = true;\n \n@@ -59,7 +55,7 @@\n     }\n \n     // Just schedule a full repaint of our object.\n-    if (view && requiresRepaint)\n+    if (requiresRepaint)\n         m_box->repaintUsingContainer(repaintContainer, pixelSnappedIntRect(layer()->repainter().repaintRect()));\n \n     // Schedule the scroll DOM event.",
        "diff_line_info": {
            "deleted_lines": [
                "",
                "    RenderView* view = m_box->view();",
                "",
                "    // We should have a RenderView if we're trying to scroll.",
                "    ASSERT(view);",
                "    bool inLayout = view ? view->frameView()->isInLayout() : false;",
                "    if (!inLayout) {",
                "        if (view) {",
                "            // Update regions, scrolling may change the clip of a particular region.",
                "            view->frameView()->updateAnnotatedRegions();",
                "            view->updateWidgetPositions();",
                "        }",
                "",
                "    if (frame) {",
                "        // The caret rect needs to be invalidated after scrolling",
                "        frame->selection().setCaretRectNeedsUpdate();",
                "        FloatQuad quadForFakeMouseMoveEvent = FloatQuad(layer()->repainter().repaintRect());",
                "        if (repaintContainer)",
                "            quadForFakeMouseMoveEvent = repaintContainer->localToAbsoluteQuad(quadForFakeMouseMoveEvent);",
                "        frame->eventHandler().dispatchFakeMouseMoveEventSoonInQuad(quadForFakeMouseMoveEvent);",
                "    }",
                "    if (view && requiresRepaint)"
            ],
            "added_lines": [
                "    ASSERT(frame);",
                "",
                "    RefPtr<FrameView> frameView = m_box->frameView();",
                "",
                "    if (!frameView->isInLayout()) {",
                "        // Update regions, scrolling may change the clip of a particular region.",
                "        frameView->updateAnnotatedRegions();",
                "        // FIXME: We shouldn't call updateWidgetPositions() here since it might tear down the render tree,",
                "        // for now we just crash to avoid allowing an attacker to use after free.",
                "        frameView->updateWidgetPositions();",
                "        RELEASE_ASSERT(frameView->renderView());",
                "    // The caret rect needs to be invalidated after scrolling",
                "    frame->selection().setCaretRectNeedsUpdate();",
                "    FloatQuad quadForFakeMouseMoveEvent = FloatQuad(layer()->repainter().repaintRect());",
                "    if (repaintContainer)",
                "        quadForFakeMouseMoveEvent = repaintContainer->localToAbsoluteQuad(quadForFakeMouseMoveEvent);",
                "    frame->eventHandler().dispatchFakeMouseMoveEventSoonInQuad(quadForFakeMouseMoveEvent);",
                "    if (requiresRepaint)"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-6658",
        "func_name": "chromium/FrameView::performPostLayoutTasks",
        "description": "Multiple use-after-free vulnerabilities in the layout implementation in Blink, as used in Google Chrome before 33.0.1750.117, allow remote attackers to cause a denial of service or possibly have unspecified other impact via vectors involving (1) running JavaScript code during execution of the updateWidgetPositions function or (2) making a call into a plugin during execution of the updateWidgetPositions function.",
        "git_url": "https://github.com/chromium/chromium/commit/fe24110c2b904cbeeab1fe15b20bf7fb7b2b6a55",
        "commit_title": "Harden the machinery around updateWidgetPositions()",
        "commit_text": " updateWidgetPositions() can blow away the RenderView by running script or calling into plugins. This patch moves it from RenderView to FrameView since having this method on RenderView which might destroy itself is not safe. It also switches to using normal RefPtr instead of manually managing the refcount and finally adds RefPtr to callers of updateWidgetPositions() to avoid use-after-frees.  There's one final call inside RenderLayerScrollableArea::setScrollOffset which is not safe but is difficult to mitigate since we're way down a callstack by the time this call is made which can destroy the render tree and the RenderLayerScrollableArea. This patch adds a RELEASE_ASSERT to kill the renderer in case we get into a sitaution where this happens. In the future we should detangle this concept entirely so such an ASSERT isn't needed and so that the render tree can never destroy itself from the inside.  It's not clear how to write a test for this since you need to get us to go into the scrolling code with a dirty tree or have a plugin that does something nefarious.   ",
        "func_before": "void FrameView::performPostLayoutTasks()\n{\n    TRACE_EVENT0(\"webkit\", \"FrameView::performPostLayoutTasks\");\n    RefPtr<FrameView> protect(this);\n\n    m_postLayoutTasksTimer.stop();\n\n    m_frame->selection().setCaretRectNeedsUpdate();\n    m_frame->selection().updateAppearance();\n\n    if (m_nestedLayoutCount <= 1) {\n        if (m_firstLayoutCallbackPending) {\n            m_firstLayoutCallbackPending = false;\n            m_frame->loader().didFirstLayout();\n        }\n\n        // Ensure that we always send this eventually.\n        if (!m_frame->document()->parsing() && m_frame->loader().stateMachine()->committedFirstRealDocumentLoad())\n            m_isVisuallyNonEmpty = true;\n\n        // If the layout was done with pending sheets, we are not in fact visually non-empty yet.\n        if (m_isVisuallyNonEmpty && !m_frame->document()->didLayoutWithPendingStylesheets() && m_firstVisuallyNonEmptyLayoutCallbackPending) {\n            m_firstVisuallyNonEmptyLayoutCallbackPending = false;\n            // FIXME: This callback is probably not needed, but is currently used\n            // by android for setting the background color.\n            m_frame->loader().client()->dispatchDidFirstVisuallyNonEmptyLayout();\n        }\n    }\n\n    FontFaceSet::didLayout(m_frame->document());\n\n    RenderView* renderView = this->renderView();\n    if (renderView)\n        renderView->updateWidgetPositions();\n\n    if (!m_updateWidgetsTimer.isActive())\n        m_updateWidgetsTimer.startOneShot(0);\n\n    if (Page* page = m_frame->page()) {\n        if (ScrollingCoordinator* scrollingCoordinator = page->scrollingCoordinator())\n            scrollingCoordinator->notifyLayoutUpdated();\n    }\n\n    scrollToAnchor();\n\n    sendResizeEventIfNeeded();\n}",
        "func": "void FrameView::performPostLayoutTasks()\n{\n    TRACE_EVENT0(\"webkit\", \"FrameView::performPostLayoutTasks\");\n    RefPtr<FrameView> protect(this);\n\n    m_postLayoutTasksTimer.stop();\n\n    m_frame->selection().setCaretRectNeedsUpdate();\n    m_frame->selection().updateAppearance();\n\n    if (m_nestedLayoutCount <= 1) {\n        if (m_firstLayoutCallbackPending) {\n            m_firstLayoutCallbackPending = false;\n            m_frame->loader().didFirstLayout();\n        }\n\n        // Ensure that we always send this eventually.\n        if (!m_frame->document()->parsing() && m_frame->loader().stateMachine()->committedFirstRealDocumentLoad())\n            m_isVisuallyNonEmpty = true;\n\n        // If the layout was done with pending sheets, we are not in fact visually non-empty yet.\n        if (m_isVisuallyNonEmpty && !m_frame->document()->didLayoutWithPendingStylesheets() && m_firstVisuallyNonEmptyLayoutCallbackPending) {\n            m_firstVisuallyNonEmptyLayoutCallbackPending = false;\n            // FIXME: This callback is probably not needed, but is currently used\n            // by android for setting the background color.\n            m_frame->loader().client()->dispatchDidFirstVisuallyNonEmptyLayout();\n        }\n    }\n\n    FontFaceSet::didLayout(m_frame->document());\n\n    updateWidgetPositions();\n\n    // Plugins could have torn down the page inside updateWidgetPositions().\n    if (!renderView())\n        return;\n\n    if (!m_updateWidgetsTimer.isActive())\n        m_updateWidgetsTimer.startOneShot(0);\n\n    if (Page* page = m_frame->page()) {\n        if (ScrollingCoordinator* scrollingCoordinator = page->scrollingCoordinator())\n            scrollingCoordinator->notifyLayoutUpdated();\n    }\n\n    scrollToAnchor();\n\n    sendResizeEventIfNeeded();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -29,9 +29,11 @@\n \n     FontFaceSet::didLayout(m_frame->document());\n \n-    RenderView* renderView = this->renderView();\n-    if (renderView)\n-        renderView->updateWidgetPositions();\n+    updateWidgetPositions();\n+\n+    // Plugins could have torn down the page inside updateWidgetPositions().\n+    if (!renderView())\n+        return;\n \n     if (!m_updateWidgetsTimer.isActive())\n         m_updateWidgetsTimer.startOneShot(0);",
        "diff_line_info": {
            "deleted_lines": [
                "    RenderView* renderView = this->renderView();",
                "    if (renderView)",
                "        renderView->updateWidgetPositions();"
            ],
            "added_lines": [
                "    updateWidgetPositions();",
                "",
                "    // Plugins could have torn down the page inside updateWidgetPositions().",
                "    if (!renderView())",
                "        return;"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-6658",
        "func_name": "chromium/FrameView::scheduleOrPerformPostLayoutTasks",
        "description": "Multiple use-after-free vulnerabilities in the layout implementation in Blink, as used in Google Chrome before 33.0.1750.117, allow remote attackers to cause a denial of service or possibly have unspecified other impact via vectors involving (1) running JavaScript code during execution of the updateWidgetPositions function or (2) making a call into a plugin during execution of the updateWidgetPositions function.",
        "git_url": "https://github.com/chromium/chromium/commit/fe24110c2b904cbeeab1fe15b20bf7fb7b2b6a55",
        "commit_title": "Harden the machinery around updateWidgetPositions()",
        "commit_text": " updateWidgetPositions() can blow away the RenderView by running script or calling into plugins. This patch moves it from RenderView to FrameView since having this method on RenderView which might destroy itself is not safe. It also switches to using normal RefPtr instead of manually managing the refcount and finally adds RefPtr to callers of updateWidgetPositions() to avoid use-after-frees.  There's one final call inside RenderLayerScrollableArea::setScrollOffset which is not safe but is difficult to mitigate since we're way down a callstack by the time this call is made which can destroy the render tree and the RenderLayerScrollableArea. This patch adds a RELEASE_ASSERT to kill the renderer in case we get into a sitaution where this happens. In the future we should detangle this concept entirely so such an ASSERT isn't needed and so that the render tree can never destroy itself from the inside.  It's not clear how to write a test for this since you need to get us to go into the scrolling code with a dirty tree or have a plugin that does something nefarious.   ",
        "func_before": "void FrameView::scheduleOrPerformPostLayoutTasks()\n{\n    if (m_postLayoutTasksTimer.isActive())\n        return;\n\n    // Partial layouts should not happen with synchronous post layouts.\n    ASSERT(!(m_inSynchronousPostLayout && partialLayout().isStopping()));\n\n    if (!m_inSynchronousPostLayout) {\n        if (frame().document()->shouldDisplaySeamlesslyWithParent()) {\n            if (RenderView* renderView = this->renderView())\n                renderView->updateWidgetPositions();\n        } else {\n            m_inSynchronousPostLayout = true;\n            // Calls resumeScheduledEvents()\n            performPostLayoutTasks();\n            m_inSynchronousPostLayout = false;\n        }\n    }\n\n    if (!m_postLayoutTasksTimer.isActive() && (needsLayout() || m_inSynchronousPostLayout || frame().document()->shouldDisplaySeamlesslyWithParent())) {\n        // If we need layout or are already in a synchronous call to postLayoutTasks(),\n        // defer widget updates and event dispatch until after we return. postLayoutTasks()\n        // can make us need to update again, and we can get stuck in a nasty cycle unless\n        // we call it through the timer here.\n        m_postLayoutTasksTimer.startOneShot(0);\n        if (!partialLayout().isStopping() && needsLayout())\n            layout();\n    }\n}",
        "func": "void FrameView::scheduleOrPerformPostLayoutTasks()\n{\n    if (m_postLayoutTasksTimer.isActive())\n        return;\n\n    // Partial layouts should not happen with synchronous post layouts.\n    ASSERT(!(m_inSynchronousPostLayout && partialLayout().isStopping()));\n\n    if (!m_inSynchronousPostLayout) {\n        if (frame().document()->shouldDisplaySeamlesslyWithParent()) {\n            updateWidgetPositions();\n        } else {\n            m_inSynchronousPostLayout = true;\n            // Calls resumeScheduledEvents()\n            performPostLayoutTasks();\n            m_inSynchronousPostLayout = false;\n        }\n    }\n\n    if (!m_postLayoutTasksTimer.isActive() && (needsLayout() || m_inSynchronousPostLayout || frame().document()->shouldDisplaySeamlesslyWithParent())) {\n        // If we need layout or are already in a synchronous call to postLayoutTasks(),\n        // defer widget updates and event dispatch until after we return. postLayoutTasks()\n        // can make us need to update again, and we can get stuck in a nasty cycle unless\n        // we call it through the timer here.\n        m_postLayoutTasksTimer.startOneShot(0);\n        if (!partialLayout().isStopping() && needsLayout())\n            layout();\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -8,8 +8,7 @@\n \n     if (!m_inSynchronousPostLayout) {\n         if (frame().document()->shouldDisplaySeamlesslyWithParent()) {\n-            if (RenderView* renderView = this->renderView())\n-                renderView->updateWidgetPositions();\n+            updateWidgetPositions();\n         } else {\n             m_inSynchronousPostLayout = true;\n             // Calls resumeScheduledEvents()",
        "diff_line_info": {
            "deleted_lines": [
                "            if (RenderView* renderView = this->renderView())",
                "                renderView->updateWidgetPositions();"
            ],
            "added_lines": [
                "            updateWidgetPositions();"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-6658",
        "func_name": "chromium/FrameView::repaintFixedElementsAfterScrolling",
        "description": "Multiple use-after-free vulnerabilities in the layout implementation in Blink, as used in Google Chrome before 33.0.1750.117, allow remote attackers to cause a denial of service or possibly have unspecified other impact via vectors involving (1) running JavaScript code during execution of the updateWidgetPositions function or (2) making a call into a plugin during execution of the updateWidgetPositions function.",
        "git_url": "https://github.com/chromium/chromium/commit/fe24110c2b904cbeeab1fe15b20bf7fb7b2b6a55",
        "commit_title": "Harden the machinery around updateWidgetPositions()",
        "commit_text": " updateWidgetPositions() can blow away the RenderView by running script or calling into plugins. This patch moves it from RenderView to FrameView since having this method on RenderView which might destroy itself is not safe. It also switches to using normal RefPtr instead of manually managing the refcount and finally adds RefPtr to callers of updateWidgetPositions() to avoid use-after-frees.  There's one final call inside RenderLayerScrollableArea::setScrollOffset which is not safe but is difficult to mitigate since we're way down a callstack by the time this call is made which can destroy the render tree and the RenderLayerScrollableArea. This patch adds a RELEASE_ASSERT to kill the renderer in case we get into a sitaution where this happens. In the future we should detangle this concept entirely so such an ASSERT isn't needed and so that the render tree can never destroy itself from the inside.  It's not clear how to write a test for this since you need to get us to go into the scrolling code with a dirty tree or have a plugin that does something nefarious.   ",
        "func_before": "void FrameView::repaintFixedElementsAfterScrolling()\n{\n    // For fixed position elements, update widget positions and compositing layers after scrolling,\n    // but only if we're not inside of layout.\n    if (!m_nestedLayoutCount && hasViewportConstrainedObjects()) {\n        if (RenderView* renderView = this->renderView()) {\n            renderView->updateWidgetPositions();\n            renderView->layer()->updateLayerPositionsAfterDocumentScroll();\n        }\n    }\n}",
        "func": "void FrameView::repaintFixedElementsAfterScrolling()\n{\n    RefPtr<FrameView> protect(this);\n    // For fixed position elements, update widget positions and compositing layers after scrolling,\n    // but only if we're not inside of layout.\n    if (!m_nestedLayoutCount && hasViewportConstrainedObjects()) {\n        updateWidgetPositions();\n        if (RenderView* renderView = this->renderView())\n            renderView->layer()->updateLayerPositionsAfterDocumentScroll();\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,11 +1,11 @@\n void FrameView::repaintFixedElementsAfterScrolling()\n {\n+    RefPtr<FrameView> protect(this);\n     // For fixed position elements, update widget positions and compositing layers after scrolling,\n     // but only if we're not inside of layout.\n     if (!m_nestedLayoutCount && hasViewportConstrainedObjects()) {\n-        if (RenderView* renderView = this->renderView()) {\n-            renderView->updateWidgetPositions();\n+        updateWidgetPositions();\n+        if (RenderView* renderView = this->renderView())\n             renderView->layer()->updateLayerPositionsAfterDocumentScroll();\n-        }\n     }\n }",
        "diff_line_info": {
            "deleted_lines": [
                "        if (RenderView* renderView = this->renderView()) {",
                "            renderView->updateWidgetPositions();",
                "        }"
            ],
            "added_lines": [
                "    RefPtr<FrameView> protect(this);",
                "        updateWidgetPositions();",
                "        if (RenderView* renderView = this->renderView())"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-6658",
        "func_name": "chromium/RenderWidget::RenderWidget",
        "description": "Multiple use-after-free vulnerabilities in the layout implementation in Blink, as used in Google Chrome before 33.0.1750.117, allow remote attackers to cause a denial of service or possibly have unspecified other impact via vectors involving (1) running JavaScript code during execution of the updateWidgetPositions function or (2) making a call into a plugin during execution of the updateWidgetPositions function.",
        "git_url": "https://github.com/chromium/chromium/commit/fe24110c2b904cbeeab1fe15b20bf7fb7b2b6a55",
        "commit_title": "Harden the machinery around updateWidgetPositions()",
        "commit_text": " updateWidgetPositions() can blow away the RenderView by running script or calling into plugins. This patch moves it from RenderView to FrameView since having this method on RenderView which might destroy itself is not safe. It also switches to using normal RefPtr instead of manually managing the refcount and finally adds RefPtr to callers of updateWidgetPositions() to avoid use-after-frees.  There's one final call inside RenderLayerScrollableArea::setScrollOffset which is not safe but is difficult to mitigate since we're way down a callstack by the time this call is made which can destroy the render tree and the RenderLayerScrollableArea. This patch adds a RELEASE_ASSERT to kill the renderer in case we get into a sitaution where this happens. In the future we should detangle this concept entirely so such an ASSERT isn't needed and so that the render tree can never destroy itself from the inside.  It's not clear how to write a test for this since you need to get us to go into the scrolling code with a dirty tree or have a plugin that does something nefarious.   ",
        "func_before": "RenderWidget::RenderWidget(Element* element)\n    : RenderReplaced(element)\n    , m_widget(0)\n    , m_frameView(element->document().view())\n    // Reference counting is used to prevent the widget from being\n    // destroyed while inside the Widget code, which might not be\n    // able to handle that.\n    , m_refCount(1)\n{\n    view()->addWidget(this);\n}",
        "func": "RenderWidget::RenderWidget(Element* element)\n    : RenderReplaced(element)\n    , m_widget(0)\n    // Reference counting is used to prevent the widget from being\n    // destroyed while inside the Widget code, which might not be\n    // able to handle that.\n    , m_refCount(1)\n{\n    ASSERT(element);\n    frameView()->addWidget(this);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,11 +1,11 @@\n RenderWidget::RenderWidget(Element* element)\n     : RenderReplaced(element)\n     , m_widget(0)\n-    , m_frameView(element->document().view())\n     // Reference counting is used to prevent the widget from being\n     // destroyed while inside the Widget code, which might not be\n     // able to handle that.\n     , m_refCount(1)\n {\n-    view()->addWidget(this);\n+    ASSERT(element);\n+    frameView()->addWidget(this);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    , m_frameView(element->document().view())",
                "    view()->addWidget(this);"
            ],
            "added_lines": [
                "    ASSERT(element);",
                "    frameView()->addWidget(this);"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-6658",
        "func_name": "chromium/RenderWidget::willBeDestroyed",
        "description": "Multiple use-after-free vulnerabilities in the layout implementation in Blink, as used in Google Chrome before 33.0.1750.117, allow remote attackers to cause a denial of service or possibly have unspecified other impact via vectors involving (1) running JavaScript code during execution of the updateWidgetPositions function or (2) making a call into a plugin during execution of the updateWidgetPositions function.",
        "git_url": "https://github.com/chromium/chromium/commit/fe24110c2b904cbeeab1fe15b20bf7fb7b2b6a55",
        "commit_title": "Harden the machinery around updateWidgetPositions()",
        "commit_text": " updateWidgetPositions() can blow away the RenderView by running script or calling into plugins. This patch moves it from RenderView to FrameView since having this method on RenderView which might destroy itself is not safe. It also switches to using normal RefPtr instead of manually managing the refcount and finally adds RefPtr to callers of updateWidgetPositions() to avoid use-after-frees.  There's one final call inside RenderLayerScrollableArea::setScrollOffset which is not safe but is difficult to mitigate since we're way down a callstack by the time this call is made which can destroy the render tree and the RenderLayerScrollableArea. This patch adds a RELEASE_ASSERT to kill the renderer in case we get into a sitaution where this happens. In the future we should detangle this concept entirely so such an ASSERT isn't needed and so that the render tree can never destroy itself from the inside.  It's not clear how to write a test for this since you need to get us to go into the scrolling code with a dirty tree or have a plugin that does something nefarious.   ",
        "func_before": "void RenderWidget::willBeDestroyed()\n{\n    if (RenderView* v = view())\n        v->removeWidget(this);\n\n    if (AXObjectCache* cache = document().existingAXObjectCache()) {\n        cache->childrenChanged(this->parent());\n        cache->remove(this);\n    }\n\n    setWidget(0);\n\n    RenderReplaced::willBeDestroyed();\n}",
        "func": "void RenderWidget::willBeDestroyed()\n{\n    frameView()->removeWidget(this);\n\n    if (AXObjectCache* cache = document().existingAXObjectCache()) {\n        cache->childrenChanged(this->parent());\n        cache->remove(this);\n    }\n\n    setWidget(0);\n\n    RenderReplaced::willBeDestroyed();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,7 +1,6 @@\n void RenderWidget::willBeDestroyed()\n {\n-    if (RenderView* v = view())\n-        v->removeWidget(this);\n+    frameView()->removeWidget(this);\n \n     if (AXObjectCache* cache = document().existingAXObjectCache()) {\n         cache->childrenChanged(this->parent());",
        "diff_line_info": {
            "deleted_lines": [
                "    if (RenderView* v = view())",
                "        v->removeWidget(this);"
            ],
            "added_lines": [
                "    frameView()->removeWidget(this);"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-6658",
        "func_name": "chromium/RenderWidget::paint",
        "description": "Multiple use-after-free vulnerabilities in the layout implementation in Blink, as used in Google Chrome before 33.0.1750.117, allow remote attackers to cause a denial of service or possibly have unspecified other impact via vectors involving (1) running JavaScript code during execution of the updateWidgetPositions function or (2) making a call into a plugin during execution of the updateWidgetPositions function.",
        "git_url": "https://github.com/chromium/chromium/commit/fe24110c2b904cbeeab1fe15b20bf7fb7b2b6a55",
        "commit_title": "Harden the machinery around updateWidgetPositions()",
        "commit_text": " updateWidgetPositions() can blow away the RenderView by running script or calling into plugins. This patch moves it from RenderView to FrameView since having this method on RenderView which might destroy itself is not safe. It also switches to using normal RefPtr instead of manually managing the refcount and finally adds RefPtr to callers of updateWidgetPositions() to avoid use-after-frees.  There's one final call inside RenderLayerScrollableArea::setScrollOffset which is not safe but is difficult to mitigate since we're way down a callstack by the time this call is made which can destroy the render tree and the RenderLayerScrollableArea. This patch adds a RELEASE_ASSERT to kill the renderer in case we get into a sitaution where this happens. In the future we should detangle this concept entirely so such an ASSERT isn't needed and so that the render tree can never destroy itself from the inside.  It's not clear how to write a test for this since you need to get us to go into the scrolling code with a dirty tree or have a plugin that does something nefarious.   ",
        "func_before": "void RenderWidget::paint(PaintInfo& paintInfo, const LayoutPoint& paintOffset)\n{\n    ANNOTATE_GRAPHICS_CONTEXT(paintInfo, this);\n\n    if (!shouldPaint(paintInfo, paintOffset))\n        return;\n\n    LayoutPoint adjustedPaintOffset = paintOffset + location();\n\n    if (hasBoxDecorations() && (paintInfo.phase == PaintPhaseForeground || paintInfo.phase == PaintPhaseSelection))\n        paintBoxDecorations(paintInfo, adjustedPaintOffset);\n\n    if (paintInfo.phase == PaintPhaseMask) {\n        paintMask(paintInfo, adjustedPaintOffset);\n        return;\n    }\n\n    if ((paintInfo.phase == PaintPhaseOutline || paintInfo.phase == PaintPhaseSelfOutline) && hasOutline())\n        paintOutline(paintInfo, LayoutRect(adjustedPaintOffset, size()));\n\n    if (!m_frameView || paintInfo.phase != PaintPhaseForeground)\n        return;\n\n    if (style()->hasBorderRadius()) {\n        LayoutRect borderRect = LayoutRect(adjustedPaintOffset, size());\n\n        if (borderRect.isEmpty())\n            return;\n\n        // Push a clip if we have a border radius, since we want to round the foreground content that gets painted.\n        paintInfo.context->save();\n        RoundedRect roundedInnerRect = style()->getRoundedInnerBorderFor(borderRect,\n            paddingTop() + borderTop(), paddingBottom() + borderBottom(), paddingLeft() + borderLeft(), paddingRight() + borderRight(), true, true);\n        clipRoundedInnerRect(paintInfo.context, borderRect, roundedInnerRect);\n    }\n\n    if (m_widget)\n        paintContents(paintInfo, paintOffset);\n\n    if (style()->hasBorderRadius())\n        paintInfo.context->restore();\n\n    // Paint a partially transparent wash over selected widgets.\n    if (isSelected() && !document().printing()) {\n        // FIXME: selectionRect() is in absolute, not painting coordinates.\n        paintInfo.context->fillRect(pixelSnappedIntRect(selectionRect()), selectionBackgroundColor());\n    }\n\n    if (canResize())\n        layer()->scrollableArea()->paintResizer(paintInfo.context, roundedIntPoint(adjustedPaintOffset), paintInfo.rect);\n}",
        "func": "void RenderWidget::paint(PaintInfo& paintInfo, const LayoutPoint& paintOffset)\n{\n    ANNOTATE_GRAPHICS_CONTEXT(paintInfo, this);\n\n    if (!shouldPaint(paintInfo, paintOffset))\n        return;\n\n    LayoutPoint adjustedPaintOffset = paintOffset + location();\n\n    if (hasBoxDecorations() && (paintInfo.phase == PaintPhaseForeground || paintInfo.phase == PaintPhaseSelection))\n        paintBoxDecorations(paintInfo, adjustedPaintOffset);\n\n    if (paintInfo.phase == PaintPhaseMask) {\n        paintMask(paintInfo, adjustedPaintOffset);\n        return;\n    }\n\n    if ((paintInfo.phase == PaintPhaseOutline || paintInfo.phase == PaintPhaseSelfOutline) && hasOutline())\n        paintOutline(paintInfo, LayoutRect(adjustedPaintOffset, size()));\n\n    if (paintInfo.phase != PaintPhaseForeground)\n        return;\n\n    if (style()->hasBorderRadius()) {\n        LayoutRect borderRect = LayoutRect(adjustedPaintOffset, size());\n\n        if (borderRect.isEmpty())\n            return;\n\n        // Push a clip if we have a border radius, since we want to round the foreground content that gets painted.\n        paintInfo.context->save();\n        RoundedRect roundedInnerRect = style()->getRoundedInnerBorderFor(borderRect,\n            paddingTop() + borderTop(), paddingBottom() + borderBottom(), paddingLeft() + borderLeft(), paddingRight() + borderRight(), true, true);\n        clipRoundedInnerRect(paintInfo.context, borderRect, roundedInnerRect);\n    }\n\n    if (m_widget)\n        paintContents(paintInfo, paintOffset);\n\n    if (style()->hasBorderRadius())\n        paintInfo.context->restore();\n\n    // Paint a partially transparent wash over selected widgets.\n    if (isSelected() && !document().printing()) {\n        // FIXME: selectionRect() is in absolute, not painting coordinates.\n        paintInfo.context->fillRect(pixelSnappedIntRect(selectionRect()), selectionBackgroundColor());\n    }\n\n    if (canResize())\n        layer()->scrollableArea()->paintResizer(paintInfo.context, roundedIntPoint(adjustedPaintOffset), paintInfo.rect);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -18,7 +18,7 @@\n     if ((paintInfo.phase == PaintPhaseOutline || paintInfo.phase == PaintPhaseSelfOutline) && hasOutline())\n         paintOutline(paintInfo, LayoutRect(adjustedPaintOffset, size()));\n \n-    if (!m_frameView || paintInfo.phase != PaintPhaseForeground)\n+    if (paintInfo.phase != PaintPhaseForeground)\n         return;\n \n     if (style()->hasBorderRadius()) {",
        "diff_line_info": {
            "deleted_lines": [
                "    if (!m_frameView || paintInfo.phase != PaintPhaseForeground)"
            ],
            "added_lines": [
                "    if (paintInfo.phase != PaintPhaseForeground)"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-6658",
        "func_name": "chromium/RenderWidget::setWidget",
        "description": "Multiple use-after-free vulnerabilities in the layout implementation in Blink, as used in Google Chrome before 33.0.1750.117, allow remote attackers to cause a denial of service or possibly have unspecified other impact via vectors involving (1) running JavaScript code during execution of the updateWidgetPositions function or (2) making a call into a plugin during execution of the updateWidgetPositions function.",
        "git_url": "https://github.com/chromium/chromium/commit/fe24110c2b904cbeeab1fe15b20bf7fb7b2b6a55",
        "commit_title": "Harden the machinery around updateWidgetPositions()",
        "commit_text": " updateWidgetPositions() can blow away the RenderView by running script or calling into plugins. This patch moves it from RenderView to FrameView since having this method on RenderView which might destroy itself is not safe. It also switches to using normal RefPtr instead of manually managing the refcount and finally adds RefPtr to callers of updateWidgetPositions() to avoid use-after-frees.  There's one final call inside RenderLayerScrollableArea::setScrollOffset which is not safe but is difficult to mitigate since we're way down a callstack by the time this call is made which can destroy the render tree and the RenderLayerScrollableArea. This patch adds a RELEASE_ASSERT to kill the renderer in case we get into a sitaution where this happens. In the future we should detangle this concept entirely so such an ASSERT isn't needed and so that the render tree can never destroy itself from the inside.  It's not clear how to write a test for this since you need to get us to go into the scrolling code with a dirty tree or have a plugin that does something nefarious.   ",
        "func_before": "void RenderWidget::setWidget(PassRefPtr<Widget> widget)\n{\n    if (widget == m_widget)\n        return;\n\n    if (m_widget) {\n        moveWidgetToParentSoon(m_widget.get(), 0);\n        clearWidget();\n    }\n    m_widget = widget;\n    if (m_widget) {\n        // If we've already received a layout, apply the calculated space to the\n        // widget immediately, but we have to have really been fully constructed (with a non-null\n        // style pointer).\n        if (style()) {\n            if (!needsLayout())\n                updateWidgetGeometry();\n\n            if (style()->visibility() != VISIBLE)\n                m_widget->hide();\n            else {\n                m_widget->show();\n                repaint();\n            }\n        }\n        moveWidgetToParentSoon(m_widget.get(), m_frameView);\n    }\n\n    if (AXObjectCache* cache = document().existingAXObjectCache())\n        cache->childrenChanged(this);\n}",
        "func": "void RenderWidget::setWidget(PassRefPtr<Widget> widget)\n{\n    if (widget == m_widget)\n        return;\n\n    if (m_widget) {\n        moveWidgetToParentSoon(m_widget.get(), 0);\n        clearWidget();\n    }\n    m_widget = widget;\n    if (m_widget) {\n        // If we've already received a layout, apply the calculated space to the\n        // widget immediately, but we have to have really been fully constructed (with a non-null\n        // style pointer).\n        if (style()) {\n            if (!needsLayout())\n                updateWidgetGeometry();\n\n            if (style()->visibility() != VISIBLE)\n                m_widget->hide();\n            else {\n                m_widget->show();\n                repaint();\n            }\n        }\n        moveWidgetToParentSoon(m_widget.get(), frameView());\n    }\n\n    if (AXObjectCache* cache = document().existingAXObjectCache())\n        cache->childrenChanged(this);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -23,7 +23,7 @@\n                 repaint();\n             }\n         }\n-        moveWidgetToParentSoon(m_widget.get(), m_frameView);\n+        moveWidgetToParentSoon(m_widget.get(), frameView());\n     }\n \n     if (AXObjectCache* cache = document().existingAXObjectCache())",
        "diff_line_info": {
            "deleted_lines": [
                "        moveWidgetToParentSoon(m_widget.get(), m_frameView);"
            ],
            "added_lines": [
                "        moveWidgetToParentSoon(m_widget.get(), frameView());"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-6658",
        "func_name": "chromium/WebViewImpl::setFixedLayoutSize",
        "description": "Multiple use-after-free vulnerabilities in the layout implementation in Blink, as used in Google Chrome before 33.0.1750.117, allow remote attackers to cause a denial of service or possibly have unspecified other impact via vectors involving (1) running JavaScript code during execution of the updateWidgetPositions function or (2) making a call into a plugin during execution of the updateWidgetPositions function.",
        "git_url": "https://github.com/chromium/chromium/commit/fe24110c2b904cbeeab1fe15b20bf7fb7b2b6a55",
        "commit_title": "Harden the machinery around updateWidgetPositions()",
        "commit_text": " updateWidgetPositions() can blow away the RenderView by running script or calling into plugins. This patch moves it from RenderView to FrameView since having this method on RenderView which might destroy itself is not safe. It also switches to using normal RefPtr instead of manually managing the refcount and finally adds RefPtr to callers of updateWidgetPositions() to avoid use-after-frees.  There's one final call inside RenderLayerScrollableArea::setScrollOffset which is not safe but is difficult to mitigate since we're way down a callstack by the time this call is made which can destroy the render tree and the RenderLayerScrollableArea. This patch adds a RELEASE_ASSERT to kill the renderer in case we get into a sitaution where this happens. In the future we should detangle this concept entirely so such an ASSERT isn't needed and so that the render tree can never destroy itself from the inside.  It's not clear how to write a test for this since you need to get us to go into the scrolling code with a dirty tree or have a plugin that does something nefarious.   ",
        "func_before": "void WebViewImpl::setFixedLayoutSize(const WebSize& layoutSize)\n{\n    if (!page())\n        return;\n\n    Frame* frame = page()->mainFrame();\n    if (!frame)\n        return;\n\n    FrameView* view = frame->view();\n    if (!view)\n        return;\n\n    m_fixedLayoutSizeLock = layoutSize.width || layoutSize.height;\n\n    if (m_fixedLayoutSizeLock)\n        view->setLayoutSize(layoutSize);\n    else\n        updateMainFrameLayoutSize();\n}",
        "func": "void WebViewImpl::setFixedLayoutSize(const WebSize& layoutSize)\n{\n    if (!page())\n        return;\n\n    Frame* frame = page()->mainFrame();\n    if (!frame)\n        return;\n\n    RefPtr<FrameView> view = frame->view();\n    if (!view)\n        return;\n\n    m_fixedLayoutSizeLock = layoutSize.width || layoutSize.height;\n\n    if (m_fixedLayoutSizeLock)\n        view->setLayoutSize(layoutSize);\n    else\n        updateMainFrameLayoutSize();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -7,7 +7,7 @@\n     if (!frame)\n         return;\n \n-    FrameView* view = frame->view();\n+    RefPtr<FrameView> view = frame->view();\n     if (!view)\n         return;\n ",
        "diff_line_info": {
            "deleted_lines": [
                "    FrameView* view = frame->view();"
            ],
            "added_lines": [
                "    RefPtr<FrameView> view = frame->view();"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-6658",
        "func_name": "chromium/WebViewImpl::updateMainFrameLayoutSize",
        "description": "Multiple use-after-free vulnerabilities in the layout implementation in Blink, as used in Google Chrome before 33.0.1750.117, allow remote attackers to cause a denial of service or possibly have unspecified other impact via vectors involving (1) running JavaScript code during execution of the updateWidgetPositions function or (2) making a call into a plugin during execution of the updateWidgetPositions function.",
        "git_url": "https://github.com/chromium/chromium/commit/fe24110c2b904cbeeab1fe15b20bf7fb7b2b6a55",
        "commit_title": "Harden the machinery around updateWidgetPositions()",
        "commit_text": " updateWidgetPositions() can blow away the RenderView by running script or calling into plugins. This patch moves it from RenderView to FrameView since having this method on RenderView which might destroy itself is not safe. It also switches to using normal RefPtr instead of manually managing the refcount and finally adds RefPtr to callers of updateWidgetPositions() to avoid use-after-frees.  There's one final call inside RenderLayerScrollableArea::setScrollOffset which is not safe but is difficult to mitigate since we're way down a callstack by the time this call is made which can destroy the render tree and the RenderLayerScrollableArea. This patch adds a RELEASE_ASSERT to kill the renderer in case we get into a sitaution where this happens. In the future we should detangle this concept entirely so such an ASSERT isn't needed and so that the render tree can never destroy itself from the inside.  It's not clear how to write a test for this since you need to get us to go into the scrolling code with a dirty tree or have a plugin that does something nefarious.   ",
        "func_before": "void WebViewImpl::updateMainFrameLayoutSize()\n{\n    if (m_fixedLayoutSizeLock || !mainFrameImpl())\n        return;\n\n    FrameView* view = mainFrameImpl()->frameView();\n    if (!view)\n        return;\n\n    WebSize layoutSize = m_size;\n\n    if (settings()->viewportEnabled()) {\n        layoutSize = flooredIntSize(m_pageScaleConstraintsSet.pageDefinedConstraints().layoutSize);\n\n        if (page()->settings().textAutosizingEnabled() && layoutSize.width != view->layoutSize().width()) {\n            TextAutosizer* textAutosizer = page()->mainFrame()->document()->textAutosizer();\n            if (textAutosizer)\n                textAutosizer->recalculateMultipliers();\n        }\n    }\n\n    view->setLayoutSize(layoutSize);\n}",
        "func": "void WebViewImpl::updateMainFrameLayoutSize()\n{\n    if (m_fixedLayoutSizeLock || !mainFrameImpl())\n        return;\n\n    RefPtr<FrameView> view = mainFrameImpl()->frameView();\n    if (!view)\n        return;\n\n    WebSize layoutSize = m_size;\n\n    if (settings()->viewportEnabled()) {\n        layoutSize = flooredIntSize(m_pageScaleConstraintsSet.pageDefinedConstraints().layoutSize);\n\n        if (page()->settings().textAutosizingEnabled() && layoutSize.width != view->layoutSize().width()) {\n            TextAutosizer* textAutosizer = page()->mainFrame()->document()->textAutosizer();\n            if (textAutosizer)\n                textAutosizer->recalculateMultipliers();\n        }\n    }\n\n    view->setLayoutSize(layoutSize);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,7 +3,7 @@\n     if (m_fixedLayoutSizeLock || !mainFrameImpl())\n         return;\n \n-    FrameView* view = mainFrameImpl()->frameView();\n+    RefPtr<FrameView> view = mainFrameImpl()->frameView();\n     if (!view)\n         return;\n ",
        "diff_line_info": {
            "deleted_lines": [
                "    FrameView* view = mainFrameImpl()->frameView();"
            ],
            "added_lines": [
                "    RefPtr<FrameView> view = mainFrameImpl()->frameView();"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-1700",
        "func_name": "chromium/SpeechSynthesis::SpeechSynthesis",
        "description": "Use-after-free vulnerability in modules/speech/SpeechSynthesis.cpp in Blink, as used in Google Chrome before 33.0.1750.149, allows remote attackers to cause a denial of service or possibly have unspecified other impact by leveraging improper handling of a certain utterance data structure.",
        "git_url": "https://github.com/chromium/chromium/commit/5df5039760b6827f83f500b5040ae78654178c54",
        "commit_title": "Fix use-after-free of m_currentSpeechUtterance.",
        "commit_text": " SpeechSynthesis.cpp incorrectly assumed that calling m_platformSpeechSynthesizer->cancel() would immediately call didFinishSpeaking or speakingErrorOccurred, which would null out m_currentSpeechUtterance. This assumption was true in WebKit/Mac, but Chromium's platform implementation is asynchronous, so that call may come later.  Fix the issue and simplify the logic by getting rid of the raw pointer to the current utterance altogether. Now the RefPtr at the front of the utterance queue is the current utterance, and the platform implementation is allowed to fire events on utterances that are no longer in the queue.   ",
        "func_before": "SpeechSynthesis::SpeechSynthesis(ExecutionContext* context)\n    : ContextLifecycleObserver(context)\n    , m_platformSpeechSynthesizer(PlatformSpeechSynthesizer::create(this))\n    , m_currentSpeechUtterance(nullptr)\n    , m_isPaused(false)\n{\n    ScriptWrappable::init(this);\n}",
        "func": "SpeechSynthesis::SpeechSynthesis(ExecutionContext* context)\n    : ContextLifecycleObserver(context)\n    , m_platformSpeechSynthesizer(PlatformSpeechSynthesizer::create(this))\n    , m_isPaused(false)\n{\n    ScriptWrappable::init(this);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,7 +1,6 @@\n SpeechSynthesis::SpeechSynthesis(ExecutionContext* context)\n     : ContextLifecycleObserver(context)\n     , m_platformSpeechSynthesizer(PlatformSpeechSynthesizer::create(this))\n-    , m_currentSpeechUtterance(nullptr)\n     , m_isPaused(false)\n {\n     ScriptWrappable::init(this);",
        "diff_line_info": {
            "deleted_lines": [
                "    , m_currentSpeechUtterance(nullptr)"
            ],
            "added_lines": []
        }
    },
    {
        "cve_id": "CVE-2014-1700",
        "func_name": "chromium/SpeechSynthesis::speaking",
        "description": "Use-after-free vulnerability in modules/speech/SpeechSynthesis.cpp in Blink, as used in Google Chrome before 33.0.1750.149, allows remote attackers to cause a denial of service or possibly have unspecified other impact by leveraging improper handling of a certain utterance data structure.",
        "git_url": "https://github.com/chromium/chromium/commit/5df5039760b6827f83f500b5040ae78654178c54",
        "commit_title": "Fix use-after-free of m_currentSpeechUtterance.",
        "commit_text": " SpeechSynthesis.cpp incorrectly assumed that calling m_platformSpeechSynthesizer->cancel() would immediately call didFinishSpeaking or speakingErrorOccurred, which would null out m_currentSpeechUtterance. This assumption was true in WebKit/Mac, but Chromium's platform implementation is asynchronous, so that call may come later.  Fix the issue and simplify the logic by getting rid of the raw pointer to the current utterance altogether. Now the RefPtr at the front of the utterance queue is the current utterance, and the platform implementation is allowed to fire events on utterances that are no longer in the queue.   ",
        "func_before": "bool SpeechSynthesis::speaking() const\n{\n    // If we have a current speech utterance, then that means we're assumed to be in a speaking state.\n    // This state is independent of whether the utterance happens to be paused.\n    return m_currentSpeechUtterance;\n}",
        "func": "bool SpeechSynthesis::speaking() const\n{\n    // If we have a current speech utterance, then that means we're assumed to be in a speaking state.\n    // This state is independent of whether the utterance happens to be paused.\n    return currentSpeechUtterance();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,5 +2,5 @@\n {\n     // If we have a current speech utterance, then that means we're assumed to be in a speaking state.\n     // This state is independent of whether the utterance happens to be paused.\n-    return m_currentSpeechUtterance;\n+    return currentSpeechUtterance();\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    return m_currentSpeechUtterance;"
            ],
            "added_lines": [
                "    return currentSpeechUtterance();"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-1700",
        "func_name": "chromium/SpeechSynthesis::startSpeakingImmediately",
        "description": "Use-after-free vulnerability in modules/speech/SpeechSynthesis.cpp in Blink, as used in Google Chrome before 33.0.1750.149, allows remote attackers to cause a denial of service or possibly have unspecified other impact by leveraging improper handling of a certain utterance data structure.",
        "git_url": "https://github.com/chromium/chromium/commit/5df5039760b6827f83f500b5040ae78654178c54",
        "commit_title": "Fix use-after-free of m_currentSpeechUtterance.",
        "commit_text": " SpeechSynthesis.cpp incorrectly assumed that calling m_platformSpeechSynthesizer->cancel() would immediately call didFinishSpeaking or speakingErrorOccurred, which would null out m_currentSpeechUtterance. This assumption was true in WebKit/Mac, but Chromium's platform implementation is asynchronous, so that call may come later.  Fix the issue and simplify the logic by getting rid of the raw pointer to the current utterance altogether. Now the RefPtr at the front of the utterance queue is the current utterance, and the platform implementation is allowed to fire events on utterances that are no longer in the queue.   ",
        "func_before": "void SpeechSynthesis::startSpeakingImmediately(SpeechSynthesisUtterance* utterance)\n{\n    ASSERT(!m_currentSpeechUtterance);\n    utterance->setStartTime(monotonicallyIncreasingTime());\n    m_currentSpeechUtterance = utterance;\n    m_isPaused = false;\n    m_platformSpeechSynthesizer->speak(utterance->platformUtterance());\n}",
        "func": "void SpeechSynthesis::startSpeakingImmediately()\n{\n    SpeechSynthesisUtterance* utterance = currentSpeechUtterance();\n    ASSERT(utterance);\n\n    utterance->setStartTime(monotonicallyIncreasingTime());\n    m_isPaused = false;\n    m_platformSpeechSynthesizer->speak(utterance->platformUtterance());\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,8 +1,9 @@\n-void SpeechSynthesis::startSpeakingImmediately(SpeechSynthesisUtterance* utterance)\n+void SpeechSynthesis::startSpeakingImmediately()\n {\n-    ASSERT(!m_currentSpeechUtterance);\n+    SpeechSynthesisUtterance* utterance = currentSpeechUtterance();\n+    ASSERT(utterance);\n+\n     utterance->setStartTime(monotonicallyIncreasingTime());\n-    m_currentSpeechUtterance = utterance;\n     m_isPaused = false;\n     m_platformSpeechSynthesizer->speak(utterance->platformUtterance());\n }",
        "diff_line_info": {
            "deleted_lines": [
                "void SpeechSynthesis::startSpeakingImmediately(SpeechSynthesisUtterance* utterance)",
                "    ASSERT(!m_currentSpeechUtterance);",
                "    m_currentSpeechUtterance = utterance;"
            ],
            "added_lines": [
                "void SpeechSynthesis::startSpeakingImmediately()",
                "    SpeechSynthesisUtterance* utterance = currentSpeechUtterance();",
                "    ASSERT(utterance);",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2014-1700",
        "func_name": "chromium/SpeechSynthesis::boundaryEventOccurred",
        "description": "Use-after-free vulnerability in modules/speech/SpeechSynthesis.cpp in Blink, as used in Google Chrome before 33.0.1750.149, allows remote attackers to cause a denial of service or possibly have unspecified other impact by leveraging improper handling of a certain utterance data structure.",
        "git_url": "https://github.com/chromium/chromium/commit/5df5039760b6827f83f500b5040ae78654178c54",
        "commit_title": "Fix use-after-free of m_currentSpeechUtterance.",
        "commit_text": " SpeechSynthesis.cpp incorrectly assumed that calling m_platformSpeechSynthesizer->cancel() would immediately call didFinishSpeaking or speakingErrorOccurred, which would null out m_currentSpeechUtterance. This assumption was true in WebKit/Mac, but Chromium's platform implementation is asynchronous, so that call may come later.  Fix the issue and simplify the logic by getting rid of the raw pointer to the current utterance altogether. Now the RefPtr at the front of the utterance queue is the current utterance, and the platform implementation is allowed to fire events on utterances that are no longer in the queue.   ",
        "func_before": "void SpeechSynthesis::boundaryEventOccurred(PassRefPtr<PlatformSpeechSynthesisUtterance> utterance, SpeechBoundary boundary, unsigned charIndex)\n{\n    DEFINE_STATIC_LOCAL(const String, wordBoundaryString, (\"word\"));\n    DEFINE_STATIC_LOCAL(const String, sentenceBoundaryString, (\"sentence\"));\n\n    switch (boundary) {\n    case SpeechWordBoundary:\n        fireEvent(EventTypeNames::boundary, static_cast<SpeechSynthesisUtterance*>(utterance->client()), charIndex, wordBoundaryString);\n        break;\n    case SpeechSentenceBoundary:\n        fireEvent(EventTypeNames::boundary, static_cast<SpeechSynthesisUtterance*>(utterance->client()), charIndex, sentenceBoundaryString);\n        break;\n    default:\n        ASSERT_NOT_REACHED();\n    }\n}\n\nvoid SpeechSynthesis::didStartSpeaking(PassRefPtr<PlatformSpeechSynthesisUtterance> utterance)\n{\n    if (utterance->client())\n        fireEvent(EventTypeNames::start, static_cast<SpeechSynthesisUtterance*>(utterance->client()), 0, String());\n}\n\nvoid SpeechSynthesis::didPauseSpeaking(PassRefPtr<PlatformSpeechSynthesisUtterance> utterance)\n{\n    m_isPaused = true;\n    if (utterance->client())\n        fireEvent(EventTypeNames::pause, static_cast<SpeechSynthesisUtterance*>(utterance->client()), 0, String());\n}\n\nvoid SpeechSynthesis::didResumeSpeaking(PassRefPtr<PlatformSpeechSynthesisUtterance> utterance)\n{\n    m_isPaused = false;\n    if (utterance->client())\n        fireEvent(EventTypeNames::resume, static_cast<SpeechSynthesisUtterance*>(utterance->client()), 0, String());\n}\n\nvoid SpeechSynthesis::didFinishSpeaking(PassRefPtr<PlatformSpeechSynthesisUtterance> utterance)\n{\n    if (utterance->client())\n        handleSpeakingCompleted(static_cast<SpeechSynthesisUtterance*>(utterance->client()), false);\n}\n\nvoid SpeechSynthesis::speakingErrorOccurred(PassRefPtr<PlatformSpeechSynthesisUtterance> utterance)\n{\n    if (utterance->client())\n        handleSpeakingCompleted(static_cast<SpeechSynthesisUtterance*>(utterance->client()), true);\n}\n\nconst AtomicString& SpeechSynthesis::interfaceName() const\n{\n    return EventTargetNames::SpeechSynthesisUtterance;\n}\n\nvoid SpeechSynthesis::trace(Visitor* visitor)\n{\n    visitor->trace(m_voiceList);\n    visitor->trace(m_currentSpeechUtterance);\n    visitor->trace(m_utteranceQueue);\n}\n\n}",
        "func": "void SpeechSynthesis::boundaryEventOccurred(PassRefPtr<PlatformSpeechSynthesisUtterance> utterance, SpeechBoundary boundary, unsigned charIndex)\n{\n    DEFINE_STATIC_LOCAL(const String, wordBoundaryString, (\"word\"));\n    DEFINE_STATIC_LOCAL(const String, sentenceBoundaryString, (\"sentence\"));\n\n    switch (boundary) {\n    case SpeechWordBoundary:\n        fireEvent(EventTypeNames::boundary, static_cast<SpeechSynthesisUtterance*>(utterance->client()), charIndex, wordBoundaryString);\n        break;\n    case SpeechSentenceBoundary:\n        fireEvent(EventTypeNames::boundary, static_cast<SpeechSynthesisUtterance*>(utterance->client()), charIndex, sentenceBoundaryString);\n        break;\n    default:\n        ASSERT_NOT_REACHED();\n    }\n}\n\nvoid SpeechSynthesis::didStartSpeaking(PassRefPtr<PlatformSpeechSynthesisUtterance> utterance)\n{\n    if (utterance->client())\n        fireEvent(EventTypeNames::start, static_cast<SpeechSynthesisUtterance*>(utterance->client()), 0, String());\n}\n\nvoid SpeechSynthesis::didPauseSpeaking(PassRefPtr<PlatformSpeechSynthesisUtterance> utterance)\n{\n    m_isPaused = true;\n    if (utterance->client())\n        fireEvent(EventTypeNames::pause, static_cast<SpeechSynthesisUtterance*>(utterance->client()), 0, String());\n}\n\nvoid SpeechSynthesis::didResumeSpeaking(PassRefPtr<PlatformSpeechSynthesisUtterance> utterance)\n{\n    m_isPaused = false;\n    if (utterance->client())\n        fireEvent(EventTypeNames::resume, static_cast<SpeechSynthesisUtterance*>(utterance->client()), 0, String());\n}\n\nvoid SpeechSynthesis::didFinishSpeaking(PassRefPtr<PlatformSpeechSynthesisUtterance> utterance)\n{\n    if (utterance->client())\n        handleSpeakingCompleted(static_cast<SpeechSynthesisUtterance*>(utterance->client()), false);\n}\n\nvoid SpeechSynthesis::speakingErrorOccurred(PassRefPtr<PlatformSpeechSynthesisUtterance> utterance)\n{\n    if (utterance->client())\n        handleSpeakingCompleted(static_cast<SpeechSynthesisUtterance*>(utterance->client()), true);\n}\n\nSpeechSynthesisUtterance* SpeechSynthesis::currentSpeechUtterance() const\n{\n    if (!m_utteranceQueue.isEmpty())\n        return m_utteranceQueue.first().get();\n    return nullptr;\n}\n\nconst AtomicString& SpeechSynthesis::interfaceName() const\n{\n    return EventTargetNames::SpeechSynthesisUtterance;\n}\n\nvoid SpeechSynthesis::trace(Visitor* visitor)\n{\n    visitor->trace(m_voiceList);\n    visitor->trace(m_utteranceQueue);\n}\n\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -47,6 +47,13 @@\n         handleSpeakingCompleted(static_cast<SpeechSynthesisUtterance*>(utterance->client()), true);\n }\n \n+SpeechSynthesisUtterance* SpeechSynthesis::currentSpeechUtterance() const\n+{\n+    if (!m_utteranceQueue.isEmpty())\n+        return m_utteranceQueue.first().get();\n+    return nullptr;\n+}\n+\n const AtomicString& SpeechSynthesis::interfaceName() const\n {\n     return EventTargetNames::SpeechSynthesisUtterance;\n@@ -55,7 +62,6 @@\n void SpeechSynthesis::trace(Visitor* visitor)\n {\n     visitor->trace(m_voiceList);\n-    visitor->trace(m_currentSpeechUtterance);\n     visitor->trace(m_utteranceQueue);\n }\n ",
        "diff_line_info": {
            "deleted_lines": [
                "    visitor->trace(m_currentSpeechUtterance);"
            ],
            "added_lines": [
                "SpeechSynthesisUtterance* SpeechSynthesis::currentSpeechUtterance() const",
                "{",
                "    if (!m_utteranceQueue.isEmpty())",
                "        return m_utteranceQueue.first().get();",
                "    return nullptr;",
                "}",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2014-1700",
        "func_name": "chromium/SpeechSynthesis::cancel",
        "description": "Use-after-free vulnerability in modules/speech/SpeechSynthesis.cpp in Blink, as used in Google Chrome before 33.0.1750.149, allows remote attackers to cause a denial of service or possibly have unspecified other impact by leveraging improper handling of a certain utterance data structure.",
        "git_url": "https://github.com/chromium/chromium/commit/5df5039760b6827f83f500b5040ae78654178c54",
        "commit_title": "Fix use-after-free of m_currentSpeechUtterance.",
        "commit_text": " SpeechSynthesis.cpp incorrectly assumed that calling m_platformSpeechSynthesizer->cancel() would immediately call didFinishSpeaking or speakingErrorOccurred, which would null out m_currentSpeechUtterance. This assumption was true in WebKit/Mac, but Chromium's platform implementation is asynchronous, so that call may come later.  Fix the issue and simplify the logic by getting rid of the raw pointer to the current utterance altogether. Now the RefPtr at the front of the utterance queue is the current utterance, and the platform implementation is allowed to fire events on utterances that are no longer in the queue.   ",
        "func_before": "void SpeechSynthesis::cancel()\n{\n    // Remove all the items from the utterance queue.\n    // Hold on to the current utterance so the platform synthesizer can have a chance to clean up.\n    RefPtrWillBeMember<SpeechSynthesisUtterance> current = m_currentSpeechUtterance;\n    m_utteranceQueue.clear();\n    m_platformSpeechSynthesizer->cancel();\n    current = nullptr;\n\n    // The platform should have called back immediately and cleared the current utterance.\n    ASSERT(!m_currentSpeechUtterance);\n}",
        "func": "void SpeechSynthesis::cancel()\n{\n    // Remove all the items from the utterance queue. The platform\n    // may still have references to some of these utterances and may\n    // fire events on them asynchronously.\n    m_utteranceQueue.clear();\n    m_platformSpeechSynthesizer->cancel();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,12 +1,8 @@\n void SpeechSynthesis::cancel()\n {\n-    // Remove all the items from the utterance queue.\n-    // Hold on to the current utterance so the platform synthesizer can have a chance to clean up.\n-    RefPtrWillBeMember<SpeechSynthesisUtterance> current = m_currentSpeechUtterance;\n+    // Remove all the items from the utterance queue. The platform\n+    // may still have references to some of these utterances and may\n+    // fire events on them asynchronously.\n     m_utteranceQueue.clear();\n     m_platformSpeechSynthesizer->cancel();\n-    current = nullptr;\n-\n-    // The platform should have called back immediately and cleared the current utterance.\n-    ASSERT(!m_currentSpeechUtterance);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    // Remove all the items from the utterance queue.",
                "    // Hold on to the current utterance so the platform synthesizer can have a chance to clean up.",
                "    RefPtrWillBeMember<SpeechSynthesisUtterance> current = m_currentSpeechUtterance;",
                "    current = nullptr;",
                "",
                "    // The platform should have called back immediately and cleared the current utterance.",
                "    ASSERT(!m_currentSpeechUtterance);"
            ],
            "added_lines": [
                "    // Remove all the items from the utterance queue. The platform",
                "    // may still have references to some of these utterances and may",
                "    // fire events on them asynchronously."
            ]
        }
    },
    {
        "cve_id": "CVE-2014-1700",
        "func_name": "chromium/SpeechSynthesis::handleSpeakingCompleted",
        "description": "Use-after-free vulnerability in modules/speech/SpeechSynthesis.cpp in Blink, as used in Google Chrome before 33.0.1750.149, allows remote attackers to cause a denial of service or possibly have unspecified other impact by leveraging improper handling of a certain utterance data structure.",
        "git_url": "https://github.com/chromium/chromium/commit/5df5039760b6827f83f500b5040ae78654178c54",
        "commit_title": "Fix use-after-free of m_currentSpeechUtterance.",
        "commit_text": " SpeechSynthesis.cpp incorrectly assumed that calling m_platformSpeechSynthesizer->cancel() would immediately call didFinishSpeaking or speakingErrorOccurred, which would null out m_currentSpeechUtterance. This assumption was true in WebKit/Mac, but Chromium's platform implementation is asynchronous, so that call may come later.  Fix the issue and simplify the logic by getting rid of the raw pointer to the current utterance altogether. Now the RefPtr at the front of the utterance queue is the current utterance, and the platform implementation is allowed to fire events on utterances that are no longer in the queue.   ",
        "func_before": "void SpeechSynthesis::handleSpeakingCompleted(SpeechSynthesisUtterance* utterance, bool errorOccurred)\n{\n    ASSERT(utterance);\n    ASSERT(m_currentSpeechUtterance);\n    m_currentSpeechUtterance = nullptr;\n\n    fireEvent(errorOccurred ? EventTypeNames::error : EventTypeNames::end, utterance, 0, String());\n\n    if (m_utteranceQueue.size()) {\n        RefPtrWillBeMember<SpeechSynthesisUtterance> firstUtterance = m_utteranceQueue.first();\n        ASSERT(firstUtterance == utterance);\n        if (firstUtterance == utterance)\n            m_utteranceQueue.removeFirst();\n\n        // Start the next job if there is one pending.\n        if (!m_utteranceQueue.isEmpty())\n            startSpeakingImmediately(m_utteranceQueue.first().get());\n    }\n}",
        "func": "void SpeechSynthesis::handleSpeakingCompleted(SpeechSynthesisUtterance* utterance, bool errorOccurred)\n{\n    ASSERT(utterance);\n\n    bool didJustFinishCurrentUtterance = false;\n    // If the utterance that completed was the one we're currently speaking,\n    // remove it from the queue and start speaking the next one.\n    if (utterance == currentSpeechUtterance()) {\n        m_utteranceQueue.removeFirst();\n        didJustFinishCurrentUtterance = true;\n    }\n\n    // Always fire the event, because the platform may have asynchronously\n    // sent an event on an utterance before it got the message that we\n    // canceled it, and we should always report to the user what actually\n    // happened.\n    fireEvent(errorOccurred ? EventTypeNames::error : EventTypeNames::end, utterance, 0, String());\n\n    // Start the next utterance if we just finished one and one was pending.\n    if (didJustFinishCurrentUtterance && !m_utteranceQueue.isEmpty())\n        startSpeakingImmediately();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,19 +1,22 @@\n void SpeechSynthesis::handleSpeakingCompleted(SpeechSynthesisUtterance* utterance, bool errorOccurred)\n {\n     ASSERT(utterance);\n-    ASSERT(m_currentSpeechUtterance);\n-    m_currentSpeechUtterance = nullptr;\n \n+    bool didJustFinishCurrentUtterance = false;\n+    // If the utterance that completed was the one we're currently speaking,\n+    // remove it from the queue and start speaking the next one.\n+    if (utterance == currentSpeechUtterance()) {\n+        m_utteranceQueue.removeFirst();\n+        didJustFinishCurrentUtterance = true;\n+    }\n+\n+    // Always fire the event, because the platform may have asynchronously\n+    // sent an event on an utterance before it got the message that we\n+    // canceled it, and we should always report to the user what actually\n+    // happened.\n     fireEvent(errorOccurred ? EventTypeNames::error : EventTypeNames::end, utterance, 0, String());\n \n-    if (m_utteranceQueue.size()) {\n-        RefPtrWillBeMember<SpeechSynthesisUtterance> firstUtterance = m_utteranceQueue.first();\n-        ASSERT(firstUtterance == utterance);\n-        if (firstUtterance == utterance)\n-            m_utteranceQueue.removeFirst();\n-\n-        // Start the next job if there is one pending.\n-        if (!m_utteranceQueue.isEmpty())\n-            startSpeakingImmediately(m_utteranceQueue.first().get());\n-    }\n+    // Start the next utterance if we just finished one and one was pending.\n+    if (didJustFinishCurrentUtterance && !m_utteranceQueue.isEmpty())\n+        startSpeakingImmediately();\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    ASSERT(m_currentSpeechUtterance);",
                "    m_currentSpeechUtterance = nullptr;",
                "    if (m_utteranceQueue.size()) {",
                "        RefPtrWillBeMember<SpeechSynthesisUtterance> firstUtterance = m_utteranceQueue.first();",
                "        ASSERT(firstUtterance == utterance);",
                "        if (firstUtterance == utterance)",
                "            m_utteranceQueue.removeFirst();",
                "",
                "        // Start the next job if there is one pending.",
                "        if (!m_utteranceQueue.isEmpty())",
                "            startSpeakingImmediately(m_utteranceQueue.first().get());",
                "    }"
            ],
            "added_lines": [
                "    bool didJustFinishCurrentUtterance = false;",
                "    // If the utterance that completed was the one we're currently speaking,",
                "    // remove it from the queue and start speaking the next one.",
                "    if (utterance == currentSpeechUtterance()) {",
                "        m_utteranceQueue.removeFirst();",
                "        didJustFinishCurrentUtterance = true;",
                "    }",
                "",
                "    // Always fire the event, because the platform may have asynchronously",
                "    // sent an event on an utterance before it got the message that we",
                "    // canceled it, and we should always report to the user what actually",
                "    // happened.",
                "    // Start the next utterance if we just finished one and one was pending.",
                "    if (didJustFinishCurrentUtterance && !m_utteranceQueue.isEmpty())",
                "        startSpeakingImmediately();"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-1700",
        "func_name": "chromium/SpeechSynthesis::speak",
        "description": "Use-after-free vulnerability in modules/speech/SpeechSynthesis.cpp in Blink, as used in Google Chrome before 33.0.1750.149, allows remote attackers to cause a denial of service or possibly have unspecified other impact by leveraging improper handling of a certain utterance data structure.",
        "git_url": "https://github.com/chromium/chromium/commit/5df5039760b6827f83f500b5040ae78654178c54",
        "commit_title": "Fix use-after-free of m_currentSpeechUtterance.",
        "commit_text": " SpeechSynthesis.cpp incorrectly assumed that calling m_platformSpeechSynthesizer->cancel() would immediately call didFinishSpeaking or speakingErrorOccurred, which would null out m_currentSpeechUtterance. This assumption was true in WebKit/Mac, but Chromium's platform implementation is asynchronous, so that call may come later.  Fix the issue and simplify the logic by getting rid of the raw pointer to the current utterance altogether. Now the RefPtr at the front of the utterance queue is the current utterance, and the platform implementation is allowed to fire events on utterances that are no longer in the queue.   ",
        "func_before": "void SpeechSynthesis::speak(SpeechSynthesisUtterance* utterance, ExceptionState& exceptionState)\n{\n    if (!utterance) {\n        exceptionState.throwTypeError(\"Invalid utterance argument\");\n        return;\n    }\n\n    m_utteranceQueue.append(utterance);\n\n    // If the queue was empty, speak this immediately and add it to the queue.\n    if (m_utteranceQueue.size() == 1)\n        startSpeakingImmediately(utterance);\n}",
        "func": "void SpeechSynthesis::speak(SpeechSynthesisUtterance* utterance, ExceptionState& exceptionState)\n{\n    if (!utterance) {\n        exceptionState.throwTypeError(\"Invalid utterance argument\");\n        return;\n    }\n\n    m_utteranceQueue.append(utterance);\n\n    // If the queue was empty, speak this immediately.\n    if (m_utteranceQueue.size() == 1)\n        startSpeakingImmediately();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -7,7 +7,7 @@\n \n     m_utteranceQueue.append(utterance);\n \n-    // If the queue was empty, speak this immediately and add it to the queue.\n+    // If the queue was empty, speak this immediately.\n     if (m_utteranceQueue.size() == 1)\n-        startSpeakingImmediately(utterance);\n+        startSpeakingImmediately();\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    // If the queue was empty, speak this immediately and add it to the queue.",
                "        startSpeakingImmediately(utterance);"
            ],
            "added_lines": [
                "    // If the queue was empty, speak this immediately.",
                "        startSpeakingImmediately();"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-1700",
        "func_name": "chromium/SpeechSynthesis::resume",
        "description": "Use-after-free vulnerability in modules/speech/SpeechSynthesis.cpp in Blink, as used in Google Chrome before 33.0.1750.149, allows remote attackers to cause a denial of service or possibly have unspecified other impact by leveraging improper handling of a certain utterance data structure.",
        "git_url": "https://github.com/chromium/chromium/commit/5df5039760b6827f83f500b5040ae78654178c54",
        "commit_title": "Fix use-after-free of m_currentSpeechUtterance.",
        "commit_text": " SpeechSynthesis.cpp incorrectly assumed that calling m_platformSpeechSynthesizer->cancel() would immediately call didFinishSpeaking or speakingErrorOccurred, which would null out m_currentSpeechUtterance. This assumption was true in WebKit/Mac, but Chromium's platform implementation is asynchronous, so that call may come later.  Fix the issue and simplify the logic by getting rid of the raw pointer to the current utterance altogether. Now the RefPtr at the front of the utterance queue is the current utterance, and the platform implementation is allowed to fire events on utterances that are no longer in the queue.   ",
        "func_before": "void SpeechSynthesis::resume()\n{\n    if (!m_currentSpeechUtterance)\n        return;\n    m_platformSpeechSynthesizer->resume();\n}",
        "func": "void SpeechSynthesis::resume()\n{\n    if (!currentSpeechUtterance())\n        return;\n    m_platformSpeechSynthesizer->resume();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,6 @@\n void SpeechSynthesis::resume()\n {\n-    if (!m_currentSpeechUtterance)\n+    if (!currentSpeechUtterance())\n         return;\n     m_platformSpeechSynthesizer->resume();\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    if (!m_currentSpeechUtterance)"
            ],
            "added_lines": [
                "    if (!currentSpeechUtterance())"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-1702",
        "func_name": "chromium/DatabaseThread::cleanupDatabaseThread",
        "description": "Use-after-free vulnerability in the DatabaseThread::cleanupDatabaseThread function in modules/webdatabase/DatabaseThread.cpp in the web database implementation in Blink, as used in Google Chrome before 33.0.1750.149, allows remote attackers to cause a denial of service or possibly have unspecified other impact by leveraging improper handling of scheduled tasks during shutdown of a thread.",
        "git_url": "https://github.com/chromium/chromium/commit/e6e535be7e2d398058f1292f026e07252b3cd214",
        "commit_title": "Ensure that scheduled tasks are executed during db thread shutdown",
        "commit_text": " Since closing the databases on the database thread can schedule new cleanup tasks, we need to postTask the notificatino that we're done.   ",
        "func_before": "void DatabaseThread::cleanupDatabaseThread()\n{\n    WTF_LOG(StorageAPI, \"Cleaning up DatabaseThread %p\", this);\n\n    // Clean up the list of all pending transactions on this database thread\n    m_transactionCoordinator->shutdown();\n\n    // Close the databases that we ran transactions on. This ensures that if any transactions are still open, they are rolled back and we don't leave the database in an\n    // inconsistent or locked state.\n    if (m_openDatabaseSet.size() > 0) {\n        // As the call to close will modify the original set, we must take a copy to iterate over.\n        DatabaseSet openSetCopy;\n        openSetCopy.swap(m_openDatabaseSet);\n        DatabaseSet::iterator end = openSetCopy.end();\n        for (DatabaseSet::iterator it = openSetCopy.begin(); it != end; ++it)\n            (*it).get()->close();\n    }\n\n    if (m_cleanupSync) // Someone wanted to know when we were done cleaning up.\n        m_cleanupSync->taskCompleted();\n}",
        "func": "void DatabaseThread::cleanupDatabaseThread()\n{\n    WTF_LOG(StorageAPI, \"Cleaning up DatabaseThread %p\", this);\n\n    // Clean up the list of all pending transactions on this database thread\n    m_transactionCoordinator->shutdown();\n\n    // Close the databases that we ran transactions on. This ensures that if any transactions are still open, they are rolled back and we don't leave the database in an\n    // inconsistent or locked state.\n    if (m_openDatabaseSet.size() > 0) {\n        // As the call to close will modify the original set, we must take a copy to iterate over.\n        DatabaseSet openSetCopy;\n        openSetCopy.swap(m_openDatabaseSet);\n        DatabaseSet::iterator end = openSetCopy.end();\n        for (DatabaseSet::iterator it = openSetCopy.begin(); it != end; ++it)\n            (*it).get()->close();\n    }\n\n    if (m_cleanupSync) // Someone wanted to know when we were done cleaning up.\n        m_thread->postTask(new Task(WTF::bind(&DatabaseTaskSynchronizer::taskCompleted, m_cleanupSync)));\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -17,5 +17,5 @@\n     }\n \n     if (m_cleanupSync) // Someone wanted to know when we were done cleaning up.\n-        m_cleanupSync->taskCompleted();\n+        m_thread->postTask(new Task(WTF::bind(&DatabaseTaskSynchronizer::taskCompleted, m_cleanupSync)));\n }",
        "diff_line_info": {
            "deleted_lines": [
                "        m_cleanupSync->taskCompleted();"
            ],
            "added_lines": [
                "        m_thread->postTask(new Task(WTF::bind(&DatabaseTaskSynchronizer::taskCompleted, m_cleanupSync)));"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-1703",
        "func_name": "chromium/WebSocketDispatcherHost::SendOrDrop",
        "description": "Use-after-free vulnerability in the WebSocketDispatcherHost::SendOrDrop function in content/browser/renderer_host/websocket_dispatcher_host.cc in the Web Sockets implementation in Google Chrome before 33.0.1750.149 might allow remote attackers to bypass the sandbox protection mechanism by leveraging an incorrect deletion in a certain failure case.",
        "git_url": "https://github.com/chromium/chromium/commit/09b09312b9847e025249b9ba5bb2071dd77a19c3",
        "commit_title": "Fix UAF in WebSocketDispatcherHost",
        "commit_text": " If Send() fails in SendOrDrop(), then |message| will have been deleted, but SendOrDrop() will still try to access its header fields.  Fixed.   ",
        "func_before": "WebSocketHostState WebSocketDispatcherHost::SendOrDrop(IPC::Message* message) {\n  if (!Send(message)) {\n    DVLOG(1) << \"Sending of message type \" << message->type()\n             << \" failed. Dropping channel.\";\n    DeleteWebSocketHost(message->routing_id());\n    return WEBSOCKET_HOST_DELETED;\n  }\n  return WEBSOCKET_HOST_ALIVE;\n}",
        "func": "WebSocketHostState WebSocketDispatcherHost::SendOrDrop(IPC::Message* message) {\n  const uint32 message_type = message->type();\n  const int32 message_routing_id = message->routing_id();\n  if (!Send(message)) {\n    message = NULL;\n    DVLOG(1) << \"Sending of message type \" << message_type\n             << \" failed. Dropping channel.\";\n    DeleteWebSocketHost(message_routing_id);\n    return WEBSOCKET_HOST_DELETED;\n  }\n  return WEBSOCKET_HOST_ALIVE;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,8 +1,11 @@\n WebSocketHostState WebSocketDispatcherHost::SendOrDrop(IPC::Message* message) {\n+  const uint32 message_type = message->type();\n+  const int32 message_routing_id = message->routing_id();\n   if (!Send(message)) {\n-    DVLOG(1) << \"Sending of message type \" << message->type()\n+    message = NULL;\n+    DVLOG(1) << \"Sending of message type \" << message_type\n              << \" failed. Dropping channel.\";\n-    DeleteWebSocketHost(message->routing_id());\n+    DeleteWebSocketHost(message_routing_id);\n     return WEBSOCKET_HOST_DELETED;\n   }\n   return WEBSOCKET_HOST_ALIVE;",
        "diff_line_info": {
            "deleted_lines": [
                "    DVLOG(1) << \"Sending of message type \" << message->type()",
                "    DeleteWebSocketHost(message->routing_id());"
            ],
            "added_lines": [
                "  const uint32 message_type = message->type();",
                "  const int32 message_routing_id = message->routing_id();",
                "    message = NULL;",
                "    DVLOG(1) << \"Sending of message type \" << message_type",
                "    DeleteWebSocketHost(message_routing_id);"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-7348",
        "func_name": "torvalds/linux/ioctx_alloc",
        "description": "Double free vulnerability in the ioctx_alloc function in fs/aio.c in the Linux kernel before 3.12.4 allows local users to cause a denial of service (system crash) or possibly have unspecified other impact via vectors involving an error condition in the aio_setup_ring function.",
        "git_url": "https://github.com/torvalds/linux/commit/d558023207e008a4476a3b7bb8706b2a2bf5d84f",
        "commit_title": "aio: prevent double free in ioctx_alloc",
        "commit_text": " ioctx_alloc() calls aio_setup_ring() to allocate a ring. If aio_setup_ring() fails to do so it would call aio_free_ring() before returning, but ioctx_alloc() would call aio_free_ring() again causing a double free of the ring.  This is easily reproducible from userspace. ",
        "func_before": "static struct kioctx *ioctx_alloc(unsigned nr_events)\n{\n\tstruct mm_struct *mm = current->mm;\n\tstruct kioctx *ctx;\n\tint err = -ENOMEM;\n\n\t/*\n\t * We keep track of the number of available ringbuffer slots, to prevent\n\t * overflow (reqs_available), and we also use percpu counters for this.\n\t *\n\t * So since up to half the slots might be on other cpu's percpu counters\n\t * and unavailable, double nr_events so userspace sees what they\n\t * expected: additionally, we move req_batch slots to/from percpu\n\t * counters at a time, so make sure that isn't 0:\n\t */\n\tnr_events = max(nr_events, num_possible_cpus() * 4);\n\tnr_events *= 2;\n\n\t/* Prevent overflows */\n\tif ((nr_events > (0x10000000U / sizeof(struct io_event))) ||\n\t    (nr_events > (0x10000000U / sizeof(struct kiocb)))) {\n\t\tpr_debug(\"ENOMEM: nr_events too high\\n\");\n\t\treturn ERR_PTR(-EINVAL);\n\t}\n\n\tif (!nr_events || (unsigned long)nr_events > (aio_max_nr * 2UL))\n\t\treturn ERR_PTR(-EAGAIN);\n\n\tctx = kmem_cache_zalloc(kioctx_cachep, GFP_KERNEL);\n\tif (!ctx)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tctx->max_reqs = nr_events;\n\n\tif (percpu_ref_init(&ctx->users, free_ioctx_users))\n\t\tgoto err;\n\n\tif (percpu_ref_init(&ctx->reqs, free_ioctx_reqs))\n\t\tgoto err;\n\n\tspin_lock_init(&ctx->ctx_lock);\n\tspin_lock_init(&ctx->completion_lock);\n\tmutex_init(&ctx->ring_lock);\n\tinit_waitqueue_head(&ctx->wait);\n\n\tINIT_LIST_HEAD(&ctx->active_reqs);\n\n\tctx->cpu = alloc_percpu(struct kioctx_cpu);\n\tif (!ctx->cpu)\n\t\tgoto err;\n\n\tif (aio_setup_ring(ctx) < 0)\n\t\tgoto err;\n\n\tatomic_set(&ctx->reqs_available, ctx->nr_events - 1);\n\tctx->req_batch = (ctx->nr_events - 1) / (num_possible_cpus() * 4);\n\tif (ctx->req_batch < 1)\n\t\tctx->req_batch = 1;\n\n\t/* limit the number of system wide aios */\n\tspin_lock(&aio_nr_lock);\n\tif (aio_nr + nr_events > (aio_max_nr * 2UL) ||\n\t    aio_nr + nr_events < aio_nr) {\n\t\tspin_unlock(&aio_nr_lock);\n\t\terr = -EAGAIN;\n\t\tgoto err;\n\t}\n\taio_nr += ctx->max_reqs;\n\tspin_unlock(&aio_nr_lock);\n\n\tpercpu_ref_get(&ctx->users); /* io_setup() will drop this ref */\n\n\terr = ioctx_add_table(ctx, mm);\n\tif (err)\n\t\tgoto err_cleanup;\n\n\tpr_debug(\"allocated ioctx %p[%ld]: mm=%p mask=0x%x\\n\",\n\t\t ctx, ctx->user_id, mm, ctx->nr_events);\n\treturn ctx;\n\nerr_cleanup:\n\taio_nr_sub(ctx->max_reqs);\nerr:\n\taio_free_ring(ctx);\n\tfree_percpu(ctx->cpu);\n\tfree_percpu(ctx->reqs.pcpu_count);\n\tfree_percpu(ctx->users.pcpu_count);\n\tkmem_cache_free(kioctx_cachep, ctx);\n\tpr_debug(\"error allocating ioctx %d\\n\", err);\n\treturn ERR_PTR(err);\n}",
        "func": "static struct kioctx *ioctx_alloc(unsigned nr_events)\n{\n\tstruct mm_struct *mm = current->mm;\n\tstruct kioctx *ctx;\n\tint err = -ENOMEM;\n\n\t/*\n\t * We keep track of the number of available ringbuffer slots, to prevent\n\t * overflow (reqs_available), and we also use percpu counters for this.\n\t *\n\t * So since up to half the slots might be on other cpu's percpu counters\n\t * and unavailable, double nr_events so userspace sees what they\n\t * expected: additionally, we move req_batch slots to/from percpu\n\t * counters at a time, so make sure that isn't 0:\n\t */\n\tnr_events = max(nr_events, num_possible_cpus() * 4);\n\tnr_events *= 2;\n\n\t/* Prevent overflows */\n\tif ((nr_events > (0x10000000U / sizeof(struct io_event))) ||\n\t    (nr_events > (0x10000000U / sizeof(struct kiocb)))) {\n\t\tpr_debug(\"ENOMEM: nr_events too high\\n\");\n\t\treturn ERR_PTR(-EINVAL);\n\t}\n\n\tif (!nr_events || (unsigned long)nr_events > (aio_max_nr * 2UL))\n\t\treturn ERR_PTR(-EAGAIN);\n\n\tctx = kmem_cache_zalloc(kioctx_cachep, GFP_KERNEL);\n\tif (!ctx)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tctx->max_reqs = nr_events;\n\n\tif (percpu_ref_init(&ctx->users, free_ioctx_users))\n\t\tgoto err;\n\n\tif (percpu_ref_init(&ctx->reqs, free_ioctx_reqs))\n\t\tgoto err;\n\n\tspin_lock_init(&ctx->ctx_lock);\n\tspin_lock_init(&ctx->completion_lock);\n\tmutex_init(&ctx->ring_lock);\n\tinit_waitqueue_head(&ctx->wait);\n\n\tINIT_LIST_HEAD(&ctx->active_reqs);\n\n\tctx->cpu = alloc_percpu(struct kioctx_cpu);\n\tif (!ctx->cpu)\n\t\tgoto err;\n\n\tif (aio_setup_ring(ctx) < 0)\n\t\tgoto err;\n\n\tatomic_set(&ctx->reqs_available, ctx->nr_events - 1);\n\tctx->req_batch = (ctx->nr_events - 1) / (num_possible_cpus() * 4);\n\tif (ctx->req_batch < 1)\n\t\tctx->req_batch = 1;\n\n\t/* limit the number of system wide aios */\n\tspin_lock(&aio_nr_lock);\n\tif (aio_nr + nr_events > (aio_max_nr * 2UL) ||\n\t    aio_nr + nr_events < aio_nr) {\n\t\tspin_unlock(&aio_nr_lock);\n\t\terr = -EAGAIN;\n\t\tgoto err;\n\t}\n\taio_nr += ctx->max_reqs;\n\tspin_unlock(&aio_nr_lock);\n\n\tpercpu_ref_get(&ctx->users); /* io_setup() will drop this ref */\n\n\terr = ioctx_add_table(ctx, mm);\n\tif (err)\n\t\tgoto err_cleanup;\n\n\tpr_debug(\"allocated ioctx %p[%ld]: mm=%p mask=0x%x\\n\",\n\t\t ctx, ctx->user_id, mm, ctx->nr_events);\n\treturn ctx;\n\nerr_cleanup:\n\taio_nr_sub(ctx->max_reqs);\nerr:\n\tfree_percpu(ctx->cpu);\n\tfree_percpu(ctx->reqs.pcpu_count);\n\tfree_percpu(ctx->users.pcpu_count);\n\tkmem_cache_free(kioctx_cachep, ctx);\n\tpr_debug(\"error allocating ioctx %d\\n\", err);\n\treturn ERR_PTR(err);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -81,7 +81,6 @@\n err_cleanup:\n \taio_nr_sub(ctx->max_reqs);\n err:\n-\taio_free_ring(ctx);\n \tfree_percpu(ctx->cpu);\n \tfree_percpu(ctx->reqs.pcpu_count);\n \tfree_percpu(ctx->users.pcpu_count);",
        "diff_line_info": {
            "deleted_lines": [
                "\taio_free_ring(ctx);"
            ],
            "added_lines": []
        }
    },
    {
        "cve_id": "CVE-2012-0033",
        "func_name": "znc/OnPrivCTCP",
        "description": "The CBounceDCCMod::OnPrivCTCP function in bouncedcc.cpp in the bouncedcc module in ZNC 0.200 and 0.202 allows remote attackers to cause a denial of service (crash) via a crafted DCC RESUME request.",
        "git_url": "https://github.com/znc/znc/commit/11508aa72efab4fad0dbd8292b9614d9371b20a9",
        "commit_title": "Fix crash in bouncedcc module.",
        "commit_text": " It happens when DCC RESUME is received. Affected ZNC versions: 0.200, 0.202.  Thanks to howeyc for reporting this and providing the patch.",
        "func_before": "virtual EModRet OnPrivCTCP(CNick& Nick, CString& sMessage) {\n\t\tif (sMessage.Equals(\"DCC \", false, 4) && m_pUser->IsUserAttached()) {\n\t\t\t// DCC CHAT chat 2453612361 44592\n\t\t\tCString sType = sMessage.Token(1);\n\t\t\tCString sFile = sMessage.Token(2);\n\t\t\tunsigned long uLongIP = sMessage.Token(3).ToULong();\n\t\t\tunsigned short uPort = sMessage.Token(4).ToUShort();\n\t\t\tunsigned long uFileSize = sMessage.Token(5).ToULong();\n\n\t\t\tif (sType.Equals(\"CHAT\")) {\n\t\t\t\tCNick FromNick(Nick.GetNickMask());\n\t\t\t\tunsigned short uBNCPort = CDCCBounce::DCCRequest(FromNick.GetNick(), uLongIP, uPort, \"\", true, this, CUtils::GetIP(uLongIP));\n\t\t\t\tif (uBNCPort) {\n\t\t\t\t\tCString sIP = GetLocalDCCIP();\n\t\t\t\t\tm_pUser->PutUser(\":\" + Nick.GetNickMask() + \" PRIVMSG \" + m_pUser->GetNick() + \" :\\001DCC CHAT chat \" + CString(CUtils::GetLongIP(sIP)) + \" \" + CString(uBNCPort) + \"\\001\");\n\t\t\t\t}\n\t\t\t} else if (sType.Equals(\"SEND\")) {\n\t\t\t\t// DCC SEND readme.txt 403120438 5550 1104\n\t\t\t\tunsigned short uBNCPort = CDCCBounce::DCCRequest(Nick.GetNick(), uLongIP, uPort, sFile, false, this, CUtils::GetIP(uLongIP));\n\t\t\t\tif (uBNCPort) {\n\t\t\t\t\tCString sIP = GetLocalDCCIP();\n\t\t\t\t\tm_pUser->PutUser(\":\" + Nick.GetNickMask() + \" PRIVMSG \" + m_pUser->GetNick() + \" :\\001DCC SEND \" + sFile + \" \" + CString(CUtils::GetLongIP(sIP)) + \" \" + CString(uBNCPort) + \" \" + CString(uFileSize) + \"\\001\");\n\t\t\t\t}\n\t\t\t} else if (sType.Equals(\"RESUME\")) {\n\t\t\t\t// Need to lookup the connection by port, filter the port, and forward to the user\n\t\t\t\tunsigned short uResumePort = sMessage.Token(3).ToUShort();\n\n\t\t\t\tset<CSocket*>::const_iterator it;\n\t\t\t\tfor (it = BeginSockets(); it != EndSockets(); ++it) {\n\t\t\t\t\tCDCCBounce* pSock = (CDCCBounce*) *it;\n\n\t\t\t\t\tif (pSock->GetLocalPort() == uResumePort) {\n\t\t\t\t\t\tm_pUser->PutUser(\":\" + Nick.GetNickMask() + \" PRIVMSG \" + m_pClient->GetNick() + \" :\\001DCC \" + sType + \" \" + sFile + \" \" + CString(pSock->GetUserPort()) + \" \" + sMessage.Token(4) + \"\\001\");\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} else if (sType.Equals(\"ACCEPT\")) {\n\t\t\t\t// Need to lookup the connection by port, filter the port, and forward to the user\n\t\t\t\tset<CSocket*>::const_iterator it;\n\t\t\t\tfor (it = BeginSockets(); it != EndSockets(); ++it) {\n\t\t\t\t\tCDCCBounce* pSock = (CDCCBounce*) *it;\n\n\t\t\t\t\tif (pSock->GetUserPort() == sMessage.Token(3).ToUShort()) {\n\t\t\t\t\t\tm_pUser->PutUser(\":\" + Nick.GetNickMask() + \" PRIVMSG \" + m_pClient->GetNick() + \" :\\001DCC \" + sType + \" \" + sFile + \" \" + CString(pSock->GetLocalPort()) + \" \" + sMessage.Token(4) + \"\\001\");\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\treturn HALTCORE;\n\t\t}\n\n\t\treturn CONTINUE;\n\t}",
        "func": "virtual EModRet OnPrivCTCP(CNick& Nick, CString& sMessage) {\n\t\tif (sMessage.Equals(\"DCC \", false, 4) && m_pUser->IsUserAttached()) {\n\t\t\t// DCC CHAT chat 2453612361 44592\n\t\t\tCString sType = sMessage.Token(1);\n\t\t\tCString sFile = sMessage.Token(2);\n\t\t\tunsigned long uLongIP = sMessage.Token(3).ToULong();\n\t\t\tunsigned short uPort = sMessage.Token(4).ToUShort();\n\t\t\tunsigned long uFileSize = sMessage.Token(5).ToULong();\n\n\t\t\tif (sType.Equals(\"CHAT\")) {\n\t\t\t\tCNick FromNick(Nick.GetNickMask());\n\t\t\t\tunsigned short uBNCPort = CDCCBounce::DCCRequest(FromNick.GetNick(), uLongIP, uPort, \"\", true, this, CUtils::GetIP(uLongIP));\n\t\t\t\tif (uBNCPort) {\n\t\t\t\t\tCString sIP = GetLocalDCCIP();\n\t\t\t\t\tm_pUser->PutUser(\":\" + Nick.GetNickMask() + \" PRIVMSG \" + m_pUser->GetNick() + \" :\\001DCC CHAT chat \" + CString(CUtils::GetLongIP(sIP)) + \" \" + CString(uBNCPort) + \"\\001\");\n\t\t\t\t}\n\t\t\t} else if (sType.Equals(\"SEND\")) {\n\t\t\t\t// DCC SEND readme.txt 403120438 5550 1104\n\t\t\t\tunsigned short uBNCPort = CDCCBounce::DCCRequest(Nick.GetNick(), uLongIP, uPort, sFile, false, this, CUtils::GetIP(uLongIP));\n\t\t\t\tif (uBNCPort) {\n\t\t\t\t\tCString sIP = GetLocalDCCIP();\n\t\t\t\t\tm_pUser->PutUser(\":\" + Nick.GetNickMask() + \" PRIVMSG \" + m_pUser->GetNick() + \" :\\001DCC SEND \" + sFile + \" \" + CString(CUtils::GetLongIP(sIP)) + \" \" + CString(uBNCPort) + \" \" + CString(uFileSize) + \"\\001\");\n\t\t\t\t}\n\t\t\t} else if (sType.Equals(\"RESUME\")) {\n\t\t\t\t// Need to lookup the connection by port, filter the port, and forward to the user\n\t\t\t\tunsigned short uResumePort = sMessage.Token(3).ToUShort();\n\n\t\t\t\tset<CSocket*>::const_iterator it;\n\t\t\t\tfor (it = BeginSockets(); it != EndSockets(); ++it) {\n\t\t\t\t\tCDCCBounce* pSock = (CDCCBounce*) *it;\n\n\t\t\t\t\tif (pSock->GetLocalPort() == uResumePort) {\n\t\t\t\t\t\tm_pUser->PutUser(\":\" + Nick.GetNickMask() + \" PRIVMSG \" + m_pUser->GetNick() + \" :\\001DCC \" + sType + \" \" + sFile + \" \" + CString(pSock->GetUserPort()) + \" \" + sMessage.Token(4) + \"\\001\");\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} else if (sType.Equals(\"ACCEPT\")) {\n\t\t\t\t// Need to lookup the connection by port, filter the port, and forward to the user\n\t\t\t\tset<CSocket*>::const_iterator it;\n\t\t\t\tfor (it = BeginSockets(); it != EndSockets(); ++it) {\n\t\t\t\t\tCDCCBounce* pSock = (CDCCBounce*) *it;\n\n\t\t\t\t\tif (pSock->GetUserPort() == sMessage.Token(3).ToUShort()) {\n\t\t\t\t\t\tm_pUser->PutUser(\":\" + Nick.GetNickMask() + \" PRIVMSG \" + m_pUser->GetNick() + \" :\\001DCC \" + sType + \" \" + sFile + \" \" + CString(pSock->GetLocalPort()) + \" \" + sMessage.Token(4) + \"\\001\");\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\treturn HALTCORE;\n\t\t}\n\n\t\treturn CONTINUE;\n\t}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -30,7 +30,7 @@\n \t\t\t\t\tCDCCBounce* pSock = (CDCCBounce*) *it;\n \n \t\t\t\t\tif (pSock->GetLocalPort() == uResumePort) {\n-\t\t\t\t\t\tm_pUser->PutUser(\":\" + Nick.GetNickMask() + \" PRIVMSG \" + m_pClient->GetNick() + \" :\\001DCC \" + sType + \" \" + sFile + \" \" + CString(pSock->GetUserPort()) + \" \" + sMessage.Token(4) + \"\\001\");\n+\t\t\t\t\t\tm_pUser->PutUser(\":\" + Nick.GetNickMask() + \" PRIVMSG \" + m_pUser->GetNick() + \" :\\001DCC \" + sType + \" \" + sFile + \" \" + CString(pSock->GetUserPort()) + \" \" + sMessage.Token(4) + \"\\001\");\n \t\t\t\t\t}\n \t\t\t\t}\n \t\t\t} else if (sType.Equals(\"ACCEPT\")) {\n@@ -40,7 +40,7 @@\n \t\t\t\t\tCDCCBounce* pSock = (CDCCBounce*) *it;\n \n \t\t\t\t\tif (pSock->GetUserPort() == sMessage.Token(3).ToUShort()) {\n-\t\t\t\t\t\tm_pUser->PutUser(\":\" + Nick.GetNickMask() + \" PRIVMSG \" + m_pClient->GetNick() + \" :\\001DCC \" + sType + \" \" + sFile + \" \" + CString(pSock->GetLocalPort()) + \" \" + sMessage.Token(4) + \"\\001\");\n+\t\t\t\t\t\tm_pUser->PutUser(\":\" + Nick.GetNickMask() + \" PRIVMSG \" + m_pUser->GetNick() + \" :\\001DCC \" + sType + \" \" + sFile + \" \" + CString(pSock->GetLocalPort()) + \" \" + sMessage.Token(4) + \"\\001\");\n \t\t\t\t\t}\n \t\t\t\t}\n \t\t\t}",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\t\t\t\tm_pUser->PutUser(\":\" + Nick.GetNickMask() + \" PRIVMSG \" + m_pClient->GetNick() + \" :\\001DCC \" + sType + \" \" + sFile + \" \" + CString(pSock->GetUserPort()) + \" \" + sMessage.Token(4) + \"\\001\");",
                "\t\t\t\t\t\tm_pUser->PutUser(\":\" + Nick.GetNickMask() + \" PRIVMSG \" + m_pClient->GetNick() + \" :\\001DCC \" + sType + \" \" + sFile + \" \" + CString(pSock->GetLocalPort()) + \" \" + sMessage.Token(4) + \"\\001\");"
            ],
            "added_lines": [
                "\t\t\t\t\t\tm_pUser->PutUser(\":\" + Nick.GetNickMask() + \" PRIVMSG \" + m_pUser->GetNick() + \" :\\001DCC \" + sType + \" \" + sFile + \" \" + CString(pSock->GetUserPort()) + \" \" + sMessage.Token(4) + \"\\001\");",
                "\t\t\t\t\t\tm_pUser->PutUser(\":\" + Nick.GetNickMask() + \" PRIVMSG \" + m_pUser->GetNick() + \" :\\001DCC \" + sType + \" \" + sFile + \" \" + CString(pSock->GetLocalPort()) + \" \" + sMessage.Token(4) + \"\\001\");"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-1719",
        "func_name": "chromium/WebSharedWorkerStub::OnTerminateWorkerContext",
        "description": "Use-after-free vulnerability in the WebSharedWorkerStub::OnTerminateWorkerContext function in content/worker/websharedworker_stub.cc in the Web Workers implementation in Google Chrome before 34.0.1847.116 allows remote attackers to cause a denial of service (heap memory corruption) or possibly have unspecified other impact via vectors that trigger a SharedWorker termination during script loading.",
        "git_url": "https://github.com/chromium/chromium/commit/b183147e6d71fdafc675a769abb07c568b47241b",
        "commit_title": "Don't terminate SharedWorker while loading the script.",
        "commit_text": " This path will fix the heap-use-after-free bug.   ",
        "func_before": "void WebSharedWorkerStub::OnTerminateWorkerContext() {\n  impl_->terminateWorkerContext();\n\n  // Call the client to make sure context exits.\n  EnsureWorkerContextTerminates();\n  running_ = false;\n}",
        "func": "void WebSharedWorkerStub::OnTerminateWorkerContext() {\n  running_ = false;\n  // Call the client to make sure context exits.\n  EnsureWorkerContextTerminates();\n  // This may call \"delete this\" via WorkerScriptLoadFailed and Shutdown.\n  impl_->terminateWorkerContext();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,7 +1,7 @@\n void WebSharedWorkerStub::OnTerminateWorkerContext() {\n-  impl_->terminateWorkerContext();\n-\n+  running_ = false;\n   // Call the client to make sure context exits.\n   EnsureWorkerContextTerminates();\n-  running_ = false;\n+  // This may call \"delete this\" via WorkerScriptLoadFailed and Shutdown.\n+  impl_->terminateWorkerContext();\n }",
        "diff_line_info": {
            "deleted_lines": [
                "  impl_->terminateWorkerContext();",
                "",
                "  running_ = false;"
            ],
            "added_lines": [
                "  running_ = false;",
                "  // This may call \"delete this\" via WorkerScriptLoadFailed and Shutdown.",
                "  impl_->terminateWorkerContext();"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-1720",
        "func_name": "chromium/HTMLBodyElement::insertedInto",
        "description": "Use-after-free vulnerability in the HTMLBodyElement::insertedInto function in core/html/HTMLBodyElement.cpp in Blink, as used in Google Chrome before 34.0.1847.116, allows remote attackers to cause a denial of service or possibly have unspecified other impact via vectors involving attributes.",
        "git_url": "https://github.com/chromium/chromium/commit/d22bd7ecd1cc576a1a586ee59d5e08d7eee6cdf3",
        "commit_title": "Do not update attributes in HTMLBodyElement::insertedInto.",
        "commit_text": " Use didNotifySubtreeInsertionsToDocument instead.   ",
        "func_before": "Node::InsertionNotificationRequest HTMLBodyElement::insertedInto(ContainerNode* insertionPoint)\n{\n    HTMLElement::insertedInto(insertionPoint);\n    if (insertionPoint->inDocument()) {\n        // FIXME: It's surprising this is web compatible since it means a marginwidth\n        // and marginheight attribute can magically appear on the <body> of all documents\n        // embedded through <iframe> or <frame>.\n        Element* ownerElement = document().ownerElement();\n        if (isHTMLFrameElementBase(ownerElement)) {\n            HTMLFrameElementBase& ownerFrameElement = toHTMLFrameElementBase(*ownerElement);\n            int marginWidth = ownerFrameElement.marginWidth();\n            if (marginWidth != -1)\n                setIntegralAttribute(marginwidthAttr, marginWidth);\n            int marginHeight = ownerFrameElement.marginHeight();\n            if (marginHeight != -1)\n                setIntegralAttribute(marginheightAttr, marginHeight);\n        }\n    }\n    return InsertionDone;\n}",
        "func": "Node::InsertionNotificationRequest HTMLBodyElement::insertedInto(ContainerNode* insertionPoint)\n{\n    HTMLElement::insertedInto(insertionPoint);\n    return InsertionShouldCallDidNotifySubtreeInsertions;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,20 +1,5 @@\n Node::InsertionNotificationRequest HTMLBodyElement::insertedInto(ContainerNode* insertionPoint)\n {\n     HTMLElement::insertedInto(insertionPoint);\n-    if (insertionPoint->inDocument()) {\n-        // FIXME: It's surprising this is web compatible since it means a marginwidth\n-        // and marginheight attribute can magically appear on the <body> of all documents\n-        // embedded through <iframe> or <frame>.\n-        Element* ownerElement = document().ownerElement();\n-        if (isHTMLFrameElementBase(ownerElement)) {\n-            HTMLFrameElementBase& ownerFrameElement = toHTMLFrameElementBase(*ownerElement);\n-            int marginWidth = ownerFrameElement.marginWidth();\n-            if (marginWidth != -1)\n-                setIntegralAttribute(marginwidthAttr, marginWidth);\n-            int marginHeight = ownerFrameElement.marginHeight();\n-            if (marginHeight != -1)\n-                setIntegralAttribute(marginheightAttr, marginHeight);\n-        }\n-    }\n-    return InsertionDone;\n+    return InsertionShouldCallDidNotifySubtreeInsertions;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    if (insertionPoint->inDocument()) {",
                "        // FIXME: It's surprising this is web compatible since it means a marginwidth",
                "        // and marginheight attribute can magically appear on the <body> of all documents",
                "        // embedded through <iframe> or <frame>.",
                "        Element* ownerElement = document().ownerElement();",
                "        if (isHTMLFrameElementBase(ownerElement)) {",
                "            HTMLFrameElementBase& ownerFrameElement = toHTMLFrameElementBase(*ownerElement);",
                "            int marginWidth = ownerFrameElement.marginWidth();",
                "            if (marginWidth != -1)",
                "                setIntegralAttribute(marginwidthAttr, marginWidth);",
                "            int marginHeight = ownerFrameElement.marginHeight();",
                "            if (marginHeight != -1)",
                "                setIntegralAttribute(marginheightAttr, marginHeight);",
                "        }",
                "    }",
                "    return InsertionDone;"
            ],
            "added_lines": [
                "    return InsertionShouldCallDidNotifySubtreeInsertions;"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-1722",
        "func_name": "chromium/RenderObjectChildList::insertChildNode",
        "description": "Use-after-free vulnerability in the RenderBlock::addChildIgnoringAnonymousColumnBlocks function in core/rendering/RenderBlock.cpp in Blink, as used in Google Chrome before 34.0.1847.116, allows remote attackers to cause a denial of service or possibly have unspecified other impact via vectors involving addition of a child node.",
        "git_url": "https://github.com/chromium/chromium/commit/473ef14d0db5a25bfddc8030f7bcd5d6f5d64a27",
        "commit_title": "Revert 164125 \"ASSERTION FAILED: !object || object->isTable()\"",
        "commit_text": " Caused multiple use-after-free bugs. See bugs 330626, 331029.  > ASSERTION FAILED: !object || object->isTable() >  > The issue is caused by call sites of > RenderBlock::addChildIgnoringAnonymousColumnBlocks > that basically bypass the RenderTable::addChild logic causing > all sorts of mayhem. The fix I decided on is to fix the previous > RenderBlock function as it's the safest approach to the current > madness. >  > This change adds an extra ASSERT into RenderObjectChildList to > catch further problem earlier. >  > BUG=309421 >  > Review URL: https://codereview.chromium.org/111873005  TBR=jchaffraix@chromium.org  ",
        "func_before": "void RenderObjectChildList::insertChildNode(RenderObject* owner, RenderObject* newChild, RenderObject* beforeChild, bool notifyRenderer)\n{\n    ASSERT(!newChild->parent());\n    ASSERT(!owner->isRenderBlockFlow() || (!newChild->isTableSection() && !newChild->isTableRow() && !newChild->isTableCell()));\n    ASSERT_WITH_SECURITY_IMPLICATION(!owner->isTable() || (newChild->isTableCaption() || newChild->isTableSection() || newChild->isRenderTableCol()));\n\n    while (beforeChild && beforeChild->parent() && beforeChild->parent() != owner)\n        beforeChild = beforeChild->parent();\n\n    // This should never happen, but if it does prevent render tree corruption\n    // where child->parent() ends up being owner but child->nextSibling()->parent()\n    // is not owner.\n    if (beforeChild && beforeChild->parent() != owner) {\n        ASSERT_NOT_REACHED();\n        return;\n    }\n\n    newChild->setParent(owner);\n\n    if (firstChild() == beforeChild)\n        setFirstChild(newChild);\n\n    if (beforeChild) {\n        RenderObject* previousSibling = beforeChild->previousSibling();\n        if (previousSibling)\n            previousSibling->setNextSibling(newChild);\n        newChild->setPreviousSibling(previousSibling);\n        newChild->setNextSibling(beforeChild);\n        beforeChild->setPreviousSibling(newChild);\n    } else {\n        if (lastChild())\n            lastChild()->setNextSibling(newChild);\n        newChild->setPreviousSibling(lastChild());\n        setLastChild(newChild);\n    }\n\n    if (!owner->documentBeingDestroyed() && notifyRenderer)\n        newChild->insertedIntoTree();\n\n    if (!owner->documentBeingDestroyed()) {\n        RenderCounter::rendererSubtreeAttached(newChild);\n    }\n\n    newChild->setNeedsLayoutAndPrefWidthsRecalc();\n    if (!owner->normalChildNeedsLayout())\n        owner->setChildNeedsLayout(); // We may supply the static position for an absolute positioned child.\n\n    if (AXObjectCache* cache = owner->document().axObjectCache())\n        cache->childrenChanged(owner);\n}",
        "func": "void RenderObjectChildList::insertChildNode(RenderObject* owner, RenderObject* newChild, RenderObject* beforeChild, bool notifyRenderer)\n{\n    ASSERT(!newChild->parent());\n    ASSERT(!owner->isRenderBlockFlow() || (!newChild->isTableSection() && !newChild->isTableRow() && !newChild->isTableCell()));\n\n    while (beforeChild && beforeChild->parent() && beforeChild->parent() != owner)\n        beforeChild = beforeChild->parent();\n\n    // This should never happen, but if it does prevent render tree corruption\n    // where child->parent() ends up being owner but child->nextSibling()->parent()\n    // is not owner.\n    if (beforeChild && beforeChild->parent() != owner) {\n        ASSERT_NOT_REACHED();\n        return;\n    }\n\n    newChild->setParent(owner);\n\n    if (firstChild() == beforeChild)\n        setFirstChild(newChild);\n\n    if (beforeChild) {\n        RenderObject* previousSibling = beforeChild->previousSibling();\n        if (previousSibling)\n            previousSibling->setNextSibling(newChild);\n        newChild->setPreviousSibling(previousSibling);\n        newChild->setNextSibling(beforeChild);\n        beforeChild->setPreviousSibling(newChild);\n    } else {\n        if (lastChild())\n            lastChild()->setNextSibling(newChild);\n        newChild->setPreviousSibling(lastChild());\n        setLastChild(newChild);\n    }\n\n    if (!owner->documentBeingDestroyed() && notifyRenderer)\n        newChild->insertedIntoTree();\n\n    if (!owner->documentBeingDestroyed()) {\n        RenderCounter::rendererSubtreeAttached(newChild);\n    }\n\n    newChild->setNeedsLayoutAndPrefWidthsRecalc();\n    if (!owner->normalChildNeedsLayout())\n        owner->setChildNeedsLayout(); // We may supply the static position for an absolute positioned child.\n\n    if (AXObjectCache* cache = owner->document().axObjectCache())\n        cache->childrenChanged(owner);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,7 +2,6 @@\n {\n     ASSERT(!newChild->parent());\n     ASSERT(!owner->isRenderBlockFlow() || (!newChild->isTableSection() && !newChild->isTableRow() && !newChild->isTableCell()));\n-    ASSERT_WITH_SECURITY_IMPLICATION(!owner->isTable() || (newChild->isTableCaption() || newChild->isTableSection() || newChild->isRenderTableCol()));\n \n     while (beforeChild && beforeChild->parent() && beforeChild->parent() != owner)\n         beforeChild = beforeChild->parent();",
        "diff_line_info": {
            "deleted_lines": [
                "    ASSERT_WITH_SECURITY_IMPLICATION(!owner->isTable() || (newChild->isTableCaption() || newChild->isTableSection() || newChild->isRenderTableCol()));"
            ],
            "added_lines": []
        }
    },
    {
        "cve_id": "CVE-2014-1722",
        "func_name": "chromium/RenderBlock::addChildIgnoringAnonymousColumnBlocks",
        "description": "Use-after-free vulnerability in the RenderBlock::addChildIgnoringAnonymousColumnBlocks function in core/rendering/RenderBlock.cpp in Blink, as used in Google Chrome before 34.0.1847.116, allows remote attackers to cause a denial of service or possibly have unspecified other impact via vectors involving addition of a child node.",
        "git_url": "https://github.com/chromium/chromium/commit/473ef14d0db5a25bfddc8030f7bcd5d6f5d64a27",
        "commit_title": "Revert 164125 \"ASSERTION FAILED: !object || object->isTable()\"",
        "commit_text": " Caused multiple use-after-free bugs. See bugs 330626, 331029.  > ASSERTION FAILED: !object || object->isTable() >  > The issue is caused by call sites of > RenderBlock::addChildIgnoringAnonymousColumnBlocks > that basically bypass the RenderTable::addChild logic causing > all sorts of mayhem. The fix I decided on is to fix the previous > RenderBlock function as it's the safest approach to the current > madness. >  > This change adds an extra ASSERT into RenderObjectChildList to > catch further problem earlier. >  > BUG=309421 >  > Review URL: https://codereview.chromium.org/111873005  TBR=jchaffraix@chromium.org  ",
        "func_before": "void RenderBlock::addChildIgnoringAnonymousColumnBlocks(RenderObject* newChild, RenderObject* beforeChild)\n{\n    // FIXME: We should NEVER hit this code path for tables as they should go through RenderTable::addChild\n    // to add the appropriate anonymous wrappers. Unfortunately a lot of callers call this method directly\n    // (bypassing the virtual addChild), which means we can't enforce this before cleaning them up.\n\n    if (beforeChild && beforeChild->parent() != this) {\n        RenderObject* beforeChildContainer = beforeChild->parent();\n        while (beforeChildContainer->parent() != this)\n            beforeChildContainer = beforeChildContainer->parent();\n        ASSERT(beforeChildContainer);\n\n        if (beforeChildContainer->isAnonymous()) {\n            // If the requested beforeChild is not one of our children, then this is because\n            // there is an anonymous container within this object that contains the beforeChild.\n            RenderObject* beforeChildAnonymousContainer = beforeChildContainer;\n            if (beforeChildAnonymousContainer->isAnonymousBlock()\n                // Full screen renderers and full screen placeholders act as anonymous blocks, not tables:\n                || beforeChildAnonymousContainer->isRenderFullScreen()\n                || beforeChildAnonymousContainer->isRenderFullScreenPlaceholder()\n                ) {\n                // Insert the child into the anonymous block box instead of here.\n                if (newChild->isInline() || newChild->isFloatingOrOutOfFlowPositioned() || beforeChild->parent()->firstChild() != beforeChild)\n                    beforeChild->parent()->addChild(newChild, beforeChild);\n                else\n                    addChild(newChild, beforeChild->parent());\n                return;\n            }\n\n            ASSERT(beforeChildAnonymousContainer->isTable());\n            if (newChild->isTablePart()) {\n                // Insert into the anonymous table.\n                beforeChildAnonymousContainer->addChild(newChild, beforeChild);\n                return;\n            }\n\n            beforeChild = splitAnonymousBoxesAroundChild(beforeChild);\n\n            ASSERT(beforeChild->parent() == this);\n            if (beforeChild->parent() != this) {\n                // We should never reach here. If we do, we need to use the\n                // safe fallback to use the topmost beforeChild container.\n                beforeChild = beforeChildContainer;\n            }\n        }\n    }\n\n    // Check for a spanning element in columns.\n    if (gColumnFlowSplitEnabled) {\n        RenderBlockFlow* columnsBlockAncestor = columnsBlockForSpanningElement(newChild);\n        if (columnsBlockAncestor) {\n            TemporaryChange<bool> columnFlowSplitEnabled(gColumnFlowSplitEnabled, false);\n            // We are placing a column-span element inside a block.\n            RenderBlockFlow* newBox = createAnonymousColumnSpanBlock();\n\n            if (columnsBlockAncestor != this && !isRenderFlowThread()) {\n                // We are nested inside a multi-column element and are being split by the span. We have to break up\n                // our block into continuations.\n                RenderBoxModelObject* oldContinuation = continuation();\n\n                // When we split an anonymous block, there's no need to do any continuation hookup,\n                // since we haven't actually split a real element.\n                if (!isAnonymousBlock())\n                    setContinuation(newBox);\n\n                splitFlow(beforeChild, newBox, newChild, oldContinuation);\n                return;\n            }\n\n            // We have to perform a split of this block's children. This involves creating an anonymous block box to hold\n            // the column-spanning |newChild|. We take all of the children from before |newChild| and put them into\n            // one anonymous columns block, and all of the children after |newChild| go into another anonymous block.\n            makeChildrenAnonymousColumnBlocks(beforeChild, newBox, newChild);\n            return;\n        }\n    }\n\n    bool madeBoxesNonInline = false;\n\n    // A block has to either have all of its children inline, or all of its children as blocks.\n    // So, if our children are currently inline and a block child has to be inserted, we move all our\n    // inline children into anonymous block boxes.\n    if (childrenInline() && !newChild->isInline() && !newChild->isFloatingOrOutOfFlowPositioned()) {\n        // This is a block with inline content. Wrap the inline content in anonymous blocks.\n        makeChildrenNonInline(beforeChild);\n        madeBoxesNonInline = true;\n\n        if (beforeChild && beforeChild->parent() != this) {\n            beforeChild = beforeChild->parent();\n            ASSERT(beforeChild->isAnonymousBlock());\n            ASSERT(beforeChild->parent() == this);\n        }\n    } else if (!childrenInline() && (newChild->isFloatingOrOutOfFlowPositioned() || newChild->isInline())) {\n        // If we're inserting an inline child but all of our children are blocks, then we have to make sure\n        // it is put into an anomyous block box. We try to use an existing anonymous box if possible, otherwise\n        // a new one is created and inserted into our list of children in the appropriate position.\n        RenderObject* afterChild = beforeChild ? beforeChild->previousSibling() : lastChild();\n\n        if (afterChild && afterChild->isAnonymousBlock()) {\n            afterChild->addChild(newChild);\n            return;\n        }\n\n        if (newChild->isInline()) {\n            // No suitable existing anonymous box - create a new one.\n            RenderBlock* newBox = createAnonymousBlock();\n            if (isTable())\n                toRenderTable(this)->addChild(newBox, beforeChild);\n            else\n                RenderBox::addChild(newBox, beforeChild);\n            newBox->addChild(newChild);\n            return;\n        }\n    }\n\n    if (isTable())\n        toRenderTable(this)->addChild(newChild, beforeChild);\n    else\n        RenderBox::addChild(newChild, beforeChild);\n\n    if (madeBoxesNonInline && parent() && isAnonymousBlock() && parent()->isRenderBlock())\n        toRenderBlock(parent())->removeLeftoverAnonymousBlock(this);\n    // this object may be dead here\n}",
        "func": "void RenderBlock::addChildIgnoringAnonymousColumnBlocks(RenderObject* newChild, RenderObject* beforeChild)\n{\n    if (beforeChild && beforeChild->parent() != this) {\n        RenderObject* beforeChildContainer = beforeChild->parent();\n        while (beforeChildContainer->parent() != this)\n            beforeChildContainer = beforeChildContainer->parent();\n        ASSERT(beforeChildContainer);\n\n        if (beforeChildContainer->isAnonymous()) {\n            // If the requested beforeChild is not one of our children, then this is because\n            // there is an anonymous container within this object that contains the beforeChild.\n            RenderObject* beforeChildAnonymousContainer = beforeChildContainer;\n            if (beforeChildAnonymousContainer->isAnonymousBlock()\n                // Full screen renderers and full screen placeholders act as anonymous blocks, not tables:\n                || beforeChildAnonymousContainer->isRenderFullScreen()\n                || beforeChildAnonymousContainer->isRenderFullScreenPlaceholder()\n                ) {\n                // Insert the child into the anonymous block box instead of here.\n                if (newChild->isInline() || newChild->isFloatingOrOutOfFlowPositioned() || beforeChild->parent()->firstChild() != beforeChild)\n                    beforeChild->parent()->addChild(newChild, beforeChild);\n                else\n                    addChild(newChild, beforeChild->parent());\n                return;\n            }\n\n            ASSERT(beforeChildAnonymousContainer->isTable());\n            if (newChild->isTablePart()) {\n                // Insert into the anonymous table.\n                beforeChildAnonymousContainer->addChild(newChild, beforeChild);\n                return;\n            }\n\n            beforeChild = splitAnonymousBoxesAroundChild(beforeChild);\n\n            ASSERT(beforeChild->parent() == this);\n            if (beforeChild->parent() != this) {\n                // We should never reach here. If we do, we need to use the\n                // safe fallback to use the topmost beforeChild container.\n                beforeChild = beforeChildContainer;\n            }\n        }\n    }\n\n    // Check for a spanning element in columns.\n    if (gColumnFlowSplitEnabled) {\n        RenderBlockFlow* columnsBlockAncestor = columnsBlockForSpanningElement(newChild);\n        if (columnsBlockAncestor) {\n            TemporaryChange<bool> columnFlowSplitEnabled(gColumnFlowSplitEnabled, false);\n            // We are placing a column-span element inside a block.\n            RenderBlockFlow* newBox = createAnonymousColumnSpanBlock();\n\n            if (columnsBlockAncestor != this && !isRenderFlowThread()) {\n                // We are nested inside a multi-column element and are being split by the span. We have to break up\n                // our block into continuations.\n                RenderBoxModelObject* oldContinuation = continuation();\n\n                // When we split an anonymous block, there's no need to do any continuation hookup,\n                // since we haven't actually split a real element.\n                if (!isAnonymousBlock())\n                    setContinuation(newBox);\n\n                splitFlow(beforeChild, newBox, newChild, oldContinuation);\n                return;\n            }\n\n            // We have to perform a split of this block's children. This involves creating an anonymous block box to hold\n            // the column-spanning |newChild|. We take all of the children from before |newChild| and put them into\n            // one anonymous columns block, and all of the children after |newChild| go into another anonymous block.\n            makeChildrenAnonymousColumnBlocks(beforeChild, newBox, newChild);\n            return;\n        }\n    }\n\n    bool madeBoxesNonInline = false;\n\n    // A block has to either have all of its children inline, or all of its children as blocks.\n    // So, if our children are currently inline and a block child has to be inserted, we move all our\n    // inline children into anonymous block boxes.\n    if (childrenInline() && !newChild->isInline() && !newChild->isFloatingOrOutOfFlowPositioned()) {\n        // This is a block with inline content. Wrap the inline content in anonymous blocks.\n        makeChildrenNonInline(beforeChild);\n        madeBoxesNonInline = true;\n\n        if (beforeChild && beforeChild->parent() != this) {\n            beforeChild = beforeChild->parent();\n            ASSERT(beforeChild->isAnonymousBlock());\n            ASSERT(beforeChild->parent() == this);\n        }\n    } else if (!childrenInline() && (newChild->isFloatingOrOutOfFlowPositioned() || newChild->isInline())) {\n        // If we're inserting an inline child but all of our children are blocks, then we have to make sure\n        // it is put into an anomyous block box. We try to use an existing anonymous box if possible, otherwise\n        // a new one is created and inserted into our list of children in the appropriate position.\n        RenderObject* afterChild = beforeChild ? beforeChild->previousSibling() : lastChild();\n\n        if (afterChild && afterChild->isAnonymousBlock()) {\n            afterChild->addChild(newChild);\n            return;\n        }\n\n        if (newChild->isInline()) {\n            // No suitable existing anonymous box - create a new one.\n            RenderBlock* newBox = createAnonymousBlock();\n            RenderBox::addChild(newBox, beforeChild);\n            newBox->addChild(newChild);\n            return;\n        }\n    }\n\n    RenderBox::addChild(newChild, beforeChild);\n\n    if (madeBoxesNonInline && parent() && isAnonymousBlock() && parent()->isRenderBlock())\n        toRenderBlock(parent())->removeLeftoverAnonymousBlock(this);\n    // this object may be dead here\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,9 +1,5 @@\n void RenderBlock::addChildIgnoringAnonymousColumnBlocks(RenderObject* newChild, RenderObject* beforeChild)\n {\n-    // FIXME: We should NEVER hit this code path for tables as they should go through RenderTable::addChild\n-    // to add the appropriate anonymous wrappers. Unfortunately a lot of callers call this method directly\n-    // (bypassing the virtual addChild), which means we can't enforce this before cleaning them up.\n-\n     if (beforeChild && beforeChild->parent() != this) {\n         RenderObject* beforeChildContainer = beforeChild->parent();\n         while (beforeChildContainer->parent() != this)\n@@ -104,19 +100,13 @@\n         if (newChild->isInline()) {\n             // No suitable existing anonymous box - create a new one.\n             RenderBlock* newBox = createAnonymousBlock();\n-            if (isTable())\n-                toRenderTable(this)->addChild(newBox, beforeChild);\n-            else\n-                RenderBox::addChild(newBox, beforeChild);\n+            RenderBox::addChild(newBox, beforeChild);\n             newBox->addChild(newChild);\n             return;\n         }\n     }\n \n-    if (isTable())\n-        toRenderTable(this)->addChild(newChild, beforeChild);\n-    else\n-        RenderBox::addChild(newChild, beforeChild);\n+    RenderBox::addChild(newChild, beforeChild);\n \n     if (madeBoxesNonInline && parent() && isAnonymousBlock() && parent()->isRenderBlock())\n         toRenderBlock(parent())->removeLeftoverAnonymousBlock(this);",
        "diff_line_info": {
            "deleted_lines": [
                "    // FIXME: We should NEVER hit this code path for tables as they should go through RenderTable::addChild",
                "    // to add the appropriate anonymous wrappers. Unfortunately a lot of callers call this method directly",
                "    // (bypassing the virtual addChild), which means we can't enforce this before cleaning them up.",
                "",
                "            if (isTable())",
                "                toRenderTable(this)->addChild(newBox, beforeChild);",
                "            else",
                "                RenderBox::addChild(newBox, beforeChild);",
                "    if (isTable())",
                "        toRenderTable(this)->addChild(newChild, beforeChild);",
                "    else",
                "        RenderBox::addChild(newChild, beforeChild);"
            ],
            "added_lines": [
                "            RenderBox::addChild(newBox, beforeChild);",
                "    RenderBox::addChild(newChild, beforeChild);"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-1724",
        "func_name": "chromium/TtsPlatformImplLinux::TtsPlatformImplLinux",
        "description": "Use-after-free vulnerability in Free(b)soft Laboratory Speech Dispatcher 0.7.1, as used in Google Chrome before 34.0.1847.116, allows remote attackers to cause a denial of service (application hang) or possibly have unspecified other impact via a text-to-speech request.",
        "git_url": "https://github.com/chromium/chromium/commit/e99a988a6345c7a1fabee2779918d0b0a152456a",
        "commit_title": "Only enable speech dispatcher on Linux with an explicit switch.",
        "commit_text": " Now that the speechSynthesis api is part of the drive-by web, we don't want just visiting a malicious site to be able to cause speech-dispatcher to crash.   ",
        "func_before": "TtsPlatformImplLinux::TtsPlatformImplLinux()\n    : utterance_id_(0) {\n  BrowserThread::PostTask(BrowserThread::FILE,\n                          FROM_HERE,\n                          base::Bind(&TtsPlatformImplLinux::Initialize,\n                                     base::Unretained(this)));\n}",
        "func": "TtsPlatformImplLinux::TtsPlatformImplLinux()\n    : utterance_id_(0) {\n  const CommandLine& command_line = *CommandLine::ForCurrentProcess();\n  if (!command_line.HasSwitch(switches::kEnableSpeechDispatcher))\n    return;\n\n  BrowserThread::PostTask(BrowserThread::FILE,\n                          FROM_HERE,\n                          base::Bind(&TtsPlatformImplLinux::Initialize,\n                                     base::Unretained(this)));\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,9 @@\n TtsPlatformImplLinux::TtsPlatformImplLinux()\n     : utterance_id_(0) {\n+  const CommandLine& command_line = *CommandLine::ForCurrentProcess();\n+  if (!command_line.HasSwitch(switches::kEnableSpeechDispatcher))\n+    return;\n+\n   BrowserThread::PostTask(BrowserThread::FILE,\n                           FROM_HERE,\n                           base::Bind(&TtsPlatformImplLinux::Initialize,",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "  const CommandLine& command_line = *CommandLine::ForCurrentProcess();",
                "  if (!command_line.HasSwitch(switches::kEnableSpeechDispatcher))",
                "    return;",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2014-1724",
        "func_name": "chromium/ShowBadFlagsPrompt",
        "description": "Use-after-free vulnerability in Free(b)soft Laboratory Speech Dispatcher 0.7.1, as used in Google Chrome before 34.0.1847.116, allows remote attackers to cause a denial of service (application hang) or possibly have unspecified other impact via a text-to-speech request.",
        "git_url": "https://github.com/chromium/chromium/commit/e99a988a6345c7a1fabee2779918d0b0a152456a",
        "commit_title": "Only enable speech dispatcher on Linux with an explicit switch.",
        "commit_text": " Now that the speechSynthesis api is part of the drive-by web, we don't want just visiting a malicious site to be able to cause speech-dispatcher to crash.   ",
        "func_before": "void ShowBadFlagsPrompt(Browser* browser) {\n  content::WebContents* web_contents =\n      browser->tab_strip_model()->GetActiveWebContents();\n  if (!web_contents)\n    return;\n\n  // Unsupported flags for which to display a warning that \"stability and\n  // security will suffer\".\n  static const char* kBadFlags[] = {\n    // These flags disable sandbox-related security.\n    switches::kDisableGpuSandbox,\n    switches::kDisableSeccompFilterSandbox,\n    switches::kDisableSetuidSandbox,\n    switches::kDisableWebSecurity,\n    switches::kNoSandbox,\n    switches::kSingleProcess,\n\n    // These flags disable or undermine the Same Origin Policy.\n    switches::kEnableBrowserPluginForAllViewTypes,\n    switches::kTrustedSpdyProxy,\n    translate::switches::kTranslateSecurityOrigin,\n\n    // These flags undermine HTTPS / connection security.\n    switches::kDisableUserMediaSecurity,\n  #if defined(ENABLE_WEBRTC)\n    switches::kDisableWebRtcEncryption,\n  #endif\n    switches::kIgnoreCertificateErrors,\n    switches::kReduceSecurityForTesting,\n    switches::kSyncAllowInsecureXmppConnection,\n\n    // These flags change the URLs that handle PII.\n    autofill::switches::kWalletSecureServiceUrl,\n    switches::kGaiaUrl,\n    translate::switches::kTranslateScriptURL,\n\n    // This flag gives extensions more powers.\n    extensions::switches::kExtensionsOnChromeURLs,\n    NULL\n  };\n\n  for (const char** flag = kBadFlags; *flag; ++flag) {\n    if (CommandLine::ForCurrentProcess()->HasSwitch(*flag)) {\n      SimpleAlertInfoBarDelegate::Create(\n          InfoBarService::FromWebContents(web_contents),\n          InfoBarDelegate::kNoIconID,\n          l10n_util::GetStringFUTF16(IDS_BAD_FLAGS_WARNING_MESSAGE,\n                                     base::UTF8ToUTF16(\n                                         std::string(\"--\") + *flag)),\n          false);\n      return;\n    }\n  }\n}",
        "func": "void ShowBadFlagsPrompt(Browser* browser) {\n  content::WebContents* web_contents =\n      browser->tab_strip_model()->GetActiveWebContents();\n  if (!web_contents)\n    return;\n\n  // Unsupported flags for which to display a warning that \"stability and\n  // security will suffer\".\n  static const char* kBadFlags[] = {\n    // These flags disable sandbox-related security.\n    switches::kDisableGpuSandbox,\n    switches::kDisableSeccompFilterSandbox,\n    switches::kDisableSetuidSandbox,\n    switches::kDisableWebSecurity,\n    switches::kNoSandbox,\n    switches::kSingleProcess,\n\n    // These flags disable or undermine the Same Origin Policy.\n    switches::kEnableBrowserPluginForAllViewTypes,\n    switches::kTrustedSpdyProxy,\n    translate::switches::kTranslateSecurityOrigin,\n\n    // These flags undermine HTTPS / connection security.\n    switches::kDisableUserMediaSecurity,\n#if defined(ENABLE_WEBRTC)\n    switches::kDisableWebRtcEncryption,\n#endif\n    switches::kIgnoreCertificateErrors,\n    switches::kReduceSecurityForTesting,\n    switches::kSyncAllowInsecureXmppConnection,\n\n    // These flags change the URLs that handle PII.\n    autofill::switches::kWalletSecureServiceUrl,\n    switches::kGaiaUrl,\n    translate::switches::kTranslateScriptURL,\n\n    // This flag gives extensions more powers.\n    extensions::switches::kExtensionsOnChromeURLs,\n\n#if defined(OS_LINUX) && !defined(OS_CHROMEOS)\n    // Speech dispatcher is buggy, it can crash and it can make Chrome freeze.\n    // http://crbug.com/327295\n    switches::kEnableSpeechDispatcher,\n#endif\n    NULL\n  };\n\n  for (const char** flag = kBadFlags; *flag; ++flag) {\n    if (CommandLine::ForCurrentProcess()->HasSwitch(*flag)) {\n      SimpleAlertInfoBarDelegate::Create(\n          InfoBarService::FromWebContents(web_contents),\n          InfoBarDelegate::kNoIconID,\n          l10n_util::GetStringFUTF16(IDS_BAD_FLAGS_WARNING_MESSAGE,\n                                     base::UTF8ToUTF16(\n                                         std::string(\"--\") + *flag)),\n          false);\n      return;\n    }\n  }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -22,9 +22,9 @@\n \n     // These flags undermine HTTPS / connection security.\n     switches::kDisableUserMediaSecurity,\n-  #if defined(ENABLE_WEBRTC)\n+#if defined(ENABLE_WEBRTC)\n     switches::kDisableWebRtcEncryption,\n-  #endif\n+#endif\n     switches::kIgnoreCertificateErrors,\n     switches::kReduceSecurityForTesting,\n     switches::kSyncAllowInsecureXmppConnection,\n@@ -36,6 +36,12 @@\n \n     // This flag gives extensions more powers.\n     extensions::switches::kExtensionsOnChromeURLs,\n+\n+#if defined(OS_LINUX) && !defined(OS_CHROMEOS)\n+    // Speech dispatcher is buggy, it can crash and it can make Chrome freeze.\n+    // http://crbug.com/327295\n+    switches::kEnableSpeechDispatcher,\n+#endif\n     NULL\n   };\n ",
        "diff_line_info": {
            "deleted_lines": [
                "  #if defined(ENABLE_WEBRTC)",
                "  #endif"
            ],
            "added_lines": [
                "#if defined(ENABLE_WEBRTC)",
                "#endif",
                "",
                "#if defined(OS_LINUX) && !defined(OS_CHROMEOS)",
                "    // Speech dispatcher is buggy, it can crash and it can make Chrome freeze.",
                "    // http://crbug.com/327295",
                "    switches::kEnableSpeechDispatcher,",
                "#endif"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-1740",
        "func_name": "chromium/WebSocketJob::OnSentHandshakeRequest",
        "description": "Multiple use-after-free vulnerabilities in net/websockets/websocket_job.cc in the WebSockets implementation in Google Chrome before 34.0.1847.137 allow remote attackers to cause a denial of service or possibly have unspecified other impact via vectors related to WebSocketJob deletion.",
        "git_url": "https://github.com/chromium/chromium/commit/b39c954297097454a3b867c45cdad8a1577c761c",
        "commit_title": "Test for WebSocketJob being deleted on the stack",
        "commit_text": " SocketStreamDispatcherHost can delete the WebSocketJob while it is still on the stack. Add tests to ensure that WebSocketJob does not attempt to access its own members after being deleted.  Also fix two cases where WebSocketJob attempted to access its members after being deleted.   ",
        "func_before": "void WebSocketJob::OnSentHandshakeRequest(\n    SocketStream* socket, int amount_sent) {\n  DCHECK_EQ(state_, CONNECTING);\n  handshake_request_sent_ += amount_sent;\n  DCHECK_LE(handshake_request_sent_, handshake_request_->raw_length());\n  if (handshake_request_sent_ >= handshake_request_->raw_length()) {\n    // handshake request has been sent.\n    // notify original size of handshake request to delegate.\n    if (delegate_)\n      delegate_->OnSentData(\n          socket,\n          handshake_request_->original_length());\n    handshake_request_.reset();\n  }\n}",
        "func": "void WebSocketJob::OnSentHandshakeRequest(\n    SocketStream* socket, int amount_sent) {\n  DCHECK_EQ(state_, CONNECTING);\n  handshake_request_sent_ += amount_sent;\n  DCHECK_LE(handshake_request_sent_, handshake_request_->raw_length());\n  if (handshake_request_sent_ >= handshake_request_->raw_length()) {\n    // handshake request has been sent.\n    // notify original size of handshake request to delegate.\n    // Reset the handshake_request_ first in case this object is deleted by the\n    // delegate.\n    size_t original_length = handshake_request_->original_length();\n    handshake_request_.reset();\n    if (delegate_)\n      delegate_->OnSentData(socket, original_length);\n  }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -6,10 +6,11 @@\n   if (handshake_request_sent_ >= handshake_request_->raw_length()) {\n     // handshake request has been sent.\n     // notify original size of handshake request to delegate.\n+    // Reset the handshake_request_ first in case this object is deleted by the\n+    // delegate.\n+    size_t original_length = handshake_request_->original_length();\n+    handshake_request_.reset();\n     if (delegate_)\n-      delegate_->OnSentData(\n-          socket,\n-          handshake_request_->original_length());\n-    handshake_request_.reset();\n+      delegate_->OnSentData(socket, original_length);\n   }\n }",
        "diff_line_info": {
            "deleted_lines": [
                "      delegate_->OnSentData(",
                "          socket,",
                "          handshake_request_->original_length());",
                "    handshake_request_.reset();"
            ],
            "added_lines": [
                "    // Reset the handshake_request_ first in case this object is deleted by the",
                "    // delegate.",
                "    size_t original_length = handshake_request_->original_length();",
                "    handshake_request_.reset();",
                "      delegate_->OnSentData(socket, original_length);"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-1740",
        "func_name": "chromium/WebSocketJob::OnSentSpdyHeaders",
        "description": "Multiple use-after-free vulnerabilities in net/websockets/websocket_job.cc in the WebSockets implementation in Google Chrome before 34.0.1847.137 allow remote attackers to cause a denial of service or possibly have unspecified other impact via vectors related to WebSocketJob deletion.",
        "git_url": "https://github.com/chromium/chromium/commit/b39c954297097454a3b867c45cdad8a1577c761c",
        "commit_title": "Test for WebSocketJob being deleted on the stack",
        "commit_text": " SocketStreamDispatcherHost can delete the WebSocketJob while it is still on the stack. Add tests to ensure that WebSocketJob does not attempt to access its own members after being deleted.  Also fix two cases where WebSocketJob attempted to access its members after being deleted.   ",
        "func_before": "void WebSocketJob::OnSentSpdyHeaders() {\n  DCHECK_NE(INITIALIZED, state_);\n  if (state_ != CONNECTING)\n    return;\n  if (delegate_)\n    delegate_->OnSentData(socket_.get(), handshake_request_->original_length());\n  handshake_request_.reset();\n}",
        "func": "void WebSocketJob::OnSentSpdyHeaders() {\n  DCHECK_NE(INITIALIZED, state_);\n  if (state_ != CONNECTING)\n    return;\n  size_t original_length = handshake_request_->original_length();\n  handshake_request_.reset();\n  if (delegate_)\n    delegate_->OnSentData(socket_.get(), original_length);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,7 +2,8 @@\n   DCHECK_NE(INITIALIZED, state_);\n   if (state_ != CONNECTING)\n     return;\n+  size_t original_length = handshake_request_->original_length();\n+  handshake_request_.reset();\n   if (delegate_)\n-    delegate_->OnSentData(socket_.get(), handshake_request_->original_length());\n-  handshake_request_.reset();\n+    delegate_->OnSentData(socket_.get(), original_length);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    delegate_->OnSentData(socket_.get(), handshake_request_->original_length());",
                "  handshake_request_.reset();"
            ],
            "added_lines": [
                "  size_t original_length = handshake_request_->original_length();",
                "  handshake_request_.reset();",
                "    delegate_->OnSentData(socket_.get(), original_length);"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-1742",
        "func_name": "chromium/FrameSelection::updateAppearance",
        "description": "Use-after-free vulnerability in the FrameSelection::updateAppearance function in core/editing/FrameSelection.cpp in Blink, as used in Google Chrome before 34.0.1847.137, allows remote attackers to cause a denial of service or possibly have unspecified other impact by leveraging improper RenderObject handling.",
        "git_url": "https://github.com/chromium/chromium/commit/3c7b24311c9bc909779984c297b43223dc6ac2f2",
        "commit_title": "Avoid using cross RenderView selection rendering",
        "commit_text": " This patch makes sure we pass |RenderObject| belong to RenderView in |RenderView::setSelection|, which takes two |RenderObject|s for start and end of selection, in |FrameSeleciton::updateAppearance|.  The bug is caused by |VisibleSelection::base| and |VisibleSelection::start| are in different document, |base| points to IFRAME and |start| points |TextNode| in IFRAME. This causes |RenderView|, which holds |RenderObject|s of selection start points and end points, have dangling |RenderObject|'s. Because, |RenderView| doesn't know destructed |RenderObject| belongs to another |RenderView|.   ",
        "func_before": "void FrameSelection::updateAppearance()\n{\n    // Paint a block cursor instead of a caret in overtype mode unless the caret is at the end of a line (in this case\n    // the FrameSelection will paint a blinking caret as usual).\n    VisiblePosition forwardPosition;\n    if (m_shouldShowBlockCursor && m_selection.isCaret()) {\n        forwardPosition = modifyExtendingForward(CharacterGranularity);\n        m_caretPaint = forwardPosition.isNull();\n    }\n\n    bool caretRectChangedOrCleared = recomputeCaretRect();\n    bool shouldBlink = shouldBlinkCaret() && forwardPosition.isNull();\n\n    // If the caret moved, stop the blink timer so we can restart with a\n    // black caret in the new location.\n    if (caretRectChangedOrCleared || !shouldBlink || shouldStopBlinkingDueToTypingCommand(m_frame)) {\n        m_caretBlinkTimer.stop();\n        if (!shouldBlink && m_caretPaint) {\n            m_caretPaint = false;\n            invalidateCaretRect();\n        }\n    }\n\n    // Start blinking with a black caret. Be sure not to restart if we're\n    // already blinking in the right location.\n    if (shouldBlink && !m_caretBlinkTimer.isActive()) {\n        if (double blinkInterval = RenderTheme::theme().caretBlinkInterval())\n            m_caretBlinkTimer.startRepeating(blinkInterval, FROM_HERE);\n\n        if (!m_caretPaint) {\n            m_caretPaint = true;\n            invalidateCaretRect();\n        }\n    }\n\n    RenderView* view = m_frame->contentRenderer();\n    if (!view)\n        return;\n\n    // Construct a new VisibleSolution, since m_selection is not necessarily valid, and the following steps\n    // assume a valid selection. See <https://bugs.webkit.org/show_bug.cgi?id=69563> and <rdar://problem/10232866>.\n    VisibleSelection selection(m_selection.visibleStart(), forwardPosition.isNotNull() ? forwardPosition : m_selection.visibleEnd());\n\n    if (!selection.isRange()) {\n        view->clearSelection();\n        return;\n    }\n\n    // Use the rightmost candidate for the start of the selection, and the leftmost candidate for the end of the selection.\n    // Example: foo <a>bar</a>.  Imagine that a line wrap occurs after 'foo', and that 'bar' is selected.   If we pass [foo, 3]\n    // as the start of the selection, the selection painting code will think that content on the line containing 'foo' is selected\n    // and will fill the gap before 'bar'.\n    Position startPos = selection.start();\n    Position candidate = startPos.downstream();\n    if (candidate.isCandidate())\n        startPos = candidate;\n    Position endPos = selection.end();\n    candidate = endPos.upstream();\n    if (candidate.isCandidate())\n        endPos = candidate;\n\n    // We can get into a state where the selection endpoints map to the same VisiblePosition when a selection is deleted\n    // because we don't yet notify the FrameSelection of text removal.\n    if (startPos.isNotNull() && endPos.isNotNull() && selection.visibleStart() != selection.visibleEnd()) {\n        RenderObject* startRenderer = startPos.deprecatedNode()->renderer();\n        RenderObject* endRenderer = endPos.deprecatedNode()->renderer();\n        view->setSelection(startRenderer, startPos.deprecatedEditingOffset(), endRenderer, endPos.deprecatedEditingOffset());\n    }\n}",
        "func": "void FrameSelection::updateAppearance()\n{\n    // Paint a block cursor instead of a caret in overtype mode unless the caret is at the end of a line (in this case\n    // the FrameSelection will paint a blinking caret as usual).\n    VisiblePosition forwardPosition;\n    if (m_shouldShowBlockCursor && m_selection.isCaret()) {\n        forwardPosition = modifyExtendingForward(CharacterGranularity);\n        m_caretPaint = forwardPosition.isNull();\n    }\n\n    bool caretRectChangedOrCleared = recomputeCaretRect();\n    bool shouldBlink = shouldBlinkCaret() && forwardPosition.isNull();\n\n    // If the caret moved, stop the blink timer so we can restart with a\n    // black caret in the new location.\n    if (caretRectChangedOrCleared || !shouldBlink || shouldStopBlinkingDueToTypingCommand(m_frame)) {\n        m_caretBlinkTimer.stop();\n        if (!shouldBlink && m_caretPaint) {\n            m_caretPaint = false;\n            invalidateCaretRect();\n        }\n    }\n\n    // Start blinking with a black caret. Be sure not to restart if we're\n    // already blinking in the right location.\n    if (shouldBlink && !m_caretBlinkTimer.isActive()) {\n        if (double blinkInterval = RenderTheme::theme().caretBlinkInterval())\n            m_caretBlinkTimer.startRepeating(blinkInterval, FROM_HERE);\n\n        if (!m_caretPaint) {\n            m_caretPaint = true;\n            invalidateCaretRect();\n        }\n    }\n\n    RenderView* view = m_frame->contentRenderer();\n    if (!view)\n        return;\n\n    // Construct a new VisibleSolution, since m_selection is not necessarily valid, and the following steps\n    // assume a valid selection. See <https://bugs.webkit.org/show_bug.cgi?id=69563> and <rdar://problem/10232866>.\n    VisibleSelection selection(m_selection.visibleStart(), forwardPosition.isNotNull() ? forwardPosition : m_selection.visibleEnd());\n\n    if (!selection.isRange()) {\n        view->clearSelection();\n        return;\n    }\n\n    // Use the rightmost candidate for the start of the selection, and the leftmost candidate for the end of the selection.\n    // Example: foo <a>bar</a>.  Imagine that a line wrap occurs after 'foo', and that 'bar' is selected.   If we pass [foo, 3]\n    // as the start of the selection, the selection painting code will think that content on the line containing 'foo' is selected\n    // and will fill the gap before 'bar'.\n    Position startPos = selection.start();\n    Position candidate = startPos.downstream();\n    if (candidate.isCandidate())\n        startPos = candidate;\n    Position endPos = selection.end();\n    candidate = endPos.upstream();\n    if (candidate.isCandidate())\n        endPos = candidate;\n\n    // We can get into a state where the selection endpoints map to the same VisiblePosition when a selection is deleted\n    // because we don't yet notify the FrameSelection of text removal.\n    if (startPos.isNotNull() && endPos.isNotNull() && selection.visibleStart() != selection.visibleEnd()) {\n        RenderObject* startRenderer = startPos.deprecatedNode()->renderer();\n        RenderObject* endRenderer = endPos.deprecatedNode()->renderer();\n        if (startRenderer->view() == view && endRenderer->view() == view)\n            view->setSelection(startRenderer, startPos.deprecatedEditingOffset(), endRenderer, endPos.deprecatedEditingOffset());\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -64,6 +64,7 @@\n     if (startPos.isNotNull() && endPos.isNotNull() && selection.visibleStart() != selection.visibleEnd()) {\n         RenderObject* startRenderer = startPos.deprecatedNode()->renderer();\n         RenderObject* endRenderer = endPos.deprecatedNode()->renderer();\n-        view->setSelection(startRenderer, startPos.deprecatedEditingOffset(), endRenderer, endPos.deprecatedEditingOffset());\n+        if (startRenderer->view() == view && endRenderer->view() == view)\n+            view->setSelection(startRenderer, startPos.deprecatedEditingOffset(), endRenderer, endPos.deprecatedEditingOffset());\n     }\n }",
        "diff_line_info": {
            "deleted_lines": [
                "        view->setSelection(startRenderer, startPos.deprecatedEditingOffset(), endRenderer, endPos.deprecatedEditingOffset());"
            ],
            "added_lines": [
                "        if (startRenderer->view() == view && endRenderer->view() == view)",
                "            view->setSelection(startRenderer, startPos.deprecatedEditingOffset(), endRenderer, endPos.deprecatedEditingOffset());"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-1743",
        "func_name": "chromium/StyleElement::processStyleSheet",
        "description": "Use-after-free vulnerability in the StyleElement::removedFromDocument function in core/dom/StyleElement.cpp in Blink, as used in Google Chrome before 35.0.1916.114, allows remote attackers to cause a denial of service (application crash) or possibly have unspecified other impact via crafted JavaScript code that triggers tree mutation.",
        "git_url": "https://github.com/chromium/chromium/commit/50834550384089500c9e79f3082300b11dc7201c",
        "commit_title": "Make StyleElement robust against tree mutation",
        "commit_text": " It is possible that HTMLStyleElement::removedFrom() is called before HTMLStyleElement::didNotifySubtreeInsertionsToDocument().   ",
        "func_before": "void StyleElement::processStyleSheet(Document& document, Element* element)\n{\n    TRACE_EVENT0(\"webkit\", \"StyleElement::processStyleSheet\");\n    ASSERT(element);\n\n    m_registeredAsCandidate = true;\n    document.styleEngine()->addStyleSheetCandidateNode(element, m_createdByParser);\n    if (m_createdByParser)\n        return;\n\n    process(element);\n}",
        "func": "void StyleElement::processStyleSheet(Document& document, Element* element)\n{\n    TRACE_EVENT0(\"webkit\", \"StyleElement::processStyleSheet\");\n    ASSERT(element);\n    ASSERT(element->inDocument());\n\n    m_registeredAsCandidate = true;\n    document.styleEngine()->addStyleSheetCandidateNode(element, m_createdByParser);\n    if (m_createdByParser)\n        return;\n\n    process(element);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,6 +2,7 @@\n {\n     TRACE_EVENT0(\"webkit\", \"StyleElement::processStyleSheet\");\n     ASSERT(element);\n+    ASSERT(element->inDocument());\n \n     m_registeredAsCandidate = true;\n     document.styleEngine()->addStyleSheetCandidateNode(element, m_createdByParser);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    ASSERT(element->inDocument());"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-1743",
        "func_name": "chromium/StyleElement::removedFromDocument",
        "description": "Use-after-free vulnerability in the StyleElement::removedFromDocument function in core/dom/StyleElement.cpp in Blink, as used in Google Chrome before 35.0.1916.114, allows remote attackers to cause a denial of service (application crash) or possibly have unspecified other impact via crafted JavaScript code that triggers tree mutation.",
        "git_url": "https://github.com/chromium/chromium/commit/50834550384089500c9e79f3082300b11dc7201c",
        "commit_title": "Make StyleElement robust against tree mutation",
        "commit_text": " It is possible that HTMLStyleElement::removedFrom() is called before HTMLStyleElement::didNotifySubtreeInsertionsToDocument().   ",
        "func_before": "void StyleElement::removedFromDocument(Document& document, Element* element, ContainerNode* scopingNode, TreeScope& treeScope)\n{\n    ASSERT(element);\n\n    if (!m_registeredAsCandidate) {\n        ASSERT(!m_sheet);\n        return;\n    }\n\n    document.styleEngine()->removeStyleSheetCandidateNode(element, scopingNode, treeScope);\n    m_registeredAsCandidate = false;\n\n    RefPtrWillBeRawPtr<StyleSheet> removedSheet = m_sheet.get();\n\n    if (m_sheet)\n        clearSheet(element);\n\n    document.removedStyleSheet(removedSheet.get(), RecalcStyleDeferred, AnalyzedStyleUpdate);\n}",
        "func": "void StyleElement::removedFromDocument(Document& document, Element* element, ContainerNode* scopingNode, TreeScope& treeScope)\n{\n    ASSERT(element);\n\n    if (m_registeredAsCandidate) {\n        document.styleEngine()->removeStyleSheetCandidateNode(element, scopingNode, treeScope);\n        m_registeredAsCandidate = false;\n    }\n\n    RefPtrWillBeRawPtr<StyleSheet> removedSheet = m_sheet.get();\n\n    if (m_sheet)\n        clearSheet(element);\n    if (removedSheet)\n        document.removedStyleSheet(removedSheet.get(), RecalcStyleDeferred, AnalyzedStyleUpdate);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,18 +2,15 @@\n {\n     ASSERT(element);\n \n-    if (!m_registeredAsCandidate) {\n-        ASSERT(!m_sheet);\n-        return;\n+    if (m_registeredAsCandidate) {\n+        document.styleEngine()->removeStyleSheetCandidateNode(element, scopingNode, treeScope);\n+        m_registeredAsCandidate = false;\n     }\n-\n-    document.styleEngine()->removeStyleSheetCandidateNode(element, scopingNode, treeScope);\n-    m_registeredAsCandidate = false;\n \n     RefPtrWillBeRawPtr<StyleSheet> removedSheet = m_sheet.get();\n \n     if (m_sheet)\n         clearSheet(element);\n-\n-    document.removedStyleSheet(removedSheet.get(), RecalcStyleDeferred, AnalyzedStyleUpdate);\n+    if (removedSheet)\n+        document.removedStyleSheet(removedSheet.get(), RecalcStyleDeferred, AnalyzedStyleUpdate);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    if (!m_registeredAsCandidate) {",
                "        ASSERT(!m_sheet);",
                "        return;",
                "",
                "    document.styleEngine()->removeStyleSheetCandidateNode(element, scopingNode, treeScope);",
                "    m_registeredAsCandidate = false;",
                "",
                "    document.removedStyleSheet(removedSheet.get(), RecalcStyleDeferred, AnalyzedStyleUpdate);"
            ],
            "added_lines": [
                "    if (m_registeredAsCandidate) {",
                "        document.styleEngine()->removeStyleSheetCandidateNode(element, scopingNode, treeScope);",
                "        m_registeredAsCandidate = false;",
                "    if (removedSheet)",
                "        document.removedStyleSheet(removedSheet.get(), RecalcStyleDeferred, AnalyzedStyleUpdate);"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-1745",
        "func_name": "chromium/RenderSVGText::layout",
        "description": "Use-after-free vulnerability in the SVG implementation in Blink, as used in Google Chrome before 35.0.1916.114, allows remote attackers to cause a denial of service or possibly have unspecified other impact via vectors that trigger removal of an SVGFontFaceElement object, related to core/svg/SVGFontFaceElement.cpp.",
        "git_url": "https://github.com/chromium/chromium/commit/9f88c15fbcd76321cfeedf3f4792534cb6041c4e",
        "commit_title": "Fix crash in SVGFontFaceElement::associatedFontElement crash when removing SVGFontFaceElement.",
        "commit_text": " (1) We need to remove its font-face rule from FontCache when removing SVGFontFaceElement,  (2) We should not use old styles in RenderSVGInlineText::styleDidChange. Since styleRecalc is done in document-order, we cannot see any styles of next renderer (obtained by nextInPreOrder). The old styles might have old fonts which are created by SVGFontFaceElement.   ",
        "func_before": "void RenderSVGText::layout()\n{\n    ASSERT(needsLayout());\n    LayoutRectRecorder recorder(*this);\n    LayoutRepainter repainter(*this, SVGRenderSupport::checkForSVGRepaintDuringLayout(this));\n\n    bool updateCachedBoundariesInParents = false;\n    if (m_needsTransformUpdate) {\n        m_localTransform = toSVGTextElement(node())->animatedLocalTransform();\n        m_needsTransformUpdate = false;\n        updateCachedBoundariesInParents = true;\n    }\n\n    if (!everHadLayout()) {\n        // When laying out initially, collect all layout attributes, build the character data map,\n        // and propogate resulting SVGLayoutAttributes to all RenderSVGInlineText children in the subtree.\n        ASSERT(m_layoutAttributes.isEmpty());\n        collectLayoutAttributes(this, m_layoutAttributes);\n        updateFontInAllDescendants(this);\n        m_layoutAttributesBuilder.buildLayoutAttributesForForSubtree(this);\n\n        m_needsReordering = true;\n        m_needsTextMetricsUpdate = false;\n        m_needsPositioningValuesUpdate = false;\n        updateCachedBoundariesInParents = true;\n    } else if (m_needsPositioningValuesUpdate) {\n        // When the x/y/dx/dy/rotate lists change, recompute the layout attributes, and eventually\n        // update the on-screen font objects as well in all descendants.\n        if (m_needsTextMetricsUpdate) {\n            updateFontInAllDescendants(this);\n            m_needsTextMetricsUpdate = false;\n        }\n\n        m_layoutAttributesBuilder.buildLayoutAttributesForForSubtree(this);\n        m_needsReordering = true;\n        m_needsPositioningValuesUpdate = false;\n        updateCachedBoundariesInParents = true;\n    } else if (m_needsTextMetricsUpdate || SVGRenderSupport::findTreeRootObject(this)->isLayoutSizeChanged()) {\n        // If the root layout size changed (eg. window size changes) or the transform to the root\n        // context has changed then recompute the on-screen font size.\n        updateFontInAllDescendants(this, &m_layoutAttributesBuilder);\n\n        ASSERT(!m_needsReordering);\n        ASSERT(!m_needsPositioningValuesUpdate);\n        m_needsTextMetricsUpdate = false;\n        updateCachedBoundariesInParents = true;\n    }\n\n    checkLayoutAttributesConsistency(this, m_layoutAttributes);\n\n    // Reduced version of RenderBlock::layoutBlock(), which only takes care of SVG text.\n    // All if branches that could cause early exit in RenderBlocks layoutBlock() method are turned into assertions.\n    ASSERT(!isInline());\n    ASSERT(!simplifiedLayout());\n    ASSERT(!scrollsOverflow());\n    ASSERT(!hasControlClip());\n    ASSERT(!hasColumns());\n    ASSERT(!positionedObjects());\n    ASSERT(!m_overflow);\n    ASSERT(!isAnonymousBlock());\n\n    if (!firstChild())\n        setChildrenInline(true);\n\n    // FIXME: We need to find a way to only layout the child boxes, if needed.\n    FloatRect oldBoundaries = objectBoundingBox();\n    ASSERT(childrenInline());\n\n    rebuildFloatsFromIntruding();\n\n    LayoutUnit beforeEdge = borderBefore() + paddingBefore();\n    LayoutUnit afterEdge = borderAfter() + paddingAfter() + scrollbarLogicalHeight();\n    setLogicalHeight(beforeEdge);\n\n    LayoutUnit repaintLogicalTop = 0;\n    LayoutUnit repaintLogicalBottom = 0;\n    layoutInlineChildren(true, repaintLogicalTop, repaintLogicalBottom, afterEdge);\n\n    if (m_needsReordering)\n        m_needsReordering = false;\n\n    if (!updateCachedBoundariesInParents)\n        updateCachedBoundariesInParents = oldBoundaries != objectBoundingBox();\n\n    // Invalidate all resources of this client if our layout changed.\n    if (everHadLayout() && selfNeedsLayout())\n        SVGResourcesCache::clientLayoutChanged(this);\n\n    // If our bounds changed, notify the parents.\n    if (updateCachedBoundariesInParents)\n        RenderSVGBlock::setNeedsBoundariesUpdate();\n\n    repainter.repaintAfterLayout();\n    clearNeedsLayout();\n}",
        "func": "void RenderSVGText::layout()\n{\n    ASSERT(needsLayout());\n\n    subtreeStyleDidChange();\n\n    LayoutRectRecorder recorder(*this);\n    LayoutRepainter repainter(*this, SVGRenderSupport::checkForSVGRepaintDuringLayout(this));\n\n    bool updateCachedBoundariesInParents = false;\n    if (m_needsTransformUpdate) {\n        m_localTransform = toSVGTextElement(node())->animatedLocalTransform();\n        m_needsTransformUpdate = false;\n        updateCachedBoundariesInParents = true;\n    }\n\n    if (!everHadLayout()) {\n        // When laying out initially, collect all layout attributes, build the character data map,\n        // and propogate resulting SVGLayoutAttributes to all RenderSVGInlineText children in the subtree.\n        ASSERT(m_layoutAttributes.isEmpty());\n        collectLayoutAttributes(this, m_layoutAttributes);\n        updateFontInAllDescendants(this);\n        m_layoutAttributesBuilder.buildLayoutAttributesForForSubtree(this);\n\n        m_needsReordering = true;\n        m_needsTextMetricsUpdate = false;\n        m_needsPositioningValuesUpdate = false;\n        updateCachedBoundariesInParents = true;\n    } else if (m_needsPositioningValuesUpdate) {\n        // When the x/y/dx/dy/rotate lists change, recompute the layout attributes, and eventually\n        // update the on-screen font objects as well in all descendants.\n        if (m_needsTextMetricsUpdate) {\n            updateFontInAllDescendants(this);\n            m_needsTextMetricsUpdate = false;\n        }\n\n        m_layoutAttributesBuilder.buildLayoutAttributesForForSubtree(this);\n        m_needsReordering = true;\n        m_needsPositioningValuesUpdate = false;\n        updateCachedBoundariesInParents = true;\n    } else if (m_needsTextMetricsUpdate || SVGRenderSupport::findTreeRootObject(this)->isLayoutSizeChanged()) {\n        // If the root layout size changed (eg. window size changes) or the transform to the root\n        // context has changed then recompute the on-screen font size.\n        updateFontInAllDescendants(this, &m_layoutAttributesBuilder);\n\n        ASSERT(!m_needsReordering);\n        ASSERT(!m_needsPositioningValuesUpdate);\n        m_needsTextMetricsUpdate = false;\n        updateCachedBoundariesInParents = true;\n    }\n\n    checkLayoutAttributesConsistency(this, m_layoutAttributes);\n\n    // Reduced version of RenderBlock::layoutBlock(), which only takes care of SVG text.\n    // All if branches that could cause early exit in RenderBlocks layoutBlock() method are turned into assertions.\n    ASSERT(!isInline());\n    ASSERT(!simplifiedLayout());\n    ASSERT(!scrollsOverflow());\n    ASSERT(!hasControlClip());\n    ASSERT(!hasColumns());\n    ASSERT(!positionedObjects());\n    ASSERT(!m_overflow);\n    ASSERT(!isAnonymousBlock());\n\n    if (!firstChild())\n        setChildrenInline(true);\n\n    // FIXME: We need to find a way to only layout the child boxes, if needed.\n    FloatRect oldBoundaries = objectBoundingBox();\n    ASSERT(childrenInline());\n\n    rebuildFloatsFromIntruding();\n\n    LayoutUnit beforeEdge = borderBefore() + paddingBefore();\n    LayoutUnit afterEdge = borderAfter() + paddingAfter() + scrollbarLogicalHeight();\n    setLogicalHeight(beforeEdge);\n\n    LayoutUnit repaintLogicalTop = 0;\n    LayoutUnit repaintLogicalBottom = 0;\n    layoutInlineChildren(true, repaintLogicalTop, repaintLogicalBottom, afterEdge);\n\n    if (m_needsReordering)\n        m_needsReordering = false;\n\n    if (!updateCachedBoundariesInParents)\n        updateCachedBoundariesInParents = oldBoundaries != objectBoundingBox();\n\n    // Invalidate all resources of this client if our layout changed.\n    if (everHadLayout() && selfNeedsLayout())\n        SVGResourcesCache::clientLayoutChanged(this);\n\n    // If our bounds changed, notify the parents.\n    if (updateCachedBoundariesInParents)\n        RenderSVGBlock::setNeedsBoundariesUpdate();\n\n    repainter.repaintAfterLayout();\n    clearNeedsLayout();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,9 @@\n void RenderSVGText::layout()\n {\n     ASSERT(needsLayout());\n+\n+    subtreeStyleDidChange();\n+\n     LayoutRectRecorder recorder(*this);\n     LayoutRepainter repainter(*this, SVGRenderSupport::checkForSVGRepaintDuringLayout(this));\n ",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "    subtreeStyleDidChange();",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2014-1745",
        "func_name": "chromium/RenderSVGText::subtreeStyleDidChange",
        "description": "Use-after-free vulnerability in the SVG implementation in Blink, as used in Google Chrome before 35.0.1916.114, allows remote attackers to cause a denial of service or possibly have unspecified other impact via vectors that trigger removal of an SVGFontFaceElement object, related to core/svg/SVGFontFaceElement.cpp.",
        "git_url": "https://github.com/chromium/chromium/commit/9f88c15fbcd76321cfeedf3f4792534cb6041c4e",
        "commit_title": "Fix crash in SVGFontFaceElement::associatedFontElement crash when removing SVGFontFaceElement.",
        "commit_text": " (1) We need to remove its font-face rule from FontCache when removing SVGFontFaceElement,  (2) We should not use old styles in RenderSVGInlineText::styleDidChange. Since styleRecalc is done in document-order, we cannot see any styles of next renderer (obtained by nextInPreOrder). The old styles might have old fonts which are created by SVGFontFaceElement.   ",
        "func_before": "void RenderSVGText::subtreeStyleDidChange(RenderSVGInlineText* text)\n{\n    ASSERT(text);\n    if (!shouldHandleSubtreeMutations() || documentBeingDestroyed())\n        return;\n\n    checkLayoutAttributesConsistency(this, m_layoutAttributes);\n\n    // Only update the metrics cache, but not the text positioning element cache\n    // nor the layout attributes cached in the leaf #text renderers.\n    FontCachePurgePreventer fontCachePurgePreventer;\n    for (RenderObject* descendant = text; descendant; descendant = descendant->nextInPreOrder(text)) {\n        if (descendant->isSVGInlineText())\n            m_layoutAttributesBuilder.rebuildMetricsForTextRenderer(toRenderSVGInlineText(descendant));\n    }\n}",
        "func": "void RenderSVGText::subtreeStyleDidChange()\n{\n    if (!shouldHandleSubtreeMutations() || documentBeingDestroyed())\n        return;\n\n    checkLayoutAttributesConsistency(this, m_layoutAttributes);\n\n    // Only update the metrics cache, but not the text positioning element cache\n    // nor the layout attributes cached in the leaf #text renderers.\n    FontCachePurgePreventer fontCachePurgePreventer;\n    for (RenderObject* descendant = firstChild(); descendant; descendant = descendant->nextInPreOrder(this)) {\n        if (descendant->isSVGInlineText())\n            m_layoutAttributesBuilder.rebuildMetricsForTextRenderer(toRenderSVGInlineText(descendant));\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,5 @@\n-void RenderSVGText::subtreeStyleDidChange(RenderSVGInlineText* text)\n+void RenderSVGText::subtreeStyleDidChange()\n {\n-    ASSERT(text);\n     if (!shouldHandleSubtreeMutations() || documentBeingDestroyed())\n         return;\n \n@@ -9,7 +8,7 @@\n     // Only update the metrics cache, but not the text positioning element cache\n     // nor the layout attributes cached in the leaf #text renderers.\n     FontCachePurgePreventer fontCachePurgePreventer;\n-    for (RenderObject* descendant = text; descendant; descendant = descendant->nextInPreOrder(text)) {\n+    for (RenderObject* descendant = firstChild(); descendant; descendant = descendant->nextInPreOrder(this)) {\n         if (descendant->isSVGInlineText())\n             m_layoutAttributesBuilder.rebuildMetricsForTextRenderer(toRenderSVGInlineText(descendant));\n     }",
        "diff_line_info": {
            "deleted_lines": [
                "void RenderSVGText::subtreeStyleDidChange(RenderSVGInlineText* text)",
                "    ASSERT(text);",
                "    for (RenderObject* descendant = text; descendant; descendant = descendant->nextInPreOrder(text)) {"
            ],
            "added_lines": [
                "void RenderSVGText::subtreeStyleDidChange()",
                "    for (RenderObject* descendant = firstChild(); descendant; descendant = descendant->nextInPreOrder(this)) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-1745",
        "func_name": "chromium/RenderSVGInlineText::styleDidChange",
        "description": "Use-after-free vulnerability in the SVG implementation in Blink, as used in Google Chrome before 35.0.1916.114, allows remote attackers to cause a denial of service or possibly have unspecified other impact via vectors that trigger removal of an SVGFontFaceElement object, related to core/svg/SVGFontFaceElement.cpp.",
        "git_url": "https://github.com/chromium/chromium/commit/9f88c15fbcd76321cfeedf3f4792534cb6041c4e",
        "commit_title": "Fix crash in SVGFontFaceElement::associatedFontElement crash when removing SVGFontFaceElement.",
        "commit_text": " (1) We need to remove its font-face rule from FontCache when removing SVGFontFaceElement,  (2) We should not use old styles in RenderSVGInlineText::styleDidChange. Since styleRecalc is done in document-order, we cannot see any styles of next renderer (obtained by nextInPreOrder). The old styles might have old fonts which are created by SVGFontFaceElement.   ",
        "func_before": "void RenderSVGInlineText::styleDidChange(StyleDifference diff, const RenderStyle* oldStyle)\n{\n    RenderText::styleDidChange(diff, oldStyle);\n    updateScaledFont();\n\n    bool newPreserves = style() ? style()->whiteSpace() == PRE : false;\n    bool oldPreserves = oldStyle ? oldStyle->whiteSpace() == PRE : false;\n    if (oldPreserves && !newPreserves) {\n        setText(applySVGWhitespaceRules(originalText(), false), true);\n        return;\n    }\n\n    if (!oldPreserves && newPreserves) {\n        setText(applySVGWhitespaceRules(originalText(), true), true);\n        return;\n    }\n\n    if (diff != StyleDifferenceLayout)\n        return;\n\n    // The text metrics may be influenced by style changes.\n    if (RenderSVGText* textRenderer = RenderSVGText::locateRenderSVGTextAncestor(this))\n        textRenderer->subtreeStyleDidChange(this);\n}",
        "func": "void RenderSVGInlineText::styleDidChange(StyleDifference diff, const RenderStyle* oldStyle)\n{\n    RenderText::styleDidChange(diff, oldStyle);\n    updateScaledFont();\n\n    bool newPreserves = style() ? style()->whiteSpace() == PRE : false;\n    bool oldPreserves = oldStyle ? oldStyle->whiteSpace() == PRE : false;\n    if (oldPreserves && !newPreserves) {\n        setText(applySVGWhitespaceRules(originalText(), false), true);\n        return;\n    }\n\n    if (!oldPreserves && newPreserves) {\n        setText(applySVGWhitespaceRules(originalText(), true), true);\n        return;\n    }\n\n    if (diff != StyleDifferenceLayout)\n        return;\n\n    // The text metrics may be influenced by style changes.\n    if (RenderSVGText* textRenderer = RenderSVGText::locateRenderSVGTextAncestor(this))\n        textRenderer->setNeedsLayout();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -20,5 +20,5 @@\n \n     // The text metrics may be influenced by style changes.\n     if (RenderSVGText* textRenderer = RenderSVGText::locateRenderSVGTextAncestor(this))\n-        textRenderer->subtreeStyleDidChange(this);\n+        textRenderer->setNeedsLayout();\n }",
        "diff_line_info": {
            "deleted_lines": [
                "        textRenderer->subtreeStyleDidChange(this);"
            ],
            "added_lines": [
                "        textRenderer->setNeedsLayout();"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-1745",
        "func_name": "chromium/SVGFontFaceElement::removedFrom",
        "description": "Use-after-free vulnerability in the SVG implementation in Blink, as used in Google Chrome before 35.0.1916.114, allows remote attackers to cause a denial of service or possibly have unspecified other impact via vectors that trigger removal of an SVGFontFaceElement object, related to core/svg/SVGFontFaceElement.cpp.",
        "git_url": "https://github.com/chromium/chromium/commit/9f88c15fbcd76321cfeedf3f4792534cb6041c4e",
        "commit_title": "Fix crash in SVGFontFaceElement::associatedFontElement crash when removing SVGFontFaceElement.",
        "commit_text": " (1) We need to remove its font-face rule from FontCache when removing SVGFontFaceElement,  (2) We should not use old styles in RenderSVGInlineText::styleDidChange. Since styleRecalc is done in document-order, we cannot see any styles of next renderer (obtained by nextInPreOrder). The old styles might have old fonts which are created by SVGFontFaceElement.   ",
        "func_before": "void SVGFontFaceElement::removedFrom(ContainerNode* rootParent)\n{\n    SVGElement::removedFrom(rootParent);\n\n    if (rootParent->inDocument()) {\n        m_fontElement = 0;\n        document().accessSVGExtensions().unregisterSVGFontFaceElement(this);\n        m_fontFaceRule->mutableProperties()->clear();\n\n        document().styleResolverChanged(RecalcStyleDeferred);\n    } else\n        ASSERT(!m_fontElement);\n}",
        "func": "void SVGFontFaceElement::removedFrom(ContainerNode* rootParent)\n{\n    SVGElement::removedFrom(rootParent);\n\n    if (rootParent->inDocument()) {\n        m_fontElement = 0;\n        document().accessSVGExtensions().unregisterSVGFontFaceElement(this);\n        document().styleEngine()->fontSelector()->fontFaceCache()->remove(m_fontFaceRule.get());\n        m_fontFaceRule->mutableProperties()->clear();\n\n        document().styleResolverChanged(RecalcStyleDeferred);\n    } else\n        ASSERT(!m_fontElement);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,6 +5,7 @@\n     if (rootParent->inDocument()) {\n         m_fontElement = 0;\n         document().accessSVGExtensions().unregisterSVGFontFaceElement(this);\n+        document().styleEngine()->fontSelector()->fontFaceCache()->remove(m_fontFaceRule.get());\n         m_fontFaceRule->mutableProperties()->clear();\n \n         document().styleResolverChanged(RecalcStyleDeferred);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "        document().styleEngine()->fontSelector()->fontFaceCache()->remove(m_fontFaceRule.get());"
            ]
        }
    },
    {
        "cve_id": "CVE-2011-2198",
        "func_name": "GNOME/vte/vte_sequence_handler_IC",
        "description": "The \"insert-blank-characters\" capability in caps.c in gnome-terminal (vte) before 0.28.1 allows remote authenticated users to cause a denial of service (CPU and memory consumption and crash) via a crafted file, as demonstrated by a file containing the string \"\\033[100000000000000000@\".",
        "git_url": "https://github.com/GNOME/vte/commit/ac71d26f067be3a21bff315c3cabf24c94360dd6",
        "commit_title": "[CVE-2011-2198] Limit insert-blank-characters",
        "commit_text": " Bug #652124.",
        "func_before": "static void\nvte_sequence_handler_IC (VteTerminal *terminal, GValueArray *params)\n{\n\tvte_sequence_handler_multiple(terminal, params, vte_sequence_handler_ic);\n}",
        "func": "static void\nvte_sequence_handler_IC (VteTerminal *terminal, GValueArray *params)\n{\n\tvte_sequence_handler_multiple_r(terminal, params, vte_sequence_handler_ic);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,5 @@\n static void\n vte_sequence_handler_IC (VteTerminal *terminal, GValueArray *params)\n {\n-\tvte_sequence_handler_multiple(terminal, params, vte_sequence_handler_ic);\n+\tvte_sequence_handler_multiple_r(terminal, params, vte_sequence_handler_ic);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tvte_sequence_handler_multiple(terminal, params, vte_sequence_handler_ic);"
            ],
            "added_lines": [
                "\tvte_sequence_handler_multiple_r(terminal, params, vte_sequence_handler_ic);"
            ]
        }
    },
    {
        "cve_id": "CVE-2011-2198",
        "func_name": "GNOME/vte/vte_sequence_handler_multiple",
        "description": "The \"insert-blank-characters\" capability in caps.c in gnome-terminal (vte) before 0.28.1 allows remote authenticated users to cause a denial of service (CPU and memory consumption and crash) via a crafted file, as demonstrated by a file containing the string \"\\033[100000000000000000@\".",
        "git_url": "https://github.com/GNOME/vte/commit/ac71d26f067be3a21bff315c3cabf24c94360dd6",
        "commit_title": "[CVE-2011-2198] Limit insert-blank-characters",
        "commit_text": " Bug #652124.",
        "func_before": "static void\nvte_sequence_handler_multiple(VteTerminal *terminal,\n\t\t\t      GValueArray *params,\n\t\t\t      VteTerminalSequenceHandler handler)\n{\n\tlong val = 1;\n\tint i;\n\tGValue *value;\n\n\tif ((params != NULL) && (params->n_values > 0)) {\n\t\tvalue = g_value_array_get_nth(params, 0);\n\t\tif (G_VALUE_HOLDS_LONG(value)) {\n\t\t\tval = g_value_get_long(value);\n\t\t\tval = MAX(val, 1);\t/* FIXME: vttest. */\n\t\t}\n\t}\n\tfor (i = 0; i < val; i++)\n\t\thandler (terminal, NULL);\n}",
        "func": "static void\nvte_sequence_handler_multiple(VteTerminal *terminal,\n                              GValueArray *params,\n                              VteTerminalSequenceHandler handler)\n{\n        vte_sequence_handler_multiple_limited(terminal, params, handler, G_MAXLONG);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,19 +1,7 @@\n static void\n vte_sequence_handler_multiple(VteTerminal *terminal,\n-\t\t\t      GValueArray *params,\n-\t\t\t      VteTerminalSequenceHandler handler)\n+                              GValueArray *params,\n+                              VteTerminalSequenceHandler handler)\n {\n-\tlong val = 1;\n-\tint i;\n-\tGValue *value;\n-\n-\tif ((params != NULL) && (params->n_values > 0)) {\n-\t\tvalue = g_value_array_get_nth(params, 0);\n-\t\tif (G_VALUE_HOLDS_LONG(value)) {\n-\t\t\tval = g_value_get_long(value);\n-\t\t\tval = MAX(val, 1);\t/* FIXME: vttest. */\n-\t\t}\n-\t}\n-\tfor (i = 0; i < val; i++)\n-\t\thandler (terminal, NULL);\n+        vte_sequence_handler_multiple_limited(terminal, params, handler, G_MAXLONG);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\t      GValueArray *params,",
                "\t\t\t      VteTerminalSequenceHandler handler)",
                "\tlong val = 1;",
                "\tint i;",
                "\tGValue *value;",
                "",
                "\tif ((params != NULL) && (params->n_values > 0)) {",
                "\t\tvalue = g_value_array_get_nth(params, 0);",
                "\t\tif (G_VALUE_HOLDS_LONG(value)) {",
                "\t\t\tval = g_value_get_long(value);",
                "\t\t\tval = MAX(val, 1);\t/* FIXME: vttest. */",
                "\t\t}",
                "\t}",
                "\tfor (i = 0; i < val; i++)",
                "\t\thandler (terminal, NULL);"
            ],
            "added_lines": [
                "                              GValueArray *params,",
                "                              VteTerminalSequenceHandler handler)",
                "        vte_sequence_handler_multiple_limited(terminal, params, handler, G_MAXLONG);"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-0237",
        "func_name": "php/php-src/cdf_unpack_summary_info",
        "description": "The cdf_unpack_summary_info function in cdf.c in the Fileinfo component in PHP before 5.4.29 and 5.5.x before 5.5.13 allows remote attackers to cause a denial of service (performance degradation) by triggering many file_printf calls.",
        "git_url": "https://github.com/php/php-src/commit/68ce2d0ea6da79b12a365e375e1c2ce882c77480",
        "commit_title": "Fix bug #67328 (fileinfo: numerous file_printf calls resulting in performance degradation)",
        "commit_text": " Upstream patch: https://github.com/file/file/commit/b8acc83781d5a24cc5101e525d15efe0482c280d",
        "func_before": "int\ncdf_unpack_summary_info(const cdf_stream_t *sst, const cdf_header_t *h,\n    cdf_summary_info_header_t *ssi, cdf_property_info_t **info, size_t *count)\n{\n\tsize_t i, maxcount;\n\tconst cdf_summary_info_header_t *si =\n\t    CAST(const cdf_summary_info_header_t *, sst->sst_tab);\n\tconst cdf_section_declaration_t *sd =\n\t    CAST(const cdf_section_declaration_t *, (const void *)\n\t    ((const char *)sst->sst_tab + CDF_SECTION_DECLARATION_OFFSET));\n\n\tif (cdf_check_stream_offset(sst, h, si, sizeof(*si), __LINE__) == -1 ||\n\t    cdf_check_stream_offset(sst, h, sd, sizeof(*sd), __LINE__) == -1)\n\t\treturn -1;\n\tssi->si_byte_order = CDF_TOLE2(si->si_byte_order);\n\tssi->si_os_version = CDF_TOLE2(si->si_os_version);\n\tssi->si_os = CDF_TOLE2(si->si_os);\n\tssi->si_class = si->si_class;\n\tcdf_swap_class(&ssi->si_class);\n\tssi->si_count = CDF_TOLE2(si->si_count);\n\t*count = 0;\n\tmaxcount = 0;\n\t*info = NULL;\n\tfor (i = 0; i < CDF_TOLE4(si->si_count); i++) {\n\t\tif (i >= CDF_LOOP_LIMIT) {\n\t\t\tDPRINTF((\"Unpack summary info loop limit\"));\n\t\t\terrno = EFTYPE;\n\t\t\treturn -1;\n\t\t}\n\t\tif (cdf_read_property_info(sst, h, CDF_TOLE4(sd->sd_offset),\n\t\t    info, count, &maxcount) == -1) {\n\t\t\treturn -1;\n\t\t}\n\t}\n\treturn 0;\n}",
        "func": "int\ncdf_unpack_summary_info(const cdf_stream_t *sst, const cdf_header_t *h,\n    cdf_summary_info_header_t *ssi, cdf_property_info_t **info, size_t *count)\n{\n\tsize_t maxcount;\n\tconst cdf_summary_info_header_t *si =\n\t    CAST(const cdf_summary_info_header_t *, sst->sst_tab);\n\tconst cdf_section_declaration_t *sd =\n\t    CAST(const cdf_section_declaration_t *, (const void *)\n\t    ((const char *)sst->sst_tab + CDF_SECTION_DECLARATION_OFFSET));\n\n\tif (cdf_check_stream_offset(sst, h, si, sizeof(*si), __LINE__) == -1 ||\n\t    cdf_check_stream_offset(sst, h, sd, sizeof(*sd), __LINE__) == -1)\n\t\treturn -1;\n\tssi->si_byte_order = CDF_TOLE2(si->si_byte_order);\n\tssi->si_os_version = CDF_TOLE2(si->si_os_version);\n\tssi->si_os = CDF_TOLE2(si->si_os);\n\tssi->si_class = si->si_class;\n\tcdf_swap_class(&ssi->si_class);\n\tssi->si_count = CDF_TOLE4(si->si_count);\n\t*count = 0;\n\tmaxcount = 0;\n\t*info = NULL;\n\tif (cdf_read_property_info(sst, h, CDF_TOLE4(sd->sd_offset), info,\n\t\tcount, &maxcount) == -1) \n\t\t\treturn -1;\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,7 +2,7 @@\n cdf_unpack_summary_info(const cdf_stream_t *sst, const cdf_header_t *h,\n     cdf_summary_info_header_t *ssi, cdf_property_info_t **info, size_t *count)\n {\n-\tsize_t i, maxcount;\n+\tsize_t maxcount;\n \tconst cdf_summary_info_header_t *si =\n \t    CAST(const cdf_summary_info_header_t *, sst->sst_tab);\n \tconst cdf_section_declaration_t *sd =\n@@ -17,20 +17,12 @@\n \tssi->si_os = CDF_TOLE2(si->si_os);\n \tssi->si_class = si->si_class;\n \tcdf_swap_class(&ssi->si_class);\n-\tssi->si_count = CDF_TOLE2(si->si_count);\n+\tssi->si_count = CDF_TOLE4(si->si_count);\n \t*count = 0;\n \tmaxcount = 0;\n \t*info = NULL;\n-\tfor (i = 0; i < CDF_TOLE4(si->si_count); i++) {\n-\t\tif (i >= CDF_LOOP_LIMIT) {\n-\t\t\tDPRINTF((\"Unpack summary info loop limit\"));\n-\t\t\terrno = EFTYPE;\n+\tif (cdf_read_property_info(sst, h, CDF_TOLE4(sd->sd_offset), info,\n+\t\tcount, &maxcount) == -1) \n \t\t\treturn -1;\n-\t\t}\n-\t\tif (cdf_read_property_info(sst, h, CDF_TOLE4(sd->sd_offset),\n-\t\t    info, count, &maxcount) == -1) {\n-\t\t\treturn -1;\n-\t\t}\n-\t}\n \treturn 0;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tsize_t i, maxcount;",
                "\tssi->si_count = CDF_TOLE2(si->si_count);",
                "\tfor (i = 0; i < CDF_TOLE4(si->si_count); i++) {",
                "\t\tif (i >= CDF_LOOP_LIMIT) {",
                "\t\t\tDPRINTF((\"Unpack summary info loop limit\"));",
                "\t\t\terrno = EFTYPE;",
                "\t\t}",
                "\t\tif (cdf_read_property_info(sst, h, CDF_TOLE4(sd->sd_offset),",
                "\t\t    info, count, &maxcount) == -1) {",
                "\t\t\treturn -1;",
                "\t\t}",
                "\t}"
            ],
            "added_lines": [
                "\tsize_t maxcount;",
                "\tssi->si_count = CDF_TOLE4(si->si_count);",
                "\tif (cdf_read_property_info(sst, h, CDF_TOLE4(sd->sd_offset), info,",
                "\t\tcount, &maxcount) == -1) "
            ]
        }
    },
    {
        "cve_id": "CVE-2014-0237",
        "func_name": "php/php-src/cdf_unpack_summary_info",
        "description": "The cdf_unpack_summary_info function in cdf.c in the Fileinfo component in PHP before 5.4.29 and 5.5.x before 5.5.13 allows remote attackers to cause a denial of service (performance degradation) by triggering many file_printf calls.",
        "git_url": "https://github.com/php/php-src/commit/ee1ab627639b2b6f8da00c687eb2386f93ec2ef6",
        "commit_title": "Fix bug #67328 (fileinfo: numerous file_printf calls resulting in performance degradation)",
        "commit_text": " Upstream patch: https://github.com/file/file/commit/b8acc83781d5a24cc5101e525d15efe0482c280d",
        "func_before": "int\ncdf_unpack_summary_info(const cdf_stream_t *sst, const cdf_header_t *h,\n    cdf_summary_info_header_t *ssi, cdf_property_info_t **info, size_t *count)\n{\n\tsize_t i, maxcount;\n\tconst cdf_summary_info_header_t *si =\n\t    CAST(const cdf_summary_info_header_t *, sst->sst_tab);\n\tconst cdf_section_declaration_t *sd =\n\t    CAST(const cdf_section_declaration_t *, (const void *)\n\t    ((const char *)sst->sst_tab + CDF_SECTION_DECLARATION_OFFSET));\n\n\tif (cdf_check_stream_offset(sst, h, si, sizeof(*si), __LINE__) == -1 ||\n\t    cdf_check_stream_offset(sst, h, sd, sizeof(*sd), __LINE__) == -1)\n\t\treturn -1;\n\tssi->si_byte_order = CDF_TOLE2(si->si_byte_order);\n\tssi->si_os_version = CDF_TOLE2(si->si_os_version);\n\tssi->si_os = CDF_TOLE2(si->si_os);\n\tssi->si_class = si->si_class;\n\tcdf_swap_class(&ssi->si_class);\n\tssi->si_count = CDF_TOLE2(si->si_count);\n\t*count = 0;\n\tmaxcount = 0;\n\t*info = NULL;\n\tfor (i = 0; i < CDF_TOLE4(si->si_count); i++) {\n\t\tif (i >= CDF_LOOP_LIMIT) {\n\t\t\tDPRINTF((\"Unpack summary info loop limit\"));\n\t\t\terrno = EFTYPE;\n\t\t\treturn -1;\n\t\t}\n\t\tif (cdf_read_property_info(sst, h, CDF_TOLE4(sd->sd_offset),\n\t\t    info, count, &maxcount) == -1) {\n\t\t\treturn -1;\n\t\t}\n\t}\n\treturn 0;\n}",
        "func": "int\ncdf_unpack_summary_info(const cdf_stream_t *sst, const cdf_header_t *h,\n    cdf_summary_info_header_t *ssi, cdf_property_info_t **info, size_t *count)\n{\n\tsize_t maxcount;\n\tconst cdf_summary_info_header_t *si =\n\t    CAST(const cdf_summary_info_header_t *, sst->sst_tab);\n\tconst cdf_section_declaration_t *sd =\n\t    CAST(const cdf_section_declaration_t *, (const void *)\n\t    ((const char *)sst->sst_tab + CDF_SECTION_DECLARATION_OFFSET));\n\n\tif (cdf_check_stream_offset(sst, h, si, sizeof(*si), __LINE__) == -1 ||\n\t    cdf_check_stream_offset(sst, h, sd, sizeof(*sd), __LINE__) == -1)\n\t\treturn -1;\n\tssi->si_byte_order = CDF_TOLE2(si->si_byte_order);\n\tssi->si_os_version = CDF_TOLE2(si->si_os_version);\n\tssi->si_os = CDF_TOLE2(si->si_os);\n\tssi->si_class = si->si_class;\n\tcdf_swap_class(&ssi->si_class);\n\tssi->si_count = CDF_TOLE4(si->si_count);\n\t*count = 0;\n\tmaxcount = 0;\n\t*info = NULL;\n\tif (cdf_read_property_info(sst, h, CDF_TOLE4(sd->sd_offset), info,\n\t\tcount, &maxcount) == -1) \n\t\t\treturn -1;\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,7 +2,7 @@\n cdf_unpack_summary_info(const cdf_stream_t *sst, const cdf_header_t *h,\n     cdf_summary_info_header_t *ssi, cdf_property_info_t **info, size_t *count)\n {\n-\tsize_t i, maxcount;\n+\tsize_t maxcount;\n \tconst cdf_summary_info_header_t *si =\n \t    CAST(const cdf_summary_info_header_t *, sst->sst_tab);\n \tconst cdf_section_declaration_t *sd =\n@@ -17,20 +17,12 @@\n \tssi->si_os = CDF_TOLE2(si->si_os);\n \tssi->si_class = si->si_class;\n \tcdf_swap_class(&ssi->si_class);\n-\tssi->si_count = CDF_TOLE2(si->si_count);\n+\tssi->si_count = CDF_TOLE4(si->si_count);\n \t*count = 0;\n \tmaxcount = 0;\n \t*info = NULL;\n-\tfor (i = 0; i < CDF_TOLE4(si->si_count); i++) {\n-\t\tif (i >= CDF_LOOP_LIMIT) {\n-\t\t\tDPRINTF((\"Unpack summary info loop limit\"));\n-\t\t\terrno = EFTYPE;\n+\tif (cdf_read_property_info(sst, h, CDF_TOLE4(sd->sd_offset), info,\n+\t\tcount, &maxcount) == -1) \n \t\t\treturn -1;\n-\t\t}\n-\t\tif (cdf_read_property_info(sst, h, CDF_TOLE4(sd->sd_offset),\n-\t\t    info, count, &maxcount) == -1) {\n-\t\t\treturn -1;\n-\t\t}\n-\t}\n \treturn 0;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tsize_t i, maxcount;",
                "\tssi->si_count = CDF_TOLE2(si->si_count);",
                "\tfor (i = 0; i < CDF_TOLE4(si->si_count); i++) {",
                "\t\tif (i >= CDF_LOOP_LIMIT) {",
                "\t\t\tDPRINTF((\"Unpack summary info loop limit\"));",
                "\t\t\terrno = EFTYPE;",
                "\t\t}",
                "\t\tif (cdf_read_property_info(sst, h, CDF_TOLE4(sd->sd_offset),",
                "\t\t    info, count, &maxcount) == -1) {",
                "\t\t\treturn -1;",
                "\t\t}",
                "\t}"
            ],
            "added_lines": [
                "\tsize_t maxcount;",
                "\tssi->si_count = CDF_TOLE4(si->si_count);",
                "\tif (cdf_read_property_info(sst, h, CDF_TOLE4(sd->sd_offset), info,",
                "\t\tcount, &maxcount) == -1) "
            ]
        }
    },
    {
        "cve_id": "CVE-2014-0237",
        "func_name": "file/cdf_unpack_summary_info",
        "description": "The cdf_unpack_summary_info function in cdf.c in the Fileinfo component in PHP before 5.4.29 and 5.5.x before 5.5.13 allows remote attackers to cause a denial of service (performance degradation) by triggering many file_printf calls.",
        "git_url": "https://github.com/file/file/commit/b8acc83781d5a24cc5101e525d15efe0482c280d",
        "commit_title": "Remove loop that kept reading the same offset (Jan Kaluza)",
        "commit_text": "",
        "func_before": "int\ncdf_unpack_summary_info(const cdf_stream_t *sst, const cdf_header_t *h,\n    cdf_summary_info_header_t *ssi, cdf_property_info_t **info, size_t *count)\n{\n\tsize_t i, maxcount;\n\tconst cdf_summary_info_header_t *si =\n\t    CAST(const cdf_summary_info_header_t *, sst->sst_tab);\n\tconst cdf_section_declaration_t *sd =\n\t    CAST(const cdf_section_declaration_t *, (const void *)\n\t    ((const char *)sst->sst_tab + CDF_SECTION_DECLARATION_OFFSET));\n\n\tif (cdf_check_stream_offset(sst, h, si, sizeof(*si), __LINE__) == -1 ||\n\t    cdf_check_stream_offset(sst, h, sd, sizeof(*sd), __LINE__) == -1)\n\t\treturn -1;\n\tssi->si_byte_order = CDF_TOLE2(si->si_byte_order);\n\tssi->si_os_version = CDF_TOLE2(si->si_os_version);\n\tssi->si_os = CDF_TOLE2(si->si_os);\n\tssi->si_class = si->si_class;\n\tcdf_swap_class(&ssi->si_class);\n\tssi->si_count = CDF_TOLE2(si->si_count);\n\t*count = 0;\n\tmaxcount = 0;\n\t*info = NULL;\n\tfor (i = 0; i < CDF_TOLE4(si->si_count); i++) {\n\t\tif (i >= CDF_LOOP_LIMIT) {\n\t\t\tDPRINTF((\"Unpack summary info loop limit\"));\n\t\t\terrno = EFTYPE;\n\t\t\treturn -1;\n\t\t}\n\t\tif (cdf_read_property_info(sst, h, CDF_TOLE4(sd->sd_offset),\n\t\t    info, count, &maxcount) == -1) {\n\t\t\treturn -1;\n\t\t}\n\t}\n\treturn 0;\n}",
        "func": "int\ncdf_unpack_summary_info(const cdf_stream_t *sst, const cdf_header_t *h,\n    cdf_summary_info_header_t *ssi, cdf_property_info_t **info, size_t *count)\n{\n\tsize_t maxcount;\n\tconst cdf_summary_info_header_t *si =\n\t    CAST(const cdf_summary_info_header_t *, sst->sst_tab);\n\tconst cdf_section_declaration_t *sd =\n\t    CAST(const cdf_section_declaration_t *, (const void *)\n\t    ((const char *)sst->sst_tab + CDF_SECTION_DECLARATION_OFFSET));\n\n\tif (cdf_check_stream_offset(sst, h, si, sizeof(*si), __LINE__) == -1 ||\n\t    cdf_check_stream_offset(sst, h, sd, sizeof(*sd), __LINE__) == -1)\n\t\treturn -1;\n\tssi->si_byte_order = CDF_TOLE2(si->si_byte_order);\n\tssi->si_os_version = CDF_TOLE2(si->si_os_version);\n\tssi->si_os = CDF_TOLE2(si->si_os);\n\tssi->si_class = si->si_class;\n\tcdf_swap_class(&ssi->si_class);\n\tssi->si_count = CDF_TOLE4(si->si_count);\n\t*count = 0;\n\tmaxcount = 0;\n\t*info = NULL;\n\tif (cdf_read_property_info(sst, h, CDF_TOLE4(sd->sd_offset), info,\n\t    count, &maxcount) == -1)\n\t\treturn -1;\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,7 +2,7 @@\n cdf_unpack_summary_info(const cdf_stream_t *sst, const cdf_header_t *h,\n     cdf_summary_info_header_t *ssi, cdf_property_info_t **info, size_t *count)\n {\n-\tsize_t i, maxcount;\n+\tsize_t maxcount;\n \tconst cdf_summary_info_header_t *si =\n \t    CAST(const cdf_summary_info_header_t *, sst->sst_tab);\n \tconst cdf_section_declaration_t *sd =\n@@ -17,20 +17,12 @@\n \tssi->si_os = CDF_TOLE2(si->si_os);\n \tssi->si_class = si->si_class;\n \tcdf_swap_class(&ssi->si_class);\n-\tssi->si_count = CDF_TOLE2(si->si_count);\n+\tssi->si_count = CDF_TOLE4(si->si_count);\n \t*count = 0;\n \tmaxcount = 0;\n \t*info = NULL;\n-\tfor (i = 0; i < CDF_TOLE4(si->si_count); i++) {\n-\t\tif (i >= CDF_LOOP_LIMIT) {\n-\t\t\tDPRINTF((\"Unpack summary info loop limit\"));\n-\t\t\terrno = EFTYPE;\n-\t\t\treturn -1;\n-\t\t}\n-\t\tif (cdf_read_property_info(sst, h, CDF_TOLE4(sd->sd_offset),\n-\t\t    info, count, &maxcount) == -1) {\n-\t\t\treturn -1;\n-\t\t}\n-\t}\n+\tif (cdf_read_property_info(sst, h, CDF_TOLE4(sd->sd_offset), info,\n+\t    count, &maxcount) == -1)\n+\t\treturn -1;\n \treturn 0;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tsize_t i, maxcount;",
                "\tssi->si_count = CDF_TOLE2(si->si_count);",
                "\tfor (i = 0; i < CDF_TOLE4(si->si_count); i++) {",
                "\t\tif (i >= CDF_LOOP_LIMIT) {",
                "\t\t\tDPRINTF((\"Unpack summary info loop limit\"));",
                "\t\t\terrno = EFTYPE;",
                "\t\t\treturn -1;",
                "\t\t}",
                "\t\tif (cdf_read_property_info(sst, h, CDF_TOLE4(sd->sd_offset),",
                "\t\t    info, count, &maxcount) == -1) {",
                "\t\t\treturn -1;",
                "\t\t}",
                "\t}"
            ],
            "added_lines": [
                "\tsize_t maxcount;",
                "\tssi->si_count = CDF_TOLE4(si->si_count);",
                "\tif (cdf_read_property_info(sst, h, CDF_TOLE4(sd->sd_offset), info,",
                "\t    count, &maxcount) == -1)",
                "\t\treturn -1;"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-0237",
        "func_name": "php/php-src/cdf_unpack_summary_info",
        "description": "The cdf_unpack_summary_info function in cdf.c in the Fileinfo component in PHP before 5.4.29 and 5.5.x before 5.5.13 allows remote attackers to cause a denial of service (performance degradation) by triggering many file_printf calls.",
        "git_url": "https://github.com/php/php-src/commit/4005f06df6a0f81f38f02a7afaf0760279a3cd6f",
        "commit_title": "Fix bug #67328 (fileinfo: numerous file_printf calls resulting in performance degradation)",
        "commit_text": " Upstream patch: https://github.com/file/file/commit/b8acc83781d5a24cc5101e525d15efe0482c280d",
        "func_before": "int\ncdf_unpack_summary_info(const cdf_stream_t *sst, const cdf_header_t *h,\n    cdf_summary_info_header_t *ssi, cdf_property_info_t **info, size_t *count)\n{\n\tsize_t i, maxcount;\n\tconst cdf_summary_info_header_t *si =\n\t    CAST(const cdf_summary_info_header_t *, sst->sst_tab);\n\tconst cdf_section_declaration_t *sd =\n\t    CAST(const cdf_section_declaration_t *, (const void *)\n\t    ((const char *)sst->sst_tab + CDF_SECTION_DECLARATION_OFFSET));\n\n\tif (cdf_check_stream_offset(sst, h, si, sizeof(*si), __LINE__) == -1 ||\n\t    cdf_check_stream_offset(sst, h, sd, sizeof(*sd), __LINE__) == -1)\n\t\treturn -1;\n\tssi->si_byte_order = CDF_TOLE2(si->si_byte_order);\n\tssi->si_os_version = CDF_TOLE2(si->si_os_version);\n\tssi->si_os = CDF_TOLE2(si->si_os);\n\tssi->si_class = si->si_class;\n\tcdf_swap_class(&ssi->si_class);\n\tssi->si_count = CDF_TOLE2(si->si_count);\n\t*count = 0;\n\tmaxcount = 0;\n\t*info = NULL;\n\tfor (i = 0; i < CDF_TOLE4(si->si_count); i++) {\n\t\tif (i >= CDF_LOOP_LIMIT) {\n\t\t\tDPRINTF((\"Unpack summary info loop limit\"));\n\t\t\terrno = EFTYPE;\n\t\t\treturn -1;\n\t\t}\n\t\tif (cdf_read_property_info(sst, h, CDF_TOLE4(sd->sd_offset),\n\t\t    info, count, &maxcount) == -1) {\n\t\t\treturn -1;\n\t\t}\n\t}\n\treturn 0;\n}",
        "func": "int\ncdf_unpack_summary_info(const cdf_stream_t *sst, const cdf_header_t *h,\n    cdf_summary_info_header_t *ssi, cdf_property_info_t **info, size_t *count)\n{\n\tsize_t maxcount;\n\tconst cdf_summary_info_header_t *si =\n\t    CAST(const cdf_summary_info_header_t *, sst->sst_tab);\n\tconst cdf_section_declaration_t *sd =\n\t    CAST(const cdf_section_declaration_t *, (const void *)\n\t    ((const char *)sst->sst_tab + CDF_SECTION_DECLARATION_OFFSET));\n\n\tif (cdf_check_stream_offset(sst, h, si, sizeof(*si), __LINE__) == -1 ||\n\t    cdf_check_stream_offset(sst, h, sd, sizeof(*sd), __LINE__) == -1)\n\t\treturn -1;\n\tssi->si_byte_order = CDF_TOLE2(si->si_byte_order);\n\tssi->si_os_version = CDF_TOLE2(si->si_os_version);\n\tssi->si_os = CDF_TOLE2(si->si_os);\n\tssi->si_class = si->si_class;\n\tcdf_swap_class(&ssi->si_class);\n\tssi->si_count = CDF_TOLE4(si->si_count);\n\t*count = 0;\n\tmaxcount = 0;\n\t*info = NULL;\n\tif (cdf_read_property_info(sst, h, CDF_TOLE4(sd->sd_offset), info,\n\t\tcount, &maxcount) == -1) \n\t\t\treturn -1;\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,7 +2,7 @@\n cdf_unpack_summary_info(const cdf_stream_t *sst, const cdf_header_t *h,\n     cdf_summary_info_header_t *ssi, cdf_property_info_t **info, size_t *count)\n {\n-\tsize_t i, maxcount;\n+\tsize_t maxcount;\n \tconst cdf_summary_info_header_t *si =\n \t    CAST(const cdf_summary_info_header_t *, sst->sst_tab);\n \tconst cdf_section_declaration_t *sd =\n@@ -17,20 +17,12 @@\n \tssi->si_os = CDF_TOLE2(si->si_os);\n \tssi->si_class = si->si_class;\n \tcdf_swap_class(&ssi->si_class);\n-\tssi->si_count = CDF_TOLE2(si->si_count);\n+\tssi->si_count = CDF_TOLE4(si->si_count);\n \t*count = 0;\n \tmaxcount = 0;\n \t*info = NULL;\n-\tfor (i = 0; i < CDF_TOLE4(si->si_count); i++) {\n-\t\tif (i >= CDF_LOOP_LIMIT) {\n-\t\t\tDPRINTF((\"Unpack summary info loop limit\"));\n-\t\t\terrno = EFTYPE;\n+\tif (cdf_read_property_info(sst, h, CDF_TOLE4(sd->sd_offset), info,\n+\t\tcount, &maxcount) == -1) \n \t\t\treturn -1;\n-\t\t}\n-\t\tif (cdf_read_property_info(sst, h, CDF_TOLE4(sd->sd_offset),\n-\t\t    info, count, &maxcount) == -1) {\n-\t\t\treturn -1;\n-\t\t}\n-\t}\n \treturn 0;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tsize_t i, maxcount;",
                "\tssi->si_count = CDF_TOLE2(si->si_count);",
                "\tfor (i = 0; i < CDF_TOLE4(si->si_count); i++) {",
                "\t\tif (i >= CDF_LOOP_LIMIT) {",
                "\t\t\tDPRINTF((\"Unpack summary info loop limit\"));",
                "\t\t\terrno = EFTYPE;",
                "\t\t}",
                "\t\tif (cdf_read_property_info(sst, h, CDF_TOLE4(sd->sd_offset),",
                "\t\t    info, count, &maxcount) == -1) {",
                "\t\t\treturn -1;",
                "\t\t}",
                "\t}"
            ],
            "added_lines": [
                "\tsize_t maxcount;",
                "\tssi->si_count = CDF_TOLE4(si->si_count);",
                "\tif (cdf_read_property_info(sst, h, CDF_TOLE4(sd->sd_offset), info,",
                "\t\tcount, &maxcount) == -1) "
            ]
        }
    },
    {
        "cve_id": "CVE-2014-3538",
        "func_name": "file/string_modifier_check",
        "description": "file before 5.19 does not properly restrict the amount of data read during a regex search, which allows remote attackers to cause a denial of service (CPU consumption) via a crafted file that triggers backtracking during processing of an awk rule.  NOTE: this vulnerability exists because of an incomplete fix for CVE-2013-7345.",
        "git_url": "https://github.com/file/file/commit/4a284c89d6ef11aca34da65da7d673050a5ea320",
        "commit_title": "* Enforce limit of 8K on regex searches that have no limits",
        "commit_text": "* Allow the l modifier for regex to mean line count. Default   to byte count. If line count is specified, assume a max   of 80 characters per line to limit the byte count. * Don't allow conversions to be used for dates, allowing   the mask field to be used as an offset. * Bump the version of the magic format so that regex changes   are visible.",
        "func_before": "private int\nstring_modifier_check(struct magic_set *ms, struct magic *m)\n{\n\tif ((ms->flags & MAGIC_CHECK) == 0)\n\t\treturn 0;\n\n\tif (m->type != FILE_PSTRING && (m->str_flags & PSTRING_LEN) != 0) {\n\t\tfile_magwarn(ms,\n\t\t    \"'/BHhLl' modifiers are only allowed for pascal strings\\n\");\n\t\treturn -1;\n\t}\n\tswitch (m->type) {\n\tcase FILE_BESTRING16:\n\tcase FILE_LESTRING16:\n\t\tif (m->str_flags != 0) {\n\t\t\tfile_magwarn(ms,\n\t\t\t    \"no modifiers allowed for 16-bit strings\\n\");\n\t\t\treturn -1;\n\t\t}\n\t\tbreak;\n\tcase FILE_STRING:\n\tcase FILE_PSTRING:\n\t\tif ((m->str_flags & REGEX_OFFSET_START) != 0) {\n\t\t\tfile_magwarn(ms,\n\t\t\t    \"'/%c' only allowed on regex and search\\n\",\n\t\t\t    CHAR_REGEX_OFFSET_START);\n\t\t\treturn -1;\n\t\t}\n\t\tbreak;\n\tcase FILE_SEARCH:\n\t\tif (m->str_range == 0) {\n\t\t\tfile_magwarn(ms,\n\t\t\t    \"missing range; defaulting to %d\\n\",\n                            STRING_DEFAULT_RANGE);\n\t\t\tm->str_range = STRING_DEFAULT_RANGE;\n\t\t\treturn -1;\n\t\t}\n\t\tbreak;\n\tcase FILE_REGEX:\n\t\tif ((m->str_flags & STRING_COMPACT_WHITESPACE) != 0) {\n\t\t\tfile_magwarn(ms, \"'/%c' not allowed on regex\\n\",\n\t\t\t    CHAR_COMPACT_WHITESPACE);\n\t\t\treturn -1;\n\t\t}\n\t\tif ((m->str_flags & STRING_COMPACT_OPTIONAL_WHITESPACE) != 0) {\n\t\t\tfile_magwarn(ms, \"'/%c' not allowed on regex\\n\",\n\t\t\t    CHAR_COMPACT_OPTIONAL_WHITESPACE);\n\t\t\treturn -1;\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\tfile_magwarn(ms, \"coding error: m->type=%d\\n\",\n\t\t    m->type);\n\t\treturn -1;\n\t}\n\treturn 0;\n}",
        "func": "private int\nstring_modifier_check(struct magic_set *ms, struct magic *m)\n{\n\tif ((ms->flags & MAGIC_CHECK) == 0)\n\t\treturn 0;\n\n\tif ((m->type != FILE_REGEX || (m->str_flags & REGEX_LINE_COUNT) == 0) &&\n\t    (m->type != FILE_PSTRING && (m->str_flags & PSTRING_LEN) != 0)) {\n\t\tfile_magwarn(ms,\n\t\t    \"'/BHhLl' modifiers are only allowed for pascal strings\\n\");\n\t\treturn -1;\n\t}\n\tswitch (m->type) {\n\tcase FILE_BESTRING16:\n\tcase FILE_LESTRING16:\n\t\tif (m->str_flags != 0) {\n\t\t\tfile_magwarn(ms,\n\t\t\t    \"no modifiers allowed for 16-bit strings\\n\");\n\t\t\treturn -1;\n\t\t}\n\t\tbreak;\n\tcase FILE_STRING:\n\tcase FILE_PSTRING:\n\t\tif ((m->str_flags & REGEX_OFFSET_START) != 0) {\n\t\t\tfile_magwarn(ms,\n\t\t\t    \"'/%c' only allowed on regex and search\\n\",\n\t\t\t    CHAR_REGEX_OFFSET_START);\n\t\t\treturn -1;\n\t\t}\n\t\tbreak;\n\tcase FILE_SEARCH:\n\t\tif (m->str_range == 0) {\n\t\t\tfile_magwarn(ms,\n\t\t\t    \"missing range; defaulting to %d\\n\",\n                            STRING_DEFAULT_RANGE);\n\t\t\tm->str_range = STRING_DEFAULT_RANGE;\n\t\t\treturn -1;\n\t\t}\n\t\tbreak;\n\tcase FILE_REGEX:\n\t\tif ((m->str_flags & STRING_COMPACT_WHITESPACE) != 0) {\n\t\t\tfile_magwarn(ms, \"'/%c' not allowed on regex\\n\",\n\t\t\t    CHAR_COMPACT_WHITESPACE);\n\t\t\treturn -1;\n\t\t}\n\t\tif ((m->str_flags & STRING_COMPACT_OPTIONAL_WHITESPACE) != 0) {\n\t\t\tfile_magwarn(ms, \"'/%c' not allowed on regex\\n\",\n\t\t\t    CHAR_COMPACT_OPTIONAL_WHITESPACE);\n\t\t\treturn -1;\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\tfile_magwarn(ms, \"coding error: m->type=%d\\n\",\n\t\t    m->type);\n\t\treturn -1;\n\t}\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,7 +4,8 @@\n \tif ((ms->flags & MAGIC_CHECK) == 0)\n \t\treturn 0;\n \n-\tif (m->type != FILE_PSTRING && (m->str_flags & PSTRING_LEN) != 0) {\n+\tif ((m->type != FILE_REGEX || (m->str_flags & REGEX_LINE_COUNT) == 0) &&\n+\t    (m->type != FILE_PSTRING && (m->str_flags & PSTRING_LEN) != 0)) {\n \t\tfile_magwarn(ms,\n \t\t    \"'/BHhLl' modifiers are only allowed for pascal strings\\n\");\n \t\treturn -1;",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (m->type != FILE_PSTRING && (m->str_flags & PSTRING_LEN) != 0) {"
            ],
            "added_lines": [
                "\tif ((m->type != FILE_REGEX || (m->str_flags & REGEX_LINE_COUNT) == 0) &&",
                "\t    (m->type != FILE_PSTRING && (m->str_flags & PSTRING_LEN) != 0)) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-3538",
        "func_name": "file/parse",
        "description": "file before 5.19 does not properly restrict the amount of data read during a regex search, which allows remote attackers to cause a denial of service (CPU consumption) via a crafted file that triggers backtracking during processing of an awk rule.  NOTE: this vulnerability exists because of an incomplete fix for CVE-2013-7345.",
        "git_url": "https://github.com/file/file/commit/4a284c89d6ef11aca34da65da7d673050a5ea320",
        "commit_title": "* Enforce limit of 8K on regex searches that have no limits",
        "commit_text": "* Allow the l modifier for regex to mean line count. Default   to byte count. If line count is specified, assume a max   of 80 characters per line to limit the byte count. * Don't allow conversions to be used for dates, allowing   the mask field to be used as an offset. * Bump the version of the magic format so that regex changes   are visible.",
        "func_before": "private int\nparse(struct magic_set *ms, struct magic_entry *me, const char *line,\n    size_t lineno, int action)\n{\n#ifdef ENABLE_CONDITIONALS\n\tstatic uint32_t last_cont_level = 0;\n#endif\n\tsize_t i;\n\tstruct magic *m;\n\tconst char *l = line;\n\tchar *t;\n\tint op;\n\tuint32_t cont_level;\n\tint32_t diff;\n\n\tcont_level = 0;\n\n\t/*\n\t * Parse the offset.\n\t */\n\twhile (*l == '>') {\n\t\t++l;\t\t/* step over */\n\t\tcont_level++; \n\t}\n#ifdef ENABLE_CONDITIONALS\n\tif (cont_level == 0 || cont_level > last_cont_level)\n\t\tif (file_check_mem(ms, cont_level) == -1)\n\t\t\treturn -1;\n\tlast_cont_level = cont_level;\n#endif\n\tif (cont_level != 0) {\n\t\tif (me->mp == NULL) {\n\t\t\tfile_magerror(ms, \"No current entry for continuation\");\n\t\t\treturn -1;\n\t\t}\n\t\tif (me->cont_count == 0) {\n\t\t\tfile_magerror(ms, \"Continuations present with 0 count\");\n\t\t\treturn -1;\n\t\t}\n\t\tm = &me->mp[me->cont_count - 1];\n\t\tdiff = (int32_t)cont_level - (int32_t)m->cont_level;\n\t\tif (diff > 1)\n\t\t\tfile_magwarn(ms, \"New continuation level %u is more \"\n\t\t\t    \"than one larger than current level %u\", cont_level,\n\t\t\t    m->cont_level);\n\t\tif (me->cont_count == me->max_count) {\n\t\t\tstruct magic *nm;\n\t\t\tsize_t cnt = me->max_count + ALLOC_CHUNK;\n\t\t\tif ((nm = CAST(struct magic *, realloc(me->mp,\n\t\t\t    sizeof(*nm) * cnt))) == NULL) {\n\t\t\t\tfile_oomem(ms, sizeof(*nm) * cnt);\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tme->mp = m = nm;\n\t\t\tme->max_count = CAST(uint32_t, cnt);\n\t\t}\n\t\tm = &me->mp[me->cont_count++];\n\t\t(void)memset(m, 0, sizeof(*m));\n\t\tm->cont_level = cont_level;\n\t} else {\n\t\tstatic const size_t len = sizeof(*m) * ALLOC_CHUNK;\n\t\tif (me->mp != NULL)\n\t\t\treturn 1;\n\t\tif ((m = CAST(struct magic *, malloc(len))) == NULL) {\n\t\t\tfile_oomem(ms, len);\n\t\t\treturn -1;\n\t\t}\n\t\tme->mp = m;\n\t\tme->max_count = ALLOC_CHUNK;\n\t\t(void)memset(m, 0, sizeof(*m));\n\t\tm->factor_op = FILE_FACTOR_OP_NONE;\n\t\tm->cont_level = 0;\n\t\tme->cont_count = 1;\n\t}\n\tm->lineno = CAST(uint32_t, lineno);\n\n\tif (*l == '&') {  /* m->cont_level == 0 checked below. */\n                ++l;            /* step over */\n                m->flag |= OFFADD;\n        }\n\tif (*l == '(') {\n\t\t++l;\t\t/* step over */\n\t\tm->flag |= INDIR;\n\t\tif (m->flag & OFFADD)\n\t\t\tm->flag = (m->flag & ~OFFADD) | INDIROFFADD;\n\n\t\tif (*l == '&') {  /* m->cont_level == 0 checked below */\n\t\t\t++l;            /* step over */\n\t\t\tm->flag |= OFFADD;\n\t\t}\n\t}\n\t/* Indirect offsets are not valid at level 0. */\n\tif (m->cont_level == 0 && (m->flag & (OFFADD | INDIROFFADD)))\n\t\tif (ms->flags & MAGIC_CHECK)\n\t\t\tfile_magwarn(ms, \"relative offset at level 0\");\n\n\t/* get offset, then skip over it */\n\tm->offset = (uint32_t)strtoul(l, &t, 0);\n        if (l == t)\n\t\tif (ms->flags & MAGIC_CHECK)\n\t\t\tfile_magwarn(ms, \"offset `%s' invalid\", l);\n        l = t;\n\n\tif (m->flag & INDIR) {\n\t\tm->in_type = FILE_LONG;\n\t\tm->in_offset = 0;\n\t\t/*\n\t\t * read [.lbs][+-]nnnnn)\n\t\t */\n\t\tif (*l == '.') {\n\t\t\tl++;\n\t\t\tswitch (*l) {\n\t\t\tcase 'l':\n\t\t\t\tm->in_type = FILE_LELONG;\n\t\t\t\tbreak;\n\t\t\tcase 'L':\n\t\t\t\tm->in_type = FILE_BELONG;\n\t\t\t\tbreak;\n\t\t\tcase 'm':\n\t\t\t\tm->in_type = FILE_MELONG;\n\t\t\t\tbreak;\n\t\t\tcase 'h':\n\t\t\tcase 's':\n\t\t\t\tm->in_type = FILE_LESHORT;\n\t\t\t\tbreak;\n\t\t\tcase 'H':\n\t\t\tcase 'S':\n\t\t\t\tm->in_type = FILE_BESHORT;\n\t\t\t\tbreak;\n\t\t\tcase 'c':\n\t\t\tcase 'b':\n\t\t\tcase 'C':\n\t\t\tcase 'B':\n\t\t\t\tm->in_type = FILE_BYTE;\n\t\t\t\tbreak;\n\t\t\tcase 'e':\n\t\t\tcase 'f':\n\t\t\tcase 'g':\n\t\t\t\tm->in_type = FILE_LEDOUBLE;\n\t\t\t\tbreak;\n\t\t\tcase 'E':\n\t\t\tcase 'F':\n\t\t\tcase 'G':\n\t\t\t\tm->in_type = FILE_BEDOUBLE;\n\t\t\t\tbreak;\n\t\t\tcase 'i':\n\t\t\t\tm->in_type = FILE_LEID3;\n\t\t\t\tbreak;\n\t\t\tcase 'I':\n\t\t\t\tm->in_type = FILE_BEID3;\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tif (ms->flags & MAGIC_CHECK)\n\t\t\t\t\tfile_magwarn(ms,\n\t\t\t\t\t    \"indirect offset type `%c' invalid\",\n\t\t\t\t\t    *l);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tl++;\n\t\t}\n\n\t\tm->in_op = 0;\n\t\tif (*l == '~') {\n\t\t\tm->in_op |= FILE_OPINVERSE;\n\t\t\tl++;\n\t\t}\n\t\tif ((op = get_op(*l)) != -1) {\n\t\t\tm->in_op |= op;\n\t\t\tl++;\n\t\t}\n\t\tif (*l == '(') {\n\t\t\tm->in_op |= FILE_OPINDIRECT;\n\t\t\tl++;\n\t\t}\n\t\tif (isdigit((unsigned char)*l) || *l == '-') {\n\t\t\tm->in_offset = (int32_t)strtol(l, &t, 0);\n\t\t\tif (l == t)\n\t\t\t\tif (ms->flags & MAGIC_CHECK)\n\t\t\t\t\tfile_magwarn(ms,\n\t\t\t\t\t    \"in_offset `%s' invalid\", l);\n\t\t\tl = t;\n\t\t}\n\t\tif (*l++ != ')' || \n\t\t    ((m->in_op & FILE_OPINDIRECT) && *l++ != ')'))\n\t\t\tif (ms->flags & MAGIC_CHECK)\n\t\t\t\tfile_magwarn(ms,\n\t\t\t\t    \"missing ')' in indirect offset\");\n\t}\n\tEATAB;\n\n#ifdef ENABLE_CONDITIONALS\n\tm->cond = get_cond(l, &l);\n\tif (check_cond(ms, m->cond, cont_level) == -1)\n\t\treturn -1;\n\n\tEATAB;\n#endif\n\n\t/*\n\t * Parse the type.\n\t */\n\tif (*l == 'u') {\n\t\t/*\n\t\t * Try it as a keyword type prefixed by \"u\"; match what\n\t\t * follows the \"u\".  If that fails, try it as an SUS\n\t\t * integer type. \n\t\t */\n\t\tm->type = get_type(type_tbl, l + 1, &l);\n\t\tif (m->type == FILE_INVALID) {\n\t\t\t/*\n\t\t\t * Not a keyword type; parse it as an SUS type,\n\t\t\t * 'u' possibly followed by a number or C/S/L.\n\t\t\t */\n\t\t\tm->type = get_standard_integer_type(l, &l);\n\t\t}\n\t\t/* It's unsigned. */\n\t\tif (m->type != FILE_INVALID)\n\t\t\tm->flag |= UNSIGNED;\n\t} else {\n\t\t/*\n\t\t * Try it as a keyword type.  If that fails, try it as\n\t\t * an SUS integer type if it begins with \"d\" or as an\n\t\t * SUS string type if it begins with \"s\".  In any case,\n\t\t * it's not unsigned.\n\t\t */\n\t\tm->type = get_type(type_tbl, l, &l);\n\t\tif (m->type == FILE_INVALID) {\n\t\t\t/*\n\t\t\t * Not a keyword type; parse it as an SUS type,\n\t\t\t * either 'd' possibly followed by a number or\n\t\t\t * C/S/L, or just 's'.\n\t\t\t */\n\t\t\tif (*l == 'd')\n\t\t\t\tm->type = get_standard_integer_type(l, &l);\n\t\t\telse if (*l == 's' && !isalpha((unsigned char)l[1])) {\n\t\t\t\tm->type = FILE_STRING;\n\t\t\t\t++l;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (m->type == FILE_INVALID) {\n\t\t/* Not found - try it as a special keyword. */\n\t\tm->type = get_type(special_tbl, l, &l);\n\t}\n\t\t\t\n\tif (m->type == FILE_INVALID) {\n\t\tif (ms->flags & MAGIC_CHECK)\n\t\t\tfile_magwarn(ms, \"type `%s' invalid\", l);\n\t\treturn -1;\n\t}\n\n\t/* New-style anding: \"0 byte&0x80 =0x80 dynamically linked\" */\n\t/* New and improved: ~ & | ^ + - * / % -- exciting, isn't it? */\n\n\tm->mask_op = 0;\n\tif (*l == '~') {\n\t\tif (!IS_STRING(m->type))\n\t\t\tm->mask_op |= FILE_OPINVERSE;\n\t\telse if (ms->flags & MAGIC_CHECK)\n\t\t\tfile_magwarn(ms, \"'~' invalid for string types\");\n\t\t++l;\n\t}\n\tm->str_range = 0;\n\tm->str_flags = m->type == FILE_PSTRING ? PSTRING_1_LE : 0;\n\tif ((op = get_op(*l)) != -1) {\n\t\tif (!IS_STRING(m->type)) {\n\t\t\tuint64_t val;\n\t\t\t++l;\n\t\t\tm->mask_op |= op;\n\t\t\tval = (uint64_t)strtoull(l, &t, 0);\n\t\t\tl = t;\n\t\t\tm->num_mask = file_signextend(ms, m, val);\n\t\t\teatsize(&l);\n\t\t}\n\t\telse if (op == FILE_OPDIVIDE) {\n\t\t\tint have_range = 0;\n\t\t\twhile (!isspace((unsigned char)*++l)) {\n\t\t\t\tswitch (*l) {\n\t\t\t\tcase '0':  case '1':  case '2':\n\t\t\t\tcase '3':  case '4':  case '5':\n\t\t\t\tcase '6':  case '7':  case '8':\n\t\t\t\tcase '9':\n\t\t\t\t\tif (have_range &&\n\t\t\t\t\t    (ms->flags & MAGIC_CHECK))\n\t\t\t\t\t\tfile_magwarn(ms,\n\t\t\t\t\t\t    \"multiple ranges\");\n\t\t\t\t\thave_range = 1;\n\t\t\t\t\tm->str_range = CAST(uint32_t,\n\t\t\t\t\t    strtoul(l, &t, 0));\n\t\t\t\t\tif (m->str_range == 0)\n\t\t\t\t\t\tfile_magwarn(ms,\n\t\t\t\t\t\t    \"zero range\");\n\t\t\t\t\tl = t - 1;\n\t\t\t\t\tbreak;\n\t\t\t\tcase CHAR_COMPACT_WHITESPACE:\n\t\t\t\t\tm->str_flags |=\n\t\t\t\t\t    STRING_COMPACT_WHITESPACE;\n\t\t\t\t\tbreak;\n\t\t\t\tcase CHAR_COMPACT_OPTIONAL_WHITESPACE:\n\t\t\t\t\tm->str_flags |=\n\t\t\t\t\t    STRING_COMPACT_OPTIONAL_WHITESPACE;\n\t\t\t\t\tbreak;\n\t\t\t\tcase CHAR_IGNORE_LOWERCASE:\n\t\t\t\t\tm->str_flags |= STRING_IGNORE_LOWERCASE;\n\t\t\t\t\tbreak;\n\t\t\t\tcase CHAR_IGNORE_UPPERCASE:\n\t\t\t\t\tm->str_flags |= STRING_IGNORE_UPPERCASE;\n\t\t\t\t\tbreak;\n\t\t\t\tcase CHAR_REGEX_OFFSET_START:\n\t\t\t\t\tm->str_flags |= REGEX_OFFSET_START;\n\t\t\t\t\tbreak;\n\t\t\t\tcase CHAR_BINTEST:\n\t\t\t\t\tm->str_flags |= STRING_BINTEST;\n\t\t\t\t\tbreak;\n\t\t\t\tcase CHAR_TEXTTEST:\n\t\t\t\t\tm->str_flags |= STRING_TEXTTEST;\n\t\t\t\t\tbreak;\n\t\t\t\tcase CHAR_TRIM:\n\t\t\t\t\tm->str_flags |= STRING_TRIM;\n\t\t\t\t\tbreak;\n\t\t\t\tcase CHAR_PSTRING_1_LE:\n\t\t\t\t\tif (m->type != FILE_PSTRING)\n\t\t\t\t\t\tgoto bad;\n\t\t\t\t\tm->str_flags = (m->str_flags & ~PSTRING_LEN) | PSTRING_1_LE;\n\t\t\t\t\tbreak;\n\t\t\t\tcase CHAR_PSTRING_2_BE:\n\t\t\t\t\tif (m->type != FILE_PSTRING)\n\t\t\t\t\t\tgoto bad;\n\t\t\t\t\tm->str_flags = (m->str_flags & ~PSTRING_LEN) | PSTRING_2_BE;\n\t\t\t\t\tbreak;\n\t\t\t\tcase CHAR_PSTRING_2_LE:\n\t\t\t\t\tif (m->type != FILE_PSTRING)\n\t\t\t\t\t\tgoto bad;\n\t\t\t\t\tm->str_flags = (m->str_flags & ~PSTRING_LEN) | PSTRING_2_LE;\n\t\t\t\t\tbreak;\n\t\t\t\tcase CHAR_PSTRING_4_BE:\n\t\t\t\t\tif (m->type != FILE_PSTRING)\n\t\t\t\t\t\tgoto bad;\n\t\t\t\t\tm->str_flags = (m->str_flags & ~PSTRING_LEN) | PSTRING_4_BE;\n\t\t\t\t\tbreak;\n\t\t\t\tcase CHAR_PSTRING_4_LE:\n\t\t\t\t\tif (m->type != FILE_PSTRING)\n\t\t\t\t\t\tgoto bad;\n\t\t\t\t\tm->str_flags = (m->str_flags & ~PSTRING_LEN) | PSTRING_4_LE;\n\t\t\t\t\tbreak;\n\t\t\t\tcase CHAR_PSTRING_LENGTH_INCLUDES_ITSELF:\n\t\t\t\t\tif (m->type != FILE_PSTRING)\n\t\t\t\t\t\tgoto bad;\n\t\t\t\t\tm->str_flags |= PSTRING_LENGTH_INCLUDES_ITSELF;\n\t\t\t\t\tbreak;\n\t\t\t\tdefault:\n\t\t\t\tbad:\n\t\t\t\t\tif (ms->flags & MAGIC_CHECK)\n\t\t\t\t\t\tfile_magwarn(ms,\n\t\t\t\t\t\t    \"string extension `%c' \"\n\t\t\t\t\t\t    \"invalid\", *l);\n\t\t\t\t\treturn -1;\n\t\t\t\t}\n\t\t\t\t/* allow multiple '/' for readability */\n\t\t\t\tif (l[1] == '/' &&\n\t\t\t\t    !isspace((unsigned char)l[2]))\n\t\t\t\t\tl++;\n\t\t\t}\n\t\t\tif (string_modifier_check(ms, m) == -1)\n\t\t\t\treturn -1;\n\t\t}\n\t\telse {\n\t\t\tif (ms->flags & MAGIC_CHECK)\n\t\t\t\tfile_magwarn(ms, \"invalid string op: %c\", *t);\n\t\t\treturn -1;\n\t\t}\n\t}\n\t/*\n\t * We used to set mask to all 1's here, instead let's just not do\n\t * anything if mask = 0 (unless you have a better idea)\n\t */\n\tEATAB;\n  \n\tswitch (*l) {\n\tcase '>':\n\tcase '<':\n  \t\tm->reln = *l;\n  \t\t++l;\n\t\tif (*l == '=') {\n\t\t\tif (ms->flags & MAGIC_CHECK) {\n\t\t\t\tfile_magwarn(ms, \"%c= not supported\",\n\t\t\t\t    m->reln);\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t   ++l;\n\t\t}\n\t\tbreak;\n\t/* Old-style anding: \"0 byte &0x80 dynamically linked\" */\n\tcase '&':\n\tcase '^':\n\tcase '=':\n  \t\tm->reln = *l;\n  \t\t++l;\n\t\tif (*l == '=') {\n\t\t   /* HP compat: ignore &= etc. */\n\t\t   ++l;\n\t\t}\n\t\tbreak;\n\tcase '!':\n\t\tm->reln = *l;\n\t\t++l;\n\t\tbreak;\n\tdefault:\n  \t\tm->reln = '=';\t/* the default relation */\n\t\tif (*l == 'x' && ((isascii((unsigned char)l[1]) && \n\t\t    isspace((unsigned char)l[1])) || !l[1])) {\n\t\t\tm->reln = *l;\n\t\t\t++l;\n\t\t}\n\t\tbreak;\n\t}\n\t/*\n\t * Grab the value part, except for an 'x' reln.\n\t */\n\tif (m->reln != 'x' && getvalue(ms, m, &l, action))\n\t\treturn -1;\n\n\t/*\n\t * TODO finish this macro and start using it!\n\t * #define offsetcheck {if (offset > HOWMANY-1) \n\t *\tmagwarn(\"offset too big\"); }\n\t */\n\n\t/*\n\t * Now get last part - the description\n\t */\n\tEATAB;\n\tif (l[0] == '\\b') {\n\t\t++l;\n\t\tm->flag |= NOSPACE;\n\t} else if ((l[0] == '\\\\') && (l[1] == 'b')) {\n\t\t++l;\n\t\t++l;\n\t\tm->flag |= NOSPACE;\n\t}\n\tfor (i = 0; (m->desc[i++] = *l++) != '\\0' && i < sizeof(m->desc); )\n\t\tcontinue;\n\tif (i == sizeof(m->desc)) {\n\t\tm->desc[sizeof(m->desc) - 1] = '\\0';\n\t\tif (ms->flags & MAGIC_CHECK)\n\t\t\tfile_magwarn(ms, \"description `%s' truncated\", m->desc);\n\t}\n\n        /*\n\t * We only do this check while compiling, or if any of the magic\n\t * files were not compiled.\n         */\n        if (ms->flags & MAGIC_CHECK) {\n\t\tif (check_format(ms, m) == -1)\n\t\t\treturn -1;\n\t}\n#ifndef COMPILE_ONLY\n\tif (action == FILE_CHECK) {\n\t\tfile_mdump(m);\n\t}\n#endif\n\tm->mimetype[0] = '\\0';\t\t/* initialise MIME type to none */\n\treturn 0;\n}",
        "func": "private int\nparse(struct magic_set *ms, struct magic_entry *me, const char *line,\n    size_t lineno, int action)\n{\n#ifdef ENABLE_CONDITIONALS\n\tstatic uint32_t last_cont_level = 0;\n#endif\n\tsize_t i;\n\tstruct magic *m;\n\tconst char *l = line;\n\tchar *t;\n\tint op;\n\tuint32_t cont_level;\n\tint32_t diff;\n\n\tcont_level = 0;\n\n\t/*\n\t * Parse the offset.\n\t */\n\twhile (*l == '>') {\n\t\t++l;\t\t/* step over */\n\t\tcont_level++; \n\t}\n#ifdef ENABLE_CONDITIONALS\n\tif (cont_level == 0 || cont_level > last_cont_level)\n\t\tif (file_check_mem(ms, cont_level) == -1)\n\t\t\treturn -1;\n\tlast_cont_level = cont_level;\n#endif\n\tif (cont_level != 0) {\n\t\tif (me->mp == NULL) {\n\t\t\tfile_magerror(ms, \"No current entry for continuation\");\n\t\t\treturn -1;\n\t\t}\n\t\tif (me->cont_count == 0) {\n\t\t\tfile_magerror(ms, \"Continuations present with 0 count\");\n\t\t\treturn -1;\n\t\t}\n\t\tm = &me->mp[me->cont_count - 1];\n\t\tdiff = (int32_t)cont_level - (int32_t)m->cont_level;\n\t\tif (diff > 1)\n\t\t\tfile_magwarn(ms, \"New continuation level %u is more \"\n\t\t\t    \"than one larger than current level %u\", cont_level,\n\t\t\t    m->cont_level);\n\t\tif (me->cont_count == me->max_count) {\n\t\t\tstruct magic *nm;\n\t\t\tsize_t cnt = me->max_count + ALLOC_CHUNK;\n\t\t\tif ((nm = CAST(struct magic *, realloc(me->mp,\n\t\t\t    sizeof(*nm) * cnt))) == NULL) {\n\t\t\t\tfile_oomem(ms, sizeof(*nm) * cnt);\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tme->mp = m = nm;\n\t\t\tme->max_count = CAST(uint32_t, cnt);\n\t\t}\n\t\tm = &me->mp[me->cont_count++];\n\t\t(void)memset(m, 0, sizeof(*m));\n\t\tm->cont_level = cont_level;\n\t} else {\n\t\tstatic const size_t len = sizeof(*m) * ALLOC_CHUNK;\n\t\tif (me->mp != NULL)\n\t\t\treturn 1;\n\t\tif ((m = CAST(struct magic *, malloc(len))) == NULL) {\n\t\t\tfile_oomem(ms, len);\n\t\t\treturn -1;\n\t\t}\n\t\tme->mp = m;\n\t\tme->max_count = ALLOC_CHUNK;\n\t\t(void)memset(m, 0, sizeof(*m));\n\t\tm->factor_op = FILE_FACTOR_OP_NONE;\n\t\tm->cont_level = 0;\n\t\tme->cont_count = 1;\n\t}\n\tm->lineno = CAST(uint32_t, lineno);\n\n\tif (*l == '&') {  /* m->cont_level == 0 checked below. */\n                ++l;            /* step over */\n                m->flag |= OFFADD;\n        }\n\tif (*l == '(') {\n\t\t++l;\t\t/* step over */\n\t\tm->flag |= INDIR;\n\t\tif (m->flag & OFFADD)\n\t\t\tm->flag = (m->flag & ~OFFADD) | INDIROFFADD;\n\n\t\tif (*l == '&') {  /* m->cont_level == 0 checked below */\n\t\t\t++l;            /* step over */\n\t\t\tm->flag |= OFFADD;\n\t\t}\n\t}\n\t/* Indirect offsets are not valid at level 0. */\n\tif (m->cont_level == 0 && (m->flag & (OFFADD | INDIROFFADD)))\n\t\tif (ms->flags & MAGIC_CHECK)\n\t\t\tfile_magwarn(ms, \"relative offset at level 0\");\n\n\t/* get offset, then skip over it */\n\tm->offset = (uint32_t)strtoul(l, &t, 0);\n        if (l == t)\n\t\tif (ms->flags & MAGIC_CHECK)\n\t\t\tfile_magwarn(ms, \"offset `%s' invalid\", l);\n        l = t;\n\n\tif (m->flag & INDIR) {\n\t\tm->in_type = FILE_LONG;\n\t\tm->in_offset = 0;\n\t\t/*\n\t\t * read [.lbs][+-]nnnnn)\n\t\t */\n\t\tif (*l == '.') {\n\t\t\tl++;\n\t\t\tswitch (*l) {\n\t\t\tcase 'l':\n\t\t\t\tm->in_type = FILE_LELONG;\n\t\t\t\tbreak;\n\t\t\tcase 'L':\n\t\t\t\tm->in_type = FILE_BELONG;\n\t\t\t\tbreak;\n\t\t\tcase 'm':\n\t\t\t\tm->in_type = FILE_MELONG;\n\t\t\t\tbreak;\n\t\t\tcase 'h':\n\t\t\tcase 's':\n\t\t\t\tm->in_type = FILE_LESHORT;\n\t\t\t\tbreak;\n\t\t\tcase 'H':\n\t\t\tcase 'S':\n\t\t\t\tm->in_type = FILE_BESHORT;\n\t\t\t\tbreak;\n\t\t\tcase 'c':\n\t\t\tcase 'b':\n\t\t\tcase 'C':\n\t\t\tcase 'B':\n\t\t\t\tm->in_type = FILE_BYTE;\n\t\t\t\tbreak;\n\t\t\tcase 'e':\n\t\t\tcase 'f':\n\t\t\tcase 'g':\n\t\t\t\tm->in_type = FILE_LEDOUBLE;\n\t\t\t\tbreak;\n\t\t\tcase 'E':\n\t\t\tcase 'F':\n\t\t\tcase 'G':\n\t\t\t\tm->in_type = FILE_BEDOUBLE;\n\t\t\t\tbreak;\n\t\t\tcase 'i':\n\t\t\t\tm->in_type = FILE_LEID3;\n\t\t\t\tbreak;\n\t\t\tcase 'I':\n\t\t\t\tm->in_type = FILE_BEID3;\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tif (ms->flags & MAGIC_CHECK)\n\t\t\t\t\tfile_magwarn(ms,\n\t\t\t\t\t    \"indirect offset type `%c' invalid\",\n\t\t\t\t\t    *l);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tl++;\n\t\t}\n\n\t\tm->in_op = 0;\n\t\tif (*l == '~') {\n\t\t\tm->in_op |= FILE_OPINVERSE;\n\t\t\tl++;\n\t\t}\n\t\tif ((op = get_op(*l)) != -1) {\n\t\t\tm->in_op |= op;\n\t\t\tl++;\n\t\t}\n\t\tif (*l == '(') {\n\t\t\tm->in_op |= FILE_OPINDIRECT;\n\t\t\tl++;\n\t\t}\n\t\tif (isdigit((unsigned char)*l) || *l == '-') {\n\t\t\tm->in_offset = (int32_t)strtol(l, &t, 0);\n\t\t\tif (l == t)\n\t\t\t\tif (ms->flags & MAGIC_CHECK)\n\t\t\t\t\tfile_magwarn(ms,\n\t\t\t\t\t    \"in_offset `%s' invalid\", l);\n\t\t\tl = t;\n\t\t}\n\t\tif (*l++ != ')' || \n\t\t    ((m->in_op & FILE_OPINDIRECT) && *l++ != ')'))\n\t\t\tif (ms->flags & MAGIC_CHECK)\n\t\t\t\tfile_magwarn(ms,\n\t\t\t\t    \"missing ')' in indirect offset\");\n\t}\n\tEATAB;\n\n#ifdef ENABLE_CONDITIONALS\n\tm->cond = get_cond(l, &l);\n\tif (check_cond(ms, m->cond, cont_level) == -1)\n\t\treturn -1;\n\n\tEATAB;\n#endif\n\n\t/*\n\t * Parse the type.\n\t */\n\tif (*l == 'u') {\n\t\t/*\n\t\t * Try it as a keyword type prefixed by \"u\"; match what\n\t\t * follows the \"u\".  If that fails, try it as an SUS\n\t\t * integer type. \n\t\t */\n\t\tm->type = get_type(type_tbl, l + 1, &l);\n\t\tif (m->type == FILE_INVALID) {\n\t\t\t/*\n\t\t\t * Not a keyword type; parse it as an SUS type,\n\t\t\t * 'u' possibly followed by a number or C/S/L.\n\t\t\t */\n\t\t\tm->type = get_standard_integer_type(l, &l);\n\t\t}\n\t\t/* It's unsigned. */\n\t\tif (m->type != FILE_INVALID)\n\t\t\tm->flag |= UNSIGNED;\n\t} else {\n\t\t/*\n\t\t * Try it as a keyword type.  If that fails, try it as\n\t\t * an SUS integer type if it begins with \"d\" or as an\n\t\t * SUS string type if it begins with \"s\".  In any case,\n\t\t * it's not unsigned.\n\t\t */\n\t\tm->type = get_type(type_tbl, l, &l);\n\t\tif (m->type == FILE_INVALID) {\n\t\t\t/*\n\t\t\t * Not a keyword type; parse it as an SUS type,\n\t\t\t * either 'd' possibly followed by a number or\n\t\t\t * C/S/L, or just 's'.\n\t\t\t */\n\t\t\tif (*l == 'd')\n\t\t\t\tm->type = get_standard_integer_type(l, &l);\n\t\t\telse if (*l == 's' && !isalpha((unsigned char)l[1])) {\n\t\t\t\tm->type = FILE_STRING;\n\t\t\t\t++l;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (m->type == FILE_INVALID) {\n\t\t/* Not found - try it as a special keyword. */\n\t\tm->type = get_type(special_tbl, l, &l);\n\t}\n\t\t\t\n\tif (m->type == FILE_INVALID) {\n\t\tif (ms->flags & MAGIC_CHECK)\n\t\t\tfile_magwarn(ms, \"type `%s' invalid\", l);\n\t\treturn -1;\n\t}\n\n\t/* New-style anding: \"0 byte&0x80 =0x80 dynamically linked\" */\n\t/* New and improved: ~ & | ^ + - * / % -- exciting, isn't it? */\n\n\tm->mask_op = 0;\n\tif (*l == '~') {\n\t\tif (!IS_STRING(m->type))\n\t\t\tm->mask_op |= FILE_OPINVERSE;\n\t\telse if (ms->flags & MAGIC_CHECK)\n\t\t\tfile_magwarn(ms, \"'~' invalid for string types\");\n\t\t++l;\n\t}\n\tm->str_range = 0;\n\tm->str_flags = m->type == FILE_PSTRING ? PSTRING_1_LE : 0;\n\tif ((op = get_op(*l)) != -1) {\n\t\tif (!IS_STRING(m->type)) {\n\t\t\tuint64_t val;\n\t\t\t++l;\n\t\t\tm->mask_op |= op;\n\t\t\tval = (uint64_t)strtoull(l, &t, 0);\n\t\t\tl = t;\n\t\t\tm->num_mask = file_signextend(ms, m, val);\n\t\t\teatsize(&l);\n\t\t}\n\t\telse if (op == FILE_OPDIVIDE) {\n\t\t\tint have_range = 0;\n\t\t\twhile (!isspace((unsigned char)*++l)) {\n\t\t\t\tswitch (*l) {\n\t\t\t\tcase '0':  case '1':  case '2':\n\t\t\t\tcase '3':  case '4':  case '5':\n\t\t\t\tcase '6':  case '7':  case '8':\n\t\t\t\tcase '9':\n\t\t\t\t\tif (have_range &&\n\t\t\t\t\t    (ms->flags & MAGIC_CHECK))\n\t\t\t\t\t\tfile_magwarn(ms,\n\t\t\t\t\t\t    \"multiple ranges\");\n\t\t\t\t\thave_range = 1;\n\t\t\t\t\tm->str_range = CAST(uint32_t,\n\t\t\t\t\t    strtoul(l, &t, 0));\n\t\t\t\t\tif (m->str_range == 0)\n\t\t\t\t\t\tfile_magwarn(ms,\n\t\t\t\t\t\t    \"zero range\");\n\t\t\t\t\tl = t - 1;\n\t\t\t\t\tbreak;\n\t\t\t\tcase CHAR_COMPACT_WHITESPACE:\n\t\t\t\t\tm->str_flags |=\n\t\t\t\t\t    STRING_COMPACT_WHITESPACE;\n\t\t\t\t\tbreak;\n\t\t\t\tcase CHAR_COMPACT_OPTIONAL_WHITESPACE:\n\t\t\t\t\tm->str_flags |=\n\t\t\t\t\t    STRING_COMPACT_OPTIONAL_WHITESPACE;\n\t\t\t\t\tbreak;\n\t\t\t\tcase CHAR_IGNORE_LOWERCASE:\n\t\t\t\t\tm->str_flags |= STRING_IGNORE_LOWERCASE;\n\t\t\t\t\tbreak;\n\t\t\t\tcase CHAR_IGNORE_UPPERCASE:\n\t\t\t\t\tm->str_flags |= STRING_IGNORE_UPPERCASE;\n\t\t\t\t\tbreak;\n\t\t\t\tcase CHAR_REGEX_OFFSET_START:\n\t\t\t\t\tm->str_flags |= REGEX_OFFSET_START;\n\t\t\t\t\tbreak;\n\t\t\t\tcase CHAR_BINTEST:\n\t\t\t\t\tm->str_flags |= STRING_BINTEST;\n\t\t\t\t\tbreak;\n\t\t\t\tcase CHAR_TEXTTEST:\n\t\t\t\t\tm->str_flags |= STRING_TEXTTEST;\n\t\t\t\t\tbreak;\n\t\t\t\tcase CHAR_TRIM:\n\t\t\t\t\tm->str_flags |= STRING_TRIM;\n\t\t\t\t\tbreak;\n\t\t\t\tcase CHAR_PSTRING_1_LE:\n\t\t\t\t\tif (m->type != FILE_PSTRING)\n\t\t\t\t\t\tgoto bad;\n\t\t\t\t\tm->str_flags = (m->str_flags & ~PSTRING_LEN) | PSTRING_1_LE;\n\t\t\t\t\tbreak;\n\t\t\t\tcase CHAR_PSTRING_2_BE:\n\t\t\t\t\tif (m->type != FILE_PSTRING)\n\t\t\t\t\t\tgoto bad;\n\t\t\t\t\tm->str_flags = (m->str_flags & ~PSTRING_LEN) | PSTRING_2_BE;\n\t\t\t\t\tbreak;\n\t\t\t\tcase CHAR_PSTRING_2_LE:\n\t\t\t\t\tif (m->type != FILE_PSTRING)\n\t\t\t\t\t\tgoto bad;\n\t\t\t\t\tm->str_flags = (m->str_flags & ~PSTRING_LEN) | PSTRING_2_LE;\n\t\t\t\t\tbreak;\n\t\t\t\tcase CHAR_PSTRING_4_BE:\n\t\t\t\t\tif (m->type != FILE_PSTRING)\n\t\t\t\t\t\tgoto bad;\n\t\t\t\t\tm->str_flags = (m->str_flags & ~PSTRING_LEN) | PSTRING_4_BE;\n\t\t\t\t\tbreak;\n\t\t\t\tcase CHAR_PSTRING_4_LE:\n\t\t\t\t\tswitch (m->type) {\n\t\t\t\t\tcase FILE_PSTRING:\n\t\t\t\t\tcase FILE_REGEX:\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tdefault:\n\t\t\t\t\t\tgoto bad;\n\t\t\t\t\t}\n\t\t\t\t\tm->str_flags = (m->str_flags & ~PSTRING_LEN) | PSTRING_4_LE;\n\t\t\t\t\tbreak;\n\t\t\t\tcase CHAR_PSTRING_LENGTH_INCLUDES_ITSELF:\n\t\t\t\t\tif (m->type != FILE_PSTRING)\n\t\t\t\t\t\tgoto bad;\n\t\t\t\t\tm->str_flags |= PSTRING_LENGTH_INCLUDES_ITSELF;\n\t\t\t\t\tbreak;\n\t\t\t\tdefault:\n\t\t\t\tbad:\n\t\t\t\t\tif (ms->flags & MAGIC_CHECK)\n\t\t\t\t\t\tfile_magwarn(ms,\n\t\t\t\t\t\t    \"string extension `%c' \"\n\t\t\t\t\t\t    \"invalid\", *l);\n\t\t\t\t\treturn -1;\n\t\t\t\t}\n\t\t\t\t/* allow multiple '/' for readability */\n\t\t\t\tif (l[1] == '/' &&\n\t\t\t\t    !isspace((unsigned char)l[2]))\n\t\t\t\t\tl++;\n\t\t\t}\n\t\t\tif (string_modifier_check(ms, m) == -1)\n\t\t\t\treturn -1;\n\t\t}\n\t\telse {\n\t\t\tif (ms->flags & MAGIC_CHECK)\n\t\t\t\tfile_magwarn(ms, \"invalid string op: %c\", *t);\n\t\t\treturn -1;\n\t\t}\n\t}\n\t/*\n\t * We used to set mask to all 1's here, instead let's just not do\n\t * anything if mask = 0 (unless you have a better idea)\n\t */\n\tEATAB;\n  \n\tswitch (*l) {\n\tcase '>':\n\tcase '<':\n  \t\tm->reln = *l;\n  \t\t++l;\n\t\tif (*l == '=') {\n\t\t\tif (ms->flags & MAGIC_CHECK) {\n\t\t\t\tfile_magwarn(ms, \"%c= not supported\",\n\t\t\t\t    m->reln);\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t   ++l;\n\t\t}\n\t\tbreak;\n\t/* Old-style anding: \"0 byte &0x80 dynamically linked\" */\n\tcase '&':\n\tcase '^':\n\tcase '=':\n  \t\tm->reln = *l;\n  \t\t++l;\n\t\tif (*l == '=') {\n\t\t   /* HP compat: ignore &= etc. */\n\t\t   ++l;\n\t\t}\n\t\tbreak;\n\tcase '!':\n\t\tm->reln = *l;\n\t\t++l;\n\t\tbreak;\n\tdefault:\n  \t\tm->reln = '=';\t/* the default relation */\n\t\tif (*l == 'x' && ((isascii((unsigned char)l[1]) && \n\t\t    isspace((unsigned char)l[1])) || !l[1])) {\n\t\t\tm->reln = *l;\n\t\t\t++l;\n\t\t}\n\t\tbreak;\n\t}\n\t/*\n\t * Grab the value part, except for an 'x' reln.\n\t */\n\tif (m->reln != 'x' && getvalue(ms, m, &l, action))\n\t\treturn -1;\n\n\t/*\n\t * TODO finish this macro and start using it!\n\t * #define offsetcheck {if (offset > HOWMANY-1) \n\t *\tmagwarn(\"offset too big\"); }\n\t */\n\n\t/*\n\t * Now get last part - the description\n\t */\n\tEATAB;\n\tif (l[0] == '\\b') {\n\t\t++l;\n\t\tm->flag |= NOSPACE;\n\t} else if ((l[0] == '\\\\') && (l[1] == 'b')) {\n\t\t++l;\n\t\t++l;\n\t\tm->flag |= NOSPACE;\n\t}\n\tfor (i = 0; (m->desc[i++] = *l++) != '\\0' && i < sizeof(m->desc); )\n\t\tcontinue;\n\tif (i == sizeof(m->desc)) {\n\t\tm->desc[sizeof(m->desc) - 1] = '\\0';\n\t\tif (ms->flags & MAGIC_CHECK)\n\t\t\tfile_magwarn(ms, \"description `%s' truncated\", m->desc);\n\t}\n\n        /*\n\t * We only do this check while compiling, or if any of the magic\n\t * files were not compiled.\n         */\n        if (ms->flags & MAGIC_CHECK) {\n\t\tif (check_format(ms, m) == -1)\n\t\t\treturn -1;\n\t}\n#ifndef COMPILE_ONLY\n\tif (action == FILE_CHECK) {\n\t\tfile_mdump(m);\n\t}\n#endif\n\tm->mimetype[0] = '\\0';\t\t/* initialise MIME type to none */\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -340,8 +340,13 @@\n \t\t\t\t\tm->str_flags = (m->str_flags & ~PSTRING_LEN) | PSTRING_4_BE;\n \t\t\t\t\tbreak;\n \t\t\t\tcase CHAR_PSTRING_4_LE:\n-\t\t\t\t\tif (m->type != FILE_PSTRING)\n-\t\t\t\t\t\tgoto bad;\n+\t\t\t\t\tswitch (m->type) {\n+\t\t\t\t\tcase FILE_PSTRING:\n+\t\t\t\t\tcase FILE_REGEX:\n+\t\t\t\t\t\tbreak;\n+\t\t\t\t\tdefault:\n+\t\t\t\t\t\tgoto bad;\n+\t\t\t\t\t}\n \t\t\t\t\tm->str_flags = (m->str_flags & ~PSTRING_LEN) | PSTRING_4_LE;\n \t\t\t\t\tbreak;\n \t\t\t\tcase CHAR_PSTRING_LENGTH_INCLUDES_ITSELF:",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\t\t\tif (m->type != FILE_PSTRING)",
                "\t\t\t\t\t\tgoto bad;"
            ],
            "added_lines": [
                "\t\t\t\t\tswitch (m->type) {",
                "\t\t\t\t\tcase FILE_PSTRING:",
                "\t\t\t\t\tcase FILE_REGEX:",
                "\t\t\t\t\t\tbreak;",
                "\t\t\t\t\tdefault:",
                "\t\t\t\t\t\tgoto bad;",
                "\t\t\t\t\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-3538",
        "func_name": "file/mprint",
        "description": "file before 5.19 does not properly restrict the amount of data read during a regex search, which allows remote attackers to cause a denial of service (CPU consumption) via a crafted file that triggers backtracking during processing of an awk rule.  NOTE: this vulnerability exists because of an incomplete fix for CVE-2013-7345.",
        "git_url": "https://github.com/file/file/commit/4a284c89d6ef11aca34da65da7d673050a5ea320",
        "commit_title": "* Enforce limit of 8K on regex searches that have no limits",
        "commit_text": "* Allow the l modifier for regex to mean line count. Default   to byte count. If line count is specified, assume a max   of 80 characters per line to limit the byte count. * Don't allow conversions to be used for dates, allowing   the mask field to be used as an offset. * Bump the version of the magic format so that regex changes   are visible.",
        "func_before": "private int32_t\nmprint(struct magic_set *ms, struct magic *m)\n{\n\tuint64_t v;\n\tfloat vf;\n\tdouble vd;\n\tint64_t t = 0;\n \tchar buf[128], tbuf[26];\n\tunion VALUETYPE *p = &ms->ms_value;\n\n  \tswitch (m->type) {\n  \tcase FILE_BYTE:\n\t\tv = file_signextend(ms, m, (uint64_t)p->b);\n\t\tswitch (check_fmt(ms, m)) {\n\t\tcase -1:\n\t\t\treturn -1;\n\t\tcase 1:\n\t\t\t(void)snprintf(buf, sizeof(buf), \"%d\",\n\t\t\t    (unsigned char)v);\n\t\t\tif (file_printf(ms, F(ms, m, \"%s\"), buf) == -1)\n\t\t\t\treturn -1;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tif (file_printf(ms, F(ms, m, \"%d\"),\n\t\t\t    (unsigned char) v) == -1)\n\t\t\t\treturn -1;\n\t\t\tbreak;\n\t\t}\n\t\tt = ms->offset + sizeof(char);\n\t\tbreak;\n\n  \tcase FILE_SHORT:\n  \tcase FILE_BESHORT:\n  \tcase FILE_LESHORT:\n\t\tv = file_signextend(ms, m, (uint64_t)p->h);\n\t\tswitch (check_fmt(ms, m)) {\n\t\tcase -1:\n\t\t\treturn -1;\n\t\tcase 1:\n\t\t\t(void)snprintf(buf, sizeof(buf), \"%u\",\n\t\t\t    (unsigned short)v);\n\t\t\tif (file_printf(ms, F(ms, m, \"%s\"), buf) == -1)\n\t\t\t\treturn -1;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tif (file_printf(ms, F(ms, m, \"%u\"),\n\t\t\t    (unsigned short) v) == -1)\n\t\t\t\treturn -1;\n\t\t\tbreak;\n\t\t}\n\t\tt = ms->offset + sizeof(short);\n\t\tbreak;\n\n  \tcase FILE_LONG:\n  \tcase FILE_BELONG:\n  \tcase FILE_LELONG:\n  \tcase FILE_MELONG:\n\t\tv = file_signextend(ms, m, (uint64_t)p->l);\n\t\tswitch (check_fmt(ms, m)) {\n\t\tcase -1:\n\t\t\treturn -1;\n\t\tcase 1:\n\t\t\t(void)snprintf(buf, sizeof(buf), \"%u\", (uint32_t) v);\n\t\t\tif (file_printf(ms, F(ms, m, \"%s\"), buf) == -1)\n\t\t\t\treturn -1;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tif (file_printf(ms, F(ms, m, \"%u\"), (uint32_t) v) == -1)\n\t\t\t\treturn -1;\n\t\t\tbreak;\n\t\t}\n\t\tt = ms->offset + sizeof(int32_t);\n  \t\tbreak;\n\n  \tcase FILE_QUAD:\n  \tcase FILE_BEQUAD:\n  \tcase FILE_LEQUAD:\n\t\tv = file_signextend(ms, m, p->q);\n\t\tswitch (check_fmt(ms, m)) {\n\t\tcase -1:\n\t\t\treturn -1;\n\t\tcase 1:\n\t\t\t(void)snprintf(buf, sizeof(buf), \"%\" INT64_T_FORMAT \"u\",\n\t\t\t    (unsigned long long)v);\n\t\t\tif (file_printf(ms, F(ms, m, \"%s\"), buf) == -1)\n\t\t\t\treturn -1;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tif (file_printf(ms, F(ms, m, \"%\" INT64_T_FORMAT \"u\"),\n\t\t\t    (unsigned long long) v) == -1)\n\t\t\t\treturn -1;\n\t\t\tbreak;\n\t\t}\n\t\tt = ms->offset + sizeof(int64_t);\n  \t\tbreak;\n\n  \tcase FILE_STRING:\n  \tcase FILE_PSTRING:\n  \tcase FILE_BESTRING16:\n  \tcase FILE_LESTRING16:\n\t\tif (m->reln == '=' || m->reln == '!') {\n\t\t\tif (file_printf(ms, F(ms, m, \"%s\"), m->value.s) == -1)\n\t\t\t\treturn -1;\n\t\t\tt = ms->offset + m->vallen;\n\t\t}\n\t\telse {\n\t\t\tchar *str = p->s;\n\n\t\t\t/* compute t before we mangle the string? */\n\t\t\tt = ms->offset + strlen(str);\n\n\t\t\tif (*m->value.s == '\\0')\n\t\t\t\tstr[strcspn(str, \"\\n\")] = '\\0';\n\n\t\t\tif (m->str_flags & STRING_TRIM) {\n\t\t\t\tchar *last;\n\t\t\t\twhile (isspace((unsigned char)*str))\n\t\t\t\t\tstr++;\n\t\t\t\tlast = str;\n\t\t\t\twhile (*last)\n\t\t\t\t\tlast++;\n\t\t\t\t--last;\n\t\t\t\twhile (isspace((unsigned char)*last))\n\t\t\t\t\tlast--;\n\t\t\t\t*++last = '\\0';\n\t\t\t}\n\n\t\t\tif (file_printf(ms, F(ms, m, \"%s\"), str) == -1)\n\t\t\t\treturn -1;\n\n\t\t\tif (m->type == FILE_PSTRING)\n\t\t\t\tt += file_pstring_length_size(m);\n\t\t}\n\t\tbreak;\n\n\tcase FILE_DATE:\n\tcase FILE_BEDATE:\n\tcase FILE_LEDATE:\n\tcase FILE_MEDATE:\n\t\tif (file_printf(ms, F(ms, m, \"%s\"),\n\t\t    file_fmttime(p->l, FILE_T_LOCAL, tbuf)) == -1)\n\t\t\treturn -1;\n\t\tt = ms->offset + sizeof(uint32_t);\n\t\tbreak;\n\n\tcase FILE_LDATE:\n\tcase FILE_BELDATE:\n\tcase FILE_LELDATE:\n\tcase FILE_MELDATE:\n\t\tif (file_printf(ms, F(ms, m, \"%s\"),\n\t\t    file_fmttime(p->l, 0, tbuf)) == -1)\n\t\t\treturn -1;\n\t\tt = ms->offset + sizeof(uint32_t);\n\t\tbreak;\n\n\tcase FILE_QDATE:\n\tcase FILE_BEQDATE:\n\tcase FILE_LEQDATE:\n\t\tif (file_printf(ms, F(ms, m, \"%s\"),\n\t\t    file_fmttime(p->q, FILE_T_LOCAL, tbuf)) == -1)\n\t\t\treturn -1;\n\t\tt = ms->offset + sizeof(uint64_t);\n\t\tbreak;\n\n\tcase FILE_QLDATE:\n\tcase FILE_BEQLDATE:\n\tcase FILE_LEQLDATE:\n\t\tif (file_printf(ms, F(ms, m, \"%s\"),\n\t\t    file_fmttime(p->q, 0, tbuf)) == -1)\n\t\t\treturn -1;\n\t\tt = ms->offset + sizeof(uint64_t);\n\t\tbreak;\n\n\tcase FILE_QWDATE:\n\tcase FILE_BEQWDATE:\n\tcase FILE_LEQWDATE:\n\t\tif (file_printf(ms, F(ms, m, \"%s\"),\n\t\t    file_fmttime(p->q, FILE_T_WINDOWS, tbuf)) == -1)\n\t\t\treturn -1;\n\t\tt = ms->offset + sizeof(uint64_t);\n\t\tbreak;\n\n  \tcase FILE_FLOAT:\n  \tcase FILE_BEFLOAT:\n  \tcase FILE_LEFLOAT:\n\t\tvf = p->f;\n\t\tswitch (check_fmt(ms, m)) {\n\t\tcase -1:\n\t\t\treturn -1;\n\t\tcase 1:\n\t\t\t(void)snprintf(buf, sizeof(buf), \"%g\", vf);\n\t\t\tif (file_printf(ms, F(ms, m, \"%s\"), buf) == -1)\n\t\t\t\treturn -1;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tif (file_printf(ms, F(ms, m, \"%g\"), vf) == -1)\n\t\t\t\treturn -1;\n\t\t\tbreak;\n\t\t}\n\t\tt = ms->offset + sizeof(float);\n  \t\tbreak;\n\n  \tcase FILE_DOUBLE:\n  \tcase FILE_BEDOUBLE:\n  \tcase FILE_LEDOUBLE:\n\t\tvd = p->d;\n\t\tswitch (check_fmt(ms, m)) {\n\t\tcase -1:\n\t\t\treturn -1;\n\t\tcase 1:\n\t\t\t(void)snprintf(buf, sizeof(buf), \"%g\", vd);\n\t\t\tif (file_printf(ms, F(ms, m, \"%s\"), buf) == -1)\n\t\t\t\treturn -1;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tif (file_printf(ms, F(ms, m, \"%g\"), vd) == -1)\n\t\t\t\treturn -1;\n\t\t\tbreak;\n\t\t}\n\t\tt = ms->offset + sizeof(double);\n  \t\tbreak;\n\n\tcase FILE_REGEX: {\n\t\tchar *cp;\n\t\tint rval;\n\n\t\tcp = strndup((const char *)ms->search.s, ms->search.rm_len);\n\t\tif (cp == NULL) {\n\t\t\tfile_oomem(ms, ms->search.rm_len);\n\t\t\treturn -1;\n\t\t}\n\t\trval = file_printf(ms, F(ms, m, \"%s\"), cp);\n\t\tfree(cp);\n\n\t\tif (rval == -1)\n\t\t\treturn -1;\n\n\t\tif ((m->str_flags & REGEX_OFFSET_START))\n\t\t\tt = ms->search.offset;\n\t\telse\n\t\t\tt = ms->search.offset + ms->search.rm_len;\n\t\tbreak;\n\t}\n\n\tcase FILE_SEARCH:\n\t  \tif (file_printf(ms, F(ms, m, \"%s\"), m->value.s) == -1)\n\t\t\treturn -1;\n\t\tif ((m->str_flags & REGEX_OFFSET_START))\n\t\t\tt = ms->search.offset;\n\t\telse\n\t\t\tt = ms->search.offset + m->vallen;\n\t\tbreak;\n\n\tcase FILE_DEFAULT:\n\tcase FILE_CLEAR:\n\t  \tif (file_printf(ms, \"%s\", m->desc) == -1)\n\t\t\treturn -1;\n\t\tt = ms->offset;\n\t\tbreak;\n\n\tcase FILE_INDIRECT:\n\tcase FILE_USE:\n\tcase FILE_NAME:\n\t\tt = ms->offset;\n\t\tbreak;\n\n\tdefault:\n\t\tfile_magerror(ms, \"invalid m->type (%d) in mprint()\", m->type);\n\t\treturn -1;\n\t}\n\treturn (int32_t)t;\n}",
        "func": "private int32_t\nmprint(struct magic_set *ms, struct magic *m)\n{\n\tuint64_t v;\n\tfloat vf;\n\tdouble vd;\n\tint64_t t = 0;\n \tchar buf[128], tbuf[26];\n\tunion VALUETYPE *p = &ms->ms_value;\n\n  \tswitch (m->type) {\n  \tcase FILE_BYTE:\n\t\tv = file_signextend(ms, m, (uint64_t)p->b);\n\t\tswitch (check_fmt(ms, m)) {\n\t\tcase -1:\n\t\t\treturn -1;\n\t\tcase 1:\n\t\t\t(void)snprintf(buf, sizeof(buf), \"%d\",\n\t\t\t    (unsigned char)v);\n\t\t\tif (file_printf(ms, F(ms, m, \"%s\"), buf) == -1)\n\t\t\t\treturn -1;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tif (file_printf(ms, F(ms, m, \"%d\"),\n\t\t\t    (unsigned char) v) == -1)\n\t\t\t\treturn -1;\n\t\t\tbreak;\n\t\t}\n\t\tt = ms->offset + sizeof(char);\n\t\tbreak;\n\n  \tcase FILE_SHORT:\n  \tcase FILE_BESHORT:\n  \tcase FILE_LESHORT:\n\t\tv = file_signextend(ms, m, (uint64_t)p->h);\n\t\tswitch (check_fmt(ms, m)) {\n\t\tcase -1:\n\t\t\treturn -1;\n\t\tcase 1:\n\t\t\t(void)snprintf(buf, sizeof(buf), \"%u\",\n\t\t\t    (unsigned short)v);\n\t\t\tif (file_printf(ms, F(ms, m, \"%s\"), buf) == -1)\n\t\t\t\treturn -1;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tif (file_printf(ms, F(ms, m, \"%u\"),\n\t\t\t    (unsigned short) v) == -1)\n\t\t\t\treturn -1;\n\t\t\tbreak;\n\t\t}\n\t\tt = ms->offset + sizeof(short);\n\t\tbreak;\n\n  \tcase FILE_LONG:\n  \tcase FILE_BELONG:\n  \tcase FILE_LELONG:\n  \tcase FILE_MELONG:\n\t\tv = file_signextend(ms, m, (uint64_t)p->l);\n\t\tswitch (check_fmt(ms, m)) {\n\t\tcase -1:\n\t\t\treturn -1;\n\t\tcase 1:\n\t\t\t(void)snprintf(buf, sizeof(buf), \"%u\", (uint32_t) v);\n\t\t\tif (file_printf(ms, F(ms, m, \"%s\"), buf) == -1)\n\t\t\t\treturn -1;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tif (file_printf(ms, F(ms, m, \"%u\"), (uint32_t) v) == -1)\n\t\t\t\treturn -1;\n\t\t\tbreak;\n\t\t}\n\t\tt = ms->offset + sizeof(int32_t);\n  \t\tbreak;\n\n  \tcase FILE_QUAD:\n  \tcase FILE_BEQUAD:\n  \tcase FILE_LEQUAD:\n\t\tv = file_signextend(ms, m, p->q);\n\t\tswitch (check_fmt(ms, m)) {\n\t\tcase -1:\n\t\t\treturn -1;\n\t\tcase 1:\n\t\t\t(void)snprintf(buf, sizeof(buf), \"%\" INT64_T_FORMAT \"u\",\n\t\t\t    (unsigned long long)v);\n\t\t\tif (file_printf(ms, F(ms, m, \"%s\"), buf) == -1)\n\t\t\t\treturn -1;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tif (file_printf(ms, F(ms, m, \"%\" INT64_T_FORMAT \"u\"),\n\t\t\t    (unsigned long long) v) == -1)\n\t\t\t\treturn -1;\n\t\t\tbreak;\n\t\t}\n\t\tt = ms->offset + sizeof(int64_t);\n  \t\tbreak;\n\n  \tcase FILE_STRING:\n  \tcase FILE_PSTRING:\n  \tcase FILE_BESTRING16:\n  \tcase FILE_LESTRING16:\n\t\tif (m->reln == '=' || m->reln == '!') {\n\t\t\tif (file_printf(ms, F(ms, m, \"%s\"), m->value.s) == -1)\n\t\t\t\treturn -1;\n\t\t\tt = ms->offset + m->vallen;\n\t\t}\n\t\telse {\n\t\t\tchar *str = p->s;\n\n\t\t\t/* compute t before we mangle the string? */\n\t\t\tt = ms->offset + strlen(str);\n\n\t\t\tif (*m->value.s == '\\0')\n\t\t\t\tstr[strcspn(str, \"\\n\")] = '\\0';\n\n\t\t\tif (m->str_flags & STRING_TRIM) {\n\t\t\t\tchar *last;\n\t\t\t\twhile (isspace((unsigned char)*str))\n\t\t\t\t\tstr++;\n\t\t\t\tlast = str;\n\t\t\t\twhile (*last)\n\t\t\t\t\tlast++;\n\t\t\t\t--last;\n\t\t\t\twhile (isspace((unsigned char)*last))\n\t\t\t\t\tlast--;\n\t\t\t\t*++last = '\\0';\n\t\t\t}\n\n\t\t\tif (file_printf(ms, F(ms, m, \"%s\"), str) == -1)\n\t\t\t\treturn -1;\n\n\t\t\tif (m->type == FILE_PSTRING)\n\t\t\t\tt += file_pstring_length_size(m);\n\t\t}\n\t\tbreak;\n\n\tcase FILE_DATE:\n\tcase FILE_BEDATE:\n\tcase FILE_LEDATE:\n\tcase FILE_MEDATE:\n\t\tif (file_printf(ms, F(ms, m, \"%s\"),\n\t\t    file_fmttime(p->l + m->num_mask, FILE_T_LOCAL, tbuf)) == -1)\n\t\t\treturn -1;\n\t\tt = ms->offset + sizeof(uint32_t);\n\t\tbreak;\n\n\tcase FILE_LDATE:\n\tcase FILE_BELDATE:\n\tcase FILE_LELDATE:\n\tcase FILE_MELDATE:\n\t\tif (file_printf(ms, F(ms, m, \"%s\"),\n\t\t    file_fmttime(p->l + m->num_mask, 0, tbuf)) == -1)\n\t\t\treturn -1;\n\t\tt = ms->offset + sizeof(uint32_t);\n\t\tbreak;\n\n\tcase FILE_QDATE:\n\tcase FILE_BEQDATE:\n\tcase FILE_LEQDATE:\n\t\tif (file_printf(ms, F(ms, m, \"%s\"),\n\t\t    file_fmttime(p->q + m->num_mask, FILE_T_LOCAL, tbuf)) == -1)\n\t\t\treturn -1;\n\t\tt = ms->offset + sizeof(uint64_t);\n\t\tbreak;\n\n\tcase FILE_QLDATE:\n\tcase FILE_BEQLDATE:\n\tcase FILE_LEQLDATE:\n\t\tif (file_printf(ms, F(ms, m, \"%s\"),\n\t\t    file_fmttime(p->q + m->num_mask, 0, tbuf)) == -1)\n\t\t\treturn -1;\n\t\tt = ms->offset + sizeof(uint64_t);\n\t\tbreak;\n\n\tcase FILE_QWDATE:\n\tcase FILE_BEQWDATE:\n\tcase FILE_LEQWDATE:\n\t\tif (file_printf(ms, F(ms, m, \"%s\"),\n\t\t    file_fmttime(p->q + m->num_mask, FILE_T_WINDOWS, tbuf)) == -1)\n\t\t\treturn -1;\n\t\tt = ms->offset + sizeof(uint64_t);\n\t\tbreak;\n\n  \tcase FILE_FLOAT:\n  \tcase FILE_BEFLOAT:\n  \tcase FILE_LEFLOAT:\n\t\tvf = p->f;\n\t\tswitch (check_fmt(ms, m)) {\n\t\tcase -1:\n\t\t\treturn -1;\n\t\tcase 1:\n\t\t\t(void)snprintf(buf, sizeof(buf), \"%g\", vf);\n\t\t\tif (file_printf(ms, F(ms, m, \"%s\"), buf) == -1)\n\t\t\t\treturn -1;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tif (file_printf(ms, F(ms, m, \"%g\"), vf) == -1)\n\t\t\t\treturn -1;\n\t\t\tbreak;\n\t\t}\n\t\tt = ms->offset + sizeof(float);\n  \t\tbreak;\n\n  \tcase FILE_DOUBLE:\n  \tcase FILE_BEDOUBLE:\n  \tcase FILE_LEDOUBLE:\n\t\tvd = p->d;\n\t\tswitch (check_fmt(ms, m)) {\n\t\tcase -1:\n\t\t\treturn -1;\n\t\tcase 1:\n\t\t\t(void)snprintf(buf, sizeof(buf), \"%g\", vd);\n\t\t\tif (file_printf(ms, F(ms, m, \"%s\"), buf) == -1)\n\t\t\t\treturn -1;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tif (file_printf(ms, F(ms, m, \"%g\"), vd) == -1)\n\t\t\t\treturn -1;\n\t\t\tbreak;\n\t\t}\n\t\tt = ms->offset + sizeof(double);\n  \t\tbreak;\n\n\tcase FILE_REGEX: {\n\t\tchar *cp;\n\t\tint rval;\n\n\t\tcp = strndup((const char *)ms->search.s, ms->search.rm_len);\n\t\tif (cp == NULL) {\n\t\t\tfile_oomem(ms, ms->search.rm_len);\n\t\t\treturn -1;\n\t\t}\n\t\trval = file_printf(ms, F(ms, m, \"%s\"), cp);\n\t\tfree(cp);\n\n\t\tif (rval == -1)\n\t\t\treturn -1;\n\n\t\tif ((m->str_flags & REGEX_OFFSET_START))\n\t\t\tt = ms->search.offset;\n\t\telse\n\t\t\tt = ms->search.offset + ms->search.rm_len;\n\t\tbreak;\n\t}\n\n\tcase FILE_SEARCH:\n\t  \tif (file_printf(ms, F(ms, m, \"%s\"), m->value.s) == -1)\n\t\t\treturn -1;\n\t\tif ((m->str_flags & REGEX_OFFSET_START))\n\t\t\tt = ms->search.offset;\n\t\telse\n\t\t\tt = ms->search.offset + m->vallen;\n\t\tbreak;\n\n\tcase FILE_DEFAULT:\n\tcase FILE_CLEAR:\n\t  \tif (file_printf(ms, \"%s\", m->desc) == -1)\n\t\t\treturn -1;\n\t\tt = ms->offset;\n\t\tbreak;\n\n\tcase FILE_INDIRECT:\n\tcase FILE_USE:\n\tcase FILE_NAME:\n\t\tt = ms->offset;\n\t\tbreak;\n\n\tdefault:\n\t\tfile_magerror(ms, \"invalid m->type (%d) in mprint()\", m->type);\n\t\treturn -1;\n\t}\n\treturn (int32_t)t;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -138,7 +138,7 @@\n \tcase FILE_LEDATE:\n \tcase FILE_MEDATE:\n \t\tif (file_printf(ms, F(ms, m, \"%s\"),\n-\t\t    file_fmttime(p->l, FILE_T_LOCAL, tbuf)) == -1)\n+\t\t    file_fmttime(p->l + m->num_mask, FILE_T_LOCAL, tbuf)) == -1)\n \t\t\treturn -1;\n \t\tt = ms->offset + sizeof(uint32_t);\n \t\tbreak;\n@@ -148,7 +148,7 @@\n \tcase FILE_LELDATE:\n \tcase FILE_MELDATE:\n \t\tif (file_printf(ms, F(ms, m, \"%s\"),\n-\t\t    file_fmttime(p->l, 0, tbuf)) == -1)\n+\t\t    file_fmttime(p->l + m->num_mask, 0, tbuf)) == -1)\n \t\t\treturn -1;\n \t\tt = ms->offset + sizeof(uint32_t);\n \t\tbreak;\n@@ -157,7 +157,7 @@\n \tcase FILE_BEQDATE:\n \tcase FILE_LEQDATE:\n \t\tif (file_printf(ms, F(ms, m, \"%s\"),\n-\t\t    file_fmttime(p->q, FILE_T_LOCAL, tbuf)) == -1)\n+\t\t    file_fmttime(p->q + m->num_mask, FILE_T_LOCAL, tbuf)) == -1)\n \t\t\treturn -1;\n \t\tt = ms->offset + sizeof(uint64_t);\n \t\tbreak;\n@@ -166,7 +166,7 @@\n \tcase FILE_BEQLDATE:\n \tcase FILE_LEQLDATE:\n \t\tif (file_printf(ms, F(ms, m, \"%s\"),\n-\t\t    file_fmttime(p->q, 0, tbuf)) == -1)\n+\t\t    file_fmttime(p->q + m->num_mask, 0, tbuf)) == -1)\n \t\t\treturn -1;\n \t\tt = ms->offset + sizeof(uint64_t);\n \t\tbreak;\n@@ -175,7 +175,7 @@\n \tcase FILE_BEQWDATE:\n \tcase FILE_LEQWDATE:\n \t\tif (file_printf(ms, F(ms, m, \"%s\"),\n-\t\t    file_fmttime(p->q, FILE_T_WINDOWS, tbuf)) == -1)\n+\t\t    file_fmttime(p->q + m->num_mask, FILE_T_WINDOWS, tbuf)) == -1)\n \t\t\treturn -1;\n \t\tt = ms->offset + sizeof(uint64_t);\n \t\tbreak;",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t    file_fmttime(p->l, FILE_T_LOCAL, tbuf)) == -1)",
                "\t\t    file_fmttime(p->l, 0, tbuf)) == -1)",
                "\t\t    file_fmttime(p->q, FILE_T_LOCAL, tbuf)) == -1)",
                "\t\t    file_fmttime(p->q, 0, tbuf)) == -1)",
                "\t\t    file_fmttime(p->q, FILE_T_WINDOWS, tbuf)) == -1)"
            ],
            "added_lines": [
                "\t\t    file_fmttime(p->l + m->num_mask, FILE_T_LOCAL, tbuf)) == -1)",
                "\t\t    file_fmttime(p->l + m->num_mask, 0, tbuf)) == -1)",
                "\t\t    file_fmttime(p->q + m->num_mask, FILE_T_LOCAL, tbuf)) == -1)",
                "\t\t    file_fmttime(p->q + m->num_mask, 0, tbuf)) == -1)",
                "\t\t    file_fmttime(p->q + m->num_mask, FILE_T_WINDOWS, tbuf)) == -1)"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-3538",
        "func_name": "file/mconvert",
        "description": "file before 5.19 does not properly restrict the amount of data read during a regex search, which allows remote attackers to cause a denial of service (CPU consumption) via a crafted file that triggers backtracking during processing of an awk rule.  NOTE: this vulnerability exists because of an incomplete fix for CVE-2013-7345.",
        "git_url": "https://github.com/file/file/commit/4a284c89d6ef11aca34da65da7d673050a5ea320",
        "commit_title": "* Enforce limit of 8K on regex searches that have no limits",
        "commit_text": "* Allow the l modifier for regex to mean line count. Default   to byte count. If line count is specified, assume a max   of 80 characters per line to limit the byte count. * Don't allow conversions to be used for dates, allowing   the mask field to be used as an offset. * Bump the version of the magic format so that regex changes   are visible.",
        "func_before": "private int\nmconvert(struct magic_set *ms, struct magic *m, int flip)\n{\n\tunion VALUETYPE *p = &ms->ms_value;\n\n\tswitch (cvt_flip(m->type, flip)) {\n\tcase FILE_BYTE:\n\t\tcvt_8(p, m);\n\t\treturn 1;\n\tcase FILE_SHORT:\n\t\tcvt_16(p, m);\n\t\treturn 1;\n\tcase FILE_LONG:\n\tcase FILE_DATE:\n\tcase FILE_LDATE:\n\t\tcvt_32(p, m);\n\t\treturn 1;\n\tcase FILE_QUAD:\n\tcase FILE_QDATE:\n\tcase FILE_QLDATE:\n\tcase FILE_QWDATE:\n\t\tcvt_64(p, m);\n\t\treturn 1;\n\tcase FILE_STRING:\n\tcase FILE_BESTRING16:\n\tcase FILE_LESTRING16: {\n\t\t/* Null terminate and eat *trailing* return */\n\t\tp->s[sizeof(p->s) - 1] = '\\0';\n\t\treturn 1;\n\t}\n\tcase FILE_PSTRING: {\n\t\tchar *ptr1 = p->s, *ptr2 = ptr1 + file_pstring_length_size(m);\n\t\tsize_t len = file_pstring_get_length(m, ptr1);\n\t\tif (len >= sizeof(p->s))\n\t\t\tlen = sizeof(p->s) - 1;\n\t\twhile (len--)\n\t\t\t*ptr1++ = *ptr2++;\n\t\t*ptr1 = '\\0';\n\t\treturn 1;\n\t}\n\tcase FILE_BESHORT:\n\t\tp->h = (short)((p->hs[0]<<8)|(p->hs[1]));\n\t\tcvt_16(p, m);\n\t\treturn 1;\n\tcase FILE_BELONG:\n\tcase FILE_BEDATE:\n\tcase FILE_BELDATE:\n\t\tp->l = (int32_t)\n\t\t    ((p->hl[0]<<24)|(p->hl[1]<<16)|(p->hl[2]<<8)|(p->hl[3]));\n\t\tcvt_32(p, m);\n\t\treturn 1;\n\tcase FILE_BEQUAD:\n\tcase FILE_BEQDATE:\n\tcase FILE_BEQLDATE:\n\tcase FILE_BEQWDATE:\n\t\tp->q = (uint64_t)\n\t\t    (((uint64_t)p->hq[0]<<56)|((uint64_t)p->hq[1]<<48)|\n\t\t     ((uint64_t)p->hq[2]<<40)|((uint64_t)p->hq[3]<<32)|\n\t\t     ((uint64_t)p->hq[4]<<24)|((uint64_t)p->hq[5]<<16)|\n\t\t     ((uint64_t)p->hq[6]<<8)|((uint64_t)p->hq[7]));\n\t\tcvt_64(p, m);\n\t\treturn 1;\n\tcase FILE_LESHORT:\n\t\tp->h = (short)((p->hs[1]<<8)|(p->hs[0]));\n\t\tcvt_16(p, m);\n\t\treturn 1;\n\tcase FILE_LELONG:\n\tcase FILE_LEDATE:\n\tcase FILE_LELDATE:\n\t\tp->l = (int32_t)\n\t\t    ((p->hl[3]<<24)|(p->hl[2]<<16)|(p->hl[1]<<8)|(p->hl[0]));\n\t\tcvt_32(p, m);\n\t\treturn 1;\n\tcase FILE_LEQUAD:\n\tcase FILE_LEQDATE:\n\tcase FILE_LEQLDATE:\n\tcase FILE_LEQWDATE:\n\t\tp->q = (uint64_t)\n\t\t    (((uint64_t)p->hq[7]<<56)|((uint64_t)p->hq[6]<<48)|\n\t\t     ((uint64_t)p->hq[5]<<40)|((uint64_t)p->hq[4]<<32)|\n\t\t     ((uint64_t)p->hq[3]<<24)|((uint64_t)p->hq[2]<<16)|\n\t\t     ((uint64_t)p->hq[1]<<8)|((uint64_t)p->hq[0]));\n\t\tcvt_64(p, m);\n\t\treturn 1;\n\tcase FILE_MELONG:\n\tcase FILE_MEDATE:\n\tcase FILE_MELDATE:\n\t\tp->l = (int32_t)\n\t\t    ((p->hl[1]<<24)|(p->hl[0]<<16)|(p->hl[3]<<8)|(p->hl[2]));\n\t\tcvt_32(p, m);\n\t\treturn 1;\n\tcase FILE_FLOAT:\n\t\tcvt_float(p, m);\n\t\treturn 1;\n\tcase FILE_BEFLOAT:\n\t\tp->l =  ((uint32_t)p->hl[0]<<24)|((uint32_t)p->hl[1]<<16)|\n\t\t\t((uint32_t)p->hl[2]<<8) |((uint32_t)p->hl[3]);\n\t\tcvt_float(p, m);\n\t\treturn 1;\n\tcase FILE_LEFLOAT:\n\t\tp->l =  ((uint32_t)p->hl[3]<<24)|((uint32_t)p->hl[2]<<16)|\n\t\t\t((uint32_t)p->hl[1]<<8) |((uint32_t)p->hl[0]);\n\t\tcvt_float(p, m);\n\t\treturn 1;\n\tcase FILE_DOUBLE:\n\t\tcvt_double(p, m);\n\t\treturn 1;\n\tcase FILE_BEDOUBLE:\n\t\tp->q =  ((uint64_t)p->hq[0]<<56)|((uint64_t)p->hq[1]<<48)|\n\t\t\t((uint64_t)p->hq[2]<<40)|((uint64_t)p->hq[3]<<32)|\n\t\t\t((uint64_t)p->hq[4]<<24)|((uint64_t)p->hq[5]<<16)|\n\t\t\t((uint64_t)p->hq[6]<<8) |((uint64_t)p->hq[7]);\n\t\tcvt_double(p, m);\n\t\treturn 1;\n\tcase FILE_LEDOUBLE:\n\t\tp->q =  ((uint64_t)p->hq[7]<<56)|((uint64_t)p->hq[6]<<48)|\n\t\t\t((uint64_t)p->hq[5]<<40)|((uint64_t)p->hq[4]<<32)|\n\t\t\t((uint64_t)p->hq[3]<<24)|((uint64_t)p->hq[2]<<16)|\n\t\t\t((uint64_t)p->hq[1]<<8) |((uint64_t)p->hq[0]);\n\t\tcvt_double(p, m);\n\t\treturn 1;\n\tcase FILE_REGEX:\n\tcase FILE_SEARCH:\n\tcase FILE_DEFAULT:\n\tcase FILE_CLEAR:\n\tcase FILE_NAME:\n\tcase FILE_USE:\n\t\treturn 1;\n\tdefault:\n\t\tfile_magerror(ms, \"invalid type %d in mconvert()\", m->type);\n\t\treturn 0;\n\t}\n}",
        "func": "private int\nmconvert(struct magic_set *ms, struct magic *m, int flip)\n{\n\tunion VALUETYPE *p = &ms->ms_value;\n\tuint8_t type;\n\n\tswitch (type = cvt_flip(m->type, flip)) {\n\tcase FILE_BYTE:\n\t\tcvt_8(p, m);\n\t\treturn 1;\n\tcase FILE_SHORT:\n\t\tcvt_16(p, m);\n\t\treturn 1;\n\tcase FILE_LONG:\n\tcase FILE_DATE:\n\tcase FILE_LDATE:\n\t\tcvt_32(p, m);\n\t\treturn 1;\n\tcase FILE_QUAD:\n\tcase FILE_QDATE:\n\tcase FILE_QLDATE:\n\tcase FILE_QWDATE:\n\t\tcvt_64(p, m);\n\t\treturn 1;\n\tcase FILE_STRING:\n\tcase FILE_BESTRING16:\n\tcase FILE_LESTRING16: {\n\t\t/* Null terminate and eat *trailing* return */\n\t\tp->s[sizeof(p->s) - 1] = '\\0';\n\t\treturn 1;\n\t}\n\tcase FILE_PSTRING: {\n\t\tchar *ptr1 = p->s, *ptr2 = ptr1 + file_pstring_length_size(m);\n\t\tsize_t len = file_pstring_get_length(m, ptr1);\n\t\tif (len >= sizeof(p->s))\n\t\t\tlen = sizeof(p->s) - 1;\n\t\twhile (len--)\n\t\t\t*ptr1++ = *ptr2++;\n\t\t*ptr1 = '\\0';\n\t\treturn 1;\n\t}\n\tcase FILE_BESHORT:\n\t\tp->h = (short)((p->hs[0]<<8)|(p->hs[1]));\n\t\tcvt_16(p, m);\n\t\treturn 1;\n\tcase FILE_BELONG:\n\tcase FILE_BEDATE:\n\tcase FILE_BELDATE:\n\t\tp->l = (int32_t)\n\t\t    ((p->hl[0]<<24)|(p->hl[1]<<16)|(p->hl[2]<<8)|(p->hl[3]));\n\t\tif (type == FILE_BELONG)\n\t\t\tcvt_32(p, m);\n\t\treturn 1;\n\tcase FILE_BEQUAD:\n\tcase FILE_BEQDATE:\n\tcase FILE_BEQLDATE:\n\tcase FILE_BEQWDATE:\n\t\tp->q = (uint64_t)\n\t\t    (((uint64_t)p->hq[0]<<56)|((uint64_t)p->hq[1]<<48)|\n\t\t     ((uint64_t)p->hq[2]<<40)|((uint64_t)p->hq[3]<<32)|\n\t\t     ((uint64_t)p->hq[4]<<24)|((uint64_t)p->hq[5]<<16)|\n\t\t     ((uint64_t)p->hq[6]<<8)|((uint64_t)p->hq[7]));\n\t\tif (type == FILE_BEQUAD)\n\t\t\tcvt_64(p, m);\n\t\treturn 1;\n\tcase FILE_LESHORT:\n\t\tp->h = (short)((p->hs[1]<<8)|(p->hs[0]));\n\t\tcvt_16(p, m);\n\t\treturn 1;\n\tcase FILE_LELONG:\n\tcase FILE_LEDATE:\n\tcase FILE_LELDATE:\n\t\tp->l = (int32_t)\n\t\t    ((p->hl[3]<<24)|(p->hl[2]<<16)|(p->hl[1]<<8)|(p->hl[0]));\n\t\tif (type == FILE_LELONG)\n\t\t\tcvt_32(p, m);\n\t\treturn 1;\n\tcase FILE_LEQUAD:\n\tcase FILE_LEQDATE:\n\tcase FILE_LEQLDATE:\n\tcase FILE_LEQWDATE:\n\t\tp->q = (uint64_t)\n\t\t    (((uint64_t)p->hq[7]<<56)|((uint64_t)p->hq[6]<<48)|\n\t\t     ((uint64_t)p->hq[5]<<40)|((uint64_t)p->hq[4]<<32)|\n\t\t     ((uint64_t)p->hq[3]<<24)|((uint64_t)p->hq[2]<<16)|\n\t\t     ((uint64_t)p->hq[1]<<8)|((uint64_t)p->hq[0]));\n\t\tif (type == FILE_LEQUAD)\n\t\t\tcvt_64(p, m);\n\t\treturn 1;\n\tcase FILE_MELONG:\n\tcase FILE_MEDATE:\n\tcase FILE_MELDATE:\n\t\tp->l = (int32_t)\n\t\t    ((p->hl[1]<<24)|(p->hl[0]<<16)|(p->hl[3]<<8)|(p->hl[2]));\n\t\tif (type == FILE_MELONG)\n\t\t\tcvt_32(p, m);\n\t\treturn 1;\n\tcase FILE_FLOAT:\n\t\tcvt_float(p, m);\n\t\treturn 1;\n\tcase FILE_BEFLOAT:\n\t\tp->l =  ((uint32_t)p->hl[0]<<24)|((uint32_t)p->hl[1]<<16)|\n\t\t\t((uint32_t)p->hl[2]<<8) |((uint32_t)p->hl[3]);\n\t\tcvt_float(p, m);\n\t\treturn 1;\n\tcase FILE_LEFLOAT:\n\t\tp->l =  ((uint32_t)p->hl[3]<<24)|((uint32_t)p->hl[2]<<16)|\n\t\t\t((uint32_t)p->hl[1]<<8) |((uint32_t)p->hl[0]);\n\t\tcvt_float(p, m);\n\t\treturn 1;\n\tcase FILE_DOUBLE:\n\t\tcvt_double(p, m);\n\t\treturn 1;\n\tcase FILE_BEDOUBLE:\n\t\tp->q =  ((uint64_t)p->hq[0]<<56)|((uint64_t)p->hq[1]<<48)|\n\t\t\t((uint64_t)p->hq[2]<<40)|((uint64_t)p->hq[3]<<32)|\n\t\t\t((uint64_t)p->hq[4]<<24)|((uint64_t)p->hq[5]<<16)|\n\t\t\t((uint64_t)p->hq[6]<<8) |((uint64_t)p->hq[7]);\n\t\tcvt_double(p, m);\n\t\treturn 1;\n\tcase FILE_LEDOUBLE:\n\t\tp->q =  ((uint64_t)p->hq[7]<<56)|((uint64_t)p->hq[6]<<48)|\n\t\t\t((uint64_t)p->hq[5]<<40)|((uint64_t)p->hq[4]<<32)|\n\t\t\t((uint64_t)p->hq[3]<<24)|((uint64_t)p->hq[2]<<16)|\n\t\t\t((uint64_t)p->hq[1]<<8) |((uint64_t)p->hq[0]);\n\t\tcvt_double(p, m);\n\t\treturn 1;\n\tcase FILE_REGEX:\n\tcase FILE_SEARCH:\n\tcase FILE_DEFAULT:\n\tcase FILE_CLEAR:\n\tcase FILE_NAME:\n\tcase FILE_USE:\n\t\treturn 1;\n\tdefault:\n\t\tfile_magerror(ms, \"invalid type %d in mconvert()\", m->type);\n\t\treturn 0;\n\t}\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,8 +2,9 @@\n mconvert(struct magic_set *ms, struct magic *m, int flip)\n {\n \tunion VALUETYPE *p = &ms->ms_value;\n+\tuint8_t type;\n \n-\tswitch (cvt_flip(m->type, flip)) {\n+\tswitch (type = cvt_flip(m->type, flip)) {\n \tcase FILE_BYTE:\n \t\tcvt_8(p, m);\n \t\treturn 1;\n@@ -47,7 +48,8 @@\n \tcase FILE_BELDATE:\n \t\tp->l = (int32_t)\n \t\t    ((p->hl[0]<<24)|(p->hl[1]<<16)|(p->hl[2]<<8)|(p->hl[3]));\n-\t\tcvt_32(p, m);\n+\t\tif (type == FILE_BELONG)\n+\t\t\tcvt_32(p, m);\n \t\treturn 1;\n \tcase FILE_BEQUAD:\n \tcase FILE_BEQDATE:\n@@ -58,7 +60,8 @@\n \t\t     ((uint64_t)p->hq[2]<<40)|((uint64_t)p->hq[3]<<32)|\n \t\t     ((uint64_t)p->hq[4]<<24)|((uint64_t)p->hq[5]<<16)|\n \t\t     ((uint64_t)p->hq[6]<<8)|((uint64_t)p->hq[7]));\n-\t\tcvt_64(p, m);\n+\t\tif (type == FILE_BEQUAD)\n+\t\t\tcvt_64(p, m);\n \t\treturn 1;\n \tcase FILE_LESHORT:\n \t\tp->h = (short)((p->hs[1]<<8)|(p->hs[0]));\n@@ -69,7 +72,8 @@\n \tcase FILE_LELDATE:\n \t\tp->l = (int32_t)\n \t\t    ((p->hl[3]<<24)|(p->hl[2]<<16)|(p->hl[1]<<8)|(p->hl[0]));\n-\t\tcvt_32(p, m);\n+\t\tif (type == FILE_LELONG)\n+\t\t\tcvt_32(p, m);\n \t\treturn 1;\n \tcase FILE_LEQUAD:\n \tcase FILE_LEQDATE:\n@@ -80,14 +84,16 @@\n \t\t     ((uint64_t)p->hq[5]<<40)|((uint64_t)p->hq[4]<<32)|\n \t\t     ((uint64_t)p->hq[3]<<24)|((uint64_t)p->hq[2]<<16)|\n \t\t     ((uint64_t)p->hq[1]<<8)|((uint64_t)p->hq[0]));\n-\t\tcvt_64(p, m);\n+\t\tif (type == FILE_LEQUAD)\n+\t\t\tcvt_64(p, m);\n \t\treturn 1;\n \tcase FILE_MELONG:\n \tcase FILE_MEDATE:\n \tcase FILE_MELDATE:\n \t\tp->l = (int32_t)\n \t\t    ((p->hl[1]<<24)|(p->hl[0]<<16)|(p->hl[3]<<8)|(p->hl[2]));\n-\t\tcvt_32(p, m);\n+\t\tif (type == FILE_MELONG)\n+\t\t\tcvt_32(p, m);\n \t\treturn 1;\n \tcase FILE_FLOAT:\n \t\tcvt_float(p, m);",
        "diff_line_info": {
            "deleted_lines": [
                "\tswitch (cvt_flip(m->type, flip)) {",
                "\t\tcvt_32(p, m);",
                "\t\tcvt_64(p, m);",
                "\t\tcvt_32(p, m);",
                "\t\tcvt_64(p, m);",
                "\t\tcvt_32(p, m);"
            ],
            "added_lines": [
                "\tuint8_t type;",
                "\tswitch (type = cvt_flip(m->type, flip)) {",
                "\t\tif (type == FILE_BELONG)",
                "\t\t\tcvt_32(p, m);",
                "\t\tif (type == FILE_BEQUAD)",
                "\t\t\tcvt_64(p, m);",
                "\t\tif (type == FILE_LELONG)",
                "\t\t\tcvt_32(p, m);",
                "\t\tif (type == FILE_LEQUAD)",
                "\t\t\tcvt_64(p, m);",
                "\t\tif (type == FILE_MELONG)",
                "\t\t\tcvt_32(p, m);"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-3538",
        "func_name": "file/mget",
        "description": "file before 5.19 does not properly restrict the amount of data read during a regex search, which allows remote attackers to cause a denial of service (CPU consumption) via a crafted file that triggers backtracking during processing of an awk rule.  NOTE: this vulnerability exists because of an incomplete fix for CVE-2013-7345.",
        "git_url": "https://github.com/file/file/commit/4a284c89d6ef11aca34da65da7d673050a5ea320",
        "commit_title": "* Enforce limit of 8K on regex searches that have no limits",
        "commit_text": "* Allow the l modifier for regex to mean line count. Default   to byte count. If line count is specified, assume a max   of 80 characters per line to limit the byte count. * Don't allow conversions to be used for dates, allowing   the mask field to be used as an offset. * Bump the version of the magic format so that regex changes   are visible.",
        "func_before": "private int\nmget(struct magic_set *ms, const unsigned char *s, struct magic *m,\n    size_t nbytes, size_t o, unsigned int cont_level, int mode, int text,\n    int flip, int recursion_level, int *printed_something,\n    int *need_separator, int *returnval)\n{\n\tuint32_t soffset, offset = ms->offset;\n\tuint32_t count = m->str_range;\n\tuint32_t lhs;\n\tint rv, oneed_separator, in_type;\n\tchar *sbuf, *rbuf;\n\tunion VALUETYPE *p = &ms->ms_value;\n\tstruct mlist ml;\n\n\tif (recursion_level >= 20) {\n\t\tfile_error(ms, 0, \"recursion nesting exceeded\");\n\t\treturn -1;\n\t}\n\n\tif (mcopy(ms, p, m->type, m->flag & INDIR, s, (uint32_t)(offset + o),\n\t    (uint32_t)nbytes, count) == -1)\n\t\treturn -1;\n\n\tif ((ms->flags & MAGIC_DEBUG) != 0) {\n\t\tfprintf(stderr, \"mget(type=%d, flag=%x, offset=%u, o=%zu, \"\n\t\t    \"nbytes=%zu, count=%u)\\n\", m->type, m->flag, offset, o,\n\t\t    nbytes, count);\n\t\tmdebug(offset, (char *)(void *)p, sizeof(union VALUETYPE));\n#ifndef COMPILE_ONLY\n\t\tfile_mdump(m);\n#endif\n\t}\n\n\tif (m->flag & INDIR) {\n\t\tint off = m->in_offset;\n\t\tif (m->in_op & FILE_OPINDIRECT) {\n\t\t\tconst union VALUETYPE *q = CAST(const union VALUETYPE *,\n\t\t\t    ((const void *)(s + offset + off)));\n\t\t\tswitch (cvt_flip(m->in_type, flip)) {\n\t\t\tcase FILE_BYTE:\n\t\t\t\toff = q->b;\n\t\t\t\tbreak;\n\t\t\tcase FILE_SHORT:\n\t\t\t\toff = q->h;\n\t\t\t\tbreak;\n\t\t\tcase FILE_BESHORT:\n\t\t\t\toff = (short)((q->hs[0]<<8)|(q->hs[1]));\n\t\t\t\tbreak;\n\t\t\tcase FILE_LESHORT:\n\t\t\t\toff = (short)((q->hs[1]<<8)|(q->hs[0]));\n\t\t\t\tbreak;\n\t\t\tcase FILE_LONG:\n\t\t\t\toff = q->l;\n\t\t\t\tbreak;\n\t\t\tcase FILE_BELONG:\n\t\t\tcase FILE_BEID3:\n\t\t\t\toff = (int32_t)((q->hl[0]<<24)|(q->hl[1]<<16)|\n\t\t\t\t\t\t (q->hl[2]<<8)|(q->hl[3]));\n\t\t\t\tbreak;\n\t\t\tcase FILE_LEID3:\n\t\t\tcase FILE_LELONG:\n\t\t\t\toff = (int32_t)((q->hl[3]<<24)|(q->hl[2]<<16)|\n\t\t\t\t\t\t (q->hl[1]<<8)|(q->hl[0]));\n\t\t\t\tbreak;\n\t\t\tcase FILE_MELONG:\n\t\t\t\toff = (int32_t)((q->hl[1]<<24)|(q->hl[0]<<16)|\n\t\t\t\t\t\t (q->hl[3]<<8)|(q->hl[2]));\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif ((ms->flags & MAGIC_DEBUG) != 0)\n\t\t\t\tfprintf(stderr, \"indirect offs=%u\\n\", off);\n\t\t}\n\t\tswitch (in_type = cvt_flip(m->in_type, flip)) {\n\t\tcase FILE_BYTE:\n\t\t\tif (OFFSET_OOB(nbytes, offset, 1))\n\t\t\t\treturn 0;\n\t\t\tif (off) {\n\t\t\t\tswitch (m->in_op & FILE_OPS_MASK) {\n\t\t\t\tcase FILE_OPAND:\n\t\t\t\t\toffset = p->b & off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPOR:\n\t\t\t\t\toffset = p->b | off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPXOR:\n\t\t\t\t\toffset = p->b ^ off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPADD:\n\t\t\t\t\toffset = p->b + off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMINUS:\n\t\t\t\t\toffset = p->b - off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMULTIPLY:\n\t\t\t\t\toffset = p->b * off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPDIVIDE:\n\t\t\t\t\toffset = p->b / off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMODULO:\n\t\t\t\t\toffset = p->b % off;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t} else\n\t\t\t\toffset = p->b;\n\t\t\tif (m->in_op & FILE_OPINVERSE)\n\t\t\t\toffset = ~offset;\n\t\t\tbreak;\n\t\tcase FILE_BESHORT:\n\t\t\tif (OFFSET_OOB(nbytes, offset, 2))\n\t\t\t\treturn 0;\n\t\t\tlhs = (p->hs[0] << 8) | p->hs[1];\n\t\t\tif (off) {\n\t\t\t\tswitch (m->in_op & FILE_OPS_MASK) {\n\t\t\t\tcase FILE_OPAND:\n\t\t\t\t\toffset = lhs & off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPOR:\n\t\t\t\t\toffset = lhs | off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPXOR:\n\t\t\t\t\toffset = lhs ^ off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPADD:\n\t\t\t\t\toffset = lhs + off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMINUS:\n\t\t\t\t\toffset = lhs - off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMULTIPLY:\n\t\t\t\t\toffset = lhs * off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPDIVIDE:\n\t\t\t\t\toffset = lhs / off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMODULO:\n\t\t\t\t\toffset = lhs % off;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t} else\n\t\t\t\toffset = lhs;\n\t\t\tif (m->in_op & FILE_OPINVERSE)\n\t\t\t\toffset = ~offset;\n\t\t\tbreak;\n\t\tcase FILE_LESHORT:\n\t\t\tif (OFFSET_OOB(nbytes, offset, 2))\n\t\t\t\treturn 0;\n\t\t\tlhs = (p->hs[1] << 8) | p->hs[0];\n\t\t\tif (off) {\n\t\t\t\tswitch (m->in_op & FILE_OPS_MASK) {\n\t\t\t\tcase FILE_OPAND:\n\t\t\t\t\toffset = lhs & off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPOR:\n\t\t\t\t\toffset = lhs | off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPXOR:\n\t\t\t\t\toffset = lhs ^ off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPADD:\n\t\t\t\t\toffset = lhs + off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMINUS:\n\t\t\t\t\toffset = lhs - off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMULTIPLY:\n\t\t\t\t\toffset = lhs * off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPDIVIDE:\n\t\t\t\t\toffset = lhs / off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMODULO:\n\t\t\t\t\toffset = lhs % off;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t} else\n\t\t\t\toffset = lhs;\n\t\t\tif (m->in_op & FILE_OPINVERSE)\n\t\t\t\toffset = ~offset;\n\t\t\tbreak;\n\t\tcase FILE_SHORT:\n\t\t\tif (OFFSET_OOB(nbytes, offset, 2))\n\t\t\t\treturn 0;\n\t\t\tif (off) {\n\t\t\t\tswitch (m->in_op & FILE_OPS_MASK) {\n\t\t\t\tcase FILE_OPAND:\n\t\t\t\t\toffset = p->h & off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPOR:\n\t\t\t\t\toffset = p->h | off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPXOR:\n\t\t\t\t\toffset = p->h ^ off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPADD:\n\t\t\t\t\toffset = p->h + off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMINUS:\n\t\t\t\t\toffset = p->h - off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMULTIPLY:\n\t\t\t\t\toffset = p->h * off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPDIVIDE:\n\t\t\t\t\toffset = p->h / off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMODULO:\n\t\t\t\t\toffset = p->h % off;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\telse\n\t\t\t\toffset = p->h;\n\t\t\tif (m->in_op & FILE_OPINVERSE)\n\t\t\t\toffset = ~offset;\n\t\t\tbreak;\n\t\tcase FILE_BELONG:\n\t\tcase FILE_BEID3:\n\t\t\tif (OFFSET_OOB(nbytes, offset, 4))\n\t\t\t\treturn 0;\n\t\t\tlhs = (p->hl[0] << 24) | (p->hl[1] << 16) |\n\t\t\t    (p->hl[2] << 8) | p->hl[3];\n\t\t\tif (off) {\n\t\t\t\tswitch (m->in_op & FILE_OPS_MASK) {\n\t\t\t\tcase FILE_OPAND:\n\t\t\t\t\toffset = lhs & off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPOR:\n\t\t\t\t\toffset = lhs | off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPXOR:\n\t\t\t\t\toffset = lhs ^ off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPADD:\n\t\t\t\t\toffset = lhs + off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMINUS:\n\t\t\t\t\toffset = lhs - off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMULTIPLY:\n\t\t\t\t\toffset = lhs * off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPDIVIDE:\n\t\t\t\t\toffset = lhs / off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMODULO:\n\t\t\t\t\toffset = lhs % off;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t} else\n\t\t\t\toffset = lhs;\n\t\t\tif (m->in_op & FILE_OPINVERSE)\n\t\t\t\toffset = ~offset;\n\t\t\tbreak;\n\t\tcase FILE_LELONG:\n\t\tcase FILE_LEID3:\n\t\t\tif (OFFSET_OOB(nbytes, offset, 4))\n\t\t\t\treturn 0;\n\t\t\tlhs = (p->hl[3] << 24) | (p->hl[2] << 16) |\n\t\t\t    (p->hl[1] << 8) | p->hl[0];\n\t\t\tif (off) {\n\t\t\t\tswitch (m->in_op & FILE_OPS_MASK) {\n\t\t\t\tcase FILE_OPAND:\n\t\t\t\t\toffset = lhs & off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPOR:\n\t\t\t\t\toffset = lhs | off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPXOR:\n\t\t\t\t\toffset = lhs ^ off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPADD:\n\t\t\t\t\toffset = lhs + off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMINUS:\n\t\t\t\t\toffset = lhs - off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMULTIPLY:\n\t\t\t\t\toffset = lhs * off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPDIVIDE:\n\t\t\t\t\toffset = lhs / off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMODULO:\n\t\t\t\t\toffset = lhs % off;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t} else\n\t\t\t\toffset = lhs;\n\t\t\tif (m->in_op & FILE_OPINVERSE)\n\t\t\t\toffset = ~offset;\n\t\t\tbreak;\n\t\tcase FILE_MELONG:\n\t\t\tif (OFFSET_OOB(nbytes, offset, 4))\n\t\t\t\treturn 0;\n\t\t\tlhs = (p->hl[1] << 24) | (p->hl[0] << 16) |\n\t\t\t    (p->hl[3] << 8) | p->hl[2];\n\t\t\tif (off) {\n\t\t\t\tswitch (m->in_op & FILE_OPS_MASK) {\n\t\t\t\tcase FILE_OPAND:\n\t\t\t\t\toffset = lhs & off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPOR:\n\t\t\t\t\toffset = lhs | off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPXOR:\n\t\t\t\t\toffset = lhs ^ off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPADD:\n\t\t\t\t\toffset = lhs + off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMINUS:\n\t\t\t\t\toffset = lhs - off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMULTIPLY:\n\t\t\t\t\toffset = lhs * off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPDIVIDE:\n\t\t\t\t\toffset = lhs / off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMODULO:\n\t\t\t\t\toffset = lhs % off;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t} else\n\t\t\t\toffset = lhs;\n\t\t\tif (m->in_op & FILE_OPINVERSE)\n\t\t\t\toffset = ~offset;\n\t\t\tbreak;\n\t\tcase FILE_LONG:\n\t\t\tif (OFFSET_OOB(nbytes, offset, 4))\n\t\t\t\treturn 0;\n\t\t\tif (off) {\n\t\t\t\tswitch (m->in_op & FILE_OPS_MASK) {\n\t\t\t\tcase FILE_OPAND:\n\t\t\t\t\toffset = p->l & off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPOR:\n\t\t\t\t\toffset = p->l | off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPXOR:\n\t\t\t\t\toffset = p->l ^ off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPADD:\n\t\t\t\t\toffset = p->l + off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMINUS:\n\t\t\t\t\toffset = p->l - off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMULTIPLY:\n\t\t\t\t\toffset = p->l * off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPDIVIDE:\n\t\t\t\t\toffset = p->l / off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMODULO:\n\t\t\t\t\toffset = p->l % off;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t} else\n\t\t\t\toffset = p->l;\n\t\t\tif (m->in_op & FILE_OPINVERSE)\n\t\t\t\toffset = ~offset;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\n\t\tswitch (in_type) {\n\t\tcase FILE_LEID3:\n\t\tcase FILE_BEID3:\n\t\t\toffset = ((((offset >>  0) & 0x7f) <<  0) |\n\t\t\t\t (((offset >>  8) & 0x7f) <<  7) |\n\t\t\t\t (((offset >> 16) & 0x7f) << 14) |\n\t\t\t\t (((offset >> 24) & 0x7f) << 21)) + 10;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\n\t\tif (m->flag & INDIROFFADD) {\n\t\t\toffset += ms->c.li[cont_level-1].off;\n\t\t\tif (offset == 0) {\n\t\t\t\tif ((ms->flags & MAGIC_DEBUG) != 0)\n\t\t\t\t\tfprintf(stderr,\n\t\t\t\t\t    \"indirect *zero* offset\\n\");\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t\tif ((ms->flags & MAGIC_DEBUG) != 0)\n\t\t\t\tfprintf(stderr, \"indirect +offs=%u\\n\", offset);\n\t\t}\n\t\tif (mcopy(ms, p, m->type, 0, s, offset, nbytes, count) == -1)\n\t\t\treturn -1;\n\t\tms->offset = offset;\n\n\t\tif ((ms->flags & MAGIC_DEBUG) != 0) {\n\t\t\tmdebug(offset, (char *)(void *)p,\n\t\t\t    sizeof(union VALUETYPE));\n#ifndef COMPILE_ONLY\n\t\t\tfile_mdump(m);\n#endif\n\t\t}\n\t}\n\n\t/* Verify we have enough data to match magic type */\n\tswitch (m->type) {\n\tcase FILE_BYTE:\n\t\tif (OFFSET_OOB(nbytes, offset, 1))\n\t\t\treturn 0;\n\t\tbreak;\n\n\tcase FILE_SHORT:\n\tcase FILE_BESHORT:\n\tcase FILE_LESHORT:\n\t\tif (OFFSET_OOB(nbytes, offset, 2))\n\t\t\treturn 0;\n\t\tbreak;\n\n\tcase FILE_LONG:\n\tcase FILE_BELONG:\n\tcase FILE_LELONG:\n\tcase FILE_MELONG:\n\tcase FILE_DATE:\n\tcase FILE_BEDATE:\n\tcase FILE_LEDATE:\n\tcase FILE_MEDATE:\n\tcase FILE_LDATE:\n\tcase FILE_BELDATE:\n\tcase FILE_LELDATE:\n\tcase FILE_MELDATE:\n\tcase FILE_FLOAT:\n\tcase FILE_BEFLOAT:\n\tcase FILE_LEFLOAT:\n\t\tif (OFFSET_OOB(nbytes, offset, 4))\n\t\t\treturn 0;\n\t\tbreak;\n\n\tcase FILE_DOUBLE:\n\tcase FILE_BEDOUBLE:\n\tcase FILE_LEDOUBLE:\n\t\tif (OFFSET_OOB(nbytes, offset, 8))\n\t\t\treturn 0;\n\t\tbreak;\n\n\tcase FILE_STRING:\n\tcase FILE_PSTRING:\n\tcase FILE_SEARCH:\n\t\tif (OFFSET_OOB(nbytes, offset, m->vallen))\n\t\t\treturn 0;\n\t\tbreak;\n\n\tcase FILE_REGEX:\n\t\tif (nbytes < offset)\n\t\t\treturn 0;\n\t\tbreak;\n\n\tcase FILE_INDIRECT:\n\t\tif (offset == 0)\n\t\t\treturn 0;\n\t\tif (nbytes < offset)\n\t\t\treturn 0;\n\t\tsbuf = ms->o.buf;\n\t\tsoffset = ms->offset;\n\t\tms->o.buf = NULL;\n\t\tms->offset = 0;\n\t\trv = file_softmagic(ms, s + offset, nbytes - offset,\n\t\t    recursion_level, BINTEST, text);\n\t\tif ((ms->flags & MAGIC_DEBUG) != 0)\n\t\t\tfprintf(stderr, \"indirect @offs=%u[%d]\\n\", offset, rv);\n\t\trbuf = ms->o.buf;\n\t\tms->o.buf = sbuf;\n\t\tms->offset = soffset;\n\t\tif (rv == 1) {\n\t\t\tif ((ms->flags & (MAGIC_MIME|MAGIC_APPLE)) == 0 &&\n\t\t\t    file_printf(ms, F(ms, m, \"%u\"), offset) == -1) {\n\t\t\t\tfree(rbuf);\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tif (file_printf(ms, \"%s\", rbuf) == -1) {\n\t\t\t\tfree(rbuf);\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t}\n\t\tfree(rbuf);\n\t\treturn rv;\n\n\tcase FILE_USE:\n\t\tif (nbytes < offset)\n\t\t\treturn 0;\n\t\tsbuf = m->value.s;\n\t\tif (*sbuf == '^') {\n\t\t\tsbuf++;\n\t\t\tflip = !flip;\n\t\t}\n\t\tif (file_magicfind(ms, sbuf, &ml) == -1) {\n\t\t\tfile_error(ms, 0, \"cannot find entry `%s'\", sbuf);\n\t\t\treturn -1;\n\t\t}\n\n\t\toneed_separator = *need_separator;\n\t\tif (m->flag & NOSPACE)\n\t\t\t*need_separator = 0;\n\t\trv = match(ms, ml.magic, ml.nmagic, s, nbytes, offset + o,\n\t\t    mode, text, flip, recursion_level, printed_something,\n\t\t    need_separator, returnval);\n\t\tif (rv != 1)\n\t\t    *need_separator = oneed_separator;\n\t\treturn rv;\n\n\tcase FILE_NAME:\n\t\tif (file_printf(ms, \"%s\", m->desc) == -1)\n\t\t\treturn -1;\n\t\treturn 1;\n\tcase FILE_DEFAULT:\t/* nothing to check */\n\tcase FILE_CLEAR:\n\tdefault:\n\t\tbreak;\n\t}\n\tif (!mconvert(ms, m, flip))\n\t\treturn 0;\n\treturn 1;\n}",
        "func": "private int\nmget(struct magic_set *ms, const unsigned char *s, struct magic *m,\n    size_t nbytes, size_t o, unsigned int cont_level, int mode, int text,\n    int flip, int recursion_level, int *printed_something,\n    int *need_separator, int *returnval)\n{\n\tuint32_t soffset, offset = ms->offset;\n\tuint32_t lhs;\n\tint rv, oneed_separator, in_type;\n\tchar *sbuf, *rbuf;\n\tunion VALUETYPE *p = &ms->ms_value;\n\tstruct mlist ml;\n\n\tif (recursion_level >= 20) {\n\t\tfile_error(ms, 0, \"recursion nesting exceeded\");\n\t\treturn -1;\n\t}\n\n\tif (mcopy(ms, p, m->type, m->flag & INDIR, s, (uint32_t)(offset + o),\n\t    (uint32_t)nbytes, m) == -1)\n\t\treturn -1;\n\n\tif ((ms->flags & MAGIC_DEBUG) != 0) {\n\t\tfprintf(stderr, \"mget(type=%d, flag=%x, offset=%u, o=%zu, \"\n\t\t    \"nbytes=%zu)\\n\", m->type, m->flag, offset, o, nbytes);\n\t\tmdebug(offset, (char *)(void *)p, sizeof(union VALUETYPE));\n#ifndef COMPILE_ONLY\n\t\tfile_mdump(m);\n#endif\n\t}\n\n\tif (m->flag & INDIR) {\n\t\tint off = m->in_offset;\n\t\tif (m->in_op & FILE_OPINDIRECT) {\n\t\t\tconst union VALUETYPE *q = CAST(const union VALUETYPE *,\n\t\t\t    ((const void *)(s + offset + off)));\n\t\t\tswitch (cvt_flip(m->in_type, flip)) {\n\t\t\tcase FILE_BYTE:\n\t\t\t\toff = q->b;\n\t\t\t\tbreak;\n\t\t\tcase FILE_SHORT:\n\t\t\t\toff = q->h;\n\t\t\t\tbreak;\n\t\t\tcase FILE_BESHORT:\n\t\t\t\toff = (short)((q->hs[0]<<8)|(q->hs[1]));\n\t\t\t\tbreak;\n\t\t\tcase FILE_LESHORT:\n\t\t\t\toff = (short)((q->hs[1]<<8)|(q->hs[0]));\n\t\t\t\tbreak;\n\t\t\tcase FILE_LONG:\n\t\t\t\toff = q->l;\n\t\t\t\tbreak;\n\t\t\tcase FILE_BELONG:\n\t\t\tcase FILE_BEID3:\n\t\t\t\toff = (int32_t)((q->hl[0]<<24)|(q->hl[1]<<16)|\n\t\t\t\t\t\t (q->hl[2]<<8)|(q->hl[3]));\n\t\t\t\tbreak;\n\t\t\tcase FILE_LEID3:\n\t\t\tcase FILE_LELONG:\n\t\t\t\toff = (int32_t)((q->hl[3]<<24)|(q->hl[2]<<16)|\n\t\t\t\t\t\t (q->hl[1]<<8)|(q->hl[0]));\n\t\t\t\tbreak;\n\t\t\tcase FILE_MELONG:\n\t\t\t\toff = (int32_t)((q->hl[1]<<24)|(q->hl[0]<<16)|\n\t\t\t\t\t\t (q->hl[3]<<8)|(q->hl[2]));\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif ((ms->flags & MAGIC_DEBUG) != 0)\n\t\t\t\tfprintf(stderr, \"indirect offs=%u\\n\", off);\n\t\t}\n\t\tswitch (in_type = cvt_flip(m->in_type, flip)) {\n\t\tcase FILE_BYTE:\n\t\t\tif (OFFSET_OOB(nbytes, offset, 1))\n\t\t\t\treturn 0;\n\t\t\tif (off) {\n\t\t\t\tswitch (m->in_op & FILE_OPS_MASK) {\n\t\t\t\tcase FILE_OPAND:\n\t\t\t\t\toffset = p->b & off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPOR:\n\t\t\t\t\toffset = p->b | off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPXOR:\n\t\t\t\t\toffset = p->b ^ off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPADD:\n\t\t\t\t\toffset = p->b + off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMINUS:\n\t\t\t\t\toffset = p->b - off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMULTIPLY:\n\t\t\t\t\toffset = p->b * off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPDIVIDE:\n\t\t\t\t\toffset = p->b / off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMODULO:\n\t\t\t\t\toffset = p->b % off;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t} else\n\t\t\t\toffset = p->b;\n\t\t\tif (m->in_op & FILE_OPINVERSE)\n\t\t\t\toffset = ~offset;\n\t\t\tbreak;\n\t\tcase FILE_BESHORT:\n\t\t\tif (OFFSET_OOB(nbytes, offset, 2))\n\t\t\t\treturn 0;\n\t\t\tlhs = (p->hs[0] << 8) | p->hs[1];\n\t\t\tif (off) {\n\t\t\t\tswitch (m->in_op & FILE_OPS_MASK) {\n\t\t\t\tcase FILE_OPAND:\n\t\t\t\t\toffset = lhs & off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPOR:\n\t\t\t\t\toffset = lhs | off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPXOR:\n\t\t\t\t\toffset = lhs ^ off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPADD:\n\t\t\t\t\toffset = lhs + off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMINUS:\n\t\t\t\t\toffset = lhs - off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMULTIPLY:\n\t\t\t\t\toffset = lhs * off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPDIVIDE:\n\t\t\t\t\toffset = lhs / off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMODULO:\n\t\t\t\t\toffset = lhs % off;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t} else\n\t\t\t\toffset = lhs;\n\t\t\tif (m->in_op & FILE_OPINVERSE)\n\t\t\t\toffset = ~offset;\n\t\t\tbreak;\n\t\tcase FILE_LESHORT:\n\t\t\tif (OFFSET_OOB(nbytes, offset, 2))\n\t\t\t\treturn 0;\n\t\t\tlhs = (p->hs[1] << 8) | p->hs[0];\n\t\t\tif (off) {\n\t\t\t\tswitch (m->in_op & FILE_OPS_MASK) {\n\t\t\t\tcase FILE_OPAND:\n\t\t\t\t\toffset = lhs & off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPOR:\n\t\t\t\t\toffset = lhs | off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPXOR:\n\t\t\t\t\toffset = lhs ^ off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPADD:\n\t\t\t\t\toffset = lhs + off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMINUS:\n\t\t\t\t\toffset = lhs - off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMULTIPLY:\n\t\t\t\t\toffset = lhs * off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPDIVIDE:\n\t\t\t\t\toffset = lhs / off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMODULO:\n\t\t\t\t\toffset = lhs % off;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t} else\n\t\t\t\toffset = lhs;\n\t\t\tif (m->in_op & FILE_OPINVERSE)\n\t\t\t\toffset = ~offset;\n\t\t\tbreak;\n\t\tcase FILE_SHORT:\n\t\t\tif (OFFSET_OOB(nbytes, offset, 2))\n\t\t\t\treturn 0;\n\t\t\tif (off) {\n\t\t\t\tswitch (m->in_op & FILE_OPS_MASK) {\n\t\t\t\tcase FILE_OPAND:\n\t\t\t\t\toffset = p->h & off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPOR:\n\t\t\t\t\toffset = p->h | off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPXOR:\n\t\t\t\t\toffset = p->h ^ off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPADD:\n\t\t\t\t\toffset = p->h + off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMINUS:\n\t\t\t\t\toffset = p->h - off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMULTIPLY:\n\t\t\t\t\toffset = p->h * off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPDIVIDE:\n\t\t\t\t\toffset = p->h / off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMODULO:\n\t\t\t\t\toffset = p->h % off;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\telse\n\t\t\t\toffset = p->h;\n\t\t\tif (m->in_op & FILE_OPINVERSE)\n\t\t\t\toffset = ~offset;\n\t\t\tbreak;\n\t\tcase FILE_BELONG:\n\t\tcase FILE_BEID3:\n\t\t\tif (OFFSET_OOB(nbytes, offset, 4))\n\t\t\t\treturn 0;\n\t\t\tlhs = (p->hl[0] << 24) | (p->hl[1] << 16) |\n\t\t\t    (p->hl[2] << 8) | p->hl[3];\n\t\t\tif (off) {\n\t\t\t\tswitch (m->in_op & FILE_OPS_MASK) {\n\t\t\t\tcase FILE_OPAND:\n\t\t\t\t\toffset = lhs & off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPOR:\n\t\t\t\t\toffset = lhs | off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPXOR:\n\t\t\t\t\toffset = lhs ^ off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPADD:\n\t\t\t\t\toffset = lhs + off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMINUS:\n\t\t\t\t\toffset = lhs - off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMULTIPLY:\n\t\t\t\t\toffset = lhs * off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPDIVIDE:\n\t\t\t\t\toffset = lhs / off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMODULO:\n\t\t\t\t\toffset = lhs % off;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t} else\n\t\t\t\toffset = lhs;\n\t\t\tif (m->in_op & FILE_OPINVERSE)\n\t\t\t\toffset = ~offset;\n\t\t\tbreak;\n\t\tcase FILE_LELONG:\n\t\tcase FILE_LEID3:\n\t\t\tif (OFFSET_OOB(nbytes, offset, 4))\n\t\t\t\treturn 0;\n\t\t\tlhs = (p->hl[3] << 24) | (p->hl[2] << 16) |\n\t\t\t    (p->hl[1] << 8) | p->hl[0];\n\t\t\tif (off) {\n\t\t\t\tswitch (m->in_op & FILE_OPS_MASK) {\n\t\t\t\tcase FILE_OPAND:\n\t\t\t\t\toffset = lhs & off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPOR:\n\t\t\t\t\toffset = lhs | off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPXOR:\n\t\t\t\t\toffset = lhs ^ off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPADD:\n\t\t\t\t\toffset = lhs + off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMINUS:\n\t\t\t\t\toffset = lhs - off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMULTIPLY:\n\t\t\t\t\toffset = lhs * off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPDIVIDE:\n\t\t\t\t\toffset = lhs / off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMODULO:\n\t\t\t\t\toffset = lhs % off;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t} else\n\t\t\t\toffset = lhs;\n\t\t\tif (m->in_op & FILE_OPINVERSE)\n\t\t\t\toffset = ~offset;\n\t\t\tbreak;\n\t\tcase FILE_MELONG:\n\t\t\tif (OFFSET_OOB(nbytes, offset, 4))\n\t\t\t\treturn 0;\n\t\t\tlhs = (p->hl[1] << 24) | (p->hl[0] << 16) |\n\t\t\t    (p->hl[3] << 8) | p->hl[2];\n\t\t\tif (off) {\n\t\t\t\tswitch (m->in_op & FILE_OPS_MASK) {\n\t\t\t\tcase FILE_OPAND:\n\t\t\t\t\toffset = lhs & off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPOR:\n\t\t\t\t\toffset = lhs | off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPXOR:\n\t\t\t\t\toffset = lhs ^ off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPADD:\n\t\t\t\t\toffset = lhs + off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMINUS:\n\t\t\t\t\toffset = lhs - off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMULTIPLY:\n\t\t\t\t\toffset = lhs * off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPDIVIDE:\n\t\t\t\t\toffset = lhs / off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMODULO:\n\t\t\t\t\toffset = lhs % off;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t} else\n\t\t\t\toffset = lhs;\n\t\t\tif (m->in_op & FILE_OPINVERSE)\n\t\t\t\toffset = ~offset;\n\t\t\tbreak;\n\t\tcase FILE_LONG:\n\t\t\tif (OFFSET_OOB(nbytes, offset, 4))\n\t\t\t\treturn 0;\n\t\t\tif (off) {\n\t\t\t\tswitch (m->in_op & FILE_OPS_MASK) {\n\t\t\t\tcase FILE_OPAND:\n\t\t\t\t\toffset = p->l & off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPOR:\n\t\t\t\t\toffset = p->l | off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPXOR:\n\t\t\t\t\toffset = p->l ^ off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPADD:\n\t\t\t\t\toffset = p->l + off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMINUS:\n\t\t\t\t\toffset = p->l - off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMULTIPLY:\n\t\t\t\t\toffset = p->l * off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPDIVIDE:\n\t\t\t\t\toffset = p->l / off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMODULO:\n\t\t\t\t\toffset = p->l % off;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t} else\n\t\t\t\toffset = p->l;\n\t\t\tif (m->in_op & FILE_OPINVERSE)\n\t\t\t\toffset = ~offset;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\n\t\tswitch (in_type) {\n\t\tcase FILE_LEID3:\n\t\tcase FILE_BEID3:\n\t\t\toffset = ((((offset >>  0) & 0x7f) <<  0) |\n\t\t\t\t (((offset >>  8) & 0x7f) <<  7) |\n\t\t\t\t (((offset >> 16) & 0x7f) << 14) |\n\t\t\t\t (((offset >> 24) & 0x7f) << 21)) + 10;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\n\t\tif (m->flag & INDIROFFADD) {\n\t\t\toffset += ms->c.li[cont_level-1].off;\n\t\t\tif (offset == 0) {\n\t\t\t\tif ((ms->flags & MAGIC_DEBUG) != 0)\n\t\t\t\t\tfprintf(stderr,\n\t\t\t\t\t    \"indirect *zero* offset\\n\");\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t\tif ((ms->flags & MAGIC_DEBUG) != 0)\n\t\t\t\tfprintf(stderr, \"indirect +offs=%u\\n\", offset);\n\t\t}\n\t\tif (mcopy(ms, p, m->type, 0, s, offset, nbytes, m) == -1)\n\t\t\treturn -1;\n\t\tms->offset = offset;\n\n\t\tif ((ms->flags & MAGIC_DEBUG) != 0) {\n\t\t\tmdebug(offset, (char *)(void *)p,\n\t\t\t    sizeof(union VALUETYPE));\n#ifndef COMPILE_ONLY\n\t\t\tfile_mdump(m);\n#endif\n\t\t}\n\t}\n\n\t/* Verify we have enough data to match magic type */\n\tswitch (m->type) {\n\tcase FILE_BYTE:\n\t\tif (OFFSET_OOB(nbytes, offset, 1))\n\t\t\treturn 0;\n\t\tbreak;\n\n\tcase FILE_SHORT:\n\tcase FILE_BESHORT:\n\tcase FILE_LESHORT:\n\t\tif (OFFSET_OOB(nbytes, offset, 2))\n\t\t\treturn 0;\n\t\tbreak;\n\n\tcase FILE_LONG:\n\tcase FILE_BELONG:\n\tcase FILE_LELONG:\n\tcase FILE_MELONG:\n\tcase FILE_DATE:\n\tcase FILE_BEDATE:\n\tcase FILE_LEDATE:\n\tcase FILE_MEDATE:\n\tcase FILE_LDATE:\n\tcase FILE_BELDATE:\n\tcase FILE_LELDATE:\n\tcase FILE_MELDATE:\n\tcase FILE_FLOAT:\n\tcase FILE_BEFLOAT:\n\tcase FILE_LEFLOAT:\n\t\tif (OFFSET_OOB(nbytes, offset, 4))\n\t\t\treturn 0;\n\t\tbreak;\n\n\tcase FILE_DOUBLE:\n\tcase FILE_BEDOUBLE:\n\tcase FILE_LEDOUBLE:\n\t\tif (OFFSET_OOB(nbytes, offset, 8))\n\t\t\treturn 0;\n\t\tbreak;\n\n\tcase FILE_STRING:\n\tcase FILE_PSTRING:\n\tcase FILE_SEARCH:\n\t\tif (OFFSET_OOB(nbytes, offset, m->vallen))\n\t\t\treturn 0;\n\t\tbreak;\n\n\tcase FILE_REGEX:\n\t\tif (nbytes < offset)\n\t\t\treturn 0;\n\t\tbreak;\n\n\tcase FILE_INDIRECT:\n\t\tif (offset == 0)\n\t\t\treturn 0;\n\t\tif (nbytes < offset)\n\t\t\treturn 0;\n\t\tsbuf = ms->o.buf;\n\t\tsoffset = ms->offset;\n\t\tms->o.buf = NULL;\n\t\tms->offset = 0;\n\t\trv = file_softmagic(ms, s + offset, nbytes - offset,\n\t\t    recursion_level, BINTEST, text);\n\t\tif ((ms->flags & MAGIC_DEBUG) != 0)\n\t\t\tfprintf(stderr, \"indirect @offs=%u[%d]\\n\", offset, rv);\n\t\trbuf = ms->o.buf;\n\t\tms->o.buf = sbuf;\n\t\tms->offset = soffset;\n\t\tif (rv == 1) {\n\t\t\tif ((ms->flags & (MAGIC_MIME|MAGIC_APPLE)) == 0 &&\n\t\t\t    file_printf(ms, F(ms, m, \"%u\"), offset) == -1) {\n\t\t\t\tfree(rbuf);\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tif (file_printf(ms, \"%s\", rbuf) == -1) {\n\t\t\t\tfree(rbuf);\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t}\n\t\tfree(rbuf);\n\t\treturn rv;\n\n\tcase FILE_USE:\n\t\tif (nbytes < offset)\n\t\t\treturn 0;\n\t\tsbuf = m->value.s;\n\t\tif (*sbuf == '^') {\n\t\t\tsbuf++;\n\t\t\tflip = !flip;\n\t\t}\n\t\tif (file_magicfind(ms, sbuf, &ml) == -1) {\n\t\t\tfile_error(ms, 0, \"cannot find entry `%s'\", sbuf);\n\t\t\treturn -1;\n\t\t}\n\n\t\toneed_separator = *need_separator;\n\t\tif (m->flag & NOSPACE)\n\t\t\t*need_separator = 0;\n\t\trv = match(ms, ml.magic, ml.nmagic, s, nbytes, offset + o,\n\t\t    mode, text, flip, recursion_level, printed_something,\n\t\t    need_separator, returnval);\n\t\tif (rv != 1)\n\t\t    *need_separator = oneed_separator;\n\t\treturn rv;\n\n\tcase FILE_NAME:\n\t\tif (file_printf(ms, \"%s\", m->desc) == -1)\n\t\t\treturn -1;\n\t\treturn 1;\n\tcase FILE_DEFAULT:\t/* nothing to check */\n\tcase FILE_CLEAR:\n\tdefault:\n\t\tbreak;\n\t}\n\tif (!mconvert(ms, m, flip))\n\t\treturn 0;\n\treturn 1;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,7 +5,6 @@\n     int *need_separator, int *returnval)\n {\n \tuint32_t soffset, offset = ms->offset;\n-\tuint32_t count = m->str_range;\n \tuint32_t lhs;\n \tint rv, oneed_separator, in_type;\n \tchar *sbuf, *rbuf;\n@@ -18,13 +17,12 @@\n \t}\n \n \tif (mcopy(ms, p, m->type, m->flag & INDIR, s, (uint32_t)(offset + o),\n-\t    (uint32_t)nbytes, count) == -1)\n+\t    (uint32_t)nbytes, m) == -1)\n \t\treturn -1;\n \n \tif ((ms->flags & MAGIC_DEBUG) != 0) {\n \t\tfprintf(stderr, \"mget(type=%d, flag=%x, offset=%u, o=%zu, \"\n-\t\t    \"nbytes=%zu, count=%u)\\n\", m->type, m->flag, offset, o,\n-\t\t    nbytes, count);\n+\t\t    \"nbytes=%zu)\\n\", m->type, m->flag, offset, o, nbytes);\n \t\tmdebug(offset, (char *)(void *)p, sizeof(union VALUETYPE));\n #ifndef COMPILE_ONLY\n \t\tfile_mdump(m);\n@@ -389,7 +387,7 @@\n \t\t\tif ((ms->flags & MAGIC_DEBUG) != 0)\n \t\t\t\tfprintf(stderr, \"indirect +offs=%u\\n\", offset);\n \t\t}\n-\t\tif (mcopy(ms, p, m->type, 0, s, offset, nbytes, count) == -1)\n+\t\tif (mcopy(ms, p, m->type, 0, s, offset, nbytes, m) == -1)\n \t\t\treturn -1;\n \t\tms->offset = offset;\n ",
        "diff_line_info": {
            "deleted_lines": [
                "\tuint32_t count = m->str_range;",
                "\t    (uint32_t)nbytes, count) == -1)",
                "\t\t    \"nbytes=%zu, count=%u)\\n\", m->type, m->flag, offset, o,",
                "\t\t    nbytes, count);",
                "\t\tif (mcopy(ms, p, m->type, 0, s, offset, nbytes, count) == -1)"
            ],
            "added_lines": [
                "\t    (uint32_t)nbytes, m) == -1)",
                "\t\t    \"nbytes=%zu)\\n\", m->type, m->flag, offset, o, nbytes);",
                "\t\tif (mcopy(ms, p, m->type, 0, s, offset, nbytes, m) == -1)"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-3538",
        "func_name": "file/magiccheck",
        "description": "file before 5.19 does not properly restrict the amount of data read during a regex search, which allows remote attackers to cause a denial of service (CPU consumption) via a crafted file that triggers backtracking during processing of an awk rule.  NOTE: this vulnerability exists because of an incomplete fix for CVE-2013-7345.",
        "git_url": "https://github.com/file/file/commit/4a284c89d6ef11aca34da65da7d673050a5ea320",
        "commit_title": "* Enforce limit of 8K on regex searches that have no limits",
        "commit_text": "* Allow the l modifier for regex to mean line count. Default   to byte count. If line count is specified, assume a max   of 80 characters per line to limit the byte count. * Don't allow conversions to be used for dates, allowing   the mask field to be used as an offset. * Bump the version of the magic format so that regex changes   are visible.",
        "func_before": "private int\nmagiccheck(struct magic_set *ms, struct magic *m)\n{\n\tuint64_t l = m->value.q;\n\tuint64_t v;\n\tfloat fl, fv;\n\tdouble dl, dv;\n\tint matched;\n\tunion VALUETYPE *p = &ms->ms_value;\n\n\tswitch (m->type) {\n\tcase FILE_BYTE:\n\t\tv = p->b;\n\t\tbreak;\n\n\tcase FILE_SHORT:\n\tcase FILE_BESHORT:\n\tcase FILE_LESHORT:\n\t\tv = p->h;\n\t\tbreak;\n\n\tcase FILE_LONG:\n\tcase FILE_BELONG:\n\tcase FILE_LELONG:\n\tcase FILE_MELONG:\n\tcase FILE_DATE:\n\tcase FILE_BEDATE:\n\tcase FILE_LEDATE:\n\tcase FILE_MEDATE:\n\tcase FILE_LDATE:\n\tcase FILE_BELDATE:\n\tcase FILE_LELDATE:\n\tcase FILE_MELDATE:\n\t\tv = p->l;\n\t\tbreak;\n\n\tcase FILE_QUAD:\n\tcase FILE_LEQUAD:\n\tcase FILE_BEQUAD:\n\tcase FILE_QDATE:\n\tcase FILE_BEQDATE:\n\tcase FILE_LEQDATE:\n\tcase FILE_QLDATE:\n\tcase FILE_BEQLDATE:\n\tcase FILE_LEQLDATE:\n\tcase FILE_QWDATE:\n\tcase FILE_BEQWDATE:\n\tcase FILE_LEQWDATE:\n\t\tv = p->q;\n\t\tbreak;\n\n\tcase FILE_FLOAT:\n\tcase FILE_BEFLOAT:\n\tcase FILE_LEFLOAT:\n\t\tfl = m->value.f;\n\t\tfv = p->f;\n\t\tswitch (m->reln) {\n\t\tcase 'x':\n\t\t\tmatched = 1;\n\t\t\tbreak;\n\n\t\tcase '!':\n\t\t\tmatched = fv != fl;\n\t\t\tbreak;\n\n\t\tcase '=':\n\t\t\tmatched = fv == fl;\n\t\t\tbreak;\n\n\t\tcase '>':\n\t\t\tmatched = fv > fl;\n\t\t\tbreak;\n\n\t\tcase '<':\n\t\t\tmatched = fv < fl;\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tfile_magerror(ms, \"cannot happen with float: invalid relation `%c'\",\n\t\t\t    m->reln);\n\t\t\treturn -1;\n\t\t}\n\t\treturn matched;\n\n\tcase FILE_DOUBLE:\n\tcase FILE_BEDOUBLE:\n\tcase FILE_LEDOUBLE:\n\t\tdl = m->value.d;\n\t\tdv = p->d;\n\t\tswitch (m->reln) {\n\t\tcase 'x':\n\t\t\tmatched = 1;\n\t\t\tbreak;\n\n\t\tcase '!':\n\t\t\tmatched = dv != dl;\n\t\t\tbreak;\n\n\t\tcase '=':\n\t\t\tmatched = dv == dl;\n\t\t\tbreak;\n\n\t\tcase '>':\n\t\t\tmatched = dv > dl;\n\t\t\tbreak;\n\n\t\tcase '<':\n\t\t\tmatched = dv < dl;\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tfile_magerror(ms, \"cannot happen with double: invalid relation `%c'\", m->reln);\n\t\t\treturn -1;\n\t\t}\n\t\treturn matched;\n\n\tcase FILE_DEFAULT:\n\tcase FILE_CLEAR:\n\t\tl = 0;\n\t\tv = 0;\n\t\tbreak;\n\n\tcase FILE_STRING:\n\tcase FILE_PSTRING:\n\t\tl = 0;\n\t\tv = file_strncmp(m->value.s, p->s, (size_t)m->vallen, m->str_flags);\n\t\tbreak;\n\n\tcase FILE_BESTRING16:\n\tcase FILE_LESTRING16:\n\t\tl = 0;\n\t\tv = file_strncmp16(m->value.s, p->s, (size_t)m->vallen, m->str_flags);\n\t\tbreak;\n\n\tcase FILE_SEARCH: { /* search ms->search.s for the string m->value.s */\n\t\tsize_t slen;\n\t\tsize_t idx;\n\n\t\tif (ms->search.s == NULL)\n\t\t\treturn 0;\n\n\t\tslen = MIN(m->vallen, sizeof(m->value.s));\n\t\tl = 0;\n\t\tv = 0;\n\n\t\tfor (idx = 0; m->str_range == 0 || idx < m->str_range; idx++) {\n\t\t\tif (slen + idx > ms->search.s_len)\n\t\t\t\tbreak;\n\n\t\t\tv = file_strncmp(m->value.s, ms->search.s + idx, slen, m->str_flags);\n\t\t\tif (v == 0) {\t/* found match */\n\t\t\t\tms->search.offset += idx;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tbreak;\n\t}\n\tcase FILE_REGEX: {\n\t\tint rc;\n\t\tfile_regex_t rx;\n\n\t\tif (ms->search.s == NULL)\n\t\t\treturn 0;\n\n\t\tl = 0;\n\t\trc = file_regcomp(&rx, m->value.s,\n\t\t    REG_EXTENDED|REG_NEWLINE|\n\t\t    ((m->str_flags & STRING_IGNORE_CASE) ? REG_ICASE : 0));\n\t\tif (rc) {\n\t\t\tfile_regerror(&rx, rc, ms);\n\t\t\tv = (uint64_t)-1;\n\t\t} else {\n#ifndef REG_STARTEND\n\t\t\tchar c;\n#endif\n\t\t\tregmatch_t pmatch[1];\n\t\t\tsize_t slen = ms->search.s_len;\n\t\t\t/* Limit by offset if requested */\n\t\t\tif (m->str_range > 0)\n\t\t\t\tslen = MIN(slen, m->str_range);\n#ifndef REG_STARTEND\n#define\tREG_STARTEND\t0\n\t\t\tif (slen != 0)\n\t\t\t\tslen--;\n\t\t\tc = ms->search.s[slen];\n\t\t\t((char *)(intptr_t)ms->search.s)[slen] = '\\0';\n#else\n\t\t\tpmatch[0].rm_so = 0;\n\t\t\tpmatch[0].rm_eo = slen;\n#endif\n\t\t\trc = file_regexec(&rx, (const char *)ms->search.s,\n\t\t\t    1, pmatch, REG_STARTEND);\n#if REG_STARTEND == 0\n\t\t\t((char *)(intptr_t)ms->search.s)[l] = c;\n#endif\n\t\t\tswitch (rc) {\n\t\t\tcase 0:\n\t\t\t\tms->search.s += (int)pmatch[0].rm_so;\n\t\t\t\tms->search.offset += (size_t)pmatch[0].rm_so;\n\t\t\t\tms->search.rm_len =\n\t\t\t\t    (size_t)(pmatch[0].rm_eo - pmatch[0].rm_so);\n\t\t\t\tv = 0;\n\t\t\t\tbreak;\n\n\t\t\tcase REG_NOMATCH:\n\t\t\t\tv = 1;\n\t\t\t\tbreak;\n\n\t\t\tdefault:\n\t\t\t\tfile_regerror(&rx, rc, ms);\n\t\t\t\tv = (uint64_t)-1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tfile_regfree(&rx);\n\t\tif (v == (uint64_t)-1)\n\t\t\treturn -1;\n\t\tbreak;\n\t}\n\tcase FILE_INDIRECT:\n\tcase FILE_USE:\n\tcase FILE_NAME:\n\t\treturn 1;\n\tdefault:\n\t\tfile_magerror(ms, \"invalid type %d in magiccheck()\", m->type);\n\t\treturn -1;\n\t}\n\n\tv = file_signextend(ms, m, v);\n\n\tswitch (m->reln) {\n\tcase 'x':\n\t\tif ((ms->flags & MAGIC_DEBUG) != 0)\n\t\t\t(void) fprintf(stderr, \"%\" INT64_T_FORMAT\n\t\t\t    \"u == *any* = 1\\n\", (unsigned long long)v);\n\t\tmatched = 1;\n\t\tbreak;\n\n\tcase '!':\n\t\tmatched = v != l;\n\t\tif ((ms->flags & MAGIC_DEBUG) != 0)\n\t\t\t(void) fprintf(stderr, \"%\" INT64_T_FORMAT \"u != %\"\n\t\t\t    INT64_T_FORMAT \"u = %d\\n\", (unsigned long long)v,\n\t\t\t    (unsigned long long)l, matched);\n\t\tbreak;\n\n\tcase '=':\n\t\tmatched = v == l;\n\t\tif ((ms->flags & MAGIC_DEBUG) != 0)\n\t\t\t(void) fprintf(stderr, \"%\" INT64_T_FORMAT \"u == %\"\n\t\t\t    INT64_T_FORMAT \"u = %d\\n\", (unsigned long long)v,\n\t\t\t    (unsigned long long)l, matched);\n\t\tbreak;\n\n\tcase '>':\n\t\tif (m->flag & UNSIGNED) {\n\t\t\tmatched = v > l;\n\t\t\tif ((ms->flags & MAGIC_DEBUG) != 0)\n\t\t\t\t(void) fprintf(stderr, \"%\" INT64_T_FORMAT\n\t\t\t\t    \"u > %\" INT64_T_FORMAT \"u = %d\\n\",\n\t\t\t\t    (unsigned long long)v,\n\t\t\t\t    (unsigned long long)l, matched);\n\t\t}\n\t\telse {\n\t\t\tmatched = (int64_t) v > (int64_t) l;\n\t\t\tif ((ms->flags & MAGIC_DEBUG) != 0)\n\t\t\t\t(void) fprintf(stderr, \"%\" INT64_T_FORMAT\n\t\t\t\t    \"d > %\" INT64_T_FORMAT \"d = %d\\n\",\n\t\t\t\t    (long long)v, (long long)l, matched);\n\t\t}\n\t\tbreak;\n\n\tcase '<':\n\t\tif (m->flag & UNSIGNED) {\n\t\t\tmatched = v < l;\n\t\t\tif ((ms->flags & MAGIC_DEBUG) != 0)\n\t\t\t\t(void) fprintf(stderr, \"%\" INT64_T_FORMAT\n\t\t\t\t    \"u < %\" INT64_T_FORMAT \"u = %d\\n\",\n\t\t\t\t    (unsigned long long)v,\n\t\t\t\t    (unsigned long long)l, matched);\n\t\t}\n\t\telse {\n\t\t\tmatched = (int64_t) v < (int64_t) l;\n\t\t\tif ((ms->flags & MAGIC_DEBUG) != 0)\n\t\t\t\t(void) fprintf(stderr, \"%\" INT64_T_FORMAT\n\t\t\t\t    \"d < %\" INT64_T_FORMAT \"d = %d\\n\",\n\t\t\t\t     (long long)v, (long long)l, matched);\n\t\t}\n\t\tbreak;\n\n\tcase '&':\n\t\tmatched = (v & l) == l;\n\t\tif ((ms->flags & MAGIC_DEBUG) != 0)\n\t\t\t(void) fprintf(stderr, \"((%\" INT64_T_FORMAT \"x & %\"\n\t\t\t    INT64_T_FORMAT \"x) == %\" INT64_T_FORMAT\n\t\t\t    \"x) = %d\\n\", (unsigned long long)v,\n\t\t\t    (unsigned long long)l, (unsigned long long)l,\n\t\t\t    matched);\n\t\tbreak;\n\n\tcase '^':\n\t\tmatched = (v & l) != l;\n\t\tif ((ms->flags & MAGIC_DEBUG) != 0)\n\t\t\t(void) fprintf(stderr, \"((%\" INT64_T_FORMAT \"x & %\"\n\t\t\t    INT64_T_FORMAT \"x) != %\" INT64_T_FORMAT\n\t\t\t    \"x) = %d\\n\", (unsigned long long)v,\n\t\t\t    (unsigned long long)l, (unsigned long long)l,\n\t\t\t    matched);\n\t\tbreak;\n\n\tdefault:\n\t\tfile_magerror(ms, \"cannot happen: invalid relation `%c'\",\n\t\t    m->reln);\n\t\treturn -1;\n\t}\n\n\treturn matched;\n}",
        "func": "private int\nmagiccheck(struct magic_set *ms, struct magic *m)\n{\n\tuint64_t l = m->value.q;\n\tuint64_t v;\n\tfloat fl, fv;\n\tdouble dl, dv;\n\tint matched;\n\tunion VALUETYPE *p = &ms->ms_value;\n\n\tswitch (m->type) {\n\tcase FILE_BYTE:\n\t\tv = p->b;\n\t\tbreak;\n\n\tcase FILE_SHORT:\n\tcase FILE_BESHORT:\n\tcase FILE_LESHORT:\n\t\tv = p->h;\n\t\tbreak;\n\n\tcase FILE_LONG:\n\tcase FILE_BELONG:\n\tcase FILE_LELONG:\n\tcase FILE_MELONG:\n\tcase FILE_DATE:\n\tcase FILE_BEDATE:\n\tcase FILE_LEDATE:\n\tcase FILE_MEDATE:\n\tcase FILE_LDATE:\n\tcase FILE_BELDATE:\n\tcase FILE_LELDATE:\n\tcase FILE_MELDATE:\n\t\tv = p->l;\n\t\tbreak;\n\n\tcase FILE_QUAD:\n\tcase FILE_LEQUAD:\n\tcase FILE_BEQUAD:\n\tcase FILE_QDATE:\n\tcase FILE_BEQDATE:\n\tcase FILE_LEQDATE:\n\tcase FILE_QLDATE:\n\tcase FILE_BEQLDATE:\n\tcase FILE_LEQLDATE:\n\tcase FILE_QWDATE:\n\tcase FILE_BEQWDATE:\n\tcase FILE_LEQWDATE:\n\t\tv = p->q;\n\t\tbreak;\n\n\tcase FILE_FLOAT:\n\tcase FILE_BEFLOAT:\n\tcase FILE_LEFLOAT:\n\t\tfl = m->value.f;\n\t\tfv = p->f;\n\t\tswitch (m->reln) {\n\t\tcase 'x':\n\t\t\tmatched = 1;\n\t\t\tbreak;\n\n\t\tcase '!':\n\t\t\tmatched = fv != fl;\n\t\t\tbreak;\n\n\t\tcase '=':\n\t\t\tmatched = fv == fl;\n\t\t\tbreak;\n\n\t\tcase '>':\n\t\t\tmatched = fv > fl;\n\t\t\tbreak;\n\n\t\tcase '<':\n\t\t\tmatched = fv < fl;\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tfile_magerror(ms, \"cannot happen with float: invalid relation `%c'\",\n\t\t\t    m->reln);\n\t\t\treturn -1;\n\t\t}\n\t\treturn matched;\n\n\tcase FILE_DOUBLE:\n\tcase FILE_BEDOUBLE:\n\tcase FILE_LEDOUBLE:\n\t\tdl = m->value.d;\n\t\tdv = p->d;\n\t\tswitch (m->reln) {\n\t\tcase 'x':\n\t\t\tmatched = 1;\n\t\t\tbreak;\n\n\t\tcase '!':\n\t\t\tmatched = dv != dl;\n\t\t\tbreak;\n\n\t\tcase '=':\n\t\t\tmatched = dv == dl;\n\t\t\tbreak;\n\n\t\tcase '>':\n\t\t\tmatched = dv > dl;\n\t\t\tbreak;\n\n\t\tcase '<':\n\t\t\tmatched = dv < dl;\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tfile_magerror(ms, \"cannot happen with double: invalid relation `%c'\", m->reln);\n\t\t\treturn -1;\n\t\t}\n\t\treturn matched;\n\n\tcase FILE_DEFAULT:\n\tcase FILE_CLEAR:\n\t\tl = 0;\n\t\tv = 0;\n\t\tbreak;\n\n\tcase FILE_STRING:\n\tcase FILE_PSTRING:\n\t\tl = 0;\n\t\tv = file_strncmp(m->value.s, p->s, (size_t)m->vallen, m->str_flags);\n\t\tbreak;\n\n\tcase FILE_BESTRING16:\n\tcase FILE_LESTRING16:\n\t\tl = 0;\n\t\tv = file_strncmp16(m->value.s, p->s, (size_t)m->vallen, m->str_flags);\n\t\tbreak;\n\n\tcase FILE_SEARCH: { /* search ms->search.s for the string m->value.s */\n\t\tsize_t slen;\n\t\tsize_t idx;\n\n\t\tif (ms->search.s == NULL)\n\t\t\treturn 0;\n\n\t\tslen = MIN(m->vallen, sizeof(m->value.s));\n\t\tl = 0;\n\t\tv = 0;\n\n\t\tfor (idx = 0; m->str_range == 0 || idx < m->str_range; idx++) {\n\t\t\tif (slen + idx > ms->search.s_len)\n\t\t\t\tbreak;\n\n\t\t\tv = file_strncmp(m->value.s, ms->search.s + idx, slen,\n\t\t\t    m->str_flags);\n\t\t\tif (v == 0) {\t/* found match */\n\t\t\t\tms->search.offset += idx;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tbreak;\n\t}\n\tcase FILE_REGEX: {\n\t\tint rc;\n\t\tfile_regex_t rx;\n\n\t\tif (ms->search.s == NULL)\n\t\t\treturn 0;\n\n\t\tl = 0;\n\t\trc = file_regcomp(&rx, m->value.s,\n\t\t    REG_EXTENDED|REG_NEWLINE|\n\t\t    ((m->str_flags & STRING_IGNORE_CASE) ? REG_ICASE : 0));\n\t\tif (rc) {\n\t\t\tfile_regerror(&rx, rc, ms);\n\t\t\tv = (uint64_t)-1;\n\t\t} else {\n\t\t\tregmatch_t pmatch[1];\n\t\t\tsize_t slen = ms->search.s_len;\n#ifndef REG_STARTEND\n#define\tREG_STARTEND\t0\n\t\t\tchar c;\n\t\t\tif (slen != 0)\n\t\t\t\tslen--;\n\t\t\tc = ms->search.s[slen];\n\t\t\t((char *)(intptr_t)ms->search.s)[slen] = '\\0';\n#else\n\t\t\tpmatch[0].rm_so = 0;\n\t\t\tpmatch[0].rm_eo = slen;\n#endif\n\t\t\trc = file_regexec(&rx, (const char *)ms->search.s,\n\t\t\t    1, pmatch, REG_STARTEND);\n#if REG_STARTEND == 0\n\t\t\t((char *)(intptr_t)ms->search.s)[l] = c;\n#endif\n\t\t\tswitch (rc) {\n\t\t\tcase 0:\n\t\t\t\tms->search.s += (int)pmatch[0].rm_so;\n\t\t\t\tms->search.offset += (size_t)pmatch[0].rm_so;\n\t\t\t\tms->search.rm_len =\n\t\t\t\t    (size_t)(pmatch[0].rm_eo - pmatch[0].rm_so);\n\t\t\t\tv = 0;\n\t\t\t\tbreak;\n\n\t\t\tcase REG_NOMATCH:\n\t\t\t\tv = 1;\n\t\t\t\tbreak;\n\n\t\t\tdefault:\n\t\t\t\tfile_regerror(&rx, rc, ms);\n\t\t\t\tv = (uint64_t)-1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tfile_regfree(&rx);\n\t\tif (v == (uint64_t)-1)\n\t\t\treturn -1;\n\t\tbreak;\n\t}\n\tcase FILE_INDIRECT:\n\tcase FILE_USE:\n\tcase FILE_NAME:\n\t\treturn 1;\n\tdefault:\n\t\tfile_magerror(ms, \"invalid type %d in magiccheck()\", m->type);\n\t\treturn -1;\n\t}\n\n\tv = file_signextend(ms, m, v);\n\n\tswitch (m->reln) {\n\tcase 'x':\n\t\tif ((ms->flags & MAGIC_DEBUG) != 0)\n\t\t\t(void) fprintf(stderr, \"%\" INT64_T_FORMAT\n\t\t\t    \"u == *any* = 1\\n\", (unsigned long long)v);\n\t\tmatched = 1;\n\t\tbreak;\n\n\tcase '!':\n\t\tmatched = v != l;\n\t\tif ((ms->flags & MAGIC_DEBUG) != 0)\n\t\t\t(void) fprintf(stderr, \"%\" INT64_T_FORMAT \"u != %\"\n\t\t\t    INT64_T_FORMAT \"u = %d\\n\", (unsigned long long)v,\n\t\t\t    (unsigned long long)l, matched);\n\t\tbreak;\n\n\tcase '=':\n\t\tmatched = v == l;\n\t\tif ((ms->flags & MAGIC_DEBUG) != 0)\n\t\t\t(void) fprintf(stderr, \"%\" INT64_T_FORMAT \"u == %\"\n\t\t\t    INT64_T_FORMAT \"u = %d\\n\", (unsigned long long)v,\n\t\t\t    (unsigned long long)l, matched);\n\t\tbreak;\n\n\tcase '>':\n\t\tif (m->flag & UNSIGNED) {\n\t\t\tmatched = v > l;\n\t\t\tif ((ms->flags & MAGIC_DEBUG) != 0)\n\t\t\t\t(void) fprintf(stderr, \"%\" INT64_T_FORMAT\n\t\t\t\t    \"u > %\" INT64_T_FORMAT \"u = %d\\n\",\n\t\t\t\t    (unsigned long long)v,\n\t\t\t\t    (unsigned long long)l, matched);\n\t\t}\n\t\telse {\n\t\t\tmatched = (int64_t) v > (int64_t) l;\n\t\t\tif ((ms->flags & MAGIC_DEBUG) != 0)\n\t\t\t\t(void) fprintf(stderr, \"%\" INT64_T_FORMAT\n\t\t\t\t    \"d > %\" INT64_T_FORMAT \"d = %d\\n\",\n\t\t\t\t    (long long)v, (long long)l, matched);\n\t\t}\n\t\tbreak;\n\n\tcase '<':\n\t\tif (m->flag & UNSIGNED) {\n\t\t\tmatched = v < l;\n\t\t\tif ((ms->flags & MAGIC_DEBUG) != 0)\n\t\t\t\t(void) fprintf(stderr, \"%\" INT64_T_FORMAT\n\t\t\t\t    \"u < %\" INT64_T_FORMAT \"u = %d\\n\",\n\t\t\t\t    (unsigned long long)v,\n\t\t\t\t    (unsigned long long)l, matched);\n\t\t}\n\t\telse {\n\t\t\tmatched = (int64_t) v < (int64_t) l;\n\t\t\tif ((ms->flags & MAGIC_DEBUG) != 0)\n\t\t\t\t(void) fprintf(stderr, \"%\" INT64_T_FORMAT\n\t\t\t\t    \"d < %\" INT64_T_FORMAT \"d = %d\\n\",\n\t\t\t\t     (long long)v, (long long)l, matched);\n\t\t}\n\t\tbreak;\n\n\tcase '&':\n\t\tmatched = (v & l) == l;\n\t\tif ((ms->flags & MAGIC_DEBUG) != 0)\n\t\t\t(void) fprintf(stderr, \"((%\" INT64_T_FORMAT \"x & %\"\n\t\t\t    INT64_T_FORMAT \"x) == %\" INT64_T_FORMAT\n\t\t\t    \"x) = %d\\n\", (unsigned long long)v,\n\t\t\t    (unsigned long long)l, (unsigned long long)l,\n\t\t\t    matched);\n\t\tbreak;\n\n\tcase '^':\n\t\tmatched = (v & l) != l;\n\t\tif ((ms->flags & MAGIC_DEBUG) != 0)\n\t\t\t(void) fprintf(stderr, \"((%\" INT64_T_FORMAT \"x & %\"\n\t\t\t    INT64_T_FORMAT \"x) != %\" INT64_T_FORMAT\n\t\t\t    \"x) = %d\\n\", (unsigned long long)v,\n\t\t\t    (unsigned long long)l, (unsigned long long)l,\n\t\t\t    matched);\n\t\tbreak;\n\n\tdefault:\n\t\tfile_magerror(ms, \"cannot happen: invalid relation `%c'\",\n\t\t    m->reln);\n\t\treturn -1;\n\t}\n\n\treturn matched;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -147,7 +147,8 @@\n \t\t\tif (slen + idx > ms->search.s_len)\n \t\t\t\tbreak;\n \n-\t\t\tv = file_strncmp(m->value.s, ms->search.s + idx, slen, m->str_flags);\n+\t\t\tv = file_strncmp(m->value.s, ms->search.s + idx, slen,\n+\t\t\t    m->str_flags);\n \t\t\tif (v == 0) {\t/* found match */\n \t\t\t\tms->search.offset += idx;\n \t\t\t\tbreak;\n@@ -170,16 +171,11 @@\n \t\t\tfile_regerror(&rx, rc, ms);\n \t\t\tv = (uint64_t)-1;\n \t\t} else {\n-#ifndef REG_STARTEND\n-\t\t\tchar c;\n-#endif\n \t\t\tregmatch_t pmatch[1];\n \t\t\tsize_t slen = ms->search.s_len;\n-\t\t\t/* Limit by offset if requested */\n-\t\t\tif (m->str_range > 0)\n-\t\t\t\tslen = MIN(slen, m->str_range);\n #ifndef REG_STARTEND\n #define\tREG_STARTEND\t0\n+\t\t\tchar c;\n \t\t\tif (slen != 0)\n \t\t\t\tslen--;\n \t\t\tc = ms->search.s[slen];",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\tv = file_strncmp(m->value.s, ms->search.s + idx, slen, m->str_flags);",
                "#ifndef REG_STARTEND",
                "\t\t\tchar c;",
                "#endif",
                "\t\t\t/* Limit by offset if requested */",
                "\t\t\tif (m->str_range > 0)",
                "\t\t\t\tslen = MIN(slen, m->str_range);"
            ],
            "added_lines": [
                "\t\t\tv = file_strncmp(m->value.s, ms->search.s + idx, slen,",
                "\t\t\t    m->str_flags);",
                "\t\t\tchar c;"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-3538",
        "func_name": "file/mcopy",
        "description": "file before 5.19 does not properly restrict the amount of data read during a regex search, which allows remote attackers to cause a denial of service (CPU consumption) via a crafted file that triggers backtracking during processing of an awk rule.  NOTE: this vulnerability exists because of an incomplete fix for CVE-2013-7345.",
        "git_url": "https://github.com/file/file/commit/4a284c89d6ef11aca34da65da7d673050a5ea320",
        "commit_title": "* Enforce limit of 8K on regex searches that have no limits",
        "commit_text": "* Allow the l modifier for regex to mean line count. Default   to byte count. If line count is specified, assume a max   of 80 characters per line to limit the byte count. * Don't allow conversions to be used for dates, allowing   the mask field to be used as an offset. * Bump the version of the magic format so that regex changes   are visible.",
        "func_before": "private int\nmcopy(struct magic_set *ms, union VALUETYPE *p, int type, int indir,\n    const unsigned char *s, uint32_t offset, size_t nbytes, size_t linecnt)\n{\n\t/*\n\t * Note: FILE_SEARCH and FILE_REGEX do not actually copy\n\t * anything, but setup pointers into the source\n\t */\n\tif (indir == 0) {\n\t\tswitch (type) {\n\t\tcase FILE_SEARCH:\n\t\t\tms->search.s = RCAST(const char *, s) + offset;\n\t\t\tms->search.s_len = nbytes - offset;\n\t\t\tms->search.offset = offset;\n\t\t\treturn 0;\n\n\t\tcase FILE_REGEX: {\n\t\t\tconst char *b;\n\t\t\tconst char *c;\n\t\t\tconst char *last;\t/* end of search region */\n\t\t\tconst char *buf;\t/* start of search region */\n\t\t\tconst char *end;\n\t\t\tsize_t lines;\n\n\t\t\tif (s == NULL) {\n\t\t\t\tms->search.s_len = 0;\n\t\t\t\tms->search.s = NULL;\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t\tbuf = RCAST(const char *, s) + offset;\n\t\t\tend = last = RCAST(const char *, s) + nbytes;\n\t\t\t/* mget() guarantees buf <= last */\n\t\t\tfor (lines = linecnt, b = buf; lines && b < end &&\n\t\t\t     ((b = CAST(const char *,\n\t\t\t\t memchr(c = b, '\\n', CAST(size_t, (end - b)))))\n\t\t\t     || (b = CAST(const char *,\n\t\t\t\t memchr(c, '\\r', CAST(size_t, (end - c))))));\n\t\t\t     lines--, b++) {\n\t\t\t\tlast = b;\n\t\t\t\tif (b[0] == '\\r' && b[1] == '\\n')\n\t\t\t\t\tb++;\n\t\t\t}\n\t\t\tif (lines)\n\t\t\t\tlast = RCAST(const char *, s) + nbytes;\n\n\t\t\tms->search.s = buf;\n\t\t\tms->search.s_len = last - buf;\n\t\t\tms->search.offset = offset;\n\t\t\tms->search.rm_len = 0;\n\t\t\treturn 0;\n\t\t}\n\t\tcase FILE_BESTRING16:\n\t\tcase FILE_LESTRING16: {\n\t\t\tconst unsigned char *src = s + offset;\n\t\t\tconst unsigned char *esrc = s + nbytes;\n\t\t\tchar *dst = p->s;\n\t\t\tchar *edst = &p->s[sizeof(p->s) - 1];\n\n\t\t\tif (type == FILE_BESTRING16)\n\t\t\t\tsrc++;\n\n\t\t\t/* check that offset is within range */\n\t\t\tif (offset >= nbytes)\n\t\t\t\tbreak;\n\t\t\tfor (/*EMPTY*/; src < esrc; src += 2, dst++) {\n\t\t\t\tif (dst < edst)\n\t\t\t\t\t*dst = *src;\n\t\t\t\telse\n\t\t\t\t\tbreak;\n\t\t\t\tif (*dst == '\\0') {\n\t\t\t\t\tif (type == FILE_BESTRING16 ?\n\t\t\t\t\t    *(src - 1) != '\\0' :\n\t\t\t\t\t    *(src + 1) != '\\0')\n\t\t\t\t\t\t*dst = ' ';\n\t\t\t\t}\n\t\t\t}\n\t\t\t*edst = '\\0';\n\t\t\treturn 0;\n\t\t}\n\t\tcase FILE_STRING:\t/* XXX - these two should not need */\n\t\tcase FILE_PSTRING:\t/* to copy anything, but do anyway. */\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (offset >= nbytes) {\n\t\t(void)memset(p, '\\0', sizeof(*p));\n\t\treturn 0;\n\t}\n\tif (nbytes - offset < sizeof(*p))\n\t\tnbytes = nbytes - offset;\n\telse\n\t\tnbytes = sizeof(*p);\n\n\t(void)memcpy(p, s + offset, nbytes);\n\n\t/*\n\t * the usefulness of padding with zeroes eludes me, it\n\t * might even cause problems\n\t */\n\tif (nbytes < sizeof(*p))\n\t\t(void)memset(((char *)(void *)p) + nbytes, '\\0',\n\t\t    sizeof(*p) - nbytes);\n\treturn 0;\n}",
        "func": "private int\nmcopy(struct magic_set *ms, union VALUETYPE *p, int type, int indir,\n    const unsigned char *s, uint32_t offset, size_t nbytes, struct magic *m)\n{\n\t/*\n\t * Note: FILE_SEARCH and FILE_REGEX do not actually copy\n\t * anything, but setup pointers into the source\n\t */\n\tif (indir == 0) {\n\t\tswitch (type) {\n\t\tcase FILE_SEARCH:\n\t\t\tms->search.s = RCAST(const char *, s) + offset;\n\t\t\tms->search.s_len = nbytes - offset;\n\t\t\tms->search.offset = offset;\n\t\t\treturn 0;\n\n\t\tcase FILE_REGEX: {\n\t\t\tconst char *b;\n\t\t\tconst char *c;\n\t\t\tconst char *last;\t/* end of search region */\n\t\t\tconst char *buf;\t/* start of search region */\n\t\t\tconst char *end;\n\t\t\tsize_t lines, linecnt, bytecnt;\n\n\t\t\tif (s == NULL) {\n\t\t\t\tms->search.s_len = 0;\n\t\t\t\tms->search.s = NULL;\n\t\t\t\treturn 0;\n\t\t\t}\n\n\t\t\tif (m->str_flags & REGEX_LINE_COUNT) {\n\t\t\t\tlinecnt = m->str_range;\n\t\t\t\tbytecnt = linecnt * 80;\n\t\t\t} else {\n\t\t\t\tlinecnt = 0;\n\t\t\t\tbytecnt = m->str_range;\n\t\t\t}\n\n\t\t\tif (bytecnt == 0)\n\t\t\t\tbytecnt = 8192;\n\t\t\tif (bytecnt > nbytes)\n\t\t\t\tbytecnt = nbytes;\n\n\t\t\tbuf = RCAST(const char *, s) + offset;\n\t\t\tend = last = RCAST(const char *, s) + bytecnt;\n\t\t\t/* mget() guarantees buf <= last */\n\t\t\tfor (lines = linecnt, b = buf; lines && b < end &&\n\t\t\t     ((b = CAST(const char *,\n\t\t\t\t memchr(c = b, '\\n', CAST(size_t, (end - b)))))\n\t\t\t     || (b = CAST(const char *,\n\t\t\t\t memchr(c, '\\r', CAST(size_t, (end - c))))));\n\t\t\t     lines--, b++) {\n\t\t\t\tlast = b;\n\t\t\t\tif (b[0] == '\\r' && b[1] == '\\n')\n\t\t\t\t\tb++;\n\t\t\t}\n\t\t\tif (lines)\n\t\t\t\tlast = RCAST(const char *, s) + bytecnt;\n\n\t\t\tms->search.s = buf;\n\t\t\tms->search.s_len = last - buf;\n\t\t\tms->search.offset = offset;\n\t\t\tms->search.rm_len = 0;\n\t\t\treturn 0;\n\t\t}\n\t\tcase FILE_BESTRING16:\n\t\tcase FILE_LESTRING16: {\n\t\t\tconst unsigned char *src = s + offset;\n\t\t\tconst unsigned char *esrc = s + nbytes;\n\t\t\tchar *dst = p->s;\n\t\t\tchar *edst = &p->s[sizeof(p->s) - 1];\n\n\t\t\tif (type == FILE_BESTRING16)\n\t\t\t\tsrc++;\n\n\t\t\t/* check that offset is within range */\n\t\t\tif (offset >= nbytes)\n\t\t\t\tbreak;\n\t\t\tfor (/*EMPTY*/; src < esrc; src += 2, dst++) {\n\t\t\t\tif (dst < edst)\n\t\t\t\t\t*dst = *src;\n\t\t\t\telse\n\t\t\t\t\tbreak;\n\t\t\t\tif (*dst == '\\0') {\n\t\t\t\t\tif (type == FILE_BESTRING16 ?\n\t\t\t\t\t    *(src - 1) != '\\0' :\n\t\t\t\t\t    *(src + 1) != '\\0')\n\t\t\t\t\t\t*dst = ' ';\n\t\t\t\t}\n\t\t\t}\n\t\t\t*edst = '\\0';\n\t\t\treturn 0;\n\t\t}\n\t\tcase FILE_STRING:\t/* XXX - these two should not need */\n\t\tcase FILE_PSTRING:\t/* to copy anything, but do anyway. */\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (offset >= nbytes) {\n\t\t(void)memset(p, '\\0', sizeof(*p));\n\t\treturn 0;\n\t}\n\tif (nbytes - offset < sizeof(*p))\n\t\tnbytes = nbytes - offset;\n\telse\n\t\tnbytes = sizeof(*p);\n\n\t(void)memcpy(p, s + offset, nbytes);\n\n\t/*\n\t * the usefulness of padding with zeroes eludes me, it\n\t * might even cause problems\n\t */\n\tif (nbytes < sizeof(*p))\n\t\t(void)memset(((char *)(void *)p) + nbytes, '\\0',\n\t\t    sizeof(*p) - nbytes);\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,6 @@\n private int\n mcopy(struct magic_set *ms, union VALUETYPE *p, int type, int indir,\n-    const unsigned char *s, uint32_t offset, size_t nbytes, size_t linecnt)\n+    const unsigned char *s, uint32_t offset, size_t nbytes, struct magic *m)\n {\n \t/*\n \t * Note: FILE_SEARCH and FILE_REGEX do not actually copy\n@@ -20,15 +20,29 @@\n \t\t\tconst char *last;\t/* end of search region */\n \t\t\tconst char *buf;\t/* start of search region */\n \t\t\tconst char *end;\n-\t\t\tsize_t lines;\n+\t\t\tsize_t lines, linecnt, bytecnt;\n \n \t\t\tif (s == NULL) {\n \t\t\t\tms->search.s_len = 0;\n \t\t\t\tms->search.s = NULL;\n \t\t\t\treturn 0;\n \t\t\t}\n+\n+\t\t\tif (m->str_flags & REGEX_LINE_COUNT) {\n+\t\t\t\tlinecnt = m->str_range;\n+\t\t\t\tbytecnt = linecnt * 80;\n+\t\t\t} else {\n+\t\t\t\tlinecnt = 0;\n+\t\t\t\tbytecnt = m->str_range;\n+\t\t\t}\n+\n+\t\t\tif (bytecnt == 0)\n+\t\t\t\tbytecnt = 8192;\n+\t\t\tif (bytecnt > nbytes)\n+\t\t\t\tbytecnt = nbytes;\n+\n \t\t\tbuf = RCAST(const char *, s) + offset;\n-\t\t\tend = last = RCAST(const char *, s) + nbytes;\n+\t\t\tend = last = RCAST(const char *, s) + bytecnt;\n \t\t\t/* mget() guarantees buf <= last */\n \t\t\tfor (lines = linecnt, b = buf; lines && b < end &&\n \t\t\t     ((b = CAST(const char *,\n@@ -41,7 +55,7 @@\n \t\t\t\t\tb++;\n \t\t\t}\n \t\t\tif (lines)\n-\t\t\t\tlast = RCAST(const char *, s) + nbytes;\n+\t\t\t\tlast = RCAST(const char *, s) + bytecnt;\n \n \t\t\tms->search.s = buf;\n \t\t\tms->search.s_len = last - buf;",
        "diff_line_info": {
            "deleted_lines": [
                "    const unsigned char *s, uint32_t offset, size_t nbytes, size_t linecnt)",
                "\t\t\tsize_t lines;",
                "\t\t\tend = last = RCAST(const char *, s) + nbytes;",
                "\t\t\t\tlast = RCAST(const char *, s) + nbytes;"
            ],
            "added_lines": [
                "    const unsigned char *s, uint32_t offset, size_t nbytes, struct magic *m)",
                "\t\t\tsize_t lines, linecnt, bytecnt;",
                "",
                "\t\t\tif (m->str_flags & REGEX_LINE_COUNT) {",
                "\t\t\t\tlinecnt = m->str_range;",
                "\t\t\t\tbytecnt = linecnt * 80;",
                "\t\t\t} else {",
                "\t\t\t\tlinecnt = 0;",
                "\t\t\t\tbytecnt = m->str_range;",
                "\t\t\t}",
                "",
                "\t\t\tif (bytecnt == 0)",
                "\t\t\t\tbytecnt = 8192;",
                "\t\t\tif (bytecnt > nbytes)",
                "\t\t\t\tbytecnt = nbytes;",
                "",
                "\t\t\tend = last = RCAST(const char *, s) + bytecnt;",
                "\t\t\t\tlast = RCAST(const char *, s) + bytecnt;"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-3538",
        "func_name": "file/magiccheck",
        "description": "file before 5.19 does not properly restrict the amount of data read during a regex search, which allows remote attackers to cause a denial of service (CPU consumption) via a crafted file that triggers backtracking during processing of an awk rule.  NOTE: this vulnerability exists because of an incomplete fix for CVE-2013-7345.",
        "git_url": "https://github.com/file/file/commit/74cafd7de9ec99a14f4480927580e501c8f852c3",
        "commit_title": "If requested, limit search length.",
        "commit_text": "",
        "func_before": "private int\nmagiccheck(struct magic_set *ms, struct magic *m)\n{\n\tuint64_t l = m->value.q;\n\tuint64_t v;\n\tfloat fl, fv;\n\tdouble dl, dv;\n\tint matched;\n\tunion VALUETYPE *p = &ms->ms_value;\n\n\tswitch (m->type) {\n\tcase FILE_BYTE:\n\t\tv = p->b;\n\t\tbreak;\n\n\tcase FILE_SHORT:\n\tcase FILE_BESHORT:\n\tcase FILE_LESHORT:\n\t\tv = p->h;\n\t\tbreak;\n\n\tcase FILE_LONG:\n\tcase FILE_BELONG:\n\tcase FILE_LELONG:\n\tcase FILE_MELONG:\n\tcase FILE_DATE:\n\tcase FILE_BEDATE:\n\tcase FILE_LEDATE:\n\tcase FILE_MEDATE:\n\tcase FILE_LDATE:\n\tcase FILE_BELDATE:\n\tcase FILE_LELDATE:\n\tcase FILE_MELDATE:\n\t\tv = p->l;\n\t\tbreak;\n\n\tcase FILE_QUAD:\n\tcase FILE_LEQUAD:\n\tcase FILE_BEQUAD:\n\tcase FILE_QDATE:\n\tcase FILE_BEQDATE:\n\tcase FILE_LEQDATE:\n\tcase FILE_QLDATE:\n\tcase FILE_BEQLDATE:\n\tcase FILE_LEQLDATE:\n\tcase FILE_QWDATE:\n\tcase FILE_BEQWDATE:\n\tcase FILE_LEQWDATE:\n\t\tv = p->q;\n\t\tbreak;\n\n\tcase FILE_FLOAT:\n\tcase FILE_BEFLOAT:\n\tcase FILE_LEFLOAT:\n\t\tfl = m->value.f;\n\t\tfv = p->f;\n\t\tswitch (m->reln) {\n\t\tcase 'x':\n\t\t\tmatched = 1;\n\t\t\tbreak;\n\n\t\tcase '!':\n\t\t\tmatched = fv != fl;\n\t\t\tbreak;\n\n\t\tcase '=':\n\t\t\tmatched = fv == fl;\n\t\t\tbreak;\n\n\t\tcase '>':\n\t\t\tmatched = fv > fl;\n\t\t\tbreak;\n\n\t\tcase '<':\n\t\t\tmatched = fv < fl;\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tfile_magerror(ms, \"cannot happen with float: invalid relation `%c'\",\n\t\t\t    m->reln);\n\t\t\treturn -1;\n\t\t}\n\t\treturn matched;\n\n\tcase FILE_DOUBLE:\n\tcase FILE_BEDOUBLE:\n\tcase FILE_LEDOUBLE:\n\t\tdl = m->value.d;\n\t\tdv = p->d;\n\t\tswitch (m->reln) {\n\t\tcase 'x':\n\t\t\tmatched = 1;\n\t\t\tbreak;\n\n\t\tcase '!':\n\t\t\tmatched = dv != dl;\n\t\t\tbreak;\n\n\t\tcase '=':\n\t\t\tmatched = dv == dl;\n\t\t\tbreak;\n\n\t\tcase '>':\n\t\t\tmatched = dv > dl;\n\t\t\tbreak;\n\n\t\tcase '<':\n\t\t\tmatched = dv < dl;\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tfile_magerror(ms, \"cannot happen with double: invalid relation `%c'\", m->reln);\n\t\t\treturn -1;\n\t\t}\n\t\treturn matched;\n\n\tcase FILE_DEFAULT:\n\tcase FILE_CLEAR:\n\t\tl = 0;\n\t\tv = 0;\n\t\tbreak;\n\n\tcase FILE_STRING:\n\tcase FILE_PSTRING:\n\t\tl = 0;\n\t\tv = file_strncmp(m->value.s, p->s, (size_t)m->vallen, m->str_flags);\n\t\tbreak;\n\n\tcase FILE_BESTRING16:\n\tcase FILE_LESTRING16:\n\t\tl = 0;\n\t\tv = file_strncmp16(m->value.s, p->s, (size_t)m->vallen, m->str_flags);\n\t\tbreak;\n\n\tcase FILE_SEARCH: { /* search ms->search.s for the string m->value.s */\n\t\tsize_t slen;\n\t\tsize_t idx;\n\n\t\tif (ms->search.s == NULL)\n\t\t\treturn 0;\n\n\t\tslen = MIN(m->vallen, sizeof(m->value.s));\n\t\tl = 0;\n\t\tv = 0;\n\n\t\tfor (idx = 0; m->str_range == 0 || idx < m->str_range; idx++) {\n\t\t\tif (slen + idx > ms->search.s_len)\n\t\t\t\tbreak;\n\n\t\t\tv = file_strncmp(m->value.s, ms->search.s + idx, slen, m->str_flags);\n\t\t\tif (v == 0) {\t/* found match */\n\t\t\t\tms->search.offset += idx;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tbreak;\n\t}\n\tcase FILE_REGEX: {\n\t\tint rc;\n\t\tfile_regex_t rx;\n\n\t\tif (ms->search.s == NULL)\n\t\t\treturn 0;\n\n\t\tl = 0;\n\t\trc = file_regcomp(&rx, m->value.s,\n\t\t    REG_EXTENDED|REG_NEWLINE|\n\t\t    ((m->str_flags & STRING_IGNORE_CASE) ? REG_ICASE : 0));\n\t\tif (rc) {\n\t\t\tfile_regerror(&rx, rc, ms);\n\t\t\tv = (uint64_t)-1;\n\t\t} else {\n\t\t\tregmatch_t pmatch[1];\n#ifndef REG_STARTEND\n#define\tREG_STARTEND\t0\n\t\t\tsize_t l = ms->search.s_len - 1;\n\t\t\tchar c = ms->search.s[l];\n\t\t\t((char *)(intptr_t)ms->search.s)[l] = '\\0';\n#else\n\t\t\tpmatch[0].rm_so = 0;\n\t\t\tpmatch[0].rm_eo = ms->search.s_len;\n#endif\n\t\t\trc = file_regexec(&rx, (const char *)ms->search.s,\n\t\t\t    1, pmatch, REG_STARTEND);\n#if REG_STARTEND == 0\n\t\t\t((char *)(intptr_t)ms->search.s)[l] = c;\n#endif\n\t\t\tswitch (rc) {\n\t\t\tcase 0:\n\t\t\t\tms->search.s += (int)pmatch[0].rm_so;\n\t\t\t\tms->search.offset += (size_t)pmatch[0].rm_so;\n\t\t\t\tms->search.rm_len =\n\t\t\t\t    (size_t)(pmatch[0].rm_eo - pmatch[0].rm_so);\n\t\t\t\tv = 0;\n\t\t\t\tbreak;\n\n\t\t\tcase REG_NOMATCH:\n\t\t\t\tv = 1;\n\t\t\t\tbreak;\n\n\t\t\tdefault:\n\t\t\t\tfile_regerror(&rx, rc, ms);\n\t\t\t\tv = (uint64_t)-1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tfile_regfree(&rx);\n\t\tif (v == (uint64_t)-1)\n\t\t\treturn -1;\n\t\tbreak;\n\t}\n\tcase FILE_INDIRECT:\n\tcase FILE_USE:\n\tcase FILE_NAME:\n\t\treturn 1;\n\tdefault:\n\t\tfile_magerror(ms, \"invalid type %d in magiccheck()\", m->type);\n\t\treturn -1;\n\t}\n\n\tv = file_signextend(ms, m, v);\n\n\tswitch (m->reln) {\n\tcase 'x':\n\t\tif ((ms->flags & MAGIC_DEBUG) != 0)\n\t\t\t(void) fprintf(stderr, \"%\" INT64_T_FORMAT\n\t\t\t    \"u == *any* = 1\\n\", (unsigned long long)v);\n\t\tmatched = 1;\n\t\tbreak;\n\n\tcase '!':\n\t\tmatched = v != l;\n\t\tif ((ms->flags & MAGIC_DEBUG) != 0)\n\t\t\t(void) fprintf(stderr, \"%\" INT64_T_FORMAT \"u != %\"\n\t\t\t    INT64_T_FORMAT \"u = %d\\n\", (unsigned long long)v,\n\t\t\t    (unsigned long long)l, matched);\n\t\tbreak;\n\n\tcase '=':\n\t\tmatched = v == l;\n\t\tif ((ms->flags & MAGIC_DEBUG) != 0)\n\t\t\t(void) fprintf(stderr, \"%\" INT64_T_FORMAT \"u == %\"\n\t\t\t    INT64_T_FORMAT \"u = %d\\n\", (unsigned long long)v,\n\t\t\t    (unsigned long long)l, matched);\n\t\tbreak;\n\n\tcase '>':\n\t\tif (m->flag & UNSIGNED) {\n\t\t\tmatched = v > l;\n\t\t\tif ((ms->flags & MAGIC_DEBUG) != 0)\n\t\t\t\t(void) fprintf(stderr, \"%\" INT64_T_FORMAT\n\t\t\t\t    \"u > %\" INT64_T_FORMAT \"u = %d\\n\",\n\t\t\t\t    (unsigned long long)v,\n\t\t\t\t    (unsigned long long)l, matched);\n\t\t}\n\t\telse {\n\t\t\tmatched = (int64_t) v > (int64_t) l;\n\t\t\tif ((ms->flags & MAGIC_DEBUG) != 0)\n\t\t\t\t(void) fprintf(stderr, \"%\" INT64_T_FORMAT\n\t\t\t\t    \"d > %\" INT64_T_FORMAT \"d = %d\\n\",\n\t\t\t\t    (long long)v, (long long)l, matched);\n\t\t}\n\t\tbreak;\n\n\tcase '<':\n\t\tif (m->flag & UNSIGNED) {\n\t\t\tmatched = v < l;\n\t\t\tif ((ms->flags & MAGIC_DEBUG) != 0)\n\t\t\t\t(void) fprintf(stderr, \"%\" INT64_T_FORMAT\n\t\t\t\t    \"u < %\" INT64_T_FORMAT \"u = %d\\n\",\n\t\t\t\t    (unsigned long long)v,\n\t\t\t\t    (unsigned long long)l, matched);\n\t\t}\n\t\telse {\n\t\t\tmatched = (int64_t) v < (int64_t) l;\n\t\t\tif ((ms->flags & MAGIC_DEBUG) != 0)\n\t\t\t\t(void) fprintf(stderr, \"%\" INT64_T_FORMAT\n\t\t\t\t    \"d < %\" INT64_T_FORMAT \"d = %d\\n\",\n\t\t\t\t     (long long)v, (long long)l, matched);\n\t\t}\n\t\tbreak;\n\n\tcase '&':\n\t\tmatched = (v & l) == l;\n\t\tif ((ms->flags & MAGIC_DEBUG) != 0)\n\t\t\t(void) fprintf(stderr, \"((%\" INT64_T_FORMAT \"x & %\"\n\t\t\t    INT64_T_FORMAT \"x) == %\" INT64_T_FORMAT\n\t\t\t    \"x) = %d\\n\", (unsigned long long)v,\n\t\t\t    (unsigned long long)l, (unsigned long long)l,\n\t\t\t    matched);\n\t\tbreak;\n\n\tcase '^':\n\t\tmatched = (v & l) != l;\n\t\tif ((ms->flags & MAGIC_DEBUG) != 0)\n\t\t\t(void) fprintf(stderr, \"((%\" INT64_T_FORMAT \"x & %\"\n\t\t\t    INT64_T_FORMAT \"x) != %\" INT64_T_FORMAT\n\t\t\t    \"x) = %d\\n\", (unsigned long long)v,\n\t\t\t    (unsigned long long)l, (unsigned long long)l,\n\t\t\t    matched);\n\t\tbreak;\n\n\tdefault:\n\t\tfile_magerror(ms, \"cannot happen: invalid relation `%c'\",\n\t\t    m->reln);\n\t\treturn -1;\n\t}\n\n\treturn matched;\n}",
        "func": "private int\nmagiccheck(struct magic_set *ms, struct magic *m)\n{\n\tuint64_t l = m->value.q;\n\tuint64_t v;\n\tfloat fl, fv;\n\tdouble dl, dv;\n\tint matched;\n\tunion VALUETYPE *p = &ms->ms_value;\n\n\tswitch (m->type) {\n\tcase FILE_BYTE:\n\t\tv = p->b;\n\t\tbreak;\n\n\tcase FILE_SHORT:\n\tcase FILE_BESHORT:\n\tcase FILE_LESHORT:\n\t\tv = p->h;\n\t\tbreak;\n\n\tcase FILE_LONG:\n\tcase FILE_BELONG:\n\tcase FILE_LELONG:\n\tcase FILE_MELONG:\n\tcase FILE_DATE:\n\tcase FILE_BEDATE:\n\tcase FILE_LEDATE:\n\tcase FILE_MEDATE:\n\tcase FILE_LDATE:\n\tcase FILE_BELDATE:\n\tcase FILE_LELDATE:\n\tcase FILE_MELDATE:\n\t\tv = p->l;\n\t\tbreak;\n\n\tcase FILE_QUAD:\n\tcase FILE_LEQUAD:\n\tcase FILE_BEQUAD:\n\tcase FILE_QDATE:\n\tcase FILE_BEQDATE:\n\tcase FILE_LEQDATE:\n\tcase FILE_QLDATE:\n\tcase FILE_BEQLDATE:\n\tcase FILE_LEQLDATE:\n\tcase FILE_QWDATE:\n\tcase FILE_BEQWDATE:\n\tcase FILE_LEQWDATE:\n\t\tv = p->q;\n\t\tbreak;\n\n\tcase FILE_FLOAT:\n\tcase FILE_BEFLOAT:\n\tcase FILE_LEFLOAT:\n\t\tfl = m->value.f;\n\t\tfv = p->f;\n\t\tswitch (m->reln) {\n\t\tcase 'x':\n\t\t\tmatched = 1;\n\t\t\tbreak;\n\n\t\tcase '!':\n\t\t\tmatched = fv != fl;\n\t\t\tbreak;\n\n\t\tcase '=':\n\t\t\tmatched = fv == fl;\n\t\t\tbreak;\n\n\t\tcase '>':\n\t\t\tmatched = fv > fl;\n\t\t\tbreak;\n\n\t\tcase '<':\n\t\t\tmatched = fv < fl;\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tfile_magerror(ms, \"cannot happen with float: invalid relation `%c'\",\n\t\t\t    m->reln);\n\t\t\treturn -1;\n\t\t}\n\t\treturn matched;\n\n\tcase FILE_DOUBLE:\n\tcase FILE_BEDOUBLE:\n\tcase FILE_LEDOUBLE:\n\t\tdl = m->value.d;\n\t\tdv = p->d;\n\t\tswitch (m->reln) {\n\t\tcase 'x':\n\t\t\tmatched = 1;\n\t\t\tbreak;\n\n\t\tcase '!':\n\t\t\tmatched = dv != dl;\n\t\t\tbreak;\n\n\t\tcase '=':\n\t\t\tmatched = dv == dl;\n\t\t\tbreak;\n\n\t\tcase '>':\n\t\t\tmatched = dv > dl;\n\t\t\tbreak;\n\n\t\tcase '<':\n\t\t\tmatched = dv < dl;\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tfile_magerror(ms, \"cannot happen with double: invalid relation `%c'\", m->reln);\n\t\t\treturn -1;\n\t\t}\n\t\treturn matched;\n\n\tcase FILE_DEFAULT:\n\tcase FILE_CLEAR:\n\t\tl = 0;\n\t\tv = 0;\n\t\tbreak;\n\n\tcase FILE_STRING:\n\tcase FILE_PSTRING:\n\t\tl = 0;\n\t\tv = file_strncmp(m->value.s, p->s, (size_t)m->vallen, m->str_flags);\n\t\tbreak;\n\n\tcase FILE_BESTRING16:\n\tcase FILE_LESTRING16:\n\t\tl = 0;\n\t\tv = file_strncmp16(m->value.s, p->s, (size_t)m->vallen, m->str_flags);\n\t\tbreak;\n\n\tcase FILE_SEARCH: { /* search ms->search.s for the string m->value.s */\n\t\tsize_t slen;\n\t\tsize_t idx;\n\n\t\tif (ms->search.s == NULL)\n\t\t\treturn 0;\n\n\t\tslen = MIN(m->vallen, sizeof(m->value.s));\n\t\tl = 0;\n\t\tv = 0;\n\n\t\tfor (idx = 0; m->str_range == 0 || idx < m->str_range; idx++) {\n\t\t\tif (slen + idx > ms->search.s_len)\n\t\t\t\tbreak;\n\n\t\t\tv = file_strncmp(m->value.s, ms->search.s + idx, slen, m->str_flags);\n\t\t\tif (v == 0) {\t/* found match */\n\t\t\t\tms->search.offset += idx;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tbreak;\n\t}\n\tcase FILE_REGEX: {\n\t\tint rc;\n\t\tfile_regex_t rx;\n\n\t\tif (ms->search.s == NULL)\n\t\t\treturn 0;\n\n\t\tl = 0;\n\t\trc = file_regcomp(&rx, m->value.s,\n\t\t    REG_EXTENDED|REG_NEWLINE|\n\t\t    ((m->str_flags & STRING_IGNORE_CASE) ? REG_ICASE : 0));\n\t\tif (rc) {\n\t\t\tfile_regerror(&rx, rc, ms);\n\t\t\tv = (uint64_t)-1;\n\t\t} else {\n#ifndef REG_STARTEND\n\t\t\tchar c;\n#endif\n\t\t\tregmatch_t pmatch[1];\n\t\t\tsize_t slen = ms->search.s_len;\n\t\t\t/* Limit by offset if requested */\n\t\t\tif (m->str_range > 0)\n\t\t\t\tslen = MIN(slen, m->str_range);\n#ifndef REG_STARTEND\n#define\tREG_STARTEND\t0\n\t\t\tif (slen != 0)\n\t\t\t\tslen--;\n\t\t\tc = ms->search.s[slen];\n\t\t\t((char *)(intptr_t)ms->search.s)[slen] = '\\0';\n#else\n\t\t\tpmatch[0].rm_so = 0;\n\t\t\tpmatch[0].rm_eo = slen;\n#endif\n\t\t\trc = file_regexec(&rx, (const char *)ms->search.s,\n\t\t\t    1, pmatch, REG_STARTEND);\n#if REG_STARTEND == 0\n\t\t\t((char *)(intptr_t)ms->search.s)[l] = c;\n#endif\n\t\t\tswitch (rc) {\n\t\t\tcase 0:\n\t\t\t\tms->search.s += (int)pmatch[0].rm_so;\n\t\t\t\tms->search.offset += (size_t)pmatch[0].rm_so;\n\t\t\t\tms->search.rm_len =\n\t\t\t\t    (size_t)(pmatch[0].rm_eo - pmatch[0].rm_so);\n\t\t\t\tv = 0;\n\t\t\t\tbreak;\n\n\t\t\tcase REG_NOMATCH:\n\t\t\t\tv = 1;\n\t\t\t\tbreak;\n\n\t\t\tdefault:\n\t\t\t\tfile_regerror(&rx, rc, ms);\n\t\t\t\tv = (uint64_t)-1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tfile_regfree(&rx);\n\t\tif (v == (uint64_t)-1)\n\t\t\treturn -1;\n\t\tbreak;\n\t}\n\tcase FILE_INDIRECT:\n\tcase FILE_USE:\n\tcase FILE_NAME:\n\t\treturn 1;\n\tdefault:\n\t\tfile_magerror(ms, \"invalid type %d in magiccheck()\", m->type);\n\t\treturn -1;\n\t}\n\n\tv = file_signextend(ms, m, v);\n\n\tswitch (m->reln) {\n\tcase 'x':\n\t\tif ((ms->flags & MAGIC_DEBUG) != 0)\n\t\t\t(void) fprintf(stderr, \"%\" INT64_T_FORMAT\n\t\t\t    \"u == *any* = 1\\n\", (unsigned long long)v);\n\t\tmatched = 1;\n\t\tbreak;\n\n\tcase '!':\n\t\tmatched = v != l;\n\t\tif ((ms->flags & MAGIC_DEBUG) != 0)\n\t\t\t(void) fprintf(stderr, \"%\" INT64_T_FORMAT \"u != %\"\n\t\t\t    INT64_T_FORMAT \"u = %d\\n\", (unsigned long long)v,\n\t\t\t    (unsigned long long)l, matched);\n\t\tbreak;\n\n\tcase '=':\n\t\tmatched = v == l;\n\t\tif ((ms->flags & MAGIC_DEBUG) != 0)\n\t\t\t(void) fprintf(stderr, \"%\" INT64_T_FORMAT \"u == %\"\n\t\t\t    INT64_T_FORMAT \"u = %d\\n\", (unsigned long long)v,\n\t\t\t    (unsigned long long)l, matched);\n\t\tbreak;\n\n\tcase '>':\n\t\tif (m->flag & UNSIGNED) {\n\t\t\tmatched = v > l;\n\t\t\tif ((ms->flags & MAGIC_DEBUG) != 0)\n\t\t\t\t(void) fprintf(stderr, \"%\" INT64_T_FORMAT\n\t\t\t\t    \"u > %\" INT64_T_FORMAT \"u = %d\\n\",\n\t\t\t\t    (unsigned long long)v,\n\t\t\t\t    (unsigned long long)l, matched);\n\t\t}\n\t\telse {\n\t\t\tmatched = (int64_t) v > (int64_t) l;\n\t\t\tif ((ms->flags & MAGIC_DEBUG) != 0)\n\t\t\t\t(void) fprintf(stderr, \"%\" INT64_T_FORMAT\n\t\t\t\t    \"d > %\" INT64_T_FORMAT \"d = %d\\n\",\n\t\t\t\t    (long long)v, (long long)l, matched);\n\t\t}\n\t\tbreak;\n\n\tcase '<':\n\t\tif (m->flag & UNSIGNED) {\n\t\t\tmatched = v < l;\n\t\t\tif ((ms->flags & MAGIC_DEBUG) != 0)\n\t\t\t\t(void) fprintf(stderr, \"%\" INT64_T_FORMAT\n\t\t\t\t    \"u < %\" INT64_T_FORMAT \"u = %d\\n\",\n\t\t\t\t    (unsigned long long)v,\n\t\t\t\t    (unsigned long long)l, matched);\n\t\t}\n\t\telse {\n\t\t\tmatched = (int64_t) v < (int64_t) l;\n\t\t\tif ((ms->flags & MAGIC_DEBUG) != 0)\n\t\t\t\t(void) fprintf(stderr, \"%\" INT64_T_FORMAT\n\t\t\t\t    \"d < %\" INT64_T_FORMAT \"d = %d\\n\",\n\t\t\t\t     (long long)v, (long long)l, matched);\n\t\t}\n\t\tbreak;\n\n\tcase '&':\n\t\tmatched = (v & l) == l;\n\t\tif ((ms->flags & MAGIC_DEBUG) != 0)\n\t\t\t(void) fprintf(stderr, \"((%\" INT64_T_FORMAT \"x & %\"\n\t\t\t    INT64_T_FORMAT \"x) == %\" INT64_T_FORMAT\n\t\t\t    \"x) = %d\\n\", (unsigned long long)v,\n\t\t\t    (unsigned long long)l, (unsigned long long)l,\n\t\t\t    matched);\n\t\tbreak;\n\n\tcase '^':\n\t\tmatched = (v & l) != l;\n\t\tif ((ms->flags & MAGIC_DEBUG) != 0)\n\t\t\t(void) fprintf(stderr, \"((%\" INT64_T_FORMAT \"x & %\"\n\t\t\t    INT64_T_FORMAT \"x) != %\" INT64_T_FORMAT\n\t\t\t    \"x) = %d\\n\", (unsigned long long)v,\n\t\t\t    (unsigned long long)l, (unsigned long long)l,\n\t\t\t    matched);\n\t\tbreak;\n\n\tdefault:\n\t\tfile_magerror(ms, \"cannot happen: invalid relation `%c'\",\n\t\t    m->reln);\n\t\treturn -1;\n\t}\n\n\treturn matched;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -170,15 +170,23 @@\n \t\t\tfile_regerror(&rx, rc, ms);\n \t\t\tv = (uint64_t)-1;\n \t\t} else {\n+#ifndef REG_STARTEND\n+\t\t\tchar c;\n+#endif\n \t\t\tregmatch_t pmatch[1];\n+\t\t\tsize_t slen = ms->search.s_len;\n+\t\t\t/* Limit by offset if requested */\n+\t\t\tif (m->str_range > 0)\n+\t\t\t\tslen = MIN(slen, m->str_range);\n #ifndef REG_STARTEND\n #define\tREG_STARTEND\t0\n-\t\t\tsize_t l = ms->search.s_len - 1;\n-\t\t\tchar c = ms->search.s[l];\n-\t\t\t((char *)(intptr_t)ms->search.s)[l] = '\\0';\n+\t\t\tif (slen != 0)\n+\t\t\t\tslen--;\n+\t\t\tc = ms->search.s[slen];\n+\t\t\t((char *)(intptr_t)ms->search.s)[slen] = '\\0';\n #else\n \t\t\tpmatch[0].rm_so = 0;\n-\t\t\tpmatch[0].rm_eo = ms->search.s_len;\n+\t\t\tpmatch[0].rm_eo = slen;\n #endif\n \t\t\trc = file_regexec(&rx, (const char *)ms->search.s,\n \t\t\t    1, pmatch, REG_STARTEND);",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\tsize_t l = ms->search.s_len - 1;",
                "\t\t\tchar c = ms->search.s[l];",
                "\t\t\t((char *)(intptr_t)ms->search.s)[l] = '\\0';",
                "\t\t\tpmatch[0].rm_eo = ms->search.s_len;"
            ],
            "added_lines": [
                "#ifndef REG_STARTEND",
                "\t\t\tchar c;",
                "#endif",
                "\t\t\tsize_t slen = ms->search.s_len;",
                "\t\t\t/* Limit by offset if requested */",
                "\t\t\tif (m->str_range > 0)",
                "\t\t\t\tslen = MIN(slen, m->str_range);",
                "\t\t\tif (slen != 0)",
                "\t\t\t\tslen--;",
                "\t\t\tc = ms->search.s[slen];",
                "\t\t\t((char *)(intptr_t)ms->search.s)[slen] = '\\0';",
                "\t\t\tpmatch[0].rm_eo = slen;"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-0798",
        "func_name": "openssl/init_ssl_connection",
        "description": "Memory leak in the SRP_VBASE_get_by_user implementation in OpenSSL 1.0.1 before 1.0.1s and 1.0.2 before 1.0.2g allows remote attackers to cause a denial of service (memory consumption) by providing an invalid username in a connection attempt, related to apps/s_server.c and crypto/srp/srp_vfy.c.",
        "git_url": "https://git.openssl.org/?p=openssl.git;a=commit;h=259b664f950c2ba66fbf4b0fe5281327904ead21",
        "commit_title": "",
        "commit_text": "CVE-2016-0798: avoid memory leak in SRP  The SRP user database lookup method SRP_VBASE_get_by_user had confusing memory management semantics; the returned pointer was sometimes newly allocated, and sometimes owned by the callee. The calling code has no way of distinguishing these two cases.  Specifically, SRP servers that configure a secret seed to hide valid login information are vulnerable to a memory leak: an attacker connecting with an invalid username can cause a memory leak of around 300 bytes per connection.  Servers that do not configure SRP, or configure SRP but do not configure a seed are not vulnerable.  In Apache, the seed directive is known as SSLSRPUnknownUserSeed.  To mitigate the memory leak, the seed handling in SRP_VBASE_get_by_user is now disabled even if the user has configured a seed.  Applications are advised to migrate to SRP_VBASE_get1_by_user. However, note that OpenSSL makes no strong guarantees about the indistinguishability of valid and invalid logins. In particular, computations are currently not carried out in constant time.  ",
        "func_before": "static int init_ssl_connection(SSL *con)\n{\n    int i;\n    const char *str;\n    X509 *peer;\n    long verify_error;\n    MS_STATIC char buf[BUFSIZ];\n#ifndef OPENSSL_NO_KRB5\n    char *client_princ;\n#endif\n#if !defined(OPENSSL_NO_TLSEXT) && !defined(OPENSSL_NO_NEXTPROTONEG)\n    const unsigned char *next_proto_neg;\n    unsigned next_proto_neg_len;\n#endif\n    unsigned char *exportedkeymat;\n\n    i = SSL_accept(con);\n#ifdef CERT_CB_TEST_RETRY\n    {\n        while (i <= 0 && SSL_get_error(con, i) == SSL_ERROR_WANT_X509_LOOKUP\n               && SSL_state(con) == SSL3_ST_SR_CLNT_HELLO_C) {\n            fprintf(stderr,\n                    \"LOOKUP from certificate callback during accept\\n\");\n            i = SSL_accept(con);\n        }\n    }\n#endif\n#ifndef OPENSSL_NO_SRP\n    while (i <= 0 && SSL_get_error(con, i) == SSL_ERROR_WANT_X509_LOOKUP) {\n        BIO_printf(bio_s_out, \"LOOKUP during accept %s\\n\",\n                   srp_callback_parm.login);\n        srp_callback_parm.user =\n            SRP_VBASE_get_by_user(srp_callback_parm.vb,\n                                  srp_callback_parm.login);\n        if (srp_callback_parm.user)\n            BIO_printf(bio_s_out, \"LOOKUP done %s\\n\",\n                       srp_callback_parm.user->info);\n        else\n            BIO_printf(bio_s_out, \"LOOKUP not successful\\n\");\n        i = SSL_accept(con);\n    }\n#endif\n\n    if (i <= 0) {\n        if (BIO_sock_should_retry(i)) {\n            BIO_printf(bio_s_out, \"DELAY\\n\");\n            return (1);\n        }\n\n        BIO_printf(bio_err, \"ERROR\\n\");\n        verify_error = SSL_get_verify_result(con);\n        if (verify_error != X509_V_OK) {\n            BIO_printf(bio_err, \"verify error:%s\\n\",\n                       X509_verify_cert_error_string(verify_error));\n        }\n        /* Always print any error messages */\n        ERR_print_errors(bio_err);\n        return (0);\n    }\n\n    if (s_brief)\n        print_ssl_summary(bio_err, con);\n\n    PEM_write_bio_SSL_SESSION(bio_s_out, SSL_get_session(con));\n\n    peer = SSL_get_peer_certificate(con);\n    if (peer != NULL) {\n        BIO_printf(bio_s_out, \"Client certificate\\n\");\n        PEM_write_bio_X509(bio_s_out, peer);\n        X509_NAME_oneline(X509_get_subject_name(peer), buf, sizeof buf);\n        BIO_printf(bio_s_out, \"subject=%s\\n\", buf);\n        X509_NAME_oneline(X509_get_issuer_name(peer), buf, sizeof buf);\n        BIO_printf(bio_s_out, \"issuer=%s\\n\", buf);\n        X509_free(peer);\n    }\n\n    if (SSL_get_shared_ciphers(con, buf, sizeof buf) != NULL)\n        BIO_printf(bio_s_out, \"Shared ciphers:%s\\n\", buf);\n    str = SSL_CIPHER_get_name(SSL_get_current_cipher(con));\n    ssl_print_sigalgs(bio_s_out, con);\n#ifndef OPENSSL_NO_EC\n    ssl_print_point_formats(bio_s_out, con);\n    ssl_print_curves(bio_s_out, con, 0);\n#endif\n    BIO_printf(bio_s_out, \"CIPHER is %s\\n\", (str != NULL) ? str : \"(NONE)\");\n\n#if !defined(OPENSSL_NO_TLSEXT) && !defined(OPENSSL_NO_NEXTPROTONEG)\n    SSL_get0_next_proto_negotiated(con, &next_proto_neg, &next_proto_neg_len);\n    if (next_proto_neg) {\n        BIO_printf(bio_s_out, \"NEXTPROTO is \");\n        BIO_write(bio_s_out, next_proto_neg, next_proto_neg_len);\n        BIO_printf(bio_s_out, \"\\n\");\n    }\n#endif\n#ifndef OPENSSL_NO_SRTP\n    {\n        SRTP_PROTECTION_PROFILE *srtp_profile\n            = SSL_get_selected_srtp_profile(con);\n\n        if (srtp_profile)\n            BIO_printf(bio_s_out, \"SRTP Extension negotiated, profile=%s\\n\",\n                       srtp_profile->name);\n    }\n#endif\n    if (SSL_cache_hit(con))\n        BIO_printf(bio_s_out, \"Reused session-id\\n\");\n    if (SSL_ctrl(con, SSL_CTRL_GET_FLAGS, 0, NULL) &\n        TLS1_FLAGS_TLS_PADDING_BUG)\n        BIO_printf(bio_s_out, \"Peer has incorrect TLSv1 block padding\\n\");\n#ifndef OPENSSL_NO_KRB5\n    client_princ = kssl_ctx_get0_client_princ(SSL_get0_kssl_ctx(con));\n    if (client_princ != NULL) {\n        BIO_printf(bio_s_out, \"Kerberos peer principal is %s\\n\",\n                   client_princ);\n    }\n#endif                          /* OPENSSL_NO_KRB5 */\n    BIO_printf(bio_s_out, \"Secure Renegotiation IS%s supported\\n\",\n               SSL_get_secure_renegotiation_support(con) ? \"\" : \" NOT\");\n    if (keymatexportlabel != NULL) {\n        BIO_printf(bio_s_out, \"Keying material exporter:\\n\");\n        BIO_printf(bio_s_out, \"    Label: '%s'\\n\", keymatexportlabel);\n        BIO_printf(bio_s_out, \"    Length: %i bytes\\n\", keymatexportlen);\n        exportedkeymat = OPENSSL_malloc(keymatexportlen);\n        if (exportedkeymat != NULL) {\n            if (!SSL_export_keying_material(con, exportedkeymat,\n                                            keymatexportlen,\n                                            keymatexportlabel,\n                                            strlen(keymatexportlabel),\n                                            NULL, 0, 0)) {\n                BIO_printf(bio_s_out, \"    Error\\n\");\n            } else {\n                BIO_printf(bio_s_out, \"    Keying material: \");\n                for (i = 0; i < keymatexportlen; i++)\n                    BIO_printf(bio_s_out, \"%02X\", exportedkeymat[i]);\n                BIO_printf(bio_s_out, \"\\n\");\n            }\n            OPENSSL_free(exportedkeymat);\n        }\n    }\n\n    return (1);\n}",
        "func": "static int init_ssl_connection(SSL *con)\n{\n    int i;\n    const char *str;\n    X509 *peer;\n    long verify_error;\n    MS_STATIC char buf[BUFSIZ];\n#ifndef OPENSSL_NO_KRB5\n    char *client_princ;\n#endif\n#if !defined(OPENSSL_NO_TLSEXT) && !defined(OPENSSL_NO_NEXTPROTONEG)\n    const unsigned char *next_proto_neg;\n    unsigned next_proto_neg_len;\n#endif\n    unsigned char *exportedkeymat;\n\n    i = SSL_accept(con);\n#ifdef CERT_CB_TEST_RETRY\n    {\n        while (i <= 0 && SSL_get_error(con, i) == SSL_ERROR_WANT_X509_LOOKUP\n               && SSL_state(con) == SSL3_ST_SR_CLNT_HELLO_C) {\n            fprintf(stderr,\n                    \"LOOKUP from certificate callback during accept\\n\");\n            i = SSL_accept(con);\n        }\n    }\n#endif\n#ifndef OPENSSL_NO_SRP\n    while (i <= 0 && SSL_get_error(con, i) == SSL_ERROR_WANT_X509_LOOKUP) {\n        BIO_printf(bio_s_out, \"LOOKUP during accept %s\\n\",\n                   srp_callback_parm.login);\n        SRP_user_pwd_free(srp_callback_parm.user);\n        srp_callback_parm.user =\n            SRP_VBASE_get1_by_user(srp_callback_parm.vb,\n                                   srp_callback_parm.login);\n        if (srp_callback_parm.user)\n            BIO_printf(bio_s_out, \"LOOKUP done %s\\n\",\n                       srp_callback_parm.user->info);\n        else\n            BIO_printf(bio_s_out, \"LOOKUP not successful\\n\");\n        i = SSL_accept(con);\n    }\n#endif\n\n    if (i <= 0) {\n        if (BIO_sock_should_retry(i)) {\n            BIO_printf(bio_s_out, \"DELAY\\n\");\n            return (1);\n        }\n\n        BIO_printf(bio_err, \"ERROR\\n\");\n        verify_error = SSL_get_verify_result(con);\n        if (verify_error != X509_V_OK) {\n            BIO_printf(bio_err, \"verify error:%s\\n\",\n                       X509_verify_cert_error_string(verify_error));\n        }\n        /* Always print any error messages */\n        ERR_print_errors(bio_err);\n        return (0);\n    }\n\n    if (s_brief)\n        print_ssl_summary(bio_err, con);\n\n    PEM_write_bio_SSL_SESSION(bio_s_out, SSL_get_session(con));\n\n    peer = SSL_get_peer_certificate(con);\n    if (peer != NULL) {\n        BIO_printf(bio_s_out, \"Client certificate\\n\");\n        PEM_write_bio_X509(bio_s_out, peer);\n        X509_NAME_oneline(X509_get_subject_name(peer), buf, sizeof buf);\n        BIO_printf(bio_s_out, \"subject=%s\\n\", buf);\n        X509_NAME_oneline(X509_get_issuer_name(peer), buf, sizeof buf);\n        BIO_printf(bio_s_out, \"issuer=%s\\n\", buf);\n        X509_free(peer);\n    }\n\n    if (SSL_get_shared_ciphers(con, buf, sizeof buf) != NULL)\n        BIO_printf(bio_s_out, \"Shared ciphers:%s\\n\", buf);\n    str = SSL_CIPHER_get_name(SSL_get_current_cipher(con));\n    ssl_print_sigalgs(bio_s_out, con);\n#ifndef OPENSSL_NO_EC\n    ssl_print_point_formats(bio_s_out, con);\n    ssl_print_curves(bio_s_out, con, 0);\n#endif\n    BIO_printf(bio_s_out, \"CIPHER is %s\\n\", (str != NULL) ? str : \"(NONE)\");\n\n#if !defined(OPENSSL_NO_TLSEXT) && !defined(OPENSSL_NO_NEXTPROTONEG)\n    SSL_get0_next_proto_negotiated(con, &next_proto_neg, &next_proto_neg_len);\n    if (next_proto_neg) {\n        BIO_printf(bio_s_out, \"NEXTPROTO is \");\n        BIO_write(bio_s_out, next_proto_neg, next_proto_neg_len);\n        BIO_printf(bio_s_out, \"\\n\");\n    }\n#endif\n#ifndef OPENSSL_NO_SRTP\n    {\n        SRTP_PROTECTION_PROFILE *srtp_profile\n            = SSL_get_selected_srtp_profile(con);\n\n        if (srtp_profile)\n            BIO_printf(bio_s_out, \"SRTP Extension negotiated, profile=%s\\n\",\n                       srtp_profile->name);\n    }\n#endif\n    if (SSL_cache_hit(con))\n        BIO_printf(bio_s_out, \"Reused session-id\\n\");\n    if (SSL_ctrl(con, SSL_CTRL_GET_FLAGS, 0, NULL) &\n        TLS1_FLAGS_TLS_PADDING_BUG)\n        BIO_printf(bio_s_out, \"Peer has incorrect TLSv1 block padding\\n\");\n#ifndef OPENSSL_NO_KRB5\n    client_princ = kssl_ctx_get0_client_princ(SSL_get0_kssl_ctx(con));\n    if (client_princ != NULL) {\n        BIO_printf(bio_s_out, \"Kerberos peer principal is %s\\n\",\n                   client_princ);\n    }\n#endif                          /* OPENSSL_NO_KRB5 */\n    BIO_printf(bio_s_out, \"Secure Renegotiation IS%s supported\\n\",\n               SSL_get_secure_renegotiation_support(con) ? \"\" : \" NOT\");\n    if (keymatexportlabel != NULL) {\n        BIO_printf(bio_s_out, \"Keying material exporter:\\n\");\n        BIO_printf(bio_s_out, \"    Label: '%s'\\n\", keymatexportlabel);\n        BIO_printf(bio_s_out, \"    Length: %i bytes\\n\", keymatexportlen);\n        exportedkeymat = OPENSSL_malloc(keymatexportlen);\n        if (exportedkeymat != NULL) {\n            if (!SSL_export_keying_material(con, exportedkeymat,\n                                            keymatexportlen,\n                                            keymatexportlabel,\n                                            strlen(keymatexportlabel),\n                                            NULL, 0, 0)) {\n                BIO_printf(bio_s_out, \"    Error\\n\");\n            } else {\n                BIO_printf(bio_s_out, \"    Keying material: \");\n                for (i = 0; i < keymatexportlen; i++)\n                    BIO_printf(bio_s_out, \"%02X\", exportedkeymat[i]);\n                BIO_printf(bio_s_out, \"\\n\");\n            }\n            OPENSSL_free(exportedkeymat);\n        }\n    }\n\n    return (1);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -29,9 +29,10 @@\n     while (i <= 0 && SSL_get_error(con, i) == SSL_ERROR_WANT_X509_LOOKUP) {\n         BIO_printf(bio_s_out, \"LOOKUP during accept %s\\n\",\n                    srp_callback_parm.login);\n+        SRP_user_pwd_free(srp_callback_parm.user);\n         srp_callback_parm.user =\n-            SRP_VBASE_get_by_user(srp_callback_parm.vb,\n-                                  srp_callback_parm.login);\n+            SRP_VBASE_get1_by_user(srp_callback_parm.vb,\n+                                   srp_callback_parm.login);\n         if (srp_callback_parm.user)\n             BIO_printf(bio_s_out, \"LOOKUP done %s\\n\",\n                        srp_callback_parm.user->info);",
        "diff_line_info": {
            "deleted_lines": [
                "            SRP_VBASE_get_by_user(srp_callback_parm.vb,",
                "                                  srp_callback_parm.login);"
            ],
            "added_lines": [
                "        SRP_user_pwd_free(srp_callback_parm.user);",
                "            SRP_VBASE_get1_by_user(srp_callback_parm.vb,",
                "                                   srp_callback_parm.login);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-0798",
        "func_name": "openssl/www_body",
        "description": "Memory leak in the SRP_VBASE_get_by_user implementation in OpenSSL 1.0.1 before 1.0.1s and 1.0.2 before 1.0.2g allows remote attackers to cause a denial of service (memory consumption) by providing an invalid username in a connection attempt, related to apps/s_server.c and crypto/srp/srp_vfy.c.",
        "git_url": "https://git.openssl.org/?p=openssl.git;a=commit;h=259b664f950c2ba66fbf4b0fe5281327904ead21",
        "commit_title": "",
        "commit_text": "CVE-2016-0798: avoid memory leak in SRP  The SRP user database lookup method SRP_VBASE_get_by_user had confusing memory management semantics; the returned pointer was sometimes newly allocated, and sometimes owned by the callee. The calling code has no way of distinguishing these two cases.  Specifically, SRP servers that configure a secret seed to hide valid login information are vulnerable to a memory leak: an attacker connecting with an invalid username can cause a memory leak of around 300 bytes per connection.  Servers that do not configure SRP, or configure SRP but do not configure a seed are not vulnerable.  In Apache, the seed directive is known as SSLSRPUnknownUserSeed.  To mitigate the memory leak, the seed handling in SRP_VBASE_get_by_user is now disabled even if the user has configured a seed.  Applications are advised to migrate to SRP_VBASE_get1_by_user. However, note that OpenSSL makes no strong guarantees about the indistinguishability of valid and invalid logins. In particular, computations are currently not carried out in constant time.  ",
        "func_before": "static int www_body(char *hostname, int s, int stype, unsigned char *context)\n{\n    char *buf = NULL;\n    int ret = 1;\n    int i, j, k, dot;\n    SSL *con;\n    const SSL_CIPHER *c;\n    BIO *io, *ssl_bio, *sbio;\n#ifndef OPENSSL_NO_KRB5\n    KSSL_CTX *kctx;\n#endif\n\n    buf = OPENSSL_malloc(bufsize);\n    if (buf == NULL)\n        return (0);\n    io = BIO_new(BIO_f_buffer());\n    ssl_bio = BIO_new(BIO_f_ssl());\n    if ((io == NULL) || (ssl_bio == NULL))\n        goto err;\n\n#ifdef FIONBIO\n    if (s_nbio) {\n        unsigned long sl = 1;\n\n        if (!s_quiet)\n            BIO_printf(bio_err, \"turning on non blocking io\\n\");\n        if (BIO_socket_ioctl(s, FIONBIO, &sl) < 0)\n            ERR_print_errors(bio_err);\n    }\n#endif\n\n    /* lets make the output buffer a reasonable size */\n    if (!BIO_set_write_buffer_size(io, bufsize))\n        goto err;\n\n    if ((con = SSL_new(ctx)) == NULL)\n        goto err;\n#ifndef OPENSSL_NO_TLSEXT\n    if (s_tlsextdebug) {\n        SSL_set_tlsext_debug_callback(con, tlsext_cb);\n        SSL_set_tlsext_debug_arg(con, bio_s_out);\n    }\n#endif\n#ifndef OPENSSL_NO_KRB5\n    if ((kctx = kssl_ctx_new()) != NULL) {\n        kssl_ctx_setstring(kctx, KSSL_SERVICE, KRB5SVC);\n        kssl_ctx_setstring(kctx, KSSL_KEYTAB, KRB5KEYTAB);\n    }\n#endif                          /* OPENSSL_NO_KRB5 */\n    if (context)\n        SSL_set_session_id_context(con, context, strlen((char *)context));\n\n    sbio = BIO_new_socket(s, BIO_NOCLOSE);\n    if (s_nbio_test) {\n        BIO *test;\n\n        test = BIO_new(BIO_f_nbio_test());\n        sbio = BIO_push(test, sbio);\n    }\n    SSL_set_bio(con, sbio, sbio);\n    SSL_set_accept_state(con);\n\n    /* SSL_set_fd(con,s); */\n    BIO_set_ssl(ssl_bio, con, BIO_CLOSE);\n    BIO_push(io, ssl_bio);\n#ifdef CHARSET_EBCDIC\n    io = BIO_push(BIO_new(BIO_f_ebcdic_filter()), io);\n#endif\n\n    if (s_debug) {\n        SSL_set_debug(con, 1);\n        BIO_set_callback(SSL_get_rbio(con), bio_dump_callback);\n        BIO_set_callback_arg(SSL_get_rbio(con), (char *)bio_s_out);\n    }\n    if (s_msg) {\n#ifndef OPENSSL_NO_SSL_TRACE\n        if (s_msg == 2)\n            SSL_set_msg_callback(con, SSL_trace);\n        else\n#endif\n            SSL_set_msg_callback(con, msg_cb);\n        SSL_set_msg_callback_arg(con, bio_s_msg ? bio_s_msg : bio_s_out);\n    }\n\n    for (;;) {\n        if (hack) {\n            i = SSL_accept(con);\n#ifndef OPENSSL_NO_SRP\n            while (i <= 0\n                   && SSL_get_error(con, i) == SSL_ERROR_WANT_X509_LOOKUP) {\n                BIO_printf(bio_s_out, \"LOOKUP during accept %s\\n\",\n                           srp_callback_parm.login);\n                srp_callback_parm.user =\n                    SRP_VBASE_get_by_user(srp_callback_parm.vb,\n                                          srp_callback_parm.login);\n                if (srp_callback_parm.user)\n                    BIO_printf(bio_s_out, \"LOOKUP done %s\\n\",\n                               srp_callback_parm.user->info);\n                else\n                    BIO_printf(bio_s_out, \"LOOKUP not successful\\n\");\n                i = SSL_accept(con);\n            }\n#endif\n            switch (SSL_get_error(con, i)) {\n            case SSL_ERROR_NONE:\n                break;\n            case SSL_ERROR_WANT_WRITE:\n            case SSL_ERROR_WANT_READ:\n            case SSL_ERROR_WANT_X509_LOOKUP:\n                continue;\n            case SSL_ERROR_SYSCALL:\n            case SSL_ERROR_SSL:\n            case SSL_ERROR_ZERO_RETURN:\n                ret = 1;\n                goto err;\n                /* break; */\n            }\n\n            SSL_renegotiate(con);\n            SSL_write(con, NULL, 0);\n        }\n\n        i = BIO_gets(io, buf, bufsize - 1);\n        if (i < 0) {            /* error */\n            if (!BIO_should_retry(io)) {\n                if (!s_quiet)\n                    ERR_print_errors(bio_err);\n                goto err;\n            } else {\n                BIO_printf(bio_s_out, \"read R BLOCK\\n\");\n#ifndef OPENSSL_NO_SRP\n                if (BIO_should_io_special(io)\n                    && BIO_get_retry_reason(io) == BIO_RR_SSL_X509_LOOKUP) {\n                    BIO_printf(bio_s_out, \"LOOKUP renego during read\\n\");\n                    srp_callback_parm.user =\n                        SRP_VBASE_get_by_user(srp_callback_parm.vb,\n                                              srp_callback_parm.login);\n                    if (srp_callback_parm.user)\n                        BIO_printf(bio_s_out, \"LOOKUP done %s\\n\",\n                                   srp_callback_parm.user->info);\n                    else\n                        BIO_printf(bio_s_out, \"LOOKUP not successful\\n\");\n                    continue;\n                }\n#endif\n#if defined(OPENSSL_SYS_NETWARE)\n                delay(1000);\n#elif !defined(OPENSSL_SYS_MSDOS) && !defined(__DJGPP__)\n                sleep(1);\n#endif\n                continue;\n            }\n        } else if (i == 0) {    /* end of input */\n            ret = 1;\n            goto end;\n        }\n\n        /* else we have data */\n        if (((www == 1) && (strncmp(\"GET \", buf, 4) == 0)) ||\n            ((www == 2) && (strncmp(\"GET /stats \", buf, 11) == 0))) {\n            char *p;\n            X509 *peer;\n            STACK_OF(SSL_CIPHER) *sk;\n            static const char *space = \"                          \";\n\n            BIO_puts(io,\n                     \"HTTP/1.0 200 ok\\r\\nContent-type: text/html\\r\\n\\r\\n\");\n            BIO_puts(io, \"<HTML><BODY BGCOLOR=\\\"#ffffff\\\">\\n\");\n            BIO_puts(io, \"<pre>\\n\");\n/*                      BIO_puts(io,SSLeay_version(SSLEAY_VERSION));*/\n            BIO_puts(io, \"\\n\");\n            for (i = 0; i < local_argc; i++) {\n                BIO_puts(io, local_argv[i]);\n                BIO_write(io, \" \", 1);\n            }\n            BIO_puts(io, \"\\n\");\n\n            BIO_printf(io,\n                       \"Secure Renegotiation IS%s supported\\n\",\n                       SSL_get_secure_renegotiation_support(con) ?\n                       \"\" : \" NOT\");\n\n            /*\n             * The following is evil and should not really be done\n             */\n            BIO_printf(io, \"Ciphers supported in s_server binary\\n\");\n            sk = SSL_get_ciphers(con);\n            j = sk_SSL_CIPHER_num(sk);\n            for (i = 0; i < j; i++) {\n                c = sk_SSL_CIPHER_value(sk, i);\n                BIO_printf(io, \"%-11s:%-25s\",\n                           SSL_CIPHER_get_version(c), SSL_CIPHER_get_name(c));\n                if ((((i + 1) % 2) == 0) && (i + 1 != j))\n                    BIO_puts(io, \"\\n\");\n            }\n            BIO_puts(io, \"\\n\");\n            p = SSL_get_shared_ciphers(con, buf, bufsize);\n            if (p != NULL) {\n                BIO_printf(io,\n                           \"---\\nCiphers common between both SSL end points:\\n\");\n                j = i = 0;\n                while (*p) {\n                    if (*p == ':') {\n                        BIO_write(io, space, 26 - j);\n                        i++;\n                        j = 0;\n                        BIO_write(io, ((i % 3) ? \" \" : \"\\n\"), 1);\n                    } else {\n                        BIO_write(io, p, 1);\n                        j++;\n                    }\n                    p++;\n                }\n                BIO_puts(io, \"\\n\");\n            }\n            ssl_print_sigalgs(io, con);\n#ifndef OPENSSL_NO_EC\n            ssl_print_curves(io, con, 0);\n#endif\n            BIO_printf(io, (SSL_cache_hit(con)\n                            ? \"---\\nReused, \" : \"---\\nNew, \"));\n            c = SSL_get_current_cipher(con);\n            BIO_printf(io, \"%s, Cipher is %s\\n\",\n                       SSL_CIPHER_get_version(c), SSL_CIPHER_get_name(c));\n            SSL_SESSION_print(io, SSL_get_session(con));\n            BIO_printf(io, \"---\\n\");\n            print_stats(io, SSL_get_SSL_CTX(con));\n            BIO_printf(io, \"---\\n\");\n            peer = SSL_get_peer_certificate(con);\n            if (peer != NULL) {\n                BIO_printf(io, \"Client certificate\\n\");\n                X509_print(io, peer);\n                PEM_write_bio_X509(io, peer);\n            } else\n                BIO_puts(io, \"no client certificate available\\n\");\n            BIO_puts(io, \"</BODY></HTML>\\r\\n\\r\\n\");\n            break;\n        } else if ((www == 2 || www == 3)\n                   && (strncmp(\"GET /\", buf, 5) == 0)) {\n            BIO *file;\n            char *p, *e;\n            static const char *text =\n                \"HTTP/1.0 200 ok\\r\\nContent-type: text/plain\\r\\n\\r\\n\";\n\n            /* skip the '/' */\n            p = &(buf[5]);\n\n            dot = 1;\n            for (e = p; *e != '\\0'; e++) {\n                if (e[0] == ' ')\n                    break;\n\n                switch (dot) {\n                case 1:\n                    dot = (e[0] == '.') ? 2 : 0;\n                    break;\n                case 2:\n                    dot = (e[0] == '.') ? 3 : 0;\n                    break;\n                case 3:\n                    dot = (e[0] == '/') ? -1 : 0;\n                    break;\n                }\n                if (dot == 0)\n                    dot = (e[0] == '/') ? 1 : 0;\n            }\n            dot = (dot == 3) || (dot == -1); /* filename contains \"..\"\n                                              * component */\n\n            if (*e == '\\0') {\n                BIO_puts(io, text);\n                BIO_printf(io, \"'%s' is an invalid file name\\r\\n\", p);\n                break;\n            }\n            *e = '\\0';\n\n            if (dot) {\n                BIO_puts(io, text);\n                BIO_printf(io, \"'%s' contains '..' reference\\r\\n\", p);\n                break;\n            }\n\n            if (*p == '/') {\n                BIO_puts(io, text);\n                BIO_printf(io, \"'%s' is an invalid path\\r\\n\", p);\n                break;\n            }\n#if 0\n            /* append if a directory lookup */\n            if (e[-1] == '/')\n                strcat(p, \"index.html\");\n#endif\n\n            /* if a directory, do the index thang */\n            if (app_isdir(p) > 0) {\n#if 0                           /* must check buffer size */\n                strcat(p, \"/index.html\");\n#else\n                BIO_puts(io, text);\n                BIO_printf(io, \"'%s' is a directory\\r\\n\", p);\n                break;\n#endif\n            }\n\n            if ((file = BIO_new_file(p, \"r\")) == NULL) {\n                BIO_puts(io, text);\n                BIO_printf(io, \"Error opening '%s'\\r\\n\", p);\n                ERR_print_errors(io);\n                break;\n            }\n\n            if (!s_quiet)\n                BIO_printf(bio_err, \"FILE:%s\\n\", p);\n\n            if (www == 2) {\n                i = strlen(p);\n                if (((i > 5) && (strcmp(&(p[i - 5]), \".html\") == 0)) ||\n                    ((i > 4) && (strcmp(&(p[i - 4]), \".php\") == 0)) ||\n                    ((i > 4) && (strcmp(&(p[i - 4]), \".htm\") == 0)))\n                    BIO_puts(io,\n                             \"HTTP/1.0 200 ok\\r\\nContent-type: text/html\\r\\n\\r\\n\");\n                else\n                    BIO_puts(io,\n                             \"HTTP/1.0 200 ok\\r\\nContent-type: text/plain\\r\\n\\r\\n\");\n            }\n            /* send the file */\n            for (;;) {\n                i = BIO_read(file, buf, bufsize);\n                if (i <= 0)\n                    break;\n\n#ifdef RENEG\n                total_bytes += i;\n                fprintf(stderr, \"%d\\n\", i);\n                if (total_bytes > 3 * 1024) {\n                    total_bytes = 0;\n                    fprintf(stderr, \"RENEGOTIATE\\n\");\n                    SSL_renegotiate(con);\n                }\n#endif\n\n                for (j = 0; j < i;) {\n#ifdef RENEG\n                    {\n                        static count = 0;\n                        if (++count == 13) {\n                            SSL_renegotiate(con);\n                        }\n                    }\n#endif\n                    k = BIO_write(io, &(buf[j]), i - j);\n                    if (k <= 0) {\n                        if (!BIO_should_retry(io))\n                            goto write_error;\n                        else {\n                            BIO_printf(bio_s_out, \"rwrite W BLOCK\\n\");\n                        }\n                    } else {\n                        j += k;\n                    }\n                }\n            }\n write_error:\n            BIO_free(file);\n            break;\n        }\n    }\n\n    for (;;) {\n        i = (int)BIO_flush(io);\n        if (i <= 0) {\n            if (!BIO_should_retry(io))\n                break;\n        } else\n            break;\n    }\n end:\n#if 1\n    /* make sure we re-use sessions */\n    SSL_set_shutdown(con, SSL_SENT_SHUTDOWN | SSL_RECEIVED_SHUTDOWN);\n#else\n    /* This kills performance */\n    /*\n     * SSL_shutdown(con); A shutdown gets sent in the BIO_free_all(io)\n     * procession\n     */\n#endif\n\n err:\n\n    if (ret >= 0)\n        BIO_printf(bio_s_out, \"ACCEPT\\n\");\n\n    if (buf != NULL)\n        OPENSSL_free(buf);\n    if (io != NULL)\n        BIO_free_all(io);\n/*      if (ssl_bio != NULL) BIO_free(ssl_bio);*/\n    return (ret);\n}",
        "func": "static int www_body(char *hostname, int s, int stype, unsigned char *context)\n{\n    char *buf = NULL;\n    int ret = 1;\n    int i, j, k, dot;\n    SSL *con;\n    const SSL_CIPHER *c;\n    BIO *io, *ssl_bio, *sbio;\n#ifndef OPENSSL_NO_KRB5\n    KSSL_CTX *kctx;\n#endif\n\n    buf = OPENSSL_malloc(bufsize);\n    if (buf == NULL)\n        return (0);\n    io = BIO_new(BIO_f_buffer());\n    ssl_bio = BIO_new(BIO_f_ssl());\n    if ((io == NULL) || (ssl_bio == NULL))\n        goto err;\n\n#ifdef FIONBIO\n    if (s_nbio) {\n        unsigned long sl = 1;\n\n        if (!s_quiet)\n            BIO_printf(bio_err, \"turning on non blocking io\\n\");\n        if (BIO_socket_ioctl(s, FIONBIO, &sl) < 0)\n            ERR_print_errors(bio_err);\n    }\n#endif\n\n    /* lets make the output buffer a reasonable size */\n    if (!BIO_set_write_buffer_size(io, bufsize))\n        goto err;\n\n    if ((con = SSL_new(ctx)) == NULL)\n        goto err;\n#ifndef OPENSSL_NO_TLSEXT\n    if (s_tlsextdebug) {\n        SSL_set_tlsext_debug_callback(con, tlsext_cb);\n        SSL_set_tlsext_debug_arg(con, bio_s_out);\n    }\n#endif\n#ifndef OPENSSL_NO_KRB5\n    if ((kctx = kssl_ctx_new()) != NULL) {\n        kssl_ctx_setstring(kctx, KSSL_SERVICE, KRB5SVC);\n        kssl_ctx_setstring(kctx, KSSL_KEYTAB, KRB5KEYTAB);\n    }\n#endif                          /* OPENSSL_NO_KRB5 */\n    if (context)\n        SSL_set_session_id_context(con, context, strlen((char *)context));\n\n    sbio = BIO_new_socket(s, BIO_NOCLOSE);\n    if (s_nbio_test) {\n        BIO *test;\n\n        test = BIO_new(BIO_f_nbio_test());\n        sbio = BIO_push(test, sbio);\n    }\n    SSL_set_bio(con, sbio, sbio);\n    SSL_set_accept_state(con);\n\n    /* SSL_set_fd(con,s); */\n    BIO_set_ssl(ssl_bio, con, BIO_CLOSE);\n    BIO_push(io, ssl_bio);\n#ifdef CHARSET_EBCDIC\n    io = BIO_push(BIO_new(BIO_f_ebcdic_filter()), io);\n#endif\n\n    if (s_debug) {\n        SSL_set_debug(con, 1);\n        BIO_set_callback(SSL_get_rbio(con), bio_dump_callback);\n        BIO_set_callback_arg(SSL_get_rbio(con), (char *)bio_s_out);\n    }\n    if (s_msg) {\n#ifndef OPENSSL_NO_SSL_TRACE\n        if (s_msg == 2)\n            SSL_set_msg_callback(con, SSL_trace);\n        else\n#endif\n            SSL_set_msg_callback(con, msg_cb);\n        SSL_set_msg_callback_arg(con, bio_s_msg ? bio_s_msg : bio_s_out);\n    }\n\n    for (;;) {\n        if (hack) {\n            i = SSL_accept(con);\n#ifndef OPENSSL_NO_SRP\n            while (i <= 0\n                   && SSL_get_error(con, i) == SSL_ERROR_WANT_X509_LOOKUP) {\n                BIO_printf(bio_s_out, \"LOOKUP during accept %s\\n\",\n                           srp_callback_parm.login);\n                SRP_user_pwd_free(srp_callback_parm.user);\n                srp_callback_parm.user =\n                    SRP_VBASE_get1_by_user(srp_callback_parm.vb,\n                                           srp_callback_parm.login);\n                if (srp_callback_parm.user)\n                    BIO_printf(bio_s_out, \"LOOKUP done %s\\n\",\n                               srp_callback_parm.user->info);\n                else\n                    BIO_printf(bio_s_out, \"LOOKUP not successful\\n\");\n                i = SSL_accept(con);\n            }\n#endif\n            switch (SSL_get_error(con, i)) {\n            case SSL_ERROR_NONE:\n                break;\n            case SSL_ERROR_WANT_WRITE:\n            case SSL_ERROR_WANT_READ:\n            case SSL_ERROR_WANT_X509_LOOKUP:\n                continue;\n            case SSL_ERROR_SYSCALL:\n            case SSL_ERROR_SSL:\n            case SSL_ERROR_ZERO_RETURN:\n                ret = 1;\n                goto err;\n                /* break; */\n            }\n\n            SSL_renegotiate(con);\n            SSL_write(con, NULL, 0);\n        }\n\n        i = BIO_gets(io, buf, bufsize - 1);\n        if (i < 0) {            /* error */\n            if (!BIO_should_retry(io)) {\n                if (!s_quiet)\n                    ERR_print_errors(bio_err);\n                goto err;\n            } else {\n                BIO_printf(bio_s_out, \"read R BLOCK\\n\");\n#ifndef OPENSSL_NO_SRP\n                if (BIO_should_io_special(io)\n                    && BIO_get_retry_reason(io) == BIO_RR_SSL_X509_LOOKUP) {\n                    BIO_printf(bio_s_out, \"LOOKUP renego during read\\n\");\n                    SRP_user_pwd_free(srp_callback_parm.user);\n                    srp_callback_parm.user =\n                        SRP_VBASE_get1_by_user(srp_callback_parm.vb,\n                                               srp_callback_parm.login);\n                    if (srp_callback_parm.user)\n                        BIO_printf(bio_s_out, \"LOOKUP done %s\\n\",\n                                   srp_callback_parm.user->info);\n                    else\n                        BIO_printf(bio_s_out, \"LOOKUP not successful\\n\");\n                    continue;\n                }\n#endif\n#if defined(OPENSSL_SYS_NETWARE)\n                delay(1000);\n#elif !defined(OPENSSL_SYS_MSDOS) && !defined(__DJGPP__)\n                sleep(1);\n#endif\n                continue;\n            }\n        } else if (i == 0) {    /* end of input */\n            ret = 1;\n            goto end;\n        }\n\n        /* else we have data */\n        if (((www == 1) && (strncmp(\"GET \", buf, 4) == 0)) ||\n            ((www == 2) && (strncmp(\"GET /stats \", buf, 11) == 0))) {\n            char *p;\n            X509 *peer;\n            STACK_OF(SSL_CIPHER) *sk;\n            static const char *space = \"                          \";\n\n            BIO_puts(io,\n                     \"HTTP/1.0 200 ok\\r\\nContent-type: text/html\\r\\n\\r\\n\");\n            BIO_puts(io, \"<HTML><BODY BGCOLOR=\\\"#ffffff\\\">\\n\");\n            BIO_puts(io, \"<pre>\\n\");\n/*                      BIO_puts(io,SSLeay_version(SSLEAY_VERSION));*/\n            BIO_puts(io, \"\\n\");\n            for (i = 0; i < local_argc; i++) {\n                BIO_puts(io, local_argv[i]);\n                BIO_write(io, \" \", 1);\n            }\n            BIO_puts(io, \"\\n\");\n\n            BIO_printf(io,\n                       \"Secure Renegotiation IS%s supported\\n\",\n                       SSL_get_secure_renegotiation_support(con) ?\n                       \"\" : \" NOT\");\n\n            /*\n             * The following is evil and should not really be done\n             */\n            BIO_printf(io, \"Ciphers supported in s_server binary\\n\");\n            sk = SSL_get_ciphers(con);\n            j = sk_SSL_CIPHER_num(sk);\n            for (i = 0; i < j; i++) {\n                c = sk_SSL_CIPHER_value(sk, i);\n                BIO_printf(io, \"%-11s:%-25s\",\n                           SSL_CIPHER_get_version(c), SSL_CIPHER_get_name(c));\n                if ((((i + 1) % 2) == 0) && (i + 1 != j))\n                    BIO_puts(io, \"\\n\");\n            }\n            BIO_puts(io, \"\\n\");\n            p = SSL_get_shared_ciphers(con, buf, bufsize);\n            if (p != NULL) {\n                BIO_printf(io,\n                           \"---\\nCiphers common between both SSL end points:\\n\");\n                j = i = 0;\n                while (*p) {\n                    if (*p == ':') {\n                        BIO_write(io, space, 26 - j);\n                        i++;\n                        j = 0;\n                        BIO_write(io, ((i % 3) ? \" \" : \"\\n\"), 1);\n                    } else {\n                        BIO_write(io, p, 1);\n                        j++;\n                    }\n                    p++;\n                }\n                BIO_puts(io, \"\\n\");\n            }\n            ssl_print_sigalgs(io, con);\n#ifndef OPENSSL_NO_EC\n            ssl_print_curves(io, con, 0);\n#endif\n            BIO_printf(io, (SSL_cache_hit(con)\n                            ? \"---\\nReused, \" : \"---\\nNew, \"));\n            c = SSL_get_current_cipher(con);\n            BIO_printf(io, \"%s, Cipher is %s\\n\",\n                       SSL_CIPHER_get_version(c), SSL_CIPHER_get_name(c));\n            SSL_SESSION_print(io, SSL_get_session(con));\n            BIO_printf(io, \"---\\n\");\n            print_stats(io, SSL_get_SSL_CTX(con));\n            BIO_printf(io, \"---\\n\");\n            peer = SSL_get_peer_certificate(con);\n            if (peer != NULL) {\n                BIO_printf(io, \"Client certificate\\n\");\n                X509_print(io, peer);\n                PEM_write_bio_X509(io, peer);\n            } else\n                BIO_puts(io, \"no client certificate available\\n\");\n            BIO_puts(io, \"</BODY></HTML>\\r\\n\\r\\n\");\n            break;\n        } else if ((www == 2 || www == 3)\n                   && (strncmp(\"GET /\", buf, 5) == 0)) {\n            BIO *file;\n            char *p, *e;\n            static const char *text =\n                \"HTTP/1.0 200 ok\\r\\nContent-type: text/plain\\r\\n\\r\\n\";\n\n            /* skip the '/' */\n            p = &(buf[5]);\n\n            dot = 1;\n            for (e = p; *e != '\\0'; e++) {\n                if (e[0] == ' ')\n                    break;\n\n                switch (dot) {\n                case 1:\n                    dot = (e[0] == '.') ? 2 : 0;\n                    break;\n                case 2:\n                    dot = (e[0] == '.') ? 3 : 0;\n                    break;\n                case 3:\n                    dot = (e[0] == '/') ? -1 : 0;\n                    break;\n                }\n                if (dot == 0)\n                    dot = (e[0] == '/') ? 1 : 0;\n            }\n            dot = (dot == 3) || (dot == -1); /* filename contains \"..\"\n                                              * component */\n\n            if (*e == '\\0') {\n                BIO_puts(io, text);\n                BIO_printf(io, \"'%s' is an invalid file name\\r\\n\", p);\n                break;\n            }\n            *e = '\\0';\n\n            if (dot) {\n                BIO_puts(io, text);\n                BIO_printf(io, \"'%s' contains '..' reference\\r\\n\", p);\n                break;\n            }\n\n            if (*p == '/') {\n                BIO_puts(io, text);\n                BIO_printf(io, \"'%s' is an invalid path\\r\\n\", p);\n                break;\n            }\n#if 0\n            /* append if a directory lookup */\n            if (e[-1] == '/')\n                strcat(p, \"index.html\");\n#endif\n\n            /* if a directory, do the index thang */\n            if (app_isdir(p) > 0) {\n#if 0                           /* must check buffer size */\n                strcat(p, \"/index.html\");\n#else\n                BIO_puts(io, text);\n                BIO_printf(io, \"'%s' is a directory\\r\\n\", p);\n                break;\n#endif\n            }\n\n            if ((file = BIO_new_file(p, \"r\")) == NULL) {\n                BIO_puts(io, text);\n                BIO_printf(io, \"Error opening '%s'\\r\\n\", p);\n                ERR_print_errors(io);\n                break;\n            }\n\n            if (!s_quiet)\n                BIO_printf(bio_err, \"FILE:%s\\n\", p);\n\n            if (www == 2) {\n                i = strlen(p);\n                if (((i > 5) && (strcmp(&(p[i - 5]), \".html\") == 0)) ||\n                    ((i > 4) && (strcmp(&(p[i - 4]), \".php\") == 0)) ||\n                    ((i > 4) && (strcmp(&(p[i - 4]), \".htm\") == 0)))\n                    BIO_puts(io,\n                             \"HTTP/1.0 200 ok\\r\\nContent-type: text/html\\r\\n\\r\\n\");\n                else\n                    BIO_puts(io,\n                             \"HTTP/1.0 200 ok\\r\\nContent-type: text/plain\\r\\n\\r\\n\");\n            }\n            /* send the file */\n            for (;;) {\n                i = BIO_read(file, buf, bufsize);\n                if (i <= 0)\n                    break;\n\n#ifdef RENEG\n                total_bytes += i;\n                fprintf(stderr, \"%d\\n\", i);\n                if (total_bytes > 3 * 1024) {\n                    total_bytes = 0;\n                    fprintf(stderr, \"RENEGOTIATE\\n\");\n                    SSL_renegotiate(con);\n                }\n#endif\n\n                for (j = 0; j < i;) {\n#ifdef RENEG\n                    {\n                        static count = 0;\n                        if (++count == 13) {\n                            SSL_renegotiate(con);\n                        }\n                    }\n#endif\n                    k = BIO_write(io, &(buf[j]), i - j);\n                    if (k <= 0) {\n                        if (!BIO_should_retry(io))\n                            goto write_error;\n                        else {\n                            BIO_printf(bio_s_out, \"rwrite W BLOCK\\n\");\n                        }\n                    } else {\n                        j += k;\n                    }\n                }\n            }\n write_error:\n            BIO_free(file);\n            break;\n        }\n    }\n\n    for (;;) {\n        i = (int)BIO_flush(io);\n        if (i <= 0) {\n            if (!BIO_should_retry(io))\n                break;\n        } else\n            break;\n    }\n end:\n#if 1\n    /* make sure we re-use sessions */\n    SSL_set_shutdown(con, SSL_SENT_SHUTDOWN | SSL_RECEIVED_SHUTDOWN);\n#else\n    /* This kills performance */\n    /*\n     * SSL_shutdown(con); A shutdown gets sent in the BIO_free_all(io)\n     * procession\n     */\n#endif\n\n err:\n\n    if (ret >= 0)\n        BIO_printf(bio_s_out, \"ACCEPT\\n\");\n\n    if (buf != NULL)\n        OPENSSL_free(buf);\n    if (io != NULL)\n        BIO_free_all(io);\n/*      if (ssl_bio != NULL) BIO_free(ssl_bio);*/\n    return (ret);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -90,9 +90,10 @@\n                    && SSL_get_error(con, i) == SSL_ERROR_WANT_X509_LOOKUP) {\n                 BIO_printf(bio_s_out, \"LOOKUP during accept %s\\n\",\n                            srp_callback_parm.login);\n+                SRP_user_pwd_free(srp_callback_parm.user);\n                 srp_callback_parm.user =\n-                    SRP_VBASE_get_by_user(srp_callback_parm.vb,\n-                                          srp_callback_parm.login);\n+                    SRP_VBASE_get1_by_user(srp_callback_parm.vb,\n+                                           srp_callback_parm.login);\n                 if (srp_callback_parm.user)\n                     BIO_printf(bio_s_out, \"LOOKUP done %s\\n\",\n                                srp_callback_parm.user->info);\n@@ -132,9 +133,10 @@\n                 if (BIO_should_io_special(io)\n                     && BIO_get_retry_reason(io) == BIO_RR_SSL_X509_LOOKUP) {\n                     BIO_printf(bio_s_out, \"LOOKUP renego during read\\n\");\n+                    SRP_user_pwd_free(srp_callback_parm.user);\n                     srp_callback_parm.user =\n-                        SRP_VBASE_get_by_user(srp_callback_parm.vb,\n-                                              srp_callback_parm.login);\n+                        SRP_VBASE_get1_by_user(srp_callback_parm.vb,\n+                                               srp_callback_parm.login);\n                     if (srp_callback_parm.user)\n                         BIO_printf(bio_s_out, \"LOOKUP done %s\\n\",\n                                    srp_callback_parm.user->info);",
        "diff_line_info": {
            "deleted_lines": [
                "                    SRP_VBASE_get_by_user(srp_callback_parm.vb,",
                "                                          srp_callback_parm.login);",
                "                        SRP_VBASE_get_by_user(srp_callback_parm.vb,",
                "                                              srp_callback_parm.login);"
            ],
            "added_lines": [
                "                SRP_user_pwd_free(srp_callback_parm.user);",
                "                    SRP_VBASE_get1_by_user(srp_callback_parm.vb,",
                "                                           srp_callback_parm.login);",
                "                    SRP_user_pwd_free(srp_callback_parm.user);",
                "                        SRP_VBASE_get1_by_user(srp_callback_parm.vb,",
                "                                               srp_callback_parm.login);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-0798",
        "func_name": "openssl/ssl_srp_server_param_cb",
        "description": "Memory leak in the SRP_VBASE_get_by_user implementation in OpenSSL 1.0.1 before 1.0.1s and 1.0.2 before 1.0.2g allows remote attackers to cause a denial of service (memory consumption) by providing an invalid username in a connection attempt, related to apps/s_server.c and crypto/srp/srp_vfy.c.",
        "git_url": "https://git.openssl.org/?p=openssl.git;a=commit;h=259b664f950c2ba66fbf4b0fe5281327904ead21",
        "commit_title": "",
        "commit_text": "CVE-2016-0798: avoid memory leak in SRP  The SRP user database lookup method SRP_VBASE_get_by_user had confusing memory management semantics; the returned pointer was sometimes newly allocated, and sometimes owned by the callee. The calling code has no way of distinguishing these two cases.  Specifically, SRP servers that configure a secret seed to hide valid login information are vulnerable to a memory leak: an attacker connecting with an invalid username can cause a memory leak of around 300 bytes per connection.  Servers that do not configure SRP, or configure SRP but do not configure a seed are not vulnerable.  In Apache, the seed directive is known as SSLSRPUnknownUserSeed.  To mitigate the memory leak, the seed handling in SRP_VBASE_get_by_user is now disabled even if the user has configured a seed.  Applications are advised to migrate to SRP_VBASE_get1_by_user. However, note that OpenSSL makes no strong guarantees about the indistinguishability of valid and invalid logins. In particular, computations are currently not carried out in constant time.  ",
        "func_before": "static int MS_CALLBACK ssl_srp_server_param_cb(SSL *s, int *ad, void *arg)\n{\n    srpsrvparm *p = (srpsrvparm *) arg;\n    if (p->login == NULL && p->user == NULL) {\n        p->login = SSL_get_srp_username(s);\n        BIO_printf(bio_err, \"SRP username = \\\"%s\\\"\\n\", p->login);\n        return (-1);\n    }\n\n    if (p->user == NULL) {\n        BIO_printf(bio_err, \"User %s doesn't exist\\n\", p->login);\n        return SSL3_AL_FATAL;\n    }\n    if (SSL_set_srp_server_param\n        (s, p->user->N, p->user->g, p->user->s, p->user->v,\n         p->user->info) < 0) {\n        *ad = SSL_AD_INTERNAL_ERROR;\n        return SSL3_AL_FATAL;\n    }\n    BIO_printf(bio_err,\n               \"SRP parameters set: username = \\\"%s\\\" info=\\\"%s\\\" \\n\",\n               p->login, p->user->info);\n    /* need to check whether there are memory leaks */\n    p->user = NULL;\n    p->login = NULL;\n    return SSL_ERROR_NONE;\n}",
        "func": "static int MS_CALLBACK ssl_srp_server_param_cb(SSL *s, int *ad, void *arg)\n{\n    srpsrvparm *p = (srpsrvparm *) arg;\n    int ret = SSL3_AL_FATAL;\n\n    if (p->login == NULL && p->user == NULL) {\n        p->login = SSL_get_srp_username(s);\n        BIO_printf(bio_err, \"SRP username = \\\"%s\\\"\\n\", p->login);\n        return (-1);\n    }\n\n    if (p->user == NULL) {\n        BIO_printf(bio_err, \"User %s doesn't exist\\n\", p->login);\n        goto err;\n    }\n\n    if (SSL_set_srp_server_param\n        (s, p->user->N, p->user->g, p->user->s, p->user->v,\n         p->user->info) < 0) {\n        *ad = SSL_AD_INTERNAL_ERROR;\n        goto err;\n    }\n    BIO_printf(bio_err,\n               \"SRP parameters set: username = \\\"%s\\\" info=\\\"%s\\\" \\n\",\n               p->login, p->user->info);\n    ret = SSL_ERROR_NONE;\n\nerr:\n    SRP_user_pwd_free(p->user);\n    p->user = NULL;\n    p->login = NULL;\n    return ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,8 @@\n static int MS_CALLBACK ssl_srp_server_param_cb(SSL *s, int *ad, void *arg)\n {\n     srpsrvparm *p = (srpsrvparm *) arg;\n+    int ret = SSL3_AL_FATAL;\n+\n     if (p->login == NULL && p->user == NULL) {\n         p->login = SSL_get_srp_username(s);\n         BIO_printf(bio_err, \"SRP username = \\\"%s\\\"\\n\", p->login);\n@@ -9,19 +11,23 @@\n \n     if (p->user == NULL) {\n         BIO_printf(bio_err, \"User %s doesn't exist\\n\", p->login);\n-        return SSL3_AL_FATAL;\n+        goto err;\n     }\n+\n     if (SSL_set_srp_server_param\n         (s, p->user->N, p->user->g, p->user->s, p->user->v,\n          p->user->info) < 0) {\n         *ad = SSL_AD_INTERNAL_ERROR;\n-        return SSL3_AL_FATAL;\n+        goto err;\n     }\n     BIO_printf(bio_err,\n                \"SRP parameters set: username = \\\"%s\\\" info=\\\"%s\\\" \\n\",\n                p->login, p->user->info);\n-    /* need to check whether there are memory leaks */\n+    ret = SSL_ERROR_NONE;\n+\n+err:\n+    SRP_user_pwd_free(p->user);\n     p->user = NULL;\n     p->login = NULL;\n-    return SSL_ERROR_NONE;\n+    return ret;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "        return SSL3_AL_FATAL;",
                "        return SSL3_AL_FATAL;",
                "    /* need to check whether there are memory leaks */",
                "    return SSL_ERROR_NONE;"
            ],
            "added_lines": [
                "    int ret = SSL3_AL_FATAL;",
                "",
                "        goto err;",
                "",
                "        goto err;",
                "    ret = SSL_ERROR_NONE;",
                "",
                "err:",
                "    SRP_user_pwd_free(p->user);",
                "    return ret;"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-0798",
        "func_name": "openssl/rev_body",
        "description": "Memory leak in the SRP_VBASE_get_by_user implementation in OpenSSL 1.0.1 before 1.0.1s and 1.0.2 before 1.0.2g allows remote attackers to cause a denial of service (memory consumption) by providing an invalid username in a connection attempt, related to apps/s_server.c and crypto/srp/srp_vfy.c.",
        "git_url": "https://git.openssl.org/?p=openssl.git;a=commit;h=259b664f950c2ba66fbf4b0fe5281327904ead21",
        "commit_title": "",
        "commit_text": "CVE-2016-0798: avoid memory leak in SRP  The SRP user database lookup method SRP_VBASE_get_by_user had confusing memory management semantics; the returned pointer was sometimes newly allocated, and sometimes owned by the callee. The calling code has no way of distinguishing these two cases.  Specifically, SRP servers that configure a secret seed to hide valid login information are vulnerable to a memory leak: an attacker connecting with an invalid username can cause a memory leak of around 300 bytes per connection.  Servers that do not configure SRP, or configure SRP but do not configure a seed are not vulnerable.  In Apache, the seed directive is known as SSLSRPUnknownUserSeed.  To mitigate the memory leak, the seed handling in SRP_VBASE_get_by_user is now disabled even if the user has configured a seed.  Applications are advised to migrate to SRP_VBASE_get1_by_user. However, note that OpenSSL makes no strong guarantees about the indistinguishability of valid and invalid logins. In particular, computations are currently not carried out in constant time.  ",
        "func_before": "static int rev_body(char *hostname, int s, int stype, unsigned char *context)\n{\n    char *buf = NULL;\n    int i;\n    int ret = 1;\n    SSL *con;\n    BIO *io, *ssl_bio, *sbio;\n#ifndef OPENSSL_NO_KRB5\n    KSSL_CTX *kctx;\n#endif\n\n    buf = OPENSSL_malloc(bufsize);\n    if (buf == NULL)\n        return (0);\n    io = BIO_new(BIO_f_buffer());\n    ssl_bio = BIO_new(BIO_f_ssl());\n    if ((io == NULL) || (ssl_bio == NULL))\n        goto err;\n\n    /* lets make the output buffer a reasonable size */\n    if (!BIO_set_write_buffer_size(io, bufsize))\n        goto err;\n\n    if ((con = SSL_new(ctx)) == NULL)\n        goto err;\n#ifndef OPENSSL_NO_TLSEXT\n    if (s_tlsextdebug) {\n        SSL_set_tlsext_debug_callback(con, tlsext_cb);\n        SSL_set_tlsext_debug_arg(con, bio_s_out);\n    }\n#endif\n#ifndef OPENSSL_NO_KRB5\n    if ((kctx = kssl_ctx_new()) != NULL) {\n        kssl_ctx_setstring(kctx, KSSL_SERVICE, KRB5SVC);\n        kssl_ctx_setstring(kctx, KSSL_KEYTAB, KRB5KEYTAB);\n    }\n#endif                          /* OPENSSL_NO_KRB5 */\n    if (context)\n        SSL_set_session_id_context(con, context, strlen((char *)context));\n\n    sbio = BIO_new_socket(s, BIO_NOCLOSE);\n    SSL_set_bio(con, sbio, sbio);\n    SSL_set_accept_state(con);\n\n    BIO_set_ssl(ssl_bio, con, BIO_CLOSE);\n    BIO_push(io, ssl_bio);\n#ifdef CHARSET_EBCDIC\n    io = BIO_push(BIO_new(BIO_f_ebcdic_filter()), io);\n#endif\n\n    if (s_debug) {\n        SSL_set_debug(con, 1);\n        BIO_set_callback(SSL_get_rbio(con), bio_dump_callback);\n        BIO_set_callback_arg(SSL_get_rbio(con), (char *)bio_s_out);\n    }\n    if (s_msg) {\n#ifndef OPENSSL_NO_SSL_TRACE\n        if (s_msg == 2)\n            SSL_set_msg_callback(con, SSL_trace);\n        else\n#endif\n            SSL_set_msg_callback(con, msg_cb);\n        SSL_set_msg_callback_arg(con, bio_s_msg ? bio_s_msg : bio_s_out);\n    }\n\n    for (;;) {\n        i = BIO_do_handshake(io);\n        if (i > 0)\n            break;\n        if (!BIO_should_retry(io)) {\n            BIO_puts(bio_err, \"CONNECTION FAILURE\\n\");\n            ERR_print_errors(bio_err);\n            goto end;\n        }\n#ifndef OPENSSL_NO_SRP\n        if (BIO_should_io_special(io)\n            && BIO_get_retry_reason(io) == BIO_RR_SSL_X509_LOOKUP) {\n            BIO_printf(bio_s_out, \"LOOKUP renego during accept\\n\");\n            srp_callback_parm.user =\n                SRP_VBASE_get_by_user(srp_callback_parm.vb,\n                                      srp_callback_parm.login);\n            if (srp_callback_parm.user)\n                BIO_printf(bio_s_out, \"LOOKUP done %s\\n\",\n                           srp_callback_parm.user->info);\n            else\n                BIO_printf(bio_s_out, \"LOOKUP not successful\\n\");\n            continue;\n        }\n#endif\n    }\n    BIO_printf(bio_err, \"CONNECTION ESTABLISHED\\n\");\n    print_ssl_summary(bio_err, con);\n\n    for (;;) {\n        i = BIO_gets(io, buf, bufsize - 1);\n        if (i < 0) {            /* error */\n            if (!BIO_should_retry(io)) {\n                if (!s_quiet)\n                    ERR_print_errors(bio_err);\n                goto err;\n            } else {\n                BIO_printf(bio_s_out, \"read R BLOCK\\n\");\n#ifndef OPENSSL_NO_SRP\n                if (BIO_should_io_special(io)\n                    && BIO_get_retry_reason(io) == BIO_RR_SSL_X509_LOOKUP) {\n                    BIO_printf(bio_s_out, \"LOOKUP renego during read\\n\");\n                    srp_callback_parm.user =\n                        SRP_VBASE_get_by_user(srp_callback_parm.vb,\n                                              srp_callback_parm.login);\n                    if (srp_callback_parm.user)\n                        BIO_printf(bio_s_out, \"LOOKUP done %s\\n\",\n                                   srp_callback_parm.user->info);\n                    else\n                        BIO_printf(bio_s_out, \"LOOKUP not successful\\n\");\n                    continue;\n                }\n#endif\n#if defined(OPENSSL_SYS_NETWARE)\n                delay(1000);\n#elif !defined(OPENSSL_SYS_MSDOS) && !defined(__DJGPP__)\n                sleep(1);\n#endif\n                continue;\n            }\n        } else if (i == 0) {    /* end of input */\n            ret = 1;\n            BIO_printf(bio_err, \"CONNECTION CLOSED\\n\");\n            goto end;\n        } else {\n            char *p = buf + i - 1;\n            while (i && (*p == '\\n' || *p == '\\r')) {\n                p--;\n                i--;\n            }\n            if (!s_ign_eof && i == 5 && !strncmp(buf, \"CLOSE\", 5)) {\n                ret = 1;\n                BIO_printf(bio_err, \"CONNECTION CLOSED\\n\");\n                goto end;\n            }\n            BUF_reverse((unsigned char *)buf, NULL, i);\n            buf[i] = '\\n';\n            BIO_write(io, buf, i + 1);\n            for (;;) {\n                i = BIO_flush(io);\n                if (i > 0)\n                    break;\n                if (!BIO_should_retry(io))\n                    goto end;\n            }\n        }\n    }\n end:\n    /* make sure we re-use sessions */\n    SSL_set_shutdown(con, SSL_SENT_SHUTDOWN | SSL_RECEIVED_SHUTDOWN);\n\n err:\n\n    if (buf != NULL)\n        OPENSSL_free(buf);\n    if (io != NULL)\n        BIO_free_all(io);\n    return (ret);\n}",
        "func": "static int rev_body(char *hostname, int s, int stype, unsigned char *context)\n{\n    char *buf = NULL;\n    int i;\n    int ret = 1;\n    SSL *con;\n    BIO *io, *ssl_bio, *sbio;\n#ifndef OPENSSL_NO_KRB5\n    KSSL_CTX *kctx;\n#endif\n\n    buf = OPENSSL_malloc(bufsize);\n    if (buf == NULL)\n        return (0);\n    io = BIO_new(BIO_f_buffer());\n    ssl_bio = BIO_new(BIO_f_ssl());\n    if ((io == NULL) || (ssl_bio == NULL))\n        goto err;\n\n    /* lets make the output buffer a reasonable size */\n    if (!BIO_set_write_buffer_size(io, bufsize))\n        goto err;\n\n    if ((con = SSL_new(ctx)) == NULL)\n        goto err;\n#ifndef OPENSSL_NO_TLSEXT\n    if (s_tlsextdebug) {\n        SSL_set_tlsext_debug_callback(con, tlsext_cb);\n        SSL_set_tlsext_debug_arg(con, bio_s_out);\n    }\n#endif\n#ifndef OPENSSL_NO_KRB5\n    if ((kctx = kssl_ctx_new()) != NULL) {\n        kssl_ctx_setstring(kctx, KSSL_SERVICE, KRB5SVC);\n        kssl_ctx_setstring(kctx, KSSL_KEYTAB, KRB5KEYTAB);\n    }\n#endif                          /* OPENSSL_NO_KRB5 */\n    if (context)\n        SSL_set_session_id_context(con, context, strlen((char *)context));\n\n    sbio = BIO_new_socket(s, BIO_NOCLOSE);\n    SSL_set_bio(con, sbio, sbio);\n    SSL_set_accept_state(con);\n\n    BIO_set_ssl(ssl_bio, con, BIO_CLOSE);\n    BIO_push(io, ssl_bio);\n#ifdef CHARSET_EBCDIC\n    io = BIO_push(BIO_new(BIO_f_ebcdic_filter()), io);\n#endif\n\n    if (s_debug) {\n        SSL_set_debug(con, 1);\n        BIO_set_callback(SSL_get_rbio(con), bio_dump_callback);\n        BIO_set_callback_arg(SSL_get_rbio(con), (char *)bio_s_out);\n    }\n    if (s_msg) {\n#ifndef OPENSSL_NO_SSL_TRACE\n        if (s_msg == 2)\n            SSL_set_msg_callback(con, SSL_trace);\n        else\n#endif\n            SSL_set_msg_callback(con, msg_cb);\n        SSL_set_msg_callback_arg(con, bio_s_msg ? bio_s_msg : bio_s_out);\n    }\n\n    for (;;) {\n        i = BIO_do_handshake(io);\n        if (i > 0)\n            break;\n        if (!BIO_should_retry(io)) {\n            BIO_puts(bio_err, \"CONNECTION FAILURE\\n\");\n            ERR_print_errors(bio_err);\n            goto end;\n        }\n#ifndef OPENSSL_NO_SRP\n        if (BIO_should_io_special(io)\n            && BIO_get_retry_reason(io) == BIO_RR_SSL_X509_LOOKUP) {\n            BIO_printf(bio_s_out, \"LOOKUP renego during accept\\n\");\n            SRP_user_pwd_free(srp_callback_parm.user);\n            srp_callback_parm.user =\n                SRP_VBASE_get1_by_user(srp_callback_parm.vb,\n                                       srp_callback_parm.login);\n            if (srp_callback_parm.user)\n                BIO_printf(bio_s_out, \"LOOKUP done %s\\n\",\n                           srp_callback_parm.user->info);\n            else\n                BIO_printf(bio_s_out, \"LOOKUP not successful\\n\");\n            continue;\n        }\n#endif\n    }\n    BIO_printf(bio_err, \"CONNECTION ESTABLISHED\\n\");\n    print_ssl_summary(bio_err, con);\n\n    for (;;) {\n        i = BIO_gets(io, buf, bufsize - 1);\n        if (i < 0) {            /* error */\n            if (!BIO_should_retry(io)) {\n                if (!s_quiet)\n                    ERR_print_errors(bio_err);\n                goto err;\n            } else {\n                BIO_printf(bio_s_out, \"read R BLOCK\\n\");\n#ifndef OPENSSL_NO_SRP\n                if (BIO_should_io_special(io)\n                    && BIO_get_retry_reason(io) == BIO_RR_SSL_X509_LOOKUP) {\n                    BIO_printf(bio_s_out, \"LOOKUP renego during read\\n\");\n                    SRP_user_pwd_free(srp_callback_parm.user);\n                    srp_callback_parm.user =\n                        SRP_VBASE_get1_by_user(srp_callback_parm.vb,\n                                               srp_callback_parm.login);\n                    if (srp_callback_parm.user)\n                        BIO_printf(bio_s_out, \"LOOKUP done %s\\n\",\n                                   srp_callback_parm.user->info);\n                    else\n                        BIO_printf(bio_s_out, \"LOOKUP not successful\\n\");\n                    continue;\n                }\n#endif\n#if defined(OPENSSL_SYS_NETWARE)\n                delay(1000);\n#elif !defined(OPENSSL_SYS_MSDOS) && !defined(__DJGPP__)\n                sleep(1);\n#endif\n                continue;\n            }\n        } else if (i == 0) {    /* end of input */\n            ret = 1;\n            BIO_printf(bio_err, \"CONNECTION CLOSED\\n\");\n            goto end;\n        } else {\n            char *p = buf + i - 1;\n            while (i && (*p == '\\n' || *p == '\\r')) {\n                p--;\n                i--;\n            }\n            if (!s_ign_eof && i == 5 && !strncmp(buf, \"CLOSE\", 5)) {\n                ret = 1;\n                BIO_printf(bio_err, \"CONNECTION CLOSED\\n\");\n                goto end;\n            }\n            BUF_reverse((unsigned char *)buf, NULL, i);\n            buf[i] = '\\n';\n            BIO_write(io, buf, i + 1);\n            for (;;) {\n                i = BIO_flush(io);\n                if (i > 0)\n                    break;\n                if (!BIO_should_retry(io))\n                    goto end;\n            }\n        }\n    }\n end:\n    /* make sure we re-use sessions */\n    SSL_set_shutdown(con, SSL_SENT_SHUTDOWN | SSL_RECEIVED_SHUTDOWN);\n\n err:\n\n    if (buf != NULL)\n        OPENSSL_free(buf);\n    if (io != NULL)\n        BIO_free_all(io);\n    return (ret);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -76,9 +76,10 @@\n         if (BIO_should_io_special(io)\n             && BIO_get_retry_reason(io) == BIO_RR_SSL_X509_LOOKUP) {\n             BIO_printf(bio_s_out, \"LOOKUP renego during accept\\n\");\n+            SRP_user_pwd_free(srp_callback_parm.user);\n             srp_callback_parm.user =\n-                SRP_VBASE_get_by_user(srp_callback_parm.vb,\n-                                      srp_callback_parm.login);\n+                SRP_VBASE_get1_by_user(srp_callback_parm.vb,\n+                                       srp_callback_parm.login);\n             if (srp_callback_parm.user)\n                 BIO_printf(bio_s_out, \"LOOKUP done %s\\n\",\n                            srp_callback_parm.user->info);\n@@ -104,9 +105,10 @@\n                 if (BIO_should_io_special(io)\n                     && BIO_get_retry_reason(io) == BIO_RR_SSL_X509_LOOKUP) {\n                     BIO_printf(bio_s_out, \"LOOKUP renego during read\\n\");\n+                    SRP_user_pwd_free(srp_callback_parm.user);\n                     srp_callback_parm.user =\n-                        SRP_VBASE_get_by_user(srp_callback_parm.vb,\n-                                              srp_callback_parm.login);\n+                        SRP_VBASE_get1_by_user(srp_callback_parm.vb,\n+                                               srp_callback_parm.login);\n                     if (srp_callback_parm.user)\n                         BIO_printf(bio_s_out, \"LOOKUP done %s\\n\",\n                                    srp_callback_parm.user->info);",
        "diff_line_info": {
            "deleted_lines": [
                "                SRP_VBASE_get_by_user(srp_callback_parm.vb,",
                "                                      srp_callback_parm.login);",
                "                        SRP_VBASE_get_by_user(srp_callback_parm.vb,",
                "                                              srp_callback_parm.login);"
            ],
            "added_lines": [
                "            SRP_user_pwd_free(srp_callback_parm.user);",
                "                SRP_VBASE_get1_by_user(srp_callback_parm.vb,",
                "                                       srp_callback_parm.login);",
                "                    SRP_user_pwd_free(srp_callback_parm.user);",
                "                        SRP_VBASE_get1_by_user(srp_callback_parm.vb,",
                "                                               srp_callback_parm.login);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-0798",
        "func_name": "openssl/sv_body",
        "description": "Memory leak in the SRP_VBASE_get_by_user implementation in OpenSSL 1.0.1 before 1.0.1s and 1.0.2 before 1.0.2g allows remote attackers to cause a denial of service (memory consumption) by providing an invalid username in a connection attempt, related to apps/s_server.c and crypto/srp/srp_vfy.c.",
        "git_url": "https://git.openssl.org/?p=openssl.git;a=commit;h=259b664f950c2ba66fbf4b0fe5281327904ead21",
        "commit_title": "",
        "commit_text": "CVE-2016-0798: avoid memory leak in SRP  The SRP user database lookup method SRP_VBASE_get_by_user had confusing memory management semantics; the returned pointer was sometimes newly allocated, and sometimes owned by the callee. The calling code has no way of distinguishing these two cases.  Specifically, SRP servers that configure a secret seed to hide valid login information are vulnerable to a memory leak: an attacker connecting with an invalid username can cause a memory leak of around 300 bytes per connection.  Servers that do not configure SRP, or configure SRP but do not configure a seed are not vulnerable.  In Apache, the seed directive is known as SSLSRPUnknownUserSeed.  To mitigate the memory leak, the seed handling in SRP_VBASE_get_by_user is now disabled even if the user has configured a seed.  Applications are advised to migrate to SRP_VBASE_get1_by_user. However, note that OpenSSL makes no strong guarantees about the indistinguishability of valid and invalid logins. In particular, computations are currently not carried out in constant time.  ",
        "func_before": "static int sv_body(char *hostname, int s, int stype, unsigned char *context)\n{\n    char *buf = NULL;\n    fd_set readfds;\n    int ret = 1, width;\n    int k, i;\n    unsigned long l;\n    SSL *con = NULL;\n    BIO *sbio;\n#ifndef OPENSSL_NO_KRB5\n    KSSL_CTX *kctx;\n#endif\n    struct timeval timeout;\n#if defined(OPENSSL_SYS_WINDOWS) || defined(OPENSSL_SYS_MSDOS) || defined(OPENSSL_SYS_NETWARE) || defined(OPENSSL_SYS_BEOS_R5)\n    struct timeval tv;\n#else\n    struct timeval *timeoutp;\n#endif\n\n    if ((buf = OPENSSL_malloc(bufsize)) == NULL) {\n        BIO_printf(bio_err, \"out of memory\\n\");\n        goto err;\n    }\n#ifdef FIONBIO\n    if (s_nbio) {\n        unsigned long sl = 1;\n\n        if (!s_quiet)\n            BIO_printf(bio_err, \"turning on non blocking io\\n\");\n        if (BIO_socket_ioctl(s, FIONBIO, &sl) < 0)\n            ERR_print_errors(bio_err);\n    }\n#endif\n\n    if (con == NULL) {\n        con = SSL_new(ctx);\n#ifndef OPENSSL_NO_TLSEXT\n        if (s_tlsextdebug) {\n            SSL_set_tlsext_debug_callback(con, tlsext_cb);\n            SSL_set_tlsext_debug_arg(con, bio_s_out);\n        }\n        if (s_tlsextstatus) {\n            SSL_CTX_set_tlsext_status_cb(ctx, cert_status_cb);\n            tlscstatp.err = bio_err;\n            SSL_CTX_set_tlsext_status_arg(ctx, &tlscstatp);\n        }\n#endif\n#ifndef OPENSSL_NO_KRB5\n        if ((kctx = kssl_ctx_new()) != NULL) {\n            SSL_set0_kssl_ctx(con, kctx);\n            kssl_ctx_setstring(kctx, KSSL_SERVICE, KRB5SVC);\n            kssl_ctx_setstring(kctx, KSSL_KEYTAB, KRB5KEYTAB);\n        }\n#endif                          /* OPENSSL_NO_KRB5 */\n        if (context)\n            SSL_set_session_id_context(con, context, strlen((char *)context));\n    }\n    SSL_clear(con);\n#if 0\n# ifdef TLSEXT_TYPE_opaque_prf_input\n    SSL_set_tlsext_opaque_prf_input(con, \"Test server\", 11);\n# endif\n#endif\n\n    if (stype == SOCK_DGRAM) {\n\n        sbio = BIO_new_dgram(s, BIO_NOCLOSE);\n\n        if (enable_timeouts) {\n            timeout.tv_sec = 0;\n            timeout.tv_usec = DGRAM_RCV_TIMEOUT;\n            BIO_ctrl(sbio, BIO_CTRL_DGRAM_SET_RECV_TIMEOUT, 0, &timeout);\n\n            timeout.tv_sec = 0;\n            timeout.tv_usec = DGRAM_SND_TIMEOUT;\n            BIO_ctrl(sbio, BIO_CTRL_DGRAM_SET_SEND_TIMEOUT, 0, &timeout);\n        }\n\n        if (socket_mtu) {\n            if (socket_mtu < DTLS_get_link_min_mtu(con)) {\n                BIO_printf(bio_err, \"MTU too small. Must be at least %ld\\n\",\n                           DTLS_get_link_min_mtu(con));\n                ret = -1;\n                BIO_free(sbio);\n                goto err;\n            }\n            SSL_set_options(con, SSL_OP_NO_QUERY_MTU);\n            if (!DTLS_set_link_mtu(con, socket_mtu)) {\n                BIO_printf(bio_err, \"Failed to set MTU\\n\");\n                ret = -1;\n                BIO_free(sbio);\n                goto err;\n            }\n        } else\n            /* want to do MTU discovery */\n            BIO_ctrl(sbio, BIO_CTRL_DGRAM_MTU_DISCOVER, 0, NULL);\n\n        /* turn on cookie exchange */\n        SSL_set_options(con, SSL_OP_COOKIE_EXCHANGE);\n    } else\n        sbio = BIO_new_socket(s, BIO_NOCLOSE);\n\n    if (s_nbio_test) {\n        BIO *test;\n\n        test = BIO_new(BIO_f_nbio_test());\n        sbio = BIO_push(test, sbio);\n    }\n#ifndef OPENSSL_NO_JPAKE\n    if (jpake_secret)\n        jpake_server_auth(bio_s_out, sbio, jpake_secret);\n#endif\n\n    SSL_set_bio(con, sbio, sbio);\n    SSL_set_accept_state(con);\n    /* SSL_set_fd(con,s); */\n\n    if (s_debug) {\n        SSL_set_debug(con, 1);\n        BIO_set_callback(SSL_get_rbio(con), bio_dump_callback);\n        BIO_set_callback_arg(SSL_get_rbio(con), (char *)bio_s_out);\n    }\n    if (s_msg) {\n#ifndef OPENSSL_NO_SSL_TRACE\n        if (s_msg == 2)\n            SSL_set_msg_callback(con, SSL_trace);\n        else\n#endif\n            SSL_set_msg_callback(con, msg_cb);\n        SSL_set_msg_callback_arg(con, bio_s_msg ? bio_s_msg : bio_s_out);\n    }\n#ifndef OPENSSL_NO_TLSEXT\n    if (s_tlsextdebug) {\n        SSL_set_tlsext_debug_callback(con, tlsext_cb);\n        SSL_set_tlsext_debug_arg(con, bio_s_out);\n    }\n#endif\n\n    width = s + 1;\n    for (;;) {\n        int read_from_terminal;\n        int read_from_sslcon;\n\n        read_from_terminal = 0;\n        read_from_sslcon = SSL_pending(con);\n\n        if (!read_from_sslcon) {\n            FD_ZERO(&readfds);\n#if !defined(OPENSSL_SYS_WINDOWS) && !defined(OPENSSL_SYS_MSDOS) && !defined(OPENSSL_SYS_NETWARE) && !defined(OPENSSL_SYS_BEOS_R5)\n            openssl_fdset(fileno(stdin), &readfds);\n#endif\n            openssl_fdset(s, &readfds);\n            /*\n             * Note: under VMS with SOCKETSHR the second parameter is\n             * currently of type (int *) whereas under other systems it is\n             * (void *) if you don't have a cast it will choke the compiler:\n             * if you do have a cast then you can either go for (int *) or\n             * (void *).\n             */\n#if defined(OPENSSL_SYS_WINDOWS) || defined(OPENSSL_SYS_MSDOS) || defined(OPENSSL_SYS_NETWARE)\n            /*\n             * Under DOS (non-djgpp) and Windows we can't select on stdin:\n             * only on sockets. As a workaround we timeout the select every\n             * second and check for any keypress. In a proper Windows\n             * application we wouldn't do this because it is inefficient.\n             */\n            tv.tv_sec = 1;\n            tv.tv_usec = 0;\n            i = select(width, (void *)&readfds, NULL, NULL, &tv);\n            if ((i < 0) || (!i && !_kbhit()))\n                continue;\n            if (_kbhit())\n                read_from_terminal = 1;\n#elif defined(OPENSSL_SYS_BEOS_R5)\n            /* Under BeOS-R5 the situation is similar to DOS */\n            tv.tv_sec = 1;\n            tv.tv_usec = 0;\n            (void)fcntl(fileno(stdin), F_SETFL, O_NONBLOCK);\n            i = select(width, (void *)&readfds, NULL, NULL, &tv);\n            if ((i < 0) || (!i && read(fileno(stdin), buf, 0) < 0))\n                continue;\n            if (read(fileno(stdin), buf, 0) >= 0)\n                read_from_terminal = 1;\n            (void)fcntl(fileno(stdin), F_SETFL, 0);\n#else\n            if ((SSL_version(con) == DTLS1_VERSION) &&\n                DTLSv1_get_timeout(con, &timeout))\n                timeoutp = &timeout;\n            else\n                timeoutp = NULL;\n\n            i = select(width, (void *)&readfds, NULL, NULL, timeoutp);\n\n            if ((SSL_version(con) == DTLS1_VERSION)\n                && DTLSv1_handle_timeout(con) > 0) {\n                BIO_printf(bio_err, \"TIMEOUT occured\\n\");\n            }\n\n            if (i <= 0)\n                continue;\n            if (FD_ISSET(fileno(stdin), &readfds))\n                read_from_terminal = 1;\n#endif\n            if (FD_ISSET(s, &readfds))\n                read_from_sslcon = 1;\n        }\n        if (read_from_terminal) {\n            if (s_crlf) {\n                int j, lf_num;\n\n                i = raw_read_stdin(buf, bufsize / 2);\n                lf_num = 0;\n                /* both loops are skipped when i <= 0 */\n                for (j = 0; j < i; j++)\n                    if (buf[j] == '\\n')\n                        lf_num++;\n                for (j = i - 1; j >= 0; j--) {\n                    buf[j + lf_num] = buf[j];\n                    if (buf[j] == '\\n') {\n                        lf_num--;\n                        i++;\n                        buf[j + lf_num] = '\\r';\n                    }\n                }\n                assert(lf_num == 0);\n            } else\n                i = raw_read_stdin(buf, bufsize);\n            if (!s_quiet && !s_brief) {\n                if ((i <= 0) || (buf[0] == 'Q')) {\n                    BIO_printf(bio_s_out, \"DONE\\n\");\n                    SHUTDOWN(s);\n                    close_accept_socket();\n                    ret = -11;\n                    goto err;\n                }\n                if ((i <= 0) || (buf[0] == 'q')) {\n                    BIO_printf(bio_s_out, \"DONE\\n\");\n                    if (SSL_version(con) != DTLS1_VERSION)\n                        SHUTDOWN(s);\n                    /*\n                     * close_accept_socket(); ret= -11;\n                     */\n                    goto err;\n                }\n#ifndef OPENSSL_NO_HEARTBEATS\n                if ((buf[0] == 'B') && ((buf[1] == '\\n') || (buf[1] == '\\r'))) {\n                    BIO_printf(bio_err, \"HEARTBEATING\\n\");\n                    SSL_heartbeat(con);\n                    i = 0;\n                    continue;\n                }\n#endif\n                if ((buf[0] == 'r') && ((buf[1] == '\\n') || (buf[1] == '\\r'))) {\n                    SSL_renegotiate(con);\n                    i = SSL_do_handshake(con);\n                    printf(\"SSL_do_handshake -> %d\\n\", i);\n                    i = 0;      /* 13; */\n                    continue;\n                    /*\n                     * strcpy(buf,\"server side RE-NEGOTIATE\\n\");\n                     */\n                }\n                if ((buf[0] == 'R') && ((buf[1] == '\\n') || (buf[1] == '\\r'))) {\n                    SSL_set_verify(con,\n                                   SSL_VERIFY_PEER | SSL_VERIFY_CLIENT_ONCE,\n                                   NULL);\n                    SSL_renegotiate(con);\n                    i = SSL_do_handshake(con);\n                    printf(\"SSL_do_handshake -> %d\\n\", i);\n                    i = 0;      /* 13; */\n                    continue;\n                    /*\n                     * strcpy(buf,\"server side RE-NEGOTIATE asking for client\n                     * cert\\n\");\n                     */\n                }\n                if (buf[0] == 'P') {\n                    static const char *str = \"Lets print some clear text\\n\";\n                    BIO_write(SSL_get_wbio(con), str, strlen(str));\n                }\n                if (buf[0] == 'S') {\n                    print_stats(bio_s_out, SSL_get_SSL_CTX(con));\n                }\n            }\n#ifdef CHARSET_EBCDIC\n            ebcdic2ascii(buf, buf, i);\n#endif\n            l = k = 0;\n            for (;;) {\n                /* should do a select for the write */\n#ifdef RENEG\n                {\n                    static count = 0;\n                    if (++count == 100) {\n                        count = 0;\n                        SSL_renegotiate(con);\n                    }\n                }\n#endif\n                k = SSL_write(con, &(buf[l]), (unsigned int)i);\n#ifndef OPENSSL_NO_SRP\n                while (SSL_get_error(con, k) == SSL_ERROR_WANT_X509_LOOKUP) {\n                    BIO_printf(bio_s_out, \"LOOKUP renego during write\\n\");\n                    srp_callback_parm.user =\n                        SRP_VBASE_get_by_user(srp_callback_parm.vb,\n                                              srp_callback_parm.login);\n                    if (srp_callback_parm.user)\n                        BIO_printf(bio_s_out, \"LOOKUP done %s\\n\",\n                                   srp_callback_parm.user->info);\n                    else\n                        BIO_printf(bio_s_out, \"LOOKUP not successful\\n\");\n                    k = SSL_write(con, &(buf[l]), (unsigned int)i);\n                }\n#endif\n                switch (SSL_get_error(con, k)) {\n                case SSL_ERROR_NONE:\n                    break;\n                case SSL_ERROR_WANT_WRITE:\n                case SSL_ERROR_WANT_READ:\n                case SSL_ERROR_WANT_X509_LOOKUP:\n                    BIO_printf(bio_s_out, \"Write BLOCK\\n\");\n                    break;\n                case SSL_ERROR_SYSCALL:\n                case SSL_ERROR_SSL:\n                    BIO_printf(bio_s_out, \"ERROR\\n\");\n                    ERR_print_errors(bio_err);\n                    ret = 1;\n                    goto err;\n                    /* break; */\n                case SSL_ERROR_ZERO_RETURN:\n                    BIO_printf(bio_s_out, \"DONE\\n\");\n                    ret = 1;\n                    goto err;\n                }\n                if (k > 0) {\n                    l += k;\n                    i -= k;\n                }\n                if (i <= 0)\n                    break;\n            }\n        }\n        if (read_from_sslcon) {\n            if (!SSL_is_init_finished(con)) {\n                i = init_ssl_connection(con);\n\n                if (i < 0) {\n                    ret = 0;\n                    goto err;\n                } else if (i == 0) {\n                    ret = 1;\n                    goto err;\n                }\n            } else {\n again:\n                i = SSL_read(con, (char *)buf, bufsize);\n#ifndef OPENSSL_NO_SRP\n                while (SSL_get_error(con, i) == SSL_ERROR_WANT_X509_LOOKUP) {\n                    BIO_printf(bio_s_out, \"LOOKUP renego during read\\n\");\n                    srp_callback_parm.user =\n                        SRP_VBASE_get_by_user(srp_callback_parm.vb,\n                                              srp_callback_parm.login);\n                    if (srp_callback_parm.user)\n                        BIO_printf(bio_s_out, \"LOOKUP done %s\\n\",\n                                   srp_callback_parm.user->info);\n                    else\n                        BIO_printf(bio_s_out, \"LOOKUP not successful\\n\");\n                    i = SSL_read(con, (char *)buf, bufsize);\n                }\n#endif\n                switch (SSL_get_error(con, i)) {\n                case SSL_ERROR_NONE:\n#ifdef CHARSET_EBCDIC\n                    ascii2ebcdic(buf, buf, i);\n#endif\n                    raw_write_stdout(buf, (unsigned int)i);\n                    if (SSL_pending(con))\n                        goto again;\n                    break;\n                case SSL_ERROR_WANT_WRITE:\n                case SSL_ERROR_WANT_READ:\n                    BIO_printf(bio_s_out, \"Read BLOCK\\n\");\n                    break;\n                case SSL_ERROR_SYSCALL:\n                case SSL_ERROR_SSL:\n                    BIO_printf(bio_s_out, \"ERROR\\n\");\n                    ERR_print_errors(bio_err);\n                    ret = 1;\n                    goto err;\n                case SSL_ERROR_ZERO_RETURN:\n                    BIO_printf(bio_s_out, \"DONE\\n\");\n                    ret = 1;\n                    goto err;\n                }\n            }\n        }\n    }\n err:\n    if (con != NULL) {\n        BIO_printf(bio_s_out, \"shutting down SSL\\n\");\n#if 1\n        SSL_set_shutdown(con, SSL_SENT_SHUTDOWN | SSL_RECEIVED_SHUTDOWN);\n#else\n        SSL_shutdown(con);\n#endif\n        SSL_free(con);\n    }\n    BIO_printf(bio_s_out, \"CONNECTION CLOSED\\n\");\n    if (buf != NULL) {\n        OPENSSL_cleanse(buf, bufsize);\n        OPENSSL_free(buf);\n    }\n    if (ret >= 0)\n        BIO_printf(bio_s_out, \"ACCEPT\\n\");\n    return (ret);\n}",
        "func": "static int sv_body(char *hostname, int s, int stype, unsigned char *context)\n{\n    char *buf = NULL;\n    fd_set readfds;\n    int ret = 1, width;\n    int k, i;\n    unsigned long l;\n    SSL *con = NULL;\n    BIO *sbio;\n#ifndef OPENSSL_NO_KRB5\n    KSSL_CTX *kctx;\n#endif\n    struct timeval timeout;\n#if defined(OPENSSL_SYS_WINDOWS) || defined(OPENSSL_SYS_MSDOS) || defined(OPENSSL_SYS_NETWARE) || defined(OPENSSL_SYS_BEOS_R5)\n    struct timeval tv;\n#else\n    struct timeval *timeoutp;\n#endif\n\n    if ((buf = OPENSSL_malloc(bufsize)) == NULL) {\n        BIO_printf(bio_err, \"out of memory\\n\");\n        goto err;\n    }\n#ifdef FIONBIO\n    if (s_nbio) {\n        unsigned long sl = 1;\n\n        if (!s_quiet)\n            BIO_printf(bio_err, \"turning on non blocking io\\n\");\n        if (BIO_socket_ioctl(s, FIONBIO, &sl) < 0)\n            ERR_print_errors(bio_err);\n    }\n#endif\n\n    if (con == NULL) {\n        con = SSL_new(ctx);\n#ifndef OPENSSL_NO_TLSEXT\n        if (s_tlsextdebug) {\n            SSL_set_tlsext_debug_callback(con, tlsext_cb);\n            SSL_set_tlsext_debug_arg(con, bio_s_out);\n        }\n        if (s_tlsextstatus) {\n            SSL_CTX_set_tlsext_status_cb(ctx, cert_status_cb);\n            tlscstatp.err = bio_err;\n            SSL_CTX_set_tlsext_status_arg(ctx, &tlscstatp);\n        }\n#endif\n#ifndef OPENSSL_NO_KRB5\n        if ((kctx = kssl_ctx_new()) != NULL) {\n            SSL_set0_kssl_ctx(con, kctx);\n            kssl_ctx_setstring(kctx, KSSL_SERVICE, KRB5SVC);\n            kssl_ctx_setstring(kctx, KSSL_KEYTAB, KRB5KEYTAB);\n        }\n#endif                          /* OPENSSL_NO_KRB5 */\n        if (context)\n            SSL_set_session_id_context(con, context, strlen((char *)context));\n    }\n    SSL_clear(con);\n#if 0\n# ifdef TLSEXT_TYPE_opaque_prf_input\n    SSL_set_tlsext_opaque_prf_input(con, \"Test server\", 11);\n# endif\n#endif\n\n    if (stype == SOCK_DGRAM) {\n\n        sbio = BIO_new_dgram(s, BIO_NOCLOSE);\n\n        if (enable_timeouts) {\n            timeout.tv_sec = 0;\n            timeout.tv_usec = DGRAM_RCV_TIMEOUT;\n            BIO_ctrl(sbio, BIO_CTRL_DGRAM_SET_RECV_TIMEOUT, 0, &timeout);\n\n            timeout.tv_sec = 0;\n            timeout.tv_usec = DGRAM_SND_TIMEOUT;\n            BIO_ctrl(sbio, BIO_CTRL_DGRAM_SET_SEND_TIMEOUT, 0, &timeout);\n        }\n\n        if (socket_mtu) {\n            if (socket_mtu < DTLS_get_link_min_mtu(con)) {\n                BIO_printf(bio_err, \"MTU too small. Must be at least %ld\\n\",\n                           DTLS_get_link_min_mtu(con));\n                ret = -1;\n                BIO_free(sbio);\n                goto err;\n            }\n            SSL_set_options(con, SSL_OP_NO_QUERY_MTU);\n            if (!DTLS_set_link_mtu(con, socket_mtu)) {\n                BIO_printf(bio_err, \"Failed to set MTU\\n\");\n                ret = -1;\n                BIO_free(sbio);\n                goto err;\n            }\n        } else\n            /* want to do MTU discovery */\n            BIO_ctrl(sbio, BIO_CTRL_DGRAM_MTU_DISCOVER, 0, NULL);\n\n        /* turn on cookie exchange */\n        SSL_set_options(con, SSL_OP_COOKIE_EXCHANGE);\n    } else\n        sbio = BIO_new_socket(s, BIO_NOCLOSE);\n\n    if (s_nbio_test) {\n        BIO *test;\n\n        test = BIO_new(BIO_f_nbio_test());\n        sbio = BIO_push(test, sbio);\n    }\n#ifndef OPENSSL_NO_JPAKE\n    if (jpake_secret)\n        jpake_server_auth(bio_s_out, sbio, jpake_secret);\n#endif\n\n    SSL_set_bio(con, sbio, sbio);\n    SSL_set_accept_state(con);\n    /* SSL_set_fd(con,s); */\n\n    if (s_debug) {\n        SSL_set_debug(con, 1);\n        BIO_set_callback(SSL_get_rbio(con), bio_dump_callback);\n        BIO_set_callback_arg(SSL_get_rbio(con), (char *)bio_s_out);\n    }\n    if (s_msg) {\n#ifndef OPENSSL_NO_SSL_TRACE\n        if (s_msg == 2)\n            SSL_set_msg_callback(con, SSL_trace);\n        else\n#endif\n            SSL_set_msg_callback(con, msg_cb);\n        SSL_set_msg_callback_arg(con, bio_s_msg ? bio_s_msg : bio_s_out);\n    }\n#ifndef OPENSSL_NO_TLSEXT\n    if (s_tlsextdebug) {\n        SSL_set_tlsext_debug_callback(con, tlsext_cb);\n        SSL_set_tlsext_debug_arg(con, bio_s_out);\n    }\n#endif\n\n    width = s + 1;\n    for (;;) {\n        int read_from_terminal;\n        int read_from_sslcon;\n\n        read_from_terminal = 0;\n        read_from_sslcon = SSL_pending(con);\n\n        if (!read_from_sslcon) {\n            FD_ZERO(&readfds);\n#if !defined(OPENSSL_SYS_WINDOWS) && !defined(OPENSSL_SYS_MSDOS) && !defined(OPENSSL_SYS_NETWARE) && !defined(OPENSSL_SYS_BEOS_R5)\n            openssl_fdset(fileno(stdin), &readfds);\n#endif\n            openssl_fdset(s, &readfds);\n            /*\n             * Note: under VMS with SOCKETSHR the second parameter is\n             * currently of type (int *) whereas under other systems it is\n             * (void *) if you don't have a cast it will choke the compiler:\n             * if you do have a cast then you can either go for (int *) or\n             * (void *).\n             */\n#if defined(OPENSSL_SYS_WINDOWS) || defined(OPENSSL_SYS_MSDOS) || defined(OPENSSL_SYS_NETWARE)\n            /*\n             * Under DOS (non-djgpp) and Windows we can't select on stdin:\n             * only on sockets. As a workaround we timeout the select every\n             * second and check for any keypress. In a proper Windows\n             * application we wouldn't do this because it is inefficient.\n             */\n            tv.tv_sec = 1;\n            tv.tv_usec = 0;\n            i = select(width, (void *)&readfds, NULL, NULL, &tv);\n            if ((i < 0) || (!i && !_kbhit()))\n                continue;\n            if (_kbhit())\n                read_from_terminal = 1;\n#elif defined(OPENSSL_SYS_BEOS_R5)\n            /* Under BeOS-R5 the situation is similar to DOS */\n            tv.tv_sec = 1;\n            tv.tv_usec = 0;\n            (void)fcntl(fileno(stdin), F_SETFL, O_NONBLOCK);\n            i = select(width, (void *)&readfds, NULL, NULL, &tv);\n            if ((i < 0) || (!i && read(fileno(stdin), buf, 0) < 0))\n                continue;\n            if (read(fileno(stdin), buf, 0) >= 0)\n                read_from_terminal = 1;\n            (void)fcntl(fileno(stdin), F_SETFL, 0);\n#else\n            if ((SSL_version(con) == DTLS1_VERSION) &&\n                DTLSv1_get_timeout(con, &timeout))\n                timeoutp = &timeout;\n            else\n                timeoutp = NULL;\n\n            i = select(width, (void *)&readfds, NULL, NULL, timeoutp);\n\n            if ((SSL_version(con) == DTLS1_VERSION)\n                && DTLSv1_handle_timeout(con) > 0) {\n                BIO_printf(bio_err, \"TIMEOUT occured\\n\");\n            }\n\n            if (i <= 0)\n                continue;\n            if (FD_ISSET(fileno(stdin), &readfds))\n                read_from_terminal = 1;\n#endif\n            if (FD_ISSET(s, &readfds))\n                read_from_sslcon = 1;\n        }\n        if (read_from_terminal) {\n            if (s_crlf) {\n                int j, lf_num;\n\n                i = raw_read_stdin(buf, bufsize / 2);\n                lf_num = 0;\n                /* both loops are skipped when i <= 0 */\n                for (j = 0; j < i; j++)\n                    if (buf[j] == '\\n')\n                        lf_num++;\n                for (j = i - 1; j >= 0; j--) {\n                    buf[j + lf_num] = buf[j];\n                    if (buf[j] == '\\n') {\n                        lf_num--;\n                        i++;\n                        buf[j + lf_num] = '\\r';\n                    }\n                }\n                assert(lf_num == 0);\n            } else\n                i = raw_read_stdin(buf, bufsize);\n            if (!s_quiet && !s_brief) {\n                if ((i <= 0) || (buf[0] == 'Q')) {\n                    BIO_printf(bio_s_out, \"DONE\\n\");\n                    SHUTDOWN(s);\n                    close_accept_socket();\n                    ret = -11;\n                    goto err;\n                }\n                if ((i <= 0) || (buf[0] == 'q')) {\n                    BIO_printf(bio_s_out, \"DONE\\n\");\n                    if (SSL_version(con) != DTLS1_VERSION)\n                        SHUTDOWN(s);\n                    /*\n                     * close_accept_socket(); ret= -11;\n                     */\n                    goto err;\n                }\n#ifndef OPENSSL_NO_HEARTBEATS\n                if ((buf[0] == 'B') && ((buf[1] == '\\n') || (buf[1] == '\\r'))) {\n                    BIO_printf(bio_err, \"HEARTBEATING\\n\");\n                    SSL_heartbeat(con);\n                    i = 0;\n                    continue;\n                }\n#endif\n                if ((buf[0] == 'r') && ((buf[1] == '\\n') || (buf[1] == '\\r'))) {\n                    SSL_renegotiate(con);\n                    i = SSL_do_handshake(con);\n                    printf(\"SSL_do_handshake -> %d\\n\", i);\n                    i = 0;      /* 13; */\n                    continue;\n                    /*\n                     * strcpy(buf,\"server side RE-NEGOTIATE\\n\");\n                     */\n                }\n                if ((buf[0] == 'R') && ((buf[1] == '\\n') || (buf[1] == '\\r'))) {\n                    SSL_set_verify(con,\n                                   SSL_VERIFY_PEER | SSL_VERIFY_CLIENT_ONCE,\n                                   NULL);\n                    SSL_renegotiate(con);\n                    i = SSL_do_handshake(con);\n                    printf(\"SSL_do_handshake -> %d\\n\", i);\n                    i = 0;      /* 13; */\n                    continue;\n                    /*\n                     * strcpy(buf,\"server side RE-NEGOTIATE asking for client\n                     * cert\\n\");\n                     */\n                }\n                if (buf[0] == 'P') {\n                    static const char *str = \"Lets print some clear text\\n\";\n                    BIO_write(SSL_get_wbio(con), str, strlen(str));\n                }\n                if (buf[0] == 'S') {\n                    print_stats(bio_s_out, SSL_get_SSL_CTX(con));\n                }\n            }\n#ifdef CHARSET_EBCDIC\n            ebcdic2ascii(buf, buf, i);\n#endif\n            l = k = 0;\n            for (;;) {\n                /* should do a select for the write */\n#ifdef RENEG\n                {\n                    static count = 0;\n                    if (++count == 100) {\n                        count = 0;\n                        SSL_renegotiate(con);\n                    }\n                }\n#endif\n                k = SSL_write(con, &(buf[l]), (unsigned int)i);\n#ifndef OPENSSL_NO_SRP\n                while (SSL_get_error(con, k) == SSL_ERROR_WANT_X509_LOOKUP) {\n                    BIO_printf(bio_s_out, \"LOOKUP renego during write\\n\");\n                    SRP_user_pwd_free(srp_callback_parm.user);\n                    srp_callback_parm.user =\n                        SRP_VBASE_get1_by_user(srp_callback_parm.vb,\n                                               srp_callback_parm.login);\n                    if (srp_callback_parm.user)\n                        BIO_printf(bio_s_out, \"LOOKUP done %s\\n\",\n                                   srp_callback_parm.user->info);\n                    else\n                        BIO_printf(bio_s_out, \"LOOKUP not successful\\n\");\n                    k = SSL_write(con, &(buf[l]), (unsigned int)i);\n                }\n#endif\n                switch (SSL_get_error(con, k)) {\n                case SSL_ERROR_NONE:\n                    break;\n                case SSL_ERROR_WANT_WRITE:\n                case SSL_ERROR_WANT_READ:\n                case SSL_ERROR_WANT_X509_LOOKUP:\n                    BIO_printf(bio_s_out, \"Write BLOCK\\n\");\n                    break;\n                case SSL_ERROR_SYSCALL:\n                case SSL_ERROR_SSL:\n                    BIO_printf(bio_s_out, \"ERROR\\n\");\n                    ERR_print_errors(bio_err);\n                    ret = 1;\n                    goto err;\n                    /* break; */\n                case SSL_ERROR_ZERO_RETURN:\n                    BIO_printf(bio_s_out, \"DONE\\n\");\n                    ret = 1;\n                    goto err;\n                }\n                if (k > 0) {\n                    l += k;\n                    i -= k;\n                }\n                if (i <= 0)\n                    break;\n            }\n        }\n        if (read_from_sslcon) {\n            if (!SSL_is_init_finished(con)) {\n                i = init_ssl_connection(con);\n\n                if (i < 0) {\n                    ret = 0;\n                    goto err;\n                } else if (i == 0) {\n                    ret = 1;\n                    goto err;\n                }\n            } else {\n again:\n                i = SSL_read(con, (char *)buf, bufsize);\n#ifndef OPENSSL_NO_SRP\n                while (SSL_get_error(con, i) == SSL_ERROR_WANT_X509_LOOKUP) {\n                    BIO_printf(bio_s_out, \"LOOKUP renego during read\\n\");\n                    SRP_user_pwd_free(srp_callback_parm.user);\n                    srp_callback_parm.user =\n                        SRP_VBASE_get1_by_user(srp_callback_parm.vb,\n                                               srp_callback_parm.login);\n                    if (srp_callback_parm.user)\n                        BIO_printf(bio_s_out, \"LOOKUP done %s\\n\",\n                                   srp_callback_parm.user->info);\n                    else\n                        BIO_printf(bio_s_out, \"LOOKUP not successful\\n\");\n                    i = SSL_read(con, (char *)buf, bufsize);\n                }\n#endif\n                switch (SSL_get_error(con, i)) {\n                case SSL_ERROR_NONE:\n#ifdef CHARSET_EBCDIC\n                    ascii2ebcdic(buf, buf, i);\n#endif\n                    raw_write_stdout(buf, (unsigned int)i);\n                    if (SSL_pending(con))\n                        goto again;\n                    break;\n                case SSL_ERROR_WANT_WRITE:\n                case SSL_ERROR_WANT_READ:\n                    BIO_printf(bio_s_out, \"Read BLOCK\\n\");\n                    break;\n                case SSL_ERROR_SYSCALL:\n                case SSL_ERROR_SSL:\n                    BIO_printf(bio_s_out, \"ERROR\\n\");\n                    ERR_print_errors(bio_err);\n                    ret = 1;\n                    goto err;\n                case SSL_ERROR_ZERO_RETURN:\n                    BIO_printf(bio_s_out, \"DONE\\n\");\n                    ret = 1;\n                    goto err;\n                }\n            }\n        }\n    }\n err:\n    if (con != NULL) {\n        BIO_printf(bio_s_out, \"shutting down SSL\\n\");\n#if 1\n        SSL_set_shutdown(con, SSL_SENT_SHUTDOWN | SSL_RECEIVED_SHUTDOWN);\n#else\n        SSL_shutdown(con);\n#endif\n        SSL_free(con);\n    }\n    BIO_printf(bio_s_out, \"CONNECTION CLOSED\\n\");\n    if (buf != NULL) {\n        OPENSSL_cleanse(buf, bufsize);\n        OPENSSL_free(buf);\n    }\n    if (ret >= 0)\n        BIO_printf(bio_s_out, \"ACCEPT\\n\");\n    return (ret);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -301,9 +301,10 @@\n #ifndef OPENSSL_NO_SRP\n                 while (SSL_get_error(con, k) == SSL_ERROR_WANT_X509_LOOKUP) {\n                     BIO_printf(bio_s_out, \"LOOKUP renego during write\\n\");\n+                    SRP_user_pwd_free(srp_callback_parm.user);\n                     srp_callback_parm.user =\n-                        SRP_VBASE_get_by_user(srp_callback_parm.vb,\n-                                              srp_callback_parm.login);\n+                        SRP_VBASE_get1_by_user(srp_callback_parm.vb,\n+                                               srp_callback_parm.login);\n                     if (srp_callback_parm.user)\n                         BIO_printf(bio_s_out, \"LOOKUP done %s\\n\",\n                                    srp_callback_parm.user->info);\n@@ -357,9 +358,10 @@\n #ifndef OPENSSL_NO_SRP\n                 while (SSL_get_error(con, i) == SSL_ERROR_WANT_X509_LOOKUP) {\n                     BIO_printf(bio_s_out, \"LOOKUP renego during read\\n\");\n+                    SRP_user_pwd_free(srp_callback_parm.user);\n                     srp_callback_parm.user =\n-                        SRP_VBASE_get_by_user(srp_callback_parm.vb,\n-                                              srp_callback_parm.login);\n+                        SRP_VBASE_get1_by_user(srp_callback_parm.vb,\n+                                               srp_callback_parm.login);\n                     if (srp_callback_parm.user)\n                         BIO_printf(bio_s_out, \"LOOKUP done %s\\n\",\n                                    srp_callback_parm.user->info);",
        "diff_line_info": {
            "deleted_lines": [
                "                        SRP_VBASE_get_by_user(srp_callback_parm.vb,",
                "                                              srp_callback_parm.login);",
                "                        SRP_VBASE_get_by_user(srp_callback_parm.vb,",
                "                                              srp_callback_parm.login);"
            ],
            "added_lines": [
                "                    SRP_user_pwd_free(srp_callback_parm.user);",
                "                        SRP_VBASE_get1_by_user(srp_callback_parm.vb,",
                "                                               srp_callback_parm.login);",
                "                    SRP_user_pwd_free(srp_callback_parm.user);",
                "                        SRP_VBASE_get1_by_user(srp_callback_parm.vb,",
                "                                               srp_callback_parm.login);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-0798",
        "func_name": "openssl/SRP_user_pwd_free",
        "description": "Memory leak in the SRP_VBASE_get_by_user implementation in OpenSSL 1.0.1 before 1.0.1s and 1.0.2 before 1.0.2g allows remote attackers to cause a denial of service (memory consumption) by providing an invalid username in a connection attempt, related to apps/s_server.c and crypto/srp/srp_vfy.c.",
        "git_url": "https://git.openssl.org/?p=openssl.git;a=commit;h=259b664f950c2ba66fbf4b0fe5281327904ead21",
        "commit_title": "",
        "commit_text": "CVE-2016-0798: avoid memory leak in SRP  The SRP user database lookup method SRP_VBASE_get_by_user had confusing memory management semantics; the returned pointer was sometimes newly allocated, and sometimes owned by the callee. The calling code has no way of distinguishing these two cases.  Specifically, SRP servers that configure a secret seed to hide valid login information are vulnerable to a memory leak: an attacker connecting with an invalid username can cause a memory leak of around 300 bytes per connection.  Servers that do not configure SRP, or configure SRP but do not configure a seed are not vulnerable.  In Apache, the seed directive is known as SSLSRPUnknownUserSeed.  To mitigate the memory leak, the seed handling in SRP_VBASE_get_by_user is now disabled even if the user has configured a seed.  Applications are advised to migrate to SRP_VBASE_get1_by_user. However, note that OpenSSL makes no strong guarantees about the indistinguishability of valid and invalid logins. In particular, computations are currently not carried out in constant time.  ",
        "func_before": "static void SRP_user_pwd_free(SRP_user_pwd *user_pwd)\n{\n    if (user_pwd == NULL)\n        return;\n    BN_free(user_pwd->s);\n    BN_clear_free(user_pwd->v);\n    OPENSSL_free(user_pwd->id);\n    OPENSSL_free(user_pwd->info);\n    OPENSSL_free(user_pwd);\n}",
        "func": "void SRP_user_pwd_free(SRP_user_pwd *user_pwd)\n{\n    if (user_pwd == NULL)\n        return;\n    BN_free(user_pwd->s);\n    BN_clear_free(user_pwd->v);\n    OPENSSL_free(user_pwd->id);\n    OPENSSL_free(user_pwd->info);\n    OPENSSL_free(user_pwd);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,4 +1,4 @@\n-static void SRP_user_pwd_free(SRP_user_pwd *user_pwd)\n+void SRP_user_pwd_free(SRP_user_pwd *user_pwd)\n {\n     if (user_pwd == NULL)\n         return;",
        "diff_line_info": {
            "deleted_lines": [
                "static void SRP_user_pwd_free(SRP_user_pwd *user_pwd)"
            ],
            "added_lines": [
                "void SRP_user_pwd_free(SRP_user_pwd *user_pwd)"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-0798",
        "func_name": "openssl/SRP_VBASE_get_by_user",
        "description": "Memory leak in the SRP_VBASE_get_by_user implementation in OpenSSL 1.0.1 before 1.0.1s and 1.0.2 before 1.0.2g allows remote attackers to cause a denial of service (memory consumption) by providing an invalid username in a connection attempt, related to apps/s_server.c and crypto/srp/srp_vfy.c.",
        "git_url": "https://git.openssl.org/?p=openssl.git;a=commit;h=259b664f950c2ba66fbf4b0fe5281327904ead21",
        "commit_title": "",
        "commit_text": "CVE-2016-0798: avoid memory leak in SRP  The SRP user database lookup method SRP_VBASE_get_by_user had confusing memory management semantics; the returned pointer was sometimes newly allocated, and sometimes owned by the callee. The calling code has no way of distinguishing these two cases.  Specifically, SRP servers that configure a secret seed to hide valid login information are vulnerable to a memory leak: an attacker connecting with an invalid username can cause a memory leak of around 300 bytes per connection.  Servers that do not configure SRP, or configure SRP but do not configure a seed are not vulnerable.  In Apache, the seed directive is known as SSLSRPUnknownUserSeed.  To mitigate the memory leak, the seed handling in SRP_VBASE_get_by_user is now disabled even if the user has configured a seed.  Applications are advised to migrate to SRP_VBASE_get1_by_user. However, note that OpenSSL makes no strong guarantees about the indistinguishability of valid and invalid logins. In particular, computations are currently not carried out in constant time.  ",
        "func_before": "SRP_user_pwd *SRP_VBASE_get_by_user(SRP_VBASE *vb, char *username)\n{\n    int i;\n    SRP_user_pwd *user;\n    unsigned char digv[SHA_DIGEST_LENGTH];\n    unsigned char digs[SHA_DIGEST_LENGTH];\n    EVP_MD_CTX ctxt;\n\n    if (vb == NULL)\n        return NULL;\n    for (i = 0; i < sk_SRP_user_pwd_num(vb->users_pwd); i++) {\n        user = sk_SRP_user_pwd_value(vb->users_pwd, i);\n        if (strcmp(user->id, username) == 0)\n            return user;\n    }\n    if ((vb->seed_key == NULL) ||\n        (vb->default_g == NULL) || (vb->default_N == NULL))\n        return NULL;\n\n/* if the user is unknown we set parameters as well if we have a seed_key */\n\n    if ((user = SRP_user_pwd_new()) == NULL)\n        return NULL;\n\n    SRP_user_pwd_set_gN(user, vb->default_g, vb->default_N);\n\n    if (!SRP_user_pwd_set_ids(user, username, NULL))\n        goto err;\n\n    if (RAND_pseudo_bytes(digv, SHA_DIGEST_LENGTH) < 0)\n        goto err;\n    EVP_MD_CTX_init(&ctxt);\n    EVP_DigestInit_ex(&ctxt, EVP_sha1(), NULL);\n    EVP_DigestUpdate(&ctxt, vb->seed_key, strlen(vb->seed_key));\n    EVP_DigestUpdate(&ctxt, username, strlen(username));\n    EVP_DigestFinal_ex(&ctxt, digs, NULL);\n    EVP_MD_CTX_cleanup(&ctxt);\n    if (SRP_user_pwd_set_sv_BN\n        (user, BN_bin2bn(digs, SHA_DIGEST_LENGTH, NULL),\n         BN_bin2bn(digv, SHA_DIGEST_LENGTH, NULL)))\n        return user;\n\n err:SRP_user_pwd_free(user);\n    return NULL;\n}",
        "func": "SRP_user_pwd *SRP_VBASE_get_by_user(SRP_VBASE *vb, char *username)\n{\n    return find_user(vb, username);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,45 +1,4 @@\n SRP_user_pwd *SRP_VBASE_get_by_user(SRP_VBASE *vb, char *username)\n {\n-    int i;\n-    SRP_user_pwd *user;\n-    unsigned char digv[SHA_DIGEST_LENGTH];\n-    unsigned char digs[SHA_DIGEST_LENGTH];\n-    EVP_MD_CTX ctxt;\n-\n-    if (vb == NULL)\n-        return NULL;\n-    for (i = 0; i < sk_SRP_user_pwd_num(vb->users_pwd); i++) {\n-        user = sk_SRP_user_pwd_value(vb->users_pwd, i);\n-        if (strcmp(user->id, username) == 0)\n-            return user;\n-    }\n-    if ((vb->seed_key == NULL) ||\n-        (vb->default_g == NULL) || (vb->default_N == NULL))\n-        return NULL;\n-\n-/* if the user is unknown we set parameters as well if we have a seed_key */\n-\n-    if ((user = SRP_user_pwd_new()) == NULL)\n-        return NULL;\n-\n-    SRP_user_pwd_set_gN(user, vb->default_g, vb->default_N);\n-\n-    if (!SRP_user_pwd_set_ids(user, username, NULL))\n-        goto err;\n-\n-    if (RAND_pseudo_bytes(digv, SHA_DIGEST_LENGTH) < 0)\n-        goto err;\n-    EVP_MD_CTX_init(&ctxt);\n-    EVP_DigestInit_ex(&ctxt, EVP_sha1(), NULL);\n-    EVP_DigestUpdate(&ctxt, vb->seed_key, strlen(vb->seed_key));\n-    EVP_DigestUpdate(&ctxt, username, strlen(username));\n-    EVP_DigestFinal_ex(&ctxt, digs, NULL);\n-    EVP_MD_CTX_cleanup(&ctxt);\n-    if (SRP_user_pwd_set_sv_BN\n-        (user, BN_bin2bn(digs, SHA_DIGEST_LENGTH, NULL),\n-         BN_bin2bn(digv, SHA_DIGEST_LENGTH, NULL)))\n-        return user;\n-\n- err:SRP_user_pwd_free(user);\n-    return NULL;\n+    return find_user(vb, username);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    int i;",
                "    SRP_user_pwd *user;",
                "    unsigned char digv[SHA_DIGEST_LENGTH];",
                "    unsigned char digs[SHA_DIGEST_LENGTH];",
                "    EVP_MD_CTX ctxt;",
                "",
                "    if (vb == NULL)",
                "        return NULL;",
                "    for (i = 0; i < sk_SRP_user_pwd_num(vb->users_pwd); i++) {",
                "        user = sk_SRP_user_pwd_value(vb->users_pwd, i);",
                "        if (strcmp(user->id, username) == 0)",
                "            return user;",
                "    }",
                "    if ((vb->seed_key == NULL) ||",
                "        (vb->default_g == NULL) || (vb->default_N == NULL))",
                "        return NULL;",
                "",
                "/* if the user is unknown we set parameters as well if we have a seed_key */",
                "",
                "    if ((user = SRP_user_pwd_new()) == NULL)",
                "        return NULL;",
                "",
                "    SRP_user_pwd_set_gN(user, vb->default_g, vb->default_N);",
                "",
                "    if (!SRP_user_pwd_set_ids(user, username, NULL))",
                "        goto err;",
                "",
                "    if (RAND_pseudo_bytes(digv, SHA_DIGEST_LENGTH) < 0)",
                "        goto err;",
                "    EVP_MD_CTX_init(&ctxt);",
                "    EVP_DigestInit_ex(&ctxt, EVP_sha1(), NULL);",
                "    EVP_DigestUpdate(&ctxt, vb->seed_key, strlen(vb->seed_key));",
                "    EVP_DigestUpdate(&ctxt, username, strlen(username));",
                "    EVP_DigestFinal_ex(&ctxt, digs, NULL);",
                "    EVP_MD_CTX_cleanup(&ctxt);",
                "    if (SRP_user_pwd_set_sv_BN",
                "        (user, BN_bin2bn(digs, SHA_DIGEST_LENGTH, NULL),",
                "         BN_bin2bn(digv, SHA_DIGEST_LENGTH, NULL)))",
                "        return user;",
                "",
                " err:SRP_user_pwd_free(user);",
                "    return NULL;"
            ],
            "added_lines": [
                "    return find_user(vb, username);"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1339",
        "func_name": "torvalds/linux/cuse_channel_release",
        "description": "Memory leak in the cuse_channel_release function in fs/fuse/cuse.c in the Linux kernel before 4.4 allows local users to cause a denial of service (memory consumption) or possibly have unspecified other impact by opening /dev/cuse many times.",
        "git_url": "https://github.com/torvalds/linux/commit/2c5816b4beccc8ba709144539f6fdd764f8fa49c",
        "commit_title": "cuse: fix memory leak",
        "commit_text": " The problem is that fuse_dev_alloc() acquires an extra reference to cc.fc, and the original ref count is never dropped.  Cc: <stable@vger.kernel.org> # v4.2+",
        "func_before": "static int cuse_channel_release(struct inode *inode, struct file *file)\n{\n\tstruct fuse_dev *fud = file->private_data;\n\tstruct cuse_conn *cc = fc_to_cc(fud->fc);\n\tint rc;\n\n\t/* remove from the conntbl, no more access from this point on */\n\tmutex_lock(&cuse_lock);\n\tlist_del_init(&cc->list);\n\tmutex_unlock(&cuse_lock);\n\n\t/* remove device */\n\tif (cc->dev)\n\t\tdevice_unregister(cc->dev);\n\tif (cc->cdev) {\n\t\tunregister_chrdev_region(cc->cdev->dev, 1);\n\t\tcdev_del(cc->cdev);\n\t}\n\n\trc = fuse_dev_release(inode, file);\t/* puts the base reference */\n\n\treturn rc;\n}",
        "func": "static int cuse_channel_release(struct inode *inode, struct file *file)\n{\n\tstruct fuse_dev *fud = file->private_data;\n\tstruct cuse_conn *cc = fc_to_cc(fud->fc);\n\tint rc;\n\n\t/* remove from the conntbl, no more access from this point on */\n\tmutex_lock(&cuse_lock);\n\tlist_del_init(&cc->list);\n\tmutex_unlock(&cuse_lock);\n\n\t/* remove device */\n\tif (cc->dev)\n\t\tdevice_unregister(cc->dev);\n\tif (cc->cdev) {\n\t\tunregister_chrdev_region(cc->cdev->dev, 1);\n\t\tcdev_del(cc->cdev);\n\t}\n\t/* Base reference is now owned by \"fud\" */\n\tfuse_conn_put(&cc->fc);\n\n\trc = fuse_dev_release(inode, file);\t/* puts the base reference */\n\n\treturn rc;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -16,6 +16,8 @@\n \t\tunregister_chrdev_region(cc->cdev->dev, 1);\n \t\tcdev_del(cc->cdev);\n \t}\n+\t/* Base reference is now owned by \"fud\" */\n+\tfuse_conn_put(&cc->fc);\n \n \trc = fuse_dev_release(inode, file);\t/* puts the base reference */\n ",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t/* Base reference is now owned by \"fud\" */",
                "\tfuse_conn_put(&cc->fc);"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1339",
        "func_name": "torvalds/linux/fuse_device_clone",
        "description": "Memory leak in the cuse_channel_release function in fs/fuse/cuse.c in the Linux kernel before 4.4 allows local users to cause a denial of service (memory consumption) or possibly have unspecified other impact by opening /dev/cuse many times.",
        "git_url": "https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?h=cc080e9e9be16ccf26135d366d7d2b65209f1d56",
        "commit_title": "Allow fuse device clones to refer to be distinguished.  This patch just",
        "commit_text": "adds the infrastructure by associating a separate \"struct fuse_dev\" with each clone.  ",
        "func_before": "static int fuse_device_clone(struct fuse_conn *fc, struct file *new)\n{\n\tif (new->private_data)\n\t\treturn -EINVAL;\n\n\tnew->private_data = fuse_conn_get(fc);\n\n\treturn 0;\n}",
        "func": "static int fuse_device_clone(struct fuse_conn *fc, struct file *new)\n{\n\tstruct fuse_dev *fud;\n\n\tif (new->private_data)\n\t\treturn -EINVAL;\n\n\tfud = fuse_dev_alloc(fc);\n\tif (!fud)\n\t\treturn -ENOMEM;\n\n\tnew->private_data = fud;\n\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,9 +1,15 @@\n static int fuse_device_clone(struct fuse_conn *fc, struct file *new)\n {\n+\tstruct fuse_dev *fud;\n+\n \tif (new->private_data)\n \t\treturn -EINVAL;\n \n-\tnew->private_data = fuse_conn_get(fc);\n+\tfud = fuse_dev_alloc(fc);\n+\tif (!fud)\n+\t\treturn -ENOMEM;\n+\n+\tnew->private_data = fud;\n \n \treturn 0;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tnew->private_data = fuse_conn_get(fc);"
            ],
            "added_lines": [
                "\tstruct fuse_dev *fud;",
                "",
                "\tfud = fuse_dev_alloc(fc);",
                "\tif (!fud)",
                "\t\treturn -ENOMEM;",
                "",
                "\tnew->private_data = fud;"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1339",
        "func_name": "torvalds/linux/fuse_dev_splice_read",
        "description": "Memory leak in the cuse_channel_release function in fs/fuse/cuse.c in the Linux kernel before 4.4 allows local users to cause a denial of service (memory consumption) or possibly have unspecified other impact by opening /dev/cuse many times.",
        "git_url": "https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?h=cc080e9e9be16ccf26135d366d7d2b65209f1d56",
        "commit_title": "Allow fuse device clones to refer to be distinguished.  This patch just",
        "commit_text": "adds the infrastructure by associating a separate \"struct fuse_dev\" with each clone.  ",
        "func_before": "static ssize_t fuse_dev_splice_read(struct file *in, loff_t *ppos,\n\t\t\t\t    struct pipe_inode_info *pipe,\n\t\t\t\t    size_t len, unsigned int flags)\n{\n\tint ret;\n\tint page_nr = 0;\n\tint do_wakeup = 0;\n\tstruct pipe_buffer *bufs;\n\tstruct fuse_copy_state cs;\n\tstruct fuse_conn *fc = fuse_get_conn(in);\n\tif (!fc)\n\t\treturn -EPERM;\n\n\tbufs = kmalloc(pipe->buffers * sizeof(struct pipe_buffer), GFP_KERNEL);\n\tif (!bufs)\n\t\treturn -ENOMEM;\n\n\tfuse_copy_init(&cs, 1, NULL);\n\tcs.pipebufs = bufs;\n\tcs.pipe = pipe;\n\tret = fuse_dev_do_read(fc, in, &cs, len);\n\tif (ret < 0)\n\t\tgoto out;\n\n\tret = 0;\n\tpipe_lock(pipe);\n\n\tif (!pipe->readers) {\n\t\tsend_sig(SIGPIPE, current, 0);\n\t\tif (!ret)\n\t\t\tret = -EPIPE;\n\t\tgoto out_unlock;\n\t}\n\n\tif (pipe->nrbufs + cs.nr_segs > pipe->buffers) {\n\t\tret = -EIO;\n\t\tgoto out_unlock;\n\t}\n\n\twhile (page_nr < cs.nr_segs) {\n\t\tint newbuf = (pipe->curbuf + pipe->nrbufs) & (pipe->buffers - 1);\n\t\tstruct pipe_buffer *buf = pipe->bufs + newbuf;\n\n\t\tbuf->page = bufs[page_nr].page;\n\t\tbuf->offset = bufs[page_nr].offset;\n\t\tbuf->len = bufs[page_nr].len;\n\t\t/*\n\t\t * Need to be careful about this.  Having buf->ops in module\n\t\t * code can Oops if the buffer persists after module unload.\n\t\t */\n\t\tbuf->ops = &nosteal_pipe_buf_ops;\n\n\t\tpipe->nrbufs++;\n\t\tpage_nr++;\n\t\tret += buf->len;\n\n\t\tif (pipe->files)\n\t\t\tdo_wakeup = 1;\n\t}\n\nout_unlock:\n\tpipe_unlock(pipe);\n\n\tif (do_wakeup) {\n\t\tsmp_mb();\n\t\tif (waitqueue_active(&pipe->wait))\n\t\t\twake_up_interruptible(&pipe->wait);\n\t\tkill_fasync(&pipe->fasync_readers, SIGIO, POLL_IN);\n\t}\n\nout:\n\tfor (; page_nr < cs.nr_segs; page_nr++)\n\t\tpage_cache_release(bufs[page_nr].page);\n\n\tkfree(bufs);\n\treturn ret;\n}",
        "func": "static ssize_t fuse_dev_splice_read(struct file *in, loff_t *ppos,\n\t\t\t\t    struct pipe_inode_info *pipe,\n\t\t\t\t    size_t len, unsigned int flags)\n{\n\tint ret;\n\tint page_nr = 0;\n\tint do_wakeup = 0;\n\tstruct pipe_buffer *bufs;\n\tstruct fuse_copy_state cs;\n\tstruct fuse_dev *fud = fuse_get_dev(in);\n\n\tif (!fud)\n\t\treturn -EPERM;\n\n\tbufs = kmalloc(pipe->buffers * sizeof(struct pipe_buffer), GFP_KERNEL);\n\tif (!bufs)\n\t\treturn -ENOMEM;\n\n\tfuse_copy_init(&cs, 1, NULL);\n\tcs.pipebufs = bufs;\n\tcs.pipe = pipe;\n\tret = fuse_dev_do_read(fud->fc, in, &cs, len);\n\tif (ret < 0)\n\t\tgoto out;\n\n\tret = 0;\n\tpipe_lock(pipe);\n\n\tif (!pipe->readers) {\n\t\tsend_sig(SIGPIPE, current, 0);\n\t\tif (!ret)\n\t\t\tret = -EPIPE;\n\t\tgoto out_unlock;\n\t}\n\n\tif (pipe->nrbufs + cs.nr_segs > pipe->buffers) {\n\t\tret = -EIO;\n\t\tgoto out_unlock;\n\t}\n\n\twhile (page_nr < cs.nr_segs) {\n\t\tint newbuf = (pipe->curbuf + pipe->nrbufs) & (pipe->buffers - 1);\n\t\tstruct pipe_buffer *buf = pipe->bufs + newbuf;\n\n\t\tbuf->page = bufs[page_nr].page;\n\t\tbuf->offset = bufs[page_nr].offset;\n\t\tbuf->len = bufs[page_nr].len;\n\t\t/*\n\t\t * Need to be careful about this.  Having buf->ops in module\n\t\t * code can Oops if the buffer persists after module unload.\n\t\t */\n\t\tbuf->ops = &nosteal_pipe_buf_ops;\n\n\t\tpipe->nrbufs++;\n\t\tpage_nr++;\n\t\tret += buf->len;\n\n\t\tif (pipe->files)\n\t\t\tdo_wakeup = 1;\n\t}\n\nout_unlock:\n\tpipe_unlock(pipe);\n\n\tif (do_wakeup) {\n\t\tsmp_mb();\n\t\tif (waitqueue_active(&pipe->wait))\n\t\t\twake_up_interruptible(&pipe->wait);\n\t\tkill_fasync(&pipe->fasync_readers, SIGIO, POLL_IN);\n\t}\n\nout:\n\tfor (; page_nr < cs.nr_segs; page_nr++)\n\t\tpage_cache_release(bufs[page_nr].page);\n\n\tkfree(bufs);\n\treturn ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -7,8 +7,9 @@\n \tint do_wakeup = 0;\n \tstruct pipe_buffer *bufs;\n \tstruct fuse_copy_state cs;\n-\tstruct fuse_conn *fc = fuse_get_conn(in);\n-\tif (!fc)\n+\tstruct fuse_dev *fud = fuse_get_dev(in);\n+\n+\tif (!fud)\n \t\treturn -EPERM;\n \n \tbufs = kmalloc(pipe->buffers * sizeof(struct pipe_buffer), GFP_KERNEL);\n@@ -18,7 +19,7 @@\n \tfuse_copy_init(&cs, 1, NULL);\n \tcs.pipebufs = bufs;\n \tcs.pipe = pipe;\n-\tret = fuse_dev_do_read(fc, in, &cs, len);\n+\tret = fuse_dev_do_read(fud->fc, in, &cs, len);\n \tif (ret < 0)\n \t\tgoto out;\n ",
        "diff_line_info": {
            "deleted_lines": [
                "\tstruct fuse_conn *fc = fuse_get_conn(in);",
                "\tif (!fc)",
                "\tret = fuse_dev_do_read(fc, in, &cs, len);"
            ],
            "added_lines": [
                "\tstruct fuse_dev *fud = fuse_get_dev(in);",
                "",
                "\tif (!fud)",
                "\tret = fuse_dev_do_read(fud->fc, in, &cs, len);"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1339",
        "func_name": "torvalds/linux/fuse_dev_splice_write",
        "description": "Memory leak in the cuse_channel_release function in fs/fuse/cuse.c in the Linux kernel before 4.4 allows local users to cause a denial of service (memory consumption) or possibly have unspecified other impact by opening /dev/cuse many times.",
        "git_url": "https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?h=cc080e9e9be16ccf26135d366d7d2b65209f1d56",
        "commit_title": "Allow fuse device clones to refer to be distinguished.  This patch just",
        "commit_text": "adds the infrastructure by associating a separate \"struct fuse_dev\" with each clone.  ",
        "func_before": "static ssize_t fuse_dev_splice_write(struct pipe_inode_info *pipe,\n\t\t\t\t     struct file *out, loff_t *ppos,\n\t\t\t\t     size_t len, unsigned int flags)\n{\n\tunsigned nbuf;\n\tunsigned idx;\n\tstruct pipe_buffer *bufs;\n\tstruct fuse_copy_state cs;\n\tstruct fuse_conn *fc;\n\tsize_t rem;\n\tssize_t ret;\n\n\tfc = fuse_get_conn(out);\n\tif (!fc)\n\t\treturn -EPERM;\n\n\tbufs = kmalloc(pipe->buffers * sizeof(struct pipe_buffer), GFP_KERNEL);\n\tif (!bufs)\n\t\treturn -ENOMEM;\n\n\tpipe_lock(pipe);\n\tnbuf = 0;\n\trem = 0;\n\tfor (idx = 0; idx < pipe->nrbufs && rem < len; idx++)\n\t\trem += pipe->bufs[(pipe->curbuf + idx) & (pipe->buffers - 1)].len;\n\n\tret = -EINVAL;\n\tif (rem < len) {\n\t\tpipe_unlock(pipe);\n\t\tgoto out;\n\t}\n\n\trem = len;\n\twhile (rem) {\n\t\tstruct pipe_buffer *ibuf;\n\t\tstruct pipe_buffer *obuf;\n\n\t\tBUG_ON(nbuf >= pipe->buffers);\n\t\tBUG_ON(!pipe->nrbufs);\n\t\tibuf = &pipe->bufs[pipe->curbuf];\n\t\tobuf = &bufs[nbuf];\n\n\t\tif (rem >= ibuf->len) {\n\t\t\t*obuf = *ibuf;\n\t\t\tibuf->ops = NULL;\n\t\t\tpipe->curbuf = (pipe->curbuf + 1) & (pipe->buffers - 1);\n\t\t\tpipe->nrbufs--;\n\t\t} else {\n\t\t\tibuf->ops->get(pipe, ibuf);\n\t\t\t*obuf = *ibuf;\n\t\t\tobuf->flags &= ~PIPE_BUF_FLAG_GIFT;\n\t\t\tobuf->len = rem;\n\t\t\tibuf->offset += obuf->len;\n\t\t\tibuf->len -= obuf->len;\n\t\t}\n\t\tnbuf++;\n\t\trem -= obuf->len;\n\t}\n\tpipe_unlock(pipe);\n\n\tfuse_copy_init(&cs, 0, NULL);\n\tcs.pipebufs = bufs;\n\tcs.nr_segs = nbuf;\n\tcs.pipe = pipe;\n\n\tif (flags & SPLICE_F_MOVE)\n\t\tcs.move_pages = 1;\n\n\tret = fuse_dev_do_write(fc, &cs, len);\n\n\tfor (idx = 0; idx < nbuf; idx++) {\n\t\tstruct pipe_buffer *buf = &bufs[idx];\n\t\tbuf->ops->release(pipe, buf);\n\t}\nout:\n\tkfree(bufs);\n\treturn ret;\n}",
        "func": "static ssize_t fuse_dev_splice_write(struct pipe_inode_info *pipe,\n\t\t\t\t     struct file *out, loff_t *ppos,\n\t\t\t\t     size_t len, unsigned int flags)\n{\n\tunsigned nbuf;\n\tunsigned idx;\n\tstruct pipe_buffer *bufs;\n\tstruct fuse_copy_state cs;\n\tstruct fuse_dev *fud;\n\tsize_t rem;\n\tssize_t ret;\n\n\tfud = fuse_get_dev(out);\n\tif (!fud)\n\t\treturn -EPERM;\n\n\tbufs = kmalloc(pipe->buffers * sizeof(struct pipe_buffer), GFP_KERNEL);\n\tif (!bufs)\n\t\treturn -ENOMEM;\n\n\tpipe_lock(pipe);\n\tnbuf = 0;\n\trem = 0;\n\tfor (idx = 0; idx < pipe->nrbufs && rem < len; idx++)\n\t\trem += pipe->bufs[(pipe->curbuf + idx) & (pipe->buffers - 1)].len;\n\n\tret = -EINVAL;\n\tif (rem < len) {\n\t\tpipe_unlock(pipe);\n\t\tgoto out;\n\t}\n\n\trem = len;\n\twhile (rem) {\n\t\tstruct pipe_buffer *ibuf;\n\t\tstruct pipe_buffer *obuf;\n\n\t\tBUG_ON(nbuf >= pipe->buffers);\n\t\tBUG_ON(!pipe->nrbufs);\n\t\tibuf = &pipe->bufs[pipe->curbuf];\n\t\tobuf = &bufs[nbuf];\n\n\t\tif (rem >= ibuf->len) {\n\t\t\t*obuf = *ibuf;\n\t\t\tibuf->ops = NULL;\n\t\t\tpipe->curbuf = (pipe->curbuf + 1) & (pipe->buffers - 1);\n\t\t\tpipe->nrbufs--;\n\t\t} else {\n\t\t\tibuf->ops->get(pipe, ibuf);\n\t\t\t*obuf = *ibuf;\n\t\t\tobuf->flags &= ~PIPE_BUF_FLAG_GIFT;\n\t\t\tobuf->len = rem;\n\t\t\tibuf->offset += obuf->len;\n\t\t\tibuf->len -= obuf->len;\n\t\t}\n\t\tnbuf++;\n\t\trem -= obuf->len;\n\t}\n\tpipe_unlock(pipe);\n\n\tfuse_copy_init(&cs, 0, NULL);\n\tcs.pipebufs = bufs;\n\tcs.nr_segs = nbuf;\n\tcs.pipe = pipe;\n\n\tif (flags & SPLICE_F_MOVE)\n\t\tcs.move_pages = 1;\n\n\tret = fuse_dev_do_write(fud->fc, &cs, len);\n\n\tfor (idx = 0; idx < nbuf; idx++) {\n\t\tstruct pipe_buffer *buf = &bufs[idx];\n\t\tbuf->ops->release(pipe, buf);\n\t}\nout:\n\tkfree(bufs);\n\treturn ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -6,12 +6,12 @@\n \tunsigned idx;\n \tstruct pipe_buffer *bufs;\n \tstruct fuse_copy_state cs;\n-\tstruct fuse_conn *fc;\n+\tstruct fuse_dev *fud;\n \tsize_t rem;\n \tssize_t ret;\n \n-\tfc = fuse_get_conn(out);\n-\tif (!fc)\n+\tfud = fuse_get_dev(out);\n+\tif (!fud)\n \t\treturn -EPERM;\n \n \tbufs = kmalloc(pipe->buffers * sizeof(struct pipe_buffer), GFP_KERNEL);\n@@ -66,7 +66,7 @@\n \tif (flags & SPLICE_F_MOVE)\n \t\tcs.move_pages = 1;\n \n-\tret = fuse_dev_do_write(fc, &cs, len);\n+\tret = fuse_dev_do_write(fud->fc, &cs, len);\n \n \tfor (idx = 0; idx < nbuf; idx++) {\n \t\tstruct pipe_buffer *buf = &bufs[idx];",
        "diff_line_info": {
            "deleted_lines": [
                "\tstruct fuse_conn *fc;",
                "\tfc = fuse_get_conn(out);",
                "\tif (!fc)",
                "\tret = fuse_dev_do_write(fc, &cs, len);"
            ],
            "added_lines": [
                "\tstruct fuse_dev *fud;",
                "\tfud = fuse_get_dev(out);",
                "\tif (!fud)",
                "\tret = fuse_dev_do_write(fud->fc, &cs, len);"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1339",
        "func_name": "torvalds/linux/fuse_dev_write",
        "description": "Memory leak in the cuse_channel_release function in fs/fuse/cuse.c in the Linux kernel before 4.4 allows local users to cause a denial of service (memory consumption) or possibly have unspecified other impact by opening /dev/cuse many times.",
        "git_url": "https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?h=cc080e9e9be16ccf26135d366d7d2b65209f1d56",
        "commit_title": "Allow fuse device clones to refer to be distinguished.  This patch just",
        "commit_text": "adds the infrastructure by associating a separate \"struct fuse_dev\" with each clone.  ",
        "func_before": "static ssize_t fuse_dev_write(struct kiocb *iocb, struct iov_iter *from)\n{\n\tstruct fuse_copy_state cs;\n\tstruct fuse_conn *fc = fuse_get_conn(iocb->ki_filp);\n\tif (!fc)\n\t\treturn -EPERM;\n\n\tif (!iter_is_iovec(from))\n\t\treturn -EINVAL;\n\n\tfuse_copy_init(&cs, 0, from);\n\n\treturn fuse_dev_do_write(fc, &cs, iov_iter_count(from));\n}",
        "func": "static ssize_t fuse_dev_write(struct kiocb *iocb, struct iov_iter *from)\n{\n\tstruct fuse_copy_state cs;\n\tstruct fuse_dev *fud = fuse_get_dev(iocb->ki_filp);\n\n\tif (!fud)\n\t\treturn -EPERM;\n\n\tif (!iter_is_iovec(from))\n\t\treturn -EINVAL;\n\n\tfuse_copy_init(&cs, 0, from);\n\n\treturn fuse_dev_do_write(fud->fc, &cs, iov_iter_count(from));\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,8 +1,9 @@\n static ssize_t fuse_dev_write(struct kiocb *iocb, struct iov_iter *from)\n {\n \tstruct fuse_copy_state cs;\n-\tstruct fuse_conn *fc = fuse_get_conn(iocb->ki_filp);\n-\tif (!fc)\n+\tstruct fuse_dev *fud = fuse_get_dev(iocb->ki_filp);\n+\n+\tif (!fud)\n \t\treturn -EPERM;\n \n \tif (!iter_is_iovec(from))\n@@ -10,5 +11,5 @@\n \n \tfuse_copy_init(&cs, 0, from);\n \n-\treturn fuse_dev_do_write(fc, &cs, iov_iter_count(from));\n+\treturn fuse_dev_do_write(fud->fc, &cs, iov_iter_count(from));\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tstruct fuse_conn *fc = fuse_get_conn(iocb->ki_filp);",
                "\tif (!fc)",
                "\treturn fuse_dev_do_write(fc, &cs, iov_iter_count(from));"
            ],
            "added_lines": [
                "\tstruct fuse_dev *fud = fuse_get_dev(iocb->ki_filp);",
                "",
                "\tif (!fud)",
                "\treturn fuse_dev_do_write(fud->fc, &cs, iov_iter_count(from));"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1339",
        "func_name": "torvalds/linux/fuse_dev_read",
        "description": "Memory leak in the cuse_channel_release function in fs/fuse/cuse.c in the Linux kernel before 4.4 allows local users to cause a denial of service (memory consumption) or possibly have unspecified other impact by opening /dev/cuse many times.",
        "git_url": "https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?h=cc080e9e9be16ccf26135d366d7d2b65209f1d56",
        "commit_title": "Allow fuse device clones to refer to be distinguished.  This patch just",
        "commit_text": "adds the infrastructure by associating a separate \"struct fuse_dev\" with each clone.  ",
        "func_before": "static ssize_t fuse_dev_read(struct kiocb *iocb, struct iov_iter *to)\n{\n\tstruct fuse_copy_state cs;\n\tstruct file *file = iocb->ki_filp;\n\tstruct fuse_conn *fc = fuse_get_conn(file);\n\tif (!fc)\n\t\treturn -EPERM;\n\n\tif (!iter_is_iovec(to))\n\t\treturn -EINVAL;\n\n\tfuse_copy_init(&cs, 1, to);\n\n\treturn fuse_dev_do_read(fc, file, &cs, iov_iter_count(to));\n}",
        "func": "static ssize_t fuse_dev_read(struct kiocb *iocb, struct iov_iter *to)\n{\n\tstruct fuse_copy_state cs;\n\tstruct file *file = iocb->ki_filp;\n\tstruct fuse_dev *fud = fuse_get_dev(file);\n\n\tif (!fud)\n\t\treturn -EPERM;\n\n\tif (!iter_is_iovec(to))\n\t\treturn -EINVAL;\n\n\tfuse_copy_init(&cs, 1, to);\n\n\treturn fuse_dev_do_read(fud->fc, file, &cs, iov_iter_count(to));\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,8 +2,9 @@\n {\n \tstruct fuse_copy_state cs;\n \tstruct file *file = iocb->ki_filp;\n-\tstruct fuse_conn *fc = fuse_get_conn(file);\n-\tif (!fc)\n+\tstruct fuse_dev *fud = fuse_get_dev(file);\n+\n+\tif (!fud)\n \t\treturn -EPERM;\n \n \tif (!iter_is_iovec(to))\n@@ -11,5 +12,5 @@\n \n \tfuse_copy_init(&cs, 1, to);\n \n-\treturn fuse_dev_do_read(fc, file, &cs, iov_iter_count(to));\n+\treturn fuse_dev_do_read(fud->fc, file, &cs, iov_iter_count(to));\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tstruct fuse_conn *fc = fuse_get_conn(file);",
                "\tif (!fc)",
                "\treturn fuse_dev_do_read(fc, file, &cs, iov_iter_count(to));"
            ],
            "added_lines": [
                "\tstruct fuse_dev *fud = fuse_get_dev(file);",
                "",
                "\tif (!fud)",
                "\treturn fuse_dev_do_read(fud->fc, file, &cs, iov_iter_count(to));"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1339",
        "func_name": "torvalds/linux/fuse_dev_fasync",
        "description": "Memory leak in the cuse_channel_release function in fs/fuse/cuse.c in the Linux kernel before 4.4 allows local users to cause a denial of service (memory consumption) or possibly have unspecified other impact by opening /dev/cuse many times.",
        "git_url": "https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?h=cc080e9e9be16ccf26135d366d7d2b65209f1d56",
        "commit_title": "Allow fuse device clones to refer to be distinguished.  This patch just",
        "commit_text": "adds the infrastructure by associating a separate \"struct fuse_dev\" with each clone.  ",
        "func_before": "static int fuse_dev_fasync(int fd, struct file *file, int on)\n{\n\tstruct fuse_conn *fc = fuse_get_conn(file);\n\tif (!fc)\n\t\treturn -EPERM;\n\n\t/* No locking - fasync_helper does its own locking */\n\treturn fasync_helper(fd, file, on, &fc->iq.fasync);\n}",
        "func": "static int fuse_dev_fasync(int fd, struct file *file, int on)\n{\n\tstruct fuse_dev *fud = fuse_get_dev(file);\n\n\tif (!fud)\n\t\treturn -EPERM;\n\n\t/* No locking - fasync_helper does its own locking */\n\treturn fasync_helper(fd, file, on, &fud->fc->iq.fasync);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,9 +1,10 @@\n static int fuse_dev_fasync(int fd, struct file *file, int on)\n {\n-\tstruct fuse_conn *fc = fuse_get_conn(file);\n-\tif (!fc)\n+\tstruct fuse_dev *fud = fuse_get_dev(file);\n+\n+\tif (!fud)\n \t\treturn -EPERM;\n \n \t/* No locking - fasync_helper does its own locking */\n-\treturn fasync_helper(fd, file, on, &fc->iq.fasync);\n+\treturn fasync_helper(fd, file, on, &fud->fc->iq.fasync);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tstruct fuse_conn *fc = fuse_get_conn(file);",
                "\tif (!fc)",
                "\treturn fasync_helper(fd, file, on, &fc->iq.fasync);"
            ],
            "added_lines": [
                "\tstruct fuse_dev *fud = fuse_get_dev(file);",
                "",
                "\tif (!fud)",
                "\treturn fasync_helper(fd, file, on, &fud->fc->iq.fasync);"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1339",
        "func_name": "torvalds/linux/fuse_dev_ioctl",
        "description": "Memory leak in the cuse_channel_release function in fs/fuse/cuse.c in the Linux kernel before 4.4 allows local users to cause a denial of service (memory consumption) or possibly have unspecified other impact by opening /dev/cuse many times.",
        "git_url": "https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?h=cc080e9e9be16ccf26135d366d7d2b65209f1d56",
        "commit_title": "Allow fuse device clones to refer to be distinguished.  This patch just",
        "commit_text": "adds the infrastructure by associating a separate \"struct fuse_dev\" with each clone.  ",
        "func_before": "static long fuse_dev_ioctl(struct file *file, unsigned int cmd,\n\t\t\t   unsigned long arg)\n{\n\tint err = -ENOTTY;\n\n\tif (cmd == FUSE_DEV_IOC_CLONE) {\n\t\tint oldfd;\n\n\t\terr = -EFAULT;\n\t\tif (!get_user(oldfd, (__u32 __user *) arg)) {\n\t\t\tstruct file *old = fget(oldfd);\n\n\t\t\terr = -EINVAL;\n\t\t\tif (old) {\n\t\t\t\tstruct fuse_conn *fc = fuse_get_conn(old);\n\n\t\t\t\tif (fc) {\n\t\t\t\t\tmutex_lock(&fuse_mutex);\n\t\t\t\t\terr = fuse_device_clone(fc, file);\n\t\t\t\t\tmutex_unlock(&fuse_mutex);\n\t\t\t\t}\n\t\t\t\tfput(old);\n\t\t\t}\n\t\t}\n\t}\n\treturn err;\n}",
        "func": "static long fuse_dev_ioctl(struct file *file, unsigned int cmd,\n\t\t\t   unsigned long arg)\n{\n\tint err = -ENOTTY;\n\n\tif (cmd == FUSE_DEV_IOC_CLONE) {\n\t\tint oldfd;\n\n\t\terr = -EFAULT;\n\t\tif (!get_user(oldfd, (__u32 __user *) arg)) {\n\t\t\tstruct file *old = fget(oldfd);\n\n\t\t\terr = -EINVAL;\n\t\t\tif (old) {\n\t\t\t\tstruct fuse_dev *fud = fuse_get_dev(old);\n\n\t\t\t\tif (fud) {\n\t\t\t\t\tmutex_lock(&fuse_mutex);\n\t\t\t\t\terr = fuse_device_clone(fud->fc, file);\n\t\t\t\t\tmutex_unlock(&fuse_mutex);\n\t\t\t\t}\n\t\t\t\tfput(old);\n\t\t\t}\n\t\t}\n\t}\n\treturn err;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -12,11 +12,11 @@\n \n \t\t\terr = -EINVAL;\n \t\t\tif (old) {\n-\t\t\t\tstruct fuse_conn *fc = fuse_get_conn(old);\n+\t\t\t\tstruct fuse_dev *fud = fuse_get_dev(old);\n \n-\t\t\t\tif (fc) {\n+\t\t\t\tif (fud) {\n \t\t\t\t\tmutex_lock(&fuse_mutex);\n-\t\t\t\t\terr = fuse_device_clone(fc, file);\n+\t\t\t\t\terr = fuse_device_clone(fud->fc, file);\n \t\t\t\t\tmutex_unlock(&fuse_mutex);\n \t\t\t\t}\n \t\t\t\tfput(old);",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\t\tstruct fuse_conn *fc = fuse_get_conn(old);",
                "\t\t\t\tif (fc) {",
                "\t\t\t\t\terr = fuse_device_clone(fc, file);"
            ],
            "added_lines": [
                "\t\t\t\tstruct fuse_dev *fud = fuse_get_dev(old);",
                "\t\t\t\tif (fud) {",
                "\t\t\t\t\terr = fuse_device_clone(fud->fc, file);"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1339",
        "func_name": "torvalds/linux/fuse_dev_poll",
        "description": "Memory leak in the cuse_channel_release function in fs/fuse/cuse.c in the Linux kernel before 4.4 allows local users to cause a denial of service (memory consumption) or possibly have unspecified other impact by opening /dev/cuse many times.",
        "git_url": "https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?h=cc080e9e9be16ccf26135d366d7d2b65209f1d56",
        "commit_title": "Allow fuse device clones to refer to be distinguished.  This patch just",
        "commit_text": "adds the infrastructure by associating a separate \"struct fuse_dev\" with each clone.  ",
        "func_before": "static unsigned fuse_dev_poll(struct file *file, poll_table *wait)\n{\n\tunsigned mask = POLLOUT | POLLWRNORM;\n\tstruct fuse_iqueue *fiq;\n\tstruct fuse_conn *fc = fuse_get_conn(file);\n\tif (!fc)\n\t\treturn POLLERR;\n\n\tfiq = &fc->iq;\n\tpoll_wait(file, &fiq->waitq, wait);\n\n\tspin_lock(&fiq->waitq.lock);\n\tif (!fiq->connected)\n\t\tmask = POLLERR;\n\telse if (request_pending(fiq))\n\t\tmask |= POLLIN | POLLRDNORM;\n\tspin_unlock(&fiq->waitq.lock);\n\n\treturn mask;\n}",
        "func": "static unsigned fuse_dev_poll(struct file *file, poll_table *wait)\n{\n\tunsigned mask = POLLOUT | POLLWRNORM;\n\tstruct fuse_iqueue *fiq;\n\tstruct fuse_dev *fud = fuse_get_dev(file);\n\n\tif (!fud)\n\t\treturn POLLERR;\n\n\tfiq = &fud->fc->iq;\n\tpoll_wait(file, &fiq->waitq, wait);\n\n\tspin_lock(&fiq->waitq.lock);\n\tif (!fiq->connected)\n\t\tmask = POLLERR;\n\telse if (request_pending(fiq))\n\t\tmask |= POLLIN | POLLRDNORM;\n\tspin_unlock(&fiq->waitq.lock);\n\n\treturn mask;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,11 +2,12 @@\n {\n \tunsigned mask = POLLOUT | POLLWRNORM;\n \tstruct fuse_iqueue *fiq;\n-\tstruct fuse_conn *fc = fuse_get_conn(file);\n-\tif (!fc)\n+\tstruct fuse_dev *fud = fuse_get_dev(file);\n+\n+\tif (!fud)\n \t\treturn POLLERR;\n \n-\tfiq = &fc->iq;\n+\tfiq = &fud->fc->iq;\n \tpoll_wait(file, &fiq->waitq, wait);\n \n \tspin_lock(&fiq->waitq.lock);",
        "diff_line_info": {
            "deleted_lines": [
                "\tstruct fuse_conn *fc = fuse_get_conn(file);",
                "\tif (!fc)",
                "\tfiq = &fc->iq;"
            ],
            "added_lines": [
                "\tstruct fuse_dev *fud = fuse_get_dev(file);",
                "",
                "\tif (!fud)",
                "\tfiq = &fud->fc->iq;"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1339",
        "func_name": "torvalds/linux/fuse_dev_release",
        "description": "Memory leak in the cuse_channel_release function in fs/fuse/cuse.c in the Linux kernel before 4.4 allows local users to cause a denial of service (memory consumption) or possibly have unspecified other impact by opening /dev/cuse many times.",
        "git_url": "https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?h=cc080e9e9be16ccf26135d366d7d2b65209f1d56",
        "commit_title": "Allow fuse device clones to refer to be distinguished.  This patch just",
        "commit_text": "adds the infrastructure by associating a separate \"struct fuse_dev\" with each clone.  ",
        "func_before": "int fuse_dev_release(struct inode *inode, struct file *file)\n{\n\tstruct fuse_conn *fc = fuse_get_conn(file);\n\tif (fc) {\n\t\tWARN_ON(!list_empty(&fc->pq.io));\n\t\tWARN_ON(fc->iq.fasync != NULL);\n\t\tfuse_abort_conn(fc);\n\t\tfuse_conn_put(fc);\n\t}\n\n\treturn 0;\n}",
        "func": "int fuse_dev_release(struct inode *inode, struct file *file)\n{\n\tstruct fuse_dev *fud = fuse_get_dev(file);\n\n\tif (fud) {\n\t\tstruct fuse_conn *fc = fud->fc;\n\n\t\tWARN_ON(!list_empty(&fc->pq.io));\n\t\tWARN_ON(fc->iq.fasync != NULL);\n\t\tfuse_abort_conn(fc);\n\t\tfuse_dev_free(fud);\n\t}\n\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,11 +1,14 @@\n int fuse_dev_release(struct inode *inode, struct file *file)\n {\n-\tstruct fuse_conn *fc = fuse_get_conn(file);\n-\tif (fc) {\n+\tstruct fuse_dev *fud = fuse_get_dev(file);\n+\n+\tif (fud) {\n+\t\tstruct fuse_conn *fc = fud->fc;\n+\n \t\tWARN_ON(!list_empty(&fc->pq.io));\n \t\tWARN_ON(fc->iq.fasync != NULL);\n \t\tfuse_abort_conn(fc);\n-\t\tfuse_conn_put(fc);\n+\t\tfuse_dev_free(fud);\n \t}\n \n \treturn 0;",
        "diff_line_info": {
            "deleted_lines": [
                "\tstruct fuse_conn *fc = fuse_get_conn(file);",
                "\tif (fc) {",
                "\t\tfuse_conn_put(fc);"
            ],
            "added_lines": [
                "\tstruct fuse_dev *fud = fuse_get_dev(file);",
                "",
                "\tif (fud) {",
                "\t\tstruct fuse_conn *fc = fud->fc;",
                "",
                "\t\tfuse_dev_free(fud);"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1339",
        "func_name": "torvalds/linux/cuse_channel_release",
        "description": "Memory leak in the cuse_channel_release function in fs/fuse/cuse.c in the Linux kernel before 4.4 allows local users to cause a denial of service (memory consumption) or possibly have unspecified other impact by opening /dev/cuse many times.",
        "git_url": "https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?h=cc080e9e9be16ccf26135d366d7d2b65209f1d56",
        "commit_title": "Allow fuse device clones to refer to be distinguished.  This patch just",
        "commit_text": "adds the infrastructure by associating a separate \"struct fuse_dev\" with each clone.  ",
        "func_before": "static int cuse_channel_release(struct inode *inode, struct file *file)\n{\n\tstruct cuse_conn *cc = fc_to_cc(file->private_data);\n\tint rc;\n\n\t/* remove from the conntbl, no more access from this point on */\n\tmutex_lock(&cuse_lock);\n\tlist_del_init(&cc->list);\n\tmutex_unlock(&cuse_lock);\n\n\t/* remove device */\n\tif (cc->dev)\n\t\tdevice_unregister(cc->dev);\n\tif (cc->cdev) {\n\t\tunregister_chrdev_region(cc->cdev->dev, 1);\n\t\tcdev_del(cc->cdev);\n\t}\n\n\trc = fuse_dev_release(inode, file);\t/* puts the base reference */\n\n\treturn rc;\n}",
        "func": "static int cuse_channel_release(struct inode *inode, struct file *file)\n{\n\tstruct fuse_dev *fud = file->private_data;\n\tstruct cuse_conn *cc = fc_to_cc(fud->fc);\n\tint rc;\n\n\t/* remove from the conntbl, no more access from this point on */\n\tmutex_lock(&cuse_lock);\n\tlist_del_init(&cc->list);\n\tmutex_unlock(&cuse_lock);\n\n\t/* remove device */\n\tif (cc->dev)\n\t\tdevice_unregister(cc->dev);\n\tif (cc->cdev) {\n\t\tunregister_chrdev_region(cc->cdev->dev, 1);\n\t\tcdev_del(cc->cdev);\n\t}\n\n\trc = fuse_dev_release(inode, file);\t/* puts the base reference */\n\n\treturn rc;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,7 @@\n static int cuse_channel_release(struct inode *inode, struct file *file)\n {\n-\tstruct cuse_conn *cc = fc_to_cc(file->private_data);\n+\tstruct fuse_dev *fud = file->private_data;\n+\tstruct cuse_conn *cc = fc_to_cc(fud->fc);\n \tint rc;\n \n \t/* remove from the conntbl, no more access from this point on */",
        "diff_line_info": {
            "deleted_lines": [
                "\tstruct cuse_conn *cc = fc_to_cc(file->private_data);"
            ],
            "added_lines": [
                "\tstruct fuse_dev *fud = file->private_data;",
                "\tstruct cuse_conn *cc = fc_to_cc(fud->fc);"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1339",
        "func_name": "torvalds/linux/cuse_channel_open",
        "description": "Memory leak in the cuse_channel_release function in fs/fuse/cuse.c in the Linux kernel before 4.4 allows local users to cause a denial of service (memory consumption) or possibly have unspecified other impact by opening /dev/cuse many times.",
        "git_url": "https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?h=cc080e9e9be16ccf26135d366d7d2b65209f1d56",
        "commit_title": "Allow fuse device clones to refer to be distinguished.  This patch just",
        "commit_text": "adds the infrastructure by associating a separate \"struct fuse_dev\" with each clone.  ",
        "func_before": "static int cuse_channel_open(struct inode *inode, struct file *file)\n{\n\tstruct cuse_conn *cc;\n\tint rc;\n\n\t/* set up cuse_conn */\n\tcc = kzalloc(sizeof(*cc), GFP_KERNEL);\n\tif (!cc)\n\t\treturn -ENOMEM;\n\n\tfuse_conn_init(&cc->fc);\n\n\tINIT_LIST_HEAD(&cc->list);\n\tcc->fc.release = cuse_fc_release;\n\n\tcc->fc.initialized = 1;\n\trc = cuse_send_init(cc);\n\tif (rc) {\n\t\tfuse_conn_put(&cc->fc);\n\t\treturn rc;\n\t}\n\tfile->private_data = &cc->fc;\t/* channel owns base reference to cc */\n\n\treturn 0;\n}",
        "func": "static int cuse_channel_open(struct inode *inode, struct file *file)\n{\n\tstruct fuse_dev *fud;\n\tstruct cuse_conn *cc;\n\tint rc;\n\n\t/* set up cuse_conn */\n\tcc = kzalloc(sizeof(*cc), GFP_KERNEL);\n\tif (!cc)\n\t\treturn -ENOMEM;\n\n\tfuse_conn_init(&cc->fc);\n\n\tfud = fuse_dev_alloc(&cc->fc);\n\tif (!fud) {\n\t\tkfree(cc);\n\t\treturn -ENOMEM;\n\t}\n\n\tINIT_LIST_HEAD(&cc->list);\n\tcc->fc.release = cuse_fc_release;\n\n\tcc->fc.initialized = 1;\n\trc = cuse_send_init(cc);\n\tif (rc) {\n\t\tfuse_dev_free(fud);\n\t\treturn rc;\n\t}\n\tfile->private_data = fud;\n\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,6 @@\n static int cuse_channel_open(struct inode *inode, struct file *file)\n {\n+\tstruct fuse_dev *fud;\n \tstruct cuse_conn *cc;\n \tint rc;\n \n@@ -10,16 +11,22 @@\n \n \tfuse_conn_init(&cc->fc);\n \n+\tfud = fuse_dev_alloc(&cc->fc);\n+\tif (!fud) {\n+\t\tkfree(cc);\n+\t\treturn -ENOMEM;\n+\t}\n+\n \tINIT_LIST_HEAD(&cc->list);\n \tcc->fc.release = cuse_fc_release;\n \n \tcc->fc.initialized = 1;\n \trc = cuse_send_init(cc);\n \tif (rc) {\n-\t\tfuse_conn_put(&cc->fc);\n+\t\tfuse_dev_free(fud);\n \t\treturn rc;\n \t}\n-\tfile->private_data = &cc->fc;\t/* channel owns base reference to cc */\n+\tfile->private_data = fud;\n \n \treturn 0;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tfuse_conn_put(&cc->fc);",
                "\tfile->private_data = &cc->fc;\t/* channel owns base reference to cc */"
            ],
            "added_lines": [
                "\tstruct fuse_dev *fud;",
                "\tfud = fuse_dev_alloc(&cc->fc);",
                "\tif (!fud) {",
                "\t\tkfree(cc);",
                "\t\treturn -ENOMEM;",
                "\t}",
                "",
                "\t\tfuse_dev_free(fud);",
                "\tfile->private_data = fud;"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1339",
        "func_name": "torvalds/linux/fuse_free_conn",
        "description": "Memory leak in the cuse_channel_release function in fs/fuse/cuse.c in the Linux kernel before 4.4 allows local users to cause a denial of service (memory consumption) or possibly have unspecified other impact by opening /dev/cuse many times.",
        "git_url": "https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?h=cc080e9e9be16ccf26135d366d7d2b65209f1d56",
        "commit_title": "Allow fuse device clones to refer to be distinguished.  This patch just",
        "commit_text": "adds the infrastructure by associating a separate \"struct fuse_dev\" with each clone.  ",
        "func_before": "static void fuse_free_conn(struct fuse_conn *fc)\n{\n\tkfree_rcu(fc, rcu);\n}",
        "func": "static void fuse_free_conn(struct fuse_conn *fc)\n{\n\tWARN_ON(!list_empty(&fc->devices));\n\tkfree_rcu(fc, rcu);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,4 +1,5 @@\n static void fuse_free_conn(struct fuse_conn *fc)\n {\n+\tWARN_ON(!list_empty(&fc->devices));\n \tkfree_rcu(fc, rcu);\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tWARN_ON(!list_empty(&fc->devices));"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1339",
        "func_name": "torvalds/linux/fuse_fill_super",
        "description": "Memory leak in the cuse_channel_release function in fs/fuse/cuse.c in the Linux kernel before 4.4 allows local users to cause a denial of service (memory consumption) or possibly have unspecified other impact by opening /dev/cuse many times.",
        "git_url": "https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?h=cc080e9e9be16ccf26135d366d7d2b65209f1d56",
        "commit_title": "Allow fuse device clones to refer to be distinguished.  This patch just",
        "commit_text": "adds the infrastructure by associating a separate \"struct fuse_dev\" with each clone.  ",
        "func_before": "static int fuse_fill_super(struct super_block *sb, void *data, int silent)\n{\n\tstruct fuse_conn *fc;\n\tstruct inode *root;\n\tstruct fuse_mount_data d;\n\tstruct file *file;\n\tstruct dentry *root_dentry;\n\tstruct fuse_req *init_req;\n\tint err;\n\tint is_bdev = sb->s_bdev != NULL;\n\n\terr = -EINVAL;\n\tif (sb->s_flags & MS_MANDLOCK)\n\t\tgoto err;\n\n\tsb->s_flags &= ~(MS_NOSEC | MS_I_VERSION);\n\n\tif (!parse_fuse_opt(data, &d, is_bdev))\n\t\tgoto err;\n\n\tif (is_bdev) {\n#ifdef CONFIG_BLOCK\n\t\terr = -EINVAL;\n\t\tif (!sb_set_blocksize(sb, d.blksize))\n\t\t\tgoto err;\n#endif\n\t} else {\n\t\tsb->s_blocksize = PAGE_CACHE_SIZE;\n\t\tsb->s_blocksize_bits = PAGE_CACHE_SHIFT;\n\t}\n\tsb->s_magic = FUSE_SUPER_MAGIC;\n\tsb->s_op = &fuse_super_operations;\n\tsb->s_maxbytes = MAX_LFS_FILESIZE;\n\tsb->s_time_gran = 1;\n\tsb->s_export_op = &fuse_export_operations;\n\n\tfile = fget(d.fd);\n\terr = -EINVAL;\n\tif (!file)\n\t\tgoto err;\n\n\tif ((file->f_op != &fuse_dev_operations) ||\n\t    (file->f_cred->user_ns != &init_user_ns))\n\t\tgoto err_fput;\n\n\tfc = kmalloc(sizeof(*fc), GFP_KERNEL);\n\terr = -ENOMEM;\n\tif (!fc)\n\t\tgoto err_fput;\n\n\tfuse_conn_init(fc);\n\tfc->release = fuse_free_conn;\n\n\tfc->dev = sb->s_dev;\n\tfc->sb = sb;\n\terr = fuse_bdi_init(fc, sb);\n\tif (err)\n\t\tgoto err_put_conn;\n\n\tsb->s_bdi = &fc->bdi;\n\n\t/* Handle umasking inside the fuse code */\n\tif (sb->s_flags & MS_POSIXACL)\n\t\tfc->dont_mask = 1;\n\tsb->s_flags |= MS_POSIXACL;\n\n\tfc->flags = d.flags;\n\tfc->user_id = d.user_id;\n\tfc->group_id = d.group_id;\n\tfc->max_read = max_t(unsigned, 4096, d.max_read);\n\n\t/* Used by get_root_inode() */\n\tsb->s_fs_info = fc;\n\n\terr = -ENOMEM;\n\troot = fuse_get_root_inode(sb, d.rootmode);\n\troot_dentry = d_make_root(root);\n\tif (!root_dentry)\n\t\tgoto err_put_conn;\n\t/* only now - we want root dentry with NULL ->d_op */\n\tsb->s_d_op = &fuse_dentry_operations;\n\n\tinit_req = fuse_request_alloc(0);\n\tif (!init_req)\n\t\tgoto err_put_root;\n\t__set_bit(FR_BACKGROUND, &init_req->flags);\n\n\tif (is_bdev) {\n\t\tfc->destroy_req = fuse_request_alloc(0);\n\t\tif (!fc->destroy_req)\n\t\t\tgoto err_free_init_req;\n\t}\n\n\tmutex_lock(&fuse_mutex);\n\terr = -EINVAL;\n\tif (file->private_data)\n\t\tgoto err_unlock;\n\n\terr = fuse_ctl_add_conn(fc);\n\tif (err)\n\t\tgoto err_unlock;\n\n\tlist_add_tail(&fc->entry, &fuse_conn_list);\n\tsb->s_root = root_dentry;\n\tfile->private_data = fuse_conn_get(fc);\n\tmutex_unlock(&fuse_mutex);\n\t/*\n\t * atomic_dec_and_test() in fput() provides the necessary\n\t * memory barrier for file->private_data to be visible on all\n\t * CPUs after this\n\t */\n\tfput(file);\n\n\tfuse_send_init(fc, init_req);\n\n\treturn 0;\n\n err_unlock:\n\tmutex_unlock(&fuse_mutex);\n err_free_init_req:\n\tfuse_request_free(init_req);\n err_put_root:\n\tdput(root_dentry);\n err_put_conn:\n\tfuse_bdi_destroy(fc);\n\tfuse_conn_put(fc);\n err_fput:\n\tfput(file);\n err:\n\treturn err;\n}",
        "func": "static int fuse_fill_super(struct super_block *sb, void *data, int silent)\n{\n\tstruct fuse_dev *fud;\n\tstruct fuse_conn *fc;\n\tstruct inode *root;\n\tstruct fuse_mount_data d;\n\tstruct file *file;\n\tstruct dentry *root_dentry;\n\tstruct fuse_req *init_req;\n\tint err;\n\tint is_bdev = sb->s_bdev != NULL;\n\n\terr = -EINVAL;\n\tif (sb->s_flags & MS_MANDLOCK)\n\t\tgoto err;\n\n\tsb->s_flags &= ~(MS_NOSEC | MS_I_VERSION);\n\n\tif (!parse_fuse_opt(data, &d, is_bdev))\n\t\tgoto err;\n\n\tif (is_bdev) {\n#ifdef CONFIG_BLOCK\n\t\terr = -EINVAL;\n\t\tif (!sb_set_blocksize(sb, d.blksize))\n\t\t\tgoto err;\n#endif\n\t} else {\n\t\tsb->s_blocksize = PAGE_CACHE_SIZE;\n\t\tsb->s_blocksize_bits = PAGE_CACHE_SHIFT;\n\t}\n\tsb->s_magic = FUSE_SUPER_MAGIC;\n\tsb->s_op = &fuse_super_operations;\n\tsb->s_maxbytes = MAX_LFS_FILESIZE;\n\tsb->s_time_gran = 1;\n\tsb->s_export_op = &fuse_export_operations;\n\n\tfile = fget(d.fd);\n\terr = -EINVAL;\n\tif (!file)\n\t\tgoto err;\n\n\tif ((file->f_op != &fuse_dev_operations) ||\n\t    (file->f_cred->user_ns != &init_user_ns))\n\t\tgoto err_fput;\n\n\tfc = kmalloc(sizeof(*fc), GFP_KERNEL);\n\terr = -ENOMEM;\n\tif (!fc)\n\t\tgoto err_fput;\n\n\tfuse_conn_init(fc);\n\tfc->release = fuse_free_conn;\n\n\tfud = fuse_dev_alloc(fc);\n\tif (!fud)\n\t\tgoto err_put_conn;\n\n\tfc->dev = sb->s_dev;\n\tfc->sb = sb;\n\terr = fuse_bdi_init(fc, sb);\n\tif (err)\n\t\tgoto err_dev_free;\n\n\tsb->s_bdi = &fc->bdi;\n\n\t/* Handle umasking inside the fuse code */\n\tif (sb->s_flags & MS_POSIXACL)\n\t\tfc->dont_mask = 1;\n\tsb->s_flags |= MS_POSIXACL;\n\n\tfc->flags = d.flags;\n\tfc->user_id = d.user_id;\n\tfc->group_id = d.group_id;\n\tfc->max_read = max_t(unsigned, 4096, d.max_read);\n\n\t/* Used by get_root_inode() */\n\tsb->s_fs_info = fc;\n\n\terr = -ENOMEM;\n\troot = fuse_get_root_inode(sb, d.rootmode);\n\troot_dentry = d_make_root(root);\n\tif (!root_dentry)\n\t\tgoto err_dev_free;\n\t/* only now - we want root dentry with NULL ->d_op */\n\tsb->s_d_op = &fuse_dentry_operations;\n\n\tinit_req = fuse_request_alloc(0);\n\tif (!init_req)\n\t\tgoto err_put_root;\n\t__set_bit(FR_BACKGROUND, &init_req->flags);\n\n\tif (is_bdev) {\n\t\tfc->destroy_req = fuse_request_alloc(0);\n\t\tif (!fc->destroy_req)\n\t\t\tgoto err_free_init_req;\n\t}\n\n\tmutex_lock(&fuse_mutex);\n\terr = -EINVAL;\n\tif (file->private_data)\n\t\tgoto err_unlock;\n\n\terr = fuse_ctl_add_conn(fc);\n\tif (err)\n\t\tgoto err_unlock;\n\n\tlist_add_tail(&fc->entry, &fuse_conn_list);\n\tsb->s_root = root_dentry;\n\tfile->private_data = fud;\n\tmutex_unlock(&fuse_mutex);\n\t/*\n\t * atomic_dec_and_test() in fput() provides the necessary\n\t * memory barrier for file->private_data to be visible on all\n\t * CPUs after this\n\t */\n\tfput(file);\n\n\tfuse_send_init(fc, init_req);\n\n\treturn 0;\n\n err_unlock:\n\tmutex_unlock(&fuse_mutex);\n err_free_init_req:\n\tfuse_request_free(init_req);\n err_put_root:\n\tdput(root_dentry);\n err_dev_free:\n\tfuse_dev_free(fud);\n err_put_conn:\n\tfuse_bdi_destroy(fc);\n\tfuse_conn_put(fc);\n err_fput:\n\tfput(file);\n err:\n\treturn err;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,6 @@\n static int fuse_fill_super(struct super_block *sb, void *data, int silent)\n {\n+\tstruct fuse_dev *fud;\n \tstruct fuse_conn *fc;\n \tstruct inode *root;\n \tstruct fuse_mount_data d;\n@@ -51,11 +52,15 @@\n \tfuse_conn_init(fc);\n \tfc->release = fuse_free_conn;\n \n+\tfud = fuse_dev_alloc(fc);\n+\tif (!fud)\n+\t\tgoto err_put_conn;\n+\n \tfc->dev = sb->s_dev;\n \tfc->sb = sb;\n \terr = fuse_bdi_init(fc, sb);\n \tif (err)\n-\t\tgoto err_put_conn;\n+\t\tgoto err_dev_free;\n \n \tsb->s_bdi = &fc->bdi;\n \n@@ -76,7 +81,7 @@\n \troot = fuse_get_root_inode(sb, d.rootmode);\n \troot_dentry = d_make_root(root);\n \tif (!root_dentry)\n-\t\tgoto err_put_conn;\n+\t\tgoto err_dev_free;\n \t/* only now - we want root dentry with NULL ->d_op */\n \tsb->s_d_op = &fuse_dentry_operations;\n \n@@ -102,7 +107,7 @@\n \n \tlist_add_tail(&fc->entry, &fuse_conn_list);\n \tsb->s_root = root_dentry;\n-\tfile->private_data = fuse_conn_get(fc);\n+\tfile->private_data = fud;\n \tmutex_unlock(&fuse_mutex);\n \t/*\n \t * atomic_dec_and_test() in fput() provides the necessary\n@@ -121,6 +126,8 @@\n \tfuse_request_free(init_req);\n  err_put_root:\n \tdput(root_dentry);\n+ err_dev_free:\n+\tfuse_dev_free(fud);\n  err_put_conn:\n \tfuse_bdi_destroy(fc);\n \tfuse_conn_put(fc);",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tgoto err_put_conn;",
                "\t\tgoto err_put_conn;",
                "\tfile->private_data = fuse_conn_get(fc);"
            ],
            "added_lines": [
                "\tstruct fuse_dev *fud;",
                "\tfud = fuse_dev_alloc(fc);",
                "\tif (!fud)",
                "\t\tgoto err_put_conn;",
                "",
                "\t\tgoto err_dev_free;",
                "\t\tgoto err_dev_free;",
                "\tfile->private_data = fud;",
                " err_dev_free:",
                "\tfuse_dev_free(fud);"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1339",
        "func_name": "torvalds/linux/fuse_conn_init",
        "description": "Memory leak in the cuse_channel_release function in fs/fuse/cuse.c in the Linux kernel before 4.4 allows local users to cause a denial of service (memory consumption) or possibly have unspecified other impact by opening /dev/cuse many times.",
        "git_url": "https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?h=cc080e9e9be16ccf26135d366d7d2b65209f1d56",
        "commit_title": "Allow fuse device clones to refer to be distinguished.  This patch just",
        "commit_text": "adds the infrastructure by associating a separate \"struct fuse_dev\" with each clone.  ",
        "func_before": "void fuse_conn_init(struct fuse_conn *fc)\n{\n\tmemset(fc, 0, sizeof(*fc));\n\tspin_lock_init(&fc->lock);\n\tinit_rwsem(&fc->killsb);\n\tatomic_set(&fc->count, 1);\n\tinit_waitqueue_head(&fc->blocked_waitq);\n\tinit_waitqueue_head(&fc->reserved_req_waitq);\n\tfuse_iqueue_init(&fc->iq);\n\tfuse_pqueue_init(&fc->pq);\n\tINIT_LIST_HEAD(&fc->bg_queue);\n\tINIT_LIST_HEAD(&fc->entry);\n\tatomic_set(&fc->num_waiting, 0);\n\tfc->max_background = FUSE_DEFAULT_MAX_BACKGROUND;\n\tfc->congestion_threshold = FUSE_DEFAULT_CONGESTION_THRESHOLD;\n\tfc->khctr = 0;\n\tfc->polled_files = RB_ROOT;\n\tfc->blocked = 0;\n\tfc->initialized = 0;\n\tfc->connected = 1;\n\tfc->attr_version = 1;\n\tget_random_bytes(&fc->scramble_key, sizeof(fc->scramble_key));\n}",
        "func": "void fuse_conn_init(struct fuse_conn *fc)\n{\n\tmemset(fc, 0, sizeof(*fc));\n\tspin_lock_init(&fc->lock);\n\tinit_rwsem(&fc->killsb);\n\tatomic_set(&fc->count, 1);\n\tinit_waitqueue_head(&fc->blocked_waitq);\n\tinit_waitqueue_head(&fc->reserved_req_waitq);\n\tfuse_iqueue_init(&fc->iq);\n\tfuse_pqueue_init(&fc->pq);\n\tINIT_LIST_HEAD(&fc->bg_queue);\n\tINIT_LIST_HEAD(&fc->entry);\n\tINIT_LIST_HEAD(&fc->devices);\n\tatomic_set(&fc->num_waiting, 0);\n\tfc->max_background = FUSE_DEFAULT_MAX_BACKGROUND;\n\tfc->congestion_threshold = FUSE_DEFAULT_CONGESTION_THRESHOLD;\n\tfc->khctr = 0;\n\tfc->polled_files = RB_ROOT;\n\tfc->blocked = 0;\n\tfc->initialized = 0;\n\tfc->connected = 1;\n\tfc->attr_version = 1;\n\tget_random_bytes(&fc->scramble_key, sizeof(fc->scramble_key));\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -10,6 +10,7 @@\n \tfuse_pqueue_init(&fc->pq);\n \tINIT_LIST_HEAD(&fc->bg_queue);\n \tINIT_LIST_HEAD(&fc->entry);\n+\tINIT_LIST_HEAD(&fc->devices);\n \tatomic_set(&fc->num_waiting, 0);\n \tfc->max_background = FUSE_DEFAULT_MAX_BACKGROUND;\n \tfc->congestion_threshold = FUSE_DEFAULT_CONGESTION_THRESHOLD;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tINIT_LIST_HEAD(&fc->devices);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-2550",
        "func_name": "torvalds/linux/scm_fp_dup",
        "description": "The Linux kernel before 4.5 allows local users to bypass file-descriptor limits and cause a denial of service (memory consumption) by leveraging incorrect tracking of descriptor ownership and sending each descriptor over a UNIX socket before closing it. NOTE: this vulnerability exists because of an incorrect fix for CVE-2013-4312.",
        "git_url": "https://github.com/torvalds/linux/commit/415e3d3e90ce9e18727e8843ae343eda5a58fad6",
        "commit_title": "unix: correctly track in-flight fds in sending process user_struct",
        "commit_text": " The commit referenced in the Fixes tag incorrectly accounted the number of in-flight fds over a unix domain socket to the original opener of the file-descriptor. This allows another process to arbitrary deplete the original file-openers resource limit for the maximum of open files. Instead the sending processes and its struct cred should be credited.  To do so, we add a reference counted struct user_struct pointer to the scm_fp_list and use it to account for the number of inflight unix fds.  Cc: David Herrmann <dh.herrmann@gmail.com> Cc: Willy Tarreau <w@1wt.eu> Cc: Linus Torvalds <torvalds@linux-foundation.org> Suggested-by: Linus Torvalds <torvalds@linux-foundation.org>",
        "func_before": "struct scm_fp_list *scm_fp_dup(struct scm_fp_list *fpl)\n{\n\tstruct scm_fp_list *new_fpl;\n\tint i;\n\n\tif (!fpl)\n\t\treturn NULL;\n\n\tnew_fpl = kmemdup(fpl, offsetof(struct scm_fp_list, fp[fpl->count]),\n\t\t\t  GFP_KERNEL);\n\tif (new_fpl) {\n\t\tfor (i = 0; i < fpl->count; i++)\n\t\t\tget_file(fpl->fp[i]);\n\t\tnew_fpl->max = new_fpl->count;\n\t}\n\treturn new_fpl;\n}",
        "func": "struct scm_fp_list *scm_fp_dup(struct scm_fp_list *fpl)\n{\n\tstruct scm_fp_list *new_fpl;\n\tint i;\n\n\tif (!fpl)\n\t\treturn NULL;\n\n\tnew_fpl = kmemdup(fpl, offsetof(struct scm_fp_list, fp[fpl->count]),\n\t\t\t  GFP_KERNEL);\n\tif (new_fpl) {\n\t\tfor (i = 0; i < fpl->count; i++)\n\t\t\tget_file(fpl->fp[i]);\n\t\tnew_fpl->max = new_fpl->count;\n\t\tnew_fpl->user = get_uid(fpl->user);\n\t}\n\treturn new_fpl;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -12,6 +12,7 @@\n \t\tfor (i = 0; i < fpl->count; i++)\n \t\t\tget_file(fpl->fp[i]);\n \t\tnew_fpl->max = new_fpl->count;\n+\t\tnew_fpl->user = get_uid(fpl->user);\n \t}\n \treturn new_fpl;\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t\tnew_fpl->user = get_uid(fpl->user);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-2550",
        "func_name": "torvalds/linux/scm_fp_copy",
        "description": "The Linux kernel before 4.5 allows local users to bypass file-descriptor limits and cause a denial of service (memory consumption) by leveraging incorrect tracking of descriptor ownership and sending each descriptor over a UNIX socket before closing it. NOTE: this vulnerability exists because of an incorrect fix for CVE-2013-4312.",
        "git_url": "https://github.com/torvalds/linux/commit/415e3d3e90ce9e18727e8843ae343eda5a58fad6",
        "commit_title": "unix: correctly track in-flight fds in sending process user_struct",
        "commit_text": " The commit referenced in the Fixes tag incorrectly accounted the number of in-flight fds over a unix domain socket to the original opener of the file-descriptor. This allows another process to arbitrary deplete the original file-openers resource limit for the maximum of open files. Instead the sending processes and its struct cred should be credited.  To do so, we add a reference counted struct user_struct pointer to the scm_fp_list and use it to account for the number of inflight unix fds.  Cc: David Herrmann <dh.herrmann@gmail.com> Cc: Willy Tarreau <w@1wt.eu> Cc: Linus Torvalds <torvalds@linux-foundation.org> Suggested-by: Linus Torvalds <torvalds@linux-foundation.org>",
        "func_before": "static int scm_fp_copy(struct cmsghdr *cmsg, struct scm_fp_list **fplp)\n{\n\tint *fdp = (int*)CMSG_DATA(cmsg);\n\tstruct scm_fp_list *fpl = *fplp;\n\tstruct file **fpp;\n\tint i, num;\n\n\tnum = (cmsg->cmsg_len - CMSG_ALIGN(sizeof(struct cmsghdr)))/sizeof(int);\n\n\tif (num <= 0)\n\t\treturn 0;\n\n\tif (num > SCM_MAX_FD)\n\t\treturn -EINVAL;\n\n\tif (!fpl)\n\t{\n\t\tfpl = kmalloc(sizeof(struct scm_fp_list), GFP_KERNEL);\n\t\tif (!fpl)\n\t\t\treturn -ENOMEM;\n\t\t*fplp = fpl;\n\t\tfpl->count = 0;\n\t\tfpl->max = SCM_MAX_FD;\n\t}\n\tfpp = &fpl->fp[fpl->count];\n\n\tif (fpl->count + num > fpl->max)\n\t\treturn -EINVAL;\n\n\t/*\n\t *\tVerify the descriptors and increment the usage count.\n\t */\n\n\tfor (i=0; i< num; i++)\n\t{\n\t\tint fd = fdp[i];\n\t\tstruct file *file;\n\n\t\tif (fd < 0 || !(file = fget_raw(fd)))\n\t\t\treturn -EBADF;\n\t\t*fpp++ = file;\n\t\tfpl->count++;\n\t}\n\treturn num;\n}",
        "func": "static int scm_fp_copy(struct cmsghdr *cmsg, struct scm_fp_list **fplp)\n{\n\tint *fdp = (int*)CMSG_DATA(cmsg);\n\tstruct scm_fp_list *fpl = *fplp;\n\tstruct file **fpp;\n\tint i, num;\n\n\tnum = (cmsg->cmsg_len - CMSG_ALIGN(sizeof(struct cmsghdr)))/sizeof(int);\n\n\tif (num <= 0)\n\t\treturn 0;\n\n\tif (num > SCM_MAX_FD)\n\t\treturn -EINVAL;\n\n\tif (!fpl)\n\t{\n\t\tfpl = kmalloc(sizeof(struct scm_fp_list), GFP_KERNEL);\n\t\tif (!fpl)\n\t\t\treturn -ENOMEM;\n\t\t*fplp = fpl;\n\t\tfpl->count = 0;\n\t\tfpl->max = SCM_MAX_FD;\n\t\tfpl->user = NULL;\n\t}\n\tfpp = &fpl->fp[fpl->count];\n\n\tif (fpl->count + num > fpl->max)\n\t\treturn -EINVAL;\n\n\t/*\n\t *\tVerify the descriptors and increment the usage count.\n\t */\n\n\tfor (i=0; i< num; i++)\n\t{\n\t\tint fd = fdp[i];\n\t\tstruct file *file;\n\n\t\tif (fd < 0 || !(file = fget_raw(fd)))\n\t\t\treturn -EBADF;\n\t\t*fpp++ = file;\n\t\tfpl->count++;\n\t}\n\n\tif (!fpl->user)\n\t\tfpl->user = get_uid(current_user());\n\n\treturn num;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -21,6 +21,7 @@\n \t\t*fplp = fpl;\n \t\tfpl->count = 0;\n \t\tfpl->max = SCM_MAX_FD;\n+\t\tfpl->user = NULL;\n \t}\n \tfpp = &fpl->fp[fpl->count];\n \n@@ -41,5 +42,9 @@\n \t\t*fpp++ = file;\n \t\tfpl->count++;\n \t}\n+\n+\tif (!fpl->user)\n+\t\tfpl->user = get_uid(current_user());\n+\n \treturn num;\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t\tfpl->user = NULL;",
                "",
                "\tif (!fpl->user)",
                "\t\tfpl->user = get_uid(current_user());",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2016-2550",
        "func_name": "torvalds/linux/__scm_destroy",
        "description": "The Linux kernel before 4.5 allows local users to bypass file-descriptor limits and cause a denial of service (memory consumption) by leveraging incorrect tracking of descriptor ownership and sending each descriptor over a UNIX socket before closing it. NOTE: this vulnerability exists because of an incorrect fix for CVE-2013-4312.",
        "git_url": "https://github.com/torvalds/linux/commit/415e3d3e90ce9e18727e8843ae343eda5a58fad6",
        "commit_title": "unix: correctly track in-flight fds in sending process user_struct",
        "commit_text": " The commit referenced in the Fixes tag incorrectly accounted the number of in-flight fds over a unix domain socket to the original opener of the file-descriptor. This allows another process to arbitrary deplete the original file-openers resource limit for the maximum of open files. Instead the sending processes and its struct cred should be credited.  To do so, we add a reference counted struct user_struct pointer to the scm_fp_list and use it to account for the number of inflight unix fds.  Cc: David Herrmann <dh.herrmann@gmail.com> Cc: Willy Tarreau <w@1wt.eu> Cc: Linus Torvalds <torvalds@linux-foundation.org> Suggested-by: Linus Torvalds <torvalds@linux-foundation.org>",
        "func_before": "void __scm_destroy(struct scm_cookie *scm)\n{\n\tstruct scm_fp_list *fpl = scm->fp;\n\tint i;\n\n\tif (fpl) {\n\t\tscm->fp = NULL;\n\t\tfor (i=fpl->count-1; i>=0; i--)\n\t\t\tfput(fpl->fp[i]);\n\t\tkfree(fpl);\n\t}\n}",
        "func": "void __scm_destroy(struct scm_cookie *scm)\n{\n\tstruct scm_fp_list *fpl = scm->fp;\n\tint i;\n\n\tif (fpl) {\n\t\tscm->fp = NULL;\n\t\tfor (i=fpl->count-1; i>=0; i--)\n\t\t\tfput(fpl->fp[i]);\n\t\tfree_uid(fpl->user);\n\t\tkfree(fpl);\n\t}\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -7,6 +7,7 @@\n \t\tscm->fp = NULL;\n \t\tfor (i=fpl->count-1; i>=0; i--)\n \t\t\tfput(fpl->fp[i]);\n+\t\tfree_uid(fpl->user);\n \t\tkfree(fpl);\n \t}\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t\tfree_uid(fpl->user);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-2550",
        "func_name": "torvalds/linux/unix_notinflight",
        "description": "The Linux kernel before 4.5 allows local users to bypass file-descriptor limits and cause a denial of service (memory consumption) by leveraging incorrect tracking of descriptor ownership and sending each descriptor over a UNIX socket before closing it. NOTE: this vulnerability exists because of an incorrect fix for CVE-2013-4312.",
        "git_url": "https://github.com/torvalds/linux/commit/415e3d3e90ce9e18727e8843ae343eda5a58fad6",
        "commit_title": "unix: correctly track in-flight fds in sending process user_struct",
        "commit_text": " The commit referenced in the Fixes tag incorrectly accounted the number of in-flight fds over a unix domain socket to the original opener of the file-descriptor. This allows another process to arbitrary deplete the original file-openers resource limit for the maximum of open files. Instead the sending processes and its struct cred should be credited.  To do so, we add a reference counted struct user_struct pointer to the scm_fp_list and use it to account for the number of inflight unix fds.  Cc: David Herrmann <dh.herrmann@gmail.com> Cc: Willy Tarreau <w@1wt.eu> Cc: Linus Torvalds <torvalds@linux-foundation.org> Suggested-by: Linus Torvalds <torvalds@linux-foundation.org>",
        "func_before": "void unix_notinflight(struct file *fp)\n{\n\tstruct sock *s = unix_get_socket(fp);\n\n\tspin_lock(&unix_gc_lock);\n\n\tif (s) {\n\t\tstruct unix_sock *u = unix_sk(s);\n\n\t\tBUG_ON(list_empty(&u->link));\n\n\t\tif (atomic_long_dec_and_test(&u->inflight))\n\t\t\tlist_del_init(&u->link);\n\t\tunix_tot_inflight--;\n\t}\n\tfp->f_cred->user->unix_inflight--;\n\tspin_unlock(&unix_gc_lock);\n}",
        "func": "void unix_notinflight(struct user_struct *user, struct file *fp)\n{\n\tstruct sock *s = unix_get_socket(fp);\n\n\tspin_lock(&unix_gc_lock);\n\n\tif (s) {\n\t\tstruct unix_sock *u = unix_sk(s);\n\n\t\tBUG_ON(list_empty(&u->link));\n\n\t\tif (atomic_long_dec_and_test(&u->inflight))\n\t\t\tlist_del_init(&u->link);\n\t\tunix_tot_inflight--;\n\t}\n\tuser->unix_inflight--;\n\tspin_unlock(&unix_gc_lock);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,4 +1,4 @@\n-void unix_notinflight(struct file *fp)\n+void unix_notinflight(struct user_struct *user, struct file *fp)\n {\n \tstruct sock *s = unix_get_socket(fp);\n \n@@ -13,6 +13,6 @@\n \t\t\tlist_del_init(&u->link);\n \t\tunix_tot_inflight--;\n \t}\n-\tfp->f_cred->user->unix_inflight--;\n+\tuser->unix_inflight--;\n \tspin_unlock(&unix_gc_lock);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "void unix_notinflight(struct file *fp)",
                "\tfp->f_cred->user->unix_inflight--;"
            ],
            "added_lines": [
                "void unix_notinflight(struct user_struct *user, struct file *fp)",
                "\tuser->unix_inflight--;"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-2550",
        "func_name": "torvalds/linux/unix_inflight",
        "description": "The Linux kernel before 4.5 allows local users to bypass file-descriptor limits and cause a denial of service (memory consumption) by leveraging incorrect tracking of descriptor ownership and sending each descriptor over a UNIX socket before closing it. NOTE: this vulnerability exists because of an incorrect fix for CVE-2013-4312.",
        "git_url": "https://github.com/torvalds/linux/commit/415e3d3e90ce9e18727e8843ae343eda5a58fad6",
        "commit_title": "unix: correctly track in-flight fds in sending process user_struct",
        "commit_text": " The commit referenced in the Fixes tag incorrectly accounted the number of in-flight fds over a unix domain socket to the original opener of the file-descriptor. This allows another process to arbitrary deplete the original file-openers resource limit for the maximum of open files. Instead the sending processes and its struct cred should be credited.  To do so, we add a reference counted struct user_struct pointer to the scm_fp_list and use it to account for the number of inflight unix fds.  Cc: David Herrmann <dh.herrmann@gmail.com> Cc: Willy Tarreau <w@1wt.eu> Cc: Linus Torvalds <torvalds@linux-foundation.org> Suggested-by: Linus Torvalds <torvalds@linux-foundation.org>",
        "func_before": "void unix_inflight(struct file *fp)\n{\n\tstruct sock *s = unix_get_socket(fp);\n\n\tspin_lock(&unix_gc_lock);\n\n\tif (s) {\n\t\tstruct unix_sock *u = unix_sk(s);\n\n\t\tif (atomic_long_inc_return(&u->inflight) == 1) {\n\t\t\tBUG_ON(!list_empty(&u->link));\n\t\t\tlist_add_tail(&u->link, &gc_inflight_list);\n\t\t} else {\n\t\t\tBUG_ON(list_empty(&u->link));\n\t\t}\n\t\tunix_tot_inflight++;\n\t}\n\tfp->f_cred->user->unix_inflight++;\n\tspin_unlock(&unix_gc_lock);\n}",
        "func": "void unix_inflight(struct user_struct *user, struct file *fp)\n{\n\tstruct sock *s = unix_get_socket(fp);\n\n\tspin_lock(&unix_gc_lock);\n\n\tif (s) {\n\t\tstruct unix_sock *u = unix_sk(s);\n\n\t\tif (atomic_long_inc_return(&u->inflight) == 1) {\n\t\t\tBUG_ON(!list_empty(&u->link));\n\t\t\tlist_add_tail(&u->link, &gc_inflight_list);\n\t\t} else {\n\t\t\tBUG_ON(list_empty(&u->link));\n\t\t}\n\t\tunix_tot_inflight++;\n\t}\n\tuser->unix_inflight++;\n\tspin_unlock(&unix_gc_lock);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,4 +1,4 @@\n-void unix_inflight(struct file *fp)\n+void unix_inflight(struct user_struct *user, struct file *fp)\n {\n \tstruct sock *s = unix_get_socket(fp);\n \n@@ -15,6 +15,6 @@\n \t\t}\n \t\tunix_tot_inflight++;\n \t}\n-\tfp->f_cred->user->unix_inflight++;\n+\tuser->unix_inflight++;\n \tspin_unlock(&unix_gc_lock);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "void unix_inflight(struct file *fp)",
                "\tfp->f_cred->user->unix_inflight++;"
            ],
            "added_lines": [
                "void unix_inflight(struct user_struct *user, struct file *fp)",
                "\tuser->unix_inflight++;"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-2550",
        "func_name": "torvalds/linux/unix_attach_fds",
        "description": "The Linux kernel before 4.5 allows local users to bypass file-descriptor limits and cause a denial of service (memory consumption) by leveraging incorrect tracking of descriptor ownership and sending each descriptor over a UNIX socket before closing it. NOTE: this vulnerability exists because of an incorrect fix for CVE-2013-4312.",
        "git_url": "https://github.com/torvalds/linux/commit/415e3d3e90ce9e18727e8843ae343eda5a58fad6",
        "commit_title": "unix: correctly track in-flight fds in sending process user_struct",
        "commit_text": " The commit referenced in the Fixes tag incorrectly accounted the number of in-flight fds over a unix domain socket to the original opener of the file-descriptor. This allows another process to arbitrary deplete the original file-openers resource limit for the maximum of open files. Instead the sending processes and its struct cred should be credited.  To do so, we add a reference counted struct user_struct pointer to the scm_fp_list and use it to account for the number of inflight unix fds.  Cc: David Herrmann <dh.herrmann@gmail.com> Cc: Willy Tarreau <w@1wt.eu> Cc: Linus Torvalds <torvalds@linux-foundation.org> Suggested-by: Linus Torvalds <torvalds@linux-foundation.org>",
        "func_before": "static int unix_attach_fds(struct scm_cookie *scm, struct sk_buff *skb)\n{\n\tint i;\n\tunsigned char max_level = 0;\n\tint unix_sock_count = 0;\n\n\tif (too_many_unix_fds(current))\n\t\treturn -ETOOMANYREFS;\n\n\tfor (i = scm->fp->count - 1; i >= 0; i--) {\n\t\tstruct sock *sk = unix_get_socket(scm->fp->fp[i]);\n\n\t\tif (sk) {\n\t\t\tunix_sock_count++;\n\t\t\tmax_level = max(max_level,\n\t\t\t\t\tunix_sk(sk)->recursion_level);\n\t\t}\n\t}\n\tif (unlikely(max_level > MAX_RECURSION_LEVEL))\n\t\treturn -ETOOMANYREFS;\n\n\t/*\n\t * Need to duplicate file references for the sake of garbage\n\t * collection.  Otherwise a socket in the fps might become a\n\t * candidate for GC while the skb is not yet queued.\n\t */\n\tUNIXCB(skb).fp = scm_fp_dup(scm->fp);\n\tif (!UNIXCB(skb).fp)\n\t\treturn -ENOMEM;\n\n\tfor (i = scm->fp->count - 1; i >= 0; i--)\n\t\tunix_inflight(scm->fp->fp[i]);\n\treturn max_level;\n}",
        "func": "static int unix_attach_fds(struct scm_cookie *scm, struct sk_buff *skb)\n{\n\tint i;\n\tunsigned char max_level = 0;\n\tint unix_sock_count = 0;\n\n\tif (too_many_unix_fds(current))\n\t\treturn -ETOOMANYREFS;\n\n\tfor (i = scm->fp->count - 1; i >= 0; i--) {\n\t\tstruct sock *sk = unix_get_socket(scm->fp->fp[i]);\n\n\t\tif (sk) {\n\t\t\tunix_sock_count++;\n\t\t\tmax_level = max(max_level,\n\t\t\t\t\tunix_sk(sk)->recursion_level);\n\t\t}\n\t}\n\tif (unlikely(max_level > MAX_RECURSION_LEVEL))\n\t\treturn -ETOOMANYREFS;\n\n\t/*\n\t * Need to duplicate file references for the sake of garbage\n\t * collection.  Otherwise a socket in the fps might become a\n\t * candidate for GC while the skb is not yet queued.\n\t */\n\tUNIXCB(skb).fp = scm_fp_dup(scm->fp);\n\tif (!UNIXCB(skb).fp)\n\t\treturn -ENOMEM;\n\n\tfor (i = scm->fp->count - 1; i >= 0; i--)\n\t\tunix_inflight(scm->fp->user, scm->fp->fp[i]);\n\treturn max_level;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -29,6 +29,6 @@\n \t\treturn -ENOMEM;\n \n \tfor (i = scm->fp->count - 1; i >= 0; i--)\n-\t\tunix_inflight(scm->fp->fp[i]);\n+\t\tunix_inflight(scm->fp->user, scm->fp->fp[i]);\n \treturn max_level;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tunix_inflight(scm->fp->fp[i]);"
            ],
            "added_lines": [
                "\t\tunix_inflight(scm->fp->user, scm->fp->fp[i]);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-2550",
        "func_name": "torvalds/linux/unix_detach_fds",
        "description": "The Linux kernel before 4.5 allows local users to bypass file-descriptor limits and cause a denial of service (memory consumption) by leveraging incorrect tracking of descriptor ownership and sending each descriptor over a UNIX socket before closing it. NOTE: this vulnerability exists because of an incorrect fix for CVE-2013-4312.",
        "git_url": "https://github.com/torvalds/linux/commit/415e3d3e90ce9e18727e8843ae343eda5a58fad6",
        "commit_title": "unix: correctly track in-flight fds in sending process user_struct",
        "commit_text": " The commit referenced in the Fixes tag incorrectly accounted the number of in-flight fds over a unix domain socket to the original opener of the file-descriptor. This allows another process to arbitrary deplete the original file-openers resource limit for the maximum of open files. Instead the sending processes and its struct cred should be credited.  To do so, we add a reference counted struct user_struct pointer to the scm_fp_list and use it to account for the number of inflight unix fds.  Cc: David Herrmann <dh.herrmann@gmail.com> Cc: Willy Tarreau <w@1wt.eu> Cc: Linus Torvalds <torvalds@linux-foundation.org> Suggested-by: Linus Torvalds <torvalds@linux-foundation.org>",
        "func_before": "static void unix_detach_fds(struct scm_cookie *scm, struct sk_buff *skb)\n{\n\tint i;\n\n\tscm->fp = UNIXCB(skb).fp;\n\tUNIXCB(skb).fp = NULL;\n\n\tfor (i = scm->fp->count-1; i >= 0; i--)\n\t\tunix_notinflight(scm->fp->fp[i]);\n}",
        "func": "static void unix_detach_fds(struct scm_cookie *scm, struct sk_buff *skb)\n{\n\tint i;\n\n\tscm->fp = UNIXCB(skb).fp;\n\tUNIXCB(skb).fp = NULL;\n\n\tfor (i = scm->fp->count-1; i >= 0; i--)\n\t\tunix_notinflight(scm->fp->user, scm->fp->fp[i]);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -6,5 +6,5 @@\n \tUNIXCB(skb).fp = NULL;\n \n \tfor (i = scm->fp->count-1; i >= 0; i--)\n-\t\tunix_notinflight(scm->fp->fp[i]);\n+\t\tunix_notinflight(scm->fp->user, scm->fp->fp[i]);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tunix_notinflight(scm->fp->fp[i]);"
            ],
            "added_lines": [
                "\t\tunix_notinflight(scm->fp->user, scm->fp->fp[i]);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-2847",
        "func_name": "torvalds/linux/pipe_set_size",
        "description": "fs/pipe.c in the Linux kernel before 4.5 does not limit the amount of unread data in pipes, which allows local users to cause a denial of service (memory consumption) by creating many pipes with non-default sizes.",
        "git_url": "https://github.com/torvalds/linux/commit/759c01142a5d0f364a462346168a56de28a80f52",
        "commit_title": "pipe: limit the per-user amount of pages allocated in pipes",
        "commit_text": " On no-so-small systems, it is possible for a single process to cause an OOM condition by filling large pipes with data that are never read. A typical process filling 4000 pipes with 1 MB of data will use 4 GB of memory. On small systems it may be tricky to set the pipe max size to prevent this from happening.  This patch makes it possible to enforce a per-user soft limit above which new pipes will be limited to a single page, effectively limiting them to 4 kB each, as well as a hard limit above which no new pipes may be created for this user. This has the effect of protecting the system against memory abuse without hurting other users, and still allowing pipes to work correctly though with less data at once.  The limit are controlled by two new sysctls : pipe-user-pages-soft, and pipe-user-pages-hard. Both may be disabled by setting them to zero. The default soft limit allows the default number of FDs per process (1024) to create pipes of the default size (64kB), thus reaching a limit of 64MB before starting to create only smaller pipes. With 256 processes limited to 1024 FDs each, this results in 1024*64kB + (256*1024 - 1024) * 4kB = 1084 MB of memory allocated for a user. The hard limit is disabled by default to avoid breaking existing applications that make intensive use of pipes (eg: for splicing).  Mitigates: CVE-2013-4312 (Linux 2.0+) Suggested-by: Linus Torvalds <torvalds@linux-foundation.org>",
        "func_before": "static long pipe_set_size(struct pipe_inode_info *pipe, unsigned long nr_pages)\n{\n\tstruct pipe_buffer *bufs;\n\n\t/*\n\t * We can shrink the pipe, if arg >= pipe->nrbufs. Since we don't\n\t * expect a lot of shrink+grow operations, just free and allocate\n\t * again like we would do for growing. If the pipe currently\n\t * contains more buffers than arg, then return busy.\n\t */\n\tif (nr_pages < pipe->nrbufs)\n\t\treturn -EBUSY;\n\n\tbufs = kcalloc(nr_pages, sizeof(*bufs), GFP_KERNEL | __GFP_NOWARN);\n\tif (unlikely(!bufs))\n\t\treturn -ENOMEM;\n\n\t/*\n\t * The pipe array wraps around, so just start the new one at zero\n\t * and adjust the indexes.\n\t */\n\tif (pipe->nrbufs) {\n\t\tunsigned int tail;\n\t\tunsigned int head;\n\n\t\ttail = pipe->curbuf + pipe->nrbufs;\n\t\tif (tail < pipe->buffers)\n\t\t\ttail = 0;\n\t\telse\n\t\t\ttail &= (pipe->buffers - 1);\n\n\t\thead = pipe->nrbufs - tail;\n\t\tif (head)\n\t\t\tmemcpy(bufs, pipe->bufs + pipe->curbuf, head * sizeof(struct pipe_buffer));\n\t\tif (tail)\n\t\t\tmemcpy(bufs + head, pipe->bufs, tail * sizeof(struct pipe_buffer));\n\t}\n\n\tpipe->curbuf = 0;\n\tkfree(pipe->bufs);\n\tpipe->bufs = bufs;\n\tpipe->buffers = nr_pages;\n\treturn nr_pages * PAGE_SIZE;\n}",
        "func": "static long pipe_set_size(struct pipe_inode_info *pipe, unsigned long nr_pages)\n{\n\tstruct pipe_buffer *bufs;\n\n\t/*\n\t * We can shrink the pipe, if arg >= pipe->nrbufs. Since we don't\n\t * expect a lot of shrink+grow operations, just free and allocate\n\t * again like we would do for growing. If the pipe currently\n\t * contains more buffers than arg, then return busy.\n\t */\n\tif (nr_pages < pipe->nrbufs)\n\t\treturn -EBUSY;\n\n\tbufs = kcalloc(nr_pages, sizeof(*bufs), GFP_KERNEL | __GFP_NOWARN);\n\tif (unlikely(!bufs))\n\t\treturn -ENOMEM;\n\n\t/*\n\t * The pipe array wraps around, so just start the new one at zero\n\t * and adjust the indexes.\n\t */\n\tif (pipe->nrbufs) {\n\t\tunsigned int tail;\n\t\tunsigned int head;\n\n\t\ttail = pipe->curbuf + pipe->nrbufs;\n\t\tif (tail < pipe->buffers)\n\t\t\ttail = 0;\n\t\telse\n\t\t\ttail &= (pipe->buffers - 1);\n\n\t\thead = pipe->nrbufs - tail;\n\t\tif (head)\n\t\t\tmemcpy(bufs, pipe->bufs + pipe->curbuf, head * sizeof(struct pipe_buffer));\n\t\tif (tail)\n\t\t\tmemcpy(bufs + head, pipe->bufs, tail * sizeof(struct pipe_buffer));\n\t}\n\n\taccount_pipe_buffers(pipe, pipe->buffers, nr_pages);\n\tpipe->curbuf = 0;\n\tkfree(pipe->bufs);\n\tpipe->bufs = bufs;\n\tpipe->buffers = nr_pages;\n\treturn nr_pages * PAGE_SIZE;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -36,6 +36,7 @@\n \t\t\tmemcpy(bufs + head, pipe->bufs, tail * sizeof(struct pipe_buffer));\n \t}\n \n+\taccount_pipe_buffers(pipe, pipe->buffers, nr_pages);\n \tpipe->curbuf = 0;\n \tkfree(pipe->bufs);\n \tpipe->bufs = bufs;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\taccount_pipe_buffers(pipe, pipe->buffers, nr_pages);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-2847",
        "func_name": "torvalds/linux/pipe_fcntl",
        "description": "fs/pipe.c in the Linux kernel before 4.5 does not limit the amount of unread data in pipes, which allows local users to cause a denial of service (memory consumption) by creating many pipes with non-default sizes.",
        "git_url": "https://github.com/torvalds/linux/commit/759c01142a5d0f364a462346168a56de28a80f52",
        "commit_title": "pipe: limit the per-user amount of pages allocated in pipes",
        "commit_text": " On no-so-small systems, it is possible for a single process to cause an OOM condition by filling large pipes with data that are never read. A typical process filling 4000 pipes with 1 MB of data will use 4 GB of memory. On small systems it may be tricky to set the pipe max size to prevent this from happening.  This patch makes it possible to enforce a per-user soft limit above which new pipes will be limited to a single page, effectively limiting them to 4 kB each, as well as a hard limit above which no new pipes may be created for this user. This has the effect of protecting the system against memory abuse without hurting other users, and still allowing pipes to work correctly though with less data at once.  The limit are controlled by two new sysctls : pipe-user-pages-soft, and pipe-user-pages-hard. Both may be disabled by setting them to zero. The default soft limit allows the default number of FDs per process (1024) to create pipes of the default size (64kB), thus reaching a limit of 64MB before starting to create only smaller pipes. With 256 processes limited to 1024 FDs each, this results in 1024*64kB + (256*1024 - 1024) * 4kB = 1084 MB of memory allocated for a user. The hard limit is disabled by default to avoid breaking existing applications that make intensive use of pipes (eg: for splicing).  Mitigates: CVE-2013-4312 (Linux 2.0+) Suggested-by: Linus Torvalds <torvalds@linux-foundation.org>",
        "func_before": "long pipe_fcntl(struct file *file, unsigned int cmd, unsigned long arg)\n{\n\tstruct pipe_inode_info *pipe;\n\tlong ret;\n\n\tpipe = get_pipe_info(file);\n\tif (!pipe)\n\t\treturn -EBADF;\n\n\t__pipe_lock(pipe);\n\n\tswitch (cmd) {\n\tcase F_SETPIPE_SZ: {\n\t\tunsigned int size, nr_pages;\n\n\t\tsize = round_pipe_size(arg);\n\t\tnr_pages = size >> PAGE_SHIFT;\n\n\t\tret = -EINVAL;\n\t\tif (!nr_pages)\n\t\t\tgoto out;\n\n\t\tif (!capable(CAP_SYS_RESOURCE) && size > pipe_max_size) {\n\t\t\tret = -EPERM;\n\t\t\tgoto out;\n\t\t}\n\t\tret = pipe_set_size(pipe, nr_pages);\n\t\tbreak;\n\t\t}\n\tcase F_GETPIPE_SZ:\n\t\tret = pipe->buffers * PAGE_SIZE;\n\t\tbreak;\n\tdefault:\n\t\tret = -EINVAL;\n\t\tbreak;\n\t}\n\nout:\n\t__pipe_unlock(pipe);\n\treturn ret;\n}",
        "func": "long pipe_fcntl(struct file *file, unsigned int cmd, unsigned long arg)\n{\n\tstruct pipe_inode_info *pipe;\n\tlong ret;\n\n\tpipe = get_pipe_info(file);\n\tif (!pipe)\n\t\treturn -EBADF;\n\n\t__pipe_lock(pipe);\n\n\tswitch (cmd) {\n\tcase F_SETPIPE_SZ: {\n\t\tunsigned int size, nr_pages;\n\n\t\tsize = round_pipe_size(arg);\n\t\tnr_pages = size >> PAGE_SHIFT;\n\n\t\tret = -EINVAL;\n\t\tif (!nr_pages)\n\t\t\tgoto out;\n\n\t\tif (!capable(CAP_SYS_RESOURCE) && size > pipe_max_size) {\n\t\t\tret = -EPERM;\n\t\t\tgoto out;\n\t\t} else if ((too_many_pipe_buffers_hard(pipe->user) ||\n\t\t\t    too_many_pipe_buffers_soft(pipe->user)) &&\n\t\t           !capable(CAP_SYS_RESOURCE) && !capable(CAP_SYS_ADMIN)) {\n\t\t\tret = -EPERM;\n\t\t\tgoto out;\n\t\t}\n\t\tret = pipe_set_size(pipe, nr_pages);\n\t\tbreak;\n\t\t}\n\tcase F_GETPIPE_SZ:\n\t\tret = pipe->buffers * PAGE_SIZE;\n\t\tbreak;\n\tdefault:\n\t\tret = -EINVAL;\n\t\tbreak;\n\t}\n\nout:\n\t__pipe_unlock(pipe);\n\treturn ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -23,6 +23,11 @@\n \t\tif (!capable(CAP_SYS_RESOURCE) && size > pipe_max_size) {\n \t\t\tret = -EPERM;\n \t\t\tgoto out;\n+\t\t} else if ((too_many_pipe_buffers_hard(pipe->user) ||\n+\t\t\t    too_many_pipe_buffers_soft(pipe->user)) &&\n+\t\t           !capable(CAP_SYS_RESOURCE) && !capable(CAP_SYS_ADMIN)) {\n+\t\t\tret = -EPERM;\n+\t\t\tgoto out;\n \t\t}\n \t\tret = pipe_set_size(pipe, nr_pages);\n \t\tbreak;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t\t} else if ((too_many_pipe_buffers_hard(pipe->user) ||",
                "\t\t\t    too_many_pipe_buffers_soft(pipe->user)) &&",
                "\t\t           !capable(CAP_SYS_RESOURCE) && !capable(CAP_SYS_ADMIN)) {",
                "\t\t\tret = -EPERM;",
                "\t\t\tgoto out;"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-2847",
        "func_name": "torvalds/linux/alloc_pipe_info",
        "description": "fs/pipe.c in the Linux kernel before 4.5 does not limit the amount of unread data in pipes, which allows local users to cause a denial of service (memory consumption) by creating many pipes with non-default sizes.",
        "git_url": "https://github.com/torvalds/linux/commit/759c01142a5d0f364a462346168a56de28a80f52",
        "commit_title": "pipe: limit the per-user amount of pages allocated in pipes",
        "commit_text": " On no-so-small systems, it is possible for a single process to cause an OOM condition by filling large pipes with data that are never read. A typical process filling 4000 pipes with 1 MB of data will use 4 GB of memory. On small systems it may be tricky to set the pipe max size to prevent this from happening.  This patch makes it possible to enforce a per-user soft limit above which new pipes will be limited to a single page, effectively limiting them to 4 kB each, as well as a hard limit above which no new pipes may be created for this user. This has the effect of protecting the system against memory abuse without hurting other users, and still allowing pipes to work correctly though with less data at once.  The limit are controlled by two new sysctls : pipe-user-pages-soft, and pipe-user-pages-hard. Both may be disabled by setting them to zero. The default soft limit allows the default number of FDs per process (1024) to create pipes of the default size (64kB), thus reaching a limit of 64MB before starting to create only smaller pipes. With 256 processes limited to 1024 FDs each, this results in 1024*64kB + (256*1024 - 1024) * 4kB = 1084 MB of memory allocated for a user. The hard limit is disabled by default to avoid breaking existing applications that make intensive use of pipes (eg: for splicing).  Mitigates: CVE-2013-4312 (Linux 2.0+) Suggested-by: Linus Torvalds <torvalds@linux-foundation.org>",
        "func_before": "struct pipe_inode_info *alloc_pipe_info(void)\n{\n\tstruct pipe_inode_info *pipe;\n\n\tpipe = kzalloc(sizeof(struct pipe_inode_info), GFP_KERNEL);\n\tif (pipe) {\n\t\tpipe->bufs = kzalloc(sizeof(struct pipe_buffer) * PIPE_DEF_BUFFERS, GFP_KERNEL);\n\t\tif (pipe->bufs) {\n\t\t\tinit_waitqueue_head(&pipe->wait);\n\t\t\tpipe->r_counter = pipe->w_counter = 1;\n\t\t\tpipe->buffers = PIPE_DEF_BUFFERS;\n\t\t\tmutex_init(&pipe->mutex);\n\t\t\treturn pipe;\n\t\t}\n\t\tkfree(pipe);\n\t}\n\n\treturn NULL;\n}",
        "func": "struct pipe_inode_info *alloc_pipe_info(void)\n{\n\tstruct pipe_inode_info *pipe;\n\n\tpipe = kzalloc(sizeof(struct pipe_inode_info), GFP_KERNEL);\n\tif (pipe) {\n\t\tunsigned long pipe_bufs = PIPE_DEF_BUFFERS;\n\t\tstruct user_struct *user = get_current_user();\n\n\t\tif (!too_many_pipe_buffers_hard(user)) {\n\t\t\tif (too_many_pipe_buffers_soft(user))\n\t\t\t\tpipe_bufs = 1;\n\t\t\tpipe->bufs = kzalloc(sizeof(struct pipe_buffer) * pipe_bufs, GFP_KERNEL);\n\t\t}\n\n\t\tif (pipe->bufs) {\n\t\t\tinit_waitqueue_head(&pipe->wait);\n\t\t\tpipe->r_counter = pipe->w_counter = 1;\n\t\t\tpipe->buffers = pipe_bufs;\n\t\t\tpipe->user = user;\n\t\t\taccount_pipe_buffers(pipe, 0, pipe_bufs);\n\t\t\tmutex_init(&pipe->mutex);\n\t\t\treturn pipe;\n\t\t}\n\t\tfree_uid(user);\n\t\tkfree(pipe);\n\t}\n\n\treturn NULL;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,14 +4,25 @@\n \n \tpipe = kzalloc(sizeof(struct pipe_inode_info), GFP_KERNEL);\n \tif (pipe) {\n-\t\tpipe->bufs = kzalloc(sizeof(struct pipe_buffer) * PIPE_DEF_BUFFERS, GFP_KERNEL);\n+\t\tunsigned long pipe_bufs = PIPE_DEF_BUFFERS;\n+\t\tstruct user_struct *user = get_current_user();\n+\n+\t\tif (!too_many_pipe_buffers_hard(user)) {\n+\t\t\tif (too_many_pipe_buffers_soft(user))\n+\t\t\t\tpipe_bufs = 1;\n+\t\t\tpipe->bufs = kzalloc(sizeof(struct pipe_buffer) * pipe_bufs, GFP_KERNEL);\n+\t\t}\n+\n \t\tif (pipe->bufs) {\n \t\t\tinit_waitqueue_head(&pipe->wait);\n \t\t\tpipe->r_counter = pipe->w_counter = 1;\n-\t\t\tpipe->buffers = PIPE_DEF_BUFFERS;\n+\t\t\tpipe->buffers = pipe_bufs;\n+\t\t\tpipe->user = user;\n+\t\t\taccount_pipe_buffers(pipe, 0, pipe_bufs);\n \t\t\tmutex_init(&pipe->mutex);\n \t\t\treturn pipe;\n \t\t}\n+\t\tfree_uid(user);\n \t\tkfree(pipe);\n \t}\n ",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tpipe->bufs = kzalloc(sizeof(struct pipe_buffer) * PIPE_DEF_BUFFERS, GFP_KERNEL);",
                "\t\t\tpipe->buffers = PIPE_DEF_BUFFERS;"
            ],
            "added_lines": [
                "\t\tunsigned long pipe_bufs = PIPE_DEF_BUFFERS;",
                "\t\tstruct user_struct *user = get_current_user();",
                "",
                "\t\tif (!too_many_pipe_buffers_hard(user)) {",
                "\t\t\tif (too_many_pipe_buffers_soft(user))",
                "\t\t\t\tpipe_bufs = 1;",
                "\t\t\tpipe->bufs = kzalloc(sizeof(struct pipe_buffer) * pipe_bufs, GFP_KERNEL);",
                "\t\t}",
                "",
                "\t\t\tpipe->buffers = pipe_bufs;",
                "\t\t\tpipe->user = user;",
                "\t\t\taccount_pipe_buffers(pipe, 0, pipe_bufs);",
                "\t\tfree_uid(user);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-2847",
        "func_name": "torvalds/linux/free_pipe_info",
        "description": "fs/pipe.c in the Linux kernel before 4.5 does not limit the amount of unread data in pipes, which allows local users to cause a denial of service (memory consumption) by creating many pipes with non-default sizes.",
        "git_url": "https://github.com/torvalds/linux/commit/759c01142a5d0f364a462346168a56de28a80f52",
        "commit_title": "pipe: limit the per-user amount of pages allocated in pipes",
        "commit_text": " On no-so-small systems, it is possible for a single process to cause an OOM condition by filling large pipes with data that are never read. A typical process filling 4000 pipes with 1 MB of data will use 4 GB of memory. On small systems it may be tricky to set the pipe max size to prevent this from happening.  This patch makes it possible to enforce a per-user soft limit above which new pipes will be limited to a single page, effectively limiting them to 4 kB each, as well as a hard limit above which no new pipes may be created for this user. This has the effect of protecting the system against memory abuse without hurting other users, and still allowing pipes to work correctly though with less data at once.  The limit are controlled by two new sysctls : pipe-user-pages-soft, and pipe-user-pages-hard. Both may be disabled by setting them to zero. The default soft limit allows the default number of FDs per process (1024) to create pipes of the default size (64kB), thus reaching a limit of 64MB before starting to create only smaller pipes. With 256 processes limited to 1024 FDs each, this results in 1024*64kB + (256*1024 - 1024) * 4kB = 1084 MB of memory allocated for a user. The hard limit is disabled by default to avoid breaking existing applications that make intensive use of pipes (eg: for splicing).  Mitigates: CVE-2013-4312 (Linux 2.0+) Suggested-by: Linus Torvalds <torvalds@linux-foundation.org>",
        "func_before": "void free_pipe_info(struct pipe_inode_info *pipe)\n{\n\tint i;\n\n\tfor (i = 0; i < pipe->buffers; i++) {\n\t\tstruct pipe_buffer *buf = pipe->bufs + i;\n\t\tif (buf->ops)\n\t\t\tbuf->ops->release(pipe, buf);\n\t}\n\tif (pipe->tmp_page)\n\t\t__free_page(pipe->tmp_page);\n\tkfree(pipe->bufs);\n\tkfree(pipe);\n}",
        "func": "void free_pipe_info(struct pipe_inode_info *pipe)\n{\n\tint i;\n\n\taccount_pipe_buffers(pipe, pipe->buffers, 0);\n\tfree_uid(pipe->user);\n\tfor (i = 0; i < pipe->buffers; i++) {\n\t\tstruct pipe_buffer *buf = pipe->bufs + i;\n\t\tif (buf->ops)\n\t\t\tbuf->ops->release(pipe, buf);\n\t}\n\tif (pipe->tmp_page)\n\t\t__free_page(pipe->tmp_page);\n\tkfree(pipe->bufs);\n\tkfree(pipe);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,6 +2,8 @@\n {\n \tint i;\n \n+\taccount_pipe_buffers(pipe, pipe->buffers, 0);\n+\tfree_uid(pipe->user);\n \tfor (i = 0; i < pipe->buffers; i++) {\n \t\tstruct pipe_buffer *buf = pipe->bufs + i;\n \t\tif (buf->ops)",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\taccount_pipe_buffers(pipe, pipe->buffers, 0);",
                "\tfree_uid(pipe->user);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-3156",
        "func_name": "torvalds/linux/__inet_del_ifa",
        "description": "The IPv4 implementation in the Linux kernel before 4.5.2 mishandles destruction of device objects, which allows guest OS users to cause a denial of service (host OS networking outage) by arranging for a large number of IP addresses.",
        "git_url": "https://github.com/torvalds/linux/commit/fbd40ea0180a2d328c5adc61414dc8bab9335ce2",
        "commit_title": "ipv4: Don't do expensive useless work during inetdev destroy.",
        "commit_text": " When an inetdev is destroyed, every address assigned to the interface is removed.  And in this scenerio we do two pointless things which can be very expensive if the number of assigned interfaces is large:  1) Address promotion.  We are deleting all addresses, so there is no    point in doing this.  2) A full nf conntrack table purge for every address.  We only need to    do this once, as is already caught by the existing    masq_dev_notifier so masq_inet_event() can skip this. ",
        "func_before": "static void __inet_del_ifa(struct in_device *in_dev, struct in_ifaddr **ifap,\n\t\t\t int destroy, struct nlmsghdr *nlh, u32 portid)\n{\n\tstruct in_ifaddr *promote = NULL;\n\tstruct in_ifaddr *ifa, *ifa1 = *ifap;\n\tstruct in_ifaddr *last_prim = in_dev->ifa_list;\n\tstruct in_ifaddr *prev_prom = NULL;\n\tint do_promote = IN_DEV_PROMOTE_SECONDARIES(in_dev);\n\n\tASSERT_RTNL();\n\n\t/* 1. Deleting primary ifaddr forces deletion all secondaries\n\t * unless alias promotion is set\n\t **/\n\n\tif (!(ifa1->ifa_flags & IFA_F_SECONDARY)) {\n\t\tstruct in_ifaddr **ifap1 = &ifa1->ifa_next;\n\n\t\twhile ((ifa = *ifap1) != NULL) {\n\t\t\tif (!(ifa->ifa_flags & IFA_F_SECONDARY) &&\n\t\t\t    ifa1->ifa_scope <= ifa->ifa_scope)\n\t\t\t\tlast_prim = ifa;\n\n\t\t\tif (!(ifa->ifa_flags & IFA_F_SECONDARY) ||\n\t\t\t    ifa1->ifa_mask != ifa->ifa_mask ||\n\t\t\t    !inet_ifa_match(ifa1->ifa_address, ifa)) {\n\t\t\t\tifap1 = &ifa->ifa_next;\n\t\t\t\tprev_prom = ifa;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (!do_promote) {\n\t\t\t\tinet_hash_remove(ifa);\n\t\t\t\t*ifap1 = ifa->ifa_next;\n\n\t\t\t\trtmsg_ifa(RTM_DELADDR, ifa, nlh, portid);\n\t\t\t\tblocking_notifier_call_chain(&inetaddr_chain,\n\t\t\t\t\t\tNETDEV_DOWN, ifa);\n\t\t\t\tinet_free_ifa(ifa);\n\t\t\t} else {\n\t\t\t\tpromote = ifa;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\t/* On promotion all secondaries from subnet are changing\n\t * the primary IP, we must remove all their routes silently\n\t * and later to add them back with new prefsrc. Do this\n\t * while all addresses are on the device list.\n\t */\n\tfor (ifa = promote; ifa; ifa = ifa->ifa_next) {\n\t\tif (ifa1->ifa_mask == ifa->ifa_mask &&\n\t\t    inet_ifa_match(ifa1->ifa_address, ifa))\n\t\t\tfib_del_ifaddr(ifa, ifa1);\n\t}\n\n\t/* 2. Unlink it */\n\n\t*ifap = ifa1->ifa_next;\n\tinet_hash_remove(ifa1);\n\n\t/* 3. Announce address deletion */\n\n\t/* Send message first, then call notifier.\n\t   At first sight, FIB update triggered by notifier\n\t   will refer to already deleted ifaddr, that could confuse\n\t   netlink listeners. It is not true: look, gated sees\n\t   that route deleted and if it still thinks that ifaddr\n\t   is valid, it will try to restore deleted routes... Grr.\n\t   So that, this order is correct.\n\t */\n\trtmsg_ifa(RTM_DELADDR, ifa1, nlh, portid);\n\tblocking_notifier_call_chain(&inetaddr_chain, NETDEV_DOWN, ifa1);\n\n\tif (promote) {\n\t\tstruct in_ifaddr *next_sec = promote->ifa_next;\n\n\t\tif (prev_prom) {\n\t\t\tprev_prom->ifa_next = promote->ifa_next;\n\t\t\tpromote->ifa_next = last_prim->ifa_next;\n\t\t\tlast_prim->ifa_next = promote;\n\t\t}\n\n\t\tpromote->ifa_flags &= ~IFA_F_SECONDARY;\n\t\trtmsg_ifa(RTM_NEWADDR, promote, nlh, portid);\n\t\tblocking_notifier_call_chain(&inetaddr_chain,\n\t\t\t\tNETDEV_UP, promote);\n\t\tfor (ifa = next_sec; ifa; ifa = ifa->ifa_next) {\n\t\t\tif (ifa1->ifa_mask != ifa->ifa_mask ||\n\t\t\t    !inet_ifa_match(ifa1->ifa_address, ifa))\n\t\t\t\t\tcontinue;\n\t\t\tfib_add_ifaddr(ifa);\n\t\t}\n\n\t}\n\tif (destroy)\n\t\tinet_free_ifa(ifa1);\n}",
        "func": "static void __inet_del_ifa(struct in_device *in_dev, struct in_ifaddr **ifap,\n\t\t\t int destroy, struct nlmsghdr *nlh, u32 portid)\n{\n\tstruct in_ifaddr *promote = NULL;\n\tstruct in_ifaddr *ifa, *ifa1 = *ifap;\n\tstruct in_ifaddr *last_prim = in_dev->ifa_list;\n\tstruct in_ifaddr *prev_prom = NULL;\n\tint do_promote = IN_DEV_PROMOTE_SECONDARIES(in_dev);\n\n\tASSERT_RTNL();\n\n\tif (in_dev->dead)\n\t\tgoto no_promotions;\n\n\t/* 1. Deleting primary ifaddr forces deletion all secondaries\n\t * unless alias promotion is set\n\t **/\n\n\tif (!(ifa1->ifa_flags & IFA_F_SECONDARY)) {\n\t\tstruct in_ifaddr **ifap1 = &ifa1->ifa_next;\n\n\t\twhile ((ifa = *ifap1) != NULL) {\n\t\t\tif (!(ifa->ifa_flags & IFA_F_SECONDARY) &&\n\t\t\t    ifa1->ifa_scope <= ifa->ifa_scope)\n\t\t\t\tlast_prim = ifa;\n\n\t\t\tif (!(ifa->ifa_flags & IFA_F_SECONDARY) ||\n\t\t\t    ifa1->ifa_mask != ifa->ifa_mask ||\n\t\t\t    !inet_ifa_match(ifa1->ifa_address, ifa)) {\n\t\t\t\tifap1 = &ifa->ifa_next;\n\t\t\t\tprev_prom = ifa;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (!do_promote) {\n\t\t\t\tinet_hash_remove(ifa);\n\t\t\t\t*ifap1 = ifa->ifa_next;\n\n\t\t\t\trtmsg_ifa(RTM_DELADDR, ifa, nlh, portid);\n\t\t\t\tblocking_notifier_call_chain(&inetaddr_chain,\n\t\t\t\t\t\tNETDEV_DOWN, ifa);\n\t\t\t\tinet_free_ifa(ifa);\n\t\t\t} else {\n\t\t\t\tpromote = ifa;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\t/* On promotion all secondaries from subnet are changing\n\t * the primary IP, we must remove all their routes silently\n\t * and later to add them back with new prefsrc. Do this\n\t * while all addresses are on the device list.\n\t */\n\tfor (ifa = promote; ifa; ifa = ifa->ifa_next) {\n\t\tif (ifa1->ifa_mask == ifa->ifa_mask &&\n\t\t    inet_ifa_match(ifa1->ifa_address, ifa))\n\t\t\tfib_del_ifaddr(ifa, ifa1);\n\t}\n\nno_promotions:\n\t/* 2. Unlink it */\n\n\t*ifap = ifa1->ifa_next;\n\tinet_hash_remove(ifa1);\n\n\t/* 3. Announce address deletion */\n\n\t/* Send message first, then call notifier.\n\t   At first sight, FIB update triggered by notifier\n\t   will refer to already deleted ifaddr, that could confuse\n\t   netlink listeners. It is not true: look, gated sees\n\t   that route deleted and if it still thinks that ifaddr\n\t   is valid, it will try to restore deleted routes... Grr.\n\t   So that, this order is correct.\n\t */\n\trtmsg_ifa(RTM_DELADDR, ifa1, nlh, portid);\n\tblocking_notifier_call_chain(&inetaddr_chain, NETDEV_DOWN, ifa1);\n\n\tif (promote) {\n\t\tstruct in_ifaddr *next_sec = promote->ifa_next;\n\n\t\tif (prev_prom) {\n\t\t\tprev_prom->ifa_next = promote->ifa_next;\n\t\t\tpromote->ifa_next = last_prim->ifa_next;\n\t\t\tlast_prim->ifa_next = promote;\n\t\t}\n\n\t\tpromote->ifa_flags &= ~IFA_F_SECONDARY;\n\t\trtmsg_ifa(RTM_NEWADDR, promote, nlh, portid);\n\t\tblocking_notifier_call_chain(&inetaddr_chain,\n\t\t\t\tNETDEV_UP, promote);\n\t\tfor (ifa = next_sec; ifa; ifa = ifa->ifa_next) {\n\t\t\tif (ifa1->ifa_mask != ifa->ifa_mask ||\n\t\t\t    !inet_ifa_match(ifa1->ifa_address, ifa))\n\t\t\t\t\tcontinue;\n\t\t\tfib_add_ifaddr(ifa);\n\t\t}\n\n\t}\n\tif (destroy)\n\t\tinet_free_ifa(ifa1);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -8,6 +8,9 @@\n \tint do_promote = IN_DEV_PROMOTE_SECONDARIES(in_dev);\n \n \tASSERT_RTNL();\n+\n+\tif (in_dev->dead)\n+\t\tgoto no_promotions;\n \n \t/* 1. Deleting primary ifaddr forces deletion all secondaries\n \t * unless alias promotion is set\n@@ -55,6 +58,7 @@\n \t\t\tfib_del_ifaddr(ifa, ifa1);\n \t}\n \n+no_promotions:\n \t/* 2. Unlink it */\n \n \t*ifap = ifa1->ifa_next;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "\tif (in_dev->dead)",
                "\t\tgoto no_promotions;",
                "no_promotions:"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-3156",
        "func_name": "torvalds/linux/masq_inet_event",
        "description": "The IPv4 implementation in the Linux kernel before 4.5.2 mishandles destruction of device objects, which allows guest OS users to cause a denial of service (host OS networking outage) by arranging for a large number of IP addresses.",
        "git_url": "https://github.com/torvalds/linux/commit/fbd40ea0180a2d328c5adc61414dc8bab9335ce2",
        "commit_title": "ipv4: Don't do expensive useless work during inetdev destroy.",
        "commit_text": " When an inetdev is destroyed, every address assigned to the interface is removed.  And in this scenerio we do two pointless things which can be very expensive if the number of assigned interfaces is large:  1) Address promotion.  We are deleting all addresses, so there is no    point in doing this.  2) A full nf conntrack table purge for every address.  We only need to    do this once, as is already caught by the existing    masq_dev_notifier so masq_inet_event() can skip this. ",
        "func_before": "static int masq_inet_event(struct notifier_block *this,\n\t\t\t   unsigned long event,\n\t\t\t   void *ptr)\n{\n\tstruct net_device *dev = ((struct in_ifaddr *)ptr)->ifa_dev->dev;\n\tstruct netdev_notifier_info info;\n\n\tnetdev_notifier_info_init(&info, dev);\n\treturn masq_device_event(this, event, &info);\n}",
        "func": "static int masq_inet_event(struct notifier_block *this,\n\t\t\t   unsigned long event,\n\t\t\t   void *ptr)\n{\n\tstruct in_device *idev = ((struct in_ifaddr *)ptr)->ifa_dev;\n\tstruct netdev_notifier_info info;\n\n\t/* The masq_dev_notifier will catch the case of the device going\n\t * down.  So if the inetdev is dead and being destroyed we have\n\t * no work to do.  Otherwise this is an individual address removal\n\t * and we have to perform the flush.\n\t */\n\tif (idev->dead)\n\t\treturn NOTIFY_DONE;\n\n\tnetdev_notifier_info_init(&info, idev->dev);\n\treturn masq_device_event(this, event, &info);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,9 +2,17 @@\n \t\t\t   unsigned long event,\n \t\t\t   void *ptr)\n {\n-\tstruct net_device *dev = ((struct in_ifaddr *)ptr)->ifa_dev->dev;\n+\tstruct in_device *idev = ((struct in_ifaddr *)ptr)->ifa_dev;\n \tstruct netdev_notifier_info info;\n \n-\tnetdev_notifier_info_init(&info, dev);\n+\t/* The masq_dev_notifier will catch the case of the device going\n+\t * down.  So if the inetdev is dead and being destroyed we have\n+\t * no work to do.  Otherwise this is an individual address removal\n+\t * and we have to perform the flush.\n+\t */\n+\tif (idev->dead)\n+\t\treturn NOTIFY_DONE;\n+\n+\tnetdev_notifier_info_init(&info, idev->dev);\n \treturn masq_device_event(this, event, &info);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tstruct net_device *dev = ((struct in_ifaddr *)ptr)->ifa_dev->dev;",
                "\tnetdev_notifier_info_init(&info, dev);"
            ],
            "added_lines": [
                "\tstruct in_device *idev = ((struct in_ifaddr *)ptr)->ifa_dev;",
                "\t/* The masq_dev_notifier will catch the case of the device going",
                "\t * down.  So if the inetdev is dead and being destroyed we have",
                "\t * no work to do.  Otherwise this is an individual address removal",
                "\t * and we have to perform the flush.",
                "\t */",
                "\tif (idev->dead)",
                "\t\treturn NOTIFY_DONE;",
                "",
                "\tnetdev_notifier_info_init(&info, idev->dev);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-3156",
        "func_name": "torvalds/linux/fib_del_ifaddr",
        "description": "The IPv4 implementation in the Linux kernel before 4.5.2 mishandles destruction of device objects, which allows guest OS users to cause a denial of service (host OS networking outage) by arranging for a large number of IP addresses.",
        "git_url": "https://github.com/torvalds/linux/commit/fbd40ea0180a2d328c5adc61414dc8bab9335ce2",
        "commit_title": "ipv4: Don't do expensive useless work during inetdev destroy.",
        "commit_text": " When an inetdev is destroyed, every address assigned to the interface is removed.  And in this scenerio we do two pointless things which can be very expensive if the number of assigned interfaces is large:  1) Address promotion.  We are deleting all addresses, so there is no    point in doing this.  2) A full nf conntrack table purge for every address.  We only need to    do this once, as is already caught by the existing    masq_dev_notifier so masq_inet_event() can skip this. ",
        "func_before": "void fib_del_ifaddr(struct in_ifaddr *ifa, struct in_ifaddr *iprim)\n{\n\tstruct in_device *in_dev = ifa->ifa_dev;\n\tstruct net_device *dev = in_dev->dev;\n\tstruct in_ifaddr *ifa1;\n\tstruct in_ifaddr *prim = ifa, *prim1 = NULL;\n\t__be32 brd = ifa->ifa_address | ~ifa->ifa_mask;\n\t__be32 any = ifa->ifa_address & ifa->ifa_mask;\n#define LOCAL_OK\t1\n#define BRD_OK\t\t2\n#define BRD0_OK\t\t4\n#define BRD1_OK\t\t8\n\tunsigned int ok = 0;\n\tint subnet = 0;\t\t/* Primary network */\n\tint gone = 1;\t\t/* Address is missing */\n\tint same_prefsrc = 0;\t/* Another primary with same IP */\n\n\tif (ifa->ifa_flags & IFA_F_SECONDARY) {\n\t\tprim = inet_ifa_byprefix(in_dev, any, ifa->ifa_mask);\n\t\tif (!prim) {\n\t\t\tpr_warn(\"%s: bug: prim == NULL\\n\", __func__);\n\t\t\treturn;\n\t\t}\n\t\tif (iprim && iprim != prim) {\n\t\t\tpr_warn(\"%s: bug: iprim != prim\\n\", __func__);\n\t\t\treturn;\n\t\t}\n\t} else if (!ipv4_is_zeronet(any) &&\n\t\t   (any != ifa->ifa_local || ifa->ifa_prefixlen < 32)) {\n\t\tif (!(ifa->ifa_flags & IFA_F_NOPREFIXROUTE))\n\t\t\tfib_magic(RTM_DELROUTE,\n\t\t\t\t  dev->flags & IFF_LOOPBACK ? RTN_LOCAL : RTN_UNICAST,\n\t\t\t\t  any, ifa->ifa_prefixlen, prim);\n\t\tsubnet = 1;\n\t}\n\n\t/* Deletion is more complicated than add.\n\t * We should take care of not to delete too much :-)\n\t *\n\t * Scan address list to be sure that addresses are really gone.\n\t */\n\n\tfor (ifa1 = in_dev->ifa_list; ifa1; ifa1 = ifa1->ifa_next) {\n\t\tif (ifa1 == ifa) {\n\t\t\t/* promotion, keep the IP */\n\t\t\tgone = 0;\n\t\t\tcontinue;\n\t\t}\n\t\t/* Ignore IFAs from our subnet */\n\t\tif (iprim && ifa1->ifa_mask == iprim->ifa_mask &&\n\t\t    inet_ifa_match(ifa1->ifa_address, iprim))\n\t\t\tcontinue;\n\n\t\t/* Ignore ifa1 if it uses different primary IP (prefsrc) */\n\t\tif (ifa1->ifa_flags & IFA_F_SECONDARY) {\n\t\t\t/* Another address from our subnet? */\n\t\t\tif (ifa1->ifa_mask == prim->ifa_mask &&\n\t\t\t    inet_ifa_match(ifa1->ifa_address, prim))\n\t\t\t\tprim1 = prim;\n\t\t\telse {\n\t\t\t\t/* We reached the secondaries, so\n\t\t\t\t * same_prefsrc should be determined.\n\t\t\t\t */\n\t\t\t\tif (!same_prefsrc)\n\t\t\t\t\tcontinue;\n\t\t\t\t/* Search new prim1 if ifa1 is not\n\t\t\t\t * using the current prim1\n\t\t\t\t */\n\t\t\t\tif (!prim1 ||\n\t\t\t\t    ifa1->ifa_mask != prim1->ifa_mask ||\n\t\t\t\t    !inet_ifa_match(ifa1->ifa_address, prim1))\n\t\t\t\t\tprim1 = inet_ifa_byprefix(in_dev,\n\t\t\t\t\t\t\tifa1->ifa_address,\n\t\t\t\t\t\t\tifa1->ifa_mask);\n\t\t\t\tif (!prim1)\n\t\t\t\t\tcontinue;\n\t\t\t\tif (prim1->ifa_local != prim->ifa_local)\n\t\t\t\t\tcontinue;\n\t\t\t}\n\t\t} else {\n\t\t\tif (prim->ifa_local != ifa1->ifa_local)\n\t\t\t\tcontinue;\n\t\t\tprim1 = ifa1;\n\t\t\tif (prim != prim1)\n\t\t\t\tsame_prefsrc = 1;\n\t\t}\n\t\tif (ifa->ifa_local == ifa1->ifa_local)\n\t\t\tok |= LOCAL_OK;\n\t\tif (ifa->ifa_broadcast == ifa1->ifa_broadcast)\n\t\t\tok |= BRD_OK;\n\t\tif (brd == ifa1->ifa_broadcast)\n\t\t\tok |= BRD1_OK;\n\t\tif (any == ifa1->ifa_broadcast)\n\t\t\tok |= BRD0_OK;\n\t\t/* primary has network specific broadcasts */\n\t\tif (prim1 == ifa1 && ifa1->ifa_prefixlen < 31) {\n\t\t\t__be32 brd1 = ifa1->ifa_address | ~ifa1->ifa_mask;\n\t\t\t__be32 any1 = ifa1->ifa_address & ifa1->ifa_mask;\n\n\t\t\tif (!ipv4_is_zeronet(any1)) {\n\t\t\t\tif (ifa->ifa_broadcast == brd1 ||\n\t\t\t\t    ifa->ifa_broadcast == any1)\n\t\t\t\t\tok |= BRD_OK;\n\t\t\t\tif (brd == brd1 || brd == any1)\n\t\t\t\t\tok |= BRD1_OK;\n\t\t\t\tif (any == brd1 || any == any1)\n\t\t\t\t\tok |= BRD0_OK;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (!(ok & BRD_OK))\n\t\tfib_magic(RTM_DELROUTE, RTN_BROADCAST, ifa->ifa_broadcast, 32, prim);\n\tif (subnet && ifa->ifa_prefixlen < 31) {\n\t\tif (!(ok & BRD1_OK))\n\t\t\tfib_magic(RTM_DELROUTE, RTN_BROADCAST, brd, 32, prim);\n\t\tif (!(ok & BRD0_OK))\n\t\t\tfib_magic(RTM_DELROUTE, RTN_BROADCAST, any, 32, prim);\n\t}\n\tif (!(ok & LOCAL_OK)) {\n\t\tunsigned int addr_type;\n\n\t\tfib_magic(RTM_DELROUTE, RTN_LOCAL, ifa->ifa_local, 32, prim);\n\n\t\t/* Check, that this local address finally disappeared. */\n\t\taddr_type = inet_addr_type_dev_table(dev_net(dev), dev,\n\t\t\t\t\t\t     ifa->ifa_local);\n\t\tif (gone && addr_type != RTN_LOCAL) {\n\t\t\t/* And the last, but not the least thing.\n\t\t\t * We must flush stray FIB entries.\n\t\t\t *\n\t\t\t * First of all, we scan fib_info list searching\n\t\t\t * for stray nexthop entries, then ignite fib_flush.\n\t\t\t */\n\t\t\tif (fib_sync_down_addr(dev_net(dev), ifa->ifa_local))\n\t\t\t\tfib_flush(dev_net(dev));\n\t\t}\n\t}\n#undef LOCAL_OK\n#undef BRD_OK\n#undef BRD0_OK\n#undef BRD1_OK\n}",
        "func": "void fib_del_ifaddr(struct in_ifaddr *ifa, struct in_ifaddr *iprim)\n{\n\tstruct in_device *in_dev = ifa->ifa_dev;\n\tstruct net_device *dev = in_dev->dev;\n\tstruct in_ifaddr *ifa1;\n\tstruct in_ifaddr *prim = ifa, *prim1 = NULL;\n\t__be32 brd = ifa->ifa_address | ~ifa->ifa_mask;\n\t__be32 any = ifa->ifa_address & ifa->ifa_mask;\n#define LOCAL_OK\t1\n#define BRD_OK\t\t2\n#define BRD0_OK\t\t4\n#define BRD1_OK\t\t8\n\tunsigned int ok = 0;\n\tint subnet = 0;\t\t/* Primary network */\n\tint gone = 1;\t\t/* Address is missing */\n\tint same_prefsrc = 0;\t/* Another primary with same IP */\n\n\tif (ifa->ifa_flags & IFA_F_SECONDARY) {\n\t\tprim = inet_ifa_byprefix(in_dev, any, ifa->ifa_mask);\n\t\tif (!prim) {\n\t\t\tpr_warn(\"%s: bug: prim == NULL\\n\", __func__);\n\t\t\treturn;\n\t\t}\n\t\tif (iprim && iprim != prim) {\n\t\t\tpr_warn(\"%s: bug: iprim != prim\\n\", __func__);\n\t\t\treturn;\n\t\t}\n\t} else if (!ipv4_is_zeronet(any) &&\n\t\t   (any != ifa->ifa_local || ifa->ifa_prefixlen < 32)) {\n\t\tif (!(ifa->ifa_flags & IFA_F_NOPREFIXROUTE))\n\t\t\tfib_magic(RTM_DELROUTE,\n\t\t\t\t  dev->flags & IFF_LOOPBACK ? RTN_LOCAL : RTN_UNICAST,\n\t\t\t\t  any, ifa->ifa_prefixlen, prim);\n\t\tsubnet = 1;\n\t}\n\n\tif (in_dev->dead)\n\t\tgoto no_promotions;\n\n\t/* Deletion is more complicated than add.\n\t * We should take care of not to delete too much :-)\n\t *\n\t * Scan address list to be sure that addresses are really gone.\n\t */\n\n\tfor (ifa1 = in_dev->ifa_list; ifa1; ifa1 = ifa1->ifa_next) {\n\t\tif (ifa1 == ifa) {\n\t\t\t/* promotion, keep the IP */\n\t\t\tgone = 0;\n\t\t\tcontinue;\n\t\t}\n\t\t/* Ignore IFAs from our subnet */\n\t\tif (iprim && ifa1->ifa_mask == iprim->ifa_mask &&\n\t\t    inet_ifa_match(ifa1->ifa_address, iprim))\n\t\t\tcontinue;\n\n\t\t/* Ignore ifa1 if it uses different primary IP (prefsrc) */\n\t\tif (ifa1->ifa_flags & IFA_F_SECONDARY) {\n\t\t\t/* Another address from our subnet? */\n\t\t\tif (ifa1->ifa_mask == prim->ifa_mask &&\n\t\t\t    inet_ifa_match(ifa1->ifa_address, prim))\n\t\t\t\tprim1 = prim;\n\t\t\telse {\n\t\t\t\t/* We reached the secondaries, so\n\t\t\t\t * same_prefsrc should be determined.\n\t\t\t\t */\n\t\t\t\tif (!same_prefsrc)\n\t\t\t\t\tcontinue;\n\t\t\t\t/* Search new prim1 if ifa1 is not\n\t\t\t\t * using the current prim1\n\t\t\t\t */\n\t\t\t\tif (!prim1 ||\n\t\t\t\t    ifa1->ifa_mask != prim1->ifa_mask ||\n\t\t\t\t    !inet_ifa_match(ifa1->ifa_address, prim1))\n\t\t\t\t\tprim1 = inet_ifa_byprefix(in_dev,\n\t\t\t\t\t\t\tifa1->ifa_address,\n\t\t\t\t\t\t\tifa1->ifa_mask);\n\t\t\t\tif (!prim1)\n\t\t\t\t\tcontinue;\n\t\t\t\tif (prim1->ifa_local != prim->ifa_local)\n\t\t\t\t\tcontinue;\n\t\t\t}\n\t\t} else {\n\t\t\tif (prim->ifa_local != ifa1->ifa_local)\n\t\t\t\tcontinue;\n\t\t\tprim1 = ifa1;\n\t\t\tif (prim != prim1)\n\t\t\t\tsame_prefsrc = 1;\n\t\t}\n\t\tif (ifa->ifa_local == ifa1->ifa_local)\n\t\t\tok |= LOCAL_OK;\n\t\tif (ifa->ifa_broadcast == ifa1->ifa_broadcast)\n\t\t\tok |= BRD_OK;\n\t\tif (brd == ifa1->ifa_broadcast)\n\t\t\tok |= BRD1_OK;\n\t\tif (any == ifa1->ifa_broadcast)\n\t\t\tok |= BRD0_OK;\n\t\t/* primary has network specific broadcasts */\n\t\tif (prim1 == ifa1 && ifa1->ifa_prefixlen < 31) {\n\t\t\t__be32 brd1 = ifa1->ifa_address | ~ifa1->ifa_mask;\n\t\t\t__be32 any1 = ifa1->ifa_address & ifa1->ifa_mask;\n\n\t\t\tif (!ipv4_is_zeronet(any1)) {\n\t\t\t\tif (ifa->ifa_broadcast == brd1 ||\n\t\t\t\t    ifa->ifa_broadcast == any1)\n\t\t\t\t\tok |= BRD_OK;\n\t\t\t\tif (brd == brd1 || brd == any1)\n\t\t\t\t\tok |= BRD1_OK;\n\t\t\t\tif (any == brd1 || any == any1)\n\t\t\t\t\tok |= BRD0_OK;\n\t\t\t}\n\t\t}\n\t}\n\nno_promotions:\n\tif (!(ok & BRD_OK))\n\t\tfib_magic(RTM_DELROUTE, RTN_BROADCAST, ifa->ifa_broadcast, 32, prim);\n\tif (subnet && ifa->ifa_prefixlen < 31) {\n\t\tif (!(ok & BRD1_OK))\n\t\t\tfib_magic(RTM_DELROUTE, RTN_BROADCAST, brd, 32, prim);\n\t\tif (!(ok & BRD0_OK))\n\t\t\tfib_magic(RTM_DELROUTE, RTN_BROADCAST, any, 32, prim);\n\t}\n\tif (!(ok & LOCAL_OK)) {\n\t\tunsigned int addr_type;\n\n\t\tfib_magic(RTM_DELROUTE, RTN_LOCAL, ifa->ifa_local, 32, prim);\n\n\t\t/* Check, that this local address finally disappeared. */\n\t\taddr_type = inet_addr_type_dev_table(dev_net(dev), dev,\n\t\t\t\t\t\t     ifa->ifa_local);\n\t\tif (gone && addr_type != RTN_LOCAL) {\n\t\t\t/* And the last, but not the least thing.\n\t\t\t * We must flush stray FIB entries.\n\t\t\t *\n\t\t\t * First of all, we scan fib_info list searching\n\t\t\t * for stray nexthop entries, then ignite fib_flush.\n\t\t\t */\n\t\t\tif (fib_sync_down_addr(dev_net(dev), ifa->ifa_local))\n\t\t\t\tfib_flush(dev_net(dev));\n\t\t}\n\t}\n#undef LOCAL_OK\n#undef BRD_OK\n#undef BRD0_OK\n#undef BRD1_OK\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -33,6 +33,9 @@\n \t\t\t\t  any, ifa->ifa_prefixlen, prim);\n \t\tsubnet = 1;\n \t}\n+\n+\tif (in_dev->dead)\n+\t\tgoto no_promotions;\n \n \t/* Deletion is more complicated than add.\n \t * We should take care of not to delete too much :-)\n@@ -109,6 +112,7 @@\n \t\t}\n \t}\n \n+no_promotions:\n \tif (!(ok & BRD_OK))\n \t\tfib_magic(RTM_DELROUTE, RTN_BROADCAST, ifa->ifa_broadcast, 32, prim);\n \tif (subnet && ifa->ifa_prefixlen < 31) {",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "\tif (in_dev->dead)",
                "\t\tgoto no_promotions;",
                "no_promotions:"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-2109",
        "func_name": "openssl/asn1_d2i_read_bio",
        "description": "The asn1_d2i_read_bio function in crypto/asn1/a_d2i_fp.c in the ASN.1 BIO implementation in OpenSSL before 1.0.1t and 1.0.2 before 1.0.2h allows remote attackers to cause a denial of service (memory consumption) via a short invalid encoding.",
        "git_url": "https://git.openssl.org/?p=openssl.git;a=commit;h=c62981390d6cf9e3d612c489b8b77c2913b25807",
        "commit_title": "",
        "commit_text": "Harden ASN.1 BIO handling of large amounts of data.  If the ASN.1 BIO is presented with a large length field read it in chunks of increasing size checking for EOF on each read. This prevents small files allocating excessive amounts of data.  CVE-2016-2109  Thanks to Brian Carpenter for reporting this issue.  ",
        "func_before": "static int asn1_d2i_read_bio(BIO *in, BUF_MEM **pb)\n{\n    BUF_MEM *b;\n    unsigned char *p;\n    int i;\n    size_t want = HEADER_SIZE;\n    int eos = 0;\n    size_t off = 0;\n    size_t len = 0;\n\n    const unsigned char *q;\n    long slen;\n    int inf, tag, xclass;\n\n    b = BUF_MEM_new();\n    if (b == NULL) {\n        ASN1err(ASN1_F_ASN1_D2I_READ_BIO, ERR_R_MALLOC_FAILURE);\n        return -1;\n    }\n\n    ERR_clear_error();\n    for (;;) {\n        if (want >= (len - off)) {\n            want -= (len - off);\n\n            if (len + want < len || !BUF_MEM_grow_clean(b, len + want)) {\n                ASN1err(ASN1_F_ASN1_D2I_READ_BIO, ERR_R_MALLOC_FAILURE);\n                goto err;\n            }\n            i = BIO_read(in, &(b->data[len]), want);\n            if ((i < 0) && ((len - off) == 0)) {\n                ASN1err(ASN1_F_ASN1_D2I_READ_BIO, ASN1_R_NOT_ENOUGH_DATA);\n                goto err;\n            }\n            if (i > 0) {\n                if (len + i < len) {\n                    ASN1err(ASN1_F_ASN1_D2I_READ_BIO, ASN1_R_TOO_LONG);\n                    goto err;\n                }\n                len += i;\n            }\n        }\n        /* else data already loaded */\n\n        p = (unsigned char *)&(b->data[off]);\n        q = p;\n        inf = ASN1_get_object(&q, &slen, &tag, &xclass, len - off);\n        if (inf & 0x80) {\n            unsigned long e;\n\n            e = ERR_GET_REASON(ERR_peek_error());\n            if (e != ASN1_R_TOO_LONG)\n                goto err;\n            else\n                ERR_clear_error(); /* clear error */\n        }\n        i = q - p;            /* header length */\n        off += i;               /* end of data */\n\n        if (inf & 1) {\n            /* no data body so go round again */\n            eos++;\n            if (eos < 0) {\n                ASN1err(ASN1_F_ASN1_D2I_READ_BIO, ASN1_R_HEADER_TOO_LONG);\n                goto err;\n            }\n            want = HEADER_SIZE;\n        } else if (eos && (slen == 0) && (tag == V_ASN1_EOC)) {\n            /* eos value, so go back and read another header */\n            eos--;\n            if (eos <= 0)\n                break;\n            else\n                want = HEADER_SIZE;\n        } else {\n            /* suck in slen bytes of data */\n            want = slen;\n            if (want > (len - off)) {\n                want -= (len - off);\n                if (want > INT_MAX /* BIO_read takes an int length */  ||\n                    len + want < len) {\n                    ASN1err(ASN1_F_ASN1_D2I_READ_BIO, ASN1_R_TOO_LONG);\n                    goto err;\n                }\n                if (!BUF_MEM_grow_clean(b, len + want)) {\n                    ASN1err(ASN1_F_ASN1_D2I_READ_BIO, ERR_R_MALLOC_FAILURE);\n                    goto err;\n                }\n                while (want > 0) {\n                    i = BIO_read(in, &(b->data[len]), want);\n                    if (i <= 0) {\n                        ASN1err(ASN1_F_ASN1_D2I_READ_BIO,\n                                ASN1_R_NOT_ENOUGH_DATA);\n                        goto err;\n                    }\n                    /*\n                     * This can't overflow because |len+want| didn't\n                     * overflow.\n                     */\n                    len += i;\n                    want -= i;\n                }\n            }\n            if (off + slen < off) {\n                ASN1err(ASN1_F_ASN1_D2I_READ_BIO, ASN1_R_TOO_LONG);\n                goto err;\n            }\n            off += slen;\n            if (eos <= 0) {\n                break;\n            } else\n                want = HEADER_SIZE;\n        }\n    }\n\n    if (off > INT_MAX) {\n        ASN1err(ASN1_F_ASN1_D2I_READ_BIO, ASN1_R_TOO_LONG);\n        goto err;\n    }\n\n    *pb = b;\n    return off;\n err:\n    BUF_MEM_free(b);\n    return -1;\n}",
        "func": "static int asn1_d2i_read_bio(BIO *in, BUF_MEM **pb)\n{\n    BUF_MEM *b;\n    unsigned char *p;\n    int i;\n    size_t want = HEADER_SIZE;\n    int eos = 0;\n    size_t off = 0;\n    size_t len = 0;\n\n    const unsigned char *q;\n    long slen;\n    int inf, tag, xclass;\n\n    b = BUF_MEM_new();\n    if (b == NULL) {\n        ASN1err(ASN1_F_ASN1_D2I_READ_BIO, ERR_R_MALLOC_FAILURE);\n        return -1;\n    }\n\n    ERR_clear_error();\n    for (;;) {\n        if (want >= (len - off)) {\n            want -= (len - off);\n\n            if (len + want < len || !BUF_MEM_grow_clean(b, len + want)) {\n                ASN1err(ASN1_F_ASN1_D2I_READ_BIO, ERR_R_MALLOC_FAILURE);\n                goto err;\n            }\n            i = BIO_read(in, &(b->data[len]), want);\n            if ((i < 0) && ((len - off) == 0)) {\n                ASN1err(ASN1_F_ASN1_D2I_READ_BIO, ASN1_R_NOT_ENOUGH_DATA);\n                goto err;\n            }\n            if (i > 0) {\n                if (len + i < len) {\n                    ASN1err(ASN1_F_ASN1_D2I_READ_BIO, ASN1_R_TOO_LONG);\n                    goto err;\n                }\n                len += i;\n            }\n        }\n        /* else data already loaded */\n\n        p = (unsigned char *)&(b->data[off]);\n        q = p;\n        inf = ASN1_get_object(&q, &slen, &tag, &xclass, len - off);\n        if (inf & 0x80) {\n            unsigned long e;\n\n            e = ERR_GET_REASON(ERR_peek_error());\n            if (e != ASN1_R_TOO_LONG)\n                goto err;\n            else\n                ERR_clear_error(); /* clear error */\n        }\n        i = q - p;            /* header length */\n        off += i;               /* end of data */\n\n        if (inf & 1) {\n            /* no data body so go round again */\n            eos++;\n            if (eos < 0) {\n                ASN1err(ASN1_F_ASN1_D2I_READ_BIO, ASN1_R_HEADER_TOO_LONG);\n                goto err;\n            }\n            want = HEADER_SIZE;\n        } else if (eos && (slen == 0) && (tag == V_ASN1_EOC)) {\n            /* eos value, so go back and read another header */\n            eos--;\n            if (eos <= 0)\n                break;\n            else\n                want = HEADER_SIZE;\n        } else {\n            /* suck in slen bytes of data */\n            want = slen;\n            if (want > (len - off)) {\n                size_t chunk_max = ASN1_CHUNK_INITIAL_SIZE;\n\n                want -= (len - off);\n                if (want > INT_MAX /* BIO_read takes an int length */  ||\n                    len + want < len) {\n                    ASN1err(ASN1_F_ASN1_D2I_READ_BIO, ASN1_R_TOO_LONG);\n                    goto err;\n                }\n                while (want > 0) {\n                    /*\n                     * Read content in chunks of increasing size\n                     * so we can return an error for EOF without\n                     * having to allocate the entire content length\n                     * in one go.\n                     */\n                    size_t chunk = want > chunk_max ? chunk_max : want;\n\n                    if (!BUF_MEM_grow_clean(b, len + chunk)) {\n                        ASN1err(ASN1_F_ASN1_D2I_READ_BIO, ERR_R_MALLOC_FAILURE);\n                        goto err;\n                    }\n                    want -= chunk;\n                    while (chunk > 0) {\n                        i = BIO_read(in, &(b->data[len]), chunk);\n                        if (i <= 0) {\n                            ASN1err(ASN1_F_ASN1_D2I_READ_BIO,\n                                    ASN1_R_NOT_ENOUGH_DATA);\n                            goto err;\n                        }\n                    /*\n                     * This can't overflow because |len+want| didn't\n                     * overflow.\n                     */\n                        len += i;\n                        chunk -= i;\n                    }\n                    if (chunk_max < INT_MAX/2)\n                        chunk_max *= 2;\n                }\n            }\n            if (off + slen < off) {\n                ASN1err(ASN1_F_ASN1_D2I_READ_BIO, ASN1_R_TOO_LONG);\n                goto err;\n            }\n            off += slen;\n            if (eos <= 0) {\n                break;\n            } else\n                want = HEADER_SIZE;\n        }\n    }\n\n    if (off > INT_MAX) {\n        ASN1err(ASN1_F_ASN1_D2I_READ_BIO, ASN1_R_TOO_LONG);\n        goto err;\n    }\n\n    *pb = b;\n    return off;\n err:\n    BUF_MEM_free(b);\n    return -1;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -76,29 +76,44 @@\n             /* suck in slen bytes of data */\n             want = slen;\n             if (want > (len - off)) {\n+                size_t chunk_max = ASN1_CHUNK_INITIAL_SIZE;\n+\n                 want -= (len - off);\n                 if (want > INT_MAX /* BIO_read takes an int length */  ||\n                     len + want < len) {\n                     ASN1err(ASN1_F_ASN1_D2I_READ_BIO, ASN1_R_TOO_LONG);\n                     goto err;\n                 }\n-                if (!BUF_MEM_grow_clean(b, len + want)) {\n-                    ASN1err(ASN1_F_ASN1_D2I_READ_BIO, ERR_R_MALLOC_FAILURE);\n-                    goto err;\n-                }\n                 while (want > 0) {\n-                    i = BIO_read(in, &(b->data[len]), want);\n-                    if (i <= 0) {\n-                        ASN1err(ASN1_F_ASN1_D2I_READ_BIO,\n-                                ASN1_R_NOT_ENOUGH_DATA);\n+                    /*\n+                     * Read content in chunks of increasing size\n+                     * so we can return an error for EOF without\n+                     * having to allocate the entire content length\n+                     * in one go.\n+                     */\n+                    size_t chunk = want > chunk_max ? chunk_max : want;\n+\n+                    if (!BUF_MEM_grow_clean(b, len + chunk)) {\n+                        ASN1err(ASN1_F_ASN1_D2I_READ_BIO, ERR_R_MALLOC_FAILURE);\n                         goto err;\n                     }\n+                    want -= chunk;\n+                    while (chunk > 0) {\n+                        i = BIO_read(in, &(b->data[len]), chunk);\n+                        if (i <= 0) {\n+                            ASN1err(ASN1_F_ASN1_D2I_READ_BIO,\n+                                    ASN1_R_NOT_ENOUGH_DATA);\n+                            goto err;\n+                        }\n                     /*\n                      * This can't overflow because |len+want| didn't\n                      * overflow.\n                      */\n-                    len += i;\n-                    want -= i;\n+                        len += i;\n+                        chunk -= i;\n+                    }\n+                    if (chunk_max < INT_MAX/2)\n+                        chunk_max *= 2;\n                 }\n             }\n             if (off + slen < off) {",
        "diff_line_info": {
            "deleted_lines": [
                "                if (!BUF_MEM_grow_clean(b, len + want)) {",
                "                    ASN1err(ASN1_F_ASN1_D2I_READ_BIO, ERR_R_MALLOC_FAILURE);",
                "                    goto err;",
                "                }",
                "                    i = BIO_read(in, &(b->data[len]), want);",
                "                    if (i <= 0) {",
                "                        ASN1err(ASN1_F_ASN1_D2I_READ_BIO,",
                "                                ASN1_R_NOT_ENOUGH_DATA);",
                "                    len += i;",
                "                    want -= i;"
            ],
            "added_lines": [
                "                size_t chunk_max = ASN1_CHUNK_INITIAL_SIZE;",
                "",
                "                    /*",
                "                     * Read content in chunks of increasing size",
                "                     * so we can return an error for EOF without",
                "                     * having to allocate the entire content length",
                "                     * in one go.",
                "                     */",
                "                    size_t chunk = want > chunk_max ? chunk_max : want;",
                "",
                "                    if (!BUF_MEM_grow_clean(b, len + chunk)) {",
                "                        ASN1err(ASN1_F_ASN1_D2I_READ_BIO, ERR_R_MALLOC_FAILURE);",
                "                    want -= chunk;",
                "                    while (chunk > 0) {",
                "                        i = BIO_read(in, &(b->data[len]), chunk);",
                "                        if (i <= 0) {",
                "                            ASN1err(ASN1_F_ASN1_D2I_READ_BIO,",
                "                                    ASN1_R_NOT_ENOUGH_DATA);",
                "                            goto err;",
                "                        }",
                "                        len += i;",
                "                        chunk -= i;",
                "                    }",
                "                    if (chunk_max < INT_MAX/2)",
                "                        chunk_max *= 2;"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-4008",
        "func_name": "libtasn1/_asn1_extract_der_octet",
        "description": "The _asn1_extract_der_octet function in lib/decoding.c in GNU Libtasn1 before 4.8, when used without the ASN1_DECODE_FLAG_STRICT_DER flag, allows remote attackers to cause a denial of service (infinite recursion) via a crafted certificate.",
        "git_url": "http://git.savannah.gnu.org/gitweb/?p=libtasn1.git;a=commit;h=f435825c0f527a8e52e6ffbc3ad0bc60531d537e",
        "commit_title": "",
        "commit_text": "_asn1_extract_der_octet: catch invalid input cases early  That is, check the calculated lengths for validity prior to entering a loop. This avoids an infinite recursion. Reported by Pascal Cuoq. ",
        "func_before": "static int\n_asn1_extract_der_octet (asn1_node node, const unsigned char *der,\n\t\t\t int der_len, unsigned flags)\n{\n  int len2, len3;\n  int counter, counter_end;\n  int result;\n\n  len2 = asn1_get_length_der (der, der_len, &len3);\n  if (len2 < -1)\n    return ASN1_DER_ERROR;\n\n  counter = len3 + 1;\n  DECR_LEN(der_len, len3);\n\n  if (len2 == -1)\n    counter_end = der_len - 2;\n  else\n    counter_end = der_len;\n\n  while (counter < counter_end)\n    {\n      DECR_LEN(der_len, 1);\n      len2 = asn1_get_length_der (der + counter, der_len, &len3);\n\n      if (IS_ERR(len2, flags))\n\t{\n\t  warn();\n\t  return ASN1_DER_ERROR;\n\t}\n\n      if (len2 >= 0)\n\t{\n\t  DECR_LEN(der_len, len2+len3);\n\t  _asn1_append_value (node, der + counter + len3, len2);\n\t}\n      else\n\t{\t\t\t/* indefinite */\n\t  DECR_LEN(der_len, len3);\n\t  result =\n\t    _asn1_extract_der_octet (node, der + counter + len3,\n\t\t\t\t     der_len, flags);\n\t  if (result != ASN1_SUCCESS)\n\t    return result;\n\t  len2 = 0;\n\t}\n\n      counter += len2 + len3 + 1;\n    }\n\n  return ASN1_SUCCESS;\n\ncleanup:\n  return result;\n}",
        "func": "static int\n_asn1_extract_der_octet (asn1_node node, const unsigned char *der,\n\t\t\t int der_len, unsigned flags)\n{\n  int len2, len3;\n  int counter, counter_end;\n  int result;\n\n  len2 = asn1_get_length_der (der, der_len, &len3);\n  if (len2 < -1)\n    return ASN1_DER_ERROR;\n\n  counter = len3 + 1;\n  DECR_LEN(der_len, len3);\n\n  if (len2 == -1)\n    {\n      if (der_len < 2)\n        return ASN1_DER_ERROR;\n      counter_end = der_len - 2;\n    }\n  else\n    counter_end = der_len;\n\n  if (counter_end < counter)\n    return ASN1_DER_ERROR;\n\n  while (counter < counter_end)\n    {\n      DECR_LEN(der_len, 1);\n      len2 = asn1_get_length_der (der + counter, der_len, &len3);\n\n      if (IS_ERR(len2, flags))\n\t{\n\t  warn();\n\t  return ASN1_DER_ERROR;\n\t}\n\n      if (len2 >= 0)\n\t{\n\t  DECR_LEN(der_len, len2+len3);\n\t  _asn1_append_value (node, der + counter + len3, len2);\n\t}\n      else\n\t{\t\t\t/* indefinite */\n\t  DECR_LEN(der_len, len3);\n\t  result =\n\t    _asn1_extract_der_octet (node, der + counter + len3,\n\t\t\t\t     der_len, flags);\n\t  if (result != ASN1_SUCCESS)\n\t    return result;\n\t  len2 = 0;\n\t}\n\n      counter += len2 + len3 + 1;\n    }\n\n  return ASN1_SUCCESS;\n\ncleanup:\n  return result;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -14,9 +14,16 @@\n   DECR_LEN(der_len, len3);\n \n   if (len2 == -1)\n-    counter_end = der_len - 2;\n+    {\n+      if (der_len < 2)\n+        return ASN1_DER_ERROR;\n+      counter_end = der_len - 2;\n+    }\n   else\n     counter_end = der_len;\n+\n+  if (counter_end < counter)\n+    return ASN1_DER_ERROR;\n \n   while (counter < counter_end)\n     {",
        "diff_line_info": {
            "deleted_lines": [
                "    counter_end = der_len - 2;"
            ],
            "added_lines": [
                "    {",
                "      if (der_len < 2)",
                "        return ASN1_DER_ERROR;",
                "      counter_end = der_len - 2;",
                "    }",
                "",
                "  if (counter_end < counter)",
                "    return ASN1_DER_ERROR;"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-4008",
        "func_name": "libtasn1/get_octet_string",
        "description": "The _asn1_extract_der_octet function in lib/decoding.c in GNU Libtasn1 before 4.8, when used without the ASN1_DECODE_FLAG_STRICT_DER flag, allows remote attackers to cause a denial of service (infinite recursion) via a crafted certificate.",
        "git_url": "http://git.savannah.gnu.org/gitweb/?p=libtasn1.git;a=commit;h=a6e0a0b58f5cdaf4e9beca5bce69c09808cbb625",
        "commit_title": "",
        "commit_text": "_asn1_extract_der_octet: properly account the bytes read through indefinite encodings  This prevents infinite recursions in the function loop. Reported by Pascal Cuoq. ",
        "func_before": "static int\nget_octet_string (asn1_node node, const unsigned char *der, int der_len,\n                        const unsigned char *tag, unsigned tag_len,\n                        int *len, unsigned flags)\n{\n  int len2, len3, counter, tot_len, indefinite;\n  int result;\n  int orig_der_len = der_len;\n\n  counter = 0;\n\n  if (tag[0] & ASN1_CLASS_STRUCTURED)\n    {\n      tot_len = 0;\n\n      indefinite = asn1_get_length_der (der, der_len, &len3);\n      if (IS_ERR(indefinite, flags))\n\t{\n\t  warn();\n\t  return ASN1_DER_ERROR;\n\t}\n\n      counter += len3;\n      DECR_LEN(der_len, len3);\n\n      if (indefinite >= 0)\n\tindefinite += len3;\n\n      while (1)\n\t{\n\t  if (indefinite == -1)\n\t    {\n\t      if (HAVE_TWO(der_len) && (der[counter] == 0) && (der[counter + 1] == 0))\n\t\t{\n\t\t  counter += 2;\n\t\t  DECR_LEN(der_len, 2);\n\t\t  break;\n\t\t}\n\t    }\n\t  else if (counter >= indefinite)\n\t    break;\n\n          DECR_LEN(der_len, 1);\n\t  if (der[counter] != ASN1_TAG_OCTET_STRING)\n\t    {\n\t      warn();\n\t      return ASN1_DER_ERROR;\n\t    }\n\n\t  counter++;\n\n\t  len2 = asn1_get_length_der (der + counter, der_len, &len3);\n\t  if (len2 <= 0)\n\t    {\n\t      warn();\n\t      return ASN1_DER_ERROR;\n\t    }\n\n          DECR_LEN(der_len, len3 + len2);\n\t  counter += len3 + len2;\n\n\t  tot_len += len2;\n\t}\n\n      /* copy */\n      if (node)\n\t{\n\t  unsigned char temp[ASN1_MAX_LENGTH_SIZE];\n\t  int ret;\n\n\t  len2 = sizeof (temp);\n\n\t  asn1_length_der (tot_len, temp, &len2);\n\t  _asn1_set_value (node, temp, len2);\n\n\t  ret = _asn1_extract_der_octet (node, der, orig_der_len, flags);\n\t  if (ret != ASN1_SUCCESS)\n\t    {\n\t      warn();\n\t      return ret;\n\t    }\n\n\t}\n    }\n  else\n    {\t\t\t\t/* NOT STRUCTURED */\n      len2 = asn1_get_length_der (der, der_len, &len3);\n      if (len2 < 0)\n        {\n          warn();\n\t  return ASN1_DER_ERROR;\n\t}\n\n      DECR_LEN(der_len, len3+len2);\n      counter = len3 + len2;\n      if (node)\n\t_asn1_set_value (node, der, counter);\n    }\n\n  *len = counter;\n  return ASN1_SUCCESS;\n\ncleanup:\n  return result;\n}",
        "func": "static int\nget_octet_string (asn1_node node, const unsigned char *der, int der_len,\n                        const unsigned char *tag, unsigned tag_len,\n                        int *len, unsigned flags)\n{\n  int len2, len3, counter, tot_len, indefinite;\n  int result;\n  int orig_der_len = der_len;\n\n  counter = 0;\n\n  if (tag[0] & ASN1_CLASS_STRUCTURED)\n    {\n      tot_len = 0;\n\n      indefinite = asn1_get_length_der (der, der_len, &len3);\n      if (IS_ERR(indefinite, flags))\n\t{\n\t  warn();\n\t  return ASN1_DER_ERROR;\n\t}\n\n      counter += len3;\n      DECR_LEN(der_len, len3);\n\n      if (indefinite >= 0)\n\tindefinite += len3;\n\n      while (1)\n\t{\n\t  if (indefinite == -1)\n\t    {\n\t      if (HAVE_TWO(der_len) && (der[counter] == 0) && (der[counter + 1] == 0))\n\t\t{\n\t\t  counter += 2;\n\t\t  DECR_LEN(der_len, 2);\n\t\t  break;\n\t\t}\n\t    }\n\t  else if (counter >= indefinite)\n\t    break;\n\n          DECR_LEN(der_len, 1);\n\t  if (der[counter] != ASN1_TAG_OCTET_STRING)\n\t    {\n\t      warn();\n\t      return ASN1_DER_ERROR;\n\t    }\n\n\t  counter++;\n\n\t  len2 = asn1_get_length_der (der + counter, der_len, &len3);\n\t  if (len2 <= 0)\n\t    {\n\t      warn();\n\t      return ASN1_DER_ERROR;\n\t    }\n\n          DECR_LEN(der_len, len3 + len2);\n\t  counter += len3 + len2;\n\n\t  tot_len += len2;\n\t}\n\n      /* copy */\n      if (node)\n\t{\n\t  unsigned char temp[ASN1_MAX_LENGTH_SIZE];\n\t  int ret;\n\n\t  len2 = sizeof (temp);\n\n\t  asn1_length_der (tot_len, temp, &len2);\n\t  _asn1_set_value (node, temp, len2);\n\n\t  ret = _asn1_extract_der_octet (node, der, orig_der_len, flags, NULL);\n\t  if (ret != ASN1_SUCCESS)\n\t    {\n\t      warn();\n\t      return ret;\n\t    }\n\n\t}\n    }\n  else\n    {\t\t\t\t/* NOT STRUCTURED */\n      len2 = asn1_get_length_der (der, der_len, &len3);\n      if (len2 < 0)\n        {\n          warn();\n\t  return ASN1_DER_ERROR;\n\t}\n\n      DECR_LEN(der_len, len3+len2);\n      counter = len3 + len2;\n      if (node)\n\t_asn1_set_value (node, der, counter);\n    }\n\n  *len = counter;\n  return ASN1_SUCCESS;\n\ncleanup:\n  return result;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -73,7 +73,7 @@\n \t  asn1_length_der (tot_len, temp, &len2);\n \t  _asn1_set_value (node, temp, len2);\n \n-\t  ret = _asn1_extract_der_octet (node, der, orig_der_len, flags);\n+\t  ret = _asn1_extract_der_octet (node, der, orig_der_len, flags, NULL);\n \t  if (ret != ASN1_SUCCESS)\n \t    {\n \t      warn();",
        "diff_line_info": {
            "deleted_lines": [
                "\t  ret = _asn1_extract_der_octet (node, der, orig_der_len, flags);"
            ],
            "added_lines": [
                "\t  ret = _asn1_extract_der_octet (node, der, orig_der_len, flags, NULL);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-4008",
        "func_name": "libtasn1/_asn1_extract_der_octet",
        "description": "The _asn1_extract_der_octet function in lib/decoding.c in GNU Libtasn1 before 4.8, when used without the ASN1_DECODE_FLAG_STRICT_DER flag, allows remote attackers to cause a denial of service (infinite recursion) via a crafted certificate.",
        "git_url": "http://git.savannah.gnu.org/gitweb/?p=libtasn1.git;a=commit;h=a6e0a0b58f5cdaf4e9beca5bce69c09808cbb625",
        "commit_title": "",
        "commit_text": "_asn1_extract_der_octet: properly account the bytes read through indefinite encodings  This prevents infinite recursions in the function loop. Reported by Pascal Cuoq. ",
        "func_before": "static int\n_asn1_extract_der_octet (asn1_node node, const unsigned char *der,\n\t\t\t int der_len, unsigned flags)\n{\n  int len2, len3;\n  int counter, counter_end;\n  int result;\n\n  len2 = asn1_get_length_der (der, der_len, &len3);\n  if (len2 < -1)\n    return ASN1_DER_ERROR;\n\n  counter = len3 + 1;\n  DECR_LEN(der_len, len3);\n\n  if (len2 == -1)\n    {\n      if (der_len < 2)\n        return ASN1_DER_ERROR;\n      counter_end = der_len - 2;\n    }\n  else\n    counter_end = der_len;\n\n  if (counter_end < counter)\n    return ASN1_DER_ERROR;\n\n  while (counter < counter_end)\n    {\n      DECR_LEN(der_len, 1);\n      len2 = asn1_get_length_der (der + counter, der_len, &len3);\n\n      if (IS_ERR(len2, flags))\n\t{\n\t  warn();\n\t  return ASN1_DER_ERROR;\n\t}\n\n      if (len2 >= 0)\n\t{\n\t  DECR_LEN(der_len, len2+len3);\n\t  _asn1_append_value (node, der + counter + len3, len2);\n\t}\n      else\n\t{\t\t\t/* indefinite */\n\t  DECR_LEN(der_len, len3);\n\t  result =\n\t    _asn1_extract_der_octet (node, der + counter + len3,\n\t\t\t\t     der_len, flags);\n\t  if (result != ASN1_SUCCESS)\n\t    return result;\n\t  len2 = 0;\n\t}\n\n      counter += len2 + len3 + 1;\n    }\n\n  return ASN1_SUCCESS;\n\ncleanup:\n  return result;\n}",
        "func": "static int\n_asn1_extract_der_octet (asn1_node node, const unsigned char *der,\n\t\t\t int der_len, unsigned flags, int *bytes)\n{\n  int len2, len3;\n  int counter, counter_end;\n  int result;\n\n  len2 = asn1_get_length_der (der, der_len, &len3);\n  if (len2 < -1)\n    return ASN1_DER_ERROR;\n\n  counter = len3 + 1;\n  DECR_LEN(der_len, len3);\n\n  if (len2 == -1)\n    {\n      if (der_len < 2)\n        return ASN1_DER_ERROR;\n      counter_end = der_len - 2;\n    }\n  else\n    counter_end = der_len;\n\n  if (counter_end < counter)\n    return ASN1_DER_ERROR;\n\n  while (counter < counter_end)\n    {\n      DECR_LEN(der_len, 1);\n      len2 = asn1_get_length_der (der + counter, der_len, &len3);\n\n      if (IS_ERR(len2, flags))\n\t{\n\t  warn();\n\t  return ASN1_DER_ERROR;\n\t}\n\n      if (len2 >= 0)\n\t{\n\t  DECR_LEN(der_len, len2+len3);\n\t  _asn1_append_value (node, der + counter + len3, len2);\n\t}\n      else\n\t{\t\t\t/* indefinite */\n\t  DECR_LEN(der_len, len3);\n\t  result =\n\t    _asn1_extract_der_octet (node, der + counter + len3,\n\t\t\t\t     der_len, flags, &len2);\n\t  if (result != ASN1_SUCCESS)\n\t    return result;\n\n\t  DECR_LEN(der_len, len2);\n\t}\n\n      counter += len2 + len3 + 1;\n    }\n\n  if (bytes)\n    *bytes = counter;\n\n  return ASN1_SUCCESS;\n\ncleanup:\n  return result;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,6 @@\n static int\n _asn1_extract_der_octet (asn1_node node, const unsigned char *der,\n-\t\t\t int der_len, unsigned flags)\n+\t\t\t int der_len, unsigned flags, int *bytes)\n {\n   int len2, len3;\n   int counter, counter_end;\n@@ -46,14 +46,18 @@\n \t  DECR_LEN(der_len, len3);\n \t  result =\n \t    _asn1_extract_der_octet (node, der + counter + len3,\n-\t\t\t\t     der_len, flags);\n+\t\t\t\t     der_len, flags, &len2);\n \t  if (result != ASN1_SUCCESS)\n \t    return result;\n-\t  len2 = 0;\n+\n+\t  DECR_LEN(der_len, len2);\n \t}\n \n       counter += len2 + len3 + 1;\n     }\n+\n+  if (bytes)\n+    *bytes = counter;\n \n   return ASN1_SUCCESS;\n ",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\t int der_len, unsigned flags)",
                "\t\t\t\t     der_len, flags);",
                "\t  len2 = 0;"
            ],
            "added_lines": [
                "\t\t\t int der_len, unsigned flags, int *bytes)",
                "\t\t\t\t     der_len, flags, &len2);",
                "",
                "\t  DECR_LEN(der_len, len2);",
                "",
                "  if (bytes)",
                "    *bytes = counter;"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-8877",
        "func_name": "php/php-src/gdImageScaleTwoPass",
        "description": "The gdImageScaleTwoPass function in gd_interpolation.c in the GD Graphics Library (aka libgd) before 2.2.0, as used in PHP before 5.6.12, uses inconsistent allocate and free approaches, which allows remote attackers to cause a denial of service (memory consumption) via a crafted call, as demonstrated by a call to the PHP imagescale function.",
        "git_url": "https://github.com/php/php-src/commit/1a4722a89ee85be74af5086a7027b3ad1e0a55e8",
        "commit_title": "Fix #70064: imagescale(..., IMG_BICUBIC) leaks memory",
        "commit_text": " A temporary image (tmp_im) is created with gdImageTrueColor() and freed with gdFree() instead of gdImageDestroy(). Let's fix that.",
        "func_before": "gdImagePtr gdImageScaleTwoPass(const gdImagePtr src, const unsigned int src_width, const unsigned int src_height, const unsigned int new_width, const unsigned int new_height)\n{\n\tgdImagePtr tmp_im;\n\tgdImagePtr dst;\n\n\t/* Convert to truecolor if it isn't; this code requires it. */\n\tif (!src->trueColor) {\n\t\tgdImagePaletteToTrueColor(src);\n\t}\n\n\ttmp_im = gdImageCreateTrueColor(new_width, src_height);\n\tif (tmp_im == NULL) {\n\t\treturn NULL;\n\t}\n\tgdImageSetInterpolationMethod(tmp_im, src->interpolation_id);\n\t_gdScaleHoriz(src, src_width, src_height, tmp_im, new_width, src_height);\n\n\tdst = gdImageCreateTrueColor(new_width, new_height);\n\tif (dst == NULL) {\n\t\tgdFree(tmp_im);\n\t\treturn NULL;\n\t}\n\tgdImageSetInterpolationMethod(dst, src->interpolation_id);\n\t_gdScaleVert(tmp_im, new_width, src_height, dst, new_width, new_height);\n\tgdFree(tmp_im);\n\n\treturn dst;\n}",
        "func": "gdImagePtr gdImageScaleTwoPass(const gdImagePtr src, const unsigned int src_width, const unsigned int src_height, const unsigned int new_width, const unsigned int new_height)\n{\n\tgdImagePtr tmp_im;\n\tgdImagePtr dst;\n\n\t/* Convert to truecolor if it isn't; this code requires it. */\n\tif (!src->trueColor) {\n\t\tgdImagePaletteToTrueColor(src);\n\t}\n\n\ttmp_im = gdImageCreateTrueColor(new_width, src_height);\n\tif (tmp_im == NULL) {\n\t\treturn NULL;\n\t}\n\tgdImageSetInterpolationMethod(tmp_im, src->interpolation_id);\n\t_gdScaleHoriz(src, src_width, src_height, tmp_im, new_width, src_height);\n\n\tdst = gdImageCreateTrueColor(new_width, new_height);\n\tif (dst == NULL) {\n\t\tgdImageDestroy(tmp_im);\n\t\treturn NULL;\n\t}\n\tgdImageSetInterpolationMethod(dst, src->interpolation_id);\n\t_gdScaleVert(tmp_im, new_width, src_height, dst, new_width, new_height);\n\tgdImageDestroy(tmp_im);\n\n\treturn dst;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -17,12 +17,12 @@\n \n \tdst = gdImageCreateTrueColor(new_width, new_height);\n \tif (dst == NULL) {\n-\t\tgdFree(tmp_im);\n+\t\tgdImageDestroy(tmp_im);\n \t\treturn NULL;\n \t}\n \tgdImageSetInterpolationMethod(dst, src->interpolation_id);\n \t_gdScaleVert(tmp_im, new_width, src_height, dst, new_width, new_height);\n-\tgdFree(tmp_im);\n+\tgdImageDestroy(tmp_im);\n \n \treturn dst;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tgdFree(tmp_im);",
                "\tgdFree(tmp_im);"
            ],
            "added_lines": [
                "\t\tgdImageDestroy(tmp_im);",
                "\tgdImageDestroy(tmp_im);"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-8877",
        "func_name": "libgd/gdImageScaleTwoPass",
        "description": "The gdImageScaleTwoPass function in gd_interpolation.c in the GD Graphics Library (aka libgd) before 2.2.0, as used in PHP before 5.6.12, uses inconsistent allocate and free approaches, which allows remote attackers to cause a denial of service (memory consumption) via a crafted call, as demonstrated by a call to the PHP imagescale function.",
        "git_url": "https://github.com/libgd/libgd/commit/4751b606fa38edc456d627140898a7ec679fcc24",
        "commit_title": "gdImageScaleTwoPass memory leak fix",
        "commit_text": " Fixing memory leak in gdImageScaleTwoPass, as reported by @cmb69 and confirmed by @vapier.  This bug actually bit me in production and I'm very thankful that it was reported with an easy fix.  Fixes #173.",
        "func_before": "static gdImagePtr\ngdImageScaleTwoPass(const gdImagePtr src, const unsigned int new_width,\n                    const unsigned int new_height)\n{\n    const unsigned int src_width = src->sx;\n    const unsigned int src_height = src->sy;\n\tgdImagePtr tmp_im = NULL;\n\tgdImagePtr dst = NULL;\n\n    /* First, handle the trivial case. */\n    if (src_width == new_width && src_height == new_height) {\n        return gdImageClone(src);\n    }/* if */\n\n\t/* Convert to truecolor if it isn't; this code requires it. */\n\tif (!src->trueColor) {\n\t\tgdImagePaletteToTrueColor(src);\n\t}/* if */\n\n    /* Scale horizontally unless sizes are the same. */\n    if (src_width == new_width) {\n        tmp_im = src;\n    } else {\n        tmp_im = gdImageCreateTrueColor(new_width, src_height);\n        if (tmp_im == NULL) {\n            return NULL;\n        }\n        gdImageSetInterpolationMethod(tmp_im, src->interpolation_id);\n\n        _gdScalePass(src, src_width, tmp_im, new_width, src_height, HORIZONTAL);\n    }/* if .. else*/\n\n    /* If vertical sizes match, we're done. */\n    if (src_height == new_height) {\n        assert(tmp_im != src);\n        return tmp_im;\n    }/* if */\n\n    /* Otherwise, we need to scale vertically. */\n\tdst = gdImageCreateTrueColor(new_width, new_height);\n\tif (dst != NULL) {\n        gdImageSetInterpolationMethod(dst, src->interpolation_id);\n        _gdScalePass(tmp_im, src_height, dst, new_height, new_width, VERTICAL);\n    }/* if */\n\n    if (src != tmp_im) {\n        gdFree(tmp_im);\n    }/* if */\n\n\treturn dst;\n}",
        "func": "static gdImagePtr\ngdImageScaleTwoPass(const gdImagePtr src, const unsigned int new_width,\n                    const unsigned int new_height)\n{\n    const unsigned int src_width = src->sx;\n    const unsigned int src_height = src->sy;\n\tgdImagePtr tmp_im = NULL;\n\tgdImagePtr dst = NULL;\n\n    /* First, handle the trivial case. */\n    if (src_width == new_width && src_height == new_height) {\n        return gdImageClone(src);\n    }/* if */\n\n\t/* Convert to truecolor if it isn't; this code requires it. */\n\tif (!src->trueColor) {\n\t\tgdImagePaletteToTrueColor(src);\n\t}/* if */\n\n    /* Scale horizontally unless sizes are the same. */\n    if (src_width == new_width) {\n        tmp_im = src;\n    } else {\n        tmp_im = gdImageCreateTrueColor(new_width, src_height);\n        if (tmp_im == NULL) {\n            return NULL;\n        }\n        gdImageSetInterpolationMethod(tmp_im, src->interpolation_id);\n\n        _gdScalePass(src, src_width, tmp_im, new_width, src_height, HORIZONTAL);\n    }/* if .. else*/\n\n    /* If vertical sizes match, we're done. */\n    if (src_height == new_height) {\n        assert(tmp_im != src);\n        return tmp_im;\n    }/* if */\n\n    /* Otherwise, we need to scale vertically. */\n\tdst = gdImageCreateTrueColor(new_width, new_height);\n\tif (dst != NULL) {\n        gdImageSetInterpolationMethod(dst, src->interpolation_id);\n        _gdScalePass(tmp_im, src_height, dst, new_height, new_width, VERTICAL);\n    }/* if */\n\n    if (src != tmp_im) {\n        gdImageDestroy(tmp_im);\n    }/* if */\n\n\treturn dst;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -44,7 +44,7 @@\n     }/* if */\n \n     if (src != tmp_im) {\n-        gdFree(tmp_im);\n+        gdImageDestroy(tmp_im);\n     }/* if */\n \n \treturn dst;",
        "diff_line_info": {
            "deleted_lines": [
                "        gdFree(tmp_im);"
            ],
            "added_lines": [
                "        gdImageDestroy(tmp_im);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-4021",
        "func_name": "kazu-yamamoto/pgpdump/read_binary",
        "description": "The read_binary function in buffer.c in pgpdump before 0.30 allows context-dependent attackers to cause a denial of service (infinite loop and CPU consumption) via crafted input, as demonstrated by the \\xa3\\x03 string.",
        "git_url": "https://github.com/kazu-yamamoto/pgpdump/commit/ece39ddefd102dce7ce84c11580f32a03da568ed",
        "commit_title": "fix endless loop on invalid 2 Byte input \\xa3\\x03 (SYSS-16-030)",
        "commit_text": "",
        "func_before": "private int\nread_binary(byte *p, unsigned int max)\n{\n\t/* errno */\n\treturn fread(p, sizeof(byte), max, stdin);\n}",
        "func": "private int\nread_binary(byte *p, unsigned int max)\n{\n\tsize_t ret = fread(p, sizeof(byte), max, stdin);\n\tif (feof(stdin) | ferror(stdin)) {\n\t\twarn_exit(\"error in read_binary, maybe preliminary EOF?\");\n\t}\n\treturn ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,9 @@\n private int\n read_binary(byte *p, unsigned int max)\n {\n-\t/* errno */\n-\treturn fread(p, sizeof(byte), max, stdin);\n+\tsize_t ret = fread(p, sizeof(byte), max, stdin);\n+\tif (feof(stdin) | ferror(stdin)) {\n+\t\twarn_exit(\"error in read_binary, maybe preliminary EOF?\");\n+\t}\n+\treturn ret;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\t/* errno */",
                "\treturn fread(p, sizeof(byte), max, stdin);"
            ],
            "added_lines": [
                "\tsize_t ret = fread(p, sizeof(byte), max, stdin);",
                "\tif (feof(stdin) | ferror(stdin)) {",
                "\t\twarn_exit(\"error in read_binary, maybe preliminary EOF?\");",
                "\t}",
                "\treturn ret;"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-3506",
        "func_name": "openssl/dtls1_process_out_of_seq_message",
        "description": "d1_both.c in the DTLS implementation in OpenSSL 0.9.8 before 0.9.8zb, 1.0.0 before 1.0.0n, and 1.0.1 before 1.0.1i allows remote attackers to cause a denial of service (memory consumption) via crafted DTLS handshake messages that trigger memory allocations corresponding to large length values.",
        "git_url": "https://git.openssl.org/gitweb/?p=openssl.git;a=commit;h=1250f12613b61758675848f6600ebd914ccd7636",
        "commit_title": "",
        "commit_text": "Fix DTLS handshake message size checks.  In |dtls1_reassemble_fragment|, the value of |msg_hdr->frag_off+frag_len| was being checked against the maximum handshake message size, but then |msg_len| bytes were allocated for the fragment buffer. This means that so long as the fragment was within the allowed size, the pending handshake message could consume 16MB + 2MB (for the reassembly bitmap). Approx 10 outstanding handshake messages are allowed, meaning that an attacker could consume ~180MB per DTLS connection.  In the non-fragmented path (in |dtls1_process_out_of_seq_message|), no check was applied.  Fixes CVE-2014-3506  Wholly based on patch by Adam Langley with one minor amendment.  ",
        "func_before": "static int\ndtls1_process_out_of_seq_message(SSL *s, struct hm_header_st* msg_hdr, int *ok)\n{\n\tint i=-1;\n\thm_fragment *frag = NULL;\n\tpitem *item = NULL;\n\tunsigned char seq64be[8];\n\tunsigned long frag_len = msg_hdr->frag_len;\n\n\tif ((msg_hdr->frag_off+frag_len) > msg_hdr->msg_len)\n\t\tgoto err;\n\n\t/* Try to find item in queue, to prevent duplicate entries */\n\tmemset(seq64be,0,sizeof(seq64be));\n\tseq64be[6] = (unsigned char) (msg_hdr->seq>>8);\n\tseq64be[7] = (unsigned char) msg_hdr->seq;\n\titem = pqueue_find(s->d1->buffered_messages, seq64be);\n\n\t/* If we already have an entry and this one is a fragment,\n\t * don't discard it and rather try to reassemble it.\n\t */\n\tif (item != NULL && frag_len < msg_hdr->msg_len)\n\t\titem = NULL;\n\n\t/* Discard the message if sequence number was already there, is\n\t * too far in the future, already in the queue or if we received\n\t * a FINISHED before the SERVER_HELLO, which then must be a stale\n\t * retransmit.\n\t */\n\tif (msg_hdr->seq <= s->d1->handshake_read_seq ||\n\t\tmsg_hdr->seq > s->d1->handshake_read_seq + 10 || item != NULL ||\n\t\t(s->d1->handshake_read_seq == 0 && msg_hdr->type == SSL3_MT_FINISHED))\n\t\t{\n\t\tunsigned char devnull [256];\n\n\t\twhile (frag_len)\n\t\t\t{\n\t\t\ti = s->method->ssl_read_bytes(s,SSL3_RT_HANDSHAKE,\n\t\t\t\tdevnull,\n\t\t\t\tfrag_len>sizeof(devnull)?sizeof(devnull):frag_len,0);\n\t\t\tif (i<=0) goto err;\n\t\t\tfrag_len -= i;\n\t\t\t}\n\t\t}\n\telse\n\t\t{\n\t\tif (frag_len && frag_len < msg_hdr->msg_len)\n\t\t\treturn dtls1_reassemble_fragment(s, msg_hdr, ok);\n\n\t\tfrag = dtls1_hm_fragment_new(frag_len, 0);\n\t\tif ( frag == NULL)\n\t\t\tgoto err;\n\n\t\tmemcpy(&(frag->msg_header), msg_hdr, sizeof(*msg_hdr));\n\n\t\tif (frag_len)\n\t\t\t{\n\t\t\t/* read the body of the fragment (header has already been read */\n\t\t\ti = s->method->ssl_read_bytes(s,SSL3_RT_HANDSHAKE,\n\t\t\t\tfrag->fragment,frag_len,0);\n\t\t\tif (i<=0 || (unsigned long)i!=frag_len)\n\t\t\t\tgoto err;\n\t\t\t}\n\n\t\tmemset(seq64be,0,sizeof(seq64be));\n\t\tseq64be[6] = (unsigned char)(msg_hdr->seq>>8);\n\t\tseq64be[7] = (unsigned char)(msg_hdr->seq);\n\n\t\titem = pitem_new(seq64be, frag);\n\t\tif ( item == NULL)\n\t\t\tgoto err;\n\n\t\tpqueue_insert(s->d1->buffered_messages, item);\n\t\t}\n\n\treturn DTLS1_HM_FRAGMENT_RETRY;\n\nerr:\n\tif (frag != NULL && item == NULL) dtls1_hm_fragment_free(frag);\n\t*ok = 0;\n\treturn i;\n\t}",
        "func": "static int\ndtls1_process_out_of_seq_message(SSL *s, struct hm_header_st* msg_hdr, int *ok)\n{\n\tint i=-1;\n\thm_fragment *frag = NULL;\n\tpitem *item = NULL;\n\tunsigned char seq64be[8];\n\tunsigned long frag_len = msg_hdr->frag_len;\n\n\tif ((msg_hdr->frag_off+frag_len) > msg_hdr->msg_len)\n\t\tgoto err;\n\n\t/* Try to find item in queue, to prevent duplicate entries */\n\tmemset(seq64be,0,sizeof(seq64be));\n\tseq64be[6] = (unsigned char) (msg_hdr->seq>>8);\n\tseq64be[7] = (unsigned char) msg_hdr->seq;\n\titem = pqueue_find(s->d1->buffered_messages, seq64be);\n\n\t/* If we already have an entry and this one is a fragment,\n\t * don't discard it and rather try to reassemble it.\n\t */\n\tif (item != NULL && frag_len < msg_hdr->msg_len)\n\t\titem = NULL;\n\n\t/* Discard the message if sequence number was already there, is\n\t * too far in the future, already in the queue or if we received\n\t * a FINISHED before the SERVER_HELLO, which then must be a stale\n\t * retransmit.\n\t */\n\tif (msg_hdr->seq <= s->d1->handshake_read_seq ||\n\t\tmsg_hdr->seq > s->d1->handshake_read_seq + 10 || item != NULL ||\n\t\t(s->d1->handshake_read_seq == 0 && msg_hdr->type == SSL3_MT_FINISHED))\n\t\t{\n\t\tunsigned char devnull [256];\n\n\t\twhile (frag_len)\n\t\t\t{\n\t\t\ti = s->method->ssl_read_bytes(s,SSL3_RT_HANDSHAKE,\n\t\t\t\tdevnull,\n\t\t\t\tfrag_len>sizeof(devnull)?sizeof(devnull):frag_len,0);\n\t\t\tif (i<=0) goto err;\n\t\t\tfrag_len -= i;\n\t\t\t}\n\t\t}\n\telse\n\t\t{\n\t\tif (frag_len && frag_len < msg_hdr->msg_len)\n\t\t\treturn dtls1_reassemble_fragment(s, msg_hdr, ok);\n\n\t\tif (frag_len > dtls1_max_handshake_message_len(s))\n\t\t\tgoto err;\n\n\t\tfrag = dtls1_hm_fragment_new(frag_len, 0);\n\t\tif ( frag == NULL)\n\t\t\tgoto err;\n\n\t\tmemcpy(&(frag->msg_header), msg_hdr, sizeof(*msg_hdr));\n\n\t\tif (frag_len)\n\t\t\t{\n\t\t\t/* read the body of the fragment (header has already been read */\n\t\t\ti = s->method->ssl_read_bytes(s,SSL3_RT_HANDSHAKE,\n\t\t\t\tfrag->fragment,frag_len,0);\n\t\t\tif (i<=0 || (unsigned long)i!=frag_len)\n\t\t\t\tgoto err;\n\t\t\t}\n\n\t\tmemset(seq64be,0,sizeof(seq64be));\n\t\tseq64be[6] = (unsigned char)(msg_hdr->seq>>8);\n\t\tseq64be[7] = (unsigned char)(msg_hdr->seq);\n\n\t\titem = pitem_new(seq64be, frag);\n\t\tif ( item == NULL)\n\t\t\tgoto err;\n\n\t\tpqueue_insert(s->d1->buffered_messages, item);\n\t\t}\n\n\treturn DTLS1_HM_FRAGMENT_RETRY;\n\nerr:\n\tif (frag != NULL && item == NULL) dtls1_hm_fragment_free(frag);\n\t*ok = 0;\n\treturn i;\n\t}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -47,6 +47,9 @@\n \t\tif (frag_len && frag_len < msg_hdr->msg_len)\n \t\t\treturn dtls1_reassemble_fragment(s, msg_hdr, ok);\n \n+\t\tif (frag_len > dtls1_max_handshake_message_len(s))\n+\t\t\tgoto err;\n+\n \t\tfrag = dtls1_hm_fragment_new(frag_len, 0);\n \t\tif ( frag == NULL)\n \t\t\tgoto err;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t\tif (frag_len > dtls1_max_handshake_message_len(s))",
                "\t\t\tgoto err;",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2014-3506",
        "func_name": "openssl/dtls1_reassemble_fragment",
        "description": "d1_both.c in the DTLS implementation in OpenSSL 0.9.8 before 0.9.8zb, 1.0.0 before 1.0.0n, and 1.0.1 before 1.0.1i allows remote attackers to cause a denial of service (memory consumption) via crafted DTLS handshake messages that trigger memory allocations corresponding to large length values.",
        "git_url": "https://git.openssl.org/gitweb/?p=openssl.git;a=commit;h=1250f12613b61758675848f6600ebd914ccd7636",
        "commit_title": "",
        "commit_text": "Fix DTLS handshake message size checks.  In |dtls1_reassemble_fragment|, the value of |msg_hdr->frag_off+frag_len| was being checked against the maximum handshake message size, but then |msg_len| bytes were allocated for the fragment buffer. This means that so long as the fragment was within the allowed size, the pending handshake message could consume 16MB + 2MB (for the reassembly bitmap). Approx 10 outstanding handshake messages are allowed, meaning that an attacker could consume ~180MB per DTLS connection.  In the non-fragmented path (in |dtls1_process_out_of_seq_message|), no check was applied.  Fixes CVE-2014-3506  Wholly based on patch by Adam Langley with one minor amendment.  ",
        "func_before": "static int\ndtls1_reassemble_fragment(SSL *s, struct hm_header_st* msg_hdr, int *ok)\n\t{\n\thm_fragment *frag = NULL;\n\tpitem *item = NULL;\n\tint i = -1, is_complete;\n\tunsigned char seq64be[8];\n\tunsigned long frag_len = msg_hdr->frag_len, max_len;\n\n\tif ((msg_hdr->frag_off+frag_len) > msg_hdr->msg_len)\n\t\tgoto err;\n\n\t/* Determine maximum allowed message size. Depends on (user set)\n\t * maximum certificate length, but 16k is minimum.\n\t */\n\tif (DTLS1_HM_HEADER_LENGTH + SSL3_RT_MAX_ENCRYPTED_LENGTH < s->max_cert_list)\n\t\tmax_len = s->max_cert_list;\n\telse\n\t\tmax_len = DTLS1_HM_HEADER_LENGTH + SSL3_RT_MAX_ENCRYPTED_LENGTH;\n\n\tif ((msg_hdr->frag_off+frag_len) > max_len)\n\t\tgoto err;\n\n\t/* Try to find item in queue */\n\tmemset(seq64be,0,sizeof(seq64be));\n\tseq64be[6] = (unsigned char) (msg_hdr->seq>>8);\n\tseq64be[7] = (unsigned char) msg_hdr->seq;\n\titem = pqueue_find(s->d1->buffered_messages, seq64be);\n\n\tif (item == NULL)\n\t\t{\n\t\tfrag = dtls1_hm_fragment_new(msg_hdr->msg_len, 1);\n\t\tif ( frag == NULL)\n\t\t\tgoto err;\n\t\tmemcpy(&(frag->msg_header), msg_hdr, sizeof(*msg_hdr));\n\t\tfrag->msg_header.frag_len = frag->msg_header.msg_len;\n\t\tfrag->msg_header.frag_off = 0;\n\t\t}\n\telse\n\t\t{\n\t\tfrag = (hm_fragment*) item->data;\n\t\tif (frag->msg_header.msg_len != msg_hdr->msg_len)\n\t\t\t{\n\t\t\titem = NULL;\n\t\t\tfrag = NULL;\n\t\t\tgoto err;\n\t\t\t}\n\t\t}\n\n\n\t/* If message is already reassembled, this must be a\n\t * retransmit and can be dropped. In this case item != NULL and so frag\n\t * does not need to be freed.\n\t */\n\tif (frag->reassembly == NULL)\n\t\t{\n\t\tunsigned char devnull [256];\n\n\t\twhile (frag_len)\n\t\t\t{\n\t\t\ti = s->method->ssl_read_bytes(s,SSL3_RT_HANDSHAKE,\n\t\t\t\tdevnull,\n\t\t\t\tfrag_len>sizeof(devnull)?sizeof(devnull):frag_len,0);\n\t\t\tif (i<=0) goto err;\n\t\t\tfrag_len -= i;\n\t\t\t}\n\t\treturn DTLS1_HM_FRAGMENT_RETRY;\n\t\t}\n\n\t/* read the body of the fragment (header has already been read */\n\ti = s->method->ssl_read_bytes(s,SSL3_RT_HANDSHAKE,\n\t\tfrag->fragment + msg_hdr->frag_off,frag_len,0);\n\tif (i<=0 || (unsigned long)i!=frag_len)\n\t\tgoto err;\n\n\tRSMBLY_BITMASK_MARK(frag->reassembly, (long)msg_hdr->frag_off,\n\t                    (long)(msg_hdr->frag_off + frag_len));\n\n\tRSMBLY_BITMASK_IS_COMPLETE(frag->reassembly, (long)msg_hdr->msg_len,\n\t                           is_complete);\n\n\tif (is_complete)\n\t\t{\n\t\tOPENSSL_free(frag->reassembly);\n\t\tfrag->reassembly = NULL;\n\t\t}\n\n\tif (item == NULL)\n\t\t{\n\t\tmemset(seq64be,0,sizeof(seq64be));\n\t\tseq64be[6] = (unsigned char)(msg_hdr->seq>>8);\n\t\tseq64be[7] = (unsigned char)(msg_hdr->seq);\n\n\t\titem = pitem_new(seq64be, frag);\n\t\tif (item == NULL)\n\t\t\t{\n\t\t\ti = -1;\n\t\t\tgoto err;\n\t\t\t}\n\n\t\tpqueue_insert(s->d1->buffered_messages, item);\n\t\t}\n\n\treturn DTLS1_HM_FRAGMENT_RETRY;\n\nerr:\n\tif (frag != NULL && item == NULL) dtls1_hm_fragment_free(frag);\n\t*ok = 0;\n\treturn i;\n\t}",
        "func": "static int\ndtls1_reassemble_fragment(SSL *s, struct hm_header_st* msg_hdr, int *ok)\n\t{\n\thm_fragment *frag = NULL;\n\tpitem *item = NULL;\n\tint i = -1, is_complete;\n\tunsigned char seq64be[8];\n\tunsigned long frag_len = msg_hdr->frag_len;\n\n\tif ((msg_hdr->frag_off+frag_len) > msg_hdr->msg_len ||\n\t    msg_hdr->msg_len > dtls1_max_handshake_message_len(s))\n\t\tgoto err;\n\n\t/* Try to find item in queue */\n\tmemset(seq64be,0,sizeof(seq64be));\n\tseq64be[6] = (unsigned char) (msg_hdr->seq>>8);\n\tseq64be[7] = (unsigned char) msg_hdr->seq;\n\titem = pqueue_find(s->d1->buffered_messages, seq64be);\n\n\tif (item == NULL)\n\t\t{\n\t\tfrag = dtls1_hm_fragment_new(msg_hdr->msg_len, 1);\n\t\tif ( frag == NULL)\n\t\t\tgoto err;\n\t\tmemcpy(&(frag->msg_header), msg_hdr, sizeof(*msg_hdr));\n\t\tfrag->msg_header.frag_len = frag->msg_header.msg_len;\n\t\tfrag->msg_header.frag_off = 0;\n\t\t}\n\telse\n\t\t{\n\t\tfrag = (hm_fragment*) item->data;\n\t\tif (frag->msg_header.msg_len != msg_hdr->msg_len)\n\t\t\t{\n\t\t\titem = NULL;\n\t\t\tfrag = NULL;\n\t\t\tgoto err;\n\t\t\t}\n\t\t}\n\n\n\t/* If message is already reassembled, this must be a\n\t * retransmit and can be dropped. In this case item != NULL and so frag\n\t * does not need to be freed.\n\t */\n\tif (frag->reassembly == NULL)\n\t\t{\n\t\tunsigned char devnull [256];\n\n\t\twhile (frag_len)\n\t\t\t{\n\t\t\ti = s->method->ssl_read_bytes(s,SSL3_RT_HANDSHAKE,\n\t\t\t\tdevnull,\n\t\t\t\tfrag_len>sizeof(devnull)?sizeof(devnull):frag_len,0);\n\t\t\tif (i<=0) goto err;\n\t\t\tfrag_len -= i;\n\t\t\t}\n\t\treturn DTLS1_HM_FRAGMENT_RETRY;\n\t\t}\n\n\t/* read the body of the fragment (header has already been read */\n\ti = s->method->ssl_read_bytes(s,SSL3_RT_HANDSHAKE,\n\t\tfrag->fragment + msg_hdr->frag_off,frag_len,0);\n\tif (i<=0 || (unsigned long)i!=frag_len)\n\t\tgoto err;\n\n\tRSMBLY_BITMASK_MARK(frag->reassembly, (long)msg_hdr->frag_off,\n\t                    (long)(msg_hdr->frag_off + frag_len));\n\n\tRSMBLY_BITMASK_IS_COMPLETE(frag->reassembly, (long)msg_hdr->msg_len,\n\t                           is_complete);\n\n\tif (is_complete)\n\t\t{\n\t\tOPENSSL_free(frag->reassembly);\n\t\tfrag->reassembly = NULL;\n\t\t}\n\n\tif (item == NULL)\n\t\t{\n\t\tmemset(seq64be,0,sizeof(seq64be));\n\t\tseq64be[6] = (unsigned char)(msg_hdr->seq>>8);\n\t\tseq64be[7] = (unsigned char)(msg_hdr->seq);\n\n\t\titem = pitem_new(seq64be, frag);\n\t\tif (item == NULL)\n\t\t\t{\n\t\t\ti = -1;\n\t\t\tgoto err;\n\t\t\t}\n\n\t\tpqueue_insert(s->d1->buffered_messages, item);\n\t\t}\n\n\treturn DTLS1_HM_FRAGMENT_RETRY;\n\nerr:\n\tif (frag != NULL && item == NULL) dtls1_hm_fragment_free(frag);\n\t*ok = 0;\n\treturn i;\n\t}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,20 +5,10 @@\n \tpitem *item = NULL;\n \tint i = -1, is_complete;\n \tunsigned char seq64be[8];\n-\tunsigned long frag_len = msg_hdr->frag_len, max_len;\n+\tunsigned long frag_len = msg_hdr->frag_len;\n \n-\tif ((msg_hdr->frag_off+frag_len) > msg_hdr->msg_len)\n-\t\tgoto err;\n-\n-\t/* Determine maximum allowed message size. Depends on (user set)\n-\t * maximum certificate length, but 16k is minimum.\n-\t */\n-\tif (DTLS1_HM_HEADER_LENGTH + SSL3_RT_MAX_ENCRYPTED_LENGTH < s->max_cert_list)\n-\t\tmax_len = s->max_cert_list;\n-\telse\n-\t\tmax_len = DTLS1_HM_HEADER_LENGTH + SSL3_RT_MAX_ENCRYPTED_LENGTH;\n-\n-\tif ((msg_hdr->frag_off+frag_len) > max_len)\n+\tif ((msg_hdr->frag_off+frag_len) > msg_hdr->msg_len ||\n+\t    msg_hdr->msg_len > dtls1_max_handshake_message_len(s))\n \t\tgoto err;\n \n \t/* Try to find item in queue */",
        "diff_line_info": {
            "deleted_lines": [
                "\tunsigned long frag_len = msg_hdr->frag_len, max_len;",
                "\tif ((msg_hdr->frag_off+frag_len) > msg_hdr->msg_len)",
                "\t\tgoto err;",
                "",
                "\t/* Determine maximum allowed message size. Depends on (user set)",
                "\t * maximum certificate length, but 16k is minimum.",
                "\t */",
                "\tif (DTLS1_HM_HEADER_LENGTH + SSL3_RT_MAX_ENCRYPTED_LENGTH < s->max_cert_list)",
                "\t\tmax_len = s->max_cert_list;",
                "\telse",
                "\t\tmax_len = DTLS1_HM_HEADER_LENGTH + SSL3_RT_MAX_ENCRYPTED_LENGTH;",
                "",
                "\tif ((msg_hdr->frag_off+frag_len) > max_len)"
            ],
            "added_lines": [
                "\tunsigned long frag_len = msg_hdr->frag_len;",
                "\tif ((msg_hdr->frag_off+frag_len) > msg_hdr->msg_len ||",
                "\t    msg_hdr->msg_len > dtls1_max_handshake_message_len(s))"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-3507",
        "func_name": "openssl/dtls1_process_out_of_seq_message",
        "description": "Memory leak in d1_both.c in the DTLS implementation in OpenSSL 0.9.8 before 0.9.8zb, 1.0.0 before 1.0.0n, and 1.0.1 before 1.0.1i allows remote attackers to cause a denial of service (memory consumption) via zero-length DTLS fragments that trigger improper handling of the return value of a certain insert function.",
        "git_url": "https://git.openssl.org/gitweb/?p=openssl.git;a=commit;h=d0a4b7d1a2948fce38515b8d862f43e7ba0ebf74",
        "commit_title": "",
        "commit_text": "Fix memory leak from zero-length DTLS fragments.  The |pqueue_insert| function can fail if one attempts to insert a duplicate sequence number. When handling a fragment of an out of sequence message, |dtls1_process_out_of_seq_message| would not call |dtls1_reassemble_fragment| if the fragment's length was zero. It would then allocate a fresh fragment and attempt to insert it, but ignore the return value, leaking the fragment.  This allows an attacker to exhaust the memory of a DTLS peer.  Fixes CVE-2014-3507  ",
        "func_before": "static int\ndtls1_process_out_of_seq_message(SSL *s, struct hm_header_st* msg_hdr, int *ok)\n{\n\tint i=-1;\n\thm_fragment *frag = NULL;\n\tpitem *item = NULL;\n\tunsigned char seq64be[8];\n\tunsigned long frag_len = msg_hdr->frag_len;\n\n\tif ((msg_hdr->frag_off+frag_len) > msg_hdr->msg_len)\n\t\tgoto err;\n\n\t/* Try to find item in queue, to prevent duplicate entries */\n\tmemset(seq64be,0,sizeof(seq64be));\n\tseq64be[6] = (unsigned char) (msg_hdr->seq>>8);\n\tseq64be[7] = (unsigned char) msg_hdr->seq;\n\titem = pqueue_find(s->d1->buffered_messages, seq64be);\n\n\t/* If we already have an entry and this one is a fragment,\n\t * don't discard it and rather try to reassemble it.\n\t */\n\tif (item != NULL && frag_len < msg_hdr->msg_len)\n\t\titem = NULL;\n\n\t/* Discard the message if sequence number was already there, is\n\t * too far in the future, already in the queue or if we received\n\t * a FINISHED before the SERVER_HELLO, which then must be a stale\n\t * retransmit.\n\t */\n\tif (msg_hdr->seq <= s->d1->handshake_read_seq ||\n\t\tmsg_hdr->seq > s->d1->handshake_read_seq + 10 || item != NULL ||\n\t\t(s->d1->handshake_read_seq == 0 && msg_hdr->type == SSL3_MT_FINISHED))\n\t\t{\n\t\tunsigned char devnull [256];\n\n\t\twhile (frag_len)\n\t\t\t{\n\t\t\ti = s->method->ssl_read_bytes(s,SSL3_RT_HANDSHAKE,\n\t\t\t\tdevnull,\n\t\t\t\tfrag_len>sizeof(devnull)?sizeof(devnull):frag_len,0);\n\t\t\tif (i<=0) goto err;\n\t\t\tfrag_len -= i;\n\t\t\t}\n\t\t}\n\telse\n\t\t{\n\t\tif (frag_len && frag_len < msg_hdr->msg_len)\n\t\t\treturn dtls1_reassemble_fragment(s, msg_hdr, ok);\n\n\t\tif (frag_len > dtls1_max_handshake_message_len(s))\n\t\t\tgoto err;\n\n\t\tfrag = dtls1_hm_fragment_new(frag_len, 0);\n\t\tif ( frag == NULL)\n\t\t\tgoto err;\n\n\t\tmemcpy(&(frag->msg_header), msg_hdr, sizeof(*msg_hdr));\n\n\t\tif (frag_len)\n\t\t\t{\n\t\t\t/* read the body of the fragment (header has already been read */\n\t\t\ti = s->method->ssl_read_bytes(s,SSL3_RT_HANDSHAKE,\n\t\t\t\tfrag->fragment,frag_len,0);\n\t\t\tif (i<=0 || (unsigned long)i!=frag_len)\n\t\t\t\tgoto err;\n\t\t\t}\n\n\t\tmemset(seq64be,0,sizeof(seq64be));\n\t\tseq64be[6] = (unsigned char)(msg_hdr->seq>>8);\n\t\tseq64be[7] = (unsigned char)(msg_hdr->seq);\n\n\t\titem = pitem_new(seq64be, frag);\n\t\tif ( item == NULL)\n\t\t\tgoto err;\n\n\t\tpqueue_insert(s->d1->buffered_messages, item);\n\t\t}\n\n\treturn DTLS1_HM_FRAGMENT_RETRY;\n\nerr:\n\tif (frag != NULL && item == NULL) dtls1_hm_fragment_free(frag);\n\t*ok = 0;\n\treturn i;\n\t}",
        "func": "static int\ndtls1_process_out_of_seq_message(SSL *s, struct hm_header_st* msg_hdr, int *ok)\n{\n\tint i=-1;\n\thm_fragment *frag = NULL;\n\tpitem *item = NULL;\n\tunsigned char seq64be[8];\n\tunsigned long frag_len = msg_hdr->frag_len;\n\n\tif ((msg_hdr->frag_off+frag_len) > msg_hdr->msg_len)\n\t\tgoto err;\n\n\t/* Try to find item in queue, to prevent duplicate entries */\n\tmemset(seq64be,0,sizeof(seq64be));\n\tseq64be[6] = (unsigned char) (msg_hdr->seq>>8);\n\tseq64be[7] = (unsigned char) msg_hdr->seq;\n\titem = pqueue_find(s->d1->buffered_messages, seq64be);\n\n\t/* If we already have an entry and this one is a fragment,\n\t * don't discard it and rather try to reassemble it.\n\t */\n\tif (item != NULL && frag_len < msg_hdr->msg_len)\n\t\titem = NULL;\n\n\t/* Discard the message if sequence number was already there, is\n\t * too far in the future, already in the queue or if we received\n\t * a FINISHED before the SERVER_HELLO, which then must be a stale\n\t * retransmit.\n\t */\n\tif (msg_hdr->seq <= s->d1->handshake_read_seq ||\n\t\tmsg_hdr->seq > s->d1->handshake_read_seq + 10 || item != NULL ||\n\t\t(s->d1->handshake_read_seq == 0 && msg_hdr->type == SSL3_MT_FINISHED))\n\t\t{\n\t\tunsigned char devnull [256];\n\n\t\twhile (frag_len)\n\t\t\t{\n\t\t\ti = s->method->ssl_read_bytes(s,SSL3_RT_HANDSHAKE,\n\t\t\t\tdevnull,\n\t\t\t\tfrag_len>sizeof(devnull)?sizeof(devnull):frag_len,0);\n\t\t\tif (i<=0) goto err;\n\t\t\tfrag_len -= i;\n\t\t\t}\n\t\t}\n\telse\n\t\t{\n\t\tif (frag_len < msg_hdr->msg_len)\n\t\t\treturn dtls1_reassemble_fragment(s, msg_hdr, ok);\n\n\t\tif (frag_len > dtls1_max_handshake_message_len(s))\n\t\t\tgoto err;\n\n\t\tfrag = dtls1_hm_fragment_new(frag_len, 0);\n\t\tif ( frag == NULL)\n\t\t\tgoto err;\n\n\t\tmemcpy(&(frag->msg_header), msg_hdr, sizeof(*msg_hdr));\n\n\t\tif (frag_len)\n\t\t\t{\n\t\t\t/* read the body of the fragment (header has already been read */\n\t\t\ti = s->method->ssl_read_bytes(s,SSL3_RT_HANDSHAKE,\n\t\t\t\tfrag->fragment,frag_len,0);\n\t\t\tif (i<=0 || (unsigned long)i!=frag_len)\n\t\t\t\tgoto err;\n\t\t\t}\n\n\t\tmemset(seq64be,0,sizeof(seq64be));\n\t\tseq64be[6] = (unsigned char)(msg_hdr->seq>>8);\n\t\tseq64be[7] = (unsigned char)(msg_hdr->seq);\n\n\t\titem = pitem_new(seq64be, frag);\n\t\tif ( item == NULL)\n\t\t\tgoto err;\n\n\t\titem = pqueue_insert(s->d1->buffered_messages, item);\n\t\t/* pqueue_insert fails iff a duplicate item is inserted.\n\t\t * However, |item| cannot be a duplicate. If it were,\n\t\t * |pqueue_find|, above, would have returned it. Then, either\n\t\t * |frag_len| != |msg_hdr->msg_len| in which case |item| is set\n\t\t * to NULL and it will have been processed with\n\t\t * |dtls1_reassemble_fragment|, above, or the record will have\n\t\t * been discarded. */\n\t\tOPENSSL_assert(item != NULL);\n\t\t}\n\n\treturn DTLS1_HM_FRAGMENT_RETRY;\n\nerr:\n\tif (frag != NULL && item == NULL) dtls1_hm_fragment_free(frag);\n\t*ok = 0;\n\treturn i;\n\t}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -44,7 +44,7 @@\n \t\t}\n \telse\n \t\t{\n-\t\tif (frag_len && frag_len < msg_hdr->msg_len)\n+\t\tif (frag_len < msg_hdr->msg_len)\n \t\t\treturn dtls1_reassemble_fragment(s, msg_hdr, ok);\n \n \t\tif (frag_len > dtls1_max_handshake_message_len(s))\n@@ -73,7 +73,15 @@\n \t\tif ( item == NULL)\n \t\t\tgoto err;\n \n-\t\tpqueue_insert(s->d1->buffered_messages, item);\n+\t\titem = pqueue_insert(s->d1->buffered_messages, item);\n+\t\t/* pqueue_insert fails iff a duplicate item is inserted.\n+\t\t * However, |item| cannot be a duplicate. If it were,\n+\t\t * |pqueue_find|, above, would have returned it. Then, either\n+\t\t * |frag_len| != |msg_hdr->msg_len| in which case |item| is set\n+\t\t * to NULL and it will have been processed with\n+\t\t * |dtls1_reassemble_fragment|, above, or the record will have\n+\t\t * been discarded. */\n+\t\tOPENSSL_assert(item != NULL);\n \t\t}\n \n \treturn DTLS1_HM_FRAGMENT_RETRY;",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tif (frag_len && frag_len < msg_hdr->msg_len)",
                "\t\tpqueue_insert(s->d1->buffered_messages, item);"
            ],
            "added_lines": [
                "\t\tif (frag_len < msg_hdr->msg_len)",
                "\t\titem = pqueue_insert(s->d1->buffered_messages, item);",
                "\t\t/* pqueue_insert fails iff a duplicate item is inserted.",
                "\t\t * However, |item| cannot be a duplicate. If it were,",
                "\t\t * |pqueue_find|, above, would have returned it. Then, either",
                "\t\t * |frag_len| != |msg_hdr->msg_len| in which case |item| is set",
                "\t\t * to NULL and it will have been processed with",
                "\t\t * |dtls1_reassemble_fragment|, above, or the record will have",
                "\t\t * been discarded. */",
                "\t\tOPENSSL_assert(item != NULL);"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-3507",
        "func_name": "openssl/dtls1_reassemble_fragment",
        "description": "Memory leak in d1_both.c in the DTLS implementation in OpenSSL 0.9.8 before 0.9.8zb, 1.0.0 before 1.0.0n, and 1.0.1 before 1.0.1i allows remote attackers to cause a denial of service (memory consumption) via zero-length DTLS fragments that trigger improper handling of the return value of a certain insert function.",
        "git_url": "https://git.openssl.org/gitweb/?p=openssl.git;a=commit;h=d0a4b7d1a2948fce38515b8d862f43e7ba0ebf74",
        "commit_title": "",
        "commit_text": "Fix memory leak from zero-length DTLS fragments.  The |pqueue_insert| function can fail if one attempts to insert a duplicate sequence number. When handling a fragment of an out of sequence message, |dtls1_process_out_of_seq_message| would not call |dtls1_reassemble_fragment| if the fragment's length was zero. It would then allocate a fresh fragment and attempt to insert it, but ignore the return value, leaking the fragment.  This allows an attacker to exhaust the memory of a DTLS peer.  Fixes CVE-2014-3507  ",
        "func_before": "static int\ndtls1_reassemble_fragment(SSL *s, struct hm_header_st* msg_hdr, int *ok)\n\t{\n\thm_fragment *frag = NULL;\n\tpitem *item = NULL;\n\tint i = -1, is_complete;\n\tunsigned char seq64be[8];\n\tunsigned long frag_len = msg_hdr->frag_len;\n\n\tif ((msg_hdr->frag_off+frag_len) > msg_hdr->msg_len ||\n\t    msg_hdr->msg_len > dtls1_max_handshake_message_len(s))\n\t\tgoto err;\n\n\t/* Try to find item in queue */\n\tmemset(seq64be,0,sizeof(seq64be));\n\tseq64be[6] = (unsigned char) (msg_hdr->seq>>8);\n\tseq64be[7] = (unsigned char) msg_hdr->seq;\n\titem = pqueue_find(s->d1->buffered_messages, seq64be);\n\n\tif (item == NULL)\n\t\t{\n\t\tfrag = dtls1_hm_fragment_new(msg_hdr->msg_len, 1);\n\t\tif ( frag == NULL)\n\t\t\tgoto err;\n\t\tmemcpy(&(frag->msg_header), msg_hdr, sizeof(*msg_hdr));\n\t\tfrag->msg_header.frag_len = frag->msg_header.msg_len;\n\t\tfrag->msg_header.frag_off = 0;\n\t\t}\n\telse\n\t\t{\n\t\tfrag = (hm_fragment*) item->data;\n\t\tif (frag->msg_header.msg_len != msg_hdr->msg_len)\n\t\t\t{\n\t\t\titem = NULL;\n\t\t\tfrag = NULL;\n\t\t\tgoto err;\n\t\t\t}\n\t\t}\n\n\n\t/* If message is already reassembled, this must be a\n\t * retransmit and can be dropped. In this case item != NULL and so frag\n\t * does not need to be freed.\n\t */\n\tif (frag->reassembly == NULL)\n\t\t{\n\t\tunsigned char devnull [256];\n\n\t\twhile (frag_len)\n\t\t\t{\n\t\t\ti = s->method->ssl_read_bytes(s,SSL3_RT_HANDSHAKE,\n\t\t\t\tdevnull,\n\t\t\t\tfrag_len>sizeof(devnull)?sizeof(devnull):frag_len,0);\n\t\t\tif (i<=0) goto err;\n\t\t\tfrag_len -= i;\n\t\t\t}\n\t\treturn DTLS1_HM_FRAGMENT_RETRY;\n\t\t}\n\n\t/* read the body of the fragment (header has already been read */\n\ti = s->method->ssl_read_bytes(s,SSL3_RT_HANDSHAKE,\n\t\tfrag->fragment + msg_hdr->frag_off,frag_len,0);\n\tif (i<=0 || (unsigned long)i!=frag_len)\n\t\tgoto err;\n\n\tRSMBLY_BITMASK_MARK(frag->reassembly, (long)msg_hdr->frag_off,\n\t                    (long)(msg_hdr->frag_off + frag_len));\n\n\tRSMBLY_BITMASK_IS_COMPLETE(frag->reassembly, (long)msg_hdr->msg_len,\n\t                           is_complete);\n\n\tif (is_complete)\n\t\t{\n\t\tOPENSSL_free(frag->reassembly);\n\t\tfrag->reassembly = NULL;\n\t\t}\n\n\tif (item == NULL)\n\t\t{\n\t\tmemset(seq64be,0,sizeof(seq64be));\n\t\tseq64be[6] = (unsigned char)(msg_hdr->seq>>8);\n\t\tseq64be[7] = (unsigned char)(msg_hdr->seq);\n\n\t\titem = pitem_new(seq64be, frag);\n\t\tif (item == NULL)\n\t\t\t{\n\t\t\ti = -1;\n\t\t\tgoto err;\n\t\t\t}\n\n\t\tpqueue_insert(s->d1->buffered_messages, item);\n\t\t}\n\n\treturn DTLS1_HM_FRAGMENT_RETRY;\n\nerr:\n\tif (frag != NULL && item == NULL) dtls1_hm_fragment_free(frag);\n\t*ok = 0;\n\treturn i;\n\t}",
        "func": "static int\ndtls1_reassemble_fragment(SSL *s, struct hm_header_st* msg_hdr, int *ok)\n\t{\n\thm_fragment *frag = NULL;\n\tpitem *item = NULL;\n\tint i = -1, is_complete;\n\tunsigned char seq64be[8];\n\tunsigned long frag_len = msg_hdr->frag_len;\n\n\tif ((msg_hdr->frag_off+frag_len) > msg_hdr->msg_len ||\n\t    msg_hdr->msg_len > dtls1_max_handshake_message_len(s))\n\t\tgoto err;\n\n\tif (frag_len == 0)\n\t\treturn DTLS1_HM_FRAGMENT_RETRY;\n\n\t/* Try to find item in queue */\n\tmemset(seq64be,0,sizeof(seq64be));\n\tseq64be[6] = (unsigned char) (msg_hdr->seq>>8);\n\tseq64be[7] = (unsigned char) msg_hdr->seq;\n\titem = pqueue_find(s->d1->buffered_messages, seq64be);\n\n\tif (item == NULL)\n\t\t{\n\t\tfrag = dtls1_hm_fragment_new(msg_hdr->msg_len, 1);\n\t\tif ( frag == NULL)\n\t\t\tgoto err;\n\t\tmemcpy(&(frag->msg_header), msg_hdr, sizeof(*msg_hdr));\n\t\tfrag->msg_header.frag_len = frag->msg_header.msg_len;\n\t\tfrag->msg_header.frag_off = 0;\n\t\t}\n\telse\n\t\t{\n\t\tfrag = (hm_fragment*) item->data;\n\t\tif (frag->msg_header.msg_len != msg_hdr->msg_len)\n\t\t\t{\n\t\t\titem = NULL;\n\t\t\tfrag = NULL;\n\t\t\tgoto err;\n\t\t\t}\n\t\t}\n\n\n\t/* If message is already reassembled, this must be a\n\t * retransmit and can be dropped. In this case item != NULL and so frag\n\t * does not need to be freed.\n\t */\n\tif (frag->reassembly == NULL)\n\t\t{\n\t\tunsigned char devnull [256];\n\n\t\twhile (frag_len)\n\t\t\t{\n\t\t\ti = s->method->ssl_read_bytes(s,SSL3_RT_HANDSHAKE,\n\t\t\t\tdevnull,\n\t\t\t\tfrag_len>sizeof(devnull)?sizeof(devnull):frag_len,0);\n\t\t\tif (i<=0) goto err;\n\t\t\tfrag_len -= i;\n\t\t\t}\n\t\treturn DTLS1_HM_FRAGMENT_RETRY;\n\t\t}\n\n\t/* read the body of the fragment (header has already been read */\n\ti = s->method->ssl_read_bytes(s,SSL3_RT_HANDSHAKE,\n\t\tfrag->fragment + msg_hdr->frag_off,frag_len,0);\n\tif (i<=0 || (unsigned long)i!=frag_len)\n\t\tgoto err;\n\n\tRSMBLY_BITMASK_MARK(frag->reassembly, (long)msg_hdr->frag_off,\n\t                    (long)(msg_hdr->frag_off + frag_len));\n\n\tRSMBLY_BITMASK_IS_COMPLETE(frag->reassembly, (long)msg_hdr->msg_len,\n\t                           is_complete);\n\n\tif (is_complete)\n\t\t{\n\t\tOPENSSL_free(frag->reassembly);\n\t\tfrag->reassembly = NULL;\n\t\t}\n\n\tif (item == NULL)\n\t\t{\n\t\tmemset(seq64be,0,sizeof(seq64be));\n\t\tseq64be[6] = (unsigned char)(msg_hdr->seq>>8);\n\t\tseq64be[7] = (unsigned char)(msg_hdr->seq);\n\n\t\titem = pitem_new(seq64be, frag);\n\t\tif (item == NULL)\n\t\t\t{\n\t\t\ti = -1;\n\t\t\tgoto err;\n\t\t\t}\n\n\t\titem = pqueue_insert(s->d1->buffered_messages, item);\n\t\t/* pqueue_insert fails iff a duplicate item is inserted.\n\t\t * However, |item| cannot be a duplicate. If it were,\n\t\t * |pqueue_find|, above, would have returned it and control\n\t\t * would never have reached this branch. */\n\t\tOPENSSL_assert(item != NULL);\n\t\t}\n\n\treturn DTLS1_HM_FRAGMENT_RETRY;\n\nerr:\n\tif (frag != NULL && item == NULL) dtls1_hm_fragment_free(frag);\n\t*ok = 0;\n\treturn i;\n\t}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -10,6 +10,9 @@\n \tif ((msg_hdr->frag_off+frag_len) > msg_hdr->msg_len ||\n \t    msg_hdr->msg_len > dtls1_max_handshake_message_len(s))\n \t\tgoto err;\n+\n+\tif (frag_len == 0)\n+\t\treturn DTLS1_HM_FRAGMENT_RETRY;\n \n \t/* Try to find item in queue */\n \tmemset(seq64be,0,sizeof(seq64be));\n@@ -88,7 +91,12 @@\n \t\t\tgoto err;\n \t\t\t}\n \n-\t\tpqueue_insert(s->d1->buffered_messages, item);\n+\t\titem = pqueue_insert(s->d1->buffered_messages, item);\n+\t\t/* pqueue_insert fails iff a duplicate item is inserted.\n+\t\t * However, |item| cannot be a duplicate. If it were,\n+\t\t * |pqueue_find|, above, would have returned it and control\n+\t\t * would never have reached this branch. */\n+\t\tOPENSSL_assert(item != NULL);\n \t\t}\n \n \treturn DTLS1_HM_FRAGMENT_RETRY;",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tpqueue_insert(s->d1->buffered_messages, item);"
            ],
            "added_lines": [
                "",
                "\tif (frag_len == 0)",
                "\t\treturn DTLS1_HM_FRAGMENT_RETRY;",
                "\t\titem = pqueue_insert(s->d1->buffered_messages, item);",
                "\t\t/* pqueue_insert fails iff a duplicate item is inserted.",
                "\t\t * However, |item| cannot be a duplicate. If it were,",
                "\t\t * |pqueue_find|, above, would have returned it and control",
                "\t\t * would never have reached this branch. */",
                "\t\tOPENSSL_assert(item != NULL);"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-5471",
        "func_name": "torvalds/linux/parse_rock_ridge_inode_internal",
        "description": "Stack consumption vulnerability in the parse_rock_ridge_inode_internal function in fs/isofs/rock.c in the Linux kernel through 3.16.1 allows local users to cause a denial of service (uncontrolled recursion, and system crash or reboot) via a crafted iso9660 image with a CL entry referring to a directory entry that has a CL entry.",
        "git_url": "https://github.com/torvalds/linux/commit/410dd3cf4c9b36f27ed4542ee18b1af5e68645a4",
        "commit_title": "isofs: Fix unbounded recursion when processing relocated directories",
        "commit_text": " We did not check relocated directory in any way when processing Rock Ridge 'CL' tag. Thus a corrupted isofs image can possibly have a CL entry pointing to another CL entry leading to possibly unbounded recursion in kernel code and thus stack overflow or deadlocks (if there is a loop created from CL entries).  Fix the problem by not allowing CL entry to point to a directory entry with CL entry (such use makes no good sense anyway) and by checking whether CL entry doesn't point to itself. ",
        "func_before": "static int\nparse_rock_ridge_inode_internal(struct iso_directory_record *de,\n\t\t\t\tstruct inode *inode, int regard_xa)\n{\n\tint symlink_len = 0;\n\tint cnt, sig;\n\tstruct inode *reloc;\n\tstruct rock_ridge *rr;\n\tint rootflag;\n\tstruct rock_state rs;\n\tint ret = 0;\n\n\tif (!ISOFS_SB(inode->i_sb)->s_rock)\n\t\treturn 0;\n\n\tinit_rock_state(&rs, inode);\n\tsetup_rock_ridge(de, inode, &rs);\n\tif (regard_xa) {\n\t\trs.chr += 14;\n\t\trs.len -= 14;\n\t\tif (rs.len < 0)\n\t\t\trs.len = 0;\n\t}\n\nrepeat:\n\twhile (rs.len > 2) { /* There may be one byte for padding somewhere */\n\t\trr = (struct rock_ridge *)rs.chr;\n\t\t/*\n\t\t * Ignore rock ridge info if rr->len is out of range, but\n\t\t * don't return -EIO because that would make the file\n\t\t * invisible.\n\t\t */\n\t\tif (rr->len < 3)\n\t\t\tgoto out;\t/* Something got screwed up here */\n\t\tsig = isonum_721(rs.chr);\n\t\tif (rock_check_overflow(&rs, sig))\n\t\t\tgoto eio;\n\t\trs.chr += rr->len;\n\t\trs.len -= rr->len;\n\t\t/*\n\t\t * As above, just ignore the rock ridge info if rr->len\n\t\t * is bogus.\n\t\t */\n\t\tif (rs.len < 0)\n\t\t\tgoto out;\t/* Something got screwed up here */\n\n\t\tswitch (sig) {\n#ifndef CONFIG_ZISOFS\t\t/* No flag for SF or ZF */\n\t\tcase SIG('R', 'R'):\n\t\t\tif ((rr->u.RR.flags[0] &\n\t\t\t     (RR_PX | RR_TF | RR_SL | RR_CL)) == 0)\n\t\t\t\tgoto out;\n\t\t\tbreak;\n#endif\n\t\tcase SIG('S', 'P'):\n\t\t\tif (check_sp(rr, inode))\n\t\t\t\tgoto out;\n\t\t\tbreak;\n\t\tcase SIG('C', 'E'):\n\t\t\trs.cont_extent = isonum_733(rr->u.CE.extent);\n\t\t\trs.cont_offset = isonum_733(rr->u.CE.offset);\n\t\t\trs.cont_size = isonum_733(rr->u.CE.size);\n\t\t\tbreak;\n\t\tcase SIG('E', 'R'):\n\t\t\tISOFS_SB(inode->i_sb)->s_rock = 1;\n\t\t\tprintk(KERN_DEBUG \"ISO 9660 Extensions: \");\n\t\t\t{\n\t\t\t\tint p;\n\t\t\t\tfor (p = 0; p < rr->u.ER.len_id; p++)\n\t\t\t\t\tprintk(\"%c\", rr->u.ER.data[p]);\n\t\t\t}\n\t\t\tprintk(\"\\n\");\n\t\t\tbreak;\n\t\tcase SIG('P', 'X'):\n\t\t\tinode->i_mode = isonum_733(rr->u.PX.mode);\n\t\t\tset_nlink(inode, isonum_733(rr->u.PX.n_links));\n\t\t\ti_uid_write(inode, isonum_733(rr->u.PX.uid));\n\t\t\ti_gid_write(inode, isonum_733(rr->u.PX.gid));\n\t\t\tbreak;\n\t\tcase SIG('P', 'N'):\n\t\t\t{\n\t\t\t\tint high, low;\n\t\t\t\thigh = isonum_733(rr->u.PN.dev_high);\n\t\t\t\tlow = isonum_733(rr->u.PN.dev_low);\n\t\t\t\t/*\n\t\t\t\t * The Rock Ridge standard specifies that if\n\t\t\t\t * sizeof(dev_t) <= 4, then the high field is\n\t\t\t\t * unused, and the device number is completely\n\t\t\t\t * stored in the low field.  Some writers may\n\t\t\t\t * ignore this subtlety,\n\t\t\t\t * and as a result we test to see if the entire\n\t\t\t\t * device number is\n\t\t\t\t * stored in the low field, and use that.\n\t\t\t\t */\n\t\t\t\tif ((low & ~0xff) && high == 0) {\n\t\t\t\t\tinode->i_rdev =\n\t\t\t\t\t    MKDEV(low >> 8, low & 0xff);\n\t\t\t\t} else {\n\t\t\t\t\tinode->i_rdev =\n\t\t\t\t\t    MKDEV(high, low);\n\t\t\t\t}\n\t\t\t}\n\t\t\tbreak;\n\t\tcase SIG('T', 'F'):\n\t\t\t/*\n\t\t\t * Some RRIP writers incorrectly place ctime in the\n\t\t\t * TF_CREATE field. Try to handle this correctly for\n\t\t\t * either case.\n\t\t\t */\n\t\t\t/* Rock ridge never appears on a High Sierra disk */\n\t\t\tcnt = 0;\n\t\t\tif (rr->u.TF.flags & TF_CREATE) {\n\t\t\t\tinode->i_ctime.tv_sec =\n\t\t\t\t    iso_date(rr->u.TF.times[cnt++].time,\n\t\t\t\t\t     0);\n\t\t\t\tinode->i_ctime.tv_nsec = 0;\n\t\t\t}\n\t\t\tif (rr->u.TF.flags & TF_MODIFY) {\n\t\t\t\tinode->i_mtime.tv_sec =\n\t\t\t\t    iso_date(rr->u.TF.times[cnt++].time,\n\t\t\t\t\t     0);\n\t\t\t\tinode->i_mtime.tv_nsec = 0;\n\t\t\t}\n\t\t\tif (rr->u.TF.flags & TF_ACCESS) {\n\t\t\t\tinode->i_atime.tv_sec =\n\t\t\t\t    iso_date(rr->u.TF.times[cnt++].time,\n\t\t\t\t\t     0);\n\t\t\t\tinode->i_atime.tv_nsec = 0;\n\t\t\t}\n\t\t\tif (rr->u.TF.flags & TF_ATTRIBUTES) {\n\t\t\t\tinode->i_ctime.tv_sec =\n\t\t\t\t    iso_date(rr->u.TF.times[cnt++].time,\n\t\t\t\t\t     0);\n\t\t\t\tinode->i_ctime.tv_nsec = 0;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase SIG('S', 'L'):\n\t\t\t{\n\t\t\t\tint slen;\n\t\t\t\tstruct SL_component *slp;\n\t\t\t\tstruct SL_component *oldslp;\n\t\t\t\tslen = rr->len - 5;\n\t\t\t\tslp = &rr->u.SL.link;\n\t\t\t\tinode->i_size = symlink_len;\n\t\t\t\twhile (slen > 1) {\n\t\t\t\t\trootflag = 0;\n\t\t\t\t\tswitch (slp->flags & ~1) {\n\t\t\t\t\tcase 0:\n\t\t\t\t\t\tinode->i_size +=\n\t\t\t\t\t\t    slp->len;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcase 2:\n\t\t\t\t\t\tinode->i_size += 1;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcase 4:\n\t\t\t\t\t\tinode->i_size += 2;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcase 8:\n\t\t\t\t\t\trootflag = 1;\n\t\t\t\t\t\tinode->i_size += 1;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tdefault:\n\t\t\t\t\t\tprintk(\"Symlink component flag \"\n\t\t\t\t\t\t\t\"not implemented\\n\");\n\t\t\t\t\t}\n\t\t\t\t\tslen -= slp->len + 2;\n\t\t\t\t\toldslp = slp;\n\t\t\t\t\tslp = (struct SL_component *)\n\t\t\t\t\t\t(((char *)slp) + slp->len + 2);\n\n\t\t\t\t\tif (slen < 2) {\n\t\t\t\t\t\tif (((rr->u.SL.\n\t\t\t\t\t\t      flags & 1) != 0)\n\t\t\t\t\t\t    &&\n\t\t\t\t\t\t    ((oldslp->\n\t\t\t\t\t\t      flags & 1) == 0))\n\t\t\t\t\t\t\tinode->i_size +=\n\t\t\t\t\t\t\t    1;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\n\t\t\t\t\t/*\n\t\t\t\t\t * If this component record isn't\n\t\t\t\t\t * continued, then append a '/'.\n\t\t\t\t\t */\n\t\t\t\t\tif (!rootflag\n\t\t\t\t\t    && (oldslp->flags & 1) == 0)\n\t\t\t\t\t\tinode->i_size += 1;\n\t\t\t\t}\n\t\t\t}\n\t\t\tsymlink_len = inode->i_size;\n\t\t\tbreak;\n\t\tcase SIG('R', 'E'):\n\t\t\tprintk(KERN_WARNING \"Attempt to read inode for \"\n\t\t\t\t\t\"relocated directory\\n\");\n\t\t\tgoto out;\n\t\tcase SIG('C', 'L'):\n\t\t\tISOFS_I(inode)->i_first_extent =\n\t\t\t    isonum_733(rr->u.CL.location);\n\t\t\treloc =\n\t\t\t    isofs_iget(inode->i_sb,\n\t\t\t\t       ISOFS_I(inode)->i_first_extent,\n\t\t\t\t       0);\n\t\t\tif (IS_ERR(reloc)) {\n\t\t\t\tret = PTR_ERR(reloc);\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tinode->i_mode = reloc->i_mode;\n\t\t\tset_nlink(inode, reloc->i_nlink);\n\t\t\tinode->i_uid = reloc->i_uid;\n\t\t\tinode->i_gid = reloc->i_gid;\n\t\t\tinode->i_rdev = reloc->i_rdev;\n\t\t\tinode->i_size = reloc->i_size;\n\t\t\tinode->i_blocks = reloc->i_blocks;\n\t\t\tinode->i_atime = reloc->i_atime;\n\t\t\tinode->i_ctime = reloc->i_ctime;\n\t\t\tinode->i_mtime = reloc->i_mtime;\n\t\t\tiput(reloc);\n\t\t\tbreak;\n#ifdef CONFIG_ZISOFS\n\t\tcase SIG('Z', 'F'): {\n\t\t\tint algo;\n\n\t\t\tif (ISOFS_SB(inode->i_sb)->s_nocompress)\n\t\t\t\tbreak;\n\t\t\talgo = isonum_721(rr->u.ZF.algorithm);\n\t\t\tif (algo == SIG('p', 'z')) {\n\t\t\t\tint block_shift =\n\t\t\t\t\tisonum_711(&rr->u.ZF.parms[1]);\n\t\t\t\tif (block_shift > 17) {\n\t\t\t\t\tprintk(KERN_WARNING \"isofs: \"\n\t\t\t\t\t\t\"Can't handle ZF block \"\n\t\t\t\t\t\t\"size of 2^%d\\n\",\n\t\t\t\t\t\tblock_shift);\n\t\t\t\t} else {\n\t\t\t\t\t/*\n\t\t\t\t\t * Note: we don't change\n\t\t\t\t\t * i_blocks here\n\t\t\t\t\t */\n\t\t\t\t\tISOFS_I(inode)->i_file_format =\n\t\t\t\t\t\tisofs_file_compressed;\n\t\t\t\t\t/*\n\t\t\t\t\t * Parameters to compression\n\t\t\t\t\t * algorithm (header size,\n\t\t\t\t\t * block size)\n\t\t\t\t\t */\n\t\t\t\t\tISOFS_I(inode)->i_format_parm[0] =\n\t\t\t\t\t\tisonum_711(&rr->u.ZF.parms[0]);\n\t\t\t\t\tISOFS_I(inode)->i_format_parm[1] =\n\t\t\t\t\t\tisonum_711(&rr->u.ZF.parms[1]);\n\t\t\t\t\tinode->i_size =\n\t\t\t\t\t    isonum_733(rr->u.ZF.\n\t\t\t\t\t\t       real_size);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tprintk(KERN_WARNING\n\t\t\t\t       \"isofs: Unknown ZF compression \"\n\t\t\t\t\t\t\"algorithm: %c%c\\n\",\n\t\t\t\t       rr->u.ZF.algorithm[0],\n\t\t\t\t       rr->u.ZF.algorithm[1]);\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n#endif\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\n\tret = rock_continue(&rs);\n\tif (ret == 0)\n\t\tgoto repeat;\n\tif (ret == 1)\n\t\tret = 0;\nout:\n\tkfree(rs.buffer);\n\treturn ret;\neio:\n\tret = -EIO;\n\tgoto out;\n}",
        "func": "static int\nparse_rock_ridge_inode_internal(struct iso_directory_record *de,\n\t\t\t\tstruct inode *inode, int flags)\n{\n\tint symlink_len = 0;\n\tint cnt, sig;\n\tunsigned int reloc_block;\n\tstruct inode *reloc;\n\tstruct rock_ridge *rr;\n\tint rootflag;\n\tstruct rock_state rs;\n\tint ret = 0;\n\n\tif (!ISOFS_SB(inode->i_sb)->s_rock)\n\t\treturn 0;\n\n\tinit_rock_state(&rs, inode);\n\tsetup_rock_ridge(de, inode, &rs);\n\tif (flags & RR_REGARD_XA) {\n\t\trs.chr += 14;\n\t\trs.len -= 14;\n\t\tif (rs.len < 0)\n\t\t\trs.len = 0;\n\t}\n\nrepeat:\n\twhile (rs.len > 2) { /* There may be one byte for padding somewhere */\n\t\trr = (struct rock_ridge *)rs.chr;\n\t\t/*\n\t\t * Ignore rock ridge info if rr->len is out of range, but\n\t\t * don't return -EIO because that would make the file\n\t\t * invisible.\n\t\t */\n\t\tif (rr->len < 3)\n\t\t\tgoto out;\t/* Something got screwed up here */\n\t\tsig = isonum_721(rs.chr);\n\t\tif (rock_check_overflow(&rs, sig))\n\t\t\tgoto eio;\n\t\trs.chr += rr->len;\n\t\trs.len -= rr->len;\n\t\t/*\n\t\t * As above, just ignore the rock ridge info if rr->len\n\t\t * is bogus.\n\t\t */\n\t\tif (rs.len < 0)\n\t\t\tgoto out;\t/* Something got screwed up here */\n\n\t\tswitch (sig) {\n#ifndef CONFIG_ZISOFS\t\t/* No flag for SF or ZF */\n\t\tcase SIG('R', 'R'):\n\t\t\tif ((rr->u.RR.flags[0] &\n\t\t\t     (RR_PX | RR_TF | RR_SL | RR_CL)) == 0)\n\t\t\t\tgoto out;\n\t\t\tbreak;\n#endif\n\t\tcase SIG('S', 'P'):\n\t\t\tif (check_sp(rr, inode))\n\t\t\t\tgoto out;\n\t\t\tbreak;\n\t\tcase SIG('C', 'E'):\n\t\t\trs.cont_extent = isonum_733(rr->u.CE.extent);\n\t\t\trs.cont_offset = isonum_733(rr->u.CE.offset);\n\t\t\trs.cont_size = isonum_733(rr->u.CE.size);\n\t\t\tbreak;\n\t\tcase SIG('E', 'R'):\n\t\t\tISOFS_SB(inode->i_sb)->s_rock = 1;\n\t\t\tprintk(KERN_DEBUG \"ISO 9660 Extensions: \");\n\t\t\t{\n\t\t\t\tint p;\n\t\t\t\tfor (p = 0; p < rr->u.ER.len_id; p++)\n\t\t\t\t\tprintk(\"%c\", rr->u.ER.data[p]);\n\t\t\t}\n\t\t\tprintk(\"\\n\");\n\t\t\tbreak;\n\t\tcase SIG('P', 'X'):\n\t\t\tinode->i_mode = isonum_733(rr->u.PX.mode);\n\t\t\tset_nlink(inode, isonum_733(rr->u.PX.n_links));\n\t\t\ti_uid_write(inode, isonum_733(rr->u.PX.uid));\n\t\t\ti_gid_write(inode, isonum_733(rr->u.PX.gid));\n\t\t\tbreak;\n\t\tcase SIG('P', 'N'):\n\t\t\t{\n\t\t\t\tint high, low;\n\t\t\t\thigh = isonum_733(rr->u.PN.dev_high);\n\t\t\t\tlow = isonum_733(rr->u.PN.dev_low);\n\t\t\t\t/*\n\t\t\t\t * The Rock Ridge standard specifies that if\n\t\t\t\t * sizeof(dev_t) <= 4, then the high field is\n\t\t\t\t * unused, and the device number is completely\n\t\t\t\t * stored in the low field.  Some writers may\n\t\t\t\t * ignore this subtlety,\n\t\t\t\t * and as a result we test to see if the entire\n\t\t\t\t * device number is\n\t\t\t\t * stored in the low field, and use that.\n\t\t\t\t */\n\t\t\t\tif ((low & ~0xff) && high == 0) {\n\t\t\t\t\tinode->i_rdev =\n\t\t\t\t\t    MKDEV(low >> 8, low & 0xff);\n\t\t\t\t} else {\n\t\t\t\t\tinode->i_rdev =\n\t\t\t\t\t    MKDEV(high, low);\n\t\t\t\t}\n\t\t\t}\n\t\t\tbreak;\n\t\tcase SIG('T', 'F'):\n\t\t\t/*\n\t\t\t * Some RRIP writers incorrectly place ctime in the\n\t\t\t * TF_CREATE field. Try to handle this correctly for\n\t\t\t * either case.\n\t\t\t */\n\t\t\t/* Rock ridge never appears on a High Sierra disk */\n\t\t\tcnt = 0;\n\t\t\tif (rr->u.TF.flags & TF_CREATE) {\n\t\t\t\tinode->i_ctime.tv_sec =\n\t\t\t\t    iso_date(rr->u.TF.times[cnt++].time,\n\t\t\t\t\t     0);\n\t\t\t\tinode->i_ctime.tv_nsec = 0;\n\t\t\t}\n\t\t\tif (rr->u.TF.flags & TF_MODIFY) {\n\t\t\t\tinode->i_mtime.tv_sec =\n\t\t\t\t    iso_date(rr->u.TF.times[cnt++].time,\n\t\t\t\t\t     0);\n\t\t\t\tinode->i_mtime.tv_nsec = 0;\n\t\t\t}\n\t\t\tif (rr->u.TF.flags & TF_ACCESS) {\n\t\t\t\tinode->i_atime.tv_sec =\n\t\t\t\t    iso_date(rr->u.TF.times[cnt++].time,\n\t\t\t\t\t     0);\n\t\t\t\tinode->i_atime.tv_nsec = 0;\n\t\t\t}\n\t\t\tif (rr->u.TF.flags & TF_ATTRIBUTES) {\n\t\t\t\tinode->i_ctime.tv_sec =\n\t\t\t\t    iso_date(rr->u.TF.times[cnt++].time,\n\t\t\t\t\t     0);\n\t\t\t\tinode->i_ctime.tv_nsec = 0;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase SIG('S', 'L'):\n\t\t\t{\n\t\t\t\tint slen;\n\t\t\t\tstruct SL_component *slp;\n\t\t\t\tstruct SL_component *oldslp;\n\t\t\t\tslen = rr->len - 5;\n\t\t\t\tslp = &rr->u.SL.link;\n\t\t\t\tinode->i_size = symlink_len;\n\t\t\t\twhile (slen > 1) {\n\t\t\t\t\trootflag = 0;\n\t\t\t\t\tswitch (slp->flags & ~1) {\n\t\t\t\t\tcase 0:\n\t\t\t\t\t\tinode->i_size +=\n\t\t\t\t\t\t    slp->len;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcase 2:\n\t\t\t\t\t\tinode->i_size += 1;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcase 4:\n\t\t\t\t\t\tinode->i_size += 2;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcase 8:\n\t\t\t\t\t\trootflag = 1;\n\t\t\t\t\t\tinode->i_size += 1;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tdefault:\n\t\t\t\t\t\tprintk(\"Symlink component flag \"\n\t\t\t\t\t\t\t\"not implemented\\n\");\n\t\t\t\t\t}\n\t\t\t\t\tslen -= slp->len + 2;\n\t\t\t\t\toldslp = slp;\n\t\t\t\t\tslp = (struct SL_component *)\n\t\t\t\t\t\t(((char *)slp) + slp->len + 2);\n\n\t\t\t\t\tif (slen < 2) {\n\t\t\t\t\t\tif (((rr->u.SL.\n\t\t\t\t\t\t      flags & 1) != 0)\n\t\t\t\t\t\t    &&\n\t\t\t\t\t\t    ((oldslp->\n\t\t\t\t\t\t      flags & 1) == 0))\n\t\t\t\t\t\t\tinode->i_size +=\n\t\t\t\t\t\t\t    1;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\n\t\t\t\t\t/*\n\t\t\t\t\t * If this component record isn't\n\t\t\t\t\t * continued, then append a '/'.\n\t\t\t\t\t */\n\t\t\t\t\tif (!rootflag\n\t\t\t\t\t    && (oldslp->flags & 1) == 0)\n\t\t\t\t\t\tinode->i_size += 1;\n\t\t\t\t}\n\t\t\t}\n\t\t\tsymlink_len = inode->i_size;\n\t\t\tbreak;\n\t\tcase SIG('R', 'E'):\n\t\t\tprintk(KERN_WARNING \"Attempt to read inode for \"\n\t\t\t\t\t\"relocated directory\\n\");\n\t\t\tgoto out;\n\t\tcase SIG('C', 'L'):\n\t\t\tif (flags & RR_RELOC_DE) {\n\t\t\t\tprintk(KERN_ERR\n\t\t\t\t       \"ISOFS: Recursive directory relocation \"\n\t\t\t\t       \"is not supported\\n\");\n\t\t\t\tgoto eio;\n\t\t\t}\n\t\t\treloc_block = isonum_733(rr->u.CL.location);\n\t\t\tif (reloc_block == ISOFS_I(inode)->i_iget5_block &&\n\t\t\t    ISOFS_I(inode)->i_iget5_offset == 0) {\n\t\t\t\tprintk(KERN_ERR\n\t\t\t\t       \"ISOFS: Directory relocation points to \"\n\t\t\t\t       \"itself\\n\");\n\t\t\t\tgoto eio;\n\t\t\t}\n\t\t\tISOFS_I(inode)->i_first_extent = reloc_block;\n\t\t\treloc = isofs_iget_reloc(inode->i_sb, reloc_block, 0);\n\t\t\tif (IS_ERR(reloc)) {\n\t\t\t\tret = PTR_ERR(reloc);\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tinode->i_mode = reloc->i_mode;\n\t\t\tset_nlink(inode, reloc->i_nlink);\n\t\t\tinode->i_uid = reloc->i_uid;\n\t\t\tinode->i_gid = reloc->i_gid;\n\t\t\tinode->i_rdev = reloc->i_rdev;\n\t\t\tinode->i_size = reloc->i_size;\n\t\t\tinode->i_blocks = reloc->i_blocks;\n\t\t\tinode->i_atime = reloc->i_atime;\n\t\t\tinode->i_ctime = reloc->i_ctime;\n\t\t\tinode->i_mtime = reloc->i_mtime;\n\t\t\tiput(reloc);\n\t\t\tbreak;\n#ifdef CONFIG_ZISOFS\n\t\tcase SIG('Z', 'F'): {\n\t\t\tint algo;\n\n\t\t\tif (ISOFS_SB(inode->i_sb)->s_nocompress)\n\t\t\t\tbreak;\n\t\t\talgo = isonum_721(rr->u.ZF.algorithm);\n\t\t\tif (algo == SIG('p', 'z')) {\n\t\t\t\tint block_shift =\n\t\t\t\t\tisonum_711(&rr->u.ZF.parms[1]);\n\t\t\t\tif (block_shift > 17) {\n\t\t\t\t\tprintk(KERN_WARNING \"isofs: \"\n\t\t\t\t\t\t\"Can't handle ZF block \"\n\t\t\t\t\t\t\"size of 2^%d\\n\",\n\t\t\t\t\t\tblock_shift);\n\t\t\t\t} else {\n\t\t\t\t\t/*\n\t\t\t\t\t * Note: we don't change\n\t\t\t\t\t * i_blocks here\n\t\t\t\t\t */\n\t\t\t\t\tISOFS_I(inode)->i_file_format =\n\t\t\t\t\t\tisofs_file_compressed;\n\t\t\t\t\t/*\n\t\t\t\t\t * Parameters to compression\n\t\t\t\t\t * algorithm (header size,\n\t\t\t\t\t * block size)\n\t\t\t\t\t */\n\t\t\t\t\tISOFS_I(inode)->i_format_parm[0] =\n\t\t\t\t\t\tisonum_711(&rr->u.ZF.parms[0]);\n\t\t\t\t\tISOFS_I(inode)->i_format_parm[1] =\n\t\t\t\t\t\tisonum_711(&rr->u.ZF.parms[1]);\n\t\t\t\t\tinode->i_size =\n\t\t\t\t\t    isonum_733(rr->u.ZF.\n\t\t\t\t\t\t       real_size);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tprintk(KERN_WARNING\n\t\t\t\t       \"isofs: Unknown ZF compression \"\n\t\t\t\t\t\t\"algorithm: %c%c\\n\",\n\t\t\t\t       rr->u.ZF.algorithm[0],\n\t\t\t\t       rr->u.ZF.algorithm[1]);\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n#endif\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\n\tret = rock_continue(&rs);\n\tif (ret == 0)\n\t\tgoto repeat;\n\tif (ret == 1)\n\t\tret = 0;\nout:\n\tkfree(rs.buffer);\n\treturn ret;\neio:\n\tret = -EIO;\n\tgoto out;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,9 +1,10 @@\n static int\n parse_rock_ridge_inode_internal(struct iso_directory_record *de,\n-\t\t\t\tstruct inode *inode, int regard_xa)\n+\t\t\t\tstruct inode *inode, int flags)\n {\n \tint symlink_len = 0;\n \tint cnt, sig;\n+\tunsigned int reloc_block;\n \tstruct inode *reloc;\n \tstruct rock_ridge *rr;\n \tint rootflag;\n@@ -15,7 +16,7 @@\n \n \tinit_rock_state(&rs, inode);\n \tsetup_rock_ridge(de, inode, &rs);\n-\tif (regard_xa) {\n+\tif (flags & RR_REGARD_XA) {\n \t\trs.chr += 14;\n \t\trs.len -= 14;\n \t\tif (rs.len < 0)\n@@ -195,12 +196,22 @@\n \t\t\t\t\t\"relocated directory\\n\");\n \t\t\tgoto out;\n \t\tcase SIG('C', 'L'):\n-\t\t\tISOFS_I(inode)->i_first_extent =\n-\t\t\t    isonum_733(rr->u.CL.location);\n-\t\t\treloc =\n-\t\t\t    isofs_iget(inode->i_sb,\n-\t\t\t\t       ISOFS_I(inode)->i_first_extent,\n-\t\t\t\t       0);\n+\t\t\tif (flags & RR_RELOC_DE) {\n+\t\t\t\tprintk(KERN_ERR\n+\t\t\t\t       \"ISOFS: Recursive directory relocation \"\n+\t\t\t\t       \"is not supported\\n\");\n+\t\t\t\tgoto eio;\n+\t\t\t}\n+\t\t\treloc_block = isonum_733(rr->u.CL.location);\n+\t\t\tif (reloc_block == ISOFS_I(inode)->i_iget5_block &&\n+\t\t\t    ISOFS_I(inode)->i_iget5_offset == 0) {\n+\t\t\t\tprintk(KERN_ERR\n+\t\t\t\t       \"ISOFS: Directory relocation points to \"\n+\t\t\t\t       \"itself\\n\");\n+\t\t\t\tgoto eio;\n+\t\t\t}\n+\t\t\tISOFS_I(inode)->i_first_extent = reloc_block;\n+\t\t\treloc = isofs_iget_reloc(inode->i_sb, reloc_block, 0);\n \t\t\tif (IS_ERR(reloc)) {\n \t\t\t\tret = PTR_ERR(reloc);\n \t\t\t\tgoto out;",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\t\tstruct inode *inode, int regard_xa)",
                "\tif (regard_xa) {",
                "\t\t\tISOFS_I(inode)->i_first_extent =",
                "\t\t\t    isonum_733(rr->u.CL.location);",
                "\t\t\treloc =",
                "\t\t\t    isofs_iget(inode->i_sb,",
                "\t\t\t\t       ISOFS_I(inode)->i_first_extent,",
                "\t\t\t\t       0);"
            ],
            "added_lines": [
                "\t\t\t\tstruct inode *inode, int flags)",
                "\tunsigned int reloc_block;",
                "\tif (flags & RR_REGARD_XA) {",
                "\t\t\tif (flags & RR_RELOC_DE) {",
                "\t\t\t\tprintk(KERN_ERR",
                "\t\t\t\t       \"ISOFS: Recursive directory relocation \"",
                "\t\t\t\t       \"is not supported\\n\");",
                "\t\t\t\tgoto eio;",
                "\t\t\t}",
                "\t\t\treloc_block = isonum_733(rr->u.CL.location);",
                "\t\t\tif (reloc_block == ISOFS_I(inode)->i_iget5_block &&",
                "\t\t\t    ISOFS_I(inode)->i_iget5_offset == 0) {",
                "\t\t\t\tprintk(KERN_ERR",
                "\t\t\t\t       \"ISOFS: Directory relocation points to \"",
                "\t\t\t\t       \"itself\\n\");",
                "\t\t\t\tgoto eio;",
                "\t\t\t}",
                "\t\t\tISOFS_I(inode)->i_first_extent = reloc_block;",
                "\t\t\treloc = isofs_iget_reloc(inode->i_sb, reloc_block, 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-5471",
        "func_name": "torvalds/linux/parse_rock_ridge_inode",
        "description": "Stack consumption vulnerability in the parse_rock_ridge_inode_internal function in fs/isofs/rock.c in the Linux kernel through 3.16.1 allows local users to cause a denial of service (uncontrolled recursion, and system crash or reboot) via a crafted iso9660 image with a CL entry referring to a directory entry that has a CL entry.",
        "git_url": "https://github.com/torvalds/linux/commit/410dd3cf4c9b36f27ed4542ee18b1af5e68645a4",
        "commit_title": "isofs: Fix unbounded recursion when processing relocated directories",
        "commit_text": " We did not check relocated directory in any way when processing Rock Ridge 'CL' tag. Thus a corrupted isofs image can possibly have a CL entry pointing to another CL entry leading to possibly unbounded recursion in kernel code and thus stack overflow or deadlocks (if there is a loop created from CL entries).  Fix the problem by not allowing CL entry to point to a directory entry with CL entry (such use makes no good sense anyway) and by checking whether CL entry doesn't point to itself. ",
        "func_before": "int parse_rock_ridge_inode(struct iso_directory_record *de, struct inode *inode)\n{\n\tint result = parse_rock_ridge_inode_internal(de, inode, 0);\n\n\t/*\n\t * if rockridge flag was reset and we didn't look for attributes\n\t * behind eventual XA attributes, have a look there\n\t */\n\tif ((ISOFS_SB(inode->i_sb)->s_rock_offset == -1)\n\t    && (ISOFS_SB(inode->i_sb)->s_rock == 2)) {\n\t\tresult = parse_rock_ridge_inode_internal(de, inode, 14);\n\t}\n\treturn result;\n}",
        "func": "int parse_rock_ridge_inode(struct iso_directory_record *de, struct inode *inode,\n\t\t\t   int relocated)\n{\n\tint flags = relocated ? RR_RELOC_DE : 0;\n\tint result = parse_rock_ridge_inode_internal(de, inode, flags);\n\n\t/*\n\t * if rockridge flag was reset and we didn't look for attributes\n\t * behind eventual XA attributes, have a look there\n\t */\n\tif ((ISOFS_SB(inode->i_sb)->s_rock_offset == -1)\n\t    && (ISOFS_SB(inode->i_sb)->s_rock == 2)) {\n\t\tresult = parse_rock_ridge_inode_internal(de, inode,\n\t\t\t\t\t\t\t flags | RR_REGARD_XA);\n\t}\n\treturn result;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,8 @@\n-int parse_rock_ridge_inode(struct iso_directory_record *de, struct inode *inode)\n+int parse_rock_ridge_inode(struct iso_directory_record *de, struct inode *inode,\n+\t\t\t   int relocated)\n {\n-\tint result = parse_rock_ridge_inode_internal(de, inode, 0);\n+\tint flags = relocated ? RR_RELOC_DE : 0;\n+\tint result = parse_rock_ridge_inode_internal(de, inode, flags);\n \n \t/*\n \t * if rockridge flag was reset and we didn't look for attributes\n@@ -8,7 +10,8 @@\n \t */\n \tif ((ISOFS_SB(inode->i_sb)->s_rock_offset == -1)\n \t    && (ISOFS_SB(inode->i_sb)->s_rock == 2)) {\n-\t\tresult = parse_rock_ridge_inode_internal(de, inode, 14);\n+\t\tresult = parse_rock_ridge_inode_internal(de, inode,\n+\t\t\t\t\t\t\t flags | RR_REGARD_XA);\n \t}\n \treturn result;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "int parse_rock_ridge_inode(struct iso_directory_record *de, struct inode *inode)",
                "\tint result = parse_rock_ridge_inode_internal(de, inode, 0);",
                "\t\tresult = parse_rock_ridge_inode_internal(de, inode, 14);"
            ],
            "added_lines": [
                "int parse_rock_ridge_inode(struct iso_directory_record *de, struct inode *inode,",
                "\t\t\t   int relocated)",
                "\tint flags = relocated ? RR_RELOC_DE : 0;",
                "\tint result = parse_rock_ridge_inode_internal(de, inode, flags);",
                "\t\tresult = parse_rock_ridge_inode_internal(de, inode,",
                "\t\t\t\t\t\t\t flags | RR_REGARD_XA);"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-5471",
        "func_name": "torvalds/linux/isofs_read_inode",
        "description": "Stack consumption vulnerability in the parse_rock_ridge_inode_internal function in fs/isofs/rock.c in the Linux kernel through 3.16.1 allows local users to cause a denial of service (uncontrolled recursion, and system crash or reboot) via a crafted iso9660 image with a CL entry referring to a directory entry that has a CL entry.",
        "git_url": "https://github.com/torvalds/linux/commit/410dd3cf4c9b36f27ed4542ee18b1af5e68645a4",
        "commit_title": "isofs: Fix unbounded recursion when processing relocated directories",
        "commit_text": " We did not check relocated directory in any way when processing Rock Ridge 'CL' tag. Thus a corrupted isofs image can possibly have a CL entry pointing to another CL entry leading to possibly unbounded recursion in kernel code and thus stack overflow or deadlocks (if there is a loop created from CL entries).  Fix the problem by not allowing CL entry to point to a directory entry with CL entry (such use makes no good sense anyway) and by checking whether CL entry doesn't point to itself. ",
        "func_before": "static int isofs_read_inode(struct inode *inode)\n{\n\tstruct super_block *sb = inode->i_sb;\n\tstruct isofs_sb_info *sbi = ISOFS_SB(sb);\n\tunsigned long bufsize = ISOFS_BUFFER_SIZE(inode);\n\tunsigned long block;\n\tint high_sierra = sbi->s_high_sierra;\n\tstruct buffer_head *bh = NULL;\n\tstruct iso_directory_record *de;\n\tstruct iso_directory_record *tmpde = NULL;\n\tunsigned int de_len;\n\tunsigned long offset;\n\tstruct iso_inode_info *ei = ISOFS_I(inode);\n\tint ret = -EIO;\n\n\tblock = ei->i_iget5_block;\n\tbh = sb_bread(inode->i_sb, block);\n\tif (!bh)\n\t\tgoto out_badread;\n\n\toffset = ei->i_iget5_offset;\n\n\tde = (struct iso_directory_record *) (bh->b_data + offset);\n\tde_len = *(unsigned char *) de;\n\n\tif (offset + de_len > bufsize) {\n\t\tint frag1 = bufsize - offset;\n\n\t\ttmpde = kmalloc(de_len, GFP_KERNEL);\n\t\tif (tmpde == NULL) {\n\t\t\tprintk(KERN_INFO \"%s: out of memory\\n\", __func__);\n\t\t\tret = -ENOMEM;\n\t\t\tgoto fail;\n\t\t}\n\t\tmemcpy(tmpde, bh->b_data + offset, frag1);\n\t\tbrelse(bh);\n\t\tbh = sb_bread(inode->i_sb, ++block);\n\t\tif (!bh)\n\t\t\tgoto out_badread;\n\t\tmemcpy((char *)tmpde+frag1, bh->b_data, de_len - frag1);\n\t\tde = tmpde;\n\t}\n\n\tinode->i_ino = isofs_get_ino(ei->i_iget5_block,\n\t\t\t\t\tei->i_iget5_offset,\n\t\t\t\t\tISOFS_BUFFER_BITS(inode));\n\n\t/* Assume it is a normal-format file unless told otherwise */\n\tei->i_file_format = isofs_file_normal;\n\n\tif (de->flags[-high_sierra] & 2) {\n\t\tif (sbi->s_dmode != ISOFS_INVALID_MODE)\n\t\t\tinode->i_mode = S_IFDIR | sbi->s_dmode;\n\t\telse\n\t\t\tinode->i_mode = S_IFDIR | S_IRUGO | S_IXUGO;\n\t\tset_nlink(inode, 1);\t/*\n\t\t\t\t\t * Set to 1.  We know there are 2, but\n\t\t\t\t\t * the find utility tries to optimize\n\t\t\t\t\t * if it is 2, and it screws up.  It is\n\t\t\t\t\t * easier to give 1 which tells find to\n\t\t\t\t\t * do it the hard way.\n\t\t\t\t\t */\n\t} else {\n\t\tif (sbi->s_fmode != ISOFS_INVALID_MODE) {\n\t\t\tinode->i_mode = S_IFREG | sbi->s_fmode;\n\t\t} else {\n\t\t\t/*\n\t\t\t * Set default permissions: r-x for all.  The disc\n\t\t\t * could be shared with DOS machines so virtually\n\t\t\t * anything could be a valid executable.\n\t\t\t */\n\t\t\tinode->i_mode = S_IFREG | S_IRUGO | S_IXUGO;\n\t\t}\n\t\tset_nlink(inode, 1);\n\t}\n\tinode->i_uid = sbi->s_uid;\n\tinode->i_gid = sbi->s_gid;\n\tinode->i_blocks = 0;\n\n\tei->i_format_parm[0] = 0;\n\tei->i_format_parm[1] = 0;\n\tei->i_format_parm[2] = 0;\n\n\tei->i_section_size = isonum_733(de->size);\n\tif (de->flags[-high_sierra] & 0x80) {\n\t\tret = isofs_read_level3_size(inode);\n\t\tif (ret < 0)\n\t\t\tgoto fail;\n\t\tret = -EIO;\n\t} else {\n\t\tei->i_next_section_block = 0;\n\t\tei->i_next_section_offset = 0;\n\t\tinode->i_size = isonum_733(de->size);\n\t}\n\n\t/*\n\t * Some dipshit decided to store some other bit of information\n\t * in the high byte of the file length.  Truncate size in case\n\t * this CDROM was mounted with the cruft option.\n\t */\n\n\tif (sbi->s_cruft)\n\t\tinode->i_size &= 0x00ffffff;\n\n\tif (de->interleave[0]) {\n\t\tprintk(KERN_DEBUG \"ISOFS: Interleaved files not (yet) supported.\\n\");\n\t\tinode->i_size = 0;\n\t}\n\n\t/* I have no idea what file_unit_size is used for, so\n\t   we will flag it for now */\n\tif (de->file_unit_size[0] != 0) {\n\t\tprintk(KERN_DEBUG \"ISOFS: File unit size != 0 for ISO file (%ld).\\n\",\n\t\t\tinode->i_ino);\n\t}\n\n\t/* I have no idea what other flag bits are used for, so\n\t   we will flag it for now */\n#ifdef DEBUG\n\tif((de->flags[-high_sierra] & ~2)!= 0){\n\t\tprintk(KERN_DEBUG \"ISOFS: Unusual flag settings for ISO file \"\n\t\t\t\t\"(%ld %x).\\n\",\n\t\t\tinode->i_ino, de->flags[-high_sierra]);\n\t}\n#endif\n\n\tinode->i_mtime.tv_sec =\n\tinode->i_atime.tv_sec =\n\tinode->i_ctime.tv_sec = iso_date(de->date, high_sierra);\n\tinode->i_mtime.tv_nsec =\n\tinode->i_atime.tv_nsec =\n\tinode->i_ctime.tv_nsec = 0;\n\n\tei->i_first_extent = (isonum_733(de->extent) +\n\t\t\tisonum_711(de->ext_attr_length));\n\n\t/* Set the number of blocks for stat() - should be done before RR */\n\tinode->i_blocks = (inode->i_size + 511) >> 9;\n\n\t/*\n\t * Now test for possible Rock Ridge extensions which will override\n\t * some of these numbers in the inode structure.\n\t */\n\n\tif (!high_sierra) {\n\t\tparse_rock_ridge_inode(de, inode);\n\t\t/* if we want uid/gid set, override the rock ridge setting */\n\t\tif (sbi->s_uid_set)\n\t\t\tinode->i_uid = sbi->s_uid;\n\t\tif (sbi->s_gid_set)\n\t\t\tinode->i_gid = sbi->s_gid;\n\t}\n\t/* Now set final access rights if overriding rock ridge setting */\n\tif (S_ISDIR(inode->i_mode) && sbi->s_overriderockperm &&\n\t    sbi->s_dmode != ISOFS_INVALID_MODE)\n\t\tinode->i_mode = S_IFDIR | sbi->s_dmode;\n\tif (S_ISREG(inode->i_mode) && sbi->s_overriderockperm &&\n\t    sbi->s_fmode != ISOFS_INVALID_MODE)\n\t\tinode->i_mode = S_IFREG | sbi->s_fmode;\n\n\t/* Install the inode operations vector */\n\tif (S_ISREG(inode->i_mode)) {\n\t\tinode->i_fop = &generic_ro_fops;\n\t\tswitch (ei->i_file_format) {\n#ifdef CONFIG_ZISOFS\n\t\tcase isofs_file_compressed:\n\t\t\tinode->i_data.a_ops = &zisofs_aops;\n\t\t\tbreak;\n#endif\n\t\tdefault:\n\t\t\tinode->i_data.a_ops = &isofs_aops;\n\t\t\tbreak;\n\t\t}\n\t} else if (S_ISDIR(inode->i_mode)) {\n\t\tinode->i_op = &isofs_dir_inode_operations;\n\t\tinode->i_fop = &isofs_dir_operations;\n\t} else if (S_ISLNK(inode->i_mode)) {\n\t\tinode->i_op = &page_symlink_inode_operations;\n\t\tinode->i_data.a_ops = &isofs_symlink_aops;\n\t} else\n\t\t/* XXX - parse_rock_ridge_inode() had already set i_rdev. */\n\t\tinit_special_inode(inode, inode->i_mode, inode->i_rdev);\n\n\tret = 0;\nout:\n\tkfree(tmpde);\n\tif (bh)\n\t\tbrelse(bh);\n\treturn ret;\n\nout_badread:\n\tprintk(KERN_WARNING \"ISOFS: unable to read i-node block\\n\");\nfail:\n\tgoto out;\n}",
        "func": "static int isofs_read_inode(struct inode *inode, int relocated)\n{\n\tstruct super_block *sb = inode->i_sb;\n\tstruct isofs_sb_info *sbi = ISOFS_SB(sb);\n\tunsigned long bufsize = ISOFS_BUFFER_SIZE(inode);\n\tunsigned long block;\n\tint high_sierra = sbi->s_high_sierra;\n\tstruct buffer_head *bh = NULL;\n\tstruct iso_directory_record *de;\n\tstruct iso_directory_record *tmpde = NULL;\n\tunsigned int de_len;\n\tunsigned long offset;\n\tstruct iso_inode_info *ei = ISOFS_I(inode);\n\tint ret = -EIO;\n\n\tblock = ei->i_iget5_block;\n\tbh = sb_bread(inode->i_sb, block);\n\tif (!bh)\n\t\tgoto out_badread;\n\n\toffset = ei->i_iget5_offset;\n\n\tde = (struct iso_directory_record *) (bh->b_data + offset);\n\tde_len = *(unsigned char *) de;\n\n\tif (offset + de_len > bufsize) {\n\t\tint frag1 = bufsize - offset;\n\n\t\ttmpde = kmalloc(de_len, GFP_KERNEL);\n\t\tif (tmpde == NULL) {\n\t\t\tprintk(KERN_INFO \"%s: out of memory\\n\", __func__);\n\t\t\tret = -ENOMEM;\n\t\t\tgoto fail;\n\t\t}\n\t\tmemcpy(tmpde, bh->b_data + offset, frag1);\n\t\tbrelse(bh);\n\t\tbh = sb_bread(inode->i_sb, ++block);\n\t\tif (!bh)\n\t\t\tgoto out_badread;\n\t\tmemcpy((char *)tmpde+frag1, bh->b_data, de_len - frag1);\n\t\tde = tmpde;\n\t}\n\n\tinode->i_ino = isofs_get_ino(ei->i_iget5_block,\n\t\t\t\t\tei->i_iget5_offset,\n\t\t\t\t\tISOFS_BUFFER_BITS(inode));\n\n\t/* Assume it is a normal-format file unless told otherwise */\n\tei->i_file_format = isofs_file_normal;\n\n\tif (de->flags[-high_sierra] & 2) {\n\t\tif (sbi->s_dmode != ISOFS_INVALID_MODE)\n\t\t\tinode->i_mode = S_IFDIR | sbi->s_dmode;\n\t\telse\n\t\t\tinode->i_mode = S_IFDIR | S_IRUGO | S_IXUGO;\n\t\tset_nlink(inode, 1);\t/*\n\t\t\t\t\t * Set to 1.  We know there are 2, but\n\t\t\t\t\t * the find utility tries to optimize\n\t\t\t\t\t * if it is 2, and it screws up.  It is\n\t\t\t\t\t * easier to give 1 which tells find to\n\t\t\t\t\t * do it the hard way.\n\t\t\t\t\t */\n\t} else {\n\t\tif (sbi->s_fmode != ISOFS_INVALID_MODE) {\n\t\t\tinode->i_mode = S_IFREG | sbi->s_fmode;\n\t\t} else {\n\t\t\t/*\n\t\t\t * Set default permissions: r-x for all.  The disc\n\t\t\t * could be shared with DOS machines so virtually\n\t\t\t * anything could be a valid executable.\n\t\t\t */\n\t\t\tinode->i_mode = S_IFREG | S_IRUGO | S_IXUGO;\n\t\t}\n\t\tset_nlink(inode, 1);\n\t}\n\tinode->i_uid = sbi->s_uid;\n\tinode->i_gid = sbi->s_gid;\n\tinode->i_blocks = 0;\n\n\tei->i_format_parm[0] = 0;\n\tei->i_format_parm[1] = 0;\n\tei->i_format_parm[2] = 0;\n\n\tei->i_section_size = isonum_733(de->size);\n\tif (de->flags[-high_sierra] & 0x80) {\n\t\tret = isofs_read_level3_size(inode);\n\t\tif (ret < 0)\n\t\t\tgoto fail;\n\t\tret = -EIO;\n\t} else {\n\t\tei->i_next_section_block = 0;\n\t\tei->i_next_section_offset = 0;\n\t\tinode->i_size = isonum_733(de->size);\n\t}\n\n\t/*\n\t * Some dipshit decided to store some other bit of information\n\t * in the high byte of the file length.  Truncate size in case\n\t * this CDROM was mounted with the cruft option.\n\t */\n\n\tif (sbi->s_cruft)\n\t\tinode->i_size &= 0x00ffffff;\n\n\tif (de->interleave[0]) {\n\t\tprintk(KERN_DEBUG \"ISOFS: Interleaved files not (yet) supported.\\n\");\n\t\tinode->i_size = 0;\n\t}\n\n\t/* I have no idea what file_unit_size is used for, so\n\t   we will flag it for now */\n\tif (de->file_unit_size[0] != 0) {\n\t\tprintk(KERN_DEBUG \"ISOFS: File unit size != 0 for ISO file (%ld).\\n\",\n\t\t\tinode->i_ino);\n\t}\n\n\t/* I have no idea what other flag bits are used for, so\n\t   we will flag it for now */\n#ifdef DEBUG\n\tif((de->flags[-high_sierra] & ~2)!= 0){\n\t\tprintk(KERN_DEBUG \"ISOFS: Unusual flag settings for ISO file \"\n\t\t\t\t\"(%ld %x).\\n\",\n\t\t\tinode->i_ino, de->flags[-high_sierra]);\n\t}\n#endif\n\n\tinode->i_mtime.tv_sec =\n\tinode->i_atime.tv_sec =\n\tinode->i_ctime.tv_sec = iso_date(de->date, high_sierra);\n\tinode->i_mtime.tv_nsec =\n\tinode->i_atime.tv_nsec =\n\tinode->i_ctime.tv_nsec = 0;\n\n\tei->i_first_extent = (isonum_733(de->extent) +\n\t\t\tisonum_711(de->ext_attr_length));\n\n\t/* Set the number of blocks for stat() - should be done before RR */\n\tinode->i_blocks = (inode->i_size + 511) >> 9;\n\n\t/*\n\t * Now test for possible Rock Ridge extensions which will override\n\t * some of these numbers in the inode structure.\n\t */\n\n\tif (!high_sierra) {\n\t\tparse_rock_ridge_inode(de, inode, relocated);\n\t\t/* if we want uid/gid set, override the rock ridge setting */\n\t\tif (sbi->s_uid_set)\n\t\t\tinode->i_uid = sbi->s_uid;\n\t\tif (sbi->s_gid_set)\n\t\t\tinode->i_gid = sbi->s_gid;\n\t}\n\t/* Now set final access rights if overriding rock ridge setting */\n\tif (S_ISDIR(inode->i_mode) && sbi->s_overriderockperm &&\n\t    sbi->s_dmode != ISOFS_INVALID_MODE)\n\t\tinode->i_mode = S_IFDIR | sbi->s_dmode;\n\tif (S_ISREG(inode->i_mode) && sbi->s_overriderockperm &&\n\t    sbi->s_fmode != ISOFS_INVALID_MODE)\n\t\tinode->i_mode = S_IFREG | sbi->s_fmode;\n\n\t/* Install the inode operations vector */\n\tif (S_ISREG(inode->i_mode)) {\n\t\tinode->i_fop = &generic_ro_fops;\n\t\tswitch (ei->i_file_format) {\n#ifdef CONFIG_ZISOFS\n\t\tcase isofs_file_compressed:\n\t\t\tinode->i_data.a_ops = &zisofs_aops;\n\t\t\tbreak;\n#endif\n\t\tdefault:\n\t\t\tinode->i_data.a_ops = &isofs_aops;\n\t\t\tbreak;\n\t\t}\n\t} else if (S_ISDIR(inode->i_mode)) {\n\t\tinode->i_op = &isofs_dir_inode_operations;\n\t\tinode->i_fop = &isofs_dir_operations;\n\t} else if (S_ISLNK(inode->i_mode)) {\n\t\tinode->i_op = &page_symlink_inode_operations;\n\t\tinode->i_data.a_ops = &isofs_symlink_aops;\n\t} else\n\t\t/* XXX - parse_rock_ridge_inode() had already set i_rdev. */\n\t\tinit_special_inode(inode, inode->i_mode, inode->i_rdev);\n\n\tret = 0;\nout:\n\tkfree(tmpde);\n\tif (bh)\n\t\tbrelse(bh);\n\treturn ret;\n\nout_badread:\n\tprintk(KERN_WARNING \"ISOFS: unable to read i-node block\\n\");\nfail:\n\tgoto out;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,4 +1,4 @@\n-static int isofs_read_inode(struct inode *inode)\n+static int isofs_read_inode(struct inode *inode, int relocated)\n {\n \tstruct super_block *sb = inode->i_sb;\n \tstruct isofs_sb_info *sbi = ISOFS_SB(sb);\n@@ -143,7 +143,7 @@\n \t */\n \n \tif (!high_sierra) {\n-\t\tparse_rock_ridge_inode(de, inode);\n+\t\tparse_rock_ridge_inode(de, inode, relocated);\n \t\t/* if we want uid/gid set, override the rock ridge setting */\n \t\tif (sbi->s_uid_set)\n \t\t\tinode->i_uid = sbi->s_uid;",
        "diff_line_info": {
            "deleted_lines": [
                "static int isofs_read_inode(struct inode *inode)",
                "\t\tparse_rock_ridge_inode(de, inode);"
            ],
            "added_lines": [
                "static int isofs_read_inode(struct inode *inode, int relocated)",
                "\t\tparse_rock_ridge_inode(de, inode, relocated);"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-6423",
        "func_name": "wireshark/tvb_raw_text_add",
        "description": "The tvb_raw_text_add function in epan/dissectors/packet-megaco.c in the MEGACO dissector in Wireshark 1.10.x before 1.10.10 and 1.12.x before 1.12.1 allows remote attackers to cause a denial of service (infinite loop) via an empty line.",
        "git_url": "https://github.com/wireshark/wireshark/commit/9112a099d7cc2cd924b7c667bf27f6e112b970c6",
        "commit_title": "Fix an infinite loop when the line has no length",
        "commit_text": " Bug:10333",
        "func_before": "static void tvb_raw_text_add(tvbuff_t *tvb, proto_tree *tree){\n\n    gint tvb_linebegin,tvb_lineend,tvb_len,linelen;\n\n    tvb_linebegin = 0;\n    tvb_len = tvb_reported_length(tvb);\n\n    proto_tree_add_text(tree, tvb, 0, -1,\"-------------- (RAW text output) ---------------\");\n\n    do {\n        linelen = tvb_find_line_end(tvb,tvb_linebegin,-1,&tvb_lineend,FALSE);\n        proto_tree_add_text(tree, tvb, tvb_linebegin, linelen,\n                            \"%s\", tvb_format_text_wsp(tvb,tvb_linebegin,\n                                                      linelen));\n        tvb_linebegin = tvb_lineend;\n    } while ( tvb_lineend < tvb_len );\n}",
        "func": "static void tvb_raw_text_add(tvbuff_t *tvb, proto_tree *tree){\n\n    gint tvb_linebegin,tvb_lineend,tvb_len,linelen;\n\n    tvb_linebegin = 0;\n    tvb_len = tvb_reported_length(tvb);\n\n    proto_tree_add_text(tree, tvb, 0, -1,\"-------------- (RAW text output) ---------------\");\n\n    do {\n        linelen = tvb_find_line_end(tvb,tvb_linebegin,-1,&tvb_lineend,FALSE);\n        proto_tree_add_text(tree, tvb, tvb_linebegin, linelen,\n                            \"%s\", tvb_format_text_wsp(tvb,tvb_linebegin,\n                                                      linelen));\n        tvb_linebegin = tvb_lineend;\n    } while ( tvb_lineend < tvb_len && linelen > 0);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -13,5 +13,5 @@\n                             \"%s\", tvb_format_text_wsp(tvb,tvb_linebegin,\n                                                       linelen));\n         tvb_linebegin = tvb_lineend;\n-    } while ( tvb_lineend < tvb_len );\n+    } while ( tvb_lineend < tvb_len && linelen > 0);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    } while ( tvb_lineend < tvb_len );"
            ],
            "added_lines": [
                "    } while ( tvb_lineend < tvb_len && linelen > 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-6426",
        "func_name": "wireshark/dissect_hip_tlv",
        "description": "The dissect_hip_tlv function in epan/dissectors/packet-hip.c in the HIP dissector in Wireshark 1.12.x before 1.12.1 does not properly handle a NULL tree, which allows remote attackers to cause a denial of service (infinite loop) via a crafted packet.",
        "git_url": "https://github.com/wireshark/wireshark/commit/d9e5021fe79973d00ddd8fcef0bbefbaae63dd0f",
        "commit_title": "hip: fix infinite loop in dissect_hip_tlv",
        "commit_text": " We can't use tree_item == NULL to determine which branch of the previous if was hit, since proto_tree_add_item can return NULL when run without tree, which was leading to an infinite loop since we were never advancing the offset. Use the actual locator_type instead.  Introduced by either g3635d7bed70 or gebff85fdbb although neither of them directly touch this code path. I'm guess that g3635d7bed70 removed an if (tree) guard in some calling function which would have prevented this, but I haven't checked. The bug would still have been there before, it just wouldn't have been hit because it's only present with a NULL tree. Somebody more familiar with the protocol should probably go over a capture or two and make sure this isn't a symptom of some other decoding gone awry in the recent changes. ",
        "func_before": "static int\ndissect_hip_tlv(tvbuff_t *tvb, packet_info *pinfo, int offset, proto_item *ti, int type, int tlv_len)\n{\n        proto_tree *t=NULL;\n        proto_item *ti_tlv, *ti_loc, *hi_len_item, *e_len_item, *arg_item;\n        guint8 n, algorithm, reg_type;\n        guint16 trans, hi_len, di_len, di_type, e_len, pv_len;\n        guint32 reserved, hi_hdr;\n        guint8 transport_proto;\n        guint8 locator_type;\n        int newoffset, newlen, hi_t;\n\n        /* move over the TLV */\n        newoffset = offset + 4;\n        t = proto_item_add_subtree(ti, ett_hip_tlv_data);\n        switch (type)\n        {\n        case PARAM_ESP_INFO:\n                /* Reserved */\n                proto_tree_add_item(t, hf_hip_tlv_ei_res, tvb, newoffset, 2, ENC_BIG_ENDIAN);\n                /* KEYMAT index */\n                newoffset += 2;\n                proto_tree_add_item(t, hf_hip_tlv_ei_keyidx, tvb, newoffset, 2, ENC_BIG_ENDIAN);\n                /* OLD SPI */\n                newoffset += 2;\n                proto_tree_add_item(t, hf_hip_tlv_ei_oldspi, tvb, newoffset, 4, ENC_BIG_ENDIAN);\n                /* NEW SPI */\n                newoffset += 4;\n                proto_tree_add_item(t, hf_hip_tlv_ei_newspi, tvb, newoffset, 4, ENC_BIG_ENDIAN);\n                break;\n        case PARAM_R1_COUNTER:\n                /* Reserved */\n                proto_tree_add_item(t, hf_hip_tlv_r1_res, tvb, newoffset, 4, ENC_BIG_ENDIAN);\n                /* R1 generation counter */\n                newoffset += 4;\n                proto_tree_add_item(t, hf_hip_tlv_r1count, tvb, newoffset, 8, ENC_NA);\n                break;\n        case PARAM_LOCATOR:\n                /* RFC 5206 section 4. and  RFC 5770 section 5.7. for type 2 locators\n                 */\n                tlv_len -= 4;\n                /* loop through included locators */\n                while (tlv_len > 0) {\n                        /* Every locator to new tree node\n                         * Skip ahead and read the 0 or 1 type locator from 8 bytes\n                         * and type 2 locator from 20 bytes to be used as the top level\n                         * tree_item for this subtree\n                         */\n                        locator_type = tvb_get_guint8(tvb, newoffset + 1);\n                        if (locator_type == 0) {\n                                ti_loc = proto_tree_add_item(t, hf_hip_tlv_locator_address,\n                                                             tvb, newoffset + 8, 16, ENC_NA);\n                        } else if (locator_type == 1) {\n                                ti_loc = proto_tree_add_item(t, hf_hip_tlv_locator_address,\n                                                             tvb, newoffset + 12, 16, ENC_NA);\n                        } else if (locator_type == 2) {\n                                ti_loc = proto_tree_add_item(t, hf_hip_tlv_locator_address,\n                                                             tvb, newoffset + 20, 16, ENC_NA);\n                        } else {\n                                /* unknown or malformed locator type jumping over it */\n                                ti_loc = NULL;\n                                newoffset += (1 + tvb_get_guint8(tvb, newoffset + 2));\n                                tlv_len -= (1 + tvb_get_guint8(tvb, newoffset + 2));\n                        }\n                        if (ti_loc) {\n                                ti_loc = proto_item_add_subtree(ti_loc, ett_hip_locator_data);\n                                /* Traffic type */\n                                proto_tree_add_item(ti_loc, hf_hip_tlv_locator_traffic_type, tvb,\n                                                    newoffset, 1, ENC_BIG_ENDIAN);\n                                newoffset++;\n                                /* Locator type */\n#if 0\n                                locator_type = tvb_get_guint8(tvb, newoffset);\n#endif\n                                proto_tree_add_item(ti_loc, hf_hip_tlv_locator_type, tvb, newoffset, 1, ENC_BIG_ENDIAN);\n                                newoffset++;\n                                /* Locator length */\n                                proto_tree_add_item(ti_loc, hf_hip_tlv_locator_len, tvb, newoffset, 1, ENC_BIG_ENDIAN);\n                                newoffset++;\n                                /* Reserved includes the Preferred bit */\n                                reserved = tvb_get_guint8(tvb, newoffset);\n                                proto_tree_add_uint_format_value(ti_loc, hf_hip_tlv_locator_reserved, tvb,\n                                                           newoffset, 1, reserved,\n                                                           \"0x%x %s\", reserved,\n                                                           (reserved >> 31) ? \"(Preferred)\" : \"\");\n                                newoffset++;\n                                /* Locator lifetime */\n                                proto_tree_add_item(ti_loc, hf_hip_tlv_locator_lifetime, tvb,\n                                                    newoffset, 4, ENC_BIG_ENDIAN);\n                                newoffset += 4;\n                                if (locator_type == 0) {\n                                        /* Locator types 1 and 0 RFC 5206 section 4.2.*/\n                                        /* Locator */\n                                        proto_tree_add_item(ti_loc, hf_hip_tlv_locator_address,\n                                                            tvb, newoffset, 16, ENC_NA);\n                                        newoffset += 16;\n                                        tlv_len -= 24;\n                                } else if (locator_type == 1) {\n                                        /* Locator types 1 and 0 RFC 5206 section 4.2.*/\n                                        /* SPI */\n                                        proto_tree_add_item(ti_loc, hf_hip_tlv_locator_spi, tvb,\n                                                            newoffset, 4, ENC_BIG_ENDIAN);\n                                        newoffset += 4;\n                                        /* Locator */\n                                        proto_tree_add_item(ti_loc, hf_hip_tlv_locator_address,\n                                                            tvb, newoffset, 16, ENC_NA);\n                                        newoffset += 16;\n                                        tlv_len -= 28;\n                                } else if (locator_type == 2) {\n                                        /* Locator type 2 RFC 5770 section 5.7. */\n                                        /* Tansport port */\n                                        proto_tree_add_item(ti_loc, hf_hip_tlv_locator_port, tvb,\n                                                            newoffset, 2, ENC_BIG_ENDIAN);\n                                        newoffset += 2;\n                                        /* Transport protocol */\n                                        transport_proto = tvb_get_guint8(tvb, newoffset);\n                                        /* RFC 5770 section 5.6 */\n                                        proto_tree_add_uint_format(ti_loc, hf_hip_tlv_locator_transport_protocol,\n                                                                   tvb, newoffset, 1, transport_proto,\n                                                                   \"Transport protocol: %d %s\",\n                                                                   transport_proto,\n                                                                   (transport_proto == 17) ?\n                                                                   \"(UDP)\" : \"\");\n                                        newoffset++;\n                                        /* Kind */\n                                        proto_tree_add_item(ti_loc, hf_hip_tlv_locator_kind, tvb,\n                                                            newoffset, 1, ENC_BIG_ENDIAN);\n                                        newoffset++;\n                                        /* Priority */\n                                        proto_tree_add_item(ti_loc, hf_hip_tlv_locator_priority, tvb,\n                                                            newoffset, 4, ENC_BIG_ENDIAN);\n                                        newoffset += 4;\n                                        /* SPI */\n                                        proto_tree_add_item(ti_loc, hf_hip_tlv_locator_spi, tvb,\n                                                            newoffset, 4, ENC_BIG_ENDIAN);\n                                        newoffset += 4;\n                                        /* Locator */\n                                        proto_tree_add_item(ti_loc, hf_hip_tlv_locator_address,\n                                                            tvb, newoffset, 16, ENC_NA);\n                                        newoffset += 16;\n                                        tlv_len -= 36;\n                                }\n                        }\n                }\n                break;\n        case PARAM_PUZZLE:\n                /* K number of verified bits */\n                proto_tree_add_item(t, hf_hip_tlv_puzzle_k, tvb, newoffset, 1, ENC_BIG_ENDIAN);\n                /* Puzzle lifetime */\n                newoffset++;\n                proto_tree_add_item(t, hf_hip_tlv_puzzle_life, tvb, newoffset, 1, ENC_BIG_ENDIAN);\n                /* Puzzle O*/\n                newoffset++;\n                proto_tree_add_item(t, hf_hip_tlv_puzzle_o, tvb, newoffset, 2, ENC_BIG_ENDIAN);\n                /* Puzzle I */\n                newoffset += 2;\n                proto_tree_add_item(t, hf_hip_tlv_puzzle_i, tvb,newoffset, tlv_len - 4, ENC_NA);\n                break;\n        case PARAM_SOLUTION:\n                /* K number of verified bits */\n                proto_tree_add_item(t, hf_hip_tlv_solution_k, tvb, newoffset, 1, ENC_BIG_ENDIAN);\n                /* Solution Reserved */\n                newoffset++;\n                proto_tree_add_item(t, hf_hip_tlv_solution_reserved, tvb, newoffset, 1, ENC_BIG_ENDIAN);\n                /* Solution Opaque */\n                newoffset++;\n                proto_tree_add_item(t, hf_hip_tlv_solution_o, tvb,newoffset, 2, ENC_BIG_ENDIAN);\n                /* Solution I */\n                newoffset += 2;\n                proto_tree_add_item(t, hf_hip_tlv_solution_i, tvb, newoffset, (tlv_len - 4)/2, ENC_NA);\n                /* Solution J */\n                newoffset += (tlv_len - 4) /2;\n                proto_tree_add_item(t, hf_hip_tlv_solution_j, tvb, newoffset, (tlv_len -4)/2, ENC_NA);\n                break;\n        case PARAM_SEQ:\n                /* Update ID */\n                proto_tree_add_item(t, hf_hip_tlv_seq_updid, tvb, newoffset, 4, ENC_BIG_ENDIAN);\n                break;\n        case PARAM_ACK:\n                /* Can contain multiple Update IDs from peer */\n                while (tlv_len > 0) {\n                        /* peer Update ID */\n                        proto_tree_add_item(t, hf_hip_tlv_ack_updid, tvb, newoffset, 4, ENC_BIG_ENDIAN);\n                        newoffset += 4;\n                        tlv_len -= 4;\n                }\n                break;\n        case PARAM_DIFFIE_HELLMAN:\n                n = tvb_get_guint8(tvb, newoffset);\n                /* First Group ID*/\n                proto_tree_add_uint_format(t, hf_hip_tlv_dh_group_id, tvb, newoffset,\n                                           1, n, \"%u (%s)\", n,\n                                           val_to_str_const(n, dh_group_id_vals, \"Unknown\"));\n                /* First Public value len */\n                newoffset++;\n                pv_len = tvb_get_ntohs(tvb, newoffset);\n                proto_tree_add_item(t, hf_hip_tlv_dh_pv_length, tvb, newoffset, 2, ENC_BIG_ENDIAN);\n\n                /* First Public value */\n                newoffset += 2;\n                proto_tree_add_item(t, hf_hip_tlv_dh_pub, tvb, newoffset, pv_len, ENC_NA);\n                /* Check for the second group */\n                if ((pv_len + newoffset) < tlv_len) {\n                        /* Second Group ID*/\n                        newoffset += pv_len;\n                        proto_tree_add_uint_format(t, hf_hip_tlv_dh_group_id, tvb, newoffset,\n                                                   1, n, \"%u (%s)\", n,\n                                                   val_to_str_const(n, dh_group_id_vals, \"Unknown\"));\n                        /* Second Public value len */\n                        newoffset += 1;\n                        pv_len = tvb_get_ntohs(tvb, newoffset);\n                        proto_tree_add_item(t, hf_hip_tlv_dh_pv_length, tvb, newoffset, 2, ENC_BIG_ENDIAN);\n                        /* Second Public Value */\n                        newoffset += 2;\n                        proto_tree_add_item(t, hf_hip_tlv_dh_pub, tvb, newoffset,\n                                             pv_len, ENC_NA);\n                }\n                break;\n        case PARAM_ESP_TRANSFORM:\n                /* Reserved */\n                proto_tree_add_item(t, hf_hip_tlv_esp_reserved, tvb, newoffset, 2, ENC_BIG_ENDIAN);\n                newoffset +=2;\n                tlv_len -= 2;\n                while (tlv_len > 0) {\n                        /* Suite # 1, 2, ...,  n\n                         * two bytes per transform id\n                         */\n                        trans = tvb_get_ntohs(tvb, newoffset);\n                        proto_tree_add_uint_format(t, hf_hip_tlv_trans_id, tvb,\n                                                   newoffset, 2, trans, \"%u (%s)\", trans,\n                                                   val_to_str_const(trans, transform_id_vals, \"Unknown\"));\n                        tlv_len -= 2;\n                        newoffset += 2;\n                }\n                break;\n        case PARAM_HIP_TRANSFORM:\n                while (tlv_len > 0) {\n                        /* Suite # 1, 2, ...,  n\n                           two bytes per transform id */\n                        trans = tvb_get_ntohs(tvb, newoffset);\n                        proto_tree_add_uint_format(t, hf_hip_tlv_trans_id, tvb,\n                                                   newoffset, 2, trans, \"%u (%s)\", trans,\n                                                   val_to_str_const(trans, transform_id_vals, \"Unknown\"));\n                        tlv_len -= 2;\n                        newoffset += 2;\n                }\n                break;\n        case PARAM_NAT_TRAVERSAL_MODE:\n                /* Reserved */\n                proto_tree_add_item(t, hf_hip_tlv_esp_reserved, tvb, newoffset, 2, ENC_BIG_ENDIAN);\n                newoffset += 2;\n                tlv_len -= 2;\n                while (tlv_len > 0) {\n                        /* Suite # 1, 2, ...,  n\n                           two bytes per mode id */\n                        trans = tvb_get_ntohs(tvb, newoffset);\n                        proto_tree_add_uint_format(t, hf_hip_tlv_nat_traversal_mode_id, tvb,\n                                                   newoffset, 2, trans, \"%u (%s)\", trans,\n                                                   val_to_str_const(trans, mode_id_vals, \"Unknown\"));\n                        tlv_len -= 2;\n                        newoffset += 2;\n                }\n                break;\n        case PARAM_TRANSACTION_PACING:\n                /* Min Ta */\n                proto_tree_add_item(t, hf_hip_tlv_transaction_minta, tvb, newoffset, 4, ENC_BIG_ENDIAN);\n                break;\n        case PARAM_ENCRYPTED:\n                /* Reserved */\n                proto_tree_add_item(t, hf_hip_tlv_enc_reserved, tvb, newoffset, 4, ENC_BIG_ENDIAN);\n                newoffset += 4;\n                /* IV\n                 * 16 bytes IV for AES CBC RFC 3602\n                 *  8 bytes IV for 3DES CBC RFC 2405\n                 *  0 bytes IV for NULL\n                 *  and\n                 *  encrypted data after that.\n                 */\n                proto_tree_add_item(t, hf_hip_encrypted_parameter_data, tvb, newoffset, tlv_len - 4, ENC_NA);\n                break;\n        case PARAM_HIP_CIPHER:\n                while (tlv_len > 0) {\n                        /* Suite # 1, 2, ...,  n\n                           two bytes per Cipher Suite id */\n                        proto_tree_add_item(t, hf_hip_tlv_cipher_id, tvb, newoffset, 2, ENC_BIG_ENDIAN);\n                        tlv_len -= 2;\n                        newoffset += 2;\n                }\n                break;\n        case PARAM_HIT_SUITE_LIST:\n                while (tlv_len > 0) {\n                        /* Suite # 1, 2, ...,  n\n                           one byte per HIT Suite id.\n                           According to specification, HIT_SUITE_LIST is defined as eight-bit field,\n                           current four-bit HIT Suite-IDs only use the four higher order bits in the ID Field.*/\n                        proto_tree_add_item(t, hf_hip_tlv_hit_suite_id, tvb, newoffset, 1, ENC_BIG_ENDIAN);\n                        tlv_len -= 1;\n                        newoffset += 1;\n                }\n                break;\n        case PARAM_HOST_ID:\n                hi_len = tvb_get_ntohs(tvb, newoffset);\n                hi_len_item = proto_tree_add_item(t, hf_hip_tlv_host_id_len, tvb, newoffset, 2, ENC_BIG_ENDIAN);\n                newoffset += 2;\n                di_len = tvb_get_ntohs(tvb, newoffset);\n                di_type = (di_len >> 12) & 0x000F;        /* get 4 bits for DI type */\n                di_len = di_len & 0x0FFF;                /* 12 bits for DI length */\n                /* DI type */\n                proto_tree_add_item(t, hf_hip_tlv_host_di_type, tvb, newoffset, 1, ENC_BIG_ENDIAN);\n                /* DI len */\n                proto_tree_add_item(t, hf_hip_tlv_host_di_len, tvb, newoffset, 2, ENC_BIG_ENDIAN);\n                newoffset += 2;\n                /* hi_hdr - first 4 bytes are 0200ff03 (KEY RR in RFC 2535)\n                 *   flags     2  octets\n                 *   protocol  1  octet\n                 *   algorithm 1  octet (DSA or RSA)\n                 *   <public key>\n                 */\n                hi_hdr = tvb_get_ntohl(tvb, newoffset);\n                ti_tlv = proto_tree_add_item(t, hf_hip_tlv_host_id_hdr,\n                                             tvb, newoffset, 4, ENC_BIG_ENDIAN);\n\n                ti_tlv = proto_item_add_subtree(ti_tlv, ett_hip_tlv_host_id_hdr);\n                /* HDR Flags*/\n                proto_tree_add_uint(ti_tlv, hf_hip_tlv_host_id_hdr_flags, tvb,\n                                    newoffset, 2, hi_hdr);\n                newoffset += 2;\n                /* HDR Protocol */\n                proto_tree_add_uint(ti_tlv, hf_hip_tlv_host_id_hdr_proto, tvb,\n                                    newoffset, 1,  hi_hdr);\n                newoffset += 1;\n                /* HDR Algorithm */\n                algorithm = tvb_get_guint8(tvb, newoffset);\n                arg_item = proto_tree_add_uint(ti_tlv, hf_hip_tlv_host_id_hdr_alg, tvb,\n                                    newoffset, 1, hi_hdr);\n\n                switch (algorithm) {\n                case HI_ALG_DSA:\n                        /* DSA KEY RR RFC 2536\n                         *   T         1  octet\n                         *   Q         20  octets\n                         *   P         64 + T*8  octets\n                         *   G         64 + T*8  octets\n                         *   Y         64 + T*8  octets\n                         */\n                        newoffset++; /* 12 + offset */\n                        /* T */\n                        proto_tree_add_item(t, hf_hip_tlv_host_id_t, tvb, newoffset, 1, ENC_BIG_ENDIAN);\n                        hi_t = tvb_get_guint8(tvb, newoffset);\n                        newoffset++;\n                        /* Q */\n                        proto_tree_add_item(t, hf_hip_tlv_host_id_q, tvb, newoffset,\n                                             20, ENC_NA);\n                        newoffset += 20;\n                        if (hi_t > 56) /* max 4096 bits */\n                                break;\n                        /* P */\n                        newlen = 64 + (hi_t * 8);\n                        proto_tree_add_item(t, hf_hip_tlv_host_id_p, tvb, newoffset,\n                                             newlen, ENC_NA);\n                        /* G */\n                        newoffset += newlen;\n                        proto_tree_add_item(t, hf_hip_tlv_host_id_g, tvb, newoffset,\n                                             newlen, ENC_NA);\n                        /* Y */\n                        newoffset += newlen;\n                        proto_tree_add_item(t, hf_hip_tlv_host_id_y, tvb, newoffset,\n                                             newlen, ENC_NA);\n                        break;\n                case HI_ALG_RSA:\n                        /* RSA KEY RR RFC 3110\n                         * e_len        1 or 3 octets\n                         * e            specified by e_len\n                         * n            variable length public modulus\n                         */\n                        newoffset++; /* 12 + offset */\n                        /* E len */\n                        e_len = tvb_get_guint8(tvb, newoffset);\n                        e_len_item = proto_tree_add_item(t, hf_hip_tlv_host_id_e_len, tvb, newoffset,\n                                            (e_len > 255) ? 3 : 1, ENC_BIG_ENDIAN);\n                        newoffset++;\n                        hi_len -= 5; /* subtract RDATA + e_len */\n                        if (e_len == 0) { /* e_len is 0 followed by 16-bit value */\n                                e_len = tvb_get_ntohs(tvb, newoffset);\n                                newoffset += 2;\n                                hi_len -= 2;\n                        }\n                        if (e_len > 512) { /* per, RFC 3110 < 4096 bits */\n                                expert_add_info(pinfo, e_len_item, &ei_hip_tlv_host_id_len);\n                                break;\n                        }\n                        /* e */\n                        proto_tree_add_item(t, hf_hip_tlv_host_id_e, tvb, newoffset,\n                                             e_len, ENC_NA);\n                        newoffset += e_len;\n                        hi_len -= e_len;\n\n                        if (hi_len > 512) {\n                                expert_add_info(pinfo, hi_len_item, &ei_hip_tlv_host_id_len);\n                                break;\n                        }\n\n                        /* RSA public modulus n */\n                        proto_tree_add_item(t, hf_hip_tlv_host_id_n, tvb, newoffset,\n                                             hi_len, ENC_NA);\n                        break;\n                default:\n                        expert_add_info(pinfo, arg_item, &ei_hip_tlv_host_id_hdr_alg);\n\n                        break;\n                }\n                /* FQDN */\n                if (di_type == 0)\n                        break;\n                if (di_type == 1) {\n                        /* RFC 1035 */\n                        proto_tree_add_item(t, hf_hip_fqdn, tvb, offset+16+hi_len, di_len, ENC_ASCII|ENC_NA);\n                } else if (di_type == 2) {\n                        /* RFC 4282 */\n                        proto_tree_add_item(t, hf_hip_nai, tvb, offset+16+hi_len, di_len, ENC_ASCII|ENC_NA);\n                }\n                break;\n        case PARAM_CERT: /* CERT */\n                /* Cert Group */\n                proto_tree_add_item(t, hf_hip_tlv_cert_group, tvb, newoffset, 1, ENC_BIG_ENDIAN);\n                newoffset++;\n                /* Cert Count */\n                proto_tree_add_item(t, hf_hip_tlv_cert_count, tvb, newoffset, 1, ENC_BIG_ENDIAN);\n                newoffset++;\n                /* Cert ID */\n                proto_tree_add_item(t, hf_hip_tlv_cert_id, tvb, newoffset, 1, ENC_BIG_ENDIAN);\n                newoffset++;\n                /* Cert Type */\n                proto_tree_add_item(t, hf_hip_tlv_cert_type, tvb, newoffset, 1, ENC_BIG_ENDIAN);\n                newoffset++;\n                /* Certificate */\n                proto_tree_add_item(t, hf_hip_tlv_certificate, tvb, newoffset,\n                                     tlv_len-4, ENC_NA);\n                break;\n        case PARAM_NOTIFICATION:\n                /* Reserved */\n                proto_tree_add_item(t, hf_hip_tlv_notification_res, tvb, newoffset, 2, ENC_BIG_ENDIAN);\n                newoffset += 2;\n                /* Notification Message Type */\n                proto_tree_add_item(t, hf_hip_tlv_notification_type, tvb, newoffset, 2, ENC_BIG_ENDIAN);\n                newoffset += 2;\n                /* Notification Data */\n                proto_tree_add_item(t, hf_hip_tlv_notification_data, tvb, newoffset,\n                                     tlv_len-4, ENC_NA);\n                break;\n        case PARAM_ECHO_REQUEST_SIGNED:\n        case PARAM_ECHO_RESPONSE_SIGNED:\n        case PARAM_ECHO_REQUEST_UNSIGNED:\n        case PARAM_ECHO_RESPONSE_UNSIGNED:\n                /* Variable length Opaque Data */\n                proto_tree_add_item(t, hf_hip_tlv_opaque_data, tvb, newoffset,\n                                     tlv_len, ENC_NA);\n                break;\n        case PARAM_REG_INFO:\n        case PARAM_REG_REQUEST:\n        case PARAM_REG_RESPONSE:\n        case PARAM_REG_FAILED:\n                if (type == PARAM_REG_INFO) {\n                        /* Min Lifetime */\n                        proto_tree_add_item(t, hf_hip_tlv_reg_ltmin, tvb, newoffset, 1, ENC_BIG_ENDIAN);\n                        newoffset++;\n                        /* Max Lifetime */\n                        proto_tree_add_item(t, hf_hip_tlv_reg_ltmax, tvb, newoffset, 1, ENC_BIG_ENDIAN);\n                        newoffset++;\n                        tlv_len -= 2;\n                } else if (type == PARAM_REG_FAILED) {\n                        /* Failure Type */\n                        proto_tree_add_item(t, hf_hip_tlv_reg_failtype, tvb, newoffset, 1, ENC_BIG_ENDIAN);\n                        newoffset++;\n                        tlv_len--;\n                } else {\n                        /* Lifetime */\n                        proto_tree_add_item(t, hf_hip_tlv_reg_lt, tvb, newoffset, 1, ENC_BIG_ENDIAN);\n                        newoffset++;\n                        tlv_len--;\n                }\n                /* Reg Type 1 ... n, Padding */\n                while (tlv_len > 0) {\n                        reg_type = tvb_get_guint8(tvb, newoffset);\n                        proto_tree_add_uint_format(t, hf_hip_tlv_reg_type, tvb,\n                                                   newoffset, 1, reg_type, \"%u (%s)\", reg_type,\n                                                   val_to_str_const(reg_type, reg_type_vals, \"Unknown\"));\n                        /* one byte per registration type */\n                        tlv_len--;\n                        newoffset++;\n                }\n                break;\n        case PARAM_HMAC:\n        case PARAM_HMAC_2:\n        case PARAM_RVS_HMAC:\n        case PARAM_RELAY_HMAC:\n                /* HMAC */\n                proto_tree_add_item(t, hf_hip_tlv_hmac, tvb, offset+4,\n                                     tlv_len, ENC_NA);\n                break;\n        case PARAM_HIP_SIGNATURE:\n        case PARAM_HIP_SIGNATURE_2:\n                /* Signature algorithm */\n                n = tvb_get_guint8(tvb, offset+4);\n                proto_tree_add_uint_format(t, hf_hip_tlv_sig_alg, tvb, newoffset, 1,\n                                           n, \"%u (%s)\", n,\n                                           val_to_str_const(n, sig_alg_vals, \"Unknown\"));\n                newoffset++;\n                /* Signature */\n                proto_tree_add_item(t, hf_hip_tlv_sig, tvb, newoffset, tlv_len-1,\n                                    ENC_NA);\n                break;\n        case PARAM_FROM:\n                /* Address */\n                proto_tree_add_item(t, hf_hip_tlv_from_address, tvb, newoffset, 16, ENC_NA);\n                break;\n        case PARAM_VIA_RVS:\n                /* RVS Addresses  */\n                while (tlv_len > 0) {\n                        proto_tree_add_item(t, hf_hip_tlv_rvs_address, tvb, newoffset, 16, ENC_NA);\n                        tlv_len -= 16;\n                        newoffset += 16;\n                }\n                break;\n        case PARAM_RELAY_FROM:\n                /* Port */\n                proto_tree_add_item(t, hf_hip_tlv_relay_from_port, tvb, newoffset, 2, ENC_BIG_ENDIAN);\n                newoffset += 2;\n                /* Protocol */\n                proto_tree_add_item(t, hf_hip_tlv_relay_from_protocol, tvb, newoffset, 1, ENC_BIG_ENDIAN);\n                newoffset += 1;\n                /* Reserved */\n                proto_tree_add_item(t, hf_hip_tlv_relay_from_reserved, tvb, newoffset, 1, ENC_BIG_ENDIAN);\n                newoffset += 1;\n                /* Address */\n                proto_tree_add_item(t, hf_hip_tlv_relay_from_address, tvb, newoffset, 16, ENC_NA);\n                break;\n        case PARAM_RELAY_TO:\n                /* Port */\n                proto_tree_add_item(t, hf_hip_tlv_relay_to_port, tvb, newoffset, 2, ENC_BIG_ENDIAN);\n                newoffset += 2;\n                /* Protocol */\n                proto_tree_add_item(t, hf_hip_tlv_relay_to_protocol, tvb, newoffset, 1, ENC_BIG_ENDIAN);\n                newoffset += 1;\n                /* Reserved */\n                proto_tree_add_item(t, hf_hip_tlv_relay_to_reserved, tvb, newoffset, 1, ENC_BIG_ENDIAN);\n                newoffset += 1;\n                /* Address */\n                proto_tree_add_item(t, hf_hip_tlv_relay_to_address, tvb, newoffset, 16, ENC_NA);\n                break;\n        case PARAM_REG_FROM:\n                /* Port */\n                proto_tree_add_item(t, hf_hip_tlv_reg_from_port, tvb, newoffset, 2, ENC_BIG_ENDIAN);\n                newoffset += 2;\n                /* Protocol */\n                proto_tree_add_item(t, hf_hip_tlv_reg_from_protocol, tvb, newoffset, 1, ENC_BIG_ENDIAN);\n                newoffset += 1;\n                /* Reserved */\n                proto_tree_add_item(t, hf_hip_tlv_reg_from_reserved, tvb, newoffset, 1, ENC_BIG_ENDIAN);\n                newoffset += 1;\n                /* Address */\n                proto_tree_add_item(t, hf_hip_tlv_reg_from_address, tvb, newoffset, 16, ENC_NA);\n                break;\n        default:\n                break;\n        }\n        return (0);\n}",
        "func": "static int\ndissect_hip_tlv(tvbuff_t *tvb, packet_info *pinfo, int offset, proto_item *ti, int type, int tlv_len)\n{\n        proto_tree *t=NULL;\n        proto_item *ti_tlv, *ti_loc, *hi_len_item, *e_len_item, *arg_item;\n        guint8 n, algorithm, reg_type;\n        guint16 trans, hi_len, di_len, di_type, e_len, pv_len;\n        guint32 reserved, hi_hdr;\n        guint8 transport_proto;\n        guint8 locator_type;\n        int newoffset, newlen, hi_t;\n\n        /* move over the TLV */\n        newoffset = offset + 4;\n        t = proto_item_add_subtree(ti, ett_hip_tlv_data);\n        switch (type)\n        {\n        case PARAM_ESP_INFO:\n                /* Reserved */\n                proto_tree_add_item(t, hf_hip_tlv_ei_res, tvb, newoffset, 2, ENC_BIG_ENDIAN);\n                /* KEYMAT index */\n                newoffset += 2;\n                proto_tree_add_item(t, hf_hip_tlv_ei_keyidx, tvb, newoffset, 2, ENC_BIG_ENDIAN);\n                /* OLD SPI */\n                newoffset += 2;\n                proto_tree_add_item(t, hf_hip_tlv_ei_oldspi, tvb, newoffset, 4, ENC_BIG_ENDIAN);\n                /* NEW SPI */\n                newoffset += 4;\n                proto_tree_add_item(t, hf_hip_tlv_ei_newspi, tvb, newoffset, 4, ENC_BIG_ENDIAN);\n                break;\n        case PARAM_R1_COUNTER:\n                /* Reserved */\n                proto_tree_add_item(t, hf_hip_tlv_r1_res, tvb, newoffset, 4, ENC_BIG_ENDIAN);\n                /* R1 generation counter */\n                newoffset += 4;\n                proto_tree_add_item(t, hf_hip_tlv_r1count, tvb, newoffset, 8, ENC_NA);\n                break;\n        case PARAM_LOCATOR:\n                /* RFC 5206 section 4. and  RFC 5770 section 5.7. for type 2 locators\n                 */\n                tlv_len -= 4;\n                /* loop through included locators */\n                while (tlv_len > 0) {\n                        /* Every locator to new tree node\n                         * Skip ahead and read the 0 or 1 type locator from 8 bytes\n                         * and type 2 locator from 20 bytes to be used as the top level\n                         * tree_item for this subtree\n                         */\n                        locator_type = tvb_get_guint8(tvb, newoffset + 1);\n                        if (locator_type == 0) {\n                                ti_loc = proto_tree_add_item(t, hf_hip_tlv_locator_address,\n                                                             tvb, newoffset + 8, 16, ENC_NA);\n                        } else if (locator_type == 1) {\n                                ti_loc = proto_tree_add_item(t, hf_hip_tlv_locator_address,\n                                                             tvb, newoffset + 12, 16, ENC_NA);\n                        } else if (locator_type == 2) {\n                                ti_loc = proto_tree_add_item(t, hf_hip_tlv_locator_address,\n                                                             tvb, newoffset + 20, 16, ENC_NA);\n                        } else {\n                                /* unknown or malformed locator type jumping over it */\n                                ti_loc = NULL;\n                                newoffset += (1 + tvb_get_guint8(tvb, newoffset + 2));\n                                tlv_len -= (1 + tvb_get_guint8(tvb, newoffset + 2));\n                        }\n                        if (locator_type <= 2) {\n                                ti_loc = proto_item_add_subtree(ti_loc, ett_hip_locator_data);\n                                /* Traffic type */\n                                proto_tree_add_item(ti_loc, hf_hip_tlv_locator_traffic_type, tvb,\n                                                    newoffset, 1, ENC_BIG_ENDIAN);\n                                newoffset++;\n                                /* Locator type */\n#if 0\n                                locator_type = tvb_get_guint8(tvb, newoffset);\n#endif\n                                proto_tree_add_item(ti_loc, hf_hip_tlv_locator_type, tvb, newoffset, 1, ENC_BIG_ENDIAN);\n                                newoffset++;\n                                /* Locator length */\n                                proto_tree_add_item(ti_loc, hf_hip_tlv_locator_len, tvb, newoffset, 1, ENC_BIG_ENDIAN);\n                                newoffset++;\n                                /* Reserved includes the Preferred bit */\n                                reserved = tvb_get_guint8(tvb, newoffset);\n                                proto_tree_add_uint_format_value(ti_loc, hf_hip_tlv_locator_reserved, tvb,\n                                                           newoffset, 1, reserved,\n                                                           \"0x%x %s\", reserved,\n                                                           (reserved >> 31) ? \"(Preferred)\" : \"\");\n                                newoffset++;\n                                /* Locator lifetime */\n                                proto_tree_add_item(ti_loc, hf_hip_tlv_locator_lifetime, tvb,\n                                                    newoffset, 4, ENC_BIG_ENDIAN);\n                                newoffset += 4;\n                                if (locator_type == 0) {\n                                        /* Locator types 1 and 0 RFC 5206 section 4.2.*/\n                                        /* Locator */\n                                        proto_tree_add_item(ti_loc, hf_hip_tlv_locator_address,\n                                                            tvb, newoffset, 16, ENC_NA);\n                                        newoffset += 16;\n                                        tlv_len -= 24;\n                                } else if (locator_type == 1) {\n                                        /* Locator types 1 and 0 RFC 5206 section 4.2.*/\n                                        /* SPI */\n                                        proto_tree_add_item(ti_loc, hf_hip_tlv_locator_spi, tvb,\n                                                            newoffset, 4, ENC_BIG_ENDIAN);\n                                        newoffset += 4;\n                                        /* Locator */\n                                        proto_tree_add_item(ti_loc, hf_hip_tlv_locator_address,\n                                                            tvb, newoffset, 16, ENC_NA);\n                                        newoffset += 16;\n                                        tlv_len -= 28;\n                                } else if (locator_type == 2) {\n                                        /* Locator type 2 RFC 5770 section 5.7. */\n                                        /* Tansport port */\n                                        proto_tree_add_item(ti_loc, hf_hip_tlv_locator_port, tvb,\n                                                            newoffset, 2, ENC_BIG_ENDIAN);\n                                        newoffset += 2;\n                                        /* Transport protocol */\n                                        transport_proto = tvb_get_guint8(tvb, newoffset);\n                                        /* RFC 5770 section 5.6 */\n                                        proto_tree_add_uint_format(ti_loc, hf_hip_tlv_locator_transport_protocol,\n                                                                   tvb, newoffset, 1, transport_proto,\n                                                                   \"Transport protocol: %d %s\",\n                                                                   transport_proto,\n                                                                   (transport_proto == 17) ?\n                                                                   \"(UDP)\" : \"\");\n                                        newoffset++;\n                                        /* Kind */\n                                        proto_tree_add_item(ti_loc, hf_hip_tlv_locator_kind, tvb,\n                                                            newoffset, 1, ENC_BIG_ENDIAN);\n                                        newoffset++;\n                                        /* Priority */\n                                        proto_tree_add_item(ti_loc, hf_hip_tlv_locator_priority, tvb,\n                                                            newoffset, 4, ENC_BIG_ENDIAN);\n                                        newoffset += 4;\n                                        /* SPI */\n                                        proto_tree_add_item(ti_loc, hf_hip_tlv_locator_spi, tvb,\n                                                            newoffset, 4, ENC_BIG_ENDIAN);\n                                        newoffset += 4;\n                                        /* Locator */\n                                        proto_tree_add_item(ti_loc, hf_hip_tlv_locator_address,\n                                                            tvb, newoffset, 16, ENC_NA);\n                                        newoffset += 16;\n                                        tlv_len -= 36;\n                                }\n                        }\n                }\n                break;\n        case PARAM_PUZZLE:\n                /* K number of verified bits */\n                proto_tree_add_item(t, hf_hip_tlv_puzzle_k, tvb, newoffset, 1, ENC_BIG_ENDIAN);\n                /* Puzzle lifetime */\n                newoffset++;\n                proto_tree_add_item(t, hf_hip_tlv_puzzle_life, tvb, newoffset, 1, ENC_BIG_ENDIAN);\n                /* Puzzle O*/\n                newoffset++;\n                proto_tree_add_item(t, hf_hip_tlv_puzzle_o, tvb, newoffset, 2, ENC_BIG_ENDIAN);\n                /* Puzzle I */\n                newoffset += 2;\n                proto_tree_add_item(t, hf_hip_tlv_puzzle_i, tvb,newoffset, tlv_len - 4, ENC_NA);\n                break;\n        case PARAM_SOLUTION:\n                /* K number of verified bits */\n                proto_tree_add_item(t, hf_hip_tlv_solution_k, tvb, newoffset, 1, ENC_BIG_ENDIAN);\n                /* Solution Reserved */\n                newoffset++;\n                proto_tree_add_item(t, hf_hip_tlv_solution_reserved, tvb, newoffset, 1, ENC_BIG_ENDIAN);\n                /* Solution Opaque */\n                newoffset++;\n                proto_tree_add_item(t, hf_hip_tlv_solution_o, tvb,newoffset, 2, ENC_BIG_ENDIAN);\n                /* Solution I */\n                newoffset += 2;\n                proto_tree_add_item(t, hf_hip_tlv_solution_i, tvb, newoffset, (tlv_len - 4)/2, ENC_NA);\n                /* Solution J */\n                newoffset += (tlv_len - 4) /2;\n                proto_tree_add_item(t, hf_hip_tlv_solution_j, tvb, newoffset, (tlv_len -4)/2, ENC_NA);\n                break;\n        case PARAM_SEQ:\n                /* Update ID */\n                proto_tree_add_item(t, hf_hip_tlv_seq_updid, tvb, newoffset, 4, ENC_BIG_ENDIAN);\n                break;\n        case PARAM_ACK:\n                /* Can contain multiple Update IDs from peer */\n                while (tlv_len > 0) {\n                        /* peer Update ID */\n                        proto_tree_add_item(t, hf_hip_tlv_ack_updid, tvb, newoffset, 4, ENC_BIG_ENDIAN);\n                        newoffset += 4;\n                        tlv_len -= 4;\n                }\n                break;\n        case PARAM_DIFFIE_HELLMAN:\n                n = tvb_get_guint8(tvb, newoffset);\n                /* First Group ID*/\n                proto_tree_add_uint_format(t, hf_hip_tlv_dh_group_id, tvb, newoffset,\n                                           1, n, \"%u (%s)\", n,\n                                           val_to_str_const(n, dh_group_id_vals, \"Unknown\"));\n                /* First Public value len */\n                newoffset++;\n                pv_len = tvb_get_ntohs(tvb, newoffset);\n                proto_tree_add_item(t, hf_hip_tlv_dh_pv_length, tvb, newoffset, 2, ENC_BIG_ENDIAN);\n\n                /* First Public value */\n                newoffset += 2;\n                proto_tree_add_item(t, hf_hip_tlv_dh_pub, tvb, newoffset, pv_len, ENC_NA);\n                /* Check for the second group */\n                if ((pv_len + newoffset) < tlv_len) {\n                        /* Second Group ID*/\n                        newoffset += pv_len;\n                        proto_tree_add_uint_format(t, hf_hip_tlv_dh_group_id, tvb, newoffset,\n                                                   1, n, \"%u (%s)\", n,\n                                                   val_to_str_const(n, dh_group_id_vals, \"Unknown\"));\n                        /* Second Public value len */\n                        newoffset += 1;\n                        pv_len = tvb_get_ntohs(tvb, newoffset);\n                        proto_tree_add_item(t, hf_hip_tlv_dh_pv_length, tvb, newoffset, 2, ENC_BIG_ENDIAN);\n                        /* Second Public Value */\n                        newoffset += 2;\n                        proto_tree_add_item(t, hf_hip_tlv_dh_pub, tvb, newoffset,\n                                             pv_len, ENC_NA);\n                }\n                break;\n        case PARAM_ESP_TRANSFORM:\n                /* Reserved */\n                proto_tree_add_item(t, hf_hip_tlv_esp_reserved, tvb, newoffset, 2, ENC_BIG_ENDIAN);\n                newoffset +=2;\n                tlv_len -= 2;\n                while (tlv_len > 0) {\n                        /* Suite # 1, 2, ...,  n\n                         * two bytes per transform id\n                         */\n                        trans = tvb_get_ntohs(tvb, newoffset);\n                        proto_tree_add_uint_format(t, hf_hip_tlv_trans_id, tvb,\n                                                   newoffset, 2, trans, \"%u (%s)\", trans,\n                                                   val_to_str_const(trans, transform_id_vals, \"Unknown\"));\n                        tlv_len -= 2;\n                        newoffset += 2;\n                }\n                break;\n        case PARAM_HIP_TRANSFORM:\n                while (tlv_len > 0) {\n                        /* Suite # 1, 2, ...,  n\n                           two bytes per transform id */\n                        trans = tvb_get_ntohs(tvb, newoffset);\n                        proto_tree_add_uint_format(t, hf_hip_tlv_trans_id, tvb,\n                                                   newoffset, 2, trans, \"%u (%s)\", trans,\n                                                   val_to_str_const(trans, transform_id_vals, \"Unknown\"));\n                        tlv_len -= 2;\n                        newoffset += 2;\n                }\n                break;\n        case PARAM_NAT_TRAVERSAL_MODE:\n                /* Reserved */\n                proto_tree_add_item(t, hf_hip_tlv_esp_reserved, tvb, newoffset, 2, ENC_BIG_ENDIAN);\n                newoffset += 2;\n                tlv_len -= 2;\n                while (tlv_len > 0) {\n                        /* Suite # 1, 2, ...,  n\n                           two bytes per mode id */\n                        trans = tvb_get_ntohs(tvb, newoffset);\n                        proto_tree_add_uint_format(t, hf_hip_tlv_nat_traversal_mode_id, tvb,\n                                                   newoffset, 2, trans, \"%u (%s)\", trans,\n                                                   val_to_str_const(trans, mode_id_vals, \"Unknown\"));\n                        tlv_len -= 2;\n                        newoffset += 2;\n                }\n                break;\n        case PARAM_TRANSACTION_PACING:\n                /* Min Ta */\n                proto_tree_add_item(t, hf_hip_tlv_transaction_minta, tvb, newoffset, 4, ENC_BIG_ENDIAN);\n                break;\n        case PARAM_ENCRYPTED:\n                /* Reserved */\n                proto_tree_add_item(t, hf_hip_tlv_enc_reserved, tvb, newoffset, 4, ENC_BIG_ENDIAN);\n                newoffset += 4;\n                /* IV\n                 * 16 bytes IV for AES CBC RFC 3602\n                 *  8 bytes IV for 3DES CBC RFC 2405\n                 *  0 bytes IV for NULL\n                 *  and\n                 *  encrypted data after that.\n                 */\n                proto_tree_add_item(t, hf_hip_encrypted_parameter_data, tvb, newoffset, tlv_len - 4, ENC_NA);\n                break;\n        case PARAM_HIP_CIPHER:\n                while (tlv_len > 0) {\n                        /* Suite # 1, 2, ...,  n\n                           two bytes per Cipher Suite id */\n                        proto_tree_add_item(t, hf_hip_tlv_cipher_id, tvb, newoffset, 2, ENC_BIG_ENDIAN);\n                        tlv_len -= 2;\n                        newoffset += 2;\n                }\n                break;\n        case PARAM_HIT_SUITE_LIST:\n                while (tlv_len > 0) {\n                        /* Suite # 1, 2, ...,  n\n                           one byte per HIT Suite id.\n                           According to specification, HIT_SUITE_LIST is defined as eight-bit field,\n                           current four-bit HIT Suite-IDs only use the four higher order bits in the ID Field.*/\n                        proto_tree_add_item(t, hf_hip_tlv_hit_suite_id, tvb, newoffset, 1, ENC_BIG_ENDIAN);\n                        tlv_len -= 1;\n                        newoffset += 1;\n                }\n                break;\n        case PARAM_HOST_ID:\n                hi_len = tvb_get_ntohs(tvb, newoffset);\n                hi_len_item = proto_tree_add_item(t, hf_hip_tlv_host_id_len, tvb, newoffset, 2, ENC_BIG_ENDIAN);\n                newoffset += 2;\n                di_len = tvb_get_ntohs(tvb, newoffset);\n                di_type = (di_len >> 12) & 0x000F;        /* get 4 bits for DI type */\n                di_len = di_len & 0x0FFF;                /* 12 bits for DI length */\n                /* DI type */\n                proto_tree_add_item(t, hf_hip_tlv_host_di_type, tvb, newoffset, 1, ENC_BIG_ENDIAN);\n                /* DI len */\n                proto_tree_add_item(t, hf_hip_tlv_host_di_len, tvb, newoffset, 2, ENC_BIG_ENDIAN);\n                newoffset += 2;\n                /* hi_hdr - first 4 bytes are 0200ff03 (KEY RR in RFC 2535)\n                 *   flags     2  octets\n                 *   protocol  1  octet\n                 *   algorithm 1  octet (DSA or RSA)\n                 *   <public key>\n                 */\n                hi_hdr = tvb_get_ntohl(tvb, newoffset);\n                ti_tlv = proto_tree_add_item(t, hf_hip_tlv_host_id_hdr,\n                                             tvb, newoffset, 4, ENC_BIG_ENDIAN);\n\n                ti_tlv = proto_item_add_subtree(ti_tlv, ett_hip_tlv_host_id_hdr);\n                /* HDR Flags*/\n                proto_tree_add_uint(ti_tlv, hf_hip_tlv_host_id_hdr_flags, tvb,\n                                    newoffset, 2, hi_hdr);\n                newoffset += 2;\n                /* HDR Protocol */\n                proto_tree_add_uint(ti_tlv, hf_hip_tlv_host_id_hdr_proto, tvb,\n                                    newoffset, 1,  hi_hdr);\n                newoffset += 1;\n                /* HDR Algorithm */\n                algorithm = tvb_get_guint8(tvb, newoffset);\n                arg_item = proto_tree_add_uint(ti_tlv, hf_hip_tlv_host_id_hdr_alg, tvb,\n                                    newoffset, 1, hi_hdr);\n\n                switch (algorithm) {\n                case HI_ALG_DSA:\n                        /* DSA KEY RR RFC 2536\n                         *   T         1  octet\n                         *   Q         20  octets\n                         *   P         64 + T*8  octets\n                         *   G         64 + T*8  octets\n                         *   Y         64 + T*8  octets\n                         */\n                        newoffset++; /* 12 + offset */\n                        /* T */\n                        proto_tree_add_item(t, hf_hip_tlv_host_id_t, tvb, newoffset, 1, ENC_BIG_ENDIAN);\n                        hi_t = tvb_get_guint8(tvb, newoffset);\n                        newoffset++;\n                        /* Q */\n                        proto_tree_add_item(t, hf_hip_tlv_host_id_q, tvb, newoffset,\n                                             20, ENC_NA);\n                        newoffset += 20;\n                        if (hi_t > 56) /* max 4096 bits */\n                                break;\n                        /* P */\n                        newlen = 64 + (hi_t * 8);\n                        proto_tree_add_item(t, hf_hip_tlv_host_id_p, tvb, newoffset,\n                                             newlen, ENC_NA);\n                        /* G */\n                        newoffset += newlen;\n                        proto_tree_add_item(t, hf_hip_tlv_host_id_g, tvb, newoffset,\n                                             newlen, ENC_NA);\n                        /* Y */\n                        newoffset += newlen;\n                        proto_tree_add_item(t, hf_hip_tlv_host_id_y, tvb, newoffset,\n                                             newlen, ENC_NA);\n                        break;\n                case HI_ALG_RSA:\n                        /* RSA KEY RR RFC 3110\n                         * e_len        1 or 3 octets\n                         * e            specified by e_len\n                         * n            variable length public modulus\n                         */\n                        newoffset++; /* 12 + offset */\n                        /* E len */\n                        e_len = tvb_get_guint8(tvb, newoffset);\n                        e_len_item = proto_tree_add_item(t, hf_hip_tlv_host_id_e_len, tvb, newoffset,\n                                            (e_len > 255) ? 3 : 1, ENC_BIG_ENDIAN);\n                        newoffset++;\n                        hi_len -= 5; /* subtract RDATA + e_len */\n                        if (e_len == 0) { /* e_len is 0 followed by 16-bit value */\n                                e_len = tvb_get_ntohs(tvb, newoffset);\n                                newoffset += 2;\n                                hi_len -= 2;\n                        }\n                        if (e_len > 512) { /* per, RFC 3110 < 4096 bits */\n                                expert_add_info(pinfo, e_len_item, &ei_hip_tlv_host_id_len);\n                                break;\n                        }\n                        /* e */\n                        proto_tree_add_item(t, hf_hip_tlv_host_id_e, tvb, newoffset,\n                                             e_len, ENC_NA);\n                        newoffset += e_len;\n                        hi_len -= e_len;\n\n                        if (hi_len > 512) {\n                                expert_add_info(pinfo, hi_len_item, &ei_hip_tlv_host_id_len);\n                                break;\n                        }\n\n                        /* RSA public modulus n */\n                        proto_tree_add_item(t, hf_hip_tlv_host_id_n, tvb, newoffset,\n                                             hi_len, ENC_NA);\n                        break;\n                default:\n                        expert_add_info(pinfo, arg_item, &ei_hip_tlv_host_id_hdr_alg);\n\n                        break;\n                }\n                /* FQDN */\n                if (di_type == 0)\n                        break;\n                if (di_type == 1) {\n                        /* RFC 1035 */\n                        proto_tree_add_item(t, hf_hip_fqdn, tvb, offset+16+hi_len, di_len, ENC_ASCII|ENC_NA);\n                } else if (di_type == 2) {\n                        /* RFC 4282 */\n                        proto_tree_add_item(t, hf_hip_nai, tvb, offset+16+hi_len, di_len, ENC_ASCII|ENC_NA);\n                }\n                break;\n        case PARAM_CERT: /* CERT */\n                /* Cert Group */\n                proto_tree_add_item(t, hf_hip_tlv_cert_group, tvb, newoffset, 1, ENC_BIG_ENDIAN);\n                newoffset++;\n                /* Cert Count */\n                proto_tree_add_item(t, hf_hip_tlv_cert_count, tvb, newoffset, 1, ENC_BIG_ENDIAN);\n                newoffset++;\n                /* Cert ID */\n                proto_tree_add_item(t, hf_hip_tlv_cert_id, tvb, newoffset, 1, ENC_BIG_ENDIAN);\n                newoffset++;\n                /* Cert Type */\n                proto_tree_add_item(t, hf_hip_tlv_cert_type, tvb, newoffset, 1, ENC_BIG_ENDIAN);\n                newoffset++;\n                /* Certificate */\n                proto_tree_add_item(t, hf_hip_tlv_certificate, tvb, newoffset,\n                                     tlv_len-4, ENC_NA);\n                break;\n        case PARAM_NOTIFICATION:\n                /* Reserved */\n                proto_tree_add_item(t, hf_hip_tlv_notification_res, tvb, newoffset, 2, ENC_BIG_ENDIAN);\n                newoffset += 2;\n                /* Notification Message Type */\n                proto_tree_add_item(t, hf_hip_tlv_notification_type, tvb, newoffset, 2, ENC_BIG_ENDIAN);\n                newoffset += 2;\n                /* Notification Data */\n                proto_tree_add_item(t, hf_hip_tlv_notification_data, tvb, newoffset,\n                                     tlv_len-4, ENC_NA);\n                break;\n        case PARAM_ECHO_REQUEST_SIGNED:\n        case PARAM_ECHO_RESPONSE_SIGNED:\n        case PARAM_ECHO_REQUEST_UNSIGNED:\n        case PARAM_ECHO_RESPONSE_UNSIGNED:\n                /* Variable length Opaque Data */\n                proto_tree_add_item(t, hf_hip_tlv_opaque_data, tvb, newoffset,\n                                     tlv_len, ENC_NA);\n                break;\n        case PARAM_REG_INFO:\n        case PARAM_REG_REQUEST:\n        case PARAM_REG_RESPONSE:\n        case PARAM_REG_FAILED:\n                if (type == PARAM_REG_INFO) {\n                        /* Min Lifetime */\n                        proto_tree_add_item(t, hf_hip_tlv_reg_ltmin, tvb, newoffset, 1, ENC_BIG_ENDIAN);\n                        newoffset++;\n                        /* Max Lifetime */\n                        proto_tree_add_item(t, hf_hip_tlv_reg_ltmax, tvb, newoffset, 1, ENC_BIG_ENDIAN);\n                        newoffset++;\n                        tlv_len -= 2;\n                } else if (type == PARAM_REG_FAILED) {\n                        /* Failure Type */\n                        proto_tree_add_item(t, hf_hip_tlv_reg_failtype, tvb, newoffset, 1, ENC_BIG_ENDIAN);\n                        newoffset++;\n                        tlv_len--;\n                } else {\n                        /* Lifetime */\n                        proto_tree_add_item(t, hf_hip_tlv_reg_lt, tvb, newoffset, 1, ENC_BIG_ENDIAN);\n                        newoffset++;\n                        tlv_len--;\n                }\n                /* Reg Type 1 ... n, Padding */\n                while (tlv_len > 0) {\n                        reg_type = tvb_get_guint8(tvb, newoffset);\n                        proto_tree_add_uint_format(t, hf_hip_tlv_reg_type, tvb,\n                                                   newoffset, 1, reg_type, \"%u (%s)\", reg_type,\n                                                   val_to_str_const(reg_type, reg_type_vals, \"Unknown\"));\n                        /* one byte per registration type */\n                        tlv_len--;\n                        newoffset++;\n                }\n                break;\n        case PARAM_HMAC:\n        case PARAM_HMAC_2:\n        case PARAM_RVS_HMAC:\n        case PARAM_RELAY_HMAC:\n                /* HMAC */\n                proto_tree_add_item(t, hf_hip_tlv_hmac, tvb, offset+4,\n                                     tlv_len, ENC_NA);\n                break;\n        case PARAM_HIP_SIGNATURE:\n        case PARAM_HIP_SIGNATURE_2:\n                /* Signature algorithm */\n                n = tvb_get_guint8(tvb, offset+4);\n                proto_tree_add_uint_format(t, hf_hip_tlv_sig_alg, tvb, newoffset, 1,\n                                           n, \"%u (%s)\", n,\n                                           val_to_str_const(n, sig_alg_vals, \"Unknown\"));\n                newoffset++;\n                /* Signature */\n                proto_tree_add_item(t, hf_hip_tlv_sig, tvb, newoffset, tlv_len-1,\n                                    ENC_NA);\n                break;\n        case PARAM_FROM:\n                /* Address */\n                proto_tree_add_item(t, hf_hip_tlv_from_address, tvb, newoffset, 16, ENC_NA);\n                break;\n        case PARAM_VIA_RVS:\n                /* RVS Addresses  */\n                while (tlv_len > 0) {\n                        proto_tree_add_item(t, hf_hip_tlv_rvs_address, tvb, newoffset, 16, ENC_NA);\n                        tlv_len -= 16;\n                        newoffset += 16;\n                }\n                break;\n        case PARAM_RELAY_FROM:\n                /* Port */\n                proto_tree_add_item(t, hf_hip_tlv_relay_from_port, tvb, newoffset, 2, ENC_BIG_ENDIAN);\n                newoffset += 2;\n                /* Protocol */\n                proto_tree_add_item(t, hf_hip_tlv_relay_from_protocol, tvb, newoffset, 1, ENC_BIG_ENDIAN);\n                newoffset += 1;\n                /* Reserved */\n                proto_tree_add_item(t, hf_hip_tlv_relay_from_reserved, tvb, newoffset, 1, ENC_BIG_ENDIAN);\n                newoffset += 1;\n                /* Address */\n                proto_tree_add_item(t, hf_hip_tlv_relay_from_address, tvb, newoffset, 16, ENC_NA);\n                break;\n        case PARAM_RELAY_TO:\n                /* Port */\n                proto_tree_add_item(t, hf_hip_tlv_relay_to_port, tvb, newoffset, 2, ENC_BIG_ENDIAN);\n                newoffset += 2;\n                /* Protocol */\n                proto_tree_add_item(t, hf_hip_tlv_relay_to_protocol, tvb, newoffset, 1, ENC_BIG_ENDIAN);\n                newoffset += 1;\n                /* Reserved */\n                proto_tree_add_item(t, hf_hip_tlv_relay_to_reserved, tvb, newoffset, 1, ENC_BIG_ENDIAN);\n                newoffset += 1;\n                /* Address */\n                proto_tree_add_item(t, hf_hip_tlv_relay_to_address, tvb, newoffset, 16, ENC_NA);\n                break;\n        case PARAM_REG_FROM:\n                /* Port */\n                proto_tree_add_item(t, hf_hip_tlv_reg_from_port, tvb, newoffset, 2, ENC_BIG_ENDIAN);\n                newoffset += 2;\n                /* Protocol */\n                proto_tree_add_item(t, hf_hip_tlv_reg_from_protocol, tvb, newoffset, 1, ENC_BIG_ENDIAN);\n                newoffset += 1;\n                /* Reserved */\n                proto_tree_add_item(t, hf_hip_tlv_reg_from_reserved, tvb, newoffset, 1, ENC_BIG_ENDIAN);\n                newoffset += 1;\n                /* Address */\n                proto_tree_add_item(t, hf_hip_tlv_reg_from_address, tvb, newoffset, 16, ENC_NA);\n                break;\n        default:\n                break;\n        }\n        return (0);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -62,7 +62,7 @@\n                                 newoffset += (1 + tvb_get_guint8(tvb, newoffset + 2));\n                                 tlv_len -= (1 + tvb_get_guint8(tvb, newoffset + 2));\n                         }\n-                        if (ti_loc) {\n+                        if (locator_type <= 2) {\n                                 ti_loc = proto_item_add_subtree(ti_loc, ett_hip_locator_data);\n                                 /* Traffic type */\n                                 proto_tree_add_item(ti_loc, hf_hip_tlv_locator_traffic_type, tvb,",
        "diff_line_info": {
            "deleted_lines": [
                "                        if (ti_loc) {"
            ],
            "added_lines": [
                "                        if (locator_type <= 2) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-6429",
        "func_name": "wireshark/SnifferDecompress",
        "description": "The SnifferDecompress function in wiretap/ngsniffer.c in the DOS Sniffer file parser in Wireshark 1.10.x before 1.10.10 and 1.12.x before 1.12.1 does not properly handle empty input data, which allows remote attackers to cause a denial of service (application crash) via a crafted file.",
        "git_url": "https://github.com/wireshark/wireshark/commit/47c592938ba9f0caeacc4c2ccadb370e72f293a2",
        "commit_title": "Add some additional checks in SnifferDecompress().",
        "commit_text": " Check the input pointer in the while clause of the loop, so that we handle an empty input buffer.  When reading a bit mask, check before fetching the bit mask that we have two bytes of bit mask and the byte after it.  Before putting an uncompressed input byte into the output, make sure we wouldn't run past the end of the output buffer.  Before copying an earlier string from the output buffer, make sure it doesn't run past the end of the data we've decompressed so far.  Bug: 10461",
        "func_before": "static int\nSnifferDecompress(unsigned char *inbuf, size_t inlen, unsigned char *outbuf,\n\t\t  size_t outlen, int *err)\n{\n\tunsigned char * pin  = inbuf;\n\tunsigned char * pout = outbuf;\n\tunsigned char * pin_end  = pin + inlen;\n\tunsigned char * pout_end = pout + outlen;\n\tunsigned int bit_mask;      /* one bit is set in this, to mask with bit_value */\n\tunsigned int bit_value = 0; /* cache the last 16 coding bits we retrieved */\n\tunsigned int code_type;     /* encoding type, from high 4 bits of byte */\n\tunsigned int code_low;      /* other 4 bits from encoding byte */\n\tint length;\t\t    /* length of RLE sequence or repeated string */\n\tint offset;\t\t    /* offset of string to repeat */\n\n\tif (inlen > G_MAXUINT16) {\n\t\treturn ( -1 );\n\t}\n\n\tbit_mask  = 0;  /* don't have any bits yet */\n\twhile (1)\n\t{\n\t\t/* Shift down the bit mask we use to see whats encoded */\n\t\tbit_mask = bit_mask >> 1;\n\n\t\t/* If there are no bits left, time to get another 16 bits */\n\t\tif ( 0 == bit_mask )\n\t\t{\n\t\t\tbit_mask  = 0x8000;  /* start with the high bit */\n\t\t\tbit_value = pletoh16(pin);   /* get the next 16 bits */\n\t\t\tpin += 2;          /* skip over what we just grabbed */\n\t\t\tif ( pin >= pin_end )\n\t\t\t{\n\t\t\t\t*err = WTAP_ERR_UNC_TRUNCATED;\t /* data was oddly truncated */\n\t\t\t\treturn ( -1 );\n\t\t\t}\n\t\t}\n\n\t\t/* Use the bits in bit_value to see what's encoded and what is raw data */\n\t\tif ( !(bit_mask & bit_value) )\n\t\t{\n\t\t\t/* bit not set - raw byte we just copy */\n\t\t\t*(pout++) = *(pin++);\n\t\t}\n\t\telse\n\t\t{\n\t\t\t/* bit set - next item is encoded.  Peel off high nybble\n\t\t\t   of next byte to see the encoding type.  Set aside low\n\t\t\t   nybble while we are at it */\n\t\t\tcode_type = (unsigned int) ((*pin) >> 4 ) & 0xF;\n\t\t\tcode_low  = (unsigned int) ((*pin) & 0xF );\n\t\t\tpin++;   /* increment over the code byte we just retrieved */\n\t\t\tif ( pin >= pin_end )\n\t\t\t{\n\t\t\t\t*err = WTAP_ERR_UNC_TRUNCATED;\t /* data was oddly truncated */\n\t\t\t\treturn ( -1 );\n\t\t\t}\n\n\t\t\t/* Based on the code type, decode the compressed string */\n\t\t\tswitch ( code_type )\n\t\t\t{\n\t\t\tcase 0  :   /* RLE short runs */\n\t\t\t\t/*\n\t\t\t\t  Run length is the low nybble of the first code byte.\n\t\t\t\t  Byte to repeat immediately follows.\n\t\t\t\t  Total code size: 2 bytes.\n\t\t\t\t*/\n\t\t\t\tlength = code_low + 3;\n\t\t\t\t/* If length would put us past end of output, avoid overflow */\n\t\t\t\tif ( pout + length > pout_end )\n\t\t\t\t{\n\t\t\t\t\t*err = WTAP_ERR_UNC_OVERFLOW;\n\t\t\t\t\treturn ( -1 );\n\t\t\t\t}\n\n\t\t\t\t/* generate the repeated series of bytes */\n\t\t\t\tmemset( pout, *pin++, length );\n\t\t\t\tpout += length;\n\t\t\t\tbreak;\n\t\t\tcase 1  :   /* RLE long runs */\n\t\t\t\t/*\n\t\t\t\t  Low 4 bits of run length is the low nybble of the\n\t\t\t\t  first code byte, upper 8 bits of run length is in\n\t\t\t\t  the next byte.\n\t\t\t\t  Byte to repeat immediately follows.\n\t\t\t\t  Total code size: 3 bytes.\n\t\t\t\t*/\n\t\t\t\tlength = code_low + ((unsigned int)(*pin++) << 4) + 19;\n\t\t\t\t/* If we are already at end of input, there is no byte\n\t\t\t\t   to repeat */\n\t\t\t\tif ( pin >= pin_end )\n\t\t\t\t{\n\t\t\t\t\t*err = WTAP_ERR_UNC_TRUNCATED;\t /* data was oddly truncated */\n\t\t\t\t\treturn ( -1 );\n\t\t\t\t}\n\t\t\t\t/* If length would put us past end of output, avoid overflow */\n\t\t\t\tif ( pout + length > pout_end )\n\t\t\t\t{\n\t\t\t\t\t*err = WTAP_ERR_UNC_OVERFLOW;\n\t\t\t\t\treturn ( -1 );\n\t\t\t\t}\n\n\t\t\t\t/* generate the repeated series of bytes */\n\t\t\t\tmemset( pout, *pin++, length );\n\t\t\t\tpout += length;\n\t\t\t\tbreak;\n\t\t\tcase 2  :   /* LZ77 long strings */\n\t\t\t\t/*\n\t\t\t\t  Low 4 bits of offset to string is the low nybble of the\n\t\t\t\t  first code byte, upper 8 bits of offset is in\n\t\t\t\t  the next byte.\n\t\t\t\t  Length of string immediately follows.\n\t\t\t\t  Total code size: 3 bytes.\n\t\t\t\t*/\n\t\t\t\toffset = code_low + ((unsigned int)(*pin++) << 4) + 3;\n\t\t\t\t/* If we are already at end of input, there is no byte\n\t\t\t\t   to repeat */\n\t\t\t\tif ( pin >= pin_end )\n\t\t\t\t{\n\t\t\t\t\t*err = WTAP_ERR_UNC_TRUNCATED;\t /* data was oddly truncated */\n\t\t\t\t\treturn ( -1 );\n\t\t\t\t}\n\t\t\t\t/* Check if offset would put us back past begin of buffer */\n\t\t\t\tif ( pout - offset < outbuf )\n\t\t\t\t{\n\t\t\t\t\t*err = WTAP_ERR_UNC_BAD_OFFSET;\n\t\t\t\t\treturn ( -1 );\n\t\t\t\t}\n\n\t\t\t\t/* get length from next byte, make sure it won't overrun buf */\n\t\t\t\tlength = (unsigned int)(*pin++) + 16;\n\t\t\t\tif ( pout + length > pout_end )\n\t\t\t\t{\n\t\t\t\t\t*err = WTAP_ERR_UNC_OVERFLOW;\n\t\t\t\t\treturn ( -1 );\n\t\t\t\t}\n\n\t\t\t\t/* Copy the string from previous text to output position,\n\t\t\t\t   advance output pointer */\n\t\t\t\tmemcpy( pout, pout - offset, length );\n\t\t\t\tpout += length;\n\t\t\t\tbreak;\n\t\t\tdefault :   /* (3 to 15): LZ77 short strings */\n\t\t\t\t/*\n\t\t\t\t  Low 4 bits of offset to string is the low nybble of the\n\t\t\t\t  first code byte, upper 8 bits of offset is in\n\t\t\t\t  the next byte.\n\t\t\t\t  Length of string to repeat is overloaded into code_type.\n\t\t\t\t  Total code size: 2 bytes.\n\t\t\t\t*/\n\t\t\t\toffset = code_low + ((unsigned int)(*pin++) << 4) + 3;\n\t\t\t\t/* Check if offset would put us back past begin of buffer */\n\t\t\t\tif ( pout - offset < outbuf )\n\t\t\t\t{\n\t\t\t\t\t*err = WTAP_ERR_UNC_BAD_OFFSET;\n\t\t\t\t\treturn ( -1 );\n\t\t\t\t}\n\n\t\t\t\t/* get length from code_type, make sure it won't overrun buf */\n\t\t\t\tlength = code_type;\n\t\t\t\tif ( pout + length > pout_end )\n\t\t\t\t{\n\t\t\t\t\t*err = WTAP_ERR_UNC_OVERFLOW;\n\t\t\t\t\treturn ( -1 );\n\t\t\t\t}\n\n\t\t\t\t/* Copy the string from previous text to output position,\n\t\t\t\t   advance output pointer */\n\t\t\t\tmemcpy( pout, pout - offset, length );\n\t\t\t\tpout += length;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\t/* If we've consumed all the input, we are done */\n\t\tif ( pin >= pin_end )\n\t\t\tbreak;\n\t}\n\n\treturn (int) ( pout - outbuf );  /* return length of expanded text */\n}",
        "func": "static int\nSnifferDecompress(unsigned char *inbuf, size_t inlen, unsigned char *outbuf,\n\t\t  size_t outlen, int *err)\n{\n\tunsigned char * pin  = inbuf;\n\tunsigned char * pout = outbuf;\n\tunsigned char * pin_end  = pin + inlen;\n\tunsigned char * pout_end = pout + outlen;\n\tunsigned int bit_mask;      /* one bit is set in this, to mask with bit_value */\n\tunsigned int bit_value = 0; /* cache the last 16 coding bits we retrieved */\n\tunsigned int code_type;     /* encoding type, from high 4 bits of byte */\n\tunsigned int code_low;      /* other 4 bits from encoding byte */\n\tint length;\t\t    /* length of RLE sequence or repeated string */\n\tint offset;\t\t    /* offset of string to repeat */\n\n\tif (inlen > G_MAXUINT16) {\n\t\treturn ( -1 );\n\t}\n\n\tbit_mask  = 0;  /* don't have any bits yet */\n\t/* Process until we've consumed all the input */\n\twhile (pin < pin_end)\n\t{\n\t\t/* Shift down the bit mask we use to see whats encoded */\n\t\tbit_mask = bit_mask >> 1;\n\n\t\t/* If there are no bits left, time to get another 16 bits */\n\t\tif ( 0 == bit_mask )\n\t\t{\n\t\t\t/* make sure there are at least *three* bytes\n\t\t\t   available - the two bytes of the bit value,\n\t\t\t   plus one byte after it */\n\t\t\tif ( pin + 2 >= pin_end )\n\t\t\t{\n\t\t\t\t*err = WTAP_ERR_UNC_TRUNCATED;\n\t\t\t\treturn ( -1 );\n\t\t\t}\n\t\t\tbit_mask  = 0x8000;  /* start with the high bit */\n\t\t\tbit_value = pletoh16(pin);   /* get the next 16 bits */\n\t\t\tpin += 2;          /* skip over what we just grabbed */\n\t\t}\n\n\t\t/* Use the bits in bit_value to see what's encoded and what is raw data */\n\t\tif ( !(bit_mask & bit_value) )\n\t\t{\n\t\t\t/* bit not set - raw byte we just copy */\n\n\t\t\t/* If length would put us past end of output, avoid overflow */\n\t\t\tif ( pout + 1 > pout_end )\n\t\t\t{\n\t\t\t\t*err = WTAP_ERR_UNC_OVERFLOW;\n\t\t\t\treturn ( -1 );\n\t\t\t}\n\t\t\t*(pout++) = *(pin++);\n\t\t}\n\t\telse\n\t\t{\n\t\t\t/* bit set - next item is encoded.  Peel off high nybble\n\t\t\t   of next byte to see the encoding type.  Set aside low\n\t\t\t   nybble while we are at it */\n\t\t\tcode_type = (unsigned int) ((*pin) >> 4 ) & 0xF;\n\t\t\tcode_low  = (unsigned int) ((*pin) & 0xF );\n\t\t\tpin++;   /* increment over the code byte we just retrieved */\n\t\t\tif ( pin >= pin_end )\n\t\t\t{\n\t\t\t\t*err = WTAP_ERR_UNC_TRUNCATED;\t /* data was oddly truncated */\n\t\t\t\treturn ( -1 );\n\t\t\t}\n\n\t\t\t/* Based on the code type, decode the compressed string */\n\t\t\tswitch ( code_type )\n\t\t\t{\n\t\t\tcase 0  :   /* RLE short runs */\n\t\t\t\t/*\n\t\t\t\t  Run length is the low nybble of the first code byte.\n\t\t\t\t  Byte to repeat immediately follows.\n\t\t\t\t  Total code size: 2 bytes.\n\t\t\t\t*/\n\t\t\t\tlength = code_low + 3;\n\t\t\t\t/* If length would put us past end of output, avoid overflow */\n\t\t\t\tif ( pout + length > pout_end )\n\t\t\t\t{\n\t\t\t\t\t*err = WTAP_ERR_UNC_OVERFLOW;\n\t\t\t\t\treturn ( -1 );\n\t\t\t\t}\n\n\t\t\t\t/* generate the repeated series of bytes */\n\t\t\t\tmemset( pout, *pin++, length );\n\t\t\t\tpout += length;\n\t\t\t\tbreak;\n\t\t\tcase 1  :   /* RLE long runs */\n\t\t\t\t/*\n\t\t\t\t  Low 4 bits of run length is the low nybble of the\n\t\t\t\t  first code byte, upper 8 bits of run length is in\n\t\t\t\t  the next byte.\n\t\t\t\t  Byte to repeat immediately follows.\n\t\t\t\t  Total code size: 3 bytes.\n\t\t\t\t*/\n\t\t\t\tlength = code_low + ((unsigned int)(*pin++) << 4) + 19;\n\t\t\t\t/* If we are already at end of input, there is no byte\n\t\t\t\t   to repeat */\n\t\t\t\tif ( pin >= pin_end )\n\t\t\t\t{\n\t\t\t\t\t*err = WTAP_ERR_UNC_TRUNCATED;\t /* data was oddly truncated */\n\t\t\t\t\treturn ( -1 );\n\t\t\t\t}\n\t\t\t\t/* If length would put us past end of output, avoid overflow */\n\t\t\t\tif ( pout + length > pout_end )\n\t\t\t\t{\n\t\t\t\t\t*err = WTAP_ERR_UNC_OVERFLOW;\n\t\t\t\t\treturn ( -1 );\n\t\t\t\t}\n\n\t\t\t\t/* generate the repeated series of bytes */\n\t\t\t\tmemset( pout, *pin++, length );\n\t\t\t\tpout += length;\n\t\t\t\tbreak;\n\t\t\tcase 2  :   /* LZ77 long strings */\n\t\t\t\t/*\n\t\t\t\t  Low 4 bits of offset to string is the low nybble of the\n\t\t\t\t  first code byte, upper 8 bits of offset is in\n\t\t\t\t  the next byte.\n\t\t\t\t  Length of string immediately follows.\n\t\t\t\t  Total code size: 3 bytes.\n\t\t\t\t*/\n\t\t\t\toffset = code_low + ((unsigned int)(*pin++) << 4) + 3;\n\t\t\t\t/* If we are already at end of input, there is no byte\n\t\t\t\t   to repeat */\n\t\t\t\tif ( pin >= pin_end )\n\t\t\t\t{\n\t\t\t\t\t*err = WTAP_ERR_UNC_TRUNCATED;\t /* data was oddly truncated */\n\t\t\t\t\treturn ( -1 );\n\t\t\t\t}\n\t\t\t\t/* Check if offset would put us back past begin of buffer */\n\t\t\t\tif ( pout - offset < outbuf )\n\t\t\t\t{\n\t\t\t\t\t*err = WTAP_ERR_UNC_BAD_OFFSET;\n\t\t\t\t\treturn ( -1 );\n\t\t\t\t}\n\n\t\t\t\t/* get length from next byte, make sure it won't overrun buf */\n\t\t\t\tlength = (unsigned int)(*pin++) + 16;\n\t\t\t\tif ( pout + length > pout_end )\n\t\t\t\t{\n\t\t\t\t\t*err = WTAP_ERR_UNC_OVERFLOW;\n\t\t\t\t\treturn ( -1 );\n\t\t\t\t}\n\t\t\t\t/* Check if offset would cause us to copy on top of ourselves */\n\t\t\t\tif ( pout - offset + length > pout )\n\t\t\t\t{\n\t\t\t\t\t*err = WTAP_ERR_UNC_BAD_OFFSET;\n\t\t\t\t\treturn ( -1 );\n\t\t\t\t}\n\n\t\t\t\t/* Copy the string from previous text to output position,\n\t\t\t\t   advance output pointer */\n\t\t\t\tmemcpy( pout, pout - offset, length );\n\t\t\t\tpout += length;\n\t\t\t\tbreak;\n\t\t\tdefault :   /* (3 to 15): LZ77 short strings */\n\t\t\t\t/*\n\t\t\t\t  Low 4 bits of offset to string is the low nybble of the\n\t\t\t\t  first code byte, upper 8 bits of offset is in\n\t\t\t\t  the next byte.\n\t\t\t\t  Length of string to repeat is overloaded into code_type.\n\t\t\t\t  Total code size: 2 bytes.\n\t\t\t\t*/\n\t\t\t\toffset = code_low + ((unsigned int)(*pin++) << 4) + 3;\n\t\t\t\t/* Check if offset would put us back past begin of buffer */\n\t\t\t\tif ( pout - offset < outbuf )\n\t\t\t\t{\n\t\t\t\t\t*err = WTAP_ERR_UNC_BAD_OFFSET;\n\t\t\t\t\treturn ( -1 );\n\t\t\t\t}\n\n\t\t\t\t/* get length from code_type, make sure it won't overrun buf */\n\t\t\t\tlength = code_type;\n\t\t\t\tif ( pout + length > pout_end )\n\t\t\t\t{\n\t\t\t\t\t*err = WTAP_ERR_UNC_OVERFLOW;\n\t\t\t\t\treturn ( -1 );\n\t\t\t\t}\n\t\t\t\t/* Check if offset would cause us to copy on top of ourselves */\n\t\t\t\tif ( pout - offset + length > pout )\n\t\t\t\t{\n\t\t\t\t\t*err = WTAP_ERR_UNC_BAD_OFFSET;\n\t\t\t\t\treturn ( -1 );\n\t\t\t\t}\n\n\t\t\t\t/* Copy the string from previous text to output position,\n\t\t\t\t   advance output pointer */\n\t\t\t\tmemcpy( pout, pout - offset, length );\n\t\t\t\tpout += length;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn (int) ( pout - outbuf );  /* return length of expanded text */\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -18,7 +18,8 @@\n \t}\n \n \tbit_mask  = 0;  /* don't have any bits yet */\n-\twhile (1)\n+\t/* Process until we've consumed all the input */\n+\twhile (pin < pin_end)\n \t{\n \t\t/* Shift down the bit mask we use to see whats encoded */\n \t\tbit_mask = bit_mask >> 1;\n@@ -26,20 +27,30 @@\n \t\t/* If there are no bits left, time to get another 16 bits */\n \t\tif ( 0 == bit_mask )\n \t\t{\n+\t\t\t/* make sure there are at least *three* bytes\n+\t\t\t   available - the two bytes of the bit value,\n+\t\t\t   plus one byte after it */\n+\t\t\tif ( pin + 2 >= pin_end )\n+\t\t\t{\n+\t\t\t\t*err = WTAP_ERR_UNC_TRUNCATED;\n+\t\t\t\treturn ( -1 );\n+\t\t\t}\n \t\t\tbit_mask  = 0x8000;  /* start with the high bit */\n \t\t\tbit_value = pletoh16(pin);   /* get the next 16 bits */\n \t\t\tpin += 2;          /* skip over what we just grabbed */\n-\t\t\tif ( pin >= pin_end )\n-\t\t\t{\n-\t\t\t\t*err = WTAP_ERR_UNC_TRUNCATED;\t /* data was oddly truncated */\n-\t\t\t\treturn ( -1 );\n-\t\t\t}\n \t\t}\n \n \t\t/* Use the bits in bit_value to see what's encoded and what is raw data */\n \t\tif ( !(bit_mask & bit_value) )\n \t\t{\n \t\t\t/* bit not set - raw byte we just copy */\n+\n+\t\t\t/* If length would put us past end of output, avoid overflow */\n+\t\t\tif ( pout + 1 > pout_end )\n+\t\t\t{\n+\t\t\t\t*err = WTAP_ERR_UNC_OVERFLOW;\n+\t\t\t\treturn ( -1 );\n+\t\t\t}\n \t\t\t*(pout++) = *(pin++);\n \t\t}\n \t\telse\n@@ -134,6 +145,12 @@\n \t\t\t\t\t*err = WTAP_ERR_UNC_OVERFLOW;\n \t\t\t\t\treturn ( -1 );\n \t\t\t\t}\n+\t\t\t\t/* Check if offset would cause us to copy on top of ourselves */\n+\t\t\t\tif ( pout - offset + length > pout )\n+\t\t\t\t{\n+\t\t\t\t\t*err = WTAP_ERR_UNC_BAD_OFFSET;\n+\t\t\t\t\treturn ( -1 );\n+\t\t\t\t}\n \n \t\t\t\t/* Copy the string from previous text to output position,\n \t\t\t\t   advance output pointer */\n@@ -163,6 +180,12 @@\n \t\t\t\t\t*err = WTAP_ERR_UNC_OVERFLOW;\n \t\t\t\t\treturn ( -1 );\n \t\t\t\t}\n+\t\t\t\t/* Check if offset would cause us to copy on top of ourselves */\n+\t\t\t\tif ( pout - offset + length > pout )\n+\t\t\t\t{\n+\t\t\t\t\t*err = WTAP_ERR_UNC_BAD_OFFSET;\n+\t\t\t\t\treturn ( -1 );\n+\t\t\t\t}\n \n \t\t\t\t/* Copy the string from previous text to output position,\n \t\t\t\t   advance output pointer */\n@@ -171,10 +194,6 @@\n \t\t\t\tbreak;\n \t\t\t}\n \t\t}\n-\n-\t\t/* If we've consumed all the input, we are done */\n-\t\tif ( pin >= pin_end )\n-\t\t\tbreak;\n \t}\n \n \treturn (int) ( pout - outbuf );  /* return length of expanded text */",
        "diff_line_info": {
            "deleted_lines": [
                "\twhile (1)",
                "\t\t\tif ( pin >= pin_end )",
                "\t\t\t{",
                "\t\t\t\t*err = WTAP_ERR_UNC_TRUNCATED;\t /* data was oddly truncated */",
                "\t\t\t\treturn ( -1 );",
                "\t\t\t}",
                "",
                "\t\t/* If we've consumed all the input, we are done */",
                "\t\tif ( pin >= pin_end )",
                "\t\t\tbreak;"
            ],
            "added_lines": [
                "\t/* Process until we've consumed all the input */",
                "\twhile (pin < pin_end)",
                "\t\t\t/* make sure there are at least *three* bytes",
                "\t\t\t   available - the two bytes of the bit value,",
                "\t\t\t   plus one byte after it */",
                "\t\t\tif ( pin + 2 >= pin_end )",
                "\t\t\t{",
                "\t\t\t\t*err = WTAP_ERR_UNC_TRUNCATED;",
                "\t\t\t\treturn ( -1 );",
                "\t\t\t}",
                "",
                "\t\t\t/* If length would put us past end of output, avoid overflow */",
                "\t\t\tif ( pout + 1 > pout_end )",
                "\t\t\t{",
                "\t\t\t\t*err = WTAP_ERR_UNC_OVERFLOW;",
                "\t\t\t\treturn ( -1 );",
                "\t\t\t}",
                "\t\t\t\t/* Check if offset would cause us to copy on top of ourselves */",
                "\t\t\t\tif ( pout - offset + length > pout )",
                "\t\t\t\t{",
                "\t\t\t\t\t*err = WTAP_ERR_UNC_BAD_OFFSET;",
                "\t\t\t\t\treturn ( -1 );",
                "\t\t\t\t}",
                "\t\t\t\t/* Check if offset would cause us to copy on top of ourselves */",
                "\t\t\t\tif ( pout - offset + length > pout )",
                "\t\t\t\t{",
                "\t\t\t\t\t*err = WTAP_ERR_UNC_BAD_OFFSET;",
                "\t\t\t\t\treturn ( -1 );",
                "\t\t\t\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-6410",
        "func_name": "torvalds/linux/__udf_read_inode",
        "description": "The __udf_read_inode function in fs/udf/inode.c in the Linux kernel through 3.16.3 does not restrict the amount of ICB indirection, which allows physically proximate attackers to cause a denial of service (infinite loop or stack consumption) via a UDF filesystem with a crafted inode.",
        "git_url": "https://github.com/torvalds/linux/commit/c03aa9f6e1f938618e6db2e23afef0574efeeb65",
        "commit_title": "udf: Avoid infinite loop when processing indirect ICBs",
        "commit_text": " We did not implement any bound on number of indirect ICBs we follow when loading inode. Thus corrupted medium could cause kernel to go into an infinite loop, possibly causing a stack overflow.  Fix the possible stack overflow by removing recursion from __udf_read_inode() and limit number of indirect ICBs we follow to avoid infinite loops. ",
        "func_before": "static void __udf_read_inode(struct inode *inode)\n{\n\tstruct buffer_head *bh = NULL;\n\tstruct fileEntry *fe;\n\tstruct extendedFileEntry *efe;\n\tuint16_t ident;\n\tstruct udf_inode_info *iinfo = UDF_I(inode);\n\tstruct udf_sb_info *sbi = UDF_SB(inode->i_sb);\n\tunsigned int link_count;\n\n\t/*\n\t * Set defaults, but the inode is still incomplete!\n\t * Note: get_new_inode() sets the following on a new inode:\n\t *      i_sb = sb\n\t *      i_no = ino\n\t *      i_flags = sb->s_flags\n\t *      i_state = 0\n\t * clean_inode(): zero fills and sets\n\t *      i_count = 1\n\t *      i_nlink = 1\n\t *      i_op = NULL;\n\t */\n\tbh = udf_read_ptagged(inode->i_sb, &iinfo->i_location, 0, &ident);\n\tif (!bh) {\n\t\tudf_err(inode->i_sb, \"(ino %ld) failed !bh\\n\", inode->i_ino);\n\t\tmake_bad_inode(inode);\n\t\treturn;\n\t}\n\n\tif (ident != TAG_IDENT_FE && ident != TAG_IDENT_EFE &&\n\t    ident != TAG_IDENT_USE) {\n\t\tudf_err(inode->i_sb, \"(ino %ld) failed ident=%d\\n\",\n\t\t\tinode->i_ino, ident);\n\t\tbrelse(bh);\n\t\tmake_bad_inode(inode);\n\t\treturn;\n\t}\n\n\tfe = (struct fileEntry *)bh->b_data;\n\tefe = (struct extendedFileEntry *)bh->b_data;\n\n\tif (fe->icbTag.strategyType == cpu_to_le16(4096)) {\n\t\tstruct buffer_head *ibh;\n\n\t\tibh = udf_read_ptagged(inode->i_sb, &iinfo->i_location, 1,\n\t\t\t\t\t&ident);\n\t\tif (ident == TAG_IDENT_IE && ibh) {\n\t\t\tstruct buffer_head *nbh = NULL;\n\t\t\tstruct kernel_lb_addr loc;\n\t\t\tstruct indirectEntry *ie;\n\n\t\t\tie = (struct indirectEntry *)ibh->b_data;\n\t\t\tloc = lelb_to_cpu(ie->indirectICB.extLocation);\n\n\t\t\tif (ie->indirectICB.extLength &&\n\t\t\t\t(nbh = udf_read_ptagged(inode->i_sb, &loc, 0,\n\t\t\t\t\t\t\t&ident))) {\n\t\t\t\tif (ident == TAG_IDENT_FE ||\n\t\t\t\t\tident == TAG_IDENT_EFE) {\n\t\t\t\t\tmemcpy(&iinfo->i_location,\n\t\t\t\t\t\t&loc,\n\t\t\t\t\t\tsizeof(struct kernel_lb_addr));\n\t\t\t\t\tbrelse(bh);\n\t\t\t\t\tbrelse(ibh);\n\t\t\t\t\tbrelse(nbh);\n\t\t\t\t\t__udf_read_inode(inode);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\tbrelse(nbh);\n\t\t\t}\n\t\t}\n\t\tbrelse(ibh);\n\t} else if (fe->icbTag.strategyType != cpu_to_le16(4)) {\n\t\tudf_err(inode->i_sb, \"unsupported strategy type: %d\\n\",\n\t\t\tle16_to_cpu(fe->icbTag.strategyType));\n\t\tbrelse(bh);\n\t\tmake_bad_inode(inode);\n\t\treturn;\n\t}\n\tif (fe->icbTag.strategyType == cpu_to_le16(4))\n\t\tiinfo->i_strat4096 = 0;\n\telse /* if (fe->icbTag.strategyType == cpu_to_le16(4096)) */\n\t\tiinfo->i_strat4096 = 1;\n\n\tiinfo->i_alloc_type = le16_to_cpu(fe->icbTag.flags) &\n\t\t\t\t\t\t\tICBTAG_FLAG_AD_MASK;\n\tiinfo->i_unique = 0;\n\tiinfo->i_lenEAttr = 0;\n\tiinfo->i_lenExtents = 0;\n\tiinfo->i_lenAlloc = 0;\n\tiinfo->i_next_alloc_block = 0;\n\tiinfo->i_next_alloc_goal = 0;\n\tif (fe->descTag.tagIdent == cpu_to_le16(TAG_IDENT_EFE)) {\n\t\tiinfo->i_efe = 1;\n\t\tiinfo->i_use = 0;\n\t\tif (udf_alloc_i_data(inode, inode->i_sb->s_blocksize -\n\t\t\t\t\tsizeof(struct extendedFileEntry))) {\n\t\t\tmake_bad_inode(inode);\n\t\t\treturn;\n\t\t}\n\t\tmemcpy(iinfo->i_ext.i_data,\n\t\t       bh->b_data + sizeof(struct extendedFileEntry),\n\t\t       inode->i_sb->s_blocksize -\n\t\t\t\t\tsizeof(struct extendedFileEntry));\n\t} else if (fe->descTag.tagIdent == cpu_to_le16(TAG_IDENT_FE)) {\n\t\tiinfo->i_efe = 0;\n\t\tiinfo->i_use = 0;\n\t\tif (udf_alloc_i_data(inode, inode->i_sb->s_blocksize -\n\t\t\t\t\t\tsizeof(struct fileEntry))) {\n\t\t\tmake_bad_inode(inode);\n\t\t\treturn;\n\t\t}\n\t\tmemcpy(iinfo->i_ext.i_data,\n\t\t       bh->b_data + sizeof(struct fileEntry),\n\t\t       inode->i_sb->s_blocksize - sizeof(struct fileEntry));\n\t} else if (fe->descTag.tagIdent == cpu_to_le16(TAG_IDENT_USE)) {\n\t\tiinfo->i_efe = 0;\n\t\tiinfo->i_use = 1;\n\t\tiinfo->i_lenAlloc = le32_to_cpu(\n\t\t\t\t((struct unallocSpaceEntry *)bh->b_data)->\n\t\t\t\t lengthAllocDescs);\n\t\tif (udf_alloc_i_data(inode, inode->i_sb->s_blocksize -\n\t\t\t\t\tsizeof(struct unallocSpaceEntry))) {\n\t\t\tmake_bad_inode(inode);\n\t\t\treturn;\n\t\t}\n\t\tmemcpy(iinfo->i_ext.i_data,\n\t\t       bh->b_data + sizeof(struct unallocSpaceEntry),\n\t\t       inode->i_sb->s_blocksize -\n\t\t\t\t\tsizeof(struct unallocSpaceEntry));\n\t\treturn;\n\t}\n\n\tread_lock(&sbi->s_cred_lock);\n\ti_uid_write(inode, le32_to_cpu(fe->uid));\n\tif (!uid_valid(inode->i_uid) ||\n\t    UDF_QUERY_FLAG(inode->i_sb, UDF_FLAG_UID_IGNORE) ||\n\t    UDF_QUERY_FLAG(inode->i_sb, UDF_FLAG_UID_SET))\n\t\tinode->i_uid = UDF_SB(inode->i_sb)->s_uid;\n\n\ti_gid_write(inode, le32_to_cpu(fe->gid));\n\tif (!gid_valid(inode->i_gid) ||\n\t    UDF_QUERY_FLAG(inode->i_sb, UDF_FLAG_GID_IGNORE) ||\n\t    UDF_QUERY_FLAG(inode->i_sb, UDF_FLAG_GID_SET))\n\t\tinode->i_gid = UDF_SB(inode->i_sb)->s_gid;\n\n\tif (fe->icbTag.fileType != ICBTAG_FILE_TYPE_DIRECTORY &&\n\t\t\tsbi->s_fmode != UDF_INVALID_MODE)\n\t\tinode->i_mode = sbi->s_fmode;\n\telse if (fe->icbTag.fileType == ICBTAG_FILE_TYPE_DIRECTORY &&\n\t\t\tsbi->s_dmode != UDF_INVALID_MODE)\n\t\tinode->i_mode = sbi->s_dmode;\n\telse\n\t\tinode->i_mode = udf_convert_permissions(fe);\n\tinode->i_mode &= ~sbi->s_umask;\n\tread_unlock(&sbi->s_cred_lock);\n\n\tlink_count = le16_to_cpu(fe->fileLinkCount);\n\tif (!link_count)\n\t\tlink_count = 1;\n\tset_nlink(inode, link_count);\n\n\tinode->i_size = le64_to_cpu(fe->informationLength);\n\tiinfo->i_lenExtents = inode->i_size;\n\n\tif (iinfo->i_efe == 0) {\n\t\tinode->i_blocks = le64_to_cpu(fe->logicalBlocksRecorded) <<\n\t\t\t(inode->i_sb->s_blocksize_bits - 9);\n\n\t\tif (!udf_disk_stamp_to_time(&inode->i_atime, fe->accessTime))\n\t\t\tinode->i_atime = sbi->s_record_time;\n\n\t\tif (!udf_disk_stamp_to_time(&inode->i_mtime,\n\t\t\t\t\t    fe->modificationTime))\n\t\t\tinode->i_mtime = sbi->s_record_time;\n\n\t\tif (!udf_disk_stamp_to_time(&inode->i_ctime, fe->attrTime))\n\t\t\tinode->i_ctime = sbi->s_record_time;\n\n\t\tiinfo->i_unique = le64_to_cpu(fe->uniqueID);\n\t\tiinfo->i_lenEAttr = le32_to_cpu(fe->lengthExtendedAttr);\n\t\tiinfo->i_lenAlloc = le32_to_cpu(fe->lengthAllocDescs);\n\t\tiinfo->i_checkpoint = le32_to_cpu(fe->checkpoint);\n\t} else {\n\t\tinode->i_blocks = le64_to_cpu(efe->logicalBlocksRecorded) <<\n\t\t    (inode->i_sb->s_blocksize_bits - 9);\n\n\t\tif (!udf_disk_stamp_to_time(&inode->i_atime, efe->accessTime))\n\t\t\tinode->i_atime = sbi->s_record_time;\n\n\t\tif (!udf_disk_stamp_to_time(&inode->i_mtime,\n\t\t\t\t\t    efe->modificationTime))\n\t\t\tinode->i_mtime = sbi->s_record_time;\n\n\t\tif (!udf_disk_stamp_to_time(&iinfo->i_crtime, efe->createTime))\n\t\t\tiinfo->i_crtime = sbi->s_record_time;\n\n\t\tif (!udf_disk_stamp_to_time(&inode->i_ctime, efe->attrTime))\n\t\t\tinode->i_ctime = sbi->s_record_time;\n\n\t\tiinfo->i_unique = le64_to_cpu(efe->uniqueID);\n\t\tiinfo->i_lenEAttr = le32_to_cpu(efe->lengthExtendedAttr);\n\t\tiinfo->i_lenAlloc = le32_to_cpu(efe->lengthAllocDescs);\n\t\tiinfo->i_checkpoint = le32_to_cpu(efe->checkpoint);\n\t}\n\n\tswitch (fe->icbTag.fileType) {\n\tcase ICBTAG_FILE_TYPE_DIRECTORY:\n\t\tinode->i_op = &udf_dir_inode_operations;\n\t\tinode->i_fop = &udf_dir_operations;\n\t\tinode->i_mode |= S_IFDIR;\n\t\tinc_nlink(inode);\n\t\tbreak;\n\tcase ICBTAG_FILE_TYPE_REALTIME:\n\tcase ICBTAG_FILE_TYPE_REGULAR:\n\tcase ICBTAG_FILE_TYPE_UNDEF:\n\tcase ICBTAG_FILE_TYPE_VAT20:\n\t\tif (iinfo->i_alloc_type == ICBTAG_FLAG_AD_IN_ICB)\n\t\t\tinode->i_data.a_ops = &udf_adinicb_aops;\n\t\telse\n\t\t\tinode->i_data.a_ops = &udf_aops;\n\t\tinode->i_op = &udf_file_inode_operations;\n\t\tinode->i_fop = &udf_file_operations;\n\t\tinode->i_mode |= S_IFREG;\n\t\tbreak;\n\tcase ICBTAG_FILE_TYPE_BLOCK:\n\t\tinode->i_mode |= S_IFBLK;\n\t\tbreak;\n\tcase ICBTAG_FILE_TYPE_CHAR:\n\t\tinode->i_mode |= S_IFCHR;\n\t\tbreak;\n\tcase ICBTAG_FILE_TYPE_FIFO:\n\t\tinit_special_inode(inode, inode->i_mode | S_IFIFO, 0);\n\t\tbreak;\n\tcase ICBTAG_FILE_TYPE_SOCKET:\n\t\tinit_special_inode(inode, inode->i_mode | S_IFSOCK, 0);\n\t\tbreak;\n\tcase ICBTAG_FILE_TYPE_SYMLINK:\n\t\tinode->i_data.a_ops = &udf_symlink_aops;\n\t\tinode->i_op = &udf_symlink_inode_operations;\n\t\tinode->i_mode = S_IFLNK | S_IRWXUGO;\n\t\tbreak;\n\tcase ICBTAG_FILE_TYPE_MAIN:\n\t\tudf_debug(\"METADATA FILE-----\\n\");\n\t\tbreak;\n\tcase ICBTAG_FILE_TYPE_MIRROR:\n\t\tudf_debug(\"METADATA MIRROR FILE-----\\n\");\n\t\tbreak;\n\tcase ICBTAG_FILE_TYPE_BITMAP:\n\t\tudf_debug(\"METADATA BITMAP FILE-----\\n\");\n\t\tbreak;\n\tdefault:\n\t\tudf_err(inode->i_sb, \"(ino %ld) failed unknown file type=%d\\n\",\n\t\t\tinode->i_ino, fe->icbTag.fileType);\n\t\tmake_bad_inode(inode);\n\t\treturn;\n\t}\n\tif (S_ISCHR(inode->i_mode) || S_ISBLK(inode->i_mode)) {\n\t\tstruct deviceSpec *dsea =\n\t\t\t(struct deviceSpec *)udf_get_extendedattr(inode, 12, 1);\n\t\tif (dsea) {\n\t\t\tinit_special_inode(inode, inode->i_mode,\n\t\t\t\tMKDEV(le32_to_cpu(dsea->majorDeviceIdent),\n\t\t\t\t      le32_to_cpu(dsea->minorDeviceIdent)));\n\t\t\t/* Developer ID ??? */\n\t\t} else\n\t\t\tmake_bad_inode(inode);\n\t}\n\tbrelse(bh);\n}",
        "func": "static void __udf_read_inode(struct inode *inode)\n{\n\tstruct buffer_head *bh = NULL;\n\tstruct fileEntry *fe;\n\tstruct extendedFileEntry *efe;\n\tuint16_t ident;\n\tstruct udf_inode_info *iinfo = UDF_I(inode);\n\tstruct udf_sb_info *sbi = UDF_SB(inode->i_sb);\n\tunsigned int link_count;\n\tunsigned int indirections = 0;\n\nreread:\n\t/*\n\t * Set defaults, but the inode is still incomplete!\n\t * Note: get_new_inode() sets the following on a new inode:\n\t *      i_sb = sb\n\t *      i_no = ino\n\t *      i_flags = sb->s_flags\n\t *      i_state = 0\n\t * clean_inode(): zero fills and sets\n\t *      i_count = 1\n\t *      i_nlink = 1\n\t *      i_op = NULL;\n\t */\n\tbh = udf_read_ptagged(inode->i_sb, &iinfo->i_location, 0, &ident);\n\tif (!bh) {\n\t\tudf_err(inode->i_sb, \"(ino %ld) failed !bh\\n\", inode->i_ino);\n\t\tmake_bad_inode(inode);\n\t\treturn;\n\t}\n\n\tif (ident != TAG_IDENT_FE && ident != TAG_IDENT_EFE &&\n\t    ident != TAG_IDENT_USE) {\n\t\tudf_err(inode->i_sb, \"(ino %ld) failed ident=%d\\n\",\n\t\t\tinode->i_ino, ident);\n\t\tbrelse(bh);\n\t\tmake_bad_inode(inode);\n\t\treturn;\n\t}\n\n\tfe = (struct fileEntry *)bh->b_data;\n\tefe = (struct extendedFileEntry *)bh->b_data;\n\n\tif (fe->icbTag.strategyType == cpu_to_le16(4096)) {\n\t\tstruct buffer_head *ibh;\n\n\t\tibh = udf_read_ptagged(inode->i_sb, &iinfo->i_location, 1,\n\t\t\t\t\t&ident);\n\t\tif (ident == TAG_IDENT_IE && ibh) {\n\t\t\tstruct kernel_lb_addr loc;\n\t\t\tstruct indirectEntry *ie;\n\n\t\t\tie = (struct indirectEntry *)ibh->b_data;\n\t\t\tloc = lelb_to_cpu(ie->indirectICB.extLocation);\n\n\t\t\tif (ie->indirectICB.extLength) {\n\t\t\t\tbrelse(bh);\n\t\t\t\tbrelse(ibh);\n\t\t\t\tmemcpy(&iinfo->i_location, &loc,\n\t\t\t\t       sizeof(struct kernel_lb_addr));\n\t\t\t\tif (++indirections > UDF_MAX_ICB_NESTING) {\n\t\t\t\t\tudf_err(inode->i_sb,\n\t\t\t\t\t\t\"too many ICBs in ICB hierarchy\"\n\t\t\t\t\t\t\" (max %d supported)\\n\",\n\t\t\t\t\t\tUDF_MAX_ICB_NESTING);\n\t\t\t\t\tmake_bad_inode(inode);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\tgoto reread;\n\t\t\t}\n\t\t}\n\t\tbrelse(ibh);\n\t} else if (fe->icbTag.strategyType != cpu_to_le16(4)) {\n\t\tudf_err(inode->i_sb, \"unsupported strategy type: %d\\n\",\n\t\t\tle16_to_cpu(fe->icbTag.strategyType));\n\t\tbrelse(bh);\n\t\tmake_bad_inode(inode);\n\t\treturn;\n\t}\n\tif (fe->icbTag.strategyType == cpu_to_le16(4))\n\t\tiinfo->i_strat4096 = 0;\n\telse /* if (fe->icbTag.strategyType == cpu_to_le16(4096)) */\n\t\tiinfo->i_strat4096 = 1;\n\n\tiinfo->i_alloc_type = le16_to_cpu(fe->icbTag.flags) &\n\t\t\t\t\t\t\tICBTAG_FLAG_AD_MASK;\n\tiinfo->i_unique = 0;\n\tiinfo->i_lenEAttr = 0;\n\tiinfo->i_lenExtents = 0;\n\tiinfo->i_lenAlloc = 0;\n\tiinfo->i_next_alloc_block = 0;\n\tiinfo->i_next_alloc_goal = 0;\n\tif (fe->descTag.tagIdent == cpu_to_le16(TAG_IDENT_EFE)) {\n\t\tiinfo->i_efe = 1;\n\t\tiinfo->i_use = 0;\n\t\tif (udf_alloc_i_data(inode, inode->i_sb->s_blocksize -\n\t\t\t\t\tsizeof(struct extendedFileEntry))) {\n\t\t\tmake_bad_inode(inode);\n\t\t\treturn;\n\t\t}\n\t\tmemcpy(iinfo->i_ext.i_data,\n\t\t       bh->b_data + sizeof(struct extendedFileEntry),\n\t\t       inode->i_sb->s_blocksize -\n\t\t\t\t\tsizeof(struct extendedFileEntry));\n\t} else if (fe->descTag.tagIdent == cpu_to_le16(TAG_IDENT_FE)) {\n\t\tiinfo->i_efe = 0;\n\t\tiinfo->i_use = 0;\n\t\tif (udf_alloc_i_data(inode, inode->i_sb->s_blocksize -\n\t\t\t\t\t\tsizeof(struct fileEntry))) {\n\t\t\tmake_bad_inode(inode);\n\t\t\treturn;\n\t\t}\n\t\tmemcpy(iinfo->i_ext.i_data,\n\t\t       bh->b_data + sizeof(struct fileEntry),\n\t\t       inode->i_sb->s_blocksize - sizeof(struct fileEntry));\n\t} else if (fe->descTag.tagIdent == cpu_to_le16(TAG_IDENT_USE)) {\n\t\tiinfo->i_efe = 0;\n\t\tiinfo->i_use = 1;\n\t\tiinfo->i_lenAlloc = le32_to_cpu(\n\t\t\t\t((struct unallocSpaceEntry *)bh->b_data)->\n\t\t\t\t lengthAllocDescs);\n\t\tif (udf_alloc_i_data(inode, inode->i_sb->s_blocksize -\n\t\t\t\t\tsizeof(struct unallocSpaceEntry))) {\n\t\t\tmake_bad_inode(inode);\n\t\t\treturn;\n\t\t}\n\t\tmemcpy(iinfo->i_ext.i_data,\n\t\t       bh->b_data + sizeof(struct unallocSpaceEntry),\n\t\t       inode->i_sb->s_blocksize -\n\t\t\t\t\tsizeof(struct unallocSpaceEntry));\n\t\treturn;\n\t}\n\n\tread_lock(&sbi->s_cred_lock);\n\ti_uid_write(inode, le32_to_cpu(fe->uid));\n\tif (!uid_valid(inode->i_uid) ||\n\t    UDF_QUERY_FLAG(inode->i_sb, UDF_FLAG_UID_IGNORE) ||\n\t    UDF_QUERY_FLAG(inode->i_sb, UDF_FLAG_UID_SET))\n\t\tinode->i_uid = UDF_SB(inode->i_sb)->s_uid;\n\n\ti_gid_write(inode, le32_to_cpu(fe->gid));\n\tif (!gid_valid(inode->i_gid) ||\n\t    UDF_QUERY_FLAG(inode->i_sb, UDF_FLAG_GID_IGNORE) ||\n\t    UDF_QUERY_FLAG(inode->i_sb, UDF_FLAG_GID_SET))\n\t\tinode->i_gid = UDF_SB(inode->i_sb)->s_gid;\n\n\tif (fe->icbTag.fileType != ICBTAG_FILE_TYPE_DIRECTORY &&\n\t\t\tsbi->s_fmode != UDF_INVALID_MODE)\n\t\tinode->i_mode = sbi->s_fmode;\n\telse if (fe->icbTag.fileType == ICBTAG_FILE_TYPE_DIRECTORY &&\n\t\t\tsbi->s_dmode != UDF_INVALID_MODE)\n\t\tinode->i_mode = sbi->s_dmode;\n\telse\n\t\tinode->i_mode = udf_convert_permissions(fe);\n\tinode->i_mode &= ~sbi->s_umask;\n\tread_unlock(&sbi->s_cred_lock);\n\n\tlink_count = le16_to_cpu(fe->fileLinkCount);\n\tif (!link_count)\n\t\tlink_count = 1;\n\tset_nlink(inode, link_count);\n\n\tinode->i_size = le64_to_cpu(fe->informationLength);\n\tiinfo->i_lenExtents = inode->i_size;\n\n\tif (iinfo->i_efe == 0) {\n\t\tinode->i_blocks = le64_to_cpu(fe->logicalBlocksRecorded) <<\n\t\t\t(inode->i_sb->s_blocksize_bits - 9);\n\n\t\tif (!udf_disk_stamp_to_time(&inode->i_atime, fe->accessTime))\n\t\t\tinode->i_atime = sbi->s_record_time;\n\n\t\tif (!udf_disk_stamp_to_time(&inode->i_mtime,\n\t\t\t\t\t    fe->modificationTime))\n\t\t\tinode->i_mtime = sbi->s_record_time;\n\n\t\tif (!udf_disk_stamp_to_time(&inode->i_ctime, fe->attrTime))\n\t\t\tinode->i_ctime = sbi->s_record_time;\n\n\t\tiinfo->i_unique = le64_to_cpu(fe->uniqueID);\n\t\tiinfo->i_lenEAttr = le32_to_cpu(fe->lengthExtendedAttr);\n\t\tiinfo->i_lenAlloc = le32_to_cpu(fe->lengthAllocDescs);\n\t\tiinfo->i_checkpoint = le32_to_cpu(fe->checkpoint);\n\t} else {\n\t\tinode->i_blocks = le64_to_cpu(efe->logicalBlocksRecorded) <<\n\t\t    (inode->i_sb->s_blocksize_bits - 9);\n\n\t\tif (!udf_disk_stamp_to_time(&inode->i_atime, efe->accessTime))\n\t\t\tinode->i_atime = sbi->s_record_time;\n\n\t\tif (!udf_disk_stamp_to_time(&inode->i_mtime,\n\t\t\t\t\t    efe->modificationTime))\n\t\t\tinode->i_mtime = sbi->s_record_time;\n\n\t\tif (!udf_disk_stamp_to_time(&iinfo->i_crtime, efe->createTime))\n\t\t\tiinfo->i_crtime = sbi->s_record_time;\n\n\t\tif (!udf_disk_stamp_to_time(&inode->i_ctime, efe->attrTime))\n\t\t\tinode->i_ctime = sbi->s_record_time;\n\n\t\tiinfo->i_unique = le64_to_cpu(efe->uniqueID);\n\t\tiinfo->i_lenEAttr = le32_to_cpu(efe->lengthExtendedAttr);\n\t\tiinfo->i_lenAlloc = le32_to_cpu(efe->lengthAllocDescs);\n\t\tiinfo->i_checkpoint = le32_to_cpu(efe->checkpoint);\n\t}\n\n\tswitch (fe->icbTag.fileType) {\n\tcase ICBTAG_FILE_TYPE_DIRECTORY:\n\t\tinode->i_op = &udf_dir_inode_operations;\n\t\tinode->i_fop = &udf_dir_operations;\n\t\tinode->i_mode |= S_IFDIR;\n\t\tinc_nlink(inode);\n\t\tbreak;\n\tcase ICBTAG_FILE_TYPE_REALTIME:\n\tcase ICBTAG_FILE_TYPE_REGULAR:\n\tcase ICBTAG_FILE_TYPE_UNDEF:\n\tcase ICBTAG_FILE_TYPE_VAT20:\n\t\tif (iinfo->i_alloc_type == ICBTAG_FLAG_AD_IN_ICB)\n\t\t\tinode->i_data.a_ops = &udf_adinicb_aops;\n\t\telse\n\t\t\tinode->i_data.a_ops = &udf_aops;\n\t\tinode->i_op = &udf_file_inode_operations;\n\t\tinode->i_fop = &udf_file_operations;\n\t\tinode->i_mode |= S_IFREG;\n\t\tbreak;\n\tcase ICBTAG_FILE_TYPE_BLOCK:\n\t\tinode->i_mode |= S_IFBLK;\n\t\tbreak;\n\tcase ICBTAG_FILE_TYPE_CHAR:\n\t\tinode->i_mode |= S_IFCHR;\n\t\tbreak;\n\tcase ICBTAG_FILE_TYPE_FIFO:\n\t\tinit_special_inode(inode, inode->i_mode | S_IFIFO, 0);\n\t\tbreak;\n\tcase ICBTAG_FILE_TYPE_SOCKET:\n\t\tinit_special_inode(inode, inode->i_mode | S_IFSOCK, 0);\n\t\tbreak;\n\tcase ICBTAG_FILE_TYPE_SYMLINK:\n\t\tinode->i_data.a_ops = &udf_symlink_aops;\n\t\tinode->i_op = &udf_symlink_inode_operations;\n\t\tinode->i_mode = S_IFLNK | S_IRWXUGO;\n\t\tbreak;\n\tcase ICBTAG_FILE_TYPE_MAIN:\n\t\tudf_debug(\"METADATA FILE-----\\n\");\n\t\tbreak;\n\tcase ICBTAG_FILE_TYPE_MIRROR:\n\t\tudf_debug(\"METADATA MIRROR FILE-----\\n\");\n\t\tbreak;\n\tcase ICBTAG_FILE_TYPE_BITMAP:\n\t\tudf_debug(\"METADATA BITMAP FILE-----\\n\");\n\t\tbreak;\n\tdefault:\n\t\tudf_err(inode->i_sb, \"(ino %ld) failed unknown file type=%d\\n\",\n\t\t\tinode->i_ino, fe->icbTag.fileType);\n\t\tmake_bad_inode(inode);\n\t\treturn;\n\t}\n\tif (S_ISCHR(inode->i_mode) || S_ISBLK(inode->i_mode)) {\n\t\tstruct deviceSpec *dsea =\n\t\t\t(struct deviceSpec *)udf_get_extendedattr(inode, 12, 1);\n\t\tif (dsea) {\n\t\t\tinit_special_inode(inode, inode->i_mode,\n\t\t\t\tMKDEV(le32_to_cpu(dsea->majorDeviceIdent),\n\t\t\t\t      le32_to_cpu(dsea->minorDeviceIdent)));\n\t\t\t/* Developer ID ??? */\n\t\t} else\n\t\t\tmake_bad_inode(inode);\n\t}\n\tbrelse(bh);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -7,7 +7,9 @@\n \tstruct udf_inode_info *iinfo = UDF_I(inode);\n \tstruct udf_sb_info *sbi = UDF_SB(inode->i_sb);\n \tunsigned int link_count;\n-\n+\tunsigned int indirections = 0;\n+\n+reread:\n \t/*\n \t * Set defaults, but the inode is still incomplete!\n \t * Note: get_new_inode() sets the following on a new inode:\n@@ -45,28 +47,26 @@\n \t\tibh = udf_read_ptagged(inode->i_sb, &iinfo->i_location, 1,\n \t\t\t\t\t&ident);\n \t\tif (ident == TAG_IDENT_IE && ibh) {\n-\t\t\tstruct buffer_head *nbh = NULL;\n \t\t\tstruct kernel_lb_addr loc;\n \t\t\tstruct indirectEntry *ie;\n \n \t\t\tie = (struct indirectEntry *)ibh->b_data;\n \t\t\tloc = lelb_to_cpu(ie->indirectICB.extLocation);\n \n-\t\t\tif (ie->indirectICB.extLength &&\n-\t\t\t\t(nbh = udf_read_ptagged(inode->i_sb, &loc, 0,\n-\t\t\t\t\t\t\t&ident))) {\n-\t\t\t\tif (ident == TAG_IDENT_FE ||\n-\t\t\t\t\tident == TAG_IDENT_EFE) {\n-\t\t\t\t\tmemcpy(&iinfo->i_location,\n-\t\t\t\t\t\t&loc,\n-\t\t\t\t\t\tsizeof(struct kernel_lb_addr));\n-\t\t\t\t\tbrelse(bh);\n-\t\t\t\t\tbrelse(ibh);\n-\t\t\t\t\tbrelse(nbh);\n-\t\t\t\t\t__udf_read_inode(inode);\n+\t\t\tif (ie->indirectICB.extLength) {\n+\t\t\t\tbrelse(bh);\n+\t\t\t\tbrelse(ibh);\n+\t\t\t\tmemcpy(&iinfo->i_location, &loc,\n+\t\t\t\t       sizeof(struct kernel_lb_addr));\n+\t\t\t\tif (++indirections > UDF_MAX_ICB_NESTING) {\n+\t\t\t\t\tudf_err(inode->i_sb,\n+\t\t\t\t\t\t\"too many ICBs in ICB hierarchy\"\n+\t\t\t\t\t\t\" (max %d supported)\\n\",\n+\t\t\t\t\t\tUDF_MAX_ICB_NESTING);\n+\t\t\t\t\tmake_bad_inode(inode);\n \t\t\t\t\treturn;\n \t\t\t\t}\n-\t\t\t\tbrelse(nbh);\n+\t\t\t\tgoto reread;\n \t\t\t}\n \t\t}\n \t\tbrelse(ibh);",
        "diff_line_info": {
            "deleted_lines": [
                "",
                "\t\t\tstruct buffer_head *nbh = NULL;",
                "\t\t\tif (ie->indirectICB.extLength &&",
                "\t\t\t\t(nbh = udf_read_ptagged(inode->i_sb, &loc, 0,",
                "\t\t\t\t\t\t\t&ident))) {",
                "\t\t\t\tif (ident == TAG_IDENT_FE ||",
                "\t\t\t\t\tident == TAG_IDENT_EFE) {",
                "\t\t\t\t\tmemcpy(&iinfo->i_location,",
                "\t\t\t\t\t\t&loc,",
                "\t\t\t\t\t\tsizeof(struct kernel_lb_addr));",
                "\t\t\t\t\tbrelse(bh);",
                "\t\t\t\t\tbrelse(ibh);",
                "\t\t\t\t\tbrelse(nbh);",
                "\t\t\t\t\t__udf_read_inode(inode);",
                "\t\t\t\tbrelse(nbh);"
            ],
            "added_lines": [
                "\tunsigned int indirections = 0;",
                "",
                "reread:",
                "\t\t\tif (ie->indirectICB.extLength) {",
                "\t\t\t\tbrelse(bh);",
                "\t\t\t\tbrelse(ibh);",
                "\t\t\t\tmemcpy(&iinfo->i_location, &loc,",
                "\t\t\t\t       sizeof(struct kernel_lb_addr));",
                "\t\t\t\tif (++indirections > UDF_MAX_ICB_NESTING) {",
                "\t\t\t\t\tudf_err(inode->i_sb,",
                "\t\t\t\t\t\t\"too many ICBs in ICB hierarchy\"",
                "\t\t\t\t\t\t\" (max %d supported)\\n\",",
                "\t\t\t\t\t\tUDF_MAX_ICB_NESTING);",
                "\t\t\t\t\tmake_bad_inode(inode);",
                "\t\t\t\tgoto reread;"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-6416",
        "func_name": "torvalds/linux/ceph_x_decrypt",
        "description": "Buffer overflow in net/ceph/auth_x.c in Ceph, as used in the Linux kernel before 3.16.3, allows remote attackers to cause a denial of service (memory corruption and panic) or possibly have unspecified other impact via a long unencrypted auth ticket.",
        "git_url": "https://github.com/torvalds/linux/commit/c27a3e4d667fdcad3db7b104f75659478e0c68d8",
        "commit_title": "libceph: do not hard code max auth ticket len",
        "commit_text": " We hard code cephx auth ticket buffer size to 256 bytes.  This isn't enough for any moderate setups and, in case tickets themselves are not encrypted, leads to buffer overflows (ceph_x_decrypt() errors out, but ceph_decode_copy() doesn't - it's just a memcpy() wrapper).  Since the buffer is allocated dynamically anyway, allocated it a bit later, at the point where we know how much is going to be needed.   Cc: stable@vger.kernel.org",
        "func_before": "static int ceph_x_decrypt(struct ceph_crypto_key *secret,\n\t\t\t  void **p, void *end, void *obuf, size_t olen)\n{\n\tstruct ceph_x_encrypt_header head;\n\tsize_t head_len = sizeof(head);\n\tint len, ret;\n\n\tlen = ceph_decode_32(p);\n\tif (*p + len > end)\n\t\treturn -EINVAL;\n\n\tdout(\"ceph_x_decrypt len %d\\n\", len);\n\tret = ceph_decrypt2(secret, &head, &head_len, obuf, &olen,\n\t\t\t    *p, len);\n\tif (ret)\n\t\treturn ret;\n\tif (head.struct_v != 1 || le64_to_cpu(head.magic) != CEPHX_ENC_MAGIC)\n\t\treturn -EPERM;\n\t*p += len;\n\treturn olen;\n}",
        "func": "static int ceph_x_decrypt(struct ceph_crypto_key *secret,\n\t\t\t  void **p, void *end, void **obuf, size_t olen)\n{\n\tstruct ceph_x_encrypt_header head;\n\tsize_t head_len = sizeof(head);\n\tint len, ret;\n\n\tlen = ceph_decode_32(p);\n\tif (*p + len > end)\n\t\treturn -EINVAL;\n\n\tdout(\"ceph_x_decrypt len %d\\n\", len);\n\tif (*obuf == NULL) {\n\t\t*obuf = kmalloc(len, GFP_NOFS);\n\t\tif (!*obuf)\n\t\t\treturn -ENOMEM;\n\t\tolen = len;\n\t}\n\n\tret = ceph_decrypt2(secret, &head, &head_len, *obuf, &olen, *p, len);\n\tif (ret)\n\t\treturn ret;\n\tif (head.struct_v != 1 || le64_to_cpu(head.magic) != CEPHX_ENC_MAGIC)\n\t\treturn -EPERM;\n\t*p += len;\n\treturn olen;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,5 @@\n static int ceph_x_decrypt(struct ceph_crypto_key *secret,\n-\t\t\t  void **p, void *end, void *obuf, size_t olen)\n+\t\t\t  void **p, void *end, void **obuf, size_t olen)\n {\n \tstruct ceph_x_encrypt_header head;\n \tsize_t head_len = sizeof(head);\n@@ -10,8 +10,14 @@\n \t\treturn -EINVAL;\n \n \tdout(\"ceph_x_decrypt len %d\\n\", len);\n-\tret = ceph_decrypt2(secret, &head, &head_len, obuf, &olen,\n-\t\t\t    *p, len);\n+\tif (*obuf == NULL) {\n+\t\t*obuf = kmalloc(len, GFP_NOFS);\n+\t\tif (!*obuf)\n+\t\t\treturn -ENOMEM;\n+\t\tolen = len;\n+\t}\n+\n+\tret = ceph_decrypt2(secret, &head, &head_len, *obuf, &olen, *p, len);\n \tif (ret)\n \t\treturn ret;\n \tif (head.struct_v != 1 || le64_to_cpu(head.magic) != CEPHX_ENC_MAGIC)",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\t  void **p, void *end, void *obuf, size_t olen)",
                "\tret = ceph_decrypt2(secret, &head, &head_len, obuf, &olen,",
                "\t\t\t    *p, len);"
            ],
            "added_lines": [
                "\t\t\t  void **p, void *end, void **obuf, size_t olen)",
                "\tif (*obuf == NULL) {",
                "\t\t*obuf = kmalloc(len, GFP_NOFS);",
                "\t\tif (!*obuf)",
                "\t\t\treturn -ENOMEM;",
                "\t\tolen = len;",
                "\t}",
                "",
                "\tret = ceph_decrypt2(secret, &head, &head_len, *obuf, &olen, *p, len);"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-6416",
        "func_name": "torvalds/linux/process_one_ticket",
        "description": "Buffer overflow in net/ceph/auth_x.c in Ceph, as used in the Linux kernel before 3.16.3, allows remote attackers to cause a denial of service (memory corruption and panic) or possibly have unspecified other impact via a long unencrypted auth ticket.",
        "git_url": "https://github.com/torvalds/linux/commit/c27a3e4d667fdcad3db7b104f75659478e0c68d8",
        "commit_title": "libceph: do not hard code max auth ticket len",
        "commit_text": " We hard code cephx auth ticket buffer size to 256 bytes.  This isn't enough for any moderate setups and, in case tickets themselves are not encrypted, leads to buffer overflows (ceph_x_decrypt() errors out, but ceph_decode_copy() doesn't - it's just a memcpy() wrapper).  Since the buffer is allocated dynamically anyway, allocated it a bit later, at the point where we know how much is going to be needed.   Cc: stable@vger.kernel.org",
        "func_before": "static int process_one_ticket(struct ceph_auth_client *ac,\n\t\t\t      struct ceph_crypto_key *secret,\n\t\t\t      void **p, void *end,\n\t\t\t      void *dbuf, void *ticket_buf)\n{\n\tstruct ceph_x_info *xi = ac->private;\n\tint type;\n\tu8 tkt_struct_v, blob_struct_v;\n\tstruct ceph_x_ticket_handler *th;\n\tvoid *dp, *dend;\n\tint dlen;\n\tchar is_enc;\n\tstruct timespec validity;\n\tstruct ceph_crypto_key old_key;\n\tvoid *tp, *tpend;\n\tstruct ceph_timespec new_validity;\n\tstruct ceph_crypto_key new_session_key;\n\tstruct ceph_buffer *new_ticket_blob;\n\tunsigned long new_expires, new_renew_after;\n\tu64 new_secret_id;\n\tint ret;\n\n\tceph_decode_need(p, end, sizeof(u32) + 1, bad);\n\n\ttype = ceph_decode_32(p);\n\tdout(\" ticket type %d %s\\n\", type, ceph_entity_type_name(type));\n\n\ttkt_struct_v = ceph_decode_8(p);\n\tif (tkt_struct_v != 1)\n\t\tgoto bad;\n\n\tth = get_ticket_handler(ac, type);\n\tif (IS_ERR(th)) {\n\t\tret = PTR_ERR(th);\n\t\tgoto out;\n\t}\n\n\t/* blob for me */\n\tdlen = ceph_x_decrypt(secret, p, end, dbuf,\n\t\t\t      TEMP_TICKET_BUF_LEN);\n\tif (dlen <= 0) {\n\t\tret = dlen;\n\t\tgoto out;\n\t}\n\tdout(\" decrypted %d bytes\\n\", dlen);\n\tdp = dbuf;\n\tdend = dp + dlen;\n\n\ttkt_struct_v = ceph_decode_8(&dp);\n\tif (tkt_struct_v != 1)\n\t\tgoto bad;\n\n\tmemcpy(&old_key, &th->session_key, sizeof(old_key));\n\tret = ceph_crypto_key_decode(&new_session_key, &dp, dend);\n\tif (ret)\n\t\tgoto out;\n\n\tceph_decode_copy(&dp, &new_validity, sizeof(new_validity));\n\tceph_decode_timespec(&validity, &new_validity);\n\tnew_expires = get_seconds() + validity.tv_sec;\n\tnew_renew_after = new_expires - (validity.tv_sec / 4);\n\tdout(\" expires=%lu renew_after=%lu\\n\", new_expires,\n\t     new_renew_after);\n\n\t/* ticket blob for service */\n\tceph_decode_8_safe(p, end, is_enc, bad);\n\ttp = ticket_buf;\n\tif (is_enc) {\n\t\t/* encrypted */\n\t\tdout(\" encrypted ticket\\n\");\n\t\tdlen = ceph_x_decrypt(&old_key, p, end, ticket_buf,\n\t\t\t\t      TEMP_TICKET_BUF_LEN);\n\t\tif (dlen < 0) {\n\t\t\tret = dlen;\n\t\t\tgoto out;\n\t\t}\n\t\tdlen = ceph_decode_32(&tp);\n\t} else {\n\t\t/* unencrypted */\n\t\tceph_decode_32_safe(p, end, dlen, bad);\n\t\tceph_decode_need(p, end, dlen, bad);\n\t\tceph_decode_copy(p, ticket_buf, dlen);\n\t}\n\ttpend = tp + dlen;\n\tdout(\" ticket blob is %d bytes\\n\", dlen);\n\tceph_decode_need(&tp, tpend, 1 + sizeof(u64), bad);\n\tblob_struct_v = ceph_decode_8(&tp);\n\tnew_secret_id = ceph_decode_64(&tp);\n\tret = ceph_decode_buffer(&new_ticket_blob, &tp, tpend);\n\tif (ret)\n\t\tgoto out;\n\n\t/* all is well, update our ticket */\n\tceph_crypto_key_destroy(&th->session_key);\n\tif (th->ticket_blob)\n\t\tceph_buffer_put(th->ticket_blob);\n\tth->session_key = new_session_key;\n\tth->ticket_blob = new_ticket_blob;\n\tth->validity = new_validity;\n\tth->secret_id = new_secret_id;\n\tth->expires = new_expires;\n\tth->renew_after = new_renew_after;\n\tdout(\" got ticket service %d (%s) secret_id %lld len %d\\n\",\n\t     type, ceph_entity_type_name(type), th->secret_id,\n\t     (int)th->ticket_blob->vec.iov_len);\n\txi->have_keys |= th->service;\n\nout:\n\treturn ret;\n\nbad:\n\tret = -EINVAL;\n\tgoto out;\n}",
        "func": "static int process_one_ticket(struct ceph_auth_client *ac,\n\t\t\t      struct ceph_crypto_key *secret,\n\t\t\t      void **p, void *end)\n{\n\tstruct ceph_x_info *xi = ac->private;\n\tint type;\n\tu8 tkt_struct_v, blob_struct_v;\n\tstruct ceph_x_ticket_handler *th;\n\tvoid *dbuf = NULL;\n\tvoid *dp, *dend;\n\tint dlen;\n\tchar is_enc;\n\tstruct timespec validity;\n\tstruct ceph_crypto_key old_key;\n\tvoid *ticket_buf = NULL;\n\tvoid *tp, *tpend;\n\tstruct ceph_timespec new_validity;\n\tstruct ceph_crypto_key new_session_key;\n\tstruct ceph_buffer *new_ticket_blob;\n\tunsigned long new_expires, new_renew_after;\n\tu64 new_secret_id;\n\tint ret;\n\n\tceph_decode_need(p, end, sizeof(u32) + 1, bad);\n\n\ttype = ceph_decode_32(p);\n\tdout(\" ticket type %d %s\\n\", type, ceph_entity_type_name(type));\n\n\ttkt_struct_v = ceph_decode_8(p);\n\tif (tkt_struct_v != 1)\n\t\tgoto bad;\n\n\tth = get_ticket_handler(ac, type);\n\tif (IS_ERR(th)) {\n\t\tret = PTR_ERR(th);\n\t\tgoto out;\n\t}\n\n\t/* blob for me */\n\tdlen = ceph_x_decrypt(secret, p, end, &dbuf, 0);\n\tif (dlen <= 0) {\n\t\tret = dlen;\n\t\tgoto out;\n\t}\n\tdout(\" decrypted %d bytes\\n\", dlen);\n\tdp = dbuf;\n\tdend = dp + dlen;\n\n\ttkt_struct_v = ceph_decode_8(&dp);\n\tif (tkt_struct_v != 1)\n\t\tgoto bad;\n\n\tmemcpy(&old_key, &th->session_key, sizeof(old_key));\n\tret = ceph_crypto_key_decode(&new_session_key, &dp, dend);\n\tif (ret)\n\t\tgoto out;\n\n\tceph_decode_copy(&dp, &new_validity, sizeof(new_validity));\n\tceph_decode_timespec(&validity, &new_validity);\n\tnew_expires = get_seconds() + validity.tv_sec;\n\tnew_renew_after = new_expires - (validity.tv_sec / 4);\n\tdout(\" expires=%lu renew_after=%lu\\n\", new_expires,\n\t     new_renew_after);\n\n\t/* ticket blob for service */\n\tceph_decode_8_safe(p, end, is_enc, bad);\n\tif (is_enc) {\n\t\t/* encrypted */\n\t\tdout(\" encrypted ticket\\n\");\n\t\tdlen = ceph_x_decrypt(&old_key, p, end, &ticket_buf, 0);\n\t\tif (dlen < 0) {\n\t\t\tret = dlen;\n\t\t\tgoto out;\n\t\t}\n\t\ttp = ticket_buf;\n\t\tdlen = ceph_decode_32(&tp);\n\t} else {\n\t\t/* unencrypted */\n\t\tceph_decode_32_safe(p, end, dlen, bad);\n\t\tticket_buf = kmalloc(dlen, GFP_NOFS);\n\t\tif (!ticket_buf) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto out;\n\t\t}\n\t\ttp = ticket_buf;\n\t\tceph_decode_need(p, end, dlen, bad);\n\t\tceph_decode_copy(p, ticket_buf, dlen);\n\t}\n\ttpend = tp + dlen;\n\tdout(\" ticket blob is %d bytes\\n\", dlen);\n\tceph_decode_need(&tp, tpend, 1 + sizeof(u64), bad);\n\tblob_struct_v = ceph_decode_8(&tp);\n\tnew_secret_id = ceph_decode_64(&tp);\n\tret = ceph_decode_buffer(&new_ticket_blob, &tp, tpend);\n\tif (ret)\n\t\tgoto out;\n\n\t/* all is well, update our ticket */\n\tceph_crypto_key_destroy(&th->session_key);\n\tif (th->ticket_blob)\n\t\tceph_buffer_put(th->ticket_blob);\n\tth->session_key = new_session_key;\n\tth->ticket_blob = new_ticket_blob;\n\tth->validity = new_validity;\n\tth->secret_id = new_secret_id;\n\tth->expires = new_expires;\n\tth->renew_after = new_renew_after;\n\tdout(\" got ticket service %d (%s) secret_id %lld len %d\\n\",\n\t     type, ceph_entity_type_name(type), th->secret_id,\n\t     (int)th->ticket_blob->vec.iov_len);\n\txi->have_keys |= th->service;\n\nout:\n\tkfree(ticket_buf);\n\tkfree(dbuf);\n\treturn ret;\n\nbad:\n\tret = -EINVAL;\n\tgoto out;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,17 +1,18 @@\n static int process_one_ticket(struct ceph_auth_client *ac,\n \t\t\t      struct ceph_crypto_key *secret,\n-\t\t\t      void **p, void *end,\n-\t\t\t      void *dbuf, void *ticket_buf)\n+\t\t\t      void **p, void *end)\n {\n \tstruct ceph_x_info *xi = ac->private;\n \tint type;\n \tu8 tkt_struct_v, blob_struct_v;\n \tstruct ceph_x_ticket_handler *th;\n+\tvoid *dbuf = NULL;\n \tvoid *dp, *dend;\n \tint dlen;\n \tchar is_enc;\n \tstruct timespec validity;\n \tstruct ceph_crypto_key old_key;\n+\tvoid *ticket_buf = NULL;\n \tvoid *tp, *tpend;\n \tstruct ceph_timespec new_validity;\n \tstruct ceph_crypto_key new_session_key;\n@@ -36,8 +37,7 @@\n \t}\n \n \t/* blob for me */\n-\tdlen = ceph_x_decrypt(secret, p, end, dbuf,\n-\t\t\t      TEMP_TICKET_BUF_LEN);\n+\tdlen = ceph_x_decrypt(secret, p, end, &dbuf, 0);\n \tif (dlen <= 0) {\n \t\tret = dlen;\n \t\tgoto out;\n@@ -64,20 +64,25 @@\n \n \t/* ticket blob for service */\n \tceph_decode_8_safe(p, end, is_enc, bad);\n-\ttp = ticket_buf;\n \tif (is_enc) {\n \t\t/* encrypted */\n \t\tdout(\" encrypted ticket\\n\");\n-\t\tdlen = ceph_x_decrypt(&old_key, p, end, ticket_buf,\n-\t\t\t\t      TEMP_TICKET_BUF_LEN);\n+\t\tdlen = ceph_x_decrypt(&old_key, p, end, &ticket_buf, 0);\n \t\tif (dlen < 0) {\n \t\t\tret = dlen;\n \t\t\tgoto out;\n \t\t}\n+\t\ttp = ticket_buf;\n \t\tdlen = ceph_decode_32(&tp);\n \t} else {\n \t\t/* unencrypted */\n \t\tceph_decode_32_safe(p, end, dlen, bad);\n+\t\tticket_buf = kmalloc(dlen, GFP_NOFS);\n+\t\tif (!ticket_buf) {\n+\t\t\tret = -ENOMEM;\n+\t\t\tgoto out;\n+\t\t}\n+\t\ttp = ticket_buf;\n \t\tceph_decode_need(p, end, dlen, bad);\n \t\tceph_decode_copy(p, ticket_buf, dlen);\n \t}\n@@ -106,6 +111,8 @@\n \txi->have_keys |= th->service;\n \n out:\n+\tkfree(ticket_buf);\n+\tkfree(dbuf);\n \treturn ret;\n \n bad:",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\t      void **p, void *end,",
                "\t\t\t      void *dbuf, void *ticket_buf)",
                "\tdlen = ceph_x_decrypt(secret, p, end, dbuf,",
                "\t\t\t      TEMP_TICKET_BUF_LEN);",
                "\ttp = ticket_buf;",
                "\t\tdlen = ceph_x_decrypt(&old_key, p, end, ticket_buf,",
                "\t\t\t\t      TEMP_TICKET_BUF_LEN);"
            ],
            "added_lines": [
                "\t\t\t      void **p, void *end)",
                "\tvoid *dbuf = NULL;",
                "\tvoid *ticket_buf = NULL;",
                "\tdlen = ceph_x_decrypt(secret, p, end, &dbuf, 0);",
                "\t\tdlen = ceph_x_decrypt(&old_key, p, end, &ticket_buf, 0);",
                "\t\ttp = ticket_buf;",
                "\t\tticket_buf = kmalloc(dlen, GFP_NOFS);",
                "\t\tif (!ticket_buf) {",
                "\t\t\tret = -ENOMEM;",
                "\t\t\tgoto out;",
                "\t\t}",
                "\t\ttp = ticket_buf;",
                "\tkfree(ticket_buf);",
                "\tkfree(dbuf);"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-6416",
        "func_name": "torvalds/linux/ceph_x_proc_ticket_reply",
        "description": "Buffer overflow in net/ceph/auth_x.c in Ceph, as used in the Linux kernel before 3.16.3, allows remote attackers to cause a denial of service (memory corruption and panic) or possibly have unspecified other impact via a long unencrypted auth ticket.",
        "git_url": "https://github.com/torvalds/linux/commit/c27a3e4d667fdcad3db7b104f75659478e0c68d8",
        "commit_title": "libceph: do not hard code max auth ticket len",
        "commit_text": " We hard code cephx auth ticket buffer size to 256 bytes.  This isn't enough for any moderate setups and, in case tickets themselves are not encrypted, leads to buffer overflows (ceph_x_decrypt() errors out, but ceph_decode_copy() doesn't - it's just a memcpy() wrapper).  Since the buffer is allocated dynamically anyway, allocated it a bit later, at the point where we know how much is going to be needed.   Cc: stable@vger.kernel.org",
        "func_before": "static int ceph_x_proc_ticket_reply(struct ceph_auth_client *ac,\n\t\t\t\t    struct ceph_crypto_key *secret,\n\t\t\t\t    void *buf, void *end)\n{\n\tvoid *p = buf;\n\tchar *dbuf;\n\tchar *ticket_buf;\n\tu8 reply_struct_v;\n\tu32 num;\n\tint ret;\n\n\tdbuf = kmalloc(TEMP_TICKET_BUF_LEN, GFP_NOFS);\n\tif (!dbuf)\n\t\treturn -ENOMEM;\n\n\tret = -ENOMEM;\n\tticket_buf = kmalloc(TEMP_TICKET_BUF_LEN, GFP_NOFS);\n\tif (!ticket_buf)\n\t\tgoto out_dbuf;\n\n\tceph_decode_8_safe(&p, end, reply_struct_v, bad);\n\tif (reply_struct_v != 1)\n\t\treturn -EINVAL;\n\n\tceph_decode_32_safe(&p, end, num, bad);\n\tdout(\"%d tickets\\n\", num);\n\n\twhile (num--) {\n\t\tret = process_one_ticket(ac, secret, &p, end,\n\t\t\t\t\t dbuf, ticket_buf);\n\t\tif (ret)\n\t\t\tgoto out;\n\t}\n\n\tret = 0;\nout:\n\tkfree(ticket_buf);\nout_dbuf:\n\tkfree(dbuf);\n\treturn ret;\n\nbad:\n\tret = -EINVAL;\n\tgoto out;\n}",
        "func": "static int ceph_x_proc_ticket_reply(struct ceph_auth_client *ac,\n\t\t\t\t    struct ceph_crypto_key *secret,\n\t\t\t\t    void *buf, void *end)\n{\n\tvoid *p = buf;\n\tu8 reply_struct_v;\n\tu32 num;\n\tint ret;\n\n\tceph_decode_8_safe(&p, end, reply_struct_v, bad);\n\tif (reply_struct_v != 1)\n\t\treturn -EINVAL;\n\n\tceph_decode_32_safe(&p, end, num, bad);\n\tdout(\"%d tickets\\n\", num);\n\n\twhile (num--) {\n\t\tret = process_one_ticket(ac, secret, &p, end);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n\nbad:\n\treturn -EINVAL;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,20 +3,9 @@\n \t\t\t\t    void *buf, void *end)\n {\n \tvoid *p = buf;\n-\tchar *dbuf;\n-\tchar *ticket_buf;\n \tu8 reply_struct_v;\n \tu32 num;\n \tint ret;\n-\n-\tdbuf = kmalloc(TEMP_TICKET_BUF_LEN, GFP_NOFS);\n-\tif (!dbuf)\n-\t\treturn -ENOMEM;\n-\n-\tret = -ENOMEM;\n-\tticket_buf = kmalloc(TEMP_TICKET_BUF_LEN, GFP_NOFS);\n-\tif (!ticket_buf)\n-\t\tgoto out_dbuf;\n \n \tceph_decode_8_safe(&p, end, reply_struct_v, bad);\n \tif (reply_struct_v != 1)\n@@ -26,20 +15,13 @@\n \tdout(\"%d tickets\\n\", num);\n \n \twhile (num--) {\n-\t\tret = process_one_ticket(ac, secret, &p, end,\n-\t\t\t\t\t dbuf, ticket_buf);\n+\t\tret = process_one_ticket(ac, secret, &p, end);\n \t\tif (ret)\n-\t\t\tgoto out;\n+\t\t\treturn ret;\n \t}\n \n-\tret = 0;\n-out:\n-\tkfree(ticket_buf);\n-out_dbuf:\n-\tkfree(dbuf);\n-\treturn ret;\n+\treturn 0;\n \n bad:\n-\tret = -EINVAL;\n-\tgoto out;\n+\treturn -EINVAL;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tchar *dbuf;",
                "\tchar *ticket_buf;",
                "",
                "\tdbuf = kmalloc(TEMP_TICKET_BUF_LEN, GFP_NOFS);",
                "\tif (!dbuf)",
                "\t\treturn -ENOMEM;",
                "",
                "\tret = -ENOMEM;",
                "\tticket_buf = kmalloc(TEMP_TICKET_BUF_LEN, GFP_NOFS);",
                "\tif (!ticket_buf)",
                "\t\tgoto out_dbuf;",
                "\t\tret = process_one_ticket(ac, secret, &p, end,",
                "\t\t\t\t\t dbuf, ticket_buf);",
                "\t\t\tgoto out;",
                "\tret = 0;",
                "out:",
                "\tkfree(ticket_buf);",
                "out_dbuf:",
                "\tkfree(dbuf);",
                "\treturn ret;",
                "\tret = -EINVAL;",
                "\tgoto out;"
            ],
            "added_lines": [
                "\t\tret = process_one_ticket(ac, secret, &p, end);",
                "\t\t\treturn ret;",
                "\treturn 0;",
                "\treturn -EINVAL;"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-6416",
        "func_name": "torvalds/linux/ceph_x_verify_authorizer_reply",
        "description": "Buffer overflow in net/ceph/auth_x.c in Ceph, as used in the Linux kernel before 3.16.3, allows remote attackers to cause a denial of service (memory corruption and panic) or possibly have unspecified other impact via a long unencrypted auth ticket.",
        "git_url": "https://github.com/torvalds/linux/commit/c27a3e4d667fdcad3db7b104f75659478e0c68d8",
        "commit_title": "libceph: do not hard code max auth ticket len",
        "commit_text": " We hard code cephx auth ticket buffer size to 256 bytes.  This isn't enough for any moderate setups and, in case tickets themselves are not encrypted, leads to buffer overflows (ceph_x_decrypt() errors out, but ceph_decode_copy() doesn't - it's just a memcpy() wrapper).  Since the buffer is allocated dynamically anyway, allocated it a bit later, at the point where we know how much is going to be needed.   Cc: stable@vger.kernel.org",
        "func_before": "static int ceph_x_verify_authorizer_reply(struct ceph_auth_client *ac,\n\t\t\t\t\t  struct ceph_authorizer *a, size_t len)\n{\n\tstruct ceph_x_authorizer *au = (void *)a;\n\tstruct ceph_x_ticket_handler *th;\n\tint ret = 0;\n\tstruct ceph_x_authorize_reply reply;\n\tvoid *p = au->reply_buf;\n\tvoid *end = p + sizeof(au->reply_buf);\n\n\tth = get_ticket_handler(ac, au->service);\n\tif (IS_ERR(th))\n\t\treturn PTR_ERR(th);\n\tret = ceph_x_decrypt(&th->session_key, &p, end, &reply, sizeof(reply));\n\tif (ret < 0)\n\t\treturn ret;\n\tif (ret != sizeof(reply))\n\t\treturn -EPERM;\n\n\tif (au->nonce + 1 != le64_to_cpu(reply.nonce_plus_one))\n\t\tret = -EPERM;\n\telse\n\t\tret = 0;\n\tdout(\"verify_authorizer_reply nonce %llx got %llx ret %d\\n\",\n\t     au->nonce, le64_to_cpu(reply.nonce_plus_one), ret);\n\treturn ret;\n}",
        "func": "static int ceph_x_verify_authorizer_reply(struct ceph_auth_client *ac,\n\t\t\t\t\t  struct ceph_authorizer *a, size_t len)\n{\n\tstruct ceph_x_authorizer *au = (void *)a;\n\tstruct ceph_x_ticket_handler *th;\n\tint ret = 0;\n\tstruct ceph_x_authorize_reply reply;\n\tvoid *preply = &reply;\n\tvoid *p = au->reply_buf;\n\tvoid *end = p + sizeof(au->reply_buf);\n\n\tth = get_ticket_handler(ac, au->service);\n\tif (IS_ERR(th))\n\t\treturn PTR_ERR(th);\n\tret = ceph_x_decrypt(&th->session_key, &p, end, &preply, sizeof(reply));\n\tif (ret < 0)\n\t\treturn ret;\n\tif (ret != sizeof(reply))\n\t\treturn -EPERM;\n\n\tif (au->nonce + 1 != le64_to_cpu(reply.nonce_plus_one))\n\t\tret = -EPERM;\n\telse\n\t\tret = 0;\n\tdout(\"verify_authorizer_reply nonce %llx got %llx ret %d\\n\",\n\t     au->nonce, le64_to_cpu(reply.nonce_plus_one), ret);\n\treturn ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,13 +5,14 @@\n \tstruct ceph_x_ticket_handler *th;\n \tint ret = 0;\n \tstruct ceph_x_authorize_reply reply;\n+\tvoid *preply = &reply;\n \tvoid *p = au->reply_buf;\n \tvoid *end = p + sizeof(au->reply_buf);\n \n \tth = get_ticket_handler(ac, au->service);\n \tif (IS_ERR(th))\n \t\treturn PTR_ERR(th);\n-\tret = ceph_x_decrypt(&th->session_key, &p, end, &reply, sizeof(reply));\n+\tret = ceph_x_decrypt(&th->session_key, &p, end, &preply, sizeof(reply));\n \tif (ret < 0)\n \t\treturn ret;\n \tif (ret != sizeof(reply))",
        "diff_line_info": {
            "deleted_lines": [
                "\tret = ceph_x_decrypt(&th->session_key, &p, end, &reply, sizeof(reply));"
            ],
            "added_lines": [
                "\tvoid *preply = &reply;",
                "\tret = ceph_x_decrypt(&th->session_key, &p, end, &preply, sizeof(reply));"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-7145",
        "func_name": "torvalds/linux/SMB2_tcon",
        "description": "The SMB2_tcon function in fs/cifs/smb2pdu.c in the Linux kernel before 3.16.3 allows remote CIFS servers to cause a denial of service (NULL pointer dereference and client system crash) or possibly have unspecified other impact by deleting the IPC$ share during resolution of DFS referrals.",
        "git_url": "https://github.com/torvalds/linux/commit/18f39e7be0121317550d03e267e3ebd4dbfbb3ce",
        "commit_title": "[CIFS] Possible null ptr deref in SMB2_tcon",
        "commit_text": " As Raphael Geissert pointed out, tcon_error_exit can dereference tcon and there is one path in which tcon can be null. ",
        "func_before": "int\nSMB2_tcon(const unsigned int xid, struct cifs_ses *ses, const char *tree,\n\t  struct cifs_tcon *tcon, const struct nls_table *cp)\n{\n\tstruct smb2_tree_connect_req *req;\n\tstruct smb2_tree_connect_rsp *rsp = NULL;\n\tstruct kvec iov[2];\n\tint rc = 0;\n\tint resp_buftype;\n\tint unc_path_len;\n\tstruct TCP_Server_Info *server;\n\t__le16 *unc_path = NULL;\n\n\tcifs_dbg(FYI, \"TCON\\n\");\n\n\tif ((ses->server) && tree)\n\t\tserver = ses->server;\n\telse\n\t\treturn -EIO;\n\n\tif (tcon && tcon->bad_network_name)\n\t\treturn -ENOENT;\n\n\tunc_path = kmalloc(MAX_SHARENAME_LENGTH * 2, GFP_KERNEL);\n\tif (unc_path == NULL)\n\t\treturn -ENOMEM;\n\n\tunc_path_len = cifs_strtoUTF16(unc_path, tree, strlen(tree), cp) + 1;\n\tunc_path_len *= 2;\n\tif (unc_path_len < 2) {\n\t\tkfree(unc_path);\n\t\treturn -EINVAL;\n\t}\n\n\trc = small_smb2_init(SMB2_TREE_CONNECT, tcon, (void **) &req);\n\tif (rc) {\n\t\tkfree(unc_path);\n\t\treturn rc;\n\t}\n\n\tif (tcon == NULL) {\n\t\t/* since no tcon, smb2_init can not do this, so do here */\n\t\treq->hdr.SessionId = ses->Suid;\n\t\t/* if (ses->server->sec_mode & SECMODE_SIGN_REQUIRED)\n\t\t\treq->hdr.Flags |= SMB2_FLAGS_SIGNED; */\n\t}\n\n\tiov[0].iov_base = (char *)req;\n\t/* 4 for rfc1002 length field and 1 for pad */\n\tiov[0].iov_len = get_rfc1002_length(req) + 4 - 1;\n\n\t/* Testing shows that buffer offset must be at location of Buffer[0] */\n\treq->PathOffset = cpu_to_le16(sizeof(struct smb2_tree_connect_req)\n\t\t\t- 1 /* pad */ - 4 /* do not count rfc1001 len field */);\n\treq->PathLength = cpu_to_le16(unc_path_len - 2);\n\tiov[1].iov_base = unc_path;\n\tiov[1].iov_len = unc_path_len;\n\n\tinc_rfc1001_len(req, unc_path_len - 1 /* pad */);\n\n\trc = SendReceive2(xid, ses, iov, 2, &resp_buftype, 0);\n\trsp = (struct smb2_tree_connect_rsp *)iov[0].iov_base;\n\n\tif (rc != 0) {\n\t\tif (tcon) {\n\t\t\tcifs_stats_fail_inc(tcon, SMB2_TREE_CONNECT_HE);\n\t\t\ttcon->need_reconnect = true;\n\t\t}\n\t\tgoto tcon_error_exit;\n\t}\n\n\tif (tcon == NULL) {\n\t\tses->ipc_tid = rsp->hdr.TreeId;\n\t\tgoto tcon_exit;\n\t}\n\n\tif (rsp->ShareType & SMB2_SHARE_TYPE_DISK)\n\t\tcifs_dbg(FYI, \"connection to disk share\\n\");\n\telse if (rsp->ShareType & SMB2_SHARE_TYPE_PIPE) {\n\t\ttcon->ipc = true;\n\t\tcifs_dbg(FYI, \"connection to pipe share\\n\");\n\t} else if (rsp->ShareType & SMB2_SHARE_TYPE_PRINT) {\n\t\ttcon->print = true;\n\t\tcifs_dbg(FYI, \"connection to printer\\n\");\n\t} else {\n\t\tcifs_dbg(VFS, \"unknown share type %d\\n\", rsp->ShareType);\n\t\trc = -EOPNOTSUPP;\n\t\tgoto tcon_error_exit;\n\t}\n\n\ttcon->share_flags = le32_to_cpu(rsp->ShareFlags);\n\ttcon->capabilities = rsp->Capabilities; /* we keep caps little endian */\n\ttcon->maximal_access = le32_to_cpu(rsp->MaximalAccess);\n\ttcon->tidStatus = CifsGood;\n\ttcon->need_reconnect = false;\n\ttcon->tid = rsp->hdr.TreeId;\n\tstrlcpy(tcon->treeName, tree, sizeof(tcon->treeName));\n\n\tif ((rsp->Capabilities & SMB2_SHARE_CAP_DFS) &&\n\t    ((tcon->share_flags & SHI1005_FLAGS_DFS) == 0))\n\t\tcifs_dbg(VFS, \"DFS capability contradicts DFS flag\\n\");\n\tinit_copy_chunk_defaults(tcon);\n\tif (tcon->ses->server->ops->validate_negotiate)\n\t\trc = tcon->ses->server->ops->validate_negotiate(xid, tcon);\ntcon_exit:\n\tfree_rsp_buf(resp_buftype, rsp);\n\tkfree(unc_path);\n\treturn rc;\n\ntcon_error_exit:\n\tif (rsp->hdr.Status == STATUS_BAD_NETWORK_NAME) {\n\t\tcifs_dbg(VFS, \"BAD_NETWORK_NAME: %s\\n\", tree);\n\t\ttcon->bad_network_name = true;\n\t}\n\tgoto tcon_exit;\n}",
        "func": "int\nSMB2_tcon(const unsigned int xid, struct cifs_ses *ses, const char *tree,\n\t  struct cifs_tcon *tcon, const struct nls_table *cp)\n{\n\tstruct smb2_tree_connect_req *req;\n\tstruct smb2_tree_connect_rsp *rsp = NULL;\n\tstruct kvec iov[2];\n\tint rc = 0;\n\tint resp_buftype;\n\tint unc_path_len;\n\tstruct TCP_Server_Info *server;\n\t__le16 *unc_path = NULL;\n\n\tcifs_dbg(FYI, \"TCON\\n\");\n\n\tif ((ses->server) && tree)\n\t\tserver = ses->server;\n\telse\n\t\treturn -EIO;\n\n\tif (tcon && tcon->bad_network_name)\n\t\treturn -ENOENT;\n\n\tunc_path = kmalloc(MAX_SHARENAME_LENGTH * 2, GFP_KERNEL);\n\tif (unc_path == NULL)\n\t\treturn -ENOMEM;\n\n\tunc_path_len = cifs_strtoUTF16(unc_path, tree, strlen(tree), cp) + 1;\n\tunc_path_len *= 2;\n\tif (unc_path_len < 2) {\n\t\tkfree(unc_path);\n\t\treturn -EINVAL;\n\t}\n\n\trc = small_smb2_init(SMB2_TREE_CONNECT, tcon, (void **) &req);\n\tif (rc) {\n\t\tkfree(unc_path);\n\t\treturn rc;\n\t}\n\n\tif (tcon == NULL) {\n\t\t/* since no tcon, smb2_init can not do this, so do here */\n\t\treq->hdr.SessionId = ses->Suid;\n\t\t/* if (ses->server->sec_mode & SECMODE_SIGN_REQUIRED)\n\t\t\treq->hdr.Flags |= SMB2_FLAGS_SIGNED; */\n\t}\n\n\tiov[0].iov_base = (char *)req;\n\t/* 4 for rfc1002 length field and 1 for pad */\n\tiov[0].iov_len = get_rfc1002_length(req) + 4 - 1;\n\n\t/* Testing shows that buffer offset must be at location of Buffer[0] */\n\treq->PathOffset = cpu_to_le16(sizeof(struct smb2_tree_connect_req)\n\t\t\t- 1 /* pad */ - 4 /* do not count rfc1001 len field */);\n\treq->PathLength = cpu_to_le16(unc_path_len - 2);\n\tiov[1].iov_base = unc_path;\n\tiov[1].iov_len = unc_path_len;\n\n\tinc_rfc1001_len(req, unc_path_len - 1 /* pad */);\n\n\trc = SendReceive2(xid, ses, iov, 2, &resp_buftype, 0);\n\trsp = (struct smb2_tree_connect_rsp *)iov[0].iov_base;\n\n\tif (rc != 0) {\n\t\tif (tcon) {\n\t\t\tcifs_stats_fail_inc(tcon, SMB2_TREE_CONNECT_HE);\n\t\t\ttcon->need_reconnect = true;\n\t\t}\n\t\tgoto tcon_error_exit;\n\t}\n\n\tif (tcon == NULL) {\n\t\tses->ipc_tid = rsp->hdr.TreeId;\n\t\tgoto tcon_exit;\n\t}\n\n\tif (rsp->ShareType & SMB2_SHARE_TYPE_DISK)\n\t\tcifs_dbg(FYI, \"connection to disk share\\n\");\n\telse if (rsp->ShareType & SMB2_SHARE_TYPE_PIPE) {\n\t\ttcon->ipc = true;\n\t\tcifs_dbg(FYI, \"connection to pipe share\\n\");\n\t} else if (rsp->ShareType & SMB2_SHARE_TYPE_PRINT) {\n\t\ttcon->print = true;\n\t\tcifs_dbg(FYI, \"connection to printer\\n\");\n\t} else {\n\t\tcifs_dbg(VFS, \"unknown share type %d\\n\", rsp->ShareType);\n\t\trc = -EOPNOTSUPP;\n\t\tgoto tcon_error_exit;\n\t}\n\n\ttcon->share_flags = le32_to_cpu(rsp->ShareFlags);\n\ttcon->capabilities = rsp->Capabilities; /* we keep caps little endian */\n\ttcon->maximal_access = le32_to_cpu(rsp->MaximalAccess);\n\ttcon->tidStatus = CifsGood;\n\ttcon->need_reconnect = false;\n\ttcon->tid = rsp->hdr.TreeId;\n\tstrlcpy(tcon->treeName, tree, sizeof(tcon->treeName));\n\n\tif ((rsp->Capabilities & SMB2_SHARE_CAP_DFS) &&\n\t    ((tcon->share_flags & SHI1005_FLAGS_DFS) == 0))\n\t\tcifs_dbg(VFS, \"DFS capability contradicts DFS flag\\n\");\n\tinit_copy_chunk_defaults(tcon);\n\tif (tcon->ses->server->ops->validate_negotiate)\n\t\trc = tcon->ses->server->ops->validate_negotiate(xid, tcon);\ntcon_exit:\n\tfree_rsp_buf(resp_buftype, rsp);\n\tkfree(unc_path);\n\treturn rc;\n\ntcon_error_exit:\n\tif (rsp->hdr.Status == STATUS_BAD_NETWORK_NAME) {\n\t\tcifs_dbg(VFS, \"BAD_NETWORK_NAME: %s\\n\", tree);\n\t\tif (tcon)\n\t\t\ttcon->bad_network_name = true;\n\t}\n\tgoto tcon_exit;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -110,7 +110,8 @@\n tcon_error_exit:\n \tif (rsp->hdr.Status == STATUS_BAD_NETWORK_NAME) {\n \t\tcifs_dbg(VFS, \"BAD_NETWORK_NAME: %s\\n\", tree);\n-\t\ttcon->bad_network_name = true;\n+\t\tif (tcon)\n+\t\t\ttcon->bad_network_name = true;\n \t}\n \tgoto tcon_exit;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\t\ttcon->bad_network_name = true;"
            ],
            "added_lines": [
                "\t\tif (tcon)",
                "\t\t\ttcon->bad_network_name = true;"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-7188",
        "func_name": "xen-project/xen/hvm_msr_read_intercept",
        "description": "The hvm_msr_read_intercept function in arch/x86/hvm/hvm.c in Xen 4.1 through 4.4.x uses an improper MSR range for x2APIC emulation, which allows local HVM guests to cause a denial of service (host crash) or read data from the hypervisor or other guests via unspecified vectors.",
        "git_url": "https://github.com/xen-project/xen/commit/61fdda7acf3de11f3d50d50e5b4f4ecfac7e0d04",
        "commit_title": "x86/HVM: properly bound x2APIC MSR range",
        "commit_text": " While the write path change appears to be purely cosmetic (but still gets done here for consistency), the read side mistake permitted accesses beyond the virtual APIC page.  Note that while this isn't fully in line with the specification (digesting MSRs 0x800-0xBFF for the x2APIC), this is the minimal possible fix addressing the security issue and getting x2APIC related code into a consistent shape (elsewhere a 256 rather than 1024 wide window is being used too). This will be dealt with subsequently.  This is CVE-2014-7188 / XSA-108. ",
        "func_before": "int hvm_msr_read_intercept(unsigned int msr, uint64_t *msr_content)\n{\n    struct vcpu *v = current;\n    uint64_t *var_range_base, *fixed_range_base;\n    bool_t mtrr;\n    unsigned int edx, index;\n    int ret = X86EMUL_OKAY;\n\n    var_range_base = (uint64_t *)v->arch.hvm_vcpu.mtrr.var_ranges;\n    fixed_range_base = (uint64_t *)v->arch.hvm_vcpu.mtrr.fixed_ranges;\n\n    hvm_cpuid(1, NULL, NULL, NULL, &edx);\n    mtrr = !!(edx & cpufeat_mask(X86_FEATURE_MTRR));\n\n    switch ( msr )\n    {\n    case MSR_EFER:\n        *msr_content = v->arch.hvm_vcpu.guest_efer;\n        break;\n\n    case MSR_IA32_TSC:\n        *msr_content = hvm_get_guest_tsc(v);\n        break;\n\n    case MSR_IA32_TSC_ADJUST:\n        *msr_content = hvm_get_guest_tsc_adjust(v);\n        break;\n\n    case MSR_TSC_AUX:\n        *msr_content = hvm_msr_tsc_aux(v);\n        break;\n\n    case MSR_IA32_APICBASE:\n        *msr_content = vcpu_vlapic(v)->hw.apic_base_msr;\n        break;\n\n    case MSR_IA32_APICBASE_MSR ... MSR_IA32_APICBASE_MSR + 0x3ff:\n        if ( hvm_x2apic_msr_read(v, msr, msr_content) )\n            goto gp_fault;\n        break;\n\n    case MSR_IA32_TSC_DEADLINE:\n        *msr_content = vlapic_tdt_msr_get(vcpu_vlapic(v));\n        break;\n\n    case MSR_IA32_CR_PAT:\n        hvm_get_guest_pat(v, msr_content);\n        break;\n\n    case MSR_MTRRcap:\n        if ( !mtrr )\n            goto gp_fault;\n        *msr_content = v->arch.hvm_vcpu.mtrr.mtrr_cap;\n        break;\n    case MSR_MTRRdefType:\n        if ( !mtrr )\n            goto gp_fault;\n        *msr_content = v->arch.hvm_vcpu.mtrr.def_type\n                        | (v->arch.hvm_vcpu.mtrr.enabled << 10);\n        break;\n    case MSR_MTRRfix64K_00000:\n        if ( !mtrr )\n            goto gp_fault;\n        *msr_content = fixed_range_base[0];\n        break;\n    case MSR_MTRRfix16K_80000:\n    case MSR_MTRRfix16K_A0000:\n        if ( !mtrr )\n            goto gp_fault;\n        index = msr - MSR_MTRRfix16K_80000;\n        *msr_content = fixed_range_base[index + 1];\n        break;\n    case MSR_MTRRfix4K_C0000...MSR_MTRRfix4K_F8000:\n        if ( !mtrr )\n            goto gp_fault;\n        index = msr - MSR_MTRRfix4K_C0000;\n        *msr_content = fixed_range_base[index + 3];\n        break;\n    case MSR_IA32_MTRR_PHYSBASE(0)...MSR_IA32_MTRR_PHYSMASK(MTRR_VCNT-1):\n        if ( !mtrr )\n            goto gp_fault;\n        index = msr - MSR_IA32_MTRR_PHYSBASE(0);\n        *msr_content = var_range_base[index];\n        break;\n\n    case MSR_K8_ENABLE_C1E:\n    case MSR_AMD64_NB_CFG:\n         /*\n          * These AMD-only registers may be accessed if this HVM guest\n          * has been migrated to an Intel host. This fixes a guest crash\n          * in this case.\n          */\n         *msr_content = 0;\n         break;\n\n    default:\n        if ( (ret = vmce_rdmsr(msr, msr_content)) < 0 )\n            goto gp_fault;\n        /* If ret == 0 then this is not an MCE MSR, see other MSRs. */\n        ret = ((ret == 0)\n               ? hvm_funcs.msr_read_intercept(msr, msr_content)\n               : X86EMUL_OKAY);\n        break;\n    }\n\n out:\n    HVMTRACE_3D(MSR_READ, msr,\n                (uint32_t)*msr_content, (uint32_t)(*msr_content >> 32));\n    return ret;\n\n gp_fault:\n    hvm_inject_hw_exception(TRAP_gp_fault, 0);\n    ret = X86EMUL_EXCEPTION;\n    *msr_content = -1ull;\n    goto out;\n}",
        "func": "int hvm_msr_read_intercept(unsigned int msr, uint64_t *msr_content)\n{\n    struct vcpu *v = current;\n    uint64_t *var_range_base, *fixed_range_base;\n    bool_t mtrr;\n    unsigned int edx, index;\n    int ret = X86EMUL_OKAY;\n\n    var_range_base = (uint64_t *)v->arch.hvm_vcpu.mtrr.var_ranges;\n    fixed_range_base = (uint64_t *)v->arch.hvm_vcpu.mtrr.fixed_ranges;\n\n    hvm_cpuid(1, NULL, NULL, NULL, &edx);\n    mtrr = !!(edx & cpufeat_mask(X86_FEATURE_MTRR));\n\n    switch ( msr )\n    {\n    case MSR_EFER:\n        *msr_content = v->arch.hvm_vcpu.guest_efer;\n        break;\n\n    case MSR_IA32_TSC:\n        *msr_content = hvm_get_guest_tsc(v);\n        break;\n\n    case MSR_IA32_TSC_ADJUST:\n        *msr_content = hvm_get_guest_tsc_adjust(v);\n        break;\n\n    case MSR_TSC_AUX:\n        *msr_content = hvm_msr_tsc_aux(v);\n        break;\n\n    case MSR_IA32_APICBASE:\n        *msr_content = vcpu_vlapic(v)->hw.apic_base_msr;\n        break;\n\n    case MSR_IA32_APICBASE_MSR ... MSR_IA32_APICBASE_MSR + 0xff:\n        if ( hvm_x2apic_msr_read(v, msr, msr_content) )\n            goto gp_fault;\n        break;\n\n    case MSR_IA32_TSC_DEADLINE:\n        *msr_content = vlapic_tdt_msr_get(vcpu_vlapic(v));\n        break;\n\n    case MSR_IA32_CR_PAT:\n        hvm_get_guest_pat(v, msr_content);\n        break;\n\n    case MSR_MTRRcap:\n        if ( !mtrr )\n            goto gp_fault;\n        *msr_content = v->arch.hvm_vcpu.mtrr.mtrr_cap;\n        break;\n    case MSR_MTRRdefType:\n        if ( !mtrr )\n            goto gp_fault;\n        *msr_content = v->arch.hvm_vcpu.mtrr.def_type\n                        | (v->arch.hvm_vcpu.mtrr.enabled << 10);\n        break;\n    case MSR_MTRRfix64K_00000:\n        if ( !mtrr )\n            goto gp_fault;\n        *msr_content = fixed_range_base[0];\n        break;\n    case MSR_MTRRfix16K_80000:\n    case MSR_MTRRfix16K_A0000:\n        if ( !mtrr )\n            goto gp_fault;\n        index = msr - MSR_MTRRfix16K_80000;\n        *msr_content = fixed_range_base[index + 1];\n        break;\n    case MSR_MTRRfix4K_C0000...MSR_MTRRfix4K_F8000:\n        if ( !mtrr )\n            goto gp_fault;\n        index = msr - MSR_MTRRfix4K_C0000;\n        *msr_content = fixed_range_base[index + 3];\n        break;\n    case MSR_IA32_MTRR_PHYSBASE(0)...MSR_IA32_MTRR_PHYSMASK(MTRR_VCNT-1):\n        if ( !mtrr )\n            goto gp_fault;\n        index = msr - MSR_IA32_MTRR_PHYSBASE(0);\n        *msr_content = var_range_base[index];\n        break;\n\n    case MSR_K8_ENABLE_C1E:\n    case MSR_AMD64_NB_CFG:\n         /*\n          * These AMD-only registers may be accessed if this HVM guest\n          * has been migrated to an Intel host. This fixes a guest crash\n          * in this case.\n          */\n         *msr_content = 0;\n         break;\n\n    default:\n        if ( (ret = vmce_rdmsr(msr, msr_content)) < 0 )\n            goto gp_fault;\n        /* If ret == 0 then this is not an MCE MSR, see other MSRs. */\n        ret = ((ret == 0)\n               ? hvm_funcs.msr_read_intercept(msr, msr_content)\n               : X86EMUL_OKAY);\n        break;\n    }\n\n out:\n    HVMTRACE_3D(MSR_READ, msr,\n                (uint32_t)*msr_content, (uint32_t)(*msr_content >> 32));\n    return ret;\n\n gp_fault:\n    hvm_inject_hw_exception(TRAP_gp_fault, 0);\n    ret = X86EMUL_EXCEPTION;\n    *msr_content = -1ull;\n    goto out;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -34,7 +34,7 @@\n         *msr_content = vcpu_vlapic(v)->hw.apic_base_msr;\n         break;\n \n-    case MSR_IA32_APICBASE_MSR ... MSR_IA32_APICBASE_MSR + 0x3ff:\n+    case MSR_IA32_APICBASE_MSR ... MSR_IA32_APICBASE_MSR + 0xff:\n         if ( hvm_x2apic_msr_read(v, msr, msr_content) )\n             goto gp_fault;\n         break;",
        "diff_line_info": {
            "deleted_lines": [
                "    case MSR_IA32_APICBASE_MSR ... MSR_IA32_APICBASE_MSR + 0x3ff:"
            ],
            "added_lines": [
                "    case MSR_IA32_APICBASE_MSR ... MSR_IA32_APICBASE_MSR + 0xff:"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-7188",
        "func_name": "xen-project/xen/hvm_msr_write_intercept",
        "description": "The hvm_msr_read_intercept function in arch/x86/hvm/hvm.c in Xen 4.1 through 4.4.x uses an improper MSR range for x2APIC emulation, which allows local HVM guests to cause a denial of service (host crash) or read data from the hypervisor or other guests via unspecified vectors.",
        "git_url": "https://github.com/xen-project/xen/commit/61fdda7acf3de11f3d50d50e5b4f4ecfac7e0d04",
        "commit_title": "x86/HVM: properly bound x2APIC MSR range",
        "commit_text": " While the write path change appears to be purely cosmetic (but still gets done here for consistency), the read side mistake permitted accesses beyond the virtual APIC page.  Note that while this isn't fully in line with the specification (digesting MSRs 0x800-0xBFF for the x2APIC), this is the minimal possible fix addressing the security issue and getting x2APIC related code into a consistent shape (elsewhere a 256 rather than 1024 wide window is being used too). This will be dealt with subsequently.  This is CVE-2014-7188 / XSA-108. ",
        "func_before": "int hvm_msr_write_intercept(unsigned int msr, uint64_t msr_content)\n{\n    struct vcpu *v = current;\n    bool_t mtrr;\n    unsigned int edx, index;\n    int ret = X86EMUL_OKAY;\n\n    HVMTRACE_3D(MSR_WRITE, msr,\n               (uint32_t)msr_content, (uint32_t)(msr_content >> 32));\n\n    hvm_cpuid(1, NULL, NULL, NULL, &edx);\n    mtrr = !!(edx & cpufeat_mask(X86_FEATURE_MTRR));\n\n    hvm_memory_event_msr(msr, msr_content);\n\n    switch ( msr )\n    {\n    case MSR_EFER:\n        if ( hvm_set_efer(msr_content) )\n           return X86EMUL_EXCEPTION;\n        break;\n\n    case MSR_IA32_TSC:\n        hvm_set_guest_tsc(v, msr_content);\n        break;\n\n    case MSR_IA32_TSC_ADJUST:\n        hvm_set_guest_tsc_adjust(v, msr_content);\n        break;\n\n    case MSR_TSC_AUX:\n        v->arch.hvm_vcpu.msr_tsc_aux = (uint32_t)msr_content;\n        if ( cpu_has_rdtscp\n             && (v->domain->arch.tsc_mode != TSC_MODE_PVRDTSCP) )\n            wrmsrl(MSR_TSC_AUX, (uint32_t)msr_content);\n        break;\n\n    case MSR_IA32_APICBASE:\n        if ( !vlapic_msr_set(vcpu_vlapic(v), msr_content) )\n            goto gp_fault;\n        break;\n\n    case MSR_IA32_TSC_DEADLINE:\n        vlapic_tdt_msr_set(vcpu_vlapic(v), msr_content);\n        break;\n\n    case MSR_IA32_APICBASE_MSR ... MSR_IA32_APICBASE_MSR + 0x3ff:\n        if ( hvm_x2apic_msr_write(v, msr, msr_content) )\n            goto gp_fault;\n        break;\n\n    case MSR_IA32_CR_PAT:\n        if ( !hvm_set_guest_pat(v, msr_content) )\n           goto gp_fault;\n        break;\n\n    case MSR_MTRRcap:\n        if ( !mtrr )\n            goto gp_fault;\n        goto gp_fault;\n    case MSR_MTRRdefType:\n        if ( !mtrr )\n            goto gp_fault;\n        if ( !mtrr_def_type_msr_set(v->domain, &v->arch.hvm_vcpu.mtrr,\n                                    msr_content) )\n           goto gp_fault;\n        break;\n    case MSR_MTRRfix64K_00000:\n        if ( !mtrr )\n            goto gp_fault;\n        if ( !mtrr_fix_range_msr_set(v->domain, &v->arch.hvm_vcpu.mtrr, 0,\n                                     msr_content) )\n            goto gp_fault;\n        break;\n    case MSR_MTRRfix16K_80000:\n    case MSR_MTRRfix16K_A0000:\n        if ( !mtrr )\n            goto gp_fault;\n        index = msr - MSR_MTRRfix16K_80000 + 1;\n        if ( !mtrr_fix_range_msr_set(v->domain, &v->arch.hvm_vcpu.mtrr,\n                                     index, msr_content) )\n            goto gp_fault;\n        break;\n    case MSR_MTRRfix4K_C0000...MSR_MTRRfix4K_F8000:\n        if ( !mtrr )\n            goto gp_fault;\n        index = msr - MSR_MTRRfix4K_C0000 + 3;\n        if ( !mtrr_fix_range_msr_set(v->domain, &v->arch.hvm_vcpu.mtrr,\n                                     index, msr_content) )\n            goto gp_fault;\n        break;\n    case MSR_IA32_MTRR_PHYSBASE(0)...MSR_IA32_MTRR_PHYSMASK(MTRR_VCNT-1):\n        if ( !mtrr )\n            goto gp_fault;\n        if ( !mtrr_var_range_msr_set(v->domain, &v->arch.hvm_vcpu.mtrr,\n                                     msr, msr_content) )\n            goto gp_fault;\n        break;\n\n    case MSR_AMD64_NB_CFG:\n        /* ignore the write */\n        break;\n\n    default:\n        if ( (ret = vmce_wrmsr(msr, msr_content)) < 0 )\n            goto gp_fault;\n        /* If ret == 0 then this is not an MCE MSR, see other MSRs. */\n        ret = ((ret == 0)\n               ? hvm_funcs.msr_write_intercept(msr, msr_content)\n               : X86EMUL_OKAY);\n        break;\n    }\n\n    return ret;\n\ngp_fault:\n    hvm_inject_hw_exception(TRAP_gp_fault, 0);\n    return X86EMUL_EXCEPTION;\n}",
        "func": "int hvm_msr_write_intercept(unsigned int msr, uint64_t msr_content)\n{\n    struct vcpu *v = current;\n    bool_t mtrr;\n    unsigned int edx, index;\n    int ret = X86EMUL_OKAY;\n\n    HVMTRACE_3D(MSR_WRITE, msr,\n               (uint32_t)msr_content, (uint32_t)(msr_content >> 32));\n\n    hvm_cpuid(1, NULL, NULL, NULL, &edx);\n    mtrr = !!(edx & cpufeat_mask(X86_FEATURE_MTRR));\n\n    hvm_memory_event_msr(msr, msr_content);\n\n    switch ( msr )\n    {\n    case MSR_EFER:\n        if ( hvm_set_efer(msr_content) )\n           return X86EMUL_EXCEPTION;\n        break;\n\n    case MSR_IA32_TSC:\n        hvm_set_guest_tsc(v, msr_content);\n        break;\n\n    case MSR_IA32_TSC_ADJUST:\n        hvm_set_guest_tsc_adjust(v, msr_content);\n        break;\n\n    case MSR_TSC_AUX:\n        v->arch.hvm_vcpu.msr_tsc_aux = (uint32_t)msr_content;\n        if ( cpu_has_rdtscp\n             && (v->domain->arch.tsc_mode != TSC_MODE_PVRDTSCP) )\n            wrmsrl(MSR_TSC_AUX, (uint32_t)msr_content);\n        break;\n\n    case MSR_IA32_APICBASE:\n        if ( !vlapic_msr_set(vcpu_vlapic(v), msr_content) )\n            goto gp_fault;\n        break;\n\n    case MSR_IA32_TSC_DEADLINE:\n        vlapic_tdt_msr_set(vcpu_vlapic(v), msr_content);\n        break;\n\n    case MSR_IA32_APICBASE_MSR ... MSR_IA32_APICBASE_MSR + 0xff:\n        if ( hvm_x2apic_msr_write(v, msr, msr_content) )\n            goto gp_fault;\n        break;\n\n    case MSR_IA32_CR_PAT:\n        if ( !hvm_set_guest_pat(v, msr_content) )\n           goto gp_fault;\n        break;\n\n    case MSR_MTRRcap:\n        if ( !mtrr )\n            goto gp_fault;\n        goto gp_fault;\n    case MSR_MTRRdefType:\n        if ( !mtrr )\n            goto gp_fault;\n        if ( !mtrr_def_type_msr_set(v->domain, &v->arch.hvm_vcpu.mtrr,\n                                    msr_content) )\n           goto gp_fault;\n        break;\n    case MSR_MTRRfix64K_00000:\n        if ( !mtrr )\n            goto gp_fault;\n        if ( !mtrr_fix_range_msr_set(v->domain, &v->arch.hvm_vcpu.mtrr, 0,\n                                     msr_content) )\n            goto gp_fault;\n        break;\n    case MSR_MTRRfix16K_80000:\n    case MSR_MTRRfix16K_A0000:\n        if ( !mtrr )\n            goto gp_fault;\n        index = msr - MSR_MTRRfix16K_80000 + 1;\n        if ( !mtrr_fix_range_msr_set(v->domain, &v->arch.hvm_vcpu.mtrr,\n                                     index, msr_content) )\n            goto gp_fault;\n        break;\n    case MSR_MTRRfix4K_C0000...MSR_MTRRfix4K_F8000:\n        if ( !mtrr )\n            goto gp_fault;\n        index = msr - MSR_MTRRfix4K_C0000 + 3;\n        if ( !mtrr_fix_range_msr_set(v->domain, &v->arch.hvm_vcpu.mtrr,\n                                     index, msr_content) )\n            goto gp_fault;\n        break;\n    case MSR_IA32_MTRR_PHYSBASE(0)...MSR_IA32_MTRR_PHYSMASK(MTRR_VCNT-1):\n        if ( !mtrr )\n            goto gp_fault;\n        if ( !mtrr_var_range_msr_set(v->domain, &v->arch.hvm_vcpu.mtrr,\n                                     msr, msr_content) )\n            goto gp_fault;\n        break;\n\n    case MSR_AMD64_NB_CFG:\n        /* ignore the write */\n        break;\n\n    default:\n        if ( (ret = vmce_wrmsr(msr, msr_content)) < 0 )\n            goto gp_fault;\n        /* If ret == 0 then this is not an MCE MSR, see other MSRs. */\n        ret = ((ret == 0)\n               ? hvm_funcs.msr_write_intercept(msr, msr_content)\n               : X86EMUL_OKAY);\n        break;\n    }\n\n    return ret;\n\ngp_fault:\n    hvm_inject_hw_exception(TRAP_gp_fault, 0);\n    return X86EMUL_EXCEPTION;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -44,7 +44,7 @@\n         vlapic_tdt_msr_set(vcpu_vlapic(v), msr_content);\n         break;\n \n-    case MSR_IA32_APICBASE_MSR ... MSR_IA32_APICBASE_MSR + 0x3ff:\n+    case MSR_IA32_APICBASE_MSR ... MSR_IA32_APICBASE_MSR + 0xff:\n         if ( hvm_x2apic_msr_write(v, msr, msr_content) )\n             goto gp_fault;\n         break;",
        "diff_line_info": {
            "deleted_lines": [
                "    case MSR_IA32_APICBASE_MSR ... MSR_IA32_APICBASE_MSR + 0x3ff:"
            ],
            "added_lines": [
                "    case MSR_IA32_APICBASE_MSR ... MSR_IA32_APICBASE_MSR + 0xff:"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-9621",
        "func_name": "file/donote",
        "description": "The ELF parser in file 5.16 through 5.21 allows remote attackers to cause a denial of service via a long string.",
        "git_url": "https://github.com/file/file/commit/65437cee25199dbd385fb35901bc0011e164276c",
        "commit_title": "Limit string printing to 100 chars, and add flags I forgot in the previous",
        "commit_text": "commit.",
        "func_before": "private size_t\ndonote(struct magic_set *ms, void *vbuf, size_t offset, size_t size,\n    int clazz, int swap, size_t align, int *flags, uint16_t *notecount)\n{\n\tElf32_Nhdr nh32;\n\tElf64_Nhdr nh64;\n\tsize_t noff, doff;\n\tuint32_t namesz, descsz;\n\tunsigned char *nbuf = CAST(unsigned char *, vbuf);\n\n\tif (*notecount == 0)\n\t\treturn 0;\n\t--*notecount;\n\n\tif (xnh_sizeof + offset > size) {\n\t\t/*\n\t\t * We're out of note headers.\n\t\t */\n\t\treturn xnh_sizeof + offset;\n\t}\n\n\t(void)memcpy(xnh_addr, &nbuf[offset], xnh_sizeof);\n\toffset += xnh_sizeof;\n\n\tnamesz = xnh_namesz;\n\tdescsz = xnh_descsz;\n\tif ((namesz == 0) && (descsz == 0)) {\n\t\t/*\n\t\t * We're out of note headers.\n\t\t */\n\t\treturn (offset >= size) ? offset : size;\n\t}\n\n\tif (namesz & 0x80000000) {\n\t    (void)file_printf(ms, \", bad note name size 0x%lx\",\n\t\t(unsigned long)namesz);\n\t    return 0;\n\t}\n\n\tif (descsz & 0x80000000) {\n\t    (void)file_printf(ms, \", bad note description size 0x%lx\",\n\t\t(unsigned long)descsz);\n\t    return 0;\n\t}\n\n\tnoff = offset;\n\tdoff = ELF_ALIGN(offset + namesz);\n\n\tif (offset + namesz > size) {\n\t\t/*\n\t\t * We're past the end of the buffer.\n\t\t */\n\t\treturn doff;\n\t}\n\n\toffset = ELF_ALIGN(doff + descsz);\n\tif (doff + descsz > size) {\n\t\t/*\n\t\t * We're past the end of the buffer.\n\t\t */\n\t\treturn (offset >= size) ? offset : size;\n\t}\n\n\tif ((*flags & FLAGS_DID_OS_NOTE) == 0) {\n\t\tif (do_os_note(ms, nbuf, xnh_type, swap,\n\t\t    namesz, descsz, noff, doff, flags))\n\t\t\treturn size;\n\t}\n\n\tif ((*flags & FLAGS_DID_BUILD_ID) == 0) {\n\t\tif (do_bid_note(ms, nbuf, xnh_type, swap,\n\t\t    namesz, descsz, noff, doff, flags))\n\t\t\treturn size;\n\t}\n\t\t\n\tif ((*flags & FLAGS_DID_NETBSD_PAX) == 0) {\n\t\tif (do_pax_note(ms, nbuf, xnh_type, swap,\n\t\t    namesz, descsz, noff, doff, flags))\n\t\t\treturn size;\n\t}\n\n\tif ((*flags & FLAGS_DID_CORE) == 0) {\n\t\tif (do_core_note(ms, nbuf, xnh_type, swap,\n\t\t    namesz, descsz, noff, doff, flags, size, clazz))\n\t\t\treturn size;\n\t}\n\n\tif (namesz == 7 && strcmp((char *)&nbuf[noff], \"NetBSD\") == 0) {\n\t\tswitch (xnh_type) {\n\t    \tcase NT_NETBSD_VERSION:\n\t\t\treturn size;\n\t\tcase NT_NETBSD_MARCH:\n\t\t\tif (*flags & FLAGS_DID_NETBSD_MARCH)\n\t\t\t\treturn size;\n\t\t\tif (file_printf(ms, \", compiled for: %.*s\", (int)descsz,\n\t\t\t    (const char *)&nbuf[doff]) == -1)\n\t\t\t\treturn size;\n\t\t\tbreak;\n\t\tcase NT_NETBSD_CMODEL:\n\t\t\tif (*flags & FLAGS_DID_NETBSD_CMODEL)\n\t\t\t\treturn size;\n\t\t\tif (file_printf(ms, \", compiler model: %.*s\",\n\t\t\t    (int)descsz, (const char *)&nbuf[doff]) == -1)\n\t\t\t\treturn size;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tif (*flags & FLAGS_DID_NETBSD_UNKNOWN)\n\t\t\t\treturn size;\n\t\t\tif (file_printf(ms, \", note=%u\", xnh_type) == -1)\n\t\t\t\treturn size;\n\t\t\tbreak;\n\t\t}\n\t\treturn size;\n\t}\n\n\treturn offset;\n}",
        "func": "private size_t\ndonote(struct magic_set *ms, void *vbuf, size_t offset, size_t size,\n    int clazz, int swap, size_t align, int *flags, uint16_t *notecount)\n{\n\tElf32_Nhdr nh32;\n\tElf64_Nhdr nh64;\n\tsize_t noff, doff;\n\tuint32_t namesz, descsz;\n\tunsigned char *nbuf = CAST(unsigned char *, vbuf);\n\n\tif (*notecount == 0)\n\t\treturn 0;\n\t--*notecount;\n\n\tif (xnh_sizeof + offset > size) {\n\t\t/*\n\t\t * We're out of note headers.\n\t\t */\n\t\treturn xnh_sizeof + offset;\n\t}\n\n\t(void)memcpy(xnh_addr, &nbuf[offset], xnh_sizeof);\n\toffset += xnh_sizeof;\n\n\tnamesz = xnh_namesz;\n\tdescsz = xnh_descsz;\n\tif ((namesz == 0) && (descsz == 0)) {\n\t\t/*\n\t\t * We're out of note headers.\n\t\t */\n\t\treturn (offset >= size) ? offset : size;\n\t}\n\n\tif (namesz & 0x80000000) {\n\t    (void)file_printf(ms, \", bad note name size 0x%lx\",\n\t\t(unsigned long)namesz);\n\t    return 0;\n\t}\n\n\tif (descsz & 0x80000000) {\n\t    (void)file_printf(ms, \", bad note description size 0x%lx\",\n\t\t(unsigned long)descsz);\n\t    return 0;\n\t}\n\n\tnoff = offset;\n\tdoff = ELF_ALIGN(offset + namesz);\n\n\tif (offset + namesz > size) {\n\t\t/*\n\t\t * We're past the end of the buffer.\n\t\t */\n\t\treturn doff;\n\t}\n\n\toffset = ELF_ALIGN(doff + descsz);\n\tif (doff + descsz > size) {\n\t\t/*\n\t\t * We're past the end of the buffer.\n\t\t */\n\t\treturn (offset >= size) ? offset : size;\n\t}\n\n\tif ((*flags & FLAGS_DID_OS_NOTE) == 0) {\n\t\tif (do_os_note(ms, nbuf, xnh_type, swap,\n\t\t    namesz, descsz, noff, doff, flags))\n\t\t\treturn size;\n\t}\n\n\tif ((*flags & FLAGS_DID_BUILD_ID) == 0) {\n\t\tif (do_bid_note(ms, nbuf, xnh_type, swap,\n\t\t    namesz, descsz, noff, doff, flags))\n\t\t\treturn size;\n\t}\n\t\t\n\tif ((*flags & FLAGS_DID_NETBSD_PAX) == 0) {\n\t\tif (do_pax_note(ms, nbuf, xnh_type, swap,\n\t\t    namesz, descsz, noff, doff, flags))\n\t\t\treturn size;\n\t}\n\n\tif ((*flags & FLAGS_DID_CORE) == 0) {\n\t\tif (do_core_note(ms, nbuf, xnh_type, swap,\n\t\t    namesz, descsz, noff, doff, flags, size, clazz))\n\t\t\treturn size;\n\t}\n\n\tif (namesz == 7 && strcmp((char *)&nbuf[noff], \"NetBSD\") == 0) {\n\t\tif (descsz > 100)\n\t\t\tdescsz = 100;\n\t\tswitch (xnh_type) {\n\t    \tcase NT_NETBSD_VERSION:\n\t\t\treturn size;\n\t\tcase NT_NETBSD_MARCH:\n\t\t\tif (*flags & FLAGS_DID_NETBSD_MARCH)\n\t\t\t\treturn size;\n\t\t\t*flags |= FLAGS_DID_NETBSD_MARCH;\n\t\t\tif (file_printf(ms, \", compiled for: %.*s\",\n\t\t\t    (int)descsz, (const char *)&nbuf[doff]) == -1)\n\t\t\t\treturn size;\n\t\t\tbreak;\n\t\tcase NT_NETBSD_CMODEL:\n\t\t\tif (*flags & FLAGS_DID_NETBSD_CMODEL)\n\t\t\t\treturn size;\n\t\t\t*flags |= FLAGS_DID_NETBSD_CMODEL;\n\t\t\tif (file_printf(ms, \", compiler model: %.*s\",\n\t\t\t    (int)descsz, (const char *)&nbuf[doff]) == -1)\n\t\t\t\treturn size;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tif (*flags & FLAGS_DID_NETBSD_UNKNOWN)\n\t\t\t\treturn size;\n\t\t\t*flags |= FLAGS_DID_NETBSD_UNKNOWN;\n\t\t\tif (file_printf(ms, \", note=%u\", xnh_type) == -1)\n\t\t\t\treturn size;\n\t\t\tbreak;\n\t\t}\n\t\treturn size;\n\t}\n\n\treturn offset;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -86,19 +86,23 @@\n \t}\n \n \tif (namesz == 7 && strcmp((char *)&nbuf[noff], \"NetBSD\") == 0) {\n+\t\tif (descsz > 100)\n+\t\t\tdescsz = 100;\n \t\tswitch (xnh_type) {\n \t    \tcase NT_NETBSD_VERSION:\n \t\t\treturn size;\n \t\tcase NT_NETBSD_MARCH:\n \t\t\tif (*flags & FLAGS_DID_NETBSD_MARCH)\n \t\t\t\treturn size;\n-\t\t\tif (file_printf(ms, \", compiled for: %.*s\", (int)descsz,\n-\t\t\t    (const char *)&nbuf[doff]) == -1)\n+\t\t\t*flags |= FLAGS_DID_NETBSD_MARCH;\n+\t\t\tif (file_printf(ms, \", compiled for: %.*s\",\n+\t\t\t    (int)descsz, (const char *)&nbuf[doff]) == -1)\n \t\t\t\treturn size;\n \t\t\tbreak;\n \t\tcase NT_NETBSD_CMODEL:\n \t\t\tif (*flags & FLAGS_DID_NETBSD_CMODEL)\n \t\t\t\treturn size;\n+\t\t\t*flags |= FLAGS_DID_NETBSD_CMODEL;\n \t\t\tif (file_printf(ms, \", compiler model: %.*s\",\n \t\t\t    (int)descsz, (const char *)&nbuf[doff]) == -1)\n \t\t\t\treturn size;\n@@ -106,6 +110,7 @@\n \t\tdefault:\n \t\t\tif (*flags & FLAGS_DID_NETBSD_UNKNOWN)\n \t\t\t\treturn size;\n+\t\t\t*flags |= FLAGS_DID_NETBSD_UNKNOWN;\n \t\t\tif (file_printf(ms, \", note=%u\", xnh_type) == -1)\n \t\t\t\treturn size;\n \t\t\tbreak;",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\tif (file_printf(ms, \", compiled for: %.*s\", (int)descsz,",
                "\t\t\t    (const char *)&nbuf[doff]) == -1)"
            ],
            "added_lines": [
                "\t\tif (descsz > 100)",
                "\t\t\tdescsz = 100;",
                "\t\t\t*flags |= FLAGS_DID_NETBSD_MARCH;",
                "\t\t\tif (file_printf(ms, \", compiled for: %.*s\",",
                "\t\t\t    (int)descsz, (const char *)&nbuf[doff]) == -1)",
                "\t\t\t*flags |= FLAGS_DID_NETBSD_CMODEL;",
                "\t\t\t*flags |= FLAGS_DID_NETBSD_UNKNOWN;"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1563",
        "func_name": "xen-project/xen/vgic_v2_distr_mmio_read",
        "description": "The ARM GIC distributor virtualization in Xen 4.4.x and 4.5.x allows local guests to cause a denial of service by causing a large number messages to be logged.",
        "git_url": "https://github.com/xen-project/xen/commit/d0b2caa80fccafbb131b28b7b8488001d82ab4bf",
        "commit_title": "xen/arm: vgic-v2: message in the emulation code should be rate-limited",
        "commit_text": " printk is not rated-limited by default. Therefore a malicious guest may be able to flood the Xen console.  If we use gdprintk, unecessary information will be printed such as the filename and the line. Instead use XENLOG_G_ERR combine with %pv.  This is XSA-118. ",
        "func_before": "static int vgic_v2_distr_mmio_read(struct vcpu *v, mmio_info_t *info)\n{\n    struct hsr_dabt dabt = info->dabt;\n    struct cpu_user_regs *regs = guest_cpu_user_regs();\n    register_t *r = select_user_reg(regs, dabt.reg);\n    struct vgic_irq_rank *rank;\n    int gicd_reg = (int)(info->gpa - v->domain->arch.vgic.dbase);\n    unsigned long flags;\n\n    perfc_incr(vgicd_reads);\n\n    switch ( gicd_reg )\n    {\n    case GICD_CTLR:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        vgic_lock(v);\n        *r = v->domain->arch.vgic.ctlr;\n        vgic_unlock(v);\n        return 1;\n    case GICD_TYPER:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        /* No secure world support for guests. */\n        vgic_lock(v);\n        *r = ( (v->domain->max_vcpus << 5) & GICD_TYPE_CPUS )\n            |( ((v->domain->arch.vgic.nr_spis / 32)) & GICD_TYPE_LINES );\n        vgic_unlock(v);\n        return 1;\n    case GICD_IIDR:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        /*\n         * XXX Do we need a JEP106 manufacturer ID?\n         * Just use the physical h/w value for now\n         */\n        *r = 0x0000043b;\n        return 1;\n\n    /* Implementation defined -- read as zero */\n    case 0x020 ... 0x03c:\n        goto read_as_zero;\n\n    case GICD_IGROUPR ... GICD_IGROUPRN:\n        /* We do not implement security extensions for guests, read zero */\n        goto read_as_zero;\n\n    case GICD_ISENABLER ... GICD_ISENABLERN:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 1, gicd_reg - GICD_ISENABLER, DABT_WORD);\n        if ( rank == NULL) goto read_as_zero;\n        vgic_lock_rank(v, rank, flags);\n        *r = rank->ienable;\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n\n    case GICD_ICENABLER ... GICD_ICENABLERN:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 1, gicd_reg - GICD_ICENABLER, DABT_WORD);\n        if ( rank == NULL) goto read_as_zero;\n        vgic_lock_rank(v, rank, flags);\n        *r = rank->ienable;\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n\n    case GICD_ISPENDR ... GICD_ISPENDRN:\n        if ( dabt.size != DABT_BYTE && dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 1, gicd_reg - GICD_ISPENDR, DABT_WORD);\n        if ( rank == NULL) goto read_as_zero;\n        vgic_lock_rank(v, rank, flags);\n        *r = vgic_byte_read(rank->ipend, dabt.sign, gicd_reg);\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n\n    case GICD_ICPENDR ... GICD_ICPENDRN:\n        if ( dabt.size != DABT_BYTE && dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 1, gicd_reg - GICD_ICPENDR, DABT_WORD);\n        if ( rank == NULL) goto read_as_zero;\n        vgic_lock_rank(v, rank, flags);\n        *r = vgic_byte_read(rank->ipend, dabt.sign, gicd_reg);\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n\n    case GICD_ISACTIVER ... GICD_ISACTIVERN:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 1, gicd_reg - GICD_ISACTIVER, DABT_WORD);\n        if ( rank == NULL) goto read_as_zero;\n        vgic_lock_rank(v, rank, flags);\n        *r = rank->iactive;\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n\n    case GICD_ICACTIVER ... GICD_ICACTIVERN:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 1, gicd_reg - GICD_ICACTIVER, DABT_WORD);\n        if ( rank == NULL) goto read_as_zero;\n        vgic_lock_rank(v, rank, flags);\n        *r = rank->iactive;\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n\n    case GICD_ITARGETSR ... GICD_ITARGETSRN:\n        if ( dabt.size != DABT_BYTE && dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 8, gicd_reg - GICD_ITARGETSR, DABT_WORD);\n        if ( rank == NULL) goto read_as_zero;\n        vgic_lock_rank(v, rank, flags);\n        *r = rank->v2.itargets[REG_RANK_INDEX(8, gicd_reg - GICD_ITARGETSR,\n                                              DABT_WORD)];\n        if ( dabt.size == DABT_BYTE )\n            *r = vgic_byte_read(*r, dabt.sign, gicd_reg);\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n\n    case GICD_IPRIORITYR ... GICD_IPRIORITYRN:\n        if ( dabt.size != DABT_BYTE && dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 8, gicd_reg - GICD_IPRIORITYR, DABT_WORD);\n        if ( rank == NULL) goto read_as_zero;\n\n        vgic_lock_rank(v, rank, flags);\n        *r = rank->ipriority[REG_RANK_INDEX(8, gicd_reg - GICD_IPRIORITYR,\n                                            DABT_WORD)];\n        if ( dabt.size == DABT_BYTE )\n            *r = vgic_byte_read(*r, dabt.sign, gicd_reg);\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n\n    case GICD_ICFGR ... GICD_ICFGRN:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 2, gicd_reg - GICD_ICFGR, DABT_WORD);\n        if ( rank == NULL) goto read_as_zero;\n        vgic_lock_rank(v, rank, flags);\n        *r = rank->icfg[REG_RANK_INDEX(2, gicd_reg - GICD_ICFGR, DABT_WORD)];\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n\n    case GICD_NSACR ... GICD_NSACRN:\n        /* We do not implement security extensions for guests, read zero */\n        goto read_as_zero;\n\n    case GICD_SGIR:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        /* Write only -- read unknown */\n        *r = 0xdeadbeef;\n        return 1;\n\n    case GICD_CPENDSGIR ... GICD_CPENDSGIRN:\n        if ( dabt.size != DABT_BYTE && dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 1, gicd_reg - GICD_CPENDSGIR, DABT_WORD);\n        if ( rank == NULL) goto read_as_zero;\n        vgic_lock_rank(v, rank, flags);\n        *r = vgic_byte_read(rank->pendsgi, dabt.sign, gicd_reg);\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n\n    case GICD_SPENDSGIR ... GICD_SPENDSGIRN:\n        if ( dabt.size != DABT_BYTE && dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 1, gicd_reg - GICD_SPENDSGIR, DABT_WORD);\n        if ( rank == NULL) goto read_as_zero;\n        vgic_lock_rank(v, rank, flags);\n        *r = vgic_byte_read(rank->pendsgi, dabt.sign, gicd_reg);\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n\n    /* Implementation defined -- read as zero */\n    case 0xfd0 ... 0xfe4:\n        goto read_as_zero;\n\n    case GICD_ICPIDR2:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        printk(\"vGICD: unhandled read from ICPIDR2\\n\");\n        return 0;\n\n    /* Implementation defined -- read as zero */\n    case 0xfec ... 0xffc:\n        goto read_as_zero;\n\n    /* Reserved -- read as zero */\n    case 0x00c ... 0x01c:\n    case 0x040 ... 0x07c:\n    case 0x7fc:\n    case 0xbfc:\n    case 0xf04 ... 0xf0c:\n    case 0xf30 ... 0xfcc:\n        goto read_as_zero;\n\n    default:\n        printk(\"vGICD: unhandled read r%d offset %#08x\\n\",\n               dabt.reg, gicd_reg);\n        return 0;\n    }\n\nbad_width:\n    printk(\"vGICD: bad read width %d r%d offset %#08x\\n\",\n           dabt.size, dabt.reg, gicd_reg);\n    domain_crash_synchronous();\n    return 0;\n\nread_as_zero:\n    if ( dabt.size != DABT_WORD ) goto bad_width;\n    *r = 0;\n    return 1;\n}",
        "func": "static int vgic_v2_distr_mmio_read(struct vcpu *v, mmio_info_t *info)\n{\n    struct hsr_dabt dabt = info->dabt;\n    struct cpu_user_regs *regs = guest_cpu_user_regs();\n    register_t *r = select_user_reg(regs, dabt.reg);\n    struct vgic_irq_rank *rank;\n    int gicd_reg = (int)(info->gpa - v->domain->arch.vgic.dbase);\n    unsigned long flags;\n\n    perfc_incr(vgicd_reads);\n\n    switch ( gicd_reg )\n    {\n    case GICD_CTLR:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        vgic_lock(v);\n        *r = v->domain->arch.vgic.ctlr;\n        vgic_unlock(v);\n        return 1;\n    case GICD_TYPER:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        /* No secure world support for guests. */\n        vgic_lock(v);\n        *r = ( (v->domain->max_vcpus << 5) & GICD_TYPE_CPUS )\n            |( ((v->domain->arch.vgic.nr_spis / 32)) & GICD_TYPE_LINES );\n        vgic_unlock(v);\n        return 1;\n    case GICD_IIDR:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        /*\n         * XXX Do we need a JEP106 manufacturer ID?\n         * Just use the physical h/w value for now\n         */\n        *r = 0x0000043b;\n        return 1;\n\n    /* Implementation defined -- read as zero */\n    case 0x020 ... 0x03c:\n        goto read_as_zero;\n\n    case GICD_IGROUPR ... GICD_IGROUPRN:\n        /* We do not implement security extensions for guests, read zero */\n        goto read_as_zero;\n\n    case GICD_ISENABLER ... GICD_ISENABLERN:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 1, gicd_reg - GICD_ISENABLER, DABT_WORD);\n        if ( rank == NULL) goto read_as_zero;\n        vgic_lock_rank(v, rank, flags);\n        *r = rank->ienable;\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n\n    case GICD_ICENABLER ... GICD_ICENABLERN:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 1, gicd_reg - GICD_ICENABLER, DABT_WORD);\n        if ( rank == NULL) goto read_as_zero;\n        vgic_lock_rank(v, rank, flags);\n        *r = rank->ienable;\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n\n    case GICD_ISPENDR ... GICD_ISPENDRN:\n        if ( dabt.size != DABT_BYTE && dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 1, gicd_reg - GICD_ISPENDR, DABT_WORD);\n        if ( rank == NULL) goto read_as_zero;\n        vgic_lock_rank(v, rank, flags);\n        *r = vgic_byte_read(rank->ipend, dabt.sign, gicd_reg);\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n\n    case GICD_ICPENDR ... GICD_ICPENDRN:\n        if ( dabt.size != DABT_BYTE && dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 1, gicd_reg - GICD_ICPENDR, DABT_WORD);\n        if ( rank == NULL) goto read_as_zero;\n        vgic_lock_rank(v, rank, flags);\n        *r = vgic_byte_read(rank->ipend, dabt.sign, gicd_reg);\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n\n    case GICD_ISACTIVER ... GICD_ISACTIVERN:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 1, gicd_reg - GICD_ISACTIVER, DABT_WORD);\n        if ( rank == NULL) goto read_as_zero;\n        vgic_lock_rank(v, rank, flags);\n        *r = rank->iactive;\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n\n    case GICD_ICACTIVER ... GICD_ICACTIVERN:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 1, gicd_reg - GICD_ICACTIVER, DABT_WORD);\n        if ( rank == NULL) goto read_as_zero;\n        vgic_lock_rank(v, rank, flags);\n        *r = rank->iactive;\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n\n    case GICD_ITARGETSR ... GICD_ITARGETSRN:\n        if ( dabt.size != DABT_BYTE && dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 8, gicd_reg - GICD_ITARGETSR, DABT_WORD);\n        if ( rank == NULL) goto read_as_zero;\n        vgic_lock_rank(v, rank, flags);\n        *r = rank->v2.itargets[REG_RANK_INDEX(8, gicd_reg - GICD_ITARGETSR,\n                                              DABT_WORD)];\n        if ( dabt.size == DABT_BYTE )\n            *r = vgic_byte_read(*r, dabt.sign, gicd_reg);\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n\n    case GICD_IPRIORITYR ... GICD_IPRIORITYRN:\n        if ( dabt.size != DABT_BYTE && dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 8, gicd_reg - GICD_IPRIORITYR, DABT_WORD);\n        if ( rank == NULL) goto read_as_zero;\n\n        vgic_lock_rank(v, rank, flags);\n        *r = rank->ipriority[REG_RANK_INDEX(8, gicd_reg - GICD_IPRIORITYR,\n                                            DABT_WORD)];\n        if ( dabt.size == DABT_BYTE )\n            *r = vgic_byte_read(*r, dabt.sign, gicd_reg);\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n\n    case GICD_ICFGR ... GICD_ICFGRN:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 2, gicd_reg - GICD_ICFGR, DABT_WORD);\n        if ( rank == NULL) goto read_as_zero;\n        vgic_lock_rank(v, rank, flags);\n        *r = rank->icfg[REG_RANK_INDEX(2, gicd_reg - GICD_ICFGR, DABT_WORD)];\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n\n    case GICD_NSACR ... GICD_NSACRN:\n        /* We do not implement security extensions for guests, read zero */\n        goto read_as_zero;\n\n    case GICD_SGIR:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        /* Write only -- read unknown */\n        *r = 0xdeadbeef;\n        return 1;\n\n    case GICD_CPENDSGIR ... GICD_CPENDSGIRN:\n        if ( dabt.size != DABT_BYTE && dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 1, gicd_reg - GICD_CPENDSGIR, DABT_WORD);\n        if ( rank == NULL) goto read_as_zero;\n        vgic_lock_rank(v, rank, flags);\n        *r = vgic_byte_read(rank->pendsgi, dabt.sign, gicd_reg);\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n\n    case GICD_SPENDSGIR ... GICD_SPENDSGIRN:\n        if ( dabt.size != DABT_BYTE && dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 1, gicd_reg - GICD_SPENDSGIR, DABT_WORD);\n        if ( rank == NULL) goto read_as_zero;\n        vgic_lock_rank(v, rank, flags);\n        *r = vgic_byte_read(rank->pendsgi, dabt.sign, gicd_reg);\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n\n    /* Implementation defined -- read as zero */\n    case 0xfd0 ... 0xfe4:\n        goto read_as_zero;\n\n    case GICD_ICPIDR2:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        printk(XENLOG_G_ERR \"%pv: vGICD: unhandled read from ICPIDR2\\n\", v);\n        return 0;\n\n    /* Implementation defined -- read as zero */\n    case 0xfec ... 0xffc:\n        goto read_as_zero;\n\n    /* Reserved -- read as zero */\n    case 0x00c ... 0x01c:\n    case 0x040 ... 0x07c:\n    case 0x7fc:\n    case 0xbfc:\n    case 0xf04 ... 0xf0c:\n    case 0xf30 ... 0xfcc:\n        goto read_as_zero;\n\n    default:\n        printk(XENLOG_G_ERR \"%pv: vGICD: unhandled read r%d offset %#08x\\n\",\n               v, dabt.reg, gicd_reg);\n        return 0;\n    }\n\nbad_width:\n    printk(XENLOG_G_ERR \"%pv: vGICD: bad read width %d r%d offset %#08x\\n\",\n           v, dabt.size, dabt.reg, gicd_reg);\n    domain_crash_synchronous();\n    return 0;\n\nread_as_zero:\n    if ( dabt.size != DABT_WORD ) goto bad_width;\n    *r = 0;\n    return 1;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -164,7 +164,7 @@\n \n     case GICD_ICPIDR2:\n         if ( dabt.size != DABT_WORD ) goto bad_width;\n-        printk(\"vGICD: unhandled read from ICPIDR2\\n\");\n+        printk(XENLOG_G_ERR \"%pv: vGICD: unhandled read from ICPIDR2\\n\", v);\n         return 0;\n \n     /* Implementation defined -- read as zero */\n@@ -181,14 +181,14 @@\n         goto read_as_zero;\n \n     default:\n-        printk(\"vGICD: unhandled read r%d offset %#08x\\n\",\n-               dabt.reg, gicd_reg);\n+        printk(XENLOG_G_ERR \"%pv: vGICD: unhandled read r%d offset %#08x\\n\",\n+               v, dabt.reg, gicd_reg);\n         return 0;\n     }\n \n bad_width:\n-    printk(\"vGICD: bad read width %d r%d offset %#08x\\n\",\n-           dabt.size, dabt.reg, gicd_reg);\n+    printk(XENLOG_G_ERR \"%pv: vGICD: bad read width %d r%d offset %#08x\\n\",\n+           v, dabt.size, dabt.reg, gicd_reg);\n     domain_crash_synchronous();\n     return 0;\n ",
        "diff_line_info": {
            "deleted_lines": [
                "        printk(\"vGICD: unhandled read from ICPIDR2\\n\");",
                "        printk(\"vGICD: unhandled read r%d offset %#08x\\n\",",
                "               dabt.reg, gicd_reg);",
                "    printk(\"vGICD: bad read width %d r%d offset %#08x\\n\",",
                "           dabt.size, dabt.reg, gicd_reg);"
            ],
            "added_lines": [
                "        printk(XENLOG_G_ERR \"%pv: vGICD: unhandled read from ICPIDR2\\n\", v);",
                "        printk(XENLOG_G_ERR \"%pv: vGICD: unhandled read r%d offset %#08x\\n\",",
                "               v, dabt.reg, gicd_reg);",
                "    printk(XENLOG_G_ERR \"%pv: vGICD: bad read width %d r%d offset %#08x\\n\",",
                "           v, dabt.size, dabt.reg, gicd_reg);"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1563",
        "func_name": "xen-project/xen/vgic_v2_distr_mmio_write",
        "description": "The ARM GIC distributor virtualization in Xen 4.4.x and 4.5.x allows local guests to cause a denial of service by causing a large number messages to be logged.",
        "git_url": "https://github.com/xen-project/xen/commit/d0b2caa80fccafbb131b28b7b8488001d82ab4bf",
        "commit_title": "xen/arm: vgic-v2: message in the emulation code should be rate-limited",
        "commit_text": " printk is not rated-limited by default. Therefore a malicious guest may be able to flood the Xen console.  If we use gdprintk, unecessary information will be printed such as the filename and the line. Instead use XENLOG_G_ERR combine with %pv.  This is XSA-118. ",
        "func_before": "static int vgic_v2_distr_mmio_write(struct vcpu *v, mmio_info_t *info)\n{\n    struct hsr_dabt dabt = info->dabt;\n    struct cpu_user_regs *regs = guest_cpu_user_regs();\n    register_t *r = select_user_reg(regs, dabt.reg);\n    struct vgic_irq_rank *rank;\n    int gicd_reg = (int)(info->gpa - v->domain->arch.vgic.dbase);\n    uint32_t tr;\n    unsigned long flags;\n\n    perfc_incr(vgicd_writes);\n\n    switch ( gicd_reg )\n    {\n    case GICD_CTLR:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        /* Ignore all but the enable bit */\n        v->domain->arch.vgic.ctlr = (*r) & GICD_CTL_ENABLE;\n        return 1;\n\n    /* R/O -- write ignored */\n    case GICD_TYPER:\n    case GICD_IIDR:\n        goto write_ignore;\n\n    /* Implementation defined -- write ignored */\n    case 0x020 ... 0x03c:\n        goto write_ignore;\n\n    case GICD_IGROUPR ... GICD_IGROUPRN:\n        /* We do not implement security extensions for guests, write ignore */\n        goto write_ignore;\n\n    case GICD_ISENABLER ... GICD_ISENABLERN:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 1, gicd_reg - GICD_ISENABLER, DABT_WORD);\n        if ( rank == NULL) goto write_ignore;\n        vgic_lock_rank(v, rank, flags);\n        tr = rank->ienable;\n        rank->ienable |= *r;\n        /* The virtual irq is derived from register offset.\n         * The register difference is word difference. So divide by 2(DABT_WORD)\n         * to get Virtual irq number */\n        vgic_enable_irqs(v, (*r) & (~tr),\n                         (gicd_reg - GICD_ISENABLER) >> DABT_WORD);\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n\n    case GICD_ICENABLER ... GICD_ICENABLERN:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 1, gicd_reg - GICD_ICENABLER, DABT_WORD);\n        if ( rank == NULL) goto write_ignore;\n        vgic_lock_rank(v, rank, flags);\n        tr = rank->ienable;\n        rank->ienable &= ~*r;\n        /* The virtual irq is derived from register offset.\n         * The register difference is word difference. So divide by 2(DABT_WORD)\n         * to get  Virtual irq number */\n        vgic_disable_irqs(v, (*r) & tr,\n                         (gicd_reg - GICD_ICENABLER) >> DABT_WORD);\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n\n    case GICD_ISPENDR ... GICD_ISPENDRN:\n        if ( dabt.size != DABT_BYTE && dabt.size != DABT_WORD ) goto bad_width;\n        printk(\"vGICD: unhandled %s write %#\"PRIregister\" to ISPENDR%d\\n\",\n               dabt.size ? \"word\" : \"byte\", *r, gicd_reg - GICD_ISPENDR);\n        return 0;\n\n    case GICD_ICPENDR ... GICD_ICPENDRN:\n        if ( dabt.size != DABT_BYTE && dabt.size != DABT_WORD ) goto bad_width;\n        printk(\"vGICD: unhandled %s write %#\"PRIregister\" to ICPENDR%d\\n\",\n               dabt.size ? \"word\" : \"byte\", *r, gicd_reg - GICD_ICPENDR);\n        return 0;\n\n    case GICD_ISACTIVER ... GICD_ISACTIVERN:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 1, gicd_reg - GICD_ISACTIVER, DABT_WORD);\n        if ( rank == NULL) goto write_ignore;\n        vgic_lock_rank(v, rank, flags);\n        rank->iactive &= ~*r;\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n\n    case GICD_ICACTIVER ... GICD_ICACTIVERN:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 1, gicd_reg - GICD_ICACTIVER, DABT_WORD);\n        if ( rank == NULL) goto write_ignore;\n        vgic_lock_rank(v, rank, flags);\n        rank->iactive &= ~*r;\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n\n    case GICD_ITARGETSR ... GICD_ITARGETSR + 7:\n        /* SGI/PPI target is read only */\n        goto write_ignore;\n\n    case GICD_ITARGETSR + 8 ... GICD_ITARGETSRN:\n    {\n        /* unsigned long needed for find_next_bit */\n        unsigned long target;\n        int i;\n        if ( dabt.size != DABT_BYTE && dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 8, gicd_reg - GICD_ITARGETSR, DABT_WORD);\n        if ( rank == NULL) goto write_ignore;\n        /* 8-bit vcpu mask for this domain */\n        BUG_ON(v->domain->max_vcpus > 8);\n        target = (1 << v->domain->max_vcpus) - 1;\n        if ( dabt.size == 2 )\n            target = target | (target << 8) | (target << 16) | (target << 24);\n        else\n            target = (target << (8 * (gicd_reg & 0x3)));\n        target &= *r;\n        /* ignore zero writes */\n        if ( !target )\n            goto write_ignore;\n        /* For word reads ignore writes where any single byte is zero */\n        if ( dabt.size == 2 &&\n            !((target & 0xff) && (target & (0xff << 8)) &&\n             (target & (0xff << 16)) && (target & (0xff << 24))))\n            goto write_ignore;\n        vgic_lock_rank(v, rank, flags);\n        i = 0;\n        while ( (i = find_next_bit(&target, 32, i)) < 32 )\n        {\n            unsigned int irq, new_target, old_target;\n            unsigned long old_target_mask;\n            struct vcpu *v_target, *v_old;\n\n            new_target = i % 8;\n            old_target_mask = vgic_byte_read(rank->v2.itargets[REG_RANK_INDEX(8,\n                                             gicd_reg - GICD_ITARGETSR, DABT_WORD)], 0, i/8);\n            old_target = find_first_bit(&old_target_mask, 8);\n\n            if ( new_target != old_target )\n            {\n                irq = gicd_reg - GICD_ITARGETSR + (i / 8);\n                v_target = v->domain->vcpu[new_target];\n                v_old = v->domain->vcpu[old_target];\n                vgic_migrate_irq(v_old, v_target, irq);\n            }\n            i += 8 - new_target;\n        }\n        if ( dabt.size == DABT_WORD )\n            rank->v2.itargets[REG_RANK_INDEX(8, gicd_reg - GICD_ITARGETSR,\n                                             DABT_WORD)] = target;\n        else\n            vgic_byte_write(&rank->v2.itargets[REG_RANK_INDEX(8,\n                      gicd_reg - GICD_ITARGETSR, DABT_WORD)], target, gicd_reg);\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n    }\n\n    case GICD_IPRIORITYR ... GICD_IPRIORITYRN:\n        if ( dabt.size != DABT_BYTE && dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 8, gicd_reg - GICD_IPRIORITYR, DABT_WORD);\n        if ( rank == NULL) goto write_ignore;\n        vgic_lock_rank(v, rank, flags);\n        if ( dabt.size == DABT_WORD )\n            rank->ipriority[REG_RANK_INDEX(8, gicd_reg - GICD_IPRIORITYR,\n                                           DABT_WORD)] = *r;\n        else\n            vgic_byte_write(&rank->ipriority[REG_RANK_INDEX(8,\n                        gicd_reg - GICD_IPRIORITYR, DABT_WORD)], *r, gicd_reg);\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n\n    case GICD_ICFGR: /* SGIs */\n        goto write_ignore;\n    case GICD_ICFGR + 1: /* PPIs */\n        /* It is implementation defined if these are writeable. We chose not */\n        goto write_ignore;\n    case GICD_ICFGR + 2 ... GICD_ICFGRN: /* SPIs */\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 2, gicd_reg - GICD_ICFGR, DABT_WORD);\n        if ( rank == NULL) goto write_ignore;\n        vgic_lock_rank(v, rank, flags);\n        rank->icfg[REG_RANK_INDEX(2, gicd_reg - GICD_ICFGR, DABT_WORD)] = *r;\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n\n    case GICD_NSACR ... GICD_NSACRN:\n        /* We do not implement security extensions for guests, write ignore */\n        goto write_ignore;\n\n    case GICD_SGIR:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        return vgic_v2_to_sgi(v, *r);\n\n    case GICD_CPENDSGIR ... GICD_CPENDSGIRN:\n        if ( dabt.size != DABT_BYTE && dabt.size != DABT_WORD ) goto bad_width;\n        printk(\"vGICD: unhandled %s write %#\"PRIregister\" to ICPENDSGIR%d\\n\",\n               dabt.size ? \"word\" : \"byte\", *r, gicd_reg - GICD_CPENDSGIR);\n        return 0;\n\n    case GICD_SPENDSGIR ... GICD_SPENDSGIRN:\n        if ( dabt.size != DABT_BYTE && dabt.size != DABT_WORD ) goto bad_width;\n        printk(\"vGICD: unhandled %s write %#\"PRIregister\" to ISPENDSGIR%d\\n\",\n               dabt.size ? \"word\" : \"byte\", *r, gicd_reg - GICD_SPENDSGIR);\n        return 0;\n\n    /* Implementation defined -- write ignored */\n    case 0xfd0 ... 0xfe4:\n        goto write_ignore;\n\n    /* R/O -- write ignore */\n    case GICD_ICPIDR2:\n        goto write_ignore;\n\n    /* Implementation defined -- write ignored */\n    case 0xfec ... 0xffc:\n        goto write_ignore;\n\n    /* Reserved -- write ignored */\n    case 0x00c ... 0x01c:\n    case 0x040 ... 0x07c:\n    case 0x7fc:\n    case 0xbfc:\n    case 0xf04 ... 0xf0c:\n    case 0xf30 ... 0xfcc:\n        goto write_ignore;\n\n    default:\n        printk(\"vGICD: unhandled write r%d=%\"PRIregister\" offset %#08x\\n\",\n               dabt.reg, *r, gicd_reg);\n        return 0;\n    }\n\nbad_width:\n    printk(\"vGICD: bad write width %d r%d=%\"PRIregister\" offset %#08x\\n\",\n           dabt.size, dabt.reg, *r, gicd_reg);\n    domain_crash_synchronous();\n    return 0;\n\nwrite_ignore:\n    if ( dabt.size != DABT_WORD ) goto bad_width;\n    return 1;\n}",
        "func": "static int vgic_v2_distr_mmio_write(struct vcpu *v, mmio_info_t *info)\n{\n    struct hsr_dabt dabt = info->dabt;\n    struct cpu_user_regs *regs = guest_cpu_user_regs();\n    register_t *r = select_user_reg(regs, dabt.reg);\n    struct vgic_irq_rank *rank;\n    int gicd_reg = (int)(info->gpa - v->domain->arch.vgic.dbase);\n    uint32_t tr;\n    unsigned long flags;\n\n    perfc_incr(vgicd_writes);\n\n    switch ( gicd_reg )\n    {\n    case GICD_CTLR:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        /* Ignore all but the enable bit */\n        v->domain->arch.vgic.ctlr = (*r) & GICD_CTL_ENABLE;\n        return 1;\n\n    /* R/O -- write ignored */\n    case GICD_TYPER:\n    case GICD_IIDR:\n        goto write_ignore;\n\n    /* Implementation defined -- write ignored */\n    case 0x020 ... 0x03c:\n        goto write_ignore;\n\n    case GICD_IGROUPR ... GICD_IGROUPRN:\n        /* We do not implement security extensions for guests, write ignore */\n        goto write_ignore;\n\n    case GICD_ISENABLER ... GICD_ISENABLERN:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 1, gicd_reg - GICD_ISENABLER, DABT_WORD);\n        if ( rank == NULL) goto write_ignore;\n        vgic_lock_rank(v, rank, flags);\n        tr = rank->ienable;\n        rank->ienable |= *r;\n        /* The virtual irq is derived from register offset.\n         * The register difference is word difference. So divide by 2(DABT_WORD)\n         * to get Virtual irq number */\n        vgic_enable_irqs(v, (*r) & (~tr),\n                         (gicd_reg - GICD_ISENABLER) >> DABT_WORD);\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n\n    case GICD_ICENABLER ... GICD_ICENABLERN:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 1, gicd_reg - GICD_ICENABLER, DABT_WORD);\n        if ( rank == NULL) goto write_ignore;\n        vgic_lock_rank(v, rank, flags);\n        tr = rank->ienable;\n        rank->ienable &= ~*r;\n        /* The virtual irq is derived from register offset.\n         * The register difference is word difference. So divide by 2(DABT_WORD)\n         * to get  Virtual irq number */\n        vgic_disable_irqs(v, (*r) & tr,\n                         (gicd_reg - GICD_ICENABLER) >> DABT_WORD);\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n\n    case GICD_ISPENDR ... GICD_ISPENDRN:\n        if ( dabt.size != DABT_BYTE && dabt.size != DABT_WORD ) goto bad_width;\n        printk(XENLOG_G_ERR\n               \"%pv: vGICD: unhandled %s write %#\"PRIregister\" to ISPENDR%d\\n\",\n               v, dabt.size ? \"word\" : \"byte\", *r, gicd_reg - GICD_ISPENDR);\n        return 0;\n\n    case GICD_ICPENDR ... GICD_ICPENDRN:\n        if ( dabt.size != DABT_BYTE && dabt.size != DABT_WORD ) goto bad_width;\n        printk(XENLOG_G_ERR\n               \"%pv: vGICD: unhandled %s write %#\"PRIregister\" to ICPENDR%d\\n\",\n               v, dabt.size ? \"word\" : \"byte\", *r, gicd_reg - GICD_ICPENDR);\n        return 0;\n\n    case GICD_ISACTIVER ... GICD_ISACTIVERN:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 1, gicd_reg - GICD_ISACTIVER, DABT_WORD);\n        if ( rank == NULL) goto write_ignore;\n        vgic_lock_rank(v, rank, flags);\n        rank->iactive &= ~*r;\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n\n    case GICD_ICACTIVER ... GICD_ICACTIVERN:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 1, gicd_reg - GICD_ICACTIVER, DABT_WORD);\n        if ( rank == NULL) goto write_ignore;\n        vgic_lock_rank(v, rank, flags);\n        rank->iactive &= ~*r;\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n\n    case GICD_ITARGETSR ... GICD_ITARGETSR + 7:\n        /* SGI/PPI target is read only */\n        goto write_ignore;\n\n    case GICD_ITARGETSR + 8 ... GICD_ITARGETSRN:\n    {\n        /* unsigned long needed for find_next_bit */\n        unsigned long target;\n        int i;\n        if ( dabt.size != DABT_BYTE && dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 8, gicd_reg - GICD_ITARGETSR, DABT_WORD);\n        if ( rank == NULL) goto write_ignore;\n        /* 8-bit vcpu mask for this domain */\n        BUG_ON(v->domain->max_vcpus > 8);\n        target = (1 << v->domain->max_vcpus) - 1;\n        if ( dabt.size == 2 )\n            target = target | (target << 8) | (target << 16) | (target << 24);\n        else\n            target = (target << (8 * (gicd_reg & 0x3)));\n        target &= *r;\n        /* ignore zero writes */\n        if ( !target )\n            goto write_ignore;\n        /* For word reads ignore writes where any single byte is zero */\n        if ( dabt.size == 2 &&\n            !((target & 0xff) && (target & (0xff << 8)) &&\n             (target & (0xff << 16)) && (target & (0xff << 24))))\n            goto write_ignore;\n        vgic_lock_rank(v, rank, flags);\n        i = 0;\n        while ( (i = find_next_bit(&target, 32, i)) < 32 )\n        {\n            unsigned int irq, new_target, old_target;\n            unsigned long old_target_mask;\n            struct vcpu *v_target, *v_old;\n\n            new_target = i % 8;\n            old_target_mask = vgic_byte_read(rank->v2.itargets[REG_RANK_INDEX(8,\n                                             gicd_reg - GICD_ITARGETSR, DABT_WORD)], 0, i/8);\n            old_target = find_first_bit(&old_target_mask, 8);\n\n            if ( new_target != old_target )\n            {\n                irq = gicd_reg - GICD_ITARGETSR + (i / 8);\n                v_target = v->domain->vcpu[new_target];\n                v_old = v->domain->vcpu[old_target];\n                vgic_migrate_irq(v_old, v_target, irq);\n            }\n            i += 8 - new_target;\n        }\n        if ( dabt.size == DABT_WORD )\n            rank->v2.itargets[REG_RANK_INDEX(8, gicd_reg - GICD_ITARGETSR,\n                                             DABT_WORD)] = target;\n        else\n            vgic_byte_write(&rank->v2.itargets[REG_RANK_INDEX(8,\n                      gicd_reg - GICD_ITARGETSR, DABT_WORD)], target, gicd_reg);\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n    }\n\n    case GICD_IPRIORITYR ... GICD_IPRIORITYRN:\n        if ( dabt.size != DABT_BYTE && dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 8, gicd_reg - GICD_IPRIORITYR, DABT_WORD);\n        if ( rank == NULL) goto write_ignore;\n        vgic_lock_rank(v, rank, flags);\n        if ( dabt.size == DABT_WORD )\n            rank->ipriority[REG_RANK_INDEX(8, gicd_reg - GICD_IPRIORITYR,\n                                           DABT_WORD)] = *r;\n        else\n            vgic_byte_write(&rank->ipriority[REG_RANK_INDEX(8,\n                        gicd_reg - GICD_IPRIORITYR, DABT_WORD)], *r, gicd_reg);\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n\n    case GICD_ICFGR: /* SGIs */\n        goto write_ignore;\n    case GICD_ICFGR + 1: /* PPIs */\n        /* It is implementation defined if these are writeable. We chose not */\n        goto write_ignore;\n    case GICD_ICFGR + 2 ... GICD_ICFGRN: /* SPIs */\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 2, gicd_reg - GICD_ICFGR, DABT_WORD);\n        if ( rank == NULL) goto write_ignore;\n        vgic_lock_rank(v, rank, flags);\n        rank->icfg[REG_RANK_INDEX(2, gicd_reg - GICD_ICFGR, DABT_WORD)] = *r;\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n\n    case GICD_NSACR ... GICD_NSACRN:\n        /* We do not implement security extensions for guests, write ignore */\n        goto write_ignore;\n\n    case GICD_SGIR:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        return vgic_v2_to_sgi(v, *r);\n\n    case GICD_CPENDSGIR ... GICD_CPENDSGIRN:\n        if ( dabt.size != DABT_BYTE && dabt.size != DABT_WORD ) goto bad_width;\n        printk(XENLOG_G_ERR\n               \"%pv: vGICD: unhandled %s write %#\"PRIregister\" to ICPENDSGIR%d\\n\",\n               v, dabt.size ? \"word\" : \"byte\", *r, gicd_reg - GICD_CPENDSGIR);\n        return 0;\n\n    case GICD_SPENDSGIR ... GICD_SPENDSGIRN:\n        if ( dabt.size != DABT_BYTE && dabt.size != DABT_WORD ) goto bad_width;\n        printk(XENLOG_G_ERR\n               \"%pv: vGICD: unhandled %s write %#\"PRIregister\" to ISPENDSGIR%d\\n\",\n               v, dabt.size ? \"word\" : \"byte\", *r, gicd_reg - GICD_SPENDSGIR);\n        return 0;\n\n    /* Implementation defined -- write ignored */\n    case 0xfd0 ... 0xfe4:\n        goto write_ignore;\n\n    /* R/O -- write ignore */\n    case GICD_ICPIDR2:\n        goto write_ignore;\n\n    /* Implementation defined -- write ignored */\n    case 0xfec ... 0xffc:\n        goto write_ignore;\n\n    /* Reserved -- write ignored */\n    case 0x00c ... 0x01c:\n    case 0x040 ... 0x07c:\n    case 0x7fc:\n    case 0xbfc:\n    case 0xf04 ... 0xf0c:\n    case 0xf30 ... 0xfcc:\n        goto write_ignore;\n\n    default:\n        printk(XENLOG_G_ERR\n               \"%pv: vGICD: unhandled write r%d=%\"PRIregister\" offset %#08x\\n\",\n               v, dabt.reg, *r, gicd_reg);\n        return 0;\n    }\n\nbad_width:\n    printk(XENLOG_G_ERR\n           \"%pv: vGICD: bad write width %d r%d=%\"PRIregister\" offset %#08x\\n\",\n           v, dabt.size, dabt.reg, *r, gicd_reg);\n    domain_crash_synchronous();\n    return 0;\n\nwrite_ignore:\n    if ( dabt.size != DABT_WORD ) goto bad_width;\n    return 1;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -63,14 +63,16 @@\n \n     case GICD_ISPENDR ... GICD_ISPENDRN:\n         if ( dabt.size != DABT_BYTE && dabt.size != DABT_WORD ) goto bad_width;\n-        printk(\"vGICD: unhandled %s write %#\"PRIregister\" to ISPENDR%d\\n\",\n-               dabt.size ? \"word\" : \"byte\", *r, gicd_reg - GICD_ISPENDR);\n+        printk(XENLOG_G_ERR\n+               \"%pv: vGICD: unhandled %s write %#\"PRIregister\" to ISPENDR%d\\n\",\n+               v, dabt.size ? \"word\" : \"byte\", *r, gicd_reg - GICD_ISPENDR);\n         return 0;\n \n     case GICD_ICPENDR ... GICD_ICPENDRN:\n         if ( dabt.size != DABT_BYTE && dabt.size != DABT_WORD ) goto bad_width;\n-        printk(\"vGICD: unhandled %s write %#\"PRIregister\" to ICPENDR%d\\n\",\n-               dabt.size ? \"word\" : \"byte\", *r, gicd_reg - GICD_ICPENDR);\n+        printk(XENLOG_G_ERR\n+               \"%pv: vGICD: unhandled %s write %#\"PRIregister\" to ICPENDR%d\\n\",\n+               v, dabt.size ? \"word\" : \"byte\", *r, gicd_reg - GICD_ICPENDR);\n         return 0;\n \n     case GICD_ISACTIVER ... GICD_ISACTIVERN:\n@@ -189,14 +191,16 @@\n \n     case GICD_CPENDSGIR ... GICD_CPENDSGIRN:\n         if ( dabt.size != DABT_BYTE && dabt.size != DABT_WORD ) goto bad_width;\n-        printk(\"vGICD: unhandled %s write %#\"PRIregister\" to ICPENDSGIR%d\\n\",\n-               dabt.size ? \"word\" : \"byte\", *r, gicd_reg - GICD_CPENDSGIR);\n+        printk(XENLOG_G_ERR\n+               \"%pv: vGICD: unhandled %s write %#\"PRIregister\" to ICPENDSGIR%d\\n\",\n+               v, dabt.size ? \"word\" : \"byte\", *r, gicd_reg - GICD_CPENDSGIR);\n         return 0;\n \n     case GICD_SPENDSGIR ... GICD_SPENDSGIRN:\n         if ( dabt.size != DABT_BYTE && dabt.size != DABT_WORD ) goto bad_width;\n-        printk(\"vGICD: unhandled %s write %#\"PRIregister\" to ISPENDSGIR%d\\n\",\n-               dabt.size ? \"word\" : \"byte\", *r, gicd_reg - GICD_SPENDSGIR);\n+        printk(XENLOG_G_ERR\n+               \"%pv: vGICD: unhandled %s write %#\"PRIregister\" to ISPENDSGIR%d\\n\",\n+               v, dabt.size ? \"word\" : \"byte\", *r, gicd_reg - GICD_SPENDSGIR);\n         return 0;\n \n     /* Implementation defined -- write ignored */\n@@ -221,14 +225,16 @@\n         goto write_ignore;\n \n     default:\n-        printk(\"vGICD: unhandled write r%d=%\"PRIregister\" offset %#08x\\n\",\n-               dabt.reg, *r, gicd_reg);\n+        printk(XENLOG_G_ERR\n+               \"%pv: vGICD: unhandled write r%d=%\"PRIregister\" offset %#08x\\n\",\n+               v, dabt.reg, *r, gicd_reg);\n         return 0;\n     }\n \n bad_width:\n-    printk(\"vGICD: bad write width %d r%d=%\"PRIregister\" offset %#08x\\n\",\n-           dabt.size, dabt.reg, *r, gicd_reg);\n+    printk(XENLOG_G_ERR\n+           \"%pv: vGICD: bad write width %d r%d=%\"PRIregister\" offset %#08x\\n\",\n+           v, dabt.size, dabt.reg, *r, gicd_reg);\n     domain_crash_synchronous();\n     return 0;\n ",
        "diff_line_info": {
            "deleted_lines": [
                "        printk(\"vGICD: unhandled %s write %#\"PRIregister\" to ISPENDR%d\\n\",",
                "               dabt.size ? \"word\" : \"byte\", *r, gicd_reg - GICD_ISPENDR);",
                "        printk(\"vGICD: unhandled %s write %#\"PRIregister\" to ICPENDR%d\\n\",",
                "               dabt.size ? \"word\" : \"byte\", *r, gicd_reg - GICD_ICPENDR);",
                "        printk(\"vGICD: unhandled %s write %#\"PRIregister\" to ICPENDSGIR%d\\n\",",
                "               dabt.size ? \"word\" : \"byte\", *r, gicd_reg - GICD_CPENDSGIR);",
                "        printk(\"vGICD: unhandled %s write %#\"PRIregister\" to ISPENDSGIR%d\\n\",",
                "               dabt.size ? \"word\" : \"byte\", *r, gicd_reg - GICD_SPENDSGIR);",
                "        printk(\"vGICD: unhandled write r%d=%\"PRIregister\" offset %#08x\\n\",",
                "               dabt.reg, *r, gicd_reg);",
                "    printk(\"vGICD: bad write width %d r%d=%\"PRIregister\" offset %#08x\\n\",",
                "           dabt.size, dabt.reg, *r, gicd_reg);"
            ],
            "added_lines": [
                "        printk(XENLOG_G_ERR",
                "               \"%pv: vGICD: unhandled %s write %#\"PRIregister\" to ISPENDR%d\\n\",",
                "               v, dabt.size ? \"word\" : \"byte\", *r, gicd_reg - GICD_ISPENDR);",
                "        printk(XENLOG_G_ERR",
                "               \"%pv: vGICD: unhandled %s write %#\"PRIregister\" to ICPENDR%d\\n\",",
                "               v, dabt.size ? \"word\" : \"byte\", *r, gicd_reg - GICD_ICPENDR);",
                "        printk(XENLOG_G_ERR",
                "               \"%pv: vGICD: unhandled %s write %#\"PRIregister\" to ICPENDSGIR%d\\n\",",
                "               v, dabt.size ? \"word\" : \"byte\", *r, gicd_reg - GICD_CPENDSGIR);",
                "        printk(XENLOG_G_ERR",
                "               \"%pv: vGICD: unhandled %s write %#\"PRIregister\" to ISPENDSGIR%d\\n\",",
                "               v, dabt.size ? \"word\" : \"byte\", *r, gicd_reg - GICD_SPENDSGIR);",
                "        printk(XENLOG_G_ERR",
                "               \"%pv: vGICD: unhandled write r%d=%\"PRIregister\" offset %#08x\\n\",",
                "               v, dabt.reg, *r, gicd_reg);",
                "    printk(XENLOG_G_ERR",
                "           \"%pv: vGICD: bad write width %d r%d=%\"PRIregister\" offset %#08x\\n\",",
                "           v, dabt.size, dabt.reg, *r, gicd_reg);"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1563",
        "func_name": "xen-project/xen/vgic_v3_rdistr_mmio_read",
        "description": "The ARM GIC distributor virtualization in Xen 4.4.x and 4.5.x allows local guests to cause a denial of service by causing a large number messages to be logged.",
        "git_url": "https://github.com/xen-project/xen/commit/c96222cc6dbb285a4de8f25e3b8e284e212ef964",
        "commit_title": "xen/arm: vgic-v3: message in the emulation code should be rate-limited",
        "commit_text": " printk by default is not rate-limited by default. Therefore a malicious guest may be able to flood the Xen console.  If we use gdprintk, unnecessary information will be printed such as the filename and the line. Instead use XENLOG_G_{ERR,DEBUG} combine with %pv.  Also remove the vGICv3 prefix which is not neccessary and update some message which were wrong.  This is XSA-118. ",
        "func_before": "static int vgic_v3_rdistr_mmio_read(struct vcpu *v, mmio_info_t *info)\n{\n    uint32_t offset;\n\n    perfc_incr(vgicr_reads);\n\n    if ( v->domain->arch.vgic.rdist_stride != 0 )\n        offset = info->gpa & (v->domain->arch.vgic.rdist_stride - 1);\n    else\n        /* If stride is not set. Default 128K */\n        offset = info->gpa & (SZ_128K - 1);\n\n    if ( offset < SZ_64K )\n        return __vgic_v3_rdistr_rd_mmio_read(v, info, offset);\n    else  if ( (offset >= SZ_64K) && (offset < 2 * SZ_64K) )\n        return vgic_v3_rdistr_sgi_mmio_read(v, info, (offset - SZ_64K));\n    else\n        gdprintk(XENLOG_WARNING,\n                 \"vGICv3: vGICR: unknown gpa read address %\"PRIpaddr\"\\n\",\n                 info->gpa);\n\n    return 0;\n}",
        "func": "static int vgic_v3_rdistr_mmio_read(struct vcpu *v, mmio_info_t *info)\n{\n    uint32_t offset;\n\n    perfc_incr(vgicr_reads);\n\n    if ( v->domain->arch.vgic.rdist_stride != 0 )\n        offset = info->gpa & (v->domain->arch.vgic.rdist_stride - 1);\n    else\n        /* If stride is not set. Default 128K */\n        offset = info->gpa & (SZ_128K - 1);\n\n    if ( offset < SZ_64K )\n        return __vgic_v3_rdistr_rd_mmio_read(v, info, offset);\n    else  if ( (offset >= SZ_64K) && (offset < 2 * SZ_64K) )\n        return vgic_v3_rdistr_sgi_mmio_read(v, info, (offset - SZ_64K));\n    else\n        printk(XENLOG_G_WARNING\n               \"%pv: vGICR: unknown gpa read address %\"PRIpaddr\"\\n\",\n                v, info->gpa);\n\n    return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -15,9 +15,9 @@\n     else  if ( (offset >= SZ_64K) && (offset < 2 * SZ_64K) )\n         return vgic_v3_rdistr_sgi_mmio_read(v, info, (offset - SZ_64K));\n     else\n-        gdprintk(XENLOG_WARNING,\n-                 \"vGICv3: vGICR: unknown gpa read address %\"PRIpaddr\"\\n\",\n-                 info->gpa);\n+        printk(XENLOG_G_WARNING\n+               \"%pv: vGICR: unknown gpa read address %\"PRIpaddr\"\\n\",\n+                v, info->gpa);\n \n     return 0;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "        gdprintk(XENLOG_WARNING,",
                "                 \"vGICv3: vGICR: unknown gpa read address %\"PRIpaddr\"\\n\",",
                "                 info->gpa);"
            ],
            "added_lines": [
                "        printk(XENLOG_G_WARNING",
                "               \"%pv: vGICR: unknown gpa read address %\"PRIpaddr\"\\n\",",
                "                v, info->gpa);"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1563",
        "func_name": "xen-project/xen/__vgic_v3_rdistr_rd_mmio_read",
        "description": "The ARM GIC distributor virtualization in Xen 4.4.x and 4.5.x allows local guests to cause a denial of service by causing a large number messages to be logged.",
        "git_url": "https://github.com/xen-project/xen/commit/c96222cc6dbb285a4de8f25e3b8e284e212ef964",
        "commit_title": "xen/arm: vgic-v3: message in the emulation code should be rate-limited",
        "commit_text": " printk by default is not rate-limited by default. Therefore a malicious guest may be able to flood the Xen console.  If we use gdprintk, unnecessary information will be printed such as the filename and the line. Instead use XENLOG_G_{ERR,DEBUG} combine with %pv.  Also remove the vGICv3 prefix which is not neccessary and update some message which were wrong.  This is XSA-118. ",
        "func_before": "static int __vgic_v3_rdistr_rd_mmio_read(struct vcpu *v, mmio_info_t *info,\n                                         uint32_t gicr_reg)\n{\n    struct hsr_dabt dabt = info->dabt;\n    struct cpu_user_regs *regs = guest_cpu_user_regs();\n    register_t *r = select_user_reg(regs, dabt.reg);\n    uint64_t aff;\n\n    switch ( gicr_reg )\n    {\n    case GICR_CTLR:\n        /* We have not implemented LPI's, read zero */\n        goto read_as_zero;\n    case GICR_IIDR:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        *r = GICV3_GICR_IIDR_VAL;\n        return 1;\n    case GICR_TYPER:\n        if ( dabt.size != DABT_DOUBLE_WORD ) goto bad_width;\n        /* TBD: Update processor id in [23:8] when ITS support is added */\n        aff = (MPIDR_AFFINITY_LEVEL(v->arch.vmpidr, 3) << 56 |\n               MPIDR_AFFINITY_LEVEL(v->arch.vmpidr, 2) << 48 |\n               MPIDR_AFFINITY_LEVEL(v->arch.vmpidr, 1) << 40 |\n               MPIDR_AFFINITY_LEVEL(v->arch.vmpidr, 0) << 32);\n        *r = aff;\n        return 1;\n    case GICR_STATUSR:\n        /* Not implemented */\n        goto read_as_zero;\n    case GICR_WAKER:\n        /* Power management is not implemented */\n        goto read_as_zero;\n    case GICR_SETLPIR:\n        /* WO. Read as zero */\n        goto read_as_zero_64;\n    case GICR_CLRLPIR:\n        /* WO. Read as zero */\n        goto read_as_zero_64;\n    case GICR_PROPBASER:\n        /* LPI's not implemented */\n        goto read_as_zero_64;\n    case GICR_PENDBASER:\n        /* LPI's not implemented */\n        goto read_as_zero_64;\n    case GICR_INVLPIR:\n        /* WO. Read as zero */\n        goto read_as_zero_64;\n    case GICR_INVALLR:\n        /* WO. Read as zero */\n        goto read_as_zero_64;\n        return 0;\n    case GICR_SYNCR:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        /* RO . But when read it always returns busy bito bit[0] */\n        *r = GICR_SYNCR_NOT_BUSY;\n        return 1;\n    case GICR_MOVLPIR:\n        /* WO Read as zero */\n        goto read_as_zero_64;\n    case GICR_MOVALLR:\n        /* WO Read as zero */\n        goto read_as_zero_64;\n    case GICR_PIDR0:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        *r = GICV3_GICR_PIDR0;\n         return 1;\n    case GICR_PIDR1:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        *r = GICV3_GICR_PIDR1;\n         return 1;\n    case GICR_PIDR2:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        *r = GICV3_GICR_PIDR2;\n         return 1;\n    case GICR_PIDR3:\n        /* Manufacture/customer defined */\n        goto read_as_zero;\n    case GICR_PIDR4:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        *r = GICV3_GICR_PIDR4;\n         return 1;\n    case GICR_PIDR5 ... GICR_PIDR7:\n        /* Reserved0 */\n        goto read_as_zero;\n    default:\n        printk(\"vGICv3: vGICR: read r%d offset %#08x\\n not found\",\n               dabt.reg, gicr_reg);\n        return 0;\n    }\nbad_width:\n    printk(\"vGICv3: vGICR: bad read width %d r%d offset %#08x\\n\",\n           dabt.size, dabt.reg, gicr_reg);\n    domain_crash_synchronous();\n    return 0;\n\nread_as_zero_64:\n    if ( dabt.size != DABT_DOUBLE_WORD ) goto bad_width;\n    *r = 0;\n    return 1;\n\nread_as_zero:\n    if ( dabt.size != DABT_WORD ) goto bad_width;\n    *r = 0;\n    return 1;\n}",
        "func": "static int __vgic_v3_rdistr_rd_mmio_read(struct vcpu *v, mmio_info_t *info,\n                                         uint32_t gicr_reg)\n{\n    struct hsr_dabt dabt = info->dabt;\n    struct cpu_user_regs *regs = guest_cpu_user_regs();\n    register_t *r = select_user_reg(regs, dabt.reg);\n    uint64_t aff;\n\n    switch ( gicr_reg )\n    {\n    case GICR_CTLR:\n        /* We have not implemented LPI's, read zero */\n        goto read_as_zero;\n    case GICR_IIDR:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        *r = GICV3_GICR_IIDR_VAL;\n        return 1;\n    case GICR_TYPER:\n        if ( dabt.size != DABT_DOUBLE_WORD ) goto bad_width;\n        /* TBD: Update processor id in [23:8] when ITS support is added */\n        aff = (MPIDR_AFFINITY_LEVEL(v->arch.vmpidr, 3) << 56 |\n               MPIDR_AFFINITY_LEVEL(v->arch.vmpidr, 2) << 48 |\n               MPIDR_AFFINITY_LEVEL(v->arch.vmpidr, 1) << 40 |\n               MPIDR_AFFINITY_LEVEL(v->arch.vmpidr, 0) << 32);\n        *r = aff;\n        return 1;\n    case GICR_STATUSR:\n        /* Not implemented */\n        goto read_as_zero;\n    case GICR_WAKER:\n        /* Power management is not implemented */\n        goto read_as_zero;\n    case GICR_SETLPIR:\n        /* WO. Read as zero */\n        goto read_as_zero_64;\n    case GICR_CLRLPIR:\n        /* WO. Read as zero */\n        goto read_as_zero_64;\n    case GICR_PROPBASER:\n        /* LPI's not implemented */\n        goto read_as_zero_64;\n    case GICR_PENDBASER:\n        /* LPI's not implemented */\n        goto read_as_zero_64;\n    case GICR_INVLPIR:\n        /* WO. Read as zero */\n        goto read_as_zero_64;\n    case GICR_INVALLR:\n        /* WO. Read as zero */\n        goto read_as_zero_64;\n        return 0;\n    case GICR_SYNCR:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        /* RO . But when read it always returns busy bito bit[0] */\n        *r = GICR_SYNCR_NOT_BUSY;\n        return 1;\n    case GICR_MOVLPIR:\n        /* WO Read as zero */\n        goto read_as_zero_64;\n    case GICR_MOVALLR:\n        /* WO Read as zero */\n        goto read_as_zero_64;\n    case GICR_PIDR0:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        *r = GICV3_GICR_PIDR0;\n         return 1;\n    case GICR_PIDR1:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        *r = GICV3_GICR_PIDR1;\n         return 1;\n    case GICR_PIDR2:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        *r = GICV3_GICR_PIDR2;\n         return 1;\n    case GICR_PIDR3:\n        /* Manufacture/customer defined */\n        goto read_as_zero;\n    case GICR_PIDR4:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        *r = GICV3_GICR_PIDR4;\n         return 1;\n    case GICR_PIDR5 ... GICR_PIDR7:\n        /* Reserved0 */\n        goto read_as_zero;\n    default:\n        printk(XENLOG_G_ERR\n               \"%pv: vGICR: read r%d offset %#08x\\n not found\",\n               v, dabt.reg, gicr_reg);\n        return 0;\n    }\nbad_width:\n    printk(XENLOG_G_ERR \"%pv vGICR: bad read width %d r%d offset %#08x\\n\",\n           v, dabt.size, dabt.reg, gicr_reg);\n    domain_crash_synchronous();\n    return 0;\n\nread_as_zero_64:\n    if ( dabt.size != DABT_DOUBLE_WORD ) goto bad_width;\n    *r = 0;\n    return 1;\n\nread_as_zero:\n    if ( dabt.size != DABT_WORD ) goto bad_width;\n    *r = 0;\n    return 1;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -83,13 +83,14 @@\n         /* Reserved0 */\n         goto read_as_zero;\n     default:\n-        printk(\"vGICv3: vGICR: read r%d offset %#08x\\n not found\",\n-               dabt.reg, gicr_reg);\n+        printk(XENLOG_G_ERR\n+               \"%pv: vGICR: read r%d offset %#08x\\n not found\",\n+               v, dabt.reg, gicr_reg);\n         return 0;\n     }\n bad_width:\n-    printk(\"vGICv3: vGICR: bad read width %d r%d offset %#08x\\n\",\n-           dabt.size, dabt.reg, gicr_reg);\n+    printk(XENLOG_G_ERR \"%pv vGICR: bad read width %d r%d offset %#08x\\n\",\n+           v, dabt.size, dabt.reg, gicr_reg);\n     domain_crash_synchronous();\n     return 0;\n ",
        "diff_line_info": {
            "deleted_lines": [
                "        printk(\"vGICv3: vGICR: read r%d offset %#08x\\n not found\",",
                "               dabt.reg, gicr_reg);",
                "    printk(\"vGICv3: vGICR: bad read width %d r%d offset %#08x\\n\",",
                "           dabt.size, dabt.reg, gicr_reg);"
            ],
            "added_lines": [
                "        printk(XENLOG_G_ERR",
                "               \"%pv: vGICR: read r%d offset %#08x\\n not found\",",
                "               v, dabt.reg, gicr_reg);",
                "    printk(XENLOG_G_ERR \"%pv vGICR: bad read width %d r%d offset %#08x\\n\",",
                "           v, dabt.size, dabt.reg, gicr_reg);"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1563",
        "func_name": "xen-project/xen/vgic_v3_distr_mmio_write",
        "description": "The ARM GIC distributor virtualization in Xen 4.4.x and 4.5.x allows local guests to cause a denial of service by causing a large number messages to be logged.",
        "git_url": "https://github.com/xen-project/xen/commit/c96222cc6dbb285a4de8f25e3b8e284e212ef964",
        "commit_title": "xen/arm: vgic-v3: message in the emulation code should be rate-limited",
        "commit_text": " printk by default is not rate-limited by default. Therefore a malicious guest may be able to flood the Xen console.  If we use gdprintk, unnecessary information will be printed such as the filename and the line. Instead use XENLOG_G_{ERR,DEBUG} combine with %pv.  Also remove the vGICv3 prefix which is not neccessary and update some message which were wrong.  This is XSA-118. ",
        "func_before": "static int vgic_v3_distr_mmio_write(struct vcpu *v, mmio_info_t *info)\n{\n    struct hsr_dabt dabt = info->dabt;\n    struct cpu_user_regs *regs = guest_cpu_user_regs();\n    register_t *r = select_user_reg(regs, dabt.reg);\n    struct vgic_irq_rank *rank;\n    unsigned long flags;\n    uint64_t new_irouter, new_target, old_target;\n    struct vcpu *old_vcpu, *new_vcpu;\n    int gicd_reg = (int)(info->gpa - v->domain->arch.vgic.dbase);\n\n    perfc_incr(vgicd_writes);\n\n    switch ( gicd_reg )\n    {\n    case GICD_CTLR:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        /* Ignore all but the enable bit */\n        v->domain->arch.vgic.ctlr = (*r) & GICD_CTL_ENABLE;\n        return 1;\n    case GICD_TYPER:\n        /* RO -- write ignored */\n        goto write_ignore;\n    case GICD_IIDR:\n        /* RO -- write ignored */\n        goto write_ignore;\n    case GICD_STATUSR:\n        /* RO -- write ignored */\n        goto write_ignore;\n    case GICD_SETSPI_NSR:\n        /* Message based SPI is not implemented */\n        goto write_ignore;\n    case GICD_CLRSPI_NSR:\n        /* Message based SPI is not implemented */\n        goto write_ignore;\n    case GICD_SETSPI_SR:\n        /* Message based SPI is not implemented */\n        goto write_ignore;\n    case GICD_CLRSPI_SR:\n        /* Message based SPI is not implemented */\n        goto write_ignore;\n    case 0x020 ... 0x03c:\n    case 0xc000 ... 0xffcc:\n        /* Implementation defined -- write ignored */\n        printk(\"vGICv3: vGICD: write unknown 0x020 - 0x03c r%d offset %#08x\\n\",\n               dabt.reg, gicd_reg);\n        goto write_ignore;\n    case GICD_IGROUPR ... GICD_IGROUPRN:\n    case GICD_ISENABLER ... GICD_ISENABLERN:\n    case GICD_ICENABLER ... GICD_ICENABLERN:\n    case GICD_ISPENDR ... GICD_ISPENDRN:\n    case GICD_ICPENDR ... GICD_ICPENDRN:\n    case GICD_ISACTIVER ... GICD_ISACTIVERN:\n    case GICD_ICACTIVER ... GICD_ICACTIVERN:\n    case GICD_IPRIORITYR ... GICD_IPRIORITYRN:\n    case GICD_ICFGR ... GICD_ICFGRN:\n        /* Above registers are common with GICR and GICD\n         * Manage in common */\n        return __vgic_v3_distr_common_mmio_write(v, info, gicd_reg);\n    case GICD_IROUTER ... GICD_IROUTER31:\n        /* SGI/PPI is RES0 */\n        goto write_ignore_64;\n    case GICD_IROUTER32 ... GICD_IROUTERN:\n        if ( dabt.size != DABT_DOUBLE_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 64, gicd_reg - GICD_IROUTER,\n                                DABT_DOUBLE_WORD);\n        if ( rank == NULL ) goto write_ignore_64;\n        BUG_ON(v->domain->max_vcpus > 8);\n        new_irouter = *r;\n        vgic_lock_rank(v, rank, flags);\n\n        old_target = rank->v3.irouter[REG_RANK_INDEX(64,\n                              (gicd_reg - GICD_IROUTER), DABT_DOUBLE_WORD)];\n        old_target &= ~(GICD_IROUTER_SPI_MODE_ANY);\n        if ( new_irouter & GICD_IROUTER_SPI_MODE_ANY )\n        {\n            /*\n             * IRQ routing mode set. Route any one processor in the entire\n             * system. We chose vcpu 0 and set IRQ mode bit[31] in irouter.\n             */\n            new_target = 0;\n            new_vcpu = v->domain->vcpu[0];\n            new_irouter = GICD_IROUTER_SPI_MODE_ANY;\n        }\n        else\n        {\n            new_target = new_irouter & MPIDR_AFF0_MASK;\n            if ( new_target >= v->domain->max_vcpus )\n            {\n                printk(\"vGICv3: vGICD: wrong irouter at offset %#08x\\n val 0x%lx vcpu %x\",\n                       gicd_reg, new_target, v->domain->max_vcpus);\n                vgic_unlock_rank(v, rank, flags);\n                return 0;\n            }\n            new_vcpu = vgic_v3_irouter_to_vcpu(v, new_irouter);\n        }\n\n        rank->v3.irouter[REG_RANK_INDEX(64, (gicd_reg - GICD_IROUTER),\n                         DABT_DOUBLE_WORD)] = new_irouter;\n        if ( old_target != new_target )\n        {\n            old_vcpu = v->domain->vcpu[old_target];\n            vgic_migrate_irq(old_vcpu, new_vcpu, (gicd_reg - GICD_IROUTER)/8);\n        }\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n    case GICD_NSACR ... GICD_NSACRN:\n        /* We do not implement security extensions for guests, write ignore */\n        goto write_ignore;\n    case GICD_SGIR:\n        /* it is accessed as system register in GICv3 */\n        goto write_ignore;\n    case GICD_CPENDSGIR ... GICD_CPENDSGIRN:\n        /* Replaced with GICR_ICPENDR0. So ignore write */\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        return 0;\n    case GICD_SPENDSGIR ... GICD_SPENDSGIRN:\n        /* Replaced with GICR_ISPENDR0. So ignore write */\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        return 0;\n    case GICD_PIDR7... GICD_PIDR0:\n        /* RO -- write ignore */\n        goto write_ignore;\n    case 0x00c:\n    case 0x044:\n    case 0x04c:\n    case 0x05c ... 0x07c:\n    case 0xf30 ... 0x5fcc:\n    case 0x8000 ... 0xbfcc:\n        /* Reserved register addresses */\n        printk(\"vGICv3: vGICD: write unknown 0x00c 0xfcc  r%d offset %#08x\\n\",\n                dabt.reg, gicd_reg);\n        goto write_ignore;\n    default:\n        printk(\"vGICv3: vGICD: unhandled write r%d=%\"PRIregister\" \"\n               \"offset %#08x\\n\", dabt.reg, *r, gicd_reg);\n        return 0;\n    }\n\nbad_width:\n    dprintk(XENLOG_ERR,\n            \"VGICv3: vGICD: bad write width %d r%d=%\"PRIregister\" \"\n            \"offset %#08x\\n\", dabt.size, dabt.reg, *r, gicd_reg);\n    domain_crash_synchronous();\n    return 0;\n\nwrite_ignore:\n    if ( dabt.size != DABT_WORD ) goto bad_width;\n    return 1;\n\nwrite_ignore_64:\n    if ( dabt.size != DABT_DOUBLE_WORD ) goto bad_width;\n    return 1;\n}",
        "func": "static int vgic_v3_distr_mmio_write(struct vcpu *v, mmio_info_t *info)\n{\n    struct hsr_dabt dabt = info->dabt;\n    struct cpu_user_regs *regs = guest_cpu_user_regs();\n    register_t *r = select_user_reg(regs, dabt.reg);\n    struct vgic_irq_rank *rank;\n    unsigned long flags;\n    uint64_t new_irouter, new_target, old_target;\n    struct vcpu *old_vcpu, *new_vcpu;\n    int gicd_reg = (int)(info->gpa - v->domain->arch.vgic.dbase);\n\n    perfc_incr(vgicd_writes);\n\n    switch ( gicd_reg )\n    {\n    case GICD_CTLR:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        /* Ignore all but the enable bit */\n        v->domain->arch.vgic.ctlr = (*r) & GICD_CTL_ENABLE;\n        return 1;\n    case GICD_TYPER:\n        /* RO -- write ignored */\n        goto write_ignore;\n    case GICD_IIDR:\n        /* RO -- write ignored */\n        goto write_ignore;\n    case GICD_STATUSR:\n        /* RO -- write ignored */\n        goto write_ignore;\n    case GICD_SETSPI_NSR:\n        /* Message based SPI is not implemented */\n        goto write_ignore;\n    case GICD_CLRSPI_NSR:\n        /* Message based SPI is not implemented */\n        goto write_ignore;\n    case GICD_SETSPI_SR:\n        /* Message based SPI is not implemented */\n        goto write_ignore;\n    case GICD_CLRSPI_SR:\n        /* Message based SPI is not implemented */\n        goto write_ignore;\n    case 0x020 ... 0x03c:\n    case 0xc000 ... 0xffcc:\n        /* Implementation defined -- write ignored */\n        printk(XENLOG_G_DEBUG\n               \"%pv: vGICD: WI on implementation defined register offset %#08x\\n\",\n               v, gicd_reg);\n        goto write_ignore;\n    case GICD_IGROUPR ... GICD_IGROUPRN:\n    case GICD_ISENABLER ... GICD_ISENABLERN:\n    case GICD_ICENABLER ... GICD_ICENABLERN:\n    case GICD_ISPENDR ... GICD_ISPENDRN:\n    case GICD_ICPENDR ... GICD_ICPENDRN:\n    case GICD_ISACTIVER ... GICD_ISACTIVERN:\n    case GICD_ICACTIVER ... GICD_ICACTIVERN:\n    case GICD_IPRIORITYR ... GICD_IPRIORITYRN:\n    case GICD_ICFGR ... GICD_ICFGRN:\n        /* Above registers are common with GICR and GICD\n         * Manage in common */\n        return __vgic_v3_distr_common_mmio_write(v, info, gicd_reg);\n    case GICD_IROUTER ... GICD_IROUTER31:\n        /* SGI/PPI is RES0 */\n        goto write_ignore_64;\n    case GICD_IROUTER32 ... GICD_IROUTERN:\n        if ( dabt.size != DABT_DOUBLE_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 64, gicd_reg - GICD_IROUTER,\n                                DABT_DOUBLE_WORD);\n        if ( rank == NULL ) goto write_ignore_64;\n        BUG_ON(v->domain->max_vcpus > 8);\n        new_irouter = *r;\n        vgic_lock_rank(v, rank, flags);\n\n        old_target = rank->v3.irouter[REG_RANK_INDEX(64,\n                              (gicd_reg - GICD_IROUTER), DABT_DOUBLE_WORD)];\n        old_target &= ~(GICD_IROUTER_SPI_MODE_ANY);\n        if ( new_irouter & GICD_IROUTER_SPI_MODE_ANY )\n        {\n            /*\n             * IRQ routing mode set. Route any one processor in the entire\n             * system. We chose vcpu 0 and set IRQ mode bit[31] in irouter.\n             */\n            new_target = 0;\n            new_vcpu = v->domain->vcpu[0];\n            new_irouter = GICD_IROUTER_SPI_MODE_ANY;\n        }\n        else\n        {\n            new_target = new_irouter & MPIDR_AFF0_MASK;\n            if ( new_target >= v->domain->max_vcpus )\n            {\n                printk(XENLOG_G_DEBUG\n                       \"%pv: vGICD: wrong irouter at offset %#08x\\n val 0x%lx vcpu %x\",\n                       v, gicd_reg, new_target, v->domain->max_vcpus);\n                vgic_unlock_rank(v, rank, flags);\n                return 0;\n            }\n            new_vcpu = vgic_v3_irouter_to_vcpu(v, new_irouter);\n        }\n\n        rank->v3.irouter[REG_RANK_INDEX(64, (gicd_reg - GICD_IROUTER),\n                         DABT_DOUBLE_WORD)] = new_irouter;\n        if ( old_target != new_target )\n        {\n            old_vcpu = v->domain->vcpu[old_target];\n            vgic_migrate_irq(old_vcpu, new_vcpu, (gicd_reg - GICD_IROUTER)/8);\n        }\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n    case GICD_NSACR ... GICD_NSACRN:\n        /* We do not implement security extensions for guests, write ignore */\n        goto write_ignore;\n    case GICD_SGIR:\n        /* it is accessed as system register in GICv3 */\n        goto write_ignore;\n    case GICD_CPENDSGIR ... GICD_CPENDSGIRN:\n        /* Replaced with GICR_ICPENDR0. So ignore write */\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        return 0;\n    case GICD_SPENDSGIR ... GICD_SPENDSGIRN:\n        /* Replaced with GICR_ISPENDR0. So ignore write */\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        return 0;\n    case GICD_PIDR7... GICD_PIDR0:\n        /* RO -- write ignore */\n        goto write_ignore;\n    case 0x00c:\n    case 0x044:\n    case 0x04c:\n    case 0x05c ... 0x07c:\n    case 0xf30 ... 0x5fcc:\n    case 0x8000 ... 0xbfcc:\n        /* Reserved register addresses */\n        printk(XENLOG_G_DEBUG\n               \"%pv: vGICD: write unknown 0x00c 0xfcc  r%d offset %#08x\\n\",\n               v, dabt.reg, gicd_reg);\n        goto write_ignore;\n    default:\n        printk(XENLOG_G_ERR\n               \"%pv: vGICD: unhandled write r%d=%\"PRIregister\" offset %#08x\\n\",\n               v, dabt.reg, *r, gicd_reg);\n        return 0;\n    }\n\nbad_width:\n    printk(XENLOG_G_ERR\n           \"%pv: vGICD: bad write width %d r%d=%\"PRIregister\" offset %#08x\\n\",\n           v, dabt.size, dabt.reg, *r, gicd_reg);\n    domain_crash_synchronous();\n    return 0;\n\nwrite_ignore:\n    if ( dabt.size != DABT_WORD ) goto bad_width;\n    return 1;\n\nwrite_ignore_64:\n    if ( dabt.size != DABT_DOUBLE_WORD ) goto bad_width;\n    return 1;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -42,8 +42,9 @@\n     case 0x020 ... 0x03c:\n     case 0xc000 ... 0xffcc:\n         /* Implementation defined -- write ignored */\n-        printk(\"vGICv3: vGICD: write unknown 0x020 - 0x03c r%d offset %#08x\\n\",\n-               dabt.reg, gicd_reg);\n+        printk(XENLOG_G_DEBUG\n+               \"%pv: vGICD: WI on implementation defined register offset %#08x\\n\",\n+               v, gicd_reg);\n         goto write_ignore;\n     case GICD_IGROUPR ... GICD_IGROUPRN:\n     case GICD_ISENABLER ... GICD_ISENABLERN:\n@@ -87,8 +88,9 @@\n             new_target = new_irouter & MPIDR_AFF0_MASK;\n             if ( new_target >= v->domain->max_vcpus )\n             {\n-                printk(\"vGICv3: vGICD: wrong irouter at offset %#08x\\n val 0x%lx vcpu %x\",\n-                       gicd_reg, new_target, v->domain->max_vcpus);\n+                printk(XENLOG_G_DEBUG\n+                       \"%pv: vGICD: wrong irouter at offset %#08x\\n val 0x%lx vcpu %x\",\n+                       v, gicd_reg, new_target, v->domain->max_vcpus);\n                 vgic_unlock_rank(v, rank, flags);\n                 return 0;\n             }\n@@ -128,19 +130,21 @@\n     case 0xf30 ... 0x5fcc:\n     case 0x8000 ... 0xbfcc:\n         /* Reserved register addresses */\n-        printk(\"vGICv3: vGICD: write unknown 0x00c 0xfcc  r%d offset %#08x\\n\",\n-                dabt.reg, gicd_reg);\n+        printk(XENLOG_G_DEBUG\n+               \"%pv: vGICD: write unknown 0x00c 0xfcc  r%d offset %#08x\\n\",\n+               v, dabt.reg, gicd_reg);\n         goto write_ignore;\n     default:\n-        printk(\"vGICv3: vGICD: unhandled write r%d=%\"PRIregister\" \"\n-               \"offset %#08x\\n\", dabt.reg, *r, gicd_reg);\n+        printk(XENLOG_G_ERR\n+               \"%pv: vGICD: unhandled write r%d=%\"PRIregister\" offset %#08x\\n\",\n+               v, dabt.reg, *r, gicd_reg);\n         return 0;\n     }\n \n bad_width:\n-    dprintk(XENLOG_ERR,\n-            \"VGICv3: vGICD: bad write width %d r%d=%\"PRIregister\" \"\n-            \"offset %#08x\\n\", dabt.size, dabt.reg, *r, gicd_reg);\n+    printk(XENLOG_G_ERR\n+           \"%pv: vGICD: bad write width %d r%d=%\"PRIregister\" offset %#08x\\n\",\n+           v, dabt.size, dabt.reg, *r, gicd_reg);\n     domain_crash_synchronous();\n     return 0;\n ",
        "diff_line_info": {
            "deleted_lines": [
                "        printk(\"vGICv3: vGICD: write unknown 0x020 - 0x03c r%d offset %#08x\\n\",",
                "               dabt.reg, gicd_reg);",
                "                printk(\"vGICv3: vGICD: wrong irouter at offset %#08x\\n val 0x%lx vcpu %x\",",
                "                       gicd_reg, new_target, v->domain->max_vcpus);",
                "        printk(\"vGICv3: vGICD: write unknown 0x00c 0xfcc  r%d offset %#08x\\n\",",
                "                dabt.reg, gicd_reg);",
                "        printk(\"vGICv3: vGICD: unhandled write r%d=%\"PRIregister\" \"",
                "               \"offset %#08x\\n\", dabt.reg, *r, gicd_reg);",
                "    dprintk(XENLOG_ERR,",
                "            \"VGICv3: vGICD: bad write width %d r%d=%\"PRIregister\" \"",
                "            \"offset %#08x\\n\", dabt.size, dabt.reg, *r, gicd_reg);"
            ],
            "added_lines": [
                "        printk(XENLOG_G_DEBUG",
                "               \"%pv: vGICD: WI on implementation defined register offset %#08x\\n\",",
                "               v, gicd_reg);",
                "                printk(XENLOG_G_DEBUG",
                "                       \"%pv: vGICD: wrong irouter at offset %#08x\\n val 0x%lx vcpu %x\",",
                "                       v, gicd_reg, new_target, v->domain->max_vcpus);",
                "        printk(XENLOG_G_DEBUG",
                "               \"%pv: vGICD: write unknown 0x00c 0xfcc  r%d offset %#08x\\n\",",
                "               v, dabt.reg, gicd_reg);",
                "        printk(XENLOG_G_ERR",
                "               \"%pv: vGICD: unhandled write r%d=%\"PRIregister\" offset %#08x\\n\",",
                "               v, dabt.reg, *r, gicd_reg);",
                "    printk(XENLOG_G_ERR",
                "           \"%pv: vGICD: bad write width %d r%d=%\"PRIregister\" offset %#08x\\n\",",
                "           v, dabt.size, dabt.reg, *r, gicd_reg);"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1563",
        "func_name": "xen-project/xen/__vgic_v3_distr_common_mmio_write",
        "description": "The ARM GIC distributor virtualization in Xen 4.4.x and 4.5.x allows local guests to cause a denial of service by causing a large number messages to be logged.",
        "git_url": "https://github.com/xen-project/xen/commit/c96222cc6dbb285a4de8f25e3b8e284e212ef964",
        "commit_title": "xen/arm: vgic-v3: message in the emulation code should be rate-limited",
        "commit_text": " printk by default is not rate-limited by default. Therefore a malicious guest may be able to flood the Xen console.  If we use gdprintk, unnecessary information will be printed such as the filename and the line. Instead use XENLOG_G_{ERR,DEBUG} combine with %pv.  Also remove the vGICv3 prefix which is not neccessary and update some message which were wrong.  This is XSA-118. ",
        "func_before": "static int __vgic_v3_distr_common_mmio_write(struct vcpu *v, mmio_info_t *info,\n                                             uint32_t reg)\n{\n    struct hsr_dabt dabt = info->dabt;\n    struct cpu_user_regs *regs = guest_cpu_user_regs();\n    register_t *r = select_user_reg(regs, dabt.reg);\n    struct vgic_irq_rank *rank;\n    uint32_t tr;\n    unsigned long flags;\n\n    switch ( reg )\n    {\n    case GICD_IGROUPR ... GICD_IGROUPRN:\n        /* We do not implement security extensions for guests, write ignore */\n        goto write_ignore;\n    case GICD_ISENABLER ... GICD_ISENABLERN:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 1, reg - GICD_ISENABLER, DABT_WORD);\n        if ( rank == NULL ) goto write_ignore;\n        vgic_lock_rank(v, rank, flags);\n        tr = rank->ienable;\n        rank->ienable |= *r;\n        /* The irq number is extracted from offset. so shift by register size */\n        vgic_enable_irqs(v, (*r) & (~tr), (reg - GICD_ISENABLER) >> DABT_WORD);\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n    case GICD_ICENABLER ... GICD_ICENABLERN:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 1, reg - GICD_ICENABLER, DABT_WORD);\n        if ( rank == NULL ) goto write_ignore;\n        vgic_lock_rank(v, rank, flags);\n        tr = rank->ienable;\n        rank->ienable &= ~*r;\n        /* The irq number is extracted from offset. so shift by register size */\n        vgic_disable_irqs(v, (*r) & tr, (reg - GICD_ICENABLER) >> DABT_WORD);\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n    case GICD_ISPENDR ... GICD_ISPENDRN:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 1, reg - GICD_ISPENDR, DABT_WORD);\n        if ( rank == NULL ) goto write_ignore;\n        vgic_lock_rank(v, rank, flags);\n        rank->ipend = *r;\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n    case GICD_ICPENDR ... GICD_ICPENDRN:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 1, reg - GICD_ICPENDR, DABT_WORD);\n        if ( rank == NULL ) goto write_ignore;\n        vgic_lock_rank(v, rank, flags);\n        rank->ipend &= ~*r;\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n    case GICD_ISACTIVER ... GICD_ISACTIVERN:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 1, reg - GICD_ISACTIVER, DABT_WORD);\n        if ( rank == NULL ) goto write_ignore;\n        vgic_lock_rank(v, rank, flags);\n        rank->iactive &= ~*r;\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n    case GICD_ICACTIVER ... GICD_ICACTIVERN:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 1, reg - GICD_ICACTIVER, DABT_WORD);\n        if ( rank == NULL ) goto write_ignore;\n        vgic_lock_rank(v, rank, flags);\n        rank->iactive &= ~*r;\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n    case GICD_IPRIORITYR ... GICD_IPRIORITYRN:\n        if ( dabt.size != DABT_BYTE && dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 8, reg - GICD_IPRIORITYR, DABT_WORD);\n        if ( rank == NULL ) goto write_ignore;\n        vgic_lock_rank(v, rank, flags);\n        if ( dabt.size == DABT_WORD )\n            rank->ipriority[REG_RANK_INDEX(8, reg - GICD_IPRIORITYR,\n                                           DABT_WORD)] = *r;\n        else\n            vgic_byte_write(&rank->ipriority[REG_RANK_INDEX(8,\n                       reg - GICD_IPRIORITYR, DABT_WORD)], *r, reg);\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n    case GICD_ICFGR: /* Restricted to configure SGIs */\n        goto write_ignore;\n    case GICD_ICFGR + 4 ... GICD_ICFGRN: /* PPI + SPIs */\n        /* ICFGR1 for PPI's, which is implementation defined\n           if ICFGR1 is programmable or not. We chose to program */\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 2, reg - GICD_ICFGR, DABT_WORD);\n        if ( rank == NULL ) goto write_ignore;\n        vgic_lock_rank(v, rank, flags);\n        rank->icfg[REG_RANK_INDEX(2, reg - GICD_ICFGR, DABT_WORD)] = *r;\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n    default:\n        printk(\"vGICv3: vGICD/vGICR: unhandled write r%d \"\n               \"=%\"PRIregister\" offset %#08x\\n\", dabt.reg, *r, reg);\n        return 0;\n    }\n\nbad_width:\n    dprintk(XENLOG_ERR,\n            \"vGICv3: vGICD/vGICR: bad write width %d r%d=%\"PRIregister\" \"\n            \"offset %#08x\\n\", dabt.size, dabt.reg, *r, reg);\n    domain_crash_synchronous();\n    return 0;\n\nwrite_ignore:\n    if ( dabt.size != DABT_WORD ) goto bad_width;\n    return 1;\n}",
        "func": "static int __vgic_v3_distr_common_mmio_write(struct vcpu *v, mmio_info_t *info,\n                                             uint32_t reg)\n{\n    struct hsr_dabt dabt = info->dabt;\n    struct cpu_user_regs *regs = guest_cpu_user_regs();\n    register_t *r = select_user_reg(regs, dabt.reg);\n    struct vgic_irq_rank *rank;\n    uint32_t tr;\n    unsigned long flags;\n\n    switch ( reg )\n    {\n    case GICD_IGROUPR ... GICD_IGROUPRN:\n        /* We do not implement security extensions for guests, write ignore */\n        goto write_ignore;\n    case GICD_ISENABLER ... GICD_ISENABLERN:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 1, reg - GICD_ISENABLER, DABT_WORD);\n        if ( rank == NULL ) goto write_ignore;\n        vgic_lock_rank(v, rank, flags);\n        tr = rank->ienable;\n        rank->ienable |= *r;\n        /* The irq number is extracted from offset. so shift by register size */\n        vgic_enable_irqs(v, (*r) & (~tr), (reg - GICD_ISENABLER) >> DABT_WORD);\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n    case GICD_ICENABLER ... GICD_ICENABLERN:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 1, reg - GICD_ICENABLER, DABT_WORD);\n        if ( rank == NULL ) goto write_ignore;\n        vgic_lock_rank(v, rank, flags);\n        tr = rank->ienable;\n        rank->ienable &= ~*r;\n        /* The irq number is extracted from offset. so shift by register size */\n        vgic_disable_irqs(v, (*r) & tr, (reg - GICD_ICENABLER) >> DABT_WORD);\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n    case GICD_ISPENDR ... GICD_ISPENDRN:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 1, reg - GICD_ISPENDR, DABT_WORD);\n        if ( rank == NULL ) goto write_ignore;\n        vgic_lock_rank(v, rank, flags);\n        rank->ipend = *r;\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n    case GICD_ICPENDR ... GICD_ICPENDRN:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 1, reg - GICD_ICPENDR, DABT_WORD);\n        if ( rank == NULL ) goto write_ignore;\n        vgic_lock_rank(v, rank, flags);\n        rank->ipend &= ~*r;\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n    case GICD_ISACTIVER ... GICD_ISACTIVERN:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 1, reg - GICD_ISACTIVER, DABT_WORD);\n        if ( rank == NULL ) goto write_ignore;\n        vgic_lock_rank(v, rank, flags);\n        rank->iactive &= ~*r;\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n    case GICD_ICACTIVER ... GICD_ICACTIVERN:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 1, reg - GICD_ICACTIVER, DABT_WORD);\n        if ( rank == NULL ) goto write_ignore;\n        vgic_lock_rank(v, rank, flags);\n        rank->iactive &= ~*r;\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n    case GICD_IPRIORITYR ... GICD_IPRIORITYRN:\n        if ( dabt.size != DABT_BYTE && dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 8, reg - GICD_IPRIORITYR, DABT_WORD);\n        if ( rank == NULL ) goto write_ignore;\n        vgic_lock_rank(v, rank, flags);\n        if ( dabt.size == DABT_WORD )\n            rank->ipriority[REG_RANK_INDEX(8, reg - GICD_IPRIORITYR,\n                                           DABT_WORD)] = *r;\n        else\n            vgic_byte_write(&rank->ipriority[REG_RANK_INDEX(8,\n                       reg - GICD_IPRIORITYR, DABT_WORD)], *r, reg);\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n    case GICD_ICFGR: /* Restricted to configure SGIs */\n        goto write_ignore;\n    case GICD_ICFGR + 4 ... GICD_ICFGRN: /* PPI + SPIs */\n        /* ICFGR1 for PPI's, which is implementation defined\n           if ICFGR1 is programmable or not. We chose to program */\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 2, reg - GICD_ICFGR, DABT_WORD);\n        if ( rank == NULL ) goto write_ignore;\n        vgic_lock_rank(v, rank, flags);\n        rank->icfg[REG_RANK_INDEX(2, reg - GICD_ICFGR, DABT_WORD)] = *r;\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n    default:\n        printk(XENLOG_G_ERR\n               \"%pv: vGICD/vGICR: unhandled write r%d=%\"PRIregister\" offset %#08x\\n\",\n               v, dabt.reg, *r, reg);\n        return 0;\n    }\n\nbad_width:\n    printk(XENLOG_G_ERR\n           \"%pv: vGICD/vGICR: bad write width %d r%d=%\"PRIregister\" offset %#08x\\n\",\n           v, dabt.size, dabt.reg, *r, reg);\n    domain_crash_synchronous();\n    return 0;\n\nwrite_ignore:\n    if ( dabt.size != DABT_WORD ) goto bad_width;\n    return 1;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -93,15 +93,16 @@\n         vgic_unlock_rank(v, rank, flags);\n         return 1;\n     default:\n-        printk(\"vGICv3: vGICD/vGICR: unhandled write r%d \"\n-               \"=%\"PRIregister\" offset %#08x\\n\", dabt.reg, *r, reg);\n+        printk(XENLOG_G_ERR\n+               \"%pv: vGICD/vGICR: unhandled write r%d=%\"PRIregister\" offset %#08x\\n\",\n+               v, dabt.reg, *r, reg);\n         return 0;\n     }\n \n bad_width:\n-    dprintk(XENLOG_ERR,\n-            \"vGICv3: vGICD/vGICR: bad write width %d r%d=%\"PRIregister\" \"\n-            \"offset %#08x\\n\", dabt.size, dabt.reg, *r, reg);\n+    printk(XENLOG_G_ERR\n+           \"%pv: vGICD/vGICR: bad write width %d r%d=%\"PRIregister\" offset %#08x\\n\",\n+           v, dabt.size, dabt.reg, *r, reg);\n     domain_crash_synchronous();\n     return 0;\n ",
        "diff_line_info": {
            "deleted_lines": [
                "        printk(\"vGICv3: vGICD/vGICR: unhandled write r%d \"",
                "               \"=%\"PRIregister\" offset %#08x\\n\", dabt.reg, *r, reg);",
                "    dprintk(XENLOG_ERR,",
                "            \"vGICv3: vGICD/vGICR: bad write width %d r%d=%\"PRIregister\" \"",
                "            \"offset %#08x\\n\", dabt.size, dabt.reg, *r, reg);"
            ],
            "added_lines": [
                "        printk(XENLOG_G_ERR",
                "               \"%pv: vGICD/vGICR: unhandled write r%d=%\"PRIregister\" offset %#08x\\n\",",
                "               v, dabt.reg, *r, reg);",
                "    printk(XENLOG_G_ERR",
                "           \"%pv: vGICD/vGICR: bad write width %d r%d=%\"PRIregister\" offset %#08x\\n\",",
                "           v, dabt.size, dabt.reg, *r, reg);"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1563",
        "func_name": "xen-project/xen/vgic_v3_rdistr_sgi_mmio_read",
        "description": "The ARM GIC distributor virtualization in Xen 4.4.x and 4.5.x allows local guests to cause a denial of service by causing a large number messages to be logged.",
        "git_url": "https://github.com/xen-project/xen/commit/c96222cc6dbb285a4de8f25e3b8e284e212ef964",
        "commit_title": "xen/arm: vgic-v3: message in the emulation code should be rate-limited",
        "commit_text": " printk by default is not rate-limited by default. Therefore a malicious guest may be able to flood the Xen console.  If we use gdprintk, unnecessary information will be printed such as the filename and the line. Instead use XENLOG_G_{ERR,DEBUG} combine with %pv.  Also remove the vGICv3 prefix which is not neccessary and update some message which were wrong.  This is XSA-118. ",
        "func_before": "static int vgic_v3_rdistr_sgi_mmio_read(struct vcpu *v, mmio_info_t *info,\n                                        uint32_t gicr_reg)\n{\n    struct hsr_dabt dabt = info->dabt;\n    struct cpu_user_regs *regs = guest_cpu_user_regs();\n    register_t *r = select_user_reg(regs, dabt.reg);\n    struct vgic_irq_rank *rank;\n    unsigned long flags;\n\n    switch ( gicr_reg )\n    {\n    case GICR_IGRPMODR0:\n        /* We do not implement security extensions for guests, read zero */\n        goto read_as_zero;\n    case GICR_IGROUPR0:\n    case GICR_ISENABLER0:\n    case GICR_ICENABLER0:\n    case GICR_ISACTIVER0:\n    case GICR_ICACTIVER0:\n    case GICR_IPRIORITYR0...GICR_IPRIORITYR7:\n    case GICR_ICFGR0... GICR_ICFGR1:\n         /*\n          * Above registers offset are common with GICD.\n          * So handle in common with GICD handling\n          */\n        return __vgic_v3_distr_common_mmio_read(v, info, gicr_reg);\n    case GICR_ISPENDR0:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 1, gicr_reg - GICR_ISPENDR0, DABT_WORD);\n        if ( rank == NULL ) goto read_as_zero;\n        vgic_lock_rank(v, rank, flags);\n        *r = rank->pendsgi;\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n    case GICR_ICPENDR0:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 1, gicr_reg - GICR_ICPENDR0, DABT_WORD);\n        if ( rank == NULL ) goto read_as_zero;\n        vgic_lock_rank(v, rank, flags);\n        *r = rank->pendsgi;\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n    case GICR_NSACR:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        return 1;\n    default:\n        printk(\"vGICv3: vGICR: read r%d offset %#08x\\n not found\",\n               dabt.reg, gicr_reg);\n        return 0;\n    }\nbad_width:\n    printk(\"vGICv3: vGICR: bad read width %d r%d offset %#08x\\n\",\n           dabt.size, dabt.reg, gicr_reg);\n    domain_crash_synchronous();\n    return 0;\n\nread_as_zero:\n    if ( dabt.size != DABT_WORD ) goto bad_width;\n    *r = 0;\n    return 1;\n}",
        "func": "static int vgic_v3_rdistr_sgi_mmio_read(struct vcpu *v, mmio_info_t *info,\n                                        uint32_t gicr_reg)\n{\n    struct hsr_dabt dabt = info->dabt;\n    struct cpu_user_regs *regs = guest_cpu_user_regs();\n    register_t *r = select_user_reg(regs, dabt.reg);\n    struct vgic_irq_rank *rank;\n    unsigned long flags;\n\n    switch ( gicr_reg )\n    {\n    case GICR_IGRPMODR0:\n        /* We do not implement security extensions for guests, read zero */\n        goto read_as_zero;\n    case GICR_IGROUPR0:\n    case GICR_ISENABLER0:\n    case GICR_ICENABLER0:\n    case GICR_ISACTIVER0:\n    case GICR_ICACTIVER0:\n    case GICR_IPRIORITYR0...GICR_IPRIORITYR7:\n    case GICR_ICFGR0... GICR_ICFGR1:\n         /*\n          * Above registers offset are common with GICD.\n          * So handle in common with GICD handling\n          */\n        return __vgic_v3_distr_common_mmio_read(v, info, gicr_reg);\n    case GICR_ISPENDR0:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 1, gicr_reg - GICR_ISPENDR0, DABT_WORD);\n        if ( rank == NULL ) goto read_as_zero;\n        vgic_lock_rank(v, rank, flags);\n        *r = rank->pendsgi;\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n    case GICR_ICPENDR0:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 1, gicr_reg - GICR_ICPENDR0, DABT_WORD);\n        if ( rank == NULL ) goto read_as_zero;\n        vgic_lock_rank(v, rank, flags);\n        *r = rank->pendsgi;\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n    case GICR_NSACR:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        return 1;\n    default:\n        printk(XENLOG_G_ERR\n               \"%pv: vGICR: SGI: read r%d offset %#08x\\n not found\",\n               v, dabt.reg, gicr_reg);\n        return 0;\n    }\nbad_width:\n    printk(XENLOG_G_ERR \"%pv: vGICR: SGI: bad read width %d r%d offset %#08x\\n\",\n           v, dabt.size, dabt.reg, gicr_reg);\n    domain_crash_synchronous();\n    return 0;\n\nread_as_zero:\n    if ( dabt.size != DABT_WORD ) goto bad_width;\n    *r = 0;\n    return 1;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -44,13 +44,14 @@\n         if ( dabt.size != DABT_WORD ) goto bad_width;\n         return 1;\n     default:\n-        printk(\"vGICv3: vGICR: read r%d offset %#08x\\n not found\",\n-               dabt.reg, gicr_reg);\n+        printk(XENLOG_G_ERR\n+               \"%pv: vGICR: SGI: read r%d offset %#08x\\n not found\",\n+               v, dabt.reg, gicr_reg);\n         return 0;\n     }\n bad_width:\n-    printk(\"vGICv3: vGICR: bad read width %d r%d offset %#08x\\n\",\n-           dabt.size, dabt.reg, gicr_reg);\n+    printk(XENLOG_G_ERR \"%pv: vGICR: SGI: bad read width %d r%d offset %#08x\\n\",\n+           v, dabt.size, dabt.reg, gicr_reg);\n     domain_crash_synchronous();\n     return 0;\n ",
        "diff_line_info": {
            "deleted_lines": [
                "        printk(\"vGICv3: vGICR: read r%d offset %#08x\\n not found\",",
                "               dabt.reg, gicr_reg);",
                "    printk(\"vGICv3: vGICR: bad read width %d r%d offset %#08x\\n\",",
                "           dabt.size, dabt.reg, gicr_reg);"
            ],
            "added_lines": [
                "        printk(XENLOG_G_ERR",
                "               \"%pv: vGICR: SGI: read r%d offset %#08x\\n not found\",",
                "               v, dabt.reg, gicr_reg);",
                "    printk(XENLOG_G_ERR \"%pv: vGICR: SGI: bad read width %d r%d offset %#08x\\n\",",
                "           v, dabt.size, dabt.reg, gicr_reg);"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1563",
        "func_name": "xen-project/xen/vgic_v3_rdistr_sgi_mmio_write",
        "description": "The ARM GIC distributor virtualization in Xen 4.4.x and 4.5.x allows local guests to cause a denial of service by causing a large number messages to be logged.",
        "git_url": "https://github.com/xen-project/xen/commit/c96222cc6dbb285a4de8f25e3b8e284e212ef964",
        "commit_title": "xen/arm: vgic-v3: message in the emulation code should be rate-limited",
        "commit_text": " printk by default is not rate-limited by default. Therefore a malicious guest may be able to flood the Xen console.  If we use gdprintk, unnecessary information will be printed such as the filename and the line. Instead use XENLOG_G_{ERR,DEBUG} combine with %pv.  Also remove the vGICv3 prefix which is not neccessary and update some message which were wrong.  This is XSA-118. ",
        "func_before": "static int vgic_v3_rdistr_sgi_mmio_write(struct vcpu *v, mmio_info_t *info,\n                                         uint32_t gicr_reg)\n{\n    struct hsr_dabt dabt = info->dabt;\n    struct cpu_user_regs *regs = guest_cpu_user_regs();\n    register_t *r = select_user_reg(regs, dabt.reg);\n    struct vgic_irq_rank *rank;\n    unsigned long flags;\n\n    switch ( gicr_reg )\n    {\n    case GICR_IGRPMODR0:\n        /* We do not implement security extensions for guests, write ignore */\n        goto write_ignore;\n    case GICR_IGROUPR0:\n    case GICR_ISENABLER0:\n    case GICR_ICENABLER0:\n    case GICR_ISACTIVER0:\n    case GICR_ICACTIVER0:\n    case GICR_ICFGR1:\n    case GICR_IPRIORITYR0...GICR_IPRIORITYR7:\n         /*\n          * Above registers offset are common with GICD.\n          * So handle common with GICD handling\n          */\n        return __vgic_v3_distr_common_mmio_write(v, info, gicr_reg);\n    case GICR_ISPENDR0:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 1, gicr_reg - GICR_ISACTIVER0, DABT_WORD);\n        if ( rank == NULL ) goto write_ignore;\n        vgic_lock_rank(v, rank, flags);\n        /* TODO: we just store the SGI pending status. Handle it properly */\n        rank->pendsgi |= *r;\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n    case GICR_ICPENDR0:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 1, gicr_reg - GICR_ISACTIVER0, DABT_WORD);\n        if ( rank == NULL ) goto write_ignore;\n        vgic_lock_rank(v, rank, flags);\n        /* TODO: we just store the SGI pending status. Handle it properly */\n        rank->pendsgi &= ~*r;\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n    case GICR_NSACR:\n        /* We do not implement security extensions for guests, write ignore */\n        goto write_ignore;\n    default:\n        printk(\"vGICv3: vGICR SGI: write r%d offset %#08x\\n not found\",\n               dabt.reg, gicr_reg);\n        return 0;\n    }\n\nbad_width:\n    printk(\"vGICR SGI: bad write width %d r%d=%\"PRIregister\" offset %#08x\\n\",\n           dabt.size, dabt.reg, *r, gicr_reg);\n    domain_crash_synchronous();\n    return 0;\n\nwrite_ignore:\n    if ( dabt.size != DABT_WORD ) goto bad_width;\n    return 1;\n}",
        "func": "static int vgic_v3_rdistr_sgi_mmio_write(struct vcpu *v, mmio_info_t *info,\n                                         uint32_t gicr_reg)\n{\n    struct hsr_dabt dabt = info->dabt;\n    struct cpu_user_regs *regs = guest_cpu_user_regs();\n    register_t *r = select_user_reg(regs, dabt.reg);\n    struct vgic_irq_rank *rank;\n    unsigned long flags;\n\n    switch ( gicr_reg )\n    {\n    case GICR_IGRPMODR0:\n        /* We do not implement security extensions for guests, write ignore */\n        goto write_ignore;\n    case GICR_IGROUPR0:\n    case GICR_ISENABLER0:\n    case GICR_ICENABLER0:\n    case GICR_ISACTIVER0:\n    case GICR_ICACTIVER0:\n    case GICR_ICFGR1:\n    case GICR_IPRIORITYR0...GICR_IPRIORITYR7:\n         /*\n          * Above registers offset are common with GICD.\n          * So handle common with GICD handling\n          */\n        return __vgic_v3_distr_common_mmio_write(v, info, gicr_reg);\n    case GICR_ISPENDR0:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 1, gicr_reg - GICR_ISACTIVER0, DABT_WORD);\n        if ( rank == NULL ) goto write_ignore;\n        vgic_lock_rank(v, rank, flags);\n        /* TODO: we just store the SGI pending status. Handle it properly */\n        rank->pendsgi |= *r;\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n    case GICR_ICPENDR0:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 1, gicr_reg - GICR_ISACTIVER0, DABT_WORD);\n        if ( rank == NULL ) goto write_ignore;\n        vgic_lock_rank(v, rank, flags);\n        /* TODO: we just store the SGI pending status. Handle it properly */\n        rank->pendsgi &= ~*r;\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n    case GICR_NSACR:\n        /* We do not implement security extensions for guests, write ignore */\n        goto write_ignore;\n    default:\n        printk(XENLOG_G_ERR\n               \"%pv: vGICR: SGI: write r%d offset %#08x\\n not found\",\n               v, dabt.reg, gicr_reg);\n        return 0;\n    }\n\nbad_width:\n    printk(XENLOG_G_ERR\n           \"%pv: vGICR: SGI: bad write width %d r%d=%\"PRIregister\" offset %#08x\\n\",\n           v, dabt.size, dabt.reg, *r, gicr_reg);\n    domain_crash_synchronous();\n    return 0;\n\nwrite_ignore:\n    if ( dabt.size != DABT_WORD ) goto bad_width;\n    return 1;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -46,14 +46,16 @@\n         /* We do not implement security extensions for guests, write ignore */\n         goto write_ignore;\n     default:\n-        printk(\"vGICv3: vGICR SGI: write r%d offset %#08x\\n not found\",\n-               dabt.reg, gicr_reg);\n+        printk(XENLOG_G_ERR\n+               \"%pv: vGICR: SGI: write r%d offset %#08x\\n not found\",\n+               v, dabt.reg, gicr_reg);\n         return 0;\n     }\n \n bad_width:\n-    printk(\"vGICR SGI: bad write width %d r%d=%\"PRIregister\" offset %#08x\\n\",\n-           dabt.size, dabt.reg, *r, gicr_reg);\n+    printk(XENLOG_G_ERR\n+           \"%pv: vGICR: SGI: bad write width %d r%d=%\"PRIregister\" offset %#08x\\n\",\n+           v, dabt.size, dabt.reg, *r, gicr_reg);\n     domain_crash_synchronous();\n     return 0;\n ",
        "diff_line_info": {
            "deleted_lines": [
                "        printk(\"vGICv3: vGICR SGI: write r%d offset %#08x\\n not found\",",
                "               dabt.reg, gicr_reg);",
                "    printk(\"vGICR SGI: bad write width %d r%d=%\"PRIregister\" offset %#08x\\n\",",
                "           dabt.size, dabt.reg, *r, gicr_reg);"
            ],
            "added_lines": [
                "        printk(XENLOG_G_ERR",
                "               \"%pv: vGICR: SGI: write r%d offset %#08x\\n not found\",",
                "               v, dabt.reg, gicr_reg);",
                "    printk(XENLOG_G_ERR",
                "           \"%pv: vGICR: SGI: bad write width %d r%d=%\"PRIregister\" offset %#08x\\n\",",
                "           v, dabt.size, dabt.reg, *r, gicr_reg);"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1563",
        "func_name": "xen-project/xen/vgic_v3_rdistr_mmio_write",
        "description": "The ARM GIC distributor virtualization in Xen 4.4.x and 4.5.x allows local guests to cause a denial of service by causing a large number messages to be logged.",
        "git_url": "https://github.com/xen-project/xen/commit/c96222cc6dbb285a4de8f25e3b8e284e212ef964",
        "commit_title": "xen/arm: vgic-v3: message in the emulation code should be rate-limited",
        "commit_text": " printk by default is not rate-limited by default. Therefore a malicious guest may be able to flood the Xen console.  If we use gdprintk, unnecessary information will be printed such as the filename and the line. Instead use XENLOG_G_{ERR,DEBUG} combine with %pv.  Also remove the vGICv3 prefix which is not neccessary and update some message which were wrong.  This is XSA-118. ",
        "func_before": "static int vgic_v3_rdistr_mmio_write(struct vcpu *v, mmio_info_t *info)\n{\n    uint32_t offset;\n\n    perfc_incr(vgicr_writes);\n\n    if ( v->domain->arch.vgic.rdist_stride != 0 )\n        offset = info->gpa & (v->domain->arch.vgic.rdist_stride - 1);\n    else\n        /* If stride is not set. Default 128K */\n        offset = info->gpa & (SZ_128K - 1);\n\n    if ( offset < SZ_64K )\n        return __vgic_v3_rdistr_rd_mmio_write(v, info, offset);\n    else  if ( (offset >= SZ_64K) && (offset < 2 * SZ_64K) )\n        return vgic_v3_rdistr_sgi_mmio_write(v, info, (offset - SZ_64K));\n    else\n        gdprintk(XENLOG_WARNING,\n                 \"vGICV3: vGICR: unknown gpa write address %\"PRIpaddr\"\\n\",\n                 info->gpa);\n\n    return 0;\n}",
        "func": "static int vgic_v3_rdistr_mmio_write(struct vcpu *v, mmio_info_t *info)\n{\n    uint32_t offset;\n\n    perfc_incr(vgicr_writes);\n\n    if ( v->domain->arch.vgic.rdist_stride != 0 )\n        offset = info->gpa & (v->domain->arch.vgic.rdist_stride - 1);\n    else\n        /* If stride is not set. Default 128K */\n        offset = info->gpa & (SZ_128K - 1);\n\n    if ( offset < SZ_64K )\n        return __vgic_v3_rdistr_rd_mmio_write(v, info, offset);\n    else  if ( (offset >= SZ_64K) && (offset < 2 * SZ_64K) )\n        return vgic_v3_rdistr_sgi_mmio_write(v, info, (offset - SZ_64K));\n    else\n        printk(XENLOG_G_WARNING\n               \"%pv: vGICR: unknown gpa write address %\"PRIpaddr\"\\n\",\n               v, info->gpa);\n\n    return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -15,9 +15,9 @@\n     else  if ( (offset >= SZ_64K) && (offset < 2 * SZ_64K) )\n         return vgic_v3_rdistr_sgi_mmio_write(v, info, (offset - SZ_64K));\n     else\n-        gdprintk(XENLOG_WARNING,\n-                 \"vGICV3: vGICR: unknown gpa write address %\"PRIpaddr\"\\n\",\n-                 info->gpa);\n+        printk(XENLOG_G_WARNING\n+               \"%pv: vGICR: unknown gpa write address %\"PRIpaddr\"\\n\",\n+               v, info->gpa);\n \n     return 0;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "        gdprintk(XENLOG_WARNING,",
                "                 \"vGICV3: vGICR: unknown gpa write address %\"PRIpaddr\"\\n\",",
                "                 info->gpa);"
            ],
            "added_lines": [
                "        printk(XENLOG_G_WARNING",
                "               \"%pv: vGICR: unknown gpa write address %\"PRIpaddr\"\\n\",",
                "               v, info->gpa);"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1563",
        "func_name": "xen-project/xen/vgic_v3_distr_mmio_read",
        "description": "The ARM GIC distributor virtualization in Xen 4.4.x and 4.5.x allows local guests to cause a denial of service by causing a large number messages to be logged.",
        "git_url": "https://github.com/xen-project/xen/commit/c96222cc6dbb285a4de8f25e3b8e284e212ef964",
        "commit_title": "xen/arm: vgic-v3: message in the emulation code should be rate-limited",
        "commit_text": " printk by default is not rate-limited by default. Therefore a malicious guest may be able to flood the Xen console.  If we use gdprintk, unnecessary information will be printed such as the filename and the line. Instead use XENLOG_G_{ERR,DEBUG} combine with %pv.  Also remove the vGICv3 prefix which is not neccessary and update some message which were wrong.  This is XSA-118. ",
        "func_before": "static int vgic_v3_distr_mmio_read(struct vcpu *v, mmio_info_t *info)\n{\n    struct hsr_dabt dabt = info->dabt;\n    struct cpu_user_regs *regs = guest_cpu_user_regs();\n    register_t *r = select_user_reg(regs, dabt.reg);\n    struct vgic_irq_rank *rank;\n    unsigned long flags;\n    uint64_t irouter;\n    unsigned int vcpu_id;\n    int gicd_reg = (int)(info->gpa - v->domain->arch.vgic.dbase);\n\n    perfc_incr(vgicd_reads);\n\n    switch ( gicd_reg )\n    {\n    case GICD_CTLR:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        vgic_lock(v);\n        *r = v->domain->arch.vgic.ctlr;\n        vgic_unlock(v);\n        return 1;\n    case GICD_TYPER:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        /* No secure world support for guests. */\n        *r = (((v->domain->max_vcpus << 5) & GICD_TYPE_CPUS ) |\n              ((v->domain->arch.vgic.nr_spis / 32) & GICD_TYPE_LINES));\n        return 1;\n    case GICD_STATUSR:\n        /*\n         *  Optional, Not implemented for now.\n         *  Update to support guest debugging.\n         */\n        goto read_as_zero;\n    case GICD_IIDR:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        *r = GICV3_GICD_IIDR_VAL;\n        return 1;\n    case 0x020 ... 0x03c:\n    case 0xc000 ... 0xffcc:\n        /* Implementation defined -- read as zero */\n        goto read_as_zero;\n    case GICD_IGROUPR ... GICD_IGROUPRN:\n    case GICD_ISENABLER ... GICD_ISENABLERN:\n    case GICD_ICENABLER ... GICD_ICENABLERN:\n    case GICD_ISPENDR ... GICD_ISPENDRN:\n    case GICD_ICPENDR ... GICD_ICPENDRN:\n    case GICD_ISACTIVER ... GICD_ISACTIVERN:\n    case GICD_IPRIORITYR ... GICD_IPRIORITYRN:\n    case GICD_ICFGR ... GICD_ICFGRN:\n        /*\n         * Above all register are common with GICR and GICD\n         * Manage in common\n         */\n        return __vgic_v3_distr_common_mmio_read(v, info, gicd_reg);\n    case GICD_IROUTER ... GICD_IROUTER31:\n        /* SGI/PPI is RES0 */\n        goto read_as_zero_64;\n    case GICD_IROUTER32 ... GICD_IROUTERN:\n        if ( dabt.size != DABT_DOUBLE_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 64, gicd_reg - GICD_IROUTER,\n                                DABT_DOUBLE_WORD);\n        if ( rank == NULL ) goto read_as_zero;\n        vgic_lock_rank(v, rank, flags);\n        irouter = rank->v3.irouter[REG_RANK_INDEX(64,\n                                  (gicd_reg - GICD_IROUTER), DABT_DOUBLE_WORD)];\n        /* XXX: bit[31] stores IRQ mode. Just return */\n        if ( irouter & GICD_IROUTER_SPI_MODE_ANY )\n        {\n            *r = GICD_IROUTER_SPI_MODE_ANY;\n            vgic_unlock_rank(v, rank, flags);\n            return 1;\n        }\n        vcpu_id = irouter;\n        *r = vgic_v3_vcpu_to_irouter(v, vcpu_id);\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n    case GICD_NSACR ... GICD_NSACRN:\n        /* We do not implement security extensions for guests, read zero */\n        goto read_as_zero;\n    case GICD_SGIR:\n        /* Read as ICH_SGIR system register with SRE set. So ignore */\n        goto read_as_zero;\n    case GICD_CPENDSGIR ... GICD_CPENDSGIRN:\n        /* Replaced with GICR_ICPENDR0. So ignore write */\n        goto read_as_zero;\n    case GICD_SPENDSGIR ... GICD_SPENDSGIRN:\n        /* Replaced with GICR_ISPENDR0. So ignore write */\n        goto read_as_zero;\n    case GICD_PIDR0:\n        /* GICv3 identification value */\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        *r = GICV3_GICD_PIDR0;\n        return 1;\n    case GICD_PIDR1:\n        /* GICv3 identification value */\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        *r = GICV3_GICD_PIDR1;\n        return 1;\n    case GICD_PIDR2:\n        /* GICv3 identification value */\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        *r = GICV3_GICD_PIDR2;\n        return 1;\n    case GICD_PIDR3:\n        /* GICv3 identification value. Manufacturer/Customer defined */\n        goto read_as_zero;\n    case GICD_PIDR4:\n        /* GICv3 identification value */\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        *r = GICV3_GICD_PIDR4;\n        return 1;\n    case GICD_PIDR5 ... GICD_PIDR7:\n        /* Reserved0 */\n        goto read_as_zero;\n    case 0x00c:\n    case 0x044:\n    case 0x04c:\n    case 0x05c ... 0x07c:\n    case 0xf30 ... 0x5fcc:\n    case 0x8000 ... 0xbfcc:\n        /* These are reserved register addresses */\n        printk(\"vGICv3: vGICD: read unknown 0x00c .. 0xfcc r%d offset %#08x\\n\",\n               dabt.reg, gicd_reg);\n        goto read_as_zero;\n    default:\n        printk(\"vGICv3: vGICD: unhandled read r%d offset %#08x\\n\",\n               dabt.reg, gicd_reg);\n        return 0;\n    }\n\nbad_width:\n    dprintk(XENLOG_ERR, \"vGICv3: vGICD: bad read width %d r%d offset %#08x\\n\",\n            dabt.size, dabt.reg, gicd_reg);\n    domain_crash_synchronous();\n    return 0;\n\nread_as_zero_64:\n    if ( dabt.size != DABT_DOUBLE_WORD ) goto bad_width;\n    *r = 0;\n    return 1;\n\nread_as_zero:\n    if ( dabt.size != DABT_WORD ) goto bad_width;\n    *r = 0;\n    return 1;\n}",
        "func": "static int vgic_v3_distr_mmio_read(struct vcpu *v, mmio_info_t *info)\n{\n    struct hsr_dabt dabt = info->dabt;\n    struct cpu_user_regs *regs = guest_cpu_user_regs();\n    register_t *r = select_user_reg(regs, dabt.reg);\n    struct vgic_irq_rank *rank;\n    unsigned long flags;\n    uint64_t irouter;\n    unsigned int vcpu_id;\n    int gicd_reg = (int)(info->gpa - v->domain->arch.vgic.dbase);\n\n    perfc_incr(vgicd_reads);\n\n    switch ( gicd_reg )\n    {\n    case GICD_CTLR:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        vgic_lock(v);\n        *r = v->domain->arch.vgic.ctlr;\n        vgic_unlock(v);\n        return 1;\n    case GICD_TYPER:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        /* No secure world support for guests. */\n        *r = (((v->domain->max_vcpus << 5) & GICD_TYPE_CPUS ) |\n              ((v->domain->arch.vgic.nr_spis / 32) & GICD_TYPE_LINES));\n        return 1;\n    case GICD_STATUSR:\n        /*\n         *  Optional, Not implemented for now.\n         *  Update to support guest debugging.\n         */\n        goto read_as_zero;\n    case GICD_IIDR:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        *r = GICV3_GICD_IIDR_VAL;\n        return 1;\n    case 0x020 ... 0x03c:\n    case 0xc000 ... 0xffcc:\n        /* Implementation defined -- read as zero */\n        goto read_as_zero;\n    case GICD_IGROUPR ... GICD_IGROUPRN:\n    case GICD_ISENABLER ... GICD_ISENABLERN:\n    case GICD_ICENABLER ... GICD_ICENABLERN:\n    case GICD_ISPENDR ... GICD_ISPENDRN:\n    case GICD_ICPENDR ... GICD_ICPENDRN:\n    case GICD_ISACTIVER ... GICD_ISACTIVERN:\n    case GICD_IPRIORITYR ... GICD_IPRIORITYRN:\n    case GICD_ICFGR ... GICD_ICFGRN:\n        /*\n         * Above all register are common with GICR and GICD\n         * Manage in common\n         */\n        return __vgic_v3_distr_common_mmio_read(v, info, gicd_reg);\n    case GICD_IROUTER ... GICD_IROUTER31:\n        /* SGI/PPI is RES0 */\n        goto read_as_zero_64;\n    case GICD_IROUTER32 ... GICD_IROUTERN:\n        if ( dabt.size != DABT_DOUBLE_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 64, gicd_reg - GICD_IROUTER,\n                                DABT_DOUBLE_WORD);\n        if ( rank == NULL ) goto read_as_zero;\n        vgic_lock_rank(v, rank, flags);\n        irouter = rank->v3.irouter[REG_RANK_INDEX(64,\n                                  (gicd_reg - GICD_IROUTER), DABT_DOUBLE_WORD)];\n        /* XXX: bit[31] stores IRQ mode. Just return */\n        if ( irouter & GICD_IROUTER_SPI_MODE_ANY )\n        {\n            *r = GICD_IROUTER_SPI_MODE_ANY;\n            vgic_unlock_rank(v, rank, flags);\n            return 1;\n        }\n        vcpu_id = irouter;\n        *r = vgic_v3_vcpu_to_irouter(v, vcpu_id);\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n    case GICD_NSACR ... GICD_NSACRN:\n        /* We do not implement security extensions for guests, read zero */\n        goto read_as_zero;\n    case GICD_SGIR:\n        /* Read as ICH_SGIR system register with SRE set. So ignore */\n        goto read_as_zero;\n    case GICD_CPENDSGIR ... GICD_CPENDSGIRN:\n        /* Replaced with GICR_ICPENDR0. So ignore write */\n        goto read_as_zero;\n    case GICD_SPENDSGIR ... GICD_SPENDSGIRN:\n        /* Replaced with GICR_ISPENDR0. So ignore write */\n        goto read_as_zero;\n    case GICD_PIDR0:\n        /* GICv3 identification value */\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        *r = GICV3_GICD_PIDR0;\n        return 1;\n    case GICD_PIDR1:\n        /* GICv3 identification value */\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        *r = GICV3_GICD_PIDR1;\n        return 1;\n    case GICD_PIDR2:\n        /* GICv3 identification value */\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        *r = GICV3_GICD_PIDR2;\n        return 1;\n    case GICD_PIDR3:\n        /* GICv3 identification value. Manufacturer/Customer defined */\n        goto read_as_zero;\n    case GICD_PIDR4:\n        /* GICv3 identification value */\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        *r = GICV3_GICD_PIDR4;\n        return 1;\n    case GICD_PIDR5 ... GICD_PIDR7:\n        /* Reserved0 */\n        goto read_as_zero;\n    case 0x00c:\n    case 0x044:\n    case 0x04c:\n    case 0x05c ... 0x07c:\n    case 0xf30 ... 0x5fcc:\n    case 0x8000 ... 0xbfcc:\n        /* These are reserved register addresses */\n        printk(XENLOG_G_DEBUG\n               \"%pv: vGICD: RAZ on reserved register offset %#08x\\n\",\n               v, gicd_reg);\n        goto read_as_zero;\n    default:\n        printk(XENLOG_G_ERR \"%pv: vGICD: unhandled read r%d offset %#08x\\n\",\n               v, dabt.reg, gicd_reg);\n        return 0;\n    }\n\nbad_width:\n    printk(XENLOG_G_ERR \"%pv: vGICD: bad read width %d r%d offset %#08x\\n\",\n           v, dabt.size, dabt.reg, gicd_reg);\n    domain_crash_synchronous();\n    return 0;\n\nread_as_zero_64:\n    if ( dabt.size != DABT_DOUBLE_WORD ) goto bad_width;\n    *r = 0;\n    return 1;\n\nread_as_zero:\n    if ( dabt.size != DABT_WORD ) goto bad_width;\n    *r = 0;\n    return 1;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -119,18 +119,19 @@\n     case 0xf30 ... 0x5fcc:\n     case 0x8000 ... 0xbfcc:\n         /* These are reserved register addresses */\n-        printk(\"vGICv3: vGICD: read unknown 0x00c .. 0xfcc r%d offset %#08x\\n\",\n-               dabt.reg, gicd_reg);\n+        printk(XENLOG_G_DEBUG\n+               \"%pv: vGICD: RAZ on reserved register offset %#08x\\n\",\n+               v, gicd_reg);\n         goto read_as_zero;\n     default:\n-        printk(\"vGICv3: vGICD: unhandled read r%d offset %#08x\\n\",\n-               dabt.reg, gicd_reg);\n+        printk(XENLOG_G_ERR \"%pv: vGICD: unhandled read r%d offset %#08x\\n\",\n+               v, dabt.reg, gicd_reg);\n         return 0;\n     }\n \n bad_width:\n-    dprintk(XENLOG_ERR, \"vGICv3: vGICD: bad read width %d r%d offset %#08x\\n\",\n-            dabt.size, dabt.reg, gicd_reg);\n+    printk(XENLOG_G_ERR \"%pv: vGICD: bad read width %d r%d offset %#08x\\n\",\n+           v, dabt.size, dabt.reg, gicd_reg);\n     domain_crash_synchronous();\n     return 0;\n ",
        "diff_line_info": {
            "deleted_lines": [
                "        printk(\"vGICv3: vGICD: read unknown 0x00c .. 0xfcc r%d offset %#08x\\n\",",
                "               dabt.reg, gicd_reg);",
                "        printk(\"vGICv3: vGICD: unhandled read r%d offset %#08x\\n\",",
                "               dabt.reg, gicd_reg);",
                "    dprintk(XENLOG_ERR, \"vGICv3: vGICD: bad read width %d r%d offset %#08x\\n\",",
                "            dabt.size, dabt.reg, gicd_reg);"
            ],
            "added_lines": [
                "        printk(XENLOG_G_DEBUG",
                "               \"%pv: vGICD: RAZ on reserved register offset %#08x\\n\",",
                "               v, gicd_reg);",
                "        printk(XENLOG_G_ERR \"%pv: vGICD: unhandled read r%d offset %#08x\\n\",",
                "               v, dabt.reg, gicd_reg);",
                "    printk(XENLOG_G_ERR \"%pv: vGICD: bad read width %d r%d offset %#08x\\n\",",
                "           v, dabt.size, dabt.reg, gicd_reg);"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1563",
        "func_name": "xen-project/xen/__vgic_v3_rdistr_rd_mmio_write",
        "description": "The ARM GIC distributor virtualization in Xen 4.4.x and 4.5.x allows local guests to cause a denial of service by causing a large number messages to be logged.",
        "git_url": "https://github.com/xen-project/xen/commit/c96222cc6dbb285a4de8f25e3b8e284e212ef964",
        "commit_title": "xen/arm: vgic-v3: message in the emulation code should be rate-limited",
        "commit_text": " printk by default is not rate-limited by default. Therefore a malicious guest may be able to flood the Xen console.  If we use gdprintk, unnecessary information will be printed such as the filename and the line. Instead use XENLOG_G_{ERR,DEBUG} combine with %pv.  Also remove the vGICv3 prefix which is not neccessary and update some message which were wrong.  This is XSA-118. ",
        "func_before": "static int __vgic_v3_rdistr_rd_mmio_write(struct vcpu *v, mmio_info_t *info,\n                                          uint32_t gicr_reg)\n{\n    struct hsr_dabt dabt = info->dabt;\n    struct cpu_user_regs *regs = guest_cpu_user_regs();\n    register_t *r = select_user_reg(regs, dabt.reg);\n\n    switch ( gicr_reg )\n    {\n    case GICR_CTLR:\n        /* LPI's not implemented */\n        goto write_ignore;\n    case GICR_IIDR:\n        /* RO */\n        goto write_ignore;\n    case GICR_TYPER:\n        /* RO */\n        goto write_ignore_64;\n    case GICR_STATUSR:\n        /* Not implemented */\n        goto write_ignore;\n    case GICR_WAKER:\n        /* Power mgmt not implemented */\n        goto write_ignore;\n    case GICR_SETLPIR:\n        /* LPI is not implemented */\n        goto write_ignore_64;\n    case GICR_CLRLPIR:\n        /* LPI is not implemented */\n        goto write_ignore_64;\n    case GICR_PROPBASER:\n        /* LPI is not implemented */\n        goto write_ignore_64;\n    case GICR_PENDBASER:\n        /* LPI is not implemented */\n        goto write_ignore_64;\n    case GICR_INVLPIR:\n        /* LPI is not implemented */\n        goto write_ignore_64;\n    case GICR_INVALLR:\n        /* LPI is not implemented */\n        goto write_ignore_64;\n    case GICR_SYNCR:\n        /* RO */\n        goto write_ignore;\n    case GICR_MOVLPIR:\n        /* LPI is not implemented */\n        goto write_ignore_64;\n    case GICR_MOVALLR:\n        /* LPI is not implemented */\n        goto write_ignore_64;\n    case GICR_PIDR7... GICR_PIDR0:\n        /* RO */\n        goto write_ignore;\n    default:\n        printk(\"vGICR: write r%d offset %#08x\\n not found\", dabt.reg, gicr_reg);\n        return 0;\n    }\nbad_width:\n    printk(\"vGICR: bad write width %d r%d=%\"PRIregister\" offset %#08x\\n\",\n           dabt.size, dabt.reg, *r, gicr_reg);\n    domain_crash_synchronous();\n    return 0;\n\nwrite_ignore_64:\n    if ( dabt.size != DABT_DOUBLE_WORD ) goto bad_width;\n    return 1;\n\nwrite_ignore:\n    if ( dabt.size != DABT_WORD ) goto bad_width;\n    return 1;\n}",
        "func": "static int __vgic_v3_rdistr_rd_mmio_write(struct vcpu *v, mmio_info_t *info,\n                                          uint32_t gicr_reg)\n{\n    struct hsr_dabt dabt = info->dabt;\n    struct cpu_user_regs *regs = guest_cpu_user_regs();\n    register_t *r = select_user_reg(regs, dabt.reg);\n\n    switch ( gicr_reg )\n    {\n    case GICR_CTLR:\n        /* LPI's not implemented */\n        goto write_ignore;\n    case GICR_IIDR:\n        /* RO */\n        goto write_ignore;\n    case GICR_TYPER:\n        /* RO */\n        goto write_ignore_64;\n    case GICR_STATUSR:\n        /* Not implemented */\n        goto write_ignore;\n    case GICR_WAKER:\n        /* Power mgmt not implemented */\n        goto write_ignore;\n    case GICR_SETLPIR:\n        /* LPI is not implemented */\n        goto write_ignore_64;\n    case GICR_CLRLPIR:\n        /* LPI is not implemented */\n        goto write_ignore_64;\n    case GICR_PROPBASER:\n        /* LPI is not implemented */\n        goto write_ignore_64;\n    case GICR_PENDBASER:\n        /* LPI is not implemented */\n        goto write_ignore_64;\n    case GICR_INVLPIR:\n        /* LPI is not implemented */\n        goto write_ignore_64;\n    case GICR_INVALLR:\n        /* LPI is not implemented */\n        goto write_ignore_64;\n    case GICR_SYNCR:\n        /* RO */\n        goto write_ignore;\n    case GICR_MOVLPIR:\n        /* LPI is not implemented */\n        goto write_ignore_64;\n    case GICR_MOVALLR:\n        /* LPI is not implemented */\n        goto write_ignore_64;\n    case GICR_PIDR7... GICR_PIDR0:\n        /* RO */\n        goto write_ignore;\n    default:\n        printk(XENLOG_G_ERR \"%pv: vGICR: write r%d offset %#08x\\n not found\",\n               v, dabt.reg, gicr_reg);\n        return 0;\n    }\nbad_width:\n    printk(XENLOG_G_ERR\n          \"%pv: vGICR: bad write width %d r%d=%\"PRIregister\" offset %#08x\\n\",\n          v, dabt.size, dabt.reg, *r, gicr_reg);\n    domain_crash_synchronous();\n    return 0;\n\nwrite_ignore_64:\n    if ( dabt.size != DABT_DOUBLE_WORD ) goto bad_width;\n    return 1;\n\nwrite_ignore:\n    if ( dabt.size != DABT_WORD ) goto bad_width;\n    return 1;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -53,12 +53,14 @@\n         /* RO */\n         goto write_ignore;\n     default:\n-        printk(\"vGICR: write r%d offset %#08x\\n not found\", dabt.reg, gicr_reg);\n+        printk(XENLOG_G_ERR \"%pv: vGICR: write r%d offset %#08x\\n not found\",\n+               v, dabt.reg, gicr_reg);\n         return 0;\n     }\n bad_width:\n-    printk(\"vGICR: bad write width %d r%d=%\"PRIregister\" offset %#08x\\n\",\n-           dabt.size, dabt.reg, *r, gicr_reg);\n+    printk(XENLOG_G_ERR\n+          \"%pv: vGICR: bad write width %d r%d=%\"PRIregister\" offset %#08x\\n\",\n+          v, dabt.size, dabt.reg, *r, gicr_reg);\n     domain_crash_synchronous();\n     return 0;\n ",
        "diff_line_info": {
            "deleted_lines": [
                "        printk(\"vGICR: write r%d offset %#08x\\n not found\", dabt.reg, gicr_reg);",
                "    printk(\"vGICR: bad write width %d r%d=%\"PRIregister\" offset %#08x\\n\",",
                "           dabt.size, dabt.reg, *r, gicr_reg);"
            ],
            "added_lines": [
                "        printk(XENLOG_G_ERR \"%pv: vGICR: write r%d offset %#08x\\n not found\",",
                "               v, dabt.reg, gicr_reg);",
                "    printk(XENLOG_G_ERR",
                "          \"%pv: vGICR: bad write width %d r%d=%\"PRIregister\" offset %#08x\\n\",",
                "          v, dabt.size, dabt.reg, *r, gicr_reg);"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1563",
        "func_name": "xen-project/xen/__vgic_v3_distr_common_mmio_read",
        "description": "The ARM GIC distributor virtualization in Xen 4.4.x and 4.5.x allows local guests to cause a denial of service by causing a large number messages to be logged.",
        "git_url": "https://github.com/xen-project/xen/commit/c96222cc6dbb285a4de8f25e3b8e284e212ef964",
        "commit_title": "xen/arm: vgic-v3: message in the emulation code should be rate-limited",
        "commit_text": " printk by default is not rate-limited by default. Therefore a malicious guest may be able to flood the Xen console.  If we use gdprintk, unnecessary information will be printed such as the filename and the line. Instead use XENLOG_G_{ERR,DEBUG} combine with %pv.  Also remove the vGICv3 prefix which is not neccessary and update some message which were wrong.  This is XSA-118. ",
        "func_before": "static int __vgic_v3_distr_common_mmio_read(struct vcpu *v, mmio_info_t *info,\n                                            uint32_t reg)\n{\n    struct hsr_dabt dabt = info->dabt;\n    struct cpu_user_regs *regs = guest_cpu_user_regs();\n    register_t *r = select_user_reg(regs, dabt.reg);\n    struct vgic_irq_rank *rank;\n    unsigned long flags;\n\n    switch ( reg )\n    {\n    case GICD_IGROUPR ... GICD_IGROUPRN:\n        /* We do not implement security extensions for guests, read zero */\n        goto read_as_zero;\n    case GICD_ISENABLER ... GICD_ISENABLERN:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 1, reg - GICD_ISENABLER, DABT_WORD);\n        if ( rank == NULL ) goto read_as_zero;\n        vgic_lock_rank(v, rank, flags);\n        *r = rank->ienable;\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n    case GICD_ICENABLER ... GICD_ICENABLERN:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 1, reg - GICD_ICENABLER, DABT_WORD);\n        if ( rank == NULL ) goto read_as_zero;\n        vgic_lock_rank(v, rank, flags);\n        *r = rank->ienable;\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n    case GICD_ISPENDR ... GICD_ISPENDRN:\n        if ( dabt.size != DABT_BYTE && dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 1, reg - GICD_ISPENDR, DABT_WORD);\n        if ( rank == NULL ) goto read_as_zero;\n        vgic_lock_rank(v, rank, flags);\n        *r = vgic_byte_read(rank->ipend, dabt.sign, reg);\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n    case GICD_ICPENDR ... GICD_ICPENDRN:\n        if ( dabt.size != DABT_BYTE && dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 1, reg - GICD_ICPENDR, DABT_WORD);\n        if ( rank == NULL ) goto read_as_zero;\n        vgic_lock_rank(v, rank, flags);\n        *r = vgic_byte_read(rank->ipend, dabt.sign, reg);\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n    case GICD_ISACTIVER ... GICD_ISACTIVERN:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 1, reg - GICD_ISACTIVER, DABT_WORD);\n        if ( rank == NULL ) goto read_as_zero;\n        vgic_lock_rank(v, rank, flags);\n        *r = rank->iactive;\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n    case GICD_ICACTIVER ... GICD_ICACTIVERN:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 1, reg - GICD_ICACTIVER, DABT_WORD);\n        if ( rank == NULL ) goto read_as_zero;\n        vgic_lock_rank(v, rank, flags);\n        *r = rank->iactive;\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n    case GICD_IPRIORITYR ... GICD_IPRIORITYRN:\n        if ( dabt.size != DABT_BYTE && dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 8, reg - GICD_IPRIORITYR, DABT_WORD);\n        if ( rank == NULL ) goto read_as_zero;\n\n        vgic_lock_rank(v, rank, flags);\n        *r = rank->ipriority[REG_RANK_INDEX(8, reg - GICD_IPRIORITYR,\n                                            DABT_WORD)];\n        if ( dabt.size == DABT_BYTE )\n            *r = vgic_byte_read(*r, dabt.sign, reg);\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n    case GICD_ICFGR ... GICD_ICFGRN:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 2, reg - GICD_ICFGR, DABT_WORD);\n        if ( rank == NULL ) goto read_as_zero;\n        vgic_lock_rank(v, rank, flags);\n        *r = rank->icfg[REG_RANK_INDEX(2, reg - GICD_ICFGR, DABT_WORD)];\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n    default:\n        printk(\"vGICv3: vGICD/vGICR: unhandled read r%d offset %#08x\\n\",\n               dabt.reg, reg);\n        return 0;\n    }\n\nbad_width:\n    dprintk(XENLOG_ERR,\n            \"vGICv3: vGICD/vGICR: bad read width %d r%d offset %#08x\\n\",\n            dabt.size, dabt.reg, reg);\n    domain_crash_synchronous();\n    return 0;\n\nread_as_zero:\n    if ( dabt.size != DABT_WORD ) goto bad_width;\n    *r = 0;\n    return 1;\n}",
        "func": "static int __vgic_v3_distr_common_mmio_read(struct vcpu *v, mmio_info_t *info,\n                                            uint32_t reg)\n{\n    struct hsr_dabt dabt = info->dabt;\n    struct cpu_user_regs *regs = guest_cpu_user_regs();\n    register_t *r = select_user_reg(regs, dabt.reg);\n    struct vgic_irq_rank *rank;\n    unsigned long flags;\n\n    switch ( reg )\n    {\n    case GICD_IGROUPR ... GICD_IGROUPRN:\n        /* We do not implement security extensions for guests, read zero */\n        goto read_as_zero;\n    case GICD_ISENABLER ... GICD_ISENABLERN:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 1, reg - GICD_ISENABLER, DABT_WORD);\n        if ( rank == NULL ) goto read_as_zero;\n        vgic_lock_rank(v, rank, flags);\n        *r = rank->ienable;\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n    case GICD_ICENABLER ... GICD_ICENABLERN:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 1, reg - GICD_ICENABLER, DABT_WORD);\n        if ( rank == NULL ) goto read_as_zero;\n        vgic_lock_rank(v, rank, flags);\n        *r = rank->ienable;\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n    case GICD_ISPENDR ... GICD_ISPENDRN:\n        if ( dabt.size != DABT_BYTE && dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 1, reg - GICD_ISPENDR, DABT_WORD);\n        if ( rank == NULL ) goto read_as_zero;\n        vgic_lock_rank(v, rank, flags);\n        *r = vgic_byte_read(rank->ipend, dabt.sign, reg);\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n    case GICD_ICPENDR ... GICD_ICPENDRN:\n        if ( dabt.size != DABT_BYTE && dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 1, reg - GICD_ICPENDR, DABT_WORD);\n        if ( rank == NULL ) goto read_as_zero;\n        vgic_lock_rank(v, rank, flags);\n        *r = vgic_byte_read(rank->ipend, dabt.sign, reg);\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n    case GICD_ISACTIVER ... GICD_ISACTIVERN:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 1, reg - GICD_ISACTIVER, DABT_WORD);\n        if ( rank == NULL ) goto read_as_zero;\n        vgic_lock_rank(v, rank, flags);\n        *r = rank->iactive;\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n    case GICD_ICACTIVER ... GICD_ICACTIVERN:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 1, reg - GICD_ICACTIVER, DABT_WORD);\n        if ( rank == NULL ) goto read_as_zero;\n        vgic_lock_rank(v, rank, flags);\n        *r = rank->iactive;\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n    case GICD_IPRIORITYR ... GICD_IPRIORITYRN:\n        if ( dabt.size != DABT_BYTE && dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 8, reg - GICD_IPRIORITYR, DABT_WORD);\n        if ( rank == NULL ) goto read_as_zero;\n\n        vgic_lock_rank(v, rank, flags);\n        *r = rank->ipriority[REG_RANK_INDEX(8, reg - GICD_IPRIORITYR,\n                                            DABT_WORD)];\n        if ( dabt.size == DABT_BYTE )\n            *r = vgic_byte_read(*r, dabt.sign, reg);\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n    case GICD_ICFGR ... GICD_ICFGRN:\n        if ( dabt.size != DABT_WORD ) goto bad_width;\n        rank = vgic_rank_offset(v, 2, reg - GICD_ICFGR, DABT_WORD);\n        if ( rank == NULL ) goto read_as_zero;\n        vgic_lock_rank(v, rank, flags);\n        *r = rank->icfg[REG_RANK_INDEX(2, reg - GICD_ICFGR, DABT_WORD)];\n        vgic_unlock_rank(v, rank, flags);\n        return 1;\n    default:\n        printk(XENLOG_G_ERR\n               \"%pv: vGICD/vGICR: unhandled read r%d offset %#08x\\n\",\n               v, dabt.reg, reg);\n        return 0;\n    }\n\nbad_width:\n    printk(XENLOG_G_ERR\n           \"%pv: vGICD/vGICR: bad read width %d r%d offset %#08x\\n\",\n           v, dabt.size, dabt.reg, reg);\n    domain_crash_synchronous();\n    return 0;\n\nread_as_zero:\n    if ( dabt.size != DABT_WORD ) goto bad_width;\n    *r = 0;\n    return 1;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -81,15 +81,16 @@\n         vgic_unlock_rank(v, rank, flags);\n         return 1;\n     default:\n-        printk(\"vGICv3: vGICD/vGICR: unhandled read r%d offset %#08x\\n\",\n-               dabt.reg, reg);\n+        printk(XENLOG_G_ERR\n+               \"%pv: vGICD/vGICR: unhandled read r%d offset %#08x\\n\",\n+               v, dabt.reg, reg);\n         return 0;\n     }\n \n bad_width:\n-    dprintk(XENLOG_ERR,\n-            \"vGICv3: vGICD/vGICR: bad read width %d r%d offset %#08x\\n\",\n-            dabt.size, dabt.reg, reg);\n+    printk(XENLOG_G_ERR\n+           \"%pv: vGICD/vGICR: bad read width %d r%d offset %#08x\\n\",\n+           v, dabt.size, dabt.reg, reg);\n     domain_crash_synchronous();\n     return 0;\n ",
        "diff_line_info": {
            "deleted_lines": [
                "        printk(\"vGICv3: vGICD/vGICR: unhandled read r%d offset %#08x\\n\",",
                "               dabt.reg, reg);",
                "    dprintk(XENLOG_ERR,",
                "            \"vGICv3: vGICD/vGICR: bad read width %d r%d offset %#08x\\n\",",
                "            dabt.size, dabt.reg, reg);"
            ],
            "added_lines": [
                "        printk(XENLOG_G_ERR",
                "               \"%pv: vGICD/vGICR: unhandled read r%d offset %#08x\\n\",",
                "               v, dabt.reg, reg);",
                "    printk(XENLOG_G_ERR",
                "           \"%pv: vGICD/vGICR: bad read width %d r%d offset %#08x\\n\",",
                "           v, dabt.size, dabt.reg, reg);"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1227",
        "func_name": "chromium/DragImage::create",
        "description": "The DragImage::create function in platform/DragImage.cpp in Blink, as used in Google Chrome before 41.0.2272.76, does not initialize memory for image drawing, which allows remote attackers to have an unspecified impact by triggering a failed image decoding, as demonstrated by an image for which the default orientation cannot be used.",
        "git_url": "https://github.com/chromium/chromium/commit/80636b85932f429456f5a6e92312facea12a846b",
        "commit_title": "Clear SkBitmap used to draw DragImage.",
        "commit_text": " SkBitmap::allocN32Pixels does not initialize the pixel memory, and we may not draw to all of it (if, for example, an image decode fails, nothing will be drawn).   ",
        "func_before": "PassOwnPtr<DragImage> DragImage::create(Image* image, RespectImageOrientationEnum shouldRespectImageOrientation, float deviceScaleFactor)\n{\n    if (!image)\n        return nullptr;\n\n    RefPtr<NativeImageSkia> bitmap = image->nativeImageForCurrentFrame();\n    if (!bitmap)\n        return nullptr;\n\n    if (image->isBitmapImage()) {\n        ImageOrientation orientation = DefaultImageOrientation;\n        BitmapImage* bitmapImage = toBitmapImage(image);\n        IntSize sizeRespectingOrientation = bitmapImage->sizeRespectingOrientation();\n\n        if (shouldRespectImageOrientation == RespectImageOrientation)\n            orientation = bitmapImage->currentFrameOrientation();\n\n        if (orientation != DefaultImageOrientation) {\n            FloatRect destRect(FloatPoint(), sizeRespectingOrientation);\n            if (orientation.usesWidthAsHeight())\n                destRect = destRect.transposedRect();\n\n            SkBitmap skBitmap;\n            if (!skBitmap.tryAllocN32Pixels(sizeRespectingOrientation.width(), sizeRespectingOrientation.height()))\n                return nullptr;\n\n            SkCanvas canvas(skBitmap);\n            canvas.concat(affineTransformToSkMatrix(orientation.transformFromDefault(sizeRespectingOrientation)));\n            canvas.drawBitmapRect(bitmap->bitmap(), 0, destRect);\n\n            return adoptPtr(new DragImage(skBitmap, deviceScaleFactor));\n        }\n    }\n\n    SkBitmap skBitmap;\n    if (!bitmap->bitmap().copyTo(&skBitmap, kN32_SkColorType))\n        return nullptr;\n    return adoptPtr(new DragImage(skBitmap, deviceScaleFactor));\n}",
        "func": "PassOwnPtr<DragImage> DragImage::create(Image* image, RespectImageOrientationEnum shouldRespectImageOrientation, float deviceScaleFactor)\n{\n    if (!image)\n        return nullptr;\n\n    RefPtr<NativeImageSkia> bitmap = image->nativeImageForCurrentFrame();\n    if (!bitmap)\n        return nullptr;\n\n    if (image->isBitmapImage()) {\n        ImageOrientation orientation = DefaultImageOrientation;\n        BitmapImage* bitmapImage = toBitmapImage(image);\n        IntSize sizeRespectingOrientation = bitmapImage->sizeRespectingOrientation();\n\n        if (shouldRespectImageOrientation == RespectImageOrientation)\n            orientation = bitmapImage->currentFrameOrientation();\n\n        if (orientation != DefaultImageOrientation) {\n            FloatRect destRect(FloatPoint(), sizeRespectingOrientation);\n            if (orientation.usesWidthAsHeight())\n                destRect = destRect.transposedRect();\n\n            SkBitmap skBitmap;\n            if (!skBitmap.tryAllocN32Pixels(sizeRespectingOrientation.width(), sizeRespectingOrientation.height()))\n                return nullptr;\n\n            skBitmap.eraseColor(SK_ColorTRANSPARENT);\n            SkCanvas canvas(skBitmap);\n            canvas.concat(affineTransformToSkMatrix(orientation.transformFromDefault(sizeRespectingOrientation)));\n            canvas.drawBitmapRect(bitmap->bitmap(), 0, destRect);\n\n            return adoptPtr(new DragImage(skBitmap, deviceScaleFactor));\n        }\n    }\n\n    SkBitmap skBitmap;\n    if (!bitmap->bitmap().copyTo(&skBitmap, kN32_SkColorType))\n        return nullptr;\n    return adoptPtr(new DragImage(skBitmap, deviceScaleFactor));\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -24,6 +24,7 @@\n             if (!skBitmap.tryAllocN32Pixels(sizeRespectingOrientation.width(), sizeRespectingOrientation.height()))\n                 return nullptr;\n \n+            skBitmap.eraseColor(SK_ColorTRANSPARENT);\n             SkCanvas canvas(skBitmap);\n             canvas.concat(affineTransformToSkMatrix(orientation.transformFromDefault(sizeRespectingOrientation)));\n             canvas.drawBitmapRect(bitmap->bitmap(), 0, destRect);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "            skBitmap.eraseColor(SK_ColorTRANSPARENT);"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1228",
        "func_name": "chromium/InlineTextBoxPainter::paint",
        "description": "The RenderCounter::updateCounter function in core/rendering/RenderCounter.cpp in Blink, as used in Google Chrome before 41.0.2272.76, does not force a relayout operation and consequently does not initialize memory for a data structure, which allows remote attackers to cause a denial of service (application crash) or possibly have unspecified other impact via a crafted Cascading Style Sheets (CSS) token sequence.",
        "git_url": "https://github.com/chromium/chromium/commit/3527a453038dde455b701c3e11eb0dc5d5fbe297",
        "commit_title": "RenderCounter::updateCounter should trigger a relayout.",
        "commit_text": " Currently, the method calls setTextInternal() - which updates the text but doesn't mark the node for layout and pref widths recalc. This can leave stale text boxes behind.  Instead, we should use setText() - which triggers the needed invalidations.   ",
        "func_before": "void InlineTextBoxPainter::paint(const PaintInfo& paintInfo, const LayoutPoint& paintOffset)\n{\n    if (m_inlineTextBox.isLineBreak() || !paintInfo.shouldPaintWithinRoot(&m_inlineTextBox.renderer()) || m_inlineTextBox.renderer().style()->visibility() != VISIBLE\n        || m_inlineTextBox.truncation() == cFullTruncation || paintInfo.phase == PaintPhaseOutline || !m_inlineTextBox.len())\n        return;\n\n    ASSERT(paintInfo.phase != PaintPhaseSelfOutline && paintInfo.phase != PaintPhaseChildOutlines);\n\n    LayoutRect logicalVisualOverflow = m_inlineTextBox.logicalOverflowRect();\n    LayoutUnit logicalStart = logicalVisualOverflow.x() + (m_inlineTextBox.isHorizontal() ? paintOffset.x() : paintOffset.y());\n    LayoutUnit logicalExtent = logicalVisualOverflow.width();\n\n    LayoutUnit paintEnd = m_inlineTextBox.isHorizontal() ? paintInfo.rect.maxX() : paintInfo.rect.maxY();\n    LayoutUnit paintStart = m_inlineTextBox.isHorizontal() ? paintInfo.rect.x() : paintInfo.rect.y();\n\n    // We round the y-axis to ensure consistent line heights.\n    LayoutPoint adjustedPaintOffset = LayoutPoint(paintOffset.x(), paintOffset.y().round());\n\n    if (logicalStart >= paintEnd || logicalStart + logicalExtent <= paintStart)\n        return;\n\n    bool isPrinting = m_inlineTextBox.renderer().document().printing();\n\n    // Determine whether or not we're selected.\n    bool haveSelection = !isPrinting && paintInfo.phase != PaintPhaseTextClip && m_inlineTextBox.selectionState() != RenderObject::SelectionNone;\n    if (!haveSelection && paintInfo.phase == PaintPhaseSelection) {\n        // When only painting the selection, don't bother to paint if there is none.\n        return;\n    }\n\n    // The text clip phase already has a DrawingRecorder. Text clips are initiated only in BoxPainter::paintLayerExtended, which is already\n    // within a DrawingRecorder.\n    OwnPtr<RenderDrawingRecorder> drawingRecorder;\n    if (RuntimeEnabledFeatures::slimmingPaintEnabled() && paintInfo.phase != PaintPhaseTextClip) {\n        drawingRecorder = adoptPtr(new RenderDrawingRecorder(paintInfo.context, m_inlineTextBox.renderer(), paintInfo.phase, pixelSnappedIntRect(adjustedPaintOffset, logicalVisualOverflow.size())));\n        if (drawingRecorder->canUseCachedDrawing())\n            return;\n    }\n\n    if (m_inlineTextBox.truncation() != cNoTruncation) {\n        if (m_inlineTextBox.renderer().containingBlock()->style()->isLeftToRightDirection() != m_inlineTextBox.isLeftToRightDirection()) {\n            // Make the visible fragment of text hug the edge closest to the rest of the run by moving the origin\n            // at which we start drawing text.\n            // e.g. In the case of LTR text truncated in an RTL Context, the correct behavior is:\n            // |Hello|CBA| -> |...He|CBA|\n            // In order to draw the fragment \"He\" aligned to the right edge of it's box, we need to start drawing\n            // farther to the right.\n            // NOTE: WebKit's behavior differs from that of IE which appears to just overlay the ellipsis on top of the\n            // truncated string i.e.  |Hello|CBA| -> |...lo|CBA|\n            LayoutUnit widthOfVisibleText = m_inlineTextBox.renderer().width(m_inlineTextBox.start(), m_inlineTextBox.truncation(), m_inlineTextBox.textPos(), m_inlineTextBox.isLeftToRightDirection() ? LTR : RTL, m_inlineTextBox.isFirstLineStyle());\n            LayoutUnit widthOfHiddenText = m_inlineTextBox.logicalWidth() - widthOfVisibleText;\n            // FIXME: The hit testing logic also needs to take this translation into account.\n            LayoutSize truncationOffset(m_inlineTextBox.isLeftToRightDirection() ? widthOfHiddenText : -widthOfHiddenText, 0);\n            adjustedPaintOffset.move(m_inlineTextBox.isHorizontal() ? truncationOffset : truncationOffset.transposedSize());\n        }\n    }\n\n    GraphicsContext* context = paintInfo.context;\n    RenderStyle* styleToUse = m_inlineTextBox.renderer().style(m_inlineTextBox.isFirstLineStyle());\n\n    adjustedPaintOffset.move(0, styleToUse->isHorizontalWritingMode() ? LayoutUnit() : -m_inlineTextBox.logicalHeight().toLayoutUnit());\n\n    FloatPoint boxOrigin = m_inlineTextBox.locationIncludingFlipping();\n    boxOrigin.move(adjustedPaintOffset.x().toFloat(), adjustedPaintOffset.y().toFloat());\n    FloatRect boxRect(boxOrigin, FloatSize(m_inlineTextBox.logicalWidth(), m_inlineTextBox.logicalHeight()));\n\n    RenderCombineText* combinedText = styleToUse->hasTextCombine() && m_inlineTextBox.renderer().isCombineText() && toRenderCombineText(m_inlineTextBox.renderer()).isCombined() ? &toRenderCombineText(m_inlineTextBox.renderer()) : 0;\n\n    bool shouldRotate = !m_inlineTextBox.isHorizontal() && !combinedText;\n    if (shouldRotate)\n        context->concatCTM(TextPainter::rotation(boxRect, TextPainter::Clockwise));\n\n    // Determine whether or not we have composition underlines to draw.\n    bool containsComposition = m_inlineTextBox.renderer().node() && m_inlineTextBox.renderer().frame()->inputMethodController().compositionNode() == m_inlineTextBox.renderer().node();\n    bool useCustomUnderlines = containsComposition && m_inlineTextBox.renderer().frame()->inputMethodController().compositionUsesCustomUnderlines();\n\n    // Determine text colors.\n    TextPainter::Style textStyle = TextPainter::textPaintingStyle(m_inlineTextBox.renderer(), styleToUse, paintInfo.forceBlackText(), isPrinting);\n    TextPainter::Style selectionStyle = TextPainter::selectionPaintingStyle(m_inlineTextBox.renderer(), haveSelection, paintInfo.forceBlackText(), isPrinting, textStyle);\n    bool paintSelectedTextOnly = (paintInfo.phase == PaintPhaseSelection);\n    bool paintSelectedTextSeparately = !paintSelectedTextOnly && textStyle != selectionStyle;\n\n    // Set our font.\n    const Font& font = styleToUse->font();\n\n    FloatPoint textOrigin = FloatPoint(boxOrigin.x(), boxOrigin.y() + font.fontMetrics().ascent());\n    if (combinedText)\n        combinedText->adjustTextOrigin(textOrigin, boxRect);\n\n    // 1. Paint backgrounds behind text if needed. Examples of such backgrounds include selection\n    // and composition highlights.\n    if (paintInfo.phase != PaintPhaseSelection && paintInfo.phase != PaintPhaseTextClip && !isPrinting) {\n        if (containsComposition) {\n            paintCompositionBackgrounds(context, boxOrigin, styleToUse, font, useCustomUnderlines);\n        }\n\n        paintDocumentMarkers(context, boxOrigin, styleToUse, font, true);\n\n        if (haveSelection && !useCustomUnderlines)\n            paintSelection(context, boxOrigin, styleToUse, font, selectionStyle.fillColor);\n    }\n\n    // 2. Now paint the foreground, including text and decorations like underline/overline (in quirks mode only).\n    int length = m_inlineTextBox.len();\n    int maximumLength;\n    StringView string;\n    if (!combinedText) {\n        string = m_inlineTextBox.renderer().text().createView();\n        if (static_cast<unsigned>(length) != string.length() || m_inlineTextBox.start())\n            string.narrow(m_inlineTextBox.start(), length);\n        maximumLength = m_inlineTextBox.renderer().textLength() - m_inlineTextBox.start();\n    } else {\n        combinedText->getStringToRender(m_inlineTextBox.start(), string, length);\n        maximumLength = length;\n    }\n\n    StringBuilder charactersWithHyphen;\n    TextRun textRun = m_inlineTextBox.constructTextRun(styleToUse, font, string, maximumLength, m_inlineTextBox.hasHyphen() ? &charactersWithHyphen : 0);\n    if (m_inlineTextBox.hasHyphen())\n        length = textRun.length();\n\n    int selectionStart = 0;\n    int selectionEnd = 0;\n    if (paintSelectedTextOnly || paintSelectedTextSeparately)\n        m_inlineTextBox.selectionStartEnd(selectionStart, selectionEnd);\n\n    bool respectHyphen = selectionEnd == static_cast<int>(m_inlineTextBox.len()) && m_inlineTextBox.hasHyphen();\n    if (respectHyphen)\n        selectionEnd = textRun.length();\n\n    if (m_inlineTextBox.truncation() != cNoTruncation) {\n        selectionStart = std::min<int>(selectionStart, m_inlineTextBox.truncation());\n        selectionEnd = std::min<int>(selectionEnd, m_inlineTextBox.truncation());\n        length = m_inlineTextBox.truncation();\n    }\n\n    TextPainter textPainter(context, font, textRun, textOrigin, boxRect, m_inlineTextBox.isHorizontal());\n    TextEmphasisPosition emphasisMarkPosition;\n    bool hasTextEmphasis = m_inlineTextBox.getEmphasisMarkPosition(styleToUse, emphasisMarkPosition);\n    if (hasTextEmphasis)\n        textPainter.setEmphasisMark(styleToUse->textEmphasisMarkString(), emphasisMarkPosition);\n    if (combinedText)\n        textPainter.setCombinedText(combinedText);\n\n    if (!paintSelectedTextOnly) {\n        // FIXME: Truncate right-to-left text correctly.\n        int startOffset = 0;\n        int endOffset = length;\n        if (paintSelectedTextSeparately && selectionStart < selectionEnd) {\n            startOffset = selectionEnd;\n            endOffset = selectionStart;\n        }\n\n        // FIXME: This cache should probably ultimately be held somewhere else.\n        // A hashmap is convenient to avoid a memory hit when the\n        // RuntimeEnabledFeature is off.\n        bool textBlobIsCacheable = RuntimeEnabledFeatures::textBlobEnabled() && startOffset == 0 && endOffset == length;\n        TextBlobPtr* cachedTextBlob = 0;\n        if (textBlobIsCacheable)\n            cachedTextBlob = addToTextBlobCache(m_inlineTextBox);\n        textPainter.paint(startOffset, endOffset, length, textStyle, cachedTextBlob);\n    }\n\n    if ((paintSelectedTextOnly || paintSelectedTextSeparately) && selectionStart < selectionEnd) {\n        // paint only the text that is selected\n        bool textBlobIsCacheable = RuntimeEnabledFeatures::textBlobEnabled() && selectionStart == 0 && selectionEnd == length;\n        TextBlobPtr* cachedTextBlob = 0;\n        if (textBlobIsCacheable)\n            cachedTextBlob = addToTextBlobCache(m_inlineTextBox);\n        textPainter.paint(selectionStart, selectionEnd, length, selectionStyle, cachedTextBlob);\n    }\n\n    // Paint decorations\n    TextDecoration textDecorations = styleToUse->textDecorationsInEffect();\n    if (textDecorations != TextDecorationNone && !paintSelectedTextOnly) {\n        GraphicsContextStateSaver stateSaver(*context, false);\n        TextPainter::updateGraphicsContext(context, textStyle, m_inlineTextBox.isHorizontal(), stateSaver);\n        if (combinedText)\n            context->concatCTM(TextPainter::rotation(boxRect, TextPainter::Clockwise));\n        paintDecoration(context, boxOrigin, textDecorations);\n        if (combinedText)\n            context->concatCTM(TextPainter::rotation(boxRect, TextPainter::Counterclockwise));\n    }\n\n    if (paintInfo.phase == PaintPhaseForeground) {\n        paintDocumentMarkers(context, boxOrigin, styleToUse, font, false);\n\n        // Paint custom underlines for compositions.\n        if (useCustomUnderlines) {\n            const Vector<CompositionUnderline>& underlines = m_inlineTextBox.renderer().frame()->inputMethodController().customCompositionUnderlines();\n            CompositionUnderlineRangeFilter filter(underlines, m_inlineTextBox.start(), m_inlineTextBox.end());\n            for (CompositionUnderlineRangeFilter::ConstIterator it = filter.begin(); it != filter.end(); ++it) {\n                if (it->color == Color::transparent)\n                    continue;\n                paintCompositionUnderline(context, boxOrigin, *it);\n            }\n        }\n    }\n\n    if (shouldRotate)\n        context->concatCTM(TextPainter::rotation(boxRect, TextPainter::Counterclockwise));\n}",
        "func": "void InlineTextBoxPainter::paint(const PaintInfo& paintInfo, const LayoutPoint& paintOffset)\n{\n    if (m_inlineTextBox.isLineBreak() || !paintInfo.shouldPaintWithinRoot(&m_inlineTextBox.renderer()) || m_inlineTextBox.renderer().style()->visibility() != VISIBLE\n        || m_inlineTextBox.truncation() == cFullTruncation || paintInfo.phase == PaintPhaseOutline || !m_inlineTextBox.len())\n        return;\n\n    ASSERT(paintInfo.phase != PaintPhaseSelfOutline && paintInfo.phase != PaintPhaseChildOutlines);\n\n    LayoutRect logicalVisualOverflow = m_inlineTextBox.logicalOverflowRect();\n    LayoutUnit logicalStart = logicalVisualOverflow.x() + (m_inlineTextBox.isHorizontal() ? paintOffset.x() : paintOffset.y());\n    LayoutUnit logicalExtent = logicalVisualOverflow.width();\n\n    LayoutUnit paintEnd = m_inlineTextBox.isHorizontal() ? paintInfo.rect.maxX() : paintInfo.rect.maxY();\n    LayoutUnit paintStart = m_inlineTextBox.isHorizontal() ? paintInfo.rect.x() : paintInfo.rect.y();\n\n    // We round the y-axis to ensure consistent line heights.\n    LayoutPoint adjustedPaintOffset = LayoutPoint(paintOffset.x(), paintOffset.y().round());\n\n    if (logicalStart >= paintEnd || logicalStart + logicalExtent <= paintStart)\n        return;\n\n    bool isPrinting = m_inlineTextBox.renderer().document().printing();\n\n    // Determine whether or not we're selected.\n    bool haveSelection = !isPrinting && paintInfo.phase != PaintPhaseTextClip && m_inlineTextBox.selectionState() != RenderObject::SelectionNone;\n    if (!haveSelection && paintInfo.phase == PaintPhaseSelection) {\n        // When only painting the selection, don't bother to paint if there is none.\n        return;\n    }\n\n    // The text clip phase already has a DrawingRecorder. Text clips are initiated only in BoxPainter::paintLayerExtended, which is already\n    // within a DrawingRecorder.\n    OwnPtr<RenderDrawingRecorder> drawingRecorder;\n    if (RuntimeEnabledFeatures::slimmingPaintEnabled() && paintInfo.phase != PaintPhaseTextClip) {\n        drawingRecorder = adoptPtr(new RenderDrawingRecorder(paintInfo.context, m_inlineTextBox.renderer(), paintInfo.phase, pixelSnappedIntRect(adjustedPaintOffset, logicalVisualOverflow.size())));\n        if (drawingRecorder->canUseCachedDrawing())\n            return;\n    }\n\n    if (m_inlineTextBox.truncation() != cNoTruncation) {\n        if (m_inlineTextBox.renderer().containingBlock()->style()->isLeftToRightDirection() != m_inlineTextBox.isLeftToRightDirection()) {\n            // Make the visible fragment of text hug the edge closest to the rest of the run by moving the origin\n            // at which we start drawing text.\n            // e.g. In the case of LTR text truncated in an RTL Context, the correct behavior is:\n            // |Hello|CBA| -> |...He|CBA|\n            // In order to draw the fragment \"He\" aligned to the right edge of it's box, we need to start drawing\n            // farther to the right.\n            // NOTE: WebKit's behavior differs from that of IE which appears to just overlay the ellipsis on top of the\n            // truncated string i.e.  |Hello|CBA| -> |...lo|CBA|\n            LayoutUnit widthOfVisibleText = m_inlineTextBox.renderer().width(m_inlineTextBox.start(), m_inlineTextBox.truncation(), m_inlineTextBox.textPos(), m_inlineTextBox.isLeftToRightDirection() ? LTR : RTL, m_inlineTextBox.isFirstLineStyle());\n            LayoutUnit widthOfHiddenText = m_inlineTextBox.logicalWidth() - widthOfVisibleText;\n            // FIXME: The hit testing logic also needs to take this translation into account.\n            LayoutSize truncationOffset(m_inlineTextBox.isLeftToRightDirection() ? widthOfHiddenText : -widthOfHiddenText, 0);\n            adjustedPaintOffset.move(m_inlineTextBox.isHorizontal() ? truncationOffset : truncationOffset.transposedSize());\n        }\n    }\n\n    GraphicsContext* context = paintInfo.context;\n    RenderStyle* styleToUse = m_inlineTextBox.renderer().style(m_inlineTextBox.isFirstLineStyle());\n\n    adjustedPaintOffset.move(0, styleToUse->isHorizontalWritingMode() ? LayoutUnit() : -m_inlineTextBox.logicalHeight().toLayoutUnit());\n\n    FloatPoint boxOrigin = m_inlineTextBox.locationIncludingFlipping();\n    boxOrigin.move(adjustedPaintOffset.x().toFloat(), adjustedPaintOffset.y().toFloat());\n    FloatRect boxRect(boxOrigin, FloatSize(m_inlineTextBox.logicalWidth(), m_inlineTextBox.logicalHeight()));\n\n    RenderCombineText* combinedText = styleToUse->hasTextCombine() && m_inlineTextBox.renderer().isCombineText() && toRenderCombineText(m_inlineTextBox.renderer()).isCombined() ? &toRenderCombineText(m_inlineTextBox.renderer()) : 0;\n\n    bool shouldRotate = !m_inlineTextBox.isHorizontal() && !combinedText;\n    if (shouldRotate)\n        context->concatCTM(TextPainter::rotation(boxRect, TextPainter::Clockwise));\n\n    // Determine whether or not we have composition underlines to draw.\n    bool containsComposition = m_inlineTextBox.renderer().node() && m_inlineTextBox.renderer().frame()->inputMethodController().compositionNode() == m_inlineTextBox.renderer().node();\n    bool useCustomUnderlines = containsComposition && m_inlineTextBox.renderer().frame()->inputMethodController().compositionUsesCustomUnderlines();\n\n    // Determine text colors.\n    TextPainter::Style textStyle = TextPainter::textPaintingStyle(m_inlineTextBox.renderer(), styleToUse, paintInfo.forceBlackText(), isPrinting);\n    TextPainter::Style selectionStyle = TextPainter::selectionPaintingStyle(m_inlineTextBox.renderer(), haveSelection, paintInfo.forceBlackText(), isPrinting, textStyle);\n    bool paintSelectedTextOnly = (paintInfo.phase == PaintPhaseSelection);\n    bool paintSelectedTextSeparately = !paintSelectedTextOnly && textStyle != selectionStyle;\n\n    // Set our font.\n    const Font& font = styleToUse->font();\n\n    FloatPoint textOrigin = FloatPoint(boxOrigin.x(), boxOrigin.y() + font.fontMetrics().ascent());\n    if (combinedText)\n        combinedText->adjustTextOrigin(textOrigin, boxRect);\n\n    // 1. Paint backgrounds behind text if needed. Examples of such backgrounds include selection\n    // and composition highlights.\n    if (paintInfo.phase != PaintPhaseSelection && paintInfo.phase != PaintPhaseTextClip && !isPrinting) {\n        if (containsComposition) {\n            paintCompositionBackgrounds(context, boxOrigin, styleToUse, font, useCustomUnderlines);\n        }\n\n        paintDocumentMarkers(context, boxOrigin, styleToUse, font, true);\n\n        if (haveSelection && !useCustomUnderlines)\n            paintSelection(context, boxOrigin, styleToUse, font, selectionStyle.fillColor);\n    }\n\n    // 2. Now paint the foreground, including text and decorations like underline/overline (in quirks mode only).\n    int length = m_inlineTextBox.len();\n    int maximumLength;\n    StringView string;\n    if (!combinedText) {\n        string = m_inlineTextBox.renderer().text().createView();\n        ASSERT(m_inlineTextBox.start() + length <= string.length());\n        if (static_cast<unsigned>(length) != string.length() || m_inlineTextBox.start())\n            string.narrow(m_inlineTextBox.start(), length);\n        maximumLength = m_inlineTextBox.renderer().textLength() - m_inlineTextBox.start();\n    } else {\n        combinedText->getStringToRender(m_inlineTextBox.start(), string, length);\n        maximumLength = length;\n    }\n\n    StringBuilder charactersWithHyphen;\n    TextRun textRun = m_inlineTextBox.constructTextRun(styleToUse, font, string, maximumLength, m_inlineTextBox.hasHyphen() ? &charactersWithHyphen : 0);\n    if (m_inlineTextBox.hasHyphen())\n        length = textRun.length();\n\n    int selectionStart = 0;\n    int selectionEnd = 0;\n    if (paintSelectedTextOnly || paintSelectedTextSeparately)\n        m_inlineTextBox.selectionStartEnd(selectionStart, selectionEnd);\n\n    bool respectHyphen = selectionEnd == static_cast<int>(m_inlineTextBox.len()) && m_inlineTextBox.hasHyphen();\n    if (respectHyphen)\n        selectionEnd = textRun.length();\n\n    if (m_inlineTextBox.truncation() != cNoTruncation) {\n        selectionStart = std::min<int>(selectionStart, m_inlineTextBox.truncation());\n        selectionEnd = std::min<int>(selectionEnd, m_inlineTextBox.truncation());\n        length = m_inlineTextBox.truncation();\n    }\n\n    TextPainter textPainter(context, font, textRun, textOrigin, boxRect, m_inlineTextBox.isHorizontal());\n    TextEmphasisPosition emphasisMarkPosition;\n    bool hasTextEmphasis = m_inlineTextBox.getEmphasisMarkPosition(styleToUse, emphasisMarkPosition);\n    if (hasTextEmphasis)\n        textPainter.setEmphasisMark(styleToUse->textEmphasisMarkString(), emphasisMarkPosition);\n    if (combinedText)\n        textPainter.setCombinedText(combinedText);\n\n    if (!paintSelectedTextOnly) {\n        // FIXME: Truncate right-to-left text correctly.\n        int startOffset = 0;\n        int endOffset = length;\n        if (paintSelectedTextSeparately && selectionStart < selectionEnd) {\n            startOffset = selectionEnd;\n            endOffset = selectionStart;\n        }\n\n        // FIXME: This cache should probably ultimately be held somewhere else.\n        // A hashmap is convenient to avoid a memory hit when the\n        // RuntimeEnabledFeature is off.\n        bool textBlobIsCacheable = RuntimeEnabledFeatures::textBlobEnabled() && startOffset == 0 && endOffset == length;\n        TextBlobPtr* cachedTextBlob = 0;\n        if (textBlobIsCacheable)\n            cachedTextBlob = addToTextBlobCache(m_inlineTextBox);\n        textPainter.paint(startOffset, endOffset, length, textStyle, cachedTextBlob);\n    }\n\n    if ((paintSelectedTextOnly || paintSelectedTextSeparately) && selectionStart < selectionEnd) {\n        // paint only the text that is selected\n        bool textBlobIsCacheable = RuntimeEnabledFeatures::textBlobEnabled() && selectionStart == 0 && selectionEnd == length;\n        TextBlobPtr* cachedTextBlob = 0;\n        if (textBlobIsCacheable)\n            cachedTextBlob = addToTextBlobCache(m_inlineTextBox);\n        textPainter.paint(selectionStart, selectionEnd, length, selectionStyle, cachedTextBlob);\n    }\n\n    // Paint decorations\n    TextDecoration textDecorations = styleToUse->textDecorationsInEffect();\n    if (textDecorations != TextDecorationNone && !paintSelectedTextOnly) {\n        GraphicsContextStateSaver stateSaver(*context, false);\n        TextPainter::updateGraphicsContext(context, textStyle, m_inlineTextBox.isHorizontal(), stateSaver);\n        if (combinedText)\n            context->concatCTM(TextPainter::rotation(boxRect, TextPainter::Clockwise));\n        paintDecoration(context, boxOrigin, textDecorations);\n        if (combinedText)\n            context->concatCTM(TextPainter::rotation(boxRect, TextPainter::Counterclockwise));\n    }\n\n    if (paintInfo.phase == PaintPhaseForeground) {\n        paintDocumentMarkers(context, boxOrigin, styleToUse, font, false);\n\n        // Paint custom underlines for compositions.\n        if (useCustomUnderlines) {\n            const Vector<CompositionUnderline>& underlines = m_inlineTextBox.renderer().frame()->inputMethodController().customCompositionUnderlines();\n            CompositionUnderlineRangeFilter filter(underlines, m_inlineTextBox.start(), m_inlineTextBox.end());\n            for (CompositionUnderlineRangeFilter::ConstIterator it = filter.begin(); it != filter.end(); ++it) {\n                if (it->color == Color::transparent)\n                    continue;\n                paintCompositionUnderline(context, boxOrigin, *it);\n            }\n        }\n    }\n\n    if (shouldRotate)\n        context->concatCTM(TextPainter::rotation(boxRect, TextPainter::Counterclockwise));\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -106,6 +106,7 @@\n     StringView string;\n     if (!combinedText) {\n         string = m_inlineTextBox.renderer().text().createView();\n+        ASSERT(m_inlineTextBox.start() + length <= string.length());\n         if (static_cast<unsigned>(length) != string.length() || m_inlineTextBox.start())\n             string.narrow(m_inlineTextBox.start(), length);\n         maximumLength = m_inlineTextBox.renderer().textLength() - m_inlineTextBox.start();",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "        ASSERT(m_inlineTextBox.start() + length <= string.length());"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1228",
        "func_name": "chromium/RenderCounter::updateCounter",
        "description": "The RenderCounter::updateCounter function in core/rendering/RenderCounter.cpp in Blink, as used in Google Chrome before 41.0.2272.76, does not force a relayout operation and consequently does not initialize memory for a data structure, which allows remote attackers to cause a denial of service (application crash) or possibly have unspecified other impact via a crafted Cascading Style Sheets (CSS) token sequence.",
        "git_url": "https://github.com/chromium/chromium/commit/3527a453038dde455b701c3e11eb0dc5d5fbe297",
        "commit_title": "RenderCounter::updateCounter should trigger a relayout.",
        "commit_text": " Currently, the method calls setTextInternal() - which updates the text but doesn't mark the node for layout and pref widths recalc. This can leave stale text boxes behind.  Instead, we should use setText() - which triggers the needed invalidations.   ",
        "func_before": "void RenderCounter::updateCounter()\n{\n    setTextInternal(originalText());\n}",
        "func": "void RenderCounter::updateCounter()\n{\n    setText(originalText());\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,4 +1,4 @@\n void RenderCounter::updateCounter()\n {\n-    setTextInternal(originalText());\n+    setText(originalText());\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    setTextInternal(originalText());"
            ],
            "added_lines": [
                "    setText(originalText());"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-2778",
        "func_name": "quassel/CtcpParser::query",
        "description": "Quassel before 0.12-rc1 uses an incorrect data-type size when splitting a message, which allows remote attackers to cause a denial of service (crash) via a long CTCP query containing only multibyte characters.",
        "git_url": "https://github.com/quassel/quassel/commit/b5e38970ffd55e2dd9f706ce75af9a8d7730b1b8",
        "commit_title": "Improve the message-splitting algorithm for PRIVMSG and CTCP",
        "commit_text": " This introduces a new message splitting algorithm based on QTextBoundaryFinder.  It works by first starting with the entire message to be sent, encoding it, and checking to see if it is over the maximum message length.  If it is, it uses QTBF to find the word boundary most immediately preceding the maximum length.  If no suitable boundary can be found, it falls back to searching for grapheme boundaries.  It repeats this process until the entire message has been sent.  Unlike what it replaces, the new splitting code is not recursive and cannot cause stack overflows.  Additionally, if it is unable to split a string, it will give up gracefully and not crash the core or cause a thread to run away.  This patch fixes two bugs.  The first is garbage characters caused by accidentally splitting the string in the middle of a multibyte character.  Since the new code splits at a character level instead of a byte level, this will no longer be an issue.  The second is the core crash caused by sending an overlength CTCP query (\"/me\") containing only multibyte characters.  This bug was caused by the old CTCP splitter using the byte index from lastParamOverrun() as a character index for a QString.",
        "func_before": "void CtcpParser::query(CoreNetwork *net, const QString &bufname, const QString &ctcpTag, const QString &message)\n{\n    QList<QByteArray> params;\n    params << net->serverEncode(bufname) << lowLevelQuote(pack(net->serverEncode(ctcpTag), net->userEncode(bufname, message)));\n\n    static const char *splitter = \" .,-!?\";\n    int maxSplitPos = message.count();\n    int splitPos = maxSplitPos;\n\n    int overrun = net->userInputHandler()->lastParamOverrun(\"PRIVMSG\", params);\n    if (overrun) {\n        maxSplitPos = message.count() - overrun -2;\n        splitPos = -1;\n        for (const char *splitChar = splitter; *splitChar != 0; splitChar++) {\n            splitPos = qMax(splitPos, message.lastIndexOf(*splitChar, maxSplitPos) + 1); // keep split char on old line\n        }\n        if (splitPos <= 0 || splitPos > maxSplitPos)\n            splitPos = maxSplitPos;\n\n        params = params.mid(0, 1) <<  lowLevelQuote(pack(net->serverEncode(ctcpTag), net->userEncode(bufname, message.left(splitPos))));\n    }\n    net->putCmd(\"PRIVMSG\", params);\n\n    if (splitPos < message.count())\n        query(net, bufname, ctcpTag, message.mid(splitPos));\n}",
        "func": "void CtcpParser::query(CoreNetwork *net, const QString &bufname, const QString &ctcpTag, const QString &message)\n{\n    QString cmd(\"PRIVMSG\");\n\n    std::function<QList<QByteArray>(QString &)> cmdGenerator = [&] (QString &splitMsg) -> QList<QByteArray> {\n        return QList<QByteArray>() << net->serverEncode(bufname) << lowLevelQuote(pack(net->serverEncode(ctcpTag), net->userEncode(bufname, splitMsg)));\n    };\n\n    net->putCmd(cmd, net->splitMessage(cmd, message, cmdGenerator));\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,26 +1,10 @@\n void CtcpParser::query(CoreNetwork *net, const QString &bufname, const QString &ctcpTag, const QString &message)\n {\n-    QList<QByteArray> params;\n-    params << net->serverEncode(bufname) << lowLevelQuote(pack(net->serverEncode(ctcpTag), net->userEncode(bufname, message)));\n+    QString cmd(\"PRIVMSG\");\n \n-    static const char *splitter = \" .,-!?\";\n-    int maxSplitPos = message.count();\n-    int splitPos = maxSplitPos;\n+    std::function<QList<QByteArray>(QString &)> cmdGenerator = [&] (QString &splitMsg) -> QList<QByteArray> {\n+        return QList<QByteArray>() << net->serverEncode(bufname) << lowLevelQuote(pack(net->serverEncode(ctcpTag), net->userEncode(bufname, splitMsg)));\n+    };\n \n-    int overrun = net->userInputHandler()->lastParamOverrun(\"PRIVMSG\", params);\n-    if (overrun) {\n-        maxSplitPos = message.count() - overrun -2;\n-        splitPos = -1;\n-        for (const char *splitChar = splitter; *splitChar != 0; splitChar++) {\n-            splitPos = qMax(splitPos, message.lastIndexOf(*splitChar, maxSplitPos) + 1); // keep split char on old line\n-        }\n-        if (splitPos <= 0 || splitPos > maxSplitPos)\n-            splitPos = maxSplitPos;\n-\n-        params = params.mid(0, 1) <<  lowLevelQuote(pack(net->serverEncode(ctcpTag), net->userEncode(bufname, message.left(splitPos))));\n-    }\n-    net->putCmd(\"PRIVMSG\", params);\n-\n-    if (splitPos < message.count())\n-        query(net, bufname, ctcpTag, message.mid(splitPos));\n+    net->putCmd(cmd, net->splitMessage(cmd, message, cmdGenerator));\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    QList<QByteArray> params;",
                "    params << net->serverEncode(bufname) << lowLevelQuote(pack(net->serverEncode(ctcpTag), net->userEncode(bufname, message)));",
                "    static const char *splitter = \" .,-!?\";",
                "    int maxSplitPos = message.count();",
                "    int splitPos = maxSplitPos;",
                "    int overrun = net->userInputHandler()->lastParamOverrun(\"PRIVMSG\", params);",
                "    if (overrun) {",
                "        maxSplitPos = message.count() - overrun -2;",
                "        splitPos = -1;",
                "        for (const char *splitChar = splitter; *splitChar != 0; splitChar++) {",
                "            splitPos = qMax(splitPos, message.lastIndexOf(*splitChar, maxSplitPos) + 1); // keep split char on old line",
                "        }",
                "        if (splitPos <= 0 || splitPos > maxSplitPos)",
                "            splitPos = maxSplitPos;",
                "",
                "        params = params.mid(0, 1) <<  lowLevelQuote(pack(net->serverEncode(ctcpTag), net->userEncode(bufname, message.left(splitPos))));",
                "    }",
                "    net->putCmd(\"PRIVMSG\", params);",
                "",
                "    if (splitPos < message.count())",
                "        query(net, bufname, ctcpTag, message.mid(splitPos));"
            ],
            "added_lines": [
                "    QString cmd(\"PRIVMSG\");",
                "    std::function<QList<QByteArray>(QString &)> cmdGenerator = [&] (QString &splitMsg) -> QList<QByteArray> {",
                "        return QList<QByteArray>() << net->serverEncode(bufname) << lowLevelQuote(pack(net->serverEncode(ctcpTag), net->userEncode(bufname, splitMsg)));",
                "    };",
                "    net->putCmd(cmd, net->splitMessage(cmd, message, cmdGenerator));"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-2778",
        "func_name": "quassel/CoreUserInputHandler::handleSay",
        "description": "Quassel before 0.12-rc1 uses an incorrect data-type size when splitting a message, which allows remote attackers to cause a denial of service (crash) via a long CTCP query containing only multibyte characters.",
        "git_url": "https://github.com/quassel/quassel/commit/b5e38970ffd55e2dd9f706ce75af9a8d7730b1b8",
        "commit_title": "Improve the message-splitting algorithm for PRIVMSG and CTCP",
        "commit_text": " This introduces a new message splitting algorithm based on QTextBoundaryFinder.  It works by first starting with the entire message to be sent, encoding it, and checking to see if it is over the maximum message length.  If it is, it uses QTBF to find the word boundary most immediately preceding the maximum length.  If no suitable boundary can be found, it falls back to searching for grapheme boundaries.  It repeats this process until the entire message has been sent.  Unlike what it replaces, the new splitting code is not recursive and cannot cause stack overflows.  Additionally, if it is unable to split a string, it will give up gracefully and not crash the core or cause a thread to run away.  This patch fixes two bugs.  The first is garbage characters caused by accidentally splitting the string in the middle of a multibyte character.  Since the new code splits at a character level instead of a byte level, this will no longer be an issue.  The second is the core crash caused by sending an overlength CTCP query (\"/me\") containing only multibyte characters.  This bug was caused by the old CTCP splitter using the byte index from lastParamOverrun() as a character index for a QString.",
        "func_before": "void CoreUserInputHandler::handleSay(const BufferInfo &bufferInfo, const QString &msg)\n{\n    if (bufferInfo.bufferName().isEmpty() || !bufferInfo.acceptsRegularMessages())\n        return;  // server buffer\n\n    QByteArray encMsg = channelEncode(bufferInfo.bufferName(), msg);\n#ifdef HAVE_QCA2\n    putPrivmsg(serverEncode(bufferInfo.bufferName()), encMsg, network()->cipher(bufferInfo.bufferName()));\n#else\n    putPrivmsg(serverEncode(bufferInfo.bufferName()), encMsg);\n#endif\n    emit displayMsg(Message::Plain, bufferInfo.type(), bufferInfo.bufferName(), msg, network()->myNick(), Message::Self);\n}",
        "func": "void CoreUserInputHandler::handleSay(const BufferInfo &bufferInfo, const QString &msg)\n{\n    if (bufferInfo.bufferName().isEmpty() || !bufferInfo.acceptsRegularMessages())\n        return;  // server buffer\n\n    std::function<QByteArray(const QString &, const QString &)> encodeFunc = [this] (const QString &target, const QString &message) -> QByteArray {\n        return channelEncode(target, message);\n    };\n\n#ifdef HAVE_QCA2\n    putPrivmsg(bufferInfo.bufferName(), msg, encodeFunc, network()->cipher(bufferInfo.bufferName()));\n#else\n    putPrivmsg(bufferInfo.bufferName(), msg, encodeFunc);\n#endif\n    emit displayMsg(Message::Plain, bufferInfo.type(), bufferInfo.bufferName(), msg, network()->myNick(), Message::Self);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,11 +3,14 @@\n     if (bufferInfo.bufferName().isEmpty() || !bufferInfo.acceptsRegularMessages())\n         return;  // server buffer\n \n-    QByteArray encMsg = channelEncode(bufferInfo.bufferName(), msg);\n+    std::function<QByteArray(const QString &, const QString &)> encodeFunc = [this] (const QString &target, const QString &message) -> QByteArray {\n+        return channelEncode(target, message);\n+    };\n+\n #ifdef HAVE_QCA2\n-    putPrivmsg(serverEncode(bufferInfo.bufferName()), encMsg, network()->cipher(bufferInfo.bufferName()));\n+    putPrivmsg(bufferInfo.bufferName(), msg, encodeFunc, network()->cipher(bufferInfo.bufferName()));\n #else\n-    putPrivmsg(serverEncode(bufferInfo.bufferName()), encMsg);\n+    putPrivmsg(bufferInfo.bufferName(), msg, encodeFunc);\n #endif\n     emit displayMsg(Message::Plain, bufferInfo.type(), bufferInfo.bufferName(), msg, network()->myNick(), Message::Self);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    QByteArray encMsg = channelEncode(bufferInfo.bufferName(), msg);",
                "    putPrivmsg(serverEncode(bufferInfo.bufferName()), encMsg, network()->cipher(bufferInfo.bufferName()));",
                "    putPrivmsg(serverEncode(bufferInfo.bufferName()), encMsg);"
            ],
            "added_lines": [
                "    std::function<QByteArray(const QString &, const QString &)> encodeFunc = [this] (const QString &target, const QString &message) -> QByteArray {",
                "        return channelEncode(target, message);",
                "    };",
                "",
                "    putPrivmsg(bufferInfo.bufferName(), msg, encodeFunc, network()->cipher(bufferInfo.bufferName()));",
                "    putPrivmsg(bufferInfo.bufferName(), msg, encodeFunc);"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-2778",
        "func_name": "quassel/CoreUserInputHandler::handleMsg",
        "description": "Quassel before 0.12-rc1 uses an incorrect data-type size when splitting a message, which allows remote attackers to cause a denial of service (crash) via a long CTCP query containing only multibyte characters.",
        "git_url": "https://github.com/quassel/quassel/commit/b5e38970ffd55e2dd9f706ce75af9a8d7730b1b8",
        "commit_title": "Improve the message-splitting algorithm for PRIVMSG and CTCP",
        "commit_text": " This introduces a new message splitting algorithm based on QTextBoundaryFinder.  It works by first starting with the entire message to be sent, encoding it, and checking to see if it is over the maximum message length.  If it is, it uses QTBF to find the word boundary most immediately preceding the maximum length.  If no suitable boundary can be found, it falls back to searching for grapheme boundaries.  It repeats this process until the entire message has been sent.  Unlike what it replaces, the new splitting code is not recursive and cannot cause stack overflows.  Additionally, if it is unable to split a string, it will give up gracefully and not crash the core or cause a thread to run away.  This patch fixes two bugs.  The first is garbage characters caused by accidentally splitting the string in the middle of a multibyte character.  Since the new code splits at a character level instead of a byte level, this will no longer be an issue.  The second is the core crash caused by sending an overlength CTCP query (\"/me\") containing only multibyte characters.  This bug was caused by the old CTCP splitter using the byte index from lastParamOverrun() as a character index for a QString.",
        "func_before": "void CoreUserInputHandler::handleMsg(const BufferInfo &bufferInfo, const QString &msg)\n{\n    Q_UNUSED(bufferInfo);\n    if (!msg.contains(' '))\n        return;\n\n    QString target = msg.section(' ', 0, 0);\n    QByteArray encMsg = userEncode(target, msg.section(' ', 1));\n\n#ifdef HAVE_QCA2\n    putPrivmsg(serverEncode(target), encMsg, network()->cipher(target));\n#else\n    putPrivmsg(serverEncode(target), encMsg);\n#endif\n}",
        "func": "void CoreUserInputHandler::handleMsg(const BufferInfo &bufferInfo, const QString &msg)\n{\n    Q_UNUSED(bufferInfo);\n    if (!msg.contains(' '))\n        return;\n\n    QString target = msg.section(' ', 0, 0);\n    QString msgSection = msg.section(' ', 1);\n\n    std::function<QByteArray(const QString &, const QString &)> encodeFunc = [this] (const QString &target, const QString &message) -> QByteArray {\n        return userEncode(target, message);\n    };\n\n#ifdef HAVE_QCA2\n    putPrivmsg(target, msgSection, encodeFunc, network()->cipher(target));\n#else\n    putPrivmsg(target, msgSection, encodeFunc);\n#endif\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,11 +5,15 @@\n         return;\n \n     QString target = msg.section(' ', 0, 0);\n-    QByteArray encMsg = userEncode(target, msg.section(' ', 1));\n+    QString msgSection = msg.section(' ', 1);\n+\n+    std::function<QByteArray(const QString &, const QString &)> encodeFunc = [this] (const QString &target, const QString &message) -> QByteArray {\n+        return userEncode(target, message);\n+    };\n \n #ifdef HAVE_QCA2\n-    putPrivmsg(serverEncode(target), encMsg, network()->cipher(target));\n+    putPrivmsg(target, msgSection, encodeFunc, network()->cipher(target));\n #else\n-    putPrivmsg(serverEncode(target), encMsg);\n+    putPrivmsg(target, msgSection, encodeFunc);\n #endif\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    QByteArray encMsg = userEncode(target, msg.section(' ', 1));",
                "    putPrivmsg(serverEncode(target), encMsg, network()->cipher(target));",
                "    putPrivmsg(serverEncode(target), encMsg);"
            ],
            "added_lines": [
                "    QString msgSection = msg.section(' ', 1);",
                "",
                "    std::function<QByteArray(const QString &, const QString &)> encodeFunc = [this] (const QString &target, const QString &message) -> QByteArray {",
                "        return userEncode(target, message);",
                "    };",
                "    putPrivmsg(target, msgSection, encodeFunc, network()->cipher(target));",
                "    putPrivmsg(target, msgSection, encodeFunc);"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-2778",
        "func_name": "quassel/CoreUserInputHandler::putPrivmsg",
        "description": "Quassel before 0.12-rc1 uses an incorrect data-type size when splitting a message, which allows remote attackers to cause a denial of service (crash) via a long CTCP query containing only multibyte characters.",
        "git_url": "https://github.com/quassel/quassel/commit/b5e38970ffd55e2dd9f706ce75af9a8d7730b1b8",
        "commit_title": "Improve the message-splitting algorithm for PRIVMSG and CTCP",
        "commit_text": " This introduces a new message splitting algorithm based on QTextBoundaryFinder.  It works by first starting with the entire message to be sent, encoding it, and checking to see if it is over the maximum message length.  If it is, it uses QTBF to find the word boundary most immediately preceding the maximum length.  If no suitable boundary can be found, it falls back to searching for grapheme boundaries.  It repeats this process until the entire message has been sent.  Unlike what it replaces, the new splitting code is not recursive and cannot cause stack overflows.  Additionally, if it is unable to split a string, it will give up gracefully and not crash the core or cause a thread to run away.  This patch fixes two bugs.  The first is garbage characters caused by accidentally splitting the string in the middle of a multibyte character.  Since the new code splits at a character level instead of a byte level, this will no longer be an issue.  The second is the core crash caused by sending an overlength CTCP query (\"/me\") containing only multibyte characters.  This bug was caused by the old CTCP splitter using the byte index from lastParamOverrun() as a character index for a QString.",
        "func_before": "void CoreUserInputHandler::putPrivmsg(const QByteArray &target, const QByteArray &message, Cipher *cipher)\n{\n    // Encrypted messages need special care. There's no clear relation between cleartext and encrypted message length,\n    // so we can't just compute the maxSplitPos. Instead, we need to loop through the splitpoints until the crypted\n    // version is short enough...\n    // TODO: check out how the various possible encryption methods behave length-wise and make\n    //       this clean by predicting the length of the crypted msg.\n    //       For example, blowfish-ebc seems to create 8-char chunks.\n\n    static const char *cmd = \"PRIVMSG\";\n    static const char *splitter = \" .,-!?\";\n\n    int maxSplitPos = message.count();\n    int splitPos = maxSplitPos;\n    forever {\n        QByteArray crypted = message.left(splitPos);\n        bool isEncrypted = false;\n#ifdef HAVE_QCA2\n        if (cipher && !cipher->key().isEmpty() && !message.isEmpty()) {\n            isEncrypted = cipher->encrypt(crypted);\n        }\n#endif\n        int overrun = lastParamOverrun(cmd, QList<QByteArray>() << target << crypted);\n        if (overrun) {\n            // In case this is not an encrypted msg, we can just cut off at the end\n            if (!isEncrypted)\n                maxSplitPos = message.count() - overrun;\n\n            splitPos = -1;\n            for (const char *splitChar = splitter; *splitChar != 0; splitChar++) {\n                splitPos = qMax(splitPos, message.lastIndexOf(*splitChar, maxSplitPos) + 1); // keep split char on old line\n            }\n            if (splitPos <= 0 || splitPos > maxSplitPos)\n                splitPos = maxSplitPos;\n\n            maxSplitPos = splitPos - 1;\n            if (maxSplitPos <= 0) { // this should never happen, but who knows...\n                qWarning() << tr(\"[Error] Could not encrypt your message: %1\").arg(message.data());\n                return;\n            }\n            continue; // we never come back here for !encrypted!\n        }\n\n        // now we have found a valid splitpos (or didn't need to split to begin with)\n        putCmd(cmd, QList<QByteArray>() << target << crypted);\n        if (splitPos < message.count())\n            putPrivmsg(target, message.mid(splitPos), cipher);\n\n        return;\n    }",
        "func": "void CoreUserInputHandler::putPrivmsg(const QString &target, const QString &message, std::function<QByteArray(const QString &, const QString &)> encodeFunc, Cipher *cipher)\n{\n    QString cmd(\"PRIVMSG\");\n    QByteArray targetEnc = serverEncode(target);\n\n    std::function<QList<QByteArray>(QString &)> cmdGenerator = [&] (QString &splitMsg) -> QList<QByteArray> {\n        QByteArray splitMsgEnc = encodeFunc(target, splitMsg);\n\n#ifdef HAVE_QCA2\n        if (cipher && !cipher->key().isEmpty() && !splitMsg.isEmpty()) {\n            cipher->encrypt(splitMsgEnc);\n        }\n#endif\n        return QList<QByteArray>() << targetEnc << splitMsgEnc;\n    };\n\n    putCmd(cmd, network()->splitMessage(cmd, message, cmdGenerator));\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,50 +1,18 @@\n-void CoreUserInputHandler::putPrivmsg(const QByteArray &target, const QByteArray &message, Cipher *cipher)\n+void CoreUserInputHandler::putPrivmsg(const QString &target, const QString &message, std::function<QByteArray(const QString &, const QString &)> encodeFunc, Cipher *cipher)\n {\n-    // Encrypted messages need special care. There's no clear relation between cleartext and encrypted message length,\n-    // so we can't just compute the maxSplitPos. Instead, we need to loop through the splitpoints until the crypted\n-    // version is short enough...\n-    // TODO: check out how the various possible encryption methods behave length-wise and make\n-    //       this clean by predicting the length of the crypted msg.\n-    //       For example, blowfish-ebc seems to create 8-char chunks.\n+    QString cmd(\"PRIVMSG\");\n+    QByteArray targetEnc = serverEncode(target);\n \n-    static const char *cmd = \"PRIVMSG\";\n-    static const char *splitter = \" .,-!?\";\n+    std::function<QList<QByteArray>(QString &)> cmdGenerator = [&] (QString &splitMsg) -> QList<QByteArray> {\n+        QByteArray splitMsgEnc = encodeFunc(target, splitMsg);\n \n-    int maxSplitPos = message.count();\n-    int splitPos = maxSplitPos;\n-    forever {\n-        QByteArray crypted = message.left(splitPos);\n-        bool isEncrypted = false;\n #ifdef HAVE_QCA2\n-        if (cipher && !cipher->key().isEmpty() && !message.isEmpty()) {\n-            isEncrypted = cipher->encrypt(crypted);\n+        if (cipher && !cipher->key().isEmpty() && !splitMsg.isEmpty()) {\n+            cipher->encrypt(splitMsgEnc);\n         }\n #endif\n-        int overrun = lastParamOverrun(cmd, QList<QByteArray>() << target << crypted);\n-        if (overrun) {\n-            // In case this is not an encrypted msg, we can just cut off at the end\n-            if (!isEncrypted)\n-                maxSplitPos = message.count() - overrun;\n+        return QList<QByteArray>() << targetEnc << splitMsgEnc;\n+    };\n \n-            splitPos = -1;\n-            for (const char *splitChar = splitter; *splitChar != 0; splitChar++) {\n-                splitPos = qMax(splitPos, message.lastIndexOf(*splitChar, maxSplitPos) + 1); // keep split char on old line\n-            }\n-            if (splitPos <= 0 || splitPos > maxSplitPos)\n-                splitPos = maxSplitPos;\n-\n-            maxSplitPos = splitPos - 1;\n-            if (maxSplitPos <= 0) { // this should never happen, but who knows...\n-                qWarning() << tr(\"[Error] Could not encrypt your message: %1\").arg(message.data());\n-                return;\n-            }\n-            continue; // we never come back here for !encrypted!\n-        }\n-\n-        // now we have found a valid splitpos (or didn't need to split to begin with)\n-        putCmd(cmd, QList<QByteArray>() << target << crypted);\n-        if (splitPos < message.count())\n-            putPrivmsg(target, message.mid(splitPos), cipher);\n-\n-        return;\n-    }\n+    putCmd(cmd, network()->splitMessage(cmd, message, cmdGenerator));\n+}",
        "diff_line_info": {
            "deleted_lines": [
                "void CoreUserInputHandler::putPrivmsg(const QByteArray &target, const QByteArray &message, Cipher *cipher)",
                "    // Encrypted messages need special care. There's no clear relation between cleartext and encrypted message length,",
                "    // so we can't just compute the maxSplitPos. Instead, we need to loop through the splitpoints until the crypted",
                "    // version is short enough...",
                "    // TODO: check out how the various possible encryption methods behave length-wise and make",
                "    //       this clean by predicting the length of the crypted msg.",
                "    //       For example, blowfish-ebc seems to create 8-char chunks.",
                "    static const char *cmd = \"PRIVMSG\";",
                "    static const char *splitter = \" .,-!?\";",
                "    int maxSplitPos = message.count();",
                "    int splitPos = maxSplitPos;",
                "    forever {",
                "        QByteArray crypted = message.left(splitPos);",
                "        bool isEncrypted = false;",
                "        if (cipher && !cipher->key().isEmpty() && !message.isEmpty()) {",
                "            isEncrypted = cipher->encrypt(crypted);",
                "        int overrun = lastParamOverrun(cmd, QList<QByteArray>() << target << crypted);",
                "        if (overrun) {",
                "            // In case this is not an encrypted msg, we can just cut off at the end",
                "            if (!isEncrypted)",
                "                maxSplitPos = message.count() - overrun;",
                "            splitPos = -1;",
                "            for (const char *splitChar = splitter; *splitChar != 0; splitChar++) {",
                "                splitPos = qMax(splitPos, message.lastIndexOf(*splitChar, maxSplitPos) + 1); // keep split char on old line",
                "            }",
                "            if (splitPos <= 0 || splitPos > maxSplitPos)",
                "                splitPos = maxSplitPos;",
                "",
                "            maxSplitPos = splitPos - 1;",
                "            if (maxSplitPos <= 0) { // this should never happen, but who knows...",
                "                qWarning() << tr(\"[Error] Could not encrypt your message: %1\").arg(message.data());",
                "                return;",
                "            }",
                "            continue; // we never come back here for !encrypted!",
                "        }",
                "",
                "        // now we have found a valid splitpos (or didn't need to split to begin with)",
                "        putCmd(cmd, QList<QByteArray>() << target << crypted);",
                "        if (splitPos < message.count())",
                "            putPrivmsg(target, message.mid(splitPos), cipher);",
                "",
                "        return;",
                "    }"
            ],
            "added_lines": [
                "void CoreUserInputHandler::putPrivmsg(const QString &target, const QString &message, std::function<QByteArray(const QString &, const QString &)> encodeFunc, Cipher *cipher)",
                "    QString cmd(\"PRIVMSG\");",
                "    QByteArray targetEnc = serverEncode(target);",
                "    std::function<QList<QByteArray>(QString &)> cmdGenerator = [&] (QString &splitMsg) -> QList<QByteArray> {",
                "        QByteArray splitMsgEnc = encodeFunc(target, splitMsg);",
                "        if (cipher && !cipher->key().isEmpty() && !splitMsg.isEmpty()) {",
                "            cipher->encrypt(splitMsgEnc);",
                "        return QList<QByteArray>() << targetEnc << splitMsgEnc;",
                "    };",
                "    putCmd(cmd, network()->splitMessage(cmd, message, cmdGenerator));",
                "}"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-2778",
        "func_name": "quassel/CoreBasicHandler::CoreBasicHandler",
        "description": "Quassel before 0.12-rc1 uses an incorrect data-type size when splitting a message, which allows remote attackers to cause a denial of service (crash) via a long CTCP query containing only multibyte characters.",
        "git_url": "https://github.com/quassel/quassel/commit/b5e38970ffd55e2dd9f706ce75af9a8d7730b1b8",
        "commit_title": "Improve the message-splitting algorithm for PRIVMSG and CTCP",
        "commit_text": " This introduces a new message splitting algorithm based on QTextBoundaryFinder.  It works by first starting with the entire message to be sent, encoding it, and checking to see if it is over the maximum message length.  If it is, it uses QTBF to find the word boundary most immediately preceding the maximum length.  If no suitable boundary can be found, it falls back to searching for grapheme boundaries.  It repeats this process until the entire message has been sent.  Unlike what it replaces, the new splitting code is not recursive and cannot cause stack overflows.  Additionally, if it is unable to split a string, it will give up gracefully and not crash the core or cause a thread to run away.  This patch fixes two bugs.  The first is garbage characters caused by accidentally splitting the string in the middle of a multibyte character.  Since the new code splits at a character level instead of a byte level, this will no longer be an issue.  The second is the core crash caused by sending an overlength CTCP query (\"/me\") containing only multibyte characters.  This bug was caused by the old CTCP splitter using the byte index from lastParamOverrun() as a character index for a QString.",
        "func_before": "CoreBasicHandler::CoreBasicHandler(CoreNetwork *parent)\n    : BasicHandler(parent),\n    _network(parent)\n{\n    connect(this, SIGNAL(displayMsg(Message::Type, BufferInfo::Type, const QString &, const QString &, const QString &, Message::Flags)),\n        network(), SLOT(displayMsg(Message::Type, BufferInfo::Type, const QString &, const QString &, const QString &, Message::Flags)));\n\n    connect(this, SIGNAL(putCmd(QString, const QList<QByteArray> &, const QByteArray &)),\n        network(), SLOT(putCmd(QString, const QList<QByteArray> &, const QByteArray &)));\n\n    connect(this, SIGNAL(putRawLine(const QByteArray &)),\n        network(), SLOT(putRawLine(const QByteArray &)));\n}",
        "func": "CoreBasicHandler::CoreBasicHandler(CoreNetwork *parent)\n    : BasicHandler(parent),\n    _network(parent)\n{\n    connect(this, SIGNAL(displayMsg(Message::Type, BufferInfo::Type, const QString &, const QString &, const QString &, Message::Flags)),\n        network(), SLOT(displayMsg(Message::Type, BufferInfo::Type, const QString &, const QString &, const QString &, Message::Flags)));\n\n    connect(this, SIGNAL(putCmd(QString, const QList<QByteArray> &, const QByteArray &)),\n        network(), SLOT(putCmd(QString, const QList<QByteArray> &, const QByteArray &)));\n\n    connect(this, SIGNAL(putCmd(QString, const QList<QList<QByteArray>> &, const QByteArray &)),\n        network(), SLOT(putCmd(QString, const QList<QList<QByteArray>> &, const QByteArray &)));\n\n    connect(this, SIGNAL(putRawLine(const QByteArray &)),\n        network(), SLOT(putRawLine(const QByteArray &)));\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -8,6 +8,9 @@\n     connect(this, SIGNAL(putCmd(QString, const QList<QByteArray> &, const QByteArray &)),\n         network(), SLOT(putCmd(QString, const QList<QByteArray> &, const QByteArray &)));\n \n+    connect(this, SIGNAL(putCmd(QString, const QList<QList<QByteArray>> &, const QByteArray &)),\n+        network(), SLOT(putCmd(QString, const QList<QList<QByteArray>> &, const QByteArray &)));\n+\n     connect(this, SIGNAL(putRawLine(const QByteArray &)),\n         network(), SLOT(putRawLine(const QByteArray &)));\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    connect(this, SIGNAL(putCmd(QString, const QList<QList<QByteArray>> &, const QByteArray &)),",
                "        network(), SLOT(putCmd(QString, const QList<QList<QByteArray>> &, const QByteArray &)));",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2014-9718",
        "func_name": "qemu/ahci_dma_prepare_buf",
        "description": "The (1) BMDMA and (2) AHCI HBA interfaces in the IDE functionality in QEMU 1.0 through 2.1.3 have multiple interpretations of a function's return value, which allows guest OS users to cause a host OS denial of service (memory consumption or infinite loop, and system crash) via a PRDT with zero complete sectors, related to the bmdma_prepare_buf and ahci_dma_prepare_buf functions.",
        "git_url": "https://github.com/qemu/qemu/commit/3251bdcf1c67427d964517053c3d185b46e618e8",
        "commit_title": "ide: Correct handling of malformed/short PRDTs",
        "commit_text": " This impacts both BMDMA and AHCI HBA interfaces for IDE. Currently, we confuse the difference between a PRDT having \"0 bytes\" and a PRDT having \"0 complete sectors.\"  When we receive an incomplete sector, inconsistent error checking leads to an infinite loop wherein the call succeeds, but it didn't give us enough bytes -- leading us to re-call the DMA chain over and over again. This leads to, in the BMDMA case, leaked memory for short PRDTs, and infinite loops and resource usage in the AHCI case.  The .prepare_buf() callback is reworked to return the number of bytes that it successfully prepared. 0 is a valid, non-error answer that means the table was empty and described no bytes. -1 indicates an error.  Our current implementation uses the io_buffer in IDEState to ultimately describe the size of a prepared scatter-gather list. Even though the AHCI PRDT/SGList can be as large as 256GiB, the AHCI command header limits transactions to just 4GiB. ATA8-ACS3, however, defines the largest transaction to be an LBA48 command that transfers 65,536 sectors. With a 512 byte sector size, this is just 32MiB.  Since our current state structures use the int type to describe the size of the buffer, and this state is migrated as int32, we are limited to describing 2GiB buffer sizes unless we change the migration protocol.  For this reason, this patch begins to unify the assertions in the IDE pathways that the scatter-gather list provided by either the AHCI PRDT or the PCI BMDMA PRDs can only describe, at a maximum, 2GiB. This should be resilient enough unless we need a sector size that exceeds 32KiB.  Further, the likelihood of any guest operating system actually attempting to transfer this much data in a single operation is very slim.  To this end, the IDEState variables have been updated to more explicitly clarify our maximum supported size. Callers to the prepare_buf callback have been reworked to understand the new return code, and all versions of the prepare_buf callback have been adjusted accordingly.  Lastly, the ahci_populate_sglist helper, relied upon by the AHCI implementation of .prepare_buf() as well as the PCI implementation of the callback have had overflow assertions added to help make clear the reasonings behind the various type changes.  [Added %d -> %\"PRId64\" fix John sent because off_pos changed from int to int64_t. --Stefan] ",
        "func_before": "static int ahci_dma_prepare_buf(IDEDMA *dma, int is_write)\n{\n    AHCIDevice *ad = DO_UPCAST(AHCIDevice, dma, dma);\n    IDEState *s = &ad->port.ifs[0];\n\n    ahci_populate_sglist(ad, &s->sg, s->io_buffer_offset);\n    s->io_buffer_size = s->sg.size;\n\n    DPRINTF(ad->port_no, \"len=%#x\\n\", s->io_buffer_size);\n    return s->io_buffer_size != 0;\n}",
        "func": "static int32_t ahci_dma_prepare_buf(IDEDMA *dma, int is_write)\n{\n    AHCIDevice *ad = DO_UPCAST(AHCIDevice, dma, dma);\n    IDEState *s = &ad->port.ifs[0];\n\n    if (ahci_populate_sglist(ad, &s->sg, s->io_buffer_offset) == -1) {\n        DPRINTF(ad->port_no, \"ahci_dma_prepare_buf failed.\\n\");\n        return -1;\n    }\n    s->io_buffer_size = s->sg.size;\n\n    DPRINTF(ad->port_no, \"len=%#x\\n\", s->io_buffer_size);\n    return s->io_buffer_size;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,11 +1,14 @@\n-static int ahci_dma_prepare_buf(IDEDMA *dma, int is_write)\n+static int32_t ahci_dma_prepare_buf(IDEDMA *dma, int is_write)\n {\n     AHCIDevice *ad = DO_UPCAST(AHCIDevice, dma, dma);\n     IDEState *s = &ad->port.ifs[0];\n \n-    ahci_populate_sglist(ad, &s->sg, s->io_buffer_offset);\n+    if (ahci_populate_sglist(ad, &s->sg, s->io_buffer_offset) == -1) {\n+        DPRINTF(ad->port_no, \"ahci_dma_prepare_buf failed.\\n\");\n+        return -1;\n+    }\n     s->io_buffer_size = s->sg.size;\n \n     DPRINTF(ad->port_no, \"len=%#x\\n\", s->io_buffer_size);\n-    return s->io_buffer_size != 0;\n+    return s->io_buffer_size;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "static int ahci_dma_prepare_buf(IDEDMA *dma, int is_write)",
                "    ahci_populate_sglist(ad, &s->sg, s->io_buffer_offset);",
                "    return s->io_buffer_size != 0;"
            ],
            "added_lines": [
                "static int32_t ahci_dma_prepare_buf(IDEDMA *dma, int is_write)",
                "    if (ahci_populate_sglist(ad, &s->sg, s->io_buffer_offset) == -1) {",
                "        DPRINTF(ad->port_no, \"ahci_dma_prepare_buf failed.\\n\");",
                "        return -1;",
                "    }",
                "    return s->io_buffer_size;"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-9718",
        "func_name": "qemu/ahci_populate_sglist",
        "description": "The (1) BMDMA and (2) AHCI HBA interfaces in the IDE functionality in QEMU 1.0 through 2.1.3 have multiple interpretations of a function's return value, which allows guest OS users to cause a host OS denial of service (memory consumption or infinite loop, and system crash) via a PRDT with zero complete sectors, related to the bmdma_prepare_buf and ahci_dma_prepare_buf functions.",
        "git_url": "https://github.com/qemu/qemu/commit/3251bdcf1c67427d964517053c3d185b46e618e8",
        "commit_title": "ide: Correct handling of malformed/short PRDTs",
        "commit_text": " This impacts both BMDMA and AHCI HBA interfaces for IDE. Currently, we confuse the difference between a PRDT having \"0 bytes\" and a PRDT having \"0 complete sectors.\"  When we receive an incomplete sector, inconsistent error checking leads to an infinite loop wherein the call succeeds, but it didn't give us enough bytes -- leading us to re-call the DMA chain over and over again. This leads to, in the BMDMA case, leaked memory for short PRDTs, and infinite loops and resource usage in the AHCI case.  The .prepare_buf() callback is reworked to return the number of bytes that it successfully prepared. 0 is a valid, non-error answer that means the table was empty and described no bytes. -1 indicates an error.  Our current implementation uses the io_buffer in IDEState to ultimately describe the size of a prepared scatter-gather list. Even though the AHCI PRDT/SGList can be as large as 256GiB, the AHCI command header limits transactions to just 4GiB. ATA8-ACS3, however, defines the largest transaction to be an LBA48 command that transfers 65,536 sectors. With a 512 byte sector size, this is just 32MiB.  Since our current state structures use the int type to describe the size of the buffer, and this state is migrated as int32, we are limited to describing 2GiB buffer sizes unless we change the migration protocol.  For this reason, this patch begins to unify the assertions in the IDE pathways that the scatter-gather list provided by either the AHCI PRDT or the PCI BMDMA PRDs can only describe, at a maximum, 2GiB. This should be resilient enough unless we need a sector size that exceeds 32KiB.  Further, the likelihood of any guest operating system actually attempting to transfer this much data in a single operation is very slim.  To this end, the IDEState variables have been updated to more explicitly clarify our maximum supported size. Callers to the prepare_buf callback have been reworked to understand the new return code, and all versions of the prepare_buf callback have been adjusted accordingly.  Lastly, the ahci_populate_sglist helper, relied upon by the AHCI implementation of .prepare_buf() as well as the PCI implementation of the callback have had overflow assertions added to help make clear the reasonings behind the various type changes.  [Added %d -> %\"PRId64\" fix John sent because off_pos changed from int to int64_t. --Stefan] ",
        "func_before": "static int ahci_populate_sglist(AHCIDevice *ad, QEMUSGList *sglist, int offset)\n{\n    AHCICmdHdr *cmd = ad->cur_cmd;\n    uint32_t opts = le32_to_cpu(cmd->opts);\n    uint64_t prdt_addr = le64_to_cpu(cmd->tbl_addr) + 0x80;\n    int sglist_alloc_hint = opts >> AHCI_CMD_HDR_PRDT_LEN;\n    dma_addr_t prdt_len = (sglist_alloc_hint * sizeof(AHCI_SG));\n    dma_addr_t real_prdt_len = prdt_len;\n    uint8_t *prdt;\n    int i;\n    int r = 0;\n    int sum = 0;\n    int off_idx = -1;\n    int off_pos = -1;\n    int tbl_entry_size;\n    IDEBus *bus = &ad->port;\n    BusState *qbus = BUS(bus);\n\n    if (!sglist_alloc_hint) {\n        DPRINTF(ad->port_no, \"no sg list given by guest: 0x%08x\\n\", opts);\n        return -1;\n    }\n\n    /* map PRDT */\n    if (!(prdt = dma_memory_map(ad->hba->as, prdt_addr, &prdt_len,\n                                DMA_DIRECTION_TO_DEVICE))){\n        DPRINTF(ad->port_no, \"map failed\\n\");\n        return -1;\n    }\n\n    if (prdt_len < real_prdt_len) {\n        DPRINTF(ad->port_no, \"mapped less than expected\\n\");\n        r = -1;\n        goto out;\n    }\n\n    /* Get entries in the PRDT, init a qemu sglist accordingly */\n    if (sglist_alloc_hint > 0) {\n        AHCI_SG *tbl = (AHCI_SG *)prdt;\n        sum = 0;\n        for (i = 0; i < sglist_alloc_hint; i++) {\n            /* flags_size is zero-based */\n            tbl_entry_size = prdt_tbl_entry_size(&tbl[i]);\n            if (offset <= (sum + tbl_entry_size)) {\n                off_idx = i;\n                off_pos = offset - sum;\n                break;\n            }\n            sum += tbl_entry_size;\n        }\n        if ((off_idx == -1) || (off_pos < 0) || (off_pos > tbl_entry_size)) {\n            DPRINTF(ad->port_no, \"%s: Incorrect offset! \"\n                            \"off_idx: %d, off_pos: %d\\n\",\n                            __func__, off_idx, off_pos);\n            r = -1;\n            goto out;\n        }\n\n        qemu_sglist_init(sglist, qbus->parent, (sglist_alloc_hint - off_idx),\n                         ad->hba->as);\n        qemu_sglist_add(sglist, le64_to_cpu(tbl[off_idx].addr + off_pos),\n                        prdt_tbl_entry_size(&tbl[off_idx]) - off_pos);\n\n        for (i = off_idx + 1; i < sglist_alloc_hint; i++) {\n            /* flags_size is zero-based */\n            qemu_sglist_add(sglist, le64_to_cpu(tbl[i].addr),\n                            prdt_tbl_entry_size(&tbl[i]));\n        }\n    }\n\nout:\n    dma_memory_unmap(ad->hba->as, prdt, prdt_len,\n                     DMA_DIRECTION_TO_DEVICE, prdt_len);\n    return r;\n}",
        "func": "static int ahci_populate_sglist(AHCIDevice *ad, QEMUSGList *sglist,\n                                int32_t offset)\n{\n    AHCICmdHdr *cmd = ad->cur_cmd;\n    uint32_t opts = le32_to_cpu(cmd->opts);\n    uint64_t prdt_addr = le64_to_cpu(cmd->tbl_addr) + 0x80;\n    int sglist_alloc_hint = opts >> AHCI_CMD_HDR_PRDT_LEN;\n    dma_addr_t prdt_len = (sglist_alloc_hint * sizeof(AHCI_SG));\n    dma_addr_t real_prdt_len = prdt_len;\n    uint8_t *prdt;\n    int i;\n    int r = 0;\n    uint64_t sum = 0;\n    int off_idx = -1;\n    int64_t off_pos = -1;\n    int tbl_entry_size;\n    IDEBus *bus = &ad->port;\n    BusState *qbus = BUS(bus);\n\n    /*\n     * Note: AHCI PRDT can describe up to 256GiB. SATA/ATA only support\n     * transactions of up to 32MiB as of ATA8-ACS3 rev 1b, assuming a\n     * 512 byte sector size. We limit the PRDT in this implementation to\n     * a reasonably large 2GiB, which can accommodate the maximum transfer\n     * request for sector sizes up to 32K.\n     */\n\n    if (!sglist_alloc_hint) {\n        DPRINTF(ad->port_no, \"no sg list given by guest: 0x%08x\\n\", opts);\n        return -1;\n    }\n\n    /* map PRDT */\n    if (!(prdt = dma_memory_map(ad->hba->as, prdt_addr, &prdt_len,\n                                DMA_DIRECTION_TO_DEVICE))){\n        DPRINTF(ad->port_no, \"map failed\\n\");\n        return -1;\n    }\n\n    if (prdt_len < real_prdt_len) {\n        DPRINTF(ad->port_no, \"mapped less than expected\\n\");\n        r = -1;\n        goto out;\n    }\n\n    /* Get entries in the PRDT, init a qemu sglist accordingly */\n    if (sglist_alloc_hint > 0) {\n        AHCI_SG *tbl = (AHCI_SG *)prdt;\n        sum = 0;\n        for (i = 0; i < sglist_alloc_hint; i++) {\n            /* flags_size is zero-based */\n            tbl_entry_size = prdt_tbl_entry_size(&tbl[i]);\n            if (offset <= (sum + tbl_entry_size)) {\n                off_idx = i;\n                off_pos = offset - sum;\n                break;\n            }\n            sum += tbl_entry_size;\n        }\n        if ((off_idx == -1) || (off_pos < 0) || (off_pos > tbl_entry_size)) {\n            DPRINTF(ad->port_no, \"%s: Incorrect offset! \"\n                            \"off_idx: %d, off_pos: %\"PRId64\"\\n\",\n                            __func__, off_idx, off_pos);\n            r = -1;\n            goto out;\n        }\n\n        qemu_sglist_init(sglist, qbus->parent, (sglist_alloc_hint - off_idx),\n                         ad->hba->as);\n        qemu_sglist_add(sglist, le64_to_cpu(tbl[off_idx].addr + off_pos),\n                        prdt_tbl_entry_size(&tbl[off_idx]) - off_pos);\n\n        for (i = off_idx + 1; i < sglist_alloc_hint; i++) {\n            /* flags_size is zero-based */\n            qemu_sglist_add(sglist, le64_to_cpu(tbl[i].addr),\n                            prdt_tbl_entry_size(&tbl[i]));\n            if (sglist->size > INT32_MAX) {\n                error_report(\"AHCI Physical Region Descriptor Table describes \"\n                             \"more than 2 GiB.\\n\");\n                qemu_sglist_destroy(sglist);\n                r = -1;\n                goto out;\n            }\n        }\n    }\n\nout:\n    dma_memory_unmap(ad->hba->as, prdt, prdt_len,\n                     DMA_DIRECTION_TO_DEVICE, prdt_len);\n    return r;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,4 +1,5 @@\n-static int ahci_populate_sglist(AHCIDevice *ad, QEMUSGList *sglist, int offset)\n+static int ahci_populate_sglist(AHCIDevice *ad, QEMUSGList *sglist,\n+                                int32_t offset)\n {\n     AHCICmdHdr *cmd = ad->cur_cmd;\n     uint32_t opts = le32_to_cpu(cmd->opts);\n@@ -9,12 +10,20 @@\n     uint8_t *prdt;\n     int i;\n     int r = 0;\n-    int sum = 0;\n+    uint64_t sum = 0;\n     int off_idx = -1;\n-    int off_pos = -1;\n+    int64_t off_pos = -1;\n     int tbl_entry_size;\n     IDEBus *bus = &ad->port;\n     BusState *qbus = BUS(bus);\n+\n+    /*\n+     * Note: AHCI PRDT can describe up to 256GiB. SATA/ATA only support\n+     * transactions of up to 32MiB as of ATA8-ACS3 rev 1b, assuming a\n+     * 512 byte sector size. We limit the PRDT in this implementation to\n+     * a reasonably large 2GiB, which can accommodate the maximum transfer\n+     * request for sector sizes up to 32K.\n+     */\n \n     if (!sglist_alloc_hint) {\n         DPRINTF(ad->port_no, \"no sg list given by guest: 0x%08x\\n\", opts);\n@@ -50,7 +59,7 @@\n         }\n         if ((off_idx == -1) || (off_pos < 0) || (off_pos > tbl_entry_size)) {\n             DPRINTF(ad->port_no, \"%s: Incorrect offset! \"\n-                            \"off_idx: %d, off_pos: %d\\n\",\n+                            \"off_idx: %d, off_pos: %\"PRId64\"\\n\",\n                             __func__, off_idx, off_pos);\n             r = -1;\n             goto out;\n@@ -65,6 +74,13 @@\n             /* flags_size is zero-based */\n             qemu_sglist_add(sglist, le64_to_cpu(tbl[i].addr),\n                             prdt_tbl_entry_size(&tbl[i]));\n+            if (sglist->size > INT32_MAX) {\n+                error_report(\"AHCI Physical Region Descriptor Table describes \"\n+                             \"more than 2 GiB.\\n\");\n+                qemu_sglist_destroy(sglist);\n+                r = -1;\n+                goto out;\n+            }\n         }\n     }\n ",
        "diff_line_info": {
            "deleted_lines": [
                "static int ahci_populate_sglist(AHCIDevice *ad, QEMUSGList *sglist, int offset)",
                "    int sum = 0;",
                "    int off_pos = -1;",
                "                            \"off_idx: %d, off_pos: %d\\n\","
            ],
            "added_lines": [
                "static int ahci_populate_sglist(AHCIDevice *ad, QEMUSGList *sglist,",
                "                                int32_t offset)",
                "    uint64_t sum = 0;",
                "    int64_t off_pos = -1;",
                "",
                "    /*",
                "     * Note: AHCI PRDT can describe up to 256GiB. SATA/ATA only support",
                "     * transactions of up to 32MiB as of ATA8-ACS3 rev 1b, assuming a",
                "     * 512 byte sector size. We limit the PRDT in this implementation to",
                "     * a reasonably large 2GiB, which can accommodate the maximum transfer",
                "     * request for sector sizes up to 32K.",
                "     */",
                "                            \"off_idx: %d, off_pos: %\"PRId64\"\\n\",",
                "            if (sglist->size > INT32_MAX) {",
                "                error_report(\"AHCI Physical Region Descriptor Table describes \"",
                "                             \"more than 2 GiB.\\n\");",
                "                qemu_sglist_destroy(sglist);",
                "                r = -1;",
                "                goto out;",
                "            }"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-9718",
        "func_name": "qemu/ide_dma_cb",
        "description": "The (1) BMDMA and (2) AHCI HBA interfaces in the IDE functionality in QEMU 1.0 through 2.1.3 have multiple interpretations of a function's return value, which allows guest OS users to cause a host OS denial of service (memory consumption or infinite loop, and system crash) via a PRDT with zero complete sectors, related to the bmdma_prepare_buf and ahci_dma_prepare_buf functions.",
        "git_url": "https://github.com/qemu/qemu/commit/3251bdcf1c67427d964517053c3d185b46e618e8",
        "commit_title": "ide: Correct handling of malformed/short PRDTs",
        "commit_text": " This impacts both BMDMA and AHCI HBA interfaces for IDE. Currently, we confuse the difference between a PRDT having \"0 bytes\" and a PRDT having \"0 complete sectors.\"  When we receive an incomplete sector, inconsistent error checking leads to an infinite loop wherein the call succeeds, but it didn't give us enough bytes -- leading us to re-call the DMA chain over and over again. This leads to, in the BMDMA case, leaked memory for short PRDTs, and infinite loops and resource usage in the AHCI case.  The .prepare_buf() callback is reworked to return the number of bytes that it successfully prepared. 0 is a valid, non-error answer that means the table was empty and described no bytes. -1 indicates an error.  Our current implementation uses the io_buffer in IDEState to ultimately describe the size of a prepared scatter-gather list. Even though the AHCI PRDT/SGList can be as large as 256GiB, the AHCI command header limits transactions to just 4GiB. ATA8-ACS3, however, defines the largest transaction to be an LBA48 command that transfers 65,536 sectors. With a 512 byte sector size, this is just 32MiB.  Since our current state structures use the int type to describe the size of the buffer, and this state is migrated as int32, we are limited to describing 2GiB buffer sizes unless we change the migration protocol.  For this reason, this patch begins to unify the assertions in the IDE pathways that the scatter-gather list provided by either the AHCI PRDT or the PCI BMDMA PRDs can only describe, at a maximum, 2GiB. This should be resilient enough unless we need a sector size that exceeds 32KiB.  Further, the likelihood of any guest operating system actually attempting to transfer this much data in a single operation is very slim.  To this end, the IDEState variables have been updated to more explicitly clarify our maximum supported size. Callers to the prepare_buf callback have been reworked to understand the new return code, and all versions of the prepare_buf callback have been adjusted accordingly.  Lastly, the ahci_populate_sglist helper, relied upon by the AHCI implementation of .prepare_buf() as well as the PCI implementation of the callback have had overflow assertions added to help make clear the reasonings behind the various type changes.  [Added %d -> %\"PRId64\" fix John sent because off_pos changed from int to int64_t. --Stefan] ",
        "func_before": "void ide_dma_cb(void *opaque, int ret)\n{\n    IDEState *s = opaque;\n    int n;\n    int64_t sector_num;\n    bool stay_active = false;\n\n    if (ret == -ECANCELED) {\n        return;\n    }\n    if (ret < 0) {\n        int op = IDE_RETRY_DMA;\n\n        if (s->dma_cmd == IDE_DMA_READ)\n            op |= IDE_RETRY_READ;\n        else if (s->dma_cmd == IDE_DMA_TRIM)\n            op |= IDE_RETRY_TRIM;\n\n        if (ide_handle_rw_error(s, -ret, op)) {\n            return;\n        }\n    }\n\n    n = s->io_buffer_size >> 9;\n    if (n > s->nsector) {\n        /* The PRDs were longer than needed for this request. Shorten them so\n         * we don't get a negative remainder. The Active bit must remain set\n         * after the request completes. */\n        n = s->nsector;\n        stay_active = true;\n    }\n\n    sector_num = ide_get_sector(s);\n    if (n > 0) {\n        assert(s->io_buffer_size == s->sg.size);\n        dma_buf_commit(s, s->io_buffer_size);\n        sector_num += n;\n        ide_set_sector(s, sector_num);\n        s->nsector -= n;\n    }\n\n    /* end of transfer ? */\n    if (s->nsector == 0) {\n        s->status = READY_STAT | SEEK_STAT;\n        ide_set_irq(s->bus);\n        goto eot;\n    }\n\n    /* launch next transfer */\n    n = s->nsector;\n    s->io_buffer_index = 0;\n    s->io_buffer_size = n * 512;\n    if (s->bus->dma->ops->prepare_buf(s->bus->dma, ide_cmd_is_read(s)) == 0) {\n        /* The PRDs were too short. Reset the Active bit, but don't raise an\n         * interrupt. */\n        s->status = READY_STAT | SEEK_STAT;\n        goto eot;\n    }\n\n#ifdef DEBUG_AIO\n    printf(\"ide_dma_cb: sector_num=%\" PRId64 \" n=%d, cmd_cmd=%d\\n\",\n           sector_num, n, s->dma_cmd);\n#endif\n\n    if ((s->dma_cmd == IDE_DMA_READ || s->dma_cmd == IDE_DMA_WRITE) &&\n        !ide_sect_range_ok(s, sector_num, n)) {\n        ide_dma_error(s);\n        return;\n    }\n\n    switch (s->dma_cmd) {\n    case IDE_DMA_READ:\n        s->bus->dma->aiocb = dma_blk_read(s->blk, &s->sg, sector_num,\n                                          ide_dma_cb, s);\n        break;\n    case IDE_DMA_WRITE:\n        s->bus->dma->aiocb = dma_blk_write(s->blk, &s->sg, sector_num,\n                                           ide_dma_cb, s);\n        break;\n    case IDE_DMA_TRIM:\n        s->bus->dma->aiocb = dma_blk_io(s->blk, &s->sg, sector_num,\n                                        ide_issue_trim, ide_dma_cb, s,\n                                        DMA_DIRECTION_TO_DEVICE);\n        break;\n    }\n    return;\n\neot:\n    if (s->dma_cmd == IDE_DMA_READ || s->dma_cmd == IDE_DMA_WRITE) {\n        block_acct_done(blk_get_stats(s->blk), &s->acct);\n    }\n    ide_set_inactive(s, stay_active);\n}",
        "func": "void ide_dma_cb(void *opaque, int ret)\n{\n    IDEState *s = opaque;\n    int n;\n    int64_t sector_num;\n    bool stay_active = false;\n\n    if (ret == -ECANCELED) {\n        return;\n    }\n    if (ret < 0) {\n        int op = IDE_RETRY_DMA;\n\n        if (s->dma_cmd == IDE_DMA_READ)\n            op |= IDE_RETRY_READ;\n        else if (s->dma_cmd == IDE_DMA_TRIM)\n            op |= IDE_RETRY_TRIM;\n\n        if (ide_handle_rw_error(s, -ret, op)) {\n            return;\n        }\n    }\n\n    n = s->io_buffer_size >> 9;\n    if (n > s->nsector) {\n        /* The PRDs were longer than needed for this request. Shorten them so\n         * we don't get a negative remainder. The Active bit must remain set\n         * after the request completes. */\n        n = s->nsector;\n        stay_active = true;\n    }\n\n    sector_num = ide_get_sector(s);\n    if (n > 0) {\n        assert(s->io_buffer_size == s->sg.size);\n        dma_buf_commit(s, s->io_buffer_size);\n        sector_num += n;\n        ide_set_sector(s, sector_num);\n        s->nsector -= n;\n    }\n\n    /* end of transfer ? */\n    if (s->nsector == 0) {\n        s->status = READY_STAT | SEEK_STAT;\n        ide_set_irq(s->bus);\n        goto eot;\n    }\n\n    /* launch next transfer */\n    n = s->nsector;\n    s->io_buffer_index = 0;\n    s->io_buffer_size = n * 512;\n    if (s->bus->dma->ops->prepare_buf(s->bus->dma, ide_cmd_is_read(s)) < 512) {\n        /* The PRDs were too short. Reset the Active bit, but don't raise an\n         * interrupt. */\n        s->status = READY_STAT | SEEK_STAT;\n        dma_buf_commit(s, 0);\n        goto eot;\n    }\n\n#ifdef DEBUG_AIO\n    printf(\"ide_dma_cb: sector_num=%\" PRId64 \" n=%d, cmd_cmd=%d\\n\",\n           sector_num, n, s->dma_cmd);\n#endif\n\n    if ((s->dma_cmd == IDE_DMA_READ || s->dma_cmd == IDE_DMA_WRITE) &&\n        !ide_sect_range_ok(s, sector_num, n)) {\n        ide_dma_error(s);\n        return;\n    }\n\n    switch (s->dma_cmd) {\n    case IDE_DMA_READ:\n        s->bus->dma->aiocb = dma_blk_read(s->blk, &s->sg, sector_num,\n                                          ide_dma_cb, s);\n        break;\n    case IDE_DMA_WRITE:\n        s->bus->dma->aiocb = dma_blk_write(s->blk, &s->sg, sector_num,\n                                           ide_dma_cb, s);\n        break;\n    case IDE_DMA_TRIM:\n        s->bus->dma->aiocb = dma_blk_io(s->blk, &s->sg, sector_num,\n                                        ide_issue_trim, ide_dma_cb, s,\n                                        DMA_DIRECTION_TO_DEVICE);\n        break;\n    }\n    return;\n\neot:\n    if (s->dma_cmd == IDE_DMA_READ || s->dma_cmd == IDE_DMA_WRITE) {\n        block_acct_done(blk_get_stats(s->blk), &s->acct);\n    }\n    ide_set_inactive(s, stay_active);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -50,10 +50,11 @@\n     n = s->nsector;\n     s->io_buffer_index = 0;\n     s->io_buffer_size = n * 512;\n-    if (s->bus->dma->ops->prepare_buf(s->bus->dma, ide_cmd_is_read(s)) == 0) {\n+    if (s->bus->dma->ops->prepare_buf(s->bus->dma, ide_cmd_is_read(s)) < 512) {\n         /* The PRDs were too short. Reset the Active bit, but don't raise an\n          * interrupt. */\n         s->status = READY_STAT | SEEK_STAT;\n+        dma_buf_commit(s, 0);\n         goto eot;\n     }\n ",
        "diff_line_info": {
            "deleted_lines": [
                "    if (s->bus->dma->ops->prepare_buf(s->bus->dma, ide_cmd_is_read(s)) == 0) {"
            ],
            "added_lines": [
                "    if (s->bus->dma->ops->prepare_buf(s->bus->dma, ide_cmd_is_read(s)) < 512) {",
                "        dma_buf_commit(s, 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-9718",
        "func_name": "qemu/bmdma_prepare_buf",
        "description": "The (1) BMDMA and (2) AHCI HBA interfaces in the IDE functionality in QEMU 1.0 through 2.1.3 have multiple interpretations of a function's return value, which allows guest OS users to cause a host OS denial of service (memory consumption or infinite loop, and system crash) via a PRDT with zero complete sectors, related to the bmdma_prepare_buf and ahci_dma_prepare_buf functions.",
        "git_url": "https://github.com/qemu/qemu/commit/3251bdcf1c67427d964517053c3d185b46e618e8",
        "commit_title": "ide: Correct handling of malformed/short PRDTs",
        "commit_text": " This impacts both BMDMA and AHCI HBA interfaces for IDE. Currently, we confuse the difference between a PRDT having \"0 bytes\" and a PRDT having \"0 complete sectors.\"  When we receive an incomplete sector, inconsistent error checking leads to an infinite loop wherein the call succeeds, but it didn't give us enough bytes -- leading us to re-call the DMA chain over and over again. This leads to, in the BMDMA case, leaked memory for short PRDTs, and infinite loops and resource usage in the AHCI case.  The .prepare_buf() callback is reworked to return the number of bytes that it successfully prepared. 0 is a valid, non-error answer that means the table was empty and described no bytes. -1 indicates an error.  Our current implementation uses the io_buffer in IDEState to ultimately describe the size of a prepared scatter-gather list. Even though the AHCI PRDT/SGList can be as large as 256GiB, the AHCI command header limits transactions to just 4GiB. ATA8-ACS3, however, defines the largest transaction to be an LBA48 command that transfers 65,536 sectors. With a 512 byte sector size, this is just 32MiB.  Since our current state structures use the int type to describe the size of the buffer, and this state is migrated as int32, we are limited to describing 2GiB buffer sizes unless we change the migration protocol.  For this reason, this patch begins to unify the assertions in the IDE pathways that the scatter-gather list provided by either the AHCI PRDT or the PCI BMDMA PRDs can only describe, at a maximum, 2GiB. This should be resilient enough unless we need a sector size that exceeds 32KiB.  Further, the likelihood of any guest operating system actually attempting to transfer this much data in a single operation is very slim.  To this end, the IDEState variables have been updated to more explicitly clarify our maximum supported size. Callers to the prepare_buf callback have been reworked to understand the new return code, and all versions of the prepare_buf callback have been adjusted accordingly.  Lastly, the ahci_populate_sglist helper, relied upon by the AHCI implementation of .prepare_buf() as well as the PCI implementation of the callback have had overflow assertions added to help make clear the reasonings behind the various type changes.  [Added %d -> %\"PRId64\" fix John sent because off_pos changed from int to int64_t. --Stefan] ",
        "func_before": "static int bmdma_prepare_buf(IDEDMA *dma, int is_write)\n{\n    BMDMAState *bm = DO_UPCAST(BMDMAState, dma, dma);\n    IDEState *s = bmdma_active_if(bm);\n    PCIDevice *pci_dev = PCI_DEVICE(bm->pci_dev);\n    struct {\n        uint32_t addr;\n        uint32_t size;\n    } prd;\n    int l, len;\n\n    pci_dma_sglist_init(&s->sg, pci_dev,\n                        s->nsector / (BMDMA_PAGE_SIZE / 512) + 1);\n    s->io_buffer_size = 0;\n    for(;;) {\n        if (bm->cur_prd_len == 0) {\n            /* end of table (with a fail safe of one page) */\n            if (bm->cur_prd_last ||\n                (bm->cur_addr - bm->addr) >= BMDMA_PAGE_SIZE)\n                return s->io_buffer_size != 0;\n            pci_dma_read(pci_dev, bm->cur_addr, &prd, 8);\n            bm->cur_addr += 8;\n            prd.addr = le32_to_cpu(prd.addr);\n            prd.size = le32_to_cpu(prd.size);\n            len = prd.size & 0xfffe;\n            if (len == 0)\n                len = 0x10000;\n            bm->cur_prd_len = len;\n            bm->cur_prd_addr = prd.addr;\n            bm->cur_prd_last = (prd.size & 0x80000000);\n        }\n        l = bm->cur_prd_len;\n        if (l > 0) {\n            qemu_sglist_add(&s->sg, bm->cur_prd_addr, l);\n            bm->cur_prd_addr += l;\n            bm->cur_prd_len -= l;\n            s->io_buffer_size += l;\n        }\n    }\n    return 1;\n}",
        "func": "static int32_t bmdma_prepare_buf(IDEDMA *dma, int is_write)\n{\n    BMDMAState *bm = DO_UPCAST(BMDMAState, dma, dma);\n    IDEState *s = bmdma_active_if(bm);\n    PCIDevice *pci_dev = PCI_DEVICE(bm->pci_dev);\n    struct {\n        uint32_t addr;\n        uint32_t size;\n    } prd;\n    int l, len;\n\n    pci_dma_sglist_init(&s->sg, pci_dev,\n                        s->nsector / (BMDMA_PAGE_SIZE / 512) + 1);\n    s->io_buffer_size = 0;\n    for(;;) {\n        if (bm->cur_prd_len == 0) {\n            /* end of table (with a fail safe of one page) */\n            if (bm->cur_prd_last ||\n                (bm->cur_addr - bm->addr) >= BMDMA_PAGE_SIZE) {\n                return s->io_buffer_size;\n            }\n            pci_dma_read(pci_dev, bm->cur_addr, &prd, 8);\n            bm->cur_addr += 8;\n            prd.addr = le32_to_cpu(prd.addr);\n            prd.size = le32_to_cpu(prd.size);\n            len = prd.size & 0xfffe;\n            if (len == 0)\n                len = 0x10000;\n            bm->cur_prd_len = len;\n            bm->cur_prd_addr = prd.addr;\n            bm->cur_prd_last = (prd.size & 0x80000000);\n        }\n        l = bm->cur_prd_len;\n        if (l > 0) {\n            qemu_sglist_add(&s->sg, bm->cur_prd_addr, l);\n\n            /* Note: We limit the max transfer to be 2GiB.\n             * This should accommodate the largest ATA transaction\n             * for LBA48 (65,536 sectors) and 32K sector sizes. */\n            if (s->sg.size > INT32_MAX) {\n                error_report(\"IDE: sglist describes more than 2GiB.\\n\");\n                break;\n            }\n            bm->cur_prd_addr += l;\n            bm->cur_prd_len -= l;\n            s->io_buffer_size += l;\n        }\n    }\n\n    qemu_sglist_destroy(&s->sg);\n    s->io_buffer_size = 0;\n    return -1;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,4 +1,4 @@\n-static int bmdma_prepare_buf(IDEDMA *dma, int is_write)\n+static int32_t bmdma_prepare_buf(IDEDMA *dma, int is_write)\n {\n     BMDMAState *bm = DO_UPCAST(BMDMAState, dma, dma);\n     IDEState *s = bmdma_active_if(bm);\n@@ -16,8 +16,9 @@\n         if (bm->cur_prd_len == 0) {\n             /* end of table (with a fail safe of one page) */\n             if (bm->cur_prd_last ||\n-                (bm->cur_addr - bm->addr) >= BMDMA_PAGE_SIZE)\n-                return s->io_buffer_size != 0;\n+                (bm->cur_addr - bm->addr) >= BMDMA_PAGE_SIZE) {\n+                return s->io_buffer_size;\n+            }\n             pci_dma_read(pci_dev, bm->cur_addr, &prd, 8);\n             bm->cur_addr += 8;\n             prd.addr = le32_to_cpu(prd.addr);\n@@ -32,10 +33,21 @@\n         l = bm->cur_prd_len;\n         if (l > 0) {\n             qemu_sglist_add(&s->sg, bm->cur_prd_addr, l);\n+\n+            /* Note: We limit the max transfer to be 2GiB.\n+             * This should accommodate the largest ATA transaction\n+             * for LBA48 (65,536 sectors) and 32K sector sizes. */\n+            if (s->sg.size > INT32_MAX) {\n+                error_report(\"IDE: sglist describes more than 2GiB.\\n\");\n+                break;\n+            }\n             bm->cur_prd_addr += l;\n             bm->cur_prd_len -= l;\n             s->io_buffer_size += l;\n         }\n     }\n-    return 1;\n+\n+    qemu_sglist_destroy(&s->sg);\n+    s->io_buffer_size = 0;\n+    return -1;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "static int bmdma_prepare_buf(IDEDMA *dma, int is_write)",
                "                (bm->cur_addr - bm->addr) >= BMDMA_PAGE_SIZE)",
                "                return s->io_buffer_size != 0;",
                "    return 1;"
            ],
            "added_lines": [
                "static int32_t bmdma_prepare_buf(IDEDMA *dma, int is_write)",
                "                (bm->cur_addr - bm->addr) >= BMDMA_PAGE_SIZE) {",
                "                return s->io_buffer_size;",
                "            }",
                "",
                "            /* Note: We limit the max transfer to be 2GiB.",
                "             * This should accommodate the largest ATA transaction",
                "             * for LBA48 (65,536 sectors) and 32K sector sizes. */",
                "            if (s->sg.size > INT32_MAX) {",
                "                error_report(\"IDE: sglist describes more than 2GiB.\\n\");",
                "                break;",
                "            }",
                "",
                "    qemu_sglist_destroy(&s->sg);",
                "    s->io_buffer_size = 0;",
                "    return -1;"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-3812",
        "func_name": "wireshark/x11_init_protocol",
        "description": "Multiple memory leaks in the x11_init_protocol function in epan/dissectors/packet-x11.c in the X11 dissector in Wireshark 1.10.x before 1.10.14 and 1.12.x before 1.12.5 allow remote attackers to cause a denial of service (memory consumption) via a crafted packet.",
        "git_url": "https://github.com/wireshark/wireshark/commit/b8ccc2a6add29823a0ff0492fc50372449007e7b",
        "commit_title": "x11: destroy two more hash tables in convo data",
        "commit_text": " Fixes a memory leak.  Bug: 11088",
        "func_before": "static void x11_init_protocol(void)\n{\n      x11_conv_data_t *state;\n\n      for (state = x11_conv_data_list; state != NULL; ) {\n            x11_conv_data_t *last;\n\n            g_hash_table_destroy(state->seqtable);\n            g_hash_table_destroy(state->valtable);\n\n            last = state;\n            state = state->next;\n            g_free(last);\n      }\n      x11_conv_data_list = NULL;\n}",
        "func": "static void x11_init_protocol(void)\n{\n      x11_conv_data_t *state;\n\n      for (state = x11_conv_data_list; state != NULL; ) {\n            x11_conv_data_t *last;\n\n            g_hash_table_destroy(state->eventcode_funcs);\n            g_hash_table_destroy(state->reply_funcs);\n\n            g_hash_table_destroy(state->seqtable);\n            g_hash_table_destroy(state->valtable);\n\n            last = state;\n            state = state->next;\n            g_free(last);\n      }\n      x11_conv_data_list = NULL;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,6 +4,9 @@\n \n       for (state = x11_conv_data_list; state != NULL; ) {\n             x11_conv_data_t *last;\n+\n+            g_hash_table_destroy(state->eventcode_funcs);\n+            g_hash_table_destroy(state->reply_funcs);\n \n             g_hash_table_destroy(state->seqtable);\n             g_hash_table_destroy(state->valtable);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "            g_hash_table_destroy(state->eventcode_funcs);",
                "            g_hash_table_destroy(state->reply_funcs);"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-3813",
        "func_name": "wireshark/fragment_add_work",
        "description": "The fragment_add_work function in epan/reassemble.c in the packet-reassembly feature in Wireshark 1.12.x before 1.12.5 does not properly determine the defragmentation state in a case of an insufficient snapshot length, which allows remote attackers to cause a denial of service (memory consumption) via a crafted packet.",
        "git_url": "https://github.com/wireshark/wireshark/commit/c35f2ccb4433718416551cc7a85afb0860529d57",
        "commit_title": "reassembly: address a 15-year old XXX comment",
        "commit_text": " Question: \"what if we didn't capture the entire fragment due to a too-short           snapshot length?\" Answer: An assertion fails and we leak a bunch of memory.  Don't do that.  Bug: 11129",
        "func_before": "static gboolean\nfragment_add_work(fragment_head *fd_head, tvbuff_t *tvb, const int offset,\n\t\t const packet_info *pinfo, const guint32 frag_offset,\n\t\t const guint32 frag_data_len, const gboolean more_frags)\n{\n\tfragment_item *fd;\n\tfragment_item *fd_i;\n\tguint32 max, dfpos, fraglen;\n\ttvbuff_t *old_tvb_data;\n\tguint8 *data;\n\n\t/* create new fd describing this fragment */\n\tfd = g_slice_new(fragment_item);\n\tfd->next = NULL;\n\tfd->flags = 0;\n\tfd->frame = pinfo->fd->num;\n\tfd->offset = frag_offset;\n\tfd->fragment_nr_offset = 0; /* will only be used with sequence */\n\tfd->len  = frag_data_len;\n\tfd->tvb_data = NULL;\n\tfd->error = NULL;\n\n\t/*\n\t * Are we adding to an already-completed reassembly?\n\t */\n\tif (fd_head->flags & FD_DEFRAGMENTED) {\n\t\t/*\n\t\t * Yes.  Does this fragment go past the end of the results\n\t\t * of that reassembly?\n\t\t * XXX - shouldn't this be \">\"?  If frag_offset + frag_data_len\n\t\t * == fd_head->datalen, this overlaps the end of the\n\t\t * reassembly, but doesn't go past it, right?\n\t\t */\n\t\tif (frag_offset + frag_data_len >= fd_head->datalen) {\n\t\t\t/*\n\t\t\t * Yes.  Have we been requested to continue reassembly?\n\t\t\t */\n\t\t\tif (fd_head->flags & FD_PARTIAL_REASSEMBLY) {\n\t\t\t\t/*\n\t\t\t\t * Yes.  Set flag in already empty fds &\n\t\t\t\t * point old fds to malloc'ed data.\n\t\t\t\t */\n\t\t\t\tfor(fd_i=fd_head->next; fd_i; fd_i=fd_i->next){\n\t\t\t\t\tif( !fd_i->tvb_data ) {\n\t\t\t\t\t\tfd_i->tvb_data = tvb_new_subset_remaining(fd_head->tvb_data, fd_i->offset);\n\t\t\t\t\t\tfd_i->flags |= FD_SUBSET_TVB;\n\t\t\t\t\t}\n\t\t\t\t\tfd_i->flags &= (~FD_TOOLONGFRAGMENT) & (~FD_MULTIPLETAILS);\n\t\t\t\t}\n\t\t\t\tfd_head->flags &= ~(FD_DEFRAGMENTED|FD_PARTIAL_REASSEMBLY|FD_DATALEN_SET);\n\t\t\t\tfd_head->flags &= (~FD_TOOLONGFRAGMENT) & (~FD_MULTIPLETAILS);\n\t\t\t\tfd_head->datalen=0;\n\t\t\t\tfd_head->reassembled_in=0;\n\t\t\t\tfd_head->reas_in_layer_num = 0;\n\t\t\t} else {\n\t\t\t\t/*\n\t\t\t\t * No.  Bail out since we have no idea what to\n\t\t\t\t * do with this fragment (and if we keep going\n\t\t\t\t * we'll run past the end of a buffer sooner\n\t\t\t\t * or later).\n\t\t\t\t */\n\t\t\t\tg_slice_free(fragment_item, fd);\n\n\t\t\t\t/*\n\t\t\t\t * This is an attempt to add a fragment to a\n\t\t\t\t * reassembly that had already completed.\n\t\t\t\t * If it had no error, we don't want to\n\t\t\t\t * mark it with an error, and if it had an\n\t\t\t\t * error, we don't want to overwrite it, so\n\t\t\t\t * we don't set fd_head->error.\n\t\t\t\t */\n\t\t\t\tif (frag_offset >= fd_head->datalen) {\n\t\t\t\t\t/*\n\t\t\t\t\t * The fragment starts past the end\n\t\t\t\t\t * of the reassembled data.\n\t\t\t\t\t */\n\t\t\t\t\tTHROW_MESSAGE(ReassemblyError, \"New fragment past old data limits\");\n\t\t\t\t} else {\n\t\t\t\t\t/*\n\t\t\t\t\t * The fragment starts before the end\n\t\t\t\t\t * of the reassembled data, but\n\t\t\t\t\t * runs past the end.  That could\n\t\t\t\t\t * just be a retransmission.\n\t\t\t\t\t */\n\t\t\t\t\tTHROW_MESSAGE(ReassemblyError, \"New fragment overlaps old data (retransmission?)\");\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\t/*\n\t\t\t * No.  That means it still overlaps that, so report\n\t\t\t * this as a problem, possibly a retransmission.\n\t\t\t */\n\t\t\tg_slice_free(fragment_item, fd);\n\t\t\tTHROW_MESSAGE(ReassemblyError, \"New fragment overlaps old data (retransmission?)\");\n\t\t}\n\t}\n\n\t/* Do this after we may have bailed out (above) so that we don't leave\n\t * fd_head->frame in a bad state if we do */\n\tif (fd->frame > fd_head->frame)\n\t\tfd_head->frame = fd->frame;\n\n\tif (!more_frags) {\n\t\t/*\n\t\t * This is the tail fragment in the sequence.\n\t\t */\n\t\tif (fd_head->flags & FD_DATALEN_SET) {\n\t\t\t/* ok we have already seen other tails for this packet\n\t\t\t * it might be a duplicate.\n\t\t\t */\n\t\t\tif (fd_head->datalen != (fd->offset + fd->len) ){\n\t\t\t\t/* Oops, this tail indicates a different packet\n\t\t\t\t * len than the previous ones. Something's wrong.\n\t\t\t\t */\n\t\t\t\tfd->flags\t   |= FD_MULTIPLETAILS;\n\t\t\t\tfd_head->flags |= FD_MULTIPLETAILS;\n\t\t\t}\n\t\t} else {\n\t\t\t/* This was the first tail fragment; now we know\n\t\t\t * what the length of the packet should be.\n\t\t\t */\n\t\t\tfd_head->datalen = fd->offset + fd->len;\n\t\t\tfd_head->flags |= FD_DATALEN_SET;\n\t\t}\n\t}\n\n\n\n\t/* If the packet is already defragmented, this MUST be an overlap.\n\t * The entire defragmented packet is in fd_head->data.\n\t * Even if we have previously defragmented this packet, we still\n\t * check it. Someone might play overlap and TTL games.\n\t */\n\tif (fd_head->flags & FD_DEFRAGMENTED) {\n\t\tguint32 end_offset = fd->offset + fd->len;\n\t\tfd->flags\t   |= FD_OVERLAP;\n\t\tfd_head->flags |= FD_OVERLAP;\n\t\t/* make sure it's not too long */\n\t\tif (end_offset > fd_head->datalen || end_offset < fd->offset || end_offset < fd->len) {\n\t\t\tfd->flags\t   |= FD_TOOLONGFRAGMENT;\n\t\t\tfd_head->flags |= FD_TOOLONGFRAGMENT;\n\t\t}\n\t\t/* make sure it doesn't conflict with previous data */\n\t\telse if ( tvb_memeql(fd_head->tvb_data, fd->offset,\n\t\t\ttvb_get_ptr(tvb,offset,fd->len),fd->len) ){\n\t\t\tfd->flags\t   |= FD_OVERLAPCONFLICT;\n\t\t\tfd_head->flags |= FD_OVERLAPCONFLICT;\n\t\t}\n\t\t/* it was just an overlap, link it and return */\n\t\tLINK_FRAG(fd_head,fd);\n\t\treturn TRUE;\n\t}\n\n\n\n\t/* If we have reached this point, the packet is not defragmented yet.\n\t * Save all payload in a buffer until we can defragment.\n\t * XXX - what if we didn't capture the entire fragment due\n\t * to a too-short snapshot length?\n\t */\n\tfd->tvb_data = tvb_clone_offset_len(tvb, offset, fd->len);\n\tLINK_FRAG(fd_head,fd);\n\n\n\tif( !(fd_head->flags & FD_DATALEN_SET) ){\n\t\t/* if we don't know the datalen, there are still missing\n\t\t * packets. Cheaper than the check below.\n\t\t */\n\t\treturn FALSE;\n\t}\n\n\n\t/*\n\t * Check if we have received the entire fragment.\n\t * This is easy since the list is sorted and the head is faked.\n\t *\n\t * First, we compute the amount of contiguous data that's\n\t * available.  (The check for fd_i->offset <= max rules out\n\t * fragments that don't start before or at the end of the\n\t * previous fragment, i.e. fragments that have a gap between\n\t * them and the previous fragment.)\n\t */\n\tmax = 0;\n\tfor (fd_i=fd_head->next;fd_i;fd_i=fd_i->next) {\n\t\tif ( ((fd_i->offset)<=max) &&\n\t\t\t((fd_i->offset+fd_i->len)>max) ){\n\t\t\tmax = fd_i->offset+fd_i->len;\n\t\t}\n\t}\n\n\tif (max < (fd_head->datalen)) {\n\t\t/*\n\t\t * The amount of contiguous data we have is less than the\n\t\t * amount of data we're trying to reassemble, so we haven't\n\t\t * received all packets yet.\n\t\t */\n\t\treturn FALSE;\n\t}\n\n\t/* we have received an entire packet, defragment it and\n\t * free all fragments\n\t */\n\t/* store old data just in case */\n\told_tvb_data=fd_head->tvb_data;\n\tdata = (guint8 *) g_malloc(fd_head->datalen);\n\tfd_head->tvb_data = tvb_new_real_data(data, fd_head->datalen, fd_head->datalen);\n\ttvb_set_free_cb(fd_head->tvb_data, g_free);\n\n\t/* add all data fragments */\n\tfor (dfpos=0,fd_i=fd_head;fd_i;fd_i=fd_i->next) {\n\t\tif (fd_i->len) {\n\t\t\t/*\n\t\t\t * The loop above that calculates max also\n\t\t\t * ensures that the only gaps that exist here\n\t\t\t * are ones where a fragment starts past the\n\t\t\t * end of the reassembled datagram, and there's\n\t\t\t * a gap between the previous fragment and\n\t\t\t * that fragment.\n\t\t\t *\n\t\t\t * A \"DESEGMENT_UNTIL_FIN\" was involved wherein the\n\t\t\t * FIN packet had an offset less than the highest\n\t\t\t * fragment offset seen. [Seen from a fuzz-test:\n\t\t\t * bug #2470]).\n\t\t\t *\n\t\t\t * Note that the \"overlap\" compare must only be\n\t\t\t * done for fragments with (offset+len) <= fd_head->datalen\n\t\t\t * and thus within the newly g_malloc'd buffer.\n\t\t\t */\n\t\t\tif (fd_i->offset + fd_i->len > dfpos) {\n\t\t\t\tif (fd_i->offset >= fd_head->datalen) {\n\t\t\t\t\t/*\n\t\t\t\t\t * Fragment starts after the end\n\t\t\t\t\t * of the reassembled packet.\n\t\t\t\t\t *\n\t\t\t\t\t * This can happen if the length was\n\t\t\t\t\t * set after the offending fragment\n\t\t\t\t\t * was added to the reassembly.\n\t\t\t\t\t *\n\t\t\t\t\t * Flag this fragment, but don't\n\t\t\t\t\t * try to extract any data from\n\t\t\t\t\t * it, as there's no place to put\n\t\t\t\t\t * it.\n\t\t\t\t\t *\n\t\t\t\t\t * XXX - add different flag value\n\t\t\t\t\t * for this.\n\t\t\t\t\t */\n\t\t\t\t\tfd_i->flags    |= FD_TOOLONGFRAGMENT;\n\t\t\t\t\tfd_head->flags |= FD_TOOLONGFRAGMENT;\n\t\t\t\t} else if (dfpos < fd_i->offset) {\n\t\t\t\t\t/*\n\t\t\t\t\t * XXX - can this happen?  We've\n\t\t\t\t\t * already rejected fragments that\n\t\t\t\t\t * start past the end of the\n\t\t\t\t\t * reassembled datagram, and\n\t\t\t\t\t * the loop that calculated max\n\t\t\t\t\t * should have ruled out gaps,\n\t\t\t\t\t * but could fd_i->offset +\n\t\t\t\t\t * fd_i->len overflow?\n\t\t\t\t\t */\n\t\t\t\t\tfd_head->error = \"dfpos < offset\";\n\t\t\t\t} else if (dfpos - fd_i->offset > fd_i->len)\n\t\t\t\t\tfd_head->error = \"dfpos - offset > len\";\n\t\t\t\telse if (!fd_head->tvb_data)\n\t\t\t\t\tfd_head->error = \"no data\";\n\t\t\t\telse {\n\t\t\t\t\tfraglen = fd_i->len;\n\t\t\t\t\tif (fd_i->offset + fraglen > fd_head->datalen) {\n\t\t\t\t\t\t/*\n\t\t\t\t\t\t * Fragment goes past the end\n\t\t\t\t\t\t * of the packet, as indicated\n\t\t\t\t\t\t * by the last fragment.\n\t\t\t\t\t\t *\n\t\t\t\t\t\t * This can happen if the\n\t\t\t\t\t\t * length was set after the\n\t\t\t\t\t\t * offending fragment was\n\t\t\t\t\t\t * added to the reassembly.\n\t\t\t\t\t\t *\n\t\t\t\t\t\t * Mark it as such, and only\n\t\t\t\t\t\t * copy from it what fits in\n\t\t\t\t\t\t * the packet.\n\t\t\t\t\t\t */\n\t\t\t\t\t\tfd_i->flags    |= FD_TOOLONGFRAGMENT;\n\t\t\t\t\t\tfd_head->flags |= FD_TOOLONGFRAGMENT;\n\t\t\t\t\t\tfraglen = fd_head->datalen - fd_i->offset;\n\t\t\t\t\t}\n\t\t\t\t\tif (fd_i->offset < dfpos) {\n\t\t\t\t\t\tguint32 cmp_len = MIN(fd_i->len,(dfpos-fd_i->offset));\n\n\t\t\t\t\t\tfd_i->flags    |= FD_OVERLAP;\n\t\t\t\t\t\tfd_head->flags |= FD_OVERLAP;\n\t\t\t\t\t\tif ( memcmp(data + fd_i->offset,\n\t\t\t\t\t\t\t\ttvb_get_ptr(fd_i->tvb_data, 0, cmp_len),\n\t\t\t\t\t\t\t\tcmp_len)\n\t\t\t\t\t\t\t\t ) {\n\t\t\t\t\t\t\tfd_i->flags    |= FD_OVERLAPCONFLICT;\n\t\t\t\t\t\t\tfd_head->flags |= FD_OVERLAPCONFLICT;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif (fraglen < dfpos - fd_i->offset) {\n\t\t\t\t\t\t/*\n\t\t\t\t\t\t * XXX - can this happen?\n\t\t\t\t\t\t */\n\t\t\t\t\t\tfd_head->error = \"fraglen < dfpos - offset\";\n\t\t\t\t\t} else {\n\t\t\t\t\t\tmemcpy(data+dfpos,\n\t\t\t\t\t\t\ttvb_get_ptr(fd_i->tvb_data, (dfpos-fd_i->offset), fraglen-(dfpos-fd_i->offset)),\n\t\t\t\t\t\t\tfraglen-(dfpos-fd_i->offset));\n\t\t\t\t\t\tdfpos=MAX(dfpos, (fd_i->offset + fraglen));\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif (fd_i->offset + fd_i->len < fd_i->offset) {\n\t\t\t\t\t/* Integer overflow? */\n\t\t\t\t\tfd_head->error = \"offset + len < offset\";\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (fd_i->flags & FD_SUBSET_TVB)\n\t\t\t\tfd_i->flags &= ~FD_SUBSET_TVB;\n\t\t\telse if (fd_i->tvb_data)\n\t\t\t\ttvb_free(fd_i->tvb_data);\n\n\t\t\tfd_i->tvb_data=NULL;\n\t\t}\n\t}\n\n\tif (old_tvb_data)\n\t\ttvb_add_to_chain(tvb, old_tvb_data);\n\t/* mark this packet as defragmented.\n\t   allows us to skip any trailing fragments */\n\tfd_head->flags |= FD_DEFRAGMENTED;\n\tfd_head->reassembled_in=pinfo->fd->num;\n\tfd_head->reas_in_layer_num = pinfo->curr_layer_num;\n\n\t/* we don't throw until here to avoid leaking old_data and others */\n\tif (fd_head->error) {\n\t\tTHROW_MESSAGE(ReassemblyError, fd_head->error);\n\t}\n\n\treturn TRUE;\n}",
        "func": "static gboolean\nfragment_add_work(fragment_head *fd_head, tvbuff_t *tvb, const int offset,\n\t\t const packet_info *pinfo, const guint32 frag_offset,\n\t\t const guint32 frag_data_len, const gboolean more_frags)\n{\n\tfragment_item *fd;\n\tfragment_item *fd_i;\n\tguint32 max, dfpos, fraglen;\n\ttvbuff_t *old_tvb_data;\n\tguint8 *data;\n\n\t/* create new fd describing this fragment */\n\tfd = g_slice_new(fragment_item);\n\tfd->next = NULL;\n\tfd->flags = 0;\n\tfd->frame = pinfo->fd->num;\n\tfd->offset = frag_offset;\n\tfd->fragment_nr_offset = 0; /* will only be used with sequence */\n\tfd->len  = frag_data_len;\n\tfd->tvb_data = NULL;\n\tfd->error = NULL;\n\n\t/*\n\t * Are we adding to an already-completed reassembly?\n\t */\n\tif (fd_head->flags & FD_DEFRAGMENTED) {\n\t\t/*\n\t\t * Yes.  Does this fragment go past the end of the results\n\t\t * of that reassembly?\n\t\t * XXX - shouldn't this be \">\"?  If frag_offset + frag_data_len\n\t\t * == fd_head->datalen, this overlaps the end of the\n\t\t * reassembly, but doesn't go past it, right?\n\t\t */\n\t\tif (frag_offset + frag_data_len >= fd_head->datalen) {\n\t\t\t/*\n\t\t\t * Yes.  Have we been requested to continue reassembly?\n\t\t\t */\n\t\t\tif (fd_head->flags & FD_PARTIAL_REASSEMBLY) {\n\t\t\t\t/*\n\t\t\t\t * Yes.  Set flag in already empty fds &\n\t\t\t\t * point old fds to malloc'ed data.\n\t\t\t\t */\n\t\t\t\tfor(fd_i=fd_head->next; fd_i; fd_i=fd_i->next){\n\t\t\t\t\tif( !fd_i->tvb_data ) {\n\t\t\t\t\t\tfd_i->tvb_data = tvb_new_subset_remaining(fd_head->tvb_data, fd_i->offset);\n\t\t\t\t\t\tfd_i->flags |= FD_SUBSET_TVB;\n\t\t\t\t\t}\n\t\t\t\t\tfd_i->flags &= (~FD_TOOLONGFRAGMENT) & (~FD_MULTIPLETAILS);\n\t\t\t\t}\n\t\t\t\tfd_head->flags &= ~(FD_DEFRAGMENTED|FD_PARTIAL_REASSEMBLY|FD_DATALEN_SET);\n\t\t\t\tfd_head->flags &= (~FD_TOOLONGFRAGMENT) & (~FD_MULTIPLETAILS);\n\t\t\t\tfd_head->datalen=0;\n\t\t\t\tfd_head->reassembled_in=0;\n\t\t\t\tfd_head->reas_in_layer_num = 0;\n\t\t\t} else {\n\t\t\t\t/*\n\t\t\t\t * No.  Bail out since we have no idea what to\n\t\t\t\t * do with this fragment (and if we keep going\n\t\t\t\t * we'll run past the end of a buffer sooner\n\t\t\t\t * or later).\n\t\t\t\t */\n\t\t\t\tg_slice_free(fragment_item, fd);\n\n\t\t\t\t/*\n\t\t\t\t * This is an attempt to add a fragment to a\n\t\t\t\t * reassembly that had already completed.\n\t\t\t\t * If it had no error, we don't want to\n\t\t\t\t * mark it with an error, and if it had an\n\t\t\t\t * error, we don't want to overwrite it, so\n\t\t\t\t * we don't set fd_head->error.\n\t\t\t\t */\n\t\t\t\tif (frag_offset >= fd_head->datalen) {\n\t\t\t\t\t/*\n\t\t\t\t\t * The fragment starts past the end\n\t\t\t\t\t * of the reassembled data.\n\t\t\t\t\t */\n\t\t\t\t\tTHROW_MESSAGE(ReassemblyError, \"New fragment past old data limits\");\n\t\t\t\t} else {\n\t\t\t\t\t/*\n\t\t\t\t\t * The fragment starts before the end\n\t\t\t\t\t * of the reassembled data, but\n\t\t\t\t\t * runs past the end.  That could\n\t\t\t\t\t * just be a retransmission.\n\t\t\t\t\t */\n\t\t\t\t\tTHROW_MESSAGE(ReassemblyError, \"New fragment overlaps old data (retransmission?)\");\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\t/*\n\t\t\t * No.  That means it still overlaps that, so report\n\t\t\t * this as a problem, possibly a retransmission.\n\t\t\t */\n\t\t\tg_slice_free(fragment_item, fd);\n\t\t\tTHROW_MESSAGE(ReassemblyError, \"New fragment overlaps old data (retransmission?)\");\n\t\t}\n\t}\n\n\t/* Do this after we may have bailed out (above) so that we don't leave\n\t * fd_head->frame in a bad state if we do */\n\tif (fd->frame > fd_head->frame)\n\t\tfd_head->frame = fd->frame;\n\n\tif (!more_frags) {\n\t\t/*\n\t\t * This is the tail fragment in the sequence.\n\t\t */\n\t\tif (fd_head->flags & FD_DATALEN_SET) {\n\t\t\t/* ok we have already seen other tails for this packet\n\t\t\t * it might be a duplicate.\n\t\t\t */\n\t\t\tif (fd_head->datalen != (fd->offset + fd->len) ){\n\t\t\t\t/* Oops, this tail indicates a different packet\n\t\t\t\t * len than the previous ones. Something's wrong.\n\t\t\t\t */\n\t\t\t\tfd->flags\t   |= FD_MULTIPLETAILS;\n\t\t\t\tfd_head->flags |= FD_MULTIPLETAILS;\n\t\t\t}\n\t\t} else {\n\t\t\t/* This was the first tail fragment; now we know\n\t\t\t * what the length of the packet should be.\n\t\t\t */\n\t\t\tfd_head->datalen = fd->offset + fd->len;\n\t\t\tfd_head->flags |= FD_DATALEN_SET;\n\t\t}\n\t}\n\n\n\n\t/* If the packet is already defragmented, this MUST be an overlap.\n\t * The entire defragmented packet is in fd_head->data.\n\t * Even if we have previously defragmented this packet, we still\n\t * check it. Someone might play overlap and TTL games.\n\t */\n\tif (fd_head->flags & FD_DEFRAGMENTED) {\n\t\tguint32 end_offset = fd->offset + fd->len;\n\t\tfd->flags\t   |= FD_OVERLAP;\n\t\tfd_head->flags |= FD_OVERLAP;\n\t\t/* make sure it's not too long */\n\t\tif (end_offset > fd_head->datalen || end_offset < fd->offset || end_offset < fd->len) {\n\t\t\tfd->flags\t   |= FD_TOOLONGFRAGMENT;\n\t\t\tfd_head->flags |= FD_TOOLONGFRAGMENT;\n\t\t}\n\t\t/* make sure it doesn't conflict with previous data */\n\t\telse if ( tvb_memeql(fd_head->tvb_data, fd->offset,\n\t\t\ttvb_get_ptr(tvb,offset,fd->len),fd->len) ){\n\t\t\tfd->flags\t   |= FD_OVERLAPCONFLICT;\n\t\t\tfd_head->flags |= FD_OVERLAPCONFLICT;\n\t\t}\n\t\t/* it was just an overlap, link it and return */\n\t\tLINK_FRAG(fd_head,fd);\n\t\treturn TRUE;\n\t}\n\n\n\n\t/* If we have reached this point, the packet is not defragmented yet.\n\t * Save all payload in a buffer until we can defragment.\n\t */\n\tif (!tvb_bytes_exist(tvb, offset, fd->len)) {\n\t\tg_slice_free(fragment_item, fd);\n\t\tTHROW(BoundsError);\n\t}\n\tfd->tvb_data = tvb_clone_offset_len(tvb, offset, fd->len);\n\tLINK_FRAG(fd_head,fd);\n\n\n\tif( !(fd_head->flags & FD_DATALEN_SET) ){\n\t\t/* if we don't know the datalen, there are still missing\n\t\t * packets. Cheaper than the check below.\n\t\t */\n\t\treturn FALSE;\n\t}\n\n\n\t/*\n\t * Check if we have received the entire fragment.\n\t * This is easy since the list is sorted and the head is faked.\n\t *\n\t * First, we compute the amount of contiguous data that's\n\t * available.  (The check for fd_i->offset <= max rules out\n\t * fragments that don't start before or at the end of the\n\t * previous fragment, i.e. fragments that have a gap between\n\t * them and the previous fragment.)\n\t */\n\tmax = 0;\n\tfor (fd_i=fd_head->next;fd_i;fd_i=fd_i->next) {\n\t\tif ( ((fd_i->offset)<=max) &&\n\t\t\t((fd_i->offset+fd_i->len)>max) ){\n\t\t\tmax = fd_i->offset+fd_i->len;\n\t\t}\n\t}\n\n\tif (max < (fd_head->datalen)) {\n\t\t/*\n\t\t * The amount of contiguous data we have is less than the\n\t\t * amount of data we're trying to reassemble, so we haven't\n\t\t * received all packets yet.\n\t\t */\n\t\treturn FALSE;\n\t}\n\n\t/* we have received an entire packet, defragment it and\n\t * free all fragments\n\t */\n\t/* store old data just in case */\n\told_tvb_data=fd_head->tvb_data;\n\tdata = (guint8 *) g_malloc(fd_head->datalen);\n\tfd_head->tvb_data = tvb_new_real_data(data, fd_head->datalen, fd_head->datalen);\n\ttvb_set_free_cb(fd_head->tvb_data, g_free);\n\n\t/* add all data fragments */\n\tfor (dfpos=0,fd_i=fd_head;fd_i;fd_i=fd_i->next) {\n\t\tif (fd_i->len) {\n\t\t\t/*\n\t\t\t * The loop above that calculates max also\n\t\t\t * ensures that the only gaps that exist here\n\t\t\t * are ones where a fragment starts past the\n\t\t\t * end of the reassembled datagram, and there's\n\t\t\t * a gap between the previous fragment and\n\t\t\t * that fragment.\n\t\t\t *\n\t\t\t * A \"DESEGMENT_UNTIL_FIN\" was involved wherein the\n\t\t\t * FIN packet had an offset less than the highest\n\t\t\t * fragment offset seen. [Seen from a fuzz-test:\n\t\t\t * bug #2470]).\n\t\t\t *\n\t\t\t * Note that the \"overlap\" compare must only be\n\t\t\t * done for fragments with (offset+len) <= fd_head->datalen\n\t\t\t * and thus within the newly g_malloc'd buffer.\n\t\t\t */\n\t\t\tif (fd_i->offset + fd_i->len > dfpos) {\n\t\t\t\tif (fd_i->offset >= fd_head->datalen) {\n\t\t\t\t\t/*\n\t\t\t\t\t * Fragment starts after the end\n\t\t\t\t\t * of the reassembled packet.\n\t\t\t\t\t *\n\t\t\t\t\t * This can happen if the length was\n\t\t\t\t\t * set after the offending fragment\n\t\t\t\t\t * was added to the reassembly.\n\t\t\t\t\t *\n\t\t\t\t\t * Flag this fragment, but don't\n\t\t\t\t\t * try to extract any data from\n\t\t\t\t\t * it, as there's no place to put\n\t\t\t\t\t * it.\n\t\t\t\t\t *\n\t\t\t\t\t * XXX - add different flag value\n\t\t\t\t\t * for this.\n\t\t\t\t\t */\n\t\t\t\t\tfd_i->flags    |= FD_TOOLONGFRAGMENT;\n\t\t\t\t\tfd_head->flags |= FD_TOOLONGFRAGMENT;\n\t\t\t\t} else if (dfpos < fd_i->offset) {\n\t\t\t\t\t/*\n\t\t\t\t\t * XXX - can this happen?  We've\n\t\t\t\t\t * already rejected fragments that\n\t\t\t\t\t * start past the end of the\n\t\t\t\t\t * reassembled datagram, and\n\t\t\t\t\t * the loop that calculated max\n\t\t\t\t\t * should have ruled out gaps,\n\t\t\t\t\t * but could fd_i->offset +\n\t\t\t\t\t * fd_i->len overflow?\n\t\t\t\t\t */\n\t\t\t\t\tfd_head->error = \"dfpos < offset\";\n\t\t\t\t} else if (dfpos - fd_i->offset > fd_i->len)\n\t\t\t\t\tfd_head->error = \"dfpos - offset > len\";\n\t\t\t\telse if (!fd_head->tvb_data)\n\t\t\t\t\tfd_head->error = \"no data\";\n\t\t\t\telse {\n\t\t\t\t\tfraglen = fd_i->len;\n\t\t\t\t\tif (fd_i->offset + fraglen > fd_head->datalen) {\n\t\t\t\t\t\t/*\n\t\t\t\t\t\t * Fragment goes past the end\n\t\t\t\t\t\t * of the packet, as indicated\n\t\t\t\t\t\t * by the last fragment.\n\t\t\t\t\t\t *\n\t\t\t\t\t\t * This can happen if the\n\t\t\t\t\t\t * length was set after the\n\t\t\t\t\t\t * offending fragment was\n\t\t\t\t\t\t * added to the reassembly.\n\t\t\t\t\t\t *\n\t\t\t\t\t\t * Mark it as such, and only\n\t\t\t\t\t\t * copy from it what fits in\n\t\t\t\t\t\t * the packet.\n\t\t\t\t\t\t */\n\t\t\t\t\t\tfd_i->flags    |= FD_TOOLONGFRAGMENT;\n\t\t\t\t\t\tfd_head->flags |= FD_TOOLONGFRAGMENT;\n\t\t\t\t\t\tfraglen = fd_head->datalen - fd_i->offset;\n\t\t\t\t\t}\n\t\t\t\t\tif (fd_i->offset < dfpos) {\n\t\t\t\t\t\tguint32 cmp_len = MIN(fd_i->len,(dfpos-fd_i->offset));\n\n\t\t\t\t\t\tfd_i->flags    |= FD_OVERLAP;\n\t\t\t\t\t\tfd_head->flags |= FD_OVERLAP;\n\t\t\t\t\t\tif ( memcmp(data + fd_i->offset,\n\t\t\t\t\t\t\t\ttvb_get_ptr(fd_i->tvb_data, 0, cmp_len),\n\t\t\t\t\t\t\t\tcmp_len)\n\t\t\t\t\t\t\t\t ) {\n\t\t\t\t\t\t\tfd_i->flags    |= FD_OVERLAPCONFLICT;\n\t\t\t\t\t\t\tfd_head->flags |= FD_OVERLAPCONFLICT;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif (fraglen < dfpos - fd_i->offset) {\n\t\t\t\t\t\t/*\n\t\t\t\t\t\t * XXX - can this happen?\n\t\t\t\t\t\t */\n\t\t\t\t\t\tfd_head->error = \"fraglen < dfpos - offset\";\n\t\t\t\t\t} else {\n\t\t\t\t\t\tmemcpy(data+dfpos,\n\t\t\t\t\t\t\ttvb_get_ptr(fd_i->tvb_data, (dfpos-fd_i->offset), fraglen-(dfpos-fd_i->offset)),\n\t\t\t\t\t\t\tfraglen-(dfpos-fd_i->offset));\n\t\t\t\t\t\tdfpos=MAX(dfpos, (fd_i->offset + fraglen));\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif (fd_i->offset + fd_i->len < fd_i->offset) {\n\t\t\t\t\t/* Integer overflow? */\n\t\t\t\t\tfd_head->error = \"offset + len < offset\";\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (fd_i->flags & FD_SUBSET_TVB)\n\t\t\t\tfd_i->flags &= ~FD_SUBSET_TVB;\n\t\t\telse if (fd_i->tvb_data)\n\t\t\t\ttvb_free(fd_i->tvb_data);\n\n\t\t\tfd_i->tvb_data=NULL;\n\t\t}\n\t}\n\n\tif (old_tvb_data)\n\t\ttvb_add_to_chain(tvb, old_tvb_data);\n\t/* mark this packet as defragmented.\n\t   allows us to skip any trailing fragments */\n\tfd_head->flags |= FD_DEFRAGMENTED;\n\tfd_head->reassembled_in=pinfo->fd->num;\n\tfd_head->reas_in_layer_num = pinfo->curr_layer_num;\n\n\t/* we don't throw until here to avoid leaking old_data and others */\n\tif (fd_head->error) {\n\t\tTHROW_MESSAGE(ReassemblyError, fd_head->error);\n\t}\n\n\treturn TRUE;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -155,9 +155,11 @@\n \n \t/* If we have reached this point, the packet is not defragmented yet.\n \t * Save all payload in a buffer until we can defragment.\n-\t * XXX - what if we didn't capture the entire fragment due\n-\t * to a too-short snapshot length?\n-\t */\n+\t */\n+\tif (!tvb_bytes_exist(tvb, offset, fd->len)) {\n+\t\tg_slice_free(fragment_item, fd);\n+\t\tTHROW(BoundsError);\n+\t}\n \tfd->tvb_data = tvb_clone_offset_len(tvb, offset, fd->len);\n \tLINK_FRAG(fd_head,fd);\n ",
        "diff_line_info": {
            "deleted_lines": [
                "\t * XXX - what if we didn't capture the entire fragment due",
                "\t * to a too-short snapshot length?",
                "\t */"
            ],
            "added_lines": [
                "\t */",
                "\tif (!tvb_bytes_exist(tvb, offset, fd->len)) {",
                "\t\tg_slice_free(fragment_item, fd);",
                "\t\tTHROW(BoundsError);",
                "\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-7441",
        "func_name": "NetworkBlockDevice/nbd/serveloop",
        "description": "The modern style negotiation in Network Block Device (nbd-server) 2.9.22 through 3.3 allows remote attackers to cause a denial of service (root process termination) by (1) closing the connection during negotiation or (2) specifying a name for a non-existent export.",
        "git_url": "https://github.com/NetworkBlockDevice/nbd/commit/741495cb08503fd32a9d22648e63b64390c601f4",
        "commit_title": "nbd-server: handle modern-style negotiation in a child process",
        "commit_text": " Previously, the modern style negotiation was carried out in the root server (listener) process before forking the actual client handler. This made it possible for a malfunctioning or evil client to terminate the root process simply by querying a non-existent export or aborting in the middle of the negotation process (caused SIGPIPE in the server).  This commit moves the negotiation process to the child to keep the root process up and running no matter what happens during the negotiation.  See http://sourceforge.net/mailarchive/message.php?msg_id=30410146 ",
        "func_before": "void serveloop(GArray* servers) {\n\tstruct sockaddr_storage addrin;\n\tsocklen_t addrinlen=sizeof(addrin);\n\tint i;\n\tint max;\n\tfd_set mset;\n\tfd_set rset;\n\n\t/* \n\t * Set up the master fd_set. The set of descriptors we need\n\t * to select() for never changes anyway and it buys us a *lot*\n\t * of time to only build this once. However, if we ever choose\n\t * to not fork() for clients anymore, we may have to revisit\n\t * this.\n\t */\n\tmax=0;\n\tFD_ZERO(&mset);\n\tfor(i=0;i<servers->len;i++) {\n\t\tint sock;\n\t\tif((sock=(g_array_index(servers, SERVER, i)).socket) >= 0) {\n\t\t\tFD_SET(sock, &mset);\n\t\t\tmax=sock>max?sock:max;\n\t\t}\n\t}\n\tfor(i=0;i<modernsocks->len;i++) {\n\t\tint sock = g_array_index(modernsocks, int, i);\n\t\tFD_SET(sock, &mset);\n\t\tmax=sock>max?sock:max;\n\t}\n\tfor(;;) {\n                /* SIGHUP causes the root server process to reconfigure\n                 * itself and add new export servers for each newly\n                 * found export configuration group, i.e. spawn new\n                 * server processes for each previously non-existent\n                 * export. This does not alter old runtime configuration\n                 * but just appends new exports. */\n                if (is_sighup_caught) {\n                        int n;\n                        GError *gerror = NULL;\n\n                        msg(LOG_INFO, \"reconfiguration request received\");\n                        is_sighup_caught = 0; /* Reset to allow catching\n                                               * it again. */\n\n                        n = append_new_servers(servers, &gerror);\n                        if (n == -1)\n                                msg(LOG_ERR, \"failed to append new servers: %s\",\n                                    gerror->message);\n\n                        for (i = servers->len - n; i < servers->len; ++i) {\n                                const SERVER server = g_array_index(servers,\n                                                                    SERVER, i);\n\n                                if (server.socket >= 0) {\n                                        FD_SET(server.socket, &mset);\n                                        max = server.socket > max ? server.socket : max;\n                                }\n\n                                msg(LOG_INFO, \"reconfigured new server: %s\",\n                                    server.servename);\n                        }\n                }\n\n\t\tmemcpy(&rset, &mset, sizeof(fd_set));\n\t\tif(select(max+1, &rset, NULL, NULL, NULL)>0) {\n\t\t\tint net;\n\n\t\t\tDEBUG(\"accept, \");\n\t\t\tfor(i=0; i < modernsocks->len; i++) {\n\t\t\t\tint sock = g_array_index(modernsocks, int, i);\n\t\t\t\tif(!FD_ISSET(sock, &rset)) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tCLIENT *client;\n\n\t\t\t\tif((net=accept(sock, (struct sockaddr *) &addrin, &addrinlen)) < 0) {\n\t\t\t\t\terr_nonfatal(\"accept: %m\");\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tclient = negotiate(net, NULL, servers, NEG_INIT | NEG_MODERN);\n\t\t\t\tif(!client) {\n\t\t\t\t\tclose(net);\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\thandle_connection(servers, net, client->server, client);\n\t\t\t}\n\t\t\tfor(i=0; i < servers->len; i++) {\n\t\t\t\tSERVER *serve;\n\n\t\t\t\tserve=&(g_array_index(servers, SERVER, i));\n\t\t\t\tif(serve->socket < 0) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tif(FD_ISSET(serve->socket, &rset)) {\n\t\t\t\t\tif ((net=accept(serve->socket, (struct sockaddr *) &addrin, &addrinlen)) < 0) {\n\t\t\t\t\t\terr_nonfatal(\"accept: %m\");\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\t\t\t\t\thandle_connection(servers, net, serve, NULL);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}",
        "func": "void serveloop(GArray* servers) {\n\tstruct sockaddr_storage addrin;\n\tsocklen_t addrinlen=sizeof(addrin);\n\tint i;\n\tint max;\n\tfd_set mset;\n\tfd_set rset;\n\n\t/* \n\t * Set up the master fd_set. The set of descriptors we need\n\t * to select() for never changes anyway and it buys us a *lot*\n\t * of time to only build this once. However, if we ever choose\n\t * to not fork() for clients anymore, we may have to revisit\n\t * this.\n\t */\n\tmax=0;\n\tFD_ZERO(&mset);\n\tfor(i=0;i<servers->len;i++) {\n\t\tint sock;\n\t\tif((sock=(g_array_index(servers, SERVER, i)).socket) >= 0) {\n\t\t\tFD_SET(sock, &mset);\n\t\t\tmax=sock>max?sock:max;\n\t\t}\n\t}\n\tfor(i=0;i<modernsocks->len;i++) {\n\t\tint sock = g_array_index(modernsocks, int, i);\n\t\tFD_SET(sock, &mset);\n\t\tmax=sock>max?sock:max;\n\t}\n\tfor(;;) {\n                /* SIGHUP causes the root server process to reconfigure\n                 * itself and add new export servers for each newly\n                 * found export configuration group, i.e. spawn new\n                 * server processes for each previously non-existent\n                 * export. This does not alter old runtime configuration\n                 * but just appends new exports. */\n                if (is_sighup_caught) {\n                        int n;\n                        GError *gerror = NULL;\n\n                        msg(LOG_INFO, \"reconfiguration request received\");\n                        is_sighup_caught = 0; /* Reset to allow catching\n                                               * it again. */\n\n                        n = append_new_servers(servers, &gerror);\n                        if (n == -1)\n                                msg(LOG_ERR, \"failed to append new servers: %s\",\n                                    gerror->message);\n\n                        for (i = servers->len - n; i < servers->len; ++i) {\n                                const SERVER server = g_array_index(servers,\n                                                                    SERVER, i);\n\n                                if (server.socket >= 0) {\n                                        FD_SET(server.socket, &mset);\n                                        max = server.socket > max ? server.socket : max;\n                                }\n\n                                msg(LOG_INFO, \"reconfigured new server: %s\",\n                                    server.servename);\n                        }\n                }\n\n\t\tmemcpy(&rset, &mset, sizeof(fd_set));\n\t\tif(select(max+1, &rset, NULL, NULL, NULL)>0) {\n\n\t\t\tDEBUG(\"accept, \");\n\t\t\tfor(i=0; i < modernsocks->len; i++) {\n\t\t\t\tint sock = g_array_index(modernsocks, int, i);\n\t\t\t\tif(!FD_ISSET(sock, &rset)) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\n\t\t\t\thandle_modern_connection(servers, sock);\n\t\t\t}\n\t\t\tfor(i=0; i < servers->len; i++) {\n\t\t\t\tint net;\n\t\t\t\tSERVER *serve;\n\n\t\t\t\tserve=&(g_array_index(servers, SERVER, i));\n\t\t\t\tif(serve->socket < 0) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tif(FD_ISSET(serve->socket, &rset)) {\n\t\t\t\t\tif ((net=accept(serve->socket, (struct sockaddr *) &addrin, &addrinlen)) < 0) {\n\t\t\t\t\t\terr_nonfatal(\"accept: %m\");\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\t\t\t\t\thandle_connection(servers, net, serve, NULL);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -63,7 +63,6 @@\n \n \t\tmemcpy(&rset, &mset, sizeof(fd_set));\n \t\tif(select(max+1, &rset, NULL, NULL, NULL)>0) {\n-\t\t\tint net;\n \n \t\t\tDEBUG(\"accept, \");\n \t\t\tfor(i=0; i < modernsocks->len; i++) {\n@@ -71,20 +70,11 @@\n \t\t\t\tif(!FD_ISSET(sock, &rset)) {\n \t\t\t\t\tcontinue;\n \t\t\t\t}\n-\t\t\t\tCLIENT *client;\n \n-\t\t\t\tif((net=accept(sock, (struct sockaddr *) &addrin, &addrinlen)) < 0) {\n-\t\t\t\t\terr_nonfatal(\"accept: %m\");\n-\t\t\t\t\tcontinue;\n-\t\t\t\t}\n-\t\t\t\tclient = negotiate(net, NULL, servers, NEG_INIT | NEG_MODERN);\n-\t\t\t\tif(!client) {\n-\t\t\t\t\tclose(net);\n-\t\t\t\t\tcontinue;\n-\t\t\t\t}\n-\t\t\t\thandle_connection(servers, net, client->server, client);\n+\t\t\t\thandle_modern_connection(servers, sock);\n \t\t\t}\n \t\t\tfor(i=0; i < servers->len; i++) {\n+\t\t\t\tint net;\n \t\t\t\tSERVER *serve;\n \n \t\t\t\tserve=&(g_array_index(servers, SERVER, i));",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\tint net;",
                "\t\t\t\tCLIENT *client;",
                "\t\t\t\tif((net=accept(sock, (struct sockaddr *) &addrin, &addrinlen)) < 0) {",
                "\t\t\t\t\terr_nonfatal(\"accept: %m\");",
                "\t\t\t\t\tcontinue;",
                "\t\t\t\t}",
                "\t\t\t\tclient = negotiate(net, NULL, servers, NEG_INIT | NEG_MODERN);",
                "\t\t\t\tif(!client) {",
                "\t\t\t\t\tclose(net);",
                "\t\t\t\t\tcontinue;",
                "\t\t\t\t}",
                "\t\t\t\thandle_connection(servers, net, client->server, client);"
            ],
            "added_lines": [
                "\t\t\t\thandle_modern_connection(servers, sock);",
                "\t\t\t\tint net;"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-4024",
        "func_name": "php/php-src/multipart_buffer_headers",
        "description": "Algorithmic complexity vulnerability in the multipart_buffer_headers function in main/rfc1867.c in PHP before 5.4.41, 5.5.x before 5.5.25, and 5.6.x before 5.6.9 allows remote attackers to cause a denial of service (CPU consumption) via crafted form data that triggers an improper order-of-growth outcome.",
        "git_url": "https://github.com/php/php-src/commit/4605d536d23b00813d11cc906bb48d39bdcf5f25",
        "commit_title": "Fixed bug #69364 - use smart_str to assemble strings",
        "commit_text": "",
        "func_before": "static int multipart_buffer_headers(multipart_buffer *self, zend_llist *header TSRMLS_DC)\n{\n\tchar *line;\n\tmime_header_entry prev_entry = {0}, entry;\n\tint prev_len, cur_len;\n\n\t/* didn't find boundary, abort */\n\tif (!find_boundary(self, self->boundary TSRMLS_CC)) {\n\t\treturn 0;\n\t}\n\n\t/* get lines of text, or CRLF_CRLF */\n\n\twhile( (line = get_line(self TSRMLS_CC)) && strlen(line) > 0 )\n\t{\n\t\t/* add header to table */\n\t\tchar *key = line;\n\t\tchar *value = NULL;\n\n\t\tif (php_rfc1867_encoding_translation(TSRMLS_C)) {\n\t\t\tself->input_encoding = zend_multibyte_encoding_detector(line, strlen(line), self->detect_order, self->detect_order_size TSRMLS_CC);\n\t\t}\n\n\t\t/* space in the beginning means same header */\n\t\tif (!isspace(line[0])) {\n\t\t\tvalue = strchr(line, ':');\n\t\t}\n\n\t\tif (value) {\n\t\t\t*value = 0;\n\t\t\tdo { value++; } while(isspace(*value));\n\n\t\t\tentry.value = estrdup(value);\n\t\t\tentry.key = estrdup(key);\n\n\t\t} else if (zend_llist_count(header)) { /* If no ':' on the line, add to previous line */\n\n\t\t\tprev_len = strlen(prev_entry.value);\n\t\t\tcur_len = strlen(line);\n\n\t\t\tentry.value = emalloc(prev_len + cur_len + 1);\n\t\t\tmemcpy(entry.value, prev_entry.value, prev_len);\n\t\t\tmemcpy(entry.value + prev_len, line, cur_len);\n\t\t\tentry.value[cur_len + prev_len] = '\\0';\n\n\t\t\tentry.key = estrdup(prev_entry.key);\n\n\t\t\tzend_llist_remove_tail(header);\n\t\t} else {\n\t\t\tcontinue;\n\t\t}\n\n\t\tzend_llist_add_element(header, &entry);\n\t\tprev_entry = entry;\n\t}\n\n\treturn 1;\n}",
        "func": "static int multipart_buffer_headers(multipart_buffer *self, zend_llist *header TSRMLS_DC)\n{\n\tchar *line;\n\tmime_header_entry entry = {0};\n\tsmart_str buf_value = {0};\n\tchar *key = NULL;\n\n\t/* didn't find boundary, abort */\n\tif (!find_boundary(self, self->boundary TSRMLS_CC)) {\n\t\treturn 0;\n\t}\n\n\t/* get lines of text, or CRLF_CRLF */\n\n\twhile( (line = get_line(self TSRMLS_CC)) && strlen(line) > 0 )\n\t{\n\t\t/* add header to table */\n\t\tchar *value = NULL;\n\n\t\tif (php_rfc1867_encoding_translation(TSRMLS_C)) {\n\t\t\tself->input_encoding = zend_multibyte_encoding_detector((unsigned char *)line, strlen(line), self->detect_order, self->detect_order_size TSRMLS_CC);\n\t\t}\n\n\t\t/* space in the beginning means same header */\n\t\tif (!isspace(line[0])) {\n\t\t\tvalue = strchr(line, ':');\n\t\t}\n\n\t\tif (value) {\n\t\t\tif(buf_value.c && key) {\n\t\t\t\t/* new entry, add the old one to the list */\n\t\t\t\tsmart_str_0(&buf_value);\n\t\t\t\tentry.key = key;\n\t\t\t\tentry.value = buf_value.c;\n\t\t\t\tzend_llist_add_element(header, &entry);\n\t\t\t\tbuf_value.c = NULL;\n\t\t\t\tkey = NULL;\n\t\t\t}\n\n\t\t\t*value = '\\0';\n\t\t\tdo { value++; } while(isspace(*value));\n\n\t\t\tkey = estrdup(line);\n\t\t\tsmart_str_appends(&buf_value, value);\n\t\t} else if (buf_value.c) { /* If no ':' on the line, add to previous line */\n\t\t\tsmart_str_appends(&buf_value, line);\n\t\t} else {\n\t\t\tcontinue;\n\t\t}\n\t}\n\tif(buf_value.c && key) {\n\t\t/* add the last one to the list */\n\t\tsmart_str_0(&buf_value);\n\t\tentry.key = key;\n\t\tentry.value = buf_value.c;\n\t\tzend_llist_add_element(header, &entry);\n\t}\n\n\treturn 1;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,8 +1,9 @@\n static int multipart_buffer_headers(multipart_buffer *self, zend_llist *header TSRMLS_DC)\n {\n \tchar *line;\n-\tmime_header_entry prev_entry = {0}, entry;\n-\tint prev_len, cur_len;\n+\tmime_header_entry entry = {0};\n+\tsmart_str buf_value = {0};\n+\tchar *key = NULL;\n \n \t/* didn't find boundary, abort */\n \tif (!find_boundary(self, self->boundary TSRMLS_CC)) {\n@@ -14,11 +15,10 @@\n \twhile( (line = get_line(self TSRMLS_CC)) && strlen(line) > 0 )\n \t{\n \t\t/* add header to table */\n-\t\tchar *key = line;\n \t\tchar *value = NULL;\n \n \t\tif (php_rfc1867_encoding_translation(TSRMLS_C)) {\n-\t\t\tself->input_encoding = zend_multibyte_encoding_detector(line, strlen(line), self->detect_order, self->detect_order_size TSRMLS_CC);\n+\t\t\tself->input_encoding = zend_multibyte_encoding_detector((unsigned char *)line, strlen(line), self->detect_order, self->detect_order_size TSRMLS_CC);\n \t\t}\n \n \t\t/* space in the beginning means same header */\n@@ -27,31 +27,33 @@\n \t\t}\n \n \t\tif (value) {\n-\t\t\t*value = 0;\n+\t\t\tif(buf_value.c && key) {\n+\t\t\t\t/* new entry, add the old one to the list */\n+\t\t\t\tsmart_str_0(&buf_value);\n+\t\t\t\tentry.key = key;\n+\t\t\t\tentry.value = buf_value.c;\n+\t\t\t\tzend_llist_add_element(header, &entry);\n+\t\t\t\tbuf_value.c = NULL;\n+\t\t\t\tkey = NULL;\n+\t\t\t}\n+\n+\t\t\t*value = '\\0';\n \t\t\tdo { value++; } while(isspace(*value));\n \n-\t\t\tentry.value = estrdup(value);\n-\t\t\tentry.key = estrdup(key);\n-\n-\t\t} else if (zend_llist_count(header)) { /* If no ':' on the line, add to previous line */\n-\n-\t\t\tprev_len = strlen(prev_entry.value);\n-\t\t\tcur_len = strlen(line);\n-\n-\t\t\tentry.value = emalloc(prev_len + cur_len + 1);\n-\t\t\tmemcpy(entry.value, prev_entry.value, prev_len);\n-\t\t\tmemcpy(entry.value + prev_len, line, cur_len);\n-\t\t\tentry.value[cur_len + prev_len] = '\\0';\n-\n-\t\t\tentry.key = estrdup(prev_entry.key);\n-\n-\t\t\tzend_llist_remove_tail(header);\n+\t\t\tkey = estrdup(line);\n+\t\t\tsmart_str_appends(&buf_value, value);\n+\t\t} else if (buf_value.c) { /* If no ':' on the line, add to previous line */\n+\t\t\tsmart_str_appends(&buf_value, line);\n \t\t} else {\n \t\t\tcontinue;\n \t\t}\n-\n+\t}\n+\tif(buf_value.c && key) {\n+\t\t/* add the last one to the list */\n+\t\tsmart_str_0(&buf_value);\n+\t\tentry.key = key;\n+\t\tentry.value = buf_value.c;\n \t\tzend_llist_add_element(header, &entry);\n-\t\tprev_entry = entry;\n \t}\n \n \treturn 1;",
        "diff_line_info": {
            "deleted_lines": [
                "\tmime_header_entry prev_entry = {0}, entry;",
                "\tint prev_len, cur_len;",
                "\t\tchar *key = line;",
                "\t\t\tself->input_encoding = zend_multibyte_encoding_detector(line, strlen(line), self->detect_order, self->detect_order_size TSRMLS_CC);",
                "\t\t\t*value = 0;",
                "\t\t\tentry.value = estrdup(value);",
                "\t\t\tentry.key = estrdup(key);",
                "",
                "\t\t} else if (zend_llist_count(header)) { /* If no ':' on the line, add to previous line */",
                "",
                "\t\t\tprev_len = strlen(prev_entry.value);",
                "\t\t\tcur_len = strlen(line);",
                "",
                "\t\t\tentry.value = emalloc(prev_len + cur_len + 1);",
                "\t\t\tmemcpy(entry.value, prev_entry.value, prev_len);",
                "\t\t\tmemcpy(entry.value + prev_len, line, cur_len);",
                "\t\t\tentry.value[cur_len + prev_len] = '\\0';",
                "",
                "\t\t\tentry.key = estrdup(prev_entry.key);",
                "",
                "\t\t\tzend_llist_remove_tail(header);",
                "",
                "\t\tprev_entry = entry;"
            ],
            "added_lines": [
                "\tmime_header_entry entry = {0};",
                "\tsmart_str buf_value = {0};",
                "\tchar *key = NULL;",
                "\t\t\tself->input_encoding = zend_multibyte_encoding_detector((unsigned char *)line, strlen(line), self->detect_order, self->detect_order_size TSRMLS_CC);",
                "\t\t\tif(buf_value.c && key) {",
                "\t\t\t\t/* new entry, add the old one to the list */",
                "\t\t\t\tsmart_str_0(&buf_value);",
                "\t\t\t\tentry.key = key;",
                "\t\t\t\tentry.value = buf_value.c;",
                "\t\t\t\tzend_llist_add_element(header, &entry);",
                "\t\t\t\tbuf_value.c = NULL;",
                "\t\t\t\tkey = NULL;",
                "\t\t\t}",
                "",
                "\t\t\t*value = '\\0';",
                "\t\t\tkey = estrdup(line);",
                "\t\t\tsmart_str_appends(&buf_value, value);",
                "\t\t} else if (buf_value.c) { /* If no ':' on the line, add to previous line */",
                "\t\t\tsmart_str_appends(&buf_value, line);",
                "\t}",
                "\tif(buf_value.c && key) {",
                "\t\t/* add the last one to the list */",
                "\t\tsmart_str_0(&buf_value);",
                "\t\tentry.key = key;",
                "\t\tentry.value = buf_value.c;"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-4024",
        "func_name": "php/php-src/SAPI_POST_HANDLER_FUNC",
        "description": "Algorithmic complexity vulnerability in the multipart_buffer_headers function in main/rfc1867.c in PHP before 5.4.41, 5.5.x before 5.5.25, and 5.6.x before 5.6.9 allows remote attackers to cause a denial of service (CPU consumption) via crafted form data that triggers an improper order-of-growth outcome.",
        "git_url": "https://github.com/php/php-src/commit/4605d536d23b00813d11cc906bb48d39bdcf5f25",
        "commit_title": "Fixed bug #69364 - use smart_str to assemble strings",
        "commit_text": "",
        "func_before": "SAPI_API SAPI_POST_HANDLER_FUNC(rfc1867_post_handler) /* {{{ */\n{\n\tchar *boundary, *s = NULL, *boundary_end = NULL, *start_arr = NULL, *array_index = NULL;\n\tchar *temp_filename = NULL, *lbuf = NULL, *abuf = NULL;\n\tint boundary_len = 0, total_bytes = 0, cancel_upload = 0, is_arr_upload = 0, array_len = 0;\n\tint max_file_size = 0, skip_upload = 0, anonindex = 0, is_anonymous;\n\tzval *http_post_files = NULL;\n\tHashTable *uploaded_files = NULL;\n\tmultipart_buffer *mbuff;\n\tzval *array_ptr = (zval *) arg;\n\tint fd = -1;\n\tzend_llist header;\n\tvoid *event_extra_data = NULL;\n\tunsigned int llen = 0;\n\tint upload_cnt = INI_INT(\"max_file_uploads\");\n\tconst zend_encoding *internal_encoding = zend_multibyte_get_internal_encoding(TSRMLS_C);\n\tphp_rfc1867_getword_t getword;\n\tphp_rfc1867_getword_conf_t getword_conf;\n\tphp_rfc1867_basename_t _basename;\n\tlong count = 0;\n\n\tif (php_rfc1867_encoding_translation(TSRMLS_C) && internal_encoding) {\n\t\tgetword = php_rfc1867_getword;\n\t\tgetword_conf = php_rfc1867_getword_conf;\n\t\t_basename = php_rfc1867_basename;\n\t} else {\n\t\tgetword = php_ap_getword;\n\t\tgetword_conf = php_ap_getword_conf;\n\t\t_basename = php_ap_basename;\n\t}\n\n\tif (SG(post_max_size) > 0 && SG(request_info).content_length > SG(post_max_size)) {\n\t\tsapi_module.sapi_error(E_WARNING, \"POST Content-Length of %ld bytes exceeds the limit of %ld bytes\", SG(request_info).content_length, SG(post_max_size));\n\t\treturn;\n\t}\n\n\t/* Get the boundary */\n\tboundary = strstr(content_type_dup, \"boundary\");\n\tif (!boundary) {\n\t\tint content_type_len = strlen(content_type_dup);\n\t\tchar *content_type_lcase = estrndup(content_type_dup, content_type_len);\n\n\t\tphp_strtolower(content_type_lcase, content_type_len);\n\t\tboundary = strstr(content_type_lcase, \"boundary\");\n\t\tif (boundary) {\n\t\t\tboundary = content_type_dup + (boundary - content_type_lcase);\n\t\t}\n\t\tefree(content_type_lcase);\n\t}\n\n\tif (!boundary || !(boundary = strchr(boundary, '='))) {\n\t\tsapi_module.sapi_error(E_WARNING, \"Missing boundary in multipart/form-data POST data\");\n\t\treturn;\n\t}\n\n\tboundary++;\n\tboundary_len = strlen(boundary);\n\n\tif (boundary[0] == '\"') {\n\t\tboundary++;\n\t\tboundary_end = strchr(boundary, '\"');\n\t\tif (!boundary_end) {\n\t\t\tsapi_module.sapi_error(E_WARNING, \"Invalid boundary in multipart/form-data POST data\");\n\t\t\treturn;\n\t\t}\n\t} else {\n\t\t/* search for the end of the boundary */\n\t\tboundary_end = strpbrk(boundary, \",;\");\n\t}\n\tif (boundary_end) {\n\t\tboundary_end[0] = '\\0';\n\t\tboundary_len = boundary_end-boundary;\n\t}\n\n\t/* Initialize the buffer */\n\tif (!(mbuff = multipart_buffer_new(boundary, boundary_len TSRMLS_CC))) {\n\t\tsapi_module.sapi_error(E_WARNING, \"Unable to initialize the input buffer\");\n\t\treturn;\n\t}\n\n\t/* Initialize $_FILES[] */\n\tzend_hash_init(&PG(rfc1867_protected_variables), 5, NULL, NULL, 0);\n\n\tALLOC_HASHTABLE(uploaded_files);\n\tzend_hash_init(uploaded_files, 5, NULL, (dtor_func_t) free_estring, 0);\n\tSG(rfc1867_uploaded_files) = uploaded_files;\n\n\tALLOC_ZVAL(http_post_files);\n\tarray_init(http_post_files);\n\tINIT_PZVAL(http_post_files);\n\tPG(http_globals)[TRACK_VARS_FILES] = http_post_files;\n\n\tzend_llist_init(&header, sizeof(mime_header_entry), (llist_dtor_func_t) php_free_hdr_entry, 0);\n\n\tif (php_rfc1867_callback != NULL) {\n\t\tmultipart_event_start event_start;\n\n\t\tevent_start.content_length = SG(request_info).content_length;\n\t\tif (php_rfc1867_callback(MULTIPART_EVENT_START, &event_start, &event_extra_data TSRMLS_CC) == FAILURE) {\n\t\t\tgoto fileupload_done;\n\t\t}\n\t}\n\n\twhile (!multipart_buffer_eof(mbuff TSRMLS_CC))\n\t{\n\t\tchar buff[FILLUNIT];\n\t\tchar *cd = NULL, *param = NULL, *filename = NULL, *tmp = NULL;\n\t\tsize_t blen = 0, wlen = 0;\n\t\toff_t offset;\n\n\t\tzend_llist_clean(&header);\n\n\t\tif (!multipart_buffer_headers(mbuff, &header TSRMLS_CC)) {\n\t\t\tgoto fileupload_done;\n\t\t}\n\n\t\tif ((cd = php_mime_get_hdr_value(header, \"Content-Disposition\"))) {\n\t\t\tchar *pair = NULL;\n\t\t\tint end = 0;\n\n\t\t\twhile (isspace(*cd)) {\n\t\t\t\t++cd;\n\t\t\t}\n\n\t\t\twhile (*cd && (pair = getword(mbuff->input_encoding, &cd, ';' TSRMLS_CC)))\n\t\t\t{\n\t\t\t\tchar *key = NULL, *word = pair;\n\n\t\t\t\twhile (isspace(*cd)) {\n\t\t\t\t\t++cd;\n\t\t\t\t}\n\n\t\t\t\tif (strchr(pair, '=')) {\n\t\t\t\t\tkey = getword(mbuff->input_encoding, &pair, '=' TSRMLS_CC);\n\n\t\t\t\t\tif (!strcasecmp(key, \"name\")) {\n\t\t\t\t\t\tif (param) {\n\t\t\t\t\t\t\tefree(param);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tparam = getword_conf(mbuff->input_encoding, pair TSRMLS_CC);\n\t\t\t\t\t\tif (mbuff->input_encoding && internal_encoding) {\n\t\t\t\t\t\t\tunsigned char *new_param;\n\t\t\t\t\t\t\tsize_t new_param_len;\n\t\t\t\t\t\t\tif ((size_t)-1 != zend_multibyte_encoding_converter(&new_param, &new_param_len, (unsigned char *)param, strlen(param), internal_encoding, mbuff->input_encoding TSRMLS_CC)) {\n\t\t\t\t\t\t\t\tefree(param);\n\t\t\t\t\t\t\t\tparam = (char *)new_param;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t} else if (!strcasecmp(key, \"filename\")) {\n\t\t\t\t\t\tif (filename) {\n\t\t\t\t\t\t\tefree(filename);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tfilename = getword_conf(mbuff->input_encoding, pair TSRMLS_CC);\n\t\t\t\t\t\tif (mbuff->input_encoding && internal_encoding) {\n\t\t\t\t\t\t\tunsigned char *new_filename;\n\t\t\t\t\t\t\tsize_t new_filename_len;\n\t\t\t\t\t\t\tif ((size_t)-1 != zend_multibyte_encoding_converter(&new_filename, &new_filename_len, (unsigned char *)filename, strlen(filename), internal_encoding, mbuff->input_encoding TSRMLS_CC)) {\n\t\t\t\t\t\t\t\tefree(filename);\n\t\t\t\t\t\t\t\tfilename = (char *)new_filename;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (key) {\n\t\t\t\t\tefree(key);\n\t\t\t\t}\n\t\t\t\tefree(word);\n\t\t\t}\n\n\t\t\t/* Normal form variable, safe to read all data into memory */\n\t\t\tif (!filename && param) {\n\t\t\t\tunsigned int value_len;\n\t\t\t\tchar *value = multipart_buffer_read_body(mbuff, &value_len TSRMLS_CC);\n\t\t\t\tunsigned int new_val_len; /* Dummy variable */\n\n\t\t\t\tif (!value) {\n\t\t\t\t\tvalue = estrdup(\"\");\n\t\t\t\t\tvalue_len = 0;\n\t\t\t\t}\n\n\t\t\t\tif (mbuff->input_encoding && internal_encoding) {\n\t\t\t\t\tunsigned char *new_value;\n\t\t\t\t\tsize_t new_value_len;\n\t\t\t\t\tif ((size_t)-1 != zend_multibyte_encoding_converter(&new_value, &new_value_len, (unsigned char *)value, value_len, internal_encoding, mbuff->input_encoding TSRMLS_CC)) {\n\t\t\t\t\t\tefree(value);\n\t\t\t\t\t\tvalue = (char *)new_value;\n\t\t\t\t\t\tvalue_len = new_value_len;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif (++count <= PG(max_input_vars) && sapi_module.input_filter(PARSE_POST, param, &value, value_len, &new_val_len TSRMLS_CC)) {\n\t\t\t\t\tif (php_rfc1867_callback != NULL) {\n\t\t\t\t\t\tmultipart_event_formdata event_formdata;\n\t\t\t\t\t\tsize_t newlength = new_val_len;\n\n\t\t\t\t\t\tevent_formdata.post_bytes_processed = SG(read_post_bytes);\n\t\t\t\t\t\tevent_formdata.name = param;\n\t\t\t\t\t\tevent_formdata.value = &value;\n\t\t\t\t\t\tevent_formdata.length = new_val_len;\n\t\t\t\t\t\tevent_formdata.newlength = &newlength;\n\t\t\t\t\t\tif (php_rfc1867_callback(MULTIPART_EVENT_FORMDATA, &event_formdata, &event_extra_data TSRMLS_CC) == FAILURE) {\n\t\t\t\t\t\t\tefree(param);\n\t\t\t\t\t\t\tefree(value);\n\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tnew_val_len = newlength;\n\t\t\t\t\t}\n\t\t\t\t\tsafe_php_register_variable(param, value, new_val_len, array_ptr, 0 TSRMLS_CC);\n\t\t\t\t} else {\n\t\t\t\t\tif (count == PG(max_input_vars) + 1) {\n\t\t\t\t\t\tphp_error_docref(NULL TSRMLS_CC, E_WARNING, \"Input variables exceeded %ld. To increase the limit change max_input_vars in php.ini.\", PG(max_input_vars));\n\t\t\t\t\t}\n\t\t\t\t\n\t\t\t\t\tif (php_rfc1867_callback != NULL) {\n\t\t\t\t\t\tmultipart_event_formdata event_formdata;\n\n\t\t\t\t\t\tevent_formdata.post_bytes_processed = SG(read_post_bytes);\n\t\t\t\t\t\tevent_formdata.name = param;\n\t\t\t\t\t\tevent_formdata.value = &value;\n\t\t\t\t\t\tevent_formdata.length = value_len;\n\t\t\t\t\t\tevent_formdata.newlength = NULL;\n\t\t\t\t\t\tphp_rfc1867_callback(MULTIPART_EVENT_FORMDATA, &event_formdata, &event_extra_data TSRMLS_CC);\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif (!strcasecmp(param, \"MAX_FILE_SIZE\")) {\n\t\t\t\t\tmax_file_size = atol(value);\n\t\t\t\t}\n\n\t\t\t\tefree(param);\n\t\t\t\tefree(value);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\t/* If file_uploads=off, skip the file part */\n\t\t\tif (!PG(file_uploads)) {\n\t\t\t\tskip_upload = 1;\n\t\t\t} else if (upload_cnt <= 0) {\n\t\t\t\tskip_upload = 1;\n\t\t\t\tsapi_module.sapi_error(E_WARNING, \"Maximum number of allowable file uploads has been exceeded\");\n\t\t\t}\n\n\t\t\t/* Return with an error if the posted data is garbled */\n\t\t\tif (!param && !filename) {\n\t\t\t\tsapi_module.sapi_error(E_WARNING, \"File Upload Mime headers garbled\");\n\t\t\t\tgoto fileupload_done;\n\t\t\t}\n\n\t\t\tif (!param) {\n\t\t\t\tis_anonymous = 1;\n\t\t\t\tparam = emalloc(MAX_SIZE_ANONNAME);\n\t\t\t\tsnprintf(param, MAX_SIZE_ANONNAME, \"%u\", anonindex++);\n\t\t\t} else {\n\t\t\t\tis_anonymous = 0;\n\t\t\t}\n\n\t\t\t/* New Rule: never repair potential malicious user input */\n\t\t\tif (!skip_upload) {\n\t\t\t\tlong c = 0;\n\t\t\t\ttmp = param;\n\n\t\t\t\twhile (*tmp) {\n\t\t\t\t\tif (*tmp == '[') {\n\t\t\t\t\t\tc++;\n\t\t\t\t\t} else if (*tmp == ']') {\n\t\t\t\t\t\tc--;\n\t\t\t\t\t\tif (tmp[1] && tmp[1] != '[') {\n\t\t\t\t\t\t\tskip_upload = 1;\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif (c < 0) {\n\t\t\t\t\t\tskip_upload = 1;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t\ttmp++;\n\t\t\t\t}\n\t\t\t\t/* Brackets should always be closed */\n\t\t\t\tif(c != 0) {\n\t\t\t\t\tskip_upload = 1;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\ttotal_bytes = cancel_upload = 0;\n\t\t\ttemp_filename = NULL;\n\t\t\tfd = -1;\n\n\t\t\tif (!skip_upload && php_rfc1867_callback != NULL) {\n\t\t\t\tmultipart_event_file_start event_file_start;\n\n\t\t\t\tevent_file_start.post_bytes_processed = SG(read_post_bytes);\n\t\t\t\tevent_file_start.name = param;\n\t\t\t\tevent_file_start.filename = &filename;\n\t\t\t\tif (php_rfc1867_callback(MULTIPART_EVENT_FILE_START, &event_file_start, &event_extra_data TSRMLS_CC) == FAILURE) {\n\t\t\t\t\ttemp_filename = \"\";\n\t\t\t\t\tefree(param);\n\t\t\t\t\tefree(filename);\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (skip_upload) {\n\t\t\t\tefree(param);\n\t\t\t\tefree(filename);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (strlen(filename) == 0) {\n#if DEBUG_FILE_UPLOAD\n\t\t\t\tsapi_module.sapi_error(E_NOTICE, \"No file uploaded\");\n#endif\n\t\t\t\tcancel_upload = UPLOAD_ERROR_D;\n\t\t\t}\n\n\t\t\toffset = 0;\n\t\t\tend = 0;\n\n\t\t\tif (!cancel_upload) {\n\t\t\t\t/* only bother to open temp file if we have data */\n\t\t\t\tblen = multipart_buffer_read(mbuff, buff, sizeof(buff), &end TSRMLS_CC);\n#if DEBUG_FILE_UPLOAD\n\t\t\t\tif (blen > 0) {\n#else\n\t\t\t\t/* in non-debug mode we have no problem with 0-length files */\n\t\t\t\t{\n#endif\n\t\t\t\t\tfd = php_open_temporary_fd_ex(PG(upload_tmp_dir), \"php\", &temp_filename, 1 TSRMLS_CC);\n\t\t\t\t\tupload_cnt--;\n\t\t\t\t\tif (fd == -1) {\n\t\t\t\t\t\tsapi_module.sapi_error(E_WARNING, \"File upload error - unable to create a temporary file\");\n\t\t\t\t\t\tcancel_upload = UPLOAD_ERROR_E;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\twhile (!cancel_upload && (blen > 0))\n\t\t\t{\n\t\t\t\tif (php_rfc1867_callback != NULL) {\n\t\t\t\t\tmultipart_event_file_data event_file_data;\n\n\t\t\t\t\tevent_file_data.post_bytes_processed = SG(read_post_bytes);\n\t\t\t\t\tevent_file_data.offset = offset;\n\t\t\t\t\tevent_file_data.data = buff;\n\t\t\t\t\tevent_file_data.length = blen;\n\t\t\t\t\tevent_file_data.newlength = &blen;\n\t\t\t\t\tif (php_rfc1867_callback(MULTIPART_EVENT_FILE_DATA, &event_file_data, &event_extra_data TSRMLS_CC) == FAILURE) {\n\t\t\t\t\t\tcancel_upload = UPLOAD_ERROR_X;\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif (PG(upload_max_filesize) > 0 && (long)(total_bytes+blen) > PG(upload_max_filesize)) {\n#if DEBUG_FILE_UPLOAD\n\t\t\t\t\tsapi_module.sapi_error(E_NOTICE, \"upload_max_filesize of %ld bytes exceeded - file [%s=%s] not saved\", PG(upload_max_filesize), param, filename);\n#endif\n\t\t\t\t\tcancel_upload = UPLOAD_ERROR_A;\n\t\t\t\t} else if (max_file_size && ((long)(total_bytes+blen) > max_file_size)) {\n#if DEBUG_FILE_UPLOAD\n\t\t\t\t\tsapi_module.sapi_error(E_NOTICE, \"MAX_FILE_SIZE of %ld bytes exceeded - file [%s=%s] not saved\", max_file_size, param, filename);\n#endif\n\t\t\t\t\tcancel_upload = UPLOAD_ERROR_B;\n\t\t\t\t} else if (blen > 0) {\n\t\t\t\t\twlen = write(fd, buff, blen);\n\n\t\t\t\t\tif (wlen == -1) {\n\t\t\t\t\t\t/* write failed */\n#if DEBUG_FILE_UPLOAD\n\t\t\t\t\t\tsapi_module.sapi_error(E_NOTICE, \"write() failed - %s\", strerror(errno));\n#endif\n\t\t\t\t\t\tcancel_upload = UPLOAD_ERROR_F;\n\t\t\t\t\t} else if (wlen < blen) {\n#if DEBUG_FILE_UPLOAD\n\t\t\t\t\t\tsapi_module.sapi_error(E_NOTICE, \"Only %d bytes were written, expected to write %d\", wlen, blen);\n#endif\n\t\t\t\t\t\tcancel_upload = UPLOAD_ERROR_F;\n\t\t\t\t\t} else {\n\t\t\t\t\t\ttotal_bytes += wlen;\n\t\t\t\t\t}\n\t\t\t\t\toffset += wlen;\n\t\t\t\t}\n\n\t\t\t\t/* read data for next iteration */\n\t\t\t\tblen = multipart_buffer_read(mbuff, buff, sizeof(buff), &end TSRMLS_CC);\n\t\t\t}\n\n\t\t\tif (fd != -1) { /* may not be initialized if file could not be created */\n\t\t\t\tclose(fd);\n\t\t\t}\n\n\t\t\tif (!cancel_upload && !end) {\n#if DEBUG_FILE_UPLOAD\n\t\t\t\tsapi_module.sapi_error(E_NOTICE, \"Missing mime boundary at the end of the data for file %s\", strlen(filename) > 0 ? filename : \"\");\n#endif\n\t\t\t\tcancel_upload = UPLOAD_ERROR_C;\n\t\t\t}\n#if DEBUG_FILE_UPLOAD\n\t\t\tif (strlen(filename) > 0 && total_bytes == 0 && !cancel_upload) {\n\t\t\t\tsapi_module.sapi_error(E_WARNING, \"Uploaded file size 0 - file [%s=%s] not saved\", param, filename);\n\t\t\t\tcancel_upload = 5;\n\t\t\t}\n#endif\n\t\t\tif (php_rfc1867_callback != NULL) {\n\t\t\t\tmultipart_event_file_end event_file_end;\n\n\t\t\t\tevent_file_end.post_bytes_processed = SG(read_post_bytes);\n\t\t\t\tevent_file_end.temp_filename = temp_filename;\n\t\t\t\tevent_file_end.cancel_upload = cancel_upload;\n\t\t\t\tif (php_rfc1867_callback(MULTIPART_EVENT_FILE_END, &event_file_end, &event_extra_data TSRMLS_CC) == FAILURE) {\n\t\t\t\t\tcancel_upload = UPLOAD_ERROR_X;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (cancel_upload) {\n\t\t\t\tif (temp_filename) {\n\t\t\t\t\tif (cancel_upload != UPLOAD_ERROR_E) { /* file creation failed */\n\t\t\t\t\t\tunlink(temp_filename);\n\t\t\t\t\t}\n\t\t\t\t\tefree(temp_filename);\n\t\t\t\t}\n\t\t\t\ttemp_filename = \"\";\n\t\t\t} else {\n\t\t\t\tzend_hash_add(SG(rfc1867_uploaded_files), temp_filename, strlen(temp_filename) + 1, &temp_filename, sizeof(char *), NULL);\n\t\t\t}\n\n\t\t\t/* is_arr_upload is true when name of file upload field\n\t\t\t * ends in [.*]\n\t\t\t * start_arr is set to point to 1st [ */\n\t\t\tis_arr_upload =\t(start_arr = strchr(param,'[')) && (param[strlen(param)-1] == ']');\n\n\t\t\tif (is_arr_upload) {\n\t\t\t\tarray_len = strlen(start_arr);\n\t\t\t\tif (array_index) {\n\t\t\t\t\tefree(array_index);\n\t\t\t\t}\n\t\t\t\tarray_index = estrndup(start_arr + 1, array_len - 2);\n\t\t\t}\n\n\t\t\t/* Add $foo_name */\n\t\t\tif (llen < strlen(param) + MAX_SIZE_OF_INDEX + 1) {\n\t\t\t\tllen = strlen(param);\n\t\t\t\tlbuf = (char *) safe_erealloc(lbuf, llen, 1, MAX_SIZE_OF_INDEX + 1);\n\t\t\t\tllen += MAX_SIZE_OF_INDEX + 1;\n\t\t\t}\n\n\t\t\tif (is_arr_upload) {\n\t\t\t\tif (abuf) efree(abuf);\n\t\t\t\tabuf = estrndup(param, strlen(param)-array_len);\n\t\t\t\tsnprintf(lbuf, llen, \"%s_name[%s]\", abuf, array_index);\n\t\t\t} else {\n\t\t\t\tsnprintf(lbuf, llen, \"%s_name\", param);\n\t\t\t}\n\n\t\t\t/* The \\ check should technically be needed for win32 systems only where\n\t\t\t * it is a valid path separator. However, IE in all it's wisdom always sends\n\t\t\t * the full path of the file on the user's filesystem, which means that unless\n\t\t\t * the user does basename() they get a bogus file name. Until IE's user base drops\n\t\t\t * to nill or problem is fixed this code must remain enabled for all systems. */\n\t\t\ts = _basename(internal_encoding, filename TSRMLS_CC);\n\t\t\tif (!s) {\n\t\t\t\ts = filename;\n\t\t\t}\n\n\t\t\tif (!is_anonymous) {\n\t\t\t\tsafe_php_register_variable(lbuf, s, strlen(s), NULL, 0 TSRMLS_CC);\n\t\t\t}\n\n\t\t\t/* Add $foo[name] */\n\t\t\tif (is_arr_upload) {\n\t\t\t\tsnprintf(lbuf, llen, \"%s[name][%s]\", abuf, array_index);\n\t\t\t} else {\n\t\t\t\tsnprintf(lbuf, llen, \"%s[name]\", param);\n\t\t\t}\n\t\t\tregister_http_post_files_variable(lbuf, s, http_post_files, 0 TSRMLS_CC);\n\t\t\tefree(filename);\n\t\t\ts = NULL;\n\n\t\t\t/* Possible Content-Type: */\n\t\t\tif (cancel_upload || !(cd = php_mime_get_hdr_value(header, \"Content-Type\"))) {\n\t\t\t\tcd = \"\";\n\t\t\t} else {\n\t\t\t\t/* fix for Opera 6.01 */\n\t\t\t\ts = strchr(cd, ';');\n\t\t\t\tif (s != NULL) {\n\t\t\t\t\t*s = '\\0';\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t/* Add $foo_type */\n\t\t\tif (is_arr_upload) {\n\t\t\t\tsnprintf(lbuf, llen, \"%s_type[%s]\", abuf, array_index);\n\t\t\t} else {\n\t\t\t\tsnprintf(lbuf, llen, \"%s_type\", param);\n\t\t\t}\n\t\t\tif (!is_anonymous) {\n\t\t\t\tsafe_php_register_variable(lbuf, cd, strlen(cd), NULL, 0 TSRMLS_CC);\n\t\t\t}\n\n\t\t\t/* Add $foo[type] */\n\t\t\tif (is_arr_upload) {\n\t\t\t\tsnprintf(lbuf, llen, \"%s[type][%s]\", abuf, array_index);\n\t\t\t} else {\n\t\t\t\tsnprintf(lbuf, llen, \"%s[type]\", param);\n\t\t\t}\n\t\t\tregister_http_post_files_variable(lbuf, cd, http_post_files, 0 TSRMLS_CC);\n\n\t\t\t/* Restore Content-Type Header */\n\t\t\tif (s != NULL) {\n\t\t\t\t*s = ';';\n\t\t\t}\n\t\t\ts = \"\";\n\n\t\t\t{\n\t\t\t\t/* store temp_filename as-is (in case upload_tmp_dir\n\t\t\t\t * contains escapeable characters. escape only the variable name.) */\n\t\t\t\tzval zfilename;\n\n\t\t\t\t/* Initialize variables */\n\t\t\t\tadd_protected_variable(param TSRMLS_CC);\n\n\t\t\t\t/* if param is of form xxx[.*] this will cut it to xxx */\n\t\t\t\tif (!is_anonymous) {\n\t\t\t\t\tZVAL_STRING(&zfilename, temp_filename, 1);\n\t\t\t\t\tsafe_php_register_variable_ex(param, &zfilename, NULL, 1 TSRMLS_CC);\n\t\t\t\t}\n\n\t\t\t\t/* Add $foo[tmp_name] */\n\t\t\t\tif (is_arr_upload) {\n\t\t\t\t\tsnprintf(lbuf, llen, \"%s[tmp_name][%s]\", abuf, array_index);\n\t\t\t\t} else {\n\t\t\t\t\tsnprintf(lbuf, llen, \"%s[tmp_name]\", param);\n\t\t\t\t}\n\t\t\t\tadd_protected_variable(lbuf TSRMLS_CC);\n\t\t\t\tZVAL_STRING(&zfilename, temp_filename, 1);\n\t\t\t\tregister_http_post_files_variable_ex(lbuf, &zfilename, http_post_files, 1 TSRMLS_CC);\n\t\t\t}\n\n\t\t\t{\n\t\t\t\tzval file_size, error_type;\n\n\t\t\t\terror_type.value.lval = cancel_upload;\n\t\t\t\terror_type.type = IS_LONG;\n\n\t\t\t\t/* Add $foo[error] */\n\t\t\t\tif (cancel_upload) {\n\t\t\t\t\tfile_size.value.lval = 0;\n\t\t\t\t\tfile_size.type = IS_LONG;\n\t\t\t\t} else {\n\t\t\t\t\tfile_size.value.lval = total_bytes;\n\t\t\t\t\tfile_size.type = IS_LONG;\n\t\t\t\t}\n\n\t\t\t\tif (is_arr_upload) {\n\t\t\t\t\tsnprintf(lbuf, llen, \"%s[error][%s]\", abuf, array_index);\n\t\t\t\t} else {\n\t\t\t\t\tsnprintf(lbuf, llen, \"%s[error]\", param);\n\t\t\t\t}\n\t\t\t\tregister_http_post_files_variable_ex(lbuf, &error_type, http_post_files, 0 TSRMLS_CC);\n\n\t\t\t\t/* Add $foo_size */\n\t\t\t\tif (is_arr_upload) {\n\t\t\t\t\tsnprintf(lbuf, llen, \"%s_size[%s]\", abuf, array_index);\n\t\t\t\t} else {\n\t\t\t\t\tsnprintf(lbuf, llen, \"%s_size\", param);\n\t\t\t\t}\n\t\t\t\tif (!is_anonymous) {\n\t\t\t\t\tsafe_php_register_variable_ex(lbuf, &file_size, NULL, 0 TSRMLS_CC);\n\t\t\t\t}\n\n\t\t\t\t/* Add $foo[size] */\n\t\t\t\tif (is_arr_upload) {\n\t\t\t\t\tsnprintf(lbuf, llen, \"%s[size][%s]\", abuf, array_index);\n\t\t\t\t} else {\n\t\t\t\t\tsnprintf(lbuf, llen, \"%s[size]\", param);\n\t\t\t\t}\n\t\t\t\tregister_http_post_files_variable_ex(lbuf, &file_size, http_post_files, 0 TSRMLS_CC);\n\t\t\t}\n\t\t\tefree(param);\n\t\t}\n\t}\n\nfileupload_done:\n\tif (php_rfc1867_callback != NULL) {\n\t\tmultipart_event_end event_end;\n\n\t\tevent_end.post_bytes_processed = SG(read_post_bytes);\n\t\tphp_rfc1867_callback(MULTIPART_EVENT_END, &event_end, &event_extra_data TSRMLS_CC);\n\t}\n\n\tif (lbuf) efree(lbuf);\n\tif (abuf) efree(abuf);\n\tif (array_index) efree(array_index);\n\tzend_hash_destroy(&PG(rfc1867_protected_variables));\n\tzend_llist_destroy(&header);\n\tif (mbuff->boundary_next) efree(mbuff->boundary_next);\n\tif (mbuff->boundary) efree(mbuff->boundary);\n\tif (mbuff->buffer) efree(mbuff->buffer);\n\tif (mbuff) efree(mbuff);\n}",
        "func": "SAPI_API SAPI_POST_HANDLER_FUNC(rfc1867_post_handler) /* {{{ */\n{\n\tchar *boundary, *s = NULL, *boundary_end = NULL, *start_arr = NULL, *array_index = NULL;\n\tchar *temp_filename = NULL, *lbuf = NULL, *abuf = NULL;\n\tint boundary_len = 0, total_bytes = 0, cancel_upload = 0, is_arr_upload = 0, array_len = 0;\n\tint max_file_size = 0, skip_upload = 0, anonindex = 0, is_anonymous;\n\tzval *http_post_files = NULL;\n\tHashTable *uploaded_files = NULL;\n\tmultipart_buffer *mbuff;\n\tzval *array_ptr = (zval *) arg;\n\tint fd = -1;\n\tzend_llist header;\n\tvoid *event_extra_data = NULL;\n\tunsigned int llen = 0;\n\tint upload_cnt = INI_INT(\"max_file_uploads\");\n\tconst zend_encoding *internal_encoding = zend_multibyte_get_internal_encoding(TSRMLS_C);\n\tphp_rfc1867_getword_t getword;\n\tphp_rfc1867_getword_conf_t getword_conf;\n\tphp_rfc1867_basename_t _basename;\n\tlong count = 0;\n\n\tif (php_rfc1867_encoding_translation(TSRMLS_C) && internal_encoding) {\n\t\tgetword = php_rfc1867_getword;\n\t\tgetword_conf = php_rfc1867_getword_conf;\n\t\t_basename = php_rfc1867_basename;\n\t} else {\n\t\tgetword = php_ap_getword;\n\t\tgetword_conf = php_ap_getword_conf;\n\t\t_basename = php_ap_basename;\n\t}\n\n\tif (SG(post_max_size) > 0 && SG(request_info).content_length > SG(post_max_size)) {\n\t\tsapi_module.sapi_error(E_WARNING, \"POST Content-Length of %ld bytes exceeds the limit of %ld bytes\", SG(request_info).content_length, SG(post_max_size));\n\t\treturn;\n\t}\n\n\t/* Get the boundary */\n\tboundary = strstr(content_type_dup, \"boundary\");\n\tif (!boundary) {\n\t\tint content_type_len = strlen(content_type_dup);\n\t\tchar *content_type_lcase = estrndup(content_type_dup, content_type_len);\n\n\t\tphp_strtolower(content_type_lcase, content_type_len);\n\t\tboundary = strstr(content_type_lcase, \"boundary\");\n\t\tif (boundary) {\n\t\t\tboundary = content_type_dup + (boundary - content_type_lcase);\n\t\t}\n\t\tefree(content_type_lcase);\n\t}\n\n\tif (!boundary || !(boundary = strchr(boundary, '='))) {\n\t\tsapi_module.sapi_error(E_WARNING, \"Missing boundary in multipart/form-data POST data\");\n\t\treturn;\n\t}\n\n\tboundary++;\n\tboundary_len = strlen(boundary);\n\n\tif (boundary[0] == '\"') {\n\t\tboundary++;\n\t\tboundary_end = strchr(boundary, '\"');\n\t\tif (!boundary_end) {\n\t\t\tsapi_module.sapi_error(E_WARNING, \"Invalid boundary in multipart/form-data POST data\");\n\t\t\treturn;\n\t\t}\n\t} else {\n\t\t/* search for the end of the boundary */\n\t\tboundary_end = strpbrk(boundary, \",;\");\n\t}\n\tif (boundary_end) {\n\t\tboundary_end[0] = '\\0';\n\t\tboundary_len = boundary_end-boundary;\n\t}\n\n\t/* Initialize the buffer */\n\tif (!(mbuff = multipart_buffer_new(boundary, boundary_len TSRMLS_CC))) {\n\t\tsapi_module.sapi_error(E_WARNING, \"Unable to initialize the input buffer\");\n\t\treturn;\n\t}\n\n\t/* Initialize $_FILES[] */\n\tzend_hash_init(&PG(rfc1867_protected_variables), 5, NULL, NULL, 0);\n\n\tALLOC_HASHTABLE(uploaded_files);\n\tzend_hash_init(uploaded_files, 5, NULL, (dtor_func_t) free_estring, 0);\n\tSG(rfc1867_uploaded_files) = uploaded_files;\n\n\tALLOC_ZVAL(http_post_files);\n\tarray_init(http_post_files);\n\tINIT_PZVAL(http_post_files);\n\tPG(http_globals)[TRACK_VARS_FILES] = http_post_files;\n\n\tzend_llist_init(&header, sizeof(mime_header_entry), (llist_dtor_func_t) php_free_hdr_entry, 0);\n\n\tif (php_rfc1867_callback != NULL) {\n\t\tmultipart_event_start event_start;\n\n\t\tevent_start.content_length = SG(request_info).content_length;\n\t\tif (php_rfc1867_callback(MULTIPART_EVENT_START, &event_start, &event_extra_data TSRMLS_CC) == FAILURE) {\n\t\t\tgoto fileupload_done;\n\t\t}\n\t}\n\n\twhile (!multipart_buffer_eof(mbuff TSRMLS_CC))\n\t{\n\t\tchar buff[FILLUNIT];\n\t\tchar *cd = NULL, *param = NULL, *filename = NULL, *tmp = NULL;\n\t\tsize_t blen = 0, wlen = 0;\n\t\toff_t offset;\n\n\t\tzend_llist_clean(&header);\n\n\t\tif (!multipart_buffer_headers(mbuff, &header TSRMLS_CC)) {\n\t\t\tgoto fileupload_done;\n\t\t}\n\n\t\tif ((cd = php_mime_get_hdr_value(header, \"Content-Disposition\"))) {\n\t\t\tchar *pair = NULL;\n\t\t\tint end = 0;\n\n\t\t\twhile (isspace(*cd)) {\n\t\t\t\t++cd;\n\t\t\t}\n\n\t\t\twhile (*cd && (pair = getword(mbuff->input_encoding, &cd, ';' TSRMLS_CC)))\n\t\t\t{\n\t\t\t\tchar *key = NULL, *word = pair;\n\n\t\t\t\twhile (isspace(*cd)) {\n\t\t\t\t\t++cd;\n\t\t\t\t}\n\n\t\t\t\tif (strchr(pair, '=')) {\n\t\t\t\t\tkey = getword(mbuff->input_encoding, &pair, '=' TSRMLS_CC);\n\n\t\t\t\t\tif (!strcasecmp(key, \"name\")) {\n\t\t\t\t\t\tif (param) {\n\t\t\t\t\t\t\tefree(param);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tparam = getword_conf(mbuff->input_encoding, pair TSRMLS_CC);\n\t\t\t\t\t\tif (mbuff->input_encoding && internal_encoding) {\n\t\t\t\t\t\t\tunsigned char *new_param;\n\t\t\t\t\t\t\tsize_t new_param_len;\n\t\t\t\t\t\t\tif ((size_t)-1 != zend_multibyte_encoding_converter(&new_param, &new_param_len, (unsigned char *)param, strlen(param), internal_encoding, mbuff->input_encoding TSRMLS_CC)) {\n\t\t\t\t\t\t\t\tefree(param);\n\t\t\t\t\t\t\t\tparam = (char *)new_param;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t} else if (!strcasecmp(key, \"filename\")) {\n\t\t\t\t\t\tif (filename) {\n\t\t\t\t\t\t\tefree(filename);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tfilename = getword_conf(mbuff->input_encoding, pair TSRMLS_CC);\n\t\t\t\t\t\tif (mbuff->input_encoding && internal_encoding) {\n\t\t\t\t\t\t\tunsigned char *new_filename;\n\t\t\t\t\t\t\tsize_t new_filename_len;\n\t\t\t\t\t\t\tif ((size_t)-1 != zend_multibyte_encoding_converter(&new_filename, &new_filename_len, (unsigned char *)filename, strlen(filename), internal_encoding, mbuff->input_encoding TSRMLS_CC)) {\n\t\t\t\t\t\t\t\tefree(filename);\n\t\t\t\t\t\t\t\tfilename = (char *)new_filename;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (key) {\n\t\t\t\t\tefree(key);\n\t\t\t\t}\n\t\t\t\tefree(word);\n\t\t\t}\n\n\t\t\t/* Normal form variable, safe to read all data into memory */\n\t\t\tif (!filename && param) {\n\t\t\t\tunsigned int value_len;\n\t\t\t\tchar *value = multipart_buffer_read_body(mbuff, &value_len TSRMLS_CC);\n\t\t\t\tunsigned int new_val_len; /* Dummy variable */\n\n\t\t\t\tif (!value) {\n\t\t\t\t\tvalue = estrdup(\"\");\n\t\t\t\t\tvalue_len = 0;\n\t\t\t\t}\n\n\t\t\t\tif (mbuff->input_encoding && internal_encoding) {\n\t\t\t\t\tunsigned char *new_value;\n\t\t\t\t\tsize_t new_value_len;\n\t\t\t\t\tif ((size_t)-1 != zend_multibyte_encoding_converter(&new_value, &new_value_len, (unsigned char *)value, value_len, internal_encoding, mbuff->input_encoding TSRMLS_CC)) {\n\t\t\t\t\t\tefree(value);\n\t\t\t\t\t\tvalue = (char *)new_value;\n\t\t\t\t\t\tvalue_len = new_value_len;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif (++count <= PG(max_input_vars) && sapi_module.input_filter(PARSE_POST, param, &value, value_len, &new_val_len TSRMLS_CC)) {\n\t\t\t\t\tif (php_rfc1867_callback != NULL) {\n\t\t\t\t\t\tmultipart_event_formdata event_formdata;\n\t\t\t\t\t\tsize_t newlength = new_val_len;\n\n\t\t\t\t\t\tevent_formdata.post_bytes_processed = SG(read_post_bytes);\n\t\t\t\t\t\tevent_formdata.name = param;\n\t\t\t\t\t\tevent_formdata.value = &value;\n\t\t\t\t\t\tevent_formdata.length = new_val_len;\n\t\t\t\t\t\tevent_formdata.newlength = &newlength;\n\t\t\t\t\t\tif (php_rfc1867_callback(MULTIPART_EVENT_FORMDATA, &event_formdata, &event_extra_data TSRMLS_CC) == FAILURE) {\n\t\t\t\t\t\t\tefree(param);\n\t\t\t\t\t\t\tefree(value);\n\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tnew_val_len = newlength;\n\t\t\t\t\t}\n\t\t\t\t\tsafe_php_register_variable(param, value, new_val_len, array_ptr, 0 TSRMLS_CC);\n\t\t\t\t} else {\n\t\t\t\t\tif (count == PG(max_input_vars) + 1) {\n\t\t\t\t\t\tphp_error_docref(NULL TSRMLS_CC, E_WARNING, \"Input variables exceeded %ld. To increase the limit change max_input_vars in php.ini.\", PG(max_input_vars));\n\t\t\t\t\t}\n\n\t\t\t\t\tif (php_rfc1867_callback != NULL) {\n\t\t\t\t\t\tmultipart_event_formdata event_formdata;\n\n\t\t\t\t\t\tevent_formdata.post_bytes_processed = SG(read_post_bytes);\n\t\t\t\t\t\tevent_formdata.name = param;\n\t\t\t\t\t\tevent_formdata.value = &value;\n\t\t\t\t\t\tevent_formdata.length = value_len;\n\t\t\t\t\t\tevent_formdata.newlength = NULL;\n\t\t\t\t\t\tphp_rfc1867_callback(MULTIPART_EVENT_FORMDATA, &event_formdata, &event_extra_data TSRMLS_CC);\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif (!strcasecmp(param, \"MAX_FILE_SIZE\")) {\n\t\t\t\t\tmax_file_size = atol(value);\n\t\t\t\t}\n\n\t\t\t\tefree(param);\n\t\t\t\tefree(value);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\t/* If file_uploads=off, skip the file part */\n\t\t\tif (!PG(file_uploads)) {\n\t\t\t\tskip_upload = 1;\n\t\t\t} else if (upload_cnt <= 0) {\n\t\t\t\tskip_upload = 1;\n\t\t\t\tsapi_module.sapi_error(E_WARNING, \"Maximum number of allowable file uploads has been exceeded\");\n\t\t\t}\n\n\t\t\t/* Return with an error if the posted data is garbled */\n\t\t\tif (!param && !filename) {\n\t\t\t\tsapi_module.sapi_error(E_WARNING, \"File Upload Mime headers garbled\");\n\t\t\t\tgoto fileupload_done;\n\t\t\t}\n\n\t\t\tif (!param) {\n\t\t\t\tis_anonymous = 1;\n\t\t\t\tparam = emalloc(MAX_SIZE_ANONNAME);\n\t\t\t\tsnprintf(param, MAX_SIZE_ANONNAME, \"%u\", anonindex++);\n\t\t\t} else {\n\t\t\t\tis_anonymous = 0;\n\t\t\t}\n\n\t\t\t/* New Rule: never repair potential malicious user input */\n\t\t\tif (!skip_upload) {\n\t\t\t\tlong c = 0;\n\t\t\t\ttmp = param;\n\n\t\t\t\twhile (*tmp) {\n\t\t\t\t\tif (*tmp == '[') {\n\t\t\t\t\t\tc++;\n\t\t\t\t\t} else if (*tmp == ']') {\n\t\t\t\t\t\tc--;\n\t\t\t\t\t\tif (tmp[1] && tmp[1] != '[') {\n\t\t\t\t\t\t\tskip_upload = 1;\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif (c < 0) {\n\t\t\t\t\t\tskip_upload = 1;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t\ttmp++;\n\t\t\t\t}\n\t\t\t\t/* Brackets should always be closed */\n\t\t\t\tif(c != 0) {\n\t\t\t\t\tskip_upload = 1;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\ttotal_bytes = cancel_upload = 0;\n\t\t\ttemp_filename = NULL;\n\t\t\tfd = -1;\n\n\t\t\tif (!skip_upload && php_rfc1867_callback != NULL) {\n\t\t\t\tmultipart_event_file_start event_file_start;\n\n\t\t\t\tevent_file_start.post_bytes_processed = SG(read_post_bytes);\n\t\t\t\tevent_file_start.name = param;\n\t\t\t\tevent_file_start.filename = &filename;\n\t\t\t\tif (php_rfc1867_callback(MULTIPART_EVENT_FILE_START, &event_file_start, &event_extra_data TSRMLS_CC) == FAILURE) {\n\t\t\t\t\ttemp_filename = \"\";\n\t\t\t\t\tefree(param);\n\t\t\t\t\tefree(filename);\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (skip_upload) {\n\t\t\t\tefree(param);\n\t\t\t\tefree(filename);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (strlen(filename) == 0) {\n#if DEBUG_FILE_UPLOAD\n\t\t\t\tsapi_module.sapi_error(E_NOTICE, \"No file uploaded\");\n#endif\n\t\t\t\tcancel_upload = UPLOAD_ERROR_D;\n\t\t\t}\n\n\t\t\toffset = 0;\n\t\t\tend = 0;\n\n\t\t\tif (!cancel_upload) {\n\t\t\t\t/* only bother to open temp file if we have data */\n\t\t\t\tblen = multipart_buffer_read(mbuff, buff, sizeof(buff), &end TSRMLS_CC);\n#if DEBUG_FILE_UPLOAD\n\t\t\t\tif (blen > 0) {\n#else\n\t\t\t\t/* in non-debug mode we have no problem with 0-length files */\n\t\t\t\t{\n#endif\n\t\t\t\t\tfd = php_open_temporary_fd_ex(PG(upload_tmp_dir), \"php\", &temp_filename, 1 TSRMLS_CC);\n\t\t\t\t\tupload_cnt--;\n\t\t\t\t\tif (fd == -1) {\n\t\t\t\t\t\tsapi_module.sapi_error(E_WARNING, \"File upload error - unable to create a temporary file\");\n\t\t\t\t\t\tcancel_upload = UPLOAD_ERROR_E;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\twhile (!cancel_upload && (blen > 0))\n\t\t\t{\n\t\t\t\tif (php_rfc1867_callback != NULL) {\n\t\t\t\t\tmultipart_event_file_data event_file_data;\n\n\t\t\t\t\tevent_file_data.post_bytes_processed = SG(read_post_bytes);\n\t\t\t\t\tevent_file_data.offset = offset;\n\t\t\t\t\tevent_file_data.data = buff;\n\t\t\t\t\tevent_file_data.length = blen;\n\t\t\t\t\tevent_file_data.newlength = &blen;\n\t\t\t\t\tif (php_rfc1867_callback(MULTIPART_EVENT_FILE_DATA, &event_file_data, &event_extra_data TSRMLS_CC) == FAILURE) {\n\t\t\t\t\t\tcancel_upload = UPLOAD_ERROR_X;\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif (PG(upload_max_filesize) > 0 && (long)(total_bytes+blen) > PG(upload_max_filesize)) {\n#if DEBUG_FILE_UPLOAD\n\t\t\t\t\tsapi_module.sapi_error(E_NOTICE, \"upload_max_filesize of %ld bytes exceeded - file [%s=%s] not saved\", PG(upload_max_filesize), param, filename);\n#endif\n\t\t\t\t\tcancel_upload = UPLOAD_ERROR_A;\n\t\t\t\t} else if (max_file_size && ((long)(total_bytes+blen) > max_file_size)) {\n#if DEBUG_FILE_UPLOAD\n\t\t\t\t\tsapi_module.sapi_error(E_NOTICE, \"MAX_FILE_SIZE of %ld bytes exceeded - file [%s=%s] not saved\", max_file_size, param, filename);\n#endif\n\t\t\t\t\tcancel_upload = UPLOAD_ERROR_B;\n\t\t\t\t} else if (blen > 0) {\n\t\t\t\t\twlen = write(fd, buff, blen);\n\n\t\t\t\t\tif (wlen == -1) {\n\t\t\t\t\t\t/* write failed */\n#if DEBUG_FILE_UPLOAD\n\t\t\t\t\t\tsapi_module.sapi_error(E_NOTICE, \"write() failed - %s\", strerror(errno));\n#endif\n\t\t\t\t\t\tcancel_upload = UPLOAD_ERROR_F;\n\t\t\t\t\t} else if (wlen < blen) {\n#if DEBUG_FILE_UPLOAD\n\t\t\t\t\t\tsapi_module.sapi_error(E_NOTICE, \"Only %d bytes were written, expected to write %d\", wlen, blen);\n#endif\n\t\t\t\t\t\tcancel_upload = UPLOAD_ERROR_F;\n\t\t\t\t\t} else {\n\t\t\t\t\t\ttotal_bytes += wlen;\n\t\t\t\t\t}\n\t\t\t\t\toffset += wlen;\n\t\t\t\t}\n\n\t\t\t\t/* read data for next iteration */\n\t\t\t\tblen = multipart_buffer_read(mbuff, buff, sizeof(buff), &end TSRMLS_CC);\n\t\t\t}\n\n\t\t\tif (fd != -1) { /* may not be initialized if file could not be created */\n\t\t\t\tclose(fd);\n\t\t\t}\n\n\t\t\tif (!cancel_upload && !end) {\n#if DEBUG_FILE_UPLOAD\n\t\t\t\tsapi_module.sapi_error(E_NOTICE, \"Missing mime boundary at the end of the data for file %s\", strlen(filename) > 0 ? filename : \"\");\n#endif\n\t\t\t\tcancel_upload = UPLOAD_ERROR_C;\n\t\t\t}\n#if DEBUG_FILE_UPLOAD\n\t\t\tif (strlen(filename) > 0 && total_bytes == 0 && !cancel_upload) {\n\t\t\t\tsapi_module.sapi_error(E_WARNING, \"Uploaded file size 0 - file [%s=%s] not saved\", param, filename);\n\t\t\t\tcancel_upload = 5;\n\t\t\t}\n#endif\n\t\t\tif (php_rfc1867_callback != NULL) {\n\t\t\t\tmultipart_event_file_end event_file_end;\n\n\t\t\t\tevent_file_end.post_bytes_processed = SG(read_post_bytes);\n\t\t\t\tevent_file_end.temp_filename = temp_filename;\n\t\t\t\tevent_file_end.cancel_upload = cancel_upload;\n\t\t\t\tif (php_rfc1867_callback(MULTIPART_EVENT_FILE_END, &event_file_end, &event_extra_data TSRMLS_CC) == FAILURE) {\n\t\t\t\t\tcancel_upload = UPLOAD_ERROR_X;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (cancel_upload) {\n\t\t\t\tif (temp_filename) {\n\t\t\t\t\tif (cancel_upload != UPLOAD_ERROR_E) { /* file creation failed */\n\t\t\t\t\t\tunlink(temp_filename);\n\t\t\t\t\t}\n\t\t\t\t\tefree(temp_filename);\n\t\t\t\t}\n\t\t\t\ttemp_filename = \"\";\n\t\t\t} else {\n\t\t\t\tzend_hash_add(SG(rfc1867_uploaded_files), temp_filename, strlen(temp_filename) + 1, &temp_filename, sizeof(char *), NULL);\n\t\t\t}\n\n\t\t\t/* is_arr_upload is true when name of file upload field\n\t\t\t * ends in [.*]\n\t\t\t * start_arr is set to point to 1st [ */\n\t\t\tis_arr_upload =\t(start_arr = strchr(param,'[')) && (param[strlen(param)-1] == ']');\n\n\t\t\tif (is_arr_upload) {\n\t\t\t\tarray_len = strlen(start_arr);\n\t\t\t\tif (array_index) {\n\t\t\t\t\tefree(array_index);\n\t\t\t\t}\n\t\t\t\tarray_index = estrndup(start_arr + 1, array_len - 2);\n\t\t\t}\n\n\t\t\t/* Add $foo_name */\n\t\t\tif (llen < strlen(param) + MAX_SIZE_OF_INDEX + 1) {\n\t\t\t\tllen = strlen(param);\n\t\t\t\tlbuf = (char *) safe_erealloc(lbuf, llen, 1, MAX_SIZE_OF_INDEX + 1);\n\t\t\t\tllen += MAX_SIZE_OF_INDEX + 1;\n\t\t\t}\n\n\t\t\tif (is_arr_upload) {\n\t\t\t\tif (abuf) efree(abuf);\n\t\t\t\tabuf = estrndup(param, strlen(param)-array_len);\n\t\t\t\tsnprintf(lbuf, llen, \"%s_name[%s]\", abuf, array_index);\n\t\t\t} else {\n\t\t\t\tsnprintf(lbuf, llen, \"%s_name\", param);\n\t\t\t}\n\n\t\t\t/* The \\ check should technically be needed for win32 systems only where\n\t\t\t * it is a valid path separator. However, IE in all it's wisdom always sends\n\t\t\t * the full path of the file on the user's filesystem, which means that unless\n\t\t\t * the user does basename() they get a bogus file name. Until IE's user base drops\n\t\t\t * to nill or problem is fixed this code must remain enabled for all systems. */\n\t\t\ts = _basename(internal_encoding, filename TSRMLS_CC);\n\t\t\tif (!s) {\n\t\t\t\ts = filename;\n\t\t\t}\n\n\t\t\tif (!is_anonymous) {\n\t\t\t\tsafe_php_register_variable(lbuf, s, strlen(s), NULL, 0 TSRMLS_CC);\n\t\t\t}\n\n\t\t\t/* Add $foo[name] */\n\t\t\tif (is_arr_upload) {\n\t\t\t\tsnprintf(lbuf, llen, \"%s[name][%s]\", abuf, array_index);\n\t\t\t} else {\n\t\t\t\tsnprintf(lbuf, llen, \"%s[name]\", param);\n\t\t\t}\n\t\t\tregister_http_post_files_variable(lbuf, s, http_post_files, 0 TSRMLS_CC);\n\t\t\tefree(filename);\n\t\t\ts = NULL;\n\n\t\t\t/* Possible Content-Type: */\n\t\t\tif (cancel_upload || !(cd = php_mime_get_hdr_value(header, \"Content-Type\"))) {\n\t\t\t\tcd = \"\";\n\t\t\t} else {\n\t\t\t\t/* fix for Opera 6.01 */\n\t\t\t\ts = strchr(cd, ';');\n\t\t\t\tif (s != NULL) {\n\t\t\t\t\t*s = '\\0';\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t/* Add $foo_type */\n\t\t\tif (is_arr_upload) {\n\t\t\t\tsnprintf(lbuf, llen, \"%s_type[%s]\", abuf, array_index);\n\t\t\t} else {\n\t\t\t\tsnprintf(lbuf, llen, \"%s_type\", param);\n\t\t\t}\n\t\t\tif (!is_anonymous) {\n\t\t\t\tsafe_php_register_variable(lbuf, cd, strlen(cd), NULL, 0 TSRMLS_CC);\n\t\t\t}\n\n\t\t\t/* Add $foo[type] */\n\t\t\tif (is_arr_upload) {\n\t\t\t\tsnprintf(lbuf, llen, \"%s[type][%s]\", abuf, array_index);\n\t\t\t} else {\n\t\t\t\tsnprintf(lbuf, llen, \"%s[type]\", param);\n\t\t\t}\n\t\t\tregister_http_post_files_variable(lbuf, cd, http_post_files, 0 TSRMLS_CC);\n\n\t\t\t/* Restore Content-Type Header */\n\t\t\tif (s != NULL) {\n\t\t\t\t*s = ';';\n\t\t\t}\n\t\t\ts = \"\";\n\n\t\t\t{\n\t\t\t\t/* store temp_filename as-is (in case upload_tmp_dir\n\t\t\t\t * contains escapeable characters. escape only the variable name.) */\n\t\t\t\tzval zfilename;\n\n\t\t\t\t/* Initialize variables */\n\t\t\t\tadd_protected_variable(param TSRMLS_CC);\n\n\t\t\t\t/* if param is of form xxx[.*] this will cut it to xxx */\n\t\t\t\tif (!is_anonymous) {\n\t\t\t\t\tZVAL_STRING(&zfilename, temp_filename, 1);\n\t\t\t\t\tsafe_php_register_variable_ex(param, &zfilename, NULL, 1 TSRMLS_CC);\n\t\t\t\t}\n\n\t\t\t\t/* Add $foo[tmp_name] */\n\t\t\t\tif (is_arr_upload) {\n\t\t\t\t\tsnprintf(lbuf, llen, \"%s[tmp_name][%s]\", abuf, array_index);\n\t\t\t\t} else {\n\t\t\t\t\tsnprintf(lbuf, llen, \"%s[tmp_name]\", param);\n\t\t\t\t}\n\t\t\t\tadd_protected_variable(lbuf TSRMLS_CC);\n\t\t\t\tZVAL_STRING(&zfilename, temp_filename, 1);\n\t\t\t\tregister_http_post_files_variable_ex(lbuf, &zfilename, http_post_files, 1 TSRMLS_CC);\n\t\t\t}\n\n\t\t\t{\n\t\t\t\tzval file_size, error_type;\n\n\t\t\t\terror_type.value.lval = cancel_upload;\n\t\t\t\terror_type.type = IS_LONG;\n\n\t\t\t\t/* Add $foo[error] */\n\t\t\t\tif (cancel_upload) {\n\t\t\t\t\tfile_size.value.lval = 0;\n\t\t\t\t\tfile_size.type = IS_LONG;\n\t\t\t\t} else {\n\t\t\t\t\tfile_size.value.lval = total_bytes;\n\t\t\t\t\tfile_size.type = IS_LONG;\n\t\t\t\t}\n\n\t\t\t\tif (is_arr_upload) {\n\t\t\t\t\tsnprintf(lbuf, llen, \"%s[error][%s]\", abuf, array_index);\n\t\t\t\t} else {\n\t\t\t\t\tsnprintf(lbuf, llen, \"%s[error]\", param);\n\t\t\t\t}\n\t\t\t\tregister_http_post_files_variable_ex(lbuf, &error_type, http_post_files, 0 TSRMLS_CC);\n\n\t\t\t\t/* Add $foo_size */\n\t\t\t\tif (is_arr_upload) {\n\t\t\t\t\tsnprintf(lbuf, llen, \"%s_size[%s]\", abuf, array_index);\n\t\t\t\t} else {\n\t\t\t\t\tsnprintf(lbuf, llen, \"%s_size\", param);\n\t\t\t\t}\n\t\t\t\tif (!is_anonymous) {\n\t\t\t\t\tsafe_php_register_variable_ex(lbuf, &file_size, NULL, 0 TSRMLS_CC);\n\t\t\t\t}\n\n\t\t\t\t/* Add $foo[size] */\n\t\t\t\tif (is_arr_upload) {\n\t\t\t\t\tsnprintf(lbuf, llen, \"%s[size][%s]\", abuf, array_index);\n\t\t\t\t} else {\n\t\t\t\t\tsnprintf(lbuf, llen, \"%s[size]\", param);\n\t\t\t\t}\n\t\t\t\tregister_http_post_files_variable_ex(lbuf, &file_size, http_post_files, 0 TSRMLS_CC);\n\t\t\t}\n\t\t\tefree(param);\n\t\t}\n\t}\n\nfileupload_done:\n\tif (php_rfc1867_callback != NULL) {\n\t\tmultipart_event_end event_end;\n\n\t\tevent_end.post_bytes_processed = SG(read_post_bytes);\n\t\tphp_rfc1867_callback(MULTIPART_EVENT_END, &event_end, &event_extra_data TSRMLS_CC);\n\t}\n\n\tif (lbuf) efree(lbuf);\n\tif (abuf) efree(abuf);\n\tif (array_index) efree(array_index);\n\tzend_hash_destroy(&PG(rfc1867_protected_variables));\n\tzend_llist_destroy(&header);\n\tif (mbuff->boundary_next) efree(mbuff->boundary_next);\n\tif (mbuff->boundary) efree(mbuff->boundary);\n\tif (mbuff->buffer) efree(mbuff->buffer);\n\tif (mbuff) efree(mbuff);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -210,7 +210,7 @@\n \t\t\t\t\tif (count == PG(max_input_vars) + 1) {\n \t\t\t\t\t\tphp_error_docref(NULL TSRMLS_CC, E_WARNING, \"Input variables exceeded %ld. To increase the limit change max_input_vars in php.ini.\", PG(max_input_vars));\n \t\t\t\t\t}\n-\t\t\t\t\n+\n \t\t\t\t\tif (php_rfc1867_callback != NULL) {\n \t\t\t\t\t\tmultipart_event_formdata event_formdata;\n ",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\t\t"
            ],
            "added_lines": [
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1788",
        "func_name": "openssl/BN_GF2m_mod_inv",
        "description": "The BN_GF2m_mod_inv function in crypto/bn/bn_gf2m.c in OpenSSL before 0.9.8s, 1.0.0 before 1.0.0e, 1.0.1 before 1.0.1n, and 1.0.2 before 1.0.2b does not properly handle ECParameters structures in which the curve is over a malformed binary polynomial field, which allows remote attackers to cause a denial of service (infinite loop) via a session that uses an Elliptic Curve algorithm, as demonstrated by an attack against a server that supports client authentication.",
        "git_url": "https://github.com/openssl/openssl/commit/4924b37ee01f71ae19c94a8934b80eeb2f677932",
        "commit_title": "bn/bn_gf2m.c: avoid infinite loop wich malformed ECParamters.",
        "commit_text": " CVE-2015-1788 ",
        "func_before": "int BN_GF2m_mod_inv(BIGNUM *r, const BIGNUM *a, const BIGNUM *p, BN_CTX *ctx)\n{\n    BIGNUM *b, *c = NULL, *u = NULL, *v = NULL, *tmp;\n    int ret = 0;\n\n    bn_check_top(a);\n    bn_check_top(p);\n\n    BN_CTX_start(ctx);\n\n    if ((b = BN_CTX_get(ctx)) == NULL)\n        goto err;\n    if ((c = BN_CTX_get(ctx)) == NULL)\n        goto err;\n    if ((u = BN_CTX_get(ctx)) == NULL)\n        goto err;\n    if ((v = BN_CTX_get(ctx)) == NULL)\n        goto err;\n\n    if (!BN_GF2m_mod(u, a, p))\n        goto err;\n    if (BN_is_zero(u))\n        goto err;\n\n    if (!BN_copy(v, p))\n        goto err;\n# if 0\n    if (!BN_one(b))\n        goto err;\n\n    while (1) {\n        while (!BN_is_odd(u)) {\n            if (BN_is_zero(u))\n                goto err;\n            if (!BN_rshift1(u, u))\n                goto err;\n            if (BN_is_odd(b)) {\n                if (!BN_GF2m_add(b, b, p))\n                    goto err;\n            }\n            if (!BN_rshift1(b, b))\n                goto err;\n        }\n\n        if (BN_abs_is_word(u, 1))\n            break;\n\n        if (BN_num_bits(u) < BN_num_bits(v)) {\n            tmp = u;\n            u = v;\n            v = tmp;\n            tmp = b;\n            b = c;\n            c = tmp;\n        }\n\n        if (!BN_GF2m_add(u, u, v))\n            goto err;\n        if (!BN_GF2m_add(b, b, c))\n            goto err;\n    }\n# else\n    {\n        int i, ubits = BN_num_bits(u), vbits = BN_num_bits(v), /* v is copy\n                                                                * of p */\n            top = p->top;\n        BN_ULONG *udp, *bdp, *vdp, *cdp;\n\n        bn_wexpand(u, top);\n        udp = u->d;\n        for (i = u->top; i < top; i++)\n            udp[i] = 0;\n        u->top = top;\n        bn_wexpand(b, top);\n        bdp = b->d;\n        bdp[0] = 1;\n        for (i = 1; i < top; i++)\n            bdp[i] = 0;\n        b->top = top;\n        bn_wexpand(c, top);\n        cdp = c->d;\n        for (i = 0; i < top; i++)\n            cdp[i] = 0;\n        c->top = top;\n        vdp = v->d;             /* It pays off to \"cache\" *->d pointers,\n                                 * because it allows optimizer to be more\n                                 * aggressive. But we don't have to \"cache\"\n                                 * p->d, because *p is declared 'const'... */\n        while (1) {\n            while (ubits && !(udp[0] & 1)) {\n                BN_ULONG u0, u1, b0, b1, mask;\n\n                u0 = udp[0];\n                b0 = bdp[0];\n                mask = (BN_ULONG)0 - (b0 & 1);\n                b0 ^= p->d[0] & mask;\n                for (i = 0; i < top - 1; i++) {\n                    u1 = udp[i + 1];\n                    udp[i] = ((u0 >> 1) | (u1 << (BN_BITS2 - 1))) & BN_MASK2;\n                    u0 = u1;\n                    b1 = bdp[i + 1] ^ (p->d[i + 1] & mask);\n                    bdp[i] = ((b0 >> 1) | (b1 << (BN_BITS2 - 1))) & BN_MASK2;\n                    b0 = b1;\n                }\n                udp[i] = u0 >> 1;\n                bdp[i] = b0 >> 1;\n                ubits--;\n            }\n\n            if (ubits <= BN_BITS2 && udp[0] == 1)\n                break;\n\n            if (ubits < vbits) {\n                i = ubits;\n                ubits = vbits;\n                vbits = i;\n                tmp = u;\n                u = v;\n                v = tmp;\n                tmp = b;\n                b = c;\n                c = tmp;\n                udp = vdp;\n                vdp = v->d;\n                bdp = cdp;\n                cdp = c->d;\n            }\n            for (i = 0; i < top; i++) {\n                udp[i] ^= vdp[i];\n                bdp[i] ^= cdp[i];\n            }\n            if (ubits == vbits) {\n                BN_ULONG ul;\n                int utop = (ubits - 1) / BN_BITS2;\n\n                while ((ul = udp[utop]) == 0 && utop)\n                    utop--;\n                ubits = utop * BN_BITS2 + BN_num_bits_word(ul);\n            }\n        }\n        bn_correct_top(b);\n    }\n# endif\n\n    if (!BN_copy(r, b))\n        goto err;\n    bn_check_top(r);\n    ret = 1;\n\n err:\n# ifdef BN_DEBUG                /* BN_CTX_end would complain about the\n                                 * expanded form */\n    bn_correct_top(c);\n    bn_correct_top(u);\n    bn_correct_top(v);\n# endif\n    BN_CTX_end(ctx);\n    return ret;\n}",
        "func": "int BN_GF2m_mod_inv(BIGNUM *r, const BIGNUM *a, const BIGNUM *p, BN_CTX *ctx)\n{\n    BIGNUM *b, *c = NULL, *u = NULL, *v = NULL, *tmp;\n    int ret = 0;\n\n    bn_check_top(a);\n    bn_check_top(p);\n\n    BN_CTX_start(ctx);\n\n    if ((b = BN_CTX_get(ctx)) == NULL)\n        goto err;\n    if ((c = BN_CTX_get(ctx)) == NULL)\n        goto err;\n    if ((u = BN_CTX_get(ctx)) == NULL)\n        goto err;\n    if ((v = BN_CTX_get(ctx)) == NULL)\n        goto err;\n\n    if (!BN_GF2m_mod(u, a, p))\n        goto err;\n    if (BN_is_zero(u))\n        goto err;\n\n    if (!BN_copy(v, p))\n        goto err;\n# if 0\n    if (!BN_one(b))\n        goto err;\n\n    while (1) {\n        while (!BN_is_odd(u)) {\n            if (BN_is_zero(u))\n                goto err;\n            if (!BN_rshift1(u, u))\n                goto err;\n            if (BN_is_odd(b)) {\n                if (!BN_GF2m_add(b, b, p))\n                    goto err;\n            }\n            if (!BN_rshift1(b, b))\n                goto err;\n        }\n\n        if (BN_abs_is_word(u, 1))\n            break;\n\n        if (BN_num_bits(u) < BN_num_bits(v)) {\n            tmp = u;\n            u = v;\n            v = tmp;\n            tmp = b;\n            b = c;\n            c = tmp;\n        }\n\n        if (!BN_GF2m_add(u, u, v))\n            goto err;\n        if (!BN_GF2m_add(b, b, c))\n            goto err;\n    }\n# else\n    {\n        int i;\n        int ubits = BN_num_bits(u);\n        int vbits = BN_num_bits(v); /* v is copy of p */\n        int top = p->top;\n        BN_ULONG *udp, *bdp, *vdp, *cdp;\n\n        bn_wexpand(u, top);\n        udp = u->d;\n        for (i = u->top; i < top; i++)\n            udp[i] = 0;\n        u->top = top;\n        bn_wexpand(b, top);\n        bdp = b->d;\n        bdp[0] = 1;\n        for (i = 1; i < top; i++)\n            bdp[i] = 0;\n        b->top = top;\n        bn_wexpand(c, top);\n        cdp = c->d;\n        for (i = 0; i < top; i++)\n            cdp[i] = 0;\n        c->top = top;\n        vdp = v->d;             /* It pays off to \"cache\" *->d pointers,\n                                 * because it allows optimizer to be more\n                                 * aggressive. But we don't have to \"cache\"\n                                 * p->d, because *p is declared 'const'... */\n        while (1) {\n            while (ubits && !(udp[0] & 1)) {\n                BN_ULONG u0, u1, b0, b1, mask;\n\n                u0 = udp[0];\n                b0 = bdp[0];\n                mask = (BN_ULONG)0 - (b0 & 1);\n                b0 ^= p->d[0] & mask;\n                for (i = 0; i < top - 1; i++) {\n                    u1 = udp[i + 1];\n                    udp[i] = ((u0 >> 1) | (u1 << (BN_BITS2 - 1))) & BN_MASK2;\n                    u0 = u1;\n                    b1 = bdp[i + 1] ^ (p->d[i + 1] & mask);\n                    bdp[i] = ((b0 >> 1) | (b1 << (BN_BITS2 - 1))) & BN_MASK2;\n                    b0 = b1;\n                }\n                udp[i] = u0 >> 1;\n                bdp[i] = b0 >> 1;\n                ubits--;\n            }\n\n            if (ubits <= BN_BITS2) {\n                if (udp[0] == 0) /* poly was reducible */\n                    goto err;\n                if (udp[0] == 1)\n                    break;\n            }\n\n            if (ubits < vbits) {\n                i = ubits;\n                ubits = vbits;\n                vbits = i;\n                tmp = u;\n                u = v;\n                v = tmp;\n                tmp = b;\n                b = c;\n                c = tmp;\n                udp = vdp;\n                vdp = v->d;\n                bdp = cdp;\n                cdp = c->d;\n            }\n            for (i = 0; i < top; i++) {\n                udp[i] ^= vdp[i];\n                bdp[i] ^= cdp[i];\n            }\n            if (ubits == vbits) {\n                BN_ULONG ul;\n                int utop = (ubits - 1) / BN_BITS2;\n\n                while ((ul = udp[utop]) == 0 && utop)\n                    utop--;\n                ubits = utop * BN_BITS2 + BN_num_bits_word(ul);\n            }\n        }\n        bn_correct_top(b);\n    }\n# endif\n\n    if (!BN_copy(r, b))\n        goto err;\n    bn_check_top(r);\n    ret = 1;\n\n err:\n# ifdef BN_DEBUG                /* BN_CTX_end would complain about the\n                                 * expanded form */\n    bn_correct_top(c);\n    bn_correct_top(u);\n    bn_correct_top(v);\n# endif\n    BN_CTX_end(ctx);\n    return ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -61,9 +61,10 @@\n     }\n # else\n     {\n-        int i, ubits = BN_num_bits(u), vbits = BN_num_bits(v), /* v is copy\n-                                                                * of p */\n-            top = p->top;\n+        int i;\n+        int ubits = BN_num_bits(u);\n+        int vbits = BN_num_bits(v); /* v is copy of p */\n+        int top = p->top;\n         BN_ULONG *udp, *bdp, *vdp, *cdp;\n \n         bn_wexpand(u, top);\n@@ -107,8 +108,12 @@\n                 ubits--;\n             }\n \n-            if (ubits <= BN_BITS2 && udp[0] == 1)\n-                break;\n+            if (ubits <= BN_BITS2) {\n+                if (udp[0] == 0) /* poly was reducible */\n+                    goto err;\n+                if (udp[0] == 1)\n+                    break;\n+            }\n \n             if (ubits < vbits) {\n                 i = ubits;",
        "diff_line_info": {
            "deleted_lines": [
                "        int i, ubits = BN_num_bits(u), vbits = BN_num_bits(v), /* v is copy",
                "                                                                * of p */",
                "            top = p->top;",
                "            if (ubits <= BN_BITS2 && udp[0] == 1)",
                "                break;"
            ],
            "added_lines": [
                "        int i;",
                "        int ubits = BN_num_bits(u);",
                "        int vbits = BN_num_bits(v); /* v is copy of p */",
                "        int top = p->top;",
                "            if (ubits <= BN_BITS2) {",
                "                if (udp[0] == 0) /* poly was reducible */",
                "                    goto err;",
                "                if (udp[0] == 1)",
                "                    break;",
                "            }"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1792",
        "func_name": "openssl/cms_copy_content",
        "description": "The do_free_upto function in crypto/cms/cms_smime.c in OpenSSL before 0.9.8zg, 1.0.0 before 1.0.0s, 1.0.1 before 1.0.1n, and 1.0.2 before 1.0.2b allows remote attackers to cause a denial of service (infinite loop) via vectors that trigger a NULL value of a BIO data structure, as demonstrated by an unrecognized X.660 OID for a hash function.",
        "git_url": "https://github.com/openssl/openssl/commit/cd30f03ac5bf2962f44bd02ae8d88245dff2f12c",
        "commit_title": "Canonicalise input in CMS_verify.",
        "commit_text": " If content is detached and not binary mode translate the input to CRLF format. Before this change the input was verified verbatim which lead to a discrepancy between sign and verify.",
        "func_before": "static int cms_copy_content(BIO *out, BIO *in, unsigned int flags)\n\t{\n\tunsigned char buf[4096];\n\tint r = 0, i;\n\tBIO *tmpout = NULL;\n\n\tif (out == NULL)\n\t\ttmpout = BIO_new(BIO_s_null());\n\telse if (flags & CMS_TEXT)\n\t\t{\n\t\ttmpout = BIO_new(BIO_s_mem());\n\t\tBIO_set_mem_eof_return(tmpout, 0);\n\t\t}\n\telse\n\t\ttmpout = out;\n\n\tif(!tmpout)\n\t\t{\n\t\tCMSerr(CMS_F_CMS_COPY_CONTENT,ERR_R_MALLOC_FAILURE);\n\t\tgoto err;\n\t\t}\n\n\t/* Read all content through chain to process digest, decrypt etc */\n\tfor (;;)\n\t{\n\t\ti=BIO_read(in,buf,sizeof(buf));\n\t\tif (i <= 0)\n\t\t\t{\n\t\t\tif (BIO_method_type(in) == BIO_TYPE_CIPHER)\n\t\t\t\t{\n\t\t\t\tif (!BIO_get_cipher_status(in))\n\t\t\t\t\tgoto err;\n\t\t\t\t}\n\t\t\tif (i < 0)\n\t\t\t\tgoto err;\n\t\t\tbreak;\n\t\t\t}\n\t\t\t\t\n\t\tif (tmpout && (BIO_write(tmpout, buf, i) != i))\n\t\t\tgoto err;\n\t}\n\n\tif(flags & CMS_TEXT)\n\t\t{\n\t\tif(!SMIME_text(tmpout, out))\n\t\t\t{\n\t\t\tCMSerr(CMS_F_CMS_COPY_CONTENT,CMS_R_SMIME_TEXT_ERROR);\n\t\t\tgoto err;\n\t\t\t}\n\t\t}\n\n\tr = 1;\n\n\terr:\n\tif (tmpout && (tmpout != out))\n\t\tBIO_free(tmpout);\n\treturn r;\n\n\t}",
        "func": "static int cms_copy_content(BIO *out, BIO *in, unsigned int flags)\n\t{\n\tunsigned char buf[4096];\n\tint r = 0, i;\n\tBIO *tmpout;\n\n\ttmpout = cms_get_text_bio(out, flags);\n\n\tif(!tmpout)\n\t\t{\n\t\tCMSerr(CMS_F_CMS_COPY_CONTENT,ERR_R_MALLOC_FAILURE);\n\t\tgoto err;\n\t\t}\n\n\t/* Read all content through chain to process digest, decrypt etc */\n\tfor (;;)\n\t{\n\t\ti=BIO_read(in,buf,sizeof(buf));\n\t\tif (i <= 0)\n\t\t\t{\n\t\t\tif (BIO_method_type(in) == BIO_TYPE_CIPHER)\n\t\t\t\t{\n\t\t\t\tif (!BIO_get_cipher_status(in))\n\t\t\t\t\tgoto err;\n\t\t\t\t}\n\t\t\tif (i < 0)\n\t\t\t\tgoto err;\n\t\t\tbreak;\n\t\t\t}\n\t\t\t\t\n\t\tif (tmpout && (BIO_write(tmpout, buf, i) != i))\n\t\t\tgoto err;\n\t}\n\n\tif(flags & CMS_TEXT)\n\t\t{\n\t\tif(!SMIME_text(tmpout, out))\n\t\t\t{\n\t\t\tCMSerr(CMS_F_CMS_COPY_CONTENT,CMS_R_SMIME_TEXT_ERROR);\n\t\t\tgoto err;\n\t\t\t}\n\t\t}\n\n\tr = 1;\n\n\terr:\n\tif (tmpout && (tmpout != out))\n\t\tBIO_free(tmpout);\n\treturn r;\n\n\t}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,17 +2,9 @@\n \t{\n \tunsigned char buf[4096];\n \tint r = 0, i;\n-\tBIO *tmpout = NULL;\n+\tBIO *tmpout;\n \n-\tif (out == NULL)\n-\t\ttmpout = BIO_new(BIO_s_null());\n-\telse if (flags & CMS_TEXT)\n-\t\t{\n-\t\ttmpout = BIO_new(BIO_s_mem());\n-\t\tBIO_set_mem_eof_return(tmpout, 0);\n-\t\t}\n-\telse\n-\t\ttmpout = out;\n+\ttmpout = cms_get_text_bio(out, flags);\n \n \tif(!tmpout)\n \t\t{",
        "diff_line_info": {
            "deleted_lines": [
                "\tBIO *tmpout = NULL;",
                "\tif (out == NULL)",
                "\t\ttmpout = BIO_new(BIO_s_null());",
                "\telse if (flags & CMS_TEXT)",
                "\t\t{",
                "\t\ttmpout = BIO_new(BIO_s_mem());",
                "\t\tBIO_set_mem_eof_return(tmpout, 0);",
                "\t\t}",
                "\telse",
                "\t\ttmpout = out;"
            ],
            "added_lines": [
                "\tBIO *tmpout;",
                "\ttmpout = cms_get_text_bio(out, flags);"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1792",
        "func_name": "openssl/CMS_verify",
        "description": "The do_free_upto function in crypto/cms/cms_smime.c in OpenSSL before 0.9.8zg, 1.0.0 before 1.0.0s, 1.0.1 before 1.0.1n, and 1.0.2 before 1.0.2b allows remote attackers to cause a denial of service (infinite loop) via vectors that trigger a NULL value of a BIO data structure, as demonstrated by an unrecognized X.660 OID for a hash function.",
        "git_url": "https://github.com/openssl/openssl/commit/cd30f03ac5bf2962f44bd02ae8d88245dff2f12c",
        "commit_title": "Canonicalise input in CMS_verify.",
        "commit_text": " If content is detached and not binary mode translate the input to CRLF format. Before this change the input was verified verbatim which lead to a discrepancy between sign and verify.",
        "func_before": "int CMS_verify(CMS_ContentInfo *cms, STACK_OF(X509) *certs,\n\t\t X509_STORE *store, BIO *dcont, BIO *out, unsigned int flags)\n\t{\n\tCMS_SignerInfo *si;\n\tSTACK_OF(CMS_SignerInfo) *sinfos;\n\tSTACK_OF(X509) *cms_certs = NULL;\n\tSTACK_OF(X509_CRL) *crls = NULL;\n\tX509 *signer;\n\tint i, scount = 0, ret = 0;\n\tBIO *cmsbio = NULL, *tmpin = NULL;\n\n\tif (!dcont && !check_content(cms))\n\t\treturn 0;\n\n\t/* Attempt to find all signer certificates */\n\n\tsinfos = CMS_get0_SignerInfos(cms);\n\n\tif (sk_CMS_SignerInfo_num(sinfos) <= 0)\n\t\t{\n\t\tCMSerr(CMS_F_CMS_VERIFY, CMS_R_NO_SIGNERS);\n\t\tgoto err;\n\t\t}\n\n\tfor (i = 0; i < sk_CMS_SignerInfo_num(sinfos); i++)\n\t\t{\n\t\tsi = sk_CMS_SignerInfo_value(sinfos, i);\n\t\tCMS_SignerInfo_get0_algs(si, NULL, &signer, NULL, NULL);\n\t\tif (signer)\n\t\t\tscount++;\n\t\t}\n\n\tif (scount != sk_CMS_SignerInfo_num(sinfos))\n\t\tscount += CMS_set1_signers_certs(cms, certs, flags);\n\n\tif (scount != sk_CMS_SignerInfo_num(sinfos))\n\t\t{\n\t\tCMSerr(CMS_F_CMS_VERIFY, CMS_R_SIGNER_CERTIFICATE_NOT_FOUND);\n\t\tgoto err;\n\t\t}\n\n\t/* Attempt to verify all signers certs */\n\n\tif (!(flags & CMS_NO_SIGNER_CERT_VERIFY))\n\t\t{\n\t\tcms_certs = CMS_get1_certs(cms);\n\t\tif (!(flags & CMS_NOCRL))\n\t\t\tcrls = CMS_get1_crls(cms);\n\t\tfor (i = 0; i < sk_CMS_SignerInfo_num(sinfos); i++)\n\t\t\t{\n\t\t\tsi = sk_CMS_SignerInfo_value(sinfos, i);\n\t\t\tif (!cms_signerinfo_verify_cert(si, store,\n\t\t\t\t\t\t\tcms_certs, crls, flags))\n\t\t\t\tgoto err;\n\t\t\t}\n\t\t}\n\n\t/* Attempt to verify all SignerInfo signed attribute signatures */\n\n\tif (!(flags & CMS_NO_ATTR_VERIFY))\n\t\t{\n\t\tfor (i = 0; i < sk_CMS_SignerInfo_num(sinfos); i++)\n\t\t\t{\n\t\t\tsi = sk_CMS_SignerInfo_value(sinfos, i);\n\t\t\tif (CMS_signed_get_attr_count(si) < 0)\n\t\t\t\tcontinue;\n\t\t\tif (CMS_SignerInfo_verify(si) <= 0)\n\t\t\t\tgoto err;\n\t\t\t}\n\t\t}\n\n\t/* Performance optimization: if the content is a memory BIO then\n\t * store its contents in a temporary read only memory BIO. This\n\t * avoids potentially large numbers of slow copies of data which will\n\t * occur when reading from a read write memory BIO when signatures\n\t * are calculated.\n\t */\n\n\tif (dcont && (BIO_method_type(dcont) == BIO_TYPE_MEM))\n\t\t{\n\t\tchar *ptr;\n\t\tlong len;\n\t\tlen = BIO_get_mem_data(dcont, &ptr);\n\t\ttmpin = BIO_new_mem_buf(ptr, len);\n\t\tif (tmpin == NULL)\n\t\t\t{\n\t\t\tCMSerr(CMS_F_CMS_VERIFY,ERR_R_MALLOC_FAILURE);\n\t\t\treturn 0;\n\t\t\t}\n\t\t}\n\telse\n\t\ttmpin = dcont;\n\t\t\n\n\tcmsbio=CMS_dataInit(cms, tmpin);\n\tif (!cmsbio)\n\t\tgoto err;\n\n\tif (!cms_copy_content(out, cmsbio, flags))\n\t\tgoto err;\n\n\tif (!(flags & CMS_NO_CONTENT_VERIFY))\n\t\t{\n\t\tfor (i = 0; i < sk_CMS_SignerInfo_num(sinfos); i++)\n\t\t\t{\n\t\t\tsi = sk_CMS_SignerInfo_value(sinfos, i);\n\t\t\tif (CMS_SignerInfo_verify_content(si, cmsbio) <= 0)\n\t\t\t\t{\n\t\t\t\tCMSerr(CMS_F_CMS_VERIFY,\n\t\t\t\t\tCMS_R_CONTENT_VERIFY_ERROR);\n\t\t\t\tgoto err;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\tret = 1;\n\n\terr:\n\t\n\tif (dcont && (tmpin == dcont))\n\t\tdo_free_upto(cmsbio, dcont);\n\telse\n\t\tBIO_free_all(cmsbio);\n\n\tif (cms_certs)\n\t\tsk_X509_pop_free(cms_certs, X509_free);\n\tif (crls)\n\t\tsk_X509_CRL_pop_free(crls, X509_CRL_free);\n\n\treturn ret;\n\t}",
        "func": "int CMS_verify(CMS_ContentInfo *cms, STACK_OF(X509) *certs,\n\t\t X509_STORE *store, BIO *dcont, BIO *out, unsigned int flags)\n\t{\n\tCMS_SignerInfo *si;\n\tSTACK_OF(CMS_SignerInfo) *sinfos;\n\tSTACK_OF(X509) *cms_certs = NULL;\n\tSTACK_OF(X509_CRL) *crls = NULL;\n\tX509 *signer;\n\tint i, scount = 0, ret = 0;\n\tBIO *cmsbio = NULL, *tmpin = NULL, *tmpout = NULL;\n\n\tif (!dcont && !check_content(cms))\n\t\treturn 0;\n\n\t/* Attempt to find all signer certificates */\n\n\tsinfos = CMS_get0_SignerInfos(cms);\n\n\tif (sk_CMS_SignerInfo_num(sinfos) <= 0)\n\t\t{\n\t\tCMSerr(CMS_F_CMS_VERIFY, CMS_R_NO_SIGNERS);\n\t\tgoto err;\n\t\t}\n\n\tfor (i = 0; i < sk_CMS_SignerInfo_num(sinfos); i++)\n\t\t{\n\t\tsi = sk_CMS_SignerInfo_value(sinfos, i);\n\t\tCMS_SignerInfo_get0_algs(si, NULL, &signer, NULL, NULL);\n\t\tif (signer)\n\t\t\tscount++;\n\t\t}\n\n\tif (scount != sk_CMS_SignerInfo_num(sinfos))\n\t\tscount += CMS_set1_signers_certs(cms, certs, flags);\n\n\tif (scount != sk_CMS_SignerInfo_num(sinfos))\n\t\t{\n\t\tCMSerr(CMS_F_CMS_VERIFY, CMS_R_SIGNER_CERTIFICATE_NOT_FOUND);\n\t\tgoto err;\n\t\t}\n\n\t/* Attempt to verify all signers certs */\n\n\tif (!(flags & CMS_NO_SIGNER_CERT_VERIFY))\n\t\t{\n\t\tcms_certs = CMS_get1_certs(cms);\n\t\tif (!(flags & CMS_NOCRL))\n\t\t\tcrls = CMS_get1_crls(cms);\n\t\tfor (i = 0; i < sk_CMS_SignerInfo_num(sinfos); i++)\n\t\t\t{\n\t\t\tsi = sk_CMS_SignerInfo_value(sinfos, i);\n\t\t\tif (!cms_signerinfo_verify_cert(si, store,\n\t\t\t\t\t\t\tcms_certs, crls, flags))\n\t\t\t\tgoto err;\n\t\t\t}\n\t\t}\n\n\t/* Attempt to verify all SignerInfo signed attribute signatures */\n\n\tif (!(flags & CMS_NO_ATTR_VERIFY))\n\t\t{\n\t\tfor (i = 0; i < sk_CMS_SignerInfo_num(sinfos); i++)\n\t\t\t{\n\t\t\tsi = sk_CMS_SignerInfo_value(sinfos, i);\n\t\t\tif (CMS_signed_get_attr_count(si) < 0)\n\t\t\t\tcontinue;\n\t\t\tif (CMS_SignerInfo_verify(si) <= 0)\n\t\t\t\tgoto err;\n\t\t\t}\n\t\t}\n\n\t/* Performance optimization: if the content is a memory BIO then\n\t * store its contents in a temporary read only memory BIO. This\n\t * avoids potentially large numbers of slow copies of data which will\n\t * occur when reading from a read write memory BIO when signatures\n\t * are calculated.\n\t */\n\n\tif (dcont && (BIO_method_type(dcont) == BIO_TYPE_MEM))\n\t\t{\n\t\tchar *ptr;\n\t\tlong len;\n\t\tlen = BIO_get_mem_data(dcont, &ptr);\n\t\ttmpin = BIO_new_mem_buf(ptr, len);\n\t\tif (tmpin == NULL)\n\t\t\t{\n\t\t\tCMSerr(CMS_F_CMS_VERIFY,ERR_R_MALLOC_FAILURE);\n\t\t\treturn 0;\n\t\t\t}\n\t\t}\n\telse\n\t\ttmpin = dcont;\n\t/* If not binary mode and detached generate digests by *writing*\n\t * through the BIO. That makes it possible to canonicalise the\n\t * input.\n\t */\n\tif (!(flags & SMIME_BINARY) && dcont)\n\t\t{\n\t\t/* Create output BIO so we can either handle text or to\n\t\t * ensure included content doesn't override detached content.\n\t\t */\n\t\ttmpout = cms_get_text_bio(out, flags);\n\t\tif(!tmpout)\n\t\t\t{\n\t\t\tCMSerr(CMS_F_CMS_VERIFY,ERR_R_MALLOC_FAILURE);\n\t\t\tgoto err;\n\t\t\t}\n\t\tcmsbio = CMS_dataInit(cms, tmpout);\n\t\tif (!cmsbio)\n\t\t\tgoto err;\n\t\t/* Don't use SMIME_TEXT for verify: it adds headers and\n\t\t * we want to remove them.\n\t\t */\n\t\tSMIME_crlf_copy(dcont, cmsbio, flags & ~SMIME_TEXT);\n\n\t\tif(flags & CMS_TEXT)\n\t\t\t{\n\t\t\tif (!SMIME_text(tmpout, out))\n\t\t\t\t{\n\t\t\t\tCMSerr(CMS_F_CMS_VERIFY,CMS_R_SMIME_TEXT_ERROR);\n\t\t\t\tgoto err;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\telse\n\t\t{\n\t\tcmsbio=CMS_dataInit(cms, tmpin);\n\t\tif (!cmsbio)\n\t\t\tgoto err;\n\n\t\tif (!cms_copy_content(out, cmsbio, flags))\n\t\t\tgoto err;\n\n\t\t}\n\tif (!(flags & CMS_NO_CONTENT_VERIFY))\n\t\t{\n\t\tfor (i = 0; i < sk_CMS_SignerInfo_num(sinfos); i++)\n\t\t\t{\n\t\t\tsi = sk_CMS_SignerInfo_value(sinfos, i);\n\t\t\tif (CMS_SignerInfo_verify_content(si, cmsbio) <= 0)\n\t\t\t\t{\n\t\t\t\tCMSerr(CMS_F_CMS_VERIFY,\n\t\t\t\t\tCMS_R_CONTENT_VERIFY_ERROR);\n\t\t\t\tgoto err;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\tret = 1;\n\n\terr:\n\tif (!(flags & SMIME_BINARY) && dcont)\n\t\t{\n\t\tdo_free_upto(cmsbio, tmpout);\n\t\tif (tmpin != dcont)\n\t\t\tBIO_free(tmpin);\n\t\t}\n\telse\n\t\t{\n\n\t\tif (dcont && (tmpin == dcont))\n\t\t\tdo_free_upto(cmsbio, dcont);\n\t\telse\n\t\t\tBIO_free_all(cmsbio);\n\t\t}\n\n\tif (tmpout && out != tmpout)\n\t\tBIO_free_all(tmpout);\n\n\tif (cms_certs)\n\t\tsk_X509_pop_free(cms_certs, X509_free);\n\tif (crls)\n\t\tsk_X509_CRL_pop_free(crls, X509_CRL_free);\n\n\treturn ret;\n\t}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -7,7 +7,7 @@\n \tSTACK_OF(X509_CRL) *crls = NULL;\n \tX509 *signer;\n \tint i, scount = 0, ret = 0;\n-\tBIO *cmsbio = NULL, *tmpin = NULL;\n+\tBIO *cmsbio = NULL, *tmpin = NULL, *tmpout = NULL;\n \n \tif (!dcont && !check_content(cms))\n \t\treturn 0;\n@@ -90,15 +90,48 @@\n \t\t}\n \telse\n \t\ttmpin = dcont;\n-\t\t\n+\t/* If not binary mode and detached generate digests by *writing*\n+\t * through the BIO. That makes it possible to canonicalise the\n+\t * input.\n+\t */\n+\tif (!(flags & SMIME_BINARY) && dcont)\n+\t\t{\n+\t\t/* Create output BIO so we can either handle text or to\n+\t\t * ensure included content doesn't override detached content.\n+\t\t */\n+\t\ttmpout = cms_get_text_bio(out, flags);\n+\t\tif(!tmpout)\n+\t\t\t{\n+\t\t\tCMSerr(CMS_F_CMS_VERIFY,ERR_R_MALLOC_FAILURE);\n+\t\t\tgoto err;\n+\t\t\t}\n+\t\tcmsbio = CMS_dataInit(cms, tmpout);\n+\t\tif (!cmsbio)\n+\t\t\tgoto err;\n+\t\t/* Don't use SMIME_TEXT for verify: it adds headers and\n+\t\t * we want to remove them.\n+\t\t */\n+\t\tSMIME_crlf_copy(dcont, cmsbio, flags & ~SMIME_TEXT);\n \n-\tcmsbio=CMS_dataInit(cms, tmpin);\n-\tif (!cmsbio)\n-\t\tgoto err;\n+\t\tif(flags & CMS_TEXT)\n+\t\t\t{\n+\t\t\tif (!SMIME_text(tmpout, out))\n+\t\t\t\t{\n+\t\t\t\tCMSerr(CMS_F_CMS_VERIFY,CMS_R_SMIME_TEXT_ERROR);\n+\t\t\t\tgoto err;\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\telse\n+\t\t{\n+\t\tcmsbio=CMS_dataInit(cms, tmpin);\n+\t\tif (!cmsbio)\n+\t\t\tgoto err;\n \n-\tif (!cms_copy_content(out, cmsbio, flags))\n-\t\tgoto err;\n+\t\tif (!cms_copy_content(out, cmsbio, flags))\n+\t\t\tgoto err;\n \n+\t\t}\n \tif (!(flags & CMS_NO_CONTENT_VERIFY))\n \t\t{\n \t\tfor (i = 0; i < sk_CMS_SignerInfo_num(sinfos); i++)\n@@ -116,11 +149,23 @@\n \tret = 1;\n \n \terr:\n-\t\n-\tif (dcont && (tmpin == dcont))\n-\t\tdo_free_upto(cmsbio, dcont);\n+\tif (!(flags & SMIME_BINARY) && dcont)\n+\t\t{\n+\t\tdo_free_upto(cmsbio, tmpout);\n+\t\tif (tmpin != dcont)\n+\t\t\tBIO_free(tmpin);\n+\t\t}\n \telse\n-\t\tBIO_free_all(cmsbio);\n+\t\t{\n+\n+\t\tif (dcont && (tmpin == dcont))\n+\t\t\tdo_free_upto(cmsbio, dcont);\n+\t\telse\n+\t\t\tBIO_free_all(cmsbio);\n+\t\t}\n+\n+\tif (tmpout && out != tmpout)\n+\t\tBIO_free_all(tmpout);\n \n \tif (cms_certs)\n \t\tsk_X509_pop_free(cms_certs, X509_free);",
        "diff_line_info": {
            "deleted_lines": [
                "\tBIO *cmsbio = NULL, *tmpin = NULL;",
                "\t\t",
                "\tcmsbio=CMS_dataInit(cms, tmpin);",
                "\tif (!cmsbio)",
                "\t\tgoto err;",
                "\tif (!cms_copy_content(out, cmsbio, flags))",
                "\t\tgoto err;",
                "\t",
                "\tif (dcont && (tmpin == dcont))",
                "\t\tdo_free_upto(cmsbio, dcont);",
                "\t\tBIO_free_all(cmsbio);"
            ],
            "added_lines": [
                "\tBIO *cmsbio = NULL, *tmpin = NULL, *tmpout = NULL;",
                "\t/* If not binary mode and detached generate digests by *writing*",
                "\t * through the BIO. That makes it possible to canonicalise the",
                "\t * input.",
                "\t */",
                "\tif (!(flags & SMIME_BINARY) && dcont)",
                "\t\t{",
                "\t\t/* Create output BIO so we can either handle text or to",
                "\t\t * ensure included content doesn't override detached content.",
                "\t\t */",
                "\t\ttmpout = cms_get_text_bio(out, flags);",
                "\t\tif(!tmpout)",
                "\t\t\t{",
                "\t\t\tCMSerr(CMS_F_CMS_VERIFY,ERR_R_MALLOC_FAILURE);",
                "\t\t\tgoto err;",
                "\t\t\t}",
                "\t\tcmsbio = CMS_dataInit(cms, tmpout);",
                "\t\tif (!cmsbio)",
                "\t\t\tgoto err;",
                "\t\t/* Don't use SMIME_TEXT for verify: it adds headers and",
                "\t\t * we want to remove them.",
                "\t\t */",
                "\t\tSMIME_crlf_copy(dcont, cmsbio, flags & ~SMIME_TEXT);",
                "\t\tif(flags & CMS_TEXT)",
                "\t\t\t{",
                "\t\t\tif (!SMIME_text(tmpout, out))",
                "\t\t\t\t{",
                "\t\t\t\tCMSerr(CMS_F_CMS_VERIFY,CMS_R_SMIME_TEXT_ERROR);",
                "\t\t\t\tgoto err;",
                "\t\t\t\t}",
                "\t\t\t}",
                "\t\t}",
                "\telse",
                "\t\t{",
                "\t\tcmsbio=CMS_dataInit(cms, tmpin);",
                "\t\tif (!cmsbio)",
                "\t\t\tgoto err;",
                "\t\tif (!cms_copy_content(out, cmsbio, flags))",
                "\t\t\tgoto err;",
                "\t\t}",
                "\tif (!(flags & SMIME_BINARY) && dcont)",
                "\t\t{",
                "\t\tdo_free_upto(cmsbio, tmpout);",
                "\t\tif (tmpin != dcont)",
                "\t\t\tBIO_free(tmpin);",
                "\t\t}",
                "\t\t{",
                "",
                "\t\tif (dcont && (tmpin == dcont))",
                "\t\t\tdo_free_upto(cmsbio, dcont);",
                "\t\telse",
                "\t\t\tBIO_free_all(cmsbio);",
                "\t\t}",
                "",
                "\tif (tmpout && out != tmpout)",
                "\t\tBIO_free_all(tmpout);"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1792",
        "func_name": "openssl/do_free_upto",
        "description": "The do_free_upto function in crypto/cms/cms_smime.c in OpenSSL before 0.9.8zg, 1.0.0 before 1.0.0s, 1.0.1 before 1.0.1n, and 1.0.2 before 1.0.2b allows remote attackers to cause a denial of service (infinite loop) via vectors that trigger a NULL value of a BIO data structure, as demonstrated by an unrecognized X.660 OID for a hash function.",
        "git_url": "https://github.com/openssl/openssl/commit/cd30f03ac5bf2962f44bd02ae8d88245dff2f12c",
        "commit_title": "Canonicalise input in CMS_verify.",
        "commit_text": " If content is detached and not binary mode translate the input to CRLF format. Before this change the input was verified verbatim which lead to a discrepancy between sign and verify.",
        "func_before": "static void do_free_upto(BIO *f, BIO *upto)\n\t{\n\tif (upto)\n\t\t{\n\t\tBIO *tbio;\n\t\tdo \n\t\t\t{\n\t\t\ttbio = BIO_pop(f);\n\t\t\tBIO_free(f);\n\t\t\tf = tbio;\n\t\t\t}\n\t\twhile (f != upto);\n\t\t}\n\telse\n\t\tBIO_free_all(f);\n\t}",
        "func": "static void do_free_upto(BIO *f, BIO *upto)\n\t{\n\tif (upto)\n\t\t{\n\t\tBIO *tbio;\n\t\tdo \n\t\t\t{\n\t\t\ttbio = BIO_pop(f);\n\t\t\tBIO_free(f);\n\t\t\tf = tbio;\n\t\t\t}\n\t\twhile (f && f != upto);\n\t\t}\n\telse\n\t\tBIO_free_all(f);\n\t}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -9,7 +9,7 @@\n \t\t\tBIO_free(f);\n \t\t\tf = tbio;\n \t\t\t}\n-\t\twhile (f != upto);\n+\t\twhile (f && f != upto);\n \t\t}\n \telse\n \t\tBIO_free_all(f);",
        "diff_line_info": {
            "deleted_lines": [
                "\t\twhile (f != upto);"
            ],
            "added_lines": [
                "\t\twhile (f && f != upto);"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-4164",
        "func_name": "xen-project/xen/compat_iret",
        "description": "The compat_iret function in Xen 3.1 through 4.5 iterates the wrong way through a loop, which allows local 32-bit PV guest administrators to cause a denial of service (large loop and system hang) via a hypercall_iret call with EFLAGS.VM set.",
        "git_url": "https://github.com/xen-project/xen/commit/1f0721377952fc038b48f175d7061ec701359aac",
        "commit_title": "x86/traps: loop in the correct direction in compat_iret()",
        "commit_text": " This is CVE-2015-4164 / XSA-136. ",
        "func_before": "unsigned int compat_iret(void)\n{\n    struct cpu_user_regs *regs = guest_cpu_user_regs();\n    struct vcpu *v = current;\n    u32 eflags;\n\n    /* Trim stack pointer to 32 bits. */\n    regs->rsp = (u32)regs->rsp;\n\n    /* Restore EAX (clobbered by hypercall). */\n    if ( unlikely(__get_user(regs->_eax, (u32 *)regs->rsp)) )\n        goto exit_and_crash;\n\n    /* Restore CS and EIP. */\n    if ( unlikely(__get_user(regs->_eip, (u32 *)regs->rsp + 1)) ||\n        unlikely(__get_user(regs->cs, (u32 *)regs->rsp + 2)) )\n        goto exit_and_crash;\n\n    /*\n     * Fix up and restore EFLAGS. We fix up in a local staging area\n     * to avoid firing the BUG_ON(IOPL) check in arch_get_info_guest.\n     */\n    if ( unlikely(__get_user(eflags, (u32 *)regs->rsp + 3)) )\n        goto exit_and_crash;\n    regs->_eflags = (eflags & ~X86_EFLAGS_IOPL) | X86_EFLAGS_IF;\n\n    if ( unlikely(eflags & X86_EFLAGS_VM) )\n    {\n        /*\n         * Cannot return to VM86 mode: inject a GP fault instead. Note that\n         * the GP fault is reported on the first VM86 mode instruction, not on\n         * the IRET (which is why we can simply leave the stack frame as-is\n         * (except for perhaps having to copy it), which in turn seems better\n         * than teaching create_bounce_frame() to needlessly deal with vm86\n         * mode frames).\n         */\n        const struct trap_info *ti;\n        u32 x, ksp = v->arch.pv_vcpu.kernel_sp - 40;\n        unsigned int i;\n        int rc = 0;\n\n        gdprintk(XENLOG_ERR, \"VM86 mode unavailable (ksp:%08X->%08X)\\n\",\n                 regs->_esp, ksp);\n        if ( ksp < regs->_esp )\n        {\n            for (i = 1; i < 10; ++i)\n            {\n                rc |= __get_user(x, (u32 *)regs->rsp + i);\n                rc |= __put_user(x, (u32 *)(unsigned long)ksp + i);\n            }\n        }\n        else if ( ksp > regs->_esp )\n        {\n            for (i = 9; i > 0; ++i)\n            {\n                rc |= __get_user(x, (u32 *)regs->rsp + i);\n                rc |= __put_user(x, (u32 *)(unsigned long)ksp + i);\n            }\n        }\n        if ( rc )\n            goto exit_and_crash;\n        regs->_esp = ksp;\n        regs->ss = v->arch.pv_vcpu.kernel_ss;\n\n        ti = &v->arch.pv_vcpu.trap_ctxt[TRAP_gp_fault];\n        if ( TI_GET_IF(ti) )\n            eflags &= ~X86_EFLAGS_IF;\n        regs->_eflags &= ~(X86_EFLAGS_VM|X86_EFLAGS_RF|\n                           X86_EFLAGS_NT|X86_EFLAGS_TF);\n        if ( unlikely(__put_user(0, (u32 *)regs->rsp)) )\n            goto exit_and_crash;\n        regs->_eip = ti->address;\n        regs->cs = ti->cs;\n    }\n    else if ( unlikely(ring_0(regs)) )\n        goto exit_and_crash;\n    else if ( !ring_1(regs) )\n    {\n        /* Return to ring 2/3: restore ESP and SS. */\n        if ( __get_user(regs->ss, (u32 *)regs->rsp + 5)\n            || __get_user(regs->_esp, (u32 *)regs->rsp + 4))\n            goto exit_and_crash;\n    }\n    else\n        regs->_esp += 16;\n\n    /* Restore upcall mask from supplied EFLAGS.IF. */\n    vcpu_info(v, evtchn_upcall_mask) = !(eflags & X86_EFLAGS_IF);\n\n    async_exception_cleanup(v);\n\n    /*\n     * The hypercall exit path will overwrite EAX with this return\n     * value.\n     */\n    return regs->_eax;\n\n exit_and_crash:\n    gprintk(XENLOG_ERR, \"Fatal IRET error\\n\");\n    domain_crash(v->domain);\n    return 0;\n}",
        "func": "unsigned int compat_iret(void)\n{\n    struct cpu_user_regs *regs = guest_cpu_user_regs();\n    struct vcpu *v = current;\n    u32 eflags;\n\n    /* Trim stack pointer to 32 bits. */\n    regs->rsp = (u32)regs->rsp;\n\n    /* Restore EAX (clobbered by hypercall). */\n    if ( unlikely(__get_user(regs->_eax, (u32 *)regs->rsp)) )\n        goto exit_and_crash;\n\n    /* Restore CS and EIP. */\n    if ( unlikely(__get_user(regs->_eip, (u32 *)regs->rsp + 1)) ||\n        unlikely(__get_user(regs->cs, (u32 *)regs->rsp + 2)) )\n        goto exit_and_crash;\n\n    /*\n     * Fix up and restore EFLAGS. We fix up in a local staging area\n     * to avoid firing the BUG_ON(IOPL) check in arch_get_info_guest.\n     */\n    if ( unlikely(__get_user(eflags, (u32 *)regs->rsp + 3)) )\n        goto exit_and_crash;\n    regs->_eflags = (eflags & ~X86_EFLAGS_IOPL) | X86_EFLAGS_IF;\n\n    if ( unlikely(eflags & X86_EFLAGS_VM) )\n    {\n        /*\n         * Cannot return to VM86 mode: inject a GP fault instead. Note that\n         * the GP fault is reported on the first VM86 mode instruction, not on\n         * the IRET (which is why we can simply leave the stack frame as-is\n         * (except for perhaps having to copy it), which in turn seems better\n         * than teaching create_bounce_frame() to needlessly deal with vm86\n         * mode frames).\n         */\n        const struct trap_info *ti;\n        u32 x, ksp = v->arch.pv_vcpu.kernel_sp - 40;\n        unsigned int i;\n        int rc = 0;\n\n        gdprintk(XENLOG_ERR, \"VM86 mode unavailable (ksp:%08X->%08X)\\n\",\n                 regs->_esp, ksp);\n        if ( ksp < regs->_esp )\n        {\n            for (i = 1; i < 10; ++i)\n            {\n                rc |= __get_user(x, (u32 *)regs->rsp + i);\n                rc |= __put_user(x, (u32 *)(unsigned long)ksp + i);\n            }\n        }\n        else if ( ksp > regs->_esp )\n        {\n            for ( i = 9; i > 0; --i )\n            {\n                rc |= __get_user(x, (u32 *)regs->rsp + i);\n                rc |= __put_user(x, (u32 *)(unsigned long)ksp + i);\n            }\n        }\n        if ( rc )\n            goto exit_and_crash;\n        regs->_esp = ksp;\n        regs->ss = v->arch.pv_vcpu.kernel_ss;\n\n        ti = &v->arch.pv_vcpu.trap_ctxt[TRAP_gp_fault];\n        if ( TI_GET_IF(ti) )\n            eflags &= ~X86_EFLAGS_IF;\n        regs->_eflags &= ~(X86_EFLAGS_VM|X86_EFLAGS_RF|\n                           X86_EFLAGS_NT|X86_EFLAGS_TF);\n        if ( unlikely(__put_user(0, (u32 *)regs->rsp)) )\n            goto exit_and_crash;\n        regs->_eip = ti->address;\n        regs->cs = ti->cs;\n    }\n    else if ( unlikely(ring_0(regs)) )\n        goto exit_and_crash;\n    else if ( !ring_1(regs) )\n    {\n        /* Return to ring 2/3: restore ESP and SS. */\n        if ( __get_user(regs->ss, (u32 *)regs->rsp + 5)\n            || __get_user(regs->_esp, (u32 *)regs->rsp + 4))\n            goto exit_and_crash;\n    }\n    else\n        regs->_esp += 16;\n\n    /* Restore upcall mask from supplied EFLAGS.IF. */\n    vcpu_info(v, evtchn_upcall_mask) = !(eflags & X86_EFLAGS_IF);\n\n    async_exception_cleanup(v);\n\n    /*\n     * The hypercall exit path will overwrite EAX with this return\n     * value.\n     */\n    return regs->_eax;\n\n exit_and_crash:\n    gprintk(XENLOG_ERR, \"Fatal IRET error\\n\");\n    domain_crash(v->domain);\n    return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -51,7 +51,7 @@\n         }\n         else if ( ksp > regs->_esp )\n         {\n-            for (i = 9; i > 0; ++i)\n+            for ( i = 9; i > 0; --i )\n             {\n                 rc |= __get_user(x, (u32 *)regs->rsp + i);\n                 rc |= __put_user(x, (u32 *)(unsigned long)ksp + i);",
        "diff_line_info": {
            "deleted_lines": [
                "            for (i = 9; i > 0; ++i)"
            ],
            "added_lines": [
                "            for ( i = 9; i > 0; --i )"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1819",
        "func_name": "GNOME/libxml2/xmlBufAdd",
        "description": "The xmlreader in libxml allows remote attackers to cause a denial of service (memory consumption) via crafted XML data, related to an XML Entity Expansion (XEE) attack.",
        "git_url": "https://github.com/GNOME/libxml2/commit/213f1fe0d76d30eaed6e5853057defc43e6df2c9",
        "commit_title": "CVE-2015-1819 Enforce the reader to run in constant memory",
        "commit_text": " One of the operation on the reader could resolve entities leading to the classic expansion issue. Make sure the buffer used for xmlreader operation is bounded. Introduce a new allocation type for the buffers for this effect.",
        "func_before": "int\nxmlBufAdd(xmlBufPtr buf, const xmlChar *str, int len) {\n    unsigned int needSize;\n\n    if ((str == NULL) || (buf == NULL) || (buf->error))\n\treturn -1;\n    CHECK_COMPAT(buf)\n\n    if (buf->alloc == XML_BUFFER_ALLOC_IMMUTABLE) return -1;\n    if (len < -1) {\n#ifdef DEBUG_BUFFER\n        xmlGenericError(xmlGenericErrorContext,\n\t\t\"xmlBufAdd: len < 0\\n\");\n#endif\n\treturn -1;\n    }\n    if (len == 0) return 0;\n\n    if (len < 0)\n        len = xmlStrlen(str);\n\n    if (len < 0) return -1;\n    if (len == 0) return 0;\n\n    needSize = buf->use + len + 2;\n    if (needSize > buf->size){\n        if (!xmlBufResize(buf, needSize)){\n\t    xmlBufMemoryError(buf, \"growing buffer\");\n            return XML_ERR_NO_MEMORY;\n        }\n    }\n\n    memmove(&buf->content[buf->use], str, len*sizeof(xmlChar));\n    buf->use += len;\n    buf->content[buf->use] = 0;\n    UPDATE_COMPAT(buf)\n    return 0;\n}",
        "func": "int\nxmlBufAdd(xmlBufPtr buf, const xmlChar *str, int len) {\n    unsigned int needSize;\n\n    if ((str == NULL) || (buf == NULL) || (buf->error))\n\treturn -1;\n    CHECK_COMPAT(buf)\n\n    if (buf->alloc == XML_BUFFER_ALLOC_IMMUTABLE) return -1;\n    if (len < -1) {\n#ifdef DEBUG_BUFFER\n        xmlGenericError(xmlGenericErrorContext,\n\t\t\"xmlBufAdd: len < 0\\n\");\n#endif\n\treturn -1;\n    }\n    if (len == 0) return 0;\n\n    if (len < 0)\n        len = xmlStrlen(str);\n\n    if (len < 0) return -1;\n    if (len == 0) return 0;\n\n    needSize = buf->use + len + 2;\n    if (needSize > buf->size){\n\tif (buf->alloc == XML_BUFFER_ALLOC_BOUNDED) {\n\t    /*\n\t     * Used to provide parsing limits\n\t     */\n\t    if (needSize >= XML_MAX_TEXT_LENGTH) {\n\t\txmlBufMemoryError(buf, \"buffer error: text too long\\n\");\n\t\treturn(-1);\n\t    }\n\t}\n        if (!xmlBufResize(buf, needSize)){\n\t    xmlBufMemoryError(buf, \"growing buffer\");\n            return XML_ERR_NO_MEMORY;\n        }\n    }\n\n    memmove(&buf->content[buf->use], str, len*sizeof(xmlChar));\n    buf->use += len;\n    buf->content[buf->use] = 0;\n    UPDATE_COMPAT(buf)\n    return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -24,6 +24,15 @@\n \n     needSize = buf->use + len + 2;\n     if (needSize > buf->size){\n+\tif (buf->alloc == XML_BUFFER_ALLOC_BOUNDED) {\n+\t    /*\n+\t     * Used to provide parsing limits\n+\t     */\n+\t    if (needSize >= XML_MAX_TEXT_LENGTH) {\n+\t\txmlBufMemoryError(buf, \"buffer error: text too long\\n\");\n+\t\treturn(-1);\n+\t    }\n+\t}\n         if (!xmlBufResize(buf, needSize)){\n \t    xmlBufMemoryError(buf, \"growing buffer\");\n             return XML_ERR_NO_MEMORY;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tif (buf->alloc == XML_BUFFER_ALLOC_BOUNDED) {",
                "\t    /*",
                "\t     * Used to provide parsing limits",
                "\t     */",
                "\t    if (needSize >= XML_MAX_TEXT_LENGTH) {",
                "\t\txmlBufMemoryError(buf, \"buffer error: text too long\\n\");",
                "\t\treturn(-1);",
                "\t    }",
                "\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1819",
        "func_name": "GNOME/libxml2/xmlBufSetAllocationScheme",
        "description": "The xmlreader in libxml allows remote attackers to cause a denial of service (memory consumption) via crafted XML data, related to an XML Entity Expansion (XEE) attack.",
        "git_url": "https://github.com/GNOME/libxml2/commit/213f1fe0d76d30eaed6e5853057defc43e6df2c9",
        "commit_title": "CVE-2015-1819 Enforce the reader to run in constant memory",
        "commit_text": " One of the operation on the reader could resolve entities leading to the classic expansion issue. Make sure the buffer used for xmlreader operation is bounded. Introduce a new allocation type for the buffers for this effect.",
        "func_before": "int\nxmlBufSetAllocationScheme(xmlBufPtr buf,\n                          xmlBufferAllocationScheme scheme) {\n    if ((buf == NULL) || (buf->error != 0)) {\n#ifdef DEBUG_BUFFER\n        xmlGenericError(xmlGenericErrorContext,\n\t\t\"xmlBufSetAllocationScheme: buf == NULL or in error\\n\");\n#endif\n        return(-1);\n    }\n    if ((buf->alloc == XML_BUFFER_ALLOC_IMMUTABLE) ||\n        (buf->alloc == XML_BUFFER_ALLOC_IO))\n        return(-1);\n    if ((scheme == XML_BUFFER_ALLOC_DOUBLEIT) ||\n        (scheme == XML_BUFFER_ALLOC_EXACT) ||\n        (scheme == XML_BUFFER_ALLOC_HYBRID) ||\n        (scheme == XML_BUFFER_ALLOC_IMMUTABLE)) {\n\tbuf->alloc = scheme;\n        if (buf->buffer)\n            buf->buffer->alloc = scheme;\n        return(0);\n    }\n    /*\n     * Switching a buffer ALLOC_IO has the side effect of initializing\n     * the contentIO field with the current content\n     */\n    if (scheme == XML_BUFFER_ALLOC_IO) {\n        buf->alloc = XML_BUFFER_ALLOC_IO;\n        buf->contentIO = buf->content;\n    }\n    return(-1);\n}",
        "func": "int\nxmlBufSetAllocationScheme(xmlBufPtr buf,\n                          xmlBufferAllocationScheme scheme) {\n    if ((buf == NULL) || (buf->error != 0)) {\n#ifdef DEBUG_BUFFER\n        xmlGenericError(xmlGenericErrorContext,\n\t\t\"xmlBufSetAllocationScheme: buf == NULL or in error\\n\");\n#endif\n        return(-1);\n    }\n    if ((buf->alloc == XML_BUFFER_ALLOC_IMMUTABLE) ||\n        (buf->alloc == XML_BUFFER_ALLOC_IO))\n        return(-1);\n    if ((scheme == XML_BUFFER_ALLOC_DOUBLEIT) ||\n        (scheme == XML_BUFFER_ALLOC_EXACT) ||\n        (scheme == XML_BUFFER_ALLOC_HYBRID) ||\n        (scheme == XML_BUFFER_ALLOC_IMMUTABLE) ||\n\t(scheme == XML_BUFFER_ALLOC_BOUNDED)) {\n\tbuf->alloc = scheme;\n        if (buf->buffer)\n            buf->buffer->alloc = scheme;\n        return(0);\n    }\n    /*\n     * Switching a buffer ALLOC_IO has the side effect of initializing\n     * the contentIO field with the current content\n     */\n    if (scheme == XML_BUFFER_ALLOC_IO) {\n        buf->alloc = XML_BUFFER_ALLOC_IO;\n        buf->contentIO = buf->content;\n    }\n    return(-1);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -14,7 +14,8 @@\n     if ((scheme == XML_BUFFER_ALLOC_DOUBLEIT) ||\n         (scheme == XML_BUFFER_ALLOC_EXACT) ||\n         (scheme == XML_BUFFER_ALLOC_HYBRID) ||\n-        (scheme == XML_BUFFER_ALLOC_IMMUTABLE)) {\n+        (scheme == XML_BUFFER_ALLOC_IMMUTABLE) ||\n+\t(scheme == XML_BUFFER_ALLOC_BOUNDED)) {\n \tbuf->alloc = scheme;\n         if (buf->buffer)\n             buf->buffer->alloc = scheme;",
        "diff_line_info": {
            "deleted_lines": [
                "        (scheme == XML_BUFFER_ALLOC_IMMUTABLE)) {"
            ],
            "added_lines": [
                "        (scheme == XML_BUFFER_ALLOC_IMMUTABLE) ||",
                "\t(scheme == XML_BUFFER_ALLOC_BOUNDED)) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1819",
        "func_name": "GNOME/libxml2/xmlBufGrowInternal",
        "description": "The xmlreader in libxml allows remote attackers to cause a denial of service (memory consumption) via crafted XML data, related to an XML Entity Expansion (XEE) attack.",
        "git_url": "https://github.com/GNOME/libxml2/commit/213f1fe0d76d30eaed6e5853057defc43e6df2c9",
        "commit_title": "CVE-2015-1819 Enforce the reader to run in constant memory",
        "commit_text": " One of the operation on the reader could resolve entities leading to the classic expansion issue. Make sure the buffer used for xmlreader operation is bounded. Introduce a new allocation type for the buffers for this effect.",
        "func_before": "static size_t\nxmlBufGrowInternal(xmlBufPtr buf, size_t len) {\n    size_t size;\n    xmlChar *newbuf;\n\n    if ((buf == NULL) || (buf->error != 0)) return(0);\n    CHECK_COMPAT(buf)\n\n    if (buf->alloc == XML_BUFFER_ALLOC_IMMUTABLE) return(0);\n    if (buf->use + len < buf->size)\n        return(buf->size - buf->use);\n\n    /*\n     * Windows has a BIG problem on realloc timing, so we try to double\n     * the buffer size (if that's enough) (bug 146697)\n     * Apparently BSD too, and it's probably best for linux too\n     * On an embedded system this may be something to change\n     */\n#if 1\n    if (buf->size > (size_t) len)\n        size = buf->size * 2;\n    else\n        size = buf->use + len + 100;\n#else\n    size = buf->use + len + 100;\n#endif\n\n    if ((buf->alloc == XML_BUFFER_ALLOC_IO) && (buf->contentIO != NULL)) {\n        size_t start_buf = buf->content - buf->contentIO;\n\n\tnewbuf = (xmlChar *) xmlRealloc(buf->contentIO, start_buf + size);\n\tif (newbuf == NULL) {\n\t    xmlBufMemoryError(buf, \"growing buffer\");\n\t    return(0);\n\t}\n\tbuf->contentIO = newbuf;\n\tbuf->content = newbuf + start_buf;\n    } else {\n\tnewbuf = (xmlChar *) xmlRealloc(buf->content, size);\n\tif (newbuf == NULL) {\n\t    xmlBufMemoryError(buf, \"growing buffer\");\n\t    return(0);\n\t}\n\tbuf->content = newbuf;\n    }\n    buf->size = size;\n    UPDATE_COMPAT(buf)\n    return(buf->size - buf->use);\n}",
        "func": "static size_t\nxmlBufGrowInternal(xmlBufPtr buf, size_t len) {\n    size_t size;\n    xmlChar *newbuf;\n\n    if ((buf == NULL) || (buf->error != 0)) return(0);\n    CHECK_COMPAT(buf)\n\n    if (buf->alloc == XML_BUFFER_ALLOC_IMMUTABLE) return(0);\n    if (buf->use + len < buf->size)\n        return(buf->size - buf->use);\n\n    /*\n     * Windows has a BIG problem on realloc timing, so we try to double\n     * the buffer size (if that's enough) (bug 146697)\n     * Apparently BSD too, and it's probably best for linux too\n     * On an embedded system this may be something to change\n     */\n#if 1\n    if (buf->size > (size_t) len)\n        size = buf->size * 2;\n    else\n        size = buf->use + len + 100;\n#else\n    size = buf->use + len + 100;\n#endif\n\n    if (buf->alloc == XML_BUFFER_ALLOC_BOUNDED) {\n        /*\n\t * Used to provide parsing limits\n\t */\n        if ((buf->use + len >= XML_MAX_TEXT_LENGTH) ||\n\t    (buf->size >= XML_MAX_TEXT_LENGTH)) {\n\t    xmlBufMemoryError(buf, \"buffer error: text too long\\n\");\n\t    return(0);\n\t}\n\tif (size >= XML_MAX_TEXT_LENGTH)\n\t    size = XML_MAX_TEXT_LENGTH;\n    }\n    if ((buf->alloc == XML_BUFFER_ALLOC_IO) && (buf->contentIO != NULL)) {\n        size_t start_buf = buf->content - buf->contentIO;\n\n\tnewbuf = (xmlChar *) xmlRealloc(buf->contentIO, start_buf + size);\n\tif (newbuf == NULL) {\n\t    xmlBufMemoryError(buf, \"growing buffer\");\n\t    return(0);\n\t}\n\tbuf->contentIO = newbuf;\n\tbuf->content = newbuf + start_buf;\n    } else {\n\tnewbuf = (xmlChar *) xmlRealloc(buf->content, size);\n\tif (newbuf == NULL) {\n\t    xmlBufMemoryError(buf, \"growing buffer\");\n\t    return(0);\n\t}\n\tbuf->content = newbuf;\n    }\n    buf->size = size;\n    UPDATE_COMPAT(buf)\n    return(buf->size - buf->use);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -25,6 +25,18 @@\n     size = buf->use + len + 100;\n #endif\n \n+    if (buf->alloc == XML_BUFFER_ALLOC_BOUNDED) {\n+        /*\n+\t * Used to provide parsing limits\n+\t */\n+        if ((buf->use + len >= XML_MAX_TEXT_LENGTH) ||\n+\t    (buf->size >= XML_MAX_TEXT_LENGTH)) {\n+\t    xmlBufMemoryError(buf, \"buffer error: text too long\\n\");\n+\t    return(0);\n+\t}\n+\tif (size >= XML_MAX_TEXT_LENGTH)\n+\t    size = XML_MAX_TEXT_LENGTH;\n+    }\n     if ((buf->alloc == XML_BUFFER_ALLOC_IO) && (buf->contentIO != NULL)) {\n         size_t start_buf = buf->content - buf->contentIO;\n ",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    if (buf->alloc == XML_BUFFER_ALLOC_BOUNDED) {",
                "        /*",
                "\t * Used to provide parsing limits",
                "\t */",
                "        if ((buf->use + len >= XML_MAX_TEXT_LENGTH) ||",
                "\t    (buf->size >= XML_MAX_TEXT_LENGTH)) {",
                "\t    xmlBufMemoryError(buf, \"buffer error: text too long\\n\");",
                "\t    return(0);",
                "\t}",
                "\tif (size >= XML_MAX_TEXT_LENGTH)",
                "\t    size = XML_MAX_TEXT_LENGTH;",
                "    }"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1819",
        "func_name": "GNOME/libxml2/xmlBufResize",
        "description": "The xmlreader in libxml allows remote attackers to cause a denial of service (memory consumption) via crafted XML data, related to an XML Entity Expansion (XEE) attack.",
        "git_url": "https://github.com/GNOME/libxml2/commit/213f1fe0d76d30eaed6e5853057defc43e6df2c9",
        "commit_title": "CVE-2015-1819 Enforce the reader to run in constant memory",
        "commit_text": " One of the operation on the reader could resolve entities leading to the classic expansion issue. Make sure the buffer used for xmlreader operation is bounded. Introduce a new allocation type for the buffers for this effect.",
        "func_before": "int\nxmlBufResize(xmlBufPtr buf, size_t size)\n{\n    unsigned int newSize;\n    xmlChar* rebuf = NULL;\n    size_t start_buf;\n\n    if ((buf == NULL) || (buf->error))\n        return(0);\n    CHECK_COMPAT(buf)\n\n    if (buf->alloc == XML_BUFFER_ALLOC_IMMUTABLE) return(0);\n\n    /* Don't resize if we don't have to */\n    if (size < buf->size)\n        return 1;\n\n    /* figure out new size */\n    switch (buf->alloc){\n\tcase XML_BUFFER_ALLOC_IO:\n\tcase XML_BUFFER_ALLOC_DOUBLEIT:\n\t    /*take care of empty case*/\n\t    newSize = (buf->size ? buf->size*2 : size + 10);\n\t    while (size > newSize) {\n\t        if (newSize > UINT_MAX / 2) {\n\t            xmlBufMemoryError(buf, \"growing buffer\");\n\t            return 0;\n\t        }\n\t        newSize *= 2;\n\t    }\n\t    break;\n\tcase XML_BUFFER_ALLOC_EXACT:\n\t    newSize = size+10;\n\t    break;\n        case XML_BUFFER_ALLOC_HYBRID:\n            if (buf->use < BASE_BUFFER_SIZE)\n                newSize = size;\n            else {\n                newSize = buf->size * 2;\n                while (size > newSize) {\n                    if (newSize > UINT_MAX / 2) {\n                        xmlBufMemoryError(buf, \"growing buffer\");\n                        return 0;\n                    }\n                    newSize *= 2;\n                }\n            }\n            break;\n\n\tdefault:\n\t    newSize = size+10;\n\t    break;\n    }\n\n    if ((buf->alloc == XML_BUFFER_ALLOC_IO) && (buf->contentIO != NULL)) {\n        start_buf = buf->content - buf->contentIO;\n\n        if (start_buf > newSize) {\n\t    /* move data back to start */\n\t    memmove(buf->contentIO, buf->content, buf->use);\n\t    buf->content = buf->contentIO;\n\t    buf->content[buf->use] = 0;\n\t    buf->size += start_buf;\n\t} else {\n\t    rebuf = (xmlChar *) xmlRealloc(buf->contentIO, start_buf + newSize);\n\t    if (rebuf == NULL) {\n\t\txmlBufMemoryError(buf, \"growing buffer\");\n\t\treturn 0;\n\t    }\n\t    buf->contentIO = rebuf;\n\t    buf->content = rebuf + start_buf;\n\t}\n    } else {\n\tif (buf->content == NULL) {\n\t    rebuf = (xmlChar *) xmlMallocAtomic(newSize);\n\t} else if (buf->size - buf->use < 100) {\n\t    rebuf = (xmlChar *) xmlRealloc(buf->content, newSize);\n        } else {\n\t    /*\n\t     * if we are reallocating a buffer far from being full, it's\n\t     * better to make a new allocation and copy only the used range\n\t     * and free the old one.\n\t     */\n\t    rebuf = (xmlChar *) xmlMallocAtomic(newSize);\n\t    if (rebuf != NULL) {\n\t\tmemcpy(rebuf, buf->content, buf->use);\n\t\txmlFree(buf->content);\n\t\trebuf[buf->use] = 0;\n\t    }\n\t}\n\tif (rebuf == NULL) {\n\t    xmlBufMemoryError(buf, \"growing buffer\");\n\t    return 0;\n\t}\n\tbuf->content = rebuf;\n    }\n    buf->size = newSize;\n    UPDATE_COMPAT(buf)\n\n    return 1;\n}",
        "func": "int\nxmlBufResize(xmlBufPtr buf, size_t size)\n{\n    unsigned int newSize;\n    xmlChar* rebuf = NULL;\n    size_t start_buf;\n\n    if ((buf == NULL) || (buf->error))\n        return(0);\n    CHECK_COMPAT(buf)\n\n    if (buf->alloc == XML_BUFFER_ALLOC_IMMUTABLE) return(0);\n    if (buf->alloc == XML_BUFFER_ALLOC_BOUNDED) {\n        /*\n\t * Used to provide parsing limits\n\t */\n        if (size >= XML_MAX_TEXT_LENGTH) {\n\t    xmlBufMemoryError(buf, \"buffer error: text too long\\n\");\n\t    return(0);\n\t}\n    }\n\n    /* Don't resize if we don't have to */\n    if (size < buf->size)\n        return 1;\n\n    /* figure out new size */\n    switch (buf->alloc){\n\tcase XML_BUFFER_ALLOC_IO:\n\tcase XML_BUFFER_ALLOC_DOUBLEIT:\n\t    /*take care of empty case*/\n\t    newSize = (buf->size ? buf->size*2 : size + 10);\n\t    while (size > newSize) {\n\t        if (newSize > UINT_MAX / 2) {\n\t            xmlBufMemoryError(buf, \"growing buffer\");\n\t            return 0;\n\t        }\n\t        newSize *= 2;\n\t    }\n\t    break;\n\tcase XML_BUFFER_ALLOC_EXACT:\n\t    newSize = size+10;\n\t    break;\n        case XML_BUFFER_ALLOC_HYBRID:\n            if (buf->use < BASE_BUFFER_SIZE)\n                newSize = size;\n            else {\n                newSize = buf->size * 2;\n                while (size > newSize) {\n                    if (newSize > UINT_MAX / 2) {\n                        xmlBufMemoryError(buf, \"growing buffer\");\n                        return 0;\n                    }\n                    newSize *= 2;\n                }\n            }\n            break;\n\n\tdefault:\n\t    newSize = size+10;\n\t    break;\n    }\n\n    if ((buf->alloc == XML_BUFFER_ALLOC_IO) && (buf->contentIO != NULL)) {\n        start_buf = buf->content - buf->contentIO;\n\n        if (start_buf > newSize) {\n\t    /* move data back to start */\n\t    memmove(buf->contentIO, buf->content, buf->use);\n\t    buf->content = buf->contentIO;\n\t    buf->content[buf->use] = 0;\n\t    buf->size += start_buf;\n\t} else {\n\t    rebuf = (xmlChar *) xmlRealloc(buf->contentIO, start_buf + newSize);\n\t    if (rebuf == NULL) {\n\t\txmlBufMemoryError(buf, \"growing buffer\");\n\t\treturn 0;\n\t    }\n\t    buf->contentIO = rebuf;\n\t    buf->content = rebuf + start_buf;\n\t}\n    } else {\n\tif (buf->content == NULL) {\n\t    rebuf = (xmlChar *) xmlMallocAtomic(newSize);\n\t} else if (buf->size - buf->use < 100) {\n\t    rebuf = (xmlChar *) xmlRealloc(buf->content, newSize);\n        } else {\n\t    /*\n\t     * if we are reallocating a buffer far from being full, it's\n\t     * better to make a new allocation and copy only the used range\n\t     * and free the old one.\n\t     */\n\t    rebuf = (xmlChar *) xmlMallocAtomic(newSize);\n\t    if (rebuf != NULL) {\n\t\tmemcpy(rebuf, buf->content, buf->use);\n\t\txmlFree(buf->content);\n\t\trebuf[buf->use] = 0;\n\t    }\n\t}\n\tif (rebuf == NULL) {\n\t    xmlBufMemoryError(buf, \"growing buffer\");\n\t    return 0;\n\t}\n\tbuf->content = rebuf;\n    }\n    buf->size = newSize;\n    UPDATE_COMPAT(buf)\n\n    return 1;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -10,6 +10,15 @@\n     CHECK_COMPAT(buf)\n \n     if (buf->alloc == XML_BUFFER_ALLOC_IMMUTABLE) return(0);\n+    if (buf->alloc == XML_BUFFER_ALLOC_BOUNDED) {\n+        /*\n+\t * Used to provide parsing limits\n+\t */\n+        if (size >= XML_MAX_TEXT_LENGTH) {\n+\t    xmlBufMemoryError(buf, \"buffer error: text too long\\n\");\n+\t    return(0);\n+\t}\n+    }\n \n     /* Don't resize if we don't have to */\n     if (size < buf->size)",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    if (buf->alloc == XML_BUFFER_ALLOC_BOUNDED) {",
                "        /*",
                "\t * Used to provide parsing limits",
                "\t */",
                "        if (size >= XML_MAX_TEXT_LENGTH) {",
                "\t    xmlBufMemoryError(buf, \"buffer error: text too long\\n\");",
                "\t    return(0);",
                "\t}",
                "    }"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1819",
        "func_name": "GNOME/libxml2/xmlBufAddHead",
        "description": "The xmlreader in libxml allows remote attackers to cause a denial of service (memory consumption) via crafted XML data, related to an XML Entity Expansion (XEE) attack.",
        "git_url": "https://github.com/GNOME/libxml2/commit/213f1fe0d76d30eaed6e5853057defc43e6df2c9",
        "commit_title": "CVE-2015-1819 Enforce the reader to run in constant memory",
        "commit_text": " One of the operation on the reader could resolve entities leading to the classic expansion issue. Make sure the buffer used for xmlreader operation is bounded. Introduce a new allocation type for the buffers for this effect.",
        "func_before": "int\nxmlBufAddHead(xmlBufPtr buf, const xmlChar *str, int len) {\n    unsigned int needSize;\n\n    if ((buf == NULL) || (buf->error))\n        return(-1);\n    CHECK_COMPAT(buf)\n    if (buf->alloc == XML_BUFFER_ALLOC_IMMUTABLE) return -1;\n    if (str == NULL) {\n#ifdef DEBUG_BUFFER\n        xmlGenericError(xmlGenericErrorContext,\n\t\t\"xmlBufAddHead: str == NULL\\n\");\n#endif\n\treturn -1;\n    }\n    if (len < -1) {\n#ifdef DEBUG_BUFFER\n        xmlGenericError(xmlGenericErrorContext,\n\t\t\"xmlBufAddHead: len < 0\\n\");\n#endif\n\treturn -1;\n    }\n    if (len == 0) return 0;\n\n    if (len < 0)\n        len = xmlStrlen(str);\n\n    if (len <= 0) return -1;\n\n    if ((buf->alloc == XML_BUFFER_ALLOC_IO) && (buf->contentIO != NULL)) {\n        size_t start_buf = buf->content - buf->contentIO;\n\n\tif (start_buf > (unsigned int) len) {\n\t    /*\n\t     * We can add it in the space previously shrinked\n\t     */\n\t    buf->content -= len;\n            memmove(&buf->content[0], str, len);\n\t    buf->use += len;\n\t    buf->size += len;\n\t    UPDATE_COMPAT(buf)\n\t    return(0);\n\t}\n    }\n    needSize = buf->use + len + 2;\n    if (needSize > buf->size){\n        if (!xmlBufResize(buf, needSize)){\n\t    xmlBufMemoryError(buf, \"growing buffer\");\n            return XML_ERR_NO_MEMORY;\n        }\n    }\n\n    memmove(&buf->content[len], &buf->content[0], buf->use);\n    memmove(&buf->content[0], str, len);\n    buf->use += len;\n    buf->content[buf->use] = 0;\n    UPDATE_COMPAT(buf)\n    return 0;\n}",
        "func": "int\nxmlBufAddHead(xmlBufPtr buf, const xmlChar *str, int len) {\n    unsigned int needSize;\n\n    if ((buf == NULL) || (buf->error))\n        return(-1);\n    CHECK_COMPAT(buf)\n    if (buf->alloc == XML_BUFFER_ALLOC_IMMUTABLE) return -1;\n    if (str == NULL) {\n#ifdef DEBUG_BUFFER\n        xmlGenericError(xmlGenericErrorContext,\n\t\t\"xmlBufAddHead: str == NULL\\n\");\n#endif\n\treturn -1;\n    }\n    if (len < -1) {\n#ifdef DEBUG_BUFFER\n        xmlGenericError(xmlGenericErrorContext,\n\t\t\"xmlBufAddHead: len < 0\\n\");\n#endif\n\treturn -1;\n    }\n    if (len == 0) return 0;\n\n    if (len < 0)\n        len = xmlStrlen(str);\n\n    if (len <= 0) return -1;\n\n    if ((buf->alloc == XML_BUFFER_ALLOC_IO) && (buf->contentIO != NULL)) {\n        size_t start_buf = buf->content - buf->contentIO;\n\n\tif (start_buf > (unsigned int) len) {\n\t    /*\n\t     * We can add it in the space previously shrinked\n\t     */\n\t    buf->content -= len;\n            memmove(&buf->content[0], str, len);\n\t    buf->use += len;\n\t    buf->size += len;\n\t    UPDATE_COMPAT(buf)\n\t    return(0);\n\t}\n    }\n    needSize = buf->use + len + 2;\n    if (needSize > buf->size){\n\tif (buf->alloc == XML_BUFFER_ALLOC_BOUNDED) {\n\t    /*\n\t     * Used to provide parsing limits\n\t     */\n\t    if (needSize >= XML_MAX_TEXT_LENGTH) {\n\t\txmlBufMemoryError(buf, \"buffer error: text too long\\n\");\n\t\treturn(-1);\n\t    }\n\t}\n        if (!xmlBufResize(buf, needSize)){\n\t    xmlBufMemoryError(buf, \"growing buffer\");\n            return XML_ERR_NO_MEMORY;\n        }\n    }\n\n    memmove(&buf->content[len], &buf->content[0], buf->use);\n    memmove(&buf->content[0], str, len);\n    buf->use += len;\n    buf->content[buf->use] = 0;\n    UPDATE_COMPAT(buf)\n    return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -44,6 +44,15 @@\n     }\n     needSize = buf->use + len + 2;\n     if (needSize > buf->size){\n+\tif (buf->alloc == XML_BUFFER_ALLOC_BOUNDED) {\n+\t    /*\n+\t     * Used to provide parsing limits\n+\t     */\n+\t    if (needSize >= XML_MAX_TEXT_LENGTH) {\n+\t\txmlBufMemoryError(buf, \"buffer error: text too long\\n\");\n+\t\treturn(-1);\n+\t    }\n+\t}\n         if (!xmlBufResize(buf, needSize)){\n \t    xmlBufMemoryError(buf, \"growing buffer\");\n             return XML_ERR_NO_MEMORY;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tif (buf->alloc == XML_BUFFER_ALLOC_BOUNDED) {",
                "\t    /*",
                "\t     * Used to provide parsing limits",
                "\t     */",
                "\t    if (needSize >= XML_MAX_TEXT_LENGTH) {",
                "\t\txmlBufMemoryError(buf, \"buffer error: text too long\\n\");",
                "\t\treturn(-1);",
                "\t    }",
                "\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1819",
        "func_name": "GNOME/libxml2/xmlTextReaderConstValue",
        "description": "The xmlreader in libxml allows remote attackers to cause a denial of service (memory consumption) via crafted XML data, related to an XML Entity Expansion (XEE) attack.",
        "git_url": "https://github.com/GNOME/libxml2/commit/213f1fe0d76d30eaed6e5853057defc43e6df2c9",
        "commit_title": "CVE-2015-1819 Enforce the reader to run in constant memory",
        "commit_text": " One of the operation on the reader could resolve entities leading to the classic expansion issue. Make sure the buffer used for xmlreader operation is bounded. Introduce a new allocation type for the buffers for this effect.",
        "func_before": "const xmlChar *\nxmlTextReaderConstValue(xmlTextReaderPtr reader) {\n    xmlNodePtr node;\n    if (reader == NULL)\n\treturn(NULL);\n    if (reader->node == NULL)\n\treturn(NULL);\n    if (reader->curnode != NULL)\n\tnode = reader->curnode;\n    else\n\tnode = reader->node;\n\n    switch (node->type) {\n        case XML_NAMESPACE_DECL:\n\t    return(((xmlNsPtr) node)->href);\n        case XML_ATTRIBUTE_NODE:{\n\t    xmlAttrPtr attr = (xmlAttrPtr) node;\n\n\t    if ((attr->children != NULL) &&\n\t        (attr->children->type == XML_TEXT_NODE) &&\n\t\t(attr->children->next == NULL))\n\t\treturn(attr->children->content);\n\t    else {\n\t\tif (reader->buffer == NULL) {\n\t\t    reader->buffer = xmlBufCreateSize(100);\n                    if (reader->buffer == NULL) {\n                        xmlGenericError(xmlGenericErrorContext,\n                                        \"xmlTextReaderSetup : malloc failed\\n\");\n                        return (NULL);\n                    }\n                } else\n                    xmlBufEmpty(reader->buffer);\n\t        xmlBufGetNodeContent(reader->buffer, node);\n\t\treturn(xmlBufContent(reader->buffer));\n\t    }\n\t    break;\n\t}\n        case XML_TEXT_NODE:\n        case XML_CDATA_SECTION_NODE:\n        case XML_PI_NODE:\n        case XML_COMMENT_NODE:\n\t    return(node->content);\n\tdefault:\n\t    break;\n    }\n    return(NULL);\n}",
        "func": "const xmlChar *\nxmlTextReaderConstValue(xmlTextReaderPtr reader) {\n    xmlNodePtr node;\n    if (reader == NULL)\n\treturn(NULL);\n    if (reader->node == NULL)\n\treturn(NULL);\n    if (reader->curnode != NULL)\n\tnode = reader->curnode;\n    else\n\tnode = reader->node;\n\n    switch (node->type) {\n        case XML_NAMESPACE_DECL:\n\t    return(((xmlNsPtr) node)->href);\n        case XML_ATTRIBUTE_NODE:{\n\t    xmlAttrPtr attr = (xmlAttrPtr) node;\n\t    const xmlChar *ret;\n\n\t    if ((attr->children != NULL) &&\n\t        (attr->children->type == XML_TEXT_NODE) &&\n\t\t(attr->children->next == NULL))\n\t\treturn(attr->children->content);\n\t    else {\n\t\tif (reader->buffer == NULL) {\n\t\t    reader->buffer = xmlBufCreateSize(100);\n                    if (reader->buffer == NULL) {\n                        xmlGenericError(xmlGenericErrorContext,\n                                        \"xmlTextReaderSetup : malloc failed\\n\");\n                        return (NULL);\n                    }\n\t\t    xmlBufSetAllocationScheme(reader->buffer,\n\t\t                              XML_BUFFER_ALLOC_BOUNDED);\n                } else\n                    xmlBufEmpty(reader->buffer);\n\t        xmlBufGetNodeContent(reader->buffer, node);\n\t\tret = xmlBufContent(reader->buffer);\n\t\tif (ret == NULL) {\n\t\t    /* error on the buffer best to reallocate */\n\t\t    xmlBufFree(reader->buffer);\n\t\t    reader->buffer = xmlBufCreateSize(100);\n\t\t    xmlBufSetAllocationScheme(reader->buffer,\n\t\t                              XML_BUFFER_ALLOC_BOUNDED);\n\t\t    ret = BAD_CAST \"\";\n\t\t}\n\t\treturn(ret);\n\t    }\n\t    break;\n\t}\n        case XML_TEXT_NODE:\n        case XML_CDATA_SECTION_NODE:\n        case XML_PI_NODE:\n        case XML_COMMENT_NODE:\n\t    return(node->content);\n\tdefault:\n\t    break;\n    }\n    return(NULL);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -15,6 +15,7 @@\n \t    return(((xmlNsPtr) node)->href);\n         case XML_ATTRIBUTE_NODE:{\n \t    xmlAttrPtr attr = (xmlAttrPtr) node;\n+\t    const xmlChar *ret;\n \n \t    if ((attr->children != NULL) &&\n \t        (attr->children->type == XML_TEXT_NODE) &&\n@@ -28,10 +29,21 @@\n                                         \"xmlTextReaderSetup : malloc failed\\n\");\n                         return (NULL);\n                     }\n+\t\t    xmlBufSetAllocationScheme(reader->buffer,\n+\t\t                              XML_BUFFER_ALLOC_BOUNDED);\n                 } else\n                     xmlBufEmpty(reader->buffer);\n \t        xmlBufGetNodeContent(reader->buffer, node);\n-\t\treturn(xmlBufContent(reader->buffer));\n+\t\tret = xmlBufContent(reader->buffer);\n+\t\tif (ret == NULL) {\n+\t\t    /* error on the buffer best to reallocate */\n+\t\t    xmlBufFree(reader->buffer);\n+\t\t    reader->buffer = xmlBufCreateSize(100);\n+\t\t    xmlBufSetAllocationScheme(reader->buffer,\n+\t\t                              XML_BUFFER_ALLOC_BOUNDED);\n+\t\t    ret = BAD_CAST \"\";\n+\t\t}\n+\t\treturn(ret);\n \t    }\n \t    break;\n \t}",
        "diff_line_info": {
            "deleted_lines": [
                "\t\treturn(xmlBufContent(reader->buffer));"
            ],
            "added_lines": [
                "\t    const xmlChar *ret;",
                "\t\t    xmlBufSetAllocationScheme(reader->buffer,",
                "\t\t                              XML_BUFFER_ALLOC_BOUNDED);",
                "\t\tret = xmlBufContent(reader->buffer);",
                "\t\tif (ret == NULL) {",
                "\t\t    /* error on the buffer best to reallocate */",
                "\t\t    xmlBufFree(reader->buffer);",
                "\t\t    reader->buffer = xmlBufCreateSize(100);",
                "\t\t    xmlBufSetAllocationScheme(reader->buffer,",
                "\t\t                              XML_BUFFER_ALLOC_BOUNDED);",
                "\t\t    ret = BAD_CAST \"\";",
                "\t\t}",
                "\t\treturn(ret);"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1819",
        "func_name": "GNOME/libxml2/xmlTextReaderSetup",
        "description": "The xmlreader in libxml allows remote attackers to cause a denial of service (memory consumption) via crafted XML data, related to an XML Entity Expansion (XEE) attack.",
        "git_url": "https://github.com/GNOME/libxml2/commit/213f1fe0d76d30eaed6e5853057defc43e6df2c9",
        "commit_title": "CVE-2015-1819 Enforce the reader to run in constant memory",
        "commit_text": " One of the operation on the reader could resolve entities leading to the classic expansion issue. Make sure the buffer used for xmlreader operation is bounded. Introduce a new allocation type for the buffers for this effect.",
        "func_before": "int\nxmlTextReaderSetup(xmlTextReaderPtr reader,\n                   xmlParserInputBufferPtr input, const char *URL,\n                   const char *encoding, int options)\n{\n    if (reader == NULL) {\n        if (input != NULL)\n\t    xmlFreeParserInputBuffer(input);\n        return (-1);\n    }\n\n    /*\n     * we force the generation of compact text nodes on the reader\n     * since usr applications should never modify the tree\n     */\n    options |= XML_PARSE_COMPACT;\n\n    reader->doc = NULL;\n    reader->entNr = 0;\n    reader->parserFlags = options;\n    reader->validate = XML_TEXTREADER_NOT_VALIDATE;\n    if ((input != NULL) && (reader->input != NULL) &&\n        (reader->allocs & XML_TEXTREADER_INPUT)) {\n\txmlFreeParserInputBuffer(reader->input);\n\treader->input = NULL;\n\treader->allocs -= XML_TEXTREADER_INPUT;\n    }\n    if (input != NULL) {\n\treader->input = input;\n\treader->allocs |= XML_TEXTREADER_INPUT;\n    }\n    if (reader->buffer == NULL)\n        reader->buffer = xmlBufCreateSize(100);\n    if (reader->buffer == NULL) {\n        xmlGenericError(xmlGenericErrorContext,\n                        \"xmlTextReaderSetup : malloc failed\\n\");\n        return (-1);\n    }\n    if (reader->sax == NULL)\n\treader->sax = (xmlSAXHandler *) xmlMalloc(sizeof(xmlSAXHandler));\n    if (reader->sax == NULL) {\n        xmlGenericError(xmlGenericErrorContext,\n                        \"xmlTextReaderSetup : malloc failed\\n\");\n        return (-1);\n    }\n    xmlSAXVersion(reader->sax, 2);\n    reader->startElement = reader->sax->startElement;\n    reader->sax->startElement = xmlTextReaderStartElement;\n    reader->endElement = reader->sax->endElement;\n    reader->sax->endElement = xmlTextReaderEndElement;\n#ifdef LIBXML_SAX1_ENABLED\n    if (reader->sax->initialized == XML_SAX2_MAGIC) {\n#endif /* LIBXML_SAX1_ENABLED */\n        reader->startElementNs = reader->sax->startElementNs;\n        reader->sax->startElementNs = xmlTextReaderStartElementNs;\n        reader->endElementNs = reader->sax->endElementNs;\n        reader->sax->endElementNs = xmlTextReaderEndElementNs;\n#ifdef LIBXML_SAX1_ENABLED\n    } else {\n        reader->startElementNs = NULL;\n        reader->endElementNs = NULL;\n    }\n#endif /* LIBXML_SAX1_ENABLED */\n    reader->characters = reader->sax->characters;\n    reader->sax->characters = xmlTextReaderCharacters;\n    reader->sax->ignorableWhitespace = xmlTextReaderCharacters;\n    reader->cdataBlock = reader->sax->cdataBlock;\n    reader->sax->cdataBlock = xmlTextReaderCDataBlock;\n\n    reader->mode = XML_TEXTREADER_MODE_INITIAL;\n    reader->node = NULL;\n    reader->curnode = NULL;\n    if (input != NULL) {\n        if (xmlBufUse(reader->input->buffer) < 4) {\n            xmlParserInputBufferRead(input, 4);\n        }\n        if (reader->ctxt == NULL) {\n            if (xmlBufUse(reader->input->buffer) >= 4) {\n                reader->ctxt = xmlCreatePushParserCtxt(reader->sax, NULL,\n\t\t       (const char *) xmlBufContent(reader->input->buffer),\n                                      4, URL);\n                reader->base = 0;\n                reader->cur = 4;\n            } else {\n                reader->ctxt =\n                    xmlCreatePushParserCtxt(reader->sax, NULL, NULL, 0, URL);\n                reader->base = 0;\n                reader->cur = 0;\n            }\n        } else {\n\t    xmlParserInputPtr inputStream;\n\t    xmlParserInputBufferPtr buf;\n\t    xmlCharEncoding enc = XML_CHAR_ENCODING_NONE;\n\n\t    xmlCtxtReset(reader->ctxt);\n\t    buf = xmlAllocParserInputBuffer(enc);\n\t    if (buf == NULL) return(-1);\n\t    inputStream = xmlNewInputStream(reader->ctxt);\n\t    if (inputStream == NULL) {\n\t\txmlFreeParserInputBuffer(buf);\n\t\treturn(-1);\n\t    }\n\n\t    if (URL == NULL)\n\t\tinputStream->filename = NULL;\n\t    else\n\t\tinputStream->filename = (char *)\n\t\t    xmlCanonicPath((const xmlChar *) URL);\n\t    inputStream->buf = buf;\n            xmlBufResetInput(buf->buffer, inputStream);\n\n\t    inputPush(reader->ctxt, inputStream);\n\t    reader->cur = 0;\n\t}\n        if (reader->ctxt == NULL) {\n            xmlGenericError(xmlGenericErrorContext,\n                            \"xmlTextReaderSetup : malloc failed\\n\");\n            return (-1);\n        }\n    }\n    if (reader->dict != NULL) {\n        if (reader->ctxt->dict != NULL) {\n\t    if (reader->dict != reader->ctxt->dict) {\n\t\txmlDictFree(reader->dict);\n\t\treader->dict = reader->ctxt->dict;\n\t    }\n\t} else {\n\t    reader->ctxt->dict = reader->dict;\n\t}\n    } else {\n\tif (reader->ctxt->dict == NULL)\n\t    reader->ctxt->dict = xmlDictCreate();\n        reader->dict = reader->ctxt->dict;\n    }\n    reader->ctxt->_private = reader;\n    reader->ctxt->linenumbers = 1;\n    reader->ctxt->dictNames = 1;\n    /*\n     * use the parser dictionnary to allocate all elements and attributes names\n     */\n    reader->ctxt->docdict = 1;\n    reader->ctxt->parseMode = XML_PARSE_READER;\n\n#ifdef LIBXML_XINCLUDE_ENABLED\n    if (reader->xincctxt != NULL) {\n\txmlXIncludeFreeContext(reader->xincctxt);\n\treader->xincctxt = NULL;\n    }\n    if (options & XML_PARSE_XINCLUDE) {\n        reader->xinclude = 1;\n\treader->xinclude_name = xmlDictLookup(reader->dict, XINCLUDE_NODE, -1);\n\toptions -= XML_PARSE_XINCLUDE;\n    } else\n        reader->xinclude = 0;\n    reader->in_xinclude = 0;\n#endif\n#ifdef LIBXML_PATTERN_ENABLED\n    if (reader->patternTab == NULL) {\n        reader->patternNr = 0;\n\treader->patternMax = 0;\n    }\n    while (reader->patternNr > 0) {\n        reader->patternNr--;\n\tif (reader->patternTab[reader->patternNr] != NULL) {\n\t    xmlFreePattern(reader->patternTab[reader->patternNr]);\n            reader->patternTab[reader->patternNr] = NULL;\n\t}\n    }\n#endif\n\n    if (options & XML_PARSE_DTDVALID)\n        reader->validate = XML_TEXTREADER_VALIDATE_DTD;\n\n    xmlCtxtUseOptions(reader->ctxt, options);\n    if (encoding != NULL) {\n        xmlCharEncodingHandlerPtr hdlr;\n\n        hdlr = xmlFindCharEncodingHandler(encoding);\n        if (hdlr != NULL)\n            xmlSwitchToEncoding(reader->ctxt, hdlr);\n    }\n    if ((URL != NULL) && (reader->ctxt->input != NULL) &&\n        (reader->ctxt->input->filename == NULL))\n        reader->ctxt->input->filename = (char *)\n            xmlStrdup((const xmlChar *) URL);\n\n    reader->doc = NULL;\n\n    return (0);\n}",
        "func": "int\nxmlTextReaderSetup(xmlTextReaderPtr reader,\n                   xmlParserInputBufferPtr input, const char *URL,\n                   const char *encoding, int options)\n{\n    if (reader == NULL) {\n        if (input != NULL)\n\t    xmlFreeParserInputBuffer(input);\n        return (-1);\n    }\n\n    /*\n     * we force the generation of compact text nodes on the reader\n     * since usr applications should never modify the tree\n     */\n    options |= XML_PARSE_COMPACT;\n\n    reader->doc = NULL;\n    reader->entNr = 0;\n    reader->parserFlags = options;\n    reader->validate = XML_TEXTREADER_NOT_VALIDATE;\n    if ((input != NULL) && (reader->input != NULL) &&\n        (reader->allocs & XML_TEXTREADER_INPUT)) {\n\txmlFreeParserInputBuffer(reader->input);\n\treader->input = NULL;\n\treader->allocs -= XML_TEXTREADER_INPUT;\n    }\n    if (input != NULL) {\n\treader->input = input;\n\treader->allocs |= XML_TEXTREADER_INPUT;\n    }\n    if (reader->buffer == NULL)\n        reader->buffer = xmlBufCreateSize(100);\n    if (reader->buffer == NULL) {\n        xmlGenericError(xmlGenericErrorContext,\n                        \"xmlTextReaderSetup : malloc failed\\n\");\n        return (-1);\n    }\n    /* no operation on a reader should require a huge buffer */\n    xmlBufSetAllocationScheme(reader->buffer,\n\t\t\t      XML_BUFFER_ALLOC_BOUNDED);\n    if (reader->sax == NULL)\n\treader->sax = (xmlSAXHandler *) xmlMalloc(sizeof(xmlSAXHandler));\n    if (reader->sax == NULL) {\n        xmlGenericError(xmlGenericErrorContext,\n                        \"xmlTextReaderSetup : malloc failed\\n\");\n        return (-1);\n    }\n    xmlSAXVersion(reader->sax, 2);\n    reader->startElement = reader->sax->startElement;\n    reader->sax->startElement = xmlTextReaderStartElement;\n    reader->endElement = reader->sax->endElement;\n    reader->sax->endElement = xmlTextReaderEndElement;\n#ifdef LIBXML_SAX1_ENABLED\n    if (reader->sax->initialized == XML_SAX2_MAGIC) {\n#endif /* LIBXML_SAX1_ENABLED */\n        reader->startElementNs = reader->sax->startElementNs;\n        reader->sax->startElementNs = xmlTextReaderStartElementNs;\n        reader->endElementNs = reader->sax->endElementNs;\n        reader->sax->endElementNs = xmlTextReaderEndElementNs;\n#ifdef LIBXML_SAX1_ENABLED\n    } else {\n        reader->startElementNs = NULL;\n        reader->endElementNs = NULL;\n    }\n#endif /* LIBXML_SAX1_ENABLED */\n    reader->characters = reader->sax->characters;\n    reader->sax->characters = xmlTextReaderCharacters;\n    reader->sax->ignorableWhitespace = xmlTextReaderCharacters;\n    reader->cdataBlock = reader->sax->cdataBlock;\n    reader->sax->cdataBlock = xmlTextReaderCDataBlock;\n\n    reader->mode = XML_TEXTREADER_MODE_INITIAL;\n    reader->node = NULL;\n    reader->curnode = NULL;\n    if (input != NULL) {\n        if (xmlBufUse(reader->input->buffer) < 4) {\n            xmlParserInputBufferRead(input, 4);\n        }\n        if (reader->ctxt == NULL) {\n            if (xmlBufUse(reader->input->buffer) >= 4) {\n                reader->ctxt = xmlCreatePushParserCtxt(reader->sax, NULL,\n\t\t       (const char *) xmlBufContent(reader->input->buffer),\n                                      4, URL);\n                reader->base = 0;\n                reader->cur = 4;\n            } else {\n                reader->ctxt =\n                    xmlCreatePushParserCtxt(reader->sax, NULL, NULL, 0, URL);\n                reader->base = 0;\n                reader->cur = 0;\n            }\n        } else {\n\t    xmlParserInputPtr inputStream;\n\t    xmlParserInputBufferPtr buf;\n\t    xmlCharEncoding enc = XML_CHAR_ENCODING_NONE;\n\n\t    xmlCtxtReset(reader->ctxt);\n\t    buf = xmlAllocParserInputBuffer(enc);\n\t    if (buf == NULL) return(-1);\n\t    inputStream = xmlNewInputStream(reader->ctxt);\n\t    if (inputStream == NULL) {\n\t\txmlFreeParserInputBuffer(buf);\n\t\treturn(-1);\n\t    }\n\n\t    if (URL == NULL)\n\t\tinputStream->filename = NULL;\n\t    else\n\t\tinputStream->filename = (char *)\n\t\t    xmlCanonicPath((const xmlChar *) URL);\n\t    inputStream->buf = buf;\n            xmlBufResetInput(buf->buffer, inputStream);\n\n\t    inputPush(reader->ctxt, inputStream);\n\t    reader->cur = 0;\n\t}\n        if (reader->ctxt == NULL) {\n            xmlGenericError(xmlGenericErrorContext,\n                            \"xmlTextReaderSetup : malloc failed\\n\");\n            return (-1);\n        }\n    }\n    if (reader->dict != NULL) {\n        if (reader->ctxt->dict != NULL) {\n\t    if (reader->dict != reader->ctxt->dict) {\n\t\txmlDictFree(reader->dict);\n\t\treader->dict = reader->ctxt->dict;\n\t    }\n\t} else {\n\t    reader->ctxt->dict = reader->dict;\n\t}\n    } else {\n\tif (reader->ctxt->dict == NULL)\n\t    reader->ctxt->dict = xmlDictCreate();\n        reader->dict = reader->ctxt->dict;\n    }\n    reader->ctxt->_private = reader;\n    reader->ctxt->linenumbers = 1;\n    reader->ctxt->dictNames = 1;\n    /*\n     * use the parser dictionnary to allocate all elements and attributes names\n     */\n    reader->ctxt->docdict = 1;\n    reader->ctxt->parseMode = XML_PARSE_READER;\n\n#ifdef LIBXML_XINCLUDE_ENABLED\n    if (reader->xincctxt != NULL) {\n\txmlXIncludeFreeContext(reader->xincctxt);\n\treader->xincctxt = NULL;\n    }\n    if (options & XML_PARSE_XINCLUDE) {\n        reader->xinclude = 1;\n\treader->xinclude_name = xmlDictLookup(reader->dict, XINCLUDE_NODE, -1);\n\toptions -= XML_PARSE_XINCLUDE;\n    } else\n        reader->xinclude = 0;\n    reader->in_xinclude = 0;\n#endif\n#ifdef LIBXML_PATTERN_ENABLED\n    if (reader->patternTab == NULL) {\n        reader->patternNr = 0;\n\treader->patternMax = 0;\n    }\n    while (reader->patternNr > 0) {\n        reader->patternNr--;\n\tif (reader->patternTab[reader->patternNr] != NULL) {\n\t    xmlFreePattern(reader->patternTab[reader->patternNr]);\n            reader->patternTab[reader->patternNr] = NULL;\n\t}\n    }\n#endif\n\n    if (options & XML_PARSE_DTDVALID)\n        reader->validate = XML_TEXTREADER_VALIDATE_DTD;\n\n    xmlCtxtUseOptions(reader->ctxt, options);\n    if (encoding != NULL) {\n        xmlCharEncodingHandlerPtr hdlr;\n\n        hdlr = xmlFindCharEncodingHandler(encoding);\n        if (hdlr != NULL)\n            xmlSwitchToEncoding(reader->ctxt, hdlr);\n    }\n    if ((URL != NULL) && (reader->ctxt->input != NULL) &&\n        (reader->ctxt->input->filename == NULL))\n        reader->ctxt->input->filename = (char *)\n            xmlStrdup((const xmlChar *) URL);\n\n    reader->doc = NULL;\n\n    return (0);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -36,6 +36,9 @@\n                         \"xmlTextReaderSetup : malloc failed\\n\");\n         return (-1);\n     }\n+    /* no operation on a reader should require a huge buffer */\n+    xmlBufSetAllocationScheme(reader->buffer,\n+\t\t\t      XML_BUFFER_ALLOC_BOUNDED);\n     if (reader->sax == NULL)\n \treader->sax = (xmlSAXHandler *) xmlMalloc(sizeof(xmlSAXHandler));\n     if (reader->sax == NULL) {",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    /* no operation on a reader should require a huge buffer */",
                "    xmlBufSetAllocationScheme(reader->buffer,",
                "\t\t\t      XML_BUFFER_ALLOC_BOUNDED);"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1819",
        "func_name": "GNOME/libxml2/xmlNewTextReader",
        "description": "The xmlreader in libxml allows remote attackers to cause a denial of service (memory consumption) via crafted XML data, related to an XML Entity Expansion (XEE) attack.",
        "git_url": "https://github.com/GNOME/libxml2/commit/213f1fe0d76d30eaed6e5853057defc43e6df2c9",
        "commit_title": "CVE-2015-1819 Enforce the reader to run in constant memory",
        "commit_text": " One of the operation on the reader could resolve entities leading to the classic expansion issue. Make sure the buffer used for xmlreader operation is bounded. Introduce a new allocation type for the buffers for this effect.",
        "func_before": "xmlTextReaderPtr\nxmlNewTextReader(xmlParserInputBufferPtr input, const char *URI) {\n    xmlTextReaderPtr ret;\n\n    if (input == NULL)\n\treturn(NULL);\n    ret = xmlMalloc(sizeof(xmlTextReader));\n    if (ret == NULL) {\n        xmlGenericError(xmlGenericErrorContext,\n\t\t\"xmlNewTextReader : malloc failed\\n\");\n\treturn(NULL);\n    }\n    memset(ret, 0, sizeof(xmlTextReader));\n    ret->doc = NULL;\n    ret->entTab = NULL;\n    ret->entMax = 0;\n    ret->entNr = 0;\n    ret->input = input;\n    ret->buffer = xmlBufCreateSize(100);\n    if (ret->buffer == NULL) {\n        xmlFree(ret);\n        xmlGenericError(xmlGenericErrorContext,\n\t\t\"xmlNewTextReader : malloc failed\\n\");\n\treturn(NULL);\n    }\n    ret->sax = (xmlSAXHandler *) xmlMalloc(sizeof(xmlSAXHandler));\n    if (ret->sax == NULL) {\n\txmlBufFree(ret->buffer);\n\txmlFree(ret);\n        xmlGenericError(xmlGenericErrorContext,\n\t\t\"xmlNewTextReader : malloc failed\\n\");\n\treturn(NULL);\n    }\n    xmlSAXVersion(ret->sax, 2);\n    ret->startElement = ret->sax->startElement;\n    ret->sax->startElement = xmlTextReaderStartElement;\n    ret->endElement = ret->sax->endElement;\n    ret->sax->endElement = xmlTextReaderEndElement;\n#ifdef LIBXML_SAX1_ENABLED\n    if (ret->sax->initialized == XML_SAX2_MAGIC) {\n#endif /* LIBXML_SAX1_ENABLED */\n\tret->startElementNs = ret->sax->startElementNs;\n\tret->sax->startElementNs = xmlTextReaderStartElementNs;\n\tret->endElementNs = ret->sax->endElementNs;\n\tret->sax->endElementNs = xmlTextReaderEndElementNs;\n#ifdef LIBXML_SAX1_ENABLED\n    } else {\n\tret->startElementNs = NULL;\n\tret->endElementNs = NULL;\n    }\n#endif /* LIBXML_SAX1_ENABLED */\n    ret->characters = ret->sax->characters;\n    ret->sax->characters = xmlTextReaderCharacters;\n    ret->sax->ignorableWhitespace = xmlTextReaderCharacters;\n    ret->cdataBlock = ret->sax->cdataBlock;\n    ret->sax->cdataBlock = xmlTextReaderCDataBlock;\n\n    ret->mode = XML_TEXTREADER_MODE_INITIAL;\n    ret->node = NULL;\n    ret->curnode = NULL;\n    if (xmlBufUse(ret->input->buffer) < 4) {\n\txmlParserInputBufferRead(input, 4);\n    }\n    if (xmlBufUse(ret->input->buffer) >= 4) {\n\tret->ctxt = xmlCreatePushParserCtxt(ret->sax, NULL,\n\t\t\t     (const char *) xmlBufContent(ret->input->buffer),\n                                            4, URI);\n\tret->base = 0;\n\tret->cur = 4;\n    } else {\n\tret->ctxt = xmlCreatePushParserCtxt(ret->sax, NULL, NULL, 0, URI);\n\tret->base = 0;\n\tret->cur = 0;\n    }\n\n    if (ret->ctxt == NULL) {\n        xmlGenericError(xmlGenericErrorContext,\n\t\t\"xmlNewTextReader : malloc failed\\n\");\n\txmlBufFree(ret->buffer);\n\txmlFree(ret->sax);\n\txmlFree(ret);\n\treturn(NULL);\n    }\n    ret->ctxt->parseMode = XML_PARSE_READER;\n    ret->ctxt->_private = ret;\n    ret->ctxt->linenumbers = 1;\n    ret->ctxt->dictNames = 1;\n    ret->allocs = XML_TEXTREADER_CTXT;\n    /*\n     * use the parser dictionnary to allocate all elements and attributes names\n     */\n    ret->ctxt->docdict = 1;\n    ret->dict = ret->ctxt->dict;\n#ifdef LIBXML_XINCLUDE_ENABLED\n    ret->xinclude = 0;\n#endif\n#ifdef LIBXML_PATTERN_ENABLED\n    ret->patternMax = 0;\n    ret->patternTab = NULL;\n#endif\n    return(ret);\n}",
        "func": "xmlTextReaderPtr\nxmlNewTextReader(xmlParserInputBufferPtr input, const char *URI) {\n    xmlTextReaderPtr ret;\n\n    if (input == NULL)\n\treturn(NULL);\n    ret = xmlMalloc(sizeof(xmlTextReader));\n    if (ret == NULL) {\n        xmlGenericError(xmlGenericErrorContext,\n\t\t\"xmlNewTextReader : malloc failed\\n\");\n\treturn(NULL);\n    }\n    memset(ret, 0, sizeof(xmlTextReader));\n    ret->doc = NULL;\n    ret->entTab = NULL;\n    ret->entMax = 0;\n    ret->entNr = 0;\n    ret->input = input;\n    ret->buffer = xmlBufCreateSize(100);\n    if (ret->buffer == NULL) {\n        xmlFree(ret);\n        xmlGenericError(xmlGenericErrorContext,\n\t\t\"xmlNewTextReader : malloc failed\\n\");\n\treturn(NULL);\n    }\n    /* no operation on a reader should require a huge buffer */\n    xmlBufSetAllocationScheme(ret->buffer,\n\t\t\t      XML_BUFFER_ALLOC_BOUNDED);\n    ret->sax = (xmlSAXHandler *) xmlMalloc(sizeof(xmlSAXHandler));\n    if (ret->sax == NULL) {\n\txmlBufFree(ret->buffer);\n\txmlFree(ret);\n        xmlGenericError(xmlGenericErrorContext,\n\t\t\"xmlNewTextReader : malloc failed\\n\");\n\treturn(NULL);\n    }\n    xmlSAXVersion(ret->sax, 2);\n    ret->startElement = ret->sax->startElement;\n    ret->sax->startElement = xmlTextReaderStartElement;\n    ret->endElement = ret->sax->endElement;\n    ret->sax->endElement = xmlTextReaderEndElement;\n#ifdef LIBXML_SAX1_ENABLED\n    if (ret->sax->initialized == XML_SAX2_MAGIC) {\n#endif /* LIBXML_SAX1_ENABLED */\n\tret->startElementNs = ret->sax->startElementNs;\n\tret->sax->startElementNs = xmlTextReaderStartElementNs;\n\tret->endElementNs = ret->sax->endElementNs;\n\tret->sax->endElementNs = xmlTextReaderEndElementNs;\n#ifdef LIBXML_SAX1_ENABLED\n    } else {\n\tret->startElementNs = NULL;\n\tret->endElementNs = NULL;\n    }\n#endif /* LIBXML_SAX1_ENABLED */\n    ret->characters = ret->sax->characters;\n    ret->sax->characters = xmlTextReaderCharacters;\n    ret->sax->ignorableWhitespace = xmlTextReaderCharacters;\n    ret->cdataBlock = ret->sax->cdataBlock;\n    ret->sax->cdataBlock = xmlTextReaderCDataBlock;\n\n    ret->mode = XML_TEXTREADER_MODE_INITIAL;\n    ret->node = NULL;\n    ret->curnode = NULL;\n    if (xmlBufUse(ret->input->buffer) < 4) {\n\txmlParserInputBufferRead(input, 4);\n    }\n    if (xmlBufUse(ret->input->buffer) >= 4) {\n\tret->ctxt = xmlCreatePushParserCtxt(ret->sax, NULL,\n\t\t\t     (const char *) xmlBufContent(ret->input->buffer),\n                                            4, URI);\n\tret->base = 0;\n\tret->cur = 4;\n    } else {\n\tret->ctxt = xmlCreatePushParserCtxt(ret->sax, NULL, NULL, 0, URI);\n\tret->base = 0;\n\tret->cur = 0;\n    }\n\n    if (ret->ctxt == NULL) {\n        xmlGenericError(xmlGenericErrorContext,\n\t\t\"xmlNewTextReader : malloc failed\\n\");\n\txmlBufFree(ret->buffer);\n\txmlFree(ret->sax);\n\txmlFree(ret);\n\treturn(NULL);\n    }\n    ret->ctxt->parseMode = XML_PARSE_READER;\n    ret->ctxt->_private = ret;\n    ret->ctxt->linenumbers = 1;\n    ret->ctxt->dictNames = 1;\n    ret->allocs = XML_TEXTREADER_CTXT;\n    /*\n     * use the parser dictionnary to allocate all elements and attributes names\n     */\n    ret->ctxt->docdict = 1;\n    ret->dict = ret->ctxt->dict;\n#ifdef LIBXML_XINCLUDE_ENABLED\n    ret->xinclude = 0;\n#endif\n#ifdef LIBXML_PATTERN_ENABLED\n    ret->patternMax = 0;\n    ret->patternTab = NULL;\n#endif\n    return(ret);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -23,6 +23,9 @@\n \t\t\"xmlNewTextReader : malloc failed\\n\");\n \treturn(NULL);\n     }\n+    /* no operation on a reader should require a huge buffer */\n+    xmlBufSetAllocationScheme(ret->buffer,\n+\t\t\t      XML_BUFFER_ALLOC_BOUNDED);\n     ret->sax = (xmlSAXHandler *) xmlMalloc(sizeof(xmlSAXHandler));\n     if (ret->sax == NULL) {\n \txmlBufFree(ret->buffer);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    /* no operation on a reader should require a huge buffer */",
                "    xmlBufSetAllocationScheme(ret->buffer,",
                "\t\t\t      XML_BUFFER_ALLOC_BOUNDED);"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-5364",
        "func_name": "torvalds/linux/udp_recvmsg",
        "description": "The (1) udp_recvmsg and (2) udpv6_recvmsg functions in the Linux kernel before 4.0.6 do not properly consider yielding a processor, which allows remote attackers to cause a denial of service (system hang) via incorrect checksums within a UDP packet flood.",
        "git_url": "https://github.com/torvalds/linux/commit/beb39db59d14990e401e235faf66a6b9b31240b0",
        "commit_title": "udp: fix behavior of wrong checksums",
        "commit_text": " We have two problems in UDP stack related to bogus checksums :  1) We return -EAGAIN to application even if receive queue is not empty.    This breaks applications using edge trigger epoll()  2) Under UDP flood, we can loop forever without yielding to other    processes, potentially hanging the host, especially on non SMP.  This patch is an attempt to make things better.  We might in the future add extra support for rt applications wanting to better control time spent doing a recv() in a hostile environment. For example we could validate checksums before queuing packets in socket receive queue.  Cc: Willem de Bruijn <willemb@google.com>",
        "func_before": "int udp_recvmsg(struct sock *sk, struct msghdr *msg, size_t len, int noblock,\n\t\tint flags, int *addr_len)\n{\n\tstruct inet_sock *inet = inet_sk(sk);\n\tDECLARE_SOCKADDR(struct sockaddr_in *, sin, msg->msg_name);\n\tstruct sk_buff *skb;\n\tunsigned int ulen, copied;\n\tint peeked, off = 0;\n\tint err;\n\tint is_udplite = IS_UDPLITE(sk);\n\tbool slow;\n\n\tif (flags & MSG_ERRQUEUE)\n\t\treturn ip_recv_error(sk, msg, len, addr_len);\n\ntry_again:\n\tskb = __skb_recv_datagram(sk, flags | (noblock ? MSG_DONTWAIT : 0),\n\t\t\t\t  &peeked, &off, &err);\n\tif (!skb)\n\t\tgoto out;\n\n\tulen = skb->len - sizeof(struct udphdr);\n\tcopied = len;\n\tif (copied > ulen)\n\t\tcopied = ulen;\n\telse if (copied < ulen)\n\t\tmsg->msg_flags |= MSG_TRUNC;\n\n\t/*\n\t * If checksum is needed at all, try to do it while copying the\n\t * data.  If the data is truncated, or if we only want a partial\n\t * coverage checksum (UDP-Lite), do it before the copy.\n\t */\n\n\tif (copied < ulen || UDP_SKB_CB(skb)->partial_cov) {\n\t\tif (udp_lib_checksum_complete(skb))\n\t\t\tgoto csum_copy_err;\n\t}\n\n\tif (skb_csum_unnecessary(skb))\n\t\terr = skb_copy_datagram_msg(skb, sizeof(struct udphdr),\n\t\t\t\t\t    msg, copied);\n\telse {\n\t\terr = skb_copy_and_csum_datagram_msg(skb, sizeof(struct udphdr),\n\t\t\t\t\t\t     msg);\n\n\t\tif (err == -EINVAL)\n\t\t\tgoto csum_copy_err;\n\t}\n\n\tif (unlikely(err)) {\n\t\ttrace_kfree_skb(skb, udp_recvmsg);\n\t\tif (!peeked) {\n\t\t\tatomic_inc(&sk->sk_drops);\n\t\t\tUDP_INC_STATS_USER(sock_net(sk),\n\t\t\t\t\t   UDP_MIB_INERRORS, is_udplite);\n\t\t}\n\t\tgoto out_free;\n\t}\n\n\tif (!peeked)\n\t\tUDP_INC_STATS_USER(sock_net(sk),\n\t\t\t\tUDP_MIB_INDATAGRAMS, is_udplite);\n\n\tsock_recv_ts_and_drops(msg, sk, skb);\n\n\t/* Copy the address. */\n\tif (sin) {\n\t\tsin->sin_family = AF_INET;\n\t\tsin->sin_port = udp_hdr(skb)->source;\n\t\tsin->sin_addr.s_addr = ip_hdr(skb)->saddr;\n\t\tmemset(sin->sin_zero, 0, sizeof(sin->sin_zero));\n\t\t*addr_len = sizeof(*sin);\n\t}\n\tif (inet->cmsg_flags)\n\t\tip_cmsg_recv_offset(msg, skb, sizeof(struct udphdr));\n\n\terr = copied;\n\tif (flags & MSG_TRUNC)\n\t\terr = ulen;\n\nout_free:\n\tskb_free_datagram_locked(sk, skb);\nout:\n\treturn err;\n\ncsum_copy_err:\n\tslow = lock_sock_fast(sk);\n\tif (!skb_kill_datagram(sk, skb, flags)) {\n\t\tUDP_INC_STATS_USER(sock_net(sk), UDP_MIB_CSUMERRORS, is_udplite);\n\t\tUDP_INC_STATS_USER(sock_net(sk), UDP_MIB_INERRORS, is_udplite);\n\t}\n\tunlock_sock_fast(sk, slow);\n\n\tif (noblock)\n\t\treturn -EAGAIN;\n\n\t/* starting over for a new packet */\n\tmsg->msg_flags &= ~MSG_TRUNC;\n\tgoto try_again;\n}",
        "func": "int udp_recvmsg(struct sock *sk, struct msghdr *msg, size_t len, int noblock,\n\t\tint flags, int *addr_len)\n{\n\tstruct inet_sock *inet = inet_sk(sk);\n\tDECLARE_SOCKADDR(struct sockaddr_in *, sin, msg->msg_name);\n\tstruct sk_buff *skb;\n\tunsigned int ulen, copied;\n\tint peeked, off = 0;\n\tint err;\n\tint is_udplite = IS_UDPLITE(sk);\n\tbool slow;\n\n\tif (flags & MSG_ERRQUEUE)\n\t\treturn ip_recv_error(sk, msg, len, addr_len);\n\ntry_again:\n\tskb = __skb_recv_datagram(sk, flags | (noblock ? MSG_DONTWAIT : 0),\n\t\t\t\t  &peeked, &off, &err);\n\tif (!skb)\n\t\tgoto out;\n\n\tulen = skb->len - sizeof(struct udphdr);\n\tcopied = len;\n\tif (copied > ulen)\n\t\tcopied = ulen;\n\telse if (copied < ulen)\n\t\tmsg->msg_flags |= MSG_TRUNC;\n\n\t/*\n\t * If checksum is needed at all, try to do it while copying the\n\t * data.  If the data is truncated, or if we only want a partial\n\t * coverage checksum (UDP-Lite), do it before the copy.\n\t */\n\n\tif (copied < ulen || UDP_SKB_CB(skb)->partial_cov) {\n\t\tif (udp_lib_checksum_complete(skb))\n\t\t\tgoto csum_copy_err;\n\t}\n\n\tif (skb_csum_unnecessary(skb))\n\t\terr = skb_copy_datagram_msg(skb, sizeof(struct udphdr),\n\t\t\t\t\t    msg, copied);\n\telse {\n\t\terr = skb_copy_and_csum_datagram_msg(skb, sizeof(struct udphdr),\n\t\t\t\t\t\t     msg);\n\n\t\tif (err == -EINVAL)\n\t\t\tgoto csum_copy_err;\n\t}\n\n\tif (unlikely(err)) {\n\t\ttrace_kfree_skb(skb, udp_recvmsg);\n\t\tif (!peeked) {\n\t\t\tatomic_inc(&sk->sk_drops);\n\t\t\tUDP_INC_STATS_USER(sock_net(sk),\n\t\t\t\t\t   UDP_MIB_INERRORS, is_udplite);\n\t\t}\n\t\tgoto out_free;\n\t}\n\n\tif (!peeked)\n\t\tUDP_INC_STATS_USER(sock_net(sk),\n\t\t\t\tUDP_MIB_INDATAGRAMS, is_udplite);\n\n\tsock_recv_ts_and_drops(msg, sk, skb);\n\n\t/* Copy the address. */\n\tif (sin) {\n\t\tsin->sin_family = AF_INET;\n\t\tsin->sin_port = udp_hdr(skb)->source;\n\t\tsin->sin_addr.s_addr = ip_hdr(skb)->saddr;\n\t\tmemset(sin->sin_zero, 0, sizeof(sin->sin_zero));\n\t\t*addr_len = sizeof(*sin);\n\t}\n\tif (inet->cmsg_flags)\n\t\tip_cmsg_recv_offset(msg, skb, sizeof(struct udphdr));\n\n\terr = copied;\n\tif (flags & MSG_TRUNC)\n\t\terr = ulen;\n\nout_free:\n\tskb_free_datagram_locked(sk, skb);\nout:\n\treturn err;\n\ncsum_copy_err:\n\tslow = lock_sock_fast(sk);\n\tif (!skb_kill_datagram(sk, skb, flags)) {\n\t\tUDP_INC_STATS_USER(sock_net(sk), UDP_MIB_CSUMERRORS, is_udplite);\n\t\tUDP_INC_STATS_USER(sock_net(sk), UDP_MIB_INERRORS, is_udplite);\n\t}\n\tunlock_sock_fast(sk, slow);\n\n\t/* starting over for a new packet, but check if we need to yield */\n\tcond_resched();\n\tmsg->msg_flags &= ~MSG_TRUNC;\n\tgoto try_again;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -92,10 +92,8 @@\n \t}\n \tunlock_sock_fast(sk, slow);\n \n-\tif (noblock)\n-\t\treturn -EAGAIN;\n-\n-\t/* starting over for a new packet */\n+\t/* starting over for a new packet, but check if we need to yield */\n+\tcond_resched();\n \tmsg->msg_flags &= ~MSG_TRUNC;\n \tgoto try_again;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (noblock)",
                "\t\treturn -EAGAIN;",
                "",
                "\t/* starting over for a new packet */"
            ],
            "added_lines": [
                "\t/* starting over for a new packet, but check if we need to yield */",
                "\tcond_resched();"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-5364",
        "func_name": "torvalds/linux/udp_recvmsg",
        "description": "The (1) udp_recvmsg and (2) udpv6_recvmsg functions in the Linux kernel before 4.0.6 do not properly consider yielding a processor, which allows remote attackers to cause a denial of service (system hang) via incorrect checksums within a UDP packet flood.",
        "git_url": "https://github.com/torvalds/linux/commit/beb39db59d14990e401e235faf66a6b9b31240b0",
        "commit_title": "udp: fix behavior of wrong checksums",
        "commit_text": " We have two problems in UDP stack related to bogus checksums :  1) We return -EAGAIN to application even if receive queue is not empty.    This breaks applications using edge trigger epoll()  2) Under UDP flood, we can loop forever without yielding to other    processes, potentially hanging the host, especially on non SMP.  This patch is an attempt to make things better.  We might in the future add extra support for rt applications wanting to better control time spent doing a recv() in a hostile environment. For example we could validate checksums before queuing packets in socket receive queue.  Cc: Willem de Bruijn <willemb@google.com>",
        "func_before": "int udp_recvmsg(struct sock *sk, struct msghdr *msg, size_t len, int noblock,\n\t\tint flags, int *addr_len)\n{\n\tstruct inet_sock *inet = inet_sk(sk);\n\tDECLARE_SOCKADDR(struct sockaddr_in *, sin, msg->msg_name);\n\tstruct sk_buff *skb;\n\tunsigned int ulen, copied;\n\tint peeked, off = 0;\n\tint err;\n\tint is_udplite = IS_UDPLITE(sk);\n\tbool slow;\n\n\tif (flags & MSG_ERRQUEUE)\n\t\treturn ip_recv_error(sk, msg, len, addr_len);\n\ntry_again:\n\tskb = __skb_recv_datagram(sk, flags | (noblock ? MSG_DONTWAIT : 0),\n\t\t\t\t  &peeked, &off, &err);\n\tif (!skb)\n\t\tgoto out;\n\n\tulen = skb->len - sizeof(struct udphdr);\n\tcopied = len;\n\tif (copied > ulen)\n\t\tcopied = ulen;\n\telse if (copied < ulen)\n\t\tmsg->msg_flags |= MSG_TRUNC;\n\n\t/*\n\t * If checksum is needed at all, try to do it while copying the\n\t * data.  If the data is truncated, or if we only want a partial\n\t * coverage checksum (UDP-Lite), do it before the copy.\n\t */\n\n\tif (copied < ulen || UDP_SKB_CB(skb)->partial_cov) {\n\t\tif (udp_lib_checksum_complete(skb))\n\t\t\tgoto csum_copy_err;\n\t}\n\n\tif (skb_csum_unnecessary(skb))\n\t\terr = skb_copy_datagram_msg(skb, sizeof(struct udphdr),\n\t\t\t\t\t    msg, copied);\n\telse {\n\t\terr = skb_copy_and_csum_datagram_msg(skb, sizeof(struct udphdr),\n\t\t\t\t\t\t     msg);\n\n\t\tif (err == -EINVAL)\n\t\t\tgoto csum_copy_err;\n\t}\n\n\tif (unlikely(err)) {\n\t\ttrace_kfree_skb(skb, udp_recvmsg);\n\t\tif (!peeked) {\n\t\t\tatomic_inc(&sk->sk_drops);\n\t\t\tUDP_INC_STATS_USER(sock_net(sk),\n\t\t\t\t\t   UDP_MIB_INERRORS, is_udplite);\n\t\t}\n\t\tgoto out_free;\n\t}\n\n\tif (!peeked)\n\t\tUDP_INC_STATS_USER(sock_net(sk),\n\t\t\t\tUDP_MIB_INDATAGRAMS, is_udplite);\n\n\tsock_recv_ts_and_drops(msg, sk, skb);\n\n\t/* Copy the address. */\n\tif (sin) {\n\t\tsin->sin_family = AF_INET;\n\t\tsin->sin_port = udp_hdr(skb)->source;\n\t\tsin->sin_addr.s_addr = ip_hdr(skb)->saddr;\n\t\tmemset(sin->sin_zero, 0, sizeof(sin->sin_zero));\n\t\t*addr_len = sizeof(*sin);\n\t}\n\tif (inet->cmsg_flags)\n\t\tip_cmsg_recv_offset(msg, skb, sizeof(struct udphdr));\n\n\terr = copied;\n\tif (flags & MSG_TRUNC)\n\t\terr = ulen;\n\nout_free:\n\tskb_free_datagram_locked(sk, skb);\nout:\n\treturn err;\n\ncsum_copy_err:\n\tslow = lock_sock_fast(sk);\n\tif (!skb_kill_datagram(sk, skb, flags)) {\n\t\tUDP_INC_STATS_USER(sock_net(sk), UDP_MIB_CSUMERRORS, is_udplite);\n\t\tUDP_INC_STATS_USER(sock_net(sk), UDP_MIB_INERRORS, is_udplite);\n\t}\n\tunlock_sock_fast(sk, slow);\n\n\tif (noblock)\n\t\treturn -EAGAIN;\n\n\t/* starting over for a new packet */\n\tmsg->msg_flags &= ~MSG_TRUNC;\n\tgoto try_again;\n}",
        "func": "int udp_recvmsg(struct sock *sk, struct msghdr *msg, size_t len, int noblock,\n\t\tint flags, int *addr_len)\n{\n\tstruct inet_sock *inet = inet_sk(sk);\n\tDECLARE_SOCKADDR(struct sockaddr_in *, sin, msg->msg_name);\n\tstruct sk_buff *skb;\n\tunsigned int ulen, copied;\n\tint peeked, off = 0;\n\tint err;\n\tint is_udplite = IS_UDPLITE(sk);\n\tbool slow;\n\n\tif (flags & MSG_ERRQUEUE)\n\t\treturn ip_recv_error(sk, msg, len, addr_len);\n\ntry_again:\n\tskb = __skb_recv_datagram(sk, flags | (noblock ? MSG_DONTWAIT : 0),\n\t\t\t\t  &peeked, &off, &err);\n\tif (!skb)\n\t\tgoto out;\n\n\tulen = skb->len - sizeof(struct udphdr);\n\tcopied = len;\n\tif (copied > ulen)\n\t\tcopied = ulen;\n\telse if (copied < ulen)\n\t\tmsg->msg_flags |= MSG_TRUNC;\n\n\t/*\n\t * If checksum is needed at all, try to do it while copying the\n\t * data.  If the data is truncated, or if we only want a partial\n\t * coverage checksum (UDP-Lite), do it before the copy.\n\t */\n\n\tif (copied < ulen || UDP_SKB_CB(skb)->partial_cov) {\n\t\tif (udp_lib_checksum_complete(skb))\n\t\t\tgoto csum_copy_err;\n\t}\n\n\tif (skb_csum_unnecessary(skb))\n\t\terr = skb_copy_datagram_msg(skb, sizeof(struct udphdr),\n\t\t\t\t\t    msg, copied);\n\telse {\n\t\terr = skb_copy_and_csum_datagram_msg(skb, sizeof(struct udphdr),\n\t\t\t\t\t\t     msg);\n\n\t\tif (err == -EINVAL)\n\t\t\tgoto csum_copy_err;\n\t}\n\n\tif (unlikely(err)) {\n\t\ttrace_kfree_skb(skb, udp_recvmsg);\n\t\tif (!peeked) {\n\t\t\tatomic_inc(&sk->sk_drops);\n\t\t\tUDP_INC_STATS_USER(sock_net(sk),\n\t\t\t\t\t   UDP_MIB_INERRORS, is_udplite);\n\t\t}\n\t\tgoto out_free;\n\t}\n\n\tif (!peeked)\n\t\tUDP_INC_STATS_USER(sock_net(sk),\n\t\t\t\tUDP_MIB_INDATAGRAMS, is_udplite);\n\n\tsock_recv_ts_and_drops(msg, sk, skb);\n\n\t/* Copy the address. */\n\tif (sin) {\n\t\tsin->sin_family = AF_INET;\n\t\tsin->sin_port = udp_hdr(skb)->source;\n\t\tsin->sin_addr.s_addr = ip_hdr(skb)->saddr;\n\t\tmemset(sin->sin_zero, 0, sizeof(sin->sin_zero));\n\t\t*addr_len = sizeof(*sin);\n\t}\n\tif (inet->cmsg_flags)\n\t\tip_cmsg_recv_offset(msg, skb, sizeof(struct udphdr));\n\n\terr = copied;\n\tif (flags & MSG_TRUNC)\n\t\terr = ulen;\n\nout_free:\n\tskb_free_datagram_locked(sk, skb);\nout:\n\treturn err;\n\ncsum_copy_err:\n\tslow = lock_sock_fast(sk);\n\tif (!skb_kill_datagram(sk, skb, flags)) {\n\t\tUDP_INC_STATS_USER(sock_net(sk), UDP_MIB_CSUMERRORS, is_udplite);\n\t\tUDP_INC_STATS_USER(sock_net(sk), UDP_MIB_INERRORS, is_udplite);\n\t}\n\tunlock_sock_fast(sk, slow);\n\n\t/* starting over for a new packet, but check if we need to yield */\n\tcond_resched();\n\tmsg->msg_flags &= ~MSG_TRUNC;\n\tgoto try_again;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -92,10 +92,8 @@\n \t}\n \tunlock_sock_fast(sk, slow);\n \n-\tif (noblock)\n-\t\treturn -EAGAIN;\n-\n-\t/* starting over for a new packet */\n+\t/* starting over for a new packet, but check if we need to yield */\n+\tcond_resched();\n \tmsg->msg_flags &= ~MSG_TRUNC;\n \tgoto try_again;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (noblock)",
                "\t\treturn -EAGAIN;",
                "",
                "\t/* starting over for a new packet */"
            ],
            "added_lines": [
                "\t/* starting over for a new packet, but check if we need to yield */",
                "\tcond_resched();"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-6526",
        "func_name": "torvalds/linux/perf_callchain_user_64",
        "description": "The perf_callchain_user_64 function in arch/powerpc/perf/callchain.c in the Linux kernel before 4.0.2 on ppc64 platforms allows local users to cause a denial of service (infinite loop) via a deep 64-bit userspace backtrace.",
        "git_url": "https://github.com/torvalds/linux/commit/9a5cbce421a283e6aea3c4007f141735bf9da8c3",
        "commit_title": "powerpc/perf: Cap 64bit userspace backtraces to PERF_MAX_STACK_DEPTH",
        "commit_text": " We cap 32bit userspace backtraces to PERF_MAX_STACK_DEPTH (currently 127), but we forgot to do the same for 64bit backtraces.  Cc: stable@vger.kernel.org",
        "func_before": "static void perf_callchain_user_64(struct perf_callchain_entry *entry,\n\t\t\t\t   struct pt_regs *regs)\n{\n\tunsigned long sp, next_sp;\n\tunsigned long next_ip;\n\tunsigned long lr;\n\tlong level = 0;\n\tstruct signal_frame_64 __user *sigframe;\n\tunsigned long __user *fp, *uregs;\n\n\tnext_ip = perf_instruction_pointer(regs);\n\tlr = regs->link;\n\tsp = regs->gpr[1];\n\tperf_callchain_store(entry, next_ip);\n\n\tfor (;;) {\n\t\tfp = (unsigned long __user *) sp;\n\t\tif (!valid_user_sp(sp, 1) || read_user_stack_64(fp, &next_sp))\n\t\t\treturn;\n\t\tif (level > 0 && read_user_stack_64(&fp[2], &next_ip))\n\t\t\treturn;\n\n\t\t/*\n\t\t * Note: the next_sp - sp >= signal frame size check\n\t\t * is true when next_sp < sp, which can happen when\n\t\t * transitioning from an alternate signal stack to the\n\t\t * normal stack.\n\t\t */\n\t\tif (next_sp - sp >= sizeof(struct signal_frame_64) &&\n\t\t    (is_sigreturn_64_address(next_ip, sp) ||\n\t\t     (level <= 1 && is_sigreturn_64_address(lr, sp))) &&\n\t\t    sane_signal_64_frame(sp)) {\n\t\t\t/*\n\t\t\t * This looks like an signal frame\n\t\t\t */\n\t\t\tsigframe = (struct signal_frame_64 __user *) sp;\n\t\t\turegs = sigframe->uc.uc_mcontext.gp_regs;\n\t\t\tif (read_user_stack_64(&uregs[PT_NIP], &next_ip) ||\n\t\t\t    read_user_stack_64(&uregs[PT_LNK], &lr) ||\n\t\t\t    read_user_stack_64(&uregs[PT_R1], &sp))\n\t\t\t\treturn;\n\t\t\tlevel = 0;\n\t\t\tperf_callchain_store(entry, PERF_CONTEXT_USER);\n\t\t\tperf_callchain_store(entry, next_ip);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (level == 0)\n\t\t\tnext_ip = lr;\n\t\tperf_callchain_store(entry, next_ip);\n\t\t++level;\n\t\tsp = next_sp;\n\t}\n}",
        "func": "static void perf_callchain_user_64(struct perf_callchain_entry *entry,\n\t\t\t\t   struct pt_regs *regs)\n{\n\tunsigned long sp, next_sp;\n\tunsigned long next_ip;\n\tunsigned long lr;\n\tlong level = 0;\n\tstruct signal_frame_64 __user *sigframe;\n\tunsigned long __user *fp, *uregs;\n\n\tnext_ip = perf_instruction_pointer(regs);\n\tlr = regs->link;\n\tsp = regs->gpr[1];\n\tperf_callchain_store(entry, next_ip);\n\n\twhile (entry->nr < PERF_MAX_STACK_DEPTH) {\n\t\tfp = (unsigned long __user *) sp;\n\t\tif (!valid_user_sp(sp, 1) || read_user_stack_64(fp, &next_sp))\n\t\t\treturn;\n\t\tif (level > 0 && read_user_stack_64(&fp[2], &next_ip))\n\t\t\treturn;\n\n\t\t/*\n\t\t * Note: the next_sp - sp >= signal frame size check\n\t\t * is true when next_sp < sp, which can happen when\n\t\t * transitioning from an alternate signal stack to the\n\t\t * normal stack.\n\t\t */\n\t\tif (next_sp - sp >= sizeof(struct signal_frame_64) &&\n\t\t    (is_sigreturn_64_address(next_ip, sp) ||\n\t\t     (level <= 1 && is_sigreturn_64_address(lr, sp))) &&\n\t\t    sane_signal_64_frame(sp)) {\n\t\t\t/*\n\t\t\t * This looks like an signal frame\n\t\t\t */\n\t\t\tsigframe = (struct signal_frame_64 __user *) sp;\n\t\t\turegs = sigframe->uc.uc_mcontext.gp_regs;\n\t\t\tif (read_user_stack_64(&uregs[PT_NIP], &next_ip) ||\n\t\t\t    read_user_stack_64(&uregs[PT_LNK], &lr) ||\n\t\t\t    read_user_stack_64(&uregs[PT_R1], &sp))\n\t\t\t\treturn;\n\t\t\tlevel = 0;\n\t\t\tperf_callchain_store(entry, PERF_CONTEXT_USER);\n\t\t\tperf_callchain_store(entry, next_ip);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (level == 0)\n\t\t\tnext_ip = lr;\n\t\tperf_callchain_store(entry, next_ip);\n\t\t++level;\n\t\tsp = next_sp;\n\t}\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -13,7 +13,7 @@\n \tsp = regs->gpr[1];\n \tperf_callchain_store(entry, next_ip);\n \n-\tfor (;;) {\n+\twhile (entry->nr < PERF_MAX_STACK_DEPTH) {\n \t\tfp = (unsigned long __user *) sp;\n \t\tif (!valid_user_sp(sp, 1) || read_user_stack_64(fp, &next_sp))\n \t\t\treturn;",
        "diff_line_info": {
            "deleted_lines": [
                "\tfor (;;) {"
            ],
            "added_lines": [
                "\twhile (entry->nr < PERF_MAX_STACK_DEPTH) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2011-3973",
        "func_name": "ffmpeg/decode_mb_i",
        "description": "cavsdec.c in libavcodec in FFmpeg before 0.7.4 and 0.8.x before 0.8.3 allows remote attackers to cause a denial of service (incorrect write operation and application crash) via an invalid bitstream in a Chinese AVS video (aka CAVS) file, related to the decode_residual_block, check_for_slice, and cavs_decode_frame functions, a different vulnerability than CVE-2011-3362.",
        "git_url": "http://git.videolan.org/?p=ffmpeg.git;a=commit;h=bd968d260aef322fb32e254a3de0d2036c57bd56",
        "commit_title": "",
        "commit_text": "cavs: fix some crashes with invalid bitstreams  This removes all valgrind-reported invalid writes with one specific test file.  Fixes http://www.ocert.org/advisories/ocert-2011-002.html  (cherry picked from commit 4a71da0f3ab7f5542decd11c81994f849d5b2c78) ",
        "func_before": "static int decode_mb_i(AVSContext *h, int cbp_code) {\n    GetBitContext *gb = &h->s.gb;\n    int block, pred_mode_uv;\n    uint8_t top[18];\n    uint8_t *left = NULL;\n    uint8_t *d;\n\n    ff_cavs_init_mb(h);\n\n    /* get intra prediction modes from stream */\n    for(block=0;block<4;block++) {\n        int nA,nB,predpred;\n        int pos = ff_cavs_scan3x3[block];\n\n        nA = h->pred_mode_Y[pos-1];\n        nB = h->pred_mode_Y[pos-3];\n        predpred = FFMIN(nA,nB);\n        if(predpred == NOT_AVAIL) // if either is not available\n            predpred = INTRA_L_LP;\n        if(!get_bits1(gb)){\n            int rem_mode= get_bits(gb, 2);\n            predpred = rem_mode + (rem_mode >= predpred);\n        }\n        h->pred_mode_Y[pos] = predpred;\n    }\n    pred_mode_uv = get_ue_golomb(gb);\n    if(pred_mode_uv > 6) {\n        av_log(h->s.avctx, AV_LOG_ERROR, \"illegal intra chroma pred mode\\n\");\n        return -1;\n    }\n    ff_cavs_modify_mb_i(h, &pred_mode_uv);\n\n    /* get coded block pattern */\n    if(h->pic_type == AV_PICTURE_TYPE_I)\n        cbp_code = get_ue_golomb(gb);\n    if(cbp_code > 63){\n        av_log(h->s.avctx, AV_LOG_ERROR, \"illegal intra cbp\\n\");\n        return -1;\n    }\n    h->cbp = cbp_tab[cbp_code][0];\n    if(h->cbp && !h->qp_fixed)\n        h->qp = (h->qp + get_se_golomb(gb)) & 63; //qp_delta\n\n    /* luma intra prediction interleaved with residual decode/transform/add */\n    for(block=0;block<4;block++) {\n        d = h->cy + h->luma_scan[block];\n        ff_cavs_load_intra_pred_luma(h, top, &left, block);\n        h->intra_pred_l[h->pred_mode_Y[ff_cavs_scan3x3[block]]]\n            (d, top, left, h->l_stride);\n        if(h->cbp & (1<<block))\n            decode_residual_block(h,gb,ff_cavs_intra_dec,1,h->qp,d,h->l_stride);\n    }\n\n    /* chroma intra prediction */\n    ff_cavs_load_intra_pred_chroma(h);\n    h->intra_pred_c[pred_mode_uv](h->cu, &h->top_border_u[h->mbx*10],\n                                  h->left_border_u, h->c_stride);\n    h->intra_pred_c[pred_mode_uv](h->cv, &h->top_border_v[h->mbx*10],\n                                  h->left_border_v, h->c_stride);\n\n    decode_residual_chroma(h);\n    ff_cavs_filter(h,I_8X8);\n    set_mv_intra(h);\n    return 0;\n}",
        "func": "static int decode_mb_i(AVSContext *h, int cbp_code) {\n    GetBitContext *gb = &h->s.gb;\n    unsigned pred_mode_uv;\n    int block;\n    uint8_t top[18];\n    uint8_t *left = NULL;\n    uint8_t *d;\n\n    ff_cavs_init_mb(h);\n\n    /* get intra prediction modes from stream */\n    for(block=0;block<4;block++) {\n        int nA,nB,predpred;\n        int pos = ff_cavs_scan3x3[block];\n\n        nA = h->pred_mode_Y[pos-1];\n        nB = h->pred_mode_Y[pos-3];\n        predpred = FFMIN(nA,nB);\n        if(predpred == NOT_AVAIL) // if either is not available\n            predpred = INTRA_L_LP;\n        if(!get_bits1(gb)){\n            int rem_mode= get_bits(gb, 2);\n            predpred = rem_mode + (rem_mode >= predpred);\n        }\n        h->pred_mode_Y[pos] = predpred;\n    }\n    pred_mode_uv = get_ue_golomb(gb);\n    if(pred_mode_uv > 6) {\n        av_log(h->s.avctx, AV_LOG_ERROR, \"illegal intra chroma pred mode\\n\");\n        return -1;\n    }\n    ff_cavs_modify_mb_i(h, &pred_mode_uv);\n\n    /* get coded block pattern */\n    if(h->pic_type == AV_PICTURE_TYPE_I)\n        cbp_code = get_ue_golomb(gb);\n    if(cbp_code > 63){\n        av_log(h->s.avctx, AV_LOG_ERROR, \"illegal intra cbp\\n\");\n        return -1;\n    }\n    h->cbp = cbp_tab[cbp_code][0];\n    if(h->cbp && !h->qp_fixed)\n        h->qp = (h->qp + get_se_golomb(gb)) & 63; //qp_delta\n\n    /* luma intra prediction interleaved with residual decode/transform/add */\n    for(block=0;block<4;block++) {\n        d = h->cy + h->luma_scan[block];\n        ff_cavs_load_intra_pred_luma(h, top, &left, block);\n        h->intra_pred_l[h->pred_mode_Y[ff_cavs_scan3x3[block]]]\n            (d, top, left, h->l_stride);\n        if(h->cbp & (1<<block))\n            decode_residual_block(h,gb,ff_cavs_intra_dec,1,h->qp,d,h->l_stride);\n    }\n\n    /* chroma intra prediction */\n    ff_cavs_load_intra_pred_chroma(h);\n    h->intra_pred_c[pred_mode_uv](h->cu, &h->top_border_u[h->mbx*10],\n                                  h->left_border_u, h->c_stride);\n    h->intra_pred_c[pred_mode_uv](h->cv, &h->top_border_v[h->mbx*10],\n                                  h->left_border_v, h->c_stride);\n\n    decode_residual_chroma(h);\n    ff_cavs_filter(h,I_8X8);\n    set_mv_intra(h);\n    return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,7 @@\n static int decode_mb_i(AVSContext *h, int cbp_code) {\n     GetBitContext *gb = &h->s.gb;\n-    int block, pred_mode_uv;\n+    unsigned pred_mode_uv;\n+    int block;\n     uint8_t top[18];\n     uint8_t *left = NULL;\n     uint8_t *d;",
        "diff_line_info": {
            "deleted_lines": [
                "    int block, pred_mode_uv;"
            ],
            "added_lines": [
                "    unsigned pred_mode_uv;",
                "    int block;"
            ]
        }
    },
    {
        "cve_id": "CVE-2011-3973",
        "func_name": "ffmpeg/cavs_decode_frame",
        "description": "cavsdec.c in libavcodec in FFmpeg before 0.7.4 and 0.8.x before 0.8.3 allows remote attackers to cause a denial of service (incorrect write operation and application crash) via an invalid bitstream in a Chinese AVS video (aka CAVS) file, related to the decode_residual_block, check_for_slice, and cavs_decode_frame functions, a different vulnerability than CVE-2011-3362.",
        "git_url": "http://git.videolan.org/?p=ffmpeg.git;a=commit;h=bd968d260aef322fb32e254a3de0d2036c57bd56",
        "commit_title": "",
        "commit_text": "cavs: fix some crashes with invalid bitstreams  This removes all valgrind-reported invalid writes with one specific test file.  Fixes http://www.ocert.org/advisories/ocert-2011-002.html  (cherry picked from commit 4a71da0f3ab7f5542decd11c81994f849d5b2c78) ",
        "func_before": "static int cavs_decode_frame(AVCodecContext * avctx,void *data, int *data_size,\n                             AVPacket *avpkt) {\n    const uint8_t *buf = avpkt->data;\n    int buf_size = avpkt->size;\n    AVSContext *h = avctx->priv_data;\n    MpegEncContext *s = &h->s;\n    int input_size;\n    const uint8_t *buf_end;\n    const uint8_t *buf_ptr;\n    AVFrame *picture = data;\n    uint32_t stc = -1;\n\n    s->avctx = avctx;\n\n    if (buf_size == 0) {\n        if(!s->low_delay && h->DPB[0].data[0]) {\n            *data_size = sizeof(AVPicture);\n            *picture = *(AVFrame *) &h->DPB[0];\n        }\n        return 0;\n    }\n\n    buf_ptr = buf;\n    buf_end = buf + buf_size;\n    for(;;) {\n        buf_ptr = ff_find_start_code(buf_ptr,buf_end, &stc);\n        if(stc & 0xFFFFFE00)\n            return FFMAX(0, buf_ptr - buf - s->parse_context.last_index);\n        input_size = (buf_end - buf_ptr)*8;\n        switch(stc) {\n        case CAVS_START_CODE:\n            init_get_bits(&s->gb, buf_ptr, input_size);\n            decode_seq_header(h);\n            break;\n        case PIC_I_START_CODE:\n            if(!h->got_keyframe) {\n                if(h->DPB[0].data[0])\n                    avctx->release_buffer(avctx, (AVFrame *)&h->DPB[0]);\n                if(h->DPB[1].data[0])\n                    avctx->release_buffer(avctx, (AVFrame *)&h->DPB[1]);\n                h->got_keyframe = 1;\n            }\n        case PIC_PB_START_CODE:\n            *data_size = 0;\n            if(!h->got_keyframe)\n                break;\n            init_get_bits(&s->gb, buf_ptr, input_size);\n            h->stc = stc;\n            if(decode_pic(h))\n                break;\n            *data_size = sizeof(AVPicture);\n            if(h->pic_type != AV_PICTURE_TYPE_B) {\n                if(h->DPB[1].data[0]) {\n                    *picture = *(AVFrame *) &h->DPB[1];\n                } else {\n                    *data_size = 0;\n                }\n            } else\n                *picture = *(AVFrame *) &h->picture;\n            break;\n        case EXT_START_CODE:\n            //mpeg_decode_extension(avctx,buf_ptr, input_size);\n            break;\n        case USER_START_CODE:\n            //mpeg_decode_user_data(avctx,buf_ptr, input_size);\n            break;\n        default:\n            if (stc <= SLICE_MAX_START_CODE) {\n                init_get_bits(&s->gb, buf_ptr, input_size);\n                decode_slice_header(h, &s->gb);\n            }\n            break;\n        }\n    }\n}",
        "func": "static int cavs_decode_frame(AVCodecContext * avctx,void *data, int *data_size,\n                             AVPacket *avpkt) {\n    const uint8_t *buf = avpkt->data;\n    int buf_size = avpkt->size;\n    AVSContext *h = avctx->priv_data;\n    MpegEncContext *s = &h->s;\n    int input_size;\n    const uint8_t *buf_end;\n    const uint8_t *buf_ptr;\n    AVFrame *picture = data;\n    uint32_t stc = -1;\n\n    s->avctx = avctx;\n\n    if (buf_size == 0) {\n        if(!s->low_delay && h->DPB[0].data[0]) {\n            *data_size = sizeof(AVPicture);\n            *picture = *(AVFrame *) &h->DPB[0];\n        }\n        return 0;\n    }\n\n    buf_ptr = buf;\n    buf_end = buf + buf_size;\n    for(;;) {\n        buf_ptr = ff_find_start_code(buf_ptr,buf_end, &stc);\n        if((stc & 0xFFFFFE00) || buf_ptr == buf_end)\n            return FFMAX(0, buf_ptr - buf - s->parse_context.last_index);\n        input_size = (buf_end - buf_ptr)*8;\n        switch(stc) {\n        case CAVS_START_CODE:\n            init_get_bits(&s->gb, buf_ptr, input_size);\n            decode_seq_header(h);\n            break;\n        case PIC_I_START_CODE:\n            if(!h->got_keyframe) {\n                if(h->DPB[0].data[0])\n                    avctx->release_buffer(avctx, (AVFrame *)&h->DPB[0]);\n                if(h->DPB[1].data[0])\n                    avctx->release_buffer(avctx, (AVFrame *)&h->DPB[1]);\n                h->got_keyframe = 1;\n            }\n        case PIC_PB_START_CODE:\n            *data_size = 0;\n            if(!h->got_keyframe)\n                break;\n            init_get_bits(&s->gb, buf_ptr, input_size);\n            h->stc = stc;\n            if(decode_pic(h))\n                break;\n            *data_size = sizeof(AVPicture);\n            if(h->pic_type != AV_PICTURE_TYPE_B) {\n                if(h->DPB[1].data[0]) {\n                    *picture = *(AVFrame *) &h->DPB[1];\n                } else {\n                    *data_size = 0;\n                }\n            } else\n                *picture = *(AVFrame *) &h->picture;\n            break;\n        case EXT_START_CODE:\n            //mpeg_decode_extension(avctx,buf_ptr, input_size);\n            break;\n        case USER_START_CODE:\n            //mpeg_decode_user_data(avctx,buf_ptr, input_size);\n            break;\n        default:\n            if (stc <= SLICE_MAX_START_CODE) {\n                init_get_bits(&s->gb, buf_ptr, input_size);\n                decode_slice_header(h, &s->gb);\n            }\n            break;\n        }\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -24,7 +24,7 @@\n     buf_end = buf + buf_size;\n     for(;;) {\n         buf_ptr = ff_find_start_code(buf_ptr,buf_end, &stc);\n-        if(stc & 0xFFFFFE00)\n+        if((stc & 0xFFFFFE00) || buf_ptr == buf_end)\n             return FFMAX(0, buf_ptr - buf - s->parse_context.last_index);\n         input_size = (buf_end - buf_ptr)*8;\n         switch(stc) {",
        "diff_line_info": {
            "deleted_lines": [
                "        if(stc & 0xFFFFFE00)"
            ],
            "added_lines": [
                "        if((stc & 0xFFFFFE00) || buf_ptr == buf_end)"
            ]
        }
    },
    {
        "cve_id": "CVE-2011-3973",
        "func_name": "ffmpeg/check_for_slice",
        "description": "cavsdec.c in libavcodec in FFmpeg before 0.7.4 and 0.8.x before 0.8.3 allows remote attackers to cause a denial of service (incorrect write operation and application crash) via an invalid bitstream in a Chinese AVS video (aka CAVS) file, related to the decode_residual_block, check_for_slice, and cavs_decode_frame functions, a different vulnerability than CVE-2011-3362.",
        "git_url": "http://git.videolan.org/?p=ffmpeg.git;a=commit;h=bd968d260aef322fb32e254a3de0d2036c57bd56",
        "commit_title": "",
        "commit_text": "cavs: fix some crashes with invalid bitstreams  This removes all valgrind-reported invalid writes with one specific test file.  Fixes http://www.ocert.org/advisories/ocert-2011-002.html  (cherry picked from commit 4a71da0f3ab7f5542decd11c81994f849d5b2c78) ",
        "func_before": "static inline int check_for_slice(AVSContext *h) {\n    GetBitContext *gb = &h->s.gb;\n    int align;\n\n    if(h->mbx)\n        return 0;\n    align = (-get_bits_count(gb)) & 7;\n    /* check for stuffing byte */\n    if(!align && (show_bits(gb,8) == 0x80))\n        align = 8;\n    if((show_bits_long(gb,24+align) & 0xFFFFFF) == 0x000001) {\n        skip_bits_long(gb,24+align);\n        h->stc = get_bits(gb,8);\n        decode_slice_header(h,gb);\n        return 1;\n    }\n    return 0;\n}",
        "func": "static inline int check_for_slice(AVSContext *h) {\n    GetBitContext *gb = &h->s.gb;\n    int align;\n\n    if(h->mbx)\n        return 0;\n    align = (-get_bits_count(gb)) & 7;\n    /* check for stuffing byte */\n    if(!align && (show_bits(gb,8) == 0x80))\n        align = 8;\n    if((show_bits_long(gb,24+align) & 0xFFFFFF) == 0x000001) {\n        skip_bits_long(gb,24+align);\n        h->stc = get_bits(gb,8);\n        if (h->stc >= h->mb_height)\n            return 0;\n        decode_slice_header(h,gb);\n        return 1;\n    }\n    return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -11,6 +11,8 @@\n     if((show_bits_long(gb,24+align) & 0xFFFFFF) == 0x000001) {\n         skip_bits_long(gb,24+align);\n         h->stc = get_bits(gb,8);\n+        if (h->stc >= h->mb_height)\n+            return 0;\n         decode_slice_header(h,gb);\n         return 1;\n     }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "        if (h->stc >= h->mb_height)",
                "            return 0;"
            ]
        }
    },
    {
        "cve_id": "CVE-2011-3973",
        "func_name": "ffmpeg/decode_residual_block",
        "description": "cavsdec.c in libavcodec in FFmpeg before 0.7.4 and 0.8.x before 0.8.3 allows remote attackers to cause a denial of service (incorrect write operation and application crash) via an invalid bitstream in a Chinese AVS video (aka CAVS) file, related to the decode_residual_block, check_for_slice, and cavs_decode_frame functions, a different vulnerability than CVE-2011-3362.",
        "git_url": "http://git.videolan.org/?p=ffmpeg.git;a=commit;h=bd968d260aef322fb32e254a3de0d2036c57bd56",
        "commit_title": "",
        "commit_text": "cavs: fix some crashes with invalid bitstreams  This removes all valgrind-reported invalid writes with one specific test file.  Fixes http://www.ocert.org/advisories/ocert-2011-002.html  (cherry picked from commit 4a71da0f3ab7f5542decd11c81994f849d5b2c78) ",
        "func_before": "static int decode_residual_block(AVSContext *h, GetBitContext *gb,\n                                 const struct dec_2dvlc *r, int esc_golomb_order,\n                                 int qp, uint8_t *dst, int stride) {\n    int i, level_code, esc_code, level, run, mask;\n    DCTELEM level_buf[65];\n    uint8_t run_buf[65];\n    DCTELEM *block = h->block;\n\n    for(i=0;i<65;i++) {\n        level_code = get_ue_code(gb,r->golomb_order);\n        if(level_code >= ESCAPE_CODE) {\n            run = ((level_code - ESCAPE_CODE) >> 1) + 1;\n            esc_code = get_ue_code(gb,esc_golomb_order);\n            level = esc_code + (run > r->max_run ? 1 : r->level_add[run]);\n            while(level > r->inc_limit)\n                r++;\n            mask = -(level_code & 1);\n            level = (level^mask) - mask;\n        } else {\n            level = r->rltab[level_code][0];\n            if(!level) //end of block signal\n                break;\n            run   = r->rltab[level_code][1];\n            r += r->rltab[level_code][2];\n        }\n        level_buf[i] = level;\n        run_buf[i] = run;\n    }\n    if(dequant(h,level_buf, run_buf, block, ff_cavs_dequant_mul[qp],\n               ff_cavs_dequant_shift[qp], i))\n        return -1;\n    h->cdsp.cavs_idct8_add(dst,block,stride);\n    h->s.dsp.clear_block(block);\n    return 0;\n}",
        "func": "static int decode_residual_block(AVSContext *h, GetBitContext *gb,\n                                 const struct dec_2dvlc *r, int esc_golomb_order,\n                                 int qp, uint8_t *dst, int stride) {\n    int i, level_code, esc_code, level, run, mask;\n    DCTELEM level_buf[65];\n    uint8_t run_buf[65];\n    DCTELEM *block = h->block;\n\n    for(i=0;i<65;i++) {\n        level_code = get_ue_code(gb,r->golomb_order);\n        if(level_code >= ESCAPE_CODE) {\n            run = ((level_code - ESCAPE_CODE) >> 1) + 1;\n            esc_code = get_ue_code(gb,esc_golomb_order);\n            level = esc_code + (run > r->max_run ? 1 : r->level_add[run]);\n            while(level > r->inc_limit)\n                r++;\n            mask = -(level_code & 1);\n            level = (level^mask) - mask;\n        } else if (level_code >= 0) {\n            level = r->rltab[level_code][0];\n            if(!level) //end of block signal\n                break;\n            run   = r->rltab[level_code][1];\n            r += r->rltab[level_code][2];\n        } else {\n            break;\n        }\n        level_buf[i] = level;\n        run_buf[i] = run;\n    }\n    if(dequant(h,level_buf, run_buf, block, ff_cavs_dequant_mul[qp],\n               ff_cavs_dequant_shift[qp], i))\n        return -1;\n    h->cdsp.cavs_idct8_add(dst,block,stride);\n    h->s.dsp.clear_block(block);\n    return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -16,12 +16,14 @@\n                 r++;\n             mask = -(level_code & 1);\n             level = (level^mask) - mask;\n-        } else {\n+        } else if (level_code >= 0) {\n             level = r->rltab[level_code][0];\n             if(!level) //end of block signal\n                 break;\n             run   = r->rltab[level_code][1];\n             r += r->rltab[level_code][2];\n+        } else {\n+            break;\n         }\n         level_buf[i] = level;\n         run_buf[i] = run;",
        "diff_line_info": {
            "deleted_lines": [
                "        } else {"
            ],
            "added_lines": [
                "        } else if (level_code >= 0) {",
                "        } else {",
                "            break;"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-9252",
        "func_name": "qpdf/QPDF::resolve",
        "description": "An issue was discovered in QPDF before 7.0.0. Endless recursion causes stack exhaustion in QPDFTokenizer::resolveLiteral() in QPDFTokenizer.cc, related to the QPDF::resolve function in QPDF.cc.",
        "git_url": "https://github.com/qpdf/qpdf/commit/701b518d5c56a1449825a3a37a716c58e05e1c3e",
        "commit_title": "Detect recursion loops resolving objects (fixes #51)",
        "commit_text": " During parsing of an object, sometimes parts of the object have to be resolved. An example is stream lengths. If such an object directly or indirectly points to the object being parsed, it can cause an infinite loop. Guard against all cases of re-entrant resolution of objects.",
        "func_before": "PointerHolder<QPDFObject>\nQPDF::resolve(int objid, int generation)\n{\n    // Check object cache before checking xref table.  This allows us\n    // to insert things into the object cache that don't actually\n    // exist in the file.\n    QPDFObjGen og(objid, generation);\n    if (! this->obj_cache.count(og))\n    {\n\tif (! this->xref_table.count(og))\n\t{\n\t    // PDF spec says unknown objects resolve to the null object.\n\t    return new QPDF_Null;\n\t}\n\n\tQPDFXRefEntry const& entry = this->xref_table[og];\n\tswitch (entry.getType())\n\t{\n\t  case 1:\n\t    {\n\t\tqpdf_offset_t offset = entry.getOffset();\n\t\t// Object stored in cache by readObjectAtOffset\n\t\tint aobjid;\n\t\tint ageneration;\n\t\tQPDFObjectHandle oh =\n\t\t    readObjectAtOffset(true, offset, \"\", objid, generation,\n\t\t\t\t       aobjid, ageneration);\n\t    }\n\t    break;\n\n\t  case 2:\n\t    resolveObjectsInStream(entry.getObjStreamNumber());\n\t    break;\n\n\t  default:\n\t    throw QPDFExc(qpdf_e_damaged_pdf, this->file->getName(), \"\", 0,\n\t\t\t  \"object \" +\n\t\t\t  QUtil::int_to_string(objid) + \"/\" +\n\t\t\t  QUtil::int_to_string(generation) +\n\t\t\t  \" has unexpected xref entry type\");\n\t}\n    }\n\n    return this->obj_cache[og].object;\n}",
        "func": "PointerHolder<QPDFObject>\nQPDF::resolve(int objid, int generation)\n{\n    // Check object cache before checking xref table.  This allows us\n    // to insert things into the object cache that don't actually\n    // exist in the file.\n    QPDFObjGen og(objid, generation);\n    if (this->resolving.count(og))\n    {\n        // This can happen if an object references itself directly or\n        // indirectly in some key that has to be resolved during\n        // object parsing, such as stream length.\n\tQTC::TC(\"qpdf\", \"QPDF recursion loop in resolve\");\n\twarn(QPDFExc(qpdf_e_damaged_pdf, this->file->getName(),\n\t\t     \"\", this->file->getLastOffset(),\n\t\t     \"loop detected resolving object \" +\n\t\t     QUtil::int_to_string(objid) + \" \" +\n\t\t     QUtil::int_to_string(generation)));\n        return new QPDF_Null;\n    }\n    ResolveRecorder rr(this, og);\n\n    if (! this->obj_cache.count(og))\n    {\n\tif (! this->xref_table.count(og))\n\t{\n\t    // PDF spec says unknown objects resolve to the null object.\n\t    return new QPDF_Null;\n\t}\n\n\tQPDFXRefEntry const& entry = this->xref_table[og];\n\tswitch (entry.getType())\n\t{\n\t  case 1:\n\t    {\n\t\tqpdf_offset_t offset = entry.getOffset();\n\t\t// Object stored in cache by readObjectAtOffset\n\t\tint aobjid;\n\t\tint ageneration;\n\t\tQPDFObjectHandle oh =\n\t\t    readObjectAtOffset(true, offset, \"\", objid, generation,\n\t\t\t\t       aobjid, ageneration);\n\t    }\n\t    break;\n\n\t  case 2:\n\t    resolveObjectsInStream(entry.getObjStreamNumber());\n\t    break;\n\n\t  default:\n\t    throw QPDFExc(qpdf_e_damaged_pdf, this->file->getName(), \"\", 0,\n\t\t\t  \"object \" +\n\t\t\t  QUtil::int_to_string(objid) + \"/\" +\n\t\t\t  QUtil::int_to_string(generation) +\n\t\t\t  \" has unexpected xref entry type\");\n\t}\n    }\n\n    return this->obj_cache[og].object;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,6 +5,21 @@\n     // to insert things into the object cache that don't actually\n     // exist in the file.\n     QPDFObjGen og(objid, generation);\n+    if (this->resolving.count(og))\n+    {\n+        // This can happen if an object references itself directly or\n+        // indirectly in some key that has to be resolved during\n+        // object parsing, such as stream length.\n+\tQTC::TC(\"qpdf\", \"QPDF recursion loop in resolve\");\n+\twarn(QPDFExc(qpdf_e_damaged_pdf, this->file->getName(),\n+\t\t     \"\", this->file->getLastOffset(),\n+\t\t     \"loop detected resolving object \" +\n+\t\t     QUtil::int_to_string(objid) + \" \" +\n+\t\t     QUtil::int_to_string(generation)));\n+        return new QPDF_Null;\n+    }\n+    ResolveRecorder rr(this, og);\n+\n     if (! this->obj_cache.count(og))\n     {\n \tif (! this->xref_table.count(og))",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    if (this->resolving.count(og))",
                "    {",
                "        // This can happen if an object references itself directly or",
                "        // indirectly in some key that has to be resolved during",
                "        // object parsing, such as stream length.",
                "\tQTC::TC(\"qpdf\", \"QPDF recursion loop in resolve\");",
                "\twarn(QPDFExc(qpdf_e_damaged_pdf, this->file->getName(),",
                "\t\t     \"\", this->file->getLastOffset(),",
                "\t\t     \"loop detected resolving object \" +",
                "\t\t     QUtil::int_to_string(objid) + \" \" +",
                "\t\t     QUtil::int_to_string(generation)));",
                "        return new QPDF_Null;",
                "    }",
                "    ResolveRecorder rr(this, og);",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2016-3754",
        "func_name": "android/main",
        "description": "mediaserver in Android 4.x before 4.4.4, 5.0.x before 5.0.2, 5.1.x before 5.1.1, and 6.x before 2016-07-01 does not limit process-memory usage, which allows remote attackers to cause a denial of service (device hang or reboot) via a crafted media file, aka internal bug 28615448.",
        "git_url": "https://android.googlesource.com/platform/frameworks/av/+/6fdee2a83432b3b150d6a34f231c4e2f7353c01e",
        "commit_title": "limit mediaserver memory",
        "commit_text": " Limit mediaserver using rlimit, to prevent it from bringing down the system via the low memory killer. Default max is 65% of total RAM, but can be customized via system property.  Bug: 28471206 Bug: 28615448 ",
        "func_before": "int main(int argc __unused, char** argv)\n{\n    signal(SIGPIPE, SIG_IGN);\n    char value[PROPERTY_VALUE_MAX];\n    bool doLog = (property_get(\"ro.test_harness\", value, \"0\") > 0) && (atoi(value) == 1);\n    pid_t childPid;\n    // FIXME The advantage of making the process containing media.log service the parent process of\n    // the process that contains all the other real services, is that it allows us to collect more\n    // detailed information such as signal numbers, stop and continue, resource usage, etc.\n    // But it is also more complex.  Consider replacing this by independent processes, and using\n    // binder on death notification instead.\n    if (doLog && (childPid = fork()) != 0) {\n        // media.log service\n        //prctl(PR_SET_NAME, (unsigned long) \"media.log\", 0, 0, 0);\n        // unfortunately ps ignores PR_SET_NAME for the main thread, so use this ugly hack\n        strcpy(argv[0], \"media.log\");\n        sp<ProcessState> proc(ProcessState::self());\n        MediaLogService::instantiate();\n        ProcessState::self()->startThreadPool();\n        for (;;) {\n            siginfo_t info;\n            int ret = waitid(P_PID, childPid, &info, WEXITED | WSTOPPED | WCONTINUED);\n            if (ret == EINTR) {\n                continue;\n            }\n            if (ret < 0) {\n                break;\n            }\n            char buffer[32];\n            const char *code;\n            switch (info.si_code) {\n            case CLD_EXITED:\n                code = \"CLD_EXITED\";\n                break;\n            case CLD_KILLED:\n                code = \"CLD_KILLED\";\n                break;\n            case CLD_DUMPED:\n                code = \"CLD_DUMPED\";\n                break;\n            case CLD_STOPPED:\n                code = \"CLD_STOPPED\";\n                break;\n            case CLD_TRAPPED:\n                code = \"CLD_TRAPPED\";\n                break;\n            case CLD_CONTINUED:\n                code = \"CLD_CONTINUED\";\n                break;\n            default:\n                snprintf(buffer, sizeof(buffer), \"unknown (%d)\", info.si_code);\n                code = buffer;\n                break;\n            }\n            struct rusage usage;\n            getrusage(RUSAGE_CHILDREN, &usage);\n            ALOG(LOG_ERROR, \"media.log\", \"pid %d status %d code %s user %ld.%03lds sys %ld.%03lds\",\n                    info.si_pid, info.si_status, code,\n                    usage.ru_utime.tv_sec, usage.ru_utime.tv_usec / 1000,\n                    usage.ru_stime.tv_sec, usage.ru_stime.tv_usec / 1000);\n            sp<IServiceManager> sm = defaultServiceManager();\n            sp<IBinder> binder = sm->getService(String16(\"media.log\"));\n            if (binder != 0) {\n                Vector<String16> args;\n                binder->dump(-1, args);\n            }\n            switch (info.si_code) {\n            case CLD_EXITED:\n            case CLD_KILLED:\n            case CLD_DUMPED: {\n                ALOG(LOG_INFO, \"media.log\", \"exiting\");\n                _exit(0);\n                // not reached\n                }\n            default:\n                break;\n            }\n        }\n    } else {\n        // all other services\n        if (doLog) {\n            prctl(PR_SET_PDEATHSIG, SIGKILL);   // if parent media.log dies before me, kill me also\n            setpgid(0, 0);                      // but if I die first, don't kill my parent\n        }\n        InitializeIcuOrDie();\n        sp<ProcessState> proc(ProcessState::self());\n        sp<IServiceManager> sm = defaultServiceManager();\n        ALOGI(\"ServiceManager: %p\", sm.get());\n        AudioFlinger::instantiate();\n        MediaPlayerService::instantiate();\n        ResourceManagerService::instantiate();\n        CameraService::instantiate();\n        AudioPolicyService::instantiate();\n        SoundTriggerHwService::instantiate();\n        RadioService::instantiate();\n        registerExtensions();\n        ProcessState::self()->startThreadPool();\n        IPCThreadState::self()->joinThreadPool();\n    }\n}",
        "func": "int main(int argc __unused, char** argv)\n{\n    limitProcessMemory(\n        \"ro.media.maxmem\", /* property that defines limit */\n        SIZE_MAX, /* upper limit in bytes */\n        65 /* upper limit as percentage of physical RAM */);\n\n    signal(SIGPIPE, SIG_IGN);\n    char value[PROPERTY_VALUE_MAX];\n    bool doLog = (property_get(\"ro.test_harness\", value, \"0\") > 0) && (atoi(value) == 1);\n    pid_t childPid;\n    // FIXME The advantage of making the process containing media.log service the parent process of\n    // the process that contains all the other real services, is that it allows us to collect more\n    // detailed information such as signal numbers, stop and continue, resource usage, etc.\n    // But it is also more complex.  Consider replacing this by independent processes, and using\n    // binder on death notification instead.\n    if (doLog && (childPid = fork()) != 0) {\n        // media.log service\n        //prctl(PR_SET_NAME, (unsigned long) \"media.log\", 0, 0, 0);\n        // unfortunately ps ignores PR_SET_NAME for the main thread, so use this ugly hack\n        strcpy(argv[0], \"media.log\");\n        sp<ProcessState> proc(ProcessState::self());\n        MediaLogService::instantiate();\n        ProcessState::self()->startThreadPool();\n        for (;;) {\n            siginfo_t info;\n            int ret = waitid(P_PID, childPid, &info, WEXITED | WSTOPPED | WCONTINUED);\n            if (ret == EINTR) {\n                continue;\n            }\n            if (ret < 0) {\n                break;\n            }\n            char buffer[32];\n            const char *code;\n            switch (info.si_code) {\n            case CLD_EXITED:\n                code = \"CLD_EXITED\";\n                break;\n            case CLD_KILLED:\n                code = \"CLD_KILLED\";\n                break;\n            case CLD_DUMPED:\n                code = \"CLD_DUMPED\";\n                break;\n            case CLD_STOPPED:\n                code = \"CLD_STOPPED\";\n                break;\n            case CLD_TRAPPED:\n                code = \"CLD_TRAPPED\";\n                break;\n            case CLD_CONTINUED:\n                code = \"CLD_CONTINUED\";\n                break;\n            default:\n                snprintf(buffer, sizeof(buffer), \"unknown (%d)\", info.si_code);\n                code = buffer;\n                break;\n            }\n            struct rusage usage;\n            getrusage(RUSAGE_CHILDREN, &usage);\n            ALOG(LOG_ERROR, \"media.log\", \"pid %d status %d code %s user %ld.%03lds sys %ld.%03lds\",\n                    info.si_pid, info.si_status, code,\n                    usage.ru_utime.tv_sec, usage.ru_utime.tv_usec / 1000,\n                    usage.ru_stime.tv_sec, usage.ru_stime.tv_usec / 1000);\n            sp<IServiceManager> sm = defaultServiceManager();\n            sp<IBinder> binder = sm->getService(String16(\"media.log\"));\n            if (binder != 0) {\n                Vector<String16> args;\n                binder->dump(-1, args);\n            }\n            switch (info.si_code) {\n            case CLD_EXITED:\n            case CLD_KILLED:\n            case CLD_DUMPED: {\n                ALOG(LOG_INFO, \"media.log\", \"exiting\");\n                _exit(0);\n                // not reached\n                }\n            default:\n                break;\n            }\n        }\n    } else {\n        // all other services\n        if (doLog) {\n            prctl(PR_SET_PDEATHSIG, SIGKILL);   // if parent media.log dies before me, kill me also\n            setpgid(0, 0);                      // but if I die first, don't kill my parent\n        }\n        InitializeIcuOrDie();\n        sp<ProcessState> proc(ProcessState::self());\n        sp<IServiceManager> sm = defaultServiceManager();\n        ALOGI(\"ServiceManager: %p\", sm.get());\n        AudioFlinger::instantiate();\n        MediaPlayerService::instantiate();\n        ResourceManagerService::instantiate();\n        CameraService::instantiate();\n        AudioPolicyService::instantiate();\n        SoundTriggerHwService::instantiate();\n        RadioService::instantiate();\n        registerExtensions();\n        ProcessState::self()->startThreadPool();\n        IPCThreadState::self()->joinThreadPool();\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,10 @@\n int main(int argc __unused, char** argv)\n {\n+    limitProcessMemory(\n+        \"ro.media.maxmem\", /* property that defines limit */\n+        SIZE_MAX, /* upper limit in bytes */\n+        65 /* upper limit as percentage of physical RAM */);\n+\n     signal(SIGPIPE, SIG_IGN);\n     char value[PROPERTY_VALUE_MAX];\n     bool doLog = (property_get(\"ro.test_harness\", value, \"0\") > 0) && (atoi(value) == 1);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    limitProcessMemory(",
                "        \"ro.media.maxmem\", /* property that defines limit */",
                "        SIZE_MAX, /* upper limit in bytes */",
                "        65 /* upper limit as percentage of physical RAM */);",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2016-3754",
        "func_name": "android/MPEG4Extractor::readMetaData",
        "description": "mediaserver in Android 4.x before 4.4.4, 5.0.x before 5.0.2, 5.1.x before 5.1.1, and 6.x before 2016-07-01 does not limit process-memory usage, which allows remote attackers to cause a denial of service (device hang or reboot) via a crafted media file, aka internal bug 28615448.",
        "git_url": "https://android.googlesource.com/platform/frameworks/av/+/e7142a0703bc93f75e213e96ebc19000022afed9",
        "commit_title": "Check malloc result to avoid NPD",
        "commit_text": " Bug: 28471206 ",
        "func_before": "status_t MPEG4Extractor::readMetaData() {\n    if (mInitCheck != NO_INIT) {\n        return mInitCheck;\n    }\n\n    off64_t offset = 0;\n    status_t err;\n    bool sawMoovOrSidx = false;\n\n    while (!(sawMoovOrSidx && (mMdatFound || mMoofFound))) {\n        off64_t orig_offset = offset;\n        err = parseChunk(&offset, 0);\n\n        if (err != OK && err != UNKNOWN_ERROR) {\n            break;\n        } else if (offset <= orig_offset) {\n            // only continue parsing if the offset was advanced,\n            // otherwise we might end up in an infinite loop\n            ALOGE(\"did not advance: %lld->%lld\", (long long)orig_offset, (long long)offset);\n            err = ERROR_MALFORMED;\n            break;\n        } else if (err == UNKNOWN_ERROR) {\n            sawMoovOrSidx = true;\n        }\n    }\n\n    if (mInitCheck == OK) {\n        if (mHasVideo) {\n            mFileMetaData->setCString(\n                    kKeyMIMEType, MEDIA_MIMETYPE_CONTAINER_MPEG4);\n        } else {\n            mFileMetaData->setCString(kKeyMIMEType, \"audio/mp4\");\n        }\n    } else {\n        mInitCheck = err;\n    }\n\n    CHECK_NE(err, (status_t)NO_INIT);\n\n    // copy pssh data into file metadata\n    uint64_t psshsize = 0;\n    for (size_t i = 0; i < mPssh.size(); i++) {\n        psshsize += 20 + mPssh[i].datalen;\n    }\n    if (psshsize > 0 && psshsize <= UINT32_MAX) {\n        char *buf = (char*)malloc(psshsize);\n        char *ptr = buf;\n        for (size_t i = 0; i < mPssh.size(); i++) {\n            memcpy(ptr, mPssh[i].uuid, 20); // uuid + length\n            memcpy(ptr + 20, mPssh[i].data, mPssh[i].datalen);\n            ptr += (20 + mPssh[i].datalen);\n        }\n        mFileMetaData->setData(kKeyPssh, 'pssh', buf, psshsize);\n        free(buf);\n    }\n    return mInitCheck;\n}",
        "func": "status_t MPEG4Extractor::readMetaData() {\n    if (mInitCheck != NO_INIT) {\n        return mInitCheck;\n    }\n\n    off64_t offset = 0;\n    status_t err;\n    bool sawMoovOrSidx = false;\n\n    while (!(sawMoovOrSidx && (mMdatFound || mMoofFound))) {\n        off64_t orig_offset = offset;\n        err = parseChunk(&offset, 0);\n\n        if (err != OK && err != UNKNOWN_ERROR) {\n            break;\n        } else if (offset <= orig_offset) {\n            // only continue parsing if the offset was advanced,\n            // otherwise we might end up in an infinite loop\n            ALOGE(\"did not advance: %lld->%lld\", (long long)orig_offset, (long long)offset);\n            err = ERROR_MALFORMED;\n            break;\n        } else if (err == UNKNOWN_ERROR) {\n            sawMoovOrSidx = true;\n        }\n    }\n\n    if (mInitCheck == OK) {\n        if (mHasVideo) {\n            mFileMetaData->setCString(\n                    kKeyMIMEType, MEDIA_MIMETYPE_CONTAINER_MPEG4);\n        } else {\n            mFileMetaData->setCString(kKeyMIMEType, \"audio/mp4\");\n        }\n    } else {\n        mInitCheck = err;\n    }\n\n    CHECK_NE(err, (status_t)NO_INIT);\n\n    // copy pssh data into file metadata\n    uint64_t psshsize = 0;\n    for (size_t i = 0; i < mPssh.size(); i++) {\n        psshsize += 20 + mPssh[i].datalen;\n    }\n    if (psshsize > 0 && psshsize <= UINT32_MAX) {\n        char *buf = (char*)malloc(psshsize);\n        if (!buf) {\n            ALOGE(\"b/28471206\");\n            return NO_MEMORY;\n        }\n        char *ptr = buf;\n        for (size_t i = 0; i < mPssh.size(); i++) {\n            memcpy(ptr, mPssh[i].uuid, 20); // uuid + length\n            memcpy(ptr + 20, mPssh[i].data, mPssh[i].datalen);\n            ptr += (20 + mPssh[i].datalen);\n        }\n        mFileMetaData->setData(kKeyPssh, 'pssh', buf, psshsize);\n        free(buf);\n    }\n    return mInitCheck;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -44,6 +44,10 @@\n     }\n     if (psshsize > 0 && psshsize <= UINT32_MAX) {\n         char *buf = (char*)malloc(psshsize);\n+        if (!buf) {\n+            ALOGE(\"b/28471206\");\n+            return NO_MEMORY;\n+        }\n         char *ptr = buf;\n         for (size_t i = 0; i < mPssh.size(); i++) {\n             memcpy(ptr, mPssh[i].uuid, 20); // uuid + length",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "        if (!buf) {",
                "            ALOGE(\"b/28471206\");",
                "            return NO_MEMORY;",
                "        }"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-3765",
        "func_name": "android/impeg2d_bit_stream_flush",
        "description": "decoder/impeg2d_bitstream.c in mediaserver in Android 6.x before 2016-07-01 allows attackers to obtain sensitive information from process memory or cause a denial of service (out-of-bounds read) via a crafted application, aka internal bug 28168413.",
        "git_url": "https://android.googlesource.com/platform/external/libmpeg2/+/d1c775d1d8d2ed117d1e026719b7f9f089716597",
        "commit_title": "Fixed out of bound read in flush_bits",
        "commit_text": " Bug: 28168413 ",
        "func_before": "INLINE void impeg2d_bit_stream_flush(void* pv_ctxt, UWORD32 u4_no_of_bits)\n{\n    stream_t *ps_stream = (stream_t *)pv_ctxt;\n\n\n    if (ps_stream->u4_offset < ps_stream->u4_max_offset)\n    {\n        FLUSH_BITS(ps_stream->u4_offset,ps_stream->u4_buf,ps_stream->u4_buf_nxt,u4_no_of_bits,ps_stream->pu4_buf_aligned)\n    }\n    return;\n}",
        "func": "INLINE void impeg2d_bit_stream_flush(void* pv_ctxt, UWORD32 u4_no_of_bits)\n{\n    stream_t *ps_stream = (stream_t *)pv_ctxt;\n    if ((ps_stream->u4_offset + 64) < ps_stream->u4_max_offset)\n    {\n        FLUSH_BITS(ps_stream->u4_offset,ps_stream->u4_buf,ps_stream->u4_buf_nxt,u4_no_of_bits,ps_stream->pu4_buf_aligned)\n    }\n    else\n    {\n        UWORD32     u4_temp;\n\n        if (((ps_stream->u4_offset & 0x1f) + u4_no_of_bits) >= 32)\n        {\n            ps_stream->u4_buf              = ps_stream->u4_buf_nxt;\n            ps_stream->u4_buf_nxt          = 0;\n        }\n        ps_stream->u4_offset += u4_no_of_bits;\n    }\n    return;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,11 +1,20 @@\n INLINE void impeg2d_bit_stream_flush(void* pv_ctxt, UWORD32 u4_no_of_bits)\n {\n     stream_t *ps_stream = (stream_t *)pv_ctxt;\n-\n-\n-    if (ps_stream->u4_offset < ps_stream->u4_max_offset)\n+    if ((ps_stream->u4_offset + 64) < ps_stream->u4_max_offset)\n     {\n         FLUSH_BITS(ps_stream->u4_offset,ps_stream->u4_buf,ps_stream->u4_buf_nxt,u4_no_of_bits,ps_stream->pu4_buf_aligned)\n     }\n+    else\n+    {\n+        UWORD32     u4_temp;\n+\n+        if (((ps_stream->u4_offset & 0x1f) + u4_no_of_bits) >= 32)\n+        {\n+            ps_stream->u4_buf              = ps_stream->u4_buf_nxt;\n+            ps_stream->u4_buf_nxt          = 0;\n+        }\n+        ps_stream->u4_offset += u4_no_of_bits;\n+    }\n     return;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "",
                "",
                "    if (ps_stream->u4_offset < ps_stream->u4_max_offset)"
            ],
            "added_lines": [
                "    if ((ps_stream->u4_offset + 64) < ps_stream->u4_max_offset)",
                "    else",
                "    {",
                "        UWORD32     u4_temp;",
                "",
                "        if (((ps_stream->u4_offset & 0x1f) + u4_no_of_bits) >= 32)",
                "        {",
                "            ps_stream->u4_buf              = ps_stream->u4_buf_nxt;",
                "            ps_stream->u4_buf_nxt          = 0;",
                "        }",
                "        ps_stream->u4_offset += u4_no_of_bits;",
                "    }"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-6506",
        "func_name": "wireshark/add_headers",
        "description": "epan/dissectors/packet-wsp.c in the WSP dissector in Wireshark 1.12.x before 1.12.13 and 2.x before 2.0.5 allows remote attackers to cause a denial of service (infinite loop) via a crafted packet.",
        "git_url": "https://github.com/wireshark/wireshark/commit/a9d5256890c9189c7461bfce6ed6edce5d861499",
        "commit_title": "packet-wsp.c: Fix infinite loop in add_headers",
        "commit_text": " Bug: 12594",
        "func_before": "static void\nadd_headers (proto_tree *tree, tvbuff_t *tvb, int hf, packet_info *pinfo)\n{\n    guint8      hdr_id, val_id, codepage = 1;\n    gint32      tvb_len                  = tvb_reported_length(tvb);\n    gint32      offset                   = 0;\n    gint32      hdr_len, hdr_start;\n    gint32      val_len, val_start;\n    gchar      *hdr_str, *val_str;\n    proto_tree *wsp_headers;\n    proto_item *ti, *hidden_item;\n    guint8      ok;\n    guint32     val                      = 0;\n\n    if (offset >= tvb_len)\n        return; /* No headers! */\n\n    /* XXX: the field pointed to by hf has a type of FT_NONE */\n    ti = proto_tree_add_item(tree, hf,\n                             tvb, offset, tvb_len, ENC_NA);\n    wsp_headers = proto_item_add_subtree(ti, ett_headers);\n\n    while (offset < tvb_len) {\n        hdr_start = offset;\n        hdr_id = tvb_get_guint8(tvb, offset);\n        if (hdr_id & 0x80) { /* Well-known header */\n            hdr_len = 1;\n            /* Call header value dissector for given header */\n            if (codepage == 1) { /* Default header code page */\n                offset = WellKnownHeader[hdr_id & 0x7F](wsp_headers, tvb,\n                                                        hdr_start, pinfo);\n            } else { /* Openwave header code page */\n                /* Here I'm delibarately assuming that Openwave is the only\n                 * company that defines a WSP header code page. */\n                offset = WellKnownOpenwaveHeader[hdr_id & 0x7F](wsp_headers,\n                                                                tvb, hdr_start, pinfo);\n            }\n        } else if (hdr_id == 0x7F) { /* HCP shift sequence */\n            codepage = tvb_get_guint8(tvb, offset+1);\n            proto_tree_add_uint(wsp_headers, hf_wsp_header_shift_code,\n                                tvb, offset, 2, codepage);\n            offset += 2;\n        } else if (hdr_id >= 0x20) { /* Textual header */\n            /* Header name MUST be NUL-ended string ==> tvb_get_stringz_enc() */\n            hdr_str = (gchar *)tvb_get_stringz_enc(wmem_packet_scope(), tvb, hdr_start, (gint *)&hdr_len, ENC_ASCII);\n            val_start = hdr_start + hdr_len;\n            val_id = tvb_get_guint8(tvb, val_start);\n            /* Call header value dissector for given header */\n            if (val_id >= 0x20 && val_id <=0x7E) { /* OK! */\n                val_str = (gchar *)tvb_get_stringz_enc(wmem_packet_scope(), tvb, val_start, (gint *)&val_len, ENC_ASCII);\n                offset = val_start + val_len;\n                proto_tree_add_string_format(wsp_headers, hf_wsp_header_text_value, tvb, hdr_start, offset-hdr_start,\n                                    val_str, \"%s: %s\", hdr_str, val_str);\n            } else {\n                /* Old-style X-WAP-TOD uses a non-textual value\n                 * after a textual header. */\n                if (g_ascii_strcasecmp(hdr_str, \"x-wap.tod\") == 0) {\n                    get_delta_seconds_value(val, tvb, val_start, val_len, ok);\n                    if (ok) {\n                        nstime_t t;\n                        t.secs = (time_t)val;\n                        t.nsecs = 0;\n                        if (val == 0) {\n                            ti = proto_tree_add_time_format_value(wsp_headers, hf_hdr_x_wap_tod,\n                                                        tvb, hdr_start, hdr_len + val_len, &t,\n                                                        \"Requesting Time Of Day\");\n                        } else {\n                            ti = proto_tree_add_time(wsp_headers, hf_hdr_x_wap_tod,\n                                                        tvb, hdr_start, hdr_len + val_len, &t);\n                        }\n                        expert_add_info(pinfo, ti, &ei_hdr_x_wap_tod);\n                    } else {\n                        /* I prefer using X-Wap-Tod to the real hdr_str */\n                        proto_tree_add_expert_format(wsp_headers, pinfo, &ei_wsp_text_field_invalid,\n                                               tvb, hdr_start, hdr_len + val_len,\n                                               \"Invalid value for the 'X-Wap-Tod' header\");\n\n                    }\n                } else {\n                    proto_tree_add_expert_format(wsp_headers, pinfo, &ei_wsp_text_field_invalid, tvb, hdr_start, hdr_len,\n                                         \"Invalid value for the textual '%s' header (should be a textual value)\",\n                                         hdr_str);\n                }\n                offset = tvb_len;\n            }\n            hidden_item = proto_tree_add_string(wsp_headers, hf_hdr_name_string,\n                                                tvb, hdr_start, offset - hdr_start, hdr_str);\n            PROTO_ITEM_SET_HIDDEN(hidden_item);\n        } else if (hdr_id > 0) { /* Shorthand HCP switch */\n            codepage = hdr_id;\n            proto_tree_add_uint (wsp_headers, hf_wsp_header_shift_code,\n                                 tvb, offset, 1, codepage);\n            offset++;\n        } else {\n            proto_tree_add_expert_format (wsp_headers, pinfo, &ei_wsp_text_field_invalid, tvb, hdr_start, 1,\n                                 \"Invalid zero-length textual header\");\n\n            offset = tvb_len;\n        }\n    }\n}",
        "func": "static void\nadd_headers (proto_tree *tree, tvbuff_t *tvb, int hf, packet_info *pinfo)\n{\n    guint8      hdr_id, val_id, codepage = 1;\n    gint32      tvb_len                  = tvb_reported_length(tvb);\n    gint32      offset                   = 0;\n    gint32      save_offset;\n    gint32      hdr_len, hdr_start;\n    gint32      val_len, val_start;\n    gchar      *hdr_str, *val_str;\n    proto_tree *wsp_headers;\n    proto_item *ti, *hidden_item;\n    guint8      ok;\n    guint32     val                      = 0;\n\n    if (offset >= tvb_len)\n        return; /* No headers! */\n\n    /* XXX: the field pointed to by hf has a type of FT_NONE */\n    ti = proto_tree_add_item(tree, hf,\n                             tvb, offset, tvb_len, ENC_NA);\n    wsp_headers = proto_item_add_subtree(ti, ett_headers);\n\n    while (offset < tvb_len) {\n        hdr_start = offset;\n        hdr_id = tvb_get_guint8(tvb, offset);\n        if (hdr_id & 0x80) { /* Well-known header */\n            hdr_len = 1;\n            /* Call header value dissector for given header */\n            if (codepage == 1) { /* Default header code page */\n                save_offset = offset;\n                offset = WellKnownHeader[hdr_id & 0x7F](wsp_headers, tvb,\n                                                        hdr_start, pinfo);\n                /* Make sure we're progressing forward */\n                if (save_offset <= offset) {\n                    expert_add_info(pinfo, ti, &ei_wsp_header_invalid);\n                    break;\n                }\n            } else { /* Openwave header code page */\n                /* Here I'm delibarately assuming that Openwave is the only\n                 * company that defines a WSP header code page. */\n                save_offset = offset;\n                offset = WellKnownOpenwaveHeader[hdr_id & 0x7F](wsp_headers,\n                                                                tvb, hdr_start, pinfo);\n                /* Make sure we're progressing forward */\n                if (save_offset <= offset) {\n                    expert_add_info(pinfo, ti, &ei_wsp_header_invalid);\n                    break;\n                }\n            }\n        } else if (hdr_id == 0x7F) { /* HCP shift sequence */\n            codepage = tvb_get_guint8(tvb, offset+1);\n            proto_tree_add_uint(wsp_headers, hf_wsp_header_shift_code,\n                                tvb, offset, 2, codepage);\n            offset += 2;\n        } else if (hdr_id >= 0x20) { /* Textual header */\n            /* Header name MUST be NUL-ended string ==> tvb_get_stringz_enc() */\n            hdr_str = (gchar *)tvb_get_stringz_enc(wmem_packet_scope(), tvb, hdr_start, (gint *)&hdr_len, ENC_ASCII);\n            val_start = hdr_start + hdr_len;\n            val_id = tvb_get_guint8(tvb, val_start);\n            /* Call header value dissector for given header */\n            if (val_id >= 0x20 && val_id <=0x7E) { /* OK! */\n                val_str = (gchar *)tvb_get_stringz_enc(wmem_packet_scope(), tvb, val_start, (gint *)&val_len, ENC_ASCII);\n                offset = val_start + val_len;\n                proto_tree_add_string_format(wsp_headers, hf_wsp_header_text_value, tvb, hdr_start, offset-hdr_start,\n                                    val_str, \"%s: %s\", hdr_str, val_str);\n            } else {\n                /* Old-style X-WAP-TOD uses a non-textual value\n                 * after a textual header. */\n                if (g_ascii_strcasecmp(hdr_str, \"x-wap.tod\") == 0) {\n                    get_delta_seconds_value(val, tvb, val_start, val_len, ok);\n                    if (ok) {\n                        nstime_t t;\n                        t.secs = (time_t)val;\n                        t.nsecs = 0;\n                        if (val == 0) {\n                            ti = proto_tree_add_time_format_value(wsp_headers, hf_hdr_x_wap_tod,\n                                                        tvb, hdr_start, hdr_len + val_len, &t,\n                                                        \"Requesting Time Of Day\");\n                        } else {\n                            ti = proto_tree_add_time(wsp_headers, hf_hdr_x_wap_tod,\n                                                        tvb, hdr_start, hdr_len + val_len, &t);\n                        }\n                        expert_add_info(pinfo, ti, &ei_hdr_x_wap_tod);\n                    } else {\n                        /* I prefer using X-Wap-Tod to the real hdr_str */\n                        proto_tree_add_expert_format(wsp_headers, pinfo, &ei_wsp_text_field_invalid,\n                                               tvb, hdr_start, hdr_len + val_len,\n                                               \"Invalid value for the 'X-Wap-Tod' header\");\n\n                    }\n                } else {\n                    proto_tree_add_expert_format(wsp_headers, pinfo, &ei_wsp_text_field_invalid, tvb, hdr_start, hdr_len,\n                                         \"Invalid value for the textual '%s' header (should be a textual value)\",\n                                         hdr_str);\n                }\n                offset = tvb_len;\n            }\n            hidden_item = proto_tree_add_string(wsp_headers, hf_hdr_name_string,\n                                                tvb, hdr_start, offset - hdr_start, hdr_str);\n            PROTO_ITEM_SET_HIDDEN(hidden_item);\n        } else if (hdr_id > 0) { /* Shorthand HCP switch */\n            codepage = hdr_id;\n            proto_tree_add_uint (wsp_headers, hf_wsp_header_shift_code,\n                                 tvb, offset, 1, codepage);\n            offset++;\n        } else {\n            proto_tree_add_expert_format (wsp_headers, pinfo, &ei_wsp_text_field_invalid, tvb, hdr_start, 1,\n                                 \"Invalid zero-length textual header\");\n\n            offset = tvb_len;\n        }\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,6 +4,7 @@\n     guint8      hdr_id, val_id, codepage = 1;\n     gint32      tvb_len                  = tvb_reported_length(tvb);\n     gint32      offset                   = 0;\n+    gint32      save_offset;\n     gint32      hdr_len, hdr_start;\n     gint32      val_len, val_start;\n     gchar      *hdr_str, *val_str;\n@@ -27,13 +28,25 @@\n             hdr_len = 1;\n             /* Call header value dissector for given header */\n             if (codepage == 1) { /* Default header code page */\n+                save_offset = offset;\n                 offset = WellKnownHeader[hdr_id & 0x7F](wsp_headers, tvb,\n                                                         hdr_start, pinfo);\n+                /* Make sure we're progressing forward */\n+                if (save_offset <= offset) {\n+                    expert_add_info(pinfo, ti, &ei_wsp_header_invalid);\n+                    break;\n+                }\n             } else { /* Openwave header code page */\n                 /* Here I'm delibarately assuming that Openwave is the only\n                  * company that defines a WSP header code page. */\n+                save_offset = offset;\n                 offset = WellKnownOpenwaveHeader[hdr_id & 0x7F](wsp_headers,\n                                                                 tvb, hdr_start, pinfo);\n+                /* Make sure we're progressing forward */\n+                if (save_offset <= offset) {\n+                    expert_add_info(pinfo, ti, &ei_wsp_header_invalid);\n+                    break;\n+                }\n             }\n         } else if (hdr_id == 0x7F) { /* HCP shift sequence */\n             codepage = tvb_get_guint8(tvb, offset+1);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    gint32      save_offset;",
                "                save_offset = offset;",
                "                /* Make sure we're progressing forward */",
                "                if (save_offset <= offset) {",
                "                    expert_add_info(pinfo, ti, &ei_wsp_header_invalid);",
                "                    break;",
                "                }",
                "                save_offset = offset;",
                "                /* Make sure we're progressing forward */",
                "                if (save_offset <= offset) {",
                "                    expert_add_info(pinfo, ti, &ei_wsp_header_invalid);",
                "                    break;",
                "                }"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-6507",
        "func_name": "wireshark/dissect_mmse",
        "description": "epan/dissectors/packet-mmse.c in the MMSE dissector in Wireshark 1.12.x before 1.12.13 allows remote attackers to cause a denial of service (infinite loop) via a crafted packet.",
        "git_url": "https://github.com/wireshark/wireshark/commit/b5a10743258bd016c07ebf6479137fda3d172a0f",
        "commit_title": "MMSE: remove proto_tree_add_text calls",
        "commit_text": " Backport changes done previously in master-2.0 branch  Bug: 12624",
        "func_before": "static void\ndissect_mmse(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree, guint8 pdut,\n\tconst char *message_type)\n{\n    guint\t offset;\n    guint8\t field = 0;\n    const char\t *strval;\n    guint\t length;\n    guint\t count;\n    guint8\t version = 0x80; /* Default to MMSE 1.0 */\n\n    /* Set up structures needed to add the protocol subtree and manage it */\n    proto_item\t*ti = NULL;\n    proto_tree\t*mmse_tree = NULL;\n\n    DebugLog((\"dissect_mmse() - START (Packet %u)\\n\", pinfo->fd->num));\n\n    /* If tree == NULL then we are only interested in protocol dissection\n     * up to reassembly and handoff to subdissectors if applicable; the\n     * columns must be set appropriately too.\n     * If tree != NULL then we also want to display the protocol tree\n     * with its fields.\n     *\n     * In the interest of speed, skip protocol tree item generation\n     * if tree is NULL.\n     */\n    if (tree) {\n\tDebugLog((\"tree != NULL\\n\"));\n\n\tti = proto_tree_add_item(tree, proto_mmse, tvb, 0, -1, ENC_NA);\n\tproto_item_append_text(ti, \", Type: %s\", message_type);\n\t/* create display subtree for the protocol */\n\tmmse_tree = proto_item_add_subtree(ti, ett_mmse);\n\n\t/* Report PDU-type\t*/\n\tproto_tree_add_uint(mmse_tree, hf_mmse_message_type, tvb, 0, 2, pdut);\n    }\n\n    offset = 2;\t\t\t/* Skip Message-Type\t*/\n\n    /*\n     * Cycle through MMS-headers\n     *\n     * NOTE - some PDUs may convey content which can be handed off\n     *        to subdissectors.\n     */\n    if (tree || pdu_has_content(pdut)) {\n\twhile ((offset < tvb_reported_length(tvb)) &&\n\t       (field = tvb_get_guint8(tvb, offset++)) != MM_CTYPE_HDR)\n\t{\n\t    DebugLog((\"\\tField =  0x%02X (offset = %u): %s\\n\",\n\t\t\tfield, offset,\n\t\t\tval_to_str(field, vals_mm_header_names,\n\t\t\t    \"Unknown MMS header 0x%02X\")));\n\t    switch (field)\n\t    {\n\t\tcase MM_TID_HDR:\t\t/* Text-string\t*/\n\t\t    length = get_text_string(tvb, offset, &strval);\n\t\t    if (tree) {\n\t\t\tproto_tree_add_string(mmse_tree, hf_mmse_transaction_id,\n\t\t\t\ttvb, offset - 1, length + 1,strval);\n\t\t    }\n\t\t    offset += length;\n\t\t    break;\n\t\tcase MM_VERSION_HDR:\t\t/* nibble-Major/nibble-minor*/\n\t\t    version = tvb_get_guint8(tvb, offset++);\n\t\t    if (tree) {\n\t\t\tguint8\t major, minor;\n\t\t\tchar    *vers_string;\n\n\t\t\tmajor = (version & 0x70) >> 4;\n\t\t\tminor = version & 0x0F;\n\t\t\tif (minor == 0x0F)\n\t\t\t    vers_string = wmem_strdup_printf(wmem_packet_scope(), \"%u\", major);\n\t\t\telse\n\t\t\t    vers_string = wmem_strdup_printf(wmem_packet_scope(), \"%u.%u\", major, minor);\n\t\t\tproto_tree_add_string(mmse_tree, hf_mmse_mms_version,\n\t\t\t\ttvb, offset - 2, 2, vers_string);\n\t\t    }\n\t\t    break;\n\t\tcase MM_BCC_HDR:\t\t/* Encoded-string-value\t*/\n\t\t    length = get_encoded_strval(tvb, offset, &strval);\n\t\t    if (tree) {\n\t\t\tproto_tree_add_string(mmse_tree, hf_mmse_bcc, tvb,\n\t\t\t\toffset - 1, length + 1, strval);\n\t\t    }\n\t\t    offset += length;\n\t\t    break;\n\t\tcase MM_CC_HDR:\t\t\t/* Encoded-string-value\t*/\n\t\t    length = get_encoded_strval(tvb, offset, &strval);\n\t\t    if (tree) {\n\t\t\tproto_tree_add_string(mmse_tree, hf_mmse_cc, tvb,\n\t\t\t\toffset - 1, length + 1, strval);\n\t\t    }\n\t\t    offset += length;\n\t\t    break;\n\t\tcase MM_CLOCATION_HDR:\t\t/* Uri-value\t\t*/\n\t\t    if (pdut == PDU_M_MBOX_DELETE_CONF) {\n\t\t\t/* General form with length */\n\t\t\tlength = tvb_get_guint8(tvb, offset);\n\t\t\tif (length == 0x1F) {\n\t\t\t    guint length_len = 0;\n\t\t\t    length = tvb_get_guintvar(tvb, offset + 1,\n\t\t\t\t    &length_len);\n\t\t\t    length += 1 + length_len;\n\t\t\t} else {\n\t\t\t    length += 1;\n\t\t\t}\n\t\t\tif (tree) {\n\t\t\t    tvb_ensure_bytes_exist(tvb, offset - 1, length + 1);\n\t\t\t    proto_tree_add_string(mmse_tree,\n\t\t\t\t    hf_mmse_content_location,\n\t\t\t\t    tvb, offset - 1, length + 1,\n\t\t\t\t    \"<Undecoded value for m-mbox-delete-conf>\");\n\t\t\t}\n\t\t    } else {\n\t\t\tlength = get_text_string(tvb, offset, &strval);\n\t\t\tif (tree) {\n\t\t\t    proto_tree_add_string(mmse_tree,\n\t\t\t\t    hf_mmse_content_location,\n\t\t\t\t    tvb, offset - 1, length + 1, strval);\n\t\t\t}\n\t\t    }\n\t\t    offset += length;\n\t\t    break;\n\t\tcase MM_DATE_HDR:\t\t/* Long-integer\t\t*/\n\t\t    {\n\t\t\tguint\t\t tval;\n\t\t\tnstime_t\t tmptime;\n\n\t\t\ttval = get_long_integer(tvb, offset, &count);\n\t\t\ttmptime.secs = tval;\n\t\t\ttmptime.nsecs = 0;\n\t\t\tif (tree) {\n\t\t\t    tvb_ensure_bytes_exist(tvb, offset - 1, count + 1);\n\t\t\t    proto_tree_add_time(mmse_tree, hf_mmse_date, tvb,\n\t\t\t\t    offset - 1, count + 1, &tmptime);\n\t\t\t}\n\t\t    }\n\t\t    offset += count;\n\t\t    break;\n\t\tcase MM_DREPORT_HDR:\t\t/* Yes|No\t\t*/\n\t\t    field = tvb_get_guint8(tvb, offset++);\n\t\t    if (tree) {\n\t\t\tproto_tree_add_uint(mmse_tree,\n\t\t\t\thf_mmse_delivery_report,\n\t\t\t\ttvb, offset - 2, 2, field);\n\t\t    }\n\t\t    break;\n\t\tcase MM_DTIME_HDR:\n\t\t    /*\n\t\t     * Value-length(Absolute-token Date-value|\n\t\t     * \t\t    Relative-token Delta-seconds-value)\n\t\t     */\n\t\t    length = get_value_length(tvb, offset, &count);\n\t\t    field = tvb_get_guint8(tvb, offset + count);\n\t\t    if (tree) {\n\t\t\tguint\t\t tval;\n\t\t\tnstime_t\t tmptime;\n\t\t\tguint\t\t cnt;\n\n\t\t\ttval =  get_long_integer(tvb, offset + count + 1, &cnt);\n\t\t\ttmptime.secs = tval;\n\t\t\ttmptime.nsecs = 0;\n\n\t\t\ttvb_ensure_bytes_exist(tvb, offset - 1, length + count + 1);\n\t\t\tif (field == 0x80)\n\t\t\t    proto_tree_add_time(mmse_tree,\n\t\t\t\t    hf_mmse_delivery_time_abs,\n\t\t\t\t    tvb, offset - 1,\n\t\t\t\t    length + count + 1, &tmptime);\n\t\t\telse\n\t\t\t    proto_tree_add_time(mmse_tree,\n\t\t\t\t    hf_mmse_delivery_time_rel,\n\t\t\t\t    tvb, offset - 1,\n\t\t\t\t    length + count + 1, &tmptime);\n\t\t    }\n\t\t    offset += length + count;\n\t\t    break;\n\t\tcase MM_EXPIRY_HDR:\n\t\t    /*\n\t\t     * Value-length(Absolute-token Date-value|\n\t\t     * \t\t    Relative-token Delta-seconds-value)\n\t\t     */\n\t\t    length = get_value_length(tvb, offset, &count);\n\t\t    field = tvb_get_guint8(tvb, offset + count);\n\t\t    if (tree) {\n\t\t\tguint\t\t tval;\n\t\t\tnstime_t\t tmptime;\n\t\t\tguint\t\t cnt;\n\n\t\t\ttval = get_long_integer(tvb, offset + count + 1, &cnt);\n\t\t\ttmptime.secs = tval;\n\t\t\ttmptime.nsecs = 0;\n\n\t\t\ttvb_ensure_bytes_exist(tvb, offset - 1, length + count + 1);\n\t\t\tif (field == 0x80)\n\t\t\t    proto_tree_add_time(mmse_tree, hf_mmse_expiry_abs,\n\t\t\t\t    tvb, offset - 1,\n\t\t\t\t    length + count + 1, &tmptime);\n\t\t\telse\n\t\t\t    proto_tree_add_time(mmse_tree, hf_mmse_expiry_rel,\n\t\t\t\t    tvb, offset - 1,\n\t\t\t\t    length + count + 1, &tmptime);\n\t\t    }\n\t\t    offset += length + count;\n\t\t    break;\n\t\tcase MM_FROM_HDR:\n\t\t    /*\n\t\t     * Value-length(Address-present-token Encoded-string-value\n\t\t     * \t\t    |Insert-address-token)\n\t\t     */\n\t\t    length = get_value_length(tvb, offset, &count);\n\t\t    if (tree) {\n\t\t\tfield = tvb_get_guint8(tvb, offset + count);\n\t\t\ttvb_ensure_bytes_exist(tvb, offset - 1, length + count + 1);\n\t\t\tif (field == 0x81) {\n\t\t\t    proto_tree_add_string(mmse_tree, hf_mmse_from, tvb,\n\t\t\t\t    offset-1, length + count + 1,\n\t\t\t\t    \"<insert address>\");\n\t\t\t} else {\n\t\t\t    (void) get_encoded_strval(tvb, offset + count + 1,\n\t\t\t\t\t\t      &strval);\n\t\t\t    proto_tree_add_string(mmse_tree, hf_mmse_from, tvb,\n\t\t\t\t    offset-1, length + count + 1, strval);\n\t\t\t}\n\t\t    }\n\t\t    offset += length + count;\n\t\t    break;\n\t\tcase MM_MCLASS_HDR:\n\t\t    /*\n\t\t     * Class-identifier|Text-string\n\t\t     */\n\t\t    field = tvb_get_guint8(tvb, offset);\n\t\t    if (field & 0x80) {\n\t\t\toffset++;\n\t\t\tif (tree) {\n\t\t\t    proto_tree_add_uint(mmse_tree,\n\t\t\t\t    hf_mmse_message_class_id,\n\t\t\t\t    tvb, offset - 2, 2, field);\n\t\t\t}\n\t\t    } else {\n\t\t\tlength = get_text_string(tvb, offset, &strval);\n\t\t\tif (tree) {\n\t\t\t    proto_tree_add_string(mmse_tree,\n\t\t\t\t    hf_mmse_message_class_str,\n\t\t\t\t    tvb, offset - 1, length + 1,\n\t\t\t\t    strval);\n\t\t\t}\n\t\t\toffset += length;\n\t\t    }\n\t\t    break;\n\t\tcase MM_MID_HDR:\t\t/* Text-string\t\t*/\n\t\t    length = get_text_string(tvb, offset, &strval);\n\t\t    if (tree) {\n\t\t\tproto_tree_add_string(mmse_tree, hf_mmse_message_id,\n\t\t\t\ttvb, offset - 1, length + 1, strval);\n\t\t    }\n\t\t    offset += length;\n\t\t    break;\n\t\tcase MM_MSIZE_HDR:\t\t/* Long-integer\t\t*/\n\t\t    length = get_long_integer(tvb, offset, &count);\n\t\t    if (tree) {\n\t\t\tproto_tree_add_uint(mmse_tree, hf_mmse_message_size,\n\t\t\t\ttvb, offset - 1, count + 1, length);\n\t\t    }\n\t\t    offset += count;\n\t\t    break;\n\t\tcase MM_PRIORITY_HDR:\t\t/* Low|Normal|High\t*/\n\t\t    field = tvb_get_guint8(tvb, offset++);\n\t\t    if (tree) {\n\t\t\tproto_tree_add_uint(mmse_tree, hf_mmse_priority, tvb,\n\t\t\t\toffset - 2, 2, field);\n\t\t    }\n\t\t    break;\n\t\tcase MM_RREPLY_HDR:\t\t/* Yes|No\t\t*/\n\t\t    field = tvb_get_guint8(tvb, offset++);\n\t\t    if (tree) {\n\t\t\tif (version == 0x80) { /* MMSE 1.0 */\n\t\t\t    proto_tree_add_uint(mmse_tree, hf_mmse_read_reply,\n\t\t\t\t    tvb, offset - 2, 2, field);\n\t\t\t} else {\n\t\t\t    proto_tree_add_uint(mmse_tree, hf_mmse_read_report,\n\t\t\t\t    tvb, offset - 2, 2, field);\n\t\t\t}\n\t\t    }\n\t\t    break;\n\t\tcase MM_RALLOWED_HDR:\t\t/* Yes|No\t\t*/\n\t\t    field = tvb_get_guint8(tvb, offset++);\n\t\t    if (tree) {\n\t\t\tproto_tree_add_uint(mmse_tree, hf_mmse_report_allowed,\n\t\t\t\ttvb, offset - 2, 2, field);\n\t\t    }\n\t\t    break;\n\t\tcase MM_RSTATUS_HDR:\n\t\t    field = tvb_get_guint8(tvb, offset++);\n\t\t    if (tree) {\n\t\t\tproto_tree_add_uint(mmse_tree, hf_mmse_response_status,\n\t\t\t\ttvb, offset - 2, 2, field);\n\t\t    }\n\t\t    break;\n\t\tcase MM_RTEXT_HDR:\t\t/* Encoded-string-value\t*/\n\t\t    if (pdut == PDU_M_MBOX_DELETE_CONF) {\n\t\t\t/* General form with length */\n\t\t\tlength = tvb_get_guint8(tvb, offset);\n\t\t\tif (length == 0x1F) {\n\t\t\t    guint length_len = 0;\n\t\t\t    length = tvb_get_guintvar(tvb, offset + 1,\n\t\t\t\t    &length_len);\n\t\t\t    length += 1 + length_len;\n\t\t\t} else {\n\t\t\t    length += 1;\n\t\t\t}\n\t\t\tif (tree) {\n\t\t\t    proto_tree_add_string(mmse_tree,\n\t\t\t\t    hf_mmse_content_location,\n\t\t\t\t    tvb, offset - 1, length + 1,\n\t\t\t\t    \"<Undecoded value for m-mbox-delete-conf>\");\n\t\t\t}\n\t\t    } else {\n    \t\t\tlength = get_encoded_strval(tvb, offset, &strval);\n\t\t\tif (tree) {\n\t\t\t    proto_tree_add_string(mmse_tree,\n\t\t\t\t    hf_mmse_response_text, tvb, offset - 1,\n\t\t\t\t    length + 1, strval);\n\t\t\t}\n\t\t    }\n\t\t    offset += length;\n\t\t    break;\n\t\tcase MM_SVISIBILITY_HDR:\t/* Hide|Show\t\t*/\n\t\t    field = tvb_get_guint8(tvb, offset++);\n\t\t    if (tree) {\n\t\t\tproto_tree_add_uint(mmse_tree,hf_mmse_sender_visibility,\n\t\t\t\ttvb, offset - 2, 2, field);\n\t\t    }\n\t\t    break;\n\t\tcase MM_STATUS_HDR:\n\t\t    field = tvb_get_guint8(tvb, offset++);\n\t\t    if (tree) {\n\t\t\tproto_tree_add_uint(mmse_tree, hf_mmse_status, tvb,\n\t\t\t\toffset - 2, 2, field);\n\t\t    }\n\t\t    break;\n\t\tcase MM_SUBJECT_HDR:\t\t/* Encoded-string-value\t*/\n\t\t    length = get_encoded_strval(tvb, offset, &strval);\n\t\t    if (tree) {\n\t\t\tproto_tree_add_string(mmse_tree, hf_mmse_subject, tvb,\n\t\t\t\toffset - 1, length + 1, strval);\n\t\t    }\n\t\t    offset += length;\n\t\t    break;\n\t\tcase MM_TO_HDR:\t\t\t/* Encoded-string-value\t*/\n\t\t    length = get_encoded_strval(tvb, offset, &strval);\n\t\t    if (tree) {\n\t\t\tproto_tree_add_string(mmse_tree, hf_mmse_to, tvb,\n\t\t\t\toffset - 1, length + 1, strval);\n\t\t    }\n\t\t    offset += length;\n\t\t    break;\n\n\t\t/*\n\t\t * MMS Encapsulation 1.1\n\t\t */\n\t\tcase MM_RETRIEVE_STATUS_HDR:\t/* Well-known-value */\n\t\t    field = tvb_get_guint8(tvb, offset++);\n\t\t    if (tree) {\n\t\t\tproto_tree_add_uint(mmse_tree, hf_mmse_retrieve_status,\n\t\t\t\ttvb, offset - 2, 2, field);\n\t\t    }\n\t\t    break;\n\t\tcase MM_RETRIEVE_TEXT_HDR:\n\t\t    if (pdut == PDU_M_MBOX_DELETE_CONF) {\n\t\t\t/* General form with length */\n\t\t\tlength = tvb_get_guint8(tvb, offset);\n\t\t\tif (length == 0x1F) {\n\t\t\t    guint length_len = 0;\n\t\t\t    length = tvb_get_guintvar(tvb, offset + 1,\n\t\t\t\t    &length_len);\n\t\t\t    length += 1 + length_len;\n\t\t\t} else {\n\t\t\t    length += 1;\n\t\t\t}\n\t\t\tif (tree) {\n\t\t\t    proto_tree_add_string(mmse_tree,\n\t\t\t\t    hf_mmse_content_location,\n\t\t\t\t    tvb, offset - 1, length + 1,\n\t\t\t\t    \"<Undecoded value for m-mbox-delete-conf>\");\n\t\t\t}\n\t\t    } else {\n\t\t\t/* Encoded-string-value */\n\t\t\tlength = get_encoded_strval(tvb, offset, &strval);\n\t\t\tif (tree) {\n\t\t\t    proto_tree_add_string(mmse_tree,\n\t\t\t\t    hf_mmse_retrieve_text, tvb, offset - 1,\n\t\t\t\t    length + 1, strval);\n\t\t\t}\n\t\t    }\n\t\t    offset += length;\n\t\t    break;\n\t\tcase MM_READ_STATUS_HDR:\t/* Well-known-value */\n\t\t    field = tvb_get_guint8(tvb, offset++);\n\t\t    if (tree) {\n\t\t\tproto_tree_add_uint(mmse_tree, hf_mmse_read_status,\n\t\t\t\ttvb, offset - 2, 2, field);\n\t\t    }\n\t\t    break;\n\t\tcase MM_REPLY_CHARGING_HDR:\t/* Well-known-value */\n\t\t    field = tvb_get_guint8(tvb, offset++);\n\t\t    if (tree) {\n\t\t\tproto_tree_add_uint(mmse_tree, hf_mmse_reply_charging,\n\t\t\t\ttvb, offset - 2, 2, field);\n\t\t    }\n\t\t    break;\n\t\tcase MM_REPLY_CHARGING_DEADLINE_HDR:\t/* Well-known-value */\n\t\t    /*\n\t\t     * Value-length(Absolute-token Date-value|\n\t\t     * \t\t    Relative-token Delta-seconds-value)\n\t\t     */\n\t\t    length = get_value_length(tvb, offset, &count);\n\t\t    field = tvb_get_guint8(tvb, offset + count);\n\t\t    if (tree) {\n\t\t\tguint\t\t tval;\n\t\t\tnstime_t\t tmptime;\n\t\t\tguint\t\t cnt;\n\n\t\t\ttval = get_long_integer(tvb, offset + count + 1, &cnt);\n\t\t\ttmptime.secs = tval;\n\t\t\ttmptime.nsecs = 0;\n\n\t\t\ttvb_ensure_bytes_exist(tvb, offset - 1, length + count + 1);\n\t\t\tif (field == 0x80)\n\t\t\t    proto_tree_add_time(mmse_tree, hf_mmse_reply_charging_deadline_abs,\n\t\t\t\t    tvb, offset - 1,\n\t\t\t\t    length + count + 1, &tmptime);\n\t\t\telse\n\t\t\t    proto_tree_add_time(mmse_tree, hf_mmse_reply_charging_deadline_rel,\n\t\t\t\t    tvb, offset - 1,\n\t\t\t\t    length + count + 1, &tmptime);\n\t\t    }\n\t\t    offset += length + count;\n\t\t    break;\n\t\tcase MM_REPLY_CHARGING_ID_HDR:\t/* Text-string */\n\t\t    length = get_text_string(tvb, offset, &strval);\n\t\t    if (tree) {\n\t\t\tproto_tree_add_string(mmse_tree,\n\t\t\t\thf_mmse_reply_charging_id,\n\t\t\t\ttvb, offset - 1, length + 1, strval);\n\t\t    }\n\t\t    offset += length;\n\t\t    break;\n\t\tcase MM_REPLY_CHARGING_SIZE_HDR:\t/* Long-integer */\n\t\t    length = get_long_integer(tvb, offset, &count);\n\t\t    if (tree) {\n\t\t\tproto_tree_add_uint(mmse_tree,\n\t\t\t\thf_mmse_reply_charging_size,\n\t\t\t\ttvb, offset - 1, count + 1, length);\n\t\t    }\n\t\t    offset += count;\n\t\t    break;\n\t\tcase MM_PREV_SENT_BY_HDR:\n\t\t    /* Value-length Integer-value Encoded-string-value */\n\t\t    length = get_value_length(tvb, offset, &count);\n\t\t    if (tree) {\n\t\t\tguint32 fwd_count, count1, count2;\n\t\t\tproto_tree *subtree = NULL;\n\t\t\tproto_item *tii = NULL;\n\t\t\t/* 1. Forwarded-count-value := Integer-value */\n\t\t\tfwd_count = get_integer_value(tvb, offset + count,\n\t\t\t    &count1);\n\t\t\t/* 2. Encoded-string-value */\n\t\t\tcount2 = get_encoded_strval(tvb,\n\t\t\t\toffset + count + count1, &strval);\n\t\t\t/* Now render the fields */\n\t\t\ttii = proto_tree_add_string_format(mmse_tree,\n\t\t\t\thf_mmse_prev_sent_by,\n\t\t\t\ttvb, offset - 1, 1 + count + length,\n\t\t\t\tstrval, \"%s (Forwarded-count=%u)\",\n\t\t\t\tformat_text(strval, strlen(strval)),\n\t\t\t\tfwd_count);\n\t\t\tsubtree = proto_item_add_subtree(tii,\n\t\t\t\tett_mmse_hdr_details);\n\t\t\tproto_tree_add_uint(subtree,\n\t\t\t\thf_mmse_prev_sent_by_fwd_count,\n\t\t\t\ttvb, offset + count, count1, fwd_count);\n\t\t\tproto_tree_add_string(subtree,\n\t\t\t\thf_mmse_prev_sent_by_address,\n\t\t\t\ttvb, offset + count + count1, count2, strval);\n\t\t    }\n\t\t    offset += length + count;\n\t\t    break;\n\t\tcase MM_PREV_SENT_DATE_HDR:\n\t\t    /* Value-Length Forwarded-count-value Date-value */\n\t\t    length = get_value_length(tvb, offset, &count);\n\t\t    if (tree) {\n\t\t\tguint32 fwd_count, count1, count2;\n\t\t\tguint\t\t tval;\n\t\t\tnstime_t\t tmptime;\n\t\t\tproto_tree *subtree = NULL;\n\t\t\tproto_item *tii = NULL;\n\t\t\t/* 1. Forwarded-count-value := Integer-value */\n\t\t\tfwd_count = get_integer_value(tvb, offset + count,\n\t\t\t    &count1);\n\t\t\t/* 2. Date-value := Long-integer */\n\t\t\ttval = get_long_integer(tvb, offset + count + count1,\n\t\t\t\t&count2);\n\t\t\ttmptime.secs = tval;\n\t\t\ttmptime.nsecs = 0;\n\t\t\tstrval = abs_time_to_ep_str(&tmptime, ABSOLUTE_TIME_LOCAL,\n\t\t\t    TRUE);\n\t\t\t/* Now render the fields */\n\t\t\ttvb_ensure_bytes_exist(tvb, offset - 1, length + count + 1);\n\t\t\ttii = proto_tree_add_string_format(mmse_tree,\n\t\t\t\thf_mmse_prev_sent_date,\n\t\t\t\ttvb, offset - 1, 1 + count + length,\n\t\t\t\tstrval, \"%s (Forwarded-count=%u)\",\n\t\t\t\tformat_text(strval, strlen(strval)),\n\t\t\t\tfwd_count);\n\t\t\tsubtree = proto_item_add_subtree(tii,\n\t\t\t\tett_mmse_hdr_details);\n\t\t\tproto_tree_add_uint(subtree,\n\t\t\t\thf_mmse_prev_sent_date_fwd_count,\n\t\t\t\ttvb, offset + count, count1, fwd_count);\n\t\t\tproto_tree_add_string(subtree,\n\t\t\t\thf_mmse_prev_sent_date_date,\n\t\t\t\ttvb, offset + count + count1, count2, strval);\n\t\t    }\n\t\t    offset += length + count;\n\t\t    break;\n\n\t\t/* MMS Encapsulation 1.2 */\n\n\t\tdefault:\n\t\t    if (field & 0x80) { /* Well-known WSP header encoding */\n\t\t\tguint8 peek = tvb_get_guint8(tvb, offset);\n\t\t\tconst char *hdr_name = val_to_str(field, vals_mm_header_names,\n\t\t\t\t\"Unknown field (0x%02x)\");\n\t\t\tDebugLog((\"\\t\\tUndecoded well-known header: %s\\n\",\n\t\t\t\t    hdr_name));\n\n\t\t\tif (peek & 0x80) { /* Well-known value */\n\t\t\t    length = 1;\n\t\t\t    if (tree) {\n\t\t\t\tproto_tree_add_text(mmse_tree, tvb, offset - 1,\n\t\t\t\t\tlength + 1,\n\t\t\t\t\t\"%s: <Well-known value 0x%02x>\"\n\t\t\t\t\t\" (not decoded)\",\n\t\t\t\t\thdr_name, peek);\n\t\t\t    }\n\t\t\t} else if ((peek == 0) || (peek >= 0x20)) { /* Text */\n\t\t\t    length = get_text_string(tvb, offset, &strval);\n\t\t\t    if (tree) {\n\t\t\t\tproto_tree_add_text(mmse_tree, tvb, offset - 1,\n\t\t\t\t\tlength + 1, \"%s: %s (Not decoded)\",\n\t\t\t\t\thdr_name,\n\t\t\t\t\tformat_text(strval, strlen(strval)));\n\t\t\t    }\n\t\t\t} else { /* General form with length */\n\t\t\t    if (peek == 0x1F) { /* Value length in guintvar */\n\t\t\t\tguint length_len = 0;\n\t\t\t\tlength = 1 + tvb_get_guintvar(tvb, offset + 1,\n\t\t\t\t\t&length_len);\n\t\t\t\tlength += length_len;\n\t\t\t    } else { /* Value length in octet */\n\t\t\t\tlength = 1 + tvb_get_guint8(tvb, offset);\n\t\t\t    }\n\t\t\t    if (tree) {\n\t\t\t\tproto_tree_add_text(mmse_tree, tvb, offset - 1,\n\t\t\t\t\tlength + 1, \"%s: \"\n\t\t\t\t\t\"<Value in general form> (not decoded)\",\n\t\t\t\t\thdr_name);\n\t\t\t    }\n\t\t\t}\n\t\t\toffset += length;\n\t\t    } else { /* Literal WSP header encoding */\n\t\t\tguint\t\t length2;\n\t\t\tconst char\t *strval2;\n\n\t\t\t--offset;\n\t\t\tlength = get_text_string(tvb, offset, &strval);\n\t\t\tDebugLog((\"\\t\\tUndecoded literal header: %s\\n\",\n\t\t\t\t    strval));\n\t\t\tlength2= get_text_string(tvb, offset+length, &strval2);\n\n\t\t\tif (tree) {\n\t\t\t    proto_tree_add_string_format(mmse_tree,\n\t\t\t\t    hf_mmse_ffheader, tvb, offset,\n\t\t\t\t    length + length2,\n\t\t\t\t    tvb_get_string(wmem_packet_scope(), tvb, offset,\n\t\t\t\t\t    length + length2),\n\t\t\t\t    \"%s: %s\",\n\t\t\t\t    format_text(strval, strlen(strval)),\n\t\t\t\t    format_text(strval2, strlen(strval2)));\n\t\t\t}\n\t\t\toffset += length + length2;\n\t\t    }\n\t\t    break;\n\t    }\n\t    DebugLog((\"\\tEnd(case)\\n\"));\n\t}\n\tDebugLog((\"\\tEnd(switch)\\n\"));\n\tif (field == MM_CTYPE_HDR) {\n\t    /*\n\t     * Eeehh, we're now actually back to good old WSP content-type\n\t     * encoding. Let's steal that from the WSP-dissector.\n\t     */\n\t    tvbuff_t\t*tmp_tvb;\n\t    guint\t type;\n\t    const char\t*type_str;\n\n\t    DebugLog((\"Content-Type: [from WSP dissector]\\n\"));\n\t    DebugLog((\"Calling add_content_type() in WSP dissector\\n\"));\n\t    offset = add_content_type(mmse_tree, tvb, offset, &type, &type_str);\n\t    DebugLog((\"Generating new TVB subset (offset = %u)\\n\", offset));\n\t    tmp_tvb = tvb_new_subset_remaining(tvb, offset);\n\t    DebugLog((\"Add POST data\\n\"));\n\t    add_post_data(mmse_tree, tmp_tvb, type, type_str, pinfo);\n\t    DebugLog((\"Done!\\n\"));\n\t}\n    } else {\n\tDebugLog((\"tree == NULL and PDU has no potential content\\n\"));\n    }\n\n    /* If this protocol has a sub-dissector call it here, see section 1.8 */\n    DebugLog((\"dissect_mmse() - END\\n\"));\n}",
        "func": "static void\ndissect_mmse(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree, guint8 pdut,\n\tconst char *message_type)\n{\n    guint\t offset;\n    guint8\t field = 0;\n    const char\t *strval;\n    guint\t length;\n    guint\t count;\n    guint8\t version = 0x80; /* Default to MMSE 1.0 */\n\n    /* Set up structures needed to add the protocol subtree and manage it */\n    proto_item\t*ti = NULL;\n    proto_tree\t*mmse_tree = NULL;\n\n    DebugLog((\"dissect_mmse() - START (Packet %u)\\n\", pinfo->fd->num));\n\n    /* If tree == NULL then we are only interested in protocol dissection\n     * up to reassembly and handoff to subdissectors if applicable; the\n     * columns must be set appropriately too.\n     * If tree != NULL then we also want to display the protocol tree\n     * with its fields.\n     *\n     * In the interest of speed, skip protocol tree item generation\n     * if tree is NULL.\n     */\n    if (tree) {\n\tDebugLog((\"tree != NULL\\n\"));\n\n\tti = proto_tree_add_item(tree, proto_mmse, tvb, 0, -1, ENC_NA);\n\tproto_item_append_text(ti, \", Type: %s\", message_type);\n\t/* create display subtree for the protocol */\n\tmmse_tree = proto_item_add_subtree(ti, ett_mmse);\n\n\t/* Report PDU-type\t*/\n\tproto_tree_add_uint(mmse_tree, hf_mmse_message_type, tvb, 0, 2, pdut);\n    }\n\n    offset = 2;\t\t\t/* Skip Message-Type\t*/\n\n    /*\n     * Cycle through MMS-headers\n     *\n     * NOTE - some PDUs may convey content which can be handed off\n     *        to subdissectors.\n     */\n    if (tree || pdu_has_content(pdut)) {\n\twhile ((offset < tvb_reported_length(tvb)) &&\n\t       (field = tvb_get_guint8(tvb, offset++)) != MM_CTYPE_HDR)\n\t{\n\t    DebugLog((\"\\tField =  0x%02X (offset = %u): %s\\n\",\n\t\t\tfield, offset,\n\t\t\tval_to_str(field, vals_mm_header_names,\n\t\t\t    \"Unknown MMS header 0x%02X\")));\n\t    switch (field)\n\t    {\n\t\tcase MM_TID_HDR:\t\t/* Text-string\t*/\n\t\t    length = get_text_string(tvb, offset, &strval);\n\t\t    if (tree) {\n\t\t\tproto_tree_add_string(mmse_tree, hf_mmse_transaction_id,\n\t\t\t\ttvb, offset - 1, length + 1,strval);\n\t\t    }\n\t\t    offset += length;\n\t\t    break;\n\t\tcase MM_VERSION_HDR:\t\t/* nibble-Major/nibble-minor*/\n\t\t    version = tvb_get_guint8(tvb, offset++);\n\t\t    if (tree) {\n\t\t\tguint8\t major, minor;\n\t\t\tchar    *vers_string;\n\n\t\t\tmajor = (version & 0x70) >> 4;\n\t\t\tminor = version & 0x0F;\n\t\t\tif (minor == 0x0F)\n\t\t\t    vers_string = wmem_strdup_printf(wmem_packet_scope(), \"%u\", major);\n\t\t\telse\n\t\t\t    vers_string = wmem_strdup_printf(wmem_packet_scope(), \"%u.%u\", major, minor);\n\t\t\tproto_tree_add_string(mmse_tree, hf_mmse_mms_version,\n\t\t\t\ttvb, offset - 2, 2, vers_string);\n\t\t    }\n\t\t    break;\n\t\tcase MM_BCC_HDR:\t\t/* Encoded-string-value\t*/\n\t\t    length = get_encoded_strval(tvb, offset, &strval);\n\t\t    if (tree) {\n\t\t\tproto_tree_add_string(mmse_tree, hf_mmse_bcc, tvb,\n\t\t\t\toffset - 1, length + 1, strval);\n\t\t    }\n\t\t    offset += length;\n\t\t    break;\n\t\tcase MM_CC_HDR:\t\t\t/* Encoded-string-value\t*/\n\t\t    length = get_encoded_strval(tvb, offset, &strval);\n\t\t    if (tree) {\n\t\t\tproto_tree_add_string(mmse_tree, hf_mmse_cc, tvb,\n\t\t\t\toffset - 1, length + 1, strval);\n\t\t    }\n\t\t    offset += length;\n\t\t    break;\n\t\tcase MM_CLOCATION_HDR:\t\t/* Uri-value\t\t*/\n\t\t    if (pdut == PDU_M_MBOX_DELETE_CONF) {\n\t\t\t/* General form with length */\n\t\t\tlength = tvb_get_guint8(tvb, offset);\n\t\t\tif (length == 0x1F) {\n\t\t\t    guint length_len = 0;\n\t\t\t    length = tvb_get_guintvar(tvb, offset + 1,\n\t\t\t\t    &length_len);\n\t\t\t    length += 1 + length_len;\n\t\t\t} else {\n\t\t\t    length += 1;\n\t\t\t}\n\t\t\tif (tree) {\n\t\t\t    tvb_ensure_bytes_exist(tvb, offset - 1, length + 1);\n\t\t\t    proto_tree_add_string(mmse_tree,\n\t\t\t\t    hf_mmse_content_location,\n\t\t\t\t    tvb, offset - 1, length + 1,\n\t\t\t\t    \"<Undecoded value for m-mbox-delete-conf>\");\n\t\t\t}\n\t\t    } else {\n\t\t\tlength = get_text_string(tvb, offset, &strval);\n\t\t\tif (tree) {\n\t\t\t    proto_tree_add_string(mmse_tree,\n\t\t\t\t    hf_mmse_content_location,\n\t\t\t\t    tvb, offset - 1, length + 1, strval);\n\t\t\t}\n\t\t    }\n\t\t    offset += length;\n\t\t    break;\n\t\tcase MM_DATE_HDR:\t\t/* Long-integer\t\t*/\n\t\t    {\n\t\t\tguint\t\t tval;\n\t\t\tnstime_t\t tmptime;\n\n\t\t\ttval = get_long_integer(tvb, offset, &count);\n\t\t\ttmptime.secs = tval;\n\t\t\ttmptime.nsecs = 0;\n\t\t\tif (tree) {\n\t\t\t    tvb_ensure_bytes_exist(tvb, offset - 1, count + 1);\n\t\t\t    proto_tree_add_time(mmse_tree, hf_mmse_date, tvb,\n\t\t\t\t    offset - 1, count + 1, &tmptime);\n\t\t\t}\n\t\t    }\n\t\t    offset += count;\n\t\t    break;\n\t\tcase MM_DREPORT_HDR:\t\t/* Yes|No\t\t*/\n\t\t    field = tvb_get_guint8(tvb, offset++);\n\t\t    if (tree) {\n\t\t\tproto_tree_add_uint(mmse_tree,\n\t\t\t\thf_mmse_delivery_report,\n\t\t\t\ttvb, offset - 2, 2, field);\n\t\t    }\n\t\t    break;\n\t\tcase MM_DTIME_HDR:\n\t\t    /*\n\t\t     * Value-length(Absolute-token Date-value|\n\t\t     * \t\t    Relative-token Delta-seconds-value)\n\t\t     */\n\t\t    length = get_value_length(tvb, offset, &count);\n\t\t    field = tvb_get_guint8(tvb, offset + count);\n\t\t    if (tree) {\n\t\t\tguint\t\t tval;\n\t\t\tnstime_t\t tmptime;\n\t\t\tguint\t\t cnt;\n\n\t\t\ttval =  get_long_integer(tvb, offset + count + 1, &cnt);\n\t\t\ttmptime.secs = tval;\n\t\t\ttmptime.nsecs = 0;\n\n\t\t\ttvb_ensure_bytes_exist(tvb, offset - 1, length + count + 1);\n\t\t\tif (field == 0x80)\n\t\t\t    proto_tree_add_time(mmse_tree,\n\t\t\t\t    hf_mmse_delivery_time_abs,\n\t\t\t\t    tvb, offset - 1,\n\t\t\t\t    length + count + 1, &tmptime);\n\t\t\telse\n\t\t\t    proto_tree_add_time(mmse_tree,\n\t\t\t\t    hf_mmse_delivery_time_rel,\n\t\t\t\t    tvb, offset - 1,\n\t\t\t\t    length + count + 1, &tmptime);\n\t\t    }\n\t\t    offset += length + count;\n\t\t    break;\n\t\tcase MM_EXPIRY_HDR:\n\t\t    /*\n\t\t     * Value-length(Absolute-token Date-value|\n\t\t     * \t\t    Relative-token Delta-seconds-value)\n\t\t     */\n\t\t    length = get_value_length(tvb, offset, &count);\n\t\t    field = tvb_get_guint8(tvb, offset + count);\n\t\t    if (tree) {\n\t\t\tguint\t\t tval;\n\t\t\tnstime_t\t tmptime;\n\t\t\tguint\t\t cnt;\n\n\t\t\ttval = get_long_integer(tvb, offset + count + 1, &cnt);\n\t\t\ttmptime.secs = tval;\n\t\t\ttmptime.nsecs = 0;\n\n\t\t\ttvb_ensure_bytes_exist(tvb, offset - 1, length + count + 1);\n\t\t\tif (field == 0x80)\n\t\t\t    proto_tree_add_time(mmse_tree, hf_mmse_expiry_abs,\n\t\t\t\t    tvb, offset - 1,\n\t\t\t\t    length + count + 1, &tmptime);\n\t\t\telse\n\t\t\t    proto_tree_add_time(mmse_tree, hf_mmse_expiry_rel,\n\t\t\t\t    tvb, offset - 1,\n\t\t\t\t    length + count + 1, &tmptime);\n\t\t    }\n\t\t    offset += length + count;\n\t\t    break;\n\t\tcase MM_FROM_HDR:\n\t\t    /*\n\t\t     * Value-length(Address-present-token Encoded-string-value\n\t\t     * \t\t    |Insert-address-token)\n\t\t     */\n\t\t    length = get_value_length(tvb, offset, &count);\n\t\t    if (tree) {\n\t\t\tfield = tvb_get_guint8(tvb, offset + count);\n\t\t\ttvb_ensure_bytes_exist(tvb, offset - 1, length + count + 1);\n\t\t\tif (field == 0x81) {\n\t\t\t    proto_tree_add_string(mmse_tree, hf_mmse_from, tvb,\n\t\t\t\t    offset-1, length + count + 1,\n\t\t\t\t    \"<insert address>\");\n\t\t\t} else {\n\t\t\t    (void) get_encoded_strval(tvb, offset + count + 1,\n\t\t\t\t\t\t      &strval);\n\t\t\t    proto_tree_add_string(mmse_tree, hf_mmse_from, tvb,\n\t\t\t\t    offset-1, length + count + 1, strval);\n\t\t\t}\n\t\t    }\n\t\t    offset += length + count;\n\t\t    break;\n\t\tcase MM_MCLASS_HDR:\n\t\t    /*\n\t\t     * Class-identifier|Text-string\n\t\t     */\n\t\t    field = tvb_get_guint8(tvb, offset);\n\t\t    if (field & 0x80) {\n\t\t\toffset++;\n\t\t\tif (tree) {\n\t\t\t    proto_tree_add_uint(mmse_tree,\n\t\t\t\t    hf_mmse_message_class_id,\n\t\t\t\t    tvb, offset - 2, 2, field);\n\t\t\t}\n\t\t    } else {\n\t\t\tlength = get_text_string(tvb, offset, &strval);\n\t\t\tif (tree) {\n\t\t\t    proto_tree_add_string(mmse_tree,\n\t\t\t\t    hf_mmse_message_class_str,\n\t\t\t\t    tvb, offset - 1, length + 1,\n\t\t\t\t    strval);\n\t\t\t}\n\t\t\toffset += length;\n\t\t    }\n\t\t    break;\n\t\tcase MM_MID_HDR:\t\t/* Text-string\t\t*/\n\t\t    length = get_text_string(tvb, offset, &strval);\n\t\t    if (tree) {\n\t\t\tproto_tree_add_string(mmse_tree, hf_mmse_message_id,\n\t\t\t\ttvb, offset - 1, length + 1, strval);\n\t\t    }\n\t\t    offset += length;\n\t\t    break;\n\t\tcase MM_MSIZE_HDR:\t\t/* Long-integer\t\t*/\n\t\t    length = get_long_integer(tvb, offset, &count);\n\t\t    if (tree) {\n\t\t\tproto_tree_add_uint(mmse_tree, hf_mmse_message_size,\n\t\t\t\ttvb, offset - 1, count + 1, length);\n\t\t    }\n\t\t    offset += count;\n\t\t    break;\n\t\tcase MM_PRIORITY_HDR:\t\t/* Low|Normal|High\t*/\n\t\t    field = tvb_get_guint8(tvb, offset++);\n\t\t    if (tree) {\n\t\t\tproto_tree_add_uint(mmse_tree, hf_mmse_priority, tvb,\n\t\t\t\toffset - 2, 2, field);\n\t\t    }\n\t\t    break;\n\t\tcase MM_RREPLY_HDR:\t\t/* Yes|No\t\t*/\n\t\t    field = tvb_get_guint8(tvb, offset++);\n\t\t    if (tree) {\n\t\t\tif (version == 0x80) { /* MMSE 1.0 */\n\t\t\t    proto_tree_add_uint(mmse_tree, hf_mmse_read_reply,\n\t\t\t\t    tvb, offset - 2, 2, field);\n\t\t\t} else {\n\t\t\t    proto_tree_add_uint(mmse_tree, hf_mmse_read_report,\n\t\t\t\t    tvb, offset - 2, 2, field);\n\t\t\t}\n\t\t    }\n\t\t    break;\n\t\tcase MM_RALLOWED_HDR:\t\t/* Yes|No\t\t*/\n\t\t    field = tvb_get_guint8(tvb, offset++);\n\t\t    if (tree) {\n\t\t\tproto_tree_add_uint(mmse_tree, hf_mmse_report_allowed,\n\t\t\t\ttvb, offset - 2, 2, field);\n\t\t    }\n\t\t    break;\n\t\tcase MM_RSTATUS_HDR:\n\t\t    field = tvb_get_guint8(tvb, offset++);\n\t\t    if (tree) {\n\t\t\tproto_tree_add_uint(mmse_tree, hf_mmse_response_status,\n\t\t\t\ttvb, offset - 2, 2, field);\n\t\t    }\n\t\t    break;\n\t\tcase MM_RTEXT_HDR:\t\t/* Encoded-string-value\t*/\n\t\t    if (pdut == PDU_M_MBOX_DELETE_CONF) {\n\t\t\t/* General form with length */\n\t\t\tlength = tvb_get_guint8(tvb, offset);\n\t\t\tif (length == 0x1F) {\n\t\t\t    guint length_len = 0;\n\t\t\t    length = tvb_get_guintvar(tvb, offset + 1,\n\t\t\t\t    &length_len);\n\t\t\t    length += 1 + length_len;\n\t\t\t} else {\n\t\t\t    length += 1;\n\t\t\t}\n\t\t\tif (tree) {\n\t\t\t    proto_tree_add_string(mmse_tree,\n\t\t\t\t    hf_mmse_content_location,\n\t\t\t\t    tvb, offset - 1, length + 1,\n\t\t\t\t    \"<Undecoded value for m-mbox-delete-conf>\");\n\t\t\t}\n\t\t    } else {\n    \t\t\tlength = get_encoded_strval(tvb, offset, &strval);\n\t\t\tif (tree) {\n\t\t\t    proto_tree_add_string(mmse_tree,\n\t\t\t\t    hf_mmse_response_text, tvb, offset - 1,\n\t\t\t\t    length + 1, strval);\n\t\t\t}\n\t\t    }\n\t\t    offset += length;\n\t\t    break;\n\t\tcase MM_SVISIBILITY_HDR:\t/* Hide|Show\t\t*/\n\t\t    field = tvb_get_guint8(tvb, offset++);\n\t\t    if (tree) {\n\t\t\tproto_tree_add_uint(mmse_tree,hf_mmse_sender_visibility,\n\t\t\t\ttvb, offset - 2, 2, field);\n\t\t    }\n\t\t    break;\n\t\tcase MM_STATUS_HDR:\n\t\t    field = tvb_get_guint8(tvb, offset++);\n\t\t    if (tree) {\n\t\t\tproto_tree_add_uint(mmse_tree, hf_mmse_status, tvb,\n\t\t\t\toffset - 2, 2, field);\n\t\t    }\n\t\t    break;\n\t\tcase MM_SUBJECT_HDR:\t\t/* Encoded-string-value\t*/\n\t\t    length = get_encoded_strval(tvb, offset, &strval);\n\t\t    if (tree) {\n\t\t\tproto_tree_add_string(mmse_tree, hf_mmse_subject, tvb,\n\t\t\t\toffset - 1, length + 1, strval);\n\t\t    }\n\t\t    offset += length;\n\t\t    break;\n\t\tcase MM_TO_HDR:\t\t\t/* Encoded-string-value\t*/\n\t\t    length = get_encoded_strval(tvb, offset, &strval);\n\t\t    if (tree) {\n\t\t\tproto_tree_add_string(mmse_tree, hf_mmse_to, tvb,\n\t\t\t\toffset - 1, length + 1, strval);\n\t\t    }\n\t\t    offset += length;\n\t\t    break;\n\n\t\t/*\n\t\t * MMS Encapsulation 1.1\n\t\t */\n\t\tcase MM_RETRIEVE_STATUS_HDR:\t/* Well-known-value */\n\t\t    field = tvb_get_guint8(tvb, offset++);\n\t\t    if (tree) {\n\t\t\tproto_tree_add_uint(mmse_tree, hf_mmse_retrieve_status,\n\t\t\t\ttvb, offset - 2, 2, field);\n\t\t    }\n\t\t    break;\n\t\tcase MM_RETRIEVE_TEXT_HDR:\n\t\t    if (pdut == PDU_M_MBOX_DELETE_CONF) {\n\t\t\t/* General form with length */\n\t\t\tlength = tvb_get_guint8(tvb, offset);\n\t\t\tif (length == 0x1F) {\n\t\t\t    guint length_len = 0;\n\t\t\t    length = tvb_get_guintvar(tvb, offset + 1,\n\t\t\t\t    &length_len);\n\t\t\t    length += 1 + length_len;\n\t\t\t} else {\n\t\t\t    length += 1;\n\t\t\t}\n\t\t\tif (tree) {\n\t\t\t    proto_tree_add_string(mmse_tree,\n\t\t\t\t    hf_mmse_content_location,\n\t\t\t\t    tvb, offset - 1, length + 1,\n\t\t\t\t    \"<Undecoded value for m-mbox-delete-conf>\");\n\t\t\t}\n\t\t    } else {\n\t\t\t/* Encoded-string-value */\n\t\t\tlength = get_encoded_strval(tvb, offset, &strval);\n\t\t\tif (tree) {\n\t\t\t    proto_tree_add_string(mmse_tree,\n\t\t\t\t    hf_mmse_retrieve_text, tvb, offset - 1,\n\t\t\t\t    length + 1, strval);\n\t\t\t}\n\t\t    }\n\t\t    offset += length;\n\t\t    break;\n\t\tcase MM_READ_STATUS_HDR:\t/* Well-known-value */\n\t\t    field = tvb_get_guint8(tvb, offset++);\n\t\t    if (tree) {\n\t\t\tproto_tree_add_uint(mmse_tree, hf_mmse_read_status,\n\t\t\t\ttvb, offset - 2, 2, field);\n\t\t    }\n\t\t    break;\n\t\tcase MM_REPLY_CHARGING_HDR:\t/* Well-known-value */\n\t\t    field = tvb_get_guint8(tvb, offset++);\n\t\t    if (tree) {\n\t\t\tproto_tree_add_uint(mmse_tree, hf_mmse_reply_charging,\n\t\t\t\ttvb, offset - 2, 2, field);\n\t\t    }\n\t\t    break;\n\t\tcase MM_REPLY_CHARGING_DEADLINE_HDR:\t/* Well-known-value */\n\t\t    /*\n\t\t     * Value-length(Absolute-token Date-value|\n\t\t     * \t\t    Relative-token Delta-seconds-value)\n\t\t     */\n\t\t    length = get_value_length(tvb, offset, &count);\n\t\t    field = tvb_get_guint8(tvb, offset + count);\n\t\t    if (tree) {\n\t\t\tguint\t\t tval;\n\t\t\tnstime_t\t tmptime;\n\t\t\tguint\t\t cnt;\n\n\t\t\ttval = get_long_integer(tvb, offset + count + 1, &cnt);\n\t\t\ttmptime.secs = tval;\n\t\t\ttmptime.nsecs = 0;\n\n\t\t\ttvb_ensure_bytes_exist(tvb, offset - 1, length + count + 1);\n\t\t\tif (field == 0x80)\n\t\t\t    proto_tree_add_time(mmse_tree, hf_mmse_reply_charging_deadline_abs,\n\t\t\t\t    tvb, offset - 1,\n\t\t\t\t    length + count + 1, &tmptime);\n\t\t\telse\n\t\t\t    proto_tree_add_time(mmse_tree, hf_mmse_reply_charging_deadline_rel,\n\t\t\t\t    tvb, offset - 1,\n\t\t\t\t    length + count + 1, &tmptime);\n\t\t    }\n\t\t    offset += length + count;\n\t\t    break;\n\t\tcase MM_REPLY_CHARGING_ID_HDR:\t/* Text-string */\n\t\t    length = get_text_string(tvb, offset, &strval);\n\t\t    if (tree) {\n\t\t\tproto_tree_add_string(mmse_tree,\n\t\t\t\thf_mmse_reply_charging_id,\n\t\t\t\ttvb, offset - 1, length + 1, strval);\n\t\t    }\n\t\t    offset += length;\n\t\t    break;\n\t\tcase MM_REPLY_CHARGING_SIZE_HDR:\t/* Long-integer */\n\t\t    length = get_long_integer(tvb, offset, &count);\n\t\t    if (tree) {\n\t\t\tproto_tree_add_uint(mmse_tree,\n\t\t\t\thf_mmse_reply_charging_size,\n\t\t\t\ttvb, offset - 1, count + 1, length);\n\t\t    }\n\t\t    offset += count;\n\t\t    break;\n\t\tcase MM_PREV_SENT_BY_HDR:\n\t\t    /* Value-length Integer-value Encoded-string-value */\n\t\t    length = get_value_length(tvb, offset, &count);\n\t\t    if (tree) {\n\t\t\tguint32 fwd_count, count1, count2;\n\t\t\tproto_tree *subtree = NULL;\n\t\t\tproto_item *tii = NULL;\n\t\t\t/* 1. Forwarded-count-value := Integer-value */\n\t\t\tfwd_count = get_integer_value(tvb, offset + count,\n\t\t\t    &count1);\n\t\t\t/* 2. Encoded-string-value */\n\t\t\tcount2 = get_encoded_strval(tvb,\n\t\t\t\toffset + count + count1, &strval);\n\t\t\t/* Now render the fields */\n\t\t\ttii = proto_tree_add_string_format(mmse_tree,\n\t\t\t\thf_mmse_prev_sent_by,\n\t\t\t\ttvb, offset - 1, 1 + count + length,\n\t\t\t\tstrval, \"%s (Forwarded-count=%u)\",\n\t\t\t\tformat_text(strval, strlen(strval)),\n\t\t\t\tfwd_count);\n\t\t\tsubtree = proto_item_add_subtree(tii,\n\t\t\t\tett_mmse_hdr_details);\n\t\t\tproto_tree_add_uint(subtree,\n\t\t\t\thf_mmse_prev_sent_by_fwd_count,\n\t\t\t\ttvb, offset + count, count1, fwd_count);\n\t\t\tproto_tree_add_string(subtree,\n\t\t\t\thf_mmse_prev_sent_by_address,\n\t\t\t\ttvb, offset + count + count1, count2, strval);\n\t\t    }\n\t\t    offset += length + count;\n\t\t    break;\n\t\tcase MM_PREV_SENT_DATE_HDR:\n\t\t    /* Value-Length Forwarded-count-value Date-value */\n\t\t    length = get_value_length(tvb, offset, &count);\n\t\t    if (tree) {\n\t\t\tguint32 fwd_count, count1, count2;\n\t\t\tguint\t\t tval;\n\t\t\tnstime_t\t tmptime;\n\t\t\tproto_tree *subtree = NULL;\n\t\t\tproto_item *tii = NULL;\n\t\t\t/* 1. Forwarded-count-value := Integer-value */\n\t\t\tfwd_count = get_integer_value(tvb, offset + count,\n\t\t\t    &count1);\n\t\t\t/* 2. Date-value := Long-integer */\n\t\t\ttval = get_long_integer(tvb, offset + count + count1,\n\t\t\t\t&count2);\n\t\t\ttmptime.secs = tval;\n\t\t\ttmptime.nsecs = 0;\n\t\t\tstrval = abs_time_to_ep_str(&tmptime, ABSOLUTE_TIME_LOCAL,\n\t\t\t    TRUE);\n\t\t\t/* Now render the fields */\n\t\t\ttvb_ensure_bytes_exist(tvb, offset - 1, length + count + 1);\n\t\t\ttii = proto_tree_add_string_format(mmse_tree,\n\t\t\t\thf_mmse_prev_sent_date,\n\t\t\t\ttvb, offset - 1, 1 + count + length,\n\t\t\t\tstrval, \"%s (Forwarded-count=%u)\",\n\t\t\t\tformat_text(strval, strlen(strval)),\n\t\t\t\tfwd_count);\n\t\t\tsubtree = proto_item_add_subtree(tii,\n\t\t\t\tett_mmse_hdr_details);\n\t\t\tproto_tree_add_uint(subtree,\n\t\t\t\thf_mmse_prev_sent_date_fwd_count,\n\t\t\t\ttvb, offset + count, count1, fwd_count);\n\t\t\tproto_tree_add_string(subtree,\n\t\t\t\thf_mmse_prev_sent_date_date,\n\t\t\t\ttvb, offset + count + count1, count2, strval);\n\t\t    }\n\t\t    offset += length + count;\n\t\t    break;\n\n\t\t/* MMS Encapsulation 1.2 */\n\n\t\tdefault:\n\t\t    if (field & 0x80) { /* Well-known WSP header encoding */\n\t\t\tguint8 peek = tvb_get_guint8(tvb, offset);\n\t\t\tconst char *hdr_name = val_to_str(field, vals_mm_header_names,\n\t\t\t\t\"Unknown field (0x%02x)\");\n\t\t\tconst char *str;\n\t\t\tDebugLog((\"\\t\\tUndecoded well-known header: %s\\n\",\n\t\t\t\t    hdr_name));\n\n\t\t\tif (peek & 0x80) { /* Well-known value */\n\t\t\t    length = 1;\n\t\t\t    if (tree) {\n\t\t\t\tproto_tree_add_uint_format(mmse_tree, hf_mmse_header_uint, tvb, offset - 1,\n\t\t\t\t\tlength + 1, peek,\n\t\t\t\t\t\"%s: <Well-known value 0x%02x>\"\n\t\t\t\t\t\" (not decoded)\",\n\t\t\t\t\thdr_name, peek);\n\t\t\t    }\n\t\t\t} else if ((peek == 0) || (peek >= 0x20)) { /* Text */\n\t\t\t    length = get_text_string(tvb, offset, &strval);\n\t\t\t    if (tree) {\n\t\t\t\tstr = format_text(strval, strlen(strval));\n\t\t\t\tproto_tree_add_string_format(mmse_tree, hf_mmse_header_string, tvb, offset - 1,\n\t\t\t\t\tlength + 1, str, \"%s: %s (Not decoded)\", hdr_name, str);\n\t\t\t    }\n\t\t\t} else { /* General form with length */\n\t\t\t    if (peek == 0x1F) { /* Value length in guintvar */\n\t\t\t\tguint length_len = 0;\n\t\t\t\tlength = 1 + tvb_get_guintvar(tvb, offset + 1,\n\t\t\t\t\t&length_len);\n\t\t\t\tlength += length_len;\n\t\t\t    } else { /* Value length in octet */\n\t\t\t\tlength = 1 + tvb_get_guint8(tvb, offset);\n\t\t\t    }\n\t\t\t    if (tree) {\n\t\t\t\tproto_tree_add_bytes_format(mmse_tree, hf_mmse_header_bytes, tvb, offset - 1,\n\t\t\t\t\tlength + 1, NULL, \"%s: \"\n\t\t\t\t\t\"<Value in general form> (not decoded)\",\n\t\t\t\t\thdr_name);\n\t\t\t    }\n\t\t\t}\n\t\t\toffset += length;\n\t\t    } else { /* Literal WSP header encoding */\n\t\t\tguint\t\t length2;\n\t\t\tconst char\t *strval2;\n\n\t\t\t--offset;\n\t\t\tlength = get_text_string(tvb, offset, &strval);\n\t\t\tDebugLog((\"\\t\\tUndecoded literal header: %s\\n\",\n\t\t\t\t    strval));\n\t\t\tlength2= get_text_string(tvb, offset+length, &strval2);\n\n\t\t\tif (tree) {\n\t\t\t    proto_tree_add_string_format(mmse_tree,\n\t\t\t\t    hf_mmse_ffheader, tvb, offset,\n\t\t\t\t    length + length2,\n\t\t\t\t    tvb_get_string(wmem_packet_scope(), tvb, offset,\n\t\t\t\t\t    length + length2),\n\t\t\t\t    \"%s: %s\",\n\t\t\t\t    format_text(strval, strlen(strval)),\n\t\t\t\t    format_text(strval2, strlen(strval2)));\n\t\t\t}\n\t\t\toffset += length + length2;\n\t\t    }\n\t\t    break;\n\t    }\n\t    DebugLog((\"\\tEnd(case)\\n\"));\n\t}\n\tDebugLog((\"\\tEnd(switch)\\n\"));\n\tif (field == MM_CTYPE_HDR) {\n\t    /*\n\t     * Eeehh, we're now actually back to good old WSP content-type\n\t     * encoding. Let's steal that from the WSP-dissector.\n\t     */\n\t    tvbuff_t\t*tmp_tvb;\n\t    guint\t type;\n\t    const char\t*type_str;\n\n\t    DebugLog((\"Content-Type: [from WSP dissector]\\n\"));\n\t    DebugLog((\"Calling add_content_type() in WSP dissector\\n\"));\n\t    offset = add_content_type(mmse_tree, tvb, offset, &type, &type_str);\n\t    DebugLog((\"Generating new TVB subset (offset = %u)\\n\", offset));\n\t    tmp_tvb = tvb_new_subset_remaining(tvb, offset);\n\t    DebugLog((\"Add POST data\\n\"));\n\t    add_post_data(mmse_tree, tmp_tvb, type, type_str, pinfo);\n\t    DebugLog((\"Done!\\n\"));\n\t}\n    } else {\n\tDebugLog((\"tree == NULL and PDU has no potential content\\n\"));\n    }\n\n    /* If this protocol has a sub-dissector call it here, see section 1.8 */\n    DebugLog((\"dissect_mmse() - END\\n\"));\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -534,14 +534,15 @@\n \t\t\tguint8 peek = tvb_get_guint8(tvb, offset);\n \t\t\tconst char *hdr_name = val_to_str(field, vals_mm_header_names,\n \t\t\t\t\"Unknown field (0x%02x)\");\n+\t\t\tconst char *str;\n \t\t\tDebugLog((\"\\t\\tUndecoded well-known header: %s\\n\",\n \t\t\t\t    hdr_name));\n \n \t\t\tif (peek & 0x80) { /* Well-known value */\n \t\t\t    length = 1;\n \t\t\t    if (tree) {\n-\t\t\t\tproto_tree_add_text(mmse_tree, tvb, offset - 1,\n-\t\t\t\t\tlength + 1,\n+\t\t\t\tproto_tree_add_uint_format(mmse_tree, hf_mmse_header_uint, tvb, offset - 1,\n+\t\t\t\t\tlength + 1, peek,\n \t\t\t\t\t\"%s: <Well-known value 0x%02x>\"\n \t\t\t\t\t\" (not decoded)\",\n \t\t\t\t\thdr_name, peek);\n@@ -549,10 +550,9 @@\n \t\t\t} else if ((peek == 0) || (peek >= 0x20)) { /* Text */\n \t\t\t    length = get_text_string(tvb, offset, &strval);\n \t\t\t    if (tree) {\n-\t\t\t\tproto_tree_add_text(mmse_tree, tvb, offset - 1,\n-\t\t\t\t\tlength + 1, \"%s: %s (Not decoded)\",\n-\t\t\t\t\thdr_name,\n-\t\t\t\t\tformat_text(strval, strlen(strval)));\n+\t\t\t\tstr = format_text(strval, strlen(strval));\n+\t\t\t\tproto_tree_add_string_format(mmse_tree, hf_mmse_header_string, tvb, offset - 1,\n+\t\t\t\t\tlength + 1, str, \"%s: %s (Not decoded)\", hdr_name, str);\n \t\t\t    }\n \t\t\t} else { /* General form with length */\n \t\t\t    if (peek == 0x1F) { /* Value length in guintvar */\n@@ -564,8 +564,8 @@\n \t\t\t\tlength = 1 + tvb_get_guint8(tvb, offset);\n \t\t\t    }\n \t\t\t    if (tree) {\n-\t\t\t\tproto_tree_add_text(mmse_tree, tvb, offset - 1,\n-\t\t\t\t\tlength + 1, \"%s: \"\n+\t\t\t\tproto_tree_add_bytes_format(mmse_tree, hf_mmse_header_bytes, tvb, offset - 1,\n+\t\t\t\t\tlength + 1, NULL, \"%s: \"\n \t\t\t\t\t\"<Value in general form> (not decoded)\",\n \t\t\t\t\thdr_name);\n \t\t\t    }",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\t\tproto_tree_add_text(mmse_tree, tvb, offset - 1,",
                "\t\t\t\t\tlength + 1,",
                "\t\t\t\tproto_tree_add_text(mmse_tree, tvb, offset - 1,",
                "\t\t\t\t\tlength + 1, \"%s: %s (Not decoded)\",",
                "\t\t\t\t\thdr_name,",
                "\t\t\t\t\tformat_text(strval, strlen(strval)));",
                "\t\t\t\tproto_tree_add_text(mmse_tree, tvb, offset - 1,",
                "\t\t\t\t\tlength + 1, \"%s: \""
            ],
            "added_lines": [
                "\t\t\tconst char *str;",
                "\t\t\t\tproto_tree_add_uint_format(mmse_tree, hf_mmse_header_uint, tvb, offset - 1,",
                "\t\t\t\t\tlength + 1, peek,",
                "\t\t\t\tstr = format_text(strval, strlen(strval));",
                "\t\t\t\tproto_tree_add_string_format(mmse_tree, hf_mmse_header_string, tvb, offset - 1,",
                "\t\t\t\t\tlength + 1, str, \"%s: %s (Not decoded)\", hdr_name, str);",
                "\t\t\t\tproto_tree_add_bytes_format(mmse_tree, hf_mmse_header_bytes, tvb, offset - 1,",
                "\t\t\t\t\tlength + 1, NULL, \"%s: \""
            ]
        }
    },
    {
        "cve_id": "CVE-2016-6507",
        "func_name": "wireshark/proto_register_mmse",
        "description": "epan/dissectors/packet-mmse.c in the MMSE dissector in Wireshark 1.12.x before 1.12.13 allows remote attackers to cause a denial of service (infinite loop) via a crafted packet.",
        "git_url": "https://github.com/wireshark/wireshark/commit/b5a10743258bd016c07ebf6479137fda3d172a0f",
        "commit_title": "MMSE: remove proto_tree_add_text calls",
        "commit_text": " Backport changes done previously in master-2.0 branch  Bug: 12624",
        "func_before": "void\nproto_register_mmse(void)\n{\n    /* Setup list of header fields  See Section 1.6.1 for details\t*/\n    static hf_register_info hf[] = {\n\t{   &hf_mmse_message_type,\n\t    {   \"X-Mms-Message-Type\", \"mmse.message_type\",\n\t\tFT_UINT8, BASE_HEX, VALS(vals_message_type), 0x00,\n\t\t\"Specifies the transaction type. Effectively defines PDU.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_transaction_id,\n\t    {   \"X-Mms-Transaction-ID\", \"mmse.transaction_id\",\n\t\tFT_STRING, BASE_NONE, NULL, 0x00,\n\t\t\"A unique identifier for this transaction. Identifies request and corresponding response only.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_mms_version,\n\t    {   \"X-Mms-MMS-Version\", \"mmse.mms_version\",\n\t\tFT_STRING, BASE_NONE, NULL, 0x00,\n\t\t\"Version of the protocol used.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_bcc,\n\t    {   \"Bcc\", \"mmse.bcc\",\n\t\tFT_STRING, BASE_NONE, NULL, 0x00,\n\t\t\"Blind carbon copy.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_cc,\n\t    {   \"Cc\", \"mmse.cc\",\n\t\tFT_STRING, BASE_NONE, NULL, 0x00,\n\t\t\"Carbon copy.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_content_location,\n\t    {   \"X-Mms-Content-Location\", \"mmse.content_location\",\n\t\tFT_STRING, BASE_NONE, NULL, 0x00,\n\t\t\"Defines the location of the message.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_date,\n\t    {   \"Date\", \"mmse.date\",\n\t\tFT_ABSOLUTE_TIME, ABSOLUTE_TIME_LOCAL, NULL, 0x00,\n\t\t\"Arrival timestamp of the message or sending timestamp.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_delivery_report,\n\t    {   \"X-Mms-Delivery-Report\", \"mmse.delivery_report\",\n\t\tFT_UINT8, BASE_HEX, VALS(vals_yes_no), 0x00,\n\t\t\"Whether a report of message delivery is wanted or not.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_delivery_time_abs,\n\t    {   \"X-Mms-Delivery-Time\", \"mmse.delivery_time.abs\",\n\t\tFT_ABSOLUTE_TIME, ABSOLUTE_TIME_LOCAL, NULL, 0x00,\n\t\t\"The time at which message delivery is desired.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_delivery_time_rel,\n\t    {   \"X-Mms-Delivery-Time\", \"mmse.delivery_time.rel\",\n\t\tFT_RELATIVE_TIME, BASE_NONE, NULL, 0x00,\n\t\t\"The desired message delivery delay.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_expiry_abs,\n\t    {   \"X-Mms-Expiry\", \"mmse.expiry.abs\",\n\t\tFT_ABSOLUTE_TIME, ABSOLUTE_TIME_LOCAL, NULL, 0x00,\n\t\t\"Time when message expires and need not be delivered anymore.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_expiry_rel,\n\t    {   \"X-Mms-Expiry\", \"mmse.expiry.rel\",\n\t\tFT_RELATIVE_TIME, BASE_NONE, NULL, 0x00,\n\t\t\"Delay before message expires and need not be delivered anymore.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_from,\n\t    {   \"From\", \"mmse.from\",\n\t\tFT_STRING, BASE_NONE, NULL, 0x00,\n\t\t\"Address of the message sender.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_message_class_id,\n\t    {   \"X-Mms-Message-Class\", \"mmse.message_class.id\",\n\t\tFT_UINT8, BASE_HEX, VALS(vals_message_class), 0x00,\n\t\t\"Of what category is the message.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_message_class_str,\n\t    {   \"X-Mms-Message-Class\", \"mmse.message_class.str\",\n\t\tFT_STRING, BASE_NONE, NULL, 0x00,\n\t\t\"Of what category is the message.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_message_id,\n\t    {   \"Message-Id\", \"mmse.message_id\",\n\t\tFT_STRING, BASE_NONE, NULL, 0x00,\n\t\t\"Unique identification of the message.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_message_size,\n\t    {   \"X-Mms-Message-Size\", \"mmse.message_size\",\n\t\tFT_UINT32, BASE_DEC, NULL, 0x00,\n\t\t\"The size of the message in octets.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_priority,\n\t    {   \"X-Mms-Priority\", \"mmse.priority\",\n\t\tFT_UINT8, BASE_HEX, VALS(vals_priority), 0x00,\n\t\t\"Priority of the message.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_read_reply,\n\t    {   \"X-Mms-Read-Reply\", \"mmse.read_reply\",\n\t\tFT_UINT8, BASE_HEX, VALS(vals_yes_no), 0x00,\n\t\t\"Whether a read report from every recipient is wanted.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_read_report,\n\t    {   \"X-Mms-Read-Report\", \"mmse.read_report\",\n\t\tFT_UINT8, BASE_HEX, VALS(vals_yes_no), 0x00,\n\t\t\"Whether a read report from every recipient is wanted.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_report_allowed,\n\t    {   \"X-Mms-Report-Allowed\", \"mmse.report_allowed\",\n\t\tFT_UINT8, BASE_HEX, VALS(vals_yes_no), 0x00,\n\t\t\"Sending of delivery report allowed or not.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_response_status,\n\t    {   \"Response-Status\", \"mmse.response_status\",\n\t\tFT_UINT8, BASE_HEX, VALS(vals_response_status), 0x00,\n\t\t\"MMS-specific result of a message submission or retrieval.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_response_text,\n\t    {   \"Response-Text\", \"mmse.response_text\",\n\t\tFT_STRING, BASE_NONE, NULL, 0x00,\n\t\t\"Additional information on MMS-specific result.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_sender_visibility,\n\t    {   \"Sender-Visibility\", \"mmse.sender_visibility\",\n\t\tFT_UINT8, BASE_HEX, VALS(vals_sender_visibility), 0x00,\n\t\t\"Disclose sender identity to receiver or not.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_status,\n\t    {   \"Status\", \"mmse.status\",\n\t\tFT_UINT8, BASE_HEX, VALS(vals_message_status), 0x00,\n\t\t\"Current status of the message.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_subject,\n\t    {   \"Subject\", \"mmse.subject\",\n\t\tFT_STRING, BASE_NONE, NULL, 0x00,\n\t\t\"Subject of the message.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_to,\n\t    {   \"To\", \"mmse.to\",\n\t\tFT_STRING, BASE_NONE, NULL, 0x00,\n\t\t\"Recipient(s) of the message.\",\n\t\tHFILL\n\t    }\n\t},\n#if 0\n\t{   &hf_mmse_content_type,\n\t    {   \"Data\", \"mmse.content_type\",\n\t\tFT_NONE, BASE_NONE, NULL, 0x00,\n\t\t\"Media content of the message.\",\n\t\tHFILL\n\t    }\n\t},\n#endif\n\t{   &hf_mmse_ffheader,\n\t    {   \"Free format (not encoded) header\", \"mmse.ffheader\",\n\t\tFT_STRING, BASE_NONE, NULL, 0x00,\n\t\t\"Application header without corresponding encoding.\",\n\t\tHFILL\n\t    }\n\t},\n\t/* MMSE 1.1 */\n\t{   &hf_mmse_retrieve_status,\n\t    {   \"X-Mms-Retrieve-Status\", \"mmse.retrieve_status\",\n\t\tFT_UINT8, BASE_HEX, VALS(vals_retrieve_status), 0x00,\n\t\t\"MMS-specific result of a message retrieval.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_retrieve_text,\n\t    {   \"X-Mms-Retrieve-Text\", \"mmse.retrieve_text\",\n\t\tFT_STRING, BASE_NONE, NULL, 0x00,\n\t\t\"Status text of a MMS message retrieval.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_read_status,\n\t    {   \"X-Mms-Read-Status\", \"mmse.read_status\",\n\t\tFT_UINT8, BASE_HEX, VALS(vals_read_status), 0x00,\n\t\t\"MMS-specific message read status.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_reply_charging,\n\t    {   \"X-Mms-Reply-Charging\", \"mmse.reply_charging\",\n\t\tFT_UINT8, BASE_HEX, VALS(vals_reply_charging), 0x00,\n\t\t\"MMS-specific message reply charging method.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_reply_charging_deadline_abs,\n\t    {   \"X-Mms-Reply-Charging-Deadline\", \"mmse.reply_charging_deadline.abs\",\n\t\tFT_ABSOLUTE_TIME, ABSOLUTE_TIME_LOCAL, NULL, 0x00,\n\t\t\"The latest time of the recipient(s) to submit the Reply MM.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_reply_charging_deadline_rel,\n\t    {   \"X-Mms-Reply-Charging-Deadline\", \"mmse.reply_charging_deadline.rel\",\n\t\tFT_RELATIVE_TIME, BASE_NONE, NULL, 0x00,\n\t\t\"The latest time of the recipient(s) to submit the Reply MM.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_reply_charging_id,\n\t    {   \"X-Mms-Reply-Charging-Id\", \"mmse.reply_charging_id\",\n\t\tFT_STRING, BASE_NONE, NULL, 0x00,\n\t\t\"Unique reply charging identification of the message.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_reply_charging_size,\n\t    {   \"X-Mms-Reply-Charging-Size\", \"mmse.reply_charging_size\",\n\t\tFT_UINT32, BASE_DEC, NULL, 0x00,\n\t\t\"The size of the reply charging in octets.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_prev_sent_by,\n\t    {   \"X-Mms-Previously-Sent-By\", \"mmse.previously_sent_by\",\n    \t\tFT_STRING, BASE_NONE, NULL, 0x00,\n    \t\t\"Indicates that the MM has been previously sent by this user.\",\n    \t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_prev_sent_by_fwd_count,\n\t    {   \"Forward Count\", \"mmse.previously_sent_by.forward_count\",\n\t\tFT_UINT32, BASE_DEC, NULL, 0x00,\n\t\t\"Forward count of the previously sent MM.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_prev_sent_by_address,\n\t    {   \"Address\", \"mmse.previously_sent_by.address\",\n    \t\tFT_STRING, BASE_NONE, NULL, 0x00,\n    \t\t\"Indicates from whom the MM has been previously sent.\",\n    \t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_prev_sent_date,\n\t    {   \"X-Mms-Previously-Sent-Date\", \"mmse.previously_sent_date\",\n    \t\tFT_STRING, BASE_NONE, NULL, 0x00,\n    \t\t\"Indicates the date that the MM has been previously sent.\",\n    \t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_prev_sent_date_fwd_count,\n\t    {   \"Forward Count\", \"mmse.previously_sent_date.forward_count\",\n\t\tFT_UINT32, BASE_DEC, NULL, 0x00,\n\t\t\"Forward count of the previously sent MM.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_prev_sent_date_date,\n\t    {   \"Date\", \"mmse.previously_sent_date.date\",\n\t\tFT_STRING, BASE_NONE, NULL, 0x00,\n\t\t\"Time when the MM has been previously sent.\",\n    \t\tHFILL\n\t    }\n\t},\n\n\n\n    };\n    /* Setup protocol subtree array */\n    static gint *ett[] = {\n\t&ett_mmse,\n\t&ett_mmse_hdr_details,\n    };\n\n    /* Register the protocol name and description */\n    proto_mmse = proto_register_protocol(\"MMS Message Encapsulation\",\n\t\t\t\t\t \"MMSE\", \"mmse\");\n\n    /* Required function calls to register header fields and subtrees used */\n    proto_register_field_array(proto_mmse, hf, array_length(hf));\n    proto_register_subtree_array(ett, array_length(ett));\n}",
        "func": "void\nproto_register_mmse(void)\n{\n    /* Setup list of header fields  See Section 1.6.1 for details\t*/\n    static hf_register_info hf[] = {\n\t{   &hf_mmse_message_type,\n\t    {   \"X-Mms-Message-Type\", \"mmse.message_type\",\n\t\tFT_UINT8, BASE_HEX, VALS(vals_message_type), 0x00,\n\t\t\"Specifies the transaction type. Effectively defines PDU.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_transaction_id,\n\t    {   \"X-Mms-Transaction-ID\", \"mmse.transaction_id\",\n\t\tFT_STRING, BASE_NONE, NULL, 0x00,\n\t\t\"A unique identifier for this transaction. Identifies request and corresponding response only.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_mms_version,\n\t    {   \"X-Mms-MMS-Version\", \"mmse.mms_version\",\n\t\tFT_STRING, BASE_NONE, NULL, 0x00,\n\t\t\"Version of the protocol used.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_bcc,\n\t    {   \"Bcc\", \"mmse.bcc\",\n\t\tFT_STRING, BASE_NONE, NULL, 0x00,\n\t\t\"Blind carbon copy.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_cc,\n\t    {   \"Cc\", \"mmse.cc\",\n\t\tFT_STRING, BASE_NONE, NULL, 0x00,\n\t\t\"Carbon copy.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_content_location,\n\t    {   \"X-Mms-Content-Location\", \"mmse.content_location\",\n\t\tFT_STRING, BASE_NONE, NULL, 0x00,\n\t\t\"Defines the location of the message.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_date,\n\t    {   \"Date\", \"mmse.date\",\n\t\tFT_ABSOLUTE_TIME, ABSOLUTE_TIME_LOCAL, NULL, 0x00,\n\t\t\"Arrival timestamp of the message or sending timestamp.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_delivery_report,\n\t    {   \"X-Mms-Delivery-Report\", \"mmse.delivery_report\",\n\t\tFT_UINT8, BASE_HEX, VALS(vals_yes_no), 0x00,\n\t\t\"Whether a report of message delivery is wanted or not.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_delivery_time_abs,\n\t    {   \"X-Mms-Delivery-Time\", \"mmse.delivery_time.abs\",\n\t\tFT_ABSOLUTE_TIME, ABSOLUTE_TIME_LOCAL, NULL, 0x00,\n\t\t\"The time at which message delivery is desired.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_delivery_time_rel,\n\t    {   \"X-Mms-Delivery-Time\", \"mmse.delivery_time.rel\",\n\t\tFT_RELATIVE_TIME, BASE_NONE, NULL, 0x00,\n\t\t\"The desired message delivery delay.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_expiry_abs,\n\t    {   \"X-Mms-Expiry\", \"mmse.expiry.abs\",\n\t\tFT_ABSOLUTE_TIME, ABSOLUTE_TIME_LOCAL, NULL, 0x00,\n\t\t\"Time when message expires and need not be delivered anymore.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_expiry_rel,\n\t    {   \"X-Mms-Expiry\", \"mmse.expiry.rel\",\n\t\tFT_RELATIVE_TIME, BASE_NONE, NULL, 0x00,\n\t\t\"Delay before message expires and need not be delivered anymore.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_from,\n\t    {   \"From\", \"mmse.from\",\n\t\tFT_STRING, BASE_NONE, NULL, 0x00,\n\t\t\"Address of the message sender.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_message_class_id,\n\t    {   \"X-Mms-Message-Class\", \"mmse.message_class.id\",\n\t\tFT_UINT8, BASE_HEX, VALS(vals_message_class), 0x00,\n\t\t\"Of what category is the message.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_message_class_str,\n\t    {   \"X-Mms-Message-Class\", \"mmse.message_class.str\",\n\t\tFT_STRING, BASE_NONE, NULL, 0x00,\n\t\t\"Of what category is the message.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_message_id,\n\t    {   \"Message-Id\", \"mmse.message_id\",\n\t\tFT_STRING, BASE_NONE, NULL, 0x00,\n\t\t\"Unique identification of the message.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_message_size,\n\t    {   \"X-Mms-Message-Size\", \"mmse.message_size\",\n\t\tFT_UINT32, BASE_DEC, NULL, 0x00,\n\t\t\"The size of the message in octets.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_priority,\n\t    {   \"X-Mms-Priority\", \"mmse.priority\",\n\t\tFT_UINT8, BASE_HEX, VALS(vals_priority), 0x00,\n\t\t\"Priority of the message.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_read_reply,\n\t    {   \"X-Mms-Read-Reply\", \"mmse.read_reply\",\n\t\tFT_UINT8, BASE_HEX, VALS(vals_yes_no), 0x00,\n\t\t\"Whether a read report from every recipient is wanted.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_read_report,\n\t    {   \"X-Mms-Read-Report\", \"mmse.read_report\",\n\t\tFT_UINT8, BASE_HEX, VALS(vals_yes_no), 0x00,\n\t\t\"Whether a read report from every recipient is wanted.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_report_allowed,\n\t    {   \"X-Mms-Report-Allowed\", \"mmse.report_allowed\",\n\t\tFT_UINT8, BASE_HEX, VALS(vals_yes_no), 0x00,\n\t\t\"Sending of delivery report allowed or not.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_response_status,\n\t    {   \"Response-Status\", \"mmse.response_status\",\n\t\tFT_UINT8, BASE_HEX, VALS(vals_response_status), 0x00,\n\t\t\"MMS-specific result of a message submission or retrieval.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_response_text,\n\t    {   \"Response-Text\", \"mmse.response_text\",\n\t\tFT_STRING, BASE_NONE, NULL, 0x00,\n\t\t\"Additional information on MMS-specific result.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_sender_visibility,\n\t    {   \"Sender-Visibility\", \"mmse.sender_visibility\",\n\t\tFT_UINT8, BASE_HEX, VALS(vals_sender_visibility), 0x00,\n\t\t\"Disclose sender identity to receiver or not.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_status,\n\t    {   \"Status\", \"mmse.status\",\n\t\tFT_UINT8, BASE_HEX, VALS(vals_message_status), 0x00,\n\t\t\"Current status of the message.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_subject,\n\t    {   \"Subject\", \"mmse.subject\",\n\t\tFT_STRING, BASE_NONE, NULL, 0x00,\n\t\t\"Subject of the message.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_to,\n\t    {   \"To\", \"mmse.to\",\n\t\tFT_STRING, BASE_NONE, NULL, 0x00,\n\t\t\"Recipient(s) of the message.\",\n\t\tHFILL\n\t    }\n\t},\n#if 0\n\t{   &hf_mmse_content_type,\n\t    {   \"Data\", \"mmse.content_type\",\n\t\tFT_NONE, BASE_NONE, NULL, 0x00,\n\t\t\"Media content of the message.\",\n\t\tHFILL\n\t    }\n\t},\n#endif\n\t{   &hf_mmse_ffheader,\n\t    {   \"Free format (not encoded) header\", \"mmse.ffheader\",\n\t\tFT_STRING, BASE_NONE, NULL, 0x00,\n\t\t\"Application header without corresponding encoding.\",\n\t\tHFILL\n\t    }\n\t},\n\t/* MMSE 1.1 */\n\t{   &hf_mmse_retrieve_status,\n\t    {   \"X-Mms-Retrieve-Status\", \"mmse.retrieve_status\",\n\t\tFT_UINT8, BASE_HEX, VALS(vals_retrieve_status), 0x00,\n\t\t\"MMS-specific result of a message retrieval.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_retrieve_text,\n\t    {   \"X-Mms-Retrieve-Text\", \"mmse.retrieve_text\",\n\t\tFT_STRING, BASE_NONE, NULL, 0x00,\n\t\t\"Status text of a MMS message retrieval.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_read_status,\n\t    {   \"X-Mms-Read-Status\", \"mmse.read_status\",\n\t\tFT_UINT8, BASE_HEX, VALS(vals_read_status), 0x00,\n\t\t\"MMS-specific message read status.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_reply_charging,\n\t    {   \"X-Mms-Reply-Charging\", \"mmse.reply_charging\",\n\t\tFT_UINT8, BASE_HEX, VALS(vals_reply_charging), 0x00,\n\t\t\"MMS-specific message reply charging method.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_reply_charging_deadline_abs,\n\t    {   \"X-Mms-Reply-Charging-Deadline\", \"mmse.reply_charging_deadline.abs\",\n\t\tFT_ABSOLUTE_TIME, ABSOLUTE_TIME_LOCAL, NULL, 0x00,\n\t\t\"The latest time of the recipient(s) to submit the Reply MM.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_reply_charging_deadline_rel,\n\t    {   \"X-Mms-Reply-Charging-Deadline\", \"mmse.reply_charging_deadline.rel\",\n\t\tFT_RELATIVE_TIME, BASE_NONE, NULL, 0x00,\n\t\t\"The latest time of the recipient(s) to submit the Reply MM.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_reply_charging_id,\n\t    {   \"X-Mms-Reply-Charging-Id\", \"mmse.reply_charging_id\",\n\t\tFT_STRING, BASE_NONE, NULL, 0x00,\n\t\t\"Unique reply charging identification of the message.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_reply_charging_size,\n\t    {   \"X-Mms-Reply-Charging-Size\", \"mmse.reply_charging_size\",\n\t\tFT_UINT32, BASE_DEC, NULL, 0x00,\n\t\t\"The size of the reply charging in octets.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_prev_sent_by,\n\t    {   \"X-Mms-Previously-Sent-By\", \"mmse.previously_sent_by\",\n    \t\tFT_STRING, BASE_NONE, NULL, 0x00,\n    \t\t\"Indicates that the MM has been previously sent by this user.\",\n    \t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_prev_sent_by_fwd_count,\n\t    {   \"Forward Count\", \"mmse.previously_sent_by.forward_count\",\n\t\tFT_UINT32, BASE_DEC, NULL, 0x00,\n\t\t\"Forward count of the previously sent MM.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_prev_sent_by_address,\n\t    {   \"Address\", \"mmse.previously_sent_by.address\",\n    \t\tFT_STRING, BASE_NONE, NULL, 0x00,\n    \t\t\"Indicates from whom the MM has been previously sent.\",\n    \t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_prev_sent_date,\n\t    {   \"X-Mms-Previously-Sent-Date\", \"mmse.previously_sent_date\",\n    \t\tFT_STRING, BASE_NONE, NULL, 0x00,\n    \t\t\"Indicates the date that the MM has been previously sent.\",\n    \t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_prev_sent_date_fwd_count,\n\t    {   \"Forward Count\", \"mmse.previously_sent_date.forward_count\",\n\t\tFT_UINT32, BASE_DEC, NULL, 0x00,\n\t\t\"Forward count of the previously sent MM.\",\n\t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_prev_sent_date_date,\n\t    {   \"Date\", \"mmse.previously_sent_date.date\",\n\t\tFT_STRING, BASE_NONE, NULL, 0x00,\n\t\t\"Time when the MM has been previously sent.\",\n    \t\tHFILL\n\t    }\n\t},\n\t{   &hf_mmse_header_uint,\n\t    {   \"Header Uint Value\", \"mmse.header.uint\",\n\t\tFT_UINT8, BASE_DEC, NULL, 0x00, NULL, HFILL\n\t    }\n\t},\n\t{   &hf_mmse_header_string,\n\t    {   \"Header String Value\", \"mmse.header.string\",\n\t\tFT_STRING, BASE_NONE, NULL, 0x00, NULL, HFILL\n\t    }\n\t},\n\t{   &hf_mmse_header_bytes,\n\t    {   \"Header Byte array\", \"mmse.header.bytes\",\n\t\tFT_BYTES, BASE_NONE, NULL, 0x00, NULL, HFILL\n\t    }\n\t}\n\n\n    };\n    /* Setup protocol subtree array */\n    static gint *ett[] = {\n\t&ett_mmse,\n\t&ett_mmse_hdr_details,\n    };\n\n    /* Register the protocol name and description */\n    proto_mmse = proto_register_protocol(\"MMS Message Encapsulation\",\n\t\t\t\t\t \"MMSE\", \"mmse\");\n\n    /* Required function calls to register header fields and subtrees used */\n    proto_register_field_array(proto_mmse, hf, array_length(hf));\n    proto_register_subtree_array(ett, array_length(ett));\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -307,7 +307,21 @@\n     \t\tHFILL\n \t    }\n \t},\n-\n+\t{   &hf_mmse_header_uint,\n+\t    {   \"Header Uint Value\", \"mmse.header.uint\",\n+\t\tFT_UINT8, BASE_DEC, NULL, 0x00, NULL, HFILL\n+\t    }\n+\t},\n+\t{   &hf_mmse_header_string,\n+\t    {   \"Header String Value\", \"mmse.header.string\",\n+\t\tFT_STRING, BASE_NONE, NULL, 0x00, NULL, HFILL\n+\t    }\n+\t},\n+\t{   &hf_mmse_header_bytes,\n+\t    {   \"Header Byte array\", \"mmse.header.bytes\",\n+\t\tFT_BYTES, BASE_NONE, NULL, 0x00, NULL, HFILL\n+\t    }\n+\t}\n \n \n     };",
        "diff_line_info": {
            "deleted_lines": [
                ""
            ],
            "added_lines": [
                "\t{   &hf_mmse_header_uint,",
                "\t    {   \"Header Uint Value\", \"mmse.header.uint\",",
                "\t\tFT_UINT8, BASE_DEC, NULL, 0x00, NULL, HFILL",
                "\t    }",
                "\t},",
                "\t{   &hf_mmse_header_string,",
                "\t    {   \"Header String Value\", \"mmse.header.string\",",
                "\t\tFT_STRING, BASE_NONE, NULL, 0x00, NULL, HFILL",
                "\t    }",
                "\t},",
                "\t{   &hf_mmse_header_bytes,",
                "\t    {   \"Header Byte array\", \"mmse.header.bytes\",",
                "\t\tFT_BYTES, BASE_NONE, NULL, 0x00, NULL, HFILL",
                "\t    }",
                "\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-6508",
        "func_name": "wireshark/rlc_decode_li",
        "description": "epan/dissectors/packet-rlc.c in the RLC dissector in Wireshark 1.12.x before 1.12.13 and 2.x before 2.0.5 uses an incorrect integer data type, which allows remote attackers to cause a denial of service (large loop) via a crafted packet.",
        "git_url": "https://github.com/wireshark/wireshark/commit/6cf9616df68a4db7e436bb77392586ff9ad84feb",
        "commit_title": "RLC: fix a variable overflow in rlc_decode_li function",
        "commit_text": " Bug: 12660",
        "func_before": "static gint16\nrlc_decode_li(enum rlc_mode mode, tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree,\n          struct rlc_li *li, guint8 max_li, gboolean li_on_2_bytes)\n{\n    guint8      ext, hdr_len, offs  = 0, num_li = 0, li_offs;\n    guint16     next_bytes, prev_li = 0;\n    proto_item *malformed;\n    guint16     total_len;\n\n    switch (mode) {\n        case RLC_AM:\n            offs = 1;\n            break;\n        case RLC_UM:\n            offs = 0;\n            break;\n        case RLC_TM:\n            /* fall through */\n        case RLC_UNKNOWN_MODE:\n        default:\n            return -1;\n    }\n    hdr_len = offs;\n    /* calculate header length */\n    ext = tvb_get_guint8(tvb, hdr_len++) & 0x01;\n    while (ext) {\n        next_bytes = li_on_2_bytes ? tvb_get_ntohs(tvb, hdr_len) : tvb_get_guint8(tvb, hdr_len);\n        ext = next_bytes & 0x01;\n        hdr_len += li_on_2_bytes ? 2 : 1;\n    }\n    total_len = tvb_captured_length_remaining(tvb, hdr_len);\n\n    /* do actual evaluation of LIs */\n    ext = tvb_get_guint8(tvb, offs++) & 0x01;\n    li_offs = offs;\n    while (ext) {\n        if (li_on_2_bytes) {\n            next_bytes = tvb_get_ntohs(tvb, offs);\n            offs += 2;\n        } else {\n            next_bytes = tvb_get_guint8(tvb, offs++);\n        }\n        ext = next_bytes & 0x01;\n        li[num_li].ext = ext;\n        li[num_li].li = next_bytes >> 1;\n\n        if (li_on_2_bytes) {\n            switch (li[num_li].li) {\n                case 0x0000: /* previous segment was the last one */\n                case 0x7ffb: /* previous PDU contains last segment of SDU (minus last byte) */\n                case 0x7ffe: /* contains piggybacked STATUS in AM or segment in UM */\n                case 0x7fff: /* padding */\n                    li[num_li].len = 0;\n                    break;\n                case 0x7ffa: /* contains exactly one SDU (minus last byte), UM only */\n                case 0x7ffc: /* start of a new SDU, UM only */\n                case 0x7ffd: /* contains exactly one SDU, UM only */\n                    if (mode == RLC_UM) {\n                        /* valid for UM */\n                        li[num_li].len = 0;\n                        break;\n                    }\n                    /*invalid for AM */\n                    /* add malformed LI for investigation */\n                    malformed = tree_add_li(mode, &li[num_li], num_li, li_offs, li_on_2_bytes, tvb, tree);\n                    expert_add_info(pinfo, malformed, &ei_rlc_li_reserved);\n                    return -1; /* just give up on this */\n                default:\n                    /* since the LI is an offset (from the end of the header), it\n                    * may not be larger than the total remaining length and no\n                    * LI may be smaller than its preceding one\n                    */\n                    if (((li[num_li].li > total_len) && !global_rlc_headers_expected)\n                        || (li[num_li].li < prev_li)) {\n                        /* add malformed LI for investigation */\n                        malformed = tree_add_li(mode, &li[num_li], num_li, li_offs, li_on_2_bytes, tvb, tree);\n                        expert_add_info(pinfo, malformed, &ei_rlc_li_incorrect_warn);\n                        return -1; /* just give up on this */\n                    }\n                    li[num_li].len = li[num_li].li - prev_li;\n                    prev_li = li[num_li].li;\n            }\n        } else {\n            switch (li[num_li].li) {\n                case 0x00: /* previous segment was the last one */\n                case 0x7e: /* contains piggybacked STATUS in AM or segment in UM */\n                case 0x7f: /* padding */\n                    li[num_li].len = 0;\n                    break;\n                case 0x7c: /* start of a new SDU, UM only */\n                case 0x7d: /* contains exactly one SDU, UM only */\n                    if (mode == RLC_UM) {\n                        /* valid for UM */\n                        li[num_li].len = 0;\n                        break;\n                    }\n                    /*invalid for AM */\n                    /* add malformed LI for investigation */\n                    malformed = tree_add_li(mode, &li[num_li], num_li, li_offs, li_on_2_bytes, tvb, tree);\n                    expert_add_info(pinfo, malformed, &ei_rlc_li_reserved);\n                    return -1; /* just give up on this */\n                default:\n                    /* since the LI is an offset (from the end of the header), it\n                    * may not be larger than the total remaining length and no\n                    * LI may be smaller than its preceding one\n                    */\n                    li[num_li].len = li[num_li].li - prev_li;\n                    if (((li[num_li].li > total_len) && !global_rlc_headers_expected)\n                        || (li[num_li].li < prev_li)) {\n                        /* add malformed LI for investigation */\n                        malformed = tree_add_li(mode, &li[num_li], num_li, li_offs, li_on_2_bytes, tvb, tree);\n                        expert_add_info_format(pinfo, malformed, &ei_rlc_li_incorrect_mal, \"Incorrect LI value 0x%x\", li[num_li].li);\n                        return -1; /* just give up on this */\n                    }\n                    prev_li = li[num_li].li;\n            }\n        }\n        li[num_li].tree = tree_add_li(mode, &li[num_li], num_li, li_offs, li_on_2_bytes, tvb, tree);\n        num_li++;\n\n        if (num_li >= max_li) {\n            /* OK, so this is not really a malformed packet, but for now,\n            * we will treat it as such, so that it is marked in some way */\n            expert_add_info(pinfo, li[num_li-1].tree, &ei_rlc_li_too_many);\n            return -1;\n        }\n    }\n    return num_li;\n}",
        "func": "static gint16\nrlc_decode_li(enum rlc_mode mode, tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree,\n          struct rlc_li *li, guint8 max_li, gboolean li_on_2_bytes)\n{\n    guint32     hdr_len, offs = 0, li_offs;\n    guint8      ext, num_li = 0;\n    guint16     next_bytes, prev_li = 0;\n    proto_item *malformed;\n    guint16     total_len;\n\n    switch (mode) {\n        case RLC_AM:\n            offs = 1;\n            break;\n        case RLC_UM:\n            offs = 0;\n            break;\n        case RLC_TM:\n            /* fall through */\n        case RLC_UNKNOWN_MODE:\n        default:\n            return -1;\n    }\n    hdr_len = offs;\n    /* calculate header length */\n    ext = tvb_get_guint8(tvb, hdr_len++) & 0x01;\n    while (ext) {\n        next_bytes = li_on_2_bytes ? tvb_get_ntohs(tvb, hdr_len) : tvb_get_guint8(tvb, hdr_len);\n        ext = next_bytes & 0x01;\n        hdr_len += li_on_2_bytes ? 2 : 1;\n    }\n    total_len = tvb_captured_length_remaining(tvb, hdr_len);\n\n    /* do actual evaluation of LIs */\n    ext = tvb_get_guint8(tvb, offs++) & 0x01;\n    li_offs = offs;\n    while (ext) {\n        if (li_on_2_bytes) {\n            next_bytes = tvb_get_ntohs(tvb, offs);\n            offs += 2;\n        } else {\n            next_bytes = tvb_get_guint8(tvb, offs++);\n        }\n        ext = next_bytes & 0x01;\n        li[num_li].ext = ext;\n        li[num_li].li = next_bytes >> 1;\n\n        if (li_on_2_bytes) {\n            switch (li[num_li].li) {\n                case 0x0000: /* previous segment was the last one */\n                case 0x7ffb: /* previous PDU contains last segment of SDU (minus last byte) */\n                case 0x7ffe: /* contains piggybacked STATUS in AM or segment in UM */\n                case 0x7fff: /* padding */\n                    li[num_li].len = 0;\n                    break;\n                case 0x7ffa: /* contains exactly one SDU (minus last byte), UM only */\n                case 0x7ffc: /* start of a new SDU, UM only */\n                case 0x7ffd: /* contains exactly one SDU, UM only */\n                    if (mode == RLC_UM) {\n                        /* valid for UM */\n                        li[num_li].len = 0;\n                        break;\n                    }\n                    /*invalid for AM */\n                    /* add malformed LI for investigation */\n                    malformed = tree_add_li(mode, &li[num_li], num_li, li_offs, li_on_2_bytes, tvb, tree);\n                    expert_add_info(pinfo, malformed, &ei_rlc_li_reserved);\n                    return -1; /* just give up on this */\n                default:\n                    /* since the LI is an offset (from the end of the header), it\n                    * may not be larger than the total remaining length and no\n                    * LI may be smaller than its preceding one\n                    */\n                    if (((li[num_li].li > total_len) && !global_rlc_headers_expected)\n                        || (li[num_li].li < prev_li)) {\n                        /* add malformed LI for investigation */\n                        malformed = tree_add_li(mode, &li[num_li], num_li, li_offs, li_on_2_bytes, tvb, tree);\n                        expert_add_info(pinfo, malformed, &ei_rlc_li_incorrect_warn);\n                        return -1; /* just give up on this */\n                    }\n                    li[num_li].len = li[num_li].li - prev_li;\n                    prev_li = li[num_li].li;\n            }\n        } else {\n            switch (li[num_li].li) {\n                case 0x00: /* previous segment was the last one */\n                case 0x7e: /* contains piggybacked STATUS in AM or segment in UM */\n                case 0x7f: /* padding */\n                    li[num_li].len = 0;\n                    break;\n                case 0x7c: /* start of a new SDU, UM only */\n                case 0x7d: /* contains exactly one SDU, UM only */\n                    if (mode == RLC_UM) {\n                        /* valid for UM */\n                        li[num_li].len = 0;\n                        break;\n                    }\n                    /*invalid for AM */\n                    /* add malformed LI for investigation */\n                    malformed = tree_add_li(mode, &li[num_li], num_li, li_offs, li_on_2_bytes, tvb, tree);\n                    expert_add_info(pinfo, malformed, &ei_rlc_li_reserved);\n                    return -1; /* just give up on this */\n                default:\n                    /* since the LI is an offset (from the end of the header), it\n                    * may not be larger than the total remaining length and no\n                    * LI may be smaller than its preceding one\n                    */\n                    li[num_li].len = li[num_li].li - prev_li;\n                    if (((li[num_li].li > total_len) && !global_rlc_headers_expected)\n                        || (li[num_li].li < prev_li)) {\n                        /* add malformed LI for investigation */\n                        malformed = tree_add_li(mode, &li[num_li], num_li, li_offs, li_on_2_bytes, tvb, tree);\n                        expert_add_info_format(pinfo, malformed, &ei_rlc_li_incorrect_mal, \"Incorrect LI value 0x%x\", li[num_li].li);\n                        return -1; /* just give up on this */\n                    }\n                    prev_li = li[num_li].li;\n            }\n        }\n        li[num_li].tree = tree_add_li(mode, &li[num_li], num_li, li_offs, li_on_2_bytes, tvb, tree);\n        num_li++;\n\n        if (num_li >= max_li) {\n            /* OK, so this is not really a malformed packet, but for now,\n            * we will treat it as such, so that it is marked in some way */\n            expert_add_info(pinfo, li[num_li-1].tree, &ei_rlc_li_too_many);\n            return -1;\n        }\n    }\n    return num_li;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,7 +2,8 @@\n rlc_decode_li(enum rlc_mode mode, tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree,\n           struct rlc_li *li, guint8 max_li, gboolean li_on_2_bytes)\n {\n-    guint8      ext, hdr_len, offs  = 0, num_li = 0, li_offs;\n+    guint32     hdr_len, offs = 0, li_offs;\n+    guint8      ext, num_li = 0;\n     guint16     next_bytes, prev_li = 0;\n     proto_item *malformed;\n     guint16     total_len;",
        "diff_line_info": {
            "deleted_lines": [
                "    guint8      ext, hdr_len, offs  = 0, num_li = 0, li_offs;"
            ],
            "added_lines": [
                "    guint32     hdr_len, offs = 0, li_offs;",
                "    guint8      ext, num_li = 0;"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-6508",
        "func_name": "wireshark/tree_add_li",
        "description": "epan/dissectors/packet-rlc.c in the RLC dissector in Wireshark 1.12.x before 1.12.13 and 2.x before 2.0.5 uses an incorrect integer data type, which allows remote attackers to cause a denial of service (large loop) via a crafted packet.",
        "git_url": "https://github.com/wireshark/wireshark/commit/6cf9616df68a4db7e436bb77392586ff9ad84feb",
        "commit_title": "RLC: fix a variable overflow in rlc_decode_li function",
        "commit_text": " Bug: 12660",
        "func_before": "static proto_tree *\ntree_add_li(enum rlc_mode mode, struct rlc_li *li, guint8 li_idx, guint8 hdr_offs,\n        gboolean li_is_on_2_bytes, tvbuff_t *tvb, proto_tree *tree)\n{\n    proto_item *root_ti, *ti;\n    proto_tree *li_tree;\n    guint8      li_offs;\n    guint64     length;\n\n    if (!tree) return NULL;\n\n    if (li_is_on_2_bytes) {\n        li_offs = hdr_offs + li_idx*2;\n        root_ti = proto_tree_add_item(tree, hf_rlc_li, tvb, li_offs, 2, ENC_NA);\n        li_tree = proto_item_add_subtree(root_ti, ett_rlc_frag);\n        ti = proto_tree_add_bits_ret_val(li_tree, hf_rlc_li_value, tvb, li_offs*8, 15, &length, ENC_BIG_ENDIAN);\n\n        switch (li->li) {\n            case 0x0000:\n                add_description(root_ti, ti, \"The previous RLC PDU was exactly filled with the last segment of an RLC SDU and there is no LI that indicates the end of the RLC SDU in the previous RLC PDU\");\n                break;\n            case 0x7ffa:\n                if (mode == RLC_UM) {\n                    add_description(root_ti, ti, \"The first data octet in this RLC PDU is the first octet of an RLC SDU and the second last octet in this RLC PDU is the last octet of the same RLC SDU. The remaining octet in the RLC PDU is ignored\");\n                } else {\n                    add_description(root_ti, ti, \"Reserved\");\n                }\n                break;\n            case 0x7ffb:\n                add_description(root_ti, ti, \"The second last octet in the previous RLC PDU is the last octet of an RLC SDU and there is no LI to indicate the end of SDU. The remaining octet in the previous RLC PDU is ignored\");\n                break;\n            case 0x7ffc:\n                if (mode == RLC_UM) {\n                    add_description(root_ti, ti, \"The first data octet in this RLC PDU is the first octet of an RLC SDU\");\n                } else {\n                    add_description(root_ti, ti, \"Reserved\");\n                }\n                break;\n            case 0x7ffd:\n                if (mode == RLC_UM) {\n                    add_description(root_ti, ti, \"The first data octet in this RLC PDU is the first octet of an RLC SDU and the last octet in this RLC PDU is the last octet of the same RLC SDU\");\n                } else {\n                    add_description(root_ti, ti, \"Reserved\");\n                }\n                break;\n            case 0x7ffe:\n                if (mode == RLC_UM) {\n                    add_description(root_ti, ti, \"The RLC PDU contains a segment of an SDU but neither the first octet nor the last octet of this SDU\");\n                } else {\n                    add_description(root_ti, ti, \"The rest of the RLC PDU includes a piggybacked STATUS PDU\");\n                }\n                break;\n            case 0x7fff:\n                add_description(root_ti, ti, \"The rest of the RLC PDU is padding\");\n                break;\n\n            default:\n                add_description(root_ti, ti, \"length=%u\", (guint16)length);\n                break;\n        }\n        proto_tree_add_bits_item(li_tree, hf_rlc_li_ext, tvb, li_offs*8+15, 1, ENC_BIG_ENDIAN);\n    } else {\n        li_offs = hdr_offs + li_idx;\n        root_ti = proto_tree_add_item(tree, hf_rlc_li, tvb, li_offs, 1, ENC_NA);\n        li_tree = proto_item_add_subtree(root_ti, ett_rlc_frag);\n        ti = proto_tree_add_bits_ret_val(li_tree, hf_rlc_li_value, tvb, li_offs*8, 7, &length, ENC_BIG_ENDIAN);\n        switch (li->li) {\n            case 0x00:\n                add_description(root_ti, ti, \"The previous RLC PDU was exactly filled with the last segment of an RLC SDU and there is no LI that indicates the end of the RLC SDU in the previous RLC PDU\");\n                break;\n            case 0x7c:\n                if (mode == RLC_UM) {\n                    add_description(root_ti, ti, \"The first data octet in this RLC PDU is the first octet of an RLC SDU\");\n                } else {\n                    add_description(root_ti, ti, \"Reserved\");\n                }\n                break;\n            case 0x7d:\n                if (mode == RLC_UM) {\n                    add_description(root_ti, ti, \"The first data octet in this RLC PDU is the first octet of an RLC SDU and the last octet in this RLC PDU is the last octet of the same RLC SDU\");\n                } else {\n                    add_description(root_ti, ti, \"Reserved\");\n                }\n                break;\n            case 0x7e:\n                if (mode == RLC_UM) {\n                    add_description(root_ti, ti, \"The RLC PDU contains a segment of an SDU but neither the first octet nor the last octet of this SDU\");\n                } else {\n                    add_description(root_ti, ti, \"The rest of the RLC PDU includes a piggybacked STATUS PDU\");\n                }\n                break;\n            case 0x7f:\n                add_description(root_ti, ti, \"The rest of the RLC PDU is padding\");\n                break;\n\n            default:\n                add_description(root_ti, ti, \"length=%u\", (guint16)length);\n                break;\n        }\n        proto_tree_add_bits_item(li_tree, hf_rlc_li_ext, tvb, li_offs*8+7, 1, ENC_BIG_ENDIAN);\n    }\n\n    if (li->len > 0) {\n        if (li->li > tvb_reported_length_remaining(tvb, hdr_offs)) return li_tree;\n        if (li->len > li->li) return li_tree;\n        ti = proto_tree_add_item(li_tree, hf_rlc_li_data, tvb, hdr_offs + li->li - li->len, li->len, ENC_NA);\n        PROTO_ITEM_SET_HIDDEN(ti);\n    }\n\n    return li_tree;\n}",
        "func": "static proto_tree *\ntree_add_li(enum rlc_mode mode, struct rlc_li *li, guint8 li_idx, guint32 hdr_offs,\n        gboolean li_is_on_2_bytes, tvbuff_t *tvb, proto_tree *tree)\n{\n    proto_item *root_ti, *ti;\n    proto_tree *li_tree;\n    guint32     li_offs;\n    guint64     length;\n\n    if (!tree) return NULL;\n\n    if (li_is_on_2_bytes) {\n        li_offs = hdr_offs + li_idx*2;\n        root_ti = proto_tree_add_item(tree, hf_rlc_li, tvb, li_offs, 2, ENC_NA);\n        li_tree = proto_item_add_subtree(root_ti, ett_rlc_frag);\n        ti = proto_tree_add_bits_ret_val(li_tree, hf_rlc_li_value, tvb, li_offs*8, 15, &length, ENC_BIG_ENDIAN);\n\n        switch (li->li) {\n            case 0x0000:\n                add_description(root_ti, ti, \"The previous RLC PDU was exactly filled with the last segment of an RLC SDU and there is no LI that indicates the end of the RLC SDU in the previous RLC PDU\");\n                break;\n            case 0x7ffa:\n                if (mode == RLC_UM) {\n                    add_description(root_ti, ti, \"The first data octet in this RLC PDU is the first octet of an RLC SDU and the second last octet in this RLC PDU is the last octet of the same RLC SDU. The remaining octet in the RLC PDU is ignored\");\n                } else {\n                    add_description(root_ti, ti, \"Reserved\");\n                }\n                break;\n            case 0x7ffb:\n                add_description(root_ti, ti, \"The second last octet in the previous RLC PDU is the last octet of an RLC SDU and there is no LI to indicate the end of SDU. The remaining octet in the previous RLC PDU is ignored\");\n                break;\n            case 0x7ffc:\n                if (mode == RLC_UM) {\n                    add_description(root_ti, ti, \"The first data octet in this RLC PDU is the first octet of an RLC SDU\");\n                } else {\n                    add_description(root_ti, ti, \"Reserved\");\n                }\n                break;\n            case 0x7ffd:\n                if (mode == RLC_UM) {\n                    add_description(root_ti, ti, \"The first data octet in this RLC PDU is the first octet of an RLC SDU and the last octet in this RLC PDU is the last octet of the same RLC SDU\");\n                } else {\n                    add_description(root_ti, ti, \"Reserved\");\n                }\n                break;\n            case 0x7ffe:\n                if (mode == RLC_UM) {\n                    add_description(root_ti, ti, \"The RLC PDU contains a segment of an SDU but neither the first octet nor the last octet of this SDU\");\n                } else {\n                    add_description(root_ti, ti, \"The rest of the RLC PDU includes a piggybacked STATUS PDU\");\n                }\n                break;\n            case 0x7fff:\n                add_description(root_ti, ti, \"The rest of the RLC PDU is padding\");\n                break;\n\n            default:\n                add_description(root_ti, ti, \"length=%u\", (guint16)length);\n                break;\n        }\n        proto_tree_add_bits_item(li_tree, hf_rlc_li_ext, tvb, li_offs*8+15, 1, ENC_BIG_ENDIAN);\n    } else {\n        li_offs = hdr_offs + li_idx;\n        root_ti = proto_tree_add_item(tree, hf_rlc_li, tvb, li_offs, 1, ENC_NA);\n        li_tree = proto_item_add_subtree(root_ti, ett_rlc_frag);\n        ti = proto_tree_add_bits_ret_val(li_tree, hf_rlc_li_value, tvb, li_offs*8, 7, &length, ENC_BIG_ENDIAN);\n        switch (li->li) {\n            case 0x00:\n                add_description(root_ti, ti, \"The previous RLC PDU was exactly filled with the last segment of an RLC SDU and there is no LI that indicates the end of the RLC SDU in the previous RLC PDU\");\n                break;\n            case 0x7c:\n                if (mode == RLC_UM) {\n                    add_description(root_ti, ti, \"The first data octet in this RLC PDU is the first octet of an RLC SDU\");\n                } else {\n                    add_description(root_ti, ti, \"Reserved\");\n                }\n                break;\n            case 0x7d:\n                if (mode == RLC_UM) {\n                    add_description(root_ti, ti, \"The first data octet in this RLC PDU is the first octet of an RLC SDU and the last octet in this RLC PDU is the last octet of the same RLC SDU\");\n                } else {\n                    add_description(root_ti, ti, \"Reserved\");\n                }\n                break;\n            case 0x7e:\n                if (mode == RLC_UM) {\n                    add_description(root_ti, ti, \"The RLC PDU contains a segment of an SDU but neither the first octet nor the last octet of this SDU\");\n                } else {\n                    add_description(root_ti, ti, \"The rest of the RLC PDU includes a piggybacked STATUS PDU\");\n                }\n                break;\n            case 0x7f:\n                add_description(root_ti, ti, \"The rest of the RLC PDU is padding\");\n                break;\n\n            default:\n                add_description(root_ti, ti, \"length=%u\", (guint16)length);\n                break;\n        }\n        proto_tree_add_bits_item(li_tree, hf_rlc_li_ext, tvb, li_offs*8+7, 1, ENC_BIG_ENDIAN);\n    }\n\n    if (li->len > 0) {\n        if (li->li > tvb_reported_length_remaining(tvb, hdr_offs)) return li_tree;\n        if (li->len > li->li) return li_tree;\n        ti = proto_tree_add_item(li_tree, hf_rlc_li_data, tvb, hdr_offs + li->li - li->len, li->len, ENC_NA);\n        PROTO_ITEM_SET_HIDDEN(ti);\n    }\n\n    return li_tree;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,10 +1,10 @@\n static proto_tree *\n-tree_add_li(enum rlc_mode mode, struct rlc_li *li, guint8 li_idx, guint8 hdr_offs,\n+tree_add_li(enum rlc_mode mode, struct rlc_li *li, guint8 li_idx, guint32 hdr_offs,\n         gboolean li_is_on_2_bytes, tvbuff_t *tvb, proto_tree *tree)\n {\n     proto_item *root_ti, *ti;\n     proto_tree *li_tree;\n-    guint8      li_offs;\n+    guint32     li_offs;\n     guint64     length;\n \n     if (!tree) return NULL;",
        "diff_line_info": {
            "deleted_lines": [
                "tree_add_li(enum rlc_mode mode, struct rlc_li *li, guint8 li_idx, guint8 hdr_offs,",
                "    guint8      li_offs;"
            ],
            "added_lines": [
                "tree_add_li(enum rlc_mode mode, struct rlc_li *li, guint8 li_idx, guint32 hdr_offs,",
                "    guint32     li_offs;"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-6511",
        "func_name": "wireshark/proto_tree_add_text_valist_internal",
        "description": "epan/proto.c in Wireshark 1.12.x before 1.12.13 and 2.x before 2.0.5 allows remote attackers to cause a denial of service (OpenFlow dissector large loop) via a crafted packet.",
        "git_url": "https://github.com/wireshark/wireshark/commit/56706427f53cc64793870bf072c2c06248ae88f3",
        "commit_title": "proto.c: add bounds check to proto_tree_add_text(_valist)_internal",
        "commit_text": " Bug: 12659",
        "func_before": "proto_item *\nproto_tree_add_text_valist_internal(proto_tree *tree, tvbuff_t *tvb, gint start,\n\t\t\t   gint length, const char *format, va_list ap)\n{\n\tproto_item        *pi;\n\theader_field_info *hfinfo;\n\n\tCHECK_FOR_NULL_TREE(tree);\n\n\tTRY_TO_FAKE_THIS_ITEM(tree, hf_text_only, hfinfo);\n\n\tpi = proto_tree_add_text_node(tree, tvb, start, length);\n\n\tTRY_TO_FAKE_THIS_REPR(pi);\n\n\tproto_tree_set_representation(pi, format, ap);\n\n\treturn pi;\n}",
        "func": "proto_item *\nproto_tree_add_text_valist_internal(proto_tree *tree, tvbuff_t *tvb, gint start,\n\t\t\t   gint length, const char *format, va_list ap)\n{\n\tproto_item        *pi;\n\theader_field_info *hfinfo;\n\n\tif (length == -1) {\n\t\t/* If we're fetching until the end of the TVB, only validate\n\t\t * that the offset is within range.\n\t\t */\n\t\tlength = 0;\n\t}\n\ttvb_ensure_bytes_exist(tvb, start, length);\n\n\tCHECK_FOR_NULL_TREE(tree);\n\n\tTRY_TO_FAKE_THIS_ITEM(tree, hf_text_only, hfinfo);\n\n\tpi = proto_tree_add_text_node(tree, tvb, start, length);\n\n\tTRY_TO_FAKE_THIS_REPR(pi);\n\n\tproto_tree_set_representation(pi, format, ap);\n\n\treturn pi;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,6 +4,14 @@\n {\n \tproto_item        *pi;\n \theader_field_info *hfinfo;\n+\n+\tif (length == -1) {\n+\t\t/* If we're fetching until the end of the TVB, only validate\n+\t\t * that the offset is within range.\n+\t\t */\n+\t\tlength = 0;\n+\t}\n+\ttvb_ensure_bytes_exist(tvb, start, length);\n \n \tCHECK_FOR_NULL_TREE(tree);\n ",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "\tif (length == -1) {",
                "\t\t/* If we're fetching until the end of the TVB, only validate",
                "\t\t * that the offset is within range.",
                "\t\t */",
                "\t\tlength = 0;",
                "\t}",
                "\ttvb_ensure_bytes_exist(tvb, start, length);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-6511",
        "func_name": "wireshark/proto_tree_add_text_internal",
        "description": "epan/proto.c in Wireshark 1.12.x before 1.12.13 and 2.x before 2.0.5 allows remote attackers to cause a denial of service (OpenFlow dissector large loop) via a crafted packet.",
        "git_url": "https://github.com/wireshark/wireshark/commit/56706427f53cc64793870bf072c2c06248ae88f3",
        "commit_title": "proto.c: add bounds check to proto_tree_add_text(_valist)_internal",
        "commit_text": " Bug: 12659",
        "func_before": "proto_item *\nproto_tree_add_text_internal(proto_tree *tree, tvbuff_t *tvb, gint start, gint length,\n\t\t    const char *format, ...)\n{\n\tproto_item\t  *pi;\n\tva_list\t\t   ap;\n\theader_field_info *hfinfo;\n\n\tCHECK_FOR_NULL_TREE(tree);\n\n\tTRY_TO_FAKE_THIS_ITEM(tree, hf_text_only, hfinfo);\n\n\tpi = proto_tree_add_text_node(tree, tvb, start, length);\n\n\tTRY_TO_FAKE_THIS_REPR(pi);\n\n\tva_start(ap, format);\n\tproto_tree_set_representation(pi, format, ap);\n\tva_end(ap);\n\n\treturn pi;\n}",
        "func": "proto_item *\nproto_tree_add_text_internal(proto_tree *tree, tvbuff_t *tvb, gint start, gint length,\n\t\t    const char *format, ...)\n{\n\tproto_item\t  *pi;\n\tva_list\t\t   ap;\n\theader_field_info *hfinfo;\n\n\tif (length == -1) {\n\t\t/* If we're fetching until the end of the TVB, only validate\n\t\t * that the offset is within range.\n\t\t */\n\t\tlength = 0;\n\t}\n\ttvb_ensure_bytes_exist(tvb, start, length);\n\n\tCHECK_FOR_NULL_TREE(tree);\n\n\tTRY_TO_FAKE_THIS_ITEM(tree, hf_text_only, hfinfo);\n\n\tpi = proto_tree_add_text_node(tree, tvb, start, length);\n\n\tTRY_TO_FAKE_THIS_REPR(pi);\n\n\tva_start(ap, format);\n\tproto_tree_set_representation(pi, format, ap);\n\tva_end(ap);\n\n\treturn pi;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,6 +5,14 @@\n \tproto_item\t  *pi;\n \tva_list\t\t   ap;\n \theader_field_info *hfinfo;\n+\n+\tif (length == -1) {\n+\t\t/* If we're fetching until the end of the TVB, only validate\n+\t\t * that the offset is within range.\n+\t\t */\n+\t\tlength = 0;\n+\t}\n+\ttvb_ensure_bytes_exist(tvb, start, length);\n \n \tCHECK_FOR_NULL_TREE(tree);\n ",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "\tif (length == -1) {",
                "\t\t/* If we're fetching until the end of the TVB, only validate",
                "\t\t * that the offset is within range.",
                "\t\t */",
                "\t\tlength = 0;",
                "\t}",
                "\ttvb_ensure_bytes_exist(tvb, start, length);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-6513",
        "func_name": "wireshark/proto_register_wbxml",
        "description": "epan/dissectors/packet-wbxml.c in the WBXML dissector in Wireshark 2.x before 2.0.5 does not restrict the recursion depth, which allows remote attackers to cause a denial of service (application crash) via a crafted packet.",
        "git_url": "https://github.com/wireshark/wireshark/commit/347f071f1b9180563c28b0f3d0627b91eb456c72",
        "commit_title": "WBXML: limit the recursion level",
        "commit_text": " Bug: 12663",
        "func_before": "void\nproto_register_wbxml(void)\n{\n\tmodule_t *wbxml_module;\t/* WBXML Preferences */\n\n\t/* Setup list of header fields. */\n\tstatic hf_register_info hf[] = {\n\t\t{ &hf_wbxml_version,\n\t\t  { \"Version\",\n\t\t    \"wbxml.version\",\n\t\t    FT_UINT8, BASE_HEX|BASE_EXT_STRING,\n\t\t    &vals_wbxml_versions_ext, 0x00,\n\t\t    \"WBXML Version\", HFILL }\n\t\t},\n\t\t{ &hf_wbxml_public_id_known,\n\t\t  { \"Public Identifier (known)\",\n\t\t    \"wbxml.public_id.known\",\n\t\t    FT_UINT32, BASE_HEX|BASE_EXT_STRING,\n\t\t    &vals_wbxml_public_ids_ext, 0x00,\n\t\t    \"WBXML Known Public Identifier (integer)\", HFILL }\n\t\t},\n\t\t{ &hf_wbxml_public_id_literal,\n\t\t  { \"Public Identifier (literal)\",\n\t\t    \"wbxml.public_id.literal\",\n\t\t    FT_STRING, BASE_NONE,\n\t\t    NULL, 0x00,\n\t\t    \"WBXML Literal Public Identifier (text string)\", HFILL }\n\t\t},\n\t\t{ &hf_wbxml_charset,\n\t\t  { \"Character Set\",\n\t\t    \"wbxml.charset\",\n\t\t    FT_UINT32, BASE_DEC|BASE_EXT_STRING,\n\t\t    &mibenum_vals_character_sets_ext, 0x00,\n\t\t    \"WBXML Character Set\", HFILL }\n\t\t},\n\t\t{ &hf_wbxml_string_table_item_offset,\n\t\t  { \"Offset\",\n\t\t    \"wbxml.string_table_item_offset\",\n\t\t    FT_UINT32, BASE_DEC,\n\t\t    NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_wbxml_string_table_item_string,\n\t\t  { \"String\",\n\t\t    \"wbxml.string_table_item_string\",\n\t\t    FT_STRINGZ, STR_UNICODE,\n\t\t    NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_wbxml_switch_page,\n\t\t  { \"SWITCH_PAGE\",\n\t\t    \"wbxml.switch_page\",\n\t\t    FT_UINT32, BASE_DEC,\n\t\t    NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_wbxml_known_tag,\n\t\t  { \"Known Tag\",\n\t\t    \"wbxml.known_tag\",\n\t\t    FT_STRING, BASE_NONE,\n\t\t    NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_wbxml_end_known_tag,\n\t\t  { \"END Known Tag\",\n\t\t    \"wbxml.end_known_tag\",\n\t\t    FT_STRING, BASE_NONE,\n\t\t    NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_wbxml_end_known_tag_uint,\n\t\t  { \"END Known Tag\",\n\t\t    \"wbxml.end_known_tag.uint\",\n\t\t    FT_UINT32, BASE_DEC,\n\t\t    NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_wbxml_str_i,\n\t\t  { \"STR_I\",\n\t\t    \"wbxml.str_i\",\n\t\t    FT_STRING, BASE_NONE,\n\t\t    NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_wbxml_str_t,\n\t\t  { \"STR_T\",\n\t\t    \"wbxml.str_t\",\n\t\t    FT_STRING, BASE_NONE,\n\t\t    NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_wbxml_opaque_data,\n\t\t  { \"Opaque Data\",\n\t\t    \"wbxml.opaque_data\",\n\t\t    FT_BYTES, BASE_NONE,\n\t\t    NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_wbxml_entity,\n\t\t  { \"ENTITY\",\n\t\t    \"wbxml.entity\",\n\t\t    FT_UINT32, BASE_DEC,\n\t\t    NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_wbxml_literal,\n\t\t  { \"LITERAL\",\n\t\t    \"wbxml.literal\",\n\t\t    FT_STRING, BASE_NONE,\n\t\t    NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_wbxml_ext_i,\n\t\t  { \"EXT_I\",\n\t\t    \"wbxml.ext_i\",\n\t\t    FT_STRING, BASE_NONE,\n\t\t    NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_wbxml_ext_t,\n\t\t  { \"EXT_T\",\n\t\t    \"wbxml.ext_t\",\n\t\t    FT_STRING, BASE_NONE,\n\t\t    NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_wbxml_extension_token,\n\t\t  { \"Extension Token\",\n\t\t    \"wbxml.extension_token\",\n\t\t    FT_STRING, BASE_NONE,\n\t\t    NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_wbxml_reserved_2,\n\t\t  { \"RESERVED_2\",\n\t\t    \"wbxml.reserved_2\",\n\t\t    FT_NONE, BASE_NONE,\n\t\t    NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_wbxml_invalid_token,\n\t\t  { \"Invalid token\",\n\t\t    \"wbxml.invalid_token\",\n\t\t    FT_UINT32, BASE_DEC,\n\t\t    NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_wbxml_known_attrvalue,\n\t\t  { \"Known attrValue\",\n\t\t    \"wbxml.known_attrvalue\",\n\t\t    FT_STRING, BASE_NONE,\n\t\t    NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_wbxml_known_attrstart,\n\t\t  { \"Known attrStart\",\n\t\t    \"wbxml.known_attrstart\",\n\t\t    FT_STRING, BASE_NONE,\n\t\t    NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_wbxml_end_literal_tag,\n\t\t  { \"END (Literal Tag)\",\n\t\t    \"wbxml.end_literal_tag\",\n\t\t    FT_STRING, BASE_NONE,\n\t\t    NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_wbxml_literal_a,\n\t\t  { \"LITERAL_A\",\n\t\t    \"wbxml.literal_a\",\n\t\t    FT_STRING, BASE_NONE,\n\t\t    NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_wbxml_literal_c,\n\t\t  { \"LITERAL_C\",\n\t\t    \"wbxml.literal_c\",\n\t\t    FT_STRING, BASE_NONE,\n\t\t    NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_wbxml_literal_ac,\n\t\t  { \"LITERAL_AC\",\n\t\t    \"wbxml.literal_ac\",\n\t\t    FT_STRING, BASE_NONE,\n\t\t    NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_wbxml_end_pi,\n\t\t  { \"END (PI)\",\n\t\t    \"wbxml.end_pi\",\n\t\t    FT_NONE, BASE_NONE,\n\t\t    NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_wbxml_end_attribute_list,\n\t\t  { \"END (attribute list)\",\n\t\t    \"wbxml.end_attribute_list\",\n\t\t    FT_NONE, BASE_NONE,\n\t\t    NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_wbxml_pi_xml,\n\t\t  { \"PI (XML Processing Instruction)\",\n\t\t    \"wbxml.pi_xml\",\n\t\t    FT_NONE, BASE_NONE,\n\t\t    NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t};\n\n\t/* Setup protocol subtree array */\n\tstatic gint *ett[] = {\n\t\t&ett_wbxml,\n\t\t&ett_wbxml_str_tbl,\n\t\t&ett_wbxml_content,\n\t\t&ett_wbxml_tags,\n\t\t&ett_wbxml_string_table_item,\n\t};\n\n\tstatic ei_register_info ei[] = {\n\t\t{ &ei_wbxml_data_not_shown, { \"wbxml.data_not_shown\", PI_PROTOCOL, PI_NOTE, \"Data representation not shown (edit WBXML preferences to show)\", EXPFILL }},\n\t\t{ &ei_wbxml_content_type_not_supported, { \"wbxml.content_type.not_supported\", PI_UNDECODED, PI_WARN, \"Rendering of this content type not (yet) supported\", EXPFILL }},\n\t\t{ &ei_wbxml_content_type_disabled, { \"wbxml.content_type.disabled\", PI_PROTOCOL, PI_NOTE, \"Rendering of this content type has been disabled (edit WBXML preferences to enable)\", EXPFILL }},\n\t\t{ &ei_wbxml_oversized_uintvar, { \"wbxml.oversized_uintvar\", PI_MALFORMED, PI_ERROR, \"Uintvar is oversized\", EXPFILL }}\n\t};\n\n\texpert_module_t* expert_wbxml;\n\n\t/* Register the protocol name and description */\n\tproto_wbxml = proto_register_protocol(\n\t\t\t\t\t      \"WAP Binary XML\",\n\t\t\t\t\t      \"WBXML\",\n\t\t\t\t\t      \"wbxml\"\n\t\t\t\t\t      );\n\n\t/* Required function calls to register the header fields\n\t * and subtrees used */\n\tproto_register_field_array(proto_wbxml, hf, array_length(hf));\n\tproto_register_subtree_array(ett, array_length(ett));\n\texpert_wbxml = expert_register_protocol(proto_wbxml);\n\texpert_register_field_array(expert_wbxml, ei, array_length(ei));\n\n\t/* Preferences */\n\twbxml_module = prefs_register_protocol(proto_wbxml, NULL);\n\tprefs_register_bool_preference(wbxml_module,\n\t\t\t\t       \"skip_wbxml_token_mapping\",\n\t\t\t\t       \"Skip the mapping of WBXML tokens to media type tokens.\",\n\t\t\t\t       \"Enable this preference if you want to view the WBXML \"\n\t\t\t\t       \"tokens without the representation in a media type \"\n\t\t\t\t       \"(e.g., WML). Tokens will show up as Tag_0x12, \"\n\t\t\t\t       \"attrStart_0x08 or attrValue_0x0B for example.\",\n\t\t\t\t       &skip_wbxml_token_mapping);\n\tprefs_register_bool_preference(wbxml_module,\n\t\t\t\t       \"disable_wbxml_token_parsing\",\n\t\t\t\t       \"Disable the parsing of the WBXML tokens.\",\n\t\t\t\t       \"Enable this preference if you want to skip the \"\n\t\t\t\t       \"parsing of the WBXML tokens that constitute the body \"\n\t\t\t\t       \"of the WBXML document. Only the WBXML header will be \"\n\t\t\t\t       \"dissected (and visualized) then.\",\n\t\t\t\t       &disable_wbxml_token_parsing);\n\n\tregister_dissector(\"wbxml\", dissect_wbxml, proto_wbxml);\n\tregister_dissector(\"wbxml-uaprof\", dissect_uaprof, proto_wbxml);\n}",
        "func": "void\nproto_register_wbxml(void)\n{\n\tmodule_t *wbxml_module;\t/* WBXML Preferences */\n\n\t/* Setup list of header fields. */\n\tstatic hf_register_info hf[] = {\n\t\t{ &hf_wbxml_version,\n\t\t  { \"Version\",\n\t\t    \"wbxml.version\",\n\t\t    FT_UINT8, BASE_HEX|BASE_EXT_STRING,\n\t\t    &vals_wbxml_versions_ext, 0x00,\n\t\t    \"WBXML Version\", HFILL }\n\t\t},\n\t\t{ &hf_wbxml_public_id_known,\n\t\t  { \"Public Identifier (known)\",\n\t\t    \"wbxml.public_id.known\",\n\t\t    FT_UINT32, BASE_HEX|BASE_EXT_STRING,\n\t\t    &vals_wbxml_public_ids_ext, 0x00,\n\t\t    \"WBXML Known Public Identifier (integer)\", HFILL }\n\t\t},\n\t\t{ &hf_wbxml_public_id_literal,\n\t\t  { \"Public Identifier (literal)\",\n\t\t    \"wbxml.public_id.literal\",\n\t\t    FT_STRING, BASE_NONE,\n\t\t    NULL, 0x00,\n\t\t    \"WBXML Literal Public Identifier (text string)\", HFILL }\n\t\t},\n\t\t{ &hf_wbxml_charset,\n\t\t  { \"Character Set\",\n\t\t    \"wbxml.charset\",\n\t\t    FT_UINT32, BASE_DEC|BASE_EXT_STRING,\n\t\t    &mibenum_vals_character_sets_ext, 0x00,\n\t\t    \"WBXML Character Set\", HFILL }\n\t\t},\n\t\t{ &hf_wbxml_string_table_item_offset,\n\t\t  { \"Offset\",\n\t\t    \"wbxml.string_table_item_offset\",\n\t\t    FT_UINT32, BASE_DEC,\n\t\t    NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_wbxml_string_table_item_string,\n\t\t  { \"String\",\n\t\t    \"wbxml.string_table_item_string\",\n\t\t    FT_STRINGZ, STR_UNICODE,\n\t\t    NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_wbxml_switch_page,\n\t\t  { \"SWITCH_PAGE\",\n\t\t    \"wbxml.switch_page\",\n\t\t    FT_UINT32, BASE_DEC,\n\t\t    NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_wbxml_known_tag,\n\t\t  { \"Known Tag\",\n\t\t    \"wbxml.known_tag\",\n\t\t    FT_STRING, BASE_NONE,\n\t\t    NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_wbxml_end_known_tag,\n\t\t  { \"END Known Tag\",\n\t\t    \"wbxml.end_known_tag\",\n\t\t    FT_STRING, BASE_NONE,\n\t\t    NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_wbxml_end_known_tag_uint,\n\t\t  { \"END Known Tag\",\n\t\t    \"wbxml.end_known_tag.uint\",\n\t\t    FT_UINT32, BASE_DEC,\n\t\t    NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_wbxml_str_i,\n\t\t  { \"STR_I\",\n\t\t    \"wbxml.str_i\",\n\t\t    FT_STRING, BASE_NONE,\n\t\t    NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_wbxml_str_t,\n\t\t  { \"STR_T\",\n\t\t    \"wbxml.str_t\",\n\t\t    FT_STRING, BASE_NONE,\n\t\t    NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_wbxml_opaque_data,\n\t\t  { \"Opaque Data\",\n\t\t    \"wbxml.opaque_data\",\n\t\t    FT_BYTES, BASE_NONE,\n\t\t    NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_wbxml_entity,\n\t\t  { \"ENTITY\",\n\t\t    \"wbxml.entity\",\n\t\t    FT_UINT32, BASE_DEC,\n\t\t    NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_wbxml_literal,\n\t\t  { \"LITERAL\",\n\t\t    \"wbxml.literal\",\n\t\t    FT_STRING, BASE_NONE,\n\t\t    NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_wbxml_ext_i,\n\t\t  { \"EXT_I\",\n\t\t    \"wbxml.ext_i\",\n\t\t    FT_STRING, BASE_NONE,\n\t\t    NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_wbxml_ext_t,\n\t\t  { \"EXT_T\",\n\t\t    \"wbxml.ext_t\",\n\t\t    FT_STRING, BASE_NONE,\n\t\t    NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_wbxml_extension_token,\n\t\t  { \"Extension Token\",\n\t\t    \"wbxml.extension_token\",\n\t\t    FT_STRING, BASE_NONE,\n\t\t    NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_wbxml_reserved_2,\n\t\t  { \"RESERVED_2\",\n\t\t    \"wbxml.reserved_2\",\n\t\t    FT_NONE, BASE_NONE,\n\t\t    NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_wbxml_invalid_token,\n\t\t  { \"Invalid token\",\n\t\t    \"wbxml.invalid_token\",\n\t\t    FT_UINT32, BASE_DEC,\n\t\t    NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_wbxml_known_attrvalue,\n\t\t  { \"Known attrValue\",\n\t\t    \"wbxml.known_attrvalue\",\n\t\t    FT_STRING, BASE_NONE,\n\t\t    NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_wbxml_known_attrstart,\n\t\t  { \"Known attrStart\",\n\t\t    \"wbxml.known_attrstart\",\n\t\t    FT_STRING, BASE_NONE,\n\t\t    NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_wbxml_end_literal_tag,\n\t\t  { \"END (Literal Tag)\",\n\t\t    \"wbxml.end_literal_tag\",\n\t\t    FT_STRING, BASE_NONE,\n\t\t    NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_wbxml_literal_a,\n\t\t  { \"LITERAL_A\",\n\t\t    \"wbxml.literal_a\",\n\t\t    FT_STRING, BASE_NONE,\n\t\t    NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_wbxml_literal_c,\n\t\t  { \"LITERAL_C\",\n\t\t    \"wbxml.literal_c\",\n\t\t    FT_STRING, BASE_NONE,\n\t\t    NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_wbxml_literal_ac,\n\t\t  { \"LITERAL_AC\",\n\t\t    \"wbxml.literal_ac\",\n\t\t    FT_STRING, BASE_NONE,\n\t\t    NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_wbxml_end_pi,\n\t\t  { \"END (PI)\",\n\t\t    \"wbxml.end_pi\",\n\t\t    FT_NONE, BASE_NONE,\n\t\t    NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_wbxml_end_attribute_list,\n\t\t  { \"END (attribute list)\",\n\t\t    \"wbxml.end_attribute_list\",\n\t\t    FT_NONE, BASE_NONE,\n\t\t    NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_wbxml_pi_xml,\n\t\t  { \"PI (XML Processing Instruction)\",\n\t\t    \"wbxml.pi_xml\",\n\t\t    FT_NONE, BASE_NONE,\n\t\t    NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t};\n\n\t/* Setup protocol subtree array */\n\tstatic gint *ett[] = {\n\t\t&ett_wbxml,\n\t\t&ett_wbxml_str_tbl,\n\t\t&ett_wbxml_content,\n\t\t&ett_wbxml_tags,\n\t\t&ett_wbxml_string_table_item,\n\t};\n\n\tstatic ei_register_info ei[] = {\n\t\t{ &ei_wbxml_data_not_shown, { \"wbxml.data_not_shown\", PI_PROTOCOL, PI_NOTE, \"Data representation not shown (edit WBXML preferences to show)\", EXPFILL }},\n\t\t{ &ei_wbxml_content_type_not_supported, { \"wbxml.content_type.not_supported\", PI_UNDECODED, PI_WARN, \"Rendering of this content type not (yet) supported\", EXPFILL }},\n\t\t{ &ei_wbxml_content_type_disabled, { \"wbxml.content_type.disabled\", PI_PROTOCOL, PI_NOTE, \"Rendering of this content type has been disabled (edit WBXML preferences to enable)\", EXPFILL }},\n\t\t{ &ei_wbxml_oversized_uintvar, { \"wbxml.oversized_uintvar\", PI_MALFORMED, PI_ERROR, \"Uintvar is oversized\", EXPFILL }},\n\t\t{ &ei_wbxml_too_much_recursion, { \"wbxml.too_much_recursion\", PI_UNDECODED, PI_WARN, \"Too much recursion\", EXPFILL }}\n\t};\n\n\texpert_module_t* expert_wbxml;\n\n\t/* Register the protocol name and description */\n\tproto_wbxml = proto_register_protocol(\n\t\t\t\t\t      \"WAP Binary XML\",\n\t\t\t\t\t      \"WBXML\",\n\t\t\t\t\t      \"wbxml\"\n\t\t\t\t\t      );\n\n\t/* Required function calls to register the header fields\n\t * and subtrees used */\n\tproto_register_field_array(proto_wbxml, hf, array_length(hf));\n\tproto_register_subtree_array(ett, array_length(ett));\n\texpert_wbxml = expert_register_protocol(proto_wbxml);\n\texpert_register_field_array(expert_wbxml, ei, array_length(ei));\n\n\t/* Preferences */\n\twbxml_module = prefs_register_protocol(proto_wbxml, NULL);\n\tprefs_register_bool_preference(wbxml_module,\n\t\t\t\t       \"skip_wbxml_token_mapping\",\n\t\t\t\t       \"Skip the mapping of WBXML tokens to media type tokens.\",\n\t\t\t\t       \"Enable this preference if you want to view the WBXML \"\n\t\t\t\t       \"tokens without the representation in a media type \"\n\t\t\t\t       \"(e.g., WML). Tokens will show up as Tag_0x12, \"\n\t\t\t\t       \"attrStart_0x08 or attrValue_0x0B for example.\",\n\t\t\t\t       &skip_wbxml_token_mapping);\n\tprefs_register_bool_preference(wbxml_module,\n\t\t\t\t       \"disable_wbxml_token_parsing\",\n\t\t\t\t       \"Disable the parsing of the WBXML tokens.\",\n\t\t\t\t       \"Enable this preference if you want to skip the \"\n\t\t\t\t       \"parsing of the WBXML tokens that constitute the body \"\n\t\t\t\t       \"of the WBXML document. Only the WBXML header will be \"\n\t\t\t\t       \"dissected (and visualized) then.\",\n\t\t\t\t       &disable_wbxml_token_parsing);\n\n\tregister_dissector(\"wbxml\", dissect_wbxml, proto_wbxml);\n\tregister_dissector(\"wbxml-uaprof\", dissect_uaprof, proto_wbxml);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -223,7 +223,8 @@\n \t\t{ &ei_wbxml_data_not_shown, { \"wbxml.data_not_shown\", PI_PROTOCOL, PI_NOTE, \"Data representation not shown (edit WBXML preferences to show)\", EXPFILL }},\n \t\t{ &ei_wbxml_content_type_not_supported, { \"wbxml.content_type.not_supported\", PI_UNDECODED, PI_WARN, \"Rendering of this content type not (yet) supported\", EXPFILL }},\n \t\t{ &ei_wbxml_content_type_disabled, { \"wbxml.content_type.disabled\", PI_PROTOCOL, PI_NOTE, \"Rendering of this content type has been disabled (edit WBXML preferences to enable)\", EXPFILL }},\n-\t\t{ &ei_wbxml_oversized_uintvar, { \"wbxml.oversized_uintvar\", PI_MALFORMED, PI_ERROR, \"Uintvar is oversized\", EXPFILL }}\n+\t\t{ &ei_wbxml_oversized_uintvar, { \"wbxml.oversized_uintvar\", PI_MALFORMED, PI_ERROR, \"Uintvar is oversized\", EXPFILL }},\n+\t\t{ &ei_wbxml_too_much_recursion, { \"wbxml.too_much_recursion\", PI_UNDECODED, PI_WARN, \"Too much recursion\", EXPFILL }}\n \t};\n \n \texpert_module_t* expert_wbxml;",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t{ &ei_wbxml_oversized_uintvar, { \"wbxml.oversized_uintvar\", PI_MALFORMED, PI_ERROR, \"Uintvar is oversized\", EXPFILL }}"
            ],
            "added_lines": [
                "\t\t{ &ei_wbxml_oversized_uintvar, { \"wbxml.oversized_uintvar\", PI_MALFORMED, PI_ERROR, \"Uintvar is oversized\", EXPFILL }},",
                "\t\t{ &ei_wbxml_too_much_recursion, { \"wbxml.too_much_recursion\", PI_UNDECODED, PI_WARN, \"Too much recursion\", EXPFILL }}"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-6513",
        "func_name": "wireshark/parse_wbxml_tag_defined",
        "description": "epan/dissectors/packet-wbxml.c in the WBXML dissector in Wireshark 2.x before 2.0.5 does not restrict the recursion depth, which allows remote attackers to cause a denial of service (application crash) via a crafted packet.",
        "git_url": "https://github.com/wireshark/wireshark/commit/347f071f1b9180563c28b0f3d0627b91eb456c72",
        "commit_title": "WBXML: limit the recursion level",
        "commit_text": " Bug: 12663",
        "func_before": "static guint32\nparse_wbxml_tag_defined (proto_tree *tree, tvbuff_t *tvb, packet_info *pinfo, guint32 offset,\n\t\t\t guint32 str_tbl, guint8 *level, guint8 *codepage_stag, guint8 *codepage_attr,\n\t\t\t const wbxml_decoding *map)\n{\n\tguint32      tvb_len  = tvb_reported_length (tvb);\n\tguint32      off      = offset;\n\tguint32      len;\n\tguint        str_len;\n\tguint32      ent;\n\tguint32      idx;\n\tguint8       peek;\n\tguint32      tag_len;                     /* Length of the index (uintvar) from a LITERAL tag */\n\tguint8       tag_save_known      = 0;     /* Will contain peek & 0x3F (tag identity) */\n\tguint8       tag_new_known       = 0;     /* Will contain peek & 0x3F (tag identity) */\n\tconst char  *tag_save_literal    = NULL;  /* Will contain the LITERAL tag identity */\n\tconst char  *tag_new_literal;             /* Will contain the LITERAL tag identity */\n\tconst gchar *str;\n\tguint8       parsing_tag_content = FALSE; /* Are we parsing content from a\n\t\t\t\t\t\t     tag with content: <x>Content</x>\n\n\t\t\t\t\t\t     The initial state is FALSE.\n\t\t\t\t\t\t     This state will trigger recursion. */\n\n\tDebugLog((\"parse_wbxml_tag_defined (level = %u, offset = %u)\\n\", *level, offset));\n\twhile (off < tvb_len) {\n\t\tpeek = tvb_get_guint8 (tvb, off);\n\t\tDebugLog((\"STAG: (top of while) level = %3u, peek = 0x%02X, off = %u, tvb_len = %u\\n\", *level, peek, off, tvb_len));\n\t\tif ((peek & 0x3F) < 4) switch (peek) { /* Global tokens in state = STAG\n\t\t\t\t\t\t\t  but not the LITERAL tokens */\n\t\tcase 0x00: /* SWITCH_PAGE */\n\t\t\t*codepage_stag = tvb_get_guint8 (tvb, off+1);\n\t\t\tproto_tree_add_uint_format(tree, hf_wbxml_switch_page, tvb, off, 2, *codepage_stag,\n\t\t\t\t\t     \"      | Tag   | T -->%3d | SWITCH_PAGE (Tag code page)     |\",\n\t\t\t\t\t     *codepage_stag);\n\t\t\toff += 2;\n\t\t\tbreak;\n\t\tcase 0x01: /* END: only possible for Tag with Content */\n\t\t\tif (tag_save_known) { /* Known TAG */\n\t\t\t\tproto_tree_add_string_format(tree, hf_wbxml_end_known_tag, tvb, off, 1, tag_save_literal,\n\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    | END (Known Tag 0x%02X)            | %s</%s>\",\n\t\t\t\t\t\t     *level, *codepage_stag,\n\t\t\t\t\t\t     tag_save_known, Indent (*level),\n\t\t\t\t\t\t     tag_save_literal); /* We already looked it up! */\n\t\t\t} else { /* Literal TAG */\n\t\t\t\tproto_tree_add_string_format(tree, hf_wbxml_end_literal_tag, tvb, off, 1, tag_save_literal ? tag_save_literal : \"\",\n\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    | END (Literal Tag)               | %s</%s>\",\n\t\t\t\t\t\t     *level, *codepage_stag, Indent (*level), tag_save_literal ? tag_save_literal : \"\");\n\t\t\t}\n\t\t\t(*level)--;\n\t\t\toff++;\n\t\t\t/* Reset code page: not needed as return from recursion */\n\t\t\tDebugLog((\"STAG: level = %u, Return: len = %u\\n\", *level, off - offset));\n\t\t\treturn (off - offset);\n\t\tcase 0x02: /* ENTITY */\n\t\t\tent = tvb_get_guintvar (tvb, off+1, &len, pinfo, &ei_wbxml_oversized_uintvar);\n\t\t\tproto_tree_add_uint_format(tree, hf_wbxml_entity, tvb, off, 1+len, ent,\n\t\t\t\t\t     \"  %3d | Tag   | T %3d    | ENTITY                          | %s'&#%u;'\",\n\t\t\t\t\t     *level, *codepage_stag, Indent (*level), ent);\n\t\t\toff += 1+len;\n\t\t\tbreak;\n\t\tcase 0x03: /* STR_I */\n\t\t\tlen = tvb_strsize (tvb, off+1);\n\t\t\tstr = tvb_format_text (tvb, off+1, len-1);\n\t\t\tproto_tree_add_string_format(tree, hf_wbxml_str_i, tvb, off, 1+len, str,\n\t\t\t\t\t     \"  %3d | Tag   | T %3d    | STR_I (Inline string)           | %s\\'%s\\'\",\n\t\t\t\t\t     *level, *codepage_stag, Indent(*level),\n\t\t\t\t\t     str);\n\t\t\toff += 1+len;\n\t\t\tbreak;\n\t\tcase 0x40: /* EXT_I_0 */\n\t\tcase 0x41: /* EXT_I_1 */\n\t\tcase 0x42: /* EXT_I_2 */\n\t\t\t/* Extension tokens */\n\t\t\tlen = tvb_strsize (tvb, off+1);\n\t\t\tstr = tvb_format_text (tvb, off+1, len-1);\n\t\t\tproto_tree_add_string_format(tree, hf_wbxml_ext_i, tvb, off, 1+len, str,\n\t\t\t\t\t     \"  %3d | Tag   | T %3d    | EXT_I_%1x    (Extension Token)    | %s(%s: \\'%s\\')\",\n\t\t\t\t\t     *level, *codepage_stag,\n\t\t\t\t\t     peek & 0x0f, Indent (*level),\n\t\t\t\t\t     ((map != NULL) ? map_token (map->global, 0, peek) : \"Inline string extension\"),\n\t\t\t\t\t     str);\n\t\t\toff += 1+len;\n\t\t\tbreak;\n\t\tcase 0x43: /* PI */\n\t\t\tproto_tree_add_none_format(tree, hf_wbxml_pi_xml, tvb, off, 1,\n\t\t\t\t\t     \"  %3d | Tag   | T %3d    | PI (XML Processing Instruction) | %s<?xml\",\n\t\t\t\t\t     *level, *codepage_stag, Indent (*level));\n\t\t\tlen = parse_wbxml_attribute_list_defined (tree, tvb, pinfo, off,\n\t\t\t\t\t\t\t\t  str_tbl, *level, codepage_attr, map);\n\t\t\t/* Check that there is still room in packet */\n\t\t\toff += len;\n\t\t\tif (off >= tvb_len) {\n\t\t\t\tDebugLog((\"STAG: level = %u, ThrowException: len = %u (short frame)\\n\", *level, off - offset));\n\t\t\t\t/*\n\t\t\t\t * TODO - Do we need to free g_malloc()ed memory?\n\t\t\t\t */\n\t\t\t\tTHROW(ReportedBoundsError);\n\t\t\t}\n\t\t\tproto_tree_add_none_format(tree, hf_wbxml_end_pi, tvb, off-1, 1,\n\t\t\t\t\t     \"  %3d | Tag   | T %3d    | END (PI)                        | %s?>\",\n\t\t\t\t\t     *level, *codepage_stag, Indent (*level));\n\t\t\tbreak;\n\t\tcase 0x80: /* EXT_T_0 */\n\t\tcase 0x81: /* EXT_T_1 */\n\t\tcase 0x82: /* EXT_T_2 */\n\t\t\t/* Extension tokens */\n\t\t\tidx = tvb_get_guintvar (tvb, off+1, &len, pinfo, &ei_wbxml_oversized_uintvar);\n\t\t\t{\n\t\t\t\tchar *s;\n\t\t\t\tif (map)\n\t\t\t\t{\n\t\t\t\t\tif (map->ext_t[peek & 0x03])\n\t\t\t\t\t\ts = (map->ext_t[peek & 0x03])(tvb, idx, str_tbl);\n\t\t\t\t\telse\n\t\t\t\t\t\ts = wmem_strdup_printf(wmem_packet_scope(), \"EXT_T_%1x (%s)\", peek & 0x03,\n\t\t\t\t\t\t\t        map_token (map->global, 0, peek));\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\ts = wmem_strdup_printf(wmem_packet_scope(), \"(Extension Token, integer value: %u)\", idx);\n\t\t\t\t}\n\t\t\t\tproto_tree_add_string_format(tree, hf_wbxml_ext_t, tvb, off, 1+len, s,\n\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    | EXT_T_%1x    (Extension Token)    | %s%s\",\n\t\t\t\t\t\t     *level, *codepage_stag, peek & 0x0f, Indent (*level), s);\n\t\t\t}\n\t\t\toff += 1+len;\n\t\t\tbreak;\n\t\tcase 0x83: /* STR_T */\n\t\t\tidx = tvb_get_guintvar (tvb, off+1, &len, pinfo, &ei_wbxml_oversized_uintvar);\n\t\t\tstr_len = tvb_strsize (tvb, str_tbl+idx);\n\t\t\tstr = tvb_format_text (tvb, str_tbl+idx, str_len-1);\n\t\t\tproto_tree_add_string_format(tree, hf_wbxml_str_t, tvb, off, 1+len, str,\n\t\t\t\t\t     \"  %3d | Tag   | T %3d    | STR_T (Tableref string)         | %s\\'%s\\'\",\n\t\t\t\t\t     *level, *codepage_stag, Indent (*level), str);\n\t\t\toff += 1+len;\n\t\t\tbreak;\n\t\tcase 0xC0: /* EXT_0 */\n\t\tcase 0xC1: /* EXT_1 */\n\t\tcase 0xC2: /* EXT_2 */\n\t\t\t/* Extension tokens */\n\t\t\tstr = (map != NULL) ? map_token (map->global, 0, peek) : \"Single-byte extension\";\n\t\t\tproto_tree_add_string_format(tree, hf_wbxml_extension_token, tvb, off, 1, str,\n\t\t\t\t\t     \"  %3d | Tag   | T %3d    | EXT_%1x      (Extension Token)    | %s(%s)\",\n\t\t\t\t\t     *level, *codepage_stag, peek & 0x0f, Indent (*level), str);\n\t\t\toff++;\n\t\t\tbreak;\n\t\tcase 0xC3: /* OPAQUE - WBXML 1.1 and newer */\n\t\t\tif (tvb_get_guint8 (tvb, 0)) { /* WBXML 1.x (x > 0) */\n\t\t\t\tif (map != NULL)\n\t\t\t\t{\n\t\t\t\t\tchar *tmp_str;\n\t\t\t\t\tif (tag_save_known) { /* Knwon tag */\n\t\t\t\t\t\tif (map->opaque_binary_tag) {\n\t\t\t\t\t\t\ttmp_str = map->opaque_binary_tag(tvb, off + 1,\n\t\t\t\t\t\t\t\t\t\t     tag_save_known, *codepage_stag, &len, pinfo);\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\ttmp_str = default_opaque_binary_tag(tvb, off + 1,\n\t\t\t\t\t\t\t\t\t\t\ttag_save_known, *codepage_stag, &len, pinfo);\n\t\t\t\t\t\t}\n\t\t\t\t\t} else { /* lITERAL tag */\n\t\t\t\t\t\tif (map->opaque_literal_tag) {\n\t\t\t\t\t\t\ttmp_str = map->opaque_literal_tag(tvb, off + 1,\n\t\t\t\t\t\t\t\t\t\t      tag_save_literal, *codepage_stag, &len, pinfo);\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\ttmp_str = default_opaque_literal_tag(tvb, off + 1,\n\t\t\t\t\t\t\t\t\t\t\t tag_save_literal, *codepage_stag, &len, pinfo);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tproto_tree_add_bytes_format(tree, hf_wbxml_opaque_data, tvb, off, 1 + len, NULL,\n\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    | OPAQUE (Opaque data)            | %s%s\",\n\t\t\t\t\t\t     *level, *codepage_stag, Indent (*level), tmp_str);\n\t\t\t\t\toff += 1 + len;\n\t\t\t\t} else {\n\t\t\t\t\tidx = tvb_get_guintvar (tvb, off+1, &len, pinfo, &ei_wbxml_oversized_uintvar);\n\t\t\t\t\tproto_tree_add_bytes_format(tree, hf_wbxml_opaque_data, tvb, off, 1 + len + idx, NULL,\n\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    | OPAQUE (Opaque data)            | %s(%u bytes of opaque data)\",\n\t\t\t\t\t\t     *level, *codepage_stag, Indent (*level), idx);\n\t\t\t\t\toff += 1+len+idx;\n\t\t\t\t}\n\t\t\t} else { /* WBXML 1.0 - RESERVED_2 token (invalid) */\n\t\t\t\tproto_tree_add_none_format(tree, hf_wbxml_reserved_2, tvb, off, 1,\n\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    | RESERVED_2     (Invalid Token!) | WBXML 1.0 parsing stops here.\",\n\t\t\t\t\t\t     *level, *codepage_stag);\n\t\t\t\t/* Stop processing as it is impossible to parse now */\n\t\t\t\toff = tvb_len;\n\t\t\t\tDebugLog((\"STAG: level = %u, Return: len = %u\\n\", *level, off - offset));\n\t\t\t\treturn (off - offset);\n\t\t\t}\n\t\t\tbreak;\n\n\t\t\t/* No default clause, as all cases have been treated */\n\t\t} else { /* LITERAL or Known TAG */\n\t\t\t/* We must store the initial tag, and also retrieve the new tag.\n\t\t\t * For efficiency reasons, we store the literal tag representation\n\t\t\t * for known tags too, so we can easily close the tag without the\n\t\t\t * need of a new lookup and avoiding storage of token codepage.\n\t\t\t *\n\t\t\t * There are 4 possibilities:\n\t\t\t *\n\t\t\t *  1. Known tag followed by a known tag\n\t\t\t *  2. Known tag followed by a LITERAL tag\n\t\t\t *  3. LITERAL tag followed by Known tag\n\t\t\t *  4. LITERAL tag followed by LITERAL tag\n\t\t\t */\n\n\t\t\t/* Store the new tag */\n\t\t\ttag_len = 0;\n\t\t\tif ((peek & 0x3F) == 4) { /* LITERAL */\n\t\t\t\tDebugLog((\"STAG: LITERAL tag (peek = 0x%02X, off = %u) - TableRef follows!\\n\", peek, off));\n\t\t\t\tidx = tvb_get_guintvar (tvb, off+1, &tag_len, pinfo, &ei_wbxml_oversized_uintvar);\n\t\t\t\tstr_len = tvb_strsize (tvb, str_tbl+idx);\n\t\t\t\ttag_new_literal = (const gchar*)tvb_get_ptr (tvb, str_tbl+idx, str_len);\n\t\t\t\ttag_new_known = 0; /* invalidate known tag_new */\n\t\t\t} else { /* Known tag */\n\t\t\t\ttag_new_known = peek & 0x3F;\n\t\t\t\tif (map != NULL) {\n\t\t\t\t\ttag_new_literal = map_token (map->tags, *codepage_stag,\n\t\t\t\t\t\t\t     tag_new_known);\n\t\t\t\t} else {\n\t\t\t\t\ttag_new_literal = wmem_strdup_printf(wmem_packet_scope(), \"Tag_0x%02X\",\n\t\t\t\t\t\t\ttag_new_known);\n\t\t\t\t}\n\t\t\t\t/* Stored looked up tag name string */\n\t\t\t}\n\n\t\t\t/* Parsing of TAG starts HERE */\n\t\t\tif (peek & 0x40) { /* Content present */\n\t\t\t\t/* Content follows\n\t\t\t\t * [!] An explicit END token is expected in these cases!\n\t\t\t\t * ==> Recursion possible if we encounter a tag with content;\n\t\t\t\t *     recursion will return at the explicit END token.\n\t\t\t\t */\n\t\t\t\tif (parsing_tag_content) { /* Recurse */\n\t\t\t\t\tDebugLog((\"STAG: Tag in Tag - RECURSE! (off = %u)\\n\", off));\n\t\t\t\t\t/* Do not process the attribute list:\n\t\t\t\t\t * recursion will take care of it */\n\t\t\t\t\t(*level)++;\n\t\t\t\t\tlen = parse_wbxml_tag_defined (tree, tvb, pinfo, off, str_tbl,\n\t\t\t\t\t\t\t\t       level, codepage_stag, codepage_attr, map);\n\t\t\t\t\toff += len;\n\t\t\t\t} else { /* Now we will have content to parse */\n\t\t\t\t\t/* Save the start tag so we can properly close it later. */\n\t\t\t\t\tif ((peek & 0x3F) == 4) { /* Literal tag */\n\t\t\t\t\t\ttag_save_literal = tag_new_literal;\n\t\t\t\t\t\ttag_save_known = 0;\n\t\t\t\t\t} else { /* Known tag */\n\t\t\t\t\t\ttag_save_known = tag_new_known;\n\t\t\t\t\t\ttag_save_literal = tag_new_literal;\n\t\t\t\t\t\t/* The last statement avoids needless lookups */\n\t\t\t\t\t}\n\t\t\t\t\t/* Process the attribute list if present */\n\t\t\t\t\tif (peek & 0x80) { /* Content and Attribute list present */\n\t\t\t\t\t\tif (tag_new_known) { /* Known tag */\n\t\t\t\t\t\t\tproto_tree_add_string_format(tree, hf_wbxml_known_tag, tvb, off, 1, tag_new_literal,\n\t\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    |   Known Tag 0x%02X           (AC) | %s<%s\",\n\t\t\t\t\t\t\t\t\t     *level, *codepage_stag, tag_new_known,\n\t\t\t\t\t\t\t\t\t     Indent (*level), tag_new_literal);\n\t\t\t\t\t\t\t/* Tag string already looked up earlier! */\n\t\t\t\t\t\t\toff++;\n\t\t\t\t\t\t} else { /* LITERAL tag */\n\t\t\t\t\t\t\tproto_tree_add_string_format(tree, hf_wbxml_literal_ac, tvb, off, 1, tag_new_literal,\n\t\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    | LITERAL_AC (Literal tag)   (AC) | %s<%s\",\n\t\t\t\t\t\t\t\t\t     *level, *codepage_stag, Indent (*level), tag_new_literal);\n\t\t\t\t\t\t\toff += 1 + tag_len;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tlen = parse_wbxml_attribute_list_defined (tree, tvb, pinfo,\n\t\t\t\t\t\t\t\t\t\t\t  off, str_tbl, *level, codepage_attr, map);\n\t\t\t\t\t\t/* Check that there is still room in packet */\n\t\t\t\t\t\toff += len;\n\t\t\t\t\t\tif (off >= tvb_len) {\n\t\t\t\t\t\t\tDebugLog((\"STAG: level = %u, ThrowException: len = %u (short frame)\\n\",\n\t\t\t\t\t\t\t\t  *level, off - offset));\n\t\t\t\t\t\t\t/*\n\t\t\t\t\t\t\t * TODO - Do we need to free g_malloc()ed memory?\n\t\t\t\t\t\t\t */\n\t\t\t\t\t\t\tTHROW(ReportedBoundsError);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tproto_tree_add_none_format(tree, hf_wbxml_end_attribute_list, tvb, off-1, 1,\n\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    | END (attribute list)            | %s>\",\n\t\t\t\t\t\t\t\t     *level, *codepage_stag, Indent (*level));\n\t\t\t\t\t} else { /* Content, no Attribute list */\n\t\t\t\t\t\tif (tag_new_known) { /* Known tag */\n\t\t\t\t\t\t\tproto_tree_add_string_format(tree, hf_wbxml_known_tag, tvb, off, 1, tag_new_literal,\n\t\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    |   Known Tag 0x%02X           (.C) | %s<%s>\",\n\t\t\t\t\t\t\t\t\t     *level, *codepage_stag, tag_new_known,\n\t\t\t\t\t\t\t\t\t     Indent (*level), tag_new_literal);\n\t\t\t\t\t\t\t/* Tag string already looked up earlier! */\n\t\t\t\t\t\t\toff++;\n\t\t\t\t\t\t} else { /* LITERAL tag */\n\t\t\t\t\t\t\tproto_tree_add_string_format(tree, hf_wbxml_literal_c, tvb, off, 1, tag_new_literal,\n\t\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    | LITERAL_C  (Literal Tag)   (.C) | %s<%s>\",\n\t\t\t\t\t\t\t\t\t     *level, *codepage_stag, Indent (*level), tag_new_literal);\n\t\t\t\t\t\t\toff += 1 + tag_len;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\t/* The data that follows in the parsing process\n\t\t\t\t\t * represents content for the opening tag\n\t\t\t\t\t * we've just processed in the lines above.\n\t\t\t\t\t * Next time we encounter a tag with content: recurse\n\t\t\t\t\t */\n\t\t\t\t\tparsing_tag_content = TRUE;\n\t\t\t\t\tDebugLog((\"Tag in Tag - No recursion this time! (off = %u)\\n\", off));\n\t\t\t\t}\n\t\t\t} else { /* No Content */\n\t\t\t\tDebugLog((\"<Tag/> in Tag - No recursion! (off = %u)\\n\", off));\n\t\t\t\t(*level)++;\n\t\t\t\tif (peek & 0x80) { /* No Content, Attribute list present */\n\t\t\t\t\tif (tag_new_known) { /* Known tag */\n\t\t\t\t\t\tproto_tree_add_string_format(tree, hf_wbxml_known_tag, tvb, off, 1, tag_new_literal,\n\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    |   Known Tag 0x%02X           (A.) | %s<%s\",\n\t\t\t\t\t\t\t\t     *level, *codepage_stag, tag_new_known,\n\t\t\t\t\t\t\t\t     Indent (*level), tag_new_literal);\n\t\t\t\t\t\t/* Tag string already looked up earlier! */\n\t\t\t\t\t\toff++;\n\t\t\t\t\t\tlen = parse_wbxml_attribute_list_defined (tree, tvb, pinfo,\n\t\t\t\t\t\t\t\t\t\t\t  off, str_tbl, *level, codepage_attr, map);\n\t\t\t\t\t\t/* Check that there is still room in packet */\n\t\t\t\t\t\toff += len;\n\t\t\t\t\t\tif (off > tvb_len) {\n\t\t\t\t\t\t\tDebugLog((\"STAG: level = %u, ThrowException: len = %u (short frame)\\n\", *level, off - offset));\n\t\t\t\t\t\t\t/*\n\t\t\t\t\t\t\t * TODO - Do we need to free g_malloc()ed memory?\n\t\t\t\t\t\t\t */\n\t\t\t\t\t\t\tTHROW(ReportedBoundsError);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tproto_tree_add_uint_format(tree, hf_wbxml_end_known_tag_uint, tvb, off-1, 1, *codepage_stag,\n\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    | END (Known Tag)                 | %s/>\",\n\t\t\t\t\t\t\t\t     *level, *codepage_stag, Indent (*level));\n\t\t\t\t\t} else { /* LITERAL tag */\n\t\t\t\t\t\tproto_tree_add_string_format(tree, hf_wbxml_literal_a, tvb, off, 1, tag_new_literal,\n\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    | LITERAL_A  (Literal Tag)   (A.) | %s<%s\",\n\t\t\t\t\t\t\t\t     *level, *codepage_stag, Indent (*level), tag_new_literal);\n\t\t\t\t\t\toff += 1 + tag_len;\n\t\t\t\t\t\tlen = parse_wbxml_attribute_list_defined (tree, tvb, pinfo,\n\t\t\t\t\t\t\t\t\t\t\t  off, str_tbl, *level, codepage_attr, map);\n\t\t\t\t\t\t/* Check that there is still room in packet */\n\t\t\t\t\t\toff += len;\n\t\t\t\t\t\tif (off >= tvb_len) {\n\t\t\t\t\t\t\tDebugLog((\"STAG: level = %u, ThrowException: len = %u (short frame)\\n\", *level, off - offset));\n\t\t\t\t\t\t\t/*\n\t\t\t\t\t\t\t * TODO - Do we need to free g_malloc()ed memory?\n\t\t\t\t\t\t\t */\n\t\t\t\t\t\t\tTHROW(ReportedBoundsError);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tproto_tree_add_string_format(tree, hf_wbxml_end_literal_tag, tvb, off-1, 1, \"\",\n\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    | END (Literal Tag)               | %s/>\",\n\t\t\t\t\t\t\t\t     *level, *codepage_stag, Indent (*level));\n\t\t\t\t\t}\n\t\t\t\t} else { /* No Content, No Attribute list */\n\t\t\t\t\tif (tag_new_known) { /* Known tag */\n\t\t\t\t\t\tproto_tree_add_string_format(tree, hf_wbxml_known_tag, tvb, off, 1, tag_new_literal,\n\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    |   Known Tag 0x%02x           (..) | %s<%s />\",\n\t\t\t\t\t\t\t\t     *level, *codepage_stag, tag_new_known,\n\t\t\t\t\t\t\t\t     Indent (*level), tag_new_literal);\n\t\t\t\t\t\t/* Tag string already looked up earlier! */\n\t\t\t\t\t\toff++;\n\t\t\t\t\t} else { /* LITERAL tag */\n\t\t\t\t\t\tproto_tree_add_string_format(tree, hf_wbxml_literal, tvb, off, 1, tag_new_literal,\n\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    | LITERAL    (Literal Tag)   (..) | %s<%s />\",\n\t\t\t\t\t\t\t\t     *level, *codepage_stag, Indent (*level),\n\t\t\t\t\t\t\t\t     tag_new_literal);\n\t\t\t\t\t\toff += 1 + tag_len;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t(*level)--;\n\t\t\t\t/* TODO: Do I have to reset code page here? */\n\t\t\t}\n\t\t} /* if (tag & 0x3F) >= 5 */\n\t} /* while */\n\tDebugLog((\"STAG: level = %u, Return: len = %u (end of function body)\\n\", *level, off - offset));\n\treturn (off - offset);\n}",
        "func": "static guint32\nparse_wbxml_tag_defined (proto_tree *tree, tvbuff_t *tvb, packet_info *pinfo, guint32 offset,\n\t\t\t guint32 str_tbl, guint8 *level, guint8 *codepage_stag, guint8 *codepage_attr,\n\t\t\t const wbxml_decoding *map)\n{\n\tguint32      tvb_len  = tvb_reported_length (tvb);\n\tguint32      off      = offset;\n\tguint32      len;\n\tguint        str_len;\n\tguint32      ent;\n\tguint32      idx;\n\tguint8       peek;\n\tguint32      tag_len;                     /* Length of the index (uintvar) from a LITERAL tag */\n\tguint8       tag_save_known      = 0;     /* Will contain peek & 0x3F (tag identity) */\n\tguint8       tag_new_known       = 0;     /* Will contain peek & 0x3F (tag identity) */\n\tconst char  *tag_save_literal    = NULL;  /* Will contain the LITERAL tag identity */\n\tconst char  *tag_new_literal;             /* Will contain the LITERAL tag identity */\n\tconst gchar *str;\n\tguint8       parsing_tag_content = FALSE; /* Are we parsing content from a\n\t\t\t\t\t\t     tag with content: <x>Content</x>\n\n\t\t\t\t\t\t     The initial state is FALSE.\n\t\t\t\t\t\t     This state will trigger recursion. */\n\n\tif (*level == 255) {\n\t\tproto_tree_add_expert(tree, pinfo, &ei_wbxml_too_much_recursion, tvb, offset, tvb_captured_length_remaining(tvb, offset));\n\t\treturn tvb_len;\n\t}\n\tDebugLog((\"parse_wbxml_tag_defined (level = %u, offset = %u)\\n\", *level, offset));\n\twhile (off < tvb_len) {\n\t\tpeek = tvb_get_guint8 (tvb, off);\n\t\tDebugLog((\"STAG: (top of while) level = %3u, peek = 0x%02X, off = %u, tvb_len = %u\\n\", *level, peek, off, tvb_len));\n\t\tif ((peek & 0x3F) < 4) switch (peek) { /* Global tokens in state = STAG\n\t\t\t\t\t\t\t  but not the LITERAL tokens */\n\t\tcase 0x00: /* SWITCH_PAGE */\n\t\t\t*codepage_stag = tvb_get_guint8 (tvb, off+1);\n\t\t\tproto_tree_add_uint_format(tree, hf_wbxml_switch_page, tvb, off, 2, *codepage_stag,\n\t\t\t\t\t     \"      | Tag   | T -->%3d | SWITCH_PAGE (Tag code page)     |\",\n\t\t\t\t\t     *codepage_stag);\n\t\t\toff += 2;\n\t\t\tbreak;\n\t\tcase 0x01: /* END: only possible for Tag with Content */\n\t\t\tif (tag_save_known) { /* Known TAG */\n\t\t\t\tproto_tree_add_string_format(tree, hf_wbxml_end_known_tag, tvb, off, 1, tag_save_literal,\n\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    | END (Known Tag 0x%02X)            | %s</%s>\",\n\t\t\t\t\t\t     *level, *codepage_stag,\n\t\t\t\t\t\t     tag_save_known, Indent (*level),\n\t\t\t\t\t\t     tag_save_literal); /* We already looked it up! */\n\t\t\t} else { /* Literal TAG */\n\t\t\t\tproto_tree_add_string_format(tree, hf_wbxml_end_literal_tag, tvb, off, 1, tag_save_literal ? tag_save_literal : \"\",\n\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    | END (Literal Tag)               | %s</%s>\",\n\t\t\t\t\t\t     *level, *codepage_stag, Indent (*level), tag_save_literal ? tag_save_literal : \"\");\n\t\t\t}\n\t\t\t(*level)--;\n\t\t\toff++;\n\t\t\t/* Reset code page: not needed as return from recursion */\n\t\t\tDebugLog((\"STAG: level = %u, Return: len = %u\\n\", *level, off - offset));\n\t\t\treturn (off - offset);\n\t\tcase 0x02: /* ENTITY */\n\t\t\tent = tvb_get_guintvar (tvb, off+1, &len, pinfo, &ei_wbxml_oversized_uintvar);\n\t\t\tproto_tree_add_uint_format(tree, hf_wbxml_entity, tvb, off, 1+len, ent,\n\t\t\t\t\t     \"  %3d | Tag   | T %3d    | ENTITY                          | %s'&#%u;'\",\n\t\t\t\t\t     *level, *codepage_stag, Indent (*level), ent);\n\t\t\toff += 1+len;\n\t\t\tbreak;\n\t\tcase 0x03: /* STR_I */\n\t\t\tlen = tvb_strsize (tvb, off+1);\n\t\t\tstr = tvb_format_text (tvb, off+1, len-1);\n\t\t\tproto_tree_add_string_format(tree, hf_wbxml_str_i, tvb, off, 1+len, str,\n\t\t\t\t\t     \"  %3d | Tag   | T %3d    | STR_I (Inline string)           | %s\\'%s\\'\",\n\t\t\t\t\t     *level, *codepage_stag, Indent(*level),\n\t\t\t\t\t     str);\n\t\t\toff += 1+len;\n\t\t\tbreak;\n\t\tcase 0x40: /* EXT_I_0 */\n\t\tcase 0x41: /* EXT_I_1 */\n\t\tcase 0x42: /* EXT_I_2 */\n\t\t\t/* Extension tokens */\n\t\t\tlen = tvb_strsize (tvb, off+1);\n\t\t\tstr = tvb_format_text (tvb, off+1, len-1);\n\t\t\tproto_tree_add_string_format(tree, hf_wbxml_ext_i, tvb, off, 1+len, str,\n\t\t\t\t\t     \"  %3d | Tag   | T %3d    | EXT_I_%1x    (Extension Token)    | %s(%s: \\'%s\\')\",\n\t\t\t\t\t     *level, *codepage_stag,\n\t\t\t\t\t     peek & 0x0f, Indent (*level),\n\t\t\t\t\t     ((map != NULL) ? map_token (map->global, 0, peek) : \"Inline string extension\"),\n\t\t\t\t\t     str);\n\t\t\toff += 1+len;\n\t\t\tbreak;\n\t\tcase 0x43: /* PI */\n\t\t\tproto_tree_add_none_format(tree, hf_wbxml_pi_xml, tvb, off, 1,\n\t\t\t\t\t     \"  %3d | Tag   | T %3d    | PI (XML Processing Instruction) | %s<?xml\",\n\t\t\t\t\t     *level, *codepage_stag, Indent (*level));\n\t\t\tlen = parse_wbxml_attribute_list_defined (tree, tvb, pinfo, off,\n\t\t\t\t\t\t\t\t  str_tbl, *level, codepage_attr, map);\n\t\t\t/* Check that there is still room in packet */\n\t\t\toff += len;\n\t\t\tif (off >= tvb_len) {\n\t\t\t\tDebugLog((\"STAG: level = %u, ThrowException: len = %u (short frame)\\n\", *level, off - offset));\n\t\t\t\t/*\n\t\t\t\t * TODO - Do we need to free g_malloc()ed memory?\n\t\t\t\t */\n\t\t\t\tTHROW(ReportedBoundsError);\n\t\t\t}\n\t\t\tproto_tree_add_none_format(tree, hf_wbxml_end_pi, tvb, off-1, 1,\n\t\t\t\t\t     \"  %3d | Tag   | T %3d    | END (PI)                        | %s?>\",\n\t\t\t\t\t     *level, *codepage_stag, Indent (*level));\n\t\t\tbreak;\n\t\tcase 0x80: /* EXT_T_0 */\n\t\tcase 0x81: /* EXT_T_1 */\n\t\tcase 0x82: /* EXT_T_2 */\n\t\t\t/* Extension tokens */\n\t\t\tidx = tvb_get_guintvar (tvb, off+1, &len, pinfo, &ei_wbxml_oversized_uintvar);\n\t\t\t{\n\t\t\t\tchar *s;\n\t\t\t\tif (map)\n\t\t\t\t{\n\t\t\t\t\tif (map->ext_t[peek & 0x03])\n\t\t\t\t\t\ts = (map->ext_t[peek & 0x03])(tvb, idx, str_tbl);\n\t\t\t\t\telse\n\t\t\t\t\t\ts = wmem_strdup_printf(wmem_packet_scope(), \"EXT_T_%1x (%s)\", peek & 0x03,\n\t\t\t\t\t\t\t        map_token (map->global, 0, peek));\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\ts = wmem_strdup_printf(wmem_packet_scope(), \"(Extension Token, integer value: %u)\", idx);\n\t\t\t\t}\n\t\t\t\tproto_tree_add_string_format(tree, hf_wbxml_ext_t, tvb, off, 1+len, s,\n\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    | EXT_T_%1x    (Extension Token)    | %s%s\",\n\t\t\t\t\t\t     *level, *codepage_stag, peek & 0x0f, Indent (*level), s);\n\t\t\t}\n\t\t\toff += 1+len;\n\t\t\tbreak;\n\t\tcase 0x83: /* STR_T */\n\t\t\tidx = tvb_get_guintvar (tvb, off+1, &len, pinfo, &ei_wbxml_oversized_uintvar);\n\t\t\tstr_len = tvb_strsize (tvb, str_tbl+idx);\n\t\t\tstr = tvb_format_text (tvb, str_tbl+idx, str_len-1);\n\t\t\tproto_tree_add_string_format(tree, hf_wbxml_str_t, tvb, off, 1+len, str,\n\t\t\t\t\t     \"  %3d | Tag   | T %3d    | STR_T (Tableref string)         | %s\\'%s\\'\",\n\t\t\t\t\t     *level, *codepage_stag, Indent (*level), str);\n\t\t\toff += 1+len;\n\t\t\tbreak;\n\t\tcase 0xC0: /* EXT_0 */\n\t\tcase 0xC1: /* EXT_1 */\n\t\tcase 0xC2: /* EXT_2 */\n\t\t\t/* Extension tokens */\n\t\t\tstr = (map != NULL) ? map_token (map->global, 0, peek) : \"Single-byte extension\";\n\t\t\tproto_tree_add_string_format(tree, hf_wbxml_extension_token, tvb, off, 1, str,\n\t\t\t\t\t     \"  %3d | Tag   | T %3d    | EXT_%1x      (Extension Token)    | %s(%s)\",\n\t\t\t\t\t     *level, *codepage_stag, peek & 0x0f, Indent (*level), str);\n\t\t\toff++;\n\t\t\tbreak;\n\t\tcase 0xC3: /* OPAQUE - WBXML 1.1 and newer */\n\t\t\tif (tvb_get_guint8 (tvb, 0)) { /* WBXML 1.x (x > 0) */\n\t\t\t\tif (map != NULL)\n\t\t\t\t{\n\t\t\t\t\tchar *tmp_str;\n\t\t\t\t\tif (tag_save_known) { /* Knwon tag */\n\t\t\t\t\t\tif (map->opaque_binary_tag) {\n\t\t\t\t\t\t\ttmp_str = map->opaque_binary_tag(tvb, off + 1,\n\t\t\t\t\t\t\t\t\t\t     tag_save_known, *codepage_stag, &len, pinfo);\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\ttmp_str = default_opaque_binary_tag(tvb, off + 1,\n\t\t\t\t\t\t\t\t\t\t\ttag_save_known, *codepage_stag, &len, pinfo);\n\t\t\t\t\t\t}\n\t\t\t\t\t} else { /* lITERAL tag */\n\t\t\t\t\t\tif (map->opaque_literal_tag) {\n\t\t\t\t\t\t\ttmp_str = map->opaque_literal_tag(tvb, off + 1,\n\t\t\t\t\t\t\t\t\t\t      tag_save_literal, *codepage_stag, &len, pinfo);\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\ttmp_str = default_opaque_literal_tag(tvb, off + 1,\n\t\t\t\t\t\t\t\t\t\t\t tag_save_literal, *codepage_stag, &len, pinfo);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tproto_tree_add_bytes_format(tree, hf_wbxml_opaque_data, tvb, off, 1 + len, NULL,\n\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    | OPAQUE (Opaque data)            | %s%s\",\n\t\t\t\t\t\t     *level, *codepage_stag, Indent (*level), tmp_str);\n\t\t\t\t\toff += 1 + len;\n\t\t\t\t} else {\n\t\t\t\t\tidx = tvb_get_guintvar (tvb, off+1, &len, pinfo, &ei_wbxml_oversized_uintvar);\n\t\t\t\t\tproto_tree_add_bytes_format(tree, hf_wbxml_opaque_data, tvb, off, 1 + len + idx, NULL,\n\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    | OPAQUE (Opaque data)            | %s(%u bytes of opaque data)\",\n\t\t\t\t\t\t     *level, *codepage_stag, Indent (*level), idx);\n\t\t\t\t\toff += 1+len+idx;\n\t\t\t\t}\n\t\t\t} else { /* WBXML 1.0 - RESERVED_2 token (invalid) */\n\t\t\t\tproto_tree_add_none_format(tree, hf_wbxml_reserved_2, tvb, off, 1,\n\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    | RESERVED_2     (Invalid Token!) | WBXML 1.0 parsing stops here.\",\n\t\t\t\t\t\t     *level, *codepage_stag);\n\t\t\t\t/* Stop processing as it is impossible to parse now */\n\t\t\t\toff = tvb_len;\n\t\t\t\tDebugLog((\"STAG: level = %u, Return: len = %u\\n\", *level, off - offset));\n\t\t\t\treturn (off - offset);\n\t\t\t}\n\t\t\tbreak;\n\n\t\t\t/* No default clause, as all cases have been treated */\n\t\t} else { /* LITERAL or Known TAG */\n\t\t\t/* We must store the initial tag, and also retrieve the new tag.\n\t\t\t * For efficiency reasons, we store the literal tag representation\n\t\t\t * for known tags too, so we can easily close the tag without the\n\t\t\t * need of a new lookup and avoiding storage of token codepage.\n\t\t\t *\n\t\t\t * There are 4 possibilities:\n\t\t\t *\n\t\t\t *  1. Known tag followed by a known tag\n\t\t\t *  2. Known tag followed by a LITERAL tag\n\t\t\t *  3. LITERAL tag followed by Known tag\n\t\t\t *  4. LITERAL tag followed by LITERAL tag\n\t\t\t */\n\n\t\t\t/* Store the new tag */\n\t\t\ttag_len = 0;\n\t\t\tif ((peek & 0x3F) == 4) { /* LITERAL */\n\t\t\t\tDebugLog((\"STAG: LITERAL tag (peek = 0x%02X, off = %u) - TableRef follows!\\n\", peek, off));\n\t\t\t\tidx = tvb_get_guintvar (tvb, off+1, &tag_len, pinfo, &ei_wbxml_oversized_uintvar);\n\t\t\t\tstr_len = tvb_strsize (tvb, str_tbl+idx);\n\t\t\t\ttag_new_literal = (const gchar*)tvb_get_ptr (tvb, str_tbl+idx, str_len);\n\t\t\t\ttag_new_known = 0; /* invalidate known tag_new */\n\t\t\t} else { /* Known tag */\n\t\t\t\ttag_new_known = peek & 0x3F;\n\t\t\t\tif (map != NULL) {\n\t\t\t\t\ttag_new_literal = map_token (map->tags, *codepage_stag,\n\t\t\t\t\t\t\t     tag_new_known);\n\t\t\t\t} else {\n\t\t\t\t\ttag_new_literal = wmem_strdup_printf(wmem_packet_scope(), \"Tag_0x%02X\",\n\t\t\t\t\t\t\ttag_new_known);\n\t\t\t\t}\n\t\t\t\t/* Stored looked up tag name string */\n\t\t\t}\n\n\t\t\t/* Parsing of TAG starts HERE */\n\t\t\tif (peek & 0x40) { /* Content present */\n\t\t\t\t/* Content follows\n\t\t\t\t * [!] An explicit END token is expected in these cases!\n\t\t\t\t * ==> Recursion possible if we encounter a tag with content;\n\t\t\t\t *     recursion will return at the explicit END token.\n\t\t\t\t */\n\t\t\t\tif (parsing_tag_content) { /* Recurse */\n\t\t\t\t\tDebugLog((\"STAG: Tag in Tag - RECURSE! (off = %u)\\n\", off));\n\t\t\t\t\t/* Do not process the attribute list:\n\t\t\t\t\t * recursion will take care of it */\n\t\t\t\t\t(*level)++;\n\t\t\t\t\tlen = parse_wbxml_tag_defined (tree, tvb, pinfo, off, str_tbl,\n\t\t\t\t\t\t\t\t       level, codepage_stag, codepage_attr, map);\n\t\t\t\t\toff += len;\n\t\t\t\t} else { /* Now we will have content to parse */\n\t\t\t\t\t/* Save the start tag so we can properly close it later. */\n\t\t\t\t\tif ((peek & 0x3F) == 4) { /* Literal tag */\n\t\t\t\t\t\ttag_save_literal = tag_new_literal;\n\t\t\t\t\t\ttag_save_known = 0;\n\t\t\t\t\t} else { /* Known tag */\n\t\t\t\t\t\ttag_save_known = tag_new_known;\n\t\t\t\t\t\ttag_save_literal = tag_new_literal;\n\t\t\t\t\t\t/* The last statement avoids needless lookups */\n\t\t\t\t\t}\n\t\t\t\t\t/* Process the attribute list if present */\n\t\t\t\t\tif (peek & 0x80) { /* Content and Attribute list present */\n\t\t\t\t\t\tif (tag_new_known) { /* Known tag */\n\t\t\t\t\t\t\tproto_tree_add_string_format(tree, hf_wbxml_known_tag, tvb, off, 1, tag_new_literal,\n\t\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    |   Known Tag 0x%02X           (AC) | %s<%s\",\n\t\t\t\t\t\t\t\t\t     *level, *codepage_stag, tag_new_known,\n\t\t\t\t\t\t\t\t\t     Indent (*level), tag_new_literal);\n\t\t\t\t\t\t\t/* Tag string already looked up earlier! */\n\t\t\t\t\t\t\toff++;\n\t\t\t\t\t\t} else { /* LITERAL tag */\n\t\t\t\t\t\t\tproto_tree_add_string_format(tree, hf_wbxml_literal_ac, tvb, off, 1, tag_new_literal,\n\t\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    | LITERAL_AC (Literal tag)   (AC) | %s<%s\",\n\t\t\t\t\t\t\t\t\t     *level, *codepage_stag, Indent (*level), tag_new_literal);\n\t\t\t\t\t\t\toff += 1 + tag_len;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tlen = parse_wbxml_attribute_list_defined (tree, tvb, pinfo,\n\t\t\t\t\t\t\t\t\t\t\t  off, str_tbl, *level, codepage_attr, map);\n\t\t\t\t\t\t/* Check that there is still room in packet */\n\t\t\t\t\t\toff += len;\n\t\t\t\t\t\tif (off >= tvb_len) {\n\t\t\t\t\t\t\tDebugLog((\"STAG: level = %u, ThrowException: len = %u (short frame)\\n\",\n\t\t\t\t\t\t\t\t  *level, off - offset));\n\t\t\t\t\t\t\t/*\n\t\t\t\t\t\t\t * TODO - Do we need to free g_malloc()ed memory?\n\t\t\t\t\t\t\t */\n\t\t\t\t\t\t\tTHROW(ReportedBoundsError);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tproto_tree_add_none_format(tree, hf_wbxml_end_attribute_list, tvb, off-1, 1,\n\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    | END (attribute list)            | %s>\",\n\t\t\t\t\t\t\t\t     *level, *codepage_stag, Indent (*level));\n\t\t\t\t\t} else { /* Content, no Attribute list */\n\t\t\t\t\t\tif (tag_new_known) { /* Known tag */\n\t\t\t\t\t\t\tproto_tree_add_string_format(tree, hf_wbxml_known_tag, tvb, off, 1, tag_new_literal,\n\t\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    |   Known Tag 0x%02X           (.C) | %s<%s>\",\n\t\t\t\t\t\t\t\t\t     *level, *codepage_stag, tag_new_known,\n\t\t\t\t\t\t\t\t\t     Indent (*level), tag_new_literal);\n\t\t\t\t\t\t\t/* Tag string already looked up earlier! */\n\t\t\t\t\t\t\toff++;\n\t\t\t\t\t\t} else { /* LITERAL tag */\n\t\t\t\t\t\t\tproto_tree_add_string_format(tree, hf_wbxml_literal_c, tvb, off, 1, tag_new_literal,\n\t\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    | LITERAL_C  (Literal Tag)   (.C) | %s<%s>\",\n\t\t\t\t\t\t\t\t\t     *level, *codepage_stag, Indent (*level), tag_new_literal);\n\t\t\t\t\t\t\toff += 1 + tag_len;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\t/* The data that follows in the parsing process\n\t\t\t\t\t * represents content for the opening tag\n\t\t\t\t\t * we've just processed in the lines above.\n\t\t\t\t\t * Next time we encounter a tag with content: recurse\n\t\t\t\t\t */\n\t\t\t\t\tparsing_tag_content = TRUE;\n\t\t\t\t\tDebugLog((\"Tag in Tag - No recursion this time! (off = %u)\\n\", off));\n\t\t\t\t}\n\t\t\t} else { /* No Content */\n\t\t\t\tDebugLog((\"<Tag/> in Tag - No recursion! (off = %u)\\n\", off));\n\t\t\t\t(*level)++;\n\t\t\t\tif (peek & 0x80) { /* No Content, Attribute list present */\n\t\t\t\t\tif (tag_new_known) { /* Known tag */\n\t\t\t\t\t\tproto_tree_add_string_format(tree, hf_wbxml_known_tag, tvb, off, 1, tag_new_literal,\n\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    |   Known Tag 0x%02X           (A.) | %s<%s\",\n\t\t\t\t\t\t\t\t     *level, *codepage_stag, tag_new_known,\n\t\t\t\t\t\t\t\t     Indent (*level), tag_new_literal);\n\t\t\t\t\t\t/* Tag string already looked up earlier! */\n\t\t\t\t\t\toff++;\n\t\t\t\t\t\tlen = parse_wbxml_attribute_list_defined (tree, tvb, pinfo,\n\t\t\t\t\t\t\t\t\t\t\t  off, str_tbl, *level, codepage_attr, map);\n\t\t\t\t\t\t/* Check that there is still room in packet */\n\t\t\t\t\t\toff += len;\n\t\t\t\t\t\tif (off > tvb_len) {\n\t\t\t\t\t\t\tDebugLog((\"STAG: level = %u, ThrowException: len = %u (short frame)\\n\", *level, off - offset));\n\t\t\t\t\t\t\t/*\n\t\t\t\t\t\t\t * TODO - Do we need to free g_malloc()ed memory?\n\t\t\t\t\t\t\t */\n\t\t\t\t\t\t\tTHROW(ReportedBoundsError);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tproto_tree_add_uint_format(tree, hf_wbxml_end_known_tag_uint, tvb, off-1, 1, *codepage_stag,\n\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    | END (Known Tag)                 | %s/>\",\n\t\t\t\t\t\t\t\t     *level, *codepage_stag, Indent (*level));\n\t\t\t\t\t} else { /* LITERAL tag */\n\t\t\t\t\t\tproto_tree_add_string_format(tree, hf_wbxml_literal_a, tvb, off, 1, tag_new_literal,\n\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    | LITERAL_A  (Literal Tag)   (A.) | %s<%s\",\n\t\t\t\t\t\t\t\t     *level, *codepage_stag, Indent (*level), tag_new_literal);\n\t\t\t\t\t\toff += 1 + tag_len;\n\t\t\t\t\t\tlen = parse_wbxml_attribute_list_defined (tree, tvb, pinfo,\n\t\t\t\t\t\t\t\t\t\t\t  off, str_tbl, *level, codepage_attr, map);\n\t\t\t\t\t\t/* Check that there is still room in packet */\n\t\t\t\t\t\toff += len;\n\t\t\t\t\t\tif (off >= tvb_len) {\n\t\t\t\t\t\t\tDebugLog((\"STAG: level = %u, ThrowException: len = %u (short frame)\\n\", *level, off - offset));\n\t\t\t\t\t\t\t/*\n\t\t\t\t\t\t\t * TODO - Do we need to free g_malloc()ed memory?\n\t\t\t\t\t\t\t */\n\t\t\t\t\t\t\tTHROW(ReportedBoundsError);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tproto_tree_add_string_format(tree, hf_wbxml_end_literal_tag, tvb, off-1, 1, \"\",\n\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    | END (Literal Tag)               | %s/>\",\n\t\t\t\t\t\t\t\t     *level, *codepage_stag, Indent (*level));\n\t\t\t\t\t}\n\t\t\t\t} else { /* No Content, No Attribute list */\n\t\t\t\t\tif (tag_new_known) { /* Known tag */\n\t\t\t\t\t\tproto_tree_add_string_format(tree, hf_wbxml_known_tag, tvb, off, 1, tag_new_literal,\n\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    |   Known Tag 0x%02x           (..) | %s<%s />\",\n\t\t\t\t\t\t\t\t     *level, *codepage_stag, tag_new_known,\n\t\t\t\t\t\t\t\t     Indent (*level), tag_new_literal);\n\t\t\t\t\t\t/* Tag string already looked up earlier! */\n\t\t\t\t\t\toff++;\n\t\t\t\t\t} else { /* LITERAL tag */\n\t\t\t\t\t\tproto_tree_add_string_format(tree, hf_wbxml_literal, tvb, off, 1, tag_new_literal,\n\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    | LITERAL    (Literal Tag)   (..) | %s<%s />\",\n\t\t\t\t\t\t\t\t     *level, *codepage_stag, Indent (*level),\n\t\t\t\t\t\t\t\t     tag_new_literal);\n\t\t\t\t\t\toff += 1 + tag_len;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t(*level)--;\n\t\t\t\t/* TODO: Do I have to reset code page here? */\n\t\t\t}\n\t\t} /* if (tag & 0x3F) >= 5 */\n\t} /* while */\n\tDebugLog((\"STAG: level = %u, Return: len = %u (end of function body)\\n\", *level, off - offset));\n\treturn (off - offset);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -22,6 +22,10 @@\n \t\t\t\t\t\t     The initial state is FALSE.\n \t\t\t\t\t\t     This state will trigger recursion. */\n \n+\tif (*level == 255) {\n+\t\tproto_tree_add_expert(tree, pinfo, &ei_wbxml_too_much_recursion, tvb, offset, tvb_captured_length_remaining(tvb, offset));\n+\t\treturn tvb_len;\n+\t}\n \tDebugLog((\"parse_wbxml_tag_defined (level = %u, offset = %u)\\n\", *level, offset));\n \twhile (off < tvb_len) {\n \t\tpeek = tvb_get_guint8 (tvb, off);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tif (*level == 255) {",
                "\t\tproto_tree_add_expert(tree, pinfo, &ei_wbxml_too_much_recursion, tvb, offset, tvb_captured_length_remaining(tvb, offset));",
                "\t\treturn tvb_len;",
                "\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-5350",
        "func_name": "wireshark/dissect_spoolss_uint16uni",
        "description": "epan/dissectors/packet-dcerpc-spoolss.c in the SPOOLS component in Wireshark 1.12.x before 1.12.12 and 2.x before 2.0.4 mishandles unexpected offsets, which allows remote attackers to cause a denial of service (infinite loop) via a crafted packet.",
        "git_url": "https://github.com/wireshark/wireshark/commit/b4d16b4495b732888e12baf5b8a7e9bf2665e22b",
        "commit_title": "SPOOLSS: Try to avoid an infinite loop.",
        "commit_text": " Use tvb_reported_length_remaining in dissect_spoolss_uint16uni. Make sure our offset always increments in dissect_spoolss_keybuffer. ",
        "func_before": "static int\ndissect_spoolss_uint16uni(tvbuff_t *tvb, int offset, packet_info *pinfo _U_,\n\t\t\t  proto_tree *tree, guint8 *drep _U_, char **data,\n\t\t\t  int hf_name)\n{\n\tgint len, remaining;\n\tchar *text;\n\n\tif (offset % 2)\n\t\toffset += 2 - (offset % 2);\n\n\t/* Get remaining data in buffer as a string */\n\n\tremaining = tvb_captured_length_remaining(tvb, offset);\n\tif (remaining <= 0) {\n\t\tif (data)\n\t\t\t*data = g_strdup(\"\");\n\t\treturn offset;\n\t}\n\n\ttext = tvb_get_string_enc(NULL, tvb, offset, remaining, ENC_UTF_16|ENC_LITTLE_ENDIAN);\n\tlen = (int)strlen(text);\n\n\tproto_tree_add_string(tree, hf_name, tvb, offset, len * 2, text);\n\n\tif (data)\n\t\t*data = text;\n\telse\n\t\tg_free(text);\n\n\treturn offset + (len + 1) * 2;\n}",
        "func": "static int\ndissect_spoolss_uint16uni(tvbuff_t *tvb, int offset, packet_info *pinfo _U_,\n\t\t\t  proto_tree *tree, guint8 *drep _U_, char **data,\n\t\t\t  int hf_name)\n{\n\tgint len, remaining;\n\tchar *text;\n\n\tif (offset % 2)\n\t\toffset += 2 - (offset % 2);\n\n\t/* Get remaining data in buffer as a string */\n\n\tremaining = tvb_reported_length_remaining(tvb, offset);\n\tif (remaining <= 0) {\n\t\tif (data)\n\t\t\t*data = g_strdup(\"\");\n\t\treturn offset;\n\t}\n\n\ttext = tvb_get_string_enc(NULL, tvb, offset, remaining, ENC_UTF_16|ENC_LITTLE_ENDIAN);\n\tlen = (int)strlen(text);\n\n\tproto_tree_add_string(tree, hf_name, tvb, offset, len * 2, text);\n\n\tif (data)\n\t\t*data = text;\n\telse\n\t\tg_free(text);\n\n\treturn offset + (len + 1) * 2;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -11,7 +11,7 @@\n \n \t/* Get remaining data in buffer as a string */\n \n-\tremaining = tvb_captured_length_remaining(tvb, offset);\n+\tremaining = tvb_reported_length_remaining(tvb, offset);\n \tif (remaining <= 0) {\n \t\tif (data)\n \t\t\t*data = g_strdup(\"\");",
        "diff_line_info": {
            "deleted_lines": [
                "\tremaining = tvb_captured_length_remaining(tvb, offset);"
            ],
            "added_lines": [
                "\tremaining = tvb_reported_length_remaining(tvb, offset);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-5350",
        "func_name": "wireshark/dissect_spoolss_keybuffer",
        "description": "epan/dissectors/packet-dcerpc-spoolss.c in the SPOOLS component in Wireshark 1.12.x before 1.12.12 and 2.x before 2.0.4 mishandles unexpected offsets, which allows remote attackers to cause a denial of service (infinite loop) via a crafted packet.",
        "git_url": "https://github.com/wireshark/wireshark/commit/b4d16b4495b732888e12baf5b8a7e9bf2665e22b",
        "commit_title": "SPOOLSS: Try to avoid an infinite loop.",
        "commit_text": " Use tvb_reported_length_remaining in dissect_spoolss_uint16uni. Make sure our offset always increments in dissect_spoolss_keybuffer. ",
        "func_before": "static int\ndissect_spoolss_keybuffer(tvbuff_t *tvb, int offset, packet_info *pinfo,\n\t\t\t  proto_tree *tree, dcerpc_info *di, guint8 *drep)\n{\n\tguint32 size;\n\tint end_offset;\n\n\tif (di->conformant_run)\n\t\treturn offset;\n\n\t/* Dissect size and data */\n\n\toffset = dissect_ndr_uint32(tvb, offset, pinfo, tree, di, drep,\n\t\t\t\t    hf_keybuffer_size, &size);\n\n\tend_offset = offset + (size*2);\n\tif (end_offset < offset) {\n\t\t/*\n\t\t * Overflow - make the end offset one past the end of\n\t\t * the packet data, so we throw an exception (as the\n\t\t * size is almost certainly too big).\n\t\t */\n\t\tend_offset = tvb_reported_length_remaining(tvb, offset) + 1;\n\t}\n\n\twhile (offset < end_offset)\n\t\toffset = dissect_spoolss_uint16uni(\n\t\t\ttvb, offset, pinfo, tree, drep, NULL, hf_keybuffer);\n\n\treturn offset;\n}",
        "func": "static int\ndissect_spoolss_keybuffer(tvbuff_t *tvb, int offset, packet_info *pinfo,\n\t\t\t  proto_tree *tree, dcerpc_info *di, guint8 *drep)\n{\n\tguint32 size;\n\tint end_offset;\n\n\tif (di->conformant_run)\n\t\treturn offset;\n\n\t/* Dissect size and data */\n\n\toffset = dissect_ndr_uint32(tvb, offset, pinfo, tree, di, drep,\n\t\t\t\t    hf_keybuffer_size, &size);\n\n\tend_offset = offset + (size*2);\n\tif (end_offset < offset) {\n\t\t/*\n\t\t * Overflow - make the end offset one past the end of\n\t\t * the packet data, so we throw an exception (as the\n\t\t * size is almost certainly too big).\n\t\t */\n\t\tend_offset = tvb_reported_length_remaining(tvb, offset) + 1;\n\t}\n\n\twhile (offset > 0 && offset < end_offset) {\n\t\toffset = dissect_spoolss_uint16uni(\n\t\t\ttvb, offset, pinfo, tree, drep, NULL, hf_keybuffer);\n\t}\n\n\treturn offset;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -23,9 +23,10 @@\n \t\tend_offset = tvb_reported_length_remaining(tvb, offset) + 1;\n \t}\n \n-\twhile (offset < end_offset)\n+\twhile (offset > 0 && offset < end_offset) {\n \t\toffset = dissect_spoolss_uint16uni(\n \t\t\ttvb, offset, pinfo, tree, drep, NULL, hf_keybuffer);\n+\t}\n \n \treturn offset;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\twhile (offset < end_offset)"
            ],
            "added_lines": [
                "\twhile (offset > 0 && offset < end_offset) {",
                "\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-5359",
        "func_name": "wireshark/parse_wbxml_attribute_list",
        "description": "epan/dissectors/packet-wbxml.c in the WBXML dissector in Wireshark 1.12.x before 1.12.12 mishandles offsets, which allows remote attackers to cause a denial of service (integer overflow and infinite loop) via a crafted packet.",
        "git_url": "https://github.com/wireshark/wireshark/commit/b8e0d416898bb975a02c1b55883342edc5b4c9c0",
        "commit_title": "WBXML: add a basic sanity check for offset overflow",
        "commit_text": " This is a naive approach allowing to detact that something went wrong, without the need to replace all proto_tree_add_text() calls as what was done in master-2.0 branch.  Bug: 12408",
        "func_before": "static guint32\nparse_wbxml_attribute_list (proto_tree *tree, tvbuff_t *tvb,\n\t\t\t    guint32 offset, guint32 str_tbl, guint8 level, guint8 *codepage_attr)\n{\n\tguint32 tvb_len = tvb_reported_length (tvb);\n\tguint32 off     = offset;\n\tguint32 len;\n\tguint   str_len;\n\tguint32 ent;\n\tguint32 idx;\n\tguint8  peek;\n\n\tDebugLog((\"parse_wbxml_attr (level = %u, offset = %u)\\n\", level, offset));\n\t/* Parse attributes */\n\twhile (off < tvb_len) {\n\t\tpeek = tvb_get_guint8 (tvb, off);\n\t\tDebugLog((\"ATTR: (top of while) level = %3u, peek = 0x%02X, \"\n\t\t\t  \"off = %u, tvb_len = %u\\n\", level, peek, off, tvb_len));\n\t\tif ((peek & 0x3F) < 5) switch (peek) { /* Global tokens\n\t\t\t\t\t\t\t  in state = ATTR */\n\t\tcase 0x00: /* SWITCH_PAGE */\n\t\t\t*codepage_attr = tvb_get_guint8 (tvb, off+1);\n\t\t\tproto_tree_add_text (tree, tvb, off, 2,\n\t\t\t\t\t     \"      |  Attr | A -->%3d \"\n\t\t\t\t\t     \"| SWITCH_PAGE (Attr code page)    |\",\n\t\t\t\t\t     *codepage_attr);\n\t\t\toff += 2;\n\t\t\tbreak;\n\t\tcase 0x01: /* END */\n\t\t\t/* BEWARE\n\t\t\t *   The Attribute END token means either \">\" or \"/>\"\n\t\t\t *   and as a consequence both must be treated separately.\n\t\t\t *   This is done in the TAG state parser.\n\t\t\t */\n\t\t\toff++;\n\t\t\tDebugLog((\"ATTR: level = %u, Return: len = %u\\n\",\n\t\t\t\t  level, off - offset));\n\t\t\treturn (off - offset);\n\t\tcase 0x02: /* ENTITY */\n\t\t\tent = tvb_get_guintvar (tvb, off+1, &len);\n\t\t\tproto_tree_add_text (tree, tvb, off, 1+len,\n\t\t\t\t\t     \"  %3d |  Attr | A %3d    \"\n\t\t\t\t\t     \"| ENTITY                          \"\n\t\t\t\t\t     \"|     %s'&#%u;'\",\n\t\t\t\t\t     level, *codepage_attr, Indent (level), ent);\n\t\t\toff += 1+len;\n\t\t\tbreak;\n\t\tcase 0x03: /* STR_I */\n\t\t\tlen = tvb_strsize (tvb, off+1);\n\t\t\tproto_tree_add_text (tree, tvb, off, 1+len,\n\t\t\t\t\t     \"  %3d |  Attr | A %3d    \"\n\t\t\t\t\t     \"| STR_I (Inline string)           \"\n\t\t\t\t\t     \"|     %s\\'%s\\'\",\n\t\t\t\t\t     level, *codepage_attr, Indent (level),\n\t\t\t\t\t     tvb_format_text (tvb, off+1, len-1));\n\t\t\toff += 1+len;\n\t\t\tbreak;\n\t\tcase 0x04: /* LITERAL */\n\t\t\tidx = tvb_get_guintvar (tvb, off+1, &len);\n\t\t\tstr_len = tvb_strsize (tvb, str_tbl+idx);\n\t\t\tproto_tree_add_text (tree, tvb, off, 1+len,\n\t\t\t\t\t     \"  %3d |  Attr | A %3d    \"\n\t\t\t\t\t     \"| LITERAL (Literal Attribute)     \"\n\t\t\t\t\t     \"|   %s<%s />\",\n\t\t\t\t\t     level, *codepage_attr, Indent (level),\n\t\t\t\t\t     tvb_format_text (tvb, str_tbl+idx, str_len-1));\n\t\t\toff += 1+len;\n\t\t\tbreak;\n\t\tcase 0x40: /* EXT_I_0 */\n\t\tcase 0x41: /* EXT_I_1 */\n\t\tcase 0x42: /* EXT_I_2 */\n\t\t\t/* Extension tokens */\n\t\t\tlen = tvb_strsize (tvb, off+1);\n\t\t\tproto_tree_add_text (tree, tvb, off, 1+len,\n\t\t\t\t\t     \"  %3d |  Attr | A %3d    \"\n\t\t\t\t\t     \"| EXT_I_%1x    (Extension Token)    \"\n\t\t\t\t\t     \"|     %s(Inline string extension: \\'%s\\')\",\n\t\t\t\t\t     level, *codepage_attr, peek & 0x0f, Indent (level),\n\t\t\t\t\t     tvb_format_text (tvb, off+1, len-1));\n\t\t\toff += 1+len;\n\t\t\tbreak;\n\t\t\t/* 0x43 impossible in ATTR state */\n\t\t\t/* 0x44 impossible in ATTR state */\n\t\tcase 0x80: /* EXT_T_0 */\n\t\tcase 0x81: /* EXT_T_1 */\n\t\tcase 0x82: /* EXT_T_2 */\n\t\t\t/* Extension tokens */\n\t\t\tidx = tvb_get_guintvar (tvb, off+1, &len);\n\t\t\tproto_tree_add_text (tree, tvb, off, 1+len,\n\t\t\t\t\t     \"  %3d |  Attr | A %3d    \"\n\t\t\t\t\t     \"| EXT_T_%1x    (Extension Token)    \"\n\t\t\t\t\t     \"|     %s(Extension Token, integer value: %u)\",\n\t\t\t\t\t     level, *codepage_attr, peek & 0x0f, Indent (level),\n\t\t\t\t\t     idx);\n\t\t\toff += 1+len;\n\t\t\tbreak;\n\t\tcase 0x83: /* STR_T */\n\t\t\tidx = tvb_get_guintvar (tvb, off+1, &len);\n\t\t\tstr_len = tvb_strsize (tvb, str_tbl+idx);\n\t\t\tproto_tree_add_text (tree, tvb, off, 1+len,\n\t\t\t\t\t     \"  %3d |  Attr | A %3d    \"\n\t\t\t\t\t     \"| STR_T (Tableref string)         \"\n\t\t\t\t\t     \"|     %s\\'%s\\'\",\n\t\t\t\t\t     level, *codepage_attr, Indent (level),\n\t\t\t\t\t     tvb_format_text (tvb, str_tbl+idx, str_len-1));\n\t\t\toff += 1+len;\n\t\t\tbreak;\n\t\t\t/* 0x84 impossible in ATTR state */\n\t\tcase 0xC0: /* EXT_0 */\n\t\tcase 0xC1: /* EXT_1 */\n\t\tcase 0xC2: /* EXT_2 */\n\t\t\t/* Extension tokens */\n\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t     \"  %3d |  Attr | A %3d    \"\n\t\t\t\t\t     \"| EXT_%1x      (Extension Token)    \"\n\t\t\t\t\t     \"|     %s(Single-byte extension)\",\n\t\t\t\t\t     level, *codepage_attr, peek & 0x0f, Indent (level));\n\t\t\toff++;\n\t\t\tbreak;\n\t\tcase 0xC3: /* OPAQUE - WBXML 1.1 and newer */\n\t\t\tif (tvb_get_guint8 (tvb, 0)) { /* WBXML 1.x (x > 0) */\n\t\t\t\tidx = tvb_get_guintvar (tvb, off+1, &len);\n\t\t\t\tproto_tree_add_text (tree, tvb, off, 1 + len + idx,\n\t\t\t\t\t\t     \"  %3d |  Attr | A %3d    \"\n\t\t\t\t\t\t     \"| OPAQUE (Opaque data)            \"\n\t\t\t\t\t\t     \"|       %s(%d bytes of opaque data)\",\n\t\t\t\t\t\t     level, *codepage_attr, Indent (level), idx);\n\t\t\t\toff += 1+len+idx;\n\t\t\t} else { /* WBXML 1.0 - RESERVED_2 token (invalid) */\n\t\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t\t     \"  %3d |  Attr | A %3d    \"\n\t\t\t\t\t\t     \"| RESERVED_2     (Invalid Token!) \"\n\t\t\t\t\t\t     \"| WBXML 1.0 parsing stops here.\",\n\t\t\t\t\t\t     level, *codepage_attr);\n\t\t\t\t/* Stop processing as it is impossible to parse now */\n\t\t\t\toff = tvb_len;\n\t\t\t\tDebugLog((\"ATTR: level = %u, Return: len = %u\\n\",\n\t\t\t\t\t  level, off - offset));\n\t\t\t\treturn (off - offset);\n\t\t\t}\n\t\t\tbreak;\n\t\t\t/* 0xC4 impossible in ATTR state */\n\t\tdefault:\n\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t     \"  %3d |  Attr | A %3d    \"\n\t\t\t\t\t     \"| %-10s     (Invalid Token!) \"\n\t\t\t\t\t     \"| WBXML parsing stops here.\",\n\t\t\t\t\t     level, *codepage_attr,\n\t\t\t\t\t     val_to_str_ext (peek, &vals_wbxml1x_global_tokens_ext, \"(unknown 0x%x)\"));\n\t\t\t/* Move to end of buffer */\n\t\t\toff = tvb_len;\n\t\t\tbreak;\n\t\t} else { /* Known atribute token */\n\t\t\tif (peek & 0x80) { /* attrValue */\n\t\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t\t     \"  %3d |  Attr | A %3d    \"\n\t\t\t\t\t\t     \"|   Known attrValue 0x%02X          \"\n\t\t\t\t\t\t     \"|       %sattrValue_0x%02X\",\n\t\t\t\t\t\t     level, *codepage_attr, peek & 0x7f, Indent (level),\n\t\t\t\t\t\t     peek);\n\t\t\t\toff++;\n\t\t\t} else { /* attrStart */\n\t\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t\t     \"  %3d |  Attr | A %3d    \"\n\t\t\t\t\t\t     \"|   Known attrStart 0x%02X          \"\n\t\t\t\t\t\t     \"|   %sattrStart_0x%02X\",\n\t\t\t\t\t\t     level, *codepage_attr, peek & 0x7f, Indent (level),\n\t\t\t\t\t\t     peek);\n\t\t\t\toff++;\n\t\t\t}\n\t\t}\n\t} /* End WHILE */\n\tDebugLog((\"ATTR: level = %u, Return: len = %u (end of function body)\\n\",\n\t\t  level, off - offset));\n\treturn (off - offset);\n}",
        "func": "static guint32\nparse_wbxml_attribute_list (proto_tree *tree, tvbuff_t *tvb,\n\t\t\t    guint32 offset, guint32 str_tbl, guint8 level, guint8 *codepage_attr)\n{\n\tguint32 tvb_len = tvb_reported_length (tvb);\n\tguint32 off     = offset, last_off;\n\tguint32 len;\n\tguint   str_len;\n\tguint32 ent;\n\tguint32 idx;\n\tguint8  peek;\n\n\tDebugLog((\"parse_wbxml_attr (level = %u, offset = %u)\\n\", level, offset));\n\t/* Parse attributes */\n\tlast_off = off;\n\twhile (off < tvb_len) {\n\t\tpeek = tvb_get_guint8 (tvb, off);\n\t\tDebugLog((\"ATTR: (top of while) level = %3u, peek = 0x%02X, \"\n\t\t\t  \"off = %u, tvb_len = %u\\n\", level, peek, off, tvb_len));\n\t\tif ((peek & 0x3F) < 5) switch (peek) { /* Global tokens\n\t\t\t\t\t\t\t  in state = ATTR */\n\t\tcase 0x00: /* SWITCH_PAGE */\n\t\t\t*codepage_attr = tvb_get_guint8 (tvb, off+1);\n\t\t\tproto_tree_add_text (tree, tvb, off, 2,\n\t\t\t\t\t     \"      |  Attr | A -->%3d \"\n\t\t\t\t\t     \"| SWITCH_PAGE (Attr code page)    |\",\n\t\t\t\t\t     *codepage_attr);\n\t\t\toff += 2;\n\t\t\tbreak;\n\t\tcase 0x01: /* END */\n\t\t\t/* BEWARE\n\t\t\t *   The Attribute END token means either \">\" or \"/>\"\n\t\t\t *   and as a consequence both must be treated separately.\n\t\t\t *   This is done in the TAG state parser.\n\t\t\t */\n\t\t\toff++;\n\t\t\tDebugLog((\"ATTR: level = %u, Return: len = %u\\n\",\n\t\t\t\t  level, off - offset));\n\t\t\treturn (off - offset);\n\t\tcase 0x02: /* ENTITY */\n\t\t\tent = tvb_get_guintvar (tvb, off+1, &len);\n\t\t\tproto_tree_add_text (tree, tvb, off, 1+len,\n\t\t\t\t\t     \"  %3d |  Attr | A %3d    \"\n\t\t\t\t\t     \"| ENTITY                          \"\n\t\t\t\t\t     \"|     %s'&#%u;'\",\n\t\t\t\t\t     level, *codepage_attr, Indent (level), ent);\n\t\t\toff += 1+len;\n\t\t\tbreak;\n\t\tcase 0x03: /* STR_I */\n\t\t\tlen = tvb_strsize (tvb, off+1);\n\t\t\tproto_tree_add_text (tree, tvb, off, 1+len,\n\t\t\t\t\t     \"  %3d |  Attr | A %3d    \"\n\t\t\t\t\t     \"| STR_I (Inline string)           \"\n\t\t\t\t\t     \"|     %s\\'%s\\'\",\n\t\t\t\t\t     level, *codepage_attr, Indent (level),\n\t\t\t\t\t     tvb_format_text (tvb, off+1, len-1));\n\t\t\toff += 1+len;\n\t\t\tbreak;\n\t\tcase 0x04: /* LITERAL */\n\t\t\tidx = tvb_get_guintvar (tvb, off+1, &len);\n\t\t\tstr_len = tvb_strsize (tvb, str_tbl+idx);\n\t\t\tproto_tree_add_text (tree, tvb, off, 1+len,\n\t\t\t\t\t     \"  %3d |  Attr | A %3d    \"\n\t\t\t\t\t     \"| LITERAL (Literal Attribute)     \"\n\t\t\t\t\t     \"|   %s<%s />\",\n\t\t\t\t\t     level, *codepage_attr, Indent (level),\n\t\t\t\t\t     tvb_format_text (tvb, str_tbl+idx, str_len-1));\n\t\t\toff += 1+len;\n\t\t\tbreak;\n\t\tcase 0x40: /* EXT_I_0 */\n\t\tcase 0x41: /* EXT_I_1 */\n\t\tcase 0x42: /* EXT_I_2 */\n\t\t\t/* Extension tokens */\n\t\t\tlen = tvb_strsize (tvb, off+1);\n\t\t\tproto_tree_add_text (tree, tvb, off, 1+len,\n\t\t\t\t\t     \"  %3d |  Attr | A %3d    \"\n\t\t\t\t\t     \"| EXT_I_%1x    (Extension Token)    \"\n\t\t\t\t\t     \"|     %s(Inline string extension: \\'%s\\')\",\n\t\t\t\t\t     level, *codepage_attr, peek & 0x0f, Indent (level),\n\t\t\t\t\t     tvb_format_text (tvb, off+1, len-1));\n\t\t\toff += 1+len;\n\t\t\tbreak;\n\t\t\t/* 0x43 impossible in ATTR state */\n\t\t\t/* 0x44 impossible in ATTR state */\n\t\tcase 0x80: /* EXT_T_0 */\n\t\tcase 0x81: /* EXT_T_1 */\n\t\tcase 0x82: /* EXT_T_2 */\n\t\t\t/* Extension tokens */\n\t\t\tidx = tvb_get_guintvar (tvb, off+1, &len);\n\t\t\tproto_tree_add_text (tree, tvb, off, 1+len,\n\t\t\t\t\t     \"  %3d |  Attr | A %3d    \"\n\t\t\t\t\t     \"| EXT_T_%1x    (Extension Token)    \"\n\t\t\t\t\t     \"|     %s(Extension Token, integer value: %u)\",\n\t\t\t\t\t     level, *codepage_attr, peek & 0x0f, Indent (level),\n\t\t\t\t\t     idx);\n\t\t\toff += 1+len;\n\t\t\tbreak;\n\t\tcase 0x83: /* STR_T */\n\t\t\tidx = tvb_get_guintvar (tvb, off+1, &len);\n\t\t\tstr_len = tvb_strsize (tvb, str_tbl+idx);\n\t\t\tproto_tree_add_text (tree, tvb, off, 1+len,\n\t\t\t\t\t     \"  %3d |  Attr | A %3d    \"\n\t\t\t\t\t     \"| STR_T (Tableref string)         \"\n\t\t\t\t\t     \"|     %s\\'%s\\'\",\n\t\t\t\t\t     level, *codepage_attr, Indent (level),\n\t\t\t\t\t     tvb_format_text (tvb, str_tbl+idx, str_len-1));\n\t\t\toff += 1+len;\n\t\t\tbreak;\n\t\t\t/* 0x84 impossible in ATTR state */\n\t\tcase 0xC0: /* EXT_0 */\n\t\tcase 0xC1: /* EXT_1 */\n\t\tcase 0xC2: /* EXT_2 */\n\t\t\t/* Extension tokens */\n\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t     \"  %3d |  Attr | A %3d    \"\n\t\t\t\t\t     \"| EXT_%1x      (Extension Token)    \"\n\t\t\t\t\t     \"|     %s(Single-byte extension)\",\n\t\t\t\t\t     level, *codepage_attr, peek & 0x0f, Indent (level));\n\t\t\toff++;\n\t\t\tbreak;\n\t\tcase 0xC3: /* OPAQUE - WBXML 1.1 and newer */\n\t\t\tif (tvb_get_guint8 (tvb, 0)) { /* WBXML 1.x (x > 0) */\n\t\t\t\tidx = tvb_get_guintvar (tvb, off+1, &len);\n\t\t\t\tproto_tree_add_text (tree, tvb, off, 1 + len + idx,\n\t\t\t\t\t\t     \"  %3d |  Attr | A %3d    \"\n\t\t\t\t\t\t     \"| OPAQUE (Opaque data)            \"\n\t\t\t\t\t\t     \"|       %s(%d bytes of opaque data)\",\n\t\t\t\t\t\t     level, *codepage_attr, Indent (level), idx);\n\t\t\t\toff += 1+len+idx;\n\t\t\t} else { /* WBXML 1.0 - RESERVED_2 token (invalid) */\n\t\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t\t     \"  %3d |  Attr | A %3d    \"\n\t\t\t\t\t\t     \"| RESERVED_2     (Invalid Token!) \"\n\t\t\t\t\t\t     \"| WBXML 1.0 parsing stops here.\",\n\t\t\t\t\t\t     level, *codepage_attr);\n\t\t\t\t/* Stop processing as it is impossible to parse now */\n\t\t\t\toff = tvb_len;\n\t\t\t\tDebugLog((\"ATTR: level = %u, Return: len = %u\\n\",\n\t\t\t\t\t  level, off - offset));\n\t\t\t\treturn (off - offset);\n\t\t\t}\n\t\t\tbreak;\n\t\t\t/* 0xC4 impossible in ATTR state */\n\t\tdefault:\n\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t     \"  %3d |  Attr | A %3d    \"\n\t\t\t\t\t     \"| %-10s     (Invalid Token!) \"\n\t\t\t\t\t     \"| WBXML parsing stops here.\",\n\t\t\t\t\t     level, *codepage_attr,\n\t\t\t\t\t     val_to_str_ext (peek, &vals_wbxml1x_global_tokens_ext, \"(unknown 0x%x)\"));\n\t\t\t/* Move to end of buffer */\n\t\t\toff = tvb_len;\n\t\t\tbreak;\n\t\t} else { /* Known atribute token */\n\t\t\tif (peek & 0x80) { /* attrValue */\n\t\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t\t     \"  %3d |  Attr | A %3d    \"\n\t\t\t\t\t\t     \"|   Known attrValue 0x%02X          \"\n\t\t\t\t\t\t     \"|       %sattrValue_0x%02X\",\n\t\t\t\t\t\t     level, *codepage_attr, peek & 0x7f, Indent (level),\n\t\t\t\t\t\t     peek);\n\t\t\t\toff++;\n\t\t\t} else { /* attrStart */\n\t\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t\t     \"  %3d |  Attr | A %3d    \"\n\t\t\t\t\t\t     \"|   Known attrStart 0x%02X          \"\n\t\t\t\t\t\t     \"|   %sattrStart_0x%02X\",\n\t\t\t\t\t\t     level, *codepage_attr, peek & 0x7f, Indent (level),\n\t\t\t\t\t\t     peek);\n\t\t\t\toff++;\n\t\t\t}\n\t\t}\n\t\tif (off < last_off) {\n\t\t\tTHROW(ReportedBoundsError);\n\t\t}\n\t\tlast_off = off;\n\t} /* End WHILE */\n\tDebugLog((\"ATTR: level = %u, Return: len = %u (end of function body)\\n\",\n\t\t  level, off - offset));\n\treturn (off - offset);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,7 +3,7 @@\n \t\t\t    guint32 offset, guint32 str_tbl, guint8 level, guint8 *codepage_attr)\n {\n \tguint32 tvb_len = tvb_reported_length (tvb);\n-\tguint32 off     = offset;\n+\tguint32 off     = offset, last_off;\n \tguint32 len;\n \tguint   str_len;\n \tguint32 ent;\n@@ -12,6 +12,7 @@\n \n \tDebugLog((\"parse_wbxml_attr (level = %u, offset = %u)\\n\", level, offset));\n \t/* Parse attributes */\n+\tlast_off = off;\n \twhile (off < tvb_len) {\n \t\tpeek = tvb_get_guint8 (tvb, off);\n \t\tDebugLog((\"ATTR: (top of while) level = %3u, peek = 0x%02X, \"\n@@ -169,6 +170,10 @@\n \t\t\t\toff++;\n \t\t\t}\n \t\t}\n+\t\tif (off < last_off) {\n+\t\t\tTHROW(ReportedBoundsError);\n+\t\t}\n+\t\tlast_off = off;\n \t} /* End WHILE */\n \tDebugLog((\"ATTR: level = %u, Return: len = %u (end of function body)\\n\",\n \t\t  level, off - offset));",
        "diff_line_info": {
            "deleted_lines": [
                "\tguint32 off     = offset;"
            ],
            "added_lines": [
                "\tguint32 off     = offset, last_off;",
                "\tlast_off = off;",
                "\t\tif (off < last_off) {",
                "\t\t\tTHROW(ReportedBoundsError);",
                "\t\t}",
                "\t\tlast_off = off;"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-5359",
        "func_name": "wireshark/parse_wbxml_attribute_list_defined",
        "description": "epan/dissectors/packet-wbxml.c in the WBXML dissector in Wireshark 1.12.x before 1.12.12 mishandles offsets, which allows remote attackers to cause a denial of service (integer overflow and infinite loop) via a crafted packet.",
        "git_url": "https://github.com/wireshark/wireshark/commit/b8e0d416898bb975a02c1b55883342edc5b4c9c0",
        "commit_title": "WBXML: add a basic sanity check for offset overflow",
        "commit_text": " This is a naive approach allowing to detact that something went wrong, without the need to replace all proto_tree_add_text() calls as what was done in master-2.0 branch.  Bug: 12408",
        "func_before": "static guint32\nparse_wbxml_attribute_list_defined (proto_tree *tree, tvbuff_t *tvb,\n\t\t\t\t    guint32 offset, guint32 str_tbl, guint8 level, guint8 *codepage_attr,\n\t\t\t\t    const wbxml_decoding *map)\n{\n\tguint32     tvb_len = tvb_reported_length (tvb);\n\tguint32     off     = offset;\n\tguint32     len;\n\tguint       str_len;\n\tguint32     ent;\n\tguint32     idx;\n\tguint8      peek;\n\tguint8      attr_save_known   = 0; /* Will contain peek & 0x3F (attr identity) */\n\tconst char *attr_save_literal = NULL; /* Will contain the LITERAL attr identity */\n\n\tDebugLog((\"parse_wbxml_attr_defined (level = %u, offset = %u)\\n\",\n\t\t  level, offset));\n\t/* Parse attributes */\n\twhile (off < tvb_len) {\n\t\tpeek = tvb_get_guint8 (tvb, off);\n\t\tDebugLog((\"ATTR: (top of while) level = %3u, peek = 0x%02X, \"\n\t\t\t  \"off = %u, tvb_len = %u\\n\", level, peek, off, tvb_len));\n\t\tif ((peek & 0x3F) < 5) switch (peek) { /* Global tokens\n\t\t\t\t\t\t\t  in state = ATTR */\n\t\tcase 0x00: /* SWITCH_PAGE */\n\t\t\t*codepage_attr = tvb_get_guint8 (tvb, off+1);\n\t\t\tproto_tree_add_text (tree, tvb, off, 2,\n\t\t\t\t\t     \"      |  Attr | A -->%3d \"\n\t\t\t\t\t     \"| SWITCH_PAGE (Attr code page)    |\",\n\t\t\t\t\t     *codepage_attr);\n\t\t\toff += 2;\n\t\t\tbreak;\n\t\tcase 0x01: /* END */\n\t\t\t/* BEWARE\n\t\t\t *   The Attribute END token means either \">\" or \"/>\"\n\t\t\t *   and as a consequence both must be treated separately.\n\t\t\t *   This is done in the TAG state parser.\n\t\t\t */\n\t\t\toff++;\n\t\t\tDebugLog((\"ATTR: level = %u, Return: len = %u\\n\",\n\t\t\t\t  level, off - offset));\n\t\t\treturn (off - offset);\n\t\tcase 0x02: /* ENTITY */\n\t\t\tent = tvb_get_guintvar (tvb, off+1, &len);\n\t\t\tproto_tree_add_text (tree, tvb, off, 1+len,\n\t\t\t\t\t     \"  %3d |  Attr | A %3d    \"\n\t\t\t\t\t     \"| ENTITY                          \"\n\t\t\t\t\t     \"|     %s'&#%u;'\",\n\t\t\t\t\t     level, *codepage_attr, Indent (level), ent);\n\t\t\toff += 1+len;\n\t\t\tbreak;\n\t\tcase 0x03: /* STR_I */\n\t\t\tlen = tvb_strsize (tvb, off+1);\n\t\t\tproto_tree_add_text (tree, tvb, off, 1+len,\n\t\t\t\t\t     \"  %3d |  Attr | A %3d    \"\n\t\t\t\t\t     \"| STR_I (Inline string)           \"\n\t\t\t\t\t     \"|     %s\\'%s\\'\",\n\t\t\t\t\t     level, *codepage_attr, Indent (level),\n\t\t\t\t\t     tvb_format_text (tvb, off+1, len-1));\n\t\t\toff += 1+len;\n\t\t\tbreak;\n\t\tcase 0x04: /* LITERAL */\n\t\t\t/* ALWAYS means the start of a new attribute,\n\t\t\t * and may only contain the NAME of the attribute.\n\t\t\t */\n\t\t\tidx = tvb_get_guintvar (tvb, off+1, &len);\n\t\t\tstr_len = tvb_strsize (tvb, str_tbl+idx);\n\t\t\tattr_save_known = 0;\n\t\t\tattr_save_literal = tvb_format_text (tvb,\n\t\t\t\t\t\t\t     str_tbl+idx, str_len-1);\n\t\t\tproto_tree_add_text (tree, tvb, off, 1+len,\n\t\t\t\t\t     \"  %3d |  Attr | A %3d    \"\n\t\t\t\t\t     \"| LITERAL (Literal Attribute)     \"\n\t\t\t\t\t     \"|   %s<%s />\",\n\t\t\t\t\t     level, *codepage_attr, Indent (level),\n\t\t\t\t\t     attr_save_literal);\n\t\t\toff += 1+len;\n\t\t\tbreak;\n\t\tcase 0x40: /* EXT_I_0 */\n\t\tcase 0x41: /* EXT_I_1 */\n\t\tcase 0x42: /* EXT_I_2 */\n\t\t\t/* Extension tokens */\n\t\t\tlen = tvb_strsize (tvb, off+1);\n\t\t\tproto_tree_add_text (tree, tvb, off, 1+len,\n\t\t\t\t\t     \"  %3d |  Attr | A %3d    \"\n\t\t\t\t\t     \"| EXT_I_%1x    (Extension Token)    \"\n\t\t\t\t\t     \"|     %s(%s: \\'%s\\')\",\n\t\t\t\t\t     level, *codepage_attr, peek & 0x0f, Indent (level),\n\t\t\t\t\t     map_token (map->global, 0, peek),\n\t\t\t\t\t     tvb_format_text (tvb, off+1, len-1));\n\t\t\toff += 1+len;\n\t\t\tbreak;\n\t\t\t/* 0x43 impossible in ATTR state */\n\t\t\t/* 0x44 impossible in ATTR state */\n\t\tcase 0x80: /* EXT_T_0 */\n\t\tcase 0x81: /* EXT_T_1 */\n\t\tcase 0x82: /* EXT_T_2 */\n\t\t\t/* Extension tokens */\n\t\t\tidx = tvb_get_guintvar (tvb, off+1, &len);\n\t\t\t{   char *s;\n\n\t\t\t\tif (map->ext_t[peek & 0x03])\n\t\t\t\t\ts = (map->ext_t[peek & 0x03])(tvb, idx, str_tbl);\n\t\t\t\telse\n\t\t\t\t\ts = wmem_strdup_printf(wmem_packet_scope(), \"EXT_T_%1x (%s)\", peek & 0x03,\n\t\t\t\t\t\t\t    map_token (map->global, 0, peek));\n\n\t\t\t\tproto_tree_add_text (tree, tvb, off, 1+len,\n\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t\t     \"| EXT_T_%1x    (Extension Token)    \"\n\t\t\t\t\t\t     \"| %s%s)\",\n\t\t\t\t\t\t     level, *codepage_attr, peek & 0x0f, Indent (level),\n\t\t\t\t\t\t     s);\n\t\t\t}\n\t\t\toff += 1+len;\n\t\t\tbreak;\n\t\tcase 0x83: /* STR_T */\n\t\t\tidx = tvb_get_guintvar (tvb, off+1, &len);\n\t\t\tstr_len = tvb_strsize (tvb, str_tbl+idx);\n\t\t\tproto_tree_add_text (tree, tvb, off, 1+len,\n\t\t\t\t\t     \"  %3d |  Attr | A %3d    \"\n\t\t\t\t\t     \"| STR_T (Tableref string)         \"\n\t\t\t\t\t     \"|     %s\\'%s\\'\",\n\t\t\t\t\t     level, *codepage_attr, Indent (level),\n\t\t\t\t\t     tvb_format_text (tvb, str_tbl+idx, str_len-1));\n\t\t\toff += 1+len;\n\t\t\tbreak;\n\t\t\t/* 0x84 impossible in ATTR state */\n\t\tcase 0xC0: /* EXT_0 */\n\t\tcase 0xC1: /* EXT_1 */\n\t\tcase 0xC2: /* EXT_2 */\n\t\t\t/* Extension tokens */\n\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t     \"  %3d |  Attr | A %3d    \"\n\t\t\t\t\t     \"| EXT_%1x      (Extension Token)    \"\n\t\t\t\t\t     \"|     %s(%s)\",\n\t\t\t\t\t     level, *codepage_attr, peek & 0x0f, Indent (level),\n\t\t\t\t\t     map_token (map->global, 0, peek));\n\t\t\toff++;\n\t\t\tbreak;\n\t\tcase 0xC3: /* OPAQUE - WBXML 1.1 and newer */\n\t\t\tif (tvb_get_guint8 (tvb, 0)) { /* WBXML 1.x (x > 0) */\n\t\t\t\tchar *str;\n\t\t\t\tif (attr_save_known) { /* Knwon attribute */\n\t\t\t\t\tif (map->opaque_binary_attr) {\n\t\t\t\t\t\tstr = map->opaque_binary_attr(tvb, off + 1,\n\t\t\t\t\t\t\t\t\t      attr_save_known, *codepage_attr, &len);\n\t\t\t\t\t} else {\n\t\t\t\t\t\tstr = default_opaque_binary_attr(tvb, off + 1,\n\t\t\t\t\t\t\t\t\t\t attr_save_known, *codepage_attr, &len);\n\t\t\t\t\t}\n\t\t\t\t} else { /* lITERAL attribute */\n\t\t\t\t\tif (map->opaque_literal_tag) {\n\t\t\t\t\t\tstr = map->opaque_literal_attr(tvb, off + 1,\n\t\t\t\t\t\t\t\t\t       attr_save_literal, *codepage_attr, &len);\n\t\t\t\t\t} else {\n\t\t\t\t\t\tstr = default_opaque_literal_attr(tvb, off + 1,\n\t\t\t\t\t\t\t\t\t\t  attr_save_literal, *codepage_attr, &len);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tproto_tree_add_text (tree, tvb, off, 1 + len,\n\t\t\t\t\t\t     \"  %3d |  Attr | A %3d    \"\n\t\t\t\t\t\t     \"| OPAQUE (Opaque data)            \"\n\t\t\t\t\t\t     \"|       %s%s\",\n\t\t\t\t\t\t     level, *codepage_attr, Indent (level), str);\n\t\t\t\toff += 1 + len;\n\t\t\t} else { /* WBXML 1.0 - RESERVED_2 token (invalid) */\n\t\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t\t     \"  %3d |  Attr | A %3d    \"\n\t\t\t\t\t\t     \"| RESERVED_2     (Invalid Token!) \"\n\t\t\t\t\t\t     \"| WBXML 1.0 parsing stops here.\",\n\t\t\t\t\t\t     level, *codepage_attr);\n\t\t\t\t/* Stop processing as it is impossible to parse now */\n\t\t\t\toff = tvb_len;\n\t\t\t\tDebugLog((\"ATTR: level = %u, Return: len = %u\\n\",\n\t\t\t\t\t  level, off - offset));\n\t\t\t\treturn (off - offset);\n\t\t\t}\n\t\t\tbreak;\n\t\t\t/* 0xC4 impossible in ATTR state */\n\t\tdefault:\n\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t     \"  %3d |  Attr | A %3d    \"\n\t\t\t\t\t     \"| %-10s     (Invalid Token!) \"\n\t\t\t\t\t     \"| WBXML parsing stops here.\",\n\t\t\t\t\t     level, *codepage_attr,\n\t\t\t\t\t     val_to_str_ext (peek, &vals_wbxml1x_global_tokens_ext, \"(unknown 0x%x)\"));\n\t\t\t/* Move to end of buffer */\n\t\t\toff = tvb_len;\n\t\t\tbreak;\n\t\t} else { /* Known atribute token */\n\t\t\tif (peek & 0x80) { /* attrValue */\n\t\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t\t     \"  %3d |  Attr | A %3d    \"\n\t\t\t\t\t\t     \"|   Known attrValue 0x%02X          \"\n\t\t\t\t\t\t     \"|       %s%s\",\n\t\t\t\t\t\t     level, *codepage_attr, peek & 0x7f, Indent (level),\n\t\t\t\t\t\t     map_token (map->attrValue, *codepage_attr, peek));\n\t\t\t\toff++;\n\t\t\t} else { /* attrStart */\n\t\t\t\tattr_save_known = peek & 0x7f;\n\t\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t\t     \"  %3d |  Attr | A %3d    \"\n\t\t\t\t\t\t     \"|   Known attrStart 0x%02X          \"\n\t\t\t\t\t\t     \"|   %s%s\",\n\t\t\t\t\t\t     level, *codepage_attr, attr_save_known, Indent (level),\n\t\t\t\t\t\t     map_token (map->attrStart, *codepage_attr, peek));\n\t\t\t\toff++;\n\t\t\t}\n\t\t}\n\t} /* End WHILE */\n\tDebugLog((\"ATTR: level = %u, Return: len = %u (end of function body)\\n\",\n\t\t  level, off - offset));\n\treturn (off - offset);\n}",
        "func": "static guint32\nparse_wbxml_attribute_list_defined (proto_tree *tree, tvbuff_t *tvb,\n\t\t\t\t    guint32 offset, guint32 str_tbl, guint8 level, guint8 *codepage_attr,\n\t\t\t\t    const wbxml_decoding *map)\n{\n\tguint32     tvb_len = tvb_reported_length (tvb);\n\tguint32     off     = offset, last_off;\n\tguint32     len;\n\tguint       str_len;\n\tguint32     ent;\n\tguint32     idx;\n\tguint8      peek;\n\tguint8      attr_save_known   = 0; /* Will contain peek & 0x3F (attr identity) */\n\tconst char *attr_save_literal = NULL; /* Will contain the LITERAL attr identity */\n\n\tDebugLog((\"parse_wbxml_attr_defined (level = %u, offset = %u)\\n\",\n\t\t  level, offset));\n\t/* Parse attributes */\n\tlast_off = off;\n\twhile (off < tvb_len) {\n\t\tpeek = tvb_get_guint8 (tvb, off);\n\t\tDebugLog((\"ATTR: (top of while) level = %3u, peek = 0x%02X, \"\n\t\t\t  \"off = %u, tvb_len = %u\\n\", level, peek, off, tvb_len));\n\t\tif ((peek & 0x3F) < 5) switch (peek) { /* Global tokens\n\t\t\t\t\t\t\t  in state = ATTR */\n\t\tcase 0x00: /* SWITCH_PAGE */\n\t\t\t*codepage_attr = tvb_get_guint8 (tvb, off+1);\n\t\t\tproto_tree_add_text (tree, tvb, off, 2,\n\t\t\t\t\t     \"      |  Attr | A -->%3d \"\n\t\t\t\t\t     \"| SWITCH_PAGE (Attr code page)    |\",\n\t\t\t\t\t     *codepage_attr);\n\t\t\toff += 2;\n\t\t\tbreak;\n\t\tcase 0x01: /* END */\n\t\t\t/* BEWARE\n\t\t\t *   The Attribute END token means either \">\" or \"/>\"\n\t\t\t *   and as a consequence both must be treated separately.\n\t\t\t *   This is done in the TAG state parser.\n\t\t\t */\n\t\t\toff++;\n\t\t\tDebugLog((\"ATTR: level = %u, Return: len = %u\\n\",\n\t\t\t\t  level, off - offset));\n\t\t\treturn (off - offset);\n\t\tcase 0x02: /* ENTITY */\n\t\t\tent = tvb_get_guintvar (tvb, off+1, &len);\n\t\t\tproto_tree_add_text (tree, tvb, off, 1+len,\n\t\t\t\t\t     \"  %3d |  Attr | A %3d    \"\n\t\t\t\t\t     \"| ENTITY                          \"\n\t\t\t\t\t     \"|     %s'&#%u;'\",\n\t\t\t\t\t     level, *codepage_attr, Indent (level), ent);\n\t\t\toff += 1+len;\n\t\t\tbreak;\n\t\tcase 0x03: /* STR_I */\n\t\t\tlen = tvb_strsize (tvb, off+1);\n\t\t\tproto_tree_add_text (tree, tvb, off, 1+len,\n\t\t\t\t\t     \"  %3d |  Attr | A %3d    \"\n\t\t\t\t\t     \"| STR_I (Inline string)           \"\n\t\t\t\t\t     \"|     %s\\'%s\\'\",\n\t\t\t\t\t     level, *codepage_attr, Indent (level),\n\t\t\t\t\t     tvb_format_text (tvb, off+1, len-1));\n\t\t\toff += 1+len;\n\t\t\tbreak;\n\t\tcase 0x04: /* LITERAL */\n\t\t\t/* ALWAYS means the start of a new attribute,\n\t\t\t * and may only contain the NAME of the attribute.\n\t\t\t */\n\t\t\tidx = tvb_get_guintvar (tvb, off+1, &len);\n\t\t\tstr_len = tvb_strsize (tvb, str_tbl+idx);\n\t\t\tattr_save_known = 0;\n\t\t\tattr_save_literal = tvb_format_text (tvb,\n\t\t\t\t\t\t\t     str_tbl+idx, str_len-1);\n\t\t\tproto_tree_add_text (tree, tvb, off, 1+len,\n\t\t\t\t\t     \"  %3d |  Attr | A %3d    \"\n\t\t\t\t\t     \"| LITERAL (Literal Attribute)     \"\n\t\t\t\t\t     \"|   %s<%s />\",\n\t\t\t\t\t     level, *codepage_attr, Indent (level),\n\t\t\t\t\t     attr_save_literal);\n\t\t\toff += 1+len;\n\t\t\tbreak;\n\t\tcase 0x40: /* EXT_I_0 */\n\t\tcase 0x41: /* EXT_I_1 */\n\t\tcase 0x42: /* EXT_I_2 */\n\t\t\t/* Extension tokens */\n\t\t\tlen = tvb_strsize (tvb, off+1);\n\t\t\tproto_tree_add_text (tree, tvb, off, 1+len,\n\t\t\t\t\t     \"  %3d |  Attr | A %3d    \"\n\t\t\t\t\t     \"| EXT_I_%1x    (Extension Token)    \"\n\t\t\t\t\t     \"|     %s(%s: \\'%s\\')\",\n\t\t\t\t\t     level, *codepage_attr, peek & 0x0f, Indent (level),\n\t\t\t\t\t     map_token (map->global, 0, peek),\n\t\t\t\t\t     tvb_format_text (tvb, off+1, len-1));\n\t\t\toff += 1+len;\n\t\t\tbreak;\n\t\t\t/* 0x43 impossible in ATTR state */\n\t\t\t/* 0x44 impossible in ATTR state */\n\t\tcase 0x80: /* EXT_T_0 */\n\t\tcase 0x81: /* EXT_T_1 */\n\t\tcase 0x82: /* EXT_T_2 */\n\t\t\t/* Extension tokens */\n\t\t\tidx = tvb_get_guintvar (tvb, off+1, &len);\n\t\t\t{   char *s;\n\n\t\t\t\tif (map->ext_t[peek & 0x03])\n\t\t\t\t\ts = (map->ext_t[peek & 0x03])(tvb, idx, str_tbl);\n\t\t\t\telse\n\t\t\t\t\ts = wmem_strdup_printf(wmem_packet_scope(), \"EXT_T_%1x (%s)\", peek & 0x03,\n\t\t\t\t\t\t\t    map_token (map->global, 0, peek));\n\n\t\t\t\tproto_tree_add_text (tree, tvb, off, 1+len,\n\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t\t     \"| EXT_T_%1x    (Extension Token)    \"\n\t\t\t\t\t\t     \"| %s%s)\",\n\t\t\t\t\t\t     level, *codepage_attr, peek & 0x0f, Indent (level),\n\t\t\t\t\t\t     s);\n\t\t\t}\n\t\t\toff += 1+len;\n\t\t\tbreak;\n\t\tcase 0x83: /* STR_T */\n\t\t\tidx = tvb_get_guintvar (tvb, off+1, &len);\n\t\t\tstr_len = tvb_strsize (tvb, str_tbl+idx);\n\t\t\tproto_tree_add_text (tree, tvb, off, 1+len,\n\t\t\t\t\t     \"  %3d |  Attr | A %3d    \"\n\t\t\t\t\t     \"| STR_T (Tableref string)         \"\n\t\t\t\t\t     \"|     %s\\'%s\\'\",\n\t\t\t\t\t     level, *codepage_attr, Indent (level),\n\t\t\t\t\t     tvb_format_text (tvb, str_tbl+idx, str_len-1));\n\t\t\toff += 1+len;\n\t\t\tbreak;\n\t\t\t/* 0x84 impossible in ATTR state */\n\t\tcase 0xC0: /* EXT_0 */\n\t\tcase 0xC1: /* EXT_1 */\n\t\tcase 0xC2: /* EXT_2 */\n\t\t\t/* Extension tokens */\n\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t     \"  %3d |  Attr | A %3d    \"\n\t\t\t\t\t     \"| EXT_%1x      (Extension Token)    \"\n\t\t\t\t\t     \"|     %s(%s)\",\n\t\t\t\t\t     level, *codepage_attr, peek & 0x0f, Indent (level),\n\t\t\t\t\t     map_token (map->global, 0, peek));\n\t\t\toff++;\n\t\t\tbreak;\n\t\tcase 0xC3: /* OPAQUE - WBXML 1.1 and newer */\n\t\t\tif (tvb_get_guint8 (tvb, 0)) { /* WBXML 1.x (x > 0) */\n\t\t\t\tchar *str;\n\t\t\t\tif (attr_save_known) { /* Knwon attribute */\n\t\t\t\t\tif (map->opaque_binary_attr) {\n\t\t\t\t\t\tstr = map->opaque_binary_attr(tvb, off + 1,\n\t\t\t\t\t\t\t\t\t      attr_save_known, *codepage_attr, &len);\n\t\t\t\t\t} else {\n\t\t\t\t\t\tstr = default_opaque_binary_attr(tvb, off + 1,\n\t\t\t\t\t\t\t\t\t\t attr_save_known, *codepage_attr, &len);\n\t\t\t\t\t}\n\t\t\t\t} else { /* lITERAL attribute */\n\t\t\t\t\tif (map->opaque_literal_tag) {\n\t\t\t\t\t\tstr = map->opaque_literal_attr(tvb, off + 1,\n\t\t\t\t\t\t\t\t\t       attr_save_literal, *codepage_attr, &len);\n\t\t\t\t\t} else {\n\t\t\t\t\t\tstr = default_opaque_literal_attr(tvb, off + 1,\n\t\t\t\t\t\t\t\t\t\t  attr_save_literal, *codepage_attr, &len);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tproto_tree_add_text (tree, tvb, off, 1 + len,\n\t\t\t\t\t\t     \"  %3d |  Attr | A %3d    \"\n\t\t\t\t\t\t     \"| OPAQUE (Opaque data)            \"\n\t\t\t\t\t\t     \"|       %s%s\",\n\t\t\t\t\t\t     level, *codepage_attr, Indent (level), str);\n\t\t\t\toff += 1 + len;\n\t\t\t} else { /* WBXML 1.0 - RESERVED_2 token (invalid) */\n\t\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t\t     \"  %3d |  Attr | A %3d    \"\n\t\t\t\t\t\t     \"| RESERVED_2     (Invalid Token!) \"\n\t\t\t\t\t\t     \"| WBXML 1.0 parsing stops here.\",\n\t\t\t\t\t\t     level, *codepage_attr);\n\t\t\t\t/* Stop processing as it is impossible to parse now */\n\t\t\t\toff = tvb_len;\n\t\t\t\tDebugLog((\"ATTR: level = %u, Return: len = %u\\n\",\n\t\t\t\t\t  level, off - offset));\n\t\t\t\treturn (off - offset);\n\t\t\t}\n\t\t\tbreak;\n\t\t\t/* 0xC4 impossible in ATTR state */\n\t\tdefault:\n\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t     \"  %3d |  Attr | A %3d    \"\n\t\t\t\t\t     \"| %-10s     (Invalid Token!) \"\n\t\t\t\t\t     \"| WBXML parsing stops here.\",\n\t\t\t\t\t     level, *codepage_attr,\n\t\t\t\t\t     val_to_str_ext (peek, &vals_wbxml1x_global_tokens_ext, \"(unknown 0x%x)\"));\n\t\t\t/* Move to end of buffer */\n\t\t\toff = tvb_len;\n\t\t\tbreak;\n\t\t} else { /* Known atribute token */\n\t\t\tif (peek & 0x80) { /* attrValue */\n\t\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t\t     \"  %3d |  Attr | A %3d    \"\n\t\t\t\t\t\t     \"|   Known attrValue 0x%02X          \"\n\t\t\t\t\t\t     \"|       %s%s\",\n\t\t\t\t\t\t     level, *codepage_attr, peek & 0x7f, Indent (level),\n\t\t\t\t\t\t     map_token (map->attrValue, *codepage_attr, peek));\n\t\t\t\toff++;\n\t\t\t} else { /* attrStart */\n\t\t\t\tattr_save_known = peek & 0x7f;\n\t\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t\t     \"  %3d |  Attr | A %3d    \"\n\t\t\t\t\t\t     \"|   Known attrStart 0x%02X          \"\n\t\t\t\t\t\t     \"|   %s%s\",\n\t\t\t\t\t\t     level, *codepage_attr, attr_save_known, Indent (level),\n\t\t\t\t\t\t     map_token (map->attrStart, *codepage_attr, peek));\n\t\t\t\toff++;\n\t\t\t}\n\t\t}\n\t\tif (off < last_off) {\n\t\t\tTHROW(ReportedBoundsError);\n\t\t}\n\t\tlast_off = off;\n\t} /* End WHILE */\n\tDebugLog((\"ATTR: level = %u, Return: len = %u (end of function body)\\n\",\n\t\t  level, off - offset));\n\treturn (off - offset);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,7 +4,7 @@\n \t\t\t\t    const wbxml_decoding *map)\n {\n \tguint32     tvb_len = tvb_reported_length (tvb);\n-\tguint32     off     = offset;\n+\tguint32     off     = offset, last_off;\n \tguint32     len;\n \tguint       str_len;\n \tguint32     ent;\n@@ -16,6 +16,7 @@\n \tDebugLog((\"parse_wbxml_attr_defined (level = %u, offset = %u)\\n\",\n \t\t  level, offset));\n \t/* Parse attributes */\n+\tlast_off = off;\n \twhile (off < tvb_len) {\n \t\tpeek = tvb_get_guint8 (tvb, off);\n \t\tDebugLog((\"ATTR: (top of while) level = %3u, peek = 0x%02X, \"\n@@ -208,6 +209,10 @@\n \t\t\t\toff++;\n \t\t\t}\n \t\t}\n+\t\tif (off < last_off) {\n+\t\t\tTHROW(ReportedBoundsError);\n+\t\t}\n+\t\tlast_off = off;\n \t} /* End WHILE */\n \tDebugLog((\"ATTR: level = %u, Return: len = %u (end of function body)\\n\",\n \t\t  level, off - offset));",
        "diff_line_info": {
            "deleted_lines": [
                "\tguint32     off     = offset;"
            ],
            "added_lines": [
                "\tguint32     off     = offset, last_off;",
                "\tlast_off = off;",
                "\t\tif (off < last_off) {",
                "\t\t\tTHROW(ReportedBoundsError);",
                "\t\t}",
                "\t\tlast_off = off;"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-5359",
        "func_name": "wireshark/parse_wbxml_tag",
        "description": "epan/dissectors/packet-wbxml.c in the WBXML dissector in Wireshark 1.12.x before 1.12.12 mishandles offsets, which allows remote attackers to cause a denial of service (integer overflow and infinite loop) via a crafted packet.",
        "git_url": "https://github.com/wireshark/wireshark/commit/b8e0d416898bb975a02c1b55883342edc5b4c9c0",
        "commit_title": "WBXML: add a basic sanity check for offset overflow",
        "commit_text": " This is a naive approach allowing to detact that something went wrong, without the need to replace all proto_tree_add_text() calls as what was done in master-2.0 branch.  Bug: 12408",
        "func_before": "static guint32\nparse_wbxml_tag (proto_tree *tree, tvbuff_t *tvb, guint32 offset,\n\t\t guint32 str_tbl, guint8 *level,\n\t\t guint8 *codepage_stag, guint8 *codepage_attr)\n{\n\tguint32     tvb_len             = tvb_reported_length (tvb);\n\tguint32     off                 = offset;\n\tguint32     len;\n\tguint       str_len;\n\tguint32     ent;\n\tguint32     idx;\n\tguint8      peek;\n\tguint32     tag_len;                     /* Length of the idx (uintvar) from a LITERAL tag */\n\tguint8      tag_save_known      = 0;     /* Will contain peek & 0x3F (tag identity) */\n\tguint8      tag_new_known       = 0;     /* Will contain peek & 0x3F (tag identity) */\n\tconst char *tag_save_literal;            /* Will contain the LITERAL tag identity */\n\tconst char *tag_new_literal;             /* Will contain the LITERAL tag identity */\n\tchar       *tag_save_buf        = NULL;  /* Will contain \"tag_0x%02X\" */\n\tchar       *tag_new_buf         = NULL;  /* Will contain \"tag_0x%02X\" */\n\tguint8      parsing_tag_content = FALSE; /* Are we parsing content from a\n\t\t\t\t\t            tag with content: <x>Content</x>\n\n\t\t\t\t\t            The initial state is FALSE.\n\t\t\t\t\t            This state will trigger recursion. */\n\ttag_save_literal = NULL;                 /* Prevents compiler warning */\n\n\tDebugLog((\"parse_wbxml_tag (level = %u, offset = %u)\\n\", *level, offset));\n\twhile (off < tvb_len) {\n\t\tpeek = tvb_get_guint8 (tvb, off);\n\t\tDebugLog((\"STAG: (top of while) level = %3u, peek = 0x%02X, off = %u, tvb_len = %u\\n\", *level, peek, off, tvb_len));\n\t\tif ((peek & 0x3F) < 4) switch (peek) { /* Global tokens in state = STAG\n\t\t\t\t\t\t\t  but not the LITERAL tokens */\n\t\tcase 0x00: /* SWITCH_PAGE */\n\t\t\t*codepage_stag = tvb_get_guint8 (tvb, off+1);\n\t\t\tproto_tree_add_text (tree, tvb, off, 2,\n\t\t\t\t\t     \"      | Tag   | T -->%3d \"\n\t\t\t\t\t     \"| SWITCH_PAGE (Tag code page)     \"\n\t\t\t\t\t     \"|\",\n\t\t\t\t\t     *codepage_stag);\n\t\t\toff += 2;\n\t\t\tbreak;\n\t\tcase 0x01: /* END: only possible for Tag with Content */\n\t\t\tif (tag_save_known) { /* Known TAG */\n\t\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t\t     \"| END (Known Tag 0x%02X)            \"\n\t\t\t\t\t\t     \"| %s</%s>\",\n\t\t\t\t\t\t     *level, *codepage_stag, tag_save_known,\n\t\t\t\t\t\t     Indent (*level),\n\t\t\t\t\t\t     tag_save_literal); /* We already looked it up! */\n\t\t\t} else { /* Literal TAG */\n\t\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t\t     \"| END (Literal Tag)               \"\n\t\t\t\t\t\t     \"| %s</%s>\",\n\t\t\t\t\t\t     *level, *codepage_stag, Indent (*level),\n\t\t\t\t\t\t     tag_save_literal ? tag_save_literal : \"\");\n\t\t\t}\n\t\t\t(*level)--;\n\t\t\toff++;\n\t\t\t/* Reset code page: not needed as return from recursion */\n\t\t\tDebugLog((\"STAG: level = %u, Return: len = %u\\n\",\n\t\t\t\t  *level, off - offset));\n\t\t\treturn (off - offset);\n\t\tcase 0x02: /* ENTITY */\n\t\t\tent = tvb_get_guintvar (tvb, off+1, &len);\n\t\t\tproto_tree_add_text (tree, tvb, off, 1+len,\n\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t     \"| ENTITY                          \"\n\t\t\t\t\t     \"| %s'&#%u;'\",\n\t\t\t\t\t     *level, *codepage_stag, Indent (*level), ent);\n\t\t\toff += 1+len;\n\t\t\tbreak;\n\t\tcase 0x03: /* STR_I */\n\t\t\tlen = tvb_strsize (tvb, off+1);\n\t\t\tproto_tree_add_text (tree, tvb, off, 1+len,\n\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t     \"| STR_I (Inline string)           \"\n\t\t\t\t\t     \"| %s\\'%s\\'\",\n\t\t\t\t\t     *level, *codepage_stag, Indent(*level),\n\t\t\t\t\t     tvb_format_text (tvb, off+1, len-1));\n\t\t\toff += 1+len;\n\t\t\tbreak;\n\t\tcase 0x40: /* EXT_I_0 */\n\t\tcase 0x41: /* EXT_I_1 */\n\t\tcase 0x42: /* EXT_I_2 */\n\t\t\t/* Extension tokens */\n\t\t\tlen = tvb_strsize (tvb, off+1);\n\t\t\tproto_tree_add_text (tree, tvb, off, 1+len,\n\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t     \"| EXT_I_%1x    (Extension Token)    \"\n\t\t\t\t\t     \"| %s(Inline string extension: \\'%s\\')\",\n\t\t\t\t\t     *level, *codepage_stag, peek & 0x0f, Indent (*level),\n\t\t\t\t\t     tvb_format_text (tvb, off+1, len-1));\n\t\t\toff += 1+len;\n\t\t\tbreak;\n\t\tcase 0x43: /* PI */\n\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t     \"| PI (XML Processing Instruction) \"\n\t\t\t\t\t     \"| %s<?xml\",\n\t\t\t\t\t     *level, *codepage_stag, Indent (*level));\n\t\t\tlen = parse_wbxml_attribute_list (tree, tvb, off, str_tbl,\n\t\t\t\t\t\t\t  *level, codepage_attr);\n\t\t\t/* Check that there is still room in packet */\n\t\t\toff += len;\n\t\t\tif (off >= tvb_len) {\n\t\t\t\tDebugLog((\"STAG: level = %u, ThrowException: len = %u (short frame)\\n\",\n\t\t\t\t\t  *level, off - offset));\n\t\t\t\t/*\n\t\t\t\t * TODO - Do we need to free g_malloc()ed memory?\n\t\t\t\t */\n\t\t\t\tTHROW(ReportedBoundsError);\n\t\t\t}\n\t\t\tproto_tree_add_text (tree, tvb, off-1, 1,\n\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t     \"| END (PI)                        \"\n\t\t\t\t\t     \"| %s?>\",\n\t\t\t\t\t     *level, *codepage_stag, Indent (*level));\n\t\t\tbreak;\n\t\tcase 0x80: /* EXT_T_0 */\n\t\tcase 0x81: /* EXT_T_1 */\n\t\tcase 0x82: /* EXT_T_2 */\n\t\t\t/* Extension tokens */\n\t\t\tidx = tvb_get_guintvar (tvb, off+1, &len);\n\t\t\tproto_tree_add_text (tree, tvb, off, 1+len,\n\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t     \"| EXT_T_%1x    (Extension Token)    \"\n\t\t\t\t\t     \"| %s(Extension Token, integer value: %u)\",\n\t\t\t\t\t     *level, *codepage_stag, peek & 0x0f, Indent (*level),\n\t\t\t\t\t     idx);\n\t\t\toff += 1+len;\n\t\t\tbreak;\n\t\tcase 0x83: /* STR_T */\n\t\t\tidx = tvb_get_guintvar (tvb, off+1, &len);\n\t\t\tstr_len = tvb_strsize (tvb, str_tbl+idx);\n\t\t\tproto_tree_add_text (tree, tvb, off, 1+len,\n\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t     \"| STR_T (Tableref string)         \"\n\t\t\t\t\t     \"| %s\\'%s\\'\",\n\t\t\t\t\t     *level, *codepage_stag, Indent (*level),\n\t\t\t\t\t     tvb_format_text (tvb, str_tbl+idx, str_len-1));\n\t\t\toff += 1+len;\n\t\t\tbreak;\n\t\tcase 0xC0: /* EXT_0 */\n\t\tcase 0xC1: /* EXT_1 */\n\t\tcase 0xC2: /* EXT_2 */\n\t\t\t/* Extension tokens */\n\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t     \"| EXT_%1x      (Extension Token)    \"\n\t\t\t\t\t     \"| %s(Single-byte extension)\",\n\t\t\t\t\t     *level, *codepage_stag, peek & 0x0f, Indent (*level));\n\t\t\toff++;\n\t\t\tbreak;\n\t\tcase 0xC3: /* OPAQUE - WBXML 1.1 and newer */\n\t\t\tif (tvb_get_guint8 (tvb, 0)) { /* WBXML 1.x (x > 0) */\n\t\t\t\tidx = tvb_get_guintvar (tvb, off+1, &len);\n\t\t\t\tproto_tree_add_text (tree, tvb, off, 1 + len + idx,\n\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t\t     \"| OPAQUE (Opaque data)            \"\n\t\t\t\t\t\t     \"| %s(%d bytes of opaque data)\",\n\t\t\t\t\t\t     *level, *codepage_stag, Indent (*level), idx);\n\t\t\t\toff += 1+len+idx;\n\t\t\t} else { /* WBXML 1.0 - RESERVED_2 token (invalid) */\n\t\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t\t     \"| RESERVED_2     (Invalid Token!) \"\n\t\t\t\t\t\t     \"| WBXML 1.0 parsing stops here.\",\n\t\t\t\t\t\t     *level, *codepage_stag);\n\t\t\t\t/* Stop processing as it is impossible to parse now */\n\t\t\t\toff = tvb_len;\n\t\t\t\tDebugLog((\"STAG: level = %u, Return: len = %u\\n\",\n\t\t\t\t\t  *level, off - offset));\n\t\t\t\treturn (off - offset);\n\t\t\t}\n\t\t\tbreak;\n\n\t\t\t/* No default clause, as all cases have been treated */\n\t\t} else { /* LITERAL or Known TAG */\n\t\t\t/* We must store the initial tag, and also retrieve the new tag.\n\t\t\t * For efficiency reasons, we store the literal tag representation\n\t\t\t * for known tags too, so we can easily close the tag without the\n\t\t\t * need of a new lookup and avoiding storage of token codepage.\n\t\t\t *\n\t\t\t * There are 4 possibilities:\n\t\t\t *\n\t\t\t *  1. Known tag followed by a known tag\n\t\t\t *  2. Known tag followed by a LITERAL tag\n\t\t\t *  3. LITERAL tag followed by Known tag\n\t\t\t *  4. LITERAL tag followed by LITERAL tag\n\t\t\t */\n\n\t\t\t/* Store the new tag */\n\t\t\ttag_len = 0;\n\t\t\tif ((peek & 0x3F) == 4) { /* LITERAL */\n\t\t\t\tDebugLog((\"STAG: LITERAL tag (peek = 0x%02X, off = %u)\"\n\t\t\t\t\t  \" - TableRef follows!\\n\", peek, off));\n\t\t\t\tidx = tvb_get_guintvar (tvb, off+1, &tag_len);\n\t\t\t\tstr_len = tvb_strsize (tvb, str_tbl+idx);\n\t\t\t\ttag_new_literal = (const gchar*)tvb_get_ptr (tvb, str_tbl+idx, str_len);\n\t\t\t\ttag_new_known = 0; /* invalidate known tag_new */\n\t\t\t} else { /* Known tag */\n\t\t\t\ttag_new_known = peek & 0x3F;\n\t\t\t\ttag_new_buf=wmem_strdup_printf(wmem_packet_scope(), \"Tag_0x%02X\",\n\t\t\t\t\t    tag_new_known);\n\t\t\t\ttag_new_literal = tag_new_buf;\n\t\t\t\t/* Stored looked up tag name string */\n\t\t\t}\n\n\t\t\t/* Parsing of TAG starts HERE */\n\t\t\tif (peek & 0x40) { /* Content present */\n\t\t\t\t/* Content follows\n\t\t\t\t * [!] An explicit END token is expected in these cases!\n\t\t\t\t * ==> Recursion possible if we encounter a tag with content;\n\t\t\t\t *     recursion will return at the explicit END token.\n\t\t\t\t */\n\t\t\t\tif (parsing_tag_content) { /* Recurse */\n\t\t\t\t\tDebugLog((\"STAG: Tag in Tag - RECURSE! (off = %u)\\n\", off));\n\t\t\t\t\t/* Do not process the attribute list:\n\t\t\t\t\t * recursion will take care of it */\n\t\t\t\t\t(*level)++;\n\t\t\t\t\tlen = parse_wbxml_tag (tree, tvb, off, str_tbl, level,\n\t\t\t\t\t\t\t       codepage_stag, codepage_attr);\n\t\t\t\t\toff += len;\n\t\t\t\t} else { /* Now we will have content to parse */\n\t\t\t\t\t/* Save the start tag so we can properly close it later. */\n\t\t\t\t\tif ((peek & 0x3F) == 4) { /* Literal tag */\n\t\t\t\t\t\ttag_save_literal = tag_new_literal;\n\t\t\t\t\t\ttag_save_known = 0;\n\t\t\t\t\t} else { /* Known tag */\n\t\t\t\t\t\ttag_save_known = tag_new_known;\n\t\t\t\t\t\ttag_save_buf=wmem_strdup_printf(wmem_packet_scope(), \"Tag_0x%02X\",\n\t\t\t\t\t\t\t    tag_new_known);\n\t\t\t\t\t\ttag_save_literal = tag_save_buf;\n\t\t\t\t\t\t/* The last statement avoids needless lookups */\n\t\t\t\t\t}\n\t\t\t\t\t/* Process the attribute list if present */\n\t\t\t\t\tif (peek & 0x80) { /* Content and Attribute list present */\n\t\t\t\t\t\tif (tag_new_known) { /* Known tag */\n\t\t\t\t\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t\t\t\t\t     \"|   Known Tag 0x%02X           (AC) \"\n\t\t\t\t\t\t\t\t\t     \"| %s<%s\",\n\t\t\t\t\t\t\t\t\t     *level, *codepage_stag, tag_new_known,\n\t\t\t\t\t\t\t\t\t     Indent (*level), tag_new_literal);\n\t\t\t\t\t\t\t/* Tag string already looked up earlier! */\n\t\t\t\t\t\t\toff++;\n\t\t\t\t\t\t} else { /* LITERAL tag */\n\t\t\t\t\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t\t\t\t\t     \"| LITERAL_AC (Literal tag)   (AC) \"\n\t\t\t\t\t\t\t\t\t     \"| %s<%s\",\n\t\t\t\t\t\t\t\t\t     *level, *codepage_stag, Indent (*level),\n\t\t\t\t\t\t\t\t\t     tag_new_literal);\n\t\t\t\t\t\t\toff += 1 + tag_len;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tlen = parse_wbxml_attribute_list (tree, tvb,\n\t\t\t\t\t\t\t\t\t\t  off, str_tbl, *level, codepage_attr);\n\t\t\t\t\t\t/* Check that there is still room in packet */\n\t\t\t\t\t\toff += len;\n\t\t\t\t\t\tif (off >= tvb_len) {\n\t\t\t\t\t\t\tDebugLog((\"STAG: level = %u, ThrowException: \"\n\t\t\t\t\t\t\t\t  \"len = %u (short frame)\\n\",\n\t\t\t\t\t\t\t\t  *level, off - offset));\n\t\t\t\t\t\t\t/*\n\t\t\t\t\t\t\t * TODO - Do we need to free g_malloc()ed memory?\n\t\t\t\t\t\t\t */\n\t\t\t\t\t\t\tTHROW(ReportedBoundsError);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tproto_tree_add_text (tree, tvb, off-1, 1,\n\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t\t\t\t     \"| END (attribute list)            \"\n\t\t\t\t\t\t\t\t     \"| %s>\",\n\t\t\t\t\t\t\t\t     *level, *codepage_stag, Indent (*level));\n\t\t\t\t\t} else { /* Content, no Attribute list */\n\t\t\t\t\t\tif (tag_new_known) { /* Known tag */\n\t\t\t\t\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t\t\t\t\t     \"|   Known Tag 0x%02X           (.C) \"\n\t\t\t\t\t\t\t\t\t     \"| %s<%s>\",\n\t\t\t\t\t\t\t\t\t     *level, *codepage_stag, tag_new_known,\n\t\t\t\t\t\t\t\t\t     Indent (*level), tag_new_literal);\n\t\t\t\t\t\t\t/* Tag string already looked up earlier! */\n\t\t\t\t\t\t\toff++;\n\t\t\t\t\t\t} else { /* LITERAL tag */\n\t\t\t\t\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t\t\t\t\t     \"| LITERAL_C  (Literal Tag)   (.C) \"\n\t\t\t\t\t\t\t\t\t     \"| %s<%s>\",\n\t\t\t\t\t\t\t\t\t     *level, *codepage_stag, Indent (*level),\n\t\t\t\t\t\t\t\t\t     tag_new_literal);\n\t\t\t\t\t\t\toff += 1 + tag_len;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\t/* The data that follows in the parsing process\n\t\t\t\t\t * represents content for the opening tag\n\t\t\t\t\t * we've just processed in the lines above.\n\t\t\t\t\t * Next time we encounter a tag with content: recurse\n\t\t\t\t\t */\n\t\t\t\t\tparsing_tag_content = TRUE;\n\t\t\t\t\tDebugLog((\"Tag in Tag - No recursion this time! \"\n\t\t\t\t\t\t  \"(off = %u)\\n\", off));\n\t\t\t\t}\n\t\t\t} else { /* No Content */\n\t\t\t\tDebugLog((\"<Tag/> in Tag - No recursion! (off = %u)\\n\", off));\n\t\t\t\t(*level)++;\n\t\t\t\tif (peek & 0x80) { /* No Content, Attribute list present */\n\t\t\t\t\tif (tag_new_known) { /* Known tag */\n\t\t\t\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t\t\t\t     \"|   Known Tag 0x%02X           (A.) \"\n\t\t\t\t\t\t\t\t     \"| %s<%s\",\n\t\t\t\t\t\t\t\t     *level, *codepage_stag, tag_new_known,\n\t\t\t\t\t\t\t\t     Indent (*level), tag_new_literal);\n\t\t\t\t\t\t/* Tag string already looked up earlier! */\n\t\t\t\t\t\toff++;\n\t\t\t\t\t\tlen = parse_wbxml_attribute_list (tree, tvb,\n\t\t\t\t\t\t\t\t\t\t  off, str_tbl, *level, codepage_attr);\n\t\t\t\t\t\t/* Check that there is still room in packet */\n\t\t\t\t\t\toff += len;\n\t\t\t\t\t\tif (off >= tvb_len) {\n\t\t\t\t\t\t\tDebugLog((\"STAG: level = %u, ThrowException: \"\n\t\t\t\t\t\t\t\t  \"len = %u (short frame)\\n\",\n\t\t\t\t\t\t\t\t  *level, off - offset));\n\t\t\t\t\t\t\t/*\n\t\t\t\t\t\t\t * TODO - Do we need to free g_malloc()ed memory?\n\t\t\t\t\t\t\t */\n\t\t\t\t\t\t\tTHROW(ReportedBoundsError);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tproto_tree_add_text (tree, tvb, off-1, 1,\n\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t\t\t\t     \"| END (Known Tag)                 \"\n\t\t\t\t\t\t\t\t     \"| %s/>\",\n\t\t\t\t\t\t\t\t     *level, *codepage_stag, Indent (*level));\n\t\t\t\t\t} else { /* LITERAL tag */\n\t\t\t\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t\t\t\t     \"| LITERAL_A  (Literal Tag)   (A.) \"\n\t\t\t\t\t\t\t\t     \"| %s<%s\",\n\t\t\t\t\t\t\t\t     *level, *codepage_stag, Indent (*level),\n\t\t\t\t\t\t\t\t     tag_new_literal);\n\t\t\t\t\t\toff += 1 + tag_len;\n\t\t\t\t\t\tlen = parse_wbxml_attribute_list (tree, tvb,\n\t\t\t\t\t\t\t\t\t\t  off, str_tbl, *level, codepage_attr);\n\t\t\t\t\t\t/* Check that there is still room in packet */\n\t\t\t\t\t\toff += len;\n\t\t\t\t\t\tif (off >= tvb_len) {\n\t\t\t\t\t\t\tDebugLog((\"STAG: level = %u, ThrowException: \"\n\t\t\t\t\t\t\t\t  \"len = %u (short frame)\\n\",\n\t\t\t\t\t\t\t\t  *level, off - offset));\n\t\t\t\t\t\t\t/*\n\t\t\t\t\t\t\t * TODO - Do we need to free g_malloc()ed memory?\n\t\t\t\t\t\t\t */\n\t\t\t\t\t\t\tTHROW(ReportedBoundsError);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tproto_tree_add_text (tree, tvb, off-1, 1,\n\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t\t\t\t     \"| END (Literal Tag)               \"\n\t\t\t\t\t\t\t\t     \"| %s/>\",\n\t\t\t\t\t\t\t\t     *level, *codepage_stag, Indent (*level));\n\t\t\t\t\t}\n\t\t\t\t} else { /* No Content, No Attribute list */\n\t\t\t\t\tif (tag_new_known) { /* Known tag */\n\t\t\t\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t\t\t\t     \"|   Known Tag 0x%02x           (..) \"\n\t\t\t\t\t\t\t\t     \"| %s<%s />\",\n\t\t\t\t\t\t\t\t     *level, *codepage_stag, tag_new_known,\n\t\t\t\t\t\t\t\t     Indent (*level), tag_new_literal);\n\t\t\t\t\t\t/* Tag string already looked up earlier! */\n\t\t\t\t\t\toff++;\n\t\t\t\t\t} else { /* LITERAL tag */\n\t\t\t\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t\t\t\t     \"| LITERAL    (Literal Tag)   (..) \"\n\t\t\t\t\t\t\t\t     \"| %s<%s />\",\n\t\t\t\t\t\t\t\t     *level, *codepage_stag, Indent (*level),\n\t\t\t\t\t\t\t\t     tag_new_literal);\n\t\t\t\t\t\toff += 1 + tag_len;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t(*level)--;\n\t\t\t\t/* TODO: Do I have to reset code page here? */\n\t\t\t}\n\t\t} /* if (tag & 0x3F) >= 5 */\n\t} /* while */\n\tDebugLog((\"STAG: level = %u, Return: len = %u (end of function body)\\n\",\n\t\t  *level, off - offset));\n\treturn (off - offset);\n}",
        "func": "static guint32\nparse_wbxml_tag (proto_tree *tree, tvbuff_t *tvb, guint32 offset,\n\t\t guint32 str_tbl, guint8 *level,\n\t\t guint8 *codepage_stag, guint8 *codepage_attr)\n{\n\tguint32     tvb_len             = tvb_reported_length (tvb);\n\tguint32     off                 = offset, last_off;\n\tguint32     len;\n\tguint       str_len;\n\tguint32     ent;\n\tguint32     idx;\n\tguint8      peek;\n\tguint32     tag_len;                     /* Length of the idx (uintvar) from a LITERAL tag */\n\tguint8      tag_save_known      = 0;     /* Will contain peek & 0x3F (tag identity) */\n\tguint8      tag_new_known       = 0;     /* Will contain peek & 0x3F (tag identity) */\n\tconst char *tag_save_literal;            /* Will contain the LITERAL tag identity */\n\tconst char *tag_new_literal;             /* Will contain the LITERAL tag identity */\n\tchar       *tag_save_buf        = NULL;  /* Will contain \"tag_0x%02X\" */\n\tchar       *tag_new_buf         = NULL;  /* Will contain \"tag_0x%02X\" */\n\tguint8      parsing_tag_content = FALSE; /* Are we parsing content from a\n\t\t\t\t\t            tag with content: <x>Content</x>\n\n\t\t\t\t\t            The initial state is FALSE.\n\t\t\t\t\t            This state will trigger recursion. */\n\ttag_save_literal = NULL;                 /* Prevents compiler warning */\n\n\tDebugLog((\"parse_wbxml_tag (level = %u, offset = %u)\\n\", *level, offset));\n\tlast_off = off;\n\twhile (off < tvb_len) {\n\t\tpeek = tvb_get_guint8 (tvb, off);\n\t\tDebugLog((\"STAG: (top of while) level = %3u, peek = 0x%02X, off = %u, tvb_len = %u\\n\", *level, peek, off, tvb_len));\n\t\tif ((peek & 0x3F) < 4) switch (peek) { /* Global tokens in state = STAG\n\t\t\t\t\t\t\t  but not the LITERAL tokens */\n\t\tcase 0x00: /* SWITCH_PAGE */\n\t\t\t*codepage_stag = tvb_get_guint8 (tvb, off+1);\n\t\t\tproto_tree_add_text (tree, tvb, off, 2,\n\t\t\t\t\t     \"      | Tag   | T -->%3d \"\n\t\t\t\t\t     \"| SWITCH_PAGE (Tag code page)     \"\n\t\t\t\t\t     \"|\",\n\t\t\t\t\t     *codepage_stag);\n\t\t\toff += 2;\n\t\t\tbreak;\n\t\tcase 0x01: /* END: only possible for Tag with Content */\n\t\t\tif (tag_save_known) { /* Known TAG */\n\t\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t\t     \"| END (Known Tag 0x%02X)            \"\n\t\t\t\t\t\t     \"| %s</%s>\",\n\t\t\t\t\t\t     *level, *codepage_stag, tag_save_known,\n\t\t\t\t\t\t     Indent (*level),\n\t\t\t\t\t\t     tag_save_literal); /* We already looked it up! */\n\t\t\t} else { /* Literal TAG */\n\t\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t\t     \"| END (Literal Tag)               \"\n\t\t\t\t\t\t     \"| %s</%s>\",\n\t\t\t\t\t\t     *level, *codepage_stag, Indent (*level),\n\t\t\t\t\t\t     tag_save_literal ? tag_save_literal : \"\");\n\t\t\t}\n\t\t\t(*level)--;\n\t\t\toff++;\n\t\t\t/* Reset code page: not needed as return from recursion */\n\t\t\tDebugLog((\"STAG: level = %u, Return: len = %u\\n\",\n\t\t\t\t  *level, off - offset));\n\t\t\treturn (off - offset);\n\t\tcase 0x02: /* ENTITY */\n\t\t\tent = tvb_get_guintvar (tvb, off+1, &len);\n\t\t\tproto_tree_add_text (tree, tvb, off, 1+len,\n\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t     \"| ENTITY                          \"\n\t\t\t\t\t     \"| %s'&#%u;'\",\n\t\t\t\t\t     *level, *codepage_stag, Indent (*level), ent);\n\t\t\toff += 1+len;\n\t\t\tbreak;\n\t\tcase 0x03: /* STR_I */\n\t\t\tlen = tvb_strsize (tvb, off+1);\n\t\t\tproto_tree_add_text (tree, tvb, off, 1+len,\n\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t     \"| STR_I (Inline string)           \"\n\t\t\t\t\t     \"| %s\\'%s\\'\",\n\t\t\t\t\t     *level, *codepage_stag, Indent(*level),\n\t\t\t\t\t     tvb_format_text (tvb, off+1, len-1));\n\t\t\toff += 1+len;\n\t\t\tbreak;\n\t\tcase 0x40: /* EXT_I_0 */\n\t\tcase 0x41: /* EXT_I_1 */\n\t\tcase 0x42: /* EXT_I_2 */\n\t\t\t/* Extension tokens */\n\t\t\tlen = tvb_strsize (tvb, off+1);\n\t\t\tproto_tree_add_text (tree, tvb, off, 1+len,\n\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t     \"| EXT_I_%1x    (Extension Token)    \"\n\t\t\t\t\t     \"| %s(Inline string extension: \\'%s\\')\",\n\t\t\t\t\t     *level, *codepage_stag, peek & 0x0f, Indent (*level),\n\t\t\t\t\t     tvb_format_text (tvb, off+1, len-1));\n\t\t\toff += 1+len;\n\t\t\tbreak;\n\t\tcase 0x43: /* PI */\n\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t     \"| PI (XML Processing Instruction) \"\n\t\t\t\t\t     \"| %s<?xml\",\n\t\t\t\t\t     *level, *codepage_stag, Indent (*level));\n\t\t\tlen = parse_wbxml_attribute_list (tree, tvb, off, str_tbl,\n\t\t\t\t\t\t\t  *level, codepage_attr);\n\t\t\t/* Check that there is still room in packet */\n\t\t\toff += len;\n\t\t\tif (off >= tvb_len) {\n\t\t\t\tDebugLog((\"STAG: level = %u, ThrowException: len = %u (short frame)\\n\",\n\t\t\t\t\t  *level, off - offset));\n\t\t\t\t/*\n\t\t\t\t * TODO - Do we need to free g_malloc()ed memory?\n\t\t\t\t */\n\t\t\t\tTHROW(ReportedBoundsError);\n\t\t\t}\n\t\t\tproto_tree_add_text (tree, tvb, off-1, 1,\n\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t     \"| END (PI)                        \"\n\t\t\t\t\t     \"| %s?>\",\n\t\t\t\t\t     *level, *codepage_stag, Indent (*level));\n\t\t\tbreak;\n\t\tcase 0x80: /* EXT_T_0 */\n\t\tcase 0x81: /* EXT_T_1 */\n\t\tcase 0x82: /* EXT_T_2 */\n\t\t\t/* Extension tokens */\n\t\t\tidx = tvb_get_guintvar (tvb, off+1, &len);\n\t\t\tproto_tree_add_text (tree, tvb, off, 1+len,\n\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t     \"| EXT_T_%1x    (Extension Token)    \"\n\t\t\t\t\t     \"| %s(Extension Token, integer value: %u)\",\n\t\t\t\t\t     *level, *codepage_stag, peek & 0x0f, Indent (*level),\n\t\t\t\t\t     idx);\n\t\t\toff += 1+len;\n\t\t\tbreak;\n\t\tcase 0x83: /* STR_T */\n\t\t\tidx = tvb_get_guintvar (tvb, off+1, &len);\n\t\t\tstr_len = tvb_strsize (tvb, str_tbl+idx);\n\t\t\tproto_tree_add_text (tree, tvb, off, 1+len,\n\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t     \"| STR_T (Tableref string)         \"\n\t\t\t\t\t     \"| %s\\'%s\\'\",\n\t\t\t\t\t     *level, *codepage_stag, Indent (*level),\n\t\t\t\t\t     tvb_format_text (tvb, str_tbl+idx, str_len-1));\n\t\t\toff += 1+len;\n\t\t\tbreak;\n\t\tcase 0xC0: /* EXT_0 */\n\t\tcase 0xC1: /* EXT_1 */\n\t\tcase 0xC2: /* EXT_2 */\n\t\t\t/* Extension tokens */\n\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t     \"| EXT_%1x      (Extension Token)    \"\n\t\t\t\t\t     \"| %s(Single-byte extension)\",\n\t\t\t\t\t     *level, *codepage_stag, peek & 0x0f, Indent (*level));\n\t\t\toff++;\n\t\t\tbreak;\n\t\tcase 0xC3: /* OPAQUE - WBXML 1.1 and newer */\n\t\t\tif (tvb_get_guint8 (tvb, 0)) { /* WBXML 1.x (x > 0) */\n\t\t\t\tidx = tvb_get_guintvar (tvb, off+1, &len);\n\t\t\t\tproto_tree_add_text (tree, tvb, off, 1 + len + idx,\n\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t\t     \"| OPAQUE (Opaque data)            \"\n\t\t\t\t\t\t     \"| %s(%d bytes of opaque data)\",\n\t\t\t\t\t\t     *level, *codepage_stag, Indent (*level), idx);\n\t\t\t\toff += 1+len+idx;\n\t\t\t} else { /* WBXML 1.0 - RESERVED_2 token (invalid) */\n\t\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t\t     \"| RESERVED_2     (Invalid Token!) \"\n\t\t\t\t\t\t     \"| WBXML 1.0 parsing stops here.\",\n\t\t\t\t\t\t     *level, *codepage_stag);\n\t\t\t\t/* Stop processing as it is impossible to parse now */\n\t\t\t\toff = tvb_len;\n\t\t\t\tDebugLog((\"STAG: level = %u, Return: len = %u\\n\",\n\t\t\t\t\t  *level, off - offset));\n\t\t\t\treturn (off - offset);\n\t\t\t}\n\t\t\tbreak;\n\n\t\t\t/* No default clause, as all cases have been treated */\n\t\t} else { /* LITERAL or Known TAG */\n\t\t\t/* We must store the initial tag, and also retrieve the new tag.\n\t\t\t * For efficiency reasons, we store the literal tag representation\n\t\t\t * for known tags too, so we can easily close the tag without the\n\t\t\t * need of a new lookup and avoiding storage of token codepage.\n\t\t\t *\n\t\t\t * There are 4 possibilities:\n\t\t\t *\n\t\t\t *  1. Known tag followed by a known tag\n\t\t\t *  2. Known tag followed by a LITERAL tag\n\t\t\t *  3. LITERAL tag followed by Known tag\n\t\t\t *  4. LITERAL tag followed by LITERAL tag\n\t\t\t */\n\n\t\t\t/* Store the new tag */\n\t\t\ttag_len = 0;\n\t\t\tif ((peek & 0x3F) == 4) { /* LITERAL */\n\t\t\t\tDebugLog((\"STAG: LITERAL tag (peek = 0x%02X, off = %u)\"\n\t\t\t\t\t  \" - TableRef follows!\\n\", peek, off));\n\t\t\t\tidx = tvb_get_guintvar (tvb, off+1, &tag_len);\n\t\t\t\tstr_len = tvb_strsize (tvb, str_tbl+idx);\n\t\t\t\ttag_new_literal = (const gchar*)tvb_get_ptr (tvb, str_tbl+idx, str_len);\n\t\t\t\ttag_new_known = 0; /* invalidate known tag_new */\n\t\t\t} else { /* Known tag */\n\t\t\t\ttag_new_known = peek & 0x3F;\n\t\t\t\ttag_new_buf=wmem_strdup_printf(wmem_packet_scope(), \"Tag_0x%02X\",\n\t\t\t\t\t    tag_new_known);\n\t\t\t\ttag_new_literal = tag_new_buf;\n\t\t\t\t/* Stored looked up tag name string */\n\t\t\t}\n\n\t\t\t/* Parsing of TAG starts HERE */\n\t\t\tif (peek & 0x40) { /* Content present */\n\t\t\t\t/* Content follows\n\t\t\t\t * [!] An explicit END token is expected in these cases!\n\t\t\t\t * ==> Recursion possible if we encounter a tag with content;\n\t\t\t\t *     recursion will return at the explicit END token.\n\t\t\t\t */\n\t\t\t\tif (parsing_tag_content) { /* Recurse */\n\t\t\t\t\tDebugLog((\"STAG: Tag in Tag - RECURSE! (off = %u)\\n\", off));\n\t\t\t\t\t/* Do not process the attribute list:\n\t\t\t\t\t * recursion will take care of it */\n\t\t\t\t\t(*level)++;\n\t\t\t\t\tlen = parse_wbxml_tag (tree, tvb, off, str_tbl, level,\n\t\t\t\t\t\t\t       codepage_stag, codepage_attr);\n\t\t\t\t\toff += len;\n\t\t\t\t} else { /* Now we will have content to parse */\n\t\t\t\t\t/* Save the start tag so we can properly close it later. */\n\t\t\t\t\tif ((peek & 0x3F) == 4) { /* Literal tag */\n\t\t\t\t\t\ttag_save_literal = tag_new_literal;\n\t\t\t\t\t\ttag_save_known = 0;\n\t\t\t\t\t} else { /* Known tag */\n\t\t\t\t\t\ttag_save_known = tag_new_known;\n\t\t\t\t\t\ttag_save_buf=wmem_strdup_printf(wmem_packet_scope(), \"Tag_0x%02X\",\n\t\t\t\t\t\t\t    tag_new_known);\n\t\t\t\t\t\ttag_save_literal = tag_save_buf;\n\t\t\t\t\t\t/* The last statement avoids needless lookups */\n\t\t\t\t\t}\n\t\t\t\t\t/* Process the attribute list if present */\n\t\t\t\t\tif (peek & 0x80) { /* Content and Attribute list present */\n\t\t\t\t\t\tif (tag_new_known) { /* Known tag */\n\t\t\t\t\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t\t\t\t\t     \"|   Known Tag 0x%02X           (AC) \"\n\t\t\t\t\t\t\t\t\t     \"| %s<%s\",\n\t\t\t\t\t\t\t\t\t     *level, *codepage_stag, tag_new_known,\n\t\t\t\t\t\t\t\t\t     Indent (*level), tag_new_literal);\n\t\t\t\t\t\t\t/* Tag string already looked up earlier! */\n\t\t\t\t\t\t\toff++;\n\t\t\t\t\t\t} else { /* LITERAL tag */\n\t\t\t\t\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t\t\t\t\t     \"| LITERAL_AC (Literal tag)   (AC) \"\n\t\t\t\t\t\t\t\t\t     \"| %s<%s\",\n\t\t\t\t\t\t\t\t\t     *level, *codepage_stag, Indent (*level),\n\t\t\t\t\t\t\t\t\t     tag_new_literal);\n\t\t\t\t\t\t\toff += 1 + tag_len;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tlen = parse_wbxml_attribute_list (tree, tvb,\n\t\t\t\t\t\t\t\t\t\t  off, str_tbl, *level, codepage_attr);\n\t\t\t\t\t\t/* Check that there is still room in packet */\n\t\t\t\t\t\toff += len;\n\t\t\t\t\t\tif (off >= tvb_len) {\n\t\t\t\t\t\t\tDebugLog((\"STAG: level = %u, ThrowException: \"\n\t\t\t\t\t\t\t\t  \"len = %u (short frame)\\n\",\n\t\t\t\t\t\t\t\t  *level, off - offset));\n\t\t\t\t\t\t\t/*\n\t\t\t\t\t\t\t * TODO - Do we need to free g_malloc()ed memory?\n\t\t\t\t\t\t\t */\n\t\t\t\t\t\t\tTHROW(ReportedBoundsError);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tproto_tree_add_text (tree, tvb, off-1, 1,\n\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t\t\t\t     \"| END (attribute list)            \"\n\t\t\t\t\t\t\t\t     \"| %s>\",\n\t\t\t\t\t\t\t\t     *level, *codepage_stag, Indent (*level));\n\t\t\t\t\t} else { /* Content, no Attribute list */\n\t\t\t\t\t\tif (tag_new_known) { /* Known tag */\n\t\t\t\t\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t\t\t\t\t     \"|   Known Tag 0x%02X           (.C) \"\n\t\t\t\t\t\t\t\t\t     \"| %s<%s>\",\n\t\t\t\t\t\t\t\t\t     *level, *codepage_stag, tag_new_known,\n\t\t\t\t\t\t\t\t\t     Indent (*level), tag_new_literal);\n\t\t\t\t\t\t\t/* Tag string already looked up earlier! */\n\t\t\t\t\t\t\toff++;\n\t\t\t\t\t\t} else { /* LITERAL tag */\n\t\t\t\t\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t\t\t\t\t     \"| LITERAL_C  (Literal Tag)   (.C) \"\n\t\t\t\t\t\t\t\t\t     \"| %s<%s>\",\n\t\t\t\t\t\t\t\t\t     *level, *codepage_stag, Indent (*level),\n\t\t\t\t\t\t\t\t\t     tag_new_literal);\n\t\t\t\t\t\t\toff += 1 + tag_len;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\t/* The data that follows in the parsing process\n\t\t\t\t\t * represents content for the opening tag\n\t\t\t\t\t * we've just processed in the lines above.\n\t\t\t\t\t * Next time we encounter a tag with content: recurse\n\t\t\t\t\t */\n\t\t\t\t\tparsing_tag_content = TRUE;\n\t\t\t\t\tDebugLog((\"Tag in Tag - No recursion this time! \"\n\t\t\t\t\t\t  \"(off = %u)\\n\", off));\n\t\t\t\t}\n\t\t\t} else { /* No Content */\n\t\t\t\tDebugLog((\"<Tag/> in Tag - No recursion! (off = %u)\\n\", off));\n\t\t\t\t(*level)++;\n\t\t\t\tif (peek & 0x80) { /* No Content, Attribute list present */\n\t\t\t\t\tif (tag_new_known) { /* Known tag */\n\t\t\t\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t\t\t\t     \"|   Known Tag 0x%02X           (A.) \"\n\t\t\t\t\t\t\t\t     \"| %s<%s\",\n\t\t\t\t\t\t\t\t     *level, *codepage_stag, tag_new_known,\n\t\t\t\t\t\t\t\t     Indent (*level), tag_new_literal);\n\t\t\t\t\t\t/* Tag string already looked up earlier! */\n\t\t\t\t\t\toff++;\n\t\t\t\t\t\tlen = parse_wbxml_attribute_list (tree, tvb,\n\t\t\t\t\t\t\t\t\t\t  off, str_tbl, *level, codepage_attr);\n\t\t\t\t\t\t/* Check that there is still room in packet */\n\t\t\t\t\t\toff += len;\n\t\t\t\t\t\tif (off >= tvb_len) {\n\t\t\t\t\t\t\tDebugLog((\"STAG: level = %u, ThrowException: \"\n\t\t\t\t\t\t\t\t  \"len = %u (short frame)\\n\",\n\t\t\t\t\t\t\t\t  *level, off - offset));\n\t\t\t\t\t\t\t/*\n\t\t\t\t\t\t\t * TODO - Do we need to free g_malloc()ed memory?\n\t\t\t\t\t\t\t */\n\t\t\t\t\t\t\tTHROW(ReportedBoundsError);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tproto_tree_add_text (tree, tvb, off-1, 1,\n\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t\t\t\t     \"| END (Known Tag)                 \"\n\t\t\t\t\t\t\t\t     \"| %s/>\",\n\t\t\t\t\t\t\t\t     *level, *codepage_stag, Indent (*level));\n\t\t\t\t\t} else { /* LITERAL tag */\n\t\t\t\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t\t\t\t     \"| LITERAL_A  (Literal Tag)   (A.) \"\n\t\t\t\t\t\t\t\t     \"| %s<%s\",\n\t\t\t\t\t\t\t\t     *level, *codepage_stag, Indent (*level),\n\t\t\t\t\t\t\t\t     tag_new_literal);\n\t\t\t\t\t\toff += 1 + tag_len;\n\t\t\t\t\t\tlen = parse_wbxml_attribute_list (tree, tvb,\n\t\t\t\t\t\t\t\t\t\t  off, str_tbl, *level, codepage_attr);\n\t\t\t\t\t\t/* Check that there is still room in packet */\n\t\t\t\t\t\toff += len;\n\t\t\t\t\t\tif (off >= tvb_len) {\n\t\t\t\t\t\t\tDebugLog((\"STAG: level = %u, ThrowException: \"\n\t\t\t\t\t\t\t\t  \"len = %u (short frame)\\n\",\n\t\t\t\t\t\t\t\t  *level, off - offset));\n\t\t\t\t\t\t\t/*\n\t\t\t\t\t\t\t * TODO - Do we need to free g_malloc()ed memory?\n\t\t\t\t\t\t\t */\n\t\t\t\t\t\t\tTHROW(ReportedBoundsError);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tproto_tree_add_text (tree, tvb, off-1, 1,\n\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t\t\t\t     \"| END (Literal Tag)               \"\n\t\t\t\t\t\t\t\t     \"| %s/>\",\n\t\t\t\t\t\t\t\t     *level, *codepage_stag, Indent (*level));\n\t\t\t\t\t}\n\t\t\t\t} else { /* No Content, No Attribute list */\n\t\t\t\t\tif (tag_new_known) { /* Known tag */\n\t\t\t\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t\t\t\t     \"|   Known Tag 0x%02x           (..) \"\n\t\t\t\t\t\t\t\t     \"| %s<%s />\",\n\t\t\t\t\t\t\t\t     *level, *codepage_stag, tag_new_known,\n\t\t\t\t\t\t\t\t     Indent (*level), tag_new_literal);\n\t\t\t\t\t\t/* Tag string already looked up earlier! */\n\t\t\t\t\t\toff++;\n\t\t\t\t\t} else { /* LITERAL tag */\n\t\t\t\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t\t\t\t     \"| LITERAL    (Literal Tag)   (..) \"\n\t\t\t\t\t\t\t\t     \"| %s<%s />\",\n\t\t\t\t\t\t\t\t     *level, *codepage_stag, Indent (*level),\n\t\t\t\t\t\t\t\t     tag_new_literal);\n\t\t\t\t\t\toff += 1 + tag_len;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t(*level)--;\n\t\t\t\t/* TODO: Do I have to reset code page here? */\n\t\t\t}\n\t\t} /* if (tag & 0x3F) >= 5 */\n\t\tif (off < last_off) {\n\t\t\tTHROW(ReportedBoundsError);\n\t\t}\n\t\tlast_off = off;\n\t} /* while */\n\tDebugLog((\"STAG: level = %u, Return: len = %u (end of function body)\\n\",\n\t\t  *level, off - offset));\n\treturn (off - offset);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,7 +4,7 @@\n \t\t guint8 *codepage_stag, guint8 *codepage_attr)\n {\n \tguint32     tvb_len             = tvb_reported_length (tvb);\n-\tguint32     off                 = offset;\n+\tguint32     off                 = offset, last_off;\n \tguint32     len;\n \tguint       str_len;\n \tguint32     ent;\n@@ -25,6 +25,7 @@\n \ttag_save_literal = NULL;                 /* Prevents compiler warning */\n \n \tDebugLog((\"parse_wbxml_tag (level = %u, offset = %u)\\n\", *level, offset));\n+\tlast_off = off;\n \twhile (off < tvb_len) {\n \t\tpeek = tvb_get_guint8 (tvb, off);\n \t\tDebugLog((\"STAG: (top of while) level = %3u, peek = 0x%02X, off = %u, tvb_len = %u\\n\", *level, peek, off, tvb_len));\n@@ -384,6 +385,10 @@\n \t\t\t\t/* TODO: Do I have to reset code page here? */\n \t\t\t}\n \t\t} /* if (tag & 0x3F) >= 5 */\n+\t\tif (off < last_off) {\n+\t\t\tTHROW(ReportedBoundsError);\n+\t\t}\n+\t\tlast_off = off;\n \t} /* while */\n \tDebugLog((\"STAG: level = %u, Return: len = %u (end of function body)\\n\",\n \t\t  *level, off - offset));",
        "diff_line_info": {
            "deleted_lines": [
                "\tguint32     off                 = offset;"
            ],
            "added_lines": [
                "\tguint32     off                 = offset, last_off;",
                "\tlast_off = off;",
                "\t\tif (off < last_off) {",
                "\t\t\tTHROW(ReportedBoundsError);",
                "\t\t}",
                "\t\tlast_off = off;"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-5359",
        "func_name": "wireshark/parse_wbxml_tag_defined",
        "description": "epan/dissectors/packet-wbxml.c in the WBXML dissector in Wireshark 1.12.x before 1.12.12 mishandles offsets, which allows remote attackers to cause a denial of service (integer overflow and infinite loop) via a crafted packet.",
        "git_url": "https://github.com/wireshark/wireshark/commit/b8e0d416898bb975a02c1b55883342edc5b4c9c0",
        "commit_title": "WBXML: add a basic sanity check for offset overflow",
        "commit_text": " This is a naive approach allowing to detact that something went wrong, without the need to replace all proto_tree_add_text() calls as what was done in master-2.0 branch.  Bug: 12408",
        "func_before": "static guint32\nparse_wbxml_tag_defined (proto_tree *tree, tvbuff_t *tvb, guint32 offset,\n\t\t\t guint32 str_tbl, guint8 *level, guint8 *codepage_stag, guint8 *codepage_attr,\n\t\t\t const wbxml_decoding *map)\n{\n\tguint32     tvb_len  = tvb_reported_length (tvb);\n\tguint32     off      = offset;\n\tguint32     len;\n\tguint       str_len;\n\tguint32     ent;\n\tguint32     idx;\n\tguint8      peek;\n\tguint32     tag_len;                     /* Length of the index (uintvar) from a LITERAL tag */\n\tguint8      tag_save_known      = 0;     /* Will contain peek & 0x3F (tag identity) */\n\tguint8      tag_new_known       = 0;     /* Will contain peek & 0x3F (tag identity) */\n\tconst char *tag_save_literal;            /* Will contain the LITERAL tag identity */\n\tconst char *tag_new_literal;             /* Will contain the LITERAL tag identity */\n\tguint8      parsing_tag_content = FALSE; /* Are we parsing content from a\n\t\t\t\t\t            tag with content: <x>Content</x>\n\n\t\t\t\t\t            The initial state is FALSE.\n\t\t\t\t\t            This state will trigger recursion. */\n\ttag_save_literal = NULL;                 /* Prevents compiler warning */\n\n\tDebugLog((\"parse_wbxml_tag_defined (level = %u, offset = %u)\\n\", *level, offset));\n\twhile (off < tvb_len) {\n\t\tpeek = tvb_get_guint8 (tvb, off);\n\t\tDebugLog((\"STAG: (top of while) level = %3u, peek = 0x%02X, off = %u, tvb_len = %u\\n\", *level, peek, off, tvb_len));\n\t\tif ((peek & 0x3F) < 4) switch (peek) { /* Global tokens in state = STAG\n\t\t\t\t\t\t\t  but not the LITERAL tokens */\n\t\tcase 0x00: /* SWITCH_PAGE */\n\t\t\t*codepage_stag = tvb_get_guint8 (tvb, off+1);\n\t\t\tproto_tree_add_text (tree, tvb, off, 2,\n\t\t\t\t\t     \"      | Tag   | T -->%3d \"\n\t\t\t\t\t     \"| SWITCH_PAGE (Tag code page)     \"\n\t\t\t\t\t     \"|\",\n\t\t\t\t\t     *codepage_stag);\n\t\t\toff += 2;\n\t\t\tbreak;\n\t\tcase 0x01: /* END: only possible for Tag with Content */\n\t\t\tif (tag_save_known) { /* Known TAG */\n\t\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t\t     \"| END (Known Tag 0x%02X)            \"\n\t\t\t\t\t\t     \"| %s</%s>\",\n\t\t\t\t\t\t     *level, *codepage_stag,\n\t\t\t\t\t\t     tag_save_known, Indent (*level),\n\t\t\t\t\t\t     tag_save_literal); /* We already looked it up! */\n\t\t\t} else { /* Literal TAG */\n\t\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t\t     \"| END (Literal Tag)               \"\n\t\t\t\t\t\t     \"| %s</%s>\",\n\t\t\t\t\t\t     *level, *codepage_stag, Indent (*level),\n\t\t\t\t\t\t     tag_save_literal ? tag_save_literal : \"\");\n\t\t\t}\n\t\t\t(*level)--;\n\t\t\toff++;\n\t\t\t/* Reset code page: not needed as return from recursion */\n\t\t\tDebugLog((\"STAG: level = %u, Return: len = %u\\n\", *level, off - offset));\n\t\t\treturn (off - offset);\n\t\tcase 0x02: /* ENTITY */\n\t\t\tent = tvb_get_guintvar (tvb, off+1, &len);\n\t\t\tproto_tree_add_text (tree, tvb, off, 1+len,\n\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t     \"| ENTITY                          \"\n\t\t\t\t\t     \"| %s'&#%u;'\",\n\t\t\t\t\t     *level, *codepage_stag, Indent (*level), ent);\n\t\t\toff += 1+len;\n\t\t\tbreak;\n\t\tcase 0x03: /* STR_I */\n\t\t\tlen = tvb_strsize (tvb, off+1);\n\t\t\tproto_tree_add_text (tree, tvb, off, 1+len,\n\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t     \"| STR_I (Inline string)           \"\n\t\t\t\t\t     \"| %s\\'%s\\'\",\n\t\t\t\t\t     *level, *codepage_stag, Indent(*level),\n\t\t\t\t\t     tvb_format_text (tvb, off+1, len-1));\n\t\t\toff += 1+len;\n\t\t\tbreak;\n\t\tcase 0x40: /* EXT_I_0 */\n\t\tcase 0x41: /* EXT_I_1 */\n\t\tcase 0x42: /* EXT_I_2 */\n\t\t\t/* Extension tokens */\n\t\t\tlen = tvb_strsize (tvb, off+1);\n\t\t\tproto_tree_add_text (tree, tvb, off, 1+len,\n\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t     \"| EXT_I_%1x    (Extension Token)    \"\n\t\t\t\t\t     \"| %s(%s: \\'%s\\')\",\n\t\t\t\t\t     *level, *codepage_stag,\n\t\t\t\t\t     peek & 0x0f, Indent (*level),\n\t\t\t\t\t     map_token (map->global, 0, peek),\n\t\t\t\t\t     tvb_format_text (tvb, off+1, len-1));\n\t\t\toff += 1+len;\n\t\t\tbreak;\n\t\tcase 0x43: /* PI */\n\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t     \"| PI (XML Processing Instruction) \"\n\t\t\t\t\t     \"| %s<?xml\",\n\t\t\t\t\t     *level, *codepage_stag, Indent (*level));\n\t\t\tlen = parse_wbxml_attribute_list_defined (tree, tvb, off,\n\t\t\t\t\t\t\t\t  str_tbl, *level, codepage_attr, map);\n\t\t\t/* Check that there is still room in packet */\n\t\t\toff += len;\n\t\t\tif (off >= tvb_len) {\n\t\t\t\tDebugLog((\"STAG: level = %u, ThrowException: len = %u (short frame)\\n\", *level, off - offset));\n\t\t\t\t/*\n\t\t\t\t * TODO - Do we need to free g_malloc()ed memory?\n\t\t\t\t */\n\t\t\t\tTHROW(ReportedBoundsError);\n\t\t\t}\n\t\t\tproto_tree_add_text (tree, tvb, off-1, 1,\n\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t     \"| END (PI)                        \"\n\t\t\t\t\t     \"| %s?>\",\n\t\t\t\t\t     *level, *codepage_stag, Indent (*level));\n\t\t\tbreak;\n\t\tcase 0x80: /* EXT_T_0 */\n\t\tcase 0x81: /* EXT_T_1 */\n\t\tcase 0x82: /* EXT_T_2 */\n\t\t\t/* Extension tokens */\n\t\t\tidx = tvb_get_guintvar (tvb, off+1, &len);\n\t\t\t{   char *s;\n\t\t\t\tif (map->ext_t[peek & 0x03])\n\t\t\t\t\ts = (map->ext_t[peek & 0x03])(tvb, idx, str_tbl);\n\t\t\t\telse\n\t\t\t\t\ts = wmem_strdup_printf(wmem_packet_scope(), \"EXT_T_%1x (%s)\", peek & 0x03,\n\t\t\t\t\t\t\t    map_token (map->global, 0, peek));\n\t\t\t\tproto_tree_add_text (tree, tvb, off, 1+len,\n\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t\t     \"| EXT_T_%1x    (Extension Token)    \"\n\t\t\t\t\t\t     \"| %s%s\",\n\t\t\t\t\t\t     *level, *codepage_stag, peek & 0x0f, Indent (*level),\n\t\t\t\t\t\t     s);\n\t\t\t}\n\t\t\toff += 1+len;\n\t\t\tbreak;\n\t\tcase 0x83: /* STR_T */\n\t\t\tidx = tvb_get_guintvar (tvb, off+1, &len);\n\t\t\tstr_len = tvb_strsize (tvb, str_tbl+idx);\n\t\t\tproto_tree_add_text (tree, tvb, off, 1+len,\n\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t     \"| STR_T (Tableref string)         \"\n\t\t\t\t\t     \"| %s\\'%s\\'\",\n\t\t\t\t\t     *level, *codepage_stag, Indent (*level),\n\t\t\t\t\t     tvb_format_text (tvb, str_tbl+idx, str_len-1));\n\t\t\toff += 1+len;\n\t\t\tbreak;\n\t\tcase 0xC0: /* EXT_0 */\n\t\tcase 0xC1: /* EXT_1 */\n\t\tcase 0xC2: /* EXT_2 */\n\t\t\t/* Extension tokens */\n\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t     \"| EXT_%1x      (Extension Token)    \"\n\t\t\t\t\t     \"| %s(%s)\",\n\t\t\t\t\t     *level, *codepage_stag, peek & 0x0f, Indent (*level),\n\t\t\t\t\t     map_token (map->global, 0, peek));\n\t\t\toff++;\n\t\t\tbreak;\n\t\tcase 0xC3: /* OPAQUE - WBXML 1.1 and newer */\n\t\t\tif (tvb_get_guint8 (tvb, 0)) { /* WBXML 1.x (x > 0) */\n\t\t\t\tchar *str;\n\t\t\t\tif (tag_save_known) { /* Knwon tag */\n\t\t\t\t\tif (map->opaque_binary_tag) {\n\t\t\t\t\t\tstr = map->opaque_binary_tag(tvb, off + 1,\n\t\t\t\t\t\t\t\t\t     tag_save_known, *codepage_stag, &len);\n\t\t\t\t\t} else {\n\t\t\t\t\t\tstr = default_opaque_binary_tag(tvb, off + 1,\n\t\t\t\t\t\t\t\t\t\ttag_save_known, *codepage_stag, &len);\n\t\t\t\t\t}\n\t\t\t\t} else { /* lITERAL tag */\n\t\t\t\t\tif (map->opaque_literal_tag) {\n\t\t\t\t\t\tstr = map->opaque_literal_tag(tvb, off + 1,\n\t\t\t\t\t\t\t\t\t      tag_save_literal, *codepage_stag, &len);\n\t\t\t\t\t} else {\n\t\t\t\t\t\tstr = default_opaque_literal_tag(tvb, off + 1,\n\t\t\t\t\t\t\t\t\t\t tag_save_literal, *codepage_stag, &len);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tproto_tree_add_text (tree, tvb, off, 1 + len,\n\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t\t     \"| OPAQUE (Opaque data)            \"\n\t\t\t\t\t\t     \"| %s%s\",\n\t\t\t\t\t\t     *level, *codepage_stag, Indent (*level), str);\n\t\t\t\toff += 1 + len;\n\t\t\t} else { /* WBXML 1.0 - RESERVED_2 token (invalid) */\n\t\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t\t     \"| RESERVED_2     (Invalid Token!) \"\n\t\t\t\t\t\t     \"| WBXML 1.0 parsing stops here.\",\n\t\t\t\t\t\t     *level, *codepage_stag);\n\t\t\t\t/* Stop processing as it is impossible to parse now */\n\t\t\t\toff = tvb_len;\n\t\t\t\tDebugLog((\"STAG: level = %u, Return: len = %u\\n\", *level, off - offset));\n\t\t\t\treturn (off - offset);\n\t\t\t}\n\t\t\tbreak;\n\n\t\t\t/* No default clause, as all cases have been treated */\n\t\t} else { /* LITERAL or Known TAG */\n\t\t\t/* We must store the initial tag, and also retrieve the new tag.\n\t\t\t * For efficiency reasons, we store the literal tag representation\n\t\t\t * for known tags too, so we can easily close the tag without the\n\t\t\t * need of a new lookup and avoiding storage of token codepage.\n\t\t\t *\n\t\t\t * There are 4 possibilities:\n\t\t\t *\n\t\t\t *  1. Known tag followed by a known tag\n\t\t\t *  2. Known tag followed by a LITERAL tag\n\t\t\t *  3. LITERAL tag followed by Known tag\n\t\t\t *  4. LITERAL tag followed by LITERAL tag\n\t\t\t */\n\n\t\t\t/* Store the new tag */\n\t\t\ttag_len = 0;\n\t\t\tif ((peek & 0x3F) == 4) { /* LITERAL */\n\t\t\t\tDebugLog((\"STAG: LITERAL tag (peek = 0x%02X, off = %u) - TableRef follows!\\n\", peek, off));\n\t\t\t\tidx = tvb_get_guintvar (tvb, off+1, &tag_len);\n\t\t\t\tstr_len = tvb_strsize (tvb, str_tbl+idx);\n\t\t\t\ttag_new_literal = (const gchar*)tvb_get_ptr (tvb, str_tbl+idx, str_len);\n\t\t\t\ttag_new_known = 0; /* invalidate known tag_new */\n\t\t\t} else { /* Known tag */\n\t\t\t\ttag_new_known = peek & 0x3F;\n\t\t\t\ttag_new_literal = map_token (map->tags, *codepage_stag,\n\t\t\t\t\t\t\t     tag_new_known);\n\t\t\t\t/* Stored looked up tag name string */\n\t\t\t}\n\n\t\t\t/* Parsing of TAG starts HERE */\n\t\t\tif (peek & 0x40) { /* Content present */\n\t\t\t\t/* Content follows\n\t\t\t\t * [!] An explicit END token is expected in these cases!\n\t\t\t\t * ==> Recursion possible if we encounter a tag with content;\n\t\t\t\t *     recursion will return at the explicit END token.\n\t\t\t\t */\n\t\t\t\tif (parsing_tag_content) { /* Recurse */\n\t\t\t\t\tDebugLog((\"STAG: Tag in Tag - RECURSE! (off = %u)\\n\", off));\n\t\t\t\t\t/* Do not process the attribute list:\n\t\t\t\t\t * recursion will take care of it */\n\t\t\t\t\t(*level)++;\n\t\t\t\t\tlen = parse_wbxml_tag_defined (tree, tvb, off, str_tbl,\n\t\t\t\t\t\t\t\t       level, codepage_stag, codepage_attr, map);\n\t\t\t\t\toff += len;\n\t\t\t\t} else { /* Now we will have content to parse */\n\t\t\t\t\t/* Save the start tag so we can properly close it later. */\n\t\t\t\t\tif ((peek & 0x3F) == 4) { /* Literal tag */\n\t\t\t\t\t\ttag_save_literal = tag_new_literal;\n\t\t\t\t\t\ttag_save_known = 0;\n\t\t\t\t\t} else { /* Known tag */\n\t\t\t\t\t\ttag_save_known = tag_new_known;\n\t\t\t\t\t\ttag_save_literal = tag_new_literal;\n\t\t\t\t\t\t/* The last statement avoids needless lookups */\n\t\t\t\t\t}\n\t\t\t\t\t/* Process the attribute list if present */\n\t\t\t\t\tif (peek & 0x80) { /* Content and Attribute list present */\n\t\t\t\t\t\tif (tag_new_known) { /* Known tag */\n\t\t\t\t\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t\t\t\t\t     \"|   Known Tag 0x%02X           (AC) \"\n\t\t\t\t\t\t\t\t\t     \"| %s<%s\",\n\t\t\t\t\t\t\t\t\t     *level, *codepage_stag, tag_new_known,\n\t\t\t\t\t\t\t\t\t     Indent (*level), tag_new_literal);\n\t\t\t\t\t\t\t/* Tag string already looked up earlier! */\n\t\t\t\t\t\t\toff++;\n\t\t\t\t\t\t} else { /* LITERAL tag */\n\t\t\t\t\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t\t\t\t\t     \"| LITERAL_AC (Literal tag)   (AC) \"\n\t\t\t\t\t\t\t\t\t     \"| %s<%s\",\n\t\t\t\t\t\t\t\t\t     *level, *codepage_stag, Indent (*level), tag_new_literal);\n\t\t\t\t\t\t\toff += 1 + tag_len;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tlen = parse_wbxml_attribute_list_defined (tree, tvb,\n\t\t\t\t\t\t\t\t\t\t\t  off, str_tbl, *level, codepage_attr, map);\n\t\t\t\t\t\t/* Check that there is still room in packet */\n\t\t\t\t\t\toff += len;\n\t\t\t\t\t\tif (off >= tvb_len) {\n\t\t\t\t\t\t\tDebugLog((\"STAG: level = %u, ThrowException: len = %u (short frame)\\n\",\n\t\t\t\t\t\t\t\t  *level, off - offset));\n\t\t\t\t\t\t\t/*\n\t\t\t\t\t\t\t * TODO - Do we need to free g_malloc()ed memory?\n\t\t\t\t\t\t\t */\n\t\t\t\t\t\t\tTHROW(ReportedBoundsError);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tproto_tree_add_text (tree, tvb, off-1, 1,\n\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t\t\t\t     \"| END (attribute list)            \"\n\t\t\t\t\t\t\t\t     \"| %s>\",\n\t\t\t\t\t\t\t\t     *level, *codepage_stag, Indent (*level));\n\t\t\t\t\t} else { /* Content, no Attribute list */\n\t\t\t\t\t\tif (tag_new_known) { /* Known tag */\n\t\t\t\t\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t\t\t\t\t     \"|   Known Tag 0x%02X           (.C) \"\n\t\t\t\t\t\t\t\t\t     \"| %s<%s>\",\n\t\t\t\t\t\t\t\t\t     *level, *codepage_stag, tag_new_known,\n\t\t\t\t\t\t\t\t\t     Indent (*level), tag_new_literal);\n\t\t\t\t\t\t\t/* Tag string already looked up earlier! */\n\t\t\t\t\t\t\toff++;\n\t\t\t\t\t\t} else { /* LITERAL tag */\n\t\t\t\t\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t\t\t\t\t     \"| LITERAL_C  (Literal Tag)   (.C) \"\n\t\t\t\t\t\t\t\t\t     \"| %s<%s>\",\n\t\t\t\t\t\t\t\t\t     *level, *codepage_stag, Indent (*level),\n\t\t\t\t\t\t\t\t\t     tag_new_literal);\n\t\t\t\t\t\t\toff += 1 + tag_len;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\t/* The data that follows in the parsing process\n\t\t\t\t\t * represents content for the opening tag\n\t\t\t\t\t * we've just processed in the lines above.\n\t\t\t\t\t * Next time we encounter a tag with content: recurse\n\t\t\t\t\t */\n\t\t\t\t\tparsing_tag_content = TRUE;\n\t\t\t\t\tDebugLog((\"Tag in Tag - No recursion this time! (off = %u)\\n\", off));\n\t\t\t\t}\n\t\t\t} else { /* No Content */\n\t\t\t\tDebugLog((\"<Tag/> in Tag - No recursion! (off = %u)\\n\", off));\n\t\t\t\t(*level)++;\n\t\t\t\tif (peek & 0x80) { /* No Content, Attribute list present */\n\t\t\t\t\tif (tag_new_known) { /* Known tag */\n\t\t\t\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t\t\t\t     \"|   Known Tag 0x%02X           (A.) \"\n\t\t\t\t\t\t\t\t     \"| %s<%s\",\n\t\t\t\t\t\t\t\t     *level, *codepage_stag, tag_new_known,\n\t\t\t\t\t\t\t\t     Indent (*level), tag_new_literal);\n\t\t\t\t\t\t/* Tag string already looked up earlier! */\n\t\t\t\t\t\toff++;\n\t\t\t\t\t\tlen = parse_wbxml_attribute_list_defined (tree, tvb,\n\t\t\t\t\t\t\t\t\t\t\t  off, str_tbl, *level, codepage_attr, map);\n\t\t\t\t\t\t/* Check that there is still room in packet */\n\t\t\t\t\t\toff += len;\n\t\t\t\t\t\tif (off > tvb_len) {\n\t\t\t\t\t\t\tDebugLog((\"STAG: level = %u, ThrowException: len = %u (short frame)\\n\", *level, off - offset));\n\t\t\t\t\t\t\t/*\n\t\t\t\t\t\t\t * TODO - Do we need to free g_malloc()ed memory?\n\t\t\t\t\t\t\t */\n\t\t\t\t\t\t\tTHROW(ReportedBoundsError);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tproto_tree_add_text (tree, tvb, off-1, 1,\n\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t\t\t\t     \"| END (Known Tag)                 \"\n\t\t\t\t\t\t\t\t     \"| %s/>\",\n\t\t\t\t\t\t\t\t     *level, *codepage_stag, Indent (*level));\n\t\t\t\t\t} else { /* LITERAL tag */\n\t\t\t\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t\t\t\t     \"| LITERAL_A  (Literal Tag)   (A.) \"\n\t\t\t\t\t\t\t\t     \"| %s<%s\",\n\t\t\t\t\t\t\t\t     *level, *codepage_stag, Indent (*level), tag_new_literal);\n\t\t\t\t\t\toff += 1 + tag_len;\n\t\t\t\t\t\tlen = parse_wbxml_attribute_list_defined (tree, tvb,\n\t\t\t\t\t\t\t\t\t\t\t  off, str_tbl, *level, codepage_attr, map);\n\t\t\t\t\t\t/* Check that there is still room in packet */\n\t\t\t\t\t\toff += len;\n\t\t\t\t\t\tif (off >= tvb_len) {\n\t\t\t\t\t\t\tDebugLog((\"STAG: level = %u, ThrowException: len = %u (short frame)\\n\", *level, off - offset));\n\t\t\t\t\t\t\t/*\n\t\t\t\t\t\t\t * TODO - Do we need to free g_malloc()ed memory?\n\t\t\t\t\t\t\t */\n\t\t\t\t\t\t\tTHROW(ReportedBoundsError);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tproto_tree_add_text (tree, tvb, off-1, 1,\n\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t\t\t\t     \"| END (Literal Tag)               \"\n\t\t\t\t\t\t\t\t     \"| %s/>\",\n\t\t\t\t\t\t\t\t     *level, *codepage_stag, Indent (*level));\n\t\t\t\t\t}\n\t\t\t\t} else { /* No Content, No Attribute list */\n\t\t\t\t\tif (tag_new_known) { /* Known tag */\n\t\t\t\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t\t\t\t     \"|   Known Tag 0x%02x           (..) \"\n\t\t\t\t\t\t\t\t     \"| %s<%s />\",\n\t\t\t\t\t\t\t\t     *level, *codepage_stag, tag_new_known,\n\t\t\t\t\t\t\t\t     Indent (*level), tag_new_literal);\n\t\t\t\t\t\t/* Tag string already looked up earlier! */\n\t\t\t\t\t\toff++;\n\t\t\t\t\t} else { /* LITERAL tag */\n\t\t\t\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t\t\t\t     \"| LITERAL    (Literal Tag)   (..) \"\n\t\t\t\t\t\t\t\t     \"| %s<%s />\",\n\t\t\t\t\t\t\t\t     *level, *codepage_stag, Indent (*level),\n\t\t\t\t\t\t\t\t     tag_new_literal);\n\t\t\t\t\t\toff += 1 + tag_len;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t(*level)--;\n\t\t\t\t/* TODO: Do I have to reset code page here? */\n\t\t\t}\n\t\t} /* if (tag & 0x3F) >= 5 */\n\t} /* while */\n\tDebugLog((\"STAG: level = %u, Return: len = %u (end of function body)\\n\", *level, off - offset));\n\treturn (off - offset);\n}",
        "func": "static guint32\nparse_wbxml_tag_defined (proto_tree *tree, tvbuff_t *tvb, guint32 offset,\n\t\t\t guint32 str_tbl, guint8 *level, guint8 *codepage_stag, guint8 *codepage_attr,\n\t\t\t const wbxml_decoding *map)\n{\n\tguint32     tvb_len  = tvb_reported_length (tvb);\n\tguint32     off      = offset, last_off;\n\tguint32     len;\n\tguint       str_len;\n\tguint32     ent;\n\tguint32     idx;\n\tguint8      peek;\n\tguint32     tag_len;                     /* Length of the index (uintvar) from a LITERAL tag */\n\tguint8      tag_save_known      = 0;     /* Will contain peek & 0x3F (tag identity) */\n\tguint8      tag_new_known       = 0;     /* Will contain peek & 0x3F (tag identity) */\n\tconst char *tag_save_literal;            /* Will contain the LITERAL tag identity */\n\tconst char *tag_new_literal;             /* Will contain the LITERAL tag identity */\n\tguint8      parsing_tag_content = FALSE; /* Are we parsing content from a\n\t\t\t\t\t            tag with content: <x>Content</x>\n\n\t\t\t\t\t            The initial state is FALSE.\n\t\t\t\t\t            This state will trigger recursion. */\n\ttag_save_literal = NULL;                 /* Prevents compiler warning */\n\n\tDebugLog((\"parse_wbxml_tag_defined (level = %u, offset = %u)\\n\", *level, offset));\n\tlast_off = off;\n\twhile (off < tvb_len) {\n\t\tpeek = tvb_get_guint8 (tvb, off);\n\t\tDebugLog((\"STAG: (top of while) level = %3u, peek = 0x%02X, off = %u, tvb_len = %u\\n\", *level, peek, off, tvb_len));\n\t\tif ((peek & 0x3F) < 4) switch (peek) { /* Global tokens in state = STAG\n\t\t\t\t\t\t\t  but not the LITERAL tokens */\n\t\tcase 0x00: /* SWITCH_PAGE */\n\t\t\t*codepage_stag = tvb_get_guint8 (tvb, off+1);\n\t\t\tproto_tree_add_text (tree, tvb, off, 2,\n\t\t\t\t\t     \"      | Tag   | T -->%3d \"\n\t\t\t\t\t     \"| SWITCH_PAGE (Tag code page)     \"\n\t\t\t\t\t     \"|\",\n\t\t\t\t\t     *codepage_stag);\n\t\t\toff += 2;\n\t\t\tbreak;\n\t\tcase 0x01: /* END: only possible for Tag with Content */\n\t\t\tif (tag_save_known) { /* Known TAG */\n\t\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t\t     \"| END (Known Tag 0x%02X)            \"\n\t\t\t\t\t\t     \"| %s</%s>\",\n\t\t\t\t\t\t     *level, *codepage_stag,\n\t\t\t\t\t\t     tag_save_known, Indent (*level),\n\t\t\t\t\t\t     tag_save_literal); /* We already looked it up! */\n\t\t\t} else { /* Literal TAG */\n\t\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t\t     \"| END (Literal Tag)               \"\n\t\t\t\t\t\t     \"| %s</%s>\",\n\t\t\t\t\t\t     *level, *codepage_stag, Indent (*level),\n\t\t\t\t\t\t     tag_save_literal ? tag_save_literal : \"\");\n\t\t\t}\n\t\t\t(*level)--;\n\t\t\toff++;\n\t\t\t/* Reset code page: not needed as return from recursion */\n\t\t\tDebugLog((\"STAG: level = %u, Return: len = %u\\n\", *level, off - offset));\n\t\t\treturn (off - offset);\n\t\tcase 0x02: /* ENTITY */\n\t\t\tent = tvb_get_guintvar (tvb, off+1, &len);\n\t\t\tproto_tree_add_text (tree, tvb, off, 1+len,\n\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t     \"| ENTITY                          \"\n\t\t\t\t\t     \"| %s'&#%u;'\",\n\t\t\t\t\t     *level, *codepage_stag, Indent (*level), ent);\n\t\t\toff += 1+len;\n\t\t\tbreak;\n\t\tcase 0x03: /* STR_I */\n\t\t\tlen = tvb_strsize (tvb, off+1);\n\t\t\tproto_tree_add_text (tree, tvb, off, 1+len,\n\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t     \"| STR_I (Inline string)           \"\n\t\t\t\t\t     \"| %s\\'%s\\'\",\n\t\t\t\t\t     *level, *codepage_stag, Indent(*level),\n\t\t\t\t\t     tvb_format_text (tvb, off+1, len-1));\n\t\t\toff += 1+len;\n\t\t\tbreak;\n\t\tcase 0x40: /* EXT_I_0 */\n\t\tcase 0x41: /* EXT_I_1 */\n\t\tcase 0x42: /* EXT_I_2 */\n\t\t\t/* Extension tokens */\n\t\t\tlen = tvb_strsize (tvb, off+1);\n\t\t\tproto_tree_add_text (tree, tvb, off, 1+len,\n\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t     \"| EXT_I_%1x    (Extension Token)    \"\n\t\t\t\t\t     \"| %s(%s: \\'%s\\')\",\n\t\t\t\t\t     *level, *codepage_stag,\n\t\t\t\t\t     peek & 0x0f, Indent (*level),\n\t\t\t\t\t     map_token (map->global, 0, peek),\n\t\t\t\t\t     tvb_format_text (tvb, off+1, len-1));\n\t\t\toff += 1+len;\n\t\t\tbreak;\n\t\tcase 0x43: /* PI */\n\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t     \"| PI (XML Processing Instruction) \"\n\t\t\t\t\t     \"| %s<?xml\",\n\t\t\t\t\t     *level, *codepage_stag, Indent (*level));\n\t\t\tlen = parse_wbxml_attribute_list_defined (tree, tvb, off,\n\t\t\t\t\t\t\t\t  str_tbl, *level, codepage_attr, map);\n\t\t\t/* Check that there is still room in packet */\n\t\t\toff += len;\n\t\t\tif (off >= tvb_len) {\n\t\t\t\tDebugLog((\"STAG: level = %u, ThrowException: len = %u (short frame)\\n\", *level, off - offset));\n\t\t\t\t/*\n\t\t\t\t * TODO - Do we need to free g_malloc()ed memory?\n\t\t\t\t */\n\t\t\t\tTHROW(ReportedBoundsError);\n\t\t\t}\n\t\t\tproto_tree_add_text (tree, tvb, off-1, 1,\n\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t     \"| END (PI)                        \"\n\t\t\t\t\t     \"| %s?>\",\n\t\t\t\t\t     *level, *codepage_stag, Indent (*level));\n\t\t\tbreak;\n\t\tcase 0x80: /* EXT_T_0 */\n\t\tcase 0x81: /* EXT_T_1 */\n\t\tcase 0x82: /* EXT_T_2 */\n\t\t\t/* Extension tokens */\n\t\t\tidx = tvb_get_guintvar (tvb, off+1, &len);\n\t\t\t{   char *s;\n\t\t\t\tif (map->ext_t[peek & 0x03])\n\t\t\t\t\ts = (map->ext_t[peek & 0x03])(tvb, idx, str_tbl);\n\t\t\t\telse\n\t\t\t\t\ts = wmem_strdup_printf(wmem_packet_scope(), \"EXT_T_%1x (%s)\", peek & 0x03,\n\t\t\t\t\t\t\t    map_token (map->global, 0, peek));\n\t\t\t\tproto_tree_add_text (tree, tvb, off, 1+len,\n\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t\t     \"| EXT_T_%1x    (Extension Token)    \"\n\t\t\t\t\t\t     \"| %s%s\",\n\t\t\t\t\t\t     *level, *codepage_stag, peek & 0x0f, Indent (*level),\n\t\t\t\t\t\t     s);\n\t\t\t}\n\t\t\toff += 1+len;\n\t\t\tbreak;\n\t\tcase 0x83: /* STR_T */\n\t\t\tidx = tvb_get_guintvar (tvb, off+1, &len);\n\t\t\tstr_len = tvb_strsize (tvb, str_tbl+idx);\n\t\t\tproto_tree_add_text (tree, tvb, off, 1+len,\n\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t     \"| STR_T (Tableref string)         \"\n\t\t\t\t\t     \"| %s\\'%s\\'\",\n\t\t\t\t\t     *level, *codepage_stag, Indent (*level),\n\t\t\t\t\t     tvb_format_text (tvb, str_tbl+idx, str_len-1));\n\t\t\toff += 1+len;\n\t\t\tbreak;\n\t\tcase 0xC0: /* EXT_0 */\n\t\tcase 0xC1: /* EXT_1 */\n\t\tcase 0xC2: /* EXT_2 */\n\t\t\t/* Extension tokens */\n\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t     \"| EXT_%1x      (Extension Token)    \"\n\t\t\t\t\t     \"| %s(%s)\",\n\t\t\t\t\t     *level, *codepage_stag, peek & 0x0f, Indent (*level),\n\t\t\t\t\t     map_token (map->global, 0, peek));\n\t\t\toff++;\n\t\t\tbreak;\n\t\tcase 0xC3: /* OPAQUE - WBXML 1.1 and newer */\n\t\t\tif (tvb_get_guint8 (tvb, 0)) { /* WBXML 1.x (x > 0) */\n\t\t\t\tchar *str;\n\t\t\t\tif (tag_save_known) { /* Knwon tag */\n\t\t\t\t\tif (map->opaque_binary_tag) {\n\t\t\t\t\t\tstr = map->opaque_binary_tag(tvb, off + 1,\n\t\t\t\t\t\t\t\t\t     tag_save_known, *codepage_stag, &len);\n\t\t\t\t\t} else {\n\t\t\t\t\t\tstr = default_opaque_binary_tag(tvb, off + 1,\n\t\t\t\t\t\t\t\t\t\ttag_save_known, *codepage_stag, &len);\n\t\t\t\t\t}\n\t\t\t\t} else { /* lITERAL tag */\n\t\t\t\t\tif (map->opaque_literal_tag) {\n\t\t\t\t\t\tstr = map->opaque_literal_tag(tvb, off + 1,\n\t\t\t\t\t\t\t\t\t      tag_save_literal, *codepage_stag, &len);\n\t\t\t\t\t} else {\n\t\t\t\t\t\tstr = default_opaque_literal_tag(tvb, off + 1,\n\t\t\t\t\t\t\t\t\t\t tag_save_literal, *codepage_stag, &len);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tproto_tree_add_text (tree, tvb, off, 1 + len,\n\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t\t     \"| OPAQUE (Opaque data)            \"\n\t\t\t\t\t\t     \"| %s%s\",\n\t\t\t\t\t\t     *level, *codepage_stag, Indent (*level), str);\n\t\t\t\toff += 1 + len;\n\t\t\t} else { /* WBXML 1.0 - RESERVED_2 token (invalid) */\n\t\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t\t     \"| RESERVED_2     (Invalid Token!) \"\n\t\t\t\t\t\t     \"| WBXML 1.0 parsing stops here.\",\n\t\t\t\t\t\t     *level, *codepage_stag);\n\t\t\t\t/* Stop processing as it is impossible to parse now */\n\t\t\t\toff = tvb_len;\n\t\t\t\tDebugLog((\"STAG: level = %u, Return: len = %u\\n\", *level, off - offset));\n\t\t\t\treturn (off - offset);\n\t\t\t}\n\t\t\tbreak;\n\n\t\t\t/* No default clause, as all cases have been treated */\n\t\t} else { /* LITERAL or Known TAG */\n\t\t\t/* We must store the initial tag, and also retrieve the new tag.\n\t\t\t * For efficiency reasons, we store the literal tag representation\n\t\t\t * for known tags too, so we can easily close the tag without the\n\t\t\t * need of a new lookup and avoiding storage of token codepage.\n\t\t\t *\n\t\t\t * There are 4 possibilities:\n\t\t\t *\n\t\t\t *  1. Known tag followed by a known tag\n\t\t\t *  2. Known tag followed by a LITERAL tag\n\t\t\t *  3. LITERAL tag followed by Known tag\n\t\t\t *  4. LITERAL tag followed by LITERAL tag\n\t\t\t */\n\n\t\t\t/* Store the new tag */\n\t\t\ttag_len = 0;\n\t\t\tif ((peek & 0x3F) == 4) { /* LITERAL */\n\t\t\t\tDebugLog((\"STAG: LITERAL tag (peek = 0x%02X, off = %u) - TableRef follows!\\n\", peek, off));\n\t\t\t\tidx = tvb_get_guintvar (tvb, off+1, &tag_len);\n\t\t\t\tstr_len = tvb_strsize (tvb, str_tbl+idx);\n\t\t\t\ttag_new_literal = (const gchar*)tvb_get_ptr (tvb, str_tbl+idx, str_len);\n\t\t\t\ttag_new_known = 0; /* invalidate known tag_new */\n\t\t\t} else { /* Known tag */\n\t\t\t\ttag_new_known = peek & 0x3F;\n\t\t\t\ttag_new_literal = map_token (map->tags, *codepage_stag,\n\t\t\t\t\t\t\t     tag_new_known);\n\t\t\t\t/* Stored looked up tag name string */\n\t\t\t}\n\n\t\t\t/* Parsing of TAG starts HERE */\n\t\t\tif (peek & 0x40) { /* Content present */\n\t\t\t\t/* Content follows\n\t\t\t\t * [!] An explicit END token is expected in these cases!\n\t\t\t\t * ==> Recursion possible if we encounter a tag with content;\n\t\t\t\t *     recursion will return at the explicit END token.\n\t\t\t\t */\n\t\t\t\tif (parsing_tag_content) { /* Recurse */\n\t\t\t\t\tDebugLog((\"STAG: Tag in Tag - RECURSE! (off = %u)\\n\", off));\n\t\t\t\t\t/* Do not process the attribute list:\n\t\t\t\t\t * recursion will take care of it */\n\t\t\t\t\t(*level)++;\n\t\t\t\t\tlen = parse_wbxml_tag_defined (tree, tvb, off, str_tbl,\n\t\t\t\t\t\t\t\t       level, codepage_stag, codepage_attr, map);\n\t\t\t\t\toff += len;\n\t\t\t\t} else { /* Now we will have content to parse */\n\t\t\t\t\t/* Save the start tag so we can properly close it later. */\n\t\t\t\t\tif ((peek & 0x3F) == 4) { /* Literal tag */\n\t\t\t\t\t\ttag_save_literal = tag_new_literal;\n\t\t\t\t\t\ttag_save_known = 0;\n\t\t\t\t\t} else { /* Known tag */\n\t\t\t\t\t\ttag_save_known = tag_new_known;\n\t\t\t\t\t\ttag_save_literal = tag_new_literal;\n\t\t\t\t\t\t/* The last statement avoids needless lookups */\n\t\t\t\t\t}\n\t\t\t\t\t/* Process the attribute list if present */\n\t\t\t\t\tif (peek & 0x80) { /* Content and Attribute list present */\n\t\t\t\t\t\tif (tag_new_known) { /* Known tag */\n\t\t\t\t\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t\t\t\t\t     \"|   Known Tag 0x%02X           (AC) \"\n\t\t\t\t\t\t\t\t\t     \"| %s<%s\",\n\t\t\t\t\t\t\t\t\t     *level, *codepage_stag, tag_new_known,\n\t\t\t\t\t\t\t\t\t     Indent (*level), tag_new_literal);\n\t\t\t\t\t\t\t/* Tag string already looked up earlier! */\n\t\t\t\t\t\t\toff++;\n\t\t\t\t\t\t} else { /* LITERAL tag */\n\t\t\t\t\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t\t\t\t\t     \"| LITERAL_AC (Literal tag)   (AC) \"\n\t\t\t\t\t\t\t\t\t     \"| %s<%s\",\n\t\t\t\t\t\t\t\t\t     *level, *codepage_stag, Indent (*level), tag_new_literal);\n\t\t\t\t\t\t\toff += 1 + tag_len;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tlen = parse_wbxml_attribute_list_defined (tree, tvb,\n\t\t\t\t\t\t\t\t\t\t\t  off, str_tbl, *level, codepage_attr, map);\n\t\t\t\t\t\t/* Check that there is still room in packet */\n\t\t\t\t\t\toff += len;\n\t\t\t\t\t\tif (off >= tvb_len) {\n\t\t\t\t\t\t\tDebugLog((\"STAG: level = %u, ThrowException: len = %u (short frame)\\n\",\n\t\t\t\t\t\t\t\t  *level, off - offset));\n\t\t\t\t\t\t\t/*\n\t\t\t\t\t\t\t * TODO - Do we need to free g_malloc()ed memory?\n\t\t\t\t\t\t\t */\n\t\t\t\t\t\t\tTHROW(ReportedBoundsError);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tproto_tree_add_text (tree, tvb, off-1, 1,\n\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t\t\t\t     \"| END (attribute list)            \"\n\t\t\t\t\t\t\t\t     \"| %s>\",\n\t\t\t\t\t\t\t\t     *level, *codepage_stag, Indent (*level));\n\t\t\t\t\t} else { /* Content, no Attribute list */\n\t\t\t\t\t\tif (tag_new_known) { /* Known tag */\n\t\t\t\t\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t\t\t\t\t     \"|   Known Tag 0x%02X           (.C) \"\n\t\t\t\t\t\t\t\t\t     \"| %s<%s>\",\n\t\t\t\t\t\t\t\t\t     *level, *codepage_stag, tag_new_known,\n\t\t\t\t\t\t\t\t\t     Indent (*level), tag_new_literal);\n\t\t\t\t\t\t\t/* Tag string already looked up earlier! */\n\t\t\t\t\t\t\toff++;\n\t\t\t\t\t\t} else { /* LITERAL tag */\n\t\t\t\t\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t\t\t\t\t     \"| LITERAL_C  (Literal Tag)   (.C) \"\n\t\t\t\t\t\t\t\t\t     \"| %s<%s>\",\n\t\t\t\t\t\t\t\t\t     *level, *codepage_stag, Indent (*level),\n\t\t\t\t\t\t\t\t\t     tag_new_literal);\n\t\t\t\t\t\t\toff += 1 + tag_len;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\t/* The data that follows in the parsing process\n\t\t\t\t\t * represents content for the opening tag\n\t\t\t\t\t * we've just processed in the lines above.\n\t\t\t\t\t * Next time we encounter a tag with content: recurse\n\t\t\t\t\t */\n\t\t\t\t\tparsing_tag_content = TRUE;\n\t\t\t\t\tDebugLog((\"Tag in Tag - No recursion this time! (off = %u)\\n\", off));\n\t\t\t\t}\n\t\t\t} else { /* No Content */\n\t\t\t\tDebugLog((\"<Tag/> in Tag - No recursion! (off = %u)\\n\", off));\n\t\t\t\t(*level)++;\n\t\t\t\tif (peek & 0x80) { /* No Content, Attribute list present */\n\t\t\t\t\tif (tag_new_known) { /* Known tag */\n\t\t\t\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t\t\t\t     \"|   Known Tag 0x%02X           (A.) \"\n\t\t\t\t\t\t\t\t     \"| %s<%s\",\n\t\t\t\t\t\t\t\t     *level, *codepage_stag, tag_new_known,\n\t\t\t\t\t\t\t\t     Indent (*level), tag_new_literal);\n\t\t\t\t\t\t/* Tag string already looked up earlier! */\n\t\t\t\t\t\toff++;\n\t\t\t\t\t\tlen = parse_wbxml_attribute_list_defined (tree, tvb,\n\t\t\t\t\t\t\t\t\t\t\t  off, str_tbl, *level, codepage_attr, map);\n\t\t\t\t\t\t/* Check that there is still room in packet */\n\t\t\t\t\t\toff += len;\n\t\t\t\t\t\tif (off > tvb_len) {\n\t\t\t\t\t\t\tDebugLog((\"STAG: level = %u, ThrowException: len = %u (short frame)\\n\", *level, off - offset));\n\t\t\t\t\t\t\t/*\n\t\t\t\t\t\t\t * TODO - Do we need to free g_malloc()ed memory?\n\t\t\t\t\t\t\t */\n\t\t\t\t\t\t\tTHROW(ReportedBoundsError);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tproto_tree_add_text (tree, tvb, off-1, 1,\n\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t\t\t\t     \"| END (Known Tag)                 \"\n\t\t\t\t\t\t\t\t     \"| %s/>\",\n\t\t\t\t\t\t\t\t     *level, *codepage_stag, Indent (*level));\n\t\t\t\t\t} else { /* LITERAL tag */\n\t\t\t\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t\t\t\t     \"| LITERAL_A  (Literal Tag)   (A.) \"\n\t\t\t\t\t\t\t\t     \"| %s<%s\",\n\t\t\t\t\t\t\t\t     *level, *codepage_stag, Indent (*level), tag_new_literal);\n\t\t\t\t\t\toff += 1 + tag_len;\n\t\t\t\t\t\tlen = parse_wbxml_attribute_list_defined (tree, tvb,\n\t\t\t\t\t\t\t\t\t\t\t  off, str_tbl, *level, codepage_attr, map);\n\t\t\t\t\t\t/* Check that there is still room in packet */\n\t\t\t\t\t\toff += len;\n\t\t\t\t\t\tif (off >= tvb_len) {\n\t\t\t\t\t\t\tDebugLog((\"STAG: level = %u, ThrowException: len = %u (short frame)\\n\", *level, off - offset));\n\t\t\t\t\t\t\t/*\n\t\t\t\t\t\t\t * TODO - Do we need to free g_malloc()ed memory?\n\t\t\t\t\t\t\t */\n\t\t\t\t\t\t\tTHROW(ReportedBoundsError);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tproto_tree_add_text (tree, tvb, off-1, 1,\n\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t\t\t\t     \"| END (Literal Tag)               \"\n\t\t\t\t\t\t\t\t     \"| %s/>\",\n\t\t\t\t\t\t\t\t     *level, *codepage_stag, Indent (*level));\n\t\t\t\t\t}\n\t\t\t\t} else { /* No Content, No Attribute list */\n\t\t\t\t\tif (tag_new_known) { /* Known tag */\n\t\t\t\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t\t\t\t     \"|   Known Tag 0x%02x           (..) \"\n\t\t\t\t\t\t\t\t     \"| %s<%s />\",\n\t\t\t\t\t\t\t\t     *level, *codepage_stag, tag_new_known,\n\t\t\t\t\t\t\t\t     Indent (*level), tag_new_literal);\n\t\t\t\t\t\t/* Tag string already looked up earlier! */\n\t\t\t\t\t\toff++;\n\t\t\t\t\t} else { /* LITERAL tag */\n\t\t\t\t\t\tproto_tree_add_text (tree, tvb, off, 1,\n\t\t\t\t\t\t\t\t     \"  %3d | Tag   | T %3d    \"\n\t\t\t\t\t\t\t\t     \"| LITERAL    (Literal Tag)   (..) \"\n\t\t\t\t\t\t\t\t     \"| %s<%s />\",\n\t\t\t\t\t\t\t\t     *level, *codepage_stag, Indent (*level),\n\t\t\t\t\t\t\t\t     tag_new_literal);\n\t\t\t\t\t\toff += 1 + tag_len;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t(*level)--;\n\t\t\t\t/* TODO: Do I have to reset code page here? */\n\t\t\t}\n\t\t} /* if (tag & 0x3F) >= 5 */\n\t\tif (off < last_off) {\n\t\t\tTHROW(ReportedBoundsError);\n\t\t}\n\t\tlast_off = off;\n\t} /* while */\n\tDebugLog((\"STAG: level = %u, Return: len = %u (end of function body)\\n\", *level, off - offset));\n\treturn (off - offset);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,7 +4,7 @@\n \t\t\t const wbxml_decoding *map)\n {\n \tguint32     tvb_len  = tvb_reported_length (tvb);\n-\tguint32     off      = offset;\n+\tguint32     off      = offset, last_off;\n \tguint32     len;\n \tguint       str_len;\n \tguint32     ent;\n@@ -23,6 +23,7 @@\n \ttag_save_literal = NULL;                 /* Prevents compiler warning */\n \n \tDebugLog((\"parse_wbxml_tag_defined (level = %u, offset = %u)\\n\", *level, offset));\n+\tlast_off = off;\n \twhile (off < tvb_len) {\n \t\tpeek = tvb_get_guint8 (tvb, off);\n \t\tDebugLog((\"STAG: (top of while) level = %3u, peek = 0x%02X, off = %u, tvb_len = %u\\n\", *level, peek, off, tvb_len));\n@@ -394,6 +395,10 @@\n \t\t\t\t/* TODO: Do I have to reset code page here? */\n \t\t\t}\n \t\t} /* if (tag & 0x3F) >= 5 */\n+\t\tif (off < last_off) {\n+\t\t\tTHROW(ReportedBoundsError);\n+\t\t}\n+\t\tlast_off = off;\n \t} /* while */\n \tDebugLog((\"STAG: level = %u, Return: len = %u (end of function body)\\n\", *level, off - offset));\n \treturn (off - offset);",
        "diff_line_info": {
            "deleted_lines": [
                "\tguint32     off      = offset;"
            ],
            "added_lines": [
                "\tguint32     off      = offset, last_off;",
                "\tlast_off = off;",
                "\t\tif (off < last_off) {",
                "\t\t\tTHROW(ReportedBoundsError);",
                "\t\t}",
                "\t\tlast_off = off;"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-2179",
        "func_name": "openssl/dtls1_stop_timer",
        "description": "The DTLS implementation in OpenSSL before 1.1.0 does not properly restrict the lifetime of queue entries associated with unused out-of-order messages, which allows remote attackers to cause a denial of service (memory consumption) by maintaining many crafted DTLS sessions simultaneously, related to d1_lib.c, statem_dtls.c, statem_lib.c, and statem_srvr.c.",
        "git_url": "https://git.openssl.org/?p=openssl.git;a=commit;h=f5c7f5dfbaf0d2f7d946d0fe86f08e6bcb36ed0d",
        "commit_title": "",
        "commit_text": "Fix DTLS buffered message DoS attack  DTLS can handle out of order record delivery. Additionally since handshake messages can be bigger than will fit into a single packet, the messages can be fragmented across multiple records (as with normal TLS). That means that the messages can arrive mixed up, and we have to reassemble them. We keep a queue of buffered messages that are \"from the future\", i.e. messages we're not ready to deal with yet but have arrived early. The messages held there may not be full yet - they could be one or more fragments that are still in the process of being reassembled.  The code assumes that we will eventually complete the reassembly and when that occurs the complete message is removed from the queue at the point that we need to use it.  However, DTLS is also tolerant of packet loss. To get around that DTLS messages can be retransmitted. If we receive a full (non-fragmented) message from the peer after previously having received a fragment of that message, then we ignore the message in the queue and just use the non-fragmented version. At that point the queued message will never get removed.  Additionally the peer could send \"future\" messages that we never get to in order to complete the handshake. Each message has a sequence number (starting from 0). We will accept a message fragment for the current message sequence number, or for any sequence up to 10 into the future. However if the Finished message has a sequence number of 2, anything greater than that in the queue is just left there.  So, in those two ways we can end up with \"orphaned\" data in the queue that will never get removed - except when the connection is closed. At that point all the queues are flushed.  An attacker could seek to exploit this by filling up the queues with lots of large messages that are never going to be used in order to attempt a DoS by memory exhaustion.  I will assume that we are only concerned with servers here. It does not seem reasonable to be concerned about a memory exhaustion attack on a client. They are unlikely to process enough connections for this to be an issue.  A \"long\" handshake with many messages might be 5 messages long (in the incoming direction), e.g. ClientHello, Certificate, ClientKeyExchange, CertificateVerify, Finished. So this would be message sequence numbers 0 to 4. Additionally we can buffer up to 10 messages in the future. Therefore the maximum number of messages that an attacker could send that could get orphaned would typically be 15.  The maximum size that a DTLS message is allowed to be is defined by max_cert_list, which by default is 100k. Therefore the maximum amount of \"orphaned\" memory per connection is 1500k.  Message sequence numbers get reset after the Finished message, so renegotiation will not extend the maximum number of messages that can be orphaned per connection.  As noted above, the queues do get cleared when the connection is closed. Therefore in order to mount an effective attack, an attacker would have to open many simultaneous connections.  Issue reported by Quan Luo.  CVE-2016-2179  ",
        "func_before": "void dtls1_stop_timer(SSL *s)\n{\n    /* Reset everything */\n    memset(&s->d1->timeout, 0, sizeof(s->d1->timeout));\n    memset(&s->d1->next_timeout, 0, sizeof(s->d1->next_timeout));\n    s->d1->timeout_duration = 1;\n    BIO_ctrl(SSL_get_rbio(s), BIO_CTRL_DGRAM_SET_NEXT_TIMEOUT, 0,\n             &(s->d1->next_timeout));\n    /* Clear retransmission buffer */\n    dtls1_clear_record_buffer(s);\n}",
        "func": "void dtls1_stop_timer(SSL *s)\n{\n    /* Reset everything */\n    memset(&s->d1->timeout, 0, sizeof(s->d1->timeout));\n    memset(&s->d1->next_timeout, 0, sizeof(s->d1->next_timeout));\n    s->d1->timeout_duration = 1;\n    BIO_ctrl(SSL_get_rbio(s), BIO_CTRL_DGRAM_SET_NEXT_TIMEOUT, 0,\n             &(s->d1->next_timeout));\n    /* Clear retransmission buffer */\n    dtls1_clear_sent_buffer(s);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -7,5 +7,5 @@\n     BIO_ctrl(SSL_get_rbio(s), BIO_CTRL_DGRAM_SET_NEXT_TIMEOUT, 0,\n              &(s->d1->next_timeout));\n     /* Clear retransmission buffer */\n-    dtls1_clear_record_buffer(s);\n+    dtls1_clear_sent_buffer(s);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    dtls1_clear_record_buffer(s);"
            ],
            "added_lines": [
                "    dtls1_clear_sent_buffer(s);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-2179",
        "func_name": "openssl/dtls1_clear_queues",
        "description": "The DTLS implementation in OpenSSL before 1.1.0 does not properly restrict the lifetime of queue entries associated with unused out-of-order messages, which allows remote attackers to cause a denial of service (memory consumption) by maintaining many crafted DTLS sessions simultaneously, related to d1_lib.c, statem_dtls.c, statem_lib.c, and statem_srvr.c.",
        "git_url": "https://git.openssl.org/?p=openssl.git;a=commit;h=f5c7f5dfbaf0d2f7d946d0fe86f08e6bcb36ed0d",
        "commit_title": "",
        "commit_text": "Fix DTLS buffered message DoS attack  DTLS can handle out of order record delivery. Additionally since handshake messages can be bigger than will fit into a single packet, the messages can be fragmented across multiple records (as with normal TLS). That means that the messages can arrive mixed up, and we have to reassemble them. We keep a queue of buffered messages that are \"from the future\", i.e. messages we're not ready to deal with yet but have arrived early. The messages held there may not be full yet - they could be one or more fragments that are still in the process of being reassembled.  The code assumes that we will eventually complete the reassembly and when that occurs the complete message is removed from the queue at the point that we need to use it.  However, DTLS is also tolerant of packet loss. To get around that DTLS messages can be retransmitted. If we receive a full (non-fragmented) message from the peer after previously having received a fragment of that message, then we ignore the message in the queue and just use the non-fragmented version. At that point the queued message will never get removed.  Additionally the peer could send \"future\" messages that we never get to in order to complete the handshake. Each message has a sequence number (starting from 0). We will accept a message fragment for the current message sequence number, or for any sequence up to 10 into the future. However if the Finished message has a sequence number of 2, anything greater than that in the queue is just left there.  So, in those two ways we can end up with \"orphaned\" data in the queue that will never get removed - except when the connection is closed. At that point all the queues are flushed.  An attacker could seek to exploit this by filling up the queues with lots of large messages that are never going to be used in order to attempt a DoS by memory exhaustion.  I will assume that we are only concerned with servers here. It does not seem reasonable to be concerned about a memory exhaustion attack on a client. They are unlikely to process enough connections for this to be an issue.  A \"long\" handshake with many messages might be 5 messages long (in the incoming direction), e.g. ClientHello, Certificate, ClientKeyExchange, CertificateVerify, Finished. So this would be message sequence numbers 0 to 4. Additionally we can buffer up to 10 messages in the future. Therefore the maximum number of messages that an attacker could send that could get orphaned would typically be 15.  The maximum size that a DTLS message is allowed to be is defined by max_cert_list, which by default is 100k. Therefore the maximum amount of \"orphaned\" memory per connection is 1500k.  Message sequence numbers get reset after the Finished message, so renegotiation will not extend the maximum number of messages that can be orphaned per connection.  As noted above, the queues do get cleared when the connection is closed. Therefore in order to mount an effective attack, an attacker would have to open many simultaneous connections.  Issue reported by Quan Luo.  CVE-2016-2179  ",
        "func_before": "static void dtls1_clear_queues(SSL *s)\n{\n    pitem *item = NULL;\n    hm_fragment *frag = NULL;\n\n    while ((item = pqueue_pop(s->d1->buffered_messages)) != NULL) {\n        frag = (hm_fragment *)item->data;\n        dtls1_hm_fragment_free(frag);\n        pitem_free(item);\n    }\n\n    while ((item = pqueue_pop(s->d1->sent_messages)) != NULL) {\n        frag = (hm_fragment *)item->data;\n        dtls1_hm_fragment_free(frag);\n        pitem_free(item);\n    }\n}",
        "func": "static void dtls1_clear_queues(SSL *s)\n{\n    dtls1_clear_received_buffer(s);\n    dtls1_clear_sent_buffer(s);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,17 +1,5 @@\n static void dtls1_clear_queues(SSL *s)\n {\n-    pitem *item = NULL;\n-    hm_fragment *frag = NULL;\n-\n-    while ((item = pqueue_pop(s->d1->buffered_messages)) != NULL) {\n-        frag = (hm_fragment *)item->data;\n-        dtls1_hm_fragment_free(frag);\n-        pitem_free(item);\n-    }\n-\n-    while ((item = pqueue_pop(s->d1->sent_messages)) != NULL) {\n-        frag = (hm_fragment *)item->data;\n-        dtls1_hm_fragment_free(frag);\n-        pitem_free(item);\n-    }\n+    dtls1_clear_received_buffer(s);\n+    dtls1_clear_sent_buffer(s);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    pitem *item = NULL;",
                "    hm_fragment *frag = NULL;",
                "",
                "    while ((item = pqueue_pop(s->d1->buffered_messages)) != NULL) {",
                "        frag = (hm_fragment *)item->data;",
                "        dtls1_hm_fragment_free(frag);",
                "        pitem_free(item);",
                "    }",
                "",
                "    while ((item = pqueue_pop(s->d1->sent_messages)) != NULL) {",
                "        frag = (hm_fragment *)item->data;",
                "        dtls1_hm_fragment_free(frag);",
                "        pitem_free(item);",
                "    }"
            ],
            "added_lines": [
                "    dtls1_clear_received_buffer(s);",
                "    dtls1_clear_sent_buffer(s);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-2179",
        "func_name": "openssl/dtls1_retrieve_buffered_fragment",
        "description": "The DTLS implementation in OpenSSL before 1.1.0 does not properly restrict the lifetime of queue entries associated with unused out-of-order messages, which allows remote attackers to cause a denial of service (memory consumption) by maintaining many crafted DTLS sessions simultaneously, related to d1_lib.c, statem_dtls.c, statem_lib.c, and statem_srvr.c.",
        "git_url": "https://git.openssl.org/?p=openssl.git;a=commit;h=f5c7f5dfbaf0d2f7d946d0fe86f08e6bcb36ed0d",
        "commit_title": "",
        "commit_text": "Fix DTLS buffered message DoS attack  DTLS can handle out of order record delivery. Additionally since handshake messages can be bigger than will fit into a single packet, the messages can be fragmented across multiple records (as with normal TLS). That means that the messages can arrive mixed up, and we have to reassemble them. We keep a queue of buffered messages that are \"from the future\", i.e. messages we're not ready to deal with yet but have arrived early. The messages held there may not be full yet - they could be one or more fragments that are still in the process of being reassembled.  The code assumes that we will eventually complete the reassembly and when that occurs the complete message is removed from the queue at the point that we need to use it.  However, DTLS is also tolerant of packet loss. To get around that DTLS messages can be retransmitted. If we receive a full (non-fragmented) message from the peer after previously having received a fragment of that message, then we ignore the message in the queue and just use the non-fragmented version. At that point the queued message will never get removed.  Additionally the peer could send \"future\" messages that we never get to in order to complete the handshake. Each message has a sequence number (starting from 0). We will accept a message fragment for the current message sequence number, or for any sequence up to 10 into the future. However if the Finished message has a sequence number of 2, anything greater than that in the queue is just left there.  So, in those two ways we can end up with \"orphaned\" data in the queue that will never get removed - except when the connection is closed. At that point all the queues are flushed.  An attacker could seek to exploit this by filling up the queues with lots of large messages that are never going to be used in order to attempt a DoS by memory exhaustion.  I will assume that we are only concerned with servers here. It does not seem reasonable to be concerned about a memory exhaustion attack on a client. They are unlikely to process enough connections for this to be an issue.  A \"long\" handshake with many messages might be 5 messages long (in the incoming direction), e.g. ClientHello, Certificate, ClientKeyExchange, CertificateVerify, Finished. So this would be message sequence numbers 0 to 4. Additionally we can buffer up to 10 messages in the future. Therefore the maximum number of messages that an attacker could send that could get orphaned would typically be 15.  The maximum size that a DTLS message is allowed to be is defined by max_cert_list, which by default is 100k. Therefore the maximum amount of \"orphaned\" memory per connection is 1500k.  Message sequence numbers get reset after the Finished message, so renegotiation will not extend the maximum number of messages that can be orphaned per connection.  As noted above, the queues do get cleared when the connection is closed. Therefore in order to mount an effective attack, an attacker would have to open many simultaneous connections.  Issue reported by Quan Luo.  CVE-2016-2179  ",
        "func_before": "static int dtls1_retrieve_buffered_fragment(SSL *s, int *ok)\n{\n    /*-\n     * (0) check whether the desired fragment is available\n     * if so:\n     * (1) copy over the fragment to s->init_buf->data[]\n     * (2) update s->init_num\n     */\n    pitem *item;\n    hm_fragment *frag;\n    int al;\n\n    *ok = 0;\n    item = pqueue_peek(s->d1->buffered_messages);\n    if (item == NULL)\n        return 0;\n\n    frag = (hm_fragment *)item->data;\n\n    /* Don't return if reassembly still in progress */\n    if (frag->reassembly != NULL)\n        return 0;\n\n    if (s->d1->handshake_read_seq == frag->msg_header.seq) {\n        unsigned long frag_len = frag->msg_header.frag_len;\n        pqueue_pop(s->d1->buffered_messages);\n\n        al = dtls1_preprocess_fragment(s, &frag->msg_header);\n\n        if (al == 0) {          /* no alert */\n            unsigned char *p =\n                (unsigned char *)s->init_buf->data + DTLS1_HM_HEADER_LENGTH;\n            memcpy(&p[frag->msg_header.frag_off], frag->fragment,\n                   frag->msg_header.frag_len);\n        }\n\n        dtls1_hm_fragment_free(frag);\n        pitem_free(item);\n\n        if (al == 0) {\n            *ok = 1;\n            return frag_len;\n        }\n\n        ssl3_send_alert(s, SSL3_AL_FATAL, al);\n        s->init_num = 0;\n        *ok = 0;\n        return -1;\n    } else\n        return 0;\n}",
        "func": "static int dtls1_retrieve_buffered_fragment(SSL *s, int *ok)\n{\n    /*-\n     * (0) check whether the desired fragment is available\n     * if so:\n     * (1) copy over the fragment to s->init_buf->data[]\n     * (2) update s->init_num\n     */\n    pitem *item;\n    hm_fragment *frag;\n    int al;\n\n    *ok = 0;\n\n    do {\n        item = pqueue_peek(s->d1->buffered_messages);\n        if (item == NULL)\n            return 0;\n\n        frag = (hm_fragment *)item->data;\n\n        if (frag->msg_header.seq < s->d1->handshake_read_seq) {\n            /* This is a stale message that has been buffered so clear it */\n            pqueue_pop(s->d1->buffered_messages);\n            dtls1_hm_fragment_free(frag);\n            pitem_free(item);\n            item = NULL;\n            frag = NULL;\n        }\n    } while (item == NULL);\n\n    /* Don't return if reassembly still in progress */\n    if (frag->reassembly != NULL)\n        return 0;\n\n    if (s->d1->handshake_read_seq == frag->msg_header.seq) {\n        unsigned long frag_len = frag->msg_header.frag_len;\n        pqueue_pop(s->d1->buffered_messages);\n\n        al = dtls1_preprocess_fragment(s, &frag->msg_header);\n\n        if (al == 0) {          /* no alert */\n            unsigned char *p =\n                (unsigned char *)s->init_buf->data + DTLS1_HM_HEADER_LENGTH;\n            memcpy(&p[frag->msg_header.frag_off], frag->fragment,\n                   frag->msg_header.frag_len);\n        }\n\n        dtls1_hm_fragment_free(frag);\n        pitem_free(item);\n\n        if (al == 0) {\n            *ok = 1;\n            return frag_len;\n        }\n\n        ssl3_send_alert(s, SSL3_AL_FATAL, al);\n        s->init_num = 0;\n        *ok = 0;\n        return -1;\n    } else\n        return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -11,11 +11,23 @@\n     int al;\n \n     *ok = 0;\n-    item = pqueue_peek(s->d1->buffered_messages);\n-    if (item == NULL)\n-        return 0;\n \n-    frag = (hm_fragment *)item->data;\n+    do {\n+        item = pqueue_peek(s->d1->buffered_messages);\n+        if (item == NULL)\n+            return 0;\n+\n+        frag = (hm_fragment *)item->data;\n+\n+        if (frag->msg_header.seq < s->d1->handshake_read_seq) {\n+            /* This is a stale message that has been buffered so clear it */\n+            pqueue_pop(s->d1->buffered_messages);\n+            dtls1_hm_fragment_free(frag);\n+            pitem_free(item);\n+            item = NULL;\n+            frag = NULL;\n+        }\n+    } while (item == NULL);\n \n     /* Don't return if reassembly still in progress */\n     if (frag->reassembly != NULL)",
        "diff_line_info": {
            "deleted_lines": [
                "    item = pqueue_peek(s->d1->buffered_messages);",
                "    if (item == NULL)",
                "        return 0;",
                "    frag = (hm_fragment *)item->data;"
            ],
            "added_lines": [
                "    do {",
                "        item = pqueue_peek(s->d1->buffered_messages);",
                "        if (item == NULL)",
                "            return 0;",
                "",
                "        frag = (hm_fragment *)item->data;",
                "",
                "        if (frag->msg_header.seq < s->d1->handshake_read_seq) {",
                "            /* This is a stale message that has been buffered so clear it */",
                "            pqueue_pop(s->d1->buffered_messages);",
                "            dtls1_hm_fragment_free(frag);",
                "            pitem_free(item);",
                "            item = NULL;",
                "            frag = NULL;",
                "        }",
                "    } while (item == NULL);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-2179",
        "func_name": "openssl/ossl_statem_server_pre_work",
        "description": "The DTLS implementation in OpenSSL before 1.1.0 does not properly restrict the lifetime of queue entries associated with unused out-of-order messages, which allows remote attackers to cause a denial of service (memory consumption) by maintaining many crafted DTLS sessions simultaneously, related to d1_lib.c, statem_dtls.c, statem_lib.c, and statem_srvr.c.",
        "git_url": "https://git.openssl.org/?p=openssl.git;a=commit;h=f5c7f5dfbaf0d2f7d946d0fe86f08e6bcb36ed0d",
        "commit_title": "",
        "commit_text": "Fix DTLS buffered message DoS attack  DTLS can handle out of order record delivery. Additionally since handshake messages can be bigger than will fit into a single packet, the messages can be fragmented across multiple records (as with normal TLS). That means that the messages can arrive mixed up, and we have to reassemble them. We keep a queue of buffered messages that are \"from the future\", i.e. messages we're not ready to deal with yet but have arrived early. The messages held there may not be full yet - they could be one or more fragments that are still in the process of being reassembled.  The code assumes that we will eventually complete the reassembly and when that occurs the complete message is removed from the queue at the point that we need to use it.  However, DTLS is also tolerant of packet loss. To get around that DTLS messages can be retransmitted. If we receive a full (non-fragmented) message from the peer after previously having received a fragment of that message, then we ignore the message in the queue and just use the non-fragmented version. At that point the queued message will never get removed.  Additionally the peer could send \"future\" messages that we never get to in order to complete the handshake. Each message has a sequence number (starting from 0). We will accept a message fragment for the current message sequence number, or for any sequence up to 10 into the future. However if the Finished message has a sequence number of 2, anything greater than that in the queue is just left there.  So, in those two ways we can end up with \"orphaned\" data in the queue that will never get removed - except when the connection is closed. At that point all the queues are flushed.  An attacker could seek to exploit this by filling up the queues with lots of large messages that are never going to be used in order to attempt a DoS by memory exhaustion.  I will assume that we are only concerned with servers here. It does not seem reasonable to be concerned about a memory exhaustion attack on a client. They are unlikely to process enough connections for this to be an issue.  A \"long\" handshake with many messages might be 5 messages long (in the incoming direction), e.g. ClientHello, Certificate, ClientKeyExchange, CertificateVerify, Finished. So this would be message sequence numbers 0 to 4. Additionally we can buffer up to 10 messages in the future. Therefore the maximum number of messages that an attacker could send that could get orphaned would typically be 15.  The maximum size that a DTLS message is allowed to be is defined by max_cert_list, which by default is 100k. Therefore the maximum amount of \"orphaned\" memory per connection is 1500k.  Message sequence numbers get reset after the Finished message, so renegotiation will not extend the maximum number of messages that can be orphaned per connection.  As noted above, the queues do get cleared when the connection is closed. Therefore in order to mount an effective attack, an attacker would have to open many simultaneous connections.  Issue reported by Quan Luo.  CVE-2016-2179  ",
        "func_before": "WORK_STATE ossl_statem_server_pre_work(SSL *s, WORK_STATE wst)\n{\n    OSSL_STATEM *st = &s->statem;\n\n    switch (st->hand_state) {\n    case TLS_ST_SW_HELLO_REQ:\n        s->shutdown = 0;\n        if (SSL_IS_DTLS(s))\n            dtls1_clear_record_buffer(s);\n        break;\n\n    case DTLS_ST_SW_HELLO_VERIFY_REQUEST:\n        s->shutdown = 0;\n        if (SSL_IS_DTLS(s)) {\n            dtls1_clear_record_buffer(s);\n            /* We don't buffer this message so don't use the timer */\n            st->use_timer = 0;\n        }\n        break;\n\n    case TLS_ST_SW_SRVR_HELLO:\n        if (SSL_IS_DTLS(s)) {\n            /*\n             * Messages we write from now on should be bufferred and\n             * retransmitted if necessary, so we need to use the timer now\n             */\n            st->use_timer = 1;\n        }\n        break;\n\n    case TLS_ST_SW_SRVR_DONE:\n#ifndef OPENSSL_NO_SCTP\n        if (SSL_IS_DTLS(s) && BIO_dgram_is_sctp(SSL_get_wbio(s)))\n            return dtls_wait_for_dry(s);\n#endif\n        return WORK_FINISHED_CONTINUE;\n\n    case TLS_ST_SW_SESSION_TICKET:\n        if (SSL_IS_DTLS(s)) {\n            /*\n             * We're into the last flight. We don't retransmit the last flight\n             * unless we need to, so we don't use the timer\n             */\n            st->use_timer = 0;\n        }\n        break;\n\n    case TLS_ST_SW_CHANGE:\n        s->session->cipher = s->s3->tmp.new_cipher;\n        if (!s->method->ssl3_enc->setup_key_block(s)) {\n            ossl_statem_set_error(s);\n            return WORK_ERROR;\n        }\n        if (SSL_IS_DTLS(s)) {\n            /*\n             * We're into the last flight. We don't retransmit the last flight\n             * unless we need to, so we don't use the timer. This might have\n             * already been set to 0 if we sent a NewSessionTicket message,\n             * but we'll set it again here in case we didn't.\n             */\n            st->use_timer = 0;\n        }\n        return WORK_FINISHED_CONTINUE;\n\n    case TLS_ST_OK:\n        return tls_finish_handshake(s, wst);\n\n    default:\n        /* No pre work to be done */\n        break;\n    }\n\n    return WORK_FINISHED_CONTINUE;\n}",
        "func": "WORK_STATE ossl_statem_server_pre_work(SSL *s, WORK_STATE wst)\n{\n    OSSL_STATEM *st = &s->statem;\n\n    switch (st->hand_state) {\n    case TLS_ST_SW_HELLO_REQ:\n        s->shutdown = 0;\n        if (SSL_IS_DTLS(s))\n            dtls1_clear_sent_buffer(s);\n        break;\n\n    case DTLS_ST_SW_HELLO_VERIFY_REQUEST:\n        s->shutdown = 0;\n        if (SSL_IS_DTLS(s)) {\n            dtls1_clear_sent_buffer(s);\n            /* We don't buffer this message so don't use the timer */\n            st->use_timer = 0;\n        }\n        break;\n\n    case TLS_ST_SW_SRVR_HELLO:\n        if (SSL_IS_DTLS(s)) {\n            /*\n             * Messages we write from now on should be bufferred and\n             * retransmitted if necessary, so we need to use the timer now\n             */\n            st->use_timer = 1;\n        }\n        break;\n\n    case TLS_ST_SW_SRVR_DONE:\n#ifndef OPENSSL_NO_SCTP\n        if (SSL_IS_DTLS(s) && BIO_dgram_is_sctp(SSL_get_wbio(s)))\n            return dtls_wait_for_dry(s);\n#endif\n        return WORK_FINISHED_CONTINUE;\n\n    case TLS_ST_SW_SESSION_TICKET:\n        if (SSL_IS_DTLS(s)) {\n            /*\n             * We're into the last flight. We don't retransmit the last flight\n             * unless we need to, so we don't use the timer\n             */\n            st->use_timer = 0;\n        }\n        break;\n\n    case TLS_ST_SW_CHANGE:\n        s->session->cipher = s->s3->tmp.new_cipher;\n        if (!s->method->ssl3_enc->setup_key_block(s)) {\n            ossl_statem_set_error(s);\n            return WORK_ERROR;\n        }\n        if (SSL_IS_DTLS(s)) {\n            /*\n             * We're into the last flight. We don't retransmit the last flight\n             * unless we need to, so we don't use the timer. This might have\n             * already been set to 0 if we sent a NewSessionTicket message,\n             * but we'll set it again here in case we didn't.\n             */\n            st->use_timer = 0;\n        }\n        return WORK_FINISHED_CONTINUE;\n\n    case TLS_ST_OK:\n        return tls_finish_handshake(s, wst);\n\n    default:\n        /* No pre work to be done */\n        break;\n    }\n\n    return WORK_FINISHED_CONTINUE;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -6,13 +6,13 @@\n     case TLS_ST_SW_HELLO_REQ:\n         s->shutdown = 0;\n         if (SSL_IS_DTLS(s))\n-            dtls1_clear_record_buffer(s);\n+            dtls1_clear_sent_buffer(s);\n         break;\n \n     case DTLS_ST_SW_HELLO_VERIFY_REQUEST:\n         s->shutdown = 0;\n         if (SSL_IS_DTLS(s)) {\n-            dtls1_clear_record_buffer(s);\n+            dtls1_clear_sent_buffer(s);\n             /* We don't buffer this message so don't use the timer */\n             st->use_timer = 0;\n         }",
        "diff_line_info": {
            "deleted_lines": [
                "            dtls1_clear_record_buffer(s);",
                "            dtls1_clear_record_buffer(s);"
            ],
            "added_lines": [
                "            dtls1_clear_sent_buffer(s);",
                "            dtls1_clear_sent_buffer(s);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-2179",
        "func_name": "openssl/tls_finish_handshake",
        "description": "The DTLS implementation in OpenSSL before 1.1.0 does not properly restrict the lifetime of queue entries associated with unused out-of-order messages, which allows remote attackers to cause a denial of service (memory consumption) by maintaining many crafted DTLS sessions simultaneously, related to d1_lib.c, statem_dtls.c, statem_lib.c, and statem_srvr.c.",
        "git_url": "https://git.openssl.org/?p=openssl.git;a=commit;h=f5c7f5dfbaf0d2f7d946d0fe86f08e6bcb36ed0d",
        "commit_title": "",
        "commit_text": "Fix DTLS buffered message DoS attack  DTLS can handle out of order record delivery. Additionally since handshake messages can be bigger than will fit into a single packet, the messages can be fragmented across multiple records (as with normal TLS). That means that the messages can arrive mixed up, and we have to reassemble them. We keep a queue of buffered messages that are \"from the future\", i.e. messages we're not ready to deal with yet but have arrived early. The messages held there may not be full yet - they could be one or more fragments that are still in the process of being reassembled.  The code assumes that we will eventually complete the reassembly and when that occurs the complete message is removed from the queue at the point that we need to use it.  However, DTLS is also tolerant of packet loss. To get around that DTLS messages can be retransmitted. If we receive a full (non-fragmented) message from the peer after previously having received a fragment of that message, then we ignore the message in the queue and just use the non-fragmented version. At that point the queued message will never get removed.  Additionally the peer could send \"future\" messages that we never get to in order to complete the handshake. Each message has a sequence number (starting from 0). We will accept a message fragment for the current message sequence number, or for any sequence up to 10 into the future. However if the Finished message has a sequence number of 2, anything greater than that in the queue is just left there.  So, in those two ways we can end up with \"orphaned\" data in the queue that will never get removed - except when the connection is closed. At that point all the queues are flushed.  An attacker could seek to exploit this by filling up the queues with lots of large messages that are never going to be used in order to attempt a DoS by memory exhaustion.  I will assume that we are only concerned with servers here. It does not seem reasonable to be concerned about a memory exhaustion attack on a client. They are unlikely to process enough connections for this to be an issue.  A \"long\" handshake with many messages might be 5 messages long (in the incoming direction), e.g. ClientHello, Certificate, ClientKeyExchange, CertificateVerify, Finished. So this would be message sequence numbers 0 to 4. Additionally we can buffer up to 10 messages in the future. Therefore the maximum number of messages that an attacker could send that could get orphaned would typically be 15.  The maximum size that a DTLS message is allowed to be is defined by max_cert_list, which by default is 100k. Therefore the maximum amount of \"orphaned\" memory per connection is 1500k.  Message sequence numbers get reset after the Finished message, so renegotiation will not extend the maximum number of messages that can be orphaned per connection.  As noted above, the queues do get cleared when the connection is closed. Therefore in order to mount an effective attack, an attacker would have to open many simultaneous connections.  Issue reported by Quan Luo.  CVE-2016-2179  ",
        "func_before": "WORK_STATE tls_finish_handshake(SSL *s, WORK_STATE wst)\n{\n    void (*cb) (const SSL *ssl, int type, int val) = NULL;\n\n#ifndef OPENSSL_NO_SCTP\n    if (SSL_IS_DTLS(s) && BIO_dgram_is_sctp(SSL_get_wbio(s))) {\n        WORK_STATE ret;\n        ret = dtls_wait_for_dry(s);\n        if (ret != WORK_FINISHED_CONTINUE)\n            return ret;\n    }\n#endif\n\n    /* clean a few things up */\n    ssl3_cleanup_key_block(s);\n\n    if (!SSL_IS_DTLS(s)) {\n        /*\n         * We don't do this in DTLS because we may still need the init_buf\n         * in case there are any unexpected retransmits\n         */\n        BUF_MEM_free(s->init_buf);\n        s->init_buf = NULL;\n    }\n\n    ssl_free_wbio_buffer(s);\n\n    s->init_num = 0;\n\n    if (!s->server || s->renegotiate == 2) {\n        /* skipped if we just sent a HelloRequest */\n        s->renegotiate = 0;\n        s->new_session = 0;\n\n        if (s->server) {\n            ssl_update_cache(s, SSL_SESS_CACHE_SERVER);\n\n            s->ctx->stats.sess_accept_good++;\n            s->handshake_func = ossl_statem_accept;\n        } else {\n            ssl_update_cache(s, SSL_SESS_CACHE_CLIENT);\n            if (s->hit)\n                s->ctx->stats.sess_hit++;\n\n            s->handshake_func = ossl_statem_connect;\n            s->ctx->stats.sess_connect_good++;\n        }\n\n        if (s->info_callback != NULL)\n            cb = s->info_callback;\n        else if (s->ctx->info_callback != NULL)\n            cb = s->ctx->info_callback;\n\n        if (cb != NULL)\n            cb(s, SSL_CB_HANDSHAKE_DONE, 1);\n\n        if (SSL_IS_DTLS(s)) {\n            /* done with handshaking */\n            s->d1->handshake_read_seq = 0;\n            s->d1->handshake_write_seq = 0;\n            s->d1->next_handshake_write_seq = 0;\n        }\n    }\n\n    return WORK_FINISHED_STOP;\n}",
        "func": "WORK_STATE tls_finish_handshake(SSL *s, WORK_STATE wst)\n{\n    void (*cb) (const SSL *ssl, int type, int val) = NULL;\n\n#ifndef OPENSSL_NO_SCTP\n    if (SSL_IS_DTLS(s) && BIO_dgram_is_sctp(SSL_get_wbio(s))) {\n        WORK_STATE ret;\n        ret = dtls_wait_for_dry(s);\n        if (ret != WORK_FINISHED_CONTINUE)\n            return ret;\n    }\n#endif\n\n    /* clean a few things up */\n    ssl3_cleanup_key_block(s);\n\n    if (!SSL_IS_DTLS(s)) {\n        /*\n         * We don't do this in DTLS because we may still need the init_buf\n         * in case there are any unexpected retransmits\n         */\n        BUF_MEM_free(s->init_buf);\n        s->init_buf = NULL;\n    }\n\n    ssl_free_wbio_buffer(s);\n\n    s->init_num = 0;\n\n    if (!s->server || s->renegotiate == 2) {\n        /* skipped if we just sent a HelloRequest */\n        s->renegotiate = 0;\n        s->new_session = 0;\n\n        if (s->server) {\n            ssl_update_cache(s, SSL_SESS_CACHE_SERVER);\n\n            s->ctx->stats.sess_accept_good++;\n            s->handshake_func = ossl_statem_accept;\n        } else {\n            ssl_update_cache(s, SSL_SESS_CACHE_CLIENT);\n            if (s->hit)\n                s->ctx->stats.sess_hit++;\n\n            s->handshake_func = ossl_statem_connect;\n            s->ctx->stats.sess_connect_good++;\n        }\n\n        if (s->info_callback != NULL)\n            cb = s->info_callback;\n        else if (s->ctx->info_callback != NULL)\n            cb = s->ctx->info_callback;\n\n        if (cb != NULL)\n            cb(s, SSL_CB_HANDSHAKE_DONE, 1);\n\n        if (SSL_IS_DTLS(s)) {\n            /* done with handshaking */\n            s->d1->handshake_read_seq = 0;\n            s->d1->handshake_write_seq = 0;\n            s->d1->next_handshake_write_seq = 0;\n            dtls1_clear_received_buffer(s);\n        }\n    }\n\n    return WORK_FINISHED_STOP;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -59,6 +59,7 @@\n             s->d1->handshake_read_seq = 0;\n             s->d1->handshake_write_seq = 0;\n             s->d1->next_handshake_write_seq = 0;\n+            dtls1_clear_received_buffer(s);\n         }\n     }\n ",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "            dtls1_clear_received_buffer(s);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-5426",
        "func_name": "PowerDNS/pdns/chopOff",
        "description": "PowerDNS (aka pdns) Authoritative Server before 3.4.10 allows remote attackers to cause a denial of service (backend CPU consumption) via a long qname.",
        "git_url": "https://github.com/PowerDNS/pdns/commit/881b5b03a590198d03008e4200dd00cc537712f3",
        "commit_title": "Reject qname's wirelength > 255, `chopOff()` handle dot inside labels",
        "commit_text": "",
        "func_before": "bool chopOff(string &domain) \n{\n  if(domain.empty())\n    return false;\n\n  string::size_type fdot=domain.find('.');\n\n  if(fdot==string::npos) \n    domain=\"\";\n  else {\n    string::size_type remain = domain.length() - (fdot + 1);\n    char tmp[remain];\n    memcpy(tmp, domain.c_str()+fdot+1, remain);\n    domain.assign(tmp, remain); // don't dare to do this w/o tmp holder :-)\n  }\n  return true;\n}",
        "func": "bool chopOff(string &domain) \n{\n  if(domain.empty())\n    return false;\n\n  bool escaped = false;\n  const string::size_type domainLen = domain.length();\n  for (size_t fdot = 0; fdot < domainLen; fdot++)\n  {\n    if (domain[fdot] == '.' && !escaped) {\n      string::size_type remain = domainLen - (fdot + 1);\n      char tmp[remain];\n      memcpy(tmp, domain.c_str()+fdot+1, remain);\n      domain.assign(tmp, remain); // don't dare to do this w/o tmp holder :-)\n\n      return true;\n    }\n    else if (domain[fdot] == '\\\\' && !escaped) {\n      escaped = true;\n    }\n    else {\n      escaped = false;\n    }\n  }\n\n  domain = \"\";\n  return true;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,15 +3,26 @@\n   if(domain.empty())\n     return false;\n \n-  string::size_type fdot=domain.find('.');\n+  bool escaped = false;\n+  const string::size_type domainLen = domain.length();\n+  for (size_t fdot = 0; fdot < domainLen; fdot++)\n+  {\n+    if (domain[fdot] == '.' && !escaped) {\n+      string::size_type remain = domainLen - (fdot + 1);\n+      char tmp[remain];\n+      memcpy(tmp, domain.c_str()+fdot+1, remain);\n+      domain.assign(tmp, remain); // don't dare to do this w/o tmp holder :-)\n \n-  if(fdot==string::npos) \n-    domain=\"\";\n-  else {\n-    string::size_type remain = domain.length() - (fdot + 1);\n-    char tmp[remain];\n-    memcpy(tmp, domain.c_str()+fdot+1, remain);\n-    domain.assign(tmp, remain); // don't dare to do this w/o tmp holder :-)\n+      return true;\n+    }\n+    else if (domain[fdot] == '\\\\' && !escaped) {\n+      escaped = true;\n+    }\n+    else {\n+      escaped = false;\n+    }\n   }\n+\n+  domain = \"\";\n   return true;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "  string::size_type fdot=domain.find('.');",
                "  if(fdot==string::npos) ",
                "    domain=\"\";",
                "  else {",
                "    string::size_type remain = domain.length() - (fdot + 1);",
                "    char tmp[remain];",
                "    memcpy(tmp, domain.c_str()+fdot+1, remain);",
                "    domain.assign(tmp, remain); // don't dare to do this w/o tmp holder :-)"
            ],
            "added_lines": [
                "  bool escaped = false;",
                "  const string::size_type domainLen = domain.length();",
                "  for (size_t fdot = 0; fdot < domainLen; fdot++)",
                "  {",
                "    if (domain[fdot] == '.' && !escaped) {",
                "      string::size_type remain = domainLen - (fdot + 1);",
                "      char tmp[remain];",
                "      memcpy(tmp, domain.c_str()+fdot+1, remain);",
                "      domain.assign(tmp, remain); // don't dare to do this w/o tmp holder :-)",
                "      return true;",
                "    }",
                "    else if (domain[fdot] == '\\\\' && !escaped) {",
                "      escaped = true;",
                "    }",
                "    else {",
                "      escaped = false;",
                "    }",
                "",
                "  domain = \"\";"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-5426",
        "func_name": "PowerDNS/pdns/chopOffDotted",
        "description": "PowerDNS (aka pdns) Authoritative Server before 3.4.10 allows remote attackers to cause a denial of service (backend CPU consumption) via a long qname.",
        "git_url": "https://github.com/PowerDNS/pdns/commit/881b5b03a590198d03008e4200dd00cc537712f3",
        "commit_title": "Reject qname's wirelength > 255, `chopOff()` handle dot inside labels",
        "commit_text": "",
        "func_before": "bool chopOffDotted(string &domain)\n{\n  if(domain.empty() || (domain.size()==1 && domain[0]=='.'))\n    return false;\n\n  string::size_type fdot=domain.find('.');\n  if(fdot == string::npos)\n    return false;\n\n  if(fdot==domain.size()-1) \n    domain=\".\";\n  else  {\n    string::size_type remain = domain.length() - (fdot + 1);\n    char tmp[remain];\n    memcpy(tmp, domain.c_str()+fdot+1, remain);\n    domain.assign(tmp, remain);\n  }\n  return true;\n}",
        "func": "bool chopOffDotted(string &domain)\n{\n  if(domain.empty() || (domain.size()==1 && domain[0]=='.'))\n    return false;\n\n  bool escaped = false;\n  const string::size_type domainLen = domain.length();\n  for (size_t fdot = 0; fdot < domainLen; fdot++)\n  {\n    if (domain[fdot] == '.' && !escaped) {\n      if (fdot==domain.size()-1) {\n        domain=\".\";\n      }\n      else {\n        string::size_type remain = domainLen - (fdot + 1);\n        char tmp[remain];\n        memcpy(tmp, domain.c_str()+fdot+1, remain);\n        domain.assign(tmp, remain); // don't dare to do this w/o tmp holder :-)\n      }\n      return true;\n    }\n    else if (domain[fdot] == '\\\\' && !escaped) {\n      escaped = true;\n    }\n    else {\n      escaped = false;\n    }\n  }\n\n  return false;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,17 +3,29 @@\n   if(domain.empty() || (domain.size()==1 && domain[0]=='.'))\n     return false;\n \n-  string::size_type fdot=domain.find('.');\n-  if(fdot == string::npos)\n-    return false;\n+  bool escaped = false;\n+  const string::size_type domainLen = domain.length();\n+  for (size_t fdot = 0; fdot < domainLen; fdot++)\n+  {\n+    if (domain[fdot] == '.' && !escaped) {\n+      if (fdot==domain.size()-1) {\n+        domain=\".\";\n+      }\n+      else {\n+        string::size_type remain = domainLen - (fdot + 1);\n+        char tmp[remain];\n+        memcpy(tmp, domain.c_str()+fdot+1, remain);\n+        domain.assign(tmp, remain); // don't dare to do this w/o tmp holder :-)\n+      }\n+      return true;\n+    }\n+    else if (domain[fdot] == '\\\\' && !escaped) {\n+      escaped = true;\n+    }\n+    else {\n+      escaped = false;\n+    }\n+  }\n \n-  if(fdot==domain.size()-1) \n-    domain=\".\";\n-  else  {\n-    string::size_type remain = domain.length() - (fdot + 1);\n-    char tmp[remain];\n-    memcpy(tmp, domain.c_str()+fdot+1, remain);\n-    domain.assign(tmp, remain);\n-  }\n-  return true;\n+  return false;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "  string::size_type fdot=domain.find('.');",
                "  if(fdot == string::npos)",
                "    return false;",
                "  if(fdot==domain.size()-1) ",
                "    domain=\".\";",
                "  else  {",
                "    string::size_type remain = domain.length() - (fdot + 1);",
                "    char tmp[remain];",
                "    memcpy(tmp, domain.c_str()+fdot+1, remain);",
                "    domain.assign(tmp, remain);",
                "  }",
                "  return true;"
            ],
            "added_lines": [
                "  bool escaped = false;",
                "  const string::size_type domainLen = domain.length();",
                "  for (size_t fdot = 0; fdot < domainLen; fdot++)",
                "  {",
                "    if (domain[fdot] == '.' && !escaped) {",
                "      if (fdot==domain.size()-1) {",
                "        domain=\".\";",
                "      }",
                "      else {",
                "        string::size_type remain = domainLen - (fdot + 1);",
                "        char tmp[remain];",
                "        memcpy(tmp, domain.c_str()+fdot+1, remain);",
                "        domain.assign(tmp, remain); // don't dare to do this w/o tmp holder :-)",
                "      }",
                "      return true;",
                "    }",
                "    else if (domain[fdot] == '\\\\' && !escaped) {",
                "      escaped = true;",
                "    }",
                "    else {",
                "      escaped = false;",
                "    }",
                "  }",
                "  return false;"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-5426",
        "func_name": "PowerDNS/pdns/PacketReader::getLabel",
        "description": "PowerDNS (aka pdns) Authoritative Server before 3.4.10 allows remote attackers to cause a denial of service (backend CPU consumption) via a long qname.",
        "git_url": "https://github.com/PowerDNS/pdns/commit/881b5b03a590198d03008e4200dd00cc537712f3",
        "commit_title": "Reject qname's wirelength > 255, `chopOff()` handle dot inside labels",
        "commit_text": "",
        "func_before": "string PacketReader::getLabel(unsigned int recurs)\n{\n  string ret;\n  ret.reserve(40);\n  getLabelFromContent(d_content, d_pos, ret, recurs++);\n  return ret;\n}",
        "func": "string PacketReader::getLabel(unsigned int recurs)\n{\n  string ret;\n  size_t wirelength = 0;\n  ret.reserve(40);\n  getLabelFromContent(d_content, d_pos, ret, recurs++, wirelength);\n  return ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,7 +1,8 @@\n string PacketReader::getLabel(unsigned int recurs)\n {\n   string ret;\n+  size_t wirelength = 0;\n   ret.reserve(40);\n-  getLabelFromContent(d_content, d_pos, ret, recurs++);\n+  getLabelFromContent(d_content, d_pos, ret, recurs++, wirelength);\n   return ret;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "  getLabelFromContent(d_content, d_pos, ret, recurs++);"
            ],
            "added_lines": [
                "  size_t wirelength = 0;",
                "  getLabelFromContent(d_content, d_pos, ret, recurs++, wirelength);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-5426",
        "func_name": "PowerDNS/pdns/PacketReader::getLabelFromContent",
        "description": "PowerDNS (aka pdns) Authoritative Server before 3.4.10 allows remote attackers to cause a denial of service (backend CPU consumption) via a long qname.",
        "git_url": "https://github.com/PowerDNS/pdns/commit/881b5b03a590198d03008e4200dd00cc537712f3",
        "commit_title": "Reject qname's wirelength > 255, `chopOff()` handle dot inside labels",
        "commit_text": "",
        "func_before": "void PacketReader::getLabelFromContent(const vector<uint8_t>& content, uint16_t& frompos, string& ret, int recurs) \n{\n  if(recurs > 100) // the forward reference-check below should make this test 100% obsolete\n    throw MOADNSException(\"Loop\");\n\n  int pos = frompos;\n  // it is tempting to call reserve on ret, but it turns out it creates a malloc/free storm in the loop\n  for(;;) {\n    unsigned char labellen=content.at(frompos++);\n\n    if(!labellen) {\n      if(ret.empty())\n              ret.append(1,'.');\n      break;\n    }\n    else if((labellen & 0xc0) == 0xc0) {\n      uint16_t offset=256*(labellen & ~0xc0) + (unsigned int)content.at(frompos++) - sizeof(dnsheader);\n      //        cout<<\"This is an offset, need to go to: \"<<offset<<endl;\n\n      if(offset >= pos)\n        throw MOADNSException(\"forward reference during label decompression\");\n      return getLabelFromContent(content, offset, ret, ++recurs);\n    }\n    else if(labellen > 63) \n      throw MOADNSException(\"Overly long label during label decompression (\"+lexical_cast<string>((unsigned int)labellen)+\")\");\n    else {\n      // XXX FIXME THIS MIGHT BE VERY SLOW!\n\n      for(string::size_type n = 0 ; n < labellen; ++n, frompos++) {\n        if(content.at(frompos)=='.' || content.at(frompos)=='\\\\') {\n          ret.append(1, '\\\\');\n          ret.append(1, content[frompos]);\n        }\n        else if(content.at(frompos)==' ') {\n          ret+=\"\\\\032\";\n        }\n        else \n          ret.append(1, content[frompos]);\n      }\n      ret.append(1,'.');\n    }\n    if (ret.length() > 1024)\n      throw MOADNSException(\"Total name too long\");\n  }\n}",
        "func": "void PacketReader::getLabelFromContent(const vector<uint8_t>& content, uint16_t& frompos, string& ret, int recurs, size_t& wirelength)\n{\n  if(recurs > 100) // the forward reference-check below should make this test 100% obsolete\n    throw MOADNSException(\"Loop\");\n\n  int pos = frompos;\n  // it is tempting to call reserve on ret, but it turns out it creates a malloc/free storm in the loop\n  for(;;) {\n    unsigned char labellen=content.at(frompos++);\n    wirelength++;\n    if (wirelength > 255) {\n      throw MOADNSException(\"Overly long DNS name (\"+lexical_cast<string>(wirelength)+\")\");\n    }\n\n    if(!labellen) {\n      if(ret.empty())\n              ret.append(1,'.');\n      break;\n    }\n    else if((labellen & 0xc0) == 0xc0) {\n      uint16_t offset=256*(labellen & ~0xc0) + (unsigned int)content.at(frompos++) - sizeof(dnsheader);\n      //        cout<<\"This is an offset, need to go to: \"<<offset<<endl;\n\n      if(offset >= pos)\n        throw MOADNSException(\"forward reference during label decompression\");\n      /* the compression pointer does not count into the wire length */\n      return getLabelFromContent(content, offset, ret, ++recurs, --wirelength);\n    }\n    else if(labellen > 63) \n      throw MOADNSException(\"Overly long label during label decompression (\"+lexical_cast<string>((unsigned int)labellen)+\")\");\n    else {\n      if (wirelength + labellen > 255) {\n        throw MOADNSException(\"Overly long DNS name (\"+lexical_cast<string>(wirelength)+\")\");\n      }\n      wirelength += labellen;\n      // XXX FIXME THIS MIGHT BE VERY SLOW!\n      for(string::size_type n = 0 ; n < labellen; ++n, frompos++) {\n        if(content.at(frompos)=='.' || content.at(frompos)=='\\\\') {\n          ret.append(1, '\\\\');\n          ret.append(1, content[frompos]);\n        }\n        else if(content.at(frompos)==' ') {\n          ret+=\"\\\\032\";\n        }\n        else \n          ret.append(1, content[frompos]);\n      }\n      ret.append(1,'.');\n    }\n    if (ret.length() > 1024)\n      throw MOADNSException(\"Total name too long\");\n  }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,4 +1,4 @@\n-void PacketReader::getLabelFromContent(const vector<uint8_t>& content, uint16_t& frompos, string& ret, int recurs) \n+void PacketReader::getLabelFromContent(const vector<uint8_t>& content, uint16_t& frompos, string& ret, int recurs, size_t& wirelength)\n {\n   if(recurs > 100) // the forward reference-check below should make this test 100% obsolete\n     throw MOADNSException(\"Loop\");\n@@ -7,6 +7,10 @@\n   // it is tempting to call reserve on ret, but it turns out it creates a malloc/free storm in the loop\n   for(;;) {\n     unsigned char labellen=content.at(frompos++);\n+    wirelength++;\n+    if (wirelength > 255) {\n+      throw MOADNSException(\"Overly long DNS name (\"+lexical_cast<string>(wirelength)+\")\");\n+    }\n \n     if(!labellen) {\n       if(ret.empty())\n@@ -19,13 +23,17 @@\n \n       if(offset >= pos)\n         throw MOADNSException(\"forward reference during label decompression\");\n-      return getLabelFromContent(content, offset, ret, ++recurs);\n+      /* the compression pointer does not count into the wire length */\n+      return getLabelFromContent(content, offset, ret, ++recurs, --wirelength);\n     }\n     else if(labellen > 63) \n       throw MOADNSException(\"Overly long label during label decompression (\"+lexical_cast<string>((unsigned int)labellen)+\")\");\n     else {\n+      if (wirelength + labellen > 255) {\n+        throw MOADNSException(\"Overly long DNS name (\"+lexical_cast<string>(wirelength)+\")\");\n+      }\n+      wirelength += labellen;\n       // XXX FIXME THIS MIGHT BE VERY SLOW!\n-\n       for(string::size_type n = 0 ; n < labellen; ++n, frompos++) {\n         if(content.at(frompos)=='.' || content.at(frompos)=='\\\\') {\n           ret.append(1, '\\\\');",
        "diff_line_info": {
            "deleted_lines": [
                "void PacketReader::getLabelFromContent(const vector<uint8_t>& content, uint16_t& frompos, string& ret, int recurs) ",
                "      return getLabelFromContent(content, offset, ret, ++recurs);",
                ""
            ],
            "added_lines": [
                "void PacketReader::getLabelFromContent(const vector<uint8_t>& content, uint16_t& frompos, string& ret, int recurs, size_t& wirelength)",
                "    wirelength++;",
                "    if (wirelength > 255) {",
                "      throw MOADNSException(\"Overly long DNS name (\"+lexical_cast<string>(wirelength)+\")\");",
                "    }",
                "      /* the compression pointer does not count into the wire length */",
                "      return getLabelFromContent(content, offset, ret, ++recurs, --wirelength);",
                "      if (wirelength + labellen > 255) {",
                "        throw MOADNSException(\"Overly long DNS name (\"+lexical_cast<string>(wirelength)+\")\");",
                "      }",
                "      wirelength += labellen;"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-7166",
        "func_name": "libarchive/choose_filters",
        "description": "libarchive before 3.2.0 does not limit the number of recursive decompressions, which allows remote attackers to cause a denial of service (memory consumption and application crash) via a crafted gzip file.",
        "git_url": "https://github.com/libarchive/libarchive/commit/6e06b1c89dd0d16f74894eac4cfc1327a06ee4a0",
        "commit_title": "Fix a potential crash issue discovered by Alexander Cherepanov:",
        "commit_text": " It seems bsdtar automatically handles stacked compression. This is a nice feature but it could be problematic when it's completely unlimited.  Most clearly it's illustrated with quines:  $ curl -sRO http://www.maximumcompression.com/selfgz.gz $ (ulimit -v 10000000 && bsdtar -tvf selfgz.gz) bsdtar: Error opening archive: Can't allocate data for gzip decompression  Without ulimit, bsdtar will eat all available memory. This could also be a problem for other applications using libarchive.",
        "func_before": "static int\nchoose_filters(struct archive_read *a)\n{\n\tint number_bidders, i, bid, best_bid;\n\tstruct archive_read_filter_bidder *bidder, *best_bidder;\n\tstruct archive_read_filter *filter;\n\tssize_t avail;\n\tint r;\n\n\tfor (;;) {\n\t\tnumber_bidders = sizeof(a->bidders) / sizeof(a->bidders[0]);\n\n\t\tbest_bid = 0;\n\t\tbest_bidder = NULL;\n\n\t\tbidder = a->bidders;\n\t\tfor (i = 0; i < number_bidders; i++, bidder++) {\n\t\t\tif (bidder->bid != NULL) {\n\t\t\t\tbid = (bidder->bid)(bidder, a->filter);\n\t\t\t\tif (bid > best_bid) {\n\t\t\t\t\tbest_bid = bid;\n\t\t\t\t\tbest_bidder = bidder;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t/* If no bidder, we're done. */\n\t\tif (best_bidder == NULL) {\n\t\t\t/* Verify the filter by asking it for some data. */\n\t\t\t__archive_read_filter_ahead(a->filter, 1, &avail);\n\t\t\tif (avail < 0) {\n\t\t\t\t__archive_read_close_filters(a);\n\t\t\t\t__archive_read_free_filters(a);\n\t\t\t\treturn (ARCHIVE_FATAL);\n\t\t\t}\n\t\t\ta->archive.compression_name = a->filter->name;\n\t\t\ta->archive.compression_code = a->filter->code;\n\t\t\treturn (ARCHIVE_OK);\n\t\t}\n\n\t\tfilter\n\t\t    = (struct archive_read_filter *)calloc(1, sizeof(*filter));\n\t\tif (filter == NULL)\n\t\t\treturn (ARCHIVE_FATAL);\n\t\tfilter->bidder = best_bidder;\n\t\tfilter->archive = a;\n\t\tfilter->upstream = a->filter;\n\t\ta->filter = filter;\n\t\tr = (best_bidder->init)(a->filter);\n\t\tif (r != ARCHIVE_OK) {\n\t\t\t__archive_read_close_filters(a);\n\t\t\t__archive_read_free_filters(a);\n\t\t\treturn (ARCHIVE_FATAL);\n\t\t}\n\t}\n}",
        "func": "static int\nchoose_filters(struct archive_read *a)\n{\n\tint number_bidders, i, bid, best_bid, n;\n\tstruct archive_read_filter_bidder *bidder, *best_bidder;\n\tstruct archive_read_filter *filter;\n\tssize_t avail;\n\tint r;\n\n\tfor (n = 0; n < 25; ++n) {\n\t\tnumber_bidders = sizeof(a->bidders) / sizeof(a->bidders[0]);\n\n\t\tbest_bid = 0;\n\t\tbest_bidder = NULL;\n\n\t\tbidder = a->bidders;\n\t\tfor (i = 0; i < number_bidders; i++, bidder++) {\n\t\t\tif (bidder->bid != NULL) {\n\t\t\t\tbid = (bidder->bid)(bidder, a->filter);\n\t\t\t\tif (bid > best_bid) {\n\t\t\t\t\tbest_bid = bid;\n\t\t\t\t\tbest_bidder = bidder;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t/* If no bidder, we're done. */\n\t\tif (best_bidder == NULL) {\n\t\t\t/* Verify the filter by asking it for some data. */\n\t\t\t__archive_read_filter_ahead(a->filter, 1, &avail);\n\t\t\tif (avail < 0) {\n\t\t\t\t__archive_read_close_filters(a);\n\t\t\t\t__archive_read_free_filters(a);\n\t\t\t\treturn (ARCHIVE_FATAL);\n\t\t\t}\n\t\t\ta->archive.compression_name = a->filter->name;\n\t\t\ta->archive.compression_code = a->filter->code;\n\t\t\treturn (ARCHIVE_OK);\n\t\t}\n\n\t\tfilter\n\t\t    = (struct archive_read_filter *)calloc(1, sizeof(*filter));\n\t\tif (filter == NULL)\n\t\t\treturn (ARCHIVE_FATAL);\n\t\tfilter->bidder = best_bidder;\n\t\tfilter->archive = a;\n\t\tfilter->upstream = a->filter;\n\t\ta->filter = filter;\n\t\tr = (best_bidder->init)(a->filter);\n\t\tif (r != ARCHIVE_OK) {\n\t\t\t__archive_read_close_filters(a);\n\t\t\t__archive_read_free_filters(a);\n\t\t\treturn (ARCHIVE_FATAL);\n\t\t}\n\t}\n\tarchive_set_error(&a->archive, ARCHIVE_ERRNO_FILE_FORMAT,\n\t    \"Input requires too many filters for decoding\");\n\treturn (ARCHIVE_FATAL);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,13 +1,13 @@\n static int\n choose_filters(struct archive_read *a)\n {\n-\tint number_bidders, i, bid, best_bid;\n+\tint number_bidders, i, bid, best_bid, n;\n \tstruct archive_read_filter_bidder *bidder, *best_bidder;\n \tstruct archive_read_filter *filter;\n \tssize_t avail;\n \tint r;\n \n-\tfor (;;) {\n+\tfor (n = 0; n < 25; ++n) {\n \t\tnumber_bidders = sizeof(a->bidders) / sizeof(a->bidders[0]);\n \n \t\tbest_bid = 0;\n@@ -53,4 +53,7 @@\n \t\t\treturn (ARCHIVE_FATAL);\n \t\t}\n \t}\n+\tarchive_set_error(&a->archive, ARCHIVE_ERRNO_FILE_FORMAT,\n+\t    \"Input requires too many filters for decoding\");\n+\treturn (ARCHIVE_FATAL);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tint number_bidders, i, bid, best_bid;",
                "\tfor (;;) {"
            ],
            "added_lines": [
                "\tint number_bidders, i, bid, best_bid, n;",
                "\tfor (n = 0; n < 25; ++n) {",
                "\tarchive_set_error(&a->archive, ARCHIVE_ERRNO_FILE_FORMAT,",
                "\t    \"Input requires too many filters for decoding\");",
                "\treturn (ARCHIVE_FATAL);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-6308",
        "func_name": "openssl/dtls1_preprocess_fragment",
        "description": "statem/statem_dtls.c in the DTLS implementation in OpenSSL 1.1.0 before 1.1.0a allocates memory before checking for an excessive length, which might allow remote attackers to cause a denial of service (memory consumption) via crafted DTLS messages.",
        "git_url": "https://git.openssl.org/?p=openssl.git;a=commit;h=df6b5e29ffea2d5a3e08de92fb765fdb21c7a21e",
        "commit_title": "",
        "commit_text": "Excessive allocation of memory in dtls1_preprocess_fragment()  This issue is very similar to CVE-2016-6307 described in the previous commit. The underlying defect is different but the security analysis and impacts are the same except that it impacts DTLS.  A DTLS message includes 3 bytes for its length in the header for the message. This would allow for messages up to 16Mb in length. Messages of this length are excessive and OpenSSL includes a check to ensure that a peer is sending reasonably sized messages in order to avoid too much memory being consumed to service a connection. A flaw in the logic of version 1.1.0 means that memory for the message is allocated too early, prior to the excessive message length check. Due to way memory is allocated in OpenSSL this could mean an attacker could force up to 21Mb to be allocated to service a connection. This could lead to a Denial of Service through memory exhaustion. However, the excessive message length check still takes place, and this would cause the connection to immediately fail. Assuming that the application calls SSL_free() on the failed conneciton in a timely manner then the 21Mb of allocated memory will then be immediately freed again. Therefore the excessive memory allocation will be transitory in nature. This then means that there is only a security impact if:  1) The application does not call SSL_free() in a timely manner in the event that the connection fails or 2) The application is working in a constrained environment where there is very little free memory or 3) The attacker initiates multiple connection attempts such that there are multiple connections in a state where memory has been allocated for the connection; SSL_free() has not yet been called; and there is insufficient memory to service the multiple requests.  Except in the instance of (1) above any Denial Of Service is likely to be transitory because as soon as the connection fails the memory is subsequently freed again in the SSL_free() call. However there is an increased risk during this period of application crashes due to the lack of memory - which would then mean a more serious Denial of Service.  This issue does not affect TLS users.  Issue was reported by Shi Lei (Gear Team, Qihoo 360 Inc.).  CVE-2016-6308  (cherry picked from commit 48c054fec3506417b2598837b8062aae7114c200) ",
        "func_before": "static int dtls1_preprocess_fragment(SSL *s, struct hm_header_st *msg_hdr)\n{\n    size_t frag_off, frag_len, msg_len;\n\n    msg_len = msg_hdr->msg_len;\n    frag_off = msg_hdr->frag_off;\n    frag_len = msg_hdr->frag_len;\n\n    /* sanity checking */\n    if ((frag_off + frag_len) > msg_len) {\n        SSLerr(SSL_F_DTLS1_PREPROCESS_FRAGMENT, SSL_R_EXCESSIVE_MESSAGE_SIZE);\n        return SSL_AD_ILLEGAL_PARAMETER;\n    }\n\n    if (s->d1->r_msg_hdr.frag_off == 0) { /* first fragment */\n        /*\n         * msg_len is limited to 2^24, but is effectively checked against max\n         * above\n         */\n        if (!BUF_MEM_grow_clean(s->init_buf, msg_len + DTLS1_HM_HEADER_LENGTH)) {\n            SSLerr(SSL_F_DTLS1_PREPROCESS_FRAGMENT, ERR_R_BUF_LIB);\n            return SSL_AD_INTERNAL_ERROR;\n        }\n\n        s->s3->tmp.message_size = msg_len;\n        s->d1->r_msg_hdr.msg_len = msg_len;\n        s->s3->tmp.message_type = msg_hdr->type;\n        s->d1->r_msg_hdr.type = msg_hdr->type;\n        s->d1->r_msg_hdr.seq = msg_hdr->seq;\n    } else if (msg_len != s->d1->r_msg_hdr.msg_len) {\n        /*\n         * They must be playing with us! BTW, failure to enforce upper limit\n         * would open possibility for buffer overrun.\n         */\n        SSLerr(SSL_F_DTLS1_PREPROCESS_FRAGMENT, SSL_R_EXCESSIVE_MESSAGE_SIZE);\n        return SSL_AD_ILLEGAL_PARAMETER;\n    }\n\n    return 0;                   /* no error */\n}",
        "func": "static int dtls1_preprocess_fragment(SSL *s, struct hm_header_st *msg_hdr)\n{\n    size_t frag_off, frag_len, msg_len;\n\n    msg_len = msg_hdr->msg_len;\n    frag_off = msg_hdr->frag_off;\n    frag_len = msg_hdr->frag_len;\n\n    /* sanity checking */\n    if ((frag_off + frag_len) > msg_len\n            || msg_len > dtls1_max_handshake_message_len(s)) {\n        SSLerr(SSL_F_DTLS1_PREPROCESS_FRAGMENT, SSL_R_EXCESSIVE_MESSAGE_SIZE);\n        return SSL_AD_ILLEGAL_PARAMETER;\n    }\n\n    if (s->d1->r_msg_hdr.frag_off == 0) { /* first fragment */\n        /*\n         * msg_len is limited to 2^24, but is effectively checked against\n         * dtls_max_handshake_message_len(s) above\n         */\n        if (!BUF_MEM_grow_clean(s->init_buf, msg_len + DTLS1_HM_HEADER_LENGTH)) {\n            SSLerr(SSL_F_DTLS1_PREPROCESS_FRAGMENT, ERR_R_BUF_LIB);\n            return SSL_AD_INTERNAL_ERROR;\n        }\n\n        s->s3->tmp.message_size = msg_len;\n        s->d1->r_msg_hdr.msg_len = msg_len;\n        s->s3->tmp.message_type = msg_hdr->type;\n        s->d1->r_msg_hdr.type = msg_hdr->type;\n        s->d1->r_msg_hdr.seq = msg_hdr->seq;\n    } else if (msg_len != s->d1->r_msg_hdr.msg_len) {\n        /*\n         * They must be playing with us! BTW, failure to enforce upper limit\n         * would open possibility for buffer overrun.\n         */\n        SSLerr(SSL_F_DTLS1_PREPROCESS_FRAGMENT, SSL_R_EXCESSIVE_MESSAGE_SIZE);\n        return SSL_AD_ILLEGAL_PARAMETER;\n    }\n\n    return 0;                   /* no error */\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -7,15 +7,16 @@\n     frag_len = msg_hdr->frag_len;\n \n     /* sanity checking */\n-    if ((frag_off + frag_len) > msg_len) {\n+    if ((frag_off + frag_len) > msg_len\n+            || msg_len > dtls1_max_handshake_message_len(s)) {\n         SSLerr(SSL_F_DTLS1_PREPROCESS_FRAGMENT, SSL_R_EXCESSIVE_MESSAGE_SIZE);\n         return SSL_AD_ILLEGAL_PARAMETER;\n     }\n \n     if (s->d1->r_msg_hdr.frag_off == 0) { /* first fragment */\n         /*\n-         * msg_len is limited to 2^24, but is effectively checked against max\n-         * above\n+         * msg_len is limited to 2^24, but is effectively checked against\n+         * dtls_max_handshake_message_len(s) above\n          */\n         if (!BUF_MEM_grow_clean(s->init_buf, msg_len + DTLS1_HM_HEADER_LENGTH)) {\n             SSLerr(SSL_F_DTLS1_PREPROCESS_FRAGMENT, ERR_R_BUF_LIB);",
        "diff_line_info": {
            "deleted_lines": [
                "    if ((frag_off + frag_len) > msg_len) {",
                "         * msg_len is limited to 2^24, but is effectively checked against max",
                "         * above"
            ],
            "added_lines": [
                "    if ((frag_off + frag_len) > msg_len",
                "            || msg_len > dtls1_max_handshake_message_len(s)) {",
                "         * msg_len is limited to 2^24, but is effectively checked against",
                "         * dtls_max_handshake_message_len(s) above"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-8953",
        "func_name": "torvalds/linux/ovl_copy_up_locked",
        "description": "fs/overlayfs/copy_up.c in the Linux kernel before 4.2.6 uses an incorrect cleanup code path, which allows local users to cause a denial of service (dentry reference leak) via filesystem operations on a large file in a lower overlayfs layer.",
        "git_url": "https://github.com/torvalds/linux/commit/ab79efab0a0ba01a74df782eb7fa44b044dae8b5",
        "commit_title": "ovl: fix dentry reference leak",
        "commit_text": " In ovl_copy_up_locked(), newdentry is leaked if the function exits through out_cleanup as this just to out after calling ovl_cleanup() - which doesn't actually release the ref on newdentry.  The out_cleanup segment should instead exit through out2 as certainly newdentry leaks - and possibly upper does also, though this isn't caught given the catch of newdentry.  Without this fix, something like the following is seen:  \tBUG: Dentry ffff880023e9eb20{i=f861,n=#ffff880023e82d90} still in use (1) [unmount of tmpfs tmpfs] \tBUG: Dentry ffff880023ece640{i=0,n=bigfile}  still in use (1) [unmount of tmpfs tmpfs]  when unmounting the upper layer after an error occurred in copyup.  An error can be induced by creating a big file in a lower layer with something like:  \tdd if=/dev/zero of=/lower/a/bigfile bs=65536 count=1 seek=$((0xf000))  to create a large file (4.1G).  Overlay an upper layer that is too small (on tmpfs might do) and then induce a copy up by opening it writably.  Cc: <stable@vger.kernel.org> # v3.18+",
        "func_before": "static int ovl_copy_up_locked(struct dentry *workdir, struct dentry *upperdir,\n\t\t\t      struct dentry *dentry, struct path *lowerpath,\n\t\t\t      struct kstat *stat, struct iattr *attr,\n\t\t\t      const char *link)\n{\n\tstruct inode *wdir = workdir->d_inode;\n\tstruct inode *udir = upperdir->d_inode;\n\tstruct dentry *newdentry = NULL;\n\tstruct dentry *upper = NULL;\n\tumode_t mode = stat->mode;\n\tint err;\n\n\tnewdentry = ovl_lookup_temp(workdir, dentry);\n\terr = PTR_ERR(newdentry);\n\tif (IS_ERR(newdentry))\n\t\tgoto out;\n\n\tupper = lookup_one_len(dentry->d_name.name, upperdir,\n\t\t\t       dentry->d_name.len);\n\terr = PTR_ERR(upper);\n\tif (IS_ERR(upper))\n\t\tgoto out1;\n\n\t/* Can't properly set mode on creation because of the umask */\n\tstat->mode &= S_IFMT;\n\terr = ovl_create_real(wdir, newdentry, stat, link, NULL, true);\n\tstat->mode = mode;\n\tif (err)\n\t\tgoto out2;\n\n\tif (S_ISREG(stat->mode)) {\n\t\tstruct path upperpath;\n\t\tovl_path_upper(dentry, &upperpath);\n\t\tBUG_ON(upperpath.dentry != NULL);\n\t\tupperpath.dentry = newdentry;\n\n\t\terr = ovl_copy_up_data(lowerpath, &upperpath, stat->size);\n\t\tif (err)\n\t\t\tgoto out_cleanup;\n\t}\n\n\terr = ovl_copy_xattr(lowerpath->dentry, newdentry);\n\tif (err)\n\t\tgoto out_cleanup;\n\n\tmutex_lock(&newdentry->d_inode->i_mutex);\n\terr = ovl_set_attr(newdentry, stat);\n\tif (!err && attr)\n\t\terr = notify_change(newdentry, attr, NULL);\n\tmutex_unlock(&newdentry->d_inode->i_mutex);\n\tif (err)\n\t\tgoto out_cleanup;\n\n\terr = ovl_do_rename(wdir, newdentry, udir, upper, 0);\n\tif (err)\n\t\tgoto out_cleanup;\n\n\tovl_dentry_update(dentry, newdentry);\n\tnewdentry = NULL;\n\n\t/*\n\t * Non-directores become opaque when copied up.\n\t */\n\tif (!S_ISDIR(stat->mode))\n\t\tovl_dentry_set_opaque(dentry, true);\nout2:\n\tdput(upper);\nout1:\n\tdput(newdentry);\nout:\n\treturn err;\n\nout_cleanup:\n\tovl_cleanup(wdir, newdentry);\n\tgoto out;\n}",
        "func": "static int ovl_copy_up_locked(struct dentry *workdir, struct dentry *upperdir,\n\t\t\t      struct dentry *dentry, struct path *lowerpath,\n\t\t\t      struct kstat *stat, struct iattr *attr,\n\t\t\t      const char *link)\n{\n\tstruct inode *wdir = workdir->d_inode;\n\tstruct inode *udir = upperdir->d_inode;\n\tstruct dentry *newdentry = NULL;\n\tstruct dentry *upper = NULL;\n\tumode_t mode = stat->mode;\n\tint err;\n\n\tnewdentry = ovl_lookup_temp(workdir, dentry);\n\terr = PTR_ERR(newdentry);\n\tif (IS_ERR(newdentry))\n\t\tgoto out;\n\n\tupper = lookup_one_len(dentry->d_name.name, upperdir,\n\t\t\t       dentry->d_name.len);\n\terr = PTR_ERR(upper);\n\tif (IS_ERR(upper))\n\t\tgoto out1;\n\n\t/* Can't properly set mode on creation because of the umask */\n\tstat->mode &= S_IFMT;\n\terr = ovl_create_real(wdir, newdentry, stat, link, NULL, true);\n\tstat->mode = mode;\n\tif (err)\n\t\tgoto out2;\n\n\tif (S_ISREG(stat->mode)) {\n\t\tstruct path upperpath;\n\t\tovl_path_upper(dentry, &upperpath);\n\t\tBUG_ON(upperpath.dentry != NULL);\n\t\tupperpath.dentry = newdentry;\n\n\t\terr = ovl_copy_up_data(lowerpath, &upperpath, stat->size);\n\t\tif (err)\n\t\t\tgoto out_cleanup;\n\t}\n\n\terr = ovl_copy_xattr(lowerpath->dentry, newdentry);\n\tif (err)\n\t\tgoto out_cleanup;\n\n\tmutex_lock(&newdentry->d_inode->i_mutex);\n\terr = ovl_set_attr(newdentry, stat);\n\tif (!err && attr)\n\t\terr = notify_change(newdentry, attr, NULL);\n\tmutex_unlock(&newdentry->d_inode->i_mutex);\n\tif (err)\n\t\tgoto out_cleanup;\n\n\terr = ovl_do_rename(wdir, newdentry, udir, upper, 0);\n\tif (err)\n\t\tgoto out_cleanup;\n\n\tovl_dentry_update(dentry, newdentry);\n\tnewdentry = NULL;\n\n\t/*\n\t * Non-directores become opaque when copied up.\n\t */\n\tif (!S_ISDIR(stat->mode))\n\t\tovl_dentry_set_opaque(dentry, true);\nout2:\n\tdput(upper);\nout1:\n\tdput(newdentry);\nout:\n\treturn err;\n\nout_cleanup:\n\tovl_cleanup(wdir, newdentry);\n\tgoto out2;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -72,5 +72,5 @@\n \n out_cleanup:\n \tovl_cleanup(wdir, newdentry);\n-\tgoto out;\n+\tgoto out2;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tgoto out;"
            ],
            "added_lines": [
                "\tgoto out2;"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-9372",
        "func_name": "wireshark/init_pn_io_rtc1",
        "description": "In Wireshark 2.2.0 to 2.2.1, the Profinet I/O dissector could loop excessively, triggered by network traffic or a capture file. This was addressed in plugins/profinet/packet-pn-rtc-one.c by rejecting input with too many I/O objects.",
        "git_url": "https://github.com/wireshark/wireshark/commit/4127e3930ef663114567002001f44e01eba8a250",
        "commit_title": "Profinet I/O: Sanity check number of I/O objects",
        "commit_text": " Can prevent really long loops from fuzz testing.  Bug: 12851 (cherry picked from commit e8022a9c7b36b96578a30fc8132def6de8928606)",
        "func_before": "void\ninit_pn_io_rtc1(int proto)\n{\n    static hf_register_info hf[] = {\n        { &hf_pn_io_io_data_object,\n            { \"IODataObject\", \"pn_io.io_data_object\",\n            FT_NONE, BASE_NONE, NULL, 0x0,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_io_data_object_info_module_diff,\n            { \"Difference\", \"pn_io.io_data_object.diff_module\",\n            FT_NONE, BASE_NONE, NULL, 0x0,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_io_data_object_info_moduleidentnumber,\n            { \"ModuleIdentNumber\", \"pn_io.io_data_object.module_nr\",\n            FT_UINT32, BASE_HEX, NULL, 0x0,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_io_data_object_info_submoduleidentnumber,\n            { \"SubmoduleIdentNumber\", \"pn_io.io_data_object.submodule_nr\",\n            FT_UINT32, BASE_HEX, NULL, 0x0,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_frame_info_type,\n            { \"PN Frame Type\", \"pn_io.frame_info.type\",\n            FT_STRING, BASE_NONE, NULL, 0x0,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_frame_info_vendor,\n            { \"DeviceVendorValue\", \"pn_io.frame_info.vendor\",\n            FT_STRING, BASE_NONE, NULL, 0x0,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_frame_info_nameofstation,\n            { \"NameOfStation\", \"pn_io.frame_info.nameofstation\",\n            FT_STRING, BASE_NONE, NULL, 0x0,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_frame_info_gsd_found,\n            { \"GSD-file found\", \"pn_io.frame_info.gsd_found\",\n            FT_NONE, BASE_NONE, NULL, 0x0,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_frame_info_gsd_error,\n            { \"GSD-file not found.\", \"pn_io.frame_info.gsd_error\",\n            FT_NONE, BASE_NONE, NULL, 0x0,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_frame_info_gsd_path,\n            { \"GSD-file networkpath failure!\", \"pn_io.frame_info.gsd_path\",\n            FT_NONE, BASE_NONE, NULL, 0x0,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_iocs,\n            { \"IOCS\", \"pn_io.ioxs\",\n            FT_UINT8, BASE_HEX, NULL, 0x0,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_iops,\n            { \"IOPS\", \"pn_io.ioxs\",\n            FT_UINT8, BASE_HEX, NULL, 0x0,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_ioxs_extension,\n            { \"Extension\", \"pn_io.ioxs.extension\",\n            FT_UINT8, BASE_HEX, VALS(pn_io_ioxs_extension), 0x01,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_ioxs_res14,\n            { \"Reserved\", \"pn_io.ioxs.res14\",\n            FT_UINT8, BASE_HEX, NULL, 0x1E,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_ioxs_instance,\n            { \"Instance\", \"pn_io.ioxs.instance\",\n            FT_UINT8, BASE_HEX, VALS(pn_io_ioxs_instance), 0x60,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_ioxs_datastate,\n            { \"DataState\", \"pn_io.ioxs.datastate\",\n            FT_UINT8, BASE_HEX, VALS(pn_io_ioxs_datastate), 0x80,\n            NULL, HFILL }\n        },\n        /* PROFIsafe parameter */\n        /* Status Byte & Control Byte for PROFIsafe --- dissector handle */\n        { &hf_pn_io_ps_sb,\n            { \"Status Byte\", \"pn_io.ps.sb\",\n            FT_UINT8, BASE_HEX, NULL, 0x0,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_ps_sb_toggelBitChanged,\n            { \"Status Byte\", \"pn_io.ps.sb.toggle_d_changed\",\n            FT_UINT8, BASE_HEX, NULL, 0x00,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_ps_sb_toggelBitChange_slot_nr,\n            { \"Slot_Number\", \"pn_io.ps.sb.toggle_d_changed.slot\",\n            FT_UINT16, BASE_HEX, NULL, 0x0,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_ps_sb_toggelBitChange_subslot_nr,\n            { \"Sub_Slot_Number\", \"pn_io.ps.sb.toggle_d_changed.subslot\",\n            FT_UINT16, BASE_HEX, NULL, 0x0,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_ps_cb,\n            { \"Control Byte\", \"pn_io.ps.cb\",\n            FT_UINT8, BASE_HEX, NULL, 0x0,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_ps_cb_toggelBitChanged,\n            { \"Control Byte\", \"pn_io.ps.cb.toggle_h_changed\",\n            FT_UINT8, BASE_HEX, NULL, 0x00,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_ps_cb_toggelBitChange_slot_nr,\n            { \"Slot_Number\", \"pn_io.ps.cb.toggle_h_changed.slot\",\n            FT_UINT16, BASE_HEX, NULL, 0x0,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_ps_cb_toggelBitChange_subslot_nr,\n            { \"Sub_Slot_Number\", \"pn_io.ps.cb.toggle_h_changed.subslot\",\n            FT_UINT16, BASE_HEX, NULL, 0x0,\n            NULL, HFILL }\n        },\n        /* Structures for dissecting Status Byte & Control Byte PROFIsafe ---dissector details */\n        { &hf_pn_io_ps_sb_iparOK,\n            { \"iPar_OK - F-Device has new iParameter values assigned\", \"pn_io.ps.sb.iPar_OK\",\n            FT_UINT8, BASE_HEX, NULL, 0x01,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_ps_sb_DeviceFault,\n            { \"Device_Fault - Failure exists in F-Device or F-Module\", \"pn_io.ps.sb.DeviceFault\",\n            FT_UINT8, BASE_HEX, NULL, 0x02,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_ps_sb_CECRC,\n            { \"CE_CRC - CRC Communication fault\", \"pn_io.ps.sb.CE_CRC\",\n            FT_UINT8, BASE_HEX, NULL, 0x04,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_ps_sb_WDtimeout,\n            { \"WD_timeout - WatchDog timeout Communication fault\", \"pn_io.ps.sb.WD_timeout\",\n            FT_UINT8, BASE_HEX, NULL, 0x08,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_ps_sb_FVactivated,\n            { \"FV_activated - Fail-safe values (FV) activated\", \"pn_io.ps.sb.FV_activated\",\n            FT_UINT8, BASE_HEX, NULL, 0x10,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_ps_sb_Toggle_d,\n            { \"Toggle_d - Device-based Toggle Bit\", \"pn_io.ps.sb.Toggle_d\",\n            FT_UINT8, BASE_HEX, NULL, 0x20,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_ps_sb_ConsNr_reset,\n            { \"cons_nr_R - F-Device has reset its consecutive number counter\", \"pn_io.ps.sb.cons_nr_R\",\n            FT_UINT8, BASE_HEX, NULL, 0x40,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_ps_sb_res,\n            { \"Bit7 - reserved for future releases\", \"pn_io.ps.sb.bit7\",\n            FT_UINT8, BASE_HEX, NULL, 0x80,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_ps_cb_iparEN,\n            { \"iPar_EN - iParameter assignment deblocked\", \"pn_io.ps.cb.iparEN\",\n            FT_UINT8, BASE_HEX, NULL, 0x01,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_ps_cb_OAReq,\n            { \"OA_Req - Operator acknowledge requested\", \"pn_io.ps.cb.OA_Req\",\n            FT_UINT8, BASE_HEX, NULL, 0x02,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_ps_cb_resetConsNr,\n            { \"R_cons_nr - Set the Virtual Consecutive Number within the F-Device to be \\\"0\\\"\", \"pn_io.ps.cb.R_cons_nr\",\n            FT_UINT8, BASE_HEX, NULL, 0x04,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_ps_cb_useTO2,\n            { \"Bit3 - Reserved or Use the secondary watchdog (Use_TO2)\", \"pn_io.ps.cb.bit3\",\n            FT_UINT8, BASE_HEX, NULL, 0x08,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_ps_cb_activateFV,\n            { \"activate_FV - Fail-safe values (FV) to be activated\", \"pn_io.ps.cb.activate_FV\",\n            FT_UINT8, BASE_HEX, NULL, 0x10,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_ps_cb_Toggle_h,\n            { \"Toggle_h - Host-based Toggle Bit\", \"pn_io.ps.cb.Toggle_h\",\n            FT_UINT8, BASE_HEX, NULL, 0x20,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_ps_cb_Chf_ACK,\n            { \"Bit6 - Reserved or Operator acknowledge after cleared channel fault (ChF_Ack)\", \"pn_io.ps.cb.bit6\",\n            FT_UINT8, BASE_HEX, NULL, 0x40,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_ps_cb_loopcheck,\n            { \"Bit7 - Reserved or Loop-back check (Loopcheck, shall be set to 1)\", \"pn_io.ps.cb.bit7\",\n            FT_UINT8, BASE_HEX, NULL, 0x80,\n            NULL, HFILL }\n        },\n        /* PROFIsafe */\n        { &hf_pn_io_ps_f_dest_adr,\n            { \"F_Dest_Add\", \"pn_io.ps.f_dest_add\",\n            FT_UINT16, BASE_DEC, NULL, 0x0,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_ps_f_data,\n            { \"SafetyIO Data\", \"pn_io.ps.f_data\",\n            FT_UINT64, BASE_HEX, NULL, 0x0,\n            NULL, HFILL }\n        },\n    };\n\n    static gint *ett[] = {\n        &ett_pn_io_rtc,\n        &ett_pn_io_ioxs,\n        &ett_pn_io_io_data_object\n    };\n\n    proto_pn_io_rtc1 = proto;\n    proto_register_field_array(proto, hf, array_length(hf));\n    proto_register_subtree_array(ett, array_length(ett));\n}",
        "func": "void\ninit_pn_io_rtc1(int proto)\n{\n    static hf_register_info hf[] = {\n        { &hf_pn_io_io_data_object,\n            { \"IODataObject\", \"pn_io.io_data_object\",\n            FT_NONE, BASE_NONE, NULL, 0x0,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_io_data_object_info_module_diff,\n            { \"Difference\", \"pn_io.io_data_object.diff_module\",\n            FT_NONE, BASE_NONE, NULL, 0x0,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_io_data_object_info_moduleidentnumber,\n            { \"ModuleIdentNumber\", \"pn_io.io_data_object.module_nr\",\n            FT_UINT32, BASE_HEX, NULL, 0x0,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_io_data_object_info_submoduleidentnumber,\n            { \"SubmoduleIdentNumber\", \"pn_io.io_data_object.submodule_nr\",\n            FT_UINT32, BASE_HEX, NULL, 0x0,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_frame_info_type,\n            { \"PN Frame Type\", \"pn_io.frame_info.type\",\n            FT_STRING, BASE_NONE, NULL, 0x0,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_frame_info_vendor,\n            { \"DeviceVendorValue\", \"pn_io.frame_info.vendor\",\n            FT_STRING, BASE_NONE, NULL, 0x0,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_frame_info_nameofstation,\n            { \"NameOfStation\", \"pn_io.frame_info.nameofstation\",\n            FT_STRING, BASE_NONE, NULL, 0x0,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_frame_info_gsd_found,\n            { \"GSD-file found\", \"pn_io.frame_info.gsd_found\",\n            FT_NONE, BASE_NONE, NULL, 0x0,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_frame_info_gsd_error,\n            { \"GSD-file not found.\", \"pn_io.frame_info.gsd_error\",\n            FT_NONE, BASE_NONE, NULL, 0x0,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_frame_info_gsd_path,\n            { \"GSD-file networkpath failure!\", \"pn_io.frame_info.gsd_path\",\n            FT_NONE, BASE_NONE, NULL, 0x0,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_iocs,\n            { \"IOCS\", \"pn_io.ioxs\",\n            FT_UINT8, BASE_HEX, NULL, 0x0,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_iops,\n            { \"IOPS\", \"pn_io.ioxs\",\n            FT_UINT8, BASE_HEX, NULL, 0x0,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_ioxs_extension,\n            { \"Extension\", \"pn_io.ioxs.extension\",\n            FT_UINT8, BASE_HEX, VALS(pn_io_ioxs_extension), 0x01,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_ioxs_res14,\n            { \"Reserved\", \"pn_io.ioxs.res14\",\n            FT_UINT8, BASE_HEX, NULL, 0x1E,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_ioxs_instance,\n            { \"Instance\", \"pn_io.ioxs.instance\",\n            FT_UINT8, BASE_HEX, VALS(pn_io_ioxs_instance), 0x60,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_ioxs_datastate,\n            { \"DataState\", \"pn_io.ioxs.datastate\",\n            FT_UINT8, BASE_HEX, VALS(pn_io_ioxs_datastate), 0x80,\n            NULL, HFILL }\n        },\n        /* PROFIsafe parameter */\n        /* Status Byte & Control Byte for PROFIsafe --- dissector handle */\n        { &hf_pn_io_ps_sb,\n            { \"Status Byte\", \"pn_io.ps.sb\",\n            FT_UINT8, BASE_HEX, NULL, 0x0,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_ps_sb_toggelBitChanged,\n            { \"Status Byte\", \"pn_io.ps.sb.toggle_d_changed\",\n            FT_UINT8, BASE_HEX, NULL, 0x00,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_ps_sb_toggelBitChange_slot_nr,\n            { \"Slot_Number\", \"pn_io.ps.sb.toggle_d_changed.slot\",\n            FT_UINT16, BASE_HEX, NULL, 0x0,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_ps_sb_toggelBitChange_subslot_nr,\n            { \"Sub_Slot_Number\", \"pn_io.ps.sb.toggle_d_changed.subslot\",\n            FT_UINT16, BASE_HEX, NULL, 0x0,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_ps_cb,\n            { \"Control Byte\", \"pn_io.ps.cb\",\n            FT_UINT8, BASE_HEX, NULL, 0x0,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_ps_cb_toggelBitChanged,\n            { \"Control Byte\", \"pn_io.ps.cb.toggle_h_changed\",\n            FT_UINT8, BASE_HEX, NULL, 0x00,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_ps_cb_toggelBitChange_slot_nr,\n            { \"Slot_Number\", \"pn_io.ps.cb.toggle_h_changed.slot\",\n            FT_UINT16, BASE_HEX, NULL, 0x0,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_ps_cb_toggelBitChange_subslot_nr,\n            { \"Sub_Slot_Number\", \"pn_io.ps.cb.toggle_h_changed.subslot\",\n            FT_UINT16, BASE_HEX, NULL, 0x0,\n            NULL, HFILL }\n        },\n        /* Structures for dissecting Status Byte & Control Byte PROFIsafe ---dissector details */\n        { &hf_pn_io_ps_sb_iparOK,\n            { \"iPar_OK - F-Device has new iParameter values assigned\", \"pn_io.ps.sb.iPar_OK\",\n            FT_UINT8, BASE_HEX, NULL, 0x01,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_ps_sb_DeviceFault,\n            { \"Device_Fault - Failure exists in F-Device or F-Module\", \"pn_io.ps.sb.DeviceFault\",\n            FT_UINT8, BASE_HEX, NULL, 0x02,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_ps_sb_CECRC,\n            { \"CE_CRC - CRC Communication fault\", \"pn_io.ps.sb.CE_CRC\",\n            FT_UINT8, BASE_HEX, NULL, 0x04,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_ps_sb_WDtimeout,\n            { \"WD_timeout - WatchDog timeout Communication fault\", \"pn_io.ps.sb.WD_timeout\",\n            FT_UINT8, BASE_HEX, NULL, 0x08,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_ps_sb_FVactivated,\n            { \"FV_activated - Fail-safe values (FV) activated\", \"pn_io.ps.sb.FV_activated\",\n            FT_UINT8, BASE_HEX, NULL, 0x10,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_ps_sb_Toggle_d,\n            { \"Toggle_d - Device-based Toggle Bit\", \"pn_io.ps.sb.Toggle_d\",\n            FT_UINT8, BASE_HEX, NULL, 0x20,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_ps_sb_ConsNr_reset,\n            { \"cons_nr_R - F-Device has reset its consecutive number counter\", \"pn_io.ps.sb.cons_nr_R\",\n            FT_UINT8, BASE_HEX, NULL, 0x40,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_ps_sb_res,\n            { \"Bit7 - reserved for future releases\", \"pn_io.ps.sb.bit7\",\n            FT_UINT8, BASE_HEX, NULL, 0x80,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_ps_cb_iparEN,\n            { \"iPar_EN - iParameter assignment deblocked\", \"pn_io.ps.cb.iparEN\",\n            FT_UINT8, BASE_HEX, NULL, 0x01,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_ps_cb_OAReq,\n            { \"OA_Req - Operator acknowledge requested\", \"pn_io.ps.cb.OA_Req\",\n            FT_UINT8, BASE_HEX, NULL, 0x02,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_ps_cb_resetConsNr,\n            { \"R_cons_nr - Set the Virtual Consecutive Number within the F-Device to be \\\"0\\\"\", \"pn_io.ps.cb.R_cons_nr\",\n            FT_UINT8, BASE_HEX, NULL, 0x04,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_ps_cb_useTO2,\n            { \"Bit3 - Reserved or Use the secondary watchdog (Use_TO2)\", \"pn_io.ps.cb.bit3\",\n            FT_UINT8, BASE_HEX, NULL, 0x08,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_ps_cb_activateFV,\n            { \"activate_FV - Fail-safe values (FV) to be activated\", \"pn_io.ps.cb.activate_FV\",\n            FT_UINT8, BASE_HEX, NULL, 0x10,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_ps_cb_Toggle_h,\n            { \"Toggle_h - Host-based Toggle Bit\", \"pn_io.ps.cb.Toggle_h\",\n            FT_UINT8, BASE_HEX, NULL, 0x20,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_ps_cb_Chf_ACK,\n            { \"Bit6 - Reserved or Operator acknowledge after cleared channel fault (ChF_Ack)\", \"pn_io.ps.cb.bit6\",\n            FT_UINT8, BASE_HEX, NULL, 0x40,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_ps_cb_loopcheck,\n            { \"Bit7 - Reserved or Loop-back check (Loopcheck, shall be set to 1)\", \"pn_io.ps.cb.bit7\",\n            FT_UINT8, BASE_HEX, NULL, 0x80,\n            NULL, HFILL }\n        },\n        /* PROFIsafe */\n        { &hf_pn_io_ps_f_dest_adr,\n            { \"F_Dest_Add\", \"pn_io.ps.f_dest_add\",\n            FT_UINT16, BASE_DEC, NULL, 0x0,\n            NULL, HFILL }\n        },\n        { &hf_pn_io_ps_f_data,\n            { \"SafetyIO Data\", \"pn_io.ps.f_data\",\n            FT_UINT64, BASE_HEX, NULL, 0x0,\n            NULL, HFILL }\n        },\n    };\n\n    static gint *ett[] = {\n        &ett_pn_io_rtc,\n        &ett_pn_io_ioxs,\n        &ett_pn_io_io_data_object\n    };\n\n    static ei_register_info ei[] = {\n        { &ei_pn_io_too_many_data_objects, { \"pn_io.too_many_data_objects\", PI_MALFORMED, PI_ERROR, \"Too many data objects\", EXPFILL }},\n    };\n\n    expert_module_t* expert_pn_io;\n\n    proto_pn_io_rtc1 = proto;\n    proto_register_field_array(proto, hf, array_length(hf));\n    proto_register_subtree_array(ett, array_length(ett));\n    expert_pn_io = expert_register_protocol(proto_pn_io_rtc1);\n    expert_register_field_array(expert_pn_io, ei, array_length(ei));\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -224,7 +224,15 @@\n         &ett_pn_io_io_data_object\n     };\n \n+    static ei_register_info ei[] = {\n+        { &ei_pn_io_too_many_data_objects, { \"pn_io.too_many_data_objects\", PI_MALFORMED, PI_ERROR, \"Too many data objects\", EXPFILL }},\n+    };\n+\n+    expert_module_t* expert_pn_io;\n+\n     proto_pn_io_rtc1 = proto;\n     proto_register_field_array(proto, hf, array_length(hf));\n     proto_register_subtree_array(ett, array_length(ett));\n+    expert_pn_io = expert_register_protocol(proto_pn_io_rtc1);\n+    expert_register_field_array(expert_pn_io, ei, array_length(ei));\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    static ei_register_info ei[] = {",
                "        { &ei_pn_io_too_many_data_objects, { \"pn_io.too_many_data_objects\", PI_MALFORMED, PI_ERROR, \"Too many data objects\", EXPFILL }},",
                "    };",
                "",
                "    expert_module_t* expert_pn_io;",
                "",
                "    expert_pn_io = expert_register_protocol(proto_pn_io_rtc1);",
                "    expert_register_field_array(expert_pn_io, ei, array_length(ei));"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-9372",
        "func_name": "wireshark/dissect_PNIO_C_SDU_RTC1",
        "description": "In Wireshark 2.2.0 to 2.2.1, the Profinet I/O dissector could loop excessively, triggered by network traffic or a capture file. This was addressed in plugins/profinet/packet-pn-rtc-one.c by rejecting input with too many I/O objects.",
        "git_url": "https://github.com/wireshark/wireshark/commit/4127e3930ef663114567002001f44e01eba8a250",
        "commit_title": "Profinet I/O: Sanity check number of I/O objects",
        "commit_text": " Can prevent really long loops from fuzz testing.  Bug: 12851 (cherry picked from commit e8022a9c7b36b96578a30fc8132def6de8928606)",
        "func_before": "int\ndissect_PNIO_C_SDU_RTC1(tvbuff_t *tvb, int offset,\n    packet_info *pinfo, proto_tree *tree, guint8 *drep _U_)\n{\n    proto_tree  *data_tree = NULL;\n\n    /* Count & offset for comparation of the arrays */\n    guint16     frameOffset;\n    guint32     objectCounter;\n    gboolean    inputFlag;\n    gboolean    outputFlag;\n    gboolean    psInfoText;     /* Used to display only once per frame the info text \"PROFIsafe Device\" */\n\n    proto_item *IODataObject_item;\n    proto_item *IODataObject_item_info;\n    proto_tree *IODataObject_tree;\n    proto_item *ModuleID_item;\n    proto_item *ModuleDiff_item;\n\n    wmem_strbuf_t *moduleName;\n\n    guint8  toggleBitSb;\n    guint8  toggleBitCb;\n    guint64 f_data;\n\n    guint8  statusbyte;\n    guint8  controlbyte;\n\n    guint16 number_io_data_objects_input_cr;\n    guint16 number_iocs_input_cr;\n    guint16 number_io_data_objects_output_cr;\n    guint16 number_iocs_output_cr;\n\n    conversation_t    *conversation;\n    stationInfo       *station_info = NULL;\n    iocsObject        *iocs_object;\n    ioDataObject      *io_data_object;\n    moduleDiffInfo    *module_diff_info;\n    wmem_list_frame_t *frame;\n    wmem_list_frame_t *frame_diff;\n\n    /* Initial */\n    frameOffset = 0;\n    f_data = 0;\n    inputFlag = FALSE;\n    outputFlag = FALSE;\n    psInfoText = FALSE;\n    number_io_data_objects_input_cr = 0;\n    number_iocs_input_cr = 0;\n    number_io_data_objects_output_cr = 0;\n    number_iocs_output_cr = 0;\n\n    col_set_str(pinfo->cinfo, COL_PROTOCOL, \"PNIO\");            /* set protocol name */\n\n    if (tree) {\n        proto_item *data_item;\n        data_item = proto_tree_add_protocol_format(tree, proto_pn_io_rtc1, tvb, offset, tvb_captured_length(tvb),\n            \"PROFINET IO Cyclic Service Data Unit: %u bytes\", tvb_captured_length(tvb));\n        data_tree = proto_item_add_subtree(data_item, ett_pn_io_rtc);\n    }\n\n    /* dissect_dcerpc_uint16(tvb, offset, pinfo, data_tree, drep, hf_pn_io_packedframe_SFCRC, &u16SFCRC); */\n    if (!(dissect_CSF_SDU_heur(tvb, pinfo, data_tree, NULL) == FALSE))\n        return(tvb_captured_length(tvb));\n\n    /* Only dissect cyclic RTC1 frames, if PN Connect Request has been read */\n    conversation = find_conversation(pinfo->num, &pinfo->dl_src, &pinfo->dl_dst, PT_NONE, 0, 0, 0);\n\n    /* Detect input data package and output data package */\n    if (conversation != NULL) {\n        station_info = (stationInfo*)conversation_get_proto_data(conversation, proto_pn_dcp);\n        if (station_info != NULL) {\n            if (pnio_ps_selection == TRUE) {\n                col_set_str(pinfo->cinfo, COL_PROTOCOL, \"PNIO_PS\");    /* set PROFISsafe protocol name */\n            }\n\n            if (addresses_equal(&(pinfo->src), &(conversation->key_ptr->addr1)) && addresses_equal(&(pinfo->dst), &(conversation->key_ptr->addr2))) {\n                inputFlag = TRUE;\n                outputFlag = FALSE;\n                number_io_data_objects_input_cr = station_info->ioDataObjectNr;\n                number_iocs_input_cr = station_info->iocsNr;\n            }\n\n            if (addresses_equal(&(pinfo->dst), &(conversation->key_ptr->addr1)) && addresses_equal(&(pinfo->src), &(conversation->key_ptr->addr2))) {\n                outputFlag = TRUE;\n                inputFlag = FALSE;\n                number_io_data_objects_output_cr = station_info->ioDataObjectNr;\n                number_iocs_output_cr = station_info->iocsNr;\n            }\n        }\n    }\n\n    /* ------- Input (PNIO) / Response (PNIO_PS) Frame Handling ------- */\n    if (inputFlag) {\n        if (pnio_ps_selection == TRUE) {\n            proto_tree_add_string_format_value(data_tree, hf_pn_io_frame_info_type, tvb,\n                offset, 0, \"Response\", \"Response Frame (IO_Device -> IO_Controller)\");\n        }\n        else {\n            proto_tree_add_string_format_value(data_tree, hf_pn_io_frame_info_type, tvb,\n                offset, 0, \"Input\", \"Input Frame (IO_Device -> IO_Controller)\");\n        }\n\n        if (station_info != NULL) {\n            if (station_info->typeofstation != NULL) {\n                proto_tree_add_string_format_value(data_tree, hf_pn_io_frame_info_vendor, tvb, 0,\n                    0, station_info->typeofstation, \"\\\"%s\\\"\", station_info->typeofstation);\n            }\n            if (station_info->nameofstation != NULL) {\n                proto_tree_add_string_format_value(data_tree, hf_pn_io_frame_info_nameofstation, tvb, 0,\n                    0, station_info->nameofstation, \"\\\"%s\\\"\", station_info->nameofstation);\n            }\n\n            if (station_info->gsdPathLength == TRUE) {      /* given path isn't too long for the array */\n                if (station_info->gsdFound == TRUE) {       /* found a GSD-file */\n                    if (station_info->gsdLocation != NULL) {\n                        IODataObject_item_info = proto_tree_add_item(data_tree, hf_pn_io_frame_info_gsd_found, tvb, offset, 0, ENC_NA);\n                        proto_item_append_text(IODataObject_item_info, \": \\\"%s\\\"\", station_info->gsdLocation);\n                    }\n                }\n                else {\n                    if (station_info->gsdLocation != NULL) {\n                        IODataObject_item_info = proto_tree_add_item(data_tree, hf_pn_io_frame_info_gsd_error, tvb, offset, 0, ENC_NA);\n                        proto_item_append_text(IODataObject_item_info, \" Please place relevant GSD-file under \\\"%s\\\"\", station_info->gsdLocation);\n                    }\n                }\n            }\n            else {\n                IODataObject_item_info = proto_tree_add_item(data_tree, hf_pn_io_frame_info_gsd_path, tvb, offset, 0, ENC_NA);\n                proto_item_append_text(IODataObject_item_info, \" Please check your GSD-file networkpath. (No Path configured)\");\n            }\n        }\n\n        /* ---- Input IOData-/IOCS-Object Handling ---- */\n        objectCounter = number_io_data_objects_input_cr + number_iocs_input_cr;\n        while (objectCounter--) {\n            /* ---- Input IO Data Object Handling ---- */\n            if (station_info != NULL) {\n                for (frame = wmem_list_head(station_info->ioobject_data_in); frame != NULL; frame = wmem_list_frame_next(frame)) {\n                    io_data_object = (ioDataObject*)wmem_list_frame_data(frame);\n                    if (io_data_object->frameOffset == frameOffset) {\n                        /* Found following object */\n\n                        IODataObject_item = proto_tree_add_item(data_tree, hf_pn_io_io_data_object, tvb, offset, 0, ENC_NA);\n                        IODataObject_tree = proto_item_add_subtree(IODataObject_item, ett_pn_io_io_data_object);\n\n                        /* Control: the Device still uses the correct ModuleIdentNumber? */\n                        for (frame_diff = wmem_list_head(station_info->diff_module); frame_diff != NULL; frame_diff = wmem_list_frame_next(frame_diff)) {\n                            module_diff_info = (moduleDiffInfo*)wmem_list_frame_data(frame_diff);\n                            if (io_data_object->moduleIdentNr != module_diff_info->modulID) {\n                                ModuleDiff_item = proto_tree_add_item(IODataObject_tree, hf_pn_io_io_data_object_info_module_diff, tvb, 0, 0, ENC_NA);\n                                proto_item_append_text(ModuleDiff_item, \": Device using ModuleIdentNumber 0x%08x instead of 0x%08x\", module_diff_info->modulID, io_data_object->moduleIdentNr);\n                                break;\n                            }\n                        }\n\n                        proto_tree_add_uint(IODataObject_tree, hf_pn_io_io_data_object_info_moduleidentnumber, tvb, 0, 0, io_data_object->moduleIdentNr);\n                        proto_tree_add_uint(IODataObject_tree, hf_pn_io_io_data_object_info_submoduleidentnumber, tvb, 0, 0, io_data_object->subModuleIdentNr);\n\n                        /* PROFIsafe Supported Inputmodule handling */\n                        if (io_data_object->profisafeSupported == TRUE && pnio_ps_selection == TRUE) {\n                            if (io_data_object->profisafeSupported == TRUE && psInfoText == FALSE) {\n                                /* Only add one information string per device to the infotext */\n                                col_append_str(pinfo->cinfo, COL_INFO, \", PROFIsafe Device\");    /* Add string to wireshark infotext */\n                                psInfoText = TRUE;\n                            }\n\n                            proto_tree_add_uint(IODataObject_tree, hf_pn_io_ps_f_dest_adr, tvb, 0, 0, io_data_object->f_dest_adr);\n\n                            /* Get Safety IO Data */\n                            if ((io_data_object->length - F_MESSAGE_TRAILER_4BYTE) > 0) {\n                                offset = dissect_pn_io_ps_uint(tvb, offset, pinfo, IODataObject_tree, drep, hf_pn_io_ps_f_data,\n                                    (io_data_object->length - F_MESSAGE_TRAILER_4BYTE), &f_data);\n                            }\n\n                            /* ---- Check for new PNIO data using togglebit ---- */\n                            statusbyte = tvb_get_guint8(tvb, offset);\n                            toggleBitSb = statusbyte & 0x20;     /* get ToggleBit of StatusByte */\n\n                            if (io_data_object->lastToggleBit != toggleBitSb) {    /* ToggleBit has changed --> new Data incoming */\n                                /* Special Filter for ToggleBit within Statusbyte */\n                                ModuleID_item = proto_tree_add_uint_format_value(IODataObject_tree, hf_pn_io_ps_sb_toggelBitChanged, tvb, offset, 0,\n                                    toggleBitSb, \"%u\", toggleBitSb);\n                                PROTO_ITEM_SET_HIDDEN(ModuleID_item);\n\n                                ModuleID_item = proto_tree_add_uint_format_value(IODataObject_tree, hf_pn_io_ps_sb_toggelBitChange_slot_nr, tvb, offset, 0,\n                                    io_data_object->slotNr, \"%u\", io_data_object->slotNr);\n                                PROTO_ITEM_SET_HIDDEN(ModuleID_item);\n\n                                ModuleID_item = proto_tree_add_uint_format_value(IODataObject_tree, hf_pn_io_ps_sb_toggelBitChange_subslot_nr, tvb, offset, 0,\n                                    io_data_object->subSlotNr, \"%u\", io_data_object->subSlotNr);\n                                PROTO_ITEM_SET_HIDDEN(ModuleID_item);\n                            }\n\n                            offset = dissect_pn_io_ps_SB(tvb, offset, pinfo, IODataObject_tree, drep, hf_pn_io_ps_sb, ps_sb_fields);\n                            offset = dissect_pn_user_data(tvb, offset, pinfo, IODataObject_tree, io_data_object->f_crc_len, \"CRC\");\n\n                            io_data_object->last_sb_cb = statusbyte;       /* save the value of current statusbyte */\n                            io_data_object->lastToggleBit = toggleBitSb;   /* save the value of current togglebit within statusbyte */\n                        }    /* END of PROFIsafe Module Handling */\n\n                        else {\n                            /* Module is not PROFIsafe supported */\n                            offset = dissect_pn_user_data(tvb, offset, pinfo, IODataObject_tree, io_data_object->length, \"IO Data\");\n                        }\n\n                        if (io_data_object->discardIOXS == FALSE) {\n                            offset = dissect_PNIO_IOxS(tvb, offset, pinfo, IODataObject_tree, drep, hf_pn_io_iops, ioxs_fields);\n                            proto_item_set_len(IODataObject_item, io_data_object->length + 1);     /* Length = Databytes + IOXS Byte */\n                        }\n                        else {\n                            proto_item_set_len(IODataObject_item, io_data_object->length);         /* Length = Databytes */\n                        }\n\n                        proto_item_append_text(IODataObject_item, \": Slot: 0x%x Subslot: 0x%x\",\n                            io_data_object->slotNr, io_data_object->subSlotNr);\n\n\n                        /* ModuleIdentNr appears not only once in GSD-file -> set module name more generally */\n                        if (io_data_object->amountInGSDML > 1) {    /* if ModuleIdentNr only appears once in GSD-file, use the found GSD-file-ModuleName, else ... */\n                            if (io_data_object->slotNr == 0) {\n                                moduleName = wmem_strbuf_new(wmem_packet_scope(), \"Headstation\");\n                            }\n                            else {\n                                moduleName = wmem_strbuf_new(wmem_packet_scope(), \"Module\");\n                            }\n\n                            if (io_data_object->profisafeSupported == TRUE) {\n                                /* PROFIsafe */\n                                if (io_data_object->length >= 5) {        /* 5 due to 3 CRC bytes &  1 status byte & (at least) 1 data byte */\n                                    wmem_strbuf_append(moduleName, \", DI\");\n                                }\n                                else {\n                                    wmem_strbuf_append(moduleName, \", DO\");\n                                }\n                            }\n                            else {\n                                /* PROFINET */\n                                if (io_data_object->length > 0) {\n                                    wmem_strbuf_append(moduleName, \", DI\");\n                                }\n                                else {\n                                    wmem_strbuf_append(moduleName, \", DO\");\n                                }\n                            }\n\n                            io_data_object->moduleNameStr = wmem_strdup(wmem_file_scope(), wmem_strbuf_get_str(moduleName));\n                        }\n\n                        proto_item_append_text(IODataObject_item, \" ModuleName: \\\"%s\\\"\", io_data_object->moduleNameStr);\n\n                        /* emphasize the PROFIsafe supported Modul */\n                        if (io_data_object->profisafeSupported == TRUE && pnio_ps_selection == TRUE) {\n                            (proto_item_append_text(IODataObject_item, \" (PROFIsafe Module)\"));\n                        }\n\n\n                        /* Set frameOffset to its new value, to find the next object */\n                        frameOffset = frameOffset + io_data_object->length;  /* frameOffset = current value + data bytes */\n                        if (io_data_object->discardIOXS == FALSE) {\n                            frameOffset = frameOffset + 1;      /* frameOffset = current value + iops byte */\n                        }\n                    }\n                }\n            }\n\n            /* ---- Input IOCS Object Handling ---- */\n            if (station_info != NULL) {\n                for (frame = wmem_list_head(station_info->iocs_data_in); frame != NULL; frame = wmem_list_frame_next(frame)) {\n                    iocs_object = (iocsObject*)wmem_list_frame_data(frame);\n                    if (iocs_object->frameOffset == frameOffset) {\n                        offset = dissect_PNIO_IOCS(tvb, offset, pinfo, data_tree, drep, hf_pn_io_iocs, iocs_object->slotNr,\n                            iocs_object->subSlotNr, ioxs_fields);\n\n                        /* Set frameOffset to its new value, to find the next object */\n                        frameOffset = frameOffset + 1;      /* frameOffset = current value + iops byte */\n\n                        break;\n                    }\n                }\n            }\n        }\n\n        /* Dissect padding */\n        offset = dissect_pn_user_data(tvb, offset, pinfo, tree, tvb_captured_length_remaining(tvb, offset), \"GAP and RTCPadding\");\n    }   /* END of Input Frame Handling */\n\n    /* ----- Output (PNIO) / Request (PNIO_PS) Frame Handling ------ */\n    else if (outputFlag) {\n        if (pnio_ps_selection == TRUE) {\n            proto_tree_add_string_format_value(data_tree, hf_pn_io_frame_info_type, tvb,\n                offset, 0, \"Request\", \"Request Frame (IO_Controller -> IO_Device)\");\n        }\n        else {\n            proto_tree_add_string_format_value(data_tree, hf_pn_io_frame_info_type, tvb,\n                offset, 0, \"Output\", \"Output Frame (IO_Controller -> IO_Device)\");\n        }\n\n        if (station_info != NULL) {\n            if (station_info->typeofstation != NULL) {\n                proto_tree_add_string_format_value(data_tree, hf_pn_io_frame_info_vendor, tvb, 0,\n                    0, station_info->typeofstation, \"\\\"%s\\\"\", station_info->typeofstation);\n            }\n            if (station_info->nameofstation != NULL) {\n                proto_tree_add_string_format_value(data_tree, hf_pn_io_frame_info_nameofstation, tvb, 0,\n                    0, station_info->nameofstation, \"\\\"%s\\\"\", station_info->nameofstation);\n            }\n\n            if (station_info->gsdPathLength == TRUE) {      /* given path isn't too long for the array */\n                if (station_info->gsdFound == TRUE) {       /* found a GSD-file */\n                    if (station_info->gsdLocation != NULL) {\n                        IODataObject_item_info = proto_tree_add_item(data_tree, hf_pn_io_frame_info_gsd_found, tvb, offset, 0, ENC_NA);\n                        proto_item_append_text(IODataObject_item_info, \": \\\"%s\\\"\", station_info->gsdLocation);\n                    }\n                }\n                else {\n                    if (station_info->gsdLocation != NULL) {\n                        IODataObject_item_info = proto_tree_add_item(data_tree, hf_pn_io_frame_info_gsd_error, tvb, offset, 0, ENC_NA);\n                        proto_item_append_text(IODataObject_item_info, \" Please place relevant GSD-file under \\\"%s\\\"\", station_info->gsdLocation);\n                    }\n                }\n            }\n            else {\n                IODataObject_item_info = proto_tree_add_item(data_tree, hf_pn_io_frame_info_gsd_path, tvb, offset, 0, ENC_NA);\n                proto_item_append_text(IODataObject_item_info, \" Please check your GSD-file networkpath. (No Path configured)\");\n            }\n        }\n\n        /* ---- Output IOData-/IOCS-Object Handling ---- */\n        objectCounter = number_io_data_objects_output_cr + number_iocs_output_cr;\n        while (objectCounter--) {\n            /* ---- Output IO Data Object Handling ---- */\n            if (station_info != NULL) {\n                for (frame = wmem_list_head(station_info->ioobject_data_out); frame != NULL; frame = wmem_list_frame_next(frame)) {\n                    io_data_object = (ioDataObject*)wmem_list_frame_data(frame);\n                    if (io_data_object != NULL && io_data_object->frameOffset == frameOffset) {\n                        /* Found following object */\n\n                        IODataObject_item = proto_tree_add_item(data_tree, hf_pn_io_io_data_object, tvb, offset, 0, ENC_NA);\n                        IODataObject_tree = proto_item_add_subtree(IODataObject_item, ett_pn_io_io_data_object);\n\n                        /* Control: the Device still uses the correct ModuleIdentNumber? */\n                        for (frame_diff = wmem_list_head(station_info->diff_module); frame_diff != NULL; frame_diff = wmem_list_frame_next(frame_diff)) {\n                            module_diff_info = (moduleDiffInfo*)wmem_list_frame_data(frame_diff);\n                            if (io_data_object->moduleIdentNr != module_diff_info->modulID) {\n                                ModuleDiff_item = proto_tree_add_item(IODataObject_tree, hf_pn_io_io_data_object_info_module_diff, tvb, 0, 0, ENC_NA);\n                                proto_item_append_text(ModuleDiff_item, \": Device using ModuleIdentNumber 0x%08x instead of 0x%08x\", module_diff_info->modulID, io_data_object->moduleIdentNr);\n                                break;\n                            }\n                        }\n\n                        proto_tree_add_uint(IODataObject_tree, hf_pn_io_io_data_object_info_moduleidentnumber, tvb, 0, 0, io_data_object->moduleIdentNr);\n                        proto_tree_add_uint(IODataObject_tree, hf_pn_io_io_data_object_info_submoduleidentnumber, tvb, 0, 0, io_data_object->subModuleIdentNr);\n\n                        if (io_data_object->profisafeSupported == TRUE && pnio_ps_selection == TRUE) {\n                            if (io_data_object->profisafeSupported == TRUE && psInfoText == FALSE) {\n                                /* Only add one information string per device to the infotext */\n                                col_append_str(pinfo->cinfo, COL_INFO, \", PROFIsafe Device\");    /* Add string to wireshark infotext */\n                                psInfoText = TRUE;\n                            }\n\n                            proto_tree_add_uint(IODataObject_tree, hf_pn_io_ps_f_dest_adr, tvb, 0, 0, io_data_object->f_dest_adr);\n\n                            /* Get Safety IO Data */\n                            if ((io_data_object->length - F_MESSAGE_TRAILER_4BYTE) > 0) {\n                                offset = dissect_pn_io_ps_uint(tvb, offset, pinfo, IODataObject_tree, drep, hf_pn_io_ps_f_data,\n                                    (io_data_object->length - F_MESSAGE_TRAILER_4BYTE), &f_data);\n                            }\n\n                            /* ---- Check for new PNIO data using togglebit ---- */\n                            controlbyte = tvb_get_guint8(tvb, offset);\n                            toggleBitCb = controlbyte & 0x20;               /* get ToggleBit of Controlbyte */\n\n                            if (io_data_object->lastToggleBit != toggleBitCb) {   /* ToggleBit has changed --> new Data incoming */\n                                /* Special Filter for ToggleBit within Controlbyte */\n                                ModuleID_item = proto_tree_add_uint_format_value(IODataObject_tree, hf_pn_io_ps_cb_toggelBitChanged, tvb, offset, 0,\n                                    toggleBitCb, \"%u\", toggleBitCb);\n                                PROTO_ITEM_SET_HIDDEN(ModuleID_item);\n\n                                ModuleID_item = proto_tree_add_uint_format_value(IODataObject_tree, hf_pn_io_ps_cb_toggelBitChange_slot_nr, tvb, offset, 0,\n                                    io_data_object->slotNr, \"%u\", io_data_object->slotNr);\n                                PROTO_ITEM_SET_HIDDEN(ModuleID_item);\n\n                                ModuleID_item = proto_tree_add_uint_format_value(IODataObject_tree, hf_pn_io_ps_cb_toggelBitChange_subslot_nr, tvb, offset, 0,\n                                    io_data_object->subSlotNr, \"%u\", io_data_object->subSlotNr);\n                                PROTO_ITEM_SET_HIDDEN(ModuleID_item);\n                            }\n\n                            offset = dissect_pn_io_ps_CB(tvb, offset, pinfo, IODataObject_tree, drep, hf_pn_io_ps_cb, ps_cb_fields);\n                            offset = dissect_pn_user_data(tvb, offset, pinfo, IODataObject_tree, io_data_object->f_crc_len, \"CRC\");\n\n                            io_data_object->last_sb_cb = controlbyte;         /* save the value of current controlbyte */\n                            io_data_object->lastToggleBit = toggleBitCb;      /* save the value of current togglebit within controlbyte */\n                        }    /* End of PROFIsafe Module Handling */\n                        else {\n                            /* Module is not PROFIsafe supported */\n                            offset = dissect_pn_user_data(tvb, offset, pinfo, IODataObject_tree, io_data_object->length, \"IO Data\");\n                        }\n\n                        if (io_data_object->discardIOXS == FALSE) {\n                            offset = dissect_PNIO_IOxS(tvb, offset, pinfo, IODataObject_tree, drep, hf_pn_io_iops, ioxs_fields);\n                            proto_item_set_len(IODataObject_item, io_data_object->length + 1);        /* Length = Databytes + IOXS Byte */\n                        }\n                        else {\n                            proto_item_set_len(IODataObject_item, io_data_object->length);            /* Length = Databytes */\n                        }\n\n                        proto_item_append_text(IODataObject_item, \": Slot: 0x%x Subslot: 0x%x\",\n                            io_data_object->slotNr, io_data_object->subSlotNr);\n\n\n                        /* ModuleIdentNr appears not only once in GSD-file -> set module name more generally */\n                        if (io_data_object->amountInGSDML > 1) {    /* if ModuleIdentNr only appears once in GSD-file, use the found GSD-file-ModuleName, else ... */\n                            if (io_data_object->slotNr == 0) {\n                                moduleName = wmem_strbuf_new(wmem_packet_scope(), \"Headstation\");\n                            }\n                            else {\n                                moduleName = wmem_strbuf_new(wmem_packet_scope(), \"Module\");\n                            }\n\n                            if (io_data_object->profisafeSupported == TRUE) {\n                                /* PROFIsafe */\n                                if (io_data_object->length >= 5) {        /* 5 due to 3 CRC bytes &  1 status byte & (at least) 1 data byte */\n                                    wmem_strbuf_append(moduleName, \", DO\");\n                                }\n                                else {\n                                    wmem_strbuf_append(moduleName, \", DI\");\n                                }\n                            }\n                            else {\n                                /* PROFINET */\n                                if (io_data_object->length > 0) {\n                                    wmem_strbuf_append(moduleName, \", DO\");\n                                }\n                                else {\n                                    wmem_strbuf_append(moduleName, \", DI\");\n                                }\n                            }\n\n                            io_data_object->moduleNameStr = wmem_strdup(wmem_file_scope(), wmem_strbuf_get_str(moduleName));\n                        }\n\n                        proto_item_append_text(IODataObject_item, \" ModuleName: \\\"%s\\\"\", io_data_object->moduleNameStr);\n\n                        /* emphasize the PROFIsafe supported Modul */\n                        if (io_data_object->profisafeSupported == TRUE && pnio_ps_selection == TRUE) {\n                            proto_item_append_text(IODataObject_item, \" (PROFIsafe Module)\");\n                        }\n\n                        /* Set frameOffset to its new value, to find the next object */\n                        frameOffset = frameOffset + io_data_object->length; /* frameOffset = current value + data bytes */\n                        if (io_data_object->discardIOXS == FALSE) {\n                            frameOffset = frameOffset + 1;      /* frameOffset = current value + iops byte */\n                        }\n                    }\n                }\n            }\n\n            /* ---- Output IOCS Object Handling ---- */\n            if (station_info != NULL) {\n                for (frame = wmem_list_head(station_info->iocs_data_out); frame != NULL; frame = wmem_list_frame_next(frame)) {\n                    iocs_object = (iocsObject*)wmem_list_frame_data(frame);\n                    if (iocs_object->frameOffset == frameOffset) {\n                        offset = dissect_PNIO_IOCS(tvb, offset, pinfo, data_tree, drep, hf_pn_io_iocs, iocs_object->slotNr,\n                            iocs_object->subSlotNr, ioxs_fields);\n\n                        /* Set frameOffset to its new value, to find the next object */\n                        frameOffset = frameOffset + 1;      /* frameOffset = current value + iops byte */\n\n                        break;\n                    }\n                }\n            }\n        }\n\n        /* Dissect padding */\n        offset = dissect_pn_user_data(tvb, offset, pinfo, tree, tvb_captured_length_remaining(tvb, offset), \"GAP and RTCPadding\");\n    }   /* END of Output Frame Handling */\n\n    return offset;\n}",
        "func": "int\ndissect_PNIO_C_SDU_RTC1(tvbuff_t *tvb, int offset,\n    packet_info *pinfo, proto_tree *tree, guint8 *drep _U_)\n{\n    proto_tree  *data_tree = NULL;\n\n    /* Count & offset for comparation of the arrays */\n    guint16     frameOffset;\n    guint32     objectCounter;\n    gboolean    inputFlag;\n    gboolean    outputFlag;\n    gboolean    psInfoText;     /* Used to display only once per frame the info text \"PROFIsafe Device\" */\n\n    proto_item *data_item;\n    proto_item *IODataObject_item;\n    proto_item *IODataObject_item_info;\n    proto_tree *IODataObject_tree;\n    proto_item *ModuleID_item;\n    proto_item *ModuleDiff_item;\n\n    wmem_strbuf_t *moduleName;\n\n    guint8  toggleBitSb;\n    guint8  toggleBitCb;\n    guint64 f_data;\n\n    guint8  statusbyte;\n    guint8  controlbyte;\n\n    guint16 number_io_data_objects_input_cr;\n    guint16 number_iocs_input_cr;\n    guint16 number_io_data_objects_output_cr;\n    guint16 number_iocs_output_cr;\n\n    conversation_t    *conversation;\n    stationInfo       *station_info = NULL;\n    iocsObject        *iocs_object;\n    ioDataObject      *io_data_object;\n    moduleDiffInfo    *module_diff_info;\n    wmem_list_frame_t *frame;\n    wmem_list_frame_t *frame_diff;\n\n    /* Initial */\n    frameOffset = 0;\n    f_data = 0;\n    inputFlag = FALSE;\n    outputFlag = FALSE;\n    psInfoText = FALSE;\n    number_io_data_objects_input_cr = 0;\n    number_iocs_input_cr = 0;\n    number_io_data_objects_output_cr = 0;\n    number_iocs_output_cr = 0;\n\n    col_set_str(pinfo->cinfo, COL_PROTOCOL, \"PNIO\");            /* set protocol name */\n\n    data_item = proto_tree_add_protocol_format(tree, proto_pn_io_rtc1, tvb, offset, tvb_captured_length(tvb),\n            \"PROFINET IO Cyclic Service Data Unit: %u bytes\", tvb_captured_length(tvb));\n    data_tree = proto_item_add_subtree(data_item, ett_pn_io_rtc);\n\n    /* dissect_dcerpc_uint16(tvb, offset, pinfo, data_tree, drep, hf_pn_io_packedframe_SFCRC, &u16SFCRC); */\n    if (!(dissect_CSF_SDU_heur(tvb, pinfo, data_tree, NULL) == FALSE))\n        return(tvb_captured_length(tvb));\n\n    /* Only dissect cyclic RTC1 frames, if PN Connect Request has been read */\n    conversation = find_conversation(pinfo->num, &pinfo->dl_src, &pinfo->dl_dst, PT_NONE, 0, 0, 0);\n\n    /* Detect input data package and output data package */\n    if (conversation != NULL) {\n        station_info = (stationInfo*)conversation_get_proto_data(conversation, proto_pn_dcp);\n        if (station_info != NULL) {\n            if (pnio_ps_selection == TRUE) {\n                col_set_str(pinfo->cinfo, COL_PROTOCOL, \"PNIO_PS\");    /* set PROFISsafe protocol name */\n            }\n\n            if (addresses_equal(&(pinfo->src), &(conversation->key_ptr->addr1)) && addresses_equal(&(pinfo->dst), &(conversation->key_ptr->addr2))) {\n                inputFlag = TRUE;\n                outputFlag = FALSE;\n                number_io_data_objects_input_cr = station_info->ioDataObjectNr;\n                number_iocs_input_cr = station_info->iocsNr;\n            }\n\n            if (addresses_equal(&(pinfo->dst), &(conversation->key_ptr->addr1)) && addresses_equal(&(pinfo->src), &(conversation->key_ptr->addr2))) {\n                outputFlag = TRUE;\n                inputFlag = FALSE;\n                number_io_data_objects_output_cr = station_info->ioDataObjectNr;\n                number_iocs_output_cr = station_info->iocsNr;\n            }\n        }\n    }\n\n    /* ------- Input (PNIO) / Response (PNIO_PS) Frame Handling ------- */\n    if (inputFlag) {\n        if (pnio_ps_selection == TRUE) {\n            proto_tree_add_string_format_value(data_tree, hf_pn_io_frame_info_type, tvb,\n                offset, 0, \"Response\", \"Response Frame (IO_Device -> IO_Controller)\");\n        }\n        else {\n            proto_tree_add_string_format_value(data_tree, hf_pn_io_frame_info_type, tvb,\n                offset, 0, \"Input\", \"Input Frame (IO_Device -> IO_Controller)\");\n        }\n\n        if (station_info != NULL) {\n            if (station_info->typeofstation != NULL) {\n                proto_tree_add_string_format_value(data_tree, hf_pn_io_frame_info_vendor, tvb, 0,\n                    0, station_info->typeofstation, \"\\\"%s\\\"\", station_info->typeofstation);\n            }\n            if (station_info->nameofstation != NULL) {\n                proto_tree_add_string_format_value(data_tree, hf_pn_io_frame_info_nameofstation, tvb, 0,\n                    0, station_info->nameofstation, \"\\\"%s\\\"\", station_info->nameofstation);\n            }\n\n            if (station_info->gsdPathLength == TRUE) {      /* given path isn't too long for the array */\n                if (station_info->gsdFound == TRUE) {       /* found a GSD-file */\n                    if (station_info->gsdLocation != NULL) {\n                        IODataObject_item_info = proto_tree_add_item(data_tree, hf_pn_io_frame_info_gsd_found, tvb, offset, 0, ENC_NA);\n                        proto_item_append_text(IODataObject_item_info, \": \\\"%s\\\"\", station_info->gsdLocation);\n                    }\n                }\n                else {\n                    if (station_info->gsdLocation != NULL) {\n                        IODataObject_item_info = proto_tree_add_item(data_tree, hf_pn_io_frame_info_gsd_error, tvb, offset, 0, ENC_NA);\n                        proto_item_append_text(IODataObject_item_info, \" Please place relevant GSD-file under \\\"%s\\\"\", station_info->gsdLocation);\n                    }\n                }\n            }\n            else {\n                IODataObject_item_info = proto_tree_add_item(data_tree, hf_pn_io_frame_info_gsd_path, tvb, offset, 0, ENC_NA);\n                proto_item_append_text(IODataObject_item_info, \" Please check your GSD-file networkpath. (No Path configured)\");\n            }\n        }\n\n        /* ---- Input IOData-/IOCS-Object Handling ---- */\n        objectCounter = number_io_data_objects_input_cr + number_iocs_input_cr;\n        if (objectCounter > (guint)tvb_reported_length_remaining(tvb, offset)) {\n            expert_add_info_format(pinfo, data_item, &ei_pn_io_too_many_data_objects, \"Too many data objects: %d\", objectCounter);\n            return(tvb_captured_length(tvb));\n        }\n\n        while (objectCounter--) {\n            /* ---- Input IO Data Object Handling ---- */\n            if (station_info != NULL) {\n                for (frame = wmem_list_head(station_info->ioobject_data_in); frame != NULL; frame = wmem_list_frame_next(frame)) {\n                    io_data_object = (ioDataObject*)wmem_list_frame_data(frame);\n                    if (io_data_object->frameOffset == frameOffset) {\n                        /* Found following object */\n\n                        IODataObject_item = proto_tree_add_item(data_tree, hf_pn_io_io_data_object, tvb, offset, 0, ENC_NA);\n                        IODataObject_tree = proto_item_add_subtree(IODataObject_item, ett_pn_io_io_data_object);\n\n                        /* Control: the Device still uses the correct ModuleIdentNumber? */\n                        for (frame_diff = wmem_list_head(station_info->diff_module); frame_diff != NULL; frame_diff = wmem_list_frame_next(frame_diff)) {\n                            module_diff_info = (moduleDiffInfo*)wmem_list_frame_data(frame_diff);\n                            if (io_data_object->moduleIdentNr != module_diff_info->modulID) {\n                                ModuleDiff_item = proto_tree_add_item(IODataObject_tree, hf_pn_io_io_data_object_info_module_diff, tvb, 0, 0, ENC_NA);\n                                proto_item_append_text(ModuleDiff_item, \": Device using ModuleIdentNumber 0x%08x instead of 0x%08x\", module_diff_info->modulID, io_data_object->moduleIdentNr);\n                                break;\n                            }\n                        }\n\n                        proto_tree_add_uint(IODataObject_tree, hf_pn_io_io_data_object_info_moduleidentnumber, tvb, 0, 0, io_data_object->moduleIdentNr);\n                        proto_tree_add_uint(IODataObject_tree, hf_pn_io_io_data_object_info_submoduleidentnumber, tvb, 0, 0, io_data_object->subModuleIdentNr);\n\n                        /* PROFIsafe Supported Inputmodule handling */\n                        if (io_data_object->profisafeSupported == TRUE && pnio_ps_selection == TRUE) {\n                            if (io_data_object->profisafeSupported == TRUE && psInfoText == FALSE) {\n                                /* Only add one information string per device to the infotext */\n                                col_append_str(pinfo->cinfo, COL_INFO, \", PROFIsafe Device\");    /* Add string to wireshark infotext */\n                                psInfoText = TRUE;\n                            }\n\n                            proto_tree_add_uint(IODataObject_tree, hf_pn_io_ps_f_dest_adr, tvb, 0, 0, io_data_object->f_dest_adr);\n\n                            /* Get Safety IO Data */\n                            if ((io_data_object->length - F_MESSAGE_TRAILER_4BYTE) > 0) {\n                                offset = dissect_pn_io_ps_uint(tvb, offset, pinfo, IODataObject_tree, drep, hf_pn_io_ps_f_data,\n                                    (io_data_object->length - F_MESSAGE_TRAILER_4BYTE), &f_data);\n                            }\n\n                            /* ---- Check for new PNIO data using togglebit ---- */\n                            statusbyte = tvb_get_guint8(tvb, offset);\n                            toggleBitSb = statusbyte & 0x20;     /* get ToggleBit of StatusByte */\n\n                            if (io_data_object->lastToggleBit != toggleBitSb) {    /* ToggleBit has changed --> new Data incoming */\n                                /* Special Filter for ToggleBit within Statusbyte */\n                                ModuleID_item = proto_tree_add_uint_format_value(IODataObject_tree, hf_pn_io_ps_sb_toggelBitChanged, tvb, offset, 0,\n                                    toggleBitSb, \"%u\", toggleBitSb);\n                                PROTO_ITEM_SET_HIDDEN(ModuleID_item);\n\n                                ModuleID_item = proto_tree_add_uint_format_value(IODataObject_tree, hf_pn_io_ps_sb_toggelBitChange_slot_nr, tvb, offset, 0,\n                                    io_data_object->slotNr, \"%u\", io_data_object->slotNr);\n                                PROTO_ITEM_SET_HIDDEN(ModuleID_item);\n\n                                ModuleID_item = proto_tree_add_uint_format_value(IODataObject_tree, hf_pn_io_ps_sb_toggelBitChange_subslot_nr, tvb, offset, 0,\n                                    io_data_object->subSlotNr, \"%u\", io_data_object->subSlotNr);\n                                PROTO_ITEM_SET_HIDDEN(ModuleID_item);\n                            }\n\n                            offset = dissect_pn_io_ps_SB(tvb, offset, pinfo, IODataObject_tree, drep, hf_pn_io_ps_sb, ps_sb_fields);\n                            offset = dissect_pn_user_data(tvb, offset, pinfo, IODataObject_tree, io_data_object->f_crc_len, \"CRC\");\n\n                            io_data_object->last_sb_cb = statusbyte;       /* save the value of current statusbyte */\n                            io_data_object->lastToggleBit = toggleBitSb;   /* save the value of current togglebit within statusbyte */\n                        }    /* END of PROFIsafe Module Handling */\n\n                        else {\n                            /* Module is not PROFIsafe supported */\n                            offset = dissect_pn_user_data(tvb, offset, pinfo, IODataObject_tree, io_data_object->length, \"IO Data\");\n                        }\n\n                        if (io_data_object->discardIOXS == FALSE) {\n                            offset = dissect_PNIO_IOxS(tvb, offset, pinfo, IODataObject_tree, drep, hf_pn_io_iops, ioxs_fields);\n                            proto_item_set_len(IODataObject_item, io_data_object->length + 1);     /* Length = Databytes + IOXS Byte */\n                        }\n                        else {\n                            proto_item_set_len(IODataObject_item, io_data_object->length);         /* Length = Databytes */\n                        }\n\n                        proto_item_append_text(IODataObject_item, \": Slot: 0x%x Subslot: 0x%x\",\n                            io_data_object->slotNr, io_data_object->subSlotNr);\n\n\n                        /* ModuleIdentNr appears not only once in GSD-file -> set module name more generally */\n                        if (io_data_object->amountInGSDML > 1) {    /* if ModuleIdentNr only appears once in GSD-file, use the found GSD-file-ModuleName, else ... */\n                            if (io_data_object->slotNr == 0) {\n                                moduleName = wmem_strbuf_new(wmem_packet_scope(), \"Headstation\");\n                            }\n                            else {\n                                moduleName = wmem_strbuf_new(wmem_packet_scope(), \"Module\");\n                            }\n\n                            if (io_data_object->profisafeSupported == TRUE) {\n                                /* PROFIsafe */\n                                if (io_data_object->length >= 5) {        /* 5 due to 3 CRC bytes &  1 status byte & (at least) 1 data byte */\n                                    wmem_strbuf_append(moduleName, \", DI\");\n                                }\n                                else {\n                                    wmem_strbuf_append(moduleName, \", DO\");\n                                }\n                            }\n                            else {\n                                /* PROFINET */\n                                if (io_data_object->length > 0) {\n                                    wmem_strbuf_append(moduleName, \", DI\");\n                                }\n                                else {\n                                    wmem_strbuf_append(moduleName, \", DO\");\n                                }\n                            }\n\n                            io_data_object->moduleNameStr = wmem_strdup(wmem_file_scope(), wmem_strbuf_get_str(moduleName));\n                        }\n\n                        proto_item_append_text(IODataObject_item, \" ModuleName: \\\"%s\\\"\", io_data_object->moduleNameStr);\n\n                        /* emphasize the PROFIsafe supported Modul */\n                        if (io_data_object->profisafeSupported == TRUE && pnio_ps_selection == TRUE) {\n                            (proto_item_append_text(IODataObject_item, \" (PROFIsafe Module)\"));\n                        }\n\n\n                        /* Set frameOffset to its new value, to find the next object */\n                        frameOffset = frameOffset + io_data_object->length;  /* frameOffset = current value + data bytes */\n                        if (io_data_object->discardIOXS == FALSE) {\n                            frameOffset = frameOffset + 1;      /* frameOffset = current value + iops byte */\n                        }\n                    }\n                }\n            }\n\n            /* ---- Input IOCS Object Handling ---- */\n            if (station_info != NULL) {\n                for (frame = wmem_list_head(station_info->iocs_data_in); frame != NULL; frame = wmem_list_frame_next(frame)) {\n                    iocs_object = (iocsObject*)wmem_list_frame_data(frame);\n                    if (iocs_object->frameOffset == frameOffset) {\n                        offset = dissect_PNIO_IOCS(tvb, offset, pinfo, data_tree, drep, hf_pn_io_iocs, iocs_object->slotNr,\n                            iocs_object->subSlotNr, ioxs_fields);\n\n                        /* Set frameOffset to its new value, to find the next object */\n                        frameOffset = frameOffset + 1;      /* frameOffset = current value + iops byte */\n\n                        break;\n                    }\n                }\n            }\n        }\n\n        /* Dissect padding */\n        offset = dissect_pn_user_data(tvb, offset, pinfo, tree, tvb_captured_length_remaining(tvb, offset), \"GAP and RTCPadding\");\n    }   /* END of Input Frame Handling */\n\n    /* ----- Output (PNIO) / Request (PNIO_PS) Frame Handling ------ */\n    else if (outputFlag) {\n        if (pnio_ps_selection == TRUE) {\n            proto_tree_add_string_format_value(data_tree, hf_pn_io_frame_info_type, tvb,\n                offset, 0, \"Request\", \"Request Frame (IO_Controller -> IO_Device)\");\n        }\n        else {\n            proto_tree_add_string_format_value(data_tree, hf_pn_io_frame_info_type, tvb,\n                offset, 0, \"Output\", \"Output Frame (IO_Controller -> IO_Device)\");\n        }\n\n        if (station_info != NULL) {\n            if (station_info->typeofstation != NULL) {\n                proto_tree_add_string_format_value(data_tree, hf_pn_io_frame_info_vendor, tvb, 0,\n                    0, station_info->typeofstation, \"\\\"%s\\\"\", station_info->typeofstation);\n            }\n            if (station_info->nameofstation != NULL) {\n                proto_tree_add_string_format_value(data_tree, hf_pn_io_frame_info_nameofstation, tvb, 0,\n                    0, station_info->nameofstation, \"\\\"%s\\\"\", station_info->nameofstation);\n            }\n\n            if (station_info->gsdPathLength == TRUE) {      /* given path isn't too long for the array */\n                if (station_info->gsdFound == TRUE) {       /* found a GSD-file */\n                    if (station_info->gsdLocation != NULL) {\n                        IODataObject_item_info = proto_tree_add_item(data_tree, hf_pn_io_frame_info_gsd_found, tvb, offset, 0, ENC_NA);\n                        proto_item_append_text(IODataObject_item_info, \": \\\"%s\\\"\", station_info->gsdLocation);\n                    }\n                }\n                else {\n                    if (station_info->gsdLocation != NULL) {\n                        IODataObject_item_info = proto_tree_add_item(data_tree, hf_pn_io_frame_info_gsd_error, tvb, offset, 0, ENC_NA);\n                        proto_item_append_text(IODataObject_item_info, \" Please place relevant GSD-file under \\\"%s\\\"\", station_info->gsdLocation);\n                    }\n                }\n            }\n            else {\n                IODataObject_item_info = proto_tree_add_item(data_tree, hf_pn_io_frame_info_gsd_path, tvb, offset, 0, ENC_NA);\n                proto_item_append_text(IODataObject_item_info, \" Please check your GSD-file networkpath. (No Path configured)\");\n            }\n        }\n\n        /* ---- Output IOData-/IOCS-Object Handling ---- */\n        objectCounter = number_io_data_objects_output_cr + number_iocs_output_cr;\n        if (objectCounter > (guint)tvb_reported_length_remaining(tvb, offset)) {\n            expert_add_info_format(pinfo, data_item, &ei_pn_io_too_many_data_objects, \"Too many data objects: %d\", objectCounter);\n            return(tvb_captured_length(tvb));\n        }\n        while (objectCounter--) {\n            /* ---- Output IO Data Object Handling ---- */\n            if (station_info != NULL) {\n                for (frame = wmem_list_head(station_info->ioobject_data_out); frame != NULL; frame = wmem_list_frame_next(frame)) {\n                    io_data_object = (ioDataObject*)wmem_list_frame_data(frame);\n                    if (io_data_object != NULL && io_data_object->frameOffset == frameOffset) {\n                        /* Found following object */\n\n                        IODataObject_item = proto_tree_add_item(data_tree, hf_pn_io_io_data_object, tvb, offset, 0, ENC_NA);\n                        IODataObject_tree = proto_item_add_subtree(IODataObject_item, ett_pn_io_io_data_object);\n\n                        /* Control: the Device still uses the correct ModuleIdentNumber? */\n                        for (frame_diff = wmem_list_head(station_info->diff_module); frame_diff != NULL; frame_diff = wmem_list_frame_next(frame_diff)) {\n                            module_diff_info = (moduleDiffInfo*)wmem_list_frame_data(frame_diff);\n                            if (io_data_object->moduleIdentNr != module_diff_info->modulID) {\n                                ModuleDiff_item = proto_tree_add_item(IODataObject_tree, hf_pn_io_io_data_object_info_module_diff, tvb, 0, 0, ENC_NA);\n                                proto_item_append_text(ModuleDiff_item, \": Device using ModuleIdentNumber 0x%08x instead of 0x%08x\", module_diff_info->modulID, io_data_object->moduleIdentNr);\n                                break;\n                            }\n                        }\n\n                        proto_tree_add_uint(IODataObject_tree, hf_pn_io_io_data_object_info_moduleidentnumber, tvb, 0, 0, io_data_object->moduleIdentNr);\n                        proto_tree_add_uint(IODataObject_tree, hf_pn_io_io_data_object_info_submoduleidentnumber, tvb, 0, 0, io_data_object->subModuleIdentNr);\n\n                        if (io_data_object->profisafeSupported == TRUE && pnio_ps_selection == TRUE) {\n                            if (io_data_object->profisafeSupported == TRUE && psInfoText == FALSE) {\n                                /* Only add one information string per device to the infotext */\n                                col_append_str(pinfo->cinfo, COL_INFO, \", PROFIsafe Device\");    /* Add string to wireshark infotext */\n                                psInfoText = TRUE;\n                            }\n\n                            proto_tree_add_uint(IODataObject_tree, hf_pn_io_ps_f_dest_adr, tvb, 0, 0, io_data_object->f_dest_adr);\n\n                            /* Get Safety IO Data */\n                            if ((io_data_object->length - F_MESSAGE_TRAILER_4BYTE) > 0) {\n                                offset = dissect_pn_io_ps_uint(tvb, offset, pinfo, IODataObject_tree, drep, hf_pn_io_ps_f_data,\n                                    (io_data_object->length - F_MESSAGE_TRAILER_4BYTE), &f_data);\n                            }\n\n                            /* ---- Check for new PNIO data using togglebit ---- */\n                            controlbyte = tvb_get_guint8(tvb, offset);\n                            toggleBitCb = controlbyte & 0x20;               /* get ToggleBit of Controlbyte */\n\n                            if (io_data_object->lastToggleBit != toggleBitCb) {   /* ToggleBit has changed --> new Data incoming */\n                                /* Special Filter for ToggleBit within Controlbyte */\n                                ModuleID_item = proto_tree_add_uint_format_value(IODataObject_tree, hf_pn_io_ps_cb_toggelBitChanged, tvb, offset, 0,\n                                    toggleBitCb, \"%u\", toggleBitCb);\n                                PROTO_ITEM_SET_HIDDEN(ModuleID_item);\n\n                                ModuleID_item = proto_tree_add_uint_format_value(IODataObject_tree, hf_pn_io_ps_cb_toggelBitChange_slot_nr, tvb, offset, 0,\n                                    io_data_object->slotNr, \"%u\", io_data_object->slotNr);\n                                PROTO_ITEM_SET_HIDDEN(ModuleID_item);\n\n                                ModuleID_item = proto_tree_add_uint_format_value(IODataObject_tree, hf_pn_io_ps_cb_toggelBitChange_subslot_nr, tvb, offset, 0,\n                                    io_data_object->subSlotNr, \"%u\", io_data_object->subSlotNr);\n                                PROTO_ITEM_SET_HIDDEN(ModuleID_item);\n                            }\n\n                            offset = dissect_pn_io_ps_CB(tvb, offset, pinfo, IODataObject_tree, drep, hf_pn_io_ps_cb, ps_cb_fields);\n                            offset = dissect_pn_user_data(tvb, offset, pinfo, IODataObject_tree, io_data_object->f_crc_len, \"CRC\");\n\n                            io_data_object->last_sb_cb = controlbyte;         /* save the value of current controlbyte */\n                            io_data_object->lastToggleBit = toggleBitCb;      /* save the value of current togglebit within controlbyte */\n                        }    /* End of PROFIsafe Module Handling */\n                        else {\n                            /* Module is not PROFIsafe supported */\n                            offset = dissect_pn_user_data(tvb, offset, pinfo, IODataObject_tree, io_data_object->length, \"IO Data\");\n                        }\n\n                        if (io_data_object->discardIOXS == FALSE) {\n                            offset = dissect_PNIO_IOxS(tvb, offset, pinfo, IODataObject_tree, drep, hf_pn_io_iops, ioxs_fields);\n                            proto_item_set_len(IODataObject_item, io_data_object->length + 1);        /* Length = Databytes + IOXS Byte */\n                        }\n                        else {\n                            proto_item_set_len(IODataObject_item, io_data_object->length);            /* Length = Databytes */\n                        }\n\n                        proto_item_append_text(IODataObject_item, \": Slot: 0x%x Subslot: 0x%x\",\n                            io_data_object->slotNr, io_data_object->subSlotNr);\n\n\n                        /* ModuleIdentNr appears not only once in GSD-file -> set module name more generally */\n                        if (io_data_object->amountInGSDML > 1) {    /* if ModuleIdentNr only appears once in GSD-file, use the found GSD-file-ModuleName, else ... */\n                            if (io_data_object->slotNr == 0) {\n                                moduleName = wmem_strbuf_new(wmem_packet_scope(), \"Headstation\");\n                            }\n                            else {\n                                moduleName = wmem_strbuf_new(wmem_packet_scope(), \"Module\");\n                            }\n\n                            if (io_data_object->profisafeSupported == TRUE) {\n                                /* PROFIsafe */\n                                if (io_data_object->length >= 5) {        /* 5 due to 3 CRC bytes &  1 status byte & (at least) 1 data byte */\n                                    wmem_strbuf_append(moduleName, \", DO\");\n                                }\n                                else {\n                                    wmem_strbuf_append(moduleName, \", DI\");\n                                }\n                            }\n                            else {\n                                /* PROFINET */\n                                if (io_data_object->length > 0) {\n                                    wmem_strbuf_append(moduleName, \", DO\");\n                                }\n                                else {\n                                    wmem_strbuf_append(moduleName, \", DI\");\n                                }\n                            }\n\n                            io_data_object->moduleNameStr = wmem_strdup(wmem_file_scope(), wmem_strbuf_get_str(moduleName));\n                        }\n\n                        proto_item_append_text(IODataObject_item, \" ModuleName: \\\"%s\\\"\", io_data_object->moduleNameStr);\n\n                        /* emphasize the PROFIsafe supported Modul */\n                        if (io_data_object->profisafeSupported == TRUE && pnio_ps_selection == TRUE) {\n                            proto_item_append_text(IODataObject_item, \" (PROFIsafe Module)\");\n                        }\n\n                        /* Set frameOffset to its new value, to find the next object */\n                        frameOffset = frameOffset + io_data_object->length; /* frameOffset = current value + data bytes */\n                        if (io_data_object->discardIOXS == FALSE) {\n                            frameOffset = frameOffset + 1;      /* frameOffset = current value + iops byte */\n                        }\n                    }\n                }\n            }\n\n            /* ---- Output IOCS Object Handling ---- */\n            if (station_info != NULL) {\n                for (frame = wmem_list_head(station_info->iocs_data_out); frame != NULL; frame = wmem_list_frame_next(frame)) {\n                    iocs_object = (iocsObject*)wmem_list_frame_data(frame);\n                    if (iocs_object->frameOffset == frameOffset) {\n                        offset = dissect_PNIO_IOCS(tvb, offset, pinfo, data_tree, drep, hf_pn_io_iocs, iocs_object->slotNr,\n                            iocs_object->subSlotNr, ioxs_fields);\n\n                        /* Set frameOffset to its new value, to find the next object */\n                        frameOffset = frameOffset + 1;      /* frameOffset = current value + iops byte */\n\n                        break;\n                    }\n                }\n            }\n        }\n\n        /* Dissect padding */\n        offset = dissect_pn_user_data(tvb, offset, pinfo, tree, tvb_captured_length_remaining(tvb, offset), \"GAP and RTCPadding\");\n    }   /* END of Output Frame Handling */\n\n    return offset;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -11,6 +11,7 @@\n     gboolean    outputFlag;\n     gboolean    psInfoText;     /* Used to display only once per frame the info text \"PROFIsafe Device\" */\n \n+    proto_item *data_item;\n     proto_item *IODataObject_item;\n     proto_item *IODataObject_item_info;\n     proto_tree *IODataObject_tree;\n@@ -52,12 +53,9 @@\n \n     col_set_str(pinfo->cinfo, COL_PROTOCOL, \"PNIO\");            /* set protocol name */\n \n-    if (tree) {\n-        proto_item *data_item;\n-        data_item = proto_tree_add_protocol_format(tree, proto_pn_io_rtc1, tvb, offset, tvb_captured_length(tvb),\n+    data_item = proto_tree_add_protocol_format(tree, proto_pn_io_rtc1, tvb, offset, tvb_captured_length(tvb),\n             \"PROFINET IO Cyclic Service Data Unit: %u bytes\", tvb_captured_length(tvb));\n-        data_tree = proto_item_add_subtree(data_item, ett_pn_io_rtc);\n-    }\n+    data_tree = proto_item_add_subtree(data_item, ett_pn_io_rtc);\n \n     /* dissect_dcerpc_uint16(tvb, offset, pinfo, data_tree, drep, hf_pn_io_packedframe_SFCRC, &u16SFCRC); */\n     if (!(dissect_CSF_SDU_heur(tvb, pinfo, data_tree, NULL) == FALSE))\n@@ -133,6 +131,11 @@\n \n         /* ---- Input IOData-/IOCS-Object Handling ---- */\n         objectCounter = number_io_data_objects_input_cr + number_iocs_input_cr;\n+        if (objectCounter > (guint)tvb_reported_length_remaining(tvb, offset)) {\n+            expert_add_info_format(pinfo, data_item, &ei_pn_io_too_many_data_objects, \"Too many data objects: %d\", objectCounter);\n+            return(tvb_captured_length(tvb));\n+        }\n+\n         while (objectCounter--) {\n             /* ---- Input IO Data Object Handling ---- */\n             if (station_info != NULL) {\n@@ -328,6 +331,10 @@\n \n         /* ---- Output IOData-/IOCS-Object Handling ---- */\n         objectCounter = number_io_data_objects_output_cr + number_iocs_output_cr;\n+        if (objectCounter > (guint)tvb_reported_length_remaining(tvb, offset)) {\n+            expert_add_info_format(pinfo, data_item, &ei_pn_io_too_many_data_objects, \"Too many data objects: %d\", objectCounter);\n+            return(tvb_captured_length(tvb));\n+        }\n         while (objectCounter--) {\n             /* ---- Output IO Data Object Handling ---- */\n             if (station_info != NULL) {",
        "diff_line_info": {
            "deleted_lines": [
                "    if (tree) {",
                "        proto_item *data_item;",
                "        data_item = proto_tree_add_protocol_format(tree, proto_pn_io_rtc1, tvb, offset, tvb_captured_length(tvb),",
                "        data_tree = proto_item_add_subtree(data_item, ett_pn_io_rtc);",
                "    }"
            ],
            "added_lines": [
                "    proto_item *data_item;",
                "    data_item = proto_tree_add_protocol_format(tree, proto_pn_io_rtc1, tvb, offset, tvb_captured_length(tvb),",
                "    data_tree = proto_item_add_subtree(data_item, ett_pn_io_rtc);",
                "        if (objectCounter > (guint)tvb_reported_length_remaining(tvb, offset)) {",
                "            expert_add_info_format(pinfo, data_item, &ei_pn_io_too_many_data_objects, \"Too many data objects: %d\", objectCounter);",
                "            return(tvb_captured_length(tvb));",
                "        }",
                "",
                "        if (objectCounter > (guint)tvb_reported_length_remaining(tvb, offset)) {",
                "            expert_add_info_format(pinfo, data_item, &ei_pn_io_too_many_data_objects, \"Too many data objects: %d\", objectCounter);",
                "            return(tvb_captured_length(tvb));",
                "        }"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-9374",
        "func_name": "wireshark/handle_message_body_parameters",
        "description": "In Wireshark 2.2.0 to 2.2.1 and 2.0.0 to 2.0.7, the AllJoyn dissector could crash with a buffer over-read, triggered by network traffic or a capture file. This was addressed in epan/dissectors/packet-alljoyn.c by ensuring that a length variable properly tracked the state of a signature variable.",
        "git_url": "https://github.com/wireshark/wireshark/commit/a5770b6559b6e6765c4ef800e85ae42781ea4900",
        "commit_title": "alljoyn: fix signature length adjustments",
        "commit_text": " Ensure that the signature pointer and length always matches, otherwise a buffer overrun (read) is possible.  Tested with the original captures from bug 12953, the PDML output is still the same while the fuzzed capture does not crash anymore.  Bug: 12953 (cherry picked from commit 7dfaec969e67e3aa14b9763d804802ef614c9ddd)  [Peter: resolved conflicts in context]",
        "func_before": "static gint\nhandle_message_body_parameters(tvbuff_t    *tvb,\n                               packet_info *pinfo,\n                               proto_tree  *header_tree,\n                               guint       encoding,\n                               gint        offset,\n                               gint32      body_length,\n                               guint8      *signature,\n                               guint8      signature_length)\n{\n    gint        packet_length, end_of_body;\n    proto_tree *tree;\n    proto_item *item;\n    const gint  starting_offset = offset;\n\n    packet_length = tvb_reported_length(tvb);\n\n    /* Add a subtree/row for the message body parameters. */\n    item = proto_tree_add_item(header_tree, hf_alljoyn_mess_body_parameters, tvb, offset, body_length, ENC_NA);\n    tree = proto_item_add_subtree(item, ett_alljoyn_mess_body_parameters);\n\n    end_of_body = offset + body_length;\n\n    if(end_of_body > packet_length) {\n        end_of_body = packet_length;\n    }\n\n    while(offset < end_of_body && signature && *signature) {\n        offset = parse_arg(tvb,\n                           pinfo,\n                           NULL,\n                           encoding,\n                           offset,\n                           tree,    /* Add the args to the Parameters tree. */\n                           FALSE,\n                           *signature,\n                           HDR_INVALID,\n                           &signature,\n                           &signature_length,\n                           starting_offset);\n    }\n\n    return offset;\n}",
        "func": "static gint\nhandle_message_body_parameters(tvbuff_t    *tvb,\n                               packet_info *pinfo,\n                               proto_tree  *header_tree,\n                               guint       encoding,\n                               gint        offset,\n                               gint32      body_length,\n                               guint8      *signature,\n                               guint8      signature_length)\n{\n    gint        packet_length, end_of_body;\n    proto_tree *tree;\n    proto_item *item;\n    const gint  starting_offset = offset;\n\n    packet_length = tvb_reported_length(tvb);\n\n    /* Add a subtree/row for the message body parameters. */\n    item = proto_tree_add_item(header_tree, hf_alljoyn_mess_body_parameters, tvb, offset, body_length, ENC_NA);\n    tree = proto_item_add_subtree(item, ett_alljoyn_mess_body_parameters);\n\n    end_of_body = offset + body_length;\n\n    if(end_of_body > packet_length) {\n        end_of_body = packet_length;\n    }\n\n    while(offset < end_of_body && signature_length > 0 && signature && *signature) {\n        offset = parse_arg(tvb,\n                           pinfo,\n                           NULL,\n                           encoding,\n                           offset,\n                           tree,    /* Add the args to the Parameters tree. */\n                           FALSE,\n                           *signature,\n                           HDR_INVALID,\n                           &signature,\n                           &signature_length,\n                           starting_offset);\n    }\n\n    return offset;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -25,7 +25,7 @@\n         end_of_body = packet_length;\n     }\n \n-    while(offset < end_of_body && signature && *signature) {\n+    while(offset < end_of_body && signature_length > 0 && signature && *signature) {\n         offset = parse_arg(tvb,\n                            pinfo,\n                            NULL,",
        "diff_line_info": {
            "deleted_lines": [
                "    while(offset < end_of_body && signature && *signature) {"
            ],
            "added_lines": [
                "    while(offset < end_of_body && signature_length > 0 && signature && *signature) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-9374",
        "func_name": "wireshark/parse_arg",
        "description": "In Wireshark 2.2.0 to 2.2.1 and 2.0.0 to 2.0.7, the AllJoyn dissector could crash with a buffer over-read, triggered by network traffic or a capture file. This was addressed in epan/dissectors/packet-alljoyn.c by ensuring that a length variable properly tracked the state of a signature variable.",
        "git_url": "https://github.com/wireshark/wireshark/commit/a5770b6559b6e6765c4ef800e85ae42781ea4900",
        "commit_title": "alljoyn: fix signature length adjustments",
        "commit_text": " Ensure that the signature pointer and length always matches, otherwise a buffer overrun (read) is possible.  Tested with the original captures from bug 12953, the PDML output is still the same while the fuzzed capture does not crash anymore.  Bug: 12953 (cherry picked from commit 7dfaec969e67e3aa14b9763d804802ef614c9ddd)  [Peter: resolved conflicts in context]",
        "func_before": "static gint\nparse_arg(tvbuff_t     *tvb,\n          packet_info  *pinfo,\n          proto_item   *header_item,\n          guint         encoding,\n          gint          offset,\n          proto_tree   *field_tree,\n          gboolean      is_reply_to,\n          guint8        type_id,\n          guint8        field_code,\n          guint8      **signature,\n          guint8       *signature_length,\n          gint          field_starting_offset)\n{\n    gint length;\n    gint padding_start;\n    gint saved_offset = offset;\n    const gchar *header_type_name = NULL;\n\n    switch(type_id)\n    {\n    case ARG_INVALID:\n        header_type_name = \"invalid\";\n        offset = round_to_8byte(offset + 1, field_starting_offset);\n        break;\n\n    case ARG_ARRAY:      /* AllJoyn array container type */\n        {\n            static gchar  bad_array_format[]  = \"BAD DATA: Array length (in bytes) is %d. Remaining packet length is %d.\";\n            proto_item   *item;\n            proto_tree   *tree;\n            guint8       *sig_saved;\n            gint          starting_offset;\n            gint          number_of_items      = 0;\n            guint8        remaining_sig_length = *signature_length;\n            gint          packet_length        = (gint)tvb_reported_length(tvb);\n\n            header_type_name = \"array\";\n\n            if(*signature == NULL || *signature_length < 1) {\n                col_add_fstr(pinfo->cinfo, COL_INFO, \"BAD DATA: A %s argument needs a signature.\", header_type_name);\n                return tvb_reported_length(tvb);\n            }\n\n            /* *sig_saved will now be the element type after the 'a'. */\n            sig_saved = (*signature) + 1;\n\n            padding_start = offset;\n            offset = round_to_4byte(offset, field_starting_offset);\n            add_padding_item(padding_start, offset, tvb, field_tree);\n\n            /* This is the length of the entire array in bytes but does not include the length field. */\n            length = (gint)get_uint32(tvb, offset, encoding);\n\n            padding_start = offset + 4;\n            starting_offset = pad_according_to_type(padding_start, field_starting_offset, packet_length, *sig_saved); /* Advance to the data elements. */\n\n            if(length < 0 || length > MAX_ARRAY_LEN || starting_offset + length > packet_length) {\n                col_add_fstr(pinfo->cinfo, COL_INFO, bad_array_format, length, tvb_reported_length_remaining(tvb, starting_offset));\n                return tvb_reported_length(tvb);\n            }\n\n            /* This item is the entire array including the length specifier plus any pad bytes. */\n            item = proto_tree_add_item(field_tree, hf_alljoyn_mess_body_array, tvb, offset, (starting_offset-offset) + length, encoding);\n            tree = proto_item_add_subtree(item, ett_alljoyn_mess_body_parameters);\n\n            offset = starting_offset;\n            add_padding_item(padding_start, offset, tvb, tree);\n\n            if(0 == length) {\n                advance_to_end_of_signature(signature, &remaining_sig_length);\n            } else {\n                while((offset - starting_offset) < length) {\n                    guint8 *sig_pointer;\n\n                    number_of_items++;\n                    sig_pointer = sig_saved;\n                    remaining_sig_length = *signature_length - 1;\n\n                    offset = parse_arg(tvb,\n                                       pinfo,\n                                       header_item,\n                                       encoding,\n                                       offset,\n                                       tree,\n                                       is_reply_to,\n                                       *sig_pointer,\n                                       field_code,\n                                       &sig_pointer,\n                                       &remaining_sig_length,\n                                       field_starting_offset);\n\n                    /* Set the signature pointer to be just past the type just handled. */\n                    *signature = sig_pointer;\n                }\n            }\n\n            *signature_length = remaining_sig_length;\n\n            if(item) {\n                proto_item_append_text(item, \" of %d '%c' elements\", number_of_items, *sig_saved);\n            }\n        }\n        break;\n\n    case ARG_BOOLEAN:    /* AllJoyn boolean basic type */\n        header_type_name = \"boolean\";\n        padding_start = offset;\n        offset = round_to_4byte(offset, field_starting_offset);\n        add_padding_item(padding_start, offset, tvb, field_tree);\n\n        proto_tree_add_item(field_tree, hf_alljoyn_boolean, tvb, offset, 4, encoding);\n        offset += 4;\n        break;\n\n    case ARG_DOUBLE:     /* AllJoyn IEEE 754 double basic type */\n        header_type_name = \"IEEE 754 double\";\n        padding_start = offset;\n        offset = round_to_8byte(offset, field_starting_offset);\n        add_padding_item(padding_start, offset, tvb, field_tree);\n\n        proto_tree_add_item(field_tree, hf_alljoyn_double, tvb, offset, 8, encoding);\n        offset += 8;\n        break;\n\n    case ARG_SIGNATURE:  /* AllJoyn signature basic type */\n        header_type_name  = \"signature\";\n        *signature_length = tvb_get_guint8(tvb, offset);\n\n        if(*signature_length + 2 > tvb_reported_length_remaining(tvb, offset)) {\n            gint bytes_left = tvb_reported_length_remaining(tvb, offset);\n\n            col_add_fstr(pinfo->cinfo, COL_INFO, \"BAD DATA: Signature length is %d. Only %d bytes left in packet.\",\n                         (gint)(*signature_length), bytes_left);\n            return tvb_reported_length(tvb);\n        }\n\n        /* Include the terminating '/0'. */\n        length = *signature_length + 1;\n\n        proto_tree_add_item(field_tree, hf_alljoyn_mess_body_signature_length, tvb, offset, 1, encoding);\n        offset += 1;\n\n        proto_tree_add_item(field_tree, hf_alljoyn_mess_body_signature, tvb, offset, length, ENC_ASCII|ENC_NA);\n\n        *signature = tvb_get_string_enc(wmem_packet_scope(), tvb, offset, length, ENC_ASCII);\n\n        if(HDR_SIGNATURE == field_code) {\n            col_append_fstr(pinfo->cinfo, COL_INFO, \" (%s)\", *signature);\n        }\n\n        offset += length;\n        break;\n\n    case ARG_HANDLE:     /* AllJoyn socket handle basic type. */\n        header_type_name = \"socket handle\";\n        padding_start = offset;\n        offset = round_to_4byte(offset, field_starting_offset);\n        add_padding_item(padding_start, offset, tvb, field_tree);\n\n        proto_tree_add_item(field_tree, hf_alljoyn_handle, tvb, offset, 4, encoding);\n        offset += 4;\n        break;\n\n    case ARG_INT32:      /* AllJoyn 32-bit signed integer basic type. */\n        header_type_name = \"int32\";\n        padding_start = offset;\n        offset = round_to_4byte(offset, field_starting_offset);\n        add_padding_item(padding_start, offset, tvb, field_tree);\n\n        proto_tree_add_item(field_tree, hf_alljoyn_int32, tvb, offset, 4, encoding);\n        offset += 4;\n        break;\n\n    case ARG_INT16:      /* AllJoyn 16-bit signed integer basic type. */\n        header_type_name = \"int16\";\n        padding_start = offset;\n        offset = round_to_2byte(offset, field_starting_offset);\n        add_padding_item(padding_start, offset, tvb, field_tree);\n\n        proto_tree_add_item(field_tree, hf_alljoyn_int16, tvb, offset, 2, encoding);\n        offset += 2;\n        break;\n\n    case ARG_OBJ_PATH:   /* AllJoyn Name of an AllJoyn object instance basic type */\n        header_type_name = \"object path\";\n        length = get_uint32(tvb, offset, encoding) + 1;\n\n        /* The + 4 is for the length specifier. Object pathes may be of \"any length\"\n           according to D-Bus spec. But there are practical limits. */\n        if(length < 0 || length > MAX_ARRAY_LEN || length + 4 > tvb_reported_length_remaining(tvb, offset)) {\n            col_add_fstr(pinfo->cinfo, COL_INFO, \"BAD DATA: Object path length is %d. Only %d bytes left in packet.\",\n                length, tvb_reported_length_remaining(tvb, offset + 4));\n            return tvb_reported_length(tvb);\n        }\n\n        proto_tree_add_item(field_tree, hf_alljoyn_uint32, tvb, offset, 4, encoding);\n        offset += 4;\n\n        proto_tree_add_item(field_tree, hf_alljoyn_string_data, tvb, offset, length, ENC_ASCII|ENC_NA);\n        offset += length;\n        break;\n\n    case ARG_UINT16:     /* AllJoyn 16-bit unsigned integer basic type */\n        header_type_name = \"uint16\";\n        padding_start = offset;\n        offset = round_to_2byte(offset, field_starting_offset);\n        add_padding_item(padding_start, offset, tvb, field_tree);\n\n        proto_tree_add_item(field_tree, hf_alljoyn_uint16, tvb, offset, 2, encoding);\n        offset += 2;\n        break;\n\n    case ARG_STRING:     /* AllJoyn UTF-8 NULL terminated string basic type */\n        header_type_name = \"string\";\n        padding_start = offset;\n        offset = round_to_4byte(offset, field_starting_offset);\n        add_padding_item(padding_start, offset, tvb, field_tree);\n\n        proto_tree_add_item(field_tree, hf_alljoyn_string_size_32bit, tvb, offset, 4, encoding);\n\n        /* Get the length so we can display the string. */\n        length = (gint)get_uint32(tvb, offset, encoding);\n\n        if(length < 0 || length > tvb_reported_length_remaining(tvb, offset)) {\n            col_add_fstr(pinfo->cinfo, COL_INFO, \"BAD DATA: String length is %d. Remaining packet length is %d.\",\n                length, (gint)tvb_reported_length_remaining(tvb, offset));\n            return tvb_reported_length(tvb);\n        }\n\n        length += 1;    /* Include the '\\0'. */\n        offset += 4;\n\n        proto_tree_add_item(field_tree, hf_alljoyn_string_data, tvb, offset, length, ENC_UTF_8|ENC_NA);\n\n        if(HDR_MEMBER == field_code) {\n            guint8 *member_name;\n\n            member_name = tvb_get_string_enc(wmem_packet_scope(), tvb, offset, length, ENC_UTF_8);\n            col_append_fstr(pinfo->cinfo, COL_INFO, \" %s\", member_name);\n        }\n\n        offset += length;\n        break;\n\n    case ARG_UINT64:     /* AllJoyn 64-bit unsigned integer basic type */\n        header_type_name = \"uint64\";\n        padding_start = offset;\n        offset = round_to_8byte(offset, field_starting_offset);\n        add_padding_item(padding_start, offset, tvb, field_tree);\n\n        proto_tree_add_item(field_tree, hf_alljoyn_uint64, tvb, offset, 8, encoding);\n        offset += 8;\n        break;\n\n    case ARG_UINT32:     /* AllJoyn 32-bit unsigned integer basic type */\n        header_type_name = \"uint32\";\n        padding_start = offset;\n        offset = round_to_4byte(offset, field_starting_offset);\n        add_padding_item(padding_start, offset, tvb, field_tree);\n\n        if(is_reply_to) {\n            static const gchar format[] = \" Replies to: %09u\";\n            guint32 replies_to;\n\n            replies_to = get_uint32(tvb, offset, encoding);\n            col_append_fstr(pinfo->cinfo, COL_INFO, format, replies_to);\n\n            if(header_item) {\n                proto_item *item;\n\n                item = proto_tree_add_item(field_tree, hf_alljoyn_uint32, tvb, offset, 4, encoding);\n                proto_item_set_text(item, format + 1, replies_to);\n            }\n        } else {\n            proto_tree_add_item(field_tree, hf_alljoyn_uint32, tvb, offset, 4, encoding);\n        }\n\n        offset += 4;\n        break;\n\n    case ARG_VARIANT:    /* AllJoyn variant container type */\n        {\n            proto_item *item;\n            proto_tree *tree;\n            guint8     *sig_saved;\n            guint8     *sig_pointer;\n            guint8      variant_sig_length;\n\n            header_type_name = \"variant\";\n\n            variant_sig_length = tvb_get_guint8(tvb, offset);\n            length = variant_sig_length;\n\n            if(length > tvb_reported_length_remaining(tvb, offset)) {\n                gint bytes_left = tvb_reported_length_remaining(tvb, offset);\n\n                col_add_fstr(pinfo->cinfo, COL_INFO, \"BAD DATA: Variant signature length is %d. Only %d bytes left in packet.\",\n                             length, bytes_left);\n                offset = tvb_reported_length(tvb);\n            }\n\n            length += 1;    /* Include the terminating '\\0'. */\n\n            /* This length (4) will be updated later with the length of the entire variant object. */\n            item = proto_tree_add_item(field_tree, hf_alljoyn_mess_body_variant, tvb, offset, 4, encoding);\n            tree = proto_item_add_subtree(item, ett_alljoyn_mess_body_parameters);\n\n            proto_tree_add_item(tree, hf_alljoyn_mess_body_signature_length, tvb, offset, 1, encoding);\n\n            offset += 1;\n\n            tree = proto_item_add_subtree(item, ett_alljoyn_mess_body_parameters);\n            proto_tree_add_item(tree, hf_alljoyn_mess_body_signature, tvb, offset, length, ENC_ASCII|ENC_NA);\n\n            sig_saved = tvb_get_string_enc(wmem_packet_scope(), tvb, offset, length, ENC_ASCII);\n\n            offset += length;\n            sig_pointer = sig_saved;\n\n            /* The signature of the variant has now been taken care of.  So now take care of the variant data. */\n            while(((sig_pointer - sig_saved) < (length - 1)) && (tvb_reported_length_remaining(tvb, offset) > 0)) {\n                proto_item_append_text(item, \"%c\", *sig_pointer);\n\n                offset = parse_arg(tvb, pinfo, header_item, encoding, offset, tree, is_reply_to,\n                                   *sig_pointer, field_code, &sig_pointer, &variant_sig_length, field_starting_offset);\n            }\n\n            proto_item_append_text(item, \"'\");\n            proto_item_set_end(item, tvb, offset);\n        }\n        break;\n\n    case ARG_INT64:      /* AllJoyn 64-bit signed integer basic type */\n        header_type_name = \"int64\";\n        padding_start = offset;\n        offset = round_to_8byte(offset, field_starting_offset);\n        add_padding_item(padding_start, offset, tvb, field_tree);\n\n        proto_tree_add_item(field_tree, hf_alljoyn_int64, tvb, offset, 8, encoding);\n        offset += 8;\n        break;\n\n    case ARG_BYTE:       /* AllJoyn 8-bit unsigned integer basic type */\n        header_type_name = \"byte\";\n\n        proto_tree_add_item(field_tree, hf_alljoyn_uint8, tvb, offset, 1, encoding);\n        offset += 1;\n        break;\n\n    case ARG_DICT_ENTRY: /* AllJoyn dictionary or map container type - an array of key-value pairs */\n    case ARG_STRUCT:     /* AllJoyn struct container type */\n        {\n            proto_item *item;\n            proto_tree *tree;\n            int         hf;\n            guint8      type_stop;\n\n            if(type_id == ARG_STRUCT) {\n                header_type_name = \"structure\";\n                hf = hf_alljoyn_mess_body_structure;\n                type_stop = ')';\n            } else {\n                header_type_name = \"dictionary\";\n                hf = hf_alljoyn_mess_body_dictionary_entry;\n                type_stop = '}';\n            }\n\n            if(*signature == NULL || *signature_length < 1) {\n                col_add_fstr(pinfo->cinfo, COL_INFO, \"BAD DATA: A %s argument needs a signature.\", header_type_name);\n                return tvb_reported_length(tvb);\n            }\n\n            /* This length (4) will be updated later with the length of the entire struct. */\n            item = proto_tree_add_item(field_tree, hf, tvb, offset, 4, encoding);\n            append_struct_signature(item, *signature, *signature_length, type_stop);\n            tree = proto_item_add_subtree(item, ett_alljoyn_mess_body_parameters);\n\n            padding_start = offset;\n            offset = pad_according_to_type(offset, field_starting_offset, tvb_reported_length(tvb), type_id);\n            add_padding_item(padding_start, offset, tvb, tree);\n\n            (*signature)++; /* Advance past the '(' or '{'. */\n            (*signature_length)--;\n\n            /* *signature should never be NULL but just make sure to avoid potential issues. */\n            while(*signature && **signature && **signature != type_stop\n                    && tvb_reported_length_remaining(tvb, offset) > 0) {\n                offset = parse_arg(tvb,\n                                   pinfo,\n                                   header_item,\n                                   encoding,\n                                   offset,\n                                   tree,\n                                   is_reply_to,\n                                   **signature,\n                                   field_code,\n                                   signature,\n                                   signature_length,\n                                   field_starting_offset);\n            }\n\n            proto_item_set_end(item, tvb, offset);\n        }\n        break;\n\n    default:\n        header_type_name = \"unexpected\";\n        /* Just say we are done with this packet. */\n        offset = tvb_reported_length(tvb);\n        break;\n    }\n\n    if(*signature && ARG_ARRAY != type_id && HDR_INVALID == field_code) {\n        (*signature)++;\n        (*signature_length)--;\n    }\n\n    if(NULL != header_item && NULL != header_type_name) {\n        /* Using \"%s\" and the argument \"header_type_name\" because some compilers don't like\n           \"header_type_name\" by itself. */\n        proto_item_append_text(header_item, \"%s\", header_type_name);\n    }\n\n    /* Make sure we never return something longer than the buffer for an offset. */\n    if(offset > (gint)tvb_reported_length(tvb)) {\n        offset = (gint)tvb_reported_length(tvb);\n    } else if (offset == saved_offset) {\n        /* The argument has a null size. Let's report the packet length to avoid an infinite loop. */\n        /*expert_add_info(pinfo, header_item, &ei_alljoyn_empty_arg);*/\n        proto_tree_add_expert(field_tree, pinfo, &ei_alljoyn_empty_arg, tvb, offset, 0);\n        offset = (gint)tvb_reported_length(tvb);\n    }\n\n    return offset;\n}",
        "func": "static gint\nparse_arg(tvbuff_t     *tvb,\n          packet_info  *pinfo,\n          proto_item   *header_item,\n          guint         encoding,\n          gint          offset,\n          proto_tree   *field_tree,\n          gboolean      is_reply_to,\n          guint8        type_id,\n          guint8        field_code,\n          guint8      **signature,\n          guint8       *signature_length,\n          gint          field_starting_offset)\n{\n    gint length;\n    gint padding_start;\n    gint saved_offset = offset;\n    const gchar *header_type_name = NULL;\n\n    switch(type_id)\n    {\n    case ARG_INVALID:\n        header_type_name = \"invalid\";\n        offset = round_to_8byte(offset + 1, field_starting_offset);\n        break;\n\n    case ARG_ARRAY:      /* AllJoyn array container type */\n        {\n            static gchar  bad_array_format[]  = \"BAD DATA: Array length (in bytes) is %d. Remaining packet length is %d.\";\n            proto_item   *item;\n            proto_tree   *tree;\n            guint8       *sig_saved;\n            gint          starting_offset;\n            gint          number_of_items      = 0;\n            gint          packet_length        = (gint)tvb_reported_length(tvb);\n\n            header_type_name = \"array\";\n\n            if(*signature == NULL || *signature_length < 1) {\n                col_add_fstr(pinfo->cinfo, COL_INFO, \"BAD DATA: A %s argument needs a signature.\", header_type_name);\n                return tvb_reported_length(tvb);\n            }\n\n            /* *sig_saved will now be the element type after the 'a'. */\n            sig_saved = (*signature) + 1;\n\n            padding_start = offset;\n            offset = round_to_4byte(offset, field_starting_offset);\n            add_padding_item(padding_start, offset, tvb, field_tree);\n\n            /* This is the length of the entire array in bytes but does not include the length field. */\n            length = (gint)get_uint32(tvb, offset, encoding);\n\n            padding_start = offset + 4;\n            starting_offset = pad_according_to_type(padding_start, field_starting_offset, packet_length, *sig_saved); /* Advance to the data elements. */\n\n            if(length < 0 || length > MAX_ARRAY_LEN || starting_offset + length > packet_length) {\n                col_add_fstr(pinfo->cinfo, COL_INFO, bad_array_format, length, tvb_reported_length_remaining(tvb, starting_offset));\n                return tvb_reported_length(tvb);\n            }\n\n            /* This item is the entire array including the length specifier plus any pad bytes. */\n            item = proto_tree_add_item(field_tree, hf_alljoyn_mess_body_array, tvb, offset, (starting_offset-offset) + length, encoding);\n            tree = proto_item_add_subtree(item, ett_alljoyn_mess_body_parameters);\n\n            offset = starting_offset;\n            add_padding_item(padding_start, offset, tvb, tree);\n\n            if(0 == length) {\n                advance_to_end_of_signature(signature, signature_length);\n            } else {\n                guint8 sig_length_saved = *signature_length - 1;\n\n                while((offset - starting_offset) < length) {\n                    guint8 *sig_pointer;\n                    guint8        remaining_sig_length;\n\n                    number_of_items++;\n                    sig_pointer = sig_saved;\n                    remaining_sig_length = sig_length_saved;\n\n                    offset = parse_arg(tvb,\n                                       pinfo,\n                                       header_item,\n                                       encoding,\n                                       offset,\n                                       tree,\n                                       is_reply_to,\n                                       *sig_pointer,\n                                       field_code,\n                                       &sig_pointer,\n                                       &remaining_sig_length,\n                                       field_starting_offset);\n\n                    /* Set the signature pointer to be just past the type just handled. */\n                    *signature = sig_pointer;\n                    *signature_length = remaining_sig_length;\n                }\n            }\n\n            if(item) {\n                proto_item_append_text(item, \" of %d '%c' elements\", number_of_items, *sig_saved);\n            }\n        }\n        break;\n\n    case ARG_BOOLEAN:    /* AllJoyn boolean basic type */\n        header_type_name = \"boolean\";\n        padding_start = offset;\n        offset = round_to_4byte(offset, field_starting_offset);\n        add_padding_item(padding_start, offset, tvb, field_tree);\n\n        proto_tree_add_item(field_tree, hf_alljoyn_boolean, tvb, offset, 4, encoding);\n        offset += 4;\n        break;\n\n    case ARG_DOUBLE:     /* AllJoyn IEEE 754 double basic type */\n        header_type_name = \"IEEE 754 double\";\n        padding_start = offset;\n        offset = round_to_8byte(offset, field_starting_offset);\n        add_padding_item(padding_start, offset, tvb, field_tree);\n\n        proto_tree_add_item(field_tree, hf_alljoyn_double, tvb, offset, 8, encoding);\n        offset += 8;\n        break;\n\n    case ARG_SIGNATURE:  /* AllJoyn signature basic type */\n        header_type_name  = \"signature\";\n        length = tvb_get_guint8(tvb, offset);\n\n        if (length + 2 > tvb_reported_length_remaining(tvb, offset)) {\n            gint bytes_left = tvb_reported_length_remaining(tvb, offset);\n\n            col_add_fstr(pinfo->cinfo, COL_INFO, \"BAD DATA: Signature length is %d. Only %d bytes left in packet.\",\n                         length, bytes_left);\n            return tvb_reported_length(tvb);\n        }\n\n        /* Include the terminating '/0'. */\n        length++;\n\n        proto_tree_add_item(field_tree, hf_alljoyn_mess_body_signature_length, tvb, offset, 1, encoding);\n        offset += 1;\n\n        /* Extract signature from tvb and return to caller. */\n        /* XXX should this extract \"length - 1\" since we always expect /0? */\n        proto_tree_add_item(field_tree, hf_alljoyn_mess_body_signature, tvb, offset, length, ENC_ASCII|ENC_NA);\n\n        *signature = tvb_get_string_enc(wmem_packet_scope(), tvb, offset, length, ENC_ASCII);\n        *signature_length = length;\n\n        if(HDR_SIGNATURE == field_code) {\n            col_append_fstr(pinfo->cinfo, COL_INFO, \" (%s)\", *signature);\n        }\n\n        offset += length;\n        break;\n\n    case ARG_HANDLE:     /* AllJoyn socket handle basic type. */\n        header_type_name = \"socket handle\";\n        padding_start = offset;\n        offset = round_to_4byte(offset, field_starting_offset);\n        add_padding_item(padding_start, offset, tvb, field_tree);\n\n        proto_tree_add_item(field_tree, hf_alljoyn_handle, tvb, offset, 4, encoding);\n        offset += 4;\n        break;\n\n    case ARG_INT32:      /* AllJoyn 32-bit signed integer basic type. */\n        header_type_name = \"int32\";\n        padding_start = offset;\n        offset = round_to_4byte(offset, field_starting_offset);\n        add_padding_item(padding_start, offset, tvb, field_tree);\n\n        proto_tree_add_item(field_tree, hf_alljoyn_int32, tvb, offset, 4, encoding);\n        offset += 4;\n        break;\n\n    case ARG_INT16:      /* AllJoyn 16-bit signed integer basic type. */\n        header_type_name = \"int16\";\n        padding_start = offset;\n        offset = round_to_2byte(offset, field_starting_offset);\n        add_padding_item(padding_start, offset, tvb, field_tree);\n\n        proto_tree_add_item(field_tree, hf_alljoyn_int16, tvb, offset, 2, encoding);\n        offset += 2;\n        break;\n\n    case ARG_OBJ_PATH:   /* AllJoyn Name of an AllJoyn object instance basic type */\n        header_type_name = \"object path\";\n        length = get_uint32(tvb, offset, encoding) + 1;\n\n        /* The + 4 is for the length specifier. Object pathes may be of \"any length\"\n           according to D-Bus spec. But there are practical limits. */\n        if(length < 0 || length > MAX_ARRAY_LEN || length + 4 > tvb_reported_length_remaining(tvb, offset)) {\n            col_add_fstr(pinfo->cinfo, COL_INFO, \"BAD DATA: Object path length is %d. Only %d bytes left in packet.\",\n                length, tvb_reported_length_remaining(tvb, offset + 4));\n            return tvb_reported_length(tvb);\n        }\n\n        proto_tree_add_item(field_tree, hf_alljoyn_uint32, tvb, offset, 4, encoding);\n        offset += 4;\n\n        proto_tree_add_item(field_tree, hf_alljoyn_string_data, tvb, offset, length, ENC_ASCII|ENC_NA);\n        offset += length;\n        break;\n\n    case ARG_UINT16:     /* AllJoyn 16-bit unsigned integer basic type */\n        header_type_name = \"uint16\";\n        padding_start = offset;\n        offset = round_to_2byte(offset, field_starting_offset);\n        add_padding_item(padding_start, offset, tvb, field_tree);\n\n        proto_tree_add_item(field_tree, hf_alljoyn_uint16, tvb, offset, 2, encoding);\n        offset += 2;\n        break;\n\n    case ARG_STRING:     /* AllJoyn UTF-8 NULL terminated string basic type */\n        header_type_name = \"string\";\n        padding_start = offset;\n        offset = round_to_4byte(offset, field_starting_offset);\n        add_padding_item(padding_start, offset, tvb, field_tree);\n\n        proto_tree_add_item(field_tree, hf_alljoyn_string_size_32bit, tvb, offset, 4, encoding);\n\n        /* Get the length so we can display the string. */\n        length = (gint)get_uint32(tvb, offset, encoding);\n\n        if(length < 0 || length > tvb_reported_length_remaining(tvb, offset)) {\n            col_add_fstr(pinfo->cinfo, COL_INFO, \"BAD DATA: String length is %d. Remaining packet length is %d.\",\n                length, (gint)tvb_reported_length_remaining(tvb, offset));\n            return tvb_reported_length(tvb);\n        }\n\n        length += 1;    /* Include the '\\0'. */\n        offset += 4;\n\n        proto_tree_add_item(field_tree, hf_alljoyn_string_data, tvb, offset, length, ENC_UTF_8|ENC_NA);\n\n        if(HDR_MEMBER == field_code) {\n            guint8 *member_name;\n\n            member_name = tvb_get_string_enc(wmem_packet_scope(), tvb, offset, length, ENC_UTF_8);\n            col_append_fstr(pinfo->cinfo, COL_INFO, \" %s\", member_name);\n        }\n\n        offset += length;\n        break;\n\n    case ARG_UINT64:     /* AllJoyn 64-bit unsigned integer basic type */\n        header_type_name = \"uint64\";\n        padding_start = offset;\n        offset = round_to_8byte(offset, field_starting_offset);\n        add_padding_item(padding_start, offset, tvb, field_tree);\n\n        proto_tree_add_item(field_tree, hf_alljoyn_uint64, tvb, offset, 8, encoding);\n        offset += 8;\n        break;\n\n    case ARG_UINT32:     /* AllJoyn 32-bit unsigned integer basic type */\n        header_type_name = \"uint32\";\n        padding_start = offset;\n        offset = round_to_4byte(offset, field_starting_offset);\n        add_padding_item(padding_start, offset, tvb, field_tree);\n\n        if(is_reply_to) {\n            static const gchar format[] = \" Replies to: %09u\";\n            guint32 replies_to;\n\n            replies_to = get_uint32(tvb, offset, encoding);\n            col_append_fstr(pinfo->cinfo, COL_INFO, format, replies_to);\n\n            if(header_item) {\n                proto_item *item;\n\n                item = proto_tree_add_item(field_tree, hf_alljoyn_uint32, tvb, offset, 4, encoding);\n                proto_item_set_text(item, format + 1, replies_to);\n            }\n        } else {\n            proto_tree_add_item(field_tree, hf_alljoyn_uint32, tvb, offset, 4, encoding);\n        }\n\n        offset += 4;\n        break;\n\n    case ARG_VARIANT:    /* AllJoyn variant container type */\n        {\n            proto_item *item;\n            proto_tree *tree;\n            guint8     *sig_saved;\n            guint8     *sig_pointer;\n            guint8      variant_sig_length;\n\n            header_type_name = \"variant\";\n\n            variant_sig_length = tvb_get_guint8(tvb, offset);\n            length = variant_sig_length;\n\n            if(length > tvb_reported_length_remaining(tvb, offset)) {\n                gint bytes_left = tvb_reported_length_remaining(tvb, offset);\n\n                col_add_fstr(pinfo->cinfo, COL_INFO, \"BAD DATA: Variant signature length is %d. Only %d bytes left in packet.\",\n                             length, bytes_left);\n                offset = tvb_reported_length(tvb);\n            }\n\n            length += 1;    /* Include the terminating '\\0'. */\n\n            /* This length (4) will be updated later with the length of the entire variant object. */\n            item = proto_tree_add_item(field_tree, hf_alljoyn_mess_body_variant, tvb, offset, 4, encoding);\n            tree = proto_item_add_subtree(item, ett_alljoyn_mess_body_parameters);\n\n            proto_tree_add_item(tree, hf_alljoyn_mess_body_signature_length, tvb, offset, 1, encoding);\n\n            offset += 1;\n\n            tree = proto_item_add_subtree(item, ett_alljoyn_mess_body_parameters);\n            proto_tree_add_item(tree, hf_alljoyn_mess_body_signature, tvb, offset, length, ENC_ASCII|ENC_NA);\n\n            sig_saved = tvb_get_string_enc(wmem_packet_scope(), tvb, offset, length, ENC_ASCII);\n\n            offset += length;\n            sig_pointer = sig_saved;\n\n            /* The signature of the variant has now been taken care of.  So now take care of the variant data. */\n            while(((sig_pointer - sig_saved) < (length - 1)) && (tvb_reported_length_remaining(tvb, offset) > 0)) {\n                proto_item_append_text(item, \"%c\", *sig_pointer);\n\n                offset = parse_arg(tvb, pinfo, header_item, encoding, offset, tree, is_reply_to,\n                                   *sig_pointer, field_code, &sig_pointer, &variant_sig_length, field_starting_offset);\n            }\n\n            proto_item_append_text(item, \"'\");\n            proto_item_set_end(item, tvb, offset);\n        }\n        break;\n\n    case ARG_INT64:      /* AllJoyn 64-bit signed integer basic type */\n        header_type_name = \"int64\";\n        padding_start = offset;\n        offset = round_to_8byte(offset, field_starting_offset);\n        add_padding_item(padding_start, offset, tvb, field_tree);\n\n        proto_tree_add_item(field_tree, hf_alljoyn_int64, tvb, offset, 8, encoding);\n        offset += 8;\n        break;\n\n    case ARG_BYTE:       /* AllJoyn 8-bit unsigned integer basic type */\n        header_type_name = \"byte\";\n\n        proto_tree_add_item(field_tree, hf_alljoyn_uint8, tvb, offset, 1, encoding);\n        offset += 1;\n        break;\n\n    case ARG_DICT_ENTRY: /* AllJoyn dictionary or map container type - an array of key-value pairs */\n    case ARG_STRUCT:     /* AllJoyn struct container type */\n        {\n            proto_item *item;\n            proto_tree *tree;\n            int         hf;\n            guint8      type_stop;\n\n            if(type_id == ARG_STRUCT) {\n                header_type_name = \"structure\";\n                hf = hf_alljoyn_mess_body_structure;\n                type_stop = ')';\n            } else {\n                header_type_name = \"dictionary\";\n                hf = hf_alljoyn_mess_body_dictionary_entry;\n                type_stop = '}';\n            }\n\n            if(*signature == NULL || *signature_length < 1) {\n                col_add_fstr(pinfo->cinfo, COL_INFO, \"BAD DATA: A %s argument needs a signature.\", header_type_name);\n                return tvb_reported_length(tvb);\n            }\n\n            /* This length (4) will be updated later with the length of the entire struct. */\n            item = proto_tree_add_item(field_tree, hf, tvb, offset, 4, encoding);\n            append_struct_signature(item, *signature, *signature_length, type_stop);\n            tree = proto_item_add_subtree(item, ett_alljoyn_mess_body_parameters);\n\n            padding_start = offset;\n            offset = pad_according_to_type(offset, field_starting_offset, tvb_reported_length(tvb), type_id);\n            add_padding_item(padding_start, offset, tvb, tree);\n\n            (*signature)++; /* Advance past the '(' or '{'. */\n            (*signature_length)--;\n\n            /* *signature should never be NULL but just make sure to avoid potential issues. */\n            while(*signature && **signature && **signature != type_stop\n                    && tvb_reported_length_remaining(tvb, offset) > 0) {\n                offset = parse_arg(tvb,\n                                   pinfo,\n                                   header_item,\n                                   encoding,\n                                   offset,\n                                   tree,\n                                   is_reply_to,\n                                   **signature,\n                                   field_code,\n                                   signature,\n                                   signature_length,\n                                   field_starting_offset);\n            }\n\n            proto_item_set_end(item, tvb, offset);\n        }\n        break;\n\n    default:\n        header_type_name = \"unexpected\";\n        /* Just say we are done with this packet. */\n        offset = tvb_reported_length(tvb);\n        break;\n    }\n\n    if (*signature && *signature_length > 0 && ARG_ARRAY != type_id && HDR_INVALID == field_code) {\n        (*signature)++;\n        (*signature_length)--;\n    }\n\n    if(NULL != header_item && NULL != header_type_name) {\n        /* Using \"%s\" and the argument \"header_type_name\" because some compilers don't like\n           \"header_type_name\" by itself. */\n        proto_item_append_text(header_item, \"%s\", header_type_name);\n    }\n\n    /* Make sure we never return something longer than the buffer for an offset. */\n    if(offset > (gint)tvb_reported_length(tvb)) {\n        offset = (gint)tvb_reported_length(tvb);\n    } else if (offset == saved_offset) {\n        /* The argument has a null size. Let's report the packet length to avoid an infinite loop. */\n        /*expert_add_info(pinfo, header_item, &ei_alljoyn_empty_arg);*/\n        proto_tree_add_expert(field_tree, pinfo, &ei_alljoyn_empty_arg, tvb, offset, 0);\n        offset = (gint)tvb_reported_length(tvb);\n    }\n\n    return offset;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -32,7 +32,6 @@\n             guint8       *sig_saved;\n             gint          starting_offset;\n             gint          number_of_items      = 0;\n-            guint8        remaining_sig_length = *signature_length;\n             gint          packet_length        = (gint)tvb_reported_length(tvb);\n \n             header_type_name = \"array\";\n@@ -68,14 +67,17 @@\n             add_padding_item(padding_start, offset, tvb, tree);\n \n             if(0 == length) {\n-                advance_to_end_of_signature(signature, &remaining_sig_length);\n+                advance_to_end_of_signature(signature, signature_length);\n             } else {\n+                guint8 sig_length_saved = *signature_length - 1;\n+\n                 while((offset - starting_offset) < length) {\n                     guint8 *sig_pointer;\n+                    guint8        remaining_sig_length;\n \n                     number_of_items++;\n                     sig_pointer = sig_saved;\n-                    remaining_sig_length = *signature_length - 1;\n+                    remaining_sig_length = sig_length_saved;\n \n                     offset = parse_arg(tvb,\n                                        pinfo,\n@@ -92,10 +94,9 @@\n \n                     /* Set the signature pointer to be just past the type just handled. */\n                     *signature = sig_pointer;\n+                    *signature_length = remaining_sig_length;\n                 }\n             }\n-\n-            *signature_length = remaining_sig_length;\n \n             if(item) {\n                 proto_item_append_text(item, \" of %d '%c' elements\", number_of_items, *sig_saved);\n@@ -125,25 +126,28 @@\n \n     case ARG_SIGNATURE:  /* AllJoyn signature basic type */\n         header_type_name  = \"signature\";\n-        *signature_length = tvb_get_guint8(tvb, offset);\n-\n-        if(*signature_length + 2 > tvb_reported_length_remaining(tvb, offset)) {\n+        length = tvb_get_guint8(tvb, offset);\n+\n+        if (length + 2 > tvb_reported_length_remaining(tvb, offset)) {\n             gint bytes_left = tvb_reported_length_remaining(tvb, offset);\n \n             col_add_fstr(pinfo->cinfo, COL_INFO, \"BAD DATA: Signature length is %d. Only %d bytes left in packet.\",\n-                         (gint)(*signature_length), bytes_left);\n+                         length, bytes_left);\n             return tvb_reported_length(tvb);\n         }\n \n         /* Include the terminating '/0'. */\n-        length = *signature_length + 1;\n+        length++;\n \n         proto_tree_add_item(field_tree, hf_alljoyn_mess_body_signature_length, tvb, offset, 1, encoding);\n         offset += 1;\n \n+        /* Extract signature from tvb and return to caller. */\n+        /* XXX should this extract \"length - 1\" since we always expect /0? */\n         proto_tree_add_item(field_tree, hf_alljoyn_mess_body_signature, tvb, offset, length, ENC_ASCII|ENC_NA);\n \n         *signature = tvb_get_string_enc(wmem_packet_scope(), tvb, offset, length, ENC_ASCII);\n+        *signature_length = length;\n \n         if(HDR_SIGNATURE == field_code) {\n             col_append_fstr(pinfo->cinfo, COL_INFO, \" (%s)\", *signature);\n@@ -411,7 +415,7 @@\n         break;\n     }\n \n-    if(*signature && ARG_ARRAY != type_id && HDR_INVALID == field_code) {\n+    if (*signature && *signature_length > 0 && ARG_ARRAY != type_id && HDR_INVALID == field_code) {\n         (*signature)++;\n         (*signature_length)--;\n     }",
        "diff_line_info": {
            "deleted_lines": [
                "            guint8        remaining_sig_length = *signature_length;",
                "                advance_to_end_of_signature(signature, &remaining_sig_length);",
                "                    remaining_sig_length = *signature_length - 1;",
                "",
                "            *signature_length = remaining_sig_length;",
                "        *signature_length = tvb_get_guint8(tvb, offset);",
                "",
                "        if(*signature_length + 2 > tvb_reported_length_remaining(tvb, offset)) {",
                "                         (gint)(*signature_length), bytes_left);",
                "        length = *signature_length + 1;",
                "    if(*signature && ARG_ARRAY != type_id && HDR_INVALID == field_code) {"
            ],
            "added_lines": [
                "                advance_to_end_of_signature(signature, signature_length);",
                "                guint8 sig_length_saved = *signature_length - 1;",
                "",
                "                    guint8        remaining_sig_length;",
                "                    remaining_sig_length = sig_length_saved;",
                "                    *signature_length = remaining_sig_length;",
                "        length = tvb_get_guint8(tvb, offset);",
                "",
                "        if (length + 2 > tvb_reported_length_remaining(tvb, offset)) {",
                "                         length, bytes_left);",
                "        length++;",
                "        /* Extract signature from tvb and return to caller. */",
                "        /* XXX should this extract \"length - 1\" since we always expect /0? */",
                "        *signature_length = length;",
                "    if (*signature && *signature_length > 0 && ARG_ARRAY != type_id && HDR_INVALID == field_code) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-9374",
        "func_name": "wireshark/advance_to_end_of_signature",
        "description": "In Wireshark 2.2.0 to 2.2.1 and 2.0.0 to 2.0.7, the AllJoyn dissector could crash with a buffer over-read, triggered by network traffic or a capture file. This was addressed in epan/dissectors/packet-alljoyn.c by ensuring that a length variable properly tracked the state of a signature variable.",
        "git_url": "https://github.com/wireshark/wireshark/commit/a5770b6559b6e6765c4ef800e85ae42781ea4900",
        "commit_title": "alljoyn: fix signature length adjustments",
        "commit_text": " Ensure that the signature pointer and length always matches, otherwise a buffer overrun (read) is possible.  Tested with the original captures from bug 12953, the PDML output is still the same while the fuzzed capture does not crash anymore.  Bug: 12953 (cherry picked from commit 7dfaec969e67e3aa14b9763d804802ef614c9ddd)  [Peter: resolved conflicts in context]",
        "func_before": "static void\nadvance_to_end_of_signature(guint8 **signature,\n                            guint8  *signature_length)\n{\n    gboolean done = FALSE;\n    gint8 current_type;\n    gint8 end_type = ARG_INVALID;\n\n    while(*(++(*signature)) && --(*signature_length) > 0 && !done) {\n        current_type = **signature;\n\n        /* Were we looking for the end of a structure or dictionary? If so, did we find it? */\n        if(end_type != ARG_INVALID) {\n            if(end_type == current_type) {\n                done = TRUE; /* Found the end of the structure or dictionary. All done. */\n            }\n\n            continue;\n        }\n\n        switch(current_type)\n        {\n        case ARG_ARRAY:\n            advance_to_end_of_signature(signature, signature_length);\n            break;\n        case ARG_STRUCT:\n            end_type = ')';\n            advance_to_end_of_signature(signature, signature_length);\n            break;\n        case ARG_DICT_ENTRY:\n            end_type = '}';\n            advance_to_end_of_signature(signature, signature_length);\n            break;\n\n        case ARG_BYTE:\n        case ARG_DOUBLE:\n        case ARG_UINT64:\n        case ARG_INT64:\n        case ARG_SIGNATURE:\n        case ARG_HANDLE:\n        case ARG_INT32:\n        case ARG_UINT32:\n        case ARG_BOOLEAN:\n        case ARG_INT16:\n        case ARG_UINT16:\n        case ARG_STRING:\n        case ARG_VARIANT:\n        case ARG_OBJ_PATH:\n            done = TRUE;\n            break;\n\n        default:    /* Unrecognized signature. Bail out. */\n            done = TRUE;\n            break;\n        }\n    }\n}",
        "func": "static void\nadvance_to_end_of_signature(guint8 **signature,\n                            guint8  *signature_length)\n{\n    gboolean done = FALSE;\n    gint8 current_type;\n    gint8 end_type = ARG_INVALID;\n\n    while (*signature_length > 0 && **signature && !done) {\n        current_type = *(++(*signature));\n        --*signature_length;\n\n        /* Were we looking for the end of a structure or dictionary? If so, did we find it? */\n        if(end_type != ARG_INVALID) {\n            if(end_type == current_type) {\n                done = TRUE; /* Found the end of the structure or dictionary. All done. */\n            }\n\n            continue;\n        }\n\n        switch(current_type)\n        {\n        case ARG_ARRAY:\n            advance_to_end_of_signature(signature, signature_length);\n            break;\n        case ARG_STRUCT:\n            end_type = ')';\n            advance_to_end_of_signature(signature, signature_length);\n            break;\n        case ARG_DICT_ENTRY:\n            end_type = '}';\n            advance_to_end_of_signature(signature, signature_length);\n            break;\n\n        case ARG_BYTE:\n        case ARG_DOUBLE:\n        case ARG_UINT64:\n        case ARG_INT64:\n        case ARG_SIGNATURE:\n        case ARG_HANDLE:\n        case ARG_INT32:\n        case ARG_UINT32:\n        case ARG_BOOLEAN:\n        case ARG_INT16:\n        case ARG_UINT16:\n        case ARG_STRING:\n        case ARG_VARIANT:\n        case ARG_OBJ_PATH:\n            done = TRUE;\n            break;\n\n        default:    /* Unrecognized signature. Bail out. */\n            done = TRUE;\n            break;\n        }\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -6,8 +6,9 @@\n     gint8 current_type;\n     gint8 end_type = ARG_INVALID;\n \n-    while(*(++(*signature)) && --(*signature_length) > 0 && !done) {\n-        current_type = **signature;\n+    while (*signature_length > 0 && **signature && !done) {\n+        current_type = *(++(*signature));\n+        --*signature_length;\n \n         /* Were we looking for the end of a structure or dictionary? If so, did we find it? */\n         if(end_type != ARG_INVALID) {",
        "diff_line_info": {
            "deleted_lines": [
                "    while(*(++(*signature)) && --(*signature_length) > 0 && !done) {",
                "        current_type = **signature;"
            ],
            "added_lines": [
                "    while (*signature_length > 0 && **signature && !done) {",
                "        current_type = *(++(*signature));",
                "        --*signature_length;"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-9375",
        "func_name": "wireshark/display_metadata_block",
        "description": "In Wireshark 2.2.0 to 2.2.1 and 2.0.0 to 2.0.7, the DTN dissector could go into an infinite loop, triggered by network traffic or a capture file. This was addressed in epan/dissectors/packet-dtn.c by checking whether SDNV evaluation was successful.",
        "git_url": "https://github.com/wireshark/wireshark/commit/be6a10afc59f8182b9884d02f9857d547539fe8a",
        "commit_title": "packet-dtn.c break loop if evaluate_sdnv doesn't succeed.",
        "commit_text": " Bug: 13097 (cherry picked from commit 63776db384f75b2dc793cab46cf27250d8913711) (cherry picked from commit 14bba927e3c343007ce408f0fc7c9ad0ed94b88c)",
        "func_before": "static int\ndisplay_metadata_block(proto_tree *tree, tvbuff_t *tvb, packet_info *pinfo, int offset, gchar *bundle_custodian, gboolean *lastheader)\n{\n    proto_item   *block_item, *ti, *block_flag_replicate_item, *block_flag_eid_reference_item;\n    proto_tree   *block_tree;\n    int           sdnv_length;\n    int           block_length;\n    guint8        type;\n    unsigned int  control_flags;\n    proto_tree   *block_flag_tree;\n    proto_item   *block_flag_item;\n\n    type = tvb_get_guint8(tvb, offset);\n    block_tree = proto_tree_add_subtree(tree, tvb, offset, -1, ett_metadata_hdr, &block_item, \"Metadata Block\");\n\n    proto_tree_add_item(block_tree, hf_bundle_block_type_code, tvb, offset, 1, ENC_BIG_ENDIAN);\n    ++offset;\n\n    control_flags = (unsigned int)evaluate_sdnv(tvb, offset, &sdnv_length);\n    if (control_flags & BLOCK_CONTROL_LAST_BLOCK) {\n        *lastheader = TRUE;\n    } else {\n        *lastheader = FALSE;\n    }\n    block_flag_item = proto_tree_add_uint(block_tree, hf_block_control_flags_sdnv, tvb,\n                                            offset, sdnv_length, control_flags);\n    block_flag_tree = proto_item_add_subtree(block_flag_item, ett_block_flags);\n    block_flag_replicate_item = proto_tree_add_boolean(block_flag_tree, hf_block_control_replicate,\n                           tvb, offset, sdnv_length, control_flags);\n    proto_tree_add_boolean(block_flag_tree, hf_block_control_transmit_status,\n                           tvb, offset, sdnv_length, control_flags);\n    proto_tree_add_boolean(block_flag_tree, hf_block_control_delete_bundle,\n                           tvb, offset, sdnv_length, control_flags);\n    proto_tree_add_boolean(block_flag_tree, hf_block_control_last_block,\n                           tvb, offset, sdnv_length, control_flags);\n    proto_tree_add_boolean(block_flag_tree, hf_block_control_discard_block,\n                           tvb, offset, sdnv_length, control_flags);\n    proto_tree_add_boolean(block_flag_tree, hf_block_control_not_processed,\n                           tvb, offset, sdnv_length, control_flags);\n    block_flag_eid_reference_item = proto_tree_add_boolean(block_flag_tree, hf_block_control_eid_reference,\n                           tvb, offset, sdnv_length, control_flags);\n    offset += sdnv_length;\n\n    /* TODO: if this block has EID references, add them to display tree */\n    if (control_flags & BLOCK_CONTROL_EID_REFERENCE) {\n        int i;\n        int num_eid_ref;\n\n        num_eid_ref = evaluate_sdnv(tvb, offset, &sdnv_length);\n        offset += sdnv_length;\n\n        for (i = 0; i < num_eid_ref; i++)\n        {\n            evaluate_sdnv(tvb, offset, &sdnv_length);\n            offset += sdnv_length;\n\n            evaluate_sdnv(tvb, offset, &sdnv_length);\n            offset += sdnv_length;\n        }\n    }\n\n    block_length = evaluate_sdnv(tvb, offset, &sdnv_length);\n    ti = proto_tree_add_int(block_tree, hf_block_control_block_length, tvb, offset, sdnv_length, block_length);\n    if (block_length < 0) {\n        expert_add_info_format(pinfo, ti, &ei_bundle_offset_error, \"Metadata Block Length Error\");\n        /* Force quitting */\n        *lastheader = TRUE;\n        return offset;\n    }\n    offset += sdnv_length;\n    /* now we have enough info to know total length of metadata block */\n    proto_item_set_len(block_item, offset + block_length);\n\n    switch (type)\n    {\n    case BUNDLE_BLOCK_TYPE_AUTHENTICATION:\n    case BUNDLE_BLOCK_TYPE_INTEGRITY:\n    case BUNDLE_BLOCK_TYPE_CONFIDENTIALITY:\n    case BUNDLE_BLOCK_TYPE_PREVIOUS_HOP_INSERT:\n    case BUNDLE_BLOCK_TYPE_METADATA_EXTENSION:\n    case BUNDLE_BLOCK_TYPE_EXTENSION_SECURITY:\n    {\n        /* not yet dissected, skip past data */\n        offset += block_length;\n        break;\n    }\n    case BUNDLE_BLOCK_TYPE_CUSTODY_TRANSFER:\n    {\n        int custody_id;\n        const char *cteb_creator_custodian_eid;\n        int cteb_creator_custodian_eid_length;\n\n        /* check requirements for Block Processing Control Flags */\n        if ((control_flags & BLOCK_CONTROL_REPLICATE) != 0) {\n            expert_add_info_format(pinfo, block_flag_replicate_item, &ei_bundle_block_control_flags, \"ERROR: Replicate must be clear for CTEB\");\n        }\n        if ((control_flags & BLOCK_CONTROL_EID_REFERENCE) != 0) {\n            expert_add_info_format(pinfo, block_flag_eid_reference_item, &ei_bundle_block_control_flags, \"ERROR: EID-Reference must be clear for CTEB\");\n        }\n\n        /* there are two elements in a CTEB, first is the custody ID */\n        custody_id = evaluate_sdnv(tvb, offset, &sdnv_length);\n        proto_tree_add_int(block_tree, hf_block_control_block_cteb_custody_id, tvb, offset, sdnv_length, custody_id);\n        offset += sdnv_length;\n\n        /* and second is the creator custodian EID */\n        cteb_creator_custodian_eid_length = block_length - sdnv_length;\n        cteb_creator_custodian_eid = (char *) tvb_get_string_enc(wmem_packet_scope(), tvb, offset, cteb_creator_custodian_eid_length, ENC_ASCII);\n        ti = proto_tree_add_string(block_tree, hf_block_control_block_cteb_creator_custodian_eid, tvb, offset,\n                                cteb_creator_custodian_eid_length, cteb_creator_custodian_eid);\n\n        /* also check if CTEB is valid, i.e. custodians match */\n        if (bundle_custodian == NULL) {\n            expert_add_info_format(pinfo, ti, &ei_block_control_block_cteb_invalid,\n                                \"CTEB Is NOT Valid (Bundle Custodian NULL)\");\n        }\n        else if (strlen(cteb_creator_custodian_eid) != strlen(bundle_custodian)) {\n            expert_add_info_format(pinfo, ti, &ei_block_control_block_cteb_invalid,\n                                \"CTEB Is NOT Valid (Bundle Custodian [%s] != CTEB Custodian [%s])\",\n                                bundle_custodian, cteb_creator_custodian_eid);\n        }\n        else if (memcmp(cteb_creator_custodian_eid, bundle_custodian, strlen(bundle_custodian)) != 0) {\n            expert_add_info_format(pinfo, ti, &ei_block_control_block_cteb_invalid,\n                                \"CTEB Is NOT Valid (Bundle Custodian [%s] != CTEB Custodian [%s])\",\n                                bundle_custodian, cteb_creator_custodian_eid);\n        }\n        else {\n            expert_add_info(pinfo, ti, &ei_block_control_block_cteb_valid);\n        }\n        offset += cteb_creator_custodian_eid_length;\n\n        break;\n    }\n    case BUNDLE_BLOCK_TYPE_EXTENDED_COS:\n    {\n        int flags, flow_label;\n        static const int * ecos_flags_fields[] = {\n            &hf_ecos_flags_critical,\n            &hf_ecos_flags_streaming,\n            &hf_ecos_flags_ordinal,\n            NULL\n        };\n\n        /* check requirements for Block Processing Control Flags */\n        if ((control_flags & BLOCK_CONTROL_REPLICATE) == 0) {\n            expert_add_info_format(pinfo, block_flag_replicate_item, &ei_bundle_block_control_flags, \"ERROR: Replicate must be set for ECOS\");\n        }\n        if ((control_flags & BLOCK_CONTROL_EID_REFERENCE) != 0) {\n            expert_add_info_format(pinfo, block_flag_eid_reference_item, &ei_bundle_block_control_flags, \"ERROR: EID-Reference must be clear for ECOS\");\n        }\n\n        /* flags byte */\n        flags = (int)tvb_get_guint8(tvb, offset);\n        proto_tree_add_bitmask(block_tree, tvb, offset, hf_ecos_flags, ett_block_flags, ecos_flags_fields, ENC_BIG_ENDIAN);\n        offset += 1;\n\n        /* ordinal byte */\n        proto_tree_add_item(block_tree, hf_ecos_ordinal, tvb, offset, 1, ENC_BIG_ENDIAN);\n        offset += 1;\n\n        /* optional flow label sdnv */\n        if ((flags & ECOS_FLAGS_ORDINAL) != 0) {\n            flow_label = evaluate_sdnv(tvb, offset, &sdnv_length);\n            ti = proto_tree_add_int(block_tree, hf_ecos_flow_label, tvb, offset, sdnv_length, flow_label);\n            if (flow_label < 0) {\n                expert_add_info_format(pinfo, ti, &ei_bundle_sdnv_length, \"ECOS Flow Label Error\");\n                /* Force quitting */\n                *lastheader = TRUE;\n                return offset;\n            }\n            offset += sdnv_length;\n        }\n\n        break;\n    }\n    default:\n    {\n        /* unknown bundle type, skip past data */\n        offset += block_length;\n        break;\n    }\n    }\n\n    return offset;\n}",
        "func": "static int\ndisplay_metadata_block(proto_tree *tree, tvbuff_t *tvb, packet_info *pinfo, int offset, gchar *bundle_custodian, gboolean *lastheader)\n{\n    proto_item   *block_item, *ti, *block_flag_replicate_item, *block_flag_eid_reference_item;\n    proto_tree   *block_tree;\n    int           sdnv_length;\n    int           block_length;\n    guint8        type;\n    unsigned int  control_flags;\n    proto_tree   *block_flag_tree;\n    proto_item   *block_flag_item;\n\n    type = tvb_get_guint8(tvb, offset);\n    block_tree = proto_tree_add_subtree(tree, tvb, offset, -1, ett_metadata_hdr, &block_item, \"Metadata Block\");\n\n    proto_tree_add_item(block_tree, hf_bundle_block_type_code, tvb, offset, 1, ENC_BIG_ENDIAN);\n    ++offset;\n\n    control_flags = (unsigned int)evaluate_sdnv(tvb, offset, &sdnv_length);\n    if (control_flags & BLOCK_CONTROL_LAST_BLOCK) {\n        *lastheader = TRUE;\n    } else {\n        *lastheader = FALSE;\n    }\n    block_flag_item = proto_tree_add_uint(block_tree, hf_block_control_flags_sdnv, tvb,\n                                            offset, sdnv_length, control_flags);\n    block_flag_tree = proto_item_add_subtree(block_flag_item, ett_block_flags);\n    block_flag_replicate_item = proto_tree_add_boolean(block_flag_tree, hf_block_control_replicate,\n                           tvb, offset, sdnv_length, control_flags);\n    proto_tree_add_boolean(block_flag_tree, hf_block_control_transmit_status,\n                           tvb, offset, sdnv_length, control_flags);\n    proto_tree_add_boolean(block_flag_tree, hf_block_control_delete_bundle,\n                           tvb, offset, sdnv_length, control_flags);\n    proto_tree_add_boolean(block_flag_tree, hf_block_control_last_block,\n                           tvb, offset, sdnv_length, control_flags);\n    proto_tree_add_boolean(block_flag_tree, hf_block_control_discard_block,\n                           tvb, offset, sdnv_length, control_flags);\n    proto_tree_add_boolean(block_flag_tree, hf_block_control_not_processed,\n                           tvb, offset, sdnv_length, control_flags);\n    block_flag_eid_reference_item = proto_tree_add_boolean(block_flag_tree, hf_block_control_eid_reference,\n                           tvb, offset, sdnv_length, control_flags);\n    offset += sdnv_length;\n\n    /* TODO: if this block has EID references, add them to display tree */\n    if (control_flags & BLOCK_CONTROL_EID_REFERENCE) {\n        int i;\n        int num_eid_ref;\n\n        num_eid_ref = evaluate_sdnv(tvb, offset, &sdnv_length);\n        offset += sdnv_length;\n\n        for (i = 0; i < num_eid_ref; i++)\n        {\n            if (evaluate_sdnv(tvb, offset, &sdnv_length) < 0)\n                break;\n            offset += sdnv_length;\n\n            if (evaluate_sdnv(tvb, offset, &sdnv_length) < 0)\n                break;\n            offset += sdnv_length;\n        }\n    }\n\n    block_length = evaluate_sdnv(tvb, offset, &sdnv_length);\n    ti = proto_tree_add_int(block_tree, hf_block_control_block_length, tvb, offset, sdnv_length, block_length);\n    if (block_length < 0) {\n        expert_add_info_format(pinfo, ti, &ei_bundle_offset_error, \"Metadata Block Length Error\");\n        /* Force quitting */\n        *lastheader = TRUE;\n        return offset;\n    }\n    offset += sdnv_length;\n    /* now we have enough info to know total length of metadata block */\n    proto_item_set_len(block_item, offset + block_length);\n\n    switch (type)\n    {\n    case BUNDLE_BLOCK_TYPE_AUTHENTICATION:\n    case BUNDLE_BLOCK_TYPE_INTEGRITY:\n    case BUNDLE_BLOCK_TYPE_CONFIDENTIALITY:\n    case BUNDLE_BLOCK_TYPE_PREVIOUS_HOP_INSERT:\n    case BUNDLE_BLOCK_TYPE_METADATA_EXTENSION:\n    case BUNDLE_BLOCK_TYPE_EXTENSION_SECURITY:\n    {\n        /* not yet dissected, skip past data */\n        offset += block_length;\n        break;\n    }\n    case BUNDLE_BLOCK_TYPE_CUSTODY_TRANSFER:\n    {\n        int custody_id;\n        const char *cteb_creator_custodian_eid;\n        int cteb_creator_custodian_eid_length;\n\n        /* check requirements for Block Processing Control Flags */\n        if ((control_flags & BLOCK_CONTROL_REPLICATE) != 0) {\n            expert_add_info_format(pinfo, block_flag_replicate_item, &ei_bundle_block_control_flags, \"ERROR: Replicate must be clear for CTEB\");\n        }\n        if ((control_flags & BLOCK_CONTROL_EID_REFERENCE) != 0) {\n            expert_add_info_format(pinfo, block_flag_eid_reference_item, &ei_bundle_block_control_flags, \"ERROR: EID-Reference must be clear for CTEB\");\n        }\n\n        /* there are two elements in a CTEB, first is the custody ID */\n        custody_id = evaluate_sdnv(tvb, offset, &sdnv_length);\n        proto_tree_add_int(block_tree, hf_block_control_block_cteb_custody_id, tvb, offset, sdnv_length, custody_id);\n        offset += sdnv_length;\n\n        /* and second is the creator custodian EID */\n        cteb_creator_custodian_eid_length = block_length - sdnv_length;\n        cteb_creator_custodian_eid = (char *) tvb_get_string_enc(wmem_packet_scope(), tvb, offset, cteb_creator_custodian_eid_length, ENC_ASCII);\n        ti = proto_tree_add_string(block_tree, hf_block_control_block_cteb_creator_custodian_eid, tvb, offset,\n                                cteb_creator_custodian_eid_length, cteb_creator_custodian_eid);\n\n        /* also check if CTEB is valid, i.e. custodians match */\n        if (bundle_custodian == NULL) {\n            expert_add_info_format(pinfo, ti, &ei_block_control_block_cteb_invalid,\n                                \"CTEB Is NOT Valid (Bundle Custodian NULL)\");\n        }\n        else if (strlen(cteb_creator_custodian_eid) != strlen(bundle_custodian)) {\n            expert_add_info_format(pinfo, ti, &ei_block_control_block_cteb_invalid,\n                                \"CTEB Is NOT Valid (Bundle Custodian [%s] != CTEB Custodian [%s])\",\n                                bundle_custodian, cteb_creator_custodian_eid);\n        }\n        else if (memcmp(cteb_creator_custodian_eid, bundle_custodian, strlen(bundle_custodian)) != 0) {\n            expert_add_info_format(pinfo, ti, &ei_block_control_block_cteb_invalid,\n                                \"CTEB Is NOT Valid (Bundle Custodian [%s] != CTEB Custodian [%s])\",\n                                bundle_custodian, cteb_creator_custodian_eid);\n        }\n        else {\n            expert_add_info(pinfo, ti, &ei_block_control_block_cteb_valid);\n        }\n        offset += cteb_creator_custodian_eid_length;\n\n        break;\n    }\n    case BUNDLE_BLOCK_TYPE_EXTENDED_COS:\n    {\n        int flags, flow_label;\n        static const int * ecos_flags_fields[] = {\n            &hf_ecos_flags_critical,\n            &hf_ecos_flags_streaming,\n            &hf_ecos_flags_ordinal,\n            NULL\n        };\n\n        /* check requirements for Block Processing Control Flags */\n        if ((control_flags & BLOCK_CONTROL_REPLICATE) == 0) {\n            expert_add_info_format(pinfo, block_flag_replicate_item, &ei_bundle_block_control_flags, \"ERROR: Replicate must be set for ECOS\");\n        }\n        if ((control_flags & BLOCK_CONTROL_EID_REFERENCE) != 0) {\n            expert_add_info_format(pinfo, block_flag_eid_reference_item, &ei_bundle_block_control_flags, \"ERROR: EID-Reference must be clear for ECOS\");\n        }\n\n        /* flags byte */\n        flags = (int)tvb_get_guint8(tvb, offset);\n        proto_tree_add_bitmask(block_tree, tvb, offset, hf_ecos_flags, ett_block_flags, ecos_flags_fields, ENC_BIG_ENDIAN);\n        offset += 1;\n\n        /* ordinal byte */\n        proto_tree_add_item(block_tree, hf_ecos_ordinal, tvb, offset, 1, ENC_BIG_ENDIAN);\n        offset += 1;\n\n        /* optional flow label sdnv */\n        if ((flags & ECOS_FLAGS_ORDINAL) != 0) {\n            flow_label = evaluate_sdnv(tvb, offset, &sdnv_length);\n            ti = proto_tree_add_int(block_tree, hf_ecos_flow_label, tvb, offset, sdnv_length, flow_label);\n            if (flow_label < 0) {\n                expert_add_info_format(pinfo, ti, &ei_bundle_sdnv_length, \"ECOS Flow Label Error\");\n                /* Force quitting */\n                *lastheader = TRUE;\n                return offset;\n            }\n            offset += sdnv_length;\n        }\n\n        break;\n    }\n    default:\n    {\n        /* unknown bundle type, skip past data */\n        offset += block_length;\n        break;\n    }\n    }\n\n    return offset;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -51,10 +51,12 @@\n \n         for (i = 0; i < num_eid_ref; i++)\n         {\n-            evaluate_sdnv(tvb, offset, &sdnv_length);\n+            if (evaluate_sdnv(tvb, offset, &sdnv_length) < 0)\n+                break;\n             offset += sdnv_length;\n \n-            evaluate_sdnv(tvb, offset, &sdnv_length);\n+            if (evaluate_sdnv(tvb, offset, &sdnv_length) < 0)\n+                break;\n             offset += sdnv_length;\n         }\n     }",
        "diff_line_info": {
            "deleted_lines": [
                "            evaluate_sdnv(tvb, offset, &sdnv_length);",
                "            evaluate_sdnv(tvb, offset, &sdnv_length);"
            ],
            "added_lines": [
                "            if (evaluate_sdnv(tvb, offset, &sdnv_length) < 0)",
                "                break;",
                "            if (evaluate_sdnv(tvb, offset, &sdnv_length) < 0)",
                "                break;"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-9376",
        "func_name": "wireshark/dissect_openflow_queue_desc_prop_v5",
        "description": "In Wireshark 2.2.0 to 2.2.1 and 2.0.0 to 2.0.7, the OpenFlow dissector could crash with memory exhaustion, triggered by network traffic or a capture file. This was addressed in epan/dissectors/packet-openflow_v5.c by ensuring that certain length values were sufficiently large.",
        "git_url": "https://github.com/wireshark/wireshark/commit/f2a7af8d3928e18ef15778e63b9b6c78f8bd1bef",
        "commit_title": "OpenFlow 1.4: check length to avoid rewinding offset",
        "commit_text": " Bug: 13071 (cherry picked from commit d1a7ed109b37c87546393160e03223e7bf770d57) (cherry picked from commit 51348a7e3edae9cfaf995841854b7cf01895fff8)",
        "func_before": "static int\ndissect_openflow_queue_desc_prop_v5(tvbuff_t *tvb, packet_info *pinfo _U_, proto_tree *tree, int offset, guint16 length _U_)\n{\n    proto_item *ti;\n    proto_tree *prop_tree;\n    guint16 prop_type;\n    guint16 prop_len;\n\n    prop_tree = proto_tree_add_subtree(tree, tvb, offset, -1, ett_openflow_v5_queue_desc_prop, &ti, \"Queue property\");\n\n    /* uint16_t property; */\n    prop_type = tvb_get_ntohs(tvb, offset);\n    proto_tree_add_item(prop_tree, hf_openflow_v5_queue_desc_prop_property, tvb, offset, 2, ENC_BIG_ENDIAN);\n    offset+=2;\n\n    /* uint16_t len; */\n    prop_len = tvb_get_ntohs(tvb, offset);\n    proto_item_set_len(ti, prop_len);\n    proto_tree_add_item(prop_tree, hf_openflow_v5_queue_desc_prop_len, tvb, offset, 2, ENC_BIG_ENDIAN);\n    offset+=2;\n\n    /* uint8_t pad[4]; */\n    proto_tree_add_item(prop_tree, hf_openflow_v5_queue_desc_prop_pad, tvb, offset, 4, ENC_NA);\n    offset+=4;\n\n    switch (prop_type) {\n    case OFPQDPT_MIN_RATE:\n        /* uint16_t rate; */\n        if (tvb_get_ntohs(tvb, offset) <= OFPQDP_MIN_RATE_MAX) {\n            proto_tree_add_item(prop_tree, hf_openflow_v5_queue_desc_prop_min_rate_rate, tvb, offset, 2, ENC_BIG_ENDIAN);\n        } else {\n            proto_tree_add_item(prop_tree, hf_openflow_v5_queue_desc_prop_min_rate_rate_reserved, tvb, offset, 2, ENC_BIG_ENDIAN);\n        }\n        offset+=2;\n\n        /* uint8_t pad[6]; */\n        proto_tree_add_item(prop_tree, hf_openflow_v5_queue_desc_prop_min_rate_pad, tvb, offset, 6, ENC_NA);\n        offset+=6;\n        break;\n\n    case OFPQDPT_MAX_RATE:\n        /* uint16_t rate; */\n        if (tvb_get_ntohs(tvb, offset) <= OFPQDP_MAX_RATE_MAX) {\n            proto_tree_add_item(prop_tree, hf_openflow_v5_queue_desc_prop_max_rate_rate, tvb, offset, 2, ENC_BIG_ENDIAN);\n        } else {\n            proto_tree_add_item(prop_tree, hf_openflow_v5_queue_desc_prop_max_rate_rate_reserved, tvb, offset, 2, ENC_BIG_ENDIAN);\n        }\n        offset+=2;\n\n        /* uint8_t pad[6]; */\n        proto_tree_add_item(prop_tree, hf_openflow_v5_queue_desc_prop_max_rate_pad, tvb, offset, 6, ENC_NA);\n        offset+=6;\n        break;\n\n    case OFPQDPT_EXPERIMENTER:\n        /* uint32_t experimenter; */\n        proto_tree_add_item(prop_tree, hf_openflow_v5_queue_desc_prop_experimenter_experimenter, tvb, offset, 4, ENC_BIG_ENDIAN);\n        offset+=4;\n\n        /* uint32_t exp_type; */\n        proto_tree_add_item(prop_tree, hf_openflow_v5_queue_desc_prop_experimenter_exp_type, tvb, offset, 4, ENC_BIG_ENDIAN);\n        offset+=4;\n\n        /* uint8_t experimenter_data[0]; */\n        proto_tree_add_expert_format(prop_tree, pinfo, &ei_openflow_v5_queue_desc_prop_undecoded,\n                                     tvb, offset, prop_len - 16, \"Experimenter queue property body.\");\n        offset+=prop_len-16;\n        break;\n\n    default:\n        proto_tree_add_expert_format(prop_tree, pinfo, &ei_openflow_v5_queue_desc_prop_undecoded,\n                                     tvb, offset, prop_len - 8, \"Unknown queue property body.\");\n        offset+=prop_len-8;\n        break;\n    }\n\n    return offset;\n}",
        "func": "static int\ndissect_openflow_queue_desc_prop_v5(tvbuff_t *tvb, packet_info *pinfo _U_, proto_tree *tree, int offset, guint16 length _U_)\n{\n    proto_item *ti;\n    proto_tree *prop_tree;\n    guint16 prop_type;\n    guint16 prop_len;\n\n    prop_tree = proto_tree_add_subtree(tree, tvb, offset, -1, ett_openflow_v5_queue_desc_prop, &ti, \"Queue property\");\n\n    /* uint16_t property; */\n    prop_type = tvb_get_ntohs(tvb, offset);\n    proto_tree_add_item(prop_tree, hf_openflow_v5_queue_desc_prop_property, tvb, offset, 2, ENC_BIG_ENDIAN);\n    offset+=2;\n\n    /* uint16_t len; */\n    prop_len = tvb_get_ntohs(tvb, offset);\n    proto_item_set_len(ti, prop_len);\n    ti = proto_tree_add_item(prop_tree, hf_openflow_v5_queue_desc_prop_len, tvb, offset, 2, ENC_BIG_ENDIAN);\n    offset+=2;\n\n    /* uint8_t pad[4]; */\n    proto_tree_add_item(prop_tree, hf_openflow_v5_queue_desc_prop_pad, tvb, offset, 4, ENC_NA);\n    offset+=4;\n\n    if (prop_len < 8) {\n        expert_add_info(pinfo, ti, &ei_openflow_v5_length_too_short);\n        return offset;\n    }\n\n    switch (prop_type) {\n    case OFPQDPT_MIN_RATE:\n        /* uint16_t rate; */\n        if (tvb_get_ntohs(tvb, offset) <= OFPQDP_MIN_RATE_MAX) {\n            proto_tree_add_item(prop_tree, hf_openflow_v5_queue_desc_prop_min_rate_rate, tvb, offset, 2, ENC_BIG_ENDIAN);\n        } else {\n            proto_tree_add_item(prop_tree, hf_openflow_v5_queue_desc_prop_min_rate_rate_reserved, tvb, offset, 2, ENC_BIG_ENDIAN);\n        }\n        offset+=2;\n\n        /* uint8_t pad[6]; */\n        proto_tree_add_item(prop_tree, hf_openflow_v5_queue_desc_prop_min_rate_pad, tvb, offset, 6, ENC_NA);\n        offset+=6;\n        break;\n\n    case OFPQDPT_MAX_RATE:\n        /* uint16_t rate; */\n        if (tvb_get_ntohs(tvb, offset) <= OFPQDP_MAX_RATE_MAX) {\n            proto_tree_add_item(prop_tree, hf_openflow_v5_queue_desc_prop_max_rate_rate, tvb, offset, 2, ENC_BIG_ENDIAN);\n        } else {\n            proto_tree_add_item(prop_tree, hf_openflow_v5_queue_desc_prop_max_rate_rate_reserved, tvb, offset, 2, ENC_BIG_ENDIAN);\n        }\n        offset+=2;\n\n        /* uint8_t pad[6]; */\n        proto_tree_add_item(prop_tree, hf_openflow_v5_queue_desc_prop_max_rate_pad, tvb, offset, 6, ENC_NA);\n        offset+=6;\n        break;\n\n    case OFPQDPT_EXPERIMENTER:\n        /* uint32_t experimenter; */\n        proto_tree_add_item(prop_tree, hf_openflow_v5_queue_desc_prop_experimenter_experimenter, tvb, offset, 4, ENC_BIG_ENDIAN);\n        offset+=4;\n\n        /* uint32_t exp_type; */\n        proto_tree_add_item(prop_tree, hf_openflow_v5_queue_desc_prop_experimenter_exp_type, tvb, offset, 4, ENC_BIG_ENDIAN);\n        offset+=4;\n\n        /* uint8_t experimenter_data[0]; */\n        proto_tree_add_expert_format(prop_tree, pinfo, &ei_openflow_v5_queue_desc_prop_undecoded,\n                                     tvb, offset, prop_len - 16, \"Experimenter queue property body.\");\n        offset+=prop_len-16;\n        break;\n\n    default:\n        proto_tree_add_expert_format(prop_tree, pinfo, &ei_openflow_v5_queue_desc_prop_undecoded,\n                                     tvb, offset, prop_len - 8, \"Unknown queue property body.\");\n        offset+=prop_len-8;\n        break;\n    }\n\n    return offset;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -16,12 +16,17 @@\n     /* uint16_t len; */\n     prop_len = tvb_get_ntohs(tvb, offset);\n     proto_item_set_len(ti, prop_len);\n-    proto_tree_add_item(prop_tree, hf_openflow_v5_queue_desc_prop_len, tvb, offset, 2, ENC_BIG_ENDIAN);\n+    ti = proto_tree_add_item(prop_tree, hf_openflow_v5_queue_desc_prop_len, tvb, offset, 2, ENC_BIG_ENDIAN);\n     offset+=2;\n \n     /* uint8_t pad[4]; */\n     proto_tree_add_item(prop_tree, hf_openflow_v5_queue_desc_prop_pad, tvb, offset, 4, ENC_NA);\n     offset+=4;\n+\n+    if (prop_len < 8) {\n+        expert_add_info(pinfo, ti, &ei_openflow_v5_length_too_short);\n+        return offset;\n+    }\n \n     switch (prop_type) {\n     case OFPQDPT_MIN_RATE:",
        "diff_line_info": {
            "deleted_lines": [
                "    proto_tree_add_item(prop_tree, hf_openflow_v5_queue_desc_prop_len, tvb, offset, 2, ENC_BIG_ENDIAN);"
            ],
            "added_lines": [
                "    ti = proto_tree_add_item(prop_tree, hf_openflow_v5_queue_desc_prop_len, tvb, offset, 2, ENC_BIG_ENDIAN);",
                "",
                "    if (prop_len < 8) {",
                "        expert_add_info(pinfo, ti, &ei_openflow_v5_length_too_short);",
                "        return offset;",
                "    }"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-9376",
        "func_name": "wireshark/dissect_openflow_meter_band_v5",
        "description": "In Wireshark 2.2.0 to 2.2.1 and 2.0.0 to 2.0.7, the OpenFlow dissector could crash with memory exhaustion, triggered by network traffic or a capture file. This was addressed in epan/dissectors/packet-openflow_v5.c by ensuring that certain length values were sufficiently large.",
        "git_url": "https://github.com/wireshark/wireshark/commit/f2a7af8d3928e18ef15778e63b9b6c78f8bd1bef",
        "commit_title": "OpenFlow 1.4: check length to avoid rewinding offset",
        "commit_text": " Bug: 13071 (cherry picked from commit d1a7ed109b37c87546393160e03223e7bf770d57) (cherry picked from commit 51348a7e3edae9cfaf995841854b7cf01895fff8)",
        "func_before": "static int\ndissect_openflow_meter_band_v5(tvbuff_t *tvb, packet_info *pinfo _U_, proto_tree *tree, int offset, guint16 length _U_)\n{\n    proto_item *ti;\n    proto_tree *band_tree;\n    guint16 band_type;\n    guint16 band_len;\n\n    band_tree = proto_tree_add_subtree(tree, tvb, offset, -1, ett_openflow_v5_meter_band, &ti, \"Meter band\");\n\n    /* uint16_t type; */\n    band_type = tvb_get_ntohs(tvb, offset);\n    proto_tree_add_item(band_tree, hf_openflow_v5_meter_band_type, tvb, offset, 2, ENC_BIG_ENDIAN);\n    offset+=2;\n\n    /* uint16_t len; */\n    band_len = tvb_get_ntohs(tvb, offset);\n    proto_item_set_len(ti, band_len);\n    proto_tree_add_item(band_tree, hf_openflow_v5_meter_band_len, tvb, offset, 2, ENC_BIG_ENDIAN);\n    offset+=2;\n\n    /* uint32_t rate; */\n    proto_tree_add_item(band_tree, hf_openflow_v5_meter_band_rate, tvb, offset, 4, ENC_BIG_ENDIAN);\n    offset+=4;\n\n    /* uint32_t burst_size; */\n    proto_tree_add_item(band_tree, hf_openflow_v5_meter_band_burst_size, tvb, offset, 4, ENC_BIG_ENDIAN);\n    offset+=4;\n\n    switch (band_type) {\n    case OFPMBT_DROP:\n        /* uint8_t pad[4]; */\n        proto_tree_add_item(band_tree, hf_openflow_v5_meter_band_drop_pad, tvb, offset, 4, ENC_NA);\n        offset+=4;\n        break;\n\n    case OFPMBT_DSCP_REMARK:\n        /* uint8_t prec_level; */\n        proto_tree_add_item(band_tree, hf_openflow_v5_meter_band_dscp_remark_prec_level, tvb, offset, 1, ENC_BIG_ENDIAN);\n        offset+=1;\n\n        /* uint8_t pad[3]; */\n        proto_tree_add_item(band_tree, hf_openflow_v5_meter_band_dscp_remark_pad, tvb, offset, 3, ENC_NA);\n        offset+=3;\n        break;\n\n    case OFPMBT_EXPERIMENTER:\n        /* uint32_t experimenter; */\n        proto_tree_add_item(band_tree, hf_openflow_v5_meter_band_experimenter_experimenter, tvb, offset, 4, ENC_BIG_ENDIAN);\n        offset+=4;\n\n        /* uint32_t experimenter_data[0]; */\n        proto_tree_add_expert_format(band_tree, pinfo, &ei_openflow_v5_meter_band_undecoded,\n                                     tvb, offset, offset - 16 + band_len, \"Experimenter meter band body.\");\n        offset+=band_len-16;\n        break;\n\n    default:\n        proto_tree_add_expert_format(band_tree, pinfo, &ei_openflow_v5_meter_band_undecoded,\n                                     tvb, offset, offset - 12 + band_len, \"Unknown meter band body.\");\n        offset+=band_len-12;\n        break;\n    }\n\n    return offset;\n}",
        "func": "static int\ndissect_openflow_meter_band_v5(tvbuff_t *tvb, packet_info *pinfo _U_, proto_tree *tree, int offset, guint16 length _U_)\n{\n    proto_item *ti;\n    proto_tree *band_tree;\n    guint16 band_type;\n    guint16 band_len;\n\n    band_tree = proto_tree_add_subtree(tree, tvb, offset, -1, ett_openflow_v5_meter_band, &ti, \"Meter band\");\n\n    /* uint16_t type; */\n    band_type = tvb_get_ntohs(tvb, offset);\n    proto_tree_add_item(band_tree, hf_openflow_v5_meter_band_type, tvb, offset, 2, ENC_BIG_ENDIAN);\n    offset+=2;\n\n    /* uint16_t len; */\n    band_len = tvb_get_ntohs(tvb, offset);\n    proto_item_set_len(ti, band_len);\n    ti = proto_tree_add_item(band_tree, hf_openflow_v5_meter_band_len, tvb, offset, 2, ENC_BIG_ENDIAN);\n    offset+=2;\n\n    /* uint32_t rate; */\n    proto_tree_add_item(band_tree, hf_openflow_v5_meter_band_rate, tvb, offset, 4, ENC_BIG_ENDIAN);\n    offset+=4;\n\n    /* uint32_t burst_size; */\n    proto_tree_add_item(band_tree, hf_openflow_v5_meter_band_burst_size, tvb, offset, 4, ENC_BIG_ENDIAN);\n    offset+=4;\n\n    if (band_len < 12) {\n        expert_add_info(pinfo, ti, &ei_openflow_v5_length_too_short);\n        return offset;\n    }\n\n    switch (band_type) {\n    case OFPMBT_DROP:\n        /* uint8_t pad[4]; */\n        proto_tree_add_item(band_tree, hf_openflow_v5_meter_band_drop_pad, tvb, offset, 4, ENC_NA);\n        offset+=4;\n        break;\n\n    case OFPMBT_DSCP_REMARK:\n        /* uint8_t prec_level; */\n        proto_tree_add_item(band_tree, hf_openflow_v5_meter_band_dscp_remark_prec_level, tvb, offset, 1, ENC_BIG_ENDIAN);\n        offset+=1;\n\n        /* uint8_t pad[3]; */\n        proto_tree_add_item(band_tree, hf_openflow_v5_meter_band_dscp_remark_pad, tvb, offset, 3, ENC_NA);\n        offset+=3;\n        break;\n\n    case OFPMBT_EXPERIMENTER:\n        /* uint32_t experimenter; */\n        proto_tree_add_item(band_tree, hf_openflow_v5_meter_band_experimenter_experimenter, tvb, offset, 4, ENC_BIG_ENDIAN);\n        offset+=4;\n\n        /* uint32_t experimenter_data[0]; */\n        proto_tree_add_expert_format(band_tree, pinfo, &ei_openflow_v5_meter_band_undecoded,\n                                     tvb, offset, offset - 16 + band_len, \"Experimenter meter band body.\");\n        offset+=band_len-16;\n        break;\n\n    default:\n        proto_tree_add_expert_format(band_tree, pinfo, &ei_openflow_v5_meter_band_undecoded,\n                                     tvb, offset, offset - 12 + band_len, \"Unknown meter band body.\");\n        offset+=band_len-12;\n        break;\n    }\n\n    return offset;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -16,7 +16,7 @@\n     /* uint16_t len; */\n     band_len = tvb_get_ntohs(tvb, offset);\n     proto_item_set_len(ti, band_len);\n-    proto_tree_add_item(band_tree, hf_openflow_v5_meter_band_len, tvb, offset, 2, ENC_BIG_ENDIAN);\n+    ti = proto_tree_add_item(band_tree, hf_openflow_v5_meter_band_len, tvb, offset, 2, ENC_BIG_ENDIAN);\n     offset+=2;\n \n     /* uint32_t rate; */\n@@ -26,6 +26,11 @@\n     /* uint32_t burst_size; */\n     proto_tree_add_item(band_tree, hf_openflow_v5_meter_band_burst_size, tvb, offset, 4, ENC_BIG_ENDIAN);\n     offset+=4;\n+\n+    if (band_len < 12) {\n+        expert_add_info(pinfo, ti, &ei_openflow_v5_length_too_short);\n+        return offset;\n+    }\n \n     switch (band_type) {\n     case OFPMBT_DROP:",
        "diff_line_info": {
            "deleted_lines": [
                "    proto_tree_add_item(band_tree, hf_openflow_v5_meter_band_len, tvb, offset, 2, ENC_BIG_ENDIAN);"
            ],
            "added_lines": [
                "    ti = proto_tree_add_item(band_tree, hf_openflow_v5_meter_band_len, tvb, offset, 2, ENC_BIG_ENDIAN);",
                "",
                "    if (band_len < 12) {",
                "        expert_add_info(pinfo, ti, &ei_openflow_v5_length_too_short);",
                "        return offset;",
                "    }"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-9376",
        "func_name": "wireshark/dissect_openflow_match_v5",
        "description": "In Wireshark 2.2.0 to 2.2.1 and 2.0.0 to 2.0.7, the OpenFlow dissector could crash with memory exhaustion, triggered by network traffic or a capture file. This was addressed in epan/dissectors/packet-openflow_v5.c by ensuring that certain length values were sufficiently large.",
        "git_url": "https://github.com/wireshark/wireshark/commit/f2a7af8d3928e18ef15778e63b9b6c78f8bd1bef",
        "commit_title": "OpenFlow 1.4: check length to avoid rewinding offset",
        "commit_text": " Bug: 13071 (cherry picked from commit d1a7ed109b37c87546393160e03223e7bf770d57) (cherry picked from commit 51348a7e3edae9cfaf995841854b7cf01895fff8)",
        "func_before": "static int\ndissect_openflow_match_v5(tvbuff_t *tvb, packet_info *pinfo _U_, proto_tree *tree, int offset, guint16 length _U_)\n{\n    proto_item *ti;\n    proto_tree *match_tree;\n    guint16 match_type;\n    guint16 match_length;\n    gint32 fields_end;\n    guint16 pad_length;\n\n    match_tree = proto_tree_add_subtree(tree, tvb, offset, -1, ett_openflow_v5_match, &ti, \"Match\");\n\n    /* uint16_t type; */\n    match_type = tvb_get_ntohs(tvb, offset);\n    proto_tree_add_item(match_tree, hf_openflow_v5_match_type, tvb, offset, 2, ENC_BIG_ENDIAN);\n    offset+=2;\n\n    /* uint16_t length; (excluding padding) */\n    match_length = tvb_get_ntohs(tvb, offset);\n    pad_length = (match_length + 7)/8*8 - match_length;\n    proto_item_set_len(ti, match_length + pad_length);\n    proto_tree_add_item(match_tree, hf_openflow_v5_match_length, tvb, offset, 2, ENC_BIG_ENDIAN);\n    offset+=2;\n\n    /* body */\n    switch (match_type) {\n    case OFPMT_STANDARD:\n        proto_tree_add_expert_format(match_tree, pinfo, &ei_openflow_v5_match_undecoded,\n                                     tvb, offset, match_length - 4, \"Standard match body (deprecated).\");\n        offset+=match_length-4;\n        break;\n\n    case OFPMT_OXM:\n        fields_end = offset + match_length - 4;\n        while(offset < fields_end) {\n            offset = dissect_openflow_oxm_v5(tvb, pinfo, match_tree, offset, length);\n        }\n        break;\n\n    default:\n        proto_tree_add_expert_format(match_tree, pinfo, &ei_openflow_v5_match_undecoded,\n                                     tvb, offset, match_length - 4, \"Unknown match body.\");\n        offset+=match_length-4;\n        break;\n    }\n\n    /* pad; Exactly ((length + 7)/8*8 - length) (between 0 and 7) bytes of all-zero bytes. */\n    if (pad_length > 0) {\n        proto_tree_add_item(match_tree, hf_openflow_v5_match_pad, tvb, offset, pad_length, ENC_NA);\n        offset+=pad_length;\n    }\n\n    return offset;\n}",
        "func": "static int\ndissect_openflow_match_v5(tvbuff_t *tvb, packet_info *pinfo _U_, proto_tree *tree, int offset, guint16 length _U_)\n{\n    proto_item *ti;\n    proto_tree *match_tree;\n    guint16 match_type;\n    guint16 match_length;\n    gint32 fields_end;\n    guint16 pad_length;\n\n    match_tree = proto_tree_add_subtree(tree, tvb, offset, -1, ett_openflow_v5_match, &ti, \"Match\");\n\n    /* uint16_t type; */\n    match_type = tvb_get_ntohs(tvb, offset);\n    proto_tree_add_item(match_tree, hf_openflow_v5_match_type, tvb, offset, 2, ENC_BIG_ENDIAN);\n    offset+=2;\n\n    /* uint16_t length; (excluding padding) */\n    match_length = tvb_get_ntohs(tvb, offset);\n    pad_length = (match_length + 7)/8*8 - match_length;\n    proto_item_set_len(ti, match_length + pad_length);\n    ti = proto_tree_add_item(match_tree, hf_openflow_v5_match_length, tvb, offset, 2, ENC_BIG_ENDIAN);\n    offset+=2;\n\n    if (match_length < 4) {\n        expert_add_info(pinfo, ti, &ei_openflow_v5_length_too_short);\n        return offset;\n    }\n\n    /* body */\n    switch (match_type) {\n    case OFPMT_STANDARD:\n        proto_tree_add_expert_format(match_tree, pinfo, &ei_openflow_v5_match_undecoded,\n                                     tvb, offset, match_length - 4, \"Standard match body (deprecated).\");\n        offset+=match_length-4;\n        break;\n\n    case OFPMT_OXM:\n        fields_end = offset + match_length - 4;\n        while(offset < fields_end) {\n            offset = dissect_openflow_oxm_v5(tvb, pinfo, match_tree, offset, length);\n        }\n        break;\n\n    default:\n        proto_tree_add_expert_format(match_tree, pinfo, &ei_openflow_v5_match_undecoded,\n                                     tvb, offset, match_length - 4, \"Unknown match body.\");\n        offset+=match_length-4;\n        break;\n    }\n\n    /* pad; Exactly ((length + 7)/8*8 - length) (between 0 and 7) bytes of all-zero bytes. */\n    if (pad_length > 0) {\n        proto_tree_add_item(match_tree, hf_openflow_v5_match_pad, tvb, offset, pad_length, ENC_NA);\n        offset+=pad_length;\n    }\n\n    return offset;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -19,8 +19,13 @@\n     match_length = tvb_get_ntohs(tvb, offset);\n     pad_length = (match_length + 7)/8*8 - match_length;\n     proto_item_set_len(ti, match_length + pad_length);\n-    proto_tree_add_item(match_tree, hf_openflow_v5_match_length, tvb, offset, 2, ENC_BIG_ENDIAN);\n+    ti = proto_tree_add_item(match_tree, hf_openflow_v5_match_length, tvb, offset, 2, ENC_BIG_ENDIAN);\n     offset+=2;\n+\n+    if (match_length < 4) {\n+        expert_add_info(pinfo, ti, &ei_openflow_v5_length_too_short);\n+        return offset;\n+    }\n \n     /* body */\n     switch (match_type) {",
        "diff_line_info": {
            "deleted_lines": [
                "    proto_tree_add_item(match_tree, hf_openflow_v5_match_length, tvb, offset, 2, ENC_BIG_ENDIAN);"
            ],
            "added_lines": [
                "    ti = proto_tree_add_item(match_tree, hf_openflow_v5_match_length, tvb, offset, 2, ENC_BIG_ENDIAN);",
                "",
                "    if (match_length < 4) {",
                "        expert_add_info(pinfo, ti, &ei_openflow_v5_length_too_short);",
                "        return offset;",
                "    }"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-9376",
        "func_name": "wireshark/dissect_openflow_flow_update_v5",
        "description": "In Wireshark 2.2.0 to 2.2.1 and 2.0.0 to 2.0.7, the OpenFlow dissector could crash with memory exhaustion, triggered by network traffic or a capture file. This was addressed in epan/dissectors/packet-openflow_v5.c by ensuring that certain length values were sufficiently large.",
        "git_url": "https://github.com/wireshark/wireshark/commit/f2a7af8d3928e18ef15778e63b9b6c78f8bd1bef",
        "commit_title": "OpenFlow 1.4: check length to avoid rewinding offset",
        "commit_text": " Bug: 13071 (cherry picked from commit d1a7ed109b37c87546393160e03223e7bf770d57) (cherry picked from commit 51348a7e3edae9cfaf995841854b7cf01895fff8)",
        "func_before": "static int\ndissect_openflow_flow_update_v5(tvbuff_t *tvb, packet_info *pinfo _U_, proto_tree *tree, int offset, guint16 length _U_)\n{\n    proto_tree *update_tree;\n    guint16 update_len;\n    guint16 update_event;\n    gint32 update_end;\n\n    update_len = tvb_get_ntohs(tvb, offset);\n    update_end = offset + update_len;\n    update_event = tvb_get_ntohs(tvb, offset + 2);\n\n    update_tree = proto_tree_add_subtree(tree, tvb, offset, update_len, ett_openflow_v5_flow_update, NULL, \"Flow update\");\n\n    /* uint16_t length; */\n    proto_tree_add_item(update_tree, hf_openflow_v5_flow_update_length, tvb, offset, 2, ENC_BIG_ENDIAN);\n\n    /* uint16_t event; */\n    proto_tree_add_item(update_tree, hf_openflow_v5_flow_update_event, tvb, offset, 2, ENC_BIG_ENDIAN);\n\n    switch (update_event) {\n    case OFPFME_INITIAL:\n    case OFPFME_ADDED:\n    case OFPFME_REMOVED:\n    case OFPFME_MODIFIED:\n        /* uint8_t table_id; */\n        if (tvb_get_guint8(tvb, offset) <= OFPTT_MAX) {\n            proto_tree_add_item(update_tree, hf_openflow_v5_flow_update_full_table_id, tvb, offset, 1, ENC_BIG_ENDIAN);\n        } else {\n            proto_tree_add_item(update_tree, hf_openflow_v5_flow_update_full_table_id_reserved, tvb, offset, 1, ENC_BIG_ENDIAN);\n        }\n        offset+=1;\n\n        if (update_event == OFPFME_REMOVED) {\n            /* uint8_t reason; */\n            proto_tree_add_item(update_tree, hf_openflow_v5_flow_update_full_reason, tvb, offset, 1, ENC_BIG_ENDIAN);\n        } else {\n            /* uint8_t zero; */\n            proto_tree_add_item(update_tree, hf_openflow_v5_flow_update_full_zero, tvb, offset, 1, ENC_NA);\n        }\n        offset+=1;\n\n        /* uint16_t idle_timeout; */\n        proto_tree_add_item(update_tree, hf_openflow_v5_flow_update_full_idle_timeout, tvb, offset, 2, ENC_BIG_ENDIAN);\n        offset+=2;\n\n        /* uint16_t hard_timeout; */\n        proto_tree_add_item(update_tree, hf_openflow_v5_flow_update_full_hard_timeout, tvb, offset, 2, ENC_BIG_ENDIAN);\n        offset+=2;\n\n        /* uint16_t priority; */\n        proto_tree_add_item(update_tree, hf_openflow_v5_flow_update_full_priority, tvb, offset, 2, ENC_BIG_ENDIAN);\n        offset+=2;\n\n        /* uint8_t zeros[4]; */\n        proto_tree_add_item(update_tree, hf_openflow_v5_flow_update_full_zeros, tvb, offset, 4, ENC_NA);\n        offset+=4;\n\n        /* uint64_t cookie; */\n        proto_tree_add_item(update_tree, hf_openflow_v5_flow_update_full_cookie, tvb, offset, 8, ENC_BIG_ENDIAN);\n        offset+=8;\n\n        /* struct ofp_match match; */\n        offset = dissect_openflow_match_v5(tvb, pinfo, update_tree, offset, length);\n\n        /* struct ofp_instruction instructions[0]; */\n        while (offset < update_end) {\n            offset = dissect_openflow_instruction_v5(tvb, pinfo, update_tree, offset, length);\n        }\n        break;\n\n    case OFPFME_ABBREV:\n        /* uint32_t xid; */\n        proto_tree_add_item(update_tree, hf_openflow_v5_flow_update_abbrev_xid, tvb, offset, 4, ENC_BIG_ENDIAN);\n        offset+=4;\n        break;\n\n    case OFPFME_PAUSED:\n    case OFPFME_RESUMED:\n        /* uint8_t zeros[4]; */\n        proto_tree_add_item(update_tree, hf_openflow_v5_flow_update_paused_zeros, tvb, offset, 4, ENC_NA);\n        offset+=4;\n        break;\n\n    default:\n        proto_tree_add_expert_format(update_tree, pinfo, &ei_openflow_v5_flow_update_undecoded,\n                                     tvb, offset, update_len - 4, \"Unknown flow update body.\");\n        offset+=update_len-4;\n        break;\n    }\n\n    return offset;\n}",
        "func": "static int\ndissect_openflow_flow_update_v5(tvbuff_t *tvb, packet_info *pinfo _U_, proto_tree *tree, int offset, guint16 length _U_)\n{\n    proto_tree *update_tree;\n    guint16 update_len;\n    guint16 update_event;\n    gint32 update_end;\n    proto_item *ti;\n\n    update_len = tvb_get_ntohs(tvb, offset);\n    update_end = offset + update_len;\n    update_event = tvb_get_ntohs(tvb, offset + 2);\n\n    update_tree = proto_tree_add_subtree(tree, tvb, offset, update_len, ett_openflow_v5_flow_update, NULL, \"Flow update\");\n\n    /* uint16_t length; */\n    proto_tree_add_item(update_tree, hf_openflow_v5_flow_update_length, tvb, offset, 2, ENC_BIG_ENDIAN);\n    offset+=2;\n\n    /* uint16_t event; */\n    ti = proto_tree_add_item(update_tree, hf_openflow_v5_flow_update_event, tvb, offset, 2, ENC_BIG_ENDIAN);\n    offset+=2;\n\n    if (update_len < 4) {\n        expert_add_info(pinfo, ti, &ei_openflow_v5_length_too_short);\n        return offset;\n    }\n\n    switch (update_event) {\n    case OFPFME_INITIAL:\n    case OFPFME_ADDED:\n    case OFPFME_REMOVED:\n    case OFPFME_MODIFIED:\n        /* uint8_t table_id; */\n        if (tvb_get_guint8(tvb, offset) <= OFPTT_MAX) {\n            proto_tree_add_item(update_tree, hf_openflow_v5_flow_update_full_table_id, tvb, offset, 1, ENC_BIG_ENDIAN);\n        } else {\n            proto_tree_add_item(update_tree, hf_openflow_v5_flow_update_full_table_id_reserved, tvb, offset, 1, ENC_BIG_ENDIAN);\n        }\n        offset+=1;\n\n        if (update_event == OFPFME_REMOVED) {\n            /* uint8_t reason; */\n            proto_tree_add_item(update_tree, hf_openflow_v5_flow_update_full_reason, tvb, offset, 1, ENC_BIG_ENDIAN);\n        } else {\n            /* uint8_t zero; */\n            proto_tree_add_item(update_tree, hf_openflow_v5_flow_update_full_zero, tvb, offset, 1, ENC_NA);\n        }\n        offset+=1;\n\n        /* uint16_t idle_timeout; */\n        proto_tree_add_item(update_tree, hf_openflow_v5_flow_update_full_idle_timeout, tvb, offset, 2, ENC_BIG_ENDIAN);\n        offset+=2;\n\n        /* uint16_t hard_timeout; */\n        proto_tree_add_item(update_tree, hf_openflow_v5_flow_update_full_hard_timeout, tvb, offset, 2, ENC_BIG_ENDIAN);\n        offset+=2;\n\n        /* uint16_t priority; */\n        proto_tree_add_item(update_tree, hf_openflow_v5_flow_update_full_priority, tvb, offset, 2, ENC_BIG_ENDIAN);\n        offset+=2;\n\n        /* uint8_t zeros[4]; */\n        proto_tree_add_item(update_tree, hf_openflow_v5_flow_update_full_zeros, tvb, offset, 4, ENC_NA);\n        offset+=4;\n\n        /* uint64_t cookie; */\n        proto_tree_add_item(update_tree, hf_openflow_v5_flow_update_full_cookie, tvb, offset, 8, ENC_BIG_ENDIAN);\n        offset+=8;\n\n        /* struct ofp_match match; */\n        offset = dissect_openflow_match_v5(tvb, pinfo, update_tree, offset, length);\n\n        /* struct ofp_instruction instructions[0]; */\n        while (offset < update_end) {\n            offset = dissect_openflow_instruction_v5(tvb, pinfo, update_tree, offset, length);\n        }\n        break;\n\n    case OFPFME_ABBREV:\n        /* uint32_t xid; */\n        proto_tree_add_item(update_tree, hf_openflow_v5_flow_update_abbrev_xid, tvb, offset, 4, ENC_BIG_ENDIAN);\n        offset+=4;\n        break;\n\n    case OFPFME_PAUSED:\n    case OFPFME_RESUMED:\n        /* uint8_t zeros[4]; */\n        proto_tree_add_item(update_tree, hf_openflow_v5_flow_update_paused_zeros, tvb, offset, 4, ENC_NA);\n        offset+=4;\n        break;\n\n    default:\n        proto_tree_add_expert_format(update_tree, pinfo, &ei_openflow_v5_flow_update_undecoded,\n                                     tvb, offset, update_len - 4, \"Unknown flow update body.\");\n        offset+=update_len-4;\n        break;\n    }\n\n    return offset;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,6 +5,7 @@\n     guint16 update_len;\n     guint16 update_event;\n     gint32 update_end;\n+    proto_item *ti;\n \n     update_len = tvb_get_ntohs(tvb, offset);\n     update_end = offset + update_len;\n@@ -14,9 +15,16 @@\n \n     /* uint16_t length; */\n     proto_tree_add_item(update_tree, hf_openflow_v5_flow_update_length, tvb, offset, 2, ENC_BIG_ENDIAN);\n+    offset+=2;\n \n     /* uint16_t event; */\n-    proto_tree_add_item(update_tree, hf_openflow_v5_flow_update_event, tvb, offset, 2, ENC_BIG_ENDIAN);\n+    ti = proto_tree_add_item(update_tree, hf_openflow_v5_flow_update_event, tvb, offset, 2, ENC_BIG_ENDIAN);\n+    offset+=2;\n+\n+    if (update_len < 4) {\n+        expert_add_info(pinfo, ti, &ei_openflow_v5_length_too_short);\n+        return offset;\n+    }\n \n     switch (update_event) {\n     case OFPFME_INITIAL:",
        "diff_line_info": {
            "deleted_lines": [
                "    proto_tree_add_item(update_tree, hf_openflow_v5_flow_update_event, tvb, offset, 2, ENC_BIG_ENDIAN);"
            ],
            "added_lines": [
                "    proto_item *ti;",
                "    offset+=2;",
                "    ti = proto_tree_add_item(update_tree, hf_openflow_v5_flow_update_event, tvb, offset, 2, ENC_BIG_ENDIAN);",
                "    offset+=2;",
                "",
                "    if (update_len < 4) {",
                "        expert_add_info(pinfo, ti, &ei_openflow_v5_length_too_short);",
                "        return offset;",
                "    }"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-8650",
        "func_name": "torvalds/linux/mpi_powm",
        "description": "The mpi_powm function in lib/mpi/mpi-pow.c in the Linux kernel through 4.8.11 does not ensure that memory is allocated for limb data, which allows local users to cause a denial of service (stack memory corruption and panic) via an add_key system call for an RSA key with a zero exponent.",
        "git_url": "https://github.com/torvalds/linux/commit/f5527fffff3f002b0a6b376163613b82f69de073",
        "commit_title": "mpi: Fix NULL ptr dereference in mpi_powm() [ver #3]",
        "commit_text": " This fixes CVE-2016-8650.  If mpi_powm() is given a zero exponent, it wants to immediately return either 1 or 0, depending on the modulus.  However, if the result was initalised with zero limb space, no limbs space is allocated and a NULL-pointer exception ensues.  Fix this by allocating a minimal amount of limb space for the result when the 0-exponent case when the result is 1 and not touching the limb space when the result is 0.  This affects the use of RSA keys and X.509 certificates that carry them.  BUG: unable to handle kernel NULL pointer dereference at           (null) IP: [<ffffffff8138ce5d>] mpi_powm+0x32/0x7e6 PGD 0 Oops: 0002 [#1] SMP Modules linked in: CPU: 3 PID: 3014 Comm: keyctl Not tainted 4.9.0-rc6-fscache+ #278 Hardware name: ASUS All Series/H97-PLUS, BIOS 2306 10/09/2014 task: ffff8804011944c0 task.stack: ffff880401294000 RIP: 0010:[<ffffffff8138ce5d>]  [<ffffffff8138ce5d>] mpi_powm+0x32/0x7e6 RSP: 0018:ffff880401297ad8  EFLAGS: 00010212 RAX: 0000000000000000 RBX: ffff88040868bec0 RCX: ffff88040868bba0 RDX: ffff88040868b260 RSI: ffff88040868bec0 RDI: ffff88040868bee0 RBP: ffff880401297ba8 R08: 0000000000000000 R09: 0000000000000000 R10: 0000000000000047 R11: ffffffff8183b210 R12: 0000000000000000 R13: ffff8804087c7600 R14: 000000000000001f R15: ffff880401297c50 FS:  00007f7a7918c700(0000) GS:ffff88041fb80000(0000) knlGS:0000000000000000 CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033 CR2: 0000000000000000 CR3: 0000000401250000 CR4: 00000000001406e0 Stack:  ffff88040868bec0 0000000000000020 ffff880401297b00 ffffffff81376cd4  0000000000000100 ffff880401297b10 ffffffff81376d12 ffff880401297b30  ffffffff81376f37 0000000000000100 0000000000000000 ffff880401297ba8 Call Trace:  [<ffffffff81376cd4>] ? __sg_page_iter_next+0x43/0x66  [<ffffffff81376d12>] ? sg_miter_get_next_page+0x1b/0x5d  [<ffffffff81376f37>] ? sg_miter_next+0x17/0xbd  [<ffffffff8138ba3a>] ? mpi_read_raw_from_sgl+0xf2/0x146  [<ffffffff8132a95c>] rsa_verify+0x9d/0xee  [<ffffffff8132acca>] ? pkcs1pad_sg_set_buf+0x2e/0xbb  [<ffffffff8132af40>] pkcs1pad_verify+0xc0/0xe1  [<ffffffff8133cb5e>] public_key_verify_signature+0x1b0/0x228  [<ffffffff8133d974>] x509_check_for_self_signed+0xa1/0xc4  [<ffffffff8133cdde>] x509_cert_parse+0x167/0x1a1  [<ffffffff8133d609>] x509_key_preparse+0x21/0x1a1  [<ffffffff8133c3d7>] asymmetric_key_preparse+0x34/0x61  [<ffffffff812fc9f3>] key_create_or_update+0x145/0x399  [<ffffffff812fe227>] SyS_add_key+0x154/0x19e  [<ffffffff81001c2b>] do_syscall_64+0x80/0x191  [<ffffffff816825e4>] entry_SYSCALL64_slow_path+0x25/0x25 Code: 56 41 55 41 54 53 48 81 ec a8 00 00 00 44 8b 71 04 8b 42 04 4c 8b 67 18 45 85 f6 89 45 80 0f 84 b4 06 00 00 85 c0 75 2f 41 ff ce <49> c7 04 24 01 00 00 00 b0 01 75 0b 48 8b 41 18 48 83 38 01 0f RIP  [<ffffffff8138ce5d>] mpi_powm+0x32/0x7e6  RSP <ffff880401297ad8> CR2: 0000000000000000 ---[ end trace d82015255d4a5d8d ]---  Basically, this is a backport of a libgcrypt patch:  \thttp://git.gnupg.org/cgi-bin/gitweb.cgi?p=libgcrypt.git;a=patch;h=6e1adb05d290aeeb1c230c763970695f4a538526  cc: Dmitry Kasatkin <dmitry.kasatkin@gmail.com> cc: linux-ima-devel@lists.sourceforge.net cc: stable@vger.kernel.org",
        "func_before": "int mpi_powm(MPI res, MPI base, MPI exp, MPI mod)\n{\n\tmpi_ptr_t mp_marker = NULL, bp_marker = NULL, ep_marker = NULL;\n\tmpi_ptr_t xp_marker = NULL;\n\tmpi_ptr_t tspace = NULL;\n\tmpi_ptr_t rp, ep, mp, bp;\n\tmpi_size_t esize, msize, bsize, rsize;\n\tint esign, msign, bsign, rsign;\n\tmpi_size_t size;\n\tint mod_shift_cnt;\n\tint negative_result;\n\tint assign_rp = 0;\n\tmpi_size_t tsize = 0;\t/* to avoid compiler warning */\n\t/* fixme: we should check that the warning is void */\n\tint rc = -ENOMEM;\n\n\tesize = exp->nlimbs;\n\tmsize = mod->nlimbs;\n\tsize = 2 * msize;\n\tesign = exp->sign;\n\tmsign = mod->sign;\n\n\trp = res->d;\n\tep = exp->d;\n\n\tif (!msize)\n\t\treturn -EINVAL;\n\n\tif (!esize) {\n\t\t/* Exponent is zero, result is 1 mod MOD, i.e., 1 or 0\n\t\t * depending on if MOD equals 1.  */\n\t\trp[0] = 1;\n\t\tres->nlimbs = (msize == 1 && mod->d[0] == 1) ? 0 : 1;\n\t\tres->sign = 0;\n\t\tgoto leave;\n\t}\n\n\t/* Normalize MOD (i.e. make its most significant bit set) as required by\n\t * mpn_divrem.  This will make the intermediate values in the calculation\n\t * slightly larger, but the correct result is obtained after a final\n\t * reduction using the original MOD value.  */\n\tmp = mp_marker = mpi_alloc_limb_space(msize);\n\tif (!mp)\n\t\tgoto enomem;\n\tmod_shift_cnt = count_leading_zeros(mod->d[msize - 1]);\n\tif (mod_shift_cnt)\n\t\tmpihelp_lshift(mp, mod->d, msize, mod_shift_cnt);\n\telse\n\t\tMPN_COPY(mp, mod->d, msize);\n\n\tbsize = base->nlimbs;\n\tbsign = base->sign;\n\tif (bsize > msize) {\t/* The base is larger than the module. Reduce it. */\n\t\t/* Allocate (BSIZE + 1) with space for remainder and quotient.\n\t\t * (The quotient is (bsize - msize + 1) limbs.)  */\n\t\tbp = bp_marker = mpi_alloc_limb_space(bsize + 1);\n\t\tif (!bp)\n\t\t\tgoto enomem;\n\t\tMPN_COPY(bp, base->d, bsize);\n\t\t/* We don't care about the quotient, store it above the remainder,\n\t\t * at BP + MSIZE.  */\n\t\tmpihelp_divrem(bp + msize, 0, bp, bsize, mp, msize);\n\t\tbsize = msize;\n\t\t/* Canonicalize the base, since we are going to multiply with it\n\t\t * quite a few times.  */\n\t\tMPN_NORMALIZE(bp, bsize);\n\t} else\n\t\tbp = base->d;\n\n\tif (!bsize) {\n\t\tres->nlimbs = 0;\n\t\tres->sign = 0;\n\t\tgoto leave;\n\t}\n\n\tif (res->alloced < size) {\n\t\t/* We have to allocate more space for RES.  If any of the input\n\t\t * parameters are identical to RES, defer deallocation of the old\n\t\t * space.  */\n\t\tif (rp == ep || rp == mp || rp == bp) {\n\t\t\trp = mpi_alloc_limb_space(size);\n\t\t\tif (!rp)\n\t\t\t\tgoto enomem;\n\t\t\tassign_rp = 1;\n\t\t} else {\n\t\t\tif (mpi_resize(res, size) < 0)\n\t\t\t\tgoto enomem;\n\t\t\trp = res->d;\n\t\t}\n\t} else {\t\t/* Make BASE, EXP and MOD not overlap with RES.  */\n\t\tif (rp == bp) {\n\t\t\t/* RES and BASE are identical.  Allocate temp. space for BASE.  */\n\t\t\tBUG_ON(bp_marker);\n\t\t\tbp = bp_marker = mpi_alloc_limb_space(bsize);\n\t\t\tif (!bp)\n\t\t\t\tgoto enomem;\n\t\t\tMPN_COPY(bp, rp, bsize);\n\t\t}\n\t\tif (rp == ep) {\n\t\t\t/* RES and EXP are identical.  Allocate temp. space for EXP.  */\n\t\t\tep = ep_marker = mpi_alloc_limb_space(esize);\n\t\t\tif (!ep)\n\t\t\t\tgoto enomem;\n\t\t\tMPN_COPY(ep, rp, esize);\n\t\t}\n\t\tif (rp == mp) {\n\t\t\t/* RES and MOD are identical.  Allocate temporary space for MOD. */\n\t\t\tBUG_ON(mp_marker);\n\t\t\tmp = mp_marker = mpi_alloc_limb_space(msize);\n\t\t\tif (!mp)\n\t\t\t\tgoto enomem;\n\t\t\tMPN_COPY(mp, rp, msize);\n\t\t}\n\t}\n\n\tMPN_COPY(rp, bp, bsize);\n\trsize = bsize;\n\trsign = bsign;\n\n\t{\n\t\tmpi_size_t i;\n\t\tmpi_ptr_t xp;\n\t\tint c;\n\t\tmpi_limb_t e;\n\t\tmpi_limb_t carry_limb;\n\t\tstruct karatsuba_ctx karactx;\n\n\t\txp = xp_marker = mpi_alloc_limb_space(2 * (msize + 1));\n\t\tif (!xp)\n\t\t\tgoto enomem;\n\n\t\tmemset(&karactx, 0, sizeof karactx);\n\t\tnegative_result = (ep[0] & 1) && base->sign;\n\n\t\ti = esize - 1;\n\t\te = ep[i];\n\t\tc = count_leading_zeros(e);\n\t\te = (e << c) << 1;\t/* shift the exp bits to the left, lose msb */\n\t\tc = BITS_PER_MPI_LIMB - 1 - c;\n\n\t\t/* Main loop.\n\t\t *\n\t\t * Make the result be pointed to alternately by XP and RP.  This\n\t\t * helps us avoid block copying, which would otherwise be necessary\n\t\t * with the overlap restrictions of mpihelp_divmod. With 50% probability\n\t\t * the result after this loop will be in the area originally pointed\n\t\t * by RP (==RES->d), and with 50% probability in the area originally\n\t\t * pointed to by XP.\n\t\t */\n\n\t\tfor (;;) {\n\t\t\twhile (c) {\n\t\t\t\tmpi_ptr_t tp;\n\t\t\t\tmpi_size_t xsize;\n\n\t\t\t\t/*if (mpihelp_mul_n(xp, rp, rp, rsize) < 0) goto enomem */\n\t\t\t\tif (rsize < KARATSUBA_THRESHOLD)\n\t\t\t\t\tmpih_sqr_n_basecase(xp, rp, rsize);\n\t\t\t\telse {\n\t\t\t\t\tif (!tspace) {\n\t\t\t\t\t\ttsize = 2 * rsize;\n\t\t\t\t\t\ttspace =\n\t\t\t\t\t\t    mpi_alloc_limb_space(tsize);\n\t\t\t\t\t\tif (!tspace)\n\t\t\t\t\t\t\tgoto enomem;\n\t\t\t\t\t} else if (tsize < (2 * rsize)) {\n\t\t\t\t\t\tmpi_free_limb_space(tspace);\n\t\t\t\t\t\ttsize = 2 * rsize;\n\t\t\t\t\t\ttspace =\n\t\t\t\t\t\t    mpi_alloc_limb_space(tsize);\n\t\t\t\t\t\tif (!tspace)\n\t\t\t\t\t\t\tgoto enomem;\n\t\t\t\t\t}\n\t\t\t\t\tmpih_sqr_n(xp, rp, rsize, tspace);\n\t\t\t\t}\n\n\t\t\t\txsize = 2 * rsize;\n\t\t\t\tif (xsize > msize) {\n\t\t\t\t\tmpihelp_divrem(xp + msize, 0, xp, xsize,\n\t\t\t\t\t\t       mp, msize);\n\t\t\t\t\txsize = msize;\n\t\t\t\t}\n\n\t\t\t\ttp = rp;\n\t\t\t\trp = xp;\n\t\t\t\txp = tp;\n\t\t\t\trsize = xsize;\n\n\t\t\t\tif ((mpi_limb_signed_t) e < 0) {\n\t\t\t\t\t/*mpihelp_mul( xp, rp, rsize, bp, bsize ); */\n\t\t\t\t\tif (bsize < KARATSUBA_THRESHOLD) {\n\t\t\t\t\t\tmpi_limb_t tmp;\n\t\t\t\t\t\tif (mpihelp_mul\n\t\t\t\t\t\t    (xp, rp, rsize, bp, bsize,\n\t\t\t\t\t\t     &tmp) < 0)\n\t\t\t\t\t\t\tgoto enomem;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tif (mpihelp_mul_karatsuba_case\n\t\t\t\t\t\t    (xp, rp, rsize, bp, bsize,\n\t\t\t\t\t\t     &karactx) < 0)\n\t\t\t\t\t\t\tgoto enomem;\n\t\t\t\t\t}\n\n\t\t\t\t\txsize = rsize + bsize;\n\t\t\t\t\tif (xsize > msize) {\n\t\t\t\t\t\tmpihelp_divrem(xp + msize, 0,\n\t\t\t\t\t\t\t       xp, xsize, mp,\n\t\t\t\t\t\t\t       msize);\n\t\t\t\t\t\txsize = msize;\n\t\t\t\t\t}\n\n\t\t\t\t\ttp = rp;\n\t\t\t\t\trp = xp;\n\t\t\t\t\txp = tp;\n\t\t\t\t\trsize = xsize;\n\t\t\t\t}\n\t\t\t\te <<= 1;\n\t\t\t\tc--;\n\t\t\t}\n\n\t\t\ti--;\n\t\t\tif (i < 0)\n\t\t\t\tbreak;\n\t\t\te = ep[i];\n\t\t\tc = BITS_PER_MPI_LIMB;\n\t\t}\n\n\t\t/* We shifted MOD, the modulo reduction argument, left MOD_SHIFT_CNT\n\t\t * steps.  Adjust the result by reducing it with the original MOD.\n\t\t *\n\t\t * Also make sure the result is put in RES->d (where it already\n\t\t * might be, see above).\n\t\t */\n\t\tif (mod_shift_cnt) {\n\t\t\tcarry_limb =\n\t\t\t    mpihelp_lshift(res->d, rp, rsize, mod_shift_cnt);\n\t\t\trp = res->d;\n\t\t\tif (carry_limb) {\n\t\t\t\trp[rsize] = carry_limb;\n\t\t\t\trsize++;\n\t\t\t}\n\t\t} else {\n\t\t\tMPN_COPY(res->d, rp, rsize);\n\t\t\trp = res->d;\n\t\t}\n\n\t\tif (rsize >= msize) {\n\t\t\tmpihelp_divrem(rp + msize, 0, rp, rsize, mp, msize);\n\t\t\trsize = msize;\n\t\t}\n\n\t\t/* Remove any leading zero words from the result.  */\n\t\tif (mod_shift_cnt)\n\t\t\tmpihelp_rshift(rp, rp, rsize, mod_shift_cnt);\n\t\tMPN_NORMALIZE(rp, rsize);\n\n\t\tmpihelp_release_karatsuba_ctx(&karactx);\n\t}\n\n\tif (negative_result && rsize) {\n\t\tif (mod_shift_cnt)\n\t\t\tmpihelp_rshift(mp, mp, msize, mod_shift_cnt);\n\t\tmpihelp_sub(rp, mp, msize, rp, rsize);\n\t\trsize = msize;\n\t\trsign = msign;\n\t\tMPN_NORMALIZE(rp, rsize);\n\t}\n\tres->nlimbs = rsize;\n\tres->sign = rsign;\n\nleave:\n\trc = 0;\nenomem:\n\tif (assign_rp)\n\t\tmpi_assign_limb_space(res, rp, size);\n\tif (mp_marker)\n\t\tmpi_free_limb_space(mp_marker);\n\tif (bp_marker)\n\t\tmpi_free_limb_space(bp_marker);\n\tif (ep_marker)\n\t\tmpi_free_limb_space(ep_marker);\n\tif (xp_marker)\n\t\tmpi_free_limb_space(xp_marker);\n\tif (tspace)\n\t\tmpi_free_limb_space(tspace);\n\treturn rc;\n}",
        "func": "int mpi_powm(MPI res, MPI base, MPI exp, MPI mod)\n{\n\tmpi_ptr_t mp_marker = NULL, bp_marker = NULL, ep_marker = NULL;\n\tmpi_ptr_t xp_marker = NULL;\n\tmpi_ptr_t tspace = NULL;\n\tmpi_ptr_t rp, ep, mp, bp;\n\tmpi_size_t esize, msize, bsize, rsize;\n\tint esign, msign, bsign, rsign;\n\tmpi_size_t size;\n\tint mod_shift_cnt;\n\tint negative_result;\n\tint assign_rp = 0;\n\tmpi_size_t tsize = 0;\t/* to avoid compiler warning */\n\t/* fixme: we should check that the warning is void */\n\tint rc = -ENOMEM;\n\n\tesize = exp->nlimbs;\n\tmsize = mod->nlimbs;\n\tsize = 2 * msize;\n\tesign = exp->sign;\n\tmsign = mod->sign;\n\n\trp = res->d;\n\tep = exp->d;\n\n\tif (!msize)\n\t\treturn -EINVAL;\n\n\tif (!esize) {\n\t\t/* Exponent is zero, result is 1 mod MOD, i.e., 1 or 0\n\t\t * depending on if MOD equals 1.  */\n\t\tres->nlimbs = (msize == 1 && mod->d[0] == 1) ? 0 : 1;\n\t\tif (res->nlimbs) {\n\t\t\tif (mpi_resize(res, 1) < 0)\n\t\t\t\tgoto enomem;\n\t\t\trp = res->d;\n\t\t\trp[0] = 1;\n\t\t}\n\t\tres->sign = 0;\n\t\tgoto leave;\n\t}\n\n\t/* Normalize MOD (i.e. make its most significant bit set) as required by\n\t * mpn_divrem.  This will make the intermediate values in the calculation\n\t * slightly larger, but the correct result is obtained after a final\n\t * reduction using the original MOD value.  */\n\tmp = mp_marker = mpi_alloc_limb_space(msize);\n\tif (!mp)\n\t\tgoto enomem;\n\tmod_shift_cnt = count_leading_zeros(mod->d[msize - 1]);\n\tif (mod_shift_cnt)\n\t\tmpihelp_lshift(mp, mod->d, msize, mod_shift_cnt);\n\telse\n\t\tMPN_COPY(mp, mod->d, msize);\n\n\tbsize = base->nlimbs;\n\tbsign = base->sign;\n\tif (bsize > msize) {\t/* The base is larger than the module. Reduce it. */\n\t\t/* Allocate (BSIZE + 1) with space for remainder and quotient.\n\t\t * (The quotient is (bsize - msize + 1) limbs.)  */\n\t\tbp = bp_marker = mpi_alloc_limb_space(bsize + 1);\n\t\tif (!bp)\n\t\t\tgoto enomem;\n\t\tMPN_COPY(bp, base->d, bsize);\n\t\t/* We don't care about the quotient, store it above the remainder,\n\t\t * at BP + MSIZE.  */\n\t\tmpihelp_divrem(bp + msize, 0, bp, bsize, mp, msize);\n\t\tbsize = msize;\n\t\t/* Canonicalize the base, since we are going to multiply with it\n\t\t * quite a few times.  */\n\t\tMPN_NORMALIZE(bp, bsize);\n\t} else\n\t\tbp = base->d;\n\n\tif (!bsize) {\n\t\tres->nlimbs = 0;\n\t\tres->sign = 0;\n\t\tgoto leave;\n\t}\n\n\tif (res->alloced < size) {\n\t\t/* We have to allocate more space for RES.  If any of the input\n\t\t * parameters are identical to RES, defer deallocation of the old\n\t\t * space.  */\n\t\tif (rp == ep || rp == mp || rp == bp) {\n\t\t\trp = mpi_alloc_limb_space(size);\n\t\t\tif (!rp)\n\t\t\t\tgoto enomem;\n\t\t\tassign_rp = 1;\n\t\t} else {\n\t\t\tif (mpi_resize(res, size) < 0)\n\t\t\t\tgoto enomem;\n\t\t\trp = res->d;\n\t\t}\n\t} else {\t\t/* Make BASE, EXP and MOD not overlap with RES.  */\n\t\tif (rp == bp) {\n\t\t\t/* RES and BASE are identical.  Allocate temp. space for BASE.  */\n\t\t\tBUG_ON(bp_marker);\n\t\t\tbp = bp_marker = mpi_alloc_limb_space(bsize);\n\t\t\tif (!bp)\n\t\t\t\tgoto enomem;\n\t\t\tMPN_COPY(bp, rp, bsize);\n\t\t}\n\t\tif (rp == ep) {\n\t\t\t/* RES and EXP are identical.  Allocate temp. space for EXP.  */\n\t\t\tep = ep_marker = mpi_alloc_limb_space(esize);\n\t\t\tif (!ep)\n\t\t\t\tgoto enomem;\n\t\t\tMPN_COPY(ep, rp, esize);\n\t\t}\n\t\tif (rp == mp) {\n\t\t\t/* RES and MOD are identical.  Allocate temporary space for MOD. */\n\t\t\tBUG_ON(mp_marker);\n\t\t\tmp = mp_marker = mpi_alloc_limb_space(msize);\n\t\t\tif (!mp)\n\t\t\t\tgoto enomem;\n\t\t\tMPN_COPY(mp, rp, msize);\n\t\t}\n\t}\n\n\tMPN_COPY(rp, bp, bsize);\n\trsize = bsize;\n\trsign = bsign;\n\n\t{\n\t\tmpi_size_t i;\n\t\tmpi_ptr_t xp;\n\t\tint c;\n\t\tmpi_limb_t e;\n\t\tmpi_limb_t carry_limb;\n\t\tstruct karatsuba_ctx karactx;\n\n\t\txp = xp_marker = mpi_alloc_limb_space(2 * (msize + 1));\n\t\tif (!xp)\n\t\t\tgoto enomem;\n\n\t\tmemset(&karactx, 0, sizeof karactx);\n\t\tnegative_result = (ep[0] & 1) && base->sign;\n\n\t\ti = esize - 1;\n\t\te = ep[i];\n\t\tc = count_leading_zeros(e);\n\t\te = (e << c) << 1;\t/* shift the exp bits to the left, lose msb */\n\t\tc = BITS_PER_MPI_LIMB - 1 - c;\n\n\t\t/* Main loop.\n\t\t *\n\t\t * Make the result be pointed to alternately by XP and RP.  This\n\t\t * helps us avoid block copying, which would otherwise be necessary\n\t\t * with the overlap restrictions of mpihelp_divmod. With 50% probability\n\t\t * the result after this loop will be in the area originally pointed\n\t\t * by RP (==RES->d), and with 50% probability in the area originally\n\t\t * pointed to by XP.\n\t\t */\n\n\t\tfor (;;) {\n\t\t\twhile (c) {\n\t\t\t\tmpi_ptr_t tp;\n\t\t\t\tmpi_size_t xsize;\n\n\t\t\t\t/*if (mpihelp_mul_n(xp, rp, rp, rsize) < 0) goto enomem */\n\t\t\t\tif (rsize < KARATSUBA_THRESHOLD)\n\t\t\t\t\tmpih_sqr_n_basecase(xp, rp, rsize);\n\t\t\t\telse {\n\t\t\t\t\tif (!tspace) {\n\t\t\t\t\t\ttsize = 2 * rsize;\n\t\t\t\t\t\ttspace =\n\t\t\t\t\t\t    mpi_alloc_limb_space(tsize);\n\t\t\t\t\t\tif (!tspace)\n\t\t\t\t\t\t\tgoto enomem;\n\t\t\t\t\t} else if (tsize < (2 * rsize)) {\n\t\t\t\t\t\tmpi_free_limb_space(tspace);\n\t\t\t\t\t\ttsize = 2 * rsize;\n\t\t\t\t\t\ttspace =\n\t\t\t\t\t\t    mpi_alloc_limb_space(tsize);\n\t\t\t\t\t\tif (!tspace)\n\t\t\t\t\t\t\tgoto enomem;\n\t\t\t\t\t}\n\t\t\t\t\tmpih_sqr_n(xp, rp, rsize, tspace);\n\t\t\t\t}\n\n\t\t\t\txsize = 2 * rsize;\n\t\t\t\tif (xsize > msize) {\n\t\t\t\t\tmpihelp_divrem(xp + msize, 0, xp, xsize,\n\t\t\t\t\t\t       mp, msize);\n\t\t\t\t\txsize = msize;\n\t\t\t\t}\n\n\t\t\t\ttp = rp;\n\t\t\t\trp = xp;\n\t\t\t\txp = tp;\n\t\t\t\trsize = xsize;\n\n\t\t\t\tif ((mpi_limb_signed_t) e < 0) {\n\t\t\t\t\t/*mpihelp_mul( xp, rp, rsize, bp, bsize ); */\n\t\t\t\t\tif (bsize < KARATSUBA_THRESHOLD) {\n\t\t\t\t\t\tmpi_limb_t tmp;\n\t\t\t\t\t\tif (mpihelp_mul\n\t\t\t\t\t\t    (xp, rp, rsize, bp, bsize,\n\t\t\t\t\t\t     &tmp) < 0)\n\t\t\t\t\t\t\tgoto enomem;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tif (mpihelp_mul_karatsuba_case\n\t\t\t\t\t\t    (xp, rp, rsize, bp, bsize,\n\t\t\t\t\t\t     &karactx) < 0)\n\t\t\t\t\t\t\tgoto enomem;\n\t\t\t\t\t}\n\n\t\t\t\t\txsize = rsize + bsize;\n\t\t\t\t\tif (xsize > msize) {\n\t\t\t\t\t\tmpihelp_divrem(xp + msize, 0,\n\t\t\t\t\t\t\t       xp, xsize, mp,\n\t\t\t\t\t\t\t       msize);\n\t\t\t\t\t\txsize = msize;\n\t\t\t\t\t}\n\n\t\t\t\t\ttp = rp;\n\t\t\t\t\trp = xp;\n\t\t\t\t\txp = tp;\n\t\t\t\t\trsize = xsize;\n\t\t\t\t}\n\t\t\t\te <<= 1;\n\t\t\t\tc--;\n\t\t\t}\n\n\t\t\ti--;\n\t\t\tif (i < 0)\n\t\t\t\tbreak;\n\t\t\te = ep[i];\n\t\t\tc = BITS_PER_MPI_LIMB;\n\t\t}\n\n\t\t/* We shifted MOD, the modulo reduction argument, left MOD_SHIFT_CNT\n\t\t * steps.  Adjust the result by reducing it with the original MOD.\n\t\t *\n\t\t * Also make sure the result is put in RES->d (where it already\n\t\t * might be, see above).\n\t\t */\n\t\tif (mod_shift_cnt) {\n\t\t\tcarry_limb =\n\t\t\t    mpihelp_lshift(res->d, rp, rsize, mod_shift_cnt);\n\t\t\trp = res->d;\n\t\t\tif (carry_limb) {\n\t\t\t\trp[rsize] = carry_limb;\n\t\t\t\trsize++;\n\t\t\t}\n\t\t} else {\n\t\t\tMPN_COPY(res->d, rp, rsize);\n\t\t\trp = res->d;\n\t\t}\n\n\t\tif (rsize >= msize) {\n\t\t\tmpihelp_divrem(rp + msize, 0, rp, rsize, mp, msize);\n\t\t\trsize = msize;\n\t\t}\n\n\t\t/* Remove any leading zero words from the result.  */\n\t\tif (mod_shift_cnt)\n\t\t\tmpihelp_rshift(rp, rp, rsize, mod_shift_cnt);\n\t\tMPN_NORMALIZE(rp, rsize);\n\n\t\tmpihelp_release_karatsuba_ctx(&karactx);\n\t}\n\n\tif (negative_result && rsize) {\n\t\tif (mod_shift_cnt)\n\t\t\tmpihelp_rshift(mp, mp, msize, mod_shift_cnt);\n\t\tmpihelp_sub(rp, mp, msize, rp, rsize);\n\t\trsize = msize;\n\t\trsign = msign;\n\t\tMPN_NORMALIZE(rp, rsize);\n\t}\n\tres->nlimbs = rsize;\n\tres->sign = rsign;\n\nleave:\n\trc = 0;\nenomem:\n\tif (assign_rp)\n\t\tmpi_assign_limb_space(res, rp, size);\n\tif (mp_marker)\n\t\tmpi_free_limb_space(mp_marker);\n\tif (bp_marker)\n\t\tmpi_free_limb_space(bp_marker);\n\tif (ep_marker)\n\t\tmpi_free_limb_space(ep_marker);\n\tif (xp_marker)\n\t\tmpi_free_limb_space(xp_marker);\n\tif (tspace)\n\t\tmpi_free_limb_space(tspace);\n\treturn rc;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -29,8 +29,13 @@\n \tif (!esize) {\n \t\t/* Exponent is zero, result is 1 mod MOD, i.e., 1 or 0\n \t\t * depending on if MOD equals 1.  */\n-\t\trp[0] = 1;\n \t\tres->nlimbs = (msize == 1 && mod->d[0] == 1) ? 0 : 1;\n+\t\tif (res->nlimbs) {\n+\t\t\tif (mpi_resize(res, 1) < 0)\n+\t\t\t\tgoto enomem;\n+\t\t\trp = res->d;\n+\t\t\trp[0] = 1;\n+\t\t}\n \t\tres->sign = 0;\n \t\tgoto leave;\n \t}",
        "diff_line_info": {
            "deleted_lines": [
                "\t\trp[0] = 1;"
            ],
            "added_lines": [
                "\t\tif (res->nlimbs) {",
                "\t\t\tif (mpi_resize(res, 1) < 0)",
                "\t\t\t\tgoto enomem;",
                "\t\t\trp = res->d;",
                "\t\t\trp[0] = 1;",
                "\t\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-9191",
        "func_name": "torvalds/linux/proc_sys_readdir",
        "description": "The cgroup offline implementation in the Linux kernel through 4.8.11 mishandles certain drain operations, which allows local users to cause a denial of service (system hang) by leveraging access to a container environment for executing a crafted application, as demonstrated by trinity.",
        "git_url": "https://github.com/torvalds/linux/commit/93362fa47fe98b62e4a34ab408c4a418432e7939",
        "commit_title": "sysctl: Drop reference added by grab_header in proc_sys_readdir",
        "commit_text": " Fixes CVE-2016-9191, proc_sys_readdir doesn't drop reference added by grab_header when return from !dir_emit_dots path. It can cause any path called unregister_sysctl_table will wait forever.  The calltrace of CVE-2016-9191:  [ 5535.960522] Call Trace: [ 5535.963265]  [<ffffffff817cdaaf>] schedule+0x3f/0xa0 [ 5535.968817]  [<ffffffff817d33fb>] schedule_timeout+0x3db/0x6f0 [ 5535.975346]  [<ffffffff817cf055>] ? wait_for_completion+0x45/0x130 [ 5535.982256]  [<ffffffff817cf0d3>] wait_for_completion+0xc3/0x130 [ 5535.988972]  [<ffffffff810d1fd0>] ? wake_up_q+0x80/0x80 [ 5535.994804]  [<ffffffff8130de64>] drop_sysctl_table+0xc4/0xe0 [ 5536.001227]  [<ffffffff8130de17>] drop_sysctl_table+0x77/0xe0 [ 5536.007648]  [<ffffffff8130decd>] unregister_sysctl_table+0x4d/0xa0 [ 5536.014654]  [<ffffffff8130deff>] unregister_sysctl_table+0x7f/0xa0 [ 5536.021657]  [<ffffffff810f57f5>] unregister_sched_domain_sysctl+0x15/0x40 [ 5536.029344]  [<ffffffff810d7704>] partition_sched_domains+0x44/0x450 [ 5536.036447]  [<ffffffff817d0761>] ? __mutex_unlock_slowpath+0x111/0x1f0 [ 5536.043844]  [<ffffffff81167684>] rebuild_sched_domains_locked+0x64/0xb0 [ 5536.051336]  [<ffffffff8116789d>] update_flag+0x11d/0x210 [ 5536.057373]  [<ffffffff817cf61f>] ? mutex_lock_nested+0x2df/0x450 [ 5536.064186]  [<ffffffff81167acb>] ? cpuset_css_offline+0x1b/0x60 [ 5536.070899]  [<ffffffff810fce3d>] ? trace_hardirqs_on+0xd/0x10 [ 5536.077420]  [<ffffffff817cf61f>] ? mutex_lock_nested+0x2df/0x450 [ 5536.084234]  [<ffffffff8115a9f5>] ? css_killed_work_fn+0x25/0x220 [ 5536.091049]  [<ffffffff81167ae5>] cpuset_css_offline+0x35/0x60 [ 5536.097571]  [<ffffffff8115aa2c>] css_killed_work_fn+0x5c/0x220 [ 5536.104207]  [<ffffffff810bc83f>] process_one_work+0x1df/0x710 [ 5536.110736]  [<ffffffff810bc7c0>] ? process_one_work+0x160/0x710 [ 5536.117461]  [<ffffffff810bce9b>] worker_thread+0x12b/0x4a0 [ 5536.123697]  [<ffffffff810bcd70>] ? process_one_work+0x710/0x710 [ 5536.130426]  [<ffffffff810c3f7e>] kthread+0xfe/0x120 [ 5536.135991]  [<ffffffff817d4baf>] ret_from_fork+0x1f/0x40 [ 5536.142041]  [<ffffffff810c3e80>] ? kthread_create_on_node+0x230/0x230  One cgroup maintainer mentioned that \"cgroup is trying to offline a cpuset css, which takes place under cgroup_mutex.  The offlining ends up trying to drain active usages of a sysctl table which apprently is not happening.\" The real reason is that proc_sys_readdir doesn't drop reference added by grab_header when return from !dir_emit_dots path. So this cpuset offline path will wait here forever.  See here for details: http://www.openwall.com/lists/oss-security/2016/11/04/13  Cc: stable@vger.kernel.org",
        "func_before": "static int proc_sys_readdir(struct file *file, struct dir_context *ctx)\n{\n\tstruct ctl_table_header *head = grab_header(file_inode(file));\n\tstruct ctl_table_header *h = NULL;\n\tstruct ctl_table *entry;\n\tstruct ctl_dir *ctl_dir;\n\tunsigned long pos;\n\n\tif (IS_ERR(head))\n\t\treturn PTR_ERR(head);\n\n\tctl_dir = container_of(head, struct ctl_dir, header);\n\n\tif (!dir_emit_dots(file, ctx))\n\t\treturn 0;\n\n\tpos = 2;\n\n\tfor (first_entry(ctl_dir, &h, &entry); h; next_entry(&h, &entry)) {\n\t\tif (!scan(h, entry, &pos, file, ctx)) {\n\t\t\tsysctl_head_finish(h);\n\t\t\tbreak;\n\t\t}\n\t}\n\tsysctl_head_finish(head);\n\treturn 0;\n}",
        "func": "static int proc_sys_readdir(struct file *file, struct dir_context *ctx)\n{\n\tstruct ctl_table_header *head = grab_header(file_inode(file));\n\tstruct ctl_table_header *h = NULL;\n\tstruct ctl_table *entry;\n\tstruct ctl_dir *ctl_dir;\n\tunsigned long pos;\n\n\tif (IS_ERR(head))\n\t\treturn PTR_ERR(head);\n\n\tctl_dir = container_of(head, struct ctl_dir, header);\n\n\tif (!dir_emit_dots(file, ctx))\n\t\tgoto out;\n\n\tpos = 2;\n\n\tfor (first_entry(ctl_dir, &h, &entry); h; next_entry(&h, &entry)) {\n\t\tif (!scan(h, entry, &pos, file, ctx)) {\n\t\t\tsysctl_head_finish(h);\n\t\t\tbreak;\n\t\t}\n\t}\nout:\n\tsysctl_head_finish(head);\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -12,7 +12,7 @@\n \tctl_dir = container_of(head, struct ctl_dir, header);\n \n \tif (!dir_emit_dots(file, ctx))\n-\t\treturn 0;\n+\t\tgoto out;\n \n \tpos = 2;\n \n@@ -22,6 +22,7 @@\n \t\t\tbreak;\n \t\t}\n \t}\n+out:\n \tsysctl_head_finish(head);\n \treturn 0;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\t\treturn 0;"
            ],
            "added_lines": [
                "\t\tgoto out;",
                "out:"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-8740",
        "func_name": "apache/httpd/on_header_cb",
        "description": "The mod_http2 module in the Apache HTTP Server 2.4.17 through 2.4.23, when the Protocols configuration includes h2 or h2c, does not restrict request-header length, which allows remote attackers to cause a denial of service (memory consumption) via crafted CONTINUATION frames in an HTTP/2 request.",
        "git_url": "https://github.com/apache/httpd/commit/29c63b786ae028d82405421585e91283c8fa0da3",
        "commit_title": "SECURITY: CVE-2016-8740",
        "commit_text": " mod_http2: properly crafted, endless HTTP/2 CONTINUATION frames could be used to exhaust all server's memory.  Reported by: Naveen Tiwari <naveen.tiwari@asu.edu> and CDF/SEFCOM at Arizona State University   ",
        "func_before": "static int on_header_cb(nghttp2_session *ngh2, const nghttp2_frame *frame,\n                        const uint8_t *name, size_t namelen,\n                        const uint8_t *value, size_t valuelen,\n                        uint8_t flags,\n                        void *userp)\n{\n    h2_session *session = (h2_session *)userp;\n    h2_stream * stream;\n    apr_status_t status;\n    \n    (void)flags;\n    stream = get_stream(session, frame->hd.stream_id);\n    if (!stream) {\n        ap_log_cerror(APLOG_MARK, APLOG_ERR, 0, session->c,\n                      APLOGNO(02920) \n                      \"h2_session:  stream(%ld-%d): on_header unknown stream\",\n                      session->id, (int)frame->hd.stream_id);\n        return NGHTTP2_ERR_TEMPORAL_CALLBACK_FAILURE;\n    }\n    \n    status = h2_stream_add_header(stream, (const char *)name, namelen,\n                                  (const char *)value, valuelen);\n    if (status != APR_SUCCESS && !h2_stream_is_ready(stream)) {\n        return NGHTTP2_ERR_TEMPORAL_CALLBACK_FAILURE;\n    }\n    return 0;\n}",
        "func": "static int on_header_cb(nghttp2_session *ngh2, const nghttp2_frame *frame,\n                        const uint8_t *name, size_t namelen,\n                        const uint8_t *value, size_t valuelen,\n                        uint8_t flags,\n                        void *userp)\n{\n    h2_session *session = (h2_session *)userp;\n    h2_stream * stream;\n    apr_status_t status;\n    \n    (void)flags;\n    stream = get_stream(session, frame->hd.stream_id);\n    if (!stream) {\n        ap_log_cerror(APLOG_MARK, APLOG_DEBUG, 0, session->c,\n                      APLOGNO(02920) \n                      \"h2_session:  stream(%ld-%d): on_header unknown stream\",\n                      session->id, (int)frame->hd.stream_id);\n        return NGHTTP2_ERR_TEMPORAL_CALLBACK_FAILURE;\n    }\n    \n    status = h2_stream_add_header(stream, (const char *)name, namelen,\n                                  (const char *)value, valuelen);\n    if (status == APR_ECONNRESET) {\n        ap_log_cerror(APLOG_MARK, APLOG_TRACE1, status, session->c,\n                      \"h2-stream(%ld-%d): on_header, reset stream\",\n                      session->id, stream->id);\n        nghttp2_submit_rst_stream(ngh2, NGHTTP2_FLAG_NONE, stream->id,\n                                  NGHTTP2_INTERNAL_ERROR);\n    }\n    else if (status != APR_SUCCESS && !h2_stream_is_ready(stream)) {\n        return NGHTTP2_ERR_TEMPORAL_CALLBACK_FAILURE;\n    }\n    return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -11,7 +11,7 @@\n     (void)flags;\n     stream = get_stream(session, frame->hd.stream_id);\n     if (!stream) {\n-        ap_log_cerror(APLOG_MARK, APLOG_ERR, 0, session->c,\n+        ap_log_cerror(APLOG_MARK, APLOG_DEBUG, 0, session->c,\n                       APLOGNO(02920) \n                       \"h2_session:  stream(%ld-%d): on_header unknown stream\",\n                       session->id, (int)frame->hd.stream_id);\n@@ -20,7 +20,14 @@\n     \n     status = h2_stream_add_header(stream, (const char *)name, namelen,\n                                   (const char *)value, valuelen);\n-    if (status != APR_SUCCESS && !h2_stream_is_ready(stream)) {\n+    if (status == APR_ECONNRESET) {\n+        ap_log_cerror(APLOG_MARK, APLOG_TRACE1, status, session->c,\n+                      \"h2-stream(%ld-%d): on_header, reset stream\",\n+                      session->id, stream->id);\n+        nghttp2_submit_rst_stream(ngh2, NGHTTP2_FLAG_NONE, stream->id,\n+                                  NGHTTP2_INTERNAL_ERROR);\n+    }\n+    else if (status != APR_SUCCESS && !h2_stream_is_ready(stream)) {\n         return NGHTTP2_ERR_TEMPORAL_CALLBACK_FAILURE;\n     }\n     return 0;",
        "diff_line_info": {
            "deleted_lines": [
                "        ap_log_cerror(APLOG_MARK, APLOG_ERR, 0, session->c,",
                "    if (status != APR_SUCCESS && !h2_stream_is_ready(stream)) {"
            ],
            "added_lines": [
                "        ap_log_cerror(APLOG_MARK, APLOG_DEBUG, 0, session->c,",
                "    if (status == APR_ECONNRESET) {",
                "        ap_log_cerror(APLOG_MARK, APLOG_TRACE1, status, session->c,",
                "                      \"h2-stream(%ld-%d): on_header, reset stream\",",
                "                      session->id, stream->id);",
                "        nghttp2_submit_rst_stream(ngh2, NGHTTP2_FLAG_NONE, stream->id,",
                "                                  NGHTTP2_INTERNAL_ERROR);",
                "    }",
                "    else if (status != APR_SUCCESS && !h2_stream_is_ready(stream)) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-8740",
        "func_name": "apache/httpd/h2_stream_add_header",
        "description": "The mod_http2 module in the Apache HTTP Server 2.4.17 through 2.4.23, when the Protocols configuration includes h2 or h2c, does not restrict request-header length, which allows remote attackers to cause a denial of service (memory consumption) via crafted CONTINUATION frames in an HTTP/2 request.",
        "git_url": "https://github.com/apache/httpd/commit/29c63b786ae028d82405421585e91283c8fa0da3",
        "commit_title": "SECURITY: CVE-2016-8740",
        "commit_text": " mod_http2: properly crafted, endless HTTP/2 CONTINUATION frames could be used to exhaust all server's memory.  Reported by: Naveen Tiwari <naveen.tiwari@asu.edu> and CDF/SEFCOM at Arizona State University   ",
        "func_before": "apr_status_t h2_stream_add_header(h2_stream *stream,\n                                  const char *name, size_t nlen,\n                                  const char *value, size_t vlen)\n{\n    ap_assert(stream);\n    \n    if (!stream->has_response) {\n        if (name[0] == ':') {\n            if ((vlen) > stream->session->s->limit_req_line) {\n                /* pseudo header: approximation of request line size check */\n                ap_log_cerror(APLOG_MARK, APLOG_TRACE1, 0, stream->session->c,\n                              \"h2_stream(%ld-%d): pseudo header %s too long\", \n                              stream->session->id, stream->id, name);\n                return h2_stream_set_error(stream, \n                                           HTTP_REQUEST_URI_TOO_LARGE);\n            }\n        }\n        else if ((nlen + 2 + vlen) > stream->session->s->limit_req_fieldsize) {\n            /* header too long */\n            ap_log_cerror(APLOG_MARK, APLOG_TRACE1, 0, stream->session->c,\n                          \"h2_stream(%ld-%d): header %s too long\", \n                          stream->session->id, stream->id, name);\n            return h2_stream_set_error(stream, \n                                       HTTP_REQUEST_HEADER_FIELDS_TOO_LARGE);\n        }\n        \n        if (name[0] != ':') {\n            ++stream->request_headers_added;\n            if (stream->request_headers_added \n                > stream->session->s->limit_req_fields) {\n                /* too many header lines */\n                ap_log_cerror(APLOG_MARK, APLOG_TRACE1, 0, stream->session->c,\n                              \"h2_stream(%ld-%d): too many header lines\", \n                              stream->session->id, stream->id);\n                return h2_stream_set_error(stream, \n                                           HTTP_REQUEST_HEADER_FIELDS_TOO_LARGE);\n            }\n        }\n    }\n    \n    if (h2_stream_is_scheduled(stream)) {\n        return add_trailer(stream, name, nlen, value, vlen);\n    }\n    else {\n        if (!stream->rtmp) {\n            stream->rtmp = h2_req_create(stream->id, stream->pool, \n                                         NULL, NULL, NULL, NULL, NULL, 0);\n        }\n        if (stream->state != H2_STREAM_ST_OPEN) {\n            return APR_ECONNRESET;\n        }\n        return h2_request_add_header(stream->rtmp, stream->pool,\n                                     name, nlen, value, vlen);\n    }\n}",
        "func": "apr_status_t h2_stream_add_header(h2_stream *stream,\n                                  const char *name, size_t nlen,\n                                  const char *value, size_t vlen)\n{\n    int error = 0;\n    ap_assert(stream);\n    \n    if (stream->has_response) {\n        return APR_EINVAL;    \n    }\n    ++stream->request_headers_added;\n    if (name[0] == ':') {\n        if ((vlen) > stream->session->s->limit_req_line) {\n            /* pseudo header: approximation of request line size check */\n            ap_log_cerror(APLOG_MARK, APLOG_TRACE1, 0, stream->session->c,\n                          \"h2_stream(%ld-%d): pseudo header %s too long\", \n                          stream->session->id, stream->id, name);\n            error = HTTP_REQUEST_URI_TOO_LARGE;\n        }\n    }\n    else if ((nlen + 2 + vlen) > stream->session->s->limit_req_fieldsize) {\n        /* header too long */\n        ap_log_cerror(APLOG_MARK, APLOG_TRACE1, 0, stream->session->c,\n                      \"h2_stream(%ld-%d): header %s too long\", \n                      stream->session->id, stream->id, name);\n        error = HTTP_REQUEST_HEADER_FIELDS_TOO_LARGE;\n    }\n    \n    if (stream->request_headers_added \n        > stream->session->s->limit_req_fields + 4) {\n        /* too many header lines, include 4 pseudo headers */\n        if (stream->request_headers_added \n            > stream->session->s->limit_req_fields + 4 + 100) {\n            /* yeah, right */\n            return APR_ECONNRESET;\n        }\n        ap_log_cerror(APLOG_MARK, APLOG_TRACE1, 0, stream->session->c,\n                      \"h2_stream(%ld-%d): too many header lines\", \n                      stream->session->id, stream->id);\n        error = HTTP_REQUEST_HEADER_FIELDS_TOO_LARGE;\n    }\n    \n    if (h2_stream_is_scheduled(stream)) {\n        return add_trailer(stream, name, nlen, value, vlen);\n    }\n    else if (error) {\n        return h2_stream_set_error(stream, error); \n    }\n    else {\n        if (!stream->rtmp) {\n            stream->rtmp = h2_req_create(stream->id, stream->pool, \n                                         NULL, NULL, NULL, NULL, NULL, 0);\n        }\n        if (stream->state != H2_STREAM_ST_OPEN) {\n            return APR_ECONNRESET;\n        }\n        return h2_request_add_header(stream->rtmp, stream->pool,\n                                     name, nlen, value, vlen);\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,44 +2,49 @@\n                                   const char *name, size_t nlen,\n                                   const char *value, size_t vlen)\n {\n+    int error = 0;\n     ap_assert(stream);\n     \n-    if (!stream->has_response) {\n-        if (name[0] == ':') {\n-            if ((vlen) > stream->session->s->limit_req_line) {\n-                /* pseudo header: approximation of request line size check */\n-                ap_log_cerror(APLOG_MARK, APLOG_TRACE1, 0, stream->session->c,\n-                              \"h2_stream(%ld-%d): pseudo header %s too long\", \n-                              stream->session->id, stream->id, name);\n-                return h2_stream_set_error(stream, \n-                                           HTTP_REQUEST_URI_TOO_LARGE);\n-            }\n+    if (stream->has_response) {\n+        return APR_EINVAL;    \n+    }\n+    ++stream->request_headers_added;\n+    if (name[0] == ':') {\n+        if ((vlen) > stream->session->s->limit_req_line) {\n+            /* pseudo header: approximation of request line size check */\n+            ap_log_cerror(APLOG_MARK, APLOG_TRACE1, 0, stream->session->c,\n+                          \"h2_stream(%ld-%d): pseudo header %s too long\", \n+                          stream->session->id, stream->id, name);\n+            error = HTTP_REQUEST_URI_TOO_LARGE;\n         }\n-        else if ((nlen + 2 + vlen) > stream->session->s->limit_req_fieldsize) {\n-            /* header too long */\n-            ap_log_cerror(APLOG_MARK, APLOG_TRACE1, 0, stream->session->c,\n-                          \"h2_stream(%ld-%d): header %s too long\", \n-                          stream->session->id, stream->id, name);\n-            return h2_stream_set_error(stream, \n-                                       HTTP_REQUEST_HEADER_FIELDS_TOO_LARGE);\n+    }\n+    else if ((nlen + 2 + vlen) > stream->session->s->limit_req_fieldsize) {\n+        /* header too long */\n+        ap_log_cerror(APLOG_MARK, APLOG_TRACE1, 0, stream->session->c,\n+                      \"h2_stream(%ld-%d): header %s too long\", \n+                      stream->session->id, stream->id, name);\n+        error = HTTP_REQUEST_HEADER_FIELDS_TOO_LARGE;\n+    }\n+    \n+    if (stream->request_headers_added \n+        > stream->session->s->limit_req_fields + 4) {\n+        /* too many header lines, include 4 pseudo headers */\n+        if (stream->request_headers_added \n+            > stream->session->s->limit_req_fields + 4 + 100) {\n+            /* yeah, right */\n+            return APR_ECONNRESET;\n         }\n-        \n-        if (name[0] != ':') {\n-            ++stream->request_headers_added;\n-            if (stream->request_headers_added \n-                > stream->session->s->limit_req_fields) {\n-                /* too many header lines */\n-                ap_log_cerror(APLOG_MARK, APLOG_TRACE1, 0, stream->session->c,\n-                              \"h2_stream(%ld-%d): too many header lines\", \n-                              stream->session->id, stream->id);\n-                return h2_stream_set_error(stream, \n-                                           HTTP_REQUEST_HEADER_FIELDS_TOO_LARGE);\n-            }\n-        }\n+        ap_log_cerror(APLOG_MARK, APLOG_TRACE1, 0, stream->session->c,\n+                      \"h2_stream(%ld-%d): too many header lines\", \n+                      stream->session->id, stream->id);\n+        error = HTTP_REQUEST_HEADER_FIELDS_TOO_LARGE;\n     }\n     \n     if (h2_stream_is_scheduled(stream)) {\n         return add_trailer(stream, name, nlen, value, vlen);\n+    }\n+    else if (error) {\n+        return h2_stream_set_error(stream, error); \n     }\n     else {\n         if (!stream->rtmp) {",
        "diff_line_info": {
            "deleted_lines": [
                "    if (!stream->has_response) {",
                "        if (name[0] == ':') {",
                "            if ((vlen) > stream->session->s->limit_req_line) {",
                "                /* pseudo header: approximation of request line size check */",
                "                ap_log_cerror(APLOG_MARK, APLOG_TRACE1, 0, stream->session->c,",
                "                              \"h2_stream(%ld-%d): pseudo header %s too long\", ",
                "                              stream->session->id, stream->id, name);",
                "                return h2_stream_set_error(stream, ",
                "                                           HTTP_REQUEST_URI_TOO_LARGE);",
                "            }",
                "        else if ((nlen + 2 + vlen) > stream->session->s->limit_req_fieldsize) {",
                "            /* header too long */",
                "            ap_log_cerror(APLOG_MARK, APLOG_TRACE1, 0, stream->session->c,",
                "                          \"h2_stream(%ld-%d): header %s too long\", ",
                "                          stream->session->id, stream->id, name);",
                "            return h2_stream_set_error(stream, ",
                "                                       HTTP_REQUEST_HEADER_FIELDS_TOO_LARGE);",
                "        ",
                "        if (name[0] != ':') {",
                "            ++stream->request_headers_added;",
                "            if (stream->request_headers_added ",
                "                > stream->session->s->limit_req_fields) {",
                "                /* too many header lines */",
                "                ap_log_cerror(APLOG_MARK, APLOG_TRACE1, 0, stream->session->c,",
                "                              \"h2_stream(%ld-%d): too many header lines\", ",
                "                              stream->session->id, stream->id);",
                "                return h2_stream_set_error(stream, ",
                "                                           HTTP_REQUEST_HEADER_FIELDS_TOO_LARGE);",
                "            }",
                "        }"
            ],
            "added_lines": [
                "    int error = 0;",
                "    if (stream->has_response) {",
                "        return APR_EINVAL;    ",
                "    }",
                "    ++stream->request_headers_added;",
                "    if (name[0] == ':') {",
                "        if ((vlen) > stream->session->s->limit_req_line) {",
                "            /* pseudo header: approximation of request line size check */",
                "            ap_log_cerror(APLOG_MARK, APLOG_TRACE1, 0, stream->session->c,",
                "                          \"h2_stream(%ld-%d): pseudo header %s too long\", ",
                "                          stream->session->id, stream->id, name);",
                "            error = HTTP_REQUEST_URI_TOO_LARGE;",
                "    }",
                "    else if ((nlen + 2 + vlen) > stream->session->s->limit_req_fieldsize) {",
                "        /* header too long */",
                "        ap_log_cerror(APLOG_MARK, APLOG_TRACE1, 0, stream->session->c,",
                "                      \"h2_stream(%ld-%d): header %s too long\", ",
                "                      stream->session->id, stream->id, name);",
                "        error = HTTP_REQUEST_HEADER_FIELDS_TOO_LARGE;",
                "    }",
                "    ",
                "    if (stream->request_headers_added ",
                "        > stream->session->s->limit_req_fields + 4) {",
                "        /* too many header lines, include 4 pseudo headers */",
                "        if (stream->request_headers_added ",
                "            > stream->session->s->limit_req_fields + 4 + 100) {",
                "            /* yeah, right */",
                "            return APR_ECONNRESET;",
                "        ap_log_cerror(APLOG_MARK, APLOG_TRACE1, 0, stream->session->c,",
                "                      \"h2_stream(%ld-%d): too many header lines\", ",
                "                      stream->session->id, stream->id);",
                "        error = HTTP_REQUEST_HEADER_FIELDS_TOO_LARGE;",
                "    }",
                "    else if (error) {",
                "        return h2_stream_set_error(stream, error); "
            ]
        }
    },
    {
        "cve_id": "CVE-2016-8858",
        "func_name": "openssh/openssh-portable/kex_input_kexinit",
        "description": "The kex_input_kexinit function in kex.c in OpenSSH 6.x and 7.x through 7.3 allows remote attackers to cause a denial of service (memory consumption) by sending many duplicate KEXINIT requests.  NOTE: a third party reports that \"OpenSSH upstream does not consider this as a security issue.\"",
        "git_url": "https://github.com/openssh/openssh-portable/commit/ec165c392ca54317dbe3064a8c200de6531e89ad",
        "commit_title": "upstream commit",
        "commit_text": " Unregister the KEXINIT handler after message has been received. Otherwise an unauthenticated peer can repeat the KEXINIT and cause allocation of up to 128MB -- until the connection is closed. Reported by shilei-c at 360.cn  Upstream-ID: 43649ae12a27ef94290db16d1a98294588b75c05",
        "func_before": "int\nkex_input_kexinit(int type, u_int32_t seq, void *ctxt)\n{\n\tstruct ssh *ssh = ctxt;\n\tstruct kex *kex = ssh->kex;\n\tconst u_char *ptr;\n\tu_int i;\n\tsize_t dlen;\n\tint r;\n\n\tdebug(\"SSH2_MSG_KEXINIT received\");\n\tif (kex == NULL)\n\t\treturn SSH_ERR_INVALID_ARGUMENT;\n\n\tptr = sshpkt_ptr(ssh, &dlen);\n\tif ((r = sshbuf_put(kex->peer, ptr, dlen)) != 0)\n\t\treturn r;\n\n\t/* discard packet */\n\tfor (i = 0; i < KEX_COOKIE_LEN; i++)\n\t\tif ((r = sshpkt_get_u8(ssh, NULL)) != 0)\n\t\t\treturn r;\n\tfor (i = 0; i < PROPOSAL_MAX; i++)\n\t\tif ((r = sshpkt_get_string(ssh, NULL, NULL)) != 0)\n\t\t\treturn r;\n\t/*\n\t * XXX RFC4253 sec 7: \"each side MAY guess\" - currently no supported\n\t * KEX method has the server move first, but a server might be using\n\t * a custom method or one that we otherwise don't support. We should\n\t * be prepared to remember first_kex_follows here so we can eat a\n\t * packet later.\n\t * XXX2 - RFC4253 is kind of ambiguous on what first_kex_follows means\n\t * for cases where the server *doesn't* go first. I guess we should\n\t * ignore it when it is set for these cases, which is what we do now.\n\t */\n\tif ((r = sshpkt_get_u8(ssh, NULL)) != 0 ||\t/* first_kex_follows */\n\t    (r = sshpkt_get_u32(ssh, NULL)) != 0 ||\t/* reserved */\n\t    (r = sshpkt_get_end(ssh)) != 0)\n\t\t\treturn r;\n\n\tif (!(kex->flags & KEX_INIT_SENT))\n\t\tif ((r = kex_send_kexinit(ssh)) != 0)\n\t\t\treturn r;\n\tif ((r = kex_choose_conf(ssh)) != 0)\n\t\treturn r;\n\n\tif (kex->kex_type < KEX_MAX && kex->kex[kex->kex_type] != NULL)\n\t\treturn (kex->kex[kex->kex_type])(ssh);\n\n\treturn SSH_ERR_INTERNAL_ERROR;\n}",
        "func": "int\nkex_input_kexinit(int type, u_int32_t seq, void *ctxt)\n{\n\tstruct ssh *ssh = ctxt;\n\tstruct kex *kex = ssh->kex;\n\tconst u_char *ptr;\n\tu_int i;\n\tsize_t dlen;\n\tint r;\n\n\tdebug(\"SSH2_MSG_KEXINIT received\");\n\tif (kex == NULL)\n\t\treturn SSH_ERR_INVALID_ARGUMENT;\n\n\tssh_dispatch_set(ssh, SSH2_MSG_KEXINIT, NULL);\n\tptr = sshpkt_ptr(ssh, &dlen);\n\tif ((r = sshbuf_put(kex->peer, ptr, dlen)) != 0)\n\t\treturn r;\n\n\t/* discard packet */\n\tfor (i = 0; i < KEX_COOKIE_LEN; i++)\n\t\tif ((r = sshpkt_get_u8(ssh, NULL)) != 0)\n\t\t\treturn r;\n\tfor (i = 0; i < PROPOSAL_MAX; i++)\n\t\tif ((r = sshpkt_get_string(ssh, NULL, NULL)) != 0)\n\t\t\treturn r;\n\t/*\n\t * XXX RFC4253 sec 7: \"each side MAY guess\" - currently no supported\n\t * KEX method has the server move first, but a server might be using\n\t * a custom method or one that we otherwise don't support. We should\n\t * be prepared to remember first_kex_follows here so we can eat a\n\t * packet later.\n\t * XXX2 - RFC4253 is kind of ambiguous on what first_kex_follows means\n\t * for cases where the server *doesn't* go first. I guess we should\n\t * ignore it when it is set for these cases, which is what we do now.\n\t */\n\tif ((r = sshpkt_get_u8(ssh, NULL)) != 0 ||\t/* first_kex_follows */\n\t    (r = sshpkt_get_u32(ssh, NULL)) != 0 ||\t/* reserved */\n\t    (r = sshpkt_get_end(ssh)) != 0)\n\t\t\treturn r;\n\n\tif (!(kex->flags & KEX_INIT_SENT))\n\t\tif ((r = kex_send_kexinit(ssh)) != 0)\n\t\t\treturn r;\n\tif ((r = kex_choose_conf(ssh)) != 0)\n\t\treturn r;\n\n\tif (kex->kex_type < KEX_MAX && kex->kex[kex->kex_type] != NULL)\n\t\treturn (kex->kex[kex->kex_type])(ssh);\n\n\treturn SSH_ERR_INTERNAL_ERROR;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -12,6 +12,7 @@\n \tif (kex == NULL)\n \t\treturn SSH_ERR_INVALID_ARGUMENT;\n \n+\tssh_dispatch_set(ssh, SSH2_MSG_KEXINIT, NULL);\n \tptr = sshpkt_ptr(ssh, &dlen);\n \tif ((r = sshbuf_put(kex->peer, ptr, dlen)) != 0)\n \t\treturn r;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tssh_dispatch_set(ssh, SSH2_MSG_KEXINIT, NULL);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-9633",
        "func_name": "tats/w3m/completeHTMLstream",
        "description": "An issue was discovered in the Tatsuya Kinoshita w3m fork before 0.5.3-33. w3m allows remote attackers to cause a denial of service (infinite loop and resource consumption) via a crafted HTML page.",
        "git_url": "https://github.com/tats/w3m/commit/2e18e9a5987b2a330143528c106c774d4050af47",
        "commit_title": "Prevent memory exhausted due to repeat appending \"</table>\"",
        "commit_text": " Bug-Debian: https://github.com/tats/w3m/issues/23 [CVE-2016-9633] Origin: https://anonscm.debian.org/cgit/collab-maint/w3m.git/commit/?id=216722ed7282cec4338b177ea9ffdd39ad1b8c8c",
        "func_before": "void\ncompleteHTMLstream(struct html_feed_environ *h_env, struct readbuffer *obuf)\n{\n    close_anchor(h_env, obuf);\n    if (obuf->img_alt) {\n\tpush_tag(obuf, \"</img_alt>\", HTML_N_IMG_ALT);\n\tobuf->img_alt = NULL;\n    }\n    if (obuf->input_alt.in) {\n\tpush_tag(obuf, \"</input_alt>\", HTML_N_INPUT_ALT);\n\tobuf->input_alt.hseq = 0;\n\tobuf->input_alt.fid = -1;\n\tobuf->input_alt.in = 0;\n\tobuf->input_alt.type = NULL;\n\tobuf->input_alt.name = NULL;\n\tobuf->input_alt.value = NULL;\n    }\n    if (obuf->in_bold) {\n\tpush_tag(obuf, \"</b>\", HTML_N_B);\n\tobuf->in_bold = 0;\n    }\n    if (obuf->in_italic) {\n\tpush_tag(obuf, \"</i>\", HTML_N_I);\n\tobuf->in_italic = 0;\n    }\n    if (obuf->in_under) {\n\tpush_tag(obuf, \"</u>\", HTML_N_U);\n\tobuf->in_under = 0;\n    }\n    if (obuf->in_strike) {\n\tpush_tag(obuf, \"</s>\", HTML_N_S);\n\tobuf->in_strike = 0;\n    }\n    if (obuf->in_ins) {\n\tpush_tag(obuf, \"</ins>\", HTML_N_INS);\n\tobuf->in_ins = 0;\n    }\n    if (obuf->flag & RB_INTXTA)\n\tHTMLlineproc1(\"</textarea>\", h_env);\n    /* for unbalanced select tag */\n    if (obuf->flag & RB_INSELECT)\n\tHTMLlineproc1(\"</select>\", h_env);\n    if (obuf->flag & RB_TITLE)\n\tHTMLlineproc1(\"</title>\", h_env);\n\n    /* for unbalanced table tag */\n    if (obuf->table_level >= MAX_TABLE)\n\tobuf->table_level = MAX_TABLE - 1;\n\n    while (obuf->table_level >= 0) {\n\ttable_mode[obuf->table_level].pre_mode\n\t    &= ~(TBLM_SCRIPT | TBLM_STYLE | TBLM_PLAIN);\n\tHTMLlineproc1(\"</table>\", h_env);\n    }\n}",
        "func": "void\ncompleteHTMLstream(struct html_feed_environ *h_env, struct readbuffer *obuf)\n{\n    close_anchor(h_env, obuf);\n    if (obuf->img_alt) {\n\tpush_tag(obuf, \"</img_alt>\", HTML_N_IMG_ALT);\n\tobuf->img_alt = NULL;\n    }\n    if (obuf->input_alt.in) {\n\tpush_tag(obuf, \"</input_alt>\", HTML_N_INPUT_ALT);\n\tobuf->input_alt.hseq = 0;\n\tobuf->input_alt.fid = -1;\n\tobuf->input_alt.in = 0;\n\tobuf->input_alt.type = NULL;\n\tobuf->input_alt.name = NULL;\n\tobuf->input_alt.value = NULL;\n    }\n    if (obuf->in_bold) {\n\tpush_tag(obuf, \"</b>\", HTML_N_B);\n\tobuf->in_bold = 0;\n    }\n    if (obuf->in_italic) {\n\tpush_tag(obuf, \"</i>\", HTML_N_I);\n\tobuf->in_italic = 0;\n    }\n    if (obuf->in_under) {\n\tpush_tag(obuf, \"</u>\", HTML_N_U);\n\tobuf->in_under = 0;\n    }\n    if (obuf->in_strike) {\n\tpush_tag(obuf, \"</s>\", HTML_N_S);\n\tobuf->in_strike = 0;\n    }\n    if (obuf->in_ins) {\n\tpush_tag(obuf, \"</ins>\", HTML_N_INS);\n\tobuf->in_ins = 0;\n    }\n    if (obuf->flag & RB_INTXTA)\n\tHTMLlineproc1(\"</textarea>\", h_env);\n    /* for unbalanced select tag */\n    if (obuf->flag & RB_INSELECT)\n\tHTMLlineproc1(\"</select>\", h_env);\n    if (obuf->flag & RB_TITLE)\n\tHTMLlineproc1(\"</title>\", h_env);\n\n    /* for unbalanced table tag */\n    if (obuf->table_level >= MAX_TABLE)\n\tobuf->table_level = MAX_TABLE - 1;\n\n    while (obuf->table_level >= 0) {\n\tint tmp = obuf->table_level;\n\ttable_mode[obuf->table_level].pre_mode\n\t    &= ~(TBLM_SCRIPT | TBLM_STYLE | TBLM_PLAIN);\n\tHTMLlineproc1(\"</table>\", h_env);\n\tif (obuf->table_level >= tmp)\n\t    break;\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -48,8 +48,11 @@\n \tobuf->table_level = MAX_TABLE - 1;\n \n     while (obuf->table_level >= 0) {\n+\tint tmp = obuf->table_level;\n \ttable_mode[obuf->table_level].pre_mode\n \t    &= ~(TBLM_SCRIPT | TBLM_STYLE | TBLM_PLAIN);\n \tHTMLlineproc1(\"</table>\", h_env);\n+\tif (obuf->table_level >= tmp)\n+\t    break;\n     }\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tint tmp = obuf->table_level;",
                "\tif (obuf->table_level >= tmp)",
                "\t    break;"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-6160",
        "func_name": "appneta/tcpreplay/rewrite_packets",
        "description": "tcprewrite in tcpreplay before 4.1.2 allows remote attackers to cause a denial of service (segmentation fault) via a large frame, a related issue to CVE-2017-14266.",
        "git_url": "https://github.com/appneta/tcpreplay/commit/545a5a90fa13a7915580ee0b061c5e8d41119d64",
        "commit_title": "#251 allow 65549 byte frame size",
        "commit_text": "",
        "func_before": "int\nrewrite_packets(tcpedit_t *tcpedit, pcap_t *pin, pcap_dumper_t *pout)\n{\n    tcpr_dir_t cache_result = TCPR_DIR_C2S;     /* default to primary */\n    struct pcap_pkthdr pkthdr, *pkthdr_ptr;     /* packet header */\n    const u_char *pktconst = NULL;              /* packet from libpcap */\n    u_char **pktdata = NULL;\n    static u_char *pktdata_buff;\n    static char *frag = NULL;\n    COUNTER packetnum = 0;\n    int rcode;\n#ifdef ENABLE_FRAGROUTE\n    int frag_len, i, proto;\n#endif\n\n    pkthdr_ptr = &pkthdr;\n\n    if (pktdata_buff == NULL)\n        pktdata_buff = (u_char *)safe_malloc(MAXPACKET);\n\n    pktdata = &pktdata_buff;\n\n    if (frag == NULL)\n        frag = (char *)safe_malloc(MAXPACKET);\n\n    /* MAIN LOOP \n     * Keep sending while we have packets or until\n     * we've sent enough packets\n     */\n    while ((pktconst = pcap_next(pin, pkthdr_ptr)) != NULL) {\n        packetnum++;\n        dbgx(2, \"packet \" COUNTER_SPEC \" caplen %d\", packetnum, pkthdr.caplen);\n\n        /* \n         * copy over the packet so we can pad it out if necessary and\n         * because pcap_next() returns a const ptr\n         */\n        memcpy(*pktdata, pktconst, pkthdr.caplen);\n\n#ifdef ENABLE_VERBOSE\n        if (options.verbose)\n            tcpdump_print(&tcpdump, pkthdr_ptr, *pktdata);\n#endif\n\n        /* Dual nic processing? */\n        if (options.cachedata != NULL) {\n            cache_result = check_cache(options.cachedata, packetnum);\n        }\n\n        /* sometimes we should not send the packet, in such cases\n         * no point in editing this packet at all, just write it to the\n         * output file (note, we can't just remove it, or the tcpprep cache\n         * file will loose it's indexing\n         */\n\n        if (cache_result == TCPR_DIR_NOSEND)\n            goto WRITE_PACKET; /* still need to write it so cache stays in sync */\n\n        if ((rcode = tcpedit_packet(tcpedit, &pkthdr_ptr, pktdata, cache_result)) == TCPEDIT_ERROR) {\n            return -1;\n        } else if ((rcode == TCPEDIT_SOFT_ERROR) && HAVE_OPT(SKIP_SOFT_ERRORS)) {\n            /* don't write packet */\n            dbgx(1, \"Packet \" COUNTER_SPEC \" is suppressed from being written due to soft errors\", packetnum);\n            continue;\n        }\n\n\nWRITE_PACKET:\n#ifdef ENABLE_FRAGROUTE\n        if (options.frag_ctx == NULL) {\n            /* write the packet when there's no fragrouting to be done */\n            pcap_dump((u_char *)pout, pkthdr_ptr, *pktdata);\n        } else {\n            /* get the L3 protocol of the packet */\n            proto = tcpedit_l3proto(tcpedit, AFTER_PROCESS, *pktdata, pkthdr_ptr->caplen);\n\n            /* packet is IPv4/IPv6 AND needs to be fragmented */\n            if ((proto ==  ETHERTYPE_IP || proto == ETHERTYPE_IP6) &&\n                ((options.fragroute_dir == FRAGROUTE_DIR_BOTH) ||\n                 (cache_result == TCPR_DIR_C2S && options.fragroute_dir == FRAGROUTE_DIR_C2S) ||\n                 (cache_result == TCPR_DIR_S2C && options.fragroute_dir == FRAGROUTE_DIR_S2C))) {\n\n                if (fragroute_process(options.frag_ctx, *pktdata, pkthdr_ptr->caplen) < 0)\n                    errx(-1, \"Error processing packet via fragroute: %s\", options.frag_ctx->errbuf);\n\n                i = 0;\n                while ((frag_len = fragroute_getfragment(options.frag_ctx, &frag)) > 0) {\n                    /* frags get the same timestamp as the original packet */\n                    dbgx(1, \"processing packet \" COUNTER_SPEC \" frag: %u (%d)\", packetnum, i++, frag_len);\n                    pkthdr_ptr->caplen = frag_len;\n                    pkthdr_ptr->len = frag_len;\n                    pcap_dump((u_char *)pout, pkthdr_ptr, (u_char *)frag);\n                }\n            } else {\n                /* write the packet without fragroute */\n                pcap_dump((u_char *)pout, pkthdr_ptr, *pktdata);\n            }\n        }\n#else\n    /* write the packet when there's no fragrouting to be done */\n    pcap_dump((u_char *)pout, pkthdr_ptr, *pktdata);\n\n#endif\n    } /* while() */\n    return 0;\n}",
        "func": "int\nrewrite_packets(tcpedit_t *tcpedit, pcap_t *pin, pcap_dumper_t *pout)\n{\n    tcpr_dir_t cache_result = TCPR_DIR_C2S;     /* default to primary */\n    struct pcap_pkthdr pkthdr, *pkthdr_ptr;     /* packet header */\n    const u_char *pktconst = NULL;              /* packet from libpcap */\n    u_char **pktdata = NULL;\n    static u_char *pktdata_buff;\n    static char *frag = NULL;\n    COUNTER packetnum = 0;\n    int rcode;\n#ifdef ENABLE_FRAGROUTE\n    int frag_len, i, proto;\n#endif\n\n    pkthdr_ptr = &pkthdr;\n\n    if (pktdata_buff == NULL)\n        pktdata_buff = (u_char *)safe_malloc(MAXPACKET);\n\n    pktdata = &pktdata_buff;\n\n    if (frag == NULL)\n        frag = (char *)safe_malloc(MAXPACKET);\n\n    /* MAIN LOOP \n     * Keep sending while we have packets or until\n     * we've sent enough packets\n     */\n    while ((pktconst = pcap_next(pin, pkthdr_ptr)) != NULL) {\n        packetnum++;\n        dbgx(2, \"packet \" COUNTER_SPEC \" caplen %d\", packetnum, pkthdr.caplen);\n\n        if (pkthdr.caplen > MAXPACKET)\n            errx(-1, \"Frame too big, caplen %d exceeds %d\", pkthdr.caplen, MAXPACKET);\n        /* \n         * copy over the packet so we can pad it out if necessary and\n         * because pcap_next() returns a const ptr\n         */\n        memcpy(*pktdata, pktconst, pkthdr.caplen);\n\n#ifdef ENABLE_VERBOSE\n        if (options.verbose)\n            tcpdump_print(&tcpdump, pkthdr_ptr, *pktdata);\n#endif\n\n        /* Dual nic processing? */\n        if (options.cachedata != NULL) {\n            cache_result = check_cache(options.cachedata, packetnum);\n        }\n\n        /* sometimes we should not send the packet, in such cases\n         * no point in editing this packet at all, just write it to the\n         * output file (note, we can't just remove it, or the tcpprep cache\n         * file will loose it's indexing\n         */\n\n        if (cache_result == TCPR_DIR_NOSEND)\n            goto WRITE_PACKET; /* still need to write it so cache stays in sync */\n\n        if ((rcode = tcpedit_packet(tcpedit, &pkthdr_ptr, pktdata, cache_result)) == TCPEDIT_ERROR) {\n            return -1;\n        } else if ((rcode == TCPEDIT_SOFT_ERROR) && HAVE_OPT(SKIP_SOFT_ERRORS)) {\n            /* don't write packet */\n            dbgx(1, \"Packet \" COUNTER_SPEC \" is suppressed from being written due to soft errors\", packetnum);\n            continue;\n        }\n\n\nWRITE_PACKET:\n#ifdef ENABLE_FRAGROUTE\n        if (options.frag_ctx == NULL) {\n            /* write the packet when there's no fragrouting to be done */\n            pcap_dump((u_char *)pout, pkthdr_ptr, *pktdata);\n        } else {\n            /* get the L3 protocol of the packet */\n            proto = tcpedit_l3proto(tcpedit, AFTER_PROCESS, *pktdata, pkthdr_ptr->caplen);\n\n            /* packet is IPv4/IPv6 AND needs to be fragmented */\n            if ((proto ==  ETHERTYPE_IP || proto == ETHERTYPE_IP6) &&\n                ((options.fragroute_dir == FRAGROUTE_DIR_BOTH) ||\n                 (cache_result == TCPR_DIR_C2S && options.fragroute_dir == FRAGROUTE_DIR_C2S) ||\n                 (cache_result == TCPR_DIR_S2C && options.fragroute_dir == FRAGROUTE_DIR_S2C))) {\n\n                if (fragroute_process(options.frag_ctx, *pktdata, pkthdr_ptr->caplen) < 0)\n                    errx(-1, \"Error processing packet via fragroute: %s\", options.frag_ctx->errbuf);\n\n                i = 0;\n                while ((frag_len = fragroute_getfragment(options.frag_ctx, &frag)) > 0) {\n                    /* frags get the same timestamp as the original packet */\n                    dbgx(1, \"processing packet \" COUNTER_SPEC \" frag: %u (%d)\", packetnum, i++, frag_len);\n                    pkthdr_ptr->caplen = frag_len;\n                    pkthdr_ptr->len = frag_len;\n                    pcap_dump((u_char *)pout, pkthdr_ptr, (u_char *)frag);\n                }\n            } else {\n                /* write the packet without fragroute */\n                pcap_dump((u_char *)pout, pkthdr_ptr, *pktdata);\n            }\n        }\n#else\n    /* write the packet when there's no fragrouting to be done */\n    pcap_dump((u_char *)pout, pkthdr_ptr, *pktdata);\n\n#endif\n    } /* while() */\n    return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -31,6 +31,8 @@\n         packetnum++;\n         dbgx(2, \"packet \" COUNTER_SPEC \" caplen %d\", packetnum, pkthdr.caplen);\n \n+        if (pkthdr.caplen > MAXPACKET)\n+            errx(-1, \"Frame too big, caplen %d exceeds %d\", pkthdr.caplen, MAXPACKET);\n         /* \n          * copy over the packet so we can pad it out if necessary and\n          * because pcap_next() returns a const ptr",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "        if (pkthdr.caplen > MAXPACKET)",
                "            errx(-1, \"Frame too big, caplen %d exceeds %d\", pkthdr.caplen, MAXPACKET);"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-5307",
        "func_name": "xen-project/xen/svm_do_resume",
        "description": "The KVM subsystem in the Linux kernel through 4.2.6, and Xen 4.3.x through 4.6.x, allows guest OS users to cause a denial of service (host OS panic or hang) by triggering many #AC (aka Alignment Check) exceptions, related to svm.c and vmx.c.",
        "git_url": "https://github.com/xen-project/xen/commit/bd2239d9fa975a1ee5bcd27c218ae042cd0a57bc",
        "commit_title": "x86/HVM: always intercept #AC and #DB",
        "commit_text": " Both being benign exceptions, and both being possible to get triggered by exception delivery, this is required to prevent a guest from locking up a CPU (resulting from no other VM exits occurring once getting into such a loop).  The specific scenarios:  1) #AC may be raised during exception delivery if the handler is set to be a ring-3 one by a 32-bit guest, and the stack is misaligned.  This is CVE-2015-5307 / XSA-156.   2) #DB may be raised during exception delivery when a breakpoint got placed on a data structure involved in delivering the exception. This can result in an endless loop when a 64-bit guest uses a non-zero IST for the vector 1 IDT entry, but even without use of IST the time it takes until a contributory fault would get raised (results depending on the handler) may be quite long.  This is CVE-2015-8104 / XSA-156. ",
        "func_before": "static void noreturn svm_do_resume(struct vcpu *v)\n{\n    struct vmcb_struct *vmcb = v->arch.hvm_svm.vmcb;\n    bool_t debug_state = v->domain->debugger_attached;\n    bool_t vcpu_guestmode = 0;\n\n    if ( nestedhvm_enabled(v->domain) && nestedhvm_vcpu_in_guestmode(v) )\n        vcpu_guestmode = 1;\n\n    if ( !vcpu_guestmode &&\n        unlikely(v->arch.hvm_vcpu.debug_state_latch != debug_state) )\n    {\n        uint32_t intercepts = vmcb_get_exception_intercepts(vmcb);\n        uint32_t mask = (1U << TRAP_debug) | (1U << TRAP_int3);\n        v->arch.hvm_vcpu.debug_state_latch = debug_state;\n        vmcb_set_exception_intercepts(\n            vmcb, debug_state ? (intercepts | mask) : (intercepts & ~mask));\n    }\n\n    if ( v->arch.hvm_svm.launch_core != smp_processor_id() )\n    {\n        v->arch.hvm_svm.launch_core = smp_processor_id();\n        hvm_migrate_timers(v);\n        hvm_migrate_pirqs(v);\n        /* Migrating to another ASID domain.  Request a new ASID. */\n        hvm_asid_flush_vcpu(v);\n    }\n\n    if ( !vcpu_guestmode )\n    {\n        vintr_t intr;\n\n        /* Reflect the vlapic's TPR in the hardware vtpr */\n        intr = vmcb_get_vintr(vmcb);\n        intr.fields.tpr =\n            (vlapic_get_reg(vcpu_vlapic(v), APIC_TASKPRI) & 0xFF) >> 4;\n        vmcb_set_vintr(vmcb, intr);\n    }\n\n    hvm_do_resume(v);\n\n    reset_stack_and_jump(svm_asm_do_resume);\n}",
        "func": "static void noreturn svm_do_resume(struct vcpu *v)\n{\n    struct vmcb_struct *vmcb = v->arch.hvm_svm.vmcb;\n    bool_t debug_state = v->domain->debugger_attached;\n    bool_t vcpu_guestmode = 0;\n\n    if ( nestedhvm_enabled(v->domain) && nestedhvm_vcpu_in_guestmode(v) )\n        vcpu_guestmode = 1;\n\n    if ( !vcpu_guestmode &&\n        unlikely(v->arch.hvm_vcpu.debug_state_latch != debug_state) )\n    {\n        uint32_t intercepts = vmcb_get_exception_intercepts(vmcb);\n\n        v->arch.hvm_vcpu.debug_state_latch = debug_state;\n        vmcb_set_exception_intercepts(\n            vmcb, debug_state ? (intercepts | (1U << TRAP_int3))\n                              : (intercepts & ~(1U << TRAP_int3)));\n    }\n\n    if ( v->arch.hvm_svm.launch_core != smp_processor_id() )\n    {\n        v->arch.hvm_svm.launch_core = smp_processor_id();\n        hvm_migrate_timers(v);\n        hvm_migrate_pirqs(v);\n        /* Migrating to another ASID domain.  Request a new ASID. */\n        hvm_asid_flush_vcpu(v);\n    }\n\n    if ( !vcpu_guestmode )\n    {\n        vintr_t intr;\n\n        /* Reflect the vlapic's TPR in the hardware vtpr */\n        intr = vmcb_get_vintr(vmcb);\n        intr.fields.tpr =\n            (vlapic_get_reg(vcpu_vlapic(v), APIC_TASKPRI) & 0xFF) >> 4;\n        vmcb_set_vintr(vmcb, intr);\n    }\n\n    hvm_do_resume(v);\n\n    reset_stack_and_jump(svm_asm_do_resume);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -11,10 +11,11 @@\n         unlikely(v->arch.hvm_vcpu.debug_state_latch != debug_state) )\n     {\n         uint32_t intercepts = vmcb_get_exception_intercepts(vmcb);\n-        uint32_t mask = (1U << TRAP_debug) | (1U << TRAP_int3);\n+\n         v->arch.hvm_vcpu.debug_state_latch = debug_state;\n         vmcb_set_exception_intercepts(\n-            vmcb, debug_state ? (intercepts | mask) : (intercepts & ~mask));\n+            vmcb, debug_state ? (intercepts | (1U << TRAP_int3))\n+                              : (intercepts & ~(1U << TRAP_int3)));\n     }\n \n     if ( v->arch.hvm_svm.launch_core != smp_processor_id() )",
        "diff_line_info": {
            "deleted_lines": [
                "        uint32_t mask = (1U << TRAP_debug) | (1U << TRAP_int3);",
                "            vmcb, debug_state ? (intercepts | mask) : (intercepts & ~mask));"
            ],
            "added_lines": [
                "",
                "            vmcb, debug_state ? (intercepts | (1U << TRAP_int3))",
                "                              : (intercepts & ~(1U << TRAP_int3)));"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-5307",
        "func_name": "xen-project/xen/svm_vmexit_handler",
        "description": "The KVM subsystem in the Linux kernel through 4.2.6, and Xen 4.3.x through 4.6.x, allows guest OS users to cause a denial of service (host OS panic or hang) by triggering many #AC (aka Alignment Check) exceptions, related to svm.c and vmx.c.",
        "git_url": "https://github.com/xen-project/xen/commit/bd2239d9fa975a1ee5bcd27c218ae042cd0a57bc",
        "commit_title": "x86/HVM: always intercept #AC and #DB",
        "commit_text": " Both being benign exceptions, and both being possible to get triggered by exception delivery, this is required to prevent a guest from locking up a CPU (resulting from no other VM exits occurring once getting into such a loop).  The specific scenarios:  1) #AC may be raised during exception delivery if the handler is set to be a ring-3 one by a 32-bit guest, and the stack is misaligned.  This is CVE-2015-5307 / XSA-156.   2) #DB may be raised during exception delivery when a breakpoint got placed on a data structure involved in delivering the exception. This can result in an endless loop when a 64-bit guest uses a non-zero IST for the vector 1 IDT entry, but even without use of IST the time it takes until a contributory fault would get raised (results depending on the handler) may be quite long.  This is CVE-2015-8104 / XSA-156. ",
        "func_before": "void svm_vmexit_handler(struct cpu_user_regs *regs)\n{\n    uint64_t exit_reason;\n    struct vcpu *v = current;\n    struct vmcb_struct *vmcb = v->arch.hvm_svm.vmcb;\n    eventinj_t eventinj;\n    int inst_len, rc;\n    vintr_t intr;\n    bool_t vcpu_guestmode = 0;\n\n    hvm_invalidate_regs_fields(regs);\n\n    if ( paging_mode_hap(v->domain) )\n        v->arch.hvm_vcpu.guest_cr[3] = v->arch.hvm_vcpu.hw_cr[3] =\n            vmcb_get_cr3(vmcb);\n\n    if ( nestedhvm_enabled(v->domain) && nestedhvm_vcpu_in_guestmode(v) )\n        vcpu_guestmode = 1;\n\n    /*\n     * Before doing anything else, we need to sync up the VLAPIC's TPR with\n     * SVM's vTPR. It's OK if the guest doesn't touch CR8 (e.g. 32-bit Windows)\n     * because we update the vTPR on MMIO writes to the TPR.\n     * NB. We need to preserve the low bits of the TPR to make checked builds\n     * of Windows work, even though they don't actually do anything.\n     */\n    if ( !vcpu_guestmode ) {\n        intr = vmcb_get_vintr(vmcb);\n        vlapic_set_reg(vcpu_vlapic(v), APIC_TASKPRI,\n                   ((intr.fields.tpr & 0x0F) << 4) |\n                   (vlapic_get_reg(vcpu_vlapic(v), APIC_TASKPRI) & 0x0F));\n    }\n\n    exit_reason = vmcb->exitcode;\n\n    if ( hvm_long_mode_enabled(v) )\n        HVMTRACE_ND(VMEXIT64, vcpu_guestmode ? TRC_HVM_NESTEDFLAG : 0,\n                    1/*cycles*/, 3, exit_reason,\n                    (uint32_t)regs->eip, (uint32_t)((uint64_t)regs->eip >> 32),\n                    0, 0, 0);\n    else\n        HVMTRACE_ND(VMEXIT, vcpu_guestmode ? TRC_HVM_NESTEDFLAG : 0,\n                    1/*cycles*/, 2, exit_reason,\n                    (uint32_t)regs->eip,\n                    0, 0, 0, 0);\n\n    if ( vcpu_guestmode ) {\n        enum nestedhvm_vmexits nsret;\n        struct nestedvcpu *nv = &vcpu_nestedhvm(v);\n        struct vmcb_struct *ns_vmcb = nv->nv_vvmcx;\n        uint64_t exitinfo1, exitinfo2;\n\n        paging_update_nestedmode(v);\n\n        /* Write real exitinfo1 back into virtual vmcb.\n         * nestedsvm_check_intercepts() expects to have the correct\n         * exitinfo1 value there.\n         */\n        exitinfo1 = ns_vmcb->exitinfo1;\n        ns_vmcb->exitinfo1 = vmcb->exitinfo1;\n        nsret = nestedsvm_check_intercepts(v, regs, exit_reason);\n        switch (nsret) {\n        case NESTEDHVM_VMEXIT_CONTINUE:\n            BUG();\n            break;\n        case NESTEDHVM_VMEXIT_HOST:\n            break;\n        case NESTEDHVM_VMEXIT_INJECT:\n            /* Switch vcpu from l2 to l1 guest. We must perform\n             * the switch here to have svm_do_resume() working\n             * as intended.\n             */\n            exitinfo1 = vmcb->exitinfo1;\n            exitinfo2 = vmcb->exitinfo2;\n            nv->nv_vmswitch_in_progress = 1;\n            nsret = nestedsvm_vmexit_n2n1(v, regs);\n            nv->nv_vmswitch_in_progress = 0;\n            switch (nsret) {\n            case NESTEDHVM_VMEXIT_DONE:\n                /* defer VMEXIT injection */\n                nestedsvm_vmexit_defer(v, exit_reason, exitinfo1, exitinfo2);\n                goto out;\n            case NESTEDHVM_VMEXIT_FATALERROR:\n                gdprintk(XENLOG_ERR, \"unexpected nestedsvm_vmexit() error\\n\");\n                domain_crash(v->domain);\n                goto out;\n            default:\n                BUG();\n            case NESTEDHVM_VMEXIT_ERROR:\n                break;\n            }\n            /* fallthrough */\n        case NESTEDHVM_VMEXIT_ERROR:\n            gdprintk(XENLOG_ERR,\n                \"nestedsvm_check_intercepts() returned NESTEDHVM_VMEXIT_ERROR\\n\");\n            goto out;\n        case NESTEDHVM_VMEXIT_FATALERROR:\n            gdprintk(XENLOG_ERR,\n                \"unexpected nestedsvm_check_intercepts() error\\n\");\n            domain_crash(v->domain);\n            goto out;\n        default:\n            gdprintk(XENLOG_INFO, \"nestedsvm_check_intercepts() returned %i\\n\",\n                nsret);\n            domain_crash(v->domain);\n            goto out;\n        }\n    }\n\n    if ( unlikely(exit_reason == VMEXIT_INVALID) )\n    {\n        gdprintk(XENLOG_ERR, \"invalid VMCB state:\\n\");\n        svm_vmcb_dump(__func__, vmcb);\n        domain_crash(v->domain);\n        goto out;\n    }\n\n    perfc_incra(svmexits, exit_reason);\n\n    hvm_maybe_deassert_evtchn_irq();\n\n    vmcb->cleanbits.bytes = cpu_has_svm_cleanbits ? ~0u : 0u;\n\n    /* Event delivery caused this intercept? Queue for redelivery. */\n    eventinj = vmcb->exitintinfo;\n    if ( unlikely(eventinj.fields.v) &&\n         hvm_event_needs_reinjection(eventinj.fields.type,\n                                     eventinj.fields.vector) )\n        vmcb->eventinj = eventinj;\n\n    switch ( exit_reason )\n    {\n    case VMEXIT_INTR:\n        /* Asynchronous event, handled when we STGI'd after the VMEXIT. */\n        HVMTRACE_0D(INTR);\n        break;\n\n    case VMEXIT_NMI:\n        /* Asynchronous event, handled when we STGI'd after the VMEXIT. */\n        HVMTRACE_0D(NMI);\n        break;\n\n    case VMEXIT_SMI:\n        /* Asynchronous event, handled when we STGI'd after the VMEXIT. */\n        HVMTRACE_0D(SMI);\n        break;\n\n    case VMEXIT_EXCEPTION_DB:\n        if ( !v->domain->debugger_attached )\n            goto unexpected_exit_type;\n        domain_pause_for_debugger();\n        break;\n\n    case VMEXIT_EXCEPTION_BP:\n        if ( !v->domain->debugger_attached )\n            goto unexpected_exit_type;\n        /* AMD Vol2, 15.11: INT3, INTO, BOUND intercepts do not update RIP. */\n        if ( (inst_len = __get_instruction_length(v, INSTR_INT3)) == 0 )\n            break;\n        __update_guest_eip(regs, inst_len);\n        current->arch.gdbsx_vcpu_event = TRAP_int3;\n        domain_pause_for_debugger();\n        break;\n\n    case VMEXIT_EXCEPTION_NM:\n        svm_fpu_dirty_intercept();\n        break;  \n\n    case VMEXIT_EXCEPTION_PF: {\n        unsigned long va;\n        va = vmcb->exitinfo2;\n        regs->error_code = vmcb->exitinfo1;\n        HVM_DBG_LOG(DBG_LEVEL_VMMU,\n                    \"eax=%lx, ebx=%lx, ecx=%lx, edx=%lx, esi=%lx, edi=%lx\",\n                    (unsigned long)regs->eax, (unsigned long)regs->ebx,\n                    (unsigned long)regs->ecx, (unsigned long)regs->edx,\n                    (unsigned long)regs->esi, (unsigned long)regs->edi);\n\n        if ( cpu_has_svm_decode )\n            v->arch.hvm_svm.cached_insn_len = vmcb->guest_ins_len & 0xf;\n        rc = paging_fault(va, regs);\n        v->arch.hvm_svm.cached_insn_len = 0;\n\n        if ( rc )\n        {\n            if ( trace_will_trace_event(TRC_SHADOW) )\n                break;\n            if ( hvm_long_mode_enabled(v) )\n                HVMTRACE_LONG_2D(PF_XEN, regs->error_code, TRC_PAR_LONG(va));\n            else\n                HVMTRACE_2D(PF_XEN, regs->error_code, va);\n            break;\n        }\n\n        hvm_inject_page_fault(regs->error_code, va);\n        break;\n    }\n\n    case VMEXIT_EXCEPTION_UD:\n        svm_vmexit_ud_intercept(regs);\n        break;\n\n    /* Asynchronous event, handled when we STGI'd after the VMEXIT. */\n    case VMEXIT_EXCEPTION_MC:\n        HVMTRACE_0D(MCE);\n        svm_vmexit_mce_intercept(v, regs);\n        break;\n\n    case VMEXIT_VINTR: {\n        u32 general1_intercepts = vmcb_get_general1_intercepts(vmcb);\n        intr = vmcb_get_vintr(vmcb);\n\n        intr.fields.irq = 0;\n        general1_intercepts &= ~GENERAL1_INTERCEPT_VINTR;\n\n        vmcb_set_vintr(vmcb, intr);\n        vmcb_set_general1_intercepts(vmcb, general1_intercepts);\n        break;\n    }\n\n    case VMEXIT_INVD:\n    case VMEXIT_WBINVD:\n        svm_vmexit_do_invalidate_cache(regs);\n        break;\n\n    case VMEXIT_TASK_SWITCH: {\n        enum hvm_task_switch_reason reason;\n        int32_t errcode = -1;\n        if ( (vmcb->exitinfo2 >> 36) & 1 )\n            reason = TSW_iret;\n        else if ( (vmcb->exitinfo2 >> 38) & 1 )\n            reason = TSW_jmp;\n        else\n            reason = TSW_call_or_int;\n        if ( (vmcb->exitinfo2 >> 44) & 1 )\n            errcode = (uint32_t)vmcb->exitinfo2;\n\n        /*\n         * Some processors set the EXITINTINFO field when the task switch\n         * is caused by a task gate in the IDT. In this case we will be\n         * emulating the event injection, so we do not want the processor\n         * to re-inject the original event!\n         */\n        vmcb->eventinj.bytes = 0;\n\n        hvm_task_switch((uint16_t)vmcb->exitinfo1, reason, errcode);\n        break;\n    }\n\n    case VMEXIT_CPUID:\n        svm_vmexit_do_cpuid(regs);\n        break;\n\n    case VMEXIT_HLT:\n        svm_vmexit_do_hlt(vmcb, regs);\n        break;\n\n    case VMEXIT_IOIO:\n        if ( (vmcb->exitinfo1 & (1u<<2)) == 0 )\n        {\n            uint16_t port = (vmcb->exitinfo1 >> 16) & 0xFFFF;\n            int bytes = ((vmcb->exitinfo1 >> 4) & 0x07);\n            int dir = (vmcb->exitinfo1 & 1) ? IOREQ_READ : IOREQ_WRITE;\n            if ( handle_pio(port, bytes, dir) )\n                __update_guest_eip(regs, vmcb->exitinfo2 - vmcb->rip);\n        }\n        else if ( !handle_mmio() )\n            hvm_inject_hw_exception(TRAP_gp_fault, 0);\n        break;\n\n    case VMEXIT_CR0_READ ... VMEXIT_CR15_READ:\n    case VMEXIT_CR0_WRITE ... VMEXIT_CR15_WRITE:\n        if ( cpu_has_svm_decode && (vmcb->exitinfo1 & (1ULL << 63)) )\n            svm_vmexit_do_cr_access(vmcb, regs);\n        else if ( !handle_mmio() ) \n            hvm_inject_hw_exception(TRAP_gp_fault, 0);\n        break;\n\n    case VMEXIT_INVLPG:\n        if ( cpu_has_svm_decode )\n        {\n            svm_invlpg_intercept(vmcb->exitinfo1);\n            __update_guest_eip(regs, vmcb->nextrip - vmcb->rip);\n        }\n        else if ( !handle_mmio() )\n            hvm_inject_hw_exception(TRAP_gp_fault, 0);\n        break;\n\n    case VMEXIT_INVLPGA:\n        if ( (inst_len = __get_instruction_length(v, INSTR_INVLPGA)) == 0 )\n            break;\n        svm_invlpga_intercept(v, regs->eax, regs->ecx);\n        __update_guest_eip(regs, inst_len);\n        break;\n\n    case VMEXIT_VMMCALL:\n        if ( (inst_len = __get_instruction_length(v, INSTR_VMCALL)) == 0 )\n            break;\n        BUG_ON(vcpu_guestmode);\n        HVMTRACE_1D(VMMCALL, regs->eax);\n        rc = hvm_do_hypercall(regs);\n        if ( rc != HVM_HCALL_preempted )\n        {\n            __update_guest_eip(regs, inst_len);\n            if ( rc == HVM_HCALL_invalidate )\n                send_invalidate_req();\n        }\n        break;\n\n    case VMEXIT_DR0_READ ... VMEXIT_DR7_READ:\n    case VMEXIT_DR0_WRITE ... VMEXIT_DR7_WRITE:\n        svm_dr_access(v, regs);\n        break;\n\n    case VMEXIT_MSR:\n        svm_do_msr_access(regs);\n        break;\n\n    case VMEXIT_SHUTDOWN:\n        hvm_triple_fault();\n        break;\n\n    case VMEXIT_RDTSCP:\n        regs->ecx = hvm_msr_tsc_aux(v);\n        /* fall through */\n    case VMEXIT_RDTSC:\n        svm_vmexit_do_rdtsc(regs);\n        break;\n\n    case VMEXIT_MONITOR:\n    case VMEXIT_MWAIT:\n        hvm_inject_hw_exception(TRAP_invalid_op, HVM_DELIVER_NO_ERROR_CODE);\n        break;\n\n    case VMEXIT_VMRUN:\n        svm_vmexit_do_vmrun(regs, v, regs->eax);\n        break;\n    case VMEXIT_VMLOAD:\n        svm_vmexit_do_vmload(vmcb, regs, v, regs->eax);\n        break;\n    case VMEXIT_VMSAVE:\n        svm_vmexit_do_vmsave(vmcb, regs, v, regs->eax);\n        break;\n    case VMEXIT_STGI:\n        svm_vmexit_do_stgi(regs, v);\n        break;\n    case VMEXIT_CLGI:\n        svm_vmexit_do_clgi(regs, v);\n        break;\n    case VMEXIT_SKINIT:\n        hvm_inject_hw_exception(TRAP_invalid_op, HVM_DELIVER_NO_ERROR_CODE);\n        break;\n\n    case VMEXIT_XSETBV:\n        if ( (inst_len = __get_instruction_length(current, INSTR_XSETBV))==0 )\n            break;\n        if ( hvm_handle_xsetbv(regs->ecx,\n                               (regs->rdx << 32) | regs->_eax) == 0 )\n            __update_guest_eip(regs, inst_len);\n        break;\n\n    case VMEXIT_NPF:\n        perfc_incra(svmexits, VMEXIT_NPF_PERFC);\n        if ( cpu_has_svm_decode )\n            v->arch.hvm_svm.cached_insn_len = vmcb->guest_ins_len & 0xf;\n        rc = vmcb->exitinfo1 & PFEC_page_present\n             ? p2m_pt_handle_deferred_changes(vmcb->exitinfo2) : 0;\n        if ( rc >= 0 )\n            svm_do_nested_pgfault(v, regs, vmcb->exitinfo1, vmcb->exitinfo2);\n        else\n        {\n            printk(XENLOG_G_ERR\n                   \"%pv: Error %d handling NPF (gpa=%08lx ec=%04lx)\\n\",\n                   v, rc, vmcb->exitinfo2, vmcb->exitinfo1);\n            domain_crash(v->domain);\n        }\n        v->arch.hvm_svm.cached_insn_len = 0;\n        break;\n\n    case VMEXIT_IRET: {\n        u32 general1_intercepts = vmcb_get_general1_intercepts(vmcb);\n\n        /*\n         * IRET clears the NMI mask. However because we clear the mask\n         * /before/ executing IRET, we set the interrupt shadow to prevent\n         * a pending NMI from being injected immediately. This will work\n         * perfectly unless the IRET instruction faults: in that case we\n         * may inject an NMI before the NMI handler's IRET instruction is\n         * retired.\n         */\n        general1_intercepts &= ~GENERAL1_INTERCEPT_IRET;\n        vmcb->interrupt_shadow = 1;\n\n        vmcb_set_general1_intercepts(vmcb, general1_intercepts);\n        break;\n    }\n\n    case VMEXIT_PAUSE:\n        svm_vmexit_do_pause(regs);\n        break;\n\n    default:\n    unexpected_exit_type:\n        gdprintk(XENLOG_ERR, \"unexpected VMEXIT: exit reason = %#\"PRIx64\", \"\n                 \"exitinfo1 = %#\"PRIx64\", exitinfo2 = %#\"PRIx64\"\\n\",\n                 exit_reason, \n                 (u64)vmcb->exitinfo1, (u64)vmcb->exitinfo2);\n        svm_crash_or_fault(v);\n        break;\n    }\n\n  out:\n    if ( vcpu_guestmode )\n        /* Don't clobber TPR of the nested guest. */\n        return;\n\n    /* The exit may have updated the TPR: reflect this in the hardware vtpr */\n    intr = vmcb_get_vintr(vmcb);\n    intr.fields.tpr =\n        (vlapic_get_reg(vcpu_vlapic(v), APIC_TASKPRI) & 0xFF) >> 4;\n    vmcb_set_vintr(vmcb, intr);\n}",
        "func": "void svm_vmexit_handler(struct cpu_user_regs *regs)\n{\n    uint64_t exit_reason;\n    struct vcpu *v = current;\n    struct vmcb_struct *vmcb = v->arch.hvm_svm.vmcb;\n    eventinj_t eventinj;\n    int inst_len, rc;\n    vintr_t intr;\n    bool_t vcpu_guestmode = 0;\n\n    hvm_invalidate_regs_fields(regs);\n\n    if ( paging_mode_hap(v->domain) )\n        v->arch.hvm_vcpu.guest_cr[3] = v->arch.hvm_vcpu.hw_cr[3] =\n            vmcb_get_cr3(vmcb);\n\n    if ( nestedhvm_enabled(v->domain) && nestedhvm_vcpu_in_guestmode(v) )\n        vcpu_guestmode = 1;\n\n    /*\n     * Before doing anything else, we need to sync up the VLAPIC's TPR with\n     * SVM's vTPR. It's OK if the guest doesn't touch CR8 (e.g. 32-bit Windows)\n     * because we update the vTPR on MMIO writes to the TPR.\n     * NB. We need to preserve the low bits of the TPR to make checked builds\n     * of Windows work, even though they don't actually do anything.\n     */\n    if ( !vcpu_guestmode ) {\n        intr = vmcb_get_vintr(vmcb);\n        vlapic_set_reg(vcpu_vlapic(v), APIC_TASKPRI,\n                   ((intr.fields.tpr & 0x0F) << 4) |\n                   (vlapic_get_reg(vcpu_vlapic(v), APIC_TASKPRI) & 0x0F));\n    }\n\n    exit_reason = vmcb->exitcode;\n\n    if ( hvm_long_mode_enabled(v) )\n        HVMTRACE_ND(VMEXIT64, vcpu_guestmode ? TRC_HVM_NESTEDFLAG : 0,\n                    1/*cycles*/, 3, exit_reason,\n                    (uint32_t)regs->eip, (uint32_t)((uint64_t)regs->eip >> 32),\n                    0, 0, 0);\n    else\n        HVMTRACE_ND(VMEXIT, vcpu_guestmode ? TRC_HVM_NESTEDFLAG : 0,\n                    1/*cycles*/, 2, exit_reason,\n                    (uint32_t)regs->eip,\n                    0, 0, 0, 0);\n\n    if ( vcpu_guestmode ) {\n        enum nestedhvm_vmexits nsret;\n        struct nestedvcpu *nv = &vcpu_nestedhvm(v);\n        struct vmcb_struct *ns_vmcb = nv->nv_vvmcx;\n        uint64_t exitinfo1, exitinfo2;\n\n        paging_update_nestedmode(v);\n\n        /* Write real exitinfo1 back into virtual vmcb.\n         * nestedsvm_check_intercepts() expects to have the correct\n         * exitinfo1 value there.\n         */\n        exitinfo1 = ns_vmcb->exitinfo1;\n        ns_vmcb->exitinfo1 = vmcb->exitinfo1;\n        nsret = nestedsvm_check_intercepts(v, regs, exit_reason);\n        switch (nsret) {\n        case NESTEDHVM_VMEXIT_CONTINUE:\n            BUG();\n            break;\n        case NESTEDHVM_VMEXIT_HOST:\n            break;\n        case NESTEDHVM_VMEXIT_INJECT:\n            /* Switch vcpu from l2 to l1 guest. We must perform\n             * the switch here to have svm_do_resume() working\n             * as intended.\n             */\n            exitinfo1 = vmcb->exitinfo1;\n            exitinfo2 = vmcb->exitinfo2;\n            nv->nv_vmswitch_in_progress = 1;\n            nsret = nestedsvm_vmexit_n2n1(v, regs);\n            nv->nv_vmswitch_in_progress = 0;\n            switch (nsret) {\n            case NESTEDHVM_VMEXIT_DONE:\n                /* defer VMEXIT injection */\n                nestedsvm_vmexit_defer(v, exit_reason, exitinfo1, exitinfo2);\n                goto out;\n            case NESTEDHVM_VMEXIT_FATALERROR:\n                gdprintk(XENLOG_ERR, \"unexpected nestedsvm_vmexit() error\\n\");\n                domain_crash(v->domain);\n                goto out;\n            default:\n                BUG();\n            case NESTEDHVM_VMEXIT_ERROR:\n                break;\n            }\n            /* fallthrough */\n        case NESTEDHVM_VMEXIT_ERROR:\n            gdprintk(XENLOG_ERR,\n                \"nestedsvm_check_intercepts() returned NESTEDHVM_VMEXIT_ERROR\\n\");\n            goto out;\n        case NESTEDHVM_VMEXIT_FATALERROR:\n            gdprintk(XENLOG_ERR,\n                \"unexpected nestedsvm_check_intercepts() error\\n\");\n            domain_crash(v->domain);\n            goto out;\n        default:\n            gdprintk(XENLOG_INFO, \"nestedsvm_check_intercepts() returned %i\\n\",\n                nsret);\n            domain_crash(v->domain);\n            goto out;\n        }\n    }\n\n    if ( unlikely(exit_reason == VMEXIT_INVALID) )\n    {\n        gdprintk(XENLOG_ERR, \"invalid VMCB state:\\n\");\n        svm_vmcb_dump(__func__, vmcb);\n        domain_crash(v->domain);\n        goto out;\n    }\n\n    perfc_incra(svmexits, exit_reason);\n\n    hvm_maybe_deassert_evtchn_irq();\n\n    vmcb->cleanbits.bytes = cpu_has_svm_cleanbits ? ~0u : 0u;\n\n    /* Event delivery caused this intercept? Queue for redelivery. */\n    eventinj = vmcb->exitintinfo;\n    if ( unlikely(eventinj.fields.v) &&\n         hvm_event_needs_reinjection(eventinj.fields.type,\n                                     eventinj.fields.vector) )\n        vmcb->eventinj = eventinj;\n\n    switch ( exit_reason )\n    {\n    case VMEXIT_INTR:\n        /* Asynchronous event, handled when we STGI'd after the VMEXIT. */\n        HVMTRACE_0D(INTR);\n        break;\n\n    case VMEXIT_NMI:\n        /* Asynchronous event, handled when we STGI'd after the VMEXIT. */\n        HVMTRACE_0D(NMI);\n        break;\n\n    case VMEXIT_SMI:\n        /* Asynchronous event, handled when we STGI'd after the VMEXIT. */\n        HVMTRACE_0D(SMI);\n        break;\n\n    case VMEXIT_EXCEPTION_DB:\n        if ( !v->domain->debugger_attached )\n            hvm_inject_hw_exception(TRAP_debug, HVM_DELIVER_NO_ERROR_CODE);\n        else\n            domain_pause_for_debugger();\n        break;\n\n    case VMEXIT_EXCEPTION_BP:\n        if ( !v->domain->debugger_attached )\n            goto unexpected_exit_type;\n        /* AMD Vol2, 15.11: INT3, INTO, BOUND intercepts do not update RIP. */\n        if ( (inst_len = __get_instruction_length(v, INSTR_INT3)) == 0 )\n            break;\n        __update_guest_eip(regs, inst_len);\n        current->arch.gdbsx_vcpu_event = TRAP_int3;\n        domain_pause_for_debugger();\n        break;\n\n    case VMEXIT_EXCEPTION_NM:\n        svm_fpu_dirty_intercept();\n        break;  \n\n    case VMEXIT_EXCEPTION_PF: {\n        unsigned long va;\n        va = vmcb->exitinfo2;\n        regs->error_code = vmcb->exitinfo1;\n        HVM_DBG_LOG(DBG_LEVEL_VMMU,\n                    \"eax=%lx, ebx=%lx, ecx=%lx, edx=%lx, esi=%lx, edi=%lx\",\n                    (unsigned long)regs->eax, (unsigned long)regs->ebx,\n                    (unsigned long)regs->ecx, (unsigned long)regs->edx,\n                    (unsigned long)regs->esi, (unsigned long)regs->edi);\n\n        if ( cpu_has_svm_decode )\n            v->arch.hvm_svm.cached_insn_len = vmcb->guest_ins_len & 0xf;\n        rc = paging_fault(va, regs);\n        v->arch.hvm_svm.cached_insn_len = 0;\n\n        if ( rc )\n        {\n            if ( trace_will_trace_event(TRC_SHADOW) )\n                break;\n            if ( hvm_long_mode_enabled(v) )\n                HVMTRACE_LONG_2D(PF_XEN, regs->error_code, TRC_PAR_LONG(va));\n            else\n                HVMTRACE_2D(PF_XEN, regs->error_code, va);\n            break;\n        }\n\n        hvm_inject_page_fault(regs->error_code, va);\n        break;\n    }\n\n    case VMEXIT_EXCEPTION_AC:\n        HVMTRACE_1D(TRAP, TRAP_alignment_check);\n        hvm_inject_hw_exception(TRAP_alignment_check, vmcb->exitinfo1);\n        break;\n\n    case VMEXIT_EXCEPTION_UD:\n        svm_vmexit_ud_intercept(regs);\n        break;\n\n    /* Asynchronous event, handled when we STGI'd after the VMEXIT. */\n    case VMEXIT_EXCEPTION_MC:\n        HVMTRACE_0D(MCE);\n        svm_vmexit_mce_intercept(v, regs);\n        break;\n\n    case VMEXIT_VINTR: {\n        u32 general1_intercepts = vmcb_get_general1_intercepts(vmcb);\n        intr = vmcb_get_vintr(vmcb);\n\n        intr.fields.irq = 0;\n        general1_intercepts &= ~GENERAL1_INTERCEPT_VINTR;\n\n        vmcb_set_vintr(vmcb, intr);\n        vmcb_set_general1_intercepts(vmcb, general1_intercepts);\n        break;\n    }\n\n    case VMEXIT_INVD:\n    case VMEXIT_WBINVD:\n        svm_vmexit_do_invalidate_cache(regs);\n        break;\n\n    case VMEXIT_TASK_SWITCH: {\n        enum hvm_task_switch_reason reason;\n        int32_t errcode = -1;\n        if ( (vmcb->exitinfo2 >> 36) & 1 )\n            reason = TSW_iret;\n        else if ( (vmcb->exitinfo2 >> 38) & 1 )\n            reason = TSW_jmp;\n        else\n            reason = TSW_call_or_int;\n        if ( (vmcb->exitinfo2 >> 44) & 1 )\n            errcode = (uint32_t)vmcb->exitinfo2;\n\n        /*\n         * Some processors set the EXITINTINFO field when the task switch\n         * is caused by a task gate in the IDT. In this case we will be\n         * emulating the event injection, so we do not want the processor\n         * to re-inject the original event!\n         */\n        vmcb->eventinj.bytes = 0;\n\n        hvm_task_switch((uint16_t)vmcb->exitinfo1, reason, errcode);\n        break;\n    }\n\n    case VMEXIT_CPUID:\n        svm_vmexit_do_cpuid(regs);\n        break;\n\n    case VMEXIT_HLT:\n        svm_vmexit_do_hlt(vmcb, regs);\n        break;\n\n    case VMEXIT_IOIO:\n        if ( (vmcb->exitinfo1 & (1u<<2)) == 0 )\n        {\n            uint16_t port = (vmcb->exitinfo1 >> 16) & 0xFFFF;\n            int bytes = ((vmcb->exitinfo1 >> 4) & 0x07);\n            int dir = (vmcb->exitinfo1 & 1) ? IOREQ_READ : IOREQ_WRITE;\n            if ( handle_pio(port, bytes, dir) )\n                __update_guest_eip(regs, vmcb->exitinfo2 - vmcb->rip);\n        }\n        else if ( !handle_mmio() )\n            hvm_inject_hw_exception(TRAP_gp_fault, 0);\n        break;\n\n    case VMEXIT_CR0_READ ... VMEXIT_CR15_READ:\n    case VMEXIT_CR0_WRITE ... VMEXIT_CR15_WRITE:\n        if ( cpu_has_svm_decode && (vmcb->exitinfo1 & (1ULL << 63)) )\n            svm_vmexit_do_cr_access(vmcb, regs);\n        else if ( !handle_mmio() ) \n            hvm_inject_hw_exception(TRAP_gp_fault, 0);\n        break;\n\n    case VMEXIT_INVLPG:\n        if ( cpu_has_svm_decode )\n        {\n            svm_invlpg_intercept(vmcb->exitinfo1);\n            __update_guest_eip(regs, vmcb->nextrip - vmcb->rip);\n        }\n        else if ( !handle_mmio() )\n            hvm_inject_hw_exception(TRAP_gp_fault, 0);\n        break;\n\n    case VMEXIT_INVLPGA:\n        if ( (inst_len = __get_instruction_length(v, INSTR_INVLPGA)) == 0 )\n            break;\n        svm_invlpga_intercept(v, regs->eax, regs->ecx);\n        __update_guest_eip(regs, inst_len);\n        break;\n\n    case VMEXIT_VMMCALL:\n        if ( (inst_len = __get_instruction_length(v, INSTR_VMCALL)) == 0 )\n            break;\n        BUG_ON(vcpu_guestmode);\n        HVMTRACE_1D(VMMCALL, regs->eax);\n        rc = hvm_do_hypercall(regs);\n        if ( rc != HVM_HCALL_preempted )\n        {\n            __update_guest_eip(regs, inst_len);\n            if ( rc == HVM_HCALL_invalidate )\n                send_invalidate_req();\n        }\n        break;\n\n    case VMEXIT_DR0_READ ... VMEXIT_DR7_READ:\n    case VMEXIT_DR0_WRITE ... VMEXIT_DR7_WRITE:\n        svm_dr_access(v, regs);\n        break;\n\n    case VMEXIT_MSR:\n        svm_do_msr_access(regs);\n        break;\n\n    case VMEXIT_SHUTDOWN:\n        hvm_triple_fault();\n        break;\n\n    case VMEXIT_RDTSCP:\n        regs->ecx = hvm_msr_tsc_aux(v);\n        /* fall through */\n    case VMEXIT_RDTSC:\n        svm_vmexit_do_rdtsc(regs);\n        break;\n\n    case VMEXIT_MONITOR:\n    case VMEXIT_MWAIT:\n        hvm_inject_hw_exception(TRAP_invalid_op, HVM_DELIVER_NO_ERROR_CODE);\n        break;\n\n    case VMEXIT_VMRUN:\n        svm_vmexit_do_vmrun(regs, v, regs->eax);\n        break;\n    case VMEXIT_VMLOAD:\n        svm_vmexit_do_vmload(vmcb, regs, v, regs->eax);\n        break;\n    case VMEXIT_VMSAVE:\n        svm_vmexit_do_vmsave(vmcb, regs, v, regs->eax);\n        break;\n    case VMEXIT_STGI:\n        svm_vmexit_do_stgi(regs, v);\n        break;\n    case VMEXIT_CLGI:\n        svm_vmexit_do_clgi(regs, v);\n        break;\n    case VMEXIT_SKINIT:\n        hvm_inject_hw_exception(TRAP_invalid_op, HVM_DELIVER_NO_ERROR_CODE);\n        break;\n\n    case VMEXIT_XSETBV:\n        if ( (inst_len = __get_instruction_length(current, INSTR_XSETBV))==0 )\n            break;\n        if ( hvm_handle_xsetbv(regs->ecx,\n                               (regs->rdx << 32) | regs->_eax) == 0 )\n            __update_guest_eip(regs, inst_len);\n        break;\n\n    case VMEXIT_NPF:\n        perfc_incra(svmexits, VMEXIT_NPF_PERFC);\n        if ( cpu_has_svm_decode )\n            v->arch.hvm_svm.cached_insn_len = vmcb->guest_ins_len & 0xf;\n        rc = vmcb->exitinfo1 & PFEC_page_present\n             ? p2m_pt_handle_deferred_changes(vmcb->exitinfo2) : 0;\n        if ( rc >= 0 )\n            svm_do_nested_pgfault(v, regs, vmcb->exitinfo1, vmcb->exitinfo2);\n        else\n        {\n            printk(XENLOG_G_ERR\n                   \"%pv: Error %d handling NPF (gpa=%08lx ec=%04lx)\\n\",\n                   v, rc, vmcb->exitinfo2, vmcb->exitinfo1);\n            domain_crash(v->domain);\n        }\n        v->arch.hvm_svm.cached_insn_len = 0;\n        break;\n\n    case VMEXIT_IRET: {\n        u32 general1_intercepts = vmcb_get_general1_intercepts(vmcb);\n\n        /*\n         * IRET clears the NMI mask. However because we clear the mask\n         * /before/ executing IRET, we set the interrupt shadow to prevent\n         * a pending NMI from being injected immediately. This will work\n         * perfectly unless the IRET instruction faults: in that case we\n         * may inject an NMI before the NMI handler's IRET instruction is\n         * retired.\n         */\n        general1_intercepts &= ~GENERAL1_INTERCEPT_IRET;\n        vmcb->interrupt_shadow = 1;\n\n        vmcb_set_general1_intercepts(vmcb, general1_intercepts);\n        break;\n    }\n\n    case VMEXIT_PAUSE:\n        svm_vmexit_do_pause(regs);\n        break;\n\n    default:\n    unexpected_exit_type:\n        gdprintk(XENLOG_ERR, \"unexpected VMEXIT: exit reason = %#\"PRIx64\", \"\n                 \"exitinfo1 = %#\"PRIx64\", exitinfo2 = %#\"PRIx64\"\\n\",\n                 exit_reason, \n                 (u64)vmcb->exitinfo1, (u64)vmcb->exitinfo2);\n        svm_crash_or_fault(v);\n        break;\n    }\n\n  out:\n    if ( vcpu_guestmode )\n        /* Don't clobber TPR of the nested guest. */\n        return;\n\n    /* The exit may have updated the TPR: reflect this in the hardware vtpr */\n    intr = vmcb_get_vintr(vmcb);\n    intr.fields.tpr =\n        (vlapic_get_reg(vcpu_vlapic(v), APIC_TASKPRI) & 0xFF) >> 4;\n    vmcb_set_vintr(vmcb, intr);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -147,8 +147,9 @@\n \n     case VMEXIT_EXCEPTION_DB:\n         if ( !v->domain->debugger_attached )\n-            goto unexpected_exit_type;\n-        domain_pause_for_debugger();\n+            hvm_inject_hw_exception(TRAP_debug, HVM_DELIVER_NO_ERROR_CODE);\n+        else\n+            domain_pause_for_debugger();\n         break;\n \n     case VMEXIT_EXCEPTION_BP:\n@@ -195,6 +196,11 @@\n         hvm_inject_page_fault(regs->error_code, va);\n         break;\n     }\n+\n+    case VMEXIT_EXCEPTION_AC:\n+        HVMTRACE_1D(TRAP, TRAP_alignment_check);\n+        hvm_inject_hw_exception(TRAP_alignment_check, vmcb->exitinfo1);\n+        break;\n \n     case VMEXIT_EXCEPTION_UD:\n         svm_vmexit_ud_intercept(regs);",
        "diff_line_info": {
            "deleted_lines": [
                "            goto unexpected_exit_type;",
                "        domain_pause_for_debugger();"
            ],
            "added_lines": [
                "            hvm_inject_hw_exception(TRAP_debug, HVM_DELIVER_NO_ERROR_CODE);",
                "        else",
                "            domain_pause_for_debugger();",
                "",
                "    case VMEXIT_EXCEPTION_AC:",
                "        HVMTRACE_1D(TRAP, TRAP_alignment_check);",
                "        hvm_inject_hw_exception(TRAP_alignment_check, vmcb->exitinfo1);",
                "        break;"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-5307",
        "func_name": "xen-project/xen/vmx_vmexit_handler",
        "description": "The KVM subsystem in the Linux kernel through 4.2.6, and Xen 4.3.x through 4.6.x, allows guest OS users to cause a denial of service (host OS panic or hang) by triggering many #AC (aka Alignment Check) exceptions, related to svm.c and vmx.c.",
        "git_url": "https://github.com/xen-project/xen/commit/bd2239d9fa975a1ee5bcd27c218ae042cd0a57bc",
        "commit_title": "x86/HVM: always intercept #AC and #DB",
        "commit_text": " Both being benign exceptions, and both being possible to get triggered by exception delivery, this is required to prevent a guest from locking up a CPU (resulting from no other VM exits occurring once getting into such a loop).  The specific scenarios:  1) #AC may be raised during exception delivery if the handler is set to be a ring-3 one by a 32-bit guest, and the stack is misaligned.  This is CVE-2015-5307 / XSA-156.   2) #DB may be raised during exception delivery when a breakpoint got placed on a data structure involved in delivering the exception. This can result in an endless loop when a 64-bit guest uses a non-zero IST for the vector 1 IDT entry, but even without use of IST the time it takes until a contributory fault would get raised (results depending on the handler) may be quite long.  This is CVE-2015-8104 / XSA-156. ",
        "func_before": "void vmx_vmexit_handler(struct cpu_user_regs *regs)\n{\n    unsigned long exit_qualification, exit_reason, idtv_info, intr_info = 0;\n    unsigned int vector = 0;\n    struct vcpu *v = current;\n\n    __vmread(GUEST_RIP,    &regs->rip);\n    __vmread(GUEST_RSP,    &regs->rsp);\n    __vmread(GUEST_RFLAGS, &regs->rflags);\n\n    hvm_invalidate_regs_fields(regs);\n\n    if ( paging_mode_hap(v->domain) )\n    {\n        __vmread(GUEST_CR3, &v->arch.hvm_vcpu.hw_cr[3]);\n        if ( vmx_unrestricted_guest(v) || hvm_paging_enabled(v) )\n            v->arch.hvm_vcpu.guest_cr[3] = v->arch.hvm_vcpu.hw_cr[3];\n    }\n\n    __vmread(VM_EXIT_REASON, &exit_reason);\n\n    if ( hvm_long_mode_enabled(v) )\n        HVMTRACE_ND(VMEXIT64, 0, 1/*cycles*/, 3, exit_reason,\n                    (uint32_t)regs->eip, (uint32_t)((uint64_t)regs->eip >> 32),\n                    0, 0, 0);\n    else\n        HVMTRACE_ND(VMEXIT, 0, 1/*cycles*/, 2, exit_reason,\n                    (uint32_t)regs->eip, \n                    0, 0, 0, 0);\n\n    perfc_incra(vmexits, exit_reason);\n\n    /* Handle the interrupt we missed before allowing any more in. */\n    switch ( (uint16_t)exit_reason )\n    {\n    case EXIT_REASON_EXTERNAL_INTERRUPT:\n        vmx_do_extint(regs);\n        break;\n    case EXIT_REASON_EXCEPTION_NMI:\n        __vmread(VM_EXIT_INTR_INFO, &intr_info);\n        BUG_ON(!(intr_info & INTR_INFO_VALID_MASK));\n        vector = intr_info & INTR_INFO_VECTOR_MASK;\n        if ( vector == TRAP_machine_check )\n            do_machine_check(regs);\n        if ( (vector == TRAP_nmi) &&\n             ((intr_info & INTR_INFO_INTR_TYPE_MASK) ==\n              MASK_INSR(X86_EVENTTYPE_NMI, INTR_INFO_INTR_TYPE_MASK)) )\n        {\n            exception_table[TRAP_nmi](regs);\n            enable_nmis();\n        }\n        break;\n    case EXIT_REASON_MCE_DURING_VMENTRY:\n        do_machine_check(regs);\n        break;\n    }\n\n    /* Now enable interrupts so it's safe to take locks. */\n    local_irq_enable();\n\n    /*\n     * If the guest has the ability to switch EPTP without an exit,\n     * figure out whether it has done so and update the altp2m data.\n     */\n    if ( altp2m_active(v->domain) &&\n        (v->arch.hvm_vmx.secondary_exec_control &\n        SECONDARY_EXEC_ENABLE_VM_FUNCTIONS) )\n    {\n        unsigned long idx;\n\n        if ( v->arch.hvm_vmx.secondary_exec_control &\n            SECONDARY_EXEC_ENABLE_VIRT_EXCEPTIONS )\n            __vmread(EPTP_INDEX, &idx);\n        else\n        {\n            unsigned long eptp;\n\n            __vmread(EPT_POINTER, &eptp);\n\n            if ( (idx = p2m_find_altp2m_by_eptp(v->domain, eptp)) ==\n                 INVALID_ALTP2M )\n            {\n                gdprintk(XENLOG_ERR, \"EPTP not found in alternate p2m list\\n\");\n                domain_crash(v->domain);\n            }\n        }\n\n        if ( idx != vcpu_altp2m(v).p2midx )\n        {\n            BUG_ON(idx >= MAX_ALTP2M);\n            atomic_dec(&p2m_get_altp2m(v)->active_vcpus);\n            vcpu_altp2m(v).p2midx = idx;\n            atomic_inc(&p2m_get_altp2m(v)->active_vcpus);\n        }\n    }\n\n    /* XXX: This looks ugly, but we need a mechanism to ensure\n     * any pending vmresume has really happened\n     */\n    vcpu_nestedhvm(v).nv_vmswitch_in_progress = 0;\n    if ( nestedhvm_vcpu_in_guestmode(v) )\n    {\n        paging_update_nestedmode(v);\n        if ( nvmx_n2_vmexit_handler(regs, exit_reason) )\n            goto out;\n    }\n\n    if ( unlikely(exit_reason & VMX_EXIT_REASONS_FAILED_VMENTRY) )\n        return vmx_failed_vmentry(exit_reason, regs);\n\n    if ( v->arch.hvm_vmx.vmx_realmode )\n    {\n        /* Put RFLAGS back the way the guest wants it */\n        regs->eflags &= ~(X86_EFLAGS_VM | X86_EFLAGS_IOPL);\n        regs->eflags |= (v->arch.hvm_vmx.vm86_saved_eflags & X86_EFLAGS_IOPL);\n\n        /* Unless this exit was for an interrupt, we've hit something\n         * vm86 can't handle.  Try again, using the emulator. */\n        switch ( exit_reason )\n        {\n        case EXIT_REASON_EXCEPTION_NMI:\n            if ( vector != TRAP_page_fault\n                 && vector != TRAP_nmi \n                 && vector != TRAP_machine_check ) \n            {\n                perfc_incr(realmode_exits);\n                v->arch.hvm_vmx.vmx_emulate = 1;\n                HVMTRACE_0D(REALMODE_EMULATE);\n                return;\n            }\n        case EXIT_REASON_EXTERNAL_INTERRUPT:\n        case EXIT_REASON_INIT:\n        case EXIT_REASON_SIPI:\n        case EXIT_REASON_PENDING_VIRT_INTR:\n        case EXIT_REASON_PENDING_VIRT_NMI:\n        case EXIT_REASON_MCE_DURING_VMENTRY:\n        case EXIT_REASON_GETSEC:\n        case EXIT_REASON_ACCESS_GDTR_OR_IDTR:\n        case EXIT_REASON_ACCESS_LDTR_OR_TR:\n        case EXIT_REASON_VMX_PREEMPTION_TIMER_EXPIRED:\n        case EXIT_REASON_INVEPT:\n        case EXIT_REASON_INVVPID:\n            break;\n\n        default:\n            v->arch.hvm_vmx.vmx_emulate = 1;\n            perfc_incr(realmode_exits);\n            HVMTRACE_0D(REALMODE_EMULATE);\n            return;\n        }\n    }\n\n    hvm_maybe_deassert_evtchn_irq();\n\n    __vmread(IDT_VECTORING_INFO, &idtv_info);\n    if ( exit_reason != EXIT_REASON_TASK_SWITCH )\n        vmx_idtv_reinject(idtv_info);\n\n    switch ( exit_reason )\n    {\n        unsigned long ecode;\n\n    case EXIT_REASON_EXCEPTION_NMI:\n    {\n        /*\n         * We don't set the software-interrupt exiting (INT n).\n         * (1) We can get an exception (e.g. #PG) in the guest, or\n         * (2) NMI\n         */\n\n        /*\n         * Re-set the NMI shadow if vmexit caused by a guest IRET fault (see 3B\n         * 25.7.1.2, \"Resuming Guest Software after Handling an Exception\").\n         * (NB. If we emulate this IRET for any reason, we should re-clear!)\n         */\n        if ( unlikely(intr_info & INTR_INFO_NMI_UNBLOCKED_BY_IRET) &&\n             !(idtv_info & INTR_INFO_VALID_MASK) &&\n             (vector != TRAP_double_fault) )\n        {\n            unsigned long guest_info;\n\n            __vmread(GUEST_INTERRUPTIBILITY_INFO, &guest_info);\n            __vmwrite(GUEST_INTERRUPTIBILITY_INFO,\n                      guest_info | VMX_INTR_SHADOW_NMI);\n        }\n\n        perfc_incra(cause_vector, vector);\n\n        switch ( vector )\n        {\n        case TRAP_debug:\n            /*\n             * Updates DR6 where debugger can peek (See 3B 23.2.1,\n             * Table 23-1, \"Exit Qualification for Debug Exceptions\").\n             */\n            __vmread(EXIT_QUALIFICATION, &exit_qualification);\n            HVMTRACE_1D(TRAP_DEBUG, exit_qualification);\n            write_debugreg(6, exit_qualification | DR_STATUS_RESERVED_ONE);\n            if ( !v->domain->debugger_attached || cpu_has_monitor_trap_flag )\n                goto exit_and_crash;\n            domain_pause_for_debugger();\n            break;\n        case TRAP_int3: \n        {\n            HVMTRACE_1D(TRAP, vector);\n            if ( v->domain->debugger_attached )\n            {\n                update_guest_eip(); /* Safe: INT3 */            \n                v->arch.gdbsx_vcpu_event = TRAP_int3;\n                domain_pause_for_debugger();\n                break;\n            }\n            else {\n                int handled = hvm_event_int3(regs->eip);\n                \n                if ( handled < 0 ) \n                {\n                    struct hvm_trap trap = {\n                        .vector = TRAP_int3,\n                        .type = X86_EVENTTYPE_SW_EXCEPTION,\n                        .error_code = HVM_DELIVER_NO_ERROR_CODE,\n                    };\n                    unsigned long insn_len;\n\n                    __vmread(VM_EXIT_INSTRUCTION_LEN, &insn_len);\n                    trap.insn_len = insn_len;\n                    hvm_inject_trap(&trap);\n                    break;\n                }\n                else if ( handled )\n                    break;\n            }\n\n            goto exit_and_crash;\n        }\n        case TRAP_no_device:\n            HVMTRACE_1D(TRAP, vector);\n            vmx_fpu_dirty_intercept();\n            break;\n        case TRAP_page_fault:\n            __vmread(EXIT_QUALIFICATION, &exit_qualification);\n            __vmread(VM_EXIT_INTR_ERROR_CODE, &ecode);\n            regs->error_code = ecode;\n\n            HVM_DBG_LOG(DBG_LEVEL_VMMU,\n                        \"eax=%lx, ebx=%lx, ecx=%lx, edx=%lx, esi=%lx, edi=%lx\",\n                        (unsigned long)regs->eax, (unsigned long)regs->ebx,\n                        (unsigned long)regs->ecx, (unsigned long)regs->edx,\n                        (unsigned long)regs->esi, (unsigned long)regs->edi);\n\n            if ( paging_fault(exit_qualification, regs) )\n            {\n                if ( trace_will_trace_event(TRC_SHADOW) )\n                    break;\n                if ( hvm_long_mode_enabled(v) )\n                    HVMTRACE_LONG_2D(PF_XEN, regs->error_code,\n                                     TRC_PAR_LONG(exit_qualification) );\n                else\n                    HVMTRACE_2D(PF_XEN,\n                                regs->error_code, exit_qualification );\n                break;\n            }\n\n            hvm_inject_page_fault(regs->error_code, exit_qualification);\n            break;\n        case TRAP_nmi:\n            if ( MASK_EXTR(intr_info, INTR_INFO_INTR_TYPE_MASK) !=\n                 X86_EVENTTYPE_NMI )\n                goto exit_and_crash;\n            HVMTRACE_0D(NMI);\n            /* Already handled above. */\n            break;\n        case TRAP_machine_check:\n            HVMTRACE_0D(MCE);\n            /* Already handled above. */\n            break;\n        case TRAP_invalid_op:\n            HVMTRACE_1D(TRAP, vector);\n            vmx_vmexit_ud_intercept(regs);\n            break;\n        default:\n            HVMTRACE_1D(TRAP, vector);\n            goto exit_and_crash;\n        }\n        break;\n    }\n    case EXIT_REASON_EXTERNAL_INTERRUPT:\n        /* Already handled above. */\n        break;\n    case EXIT_REASON_TRIPLE_FAULT:\n        hvm_triple_fault();\n        break;\n    case EXIT_REASON_PENDING_VIRT_INTR:\n        /* Disable the interrupt window. */\n        v->arch.hvm_vmx.exec_control &= ~CPU_BASED_VIRTUAL_INTR_PENDING;\n        vmx_update_cpu_exec_control(v);\n        break;\n    case EXIT_REASON_PENDING_VIRT_NMI:\n        /* Disable the NMI window. */\n        v->arch.hvm_vmx.exec_control &= ~CPU_BASED_VIRTUAL_NMI_PENDING;\n        vmx_update_cpu_exec_control(v);\n        break;\n    case EXIT_REASON_TASK_SWITCH: {\n        static const enum hvm_task_switch_reason reasons[] = {\n            TSW_call_or_int, TSW_iret, TSW_jmp, TSW_call_or_int\n        };\n        unsigned int inst_len, source;\n\n        __vmread(EXIT_QUALIFICATION, &exit_qualification);\n        source = (exit_qualification >> 30) & 3;\n        /* Vectored event should fill in interrupt information. */\n        WARN_ON((source == 3) && !(idtv_info & INTR_INFO_VALID_MASK));\n        /*\n         * In the following cases there is an instruction to skip over:\n         *  - TSW is due to a CALL, IRET or JMP instruction.\n         *  - TSW is a vectored event due to a SW exception or SW interrupt.\n         */\n        inst_len = ((source != 3) ||        /* CALL, IRET, or JMP? */\n                    (MASK_EXTR(idtv_info, INTR_INFO_INTR_TYPE_MASK)\n                     > 3)) /* IntrType > 3? */\n            ? get_instruction_length() /* Safe: SDM 3B 23.2.4 */ : 0;\n        if ( (source == 3) && (idtv_info & INTR_INFO_DELIVER_CODE_MASK) )\n            __vmread(IDT_VECTORING_ERROR_CODE, &ecode);\n        else\n             ecode = -1;\n        regs->eip += inst_len;\n        hvm_task_switch((uint16_t)exit_qualification, reasons[source], ecode);\n        break;\n    }\n    case EXIT_REASON_CPUID:\n        is_pvh_vcpu(v) ? pv_cpuid(regs) : vmx_do_cpuid(regs);\n        update_guest_eip(); /* Safe: CPUID */\n        break;\n    case EXIT_REASON_HLT:\n        update_guest_eip(); /* Safe: HLT */\n        hvm_hlt(regs->eflags);\n        break;\n    case EXIT_REASON_INVLPG:\n        update_guest_eip(); /* Safe: INVLPG */\n        __vmread(EXIT_QUALIFICATION, &exit_qualification);\n        vmx_invlpg_intercept(exit_qualification);\n        break;\n    case EXIT_REASON_RDTSCP:\n        regs->ecx = hvm_msr_tsc_aux(v);\n        /* fall through */\n    case EXIT_REASON_RDTSC:\n        update_guest_eip(); /* Safe: RDTSC, RDTSCP */\n        hvm_rdtsc_intercept(regs);\n        break;\n    case EXIT_REASON_VMCALL:\n    {\n        int rc;\n        HVMTRACE_1D(VMMCALL, regs->eax);\n        rc = hvm_do_hypercall(regs);\n        if ( rc != HVM_HCALL_preempted )\n        {\n            update_guest_eip(); /* Safe: VMCALL */\n            if ( rc == HVM_HCALL_invalidate )\n                send_invalidate_req();\n        }\n        break;\n    }\n    case EXIT_REASON_CR_ACCESS:\n    {\n        __vmread(EXIT_QUALIFICATION, &exit_qualification);\n        if ( vmx_cr_access(exit_qualification) == X86EMUL_OKAY )\n            update_guest_eip(); /* Safe: MOV Cn, LMSW, CLTS */\n        break;\n    }\n    case EXIT_REASON_DR_ACCESS:\n        __vmread(EXIT_QUALIFICATION, &exit_qualification);\n        vmx_dr_access(exit_qualification, regs);\n        break;\n    case EXIT_REASON_MSR_READ:\n    {\n        uint64_t msr_content;\n        if ( hvm_msr_read_intercept(regs->ecx, &msr_content) == X86EMUL_OKAY )\n        {\n            regs->eax = (uint32_t)msr_content;\n            regs->edx = (uint32_t)(msr_content >> 32);\n            update_guest_eip(); /* Safe: RDMSR */\n        }\n        break;\n    }\n    case EXIT_REASON_MSR_WRITE:\n    {\n        uint64_t msr_content;\n        msr_content = ((uint64_t)regs->edx << 32) | (uint32_t)regs->eax;\n        if ( hvm_msr_write_intercept(regs->ecx, msr_content, 1) == X86EMUL_OKAY )\n            update_guest_eip(); /* Safe: WRMSR */\n        break;\n    }\n\n    case EXIT_REASON_VMXOFF:\n        if ( nvmx_handle_vmxoff(regs) == X86EMUL_OKAY )\n            update_guest_eip();\n        break;\n\n    case EXIT_REASON_VMXON:\n        if ( nvmx_handle_vmxon(regs) == X86EMUL_OKAY )\n            update_guest_eip();\n        break;\n\n    case EXIT_REASON_VMCLEAR:\n        if ( nvmx_handle_vmclear(regs) == X86EMUL_OKAY )\n            update_guest_eip();\n        break;\n \n    case EXIT_REASON_VMPTRLD:\n        if ( nvmx_handle_vmptrld(regs) == X86EMUL_OKAY )\n            update_guest_eip();\n        break;\n\n    case EXIT_REASON_VMPTRST:\n        if ( nvmx_handle_vmptrst(regs) == X86EMUL_OKAY )\n            update_guest_eip();\n        break;\n\n    case EXIT_REASON_VMREAD:\n        if ( nvmx_handle_vmread(regs) == X86EMUL_OKAY )\n            update_guest_eip();\n        break;\n \n    case EXIT_REASON_VMWRITE:\n        if ( nvmx_handle_vmwrite(regs) == X86EMUL_OKAY )\n            update_guest_eip();\n        break;\n\n    case EXIT_REASON_VMLAUNCH:\n        if ( nvmx_handle_vmlaunch(regs) == X86EMUL_OKAY )\n            update_guest_eip();\n        break;\n\n    case EXIT_REASON_VMRESUME:\n        if ( nvmx_handle_vmresume(regs) == X86EMUL_OKAY )\n            update_guest_eip();\n        break;\n\n    case EXIT_REASON_INVEPT:\n        if ( nvmx_handle_invept(regs) == X86EMUL_OKAY )\n            update_guest_eip();\n        break;\n\n    case EXIT_REASON_INVVPID:\n        if ( nvmx_handle_invvpid(regs) == X86EMUL_OKAY )\n            update_guest_eip();\n        break;\n\n    case EXIT_REASON_VMFUNC:\n        if ( vmx_vmfunc_intercept(regs) != X86EMUL_OKAY )\n            hvm_inject_hw_exception(TRAP_invalid_op, HVM_DELIVER_NO_ERROR_CODE);\n        else\n            update_guest_eip();\n        break;\n\n    case EXIT_REASON_MWAIT_INSTRUCTION:\n    case EXIT_REASON_MONITOR_INSTRUCTION:\n    case EXIT_REASON_GETSEC:\n        /*\n         * We should never exit on GETSEC because CR4.SMXE is always 0 when\n         * running in guest context, and the CPU checks that before getting\n         * as far as vmexit.\n         */\n        WARN_ON(exit_reason == EXIT_REASON_GETSEC);\n        hvm_inject_hw_exception(TRAP_invalid_op, HVM_DELIVER_NO_ERROR_CODE);\n        break;\n\n    case EXIT_REASON_TPR_BELOW_THRESHOLD:\n        break;\n\n    case EXIT_REASON_APIC_ACCESS:\n        if ( !vmx_handle_eoi_write() && !handle_mmio() )\n            hvm_inject_hw_exception(TRAP_gp_fault, 0);\n        break;\n\n    case EXIT_REASON_EOI_INDUCED:\n        __vmread(EXIT_QUALIFICATION, &exit_qualification);\n\n        ASSERT(cpu_has_vmx_virtual_intr_delivery);\n\n        vlapic_handle_EOI(vcpu_vlapic(v), exit_qualification);\n        break;\n\n    case EXIT_REASON_IO_INSTRUCTION:\n        __vmread(EXIT_QUALIFICATION, &exit_qualification);\n        if ( exit_qualification & 0x10 )\n        {\n            /* INS, OUTS */\n            if ( unlikely(is_pvh_vcpu(v)) /* PVH fixme */ ||\n                 !handle_mmio() )\n                hvm_inject_hw_exception(TRAP_gp_fault, 0);\n        }\n        else\n        {\n            /* IN, OUT */\n            uint16_t port = (exit_qualification >> 16) & 0xFFFF;\n            int bytes = (exit_qualification & 0x07) + 1;\n            int dir = (exit_qualification & 0x08) ? IOREQ_READ : IOREQ_WRITE;\n            if ( handle_pio(port, bytes, dir) )\n                update_guest_eip(); /* Safe: IN, OUT */\n        }\n        break;\n\n    case EXIT_REASON_INVD:\n    case EXIT_REASON_WBINVD:\n    {\n        update_guest_eip(); /* Safe: INVD, WBINVD */\n        vmx_wbinvd_intercept();\n        break;\n    }\n\n    case EXIT_REASON_EPT_VIOLATION:\n    {\n        paddr_t gpa;\n\n        __vmread(GUEST_PHYSICAL_ADDRESS, &gpa);\n        __vmread(EXIT_QUALIFICATION, &exit_qualification);\n        ept_handle_violation(exit_qualification, gpa);\n        break;\n    }\n\n    case EXIT_REASON_EPT_MISCONFIG:\n    {\n        paddr_t gpa;\n\n        __vmread(GUEST_PHYSICAL_ADDRESS, &gpa);\n        if ( !ept_handle_misconfig(gpa) )\n            goto exit_and_crash;\n        break;\n    }\n\n    case EXIT_REASON_MONITOR_TRAP_FLAG:\n        v->arch.hvm_vmx.exec_control &= ~CPU_BASED_MONITOR_TRAP_FLAG;\n        vmx_update_cpu_exec_control(v);\n        if ( v->arch.hvm_vcpu.single_step ) {\n          hvm_event_single_step(regs->eip);\n          if ( v->domain->debugger_attached )\n              domain_pause_for_debugger();\n        }\n\n        break;\n\n    case EXIT_REASON_PAUSE_INSTRUCTION:\n        perfc_incr(pauseloop_exits);\n        do_sched_op(SCHEDOP_yield, guest_handle_from_ptr(NULL, void));\n        break;\n\n    case EXIT_REASON_XSETBV:\n        if ( hvm_handle_xsetbv(regs->ecx,\n                               (regs->rdx << 32) | regs->_eax) == 0 )\n            update_guest_eip(); /* Safe: XSETBV */\n        break;\n\n    case EXIT_REASON_APIC_WRITE:\n        vmx_handle_apic_write();\n        break;\n\n    case EXIT_REASON_PML_FULL:\n        vmx_vcpu_flush_pml_buffer(v);\n        break;\n\n    case EXIT_REASON_ACCESS_GDTR_OR_IDTR:\n    case EXIT_REASON_ACCESS_LDTR_OR_TR:\n    case EXIT_REASON_VMX_PREEMPTION_TIMER_EXPIRED:\n    case EXIT_REASON_INVPCID:\n    /* fall through */\n    default:\n    exit_and_crash:\n        {\n            struct segment_register ss;\n\n            gdprintk(XENLOG_WARNING, \"Bad vmexit (reason %#lx)\\n\",\n                     exit_reason);\n\n            vmx_get_segment_register(v, x86_seg_ss, &ss);\n            if ( ss.attr.fields.dpl )\n                hvm_inject_hw_exception(TRAP_invalid_op,\n                                        HVM_DELIVER_NO_ERROR_CODE);\n            else\n                domain_crash(v->domain);\n        }\n        break;\n    }\n\nout:\n    if ( nestedhvm_vcpu_in_guestmode(v) )\n        nvmx_idtv_handling();\n}",
        "func": "void vmx_vmexit_handler(struct cpu_user_regs *regs)\n{\n    unsigned long exit_qualification, exit_reason, idtv_info, intr_info = 0;\n    unsigned int vector = 0;\n    struct vcpu *v = current;\n\n    __vmread(GUEST_RIP,    &regs->rip);\n    __vmread(GUEST_RSP,    &regs->rsp);\n    __vmread(GUEST_RFLAGS, &regs->rflags);\n\n    hvm_invalidate_regs_fields(regs);\n\n    if ( paging_mode_hap(v->domain) )\n    {\n        __vmread(GUEST_CR3, &v->arch.hvm_vcpu.hw_cr[3]);\n        if ( vmx_unrestricted_guest(v) || hvm_paging_enabled(v) )\n            v->arch.hvm_vcpu.guest_cr[3] = v->arch.hvm_vcpu.hw_cr[3];\n    }\n\n    __vmread(VM_EXIT_REASON, &exit_reason);\n\n    if ( hvm_long_mode_enabled(v) )\n        HVMTRACE_ND(VMEXIT64, 0, 1/*cycles*/, 3, exit_reason,\n                    (uint32_t)regs->eip, (uint32_t)((uint64_t)regs->eip >> 32),\n                    0, 0, 0);\n    else\n        HVMTRACE_ND(VMEXIT, 0, 1/*cycles*/, 2, exit_reason,\n                    (uint32_t)regs->eip, \n                    0, 0, 0, 0);\n\n    perfc_incra(vmexits, exit_reason);\n\n    /* Handle the interrupt we missed before allowing any more in. */\n    switch ( (uint16_t)exit_reason )\n    {\n    case EXIT_REASON_EXTERNAL_INTERRUPT:\n        vmx_do_extint(regs);\n        break;\n    case EXIT_REASON_EXCEPTION_NMI:\n        __vmread(VM_EXIT_INTR_INFO, &intr_info);\n        BUG_ON(!(intr_info & INTR_INFO_VALID_MASK));\n        vector = intr_info & INTR_INFO_VECTOR_MASK;\n        if ( vector == TRAP_machine_check )\n            do_machine_check(regs);\n        if ( (vector == TRAP_nmi) &&\n             ((intr_info & INTR_INFO_INTR_TYPE_MASK) ==\n              MASK_INSR(X86_EVENTTYPE_NMI, INTR_INFO_INTR_TYPE_MASK)) )\n        {\n            exception_table[TRAP_nmi](regs);\n            enable_nmis();\n        }\n        break;\n    case EXIT_REASON_MCE_DURING_VMENTRY:\n        do_machine_check(regs);\n        break;\n    }\n\n    /* Now enable interrupts so it's safe to take locks. */\n    local_irq_enable();\n\n    /*\n     * If the guest has the ability to switch EPTP without an exit,\n     * figure out whether it has done so and update the altp2m data.\n     */\n    if ( altp2m_active(v->domain) &&\n        (v->arch.hvm_vmx.secondary_exec_control &\n        SECONDARY_EXEC_ENABLE_VM_FUNCTIONS) )\n    {\n        unsigned long idx;\n\n        if ( v->arch.hvm_vmx.secondary_exec_control &\n            SECONDARY_EXEC_ENABLE_VIRT_EXCEPTIONS )\n            __vmread(EPTP_INDEX, &idx);\n        else\n        {\n            unsigned long eptp;\n\n            __vmread(EPT_POINTER, &eptp);\n\n            if ( (idx = p2m_find_altp2m_by_eptp(v->domain, eptp)) ==\n                 INVALID_ALTP2M )\n            {\n                gdprintk(XENLOG_ERR, \"EPTP not found in alternate p2m list\\n\");\n                domain_crash(v->domain);\n            }\n        }\n\n        if ( idx != vcpu_altp2m(v).p2midx )\n        {\n            BUG_ON(idx >= MAX_ALTP2M);\n            atomic_dec(&p2m_get_altp2m(v)->active_vcpus);\n            vcpu_altp2m(v).p2midx = idx;\n            atomic_inc(&p2m_get_altp2m(v)->active_vcpus);\n        }\n    }\n\n    /* XXX: This looks ugly, but we need a mechanism to ensure\n     * any pending vmresume has really happened\n     */\n    vcpu_nestedhvm(v).nv_vmswitch_in_progress = 0;\n    if ( nestedhvm_vcpu_in_guestmode(v) )\n    {\n        paging_update_nestedmode(v);\n        if ( nvmx_n2_vmexit_handler(regs, exit_reason) )\n            goto out;\n    }\n\n    if ( unlikely(exit_reason & VMX_EXIT_REASONS_FAILED_VMENTRY) )\n        return vmx_failed_vmentry(exit_reason, regs);\n\n    if ( v->arch.hvm_vmx.vmx_realmode )\n    {\n        /* Put RFLAGS back the way the guest wants it */\n        regs->eflags &= ~(X86_EFLAGS_VM | X86_EFLAGS_IOPL);\n        regs->eflags |= (v->arch.hvm_vmx.vm86_saved_eflags & X86_EFLAGS_IOPL);\n\n        /* Unless this exit was for an interrupt, we've hit something\n         * vm86 can't handle.  Try again, using the emulator. */\n        switch ( exit_reason )\n        {\n        case EXIT_REASON_EXCEPTION_NMI:\n            if ( vector != TRAP_page_fault\n                 && vector != TRAP_nmi \n                 && vector != TRAP_machine_check ) \n            {\n                perfc_incr(realmode_exits);\n                v->arch.hvm_vmx.vmx_emulate = 1;\n                HVMTRACE_0D(REALMODE_EMULATE);\n                return;\n            }\n        case EXIT_REASON_EXTERNAL_INTERRUPT:\n        case EXIT_REASON_INIT:\n        case EXIT_REASON_SIPI:\n        case EXIT_REASON_PENDING_VIRT_INTR:\n        case EXIT_REASON_PENDING_VIRT_NMI:\n        case EXIT_REASON_MCE_DURING_VMENTRY:\n        case EXIT_REASON_GETSEC:\n        case EXIT_REASON_ACCESS_GDTR_OR_IDTR:\n        case EXIT_REASON_ACCESS_LDTR_OR_TR:\n        case EXIT_REASON_VMX_PREEMPTION_TIMER_EXPIRED:\n        case EXIT_REASON_INVEPT:\n        case EXIT_REASON_INVVPID:\n            break;\n\n        default:\n            v->arch.hvm_vmx.vmx_emulate = 1;\n            perfc_incr(realmode_exits);\n            HVMTRACE_0D(REALMODE_EMULATE);\n            return;\n        }\n    }\n\n    hvm_maybe_deassert_evtchn_irq();\n\n    __vmread(IDT_VECTORING_INFO, &idtv_info);\n    if ( exit_reason != EXIT_REASON_TASK_SWITCH )\n        vmx_idtv_reinject(idtv_info);\n\n    switch ( exit_reason )\n    {\n        unsigned long ecode;\n\n    case EXIT_REASON_EXCEPTION_NMI:\n    {\n        /*\n         * We don't set the software-interrupt exiting (INT n).\n         * (1) We can get an exception (e.g. #PG) in the guest, or\n         * (2) NMI\n         */\n\n        /*\n         * Re-set the NMI shadow if vmexit caused by a guest IRET fault (see 3B\n         * 25.7.1.2, \"Resuming Guest Software after Handling an Exception\").\n         * (NB. If we emulate this IRET for any reason, we should re-clear!)\n         */\n        if ( unlikely(intr_info & INTR_INFO_NMI_UNBLOCKED_BY_IRET) &&\n             !(idtv_info & INTR_INFO_VALID_MASK) &&\n             (vector != TRAP_double_fault) )\n        {\n            unsigned long guest_info;\n\n            __vmread(GUEST_INTERRUPTIBILITY_INFO, &guest_info);\n            __vmwrite(GUEST_INTERRUPTIBILITY_INFO,\n                      guest_info | VMX_INTR_SHADOW_NMI);\n        }\n\n        perfc_incra(cause_vector, vector);\n\n        switch ( vector )\n        {\n        case TRAP_debug:\n            /*\n             * Updates DR6 where debugger can peek (See 3B 23.2.1,\n             * Table 23-1, \"Exit Qualification for Debug Exceptions\").\n             */\n            __vmread(EXIT_QUALIFICATION, &exit_qualification);\n            HVMTRACE_1D(TRAP_DEBUG, exit_qualification);\n            write_debugreg(6, exit_qualification | DR_STATUS_RESERVED_ONE);\n            if ( !v->domain->debugger_attached )\n                hvm_inject_hw_exception(vector, HVM_DELIVER_NO_ERROR_CODE);\n            else\n                domain_pause_for_debugger();\n            break;\n        case TRAP_int3: \n        {\n            HVMTRACE_1D(TRAP, vector);\n            if ( v->domain->debugger_attached )\n            {\n                update_guest_eip(); /* Safe: INT3 */            \n                v->arch.gdbsx_vcpu_event = TRAP_int3;\n                domain_pause_for_debugger();\n                break;\n            }\n            else {\n                int handled = hvm_event_int3(regs->eip);\n                \n                if ( handled < 0 ) \n                {\n                    struct hvm_trap trap = {\n                        .vector = TRAP_int3,\n                        .type = X86_EVENTTYPE_SW_EXCEPTION,\n                        .error_code = HVM_DELIVER_NO_ERROR_CODE,\n                    };\n                    unsigned long insn_len;\n\n                    __vmread(VM_EXIT_INSTRUCTION_LEN, &insn_len);\n                    trap.insn_len = insn_len;\n                    hvm_inject_trap(&trap);\n                    break;\n                }\n                else if ( handled )\n                    break;\n            }\n\n            goto exit_and_crash;\n        }\n        case TRAP_no_device:\n            HVMTRACE_1D(TRAP, vector);\n            vmx_fpu_dirty_intercept();\n            break;\n        case TRAP_page_fault:\n            __vmread(EXIT_QUALIFICATION, &exit_qualification);\n            __vmread(VM_EXIT_INTR_ERROR_CODE, &ecode);\n            regs->error_code = ecode;\n\n            HVM_DBG_LOG(DBG_LEVEL_VMMU,\n                        \"eax=%lx, ebx=%lx, ecx=%lx, edx=%lx, esi=%lx, edi=%lx\",\n                        (unsigned long)regs->eax, (unsigned long)regs->ebx,\n                        (unsigned long)regs->ecx, (unsigned long)regs->edx,\n                        (unsigned long)regs->esi, (unsigned long)regs->edi);\n\n            if ( paging_fault(exit_qualification, regs) )\n            {\n                if ( trace_will_trace_event(TRC_SHADOW) )\n                    break;\n                if ( hvm_long_mode_enabled(v) )\n                    HVMTRACE_LONG_2D(PF_XEN, regs->error_code,\n                                     TRC_PAR_LONG(exit_qualification) );\n                else\n                    HVMTRACE_2D(PF_XEN,\n                                regs->error_code, exit_qualification );\n                break;\n            }\n\n            hvm_inject_page_fault(regs->error_code, exit_qualification);\n            break;\n        case TRAP_alignment_check:\n            HVMTRACE_1D(TRAP, vector);\n            __vmread(VM_EXIT_INTR_ERROR_CODE, &ecode);\n            hvm_inject_hw_exception(vector, ecode);\n            break;\n        case TRAP_nmi:\n            if ( MASK_EXTR(intr_info, INTR_INFO_INTR_TYPE_MASK) !=\n                 X86_EVENTTYPE_NMI )\n                goto exit_and_crash;\n            HVMTRACE_0D(NMI);\n            /* Already handled above. */\n            break;\n        case TRAP_machine_check:\n            HVMTRACE_0D(MCE);\n            /* Already handled above. */\n            break;\n        case TRAP_invalid_op:\n            HVMTRACE_1D(TRAP, vector);\n            vmx_vmexit_ud_intercept(regs);\n            break;\n        default:\n            HVMTRACE_1D(TRAP, vector);\n            goto exit_and_crash;\n        }\n        break;\n    }\n    case EXIT_REASON_EXTERNAL_INTERRUPT:\n        /* Already handled above. */\n        break;\n    case EXIT_REASON_TRIPLE_FAULT:\n        hvm_triple_fault();\n        break;\n    case EXIT_REASON_PENDING_VIRT_INTR:\n        /* Disable the interrupt window. */\n        v->arch.hvm_vmx.exec_control &= ~CPU_BASED_VIRTUAL_INTR_PENDING;\n        vmx_update_cpu_exec_control(v);\n        break;\n    case EXIT_REASON_PENDING_VIRT_NMI:\n        /* Disable the NMI window. */\n        v->arch.hvm_vmx.exec_control &= ~CPU_BASED_VIRTUAL_NMI_PENDING;\n        vmx_update_cpu_exec_control(v);\n        break;\n    case EXIT_REASON_TASK_SWITCH: {\n        static const enum hvm_task_switch_reason reasons[] = {\n            TSW_call_or_int, TSW_iret, TSW_jmp, TSW_call_or_int\n        };\n        unsigned int inst_len, source;\n\n        __vmread(EXIT_QUALIFICATION, &exit_qualification);\n        source = (exit_qualification >> 30) & 3;\n        /* Vectored event should fill in interrupt information. */\n        WARN_ON((source == 3) && !(idtv_info & INTR_INFO_VALID_MASK));\n        /*\n         * In the following cases there is an instruction to skip over:\n         *  - TSW is due to a CALL, IRET or JMP instruction.\n         *  - TSW is a vectored event due to a SW exception or SW interrupt.\n         */\n        inst_len = ((source != 3) ||        /* CALL, IRET, or JMP? */\n                    (MASK_EXTR(idtv_info, INTR_INFO_INTR_TYPE_MASK)\n                     > 3)) /* IntrType > 3? */\n            ? get_instruction_length() /* Safe: SDM 3B 23.2.4 */ : 0;\n        if ( (source == 3) && (idtv_info & INTR_INFO_DELIVER_CODE_MASK) )\n            __vmread(IDT_VECTORING_ERROR_CODE, &ecode);\n        else\n             ecode = -1;\n        regs->eip += inst_len;\n        hvm_task_switch((uint16_t)exit_qualification, reasons[source], ecode);\n        break;\n    }\n    case EXIT_REASON_CPUID:\n        is_pvh_vcpu(v) ? pv_cpuid(regs) : vmx_do_cpuid(regs);\n        update_guest_eip(); /* Safe: CPUID */\n        break;\n    case EXIT_REASON_HLT:\n        update_guest_eip(); /* Safe: HLT */\n        hvm_hlt(regs->eflags);\n        break;\n    case EXIT_REASON_INVLPG:\n        update_guest_eip(); /* Safe: INVLPG */\n        __vmread(EXIT_QUALIFICATION, &exit_qualification);\n        vmx_invlpg_intercept(exit_qualification);\n        break;\n    case EXIT_REASON_RDTSCP:\n        regs->ecx = hvm_msr_tsc_aux(v);\n        /* fall through */\n    case EXIT_REASON_RDTSC:\n        update_guest_eip(); /* Safe: RDTSC, RDTSCP */\n        hvm_rdtsc_intercept(regs);\n        break;\n    case EXIT_REASON_VMCALL:\n    {\n        int rc;\n        HVMTRACE_1D(VMMCALL, regs->eax);\n        rc = hvm_do_hypercall(regs);\n        if ( rc != HVM_HCALL_preempted )\n        {\n            update_guest_eip(); /* Safe: VMCALL */\n            if ( rc == HVM_HCALL_invalidate )\n                send_invalidate_req();\n        }\n        break;\n    }\n    case EXIT_REASON_CR_ACCESS:\n    {\n        __vmread(EXIT_QUALIFICATION, &exit_qualification);\n        if ( vmx_cr_access(exit_qualification) == X86EMUL_OKAY )\n            update_guest_eip(); /* Safe: MOV Cn, LMSW, CLTS */\n        break;\n    }\n    case EXIT_REASON_DR_ACCESS:\n        __vmread(EXIT_QUALIFICATION, &exit_qualification);\n        vmx_dr_access(exit_qualification, regs);\n        break;\n    case EXIT_REASON_MSR_READ:\n    {\n        uint64_t msr_content;\n        if ( hvm_msr_read_intercept(regs->ecx, &msr_content) == X86EMUL_OKAY )\n        {\n            regs->eax = (uint32_t)msr_content;\n            regs->edx = (uint32_t)(msr_content >> 32);\n            update_guest_eip(); /* Safe: RDMSR */\n        }\n        break;\n    }\n    case EXIT_REASON_MSR_WRITE:\n    {\n        uint64_t msr_content;\n        msr_content = ((uint64_t)regs->edx << 32) | (uint32_t)regs->eax;\n        if ( hvm_msr_write_intercept(regs->ecx, msr_content, 1) == X86EMUL_OKAY )\n            update_guest_eip(); /* Safe: WRMSR */\n        break;\n    }\n\n    case EXIT_REASON_VMXOFF:\n        if ( nvmx_handle_vmxoff(regs) == X86EMUL_OKAY )\n            update_guest_eip();\n        break;\n\n    case EXIT_REASON_VMXON:\n        if ( nvmx_handle_vmxon(regs) == X86EMUL_OKAY )\n            update_guest_eip();\n        break;\n\n    case EXIT_REASON_VMCLEAR:\n        if ( nvmx_handle_vmclear(regs) == X86EMUL_OKAY )\n            update_guest_eip();\n        break;\n \n    case EXIT_REASON_VMPTRLD:\n        if ( nvmx_handle_vmptrld(regs) == X86EMUL_OKAY )\n            update_guest_eip();\n        break;\n\n    case EXIT_REASON_VMPTRST:\n        if ( nvmx_handle_vmptrst(regs) == X86EMUL_OKAY )\n            update_guest_eip();\n        break;\n\n    case EXIT_REASON_VMREAD:\n        if ( nvmx_handle_vmread(regs) == X86EMUL_OKAY )\n            update_guest_eip();\n        break;\n \n    case EXIT_REASON_VMWRITE:\n        if ( nvmx_handle_vmwrite(regs) == X86EMUL_OKAY )\n            update_guest_eip();\n        break;\n\n    case EXIT_REASON_VMLAUNCH:\n        if ( nvmx_handle_vmlaunch(regs) == X86EMUL_OKAY )\n            update_guest_eip();\n        break;\n\n    case EXIT_REASON_VMRESUME:\n        if ( nvmx_handle_vmresume(regs) == X86EMUL_OKAY )\n            update_guest_eip();\n        break;\n\n    case EXIT_REASON_INVEPT:\n        if ( nvmx_handle_invept(regs) == X86EMUL_OKAY )\n            update_guest_eip();\n        break;\n\n    case EXIT_REASON_INVVPID:\n        if ( nvmx_handle_invvpid(regs) == X86EMUL_OKAY )\n            update_guest_eip();\n        break;\n\n    case EXIT_REASON_VMFUNC:\n        if ( vmx_vmfunc_intercept(regs) != X86EMUL_OKAY )\n            hvm_inject_hw_exception(TRAP_invalid_op, HVM_DELIVER_NO_ERROR_CODE);\n        else\n            update_guest_eip();\n        break;\n\n    case EXIT_REASON_MWAIT_INSTRUCTION:\n    case EXIT_REASON_MONITOR_INSTRUCTION:\n    case EXIT_REASON_GETSEC:\n        /*\n         * We should never exit on GETSEC because CR4.SMXE is always 0 when\n         * running in guest context, and the CPU checks that before getting\n         * as far as vmexit.\n         */\n        WARN_ON(exit_reason == EXIT_REASON_GETSEC);\n        hvm_inject_hw_exception(TRAP_invalid_op, HVM_DELIVER_NO_ERROR_CODE);\n        break;\n\n    case EXIT_REASON_TPR_BELOW_THRESHOLD:\n        break;\n\n    case EXIT_REASON_APIC_ACCESS:\n        if ( !vmx_handle_eoi_write() && !handle_mmio() )\n            hvm_inject_hw_exception(TRAP_gp_fault, 0);\n        break;\n\n    case EXIT_REASON_EOI_INDUCED:\n        __vmread(EXIT_QUALIFICATION, &exit_qualification);\n\n        ASSERT(cpu_has_vmx_virtual_intr_delivery);\n\n        vlapic_handle_EOI(vcpu_vlapic(v), exit_qualification);\n        break;\n\n    case EXIT_REASON_IO_INSTRUCTION:\n        __vmread(EXIT_QUALIFICATION, &exit_qualification);\n        if ( exit_qualification & 0x10 )\n        {\n            /* INS, OUTS */\n            if ( unlikely(is_pvh_vcpu(v)) /* PVH fixme */ ||\n                 !handle_mmio() )\n                hvm_inject_hw_exception(TRAP_gp_fault, 0);\n        }\n        else\n        {\n            /* IN, OUT */\n            uint16_t port = (exit_qualification >> 16) & 0xFFFF;\n            int bytes = (exit_qualification & 0x07) + 1;\n            int dir = (exit_qualification & 0x08) ? IOREQ_READ : IOREQ_WRITE;\n            if ( handle_pio(port, bytes, dir) )\n                update_guest_eip(); /* Safe: IN, OUT */\n        }\n        break;\n\n    case EXIT_REASON_INVD:\n    case EXIT_REASON_WBINVD:\n    {\n        update_guest_eip(); /* Safe: INVD, WBINVD */\n        vmx_wbinvd_intercept();\n        break;\n    }\n\n    case EXIT_REASON_EPT_VIOLATION:\n    {\n        paddr_t gpa;\n\n        __vmread(GUEST_PHYSICAL_ADDRESS, &gpa);\n        __vmread(EXIT_QUALIFICATION, &exit_qualification);\n        ept_handle_violation(exit_qualification, gpa);\n        break;\n    }\n\n    case EXIT_REASON_EPT_MISCONFIG:\n    {\n        paddr_t gpa;\n\n        __vmread(GUEST_PHYSICAL_ADDRESS, &gpa);\n        if ( !ept_handle_misconfig(gpa) )\n            goto exit_and_crash;\n        break;\n    }\n\n    case EXIT_REASON_MONITOR_TRAP_FLAG:\n        v->arch.hvm_vmx.exec_control &= ~CPU_BASED_MONITOR_TRAP_FLAG;\n        vmx_update_cpu_exec_control(v);\n        if ( v->arch.hvm_vcpu.single_step ) {\n          hvm_event_single_step(regs->eip);\n          if ( v->domain->debugger_attached )\n              domain_pause_for_debugger();\n        }\n\n        break;\n\n    case EXIT_REASON_PAUSE_INSTRUCTION:\n        perfc_incr(pauseloop_exits);\n        do_sched_op(SCHEDOP_yield, guest_handle_from_ptr(NULL, void));\n        break;\n\n    case EXIT_REASON_XSETBV:\n        if ( hvm_handle_xsetbv(regs->ecx,\n                               (regs->rdx << 32) | regs->_eax) == 0 )\n            update_guest_eip(); /* Safe: XSETBV */\n        break;\n\n    case EXIT_REASON_APIC_WRITE:\n        vmx_handle_apic_write();\n        break;\n\n    case EXIT_REASON_PML_FULL:\n        vmx_vcpu_flush_pml_buffer(v);\n        break;\n\n    case EXIT_REASON_ACCESS_GDTR_OR_IDTR:\n    case EXIT_REASON_ACCESS_LDTR_OR_TR:\n    case EXIT_REASON_VMX_PREEMPTION_TIMER_EXPIRED:\n    case EXIT_REASON_INVPCID:\n    /* fall through */\n    default:\n    exit_and_crash:\n        {\n            struct segment_register ss;\n\n            gdprintk(XENLOG_WARNING, \"Bad vmexit (reason %#lx)\\n\",\n                     exit_reason);\n\n            vmx_get_segment_register(v, x86_seg_ss, &ss);\n            if ( ss.attr.fields.dpl )\n                hvm_inject_hw_exception(TRAP_invalid_op,\n                                        HVM_DELIVER_NO_ERROR_CODE);\n            else\n                domain_crash(v->domain);\n        }\n        break;\n    }\n\nout:\n    if ( nestedhvm_vcpu_in_guestmode(v) )\n        nvmx_idtv_handling();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -196,9 +196,10 @@\n             __vmread(EXIT_QUALIFICATION, &exit_qualification);\n             HVMTRACE_1D(TRAP_DEBUG, exit_qualification);\n             write_debugreg(6, exit_qualification | DR_STATUS_RESERVED_ONE);\n-            if ( !v->domain->debugger_attached || cpu_has_monitor_trap_flag )\n-                goto exit_and_crash;\n-            domain_pause_for_debugger();\n+            if ( !v->domain->debugger_attached )\n+                hvm_inject_hw_exception(vector, HVM_DELIVER_NO_ERROR_CODE);\n+            else\n+                domain_pause_for_debugger();\n             break;\n         case TRAP_int3: \n         {\n@@ -263,6 +264,11 @@\n \n             hvm_inject_page_fault(regs->error_code, exit_qualification);\n             break;\n+        case TRAP_alignment_check:\n+            HVMTRACE_1D(TRAP, vector);\n+            __vmread(VM_EXIT_INTR_ERROR_CODE, &ecode);\n+            hvm_inject_hw_exception(vector, ecode);\n+            break;\n         case TRAP_nmi:\n             if ( MASK_EXTR(intr_info, INTR_INFO_INTR_TYPE_MASK) !=\n                  X86_EVENTTYPE_NMI )",
        "diff_line_info": {
            "deleted_lines": [
                "            if ( !v->domain->debugger_attached || cpu_has_monitor_trap_flag )",
                "                goto exit_and_crash;",
                "            domain_pause_for_debugger();"
            ],
            "added_lines": [
                "            if ( !v->domain->debugger_attached )",
                "                hvm_inject_hw_exception(vector, HVM_DELIVER_NO_ERROR_CODE);",
                "            else",
                "                domain_pause_for_debugger();",
                "        case TRAP_alignment_check:",
                "            HVMTRACE_1D(TRAP, vector);",
                "            __vmread(VM_EXIT_INTR_ERROR_CODE, &ecode);",
                "            hvm_inject_hw_exception(vector, ecode);",
                "            break;"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-5307",
        "func_name": "xen-project/xen/vmx_update_debug_state",
        "description": "The KVM subsystem in the Linux kernel through 4.2.6, and Xen 4.3.x through 4.6.x, allows guest OS users to cause a denial of service (host OS panic or hang) by triggering many #AC (aka Alignment Check) exceptions, related to svm.c and vmx.c.",
        "git_url": "https://github.com/xen-project/xen/commit/bd2239d9fa975a1ee5bcd27c218ae042cd0a57bc",
        "commit_title": "x86/HVM: always intercept #AC and #DB",
        "commit_text": " Both being benign exceptions, and both being possible to get triggered by exception delivery, this is required to prevent a guest from locking up a CPU (resulting from no other VM exits occurring once getting into such a loop).  The specific scenarios:  1) #AC may be raised during exception delivery if the handler is set to be a ring-3 one by a 32-bit guest, and the stack is misaligned.  This is CVE-2015-5307 / XSA-156.   2) #DB may be raised during exception delivery when a breakpoint got placed on a data structure involved in delivering the exception. This can result in an endless loop when a 64-bit guest uses a non-zero IST for the vector 1 IDT entry, but even without use of IST the time it takes until a contributory fault would get raised (results depending on the handler) may be quite long.  This is CVE-2015-8104 / XSA-156. ",
        "func_before": "void vmx_update_debug_state(struct vcpu *v)\n{\n    unsigned long mask;\n\n    mask = 1u << TRAP_int3;\n    if ( !cpu_has_monitor_trap_flag )\n        mask |= 1u << TRAP_debug;\n\n    if ( v->arch.hvm_vcpu.debug_state_latch )\n        v->arch.hvm_vmx.exception_bitmap |= mask;\n    else\n        v->arch.hvm_vmx.exception_bitmap &= ~mask;\n\n    vmx_vmcs_enter(v);\n    vmx_update_exception_bitmap(v);\n    vmx_vmcs_exit(v);\n}",
        "func": "void vmx_update_debug_state(struct vcpu *v)\n{\n    if ( v->arch.hvm_vcpu.debug_state_latch )\n        v->arch.hvm_vmx.exception_bitmap |= 1U << TRAP_int3;\n    else\n        v->arch.hvm_vmx.exception_bitmap &= ~(1U << TRAP_int3);\n\n    vmx_vmcs_enter(v);\n    vmx_update_exception_bitmap(v);\n    vmx_vmcs_exit(v);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,15 +1,9 @@\n void vmx_update_debug_state(struct vcpu *v)\n {\n-    unsigned long mask;\n-\n-    mask = 1u << TRAP_int3;\n-    if ( !cpu_has_monitor_trap_flag )\n-        mask |= 1u << TRAP_debug;\n-\n     if ( v->arch.hvm_vcpu.debug_state_latch )\n-        v->arch.hvm_vmx.exception_bitmap |= mask;\n+        v->arch.hvm_vmx.exception_bitmap |= 1U << TRAP_int3;\n     else\n-        v->arch.hvm_vmx.exception_bitmap &= ~mask;\n+        v->arch.hvm_vmx.exception_bitmap &= ~(1U << TRAP_int3);\n \n     vmx_vmcs_enter(v);\n     vmx_update_exception_bitmap(v);",
        "diff_line_info": {
            "deleted_lines": [
                "    unsigned long mask;",
                "",
                "    mask = 1u << TRAP_int3;",
                "    if ( !cpu_has_monitor_trap_flag )",
                "        mask |= 1u << TRAP_debug;",
                "",
                "        v->arch.hvm_vmx.exception_bitmap |= mask;",
                "        v->arch.hvm_vmx.exception_bitmap &= ~mask;"
            ],
            "added_lines": [
                "        v->arch.hvm_vmx.exception_bitmap |= 1U << TRAP_int3;",
                "        v->arch.hvm_vmx.exception_bitmap &= ~(1U << TRAP_int3);"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-5307",
        "func_name": "torvalds/linux/init_vmcb",
        "description": "The KVM subsystem in the Linux kernel through 4.2.6, and Xen 4.3.x through 4.6.x, allows guest OS users to cause a denial of service (host OS panic or hang) by triggering many #AC (aka Alignment Check) exceptions, related to svm.c and vmx.c.",
        "git_url": "https://github.com/torvalds/linux/commit/54a20552e1eae07aa240fa370a0293e006b5faed",
        "commit_title": "KVM: x86: work around infinite loop in microcode when #AC is delivered",
        "commit_text": " It was found that a guest can DoS a host by triggering an infinite stream of \"alignment check\" (#AC) exceptions.  This causes the microcode to enter an infinite loop where the core never receives another interrupt.  The host kernel panics pretty quickly due to the effects (CVE-2015-5307).  Cc: stable@vger.kernel.org",
        "func_before": "static void init_vmcb(struct vcpu_svm *svm)\n{\n\tstruct vmcb_control_area *control = &svm->vmcb->control;\n\tstruct vmcb_save_area *save = &svm->vmcb->save;\n\n\tsvm->vcpu.fpu_active = 1;\n\tsvm->vcpu.arch.hflags = 0;\n\n\tset_cr_intercept(svm, INTERCEPT_CR0_READ);\n\tset_cr_intercept(svm, INTERCEPT_CR3_READ);\n\tset_cr_intercept(svm, INTERCEPT_CR4_READ);\n\tset_cr_intercept(svm, INTERCEPT_CR0_WRITE);\n\tset_cr_intercept(svm, INTERCEPT_CR3_WRITE);\n\tset_cr_intercept(svm, INTERCEPT_CR4_WRITE);\n\tset_cr_intercept(svm, INTERCEPT_CR8_WRITE);\n\n\tset_dr_intercepts(svm);\n\n\tset_exception_intercept(svm, PF_VECTOR);\n\tset_exception_intercept(svm, UD_VECTOR);\n\tset_exception_intercept(svm, MC_VECTOR);\n\n\tset_intercept(svm, INTERCEPT_INTR);\n\tset_intercept(svm, INTERCEPT_NMI);\n\tset_intercept(svm, INTERCEPT_SMI);\n\tset_intercept(svm, INTERCEPT_SELECTIVE_CR0);\n\tset_intercept(svm, INTERCEPT_RDPMC);\n\tset_intercept(svm, INTERCEPT_CPUID);\n\tset_intercept(svm, INTERCEPT_INVD);\n\tset_intercept(svm, INTERCEPT_HLT);\n\tset_intercept(svm, INTERCEPT_INVLPG);\n\tset_intercept(svm, INTERCEPT_INVLPGA);\n\tset_intercept(svm, INTERCEPT_IOIO_PROT);\n\tset_intercept(svm, INTERCEPT_MSR_PROT);\n\tset_intercept(svm, INTERCEPT_TASK_SWITCH);\n\tset_intercept(svm, INTERCEPT_SHUTDOWN);\n\tset_intercept(svm, INTERCEPT_VMRUN);\n\tset_intercept(svm, INTERCEPT_VMMCALL);\n\tset_intercept(svm, INTERCEPT_VMLOAD);\n\tset_intercept(svm, INTERCEPT_VMSAVE);\n\tset_intercept(svm, INTERCEPT_STGI);\n\tset_intercept(svm, INTERCEPT_CLGI);\n\tset_intercept(svm, INTERCEPT_SKINIT);\n\tset_intercept(svm, INTERCEPT_WBINVD);\n\tset_intercept(svm, INTERCEPT_MONITOR);\n\tset_intercept(svm, INTERCEPT_MWAIT);\n\tset_intercept(svm, INTERCEPT_XSETBV);\n\n\tcontrol->iopm_base_pa = iopm_base;\n\tcontrol->msrpm_base_pa = __pa(svm->msrpm);\n\tcontrol->int_ctl = V_INTR_MASKING_MASK;\n\n\tinit_seg(&save->es);\n\tinit_seg(&save->ss);\n\tinit_seg(&save->ds);\n\tinit_seg(&save->fs);\n\tinit_seg(&save->gs);\n\n\tsave->cs.selector = 0xf000;\n\tsave->cs.base = 0xffff0000;\n\t/* Executable/Readable Code Segment */\n\tsave->cs.attrib = SVM_SELECTOR_READ_MASK | SVM_SELECTOR_P_MASK |\n\t\tSVM_SELECTOR_S_MASK | SVM_SELECTOR_CODE_MASK;\n\tsave->cs.limit = 0xffff;\n\n\tsave->gdtr.limit = 0xffff;\n\tsave->idtr.limit = 0xffff;\n\n\tinit_sys_seg(&save->ldtr, SEG_TYPE_LDT);\n\tinit_sys_seg(&save->tr, SEG_TYPE_BUSY_TSS16);\n\n\tsvm_set_efer(&svm->vcpu, 0);\n\tsave->dr6 = 0xffff0ff0;\n\tkvm_set_rflags(&svm->vcpu, 2);\n\tsave->rip = 0x0000fff0;\n\tsvm->vcpu.arch.regs[VCPU_REGS_RIP] = save->rip;\n\n\t/*\n\t * svm_set_cr0() sets PG and WP and clears NW and CD on save->cr0.\n\t * It also updates the guest-visible cr0 value.\n\t */\n\tsvm_set_cr0(&svm->vcpu, X86_CR0_NW | X86_CR0_CD | X86_CR0_ET);\n\tkvm_mmu_reset_context(&svm->vcpu);\n\n\tsave->cr4 = X86_CR4_PAE;\n\t/* rdx = ?? */\n\n\tif (npt_enabled) {\n\t\t/* Setup VMCB for Nested Paging */\n\t\tcontrol->nested_ctl = 1;\n\t\tclr_intercept(svm, INTERCEPT_INVLPG);\n\t\tclr_exception_intercept(svm, PF_VECTOR);\n\t\tclr_cr_intercept(svm, INTERCEPT_CR3_READ);\n\t\tclr_cr_intercept(svm, INTERCEPT_CR3_WRITE);\n\t\tsave->g_pat = svm->vcpu.arch.pat;\n\t\tsave->cr3 = 0;\n\t\tsave->cr4 = 0;\n\t}\n\tsvm->asid_generation = 0;\n\n\tsvm->nested.vmcb = 0;\n\tsvm->vcpu.arch.hflags = 0;\n\n\tif (boot_cpu_has(X86_FEATURE_PAUSEFILTER)) {\n\t\tcontrol->pause_filter_count = 3000;\n\t\tset_intercept(svm, INTERCEPT_PAUSE);\n\t}\n\n\tmark_all_dirty(svm->vmcb);\n\n\tenable_gif(svm);\n}",
        "func": "static void init_vmcb(struct vcpu_svm *svm)\n{\n\tstruct vmcb_control_area *control = &svm->vmcb->control;\n\tstruct vmcb_save_area *save = &svm->vmcb->save;\n\n\tsvm->vcpu.fpu_active = 1;\n\tsvm->vcpu.arch.hflags = 0;\n\n\tset_cr_intercept(svm, INTERCEPT_CR0_READ);\n\tset_cr_intercept(svm, INTERCEPT_CR3_READ);\n\tset_cr_intercept(svm, INTERCEPT_CR4_READ);\n\tset_cr_intercept(svm, INTERCEPT_CR0_WRITE);\n\tset_cr_intercept(svm, INTERCEPT_CR3_WRITE);\n\tset_cr_intercept(svm, INTERCEPT_CR4_WRITE);\n\tset_cr_intercept(svm, INTERCEPT_CR8_WRITE);\n\n\tset_dr_intercepts(svm);\n\n\tset_exception_intercept(svm, PF_VECTOR);\n\tset_exception_intercept(svm, UD_VECTOR);\n\tset_exception_intercept(svm, MC_VECTOR);\n\tset_exception_intercept(svm, AC_VECTOR);\n\n\tset_intercept(svm, INTERCEPT_INTR);\n\tset_intercept(svm, INTERCEPT_NMI);\n\tset_intercept(svm, INTERCEPT_SMI);\n\tset_intercept(svm, INTERCEPT_SELECTIVE_CR0);\n\tset_intercept(svm, INTERCEPT_RDPMC);\n\tset_intercept(svm, INTERCEPT_CPUID);\n\tset_intercept(svm, INTERCEPT_INVD);\n\tset_intercept(svm, INTERCEPT_HLT);\n\tset_intercept(svm, INTERCEPT_INVLPG);\n\tset_intercept(svm, INTERCEPT_INVLPGA);\n\tset_intercept(svm, INTERCEPT_IOIO_PROT);\n\tset_intercept(svm, INTERCEPT_MSR_PROT);\n\tset_intercept(svm, INTERCEPT_TASK_SWITCH);\n\tset_intercept(svm, INTERCEPT_SHUTDOWN);\n\tset_intercept(svm, INTERCEPT_VMRUN);\n\tset_intercept(svm, INTERCEPT_VMMCALL);\n\tset_intercept(svm, INTERCEPT_VMLOAD);\n\tset_intercept(svm, INTERCEPT_VMSAVE);\n\tset_intercept(svm, INTERCEPT_STGI);\n\tset_intercept(svm, INTERCEPT_CLGI);\n\tset_intercept(svm, INTERCEPT_SKINIT);\n\tset_intercept(svm, INTERCEPT_WBINVD);\n\tset_intercept(svm, INTERCEPT_MONITOR);\n\tset_intercept(svm, INTERCEPT_MWAIT);\n\tset_intercept(svm, INTERCEPT_XSETBV);\n\n\tcontrol->iopm_base_pa = iopm_base;\n\tcontrol->msrpm_base_pa = __pa(svm->msrpm);\n\tcontrol->int_ctl = V_INTR_MASKING_MASK;\n\n\tinit_seg(&save->es);\n\tinit_seg(&save->ss);\n\tinit_seg(&save->ds);\n\tinit_seg(&save->fs);\n\tinit_seg(&save->gs);\n\n\tsave->cs.selector = 0xf000;\n\tsave->cs.base = 0xffff0000;\n\t/* Executable/Readable Code Segment */\n\tsave->cs.attrib = SVM_SELECTOR_READ_MASK | SVM_SELECTOR_P_MASK |\n\t\tSVM_SELECTOR_S_MASK | SVM_SELECTOR_CODE_MASK;\n\tsave->cs.limit = 0xffff;\n\n\tsave->gdtr.limit = 0xffff;\n\tsave->idtr.limit = 0xffff;\n\n\tinit_sys_seg(&save->ldtr, SEG_TYPE_LDT);\n\tinit_sys_seg(&save->tr, SEG_TYPE_BUSY_TSS16);\n\n\tsvm_set_efer(&svm->vcpu, 0);\n\tsave->dr6 = 0xffff0ff0;\n\tkvm_set_rflags(&svm->vcpu, 2);\n\tsave->rip = 0x0000fff0;\n\tsvm->vcpu.arch.regs[VCPU_REGS_RIP] = save->rip;\n\n\t/*\n\t * svm_set_cr0() sets PG and WP and clears NW and CD on save->cr0.\n\t * It also updates the guest-visible cr0 value.\n\t */\n\tsvm_set_cr0(&svm->vcpu, X86_CR0_NW | X86_CR0_CD | X86_CR0_ET);\n\tkvm_mmu_reset_context(&svm->vcpu);\n\n\tsave->cr4 = X86_CR4_PAE;\n\t/* rdx = ?? */\n\n\tif (npt_enabled) {\n\t\t/* Setup VMCB for Nested Paging */\n\t\tcontrol->nested_ctl = 1;\n\t\tclr_intercept(svm, INTERCEPT_INVLPG);\n\t\tclr_exception_intercept(svm, PF_VECTOR);\n\t\tclr_cr_intercept(svm, INTERCEPT_CR3_READ);\n\t\tclr_cr_intercept(svm, INTERCEPT_CR3_WRITE);\n\t\tsave->g_pat = svm->vcpu.arch.pat;\n\t\tsave->cr3 = 0;\n\t\tsave->cr4 = 0;\n\t}\n\tsvm->asid_generation = 0;\n\n\tsvm->nested.vmcb = 0;\n\tsvm->vcpu.arch.hflags = 0;\n\n\tif (boot_cpu_has(X86_FEATURE_PAUSEFILTER)) {\n\t\tcontrol->pause_filter_count = 3000;\n\t\tset_intercept(svm, INTERCEPT_PAUSE);\n\t}\n\n\tmark_all_dirty(svm->vmcb);\n\n\tenable_gif(svm);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -19,6 +19,7 @@\n \tset_exception_intercept(svm, PF_VECTOR);\n \tset_exception_intercept(svm, UD_VECTOR);\n \tset_exception_intercept(svm, MC_VECTOR);\n+\tset_exception_intercept(svm, AC_VECTOR);\n \n \tset_intercept(svm, INTERCEPT_INTR);\n \tset_intercept(svm, INTERCEPT_NMI);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tset_exception_intercept(svm, AC_VECTOR);"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-5307",
        "func_name": "torvalds/linux/update_exception_bitmap",
        "description": "The KVM subsystem in the Linux kernel through 4.2.6, and Xen 4.3.x through 4.6.x, allows guest OS users to cause a denial of service (host OS panic or hang) by triggering many #AC (aka Alignment Check) exceptions, related to svm.c and vmx.c.",
        "git_url": "https://github.com/torvalds/linux/commit/54a20552e1eae07aa240fa370a0293e006b5faed",
        "commit_title": "KVM: x86: work around infinite loop in microcode when #AC is delivered",
        "commit_text": " It was found that a guest can DoS a host by triggering an infinite stream of \"alignment check\" (#AC) exceptions.  This causes the microcode to enter an infinite loop where the core never receives another interrupt.  The host kernel panics pretty quickly due to the effects (CVE-2015-5307).  Cc: stable@vger.kernel.org",
        "func_before": "static void update_exception_bitmap(struct kvm_vcpu *vcpu)\n{\n\tu32 eb;\n\n\teb = (1u << PF_VECTOR) | (1u << UD_VECTOR) | (1u << MC_VECTOR) |\n\t     (1u << NM_VECTOR) | (1u << DB_VECTOR);\n\tif ((vcpu->guest_debug &\n\t     (KVM_GUESTDBG_ENABLE | KVM_GUESTDBG_USE_SW_BP)) ==\n\t    (KVM_GUESTDBG_ENABLE | KVM_GUESTDBG_USE_SW_BP))\n\t\teb |= 1u << BP_VECTOR;\n\tif (to_vmx(vcpu)->rmode.vm86_active)\n\t\teb = ~0;\n\tif (enable_ept)\n\t\teb &= ~(1u << PF_VECTOR); /* bypass_guest_pf = 0 */\n\tif (vcpu->fpu_active)\n\t\teb &= ~(1u << NM_VECTOR);\n\n\t/* When we are running a nested L2 guest and L1 specified for it a\n\t * certain exception bitmap, we must trap the same exceptions and pass\n\t * them to L1. When running L2, we will only handle the exceptions\n\t * specified above if L1 did not want them.\n\t */\n\tif (is_guest_mode(vcpu))\n\t\teb |= get_vmcs12(vcpu)->exception_bitmap;\n\n\tvmcs_write32(EXCEPTION_BITMAP, eb);\n}",
        "func": "static void update_exception_bitmap(struct kvm_vcpu *vcpu)\n{\n\tu32 eb;\n\n\teb = (1u << PF_VECTOR) | (1u << UD_VECTOR) | (1u << MC_VECTOR) |\n\t     (1u << NM_VECTOR) | (1u << DB_VECTOR) | (1u << AC_VECTOR);\n\tif ((vcpu->guest_debug &\n\t     (KVM_GUESTDBG_ENABLE | KVM_GUESTDBG_USE_SW_BP)) ==\n\t    (KVM_GUESTDBG_ENABLE | KVM_GUESTDBG_USE_SW_BP))\n\t\teb |= 1u << BP_VECTOR;\n\tif (to_vmx(vcpu)->rmode.vm86_active)\n\t\teb = ~0;\n\tif (enable_ept)\n\t\teb &= ~(1u << PF_VECTOR); /* bypass_guest_pf = 0 */\n\tif (vcpu->fpu_active)\n\t\teb &= ~(1u << NM_VECTOR);\n\n\t/* When we are running a nested L2 guest and L1 specified for it a\n\t * certain exception bitmap, we must trap the same exceptions and pass\n\t * them to L1. When running L2, we will only handle the exceptions\n\t * specified above if L1 did not want them.\n\t */\n\tif (is_guest_mode(vcpu))\n\t\teb |= get_vmcs12(vcpu)->exception_bitmap;\n\n\tvmcs_write32(EXCEPTION_BITMAP, eb);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,7 +3,7 @@\n \tu32 eb;\n \n \teb = (1u << PF_VECTOR) | (1u << UD_VECTOR) | (1u << MC_VECTOR) |\n-\t     (1u << NM_VECTOR) | (1u << DB_VECTOR);\n+\t     (1u << NM_VECTOR) | (1u << DB_VECTOR) | (1u << AC_VECTOR);\n \tif ((vcpu->guest_debug &\n \t     (KVM_GUESTDBG_ENABLE | KVM_GUESTDBG_USE_SW_BP)) ==\n \t    (KVM_GUESTDBG_ENABLE | KVM_GUESTDBG_USE_SW_BP))",
        "diff_line_info": {
            "deleted_lines": [
                "\t     (1u << NM_VECTOR) | (1u << DB_VECTOR);"
            ],
            "added_lines": [
                "\t     (1u << NM_VECTOR) | (1u << DB_VECTOR) | (1u << AC_VECTOR);"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-5307",
        "func_name": "torvalds/linux/handle_exception",
        "description": "The KVM subsystem in the Linux kernel through 4.2.6, and Xen 4.3.x through 4.6.x, allows guest OS users to cause a denial of service (host OS panic or hang) by triggering many #AC (aka Alignment Check) exceptions, related to svm.c and vmx.c.",
        "git_url": "https://github.com/torvalds/linux/commit/54a20552e1eae07aa240fa370a0293e006b5faed",
        "commit_title": "KVM: x86: work around infinite loop in microcode when #AC is delivered",
        "commit_text": " It was found that a guest can DoS a host by triggering an infinite stream of \"alignment check\" (#AC) exceptions.  This causes the microcode to enter an infinite loop where the core never receives another interrupt.  The host kernel panics pretty quickly due to the effects (CVE-2015-5307).  Cc: stable@vger.kernel.org",
        "func_before": "static int handle_exception(struct kvm_vcpu *vcpu)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tstruct kvm_run *kvm_run = vcpu->run;\n\tu32 intr_info, ex_no, error_code;\n\tunsigned long cr2, rip, dr6;\n\tu32 vect_info;\n\tenum emulation_result er;\n\n\tvect_info = vmx->idt_vectoring_info;\n\tintr_info = vmx->exit_intr_info;\n\n\tif (is_machine_check(intr_info))\n\t\treturn handle_machine_check(vcpu);\n\n\tif ((intr_info & INTR_INFO_INTR_TYPE_MASK) == INTR_TYPE_NMI_INTR)\n\t\treturn 1;  /* already handled by vmx_vcpu_run() */\n\n\tif (is_no_device(intr_info)) {\n\t\tvmx_fpu_activate(vcpu);\n\t\treturn 1;\n\t}\n\n\tif (is_invalid_opcode(intr_info)) {\n\t\tif (is_guest_mode(vcpu)) {\n\t\t\tkvm_queue_exception(vcpu, UD_VECTOR);\n\t\t\treturn 1;\n\t\t}\n\t\ter = emulate_instruction(vcpu, EMULTYPE_TRAP_UD);\n\t\tif (er != EMULATE_DONE)\n\t\t\tkvm_queue_exception(vcpu, UD_VECTOR);\n\t\treturn 1;\n\t}\n\n\terror_code = 0;\n\tif (intr_info & INTR_INFO_DELIVER_CODE_MASK)\n\t\terror_code = vmcs_read32(VM_EXIT_INTR_ERROR_CODE);\n\n\t/*\n\t * The #PF with PFEC.RSVD = 1 indicates the guest is accessing\n\t * MMIO, it is better to report an internal error.\n\t * See the comments in vmx_handle_exit.\n\t */\n\tif ((vect_info & VECTORING_INFO_VALID_MASK) &&\n\t    !(is_page_fault(intr_info) && !(error_code & PFERR_RSVD_MASK))) {\n\t\tvcpu->run->exit_reason = KVM_EXIT_INTERNAL_ERROR;\n\t\tvcpu->run->internal.suberror = KVM_INTERNAL_ERROR_SIMUL_EX;\n\t\tvcpu->run->internal.ndata = 3;\n\t\tvcpu->run->internal.data[0] = vect_info;\n\t\tvcpu->run->internal.data[1] = intr_info;\n\t\tvcpu->run->internal.data[2] = error_code;\n\t\treturn 0;\n\t}\n\n\tif (is_page_fault(intr_info)) {\n\t\t/* EPT won't cause page fault directly */\n\t\tBUG_ON(enable_ept);\n\t\tcr2 = vmcs_readl(EXIT_QUALIFICATION);\n\t\ttrace_kvm_page_fault(cr2, error_code);\n\n\t\tif (kvm_event_needs_reinjection(vcpu))\n\t\t\tkvm_mmu_unprotect_page_virt(vcpu, cr2);\n\t\treturn kvm_mmu_page_fault(vcpu, cr2, error_code, NULL, 0);\n\t}\n\n\tex_no = intr_info & INTR_INFO_VECTOR_MASK;\n\n\tif (vmx->rmode.vm86_active && rmode_exception(vcpu, ex_no))\n\t\treturn handle_rmode_exception(vcpu, ex_no, error_code);\n\n\tswitch (ex_no) {\n\tcase DB_VECTOR:\n\t\tdr6 = vmcs_readl(EXIT_QUALIFICATION);\n\t\tif (!(vcpu->guest_debug &\n\t\t      (KVM_GUESTDBG_SINGLESTEP | KVM_GUESTDBG_USE_HW_BP))) {\n\t\t\tvcpu->arch.dr6 &= ~15;\n\t\t\tvcpu->arch.dr6 |= dr6 | DR6_RTM;\n\t\t\tif (!(dr6 & ~DR6_RESERVED)) /* icebp */\n\t\t\t\tskip_emulated_instruction(vcpu);\n\n\t\t\tkvm_queue_exception(vcpu, DB_VECTOR);\n\t\t\treturn 1;\n\t\t}\n\t\tkvm_run->debug.arch.dr6 = dr6 | DR6_FIXED_1;\n\t\tkvm_run->debug.arch.dr7 = vmcs_readl(GUEST_DR7);\n\t\t/* fall through */\n\tcase BP_VECTOR:\n\t\t/*\n\t\t * Update instruction length as we may reinject #BP from\n\t\t * user space while in guest debugging mode. Reading it for\n\t\t * #DB as well causes no harm, it is not used in that case.\n\t\t */\n\t\tvmx->vcpu.arch.event_exit_inst_len =\n\t\t\tvmcs_read32(VM_EXIT_INSTRUCTION_LEN);\n\t\tkvm_run->exit_reason = KVM_EXIT_DEBUG;\n\t\trip = kvm_rip_read(vcpu);\n\t\tkvm_run->debug.arch.pc = vmcs_readl(GUEST_CS_BASE) + rip;\n\t\tkvm_run->debug.arch.exception = ex_no;\n\t\tbreak;\n\tdefault:\n\t\tkvm_run->exit_reason = KVM_EXIT_EXCEPTION;\n\t\tkvm_run->ex.exception = ex_no;\n\t\tkvm_run->ex.error_code = error_code;\n\t\tbreak;\n\t}\n\treturn 0;\n}",
        "func": "static int handle_exception(struct kvm_vcpu *vcpu)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\tstruct kvm_run *kvm_run = vcpu->run;\n\tu32 intr_info, ex_no, error_code;\n\tunsigned long cr2, rip, dr6;\n\tu32 vect_info;\n\tenum emulation_result er;\n\n\tvect_info = vmx->idt_vectoring_info;\n\tintr_info = vmx->exit_intr_info;\n\n\tif (is_machine_check(intr_info))\n\t\treturn handle_machine_check(vcpu);\n\n\tif ((intr_info & INTR_INFO_INTR_TYPE_MASK) == INTR_TYPE_NMI_INTR)\n\t\treturn 1;  /* already handled by vmx_vcpu_run() */\n\n\tif (is_no_device(intr_info)) {\n\t\tvmx_fpu_activate(vcpu);\n\t\treturn 1;\n\t}\n\n\tif (is_invalid_opcode(intr_info)) {\n\t\tif (is_guest_mode(vcpu)) {\n\t\t\tkvm_queue_exception(vcpu, UD_VECTOR);\n\t\t\treturn 1;\n\t\t}\n\t\ter = emulate_instruction(vcpu, EMULTYPE_TRAP_UD);\n\t\tif (er != EMULATE_DONE)\n\t\t\tkvm_queue_exception(vcpu, UD_VECTOR);\n\t\treturn 1;\n\t}\n\n\terror_code = 0;\n\tif (intr_info & INTR_INFO_DELIVER_CODE_MASK)\n\t\terror_code = vmcs_read32(VM_EXIT_INTR_ERROR_CODE);\n\n\t/*\n\t * The #PF with PFEC.RSVD = 1 indicates the guest is accessing\n\t * MMIO, it is better to report an internal error.\n\t * See the comments in vmx_handle_exit.\n\t */\n\tif ((vect_info & VECTORING_INFO_VALID_MASK) &&\n\t    !(is_page_fault(intr_info) && !(error_code & PFERR_RSVD_MASK))) {\n\t\tvcpu->run->exit_reason = KVM_EXIT_INTERNAL_ERROR;\n\t\tvcpu->run->internal.suberror = KVM_INTERNAL_ERROR_SIMUL_EX;\n\t\tvcpu->run->internal.ndata = 3;\n\t\tvcpu->run->internal.data[0] = vect_info;\n\t\tvcpu->run->internal.data[1] = intr_info;\n\t\tvcpu->run->internal.data[2] = error_code;\n\t\treturn 0;\n\t}\n\n\tif (is_page_fault(intr_info)) {\n\t\t/* EPT won't cause page fault directly */\n\t\tBUG_ON(enable_ept);\n\t\tcr2 = vmcs_readl(EXIT_QUALIFICATION);\n\t\ttrace_kvm_page_fault(cr2, error_code);\n\n\t\tif (kvm_event_needs_reinjection(vcpu))\n\t\t\tkvm_mmu_unprotect_page_virt(vcpu, cr2);\n\t\treturn kvm_mmu_page_fault(vcpu, cr2, error_code, NULL, 0);\n\t}\n\n\tex_no = intr_info & INTR_INFO_VECTOR_MASK;\n\n\tif (vmx->rmode.vm86_active && rmode_exception(vcpu, ex_no))\n\t\treturn handle_rmode_exception(vcpu, ex_no, error_code);\n\n\tswitch (ex_no) {\n\tcase AC_VECTOR:\n\t\tkvm_queue_exception_e(vcpu, AC_VECTOR, error_code);\n\t\treturn 1;\n\tcase DB_VECTOR:\n\t\tdr6 = vmcs_readl(EXIT_QUALIFICATION);\n\t\tif (!(vcpu->guest_debug &\n\t\t      (KVM_GUESTDBG_SINGLESTEP | KVM_GUESTDBG_USE_HW_BP))) {\n\t\t\tvcpu->arch.dr6 &= ~15;\n\t\t\tvcpu->arch.dr6 |= dr6 | DR6_RTM;\n\t\t\tif (!(dr6 & ~DR6_RESERVED)) /* icebp */\n\t\t\t\tskip_emulated_instruction(vcpu);\n\n\t\t\tkvm_queue_exception(vcpu, DB_VECTOR);\n\t\t\treturn 1;\n\t\t}\n\t\tkvm_run->debug.arch.dr6 = dr6 | DR6_FIXED_1;\n\t\tkvm_run->debug.arch.dr7 = vmcs_readl(GUEST_DR7);\n\t\t/* fall through */\n\tcase BP_VECTOR:\n\t\t/*\n\t\t * Update instruction length as we may reinject #BP from\n\t\t * user space while in guest debugging mode. Reading it for\n\t\t * #DB as well causes no harm, it is not used in that case.\n\t\t */\n\t\tvmx->vcpu.arch.event_exit_inst_len =\n\t\t\tvmcs_read32(VM_EXIT_INSTRUCTION_LEN);\n\t\tkvm_run->exit_reason = KVM_EXIT_DEBUG;\n\t\trip = kvm_rip_read(vcpu);\n\t\tkvm_run->debug.arch.pc = vmcs_readl(GUEST_CS_BASE) + rip;\n\t\tkvm_run->debug.arch.exception = ex_no;\n\t\tbreak;\n\tdefault:\n\t\tkvm_run->exit_reason = KVM_EXIT_EXCEPTION;\n\t\tkvm_run->ex.exception = ex_no;\n\t\tkvm_run->ex.error_code = error_code;\n\t\tbreak;\n\t}\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -69,6 +69,9 @@\n \t\treturn handle_rmode_exception(vcpu, ex_no, error_code);\n \n \tswitch (ex_no) {\n+\tcase AC_VECTOR:\n+\t\tkvm_queue_exception_e(vcpu, AC_VECTOR, error_code);\n+\t\treturn 1;\n \tcase DB_VECTOR:\n \t\tdr6 = vmcs_readl(EXIT_QUALIFICATION);\n \t\tif (!(vcpu->guest_debug &",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tcase AC_VECTOR:",
                "\t\tkvm_queue_exception_e(vcpu, AC_VECTOR, error_code);",
                "\t\treturn 1;"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-8104",
        "func_name": "torvalds/linux/db_interception",
        "description": "The KVM subsystem in the Linux kernel through 4.2.6, and Xen 4.3.x through 4.6.x, allows guest OS users to cause a denial of service (host OS panic or hang) by triggering many #DB (aka Debug) exceptions, related to svm.c.",
        "git_url": "https://github.com/torvalds/linux/commit/cbdb967af3d54993f5814f1cee0ed311a055377d",
        "commit_title": "KVM: svm: unconditionally intercept #DB",
        "commit_text": " This is needed to avoid the possibility that the guest triggers an infinite stream of #DB exceptions (CVE-2015-8104).  VMX is not affected: because it does not save DR6 in the VMCS, it already intercepts #DB unconditionally.  Cc: stable@vger.kernel.org",
        "func_before": "static int db_interception(struct vcpu_svm *svm)\n{\n\tstruct kvm_run *kvm_run = svm->vcpu.run;\n\n\tif (!(svm->vcpu.guest_debug &\n\t      (KVM_GUESTDBG_SINGLESTEP | KVM_GUESTDBG_USE_HW_BP)) &&\n\t\t!svm->nmi_singlestep) {\n\t\tkvm_queue_exception(&svm->vcpu, DB_VECTOR);\n\t\treturn 1;\n\t}\n\n\tif (svm->nmi_singlestep) {\n\t\tsvm->nmi_singlestep = false;\n\t\tif (!(svm->vcpu.guest_debug & KVM_GUESTDBG_SINGLESTEP))\n\t\t\tsvm->vmcb->save.rflags &=\n\t\t\t\t~(X86_EFLAGS_TF | X86_EFLAGS_RF);\n\t\tupdate_db_bp_intercept(&svm->vcpu);\n\t}\n\n\tif (svm->vcpu.guest_debug &\n\t    (KVM_GUESTDBG_SINGLESTEP | KVM_GUESTDBG_USE_HW_BP)) {\n\t\tkvm_run->exit_reason = KVM_EXIT_DEBUG;\n\t\tkvm_run->debug.arch.pc =\n\t\t\tsvm->vmcb->save.cs.base + svm->vmcb->save.rip;\n\t\tkvm_run->debug.arch.exception = DB_VECTOR;\n\t\treturn 0;\n\t}\n\n\treturn 1;\n}",
        "func": "static int db_interception(struct vcpu_svm *svm)\n{\n\tstruct kvm_run *kvm_run = svm->vcpu.run;\n\n\tif (!(svm->vcpu.guest_debug &\n\t      (KVM_GUESTDBG_SINGLESTEP | KVM_GUESTDBG_USE_HW_BP)) &&\n\t\t!svm->nmi_singlestep) {\n\t\tkvm_queue_exception(&svm->vcpu, DB_VECTOR);\n\t\treturn 1;\n\t}\n\n\tif (svm->nmi_singlestep) {\n\t\tsvm->nmi_singlestep = false;\n\t\tif (!(svm->vcpu.guest_debug & KVM_GUESTDBG_SINGLESTEP))\n\t\t\tsvm->vmcb->save.rflags &=\n\t\t\t\t~(X86_EFLAGS_TF | X86_EFLAGS_RF);\n\t}\n\n\tif (svm->vcpu.guest_debug &\n\t    (KVM_GUESTDBG_SINGLESTEP | KVM_GUESTDBG_USE_HW_BP)) {\n\t\tkvm_run->exit_reason = KVM_EXIT_DEBUG;\n\t\tkvm_run->debug.arch.pc =\n\t\t\tsvm->vmcb->save.cs.base + svm->vmcb->save.rip;\n\t\tkvm_run->debug.arch.exception = DB_VECTOR;\n\t\treturn 0;\n\t}\n\n\treturn 1;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -14,7 +14,6 @@\n \t\tif (!(svm->vcpu.guest_debug & KVM_GUESTDBG_SINGLESTEP))\n \t\t\tsvm->vmcb->save.rflags &=\n \t\t\t\t~(X86_EFLAGS_TF | X86_EFLAGS_RF);\n-\t\tupdate_db_bp_intercept(&svm->vcpu);\n \t}\n \n \tif (svm->vcpu.guest_debug &",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tupdate_db_bp_intercept(&svm->vcpu);"
            ],
            "added_lines": []
        }
    },
    {
        "cve_id": "CVE-2015-8104",
        "func_name": "torvalds/linux/enable_nmi_window",
        "description": "The KVM subsystem in the Linux kernel through 4.2.6, and Xen 4.3.x through 4.6.x, allows guest OS users to cause a denial of service (host OS panic or hang) by triggering many #DB (aka Debug) exceptions, related to svm.c.",
        "git_url": "https://github.com/torvalds/linux/commit/cbdb967af3d54993f5814f1cee0ed311a055377d",
        "commit_title": "KVM: svm: unconditionally intercept #DB",
        "commit_text": " This is needed to avoid the possibility that the guest triggers an infinite stream of #DB exceptions (CVE-2015-8104).  VMX is not affected: because it does not save DR6 in the VMCS, it already intercepts #DB unconditionally.  Cc: stable@vger.kernel.org",
        "func_before": "static void enable_nmi_window(struct kvm_vcpu *vcpu)\n{\n\tstruct vcpu_svm *svm = to_svm(vcpu);\n\n\tif ((svm->vcpu.arch.hflags & (HF_NMI_MASK | HF_IRET_MASK))\n\t    == HF_NMI_MASK)\n\t\treturn; /* IRET will cause a vm exit */\n\n\t/*\n\t * Something prevents NMI from been injected. Single step over possible\n\t * problem (IRET or exception injection or interrupt shadow)\n\t */\n\tsvm->nmi_singlestep = true;\n\tsvm->vmcb->save.rflags |= (X86_EFLAGS_TF | X86_EFLAGS_RF);\n\tupdate_db_bp_intercept(vcpu);\n}",
        "func": "static void enable_nmi_window(struct kvm_vcpu *vcpu)\n{\n\tstruct vcpu_svm *svm = to_svm(vcpu);\n\n\tif ((svm->vcpu.arch.hflags & (HF_NMI_MASK | HF_IRET_MASK))\n\t    == HF_NMI_MASK)\n\t\treturn; /* IRET will cause a vm exit */\n\n\t/*\n\t * Something prevents NMI from been injected. Single step over possible\n\t * problem (IRET or exception injection or interrupt shadow)\n\t */\n\tsvm->nmi_singlestep = true;\n\tsvm->vmcb->save.rflags |= (X86_EFLAGS_TF | X86_EFLAGS_RF);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -12,5 +12,4 @@\n \t */\n \tsvm->nmi_singlestep = true;\n \tsvm->vmcb->save.rflags |= (X86_EFLAGS_TF | X86_EFLAGS_RF);\n-\tupdate_db_bp_intercept(vcpu);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tupdate_db_bp_intercept(vcpu);"
            ],
            "added_lines": []
        }
    },
    {
        "cve_id": "CVE-2015-8104",
        "func_name": "torvalds/linux/init_vmcb",
        "description": "The KVM subsystem in the Linux kernel through 4.2.6, and Xen 4.3.x through 4.6.x, allows guest OS users to cause a denial of service (host OS panic or hang) by triggering many #DB (aka Debug) exceptions, related to svm.c.",
        "git_url": "https://github.com/torvalds/linux/commit/cbdb967af3d54993f5814f1cee0ed311a055377d",
        "commit_title": "KVM: svm: unconditionally intercept #DB",
        "commit_text": " This is needed to avoid the possibility that the guest triggers an infinite stream of #DB exceptions (CVE-2015-8104).  VMX is not affected: because it does not save DR6 in the VMCS, it already intercepts #DB unconditionally.  Cc: stable@vger.kernel.org",
        "func_before": "static void init_vmcb(struct vcpu_svm *svm)\n{\n\tstruct vmcb_control_area *control = &svm->vmcb->control;\n\tstruct vmcb_save_area *save = &svm->vmcb->save;\n\n\tsvm->vcpu.fpu_active = 1;\n\tsvm->vcpu.arch.hflags = 0;\n\n\tset_cr_intercept(svm, INTERCEPT_CR0_READ);\n\tset_cr_intercept(svm, INTERCEPT_CR3_READ);\n\tset_cr_intercept(svm, INTERCEPT_CR4_READ);\n\tset_cr_intercept(svm, INTERCEPT_CR0_WRITE);\n\tset_cr_intercept(svm, INTERCEPT_CR3_WRITE);\n\tset_cr_intercept(svm, INTERCEPT_CR4_WRITE);\n\tset_cr_intercept(svm, INTERCEPT_CR8_WRITE);\n\n\tset_dr_intercepts(svm);\n\n\tset_exception_intercept(svm, PF_VECTOR);\n\tset_exception_intercept(svm, UD_VECTOR);\n\tset_exception_intercept(svm, MC_VECTOR);\n\tset_exception_intercept(svm, AC_VECTOR);\n\n\tset_intercept(svm, INTERCEPT_INTR);\n\tset_intercept(svm, INTERCEPT_NMI);\n\tset_intercept(svm, INTERCEPT_SMI);\n\tset_intercept(svm, INTERCEPT_SELECTIVE_CR0);\n\tset_intercept(svm, INTERCEPT_RDPMC);\n\tset_intercept(svm, INTERCEPT_CPUID);\n\tset_intercept(svm, INTERCEPT_INVD);\n\tset_intercept(svm, INTERCEPT_HLT);\n\tset_intercept(svm, INTERCEPT_INVLPG);\n\tset_intercept(svm, INTERCEPT_INVLPGA);\n\tset_intercept(svm, INTERCEPT_IOIO_PROT);\n\tset_intercept(svm, INTERCEPT_MSR_PROT);\n\tset_intercept(svm, INTERCEPT_TASK_SWITCH);\n\tset_intercept(svm, INTERCEPT_SHUTDOWN);\n\tset_intercept(svm, INTERCEPT_VMRUN);\n\tset_intercept(svm, INTERCEPT_VMMCALL);\n\tset_intercept(svm, INTERCEPT_VMLOAD);\n\tset_intercept(svm, INTERCEPT_VMSAVE);\n\tset_intercept(svm, INTERCEPT_STGI);\n\tset_intercept(svm, INTERCEPT_CLGI);\n\tset_intercept(svm, INTERCEPT_SKINIT);\n\tset_intercept(svm, INTERCEPT_WBINVD);\n\tset_intercept(svm, INTERCEPT_MONITOR);\n\tset_intercept(svm, INTERCEPT_MWAIT);\n\tset_intercept(svm, INTERCEPT_XSETBV);\n\n\tcontrol->iopm_base_pa = iopm_base;\n\tcontrol->msrpm_base_pa = __pa(svm->msrpm);\n\tcontrol->int_ctl = V_INTR_MASKING_MASK;\n\n\tinit_seg(&save->es);\n\tinit_seg(&save->ss);\n\tinit_seg(&save->ds);\n\tinit_seg(&save->fs);\n\tinit_seg(&save->gs);\n\n\tsave->cs.selector = 0xf000;\n\tsave->cs.base = 0xffff0000;\n\t/* Executable/Readable Code Segment */\n\tsave->cs.attrib = SVM_SELECTOR_READ_MASK | SVM_SELECTOR_P_MASK |\n\t\tSVM_SELECTOR_S_MASK | SVM_SELECTOR_CODE_MASK;\n\tsave->cs.limit = 0xffff;\n\n\tsave->gdtr.limit = 0xffff;\n\tsave->idtr.limit = 0xffff;\n\n\tinit_sys_seg(&save->ldtr, SEG_TYPE_LDT);\n\tinit_sys_seg(&save->tr, SEG_TYPE_BUSY_TSS16);\n\n\tsvm_set_efer(&svm->vcpu, 0);\n\tsave->dr6 = 0xffff0ff0;\n\tkvm_set_rflags(&svm->vcpu, 2);\n\tsave->rip = 0x0000fff0;\n\tsvm->vcpu.arch.regs[VCPU_REGS_RIP] = save->rip;\n\n\t/*\n\t * svm_set_cr0() sets PG and WP and clears NW and CD on save->cr0.\n\t * It also updates the guest-visible cr0 value.\n\t */\n\tsvm_set_cr0(&svm->vcpu, X86_CR0_NW | X86_CR0_CD | X86_CR0_ET);\n\tkvm_mmu_reset_context(&svm->vcpu);\n\n\tsave->cr4 = X86_CR4_PAE;\n\t/* rdx = ?? */\n\n\tif (npt_enabled) {\n\t\t/* Setup VMCB for Nested Paging */\n\t\tcontrol->nested_ctl = 1;\n\t\tclr_intercept(svm, INTERCEPT_INVLPG);\n\t\tclr_exception_intercept(svm, PF_VECTOR);\n\t\tclr_cr_intercept(svm, INTERCEPT_CR3_READ);\n\t\tclr_cr_intercept(svm, INTERCEPT_CR3_WRITE);\n\t\tsave->g_pat = svm->vcpu.arch.pat;\n\t\tsave->cr3 = 0;\n\t\tsave->cr4 = 0;\n\t}\n\tsvm->asid_generation = 0;\n\n\tsvm->nested.vmcb = 0;\n\tsvm->vcpu.arch.hflags = 0;\n\n\tif (boot_cpu_has(X86_FEATURE_PAUSEFILTER)) {\n\t\tcontrol->pause_filter_count = 3000;\n\t\tset_intercept(svm, INTERCEPT_PAUSE);\n\t}\n\n\tmark_all_dirty(svm->vmcb);\n\n\tenable_gif(svm);\n}",
        "func": "static void init_vmcb(struct vcpu_svm *svm)\n{\n\tstruct vmcb_control_area *control = &svm->vmcb->control;\n\tstruct vmcb_save_area *save = &svm->vmcb->save;\n\n\tsvm->vcpu.fpu_active = 1;\n\tsvm->vcpu.arch.hflags = 0;\n\n\tset_cr_intercept(svm, INTERCEPT_CR0_READ);\n\tset_cr_intercept(svm, INTERCEPT_CR3_READ);\n\tset_cr_intercept(svm, INTERCEPT_CR4_READ);\n\tset_cr_intercept(svm, INTERCEPT_CR0_WRITE);\n\tset_cr_intercept(svm, INTERCEPT_CR3_WRITE);\n\tset_cr_intercept(svm, INTERCEPT_CR4_WRITE);\n\tset_cr_intercept(svm, INTERCEPT_CR8_WRITE);\n\n\tset_dr_intercepts(svm);\n\n\tset_exception_intercept(svm, PF_VECTOR);\n\tset_exception_intercept(svm, UD_VECTOR);\n\tset_exception_intercept(svm, MC_VECTOR);\n\tset_exception_intercept(svm, AC_VECTOR);\n\tset_exception_intercept(svm, DB_VECTOR);\n\n\tset_intercept(svm, INTERCEPT_INTR);\n\tset_intercept(svm, INTERCEPT_NMI);\n\tset_intercept(svm, INTERCEPT_SMI);\n\tset_intercept(svm, INTERCEPT_SELECTIVE_CR0);\n\tset_intercept(svm, INTERCEPT_RDPMC);\n\tset_intercept(svm, INTERCEPT_CPUID);\n\tset_intercept(svm, INTERCEPT_INVD);\n\tset_intercept(svm, INTERCEPT_HLT);\n\tset_intercept(svm, INTERCEPT_INVLPG);\n\tset_intercept(svm, INTERCEPT_INVLPGA);\n\tset_intercept(svm, INTERCEPT_IOIO_PROT);\n\tset_intercept(svm, INTERCEPT_MSR_PROT);\n\tset_intercept(svm, INTERCEPT_TASK_SWITCH);\n\tset_intercept(svm, INTERCEPT_SHUTDOWN);\n\tset_intercept(svm, INTERCEPT_VMRUN);\n\tset_intercept(svm, INTERCEPT_VMMCALL);\n\tset_intercept(svm, INTERCEPT_VMLOAD);\n\tset_intercept(svm, INTERCEPT_VMSAVE);\n\tset_intercept(svm, INTERCEPT_STGI);\n\tset_intercept(svm, INTERCEPT_CLGI);\n\tset_intercept(svm, INTERCEPT_SKINIT);\n\tset_intercept(svm, INTERCEPT_WBINVD);\n\tset_intercept(svm, INTERCEPT_MONITOR);\n\tset_intercept(svm, INTERCEPT_MWAIT);\n\tset_intercept(svm, INTERCEPT_XSETBV);\n\n\tcontrol->iopm_base_pa = iopm_base;\n\tcontrol->msrpm_base_pa = __pa(svm->msrpm);\n\tcontrol->int_ctl = V_INTR_MASKING_MASK;\n\n\tinit_seg(&save->es);\n\tinit_seg(&save->ss);\n\tinit_seg(&save->ds);\n\tinit_seg(&save->fs);\n\tinit_seg(&save->gs);\n\n\tsave->cs.selector = 0xf000;\n\tsave->cs.base = 0xffff0000;\n\t/* Executable/Readable Code Segment */\n\tsave->cs.attrib = SVM_SELECTOR_READ_MASK | SVM_SELECTOR_P_MASK |\n\t\tSVM_SELECTOR_S_MASK | SVM_SELECTOR_CODE_MASK;\n\tsave->cs.limit = 0xffff;\n\n\tsave->gdtr.limit = 0xffff;\n\tsave->idtr.limit = 0xffff;\n\n\tinit_sys_seg(&save->ldtr, SEG_TYPE_LDT);\n\tinit_sys_seg(&save->tr, SEG_TYPE_BUSY_TSS16);\n\n\tsvm_set_efer(&svm->vcpu, 0);\n\tsave->dr6 = 0xffff0ff0;\n\tkvm_set_rflags(&svm->vcpu, 2);\n\tsave->rip = 0x0000fff0;\n\tsvm->vcpu.arch.regs[VCPU_REGS_RIP] = save->rip;\n\n\t/*\n\t * svm_set_cr0() sets PG and WP and clears NW and CD on save->cr0.\n\t * It also updates the guest-visible cr0 value.\n\t */\n\tsvm_set_cr0(&svm->vcpu, X86_CR0_NW | X86_CR0_CD | X86_CR0_ET);\n\tkvm_mmu_reset_context(&svm->vcpu);\n\n\tsave->cr4 = X86_CR4_PAE;\n\t/* rdx = ?? */\n\n\tif (npt_enabled) {\n\t\t/* Setup VMCB for Nested Paging */\n\t\tcontrol->nested_ctl = 1;\n\t\tclr_intercept(svm, INTERCEPT_INVLPG);\n\t\tclr_exception_intercept(svm, PF_VECTOR);\n\t\tclr_cr_intercept(svm, INTERCEPT_CR3_READ);\n\t\tclr_cr_intercept(svm, INTERCEPT_CR3_WRITE);\n\t\tsave->g_pat = svm->vcpu.arch.pat;\n\t\tsave->cr3 = 0;\n\t\tsave->cr4 = 0;\n\t}\n\tsvm->asid_generation = 0;\n\n\tsvm->nested.vmcb = 0;\n\tsvm->vcpu.arch.hflags = 0;\n\n\tif (boot_cpu_has(X86_FEATURE_PAUSEFILTER)) {\n\t\tcontrol->pause_filter_count = 3000;\n\t\tset_intercept(svm, INTERCEPT_PAUSE);\n\t}\n\n\tmark_all_dirty(svm->vmcb);\n\n\tenable_gif(svm);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -20,6 +20,7 @@\n \tset_exception_intercept(svm, UD_VECTOR);\n \tset_exception_intercept(svm, MC_VECTOR);\n \tset_exception_intercept(svm, AC_VECTOR);\n+\tset_exception_intercept(svm, DB_VECTOR);\n \n \tset_intercept(svm, INTERCEPT_INTR);\n \tset_intercept(svm, INTERCEPT_NMI);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tset_exception_intercept(svm, DB_VECTOR);"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-5312",
        "func_name": "GNOME/libxml2/xmlStringLenDecodeEntities",
        "description": "The xmlStringLenDecodeEntities function in parser.c in libxml2 before 2.9.3 does not properly prevent entity expansion, which allows context-dependent attackers to cause a denial of service (CPU consumption) via crafted XML data, a different vulnerability than CVE-2014-3660.",
        "git_url": "https://github.com/GNOME/libxml2/commit/69030714cde66d525a8884bda01b9e8f0abf8e1e",
        "commit_title": "CVE-2015-5312 Another entity expansion issue",
        "commit_text": " For https://bugzilla.gnome.org/show_bug.cgi?id=756733 It is one case where the code in place to detect entities expansions failed to exit when the situation was detected, leading to DoS Problem reported by Kostya Serebryany @ Google Patch provided by David Drysdale @ Google",
        "func_before": "xmlChar *\nxmlStringLenDecodeEntities(xmlParserCtxtPtr ctxt, const xmlChar *str, int len,\n\t\t      int what, xmlChar end, xmlChar  end2, xmlChar end3) {\n    xmlChar *buffer = NULL;\n    size_t buffer_size = 0;\n    size_t nbchars = 0;\n\n    xmlChar *current = NULL;\n    xmlChar *rep = NULL;\n    const xmlChar *last;\n    xmlEntityPtr ent;\n    int c,l;\n\n    if ((ctxt == NULL) || (str == NULL) || (len < 0))\n\treturn(NULL);\n    last = str + len;\n\n    if (((ctxt->depth > 40) &&\n         ((ctxt->options & XML_PARSE_HUGE) == 0)) ||\n\t(ctxt->depth > 1024)) {\n\txmlFatalErr(ctxt, XML_ERR_ENTITY_LOOP, NULL);\n\treturn(NULL);\n    }\n\n    /*\n     * allocate a translation buffer.\n     */\n    buffer_size = XML_PARSER_BIG_BUFFER_SIZE;\n    buffer = (xmlChar *) xmlMallocAtomic(buffer_size);\n    if (buffer == NULL) goto mem_error;\n\n    /*\n     * OK loop until we reach one of the ending char or a size limit.\n     * we are operating on already parsed values.\n     */\n    if (str < last)\n\tc = CUR_SCHAR(str, l);\n    else\n        c = 0;\n    while ((c != 0) && (c != end) && /* non input consuming loop */\n\t   (c != end2) && (c != end3)) {\n\n\tif (c == 0) break;\n        if ((c == '&') && (str[1] == '#')) {\n\t    int val = xmlParseStringCharRef(ctxt, &str);\n\t    if (val != 0) {\n\t\tCOPY_BUF(0,buffer,nbchars,val);\n\t    }\n\t    if (nbchars + XML_PARSER_BUFFER_SIZE > buffer_size) {\n\t        growBuffer(buffer, XML_PARSER_BUFFER_SIZE);\n\t    }\n\t} else if ((c == '&') && (what & XML_SUBSTITUTE_REF)) {\n\t    if (xmlParserDebugEntities)\n\t\txmlGenericError(xmlGenericErrorContext,\n\t\t\t\"String decoding Entity Reference: %.30s\\n\",\n\t\t\tstr);\n\t    ent = xmlParseStringEntityRef(ctxt, &str);\n\t    if ((ctxt->lastError.code == XML_ERR_ENTITY_LOOP) ||\n\t        (ctxt->lastError.code == XML_ERR_INTERNAL_ERROR))\n\t        goto int_error;\n\t    xmlParserEntityCheck(ctxt, 0, ent, 0);\n\t    if (ent != NULL)\n\t        ctxt->nbentities += ent->checked / 2;\n\t    if ((ent != NULL) &&\n\t\t(ent->etype == XML_INTERNAL_PREDEFINED_ENTITY)) {\n\t\tif (ent->content != NULL) {\n\t\t    COPY_BUF(0,buffer,nbchars,ent->content[0]);\n\t\t    if (nbchars + XML_PARSER_BUFFER_SIZE > buffer_size) {\n\t\t\tgrowBuffer(buffer, XML_PARSER_BUFFER_SIZE);\n\t\t    }\n\t\t} else {\n\t\t    xmlFatalErrMsg(ctxt, XML_ERR_INTERNAL_ERROR,\n\t\t\t    \"predefined entity has no content\\n\");\n\t\t}\n\t    } else if ((ent != NULL) && (ent->content != NULL)) {\n\t\tctxt->depth++;\n\t\trep = xmlStringDecodeEntities(ctxt, ent->content, what,\n\t\t\t                      0, 0, 0);\n\t\tctxt->depth--;\n\n\t\tif (rep != NULL) {\n\t\t    current = rep;\n\t\t    while (*current != 0) { /* non input consuming loop */\n\t\t\tbuffer[nbchars++] = *current++;\n\t\t\tif (nbchars + XML_PARSER_BUFFER_SIZE > buffer_size) {\n\t\t\t    if (xmlParserEntityCheck(ctxt, nbchars, ent, 0))\n\t\t\t\tgoto int_error;\n\t\t\t    growBuffer(buffer, XML_PARSER_BUFFER_SIZE);\n\t\t\t}\n\t\t    }\n\t\t    xmlFree(rep);\n\t\t    rep = NULL;\n\t\t}\n\t    } else if (ent != NULL) {\n\t\tint i = xmlStrlen(ent->name);\n\t\tconst xmlChar *cur = ent->name;\n\n\t\tbuffer[nbchars++] = '&';\n\t\tif (nbchars + i + XML_PARSER_BUFFER_SIZE > buffer_size) {\n\t\t    growBuffer(buffer, i + XML_PARSER_BUFFER_SIZE);\n\t\t}\n\t\tfor (;i > 0;i--)\n\t\t    buffer[nbchars++] = *cur++;\n\t\tbuffer[nbchars++] = ';';\n\t    }\n\t} else if (c == '%' && (what & XML_SUBSTITUTE_PEREF)) {\n\t    if (xmlParserDebugEntities)\n\t\txmlGenericError(xmlGenericErrorContext,\n\t\t\t\"String decoding PE Reference: %.30s\\n\", str);\n\t    ent = xmlParseStringPEReference(ctxt, &str);\n\t    if (ctxt->lastError.code == XML_ERR_ENTITY_LOOP)\n\t        goto int_error;\n\t    xmlParserEntityCheck(ctxt, 0, ent, 0);\n\t    if (ent != NULL)\n\t        ctxt->nbentities += ent->checked / 2;\n\t    if (ent != NULL) {\n                if (ent->content == NULL) {\n\t\t    xmlLoadEntityContent(ctxt, ent);\n\t\t}\n\t\tctxt->depth++;\n\t\trep = xmlStringDecodeEntities(ctxt, ent->content, what,\n\t\t\t                      0, 0, 0);\n\t\tctxt->depth--;\n\t\tif (rep != NULL) {\n\t\t    current = rep;\n\t\t    while (*current != 0) { /* non input consuming loop */\n\t\t\tbuffer[nbchars++] = *current++;\n\t\t\tif (nbchars + XML_PARSER_BUFFER_SIZE > buffer_size) {\n\t\t\t    if (xmlParserEntityCheck(ctxt, nbchars, ent, 0))\n\t\t\t        goto int_error;\n\t\t\t    growBuffer(buffer, XML_PARSER_BUFFER_SIZE);\n\t\t\t}\n\t\t    }\n\t\t    xmlFree(rep);\n\t\t    rep = NULL;\n\t\t}\n\t    }\n\t} else {\n\t    COPY_BUF(l,buffer,nbchars,c);\n\t    str += l;\n\t    if (nbchars + XML_PARSER_BUFFER_SIZE > buffer_size) {\n\t        growBuffer(buffer, XML_PARSER_BUFFER_SIZE);\n\t    }\n\t}\n\tif (str < last)\n\t    c = CUR_SCHAR(str, l);\n\telse\n\t    c = 0;\n    }\n    buffer[nbchars] = 0;\n    return(buffer);\n\nmem_error:\n    xmlErrMemory(ctxt, NULL);\nint_error:\n    if (rep != NULL)\n        xmlFree(rep);\n    if (buffer != NULL)\n        xmlFree(buffer);\n    return(NULL);\n}",
        "func": "xmlChar *\nxmlStringLenDecodeEntities(xmlParserCtxtPtr ctxt, const xmlChar *str, int len,\n\t\t      int what, xmlChar end, xmlChar  end2, xmlChar end3) {\n    xmlChar *buffer = NULL;\n    size_t buffer_size = 0;\n    size_t nbchars = 0;\n\n    xmlChar *current = NULL;\n    xmlChar *rep = NULL;\n    const xmlChar *last;\n    xmlEntityPtr ent;\n    int c,l;\n\n    if ((ctxt == NULL) || (str == NULL) || (len < 0))\n\treturn(NULL);\n    last = str + len;\n\n    if (((ctxt->depth > 40) &&\n         ((ctxt->options & XML_PARSE_HUGE) == 0)) ||\n\t(ctxt->depth > 1024)) {\n\txmlFatalErr(ctxt, XML_ERR_ENTITY_LOOP, NULL);\n\treturn(NULL);\n    }\n\n    /*\n     * allocate a translation buffer.\n     */\n    buffer_size = XML_PARSER_BIG_BUFFER_SIZE;\n    buffer = (xmlChar *) xmlMallocAtomic(buffer_size);\n    if (buffer == NULL) goto mem_error;\n\n    /*\n     * OK loop until we reach one of the ending char or a size limit.\n     * we are operating on already parsed values.\n     */\n    if (str < last)\n\tc = CUR_SCHAR(str, l);\n    else\n        c = 0;\n    while ((c != 0) && (c != end) && /* non input consuming loop */\n\t   (c != end2) && (c != end3)) {\n\n\tif (c == 0) break;\n        if ((c == '&') && (str[1] == '#')) {\n\t    int val = xmlParseStringCharRef(ctxt, &str);\n\t    if (val != 0) {\n\t\tCOPY_BUF(0,buffer,nbchars,val);\n\t    }\n\t    if (nbchars + XML_PARSER_BUFFER_SIZE > buffer_size) {\n\t        growBuffer(buffer, XML_PARSER_BUFFER_SIZE);\n\t    }\n\t} else if ((c == '&') && (what & XML_SUBSTITUTE_REF)) {\n\t    if (xmlParserDebugEntities)\n\t\txmlGenericError(xmlGenericErrorContext,\n\t\t\t\"String decoding Entity Reference: %.30s\\n\",\n\t\t\tstr);\n\t    ent = xmlParseStringEntityRef(ctxt, &str);\n\t    if ((ctxt->lastError.code == XML_ERR_ENTITY_LOOP) ||\n\t        (ctxt->lastError.code == XML_ERR_INTERNAL_ERROR))\n\t        goto int_error;\n\t    xmlParserEntityCheck(ctxt, 0, ent, 0);\n\t    if (ent != NULL)\n\t        ctxt->nbentities += ent->checked / 2;\n\t    if ((ent != NULL) &&\n\t\t(ent->etype == XML_INTERNAL_PREDEFINED_ENTITY)) {\n\t\tif (ent->content != NULL) {\n\t\t    COPY_BUF(0,buffer,nbchars,ent->content[0]);\n\t\t    if (nbchars + XML_PARSER_BUFFER_SIZE > buffer_size) {\n\t\t\tgrowBuffer(buffer, XML_PARSER_BUFFER_SIZE);\n\t\t    }\n\t\t} else {\n\t\t    xmlFatalErrMsg(ctxt, XML_ERR_INTERNAL_ERROR,\n\t\t\t    \"predefined entity has no content\\n\");\n\t\t}\n\t    } else if ((ent != NULL) && (ent->content != NULL)) {\n\t\tctxt->depth++;\n\t\trep = xmlStringDecodeEntities(ctxt, ent->content, what,\n\t\t\t                      0, 0, 0);\n\t\tctxt->depth--;\n\n\t\tif ((ctxt->lastError.code == XML_ERR_ENTITY_LOOP) ||\n\t\t    (ctxt->lastError.code == XML_ERR_INTERNAL_ERROR))\n\t\t    goto int_error;\n\n\t\tif (rep != NULL) {\n\t\t    current = rep;\n\t\t    while (*current != 0) { /* non input consuming loop */\n\t\t\tbuffer[nbchars++] = *current++;\n\t\t\tif (nbchars + XML_PARSER_BUFFER_SIZE > buffer_size) {\n\t\t\t    if (xmlParserEntityCheck(ctxt, nbchars, ent, 0))\n\t\t\t\tgoto int_error;\n\t\t\t    growBuffer(buffer, XML_PARSER_BUFFER_SIZE);\n\t\t\t}\n\t\t    }\n\t\t    xmlFree(rep);\n\t\t    rep = NULL;\n\t\t}\n\t    } else if (ent != NULL) {\n\t\tint i = xmlStrlen(ent->name);\n\t\tconst xmlChar *cur = ent->name;\n\n\t\tbuffer[nbchars++] = '&';\n\t\tif (nbchars + i + XML_PARSER_BUFFER_SIZE > buffer_size) {\n\t\t    growBuffer(buffer, i + XML_PARSER_BUFFER_SIZE);\n\t\t}\n\t\tfor (;i > 0;i--)\n\t\t    buffer[nbchars++] = *cur++;\n\t\tbuffer[nbchars++] = ';';\n\t    }\n\t} else if (c == '%' && (what & XML_SUBSTITUTE_PEREF)) {\n\t    if (xmlParserDebugEntities)\n\t\txmlGenericError(xmlGenericErrorContext,\n\t\t\t\"String decoding PE Reference: %.30s\\n\", str);\n\t    ent = xmlParseStringPEReference(ctxt, &str);\n\t    if (ctxt->lastError.code == XML_ERR_ENTITY_LOOP)\n\t        goto int_error;\n\t    xmlParserEntityCheck(ctxt, 0, ent, 0);\n\t    if (ent != NULL)\n\t        ctxt->nbentities += ent->checked / 2;\n\t    if (ent != NULL) {\n                if (ent->content == NULL) {\n\t\t    xmlLoadEntityContent(ctxt, ent);\n\t\t}\n\t\tctxt->depth++;\n\t\trep = xmlStringDecodeEntities(ctxt, ent->content, what,\n\t\t\t                      0, 0, 0);\n\t\tctxt->depth--;\n\t\tif (rep != NULL) {\n\t\t    current = rep;\n\t\t    while (*current != 0) { /* non input consuming loop */\n\t\t\tbuffer[nbchars++] = *current++;\n\t\t\tif (nbchars + XML_PARSER_BUFFER_SIZE > buffer_size) {\n\t\t\t    if (xmlParserEntityCheck(ctxt, nbchars, ent, 0))\n\t\t\t        goto int_error;\n\t\t\t    growBuffer(buffer, XML_PARSER_BUFFER_SIZE);\n\t\t\t}\n\t\t    }\n\t\t    xmlFree(rep);\n\t\t    rep = NULL;\n\t\t}\n\t    }\n\t} else {\n\t    COPY_BUF(l,buffer,nbchars,c);\n\t    str += l;\n\t    if (nbchars + XML_PARSER_BUFFER_SIZE > buffer_size) {\n\t        growBuffer(buffer, XML_PARSER_BUFFER_SIZE);\n\t    }\n\t}\n\tif (str < last)\n\t    c = CUR_SCHAR(str, l);\n\telse\n\t    c = 0;\n    }\n    buffer[nbchars] = 0;\n    return(buffer);\n\nmem_error:\n    xmlErrMemory(ctxt, NULL);\nint_error:\n    if (rep != NULL)\n        xmlFree(rep);\n    if (buffer != NULL)\n        xmlFree(buffer);\n    return(NULL);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -77,6 +77,10 @@\n \t\trep = xmlStringDecodeEntities(ctxt, ent->content, what,\n \t\t\t                      0, 0, 0);\n \t\tctxt->depth--;\n+\n+\t\tif ((ctxt->lastError.code == XML_ERR_ENTITY_LOOP) ||\n+\t\t    (ctxt->lastError.code == XML_ERR_INTERNAL_ERROR))\n+\t\t    goto int_error;\n \n \t\tif (rep != NULL) {\n \t\t    current = rep;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "\t\tif ((ctxt->lastError.code == XML_ERR_ENTITY_LOOP) ||",
                "\t\t    (ctxt->lastError.code == XML_ERR_INTERNAL_ERROR))",
                "\t\t    goto int_error;"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-8341",
        "func_name": "xen-project/xen/domcreate_complete",
        "description": "The libxl toolstack library in Xen 4.1.x through 4.6.x does not properly release mappings of files used as kernels and initial ramdisks when managing multiple domains in the same process, which allows attackers to cause a denial of service (memory and disk consumption) by starting domains.",
        "git_url": "https://github.com/xen-project/xen/commit/40412e3c99722229f1ec93cd95fc8486d778f5df",
        "commit_title": "libxl: Fix bootloader-related virtual memory leak on pv build failure",
        "commit_text": " The bootloader may call libxl__file_reference_map(), which mmap's the pv_kernel and pv_ramdisk into process memory.  This was only unmapped, however, on the success path of libxl__build_pv().  If there were a failure anywhere between libxl_bootloader.c:parse_bootloader_result() and the end of libxl__build_pv(), the calls to libxl__file_reference_unmap() would be skipped, leaking the mapped virtual memory.  Ideally this would be fixed by adding the unmap calls to the destruction path for libxl__domain_build_state.  Unfortunately the lifetime of the libxl__domain_build_state is opaque, and it doesn't have a proper destruction path.  But, the only thing in it that isn't from the gc are these bootloader references, and they are only ever set for one libxl__domain_build_state, the one which is libxl__domain_create_state.build_state.  So we can clean up in the exit path from libxl__domain_create_*, which always comes through domcreate_complete.  Remove the now-redundant unmaps in libxl__build_pv's success path.  This is XSA-160. ",
        "func_before": "static void domcreate_complete(libxl__egc *egc,\n                               libxl__domain_create_state *dcs,\n                               int rc)\n{\n    STATE_AO_GC(dcs->ao);\n    libxl_domain_config *const d_config = dcs->guest_config;\n    libxl_domain_config *d_config_saved = &dcs->guest_config_saved;\n\n    if (!rc && d_config->b_info.exec_ssidref)\n        rc = xc_flask_relabel_domain(CTX->xch, dcs->guest_domid, d_config->b_info.exec_ssidref);\n\n    bool retain_domain = !rc || rc == ERROR_ABORTED;\n\n    if (retain_domain) {\n        libxl__domain_userdata_lock *lock;\n\n        /* Note that we hold CTX lock at this point so only need to\n         * take data store lock\n         */\n        lock = libxl__lock_domain_userdata(gc, dcs->guest_domid);\n        if (!lock) {\n            rc = ERROR_LOCK_FAIL;\n        } else {\n            libxl__update_domain_configuration(gc, d_config_saved, d_config);\n            int cfg_rc = libxl__set_domain_configuration\n                (gc, dcs->guest_domid, d_config_saved);\n            if (!rc)\n                rc = cfg_rc;\n            libxl__unlock_domain_userdata(lock);\n        }\n    }\n\n    libxl_domain_config_dispose(d_config_saved);\n\n    if (!retain_domain) {\n        if (dcs->guest_domid > 0) {\n            dcs->dds.ao = ao;\n            dcs->dds.domid = dcs->guest_domid;\n            dcs->dds.callback = domcreate_destruction_cb;\n            libxl__domain_destroy(egc, &dcs->dds);\n            return;\n        }\n        dcs->guest_domid = -1;\n    }\n    dcs->callback(egc, dcs, rc, dcs->guest_domid);\n}",
        "func": "static void domcreate_complete(libxl__egc *egc,\n                               libxl__domain_create_state *dcs,\n                               int rc)\n{\n    STATE_AO_GC(dcs->ao);\n    libxl_domain_config *const d_config = dcs->guest_config;\n    libxl_domain_config *d_config_saved = &dcs->guest_config_saved;\n\n    libxl__file_reference_unmap(&dcs->build_state.pv_kernel);\n    libxl__file_reference_unmap(&dcs->build_state.pv_ramdisk);\n\n    if (!rc && d_config->b_info.exec_ssidref)\n        rc = xc_flask_relabel_domain(CTX->xch, dcs->guest_domid, d_config->b_info.exec_ssidref);\n\n    bool retain_domain = !rc || rc == ERROR_ABORTED;\n\n    if (retain_domain) {\n        libxl__domain_userdata_lock *lock;\n\n        /* Note that we hold CTX lock at this point so only need to\n         * take data store lock\n         */\n        lock = libxl__lock_domain_userdata(gc, dcs->guest_domid);\n        if (!lock) {\n            rc = ERROR_LOCK_FAIL;\n        } else {\n            libxl__update_domain_configuration(gc, d_config_saved, d_config);\n            int cfg_rc = libxl__set_domain_configuration\n                (gc, dcs->guest_domid, d_config_saved);\n            if (!rc)\n                rc = cfg_rc;\n            libxl__unlock_domain_userdata(lock);\n        }\n    }\n\n    libxl_domain_config_dispose(d_config_saved);\n\n    if (!retain_domain) {\n        if (dcs->guest_domid > 0) {\n            dcs->dds.ao = ao;\n            dcs->dds.domid = dcs->guest_domid;\n            dcs->dds.callback = domcreate_destruction_cb;\n            libxl__domain_destroy(egc, &dcs->dds);\n            return;\n        }\n        dcs->guest_domid = -1;\n    }\n    dcs->callback(egc, dcs, rc, dcs->guest_domid);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,6 +5,9 @@\n     STATE_AO_GC(dcs->ao);\n     libxl_domain_config *const d_config = dcs->guest_config;\n     libxl_domain_config *d_config_saved = &dcs->guest_config_saved;\n+\n+    libxl__file_reference_unmap(&dcs->build_state.pv_kernel);\n+    libxl__file_reference_unmap(&dcs->build_state.pv_ramdisk);\n \n     if (!rc && d_config->b_info.exec_ssidref)\n         rc = xc_flask_relabel_domain(CTX->xch, dcs->guest_domid, d_config->b_info.exec_ssidref);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "    libxl__file_reference_unmap(&dcs->build_state.pv_kernel);",
                "    libxl__file_reference_unmap(&dcs->build_state.pv_ramdisk);"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-8341",
        "func_name": "xen-project/xen/libxl__build_pv",
        "description": "The libxl toolstack library in Xen 4.1.x through 4.6.x does not properly release mappings of files used as kernels and initial ramdisks when managing multiple domains in the same process, which allows attackers to cause a denial of service (memory and disk consumption) by starting domains.",
        "git_url": "https://github.com/xen-project/xen/commit/40412e3c99722229f1ec93cd95fc8486d778f5df",
        "commit_title": "libxl: Fix bootloader-related virtual memory leak on pv build failure",
        "commit_text": " The bootloader may call libxl__file_reference_map(), which mmap's the pv_kernel and pv_ramdisk into process memory.  This was only unmapped, however, on the success path of libxl__build_pv().  If there were a failure anywhere between libxl_bootloader.c:parse_bootloader_result() and the end of libxl__build_pv(), the calls to libxl__file_reference_unmap() would be skipped, leaking the mapped virtual memory.  Ideally this would be fixed by adding the unmap calls to the destruction path for libxl__domain_build_state.  Unfortunately the lifetime of the libxl__domain_build_state is opaque, and it doesn't have a proper destruction path.  But, the only thing in it that isn't from the gc are these bootloader references, and they are only ever set for one libxl__domain_build_state, the one which is libxl__domain_create_state.build_state.  So we can clean up in the exit path from libxl__domain_create_*, which always comes through domcreate_complete.  Remove the now-redundant unmaps in libxl__build_pv's success path.  This is XSA-160. ",
        "func_before": "int libxl__build_pv(libxl__gc *gc, uint32_t domid,\n             libxl_domain_build_info *info, libxl__domain_build_state *state)\n{\n    libxl_ctx *ctx = libxl__gc_owner(gc);\n    struct xc_dom_image *dom;\n    int ret;\n    int flags = 0;\n\n    xc_dom_loginit(ctx->xch);\n\n    dom = xc_dom_allocate(ctx->xch, state->pv_cmdline, info->u.pv.features);\n    if (!dom) {\n        LOGE(ERROR, \"xc_dom_allocate failed\");\n        return ERROR_FAIL;\n    }\n\n    dom->pvh_enabled = state->pvh_enabled;\n    dom->container_type = XC_DOM_PV_CONTAINER;\n\n    LOG(DEBUG, \"pv kernel mapped %d path %s\", state->pv_kernel.mapped, state->pv_kernel.path);\n\n    if (state->pv_kernel.mapped) {\n        ret = xc_dom_kernel_mem(dom,\n                                state->pv_kernel.data,\n                                state->pv_kernel.size);\n        if ( ret != 0) {\n            LOGE(ERROR, \"xc_dom_kernel_mem failed\");\n            goto out;\n        }\n    } else {\n        ret = xc_dom_kernel_file(dom, state->pv_kernel.path);\n        if ( ret != 0) {\n            LOGE(ERROR, \"xc_dom_kernel_file failed\");\n            goto out;\n        }\n    }\n\n    if ( state->pv_ramdisk.path && strlen(state->pv_ramdisk.path) ) {\n        if (state->pv_ramdisk.mapped) {\n            if ( (ret = xc_dom_ramdisk_mem(dom, state->pv_ramdisk.data, state->pv_ramdisk.size)) != 0 ) {\n                LOGE(ERROR, \"xc_dom_ramdisk_mem failed\");\n                goto out;\n            }\n        } else {\n            if ( (ret = xc_dom_ramdisk_file(dom, state->pv_ramdisk.path)) != 0 ) {\n                LOGE(ERROR, \"xc_dom_ramdisk_file failed\");\n                goto out;\n            }\n        }\n    }\n\n    dom->flags = flags;\n    dom->console_evtchn = state->console_port;\n    dom->console_domid = state->console_domid;\n    dom->xenstore_evtchn = state->store_port;\n    dom->xenstore_domid = state->store_domid;\n    dom->claim_enabled = libxl_defbool_val(info->claim_mode);\n\n    if (info->num_vnuma_nodes != 0) {\n        unsigned int i;\n\n        ret = libxl__vnuma_build_vmemrange_pv(gc, domid, info, state);\n        if (ret) {\n            LOGE(ERROR, \"cannot build vmemranges\");\n            goto out;\n        }\n        ret = libxl__vnuma_config_check(gc, info, state);\n        if (ret) goto out;\n\n        ret = set_vnuma_info(gc, domid, info, state);\n        if (ret) goto out;\n\n        dom->nr_vmemranges = state->num_vmemranges;\n        dom->vmemranges = xc_dom_malloc(dom, sizeof(*dom->vmemranges) *\n                                        dom->nr_vmemranges);\n\n        for (i = 0; i < dom->nr_vmemranges; i++) {\n            dom->vmemranges[i].start = state->vmemranges[i].start;\n            dom->vmemranges[i].end   = state->vmemranges[i].end;\n            dom->vmemranges[i].flags = state->vmemranges[i].flags;\n            dom->vmemranges[i].nid   = state->vmemranges[i].nid;\n        }\n\n        dom->nr_vnodes = info->num_vnuma_nodes;\n        dom->vnode_to_pnode = xc_dom_malloc(dom, sizeof(*dom->vnode_to_pnode) *\n                                            dom->nr_vnodes);\n        for (i = 0; i < info->num_vnuma_nodes; i++)\n            dom->vnode_to_pnode[i] = info->vnuma_nodes[i].pnode;\n    }\n\n    ret = libxl__build_dom(gc, domid, info, state, dom);\n    if (ret != 0)\n        goto out;\n\n    if (xc_dom_feature_translated(dom)) {\n        state->console_mfn = dom->console_pfn;\n        state->store_mfn = dom->xenstore_pfn;\n    } else {\n        state->console_mfn = xc_dom_p2m(dom, dom->console_pfn);\n        state->store_mfn = xc_dom_p2m(dom, dom->xenstore_pfn);\n    }\n\n    libxl__file_reference_unmap(&state->pv_kernel);\n    libxl__file_reference_unmap(&state->pv_ramdisk);\n\n    ret = 0;\nout:\n    xc_dom_release(dom);\n    return ret == 0 ? 0 : ERROR_FAIL;\n}",
        "func": "int libxl__build_pv(libxl__gc *gc, uint32_t domid,\n             libxl_domain_build_info *info, libxl__domain_build_state *state)\n{\n    libxl_ctx *ctx = libxl__gc_owner(gc);\n    struct xc_dom_image *dom;\n    int ret;\n    int flags = 0;\n\n    xc_dom_loginit(ctx->xch);\n\n    dom = xc_dom_allocate(ctx->xch, state->pv_cmdline, info->u.pv.features);\n    if (!dom) {\n        LOGE(ERROR, \"xc_dom_allocate failed\");\n        return ERROR_FAIL;\n    }\n\n    dom->pvh_enabled = state->pvh_enabled;\n    dom->container_type = XC_DOM_PV_CONTAINER;\n\n    LOG(DEBUG, \"pv kernel mapped %d path %s\", state->pv_kernel.mapped, state->pv_kernel.path);\n\n    if (state->pv_kernel.mapped) {\n        ret = xc_dom_kernel_mem(dom,\n                                state->pv_kernel.data,\n                                state->pv_kernel.size);\n        if ( ret != 0) {\n            LOGE(ERROR, \"xc_dom_kernel_mem failed\");\n            goto out;\n        }\n    } else {\n        ret = xc_dom_kernel_file(dom, state->pv_kernel.path);\n        if ( ret != 0) {\n            LOGE(ERROR, \"xc_dom_kernel_file failed\");\n            goto out;\n        }\n    }\n\n    if ( state->pv_ramdisk.path && strlen(state->pv_ramdisk.path) ) {\n        if (state->pv_ramdisk.mapped) {\n            if ( (ret = xc_dom_ramdisk_mem(dom, state->pv_ramdisk.data, state->pv_ramdisk.size)) != 0 ) {\n                LOGE(ERROR, \"xc_dom_ramdisk_mem failed\");\n                goto out;\n            }\n        } else {\n            if ( (ret = xc_dom_ramdisk_file(dom, state->pv_ramdisk.path)) != 0 ) {\n                LOGE(ERROR, \"xc_dom_ramdisk_file failed\");\n                goto out;\n            }\n        }\n    }\n\n    dom->flags = flags;\n    dom->console_evtchn = state->console_port;\n    dom->console_domid = state->console_domid;\n    dom->xenstore_evtchn = state->store_port;\n    dom->xenstore_domid = state->store_domid;\n    dom->claim_enabled = libxl_defbool_val(info->claim_mode);\n\n    if (info->num_vnuma_nodes != 0) {\n        unsigned int i;\n\n        ret = libxl__vnuma_build_vmemrange_pv(gc, domid, info, state);\n        if (ret) {\n            LOGE(ERROR, \"cannot build vmemranges\");\n            goto out;\n        }\n        ret = libxl__vnuma_config_check(gc, info, state);\n        if (ret) goto out;\n\n        ret = set_vnuma_info(gc, domid, info, state);\n        if (ret) goto out;\n\n        dom->nr_vmemranges = state->num_vmemranges;\n        dom->vmemranges = xc_dom_malloc(dom, sizeof(*dom->vmemranges) *\n                                        dom->nr_vmemranges);\n\n        for (i = 0; i < dom->nr_vmemranges; i++) {\n            dom->vmemranges[i].start = state->vmemranges[i].start;\n            dom->vmemranges[i].end   = state->vmemranges[i].end;\n            dom->vmemranges[i].flags = state->vmemranges[i].flags;\n            dom->vmemranges[i].nid   = state->vmemranges[i].nid;\n        }\n\n        dom->nr_vnodes = info->num_vnuma_nodes;\n        dom->vnode_to_pnode = xc_dom_malloc(dom, sizeof(*dom->vnode_to_pnode) *\n                                            dom->nr_vnodes);\n        for (i = 0; i < info->num_vnuma_nodes; i++)\n            dom->vnode_to_pnode[i] = info->vnuma_nodes[i].pnode;\n    }\n\n    ret = libxl__build_dom(gc, domid, info, state, dom);\n    if (ret != 0)\n        goto out;\n\n    if (xc_dom_feature_translated(dom)) {\n        state->console_mfn = dom->console_pfn;\n        state->store_mfn = dom->xenstore_pfn;\n    } else {\n        state->console_mfn = xc_dom_p2m(dom, dom->console_pfn);\n        state->store_mfn = xc_dom_p2m(dom, dom->xenstore_pfn);\n    }\n\n    ret = 0;\nout:\n    xc_dom_release(dom);\n    return ret == 0 ? 0 : ERROR_FAIL;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -100,9 +100,6 @@\n         state->store_mfn = xc_dom_p2m(dom, dom->xenstore_pfn);\n     }\n \n-    libxl__file_reference_unmap(&state->pv_kernel);\n-    libxl__file_reference_unmap(&state->pv_ramdisk);\n-\n     ret = 0;\n out:\n     xc_dom_release(dom);",
        "diff_line_info": {
            "deleted_lines": [
                "    libxl__file_reference_unmap(&state->pv_kernel);",
                "    libxl__file_reference_unmap(&state->pv_ramdisk);",
                ""
            ],
            "added_lines": []
        }
    },
    {
        "cve_id": "CVE-2015-7509",
        "func_name": "torvalds/linux/ext4_orphan_add",
        "description": "fs/ext4/namei.c in the Linux kernel before 3.7 allows physically proximate attackers to cause a denial of service (system crash) via a crafted no-journal filesystem, a related issue to CVE-2013-2015.",
        "git_url": "https://github.com/torvalds/linux/commit/c9b92530a723ac5ef8e352885a1862b18f31b2f5",
        "commit_title": "ext4: make orphan functions be no-op in no-journal mode",
        "commit_text": " Instead of checking whether the handle is valid, we check if journal is enabled. This avoids taking the s_orphan_lock mutex in all cases when there is no journal in use, including the error paths where ext4_orphan_del() is called with a handle set to NULL. ",
        "func_before": "int ext4_orphan_add(handle_t *handle, struct inode *inode)\n{\n\tstruct super_block *sb = inode->i_sb;\n\tstruct ext4_iloc iloc;\n\tint err = 0, rc;\n\n\tif (!ext4_handle_valid(handle))\n\t\treturn 0;\n\n\tmutex_lock(&EXT4_SB(sb)->s_orphan_lock);\n\tif (!list_empty(&EXT4_I(inode)->i_orphan))\n\t\tgoto out_unlock;\n\n\t/*\n\t * Orphan handling is only valid for files with data blocks\n\t * being truncated, or files being unlinked. Note that we either\n\t * hold i_mutex, or the inode can not be referenced from outside,\n\t * so i_nlink should not be bumped due to race\n\t */\n\tJ_ASSERT((S_ISREG(inode->i_mode) || S_ISDIR(inode->i_mode) ||\n\t\t  S_ISLNK(inode->i_mode)) || inode->i_nlink == 0);\n\n\tBUFFER_TRACE(EXT4_SB(sb)->s_sbh, \"get_write_access\");\n\terr = ext4_journal_get_write_access(handle, EXT4_SB(sb)->s_sbh);\n\tif (err)\n\t\tgoto out_unlock;\n\n\terr = ext4_reserve_inode_write(handle, inode, &iloc);\n\tif (err)\n\t\tgoto out_unlock;\n\t/*\n\t * Due to previous errors inode may be already a part of on-disk\n\t * orphan list. If so skip on-disk list modification.\n\t */\n\tif (NEXT_ORPHAN(inode) && NEXT_ORPHAN(inode) <=\n\t\t(le32_to_cpu(EXT4_SB(sb)->s_es->s_inodes_count)))\n\t\t\tgoto mem_insert;\n\n\t/* Insert this inode at the head of the on-disk orphan list... */\n\tNEXT_ORPHAN(inode) = le32_to_cpu(EXT4_SB(sb)->s_es->s_last_orphan);\n\tEXT4_SB(sb)->s_es->s_last_orphan = cpu_to_le32(inode->i_ino);\n\terr = ext4_handle_dirty_super(handle, sb);\n\trc = ext4_mark_iloc_dirty(handle, inode, &iloc);\n\tif (!err)\n\t\terr = rc;\n\n\t/* Only add to the head of the in-memory list if all the\n\t * previous operations succeeded.  If the orphan_add is going to\n\t * fail (possibly taking the journal offline), we can't risk\n\t * leaving the inode on the orphan list: stray orphan-list\n\t * entries can cause panics at unmount time.\n\t *\n\t * This is safe: on error we're going to ignore the orphan list\n\t * anyway on the next recovery. */\nmem_insert:\n\tif (!err)\n\t\tlist_add(&EXT4_I(inode)->i_orphan, &EXT4_SB(sb)->s_orphan);\n\n\tjbd_debug(4, \"superblock will point to %lu\\n\", inode->i_ino);\n\tjbd_debug(4, \"orphan inode %lu will point to %d\\n\",\n\t\t\tinode->i_ino, NEXT_ORPHAN(inode));\nout_unlock:\n\tmutex_unlock(&EXT4_SB(sb)->s_orphan_lock);\n\text4_std_error(inode->i_sb, err);\n\treturn err;\n}",
        "func": "int ext4_orphan_add(handle_t *handle, struct inode *inode)\n{\n\tstruct super_block *sb = inode->i_sb;\n\tstruct ext4_iloc iloc;\n\tint err = 0, rc;\n\n\tif (!EXT4_SB(sb)->s_journal)\n\t\treturn 0;\n\n\tmutex_lock(&EXT4_SB(sb)->s_orphan_lock);\n\tif (!list_empty(&EXT4_I(inode)->i_orphan))\n\t\tgoto out_unlock;\n\n\t/*\n\t * Orphan handling is only valid for files with data blocks\n\t * being truncated, or files being unlinked. Note that we either\n\t * hold i_mutex, or the inode can not be referenced from outside,\n\t * so i_nlink should not be bumped due to race\n\t */\n\tJ_ASSERT((S_ISREG(inode->i_mode) || S_ISDIR(inode->i_mode) ||\n\t\t  S_ISLNK(inode->i_mode)) || inode->i_nlink == 0);\n\n\tBUFFER_TRACE(EXT4_SB(sb)->s_sbh, \"get_write_access\");\n\terr = ext4_journal_get_write_access(handle, EXT4_SB(sb)->s_sbh);\n\tif (err)\n\t\tgoto out_unlock;\n\n\terr = ext4_reserve_inode_write(handle, inode, &iloc);\n\tif (err)\n\t\tgoto out_unlock;\n\t/*\n\t * Due to previous errors inode may be already a part of on-disk\n\t * orphan list. If so skip on-disk list modification.\n\t */\n\tif (NEXT_ORPHAN(inode) && NEXT_ORPHAN(inode) <=\n\t\t(le32_to_cpu(EXT4_SB(sb)->s_es->s_inodes_count)))\n\t\t\tgoto mem_insert;\n\n\t/* Insert this inode at the head of the on-disk orphan list... */\n\tNEXT_ORPHAN(inode) = le32_to_cpu(EXT4_SB(sb)->s_es->s_last_orphan);\n\tEXT4_SB(sb)->s_es->s_last_orphan = cpu_to_le32(inode->i_ino);\n\terr = ext4_handle_dirty_super(handle, sb);\n\trc = ext4_mark_iloc_dirty(handle, inode, &iloc);\n\tif (!err)\n\t\terr = rc;\n\n\t/* Only add to the head of the in-memory list if all the\n\t * previous operations succeeded.  If the orphan_add is going to\n\t * fail (possibly taking the journal offline), we can't risk\n\t * leaving the inode on the orphan list: stray orphan-list\n\t * entries can cause panics at unmount time.\n\t *\n\t * This is safe: on error we're going to ignore the orphan list\n\t * anyway on the next recovery. */\nmem_insert:\n\tif (!err)\n\t\tlist_add(&EXT4_I(inode)->i_orphan, &EXT4_SB(sb)->s_orphan);\n\n\tjbd_debug(4, \"superblock will point to %lu\\n\", inode->i_ino);\n\tjbd_debug(4, \"orphan inode %lu will point to %d\\n\",\n\t\t\tinode->i_ino, NEXT_ORPHAN(inode));\nout_unlock:\n\tmutex_unlock(&EXT4_SB(sb)->s_orphan_lock);\n\text4_std_error(inode->i_sb, err);\n\treturn err;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,7 +4,7 @@\n \tstruct ext4_iloc iloc;\n \tint err = 0, rc;\n \n-\tif (!ext4_handle_valid(handle))\n+\tif (!EXT4_SB(sb)->s_journal)\n \t\treturn 0;\n \n \tmutex_lock(&EXT4_SB(sb)->s_orphan_lock);",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (!ext4_handle_valid(handle))"
            ],
            "added_lines": [
                "\tif (!EXT4_SB(sb)->s_journal)"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-7509",
        "func_name": "torvalds/linux/ext4_orphan_del",
        "description": "fs/ext4/namei.c in the Linux kernel before 3.7 allows physically proximate attackers to cause a denial of service (system crash) via a crafted no-journal filesystem, a related issue to CVE-2013-2015.",
        "git_url": "https://github.com/torvalds/linux/commit/c9b92530a723ac5ef8e352885a1862b18f31b2f5",
        "commit_title": "ext4: make orphan functions be no-op in no-journal mode",
        "commit_text": " Instead of checking whether the handle is valid, we check if journal is enabled. This avoids taking the s_orphan_lock mutex in all cases when there is no journal in use, including the error paths where ext4_orphan_del() is called with a handle set to NULL. ",
        "func_before": "int ext4_orphan_del(handle_t *handle, struct inode *inode)\n{\n\tstruct list_head *prev;\n\tstruct ext4_inode_info *ei = EXT4_I(inode);\n\tstruct ext4_sb_info *sbi;\n\t__u32 ino_next;\n\tstruct ext4_iloc iloc;\n\tint err = 0;\n\n\t/* ext4_handle_valid() assumes a valid handle_t pointer */\n\tif (handle && !ext4_handle_valid(handle))\n\t\treturn 0;\n\n\tmutex_lock(&EXT4_SB(inode->i_sb)->s_orphan_lock);\n\tif (list_empty(&ei->i_orphan))\n\t\tgoto out;\n\n\tino_next = NEXT_ORPHAN(inode);\n\tprev = ei->i_orphan.prev;\n\tsbi = EXT4_SB(inode->i_sb);\n\n\tjbd_debug(4, \"remove inode %lu from orphan list\\n\", inode->i_ino);\n\n\tlist_del_init(&ei->i_orphan);\n\n\t/* If we're on an error path, we may not have a valid\n\t * transaction handle with which to update the orphan list on\n\t * disk, but we still need to remove the inode from the linked\n\t * list in memory. */\n\tif (sbi->s_journal && !handle)\n\t\tgoto out;\n\n\terr = ext4_reserve_inode_write(handle, inode, &iloc);\n\tif (err)\n\t\tgoto out_err;\n\n\tif (prev == &sbi->s_orphan) {\n\t\tjbd_debug(4, \"superblock will point to %u\\n\", ino_next);\n\t\tBUFFER_TRACE(sbi->s_sbh, \"get_write_access\");\n\t\terr = ext4_journal_get_write_access(handle, sbi->s_sbh);\n\t\tif (err)\n\t\t\tgoto out_brelse;\n\t\tsbi->s_es->s_last_orphan = cpu_to_le32(ino_next);\n\t\terr = ext4_handle_dirty_super(handle, inode->i_sb);\n\t} else {\n\t\tstruct ext4_iloc iloc2;\n\t\tstruct inode *i_prev =\n\t\t\t&list_entry(prev, struct ext4_inode_info, i_orphan)->vfs_inode;\n\n\t\tjbd_debug(4, \"orphan inode %lu will point to %u\\n\",\n\t\t\t  i_prev->i_ino, ino_next);\n\t\terr = ext4_reserve_inode_write(handle, i_prev, &iloc2);\n\t\tif (err)\n\t\t\tgoto out_brelse;\n\t\tNEXT_ORPHAN(i_prev) = ino_next;\n\t\terr = ext4_mark_iloc_dirty(handle, i_prev, &iloc2);\n\t}\n\tif (err)\n\t\tgoto out_brelse;\n\tNEXT_ORPHAN(inode) = 0;\n\terr = ext4_mark_iloc_dirty(handle, inode, &iloc);\n\nout_err:\n\text4_std_error(inode->i_sb, err);\nout:\n\tmutex_unlock(&EXT4_SB(inode->i_sb)->s_orphan_lock);\n\treturn err;\n\nout_brelse:\n\tbrelse(iloc.bh);\n\tgoto out_err;\n}",
        "func": "int ext4_orphan_del(handle_t *handle, struct inode *inode)\n{\n\tstruct list_head *prev;\n\tstruct ext4_inode_info *ei = EXT4_I(inode);\n\tstruct ext4_sb_info *sbi;\n\t__u32 ino_next;\n\tstruct ext4_iloc iloc;\n\tint err = 0;\n\n\tif (!EXT4_SB(inode->i_sb)->s_journal)\n\t\treturn 0;\n\n\tmutex_lock(&EXT4_SB(inode->i_sb)->s_orphan_lock);\n\tif (list_empty(&ei->i_orphan))\n\t\tgoto out;\n\n\tino_next = NEXT_ORPHAN(inode);\n\tprev = ei->i_orphan.prev;\n\tsbi = EXT4_SB(inode->i_sb);\n\n\tjbd_debug(4, \"remove inode %lu from orphan list\\n\", inode->i_ino);\n\n\tlist_del_init(&ei->i_orphan);\n\n\t/* If we're on an error path, we may not have a valid\n\t * transaction handle with which to update the orphan list on\n\t * disk, but we still need to remove the inode from the linked\n\t * list in memory. */\n\tif (!handle)\n\t\tgoto out;\n\n\terr = ext4_reserve_inode_write(handle, inode, &iloc);\n\tif (err)\n\t\tgoto out_err;\n\n\tif (prev == &sbi->s_orphan) {\n\t\tjbd_debug(4, \"superblock will point to %u\\n\", ino_next);\n\t\tBUFFER_TRACE(sbi->s_sbh, \"get_write_access\");\n\t\terr = ext4_journal_get_write_access(handle, sbi->s_sbh);\n\t\tif (err)\n\t\t\tgoto out_brelse;\n\t\tsbi->s_es->s_last_orphan = cpu_to_le32(ino_next);\n\t\terr = ext4_handle_dirty_super(handle, inode->i_sb);\n\t} else {\n\t\tstruct ext4_iloc iloc2;\n\t\tstruct inode *i_prev =\n\t\t\t&list_entry(prev, struct ext4_inode_info, i_orphan)->vfs_inode;\n\n\t\tjbd_debug(4, \"orphan inode %lu will point to %u\\n\",\n\t\t\t  i_prev->i_ino, ino_next);\n\t\terr = ext4_reserve_inode_write(handle, i_prev, &iloc2);\n\t\tif (err)\n\t\t\tgoto out_brelse;\n\t\tNEXT_ORPHAN(i_prev) = ino_next;\n\t\terr = ext4_mark_iloc_dirty(handle, i_prev, &iloc2);\n\t}\n\tif (err)\n\t\tgoto out_brelse;\n\tNEXT_ORPHAN(inode) = 0;\n\terr = ext4_mark_iloc_dirty(handle, inode, &iloc);\n\nout_err:\n\text4_std_error(inode->i_sb, err);\nout:\n\tmutex_unlock(&EXT4_SB(inode->i_sb)->s_orphan_lock);\n\treturn err;\n\nout_brelse:\n\tbrelse(iloc.bh);\n\tgoto out_err;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -7,8 +7,7 @@\n \tstruct ext4_iloc iloc;\n \tint err = 0;\n \n-\t/* ext4_handle_valid() assumes a valid handle_t pointer */\n-\tif (handle && !ext4_handle_valid(handle))\n+\tif (!EXT4_SB(inode->i_sb)->s_journal)\n \t\treturn 0;\n \n \tmutex_lock(&EXT4_SB(inode->i_sb)->s_orphan_lock);\n@@ -27,7 +26,7 @@\n \t * transaction handle with which to update the orphan list on\n \t * disk, but we still need to remove the inode from the linked\n \t * list in memory. */\n-\tif (sbi->s_journal && !handle)\n+\tif (!handle)\n \t\tgoto out;\n \n \terr = ext4_reserve_inode_write(handle, inode, &iloc);",
        "diff_line_info": {
            "deleted_lines": [
                "\t/* ext4_handle_valid() assumes a valid handle_t pointer */",
                "\tif (handle && !ext4_handle_valid(handle))",
                "\tif (sbi->s_journal && !handle)"
            ],
            "added_lines": [
                "\tif (!EXT4_SB(inode->i_sb)->s_journal)",
                "\tif (!handle)"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-7509",
        "func_name": "torvalds/linux/ext4_orphan_del",
        "description": "fs/ext4/namei.c in the Linux kernel before 3.7 allows physically proximate attackers to cause a denial of service (system crash) via a crafted no-journal filesystem, a related issue to CVE-2013-2015.",
        "git_url": "https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?h=0e9a9a1ad619e7e987815d20262d36a2f95717ca",
        "commit_title": "When trying to mount a file system which does not contain a journal,",
        "commit_text": "but which does have a orphan list containing an inode which needs to be truncated, the mount call with hang forever in ext4_orphan_cleanup() because ext4_orphan_del() will return immediately without removing the inode from the orphan list, leading to an uninterruptible loop in kernel code which will busy out one of the CPU's on the system.  This can be trivially reproduced by trying to mount the file system found in tests/f_orphan_extents_inode/image.gz from the e2fsprogs source tree.  If a malicious user were to put this on a USB stick, and mount it on a Linux desktop which has automatic mounts enabled, this could be considered a potential denial of service attack.  (Not a big deal in practice, but professional paranoids worry about such things, and have even been known to allocate CVE numbers for such problems.)  Cc: stable@vger.kernel.org ",
        "func_before": "int ext4_orphan_del(handle_t *handle, struct inode *inode)\n{\n\tstruct list_head *prev;\n\tstruct ext4_inode_info *ei = EXT4_I(inode);\n\tstruct ext4_sb_info *sbi;\n\t__u32 ino_next;\n\tstruct ext4_iloc iloc;\n\tint err = 0;\n\n\tif (!EXT4_SB(inode->i_sb)->s_journal)\n\t\treturn 0;\n\n\tmutex_lock(&EXT4_SB(inode->i_sb)->s_orphan_lock);\n\tif (list_empty(&ei->i_orphan))\n\t\tgoto out;\n\n\tino_next = NEXT_ORPHAN(inode);\n\tprev = ei->i_orphan.prev;\n\tsbi = EXT4_SB(inode->i_sb);\n\n\tjbd_debug(4, \"remove inode %lu from orphan list\\n\", inode->i_ino);\n\n\tlist_del_init(&ei->i_orphan);\n\n\t/* If we're on an error path, we may not have a valid\n\t * transaction handle with which to update the orphan list on\n\t * disk, but we still need to remove the inode from the linked\n\t * list in memory. */\n\tif (!handle)\n\t\tgoto out;\n\n\terr = ext4_reserve_inode_write(handle, inode, &iloc);\n\tif (err)\n\t\tgoto out_err;\n\n\tif (prev == &sbi->s_orphan) {\n\t\tjbd_debug(4, \"superblock will point to %u\\n\", ino_next);\n\t\tBUFFER_TRACE(sbi->s_sbh, \"get_write_access\");\n\t\terr = ext4_journal_get_write_access(handle, sbi->s_sbh);\n\t\tif (err)\n\t\t\tgoto out_brelse;\n\t\tsbi->s_es->s_last_orphan = cpu_to_le32(ino_next);\n\t\terr = ext4_handle_dirty_super(handle, inode->i_sb);\n\t} else {\n\t\tstruct ext4_iloc iloc2;\n\t\tstruct inode *i_prev =\n\t\t\t&list_entry(prev, struct ext4_inode_info, i_orphan)->vfs_inode;\n\n\t\tjbd_debug(4, \"orphan inode %lu will point to %u\\n\",\n\t\t\t  i_prev->i_ino, ino_next);\n\t\terr = ext4_reserve_inode_write(handle, i_prev, &iloc2);\n\t\tif (err)\n\t\t\tgoto out_brelse;\n\t\tNEXT_ORPHAN(i_prev) = ino_next;\n\t\terr = ext4_mark_iloc_dirty(handle, i_prev, &iloc2);\n\t}\n\tif (err)\n\t\tgoto out_brelse;\n\tNEXT_ORPHAN(inode) = 0;\n\terr = ext4_mark_iloc_dirty(handle, inode, &iloc);\n\nout_err:\n\text4_std_error(inode->i_sb, err);\nout:\n\tmutex_unlock(&EXT4_SB(inode->i_sb)->s_orphan_lock);\n\treturn err;\n\nout_brelse:\n\tbrelse(iloc.bh);\n\tgoto out_err;\n}",
        "func": "int ext4_orphan_del(handle_t *handle, struct inode *inode)\n{\n\tstruct list_head *prev;\n\tstruct ext4_inode_info *ei = EXT4_I(inode);\n\tstruct ext4_sb_info *sbi;\n\t__u32 ino_next;\n\tstruct ext4_iloc iloc;\n\tint err = 0;\n\n\tif ((!EXT4_SB(inode->i_sb)->s_journal) &&\n\t    !(EXT4_SB(inode->i_sb)->s_mount_state & EXT4_ORPHAN_FS))\n\t\treturn 0;\n\n\tmutex_lock(&EXT4_SB(inode->i_sb)->s_orphan_lock);\n\tif (list_empty(&ei->i_orphan))\n\t\tgoto out;\n\n\tino_next = NEXT_ORPHAN(inode);\n\tprev = ei->i_orphan.prev;\n\tsbi = EXT4_SB(inode->i_sb);\n\n\tjbd_debug(4, \"remove inode %lu from orphan list\\n\", inode->i_ino);\n\n\tlist_del_init(&ei->i_orphan);\n\n\t/* If we're on an error path, we may not have a valid\n\t * transaction handle with which to update the orphan list on\n\t * disk, but we still need to remove the inode from the linked\n\t * list in memory. */\n\tif (!handle)\n\t\tgoto out;\n\n\terr = ext4_reserve_inode_write(handle, inode, &iloc);\n\tif (err)\n\t\tgoto out_err;\n\n\tif (prev == &sbi->s_orphan) {\n\t\tjbd_debug(4, \"superblock will point to %u\\n\", ino_next);\n\t\tBUFFER_TRACE(sbi->s_sbh, \"get_write_access\");\n\t\terr = ext4_journal_get_write_access(handle, sbi->s_sbh);\n\t\tif (err)\n\t\t\tgoto out_brelse;\n\t\tsbi->s_es->s_last_orphan = cpu_to_le32(ino_next);\n\t\terr = ext4_handle_dirty_super(handle, inode->i_sb);\n\t} else {\n\t\tstruct ext4_iloc iloc2;\n\t\tstruct inode *i_prev =\n\t\t\t&list_entry(prev, struct ext4_inode_info, i_orphan)->vfs_inode;\n\n\t\tjbd_debug(4, \"orphan inode %lu will point to %u\\n\",\n\t\t\t  i_prev->i_ino, ino_next);\n\t\terr = ext4_reserve_inode_write(handle, i_prev, &iloc2);\n\t\tif (err)\n\t\t\tgoto out_brelse;\n\t\tNEXT_ORPHAN(i_prev) = ino_next;\n\t\terr = ext4_mark_iloc_dirty(handle, i_prev, &iloc2);\n\t}\n\tif (err)\n\t\tgoto out_brelse;\n\tNEXT_ORPHAN(inode) = 0;\n\terr = ext4_mark_iloc_dirty(handle, inode, &iloc);\n\nout_err:\n\text4_std_error(inode->i_sb, err);\nout:\n\tmutex_unlock(&EXT4_SB(inode->i_sb)->s_orphan_lock);\n\treturn err;\n\nout_brelse:\n\tbrelse(iloc.bh);\n\tgoto out_err;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -7,7 +7,8 @@\n \tstruct ext4_iloc iloc;\n \tint err = 0;\n \n-\tif (!EXT4_SB(inode->i_sb)->s_journal)\n+\tif ((!EXT4_SB(inode->i_sb)->s_journal) &&\n+\t    !(EXT4_SB(inode->i_sb)->s_mount_state & EXT4_ORPHAN_FS))\n \t\treturn 0;\n \n \tmutex_lock(&EXT4_SB(inode->i_sb)->s_orphan_lock);",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (!EXT4_SB(inode->i_sb)->s_journal)"
            ],
            "added_lines": [
                "\tif ((!EXT4_SB(inode->i_sb)->s_journal) &&",
                "\t    !(EXT4_SB(inode->i_sb)->s_mount_state & EXT4_ORPHAN_FS))"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-3199",
        "func_name": "chromium/wrap",
        "description": "The wrap function in bindings/core/v8/custom/V8EventCustom.cpp in the V8 bindings in Blink, as used in Google Chrome before 38.0.2125.101, has an erroneous fallback outcome for wrapper-selection failures, which allows remote attackers to cause a denial of service via vectors that trigger stopping a worker process that had been handling an Event object.",
        "git_url": "https://github.com/chromium/chromium/commit/7c167734040a28f3618c9209bcc2259ebd60856e",
        "commit_title": "Simply V8 wrapper generation for Event objects",
        "commit_text": " When trying to determine what kind of wrapper to produce, we'd iterate over core event types (exiting early) then try iterating over module event types. If the latter yielded an empty handle we'd wrap the object as just a V8Event, which is bogus. This could happen in a worker if the object was indeed a module event type, but the worker had been asynchronously stopped and v8 was politely failing to produce a wrapper.  Remove the fallback case, and instead assert if we make it as far as module event type iteration and no match is found.   ",
        "func_before": "v8::Handle<v8::Object> wrap(Event* event, v8::Handle<v8::Object> creationContext, v8::Isolate *isolate)\n{\n    ASSERT(event);\n\n    String desiredInterface = event->interfaceName();\n\n    // We need to check Event first to avoid infinite recursion.\n    if (EventNames::Event == desiredInterface)\n        return V8Event::createWrapper(event, creationContext, isolate);\n\n    EVENT_INTERFACES_FOR_EACH(TRY_TO_WRAP_WITH_INTERFACE)\n\n    v8::Handle<v8::Object> wrapper = ModuleProxy::moduleProxy().wrapForEvent(event, creationContext, isolate);\n    if (!wrapper.IsEmpty())\n        return wrapper;\n    return V8Event::createWrapper(event, creationContext, isolate);\n}",
        "func": "v8::Handle<v8::Object> wrap(Event* event, v8::Handle<v8::Object> creationContext, v8::Isolate *isolate)\n{\n    ASSERT(event);\n\n    String desiredInterface = event->interfaceName();\n\n    // We need to check Event first to avoid infinite recursion.\n    if (EventNames::Event == desiredInterface)\n        return V8Event::createWrapper(event, creationContext, isolate);\n\n    EVENT_INTERFACES_FOR_EACH(TRY_TO_WRAP_WITH_INTERFACE);\n\n    return ModuleProxy::moduleProxy().wrapForEvent(event, creationContext, isolate);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -8,10 +8,7 @@\n     if (EventNames::Event == desiredInterface)\n         return V8Event::createWrapper(event, creationContext, isolate);\n \n-    EVENT_INTERFACES_FOR_EACH(TRY_TO_WRAP_WITH_INTERFACE)\n+    EVENT_INTERFACES_FOR_EACH(TRY_TO_WRAP_WITH_INTERFACE);\n \n-    v8::Handle<v8::Object> wrapper = ModuleProxy::moduleProxy().wrapForEvent(event, creationContext, isolate);\n-    if (!wrapper.IsEmpty())\n-        return wrapper;\n-    return V8Event::createWrapper(event, creationContext, isolate);\n+    return ModuleProxy::moduleProxy().wrapForEvent(event, creationContext, isolate);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    EVENT_INTERFACES_FOR_EACH(TRY_TO_WRAP_WITH_INTERFACE)",
                "    v8::Handle<v8::Object> wrapper = ModuleProxy::moduleProxy().wrapForEvent(event, creationContext, isolate);",
                "    if (!wrapper.IsEmpty())",
                "        return wrapper;",
                "    return V8Event::createWrapper(event, creationContext, isolate);"
            ],
            "added_lines": [
                "    EVENT_INTERFACES_FOR_EACH(TRY_TO_WRAP_WITH_INTERFACE);",
                "    return ModuleProxy::moduleProxy().wrapForEvent(event, creationContext, isolate);"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-3199",
        "func_name": "chromium/wrapForModuleEvent",
        "description": "The wrap function in bindings/core/v8/custom/V8EventCustom.cpp in the V8 bindings in Blink, as used in Google Chrome before 38.0.2125.101, has an erroneous fallback outcome for wrapper-selection failures, which allows remote attackers to cause a denial of service via vectors that trigger stopping a worker process that had been handling an Event object.",
        "git_url": "https://github.com/chromium/chromium/commit/7c167734040a28f3618c9209bcc2259ebd60856e",
        "commit_title": "Simply V8 wrapper generation for Event objects",
        "commit_text": " When trying to determine what kind of wrapper to produce, we'd iterate over core event types (exiting early) then try iterating over module event types. If the latter yielded an empty handle we'd wrap the object as just a V8Event, which is bogus. This could happen in a worker if the object was indeed a module event type, but the worker had been asynchronously stopped and v8 was politely failing to produce a wrapper.  Remove the fallback case, and instead assert if we make it as far as module event type iteration and no match is found.   ",
        "func_before": "static v8::Handle<v8::Object> wrapForModuleEvent(Event* event, v8::Handle<v8::Object> creationContext, v8::Isolate *isolate)\n{\n    ASSERT(event);\n\n    String desiredInterface = event->interfaceName();\n    EVENT_MODULES_INTERFACES_FOR_EACH(TRY_TO_WRAP_WITH_INTERFACE)\n    return v8::Handle<v8::Object>();\n}",
        "func": "static v8::Handle<v8::Object> wrapForModuleEvent(Event* event, v8::Handle<v8::Object> creationContext, v8::Isolate *isolate)\n{\n    ASSERT(event);\n\n    String desiredInterface = event->interfaceName();\n    EVENT_MODULES_INTERFACES_FOR_EACH(TRY_TO_WRAP_WITH_INTERFACE);\n\n    // Wrapping for core event types should have been tried before this\n    // function was called, so |event| should have been a module event type.\n    // If this ASSERT is hit, the event type was missing from both\n    // enumerations.\n    ASSERT_NOT_REACHED();\n    return v8::Handle<v8::Object>();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,6 +3,12 @@\n     ASSERT(event);\n \n     String desiredInterface = event->interfaceName();\n-    EVENT_MODULES_INTERFACES_FOR_EACH(TRY_TO_WRAP_WITH_INTERFACE)\n+    EVENT_MODULES_INTERFACES_FOR_EACH(TRY_TO_WRAP_WITH_INTERFACE);\n+\n+    // Wrapping for core event types should have been tried before this\n+    // function was called, so |event| should have been a module event type.\n+    // If this ASSERT is hit, the event type was missing from both\n+    // enumerations.\n+    ASSERT_NOT_REACHED();\n     return v8::Handle<v8::Object>();\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    EVENT_MODULES_INTERFACES_FOR_EACH(TRY_TO_WRAP_WITH_INTERFACE)"
            ],
            "added_lines": [
                "    EVENT_MODULES_INTERFACES_FOR_EACH(TRY_TO_WRAP_WITH_INTERFACE);",
                "",
                "    // Wrapping for core event types should have been tried before this",
                "    // function was called, so |event| should have been a module event type.",
                "    // If this ASSERT is hit, the event type was missing from both",
                "    // enumerations.",
                "    ASSERT_NOT_REACHED();"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-7283",
        "func_name": "torvalds/linux/xfs_da3_fixhashpath",
        "description": "The xfs_da3_fixhashpath function in fs/xfs/xfs_da_btree.c in the xfs implementation in the Linux kernel before 3.14.2 does not properly compare btree hash values, which allows local users to cause a denial of service (filesystem corruption, and OOPS or panic) via operations on directories that have hash collisions, as demonstrated by rmdir operations.",
        "git_url": "https://github.com/torvalds/linux/commit/c88547a8119e3b581318ab65e9b72f27f23e641d",
        "commit_title": "xfs: fix directory hash ordering bug",
        "commit_text": " Commit f5ea1100 (\"xfs: add CRCs to dir2/da node blocks\") introduced in 3.10 incorrectly converted the btree hash index array pointer in xfs_da3_fixhashpath(). It resulted in the the current hash always being compared against the first entry in the btree rather than the current block index into the btree block's hash entry array. As a result, it was comparing the wrong hashes, and so could misorder the entries in the btree.  For most cases, this doesn't cause any problems as it requires hash collisions to expose the ordering problem. However, when there are hash collisions within a directory there is a very good probability that the entries will be ordered incorrectly and that actually matters when duplicate hashes are placed into or removed from the btree block hash entry array.  This bug results in an on-disk directory corruption and that results in directory verifier functions throwing corruption warnings into the logs. While no data or directory entries are lost, access to them may be compromised, and attempts to remove entries from a directory that has suffered from this corruption may result in a filesystem shutdown.  xfs_repair will fix the directory hash ordering without data loss occuring.  [dchinner: wrote useful a commit message]  cc: <stable@vger.kernel.org>",
        "func_before": "void\nxfs_da3_fixhashpath(\n\tstruct xfs_da_state\t*state,\n\tstruct xfs_da_state_path *path)\n{\n\tstruct xfs_da_state_blk\t*blk;\n\tstruct xfs_da_intnode\t*node;\n\tstruct xfs_da_node_entry *btree;\n\txfs_dahash_t\t\tlasthash=0;\n\tint\t\t\tlevel;\n\tint\t\t\tcount;\n\tstruct xfs_inode\t*dp = state->args->dp;\n\n\ttrace_xfs_da_fixhashpath(state->args);\n\n\tlevel = path->active-1;\n\tblk = &path->blk[ level ];\n\tswitch (blk->magic) {\n\tcase XFS_ATTR_LEAF_MAGIC:\n\t\tlasthash = xfs_attr_leaf_lasthash(blk->bp, &count);\n\t\tif (count == 0)\n\t\t\treturn;\n\t\tbreak;\n\tcase XFS_DIR2_LEAFN_MAGIC:\n\t\tlasthash = xfs_dir2_leafn_lasthash(dp, blk->bp, &count);\n\t\tif (count == 0)\n\t\t\treturn;\n\t\tbreak;\n\tcase XFS_DA_NODE_MAGIC:\n\t\tlasthash = xfs_da3_node_lasthash(dp, blk->bp, &count);\n\t\tif (count == 0)\n\t\t\treturn;\n\t\tbreak;\n\t}\n\tfor (blk--, level--; level >= 0; blk--, level--) {\n\t\tstruct xfs_da3_icnode_hdr nodehdr;\n\n\t\tnode = blk->bp->b_addr;\n\t\tdp->d_ops->node_hdr_from_disk(&nodehdr, node);\n\t\tbtree = dp->d_ops->node_tree_p(node);\n\t\tif (be32_to_cpu(btree->hashval) == lasthash)\n\t\t\tbreak;\n\t\tblk->hashval = lasthash;\n\t\tbtree[blk->index].hashval = cpu_to_be32(lasthash);\n\t\txfs_trans_log_buf(state->args->trans, blk->bp,\n\t\t\t\t  XFS_DA_LOGRANGE(node, &btree[blk->index],\n\t\t\t\t\t\t  sizeof(*btree)));\n\n\t\tlasthash = be32_to_cpu(btree[nodehdr.count - 1].hashval);\n\t}\n}",
        "func": "void\nxfs_da3_fixhashpath(\n\tstruct xfs_da_state\t*state,\n\tstruct xfs_da_state_path *path)\n{\n\tstruct xfs_da_state_blk\t*blk;\n\tstruct xfs_da_intnode\t*node;\n\tstruct xfs_da_node_entry *btree;\n\txfs_dahash_t\t\tlasthash=0;\n\tint\t\t\tlevel;\n\tint\t\t\tcount;\n\tstruct xfs_inode\t*dp = state->args->dp;\n\n\ttrace_xfs_da_fixhashpath(state->args);\n\n\tlevel = path->active-1;\n\tblk = &path->blk[ level ];\n\tswitch (blk->magic) {\n\tcase XFS_ATTR_LEAF_MAGIC:\n\t\tlasthash = xfs_attr_leaf_lasthash(blk->bp, &count);\n\t\tif (count == 0)\n\t\t\treturn;\n\t\tbreak;\n\tcase XFS_DIR2_LEAFN_MAGIC:\n\t\tlasthash = xfs_dir2_leafn_lasthash(dp, blk->bp, &count);\n\t\tif (count == 0)\n\t\t\treturn;\n\t\tbreak;\n\tcase XFS_DA_NODE_MAGIC:\n\t\tlasthash = xfs_da3_node_lasthash(dp, blk->bp, &count);\n\t\tif (count == 0)\n\t\t\treturn;\n\t\tbreak;\n\t}\n\tfor (blk--, level--; level >= 0; blk--, level--) {\n\t\tstruct xfs_da3_icnode_hdr nodehdr;\n\n\t\tnode = blk->bp->b_addr;\n\t\tdp->d_ops->node_hdr_from_disk(&nodehdr, node);\n\t\tbtree = dp->d_ops->node_tree_p(node);\n\t\tif (be32_to_cpu(btree[blk->index].hashval) == lasthash)\n\t\t\tbreak;\n\t\tblk->hashval = lasthash;\n\t\tbtree[blk->index].hashval = cpu_to_be32(lasthash);\n\t\txfs_trans_log_buf(state->args->trans, blk->bp,\n\t\t\t\t  XFS_DA_LOGRANGE(node, &btree[blk->index],\n\t\t\t\t\t\t  sizeof(*btree)));\n\n\t\tlasthash = be32_to_cpu(btree[nodehdr.count - 1].hashval);\n\t}\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -38,7 +38,7 @@\n \t\tnode = blk->bp->b_addr;\n \t\tdp->d_ops->node_hdr_from_disk(&nodehdr, node);\n \t\tbtree = dp->d_ops->node_tree_p(node);\n-\t\tif (be32_to_cpu(btree->hashval) == lasthash)\n+\t\tif (be32_to_cpu(btree[blk->index].hashval) == lasthash)\n \t\t\tbreak;\n \t\tblk->hashval = lasthash;\n \t\tbtree[blk->index].hashval = cpu_to_be32(lasthash);",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tif (be32_to_cpu(btree->hashval) == lasthash)"
            ],
            "added_lines": [
                "\t\tif (be32_to_cpu(btree[blk->index].hashval) == lasthash)"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-3567",
        "func_name": "openssl/tls_decrypt_ticket",
        "description": "Memory leak in the tls_decrypt_ticket function in t1_lib.c in OpenSSL before 0.9.8zc, 1.0.0 before 1.0.0o, and 1.0.1 before 1.0.1j allows remote attackers to cause a denial of service (memory consumption) via a crafted session ticket that triggers an integrity-check failure.",
        "git_url": "https://git.openssl.org/gitweb/?p=openssl.git;a=commit;h=7fd4ce6a997be5f5c9e744ac527725c2850de203",
        "commit_title": "",
        "commit_text": "Fix for session tickets memory leak.  CVE-2014-3567  (cherry picked from commit 5dc6070a03779cd524f0e67f76c945cb0ac38320) ",
        "func_before": "static int tls_decrypt_ticket(SSL *s, const unsigned char *etick, int eticklen,\n\t\t\t\tconst unsigned char *sess_id, int sesslen,\n\t\t\t\tSSL_SESSION **psess)\n\t{\n\tSSL_SESSION *sess;\n\tunsigned char *sdec;\n\tconst unsigned char *p;\n\tint slen, mlen, renew_ticket = 0;\n\tunsigned char tick_hmac[EVP_MAX_MD_SIZE];\n\tHMAC_CTX hctx;\n\tEVP_CIPHER_CTX ctx;\n\tSSL_CTX *tctx = s->initial_ctx;\n\t/* Need at least keyname + iv + some encrypted data */\n\tif (eticklen < 48)\n\t\treturn 2;\n\t/* Initialize session ticket encryption and HMAC contexts */\n\tHMAC_CTX_init(&hctx);\n\tEVP_CIPHER_CTX_init(&ctx);\n\tif (tctx->tlsext_ticket_key_cb)\n\t\t{\n\t\tunsigned char *nctick = (unsigned char *)etick;\n\t\tint rv = tctx->tlsext_ticket_key_cb(s, nctick, nctick + 16,\n\t\t\t\t\t\t\t&ctx, &hctx, 0);\n\t\tif (rv < 0)\n\t\t\treturn -1;\n\t\tif (rv == 0)\n\t\t\treturn 2;\n\t\tif (rv == 2)\n\t\t\trenew_ticket = 1;\n\t\t}\n\telse\n\t\t{\n\t\t/* Check key name matches */\n\t\tif (memcmp(etick, tctx->tlsext_tick_key_name, 16))\n\t\t\treturn 2;\n\t\tHMAC_Init_ex(&hctx, tctx->tlsext_tick_hmac_key, 16,\n\t\t\t\t\ttlsext_tick_md(), NULL);\n\t\tEVP_DecryptInit_ex(&ctx, EVP_aes_128_cbc(), NULL,\n\t\t\t\ttctx->tlsext_tick_aes_key, etick + 16);\n\t\t}\n\t/* Attempt to process session ticket, first conduct sanity and\n\t * integrity checks on ticket.\n\t */\n\tmlen = HMAC_size(&hctx);\n\tif (mlen < 0)\n\t\t{\n\t\tEVP_CIPHER_CTX_cleanup(&ctx);\n\t\treturn -1;\n\t\t}\n\teticklen -= mlen;\n\t/* Check HMAC of encrypted ticket */\n\tHMAC_Update(&hctx, etick, eticklen);\n\tHMAC_Final(&hctx, tick_hmac, NULL);\n\tHMAC_CTX_cleanup(&hctx);\n\tif (CRYPTO_memcmp(tick_hmac, etick + eticklen, mlen))\n\t\treturn 2;\n\t/* Attempt to decrypt session data */\n\t/* Move p after IV to start of encrypted ticket, update length */\n\tp = etick + 16 + EVP_CIPHER_CTX_iv_length(&ctx);\n\teticklen -= 16 + EVP_CIPHER_CTX_iv_length(&ctx);\n\tsdec = OPENSSL_malloc(eticklen);\n\tif (!sdec)\n\t\t{\n\t\tEVP_CIPHER_CTX_cleanup(&ctx);\n\t\treturn -1;\n\t\t}\n\tEVP_DecryptUpdate(&ctx, sdec, &slen, p, eticklen);\n\tif (EVP_DecryptFinal(&ctx, sdec + slen, &mlen) <= 0)\n\t\t{\n\t\tEVP_CIPHER_CTX_cleanup(&ctx);\n\t\tOPENSSL_free(sdec);\n\t\treturn 2;\n\t\t}\n\tslen += mlen;\n\tEVP_CIPHER_CTX_cleanup(&ctx);\n\tp = sdec;\n\n\tsess = d2i_SSL_SESSION(NULL, &p, slen);\n\tOPENSSL_free(sdec);\n\tif (sess)\n\t\t{\n\t\t/* The session ID, if non-empty, is used by some clients to\n\t\t * detect that the ticket has been accepted. So we copy it to\n\t\t * the session structure. If it is empty set length to zero\n\t\t * as required by standard.\n\t\t */\n\t\tif (sesslen)\n\t\t\tmemcpy(sess->session_id, sess_id, sesslen);\n\t\tsess->session_id_length = sesslen;\n\t\t*psess = sess;\n\t\tif (renew_ticket)\n\t\t\treturn 4;\n\t\telse\n\t\t\treturn 3;\n\t\t}\n        ERR_clear_error();\n\t/* For session parse failure, indicate that we need to send a new\n\t * ticket. */\n\treturn 2;\n\t}",
        "func": "static int tls_decrypt_ticket(SSL *s, const unsigned char *etick, int eticklen,\n\t\t\t\tconst unsigned char *sess_id, int sesslen,\n\t\t\t\tSSL_SESSION **psess)\n\t{\n\tSSL_SESSION *sess;\n\tunsigned char *sdec;\n\tconst unsigned char *p;\n\tint slen, mlen, renew_ticket = 0;\n\tunsigned char tick_hmac[EVP_MAX_MD_SIZE];\n\tHMAC_CTX hctx;\n\tEVP_CIPHER_CTX ctx;\n\tSSL_CTX *tctx = s->initial_ctx;\n\t/* Need at least keyname + iv + some encrypted data */\n\tif (eticklen < 48)\n\t\treturn 2;\n\t/* Initialize session ticket encryption and HMAC contexts */\n\tHMAC_CTX_init(&hctx);\n\tEVP_CIPHER_CTX_init(&ctx);\n\tif (tctx->tlsext_ticket_key_cb)\n\t\t{\n\t\tunsigned char *nctick = (unsigned char *)etick;\n\t\tint rv = tctx->tlsext_ticket_key_cb(s, nctick, nctick + 16,\n\t\t\t\t\t\t\t&ctx, &hctx, 0);\n\t\tif (rv < 0)\n\t\t\treturn -1;\n\t\tif (rv == 0)\n\t\t\treturn 2;\n\t\tif (rv == 2)\n\t\t\trenew_ticket = 1;\n\t\t}\n\telse\n\t\t{\n\t\t/* Check key name matches */\n\t\tif (memcmp(etick, tctx->tlsext_tick_key_name, 16))\n\t\t\treturn 2;\n\t\tHMAC_Init_ex(&hctx, tctx->tlsext_tick_hmac_key, 16,\n\t\t\t\t\ttlsext_tick_md(), NULL);\n\t\tEVP_DecryptInit_ex(&ctx, EVP_aes_128_cbc(), NULL,\n\t\t\t\ttctx->tlsext_tick_aes_key, etick + 16);\n\t\t}\n\t/* Attempt to process session ticket, first conduct sanity and\n\t * integrity checks on ticket.\n\t */\n\tmlen = HMAC_size(&hctx);\n\tif (mlen < 0)\n\t\t{\n\t\tEVP_CIPHER_CTX_cleanup(&ctx);\n\t\treturn -1;\n\t\t}\n\teticklen -= mlen;\n\t/* Check HMAC of encrypted ticket */\n\tHMAC_Update(&hctx, etick, eticklen);\n\tHMAC_Final(&hctx, tick_hmac, NULL);\n\tHMAC_CTX_cleanup(&hctx);\n\tif (CRYPTO_memcmp(tick_hmac, etick + eticklen, mlen))\n\t\t{\n\t\tEVP_CIPHER_CTX_cleanup(&ctx);\n\t\treturn 2;\n\t\t}\n\t/* Attempt to decrypt session data */\n\t/* Move p after IV to start of encrypted ticket, update length */\n\tp = etick + 16 + EVP_CIPHER_CTX_iv_length(&ctx);\n\teticklen -= 16 + EVP_CIPHER_CTX_iv_length(&ctx);\n\tsdec = OPENSSL_malloc(eticklen);\n\tif (!sdec)\n\t\t{\n\t\tEVP_CIPHER_CTX_cleanup(&ctx);\n\t\treturn -1;\n\t\t}\n\tEVP_DecryptUpdate(&ctx, sdec, &slen, p, eticklen);\n\tif (EVP_DecryptFinal(&ctx, sdec + slen, &mlen) <= 0)\n\t\t{\n\t\tEVP_CIPHER_CTX_cleanup(&ctx);\n\t\tOPENSSL_free(sdec);\n\t\treturn 2;\n\t\t}\n\tslen += mlen;\n\tEVP_CIPHER_CTX_cleanup(&ctx);\n\tp = sdec;\n\n\tsess = d2i_SSL_SESSION(NULL, &p, slen);\n\tOPENSSL_free(sdec);\n\tif (sess)\n\t\t{\n\t\t/* The session ID, if non-empty, is used by some clients to\n\t\t * detect that the ticket has been accepted. So we copy it to\n\t\t * the session structure. If it is empty set length to zero\n\t\t * as required by standard.\n\t\t */\n\t\tif (sesslen)\n\t\t\tmemcpy(sess->session_id, sess_id, sesslen);\n\t\tsess->session_id_length = sesslen;\n\t\t*psess = sess;\n\t\tif (renew_ticket)\n\t\t\treturn 4;\n\t\telse\n\t\t\treturn 3;\n\t\t}\n        ERR_clear_error();\n\t/* For session parse failure, indicate that we need to send a new\n\t * ticket. */\n\treturn 2;\n\t}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -53,7 +53,10 @@\n \tHMAC_Final(&hctx, tick_hmac, NULL);\n \tHMAC_CTX_cleanup(&hctx);\n \tif (CRYPTO_memcmp(tick_hmac, etick + eticklen, mlen))\n+\t\t{\n+\t\tEVP_CIPHER_CTX_cleanup(&ctx);\n \t\treturn 2;\n+\t\t}\n \t/* Attempt to decrypt session data */\n \t/* Move p after IV to start of encrypted ticket, update length */\n \tp = etick + 16 + EVP_CIPHER_CTX_iv_length(&ctx);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t\t{",
                "\t\tEVP_CIPHER_CTX_cleanup(&ctx);",
                "\t\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-8481",
        "func_name": "torvalds/linux/x86_decode_insn",
        "description": "The instruction decoder in arch/x86/kvm/emulate.c in the KVM subsystem in the Linux kernel before 3.18-rc2 does not properly handle invalid instructions, which allows guest OS users to cause a denial of service (NULL pointer dereference and host OS crash) via a crafted application that triggers (1) an improperly fetched instruction or (2) an instruction that occupies too many bytes.  NOTE: this vulnerability exists because of an incomplete fix for CVE-2014-8480.",
        "git_url": "https://github.com/torvalds/linux/commit/a430c9166312e1aa3d80bce32374233bdbfeba32",
        "commit_title": "KVM: emulate: avoid accessing NULL ctxt->memopp",
        "commit_text": " A failure to decode the instruction can cause a NULL pointer access. This is fixed simply by moving the \"done\" label as close as possible to the return.  This fixes CVE-2014-8481.  Cc: stable@vger.kernel.org",
        "func_before": "int x86_decode_insn(struct x86_emulate_ctxt *ctxt, void *insn, int insn_len)\n{\n\tint rc = X86EMUL_CONTINUE;\n\tint mode = ctxt->mode;\n\tint def_op_bytes, def_ad_bytes, goffset, simd_prefix;\n\tbool op_prefix = false;\n\tbool has_seg_override = false;\n\tstruct opcode opcode;\n\n\tctxt->memop.type = OP_NONE;\n\tctxt->memopp = NULL;\n\tctxt->_eip = ctxt->eip;\n\tctxt->fetch.ptr = ctxt->fetch.data;\n\tctxt->fetch.end = ctxt->fetch.data + insn_len;\n\tctxt->opcode_len = 1;\n\tif (insn_len > 0)\n\t\tmemcpy(ctxt->fetch.data, insn, insn_len);\n\telse {\n\t\trc = __do_insn_fetch_bytes(ctxt, 1);\n\t\tif (rc != X86EMUL_CONTINUE)\n\t\t\treturn rc;\n\t}\n\n\tswitch (mode) {\n\tcase X86EMUL_MODE_REAL:\n\tcase X86EMUL_MODE_VM86:\n\tcase X86EMUL_MODE_PROT16:\n\t\tdef_op_bytes = def_ad_bytes = 2;\n\t\tbreak;\n\tcase X86EMUL_MODE_PROT32:\n\t\tdef_op_bytes = def_ad_bytes = 4;\n\t\tbreak;\n#ifdef CONFIG_X86_64\n\tcase X86EMUL_MODE_PROT64:\n\t\tdef_op_bytes = 4;\n\t\tdef_ad_bytes = 8;\n\t\tbreak;\n#endif\n\tdefault:\n\t\treturn EMULATION_FAILED;\n\t}\n\n\tctxt->op_bytes = def_op_bytes;\n\tctxt->ad_bytes = def_ad_bytes;\n\n\t/* Legacy prefixes. */\n\tfor (;;) {\n\t\tswitch (ctxt->b = insn_fetch(u8, ctxt)) {\n\t\tcase 0x66:\t/* operand-size override */\n\t\t\top_prefix = true;\n\t\t\t/* switch between 2/4 bytes */\n\t\t\tctxt->op_bytes = def_op_bytes ^ 6;\n\t\t\tbreak;\n\t\tcase 0x67:\t/* address-size override */\n\t\t\tif (mode == X86EMUL_MODE_PROT64)\n\t\t\t\t/* switch between 4/8 bytes */\n\t\t\t\tctxt->ad_bytes = def_ad_bytes ^ 12;\n\t\t\telse\n\t\t\t\t/* switch between 2/4 bytes */\n\t\t\t\tctxt->ad_bytes = def_ad_bytes ^ 6;\n\t\t\tbreak;\n\t\tcase 0x26:\t/* ES override */\n\t\tcase 0x2e:\t/* CS override */\n\t\tcase 0x36:\t/* SS override */\n\t\tcase 0x3e:\t/* DS override */\n\t\t\thas_seg_override = true;\n\t\t\tctxt->seg_override = (ctxt->b >> 3) & 3;\n\t\t\tbreak;\n\t\tcase 0x64:\t/* FS override */\n\t\tcase 0x65:\t/* GS override */\n\t\t\thas_seg_override = true;\n\t\t\tctxt->seg_override = ctxt->b & 7;\n\t\t\tbreak;\n\t\tcase 0x40 ... 0x4f: /* REX */\n\t\t\tif (mode != X86EMUL_MODE_PROT64)\n\t\t\t\tgoto done_prefixes;\n\t\t\tctxt->rex_prefix = ctxt->b;\n\t\t\tcontinue;\n\t\tcase 0xf0:\t/* LOCK */\n\t\t\tctxt->lock_prefix = 1;\n\t\t\tbreak;\n\t\tcase 0xf2:\t/* REPNE/REPNZ */\n\t\tcase 0xf3:\t/* REP/REPE/REPZ */\n\t\t\tctxt->rep_prefix = ctxt->b;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tgoto done_prefixes;\n\t\t}\n\n\t\t/* Any legacy prefix after a REX prefix nullifies its effect. */\n\n\t\tctxt->rex_prefix = 0;\n\t}\n\ndone_prefixes:\n\n\t/* REX prefix. */\n\tif (ctxt->rex_prefix & 8)\n\t\tctxt->op_bytes = 8;\t/* REX.W */\n\n\t/* Opcode byte(s). */\n\topcode = opcode_table[ctxt->b];\n\t/* Two-byte opcode? */\n\tif (ctxt->b == 0x0f) {\n\t\tctxt->opcode_len = 2;\n\t\tctxt->b = insn_fetch(u8, ctxt);\n\t\topcode = twobyte_table[ctxt->b];\n\n\t\t/* 0F_38 opcode map */\n\t\tif (ctxt->b == 0x38) {\n\t\t\tctxt->opcode_len = 3;\n\t\t\tctxt->b = insn_fetch(u8, ctxt);\n\t\t\topcode = opcode_map_0f_38[ctxt->b];\n\t\t}\n\t}\n\tctxt->d = opcode.flags;\n\n\tif (ctxt->d & ModRM)\n\t\tctxt->modrm = insn_fetch(u8, ctxt);\n\n\t/* vex-prefix instructions are not implemented */\n\tif (ctxt->opcode_len == 1 && (ctxt->b == 0xc5 || ctxt->b == 0xc4) &&\n\t    (mode == X86EMUL_MODE_PROT64 ||\n\t    (mode >= X86EMUL_MODE_PROT16 && (ctxt->modrm & 0x80)))) {\n\t\tctxt->d = NotImpl;\n\t}\n\n\twhile (ctxt->d & GroupMask) {\n\t\tswitch (ctxt->d & GroupMask) {\n\t\tcase Group:\n\t\t\tgoffset = (ctxt->modrm >> 3) & 7;\n\t\t\topcode = opcode.u.group[goffset];\n\t\t\tbreak;\n\t\tcase GroupDual:\n\t\t\tgoffset = (ctxt->modrm >> 3) & 7;\n\t\t\tif ((ctxt->modrm >> 6) == 3)\n\t\t\t\topcode = opcode.u.gdual->mod3[goffset];\n\t\t\telse\n\t\t\t\topcode = opcode.u.gdual->mod012[goffset];\n\t\t\tbreak;\n\t\tcase RMExt:\n\t\t\tgoffset = ctxt->modrm & 7;\n\t\t\topcode = opcode.u.group[goffset];\n\t\t\tbreak;\n\t\tcase Prefix:\n\t\t\tif (ctxt->rep_prefix && op_prefix)\n\t\t\t\treturn EMULATION_FAILED;\n\t\t\tsimd_prefix = op_prefix ? 0x66 : ctxt->rep_prefix;\n\t\t\tswitch (simd_prefix) {\n\t\t\tcase 0x00: opcode = opcode.u.gprefix->pfx_no; break;\n\t\t\tcase 0x66: opcode = opcode.u.gprefix->pfx_66; break;\n\t\t\tcase 0xf2: opcode = opcode.u.gprefix->pfx_f2; break;\n\t\t\tcase 0xf3: opcode = opcode.u.gprefix->pfx_f3; break;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase Escape:\n\t\t\tif (ctxt->modrm > 0xbf)\n\t\t\t\topcode = opcode.u.esc->high[ctxt->modrm - 0xc0];\n\t\t\telse\n\t\t\t\topcode = opcode.u.esc->op[(ctxt->modrm >> 3) & 7];\n\t\t\tbreak;\n\t\tdefault:\n\t\t\treturn EMULATION_FAILED;\n\t\t}\n\n\t\tctxt->d &= ~(u64)GroupMask;\n\t\tctxt->d |= opcode.flags;\n\t}\n\n\t/* Unrecognised? */\n\tif (ctxt->d == 0)\n\t\treturn EMULATION_FAILED;\n\n\tctxt->execute = opcode.u.execute;\n\n\tif (unlikely(ctxt->ud) && likely(!(ctxt->d & EmulateOnUD)))\n\t\treturn EMULATION_FAILED;\n\n\tif (unlikely(ctxt->d &\n\t\t     (NotImpl|Stack|Op3264|Sse|Mmx|Intercept|CheckPerm))) {\n\t\t/*\n\t\t * These are copied unconditionally here, and checked unconditionally\n\t\t * in x86_emulate_insn.\n\t\t */\n\t\tctxt->check_perm = opcode.check_perm;\n\t\tctxt->intercept = opcode.intercept;\n\n\t\tif (ctxt->d & NotImpl)\n\t\t\treturn EMULATION_FAILED;\n\n\t\tif (mode == X86EMUL_MODE_PROT64 && (ctxt->d & Stack))\n\t\t\tctxt->op_bytes = 8;\n\n\t\tif (ctxt->d & Op3264) {\n\t\t\tif (mode == X86EMUL_MODE_PROT64)\n\t\t\t\tctxt->op_bytes = 8;\n\t\t\telse\n\t\t\t\tctxt->op_bytes = 4;\n\t\t}\n\n\t\tif (ctxt->d & Sse)\n\t\t\tctxt->op_bytes = 16;\n\t\telse if (ctxt->d & Mmx)\n\t\t\tctxt->op_bytes = 8;\n\t}\n\n\t/* ModRM and SIB bytes. */\n\tif (ctxt->d & ModRM) {\n\t\trc = decode_modrm(ctxt, &ctxt->memop);\n\t\tif (!has_seg_override) {\n\t\t\thas_seg_override = true;\n\t\t\tctxt->seg_override = ctxt->modrm_seg;\n\t\t}\n\t} else if (ctxt->d & MemAbs)\n\t\trc = decode_abs(ctxt, &ctxt->memop);\n\tif (rc != X86EMUL_CONTINUE)\n\t\tgoto done;\n\n\tif (!has_seg_override)\n\t\tctxt->seg_override = VCPU_SREG_DS;\n\n\tctxt->memop.addr.mem.seg = ctxt->seg_override;\n\n\t/*\n\t * Decode and fetch the source operand: register, memory\n\t * or immediate.\n\t */\n\trc = decode_operand(ctxt, &ctxt->src, (ctxt->d >> SrcShift) & OpMask);\n\tif (rc != X86EMUL_CONTINUE)\n\t\tgoto done;\n\n\t/*\n\t * Decode and fetch the second source operand: register, memory\n\t * or immediate.\n\t */\n\trc = decode_operand(ctxt, &ctxt->src2, (ctxt->d >> Src2Shift) & OpMask);\n\tif (rc != X86EMUL_CONTINUE)\n\t\tgoto done;\n\n\t/* Decode and fetch the destination operand: register or memory. */\n\trc = decode_operand(ctxt, &ctxt->dst, (ctxt->d >> DstShift) & OpMask);\n\ndone:\n\tif (ctxt->rip_relative)\n\t\tctxt->memopp->addr.mem.ea += ctxt->_eip;\n\n\treturn (rc != X86EMUL_CONTINUE) ? EMULATION_FAILED : EMULATION_OK;\n}",
        "func": "int x86_decode_insn(struct x86_emulate_ctxt *ctxt, void *insn, int insn_len)\n{\n\tint rc = X86EMUL_CONTINUE;\n\tint mode = ctxt->mode;\n\tint def_op_bytes, def_ad_bytes, goffset, simd_prefix;\n\tbool op_prefix = false;\n\tbool has_seg_override = false;\n\tstruct opcode opcode;\n\n\tctxt->memop.type = OP_NONE;\n\tctxt->memopp = NULL;\n\tctxt->_eip = ctxt->eip;\n\tctxt->fetch.ptr = ctxt->fetch.data;\n\tctxt->fetch.end = ctxt->fetch.data + insn_len;\n\tctxt->opcode_len = 1;\n\tif (insn_len > 0)\n\t\tmemcpy(ctxt->fetch.data, insn, insn_len);\n\telse {\n\t\trc = __do_insn_fetch_bytes(ctxt, 1);\n\t\tif (rc != X86EMUL_CONTINUE)\n\t\t\treturn rc;\n\t}\n\n\tswitch (mode) {\n\tcase X86EMUL_MODE_REAL:\n\tcase X86EMUL_MODE_VM86:\n\tcase X86EMUL_MODE_PROT16:\n\t\tdef_op_bytes = def_ad_bytes = 2;\n\t\tbreak;\n\tcase X86EMUL_MODE_PROT32:\n\t\tdef_op_bytes = def_ad_bytes = 4;\n\t\tbreak;\n#ifdef CONFIG_X86_64\n\tcase X86EMUL_MODE_PROT64:\n\t\tdef_op_bytes = 4;\n\t\tdef_ad_bytes = 8;\n\t\tbreak;\n#endif\n\tdefault:\n\t\treturn EMULATION_FAILED;\n\t}\n\n\tctxt->op_bytes = def_op_bytes;\n\tctxt->ad_bytes = def_ad_bytes;\n\n\t/* Legacy prefixes. */\n\tfor (;;) {\n\t\tswitch (ctxt->b = insn_fetch(u8, ctxt)) {\n\t\tcase 0x66:\t/* operand-size override */\n\t\t\top_prefix = true;\n\t\t\t/* switch between 2/4 bytes */\n\t\t\tctxt->op_bytes = def_op_bytes ^ 6;\n\t\t\tbreak;\n\t\tcase 0x67:\t/* address-size override */\n\t\t\tif (mode == X86EMUL_MODE_PROT64)\n\t\t\t\t/* switch between 4/8 bytes */\n\t\t\t\tctxt->ad_bytes = def_ad_bytes ^ 12;\n\t\t\telse\n\t\t\t\t/* switch between 2/4 bytes */\n\t\t\t\tctxt->ad_bytes = def_ad_bytes ^ 6;\n\t\t\tbreak;\n\t\tcase 0x26:\t/* ES override */\n\t\tcase 0x2e:\t/* CS override */\n\t\tcase 0x36:\t/* SS override */\n\t\tcase 0x3e:\t/* DS override */\n\t\t\thas_seg_override = true;\n\t\t\tctxt->seg_override = (ctxt->b >> 3) & 3;\n\t\t\tbreak;\n\t\tcase 0x64:\t/* FS override */\n\t\tcase 0x65:\t/* GS override */\n\t\t\thas_seg_override = true;\n\t\t\tctxt->seg_override = ctxt->b & 7;\n\t\t\tbreak;\n\t\tcase 0x40 ... 0x4f: /* REX */\n\t\t\tif (mode != X86EMUL_MODE_PROT64)\n\t\t\t\tgoto done_prefixes;\n\t\t\tctxt->rex_prefix = ctxt->b;\n\t\t\tcontinue;\n\t\tcase 0xf0:\t/* LOCK */\n\t\t\tctxt->lock_prefix = 1;\n\t\t\tbreak;\n\t\tcase 0xf2:\t/* REPNE/REPNZ */\n\t\tcase 0xf3:\t/* REP/REPE/REPZ */\n\t\t\tctxt->rep_prefix = ctxt->b;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tgoto done_prefixes;\n\t\t}\n\n\t\t/* Any legacy prefix after a REX prefix nullifies its effect. */\n\n\t\tctxt->rex_prefix = 0;\n\t}\n\ndone_prefixes:\n\n\t/* REX prefix. */\n\tif (ctxt->rex_prefix & 8)\n\t\tctxt->op_bytes = 8;\t/* REX.W */\n\n\t/* Opcode byte(s). */\n\topcode = opcode_table[ctxt->b];\n\t/* Two-byte opcode? */\n\tif (ctxt->b == 0x0f) {\n\t\tctxt->opcode_len = 2;\n\t\tctxt->b = insn_fetch(u8, ctxt);\n\t\topcode = twobyte_table[ctxt->b];\n\n\t\t/* 0F_38 opcode map */\n\t\tif (ctxt->b == 0x38) {\n\t\t\tctxt->opcode_len = 3;\n\t\t\tctxt->b = insn_fetch(u8, ctxt);\n\t\t\topcode = opcode_map_0f_38[ctxt->b];\n\t\t}\n\t}\n\tctxt->d = opcode.flags;\n\n\tif (ctxt->d & ModRM)\n\t\tctxt->modrm = insn_fetch(u8, ctxt);\n\n\t/* vex-prefix instructions are not implemented */\n\tif (ctxt->opcode_len == 1 && (ctxt->b == 0xc5 || ctxt->b == 0xc4) &&\n\t    (mode == X86EMUL_MODE_PROT64 ||\n\t    (mode >= X86EMUL_MODE_PROT16 && (ctxt->modrm & 0x80)))) {\n\t\tctxt->d = NotImpl;\n\t}\n\n\twhile (ctxt->d & GroupMask) {\n\t\tswitch (ctxt->d & GroupMask) {\n\t\tcase Group:\n\t\t\tgoffset = (ctxt->modrm >> 3) & 7;\n\t\t\topcode = opcode.u.group[goffset];\n\t\t\tbreak;\n\t\tcase GroupDual:\n\t\t\tgoffset = (ctxt->modrm >> 3) & 7;\n\t\t\tif ((ctxt->modrm >> 6) == 3)\n\t\t\t\topcode = opcode.u.gdual->mod3[goffset];\n\t\t\telse\n\t\t\t\topcode = opcode.u.gdual->mod012[goffset];\n\t\t\tbreak;\n\t\tcase RMExt:\n\t\t\tgoffset = ctxt->modrm & 7;\n\t\t\topcode = opcode.u.group[goffset];\n\t\t\tbreak;\n\t\tcase Prefix:\n\t\t\tif (ctxt->rep_prefix && op_prefix)\n\t\t\t\treturn EMULATION_FAILED;\n\t\t\tsimd_prefix = op_prefix ? 0x66 : ctxt->rep_prefix;\n\t\t\tswitch (simd_prefix) {\n\t\t\tcase 0x00: opcode = opcode.u.gprefix->pfx_no; break;\n\t\t\tcase 0x66: opcode = opcode.u.gprefix->pfx_66; break;\n\t\t\tcase 0xf2: opcode = opcode.u.gprefix->pfx_f2; break;\n\t\t\tcase 0xf3: opcode = opcode.u.gprefix->pfx_f3; break;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase Escape:\n\t\t\tif (ctxt->modrm > 0xbf)\n\t\t\t\topcode = opcode.u.esc->high[ctxt->modrm - 0xc0];\n\t\t\telse\n\t\t\t\topcode = opcode.u.esc->op[(ctxt->modrm >> 3) & 7];\n\t\t\tbreak;\n\t\tdefault:\n\t\t\treturn EMULATION_FAILED;\n\t\t}\n\n\t\tctxt->d &= ~(u64)GroupMask;\n\t\tctxt->d |= opcode.flags;\n\t}\n\n\t/* Unrecognised? */\n\tif (ctxt->d == 0)\n\t\treturn EMULATION_FAILED;\n\n\tctxt->execute = opcode.u.execute;\n\n\tif (unlikely(ctxt->ud) && likely(!(ctxt->d & EmulateOnUD)))\n\t\treturn EMULATION_FAILED;\n\n\tif (unlikely(ctxt->d &\n\t\t     (NotImpl|Stack|Op3264|Sse|Mmx|Intercept|CheckPerm))) {\n\t\t/*\n\t\t * These are copied unconditionally here, and checked unconditionally\n\t\t * in x86_emulate_insn.\n\t\t */\n\t\tctxt->check_perm = opcode.check_perm;\n\t\tctxt->intercept = opcode.intercept;\n\n\t\tif (ctxt->d & NotImpl)\n\t\t\treturn EMULATION_FAILED;\n\n\t\tif (mode == X86EMUL_MODE_PROT64 && (ctxt->d & Stack))\n\t\t\tctxt->op_bytes = 8;\n\n\t\tif (ctxt->d & Op3264) {\n\t\t\tif (mode == X86EMUL_MODE_PROT64)\n\t\t\t\tctxt->op_bytes = 8;\n\t\t\telse\n\t\t\t\tctxt->op_bytes = 4;\n\t\t}\n\n\t\tif (ctxt->d & Sse)\n\t\t\tctxt->op_bytes = 16;\n\t\telse if (ctxt->d & Mmx)\n\t\t\tctxt->op_bytes = 8;\n\t}\n\n\t/* ModRM and SIB bytes. */\n\tif (ctxt->d & ModRM) {\n\t\trc = decode_modrm(ctxt, &ctxt->memop);\n\t\tif (!has_seg_override) {\n\t\t\thas_seg_override = true;\n\t\t\tctxt->seg_override = ctxt->modrm_seg;\n\t\t}\n\t} else if (ctxt->d & MemAbs)\n\t\trc = decode_abs(ctxt, &ctxt->memop);\n\tif (rc != X86EMUL_CONTINUE)\n\t\tgoto done;\n\n\tif (!has_seg_override)\n\t\tctxt->seg_override = VCPU_SREG_DS;\n\n\tctxt->memop.addr.mem.seg = ctxt->seg_override;\n\n\t/*\n\t * Decode and fetch the source operand: register, memory\n\t * or immediate.\n\t */\n\trc = decode_operand(ctxt, &ctxt->src, (ctxt->d >> SrcShift) & OpMask);\n\tif (rc != X86EMUL_CONTINUE)\n\t\tgoto done;\n\n\t/*\n\t * Decode and fetch the second source operand: register, memory\n\t * or immediate.\n\t */\n\trc = decode_operand(ctxt, &ctxt->src2, (ctxt->d >> Src2Shift) & OpMask);\n\tif (rc != X86EMUL_CONTINUE)\n\t\tgoto done;\n\n\t/* Decode and fetch the destination operand: register or memory. */\n\trc = decode_operand(ctxt, &ctxt->dst, (ctxt->d >> DstShift) & OpMask);\n\n\tif (ctxt->rip_relative)\n\t\tctxt->memopp->addr.mem.ea += ctxt->_eip;\n\ndone:\n\treturn (rc != X86EMUL_CONTINUE) ? EMULATION_FAILED : EMULATION_OK;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -240,9 +240,9 @@\n \t/* Decode and fetch the destination operand: register or memory. */\n \trc = decode_operand(ctxt, &ctxt->dst, (ctxt->d >> DstShift) & OpMask);\n \n-done:\n \tif (ctxt->rip_relative)\n \t\tctxt->memopp->addr.mem.ea += ctxt->_eip;\n \n+done:\n \treturn (rc != X86EMUL_CONTINUE) ? EMULATION_FAILED : EMULATION_OK;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "done:"
            ],
            "added_lines": [
                "done:"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-7907",
        "func_name": "chromium/ScreenOrientationController::unlock",
        "description": "Multiple use-after-free vulnerabilities in modules/screen_orientation/ScreenOrientationController.cpp in Blink, as used in Google Chrome before 39.0.2171.65, allow remote attackers to cause a denial of service or possibly have unspecified other impact via vectors that trigger improper handling of a detached frame, related to the (1) lock and (2) unlock methods.",
        "git_url": "https://github.com/chromium/chromium/commit/e3f00cea7287f6b4b69ed90cee5a19d74c5a3e51",
        "commit_title": "Disconnect from WebScreenOrientationClient when frame is detached.",
        "commit_text": "  ",
        "func_before": "void ScreenOrientationController::unlock()\n{\n    ASSERT(m_client);\n    m_client->unlockOrientation();\n}",
        "func": "void ScreenOrientationController::unlock()\n{\n    // When detached, the client is no longer valid.\n    if (!m_client)\n        return;\n    m_client->unlockOrientation();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,7 @@\n void ScreenOrientationController::unlock()\n {\n-    ASSERT(m_client);\n+    // When detached, the client is no longer valid.\n+    if (!m_client)\n+        return;\n     m_client->unlockOrientation();\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    ASSERT(m_client);"
            ],
            "added_lines": [
                "    // When detached, the client is no longer valid.",
                "    if (!m_client)",
                "        return;"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-7907",
        "func_name": "chromium/ScreenOrientationController::lock",
        "description": "Multiple use-after-free vulnerabilities in modules/screen_orientation/ScreenOrientationController.cpp in Blink, as used in Google Chrome before 39.0.2171.65, allow remote attackers to cause a denial of service or possibly have unspecified other impact via vectors that trigger improper handling of a detached frame, related to the (1) lock and (2) unlock methods.",
        "git_url": "https://github.com/chromium/chromium/commit/e3f00cea7287f6b4b69ed90cee5a19d74c5a3e51",
        "commit_title": "Disconnect from WebScreenOrientationClient when frame is detached.",
        "commit_text": "  ",
        "func_before": "void ScreenOrientationController::lock(WebScreenOrientationLockType orientation, WebLockOrientationCallback* callback)\n{\n    ASSERT(m_client);\n    m_client->lockOrientation(orientation, callback);\n}",
        "func": "void ScreenOrientationController::lock(WebScreenOrientationLockType orientation, WebLockOrientationCallback* callback)\n{\n    // When detached, the client is no longer valid.\n    if (!m_client)\n        return;\n    m_client->lockOrientation(orientation, callback);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,7 @@\n void ScreenOrientationController::lock(WebScreenOrientationLockType orientation, WebLockOrientationCallback* callback)\n {\n-    ASSERT(m_client);\n+    // When detached, the client is no longer valid.\n+    if (!m_client)\n+        return;\n     m_client->lockOrientation(orientation, callback);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    ASSERT(m_client);"
            ],
            "added_lines": [
                "    // When detached, the client is no longer valid.",
                "    if (!m_client)",
                "        return;"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-8714",
        "func_name": "wireshark/dissect_write_structured_field",
        "description": "The dissect_write_structured_field function in epan/dissectors/packet-tn5250.c in the TN5250 dissector in Wireshark 1.10.x before 1.10.11 and 1.12.x before 1.12.2 allows remote attackers to cause a denial of service (infinite loop) via a crafted packet.",
        "git_url": "https://github.com/wireshark/wireshark/commit/1463db37d9bbc9cd532afdf2817caaf8eb367831",
        "commit_title": "tn5220: prevent another potential endless loop",
        "commit_text": "exit the loop if dissect_unknown_data() returns 0 ",
        "func_before": "static guint32\ndissect_write_structured_field(proto_tree *tn5250_tree, tvbuff_t *tvb, gint offset)\n{\n  int start = offset;\n  guint16 sf_length = 0;\n  int length, type, done = 0, used = 0;\n\n  hf_items standard_fields[] = {\n    { &hf_tn5250_sf_length, 0, 2, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_sf_class, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_sf_type, 0, 1, 0, ENC_BIG_ENDIAN },\n    { NULL, 0, 0, 0, 0 }\n  };\n\n  static const int *qss_byte1[] = {\n    &hf_tn5250_wsf_qss_flag1_0,\n    &hf_tn5250_wsf_qss_flag1_reserved,\n    NULL\n  };\n\n  static const int *qss_byte2[] = {\n    &hf_tn5250_wsf_qss_flag2_reserved,\n    &hf_tn5250_wsf_qss_flag2_7,\n    NULL\n  };\n\n  hf_items qss_fields[] = {\n    { &hf_tn5250_wsf_qss_flag1, ett_tn5250_wsf_qss_mask, 1, qss_byte1, 0 },\n    { &hf_tn5250_wsf_qss_flag2, ett_tn5250_wsf_qss_mask, 1, qss_byte2, 0 },\n    { NULL, 0, 0, 0, 0 }\n  };\n\n  hf_items dawt_fields[] = {\n    { &hf_tn5250_dawt_length, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dawt_char, 0, 1, 0, ENC_EBCDIC|ENC_NA },\n    { NULL, 0, 0, 0, 0 }\n  };\n\n  hf_items dckf_fields[] = {\n    { &hf_tn5250_dckf_length, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dckf_key_code, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dckf_function_code, 0, 1, 0, ENC_BIG_ENDIAN },\n    { NULL, 0, 0, 0, 0 }\n  };\n\n  static const int *rts_byte1[] = {\n    &hf_tn5250_rts_flag1_0,\n    &hf_tn5250_rts_flag1_reserved,\n    NULL\n  };\n\n  hf_items rts_fields[] = {\n    { &hf_tn5250_rts_partition, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_rts_flag1, ett_tn5250_wsf_rts_mask, 1, rts_byte1, 0 },\n    { &hf_tn5250_reserved, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_reserved, 0, 1, 0, ENC_BIG_ENDIAN },\n    { NULL, 0, 0, 0, 0 }\n  };\n\n  static const int *dpo_byte1[] = {\n    &hf_tn5250_dpo_flag1_0,\n    &hf_tn5250_dpo_flag1_1,\n    &hf_tn5250_dpo_flag1_2,\n    &hf_tn5250_dpo_flag1_3,\n    &hf_tn5250_dpo_flag1_4,\n    &hf_tn5250_dpo_flag1_5,\n    &hf_tn5250_dpo_flag1_6,\n    &hf_tn5250_dpo_flag1_7,\n    NULL\n  };\n\n  static const int *dpo_byte2[] = {\n    &hf_tn5250_dpo_flag2_0,\n    &hf_tn5250_dpo_flag2_reserved,\n    NULL\n  };\n\n  hf_items dpo_fields[] = {\n    { &hf_tn5250_dpo_partition, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dpo_flag1, ett_tn5250_wsf_dpo_mask, 1, dpo_byte1, 0 },\n    { &hf_tn5250_dpo_flag2, ett_tn5250_wsf_dpo_mask, 1, dpo_byte2, 0 },\n    { &hf_tn5250_dpo_displace_characters, 0, 3, 0, ENC_EBCDIC|ENC_NA },\n    { &hf_tn5250_dpo_start_location_row, 0, 2, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dpo_start_location_col, 0, 2, 0, ENC_BIG_ENDIAN },\n    { NULL, 0, 0, 0, 0 }\n  };\n\n  static const int *dtsf_byte1[] = {\n    &hf_tn5250_dtsf_flag1_0,\n    &hf_tn5250_dtsf_flag1_1,\n    &hf_tn5250_dtsf_flag1_2,\n    &hf_tn5250_dtsf_flag1_3,\n    &hf_tn5250_dtsf_flag1_4,\n    &hf_tn5250_dtsf_flag1_5,\n    &hf_tn5250_dtsf_flag1_6,\n    &hf_tn5250_dtsf_flag1_7,\n    NULL\n  };\n\n  static const int *dtsf_byte2[] = {\n    &hf_tn5250_dtsf_flag2_0,\n    &hf_tn5250_dtsf_flag2_1,\n    &hf_tn5250_dtsf_flag2_2,\n    &hf_tn5250_dtsf_flag2_3,\n    &hf_tn5250_dtsf_flag2_4to7,\n    NULL\n  };\n\n  hf_items dtsf_fields[] = {\n    { &hf_tn5250_dtsf_partition, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dtsf_flag1, ett_tn5250_wsf_dtsf_mask, 1, dtsf_byte1, 0 },\n    { &hf_tn5250_dtsf_flag2, ett_tn5250_wsf_dtsf_mask, 1, dtsf_byte2, 0 },\n    { &hf_tn5250_dtsf_text_body_height, 0, 2, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dtsf_text_body_width, 0, 2, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dtsf_line_cmd_field_size, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dtsf_location_of_pitch, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dtsf_first_line, 0, 1, 0, ENC_BIG_ENDIAN },\n    { NULL, 0, 0, 0, 0 }\n  };\n\n  static const int *dsl_byte1[] = {\n    &hf_tn5250_dsl_flag1_0,\n    &hf_tn5250_dsl_flag1_1,\n    &hf_tn5250_dsl_flag1_2,\n    &hf_tn5250_dsl_flag1_reserved,\n    NULL\n  };\n\n  hf_items dsl_fields[] = {\n    { &hf_tn5250_dsl_partition, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_reserved, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dsl_rtl_offset, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dsl_offset, 0, 1, 0, ENC_BIG_ENDIAN },\n    { NULL, 0, 0, 0, 0 }\n  };\n\n  hf_items dsl_fields2[] = {\n    { &hf_tn5250_length, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dsl_flag1, ett_tn5250_wsf_dsl_mask, 1, dsl_byte1, 0 },\n    { &hf_tn5250_dsl_id, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dsl_location, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dsl_function, 0, 1, 0, ENC_BIG_ENDIAN },\n    { NULL, 0, 0, 0, 0 }\n  };\n\n  static const int *wts_byte1[] = {\n    &hf_tn5250_wts_flag1_0,\n    &hf_tn5250_wts_flag1_1,\n    &hf_tn5250_wts_flag1_2,\n    &hf_tn5250_wts_flag1_3,\n    &hf_tn5250_wts_flag1_reserved,\n    NULL\n  };\n\n  static const int *wts_byte2[] = {\n    &hf_tn5250_wts_flag2_reserved,\n    &hf_tn5250_wts_flag2_6,\n    &hf_tn5250_wts_flag2_reserved2,\n    NULL\n  };\n\n  static const int *wts_byte3[] = {\n    &hf_tn5250_wts_flag3_0,\n    &hf_tn5250_wts_flag3_1,\n    &hf_tn5250_wts_flag3_2,\n    &hf_tn5250_wts_flag3_3,\n    &hf_tn5250_wts_flag3_4,\n    &hf_tn5250_wts_flag3_5,\n    &hf_tn5250_wts_flag3_6,\n    &hf_tn5250_wts_flag3_7,\n    NULL\n  };\n\n  hf_items wts_fields[] = {\n    { &hf_tn5250_wts_partition, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_wts_flag1, ett_tn5250_wts_mask, 1, wts_byte1, 0 },\n    { &hf_tn5250_wts_flag2, ett_tn5250_wts_mask, 1, wts_byte2, 0 },\n    { &hf_tn5250_wts_flag3, ett_tn5250_wts_mask, 1, wts_byte3, 0 },\n    { &hf_tn5250_wts_home_position_row, 0, 2, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_wts_home_position_col, 0, 2, 0, ENC_BIG_ENDIAN },\n    { NULL, 0, 0, 0, 0 }\n  };\n\n  static const int *wts_cld_byte1[] = {\n    &hf_tn5250_wts_cld_flag1_0,\n    &hf_tn5250_wts_cld_flag1_1,\n    &hf_tn5250_wts_cld_flag1_2,\n    &hf_tn5250_wts_cld_flag1_3,\n    &hf_tn5250_wts_cld_flag1_4,\n    &hf_tn5250_wts_cld_flag1_5,\n    &hf_tn5250_wts_cld_flag1_6,\n    &hf_tn5250_wts_cld_flag1_7,\n    NULL\n  };\n\n  static const int *wts_cld_byte2[] = {\n    &hf_tn5250_wts_cld_flag2_0,\n    &hf_tn5250_wts_cld_flag2_1,\n    &hf_tn5250_wts_cld_flag2_2,\n    &hf_tn5250_wts_cld_flag2_3,\n    &hf_tn5250_wts_cld_flag2_4,\n    &hf_tn5250_wts_cld_flag2_line_spacing,\n    NULL\n  };\n\n  static const int *wts_cld_byte3[] = {\n    &hf_tn5250_wts_cld_flag3_0,\n    &hf_tn5250_wts_cld_flag3_1,\n    &hf_tn5250_wts_cld_flag3_2,\n    &hf_tn5250_wts_cld_flag3_3,\n    &hf_tn5250_wts_cld_flag3_4,\n    &hf_tn5250_wts_cld_flag3_5,\n    &hf_tn5250_wts_cld_flag3_6,\n    &hf_tn5250_wts_cld_flag3_7,\n    NULL\n  };\n\n  hf_items wts_line_data_fields[] = {\n    { &hf_tn5250_length, 0, 1, 0, ENC_BIG_ENDIAN }, /*FIXME: Could be one or two bytes! */\n    { &hf_tn5250_wts_cld_flag1, ett_tn5250_wts_mask, 1, wts_cld_byte1, 0 },\n    { &hf_tn5250_wts_cld_flag2, ett_tn5250_wts_mask, 1, wts_cld_byte2, 0 },\n    { &hf_tn5250_wts_cld_row, 0, 2, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_wts_cld_flag3, ett_tn5250_wts_mask, 1, wts_cld_byte3, 0 },\n    { &hf_tn5250_wts_cld_page_num, 0, 2, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_wts_cld_lmo, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_wts_cld_io, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_wts_cld_sli, 0, 1, 0, ENC_BIG_ENDIAN },\n    { NULL, 0, 0, 0, 0 }\n  };\n\n\n  hf_items dsc_fields[] = {\n    { &hf_tn5250_dsc_partition, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_reserved, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_reserved, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dsc_sk, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dsc_ev, 0, 1, 0, ENC_EBCDIC|ENC_NA },\n    { NULL, 0, 0, 0, 0 }\n  };\n\n  hf_items dorm_fields[] = {\n    { &hf_tn5250_dorm_length, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dorm_ec, 0, 2, 0, ENC_BIG_ENDIAN },\n    { NULL, 0, 0, 0, 0 }\n  };\n\n\n  static const int *dfdpck_coreflag[] = {\n    &hf_tn5250_dfdpck_coreflag_0,\n    &hf_tn5250_dfdpck_coreflag_1,\n    &hf_tn5250_dfdpck_coreflag_2,\n    &hf_tn5250_dfdpck_coreflag_3,\n    &hf_tn5250_dfdpck_coreflag_4,\n    &hf_tn5250_dfdpck_coreflag_5,\n    &hf_tn5250_dfdpck_coreflag_6,\n    &hf_tn5250_dfdpck_coreflag_7,\n    NULL\n  };\n\n  static const int *dfdpck_toprowflag1[] = {\n    &hf_tn5250_dfdpck_toprowflag1_0,\n    &hf_tn5250_dfdpck_toprowflag1_1,\n    &hf_tn5250_dfdpck_toprowflag1_2,\n    &hf_tn5250_dfdpck_toprowflag1_3,\n    &hf_tn5250_dfdpck_toprowflag1_4,\n    &hf_tn5250_dfdpck_toprowflag1_5,\n    &hf_tn5250_dfdpck_toprowflag1_6,\n    &hf_tn5250_dfdpck_toprowflag1_7,\n    NULL\n  };\n\n  static const int *dfdpck_toprowflag2[] = {\n    &hf_tn5250_dfdpck_toprowflag2_0,\n    &hf_tn5250_dfdpck_toprowflag2_1,\n    &hf_tn5250_dfdpck_toprowflag2_2,\n    &hf_tn5250_dfdpck_toprowflag2_3,\n    &hf_tn5250_dfdpck_toprowflag2_4,\n    &hf_tn5250_dfdpck_toprowflag2_5,\n    &hf_tn5250_dfdpck_toprowflag2_6,\n    &hf_tn5250_dfdpck_toprowflag2_7,\n    NULL\n  };\n\n  static const int *dfdpck_toprowflag3[] = {\n    &hf_tn5250_dfdpck_toprowflag3_0,\n    &hf_tn5250_dfdpck_toprowflag3_1,\n    &hf_tn5250_dfdpck_toprowflag3_2,\n    &hf_tn5250_dfdpck_toprowflag3_3,\n    &hf_tn5250_dfdpck_toprowflag3_4,\n    &hf_tn5250_dfdpck_toprowflag3_5,\n    &hf_tn5250_dfdpck_toprowflag3_6,\n    &hf_tn5250_dfdpck_toprowflag3_7,\n    NULL\n  };\n\n  hf_items dfdpck_fields[] = {\n    { &hf_tn5250_dfdpck_partition, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_reserved, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_reserved, 0, 1, 0, ENC_BIG_ENDIAN },\n    { NULL, 0, 0, 0, 0 }\n  };\n\n  hf_items dfdpck_core_area_fields[] = {\n    { &hf_tn5250_length, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dfdpck_data_field, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dfdpck_coreflag, ett_tn5250_dfdpck_mask, 1, dfdpck_coreflag, 0 },\n    { &hf_tn5250_reserved, 0, 1, 0, ENC_BIG_ENDIAN },\n    { NULL, 0, 0, 0, 0 }\n  };\n\n  hf_items dfdpck_top_row_fields[] = {\n    { &hf_tn5250_length, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dfdpck_data_field, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dfdpck_toprowflag1, ett_tn5250_dfdpck_mask, 1, dfdpck_toprowflag1, 0 },\n    { &hf_tn5250_dfdpck_toprowflag2, ett_tn5250_dfdpck_mask, 1, dfdpck_toprowflag2, 0 },\n    { &hf_tn5250_dfdpck_toprowflag3, ett_tn5250_dfdpck_mask, 1, dfdpck_toprowflag3, 0 },\n    { &hf_tn5250_reserved, 0, 1, 0, ENC_BIG_ENDIAN },\n    { NULL, 0, 0, 0, 0 }\n  };\n\n  while (tvb_reported_length_remaining(tvb, offset) > 0 && !done) {\n    sf_length = tvb_get_ntohs(tvb,offset);\n    type = tvb_get_guint8(tvb, offset+3);\n\n    offset += tn5250_add_hf_items(tn5250_tree, tvb, offset, standard_fields);\n\n    switch (type) {\n      case PASS_THROUGH:\n        proto_tree_add_item(tn5250_tree, hf_tn5250_field_data, tvb, offset,\n                            (sf_length - (start + offset)), ENC_EBCDIC|ENC_NA);\n        offset += (guint32)(sf_length - (start + offset));\n        break;\n      case TN5250_QUERY:\n        proto_tree_add_item(tn5250_tree, hf_tn5250_reserved, tvb, offset,\n                            1, ENC_BIG_ENDIAN);\n        offset ++;\n        break;\n      case TN5250_QUERY_STATION_STATE:\n        offset += tn5250_add_hf_items(tn5250_tree, tvb, offset, qss_fields);\n        break;\n      case DEFINE_AUDIT_WINDOW__TABLE:\n        proto_tree_add_item(tn5250_tree, hf_tn5250_dawt_id, tvb, offset,\n                            1, ENC_BIG_ENDIAN);\n        offset += 1;\n        while ((offset - start) < sf_length) {\n          length = tvb_get_guint8(tvb,offset);\n          offset += tn5250_add_hf_items(tn5250_tree, tvb, offset, dawt_fields);\n          if (length < 2) {\n            /* XXX - expert info on the length field */\n            break;\n          }\n          proto_tree_add_item(tn5250_tree, hf_tn5250_dawt_message, tvb, offset,\n                              (length - 2), ENC_EBCDIC|ENC_NA);\n          offset += length;\n        }\n        break;\n      case DEFINE_COMMAND_KEY_FUNCTION:\n        proto_tree_add_item(tn5250_tree, hf_tn5250_dckf_id, tvb, offset,\n                            1, ENC_BIG_ENDIAN);\n        offset++;\n        while ((offset - start) < sf_length) {\n          length = tvb_get_guint8(tvb,offset);\n          offset += tn5250_add_hf_items(tn5250_tree, tvb, offset,\n                                        dckf_fields);\n          if (length < 2) {\n            /* XXX - expert info on the length field */\n            break;\n          }\n          proto_tree_add_item(tn5250_tree, hf_tn5250_dckf_prompt_text, tvb,\n                              offset, (length - 2), ENC_EBCDIC|ENC_NA);\n          offset += length;\n        }\n        break;\n      case READ_TEXT_SCREEN:\n        offset += tn5250_add_hf_items(tn5250_tree, tvb, offset, rts_fields);\n        break;\n      case DEFINE_PENDING_OPERATIONS:\n        offset += tn5250_add_hf_items(tn5250_tree, tvb, offset, dpo_fields);\n        break;\n      case DEFINE_TEXT_SCREEN_FORMAT:\n        offset += tn5250_add_hf_items(tn5250_tree, tvb, offset, dtsf_fields);\n        break;\n      case DEFINE_SCALE_LINE:\n        offset += tn5250_add_hf_items(tn5250_tree, tvb, offset, dsl_fields);\n        while ((offset - start) < sf_length) {\n          /* XXX length unused\n          length = tvb_get_guint8(tvb,offset); */\n          offset += tn5250_add_hf_items(tn5250_tree, tvb, offset, dsl_fields2);\n        }\n        break;\n      case WRITE_TEXT_SCREEN:\n        offset += tn5250_add_hf_items(tn5250_tree, tvb, offset,\n                                      wts_fields);\n        length = tvb_get_guint8(tvb,offset);\n        used = tn5250_add_hf_items(tn5250_tree, tvb, offset,\n                                   wts_line_data_fields);\n        offset += used;\n        if (length < used) {\n          /* XXX - expert info on the length field */\n          break;\n        }\n        proto_tree_add_item(tn5250_tree, hf_tn5250_wts_cld_li, tvb, offset,\n                            (length - used), ENC_EBCDIC|ENC_NA);\n        break;\n      case DEFINE_SPECIAL_CHARACTERS:\n        offset += tn5250_add_hf_items(tn5250_tree, tvb, offset,\n                                      dsc_fields);\n        break;\n      case DEFINE_OPERATOR_ERROR_MESSAGES:\n        proto_tree_add_item(tn5250_tree, hf_tn5250_dorm_id, tvb, offset,\n                            1, ENC_BIG_ENDIAN);\n        offset++;\n        while ((offset - start) < sf_length) {\n          length = tvb_get_guint8(tvb,offset);\n          offset += tn5250_add_hf_items(tn5250_tree, tvb, offset,\n                                        dorm_fields);\n          if (length < 2) {\n            /* XXX - expert info on the length field */\n            break;\n          }\n          proto_tree_add_item(tn5250_tree, hf_tn5250_dorm_mt, tvb, offset,\n                              (length - 2), ENC_EBCDIC|ENC_NA);\n          offset += length;\n        }\n        break;\n      case DEFINE_PITCH_TABLE:\n        proto_tree_add_item(tn5250_tree, hf_tn5250_dpt_id, tvb, offset,\n                            1, ENC_BIG_ENDIAN);\n        offset++;\n        while ((offset - start) < sf_length) {\n          length = tvb_get_guint8(tvb,offset);\n          proto_tree_add_item(tn5250_tree, hf_tn5250_length, tvb, offset,\n                              1, ENC_BIG_ENDIAN);\n          offset++;\n          /*\n           * XXX - the documentation cited above says this is a\n           * \"4-byte EBCDIC code for the value of text pitch that is\n           * displayed on the status line\".  Does that mean that\n           * each of these entries is 5 bytes long?\n           */\n          proto_tree_add_item(tn5250_tree, hf_tn5250_dpt_ec, tvb, offset,\n                              4, ENC_EBCDIC|ENC_NA);\n          offset += 4;\n        }\n        break;\n      case DEFINE_FAKE_DP_COMMAND_KEY_FUNCTION:\n        offset += tn5250_add_hf_items(tn5250_tree, tvb, offset,\n                                      dfdpck_fields);\n        while ((offset - start) < sf_length) {\n          length = tvb_get_guint8(tvb,offset);\n          type = tvb_get_guint8(tvb,offset+1);\n          if (type == CORE_AREA_COMMAND_KEYS) {\n            offset += tn5250_add_hf_items(tn5250_tree, tvb, offset,\n                                          dfdpck_core_area_fields);\n          } else if (type == TOP_ROW_COMMAND_KEYS) {\n            offset += tn5250_add_hf_items(tn5250_tree, tvb, offset,\n                                          dfdpck_top_row_fields);\n          } else {\n            offset += dissect_unknown_data(tn5250_tree, tvb, offset, start, length);\n          }\n        }\n        break;\n      default:\n        done = 1;\n        break;\n    }\n  }\n\n  offset += dissect_unknown_data(tn5250_tree, tvb, offset, start, sf_length);\n\n  return (offset - start);\n}",
        "func": "static guint32\ndissect_write_structured_field(proto_tree *tn5250_tree, tvbuff_t *tvb, gint offset)\n{\n  int start = offset;\n  guint16 sf_length = 0;\n  int length, type, done = 0, used = 0;\n\n  hf_items standard_fields[] = {\n    { &hf_tn5250_sf_length, 0, 2, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_sf_class, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_sf_type, 0, 1, 0, ENC_BIG_ENDIAN },\n    { NULL, 0, 0, 0, 0 }\n  };\n\n  static const int *qss_byte1[] = {\n    &hf_tn5250_wsf_qss_flag1_0,\n    &hf_tn5250_wsf_qss_flag1_reserved,\n    NULL\n  };\n\n  static const int *qss_byte2[] = {\n    &hf_tn5250_wsf_qss_flag2_reserved,\n    &hf_tn5250_wsf_qss_flag2_7,\n    NULL\n  };\n\n  hf_items qss_fields[] = {\n    { &hf_tn5250_wsf_qss_flag1, ett_tn5250_wsf_qss_mask, 1, qss_byte1, 0 },\n    { &hf_tn5250_wsf_qss_flag2, ett_tn5250_wsf_qss_mask, 1, qss_byte2, 0 },\n    { NULL, 0, 0, 0, 0 }\n  };\n\n  hf_items dawt_fields[] = {\n    { &hf_tn5250_dawt_length, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dawt_char, 0, 1, 0, ENC_EBCDIC|ENC_NA },\n    { NULL, 0, 0, 0, 0 }\n  };\n\n  hf_items dckf_fields[] = {\n    { &hf_tn5250_dckf_length, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dckf_key_code, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dckf_function_code, 0, 1, 0, ENC_BIG_ENDIAN },\n    { NULL, 0, 0, 0, 0 }\n  };\n\n  static const int *rts_byte1[] = {\n    &hf_tn5250_rts_flag1_0,\n    &hf_tn5250_rts_flag1_reserved,\n    NULL\n  };\n\n  hf_items rts_fields[] = {\n    { &hf_tn5250_rts_partition, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_rts_flag1, ett_tn5250_wsf_rts_mask, 1, rts_byte1, 0 },\n    { &hf_tn5250_reserved, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_reserved, 0, 1, 0, ENC_BIG_ENDIAN },\n    { NULL, 0, 0, 0, 0 }\n  };\n\n  static const int *dpo_byte1[] = {\n    &hf_tn5250_dpo_flag1_0,\n    &hf_tn5250_dpo_flag1_1,\n    &hf_tn5250_dpo_flag1_2,\n    &hf_tn5250_dpo_flag1_3,\n    &hf_tn5250_dpo_flag1_4,\n    &hf_tn5250_dpo_flag1_5,\n    &hf_tn5250_dpo_flag1_6,\n    &hf_tn5250_dpo_flag1_7,\n    NULL\n  };\n\n  static const int *dpo_byte2[] = {\n    &hf_tn5250_dpo_flag2_0,\n    &hf_tn5250_dpo_flag2_reserved,\n    NULL\n  };\n\n  hf_items dpo_fields[] = {\n    { &hf_tn5250_dpo_partition, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dpo_flag1, ett_tn5250_wsf_dpo_mask, 1, dpo_byte1, 0 },\n    { &hf_tn5250_dpo_flag2, ett_tn5250_wsf_dpo_mask, 1, dpo_byte2, 0 },\n    { &hf_tn5250_dpo_displace_characters, 0, 3, 0, ENC_EBCDIC|ENC_NA },\n    { &hf_tn5250_dpo_start_location_row, 0, 2, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dpo_start_location_col, 0, 2, 0, ENC_BIG_ENDIAN },\n    { NULL, 0, 0, 0, 0 }\n  };\n\n  static const int *dtsf_byte1[] = {\n    &hf_tn5250_dtsf_flag1_0,\n    &hf_tn5250_dtsf_flag1_1,\n    &hf_tn5250_dtsf_flag1_2,\n    &hf_tn5250_dtsf_flag1_3,\n    &hf_tn5250_dtsf_flag1_4,\n    &hf_tn5250_dtsf_flag1_5,\n    &hf_tn5250_dtsf_flag1_6,\n    &hf_tn5250_dtsf_flag1_7,\n    NULL\n  };\n\n  static const int *dtsf_byte2[] = {\n    &hf_tn5250_dtsf_flag2_0,\n    &hf_tn5250_dtsf_flag2_1,\n    &hf_tn5250_dtsf_flag2_2,\n    &hf_tn5250_dtsf_flag2_3,\n    &hf_tn5250_dtsf_flag2_4to7,\n    NULL\n  };\n\n  hf_items dtsf_fields[] = {\n    { &hf_tn5250_dtsf_partition, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dtsf_flag1, ett_tn5250_wsf_dtsf_mask, 1, dtsf_byte1, 0 },\n    { &hf_tn5250_dtsf_flag2, ett_tn5250_wsf_dtsf_mask, 1, dtsf_byte2, 0 },\n    { &hf_tn5250_dtsf_text_body_height, 0, 2, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dtsf_text_body_width, 0, 2, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dtsf_line_cmd_field_size, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dtsf_location_of_pitch, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dtsf_first_line, 0, 1, 0, ENC_BIG_ENDIAN },\n    { NULL, 0, 0, 0, 0 }\n  };\n\n  static const int *dsl_byte1[] = {\n    &hf_tn5250_dsl_flag1_0,\n    &hf_tn5250_dsl_flag1_1,\n    &hf_tn5250_dsl_flag1_2,\n    &hf_tn5250_dsl_flag1_reserved,\n    NULL\n  };\n\n  hf_items dsl_fields[] = {\n    { &hf_tn5250_dsl_partition, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_reserved, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dsl_rtl_offset, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dsl_offset, 0, 1, 0, ENC_BIG_ENDIAN },\n    { NULL, 0, 0, 0, 0 }\n  };\n\n  hf_items dsl_fields2[] = {\n    { &hf_tn5250_length, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dsl_flag1, ett_tn5250_wsf_dsl_mask, 1, dsl_byte1, 0 },\n    { &hf_tn5250_dsl_id, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dsl_location, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dsl_function, 0, 1, 0, ENC_BIG_ENDIAN },\n    { NULL, 0, 0, 0, 0 }\n  };\n\n  static const int *wts_byte1[] = {\n    &hf_tn5250_wts_flag1_0,\n    &hf_tn5250_wts_flag1_1,\n    &hf_tn5250_wts_flag1_2,\n    &hf_tn5250_wts_flag1_3,\n    &hf_tn5250_wts_flag1_reserved,\n    NULL\n  };\n\n  static const int *wts_byte2[] = {\n    &hf_tn5250_wts_flag2_reserved,\n    &hf_tn5250_wts_flag2_6,\n    &hf_tn5250_wts_flag2_reserved2,\n    NULL\n  };\n\n  static const int *wts_byte3[] = {\n    &hf_tn5250_wts_flag3_0,\n    &hf_tn5250_wts_flag3_1,\n    &hf_tn5250_wts_flag3_2,\n    &hf_tn5250_wts_flag3_3,\n    &hf_tn5250_wts_flag3_4,\n    &hf_tn5250_wts_flag3_5,\n    &hf_tn5250_wts_flag3_6,\n    &hf_tn5250_wts_flag3_7,\n    NULL\n  };\n\n  hf_items wts_fields[] = {\n    { &hf_tn5250_wts_partition, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_wts_flag1, ett_tn5250_wts_mask, 1, wts_byte1, 0 },\n    { &hf_tn5250_wts_flag2, ett_tn5250_wts_mask, 1, wts_byte2, 0 },\n    { &hf_tn5250_wts_flag3, ett_tn5250_wts_mask, 1, wts_byte3, 0 },\n    { &hf_tn5250_wts_home_position_row, 0, 2, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_wts_home_position_col, 0, 2, 0, ENC_BIG_ENDIAN },\n    { NULL, 0, 0, 0, 0 }\n  };\n\n  static const int *wts_cld_byte1[] = {\n    &hf_tn5250_wts_cld_flag1_0,\n    &hf_tn5250_wts_cld_flag1_1,\n    &hf_tn5250_wts_cld_flag1_2,\n    &hf_tn5250_wts_cld_flag1_3,\n    &hf_tn5250_wts_cld_flag1_4,\n    &hf_tn5250_wts_cld_flag1_5,\n    &hf_tn5250_wts_cld_flag1_6,\n    &hf_tn5250_wts_cld_flag1_7,\n    NULL\n  };\n\n  static const int *wts_cld_byte2[] = {\n    &hf_tn5250_wts_cld_flag2_0,\n    &hf_tn5250_wts_cld_flag2_1,\n    &hf_tn5250_wts_cld_flag2_2,\n    &hf_tn5250_wts_cld_flag2_3,\n    &hf_tn5250_wts_cld_flag2_4,\n    &hf_tn5250_wts_cld_flag2_line_spacing,\n    NULL\n  };\n\n  static const int *wts_cld_byte3[] = {\n    &hf_tn5250_wts_cld_flag3_0,\n    &hf_tn5250_wts_cld_flag3_1,\n    &hf_tn5250_wts_cld_flag3_2,\n    &hf_tn5250_wts_cld_flag3_3,\n    &hf_tn5250_wts_cld_flag3_4,\n    &hf_tn5250_wts_cld_flag3_5,\n    &hf_tn5250_wts_cld_flag3_6,\n    &hf_tn5250_wts_cld_flag3_7,\n    NULL\n  };\n\n  hf_items wts_line_data_fields[] = {\n    { &hf_tn5250_length, 0, 1, 0, ENC_BIG_ENDIAN }, /*FIXME: Could be one or two bytes! */\n    { &hf_tn5250_wts_cld_flag1, ett_tn5250_wts_mask, 1, wts_cld_byte1, 0 },\n    { &hf_tn5250_wts_cld_flag2, ett_tn5250_wts_mask, 1, wts_cld_byte2, 0 },\n    { &hf_tn5250_wts_cld_row, 0, 2, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_wts_cld_flag3, ett_tn5250_wts_mask, 1, wts_cld_byte3, 0 },\n    { &hf_tn5250_wts_cld_page_num, 0, 2, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_wts_cld_lmo, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_wts_cld_io, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_wts_cld_sli, 0, 1, 0, ENC_BIG_ENDIAN },\n    { NULL, 0, 0, 0, 0 }\n  };\n\n\n  hf_items dsc_fields[] = {\n    { &hf_tn5250_dsc_partition, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_reserved, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_reserved, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dsc_sk, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dsc_ev, 0, 1, 0, ENC_EBCDIC|ENC_NA },\n    { NULL, 0, 0, 0, 0 }\n  };\n\n  hf_items dorm_fields[] = {\n    { &hf_tn5250_dorm_length, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dorm_ec, 0, 2, 0, ENC_BIG_ENDIAN },\n    { NULL, 0, 0, 0, 0 }\n  };\n\n\n  static const int *dfdpck_coreflag[] = {\n    &hf_tn5250_dfdpck_coreflag_0,\n    &hf_tn5250_dfdpck_coreflag_1,\n    &hf_tn5250_dfdpck_coreflag_2,\n    &hf_tn5250_dfdpck_coreflag_3,\n    &hf_tn5250_dfdpck_coreflag_4,\n    &hf_tn5250_dfdpck_coreflag_5,\n    &hf_tn5250_dfdpck_coreflag_6,\n    &hf_tn5250_dfdpck_coreflag_7,\n    NULL\n  };\n\n  static const int *dfdpck_toprowflag1[] = {\n    &hf_tn5250_dfdpck_toprowflag1_0,\n    &hf_tn5250_dfdpck_toprowflag1_1,\n    &hf_tn5250_dfdpck_toprowflag1_2,\n    &hf_tn5250_dfdpck_toprowflag1_3,\n    &hf_tn5250_dfdpck_toprowflag1_4,\n    &hf_tn5250_dfdpck_toprowflag1_5,\n    &hf_tn5250_dfdpck_toprowflag1_6,\n    &hf_tn5250_dfdpck_toprowflag1_7,\n    NULL\n  };\n\n  static const int *dfdpck_toprowflag2[] = {\n    &hf_tn5250_dfdpck_toprowflag2_0,\n    &hf_tn5250_dfdpck_toprowflag2_1,\n    &hf_tn5250_dfdpck_toprowflag2_2,\n    &hf_tn5250_dfdpck_toprowflag2_3,\n    &hf_tn5250_dfdpck_toprowflag2_4,\n    &hf_tn5250_dfdpck_toprowflag2_5,\n    &hf_tn5250_dfdpck_toprowflag2_6,\n    &hf_tn5250_dfdpck_toprowflag2_7,\n    NULL\n  };\n\n  static const int *dfdpck_toprowflag3[] = {\n    &hf_tn5250_dfdpck_toprowflag3_0,\n    &hf_tn5250_dfdpck_toprowflag3_1,\n    &hf_tn5250_dfdpck_toprowflag3_2,\n    &hf_tn5250_dfdpck_toprowflag3_3,\n    &hf_tn5250_dfdpck_toprowflag3_4,\n    &hf_tn5250_dfdpck_toprowflag3_5,\n    &hf_tn5250_dfdpck_toprowflag3_6,\n    &hf_tn5250_dfdpck_toprowflag3_7,\n    NULL\n  };\n\n  hf_items dfdpck_fields[] = {\n    { &hf_tn5250_dfdpck_partition, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_reserved, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_reserved, 0, 1, 0, ENC_BIG_ENDIAN },\n    { NULL, 0, 0, 0, 0 }\n  };\n\n  hf_items dfdpck_core_area_fields[] = {\n    { &hf_tn5250_length, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dfdpck_data_field, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dfdpck_coreflag, ett_tn5250_dfdpck_mask, 1, dfdpck_coreflag, 0 },\n    { &hf_tn5250_reserved, 0, 1, 0, ENC_BIG_ENDIAN },\n    { NULL, 0, 0, 0, 0 }\n  };\n\n  hf_items dfdpck_top_row_fields[] = {\n    { &hf_tn5250_length, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dfdpck_data_field, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dfdpck_toprowflag1, ett_tn5250_dfdpck_mask, 1, dfdpck_toprowflag1, 0 },\n    { &hf_tn5250_dfdpck_toprowflag2, ett_tn5250_dfdpck_mask, 1, dfdpck_toprowflag2, 0 },\n    { &hf_tn5250_dfdpck_toprowflag3, ett_tn5250_dfdpck_mask, 1, dfdpck_toprowflag3, 0 },\n    { &hf_tn5250_reserved, 0, 1, 0, ENC_BIG_ENDIAN },\n    { NULL, 0, 0, 0, 0 }\n  };\n\n  while (tvb_reported_length_remaining(tvb, offset) > 0 && !done) {\n    sf_length = tvb_get_ntohs(tvb,offset);\n    type = tvb_get_guint8(tvb, offset+3);\n\n    offset += tn5250_add_hf_items(tn5250_tree, tvb, offset, standard_fields);\n\n    switch (type) {\n      case PASS_THROUGH:\n        proto_tree_add_item(tn5250_tree, hf_tn5250_field_data, tvb, offset,\n                            (sf_length - (start + offset)), ENC_EBCDIC|ENC_NA);\n        offset += (guint32)(sf_length - (start + offset));\n        break;\n      case TN5250_QUERY:\n        proto_tree_add_item(tn5250_tree, hf_tn5250_reserved, tvb, offset,\n                            1, ENC_BIG_ENDIAN);\n        offset ++;\n        break;\n      case TN5250_QUERY_STATION_STATE:\n        offset += tn5250_add_hf_items(tn5250_tree, tvb, offset, qss_fields);\n        break;\n      case DEFINE_AUDIT_WINDOW__TABLE:\n        proto_tree_add_item(tn5250_tree, hf_tn5250_dawt_id, tvb, offset,\n                            1, ENC_BIG_ENDIAN);\n        offset += 1;\n        while ((offset - start) < sf_length) {\n          length = tvb_get_guint8(tvb,offset);\n          offset += tn5250_add_hf_items(tn5250_tree, tvb, offset, dawt_fields);\n          if (length < 2) {\n            /* XXX - expert info on the length field */\n            break;\n          }\n          proto_tree_add_item(tn5250_tree, hf_tn5250_dawt_message, tvb, offset,\n                              (length - 2), ENC_EBCDIC|ENC_NA);\n          offset += length;\n        }\n        break;\n      case DEFINE_COMMAND_KEY_FUNCTION:\n        proto_tree_add_item(tn5250_tree, hf_tn5250_dckf_id, tvb, offset,\n                            1, ENC_BIG_ENDIAN);\n        offset++;\n        while ((offset - start) < sf_length) {\n          length = tvb_get_guint8(tvb,offset);\n          offset += tn5250_add_hf_items(tn5250_tree, tvb, offset,\n                                        dckf_fields);\n          if (length < 2) {\n            /* XXX - expert info on the length field */\n            break;\n          }\n          proto_tree_add_item(tn5250_tree, hf_tn5250_dckf_prompt_text, tvb,\n                              offset, (length - 2), ENC_EBCDIC|ENC_NA);\n          offset += length;\n        }\n        break;\n      case READ_TEXT_SCREEN:\n        offset += tn5250_add_hf_items(tn5250_tree, tvb, offset, rts_fields);\n        break;\n      case DEFINE_PENDING_OPERATIONS:\n        offset += tn5250_add_hf_items(tn5250_tree, tvb, offset, dpo_fields);\n        break;\n      case DEFINE_TEXT_SCREEN_FORMAT:\n        offset += tn5250_add_hf_items(tn5250_tree, tvb, offset, dtsf_fields);\n        break;\n      case DEFINE_SCALE_LINE:\n        offset += tn5250_add_hf_items(tn5250_tree, tvb, offset, dsl_fields);\n        while ((offset - start) < sf_length) {\n          /* XXX length unused\n          length = tvb_get_guint8(tvb,offset); */\n          offset += tn5250_add_hf_items(tn5250_tree, tvb, offset, dsl_fields2);\n        }\n        break;\n      case WRITE_TEXT_SCREEN:\n        offset += tn5250_add_hf_items(tn5250_tree, tvb, offset,\n                                      wts_fields);\n        length = tvb_get_guint8(tvb,offset);\n        used = tn5250_add_hf_items(tn5250_tree, tvb, offset,\n                                   wts_line_data_fields);\n        offset += used;\n        if (length < used) {\n          /* XXX - expert info on the length field */\n          break;\n        }\n        proto_tree_add_item(tn5250_tree, hf_tn5250_wts_cld_li, tvb, offset,\n                            (length - used), ENC_EBCDIC|ENC_NA);\n        break;\n      case DEFINE_SPECIAL_CHARACTERS:\n        offset += tn5250_add_hf_items(tn5250_tree, tvb, offset,\n                                      dsc_fields);\n        break;\n      case DEFINE_OPERATOR_ERROR_MESSAGES:\n        proto_tree_add_item(tn5250_tree, hf_tn5250_dorm_id, tvb, offset,\n                            1, ENC_BIG_ENDIAN);\n        offset++;\n        while ((offset - start) < sf_length) {\n          length = tvb_get_guint8(tvb,offset);\n          offset += tn5250_add_hf_items(tn5250_tree, tvb, offset,\n                                        dorm_fields);\n          if (length < 2) {\n            /* XXX - expert info on the length field */\n            break;\n          }\n          proto_tree_add_item(tn5250_tree, hf_tn5250_dorm_mt, tvb, offset,\n                              (length - 2), ENC_EBCDIC|ENC_NA);\n          offset += length;\n        }\n        break;\n      case DEFINE_PITCH_TABLE:\n        proto_tree_add_item(tn5250_tree, hf_tn5250_dpt_id, tvb, offset,\n                            1, ENC_BIG_ENDIAN);\n        offset++;\n        while ((offset - start) < sf_length) {\n          length = tvb_get_guint8(tvb,offset);\n          proto_tree_add_item(tn5250_tree, hf_tn5250_length, tvb, offset,\n                              1, ENC_BIG_ENDIAN);\n          offset++;\n          /*\n           * XXX - the documentation cited above says this is a\n           * \"4-byte EBCDIC code for the value of text pitch that is\n           * displayed on the status line\".  Does that mean that\n           * each of these entries is 5 bytes long?\n           */\n          proto_tree_add_item(tn5250_tree, hf_tn5250_dpt_ec, tvb, offset,\n                              4, ENC_EBCDIC|ENC_NA);\n          offset += 4;\n        }\n        break;\n      case DEFINE_FAKE_DP_COMMAND_KEY_FUNCTION:\n        offset += tn5250_add_hf_items(tn5250_tree, tvb, offset,\n                                      dfdpck_fields);\n        while ((offset - start) < sf_length) {\n          length = tvb_get_guint8(tvb,offset);\n          type = tvb_get_guint8(tvb,offset+1);\n          if (type == CORE_AREA_COMMAND_KEYS) {\n            offset += tn5250_add_hf_items(tn5250_tree, tvb, offset,\n                                          dfdpck_core_area_fields);\n          } else if (type == TOP_ROW_COMMAND_KEYS) {\n            offset += tn5250_add_hf_items(tn5250_tree, tvb, offset,\n                                          dfdpck_top_row_fields);\n          } else {\n            guint32 step;\n\n            step = dissect_unknown_data(tn5250_tree, tvb, offset, start, length);\n            if (step==0)\n              break;\n            offset += step;\n          }\n        }\n        break;\n      default:\n        done = 1;\n        break;\n    }\n  }\n\n  offset += dissect_unknown_data(tn5250_tree, tvb, offset, start, sf_length);\n\n  return (offset - start);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -456,7 +456,12 @@\n             offset += tn5250_add_hf_items(tn5250_tree, tvb, offset,\n                                           dfdpck_top_row_fields);\n           } else {\n-            offset += dissect_unknown_data(tn5250_tree, tvb, offset, start, length);\n+            guint32 step;\n+\n+            step = dissect_unknown_data(tn5250_tree, tvb, offset, start, length);\n+            if (step==0)\n+              break;\n+            offset += step;\n           }\n         }\n         break;",
        "diff_line_info": {
            "deleted_lines": [
                "            offset += dissect_unknown_data(tn5250_tree, tvb, offset, start, length);"
            ],
            "added_lines": [
                "            guint32 step;",
                "",
                "            step = dissect_unknown_data(tn5250_tree, tvb, offset, start, length);",
                "            if (step==0)",
                "              break;",
                "            offset += step;"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-8714",
        "func_name": "wireshark/dissect_write_structured_field",
        "description": "The dissect_write_structured_field function in epan/dissectors/packet-tn5250.c in the TN5250 dissector in Wireshark 1.10.x before 1.10.11 and 1.12.x before 1.12.2 allows remote attackers to cause a denial of service (infinite loop) via a crafted packet.",
        "git_url": "https://github.com/wireshark/wireshark/commit/bc2726578156f3608960fc65ce1f691639e6addc",
        "commit_title": "tn5250: fix an endless loop, exit when offset is not incremented",
        "commit_text": " Bug: 10596",
        "func_before": "static guint32\ndissect_write_structured_field(proto_tree *tn5250_tree, tvbuff_t *tvb, gint offset)\n{\n  int start = offset;\n  guint16 sf_length = 0;\n  int length, type, done = 0, used = 0;\n\n  hf_items standard_fields[] = {\n    { &hf_tn5250_sf_length, 0, 2, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_sf_class, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_sf_type, 0, 1, 0, ENC_BIG_ENDIAN },\n    { NULL, 0, 0, 0, 0 }\n  };\n\n  static const int *qss_byte1[] = {\n    &hf_tn5250_wsf_qss_flag1_0,\n    &hf_tn5250_wsf_qss_flag1_reserved,\n    NULL\n  };\n\n  static const int *qss_byte2[] = {\n    &hf_tn5250_wsf_qss_flag2_reserved,\n    &hf_tn5250_wsf_qss_flag2_7,\n    NULL\n  };\n\n  hf_items qss_fields[] = {\n    { &hf_tn5250_wsf_qss_flag1, ett_tn5250_wsf_qss_mask, 1, qss_byte1, 0 },\n    { &hf_tn5250_wsf_qss_flag2, ett_tn5250_wsf_qss_mask, 1, qss_byte2, 0 },\n    { NULL, 0, 0, 0, 0 }\n  };\n\n  hf_items dawt_fields[] = {\n    { &hf_tn5250_dawt_length, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dawt_char, 0, 1, 0, ENC_EBCDIC|ENC_NA },\n    { NULL, 0, 0, 0, 0 }\n  };\n\n  hf_items dckf_fields[] = {\n    { &hf_tn5250_dckf_length, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dckf_key_code, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dckf_function_code, 0, 1, 0, ENC_BIG_ENDIAN },\n    { NULL, 0, 0, 0, 0 }\n  };\n\n  static const int *rts_byte1[] = {\n    &hf_tn5250_rts_flag1_0,\n    &hf_tn5250_rts_flag1_reserved,\n    NULL\n  };\n\n  hf_items rts_fields[] = {\n    { &hf_tn5250_rts_partition, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_rts_flag1, ett_tn5250_wsf_rts_mask, 1, rts_byte1, 0 },\n    { &hf_tn5250_reserved, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_reserved, 0, 1, 0, ENC_BIG_ENDIAN },\n    { NULL, 0, 0, 0, 0 }\n  };\n\n  static const int *dpo_byte1[] = {\n    &hf_tn5250_dpo_flag1_0,\n    &hf_tn5250_dpo_flag1_1,\n    &hf_tn5250_dpo_flag1_2,\n    &hf_tn5250_dpo_flag1_3,\n    &hf_tn5250_dpo_flag1_4,\n    &hf_tn5250_dpo_flag1_5,\n    &hf_tn5250_dpo_flag1_6,\n    &hf_tn5250_dpo_flag1_7,\n    NULL\n  };\n\n  static const int *dpo_byte2[] = {\n    &hf_tn5250_dpo_flag2_0,\n    &hf_tn5250_dpo_flag2_reserved,\n    NULL\n  };\n\n  hf_items dpo_fields[] = {\n    { &hf_tn5250_dpo_partition, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dpo_flag1, ett_tn5250_wsf_dpo_mask, 1, dpo_byte1, 0 },\n    { &hf_tn5250_dpo_flag2, ett_tn5250_wsf_dpo_mask, 1, dpo_byte2, 0 },\n    { &hf_tn5250_dpo_displace_characters, 0, 3, 0, ENC_EBCDIC|ENC_NA },\n    { &hf_tn5250_dpo_start_location_row, 0, 2, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dpo_start_location_col, 0, 2, 0, ENC_BIG_ENDIAN },\n    { NULL, 0, 0, 0, 0 }\n  };\n\n  static const int *dtsf_byte1[] = {\n    &hf_tn5250_dtsf_flag1_0,\n    &hf_tn5250_dtsf_flag1_1,\n    &hf_tn5250_dtsf_flag1_2,\n    &hf_tn5250_dtsf_flag1_3,\n    &hf_tn5250_dtsf_flag1_4,\n    &hf_tn5250_dtsf_flag1_5,\n    &hf_tn5250_dtsf_flag1_6,\n    &hf_tn5250_dtsf_flag1_7,\n    NULL\n  };\n\n  static const int *dtsf_byte2[] = {\n    &hf_tn5250_dtsf_flag2_0,\n    &hf_tn5250_dtsf_flag2_1,\n    &hf_tn5250_dtsf_flag2_2,\n    &hf_tn5250_dtsf_flag2_3,\n    &hf_tn5250_dtsf_flag2_4to7,\n    NULL\n  };\n\n  hf_items dtsf_fields[] = {\n    { &hf_tn5250_dtsf_partition, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dtsf_flag1, ett_tn5250_wsf_dtsf_mask, 1, dtsf_byte1, 0 },\n    { &hf_tn5250_dtsf_flag2, ett_tn5250_wsf_dtsf_mask, 1, dtsf_byte2, 0 },\n    { &hf_tn5250_dtsf_text_body_height, 0, 2, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dtsf_text_body_width, 0, 2, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dtsf_line_cmd_field_size, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dtsf_location_of_pitch, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dtsf_first_line, 0, 1, 0, ENC_BIG_ENDIAN },\n    { NULL, 0, 0, 0, 0 }\n  };\n\n  static const int *dsl_byte1[] = {\n    &hf_tn5250_dsl_flag1_0,\n    &hf_tn5250_dsl_flag1_1,\n    &hf_tn5250_dsl_flag1_2,\n    &hf_tn5250_dsl_flag1_reserved,\n    NULL\n  };\n\n  hf_items dsl_fields[] = {\n    { &hf_tn5250_dsl_partition, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_reserved, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dsl_rtl_offset, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dsl_offset, 0, 1, 0, ENC_BIG_ENDIAN },\n    { NULL, 0, 0, 0, 0 }\n  };\n\n  hf_items dsl_fields2[] = {\n    { &hf_tn5250_length, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dsl_flag1, ett_tn5250_wsf_dsl_mask, 1, dsl_byte1, 0 },\n    { &hf_tn5250_dsl_id, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dsl_location, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dsl_function, 0, 1, 0, ENC_BIG_ENDIAN },\n    { NULL, 0, 0, 0, 0 }\n  };\n\n  static const int *wts_byte1[] = {\n    &hf_tn5250_wts_flag1_0,\n    &hf_tn5250_wts_flag1_1,\n    &hf_tn5250_wts_flag1_2,\n    &hf_tn5250_wts_flag1_3,\n    &hf_tn5250_wts_flag1_reserved,\n    NULL\n  };\n\n  static const int *wts_byte2[] = {\n    &hf_tn5250_wts_flag2_reserved,\n    &hf_tn5250_wts_flag2_6,\n    &hf_tn5250_wts_flag2_reserved2,\n    NULL\n  };\n\n  static const int *wts_byte3[] = {\n    &hf_tn5250_wts_flag3_0,\n    &hf_tn5250_wts_flag3_1,\n    &hf_tn5250_wts_flag3_2,\n    &hf_tn5250_wts_flag3_3,\n    &hf_tn5250_wts_flag3_4,\n    &hf_tn5250_wts_flag3_5,\n    &hf_tn5250_wts_flag3_6,\n    &hf_tn5250_wts_flag3_7,\n    NULL\n  };\n\n  hf_items wts_fields[] = {\n    { &hf_tn5250_wts_partition, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_wts_flag1, ett_tn5250_wts_mask, 1, wts_byte1, 0 },\n    { &hf_tn5250_wts_flag2, ett_tn5250_wts_mask, 1, wts_byte2, 0 },\n    { &hf_tn5250_wts_flag3, ett_tn5250_wts_mask, 1, wts_byte3, 0 },\n    { &hf_tn5250_wts_home_position_row, 0, 2, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_wts_home_position_col, 0, 2, 0, ENC_BIG_ENDIAN },\n    { NULL, 0, 0, 0, 0 }\n  };\n\n  static const int *wts_cld_byte1[] = {\n    &hf_tn5250_wts_cld_flag1_0,\n    &hf_tn5250_wts_cld_flag1_1,\n    &hf_tn5250_wts_cld_flag1_2,\n    &hf_tn5250_wts_cld_flag1_3,\n    &hf_tn5250_wts_cld_flag1_4,\n    &hf_tn5250_wts_cld_flag1_5,\n    &hf_tn5250_wts_cld_flag1_6,\n    &hf_tn5250_wts_cld_flag1_7,\n    NULL\n  };\n\n  static const int *wts_cld_byte2[] = {\n    &hf_tn5250_wts_cld_flag2_0,\n    &hf_tn5250_wts_cld_flag2_1,\n    &hf_tn5250_wts_cld_flag2_2,\n    &hf_tn5250_wts_cld_flag2_3,\n    &hf_tn5250_wts_cld_flag2_4,\n    &hf_tn5250_wts_cld_flag2_line_spacing,\n    NULL\n  };\n\n  static const int *wts_cld_byte3[] = {\n    &hf_tn5250_wts_cld_flag3_0,\n    &hf_tn5250_wts_cld_flag3_1,\n    &hf_tn5250_wts_cld_flag3_2,\n    &hf_tn5250_wts_cld_flag3_3,\n    &hf_tn5250_wts_cld_flag3_4,\n    &hf_tn5250_wts_cld_flag3_5,\n    &hf_tn5250_wts_cld_flag3_6,\n    &hf_tn5250_wts_cld_flag3_7,\n    NULL\n  };\n\n  hf_items wts_line_data_fields[] = {\n    { &hf_tn5250_length, 0, 1, 0, ENC_BIG_ENDIAN }, /*FIXME: Could be one or two bytes! */\n    { &hf_tn5250_wts_cld_flag1, ett_tn5250_wts_mask, 1, wts_cld_byte1, 0 },\n    { &hf_tn5250_wts_cld_flag2, ett_tn5250_wts_mask, 1, wts_cld_byte2, 0 },\n    { &hf_tn5250_wts_cld_row, 0, 2, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_wts_cld_flag3, ett_tn5250_wts_mask, 1, wts_cld_byte3, 0 },\n    { &hf_tn5250_wts_cld_page_num, 0, 2, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_wts_cld_lmo, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_wts_cld_io, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_wts_cld_sli, 0, 1, 0, ENC_BIG_ENDIAN },\n    { NULL, 0, 0, 0, 0 }\n  };\n\n\n  hf_items dsc_fields[] = {\n    { &hf_tn5250_dsc_partition, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_reserved, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_reserved, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dsc_sk, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dsc_ev, 0, 1, 0, ENC_EBCDIC|ENC_NA },\n    { NULL, 0, 0, 0, 0 }\n  };\n\n  hf_items dorm_fields[] = {\n    { &hf_tn5250_dorm_length, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dorm_ec, 0, 2, 0, ENC_BIG_ENDIAN },\n    { NULL, 0, 0, 0, 0 }\n  };\n\n\n  static const int *dfdpck_coreflag[] = {\n    &hf_tn5250_dfdpck_coreflag_0,\n    &hf_tn5250_dfdpck_coreflag_1,\n    &hf_tn5250_dfdpck_coreflag_2,\n    &hf_tn5250_dfdpck_coreflag_3,\n    &hf_tn5250_dfdpck_coreflag_4,\n    &hf_tn5250_dfdpck_coreflag_5,\n    &hf_tn5250_dfdpck_coreflag_6,\n    &hf_tn5250_dfdpck_coreflag_7,\n    NULL\n  };\n\n  static const int *dfdpck_toprowflag1[] = {\n    &hf_tn5250_dfdpck_toprowflag1_0,\n    &hf_tn5250_dfdpck_toprowflag1_1,\n    &hf_tn5250_dfdpck_toprowflag1_2,\n    &hf_tn5250_dfdpck_toprowflag1_3,\n    &hf_tn5250_dfdpck_toprowflag1_4,\n    &hf_tn5250_dfdpck_toprowflag1_5,\n    &hf_tn5250_dfdpck_toprowflag1_6,\n    &hf_tn5250_dfdpck_toprowflag1_7,\n    NULL\n  };\n\n  static const int *dfdpck_toprowflag2[] = {\n    &hf_tn5250_dfdpck_toprowflag2_0,\n    &hf_tn5250_dfdpck_toprowflag2_1,\n    &hf_tn5250_dfdpck_toprowflag2_2,\n    &hf_tn5250_dfdpck_toprowflag2_3,\n    &hf_tn5250_dfdpck_toprowflag2_4,\n    &hf_tn5250_dfdpck_toprowflag2_5,\n    &hf_tn5250_dfdpck_toprowflag2_6,\n    &hf_tn5250_dfdpck_toprowflag2_7,\n    NULL\n  };\n\n  static const int *dfdpck_toprowflag3[] = {\n    &hf_tn5250_dfdpck_toprowflag3_0,\n    &hf_tn5250_dfdpck_toprowflag3_1,\n    &hf_tn5250_dfdpck_toprowflag3_2,\n    &hf_tn5250_dfdpck_toprowflag3_3,\n    &hf_tn5250_dfdpck_toprowflag3_4,\n    &hf_tn5250_dfdpck_toprowflag3_5,\n    &hf_tn5250_dfdpck_toprowflag3_6,\n    &hf_tn5250_dfdpck_toprowflag3_7,\n    NULL\n  };\n\n  hf_items dfdpck_fields[] = {\n    { &hf_tn5250_dfdpck_partition, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_reserved, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_reserved, 0, 1, 0, ENC_BIG_ENDIAN },\n    { NULL, 0, 0, 0, 0 }\n  };\n\n  hf_items dfdpck_core_area_fields[] = {\n    { &hf_tn5250_length, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dfdpck_data_field, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dfdpck_coreflag, ett_tn5250_dfdpck_mask, 1, dfdpck_coreflag, 0 },\n    { &hf_tn5250_reserved, 0, 1, 0, ENC_BIG_ENDIAN },\n    { NULL, 0, 0, 0, 0 }\n  };\n\n  hf_items dfdpck_top_row_fields[] = {\n    { &hf_tn5250_length, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dfdpck_data_field, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dfdpck_toprowflag1, ett_tn5250_dfdpck_mask, 1, dfdpck_toprowflag1, 0 },\n    { &hf_tn5250_dfdpck_toprowflag2, ett_tn5250_dfdpck_mask, 1, dfdpck_toprowflag2, 0 },\n    { &hf_tn5250_dfdpck_toprowflag3, ett_tn5250_dfdpck_mask, 1, dfdpck_toprowflag3, 0 },\n    { &hf_tn5250_reserved, 0, 1, 0, ENC_BIG_ENDIAN },\n    { NULL, 0, 0, 0, 0 }\n  };\n\n  while (tvb_reported_length_remaining(tvb, offset) > 0 && !done) {\n    sf_length = tvb_get_ntohs(tvb,offset);\n    type = tvb_get_guint8(tvb, offset+3);\n\n    offset += tn5250_add_hf_items(tn5250_tree, tvb, offset, standard_fields);\n\n    switch (type) {\n      case PASS_THROUGH:\n        proto_tree_add_item(tn5250_tree, hf_tn5250_field_data, tvb, offset,\n                            (sf_length - (start + offset)), ENC_EBCDIC|ENC_NA);\n        offset += (guint32)(sf_length - (start + offset));\n        break;\n      case TN5250_QUERY:\n        proto_tree_add_item(tn5250_tree, hf_tn5250_reserved, tvb, offset,\n                            1, ENC_BIG_ENDIAN);\n        offset ++;\n        break;\n      case TN5250_QUERY_STATION_STATE:\n        offset += tn5250_add_hf_items(tn5250_tree, tvb, offset, qss_fields);\n        break;\n      case DEFINE_AUDIT_WINDOW__TABLE:\n        proto_tree_add_item(tn5250_tree, hf_tn5250_dawt_id, tvb, offset,\n                            1, ENC_BIG_ENDIAN);\n        while ((offset - start) < sf_length) {\n          length = tvb_get_guint8(tvb,offset);\n          offset += tn5250_add_hf_items(tn5250_tree, tvb, offset, dawt_fields);\n          proto_tree_add_item(tn5250_tree, hf_tn5250_dawt_message, tvb, offset,\n                              (length - 2), ENC_EBCDIC|ENC_NA);\n          offset += length;\n        }\n        break;\n      case DEFINE_COMMAND_KEY_FUNCTION:\n        proto_tree_add_item(tn5250_tree, hf_tn5250_dckf_id, tvb, offset,\n                            1, ENC_BIG_ENDIAN);\n        while ((offset - start) < sf_length) {\n          length = tvb_get_guint8(tvb,offset);\n          offset += tn5250_add_hf_items(tn5250_tree, tvb, offset,\n                                        dckf_fields);\n          proto_tree_add_item(tn5250_tree, hf_tn5250_dckf_prompt_text, tvb,\n                              offset, (length - 2), ENC_EBCDIC|ENC_NA);\n          offset += length;\n        }\n        break;\n      case READ_TEXT_SCREEN:\n        offset += tn5250_add_hf_items(tn5250_tree, tvb, offset, rts_fields);\n        break;\n      case DEFINE_PENDING_OPERATIONS:\n        offset += tn5250_add_hf_items(tn5250_tree, tvb, offset, dpo_fields);\n        break;\n      case DEFINE_TEXT_SCREEN_FORMAT:\n        offset += tn5250_add_hf_items(tn5250_tree, tvb, offset, dtsf_fields);\n        break;\n      case DEFINE_SCALE_LINE:\n        offset += tn5250_add_hf_items(tn5250_tree, tvb, offset, dsl_fields);\n        while ((offset - start) < sf_length) {\n          /* XXX length unused\n          length = tvb_get_guint8(tvb,offset); */\n          offset += tn5250_add_hf_items(tn5250_tree, tvb, offset, dsl_fields2);\n        }\n        break;\n      case WRITE_TEXT_SCREEN:\n        offset += tn5250_add_hf_items(tn5250_tree, tvb, offset,\n                                      wts_fields);\n        length = tvb_get_guint8(tvb,offset);\n        used = tn5250_add_hf_items(tn5250_tree, tvb, offset,\n                                   wts_line_data_fields);\n        offset += used;\n        proto_tree_add_item(tn5250_tree, hf_tn5250_wts_cld_li, tvb, offset,\n                            (length - used), ENC_EBCDIC|ENC_NA);\n        break;\n      case DEFINE_SPECIAL_CHARACTERS:\n        offset += tn5250_add_hf_items(tn5250_tree, tvb, offset,\n                                      dsc_fields);\n        break;\n      case DEFINE_OPERATOR_ERROR_MESSAGES:\n        proto_tree_add_item(tn5250_tree, hf_tn5250_dorm_id, tvb, offset,\n                            1, ENC_BIG_ENDIAN);\n        while ((offset - start) < sf_length) {\n          length = tvb_get_guint8(tvb,offset);\n          offset += tn5250_add_hf_items(tn5250_tree, tvb, offset,\n                                        dorm_fields);\n          proto_tree_add_item(tn5250_tree, hf_tn5250_dorm_mt, tvb, offset,\n                              (length - 2), ENC_EBCDIC|ENC_NA);\n          offset += length;\n        }\n        break;\n      case DEFINE_PITCH_TABLE:\n        proto_tree_add_item(tn5250_tree, hf_tn5250_dpt_id, tvb, offset,\n                            1, ENC_BIG_ENDIAN);\n        while ((offset - start) < sf_length) {\n          length = tvb_get_guint8(tvb,offset);\n          proto_tree_add_item(tn5250_tree, hf_tn5250_length, tvb, offset,\n                              1, ENC_BIG_ENDIAN);\n          proto_tree_add_item(tn5250_tree, hf_tn5250_dpt_ec, tvb, offset,\n                              length, ENC_EBCDIC|ENC_NA);\n          offset += length;\n        }\n        break;\n      case DEFINE_FAKE_DP_COMMAND_KEY_FUNCTION:\n        offset += tn5250_add_hf_items(tn5250_tree, tvb, offset,\n                                      dfdpck_fields);\n        while ((offset - start) < sf_length) {\n          length = tvb_get_guint8(tvb,offset);\n          type = tvb_get_guint8(tvb,offset+1);\n          if (type == CORE_AREA_COMMAND_KEYS) {\n            offset += tn5250_add_hf_items(tn5250_tree, tvb, offset,\n                                          dfdpck_core_area_fields);\n          } else if (type == TOP_ROW_COMMAND_KEYS) {\n            offset += tn5250_add_hf_items(tn5250_tree, tvb, offset,\n                                          dfdpck_top_row_fields);\n          } else {\n            offset += dissect_unknown_data(tn5250_tree, tvb, offset, start, length);\n          }\n        }\n        break;\n      default:\n        done = 1;\n        break;\n    }\n  }\n\n  offset += dissect_unknown_data(tn5250_tree, tvb, offset, start, sf_length);\n\n  return (offset - start);\n}",
        "func": "static guint32\ndissect_write_structured_field(proto_tree *tn5250_tree, tvbuff_t *tvb, gint offset)\n{\n  int start = offset;\n  guint16 sf_length = 0;\n  int length, type, done = 0, used = 0;\n\n  hf_items standard_fields[] = {\n    { &hf_tn5250_sf_length, 0, 2, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_sf_class, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_sf_type, 0, 1, 0, ENC_BIG_ENDIAN },\n    { NULL, 0, 0, 0, 0 }\n  };\n\n  static const int *qss_byte1[] = {\n    &hf_tn5250_wsf_qss_flag1_0,\n    &hf_tn5250_wsf_qss_flag1_reserved,\n    NULL\n  };\n\n  static const int *qss_byte2[] = {\n    &hf_tn5250_wsf_qss_flag2_reserved,\n    &hf_tn5250_wsf_qss_flag2_7,\n    NULL\n  };\n\n  hf_items qss_fields[] = {\n    { &hf_tn5250_wsf_qss_flag1, ett_tn5250_wsf_qss_mask, 1, qss_byte1, 0 },\n    { &hf_tn5250_wsf_qss_flag2, ett_tn5250_wsf_qss_mask, 1, qss_byte2, 0 },\n    { NULL, 0, 0, 0, 0 }\n  };\n\n  hf_items dawt_fields[] = {\n    { &hf_tn5250_dawt_length, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dawt_char, 0, 1, 0, ENC_EBCDIC|ENC_NA },\n    { NULL, 0, 0, 0, 0 }\n  };\n\n  hf_items dckf_fields[] = {\n    { &hf_tn5250_dckf_length, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dckf_key_code, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dckf_function_code, 0, 1, 0, ENC_BIG_ENDIAN },\n    { NULL, 0, 0, 0, 0 }\n  };\n\n  static const int *rts_byte1[] = {\n    &hf_tn5250_rts_flag1_0,\n    &hf_tn5250_rts_flag1_reserved,\n    NULL\n  };\n\n  hf_items rts_fields[] = {\n    { &hf_tn5250_rts_partition, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_rts_flag1, ett_tn5250_wsf_rts_mask, 1, rts_byte1, 0 },\n    { &hf_tn5250_reserved, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_reserved, 0, 1, 0, ENC_BIG_ENDIAN },\n    { NULL, 0, 0, 0, 0 }\n  };\n\n  static const int *dpo_byte1[] = {\n    &hf_tn5250_dpo_flag1_0,\n    &hf_tn5250_dpo_flag1_1,\n    &hf_tn5250_dpo_flag1_2,\n    &hf_tn5250_dpo_flag1_3,\n    &hf_tn5250_dpo_flag1_4,\n    &hf_tn5250_dpo_flag1_5,\n    &hf_tn5250_dpo_flag1_6,\n    &hf_tn5250_dpo_flag1_7,\n    NULL\n  };\n\n  static const int *dpo_byte2[] = {\n    &hf_tn5250_dpo_flag2_0,\n    &hf_tn5250_dpo_flag2_reserved,\n    NULL\n  };\n\n  hf_items dpo_fields[] = {\n    { &hf_tn5250_dpo_partition, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dpo_flag1, ett_tn5250_wsf_dpo_mask, 1, dpo_byte1, 0 },\n    { &hf_tn5250_dpo_flag2, ett_tn5250_wsf_dpo_mask, 1, dpo_byte2, 0 },\n    { &hf_tn5250_dpo_displace_characters, 0, 3, 0, ENC_EBCDIC|ENC_NA },\n    { &hf_tn5250_dpo_start_location_row, 0, 2, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dpo_start_location_col, 0, 2, 0, ENC_BIG_ENDIAN },\n    { NULL, 0, 0, 0, 0 }\n  };\n\n  static const int *dtsf_byte1[] = {\n    &hf_tn5250_dtsf_flag1_0,\n    &hf_tn5250_dtsf_flag1_1,\n    &hf_tn5250_dtsf_flag1_2,\n    &hf_tn5250_dtsf_flag1_3,\n    &hf_tn5250_dtsf_flag1_4,\n    &hf_tn5250_dtsf_flag1_5,\n    &hf_tn5250_dtsf_flag1_6,\n    &hf_tn5250_dtsf_flag1_7,\n    NULL\n  };\n\n  static const int *dtsf_byte2[] = {\n    &hf_tn5250_dtsf_flag2_0,\n    &hf_tn5250_dtsf_flag2_1,\n    &hf_tn5250_dtsf_flag2_2,\n    &hf_tn5250_dtsf_flag2_3,\n    &hf_tn5250_dtsf_flag2_4to7,\n    NULL\n  };\n\n  hf_items dtsf_fields[] = {\n    { &hf_tn5250_dtsf_partition, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dtsf_flag1, ett_tn5250_wsf_dtsf_mask, 1, dtsf_byte1, 0 },\n    { &hf_tn5250_dtsf_flag2, ett_tn5250_wsf_dtsf_mask, 1, dtsf_byte2, 0 },\n    { &hf_tn5250_dtsf_text_body_height, 0, 2, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dtsf_text_body_width, 0, 2, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dtsf_line_cmd_field_size, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dtsf_location_of_pitch, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dtsf_first_line, 0, 1, 0, ENC_BIG_ENDIAN },\n    { NULL, 0, 0, 0, 0 }\n  };\n\n  static const int *dsl_byte1[] = {\n    &hf_tn5250_dsl_flag1_0,\n    &hf_tn5250_dsl_flag1_1,\n    &hf_tn5250_dsl_flag1_2,\n    &hf_tn5250_dsl_flag1_reserved,\n    NULL\n  };\n\n  hf_items dsl_fields[] = {\n    { &hf_tn5250_dsl_partition, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_reserved, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dsl_rtl_offset, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dsl_offset, 0, 1, 0, ENC_BIG_ENDIAN },\n    { NULL, 0, 0, 0, 0 }\n  };\n\n  hf_items dsl_fields2[] = {\n    { &hf_tn5250_length, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dsl_flag1, ett_tn5250_wsf_dsl_mask, 1, dsl_byte1, 0 },\n    { &hf_tn5250_dsl_id, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dsl_location, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dsl_function, 0, 1, 0, ENC_BIG_ENDIAN },\n    { NULL, 0, 0, 0, 0 }\n  };\n\n  static const int *wts_byte1[] = {\n    &hf_tn5250_wts_flag1_0,\n    &hf_tn5250_wts_flag1_1,\n    &hf_tn5250_wts_flag1_2,\n    &hf_tn5250_wts_flag1_3,\n    &hf_tn5250_wts_flag1_reserved,\n    NULL\n  };\n\n  static const int *wts_byte2[] = {\n    &hf_tn5250_wts_flag2_reserved,\n    &hf_tn5250_wts_flag2_6,\n    &hf_tn5250_wts_flag2_reserved2,\n    NULL\n  };\n\n  static const int *wts_byte3[] = {\n    &hf_tn5250_wts_flag3_0,\n    &hf_tn5250_wts_flag3_1,\n    &hf_tn5250_wts_flag3_2,\n    &hf_tn5250_wts_flag3_3,\n    &hf_tn5250_wts_flag3_4,\n    &hf_tn5250_wts_flag3_5,\n    &hf_tn5250_wts_flag3_6,\n    &hf_tn5250_wts_flag3_7,\n    NULL\n  };\n\n  hf_items wts_fields[] = {\n    { &hf_tn5250_wts_partition, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_wts_flag1, ett_tn5250_wts_mask, 1, wts_byte1, 0 },\n    { &hf_tn5250_wts_flag2, ett_tn5250_wts_mask, 1, wts_byte2, 0 },\n    { &hf_tn5250_wts_flag3, ett_tn5250_wts_mask, 1, wts_byte3, 0 },\n    { &hf_tn5250_wts_home_position_row, 0, 2, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_wts_home_position_col, 0, 2, 0, ENC_BIG_ENDIAN },\n    { NULL, 0, 0, 0, 0 }\n  };\n\n  static const int *wts_cld_byte1[] = {\n    &hf_tn5250_wts_cld_flag1_0,\n    &hf_tn5250_wts_cld_flag1_1,\n    &hf_tn5250_wts_cld_flag1_2,\n    &hf_tn5250_wts_cld_flag1_3,\n    &hf_tn5250_wts_cld_flag1_4,\n    &hf_tn5250_wts_cld_flag1_5,\n    &hf_tn5250_wts_cld_flag1_6,\n    &hf_tn5250_wts_cld_flag1_7,\n    NULL\n  };\n\n  static const int *wts_cld_byte2[] = {\n    &hf_tn5250_wts_cld_flag2_0,\n    &hf_tn5250_wts_cld_flag2_1,\n    &hf_tn5250_wts_cld_flag2_2,\n    &hf_tn5250_wts_cld_flag2_3,\n    &hf_tn5250_wts_cld_flag2_4,\n    &hf_tn5250_wts_cld_flag2_line_spacing,\n    NULL\n  };\n\n  static const int *wts_cld_byte3[] = {\n    &hf_tn5250_wts_cld_flag3_0,\n    &hf_tn5250_wts_cld_flag3_1,\n    &hf_tn5250_wts_cld_flag3_2,\n    &hf_tn5250_wts_cld_flag3_3,\n    &hf_tn5250_wts_cld_flag3_4,\n    &hf_tn5250_wts_cld_flag3_5,\n    &hf_tn5250_wts_cld_flag3_6,\n    &hf_tn5250_wts_cld_flag3_7,\n    NULL\n  };\n\n  hf_items wts_line_data_fields[] = {\n    { &hf_tn5250_length, 0, 1, 0, ENC_BIG_ENDIAN }, /*FIXME: Could be one or two bytes! */\n    { &hf_tn5250_wts_cld_flag1, ett_tn5250_wts_mask, 1, wts_cld_byte1, 0 },\n    { &hf_tn5250_wts_cld_flag2, ett_tn5250_wts_mask, 1, wts_cld_byte2, 0 },\n    { &hf_tn5250_wts_cld_row, 0, 2, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_wts_cld_flag3, ett_tn5250_wts_mask, 1, wts_cld_byte3, 0 },\n    { &hf_tn5250_wts_cld_page_num, 0, 2, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_wts_cld_lmo, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_wts_cld_io, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_wts_cld_sli, 0, 1, 0, ENC_BIG_ENDIAN },\n    { NULL, 0, 0, 0, 0 }\n  };\n\n\n  hf_items dsc_fields[] = {\n    { &hf_tn5250_dsc_partition, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_reserved, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_reserved, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dsc_sk, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dsc_ev, 0, 1, 0, ENC_EBCDIC|ENC_NA },\n    { NULL, 0, 0, 0, 0 }\n  };\n\n  hf_items dorm_fields[] = {\n    { &hf_tn5250_dorm_length, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dorm_ec, 0, 2, 0, ENC_BIG_ENDIAN },\n    { NULL, 0, 0, 0, 0 }\n  };\n\n\n  static const int *dfdpck_coreflag[] = {\n    &hf_tn5250_dfdpck_coreflag_0,\n    &hf_tn5250_dfdpck_coreflag_1,\n    &hf_tn5250_dfdpck_coreflag_2,\n    &hf_tn5250_dfdpck_coreflag_3,\n    &hf_tn5250_dfdpck_coreflag_4,\n    &hf_tn5250_dfdpck_coreflag_5,\n    &hf_tn5250_dfdpck_coreflag_6,\n    &hf_tn5250_dfdpck_coreflag_7,\n    NULL\n  };\n\n  static const int *dfdpck_toprowflag1[] = {\n    &hf_tn5250_dfdpck_toprowflag1_0,\n    &hf_tn5250_dfdpck_toprowflag1_1,\n    &hf_tn5250_dfdpck_toprowflag1_2,\n    &hf_tn5250_dfdpck_toprowflag1_3,\n    &hf_tn5250_dfdpck_toprowflag1_4,\n    &hf_tn5250_dfdpck_toprowflag1_5,\n    &hf_tn5250_dfdpck_toprowflag1_6,\n    &hf_tn5250_dfdpck_toprowflag1_7,\n    NULL\n  };\n\n  static const int *dfdpck_toprowflag2[] = {\n    &hf_tn5250_dfdpck_toprowflag2_0,\n    &hf_tn5250_dfdpck_toprowflag2_1,\n    &hf_tn5250_dfdpck_toprowflag2_2,\n    &hf_tn5250_dfdpck_toprowflag2_3,\n    &hf_tn5250_dfdpck_toprowflag2_4,\n    &hf_tn5250_dfdpck_toprowflag2_5,\n    &hf_tn5250_dfdpck_toprowflag2_6,\n    &hf_tn5250_dfdpck_toprowflag2_7,\n    NULL\n  };\n\n  static const int *dfdpck_toprowflag3[] = {\n    &hf_tn5250_dfdpck_toprowflag3_0,\n    &hf_tn5250_dfdpck_toprowflag3_1,\n    &hf_tn5250_dfdpck_toprowflag3_2,\n    &hf_tn5250_dfdpck_toprowflag3_3,\n    &hf_tn5250_dfdpck_toprowflag3_4,\n    &hf_tn5250_dfdpck_toprowflag3_5,\n    &hf_tn5250_dfdpck_toprowflag3_6,\n    &hf_tn5250_dfdpck_toprowflag3_7,\n    NULL\n  };\n\n  hf_items dfdpck_fields[] = {\n    { &hf_tn5250_dfdpck_partition, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_reserved, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_reserved, 0, 1, 0, ENC_BIG_ENDIAN },\n    { NULL, 0, 0, 0, 0 }\n  };\n\n  hf_items dfdpck_core_area_fields[] = {\n    { &hf_tn5250_length, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dfdpck_data_field, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dfdpck_coreflag, ett_tn5250_dfdpck_mask, 1, dfdpck_coreflag, 0 },\n    { &hf_tn5250_reserved, 0, 1, 0, ENC_BIG_ENDIAN },\n    { NULL, 0, 0, 0, 0 }\n  };\n\n  hf_items dfdpck_top_row_fields[] = {\n    { &hf_tn5250_length, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dfdpck_data_field, 0, 1, 0, ENC_BIG_ENDIAN },\n    { &hf_tn5250_dfdpck_toprowflag1, ett_tn5250_dfdpck_mask, 1, dfdpck_toprowflag1, 0 },\n    { &hf_tn5250_dfdpck_toprowflag2, ett_tn5250_dfdpck_mask, 1, dfdpck_toprowflag2, 0 },\n    { &hf_tn5250_dfdpck_toprowflag3, ett_tn5250_dfdpck_mask, 1, dfdpck_toprowflag3, 0 },\n    { &hf_tn5250_reserved, 0, 1, 0, ENC_BIG_ENDIAN },\n    { NULL, 0, 0, 0, 0 }\n  };\n\n  while (tvb_reported_length_remaining(tvb, offset) > 0 && !done) {\n    sf_length = tvb_get_ntohs(tvb,offset);\n    type = tvb_get_guint8(tvb, offset+3);\n\n    offset += tn5250_add_hf_items(tn5250_tree, tvb, offset, standard_fields);\n\n    switch (type) {\n      case PASS_THROUGH:\n        proto_tree_add_item(tn5250_tree, hf_tn5250_field_data, tvb, offset,\n                            (sf_length - (start + offset)), ENC_EBCDIC|ENC_NA);\n        offset += (guint32)(sf_length - (start + offset));\n        break;\n      case TN5250_QUERY:\n        proto_tree_add_item(tn5250_tree, hf_tn5250_reserved, tvb, offset,\n                            1, ENC_BIG_ENDIAN);\n        offset ++;\n        break;\n      case TN5250_QUERY_STATION_STATE:\n        offset += tn5250_add_hf_items(tn5250_tree, tvb, offset, qss_fields);\n        break;\n      case DEFINE_AUDIT_WINDOW__TABLE:\n        proto_tree_add_item(tn5250_tree, hf_tn5250_dawt_id, tvb, offset,\n                            1, ENC_BIG_ENDIAN);\n        while ((offset - start) < sf_length) {\n          length = tvb_get_guint8(tvb,offset);\n          offset += tn5250_add_hf_items(tn5250_tree, tvb, offset, dawt_fields);\n          proto_tree_add_item(tn5250_tree, hf_tn5250_dawt_message, tvb, offset,\n                              (length - 2), ENC_EBCDIC|ENC_NA);\n          offset += length;\n        }\n        break;\n      case DEFINE_COMMAND_KEY_FUNCTION:\n        proto_tree_add_item(tn5250_tree, hf_tn5250_dckf_id, tvb, offset,\n                            1, ENC_BIG_ENDIAN);\n        while ((offset - start) < sf_length) {\n          length = tvb_get_guint8(tvb,offset);\n          offset += tn5250_add_hf_items(tn5250_tree, tvb, offset,\n                                        dckf_fields);\n          proto_tree_add_item(tn5250_tree, hf_tn5250_dckf_prompt_text, tvb,\n                              offset, (length - 2), ENC_EBCDIC|ENC_NA);\n          offset += length;\n        }\n        break;\n      case READ_TEXT_SCREEN:\n        offset += tn5250_add_hf_items(tn5250_tree, tvb, offset, rts_fields);\n        break;\n      case DEFINE_PENDING_OPERATIONS:\n        offset += tn5250_add_hf_items(tn5250_tree, tvb, offset, dpo_fields);\n        break;\n      case DEFINE_TEXT_SCREEN_FORMAT:\n        offset += tn5250_add_hf_items(tn5250_tree, tvb, offset, dtsf_fields);\n        break;\n      case DEFINE_SCALE_LINE:\n        offset += tn5250_add_hf_items(tn5250_tree, tvb, offset, dsl_fields);\n        while ((offset - start) < sf_length) {\n          /* XXX length unused\n          length = tvb_get_guint8(tvb,offset); */\n          offset += tn5250_add_hf_items(tn5250_tree, tvb, offset, dsl_fields2);\n        }\n        break;\n      case WRITE_TEXT_SCREEN:\n        offset += tn5250_add_hf_items(tn5250_tree, tvb, offset,\n                                      wts_fields);\n        length = tvb_get_guint8(tvb,offset);\n        used = tn5250_add_hf_items(tn5250_tree, tvb, offset,\n                                   wts_line_data_fields);\n        offset += used;\n        proto_tree_add_item(tn5250_tree, hf_tn5250_wts_cld_li, tvb, offset,\n                            (length - used), ENC_EBCDIC|ENC_NA);\n        break;\n      case DEFINE_SPECIAL_CHARACTERS:\n        offset += tn5250_add_hf_items(tn5250_tree, tvb, offset,\n                                      dsc_fields);\n        break;\n      case DEFINE_OPERATOR_ERROR_MESSAGES:\n        proto_tree_add_item(tn5250_tree, hf_tn5250_dorm_id, tvb, offset,\n                            1, ENC_BIG_ENDIAN);\n        while ((offset - start) < sf_length) {\n          length = tvb_get_guint8(tvb,offset);\n          offset += tn5250_add_hf_items(tn5250_tree, tvb, offset,\n                                        dorm_fields);\n          proto_tree_add_item(tn5250_tree, hf_tn5250_dorm_mt, tvb, offset,\n                              (length - 2), ENC_EBCDIC|ENC_NA);\n          offset += length;\n        }\n        break;\n      case DEFINE_PITCH_TABLE:\n        proto_tree_add_item(tn5250_tree, hf_tn5250_dpt_id, tvb, offset,\n                            1, ENC_BIG_ENDIAN);\n        while ((offset - start) < sf_length) {\n          length = tvb_get_guint8(tvb,offset);\n          proto_tree_add_item(tn5250_tree, hf_tn5250_length, tvb, offset,\n                              1, ENC_BIG_ENDIAN);\n          if (length==0)\n            break;\n          proto_tree_add_item(tn5250_tree, hf_tn5250_dpt_ec, tvb, offset,\n                              length, ENC_EBCDIC|ENC_NA);\n          offset += length;\n        }\n        break;\n      case DEFINE_FAKE_DP_COMMAND_KEY_FUNCTION:\n        offset += tn5250_add_hf_items(tn5250_tree, tvb, offset,\n                                      dfdpck_fields);\n        while ((offset - start) < sf_length) {\n          length = tvb_get_guint8(tvb,offset);\n          type = tvb_get_guint8(tvb,offset+1);\n          if (type == CORE_AREA_COMMAND_KEYS) {\n            offset += tn5250_add_hf_items(tn5250_tree, tvb, offset,\n                                          dfdpck_core_area_fields);\n          } else if (type == TOP_ROW_COMMAND_KEYS) {\n            offset += tn5250_add_hf_items(tn5250_tree, tvb, offset,\n                                          dfdpck_top_row_fields);\n          } else {\n            offset += dissect_unknown_data(tn5250_tree, tvb, offset, start, length);\n          }\n        }\n        break;\n      default:\n        done = 1;\n        break;\n    }\n  }\n\n  offset += dissect_unknown_data(tn5250_tree, tvb, offset, start, sf_length);\n\n  return (offset - start);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -411,6 +411,8 @@\n           length = tvb_get_guint8(tvb,offset);\n           proto_tree_add_item(tn5250_tree, hf_tn5250_length, tvb, offset,\n                               1, ENC_BIG_ENDIAN);\n+          if (length==0)\n+            break;\n           proto_tree_add_item(tn5250_tree, hf_tn5250_dpt_ec, tvb, offset,\n                               length, ENC_EBCDIC|ENC_NA);\n           offset += length;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "          if (length==0)",
                "            break;"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-3688",
        "func_name": "torvalds/linux/sctp_inq_pop",
        "description": "The SCTP implementation in the Linux kernel before 3.17.4 allows remote attackers to cause a denial of service (memory consumption) by triggering a large number of chunks in an association's output queue, as demonstrated by ASCONF probes, related to net/sctp/inqueue.c and net/sctp/sm_statefuns.c.",
        "git_url": "https://github.com/torvalds/linux/commit/26b87c7881006311828bb0ab271a551a62dcceb4",
        "commit_title": "net: sctp: fix remote memory pressure from excessive queueing",
        "commit_text": " This scenario is not limited to ASCONF, just taken as one example triggering the issue. When receiving ASCONF probes in the form of ...    -------------- INIT[ASCONF; ASCONF_ACK] ------------->   <----------- INIT-ACK[ASCONF; ASCONF_ACK] ------------   -------------------- COOKIE-ECHO -------------------->   <-------------------- COOKIE-ACK ---------------------   ---- ASCONF_a; [ASCONF_b; ...; ASCONF_n;] JUNK ------>   [...]   ---- ASCONF_m; [ASCONF_o; ...; ASCONF_z;] JUNK ------>  ... where ASCONF_a, ASCONF_b, ..., ASCONF_z are good-formed ASCONFs and have increasing serial numbers, we process such ASCONF chunk(s) marked with !end_of_packet and !singleton, since we have not yet reached the SCTP packet end. SCTP does only do verification on a chunk by chunk basis, as an SCTP packet is nothing more than just a container of a stream of chunks which it eats up one by one.  We could run into the case that we receive a packet with a malformed tail, above marked as trailing JUNK. All previous chunks are here goodformed, so the stack will eat up all previous chunks up to this point. In case JUNK does not fit into a chunk header and there are no more other chunks in the input queue, or in case JUNK contains a garbage chunk header, but the encoded chunk length would exceed the skb tail, or we came here from an entirely different scenario and the chunk has pdiscard=1 mark (without having had a flush point), it will happen, that we will excessively queue up the association's output queue (a correct final chunk may then turn it into a response flood when flushing the queue ;)): I ran a simple script with incremental ASCONF serial numbers and could see the server side consuming excessive amount of RAM [before/after: up to 2GB and more].  The issue at heart is that the chunk train basically ends with !end_of_packet and !singleton markers and since commit 2e3216cd54b1 (\"sctp: Follow security requirement of responding with 1 packet\") therefore preventing an output queue flush point in sctp_do_sm() -> sctp_cmd_interpreter() on the input chunk (chunk = event_arg) even though local_cork is set, but its precedence has changed since then. In the normal case, the last chunk with end_of_packet=1 would trigger the queue flush to accommodate possible outgoing bundling.  In the input queue, sctp_inq_pop() seems to do the right thing in terms of discarding invalid chunks. So, above JUNK will not enter the state machine and instead be released and exit the sctp_assoc_bh_rcv() chunk processing loop. It's simply the flush point being missing at loop exit. Adding a try-flush approach on the output queue might not work as the underlying infrastructure might be long gone at this point due to the side-effect interpreter run.  One possibility, albeit a bit of a kludge, would be to defer invalid chunk freeing into the state machine in order to possibly trigger packet discards and thus indirectly a queue flush on error. It would surely be better to discard chunks as in the current, perhaps better controlled environment, but going back and forth, it's simply architecturally not possible. I tried various trailing JUNK attack cases and it seems to look good now.  Joint work with Vlad Yasevich. ",
        "func_before": "struct sctp_chunk *sctp_inq_pop(struct sctp_inq *queue)\n{\n\tstruct sctp_chunk *chunk;\n\tsctp_chunkhdr_t *ch = NULL;\n\n\t/* The assumption is that we are safe to process the chunks\n\t * at this time.\n\t */\n\n\tif ((chunk = queue->in_progress)) {\n\t\t/* There is a packet that we have been working on.\n\t\t * Any post processing work to do before we move on?\n\t\t */\n\t\tif (chunk->singleton ||\n\t\t    chunk->end_of_packet ||\n\t\t    chunk->pdiscard) {\n\t\t\tsctp_chunk_free(chunk);\n\t\t\tchunk = queue->in_progress = NULL;\n\t\t} else {\n\t\t\t/* Nothing to do. Next chunk in the packet, please. */\n\t\t\tch = (sctp_chunkhdr_t *) chunk->chunk_end;\n\n\t\t\t/* Force chunk->skb->data to chunk->chunk_end.  */\n\t\t\tskb_pull(chunk->skb,\n\t\t\t\t chunk->chunk_end - chunk->skb->data);\n\n\t\t\t/* Verify that we have at least chunk headers\n\t\t\t * worth of buffer left.\n\t\t\t */\n\t\t\tif (skb_headlen(chunk->skb) < sizeof(sctp_chunkhdr_t)) {\n\t\t\t\tsctp_chunk_free(chunk);\n\t\t\t\tchunk = queue->in_progress = NULL;\n\t\t\t}\n\t\t}\n\t}\n\n\t/* Do we need to take the next packet out of the queue to process? */\n\tif (!chunk) {\n\t\tstruct list_head *entry;\n\n\t\t/* Is the queue empty?  */\n\t\tif (list_empty(&queue->in_chunk_list))\n\t\t\treturn NULL;\n\n\t\tentry = queue->in_chunk_list.next;\n\t\tchunk = queue->in_progress =\n\t\t\tlist_entry(entry, struct sctp_chunk, list);\n\t\tlist_del_init(entry);\n\n\t\t/* This is the first chunk in the packet.  */\n\t\tchunk->singleton = 1;\n\t\tch = (sctp_chunkhdr_t *) chunk->skb->data;\n\t\tchunk->data_accepted = 0;\n\t}\n\n\tchunk->chunk_hdr = ch;\n\tchunk->chunk_end = ((__u8 *)ch) + WORD_ROUND(ntohs(ch->length));\n\t/* In the unlikely case of an IP reassembly, the skb could be\n\t * non-linear. If so, update chunk_end so that it doesn't go past\n\t * the skb->tail.\n\t */\n\tif (unlikely(skb_is_nonlinear(chunk->skb))) {\n\t\tif (chunk->chunk_end > skb_tail_pointer(chunk->skb))\n\t\t\tchunk->chunk_end = skb_tail_pointer(chunk->skb);\n\t}\n\tskb_pull(chunk->skb, sizeof(sctp_chunkhdr_t));\n\tchunk->subh.v = NULL; /* Subheader is no longer valid.  */\n\n\tif (chunk->chunk_end < skb_tail_pointer(chunk->skb)) {\n\t\t/* This is not a singleton */\n\t\tchunk->singleton = 0;\n\t} else if (chunk->chunk_end > skb_tail_pointer(chunk->skb)) {\n\t\t/* RFC 2960, Section 6.10  Bundling\n\t\t *\n\t\t * Partial chunks MUST NOT be placed in an SCTP packet.\n\t\t * If the receiver detects a partial chunk, it MUST drop\n\t\t * the chunk.\n\t\t *\n\t\t * Since the end of the chunk is past the end of our buffer\n\t\t * (which contains the whole packet, we can freely discard\n\t\t * the whole packet.\n\t\t */\n\t\tsctp_chunk_free(chunk);\n\t\tchunk = queue->in_progress = NULL;\n\n\t\treturn NULL;\n\t} else {\n\t\t/* We are at the end of the packet, so mark the chunk\n\t\t * in case we need to send a SACK.\n\t\t */\n\t\tchunk->end_of_packet = 1;\n\t}\n\n\tpr_debug(\"+++sctp_inq_pop+++ chunk:%p[%s], length:%d, skb->len:%d\\n\",\n\t\t chunk, sctp_cname(SCTP_ST_CHUNK(chunk->chunk_hdr->type)),\n\t\t ntohs(chunk->chunk_hdr->length), chunk->skb->len);\n\n\treturn chunk;\n}",
        "func": "struct sctp_chunk *sctp_inq_pop(struct sctp_inq *queue)\n{\n\tstruct sctp_chunk *chunk;\n\tsctp_chunkhdr_t *ch = NULL;\n\n\t/* The assumption is that we are safe to process the chunks\n\t * at this time.\n\t */\n\n\tif ((chunk = queue->in_progress)) {\n\t\t/* There is a packet that we have been working on.\n\t\t * Any post processing work to do before we move on?\n\t\t */\n\t\tif (chunk->singleton ||\n\t\t    chunk->end_of_packet ||\n\t\t    chunk->pdiscard) {\n\t\t\tsctp_chunk_free(chunk);\n\t\t\tchunk = queue->in_progress = NULL;\n\t\t} else {\n\t\t\t/* Nothing to do. Next chunk in the packet, please. */\n\t\t\tch = (sctp_chunkhdr_t *) chunk->chunk_end;\n\t\t\t/* Force chunk->skb->data to chunk->chunk_end.  */\n\t\t\tskb_pull(chunk->skb, chunk->chunk_end - chunk->skb->data);\n\t\t\t/* We are guaranteed to pull a SCTP header. */\n\t\t}\n\t}\n\n\t/* Do we need to take the next packet out of the queue to process? */\n\tif (!chunk) {\n\t\tstruct list_head *entry;\n\n\t\t/* Is the queue empty?  */\n\t\tif (list_empty(&queue->in_chunk_list))\n\t\t\treturn NULL;\n\n\t\tentry = queue->in_chunk_list.next;\n\t\tchunk = queue->in_progress =\n\t\t\tlist_entry(entry, struct sctp_chunk, list);\n\t\tlist_del_init(entry);\n\n\t\t/* This is the first chunk in the packet.  */\n\t\tchunk->singleton = 1;\n\t\tch = (sctp_chunkhdr_t *) chunk->skb->data;\n\t\tchunk->data_accepted = 0;\n\t}\n\n\tchunk->chunk_hdr = ch;\n\tchunk->chunk_end = ((__u8 *)ch) + WORD_ROUND(ntohs(ch->length));\n\t/* In the unlikely case of an IP reassembly, the skb could be\n\t * non-linear. If so, update chunk_end so that it doesn't go past\n\t * the skb->tail.\n\t */\n\tif (unlikely(skb_is_nonlinear(chunk->skb))) {\n\t\tif (chunk->chunk_end > skb_tail_pointer(chunk->skb))\n\t\t\tchunk->chunk_end = skb_tail_pointer(chunk->skb);\n\t}\n\tskb_pull(chunk->skb, sizeof(sctp_chunkhdr_t));\n\tchunk->subh.v = NULL; /* Subheader is no longer valid.  */\n\n\tif (chunk->chunk_end + sizeof(sctp_chunkhdr_t) <\n\t    skb_tail_pointer(chunk->skb)) {\n\t\t/* This is not a singleton */\n\t\tchunk->singleton = 0;\n\t} else if (chunk->chunk_end > skb_tail_pointer(chunk->skb)) {\n\t\t/* Discard inside state machine. */\n\t\tchunk->pdiscard = 1;\n\t\tchunk->chunk_end = skb_tail_pointer(chunk->skb);\n\t} else {\n\t\t/* We are at the end of the packet, so mark the chunk\n\t\t * in case we need to send a SACK.\n\t\t */\n\t\tchunk->end_of_packet = 1;\n\t}\n\n\tpr_debug(\"+++sctp_inq_pop+++ chunk:%p[%s], length:%d, skb->len:%d\\n\",\n\t\t chunk, sctp_cname(SCTP_ST_CHUNK(chunk->chunk_hdr->type)),\n\t\t ntohs(chunk->chunk_hdr->length), chunk->skb->len);\n\n\treturn chunk;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -19,18 +19,9 @@\n \t\t} else {\n \t\t\t/* Nothing to do. Next chunk in the packet, please. */\n \t\t\tch = (sctp_chunkhdr_t *) chunk->chunk_end;\n-\n \t\t\t/* Force chunk->skb->data to chunk->chunk_end.  */\n-\t\t\tskb_pull(chunk->skb,\n-\t\t\t\t chunk->chunk_end - chunk->skb->data);\n-\n-\t\t\t/* Verify that we have at least chunk headers\n-\t\t\t * worth of buffer left.\n-\t\t\t */\n-\t\t\tif (skb_headlen(chunk->skb) < sizeof(sctp_chunkhdr_t)) {\n-\t\t\t\tsctp_chunk_free(chunk);\n-\t\t\t\tchunk = queue->in_progress = NULL;\n-\t\t\t}\n+\t\t\tskb_pull(chunk->skb, chunk->chunk_end - chunk->skb->data);\n+\t\t\t/* We are guaranteed to pull a SCTP header. */\n \t\t}\n \t}\n \n@@ -66,24 +57,14 @@\n \tskb_pull(chunk->skb, sizeof(sctp_chunkhdr_t));\n \tchunk->subh.v = NULL; /* Subheader is no longer valid.  */\n \n-\tif (chunk->chunk_end < skb_tail_pointer(chunk->skb)) {\n+\tif (chunk->chunk_end + sizeof(sctp_chunkhdr_t) <\n+\t    skb_tail_pointer(chunk->skb)) {\n \t\t/* This is not a singleton */\n \t\tchunk->singleton = 0;\n \t} else if (chunk->chunk_end > skb_tail_pointer(chunk->skb)) {\n-\t\t/* RFC 2960, Section 6.10  Bundling\n-\t\t *\n-\t\t * Partial chunks MUST NOT be placed in an SCTP packet.\n-\t\t * If the receiver detects a partial chunk, it MUST drop\n-\t\t * the chunk.\n-\t\t *\n-\t\t * Since the end of the chunk is past the end of our buffer\n-\t\t * (which contains the whole packet, we can freely discard\n-\t\t * the whole packet.\n-\t\t */\n-\t\tsctp_chunk_free(chunk);\n-\t\tchunk = queue->in_progress = NULL;\n-\n-\t\treturn NULL;\n+\t\t/* Discard inside state machine. */\n+\t\tchunk->pdiscard = 1;\n+\t\tchunk->chunk_end = skb_tail_pointer(chunk->skb);\n \t} else {\n \t\t/* We are at the end of the packet, so mark the chunk\n \t\t * in case we need to send a SACK.",
        "diff_line_info": {
            "deleted_lines": [
                "",
                "\t\t\tskb_pull(chunk->skb,",
                "\t\t\t\t chunk->chunk_end - chunk->skb->data);",
                "",
                "\t\t\t/* Verify that we have at least chunk headers",
                "\t\t\t * worth of buffer left.",
                "\t\t\t */",
                "\t\t\tif (skb_headlen(chunk->skb) < sizeof(sctp_chunkhdr_t)) {",
                "\t\t\t\tsctp_chunk_free(chunk);",
                "\t\t\t\tchunk = queue->in_progress = NULL;",
                "\t\t\t}",
                "\tif (chunk->chunk_end < skb_tail_pointer(chunk->skb)) {",
                "\t\t/* RFC 2960, Section 6.10  Bundling",
                "\t\t *",
                "\t\t * Partial chunks MUST NOT be placed in an SCTP packet.",
                "\t\t * If the receiver detects a partial chunk, it MUST drop",
                "\t\t * the chunk.",
                "\t\t *",
                "\t\t * Since the end of the chunk is past the end of our buffer",
                "\t\t * (which contains the whole packet, we can freely discard",
                "\t\t * the whole packet.",
                "\t\t */",
                "\t\tsctp_chunk_free(chunk);",
                "\t\tchunk = queue->in_progress = NULL;",
                "",
                "\t\treturn NULL;"
            ],
            "added_lines": [
                "\t\t\tskb_pull(chunk->skb, chunk->chunk_end - chunk->skb->data);",
                "\t\t\t/* We are guaranteed to pull a SCTP header. */",
                "\tif (chunk->chunk_end + sizeof(sctp_chunkhdr_t) <",
                "\t    skb_tail_pointer(chunk->skb)) {",
                "\t\t/* Discard inside state machine. */",
                "\t\tchunk->pdiscard = 1;",
                "\t\tchunk->chunk_end = skb_tail_pointer(chunk->skb);"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-3688",
        "func_name": "torvalds/linux/sctp_chunk_length_valid",
        "description": "The SCTP implementation in the Linux kernel before 3.17.4 allows remote attackers to cause a denial of service (memory consumption) by triggering a large number of chunks in an association's output queue, as demonstrated by ASCONF probes, related to net/sctp/inqueue.c and net/sctp/sm_statefuns.c.",
        "git_url": "https://github.com/torvalds/linux/commit/26b87c7881006311828bb0ab271a551a62dcceb4",
        "commit_title": "net: sctp: fix remote memory pressure from excessive queueing",
        "commit_text": " This scenario is not limited to ASCONF, just taken as one example triggering the issue. When receiving ASCONF probes in the form of ...    -------------- INIT[ASCONF; ASCONF_ACK] ------------->   <----------- INIT-ACK[ASCONF; ASCONF_ACK] ------------   -------------------- COOKIE-ECHO -------------------->   <-------------------- COOKIE-ACK ---------------------   ---- ASCONF_a; [ASCONF_b; ...; ASCONF_n;] JUNK ------>   [...]   ---- ASCONF_m; [ASCONF_o; ...; ASCONF_z;] JUNK ------>  ... where ASCONF_a, ASCONF_b, ..., ASCONF_z are good-formed ASCONFs and have increasing serial numbers, we process such ASCONF chunk(s) marked with !end_of_packet and !singleton, since we have not yet reached the SCTP packet end. SCTP does only do verification on a chunk by chunk basis, as an SCTP packet is nothing more than just a container of a stream of chunks which it eats up one by one.  We could run into the case that we receive a packet with a malformed tail, above marked as trailing JUNK. All previous chunks are here goodformed, so the stack will eat up all previous chunks up to this point. In case JUNK does not fit into a chunk header and there are no more other chunks in the input queue, or in case JUNK contains a garbage chunk header, but the encoded chunk length would exceed the skb tail, or we came here from an entirely different scenario and the chunk has pdiscard=1 mark (without having had a flush point), it will happen, that we will excessively queue up the association's output queue (a correct final chunk may then turn it into a response flood when flushing the queue ;)): I ran a simple script with incremental ASCONF serial numbers and could see the server side consuming excessive amount of RAM [before/after: up to 2GB and more].  The issue at heart is that the chunk train basically ends with !end_of_packet and !singleton markers and since commit 2e3216cd54b1 (\"sctp: Follow security requirement of responding with 1 packet\") therefore preventing an output queue flush point in sctp_do_sm() -> sctp_cmd_interpreter() on the input chunk (chunk = event_arg) even though local_cork is set, but its precedence has changed since then. In the normal case, the last chunk with end_of_packet=1 would trigger the queue flush to accommodate possible outgoing bundling.  In the input queue, sctp_inq_pop() seems to do the right thing in terms of discarding invalid chunks. So, above JUNK will not enter the state machine and instead be released and exit the sctp_assoc_bh_rcv() chunk processing loop. It's simply the flush point being missing at loop exit. Adding a try-flush approach on the output queue might not work as the underlying infrastructure might be long gone at this point due to the side-effect interpreter run.  One possibility, albeit a bit of a kludge, would be to defer invalid chunk freeing into the state machine in order to possibly trigger packet discards and thus indirectly a queue flush on error. It would surely be better to discard chunks as in the current, perhaps better controlled environment, but going back and forth, it's simply architecturally not possible. I tried various trailing JUNK attack cases and it seems to look good now.  Joint work with Vlad Yasevich. ",
        "func_before": "static inline int\nsctp_chunk_length_valid(struct sctp_chunk *chunk,\n\t\t\t   __u16 required_length)\n{\n\t__u16 chunk_length = ntohs(chunk->chunk_hdr->length);\n\n\tif (unlikely(chunk_length < required_length))\n\t\treturn 0;\n\n\treturn 1;\n}",
        "func": "static inline int\nsctp_chunk_length_valid(struct sctp_chunk *chunk,\n\t\t\t   __u16 required_length)\n{\n\t__u16 chunk_length = ntohs(chunk->chunk_hdr->length);\n\n\t/* Previously already marked? */\n\tif (unlikely(chunk->pdiscard))\n\t\treturn 0;\n\tif (unlikely(chunk_length < required_length))\n\t\treturn 0;\n\n\treturn 1;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,6 +4,9 @@\n {\n \t__u16 chunk_length = ntohs(chunk->chunk_hdr->length);\n \n+\t/* Previously already marked? */\n+\tif (unlikely(chunk->pdiscard))\n+\t\treturn 0;\n \tif (unlikely(chunk_length < required_length))\n \t\treturn 0;\n ",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t/* Previously already marked? */",
                "\tif (unlikely(chunk->pdiscard))",
                "\t\treturn 0;"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-7841",
        "func_name": "torvalds/linux/sctp_process_param",
        "description": "The sctp_process_param function in net/sctp/sm_make_chunk.c in the SCTP implementation in the Linux kernel before 3.17.4, when ASCONF is used, allows remote attackers to cause a denial of service (NULL pointer dereference and system crash) via a malformed INIT chunk.",
        "git_url": "https://github.com/torvalds/linux/commit/e40607cbe270a9e8360907cb1e62ddf0736e4864",
        "commit_title": "net: sctp: fix NULL pointer dereference in af->from_addr_param on malformed packet",
        "commit_text": " An SCTP server doing ASCONF will panic on malformed INIT ping-of-death in the form of:    ------------ INIT[PARAM: SET_PRIMARY_IP] ------------>  While the INIT chunk parameter verification dissects through many things in order to detect malformed input, it misses to actually check parameters inside of parameters. E.g. RFC5061, section 4.2.4 proposes a 'set primary IP address' parameter in ASCONF, which has as a subparameter an address parameter.  So an attacker may send a parameter type other than SCTP_PARAM_IPV4_ADDRESS or SCTP_PARAM_IPV6_ADDRESS, param_type2af() will subsequently return 0 and thus sctp_get_af_specific() returns NULL, too, which we then happily dereference unconditionally through af->from_addr_param().  The trace for the log:  BUG: unable to handle kernel NULL pointer dereference at 0000000000000078 IP: [<ffffffffa01e9c62>] sctp_process_init+0x492/0x990 [sctp] PGD 0 Oops: 0000 [#1] SMP [...] Pid: 0, comm: swapper Not tainted 2.6.32-504.el6.x86_64 #1 Bochs Bochs RIP: 0010:[<ffffffffa01e9c62>]  [<ffffffffa01e9c62>] sctp_process_init+0x492/0x990 [sctp] [...] Call Trace:  <IRQ>  [<ffffffffa01f2add>] ? sctp_bind_addr_copy+0x5d/0xe0 [sctp]  [<ffffffffa01e1fcb>] sctp_sf_do_5_1B_init+0x21b/0x340 [sctp]  [<ffffffffa01e3751>] sctp_do_sm+0x71/0x1210 [sctp]  [<ffffffffa01e5c09>] ? sctp_endpoint_lookup_assoc+0xc9/0xf0 [sctp]  [<ffffffffa01e61f6>] sctp_endpoint_bh_rcv+0x116/0x230 [sctp]  [<ffffffffa01ee986>] sctp_inq_push+0x56/0x80 [sctp]  [<ffffffffa01fcc42>] sctp_rcv+0x982/0xa10 [sctp]  [<ffffffffa01d5123>] ? ipt_local_in_hook+0x23/0x28 [iptable_filter]  [<ffffffff8148bdc9>] ? nf_iterate+0x69/0xb0  [<ffffffff81496d10>] ? ip_local_deliver_finish+0x0/0x2d0  [<ffffffff8148bf86>] ? nf_hook_slow+0x76/0x120  [<ffffffff81496d10>] ? ip_local_deliver_finish+0x0/0x2d0 [...]  A minimal way to address this is to check for NULL as we do on all other such occasions where we know sctp_get_af_specific() could possibly return with NULL.  Cc: Vlad Yasevich <vyasevich@gmail.com>",
        "func_before": "static int sctp_process_param(struct sctp_association *asoc,\n\t\t\t      union sctp_params param,\n\t\t\t      const union sctp_addr *peer_addr,\n\t\t\t      gfp_t gfp)\n{\n\tstruct net *net = sock_net(asoc->base.sk);\n\tunion sctp_addr addr;\n\tint i;\n\t__u16 sat;\n\tint retval = 1;\n\tsctp_scope_t scope;\n\ttime_t stale;\n\tstruct sctp_af *af;\n\tunion sctp_addr_param *addr_param;\n\tstruct sctp_transport *t;\n\tstruct sctp_endpoint *ep = asoc->ep;\n\n\t/* We maintain all INIT parameters in network byte order all the\n\t * time.  This allows us to not worry about whether the parameters\n\t * came from a fresh INIT, and INIT ACK, or were stored in a cookie.\n\t */\n\tswitch (param.p->type) {\n\tcase SCTP_PARAM_IPV6_ADDRESS:\n\t\tif (PF_INET6 != asoc->base.sk->sk_family)\n\t\t\tbreak;\n\t\tgoto do_addr_param;\n\n\tcase SCTP_PARAM_IPV4_ADDRESS:\n\t\t/* v4 addresses are not allowed on v6-only socket */\n\t\tif (ipv6_only_sock(asoc->base.sk))\n\t\t\tbreak;\ndo_addr_param:\n\t\taf = sctp_get_af_specific(param_type2af(param.p->type));\n\t\taf->from_addr_param(&addr, param.addr, htons(asoc->peer.port), 0);\n\t\tscope = sctp_scope(peer_addr);\n\t\tif (sctp_in_scope(net, &addr, scope))\n\t\t\tif (!sctp_assoc_add_peer(asoc, &addr, gfp, SCTP_UNCONFIRMED))\n\t\t\t\treturn 0;\n\t\tbreak;\n\n\tcase SCTP_PARAM_COOKIE_PRESERVATIVE:\n\t\tif (!net->sctp.cookie_preserve_enable)\n\t\t\tbreak;\n\n\t\tstale = ntohl(param.life->lifespan_increment);\n\n\t\t/* Suggested Cookie Life span increment's unit is msec,\n\t\t * (1/1000sec).\n\t\t */\n\t\tasoc->cookie_life = ktime_add_ms(asoc->cookie_life, stale);\n\t\tbreak;\n\n\tcase SCTP_PARAM_HOST_NAME_ADDRESS:\n\t\tpr_debug(\"%s: unimplemented SCTP_HOST_NAME_ADDRESS\\n\", __func__);\n\t\tbreak;\n\n\tcase SCTP_PARAM_SUPPORTED_ADDRESS_TYPES:\n\t\t/* Turn off the default values first so we'll know which\n\t\t * ones are really set by the peer.\n\t\t */\n\t\tasoc->peer.ipv4_address = 0;\n\t\tasoc->peer.ipv6_address = 0;\n\n\t\t/* Assume that peer supports the address family\n\t\t * by which it sends a packet.\n\t\t */\n\t\tif (peer_addr->sa.sa_family == AF_INET6)\n\t\t\tasoc->peer.ipv6_address = 1;\n\t\telse if (peer_addr->sa.sa_family == AF_INET)\n\t\t\tasoc->peer.ipv4_address = 1;\n\n\t\t/* Cycle through address types; avoid divide by 0. */\n\t\tsat = ntohs(param.p->length) - sizeof(sctp_paramhdr_t);\n\t\tif (sat)\n\t\t\tsat /= sizeof(__u16);\n\n\t\tfor (i = 0; i < sat; ++i) {\n\t\t\tswitch (param.sat->types[i]) {\n\t\t\tcase SCTP_PARAM_IPV4_ADDRESS:\n\t\t\t\tasoc->peer.ipv4_address = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase SCTP_PARAM_IPV6_ADDRESS:\n\t\t\t\tif (PF_INET6 == asoc->base.sk->sk_family)\n\t\t\t\t\tasoc->peer.ipv6_address = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase SCTP_PARAM_HOST_NAME_ADDRESS:\n\t\t\t\tasoc->peer.hostname_address = 1;\n\t\t\t\tbreak;\n\n\t\t\tdefault: /* Just ignore anything else.  */\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tbreak;\n\n\tcase SCTP_PARAM_STATE_COOKIE:\n\t\tasoc->peer.cookie_len =\n\t\t\tntohs(param.p->length) - sizeof(sctp_paramhdr_t);\n\t\tasoc->peer.cookie = param.cookie->body;\n\t\tbreak;\n\n\tcase SCTP_PARAM_HEARTBEAT_INFO:\n\t\t/* Would be odd to receive, but it causes no problems. */\n\t\tbreak;\n\n\tcase SCTP_PARAM_UNRECOGNIZED_PARAMETERS:\n\t\t/* Rejected during verify stage. */\n\t\tbreak;\n\n\tcase SCTP_PARAM_ECN_CAPABLE:\n\t\tasoc->peer.ecn_capable = 1;\n\t\tbreak;\n\n\tcase SCTP_PARAM_ADAPTATION_LAYER_IND:\n\t\tasoc->peer.adaptation_ind = ntohl(param.aind->adaptation_ind);\n\t\tbreak;\n\n\tcase SCTP_PARAM_SET_PRIMARY:\n\t\tif (!net->sctp.addip_enable)\n\t\t\tgoto fall_through;\n\n\t\taddr_param = param.v + sizeof(sctp_addip_param_t);\n\n\t\taf = sctp_get_af_specific(param_type2af(param.p->type));\n\t\taf->from_addr_param(&addr, addr_param,\n\t\t\t\t    htons(asoc->peer.port), 0);\n\n\t\t/* if the address is invalid, we can't process it.\n\t\t * XXX: see spec for what to do.\n\t\t */\n\t\tif (!af->addr_valid(&addr, NULL, NULL))\n\t\t\tbreak;\n\n\t\tt = sctp_assoc_lookup_paddr(asoc, &addr);\n\t\tif (!t)\n\t\t\tbreak;\n\n\t\tsctp_assoc_set_primary(asoc, t);\n\t\tbreak;\n\n\tcase SCTP_PARAM_SUPPORTED_EXT:\n\t\tsctp_process_ext_param(asoc, param);\n\t\tbreak;\n\n\tcase SCTP_PARAM_FWD_TSN_SUPPORT:\n\t\tif (net->sctp.prsctp_enable) {\n\t\t\tasoc->peer.prsctp_capable = 1;\n\t\t\tbreak;\n\t\t}\n\t\t/* Fall Through */\n\t\tgoto fall_through;\n\n\tcase SCTP_PARAM_RANDOM:\n\t\tif (!ep->auth_enable)\n\t\t\tgoto fall_through;\n\n\t\t/* Save peer's random parameter */\n\t\tasoc->peer.peer_random = kmemdup(param.p,\n\t\t\t\t\t    ntohs(param.p->length), gfp);\n\t\tif (!asoc->peer.peer_random) {\n\t\t\tretval = 0;\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\n\tcase SCTP_PARAM_HMAC_ALGO:\n\t\tif (!ep->auth_enable)\n\t\t\tgoto fall_through;\n\n\t\t/* Save peer's HMAC list */\n\t\tasoc->peer.peer_hmacs = kmemdup(param.p,\n\t\t\t\t\t    ntohs(param.p->length), gfp);\n\t\tif (!asoc->peer.peer_hmacs) {\n\t\t\tretval = 0;\n\t\t\tbreak;\n\t\t}\n\n\t\t/* Set the default HMAC the peer requested*/\n\t\tsctp_auth_asoc_set_default_hmac(asoc, param.hmac_algo);\n\t\tbreak;\n\n\tcase SCTP_PARAM_CHUNKS:\n\t\tif (!ep->auth_enable)\n\t\t\tgoto fall_through;\n\n\t\tasoc->peer.peer_chunks = kmemdup(param.p,\n\t\t\t\t\t    ntohs(param.p->length), gfp);\n\t\tif (!asoc->peer.peer_chunks)\n\t\t\tretval = 0;\n\t\tbreak;\nfall_through:\n\tdefault:\n\t\t/* Any unrecognized parameters should have been caught\n\t\t * and handled by sctp_verify_param() which should be\n\t\t * called prior to this routine.  Simply log the error\n\t\t * here.\n\t\t */\n\t\tpr_debug(\"%s: ignoring param:%d for association:%p.\\n\",\n\t\t\t __func__, ntohs(param.p->type), asoc);\n\t\tbreak;\n\t}\n\n\treturn retval;\n}",
        "func": "static int sctp_process_param(struct sctp_association *asoc,\n\t\t\t      union sctp_params param,\n\t\t\t      const union sctp_addr *peer_addr,\n\t\t\t      gfp_t gfp)\n{\n\tstruct net *net = sock_net(asoc->base.sk);\n\tunion sctp_addr addr;\n\tint i;\n\t__u16 sat;\n\tint retval = 1;\n\tsctp_scope_t scope;\n\ttime_t stale;\n\tstruct sctp_af *af;\n\tunion sctp_addr_param *addr_param;\n\tstruct sctp_transport *t;\n\tstruct sctp_endpoint *ep = asoc->ep;\n\n\t/* We maintain all INIT parameters in network byte order all the\n\t * time.  This allows us to not worry about whether the parameters\n\t * came from a fresh INIT, and INIT ACK, or were stored in a cookie.\n\t */\n\tswitch (param.p->type) {\n\tcase SCTP_PARAM_IPV6_ADDRESS:\n\t\tif (PF_INET6 != asoc->base.sk->sk_family)\n\t\t\tbreak;\n\t\tgoto do_addr_param;\n\n\tcase SCTP_PARAM_IPV4_ADDRESS:\n\t\t/* v4 addresses are not allowed on v6-only socket */\n\t\tif (ipv6_only_sock(asoc->base.sk))\n\t\t\tbreak;\ndo_addr_param:\n\t\taf = sctp_get_af_specific(param_type2af(param.p->type));\n\t\taf->from_addr_param(&addr, param.addr, htons(asoc->peer.port), 0);\n\t\tscope = sctp_scope(peer_addr);\n\t\tif (sctp_in_scope(net, &addr, scope))\n\t\t\tif (!sctp_assoc_add_peer(asoc, &addr, gfp, SCTP_UNCONFIRMED))\n\t\t\t\treturn 0;\n\t\tbreak;\n\n\tcase SCTP_PARAM_COOKIE_PRESERVATIVE:\n\t\tif (!net->sctp.cookie_preserve_enable)\n\t\t\tbreak;\n\n\t\tstale = ntohl(param.life->lifespan_increment);\n\n\t\t/* Suggested Cookie Life span increment's unit is msec,\n\t\t * (1/1000sec).\n\t\t */\n\t\tasoc->cookie_life = ktime_add_ms(asoc->cookie_life, stale);\n\t\tbreak;\n\n\tcase SCTP_PARAM_HOST_NAME_ADDRESS:\n\t\tpr_debug(\"%s: unimplemented SCTP_HOST_NAME_ADDRESS\\n\", __func__);\n\t\tbreak;\n\n\tcase SCTP_PARAM_SUPPORTED_ADDRESS_TYPES:\n\t\t/* Turn off the default values first so we'll know which\n\t\t * ones are really set by the peer.\n\t\t */\n\t\tasoc->peer.ipv4_address = 0;\n\t\tasoc->peer.ipv6_address = 0;\n\n\t\t/* Assume that peer supports the address family\n\t\t * by which it sends a packet.\n\t\t */\n\t\tif (peer_addr->sa.sa_family == AF_INET6)\n\t\t\tasoc->peer.ipv6_address = 1;\n\t\telse if (peer_addr->sa.sa_family == AF_INET)\n\t\t\tasoc->peer.ipv4_address = 1;\n\n\t\t/* Cycle through address types; avoid divide by 0. */\n\t\tsat = ntohs(param.p->length) - sizeof(sctp_paramhdr_t);\n\t\tif (sat)\n\t\t\tsat /= sizeof(__u16);\n\n\t\tfor (i = 0; i < sat; ++i) {\n\t\t\tswitch (param.sat->types[i]) {\n\t\t\tcase SCTP_PARAM_IPV4_ADDRESS:\n\t\t\t\tasoc->peer.ipv4_address = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase SCTP_PARAM_IPV6_ADDRESS:\n\t\t\t\tif (PF_INET6 == asoc->base.sk->sk_family)\n\t\t\t\t\tasoc->peer.ipv6_address = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase SCTP_PARAM_HOST_NAME_ADDRESS:\n\t\t\t\tasoc->peer.hostname_address = 1;\n\t\t\t\tbreak;\n\n\t\t\tdefault: /* Just ignore anything else.  */\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tbreak;\n\n\tcase SCTP_PARAM_STATE_COOKIE:\n\t\tasoc->peer.cookie_len =\n\t\t\tntohs(param.p->length) - sizeof(sctp_paramhdr_t);\n\t\tasoc->peer.cookie = param.cookie->body;\n\t\tbreak;\n\n\tcase SCTP_PARAM_HEARTBEAT_INFO:\n\t\t/* Would be odd to receive, but it causes no problems. */\n\t\tbreak;\n\n\tcase SCTP_PARAM_UNRECOGNIZED_PARAMETERS:\n\t\t/* Rejected during verify stage. */\n\t\tbreak;\n\n\tcase SCTP_PARAM_ECN_CAPABLE:\n\t\tasoc->peer.ecn_capable = 1;\n\t\tbreak;\n\n\tcase SCTP_PARAM_ADAPTATION_LAYER_IND:\n\t\tasoc->peer.adaptation_ind = ntohl(param.aind->adaptation_ind);\n\t\tbreak;\n\n\tcase SCTP_PARAM_SET_PRIMARY:\n\t\tif (!net->sctp.addip_enable)\n\t\t\tgoto fall_through;\n\n\t\taddr_param = param.v + sizeof(sctp_addip_param_t);\n\n\t\taf = sctp_get_af_specific(param_type2af(param.p->type));\n\t\tif (af == NULL)\n\t\t\tbreak;\n\n\t\taf->from_addr_param(&addr, addr_param,\n\t\t\t\t    htons(asoc->peer.port), 0);\n\n\t\t/* if the address is invalid, we can't process it.\n\t\t * XXX: see spec for what to do.\n\t\t */\n\t\tif (!af->addr_valid(&addr, NULL, NULL))\n\t\t\tbreak;\n\n\t\tt = sctp_assoc_lookup_paddr(asoc, &addr);\n\t\tif (!t)\n\t\t\tbreak;\n\n\t\tsctp_assoc_set_primary(asoc, t);\n\t\tbreak;\n\n\tcase SCTP_PARAM_SUPPORTED_EXT:\n\t\tsctp_process_ext_param(asoc, param);\n\t\tbreak;\n\n\tcase SCTP_PARAM_FWD_TSN_SUPPORT:\n\t\tif (net->sctp.prsctp_enable) {\n\t\t\tasoc->peer.prsctp_capable = 1;\n\t\t\tbreak;\n\t\t}\n\t\t/* Fall Through */\n\t\tgoto fall_through;\n\n\tcase SCTP_PARAM_RANDOM:\n\t\tif (!ep->auth_enable)\n\t\t\tgoto fall_through;\n\n\t\t/* Save peer's random parameter */\n\t\tasoc->peer.peer_random = kmemdup(param.p,\n\t\t\t\t\t    ntohs(param.p->length), gfp);\n\t\tif (!asoc->peer.peer_random) {\n\t\t\tretval = 0;\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\n\tcase SCTP_PARAM_HMAC_ALGO:\n\t\tif (!ep->auth_enable)\n\t\t\tgoto fall_through;\n\n\t\t/* Save peer's HMAC list */\n\t\tasoc->peer.peer_hmacs = kmemdup(param.p,\n\t\t\t\t\t    ntohs(param.p->length), gfp);\n\t\tif (!asoc->peer.peer_hmacs) {\n\t\t\tretval = 0;\n\t\t\tbreak;\n\t\t}\n\n\t\t/* Set the default HMAC the peer requested*/\n\t\tsctp_auth_asoc_set_default_hmac(asoc, param.hmac_algo);\n\t\tbreak;\n\n\tcase SCTP_PARAM_CHUNKS:\n\t\tif (!ep->auth_enable)\n\t\t\tgoto fall_through;\n\n\t\tasoc->peer.peer_chunks = kmemdup(param.p,\n\t\t\t\t\t    ntohs(param.p->length), gfp);\n\t\tif (!asoc->peer.peer_chunks)\n\t\t\tretval = 0;\n\t\tbreak;\nfall_through:\n\tdefault:\n\t\t/* Any unrecognized parameters should have been caught\n\t\t * and handled by sctp_verify_param() which should be\n\t\t * called prior to this routine.  Simply log the error\n\t\t * here.\n\t\t */\n\t\tpr_debug(\"%s: ignoring param:%d for association:%p.\\n\",\n\t\t\t __func__, ntohs(param.p->type), asoc);\n\t\tbreak;\n\t}\n\n\treturn retval;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -124,6 +124,9 @@\n \t\taddr_param = param.v + sizeof(sctp_addip_param_t);\n \n \t\taf = sctp_get_af_specific(param_type2af(param.p->type));\n+\t\tif (af == NULL)\n+\t\t\tbreak;\n+\n \t\taf->from_addr_param(&addr, addr_param,\n \t\t\t\t    htons(asoc->peer.port), 0);\n ",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t\tif (af == NULL)",
                "\t\t\tbreak;",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2014-8116",
        "func_name": "file/doshn",
        "description": "The ELF parser (readelf.c) in file before 5.21 allows remote attackers to cause a denial of service (CPU consumption or crash) via a large number of (1) program or (2) section headers or (3) invalid capabilities.",
        "git_url": "https://github.com/file/file/commit/d7cdad007c507e6c79f51f058dd77fab70ceb9f6",
        "commit_title": "Stop reporting bad capabilities after the first few.",
        "commit_text": "",
        "func_before": "private int\ndoshn(struct magic_set *ms, int clazz, int swap, int fd, off_t off, int num,\n    size_t size, off_t fsize, int *flags, int mach, int strtab)\n{\n\tElf32_Shdr sh32;\n\tElf64_Shdr sh64;\n\tint stripped = 1;\n\tvoid *nbuf;\n\toff_t noff, coff, name_off;\n\tuint64_t cap_hw1 = 0;\t/* SunOS 5.x hardware capabilites */\n\tuint64_t cap_sf1 = 0;\t/* SunOS 5.x software capabilites */\n\tchar name[50];\n\n\tif (size != xsh_sizeof) {\n\t\tif (file_printf(ms, \", corrupted section header size\") == -1)\n\t\t\treturn -1;\n\t\treturn 0;\n\t}\n\n\t/* Read offset of name section to be able to read section names later */\n\tif (pread(fd, xsh_addr, xsh_sizeof, off + size * strtab) == -1) {\n\t\tfile_badread(ms);\n\t\treturn -1;\n\t}\n\tname_off = xsh_offset;\n\n\tfor ( ; num; num--) {\n\t\t/* Read the name of this section. */\n\t\tif (pread(fd, name, sizeof(name), name_off + xsh_name) == -1) {\n\t\t\tfile_badread(ms);\n\t\t\treturn -1;\n\t\t}\n\t\tname[sizeof(name) - 1] = '\\0';\n\t\tif (strcmp(name, \".debug_info\") == 0)\n\t\t\tstripped = 0;\n\n\t\tif (pread(fd, xsh_addr, xsh_sizeof, off) == -1) {\n\t\t\tfile_badread(ms);\n\t\t\treturn -1;\n\t\t}\n\t\toff += size;\n\n\t\t/* Things we can determine before we seek */\n\t\tswitch (xsh_type) {\n\t\tcase SHT_SYMTAB:\n#if 0\n\t\tcase SHT_DYNSYM:\n#endif\n\t\t\tstripped = 0;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tif (xsh_offset > fsize) {\n\t\t\t\t/* Perhaps warn here */\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\n\t\t/* Things we can determine when we seek */\n\t\tswitch (xsh_type) {\n\t\tcase SHT_NOTE:\n\t\t\tif ((nbuf = malloc(xsh_size)) == NULL) {\n\t\t\t\tfile_error(ms, errno, \"Cannot allocate memory\"\n\t\t\t\t    \" for note\");\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tif (pread(fd, nbuf, xsh_size, xsh_offset) == -1) {\n\t\t\t\tfile_badread(ms);\n\t\t\t\tfree(nbuf);\n\t\t\t\treturn -1;\n\t\t\t}\n\n\t\t\tnoff = 0;\n\t\t\tfor (;;) {\n\t\t\t\tif (noff >= (off_t)xsh_size)\n\t\t\t\t\tbreak;\n\t\t\t\tnoff = donote(ms, nbuf, (size_t)noff,\n\t\t\t\t    xsh_size, clazz, swap, 4, flags);\n\t\t\t\tif (noff == 0)\n\t\t\t\t\tbreak;\n\t\t\t}\n\t\t\tfree(nbuf);\n\t\t\tbreak;\n\t\tcase SHT_SUNW_cap:\n\t\t\tswitch (mach) {\n\t\t\tcase EM_SPARC:\n\t\t\tcase EM_SPARCV9:\n\t\t\tcase EM_IA_64:\n\t\t\tcase EM_386:\n\t\t\tcase EM_AMD64:\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tgoto skip;\n\t\t\t}\n\n\t\t\tif (lseek(fd, xsh_offset, SEEK_SET) == (off_t)-1) {\n\t\t\t\tfile_badseek(ms);\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tcoff = 0;\n\t\t\tfor (;;) {\n\t\t\t\tElf32_Cap cap32;\n\t\t\t\tElf64_Cap cap64;\n\t\t\t\tchar cbuf[/*CONSTCOND*/\n\t\t\t\t    MAX(sizeof cap32, sizeof cap64)];\n\t\t\t\tif ((coff += xcap_sizeof) > (off_t)xsh_size)\n\t\t\t\t\tbreak;\n\t\t\t\tif (read(fd, cbuf, (size_t)xcap_sizeof) !=\n\t\t\t\t    (ssize_t)xcap_sizeof) {\n\t\t\t\t\tfile_badread(ms);\n\t\t\t\t\treturn -1;\n\t\t\t\t}\n\t\t\t\tif (cbuf[0] == 'A') {\n#ifdef notyet\n\t\t\t\t\tchar *p = cbuf + 1;\n\t\t\t\t\tuint32_t len, tag;\n\t\t\t\t\tmemcpy(&len, p, sizeof(len));\n\t\t\t\t\tp += 4;\n\t\t\t\t\tlen = getu32(swap, len);\n\t\t\t\t\tif (memcmp(\"gnu\", p, 3) != 0) {\n\t\t\t\t\t    if (file_printf(ms,\n\t\t\t\t\t\t\", unknown capability %.3s\", p)\n\t\t\t\t\t\t== -1)\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\t    break;\n\t\t\t\t\t}\n\t\t\t\t\tp += strlen(p) + 1;\n\t\t\t\t\ttag = *p++;\n\t\t\t\t\tmemcpy(&len, p, sizeof(len));\n\t\t\t\t\tp += 4;\n\t\t\t\t\tlen = getu32(swap, len);\n\t\t\t\t\tif (tag != 1) {\n\t\t\t\t\t    if (file_printf(ms, \", unknown gnu\"\n\t\t\t\t\t\t\" capability tag %d\", tag)\n\t\t\t\t\t\t== -1)\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\t    break;\n\t\t\t\t\t}\n\t\t\t\t\t// gnu attributes \n#endif\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\t(void)memcpy(xcap_addr, cbuf, xcap_sizeof);\n\t\t\t\tswitch (xcap_tag) {\n\t\t\t\tcase CA_SUNW_NULL:\n\t\t\t\t\tbreak;\n\t\t\t\tcase CA_SUNW_HW_1:\n\t\t\t\t\tcap_hw1 |= xcap_val;\n\t\t\t\t\tbreak;\n\t\t\t\tcase CA_SUNW_SF_1:\n\t\t\t\t\tcap_sf1 |= xcap_val;\n\t\t\t\t\tbreak;\n\t\t\t\tdefault:\n\t\t\t\t\tif (file_printf(ms,\n\t\t\t\t\t    \", with unknown capability \"\n\t\t\t\t\t    \"0x%\" INT64_T_FORMAT \"x = 0x%\"\n\t\t\t\t\t    INT64_T_FORMAT \"x\",\n\t\t\t\t\t    (unsigned long long)xcap_tag,\n\t\t\t\t\t    (unsigned long long)xcap_val) == -1)\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\t/*FALLTHROUGH*/\n\t\tskip:\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (file_printf(ms, \", %sstripped\", stripped ? \"\" : \"not \") == -1)\n\t\treturn -1;\n\tif (cap_hw1) {\n\t\tconst cap_desc_t *cdp;\n\t\tswitch (mach) {\n\t\tcase EM_SPARC:\n\t\tcase EM_SPARC32PLUS:\n\t\tcase EM_SPARCV9:\n\t\t\tcdp = cap_desc_sparc;\n\t\t\tbreak;\n\t\tcase EM_386:\n\t\tcase EM_IA_64:\n\t\tcase EM_AMD64:\n\t\t\tcdp = cap_desc_386;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tcdp = NULL;\n\t\t\tbreak;\n\t\t}\n\t\tif (file_printf(ms, \", uses\") == -1)\n\t\t\treturn -1;\n\t\tif (cdp) {\n\t\t\twhile (cdp->cd_name) {\n\t\t\t\tif (cap_hw1 & cdp->cd_mask) {\n\t\t\t\t\tif (file_printf(ms,\n\t\t\t\t\t    \" %s\", cdp->cd_name) == -1)\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\tcap_hw1 &= ~cdp->cd_mask;\n\t\t\t\t}\n\t\t\t\t++cdp;\n\t\t\t}\n\t\t\tif (cap_hw1)\n\t\t\t\tif (file_printf(ms,\n\t\t\t\t    \" unknown hardware capability 0x%\"\n\t\t\t\t    INT64_T_FORMAT \"x\",\n\t\t\t\t    (unsigned long long)cap_hw1) == -1)\n\t\t\t\t\treturn -1;\n\t\t} else {\n\t\t\tif (file_printf(ms,\n\t\t\t    \" hardware capability 0x%\" INT64_T_FORMAT \"x\",\n\t\t\t    (unsigned long long)cap_hw1) == -1)\n\t\t\t\treturn -1;\n\t\t}\n\t}\n\tif (cap_sf1) {\n\t\tif (cap_sf1 & SF1_SUNW_FPUSED) {\n\t\t\tif (file_printf(ms,\n\t\t\t    (cap_sf1 & SF1_SUNW_FPKNWN)\n\t\t\t    ? \", uses frame pointer\"\n\t\t\t    : \", not known to use frame pointer\") == -1)\n\t\t\t\treturn -1;\n\t\t}\n\t\tcap_sf1 &= ~SF1_SUNW_MASK;\n\t\tif (cap_sf1)\n\t\t\tif (file_printf(ms,\n\t\t\t    \", with unknown software capability 0x%\"\n\t\t\t    INT64_T_FORMAT \"x\",\n\t\t\t    (unsigned long long)cap_sf1) == -1)\n\t\t\t\treturn -1;\n\t}\n\treturn 0;\n}",
        "func": "private int\ndoshn(struct magic_set *ms, int clazz, int swap, int fd, off_t off, int num,\n    size_t size, off_t fsize, int *flags, int mach, int strtab)\n{\n\tElf32_Shdr sh32;\n\tElf64_Shdr sh64;\n\tint stripped = 1;\n\tsize_t nbadcap = 0;\n\tvoid *nbuf;\n\toff_t noff, coff, name_off;\n\tuint64_t cap_hw1 = 0;\t/* SunOS 5.x hardware capabilites */\n\tuint64_t cap_sf1 = 0;\t/* SunOS 5.x software capabilites */\n\tchar name[50];\n\n\tif (size != xsh_sizeof) {\n\t\tif (file_printf(ms, \", corrupted section header size\") == -1)\n\t\t\treturn -1;\n\t\treturn 0;\n\t}\n\n\t/* Read offset of name section to be able to read section names later */\n\tif (pread(fd, xsh_addr, xsh_sizeof, off + size * strtab) == -1) {\n\t\tfile_badread(ms);\n\t\treturn -1;\n\t}\n\tname_off = xsh_offset;\n\n\tfor ( ; num; num--) {\n\t\t/* Read the name of this section. */\n\t\tif (pread(fd, name, sizeof(name), name_off + xsh_name) == -1) {\n\t\t\tfile_badread(ms);\n\t\t\treturn -1;\n\t\t}\n\t\tname[sizeof(name) - 1] = '\\0';\n\t\tif (strcmp(name, \".debug_info\") == 0)\n\t\t\tstripped = 0;\n\n\t\tif (pread(fd, xsh_addr, xsh_sizeof, off) == -1) {\n\t\t\tfile_badread(ms);\n\t\t\treturn -1;\n\t\t}\n\t\toff += size;\n\n\t\t/* Things we can determine before we seek */\n\t\tswitch (xsh_type) {\n\t\tcase SHT_SYMTAB:\n#if 0\n\t\tcase SHT_DYNSYM:\n#endif\n\t\t\tstripped = 0;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tif (xsh_offset > fsize) {\n\t\t\t\t/* Perhaps warn here */\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\n\t\t/* Things we can determine when we seek */\n\t\tswitch (xsh_type) {\n\t\tcase SHT_NOTE:\n\t\t\tif ((nbuf = malloc(xsh_size)) == NULL) {\n\t\t\t\tfile_error(ms, errno, \"Cannot allocate memory\"\n\t\t\t\t    \" for note\");\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tif (pread(fd, nbuf, xsh_size, xsh_offset) == -1) {\n\t\t\t\tfile_badread(ms);\n\t\t\t\tfree(nbuf);\n\t\t\t\treturn -1;\n\t\t\t}\n\n\t\t\tnoff = 0;\n\t\t\tfor (;;) {\n\t\t\t\tif (noff >= (off_t)xsh_size)\n\t\t\t\t\tbreak;\n\t\t\t\tnoff = donote(ms, nbuf, (size_t)noff,\n\t\t\t\t    xsh_size, clazz, swap, 4, flags);\n\t\t\t\tif (noff == 0)\n\t\t\t\t\tbreak;\n\t\t\t}\n\t\t\tfree(nbuf);\n\t\t\tbreak;\n\t\tcase SHT_SUNW_cap:\n\t\t\tswitch (mach) {\n\t\t\tcase EM_SPARC:\n\t\t\tcase EM_SPARCV9:\n\t\t\tcase EM_IA_64:\n\t\t\tcase EM_386:\n\t\t\tcase EM_AMD64:\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tgoto skip;\n\t\t\t}\n\n\t\t\tif (nbadcap > 5)\n\t\t\t\tbreak;\n\t\t\tif (lseek(fd, xsh_offset, SEEK_SET) == (off_t)-1) {\n\t\t\t\tfile_badseek(ms);\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tcoff = 0;\n\t\t\tfor (;;) {\n\t\t\t\tElf32_Cap cap32;\n\t\t\t\tElf64_Cap cap64;\n\t\t\t\tchar cbuf[/*CONSTCOND*/\n\t\t\t\t    MAX(sizeof cap32, sizeof cap64)];\n\t\t\t\tif ((coff += xcap_sizeof) > (off_t)xsh_size)\n\t\t\t\t\tbreak;\n\t\t\t\tif (read(fd, cbuf, (size_t)xcap_sizeof) !=\n\t\t\t\t    (ssize_t)xcap_sizeof) {\n\t\t\t\t\tfile_badread(ms);\n\t\t\t\t\treturn -1;\n\t\t\t\t}\n\t\t\t\tif (cbuf[0] == 'A') {\n#ifdef notyet\n\t\t\t\t\tchar *p = cbuf + 1;\n\t\t\t\t\tuint32_t len, tag;\n\t\t\t\t\tmemcpy(&len, p, sizeof(len));\n\t\t\t\t\tp += 4;\n\t\t\t\t\tlen = getu32(swap, len);\n\t\t\t\t\tif (memcmp(\"gnu\", p, 3) != 0) {\n\t\t\t\t\t    if (file_printf(ms,\n\t\t\t\t\t\t\", unknown capability %.3s\", p)\n\t\t\t\t\t\t== -1)\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\t    break;\n\t\t\t\t\t}\n\t\t\t\t\tp += strlen(p) + 1;\n\t\t\t\t\ttag = *p++;\n\t\t\t\t\tmemcpy(&len, p, sizeof(len));\n\t\t\t\t\tp += 4;\n\t\t\t\t\tlen = getu32(swap, len);\n\t\t\t\t\tif (tag != 1) {\n\t\t\t\t\t    if (file_printf(ms, \", unknown gnu\"\n\t\t\t\t\t\t\" capability tag %d\", tag)\n\t\t\t\t\t\t== -1)\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\t    break;\n\t\t\t\t\t}\n\t\t\t\t\t// gnu attributes \n#endif\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\t(void)memcpy(xcap_addr, cbuf, xcap_sizeof);\n\t\t\t\tswitch (xcap_tag) {\n\t\t\t\tcase CA_SUNW_NULL:\n\t\t\t\t\tbreak;\n\t\t\t\tcase CA_SUNW_HW_1:\n\t\t\t\t\tcap_hw1 |= xcap_val;\n\t\t\t\t\tbreak;\n\t\t\t\tcase CA_SUNW_SF_1:\n\t\t\t\t\tcap_sf1 |= xcap_val;\n\t\t\t\t\tbreak;\n\t\t\t\tdefault:\n\t\t\t\t\tif (file_printf(ms,\n\t\t\t\t\t    \", with unknown capability \"\n\t\t\t\t\t    \"0x%\" INT64_T_FORMAT \"x = 0x%\"\n\t\t\t\t\t    INT64_T_FORMAT \"x\",\n\t\t\t\t\t    (unsigned long long)xcap_tag,\n\t\t\t\t\t    (unsigned long long)xcap_val) == -1)\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\tif (nbadcap++ > 2)\n\t\t\t\t\t\tcoff = xsh_size;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\t/*FALLTHROUGH*/\n\t\tskip:\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (file_printf(ms, \", %sstripped\", stripped ? \"\" : \"not \") == -1)\n\t\treturn -1;\n\tif (cap_hw1) {\n\t\tconst cap_desc_t *cdp;\n\t\tswitch (mach) {\n\t\tcase EM_SPARC:\n\t\tcase EM_SPARC32PLUS:\n\t\tcase EM_SPARCV9:\n\t\t\tcdp = cap_desc_sparc;\n\t\t\tbreak;\n\t\tcase EM_386:\n\t\tcase EM_IA_64:\n\t\tcase EM_AMD64:\n\t\t\tcdp = cap_desc_386;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tcdp = NULL;\n\t\t\tbreak;\n\t\t}\n\t\tif (file_printf(ms, \", uses\") == -1)\n\t\t\treturn -1;\n\t\tif (cdp) {\n\t\t\twhile (cdp->cd_name) {\n\t\t\t\tif (cap_hw1 & cdp->cd_mask) {\n\t\t\t\t\tif (file_printf(ms,\n\t\t\t\t\t    \" %s\", cdp->cd_name) == -1)\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\tcap_hw1 &= ~cdp->cd_mask;\n\t\t\t\t}\n\t\t\t\t++cdp;\n\t\t\t}\n\t\t\tif (cap_hw1)\n\t\t\t\tif (file_printf(ms,\n\t\t\t\t    \" unknown hardware capability 0x%\"\n\t\t\t\t    INT64_T_FORMAT \"x\",\n\t\t\t\t    (unsigned long long)cap_hw1) == -1)\n\t\t\t\t\treturn -1;\n\t\t} else {\n\t\t\tif (file_printf(ms,\n\t\t\t    \" hardware capability 0x%\" INT64_T_FORMAT \"x\",\n\t\t\t    (unsigned long long)cap_hw1) == -1)\n\t\t\t\treturn -1;\n\t\t}\n\t}\n\tif (cap_sf1) {\n\t\tif (cap_sf1 & SF1_SUNW_FPUSED) {\n\t\t\tif (file_printf(ms,\n\t\t\t    (cap_sf1 & SF1_SUNW_FPKNWN)\n\t\t\t    ? \", uses frame pointer\"\n\t\t\t    : \", not known to use frame pointer\") == -1)\n\t\t\t\treturn -1;\n\t\t}\n\t\tcap_sf1 &= ~SF1_SUNW_MASK;\n\t\tif (cap_sf1)\n\t\t\tif (file_printf(ms,\n\t\t\t    \", with unknown software capability 0x%\"\n\t\t\t    INT64_T_FORMAT \"x\",\n\t\t\t    (unsigned long long)cap_sf1) == -1)\n\t\t\t\treturn -1;\n\t}\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,6 +5,7 @@\n \tElf32_Shdr sh32;\n \tElf64_Shdr sh64;\n \tint stripped = 1;\n+\tsize_t nbadcap = 0;\n \tvoid *nbuf;\n \toff_t noff, coff, name_off;\n \tuint64_t cap_hw1 = 0;\t/* SunOS 5.x hardware capabilites */\n@@ -93,6 +94,8 @@\n \t\t\t\tgoto skip;\n \t\t\t}\n \n+\t\t\tif (nbadcap > 5)\n+\t\t\t\tbreak;\n \t\t\tif (lseek(fd, xsh_offset, SEEK_SET) == (off_t)-1) {\n \t\t\t\tfile_badseek(ms);\n \t\t\t\treturn -1;\n@@ -158,6 +161,8 @@\n \t\t\t\t\t    (unsigned long long)xcap_tag,\n \t\t\t\t\t    (unsigned long long)xcap_val) == -1)\n \t\t\t\t\t\treturn -1;\n+\t\t\t\t\tif (nbadcap++ > 2)\n+\t\t\t\t\t\tcoff = xsh_size;\n \t\t\t\t\tbreak;\n \t\t\t\t}\n \t\t\t}",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tsize_t nbadcap = 0;",
                "\t\t\tif (nbadcap > 5)",
                "\t\t\t\tbreak;",
                "\t\t\t\t\tif (nbadcap++ > 2)",
                "\t\t\t\t\t\tcoff = xsh_size;"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-8116",
        "func_name": "file/donote",
        "description": "The ELF parser (readelf.c) in file before 5.21 allows remote attackers to cause a denial of service (CPU consumption or crash) via a large number of (1) program or (2) section headers or (3) invalid capabilities.",
        "git_url": "https://github.com/file/file/commit/b4c01141e5367f247b84dcaf6aefbb4e741842b8",
        "commit_title": "- limit the number of program and section header number of sections to be",
        "commit_text": "  processed to avoid excessive processing time. - if a bad note is found, return 0 to stop processing immediately.",
        "func_before": "private size_t\ndonote(struct magic_set *ms, void *vbuf, size_t offset, size_t size,\n    int clazz, int swap, size_t align, int *flags)\n{\n\tElf32_Nhdr nh32;\n\tElf64_Nhdr nh64;\n\tsize_t noff, doff;\n#ifdef ELFCORE\n\tint os_style = -1;\n#endif\n\tuint32_t namesz, descsz;\n\tunsigned char *nbuf = CAST(unsigned char *, vbuf);\n\n\tif (xnh_sizeof + offset > size) {\n\t\t/*\n\t\t * We're out of note headers.\n\t\t */\n\t\treturn xnh_sizeof + offset;\n\t}\n\n\t(void)memcpy(xnh_addr, &nbuf[offset], xnh_sizeof);\n\toffset += xnh_sizeof;\n\n\tnamesz = xnh_namesz;\n\tdescsz = xnh_descsz;\n\tif ((namesz == 0) && (descsz == 0)) {\n\t\t/*\n\t\t * We're out of note headers.\n\t\t */\n\t\treturn (offset >= size) ? offset : size;\n\t}\n\n\tif (namesz & 0x80000000) {\n\t    (void)file_printf(ms, \", bad note name size 0x%lx\",\n\t\t(unsigned long)namesz);\n\t    return offset;\n\t}\n\n\tif (descsz & 0x80000000) {\n\t    (void)file_printf(ms, \", bad note description size 0x%lx\",\n\t\t(unsigned long)descsz);\n\t    return offset;\n\t}\n\n\n\tnoff = offset;\n\tdoff = ELF_ALIGN(offset + namesz);\n\n\tif (offset + namesz > size) {\n\t\t/*\n\t\t * We're past the end of the buffer.\n\t\t */\n\t\treturn doff;\n\t}\n\n\toffset = ELF_ALIGN(doff + descsz);\n\tif (doff + descsz > size) {\n\t\t/*\n\t\t * We're past the end of the buffer.\n\t\t */\n\t\treturn (offset >= size) ? offset : size;\n\t}\n\n\tif ((*flags & (FLAGS_DID_NOTE|FLAGS_DID_BUILD_ID)) ==\n\t    (FLAGS_DID_NOTE|FLAGS_DID_BUILD_ID))\n\t\tgoto core;\n\n\tif (namesz == 5 && strcmp((char *)&nbuf[noff], \"SuSE\") == 0 &&\n\t    xnh_type == NT_GNU_VERSION && descsz == 2) {\n\t    file_printf(ms, \", for SuSE %d.%d\", nbuf[doff], nbuf[doff + 1]);\n\t}\n\tif (namesz == 4 && strcmp((char *)&nbuf[noff], \"GNU\") == 0 &&\n\t    xnh_type == NT_GNU_VERSION && descsz == 16) {\n\t\tuint32_t desc[4];\n\t\t(void)memcpy(desc, &nbuf[doff], sizeof(desc));\n\n\t\tif (file_printf(ms, \", for GNU/\") == -1)\n\t\t\treturn size;\n\t\tswitch (elf_getu32(swap, desc[0])) {\n\t\tcase GNU_OS_LINUX:\n\t\t\tif (file_printf(ms, \"Linux\") == -1)\n\t\t\t\treturn size;\n\t\t\tbreak;\n\t\tcase GNU_OS_HURD:\n\t\t\tif (file_printf(ms, \"Hurd\") == -1)\n\t\t\t\treturn size;\n\t\t\tbreak;\n\t\tcase GNU_OS_SOLARIS:\n\t\t\tif (file_printf(ms, \"Solaris\") == -1)\n\t\t\t\treturn size;\n\t\t\tbreak;\n\t\tcase GNU_OS_KFREEBSD:\n\t\t\tif (file_printf(ms, \"kFreeBSD\") == -1)\n\t\t\t\treturn size;\n\t\t\tbreak;\n\t\tcase GNU_OS_KNETBSD:\n\t\t\tif (file_printf(ms, \"kNetBSD\") == -1)\n\t\t\t\treturn size;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tif (file_printf(ms, \"<unknown>\") == -1)\n\t\t\t\treturn size; \n\t\t}\n\t\tif (file_printf(ms, \" %d.%d.%d\", elf_getu32(swap, desc[1]),\n\t\t    elf_getu32(swap, desc[2]), elf_getu32(swap, desc[3])) == -1)\n\t\t\treturn size;\n\t\t*flags |= FLAGS_DID_NOTE;\n\t\treturn size;\n\t}\n\n\tif (namesz == 4 && strcmp((char *)&nbuf[noff], \"GNU\") == 0 &&\n\t    xnh_type == NT_GNU_BUILD_ID && (descsz == 16 || descsz == 20)) {\n\t    uint8_t desc[20];\n\t    uint32_t i;\n\t    if (file_printf(ms, \", BuildID[%s]=\", descsz == 16 ? \"md5/uuid\" :\n\t\t\"sha1\") == -1)\n\t\t    return size;\n\t    (void)memcpy(desc, &nbuf[doff], descsz);\n\t    for (i = 0; i < descsz; i++)\n\t\tif (file_printf(ms, \"%02x\", desc[i]) == -1)\n\t\t    return size;\n\t    *flags |= FLAGS_DID_BUILD_ID;\n\t}\n\n\tif (namesz == 4 && strcmp((char *)&nbuf[noff], \"PaX\") == 0 &&\n\t    xnh_type == NT_NETBSD_PAX && descsz == 4) {\n\t\tstatic const char *pax[] = {\n\t\t    \"+mprotect\",\n\t\t    \"-mprotect\",\n\t\t    \"+segvguard\",\n\t\t    \"-segvguard\",\n\t\t    \"+ASLR\",\n\t\t    \"-ASLR\",\n\t\t};\n\t\tuint32_t desc;\n\t\tsize_t i;\n\t\tint did = 0;\n\n\t\t(void)memcpy(&desc, &nbuf[doff], sizeof(desc));\n\t\tdesc = elf_getu32(swap, desc);\n\n\t\tif (desc && file_printf(ms, \", PaX: \") == -1)\n\t\t\treturn size;\n\n\t\tfor (i = 0; i < __arraycount(pax); i++) {\n\t\t\tif (((1 << i) & desc) == 0)\n\t\t\t\tcontinue;\n\t\t\tif (file_printf(ms, \"%s%s\", did++ ? \",\" : \"\",\n\t\t\t    pax[i]) == -1)\n\t\t\t\treturn size;\n\t\t}\n\t}\n\n\tif (namesz == 7 && strcmp((char *)&nbuf[noff], \"NetBSD\") == 0) {\n\t\tswitch (xnh_type) {\n\t\tcase NT_NETBSD_VERSION:\n\t\t\tif (descsz == 4) {\n\t\t\t\tdo_note_netbsd_version(ms, swap, &nbuf[doff]);\n\t\t\t\t*flags |= FLAGS_DID_NOTE;\n\t\t\t\treturn size;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase NT_NETBSD_MARCH:\n\t\t\tif (file_printf(ms, \", compiled for: %.*s\", (int)descsz,\n\t\t\t    (const char *)&nbuf[doff]) == -1)\n\t\t\t\treturn size;\n\t\t\tbreak;\n\t\tcase NT_NETBSD_CMODEL:\n\t\t\tif (file_printf(ms, \", compiler model: %.*s\",\n\t\t\t    (int)descsz, (const char *)&nbuf[doff]) == -1)\n\t\t\t\treturn size;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tif (file_printf(ms, \", note=%u\", xnh_type) == -1)\n\t\t\t\treturn size;\n\t\t\tbreak;\n\t\t}\n\t\treturn size;\n\t}\n\n\tif (namesz == 8 && strcmp((char *)&nbuf[noff], \"FreeBSD\") == 0) {\n\t    \tif (xnh_type == NT_FREEBSD_VERSION && descsz == 4) {\n\t\t\tdo_note_freebsd_version(ms, swap, &nbuf[doff]);\n\t\t\t*flags |= FLAGS_DID_NOTE;\n\t\t\treturn size;\n\t\t}\n\t}\n\n\tif (namesz == 8 && strcmp((char *)&nbuf[noff], \"OpenBSD\") == 0 &&\n\t    xnh_type == NT_OPENBSD_VERSION && descsz == 4) {\n\t\tif (file_printf(ms, \", for OpenBSD\") == -1)\n\t\t\treturn size;\n\t\t/* Content of note is always 0 */\n\t\t*flags |= FLAGS_DID_NOTE;\n\t\treturn size;\n\t}\n\n\tif (namesz == 10 && strcmp((char *)&nbuf[noff], \"DragonFly\") == 0 &&\n\t    xnh_type == NT_DRAGONFLY_VERSION && descsz == 4) {\n\t\tuint32_t desc;\n\t\tif (file_printf(ms, \", for DragonFly\") == -1)\n\t\t\treturn size;\n\t\t(void)memcpy(&desc, &nbuf[doff], sizeof(desc));\n\t\tdesc = elf_getu32(swap, desc);\n\t\tif (file_printf(ms, \" %d.%d.%d\", desc / 100000,\n\t\t    desc / 10000 % 10, desc % 10000) == -1)\n\t\t\treturn size;\n\t\t*flags |= FLAGS_DID_NOTE;\n\t\treturn size;\n\t}\n\ncore:\n\t/*\n\t * Sigh.  The 2.0.36 kernel in Debian 2.1, at\n\t * least, doesn't correctly implement name\n\t * sections, in core dumps, as specified by\n\t * the \"Program Linking\" section of \"UNIX(R) System\n\t * V Release 4 Programmer's Guide: ANSI C and\n\t * Programming Support Tools\", because my copy\n\t * clearly says \"The first 'namesz' bytes in 'name'\n\t * contain a *null-terminated* [emphasis mine]\n\t * character representation of the entry's owner\n\t * or originator\", but the 2.0.36 kernel code\n\t * doesn't include the terminating null in the\n\t * name....\n\t */\n\tif ((namesz == 4 && strncmp((char *)&nbuf[noff], \"CORE\", 4) == 0) ||\n\t    (namesz == 5 && strcmp((char *)&nbuf[noff], \"CORE\") == 0)) {\n\t\tos_style = OS_STYLE_SVR4;\n\t} \n\n\tif ((namesz == 8 && strcmp((char *)&nbuf[noff], \"FreeBSD\") == 0)) {\n\t\tos_style = OS_STYLE_FREEBSD;\n\t}\n\n\tif ((namesz >= 11 && strncmp((char *)&nbuf[noff], \"NetBSD-CORE\", 11)\n\t    == 0)) {\n\t\tos_style = OS_STYLE_NETBSD;\n\t}\n\n#ifdef ELFCORE\n\tif ((*flags & FLAGS_DID_CORE) != 0)\n\t\treturn size;\n\n\tif (os_style != -1 && (*flags & FLAGS_DID_CORE_STYLE) == 0) {\n\t\tif (file_printf(ms, \", %s-style\", os_style_names[os_style])\n\t\t    == -1)\n\t\t\treturn size;\n\t\t*flags |= FLAGS_DID_CORE_STYLE;\n\t}\n\n\tswitch (os_style) {\n\tcase OS_STYLE_NETBSD:\n\t\tif (xnh_type == NT_NETBSD_CORE_PROCINFO) {\n\t\t\tuint32_t signo;\n\t\t\t/*\n\t\t\t * Extract the program name.  It is at\n\t\t\t * offset 0x7c, and is up to 32-bytes,\n\t\t\t * including the terminating NUL.\n\t\t\t */\n\t\t\tif (file_printf(ms, \", from '%.31s'\",\n\t\t\t    &nbuf[doff + 0x7c]) == -1)\n\t\t\t\treturn size;\n\t\t\t\n\t\t\t/*\n\t\t\t * Extract the signal number.  It is at\n\t\t\t * offset 0x08.\n\t\t\t */\n\t\t\t(void)memcpy(&signo, &nbuf[doff + 0x08],\n\t\t\t    sizeof(signo));\n\t\t\tif (file_printf(ms, \" (signal %u)\",\n\t\t\t    elf_getu32(swap, signo)) == -1)\n\t\t\t\treturn size;\n\t\t\t*flags |= FLAGS_DID_CORE;\n\t\t\treturn size;\n\t\t}\n\t\tbreak;\n\n\tdefault:\n\t\tif (xnh_type == NT_PRPSINFO && *flags & FLAGS_IS_CORE) {\n\t\t\tsize_t i, j;\n\t\t\tunsigned char c;\n\t\t\t/*\n\t\t\t * Extract the program name.  We assume\n\t\t\t * it to be 16 characters (that's what it\n\t\t\t * is in SunOS 5.x and Linux).\n\t\t\t *\n\t\t\t * Unfortunately, it's at a different offset\n\t\t\t * in various OSes, so try multiple offsets.\n\t\t\t * If the characters aren't all printable,\n\t\t\t * reject it.\n\t\t\t */\n\t\t\tfor (i = 0; i < NOFFSETS; i++) {\n\t\t\t\tunsigned char *cname, *cp;\n\t\t\t\tsize_t reloffset = prpsoffsets(i);\n\t\t\t\tsize_t noffset = doff + reloffset;\n\t\t\t\tsize_t k;\n\t\t\t\tfor (j = 0; j < 16; j++, noffset++,\n\t\t\t\t    reloffset++) {\n\t\t\t\t\t/*\n\t\t\t\t\t * Make sure we're not past\n\t\t\t\t\t * the end of the buffer; if\n\t\t\t\t\t * we are, just give up.\n\t\t\t\t\t */\n\t\t\t\t\tif (noffset >= size)\n\t\t\t\t\t\tgoto tryanother;\n\n\t\t\t\t\t/*\n\t\t\t\t\t * Make sure we're not past\n\t\t\t\t\t * the end of the contents;\n\t\t\t\t\t * if we are, this obviously\n\t\t\t\t\t * isn't the right offset.\n\t\t\t\t\t */\n\t\t\t\t\tif (reloffset >= descsz)\n\t\t\t\t\t\tgoto tryanother;\n\n\t\t\t\t\tc = nbuf[noffset];\n\t\t\t\t\tif (c == '\\0') {\n\t\t\t\t\t\t/*\n\t\t\t\t\t\t * A '\\0' at the\n\t\t\t\t\t\t * beginning is\n\t\t\t\t\t\t * obviously wrong.\n\t\t\t\t\t\t * Any other '\\0'\n\t\t\t\t\t\t * means we're done.\n\t\t\t\t\t\t */\n\t\t\t\t\t\tif (j == 0)\n\t\t\t\t\t\t\tgoto tryanother;\n\t\t\t\t\t\telse\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t} else {\n\t\t\t\t\t\t/*\n\t\t\t\t\t\t * A nonprintable\n\t\t\t\t\t\t * character is also\n\t\t\t\t\t\t * wrong.\n\t\t\t\t\t\t */\n\t\t\t\t\t\tif (!isprint(c) || isquote(c))\n\t\t\t\t\t\t\tgoto tryanother;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t/*\n\t\t\t\t * Well, that worked.\n\t\t\t\t */\n\n\t\t\t\t/*\n\t\t\t\t * Try next offsets, in case this match is\n\t\t\t\t * in the middle of a string.\n\t\t\t\t */\n\t\t\t\tfor (k = i + 1 ; k < NOFFSETS ; k++) {\n\t\t\t\t\tsize_t no;\n\t\t\t\t\tint adjust = 1;\n\t\t\t\t\tif (prpsoffsets(k) >= prpsoffsets(i))\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\tfor (no = doff + prpsoffsets(k);\n\t\t\t\t\t     no < doff + prpsoffsets(i); no++)\n\t\t\t\t\t\tadjust = adjust\n\t\t\t\t\t\t         && isprint(nbuf[no]);\n\t\t\t\t\tif (adjust)\n\t\t\t\t\t\ti = k;\n\t\t\t\t}\n\n\t\t\t\tcname = (unsigned char *)\n\t\t\t\t    &nbuf[doff + prpsoffsets(i)];\n\t\t\t\tfor (cp = cname; *cp && isprint(*cp); cp++)\n\t\t\t\t\tcontinue;\n\t\t\t\t/*\n\t\t\t\t * Linux apparently appends a space at the end\n\t\t\t\t * of the command line: remove it.\n\t\t\t\t */\n\t\t\t\twhile (cp > cname && isspace(cp[-1]))\n\t\t\t\t\tcp--;\n\t\t\t\tif (file_printf(ms, \", from '%.*s'\",\n\t\t\t\t    (int)(cp - cname), cname) == -1)\n\t\t\t\t\treturn size;\n\t\t\t\t*flags |= FLAGS_DID_CORE;\n\t\t\t\treturn size;\n\n\t\t\ttryanother:\n\t\t\t\t;\n\t\t\t}\n\t\t}\n\t\tbreak;\n\t}\n#endif\n\treturn offset;\n}",
        "func": "private size_t\ndonote(struct magic_set *ms, void *vbuf, size_t offset, size_t size,\n    int clazz, int swap, size_t align, int *flags)\n{\n\tElf32_Nhdr nh32;\n\tElf64_Nhdr nh64;\n\tsize_t noff, doff;\n#ifdef ELFCORE\n\tint os_style = -1;\n#endif\n\tuint32_t namesz, descsz;\n\tunsigned char *nbuf = CAST(unsigned char *, vbuf);\n\n\tif (xnh_sizeof + offset > size) {\n\t\t/*\n\t\t * We're out of note headers.\n\t\t */\n\t\treturn xnh_sizeof + offset;\n\t}\n\n\t(void)memcpy(xnh_addr, &nbuf[offset], xnh_sizeof);\n\toffset += xnh_sizeof;\n\n\tnamesz = xnh_namesz;\n\tdescsz = xnh_descsz;\n\tif ((namesz == 0) && (descsz == 0)) {\n\t\t/*\n\t\t * We're out of note headers.\n\t\t */\n\t\treturn (offset >= size) ? offset : size;\n\t}\n\n\tif (namesz & 0x80000000) {\n\t    (void)file_printf(ms, \", bad note name size 0x%lx\",\n\t\t(unsigned long)namesz);\n\t    return 0;\n\t}\n\n\tif (descsz & 0x80000000) {\n\t    (void)file_printf(ms, \", bad note description size 0x%lx\",\n\t\t(unsigned long)descsz);\n\t    return 0;\n\t}\n\n\n\tnoff = offset;\n\tdoff = ELF_ALIGN(offset + namesz);\n\n\tif (offset + namesz > size) {\n\t\t/*\n\t\t * We're past the end of the buffer.\n\t\t */\n\t\treturn doff;\n\t}\n\n\toffset = ELF_ALIGN(doff + descsz);\n\tif (doff + descsz > size) {\n\t\t/*\n\t\t * We're past the end of the buffer.\n\t\t */\n\t\treturn (offset >= size) ? offset : size;\n\t}\n\n\tif ((*flags & (FLAGS_DID_NOTE|FLAGS_DID_BUILD_ID)) ==\n\t    (FLAGS_DID_NOTE|FLAGS_DID_BUILD_ID))\n\t\tgoto core;\n\n\tif (namesz == 5 && strcmp((char *)&nbuf[noff], \"SuSE\") == 0 &&\n\t    xnh_type == NT_GNU_VERSION && descsz == 2) {\n\t    file_printf(ms, \", for SuSE %d.%d\", nbuf[doff], nbuf[doff + 1]);\n\t}\n\tif (namesz == 4 && strcmp((char *)&nbuf[noff], \"GNU\") == 0 &&\n\t    xnh_type == NT_GNU_VERSION && descsz == 16) {\n\t\tuint32_t desc[4];\n\t\t(void)memcpy(desc, &nbuf[doff], sizeof(desc));\n\n\t\tif (file_printf(ms, \", for GNU/\") == -1)\n\t\t\treturn size;\n\t\tswitch (elf_getu32(swap, desc[0])) {\n\t\tcase GNU_OS_LINUX:\n\t\t\tif (file_printf(ms, \"Linux\") == -1)\n\t\t\t\treturn size;\n\t\t\tbreak;\n\t\tcase GNU_OS_HURD:\n\t\t\tif (file_printf(ms, \"Hurd\") == -1)\n\t\t\t\treturn size;\n\t\t\tbreak;\n\t\tcase GNU_OS_SOLARIS:\n\t\t\tif (file_printf(ms, \"Solaris\") == -1)\n\t\t\t\treturn size;\n\t\t\tbreak;\n\t\tcase GNU_OS_KFREEBSD:\n\t\t\tif (file_printf(ms, \"kFreeBSD\") == -1)\n\t\t\t\treturn size;\n\t\t\tbreak;\n\t\tcase GNU_OS_KNETBSD:\n\t\t\tif (file_printf(ms, \"kNetBSD\") == -1)\n\t\t\t\treturn size;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tif (file_printf(ms, \"<unknown>\") == -1)\n\t\t\t\treturn size; \n\t\t}\n\t\tif (file_printf(ms, \" %d.%d.%d\", elf_getu32(swap, desc[1]),\n\t\t    elf_getu32(swap, desc[2]), elf_getu32(swap, desc[3])) == -1)\n\t\t\treturn size;\n\t\t*flags |= FLAGS_DID_NOTE;\n\t\treturn size;\n\t}\n\n\tif (namesz == 4 && strcmp((char *)&nbuf[noff], \"GNU\") == 0 &&\n\t    xnh_type == NT_GNU_BUILD_ID && (descsz == 16 || descsz == 20)) {\n\t    uint8_t desc[20];\n\t    uint32_t i;\n\t    if (file_printf(ms, \", BuildID[%s]=\", descsz == 16 ? \"md5/uuid\" :\n\t\t\"sha1\") == -1)\n\t\t    return size;\n\t    (void)memcpy(desc, &nbuf[doff], descsz);\n\t    for (i = 0; i < descsz; i++)\n\t\tif (file_printf(ms, \"%02x\", desc[i]) == -1)\n\t\t    return size;\n\t    *flags |= FLAGS_DID_BUILD_ID;\n\t}\n\n\tif (namesz == 4 && strcmp((char *)&nbuf[noff], \"PaX\") == 0 &&\n\t    xnh_type == NT_NETBSD_PAX && descsz == 4) {\n\t\tstatic const char *pax[] = {\n\t\t    \"+mprotect\",\n\t\t    \"-mprotect\",\n\t\t    \"+segvguard\",\n\t\t    \"-segvguard\",\n\t\t    \"+ASLR\",\n\t\t    \"-ASLR\",\n\t\t};\n\t\tuint32_t desc;\n\t\tsize_t i;\n\t\tint did = 0;\n\n\t\t(void)memcpy(&desc, &nbuf[doff], sizeof(desc));\n\t\tdesc = elf_getu32(swap, desc);\n\n\t\tif (desc && file_printf(ms, \", PaX: \") == -1)\n\t\t\treturn size;\n\n\t\tfor (i = 0; i < __arraycount(pax); i++) {\n\t\t\tif (((1 << i) & desc) == 0)\n\t\t\t\tcontinue;\n\t\t\tif (file_printf(ms, \"%s%s\", did++ ? \",\" : \"\",\n\t\t\t    pax[i]) == -1)\n\t\t\t\treturn size;\n\t\t}\n\t}\n\n\tif (namesz == 7 && strcmp((char *)&nbuf[noff], \"NetBSD\") == 0) {\n\t\tswitch (xnh_type) {\n\t\tcase NT_NETBSD_VERSION:\n\t\t\tif (descsz == 4) {\n\t\t\t\tdo_note_netbsd_version(ms, swap, &nbuf[doff]);\n\t\t\t\t*flags |= FLAGS_DID_NOTE;\n\t\t\t\treturn size;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase NT_NETBSD_MARCH:\n\t\t\tif (file_printf(ms, \", compiled for: %.*s\", (int)descsz,\n\t\t\t    (const char *)&nbuf[doff]) == -1)\n\t\t\t\treturn size;\n\t\t\tbreak;\n\t\tcase NT_NETBSD_CMODEL:\n\t\t\tif (file_printf(ms, \", compiler model: %.*s\",\n\t\t\t    (int)descsz, (const char *)&nbuf[doff]) == -1)\n\t\t\t\treturn size;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tif (file_printf(ms, \", note=%u\", xnh_type) == -1)\n\t\t\t\treturn size;\n\t\t\tbreak;\n\t\t}\n\t\treturn size;\n\t}\n\n\tif (namesz == 8 && strcmp((char *)&nbuf[noff], \"FreeBSD\") == 0) {\n\t    \tif (xnh_type == NT_FREEBSD_VERSION && descsz == 4) {\n\t\t\tdo_note_freebsd_version(ms, swap, &nbuf[doff]);\n\t\t\t*flags |= FLAGS_DID_NOTE;\n\t\t\treturn size;\n\t\t}\n\t}\n\n\tif (namesz == 8 && strcmp((char *)&nbuf[noff], \"OpenBSD\") == 0 &&\n\t    xnh_type == NT_OPENBSD_VERSION && descsz == 4) {\n\t\tif (file_printf(ms, \", for OpenBSD\") == -1)\n\t\t\treturn size;\n\t\t/* Content of note is always 0 */\n\t\t*flags |= FLAGS_DID_NOTE;\n\t\treturn size;\n\t}\n\n\tif (namesz == 10 && strcmp((char *)&nbuf[noff], \"DragonFly\") == 0 &&\n\t    xnh_type == NT_DRAGONFLY_VERSION && descsz == 4) {\n\t\tuint32_t desc;\n\t\tif (file_printf(ms, \", for DragonFly\") == -1)\n\t\t\treturn size;\n\t\t(void)memcpy(&desc, &nbuf[doff], sizeof(desc));\n\t\tdesc = elf_getu32(swap, desc);\n\t\tif (file_printf(ms, \" %d.%d.%d\", desc / 100000,\n\t\t    desc / 10000 % 10, desc % 10000) == -1)\n\t\t\treturn size;\n\t\t*flags |= FLAGS_DID_NOTE;\n\t\treturn size;\n\t}\n\ncore:\n\t/*\n\t * Sigh.  The 2.0.36 kernel in Debian 2.1, at\n\t * least, doesn't correctly implement name\n\t * sections, in core dumps, as specified by\n\t * the \"Program Linking\" section of \"UNIX(R) System\n\t * V Release 4 Programmer's Guide: ANSI C and\n\t * Programming Support Tools\", because my copy\n\t * clearly says \"The first 'namesz' bytes in 'name'\n\t * contain a *null-terminated* [emphasis mine]\n\t * character representation of the entry's owner\n\t * or originator\", but the 2.0.36 kernel code\n\t * doesn't include the terminating null in the\n\t * name....\n\t */\n\tif ((namesz == 4 && strncmp((char *)&nbuf[noff], \"CORE\", 4) == 0) ||\n\t    (namesz == 5 && strcmp((char *)&nbuf[noff], \"CORE\") == 0)) {\n\t\tos_style = OS_STYLE_SVR4;\n\t} \n\n\tif ((namesz == 8 && strcmp((char *)&nbuf[noff], \"FreeBSD\") == 0)) {\n\t\tos_style = OS_STYLE_FREEBSD;\n\t}\n\n\tif ((namesz >= 11 && strncmp((char *)&nbuf[noff], \"NetBSD-CORE\", 11)\n\t    == 0)) {\n\t\tos_style = OS_STYLE_NETBSD;\n\t}\n\n#ifdef ELFCORE\n\tif ((*flags & FLAGS_DID_CORE) != 0)\n\t\treturn size;\n\n\tif (os_style != -1 && (*flags & FLAGS_DID_CORE_STYLE) == 0) {\n\t\tif (file_printf(ms, \", %s-style\", os_style_names[os_style])\n\t\t    == -1)\n\t\t\treturn size;\n\t\t*flags |= FLAGS_DID_CORE_STYLE;\n\t}\n\n\tswitch (os_style) {\n\tcase OS_STYLE_NETBSD:\n\t\tif (xnh_type == NT_NETBSD_CORE_PROCINFO) {\n\t\t\tuint32_t signo;\n\t\t\t/*\n\t\t\t * Extract the program name.  It is at\n\t\t\t * offset 0x7c, and is up to 32-bytes,\n\t\t\t * including the terminating NUL.\n\t\t\t */\n\t\t\tif (file_printf(ms, \", from '%.31s'\",\n\t\t\t    &nbuf[doff + 0x7c]) == -1)\n\t\t\t\treturn size;\n\t\t\t\n\t\t\t/*\n\t\t\t * Extract the signal number.  It is at\n\t\t\t * offset 0x08.\n\t\t\t */\n\t\t\t(void)memcpy(&signo, &nbuf[doff + 0x08],\n\t\t\t    sizeof(signo));\n\t\t\tif (file_printf(ms, \" (signal %u)\",\n\t\t\t    elf_getu32(swap, signo)) == -1)\n\t\t\t\treturn size;\n\t\t\t*flags |= FLAGS_DID_CORE;\n\t\t\treturn size;\n\t\t}\n\t\tbreak;\n\n\tdefault:\n\t\tif (xnh_type == NT_PRPSINFO && *flags & FLAGS_IS_CORE) {\n\t\t\tsize_t i, j;\n\t\t\tunsigned char c;\n\t\t\t/*\n\t\t\t * Extract the program name.  We assume\n\t\t\t * it to be 16 characters (that's what it\n\t\t\t * is in SunOS 5.x and Linux).\n\t\t\t *\n\t\t\t * Unfortunately, it's at a different offset\n\t\t\t * in various OSes, so try multiple offsets.\n\t\t\t * If the characters aren't all printable,\n\t\t\t * reject it.\n\t\t\t */\n\t\t\tfor (i = 0; i < NOFFSETS; i++) {\n\t\t\t\tunsigned char *cname, *cp;\n\t\t\t\tsize_t reloffset = prpsoffsets(i);\n\t\t\t\tsize_t noffset = doff + reloffset;\n\t\t\t\tsize_t k;\n\t\t\t\tfor (j = 0; j < 16; j++, noffset++,\n\t\t\t\t    reloffset++) {\n\t\t\t\t\t/*\n\t\t\t\t\t * Make sure we're not past\n\t\t\t\t\t * the end of the buffer; if\n\t\t\t\t\t * we are, just give up.\n\t\t\t\t\t */\n\t\t\t\t\tif (noffset >= size)\n\t\t\t\t\t\tgoto tryanother;\n\n\t\t\t\t\t/*\n\t\t\t\t\t * Make sure we're not past\n\t\t\t\t\t * the end of the contents;\n\t\t\t\t\t * if we are, this obviously\n\t\t\t\t\t * isn't the right offset.\n\t\t\t\t\t */\n\t\t\t\t\tif (reloffset >= descsz)\n\t\t\t\t\t\tgoto tryanother;\n\n\t\t\t\t\tc = nbuf[noffset];\n\t\t\t\t\tif (c == '\\0') {\n\t\t\t\t\t\t/*\n\t\t\t\t\t\t * A '\\0' at the\n\t\t\t\t\t\t * beginning is\n\t\t\t\t\t\t * obviously wrong.\n\t\t\t\t\t\t * Any other '\\0'\n\t\t\t\t\t\t * means we're done.\n\t\t\t\t\t\t */\n\t\t\t\t\t\tif (j == 0)\n\t\t\t\t\t\t\tgoto tryanother;\n\t\t\t\t\t\telse\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t} else {\n\t\t\t\t\t\t/*\n\t\t\t\t\t\t * A nonprintable\n\t\t\t\t\t\t * character is also\n\t\t\t\t\t\t * wrong.\n\t\t\t\t\t\t */\n\t\t\t\t\t\tif (!isprint(c) || isquote(c))\n\t\t\t\t\t\t\tgoto tryanother;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t/*\n\t\t\t\t * Well, that worked.\n\t\t\t\t */\n\n\t\t\t\t/*\n\t\t\t\t * Try next offsets, in case this match is\n\t\t\t\t * in the middle of a string.\n\t\t\t\t */\n\t\t\t\tfor (k = i + 1 ; k < NOFFSETS ; k++) {\n\t\t\t\t\tsize_t no;\n\t\t\t\t\tint adjust = 1;\n\t\t\t\t\tif (prpsoffsets(k) >= prpsoffsets(i))\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\tfor (no = doff + prpsoffsets(k);\n\t\t\t\t\t     no < doff + prpsoffsets(i); no++)\n\t\t\t\t\t\tadjust = adjust\n\t\t\t\t\t\t         && isprint(nbuf[no]);\n\t\t\t\t\tif (adjust)\n\t\t\t\t\t\ti = k;\n\t\t\t\t}\n\n\t\t\t\tcname = (unsigned char *)\n\t\t\t\t    &nbuf[doff + prpsoffsets(i)];\n\t\t\t\tfor (cp = cname; *cp && isprint(*cp); cp++)\n\t\t\t\t\tcontinue;\n\t\t\t\t/*\n\t\t\t\t * Linux apparently appends a space at the end\n\t\t\t\t * of the command line: remove it.\n\t\t\t\t */\n\t\t\t\twhile (cp > cname && isspace(cp[-1]))\n\t\t\t\t\tcp--;\n\t\t\t\tif (file_printf(ms, \", from '%.*s'\",\n\t\t\t\t    (int)(cp - cname), cname) == -1)\n\t\t\t\t\treturn size;\n\t\t\t\t*flags |= FLAGS_DID_CORE;\n\t\t\t\treturn size;\n\n\t\t\ttryanother:\n\t\t\t\t;\n\t\t\t}\n\t\t}\n\t\tbreak;\n\t}\n#endif\n\treturn offset;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -33,13 +33,13 @@\n \tif (namesz & 0x80000000) {\n \t    (void)file_printf(ms, \", bad note name size 0x%lx\",\n \t\t(unsigned long)namesz);\n-\t    return offset;\n+\t    return 0;\n \t}\n \n \tif (descsz & 0x80000000) {\n \t    (void)file_printf(ms, \", bad note description size 0x%lx\",\n \t\t(unsigned long)descsz);\n-\t    return offset;\n+\t    return 0;\n \t}\n \n ",
        "diff_line_info": {
            "deleted_lines": [
                "\t    return offset;",
                "\t    return offset;"
            ],
            "added_lines": [
                "\t    return 0;",
                "\t    return 0;"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-8116",
        "func_name": "file/file_tryelf",
        "description": "The ELF parser (readelf.c) in file before 5.21 allows remote attackers to cause a denial of service (CPU consumption or crash) via a large number of (1) program or (2) section headers or (3) invalid capabilities.",
        "git_url": "https://github.com/file/file/commit/b4c01141e5367f247b84dcaf6aefbb4e741842b8",
        "commit_title": "- limit the number of program and section header number of sections to be",
        "commit_text": "  processed to avoid excessive processing time. - if a bad note is found, return 0 to stop processing immediately.",
        "func_before": "protected int\nfile_tryelf(struct magic_set *ms, int fd, const unsigned char *buf,\n    size_t nbytes)\n{\n\tunion {\n\t\tint32_t l;\n\t\tchar c[sizeof (int32_t)];\n\t} u;\n\tint clazz;\n\tint swap;\n\tstruct stat st;\n\toff_t fsize;\n\tint flags = 0;\n\tElf32_Ehdr elf32hdr;\n\tElf64_Ehdr elf64hdr;\n\tuint16_t type;\n\n\tif (ms->flags & (MAGIC_MIME|MAGIC_APPLE))\n\t\treturn 0;\n\t/*\n\t * ELF executables have multiple section headers in arbitrary\n\t * file locations and thus file(1) cannot determine it from easily.\n\t * Instead we traverse thru all section headers until a symbol table\n\t * one is found or else the binary is stripped.\n\t * Return immediately if it's not ELF (so we avoid pipe2file unless needed).\n\t */\n\tif (buf[EI_MAG0] != ELFMAG0\n\t    || (buf[EI_MAG1] != ELFMAG1 && buf[EI_MAG1] != OLFMAG1)\n\t    || buf[EI_MAG2] != ELFMAG2 || buf[EI_MAG3] != ELFMAG3)\n\t\treturn 0;\n\n\t/*\n\t * If we cannot seek, it must be a pipe, socket or fifo.\n\t */\n\tif((lseek(fd, (off_t)0, SEEK_SET) == (off_t)-1) && (errno == ESPIPE))\n\t\tfd = file_pipe2file(ms, fd, buf, nbytes);\n\n\tif (fstat(fd, &st) == -1) {\n  \t\tfile_badread(ms);\n\t\treturn -1;\n\t}\n\tfsize = st.st_size;\n\n\tclazz = buf[EI_CLASS];\n\n\tswitch (clazz) {\n\tcase ELFCLASS32:\n#undef elf_getu\n#define elf_getu(a, b)\telf_getu32(a, b)\n#undef elfhdr\n#define elfhdr elf32hdr\n#include \"elfclass.h\"\n\tcase ELFCLASS64:\n#undef elf_getu\n#define elf_getu(a, b)\telf_getu64(a, b)\n#undef elfhdr\n#define elfhdr elf64hdr\n#include \"elfclass.h\"\n\tdefault:\n\t    if (file_printf(ms, \", unknown class %d\", clazz) == -1)\n\t\t    return -1;\n\t    break;\n\t}\n\treturn 0;\n}",
        "func": "protected int\nfile_tryelf(struct magic_set *ms, int fd, const unsigned char *buf,\n    size_t nbytes)\n{\n\tunion {\n\t\tint32_t l;\n\t\tchar c[sizeof (int32_t)];\n\t} u;\n\tint clazz;\n\tint swap;\n\tstruct stat st;\n\toff_t fsize;\n\tint flags = 0;\n\tElf32_Ehdr elf32hdr;\n\tElf64_Ehdr elf64hdr;\n\tuint16_t type, phnum, shnum;\n\n\tif (ms->flags & (MAGIC_MIME|MAGIC_APPLE))\n\t\treturn 0;\n\t/*\n\t * ELF executables have multiple section headers in arbitrary\n\t * file locations and thus file(1) cannot determine it from easily.\n\t * Instead we traverse thru all section headers until a symbol table\n\t * one is found or else the binary is stripped.\n\t * Return immediately if it's not ELF (so we avoid pipe2file unless needed).\n\t */\n\tif (buf[EI_MAG0] != ELFMAG0\n\t    || (buf[EI_MAG1] != ELFMAG1 && buf[EI_MAG1] != OLFMAG1)\n\t    || buf[EI_MAG2] != ELFMAG2 || buf[EI_MAG3] != ELFMAG3)\n\t\treturn 0;\n\n\t/*\n\t * If we cannot seek, it must be a pipe, socket or fifo.\n\t */\n\tif((lseek(fd, (off_t)0, SEEK_SET) == (off_t)-1) && (errno == ESPIPE))\n\t\tfd = file_pipe2file(ms, fd, buf, nbytes);\n\n\tif (fstat(fd, &st) == -1) {\n  \t\tfile_badread(ms);\n\t\treturn -1;\n\t}\n\tfsize = st.st_size;\n\n\tclazz = buf[EI_CLASS];\n\n\tswitch (clazz) {\n\tcase ELFCLASS32:\n#undef elf_getu\n#define elf_getu(a, b)\telf_getu32(a, b)\n#undef elfhdr\n#define elfhdr elf32hdr\n#include \"elfclass.h\"\n\tcase ELFCLASS64:\n#undef elf_getu\n#define elf_getu(a, b)\telf_getu64(a, b)\n#undef elfhdr\n#define elfhdr elf64hdr\n#include \"elfclass.h\"\n\tdefault:\n\t    if (file_printf(ms, \", unknown class %d\", clazz) == -1)\n\t\t    return -1;\n\t    break;\n\t}\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -13,7 +13,7 @@\n \tint flags = 0;\n \tElf32_Ehdr elf32hdr;\n \tElf64_Ehdr elf64hdr;\n-\tuint16_t type;\n+\tuint16_t type, phnum, shnum;\n \n \tif (ms->flags & (MAGIC_MIME|MAGIC_APPLE))\n \t\treturn 0;",
        "diff_line_info": {
            "deleted_lines": [
                "\tuint16_t type;"
            ],
            "added_lines": [
                "\tuint16_t type, phnum, shnum;"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-8117",
        "func_name": "file/mget",
        "description": "softmagic.c in file before 5.21 does not properly limit recursion, which allows remote attackers to cause a denial of service (CPU consumption or crash) via unspecified vectors.",
        "git_url": "https://github.com/file/file/commit/6f737ddfadb596d7d4a993f7ed2141ffd664a81c",
        "commit_title": "- reduce recursion level from 20 to 10 and make a symbolic constant for it.",
        "commit_text": "- pull out the guts of saving and restoring the output buffer into functions   and take care not to overwrite the error message if an error happened.",
        "func_before": "private int\nmget(struct magic_set *ms, const unsigned char *s, struct magic *m,\n    size_t nbytes, size_t o, unsigned int cont_level, int mode, int text,\n    int flip, int recursion_level, int *printed_something,\n    int *need_separator, int *returnval)\n{\n\tuint32_t soffset, offset = ms->offset;\n\tuint32_t lhs;\n\tint rv, oneed_separator, in_type;\n\tchar *sbuf, *rbuf;\n\tunion VALUETYPE *p = &ms->ms_value;\n\tstruct mlist ml;\n\n\tif (recursion_level >= 20) {\n\t\tfile_error(ms, 0, \"recursion nesting exceeded\");\n\t\treturn -1;\n\t}\n\n\tif (mcopy(ms, p, m->type, m->flag & INDIR, s, (uint32_t)(offset + o),\n\t    (uint32_t)nbytes, m) == -1)\n\t\treturn -1;\n\n\tif ((ms->flags & MAGIC_DEBUG) != 0) {\n\t\tfprintf(stderr, \"mget(type=%d, flag=%x, offset=%u, o=%\"\n\t\t    SIZE_T_FORMAT \"u, \" \"nbytes=%\" SIZE_T_FORMAT \"u)\\n\",\n\t\t    m->type, m->flag, offset, o, nbytes);\n\t\tmdebug(offset, (char *)(void *)p, sizeof(union VALUETYPE));\n#ifndef COMPILE_ONLY\n\t\tfile_mdump(m);\n#endif\n\t}\n\n\tif (m->flag & INDIR) {\n\t\tint off = m->in_offset;\n\t\tif (m->in_op & FILE_OPINDIRECT) {\n\t\t\tconst union VALUETYPE *q = CAST(const union VALUETYPE *,\n\t\t\t    ((const void *)(s + offset + off)));\n\t\t\tswitch (cvt_flip(m->in_type, flip)) {\n\t\t\tcase FILE_BYTE:\n\t\t\t\toff = q->b;\n\t\t\t\tbreak;\n\t\t\tcase FILE_SHORT:\n\t\t\t\toff = q->h;\n\t\t\t\tbreak;\n\t\t\tcase FILE_BESHORT:\n\t\t\t\toff = (short)((q->hs[0]<<8)|(q->hs[1]));\n\t\t\t\tbreak;\n\t\t\tcase FILE_LESHORT:\n\t\t\t\toff = (short)((q->hs[1]<<8)|(q->hs[0]));\n\t\t\t\tbreak;\n\t\t\tcase FILE_LONG:\n\t\t\t\toff = q->l;\n\t\t\t\tbreak;\n\t\t\tcase FILE_BELONG:\n\t\t\tcase FILE_BEID3:\n\t\t\t\toff = (int32_t)((q->hl[0]<<24)|(q->hl[1]<<16)|\n\t\t\t\t\t\t (q->hl[2]<<8)|(q->hl[3]));\n\t\t\t\tbreak;\n\t\t\tcase FILE_LEID3:\n\t\t\tcase FILE_LELONG:\n\t\t\t\toff = (int32_t)((q->hl[3]<<24)|(q->hl[2]<<16)|\n\t\t\t\t\t\t (q->hl[1]<<8)|(q->hl[0]));\n\t\t\t\tbreak;\n\t\t\tcase FILE_MELONG:\n\t\t\t\toff = (int32_t)((q->hl[1]<<24)|(q->hl[0]<<16)|\n\t\t\t\t\t\t (q->hl[3]<<8)|(q->hl[2]));\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif ((ms->flags & MAGIC_DEBUG) != 0)\n\t\t\t\tfprintf(stderr, \"indirect offs=%u\\n\", off);\n\t\t}\n\t\tswitch (in_type = cvt_flip(m->in_type, flip)) {\n\t\tcase FILE_BYTE:\n\t\t\tif (OFFSET_OOB(nbytes, offset, 1))\n\t\t\t\treturn 0;\n\t\t\tif (off) {\n\t\t\t\tswitch (m->in_op & FILE_OPS_MASK) {\n\t\t\t\tcase FILE_OPAND:\n\t\t\t\t\toffset = p->b & off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPOR:\n\t\t\t\t\toffset = p->b | off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPXOR:\n\t\t\t\t\toffset = p->b ^ off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPADD:\n\t\t\t\t\toffset = p->b + off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMINUS:\n\t\t\t\t\toffset = p->b - off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMULTIPLY:\n\t\t\t\t\toffset = p->b * off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPDIVIDE:\n\t\t\t\t\toffset = p->b / off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMODULO:\n\t\t\t\t\toffset = p->b % off;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t} else\n\t\t\t\toffset = p->b;\n\t\t\tif (m->in_op & FILE_OPINVERSE)\n\t\t\t\toffset = ~offset;\n\t\t\tbreak;\n\t\tcase FILE_BESHORT:\n\t\t\tif (OFFSET_OOB(nbytes, offset, 2))\n\t\t\t\treturn 0;\n\t\t\tlhs = (p->hs[0] << 8) | p->hs[1];\n\t\t\tif (off) {\n\t\t\t\tswitch (m->in_op & FILE_OPS_MASK) {\n\t\t\t\tcase FILE_OPAND:\n\t\t\t\t\toffset = lhs & off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPOR:\n\t\t\t\t\toffset = lhs | off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPXOR:\n\t\t\t\t\toffset = lhs ^ off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPADD:\n\t\t\t\t\toffset = lhs + off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMINUS:\n\t\t\t\t\toffset = lhs - off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMULTIPLY:\n\t\t\t\t\toffset = lhs * off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPDIVIDE:\n\t\t\t\t\toffset = lhs / off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMODULO:\n\t\t\t\t\toffset = lhs % off;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t} else\n\t\t\t\toffset = lhs;\n\t\t\tif (m->in_op & FILE_OPINVERSE)\n\t\t\t\toffset = ~offset;\n\t\t\tbreak;\n\t\tcase FILE_LESHORT:\n\t\t\tif (OFFSET_OOB(nbytes, offset, 2))\n\t\t\t\treturn 0;\n\t\t\tlhs = (p->hs[1] << 8) | p->hs[0];\n\t\t\tif (off) {\n\t\t\t\tswitch (m->in_op & FILE_OPS_MASK) {\n\t\t\t\tcase FILE_OPAND:\n\t\t\t\t\toffset = lhs & off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPOR:\n\t\t\t\t\toffset = lhs | off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPXOR:\n\t\t\t\t\toffset = lhs ^ off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPADD:\n\t\t\t\t\toffset = lhs + off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMINUS:\n\t\t\t\t\toffset = lhs - off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMULTIPLY:\n\t\t\t\t\toffset = lhs * off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPDIVIDE:\n\t\t\t\t\toffset = lhs / off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMODULO:\n\t\t\t\t\toffset = lhs % off;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t} else\n\t\t\t\toffset = lhs;\n\t\t\tif (m->in_op & FILE_OPINVERSE)\n\t\t\t\toffset = ~offset;\n\t\t\tbreak;\n\t\tcase FILE_SHORT:\n\t\t\tif (OFFSET_OOB(nbytes, offset, 2))\n\t\t\t\treturn 0;\n\t\t\tif (off) {\n\t\t\t\tswitch (m->in_op & FILE_OPS_MASK) {\n\t\t\t\tcase FILE_OPAND:\n\t\t\t\t\toffset = p->h & off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPOR:\n\t\t\t\t\toffset = p->h | off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPXOR:\n\t\t\t\t\toffset = p->h ^ off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPADD:\n\t\t\t\t\toffset = p->h + off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMINUS:\n\t\t\t\t\toffset = p->h - off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMULTIPLY:\n\t\t\t\t\toffset = p->h * off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPDIVIDE:\n\t\t\t\t\toffset = p->h / off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMODULO:\n\t\t\t\t\toffset = p->h % off;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\telse\n\t\t\t\toffset = p->h;\n\t\t\tif (m->in_op & FILE_OPINVERSE)\n\t\t\t\toffset = ~offset;\n\t\t\tbreak;\n\t\tcase FILE_BELONG:\n\t\tcase FILE_BEID3:\n\t\t\tif (OFFSET_OOB(nbytes, offset, 4))\n\t\t\t\treturn 0;\n\t\t\tlhs = (p->hl[0] << 24) | (p->hl[1] << 16) |\n\t\t\t    (p->hl[2] << 8) | p->hl[3];\n\t\t\tif (off) {\n\t\t\t\tswitch (m->in_op & FILE_OPS_MASK) {\n\t\t\t\tcase FILE_OPAND:\n\t\t\t\t\toffset = lhs & off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPOR:\n\t\t\t\t\toffset = lhs | off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPXOR:\n\t\t\t\t\toffset = lhs ^ off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPADD:\n\t\t\t\t\toffset = lhs + off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMINUS:\n\t\t\t\t\toffset = lhs - off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMULTIPLY:\n\t\t\t\t\toffset = lhs * off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPDIVIDE:\n\t\t\t\t\toffset = lhs / off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMODULO:\n\t\t\t\t\toffset = lhs % off;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t} else\n\t\t\t\toffset = lhs;\n\t\t\tif (m->in_op & FILE_OPINVERSE)\n\t\t\t\toffset = ~offset;\n\t\t\tbreak;\n\t\tcase FILE_LELONG:\n\t\tcase FILE_LEID3:\n\t\t\tif (OFFSET_OOB(nbytes, offset, 4))\n\t\t\t\treturn 0;\n\t\t\tlhs = (p->hl[3] << 24) | (p->hl[2] << 16) |\n\t\t\t    (p->hl[1] << 8) | p->hl[0];\n\t\t\tif (off) {\n\t\t\t\tswitch (m->in_op & FILE_OPS_MASK) {\n\t\t\t\tcase FILE_OPAND:\n\t\t\t\t\toffset = lhs & off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPOR:\n\t\t\t\t\toffset = lhs | off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPXOR:\n\t\t\t\t\toffset = lhs ^ off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPADD:\n\t\t\t\t\toffset = lhs + off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMINUS:\n\t\t\t\t\toffset = lhs - off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMULTIPLY:\n\t\t\t\t\toffset = lhs * off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPDIVIDE:\n\t\t\t\t\toffset = lhs / off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMODULO:\n\t\t\t\t\toffset = lhs % off;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t} else\n\t\t\t\toffset = lhs;\n\t\t\tif (m->in_op & FILE_OPINVERSE)\n\t\t\t\toffset = ~offset;\n\t\t\tbreak;\n\t\tcase FILE_MELONG:\n\t\t\tif (OFFSET_OOB(nbytes, offset, 4))\n\t\t\t\treturn 0;\n\t\t\tlhs = (p->hl[1] << 24) | (p->hl[0] << 16) |\n\t\t\t    (p->hl[3] << 8) | p->hl[2];\n\t\t\tif (off) {\n\t\t\t\tswitch (m->in_op & FILE_OPS_MASK) {\n\t\t\t\tcase FILE_OPAND:\n\t\t\t\t\toffset = lhs & off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPOR:\n\t\t\t\t\toffset = lhs | off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPXOR:\n\t\t\t\t\toffset = lhs ^ off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPADD:\n\t\t\t\t\toffset = lhs + off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMINUS:\n\t\t\t\t\toffset = lhs - off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMULTIPLY:\n\t\t\t\t\toffset = lhs * off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPDIVIDE:\n\t\t\t\t\toffset = lhs / off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMODULO:\n\t\t\t\t\toffset = lhs % off;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t} else\n\t\t\t\toffset = lhs;\n\t\t\tif (m->in_op & FILE_OPINVERSE)\n\t\t\t\toffset = ~offset;\n\t\t\tbreak;\n\t\tcase FILE_LONG:\n\t\t\tif (OFFSET_OOB(nbytes, offset, 4))\n\t\t\t\treturn 0;\n\t\t\tif (off) {\n\t\t\t\tswitch (m->in_op & FILE_OPS_MASK) {\n\t\t\t\tcase FILE_OPAND:\n\t\t\t\t\toffset = p->l & off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPOR:\n\t\t\t\t\toffset = p->l | off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPXOR:\n\t\t\t\t\toffset = p->l ^ off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPADD:\n\t\t\t\t\toffset = p->l + off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMINUS:\n\t\t\t\t\toffset = p->l - off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMULTIPLY:\n\t\t\t\t\toffset = p->l * off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPDIVIDE:\n\t\t\t\t\toffset = p->l / off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMODULO:\n\t\t\t\t\toffset = p->l % off;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t} else\n\t\t\t\toffset = p->l;\n\t\t\tif (m->in_op & FILE_OPINVERSE)\n\t\t\t\toffset = ~offset;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\n\t\tswitch (in_type) {\n\t\tcase FILE_LEID3:\n\t\tcase FILE_BEID3:\n\t\t\toffset = ((((offset >>  0) & 0x7f) <<  0) |\n\t\t\t\t (((offset >>  8) & 0x7f) <<  7) |\n\t\t\t\t (((offset >> 16) & 0x7f) << 14) |\n\t\t\t\t (((offset >> 24) & 0x7f) << 21)) + 10;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\n\t\tif (m->flag & INDIROFFADD) {\n\t\t\toffset += ms->c.li[cont_level-1].off;\n\t\t\tif (offset == 0) {\n\t\t\t\tif ((ms->flags & MAGIC_DEBUG) != 0)\n\t\t\t\t\tfprintf(stderr,\n\t\t\t\t\t    \"indirect *zero* offset\\n\");\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t\tif ((ms->flags & MAGIC_DEBUG) != 0)\n\t\t\t\tfprintf(stderr, \"indirect +offs=%u\\n\", offset);\n\t\t}\n\t\tif (mcopy(ms, p, m->type, 0, s, offset, nbytes, m) == -1)\n\t\t\treturn -1;\n\t\tms->offset = offset;\n\n\t\tif ((ms->flags & MAGIC_DEBUG) != 0) {\n\t\t\tmdebug(offset, (char *)(void *)p,\n\t\t\t    sizeof(union VALUETYPE));\n#ifndef COMPILE_ONLY\n\t\t\tfile_mdump(m);\n#endif\n\t\t}\n\t}\n\n\t/* Verify we have enough data to match magic type */\n\tswitch (m->type) {\n\tcase FILE_BYTE:\n\t\tif (OFFSET_OOB(nbytes, offset, 1))\n\t\t\treturn 0;\n\t\tbreak;\n\n\tcase FILE_SHORT:\n\tcase FILE_BESHORT:\n\tcase FILE_LESHORT:\n\t\tif (OFFSET_OOB(nbytes, offset, 2))\n\t\t\treturn 0;\n\t\tbreak;\n\n\tcase FILE_LONG:\n\tcase FILE_BELONG:\n\tcase FILE_LELONG:\n\tcase FILE_MELONG:\n\tcase FILE_DATE:\n\tcase FILE_BEDATE:\n\tcase FILE_LEDATE:\n\tcase FILE_MEDATE:\n\tcase FILE_LDATE:\n\tcase FILE_BELDATE:\n\tcase FILE_LELDATE:\n\tcase FILE_MELDATE:\n\tcase FILE_FLOAT:\n\tcase FILE_BEFLOAT:\n\tcase FILE_LEFLOAT:\n\t\tif (OFFSET_OOB(nbytes, offset, 4))\n\t\t\treturn 0;\n\t\tbreak;\n\n\tcase FILE_DOUBLE:\n\tcase FILE_BEDOUBLE:\n\tcase FILE_LEDOUBLE:\n\t\tif (OFFSET_OOB(nbytes, offset, 8))\n\t\t\treturn 0;\n\t\tbreak;\n\n\tcase FILE_STRING:\n\tcase FILE_PSTRING:\n\tcase FILE_SEARCH:\n\t\tif (OFFSET_OOB(nbytes, offset, m->vallen))\n\t\t\treturn 0;\n\t\tbreak;\n\n\tcase FILE_REGEX:\n\t\tif (nbytes < offset)\n\t\t\treturn 0;\n\t\tbreak;\n\n\tcase FILE_INDIRECT:\n\t\tif (offset == 0)\n\t\t\treturn 0;\n\t\tif (nbytes < offset)\n\t\t\treturn 0;\n\t\tsbuf = ms->o.buf;\n\t\tsoffset = ms->offset;\n\t\tms->o.buf = NULL;\n\t\tms->offset = 0;\n\t\trv = file_softmagic(ms, s + offset, nbytes - offset,\n\t\t    recursion_level, BINTEST, text);\n\t\tif ((ms->flags & MAGIC_DEBUG) != 0)\n\t\t\tfprintf(stderr, \"indirect @offs=%u[%d]\\n\", offset, rv);\n\t\trbuf = ms->o.buf;\n\t\tms->o.buf = sbuf;\n\t\tms->offset = soffset;\n\t\tif (rv == 1) {\n\t\t\tif ((ms->flags & (MAGIC_MIME|MAGIC_APPLE)) == 0 &&\n\t\t\t    file_printf(ms, F(ms, m, \"%u\"), offset) == -1) {\n\t\t\t\tfree(rbuf);\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tif (file_printf(ms, \"%s\", rbuf) == -1) {\n\t\t\t\tfree(rbuf);\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t}\n\t\tfree(rbuf);\n\t\treturn rv;\n\n\tcase FILE_USE:\n\t\tif (nbytes < offset)\n\t\t\treturn 0;\n\t\tsbuf = m->value.s;\n\t\tif (*sbuf == '^') {\n\t\t\tsbuf++;\n\t\t\tflip = !flip;\n\t\t}\n\t\tif (file_magicfind(ms, sbuf, &ml) == -1) {\n\t\t\tfile_error(ms, 0, \"cannot find entry `%s'\", sbuf);\n\t\t\treturn -1;\n\t\t}\n\n\t\toneed_separator = *need_separator;\n\t\tif (m->flag & NOSPACE)\n\t\t\t*need_separator = 0;\n\t\trv = match(ms, ml.magic, ml.nmagic, s, nbytes, offset + o,\n\t\t    mode, text, flip, recursion_level, printed_something,\n\t\t    need_separator, returnval);\n\t\tif (rv != 1)\n\t\t    *need_separator = oneed_separator;\n\t\treturn rv;\n\n\tcase FILE_NAME:\n\t\tif (file_printf(ms, \"%s\", m->desc) == -1)\n\t\t\treturn -1;\n\t\treturn 1;\n\tcase FILE_DEFAULT:\t/* nothing to check */\n\tcase FILE_CLEAR:\n\tdefault:\n\t\tbreak;\n\t}\n\tif (!mconvert(ms, m, flip))\n\t\treturn 0;\n\treturn 1;\n}",
        "func": "private int\nmget(struct magic_set *ms, const unsigned char *s, struct magic *m,\n    size_t nbytes, size_t o, unsigned int cont_level, int mode, int text,\n    int flip, int recursion_level, int *printed_something,\n    int *need_separator, int *returnval)\n{\n\tuint32_t offset = ms->offset;\n\tuint32_t lhs;\n\tfile_pushbuf_t *pb;\n\tint rv, oneed_separator, in_type;\n\tchar *rbuf;\n\tunion VALUETYPE *p = &ms->ms_value;\n\tstruct mlist ml;\n\n\tif (recursion_level >= MAX_RECURSION_LEVEL) {\n\t\tfile_error(ms, 0, \"recursion nesting exceeded\");\n\t\treturn -1;\n\t}\n\n\tif (mcopy(ms, p, m->type, m->flag & INDIR, s, (uint32_t)(offset + o),\n\t    (uint32_t)nbytes, m) == -1)\n\t\treturn -1;\n\n\tif ((ms->flags & MAGIC_DEBUG) != 0) {\n\t\tfprintf(stderr, \"mget(type=%d, flag=%x, offset=%u, o=%\"\n\t\t    SIZE_T_FORMAT \"u, \" \"nbytes=%\" SIZE_T_FORMAT \"u)\\n\",\n\t\t    m->type, m->flag, offset, o, nbytes);\n\t\tmdebug(offset, (char *)(void *)p, sizeof(union VALUETYPE));\n#ifndef COMPILE_ONLY\n\t\tfile_mdump(m);\n#endif\n\t}\n\n\tif (m->flag & INDIR) {\n\t\tint off = m->in_offset;\n\t\tif (m->in_op & FILE_OPINDIRECT) {\n\t\t\tconst union VALUETYPE *q = CAST(const union VALUETYPE *,\n\t\t\t    ((const void *)(s + offset + off)));\n\t\t\tswitch (cvt_flip(m->in_type, flip)) {\n\t\t\tcase FILE_BYTE:\n\t\t\t\toff = q->b;\n\t\t\t\tbreak;\n\t\t\tcase FILE_SHORT:\n\t\t\t\toff = q->h;\n\t\t\t\tbreak;\n\t\t\tcase FILE_BESHORT:\n\t\t\t\toff = (short)((q->hs[0]<<8)|(q->hs[1]));\n\t\t\t\tbreak;\n\t\t\tcase FILE_LESHORT:\n\t\t\t\toff = (short)((q->hs[1]<<8)|(q->hs[0]));\n\t\t\t\tbreak;\n\t\t\tcase FILE_LONG:\n\t\t\t\toff = q->l;\n\t\t\t\tbreak;\n\t\t\tcase FILE_BELONG:\n\t\t\tcase FILE_BEID3:\n\t\t\t\toff = (int32_t)((q->hl[0]<<24)|(q->hl[1]<<16)|\n\t\t\t\t\t\t (q->hl[2]<<8)|(q->hl[3]));\n\t\t\t\tbreak;\n\t\t\tcase FILE_LEID3:\n\t\t\tcase FILE_LELONG:\n\t\t\t\toff = (int32_t)((q->hl[3]<<24)|(q->hl[2]<<16)|\n\t\t\t\t\t\t (q->hl[1]<<8)|(q->hl[0]));\n\t\t\t\tbreak;\n\t\t\tcase FILE_MELONG:\n\t\t\t\toff = (int32_t)((q->hl[1]<<24)|(q->hl[0]<<16)|\n\t\t\t\t\t\t (q->hl[3]<<8)|(q->hl[2]));\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif ((ms->flags & MAGIC_DEBUG) != 0)\n\t\t\t\tfprintf(stderr, \"indirect offs=%u\\n\", off);\n\t\t}\n\t\tswitch (in_type = cvt_flip(m->in_type, flip)) {\n\t\tcase FILE_BYTE:\n\t\t\tif (OFFSET_OOB(nbytes, offset, 1))\n\t\t\t\treturn 0;\n\t\t\tif (off) {\n\t\t\t\tswitch (m->in_op & FILE_OPS_MASK) {\n\t\t\t\tcase FILE_OPAND:\n\t\t\t\t\toffset = p->b & off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPOR:\n\t\t\t\t\toffset = p->b | off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPXOR:\n\t\t\t\t\toffset = p->b ^ off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPADD:\n\t\t\t\t\toffset = p->b + off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMINUS:\n\t\t\t\t\toffset = p->b - off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMULTIPLY:\n\t\t\t\t\toffset = p->b * off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPDIVIDE:\n\t\t\t\t\toffset = p->b / off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMODULO:\n\t\t\t\t\toffset = p->b % off;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t} else\n\t\t\t\toffset = p->b;\n\t\t\tif (m->in_op & FILE_OPINVERSE)\n\t\t\t\toffset = ~offset;\n\t\t\tbreak;\n\t\tcase FILE_BESHORT:\n\t\t\tif (OFFSET_OOB(nbytes, offset, 2))\n\t\t\t\treturn 0;\n\t\t\tlhs = (p->hs[0] << 8) | p->hs[1];\n\t\t\tif (off) {\n\t\t\t\tswitch (m->in_op & FILE_OPS_MASK) {\n\t\t\t\tcase FILE_OPAND:\n\t\t\t\t\toffset = lhs & off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPOR:\n\t\t\t\t\toffset = lhs | off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPXOR:\n\t\t\t\t\toffset = lhs ^ off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPADD:\n\t\t\t\t\toffset = lhs + off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMINUS:\n\t\t\t\t\toffset = lhs - off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMULTIPLY:\n\t\t\t\t\toffset = lhs * off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPDIVIDE:\n\t\t\t\t\toffset = lhs / off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMODULO:\n\t\t\t\t\toffset = lhs % off;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t} else\n\t\t\t\toffset = lhs;\n\t\t\tif (m->in_op & FILE_OPINVERSE)\n\t\t\t\toffset = ~offset;\n\t\t\tbreak;\n\t\tcase FILE_LESHORT:\n\t\t\tif (OFFSET_OOB(nbytes, offset, 2))\n\t\t\t\treturn 0;\n\t\t\tlhs = (p->hs[1] << 8) | p->hs[0];\n\t\t\tif (off) {\n\t\t\t\tswitch (m->in_op & FILE_OPS_MASK) {\n\t\t\t\tcase FILE_OPAND:\n\t\t\t\t\toffset = lhs & off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPOR:\n\t\t\t\t\toffset = lhs | off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPXOR:\n\t\t\t\t\toffset = lhs ^ off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPADD:\n\t\t\t\t\toffset = lhs + off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMINUS:\n\t\t\t\t\toffset = lhs - off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMULTIPLY:\n\t\t\t\t\toffset = lhs * off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPDIVIDE:\n\t\t\t\t\toffset = lhs / off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMODULO:\n\t\t\t\t\toffset = lhs % off;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t} else\n\t\t\t\toffset = lhs;\n\t\t\tif (m->in_op & FILE_OPINVERSE)\n\t\t\t\toffset = ~offset;\n\t\t\tbreak;\n\t\tcase FILE_SHORT:\n\t\t\tif (OFFSET_OOB(nbytes, offset, 2))\n\t\t\t\treturn 0;\n\t\t\tif (off) {\n\t\t\t\tswitch (m->in_op & FILE_OPS_MASK) {\n\t\t\t\tcase FILE_OPAND:\n\t\t\t\t\toffset = p->h & off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPOR:\n\t\t\t\t\toffset = p->h | off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPXOR:\n\t\t\t\t\toffset = p->h ^ off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPADD:\n\t\t\t\t\toffset = p->h + off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMINUS:\n\t\t\t\t\toffset = p->h - off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMULTIPLY:\n\t\t\t\t\toffset = p->h * off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPDIVIDE:\n\t\t\t\t\toffset = p->h / off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMODULO:\n\t\t\t\t\toffset = p->h % off;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\telse\n\t\t\t\toffset = p->h;\n\t\t\tif (m->in_op & FILE_OPINVERSE)\n\t\t\t\toffset = ~offset;\n\t\t\tbreak;\n\t\tcase FILE_BELONG:\n\t\tcase FILE_BEID3:\n\t\t\tif (OFFSET_OOB(nbytes, offset, 4))\n\t\t\t\treturn 0;\n\t\t\tlhs = (p->hl[0] << 24) | (p->hl[1] << 16) |\n\t\t\t    (p->hl[2] << 8) | p->hl[3];\n\t\t\tif (off) {\n\t\t\t\tswitch (m->in_op & FILE_OPS_MASK) {\n\t\t\t\tcase FILE_OPAND:\n\t\t\t\t\toffset = lhs & off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPOR:\n\t\t\t\t\toffset = lhs | off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPXOR:\n\t\t\t\t\toffset = lhs ^ off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPADD:\n\t\t\t\t\toffset = lhs + off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMINUS:\n\t\t\t\t\toffset = lhs - off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMULTIPLY:\n\t\t\t\t\toffset = lhs * off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPDIVIDE:\n\t\t\t\t\toffset = lhs / off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMODULO:\n\t\t\t\t\toffset = lhs % off;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t} else\n\t\t\t\toffset = lhs;\n\t\t\tif (m->in_op & FILE_OPINVERSE)\n\t\t\t\toffset = ~offset;\n\t\t\tbreak;\n\t\tcase FILE_LELONG:\n\t\tcase FILE_LEID3:\n\t\t\tif (OFFSET_OOB(nbytes, offset, 4))\n\t\t\t\treturn 0;\n\t\t\tlhs = (p->hl[3] << 24) | (p->hl[2] << 16) |\n\t\t\t    (p->hl[1] << 8) | p->hl[0];\n\t\t\tif (off) {\n\t\t\t\tswitch (m->in_op & FILE_OPS_MASK) {\n\t\t\t\tcase FILE_OPAND:\n\t\t\t\t\toffset = lhs & off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPOR:\n\t\t\t\t\toffset = lhs | off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPXOR:\n\t\t\t\t\toffset = lhs ^ off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPADD:\n\t\t\t\t\toffset = lhs + off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMINUS:\n\t\t\t\t\toffset = lhs - off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMULTIPLY:\n\t\t\t\t\toffset = lhs * off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPDIVIDE:\n\t\t\t\t\toffset = lhs / off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMODULO:\n\t\t\t\t\toffset = lhs % off;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t} else\n\t\t\t\toffset = lhs;\n\t\t\tif (m->in_op & FILE_OPINVERSE)\n\t\t\t\toffset = ~offset;\n\t\t\tbreak;\n\t\tcase FILE_MELONG:\n\t\t\tif (OFFSET_OOB(nbytes, offset, 4))\n\t\t\t\treturn 0;\n\t\t\tlhs = (p->hl[1] << 24) | (p->hl[0] << 16) |\n\t\t\t    (p->hl[3] << 8) | p->hl[2];\n\t\t\tif (off) {\n\t\t\t\tswitch (m->in_op & FILE_OPS_MASK) {\n\t\t\t\tcase FILE_OPAND:\n\t\t\t\t\toffset = lhs & off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPOR:\n\t\t\t\t\toffset = lhs | off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPXOR:\n\t\t\t\t\toffset = lhs ^ off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPADD:\n\t\t\t\t\toffset = lhs + off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMINUS:\n\t\t\t\t\toffset = lhs - off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMULTIPLY:\n\t\t\t\t\toffset = lhs * off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPDIVIDE:\n\t\t\t\t\toffset = lhs / off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMODULO:\n\t\t\t\t\toffset = lhs % off;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t} else\n\t\t\t\toffset = lhs;\n\t\t\tif (m->in_op & FILE_OPINVERSE)\n\t\t\t\toffset = ~offset;\n\t\t\tbreak;\n\t\tcase FILE_LONG:\n\t\t\tif (OFFSET_OOB(nbytes, offset, 4))\n\t\t\t\treturn 0;\n\t\t\tif (off) {\n\t\t\t\tswitch (m->in_op & FILE_OPS_MASK) {\n\t\t\t\tcase FILE_OPAND:\n\t\t\t\t\toffset = p->l & off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPOR:\n\t\t\t\t\toffset = p->l | off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPXOR:\n\t\t\t\t\toffset = p->l ^ off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPADD:\n\t\t\t\t\toffset = p->l + off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMINUS:\n\t\t\t\t\toffset = p->l - off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMULTIPLY:\n\t\t\t\t\toffset = p->l * off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPDIVIDE:\n\t\t\t\t\toffset = p->l / off;\n\t\t\t\t\tbreak;\n\t\t\t\tcase FILE_OPMODULO:\n\t\t\t\t\toffset = p->l % off;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t} else\n\t\t\t\toffset = p->l;\n\t\t\tif (m->in_op & FILE_OPINVERSE)\n\t\t\t\toffset = ~offset;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\n\t\tswitch (in_type) {\n\t\tcase FILE_LEID3:\n\t\tcase FILE_BEID3:\n\t\t\toffset = ((((offset >>  0) & 0x7f) <<  0) |\n\t\t\t\t (((offset >>  8) & 0x7f) <<  7) |\n\t\t\t\t (((offset >> 16) & 0x7f) << 14) |\n\t\t\t\t (((offset >> 24) & 0x7f) << 21)) + 10;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\n\t\tif (m->flag & INDIROFFADD) {\n\t\t\toffset += ms->c.li[cont_level-1].off;\n\t\t\tif (offset == 0) {\n\t\t\t\tif ((ms->flags & MAGIC_DEBUG) != 0)\n\t\t\t\t\tfprintf(stderr,\n\t\t\t\t\t    \"indirect *zero* offset\\n\");\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t\tif ((ms->flags & MAGIC_DEBUG) != 0)\n\t\t\t\tfprintf(stderr, \"indirect +offs=%u\\n\", offset);\n\t\t}\n\t\tif (mcopy(ms, p, m->type, 0, s, offset, nbytes, m) == -1)\n\t\t\treturn -1;\n\t\tms->offset = offset;\n\n\t\tif ((ms->flags & MAGIC_DEBUG) != 0) {\n\t\t\tmdebug(offset, (char *)(void *)p,\n\t\t\t    sizeof(union VALUETYPE));\n#ifndef COMPILE_ONLY\n\t\t\tfile_mdump(m);\n#endif\n\t\t}\n\t}\n\n\t/* Verify we have enough data to match magic type */\n\tswitch (m->type) {\n\tcase FILE_BYTE:\n\t\tif (OFFSET_OOB(nbytes, offset, 1))\n\t\t\treturn 0;\n\t\tbreak;\n\n\tcase FILE_SHORT:\n\tcase FILE_BESHORT:\n\tcase FILE_LESHORT:\n\t\tif (OFFSET_OOB(nbytes, offset, 2))\n\t\t\treturn 0;\n\t\tbreak;\n\n\tcase FILE_LONG:\n\tcase FILE_BELONG:\n\tcase FILE_LELONG:\n\tcase FILE_MELONG:\n\tcase FILE_DATE:\n\tcase FILE_BEDATE:\n\tcase FILE_LEDATE:\n\tcase FILE_MEDATE:\n\tcase FILE_LDATE:\n\tcase FILE_BELDATE:\n\tcase FILE_LELDATE:\n\tcase FILE_MELDATE:\n\tcase FILE_FLOAT:\n\tcase FILE_BEFLOAT:\n\tcase FILE_LEFLOAT:\n\t\tif (OFFSET_OOB(nbytes, offset, 4))\n\t\t\treturn 0;\n\t\tbreak;\n\n\tcase FILE_DOUBLE:\n\tcase FILE_BEDOUBLE:\n\tcase FILE_LEDOUBLE:\n\t\tif (OFFSET_OOB(nbytes, offset, 8))\n\t\t\treturn 0;\n\t\tbreak;\n\n\tcase FILE_STRING:\n\tcase FILE_PSTRING:\n\tcase FILE_SEARCH:\n\t\tif (OFFSET_OOB(nbytes, offset, m->vallen))\n\t\t\treturn 0;\n\t\tbreak;\n\n\tcase FILE_REGEX:\n\t\tif (nbytes < offset)\n\t\t\treturn 0;\n\t\tbreak;\n\n\tcase FILE_INDIRECT:\n\t\tif (offset == 0)\n\t\t\treturn 0;\n\n\t\tif (nbytes < offset)\n\t\t\treturn 0;\n\n\t\tif ((pb = file_push_buffer(ms)) == NULL)\n\t\t\treturn -1;\n\n\t\trv = file_softmagic(ms, s + offset, nbytes - offset,\n\t\t    recursion_level, BINTEST, text);\n\n\t\tif ((ms->flags & MAGIC_DEBUG) != 0)\n\t\t\tfprintf(stderr, \"indirect @offs=%u[%d]\\n\", offset, rv);\n\n\t\trbuf = file_pop_buffer(ms, pb);\n\t\tif (rbuf == NULL)\n\t\t\treturn -1;\n\n\t\tif (rv == 1) {\n\t\t\tif ((ms->flags & (MAGIC_MIME|MAGIC_APPLE)) == 0 &&\n\t\t\t    file_printf(ms, F(ms, m, \"%u\"), offset) == -1) {\n\t\t\t\tfree(rbuf);\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tif (file_printf(ms, \"%s\", rbuf) == -1) {\n\t\t\t\tfree(rbuf);\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t}\n\t\tfree(rbuf);\n\t\treturn rv;\n\n\tcase FILE_USE:\n\t\tif (nbytes < offset)\n\t\t\treturn 0;\n\t\trbuf = m->value.s;\n\t\tif (*rbuf == '^') {\n\t\t\trbuf++;\n\t\t\tflip = !flip;\n\t\t}\n\t\tif (file_magicfind(ms, rbuf, &ml) == -1) {\n\t\t\tfile_error(ms, 0, \"cannot find entry `%s'\", rbuf);\n\t\t\treturn -1;\n\t\t}\n\n\t\toneed_separator = *need_separator;\n\t\tif (m->flag & NOSPACE)\n\t\t\t*need_separator = 0;\n\t\trv = match(ms, ml.magic, ml.nmagic, s, nbytes, offset + o,\n\t\t    mode, text, flip, recursion_level, printed_something,\n\t\t    need_separator, returnval);\n\t\tif (rv != 1)\n\t\t    *need_separator = oneed_separator;\n\t\treturn rv;\n\n\tcase FILE_NAME:\n\t\tif (file_printf(ms, \"%s\", m->desc) == -1)\n\t\t\treturn -1;\n\t\treturn 1;\n\tcase FILE_DEFAULT:\t/* nothing to check */\n\tcase FILE_CLEAR:\n\tdefault:\n\t\tbreak;\n\t}\n\tif (!mconvert(ms, m, flip))\n\t\treturn 0;\n\treturn 1;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,14 +4,15 @@\n     int flip, int recursion_level, int *printed_something,\n     int *need_separator, int *returnval)\n {\n-\tuint32_t soffset, offset = ms->offset;\n+\tuint32_t offset = ms->offset;\n \tuint32_t lhs;\n+\tfile_pushbuf_t *pb;\n \tint rv, oneed_separator, in_type;\n-\tchar *sbuf, *rbuf;\n+\tchar *rbuf;\n \tunion VALUETYPE *p = &ms->ms_value;\n \tstruct mlist ml;\n \n-\tif (recursion_level >= 20) {\n+\tif (recursion_level >= MAX_RECURSION_LEVEL) {\n \t\tfile_error(ms, 0, \"recursion nesting exceeded\");\n \t\treturn -1;\n \t}\n@@ -456,19 +457,23 @@\n \tcase FILE_INDIRECT:\n \t\tif (offset == 0)\n \t\t\treturn 0;\n+\n \t\tif (nbytes < offset)\n \t\t\treturn 0;\n-\t\tsbuf = ms->o.buf;\n-\t\tsoffset = ms->offset;\n-\t\tms->o.buf = NULL;\n-\t\tms->offset = 0;\n+\n+\t\tif ((pb = file_push_buffer(ms)) == NULL)\n+\t\t\treturn -1;\n+\n \t\trv = file_softmagic(ms, s + offset, nbytes - offset,\n \t\t    recursion_level, BINTEST, text);\n+\n \t\tif ((ms->flags & MAGIC_DEBUG) != 0)\n \t\t\tfprintf(stderr, \"indirect @offs=%u[%d]\\n\", offset, rv);\n-\t\trbuf = ms->o.buf;\n-\t\tms->o.buf = sbuf;\n-\t\tms->offset = soffset;\n+\n+\t\trbuf = file_pop_buffer(ms, pb);\n+\t\tif (rbuf == NULL)\n+\t\t\treturn -1;\n+\n \t\tif (rv == 1) {\n \t\t\tif ((ms->flags & (MAGIC_MIME|MAGIC_APPLE)) == 0 &&\n \t\t\t    file_printf(ms, F(ms, m, \"%u\"), offset) == -1) {\n@@ -486,13 +491,13 @@\n \tcase FILE_USE:\n \t\tif (nbytes < offset)\n \t\t\treturn 0;\n-\t\tsbuf = m->value.s;\n-\t\tif (*sbuf == '^') {\n-\t\t\tsbuf++;\n+\t\trbuf = m->value.s;\n+\t\tif (*rbuf == '^') {\n+\t\t\trbuf++;\n \t\t\tflip = !flip;\n \t\t}\n-\t\tif (file_magicfind(ms, sbuf, &ml) == -1) {\n-\t\t\tfile_error(ms, 0, \"cannot find entry `%s'\", sbuf);\n+\t\tif (file_magicfind(ms, rbuf, &ml) == -1) {\n+\t\t\tfile_error(ms, 0, \"cannot find entry `%s'\", rbuf);\n \t\t\treturn -1;\n \t\t}\n ",
        "diff_line_info": {
            "deleted_lines": [
                "\tuint32_t soffset, offset = ms->offset;",
                "\tchar *sbuf, *rbuf;",
                "\tif (recursion_level >= 20) {",
                "\t\tsbuf = ms->o.buf;",
                "\t\tsoffset = ms->offset;",
                "\t\tms->o.buf = NULL;",
                "\t\tms->offset = 0;",
                "\t\trbuf = ms->o.buf;",
                "\t\tms->o.buf = sbuf;",
                "\t\tms->offset = soffset;",
                "\t\tsbuf = m->value.s;",
                "\t\tif (*sbuf == '^') {",
                "\t\t\tsbuf++;",
                "\t\tif (file_magicfind(ms, sbuf, &ml) == -1) {",
                "\t\t\tfile_error(ms, 0, \"cannot find entry `%s'\", sbuf);"
            ],
            "added_lines": [
                "\tuint32_t offset = ms->offset;",
                "\tfile_pushbuf_t *pb;",
                "\tchar *rbuf;",
                "\tif (recursion_level >= MAX_RECURSION_LEVEL) {",
                "",
                "",
                "\t\tif ((pb = file_push_buffer(ms)) == NULL)",
                "\t\t\treturn -1;",
                "",
                "",
                "",
                "\t\trbuf = file_pop_buffer(ms, pb);",
                "\t\tif (rbuf == NULL)",
                "\t\t\treturn -1;",
                "",
                "\t\trbuf = m->value.s;",
                "\t\tif (*rbuf == '^') {",
                "\t\t\trbuf++;",
                "\t\tif (file_magicfind(ms, rbuf, &ml) == -1) {",
                "\t\t\tfile_error(ms, 0, \"cannot find entry `%s'\", rbuf);"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-9420",
        "func_name": "torvalds/linux/rock_continue",
        "description": "The rock_continue function in fs/isofs/rock.c in the Linux kernel through 3.18.1 does not restrict the number of Rock Ridge continuation entries, which allows local users to cause a denial of service (infinite loop, and system crash or hang) via a crafted iso9660 image.",
        "git_url": "https://github.com/torvalds/linux/commit/f54e18f1b831c92f6512d2eedb224cd63d607d3d",
        "commit_title": "isofs: Fix infinite looping over CE entries",
        "commit_text": " Rock Ridge extensions define so called Continuation Entries (CE) which define where is further space with Rock Ridge data. Corrupted isofs image can contain arbitrarily long chain of these, including a one containing loop and thus causing kernel to end in an infinite loop when traversing these entries.  Limit the traversal to 32 entries which should be more than enough space to store all the Rock Ridge data. ",
        "func_before": "static int rock_continue(struct rock_state *rs)\n{\n\tint ret = 1;\n\tint blocksize = 1 << rs->inode->i_blkbits;\n\tconst int min_de_size = offsetof(struct rock_ridge, u);\n\n\tkfree(rs->buffer);\n\trs->buffer = NULL;\n\n\tif ((unsigned)rs->cont_offset > blocksize - min_de_size ||\n\t    (unsigned)rs->cont_size > blocksize ||\n\t    (unsigned)(rs->cont_offset + rs->cont_size) > blocksize) {\n\t\tprintk(KERN_NOTICE \"rock: corrupted directory entry. \"\n\t\t\t\"extent=%d, offset=%d, size=%d\\n\",\n\t\t\trs->cont_extent, rs->cont_offset, rs->cont_size);\n\t\tret = -EIO;\n\t\tgoto out;\n\t}\n\n\tif (rs->cont_extent) {\n\t\tstruct buffer_head *bh;\n\n\t\trs->buffer = kmalloc(rs->cont_size, GFP_KERNEL);\n\t\tif (!rs->buffer) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto out;\n\t\t}\n\t\tret = -EIO;\n\t\tbh = sb_bread(rs->inode->i_sb, rs->cont_extent);\n\t\tif (bh) {\n\t\t\tmemcpy(rs->buffer, bh->b_data + rs->cont_offset,\n\t\t\t\t\trs->cont_size);\n\t\t\tput_bh(bh);\n\t\t\trs->chr = rs->buffer;\n\t\t\trs->len = rs->cont_size;\n\t\t\trs->cont_extent = 0;\n\t\t\trs->cont_size = 0;\n\t\t\trs->cont_offset = 0;\n\t\t\treturn 0;\n\t\t}\n\t\tprintk(\"Unable to read rock-ridge attributes\\n\");\n\t}\nout:\n\tkfree(rs->buffer);\n\trs->buffer = NULL;\n\treturn ret;\n}",
        "func": "static int rock_continue(struct rock_state *rs)\n{\n\tint ret = 1;\n\tint blocksize = 1 << rs->inode->i_blkbits;\n\tconst int min_de_size = offsetof(struct rock_ridge, u);\n\n\tkfree(rs->buffer);\n\trs->buffer = NULL;\n\n\tif ((unsigned)rs->cont_offset > blocksize - min_de_size ||\n\t    (unsigned)rs->cont_size > blocksize ||\n\t    (unsigned)(rs->cont_offset + rs->cont_size) > blocksize) {\n\t\tprintk(KERN_NOTICE \"rock: corrupted directory entry. \"\n\t\t\t\"extent=%d, offset=%d, size=%d\\n\",\n\t\t\trs->cont_extent, rs->cont_offset, rs->cont_size);\n\t\tret = -EIO;\n\t\tgoto out;\n\t}\n\n\tif (rs->cont_extent) {\n\t\tstruct buffer_head *bh;\n\n\t\trs->buffer = kmalloc(rs->cont_size, GFP_KERNEL);\n\t\tif (!rs->buffer) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto out;\n\t\t}\n\t\tret = -EIO;\n\t\tif (++rs->cont_loops >= RR_MAX_CE_ENTRIES)\n\t\t\tgoto out;\n\t\tbh = sb_bread(rs->inode->i_sb, rs->cont_extent);\n\t\tif (bh) {\n\t\t\tmemcpy(rs->buffer, bh->b_data + rs->cont_offset,\n\t\t\t\t\trs->cont_size);\n\t\t\tput_bh(bh);\n\t\t\trs->chr = rs->buffer;\n\t\t\trs->len = rs->cont_size;\n\t\t\trs->cont_extent = 0;\n\t\t\trs->cont_size = 0;\n\t\t\trs->cont_offset = 0;\n\t\t\treturn 0;\n\t\t}\n\t\tprintk(\"Unable to read rock-ridge attributes\\n\");\n\t}\nout:\n\tkfree(rs->buffer);\n\trs->buffer = NULL;\n\treturn ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -26,6 +26,8 @@\n \t\t\tgoto out;\n \t\t}\n \t\tret = -EIO;\n+\t\tif (++rs->cont_loops >= RR_MAX_CE_ENTRIES)\n+\t\t\tgoto out;\n \t\tbh = sb_bread(rs->inode->i_sb, rs->cont_extent);\n \t\tif (bh) {\n \t\t\tmemcpy(rs->buffer, bh->b_data + rs->cont_offset,",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t\tif (++rs->cont_loops >= RR_MAX_CE_ENTRIES)",
                "\t\t\tgoto out;"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-9428",
        "func_name": "torvalds/linux/batadv_frag_merge_packets",
        "description": "The batadv_frag_merge_packets function in net/batman-adv/fragmentation.c in the B.A.T.M.A.N. implementation in the Linux kernel through 3.18.1 uses an incorrect length field during a calculation of an amount of memory, which allows remote attackers to cause a denial of service (mesh-node system crash) via fragmented packets.",
        "git_url": "https://github.com/torvalds/linux/commit/5b6698b0e4a37053de35cc24ee695b98a7eb712b",
        "commit_title": "batman-adv: Calculate extra tail size based on queued fragments",
        "commit_text": " The fragmentation code was replaced in 610bfc6bc99bc83680d190ebc69359a05fc7f605 (\"batman-adv: Receive fragmented packets and merge\"). The new code provided a mostly unused parameter skb for the merging function. It is used inside the function to calculate the additionally needed skb tailroom. But instead of increasing its own tailroom, it is only increasing the tailroom of the first queued skb. This is not correct in some situations because the first queued entry can be a different one than the parameter.  An observed problem was:  1. packet with size 104, total_size 1464, fragno 1 was received    - packet is queued 2. packet with size 1400, total_size 1464, fragno 0 was received    - packet is queued at the end of the list 3. enough data was received and can be given to the merge function    (1464 == (1400 - 20) + (104 - 20))    - merge functions gets 1400 byte large packet as skb argument 4. merge function gets first entry in queue (104 byte)    - stored as skb_out 5. merge function calculates the required extra tail as total_size - skb->len    - pskb_expand_head tail of skb_out with 64 bytes 6. merge function tries to squeeze the extra 1380 bytes from the second queued    skb (1400 byte aka skb parameter) in the 64 extra tail bytes of skb_out  Instead calculate the extra required tail bytes for skb_out also using skb_out instead of using the parameter skb. The skb parameter is only used to get the total_size from the last received packet. This is also the total_size used to decide that all fragments were received. ",
        "func_before": "static struct sk_buff *\nbatadv_frag_merge_packets(struct hlist_head *chain, struct sk_buff *skb)\n{\n\tstruct batadv_frag_packet *packet;\n\tstruct batadv_frag_list_entry *entry;\n\tstruct sk_buff *skb_out = NULL;\n\tint size, hdr_size = sizeof(struct batadv_frag_packet);\n\n\t/* Make sure incoming skb has non-bogus data. */\n\tpacket = (struct batadv_frag_packet *)skb->data;\n\tsize = ntohs(packet->total_size);\n\tif (size > batadv_frag_size_limit())\n\t\tgoto free;\n\n\t/* Remove first entry, as this is the destination for the rest of the\n\t * fragments.\n\t */\n\tentry = hlist_entry(chain->first, struct batadv_frag_list_entry, list);\n\thlist_del(&entry->list);\n\tskb_out = entry->skb;\n\tkfree(entry);\n\n\t/* Make room for the rest of the fragments. */\n\tif (pskb_expand_head(skb_out, 0, size - skb->len, GFP_ATOMIC) < 0) {\n\t\tkfree_skb(skb_out);\n\t\tskb_out = NULL;\n\t\tgoto free;\n\t}\n\n\t/* Move the existing MAC header to just before the payload. (Override\n\t * the fragment header.)\n\t */\n\tskb_pull_rcsum(skb_out, hdr_size);\n\tmemmove(skb_out->data - ETH_HLEN, skb_mac_header(skb_out), ETH_HLEN);\n\tskb_set_mac_header(skb_out, -ETH_HLEN);\n\tskb_reset_network_header(skb_out);\n\tskb_reset_transport_header(skb_out);\n\n\t/* Copy the payload of the each fragment into the last skb */\n\thlist_for_each_entry(entry, chain, list) {\n\t\tsize = entry->skb->len - hdr_size;\n\t\tmemcpy(skb_put(skb_out, size), entry->skb->data + hdr_size,\n\t\t       size);\n\t}\n\nfree:\n\t/* Locking is not needed, because 'chain' is not part of any orig. */\n\tbatadv_frag_clear_chain(chain);\n\treturn skb_out;\n}",
        "func": "static struct sk_buff *\nbatadv_frag_merge_packets(struct hlist_head *chain, struct sk_buff *skb)\n{\n\tstruct batadv_frag_packet *packet;\n\tstruct batadv_frag_list_entry *entry;\n\tstruct sk_buff *skb_out = NULL;\n\tint size, hdr_size = sizeof(struct batadv_frag_packet);\n\n\t/* Make sure incoming skb has non-bogus data. */\n\tpacket = (struct batadv_frag_packet *)skb->data;\n\tsize = ntohs(packet->total_size);\n\tif (size > batadv_frag_size_limit())\n\t\tgoto free;\n\n\t/* Remove first entry, as this is the destination for the rest of the\n\t * fragments.\n\t */\n\tentry = hlist_entry(chain->first, struct batadv_frag_list_entry, list);\n\thlist_del(&entry->list);\n\tskb_out = entry->skb;\n\tkfree(entry);\n\n\t/* Make room for the rest of the fragments. */\n\tif (pskb_expand_head(skb_out, 0, size - skb_out->len, GFP_ATOMIC) < 0) {\n\t\tkfree_skb(skb_out);\n\t\tskb_out = NULL;\n\t\tgoto free;\n\t}\n\n\t/* Move the existing MAC header to just before the payload. (Override\n\t * the fragment header.)\n\t */\n\tskb_pull_rcsum(skb_out, hdr_size);\n\tmemmove(skb_out->data - ETH_HLEN, skb_mac_header(skb_out), ETH_HLEN);\n\tskb_set_mac_header(skb_out, -ETH_HLEN);\n\tskb_reset_network_header(skb_out);\n\tskb_reset_transport_header(skb_out);\n\n\t/* Copy the payload of the each fragment into the last skb */\n\thlist_for_each_entry(entry, chain, list) {\n\t\tsize = entry->skb->len - hdr_size;\n\t\tmemcpy(skb_put(skb_out, size), entry->skb->data + hdr_size,\n\t\t       size);\n\t}\n\nfree:\n\t/* Locking is not needed, because 'chain' is not part of any orig. */\n\tbatadv_frag_clear_chain(chain);\n\treturn skb_out;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -21,7 +21,7 @@\n \tkfree(entry);\n \n \t/* Make room for the rest of the fragments. */\n-\tif (pskb_expand_head(skb_out, 0, size - skb->len, GFP_ATOMIC) < 0) {\n+\tif (pskb_expand_head(skb_out, 0, size - skb_out->len, GFP_ATOMIC) < 0) {\n \t\tkfree_skb(skb_out);\n \t\tskb_out = NULL;\n \t\tgoto free;",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (pskb_expand_head(skb_out, 0, size - skb->len, GFP_ATOMIC) < 0) {"
            ],
            "added_lines": [
                "\tif (pskb_expand_head(skb_out, 0, size - skb_out->len, GFP_ATOMIC) < 0) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-6268",
        "func_name": "xen-project/xen/init_queue",
        "description": "The evtchn_fifo_set_pending function in Xen 4.4.x allows local guest users to cause a denial of service (host crash) via vectors involving an uninitialized FIFO-based event channel control block when (1) binding or (2) moving an event to a different VCPU.",
        "git_url": "https://github.com/xen-project/xen/commit/a4e0cea6fced50e251453dfe52e1b9dde77a84f5",
        "commit_title": "evtchn: check control block exists when using FIFO-based events",
        "commit_text": " When using the FIFO-based event channels, there are no checks for the existance of a control block when binding an event or moving it to a different VCPU.  This is because events may be bound when the ABI is in 2-level mode (e.g., by the toolstack before the domain is started).  The guest may trigger a Xen crash in evtchn_fifo_set_pending() if:    a) the event is bound to a VCPU without a control block; or   b) VCPU 0 does not have a control block.  In case (a), Xen will crash when looking up the current queue.  In (b), Xen will crash when looking up the old queue (which defaults to a queue on VCPU 0).  By allocating all the per-VCPU structures when enabling the FIFO ABI, we can be sure that v->evtchn_fifo is always valid.  EVTCHNOP_init_control_block for all the other CPUs need only map the shared control block.  A single check in evtchn_fifo_set_pending() before accessing the control block fixes all cases where the guest has not initialized some control blocks.  This is XSA-107. ",
        "func_before": "static void init_queue(struct vcpu *v, struct evtchn_fifo_queue *q,\n                       unsigned int i)\n{\n    spin_lock_init(&q->lock);\n    q->priority = i;\n    q->head = &v->evtchn_fifo->control_block->head[i];\n}",
        "func": "static void init_queue(struct vcpu *v, struct evtchn_fifo_queue *q,\n                       unsigned int i)\n{\n    spin_lock_init(&q->lock);\n    q->priority = i;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,5 +3,4 @@\n {\n     spin_lock_init(&q->lock);\n     q->priority = i;\n-    q->head = &v->evtchn_fifo->control_block->head[i];\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    q->head = &v->evtchn_fifo->control_block->head[i];"
            ],
            "added_lines": []
        }
    },
    {
        "cve_id": "CVE-2014-6268",
        "func_name": "xen-project/xen/evtchn_fifo_init_control",
        "description": "The evtchn_fifo_set_pending function in Xen 4.4.x allows local guest users to cause a denial of service (host crash) via vectors involving an uninitialized FIFO-based event channel control block when (1) binding or (2) moving an event to a different VCPU.",
        "git_url": "https://github.com/xen-project/xen/commit/a4e0cea6fced50e251453dfe52e1b9dde77a84f5",
        "commit_title": "evtchn: check control block exists when using FIFO-based events",
        "commit_text": " When using the FIFO-based event channels, there are no checks for the existance of a control block when binding an event or moving it to a different VCPU.  This is because events may be bound when the ABI is in 2-level mode (e.g., by the toolstack before the domain is started).  The guest may trigger a Xen crash in evtchn_fifo_set_pending() if:    a) the event is bound to a VCPU without a control block; or   b) VCPU 0 does not have a control block.  In case (a), Xen will crash when looking up the current queue.  In (b), Xen will crash when looking up the old queue (which defaults to a queue on VCPU 0).  By allocating all the per-VCPU structures when enabling the FIFO ABI, we can be sure that v->evtchn_fifo is always valid.  EVTCHNOP_init_control_block for all the other CPUs need only map the shared control block.  A single check in evtchn_fifo_set_pending() before accessing the control block fixes all cases where the guest has not initialized some control blocks.  This is XSA-107. ",
        "func_before": "int evtchn_fifo_init_control(struct evtchn_init_control *init_control)\n{\n    struct domain *d = current->domain;\n    uint32_t vcpu_id;\n    uint64_t gfn;\n    uint32_t offset;\n    struct vcpu *v;\n    int rc;\n\n    init_control->link_bits = EVTCHN_FIFO_LINK_BITS;\n\n    vcpu_id = init_control->vcpu;\n    gfn     = init_control->control_gfn;\n    offset  = init_control->offset;\n\n    if ( vcpu_id >= d->max_vcpus || !d->vcpu[vcpu_id] )\n        return -ENOENT;\n    v = d->vcpu[vcpu_id];\n\n    /* Must not cross page boundary. */\n    if ( offset > (PAGE_SIZE - sizeof(evtchn_fifo_control_block_t)) )\n        return -EINVAL;\n\n    /* Must be 8-bytes aligned. */\n    if ( offset & (8 - 1) )\n        return -EINVAL;\n\n    spin_lock(&d->event_lock);\n\n    rc = setup_control_block(v, gfn, offset);\n\n    /*\n     * If this is the first control block, setup an empty event array\n     * and switch to the fifo port ops.\n     */\n    if ( rc == 0 && !d->evtchn_fifo )\n    {\n        rc = setup_event_array(d);\n        if ( rc < 0 )\n            cleanup_control_block(v);\n        else\n        {\n            d->evtchn_port_ops = &evtchn_port_ops_fifo;\n            d->max_evtchns = EVTCHN_FIFO_NR_CHANNELS;\n            setup_ports(d);\n        }\n    }\n\n    spin_unlock(&d->event_lock);\n\n    return rc;\n}",
        "func": "int evtchn_fifo_init_control(struct evtchn_init_control *init_control)\n{\n    struct domain *d = current->domain;\n    uint32_t vcpu_id;\n    uint64_t gfn;\n    uint32_t offset;\n    struct vcpu *v;\n    int rc;\n\n    init_control->link_bits = EVTCHN_FIFO_LINK_BITS;\n\n    vcpu_id = init_control->vcpu;\n    gfn     = init_control->control_gfn;\n    offset  = init_control->offset;\n\n    if ( vcpu_id >= d->max_vcpus || !d->vcpu[vcpu_id] )\n        return -ENOENT;\n    v = d->vcpu[vcpu_id];\n\n    /* Must not cross page boundary. */\n    if ( offset > (PAGE_SIZE - sizeof(evtchn_fifo_control_block_t)) )\n        return -EINVAL;\n\n    /* Must be 8-bytes aligned. */\n    if ( offset & (8 - 1) )\n        return -EINVAL;\n\n    spin_lock(&d->event_lock);\n\n    /*\n     * If this is the first control block, setup an empty event array\n     * and switch to the fifo port ops.\n     */\n    if ( !d->evtchn_fifo )\n    {\n        struct vcpu *vcb;\n\n        for_each_vcpu ( d, vcb ) {\n            rc = setup_control_block(vcb);\n            if ( rc < 0 )\n                goto error;\n        }\n\n        rc = setup_event_array(d);\n        if ( rc < 0 )\n            goto error;\n\n        rc = map_control_block(v, gfn, offset);\n        if ( rc < 0 )\n            goto error;\n\n        d->evtchn_port_ops = &evtchn_port_ops_fifo;\n        d->max_evtchns = EVTCHN_FIFO_NR_CHANNELS;\n        setup_ports(d);\n    }\n    else\n        rc = map_control_block(v, gfn, offset);\n\n    spin_unlock(&d->event_lock);\n\n    return rc;\n\n error:\n    evtchn_fifo_destroy(d);\n    spin_unlock(&d->event_lock);\n    return rc;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -27,26 +27,41 @@\n \n     spin_lock(&d->event_lock);\n \n-    rc = setup_control_block(v, gfn, offset);\n-\n     /*\n      * If this is the first control block, setup an empty event array\n      * and switch to the fifo port ops.\n      */\n-    if ( rc == 0 && !d->evtchn_fifo )\n+    if ( !d->evtchn_fifo )\n     {\n+        struct vcpu *vcb;\n+\n+        for_each_vcpu ( d, vcb ) {\n+            rc = setup_control_block(vcb);\n+            if ( rc < 0 )\n+                goto error;\n+        }\n+\n         rc = setup_event_array(d);\n         if ( rc < 0 )\n-            cleanup_control_block(v);\n-        else\n-        {\n-            d->evtchn_port_ops = &evtchn_port_ops_fifo;\n-            d->max_evtchns = EVTCHN_FIFO_NR_CHANNELS;\n-            setup_ports(d);\n-        }\n+            goto error;\n+\n+        rc = map_control_block(v, gfn, offset);\n+        if ( rc < 0 )\n+            goto error;\n+\n+        d->evtchn_port_ops = &evtchn_port_ops_fifo;\n+        d->max_evtchns = EVTCHN_FIFO_NR_CHANNELS;\n+        setup_ports(d);\n     }\n+    else\n+        rc = map_control_block(v, gfn, offset);\n \n     spin_unlock(&d->event_lock);\n \n     return rc;\n+\n+ error:\n+    evtchn_fifo_destroy(d);\n+    spin_unlock(&d->event_lock);\n+    return rc;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    rc = setup_control_block(v, gfn, offset);",
                "",
                "    if ( rc == 0 && !d->evtchn_fifo )",
                "            cleanup_control_block(v);",
                "        else",
                "        {",
                "            d->evtchn_port_ops = &evtchn_port_ops_fifo;",
                "            d->max_evtchns = EVTCHN_FIFO_NR_CHANNELS;",
                "            setup_ports(d);",
                "        }"
            ],
            "added_lines": [
                "    if ( !d->evtchn_fifo )",
                "        struct vcpu *vcb;",
                "",
                "        for_each_vcpu ( d, vcb ) {",
                "            rc = setup_control_block(vcb);",
                "            if ( rc < 0 )",
                "                goto error;",
                "        }",
                "",
                "            goto error;",
                "",
                "        rc = map_control_block(v, gfn, offset);",
                "        if ( rc < 0 )",
                "            goto error;",
                "",
                "        d->evtchn_port_ops = &evtchn_port_ops_fifo;",
                "        d->max_evtchns = EVTCHN_FIFO_NR_CHANNELS;",
                "        setup_ports(d);",
                "    else",
                "        rc = map_control_block(v, gfn, offset);",
                "",
                " error:",
                "    evtchn_fifo_destroy(d);",
                "    spin_unlock(&d->event_lock);",
                "    return rc;"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-6268",
        "func_name": "xen-project/xen/setup_control_block",
        "description": "The evtchn_fifo_set_pending function in Xen 4.4.x allows local guest users to cause a denial of service (host crash) via vectors involving an uninitialized FIFO-based event channel control block when (1) binding or (2) moving an event to a different VCPU.",
        "git_url": "https://github.com/xen-project/xen/commit/a4e0cea6fced50e251453dfe52e1b9dde77a84f5",
        "commit_title": "evtchn: check control block exists when using FIFO-based events",
        "commit_text": " When using the FIFO-based event channels, there are no checks for the existance of a control block when binding an event or moving it to a different VCPU.  This is because events may be bound when the ABI is in 2-level mode (e.g., by the toolstack before the domain is started).  The guest may trigger a Xen crash in evtchn_fifo_set_pending() if:    a) the event is bound to a VCPU without a control block; or   b) VCPU 0 does not have a control block.  In case (a), Xen will crash when looking up the current queue.  In (b), Xen will crash when looking up the old queue (which defaults to a queue on VCPU 0).  By allocating all the per-VCPU structures when enabling the FIFO ABI, we can be sure that v->evtchn_fifo is always valid.  EVTCHNOP_init_control_block for all the other CPUs need only map the shared control block.  A single check in evtchn_fifo_set_pending() before accessing the control block fixes all cases where the guest has not initialized some control blocks.  This is XSA-107. ",
        "func_before": "static int setup_control_block(struct vcpu *v, uint64_t gfn, uint32_t offset)\n{\n    struct domain *d = v->domain;\n    struct evtchn_fifo_vcpu *efv;\n    void *virt;\n    unsigned int i;\n    int rc;\n\n    if ( v->evtchn_fifo )\n        return -EINVAL;\n\n    efv = xzalloc(struct evtchn_fifo_vcpu);\n    if ( !efv )\n        return -ENOMEM;\n\n    rc = map_guest_page(d, gfn, &virt);\n    if ( rc < 0 )\n    {\n        xfree(efv);\n        return rc;\n    }\n\n    v->evtchn_fifo = efv;\n    v->evtchn_fifo->control_block = virt + offset;\n\n    for ( i = 0; i <= EVTCHN_FIFO_PRIORITY_MIN; i++ )\n        init_queue(v, &v->evtchn_fifo->queue[i], i);\n\n    return 0;\n}",
        "func": "static int setup_control_block(struct vcpu *v)\n{\n    struct evtchn_fifo_vcpu *efv;\n    unsigned int i;\n\n    efv = xzalloc(struct evtchn_fifo_vcpu);\n    if ( !efv )\n        return -ENOMEM;\n\n    for ( i = 0; i <= EVTCHN_FIFO_PRIORITY_MIN; i++ )\n        init_queue(v, &efv->queue[i], i);\n\n    v->evtchn_fifo = efv;\n\n    return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,30 +1,16 @@\n-static int setup_control_block(struct vcpu *v, uint64_t gfn, uint32_t offset)\n+static int setup_control_block(struct vcpu *v)\n {\n-    struct domain *d = v->domain;\n     struct evtchn_fifo_vcpu *efv;\n-    void *virt;\n     unsigned int i;\n-    int rc;\n-\n-    if ( v->evtchn_fifo )\n-        return -EINVAL;\n \n     efv = xzalloc(struct evtchn_fifo_vcpu);\n     if ( !efv )\n         return -ENOMEM;\n \n-    rc = map_guest_page(d, gfn, &virt);\n-    if ( rc < 0 )\n-    {\n-        xfree(efv);\n-        return rc;\n-    }\n+    for ( i = 0; i <= EVTCHN_FIFO_PRIORITY_MIN; i++ )\n+        init_queue(v, &efv->queue[i], i);\n \n     v->evtchn_fifo = efv;\n-    v->evtchn_fifo->control_block = virt + offset;\n-\n-    for ( i = 0; i <= EVTCHN_FIFO_PRIORITY_MIN; i++ )\n-        init_queue(v, &v->evtchn_fifo->queue[i], i);\n \n     return 0;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "static int setup_control_block(struct vcpu *v, uint64_t gfn, uint32_t offset)",
                "    struct domain *d = v->domain;",
                "    void *virt;",
                "    int rc;",
                "",
                "    if ( v->evtchn_fifo )",
                "        return -EINVAL;",
                "    rc = map_guest_page(d, gfn, &virt);",
                "    if ( rc < 0 )",
                "    {",
                "        xfree(efv);",
                "        return rc;",
                "    }",
                "    v->evtchn_fifo->control_block = virt + offset;",
                "",
                "    for ( i = 0; i <= EVTCHN_FIFO_PRIORITY_MIN; i++ )",
                "        init_queue(v, &v->evtchn_fifo->queue[i], i);"
            ],
            "added_lines": [
                "static int setup_control_block(struct vcpu *v)",
                "    for ( i = 0; i <= EVTCHN_FIFO_PRIORITY_MIN; i++ )",
                "        init_queue(v, &efv->queue[i], i);"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-6268",
        "func_name": "xen-project/xen/evtchn_fifo_set_pending",
        "description": "The evtchn_fifo_set_pending function in Xen 4.4.x allows local guest users to cause a denial of service (host crash) via vectors involving an uninitialized FIFO-based event channel control block when (1) binding or (2) moving an event to a different VCPU.",
        "git_url": "https://github.com/xen-project/xen/commit/a4e0cea6fced50e251453dfe52e1b9dde77a84f5",
        "commit_title": "evtchn: check control block exists when using FIFO-based events",
        "commit_text": " When using the FIFO-based event channels, there are no checks for the existance of a control block when binding an event or moving it to a different VCPU.  This is because events may be bound when the ABI is in 2-level mode (e.g., by the toolstack before the domain is started).  The guest may trigger a Xen crash in evtchn_fifo_set_pending() if:    a) the event is bound to a VCPU without a control block; or   b) VCPU 0 does not have a control block.  In case (a), Xen will crash when looking up the current queue.  In (b), Xen will crash when looking up the old queue (which defaults to a queue on VCPU 0).  By allocating all the per-VCPU structures when enabling the FIFO ABI, we can be sure that v->evtchn_fifo is always valid.  EVTCHNOP_init_control_block for all the other CPUs need only map the shared control block.  A single check in evtchn_fifo_set_pending() before accessing the control block fixes all cases where the guest has not initialized some control blocks.  This is XSA-107. ",
        "func_before": "static void evtchn_fifo_set_pending(struct vcpu *v, struct evtchn *evtchn)\n{\n    struct domain *d = v->domain;\n    unsigned int port;\n    event_word_t *word;\n    unsigned long flags;\n    bool_t was_pending;\n\n    port = evtchn->port;\n    word = evtchn_fifo_word_from_port(d, port);\n\n    /*\n     * Event array page may not exist yet, save the pending state for\n     * when the page is added.\n     */\n    if ( unlikely(!word) )\n    {\n        evtchn->pending = 1;\n        return;\n    }\n\n    was_pending = test_and_set_bit(EVTCHN_FIFO_PENDING, word);\n\n    /*\n     * Link the event if it unmasked and not already linked.\n     */\n    if ( !test_bit(EVTCHN_FIFO_MASKED, word)\n         && !test_bit(EVTCHN_FIFO_LINKED, word) )\n    {\n        struct evtchn_fifo_queue *q, *old_q;\n        event_word_t *tail_word;\n        bool_t linked = 0;\n\n        /*\n         * No locking around getting the queue. This may race with\n         * changing the priority but we are allowed to signal the\n         * event once on the old priority.\n         */\n        q = &v->evtchn_fifo->queue[evtchn->priority];\n\n        old_q = lock_old_queue(d, evtchn, &flags);\n        if ( !old_q )\n            goto done;\n\n        if ( test_and_set_bit(EVTCHN_FIFO_LINKED, word) )\n        {\n            spin_unlock_irqrestore(&old_q->lock, flags);\n            goto done;\n        }\n\n        /*\n         * If this event was a tail, the old queue is now empty and\n         * its tail must be invalidated to prevent adding an event to\n         * the old queue from corrupting the new queue.\n         */\n        if ( old_q->tail == port )\n            old_q->tail = 0;\n\n        /* Moved to a different queue? */\n        if ( old_q != q )\n        {\n            evtchn->last_vcpu_id = evtchn->notify_vcpu_id;\n            evtchn->last_priority = evtchn->priority;\n\n            spin_unlock_irqrestore(&old_q->lock, flags);\n            spin_lock_irqsave(&q->lock, flags);\n        }\n\n        /*\n         * Atomically link the tail to port iff the tail is linked.\n         * If the tail is unlinked the queue is empty.\n         *\n         * If port is the same as tail, the queue is empty but q->tail\n         * will appear linked as we just set LINKED above.\n         *\n         * If the queue is empty (i.e., we haven't linked to the new\n         * event), head must be updated.\n         */\n        if ( q->tail )\n        {\n            tail_word = evtchn_fifo_word_from_port(d, q->tail);\n            linked = evtchn_fifo_set_link(d, tail_word, port);\n        }\n        if ( !linked )\n            write_atomic(q->head, port);\n        q->tail = port;\n\n        spin_unlock_irqrestore(&q->lock, flags);\n\n        if ( !linked\n             && !test_and_set_bit(q->priority,\n                                  &v->evtchn_fifo->control_block->ready) )\n            vcpu_mark_events_pending(v);\n    }\n done:\n    if ( !was_pending )\n        evtchn_check_pollers(d, port);\n}",
        "func": "static void evtchn_fifo_set_pending(struct vcpu *v, struct evtchn *evtchn)\n{\n    struct domain *d = v->domain;\n    unsigned int port;\n    event_word_t *word;\n    unsigned long flags;\n    bool_t was_pending;\n\n    port = evtchn->port;\n    word = evtchn_fifo_word_from_port(d, port);\n\n    /*\n     * Event array page may not exist yet, save the pending state for\n     * when the page is added.\n     */\n    if ( unlikely(!word) )\n    {\n        evtchn->pending = 1;\n        return;\n    }\n\n    was_pending = test_and_set_bit(EVTCHN_FIFO_PENDING, word);\n\n    /*\n     * Link the event if it unmasked and not already linked.\n     */\n    if ( !test_bit(EVTCHN_FIFO_MASKED, word)\n         && !test_bit(EVTCHN_FIFO_LINKED, word) )\n    {\n        struct evtchn_fifo_queue *q, *old_q;\n        event_word_t *tail_word;\n        bool_t linked = 0;\n\n        /*\n         * Control block not mapped.  The guest must not unmask an\n         * event until the control block is initialized, so we can\n         * just drop the event.\n         */\n        if ( unlikely(!v->evtchn_fifo->control_block) )\n        {\n            printk(XENLOG_G_WARNING\n                   \"%pv has no FIFO event channel control block\\n\", v);\n            goto done;\n        }\n\n        /*\n         * No locking around getting the queue. This may race with\n         * changing the priority but we are allowed to signal the\n         * event once on the old priority.\n         */\n        q = &v->evtchn_fifo->queue[evtchn->priority];\n\n        old_q = lock_old_queue(d, evtchn, &flags);\n        if ( !old_q )\n            goto done;\n\n        if ( test_and_set_bit(EVTCHN_FIFO_LINKED, word) )\n        {\n            spin_unlock_irqrestore(&old_q->lock, flags);\n            goto done;\n        }\n\n        /*\n         * If this event was a tail, the old queue is now empty and\n         * its tail must be invalidated to prevent adding an event to\n         * the old queue from corrupting the new queue.\n         */\n        if ( old_q->tail == port )\n            old_q->tail = 0;\n\n        /* Moved to a different queue? */\n        if ( old_q != q )\n        {\n            evtchn->last_vcpu_id = evtchn->notify_vcpu_id;\n            evtchn->last_priority = evtchn->priority;\n\n            spin_unlock_irqrestore(&old_q->lock, flags);\n            spin_lock_irqsave(&q->lock, flags);\n        }\n\n        /*\n         * Atomically link the tail to port iff the tail is linked.\n         * If the tail is unlinked the queue is empty.\n         *\n         * If port is the same as tail, the queue is empty but q->tail\n         * will appear linked as we just set LINKED above.\n         *\n         * If the queue is empty (i.e., we haven't linked to the new\n         * event), head must be updated.\n         */\n        if ( q->tail )\n        {\n            tail_word = evtchn_fifo_word_from_port(d, q->tail);\n            linked = evtchn_fifo_set_link(d, tail_word, port);\n        }\n        if ( !linked )\n            write_atomic(q->head, port);\n        q->tail = port;\n\n        spin_unlock_irqrestore(&q->lock, flags);\n\n        if ( !linked\n             && !test_and_set_bit(q->priority,\n                                  &v->evtchn_fifo->control_block->ready) )\n            vcpu_mark_events_pending(v);\n    }\n done:\n    if ( !was_pending )\n        evtchn_check_pollers(d, port);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -30,6 +30,18 @@\n         struct evtchn_fifo_queue *q, *old_q;\n         event_word_t *tail_word;\n         bool_t linked = 0;\n+\n+        /*\n+         * Control block not mapped.  The guest must not unmask an\n+         * event until the control block is initialized, so we can\n+         * just drop the event.\n+         */\n+        if ( unlikely(!v->evtchn_fifo->control_block) )\n+        {\n+            printk(XENLOG_G_WARNING\n+                   \"%pv has no FIFO event channel control block\\n\", v);\n+            goto done;\n+        }\n \n         /*\n          * No locking around getting the queue. This may race with",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "        /*",
                "         * Control block not mapped.  The guest must not unmask an",
                "         * event until the control block is initialized, so we can",
                "         * just drop the event.",
                "         */",
                "        if ( unlikely(!v->evtchn_fifo->control_block) )",
                "        {",
                "            printk(XENLOG_G_WARNING",
                "                   \"%pv has no FIFO event channel control block\\n\", v);",
                "            goto done;",
                "        }"
            ]
        }
    },
    {
        "cve_id": "CVE-2010-1188",
        "func_name": "torvalds/linux/tcp_rcv_state_process",
        "description": "Use-after-free vulnerability in net/ipv4/tcp_input.c in the Linux kernel 2.6 before 2.6.20, when IPV6_RECVPKTINFO is set on a listening socket, allows remote attackers to cause a denial of service (kernel panic) via a SYN packet while the socket is in a listening (TCP_LISTEN) state, which is not properly handled and causes the skb structure to be freed.",
        "git_url": "https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?h=fb7e2399ec17f1004c0e0ccfd17439f8759ede01",
        "commit_title": "I encountered a kernel panic with my test program, which is a very",
        "commit_text": "simple IPv6 client-server program.  The server side sets IPV6_RECVPKTINFO on a listening socket, and the client side just sends a message to the server.  Then the kernel panic occurs on the server.  (If you need the test program, please let me know. I can provide it.)  This problem happens because a skb is forcibly freed in tcp_rcv_state_process().  When a socket in listening state(TCP_LISTEN) receives a syn packet, then tcp_v6_conn_request() will be called from tcp_rcv_state_process().  If the tcp_v6_conn_request() successfully returns, the skb would be discarded by __kfree_skb().  However, in case of a listening socket which was already set IPV6_RECVPKTINFO, an address of the skb will be stored in treq->pktopts and a ref count of the skb will be incremented in tcp_v6_conn_request().  But, even if the skb is still in use, the skb will be freed.  Then someone still using the freed skb will cause the kernel panic.  I suggest to use kfree_skb() instead of __kfree_skb().  ",
        "func_before": "int tcp_rcv_state_process(struct sock *sk, struct sk_buff *skb,\n\t\t\t  struct tcphdr *th, unsigned len)\n{\n\tstruct tcp_sock *tp = tcp_sk(sk);\n\tstruct inet_connection_sock *icsk = inet_csk(sk);\n\tint queued = 0;\n\n\ttp->rx_opt.saw_tstamp = 0;\n\n\tswitch (sk->sk_state) {\n\tcase TCP_CLOSE:\n\t\tgoto discard;\n\n\tcase TCP_LISTEN:\n\t\tif(th->ack)\n\t\t\treturn 1;\n\n\t\tif(th->rst)\n\t\t\tgoto discard;\n\n\t\tif(th->syn) {\n\t\t\tif (icsk->icsk_af_ops->conn_request(sk, skb) < 0)\n\t\t\t\treturn 1;\n\n\t\t\t/* Now we have several options: In theory there is \n\t\t\t * nothing else in the frame. KA9Q has an option to \n\t\t\t * send data with the syn, BSD accepts data with the\n\t\t\t * syn up to the [to be] advertised window and \n\t\t\t * Solaris 2.1 gives you a protocol error. For now \n\t\t\t * we just ignore it, that fits the spec precisely \n\t\t\t * and avoids incompatibilities. It would be nice in\n\t\t\t * future to drop through and process the data.\n\t\t\t *\n\t\t\t * Now that TTCP is starting to be used we ought to \n\t\t\t * queue this data.\n\t\t\t * But, this leaves one open to an easy denial of\n\t\t \t * service attack, and SYN cookies can't defend\n\t\t\t * against this problem. So, we drop the data\n\t\t\t * in the interest of security over speed.\n\t\t\t */\n\t\t\tgoto discard;\n\t\t}\n\t\tgoto discard;\n\n\tcase TCP_SYN_SENT:\n\t\tqueued = tcp_rcv_synsent_state_process(sk, skb, th, len);\n\t\tif (queued >= 0)\n\t\t\treturn queued;\n\n\t\t/* Do step6 onward by hand. */\n\t\ttcp_urg(sk, skb, th);\n\t\t__kfree_skb(skb);\n\t\ttcp_data_snd_check(sk, tp);\n\t\treturn 0;\n\t}\n\n\tif (tcp_fast_parse_options(skb, th, tp) && tp->rx_opt.saw_tstamp &&\n\t    tcp_paws_discard(sk, skb)) {\n\t\tif (!th->rst) {\n\t\t\tNET_INC_STATS_BH(LINUX_MIB_PAWSESTABREJECTED);\n\t\t\ttcp_send_dupack(sk, skb);\n\t\t\tgoto discard;\n\t\t}\n\t\t/* Reset is accepted even if it did not pass PAWS. */\n\t}\n\n\t/* step 1: check sequence number */\n\tif (!tcp_sequence(tp, TCP_SKB_CB(skb)->seq, TCP_SKB_CB(skb)->end_seq)) {\n\t\tif (!th->rst)\n\t\t\ttcp_send_dupack(sk, skb);\n\t\tgoto discard;\n\t}\n\n\t/* step 2: check RST bit */\n\tif(th->rst) {\n\t\ttcp_reset(sk);\n\t\tgoto discard;\n\t}\n\n\ttcp_replace_ts_recent(tp, TCP_SKB_CB(skb)->seq);\n\n\t/* step 3: check security and precedence [ignored] */\n\n\t/*\tstep 4:\n\t *\n\t *\tCheck for a SYN in window.\n\t */\n\tif (th->syn && !before(TCP_SKB_CB(skb)->seq, tp->rcv_nxt)) {\n\t\tNET_INC_STATS_BH(LINUX_MIB_TCPABORTONSYN);\n\t\ttcp_reset(sk);\n\t\treturn 1;\n\t}\n\n\t/* step 5: check the ACK field */\n\tif (th->ack) {\n\t\tint acceptable = tcp_ack(sk, skb, FLAG_SLOWPATH);\n\n\t\tswitch(sk->sk_state) {\n\t\tcase TCP_SYN_RECV:\n\t\t\tif (acceptable) {\n\t\t\t\ttp->copied_seq = tp->rcv_nxt;\n\t\t\t\tsmp_mb();\n\t\t\t\ttcp_set_state(sk, TCP_ESTABLISHED);\n\t\t\t\tsk->sk_state_change(sk);\n\n\t\t\t\t/* Note, that this wakeup is only for marginal\n\t\t\t\t * crossed SYN case. Passively open sockets\n\t\t\t\t * are not waked up, because sk->sk_sleep ==\n\t\t\t\t * NULL and sk->sk_socket == NULL.\n\t\t\t\t */\n\t\t\t\tif (sk->sk_socket) {\n\t\t\t\t\tsk_wake_async(sk,0,POLL_OUT);\n\t\t\t\t}\n\n\t\t\t\ttp->snd_una = TCP_SKB_CB(skb)->ack_seq;\n\t\t\t\ttp->snd_wnd = ntohs(th->window) <<\n\t\t\t\t\t      tp->rx_opt.snd_wscale;\n\t\t\t\ttcp_init_wl(tp, TCP_SKB_CB(skb)->ack_seq,\n\t\t\t\t\t    TCP_SKB_CB(skb)->seq);\n\n\t\t\t\t/* tcp_ack considers this ACK as duplicate\n\t\t\t\t * and does not calculate rtt.\n\t\t\t\t * Fix it at least with timestamps.\n\t\t\t\t */\n\t\t\t\tif (tp->rx_opt.saw_tstamp && tp->rx_opt.rcv_tsecr &&\n\t\t\t\t    !tp->srtt)\n\t\t\t\t\ttcp_ack_saw_tstamp(sk, 0);\n\n\t\t\t\tif (tp->rx_opt.tstamp_ok)\n\t\t\t\t\ttp->advmss -= TCPOLEN_TSTAMP_ALIGNED;\n\n\t\t\t\t/* Make sure socket is routed, for\n\t\t\t\t * correct metrics.\n\t\t\t\t */\n\t\t\t\ticsk->icsk_af_ops->rebuild_header(sk);\n\n\t\t\t\ttcp_init_metrics(sk);\n\n\t\t\t\ttcp_init_congestion_control(sk);\n\n\t\t\t\t/* Prevent spurious tcp_cwnd_restart() on\n\t\t\t\t * first data packet.\n\t\t\t\t */\n\t\t\t\ttp->lsndtime = tcp_time_stamp;\n\n\t\t\t\ttcp_mtup_init(sk);\n\t\t\t\ttcp_initialize_rcv_mss(sk);\n\t\t\t\ttcp_init_buffer_space(sk);\n\t\t\t\ttcp_fast_path_on(tp);\n\t\t\t} else {\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t\tbreak;\n\n\t\tcase TCP_FIN_WAIT1:\n\t\t\tif (tp->snd_una == tp->write_seq) {\n\t\t\t\ttcp_set_state(sk, TCP_FIN_WAIT2);\n\t\t\t\tsk->sk_shutdown |= SEND_SHUTDOWN;\n\t\t\t\tdst_confirm(sk->sk_dst_cache);\n\n\t\t\t\tif (!sock_flag(sk, SOCK_DEAD))\n\t\t\t\t\t/* Wake up lingering close() */\n\t\t\t\t\tsk->sk_state_change(sk);\n\t\t\t\telse {\n\t\t\t\t\tint tmo;\n\n\t\t\t\t\tif (tp->linger2 < 0 ||\n\t\t\t\t\t    (TCP_SKB_CB(skb)->end_seq != TCP_SKB_CB(skb)->seq &&\n\t\t\t\t\t     after(TCP_SKB_CB(skb)->end_seq - th->fin, tp->rcv_nxt))) {\n\t\t\t\t\t\ttcp_done(sk);\n\t\t\t\t\t\tNET_INC_STATS_BH(LINUX_MIB_TCPABORTONDATA);\n\t\t\t\t\t\treturn 1;\n\t\t\t\t\t}\n\n\t\t\t\t\ttmo = tcp_fin_time(sk);\n\t\t\t\t\tif (tmo > TCP_TIMEWAIT_LEN) {\n\t\t\t\t\t\tinet_csk_reset_keepalive_timer(sk, tmo - TCP_TIMEWAIT_LEN);\n\t\t\t\t\t} else if (th->fin || sock_owned_by_user(sk)) {\n\t\t\t\t\t\t/* Bad case. We could lose such FIN otherwise.\n\t\t\t\t\t\t * It is not a big problem, but it looks confusing\n\t\t\t\t\t\t * and not so rare event. We still can lose it now,\n\t\t\t\t\t\t * if it spins in bh_lock_sock(), but it is really\n\t\t\t\t\t\t * marginal case.\n\t\t\t\t\t\t */\n\t\t\t\t\t\tinet_csk_reset_keepalive_timer(sk, tmo);\n\t\t\t\t\t} else {\n\t\t\t\t\t\ttcp_time_wait(sk, TCP_FIN_WAIT2, tmo);\n\t\t\t\t\t\tgoto discard;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tbreak;\n\n\t\tcase TCP_CLOSING:\n\t\t\tif (tp->snd_una == tp->write_seq) {\n\t\t\t\ttcp_time_wait(sk, TCP_TIME_WAIT, 0);\n\t\t\t\tgoto discard;\n\t\t\t}\n\t\t\tbreak;\n\n\t\tcase TCP_LAST_ACK:\n\t\t\tif (tp->snd_una == tp->write_seq) {\n\t\t\t\ttcp_update_metrics(sk);\n\t\t\t\ttcp_done(sk);\n\t\t\t\tgoto discard;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t} else\n\t\tgoto discard;\n\n\t/* step 6: check the URG bit */\n\ttcp_urg(sk, skb, th);\n\n\t/* step 7: process the segment text */\n\tswitch (sk->sk_state) {\n\tcase TCP_CLOSE_WAIT:\n\tcase TCP_CLOSING:\n\tcase TCP_LAST_ACK:\n\t\tif (!before(TCP_SKB_CB(skb)->seq, tp->rcv_nxt))\n\t\t\tbreak;\n\tcase TCP_FIN_WAIT1:\n\tcase TCP_FIN_WAIT2:\n\t\t/* RFC 793 says to queue data in these states,\n\t\t * RFC 1122 says we MUST send a reset. \n\t\t * BSD 4.4 also does reset.\n\t\t */\n\t\tif (sk->sk_shutdown & RCV_SHUTDOWN) {\n\t\t\tif (TCP_SKB_CB(skb)->end_seq != TCP_SKB_CB(skb)->seq &&\n\t\t\t    after(TCP_SKB_CB(skb)->end_seq - th->fin, tp->rcv_nxt)) {\n\t\t\t\tNET_INC_STATS_BH(LINUX_MIB_TCPABORTONDATA);\n\t\t\t\ttcp_reset(sk);\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t}\n\t\t/* Fall through */\n\tcase TCP_ESTABLISHED: \n\t\ttcp_data_queue(sk, skb);\n\t\tqueued = 1;\n\t\tbreak;\n\t}\n\n\t/* tcp_data could move socket to TIME-WAIT */\n\tif (sk->sk_state != TCP_CLOSE) {\n\t\ttcp_data_snd_check(sk, tp);\n\t\ttcp_ack_snd_check(sk);\n\t}\n\n\tif (!queued) { \ndiscard:\n\t\t__kfree_skb(skb);\n\t}\n\treturn 0;\n}",
        "func": "int tcp_rcv_state_process(struct sock *sk, struct sk_buff *skb,\n\t\t\t  struct tcphdr *th, unsigned len)\n{\n\tstruct tcp_sock *tp = tcp_sk(sk);\n\tstruct inet_connection_sock *icsk = inet_csk(sk);\n\tint queued = 0;\n\n\ttp->rx_opt.saw_tstamp = 0;\n\n\tswitch (sk->sk_state) {\n\tcase TCP_CLOSE:\n\t\tgoto discard;\n\n\tcase TCP_LISTEN:\n\t\tif(th->ack)\n\t\t\treturn 1;\n\n\t\tif(th->rst)\n\t\t\tgoto discard;\n\n\t\tif(th->syn) {\n\t\t\tif (icsk->icsk_af_ops->conn_request(sk, skb) < 0)\n\t\t\t\treturn 1;\n\n\t\t\t/* Now we have several options: In theory there is \n\t\t\t * nothing else in the frame. KA9Q has an option to \n\t\t\t * send data with the syn, BSD accepts data with the\n\t\t\t * syn up to the [to be] advertised window and \n\t\t\t * Solaris 2.1 gives you a protocol error. For now \n\t\t\t * we just ignore it, that fits the spec precisely \n\t\t\t * and avoids incompatibilities. It would be nice in\n\t\t\t * future to drop through and process the data.\n\t\t\t *\n\t\t\t * Now that TTCP is starting to be used we ought to \n\t\t\t * queue this data.\n\t\t\t * But, this leaves one open to an easy denial of\n\t\t \t * service attack, and SYN cookies can't defend\n\t\t\t * against this problem. So, we drop the data\n\t\t\t * in the interest of security over speed unless\n\t\t\t * it's still in use.\n\t\t\t */\n\t\t\tkfree_skb(skb);\n\t\t\treturn 0;\n\t\t}\n\t\tgoto discard;\n\n\tcase TCP_SYN_SENT:\n\t\tqueued = tcp_rcv_synsent_state_process(sk, skb, th, len);\n\t\tif (queued >= 0)\n\t\t\treturn queued;\n\n\t\t/* Do step6 onward by hand. */\n\t\ttcp_urg(sk, skb, th);\n\t\t__kfree_skb(skb);\n\t\ttcp_data_snd_check(sk, tp);\n\t\treturn 0;\n\t}\n\n\tif (tcp_fast_parse_options(skb, th, tp) && tp->rx_opt.saw_tstamp &&\n\t    tcp_paws_discard(sk, skb)) {\n\t\tif (!th->rst) {\n\t\t\tNET_INC_STATS_BH(LINUX_MIB_PAWSESTABREJECTED);\n\t\t\ttcp_send_dupack(sk, skb);\n\t\t\tgoto discard;\n\t\t}\n\t\t/* Reset is accepted even if it did not pass PAWS. */\n\t}\n\n\t/* step 1: check sequence number */\n\tif (!tcp_sequence(tp, TCP_SKB_CB(skb)->seq, TCP_SKB_CB(skb)->end_seq)) {\n\t\tif (!th->rst)\n\t\t\ttcp_send_dupack(sk, skb);\n\t\tgoto discard;\n\t}\n\n\t/* step 2: check RST bit */\n\tif(th->rst) {\n\t\ttcp_reset(sk);\n\t\tgoto discard;\n\t}\n\n\ttcp_replace_ts_recent(tp, TCP_SKB_CB(skb)->seq);\n\n\t/* step 3: check security and precedence [ignored] */\n\n\t/*\tstep 4:\n\t *\n\t *\tCheck for a SYN in window.\n\t */\n\tif (th->syn && !before(TCP_SKB_CB(skb)->seq, tp->rcv_nxt)) {\n\t\tNET_INC_STATS_BH(LINUX_MIB_TCPABORTONSYN);\n\t\ttcp_reset(sk);\n\t\treturn 1;\n\t}\n\n\t/* step 5: check the ACK field */\n\tif (th->ack) {\n\t\tint acceptable = tcp_ack(sk, skb, FLAG_SLOWPATH);\n\n\t\tswitch(sk->sk_state) {\n\t\tcase TCP_SYN_RECV:\n\t\t\tif (acceptable) {\n\t\t\t\ttp->copied_seq = tp->rcv_nxt;\n\t\t\t\tsmp_mb();\n\t\t\t\ttcp_set_state(sk, TCP_ESTABLISHED);\n\t\t\t\tsk->sk_state_change(sk);\n\n\t\t\t\t/* Note, that this wakeup is only for marginal\n\t\t\t\t * crossed SYN case. Passively open sockets\n\t\t\t\t * are not waked up, because sk->sk_sleep ==\n\t\t\t\t * NULL and sk->sk_socket == NULL.\n\t\t\t\t */\n\t\t\t\tif (sk->sk_socket) {\n\t\t\t\t\tsk_wake_async(sk,0,POLL_OUT);\n\t\t\t\t}\n\n\t\t\t\ttp->snd_una = TCP_SKB_CB(skb)->ack_seq;\n\t\t\t\ttp->snd_wnd = ntohs(th->window) <<\n\t\t\t\t\t      tp->rx_opt.snd_wscale;\n\t\t\t\ttcp_init_wl(tp, TCP_SKB_CB(skb)->ack_seq,\n\t\t\t\t\t    TCP_SKB_CB(skb)->seq);\n\n\t\t\t\t/* tcp_ack considers this ACK as duplicate\n\t\t\t\t * and does not calculate rtt.\n\t\t\t\t * Fix it at least with timestamps.\n\t\t\t\t */\n\t\t\t\tif (tp->rx_opt.saw_tstamp && tp->rx_opt.rcv_tsecr &&\n\t\t\t\t    !tp->srtt)\n\t\t\t\t\ttcp_ack_saw_tstamp(sk, 0);\n\n\t\t\t\tif (tp->rx_opt.tstamp_ok)\n\t\t\t\t\ttp->advmss -= TCPOLEN_TSTAMP_ALIGNED;\n\n\t\t\t\t/* Make sure socket is routed, for\n\t\t\t\t * correct metrics.\n\t\t\t\t */\n\t\t\t\ticsk->icsk_af_ops->rebuild_header(sk);\n\n\t\t\t\ttcp_init_metrics(sk);\n\n\t\t\t\ttcp_init_congestion_control(sk);\n\n\t\t\t\t/* Prevent spurious tcp_cwnd_restart() on\n\t\t\t\t * first data packet.\n\t\t\t\t */\n\t\t\t\ttp->lsndtime = tcp_time_stamp;\n\n\t\t\t\ttcp_mtup_init(sk);\n\t\t\t\ttcp_initialize_rcv_mss(sk);\n\t\t\t\ttcp_init_buffer_space(sk);\n\t\t\t\ttcp_fast_path_on(tp);\n\t\t\t} else {\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t\tbreak;\n\n\t\tcase TCP_FIN_WAIT1:\n\t\t\tif (tp->snd_una == tp->write_seq) {\n\t\t\t\ttcp_set_state(sk, TCP_FIN_WAIT2);\n\t\t\t\tsk->sk_shutdown |= SEND_SHUTDOWN;\n\t\t\t\tdst_confirm(sk->sk_dst_cache);\n\n\t\t\t\tif (!sock_flag(sk, SOCK_DEAD))\n\t\t\t\t\t/* Wake up lingering close() */\n\t\t\t\t\tsk->sk_state_change(sk);\n\t\t\t\telse {\n\t\t\t\t\tint tmo;\n\n\t\t\t\t\tif (tp->linger2 < 0 ||\n\t\t\t\t\t    (TCP_SKB_CB(skb)->end_seq != TCP_SKB_CB(skb)->seq &&\n\t\t\t\t\t     after(TCP_SKB_CB(skb)->end_seq - th->fin, tp->rcv_nxt))) {\n\t\t\t\t\t\ttcp_done(sk);\n\t\t\t\t\t\tNET_INC_STATS_BH(LINUX_MIB_TCPABORTONDATA);\n\t\t\t\t\t\treturn 1;\n\t\t\t\t\t}\n\n\t\t\t\t\ttmo = tcp_fin_time(sk);\n\t\t\t\t\tif (tmo > TCP_TIMEWAIT_LEN) {\n\t\t\t\t\t\tinet_csk_reset_keepalive_timer(sk, tmo - TCP_TIMEWAIT_LEN);\n\t\t\t\t\t} else if (th->fin || sock_owned_by_user(sk)) {\n\t\t\t\t\t\t/* Bad case. We could lose such FIN otherwise.\n\t\t\t\t\t\t * It is not a big problem, but it looks confusing\n\t\t\t\t\t\t * and not so rare event. We still can lose it now,\n\t\t\t\t\t\t * if it spins in bh_lock_sock(), but it is really\n\t\t\t\t\t\t * marginal case.\n\t\t\t\t\t\t */\n\t\t\t\t\t\tinet_csk_reset_keepalive_timer(sk, tmo);\n\t\t\t\t\t} else {\n\t\t\t\t\t\ttcp_time_wait(sk, TCP_FIN_WAIT2, tmo);\n\t\t\t\t\t\tgoto discard;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tbreak;\n\n\t\tcase TCP_CLOSING:\n\t\t\tif (tp->snd_una == tp->write_seq) {\n\t\t\t\ttcp_time_wait(sk, TCP_TIME_WAIT, 0);\n\t\t\t\tgoto discard;\n\t\t\t}\n\t\t\tbreak;\n\n\t\tcase TCP_LAST_ACK:\n\t\t\tif (tp->snd_una == tp->write_seq) {\n\t\t\t\ttcp_update_metrics(sk);\n\t\t\t\ttcp_done(sk);\n\t\t\t\tgoto discard;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t} else\n\t\tgoto discard;\n\n\t/* step 6: check the URG bit */\n\ttcp_urg(sk, skb, th);\n\n\t/* step 7: process the segment text */\n\tswitch (sk->sk_state) {\n\tcase TCP_CLOSE_WAIT:\n\tcase TCP_CLOSING:\n\tcase TCP_LAST_ACK:\n\t\tif (!before(TCP_SKB_CB(skb)->seq, tp->rcv_nxt))\n\t\t\tbreak;\n\tcase TCP_FIN_WAIT1:\n\tcase TCP_FIN_WAIT2:\n\t\t/* RFC 793 says to queue data in these states,\n\t\t * RFC 1122 says we MUST send a reset. \n\t\t * BSD 4.4 also does reset.\n\t\t */\n\t\tif (sk->sk_shutdown & RCV_SHUTDOWN) {\n\t\t\tif (TCP_SKB_CB(skb)->end_seq != TCP_SKB_CB(skb)->seq &&\n\t\t\t    after(TCP_SKB_CB(skb)->end_seq - th->fin, tp->rcv_nxt)) {\n\t\t\t\tNET_INC_STATS_BH(LINUX_MIB_TCPABORTONDATA);\n\t\t\t\ttcp_reset(sk);\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t}\n\t\t/* Fall through */\n\tcase TCP_ESTABLISHED: \n\t\ttcp_data_queue(sk, skb);\n\t\tqueued = 1;\n\t\tbreak;\n\t}\n\n\t/* tcp_data could move socket to TIME-WAIT */\n\tif (sk->sk_state != TCP_CLOSE) {\n\t\ttcp_data_snd_check(sk, tp);\n\t\ttcp_ack_snd_check(sk);\n\t}\n\n\tif (!queued) { \ndiscard:\n\t\t__kfree_skb(skb);\n\t}\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -36,9 +36,11 @@\n \t\t\t * But, this leaves one open to an easy denial of\n \t\t \t * service attack, and SYN cookies can't defend\n \t\t\t * against this problem. So, we drop the data\n-\t\t\t * in the interest of security over speed.\n+\t\t\t * in the interest of security over speed unless\n+\t\t\t * it's still in use.\n \t\t\t */\n-\t\t\tgoto discard;\n+\t\t\tkfree_skb(skb);\n+\t\t\treturn 0;\n \t\t}\n \t\tgoto discard;\n ",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\t * in the interest of security over speed.",
                "\t\t\tgoto discard;"
            ],
            "added_lines": [
                "\t\t\t * in the interest of security over speed unless",
                "\t\t\t * it's still in use.",
                "\t\t\tkfree_skb(skb);",
                "\t\t\treturn 0;"
            ]
        }
    },
    {
        "cve_id": "CVE-2010-1086",
        "func_name": "torvalds/linux/dvb_net_ule",
        "description": "The ULE decapsulation functionality in drivers/media/dvb/dvb-core/dvb_net.c in dvb-core in Linux kernel 2.6.33 and earlier allows attackers to cause a denial of service (infinite loop) via a crafted MPEG2-TS frame, related to an invalid Payload Pointer ULE.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commitdiff;h=29e1fa3565a7951cc415c634eb2b78dbdbee151d",
        "commit_title": "ULE (Unidirectional Lightweight Encapsulation RFC 4326) decapsulation",
        "commit_text": "has a bug that causes endless loop when Payload Pointer of MPEG2-TS frame is 182 or 183.  Anyone who sends malicious MPEG2-TS frame will cause the receiver of ULE SNDU to go into endless loop.  This patch was generated and tested against linux-2.6.32.9 and should apply cleanly to linux-2.6.33 as well because there was only one typo fix to dvb_net.c since v2.6.32.  This bug was brought to you by modern day Santa Claus who decided to shower the satellite dish at Keio University with heavy snow causing huge burst of errors.  We, receiver end, received Santa Claus's gift in the form of kernel bug.  Care has been taken not to introduce more bug by fixing this bug, but please scrutinize the code for I always produces buggy code.  Cc: stable@kernel.org ",
        "func_before": "static void dvb_net_ule( struct net_device *dev, const u8 *buf, size_t buf_len )\n{\n\tstruct dvb_net_priv *priv = netdev_priv(dev);\n\tunsigned long skipped = 0L;\n\tconst u8 *ts, *ts_end, *from_where = NULL;\n\tu8 ts_remain = 0, how_much = 0, new_ts = 1;\n\tstruct ethhdr *ethh = NULL;\n\n#ifdef ULE_DEBUG\n\t/* The code inside ULE_DEBUG keeps a history of the last 100 TS cells processed. */\n\tstatic unsigned char ule_hist[100*TS_SZ];\n\tstatic unsigned char *ule_where = ule_hist, ule_dump;\n#endif\n\n\t/* For all TS cells in current buffer.\n\t * Appearently, we are called for every single TS cell.\n\t */\n\tfor (ts = buf, ts_end = buf + buf_len; ts < ts_end; /* no default incr. */ ) {\n\n\t\tif (new_ts) {\n\t\t\t/* We are about to process a new TS cell. */\n\n#ifdef ULE_DEBUG\n\t\t\tif (ule_where >= &ule_hist[100*TS_SZ]) ule_where = ule_hist;\n\t\t\tmemcpy( ule_where, ts, TS_SZ );\n\t\t\tif (ule_dump) {\n\t\t\t\thexdump( ule_where, TS_SZ );\n\t\t\t\tule_dump = 0;\n\t\t\t}\n\t\t\tule_where += TS_SZ;\n#endif\n\n\t\t\t/* Check TS error conditions: sync_byte, transport_error_indicator, scrambling_control . */\n\t\t\tif ((ts[0] != TS_SYNC) || (ts[1] & TS_TEI) || ((ts[3] & TS_SC) != 0)) {\n\t\t\t\tprintk(KERN_WARNING \"%lu: Invalid TS cell: SYNC %#x, TEI %u, SC %#x.\\n\",\n\t\t\t\t       priv->ts_count, ts[0], ts[1] & TS_TEI >> 7, ts[3] & 0xC0 >> 6);\n\n\t\t\t\t/* Drop partly decoded SNDU, reset state, resync on PUSI. */\n\t\t\t\tif (priv->ule_skb) {\n\t\t\t\t\tdev_kfree_skb( priv->ule_skb );\n\t\t\t\t\t/* Prepare for next SNDU. */\n\t\t\t\t\tdev->stats.rx_errors++;\n\t\t\t\t\tdev->stats.rx_frame_errors++;\n\t\t\t\t}\n\t\t\t\treset_ule(priv);\n\t\t\t\tpriv->need_pusi = 1;\n\n\t\t\t\t/* Continue with next TS cell. */\n\t\t\t\tts += TS_SZ;\n\t\t\t\tpriv->ts_count++;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tts_remain = 184;\n\t\t\tfrom_where = ts + 4;\n\t\t}\n\t\t/* Synchronize on PUSI, if required. */\n\t\tif (priv->need_pusi) {\n\t\t\tif (ts[1] & TS_PUSI) {\n\t\t\t\t/* Find beginning of first ULE SNDU in current TS cell. */\n\t\t\t\t/* Synchronize continuity counter. */\n\t\t\t\tpriv->tscc = ts[3] & 0x0F;\n\t\t\t\t/* There is a pointer field here. */\n\t\t\t\tif (ts[4] > ts_remain) {\n\t\t\t\t\tprintk(KERN_ERR \"%lu: Invalid ULE packet \"\n\t\t\t\t\t       \"(pointer field %d)\\n\", priv->ts_count, ts[4]);\n\t\t\t\t\tts += TS_SZ;\n\t\t\t\t\tpriv->ts_count++;\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\t/* Skip to destination of pointer field. */\n\t\t\t\tfrom_where = &ts[5] + ts[4];\n\t\t\t\tts_remain -= 1 + ts[4];\n\t\t\t\tskipped = 0;\n\t\t\t} else {\n\t\t\t\tskipped++;\n\t\t\t\tts += TS_SZ;\n\t\t\t\tpriv->ts_count++;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t}\n\n\t\tif (new_ts) {\n\t\t\t/* Check continuity counter. */\n\t\t\tif ((ts[3] & 0x0F) == priv->tscc)\n\t\t\t\tpriv->tscc = (priv->tscc + 1) & 0x0F;\n\t\t\telse {\n\t\t\t\t/* TS discontinuity handling: */\n\t\t\t\tprintk(KERN_WARNING \"%lu: TS discontinuity: got %#x, \"\n\t\t\t\t       \"expected %#x.\\n\", priv->ts_count, ts[3] & 0x0F, priv->tscc);\n\t\t\t\t/* Drop partly decoded SNDU, reset state, resync on PUSI. */\n\t\t\t\tif (priv->ule_skb) {\n\t\t\t\t\tdev_kfree_skb( priv->ule_skb );\n\t\t\t\t\t/* Prepare for next SNDU. */\n\t\t\t\t\t// reset_ule(priv);  moved to below.\n\t\t\t\t\tdev->stats.rx_errors++;\n\t\t\t\t\tdev->stats.rx_frame_errors++;\n\t\t\t\t}\n\t\t\t\treset_ule(priv);\n\t\t\t\t/* skip to next PUSI. */\n\t\t\t\tpriv->need_pusi = 1;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\t/* If we still have an incomplete payload, but PUSI is\n\t\t\t * set; some TS cells are missing.\n\t\t\t * This is only possible here, if we missed exactly 16 TS\n\t\t\t * cells (continuity counter wrap). */\n\t\t\tif (ts[1] & TS_PUSI) {\n\t\t\t\tif (! priv->need_pusi) {\n\t\t\t\t\tif (!(*from_where < (ts_remain-1)) || *from_where != priv->ule_sndu_remain) {\n\t\t\t\t\t\t/* Pointer field is invalid.  Drop this TS cell and any started ULE SNDU. */\n\t\t\t\t\t\tprintk(KERN_WARNING \"%lu: Invalid pointer \"\n\t\t\t\t\t\t       \"field: %u.\\n\", priv->ts_count, *from_where);\n\n\t\t\t\t\t\t/* Drop partly decoded SNDU, reset state, resync on PUSI. */\n\t\t\t\t\t\tif (priv->ule_skb) {\n\t\t\t\t\t\t\tdev_kfree_skb( priv->ule_skb );\n\t\t\t\t\t\t\tdev->stats.rx_errors++;\n\t\t\t\t\t\t\tdev->stats.rx_frame_errors++;\n\t\t\t\t\t\t}\n\t\t\t\t\t\treset_ule(priv);\n\t\t\t\t\t\tpriv->need_pusi = 1;\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\t\t\t\t\t/* Skip pointer field (we're processing a\n\t\t\t\t\t * packed payload). */\n\t\t\t\t\tfrom_where += 1;\n\t\t\t\t\tts_remain -= 1;\n\t\t\t\t} else\n\t\t\t\t\tpriv->need_pusi = 0;\n\n\t\t\t\tif (priv->ule_sndu_remain > 183) {\n\t\t\t\t\t/* Current SNDU lacks more data than there could be available in the\n\t\t\t\t\t * current TS cell. */\n\t\t\t\t\tdev->stats.rx_errors++;\n\t\t\t\t\tdev->stats.rx_length_errors++;\n\t\t\t\t\tprintk(KERN_WARNING \"%lu: Expected %d more SNDU bytes, but \"\n\t\t\t\t\t       \"got PUSI (pf %d, ts_remain %d).  Flushing incomplete payload.\\n\",\n\t\t\t\t\t       priv->ts_count, priv->ule_sndu_remain, ts[4], ts_remain);\n\t\t\t\t\tdev_kfree_skb(priv->ule_skb);\n\t\t\t\t\t/* Prepare for next SNDU. */\n\t\t\t\t\treset_ule(priv);\n\t\t\t\t\t/* Resync: go to where pointer field points to: start of next ULE SNDU. */\n\t\t\t\t\tfrom_where += ts[4];\n\t\t\t\t\tts_remain -= ts[4];\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t/* Check if new payload needs to be started. */\n\t\tif (priv->ule_skb == NULL) {\n\t\t\t/* Start a new payload with skb.\n\t\t\t * Find ULE header.  It is only guaranteed that the\n\t\t\t * length field (2 bytes) is contained in the current\n\t\t\t * TS.\n\t\t\t * Check ts_remain has to be >= 2 here. */\n\t\t\tif (ts_remain < 2) {\n\t\t\t\tprintk(KERN_WARNING \"Invalid payload packing: only %d \"\n\t\t\t\t       \"bytes left in TS.  Resyncing.\\n\", ts_remain);\n\t\t\t\tpriv->ule_sndu_len = 0;\n\t\t\t\tpriv->need_pusi = 1;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (! priv->ule_sndu_len) {\n\t\t\t\t/* Got at least two bytes, thus extrace the SNDU length. */\n\t\t\t\tpriv->ule_sndu_len = from_where[0] << 8 | from_where[1];\n\t\t\t\tif (priv->ule_sndu_len & 0x8000) {\n\t\t\t\t\t/* D-Bit is set: no dest mac present. */\n\t\t\t\t\tpriv->ule_sndu_len &= 0x7FFF;\n\t\t\t\t\tpriv->ule_dbit = 1;\n\t\t\t\t} else\n\t\t\t\t\tpriv->ule_dbit = 0;\n\n\t\t\t\tif (priv->ule_sndu_len < 5) {\n\t\t\t\t\tprintk(KERN_WARNING \"%lu: Invalid ULE SNDU length %u. \"\n\t\t\t\t\t       \"Resyncing.\\n\", priv->ts_count, priv->ule_sndu_len);\n\t\t\t\t\tdev->stats.rx_errors++;\n\t\t\t\t\tdev->stats.rx_length_errors++;\n\t\t\t\t\tpriv->ule_sndu_len = 0;\n\t\t\t\t\tpriv->need_pusi = 1;\n\t\t\t\t\tnew_ts = 1;\n\t\t\t\t\tts += TS_SZ;\n\t\t\t\t\tpriv->ts_count++;\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tts_remain -= 2;\t/* consume the 2 bytes SNDU length. */\n\t\t\t\tfrom_where += 2;\n\t\t\t}\n\n\t\t\t/*\n\t\t\t * State of current TS:\n\t\t\t *   ts_remain (remaining bytes in the current TS cell)\n\t\t\t *   0\tule_type is not available now, we need the next TS cell\n\t\t\t *   1\tthe first byte of the ule_type is present\n\t\t\t * >=2\tfull ULE header present, maybe some payload data as well.\n\t\t\t */\n\t\t\tswitch (ts_remain) {\n\t\t\t\tcase 1:\n\t\t\t\t\tpriv->ule_sndu_type = from_where[0] << 8;\n\t\t\t\t\tpriv->ule_sndu_type_1 = 1; /* first byte of ule_type is set. */\n\t\t\t\t\tts_remain -= 1; from_where += 1;\n\t\t\t\t\t/* Continue w/ next TS. */\n\t\t\t\tcase 0:\n\t\t\t\t\tnew_ts = 1;\n\t\t\t\t\tts += TS_SZ;\n\t\t\t\t\tpriv->ts_count++;\n\t\t\t\t\tcontinue;\n\n\t\t\t\tdefault: /* complete ULE header is present in current TS. */\n\t\t\t\t\t/* Extract ULE type field. */\n\t\t\t\t\tif (priv->ule_sndu_type_1) {\n\t\t\t\t\t\tpriv->ule_sndu_type |= from_where[0];\n\t\t\t\t\t\tfrom_where += 1; /* points to payload start. */\n\t\t\t\t\t\tts_remain -= 1;\n\t\t\t\t\t} else {\n\t\t\t\t\t\t/* Complete type is present in new TS. */\n\t\t\t\t\t\tpriv->ule_sndu_type = from_where[0] << 8 | from_where[1];\n\t\t\t\t\t\tfrom_where += 2; /* points to payload start. */\n\t\t\t\t\t\tts_remain -= 2;\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t/* Allocate the skb (decoder target buffer) with the correct size, as follows:\n\t\t\t * prepare for the largest case: bridged SNDU with MAC address (dbit = 0). */\n\t\t\tpriv->ule_skb = dev_alloc_skb( priv->ule_sndu_len + ETH_HLEN + ETH_ALEN );\n\t\t\tif (priv->ule_skb == NULL) {\n\t\t\t\tprintk(KERN_NOTICE \"%s: Memory squeeze, dropping packet.\\n\",\n\t\t\t\t       dev->name);\n\t\t\t\tdev->stats.rx_dropped++;\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\t/* This includes the CRC32 _and_ dest mac, if !dbit. */\n\t\t\tpriv->ule_sndu_remain = priv->ule_sndu_len;\n\t\t\tpriv->ule_skb->dev = dev;\n\t\t\t/* Leave space for Ethernet or bridged SNDU header (eth hdr plus one MAC addr). */\n\t\t\tskb_reserve( priv->ule_skb, ETH_HLEN + ETH_ALEN );\n\t\t}\n\n\t\t/* Copy data into our current skb. */\n\t\thow_much = min(priv->ule_sndu_remain, (int)ts_remain);\n\t\tmemcpy(skb_put(priv->ule_skb, how_much), from_where, how_much);\n\t\tpriv->ule_sndu_remain -= how_much;\n\t\tts_remain -= how_much;\n\t\tfrom_where += how_much;\n\n\t\t/* Check for complete payload. */\n\t\tif (priv->ule_sndu_remain <= 0) {\n\t\t\t/* Check CRC32, we've got it in our skb already. */\n\t\t\t__be16 ulen = htons(priv->ule_sndu_len);\n\t\t\t__be16 utype = htons(priv->ule_sndu_type);\n\t\t\tconst u8 *tail;\n\t\t\tstruct kvec iov[3] = {\n\t\t\t\t{ &ulen, sizeof ulen },\n\t\t\t\t{ &utype, sizeof utype },\n\t\t\t\t{ priv->ule_skb->data, priv->ule_skb->len - 4 }\n\t\t\t};\n\t\t\tu32 ule_crc = ~0L, expected_crc;\n\t\t\tif (priv->ule_dbit) {\n\t\t\t\t/* Set D-bit for CRC32 verification,\n\t\t\t\t * if it was set originally. */\n\t\t\t\tulen |= htons(0x8000);\n\t\t\t}\n\n\t\t\tule_crc = iov_crc32(ule_crc, iov, 3);\n\t\t\ttail = skb_tail_pointer(priv->ule_skb);\n\t\t\texpected_crc = *(tail - 4) << 24 |\n\t\t\t\t       *(tail - 3) << 16 |\n\t\t\t\t       *(tail - 2) << 8 |\n\t\t\t\t       *(tail - 1);\n\t\t\tif (ule_crc != expected_crc) {\n\t\t\t\tprintk(KERN_WARNING \"%lu: CRC32 check FAILED: %08x / %08x, SNDU len %d type %#x, ts_remain %d, next 2: %x.\\n\",\n\t\t\t\t       priv->ts_count, ule_crc, expected_crc, priv->ule_sndu_len, priv->ule_sndu_type, ts_remain, ts_remain > 2 ? *(unsigned short *)from_where : 0);\n\n#ifdef ULE_DEBUG\n\t\t\t\thexdump( iov[0].iov_base, iov[0].iov_len );\n\t\t\t\thexdump( iov[1].iov_base, iov[1].iov_len );\n\t\t\t\thexdump( iov[2].iov_base, iov[2].iov_len );\n\n\t\t\t\tif (ule_where == ule_hist) {\n\t\t\t\t\thexdump( &ule_hist[98*TS_SZ], TS_SZ );\n\t\t\t\t\thexdump( &ule_hist[99*TS_SZ], TS_SZ );\n\t\t\t\t} else if (ule_where == &ule_hist[TS_SZ]) {\n\t\t\t\t\thexdump( &ule_hist[99*TS_SZ], TS_SZ );\n\t\t\t\t\thexdump( ule_hist, TS_SZ );\n\t\t\t\t} else {\n\t\t\t\t\thexdump( ule_where - TS_SZ - TS_SZ, TS_SZ );\n\t\t\t\t\thexdump( ule_where - TS_SZ, TS_SZ );\n\t\t\t\t}\n\t\t\t\tule_dump = 1;\n#endif\n\n\t\t\t\tdev->stats.rx_errors++;\n\t\t\t\tdev->stats.rx_crc_errors++;\n\t\t\t\tdev_kfree_skb(priv->ule_skb);\n\t\t\t} else {\n\t\t\t\t/* CRC32 verified OK. */\n\t\t\t\tu8 dest_addr[ETH_ALEN];\n\t\t\t\tstatic const u8 bc_addr[ETH_ALEN] =\n\t\t\t\t\t{ [ 0 ... ETH_ALEN-1] = 0xff };\n\n\t\t\t\t/* CRC32 was OK. Remove it from skb. */\n\t\t\t\tpriv->ule_skb->tail -= 4;\n\t\t\t\tpriv->ule_skb->len -= 4;\n\n\t\t\t\tif (!priv->ule_dbit) {\n\t\t\t\t\t/*\n\t\t\t\t\t * The destination MAC address is the\n\t\t\t\t\t * next data in the skb.  It comes\n\t\t\t\t\t * before any extension headers.\n\t\t\t\t\t *\n\t\t\t\t\t * Check if the payload of this SNDU\n\t\t\t\t\t * should be passed up the stack.\n\t\t\t\t\t */\n\t\t\t\t\tregister int drop = 0;\n\t\t\t\t\tif (priv->rx_mode != RX_MODE_PROMISC) {\n\t\t\t\t\t\tif (priv->ule_skb->data[0] & 0x01) {\n\t\t\t\t\t\t\t/* multicast or broadcast */\n\t\t\t\t\t\t\tif (memcmp(priv->ule_skb->data, bc_addr, ETH_ALEN)) {\n\t\t\t\t\t\t\t\t/* multicast */\n\t\t\t\t\t\t\t\tif (priv->rx_mode == RX_MODE_MULTI) {\n\t\t\t\t\t\t\t\t\tint i;\n\t\t\t\t\t\t\t\t\tfor(i = 0; i < priv->multi_num && memcmp(priv->ule_skb->data, priv->multi_macs[i], ETH_ALEN); i++)\n\t\t\t\t\t\t\t\t\t\t;\n\t\t\t\t\t\t\t\t\tif (i == priv->multi_num)\n\t\t\t\t\t\t\t\t\t\tdrop = 1;\n\t\t\t\t\t\t\t\t} else if (priv->rx_mode != RX_MODE_ALL_MULTI)\n\t\t\t\t\t\t\t\t\tdrop = 1; /* no broadcast; */\n\t\t\t\t\t\t\t\t/* else: all multicast mode: accept all multicast packets */\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t/* else: broadcast */\n\t\t\t\t\t\t}\n\t\t\t\t\t\telse if (memcmp(priv->ule_skb->data, dev->dev_addr, ETH_ALEN))\n\t\t\t\t\t\t\tdrop = 1;\n\t\t\t\t\t\t/* else: destination address matches the MAC address of our receiver device */\n\t\t\t\t\t}\n\t\t\t\t\t/* else: promiscuous mode; pass everything up the stack */\n\n\t\t\t\t\tif (drop) {\n#ifdef ULE_DEBUG\n\t\t\t\t\t\tdprintk(\"Dropping SNDU: MAC destination address does not match: dest addr: \"MAC_ADDR_PRINTFMT\", dev addr: \"MAC_ADDR_PRINTFMT\"\\n\",\n\t\t\t\t\t\t\tMAX_ADDR_PRINTFMT_ARGS(priv->ule_skb->data), MAX_ADDR_PRINTFMT_ARGS(dev->dev_addr));\n#endif\n\t\t\t\t\t\tdev_kfree_skb(priv->ule_skb);\n\t\t\t\t\t\tgoto sndu_done;\n\t\t\t\t\t}\n\t\t\t\t\telse\n\t\t\t\t\t{\n\t\t\t\t\t\tskb_copy_from_linear_data(priv->ule_skb,\n\t\t\t\t\t\t\t      dest_addr,\n\t\t\t\t\t\t\t      ETH_ALEN);\n\t\t\t\t\t\tskb_pull(priv->ule_skb, ETH_ALEN);\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t/* Handle ULE Extension Headers. */\n\t\t\t\tif (priv->ule_sndu_type < 1536) {\n\t\t\t\t\t/* There is an extension header.  Handle it accordingly. */\n\t\t\t\t\tint l = handle_ule_extensions(priv);\n\t\t\t\t\tif (l < 0) {\n\t\t\t\t\t\t/* Mandatory extension header unknown or TEST SNDU.  Drop it. */\n\t\t\t\t\t\t// printk( KERN_WARNING \"Dropping SNDU, extension headers.\\n\" );\n\t\t\t\t\t\tdev_kfree_skb(priv->ule_skb);\n\t\t\t\t\t\tgoto sndu_done;\n\t\t\t\t\t}\n\t\t\t\t\tskb_pull(priv->ule_skb, l);\n\t\t\t\t}\n\n\t\t\t\t/*\n\t\t\t\t * Construct/assure correct ethernet header.\n\t\t\t\t * Note: in bridged mode (priv->ule_bridged !=\n\t\t\t\t * 0) we already have the (original) ethernet\n\t\t\t\t * header at the start of the payload (after\n\t\t\t\t * optional dest. address and any extension\n\t\t\t\t * headers).\n\t\t\t\t */\n\n\t\t\t\tif (!priv->ule_bridged) {\n\t\t\t\t\tskb_push(priv->ule_skb, ETH_HLEN);\n\t\t\t\t\tethh = (struct ethhdr *)priv->ule_skb->data;\n\t\t\t\t\tif (!priv->ule_dbit) {\n\t\t\t\t\t\t /* dest_addr buffer is only valid if priv->ule_dbit == 0 */\n\t\t\t\t\t\tmemcpy(ethh->h_dest, dest_addr, ETH_ALEN);\n\t\t\t\t\t\tmemset(ethh->h_source, 0, ETH_ALEN);\n\t\t\t\t\t}\n\t\t\t\t\telse /* zeroize source and dest */\n\t\t\t\t\t\tmemset( ethh, 0, ETH_ALEN*2 );\n\n\t\t\t\t\tethh->h_proto = htons(priv->ule_sndu_type);\n\t\t\t\t}\n\t\t\t\t/* else:  skb is in correct state; nothing to do. */\n\t\t\t\tpriv->ule_bridged = 0;\n\n\t\t\t\t/* Stuff into kernel's protocol stack. */\n\t\t\t\tpriv->ule_skb->protocol = dvb_net_eth_type_trans(priv->ule_skb, dev);\n\t\t\t\t/* If D-bit is set (i.e. destination MAC address not present),\n\t\t\t\t * receive the packet anyhow. */\n\t\t\t\t/* if (priv->ule_dbit && skb->pkt_type == PACKET_OTHERHOST)\n\t\t\t\t\tpriv->ule_skb->pkt_type = PACKET_HOST; */\n\t\t\t\tdev->stats.rx_packets++;\n\t\t\t\tdev->stats.rx_bytes += priv->ule_skb->len;\n\t\t\t\tnetif_rx(priv->ule_skb);\n\t\t\t}\n\t\t\tsndu_done:\n\t\t\t/* Prepare for next SNDU. */\n\t\t\treset_ule(priv);\n\t\t}\n\n\t\t/* More data in current TS (look at the bytes following the CRC32)? */\n\t\tif (ts_remain >= 2 && *((unsigned short *)from_where) != 0xFFFF) {\n\t\t\t/* Next ULE SNDU starts right there. */\n\t\t\tnew_ts = 0;\n\t\t\tpriv->ule_skb = NULL;\n\t\t\tpriv->ule_sndu_type_1 = 0;\n\t\t\tpriv->ule_sndu_len = 0;\n\t\t\t// printk(KERN_WARNING \"More data in current TS: [%#x %#x %#x %#x]\\n\",\n\t\t\t//\t*(from_where + 0), *(from_where + 1),\n\t\t\t//\t*(from_where + 2), *(from_where + 3));\n\t\t\t// printk(KERN_WARNING \"ts @ %p, stopped @ %p:\\n\", ts, from_where + 0);\n\t\t\t// hexdump(ts, 188);\n\t\t} else {\n\t\t\tnew_ts = 1;\n\t\t\tts += TS_SZ;\n\t\t\tpriv->ts_count++;\n\t\t\tif (priv->ule_skb == NULL) {\n\t\t\t\tpriv->need_pusi = 1;\n\t\t\t\tpriv->ule_sndu_type_1 = 0;\n\t\t\t\tpriv->ule_sndu_len = 0;\n\t\t\t}\n\t\t}\n\t}\t/* for all available TS cells */\n}",
        "func": "static void dvb_net_ule( struct net_device *dev, const u8 *buf, size_t buf_len )\n{\n\tstruct dvb_net_priv *priv = netdev_priv(dev);\n\tunsigned long skipped = 0L;\n\tconst u8 *ts, *ts_end, *from_where = NULL;\n\tu8 ts_remain = 0, how_much = 0, new_ts = 1;\n\tstruct ethhdr *ethh = NULL;\n\n#ifdef ULE_DEBUG\n\t/* The code inside ULE_DEBUG keeps a history of the last 100 TS cells processed. */\n\tstatic unsigned char ule_hist[100*TS_SZ];\n\tstatic unsigned char *ule_where = ule_hist, ule_dump;\n#endif\n\n\t/* For all TS cells in current buffer.\n\t * Appearently, we are called for every single TS cell.\n\t */\n\tfor (ts = buf, ts_end = buf + buf_len; ts < ts_end; /* no default incr. */ ) {\n\n\t\tif (new_ts) {\n\t\t\t/* We are about to process a new TS cell. */\n\n#ifdef ULE_DEBUG\n\t\t\tif (ule_where >= &ule_hist[100*TS_SZ]) ule_where = ule_hist;\n\t\t\tmemcpy( ule_where, ts, TS_SZ );\n\t\t\tif (ule_dump) {\n\t\t\t\thexdump( ule_where, TS_SZ );\n\t\t\t\tule_dump = 0;\n\t\t\t}\n\t\t\tule_where += TS_SZ;\n#endif\n\n\t\t\t/* Check TS error conditions: sync_byte, transport_error_indicator, scrambling_control . */\n\t\t\tif ((ts[0] != TS_SYNC) || (ts[1] & TS_TEI) || ((ts[3] & TS_SC) != 0)) {\n\t\t\t\tprintk(KERN_WARNING \"%lu: Invalid TS cell: SYNC %#x, TEI %u, SC %#x.\\n\",\n\t\t\t\t       priv->ts_count, ts[0], ts[1] & TS_TEI >> 7, ts[3] & 0xC0 >> 6);\n\n\t\t\t\t/* Drop partly decoded SNDU, reset state, resync on PUSI. */\n\t\t\t\tif (priv->ule_skb) {\n\t\t\t\t\tdev_kfree_skb( priv->ule_skb );\n\t\t\t\t\t/* Prepare for next SNDU. */\n\t\t\t\t\tdev->stats.rx_errors++;\n\t\t\t\t\tdev->stats.rx_frame_errors++;\n\t\t\t\t}\n\t\t\t\treset_ule(priv);\n\t\t\t\tpriv->need_pusi = 1;\n\n\t\t\t\t/* Continue with next TS cell. */\n\t\t\t\tts += TS_SZ;\n\t\t\t\tpriv->ts_count++;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tts_remain = 184;\n\t\t\tfrom_where = ts + 4;\n\t\t}\n\t\t/* Synchronize on PUSI, if required. */\n\t\tif (priv->need_pusi) {\n\t\t\tif (ts[1] & TS_PUSI) {\n\t\t\t\t/* Find beginning of first ULE SNDU in current TS cell. */\n\t\t\t\t/* Synchronize continuity counter. */\n\t\t\t\tpriv->tscc = ts[3] & 0x0F;\n\t\t\t\t/* There is a pointer field here. */\n\t\t\t\tif (ts[4] > ts_remain) {\n\t\t\t\t\tprintk(KERN_ERR \"%lu: Invalid ULE packet \"\n\t\t\t\t\t       \"(pointer field %d)\\n\", priv->ts_count, ts[4]);\n\t\t\t\t\tts += TS_SZ;\n\t\t\t\t\tpriv->ts_count++;\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\t/* Skip to destination of pointer field. */\n\t\t\t\tfrom_where = &ts[5] + ts[4];\n\t\t\t\tts_remain -= 1 + ts[4];\n\t\t\t\tskipped = 0;\n\t\t\t} else {\n\t\t\t\tskipped++;\n\t\t\t\tts += TS_SZ;\n\t\t\t\tpriv->ts_count++;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t}\n\n\t\tif (new_ts) {\n\t\t\t/* Check continuity counter. */\n\t\t\tif ((ts[3] & 0x0F) == priv->tscc)\n\t\t\t\tpriv->tscc = (priv->tscc + 1) & 0x0F;\n\t\t\telse {\n\t\t\t\t/* TS discontinuity handling: */\n\t\t\t\tprintk(KERN_WARNING \"%lu: TS discontinuity: got %#x, \"\n\t\t\t\t       \"expected %#x.\\n\", priv->ts_count, ts[3] & 0x0F, priv->tscc);\n\t\t\t\t/* Drop partly decoded SNDU, reset state, resync on PUSI. */\n\t\t\t\tif (priv->ule_skb) {\n\t\t\t\t\tdev_kfree_skb( priv->ule_skb );\n\t\t\t\t\t/* Prepare for next SNDU. */\n\t\t\t\t\t// reset_ule(priv);  moved to below.\n\t\t\t\t\tdev->stats.rx_errors++;\n\t\t\t\t\tdev->stats.rx_frame_errors++;\n\t\t\t\t}\n\t\t\t\treset_ule(priv);\n\t\t\t\t/* skip to next PUSI. */\n\t\t\t\tpriv->need_pusi = 1;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\t/* If we still have an incomplete payload, but PUSI is\n\t\t\t * set; some TS cells are missing.\n\t\t\t * This is only possible here, if we missed exactly 16 TS\n\t\t\t * cells (continuity counter wrap). */\n\t\t\tif (ts[1] & TS_PUSI) {\n\t\t\t\tif (! priv->need_pusi) {\n\t\t\t\t\tif (!(*from_where < (ts_remain-1)) || *from_where != priv->ule_sndu_remain) {\n\t\t\t\t\t\t/* Pointer field is invalid.  Drop this TS cell and any started ULE SNDU. */\n\t\t\t\t\t\tprintk(KERN_WARNING \"%lu: Invalid pointer \"\n\t\t\t\t\t\t       \"field: %u.\\n\", priv->ts_count, *from_where);\n\n\t\t\t\t\t\t/* Drop partly decoded SNDU, reset state, resync on PUSI. */\n\t\t\t\t\t\tif (priv->ule_skb) {\n\t\t\t\t\t\t\tdev_kfree_skb( priv->ule_skb );\n\t\t\t\t\t\t\tdev->stats.rx_errors++;\n\t\t\t\t\t\t\tdev->stats.rx_frame_errors++;\n\t\t\t\t\t\t}\n\t\t\t\t\t\treset_ule(priv);\n\t\t\t\t\t\tpriv->need_pusi = 1;\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\t\t\t\t\t/* Skip pointer field (we're processing a\n\t\t\t\t\t * packed payload). */\n\t\t\t\t\tfrom_where += 1;\n\t\t\t\t\tts_remain -= 1;\n\t\t\t\t} else\n\t\t\t\t\tpriv->need_pusi = 0;\n\n\t\t\t\tif (priv->ule_sndu_remain > 183) {\n\t\t\t\t\t/* Current SNDU lacks more data than there could be available in the\n\t\t\t\t\t * current TS cell. */\n\t\t\t\t\tdev->stats.rx_errors++;\n\t\t\t\t\tdev->stats.rx_length_errors++;\n\t\t\t\t\tprintk(KERN_WARNING \"%lu: Expected %d more SNDU bytes, but \"\n\t\t\t\t\t       \"got PUSI (pf %d, ts_remain %d).  Flushing incomplete payload.\\n\",\n\t\t\t\t\t       priv->ts_count, priv->ule_sndu_remain, ts[4], ts_remain);\n\t\t\t\t\tdev_kfree_skb(priv->ule_skb);\n\t\t\t\t\t/* Prepare for next SNDU. */\n\t\t\t\t\treset_ule(priv);\n\t\t\t\t\t/* Resync: go to where pointer field points to: start of next ULE SNDU. */\n\t\t\t\t\tfrom_where += ts[4];\n\t\t\t\t\tts_remain -= ts[4];\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t/* Check if new payload needs to be started. */\n\t\tif (priv->ule_skb == NULL) {\n\t\t\t/* Start a new payload with skb.\n\t\t\t * Find ULE header.  It is only guaranteed that the\n\t\t\t * length field (2 bytes) is contained in the current\n\t\t\t * TS.\n\t\t\t * Check ts_remain has to be >= 2 here. */\n\t\t\tif (ts_remain < 2) {\n\t\t\t\tprintk(KERN_WARNING \"Invalid payload packing: only %d \"\n\t\t\t\t       \"bytes left in TS.  Resyncing.\\n\", ts_remain);\n\t\t\t\tpriv->ule_sndu_len = 0;\n\t\t\t\tpriv->need_pusi = 1;\n\t\t\t\tts += TS_SZ;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (! priv->ule_sndu_len) {\n\t\t\t\t/* Got at least two bytes, thus extrace the SNDU length. */\n\t\t\t\tpriv->ule_sndu_len = from_where[0] << 8 | from_where[1];\n\t\t\t\tif (priv->ule_sndu_len & 0x8000) {\n\t\t\t\t\t/* D-Bit is set: no dest mac present. */\n\t\t\t\t\tpriv->ule_sndu_len &= 0x7FFF;\n\t\t\t\t\tpriv->ule_dbit = 1;\n\t\t\t\t} else\n\t\t\t\t\tpriv->ule_dbit = 0;\n\n\t\t\t\tif (priv->ule_sndu_len < 5) {\n\t\t\t\t\tprintk(KERN_WARNING \"%lu: Invalid ULE SNDU length %u. \"\n\t\t\t\t\t       \"Resyncing.\\n\", priv->ts_count, priv->ule_sndu_len);\n\t\t\t\t\tdev->stats.rx_errors++;\n\t\t\t\t\tdev->stats.rx_length_errors++;\n\t\t\t\t\tpriv->ule_sndu_len = 0;\n\t\t\t\t\tpriv->need_pusi = 1;\n\t\t\t\t\tnew_ts = 1;\n\t\t\t\t\tts += TS_SZ;\n\t\t\t\t\tpriv->ts_count++;\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tts_remain -= 2;\t/* consume the 2 bytes SNDU length. */\n\t\t\t\tfrom_where += 2;\n\t\t\t}\n\n\t\t\t/*\n\t\t\t * State of current TS:\n\t\t\t *   ts_remain (remaining bytes in the current TS cell)\n\t\t\t *   0\tule_type is not available now, we need the next TS cell\n\t\t\t *   1\tthe first byte of the ule_type is present\n\t\t\t * >=2\tfull ULE header present, maybe some payload data as well.\n\t\t\t */\n\t\t\tswitch (ts_remain) {\n\t\t\t\tcase 1:\n\t\t\t\t\tpriv->ule_sndu_type = from_where[0] << 8;\n\t\t\t\t\tpriv->ule_sndu_type_1 = 1; /* first byte of ule_type is set. */\n\t\t\t\t\tts_remain -= 1; from_where += 1;\n\t\t\t\t\t/* Continue w/ next TS. */\n\t\t\t\tcase 0:\n\t\t\t\t\tnew_ts = 1;\n\t\t\t\t\tts += TS_SZ;\n\t\t\t\t\tpriv->ts_count++;\n\t\t\t\t\tcontinue;\n\n\t\t\t\tdefault: /* complete ULE header is present in current TS. */\n\t\t\t\t\t/* Extract ULE type field. */\n\t\t\t\t\tif (priv->ule_sndu_type_1) {\n\t\t\t\t\t\tpriv->ule_sndu_type |= from_where[0];\n\t\t\t\t\t\tfrom_where += 1; /* points to payload start. */\n\t\t\t\t\t\tts_remain -= 1;\n\t\t\t\t\t} else {\n\t\t\t\t\t\t/* Complete type is present in new TS. */\n\t\t\t\t\t\tpriv->ule_sndu_type = from_where[0] << 8 | from_where[1];\n\t\t\t\t\t\tfrom_where += 2; /* points to payload start. */\n\t\t\t\t\t\tts_remain -= 2;\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t/* Allocate the skb (decoder target buffer) with the correct size, as follows:\n\t\t\t * prepare for the largest case: bridged SNDU with MAC address (dbit = 0). */\n\t\t\tpriv->ule_skb = dev_alloc_skb( priv->ule_sndu_len + ETH_HLEN + ETH_ALEN );\n\t\t\tif (priv->ule_skb == NULL) {\n\t\t\t\tprintk(KERN_NOTICE \"%s: Memory squeeze, dropping packet.\\n\",\n\t\t\t\t       dev->name);\n\t\t\t\tdev->stats.rx_dropped++;\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\t/* This includes the CRC32 _and_ dest mac, if !dbit. */\n\t\t\tpriv->ule_sndu_remain = priv->ule_sndu_len;\n\t\t\tpriv->ule_skb->dev = dev;\n\t\t\t/* Leave space for Ethernet or bridged SNDU header (eth hdr plus one MAC addr). */\n\t\t\tskb_reserve( priv->ule_skb, ETH_HLEN + ETH_ALEN );\n\t\t}\n\n\t\t/* Copy data into our current skb. */\n\t\thow_much = min(priv->ule_sndu_remain, (int)ts_remain);\n\t\tmemcpy(skb_put(priv->ule_skb, how_much), from_where, how_much);\n\t\tpriv->ule_sndu_remain -= how_much;\n\t\tts_remain -= how_much;\n\t\tfrom_where += how_much;\n\n\t\t/* Check for complete payload. */\n\t\tif (priv->ule_sndu_remain <= 0) {\n\t\t\t/* Check CRC32, we've got it in our skb already. */\n\t\t\t__be16 ulen = htons(priv->ule_sndu_len);\n\t\t\t__be16 utype = htons(priv->ule_sndu_type);\n\t\t\tconst u8 *tail;\n\t\t\tstruct kvec iov[3] = {\n\t\t\t\t{ &ulen, sizeof ulen },\n\t\t\t\t{ &utype, sizeof utype },\n\t\t\t\t{ priv->ule_skb->data, priv->ule_skb->len - 4 }\n\t\t\t};\n\t\t\tu32 ule_crc = ~0L, expected_crc;\n\t\t\tif (priv->ule_dbit) {\n\t\t\t\t/* Set D-bit for CRC32 verification,\n\t\t\t\t * if it was set originally. */\n\t\t\t\tulen |= htons(0x8000);\n\t\t\t}\n\n\t\t\tule_crc = iov_crc32(ule_crc, iov, 3);\n\t\t\ttail = skb_tail_pointer(priv->ule_skb);\n\t\t\texpected_crc = *(tail - 4) << 24 |\n\t\t\t\t       *(tail - 3) << 16 |\n\t\t\t\t       *(tail - 2) << 8 |\n\t\t\t\t       *(tail - 1);\n\t\t\tif (ule_crc != expected_crc) {\n\t\t\t\tprintk(KERN_WARNING \"%lu: CRC32 check FAILED: %08x / %08x, SNDU len %d type %#x, ts_remain %d, next 2: %x.\\n\",\n\t\t\t\t       priv->ts_count, ule_crc, expected_crc, priv->ule_sndu_len, priv->ule_sndu_type, ts_remain, ts_remain > 2 ? *(unsigned short *)from_where : 0);\n\n#ifdef ULE_DEBUG\n\t\t\t\thexdump( iov[0].iov_base, iov[0].iov_len );\n\t\t\t\thexdump( iov[1].iov_base, iov[1].iov_len );\n\t\t\t\thexdump( iov[2].iov_base, iov[2].iov_len );\n\n\t\t\t\tif (ule_where == ule_hist) {\n\t\t\t\t\thexdump( &ule_hist[98*TS_SZ], TS_SZ );\n\t\t\t\t\thexdump( &ule_hist[99*TS_SZ], TS_SZ );\n\t\t\t\t} else if (ule_where == &ule_hist[TS_SZ]) {\n\t\t\t\t\thexdump( &ule_hist[99*TS_SZ], TS_SZ );\n\t\t\t\t\thexdump( ule_hist, TS_SZ );\n\t\t\t\t} else {\n\t\t\t\t\thexdump( ule_where - TS_SZ - TS_SZ, TS_SZ );\n\t\t\t\t\thexdump( ule_where - TS_SZ, TS_SZ );\n\t\t\t\t}\n\t\t\t\tule_dump = 1;\n#endif\n\n\t\t\t\tdev->stats.rx_errors++;\n\t\t\t\tdev->stats.rx_crc_errors++;\n\t\t\t\tdev_kfree_skb(priv->ule_skb);\n\t\t\t} else {\n\t\t\t\t/* CRC32 verified OK. */\n\t\t\t\tu8 dest_addr[ETH_ALEN];\n\t\t\t\tstatic const u8 bc_addr[ETH_ALEN] =\n\t\t\t\t\t{ [ 0 ... ETH_ALEN-1] = 0xff };\n\n\t\t\t\t/* CRC32 was OK. Remove it from skb. */\n\t\t\t\tpriv->ule_skb->tail -= 4;\n\t\t\t\tpriv->ule_skb->len -= 4;\n\n\t\t\t\tif (!priv->ule_dbit) {\n\t\t\t\t\t/*\n\t\t\t\t\t * The destination MAC address is the\n\t\t\t\t\t * next data in the skb.  It comes\n\t\t\t\t\t * before any extension headers.\n\t\t\t\t\t *\n\t\t\t\t\t * Check if the payload of this SNDU\n\t\t\t\t\t * should be passed up the stack.\n\t\t\t\t\t */\n\t\t\t\t\tregister int drop = 0;\n\t\t\t\t\tif (priv->rx_mode != RX_MODE_PROMISC) {\n\t\t\t\t\t\tif (priv->ule_skb->data[0] & 0x01) {\n\t\t\t\t\t\t\t/* multicast or broadcast */\n\t\t\t\t\t\t\tif (memcmp(priv->ule_skb->data, bc_addr, ETH_ALEN)) {\n\t\t\t\t\t\t\t\t/* multicast */\n\t\t\t\t\t\t\t\tif (priv->rx_mode == RX_MODE_MULTI) {\n\t\t\t\t\t\t\t\t\tint i;\n\t\t\t\t\t\t\t\t\tfor(i = 0; i < priv->multi_num && memcmp(priv->ule_skb->data, priv->multi_macs[i], ETH_ALEN); i++)\n\t\t\t\t\t\t\t\t\t\t;\n\t\t\t\t\t\t\t\t\tif (i == priv->multi_num)\n\t\t\t\t\t\t\t\t\t\tdrop = 1;\n\t\t\t\t\t\t\t\t} else if (priv->rx_mode != RX_MODE_ALL_MULTI)\n\t\t\t\t\t\t\t\t\tdrop = 1; /* no broadcast; */\n\t\t\t\t\t\t\t\t/* else: all multicast mode: accept all multicast packets */\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t/* else: broadcast */\n\t\t\t\t\t\t}\n\t\t\t\t\t\telse if (memcmp(priv->ule_skb->data, dev->dev_addr, ETH_ALEN))\n\t\t\t\t\t\t\tdrop = 1;\n\t\t\t\t\t\t/* else: destination address matches the MAC address of our receiver device */\n\t\t\t\t\t}\n\t\t\t\t\t/* else: promiscuous mode; pass everything up the stack */\n\n\t\t\t\t\tif (drop) {\n#ifdef ULE_DEBUG\n\t\t\t\t\t\tdprintk(\"Dropping SNDU: MAC destination address does not match: dest addr: \"MAC_ADDR_PRINTFMT\", dev addr: \"MAC_ADDR_PRINTFMT\"\\n\",\n\t\t\t\t\t\t\tMAX_ADDR_PRINTFMT_ARGS(priv->ule_skb->data), MAX_ADDR_PRINTFMT_ARGS(dev->dev_addr));\n#endif\n\t\t\t\t\t\tdev_kfree_skb(priv->ule_skb);\n\t\t\t\t\t\tgoto sndu_done;\n\t\t\t\t\t}\n\t\t\t\t\telse\n\t\t\t\t\t{\n\t\t\t\t\t\tskb_copy_from_linear_data(priv->ule_skb,\n\t\t\t\t\t\t\t      dest_addr,\n\t\t\t\t\t\t\t      ETH_ALEN);\n\t\t\t\t\t\tskb_pull(priv->ule_skb, ETH_ALEN);\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t/* Handle ULE Extension Headers. */\n\t\t\t\tif (priv->ule_sndu_type < 1536) {\n\t\t\t\t\t/* There is an extension header.  Handle it accordingly. */\n\t\t\t\t\tint l = handle_ule_extensions(priv);\n\t\t\t\t\tif (l < 0) {\n\t\t\t\t\t\t/* Mandatory extension header unknown or TEST SNDU.  Drop it. */\n\t\t\t\t\t\t// printk( KERN_WARNING \"Dropping SNDU, extension headers.\\n\" );\n\t\t\t\t\t\tdev_kfree_skb(priv->ule_skb);\n\t\t\t\t\t\tgoto sndu_done;\n\t\t\t\t\t}\n\t\t\t\t\tskb_pull(priv->ule_skb, l);\n\t\t\t\t}\n\n\t\t\t\t/*\n\t\t\t\t * Construct/assure correct ethernet header.\n\t\t\t\t * Note: in bridged mode (priv->ule_bridged !=\n\t\t\t\t * 0) we already have the (original) ethernet\n\t\t\t\t * header at the start of the payload (after\n\t\t\t\t * optional dest. address and any extension\n\t\t\t\t * headers).\n\t\t\t\t */\n\n\t\t\t\tif (!priv->ule_bridged) {\n\t\t\t\t\tskb_push(priv->ule_skb, ETH_HLEN);\n\t\t\t\t\tethh = (struct ethhdr *)priv->ule_skb->data;\n\t\t\t\t\tif (!priv->ule_dbit) {\n\t\t\t\t\t\t /* dest_addr buffer is only valid if priv->ule_dbit == 0 */\n\t\t\t\t\t\tmemcpy(ethh->h_dest, dest_addr, ETH_ALEN);\n\t\t\t\t\t\tmemset(ethh->h_source, 0, ETH_ALEN);\n\t\t\t\t\t}\n\t\t\t\t\telse /* zeroize source and dest */\n\t\t\t\t\t\tmemset( ethh, 0, ETH_ALEN*2 );\n\n\t\t\t\t\tethh->h_proto = htons(priv->ule_sndu_type);\n\t\t\t\t}\n\t\t\t\t/* else:  skb is in correct state; nothing to do. */\n\t\t\t\tpriv->ule_bridged = 0;\n\n\t\t\t\t/* Stuff into kernel's protocol stack. */\n\t\t\t\tpriv->ule_skb->protocol = dvb_net_eth_type_trans(priv->ule_skb, dev);\n\t\t\t\t/* If D-bit is set (i.e. destination MAC address not present),\n\t\t\t\t * receive the packet anyhow. */\n\t\t\t\t/* if (priv->ule_dbit && skb->pkt_type == PACKET_OTHERHOST)\n\t\t\t\t\tpriv->ule_skb->pkt_type = PACKET_HOST; */\n\t\t\t\tdev->stats.rx_packets++;\n\t\t\t\tdev->stats.rx_bytes += priv->ule_skb->len;\n\t\t\t\tnetif_rx(priv->ule_skb);\n\t\t\t}\n\t\t\tsndu_done:\n\t\t\t/* Prepare for next SNDU. */\n\t\t\treset_ule(priv);\n\t\t}\n\n\t\t/* More data in current TS (look at the bytes following the CRC32)? */\n\t\tif (ts_remain >= 2 && *((unsigned short *)from_where) != 0xFFFF) {\n\t\t\t/* Next ULE SNDU starts right there. */\n\t\t\tnew_ts = 0;\n\t\t\tpriv->ule_skb = NULL;\n\t\t\tpriv->ule_sndu_type_1 = 0;\n\t\t\tpriv->ule_sndu_len = 0;\n\t\t\t// printk(KERN_WARNING \"More data in current TS: [%#x %#x %#x %#x]\\n\",\n\t\t\t//\t*(from_where + 0), *(from_where + 1),\n\t\t\t//\t*(from_where + 2), *(from_where + 3));\n\t\t\t// printk(KERN_WARNING \"ts @ %p, stopped @ %p:\\n\", ts, from_where + 0);\n\t\t\t// hexdump(ts, 188);\n\t\t} else {\n\t\t\tnew_ts = 1;\n\t\t\tts += TS_SZ;\n\t\t\tpriv->ts_count++;\n\t\t\tif (priv->ule_skb == NULL) {\n\t\t\t\tpriv->need_pusi = 1;\n\t\t\t\tpriv->ule_sndu_type_1 = 0;\n\t\t\t\tpriv->ule_sndu_len = 0;\n\t\t\t}\n\t\t}\n\t}\t/* for all available TS cells */\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -159,6 +159,7 @@\n \t\t\t\t       \"bytes left in TS.  Resyncing.\\n\", ts_remain);\n \t\t\t\tpriv->ule_sndu_len = 0;\n \t\t\t\tpriv->need_pusi = 1;\n+\t\t\t\tts += TS_SZ;\n \t\t\t\tcontinue;\n \t\t\t}\n ",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t\t\t\tts += TS_SZ;"
            ]
        }
    },
    {
        "cve_id": "CVE-2010-1488",
        "func_name": "torvalds/linux/proc_oom_score",
        "description": "The proc_oom_score function in fs/proc/base.c in the Linux kernel before 2.6.34-rc4 uses inappropriate data structures during selection of a candidate for the OOM killer, which might allow local users to cause a denial of service via unspecified patterns of task creation.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=b95c35e76b29ba812e5dabdd91592e25ec640e93",
        "commit_title": "proc_oom_score(task) has a reference to task_struct, but that is all.",
        "commit_text": "If this task was already released before we take tasklist_lock  \t- we can't use task->group_leader, it points to nowhere  \t- it is not safe to call badness() even if this task is \t  ->group_leader, has_intersects_mems_allowed() assumes \t  it is safe to iterate over ->thread_group list.  \t- even worse, badness() can hit ->signal == NULL  Add the pid_alive() check to ensure __unhash_process() was not called.  Also, use \"task\" instead of task->group_leader. badness() should return the same result for any sub-thread. Currently this is not true, but this should be changed anyway.  Cc: stable@kernel.org ",
        "func_before": "static int proc_oom_score(struct task_struct *task, char *buffer)\n{\n\tunsigned long points;\n\tstruct timespec uptime;\n\n\tdo_posix_clock_monotonic_gettime(&uptime);\n\tread_lock(&tasklist_lock);\n\tpoints = badness(task->group_leader, uptime.tv_sec);\n\tread_unlock(&tasklist_lock);\n\treturn sprintf(buffer, \"%lu\\n\", points);\n}",
        "func": "static int proc_oom_score(struct task_struct *task, char *buffer)\n{\n\tunsigned long points = 0;\n\tstruct timespec uptime;\n\n\tdo_posix_clock_monotonic_gettime(&uptime);\n\tread_lock(&tasklist_lock);\n\tif (pid_alive(task))\n\t\tpoints = badness(task, uptime.tv_sec);\n\tread_unlock(&tasklist_lock);\n\treturn sprintf(buffer, \"%lu\\n\", points);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,11 +1,12 @@\n static int proc_oom_score(struct task_struct *task, char *buffer)\n {\n-\tunsigned long points;\n+\tunsigned long points = 0;\n \tstruct timespec uptime;\n \n \tdo_posix_clock_monotonic_gettime(&uptime);\n \tread_lock(&tasklist_lock);\n-\tpoints = badness(task->group_leader, uptime.tv_sec);\n+\tif (pid_alive(task))\n+\t\tpoints = badness(task, uptime.tv_sec);\n \tread_unlock(&tasklist_lock);\n \treturn sprintf(buffer, \"%lu\\n\", points);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tunsigned long points;",
                "\tpoints = badness(task->group_leader, uptime.tv_sec);"
            ],
            "added_lines": [
                "\tunsigned long points = 0;",
                "\tif (pid_alive(task))",
                "\t\tpoints = badness(task, uptime.tv_sec);"
            ]
        }
    },
    {
        "cve_id": "CVE-2010-3477",
        "func_name": "kernel/git/netdev/net/tcf_act_police_dump",
        "description": "The tcf_act_police_dump function in net/sched/act_police.c in the actions implementation in the network queueing functionality in the Linux kernel before 2.6.36-rc4 does not properly initialize certain structure members, which allows local users to obtain potentially sensitive information from kernel memory via vectors involving a dump operation.  NOTE: this vulnerability exists because of an incomplete fix for CVE-2010-2942.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/davem/net.git;a=commit;h=0f04cfd098fb81fded74e78ea1a1b86cc6c6c31e",
        "commit_title": "While reviewing commit 1c40be12f7d8ca1d387510d39787b12e512a7ce8, I",
        "commit_text": " audited other users of tc_action_ops->dump for information leaks.   That commit covered almost all of them but act_police still had a leak.   opt.limit and opt.capab aren't zeroed out before the structure is  passed out.   This patch uses the C99 initializers to zero everything unused out.  ",
        "func_before": "static int\ntcf_act_police_dump(struct sk_buff *skb, struct tc_action *a, int bind, int ref)\n{\n\tunsigned char *b = skb_tail_pointer(skb);\n\tstruct tcf_police *police = a->priv;\n\tstruct tc_police opt;\n\n\topt.index = police->tcf_index;\n\topt.action = police->tcf_action;\n\topt.mtu = police->tcfp_mtu;\n\topt.burst = police->tcfp_burst;\n\topt.refcnt = police->tcf_refcnt - ref;\n\topt.bindcnt = police->tcf_bindcnt - bind;\n\tif (police->tcfp_R_tab)\n\t\topt.rate = police->tcfp_R_tab->rate;\n\telse\n\t\tmemset(&opt.rate, 0, sizeof(opt.rate));\n\tif (police->tcfp_P_tab)\n\t\topt.peakrate = police->tcfp_P_tab->rate;\n\telse\n\t\tmemset(&opt.peakrate, 0, sizeof(opt.peakrate));\n\tNLA_PUT(skb, TCA_POLICE_TBF, sizeof(opt), &opt);\n\tif (police->tcfp_result)\n\t\tNLA_PUT_U32(skb, TCA_POLICE_RESULT, police->tcfp_result);\n\tif (police->tcfp_ewma_rate)\n\t\tNLA_PUT_U32(skb, TCA_POLICE_AVRATE, police->tcfp_ewma_rate);\n\treturn skb->len;\n\nnla_put_failure:\n\tnlmsg_trim(skb, b);\n\treturn -1;\n}",
        "func": "static int\ntcf_act_police_dump(struct sk_buff *skb, struct tc_action *a, int bind, int ref)\n{\n\tunsigned char *b = skb_tail_pointer(skb);\n\tstruct tcf_police *police = a->priv;\n\tstruct tc_police opt = {\n\t\t.index = police->tcf_index,\n\t\t.action = police->tcf_action,\n\t\t.mtu = police->tcfp_mtu,\n\t\t.burst = police->tcfp_burst,\n\t\t.refcnt = police->tcf_refcnt - ref,\n\t\t.bindcnt = police->tcf_bindcnt - bind,\n\t};\n\n\tif (police->tcfp_R_tab)\n\t\topt.rate = police->tcfp_R_tab->rate;\n\tif (police->tcfp_P_tab)\n\t\topt.peakrate = police->tcfp_P_tab->rate;\n\tNLA_PUT(skb, TCA_POLICE_TBF, sizeof(opt), &opt);\n\tif (police->tcfp_result)\n\t\tNLA_PUT_U32(skb, TCA_POLICE_RESULT, police->tcfp_result);\n\tif (police->tcfp_ewma_rate)\n\t\tNLA_PUT_U32(skb, TCA_POLICE_AVRATE, police->tcfp_ewma_rate);\n\treturn skb->len;\n\nnla_put_failure:\n\tnlmsg_trim(skb, b);\n\treturn -1;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,22 +3,19 @@\n {\n \tunsigned char *b = skb_tail_pointer(skb);\n \tstruct tcf_police *police = a->priv;\n-\tstruct tc_police opt;\n+\tstruct tc_police opt = {\n+\t\t.index = police->tcf_index,\n+\t\t.action = police->tcf_action,\n+\t\t.mtu = police->tcfp_mtu,\n+\t\t.burst = police->tcfp_burst,\n+\t\t.refcnt = police->tcf_refcnt - ref,\n+\t\t.bindcnt = police->tcf_bindcnt - bind,\n+\t};\n \n-\topt.index = police->tcf_index;\n-\topt.action = police->tcf_action;\n-\topt.mtu = police->tcfp_mtu;\n-\topt.burst = police->tcfp_burst;\n-\topt.refcnt = police->tcf_refcnt - ref;\n-\topt.bindcnt = police->tcf_bindcnt - bind;\n \tif (police->tcfp_R_tab)\n \t\topt.rate = police->tcfp_R_tab->rate;\n-\telse\n-\t\tmemset(&opt.rate, 0, sizeof(opt.rate));\n \tif (police->tcfp_P_tab)\n \t\topt.peakrate = police->tcfp_P_tab->rate;\n-\telse\n-\t\tmemset(&opt.peakrate, 0, sizeof(opt.peakrate));\n \tNLA_PUT(skb, TCA_POLICE_TBF, sizeof(opt), &opt);\n \tif (police->tcfp_result)\n \t\tNLA_PUT_U32(skb, TCA_POLICE_RESULT, police->tcfp_result);",
        "diff_line_info": {
            "deleted_lines": [
                "\tstruct tc_police opt;",
                "\topt.index = police->tcf_index;",
                "\topt.action = police->tcf_action;",
                "\topt.mtu = police->tcfp_mtu;",
                "\topt.burst = police->tcfp_burst;",
                "\topt.refcnt = police->tcf_refcnt - ref;",
                "\topt.bindcnt = police->tcf_bindcnt - bind;",
                "\telse",
                "\t\tmemset(&opt.rate, 0, sizeof(opt.rate));",
                "\telse",
                "\t\tmemset(&opt.peakrate, 0, sizeof(opt.peakrate));"
            ],
            "added_lines": [
                "\tstruct tc_police opt = {",
                "\t\t.index = police->tcf_index,",
                "\t\t.action = police->tcf_action,",
                "\t\t.mtu = police->tcfp_mtu,",
                "\t\t.burst = police->tcfp_burst,",
                "\t\t.refcnt = police->tcf_refcnt - ref,",
                "\t\t.bindcnt = police->tcf_bindcnt - bind,",
                "\t};"
            ]
        }
    },
    {
        "cve_id": "CVE-2010-3696",
        "func_name": "alandekok/freeradius-server/fr_dhcp_decode",
        "description": "The fr_dhcp_decode function in lib/dhcp.c in FreeRADIUS 2.1.9, in certain non-default builds, does not properly handle the DHCP Relay Agent Information option, which allows remote attackers to cause a denial of service (infinite loop and daemon outage) via a packet that has more than one sub-option.  NOTE: some of these details are obtained from third party information.",
        "git_url": "https://github.com/alandekok/freeradius-server/commit/4dc7800b866f889a1247685bbaa6dd4238a56279",
        "commit_title": "Fix endless loop when there are multiple DHCP options",
        "commit_text": "",
        "func_before": "int fr_dhcp_decode(RADIUS_PACKET *packet)\n{\n\tint i;\n\tuint8_t *p, *next;\n\tuint32_t giaddr;\n\tVALUE_PAIR *head, *vp, **tail;\n\tVALUE_PAIR *maxms, *mtu;\n\tchar buffer[2048];\n\n\thead = NULL;\n\ttail = &head;\n\tp = packet->data;\n\t\n\tif ((fr_debug_flag > 2) && fr_log_fp) {\n\t\tfor (i = 0; i < packet->data_len; i++) {\n\t\t\tif ((i & 0x0f) == 0x00) fr_strerror_printf(\"%d: \", i);\n\t\t\tfprintf(fr_log_fp, \"%02x \", packet->data[i]);\n\t\t\tif ((i & 0x0f) == 0x0f) fprintf(fr_log_fp, \"\\n\");\n\t\t}\n\t\tfprintf(fr_log_fp, \"\\n\");\n\t}\n\n\tif (packet->data[1] != 1) {\n\t\tfr_strerror_printf(\"Packet is not Ethernet: %u\",\n\t\t      packet->data[1]);\n\t\treturn -1;\n\t}\n\n\t/*\n\t *\tDecode the header.\n\t */\n\tfor (i = 0; i < 14; i++) {\n\t\tvp = pairmake(dhcp_header_names[i], NULL, T_OP_EQ);\n\t\tif (!vp) {\n\t\t\tfr_strerror_printf(\"Parse error %s\", fr_strerror());\n\t\t\tpairfree(&head);\n\t\t\treturn -1;\n\t\t}\n\n\t\tif ((i == 11) && \n\t\t    (packet->data[1] == 1) &&\n\t\t    (packet->data[2] == 6)) {\n\t\t\tvp->type = PW_TYPE_ETHERNET;\n\t\t}\n\n\t\tswitch (vp->type) {\n\t\tcase PW_TYPE_BYTE:\n\t\t\tvp->vp_integer = p[0];\n\t\t\tvp->length = 1;\n\t\t\tbreak;\n\t\t\t\n\t\tcase PW_TYPE_SHORT:\n\t\t\tvp->vp_integer = (p[0] << 8) | p[1];\n\t\t\tvp->length = 2;\n\t\t\tbreak;\n\t\t\t\n\t\tcase PW_TYPE_INTEGER:\n\t\t\tmemcpy(&vp->vp_integer, p, 4);\n\t\t\tvp->vp_integer = ntohl(vp->vp_integer);\n\t\t\tvp->length = 4;\n\t\t\tbreak;\n\t\t\t\n\t\tcase PW_TYPE_IPADDR:\n\t\t\tmemcpy(&vp->vp_ipaddr, p, 4);\n\t\t\tvp->length = 4;\n\t\t\tbreak;\n\t\t\t\n\t\tcase PW_TYPE_STRING:\n\t\t\tmemcpy(vp->vp_strvalue, p, dhcp_header_sizes[i]);\n\t\t\tvp->vp_strvalue[dhcp_header_sizes[i]] = '\\0';\n\t\t\tvp->length = strlen(vp->vp_strvalue);\n\t\t\tif (vp->length == 0) {\n\t\t\t\tpairfree(&vp);\n\t\t\t}\n\t\t\tbreak;\n\t\t\t\n\t\tcase PW_TYPE_OCTETS:\n\t\t\tmemcpy(vp->vp_octets, p, packet->data[2]);\n\t\t\tvp->length = packet->data[2];\n\t\t\tbreak;\n\t\t\t\n\t\tcase PW_TYPE_ETHERNET:\n\t\t\tmemcpy(vp->vp_ether, p, sizeof(vp->vp_ether));\n\t\t\tvp->length = sizeof(vp->vp_ether);\n\t\t\tbreak;\n\t\t\t\n\t\tdefault:\n\t\t\tfr_strerror_printf(\"BAD TYPE %d\", vp->type);\n\t\t\tpairfree(&vp);\n\t\t\tbreak;\n\t\t}\n\t\tp += dhcp_header_sizes[i];\n\n\t\tif (!vp) continue;\n\t\t\n\t\tif (fr_debug_flag > 1) {\n\t\t\tvp_prints(buffer, sizeof(buffer), vp);\n\t\t\tfr_strerror_printf(\"\\t%s\", buffer);\n\t\t}\n\t\t*tail = vp;\n\t\ttail = &vp->next;\n\t}\n\t\n\t/*\n\t *\tLoop over the options.\n\t */\n\tnext = packet->data + 240;\n\n\t/*\n\t *\tFIXME: This should also check sname && file fields.\n\t *\tSee the dhcp_get_option() function above.\n\t */\n\twhile (next < (packet->data + packet->data_len)) {\n\t\tint num_entries, alen;\n\t\tDICT_ATTR *da;\n\t\t\n\t\tp = next;\n\n\t\tif (*p == 0) break;\n\t\tif (*p == 255) break; /* end of options signifier */\n\t\tif ((p + 2) > (packet->data + packet->data_len)) break;\n\n\t\tnext = p + 2 + p[1];\n\n\t\tif (p[1] >= 253) {\n\t\t\tfr_strerror_printf(\"Attribute too long %u %u\",\n\t\t\t      p[0], p[1]);\n\t\t\tcontinue;\n\t\t}\n\t\t\t\t\n\t\tda = dict_attrbyvalue(DHCP2ATTR(p[0]));\n\t\tif (!da) {\n\t\t\tfr_strerror_printf(\"Attribute not in our dictionary: %u\",\n\t\t\t      p[0]);\n\t\t\tcontinue;\n\t\t}\n\n\t\tvp = NULL;\n\t\tnum_entries = 1;\n\t\talen = p[1];\n\t\tp += 2;\n\n\t\t/*\n\t\t *\tCould be an array of bytes, integers, etc.\n\t\t */\n\t\tif (da->flags.array) {\n\t\t\tswitch (da->type) {\n\t\t\tcase PW_TYPE_BYTE:\n\t\t\t\tnum_entries = alen;\n\t\t\t\talen = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase PW_TYPE_SHORT: /* ignore any trailing data */\n\t\t\t\tnum_entries = alen >> 1;\n\t\t\t\talen = 2;\n\t\t\t\tbreak;\n\n\t\t\tcase PW_TYPE_IPADDR:\n\t\t\tcase PW_TYPE_INTEGER:\n\t\t\tcase PW_TYPE_DATE: /* ignore any trailing data */\n\t\t\t\tnum_entries = alen >> 2;\n\t\t\t\talen = 4;\n\t\t\t\tbreak;\n\n\t\t\tdefault:\n\n\t\t\t\tbreak; /* really an internal sanity failure */\n\t\t\t}\n\t\t}\n\n\t\t/*\n\t\t *\tLoop over all of the entries, building VPs\n\t\t */\n\t\tfor (i = 0; i < num_entries; i++) {\n\t\t\tvp = pairmake(da->name, NULL, T_OP_EQ);\n\t\t\tif (!vp) {\n\t\t\t\tfr_strerror_printf(\"Cannot build attribute %s\",\n\t\t\t\t\tfr_strerror());\n\t\t\t\tpairfree(&head);\n\t\t\t\treturn -1;\n\t\t\t}\n\n\t\t\t/*\n\t\t\t *\tHack for ease of use.\n\t\t\t */\n\t\t\tif ((da->attr == DHCP2ATTR(0x3d)) &&\n\t\t\t    !da->flags.array &&\n\t\t\t    (alen == 7) && (*p == 1) && (num_entries == 1)) {\n\t\t\t\tvp->type = PW_TYPE_ETHERNET;\n\t\t\t\tmemcpy(vp->vp_octets, p + 1, 6);\n\t\t\t\tvp->length = alen;\n\n\t\t\t} else if (fr_dhcp_attr2vp(vp, p, alen) < 0) {\n\t\t\t\t\tpairfree(&vp);\n\t\t\t\t\tpairfree(&head);\n\t\t\t\t\treturn -1;\n\t\t\t}\n\n\t\t\tif (fr_debug_flag > 1) {\n\t\t\t\tvp_prints(buffer, sizeof(buffer), vp);\n\t\t\t\tfr_strerror_printf(\"\\t%s\", buffer);\n\t\t\t}\n\n\t\t\t*tail = vp;\n\t\t\twhile (*tail) tail = &vp->next;\n\t\t\tp += alen;\n\t\t} /* loop over array entries */\n\t} /* loop over the entire packet */\n\n\t/*\n\t *\tIf DHCP request, set ciaddr to zero.\n\t */\n\n\t/*\n\t *\tSet broadcast flag for broken vendors, but only if\n\t *\tgiaddr isn't set.\n\t */\n\tmemcpy(&giaddr, packet->data + 24, sizeof(giaddr));\n\tif (giaddr == htonl(INADDR_ANY)) {\n\t\t/*\n\t\t *\tDHCP Opcode is request\n\t\t */\n\t\tvp = pairfind(head, DHCP2ATTR(256));\n\t\tif (vp && vp->lvalue == 3) {\n\t\t\t/*\n\t\t\t *\tVendor is \"MSFT 98\"\n\t\t\t */\n\t\t\tvp = pairfind(head, DHCP2ATTR(63));\n\t\t\tif (vp && (strcmp(vp->vp_strvalue, \"MSFT 98\") == 0)) {\n\t\t\t\tvp = pairfind(head, DHCP2ATTR(262));\n\n\t\t\t\t/*\n\t\t\t\t *\tReply should be broadcast.\n\t\t\t\t */\n\t\t\t\tif (vp) vp->lvalue |= 0x8000;\n\t\t\t\tpacket->data[10] |= 0x80;\t\t\t\n\t\t\t}\n\t\t}\n\t}\n\n\t/*\n\t *\tFIXME: Nuke attributes that aren't used in the normal\n\t *\theader for discover/requests.\n\t */\n\tpacket->vps = head;\n\n\t/*\n\t *\tClient can request a LARGER size, but not a smaller\n\t *\tone.  They also cannot request a size larger than MTU.\n\t */\n\tmaxms = pairfind(packet->vps, DHCP2ATTR(57));\n\tmtu = pairfind(packet->vps, DHCP2ATTR(26));\n\n\tif (mtu && (mtu->vp_integer < DEFAULT_PACKET_SIZE)) {\n\t\tfr_strerror_printf(\"DHCP Fatal: Client says MTU is smaller than minimum permitted by the specification.\");\n\t\treturn -1;\n\t}\n\n\tif (maxms && (maxms->vp_integer < DEFAULT_PACKET_SIZE)) {\n\t\tfr_strerror_printf(\"DHCP WARNING: Client says maximum message size is smaller than minimum permitted by the specification: fixing it\");\n\t\tmaxms->vp_integer = DEFAULT_PACKET_SIZE;\n\t}\n\n\tif (maxms && mtu && (maxms->vp_integer > mtu->vp_integer)) {\n\t\tfr_strerror_printf(\"DHCP WARNING: Client says MTU is smaller than maximum message size: fixing it\");\n\t\tmaxms->vp_integer = mtu->vp_integer;\n\t}\n\n\tif (fr_debug_flag) fflush(stdout);\n\n\treturn 0;\n}",
        "func": "int fr_dhcp_decode(RADIUS_PACKET *packet)\n{\n\tint i;\n\tuint8_t *p, *next;\n\tuint32_t giaddr;\n\tVALUE_PAIR *head, *vp, **tail;\n\tVALUE_PAIR *maxms, *mtu;\n\tchar buffer[2048];\n\n\thead = NULL;\n\ttail = &head;\n\tp = packet->data;\n\t\n\tif ((fr_debug_flag > 2) && fr_log_fp) {\n\t\tfor (i = 0; i < packet->data_len; i++) {\n\t\t\tif ((i & 0x0f) == 0x00) fr_strerror_printf(\"%d: \", i);\n\t\t\tfprintf(fr_log_fp, \"%02x \", packet->data[i]);\n\t\t\tif ((i & 0x0f) == 0x0f) fprintf(fr_log_fp, \"\\n\");\n\t\t}\n\t\tfprintf(fr_log_fp, \"\\n\");\n\t}\n\n\tif (packet->data[1] != 1) {\n\t\tfr_strerror_printf(\"Packet is not Ethernet: %u\",\n\t\t      packet->data[1]);\n\t\treturn -1;\n\t}\n\n\t/*\n\t *\tDecode the header.\n\t */\n\tfor (i = 0; i < 14; i++) {\n\t\tvp = pairmake(dhcp_header_names[i], NULL, T_OP_EQ);\n\t\tif (!vp) {\n\t\t\tfr_strerror_printf(\"Parse error %s\", fr_strerror());\n\t\t\tpairfree(&head);\n\t\t\treturn -1;\n\t\t}\n\n\t\tif ((i == 11) && \n\t\t    (packet->data[1] == 1) &&\n\t\t    (packet->data[2] == 6)) {\n\t\t\tvp->type = PW_TYPE_ETHERNET;\n\t\t}\n\n\t\tswitch (vp->type) {\n\t\tcase PW_TYPE_BYTE:\n\t\t\tvp->vp_integer = p[0];\n\t\t\tvp->length = 1;\n\t\t\tbreak;\n\t\t\t\n\t\tcase PW_TYPE_SHORT:\n\t\t\tvp->vp_integer = (p[0] << 8) | p[1];\n\t\t\tvp->length = 2;\n\t\t\tbreak;\n\t\t\t\n\t\tcase PW_TYPE_INTEGER:\n\t\t\tmemcpy(&vp->vp_integer, p, 4);\n\t\t\tvp->vp_integer = ntohl(vp->vp_integer);\n\t\t\tvp->length = 4;\n\t\t\tbreak;\n\t\t\t\n\t\tcase PW_TYPE_IPADDR:\n\t\t\tmemcpy(&vp->vp_ipaddr, p, 4);\n\t\t\tvp->length = 4;\n\t\t\tbreak;\n\t\t\t\n\t\tcase PW_TYPE_STRING:\n\t\t\tmemcpy(vp->vp_strvalue, p, dhcp_header_sizes[i]);\n\t\t\tvp->vp_strvalue[dhcp_header_sizes[i]] = '\\0';\n\t\t\tvp->length = strlen(vp->vp_strvalue);\n\t\t\tif (vp->length == 0) {\n\t\t\t\tpairfree(&vp);\n\t\t\t}\n\t\t\tbreak;\n\t\t\t\n\t\tcase PW_TYPE_OCTETS:\n\t\t\tmemcpy(vp->vp_octets, p, packet->data[2]);\n\t\t\tvp->length = packet->data[2];\n\t\t\tbreak;\n\t\t\t\n\t\tcase PW_TYPE_ETHERNET:\n\t\t\tmemcpy(vp->vp_ether, p, sizeof(vp->vp_ether));\n\t\t\tvp->length = sizeof(vp->vp_ether);\n\t\t\tbreak;\n\t\t\t\n\t\tdefault:\n\t\t\tfr_strerror_printf(\"BAD TYPE %d\", vp->type);\n\t\t\tpairfree(&vp);\n\t\t\tbreak;\n\t\t}\n\t\tp += dhcp_header_sizes[i];\n\n\t\tif (!vp) continue;\n\t\t\n\t\tif (fr_debug_flag > 1) {\n\t\t\tvp_prints(buffer, sizeof(buffer), vp);\n\t\t\tfr_strerror_printf(\"\\t%s\", buffer);\n\t\t}\n\t\t*tail = vp;\n\t\ttail = &vp->next;\n\t}\n\t\n\t/*\n\t *\tLoop over the options.\n\t */\n\tnext = packet->data + 240;\n\n\t/*\n\t *\tFIXME: This should also check sname && file fields.\n\t *\tSee the dhcp_get_option() function above.\n\t */\n\twhile (next < (packet->data + packet->data_len)) {\n\t\tint num_entries, alen;\n\t\tDICT_ATTR *da;\n\t\t\n\t\tp = next;\n\n\t\tif (*p == 0) break;\n\t\tif (*p == 255) break; /* end of options signifier */\n\t\tif ((p + 2) > (packet->data + packet->data_len)) break;\n\n\t\tnext = p + 2 + p[1];\n\n\t\tif (p[1] >= 253) {\n\t\t\tfr_strerror_printf(\"Attribute too long %u %u\",\n\t\t\t      p[0], p[1]);\n\t\t\tcontinue;\n\t\t}\n\t\t\t\t\n\t\tda = dict_attrbyvalue(DHCP2ATTR(p[0]));\n\t\tif (!da) {\n\t\t\tfr_strerror_printf(\"Attribute not in our dictionary: %u\",\n\t\t\t      p[0]);\n\t\t\tcontinue;\n\t\t}\n\n\t\tvp = NULL;\n\t\tnum_entries = 1;\n\t\talen = p[1];\n\t\tp += 2;\n\n\t\t/*\n\t\t *\tCould be an array of bytes, integers, etc.\n\t\t */\n\t\tif (da->flags.array) {\n\t\t\tswitch (da->type) {\n\t\t\tcase PW_TYPE_BYTE:\n\t\t\t\tnum_entries = alen;\n\t\t\t\talen = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase PW_TYPE_SHORT: /* ignore any trailing data */\n\t\t\t\tnum_entries = alen >> 1;\n\t\t\t\talen = 2;\n\t\t\t\tbreak;\n\n\t\t\tcase PW_TYPE_IPADDR:\n\t\t\tcase PW_TYPE_INTEGER:\n\t\t\tcase PW_TYPE_DATE: /* ignore any trailing data */\n\t\t\t\tnum_entries = alen >> 2;\n\t\t\t\talen = 4;\n\t\t\t\tbreak;\n\n\t\t\tdefault:\n\n\t\t\t\tbreak; /* really an internal sanity failure */\n\t\t\t}\n\t\t}\n\n\t\t/*\n\t\t *\tLoop over all of the entries, building VPs\n\t\t */\n\t\tfor (i = 0; i < num_entries; i++) {\n\t\t\tvp = pairmake(da->name, NULL, T_OP_EQ);\n\t\t\tif (!vp) {\n\t\t\t\tfr_strerror_printf(\"Cannot build attribute %s\",\n\t\t\t\t\tfr_strerror());\n\t\t\t\tpairfree(&head);\n\t\t\t\treturn -1;\n\t\t\t}\n\n\t\t\t/*\n\t\t\t *\tHack for ease of use.\n\t\t\t */\n\t\t\tif ((da->attr == DHCP2ATTR(0x3d)) &&\n\t\t\t    !da->flags.array &&\n\t\t\t    (alen == 7) && (*p == 1) && (num_entries == 1)) {\n\t\t\t\tvp->type = PW_TYPE_ETHERNET;\n\t\t\t\tmemcpy(vp->vp_octets, p + 1, 6);\n\t\t\t\tvp->length = alen;\n\n\t\t\t} else if (fr_dhcp_attr2vp(vp, p, alen) < 0) {\n\t\t\t\t\tpairfree(&vp);\n\t\t\t\t\tpairfree(&head);\n\t\t\t\t\treturn -1;\n\t\t\t}\n\n\t\t\tif (fr_debug_flag > 1) {\n\t\t\t\tvp_prints(buffer, sizeof(buffer), vp);\n\t\t\t\tfr_strerror_printf(\"\\t%s\", buffer);\n\t\t\t}\n\n\t\t\t*tail = vp;\n\t\t\twhile (*tail) tail = &(*tail)->next;\n\t\t\tp += alen;\n\t\t} /* loop over array entries */\n\t} /* loop over the entire packet */\n\n\t/*\n\t *\tIf DHCP request, set ciaddr to zero.\n\t */\n\n\t/*\n\t *\tSet broadcast flag for broken vendors, but only if\n\t *\tgiaddr isn't set.\n\t */\n\tmemcpy(&giaddr, packet->data + 24, sizeof(giaddr));\n\tif (giaddr == htonl(INADDR_ANY)) {\n\t\t/*\n\t\t *\tDHCP Opcode is request\n\t\t */\n\t\tvp = pairfind(head, DHCP2ATTR(256));\n\t\tif (vp && vp->lvalue == 3) {\n\t\t\t/*\n\t\t\t *\tVendor is \"MSFT 98\"\n\t\t\t */\n\t\t\tvp = pairfind(head, DHCP2ATTR(63));\n\t\t\tif (vp && (strcmp(vp->vp_strvalue, \"MSFT 98\") == 0)) {\n\t\t\t\tvp = pairfind(head, DHCP2ATTR(262));\n\n\t\t\t\t/*\n\t\t\t\t *\tReply should be broadcast.\n\t\t\t\t */\n\t\t\t\tif (vp) vp->lvalue |= 0x8000;\n\t\t\t\tpacket->data[10] |= 0x80;\t\t\t\n\t\t\t}\n\t\t}\n\t}\n\n\t/*\n\t *\tFIXME: Nuke attributes that aren't used in the normal\n\t *\theader for discover/requests.\n\t */\n\tpacket->vps = head;\n\n\t/*\n\t *\tClient can request a LARGER size, but not a smaller\n\t *\tone.  They also cannot request a size larger than MTU.\n\t */\n\tmaxms = pairfind(packet->vps, DHCP2ATTR(57));\n\tmtu = pairfind(packet->vps, DHCP2ATTR(26));\n\n\tif (mtu && (mtu->vp_integer < DEFAULT_PACKET_SIZE)) {\n\t\tfr_strerror_printf(\"DHCP Fatal: Client says MTU is smaller than minimum permitted by the specification.\");\n\t\treturn -1;\n\t}\n\n\tif (maxms && (maxms->vp_integer < DEFAULT_PACKET_SIZE)) {\n\t\tfr_strerror_printf(\"DHCP WARNING: Client says maximum message size is smaller than minimum permitted by the specification: fixing it\");\n\t\tmaxms->vp_integer = DEFAULT_PACKET_SIZE;\n\t}\n\n\tif (maxms && mtu && (maxms->vp_integer > mtu->vp_integer)) {\n\t\tfr_strerror_printf(\"DHCP WARNING: Client says MTU is smaller than maximum message size: fixing it\");\n\t\tmaxms->vp_integer = mtu->vp_integer;\n\t}\n\n\tif (fr_debug_flag) fflush(stdout);\n\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -202,7 +202,7 @@\n \t\t\t}\n \n \t\t\t*tail = vp;\n-\t\t\twhile (*tail) tail = &vp->next;\n+\t\t\twhile (*tail) tail = &(*tail)->next;\n \t\t\tp += alen;\n \t\t} /* loop over array entries */\n \t} /* loop over the entire packet */",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\twhile (*tail) tail = &vp->next;"
            ],
            "added_lines": [
                "\t\t\twhile (*tail) tail = &(*tail)->next;"
            ]
        }
    },
    {
        "cve_id": "CVE-2010-3697",
        "func_name": "alandekok/freeradius-server/wait_a_bit",
        "description": "The wait_for_child_to_die function in main/event.c in FreeRADIUS 2.1.x before 2.1.10, in certain circumstances involving long-term database outages, does not properly handle long queue times for requests, which allows remote attackers to cause a denial of service (daemon crash) by sending many requests.",
        "git_url": "https://github.com/alandekok/freeradius-server/commit/ff94dd35673bba1476594299d31ce8293b8bd223",
        "commit_title": "Do not delete \"old\" requests until they are free.",
        "commit_text": " If the request is in the queue for 30+ seconds, do NOT delete it. Instead, mark it as \"STOP PROCESSING\", and do \"wait_for_child_to_die\", which waits for a child thread to pick it up, and acknowledge that it's done.  Once it's marked done, we can finally clean it up.  This may be the underlying issue behind bug #35",
        "func_before": "static void wait_a_bit(void *ctx)\n{\n\tstruct timeval when;\n\tREQUEST *request = ctx;\n\tfr_event_callback_t callback = NULL;\n\n\trad_assert(request->magic == REQUEST_MAGIC);\n\n#ifdef WITH_COA\n\t/*\n\t *\tThe CoA request is a new (internally generated)\n\t *\trequest, created in a child thread.  We therefore need\n\t *\tsome way to tie its events back into the main event\n\t *\thandler.\n\t */\n\tif (request->coa && !request->coa->proxy_reply &&\n\t    request->coa->next_callback) {\n\t\trequest->coa->when = request->coa->next_when;\n\t\tINSERT_EVENT(request->coa->next_callback, request->coa);\n\t\trequest->coa->next_callback = NULL;\n\t\trequest->coa->parent = NULL;\n\t\trequest->coa = NULL;\n\t}\n#endif\n\n\tswitch (request->child_state) {\n\tcase REQUEST_QUEUED:\n\tcase REQUEST_RUNNING:\n\t\twhen = request->received;\n\t\twhen.tv_sec += request->root->max_request_time;\n\n\t\t/*\n\t\t *\tNormally called from the event loop with the\n\t\t *\tproper event loop time.  Otherwise, called from\n\t\t *\tpost proxy fail handler, which sets \"now\", and\n\t\t *\tthis call won't re-set it, because we're not\n\t\t *\tin the event loop.\n\t\t */\n\t\tfr_event_now(el, &now);\n\n\t\t/*\n\t\t *\tRequest still has more time.  Continue\n\t\t *\twaiting.\n\t\t */\n\t\tif (timercmp(&now, &when, <) ||\n\t\t    ((request->listener->type == RAD_LISTEN_DETAIL) &&\n\t\t     (request->child_state == REQUEST_QUEUED))) {\n\t\t\tif (request->delay < (USEC / 10)) {\n\t\t\t\trequest->delay = USEC / 10;\n\t\t\t}\n\t\t\trequest->delay += request->delay >> 1;\n\n#ifdef WITH_DETAIL\n\t\t\t/*\n\t\t\t *\tCap wait at some sane value for detail\n\t\t\t *\tfiles.\n\t\t\t */\n\t\t\tif ((request->listener->type == RAD_LISTEN_DETAIL) &&\n\t\t\t    (request->delay > (request->root->max_request_time * USEC))) {\n\t\t\t\trequest->delay = request->root->max_request_time * USEC;\n\t\t\t}\n#endif\n\n\t\t\trequest->when = now;\n\t\t\ttv_add(&request->when, request->delay);\n\t\t\tcallback = wait_a_bit;\n\t\t\tbreak;\n\t\t}\n\n#if defined(HAVE_PTHREAD_H)\n\t\t/*\n\t\t *\tA child thread MAY still be running on the\n\t\t *\trequest.  Ask the thread to stop working on\n\t\t *\tthe request.\n\t\t */\n\t\tif (have_children &&\n\t\t    (pthread_equal(request->child_pid, NO_SUCH_CHILD_PID) == 0)) {\n\t\t\trequest->master_state = REQUEST_STOP_PROCESSING;\n\n\t\t\tradlog(L_ERR, \"WARNING: Unresponsive child for request %u, in module %s component %s\",\n\t\t\t       request->number,\n\t\t\t       request->module ? request->module : \"<server core>\",\n\t\t\t       request->component ? request->component : \"<server core>\");\n\t\t\t\n\t\t\trequest->delay = USEC / 4;\n\t\t\ttv_add(&request->when, request->delay);\n\t\t\tcallback = wait_for_child_to_die;\n\t\t\tbreak;\n\t\t}\n#endif\n\n\t\t/*\n\t\t *\tElse no child thread is processing the\n\t\t *\trequest.  We probably should have just marked\n\t\t *\tthe request as 'done' elsewhere, like in the\n\t\t *\tpost-proxy-fail handler.  But doing that would\n\t\t *\tinvolve checking for max_request_time in\n\t\t *\tmultiple places, so this may be simplest.\n\t\t */\n\t\trequest->child_state = REQUEST_DONE;\n\t\t/* FALL-THROUGH */\n\n\t\t/*\n\t\t *\tMark the request as no longer running,\n\t\t *\tand clean it up.\n\t\t */\n\tcase REQUEST_DONE:\n#ifdef HAVE_PTHREAD_H\n\t\trequest->child_pid = NO_SUCH_CHILD_PID;\n#endif\n\n#ifdef WITH_COA\n\t\t/*\n\t\t *\tThis is a CoA request.  It's been divorced\n\t\t *\tfrom everything else, so we clean it up now.\n\t\t */\n\t\tif (!request->in_request_hash &&\n\t\t    request->proxy &&\n\t\t    (request->packet->code != request->proxy->code) &&\n\t\t    ((request->proxy->code == PW_COA_REQUEST) ||\n\t\t     (request->proxy->code == PW_DISCONNECT_REQUEST))) {\n\t\t\t/*\n\t\t\t *\tFIXME: Do CoA MIBs\n\t\t\t */\n\t\t\tev_request_free(&request);\n\t\t\treturn;\n\t\t}\n#endif\n\t\trequest_stats_final(request);\n\t\tcleanup_delay(request);\n\t\treturn;\n\n\tcase REQUEST_REJECT_DELAY:\n\tcase REQUEST_CLEANUP_DELAY:\n#ifdef HAVE_PTHREAD_H\n\t\trequest->child_pid = NO_SUCH_CHILD_PID;\n#endif\n\t\trequest_stats_final(request);\n\n\tcase REQUEST_PROXIED:\n\t\trad_assert(request->next_callback != NULL);\n\t\trad_assert(request->next_callback != wait_a_bit);\n\n\t\trequest->when = request->next_when;\n\t\tcallback = request->next_callback;\n\t\trequest->next_callback = NULL;\n\t\tbreak;\n\n\tdefault:\n\t\trad_panic(\"Internal sanity check failure\");\n\t\treturn;\n\t}\n\n\t/*\n\t *\tSomething major went wrong.  Discard the request, and\n\t *\tkeep running.\n\t *\n\t *\tFIXME: No idea why this happens or how to fix it...\n\t *\tIt seems to happen *only* when requests are proxied,\n\t *\tand where the home server doesn't respond.  So it looks\n\t *\tlike a race condition above, but it happens in debug\n\t *\tmode, with no threads...\n\t */\n\tif (!callback) {\n\t\tRDEBUG(\"WARNING: Internal sanity check failed in event handler for request %u: Discarding the request!\", request->number);\n\t\tev_request_free(&request);\n\t\treturn;\n\t}\n\n\tINSERT_EVENT(callback, request);\n}",
        "func": "static void wait_a_bit(void *ctx)\n{\n\tstruct timeval when;\n\tREQUEST *request = ctx;\n\tfr_event_callback_t callback = NULL;\n\n\trad_assert(request->magic == REQUEST_MAGIC);\n\n#ifdef WITH_COA\n\t/*\n\t *\tThe CoA request is a new (internally generated)\n\t *\trequest, created in a child thread.  We therefore need\n\t *\tsome way to tie its events back into the main event\n\t *\thandler.\n\t */\n\tif (request->coa && !request->coa->proxy_reply &&\n\t    request->coa->next_callback) {\n\t\trequest->coa->when = request->coa->next_when;\n\t\tINSERT_EVENT(request->coa->next_callback, request->coa);\n\t\trequest->coa->next_callback = NULL;\n\t\trequest->coa->parent = NULL;\n\t\trequest->coa = NULL;\n\t}\n#endif\n\n\tswitch (request->child_state) {\n\tcase REQUEST_QUEUED:\n\tcase REQUEST_RUNNING:\n\t\t/*\n\t\t *\tIf we're not thread-capable, OR we're capable,\n\t\t *\tbut have been told to run without threads,\n\t\t *\tcomplain when the requests is queued for a\n\t\t *\tthread, or running in a child thread.\n\t\t */\n#ifdef HAVE_PTHREAD_H\n\t\tif (!have_children)\n#endif\n\t\t{\n\t\t\trad_assert(\"We do not have threads, but the request is marked as queued or running in a child thread\" == NULL);\n\t\t\tbreak;\n\t\t}\n\n#ifdef HAVE_PTHREAD_H\n\t\t/*\n\t\t *\tIf we have threads, wait for the child thread\n\t\t *\tto stop.\n\t\t */\n\t\twhen = request->received;\n\t\twhen.tv_sec += request->root->max_request_time;\n\n\t\t/*\n\t\t *\tNormally called from the event loop with the\n\t\t *\tproper event loop time.  Otherwise, called from\n\t\t *\tpost proxy fail handler, which sets \"now\", and\n\t\t *\tthis call won't re-set it, because we're not\n\t\t *\tin the event loop.\n\t\t */\n\t\tfr_event_now(el, &now);\n\n\t\t/*\n\t\t *\tRequest still has more time.  Continue\n\t\t *\twaiting.\n\t\t */\n\t\tif (timercmp(&now, &when, <)) {\n\t\t\tif (request->delay < (USEC / 10)) {\n\t\t\t\trequest->delay = USEC / 10;\n\t\t\t}\n\t\t\trequest->delay += request->delay >> 1;\n\n\t\t\t/*\n\t\t\t *\tCap delays at something reasonable.\n\t\t\t */\n\t\t\tif (request->delay > (request->root->max_request_time * USEC)) {\n\t\t\t\trequest->delay = request->root->max_request_time * USEC;\n\t\t\t}\n\n\t\t\trequest->when = now;\n\t\t\ttv_add(&request->when, request->delay);\n\t\t\tcallback = wait_a_bit;\n\t\t\tbreak;\n\t\t}\n\n\t\trequest->master_state = REQUEST_STOP_PROCESSING;\n\n\t\t/*\n\t\t *\tA child thread MAY still be running on the\n\t\t *\trequest.  Ask the thread to stop working on\n\t\t *\tthe request.\n\t\t */\n\t\tif (have_children &&\n\t\t    (pthread_equal(request->child_pid, NO_SUCH_CHILD_PID) == 0)) {\n\t\t\tradlog(L_ERR, \"WARNING: Unresponsive child for request %u, in module %s component %s\",\n\t\t\t       request->number,\n\t\t\t       request->module ? request->module : \"<server core>\",\n\t\t\t       request->component ? request->component : \"<server core>\");\n\t\t}\n\t\t\t\n\t\trequest->delay = USEC;\n\t\ttv_add(&request->when, request->delay);\n\t\tcallback = wait_for_child_to_die;\n\t\tbreak;\n#endif\n\n\t\t/*\n\t\t *\tMark the request as no longer running,\n\t\t *\tand clean it up.\n\t\t */\n\tcase REQUEST_DONE:\n#ifdef HAVE_PTHREAD_H\n\t\trequest->child_pid = NO_SUCH_CHILD_PID;\n#endif\n\n#ifdef WITH_COA\n\t\t/*\n\t\t *\tThis is a CoA request.  It's been divorced\n\t\t *\tfrom everything else, so we clean it up now.\n\t\t */\n\t\tif (!request->in_request_hash &&\n\t\t    request->proxy &&\n\t\t    (request->packet->code != request->proxy->code) &&\n\t\t    ((request->proxy->code == PW_COA_REQUEST) ||\n\t\t     (request->proxy->code == PW_DISCONNECT_REQUEST))) {\n\t\t\t/*\n\t\t\t *\tFIXME: Do CoA MIBs\n\t\t\t */\n\t\t\tev_request_free(&request);\n\t\t\treturn;\n\t\t}\n#endif\n\t\trequest_stats_final(request);\n\t\tcleanup_delay(request);\n\t\treturn;\n\n\tcase REQUEST_REJECT_DELAY:\n\tcase REQUEST_CLEANUP_DELAY:\n#ifdef HAVE_PTHREAD_H\n\t\trequest->child_pid = NO_SUCH_CHILD_PID;\n#endif\n\t\trequest_stats_final(request);\n\n\tcase REQUEST_PROXIED:\n\t\trad_assert(request->next_callback != NULL);\n\t\trad_assert(request->next_callback != wait_a_bit);\n\n\t\trequest->when = request->next_when;\n\t\tcallback = request->next_callback;\n\t\trequest->next_callback = NULL;\n\t\tbreak;\n\n\tdefault:\n\t\trad_panic(\"Internal sanity check failure\");\n\t\treturn;\n\t}\n\n\t/*\n\t *\tSomething major went wrong.  Discard the request, and\n\t *\tkeep running.\n\t *\n\t *\tFIXME: No idea why this happens or how to fix it...\n\t *\tIt seems to happen *only* when requests are proxied,\n\t *\tand where the home server doesn't respond.  So it looks\n\t *\tlike a race condition above, but it happens in debug\n\t *\tmode, with no threads...\n\t */\n\tif (!callback) {\n\t\tRDEBUG(\"WARNING: Internal sanity check failed in event handler for request %u: Discarding the request!\", request->number);\n\t\tev_request_free(&request);\n\t\treturn;\n\t}\n\n\tINSERT_EVENT(callback, request);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -26,6 +26,25 @@\n \tswitch (request->child_state) {\n \tcase REQUEST_QUEUED:\n \tcase REQUEST_RUNNING:\n+\t\t/*\n+\t\t *\tIf we're not thread-capable, OR we're capable,\n+\t\t *\tbut have been told to run without threads,\n+\t\t *\tcomplain when the requests is queued for a\n+\t\t *\tthread, or running in a child thread.\n+\t\t */\n+#ifdef HAVE_PTHREAD_H\n+\t\tif (!have_children)\n+#endif\n+\t\t{\n+\t\t\trad_assert(\"We do not have threads, but the request is marked as queued or running in a child thread\" == NULL);\n+\t\t\tbreak;\n+\t\t}\n+\n+#ifdef HAVE_PTHREAD_H\n+\t\t/*\n+\t\t *\tIf we have threads, wait for the child thread\n+\t\t *\tto stop.\n+\t\t */\n \t\twhen = request->received;\n \t\twhen.tv_sec += request->root->max_request_time;\n \n@@ -42,24 +61,18 @@\n \t\t *\tRequest still has more time.  Continue\n \t\t *\twaiting.\n \t\t */\n-\t\tif (timercmp(&now, &when, <) ||\n-\t\t    ((request->listener->type == RAD_LISTEN_DETAIL) &&\n-\t\t     (request->child_state == REQUEST_QUEUED))) {\n+\t\tif (timercmp(&now, &when, <)) {\n \t\t\tif (request->delay < (USEC / 10)) {\n \t\t\t\trequest->delay = USEC / 10;\n \t\t\t}\n \t\t\trequest->delay += request->delay >> 1;\n \n-#ifdef WITH_DETAIL\n \t\t\t/*\n-\t\t\t *\tCap wait at some sane value for detail\n-\t\t\t *\tfiles.\n+\t\t\t *\tCap delays at something reasonable.\n \t\t\t */\n-\t\t\tif ((request->listener->type == RAD_LISTEN_DETAIL) &&\n-\t\t\t    (request->delay > (request->root->max_request_time * USEC))) {\n+\t\t\tif (request->delay > (request->root->max_request_time * USEC)) {\n \t\t\t\trequest->delay = request->root->max_request_time * USEC;\n \t\t\t}\n-#endif\n \n \t\t\trequest->when = now;\n \t\t\ttv_add(&request->when, request->delay);\n@@ -67,7 +80,8 @@\n \t\t\tbreak;\n \t\t}\n \n-#if defined(HAVE_PTHREAD_H)\n+\t\trequest->master_state = REQUEST_STOP_PROCESSING;\n+\n \t\t/*\n \t\t *\tA child thread MAY still be running on the\n \t\t *\trequest.  Ask the thread to stop working on\n@@ -75,30 +89,17 @@\n \t\t */\n \t\tif (have_children &&\n \t\t    (pthread_equal(request->child_pid, NO_SUCH_CHILD_PID) == 0)) {\n-\t\t\trequest->master_state = REQUEST_STOP_PROCESSING;\n-\n \t\t\tradlog(L_ERR, \"WARNING: Unresponsive child for request %u, in module %s component %s\",\n \t\t\t       request->number,\n \t\t\t       request->module ? request->module : \"<server core>\",\n \t\t\t       request->component ? request->component : \"<server core>\");\n+\t\t}\n \t\t\t\n-\t\t\trequest->delay = USEC / 4;\n-\t\t\ttv_add(&request->when, request->delay);\n-\t\t\tcallback = wait_for_child_to_die;\n-\t\t\tbreak;\n-\t\t}\n+\t\trequest->delay = USEC;\n+\t\ttv_add(&request->when, request->delay);\n+\t\tcallback = wait_for_child_to_die;\n+\t\tbreak;\n #endif\n-\n-\t\t/*\n-\t\t *\tElse no child thread is processing the\n-\t\t *\trequest.  We probably should have just marked\n-\t\t *\tthe request as 'done' elsewhere, like in the\n-\t\t *\tpost-proxy-fail handler.  But doing that would\n-\t\t *\tinvolve checking for max_request_time in\n-\t\t *\tmultiple places, so this may be simplest.\n-\t\t */\n-\t\trequest->child_state = REQUEST_DONE;\n-\t\t/* FALL-THROUGH */\n \n \t\t/*\n \t\t *\tMark the request as no longer running,",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tif (timercmp(&now, &when, <) ||",
                "\t\t    ((request->listener->type == RAD_LISTEN_DETAIL) &&",
                "\t\t     (request->child_state == REQUEST_QUEUED))) {",
                "#ifdef WITH_DETAIL",
                "\t\t\t *\tCap wait at some sane value for detail",
                "\t\t\t *\tfiles.",
                "\t\t\tif ((request->listener->type == RAD_LISTEN_DETAIL) &&",
                "\t\t\t    (request->delay > (request->root->max_request_time * USEC))) {",
                "#endif",
                "#if defined(HAVE_PTHREAD_H)",
                "\t\t\trequest->master_state = REQUEST_STOP_PROCESSING;",
                "",
                "\t\t\trequest->delay = USEC / 4;",
                "\t\t\ttv_add(&request->when, request->delay);",
                "\t\t\tcallback = wait_for_child_to_die;",
                "\t\t\tbreak;",
                "\t\t}",
                "",
                "\t\t/*",
                "\t\t *\tElse no child thread is processing the",
                "\t\t *\trequest.  We probably should have just marked",
                "\t\t *\tthe request as 'done' elsewhere, like in the",
                "\t\t *\tpost-proxy-fail handler.  But doing that would",
                "\t\t *\tinvolve checking for max_request_time in",
                "\t\t *\tmultiple places, so this may be simplest.",
                "\t\t */",
                "\t\trequest->child_state = REQUEST_DONE;",
                "\t\t/* FALL-THROUGH */"
            ],
            "added_lines": [
                "\t\t/*",
                "\t\t *\tIf we're not thread-capable, OR we're capable,",
                "\t\t *\tbut have been told to run without threads,",
                "\t\t *\tcomplain when the requests is queued for a",
                "\t\t *\tthread, or running in a child thread.",
                "\t\t */",
                "#ifdef HAVE_PTHREAD_H",
                "\t\tif (!have_children)",
                "#endif",
                "\t\t{",
                "\t\t\trad_assert(\"We do not have threads, but the request is marked as queued or running in a child thread\" == NULL);",
                "\t\t\tbreak;",
                "\t\t}",
                "",
                "#ifdef HAVE_PTHREAD_H",
                "\t\t/*",
                "\t\t *\tIf we have threads, wait for the child thread",
                "\t\t *\tto stop.",
                "\t\t */",
                "\t\tif (timercmp(&now, &when, <)) {",
                "\t\t\t *\tCap delays at something reasonable.",
                "\t\t\tif (request->delay > (request->root->max_request_time * USEC)) {",
                "\t\trequest->master_state = REQUEST_STOP_PROCESSING;",
                "",
                "\t\t}",
                "\t\trequest->delay = USEC;",
                "\t\ttv_add(&request->when, request->delay);",
                "\t\tcallback = wait_for_child_to_die;",
                "\t\tbreak;"
            ]
        }
    },
    {
        "cve_id": "CVE-2010-3697",
        "func_name": "alandekok/freeradius-server/wait_for_child_to_die",
        "description": "The wait_for_child_to_die function in main/event.c in FreeRADIUS 2.1.x before 2.1.10, in certain circumstances involving long-term database outages, does not properly handle long queue times for requests, which allows remote attackers to cause a denial of service (daemon crash) by sending many requests.",
        "git_url": "https://github.com/alandekok/freeradius-server/commit/ff94dd35673bba1476594299d31ce8293b8bd223",
        "commit_title": "Do not delete \"old\" requests until they are free.",
        "commit_text": " If the request is in the queue for 30+ seconds, do NOT delete it. Instead, mark it as \"STOP PROCESSING\", and do \"wait_for_child_to_die\", which waits for a child thread to pick it up, and acknowledge that it's done.  Once it's marked done, we can finally clean it up.  This may be the underlying issue behind bug #35",
        "func_before": "static void wait_for_child_to_die(void *ctx)\n{\n\tREQUEST *request = ctx;\n\n\trad_assert(request->magic == REQUEST_MAGIC);\n\n\t/*\n\t *\tIf it's still queued (waiting for a thread to pick it\n\t *\tup) OR, it's running AND there's still a child thread\n\t *\thandling it, THEN delay some more.\n\t */\n\tif ((request->child_state == REQUEST_QUEUED) ||\n\t    ((request->child_state == REQUEST_RUNNING) &&\n\t     (pthread_equal(request->child_pid, NO_SUCH_CHILD_PID) == 0))) {\n\n\t\t/*\n\t\t *\tCap delay at five minutes.\n\t\t */\n\t\tif (request->delay < (USEC * 60 * 5)) {\n\t\t\trequest->delay += (request->delay >> 1);\n\t\t\tradlog(L_INFO, \"WARNING: Child is hung for request %u in component %s module %s.\",\n\t\t\t       request->number, request->component, request->module);\n\t\t} else {\n\t\t\tRDEBUG2(\"Child is still stuck for request %u\",\n\t\t\t\trequest->number);\n\t\t}\n\t\ttv_add(&request->when, request->delay);\n\n\t\tINSERT_EVENT(wait_for_child_to_die, request);\n\t\treturn;\n\t}\n\n\tRDEBUG2(\"Child is finally responsive for request %u\", request->number);\n\tremove_from_request_hash(request);\n\n#ifdef WITH_PROXY\n\tif (request->proxy) {\n\t\twait_for_proxy_id_to_expire(request);\n\t\treturn;\n\t}\n#endif\n\n\tev_request_free(&request);\n}",
        "func": "static void wait_for_child_to_die(void *ctx)\n{\n\tREQUEST *request = ctx;\n\n\trad_assert(request->magic == REQUEST_MAGIC);\n\tremove_from_request_hash(request);\n\n\t/*\n\t *\tIf it's still queued (waiting for a thread to pick it\n\t *\tup) OR, it's running AND there's still a child thread\n\t *\thandling it, THEN delay some more.\n\t */\n\tif ((request->child_state == REQUEST_QUEUED) ||\n\t    ((request->child_state == REQUEST_RUNNING) &&\n\t     (pthread_equal(request->child_pid, NO_SUCH_CHILD_PID) == 0))) {\n\n\t\t/*\n\t\t *\tCap delay at max_request_time\n\t\t */\n\t\tif (request->delay < (USEC * request->root->max_request_time)) {\n\t\t\trequest->delay += (request->delay >> 1);\n\t\t\tradlog(L_INFO, \"WARNING: Child is hung for request %u in component %s module %s.\",\n\t\t\t       request->number, request->component, request->module);\n\t\t} else {\n\t\t\trequest->delay = USEC * request->root->max_request_time;\n\t\t\tRDEBUG2(\"WARNING: Child is still stuck for request %u\",\n\t\t\t\trequest->number);\n\t\t}\n\t\ttv_add(&request->when, request->delay);\n\n\t\tINSERT_EVENT(wait_for_child_to_die, request);\n\t\treturn;\n\t}\n\n\tRDEBUG2(\"Child is finally responsive for request %u\", request->number);\n\n#ifdef WITH_PROXY\n\tif (request->proxy) {\n\t\twait_for_proxy_id_to_expire(request);\n\t\treturn;\n\t}\n#endif\n\n\tev_request_free(&request);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,6 +3,7 @@\n \tREQUEST *request = ctx;\n \n \trad_assert(request->magic == REQUEST_MAGIC);\n+\tremove_from_request_hash(request);\n \n \t/*\n \t *\tIf it's still queued (waiting for a thread to pick it\n@@ -14,14 +15,15 @@\n \t     (pthread_equal(request->child_pid, NO_SUCH_CHILD_PID) == 0))) {\n \n \t\t/*\n-\t\t *\tCap delay at five minutes.\n+\t\t *\tCap delay at max_request_time\n \t\t */\n-\t\tif (request->delay < (USEC * 60 * 5)) {\n+\t\tif (request->delay < (USEC * request->root->max_request_time)) {\n \t\t\trequest->delay += (request->delay >> 1);\n \t\t\tradlog(L_INFO, \"WARNING: Child is hung for request %u in component %s module %s.\",\n \t\t\t       request->number, request->component, request->module);\n \t\t} else {\n-\t\t\tRDEBUG2(\"Child is still stuck for request %u\",\n+\t\t\trequest->delay = USEC * request->root->max_request_time;\n+\t\t\tRDEBUG2(\"WARNING: Child is still stuck for request %u\",\n \t\t\t\trequest->number);\n \t\t}\n \t\ttv_add(&request->when, request->delay);\n@@ -31,7 +33,6 @@\n \t}\n \n \tRDEBUG2(\"Child is finally responsive for request %u\", request->number);\n-\tremove_from_request_hash(request);\n \n #ifdef WITH_PROXY\n \tif (request->proxy) {",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t *\tCap delay at five minutes.",
                "\t\tif (request->delay < (USEC * 60 * 5)) {",
                "\t\t\tRDEBUG2(\"Child is still stuck for request %u\",",
                "\tremove_from_request_hash(request);"
            ],
            "added_lines": [
                "\tremove_from_request_hash(request);",
                "\t\t *\tCap delay at max_request_time",
                "\t\tif (request->delay < (USEC * request->root->max_request_time)) {",
                "\t\t\trequest->delay = USEC * request->root->max_request_time;",
                "\t\t\tRDEBUG2(\"WARNING: Child is still stuck for request %u\","
            ]
        }
    },
    {
        "cve_id": "CVE-2010-4352",
        "func_name": "dbus/_dbus_validity_to_error_message",
        "description": "Stack consumption vulnerability in D-Bus (aka DBus) before 1.4.1 allows local users to cause a denial of service (daemon crash) via a message containing many nested variants.",
        "git_url": "http://cgit.freedesktop.org/dbus/dbus/commit/?id=7d65a3a6ed8815e34a99c680ac3869fde49dbbd4",
        "commit_title": "Add DBUS_INVALID_NESTED_TOO_DEEPLY validity problem and a test that",
        "commit_text": "should generate it.  Previously, we rejected deep nesting in the signature, but variants allow dynamic message nesting, conditional only on the depth of the message body.  The nesting limit is 64, which was also the limit in static signatures.  Empirically, dynamic nesting depth observed on my Fedora 14 system doesn't exceed 2; 64 is really a huge limit.  https://bugs.freedesktop.org/show_bug.cgi?id=32321  Signed-Off-By: Colin Walters <walters@verbum.org> ",
        "func_before": "const char *\n_dbus_validity_to_error_message (DBusValidity validity)\n{\n  switch (validity)\n    {\n    case DBUS_VALIDITY_UNKNOWN_OOM_ERROR:                          return \"Out of memory\";\n    case DBUS_INVALID_FOR_UNKNOWN_REASON:                          return \"Unknown reason\";\n    case DBUS_VALID_BUT_INCOMPLETE:                                return \"Valid but incomplete\";\n    case DBUS_VALIDITY_UNKNOWN:                                    return \"Validity unknown\";\n    case DBUS_VALID:                                               return \"Valid\";\n    case DBUS_INVALID_UNKNOWN_TYPECODE:                            return \"Unknown typecode\";\n    case DBUS_INVALID_MISSING_ARRAY_ELEMENT_TYPE:                  return \"Missing array element type\";\n    case DBUS_INVALID_SIGNATURE_TOO_LONG:                          return \"Signature is too long\";\n    case DBUS_INVALID_EXCEEDED_MAXIMUM_ARRAY_RECURSION:            return \"Exceeded maximum array recursion\";\n    case DBUS_INVALID_EXCEEDED_MAXIMUM_STRUCT_RECURSION:           return \"Exceeded maximum struct recursion\";\n    case DBUS_INVALID_STRUCT_ENDED_BUT_NOT_STARTED:                return \"Struct ended but not started\";\n    case DBUS_INVALID_STRUCT_STARTED_BUT_NOT_ENDED:                return \"Struct started but not ended\";\n    case DBUS_INVALID_STRUCT_HAS_NO_FIELDS:                        return \"Struct has no fields\";\n    case DBUS_INVALID_ALIGNMENT_PADDING_NOT_NUL:                   return \"Alignment padding not null\";\n    case DBUS_INVALID_BOOLEAN_NOT_ZERO_OR_ONE:                     return \"Boolean is not zero or one\";\n    case DBUS_INVALID_NOT_ENOUGH_DATA:                             return \"Not enough data\";\n    case DBUS_INVALID_TOO_MUCH_DATA:                               return \"Too much data\";\n    case DBUS_INVALID_BAD_BYTE_ORDER:                              return \"Bad byte order\";\n    case DBUS_INVALID_BAD_PROTOCOL_VERSION:                        return \"Bad protocol version\";\n    case DBUS_INVALID_BAD_MESSAGE_TYPE:                            return \"Bad message type\";\n    case DBUS_INVALID_BAD_SERIAL:                                  return \"Bad serial\";\n    case DBUS_INVALID_INSANE_FIELDS_ARRAY_LENGTH:                  return \"Insane fields array length\";\n    case DBUS_INVALID_INSANE_BODY_LENGTH:                          return \"Insane body length\";\n    case DBUS_INVALID_MESSAGE_TOO_LONG:                            return \"Message too long\";\n    case DBUS_INVALID_HEADER_FIELD_CODE:                           return \"Header field code\";\n    case DBUS_INVALID_HEADER_FIELD_HAS_WRONG_TYPE:                 return \"Header field has wrong type\";\n    case DBUS_INVALID_USES_LOCAL_INTERFACE:                        return \"Uses local interface\";\n    case DBUS_INVALID_USES_LOCAL_PATH:                             return \"Uses local path\";\n    case DBUS_INVALID_HEADER_FIELD_APPEARS_TWICE:                  return \"Header field appears twice\";\n    case DBUS_INVALID_BAD_DESTINATION:                             return \"Bad destination\";\n    case DBUS_INVALID_BAD_INTERFACE:                               return \"Bad interface\";\n    case DBUS_INVALID_BAD_MEMBER:                                  return \"Bad member\";\n    case DBUS_INVALID_BAD_ERROR_NAME:                              return \"Bad error name\";\n    case DBUS_INVALID_BAD_SENDER:                                  return \"Bad sender\";\n    case DBUS_INVALID_MISSING_PATH:                                return \"Missing path\";\n    case DBUS_INVALID_MISSING_INTERFACE:                           return \"Missing interface\";\n    case DBUS_INVALID_MISSING_MEMBER:                              return \"Missing member\";\n    case DBUS_INVALID_MISSING_ERROR_NAME:                          return \"Missing error name\";\n    case DBUS_INVALID_MISSING_REPLY_SERIAL:                        return \"Missing reply serial\";\n    case DBUS_INVALID_LENGTH_OUT_OF_BOUNDS:                        return \"Length out of bounds\";\n    case DBUS_INVALID_ARRAY_LENGTH_EXCEEDS_MAXIMUM:                return \"Array length exceeds maximum\";\n    case DBUS_INVALID_BAD_PATH:                                    return \"Bad path\";\n    case DBUS_INVALID_SIGNATURE_LENGTH_OUT_OF_BOUNDS:              return \"Signature length out of bounds\";\n    case DBUS_INVALID_BAD_UTF8_IN_STRING:                          return \"Bad utf8 in string\";\n    case DBUS_INVALID_ARRAY_LENGTH_INCORRECT:                      return \"Array length incorrect\";\n    case DBUS_INVALID_VARIANT_SIGNATURE_LENGTH_OUT_OF_BOUNDS:      return \"Variant signature length out of bounds\";\n    case DBUS_INVALID_VARIANT_SIGNATURE_BAD:                       return \"Variant signature bad\";\n    case DBUS_INVALID_VARIANT_SIGNATURE_EMPTY:                     return \"Variant signature empty\";\n    case DBUS_INVALID_VARIANT_SIGNATURE_SPECIFIES_MULTIPLE_VALUES: return \"Variant signature specifies multiple values\";\n    case DBUS_INVALID_VARIANT_SIGNATURE_MISSING_NUL:               return \"Variant signature missing nul\";\n    case DBUS_INVALID_STRING_MISSING_NUL:                          return \"String missing nul\";\n    case DBUS_INVALID_SIGNATURE_MISSING_NUL:                       return \"Signature missing nul\";\n    case DBUS_INVALID_EXCEEDED_MAXIMUM_DICT_ENTRY_RECURSION:       return \"Exceeded maximum dict entry recursion\";\n    case DBUS_INVALID_DICT_ENTRY_ENDED_BUT_NOT_STARTED:            return \"Dict entry ended but not started\";\n    case DBUS_INVALID_DICT_ENTRY_STARTED_BUT_NOT_ENDED:            return \"Dict entry started but not ended\";\n    case DBUS_INVALID_DICT_ENTRY_HAS_NO_FIELDS:                    return \"Dict entry has no fields\";\n    case DBUS_INVALID_DICT_ENTRY_HAS_ONLY_ONE_FIELD:               return \"Dict entry has only one field\";\n    case DBUS_INVALID_DICT_ENTRY_HAS_TOO_MANY_FIELDS:              return \"Dict entry has too many fields\";\n    case DBUS_INVALID_DICT_ENTRY_NOT_INSIDE_ARRAY:                 return \"Dict entry not inside array\";\n    case DBUS_INVALID_DICT_KEY_MUST_BE_BASIC_TYPE:                 return \"Dict key must be basic type\";\n\n    default:\n      return \"Invalid\";\n    }\n}",
        "func": "const char *\n_dbus_validity_to_error_message (DBusValidity validity)\n{\n  switch (validity)\n    {\n    case DBUS_VALIDITY_UNKNOWN_OOM_ERROR:                          return \"Out of memory\";\n    case DBUS_INVALID_FOR_UNKNOWN_REASON:                          return \"Unknown reason\";\n    case DBUS_VALID_BUT_INCOMPLETE:                                return \"Valid but incomplete\";\n    case DBUS_VALIDITY_UNKNOWN:                                    return \"Validity unknown\";\n    case DBUS_VALID:                                               return \"Valid\";\n    case DBUS_INVALID_UNKNOWN_TYPECODE:                            return \"Unknown typecode\";\n    case DBUS_INVALID_MISSING_ARRAY_ELEMENT_TYPE:                  return \"Missing array element type\";\n    case DBUS_INVALID_SIGNATURE_TOO_LONG:                          return \"Signature is too long\";\n    case DBUS_INVALID_EXCEEDED_MAXIMUM_ARRAY_RECURSION:            return \"Exceeded maximum array recursion\";\n    case DBUS_INVALID_EXCEEDED_MAXIMUM_STRUCT_RECURSION:           return \"Exceeded maximum struct recursion\";\n    case DBUS_INVALID_STRUCT_ENDED_BUT_NOT_STARTED:                return \"Struct ended but not started\";\n    case DBUS_INVALID_STRUCT_STARTED_BUT_NOT_ENDED:                return \"Struct started but not ended\";\n    case DBUS_INVALID_STRUCT_HAS_NO_FIELDS:                        return \"Struct has no fields\";\n    case DBUS_INVALID_ALIGNMENT_PADDING_NOT_NUL:                   return \"Alignment padding not null\";\n    case DBUS_INVALID_BOOLEAN_NOT_ZERO_OR_ONE:                     return \"Boolean is not zero or one\";\n    case DBUS_INVALID_NOT_ENOUGH_DATA:                             return \"Not enough data\";\n    case DBUS_INVALID_TOO_MUCH_DATA:                               return \"Too much data\";\n    case DBUS_INVALID_BAD_BYTE_ORDER:                              return \"Bad byte order\";\n    case DBUS_INVALID_BAD_PROTOCOL_VERSION:                        return \"Bad protocol version\";\n    case DBUS_INVALID_BAD_MESSAGE_TYPE:                            return \"Bad message type\";\n    case DBUS_INVALID_BAD_SERIAL:                                  return \"Bad serial\";\n    case DBUS_INVALID_INSANE_FIELDS_ARRAY_LENGTH:                  return \"Insane fields array length\";\n    case DBUS_INVALID_INSANE_BODY_LENGTH:                          return \"Insane body length\";\n    case DBUS_INVALID_MESSAGE_TOO_LONG:                            return \"Message too long\";\n    case DBUS_INVALID_HEADER_FIELD_CODE:                           return \"Header field code\";\n    case DBUS_INVALID_HEADER_FIELD_HAS_WRONG_TYPE:                 return \"Header field has wrong type\";\n    case DBUS_INVALID_USES_LOCAL_INTERFACE:                        return \"Uses local interface\";\n    case DBUS_INVALID_USES_LOCAL_PATH:                             return \"Uses local path\";\n    case DBUS_INVALID_HEADER_FIELD_APPEARS_TWICE:                  return \"Header field appears twice\";\n    case DBUS_INVALID_BAD_DESTINATION:                             return \"Bad destination\";\n    case DBUS_INVALID_BAD_INTERFACE:                               return \"Bad interface\";\n    case DBUS_INVALID_BAD_MEMBER:                                  return \"Bad member\";\n    case DBUS_INVALID_BAD_ERROR_NAME:                              return \"Bad error name\";\n    case DBUS_INVALID_BAD_SENDER:                                  return \"Bad sender\";\n    case DBUS_INVALID_MISSING_PATH:                                return \"Missing path\";\n    case DBUS_INVALID_MISSING_INTERFACE:                           return \"Missing interface\";\n    case DBUS_INVALID_MISSING_MEMBER:                              return \"Missing member\";\n    case DBUS_INVALID_MISSING_ERROR_NAME:                          return \"Missing error name\";\n    case DBUS_INVALID_MISSING_REPLY_SERIAL:                        return \"Missing reply serial\";\n    case DBUS_INVALID_LENGTH_OUT_OF_BOUNDS:                        return \"Length out of bounds\";\n    case DBUS_INVALID_ARRAY_LENGTH_EXCEEDS_MAXIMUM:                return \"Array length exceeds maximum\";\n    case DBUS_INVALID_BAD_PATH:                                    return \"Bad path\";\n    case DBUS_INVALID_SIGNATURE_LENGTH_OUT_OF_BOUNDS:              return \"Signature length out of bounds\";\n    case DBUS_INVALID_BAD_UTF8_IN_STRING:                          return \"Bad utf8 in string\";\n    case DBUS_INVALID_ARRAY_LENGTH_INCORRECT:                      return \"Array length incorrect\";\n    case DBUS_INVALID_VARIANT_SIGNATURE_LENGTH_OUT_OF_BOUNDS:      return \"Variant signature length out of bounds\";\n    case DBUS_INVALID_VARIANT_SIGNATURE_BAD:                       return \"Variant signature bad\";\n    case DBUS_INVALID_VARIANT_SIGNATURE_EMPTY:                     return \"Variant signature empty\";\n    case DBUS_INVALID_VARIANT_SIGNATURE_SPECIFIES_MULTIPLE_VALUES: return \"Variant signature specifies multiple values\";\n    case DBUS_INVALID_VARIANT_SIGNATURE_MISSING_NUL:               return \"Variant signature missing nul\";\n    case DBUS_INVALID_STRING_MISSING_NUL:                          return \"String missing nul\";\n    case DBUS_INVALID_SIGNATURE_MISSING_NUL:                       return \"Signature missing nul\";\n    case DBUS_INVALID_EXCEEDED_MAXIMUM_DICT_ENTRY_RECURSION:       return \"Exceeded maximum dict entry recursion\";\n    case DBUS_INVALID_DICT_ENTRY_ENDED_BUT_NOT_STARTED:            return \"Dict entry ended but not started\";\n    case DBUS_INVALID_DICT_ENTRY_STARTED_BUT_NOT_ENDED:            return \"Dict entry started but not ended\";\n    case DBUS_INVALID_DICT_ENTRY_HAS_NO_FIELDS:                    return \"Dict entry has no fields\";\n    case DBUS_INVALID_DICT_ENTRY_HAS_ONLY_ONE_FIELD:               return \"Dict entry has only one field\";\n    case DBUS_INVALID_DICT_ENTRY_HAS_TOO_MANY_FIELDS:              return \"Dict entry has too many fields\";\n    case DBUS_INVALID_DICT_ENTRY_NOT_INSIDE_ARRAY:                 return \"Dict entry not inside array\";\n    case DBUS_INVALID_DICT_KEY_MUST_BE_BASIC_TYPE:                 return \"Dict key must be basic type\";\n    case DBUS_INVALID_NESTED_TOO_DEEPLY:                           return \"Variants cannot be used to create a hugely recursive tree of values\";\n    default:\n      return \"Invalid\";\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -63,7 +63,7 @@\n     case DBUS_INVALID_DICT_ENTRY_HAS_TOO_MANY_FIELDS:              return \"Dict entry has too many fields\";\n     case DBUS_INVALID_DICT_ENTRY_NOT_INSIDE_ARRAY:                 return \"Dict entry not inside array\";\n     case DBUS_INVALID_DICT_KEY_MUST_BE_BASIC_TYPE:                 return \"Dict key must be basic type\";\n-\n+    case DBUS_INVALID_NESTED_TOO_DEEPLY:                           return \"Variants cannot be used to create a hugely recursive tree of values\";\n     default:\n       return \"Invalid\";\n     }",
        "diff_line_info": {
            "deleted_lines": [
                ""
            ],
            "added_lines": [
                "    case DBUS_INVALID_NESTED_TOO_DEEPLY:                           return \"Variants cannot be used to create a hugely recursive tree of values\";"
            ]
        }
    },
    {
        "cve_id": "CVE-2010-4352",
        "func_name": "dbus/_dbus_validate_body_with_reason",
        "description": "Stack consumption vulnerability in D-Bus (aka DBus) before 1.4.1 allows local users to cause a denial of service (daemon crash) via a message containing many nested variants.",
        "git_url": "http://cgit.freedesktop.org/dbus/dbus/commit/?id=7d65a3a6ed8815e34a99c680ac3869fde49dbbd4",
        "commit_title": "Add DBUS_INVALID_NESTED_TOO_DEEPLY validity problem and a test that",
        "commit_text": "should generate it.  Previously, we rejected deep nesting in the signature, but variants allow dynamic message nesting, conditional only on the depth of the message body.  The nesting limit is 64, which was also the limit in static signatures.  Empirically, dynamic nesting depth observed on my Fedora 14 system doesn't exceed 2; 64 is really a huge limit.  https://bugs.freedesktop.org/show_bug.cgi?id=32321  Signed-Off-By: Colin Walters <walters@verbum.org> ",
        "func_before": "DBusValidity\n_dbus_validate_body_with_reason (const DBusString *expected_signature,\n                                 int               expected_signature_start,\n                                 int               byte_order,\n                                 int              *bytes_remaining,\n                                 const DBusString *value_str,\n                                 int               value_pos,\n                                 int               len)\n{\n  DBusTypeReader reader;\n  const unsigned char *p;\n  const unsigned char *end;\n  DBusValidity validity;\n\n  _dbus_assert (len >= 0);\n  _dbus_assert (value_pos >= 0);\n  _dbus_assert (value_pos <= _dbus_string_get_length (value_str) - len);\n\n  _dbus_verbose (\"validating body from pos %d len %d sig '%s'\\n\",\n                 value_pos, len, _dbus_string_get_const_data_len (expected_signature,\n                                                                  expected_signature_start,\n                                                                  0));\n\n  _dbus_type_reader_init_types_only (&reader,\n                                     expected_signature, expected_signature_start);\n\n  p = _dbus_string_get_const_data_len (value_str, value_pos, len);\n  end = p + len;\n\n  validity = validate_body_helper (&reader, byte_order, TRUE, p, end, &p);\n  if (validity != DBUS_VALID)\n    return validity;\n  \n  if (bytes_remaining)\n    {\n      *bytes_remaining = end - p;\n      return DBUS_VALID;\n    }\n  else if (p < end)\n    return DBUS_INVALID_TOO_MUCH_DATA;\n  else\n    {\n      _dbus_assert (p == end);\n      return DBUS_VALID;\n    }\n}",
        "func": "DBusValidity\n_dbus_validate_body_with_reason (const DBusString *expected_signature,\n                                 int               expected_signature_start,\n                                 int               byte_order,\n                                 int              *bytes_remaining,\n                                 const DBusString *value_str,\n                                 int               value_pos,\n                                 int               len)\n{\n  DBusTypeReader reader;\n  const unsigned char *p;\n  const unsigned char *end;\n  DBusValidity validity;\n\n  _dbus_assert (len >= 0);\n  _dbus_assert (value_pos >= 0);\n  _dbus_assert (value_pos <= _dbus_string_get_length (value_str) - len);\n\n  _dbus_verbose (\"validating body from pos %d len %d sig '%s'\\n\",\n                 value_pos, len, _dbus_string_get_const_data_len (expected_signature,\n                                                                  expected_signature_start,\n                                                                  0));\n\n  _dbus_type_reader_init_types_only (&reader,\n                                     expected_signature, expected_signature_start);\n\n  p = _dbus_string_get_const_data_len (value_str, value_pos, len);\n  end = p + len;\n\n  validity = validate_body_helper (&reader, byte_order, TRUE, 0, p, end, &p);\n  if (validity != DBUS_VALID)\n    return validity;\n  \n  if (bytes_remaining)\n    {\n      *bytes_remaining = end - p;\n      return DBUS_VALID;\n    }\n  else if (p < end)\n    return DBUS_INVALID_TOO_MUCH_DATA;\n  else\n    {\n      _dbus_assert (p == end);\n      return DBUS_VALID;\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -27,7 +27,7 @@\n   p = _dbus_string_get_const_data_len (value_str, value_pos, len);\n   end = p + len;\n \n-  validity = validate_body_helper (&reader, byte_order, TRUE, p, end, &p);\n+  validity = validate_body_helper (&reader, byte_order, TRUE, 0, p, end, &p);\n   if (validity != DBUS_VALID)\n     return validity;\n   ",
        "diff_line_info": {
            "deleted_lines": [
                "  validity = validate_body_helper (&reader, byte_order, TRUE, p, end, &p);"
            ],
            "added_lines": [
                "  validity = validate_body_helper (&reader, byte_order, TRUE, 0, p, end, &p);"
            ]
        }
    },
    {
        "cve_id": "CVE-2010-4352",
        "func_name": "dbus/validate_body_helper",
        "description": "Stack consumption vulnerability in D-Bus (aka DBus) before 1.4.1 allows local users to cause a denial of service (daemon crash) via a message containing many nested variants.",
        "git_url": "http://cgit.freedesktop.org/dbus/dbus/commit/?id=7d65a3a6ed8815e34a99c680ac3869fde49dbbd4",
        "commit_title": "Add DBUS_INVALID_NESTED_TOO_DEEPLY validity problem and a test that",
        "commit_text": "should generate it.  Previously, we rejected deep nesting in the signature, but variants allow dynamic message nesting, conditional only on the depth of the message body.  The nesting limit is 64, which was also the limit in static signatures.  Empirically, dynamic nesting depth observed on my Fedora 14 system doesn't exceed 2; 64 is really a huge limit.  https://bugs.freedesktop.org/show_bug.cgi?id=32321  Signed-Off-By: Colin Walters <walters@verbum.org> ",
        "func_before": "static DBusValidity\nvalidate_body_helper (DBusTypeReader       *reader,\n                      int                   byte_order,\n                      dbus_bool_t           walk_reader_to_end,\n                      const unsigned char  *p,\n                      const unsigned char  *end,\n                      const unsigned char **new_p)\n{\n  int current_type;\n\n  while ((current_type = _dbus_type_reader_get_current_type (reader)) != DBUS_TYPE_INVALID)\n    {\n      const unsigned char *a;\n      int alignment;\n\n#if 0\n      _dbus_verbose (\"   validating value of type %s type reader %p type_pos %d p %p end %p %d remain\\n\",\n                     _dbus_type_to_string (current_type), reader, reader->type_pos, p, end,\n                     (int) (end - p));\n#endif\n\n      /* Guarantee that p has one byte to look at */\n      if (p == end)\n        return DBUS_INVALID_NOT_ENOUGH_DATA;\n\n      switch (current_type)\n        {\n        case DBUS_TYPE_BYTE:\n          ++p;\n          break;\n\n        case DBUS_TYPE_BOOLEAN:\n        case DBUS_TYPE_INT16:\n        case DBUS_TYPE_UINT16:\n        case DBUS_TYPE_INT32:\n        case DBUS_TYPE_UINT32:\n        case DBUS_TYPE_UNIX_FD:\n        case DBUS_TYPE_INT64:\n        case DBUS_TYPE_UINT64:\n        case DBUS_TYPE_DOUBLE:\n          alignment = _dbus_type_get_alignment (current_type);\n          a = _DBUS_ALIGN_ADDRESS (p, alignment);\n          if (a >= end)\n            return DBUS_INVALID_NOT_ENOUGH_DATA;\n          while (p != a)\n            {\n              if (*p != '\\0')\n                return DBUS_INVALID_ALIGNMENT_PADDING_NOT_NUL;\n              ++p;\n            }\n          \n          if (current_type == DBUS_TYPE_BOOLEAN)\n            {\n              dbus_uint32_t v = _dbus_unpack_uint32 (byte_order,\n                                                     p);\n              if (!(v == 0 || v == 1))\n                return DBUS_INVALID_BOOLEAN_NOT_ZERO_OR_ONE;\n            }\n          \n          p += alignment;\n          break;\n\n        case DBUS_TYPE_ARRAY:\n        case DBUS_TYPE_STRING:\n        case DBUS_TYPE_OBJECT_PATH:\n          {\n            dbus_uint32_t claimed_len;\n\n            a = _DBUS_ALIGN_ADDRESS (p, 4);\n            if (a + 4 > end)\n              return DBUS_INVALID_NOT_ENOUGH_DATA;\n            while (p != a)\n              {\n                if (*p != '\\0')\n                  return DBUS_INVALID_ALIGNMENT_PADDING_NOT_NUL;\n                ++p;\n              }\n\n            claimed_len = _dbus_unpack_uint32 (byte_order, p);\n            p += 4;\n\n            /* p may now be == end */\n            _dbus_assert (p <= end);\n\n            if (current_type == DBUS_TYPE_ARRAY)\n              {\n                int array_elem_type = _dbus_type_reader_get_element_type (reader);\n\n                if (!_dbus_type_is_valid (array_elem_type))\n                  {\n                    return DBUS_INVALID_UNKNOWN_TYPECODE;\n                  }\n\n                alignment = _dbus_type_get_alignment (array_elem_type);\n\n                a = _DBUS_ALIGN_ADDRESS (p, alignment);\n\n                /* a may now be == end */\n                if (a > end)\n                  return DBUS_INVALID_NOT_ENOUGH_DATA;\n\n                while (p != a)\n                  {\n                    if (*p != '\\0')\n                      return DBUS_INVALID_ALIGNMENT_PADDING_NOT_NUL;\n                    ++p;\n                  }\n              }\n\n            if (claimed_len > (unsigned long) (end - p))\n              return DBUS_INVALID_LENGTH_OUT_OF_BOUNDS;\n\n            if (current_type == DBUS_TYPE_OBJECT_PATH)\n              {\n                DBusString str;\n                _dbus_string_init_const_len (&str, p, claimed_len);\n                if (!_dbus_validate_path (&str, 0,\n                                          _dbus_string_get_length (&str)))\n                  return DBUS_INVALID_BAD_PATH;\n\n                p += claimed_len;\n              }\n            else if (current_type == DBUS_TYPE_STRING)\n              {\n                DBusString str;\n                _dbus_string_init_const_len (&str, p, claimed_len);\n                if (!_dbus_string_validate_utf8 (&str, 0,\n                                                 _dbus_string_get_length (&str)))\n                  return DBUS_INVALID_BAD_UTF8_IN_STRING;\n\n                p += claimed_len;\n              }\n            else if (current_type == DBUS_TYPE_ARRAY && claimed_len > 0)\n              {\n                DBusTypeReader sub;\n                DBusValidity validity;\n                const unsigned char *array_end;\n                int array_elem_type;\n\n                if (claimed_len > DBUS_MAXIMUM_ARRAY_LENGTH)\n                  return DBUS_INVALID_ARRAY_LENGTH_EXCEEDS_MAXIMUM;\n                \n                /* Remember that the reader is types only, so we can't\n                 * use it to iterate over elements. It stays the same\n                 * for all elements.\n                 */\n                _dbus_type_reader_recurse (reader, &sub);\n\n                array_end = p + claimed_len;\n\n                array_elem_type = _dbus_type_reader_get_element_type (reader);\n\n                /* avoid recursive call to validate_body_helper if this is an array\n                 * of fixed-size elements\n                 */ \n                if (dbus_type_is_fixed (array_elem_type))\n                  {\n                    /* bools need to be handled differently, because they can\n                     * have an invalid value\n                     */\n                    if (array_elem_type == DBUS_TYPE_BOOLEAN)\n                      {\n                        dbus_uint32_t v;\n                        alignment = _dbus_type_get_alignment (array_elem_type);\n\n                        while (p < array_end)\n                          {\n                            v = _dbus_unpack_uint32 (byte_order, p);\n\n                            if (!(v == 0 || v == 1))\n                              return DBUS_INVALID_BOOLEAN_NOT_ZERO_OR_ONE;\n\n                            p += alignment;\n                          }\n                      }\n\n                    else\n                      {\n                        p = array_end;\n                      }\n                  }\n\n                else\n                  {\n                    while (p < array_end)\n                      {\n                        validity = validate_body_helper (&sub, byte_order, FALSE, p, end, &p);\n                        if (validity != DBUS_VALID)\n                          return validity;\n                      }\n                  }\n\n                if (p != array_end)\n                  return DBUS_INVALID_ARRAY_LENGTH_INCORRECT;\n              }\n\n            /* check nul termination */\n            if (current_type != DBUS_TYPE_ARRAY)\n              {\n                if (p == end)\n                  return DBUS_INVALID_NOT_ENOUGH_DATA;\n\n                if (*p != '\\0')\n                  return DBUS_INVALID_STRING_MISSING_NUL;\n                ++p;\n              }\n          }\n          break;\n\n        case DBUS_TYPE_SIGNATURE:\n          {\n            dbus_uint32_t claimed_len;\n            DBusString str;\n            DBusValidity validity;\n\n            claimed_len = *p;\n            ++p;\n\n            /* 1 is for nul termination */\n            if (claimed_len + 1 > (unsigned long) (end - p))\n              return DBUS_INVALID_SIGNATURE_LENGTH_OUT_OF_BOUNDS;\n\n            _dbus_string_init_const_len (&str, p, claimed_len);\n            validity =\n              _dbus_validate_signature_with_reason (&str, 0,\n                                                    _dbus_string_get_length (&str));\n\n            if (validity != DBUS_VALID)\n              return validity;\n\n            p += claimed_len;\n\n            _dbus_assert (p < end);\n            if (*p != DBUS_TYPE_INVALID)\n              return DBUS_INVALID_SIGNATURE_MISSING_NUL;\n\n            ++p;\n\n            _dbus_verbose (\"p = %p end = %p claimed_len %u\\n\", p, end, claimed_len);\n          }\n          break;\n\n        case DBUS_TYPE_VARIANT:\n          {\n            /* 1 byte sig len, sig typecodes, align to\n             * contained-type-boundary, values.\n             */\n\n            /* In addition to normal signature validation, we need to be sure\n             * the signature contains only a single (possibly container) type.\n             */\n            dbus_uint32_t claimed_len;\n            DBusString sig;\n            DBusTypeReader sub;\n            DBusValidity validity;\n            int contained_alignment;\n            int contained_type;\n            DBusValidity reason;\n\n            claimed_len = *p;\n            ++p;\n\n            /* + 1 for nul */\n            if (claimed_len + 1 > (unsigned long) (end - p))\n              return DBUS_INVALID_VARIANT_SIGNATURE_LENGTH_OUT_OF_BOUNDS;\n\n            _dbus_string_init_const_len (&sig, p, claimed_len);\n            reason = _dbus_validate_signature_with_reason (&sig, 0,\n                                           _dbus_string_get_length (&sig));\n            if (!(reason == DBUS_VALID))\n              {\n                if (reason == DBUS_VALIDITY_UNKNOWN_OOM_ERROR)\n                  return reason;\n                else \n                  return DBUS_INVALID_VARIANT_SIGNATURE_BAD;\n              }\n\n            p += claimed_len;\n            \n            if (*p != DBUS_TYPE_INVALID)\n              return DBUS_INVALID_VARIANT_SIGNATURE_MISSING_NUL;\n            ++p;\n\n            contained_type = _dbus_first_type_in_signature (&sig, 0);\n            if (contained_type == DBUS_TYPE_INVALID)\n              return DBUS_INVALID_VARIANT_SIGNATURE_EMPTY;\n            \n            contained_alignment = _dbus_type_get_alignment (contained_type);\n            \n            a = _DBUS_ALIGN_ADDRESS (p, contained_alignment);\n            if (a > end)\n              return DBUS_INVALID_NOT_ENOUGH_DATA;\n            while (p != a)\n              {\n                if (*p != '\\0')\n                  return DBUS_INVALID_ALIGNMENT_PADDING_NOT_NUL;\n                ++p;\n              }\n\n            _dbus_type_reader_init_types_only (&sub, &sig, 0);\n\n            _dbus_assert (_dbus_type_reader_get_current_type (&sub) != DBUS_TYPE_INVALID);\n\n            validity = validate_body_helper (&sub, byte_order, FALSE, p, end, &p);\n            if (validity != DBUS_VALID)\n              return validity;\n\n            if (_dbus_type_reader_next (&sub))\n              return DBUS_INVALID_VARIANT_SIGNATURE_SPECIFIES_MULTIPLE_VALUES;\n\n            _dbus_assert (_dbus_type_reader_get_current_type (&sub) == DBUS_TYPE_INVALID);\n          }\n          break;\n\n        case DBUS_TYPE_DICT_ENTRY:\n        case DBUS_TYPE_STRUCT:\n          {\n            DBusTypeReader sub;\n            DBusValidity validity;\n\n            a = _DBUS_ALIGN_ADDRESS (p, 8);\n            if (a > end)\n              return DBUS_INVALID_NOT_ENOUGH_DATA;\n            while (p != a)\n              {\n                if (*p != '\\0')\n                  return DBUS_INVALID_ALIGNMENT_PADDING_NOT_NUL;\n                ++p;\n              }\n\n            _dbus_type_reader_recurse (reader, &sub);\n\n            validity = validate_body_helper (&sub, byte_order, TRUE, p, end, &p);\n            if (validity != DBUS_VALID)\n              return validity;\n          }\n          break;\n\n        default:\n          _dbus_assert_not_reached (\"invalid typecode in supposedly-validated signature\");\n          break;\n        }\n\n#if 0\n      _dbus_verbose (\"   validated value of type %s type reader %p type_pos %d p %p end %p %d remain\\n\",\n                     _dbus_type_to_string (current_type), reader, reader->type_pos, p, end,\n                     (int) (end - p));\n#endif\n\n      if (p > end)\n        {\n          _dbus_verbose (\"not enough data!!! p = %p end = %p end-p = %d\\n\",\n                         p, end, (int) (end - p));\n          return DBUS_INVALID_NOT_ENOUGH_DATA;\n        }\n\n      if (walk_reader_to_end)\n        _dbus_type_reader_next (reader);\n      else\n        break;\n    }\n\n  if (new_p)\n    *new_p = p;\n\n  return DBUS_VALID;\n}",
        "func": "static DBusValidity\nvalidate_body_helper (DBusTypeReader       *reader,\n                      int                   byte_order,\n                      dbus_bool_t           walk_reader_to_end,\n                      int                   total_depth,\n                      const unsigned char  *p,\n                      const unsigned char  *end,\n                      const unsigned char **new_p)\n{\n  int current_type;\n\n  /* The spec allows arrays and structs to each nest 32, for total\n   * nesting of 2*32. We want to impose the same limit on \"dynamic\"\n   * value nesting (not visible in the signature) which is introduced\n   * by DBUS_TYPE_VARIANT.\n   */\n  if (total_depth > (DBUS_MAXIMUM_TYPE_RECURSION_DEPTH * 2))\n    {\n      return DBUS_INVALID_NESTED_TOO_DEEPLY;\n    }\n\n  while ((current_type = _dbus_type_reader_get_current_type (reader)) != DBUS_TYPE_INVALID)\n    {\n      const unsigned char *a;\n      int alignment;\n\n#if 0\n      _dbus_verbose (\"   validating value of type %s type reader %p type_pos %d p %p end %p %d remain\\n\",\n                     _dbus_type_to_string (current_type), reader, reader->type_pos, p, end,\n                     (int) (end - p));\n#endif\n\n      /* Guarantee that p has one byte to look at */\n      if (p == end)\n        return DBUS_INVALID_NOT_ENOUGH_DATA;\n\n      switch (current_type)\n        {\n        case DBUS_TYPE_BYTE:\n          ++p;\n          break;\n\n        case DBUS_TYPE_BOOLEAN:\n        case DBUS_TYPE_INT16:\n        case DBUS_TYPE_UINT16:\n        case DBUS_TYPE_INT32:\n        case DBUS_TYPE_UINT32:\n        case DBUS_TYPE_UNIX_FD:\n        case DBUS_TYPE_INT64:\n        case DBUS_TYPE_UINT64:\n        case DBUS_TYPE_DOUBLE:\n          alignment = _dbus_type_get_alignment (current_type);\n          a = _DBUS_ALIGN_ADDRESS (p, alignment);\n          if (a >= end)\n            return DBUS_INVALID_NOT_ENOUGH_DATA;\n          while (p != a)\n            {\n              if (*p != '\\0')\n                return DBUS_INVALID_ALIGNMENT_PADDING_NOT_NUL;\n              ++p;\n            }\n          \n          if (current_type == DBUS_TYPE_BOOLEAN)\n            {\n              dbus_uint32_t v = _dbus_unpack_uint32 (byte_order,\n                                                     p);\n              if (!(v == 0 || v == 1))\n                return DBUS_INVALID_BOOLEAN_NOT_ZERO_OR_ONE;\n            }\n          \n          p += alignment;\n          break;\n\n        case DBUS_TYPE_ARRAY:\n        case DBUS_TYPE_STRING:\n        case DBUS_TYPE_OBJECT_PATH:\n          {\n            dbus_uint32_t claimed_len;\n\n            a = _DBUS_ALIGN_ADDRESS (p, 4);\n            if (a + 4 > end)\n              return DBUS_INVALID_NOT_ENOUGH_DATA;\n            while (p != a)\n              {\n                if (*p != '\\0')\n                  return DBUS_INVALID_ALIGNMENT_PADDING_NOT_NUL;\n                ++p;\n              }\n\n            claimed_len = _dbus_unpack_uint32 (byte_order, p);\n            p += 4;\n\n            /* p may now be == end */\n            _dbus_assert (p <= end);\n\n            if (current_type == DBUS_TYPE_ARRAY)\n              {\n                int array_elem_type = _dbus_type_reader_get_element_type (reader);\n\n                if (!_dbus_type_is_valid (array_elem_type))\n                  {\n                    return DBUS_INVALID_UNKNOWN_TYPECODE;\n                  }\n\n                alignment = _dbus_type_get_alignment (array_elem_type);\n\n                a = _DBUS_ALIGN_ADDRESS (p, alignment);\n\n                /* a may now be == end */\n                if (a > end)\n                  return DBUS_INVALID_NOT_ENOUGH_DATA;\n\n                while (p != a)\n                  {\n                    if (*p != '\\0')\n                      return DBUS_INVALID_ALIGNMENT_PADDING_NOT_NUL;\n                    ++p;\n                  }\n              }\n\n            if (claimed_len > (unsigned long) (end - p))\n              return DBUS_INVALID_LENGTH_OUT_OF_BOUNDS;\n\n            if (current_type == DBUS_TYPE_OBJECT_PATH)\n              {\n                DBusString str;\n                _dbus_string_init_const_len (&str, p, claimed_len);\n                if (!_dbus_validate_path (&str, 0,\n                                          _dbus_string_get_length (&str)))\n                  return DBUS_INVALID_BAD_PATH;\n\n                p += claimed_len;\n              }\n            else if (current_type == DBUS_TYPE_STRING)\n              {\n                DBusString str;\n                _dbus_string_init_const_len (&str, p, claimed_len);\n                if (!_dbus_string_validate_utf8 (&str, 0,\n                                                 _dbus_string_get_length (&str)))\n                  return DBUS_INVALID_BAD_UTF8_IN_STRING;\n\n                p += claimed_len;\n              }\n            else if (current_type == DBUS_TYPE_ARRAY && claimed_len > 0)\n              {\n                DBusTypeReader sub;\n                DBusValidity validity;\n                const unsigned char *array_end;\n                int array_elem_type;\n\n                if (claimed_len > DBUS_MAXIMUM_ARRAY_LENGTH)\n                  return DBUS_INVALID_ARRAY_LENGTH_EXCEEDS_MAXIMUM;\n                \n                /* Remember that the reader is types only, so we can't\n                 * use it to iterate over elements. It stays the same\n                 * for all elements.\n                 */\n                _dbus_type_reader_recurse (reader, &sub);\n\n                array_end = p + claimed_len;\n\n                array_elem_type = _dbus_type_reader_get_element_type (reader);\n\n                /* avoid recursive call to validate_body_helper if this is an array\n                 * of fixed-size elements\n                 */ \n                if (dbus_type_is_fixed (array_elem_type))\n                  {\n                    /* bools need to be handled differently, because they can\n                     * have an invalid value\n                     */\n                    if (array_elem_type == DBUS_TYPE_BOOLEAN)\n                      {\n                        dbus_uint32_t v;\n                        alignment = _dbus_type_get_alignment (array_elem_type);\n\n                        while (p < array_end)\n                          {\n                            v = _dbus_unpack_uint32 (byte_order, p);\n\n                            if (!(v == 0 || v == 1))\n                              return DBUS_INVALID_BOOLEAN_NOT_ZERO_OR_ONE;\n\n                            p += alignment;\n                          }\n                      }\n\n                    else\n                      {\n                        p = array_end;\n                      }\n                  }\n\n                else\n                  {\n                    while (p < array_end)\n                      {\n                        validity = validate_body_helper (&sub, byte_order, FALSE,\n                                                         total_depth + 1,\n                                                         p, end, &p);\n                        if (validity != DBUS_VALID)\n                          return validity;\n                      }\n                  }\n\n                if (p != array_end)\n                  return DBUS_INVALID_ARRAY_LENGTH_INCORRECT;\n              }\n\n            /* check nul termination */\n            if (current_type != DBUS_TYPE_ARRAY)\n              {\n                if (p == end)\n                  return DBUS_INVALID_NOT_ENOUGH_DATA;\n\n                if (*p != '\\0')\n                  return DBUS_INVALID_STRING_MISSING_NUL;\n                ++p;\n              }\n          }\n          break;\n\n        case DBUS_TYPE_SIGNATURE:\n          {\n            dbus_uint32_t claimed_len;\n            DBusString str;\n            DBusValidity validity;\n\n            claimed_len = *p;\n            ++p;\n\n            /* 1 is for nul termination */\n            if (claimed_len + 1 > (unsigned long) (end - p))\n              return DBUS_INVALID_SIGNATURE_LENGTH_OUT_OF_BOUNDS;\n\n            _dbus_string_init_const_len (&str, p, claimed_len);\n            validity =\n              _dbus_validate_signature_with_reason (&str, 0,\n                                                    _dbus_string_get_length (&str));\n\n            if (validity != DBUS_VALID)\n              return validity;\n\n            p += claimed_len;\n\n            _dbus_assert (p < end);\n            if (*p != DBUS_TYPE_INVALID)\n              return DBUS_INVALID_SIGNATURE_MISSING_NUL;\n\n            ++p;\n\n            _dbus_verbose (\"p = %p end = %p claimed_len %u\\n\", p, end, claimed_len);\n          }\n          break;\n\n        case DBUS_TYPE_VARIANT:\n          {\n            /* 1 byte sig len, sig typecodes, align to\n             * contained-type-boundary, values.\n             */\n\n            /* In addition to normal signature validation, we need to be sure\n             * the signature contains only a single (possibly container) type.\n             */\n            dbus_uint32_t claimed_len;\n            DBusString sig;\n            DBusTypeReader sub;\n            DBusValidity validity;\n            int contained_alignment;\n            int contained_type;\n            DBusValidity reason;\n\n            claimed_len = *p;\n            ++p;\n\n            /* + 1 for nul */\n            if (claimed_len + 1 > (unsigned long) (end - p))\n              return DBUS_INVALID_VARIANT_SIGNATURE_LENGTH_OUT_OF_BOUNDS;\n\n            _dbus_string_init_const_len (&sig, p, claimed_len);\n            reason = _dbus_validate_signature_with_reason (&sig, 0,\n                                           _dbus_string_get_length (&sig));\n            if (!(reason == DBUS_VALID))\n              {\n                if (reason == DBUS_VALIDITY_UNKNOWN_OOM_ERROR)\n                  return reason;\n                else \n                  return DBUS_INVALID_VARIANT_SIGNATURE_BAD;\n              }\n\n            p += claimed_len;\n            \n            if (*p != DBUS_TYPE_INVALID)\n              return DBUS_INVALID_VARIANT_SIGNATURE_MISSING_NUL;\n            ++p;\n\n            contained_type = _dbus_first_type_in_signature (&sig, 0);\n            if (contained_type == DBUS_TYPE_INVALID)\n              return DBUS_INVALID_VARIANT_SIGNATURE_EMPTY;\n            \n            contained_alignment = _dbus_type_get_alignment (contained_type);\n            \n            a = _DBUS_ALIGN_ADDRESS (p, contained_alignment);\n            if (a > end)\n              return DBUS_INVALID_NOT_ENOUGH_DATA;\n            while (p != a)\n              {\n                if (*p != '\\0')\n                  return DBUS_INVALID_ALIGNMENT_PADDING_NOT_NUL;\n                ++p;\n              }\n\n            _dbus_type_reader_init_types_only (&sub, &sig, 0);\n\n            _dbus_assert (_dbus_type_reader_get_current_type (&sub) != DBUS_TYPE_INVALID);\n\n            validity = validate_body_helper (&sub, byte_order, FALSE,\n                                             total_depth + 1,\n                                             p, end, &p);\n            if (validity != DBUS_VALID)\n              return validity;\n\n            if (_dbus_type_reader_next (&sub))\n              return DBUS_INVALID_VARIANT_SIGNATURE_SPECIFIES_MULTIPLE_VALUES;\n\n            _dbus_assert (_dbus_type_reader_get_current_type (&sub) == DBUS_TYPE_INVALID);\n          }\n          break;\n\n        case DBUS_TYPE_DICT_ENTRY:\n        case DBUS_TYPE_STRUCT:\n          {\n            DBusTypeReader sub;\n            DBusValidity validity;\n\n            a = _DBUS_ALIGN_ADDRESS (p, 8);\n            if (a > end)\n              return DBUS_INVALID_NOT_ENOUGH_DATA;\n            while (p != a)\n              {\n                if (*p != '\\0')\n                  return DBUS_INVALID_ALIGNMENT_PADDING_NOT_NUL;\n                ++p;\n              }\n\n            _dbus_type_reader_recurse (reader, &sub);\n\n            validity = validate_body_helper (&sub, byte_order, TRUE,\n                                             total_depth + 1,\n                                             p, end, &p);\n            if (validity != DBUS_VALID)\n              return validity;\n          }\n          break;\n\n        default:\n          _dbus_assert_not_reached (\"invalid typecode in supposedly-validated signature\");\n          break;\n        }\n\n#if 0\n      _dbus_verbose (\"   validated value of type %s type reader %p type_pos %d p %p end %p %d remain\\n\",\n                     _dbus_type_to_string (current_type), reader, reader->type_pos, p, end,\n                     (int) (end - p));\n#endif\n\n      if (p > end)\n        {\n          _dbus_verbose (\"not enough data!!! p = %p end = %p end-p = %d\\n\",\n                         p, end, (int) (end - p));\n          return DBUS_INVALID_NOT_ENOUGH_DATA;\n        }\n\n      if (walk_reader_to_end)\n        _dbus_type_reader_next (reader);\n      else\n        break;\n    }\n\n  if (new_p)\n    *new_p = p;\n\n  return DBUS_VALID;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,11 +2,22 @@\n validate_body_helper (DBusTypeReader       *reader,\n                       int                   byte_order,\n                       dbus_bool_t           walk_reader_to_end,\n+                      int                   total_depth,\n                       const unsigned char  *p,\n                       const unsigned char  *end,\n                       const unsigned char **new_p)\n {\n   int current_type;\n+\n+  /* The spec allows arrays and structs to each nest 32, for total\n+   * nesting of 2*32. We want to impose the same limit on \"dynamic\"\n+   * value nesting (not visible in the signature) which is introduced\n+   * by DBUS_TYPE_VARIANT.\n+   */\n+  if (total_depth > (DBUS_MAXIMUM_TYPE_RECURSION_DEPTH * 2))\n+    {\n+      return DBUS_INVALID_NESTED_TOO_DEEPLY;\n+    }\n \n   while ((current_type = _dbus_type_reader_get_current_type (reader)) != DBUS_TYPE_INVALID)\n     {\n@@ -184,7 +195,9 @@\n                   {\n                     while (p < array_end)\n                       {\n-                        validity = validate_body_helper (&sub, byte_order, FALSE, p, end, &p);\n+                        validity = validate_body_helper (&sub, byte_order, FALSE,\n+                                                         total_depth + 1,\n+                                                         p, end, &p);\n                         if (validity != DBUS_VALID)\n                           return validity;\n                       }\n@@ -301,7 +314,9 @@\n \n             _dbus_assert (_dbus_type_reader_get_current_type (&sub) != DBUS_TYPE_INVALID);\n \n-            validity = validate_body_helper (&sub, byte_order, FALSE, p, end, &p);\n+            validity = validate_body_helper (&sub, byte_order, FALSE,\n+                                             total_depth + 1,\n+                                             p, end, &p);\n             if (validity != DBUS_VALID)\n               return validity;\n \n@@ -330,7 +345,9 @@\n \n             _dbus_type_reader_recurse (reader, &sub);\n \n-            validity = validate_body_helper (&sub, byte_order, TRUE, p, end, &p);\n+            validity = validate_body_helper (&sub, byte_order, TRUE,\n+                                             total_depth + 1,\n+                                             p, end, &p);\n             if (validity != DBUS_VALID)\n               return validity;\n           }",
        "diff_line_info": {
            "deleted_lines": [
                "                        validity = validate_body_helper (&sub, byte_order, FALSE, p, end, &p);",
                "            validity = validate_body_helper (&sub, byte_order, FALSE, p, end, &p);",
                "            validity = validate_body_helper (&sub, byte_order, TRUE, p, end, &p);"
            ],
            "added_lines": [
                "                      int                   total_depth,",
                "",
                "  /* The spec allows arrays and structs to each nest 32, for total",
                "   * nesting of 2*32. We want to impose the same limit on \"dynamic\"",
                "   * value nesting (not visible in the signature) which is introduced",
                "   * by DBUS_TYPE_VARIANT.",
                "   */",
                "  if (total_depth > (DBUS_MAXIMUM_TYPE_RECURSION_DEPTH * 2))",
                "    {",
                "      return DBUS_INVALID_NESTED_TOO_DEEPLY;",
                "    }",
                "                        validity = validate_body_helper (&sub, byte_order, FALSE,",
                "                                                         total_depth + 1,",
                "                                                         p, end, &p);",
                "            validity = validate_body_helper (&sub, byte_order, FALSE,",
                "                                             total_depth + 1,",
                "                                             p, end, &p);",
                "            validity = validate_body_helper (&sub, byte_order, TRUE,",
                "                                             total_depth + 1,",
                "                                             p, end, &p);"
            ]
        }
    },
    {
        "cve_id": "CVE-2010-4352",
        "func_name": "dbus/generate_special",
        "description": "Stack consumption vulnerability in D-Bus (aka DBus) before 1.4.1 allows local users to cause a denial of service (daemon crash) via a message containing many nested variants.",
        "git_url": "http://cgit.freedesktop.org/dbus/dbus/commit/?id=7d65a3a6ed8815e34a99c680ac3869fde49dbbd4",
        "commit_title": "Add DBUS_INVALID_NESTED_TOO_DEEPLY validity problem and a test that",
        "commit_text": "should generate it.  Previously, we rejected deep nesting in the signature, but variants allow dynamic message nesting, conditional only on the depth of the message body.  The nesting limit is 64, which was also the limit in static signatures.  Empirically, dynamic nesting depth observed on my Fedora 14 system doesn't exceed 2; 64 is really a huge limit.  https://bugs.freedesktop.org/show_bug.cgi?id=32321  Signed-Off-By: Colin Walters <walters@verbum.org> ",
        "func_before": "static dbus_bool_t\ngenerate_special (DBusMessageDataIter   *iter,\n                  DBusString            *data,\n                  DBusValidity          *expected_validity)\n{\n  int item_seq;\n  DBusMessage *message;\n  int pos;\n  dbus_int32_t v_INT32;\n\n  _dbus_assert (_dbus_string_get_length (data) == 0);\n  \n  message = NULL;\n  pos = -1;\n  v_INT32 = 42;\n  item_seq = iter_get_sequence (iter);\n\n  if (item_seq == 0)\n    {\n      message = simple_method_call ();\n      if (!dbus_message_append_args (message,\n                                     DBUS_TYPE_INT32, &v_INT32,\n                                     DBUS_TYPE_INT32, &v_INT32,\n                                     DBUS_TYPE_INT32, &v_INT32,\n                                     DBUS_TYPE_INVALID))\n        _dbus_assert_not_reached (\"oom\");\n                                     \n      _dbus_header_get_field_raw (&message->header,\n                                  DBUS_HEADER_FIELD_SIGNATURE,\n                                  NULL, &pos);\n      generate_from_message (data, expected_validity, message);\n      \n      /* set an invalid typecode */\n      _dbus_string_set_byte (data, pos + 1, '$');\n\n      *expected_validity = DBUS_INVALID_UNKNOWN_TYPECODE;\n    }\n  else if (item_seq == 1)\n    {\n      char long_sig[DBUS_MAXIMUM_TYPE_RECURSION_DEPTH+2];\n      const char *v_STRING;\n      int i;\n      \n      message = simple_method_call ();\n      if (!dbus_message_append_args (message,\n                                     DBUS_TYPE_INT32, &v_INT32,\n                                     DBUS_TYPE_INT32, &v_INT32,\n                                     DBUS_TYPE_INT32, &v_INT32,\n                                     DBUS_TYPE_INVALID))\n        _dbus_assert_not_reached (\"oom\");\n\n      i = 0;\n      while (i < (DBUS_MAXIMUM_TYPE_RECURSION_DEPTH + 1))\n        {\n          long_sig[i] = DBUS_TYPE_ARRAY;\n          ++i;\n        }\n      long_sig[i] = DBUS_TYPE_INVALID;\n\n      v_STRING = long_sig;\n      if (!_dbus_header_set_field_basic (&message->header,\n                                         DBUS_HEADER_FIELD_SIGNATURE,\n                                         DBUS_TYPE_SIGNATURE,\n                                         &v_STRING))\n        _dbus_assert_not_reached (\"oom\");\n      \n      _dbus_header_get_field_raw (&message->header,\n                                  DBUS_HEADER_FIELD_SIGNATURE,\n                                  NULL, &pos);\n      generate_from_message (data, expected_validity, message);\n      \n      *expected_validity = DBUS_INVALID_EXCEEDED_MAXIMUM_ARRAY_RECURSION;\n    }\n  else if (item_seq == 2)\n    {\n      char long_sig[DBUS_MAXIMUM_TYPE_RECURSION_DEPTH*2+4];\n      const char *v_STRING;\n      int i;\n      \n      message = simple_method_call ();\n      if (!dbus_message_append_args (message,\n                                     DBUS_TYPE_INT32, &v_INT32,\n                                     DBUS_TYPE_INT32, &v_INT32,\n                                     DBUS_TYPE_INT32, &v_INT32,\n                                     DBUS_TYPE_INVALID))\n        _dbus_assert_not_reached (\"oom\");\n\n      i = 0;\n      while (i <= (DBUS_MAXIMUM_TYPE_RECURSION_DEPTH + 1))\n        {\n          long_sig[i] = DBUS_STRUCT_BEGIN_CHAR;\n          ++i;\n        }\n\n      long_sig[i] = DBUS_TYPE_INT32;\n      ++i;\n\n      while (i < (DBUS_MAXIMUM_TYPE_RECURSION_DEPTH*2 + 3))\n        {\n          long_sig[i] = DBUS_STRUCT_END_CHAR;\n          ++i;\n        }\n      long_sig[i] = DBUS_TYPE_INVALID;\n      \n      v_STRING = long_sig;\n      if (!_dbus_header_set_field_basic (&message->header,\n                                         DBUS_HEADER_FIELD_SIGNATURE,\n                                         DBUS_TYPE_SIGNATURE,\n                                         &v_STRING))\n        _dbus_assert_not_reached (\"oom\");\n      \n      _dbus_header_get_field_raw (&message->header,\n                                  DBUS_HEADER_FIELD_SIGNATURE,\n                                  NULL, &pos);\n      generate_from_message (data, expected_validity, message);\n      \n      *expected_validity = DBUS_INVALID_EXCEEDED_MAXIMUM_STRUCT_RECURSION;\n    }\n  else if (item_seq == 3)\n    {\n      message = simple_method_call ();\n      if (!dbus_message_append_args (message,\n                                     DBUS_TYPE_INT32, &v_INT32,\n                                     DBUS_TYPE_INT32, &v_INT32,\n                                     DBUS_TYPE_INT32, &v_INT32,\n                                     DBUS_TYPE_INVALID))\n        _dbus_assert_not_reached (\"oom\");\n                                     \n      _dbus_header_get_field_raw (&message->header,\n                                  DBUS_HEADER_FIELD_SIGNATURE,\n                                  NULL, &pos);\n      generate_from_message (data, expected_validity, message);\n      \n      _dbus_string_set_byte (data, pos + 1, DBUS_STRUCT_BEGIN_CHAR);\n      \n      *expected_validity = DBUS_INVALID_STRUCT_STARTED_BUT_NOT_ENDED;\n    }\n  else if (item_seq == 4)\n    {\n      message = simple_method_call ();\n      if (!dbus_message_append_args (message,\n                                     DBUS_TYPE_INT32, &v_INT32,\n                                     DBUS_TYPE_INT32, &v_INT32,\n                                     DBUS_TYPE_INT32, &v_INT32,\n                                     DBUS_TYPE_INVALID))\n        _dbus_assert_not_reached (\"oom\");\n                                     \n      _dbus_header_get_field_raw (&message->header,\n                                  DBUS_HEADER_FIELD_SIGNATURE,\n                                  NULL, &pos);\n      generate_from_message (data, expected_validity, message);\n      \n      _dbus_string_set_byte (data, pos + 1, DBUS_STRUCT_END_CHAR);\n      \n      *expected_validity = DBUS_INVALID_STRUCT_ENDED_BUT_NOT_STARTED;\n    }\n  else if (item_seq == 5)\n    {\n      message = simple_method_call ();\n      if (!dbus_message_append_args (message,\n                                     DBUS_TYPE_INT32, &v_INT32,\n                                     DBUS_TYPE_INT32, &v_INT32,\n                                     DBUS_TYPE_INT32, &v_INT32,\n                                     DBUS_TYPE_INVALID))\n        _dbus_assert_not_reached (\"oom\");\n                                     \n      _dbus_header_get_field_raw (&message->header,\n                                  DBUS_HEADER_FIELD_SIGNATURE,\n                                  NULL, &pos);\n      generate_from_message (data, expected_validity, message);\n      \n      _dbus_string_set_byte (data, pos + 1, DBUS_STRUCT_BEGIN_CHAR);\n      _dbus_string_set_byte (data, pos + 2, DBUS_STRUCT_END_CHAR);\n      \n      *expected_validity = DBUS_INVALID_STRUCT_HAS_NO_FIELDS;\n    }\n  else if (item_seq == 6)\n    {\n      message = simple_method_call ();\n      generate_from_message (data, expected_validity, message);\n      \n      _dbus_string_set_byte (data, TYPE_OFFSET, DBUS_MESSAGE_TYPE_INVALID);\n      \n      *expected_validity = DBUS_INVALID_BAD_MESSAGE_TYPE;\n    }\n  else if (item_seq == 7)\n    {\n      /* Messages of unknown type are considered valid */\n      message = simple_method_call ();\n      generate_from_message (data, expected_validity, message);\n      \n      _dbus_string_set_byte (data, TYPE_OFFSET, 100);\n      \n      *expected_validity = DBUS_VALID;\n    }\n  else if (item_seq == 8)\n    {\n      message = simple_method_call ();\n      generate_from_message (data, expected_validity, message);\n      \n      _dbus_marshal_set_uint32 (data, BODY_LENGTH_OFFSET,\n                                DBUS_MAXIMUM_MESSAGE_LENGTH / 2 + 4,\n                                message->byte_order);\n      _dbus_marshal_set_uint32 (data, FIELDS_ARRAY_LENGTH_OFFSET,\n                                DBUS_MAXIMUM_MESSAGE_LENGTH / 2 + 4,\n                                message->byte_order);\n      *expected_validity = DBUS_INVALID_MESSAGE_TOO_LONG;\n    }\n  else if (item_seq == 9)\n    {\n      const char *v_STRING = \"not a valid bus name\";\n      message = simple_method_call ();\n\n      if (!_dbus_header_set_field_basic (&message->header,\n                                         DBUS_HEADER_FIELD_SENDER,\n                                         DBUS_TYPE_STRING, &v_STRING))\n        _dbus_assert_not_reached (\"oom\");\n      \n      generate_from_message (data, expected_validity, message);\n\n      *expected_validity = DBUS_INVALID_BAD_SENDER;\n    }\n  else if (item_seq == 10)\n    {\n      message = simple_method_call ();\n\n      if (!dbus_message_set_interface (message, DBUS_INTERFACE_LOCAL))\n        _dbus_assert_not_reached (\"oom\");\n      \n      generate_from_message (data, expected_validity, message);\n\n      *expected_validity = DBUS_INVALID_USES_LOCAL_INTERFACE;\n    }\n  else if (item_seq == 11)\n    {\n      message = simple_method_call ();\n\n      if (!dbus_message_set_path (message, DBUS_PATH_LOCAL))\n        _dbus_assert_not_reached (\"oom\");\n      \n      generate_from_message (data, expected_validity, message);\n\n      *expected_validity = DBUS_INVALID_USES_LOCAL_PATH;\n    }\n  else if (item_seq == 12)\n    {\n      /* Method calls don't have to have interface */\n      message = simple_method_call ();\n\n      if (!dbus_message_set_interface (message, NULL))\n        _dbus_assert_not_reached (\"oom\");\n      \n      generate_from_message (data, expected_validity, message);\n      \n      *expected_validity = DBUS_VALID;\n    }\n  else if (item_seq == 13)\n    {\n      /* Signals require an interface */\n      message = simple_signal ();\n\n      if (!dbus_message_set_interface (message, NULL))\n        _dbus_assert_not_reached (\"oom\");\n      \n      generate_from_message (data, expected_validity, message);\n      \n      *expected_validity = DBUS_INVALID_MISSING_INTERFACE;\n    }\n  else if (item_seq == 14)\n    {\n      message = simple_method_return ();\n\n      if (!_dbus_header_delete_field (&message->header, DBUS_HEADER_FIELD_REPLY_SERIAL))\n        _dbus_assert_not_reached (\"oom\");\n      \n      generate_from_message (data, expected_validity, message);\n      \n      *expected_validity = DBUS_INVALID_MISSING_REPLY_SERIAL;\n    }\n  else if (item_seq == 15)\n    {\n      message = simple_error ();\n\n      if (!dbus_message_set_error_name (message, NULL))\n        _dbus_assert_not_reached (\"oom\");\n      \n      generate_from_message (data, expected_validity, message);\n      \n      *expected_validity = DBUS_INVALID_MISSING_ERROR_NAME;\n    }\n  else if (item_seq == 16)\n    {\n      char long_sig[DBUS_MAXIMUM_TYPE_RECURSION_DEPTH*4+10];\n      const char *v_STRING;\n      int i;\n      int n_begins;\n      \n      message = simple_method_call ();\n      if (!dbus_message_append_args (message,\n                                     DBUS_TYPE_INT32, &v_INT32,\n                                     DBUS_TYPE_INT32, &v_INT32,\n                                     DBUS_TYPE_INT32, &v_INT32,\n                                     DBUS_TYPE_INVALID))\n        _dbus_assert_not_reached (\"oom\");\n\n      i = 0;\n      while (i <= (DBUS_MAXIMUM_TYPE_RECURSION_DEPTH*3 + 3))\n        {\n          long_sig[i] = DBUS_TYPE_ARRAY;\n          ++i;\n          long_sig[i] = DBUS_DICT_ENTRY_BEGIN_CHAR;\n          ++i;\n          long_sig[i] = DBUS_TYPE_INT32;\n          ++i;\n        }\n      n_begins = i / 3;\n\n      long_sig[i] = DBUS_TYPE_INT32;\n      ++i;\n      \n      while (n_begins > 0)\n        {\n          long_sig[i] = DBUS_DICT_ENTRY_END_CHAR;\n          ++i;\n          n_begins -= 1;\n        }\n      long_sig[i] = DBUS_TYPE_INVALID;\n      \n      v_STRING = long_sig;\n      if (!_dbus_header_set_field_basic (&message->header,\n                                         DBUS_HEADER_FIELD_SIGNATURE,\n                                         DBUS_TYPE_SIGNATURE,\n                                         &v_STRING))\n        _dbus_assert_not_reached (\"oom\");\n      \n      _dbus_header_get_field_raw (&message->header,\n                                  DBUS_HEADER_FIELD_SIGNATURE,\n                                  NULL, &pos);\n      generate_from_message (data, expected_validity, message);\n      \n      *expected_validity = DBUS_INVALID_EXCEEDED_MAXIMUM_DICT_ENTRY_RECURSION;\n    }\n  else if (item_seq == 17)\n    {\n      message = simple_method_call ();\n      if (!dbus_message_append_args (message,\n                                     DBUS_TYPE_INT32, &v_INT32,\n                                     DBUS_TYPE_INT32, &v_INT32,\n                                     DBUS_TYPE_INT32, &v_INT32,\n                                     DBUS_TYPE_INVALID))\n        _dbus_assert_not_reached (\"oom\");\n                                     \n      _dbus_header_get_field_raw (&message->header,\n                                  DBUS_HEADER_FIELD_SIGNATURE,\n                                  NULL, &pos);\n      generate_from_message (data, expected_validity, message);\n\n      _dbus_string_set_byte (data, pos + 1, DBUS_TYPE_ARRAY);\n      _dbus_string_set_byte (data, pos + 2, DBUS_DICT_ENTRY_BEGIN_CHAR);\n      \n      *expected_validity = DBUS_INVALID_DICT_ENTRY_STARTED_BUT_NOT_ENDED;\n    }\n  else if (item_seq == 18)\n    {\n      message = simple_method_call ();\n      if (!dbus_message_append_args (message,\n                                     DBUS_TYPE_INT32, &v_INT32,\n                                     DBUS_TYPE_INT32, &v_INT32,\n                                     DBUS_TYPE_INT32, &v_INT32,\n                                     DBUS_TYPE_INVALID))\n        _dbus_assert_not_reached (\"oom\");\n                                     \n      _dbus_header_get_field_raw (&message->header,\n                                  DBUS_HEADER_FIELD_SIGNATURE,\n                                  NULL, &pos);\n      generate_from_message (data, expected_validity, message);\n      \n      _dbus_string_set_byte (data, pos + 1, DBUS_DICT_ENTRY_END_CHAR);\n      \n      *expected_validity = DBUS_INVALID_DICT_ENTRY_ENDED_BUT_NOT_STARTED;\n    }\n  else if (item_seq == 19)\n    {\n      message = simple_method_call ();\n      if (!dbus_message_append_args (message,\n                                     DBUS_TYPE_INT32, &v_INT32,\n                                     DBUS_TYPE_INT32, &v_INT32,\n                                     DBUS_TYPE_INT32, &v_INT32,\n                                     DBUS_TYPE_INVALID))\n        _dbus_assert_not_reached (\"oom\");\n                                     \n      _dbus_header_get_field_raw (&message->header,\n                                  DBUS_HEADER_FIELD_SIGNATURE,\n                                  NULL, &pos);\n      generate_from_message (data, expected_validity, message);\n\n      _dbus_string_set_byte (data, pos + 1, DBUS_TYPE_ARRAY);\n      _dbus_string_set_byte (data, pos + 2, DBUS_DICT_ENTRY_BEGIN_CHAR);\n      _dbus_string_set_byte (data, pos + 3, DBUS_DICT_ENTRY_END_CHAR);\n      \n      *expected_validity = DBUS_INVALID_DICT_ENTRY_HAS_NO_FIELDS;\n    }\n  else\n    {\n      return FALSE;\n    }\n\n  if (message)\n    dbus_message_unref (message);\n\n  iter_next (iter);\n  return TRUE;\n}",
        "func": "static dbus_bool_t\ngenerate_special (DBusMessageDataIter   *iter,\n                  DBusString            *data,\n                  DBusValidity          *expected_validity)\n{\n  int item_seq;\n  DBusMessage *message;\n  int pos;\n  dbus_int32_t v_INT32;\n\n  _dbus_assert (_dbus_string_get_length (data) == 0);\n  \n  message = NULL;\n  pos = -1;\n  v_INT32 = 42;\n  item_seq = iter_get_sequence (iter);\n\n  if (item_seq == 0)\n    {\n      message = simple_method_call ();\n      if (!dbus_message_append_args (message,\n                                     DBUS_TYPE_INT32, &v_INT32,\n                                     DBUS_TYPE_INT32, &v_INT32,\n                                     DBUS_TYPE_INT32, &v_INT32,\n                                     DBUS_TYPE_INVALID))\n        _dbus_assert_not_reached (\"oom\");\n                                     \n      _dbus_header_get_field_raw (&message->header,\n                                  DBUS_HEADER_FIELD_SIGNATURE,\n                                  NULL, &pos);\n      generate_from_message (data, expected_validity, message);\n      \n      /* set an invalid typecode */\n      _dbus_string_set_byte (data, pos + 1, '$');\n\n      *expected_validity = DBUS_INVALID_UNKNOWN_TYPECODE;\n    }\n  else if (item_seq == 1)\n    {\n      char long_sig[DBUS_MAXIMUM_TYPE_RECURSION_DEPTH+2];\n      const char *v_STRING;\n      int i;\n      \n      message = simple_method_call ();\n      if (!dbus_message_append_args (message,\n                                     DBUS_TYPE_INT32, &v_INT32,\n                                     DBUS_TYPE_INT32, &v_INT32,\n                                     DBUS_TYPE_INT32, &v_INT32,\n                                     DBUS_TYPE_INVALID))\n        _dbus_assert_not_reached (\"oom\");\n\n      i = 0;\n      while (i < (DBUS_MAXIMUM_TYPE_RECURSION_DEPTH + 1))\n        {\n          long_sig[i] = DBUS_TYPE_ARRAY;\n          ++i;\n        }\n      long_sig[i] = DBUS_TYPE_INVALID;\n\n      v_STRING = long_sig;\n      if (!_dbus_header_set_field_basic (&message->header,\n                                         DBUS_HEADER_FIELD_SIGNATURE,\n                                         DBUS_TYPE_SIGNATURE,\n                                         &v_STRING))\n        _dbus_assert_not_reached (\"oom\");\n      \n      _dbus_header_get_field_raw (&message->header,\n                                  DBUS_HEADER_FIELD_SIGNATURE,\n                                  NULL, &pos);\n      generate_from_message (data, expected_validity, message);\n      \n      *expected_validity = DBUS_INVALID_EXCEEDED_MAXIMUM_ARRAY_RECURSION;\n    }\n  else if (item_seq == 2)\n    {\n      char long_sig[DBUS_MAXIMUM_TYPE_RECURSION_DEPTH*2+4];\n      const char *v_STRING;\n      int i;\n      \n      message = simple_method_call ();\n      if (!dbus_message_append_args (message,\n                                     DBUS_TYPE_INT32, &v_INT32,\n                                     DBUS_TYPE_INT32, &v_INT32,\n                                     DBUS_TYPE_INT32, &v_INT32,\n                                     DBUS_TYPE_INVALID))\n        _dbus_assert_not_reached (\"oom\");\n\n      i = 0;\n      while (i <= (DBUS_MAXIMUM_TYPE_RECURSION_DEPTH + 1))\n        {\n          long_sig[i] = DBUS_STRUCT_BEGIN_CHAR;\n          ++i;\n        }\n\n      long_sig[i] = DBUS_TYPE_INT32;\n      ++i;\n\n      while (i < (DBUS_MAXIMUM_TYPE_RECURSION_DEPTH*2 + 3))\n        {\n          long_sig[i] = DBUS_STRUCT_END_CHAR;\n          ++i;\n        }\n      long_sig[i] = DBUS_TYPE_INVALID;\n      \n      v_STRING = long_sig;\n      if (!_dbus_header_set_field_basic (&message->header,\n                                         DBUS_HEADER_FIELD_SIGNATURE,\n                                         DBUS_TYPE_SIGNATURE,\n                                         &v_STRING))\n        _dbus_assert_not_reached (\"oom\");\n      \n      _dbus_header_get_field_raw (&message->header,\n                                  DBUS_HEADER_FIELD_SIGNATURE,\n                                  NULL, &pos);\n      generate_from_message (data, expected_validity, message);\n      \n      *expected_validity = DBUS_INVALID_EXCEEDED_MAXIMUM_STRUCT_RECURSION;\n    }\n  else if (item_seq == 3)\n    {\n      message = simple_method_call ();\n      if (!dbus_message_append_args (message,\n                                     DBUS_TYPE_INT32, &v_INT32,\n                                     DBUS_TYPE_INT32, &v_INT32,\n                                     DBUS_TYPE_INT32, &v_INT32,\n                                     DBUS_TYPE_INVALID))\n        _dbus_assert_not_reached (\"oom\");\n                                     \n      _dbus_header_get_field_raw (&message->header,\n                                  DBUS_HEADER_FIELD_SIGNATURE,\n                                  NULL, &pos);\n      generate_from_message (data, expected_validity, message);\n      \n      _dbus_string_set_byte (data, pos + 1, DBUS_STRUCT_BEGIN_CHAR);\n      \n      *expected_validity = DBUS_INVALID_STRUCT_STARTED_BUT_NOT_ENDED;\n    }\n  else if (item_seq == 4)\n    {\n      message = simple_method_call ();\n      if (!dbus_message_append_args (message,\n                                     DBUS_TYPE_INT32, &v_INT32,\n                                     DBUS_TYPE_INT32, &v_INT32,\n                                     DBUS_TYPE_INT32, &v_INT32,\n                                     DBUS_TYPE_INVALID))\n        _dbus_assert_not_reached (\"oom\");\n                                     \n      _dbus_header_get_field_raw (&message->header,\n                                  DBUS_HEADER_FIELD_SIGNATURE,\n                                  NULL, &pos);\n      generate_from_message (data, expected_validity, message);\n      \n      _dbus_string_set_byte (data, pos + 1, DBUS_STRUCT_END_CHAR);\n      \n      *expected_validity = DBUS_INVALID_STRUCT_ENDED_BUT_NOT_STARTED;\n    }\n  else if (item_seq == 5)\n    {\n      message = simple_method_call ();\n      if (!dbus_message_append_args (message,\n                                     DBUS_TYPE_INT32, &v_INT32,\n                                     DBUS_TYPE_INT32, &v_INT32,\n                                     DBUS_TYPE_INT32, &v_INT32,\n                                     DBUS_TYPE_INVALID))\n        _dbus_assert_not_reached (\"oom\");\n                                     \n      _dbus_header_get_field_raw (&message->header,\n                                  DBUS_HEADER_FIELD_SIGNATURE,\n                                  NULL, &pos);\n      generate_from_message (data, expected_validity, message);\n      \n      _dbus_string_set_byte (data, pos + 1, DBUS_STRUCT_BEGIN_CHAR);\n      _dbus_string_set_byte (data, pos + 2, DBUS_STRUCT_END_CHAR);\n      \n      *expected_validity = DBUS_INVALID_STRUCT_HAS_NO_FIELDS;\n    }\n  else if (item_seq == 6)\n    {\n      message = simple_method_call ();\n      generate_from_message (data, expected_validity, message);\n      \n      _dbus_string_set_byte (data, TYPE_OFFSET, DBUS_MESSAGE_TYPE_INVALID);\n      \n      *expected_validity = DBUS_INVALID_BAD_MESSAGE_TYPE;\n    }\n  else if (item_seq == 7)\n    {\n      /* Messages of unknown type are considered valid */\n      message = simple_method_call ();\n      generate_from_message (data, expected_validity, message);\n      \n      _dbus_string_set_byte (data, TYPE_OFFSET, 100);\n      \n      *expected_validity = DBUS_VALID;\n    }\n  else if (item_seq == 8)\n    {\n      message = simple_method_call ();\n      generate_from_message (data, expected_validity, message);\n      \n      _dbus_marshal_set_uint32 (data, BODY_LENGTH_OFFSET,\n                                DBUS_MAXIMUM_MESSAGE_LENGTH / 2 + 4,\n                                message->byte_order);\n      _dbus_marshal_set_uint32 (data, FIELDS_ARRAY_LENGTH_OFFSET,\n                                DBUS_MAXIMUM_MESSAGE_LENGTH / 2 + 4,\n                                message->byte_order);\n      *expected_validity = DBUS_INVALID_MESSAGE_TOO_LONG;\n    }\n  else if (item_seq == 9)\n    {\n      const char *v_STRING = \"not a valid bus name\";\n      message = simple_method_call ();\n\n      if (!_dbus_header_set_field_basic (&message->header,\n                                         DBUS_HEADER_FIELD_SENDER,\n                                         DBUS_TYPE_STRING, &v_STRING))\n        _dbus_assert_not_reached (\"oom\");\n      \n      generate_from_message (data, expected_validity, message);\n\n      *expected_validity = DBUS_INVALID_BAD_SENDER;\n    }\n  else if (item_seq == 10)\n    {\n      message = simple_method_call ();\n\n      if (!dbus_message_set_interface (message, DBUS_INTERFACE_LOCAL))\n        _dbus_assert_not_reached (\"oom\");\n      \n      generate_from_message (data, expected_validity, message);\n\n      *expected_validity = DBUS_INVALID_USES_LOCAL_INTERFACE;\n    }\n  else if (item_seq == 11)\n    {\n      message = simple_method_call ();\n\n      if (!dbus_message_set_path (message, DBUS_PATH_LOCAL))\n        _dbus_assert_not_reached (\"oom\");\n      \n      generate_from_message (data, expected_validity, message);\n\n      *expected_validity = DBUS_INVALID_USES_LOCAL_PATH;\n    }\n  else if (item_seq == 12)\n    {\n      /* Method calls don't have to have interface */\n      message = simple_method_call ();\n\n      if (!dbus_message_set_interface (message, NULL))\n        _dbus_assert_not_reached (\"oom\");\n      \n      generate_from_message (data, expected_validity, message);\n      \n      *expected_validity = DBUS_VALID;\n    }\n  else if (item_seq == 13)\n    {\n      /* Signals require an interface */\n      message = simple_signal ();\n\n      if (!dbus_message_set_interface (message, NULL))\n        _dbus_assert_not_reached (\"oom\");\n      \n      generate_from_message (data, expected_validity, message);\n      \n      *expected_validity = DBUS_INVALID_MISSING_INTERFACE;\n    }\n  else if (item_seq == 14)\n    {\n      message = simple_method_return ();\n\n      if (!_dbus_header_delete_field (&message->header, DBUS_HEADER_FIELD_REPLY_SERIAL))\n        _dbus_assert_not_reached (\"oom\");\n      \n      generate_from_message (data, expected_validity, message);\n      \n      *expected_validity = DBUS_INVALID_MISSING_REPLY_SERIAL;\n    }\n  else if (item_seq == 15)\n    {\n      message = simple_error ();\n\n      if (!dbus_message_set_error_name (message, NULL))\n        _dbus_assert_not_reached (\"oom\");\n      \n      generate_from_message (data, expected_validity, message);\n      \n      *expected_validity = DBUS_INVALID_MISSING_ERROR_NAME;\n    }\n  else if (item_seq == 16)\n    {\n      char long_sig[DBUS_MAXIMUM_TYPE_RECURSION_DEPTH*4+10];\n      const char *v_STRING;\n      int i;\n      int n_begins;\n      \n      message = simple_method_call ();\n      if (!dbus_message_append_args (message,\n                                     DBUS_TYPE_INT32, &v_INT32,\n                                     DBUS_TYPE_INT32, &v_INT32,\n                                     DBUS_TYPE_INT32, &v_INT32,\n                                     DBUS_TYPE_INVALID))\n        _dbus_assert_not_reached (\"oom\");\n\n      i = 0;\n      while (i <= (DBUS_MAXIMUM_TYPE_RECURSION_DEPTH*3 + 3))\n        {\n          long_sig[i] = DBUS_TYPE_ARRAY;\n          ++i;\n          long_sig[i] = DBUS_DICT_ENTRY_BEGIN_CHAR;\n          ++i;\n          long_sig[i] = DBUS_TYPE_INT32;\n          ++i;\n        }\n      n_begins = i / 3;\n\n      long_sig[i] = DBUS_TYPE_INT32;\n      ++i;\n      \n      while (n_begins > 0)\n        {\n          long_sig[i] = DBUS_DICT_ENTRY_END_CHAR;\n          ++i;\n          n_begins -= 1;\n        }\n      long_sig[i] = DBUS_TYPE_INVALID;\n      \n      v_STRING = long_sig;\n      if (!_dbus_header_set_field_basic (&message->header,\n                                         DBUS_HEADER_FIELD_SIGNATURE,\n                                         DBUS_TYPE_SIGNATURE,\n                                         &v_STRING))\n        _dbus_assert_not_reached (\"oom\");\n      \n      _dbus_header_get_field_raw (&message->header,\n                                  DBUS_HEADER_FIELD_SIGNATURE,\n                                  NULL, &pos);\n      generate_from_message (data, expected_validity, message);\n      \n      *expected_validity = DBUS_INVALID_EXCEEDED_MAXIMUM_DICT_ENTRY_RECURSION;\n    }\n  else if (item_seq == 17)\n    {\n      message = simple_method_call ();\n      if (!dbus_message_append_args (message,\n                                     DBUS_TYPE_INT32, &v_INT32,\n                                     DBUS_TYPE_INT32, &v_INT32,\n                                     DBUS_TYPE_INT32, &v_INT32,\n                                     DBUS_TYPE_INVALID))\n        _dbus_assert_not_reached (\"oom\");\n                                     \n      _dbus_header_get_field_raw (&message->header,\n                                  DBUS_HEADER_FIELD_SIGNATURE,\n                                  NULL, &pos);\n      generate_from_message (data, expected_validity, message);\n\n      _dbus_string_set_byte (data, pos + 1, DBUS_TYPE_ARRAY);\n      _dbus_string_set_byte (data, pos + 2, DBUS_DICT_ENTRY_BEGIN_CHAR);\n      \n      *expected_validity = DBUS_INVALID_DICT_ENTRY_STARTED_BUT_NOT_ENDED;\n    }\n  else if (item_seq == 18)\n    {\n      message = simple_method_call ();\n      if (!dbus_message_append_args (message,\n                                     DBUS_TYPE_INT32, &v_INT32,\n                                     DBUS_TYPE_INT32, &v_INT32,\n                                     DBUS_TYPE_INT32, &v_INT32,\n                                     DBUS_TYPE_INVALID))\n        _dbus_assert_not_reached (\"oom\");\n                                     \n      _dbus_header_get_field_raw (&message->header,\n                                  DBUS_HEADER_FIELD_SIGNATURE,\n                                  NULL, &pos);\n      generate_from_message (data, expected_validity, message);\n      \n      _dbus_string_set_byte (data, pos + 1, DBUS_DICT_ENTRY_END_CHAR);\n      \n      *expected_validity = DBUS_INVALID_DICT_ENTRY_ENDED_BUT_NOT_STARTED;\n    }\n  else if (item_seq == 19)\n    {\n      message = simple_method_call ();\n      if (!dbus_message_append_args (message,\n                                     DBUS_TYPE_INT32, &v_INT32,\n                                     DBUS_TYPE_INT32, &v_INT32,\n                                     DBUS_TYPE_INT32, &v_INT32,\n                                     DBUS_TYPE_INVALID))\n        _dbus_assert_not_reached (\"oom\");\n                                     \n      _dbus_header_get_field_raw (&message->header,\n                                  DBUS_HEADER_FIELD_SIGNATURE,\n                                  NULL, &pos);\n      generate_from_message (data, expected_validity, message);\n\n      _dbus_string_set_byte (data, pos + 1, DBUS_TYPE_ARRAY);\n      _dbus_string_set_byte (data, pos + 2, DBUS_DICT_ENTRY_BEGIN_CHAR);\n      _dbus_string_set_byte (data, pos + 3, DBUS_DICT_ENTRY_END_CHAR);\n      \n      *expected_validity = DBUS_INVALID_DICT_ENTRY_HAS_NO_FIELDS;\n    }\n  else if (item_seq == 20)\n    {\n      /* 64 levels of nesting is OK */\n      message = message_with_nesting_levels(64);\n\n      generate_from_message (data, expected_validity, message);\n\n      *expected_validity = DBUS_VALID;\n    }\n  else if (item_seq == 21)\n    {\n      /* 65 levels of nesting is not OK */\n      message = message_with_nesting_levels(65);\n\n      generate_from_message (data, expected_validity, message);\n\n      *expected_validity = DBUS_INVALID_NESTED_TOO_DEEPLY;\n    }\n  else\n    {\n      return FALSE;\n    }\n\n  if (message)\n    dbus_message_unref (message);\n\n  iter_next (iter);\n  return TRUE;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -400,6 +400,24 @@\n       \n       *expected_validity = DBUS_INVALID_DICT_ENTRY_HAS_NO_FIELDS;\n     }\n+  else if (item_seq == 20)\n+    {\n+      /* 64 levels of nesting is OK */\n+      message = message_with_nesting_levels(64);\n+\n+      generate_from_message (data, expected_validity, message);\n+\n+      *expected_validity = DBUS_VALID;\n+    }\n+  else if (item_seq == 21)\n+    {\n+      /* 65 levels of nesting is not OK */\n+      message = message_with_nesting_levels(65);\n+\n+      generate_from_message (data, expected_validity, message);\n+\n+      *expected_validity = DBUS_INVALID_NESTED_TOO_DEEPLY;\n+    }\n   else\n     {\n       return FALSE;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "  else if (item_seq == 20)",
                "    {",
                "      /* 64 levels of nesting is OK */",
                "      message = message_with_nesting_levels(64);",
                "",
                "      generate_from_message (data, expected_validity, message);",
                "",
                "      *expected_validity = DBUS_VALID;",
                "    }",
                "  else if (item_seq == 21)",
                "    {",
                "      /* 65 levels of nesting is not OK */",
                "      message = message_with_nesting_levels(65);",
                "",
                "      generate_from_message (data, expected_validity, message);",
                "",
                "      *expected_validity = DBUS_INVALID_NESTED_TOO_DEEPLY;",
                "    }"
            ]
        }
    },
    {
        "cve_id": "CVE-2011-0991",
        "func_name": "mono/mono_reflection_create_dynamic_method",
        "description": "Use-after-free vulnerability in Mono, when Moonlight 2.x before 2.4.1 or 3.x before 3.99.3 is used, allows remote attackers to cause a denial of service or possibly have unspecified other impact via vectors related to finalizing and then resurrecting a DynamicMethod instance.",
        "git_url": "https://github.com/mono/mono/commit/3f8ee42b8c867d9a4c18c22657840d072cca5c3a",
        "commit_title": "    Don't use finalization to cleanup dynamic methods.",
        "commit_text": "         * reflection.c: Use a reference queue to cleanup         dynamic methods instead of finalization.          * runtime.c: Shutdown the dynamic method queue         before runtime cleanup begins.          * DynamicMethod.cs: No longer finalizable.          * icall-def.h: Remove unused dynamic method icall.          Fixes #660422      Implement a reference queue API.          * gc.c: A reference queue allows one to queue         callbcks for when objects are collected.         It allows for safe cleanup of objects that can         only be done when it is effectively collected.         The major difference with regular finalization         is that the collector makes sure the object         was collected - and can't be resurrected.          * gc-internal.h: Export entrypoints for the         new API.",
        "func_before": "void \nmono_reflection_create_dynamic_method (MonoReflectionDynamicMethod *mb)\n{\n\tReflectionMethodBuilder rmb;\n\tMonoMethodSignature *sig;\n\tMonoClass *klass;\n\tGSList *l;\n\tint i;\n\n\tsig = dynamic_method_to_signature (mb);\n\n\treflection_methodbuilder_from_dynamic_method (&rmb, mb);\n\n\t/*\n\t * Resolve references.\n\t */\n\t/* \n\t * Every second entry in the refs array is reserved for storing handle_class,\n\t * which is needed by the ldtoken implementation in the JIT.\n\t */\n\trmb.nrefs = mb->nrefs;\n\trmb.refs = g_new0 (gpointer, mb->nrefs + 1);\n\tfor (i = 0; i < mb->nrefs; i += 2) {\n\t\tMonoClass *handle_class;\n\t\tgpointer ref;\n\t\tMonoObject *obj = mono_array_get (mb->refs, MonoObject*, i);\n\n\t\tif (strcmp (obj->vtable->klass->name, \"DynamicMethod\") == 0) {\n\t\t\tMonoReflectionDynamicMethod *method = (MonoReflectionDynamicMethod*)obj;\n\t\t\t/*\n\t\t\t * The referenced DynamicMethod should already be created by the managed\n\t\t\t * code, except in the case of circular references. In that case, we store\n\t\t\t * method in the refs array, and fix it up later when the referenced \n\t\t\t * DynamicMethod is created.\n\t\t\t */\n\t\t\tif (method->mhandle) {\n\t\t\t\tref = method->mhandle;\n\t\t\t} else {\n\t\t\t\t/* FIXME: GC object stored in unmanaged memory */\n\t\t\t\tref = method;\n\n\t\t\t\t/* FIXME: GC object stored in unmanaged memory */\n\t\t\t\tmethod->referenced_by = g_slist_append (method->referenced_by, mb);\n\t\t\t}\n\t\t\thandle_class = mono_defaults.methodhandle_class;\n\t\t} else {\n\t\t\tMonoException *ex = NULL;\n\t\t\tref = resolve_object (mb->module->image, obj, &handle_class, NULL);\n\t\t\tif (!ref)\n\t\t\t\tex = mono_get_exception_type_load (NULL, NULL);\n\t\t\telse if (mono_security_get_mode () == MONO_SECURITY_MODE_CORE_CLR)\n\t\t\t\tex = mono_security_core_clr_ensure_dynamic_method_resolved_object (ref, handle_class);\n\n\t\t\tif (ex) {\n\t\t\t\tg_free (rmb.refs);\n\t\t\t\tmono_raise_exception (ex);\n\t\t\t\treturn;\n\t\t\t}\n\t\t}\n\n\t\trmb.refs [i] = ref; /* FIXME: GC object stored in unmanaged memory (change also resolve_object() signature) */\n\t\trmb.refs [i + 1] = handle_class;\n\t}\t\t\n\n\tklass = mb->owner ? mono_class_from_mono_type (mono_reflection_type_get_handle ((MonoReflectionType*)mb->owner)) : mono_defaults.object_class;\n\n\tmb->mhandle = reflection_methodbuilder_to_mono_method (klass, &rmb, sig);\n\n\t/* Fix up refs entries pointing at us */\n\tfor (l = mb->referenced_by; l; l = l->next) {\n\t\tMonoReflectionDynamicMethod *method = (MonoReflectionDynamicMethod*)l->data;\n\t\tMonoMethodWrapper *wrapper = (MonoMethodWrapper*)method->mhandle;\n\t\tgpointer *data;\n\t\t\n\t\tg_assert (method->mhandle);\n\n\t\tdata = (gpointer*)wrapper->method_data;\n\t\tfor (i = 0; i < GPOINTER_TO_UINT (data [0]); i += 2) {\n\t\t\tif ((data [i + 1] == mb) && (data [i + 1 + 1] == mono_defaults.methodhandle_class))\n\t\t\t\tdata [i + 1] = mb->mhandle;\n\t\t}\n\t}\n\tg_slist_free (mb->referenced_by);\n\n\tg_free (rmb.refs);\n\n\t/* ilgen is no longer needed */\n\tmb->ilgen = NULL;\n}",
        "func": "void \nmono_reflection_create_dynamic_method (MonoReflectionDynamicMethod *mb)\n{\n\tMonoReferenceQueue *queue;\n\tMonoMethod *handle;\n\tDynamicMethodReleaseData *release_data;\n\tReflectionMethodBuilder rmb;\n\tMonoMethodSignature *sig;\n\tMonoClass *klass;\n\tGSList *l;\n\tint i;\n\n\tif (mono_runtime_is_shutting_down ())\n\t\tmono_raise_exception (mono_get_exception_invalid_operation (\"\"));\n\n\tif (!(queue = dynamic_method_queue)) {\n\t\tmono_loader_lock ();\n\t\tif (!(queue = dynamic_method_queue))\n\t\t\tqueue = dynamic_method_queue = mono_gc_reference_queue_new (free_dynamic_method);\n\t\tmono_loader_unlock ();\n\t}\n\n\tsig = dynamic_method_to_signature (mb);\n\n\treflection_methodbuilder_from_dynamic_method (&rmb, mb);\n\n\t/*\n\t * Resolve references.\n\t */\n\t/* \n\t * Every second entry in the refs array is reserved for storing handle_class,\n\t * which is needed by the ldtoken implementation in the JIT.\n\t */\n\trmb.nrefs = mb->nrefs;\n\trmb.refs = g_new0 (gpointer, mb->nrefs + 1);\n\tfor (i = 0; i < mb->nrefs; i += 2) {\n\t\tMonoClass *handle_class;\n\t\tgpointer ref;\n\t\tMonoObject *obj = mono_array_get (mb->refs, MonoObject*, i);\n\n\t\tif (strcmp (obj->vtable->klass->name, \"DynamicMethod\") == 0) {\n\t\t\tMonoReflectionDynamicMethod *method = (MonoReflectionDynamicMethod*)obj;\n\t\t\t/*\n\t\t\t * The referenced DynamicMethod should already be created by the managed\n\t\t\t * code, except in the case of circular references. In that case, we store\n\t\t\t * method in the refs array, and fix it up later when the referenced \n\t\t\t * DynamicMethod is created.\n\t\t\t */\n\t\t\tif (method->mhandle) {\n\t\t\t\tref = method->mhandle;\n\t\t\t} else {\n\t\t\t\t/* FIXME: GC object stored in unmanaged memory */\n\t\t\t\tref = method;\n\n\t\t\t\t/* FIXME: GC object stored in unmanaged memory */\n\t\t\t\tmethod->referenced_by = g_slist_append (method->referenced_by, mb);\n\t\t\t}\n\t\t\thandle_class = mono_defaults.methodhandle_class;\n\t\t} else {\n\t\t\tMonoException *ex = NULL;\n\t\t\tref = resolve_object (mb->module->image, obj, &handle_class, NULL);\n\t\t\tif (!ref)\n\t\t\t\tex = mono_get_exception_type_load (NULL, NULL);\n\t\t\telse if (mono_security_get_mode () == MONO_SECURITY_MODE_CORE_CLR)\n\t\t\t\tex = mono_security_core_clr_ensure_dynamic_method_resolved_object (ref, handle_class);\n\n\t\t\tif (ex) {\n\t\t\t\tg_free (rmb.refs);\n\t\t\t\tmono_raise_exception (ex);\n\t\t\t\treturn;\n\t\t\t}\n\t\t}\n\n\t\trmb.refs [i] = ref; /* FIXME: GC object stored in unmanaged memory (change also resolve_object() signature) */\n\t\trmb.refs [i + 1] = handle_class;\n\t}\t\t\n\n\tklass = mb->owner ? mono_class_from_mono_type (mono_reflection_type_get_handle ((MonoReflectionType*)mb->owner)) : mono_defaults.object_class;\n\n\tmb->mhandle = handle = reflection_methodbuilder_to_mono_method (klass, &rmb, sig);\n\trelease_data = g_new (DynamicMethodReleaseData, 1);\n\trelease_data->handle = handle;\n\trelease_data->domain = mono_object_get_domain ((MonoObject*)mb);\n\tif (!mono_gc_reference_queue_add (queue, (MonoObject*)mb, release_data))\n\t\tg_free (release_data);\n\n\t/* Fix up refs entries pointing at us */\n\tfor (l = mb->referenced_by; l; l = l->next) {\n\t\tMonoReflectionDynamicMethod *method = (MonoReflectionDynamicMethod*)l->data;\n\t\tMonoMethodWrapper *wrapper = (MonoMethodWrapper*)method->mhandle;\n\t\tgpointer *data;\n\t\t\n\t\tg_assert (method->mhandle);\n\n\t\tdata = (gpointer*)wrapper->method_data;\n\t\tfor (i = 0; i < GPOINTER_TO_UINT (data [0]); i += 2) {\n\t\t\tif ((data [i + 1] == mb) && (data [i + 1 + 1] == mono_defaults.methodhandle_class))\n\t\t\t\tdata [i + 1] = mb->mhandle;\n\t\t}\n\t}\n\tg_slist_free (mb->referenced_by);\n\n\tg_free (rmb.refs);\n\n\t/* ilgen is no longer needed */\n\tmb->ilgen = NULL;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,11 +1,24 @@\n void \n mono_reflection_create_dynamic_method (MonoReflectionDynamicMethod *mb)\n {\n+\tMonoReferenceQueue *queue;\n+\tMonoMethod *handle;\n+\tDynamicMethodReleaseData *release_data;\n \tReflectionMethodBuilder rmb;\n \tMonoMethodSignature *sig;\n \tMonoClass *klass;\n \tGSList *l;\n \tint i;\n+\n+\tif (mono_runtime_is_shutting_down ())\n+\t\tmono_raise_exception (mono_get_exception_invalid_operation (\"\"));\n+\n+\tif (!(queue = dynamic_method_queue)) {\n+\t\tmono_loader_lock ();\n+\t\tif (!(queue = dynamic_method_queue))\n+\t\t\tqueue = dynamic_method_queue = mono_gc_reference_queue_new (free_dynamic_method);\n+\t\tmono_loader_unlock ();\n+\t}\n \n \tsig = dynamic_method_to_signature (mb);\n \n@@ -64,7 +77,12 @@\n \n \tklass = mb->owner ? mono_class_from_mono_type (mono_reflection_type_get_handle ((MonoReflectionType*)mb->owner)) : mono_defaults.object_class;\n \n-\tmb->mhandle = reflection_methodbuilder_to_mono_method (klass, &rmb, sig);\n+\tmb->mhandle = handle = reflection_methodbuilder_to_mono_method (klass, &rmb, sig);\n+\trelease_data = g_new (DynamicMethodReleaseData, 1);\n+\trelease_data->handle = handle;\n+\trelease_data->domain = mono_object_get_domain ((MonoObject*)mb);\n+\tif (!mono_gc_reference_queue_add (queue, (MonoObject*)mb, release_data))\n+\t\tg_free (release_data);\n \n \t/* Fix up refs entries pointing at us */\n \tfor (l = mb->referenced_by; l; l = l->next) {",
        "diff_line_info": {
            "deleted_lines": [
                "\tmb->mhandle = reflection_methodbuilder_to_mono_method (klass, &rmb, sig);"
            ],
            "added_lines": [
                "\tMonoReferenceQueue *queue;",
                "\tMonoMethod *handle;",
                "\tDynamicMethodReleaseData *release_data;",
                "",
                "\tif (mono_runtime_is_shutting_down ())",
                "\t\tmono_raise_exception (mono_get_exception_invalid_operation (\"\"));",
                "",
                "\tif (!(queue = dynamic_method_queue)) {",
                "\t\tmono_loader_lock ();",
                "\t\tif (!(queue = dynamic_method_queue))",
                "\t\t\tqueue = dynamic_method_queue = mono_gc_reference_queue_new (free_dynamic_method);",
                "\t\tmono_loader_unlock ();",
                "\t}",
                "\tmb->mhandle = handle = reflection_methodbuilder_to_mono_method (klass, &rmb, sig);",
                "\trelease_data = g_new (DynamicMethodReleaseData, 1);",
                "\trelease_data->handle = handle;",
                "\trelease_data->domain = mono_object_get_domain ((MonoObject*)mb);",
                "\tif (!mono_gc_reference_queue_add (queue, (MonoObject*)mb, release_data))",
                "\t\tg_free (release_data);"
            ]
        }
    },
    {
        "cve_id": "CVE-2011-0991",
        "func_name": "mono/mono_runtime_shutdown",
        "description": "Use-after-free vulnerability in Mono, when Moonlight 2.x before 2.4.1 or 3.x before 3.99.3 is used, allows remote attackers to cause a denial of service or possibly have unspecified other impact via vectors related to finalizing and then resurrecting a DynamicMethod instance.",
        "git_url": "https://github.com/mono/mono/commit/89d1455a80ef13cddee5d79ec00c06055da3085c",
        "commit_title": "Don't use finalization to cleanup dynamic methods.",
        "commit_text": " \t* reflection.c: Use a reference queue to cleanup \tdynamic methods instead of finalization.  \t* runtime.c: Shutdown the dynamic method queue \tbefore runtime cleanup begins.  \t* DynamicMethod.cs: No longer finalizable.  \t* icall-def.h: Remove unused dynamic method icall.  \tFixes #660422",
        "func_before": "void\nmono_runtime_shutdown (void)\n{\n\tmono_domain_foreach (fire_process_exit_event, NULL);\n}",
        "func": "void\nmono_runtime_shutdown (void)\n{\n\tmono_domain_foreach (fire_process_exit_event, NULL);\n\n\t/*From this point on, no more DM methods can be created. */\n\tmono_reflection_shutdown ();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,4 +2,7 @@\n mono_runtime_shutdown (void)\n {\n \tmono_domain_foreach (fire_process_exit_event, NULL);\n+\n+\t/*From this point on, no more DM methods can be created. */\n+\tmono_reflection_shutdown ();\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "\t/*From this point on, no more DM methods can be created. */",
                "\tmono_reflection_shutdown ();"
            ]
        }
    },
    {
        "cve_id": "CVE-2011-0991",
        "func_name": "mono/mono_reflection_create_dynamic_method",
        "description": "Use-after-free vulnerability in Mono, when Moonlight 2.x before 2.4.1 or 3.x before 3.99.3 is used, allows remote attackers to cause a denial of service or possibly have unspecified other impact via vectors related to finalizing and then resurrecting a DynamicMethod instance.",
        "git_url": "https://github.com/mono/mono/commit/89d1455a80ef13cddee5d79ec00c06055da3085c",
        "commit_title": "Don't use finalization to cleanup dynamic methods.",
        "commit_text": " \t* reflection.c: Use a reference queue to cleanup \tdynamic methods instead of finalization.  \t* runtime.c: Shutdown the dynamic method queue \tbefore runtime cleanup begins.  \t* DynamicMethod.cs: No longer finalizable.  \t* icall-def.h: Remove unused dynamic method icall.  \tFixes #660422",
        "func_before": "void \nmono_reflection_create_dynamic_method (MonoReflectionDynamicMethod *mb)\n{\n\tReflectionMethodBuilder rmb;\n\tMonoMethodSignature *sig;\n\tMonoClass *klass;\n\tGSList *l;\n\tint i;\n\n\tsig = dynamic_method_to_signature (mb);\n\n\treflection_methodbuilder_from_dynamic_method (&rmb, mb);\n\n\t/*\n\t * Resolve references.\n\t */\n\t/* \n\t * Every second entry in the refs array is reserved for storing handle_class,\n\t * which is needed by the ldtoken implementation in the JIT.\n\t */\n\trmb.nrefs = mb->nrefs;\n\trmb.refs = g_new0 (gpointer, mb->nrefs + 1);\n\tfor (i = 0; i < mb->nrefs; i += 2) {\n\t\tMonoClass *handle_class;\n\t\tgpointer ref;\n\t\tMonoObject *obj = mono_array_get (mb->refs, MonoObject*, i);\n\n\t\tif (strcmp (obj->vtable->klass->name, \"DynamicMethod\") == 0) {\n\t\t\tMonoReflectionDynamicMethod *method = (MonoReflectionDynamicMethod*)obj;\n\t\t\t/*\n\t\t\t * The referenced DynamicMethod should already be created by the managed\n\t\t\t * code, except in the case of circular references. In that case, we store\n\t\t\t * method in the refs array, and fix it up later when the referenced \n\t\t\t * DynamicMethod is created.\n\t\t\t */\n\t\t\tif (method->mhandle) {\n\t\t\t\tref = method->mhandle;\n\t\t\t} else {\n\t\t\t\t/* FIXME: GC object stored in unmanaged memory */\n\t\t\t\tref = method;\n\n\t\t\t\t/* FIXME: GC object stored in unmanaged memory */\n\t\t\t\tmethod->referenced_by = g_slist_append (method->referenced_by, mb);\n\t\t\t}\n\t\t\thandle_class = mono_defaults.methodhandle_class;\n\t\t} else {\n\t\t\tMonoException *ex = NULL;\n\t\t\tref = resolve_object (mb->module->image, obj, &handle_class, NULL);\n\t\t\tif (!ref)\n\t\t\t\tex = mono_get_exception_type_load (NULL, NULL);\n\t\t\telse if (mono_security_get_mode () == MONO_SECURITY_MODE_CORE_CLR)\n\t\t\t\tex = mono_security_core_clr_ensure_dynamic_method_resolved_object (ref, handle_class);\n\n\t\t\tif (ex) {\n\t\t\t\tg_free (rmb.refs);\n\t\t\t\tmono_raise_exception (ex);\n\t\t\t\treturn;\n\t\t\t}\n\t\t}\n\n\t\trmb.refs [i] = ref; /* FIXME: GC object stored in unmanaged memory (change also resolve_object() signature) */\n\t\trmb.refs [i + 1] = handle_class;\n\t}\t\t\n\n\tklass = mb->owner ? mono_class_from_mono_type (mono_reflection_type_get_handle ((MonoReflectionType*)mb->owner)) : mono_defaults.object_class;\n\n\tmb->mhandle = reflection_methodbuilder_to_mono_method (klass, &rmb, sig);\n\n\t/* Fix up refs entries pointing at us */\n\tfor (l = mb->referenced_by; l; l = l->next) {\n\t\tMonoReflectionDynamicMethod *method = (MonoReflectionDynamicMethod*)l->data;\n\t\tMonoMethodWrapper *wrapper = (MonoMethodWrapper*)method->mhandle;\n\t\tgpointer *data;\n\t\t\n\t\tg_assert (method->mhandle);\n\n\t\tdata = (gpointer*)wrapper->method_data;\n\t\tfor (i = 0; i < GPOINTER_TO_UINT (data [0]); i += 2) {\n\t\t\tif ((data [i + 1] == mb) && (data [i + 1 + 1] == mono_defaults.methodhandle_class))\n\t\t\t\tdata [i + 1] = mb->mhandle;\n\t\t}\n\t}\n\tg_slist_free (mb->referenced_by);\n\n\tg_free (rmb.refs);\n\n\t/* ilgen is no longer needed */\n\tmb->ilgen = NULL;\n}",
        "func": "void \nmono_reflection_create_dynamic_method (MonoReflectionDynamicMethod *mb)\n{\n\tMonoReferenceQueue *queue;\n\tMonoMethod *handle;\n\tDynamicMethodReleaseData *release_data;\n\tReflectionMethodBuilder rmb;\n\tMonoMethodSignature *sig;\n\tMonoClass *klass;\n\tGSList *l;\n\tint i;\n\n\tif (mono_runtime_is_shutting_down ())\n\t\tmono_raise_exception (mono_get_exception_invalid_operation (\"\"));\n\n\tif (!(queue = dynamic_method_queue)) {\n\t\tmono_loader_lock ();\n\t\tif (!(queue = dynamic_method_queue))\n\t\t\tqueue = dynamic_method_queue = mono_gc_reference_queue_new (free_dynamic_method);\n\t\tmono_loader_unlock ();\n\t}\n\n\tsig = dynamic_method_to_signature (mb);\n\n\treflection_methodbuilder_from_dynamic_method (&rmb, mb);\n\n\t/*\n\t * Resolve references.\n\t */\n\t/* \n\t * Every second entry in the refs array is reserved for storing handle_class,\n\t * which is needed by the ldtoken implementation in the JIT.\n\t */\n\trmb.nrefs = mb->nrefs;\n\trmb.refs = g_new0 (gpointer, mb->nrefs + 1);\n\tfor (i = 0; i < mb->nrefs; i += 2) {\n\t\tMonoClass *handle_class;\n\t\tgpointer ref;\n\t\tMonoObject *obj = mono_array_get (mb->refs, MonoObject*, i);\n\n\t\tif (strcmp (obj->vtable->klass->name, \"DynamicMethod\") == 0) {\n\t\t\tMonoReflectionDynamicMethod *method = (MonoReflectionDynamicMethod*)obj;\n\t\t\t/*\n\t\t\t * The referenced DynamicMethod should already be created by the managed\n\t\t\t * code, except in the case of circular references. In that case, we store\n\t\t\t * method in the refs array, and fix it up later when the referenced \n\t\t\t * DynamicMethod is created.\n\t\t\t */\n\t\t\tif (method->mhandle) {\n\t\t\t\tref = method->mhandle;\n\t\t\t} else {\n\t\t\t\t/* FIXME: GC object stored in unmanaged memory */\n\t\t\t\tref = method;\n\n\t\t\t\t/* FIXME: GC object stored in unmanaged memory */\n\t\t\t\tmethod->referenced_by = g_slist_append (method->referenced_by, mb);\n\t\t\t}\n\t\t\thandle_class = mono_defaults.methodhandle_class;\n\t\t} else {\n\t\t\tMonoException *ex = NULL;\n\t\t\tref = resolve_object (mb->module->image, obj, &handle_class, NULL);\n\t\t\tif (!ref)\n\t\t\t\tex = mono_get_exception_type_load (NULL, NULL);\n\t\t\telse if (mono_security_get_mode () == MONO_SECURITY_MODE_CORE_CLR)\n\t\t\t\tex = mono_security_core_clr_ensure_dynamic_method_resolved_object (ref, handle_class);\n\n\t\t\tif (ex) {\n\t\t\t\tg_free (rmb.refs);\n\t\t\t\tmono_raise_exception (ex);\n\t\t\t\treturn;\n\t\t\t}\n\t\t}\n\n\t\trmb.refs [i] = ref; /* FIXME: GC object stored in unmanaged memory (change also resolve_object() signature) */\n\t\trmb.refs [i + 1] = handle_class;\n\t}\t\t\n\n\tklass = mb->owner ? mono_class_from_mono_type (mono_reflection_type_get_handle ((MonoReflectionType*)mb->owner)) : mono_defaults.object_class;\n\n\tmb->mhandle = handle = reflection_methodbuilder_to_mono_method (klass, &rmb, sig);\n\trelease_data = g_new (DynamicMethodReleaseData, 1);\n\trelease_data->handle = handle;\n\trelease_data->domain = mono_object_get_domain ((MonoObject*)mb);\n\tif (!mono_gc_reference_queue_add (queue, (MonoObject*)mb, release_data))\n\t\tg_free (release_data);\n\n\t/* Fix up refs entries pointing at us */\n\tfor (l = mb->referenced_by; l; l = l->next) {\n\t\tMonoReflectionDynamicMethod *method = (MonoReflectionDynamicMethod*)l->data;\n\t\tMonoMethodWrapper *wrapper = (MonoMethodWrapper*)method->mhandle;\n\t\tgpointer *data;\n\t\t\n\t\tg_assert (method->mhandle);\n\n\t\tdata = (gpointer*)wrapper->method_data;\n\t\tfor (i = 0; i < GPOINTER_TO_UINT (data [0]); i += 2) {\n\t\t\tif ((data [i + 1] == mb) && (data [i + 1 + 1] == mono_defaults.methodhandle_class))\n\t\t\t\tdata [i + 1] = mb->mhandle;\n\t\t}\n\t}\n\tg_slist_free (mb->referenced_by);\n\n\tg_free (rmb.refs);\n\n\t/* ilgen is no longer needed */\n\tmb->ilgen = NULL;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,11 +1,24 @@\n void \n mono_reflection_create_dynamic_method (MonoReflectionDynamicMethod *mb)\n {\n+\tMonoReferenceQueue *queue;\n+\tMonoMethod *handle;\n+\tDynamicMethodReleaseData *release_data;\n \tReflectionMethodBuilder rmb;\n \tMonoMethodSignature *sig;\n \tMonoClass *klass;\n \tGSList *l;\n \tint i;\n+\n+\tif (mono_runtime_is_shutting_down ())\n+\t\tmono_raise_exception (mono_get_exception_invalid_operation (\"\"));\n+\n+\tif (!(queue = dynamic_method_queue)) {\n+\t\tmono_loader_lock ();\n+\t\tif (!(queue = dynamic_method_queue))\n+\t\t\tqueue = dynamic_method_queue = mono_gc_reference_queue_new (free_dynamic_method);\n+\t\tmono_loader_unlock ();\n+\t}\n \n \tsig = dynamic_method_to_signature (mb);\n \n@@ -64,7 +77,12 @@\n \n \tklass = mb->owner ? mono_class_from_mono_type (mono_reflection_type_get_handle ((MonoReflectionType*)mb->owner)) : mono_defaults.object_class;\n \n-\tmb->mhandle = reflection_methodbuilder_to_mono_method (klass, &rmb, sig);\n+\tmb->mhandle = handle = reflection_methodbuilder_to_mono_method (klass, &rmb, sig);\n+\trelease_data = g_new (DynamicMethodReleaseData, 1);\n+\trelease_data->handle = handle;\n+\trelease_data->domain = mono_object_get_domain ((MonoObject*)mb);\n+\tif (!mono_gc_reference_queue_add (queue, (MonoObject*)mb, release_data))\n+\t\tg_free (release_data);\n \n \t/* Fix up refs entries pointing at us */\n \tfor (l = mb->referenced_by; l; l = l->next) {",
        "diff_line_info": {
            "deleted_lines": [
                "\tmb->mhandle = reflection_methodbuilder_to_mono_method (klass, &rmb, sig);"
            ],
            "added_lines": [
                "\tMonoReferenceQueue *queue;",
                "\tMonoMethod *handle;",
                "\tDynamicMethodReleaseData *release_data;",
                "",
                "\tif (mono_runtime_is_shutting_down ())",
                "\t\tmono_raise_exception (mono_get_exception_invalid_operation (\"\"));",
                "",
                "\tif (!(queue = dynamic_method_queue)) {",
                "\t\tmono_loader_lock ();",
                "\t\tif (!(queue = dynamic_method_queue))",
                "\t\t\tqueue = dynamic_method_queue = mono_gc_reference_queue_new (free_dynamic_method);",
                "\t\tmono_loader_unlock ();",
                "\t}",
                "\tmb->mhandle = handle = reflection_methodbuilder_to_mono_method (klass, &rmb, sig);",
                "\trelease_data = g_new (DynamicMethodReleaseData, 1);",
                "\trelease_data->handle = handle;",
                "\trelease_data->domain = mono_object_get_domain ((MonoObject*)mb);",
                "\tif (!mono_gc_reference_queue_add (queue, (MonoObject*)mb, release_data))",
                "\t\tg_free (release_data);"
            ]
        }
    },
    {
        "cve_id": "CVE-2011-0991",
        "func_name": "mono/finalizer_thread",
        "description": "Use-after-free vulnerability in Mono, when Moonlight 2.x before 2.4.1 or 3.x before 3.99.3 is used, allows remote attackers to cause a denial of service or possibly have unspecified other impact via vectors related to finalizing and then resurrecting a DynamicMethod instance.",
        "git_url": "https://github.com/mono/mono/commit/8eb1189099e02372fd45ca1c67230eccf1edddc0",
        "commit_title": "Implement a reference queue API.",
        "commit_text": " \t* gc.c: A reference queue allows one to queue \tcallbcks for when objects are collected. \tIt allows for safe cleanup of objects that can \tonly be done when it is effectively collected. \tThe major difference with regular finalization \tis that the collector makes sure the object \twas collected - and can't be resurrected.  \t* gc-internal.h: Export entrypoints for the \tnew API.",
        "func_before": "static guint32\nfinalizer_thread (gpointer unused)\n{\n\twhile (!finished) {\n\t\t/* Wait to be notified that there's at least one\n\t\t * finaliser to run\n\t\t */\n\n\t\tg_assert (mono_domain_get () == mono_get_root_domain ());\n\n#ifdef MONO_HAS_SEMAPHORES\n\t\tMONO_SEM_WAIT (&finalizer_sem);\n#else\n\t\t/* Use alertable=FALSE since we will be asked to exit using the event too */\n\t\tWaitForSingleObjectEx (finalizer_event, INFINITE, FALSE);\n#endif\n\n\t\tmono_console_handle_async_ops ();\n\n#ifndef DISABLE_ATTACH\n\t\tmono_attach_maybe_start ();\n#endif\n\n\t\tif (domains_to_finalize) {\n\t\t\tmono_finalizer_lock ();\n\t\t\tif (domains_to_finalize) {\n\t\t\t\tDomainFinalizationReq *req = domains_to_finalize->data;\n\t\t\t\tdomains_to_finalize = g_slist_remove (domains_to_finalize, req);\n\t\t\t\tmono_finalizer_unlock ();\n\n\t\t\t\tfinalize_domain_objects (req);\n\t\t\t} else {\n\t\t\t\tmono_finalizer_unlock ();\n\t\t\t}\n\t\t}\t\t\t\t\n\n\t\t/* If finished == TRUE, mono_gc_cleanup has been called (from mono_runtime_cleanup),\n\t\t * before the domain is unloaded.\n\t\t */\n\t\tmono_gc_invoke_finalizers ();\n\n\t\tSetEvent (pending_done_event);\n\t}\n\n\tSetEvent (shutdown_event);\n\treturn 0;\n}",
        "func": "static guint32\nfinalizer_thread (gpointer unused)\n{\n\twhile (!finished) {\n\t\t/* Wait to be notified that there's at least one\n\t\t * finaliser to run\n\t\t */\n\n\t\tg_assert (mono_domain_get () == mono_get_root_domain ());\n\n#ifdef MONO_HAS_SEMAPHORES\n\t\tMONO_SEM_WAIT (&finalizer_sem);\n#else\n\t\t/* Use alertable=FALSE since we will be asked to exit using the event too */\n\t\tWaitForSingleObjectEx (finalizer_event, INFINITE, FALSE);\n#endif\n\n\t\tmono_console_handle_async_ops ();\n\n#ifndef DISABLE_ATTACH\n\t\tmono_attach_maybe_start ();\n#endif\n\n\t\treference_queue_proccess_all ();\n\n\t\tif (domains_to_finalize) {\n\t\t\tmono_finalizer_lock ();\n\t\t\tif (domains_to_finalize) {\n\t\t\t\tDomainFinalizationReq *req = domains_to_finalize->data;\n\t\t\t\tdomains_to_finalize = g_slist_remove (domains_to_finalize, req);\n\t\t\t\tmono_finalizer_unlock ();\n\n\t\t\t\tfinalize_domain_objects (req);\n\t\t\t} else {\n\t\t\t\tmono_finalizer_unlock ();\n\t\t\t}\n\t\t}\t\t\t\t\n\n\t\t/* If finished == TRUE, mono_gc_cleanup has been called (from mono_runtime_cleanup),\n\t\t * before the domain is unloaded.\n\t\t */\n\t\tmono_gc_invoke_finalizers ();\n\n\n\t\tSetEvent (pending_done_event);\n\t}\n\n\tSetEvent (shutdown_event);\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -21,6 +21,8 @@\n \t\tmono_attach_maybe_start ();\n #endif\n \n+\t\treference_queue_proccess_all ();\n+\n \t\tif (domains_to_finalize) {\n \t\t\tmono_finalizer_lock ();\n \t\t\tif (domains_to_finalize) {\n@@ -39,6 +41,7 @@\n \t\t */\n \t\tmono_gc_invoke_finalizers ();\n \n+\n \t\tSetEvent (pending_done_event);\n \t}\n ",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t\treference_queue_proccess_all ();",
                "",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2011-0991",
        "func_name": "mono/mono_gc_cleanup",
        "description": "Use-after-free vulnerability in Mono, when Moonlight 2.x before 2.4.1 or 3.x before 3.99.3 is used, allows remote attackers to cause a denial of service or possibly have unspecified other impact via vectors related to finalizing and then resurrecting a DynamicMethod instance.",
        "git_url": "https://github.com/mono/mono/commit/8eb1189099e02372fd45ca1c67230eccf1edddc0",
        "commit_title": "Implement a reference queue API.",
        "commit_text": " \t* gc.c: A reference queue allows one to queue \tcallbcks for when objects are collected. \tIt allows for safe cleanup of objects that can \tonly be done when it is effectively collected. \tThe major difference with regular finalization \tis that the collector makes sure the object \twas collected - and can't be resurrected.  \t* gc-internal.h: Export entrypoints for the \tnew API.",
        "func_before": "void\nmono_gc_cleanup (void)\n{\n#ifdef DEBUG\n\tg_message (\"%s: cleaning up finalizer\", __func__);\n#endif\n\n\tif (!gc_disabled) {\n\t\tResetEvent (shutdown_event);\n\t\tfinished = TRUE;\n\t\tif (mono_thread_internal_current () != gc_thread) {\n\t\t\tmono_gc_finalize_notify ();\n\t\t\t/* Finishing the finalizer thread, so wait a little bit... */\n\t\t\t/* MS seems to wait for about 2 seconds */\n\t\t\tif (WaitForSingleObjectEx (shutdown_event, 2000, FALSE) == WAIT_TIMEOUT) {\n\t\t\t\tint ret;\n\n\t\t\t\t/* Set a flag which the finalizer thread can check */\n\t\t\t\tsuspend_finalizers = TRUE;\n\n\t\t\t\t/* Try to abort the thread, in the hope that it is running managed code */\n\t\t\t\tmono_thread_internal_stop (gc_thread);\n\n\t\t\t\t/* Wait for it to stop */\n\t\t\t\tret = WaitForSingleObjectEx (gc_thread->handle, 100, TRUE);\n\n\t\t\t\tif (ret == WAIT_TIMEOUT) {\n\t\t\t\t\t/* \n\t\t\t\t\t * The finalizer thread refused to die. There is not much we \n\t\t\t\t\t * can do here, since the runtime is shutting down so the \n\t\t\t\t\t * state the finalizer thread depends on will vanish.\n\t\t\t\t\t */\n\t\t\t\t\tg_warning (\"Shutting down finalizer thread timed out.\");\n\t\t\t\t} else {\n\t\t\t\t\t/*\n\t\t\t\t\t * FIXME: On unix, when the above wait returns, the thread \n\t\t\t\t\t * might still be running io-layer code, or pthreads code.\n\t\t\t\t\t */\n\t\t\t\t\tSleep (100);\n\t\t\t\t}\n\n\t\t\t}\n\t\t}\n\t\tgc_thread = NULL;\n#ifdef HAVE_BOEHM_GC\n\t\tGC_finalizer_notifier = NULL;\n#endif\n\t}\n\n\tDeleteCriticalSection (&handle_section);\n\tDeleteCriticalSection (&allocator_section);\n\tDeleteCriticalSection (&finalizer_mutex);\n}",
        "func": "void\nmono_gc_cleanup (void)\n{\n#ifdef DEBUG\n\tg_message (\"%s: cleaning up finalizer\", __func__);\n#endif\n\n\tif (!gc_disabled) {\n\t\tResetEvent (shutdown_event);\n\t\tfinished = TRUE;\n\t\tif (mono_thread_internal_current () != gc_thread) {\n\t\t\tmono_gc_finalize_notify ();\n\t\t\t/* Finishing the finalizer thread, so wait a little bit... */\n\t\t\t/* MS seems to wait for about 2 seconds */\n\t\t\tif (WaitForSingleObjectEx (shutdown_event, 2000, FALSE) == WAIT_TIMEOUT) {\n\t\t\t\tint ret;\n\n\t\t\t\t/* Set a flag which the finalizer thread can check */\n\t\t\t\tsuspend_finalizers = TRUE;\n\n\t\t\t\t/* Try to abort the thread, in the hope that it is running managed code */\n\t\t\t\tmono_thread_internal_stop (gc_thread);\n\n\t\t\t\t/* Wait for it to stop */\n\t\t\t\tret = WaitForSingleObjectEx (gc_thread->handle, 100, TRUE);\n\n\t\t\t\tif (ret == WAIT_TIMEOUT) {\n\t\t\t\t\t/* \n\t\t\t\t\t * The finalizer thread refused to die. There is not much we \n\t\t\t\t\t * can do here, since the runtime is shutting down so the \n\t\t\t\t\t * state the finalizer thread depends on will vanish.\n\t\t\t\t\t */\n\t\t\t\t\tg_warning (\"Shutting down finalizer thread timed out.\");\n\t\t\t\t} else {\n\t\t\t\t\t/*\n\t\t\t\t\t * FIXME: On unix, when the above wait returns, the thread \n\t\t\t\t\t * might still be running io-layer code, or pthreads code.\n\t\t\t\t\t */\n\t\t\t\t\tSleep (100);\n\t\t\t\t}\n\n\t\t\t}\n\t\t}\n\t\tgc_thread = NULL;\n#ifdef HAVE_BOEHM_GC\n\t\tGC_finalizer_notifier = NULL;\n#endif\n\t}\n\n\tDeleteCriticalSection (&handle_section);\n\tDeleteCriticalSection (&allocator_section);\n\tDeleteCriticalSection (&finalizer_mutex);\n\tDeleteCriticalSection (&reference_queue_mutex);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -50,4 +50,5 @@\n \tDeleteCriticalSection (&handle_section);\n \tDeleteCriticalSection (&allocator_section);\n \tDeleteCriticalSection (&finalizer_mutex);\n+\tDeleteCriticalSection (&reference_queue_mutex);\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tDeleteCriticalSection (&reference_queue_mutex);"
            ]
        }
    },
    {
        "cve_id": "CVE-2011-0991",
        "func_name": "mono/mono_gc_init",
        "description": "Use-after-free vulnerability in Mono, when Moonlight 2.x before 2.4.1 or 3.x before 3.99.3 is used, allows remote attackers to cause a denial of service or possibly have unspecified other impact via vectors related to finalizing and then resurrecting a DynamicMethod instance.",
        "git_url": "https://github.com/mono/mono/commit/8eb1189099e02372fd45ca1c67230eccf1edddc0",
        "commit_title": "Implement a reference queue API.",
        "commit_text": " \t* gc.c: A reference queue allows one to queue \tcallbcks for when objects are collected. \tIt allows for safe cleanup of objects that can \tonly be done when it is effectively collected. \tThe major difference with regular finalization \tis that the collector makes sure the object \twas collected - and can't be resurrected.  \t* gc-internal.h: Export entrypoints for the \tnew API.",
        "func_before": "void\nmono_gc_init (void)\n{\n\tInitializeCriticalSection (&handle_section);\n\tInitializeCriticalSection (&allocator_section);\n\n\tInitializeCriticalSection (&finalizer_mutex);\n\n\tMONO_GC_REGISTER_ROOT_FIXED (gc_handles [HANDLE_NORMAL].entries);\n\tMONO_GC_REGISTER_ROOT_FIXED (gc_handles [HANDLE_PINNED].entries);\n\n\tmono_gc_base_init ();\n\n\tif (mono_gc_is_disabled ()) {\n\t\tgc_disabled = TRUE;\n\t\treturn;\n\t}\n\t\n\tfinalizer_event = CreateEvent (NULL, FALSE, FALSE, NULL);\n\tpending_done_event = CreateEvent (NULL, TRUE, FALSE, NULL);\n\tshutdown_event = CreateEvent (NULL, TRUE, FALSE, NULL);\n\tif (finalizer_event == NULL || pending_done_event == NULL || shutdown_event == NULL) {\n\t\tg_assert_not_reached ();\n\t}\n#ifdef MONO_HAS_SEMAPHORES\n\tMONO_SEM_INIT (&finalizer_sem, 0);\n#endif\n\n\tgc_thread = mono_thread_create_internal (mono_domain_get (), finalizer_thread, NULL, FALSE);\n\tves_icall_System_Threading_Thread_SetName_internal (gc_thread, mono_string_new (mono_domain_get (), \"Finalizer\"));\n}",
        "func": "void\nmono_gc_init (void)\n{\n\tInitializeCriticalSection (&handle_section);\n\tInitializeCriticalSection (&allocator_section);\n\n\tInitializeCriticalSection (&finalizer_mutex);\n\tInitializeCriticalSection (&reference_queue_mutex);\n\n\tMONO_GC_REGISTER_ROOT_FIXED (gc_handles [HANDLE_NORMAL].entries);\n\tMONO_GC_REGISTER_ROOT_FIXED (gc_handles [HANDLE_PINNED].entries);\n\n\tmono_gc_base_init ();\n\n\tif (mono_gc_is_disabled ()) {\n\t\tgc_disabled = TRUE;\n\t\treturn;\n\t}\n\t\n\tfinalizer_event = CreateEvent (NULL, FALSE, FALSE, NULL);\n\tpending_done_event = CreateEvent (NULL, TRUE, FALSE, NULL);\n\tshutdown_event = CreateEvent (NULL, TRUE, FALSE, NULL);\n\tif (finalizer_event == NULL || pending_done_event == NULL || shutdown_event == NULL) {\n\t\tg_assert_not_reached ();\n\t}\n#ifdef MONO_HAS_SEMAPHORES\n\tMONO_SEM_INIT (&finalizer_sem, 0);\n#endif\n\n\tgc_thread = mono_thread_create_internal (mono_domain_get (), finalizer_thread, NULL, FALSE);\n\tves_icall_System_Threading_Thread_SetName_internal (gc_thread, mono_string_new (mono_domain_get (), \"Finalizer\"));\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,6 +5,7 @@\n \tInitializeCriticalSection (&allocator_section);\n \n \tInitializeCriticalSection (&finalizer_mutex);\n+\tInitializeCriticalSection (&reference_queue_mutex);\n \n \tMONO_GC_REGISTER_ROOT_FIXED (gc_handles [HANDLE_NORMAL].entries);\n \tMONO_GC_REGISTER_ROOT_FIXED (gc_handles [HANDLE_PINNED].entries);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tInitializeCriticalSection (&reference_queue_mutex);"
            ]
        }
    },
    {
        "cve_id": "CVE-2011-0992",
        "func_name": "mono/ves_icall_System_Threading_InternalThread_Thread_free_internal",
        "description": "Use-after-free vulnerability in Mono, when Moonlight 2.x before 2.4.1 or 3.x before 3.99.3 is used, allows remote attackers to cause a denial of service (plugin crash) or obtain sensitive information via vectors related to member data in a resurrected MonoThread instance.",
        "git_url": "https://github.com/mono/mono/commit/722f9890f09aadfc37ae479e7d946d5fc5ef7b91",
        "commit_title": "Fix access to freed members of a dead thread",
        "commit_text": " * threads.c: Fix access to freed members of a dead thread. Found and fixed by Rodrigo Kumpera <rkumpera@novell.com> Ref: CVE-2011-0992",
        "func_before": "void ves_icall_System_Threading_InternalThread_Thread_free_internal (MonoInternalThread *this, HANDLE thread)\n{\n\tMONO_ARCH_SAVE_REGS;\n\n\tTHREAD_DEBUG (g_message (\"%s: Closing thread %p, handle %p\", __func__, this, thread));\n\n\tif (thread)\n\t\tCloseHandle (thread);\n\n\tif (this->synch_cs) {\n\t\tDeleteCriticalSection (this->synch_cs);\n\t\tg_free (this->synch_cs);\n\t\tthis->synch_cs = NULL;\n\t}\n\n\tg_free (this->name);\n}",
        "func": "void ves_icall_System_Threading_InternalThread_Thread_free_internal (MonoInternalThread *this, HANDLE thread)\n{\n\tMONO_ARCH_SAVE_REGS;\n\n\tTHREAD_DEBUG (g_message (\"%s: Closing thread %p, handle %p\", __func__, this, thread));\n\n\tif (thread)\n\t\tCloseHandle (thread);\n\n\tif (this->synch_cs) {\n\t\tCRITICAL_SECTION *synch_cs = this->synch_cs;\n\t\tthis->synch_cs = NULL;\n\t\tDeleteCriticalSection (synch_cs);\n\t\tg_free (synch_cs);\n\t}\n\n\tif (this->name) {\n\t\tvoid *name = this->name;\n\t\tthis->name = NULL;\n\t\tg_free (name);\n\t}\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -8,10 +8,15 @@\n \t\tCloseHandle (thread);\n \n \tif (this->synch_cs) {\n-\t\tDeleteCriticalSection (this->synch_cs);\n-\t\tg_free (this->synch_cs);\n+\t\tCRITICAL_SECTION *synch_cs = this->synch_cs;\n \t\tthis->synch_cs = NULL;\n+\t\tDeleteCriticalSection (synch_cs);\n+\t\tg_free (synch_cs);\n \t}\n \n-\tg_free (this->name);\n+\tif (this->name) {\n+\t\tvoid *name = this->name;\n+\t\tthis->name = NULL;\n+\t\tg_free (name);\n+\t}\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tDeleteCriticalSection (this->synch_cs);",
                "\t\tg_free (this->synch_cs);",
                "\tg_free (this->name);"
            ],
            "added_lines": [
                "\t\tCRITICAL_SECTION *synch_cs = this->synch_cs;",
                "\t\tDeleteCriticalSection (synch_cs);",
                "\t\tg_free (synch_cs);",
                "\tif (this->name) {",
                "\t\tvoid *name = this->name;",
                "\t\tthis->name = NULL;",
                "\t\tg_free (name);",
                "\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2011-1090",
        "func_name": "torvalds/linux/__nfs4_proc_set_acl",
        "description": "The __nfs4_proc_set_acl function in fs/nfs/nfs4proc.c in the Linux kernel before 2.6.38 stores NFSv4 ACL data in memory that is allocated by kmalloc but not properly freed, which allows local users to cause a denial of service (panic) via a crafted attempt to set an ACL.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=e9e3d724e2145f5039b423c290ce2b2c3d8f94bc",
        "commit_title": "The \"bad_page()\" page allocator sanity check was reported recently (call",
        "commit_text": "chain as follows):    bad_page+0x69/0x91   free_hot_cold_page+0x81/0x144   skb_release_data+0x5f/0x98   __kfree_skb+0x11/0x1a   tcp_ack+0x6a3/0x1868   tcp_rcv_established+0x7a6/0x8b9   tcp_v4_do_rcv+0x2a/0x2fa   tcp_v4_rcv+0x9a2/0x9f6   do_timer+0x2df/0x52c   ip_local_deliver+0x19d/0x263   ip_rcv+0x539/0x57c   netif_receive_skb+0x470/0x49f   :virtio_net:virtnet_poll+0x46b/0x5c5   net_rx_action+0xac/0x1b3   __do_softirq+0x89/0x133   call_softirq+0x1c/0x28   do_softirq+0x2c/0x7d   do_IRQ+0xec/0xf5   default_idle+0x0/0x50   ret_from_intr+0x0/0xa   default_idle+0x29/0x50   cpu_idle+0x95/0xb8   start_kernel+0x220/0x225   _sinittext+0x22f/0x236  It occurs because an skb with a fraglist was freed from the tcp retransmit queue when it was acked, but a page on that fraglist had PG_Slab set (indicating it was allocated from the Slab allocator (which means the free path above can't safely free it via put_page.  We tracked this back to an nfsv4 setacl operation, in which the nfs code attempted to fill convert the passed in buffer to an array of pages in __nfs4_proc_set_acl, which gets used by the skb->frags list in xs_sendpages.  __nfs4_proc_set_acl just converts each page in the buffer to a page struct via virt_to_page, but the vfs allocates the buffer via kmalloc, meaning the PG_slab bit is set.  We can't create a buffer with kmalloc and free it later in the tcp ack path with put_page, so we need to either:  1) ensure that when we create the list of pages, no page struct has    PG_Slab set   or  2) not use a page list to send this data  Given that these buffers can be multiple pages and arbitrarily sized, I think (1) is the right way to go.  I've written the below patch to allocate a page from the buddy allocator directly and copy the data over to it.  This ensures that we have a put_page free-able page for every entry that winds up on an skb frag list, so it can be safely freed when the frame is acked.  We do a put page on each entry after the rpc_call_sync call so as to drop our own reference count to the page, leaving only the ref count taken by tcp_sendpages.  This way the data will be properly freed when the ack comes in  Successfully tested by myself to solve the above oops.  Note, as this is the result of a setacl operation that exceeded a page of data, I think this amounts to a local DOS triggerable by an uprivlidged user, so I'm CCing security on this as well.  ",
        "func_before": "static int __nfs4_proc_set_acl(struct inode *inode, const void *buf, size_t buflen)\n{\n\tstruct nfs_server *server = NFS_SERVER(inode);\n\tstruct page *pages[NFS4ACL_MAXPAGES];\n\tstruct nfs_setaclargs arg = {\n\t\t.fh\t\t= NFS_FH(inode),\n\t\t.acl_pages\t= pages,\n\t\t.acl_len\t= buflen,\n\t};\n\tstruct nfs_setaclres res;\n\tstruct rpc_message msg = {\n\t\t.rpc_proc\t= &nfs4_procedures[NFSPROC4_CLNT_SETACL],\n\t\t.rpc_argp\t= &arg,\n\t\t.rpc_resp\t= &res,\n\t};\n\tint ret;\n\n\tif (!nfs4_server_supports_acls(server))\n\t\treturn -EOPNOTSUPP;\n\tnfs_inode_return_delegation(inode);\n\tbuf_to_pages(buf, buflen, arg.acl_pages, &arg.acl_pgbase);\n\tret = nfs4_call_sync(server, &msg, &arg, &res, 1);\n\t/*\n\t * Acl update can result in inode attribute update.\n\t * so mark the attribute cache invalid.\n\t */\n\tspin_lock(&inode->i_lock);\n\tNFS_I(inode)->cache_validity |= NFS_INO_INVALID_ATTR;\n\tspin_unlock(&inode->i_lock);\n\tnfs_access_zap_cache(inode);\n\tnfs_zap_acl_cache(inode);\n\treturn ret;\n}",
        "func": "static int __nfs4_proc_set_acl(struct inode *inode, const void *buf, size_t buflen)\n{\n\tstruct nfs_server *server = NFS_SERVER(inode);\n\tstruct page *pages[NFS4ACL_MAXPAGES];\n\tstruct nfs_setaclargs arg = {\n\t\t.fh\t\t= NFS_FH(inode),\n\t\t.acl_pages\t= pages,\n\t\t.acl_len\t= buflen,\n\t};\n\tstruct nfs_setaclres res;\n\tstruct rpc_message msg = {\n\t\t.rpc_proc\t= &nfs4_procedures[NFSPROC4_CLNT_SETACL],\n\t\t.rpc_argp\t= &arg,\n\t\t.rpc_resp\t= &res,\n\t};\n\tint ret, i;\n\n\tif (!nfs4_server_supports_acls(server))\n\t\treturn -EOPNOTSUPP;\n\ti = buf_to_pages_noslab(buf, buflen, arg.acl_pages, &arg.acl_pgbase);\n\tif (i < 0)\n\t\treturn i;\n\tnfs_inode_return_delegation(inode);\n\tret = nfs4_call_sync(server, &msg, &arg, &res, 1);\n\n\t/*\n\t * Free each page after tx, so the only ref left is\n\t * held by the network stack\n\t */\n\tfor (; i > 0; i--)\n\t\tput_page(pages[i-1]);\n\n\t/*\n\t * Acl update can result in inode attribute update.\n\t * so mark the attribute cache invalid.\n\t */\n\tspin_lock(&inode->i_lock);\n\tNFS_I(inode)->cache_validity |= NFS_INO_INVALID_ATTR;\n\tspin_unlock(&inode->i_lock);\n\tnfs_access_zap_cache(inode);\n\tnfs_zap_acl_cache(inode);\n\treturn ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -13,13 +13,23 @@\n \t\t.rpc_argp\t= &arg,\n \t\t.rpc_resp\t= &res,\n \t};\n-\tint ret;\n+\tint ret, i;\n \n \tif (!nfs4_server_supports_acls(server))\n \t\treturn -EOPNOTSUPP;\n+\ti = buf_to_pages_noslab(buf, buflen, arg.acl_pages, &arg.acl_pgbase);\n+\tif (i < 0)\n+\t\treturn i;\n \tnfs_inode_return_delegation(inode);\n-\tbuf_to_pages(buf, buflen, arg.acl_pages, &arg.acl_pgbase);\n \tret = nfs4_call_sync(server, &msg, &arg, &res, 1);\n+\n+\t/*\n+\t * Free each page after tx, so the only ref left is\n+\t * held by the network stack\n+\t */\n+\tfor (; i > 0; i--)\n+\t\tput_page(pages[i-1]);\n+\n \t/*\n \t * Acl update can result in inode attribute update.\n \t * so mark the attribute cache invalid.",
        "diff_line_info": {
            "deleted_lines": [
                "\tint ret;",
                "\tbuf_to_pages(buf, buflen, arg.acl_pages, &arg.acl_pgbase);"
            ],
            "added_lines": [
                "\tint ret, i;",
                "\ti = buf_to_pages_noslab(buf, buflen, arg.acl_pages, &arg.acl_pgbase);",
                "\tif (i < 0)",
                "\t\treturn i;",
                "",
                "\t/*",
                "\t * Free each page after tx, so the only ref left is",
                "\t * held by the network stack",
                "\t */",
                "\tfor (; i > 0; i--)",
                "\t\tput_page(pages[i-1]);",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2011-1746",
        "func_name": "torvalds/linux/agp_create_user_memory",
        "description": "Multiple integer overflows in the (1) agp_allocate_memory and (2) agp_create_user_memory functions in drivers/char/agp/generic.c in the Linux kernel before 2.6.38.5 allow local users to trigger buffer overflows, and consequently cause a denial of service (system crash) or possibly have unspecified other impact, via vectors related to calls that specify a large number of memory pages.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=b522f02184b413955f3bc952e3776ce41edc6355",
        "commit_title": "page_count is copied from userspace.  agp_allocate_memory() tries to",
        "commit_text": "check whether this number is too big, but doesn't take into account the wrap case.  Also agp_create_user_memory() doesn't check whether alloc_size is calculated from num_agp_pages variable without overflow. This may lead to allocation of too small buffer with following buffer overflow.  Another problem in agp code is not addressed in the patch - kernel memory exhaustion (AGPIOC_RESERVE and AGPIOC_ALLOCATE ioctls).  It is not checked whether requested pid is a pid of the caller (no check in agpioc_reserve_wrap()). Each allocation is limited to 16KB, though, there is no per-process limit. This might lead to OOM situation, which is not even solved in case of the caller death by OOM killer - the memory is allocated for another (faked) process.  ",
        "func_before": "static struct agp_memory *agp_create_user_memory(unsigned long num_agp_pages)\n{\n\tstruct agp_memory *new;\n\tunsigned long alloc_size = num_agp_pages*sizeof(struct page *);\n\n\tnew = kzalloc(sizeof(struct agp_memory), GFP_KERNEL);\n\tif (new == NULL)\n\t\treturn NULL;\n\n\tnew->key = agp_get_key();\n\n\tif (new->key < 0) {\n\t\tkfree(new);\n\t\treturn NULL;\n\t}\n\n\tagp_alloc_page_array(alloc_size, new);\n\n\tif (new->pages == NULL) {\n\t\tagp_free_key(new->key);\n\t\tkfree(new);\n\t\treturn NULL;\n\t}\n\tnew->num_scratch_pages = 0;\n\treturn new;\n}",
        "func": "static struct agp_memory *agp_create_user_memory(unsigned long num_agp_pages)\n{\n\tstruct agp_memory *new;\n\tunsigned long alloc_size = num_agp_pages*sizeof(struct page *);\n\n\tif (INT_MAX/sizeof(struct page *) < num_agp_pages)\n\t\treturn NULL;\n\n\tnew = kzalloc(sizeof(struct agp_memory), GFP_KERNEL);\n\tif (new == NULL)\n\t\treturn NULL;\n\n\tnew->key = agp_get_key();\n\n\tif (new->key < 0) {\n\t\tkfree(new);\n\t\treturn NULL;\n\t}\n\n\tagp_alloc_page_array(alloc_size, new);\n\n\tif (new->pages == NULL) {\n\t\tagp_free_key(new->key);\n\t\tkfree(new);\n\t\treturn NULL;\n\t}\n\tnew->num_scratch_pages = 0;\n\treturn new;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,6 +2,9 @@\n {\n \tstruct agp_memory *new;\n \tunsigned long alloc_size = num_agp_pages*sizeof(struct page *);\n+\n+\tif (INT_MAX/sizeof(struct page *) < num_agp_pages)\n+\t\treturn NULL;\n \n \tnew = kzalloc(sizeof(struct agp_memory), GFP_KERNEL);\n \tif (new == NULL)",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "\tif (INT_MAX/sizeof(struct page *) < num_agp_pages)",
                "\t\treturn NULL;"
            ]
        }
    },
    {
        "cve_id": "CVE-2011-1746",
        "func_name": "torvalds/linux/agp_allocate_memory",
        "description": "Multiple integer overflows in the (1) agp_allocate_memory and (2) agp_create_user_memory functions in drivers/char/agp/generic.c in the Linux kernel before 2.6.38.5 allow local users to trigger buffer overflows, and consequently cause a denial of service (system crash) or possibly have unspecified other impact, via vectors related to calls that specify a large number of memory pages.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=b522f02184b413955f3bc952e3776ce41edc6355",
        "commit_title": "page_count is copied from userspace.  agp_allocate_memory() tries to",
        "commit_text": "check whether this number is too big, but doesn't take into account the wrap case.  Also agp_create_user_memory() doesn't check whether alloc_size is calculated from num_agp_pages variable without overflow. This may lead to allocation of too small buffer with following buffer overflow.  Another problem in agp code is not addressed in the patch - kernel memory exhaustion (AGPIOC_RESERVE and AGPIOC_ALLOCATE ioctls).  It is not checked whether requested pid is a pid of the caller (no check in agpioc_reserve_wrap()). Each allocation is limited to 16KB, though, there is no per-process limit. This might lead to OOM situation, which is not even solved in case of the caller death by OOM killer - the memory is allocated for another (faked) process.  ",
        "func_before": "struct agp_memory *agp_allocate_memory(struct agp_bridge_data *bridge,\n\t\t\t\t\tsize_t page_count, u32 type)\n{\n\tint scratch_pages;\n\tstruct agp_memory *new;\n\tsize_t i;\n\n\tif (!bridge)\n\t\treturn NULL;\n\n\tif ((atomic_read(&bridge->current_memory_agp) + page_count) > bridge->max_memory_agp)\n\t\treturn NULL;\n\n\tif (type >= AGP_USER_TYPES) {\n\t\tnew = agp_generic_alloc_user(page_count, type);\n\t\tif (new)\n\t\t\tnew->bridge = bridge;\n\t\treturn new;\n\t}\n\n\tif (type != 0) {\n\t\tnew = bridge->driver->alloc_by_type(page_count, type);\n\t\tif (new)\n\t\t\tnew->bridge = bridge;\n\t\treturn new;\n\t}\n\n\tscratch_pages = (page_count + ENTRIES_PER_PAGE - 1) / ENTRIES_PER_PAGE;\n\n\tnew = agp_create_memory(scratch_pages);\n\n\tif (new == NULL)\n\t\treturn NULL;\n\n\tif (bridge->driver->agp_alloc_pages) {\n\t\tif (bridge->driver->agp_alloc_pages(bridge, new, page_count)) {\n\t\t\tagp_free_memory(new);\n\t\t\treturn NULL;\n\t\t}\n\t\tnew->bridge = bridge;\n\t\treturn new;\n\t}\n\n\tfor (i = 0; i < page_count; i++) {\n\t\tstruct page *page = bridge->driver->agp_alloc_page(bridge);\n\n\t\tif (page == NULL) {\n\t\t\tagp_free_memory(new);\n\t\t\treturn NULL;\n\t\t}\n\t\tnew->pages[i] = page;\n\t\tnew->page_count++;\n\t}\n\tnew->bridge = bridge;\n\n\treturn new;\n}",
        "func": "struct agp_memory *agp_allocate_memory(struct agp_bridge_data *bridge,\n\t\t\t\t\tsize_t page_count, u32 type)\n{\n\tint scratch_pages;\n\tstruct agp_memory *new;\n\tsize_t i;\n\tint cur_memory;\n\n\tif (!bridge)\n\t\treturn NULL;\n\n\tcur_memory = atomic_read(&bridge->current_memory_agp);\n\tif ((cur_memory + page_count > bridge->max_memory_agp) ||\n\t    (cur_memory + page_count < page_count))\n\t\treturn NULL;\n\n\tif (type >= AGP_USER_TYPES) {\n\t\tnew = agp_generic_alloc_user(page_count, type);\n\t\tif (new)\n\t\t\tnew->bridge = bridge;\n\t\treturn new;\n\t}\n\n\tif (type != 0) {\n\t\tnew = bridge->driver->alloc_by_type(page_count, type);\n\t\tif (new)\n\t\t\tnew->bridge = bridge;\n\t\treturn new;\n\t}\n\n\tscratch_pages = (page_count + ENTRIES_PER_PAGE - 1) / ENTRIES_PER_PAGE;\n\n\tnew = agp_create_memory(scratch_pages);\n\n\tif (new == NULL)\n\t\treturn NULL;\n\n\tif (bridge->driver->agp_alloc_pages) {\n\t\tif (bridge->driver->agp_alloc_pages(bridge, new, page_count)) {\n\t\t\tagp_free_memory(new);\n\t\t\treturn NULL;\n\t\t}\n\t\tnew->bridge = bridge;\n\t\treturn new;\n\t}\n\n\tfor (i = 0; i < page_count; i++) {\n\t\tstruct page *page = bridge->driver->agp_alloc_page(bridge);\n\n\t\tif (page == NULL) {\n\t\t\tagp_free_memory(new);\n\t\t\treturn NULL;\n\t\t}\n\t\tnew->pages[i] = page;\n\t\tnew->page_count++;\n\t}\n\tnew->bridge = bridge;\n\n\treturn new;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,11 +4,14 @@\n \tint scratch_pages;\n \tstruct agp_memory *new;\n \tsize_t i;\n+\tint cur_memory;\n \n \tif (!bridge)\n \t\treturn NULL;\n \n-\tif ((atomic_read(&bridge->current_memory_agp) + page_count) > bridge->max_memory_agp)\n+\tcur_memory = atomic_read(&bridge->current_memory_agp);\n+\tif ((cur_memory + page_count > bridge->max_memory_agp) ||\n+\t    (cur_memory + page_count < page_count))\n \t\treturn NULL;\n \n \tif (type >= AGP_USER_TYPES) {",
        "diff_line_info": {
            "deleted_lines": [
                "\tif ((atomic_read(&bridge->current_memory_agp) + page_count) > bridge->max_memory_agp)"
            ],
            "added_lines": [
                "\tint cur_memory;",
                "\tcur_memory = atomic_read(&bridge->current_memory_agp);",
                "\tif ((cur_memory + page_count > bridge->max_memory_agp) ||",
                "\t    (cur_memory + page_count < page_count))"
            ]
        }
    },
    {
        "cve_id": "CVE-2011-2161",
        "func_name": "ffmpeg/ape_read_header",
        "description": "The ape_read_header function in ape.c in libavformat in FFmpeg before 0.5.4, as used in MPlayer, VideoLAN VLC media player, and other products, allows remote attackers to cause a denial of service (application crash) via an APE (aka Monkey's Audio) file that contains a header but no frames.",
        "git_url": "https://github.com/FFmpeg/FFmpeg/commit/8312e3fc9041027a33c8bc667bb99740fdf41dd5",
        "commit_title": "Do not attempt to decode APE file with no frames",
        "commit_text": " This fixes invalid reads/writes with this sample: http://packetstorm.linuxsecurity.com/1103-exploits/vlc105-dos.txt",
        "func_before": "static int ape_read_header(AVFormatContext * s, AVFormatParameters * ap)\n{\n    AVIOContext *pb = s->pb;\n    APEContext *ape = s->priv_data;\n    AVStream *st;\n    uint32_t tag;\n    int i;\n    int total_blocks;\n    int64_t pts;\n\n    /* TODO: Skip any leading junk such as id3v2 tags */\n    ape->junklength = 0;\n\n    tag = avio_rl32(pb);\n    if (tag != MKTAG('M', 'A', 'C', ' '))\n        return -1;\n\n    ape->fileversion = avio_rl16(pb);\n\n    if (ape->fileversion < APE_MIN_VERSION || ape->fileversion > APE_MAX_VERSION) {\n        av_log(s, AV_LOG_ERROR, \"Unsupported file version - %d.%02d\\n\", ape->fileversion / 1000, (ape->fileversion % 1000) / 10);\n        return -1;\n    }\n\n    if (ape->fileversion >= 3980) {\n        ape->padding1             = avio_rl16(pb);\n        ape->descriptorlength     = avio_rl32(pb);\n        ape->headerlength         = avio_rl32(pb);\n        ape->seektablelength      = avio_rl32(pb);\n        ape->wavheaderlength      = avio_rl32(pb);\n        ape->audiodatalength      = avio_rl32(pb);\n        ape->audiodatalength_high = avio_rl32(pb);\n        ape->wavtaillength        = avio_rl32(pb);\n        avio_read(pb, ape->md5, 16);\n\n        /* Skip any unknown bytes at the end of the descriptor.\n           This is for future compatibility */\n        if (ape->descriptorlength > 52)\n            avio_seek(pb, ape->descriptorlength - 52, SEEK_CUR);\n\n        /* Read header data */\n        ape->compressiontype      = avio_rl16(pb);\n        ape->formatflags          = avio_rl16(pb);\n        ape->blocksperframe       = avio_rl32(pb);\n        ape->finalframeblocks     = avio_rl32(pb);\n        ape->totalframes          = avio_rl32(pb);\n        ape->bps                  = avio_rl16(pb);\n        ape->channels             = avio_rl16(pb);\n        ape->samplerate           = avio_rl32(pb);\n    } else {\n        ape->descriptorlength = 0;\n        ape->headerlength = 32;\n\n        ape->compressiontype      = avio_rl16(pb);\n        ape->formatflags          = avio_rl16(pb);\n        ape->channels             = avio_rl16(pb);\n        ape->samplerate           = avio_rl32(pb);\n        ape->wavheaderlength      = avio_rl32(pb);\n        ape->wavtaillength        = avio_rl32(pb);\n        ape->totalframes          = avio_rl32(pb);\n        ape->finalframeblocks     = avio_rl32(pb);\n\n        if (ape->formatflags & MAC_FORMAT_FLAG_HAS_PEAK_LEVEL) {\n            avio_seek(pb, 4, SEEK_CUR); /* Skip the peak level */\n            ape->headerlength += 4;\n        }\n\n        if (ape->formatflags & MAC_FORMAT_FLAG_HAS_SEEK_ELEMENTS) {\n            ape->seektablelength = avio_rl32(pb);\n            ape->headerlength += 4;\n            ape->seektablelength *= sizeof(int32_t);\n        } else\n            ape->seektablelength = ape->totalframes * sizeof(int32_t);\n\n        if (ape->formatflags & MAC_FORMAT_FLAG_8_BIT)\n            ape->bps = 8;\n        else if (ape->formatflags & MAC_FORMAT_FLAG_24_BIT)\n            ape->bps = 24;\n        else\n            ape->bps = 16;\n\n        if (ape->fileversion >= 3950)\n            ape->blocksperframe = 73728 * 4;\n        else if (ape->fileversion >= 3900 || (ape->fileversion >= 3800  && ape->compressiontype >= 4000))\n            ape->blocksperframe = 73728;\n        else\n            ape->blocksperframe = 9216;\n\n        /* Skip any stored wav header */\n        if (!(ape->formatflags & MAC_FORMAT_FLAG_CREATE_WAV_HEADER))\n            avio_seek(pb, ape->wavheaderlength, SEEK_CUR);\n    }\n\n    if(ape->totalframes > UINT_MAX / sizeof(APEFrame)){\n        av_log(s, AV_LOG_ERROR, \"Too many frames: %d\\n\", ape->totalframes);\n        return -1;\n    }\n    ape->frames       = av_malloc(ape->totalframes * sizeof(APEFrame));\n    if(!ape->frames)\n        return AVERROR(ENOMEM);\n    ape->firstframe   = ape->junklength + ape->descriptorlength + ape->headerlength + ape->seektablelength + ape->wavheaderlength;\n    ape->currentframe = 0;\n\n\n    ape->totalsamples = ape->finalframeblocks;\n    if (ape->totalframes > 1)\n        ape->totalsamples += ape->blocksperframe * (ape->totalframes - 1);\n\n    if (ape->seektablelength > 0) {\n        ape->seektable = av_malloc(ape->seektablelength);\n        for (i = 0; i < ape->seektablelength / sizeof(uint32_t); i++)\n            ape->seektable[i] = avio_rl32(pb);\n    }\n\n    ape->frames[0].pos     = ape->firstframe;\n    ape->frames[0].nblocks = ape->blocksperframe;\n    ape->frames[0].skip    = 0;\n    for (i = 1; i < ape->totalframes; i++) {\n        ape->frames[i].pos      = ape->seektable[i]; //ape->frames[i-1].pos + ape->blocksperframe;\n        ape->frames[i].nblocks  = ape->blocksperframe;\n        ape->frames[i - 1].size = ape->frames[i].pos - ape->frames[i - 1].pos;\n        ape->frames[i].skip     = (ape->frames[i].pos - ape->frames[0].pos) & 3;\n    }\n    ape->frames[ape->totalframes - 1].size    = ape->finalframeblocks * 4;\n    ape->frames[ape->totalframes - 1].nblocks = ape->finalframeblocks;\n\n    for (i = 0; i < ape->totalframes; i++) {\n        if(ape->frames[i].skip){\n            ape->frames[i].pos  -= ape->frames[i].skip;\n            ape->frames[i].size += ape->frames[i].skip;\n        }\n        ape->frames[i].size = (ape->frames[i].size + 3) & ~3;\n    }\n\n\n    ape_dumpinfo(s, ape);\n\n    /* try to read APE tags */\n    if (!url_is_streamed(pb)) {\n        ff_ape_parse_tag(s);\n        avio_seek(pb, 0, SEEK_SET);\n    }\n\n    av_log(s, AV_LOG_DEBUG, \"Decoding file - v%d.%02d, compression level %d\\n\", ape->fileversion / 1000, (ape->fileversion % 1000) / 10, ape->compressiontype);\n\n    /* now we are ready: build format streams */\n    st = av_new_stream(s, 0);\n    if (!st)\n        return -1;\n\n    total_blocks = (ape->totalframes == 0) ? 0 : ((ape->totalframes - 1) * ape->blocksperframe) + ape->finalframeblocks;\n\n    st->codec->codec_type      = AVMEDIA_TYPE_AUDIO;\n    st->codec->codec_id        = CODEC_ID_APE;\n    st->codec->codec_tag       = MKTAG('A', 'P', 'E', ' ');\n    st->codec->channels        = ape->channels;\n    st->codec->sample_rate     = ape->samplerate;\n    st->codec->bits_per_coded_sample = ape->bps;\n    st->codec->frame_size      = MAC_SUBFRAME_SIZE;\n\n    st->nb_frames = ape->totalframes;\n    st->start_time = 0;\n    st->duration  = total_blocks / MAC_SUBFRAME_SIZE;\n    av_set_pts_info(st, 64, MAC_SUBFRAME_SIZE, ape->samplerate);\n\n    st->codec->extradata = av_malloc(APE_EXTRADATA_SIZE);\n    st->codec->extradata_size = APE_EXTRADATA_SIZE;\n    AV_WL16(st->codec->extradata + 0, ape->fileversion);\n    AV_WL16(st->codec->extradata + 2, ape->compressiontype);\n    AV_WL16(st->codec->extradata + 4, ape->formatflags);\n\n    pts = 0;\n    for (i = 0; i < ape->totalframes; i++) {\n        ape->frames[i].pts = pts;\n        av_add_index_entry(st, ape->frames[i].pos, ape->frames[i].pts, 0, 0, AVINDEX_KEYFRAME);\n        pts += ape->blocksperframe / MAC_SUBFRAME_SIZE;\n    }\n\n    return 0;\n}",
        "func": "static int ape_read_header(AVFormatContext * s, AVFormatParameters * ap)\n{\n    AVIOContext *pb = s->pb;\n    APEContext *ape = s->priv_data;\n    AVStream *st;\n    uint32_t tag;\n    int i;\n    int total_blocks;\n    int64_t pts;\n\n    /* TODO: Skip any leading junk such as id3v2 tags */\n    ape->junklength = 0;\n\n    tag = avio_rl32(pb);\n    if (tag != MKTAG('M', 'A', 'C', ' '))\n        return -1;\n\n    ape->fileversion = avio_rl16(pb);\n\n    if (ape->fileversion < APE_MIN_VERSION || ape->fileversion > APE_MAX_VERSION) {\n        av_log(s, AV_LOG_ERROR, \"Unsupported file version - %d.%02d\\n\", ape->fileversion / 1000, (ape->fileversion % 1000) / 10);\n        return -1;\n    }\n\n    if (ape->fileversion >= 3980) {\n        ape->padding1             = avio_rl16(pb);\n        ape->descriptorlength     = avio_rl32(pb);\n        ape->headerlength         = avio_rl32(pb);\n        ape->seektablelength      = avio_rl32(pb);\n        ape->wavheaderlength      = avio_rl32(pb);\n        ape->audiodatalength      = avio_rl32(pb);\n        ape->audiodatalength_high = avio_rl32(pb);\n        ape->wavtaillength        = avio_rl32(pb);\n        avio_read(pb, ape->md5, 16);\n\n        /* Skip any unknown bytes at the end of the descriptor.\n           This is for future compatibility */\n        if (ape->descriptorlength > 52)\n            avio_seek(pb, ape->descriptorlength - 52, SEEK_CUR);\n\n        /* Read header data */\n        ape->compressiontype      = avio_rl16(pb);\n        ape->formatflags          = avio_rl16(pb);\n        ape->blocksperframe       = avio_rl32(pb);\n        ape->finalframeblocks     = avio_rl32(pb);\n        ape->totalframes          = avio_rl32(pb);\n        ape->bps                  = avio_rl16(pb);\n        ape->channels             = avio_rl16(pb);\n        ape->samplerate           = avio_rl32(pb);\n    } else {\n        ape->descriptorlength = 0;\n        ape->headerlength = 32;\n\n        ape->compressiontype      = avio_rl16(pb);\n        ape->formatflags          = avio_rl16(pb);\n        ape->channels             = avio_rl16(pb);\n        ape->samplerate           = avio_rl32(pb);\n        ape->wavheaderlength      = avio_rl32(pb);\n        ape->wavtaillength        = avio_rl32(pb);\n        ape->totalframes          = avio_rl32(pb);\n        ape->finalframeblocks     = avio_rl32(pb);\n\n        if (ape->formatflags & MAC_FORMAT_FLAG_HAS_PEAK_LEVEL) {\n            avio_seek(pb, 4, SEEK_CUR); /* Skip the peak level */\n            ape->headerlength += 4;\n        }\n\n        if (ape->formatflags & MAC_FORMAT_FLAG_HAS_SEEK_ELEMENTS) {\n            ape->seektablelength = avio_rl32(pb);\n            ape->headerlength += 4;\n            ape->seektablelength *= sizeof(int32_t);\n        } else\n            ape->seektablelength = ape->totalframes * sizeof(int32_t);\n\n        if (ape->formatflags & MAC_FORMAT_FLAG_8_BIT)\n            ape->bps = 8;\n        else if (ape->formatflags & MAC_FORMAT_FLAG_24_BIT)\n            ape->bps = 24;\n        else\n            ape->bps = 16;\n\n        if (ape->fileversion >= 3950)\n            ape->blocksperframe = 73728 * 4;\n        else if (ape->fileversion >= 3900 || (ape->fileversion >= 3800  && ape->compressiontype >= 4000))\n            ape->blocksperframe = 73728;\n        else\n            ape->blocksperframe = 9216;\n\n        /* Skip any stored wav header */\n        if (!(ape->formatflags & MAC_FORMAT_FLAG_CREATE_WAV_HEADER))\n            avio_seek(pb, ape->wavheaderlength, SEEK_CUR);\n    }\n\n    if(!ape->totalframes){\n        av_log(s, AV_LOG_ERROR, \"No frames in the file!\\n\");\n        return AVERROR(EINVAL);\n    }\n    if(ape->totalframes > UINT_MAX / sizeof(APEFrame)){\n        av_log(s, AV_LOG_ERROR, \"Too many frames: %d\\n\", ape->totalframes);\n        return -1;\n    }\n    ape->frames       = av_malloc(ape->totalframes * sizeof(APEFrame));\n    if(!ape->frames)\n        return AVERROR(ENOMEM);\n    ape->firstframe   = ape->junklength + ape->descriptorlength + ape->headerlength + ape->seektablelength + ape->wavheaderlength;\n    ape->currentframe = 0;\n\n\n    ape->totalsamples = ape->finalframeblocks;\n    if (ape->totalframes > 1)\n        ape->totalsamples += ape->blocksperframe * (ape->totalframes - 1);\n\n    if (ape->seektablelength > 0) {\n        ape->seektable = av_malloc(ape->seektablelength);\n        for (i = 0; i < ape->seektablelength / sizeof(uint32_t); i++)\n            ape->seektable[i] = avio_rl32(pb);\n    }\n\n    ape->frames[0].pos     = ape->firstframe;\n    ape->frames[0].nblocks = ape->blocksperframe;\n    ape->frames[0].skip    = 0;\n    for (i = 1; i < ape->totalframes; i++) {\n        ape->frames[i].pos      = ape->seektable[i]; //ape->frames[i-1].pos + ape->blocksperframe;\n        ape->frames[i].nblocks  = ape->blocksperframe;\n        ape->frames[i - 1].size = ape->frames[i].pos - ape->frames[i - 1].pos;\n        ape->frames[i].skip     = (ape->frames[i].pos - ape->frames[0].pos) & 3;\n    }\n    ape->frames[ape->totalframes - 1].size    = ape->finalframeblocks * 4;\n    ape->frames[ape->totalframes - 1].nblocks = ape->finalframeblocks;\n\n    for (i = 0; i < ape->totalframes; i++) {\n        if(ape->frames[i].skip){\n            ape->frames[i].pos  -= ape->frames[i].skip;\n            ape->frames[i].size += ape->frames[i].skip;\n        }\n        ape->frames[i].size = (ape->frames[i].size + 3) & ~3;\n    }\n\n\n    ape_dumpinfo(s, ape);\n\n    /* try to read APE tags */\n    if (!url_is_streamed(pb)) {\n        ff_ape_parse_tag(s);\n        avio_seek(pb, 0, SEEK_SET);\n    }\n\n    av_log(s, AV_LOG_DEBUG, \"Decoding file - v%d.%02d, compression level %d\\n\", ape->fileversion / 1000, (ape->fileversion % 1000) / 10, ape->compressiontype);\n\n    /* now we are ready: build format streams */\n    st = av_new_stream(s, 0);\n    if (!st)\n        return -1;\n\n    total_blocks = (ape->totalframes == 0) ? 0 : ((ape->totalframes - 1) * ape->blocksperframe) + ape->finalframeblocks;\n\n    st->codec->codec_type      = AVMEDIA_TYPE_AUDIO;\n    st->codec->codec_id        = CODEC_ID_APE;\n    st->codec->codec_tag       = MKTAG('A', 'P', 'E', ' ');\n    st->codec->channels        = ape->channels;\n    st->codec->sample_rate     = ape->samplerate;\n    st->codec->bits_per_coded_sample = ape->bps;\n    st->codec->frame_size      = MAC_SUBFRAME_SIZE;\n\n    st->nb_frames = ape->totalframes;\n    st->start_time = 0;\n    st->duration  = total_blocks / MAC_SUBFRAME_SIZE;\n    av_set_pts_info(st, 64, MAC_SUBFRAME_SIZE, ape->samplerate);\n\n    st->codec->extradata = av_malloc(APE_EXTRADATA_SIZE);\n    st->codec->extradata_size = APE_EXTRADATA_SIZE;\n    AV_WL16(st->codec->extradata + 0, ape->fileversion);\n    AV_WL16(st->codec->extradata + 2, ape->compressiontype);\n    AV_WL16(st->codec->extradata + 4, ape->formatflags);\n\n    pts = 0;\n    for (i = 0; i < ape->totalframes; i++) {\n        ape->frames[i].pts = pts;\n        av_add_index_entry(st, ape->frames[i].pos, ape->frames[i].pts, 0, 0, AVINDEX_KEYFRAME);\n        pts += ape->blocksperframe / MAC_SUBFRAME_SIZE;\n    }\n\n    return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -91,6 +91,10 @@\n             avio_seek(pb, ape->wavheaderlength, SEEK_CUR);\n     }\n \n+    if(!ape->totalframes){\n+        av_log(s, AV_LOG_ERROR, \"No frames in the file!\\n\");\n+        return AVERROR(EINVAL);\n+    }\n     if(ape->totalframes > UINT_MAX / sizeof(APEFrame)){\n         av_log(s, AV_LOG_ERROR, \"Too many frames: %d\\n\", ape->totalframes);\n         return -1;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    if(!ape->totalframes){",
                "        av_log(s, AV_LOG_ERROR, \"No frames in the file!\\n\");",
                "        return AVERROR(EINVAL);",
                "    }"
            ]
        }
    },
    {
        "cve_id": "CVE-2011-1575",
        "func_name": "jedisct1/pure-ftpd/sfgets",
        "description": "The STARTTLS implementation in ftp_parser.c in Pure-FTPd before 1.0.30 does not properly restrict I/O buffering, which allows man-in-the-middle attackers to insert commands into encrypted FTP sessions by sending a cleartext command that is processed after TLS is in place, related to a \"plaintext command injection\" attack, a similar issue to CVE-2011-0411.",
        "git_url": "https://github.com/jedisct1/pure-ftpd/commit/65c4d4ad331e94661de763e9b5304d28698999c4",
        "commit_title": "Flush the command buffer after switching to TLS.",
        "commit_text": "Fixes a flaw similar to CVE-2011-0411.",
        "func_before": "int sfgets(void)\n{\n    struct pollfd pfd;\n    int pollret;\n    ssize_t readnb;\n    signed char seen_r = 0;\n    static size_t scanned;\n    static size_t readnbd;\n    \n    if (scanned > (size_t) 0U) {       /* support pipelining */\n        readnbd -= scanned;        \n        memmove(cmd, cmd + scanned, readnbd);   /* safe */\n        scanned = (size_t) 0U;\n    }\n    pfd.fd = clientfd;\n#ifdef __APPLE_CC__\n    pfd.events = POLLIN | POLLERR | POLLHUP;\n#else\n    pfd.events = POLLIN | POLLPRI | POLLERR | POLLHUP;\n#endif\n    while (scanned < cmdsize) {\n        if (scanned >= readnbd) {      /* nothing left in the buffer */\n            pfd.revents = 0;\n            while ((pollret = poll(&pfd, 1U, idletime * 1000UL)) < 0 &&\n                   errno == EINTR);\n            if (pollret == 0) {\n                return -1;\n            }\n            if (pollret <= 0 ||\n                (pfd.revents & (POLLERR | POLLHUP | POLLNVAL)) != 0) {\n                return -2;\n            }\n            if ((pfd.revents & (POLLIN | POLLPRI)) == 0) {\n                continue;\n            }\n            if (readnbd >= cmdsize) {\n                break;\n            }\n#ifdef WITH_TLS\n            if (tls_cnx != NULL) {\n                while ((readnb = SSL_read\n                        (tls_cnx, cmd + readnbd, cmdsize - readnbd))\n                       < (ssize_t) 0 && errno == EINTR);\n            } else\n#endif\n            {\n                while ((readnb = read(clientfd, cmd + readnbd,\n                                      cmdsize - readnbd)) < (ssize_t) 0 &&\n                       errno == EINTR);\n            }\n            if (readnb <= (ssize_t) 0) {\n                return -2;\n            }\n            readnbd += readnb;\n            if (readnbd > cmdsize) {\n                return -2;\n            }\n        }\n#ifdef RFC_CONFORMANT_LINES\n        if (seen_r != 0) {\n#endif\n            if (cmd[scanned] == '\\n') {\n#ifndef RFC_CONFORMANT_LINES\n                if (seen_r != 0) {\n#endif\n                    cmd[scanned - 1U] = 0;\n#ifndef RFC_CONFORMANT_LINES\n                } else {\n                    cmd[scanned] = 0;\n                }\n#endif\n                if (++scanned >= readnbd) {   /* non-pipelined command */\n                    scanned = readnbd = (size_t) 0U;\n                }\n                return 0;\n            }\n            seen_r = 0;\n#ifdef RFC_CONFORMANT_LINES\n        }\n#endif\n        if (ISCTRLCODE(cmd[scanned])) {\n            if (cmd[scanned] == '\\r') {\n                seen_r = 1;\n            }\n#ifdef RFC_CONFORMANT_PARSER                   /* disabled by default, intentionnaly */\n            else if (cmd[scanned] == 0) {\n                cmd[scanned] = '\\n';\n            }\n#else\n            /* replace control chars with _ */\n            cmd[scanned] = '_';                \n#endif\n        }\n        scanned++;\n    }\n    die(421, LOG_WARNING, MSG_LINE_TOO_LONG);   /* don't remove this */\n    \n    return 0;                         /* to please GCC */\n}",
        "func": "int sfgets(void)\n{\n    struct pollfd pfd;\n    int pollret;\n    ssize_t readnb;\n    signed char seen_r = 0;\n    \n    if (scanned > (size_t) 0U) {       /* support pipelining */\n        readnbd -= scanned;        \n        memmove(cmd, cmd + scanned, readnbd);   /* safe */\n        scanned = (size_t) 0U;\n    }\n    pfd.fd = clientfd;\n#ifdef __APPLE_CC__\n    pfd.events = POLLIN | POLLERR | POLLHUP;\n#else\n    pfd.events = POLLIN | POLLPRI | POLLERR | POLLHUP;\n#endif\n    while (scanned < cmdsize) {\n        if (scanned >= readnbd) {      /* nothing left in the buffer */\n            pfd.revents = 0;\n            while ((pollret = poll(&pfd, 1U, idletime * 1000UL)) < 0 &&\n                   errno == EINTR);\n            if (pollret == 0) {\n                return -1;\n            }\n            if (pollret <= 0 ||\n                (pfd.revents & (POLLERR | POLLHUP | POLLNVAL)) != 0) {\n                return -2;\n            }\n            if ((pfd.revents & (POLLIN | POLLPRI)) == 0) {\n                continue;\n            }\n            if (readnbd >= cmdsize) {\n                break;\n            }\n#ifdef WITH_TLS\n            if (tls_cnx != NULL) {\n                while ((readnb = SSL_read\n                        (tls_cnx, cmd + readnbd, cmdsize - readnbd))\n                       < (ssize_t) 0 && errno == EINTR);\n            } else\n#endif\n            {\n                while ((readnb = read(clientfd, cmd + readnbd,\n                                      cmdsize - readnbd)) < (ssize_t) 0 &&\n                       errno == EINTR);\n            }\n            if (readnb <= (ssize_t) 0) {\n                return -2;\n            }\n            readnbd += readnb;\n            if (readnbd > cmdsize) {\n                return -2;\n            }\n        }\n#ifdef RFC_CONFORMANT_LINES\n        if (seen_r != 0) {\n#endif\n            if (cmd[scanned] == '\\n') {\n#ifndef RFC_CONFORMANT_LINES\n                if (seen_r != 0) {\n#endif\n                    cmd[scanned - 1U] = 0;\n#ifndef RFC_CONFORMANT_LINES\n                } else {\n                    cmd[scanned] = 0;\n                }\n#endif\n                if (++scanned >= readnbd) {   /* non-pipelined command */\n                    scanned = readnbd = (size_t) 0U;\n                }\n                return 0;\n            }\n            seen_r = 0;\n#ifdef RFC_CONFORMANT_LINES\n        }\n#endif\n        if (ISCTRLCODE(cmd[scanned])) {\n            if (cmd[scanned] == '\\r') {\n                seen_r = 1;\n            }\n#ifdef RFC_CONFORMANT_PARSER                   /* disabled by default, intentionnaly */\n            else if (cmd[scanned] == 0) {\n                cmd[scanned] = '\\n';\n            }\n#else\n            /* replace control chars with _ */\n            cmd[scanned] = '_';                \n#endif\n        }\n        scanned++;\n    }\n    die(421, LOG_WARNING, MSG_LINE_TOO_LONG);   /* don't remove this */\n    \n    return 0;                         /* to please GCC */\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,8 +4,6 @@\n     int pollret;\n     ssize_t readnb;\n     signed char seen_r = 0;\n-    static size_t scanned;\n-    static size_t readnbd;\n     \n     if (scanned > (size_t) 0U) {       /* support pipelining */\n         readnbd -= scanned;        ",
        "diff_line_info": {
            "deleted_lines": [
                "    static size_t scanned;",
                "    static size_t readnbd;"
            ],
            "added_lines": []
        }
    },
    {
        "cve_id": "CVE-2011-1575",
        "func_name": "jedisct1/pure-ftpd/parser",
        "description": "The STARTTLS implementation in ftp_parser.c in Pure-FTPd before 1.0.30 does not properly restrict I/O buffering, which allows man-in-the-middle attackers to insert commands into encrypted FTP sessions by sending a cleartext command that is processed after TLS is in place, related to a \"plaintext command injection\" attack, a similar issue to CVE-2011-0411.",
        "git_url": "https://github.com/jedisct1/pure-ftpd/commit/65c4d4ad331e94661de763e9b5304d28698999c4",
        "commit_title": "Flush the command buffer after switching to TLS.",
        "commit_text": "Fixes a flaw similar to CVE-2011-0411.",
        "func_before": "void parser(void)\n{\n    char *arg;\n#ifndef MINIMAL\n    char *sitearg;\n#endif\n#ifdef WITH_RFC2640\n    char *narg = NULL;\n#endif\n    size_t n;\n\n#ifdef IMPLICIT_TLS\n    (void) tls_init_new_session();\n    data_protection_level = CPL_PRIVATE;\n#endif\n    for (;;) {\n        xferfd = -1;\n        if (state_needs_update != 0) {\n            state_needs_update = 0;\n            setprocessname(\"pure-ftpd (IDLE)\");\n#ifdef FTPWHO\n            if (shm_data_cur != NULL) {\n                ftpwho_lock();\n                shm_data_cur->state = FTPWHO_STATE_IDLE;\n                *shm_data_cur->filename = 0;\n                ftpwho_unlock();\n            }\n#endif\n        }\n        doreply();\n        alarm(idletime * 2);\n        switch (sfgets()) {\n        case -1:\n#ifdef BORING_MODE\n            die(421, LOG_INFO, MSG_TIMEOUT);\n#else\n            die(421, LOG_INFO, MSG_TIMEOUT_PARSER);\n#endif\n        case -2:\n            return;\n        }\n#ifdef DEBUG\n        if (debug != 0) {\n            addreply(0, \"%s\", cmd);\n        }\n#endif\n        n = (size_t) 0U;\n        while ((isalpha((unsigned char) cmd[n]) || cmd[n] == '@') &&\n               n < cmdsize) {\n            cmd[n] = (char) tolower((unsigned char) cmd[n]);\n            n++;\n        }\n        if (n >= cmdsize) {            /* overparanoid, it should never happen */\n            die(421, LOG_WARNING, MSG_LINE_TOO_LONG);\n        }\n        if (n == (size_t) 0U) {\n            nop:\n            addreply_noformat(500, \"?\");\n            continue;\n        }\n#ifdef SKIP_COMMAND_TRAILING_SPACES        \n        while (isspace((unsigned char) cmd[n]) && n < cmdsize) {\n            cmd[n++] = 0;\n        }\n        arg = cmd + n;        \n        while (cmd[n] != 0 && n < cmdsize) {\n            n++;\n        }\n        n--;\n        while (isspace((unsigned char) cmd[n])) {\n            cmd[n--] = 0;\n        }\n#else\n        if (cmd[n] == 0) {\n            arg = cmd + n;\n        } else if (isspace((unsigned char) cmd[n])) {\n            cmd[n] = 0;\n            arg = cmd + n + 1;\n        } else {\n            goto nop;\n        }\n#endif\n        if (logging != 0) {\n#ifdef DEBUG\n            logfile(LOG_DEBUG, MSG_DEBUG_COMMAND \" [%s] [%s]\",\n                   cmd, arg);\n#else\n            logfile(LOG_DEBUG, MSG_DEBUG_COMMAND \" [%s] [%s]\",\n                   cmd, strcmp(cmd, \"pass\") ? arg : \"<*>\");\n#endif\n        }\n#ifdef WITH_RFC2640\n        narg = charset_client2fs(arg);\n\targ = narg;\n#endif\n        /*\n         * antiidle() is called with dummy commands, usually used by clients\n         * who are wanting extra idle time. We give them some, but not too much.\n         * When we jump to wayout, the idle timer is not zeroed. It means that\n         * we didn't issue an 'active' command like RETR.\n         */\n        \n#ifndef MINIMAL\n        if (!strcmp(cmd, \"noop\")) {\n            antiidle();\n            donoop();\n            goto wayout;\n        }\n#endif\n        if (!strcmp(cmd, \"user\")) {\n#ifdef WITH_TLS\n            if (enforce_tls_auth > 1 && tls_cnx == NULL) {\n                die(421, LOG_WARNING, MSG_TLS_NEEDED);\n            }\n#endif\n            douser(arg);\n        } else if (!strcmp(cmd, \"acct\")) {\n            addreply(202, MSG_WHOAREYOU);\n        } else if (!strcmp(cmd, \"pass\")) {\n            if (guest == 0) {\n                randomdelay();\n            }\n            dopass(arg);\n        } else if (!strcmp(cmd, \"quit\")) {\n            addreply(221, MSG_GOODBYE,\n                     (unsigned long long) ((uploaded + 1023ULL) / 1024ULL),\n                     (unsigned long long) ((downloaded + 1023ULL) / 1024ULL));\n            return;\n        } else if (!strcmp(cmd, \"syst\")) {\n            antiidle();\n            addreply_noformat(215, \"UNIX Type: L8\");\n            goto wayout;\n#ifdef WITH_TLS\n        } else if (enforce_tls_auth > 0 &&\n                   !strcmp(cmd, \"auth\") && !strcasecmp(arg, \"tls\")) {\n            addreply_noformat(234, \"AUTH TLS OK.\");\n            doreply();\n            if (tls_cnx == NULL) {\n                (void) tls_init_new_session();\n            }\n            goto wayout;\n        } else if (!strcmp(cmd, \"pbsz\")) {\n            addreply_noformat(tls_cnx == NULL ? 503 : 200, \"PBSZ=0\");\n        } else if (!strcmp(cmd, \"prot\")) {\n            if (tls_cnx == NULL) {\n                addreply_noformat(503, MSG_PROT_BEFORE_PBSZ);\n                goto wayout;\n            }\n            switch (*arg) {\n            case 0:\n                addreply_noformat(503, MSG_MISSING_ARG);\n                data_protection_level = CPL_NONE;\n                break;\n            case 'C':\n                if (arg[1] == 0) {\n                    addreply(200, MSG_PROT_OK, \"clear\");\n                    data_protection_level = CPL_CLEAR;\n                    break;\n                }\n            case 'S':\n            case 'E':\n                if (arg[1] == 0) {\n                    addreply(200, MSG_PROT_UNKNOWN_LEVEL, arg, \"private\");\n                    data_protection_level = CPL_PRIVATE;\n                    break;\n                }\n            case 'P':\n                if (arg[1] == 0) {\n                    addreply(200, MSG_PROT_OK, \"private\");\n                    data_protection_level = CPL_PRIVATE;\n                    break;\n                }\n            default:\n                addreply_noformat(534, \"Fallback to [C]\");\n                data_protection_level = CPL_CLEAR;\n                break;\n            }\n#endif\n        } else if (!strcmp(cmd, \"auth\") || !strcmp(cmd, \"adat\")) {\n            addreply_noformat(500, MSG_AUTH_UNIMPLEMENTED);\n        } else if (!strcmp(cmd, \"type\")) {\n            antiidle();\n            dotype(arg);\n            goto wayout;\n        } else if (!strcmp(cmd, \"mode\")) {\n            antiidle();                \n            domode(arg);\n            goto wayout;\n#ifndef MINIMAL\n        } else if (!strcmp(cmd, \"feat\")) {\n            dofeat();\n            goto wayout;\n\t} else if (!strcmp(cmd, \"opts\")) {\n\t    doopts(arg);\n\t    goto wayout;\n#endif\n        } else if (!strcmp(cmd, \"stru\")) {\n            dostru(arg);\n            goto wayout;\n#ifndef MINIMAL\n        } else if (!strcmp(cmd, \"help\")) {\n            goto help_site;\n#endif\n#ifdef DEBUG\n        } else if (!strcmp(cmd, \"xdbg\")) {\n            debug++;\n            addreply(200, MSG_XDBG_OK, debug);\n            goto wayout;\n#endif            \n        } else if (loggedin == 0) {            \n            /* from this point, all commands need authentication */\n            addreply_noformat(530, MSG_NOT_LOGGED_IN);\n            goto wayout;\n        } else {\n            if (!strcmp(cmd, \"cwd\") || !strcmp(cmd, \"xcwd\")) {\n                antiidle();\n                docwd(arg);\n                goto wayout;\n            } else if (!strcmp(cmd, \"port\")) {\n                doport(arg);\n#ifndef MINIMAL\n            } else if (!strcmp(cmd, \"eprt\")) {\n                doeprt(arg);\n            } else if (!strcmp(cmd, \"esta\") &&\n                       disallow_passive == 0 &&\n                       STORAGE_FAMILY(force_passive_ip) == 0) {\n                doesta();\n            } else if (!strcmp(cmd, \"estp\")) {\n                doestp();\n#endif\n            } else if (disallow_passive == 0 && \n                       (!strcmp(cmd, \"pasv\") || !strcmp(cmd, \"p@sw\"))) {\n                dopasv(0);\n            } else if (disallow_passive == 0 && \n                       (!strcmp(cmd, \"epsv\") && \n                       (broken_client_compat == 0 ||\n                        STORAGE_FAMILY(ctrlconn) == AF_INET6))) {\n                if (!strcasecmp(arg, \"all\")) {\n                    epsv_all = 1;\n                    addreply_noformat(220, MSG_ACTIVE_DISABLED);\n                } else if (!strcmp(arg, \"2\") && !v6ready) {\n                    addreply_noformat(522, MSG_ONLY_IPV4);\n                } else {\n                    dopasv(1);\n                }\n#ifndef MINIMAL            \n            } else if (disallow_passive == 0 && !strcmp(cmd, \"spsv\")) {\n                dopasv(2);\n            } else if (!strcmp(cmd, \"allo\")) {\n                if (*arg == 0) {\n                    addreply_noformat(501, MSG_STAT_FAILURE);\n                } else {\n                    const off_t size = (off_t) strtoull(arg, NULL, 10);\n                    \n                    if (size < (off_t) 0) {\n                        addreply_noformat(501, MSG_STAT_FAILURE);                        \n                    } else {\n                        doallo(size);\n                    }\n                }\n#endif\n            } else if (!strcmp(cmd, \"pwd\") || !strcmp(cmd, \"xpwd\")) {\n#ifdef WITH_RFC2640\n\t\tchar *nwd;\n#endif\n                antiidle();\n#ifdef WITH_RFC2640\n\t\tnwd = charset_fs2client(wd);\n\t\taddreply(257, \"\\\"%s\\\" \" MSG_IS_YOUR_CURRENT_LOCATION, nwd);\n\t\tfree(nwd);\n#else\n                addreply(257, \"\\\"%s\\\" \" MSG_IS_YOUR_CURRENT_LOCATION, wd);\n#endif\n                goto wayout;                \n            } else if (!strcmp(cmd, \"cdup\") || !strcmp(cmd, \"xcup\")) {\n                docwd(\"..\");\n            } else if (!strcmp(cmd, \"retr\")) {\n                if (*arg != 0) {\n#ifdef WITH_TLS\n                    if (enforce_tls_auth == 3 &&\n                        data_protection_level != CPL_PRIVATE) {\n                        addreply_noformat(521, MSG_PROT_PRIVATE_NEEDED);\n                    }\n                    else\n#endif\n                    {\n                        doretr(arg);\n                    }\n                } else {\n                    addreply_noformat(501, MSG_NO_FILE_NAME);\n                }\n            } else if (!strcmp(cmd, \"rest\")) {\n                antiidle();\n                if (*arg != 0) {\n                    dorest(arg);\n                } else {\n                    addreply_noformat(501, MSG_NO_RESTART_POINT);\n                    restartat = (off_t) 0;\n                }\n                goto wayout;\n            } else if (!strcmp(cmd, \"dele\")) {\n                if (*arg != 0) {\n                    dodele(arg);\n                } else {\n                    addreply_noformat(501, MSG_NO_FILE_NAME);\n                }\n            } else if (!strcmp(cmd, \"stor\")) {\n                arg = revealextraspc(arg);\n                if (*arg != 0) {\n#ifdef WITH_TLS\n                    if (enforce_tls_auth == 3 &&\n                        data_protection_level != CPL_PRIVATE) {\n                        addreply_noformat(521, MSG_PROT_PRIVATE_NEEDED);\n                    } else \n#endif\n                    {\n                        dostor(arg, 0, autorename);\n                    }\n                } else {\n                    addreply_noformat(501, MSG_NO_FILE_NAME);\n                }\n            } else if (!strcmp(cmd, \"appe\")) {\n                arg = revealextraspc(arg);\n                if (*arg != 0) {\n#ifdef WITH_TLS\n                    if (enforce_tls_auth == 3 &&\n                        data_protection_level != CPL_PRIVATE) {\n                        addreply_noformat(521, MSG_PROT_PRIVATE_NEEDED);\n                    } else \n#endif\n                    {\n                        dostor(arg, 1, 0);\n                    }\n                } else {\n                    addreply_noformat(501, MSG_NO_FILE_NAME);\n                }\n#ifndef MINIMAL\n            } else if (!strcmp(cmd, \"stou\")) {\n#ifdef WITH_TLS\n                if (enforce_tls_auth == 3 &&\n                    data_protection_level != CPL_PRIVATE) {\n                    addreply_noformat(521, MSG_PROT_PRIVATE_NEEDED);\n                } else \n#endif\n                {\n            \t     dostou();\n                }\n#endif\n#ifndef DISABLE_MKD_RMD\n            } else if (!strcmp(cmd, \"mkd\") || !strcmp(cmd, \"xmkd\")) {\n                arg = revealextraspc(arg);\n                if (*arg != 0) {\n                    domkd(arg);\n                } else {\n                    addreply_noformat(501, MSG_NO_DIRECTORY_NAME);\n                }\n            } else if (!strcmp(cmd, \"rmd\") || !strcmp(cmd, \"xrmd\")) {\n                if (*arg != 0) {\n                    dormd(arg);\n                } else {\n                    addreply_noformat(550, MSG_NO_DIRECTORY_NAME);\n                }\n#endif\n#ifndef MINIMAL\n            } else if (!strcmp(cmd, \"stat\")) {\n                if (*arg != 0) {\n                    modern_listings = 0;\n                    donlist(arg, 1, 1, 1, 1);\n                } else {\n                    addreply_noformat(211, \"http://www.pureftpd.org/\");\n                }\n#endif\n            } else if (!strcmp(cmd, \"list\")) {\n#ifndef MINIMAL\n                modern_listings = 0;\n#endif\n#ifdef WITH_TLS\n                if (enforce_tls_auth == 3 &&\n                    data_protection_level != CPL_PRIVATE) {\n                    addreply_noformat(521, MSG_PROT_PRIVATE_NEEDED);\n                } else\n#endif\n                {\n                    donlist(arg, 0, 1, 0, 1);\n                }\n            } else if (!strcmp(cmd, \"nlst\")) {\n#ifndef MINIMAL                \n                modern_listings = 0;\n#endif\n#ifdef WITH_TLS\n                if (enforce_tls_auth == 3 &&\n                    data_protection_level != CPL_PRIVATE) {\n                    addreply_noformat(521, MSG_PROT_PRIVATE_NEEDED);\n                } else\n#endif\n                {\n                    donlist(arg, 0, 0, 0, broken_client_compat);\n                }\n#ifndef MINIMAL\n            } else if (!strcmp(cmd, \"mlst\")) {\n#ifdef WITH_TLS\n                if (enforce_tls_auth == 3 &&\n                    data_protection_level != CPL_PRIVATE) {\n                    addreply_noformat(521, MSG_PROT_PRIVATE_NEEDED);\n                } else\n#endif\n                {\n                    domlst(*arg != 0 ? arg : \".\");\n                }\n            } else if (!strcmp(cmd, \"mlsd\")) {\n                modern_listings = 1;\n#ifdef WITH_TLS\n                if (enforce_tls_auth == 3 &&\n                    data_protection_level != CPL_PRIVATE) {\n                    addreply_noformat(521, MSG_PROT_PRIVATE_NEEDED);\n                } else\n#endif\n                {\n                    donlist(arg, 0, 1, 1, 0);\n                }\n#endif\n            } else if (!strcmp(cmd, \"abor\")) {\n                addreply_noformat(226, MSG_ABOR_SUCCESS);\n#ifndef MINIMAL\n            } else if (!strcmp(cmd, \"site\")) {\n                if ((sitearg = arg) != NULL) {\n                    while (*sitearg != 0 && !isspace((unsigned char) *sitearg)) {\n                        sitearg++;\n                    }\n                    if (*sitearg != 0) {\n                        *sitearg++ = 0;\n                    }\n                }\n                if (!strcasecmp(arg, \"idle\")) {\n                    if (sitearg == NULL || *sitearg == 0) {\n                        addreply_noformat(501, \"SITE IDLE: \" MSG_MISSING_ARG);\n                    } else {\n                        unsigned long int i = 0;\n\n                        i = strtoul(sitearg, &sitearg, 10);\n                        if (sitearg && *sitearg)\n                            addreply(501, MSG_GARBAGE_FOUND \" : %s\", sitearg);\n                        else if (i > MAX_SITE_IDLE)\n                            addreply_noformat(501, MSG_VALUE_TOO_LARGE);\n                        else {\n                            idletime = i;\n                            addreply(200, MSG_IDLE_TIME, idletime);\n                            idletime_noop = (double) idletime * 2.0;\n                        }\n                    }\n                } else if (!strcasecmp(arg, \"time\")) {\n                    dositetime();\n                } else if (!strcasecmp(arg, \"help\")) {\n                    help_site:\n                    \n                    addreply_noformat(214, MSG_SITE_HELP CRLF\n# ifdef WITH_DIRALIASES\n                                      \" ALIAS\" CRLF\n# endif\n                                      \" CHMOD\" CRLF \" IDLE\" CRLF \" UTIME\");\n                    addreply_noformat(214, \"Pure-FTPd - http://pureftpd.org/\");\n                } else if (!strcasecmp(arg, \"chmod\")) {\n                    char *sitearg2;\n                    mode_t mode;\n                    \n                    parsechmod:\n                    if (sitearg == NULL || *sitearg == 0) {\n                        addreply_noformat(501, MSG_MISSING_ARG);\n                        goto chmod_wayout;\n                    }\n                    sitearg2 = sitearg;\n                    while (*sitearg2 != 0 && !isspace((unsigned char) *sitearg2)) {\n                        sitearg2++;\n                    }                    \n                    while (*sitearg2 != 0 && isspace((unsigned char) *sitearg2)) {\n                        sitearg2++;\n                    }                    \n                    if (*sitearg2 == 0) {\n                        addreply_noformat(550, MSG_NO_FILE_NAME);\n                        goto chmod_wayout;\n                    }\n                    mode = (mode_t) strtoul(sitearg, NULL, 8);\n                    if (mode > (mode_t) 07777) {\n                        addreply_noformat(501, MSG_BAD_CHMOD);\n                        goto chmod_wayout;\n                    }\n                    dochmod(sitearg2, mode);\n                    chmod_wayout:\n                    (void) 0;\n                } else if (!strcasecmp(arg, \"utime\")) {\n                    char *sitearg2;\n                    \n                    if (sitearg == NULL || *sitearg == 0) {\n                        addreply_noformat(501, MSG_NO_FILE_NAME);\n                        goto utime_wayout;\n                    }\t\t    \n                    if ((sitearg2 = strrchr(sitearg, ' ')) == NULL ||\n                        sitearg2 == sitearg) {\n                        addreply_noformat(501, MSG_MISSING_ARG);\n                        goto utime_wayout;\n                    }\n                    if (strcasecmp(sitearg2, \" UTC\") != 0) {\n                        addreply_noformat(500, \"UTC Only\");\n                        goto utime_wayout;\t\t\t\n                    }\n                    *sitearg2-- = 0;\n                    if ((sitearg2 = strrchr(sitearg, ' ')) == NULL ||\n                        sitearg2 == sitearg) {\n                        utime_no_arg:\n                        addreply_noformat(501, MSG_MISSING_ARG);\n                        goto utime_wayout;\n                    }\n                    *sitearg2-- = 0;\n                    if ((sitearg2 = strrchr(sitearg, ' ')) == NULL ||\n                        sitearg2 == sitearg) {\n                        goto utime_no_arg;\n                    }\n                    *sitearg2-- = 0;\n                    if ((sitearg2 = strrchr(sitearg, ' ')) == NULL ||\n                        sitearg2 == sitearg) {\n                        goto utime_no_arg;\n                    }\n                    *sitearg2++ = 0;\n                    if (*sitearg2 == 0) {\n                        goto utime_no_arg;\t\t\t\n                    }\n                    doutime(sitearg, sitearg2);\n                    utime_wayout:\n                    (void) 0;\n# ifdef WITH_DIRALIASES\t\t    \n                } else if (!strcasecmp(arg, \"alias\")) {\n                    if (sitearg == NULL || *sitearg == 0) {\n                        print_aliases();\n                    } else {\n                        const char *alias;\n                        \n                        if ((alias = lookup_alias(sitearg)) != NULL) {\n                            addreply(214, MSG_ALIASES_ALIAS, sitearg, alias);\n                        } else {\n                            addreply(502, MSG_ALIASES_UNKNOWN, sitearg);\n                        }\n                    }\n# endif\n                } else if (*arg != 0) {\n                    addreply(500, \"SITE %s \" MSG_UNKNOWN_EXTENSION, arg);\n                } else {\n                    addreply_noformat(500, \"SITE: \" MSG_MISSING_ARG);\n                }\n#endif\n            } else if (!strcmp(cmd, \"mdtm\")) {\n                domdtm(arg);\n            } else if (!strcmp(cmd, \"size\")) {\n                dosize(arg);\n#ifndef MINIMAL\n            } else if (!strcmp(cmd, \"chmod\")) {\n                sitearg = arg;\n                goto parsechmod;\n#endif\n            } else if (!strcmp(cmd, \"rnfr\")) {\n                if (*arg != 0) {\n                    dornfr(arg);\n                } else {\n                    addreply_noformat(550, MSG_NO_FILE_NAME);\n                }\n            } else if (!strcmp(cmd, \"rnto\")) {\n                arg = revealextraspc(arg);\n                if (*arg != 0) {\n                    dornto(arg);\n                } else {\n                    addreply_noformat(550, MSG_NO_FILE_NAME);\n                }\n            } else {\n                addreply_noformat(500, MSG_UNKNOWN_COMMAND);\n            }\n        }\n        noopidle = (time_t) -1;\n        wayout:\n#ifdef WITH_RFC2640\n        free(narg);\n        narg = NULL;\n#endif\n#ifdef THROTTLING\n        if (throttling_delay != 0UL) {\n            usleep2(throttling_delay);\n        }\n#else\n        (void) 0;\n#endif\n    }\n}",
        "func": "void parser(void)\n{\n    char *arg;\n#ifndef MINIMAL\n    char *sitearg;\n#endif\n#ifdef WITH_RFC2640\n    char *narg = NULL;\n#endif\n    size_t n;\n\n#ifdef IMPLICIT_TLS\n    (void) tls_init_new_session();\n    data_protection_level = CPL_PRIVATE;\n#endif\n    for (;;) {\n        xferfd = -1;\n        if (state_needs_update != 0) {\n            state_needs_update = 0;\n            setprocessname(\"pure-ftpd (IDLE)\");\n#ifdef FTPWHO\n            if (shm_data_cur != NULL) {\n                ftpwho_lock();\n                shm_data_cur->state = FTPWHO_STATE_IDLE;\n                *shm_data_cur->filename = 0;\n                ftpwho_unlock();\n            }\n#endif\n        }\n        doreply();\n        alarm(idletime * 2);\n        switch (sfgets()) {\n        case -1:\n#ifdef BORING_MODE\n            die(421, LOG_INFO, MSG_TIMEOUT);\n#else\n            die(421, LOG_INFO, MSG_TIMEOUT_PARSER);\n#endif\n        case -2:\n            return;\n        }\n#ifdef DEBUG\n        if (debug != 0) {\n            addreply(0, \"%s\", cmd);\n        }\n#endif\n        n = (size_t) 0U;\n        while ((isalpha((unsigned char) cmd[n]) || cmd[n] == '@') &&\n               n < cmdsize) {\n            cmd[n] = (char) tolower((unsigned char) cmd[n]);\n            n++;\n        }\n        if (n >= cmdsize) {            /* overparanoid, it should never happen */\n            die(421, LOG_WARNING, MSG_LINE_TOO_LONG);\n        }\n        if (n == (size_t) 0U) {\n            nop:\n            addreply_noformat(500, \"?\");\n            continue;\n        }\n#ifdef SKIP_COMMAND_TRAILING_SPACES        \n        while (isspace((unsigned char) cmd[n]) && n < cmdsize) {\n            cmd[n++] = 0;\n        }\n        arg = cmd + n;        \n        while (cmd[n] != 0 && n < cmdsize) {\n            n++;\n        }\n        n--;\n        while (isspace((unsigned char) cmd[n])) {\n            cmd[n--] = 0;\n        }\n#else\n        if (cmd[n] == 0) {\n            arg = cmd + n;\n        } else if (isspace((unsigned char) cmd[n])) {\n            cmd[n] = 0;\n            arg = cmd + n + 1;\n        } else {\n            goto nop;\n        }\n#endif\n        if (logging != 0) {\n#ifdef DEBUG\n            logfile(LOG_DEBUG, MSG_DEBUG_COMMAND \" [%s] [%s]\",\n                   cmd, arg);\n#else\n            logfile(LOG_DEBUG, MSG_DEBUG_COMMAND \" [%s] [%s]\",\n                   cmd, strcmp(cmd, \"pass\") ? arg : \"<*>\");\n#endif\n        }\n#ifdef WITH_RFC2640\n        narg = charset_client2fs(arg);\n\targ = narg;\n#endif\n        /*\n         * antiidle() is called with dummy commands, usually used by clients\n         * who are wanting extra idle time. We give them some, but not too much.\n         * When we jump to wayout, the idle timer is not zeroed. It means that\n         * we didn't issue an 'active' command like RETR.\n         */\n        \n#ifndef MINIMAL\n        if (!strcmp(cmd, \"noop\")) {\n            antiidle();\n            donoop();\n            goto wayout;\n        }\n#endif\n        if (!strcmp(cmd, \"user\")) {\n#ifdef WITH_TLS\n            if (enforce_tls_auth > 1 && tls_cnx == NULL) {\n                die(421, LOG_WARNING, MSG_TLS_NEEDED);\n            }\n#endif\n            douser(arg);\n        } else if (!strcmp(cmd, \"acct\")) {\n            addreply(202, MSG_WHOAREYOU);\n        } else if (!strcmp(cmd, \"pass\")) {\n            if (guest == 0) {\n                randomdelay();\n            }\n            dopass(arg);\n        } else if (!strcmp(cmd, \"quit\")) {\n            addreply(221, MSG_GOODBYE,\n                     (unsigned long long) ((uploaded + 1023ULL) / 1024ULL),\n                     (unsigned long long) ((downloaded + 1023ULL) / 1024ULL));\n            return;\n        } else if (!strcmp(cmd, \"syst\")) {\n            antiidle();\n            addreply_noformat(215, \"UNIX Type: L8\");\n            goto wayout;\n#ifdef WITH_TLS\n        } else if (enforce_tls_auth > 0 &&\n                   !strcmp(cmd, \"auth\") && !strcasecmp(arg, \"tls\")) {\n            addreply_noformat(234, \"AUTH TLS OK.\");\n            doreply();\n            if (tls_cnx == NULL) {\n                flush_cmd();\n                (void) tls_init_new_session();\n            }\n            goto wayout;\n        } else if (!strcmp(cmd, \"pbsz\")) {\n            addreply_noformat(tls_cnx == NULL ? 503 : 200, \"PBSZ=0\");\n        } else if (!strcmp(cmd, \"prot\")) {\n            if (tls_cnx == NULL) {\n                addreply_noformat(503, MSG_PROT_BEFORE_PBSZ);\n                goto wayout;\n            }\n            switch (*arg) {\n            case 0:\n                addreply_noformat(503, MSG_MISSING_ARG);\n                data_protection_level = CPL_NONE;\n                break;\n            case 'C':\n                if (arg[1] == 0) {\n                    addreply(200, MSG_PROT_OK, \"clear\");\n                    data_protection_level = CPL_CLEAR;\n                    break;\n                }\n            case 'S':\n            case 'E':\n                if (arg[1] == 0) {\n                    addreply(200, MSG_PROT_UNKNOWN_LEVEL, arg, \"private\");\n                    data_protection_level = CPL_PRIVATE;\n                    break;\n                }\n            case 'P':\n                if (arg[1] == 0) {\n                    addreply(200, MSG_PROT_OK, \"private\");\n                    data_protection_level = CPL_PRIVATE;\n                    break;\n                }\n            default:\n                addreply_noformat(534, \"Fallback to [C]\");\n                data_protection_level = CPL_CLEAR;\n                break;\n            }\n#endif\n        } else if (!strcmp(cmd, \"auth\") || !strcmp(cmd, \"adat\")) {\n            addreply_noformat(500, MSG_AUTH_UNIMPLEMENTED);\n        } else if (!strcmp(cmd, \"type\")) {\n            antiidle();\n            dotype(arg);\n            goto wayout;\n        } else if (!strcmp(cmd, \"mode\")) {\n            antiidle();                \n            domode(arg);\n            goto wayout;\n#ifndef MINIMAL\n        } else if (!strcmp(cmd, \"feat\")) {\n            dofeat();\n            goto wayout;\n\t} else if (!strcmp(cmd, \"opts\")) {\n\t    doopts(arg);\n\t    goto wayout;\n#endif\n        } else if (!strcmp(cmd, \"stru\")) {\n            dostru(arg);\n            goto wayout;\n#ifndef MINIMAL\n        } else if (!strcmp(cmd, \"help\")) {\n            goto help_site;\n#endif\n#ifdef DEBUG\n        } else if (!strcmp(cmd, \"xdbg\")) {\n            debug++;\n            addreply(200, MSG_XDBG_OK, debug);\n            goto wayout;\n#endif            \n        } else if (loggedin == 0) {            \n            /* from this point, all commands need authentication */\n            addreply_noformat(530, MSG_NOT_LOGGED_IN);\n            goto wayout;\n        } else {\n            if (!strcmp(cmd, \"cwd\") || !strcmp(cmd, \"xcwd\")) {\n                antiidle();\n                docwd(arg);\n                goto wayout;\n            } else if (!strcmp(cmd, \"port\")) {\n                doport(arg);\n#ifndef MINIMAL\n            } else if (!strcmp(cmd, \"eprt\")) {\n                doeprt(arg);\n            } else if (!strcmp(cmd, \"esta\") &&\n                       disallow_passive == 0 &&\n                       STORAGE_FAMILY(force_passive_ip) == 0) {\n                doesta();\n            } else if (!strcmp(cmd, \"estp\")) {\n                doestp();\n#endif\n            } else if (disallow_passive == 0 && \n                       (!strcmp(cmd, \"pasv\") || !strcmp(cmd, \"p@sw\"))) {\n                dopasv(0);\n            } else if (disallow_passive == 0 && \n                       (!strcmp(cmd, \"epsv\") && \n                       (broken_client_compat == 0 ||\n                        STORAGE_FAMILY(ctrlconn) == AF_INET6))) {\n                if (!strcasecmp(arg, \"all\")) {\n                    epsv_all = 1;\n                    addreply_noformat(220, MSG_ACTIVE_DISABLED);\n                } else if (!strcmp(arg, \"2\") && !v6ready) {\n                    addreply_noformat(522, MSG_ONLY_IPV4);\n                } else {\n                    dopasv(1);\n                }\n#ifndef MINIMAL            \n            } else if (disallow_passive == 0 && !strcmp(cmd, \"spsv\")) {\n                dopasv(2);\n            } else if (!strcmp(cmd, \"allo\")) {\n                if (*arg == 0) {\n                    addreply_noformat(501, MSG_STAT_FAILURE);\n                } else {\n                    const off_t size = (off_t) strtoull(arg, NULL, 10);\n                    \n                    if (size < (off_t) 0) {\n                        addreply_noformat(501, MSG_STAT_FAILURE);                        \n                    } else {\n                        doallo(size);\n                    }\n                }\n#endif\n            } else if (!strcmp(cmd, \"pwd\") || !strcmp(cmd, \"xpwd\")) {\n#ifdef WITH_RFC2640\n\t\tchar *nwd;\n#endif\n                antiidle();\n#ifdef WITH_RFC2640\n\t\tnwd = charset_fs2client(wd);\n\t\taddreply(257, \"\\\"%s\\\" \" MSG_IS_YOUR_CURRENT_LOCATION, nwd);\n\t\tfree(nwd);\n#else\n                addreply(257, \"\\\"%s\\\" \" MSG_IS_YOUR_CURRENT_LOCATION, wd);\n#endif\n                goto wayout;                \n            } else if (!strcmp(cmd, \"cdup\") || !strcmp(cmd, \"xcup\")) {\n                docwd(\"..\");\n            } else if (!strcmp(cmd, \"retr\")) {\n                if (*arg != 0) {\n#ifdef WITH_TLS\n                    if (enforce_tls_auth == 3 &&\n                        data_protection_level != CPL_PRIVATE) {\n                        addreply_noformat(521, MSG_PROT_PRIVATE_NEEDED);\n                    }\n                    else\n#endif\n                    {\n                        doretr(arg);\n                    }\n                } else {\n                    addreply_noformat(501, MSG_NO_FILE_NAME);\n                }\n            } else if (!strcmp(cmd, \"rest\")) {\n                antiidle();\n                if (*arg != 0) {\n                    dorest(arg);\n                } else {\n                    addreply_noformat(501, MSG_NO_RESTART_POINT);\n                    restartat = (off_t) 0;\n                }\n                goto wayout;\n            } else if (!strcmp(cmd, \"dele\")) {\n                if (*arg != 0) {\n                    dodele(arg);\n                } else {\n                    addreply_noformat(501, MSG_NO_FILE_NAME);\n                }\n            } else if (!strcmp(cmd, \"stor\")) {\n                arg = revealextraspc(arg);\n                if (*arg != 0) {\n#ifdef WITH_TLS\n                    if (enforce_tls_auth == 3 &&\n                        data_protection_level != CPL_PRIVATE) {\n                        addreply_noformat(521, MSG_PROT_PRIVATE_NEEDED);\n                    } else \n#endif\n                    {\n                        dostor(arg, 0, autorename);\n                    }\n                } else {\n                    addreply_noformat(501, MSG_NO_FILE_NAME);\n                }\n            } else if (!strcmp(cmd, \"appe\")) {\n                arg = revealextraspc(arg);\n                if (*arg != 0) {\n#ifdef WITH_TLS\n                    if (enforce_tls_auth == 3 &&\n                        data_protection_level != CPL_PRIVATE) {\n                        addreply_noformat(521, MSG_PROT_PRIVATE_NEEDED);\n                    } else \n#endif\n                    {\n                        dostor(arg, 1, 0);\n                    }\n                } else {\n                    addreply_noformat(501, MSG_NO_FILE_NAME);\n                }\n#ifndef MINIMAL\n            } else if (!strcmp(cmd, \"stou\")) {\n#ifdef WITH_TLS\n                if (enforce_tls_auth == 3 &&\n                    data_protection_level != CPL_PRIVATE) {\n                    addreply_noformat(521, MSG_PROT_PRIVATE_NEEDED);\n                } else \n#endif\n                {\n            \t     dostou();\n                }\n#endif\n#ifndef DISABLE_MKD_RMD\n            } else if (!strcmp(cmd, \"mkd\") || !strcmp(cmd, \"xmkd\")) {\n                arg = revealextraspc(arg);\n                if (*arg != 0) {\n                    domkd(arg);\n                } else {\n                    addreply_noformat(501, MSG_NO_DIRECTORY_NAME);\n                }\n            } else if (!strcmp(cmd, \"rmd\") || !strcmp(cmd, \"xrmd\")) {\n                if (*arg != 0) {\n                    dormd(arg);\n                } else {\n                    addreply_noformat(550, MSG_NO_DIRECTORY_NAME);\n                }\n#endif\n#ifndef MINIMAL\n            } else if (!strcmp(cmd, \"stat\")) {\n                if (*arg != 0) {\n                    modern_listings = 0;\n                    donlist(arg, 1, 1, 1, 1);\n                } else {\n                    addreply_noformat(211, \"http://www.pureftpd.org/\");\n                }\n#endif\n            } else if (!strcmp(cmd, \"list\")) {\n#ifndef MINIMAL\n                modern_listings = 0;\n#endif\n#ifdef WITH_TLS\n                if (enforce_tls_auth == 3 &&\n                    data_protection_level != CPL_PRIVATE) {\n                    addreply_noformat(521, MSG_PROT_PRIVATE_NEEDED);\n                } else\n#endif\n                {\n                    donlist(arg, 0, 1, 0, 1);\n                }\n            } else if (!strcmp(cmd, \"nlst\")) {\n#ifndef MINIMAL                \n                modern_listings = 0;\n#endif\n#ifdef WITH_TLS\n                if (enforce_tls_auth == 3 &&\n                    data_protection_level != CPL_PRIVATE) {\n                    addreply_noformat(521, MSG_PROT_PRIVATE_NEEDED);\n                } else\n#endif\n                {\n                    donlist(arg, 0, 0, 0, broken_client_compat);\n                }\n#ifndef MINIMAL\n            } else if (!strcmp(cmd, \"mlst\")) {\n#ifdef WITH_TLS\n                if (enforce_tls_auth == 3 &&\n                    data_protection_level != CPL_PRIVATE) {\n                    addreply_noformat(521, MSG_PROT_PRIVATE_NEEDED);\n                } else\n#endif\n                {\n                    domlst(*arg != 0 ? arg : \".\");\n                }\n            } else if (!strcmp(cmd, \"mlsd\")) {\n                modern_listings = 1;\n#ifdef WITH_TLS\n                if (enforce_tls_auth == 3 &&\n                    data_protection_level != CPL_PRIVATE) {\n                    addreply_noformat(521, MSG_PROT_PRIVATE_NEEDED);\n                } else\n#endif\n                {\n                    donlist(arg, 0, 1, 1, 0);\n                }\n#endif\n            } else if (!strcmp(cmd, \"abor\")) {\n                addreply_noformat(226, MSG_ABOR_SUCCESS);\n#ifndef MINIMAL\n            } else if (!strcmp(cmd, \"site\")) {\n                if ((sitearg = arg) != NULL) {\n                    while (*sitearg != 0 && !isspace((unsigned char) *sitearg)) {\n                        sitearg++;\n                    }\n                    if (*sitearg != 0) {\n                        *sitearg++ = 0;\n                    }\n                }\n                if (!strcasecmp(arg, \"idle\")) {\n                    if (sitearg == NULL || *sitearg == 0) {\n                        addreply_noformat(501, \"SITE IDLE: \" MSG_MISSING_ARG);\n                    } else {\n                        unsigned long int i = 0;\n\n                        i = strtoul(sitearg, &sitearg, 10);\n                        if (sitearg && *sitearg)\n                            addreply(501, MSG_GARBAGE_FOUND \" : %s\", sitearg);\n                        else if (i > MAX_SITE_IDLE)\n                            addreply_noformat(501, MSG_VALUE_TOO_LARGE);\n                        else {\n                            idletime = i;\n                            addreply(200, MSG_IDLE_TIME, idletime);\n                            idletime_noop = (double) idletime * 2.0;\n                        }\n                    }\n                } else if (!strcasecmp(arg, \"time\")) {\n                    dositetime();\n                } else if (!strcasecmp(arg, \"help\")) {\n                    help_site:\n                    \n                    addreply_noformat(214, MSG_SITE_HELP CRLF\n# ifdef WITH_DIRALIASES\n                                      \" ALIAS\" CRLF\n# endif\n                                      \" CHMOD\" CRLF \" IDLE\" CRLF \" UTIME\");\n                    addreply_noformat(214, \"Pure-FTPd - http://pureftpd.org/\");\n                } else if (!strcasecmp(arg, \"chmod\")) {\n                    char *sitearg2;\n                    mode_t mode;\n                    \n                    parsechmod:\n                    if (sitearg == NULL || *sitearg == 0) {\n                        addreply_noformat(501, MSG_MISSING_ARG);\n                        goto chmod_wayout;\n                    }\n                    sitearg2 = sitearg;\n                    while (*sitearg2 != 0 && !isspace((unsigned char) *sitearg2)) {\n                        sitearg2++;\n                    }                    \n                    while (*sitearg2 != 0 && isspace((unsigned char) *sitearg2)) {\n                        sitearg2++;\n                    }                    \n                    if (*sitearg2 == 0) {\n                        addreply_noformat(550, MSG_NO_FILE_NAME);\n                        goto chmod_wayout;\n                    }\n                    mode = (mode_t) strtoul(sitearg, NULL, 8);\n                    if (mode > (mode_t) 07777) {\n                        addreply_noformat(501, MSG_BAD_CHMOD);\n                        goto chmod_wayout;\n                    }\n                    dochmod(sitearg2, mode);\n                    chmod_wayout:\n                    (void) 0;\n                } else if (!strcasecmp(arg, \"utime\")) {\n                    char *sitearg2;\n                    \n                    if (sitearg == NULL || *sitearg == 0) {\n                        addreply_noformat(501, MSG_NO_FILE_NAME);\n                        goto utime_wayout;\n                    }\t\t    \n                    if ((sitearg2 = strrchr(sitearg, ' ')) == NULL ||\n                        sitearg2 == sitearg) {\n                        addreply_noformat(501, MSG_MISSING_ARG);\n                        goto utime_wayout;\n                    }\n                    if (strcasecmp(sitearg2, \" UTC\") != 0) {\n                        addreply_noformat(500, \"UTC Only\");\n                        goto utime_wayout;\t\t\t\n                    }\n                    *sitearg2-- = 0;\n                    if ((sitearg2 = strrchr(sitearg, ' ')) == NULL ||\n                        sitearg2 == sitearg) {\n                        utime_no_arg:\n                        addreply_noformat(501, MSG_MISSING_ARG);\n                        goto utime_wayout;\n                    }\n                    *sitearg2-- = 0;\n                    if ((sitearg2 = strrchr(sitearg, ' ')) == NULL ||\n                        sitearg2 == sitearg) {\n                        goto utime_no_arg;\n                    }\n                    *sitearg2-- = 0;\n                    if ((sitearg2 = strrchr(sitearg, ' ')) == NULL ||\n                        sitearg2 == sitearg) {\n                        goto utime_no_arg;\n                    }\n                    *sitearg2++ = 0;\n                    if (*sitearg2 == 0) {\n                        goto utime_no_arg;\t\t\t\n                    }\n                    doutime(sitearg, sitearg2);\n                    utime_wayout:\n                    (void) 0;\n# ifdef WITH_DIRALIASES\t\t    \n                } else if (!strcasecmp(arg, \"alias\")) {\n                    if (sitearg == NULL || *sitearg == 0) {\n                        print_aliases();\n                    } else {\n                        const char *alias;\n                        \n                        if ((alias = lookup_alias(sitearg)) != NULL) {\n                            addreply(214, MSG_ALIASES_ALIAS, sitearg, alias);\n                        } else {\n                            addreply(502, MSG_ALIASES_UNKNOWN, sitearg);\n                        }\n                    }\n# endif\n                } else if (*arg != 0) {\n                    addreply(500, \"SITE %s \" MSG_UNKNOWN_EXTENSION, arg);\n                } else {\n                    addreply_noformat(500, \"SITE: \" MSG_MISSING_ARG);\n                }\n#endif\n            } else if (!strcmp(cmd, \"mdtm\")) {\n                domdtm(arg);\n            } else if (!strcmp(cmd, \"size\")) {\n                dosize(arg);\n#ifndef MINIMAL\n            } else if (!strcmp(cmd, \"chmod\")) {\n                sitearg = arg;\n                goto parsechmod;\n#endif\n            } else if (!strcmp(cmd, \"rnfr\")) {\n                if (*arg != 0) {\n                    dornfr(arg);\n                } else {\n                    addreply_noformat(550, MSG_NO_FILE_NAME);\n                }\n            } else if (!strcmp(cmd, \"rnto\")) {\n                arg = revealextraspc(arg);\n                if (*arg != 0) {\n                    dornto(arg);\n                } else {\n                    addreply_noformat(550, MSG_NO_FILE_NAME);\n                }\n            } else {\n                addreply_noformat(500, MSG_UNKNOWN_COMMAND);\n            }\n        }\n        noopidle = (time_t) -1;\n        wayout:\n#ifdef WITH_RFC2640\n        free(narg);\n        narg = NULL;\n#endif\n#ifdef THROTTLING\n        if (throttling_delay != 0UL) {\n            usleep2(throttling_delay);\n        }\n#else\n        (void) 0;\n#endif\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -136,6 +136,7 @@\n             addreply_noformat(234, \"AUTH TLS OK.\");\n             doreply();\n             if (tls_cnx == NULL) {\n+                flush_cmd();\n                 (void) tls_init_new_session();\n             }\n             goto wayout;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "                flush_cmd();"
            ]
        }
    },
    {
        "cve_id": "CVE-2011-2761",
        "func_name": "chromium/Widget::Init",
        "description": "Google Chrome 14.0.794.0 does not properly handle a reload of a page generated in response to a POST, which allows user-assisted remote attackers to cause a denial of service (application crash) via a crafted web site, related to GetWidget methods.",
        "git_url": "https://github.com/chromium/chromium/commit/080440cebdc80def86dd88356e5922946cc11a79",
        "commit_title": "Fix even more crashes. To help identify remaining crashes now and in the future, I have made the GetWidget methods on WidgetDelegate pure virtual. This will cause classes that don't define them to fail compile instead of crashing at run time.",
        "commit_text": " http://crbug.com/86119 ",
        "func_before": "void Widget::Init(const InitParams& params) {\n  widget_delegate_ =\n      params.delegate ? params.delegate : new DefaultWidgetDelegate;\n  ownership_ = params.ownership;\n  native_widget_ = params.native_widget ?\n      params.native_widget->AsNativeWidgetPrivate() :\n      internal::NativeWidgetPrivate::CreateNativeWidget(this);\n  GetRootView();\n  default_theme_provider_.reset(new DefaultThemeProvider);\n  if (params.type == InitParams::TYPE_MENU)\n    is_mouse_button_pressed_ = native_widget_->IsMouseButtonDown();\n  native_widget_->InitNativeWidget(params);\n  if (params.type == InitParams::TYPE_WINDOW) {\n    non_client_view_ = new NonClientView;\n    non_client_view_->SetFrameView(CreateNonClientFrameView());\n    // Create the ClientView, add it to the NonClientView and add the\n    // NonClientView to the RootView. This will cause everything to be parented.\n    non_client_view_->set_client_view(widget_delegate_->CreateClientView(this));\n    SetContentsView(non_client_view_);\n    SetInitialBounds(params.bounds);\n    UpdateWindowTitle();\n  }\n}",
        "func": "void Widget::Init(const InitParams& params) {\n  widget_delegate_ =\n      params.delegate ? params.delegate : new DefaultWidgetDelegate(this);\n  ownership_ = params.ownership;\n  native_widget_ = params.native_widget ?\n      params.native_widget->AsNativeWidgetPrivate() :\n      internal::NativeWidgetPrivate::CreateNativeWidget(this);\n  GetRootView();\n  default_theme_provider_.reset(new DefaultThemeProvider);\n  if (params.type == InitParams::TYPE_MENU)\n    is_mouse_button_pressed_ = native_widget_->IsMouseButtonDown();\n  native_widget_->InitNativeWidget(params);\n  if (params.type == InitParams::TYPE_WINDOW) {\n    non_client_view_ = new NonClientView;\n    non_client_view_->SetFrameView(CreateNonClientFrameView());\n    // Create the ClientView, add it to the NonClientView and add the\n    // NonClientView to the RootView. This will cause everything to be parented.\n    non_client_view_->set_client_view(widget_delegate_->CreateClientView(this));\n    SetContentsView(non_client_view_);\n    SetInitialBounds(params.bounds);\n    UpdateWindowTitle();\n  }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,6 @@\n void Widget::Init(const InitParams& params) {\n   widget_delegate_ =\n-      params.delegate ? params.delegate : new DefaultWidgetDelegate;\n+      params.delegate ? params.delegate : new DefaultWidgetDelegate(this);\n   ownership_ = params.ownership;\n   native_widget_ = params.native_widget ?\n       params.native_widget->AsNativeWidgetPrivate() :",
        "diff_line_info": {
            "deleted_lines": [
                "      params.delegate ? params.delegate : new DefaultWidgetDelegate;"
            ],
            "added_lines": [
                "      params.delegate ? params.delegate : new DefaultWidgetDelegate(this);"
            ]
        }
    },
    {
        "cve_id": "CVE-2011-2761",
        "func_name": "chromium/DefaultWidgetDelegate",
        "description": "Google Chrome 14.0.794.0 does not properly handle a reload of a page generated in response to a POST, which allows user-assisted remote attackers to cause a denial of service (application crash) via a crafted web site, related to GetWidget methods.",
        "git_url": "https://github.com/chromium/chromium/commit/080440cebdc80def86dd88356e5922946cc11a79",
        "commit_title": "Fix even more crashes. To help identify remaining crashes now and in the future, I have made the GetWidget methods on WidgetDelegate pure virtual. This will cause classes that don't define them to fail compile instead of crashing at run time.",
        "commit_text": " http://crbug.com/86119 ",
        "func_before": "DefaultWidgetDelegate() {}",
        "func": "explicit DefaultWidgetDelegate(Widget* widget) : widget_(widget) {}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1 +1 @@\n-DefaultWidgetDelegate() {}\n+explicit DefaultWidgetDelegate(Widget* widget) : widget_(widget) {}",
        "diff_line_info": {
            "deleted_lines": [
                "DefaultWidgetDelegate() {}"
            ],
            "added_lines": [
                "explicit DefaultWidgetDelegate(Widget* widget) : widget_(widget) {}"
            ]
        }
    },
    {
        "cve_id": "CVE-2011-2761",
        "func_name": "chromium/HandleKeyboardEvent",
        "description": "Google Chrome 14.0.794.0 does not properly handle a reload of a page generated in response to a POST, which allows user-assisted remote attackers to cause a denial of service (application crash) via a crafted web site, related to GetWidget methods.",
        "git_url": "https://github.com/chromium/chromium/commit/080440cebdc80def86dd88356e5922946cc11a79",
        "commit_title": "Fix even more crashes. To help identify remaining crashes now and in the future, I have made the GetWidget methods on WidgetDelegate pure virtual. This will cause classes that don't define them to fail compile instead of crashing at run time.",
        "commit_text": " http://crbug.com/86119 ",
        "func_before": "void HandleKeyboardEvent(const NativeWebKeyboardEvent& event) {}",
        "func": "void HandleKeyboardEvent(const NativeWebKeyboardEvent& event) OVERRIDE {}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1 +1 @@\n-void HandleKeyboardEvent(const NativeWebKeyboardEvent& event) {}\n+void HandleKeyboardEvent(const NativeWebKeyboardEvent& event) OVERRIDE {}",
        "diff_line_info": {
            "deleted_lines": [
                "void HandleKeyboardEvent(const NativeWebKeyboardEvent& event) {}"
            ],
            "added_lines": [
                "void HandleKeyboardEvent(const NativeWebKeyboardEvent& event) OVERRIDE {}"
            ]
        }
    },
    {
        "cve_id": "CVE-2011-2761",
        "func_name": "chromium/WindowClosing",
        "description": "Google Chrome 14.0.794.0 does not properly handle a reload of a page generated in response to a POST, which allows user-assisted remote attackers to cause a denial of service (application crash) via a crafted web site, related to GetWidget methods.",
        "git_url": "https://github.com/chromium/chromium/commit/080440cebdc80def86dd88356e5922946cc11a79",
        "commit_title": "Fix even more crashes. To help identify remaining crashes now and in the future, I have made the GetWidget methods on WidgetDelegate pure virtual. This will cause classes that don't define them to fail compile instead of crashing at run time.",
        "commit_text": " http://crbug.com/86119 ",
        "func_before": "virtual void WindowClosing() {\n    html_delegate_->OnWindowClosed();\n    html_delegate_->OnDialogClosed(\"\");\n  }",
        "func": "virtual void WindowClosing() OVERRIDE {\n    html_delegate_->OnWindowClosed();\n    html_delegate_->OnDialogClosed(\"\");\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,4 +1,4 @@\n-virtual void WindowClosing() {\n+virtual void WindowClosing() OVERRIDE {\n     html_delegate_->OnWindowClosed();\n     html_delegate_->OnDialogClosed(\"\");\n   }",
        "diff_line_info": {
            "deleted_lines": [
                "virtual void WindowClosing() {"
            ],
            "added_lines": [
                "virtual void WindowClosing() OVERRIDE {"
            ]
        }
    },
    {
        "cve_id": "CVE-2011-2761",
        "func_name": "chromium/MoveContents",
        "description": "Google Chrome 14.0.794.0 does not properly handle a reload of a page generated in response to a POST, which allows user-assisted remote attackers to cause a denial of service (application crash) via a crafted web site, related to GetWidget methods.",
        "git_url": "https://github.com/chromium/chromium/commit/080440cebdc80def86dd88356e5922946cc11a79",
        "commit_title": "Fix even more crashes. To help identify remaining crashes now and in the future, I have made the GetWidget methods on WidgetDelegate pure virtual. This will cause classes that don't define them to fail compile instead of crashing at run time.",
        "commit_text": " http://crbug.com/86119 ",
        "func_before": "void MoveContents(TabContents* source, const gfx::Rect& pos) {}",
        "func": "void MoveContents(TabContents* source, const gfx::Rect& pos) OVERRIDE {}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1 +1 @@\n-void MoveContents(TabContents* source, const gfx::Rect& pos) {}\n+void MoveContents(TabContents* source, const gfx::Rect& pos) OVERRIDE {}",
        "diff_line_info": {
            "deleted_lines": [
                "void MoveContents(TabContents* source, const gfx::Rect& pos) {}"
            ],
            "added_lines": [
                "void MoveContents(TabContents* source, const gfx::Rect& pos) OVERRIDE {}"
            ]
        }
    },
    {
        "cve_id": "CVE-2011-2761",
        "func_name": "chromium/ViewHierarchyChanged",
        "description": "Google Chrome 14.0.794.0 does not properly handle a reload of a page generated in response to a POST, which allows user-assisted remote attackers to cause a denial of service (application crash) via a crafted web site, related to GetWidget methods.",
        "git_url": "https://github.com/chromium/chromium/commit/080440cebdc80def86dd88356e5922946cc11a79",
        "commit_title": "Fix even more crashes. To help identify remaining crashes now and in the future, I have made the GetWidget methods on WidgetDelegate pure virtual. This will cause classes that don't define them to fail compile instead of crashing at run time.",
        "commit_text": " http://crbug.com/86119 ",
        "func_before": "virtual void ViewHierarchyChanged(bool is_add,\n                                    views::View* parent,\n                                    views::View* child) {\n    TabContentsContainer::ViewHierarchyChanged(is_add, parent, child);\n    if (is_add && child == this) {\n      ChangeTabContents(&html_tab_contents_);\n    }\n  }",
        "func": "virtual void ViewHierarchyChanged(bool is_add,\n                                    views::View* parent,\n                                    views::View* child) OVERRIDE {\n    TabContentsContainer::ViewHierarchyChanged(is_add, parent, child);\n    if (is_add && child == this) {\n      ChangeTabContents(&html_tab_contents_);\n    }\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,6 @@\n virtual void ViewHierarchyChanged(bool is_add,\n                                     views::View* parent,\n-                                    views::View* child) {\n+                                    views::View* child) OVERRIDE {\n     TabContentsContainer::ViewHierarchyChanged(is_add, parent, child);\n     if (is_add && child == this) {\n       ChangeTabContents(&html_tab_contents_);",
        "diff_line_info": {
            "deleted_lines": [
                "                                    views::View* child) {"
            ],
            "added_lines": [
                "                                    views::View* child) OVERRIDE {"
            ]
        }
    },
    {
        "cve_id": "CVE-2011-2761",
        "func_name": "chromium/GetPreferredSize",
        "description": "Google Chrome 14.0.794.0 does not properly handle a reload of a page generated in response to a POST, which allows user-assisted remote attackers to cause a denial of service (application crash) via a crafted web site, related to GetWidget methods.",
        "git_url": "https://github.com/chromium/chromium/commit/080440cebdc80def86dd88356e5922946cc11a79",
        "commit_title": "Fix even more crashes. To help identify remaining crashes now and in the future, I have made the GetWidget methods on WidgetDelegate pure virtual. This will cause classes that don't define them to fail compile instead of crashing at run time.",
        "commit_text": " http://crbug.com/86119 ",
        "func_before": "virtual gfx::Size GetPreferredSize() {\n    gfx::Size size;\n    html_delegate_->GetDialogSize(&size);\n    return size;\n  }",
        "func": "virtual gfx::Size GetPreferredSize() OVERRIDE {\n    gfx::Size size;\n    html_delegate_->GetDialogSize(&size);\n    return size;\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,4 +1,4 @@\n-virtual gfx::Size GetPreferredSize() {\n+virtual gfx::Size GetPreferredSize() OVERRIDE {\n     gfx::Size size;\n     html_delegate_->GetDialogSize(&size);\n     return size;",
        "diff_line_info": {
            "deleted_lines": [
                "virtual gfx::Size GetPreferredSize() {"
            ],
            "added_lines": [
                "virtual gfx::Size GetPreferredSize() OVERRIDE {"
            ]
        }
    },
    {
        "cve_id": "CVE-2011-2761",
        "func_name": "chromium/CanResize",
        "description": "Google Chrome 14.0.794.0 does not properly handle a reload of a page generated in response to a POST, which allows user-assisted remote attackers to cause a denial of service (application crash) via a crafted web site, related to GetWidget methods.",
        "git_url": "https://github.com/chromium/chromium/commit/080440cebdc80def86dd88356e5922946cc11a79",
        "commit_title": "Fix even more crashes. To help identify remaining crashes now and in the future, I have made the GetWidget methods on WidgetDelegate pure virtual. This will cause classes that don't define them to fail compile instead of crashing at run time.",
        "commit_text": " http://crbug.com/86119 ",
        "func_before": "virtual bool CanResize() const { return true; }",
        "func": "virtual bool CanResize() const OVERRIDE { return true; }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1 +1 @@\n-virtual bool CanResize() const { return true; }\n+virtual bool CanResize() const OVERRIDE { return true; }",
        "diff_line_info": {
            "deleted_lines": [
                "virtual bool CanResize() const { return true; }"
            ],
            "added_lines": [
                "virtual bool CanResize() const OVERRIDE { return true; }"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-10252",
        "func_name": "Opendigitalradio/ODR-PadEnc/SLSManager::encodeFile",
        "description": "Memory leak in the IsOptionMember function in MagickCore/option.c in ImageMagick before 6.9.2-2, as used in ODR-PadEnc and other products, allows attackers to trigger memory consumption.",
        "git_url": "https://github.com/Opendigitalradio/ODR-PadEnc/commit/7c9ab0e51ad3256ab836cf370a16e93099c65ed6",
        "commit_title": "SLS: fix conditional memleak",
        "commit_text": " A memleak occured when non-raw mode was used and a slide complied to the following conditions: - PNG/JPG file - 320x240 resolution or less - size above max slide size (~50 KB)  Closes #2.",
        "func_before": "bool SLSManager::encodeFile(const std::string& fname, int fidx, bool raw_slides)\n{\n    bool result = false;\n    int nseg, lastseglen, i, last, curseglen;\n#if HAVE_MAGICKWAND\n    MagickWand *m_wand = NULL;\n    MagickBooleanType err;\n#endif\n    size_t blobsize, height, width;\n    bool jpeg_progr;\n    unsigned char *blob = NULL;\n    unsigned char *curseg = NULL;\n    MSCDG msc;\n    DATA_GROUP* dgli;\n    DATA_GROUP* mscdg;\n\n    size_t orig_quality;\n    char*  orig_format = NULL;\n    /*! We handle JPEG differently, because we want to avoid recompressing the\n     * image if it is suitable as is\n     */\n    bool orig_is_jpeg = false;\n\n    /*! If the original is a PNG, we transmit it as is, if the resolution is correct\n     * and the file is not too large. Otherwise it gets resized and sent as JPEG.\n     */\n    bool orig_is_png = false;\n\n    /*! By default, we do resize the image to 320x240, with a quality such that\n     * the blobsize is at most MAXSLIDESIZE.\n     *\n     * For JPEG input files that are already at the right resolution and at the\n     * right blobsize, we disable this to avoid quality loss due to recompression\n     *\n     * As device support of this feature is optional, we furthermore require JPEG input\n     * files to not have progressive coding.\n     */\n    bool resize_required = true;\n\n    bool jfif_not_png = true;\n\n    if (!raw_slides) {\n#if HAVE_MAGICKWAND\n\n        m_wand = NewMagickWand();\n\n        err = MagickReadImage(m_wand, fname.c_str());\n        if (err == MagickFalse) {\n            fprintf(stderr, \"ODR-PadEnc Error: Unable to load image '%s'\\n\",\n                    fname.c_str());\n\n            goto encodefile_out;\n        }\n\n        height       = MagickGetImageHeight(m_wand);\n        width        = MagickGetImageWidth(m_wand);\n        orig_format  = MagickGetImageFormat(m_wand);\n        jpeg_progr   = MagickGetImageInterlaceScheme(m_wand) == JPEGInterlace;\n\n        // By default assume that the image has full quality and can be reduced\n        orig_quality = 100;\n\n        // strip unneeded information (profiles, meta data)\n        MagickStripImage(m_wand);\n\n        if (orig_format) {\n            if (strcmp(orig_format, \"JPEG\") == 0) {\n                orig_quality = MagickGetImageCompressionQuality(m_wand);\n                orig_is_jpeg = true;\n\n                if (verbose) {\n                    fprintf(stderr, \"ODR-PadEnc image: '\" \"\\x1B[33m\" \"%s\" \"\\x1B[0m\" \"' (id=%d).\"\n                            \" Original size: %zu x %zu. (%s, q=%zu, progr=%s)\\n\",\n                            fname.c_str(), fidx, width, height, orig_format, orig_quality, jpeg_progr ? \"y\" : \"n\");\n                }\n            }\n            else if (strcmp(orig_format, \"PNG\") == 0) {\n                orig_is_png = true;\n                jfif_not_png = false;\n\n                if (verbose) {\n                    fprintf(stderr, \"ODR-PadEnc image: '\" \"\\x1B[33m\" \"%s\" \"\\x1B[0m\" \"' (id=%d).\"\n                            \" Original size: %zu x %zu. (%s)\\n\",\n                            fname.c_str(), fidx, width, height, orig_format);\n                }\n            }\n            else if (verbose) {\n                fprintf(stderr, \"ODR-PadEnc image: '\" \"\\x1B[33m\" \"%s\" \"\\x1B[0m\" \"' (id=%d).\"\n                        \" Original size: %zu x %zu. (%s)\\n\",\n                        fname.c_str(), fidx, width, height, orig_format);\n            }\n\n            free(orig_format);\n        }\n        else {\n            fprintf(stderr, \"ODR-PadEnc Warning: Unable to detect image format of '%s'\\n\",\n                    fname.c_str());\n\n            fprintf(stderr, \"ODR-PadEnc image: '\" \"\\x1B[33m\" \"%s\" \"\\x1B[0m\" \"' (id=%d).  Original size: %zu x %zu.\\n\",\n                    fname.c_str(), fidx, width, height);\n        }\n\n        if ((orig_is_jpeg || orig_is_png) && height <= 240 && width <= 320 && not jpeg_progr) {\n            // Don't recompress the image and check if the blobsize is suitable\n            blob = MagickGetImageBlob(m_wand, &blobsize);\n\n            if (blobsize <= MAXSLIDESIZE) {\n                if (verbose) {\n                    fprintf(stderr, \"ODR-PadEnc image: '\" \"\\x1B[33m\" \"%s\" \"\\x1B[0m\" \"' (id=%d).  No resize needed: %zu Bytes\\n\",\n                            fname.c_str(), fidx, blobsize);\n                }\n                resize_required = false;\n            }\n        }\n\n        if (resize_required) {\n            blobsize = resizeImage(m_wand, &blob, fname, &jfif_not_png);\n        }\n        else {\n            // warn if unresized image smaller than default dimension\n            warnOnSmallerImage(height, width, fname);\n        }\n\n#else\n        fprintf(stderr, \"ODR-PadEnc has not been compiled with MagickWand, only RAW slides are supported!\\n\");\n        ret = -1;\n        goto encodefile_out;\n#endif\n    }\n    else { // Use RAW data, it might not even be a jpg !\n        // read file\n        FILE* pFile = fopen(fname.c_str(), \"rb\");\n        if (pFile == NULL) {\n            fprintf(stderr, \"ODR-PadEnc Error: Unable to load file '%s'\\n\",\n                    fname.c_str());\n            goto encodefile_out;\n        }\n\n        // obtain file size:\n        fseek(pFile, 0, SEEK_END);\n        blobsize = ftell(pFile);\n        rewind(pFile);\n\n        if (verbose) {\n            fprintf(stderr, \"ODR-PadEnc image: '\" \"\\x1B[33m\" \"%s\" \"\\x1B[0m\" \"' (id=%d). Raw file: %zu Bytes\\n\",\n                    fname.c_str(), fidx, blobsize);\n        }\n\n        if (blobsize > MAXSLIDESIZE) {\n            fprintf(stderr, \"ODR-PadEnc Warning: blob in raw-slide '%s' too large\\n\",\n                    fname.c_str());\n        }\n\n        // allocate memory to contain the whole file:\n        blob = (unsigned char*)malloc(sizeof(char) * blobsize);\n        if (blob == NULL) {\n            fprintf(stderr, \"ODR-PadEnc Error: Memory allocation error\\n\");\n            goto encodefile_out;\n        }\n\n        // copy the file into the buffer:\n        if (fread(blob, blobsize, 1, pFile) != 1) {\n            fprintf(stderr, \"ODR-PadEnc Error: Could not read file\\n\");\n            goto encodefile_out;\n        }\n\n        size_t last_dot = fname.rfind(\".\");\n\n        // default:\n        jfif_not_png = true; // This is how we did it in the past.\n                             // It's wrong anyway, so we're at least compatible\n\n        if (last_dot != std::string::npos) {\n            std::string file_extension = fname.substr(last_dot, std::string::npos);\n\n            std::transform(file_extension.begin(), file_extension.end(), file_extension.begin(), ::tolower);\n\n            if (file_extension == \".png\") {\n                jfif_not_png = false;\n            }\n        }\n\n        if (pFile != NULL) {\n            fclose(pFile);\n        }\n    }\n\n    if (blobsize) {\n        nseg = blobsize / MAXSEGLEN;\n        lastseglen = blobsize % MAXSEGLEN;\n        if (lastseglen != 0) {\n            nseg++;\n        }\n\n        uint8_vector_t mothdr = createMotHeader(blobsize, fidx, jfif_not_png, fname + SLS_PARAMS_SUFFIX);\n        // Create the MSC Data Group C-Structure\n        createMscDG(&msc, 3, &cindex_header, 0, 1, fidx, &mothdr[0], mothdr.size());\n        // Generate the MSC DG frame (Figure 9 en 300 401)\n        mscdg = packMscDG(&msc);\n        dgli = PADPacketizer::CreateDataGroupLengthIndicator(mscdg->data.size());\n\n        pad_packetizer->AddDG(dgli, false);\n        pad_packetizer->AddDG(mscdg, false);\n\n        for (i = 0; i < nseg; i++) {\n            curseg = blob + i * MAXSEGLEN;\n            if (i == nseg-1) {\n                curseglen = lastseglen;\n                last = 1;\n            }\n            else {\n                curseglen = MAXSEGLEN;\n                last = 0;\n            }\n\n            createMscDG(&msc, 4, &cindex_body, i, last, fidx, curseg, curseglen);\n            mscdg = packMscDG(&msc);\n            dgli = PADPacketizer::CreateDataGroupLengthIndicator(mscdg->data.size());\n\n            pad_packetizer->AddDG(dgli, false);\n            pad_packetizer->AddDG(mscdg, false);\n        }\n\n        result = true;\n    }\n\nencodefile_out:\n#if HAVE_MAGICKWAND\n    if (m_wand) {\n        m_wand = DestroyMagickWand(m_wand);\n    }\n#endif\n\n    if (blob) {\n        free(blob);\n    }\n    return result;\n}",
        "func": "bool SLSManager::encodeFile(const std::string& fname, int fidx, bool raw_slides)\n{\n    bool result = false;\n    int nseg, lastseglen, i, last, curseglen;\n#if HAVE_MAGICKWAND\n    MagickWand *m_wand = NULL;\n    MagickBooleanType err;\n#endif\n    size_t blobsize, height, width;\n    bool jpeg_progr;\n    unsigned char *blob = NULL;\n    unsigned char *curseg = NULL;\n    MSCDG msc;\n    DATA_GROUP* dgli;\n    DATA_GROUP* mscdg;\n\n    size_t orig_quality;\n    char*  orig_format = NULL;\n    /*! We handle JPEG differently, because we want to avoid recompressing the\n     * image if it is suitable as is\n     */\n    bool orig_is_jpeg = false;\n\n    /*! If the original is a PNG, we transmit it as is, if the resolution is correct\n     * and the file is not too large. Otherwise it gets resized and sent as JPEG.\n     */\n    bool orig_is_png = false;\n\n    /*! By default, we do resize the image to 320x240, with a quality such that\n     * the blobsize is at most MAXSLIDESIZE.\n     *\n     * For JPEG input files that are already at the right resolution and at the\n     * right blobsize, we disable this to avoid quality loss due to recompression\n     *\n     * As device support of this feature is optional, we furthermore require JPEG input\n     * files to not have progressive coding.\n     */\n    bool resize_required = true;\n\n    bool jfif_not_png = true;\n\n    if (!raw_slides) {\n#if HAVE_MAGICKWAND\n\n        m_wand = NewMagickWand();\n\n        err = MagickReadImage(m_wand, fname.c_str());\n        if (err == MagickFalse) {\n            fprintf(stderr, \"ODR-PadEnc Error: Unable to load image '%s'\\n\",\n                    fname.c_str());\n\n            goto encodefile_out;\n        }\n\n        height       = MagickGetImageHeight(m_wand);\n        width        = MagickGetImageWidth(m_wand);\n        orig_format  = MagickGetImageFormat(m_wand);\n        jpeg_progr   = MagickGetImageInterlaceScheme(m_wand) == JPEGInterlace;\n\n        // By default assume that the image has full quality and can be reduced\n        orig_quality = 100;\n\n        // strip unneeded information (profiles, meta data)\n        MagickStripImage(m_wand);\n\n        if (orig_format) {\n            if (strcmp(orig_format, \"JPEG\") == 0) {\n                orig_quality = MagickGetImageCompressionQuality(m_wand);\n                orig_is_jpeg = true;\n\n                if (verbose) {\n                    fprintf(stderr, \"ODR-PadEnc image: '\" \"\\x1B[33m\" \"%s\" \"\\x1B[0m\" \"' (id=%d).\"\n                            \" Original size: %zu x %zu. (%s, q=%zu, progr=%s)\\n\",\n                            fname.c_str(), fidx, width, height, orig_format, orig_quality, jpeg_progr ? \"y\" : \"n\");\n                }\n            }\n            else if (strcmp(orig_format, \"PNG\") == 0) {\n                orig_is_png = true;\n                jfif_not_png = false;\n\n                if (verbose) {\n                    fprintf(stderr, \"ODR-PadEnc image: '\" \"\\x1B[33m\" \"%s\" \"\\x1B[0m\" \"' (id=%d).\"\n                            \" Original size: %zu x %zu. (%s)\\n\",\n                            fname.c_str(), fidx, width, height, orig_format);\n                }\n            }\n            else if (verbose) {\n                fprintf(stderr, \"ODR-PadEnc image: '\" \"\\x1B[33m\" \"%s\" \"\\x1B[0m\" \"' (id=%d).\"\n                        \" Original size: %zu x %zu. (%s)\\n\",\n                        fname.c_str(), fidx, width, height, orig_format);\n            }\n\n            free(orig_format);\n        }\n        else {\n            fprintf(stderr, \"ODR-PadEnc Warning: Unable to detect image format of '%s'\\n\",\n                    fname.c_str());\n\n            fprintf(stderr, \"ODR-PadEnc image: '\" \"\\x1B[33m\" \"%s\" \"\\x1B[0m\" \"' (id=%d).  Original size: %zu x %zu.\\n\",\n                    fname.c_str(), fidx, width, height);\n        }\n\n        if ((orig_is_jpeg || orig_is_png) && height <= 240 && width <= 320 && not jpeg_progr) {\n            // Don't recompress the image and check if the blobsize is suitable\n            blob = MagickGetImageBlob(m_wand, &blobsize);\n\n            if (blobsize <= MAXSLIDESIZE) {\n                if (verbose) {\n                    fprintf(stderr, \"ODR-PadEnc image: '\" \"\\x1B[33m\" \"%s\" \"\\x1B[0m\" \"' (id=%d).  No resize needed: %zu Bytes\\n\",\n                            fname.c_str(), fidx, blobsize);\n                }\n                resize_required = false;\n            } else {\n                free(blob);\n                blob = NULL;\n            }\n        }\n\n        if (resize_required) {\n            blobsize = resizeImage(m_wand, &blob, fname, &jfif_not_png);\n        }\n        else {\n            // warn if unresized image smaller than default dimension\n            warnOnSmallerImage(height, width, fname);\n        }\n\n#else\n        fprintf(stderr, \"ODR-PadEnc has not been compiled with MagickWand, only RAW slides are supported!\\n\");\n        ret = -1;\n        goto encodefile_out;\n#endif\n    }\n    else { // Use RAW data, it might not even be a jpg !\n        // read file\n        FILE* pFile = fopen(fname.c_str(), \"rb\");\n        if (pFile == NULL) {\n            fprintf(stderr, \"ODR-PadEnc Error: Unable to load file '%s'\\n\",\n                    fname.c_str());\n            goto encodefile_out;\n        }\n\n        // obtain file size:\n        fseek(pFile, 0, SEEK_END);\n        blobsize = ftell(pFile);\n        rewind(pFile);\n\n        if (verbose) {\n            fprintf(stderr, \"ODR-PadEnc image: '\" \"\\x1B[33m\" \"%s\" \"\\x1B[0m\" \"' (id=%d). Raw file: %zu Bytes\\n\",\n                    fname.c_str(), fidx, blobsize);\n        }\n\n        if (blobsize > MAXSLIDESIZE) {\n            fprintf(stderr, \"ODR-PadEnc Warning: blob in raw-slide '%s' too large\\n\",\n                    fname.c_str());\n        }\n\n        // allocate memory to contain the whole file:\n        blob = (unsigned char*)malloc(sizeof(char) * blobsize);\n        if (blob == NULL) {\n            fprintf(stderr, \"ODR-PadEnc Error: Memory allocation error\\n\");\n            goto encodefile_out;\n        }\n\n        // copy the file into the buffer:\n        if (fread(blob, blobsize, 1, pFile) != 1) {\n            fprintf(stderr, \"ODR-PadEnc Error: Could not read file\\n\");\n            goto encodefile_out;\n        }\n\n        size_t last_dot = fname.rfind(\".\");\n\n        // default:\n        jfif_not_png = true; // This is how we did it in the past.\n                             // It's wrong anyway, so we're at least compatible\n\n        if (last_dot != std::string::npos) {\n            std::string file_extension = fname.substr(last_dot, std::string::npos);\n\n            std::transform(file_extension.begin(), file_extension.end(), file_extension.begin(), ::tolower);\n\n            if (file_extension == \".png\") {\n                jfif_not_png = false;\n            }\n        }\n\n        if (pFile != NULL) {\n            fclose(pFile);\n        }\n    }\n\n    if (blobsize) {\n        nseg = blobsize / MAXSEGLEN;\n        lastseglen = blobsize % MAXSEGLEN;\n        if (lastseglen != 0) {\n            nseg++;\n        }\n\n        uint8_vector_t mothdr = createMotHeader(blobsize, fidx, jfif_not_png, fname + SLS_PARAMS_SUFFIX);\n        // Create the MSC Data Group C-Structure\n        createMscDG(&msc, 3, &cindex_header, 0, 1, fidx, &mothdr[0], mothdr.size());\n        // Generate the MSC DG frame (Figure 9 en 300 401)\n        mscdg = packMscDG(&msc);\n        dgli = PADPacketizer::CreateDataGroupLengthIndicator(mscdg->data.size());\n\n        pad_packetizer->AddDG(dgli, false);\n        pad_packetizer->AddDG(mscdg, false);\n\n        for (i = 0; i < nseg; i++) {\n            curseg = blob + i * MAXSEGLEN;\n            if (i == nseg-1) {\n                curseglen = lastseglen;\n                last = 1;\n            }\n            else {\n                curseglen = MAXSEGLEN;\n                last = 0;\n            }\n\n            createMscDG(&msc, 4, &cindex_body, i, last, fidx, curseg, curseglen);\n            mscdg = packMscDG(&msc);\n            dgli = PADPacketizer::CreateDataGroupLengthIndicator(mscdg->data.size());\n\n            pad_packetizer->AddDG(dgli, false);\n            pad_packetizer->AddDG(mscdg, false);\n        }\n\n        result = true;\n    }\n\nencodefile_out:\n#if HAVE_MAGICKWAND\n    if (m_wand) {\n        m_wand = DestroyMagickWand(m_wand);\n    }\n#endif\n\n    if (blob) {\n        free(blob);\n    }\n    return result;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -110,6 +110,9 @@\n                             fname.c_str(), fidx, blobsize);\n                 }\n                 resize_required = false;\n+            } else {\n+                free(blob);\n+                blob = NULL;\n             }\n         }\n ",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "            } else {",
                "                free(blob);",
                "                blob = NULL;"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-10163",
        "func_name": "virglrenderer/vrend_renderer_context_create_internal",
        "description": "Memory leak in the vrend_renderer_context_create_internal function in vrend_decode.c in virglrenderer before 0.6.0 allows local guest OS users to cause a denial of service (host memory consumption) by repeatedly creating a decode context.",
        "git_url": "https://cgit.freedesktop.org/virglrenderer/commit/?id=747a293ff6055203e529f083896b823e22523fe7",
        "commit_title": "Create a context more than once causes memory leak issue.",
        "commit_text": "Juest return if the context exists.  ",
        "func_before": "void vrend_renderer_context_create_internal(uint32_t handle, uint32_t nlen,\n                                            const char *debug_name)\n{\n   struct vrend_decode_ctx *dctx;\n\n   if (handle >= VREND_MAX_CTX)\n      return;\n\n   dctx = malloc(sizeof(struct vrend_decode_ctx));\n   if (!dctx)\n      return;\n\n   dctx->grctx = vrend_create_context(handle, nlen, debug_name);\n   if (!dctx->grctx) {\n      free(dctx);\n      return;\n   }\n\n   dctx->ds = &dctx->ids;\n\n   dec_ctx[handle] = dctx;\n}",
        "func": "void vrend_renderer_context_create_internal(uint32_t handle, uint32_t nlen,\n                                            const char *debug_name)\n{\n   struct vrend_decode_ctx *dctx;\n\n   if (handle >= VREND_MAX_CTX)\n      return;\n\n   dctx = dec_ctx[handle];\n   if (dctx)\n      return;\n\n   dctx = malloc(sizeof(struct vrend_decode_ctx));\n   if (!dctx)\n      return;\n\n   dctx->grctx = vrend_create_context(handle, nlen, debug_name);\n   if (!dctx->grctx) {\n      free(dctx);\n      return;\n   }\n\n   dctx->ds = &dctx->ids;\n\n   dec_ctx[handle] = dctx;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,6 +4,10 @@\n    struct vrend_decode_ctx *dctx;\n \n    if (handle >= VREND_MAX_CTX)\n+      return;\n+\n+   dctx = dec_ctx[handle];\n+   if (dctx)\n       return;\n \n    dctx = malloc(sizeof(struct vrend_decode_ctx));",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "      return;",
                "",
                "   dctx = dec_ctx[handle];",
                "   if (dctx)"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-10214",
        "func_name": "virglrenderer/vrend_renderer_resource_attach_iov",
        "description": "Memory leak in the virgl_resource_attach_backing function in virglrenderer before 0.6.0 allows local guest OS users to cause a denial of service (memory consumption) via a large number of VIRTIO_GPU_CMD_RESOURCE_ATTACH_BACKING commands.",
        "git_url": "https://cgit.freedesktop.org/virglrenderer/commit/?id=40b0e7813325b08077b6f541b3989edb2d86d837",
        "commit_title": "Just return if the resource has been attached a iov",
        "commit_text": "to avoid memory leak.  ",
        "func_before": "int vrend_renderer_resource_attach_iov(int res_handle, struct iovec *iov,\n                                       int num_iovs)\n{\n   struct vrend_resource *res;\n\n   res = vrend_resource_lookup(res_handle, 0);\n   if (!res)\n      return EINVAL;\n\n   /* work out size and max resource size */\n   res->iov = iov;\n   res->num_iovs = num_iovs;\n   return 0;\n}",
        "func": "int vrend_renderer_resource_attach_iov(int res_handle, struct iovec *iov,\n                                       int num_iovs)\n{\n   struct vrend_resource *res;\n\n   res = vrend_resource_lookup(res_handle, 0);\n   if (!res)\n      return EINVAL;\n\n   if (res->iov)\n      return 0;\n\n   /* work out size and max resource size */\n   res->iov = iov;\n   res->num_iovs = num_iovs;\n   return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -7,6 +7,9 @@\n    if (!res)\n       return EINVAL;\n \n+   if (res->iov)\n+      return 0;\n+\n    /* work out size and max resource size */\n    res->iov = iov;\n    res->num_iovs = num_iovs;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "   if (res->iov)",
                "      return 0;",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2016-10146",
        "func_name": "ImageMagick/ReadCAPTIONImage",
        "description": "Multiple memory leaks in the caption and label handling code in ImageMagick allow remote attackers to cause a denial of service (memory consumption) via unspecified vectors.",
        "git_url": "https://github.com/ImageMagick/ImageMagick/commit/aeff00de228bc5a158c2a975ab47845d8a1db456",
        "commit_title": "Fix a small memory leak",
        "commit_text": "",
        "func_before": "static Image *ReadCAPTIONImage(const ImageInfo *image_info,\n  ExceptionInfo *exception)\n{\n  char\n    *caption,\n    geometry[MaxTextExtent],\n    *property,\n    *text;\n\n  const char\n    *gravity,\n    *option;\n\n  DrawInfo\n    *draw_info;\n\n  Image\n    *image;\n\n  MagickBooleanType\n    split,\n    status;\n\n  register ssize_t\n    i;\n\n  size_t\n    height,\n    width;\n\n  TypeMetric\n    metrics;\n\n  /*\n    Initialize Image structure.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickSignature);\n  image=AcquireImage(image_info);\n  (void) ResetImagePage(image,\"0x0+0+0\");\n  /*\n    Format caption.\n  */\n  option=GetImageOption(image_info,\"filename\");\n  if (option == (const char *) NULL)\n    property=InterpretImageProperties(image_info,image,image_info->filename);\n  else\n    if (LocaleNCompare(option,\"caption:\",8) == 0)\n      property=InterpretImageProperties(image_info,image,option+8);\n    else\n      property=InterpretImageProperties(image_info,image,option);\n  (void) SetImageProperty(image,\"caption\",property);\n  property=DestroyString(property);\n  caption=ConstantString(GetImageProperty(image,\"caption\"));\n  draw_info=CloneDrawInfo(image_info,(DrawInfo *) NULL);\n  (void) CloneString(&draw_info->text,caption);\n  gravity=GetImageOption(image_info,\"gravity\");\n  if (gravity != (char *) NULL)\n    draw_info->gravity=(GravityType) ParseCommandOption(MagickGravityOptions,\n      MagickFalse,gravity);\n  split=MagickFalse;\n  status=MagickTrue;\n  if (image->columns == 0)\n    {\n      text=AcquireString(caption);\n      i=FormatMagickCaption(image,draw_info,split,&metrics,&text);\n      (void) CloneString(&draw_info->text,text);\n      text=DestroyString(text);\n      (void) FormatLocaleString(geometry,MaxTextExtent,\"%+g%+g\",\n        -metrics.bounds.x1,metrics.ascent);\n      if (draw_info->gravity == UndefinedGravity)\n        (void) CloneString(&draw_info->geometry,geometry);\n      status=GetMultilineTypeMetrics(image,draw_info,&metrics);\n      width=(size_t) floor(metrics.width+draw_info->stroke_width+0.5);\n      image->columns=width;\n    }\n  if (image->rows == 0)\n    {\n      split=MagickTrue;\n      text=AcquireString(caption);\n      i=FormatMagickCaption(image,draw_info,split,&metrics,&text);\n      (void) CloneString(&draw_info->text,text);\n      text=DestroyString(text);\n      (void) FormatLocaleString(geometry,MaxTextExtent,\"%+g%+g\",\n        -metrics.bounds.x1,metrics.ascent);\n      if (draw_info->gravity == UndefinedGravity)\n        (void) CloneString(&draw_info->geometry,geometry);\n      status=GetMultilineTypeMetrics(image,draw_info,&metrics);\n      image->rows=(size_t) ((i+1)*(metrics.ascent-metrics.descent+\n        draw_info->interline_spacing+draw_info->stroke_width)+0.5);\n    }\n  if (status != MagickFalse)\n    status=SetImageExtent(image,image->columns,image->rows);\n  if (status == MagickFalse)\n    { \n      draw_info=DestroyDrawInfo(draw_info);\n      InheritException(exception,&image->exception);\n      return(DestroyImageList(image));\n    }\n  if (SetImageBackgroundColor(image) == MagickFalse)\n    {\n      draw_info=DestroyDrawInfo(draw_info);\n      InheritException(exception,&image->exception);\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  if ((fabs(image_info->pointsize) < MagickEpsilon) && (strlen(caption) > 0))\n    {\n      double\n        high,\n        low;\n\n      /*\n        Auto fit text into bounding box.\n      */\n      for ( ; ; draw_info->pointsize*=2.0)\n      {\n        text=AcquireString(caption);\n        i=FormatMagickCaption(image,draw_info,split,&metrics,&text);\n        (void) CloneString(&draw_info->text,text);\n        text=DestroyString(text);\n        (void) FormatLocaleString(geometry,MaxTextExtent,\"%+g%+g\",\n          -metrics.bounds.x1,metrics.ascent);\n        if (draw_info->gravity == UndefinedGravity)\n          (void) CloneString(&draw_info->geometry,geometry);\n        status=GetMultilineTypeMetrics(image,draw_info,&metrics);\n        (void) status;\n        width=(size_t) floor(metrics.width+draw_info->stroke_width+0.5);\n        height=(size_t) floor(metrics.height+draw_info->stroke_width+0.5);\n        if ((image->columns != 0) && (image->rows != 0))\n          {\n            if ((width >= image->columns) && (height >= image->rows))\n              break;\n          }\n        else\n          if (((image->columns != 0) && (width >= image->columns)) ||\n              ((image->rows != 0) && (height >= image->rows)))\n            break;\n      }\n      high=draw_info->pointsize;\n      for (low=1.0; (high-low) > 0.5; )\n      {\n        draw_info->pointsize=(low+high)/2.0;\n        text=AcquireString(caption);\n        i=FormatMagickCaption(image,draw_info,split,&metrics,&text);\n        (void) CloneString(&draw_info->text,text);\n        text=DestroyString(text);\n        (void) FormatLocaleString(geometry,MaxTextExtent,\"%+g%+g\",\n          -metrics.bounds.x1,metrics.ascent);\n        if (draw_info->gravity == UndefinedGravity)\n          (void) CloneString(&draw_info->geometry,geometry);\n        (void) GetMultilineTypeMetrics(image,draw_info,&metrics);\n        width=(size_t) floor(metrics.width+draw_info->stroke_width+0.5);\n        height=(size_t) floor(metrics.height+draw_info->stroke_width+0.5);\n        if ((image->columns != 0) && (image->rows != 0))\n          {\n            if ((width < image->columns) && (height < image->rows))\n              low=draw_info->pointsize+0.5;\n            else\n              high=draw_info->pointsize-0.5;\n          }\n        else\n          if (((image->columns != 0) && (width < image->columns)) ||\n              ((image->rows != 0) && (height < image->rows)))\n            low=draw_info->pointsize+0.5;\n          else\n            high=draw_info->pointsize-0.5;\n      }\n      draw_info->pointsize=floor((low+high)/2.0-0.5);\n    }\n  /*\n    Draw caption.\n  */\n  i=FormatMagickCaption(image,draw_info,split,&metrics,&caption);\n  (void) CloneString(&draw_info->text,caption);\n  (void) FormatLocaleString(geometry,MaxTextExtent,\"%+g%+g\",MagickMax(\n    draw_info->direction == RightToLeftDirection ? image->columns-\n    metrics.bounds.x2 : -metrics.bounds.x1,0.0),draw_info->gravity ==\n    UndefinedGravity ? metrics.ascent : 0.0);\n  draw_info->geometry=AcquireString(geometry);\n  status=AnnotateImage(image,draw_info);\n  if (image_info->pointsize == 0.0)\n    { \n      char\n        pointsize[MaxTextExtent];\n      \n      (void) FormatLocaleString(pointsize,MaxTextExtent,\"%.20g\",\n        draw_info->pointsize);\n      (void) SetImageProperty(image,\"caption:pointsize\",pointsize);\n    }\n  draw_info=DestroyDrawInfo(draw_info);\n  caption=DestroyString(caption);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  return(GetFirstImageInList(image));\n}",
        "func": "static Image *ReadCAPTIONImage(const ImageInfo *image_info,\n  ExceptionInfo *exception)\n{\n  char\n    *caption,\n    geometry[MaxTextExtent],\n    *property,\n    *text;\n\n  const char\n    *gravity,\n    *option;\n\n  DrawInfo\n    *draw_info;\n\n  Image\n    *image;\n\n  MagickBooleanType\n    split,\n    status;\n\n  register ssize_t\n    i;\n\n  size_t\n    height,\n    width;\n\n  TypeMetric\n    metrics;\n\n  /*\n    Initialize Image structure.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickSignature);\n  image=AcquireImage(image_info);\n  (void) ResetImagePage(image,\"0x0+0+0\");\n  /*\n    Format caption.\n  */\n  option=GetImageOption(image_info,\"filename\");\n  if (option == (const char *) NULL)\n    property=InterpretImageProperties(image_info,image,image_info->filename);\n  else\n    if (LocaleNCompare(option,\"caption:\",8) == 0)\n      property=InterpretImageProperties(image_info,image,option+8);\n    else\n      property=InterpretImageProperties(image_info,image,option);\n  (void) SetImageProperty(image,\"caption\",property);\n  property=DestroyString(property);\n  caption=ConstantString(GetImageProperty(image,\"caption\"));\n  draw_info=CloneDrawInfo(image_info,(DrawInfo *) NULL);\n  (void) CloneString(&draw_info->text,caption);\n  gravity=GetImageOption(image_info,\"gravity\");\n  if (gravity != (char *) NULL)\n    draw_info->gravity=(GravityType) ParseCommandOption(MagickGravityOptions,\n      MagickFalse,gravity);\n  split=MagickFalse;\n  status=MagickTrue;\n  if (image->columns == 0)\n    {\n      text=AcquireString(caption);\n      i=FormatMagickCaption(image,draw_info,split,&metrics,&text);\n      (void) CloneString(&draw_info->text,text);\n      text=DestroyString(text);\n      (void) FormatLocaleString(geometry,MaxTextExtent,\"%+g%+g\",\n        -metrics.bounds.x1,metrics.ascent);\n      if (draw_info->gravity == UndefinedGravity)\n        (void) CloneString(&draw_info->geometry,geometry);\n      status=GetMultilineTypeMetrics(image,draw_info,&metrics);\n      width=(size_t) floor(metrics.width+draw_info->stroke_width+0.5);\n      image->columns=width;\n    }\n  if (image->rows == 0)\n    {\n      split=MagickTrue;\n      text=AcquireString(caption);\n      i=FormatMagickCaption(image,draw_info,split,&metrics,&text);\n      (void) CloneString(&draw_info->text,text);\n      text=DestroyString(text);\n      (void) FormatLocaleString(geometry,MaxTextExtent,\"%+g%+g\",\n        -metrics.bounds.x1,metrics.ascent);\n      if (draw_info->gravity == UndefinedGravity)\n        (void) CloneString(&draw_info->geometry,geometry);\n      status=GetMultilineTypeMetrics(image,draw_info,&metrics);\n      image->rows=(size_t) ((i+1)*(metrics.ascent-metrics.descent+\n        draw_info->interline_spacing+draw_info->stroke_width)+0.5);\n    }\n  if (status != MagickFalse)\n    status=SetImageExtent(image,image->columns,image->rows);\n  if (status == MagickFalse)\n    { \n      draw_info=DestroyDrawInfo(draw_info);\n      InheritException(exception,&image->exception);\n      return(DestroyImageList(image));\n    }\n  if (SetImageBackgroundColor(image) == MagickFalse)\n    {\n      draw_info=DestroyDrawInfo(draw_info);\n      InheritException(exception,&image->exception);\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  if ((fabs(image_info->pointsize) < MagickEpsilon) && (strlen(caption) > 0))\n    {\n      double\n        high,\n        low;\n\n      /*\n        Auto fit text into bounding box.\n      */\n      for ( ; ; draw_info->pointsize*=2.0)\n      {\n        text=AcquireString(caption);\n        i=FormatMagickCaption(image,draw_info,split,&metrics,&text);\n        (void) CloneString(&draw_info->text,text);\n        text=DestroyString(text);\n        (void) FormatLocaleString(geometry,MaxTextExtent,\"%+g%+g\",\n          -metrics.bounds.x1,metrics.ascent);\n        if (draw_info->gravity == UndefinedGravity)\n          (void) CloneString(&draw_info->geometry,geometry);\n        status=GetMultilineTypeMetrics(image,draw_info,&metrics);\n        (void) status;\n        width=(size_t) floor(metrics.width+draw_info->stroke_width+0.5);\n        height=(size_t) floor(metrics.height+draw_info->stroke_width+0.5);\n        if ((image->columns != 0) && (image->rows != 0))\n          {\n            if ((width >= image->columns) && (height >= image->rows))\n              break;\n          }\n        else\n          if (((image->columns != 0) && (width >= image->columns)) ||\n              ((image->rows != 0) && (height >= image->rows)))\n            break;\n      }\n      high=draw_info->pointsize;\n      for (low=1.0; (high-low) > 0.5; )\n      {\n        draw_info->pointsize=(low+high)/2.0;\n        text=AcquireString(caption);\n        i=FormatMagickCaption(image,draw_info,split,&metrics,&text);\n        (void) CloneString(&draw_info->text,text);\n        text=DestroyString(text);\n        (void) FormatLocaleString(geometry,MaxTextExtent,\"%+g%+g\",\n          -metrics.bounds.x1,metrics.ascent);\n        if (draw_info->gravity == UndefinedGravity)\n          (void) CloneString(&draw_info->geometry,geometry);\n        (void) GetMultilineTypeMetrics(image,draw_info,&metrics);\n        width=(size_t) floor(metrics.width+draw_info->stroke_width+0.5);\n        height=(size_t) floor(metrics.height+draw_info->stroke_width+0.5);\n        if ((image->columns != 0) && (image->rows != 0))\n          {\n            if ((width < image->columns) && (height < image->rows))\n              low=draw_info->pointsize+0.5;\n            else\n              high=draw_info->pointsize-0.5;\n          }\n        else\n          if (((image->columns != 0) && (width < image->columns)) ||\n              ((image->rows != 0) && (height < image->rows)))\n            low=draw_info->pointsize+0.5;\n          else\n            high=draw_info->pointsize-0.5;\n      }\n      draw_info->pointsize=floor((low+high)/2.0-0.5);\n    }\n  /*\n    Draw caption.\n  */\n  i=FormatMagickCaption(image,draw_info,split,&metrics,&caption);\n  (void) CloneString(&draw_info->text,caption);\n  (void) FormatLocaleString(geometry,MaxTextExtent,\"%+g%+g\",MagickMax(\n    draw_info->direction == RightToLeftDirection ? image->columns-\n    metrics.bounds.x2 : -metrics.bounds.x1,0.0),draw_info->gravity ==\n    UndefinedGravity ? metrics.ascent : 0.0);\n  (void) CloneString(&draw_info->geometry,geometry);\n  status=AnnotateImage(image,draw_info);\n  if (image_info->pointsize == 0.0)\n    { \n      char\n        pointsize[MaxTextExtent];\n      \n      (void) FormatLocaleString(pointsize,MaxTextExtent,\"%.20g\",\n        draw_info->pointsize);\n      (void) SetImageProperty(image,\"caption:pointsize\",pointsize);\n    }\n  draw_info=DestroyDrawInfo(draw_info);\n  caption=DestroyString(caption);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  return(GetFirstImageInList(image));\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -182,7 +182,7 @@\n     draw_info->direction == RightToLeftDirection ? image->columns-\n     metrics.bounds.x2 : -metrics.bounds.x1,0.0),draw_info->gravity ==\n     UndefinedGravity ? metrics.ascent : 0.0);\n-  draw_info->geometry=AcquireString(geometry);\n+  (void) CloneString(&draw_info->geometry,geometry);\n   status=AnnotateImage(image,draw_info);\n   if (image_info->pointsize == 0.0)\n     { ",
        "diff_line_info": {
            "deleted_lines": [
                "  draw_info->geometry=AcquireString(geometry);"
            ],
            "added_lines": [
                "  (void) CloneString(&draw_info->geometry,geometry);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-10146",
        "func_name": "ImageMagick/ReadLABELImage",
        "description": "Multiple memory leaks in the caption and label handling code in ImageMagick allow remote attackers to cause a denial of service (memory consumption) via unspecified vectors.",
        "git_url": "https://github.com/ImageMagick/ImageMagick/commit/aeff00de228bc5a158c2a975ab47845d8a1db456",
        "commit_title": "Fix a small memory leak",
        "commit_text": "",
        "func_before": "static Image *ReadLABELImage(const ImageInfo *image_info,\n  ExceptionInfo *exception)\n{\n  char\n    geometry[MaxTextExtent],\n    *property;\n\n  const char\n    *label;\n\n  DrawInfo\n    *draw_info;\n\n  Image\n    *image;\n\n  MagickBooleanType\n    status;\n\n  TypeMetric\n    metrics;\n\n  size_t\n    height,\n    width;\n\n  /*\n    Initialize Image structure.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickSignature);\n  image=AcquireImage(image_info);\n  (void) ResetImagePage(image,\"0x0+0+0\");\n  property=InterpretImageProperties(image_info,image,image_info->filename);\n  (void) SetImageProperty(image,\"label\",property);\n  property=DestroyString(property);\n  label=GetImageProperty(image,\"label\");\n  draw_info=CloneDrawInfo(image_info,(DrawInfo *) NULL);\n  draw_info->text=ConstantString(label);\n  metrics.width=0;\n  metrics.ascent=0.0;\n  status=GetMultilineTypeMetrics(image,draw_info,&metrics);\n  if ((image->columns == 0) && (image->rows == 0))\n    {\n      image->columns=(size_t) floor(metrics.width+draw_info->stroke_width+0.5);\n      image->rows=(size_t) floor(metrics.height+draw_info->stroke_width+0.5);\n    }\n  else\n    if ((strlen(label) > 0) &&\n        (((image->columns == 0) || (image->rows == 0)) ||\n         (fabs(image_info->pointsize) < MagickEpsilon)))\n      {\n        double\n          high,\n          low;\n\n        /*\n          Auto fit text into bounding box.\n        */\n        for ( ; ; draw_info->pointsize*=2.0)\n        {\n          (void) FormatLocaleString(geometry,MaxTextExtent,\"%+g%+g\",\n            -metrics.bounds.x1,metrics.ascent);\n          if (draw_info->gravity == UndefinedGravity)\n            (void) CloneString(&draw_info->geometry,geometry);\n          (void) GetMultilineTypeMetrics(image,draw_info,&metrics);\n          width=(size_t) floor(metrics.width+draw_info->stroke_width+0.5);\n          height=(size_t) floor(metrics.height+draw_info->stroke_width+0.5);\n          if ((image->columns != 0) && (image->rows != 0))\n            {\n              if ((width >= image->columns) && (height >= image->rows))\n                break;\n            }\n          else\n            if (((image->columns != 0) && (width >= image->columns)) ||\n                ((image->rows != 0) && (height >= image->rows)))\n              break;\n        }\n        high=draw_info->pointsize;\n        for (low=1.0; (high-low) > 0.5; )\n        {\n          draw_info->pointsize=(low+high)/2.0;\n          (void) FormatLocaleString(geometry,MaxTextExtent,\"%+g%+g\",\n            -metrics.bounds.x1,metrics.ascent);\n          if (draw_info->gravity == UndefinedGravity)\n            (void) CloneString(&draw_info->geometry,geometry);\n          (void) GetMultilineTypeMetrics(image,draw_info,&metrics);\n          width=(size_t) floor(metrics.width+draw_info->stroke_width+0.5);\n          height=(size_t) floor(metrics.height+draw_info->stroke_width+0.5);\n          if ((image->columns != 0) && (image->rows != 0))\n            {\n              if ((width < image->columns) && (height < image->rows))\n                low=draw_info->pointsize+0.5;\n              else\n                high=draw_info->pointsize-0.5;\n            }\n          else\n            if (((image->columns != 0) && (width < image->columns)) ||\n                ((image->rows != 0) && (height < image->rows)))\n              low=draw_info->pointsize+0.5;\n            else\n              high=draw_info->pointsize-0.5;\n        }\n        draw_info->pointsize=(low+high)/2.0-0.5;\n      }\n  status=GetMultilineTypeMetrics(image,draw_info,&metrics);\n  if (status == MagickFalse)\n    {\n      draw_info=DestroyDrawInfo(draw_info);\n      InheritException(exception,&image->exception);\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  if (image->columns == 0)\n    image->columns=(size_t) floor(metrics.width+draw_info->stroke_width+0.5);\n  if (image->columns == 0)\n    image->columns=(size_t) floor(draw_info->pointsize+draw_info->stroke_width+\n      0.5);\n  if (image->rows == 0)\n    image->rows=(size_t) floor(metrics.ascent-metrics.descent+\n      draw_info->stroke_width+0.5);\n  if (image->rows == 0)\n    image->rows=(size_t) floor(draw_info->pointsize+draw_info->stroke_width+\n      0.5);\n  status=SetImageExtent(image,image->columns,image->rows);\n  if (status == MagickFalse)\n    {\n      draw_info=DestroyDrawInfo(draw_info);\n      InheritException(exception,&image->exception);\n      return(DestroyImageList(image));\n    }\n  if (SetImageBackgroundColor(image) == MagickFalse)\n    {\n      draw_info=DestroyDrawInfo(draw_info);\n      InheritException(exception,&image->exception);\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n    Draw label.\n  */\n  (void) FormatLocaleString(geometry,MaxTextExtent,\"%+g%+g\",\n    draw_info->direction == RightToLeftDirection ? image->columns-\n    metrics.bounds.x2 : 0.0,draw_info->gravity == UndefinedGravity ?\n    metrics.ascent : 0.0);\n  draw_info->geometry=AcquireString(geometry);\n  status=AnnotateImage(image,draw_info);\n  if (image_info->pointsize == 0.0)\n    {\n      char\n        pointsize[MaxTextExtent];\n\n      (void) FormatLocaleString(pointsize,MaxTextExtent,\"%.20g\",\n        draw_info->pointsize);\n      (void) SetImageProperty(image,\"label:pointsize\",pointsize);\n    }\n  draw_info=DestroyDrawInfo(draw_info);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  return(GetFirstImageInList(image));\n}",
        "func": "static Image *ReadLABELImage(const ImageInfo *image_info,\n  ExceptionInfo *exception)\n{\n  char\n    geometry[MaxTextExtent],\n    *property;\n\n  const char\n    *label;\n\n  DrawInfo\n    *draw_info;\n\n  Image\n    *image;\n\n  MagickBooleanType\n    status;\n\n  TypeMetric\n    metrics;\n\n  size_t\n    height,\n    width;\n\n  /*\n    Initialize Image structure.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickSignature);\n  image=AcquireImage(image_info);\n  (void) ResetImagePage(image,\"0x0+0+0\");\n  property=InterpretImageProperties(image_info,image,image_info->filename);\n  (void) SetImageProperty(image,\"label\",property);\n  property=DestroyString(property);\n  label=GetImageProperty(image,\"label\");\n  draw_info=CloneDrawInfo(image_info,(DrawInfo *) NULL);\n  draw_info->text=ConstantString(label);\n  metrics.width=0;\n  metrics.ascent=0.0;\n  status=GetMultilineTypeMetrics(image,draw_info,&metrics);\n  if ((image->columns == 0) && (image->rows == 0))\n    {\n      image->columns=(size_t) floor(metrics.width+draw_info->stroke_width+0.5);\n      image->rows=(size_t) floor(metrics.height+draw_info->stroke_width+0.5);\n    }\n  else\n    if ((strlen(label) > 0) &&\n        (((image->columns == 0) || (image->rows == 0)) ||\n         (fabs(image_info->pointsize) < MagickEpsilon)))\n      {\n        double\n          high,\n          low;\n\n        /*\n          Auto fit text into bounding box.\n        */\n        for ( ; ; draw_info->pointsize*=2.0)\n        {\n          (void) FormatLocaleString(geometry,MaxTextExtent,\"%+g%+g\",\n            -metrics.bounds.x1,metrics.ascent);\n          if (draw_info->gravity == UndefinedGravity)\n            (void) CloneString(&draw_info->geometry,geometry);\n          (void) GetMultilineTypeMetrics(image,draw_info,&metrics);\n          width=(size_t) floor(metrics.width+draw_info->stroke_width+0.5);\n          height=(size_t) floor(metrics.height+draw_info->stroke_width+0.5);\n          if ((image->columns != 0) && (image->rows != 0))\n            {\n              if ((width >= image->columns) && (height >= image->rows))\n                break;\n            }\n          else\n            if (((image->columns != 0) && (width >= image->columns)) ||\n                ((image->rows != 0) && (height >= image->rows)))\n              break;\n        }\n        high=draw_info->pointsize;\n        for (low=1.0; (high-low) > 0.5; )\n        {\n          draw_info->pointsize=(low+high)/2.0;\n          (void) FormatLocaleString(geometry,MaxTextExtent,\"%+g%+g\",\n            -metrics.bounds.x1,metrics.ascent);\n          if (draw_info->gravity == UndefinedGravity)\n            (void) CloneString(&draw_info->geometry,geometry);\n          (void) GetMultilineTypeMetrics(image,draw_info,&metrics);\n          width=(size_t) floor(metrics.width+draw_info->stroke_width+0.5);\n          height=(size_t) floor(metrics.height+draw_info->stroke_width+0.5);\n          if ((image->columns != 0) && (image->rows != 0))\n            {\n              if ((width < image->columns) && (height < image->rows))\n                low=draw_info->pointsize+0.5;\n              else\n                high=draw_info->pointsize-0.5;\n            }\n          else\n            if (((image->columns != 0) && (width < image->columns)) ||\n                ((image->rows != 0) && (height < image->rows)))\n              low=draw_info->pointsize+0.5;\n            else\n              high=draw_info->pointsize-0.5;\n        }\n        draw_info->pointsize=(low+high)/2.0-0.5;\n      }\n  status=GetMultilineTypeMetrics(image,draw_info,&metrics);\n  if (status == MagickFalse)\n    {\n      draw_info=DestroyDrawInfo(draw_info);\n      InheritException(exception,&image->exception);\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  if (image->columns == 0)\n    image->columns=(size_t) floor(metrics.width+draw_info->stroke_width+0.5);\n  if (image->columns == 0)\n    image->columns=(size_t) floor(draw_info->pointsize+draw_info->stroke_width+\n      0.5);\n  if (image->rows == 0)\n    image->rows=(size_t) floor(metrics.ascent-metrics.descent+\n      draw_info->stroke_width+0.5);\n  if (image->rows == 0)\n    image->rows=(size_t) floor(draw_info->pointsize+draw_info->stroke_width+\n      0.5);\n  status=SetImageExtent(image,image->columns,image->rows);\n  if (status == MagickFalse)\n    {\n      draw_info=DestroyDrawInfo(draw_info);\n      InheritException(exception,&image->exception);\n      return(DestroyImageList(image));\n    }\n  if (SetImageBackgroundColor(image) == MagickFalse)\n    {\n      draw_info=DestroyDrawInfo(draw_info);\n      InheritException(exception,&image->exception);\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n    Draw label.\n  */\n  (void) FormatLocaleString(geometry,MaxTextExtent,\"%+g%+g\",\n    draw_info->direction == RightToLeftDirection ? image->columns-\n    metrics.bounds.x2 : 0.0,draw_info->gravity == UndefinedGravity ?\n    metrics.ascent : 0.0);\n  (void) CloneString(&draw_info->geometry,geometry);\n  status=AnnotateImage(image,draw_info);\n  if (image_info->pointsize == 0.0)\n    {\n      char\n        pointsize[MaxTextExtent];\n\n      (void) FormatLocaleString(pointsize,MaxTextExtent,\"%.20g\",\n        draw_info->pointsize);\n      (void) SetImageProperty(image,\"label:pointsize\",pointsize);\n    }\n  draw_info=DestroyDrawInfo(draw_info);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  return(GetFirstImageInList(image));\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -148,7 +148,7 @@\n     draw_info->direction == RightToLeftDirection ? image->columns-\n     metrics.bounds.x2 : 0.0,draw_info->gravity == UndefinedGravity ?\n     metrics.ascent : 0.0);\n-  draw_info->geometry=AcquireString(geometry);\n+  (void) CloneString(&draw_info->geometry,geometry);\n   status=AnnotateImage(image,draw_info);\n   if (image_info->pointsize == 0.0)\n     {",
        "diff_line_info": {
            "deleted_lines": [
                "  draw_info->geometry=AcquireString(geometry);"
            ],
            "added_lines": [
                "  (void) CloneString(&draw_info->geometry,geometry);"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-6697",
        "func_name": "inspircd/DNSRequest::ResultIsReady",
        "description": "InspIRCd before 2.0.7 allows remote attackers to cause a denial of service (infinite loop).",
        "git_url": "https://github.com/inspircd/inspircd/commit/58c893e834ff20495d007709220881a3ff13f423",
        "commit_title": "Fixed infinite loop cauesd by invalid dns packets",
        "commit_text": "",
        "func_before": "DNSInfo DNSRequest::ResultIsReady(DNSHeader &header, unsigned length)\n{\n\tunsigned i = 0, o;\n\tint q = 0;\n\tint curanswer;\n\tResourceRecord rr;\n \tunsigned short ptr;\n\n\t/* This is just to keep _FORTIFY_SOURCE happy */\n\trr.type = DNS_QUERY_NONE;\n\trr.rdlength = 0;\n\trr.ttl = 1;\t/* GCC is a whiney bastard -- see the XXX below. */\n\trr.rr_class = 0; /* Same for VC++ */\n\n\tif (!(header.flags1 & FLAGS_MASK_QR))\n\t\treturn std::make_pair((unsigned char*)NULL,\"Not a query result\");\n\n\tif (header.flags1 & FLAGS_MASK_OPCODE)\n\t\treturn std::make_pair((unsigned char*)NULL,\"Unexpected value in DNS reply packet\");\n\n\tif (header.flags2 & FLAGS_MASK_RCODE)\n\t\treturn std::make_pair((unsigned char*)NULL,\"Domain name not found\");\n\n\tif (header.ancount < 1)\n\t\treturn std::make_pair((unsigned char*)NULL,\"No resource records returned\");\n\n\t/* Subtract the length of the header from the length of the packet */\n\tlength -= 12;\n\n\twhile ((unsigned int)q < header.qdcount && i < length)\n\t{\n\t\tif (header.payload[i] > 63)\n\t\t{\n\t\t\ti += 6;\n\t\t\tq++;\n\t\t}\n\t\telse\n\t\t{\n\t\t\tif (header.payload[i] == 0)\n\t\t\t{\n\t\t\t\tq++;\n\t\t\t\ti += 5;\n\t\t\t}\n\t\t\telse i += header.payload[i] + 1;\n\t\t}\n\t}\n\tcuranswer = 0;\n\twhile ((unsigned)curanswer < header.ancount)\n\t{\n\t\tq = 0;\n\t\twhile (q == 0 && i < length)\n\t\t{\n\t\t\tif (header.payload[i] > 63)\n\t\t\t{\n\t\t\t\ti += 2;\n\t\t\t\tq = 1;\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tif (header.payload[i] == 0)\n\t\t\t\t{\n\t\t\t\t\ti++;\n\t\t\t\t\tq = 1;\n\t\t\t\t}\n\t\t\t\telse i += header.payload[i] + 1; /* skip length and label */\n\t\t\t}\n\t\t}\n\t\tif (static_cast<int>(length - i) < 10)\n\t\t\treturn std::make_pair((unsigned char*)NULL,\"Incorrectly sized DNS reply\");\n\n\t\t/* XXX: We actually initialise 'rr' here including its ttl field */\n\t\tDNS::FillResourceRecord(&rr,&header.payload[i]);\n\n\t\ti += 10;\n\t\tServerInstance->Logs->Log(\"RESOLVER\",DEBUG,\"Resolver: rr.type is %d and this.type is %d rr.class %d this.class %d\", rr.type, this->type, rr.rr_class, this->rr_class);\n\t\tif (rr.type != this->type)\n\t\t{\n\t\t\tcuranswer++;\n\t\t\ti += rr.rdlength;\n\t\t\tcontinue;\n\t\t}\n\t\tif (rr.rr_class != this->rr_class)\n\t\t{\n\t\t\tcuranswer++;\n\t\t\ti += rr.rdlength;\n\t\t\tcontinue;\n\t\t}\n\t\tbreak;\n\t}\n\tif ((unsigned int)curanswer == header.ancount)\n\t\treturn std::make_pair((unsigned char*)NULL,\"No A, AAAA or PTR type answers (\" + ConvToStr(header.ancount) + \" answers)\");\n\n\tif (i + rr.rdlength > (unsigned int)length)\n\t\treturn std::make_pair((unsigned char*)NULL,\"Resource record larger than stated\");\n\n\tif (rr.rdlength > 1023)\n\t\treturn std::make_pair((unsigned char*)NULL,\"Resource record too large\");\n\n\tthis->ttl = rr.ttl;\n\n\tswitch (rr.type)\n\t{\n\t\t/*\n\t\t * CNAME and PTR are compressed.  We need to decompress them.\n\t\t */\n\t\tcase DNS_QUERY_CNAME:\n\t\tcase DNS_QUERY_PTR:\n\t\t\to = 0;\n\t\t\tq = 0;\n\t\t\twhile (q == 0 && i < length && o + 256 < 1023)\n\t\t\t{\n\t\t\t\t/* DN label found (byte over 63) */\n\t\t\t\tif (header.payload[i] > 63)\n\t\t\t\t{\n\t\t\t\t\tmemcpy(&ptr,&header.payload[i],2);\n\n\t\t\t\t\ti = ntohs(ptr);\n\n\t\t\t\t\t/* check that highest two bits are set. if not, we've been had */\n\t\t\t\t\tif (!(i & DN_COMP_BITMASK))\n\t\t\t\t\t\treturn std::make_pair((unsigned char *) NULL, \"DN label decompression header is bogus\");\n\n\t\t\t\t\t/* mask away the two highest bits. */\n\t\t\t\t\ti &= ~DN_COMP_BITMASK;\n\n\t\t\t\t\t/* and decrease length by 12 bytes. */\n\t\t\t\t\ti =- 12;\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\tif (header.payload[i] == 0)\n\t\t\t\t\t{\n\t\t\t\t\t\tq = 1;\n\t\t\t\t\t}\n\t\t\t\t\telse\n\t\t\t\t\t{\n\t\t\t\t\t\tres[o] = 0;\n\t\t\t\t\t\tif (o != 0)\n\t\t\t\t\t\t\tres[o++] = '.';\n\n\t\t\t\t\t\tif (o + header.payload[i] > sizeof(DNSHeader))\n\t\t\t\t\t\t\treturn std::make_pair((unsigned char *) NULL, \"DN label decompression is impossible -- malformed/hostile packet?\");\n\n\t\t\t\t\t\tmemcpy(&res[o], &header.payload[i + 1], header.payload[i]);\n\t\t\t\t\t\to += header.payload[i];\n\t\t\t\t\t\ti += header.payload[i] + 1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tres[o] = 0;\n\t\tbreak;\n\t\tcase DNS_QUERY_AAAA:\n\t\t\tif (rr.rdlength != sizeof(struct in6_addr))\n\t\t\t\treturn std::make_pair((unsigned char *) NULL, \"rr.rdlength is larger than 16 bytes for an ipv6 entry -- malformed/hostile packet?\");\n\n\t\t\tmemcpy(res,&header.payload[i],rr.rdlength);\n\t\t\tres[rr.rdlength] = 0;\n\t\tbreak;\n\t\tcase DNS_QUERY_A:\n\t\t\tif (rr.rdlength != sizeof(struct in_addr))\n\t\t\t\treturn std::make_pair((unsigned char *) NULL, \"rr.rdlength is larger than 4 bytes for an ipv4 entry -- malformed/hostile packet?\");\n\n\t\t\tmemcpy(res,&header.payload[i],rr.rdlength);\n\t\t\tres[rr.rdlength] = 0;\n\t\tbreak;\n\t\tdefault:\n\t\t\treturn std::make_pair((unsigned char *) NULL, \"don't know how to handle undefined type (\" + ConvToStr(rr.type) + \") -- rejecting\");\n\t\tbreak;\n\t}\n\treturn std::make_pair(res,\"No error\");\n}",
        "func": "DNSInfo DNSRequest::ResultIsReady(DNSHeader &header, unsigned length)\n{\n\tunsigned i = 0, o;\n\tint q = 0;\n\tint curanswer;\n\tResourceRecord rr;\n \tunsigned short ptr;\n\n\t/* This is just to keep _FORTIFY_SOURCE happy */\n\trr.type = DNS_QUERY_NONE;\n\trr.rdlength = 0;\n\trr.ttl = 1;\t/* GCC is a whiney bastard -- see the XXX below. */\n\trr.rr_class = 0; /* Same for VC++ */\n\n\tif (!(header.flags1 & FLAGS_MASK_QR))\n\t\treturn std::make_pair((unsigned char*)NULL,\"Not a query result\");\n\n\tif (header.flags1 & FLAGS_MASK_OPCODE)\n\t\treturn std::make_pair((unsigned char*)NULL,\"Unexpected value in DNS reply packet\");\n\n\tif (header.flags2 & FLAGS_MASK_RCODE)\n\t\treturn std::make_pair((unsigned char*)NULL,\"Domain name not found\");\n\n\tif (header.ancount < 1)\n\t\treturn std::make_pair((unsigned char*)NULL,\"No resource records returned\");\n\n\t/* Subtract the length of the header from the length of the packet */\n\tlength -= 12;\n\n\twhile ((unsigned int)q < header.qdcount && i < length)\n\t{\n\t\tif (header.payload[i] > 63)\n\t\t{\n\t\t\ti += 6;\n\t\t\tq++;\n\t\t}\n\t\telse\n\t\t{\n\t\t\tif (header.payload[i] == 0)\n\t\t\t{\n\t\t\t\tq++;\n\t\t\t\ti += 5;\n\t\t\t}\n\t\t\telse i += header.payload[i] + 1;\n\t\t}\n\t}\n\tcuranswer = 0;\n\twhile ((unsigned)curanswer < header.ancount)\n\t{\n\t\tq = 0;\n\t\twhile (q == 0 && i < length)\n\t\t{\n\t\t\tif (header.payload[i] > 63)\n\t\t\t{\n\t\t\t\ti += 2;\n\t\t\t\tq = 1;\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tif (header.payload[i] == 0)\n\t\t\t\t{\n\t\t\t\t\ti++;\n\t\t\t\t\tq = 1;\n\t\t\t\t}\n\t\t\t\telse i += header.payload[i] + 1; /* skip length and label */\n\t\t\t}\n\t\t}\n\t\tif (static_cast<int>(length - i) < 10)\n\t\t\treturn std::make_pair((unsigned char*)NULL,\"Incorrectly sized DNS reply\");\n\n\t\t/* XXX: We actually initialise 'rr' here including its ttl field */\n\t\tDNS::FillResourceRecord(&rr,&header.payload[i]);\n\n\t\ti += 10;\n\t\tServerInstance->Logs->Log(\"RESOLVER\",DEBUG,\"Resolver: rr.type is %d and this.type is %d rr.class %d this.class %d\", rr.type, this->type, rr.rr_class, this->rr_class);\n\t\tif (rr.type != this->type)\n\t\t{\n\t\t\tcuranswer++;\n\t\t\ti += rr.rdlength;\n\t\t\tcontinue;\n\t\t}\n\t\tif (rr.rr_class != this->rr_class)\n\t\t{\n\t\t\tcuranswer++;\n\t\t\ti += rr.rdlength;\n\t\t\tcontinue;\n\t\t}\n\t\tbreak;\n\t}\n\tif ((unsigned int)curanswer == header.ancount)\n\t\treturn std::make_pair((unsigned char*)NULL,\"No A, AAAA or PTR type answers (\" + ConvToStr(header.ancount) + \" answers)\");\n\n\tif (i + rr.rdlength > (unsigned int)length)\n\t\treturn std::make_pair((unsigned char*)NULL,\"Resource record larger than stated\");\n\n\tif (rr.rdlength > 1023)\n\t\treturn std::make_pair((unsigned char*)NULL,\"Resource record too large\");\n\n\tthis->ttl = rr.ttl;\n\n\tswitch (rr.type)\n\t{\n\t\t/*\n\t\t * CNAME and PTR are compressed.  We need to decompress them.\n\t\t */\n\t\tcase DNS_QUERY_CNAME:\n\t\tcase DNS_QUERY_PTR:\n\t\t{\n\t\t\tunsigned short lowest_pos = length;\n\t\t\to = 0;\n\t\t\tq = 0;\n\t\t\twhile (q == 0 && i < length && o + 256 < 1023)\n\t\t\t{\n\t\t\t\t/* DN label found (byte over 63) */\n\t\t\t\tif (header.payload[i] > 63)\n\t\t\t\t{\n\t\t\t\t\tmemcpy(&ptr,&header.payload[i],2);\n\n\t\t\t\t\ti = ntohs(ptr);\n\n\t\t\t\t\t/* check that highest two bits are set. if not, we've been had */\n\t\t\t\t\tif ((i & DN_COMP_BITMASK) != DN_COMP_BITMASK)\n\t\t\t\t\t\treturn std::make_pair((unsigned char *) NULL, \"DN label decompression header is bogus\");\n\n\t\t\t\t\t/* mask away the two highest bits. */\n\t\t\t\t\ti &= ~DN_COMP_BITMASK;\n\n\t\t\t\t\t/* and decrease length by 12 bytes. */\n\t\t\t\t\ti -= 12;\n\n\t\t\t\t\tif (i >= lowest_pos)\n\t\t\t\t\t\treturn std::make_pair((unsigned char *) NULL, \"Invalid decompression pointer\");\n\t\t\t\t\tlowest_pos = i;\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\tif (header.payload[i] == 0)\n\t\t\t\t\t{\n\t\t\t\t\t\tq = 1;\n\t\t\t\t\t}\n\t\t\t\t\telse\n\t\t\t\t\t{\n\t\t\t\t\t\tres[o] = 0;\n\t\t\t\t\t\tif (o != 0)\n\t\t\t\t\t\t\tres[o++] = '.';\n\n\t\t\t\t\t\tif (o + header.payload[i] > sizeof(DNSHeader))\n\t\t\t\t\t\t\treturn std::make_pair((unsigned char *) NULL, \"DN label decompression is impossible -- malformed/hostile packet?\");\n\n\t\t\t\t\t\tmemcpy(&res[o], &header.payload[i + 1], header.payload[i]);\n\t\t\t\t\t\to += header.payload[i];\n\t\t\t\t\t\ti += header.payload[i] + 1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tres[o] = 0;\n\t\t}\n\t\tbreak;\n\t\tcase DNS_QUERY_AAAA:\n\t\t\tif (rr.rdlength != sizeof(struct in6_addr))\n\t\t\t\treturn std::make_pair((unsigned char *) NULL, \"rr.rdlength is larger than 16 bytes for an ipv6 entry -- malformed/hostile packet?\");\n\n\t\t\tmemcpy(res,&header.payload[i],rr.rdlength);\n\t\t\tres[rr.rdlength] = 0;\n\t\tbreak;\n\t\tcase DNS_QUERY_A:\n\t\t\tif (rr.rdlength != sizeof(struct in_addr))\n\t\t\t\treturn std::make_pair((unsigned char *) NULL, \"rr.rdlength is larger than 4 bytes for an ipv4 entry -- malformed/hostile packet?\");\n\n\t\t\tmemcpy(res,&header.payload[i],rr.rdlength);\n\t\t\tres[rr.rdlength] = 0;\n\t\tbreak;\n\t\tdefault:\n\t\t\treturn std::make_pair((unsigned char *) NULL, \"don't know how to handle undefined type (\" + ConvToStr(rr.type) + \") -- rejecting\");\n\t\tbreak;\n\t}\n\treturn std::make_pair(res,\"No error\");\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -105,6 +105,8 @@\n \t\t */\n \t\tcase DNS_QUERY_CNAME:\n \t\tcase DNS_QUERY_PTR:\n+\t\t{\n+\t\t\tunsigned short lowest_pos = length;\n \t\t\to = 0;\n \t\t\tq = 0;\n \t\t\twhile (q == 0 && i < length && o + 256 < 1023)\n@@ -117,14 +119,18 @@\n \t\t\t\t\ti = ntohs(ptr);\n \n \t\t\t\t\t/* check that highest two bits are set. if not, we've been had */\n-\t\t\t\t\tif (!(i & DN_COMP_BITMASK))\n+\t\t\t\t\tif ((i & DN_COMP_BITMASK) != DN_COMP_BITMASK)\n \t\t\t\t\t\treturn std::make_pair((unsigned char *) NULL, \"DN label decompression header is bogus\");\n \n \t\t\t\t\t/* mask away the two highest bits. */\n \t\t\t\t\ti &= ~DN_COMP_BITMASK;\n \n \t\t\t\t\t/* and decrease length by 12 bytes. */\n-\t\t\t\t\ti =- 12;\n+\t\t\t\t\ti -= 12;\n+\n+\t\t\t\t\tif (i >= lowest_pos)\n+\t\t\t\t\t\treturn std::make_pair((unsigned char *) NULL, \"Invalid decompression pointer\");\n+\t\t\t\t\tlowest_pos = i;\n \t\t\t\t}\n \t\t\t\telse\n \t\t\t\t{\n@@ -148,6 +154,7 @@\n \t\t\t\t}\n \t\t\t}\n \t\t\tres[o] = 0;\n+\t\t}\n \t\tbreak;\n \t\tcase DNS_QUERY_AAAA:\n \t\t\tif (rr.rdlength != sizeof(struct in6_addr))",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\t\t\tif (!(i & DN_COMP_BITMASK))",
                "\t\t\t\t\ti =- 12;"
            ],
            "added_lines": [
                "\t\t{",
                "\t\t\tunsigned short lowest_pos = length;",
                "\t\t\t\t\tif ((i & DN_COMP_BITMASK) != DN_COMP_BITMASK)",
                "\t\t\t\t\ti -= 12;",
                "",
                "\t\t\t\t\tif (i >= lowest_pos)",
                "\t\t\t\t\t\treturn std::make_pair((unsigned char *) NULL, \"Invalid decompression pointer\");",
                "\t\t\t\t\tlowest_pos = i;",
                "\t\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-8959",
        "func_name": "ImageMagick/SkipDXTMipmaps",
        "description": "coders/dds.c in ImageMagick before 6.9.0-4 Beta allows remote attackers to cause a denial of service (CPU consumption) via a crafted DDS file.",
        "git_url": "https://github.com/ImageMagick/ImageMagick/commit/cc2a4d2ba5371d25c58763e4db2dbc1f4691c0f7",
        "commit_title": "http://www.imagemagick.org/discourse-server/viewtopic.php?f=3&t=26861",
        "commit_text": "",
        "func_before": "static MagickBooleanType SkipDXTMipmaps(Image *image,DDSInfo *dds_info,\n  int texel_size,ExceptionInfo *exception)\n{\n  MagickOffsetType\n    offset;\n\n  register ssize_t\n    i;\n\n  size_t\n    h,\n    w;\n  \n  /*\n    Only skip mipmaps for textures and cube maps\n  */\n  if (EOFBlob(image) != MagickFalse)\n    {\n      ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n        image->filename);\n      return(MagickFalse);\n    }\n  if (dds_info->ddscaps1 & DDSCAPS_MIPMAP\n      && (dds_info->ddscaps1 & DDSCAPS_TEXTURE\n          || dds_info->ddscaps2 & DDSCAPS2_CUBEMAP))\n    {\n      w = DIV2(dds_info->width);\n      h = DIV2(dds_info->height);\n      \n      /*\n        Mipmapcount includes the main image, so start from one\n      */\n      for (i = 1; (i < (ssize_t) dds_info->mipmapcount) && w && h; i++)\n      {\n        offset = (MagickOffsetType) ((w + 3) / 4) * ((h + 3) / 4) * texel_size;\n        (void) SeekBlob(image, offset, SEEK_CUR);\n        \n        w = DIV2(w);\n        h = DIV2(h);\n      }\n    }\n  return(MagickTrue);\n}",
        "func": "static MagickBooleanType SkipDXTMipmaps(Image *image,DDSInfo *dds_info,\n  int texel_size,ExceptionInfo *exception)\n{\n  MagickOffsetType\n    offset;\n\n  register ssize_t\n    i;\n\n  size_t\n    h,\n    w;\n  \n  /*\n    Only skip mipmaps for textures and cube maps\n  */\n  if (EOFBlob(image) != MagickFalse)\n    {\n      ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n        image->filename);\n      return(MagickFalse);\n    }\n  if (dds_info->ddscaps1 & DDSCAPS_MIPMAP\n      && (dds_info->ddscaps1 & DDSCAPS_TEXTURE\n          || dds_info->ddscaps2 & DDSCAPS2_CUBEMAP))\n    {\n      w = DIV2(dds_info->width);\n      h = DIV2(dds_info->height);\n      \n      /*\n        Mipmapcount includes the main image, so start from one\n      */\n      for (i = 1; (i < (ssize_t) dds_info->mipmapcount) && w && h; i++)\n      {\n        offset = (MagickOffsetType) ((w + 3) / 4) * ((h + 3) / 4) * texel_size;\n        if (SeekBlob(image, offset, SEEK_CUR) < 0)\n          break;\n        w = DIV2(w);\n        h = DIV2(h);\n      }\n    }\n  return(MagickTrue);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -33,8 +33,8 @@\n       for (i = 1; (i < (ssize_t) dds_info->mipmapcount) && w && h; i++)\n       {\n         offset = (MagickOffsetType) ((w + 3) / 4) * ((h + 3) / 4) * texel_size;\n-        (void) SeekBlob(image, offset, SEEK_CUR);\n-        \n+        if (SeekBlob(image, offset, SEEK_CUR) < 0)\n+          break;\n         w = DIV2(w);\n         h = DIV2(h);\n       }",
        "diff_line_info": {
            "deleted_lines": [
                "        (void) SeekBlob(image, offset, SEEK_CUR);",
                "        "
            ],
            "added_lines": [
                "        if (SeekBlob(image, offset, SEEK_CUR) < 0)",
                "          break;"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-8959",
        "func_name": "ImageMagick/SkipRGBMipmaps",
        "description": "coders/dds.c in ImageMagick before 6.9.0-4 Beta allows remote attackers to cause a denial of service (CPU consumption) via a crafted DDS file.",
        "git_url": "https://github.com/ImageMagick/ImageMagick/commit/cc2a4d2ba5371d25c58763e4db2dbc1f4691c0f7",
        "commit_title": "http://www.imagemagick.org/discourse-server/viewtopic.php?f=3&t=26861",
        "commit_text": "",
        "func_before": "static MagickBooleanType SkipRGBMipmaps(Image *image,DDSInfo *dds_info,\n  int pixel_size,ExceptionInfo *exception)\n{\n  MagickOffsetType\n    offset;\n  \n  register ssize_t\n    i;\n\n  size_t\n    h,\n    w;\n\n  /*\n    Only skip mipmaps for textures and cube maps\n  */\n  if (EOFBlob(image) != MagickFalse)\n    {\n      ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n        image->filename);\n      return(MagickFalse);\n    }\n  if (dds_info->ddscaps1 & DDSCAPS_MIPMAP\n      && (dds_info->ddscaps1 & DDSCAPS_TEXTURE\n          || dds_info->ddscaps2 & DDSCAPS2_CUBEMAP))\n    {\n      w = DIV2(dds_info->width);\n      h = DIV2(dds_info->height);\n      \n      /*\n        Mipmapcount includes the main image, so start from one\n      */\n      for (i=1; (i < (ssize_t) dds_info->mipmapcount) && w && h; i++)\n      {\n        offset = (MagickOffsetType) w * h * pixel_size;\n        (void) SeekBlob(image, offset, SEEK_CUR);\n        \n        w = DIV2(w);\n        h = DIV2(h);\n      }\n    }\n  return(MagickTrue);\n}",
        "func": "static MagickBooleanType SkipRGBMipmaps(Image *image,DDSInfo *dds_info,\n  int pixel_size,ExceptionInfo *exception)\n{\n  MagickOffsetType\n    offset;\n  \n  register ssize_t\n    i;\n\n  size_t\n    h,\n    w;\n\n  /*\n    Only skip mipmaps for textures and cube maps\n  */\n  if (EOFBlob(image) != MagickFalse)\n    {\n      ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n        image->filename);\n      return(MagickFalse);\n    }\n  if (dds_info->ddscaps1 & DDSCAPS_MIPMAP\n      && (dds_info->ddscaps1 & DDSCAPS_TEXTURE\n          || dds_info->ddscaps2 & DDSCAPS2_CUBEMAP))\n    {\n      w = DIV2(dds_info->width);\n      h = DIV2(dds_info->height);\n      \n      /*\n        Mipmapcount includes the main image, so start from one\n      */\n      for (i=1; (i < (ssize_t) dds_info->mipmapcount) && w && h; i++)\n      {\n        offset = (MagickOffsetType) w * h * pixel_size;\n        if (SeekBlob(image, offset, SEEK_CUR) < 0)\n          break;\n        w = DIV2(w);\n        h = DIV2(h);\n      }\n    }\n  return(MagickTrue);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -33,8 +33,8 @@\n       for (i=1; (i < (ssize_t) dds_info->mipmapcount) && w && h; i++)\n       {\n         offset = (MagickOffsetType) w * h * pixel_size;\n-        (void) SeekBlob(image, offset, SEEK_CUR);\n-        \n+        if (SeekBlob(image, offset, SEEK_CUR) < 0)\n+          break;\n         w = DIV2(w);\n         h = DIV2(h);\n       }",
        "diff_line_info": {
            "deleted_lines": [
                "        (void) SeekBlob(image, offset, SEEK_CUR);",
                "        "
            ],
            "added_lines": [
                "        if (SeekBlob(image, offset, SEEK_CUR) < 0)",
                "          break;"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-8959",
        "func_name": "ImageMagick/SkipDXTMipmaps",
        "description": "coders/dds.c in ImageMagick before 6.9.0-4 Beta allows remote attackers to cause a denial of service (CPU consumption) via a crafted DDS file.",
        "git_url": "https://github.com/ImageMagick/ImageMagick/commit/9b428b7af688fe319320aed15f2b94281d1e37b4",
        "commit_title": "",
        "commit_text": "",
        "func_before": "static MagickBooleanType SkipDXTMipmaps(Image *image,DDSInfo *dds_info,\n  int texel_size,ExceptionInfo *exception)\n{\n  register ssize_t\n    i;\n\n  MagickOffsetType\n    offset;\n\n  size_t\n    h,\n    w;\n\n  /*\n    Only skip mipmaps for textures and cube maps\n  */\n  if (EOFBlob(image) != MagickFalse)\n    {\n      ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n        image->filename);\n      return(MagickFalse);\n    }\n  if (dds_info->ddscaps1 & DDSCAPS_MIPMAP\n      && (dds_info->ddscaps1 & DDSCAPS_TEXTURE\n          || dds_info->ddscaps2 & DDSCAPS2_CUBEMAP))\n    {\n      w = DIV2(dds_info->width);\n      h = DIV2(dds_info->height);\n\n      /*\n        Mipmapcount includes the main image, so start from one\n      */\n      for (i = 1; (i < (ssize_t) dds_info->mipmapcount) && w && h; i++)\n      {\n        offset = (MagickOffsetType) ((w + 3) / 4) * ((h + 3) / 4) * texel_size;\n        (void) SeekBlob(image, offset, SEEK_CUR);\n\n        w = DIV2(w);\n        h = DIV2(h);\n      }\n    }\n  return(MagickTrue);\n}",
        "func": "static MagickBooleanType SkipDXTMipmaps(Image *image,DDSInfo *dds_info,\n  int texel_size,ExceptionInfo *exception)\n{\n  register ssize_t\n    i;\n\n  MagickOffsetType\n    offset;\n\n  size_t\n    h,\n    w;\n\n  /*\n    Only skip mipmaps for textures and cube maps\n  */\n  if (EOFBlob(image) != MagickFalse)\n    {\n      ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n        image->filename);\n      return(MagickFalse);\n    }\n  if (dds_info->ddscaps1 & DDSCAPS_MIPMAP\n      && (dds_info->ddscaps1 & DDSCAPS_TEXTURE\n          || dds_info->ddscaps2 & DDSCAPS2_CUBEMAP))\n    {\n      w = DIV2(dds_info->width);\n      h = DIV2(dds_info->height);\n\n      /*\n        Mipmapcount includes the main image, so start from one\n      */\n      for (i = 1; (i < (ssize_t) dds_info->mipmapcount) && w && h; i++)\n      {\n        offset = (MagickOffsetType) ((w + 3) / 4) * ((h + 3) / 4) * texel_size;\n        if (SeekBlob(image,offset,SEEK_CUR) < 0)\n          break;\n        w = DIV2(w);\n        h = DIV2(h);\n      }\n    }\n  return(MagickTrue);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -33,8 +33,8 @@\n       for (i = 1; (i < (ssize_t) dds_info->mipmapcount) && w && h; i++)\n       {\n         offset = (MagickOffsetType) ((w + 3) / 4) * ((h + 3) / 4) * texel_size;\n-        (void) SeekBlob(image, offset, SEEK_CUR);\n-\n+        if (SeekBlob(image,offset,SEEK_CUR) < 0)\n+          break;\n         w = DIV2(w);\n         h = DIV2(h);\n       }",
        "diff_line_info": {
            "deleted_lines": [
                "        (void) SeekBlob(image, offset, SEEK_CUR);",
                ""
            ],
            "added_lines": [
                "        if (SeekBlob(image,offset,SEEK_CUR) < 0)",
                "          break;"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-8959",
        "func_name": "ImageMagick/SkipRGBMipmaps",
        "description": "coders/dds.c in ImageMagick before 6.9.0-4 Beta allows remote attackers to cause a denial of service (CPU consumption) via a crafted DDS file.",
        "git_url": "https://github.com/ImageMagick/ImageMagick/commit/3ab016764c7f787829d9065440d86f5609765110",
        "commit_title": "http://www.imagemagick.org/discourse-server/viewtopic.php?f=3&t=26861",
        "commit_text": "",
        "func_before": "static MagickBooleanType SkipRGBMipmaps(Image *image,DDSInfo *dds_info,\n  int pixel_size,ExceptionInfo *exception)\n{\n  MagickOffsetType\n    offset;\n\n  register ssize_t\n    i;\n\n  size_t\n    h,\n    w;\n\n  /*\n    Only skip mipmaps for textures and cube maps\n  */\n  if (EOFBlob(image) != MagickFalse)\n    {\n      ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n        image->filename);\n      return(MagickFalse);\n    }\n  if (dds_info->ddscaps1 & DDSCAPS_MIPMAP\n      && (dds_info->ddscaps1 & DDSCAPS_TEXTURE\n          || dds_info->ddscaps2 & DDSCAPS2_CUBEMAP))\n    {\n      w = DIV2(dds_info->width);\n      h = DIV2(dds_info->height);\n\n      /*\n        Mipmapcount includes the main image, so start from one\n      */\n      for (i=1; (i < (ssize_t) dds_info->mipmapcount) && w && h; i++)\n      {\n        offset = (MagickOffsetType) w * h * pixel_size;\n        (void) SeekBlob(image, offset, SEEK_CUR);\n\n        w = DIV2(w);\n        h = DIV2(h);\n      }\n    }\n  return(MagickTrue);\n}",
        "func": "static MagickBooleanType SkipRGBMipmaps(Image *image,DDSInfo *dds_info,\n  int pixel_size,ExceptionInfo *exception)\n{\n  MagickOffsetType\n    offset;\n\n  register ssize_t\n    i;\n\n  size_t\n    h,\n    w;\n\n  /*\n    Only skip mipmaps for textures and cube maps\n  */\n  if (EOFBlob(image) != MagickFalse)\n    {\n      ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n        image->filename);\n      return(MagickFalse);\n    }\n  if (dds_info->ddscaps1 & DDSCAPS_MIPMAP\n      && (dds_info->ddscaps1 & DDSCAPS_TEXTURE\n          || dds_info->ddscaps2 & DDSCAPS2_CUBEMAP))\n    {\n      w = DIV2(dds_info->width);\n      h = DIV2(dds_info->height);\n\n      /*\n        Mipmapcount includes the main image, so start from one\n      */\n      for (i=1; (i < (ssize_t) dds_info->mipmapcount) && w && h; i++)\n      {\n        offset = (MagickOffsetType) w * h * pixel_size;\n        if (SeekBlob(image,offset,SEEK_CUR) < 0)\n          break;\n        w = DIV2(w);\n        h = DIV2(h);\n      }\n    }\n  return(MagickTrue);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -33,8 +33,8 @@\n       for (i=1; (i < (ssize_t) dds_info->mipmapcount) && w && h; i++)\n       {\n         offset = (MagickOffsetType) w * h * pixel_size;\n-        (void) SeekBlob(image, offset, SEEK_CUR);\n-\n+        if (SeekBlob(image,offset,SEEK_CUR) < 0)\n+          break;\n         w = DIV2(w);\n         h = DIV2(h);\n       }",
        "diff_line_info": {
            "deleted_lines": [
                "        (void) SeekBlob(image, offset, SEEK_CUR);",
                ""
            ],
            "added_lines": [
                "        if (SeekBlob(image,offset,SEEK_CUR) < 0)",
                "          break;"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-7539",
        "func_name": "ImageMagick/OpenPixelCache",
        "description": "Memory leak in AcquireVirtualMemory in ImageMagick before 7 allows remote attackers to cause a denial of service (memory consumption) via unspecified vectors.",
        "git_url": "https://github.com/ImageMagick/ImageMagick/commit/4e81ce8b07219c69a9aeccb0f7f7b927ca6db74c",
        "commit_title": "http://www.imagemagick.org/discourse-server/viewtopic.php?f=2&t=28946",
        "commit_text": "",
        "func_before": "static MagickBooleanType OpenPixelCache(Image *image,const MapMode mode,\n  ExceptionInfo *exception)\n{\n  CacheInfo\n    *magick_restrict cache_info,\n    source_info;\n\n  char\n    format[MaxTextExtent],\n    message[MaxTextExtent];\n\n  const char\n    *type;\n\n  MagickSizeType\n    length,\n    number_pixels;\n\n  MagickStatusType\n    status;\n\n  size_t\n    columns,\n    packet_size;\n\n  assert(image != (const Image *) NULL);\n  assert(image->signature == MagickSignature);\n  assert(image->cache != (Cache) NULL);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",image->filename);\n  if ((image->columns == 0) || (image->rows == 0))\n    ThrowBinaryException(CacheError,\"NoPixelsDefinedInCache\",image->filename);\n  cache_info=(CacheInfo *) image->cache;\n  assert(cache_info->signature == MagickSignature);\n  if ((AcquireMagickResource(WidthResource,image->columns) == MagickFalse) ||\n      (AcquireMagickResource(HeightResource,image->rows) == MagickFalse))\n    ThrowBinaryException(ResourceLimitError,\"PixelCacheAllocationFailed\",\n      image->filename);\n  source_info=(*cache_info);\n  source_info.file=(-1);\n  (void) FormatLocaleString(cache_info->filename,MaxTextExtent,\"%s[%.20g]\",\n    image->filename,(double) GetImageIndexInList(image));\n  cache_info->mode=mode;\n  cache_info->rows=image->rows;\n  cache_info->columns=image->columns;\n  cache_info->channels=image->channels;\n  cache_info->active_index_channel=((image->storage_class == PseudoClass) ||\n    (image->colorspace == CMYKColorspace)) ? MagickTrue : MagickFalse;\n  number_pixels=(MagickSizeType) cache_info->columns*cache_info->rows;\n  packet_size=sizeof(PixelPacket);\n  if (cache_info->active_index_channel != MagickFalse)\n    packet_size+=sizeof(IndexPacket);\n  length=number_pixels*packet_size;\n  columns=(size_t) (length/cache_info->rows/packet_size);\n  if ((cache_info->columns != columns) || ((ssize_t) cache_info->columns < 0) ||\n      ((ssize_t) cache_info->rows < 0))\n    ThrowBinaryException(ResourceLimitError,\"PixelCacheAllocationFailed\",\n      image->filename);\n  cache_info->length=length;\n  if (image->ping != MagickFalse)\n    {\n      cache_info->storage_class=image->storage_class;\n      cache_info->colorspace=image->colorspace;\n      cache_info->type=PingCache;\n      return(MagickTrue);\n    }\n  status=AcquireMagickResource(AreaResource,cache_info->length);\n  length=number_pixels*(sizeof(PixelPacket)+sizeof(IndexPacket));\n  if ((status != MagickFalse) && (length == (MagickSizeType) ((size_t) length)))\n    {\n      status=AcquireMagickResource(MemoryResource,cache_info->length);\n      if (((cache_info->type == UndefinedCache) && (status != MagickFalse)) ||\n          (cache_info->type == MemoryCache))\n        {\n          AllocatePixelCachePixels(cache_info);\n          if (cache_info->pixels == (PixelPacket *) NULL)\n            cache_info->pixels=source_info.pixels;\n          else\n            {\n              /*\n                Create memory pixel cache.\n              */\n              cache_info->colorspace=image->colorspace;\n              cache_info->type=MemoryCache;\n              cache_info->indexes=(IndexPacket *) NULL;\n              if (cache_info->active_index_channel != MagickFalse)\n                cache_info->indexes=(IndexPacket *) (cache_info->pixels+\n                  number_pixels);\n              if ((source_info.storage_class != UndefinedClass) &&\n                  (mode != ReadMode))\n                {\n                  status&=ClonePixelCacheRepository(cache_info,&source_info,\n                    exception);\n                  RelinquishPixelCachePixels(&source_info);\n                }\n              if (image->debug != MagickFalse)\n                {\n                  (void) FormatMagickSize(cache_info->length,MagickTrue,format);\n                  type=CommandOptionToMnemonic(MagickCacheOptions,(ssize_t)\n                    cache_info->type);\n                  (void) FormatLocaleString(message,MaxTextExtent,\n                    \"open %s (%s %s, %.20gx%.20g %s)\",cache_info->filename,\n                    cache_info->mapped != MagickFalse ? \"Anonymous\" : \"Heap\",\n                    type,(double) cache_info->columns,(double) cache_info->rows,\n                    format);\n                  (void) LogMagickEvent(CacheEvent,GetMagickModule(),\"%s\",\n                    message);\n                }\n              cache_info->storage_class=image->storage_class;\n              return(MagickTrue);\n            }\n        }\n      RelinquishMagickResource(MemoryResource,cache_info->length);\n    }\n  /*\n    Create pixel cache on disk.\n  */\n  status=AcquireMagickResource(DiskResource,cache_info->length);\n  if ((status == MagickFalse) || (cache_info->type == DistributedCache))\n    {\n      DistributeCacheInfo\n        *server_info;\n\n      if (cache_info->type == DistributedCache)\n        RelinquishMagickResource(DiskResource,cache_info->length);\n      server_info=AcquireDistributeCacheInfo(exception);\n      if (server_info != (DistributeCacheInfo *) NULL)\n        {\n          status=OpenDistributePixelCache(server_info,image);\n          if (status == MagickFalse)\n            {\n              ThrowFileException(exception,CacheError,\"UnableToOpenPixelCache\",\n                GetDistributeCacheHostname(server_info));\n              server_info=DestroyDistributeCacheInfo(server_info);\n            }\n          else\n            {\n              /*\n                Create a distributed pixel cache.\n              */\n              cache_info->type=DistributedCache;\n              cache_info->storage_class=image->storage_class;\n              cache_info->colorspace=image->colorspace;\n              cache_info->server_info=server_info;\n              (void) FormatLocaleString(cache_info->cache_filename,\n                MaxTextExtent,\"%s:%d\",GetDistributeCacheHostname(\n                (DistributeCacheInfo *) cache_info->server_info),\n                GetDistributeCachePort((DistributeCacheInfo *)\n                cache_info->server_info));\n              if ((source_info.storage_class != UndefinedClass) &&\n                  (mode != ReadMode))\n                {\n                  status=ClonePixelCacheRepository(cache_info,&source_info,\n                    exception);\n                  RelinquishPixelCachePixels(&source_info);\n                }\n              if (image->debug != MagickFalse)\n                {\n                  (void) FormatMagickSize(cache_info->length,MagickFalse,\n                    format);\n                  type=CommandOptionToMnemonic(MagickCacheOptions,(ssize_t)\n                    cache_info->type);\n                  (void) FormatLocaleString(message,MaxTextExtent,\n                    \"open %s (%s[%d], %s, %.20gx%.20g %s)\",cache_info->filename,\n                    cache_info->cache_filename,GetDistributeCacheFile(\n                    (DistributeCacheInfo *) cache_info->server_info),type,\n                    (double) cache_info->columns,(double) cache_info->rows,\n                    format);\n                  (void) LogMagickEvent(CacheEvent,GetMagickModule(),\"%s\",\n                    message);\n                }\n              return(MagickTrue);\n            }\n        }\n      RelinquishMagickResource(DiskResource,cache_info->length);\n      (void) ThrowMagickException(exception,GetMagickModule(),CacheError,\n        \"CacheResourcesExhausted\",\"`%s'\",image->filename);\n      return(MagickFalse);\n    }\n  if ((source_info.storage_class != UndefinedClass) && (mode != ReadMode))\n    {\n      (void) ClosePixelCacheOnDisk(cache_info);\n      *cache_info->cache_filename='\\0';\n    }\n  if (OpenPixelCacheOnDisk(cache_info,mode) == MagickFalse)\n    {\n      RelinquishMagickResource(DiskResource,cache_info->length);\n      ThrowFileException(exception,CacheError,\"UnableToOpenPixelCache\",\n        image->filename);\n      return(MagickFalse);\n    }\n  status=SetPixelCacheExtent(image,(MagickSizeType) cache_info->offset+\n    cache_info->length);\n  if (status == MagickFalse)\n    {\n      ThrowFileException(exception,CacheError,\"UnableToExtendCache\",\n        image->filename);\n      return(MagickFalse);\n    }\n  cache_info->storage_class=image->storage_class;\n  cache_info->colorspace=image->colorspace;\n  length=number_pixels*(sizeof(PixelPacket)+sizeof(IndexPacket));\n  if (length != (MagickSizeType) ((size_t) length))\n    cache_info->type=DiskCache;\n  else\n    {\n      status=AcquireMagickResource(MapResource,cache_info->length);\n      if ((status == MagickFalse) && (cache_info->type != MapCache) &&\n          (cache_info->type != MemoryCache))\n        cache_info->type=DiskCache;\n      else\n        {\n          cache_info->pixels=(PixelPacket *) MapBlob(cache_info->file,mode,\n            cache_info->offset,(size_t) cache_info->length);\n          if (cache_info->pixels == (PixelPacket *) NULL)\n            {\n              cache_info->pixels=source_info.pixels;\n              cache_info->type=DiskCache;\n            }\n          else\n            {\n              /*\n                Create file-backed memory-mapped pixel cache.\n              */\n              (void) ClosePixelCacheOnDisk(cache_info);\n              cache_info->type=MapCache;\n              cache_info->mapped=MagickTrue;\n              cache_info->indexes=(IndexPacket *) NULL;\n              if (cache_info->active_index_channel != MagickFalse)\n                cache_info->indexes=(IndexPacket *) (cache_info->pixels+\n                  number_pixels);\n              if ((source_info.storage_class != UndefinedClass) &&\n                  (mode != ReadMode))\n                {\n                  status=ClonePixelCacheRepository(cache_info,&source_info,\n                    exception);\n                  RelinquishPixelCachePixels(&source_info);\n                }\n              if (image->debug != MagickFalse)\n                {\n                  (void) FormatMagickSize(cache_info->length,MagickTrue,format);\n                  type=CommandOptionToMnemonic(MagickCacheOptions,(ssize_t)\n                    cache_info->type);\n                  (void) FormatLocaleString(message,MaxTextExtent,\n                    \"open %s (%s[%d], %s, %.20gx%.20g %s)\",\n                    cache_info->filename,cache_info->cache_filename,\n                    cache_info->file,type,(double) cache_info->columns,(double)\n                    cache_info->rows,format);\n                  (void) LogMagickEvent(CacheEvent,GetMagickModule(),\"%s\",\n                    message);\n                }\n              return(MagickTrue);\n            }\n        }\n      RelinquishMagickResource(MapResource,cache_info->length);\n    }\n  if ((source_info.storage_class != UndefinedClass) && (mode != ReadMode))\n    {\n      status=ClonePixelCacheRepository(cache_info,&source_info,exception);\n      RelinquishPixelCachePixels(&source_info);\n    }\n  if (image->debug != MagickFalse)\n    {\n      (void) FormatMagickSize(cache_info->length,MagickFalse,format);\n      type=CommandOptionToMnemonic(MagickCacheOptions,(ssize_t)\n        cache_info->type);\n      (void) FormatLocaleString(message,MaxTextExtent,\n        \"open %s (%s[%d], %s, %.20gx%.20g %s)\",cache_info->filename,\n        cache_info->cache_filename,cache_info->file,type,(double)\n        cache_info->columns,(double) cache_info->rows,format);\n      (void) LogMagickEvent(CacheEvent,GetMagickModule(),\"%s\",message);\n    }\n  return(MagickTrue);\n}",
        "func": "static MagickBooleanType OpenPixelCache(Image *image,const MapMode mode,\n  ExceptionInfo *exception)\n{\n  CacheInfo\n    *magick_restrict cache_info,\n    source_info;\n\n  char\n    format[MaxTextExtent],\n    message[MaxTextExtent];\n\n  const char\n    *type;\n\n  MagickSizeType\n    length,\n    number_pixels;\n\n  MagickStatusType\n    status;\n\n  size_t\n    columns,\n    packet_size;\n\n  assert(image != (const Image *) NULL);\n  assert(image->signature == MagickSignature);\n  assert(image->cache != (Cache) NULL);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",image->filename);\n  if ((image->columns == 0) || (image->rows == 0))\n    ThrowBinaryException(CacheError,\"NoPixelsDefinedInCache\",image->filename);\n  cache_info=(CacheInfo *) image->cache;\n  assert(cache_info->signature == MagickSignature);\n  if ((AcquireMagickResource(WidthResource,image->columns) == MagickFalse) ||\n      (AcquireMagickResource(HeightResource,image->rows) == MagickFalse))\n    ThrowBinaryException(ResourceLimitError,\"PixelCacheAllocationFailed\",\n      image->filename);\n  source_info=(*cache_info);\n  source_info.file=(-1);\n  (void) FormatLocaleString(cache_info->filename,MaxTextExtent,\"%s[%.20g]\",\n    image->filename,(double) GetImageIndexInList(image));\n  cache_info->mode=mode;\n  cache_info->rows=image->rows;\n  cache_info->columns=image->columns;\n  cache_info->channels=image->channels;\n  cache_info->active_index_channel=((image->storage_class == PseudoClass) ||\n    (image->colorspace == CMYKColorspace)) ? MagickTrue : MagickFalse;\n  number_pixels=(MagickSizeType) cache_info->columns*cache_info->rows;\n  packet_size=sizeof(PixelPacket);\n  if (cache_info->active_index_channel != MagickFalse)\n    packet_size+=sizeof(IndexPacket);\n  length=number_pixels*packet_size;\n  columns=(size_t) (length/cache_info->rows/packet_size);\n  if ((cache_info->columns != columns) || ((ssize_t) cache_info->columns < 0) ||\n      ((ssize_t) cache_info->rows < 0))\n    ThrowBinaryException(ResourceLimitError,\"PixelCacheAllocationFailed\",\n      image->filename);\n  cache_info->length=length;\n  if (image->ping != MagickFalse)\n    {\n      cache_info->storage_class=image->storage_class;\n      cache_info->colorspace=image->colorspace;\n      cache_info->type=PingCache;\n      return(MagickTrue);\n    }\n  status=AcquireMagickResource(AreaResource,cache_info->length);\n  length=number_pixels*(sizeof(PixelPacket)+sizeof(IndexPacket));\n  if ((status != MagickFalse) && (length == (MagickSizeType) ((size_t) length)))\n    {\n      status=AcquireMagickResource(MemoryResource,cache_info->length);\n      if (((cache_info->type == UndefinedCache) && (status != MagickFalse)) ||\n          (cache_info->type == MemoryCache))\n        {\n          cache_info->mapped=MagickFalse;\n          cache_info->pixels=(PixelPacket *) MagickAssumeAligned(\n            AcquireAlignedMemory(1,(size_t) cache_info->length));\n          if (cache_info->pixels == (PixelPacket *) NULL)\n            cache_info->pixels=source_info.pixels;\n          else\n            {\n              /*\n                Create memory pixel cache.\n              */\n              cache_info->colorspace=image->colorspace;\n              cache_info->type=MemoryCache;\n              cache_info->indexes=(IndexPacket *) NULL;\n              if (cache_info->active_index_channel != MagickFalse)\n                cache_info->indexes=(IndexPacket *) (cache_info->pixels+\n                  number_pixels);\n              if ((source_info.storage_class != UndefinedClass) &&\n                  (mode != ReadMode))\n                {\n                  status&=ClonePixelCacheRepository(cache_info,&source_info,\n                    exception);\n                  RelinquishPixelCachePixels(&source_info);\n                }\n              if (image->debug != MagickFalse)\n                {\n                  (void) FormatMagickSize(cache_info->length,MagickTrue,format);\n                  type=CommandOptionToMnemonic(MagickCacheOptions,(ssize_t)\n                    cache_info->type);\n                  (void) FormatLocaleString(message,MaxTextExtent,\n                    \"open %s (%s %s, %.20gx%.20g %s)\",cache_info->filename,\n                    cache_info->mapped != MagickFalse ? \"Anonymous\" : \"Heap\",\n                    type,(double) cache_info->columns,(double) cache_info->rows,\n                    format);\n                  (void) LogMagickEvent(CacheEvent,GetMagickModule(),\"%s\",\n                    message);\n                }\n              cache_info->storage_class=image->storage_class;\n              return(MagickTrue);\n            }\n        }\n      RelinquishMagickResource(MemoryResource,cache_info->length);\n    }\n  /*\n    Create pixel cache on disk.\n  */\n  status=AcquireMagickResource(DiskResource,cache_info->length);\n  if ((status == MagickFalse) || (cache_info->type == DistributedCache))\n    {\n      DistributeCacheInfo\n        *server_info;\n\n      if (cache_info->type == DistributedCache)\n        RelinquishMagickResource(DiskResource,cache_info->length);\n      server_info=AcquireDistributeCacheInfo(exception);\n      if (server_info != (DistributeCacheInfo *) NULL)\n        {\n          status=OpenDistributePixelCache(server_info,image);\n          if (status == MagickFalse)\n            {\n              ThrowFileException(exception,CacheError,\"UnableToOpenPixelCache\",\n                GetDistributeCacheHostname(server_info));\n              server_info=DestroyDistributeCacheInfo(server_info);\n            }\n          else\n            {\n              /*\n                Create a distributed pixel cache.\n              */\n              cache_info->type=DistributedCache;\n              cache_info->storage_class=image->storage_class;\n              cache_info->colorspace=image->colorspace;\n              cache_info->server_info=server_info;\n              (void) FormatLocaleString(cache_info->cache_filename,\n                MaxTextExtent,\"%s:%d\",GetDistributeCacheHostname(\n                (DistributeCacheInfo *) cache_info->server_info),\n                GetDistributeCachePort((DistributeCacheInfo *)\n                cache_info->server_info));\n              if ((source_info.storage_class != UndefinedClass) &&\n                  (mode != ReadMode))\n                {\n                  status=ClonePixelCacheRepository(cache_info,&source_info,\n                    exception);\n                  RelinquishPixelCachePixels(&source_info);\n                }\n              if (image->debug != MagickFalse)\n                {\n                  (void) FormatMagickSize(cache_info->length,MagickFalse,\n                    format);\n                  type=CommandOptionToMnemonic(MagickCacheOptions,(ssize_t)\n                    cache_info->type);\n                  (void) FormatLocaleString(message,MaxTextExtent,\n                    \"open %s (%s[%d], %s, %.20gx%.20g %s)\",cache_info->filename,\n                    cache_info->cache_filename,GetDistributeCacheFile(\n                    (DistributeCacheInfo *) cache_info->server_info),type,\n                    (double) cache_info->columns,(double) cache_info->rows,\n                    format);\n                  (void) LogMagickEvent(CacheEvent,GetMagickModule(),\"%s\",\n                    message);\n                }\n              return(MagickTrue);\n            }\n        }\n      RelinquishMagickResource(DiskResource,cache_info->length);\n      (void) ThrowMagickException(exception,GetMagickModule(),CacheError,\n        \"CacheResourcesExhausted\",\"`%s'\",image->filename);\n      return(MagickFalse);\n    }\n  if ((source_info.storage_class != UndefinedClass) && (mode != ReadMode))\n    {\n      (void) ClosePixelCacheOnDisk(cache_info);\n      *cache_info->cache_filename='\\0';\n    }\n  if (OpenPixelCacheOnDisk(cache_info,mode) == MagickFalse)\n    {\n      RelinquishMagickResource(DiskResource,cache_info->length);\n      ThrowFileException(exception,CacheError,\"UnableToOpenPixelCache\",\n        image->filename);\n      return(MagickFalse);\n    }\n  status=SetPixelCacheExtent(image,(MagickSizeType) cache_info->offset+\n    cache_info->length);\n  if (status == MagickFalse)\n    {\n      ThrowFileException(exception,CacheError,\"UnableToExtendCache\",\n        image->filename);\n      return(MagickFalse);\n    }\n  cache_info->storage_class=image->storage_class;\n  cache_info->colorspace=image->colorspace;\n  length=number_pixels*(sizeof(PixelPacket)+sizeof(IndexPacket));\n  if (length != (MagickSizeType) ((size_t) length))\n    cache_info->type=DiskCache;\n  else\n    {\n      status=AcquireMagickResource(MapResource,cache_info->length);\n      if ((status == MagickFalse) && (cache_info->type != MapCache) &&\n          (cache_info->type != MemoryCache))\n        cache_info->type=DiskCache;\n      else\n        {\n          cache_info->pixels=(PixelPacket *) MapBlob(cache_info->file,mode,\n            cache_info->offset,(size_t) cache_info->length);\n          if (cache_info->pixels == (PixelPacket *) NULL)\n            {\n              cache_info->pixels=source_info.pixels;\n              cache_info->type=DiskCache;\n            }\n          else\n            {\n              /*\n                Create file-backed memory-mapped pixel cache.\n              */\n              (void) ClosePixelCacheOnDisk(cache_info);\n              cache_info->type=MapCache;\n              cache_info->mapped=MagickTrue;\n              cache_info->indexes=(IndexPacket *) NULL;\n              if (cache_info->active_index_channel != MagickFalse)\n                cache_info->indexes=(IndexPacket *) (cache_info->pixels+\n                  number_pixels);\n              if ((source_info.storage_class != UndefinedClass) &&\n                  (mode != ReadMode))\n                {\n                  status=ClonePixelCacheRepository(cache_info,&source_info,\n                    exception);\n                  RelinquishPixelCachePixels(&source_info);\n                }\n              if (image->debug != MagickFalse)\n                {\n                  (void) FormatMagickSize(cache_info->length,MagickTrue,format);\n                  type=CommandOptionToMnemonic(MagickCacheOptions,(ssize_t)\n                    cache_info->type);\n                  (void) FormatLocaleString(message,MaxTextExtent,\n                    \"open %s (%s[%d], %s, %.20gx%.20g %s)\",\n                    cache_info->filename,cache_info->cache_filename,\n                    cache_info->file,type,(double) cache_info->columns,(double)\n                    cache_info->rows,format);\n                  (void) LogMagickEvent(CacheEvent,GetMagickModule(),\"%s\",\n                    message);\n                }\n              return(MagickTrue);\n            }\n        }\n      RelinquishMagickResource(MapResource,cache_info->length);\n    }\n  if ((source_info.storage_class != UndefinedClass) && (mode != ReadMode))\n    {\n      status=ClonePixelCacheRepository(cache_info,&source_info,exception);\n      RelinquishPixelCachePixels(&source_info);\n    }\n  if (image->debug != MagickFalse)\n    {\n      (void) FormatMagickSize(cache_info->length,MagickFalse,format);\n      type=CommandOptionToMnemonic(MagickCacheOptions,(ssize_t)\n        cache_info->type);\n      (void) FormatLocaleString(message,MaxTextExtent,\n        \"open %s (%s[%d], %s, %.20gx%.20g %s)\",cache_info->filename,\n        cache_info->cache_filename,cache_info->file,type,(double)\n        cache_info->columns,(double) cache_info->rows,format);\n      (void) LogMagickEvent(CacheEvent,GetMagickModule(),\"%s\",message);\n    }\n  return(MagickTrue);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -72,7 +72,9 @@\n       if (((cache_info->type == UndefinedCache) && (status != MagickFalse)) ||\n           (cache_info->type == MemoryCache))\n         {\n-          AllocatePixelCachePixels(cache_info);\n+          cache_info->mapped=MagickFalse;\n+          cache_info->pixels=(PixelPacket *) MagickAssumeAligned(\n+            AcquireAlignedMemory(1,(size_t) cache_info->length));\n           if (cache_info->pixels == (PixelPacket *) NULL)\n             cache_info->pixels=source_info.pixels;\n           else",
        "diff_line_info": {
            "deleted_lines": [
                "          AllocatePixelCachePixels(cache_info);"
            ],
            "added_lines": [
                "          cache_info->mapped=MagickFalse;",
                "          cache_info->pixels=(PixelPacket *) MagickAssumeAligned(",
                "            AcquireAlignedMemory(1,(size_t) cache_info->length));"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-7972",
        "func_name": "libass/check_allocations",
        "description": "The check_allocations function in libass/ass_shaper.c in libass before 0.13.4 allows remote attackers to cause a denial of service (memory allocation failure) via unspecified vectors.",
        "git_url": "https://github.com/libass/libass/commit/aa54e0b59200a994d50a346b5d7ac818ebcf2d4b",
        "commit_title": "shaper: fix reallocation",
        "commit_text": " Update the variable that tracks the allocated size. This potentially improves performance and avoid some side effects, which lead to undefined behavior in some cases.  Fixes fuzzer test case id:000051,sig:11,sync:fuzzer3,src:004221.",
        "func_before": "static bool check_allocations(ASS_Shaper *shaper, size_t new_size)\n{\n    if (new_size > shaper->n_glyphs) {\n        if (!ASS_REALLOC_ARRAY(shaper->event_text, new_size) ||\n            !ASS_REALLOC_ARRAY(shaper->ctypes, new_size) ||\n            !ASS_REALLOC_ARRAY(shaper->emblevels, new_size) ||\n            !ASS_REALLOC_ARRAY(shaper->cmap, new_size))\n            return false;\n    }\n    return true;\n}",
        "func": "static bool check_allocations(ASS_Shaper *shaper, size_t new_size)\n{\n    if (new_size > shaper->n_glyphs) {\n        if (!ASS_REALLOC_ARRAY(shaper->event_text, new_size) ||\n            !ASS_REALLOC_ARRAY(shaper->ctypes, new_size) ||\n            !ASS_REALLOC_ARRAY(shaper->emblevels, new_size) ||\n            !ASS_REALLOC_ARRAY(shaper->cmap, new_size))\n            return false;\n        shaper->n_glyphs = new_size;\n    }\n    return true;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -6,6 +6,7 @@\n             !ASS_REALLOC_ARRAY(shaper->emblevels, new_size) ||\n             !ASS_REALLOC_ARRAY(shaper->cmap, new_size))\n             return false;\n+        shaper->n_glyphs = new_size;\n     }\n     return true;\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "        shaper->n_glyphs = new_size;"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-9745",
        "func_name": "freetype/freetype2/parse_encoding",
        "description": "The parse_encoding function in type1/t1load.c in FreeType before 2.5.3 allows remote attackers to cause a denial of service (infinite loop) via a \"broken number-with-base\" in a Postscript stream, as demonstrated by 8#garbage.",
        "git_url": "http://git.savannah.gnu.org/cgit/freetype/freetype2.git/commit/?id=df14e6c0b9592cbb24d5381dfc6106b14f915e75",
        "commit_title": "* src/type1/t1load.c (parse_encoding): Protect against invalid",
        "commit_text": "number. ",
        "func_before": "static void\n  parse_encoding( T1_Face    face,\n                  T1_Loader  loader )\n  {\n    T1_Parser  parser = &loader->parser;\n    FT_Byte*   cur;\n    FT_Byte*   limit  = parser->root.limit;\n\n    PSAux_Service  psaux = (PSAux_Service)face->psaux;\n\n\n    T1_Skip_Spaces( parser );\n    cur = parser->root.cursor;\n    if ( cur >= limit )\n    {\n      FT_ERROR(( \"parse_encoding: out of bounds\\n\" ));\n      parser->root.error = FT_THROW( Invalid_File_Format );\n      return;\n    }\n\n    /* if we have a number or `[', the encoding is an array, */\n    /* and we must load it now                               */\n    if ( ft_isdigit( *cur ) || *cur == '[' )\n    {\n      T1_Encoding  encode          = &face->type1.encoding;\n      FT_Int       count, n;\n      PS_Table     char_table      = &loader->encoding_table;\n      FT_Memory    memory          = parser->root.memory;\n      FT_Error     error;\n      FT_Bool      only_immediates = 0;\n\n\n      /* read the number of entries in the encoding; should be 256 */\n      if ( *cur == '[' )\n      {\n        count           = 256;\n        only_immediates = 1;\n        parser->root.cursor++;\n      }\n      else\n        count = (FT_Int)T1_ToInt( parser );\n\n      T1_Skip_Spaces( parser );\n      if ( parser->root.cursor >= limit )\n        return;\n\n      /* we use a T1_Table to store our charnames */\n      loader->num_chars = encode->num_chars = count;\n      if ( FT_NEW_ARRAY( encode->char_index, count )     ||\n           FT_NEW_ARRAY( encode->char_name,  count )     ||\n           FT_SET_ERROR( psaux->ps_table_funcs->init(\n                           char_table, count, memory ) ) )\n      {\n        parser->root.error = error;\n        return;\n      }\n\n      /* We need to `zero' out encoding_table.elements */\n      for ( n = 0; n < count; n++ )\n      {\n        char*  notdef = (char *)\".notdef\";\n\n\n        T1_Add_Table( char_table, n, notdef, 8 );\n      }\n\n      /* Now we need to read records of the form                */\n      /*                                                        */\n      /*   ... charcode /charname ...                           */\n      /*                                                        */\n      /* for each entry in our table.                           */\n      /*                                                        */\n      /* We simply look for a number followed by an immediate   */\n      /* name.  Note that this ignores correctly the sequence   */\n      /* that is often seen in type1 fonts:                     */\n      /*                                                        */\n      /*   0 1 255 { 1 index exch /.notdef put } for dup        */\n      /*                                                        */\n      /* used to clean the encoding array before anything else. */\n      /*                                                        */\n      /* Alternatively, if the array is directly given as       */\n      /*                                                        */\n      /*   /Encoding [ ... ]                                    */\n      /*                                                        */\n      /* we only read immediates.                               */\n\n      n = 0;\n      T1_Skip_Spaces( parser );\n\n      while ( parser->root.cursor < limit )\n      {\n        cur = parser->root.cursor;\n\n        /* we stop when we encounter a `def' or `]' */\n        if ( *cur == 'd' && cur + 3 < limit )\n        {\n          if ( cur[1] == 'e'         &&\n               cur[2] == 'f'         &&\n               IS_PS_DELIM( cur[3] ) )\n          {\n            FT_TRACE6(( \"encoding end\\n\" ));\n            cur += 3;\n            break;\n          }\n        }\n        if ( *cur == ']' )\n        {\n          FT_TRACE6(( \"encoding end\\n\" ));\n          cur++;\n          break;\n        }\n\n        /* check whether we've found an entry */\n        if ( ft_isdigit( *cur ) || only_immediates )\n        {\n          FT_Int  charcode;\n\n\n          if ( only_immediates )\n            charcode = n;\n          else\n          {\n            charcode = (FT_Int)T1_ToInt( parser );\n            T1_Skip_Spaces( parser );\n          }\n\n          cur = parser->root.cursor;\n\n          if ( cur + 2 < limit && *cur == '/' && n < count )\n          {\n            FT_PtrDist  len;\n\n\n            cur++;\n\n            parser->root.cursor = cur;\n            T1_Skip_PS_Token( parser );\n            if ( parser->root.cursor >= limit )\n              return;\n            if ( parser->root.error )\n              return;\n\n            len = parser->root.cursor - cur;\n\n            parser->root.error = T1_Add_Table( char_table, charcode,\n                                               cur, len + 1 );\n            if ( parser->root.error )\n              return;\n            char_table->elements[charcode][len] = '\\0';\n\n            n++;\n          }\n          else if ( only_immediates )\n          {\n            /* Since the current position is not updated for           */\n            /* immediates-only mode we would get an infinite loop if   */\n            /* we don't do anything here.                              */\n            /*                                                         */\n            /* This encoding array is not valid according to the type1 */\n            /* specification (it might be an encoding for a CID type1  */\n            /* font, however), so we conclude that this font is NOT a  */\n            /* type1 font.                                             */\n            parser->root.error = FT_THROW( Unknown_File_Format );\n            return;\n          }\n        }\n        else\n        {\n          T1_Skip_PS_Token( parser );\n          if ( parser->root.error )\n            return;\n        }\n\n        T1_Skip_Spaces( parser );\n      }\n\n      face->type1.encoding_type = T1_ENCODING_TYPE_ARRAY;\n      parser->root.cursor       = cur;\n    }\n\n    /* Otherwise, we should have either `StandardEncoding', */\n    /* `ExpertEncoding', or `ISOLatin1Encoding'             */\n    else\n    {\n      if ( cur + 17 < limit                                            &&\n           ft_strncmp( (const char*)cur, \"StandardEncoding\", 16 ) == 0 )\n        face->type1.encoding_type = T1_ENCODING_TYPE_STANDARD;\n\n      else if ( cur + 15 < limit                                          &&\n                ft_strncmp( (const char*)cur, \"ExpertEncoding\", 14 ) == 0 )\n        face->type1.encoding_type = T1_ENCODING_TYPE_EXPERT;\n\n      else if ( cur + 18 < limit                                             &&\n                ft_strncmp( (const char*)cur, \"ISOLatin1Encoding\", 17 ) == 0 )\n        face->type1.encoding_type = T1_ENCODING_TYPE_ISOLATIN1;\n\n      else\n        parser->root.error = FT_ERR( Ignore );\n    }\n  }",
        "func": "static void\n  parse_encoding( T1_Face    face,\n                  T1_Loader  loader )\n  {\n    T1_Parser  parser = &loader->parser;\n    FT_Byte*   cur;\n    FT_Byte*   limit  = parser->root.limit;\n\n    PSAux_Service  psaux = (PSAux_Service)face->psaux;\n\n\n    T1_Skip_Spaces( parser );\n    cur = parser->root.cursor;\n    if ( cur >= limit )\n    {\n      FT_ERROR(( \"parse_encoding: out of bounds\\n\" ));\n      parser->root.error = FT_THROW( Invalid_File_Format );\n      return;\n    }\n\n    /* if we have a number or `[', the encoding is an array, */\n    /* and we must load it now                               */\n    if ( ft_isdigit( *cur ) || *cur == '[' )\n    {\n      T1_Encoding  encode          = &face->type1.encoding;\n      FT_Int       count, n;\n      PS_Table     char_table      = &loader->encoding_table;\n      FT_Memory    memory          = parser->root.memory;\n      FT_Error     error;\n      FT_Bool      only_immediates = 0;\n\n\n      /* read the number of entries in the encoding; should be 256 */\n      if ( *cur == '[' )\n      {\n        count           = 256;\n        only_immediates = 1;\n        parser->root.cursor++;\n      }\n      else\n        count = (FT_Int)T1_ToInt( parser );\n\n      T1_Skip_Spaces( parser );\n      if ( parser->root.cursor >= limit )\n        return;\n\n      /* we use a T1_Table to store our charnames */\n      loader->num_chars = encode->num_chars = count;\n      if ( FT_NEW_ARRAY( encode->char_index, count )     ||\n           FT_NEW_ARRAY( encode->char_name,  count )     ||\n           FT_SET_ERROR( psaux->ps_table_funcs->init(\n                           char_table, count, memory ) ) )\n      {\n        parser->root.error = error;\n        return;\n      }\n\n      /* We need to `zero' out encoding_table.elements */\n      for ( n = 0; n < count; n++ )\n      {\n        char*  notdef = (char *)\".notdef\";\n\n\n        T1_Add_Table( char_table, n, notdef, 8 );\n      }\n\n      /* Now we need to read records of the form                */\n      /*                                                        */\n      /*   ... charcode /charname ...                           */\n      /*                                                        */\n      /* for each entry in our table.                           */\n      /*                                                        */\n      /* We simply look for a number followed by an immediate   */\n      /* name.  Note that this ignores correctly the sequence   */\n      /* that is often seen in type1 fonts:                     */\n      /*                                                        */\n      /*   0 1 255 { 1 index exch /.notdef put } for dup        */\n      /*                                                        */\n      /* used to clean the encoding array before anything else. */\n      /*                                                        */\n      /* Alternatively, if the array is directly given as       */\n      /*                                                        */\n      /*   /Encoding [ ... ]                                    */\n      /*                                                        */\n      /* we only read immediates.                               */\n\n      n = 0;\n      T1_Skip_Spaces( parser );\n\n      while ( parser->root.cursor < limit )\n      {\n        cur = parser->root.cursor;\n\n        /* we stop when we encounter a `def' or `]' */\n        if ( *cur == 'd' && cur + 3 < limit )\n        {\n          if ( cur[1] == 'e'         &&\n               cur[2] == 'f'         &&\n               IS_PS_DELIM( cur[3] ) )\n          {\n            FT_TRACE6(( \"encoding end\\n\" ));\n            cur += 3;\n            break;\n          }\n        }\n        if ( *cur == ']' )\n        {\n          FT_TRACE6(( \"encoding end\\n\" ));\n          cur++;\n          break;\n        }\n\n        /* check whether we've found an entry */\n        if ( ft_isdigit( *cur ) || only_immediates )\n        {\n          FT_Int  charcode;\n\n\n          if ( only_immediates )\n            charcode = n;\n          else\n          {\n            charcode = (FT_Int)T1_ToInt( parser );\n            T1_Skip_Spaces( parser );\n\n            /* protect against invalid charcode */\n            if ( cur == parser->root.cursor )\n            {\n              parser->root.error = FT_THROW( Unknown_File_Format );\n              return;\n            }\n          }\n\n          cur = parser->root.cursor;\n\n          if ( cur + 2 < limit && *cur == '/' && n < count )\n          {\n            FT_PtrDist  len;\n\n\n            cur++;\n\n            parser->root.cursor = cur;\n            T1_Skip_PS_Token( parser );\n            if ( parser->root.cursor >= limit )\n              return;\n            if ( parser->root.error )\n              return;\n\n            len = parser->root.cursor - cur;\n\n            parser->root.error = T1_Add_Table( char_table, charcode,\n                                               cur, len + 1 );\n            if ( parser->root.error )\n              return;\n            char_table->elements[charcode][len] = '\\0';\n\n            n++;\n          }\n          else if ( only_immediates )\n          {\n            /* Since the current position is not updated for           */\n            /* immediates-only mode we would get an infinite loop if   */\n            /* we don't do anything here.                              */\n            /*                                                         */\n            /* This encoding array is not valid according to the type1 */\n            /* specification (it might be an encoding for a CID type1  */\n            /* font, however), so we conclude that this font is NOT a  */\n            /* type1 font.                                             */\n            parser->root.error = FT_THROW( Unknown_File_Format );\n            return;\n          }\n        }\n        else\n        {\n          T1_Skip_PS_Token( parser );\n          if ( parser->root.error )\n            return;\n        }\n\n        T1_Skip_Spaces( parser );\n      }\n\n      face->type1.encoding_type = T1_ENCODING_TYPE_ARRAY;\n      parser->root.cursor       = cur;\n    }\n\n    /* Otherwise, we should have either `StandardEncoding', */\n    /* `ExpertEncoding', or `ISOLatin1Encoding'             */\n    else\n    {\n      if ( cur + 17 < limit                                            &&\n           ft_strncmp( (const char*)cur, \"StandardEncoding\", 16 ) == 0 )\n        face->type1.encoding_type = T1_ENCODING_TYPE_STANDARD;\n\n      else if ( cur + 15 < limit                                          &&\n                ft_strncmp( (const char*)cur, \"ExpertEncoding\", 14 ) == 0 )\n        face->type1.encoding_type = T1_ENCODING_TYPE_EXPERT;\n\n      else if ( cur + 18 < limit                                             &&\n                ft_strncmp( (const char*)cur, \"ISOLatin1Encoding\", 17 ) == 0 )\n        face->type1.encoding_type = T1_ENCODING_TYPE_ISOLATIN1;\n\n      else\n        parser->root.error = FT_ERR( Ignore );\n    }\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -122,6 +122,13 @@\n           {\n             charcode = (FT_Int)T1_ToInt( parser );\n             T1_Skip_Spaces( parser );\n+\n+            /* protect against invalid charcode */\n+            if ( cur == parser->root.cursor )\n+            {\n+              parser->root.error = FT_THROW( Unknown_File_Format );\n+              return;\n+            }\n           }\n \n           cur = parser->root.cursor;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "            /* protect against invalid charcode */",
                "            if ( cur == parser->root.cursor )",
                "            {",
                "              parser->root.error = FT_THROW( Unknown_File_Format );",
                "              return;",
                "            }"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-6252",
        "func_name": "torvalds/linux/vhost_dev_ioctl",
        "description": "The vhost_dev_ioctl function in drivers/vhost/vhost.c in the Linux kernel before 4.1.5 allows local users to cause a denial of service (memory consumption) via a VHOST_SET_LOG_FD ioctl call that triggers permanent file-descriptor allocation.",
        "git_url": "https://github.com/torvalds/linux/commit/7932c0bd7740f4cd2aa168d3ce0199e7af7d72d5",
        "commit_title": "vhost: actually track log eventfd file",
        "commit_text": " While reviewing vhost log code, I found out that log_file is never set. Note: I haven't tested the change (QEMU doesn't use LOG_FD yet).  Cc: stable@vger.kernel.org",
        "func_before": "long vhost_dev_ioctl(struct vhost_dev *d, unsigned int ioctl, void __user *argp)\n{\n\tstruct file *eventfp, *filep = NULL;\n\tstruct eventfd_ctx *ctx = NULL;\n\tu64 p;\n\tlong r;\n\tint i, fd;\n\n\t/* If you are not the owner, you can become one */\n\tif (ioctl == VHOST_SET_OWNER) {\n\t\tr = vhost_dev_set_owner(d);\n\t\tgoto done;\n\t}\n\n\t/* You must be the owner to do anything else */\n\tr = vhost_dev_check_owner(d);\n\tif (r)\n\t\tgoto done;\n\n\tswitch (ioctl) {\n\tcase VHOST_SET_MEM_TABLE:\n\t\tr = vhost_set_memory(d, argp);\n\t\tbreak;\n\tcase VHOST_SET_LOG_BASE:\n\t\tif (copy_from_user(&p, argp, sizeof p)) {\n\t\t\tr = -EFAULT;\n\t\t\tbreak;\n\t\t}\n\t\tif ((u64)(unsigned long)p != p) {\n\t\t\tr = -EFAULT;\n\t\t\tbreak;\n\t\t}\n\t\tfor (i = 0; i < d->nvqs; ++i) {\n\t\t\tstruct vhost_virtqueue *vq;\n\t\t\tvoid __user *base = (void __user *)(unsigned long)p;\n\t\t\tvq = d->vqs[i];\n\t\t\tmutex_lock(&vq->mutex);\n\t\t\t/* If ring is inactive, will check when it's enabled. */\n\t\t\tif (vq->private_data && !vq_log_access_ok(vq, base))\n\t\t\t\tr = -EFAULT;\n\t\t\telse\n\t\t\t\tvq->log_base = base;\n\t\t\tmutex_unlock(&vq->mutex);\n\t\t}\n\t\tbreak;\n\tcase VHOST_SET_LOG_FD:\n\t\tr = get_user(fd, (int __user *)argp);\n\t\tif (r < 0)\n\t\t\tbreak;\n\t\teventfp = fd == -1 ? NULL : eventfd_fget(fd);\n\t\tif (IS_ERR(eventfp)) {\n\t\t\tr = PTR_ERR(eventfp);\n\t\t\tbreak;\n\t\t}\n\t\tif (eventfp != d->log_file) {\n\t\t\tfilep = d->log_file;\n\t\t\tctx = d->log_ctx;\n\t\t\td->log_ctx = eventfp ?\n\t\t\t\teventfd_ctx_fileget(eventfp) : NULL;\n\t\t} else\n\t\t\tfilep = eventfp;\n\t\tfor (i = 0; i < d->nvqs; ++i) {\n\t\t\tmutex_lock(&d->vqs[i]->mutex);\n\t\t\td->vqs[i]->log_ctx = d->log_ctx;\n\t\t\tmutex_unlock(&d->vqs[i]->mutex);\n\t\t}\n\t\tif (ctx)\n\t\t\teventfd_ctx_put(ctx);\n\t\tif (filep)\n\t\t\tfput(filep);\n\t\tbreak;\n\tdefault:\n\t\tr = -ENOIOCTLCMD;\n\t\tbreak;\n\t}\ndone:\n\treturn r;\n}",
        "func": "long vhost_dev_ioctl(struct vhost_dev *d, unsigned int ioctl, void __user *argp)\n{\n\tstruct file *eventfp, *filep = NULL;\n\tstruct eventfd_ctx *ctx = NULL;\n\tu64 p;\n\tlong r;\n\tint i, fd;\n\n\t/* If you are not the owner, you can become one */\n\tif (ioctl == VHOST_SET_OWNER) {\n\t\tr = vhost_dev_set_owner(d);\n\t\tgoto done;\n\t}\n\n\t/* You must be the owner to do anything else */\n\tr = vhost_dev_check_owner(d);\n\tif (r)\n\t\tgoto done;\n\n\tswitch (ioctl) {\n\tcase VHOST_SET_MEM_TABLE:\n\t\tr = vhost_set_memory(d, argp);\n\t\tbreak;\n\tcase VHOST_SET_LOG_BASE:\n\t\tif (copy_from_user(&p, argp, sizeof p)) {\n\t\t\tr = -EFAULT;\n\t\t\tbreak;\n\t\t}\n\t\tif ((u64)(unsigned long)p != p) {\n\t\t\tr = -EFAULT;\n\t\t\tbreak;\n\t\t}\n\t\tfor (i = 0; i < d->nvqs; ++i) {\n\t\t\tstruct vhost_virtqueue *vq;\n\t\t\tvoid __user *base = (void __user *)(unsigned long)p;\n\t\t\tvq = d->vqs[i];\n\t\t\tmutex_lock(&vq->mutex);\n\t\t\t/* If ring is inactive, will check when it's enabled. */\n\t\t\tif (vq->private_data && !vq_log_access_ok(vq, base))\n\t\t\t\tr = -EFAULT;\n\t\t\telse\n\t\t\t\tvq->log_base = base;\n\t\t\tmutex_unlock(&vq->mutex);\n\t\t}\n\t\tbreak;\n\tcase VHOST_SET_LOG_FD:\n\t\tr = get_user(fd, (int __user *)argp);\n\t\tif (r < 0)\n\t\t\tbreak;\n\t\teventfp = fd == -1 ? NULL : eventfd_fget(fd);\n\t\tif (IS_ERR(eventfp)) {\n\t\t\tr = PTR_ERR(eventfp);\n\t\t\tbreak;\n\t\t}\n\t\tif (eventfp != d->log_file) {\n\t\t\tfilep = d->log_file;\n\t\t\td->log_file = eventfp;\n\t\t\tctx = d->log_ctx;\n\t\t\td->log_ctx = eventfp ?\n\t\t\t\teventfd_ctx_fileget(eventfp) : NULL;\n\t\t} else\n\t\t\tfilep = eventfp;\n\t\tfor (i = 0; i < d->nvqs; ++i) {\n\t\t\tmutex_lock(&d->vqs[i]->mutex);\n\t\t\td->vqs[i]->log_ctx = d->log_ctx;\n\t\t\tmutex_unlock(&d->vqs[i]->mutex);\n\t\t}\n\t\tif (ctx)\n\t\t\teventfd_ctx_put(ctx);\n\t\tif (filep)\n\t\t\tfput(filep);\n\t\tbreak;\n\tdefault:\n\t\tr = -ENOIOCTLCMD;\n\t\tbreak;\n\t}\ndone:\n\treturn r;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -54,6 +54,7 @@\n \t\t}\n \t\tif (eventfp != d->log_file) {\n \t\t\tfilep = d->log_file;\n+\t\t\td->log_file = eventfp;\n \t\t\tctx = d->log_ctx;\n \t\t\td->log_ctx = eventfp ?\n \t\t\t\teventfd_ctx_fileget(eventfp) : NULL;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t\t\td->log_file = eventfp;"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-7813",
        "func_name": "xen-project/xen/do_hvm_op",
        "description": "Xen 4.4.x, 4.5.x, and 4.6.x does not limit the number of printk console messages when reporting unimplemented hypercalls, which allows local guests to cause a denial of service via a sequence of (1) HYPERVISOR_physdev_op hypercalls, which are not properly handled in the do_physdev_op function in arch/arm/physdev.c, or (2) HYPERVISOR_hvm_op hypercalls, which are not properly handled in the do_hvm_op function in arch/arm/hvm.c.",
        "git_url": "https://github.com/xen-project/xen/commit/1c0e59ff15764e7b0c59282365974f5b8924ce83",
        "commit_title": "arm: rate-limit logging from unimplemented PHYSDEVOP and HVMOP.",
        "commit_text": " These are guest accessible and should therefore be rate-limited. Moreover, include them only in debug builds.  This is CVE-2015-7813 / XSA-146. ",
        "func_before": "long do_hvm_op(unsigned long op, XEN_GUEST_HANDLE_PARAM(void) arg)\n\n{\n    long rc = 0;\n\n    switch ( op )\n    {\n    case HVMOP_set_param:\n    case HVMOP_get_param:\n    {\n        struct xen_hvm_param a;\n        struct domain *d;\n\n        if ( copy_from_guest(&a, arg, 1) )\n            return -EFAULT;\n\n        if ( a.index >= HVM_NR_PARAMS )\n            return -EINVAL;\n\n        d = rcu_lock_domain_by_any_id(a.domid);\n        if ( d == NULL )\n            return -ESRCH;\n\n        rc = xsm_hvm_param(XSM_TARGET, d, op);\n        if ( rc )\n            goto param_fail;\n\n        if ( op == HVMOP_set_param )\n        {\n            d->arch.hvm_domain.params[a.index] = a.value;\n        }\n        else\n        {\n            a.value = d->arch.hvm_domain.params[a.index];\n            rc = copy_to_guest(arg, &a, 1) ? -EFAULT : 0;\n        }\n\n    param_fail:\n        rcu_unlock_domain(d);\n        break;\n    }\n\n    default:\n    {\n        printk(\"%s: Bad HVM op %ld.\\n\", __func__, op);\n        rc = -ENOSYS;\n        break;\n    }\n    }\n\n    return rc;\n}",
        "func": "long do_hvm_op(unsigned long op, XEN_GUEST_HANDLE_PARAM(void) arg)\n\n{\n    long rc = 0;\n\n    switch ( op )\n    {\n    case HVMOP_set_param:\n    case HVMOP_get_param:\n    {\n        struct xen_hvm_param a;\n        struct domain *d;\n\n        if ( copy_from_guest(&a, arg, 1) )\n            return -EFAULT;\n\n        if ( a.index >= HVM_NR_PARAMS )\n            return -EINVAL;\n\n        d = rcu_lock_domain_by_any_id(a.domid);\n        if ( d == NULL )\n            return -ESRCH;\n\n        rc = xsm_hvm_param(XSM_TARGET, d, op);\n        if ( rc )\n            goto param_fail;\n\n        if ( op == HVMOP_set_param )\n        {\n            d->arch.hvm_domain.params[a.index] = a.value;\n        }\n        else\n        {\n            a.value = d->arch.hvm_domain.params[a.index];\n            rc = copy_to_guest(arg, &a, 1) ? -EFAULT : 0;\n        }\n\n    param_fail:\n        rcu_unlock_domain(d);\n        break;\n    }\n\n    default:\n    {\n        gdprintk(XENLOG_DEBUG, \"HVMOP op=%lu: not implemented\\n\", op);\n        rc = -ENOSYS;\n        break;\n    }\n    }\n\n    return rc;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -42,7 +42,7 @@\n \n     default:\n     {\n-        printk(\"%s: Bad HVM op %ld.\\n\", __func__, op);\n+        gdprintk(XENLOG_DEBUG, \"HVMOP op=%lu: not implemented\\n\", op);\n         rc = -ENOSYS;\n         break;\n     }",
        "diff_line_info": {
            "deleted_lines": [
                "        printk(\"%s: Bad HVM op %ld.\\n\", __func__, op);"
            ],
            "added_lines": [
                "        gdprintk(XENLOG_DEBUG, \"HVMOP op=%lu: not implemented\\n\", op);"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-7813",
        "func_name": "xen-project/xen/do_physdev_op",
        "description": "Xen 4.4.x, 4.5.x, and 4.6.x does not limit the number of printk console messages when reporting unimplemented hypercalls, which allows local guests to cause a denial of service via a sequence of (1) HYPERVISOR_physdev_op hypercalls, which are not properly handled in the do_physdev_op function in arch/arm/physdev.c, or (2) HYPERVISOR_hvm_op hypercalls, which are not properly handled in the do_hvm_op function in arch/arm/hvm.c.",
        "git_url": "https://github.com/xen-project/xen/commit/1c0e59ff15764e7b0c59282365974f5b8924ce83",
        "commit_title": "arm: rate-limit logging from unimplemented PHYSDEVOP and HVMOP.",
        "commit_text": " These are guest accessible and should therefore be rate-limited. Moreover, include them only in debug builds.  This is CVE-2015-7813 / XSA-146. ",
        "func_before": "int do_physdev_op(int cmd, XEN_GUEST_HANDLE_PARAM(void) arg)\n{\n    printk(\"%s %d cmd=%d: not implemented yet\\n\", __func__, __LINE__, cmd);\n    return -ENOSYS;\n}",
        "func": "int do_physdev_op(int cmd, XEN_GUEST_HANDLE_PARAM(void) arg)\n{\n    gdprintk(XENLOG_DEBUG, \"PHYSDEVOP cmd=%d: not implemented\\n\", cmd);\n    return -ENOSYS;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,5 @@\n int do_physdev_op(int cmd, XEN_GUEST_HANDLE_PARAM(void) arg)\n {\n-    printk(\"%s %d cmd=%d: not implemented yet\\n\", __func__, __LINE__, cmd);\n+    gdprintk(XENLOG_DEBUG, \"PHYSDEVOP cmd=%d: not implemented\\n\", cmd);\n     return -ENOSYS;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    printk(\"%s %d cmd=%d: not implemented yet\\n\", __func__, __LINE__, cmd);"
            ],
            "added_lines": [
                "    gdprintk(XENLOG_DEBUG, \"PHYSDEVOP cmd=%d: not implemented\\n\", cmd);"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-7969",
        "func_name": "xen-project/xen/alloc_xenoprof_struct",
        "description": "Multiple memory leaks in Xen 4.0 through 4.6.x allow local guest administrators or domains with certain permission to cause a denial of service (memory consumption) via a large number of \"teardowns\" of domains with the vcpu pointer array allocated using the (1) XEN_DOMCTL_max_vcpus hypercall or the xenoprofile state vcpu pointer array allocated using the (2) XENOPROF_get_buffer or (3) XENOPROF_set_passive hypercall.",
        "git_url": "https://github.com/xen-project/xen/commit/6e97c4b37386c2d09e09e9b5d5d232e37728b960",
        "commit_title": "xenoprof: free domain's vcpu array",
        "commit_text": " This was overlooked in fb442e2171 (\"x86_64: allow more vCPU-s per guest\").  This is CVE-2015-7969 / XSA-151. ",
        "func_before": "static int alloc_xenoprof_struct(\n    struct domain *d, int max_samples, int is_passive)\n{\n    struct vcpu *v;\n    int nvcpu, npages, bufsize, max_bufsize;\n    unsigned max_max_samples;\n    int i;\n\n    nvcpu = 0;\n    for_each_vcpu ( d, v )\n        nvcpu++;\n\n    if ( !nvcpu )\n        return -EINVAL;\n\n    d->xenoprof = xzalloc(struct xenoprof);\n    if ( d->xenoprof == NULL )\n    {\n        printk(\"alloc_xenoprof_struct(): memory allocation failed\\n\");\n        return -ENOMEM;\n    }\n\n    d->xenoprof->vcpu = xzalloc_array(struct xenoprof_vcpu, d->max_vcpus);\n    if ( d->xenoprof->vcpu == NULL )\n    {\n        xfree(d->xenoprof);\n        d->xenoprof = NULL;\n        printk(\"alloc_xenoprof_struct(): vcpu array allocation failed\\n\");\n        return -ENOMEM;\n    }\n\n    bufsize = sizeof(struct xenoprof_buf);\n    i = sizeof(struct event_log);\n#ifdef CONFIG_COMPAT\n    d->xenoprof->is_compat = is_pv_32bit_domain(is_passive ? hardware_domain : d);\n    if ( XENOPROF_COMPAT(d->xenoprof) )\n    {\n        bufsize = sizeof(struct compat_oprof_buf);\n        i = sizeof(struct compat_event_log);\n    }\n#endif\n\n    /* reduce max_samples if necessary to limit pages allocated */\n    max_bufsize = (MAX_OPROF_SHARED_PAGES * PAGE_SIZE) / nvcpu;\n    max_max_samples = ( (max_bufsize - bufsize) / i ) + 1;\n    if ( (unsigned)max_samples > max_max_samples )\n        max_samples = max_max_samples;\n\n    bufsize += (max_samples - 1) * i;\n    npages = (nvcpu * bufsize - 1) / PAGE_SIZE + 1;\n\n    d->xenoprof->rawbuf = alloc_xenheap_pages(get_order_from_pages(npages), 0);\n    if ( d->xenoprof->rawbuf == NULL )\n    {\n        xfree(d->xenoprof);\n        d->xenoprof = NULL;\n        return -ENOMEM;\n    }\n\n    d->xenoprof->npages = npages;\n    d->xenoprof->nbuf = nvcpu;\n    d->xenoprof->bufsize = bufsize;\n    d->xenoprof->domain_ready = 0;\n    d->xenoprof->domain_type = XENOPROF_DOMAIN_IGNORED;\n\n    /* Update buffer pointers for active vcpus */\n    i = 0;\n    for_each_vcpu ( d, v )\n    {\n        xenoprof_buf_t *buf = (xenoprof_buf_t *)\n            &d->xenoprof->rawbuf[i * bufsize];\n\n        d->xenoprof->vcpu[v->vcpu_id].event_size = max_samples;\n        d->xenoprof->vcpu[v->vcpu_id].buffer = buf;\n        xenoprof_buf(d, buf, event_size) = max_samples;\n        xenoprof_buf(d, buf, vcpu_id) = v->vcpu_id;\n\n        i++;\n        /* in the unlikely case that the number of active vcpus changes */\n        if ( i >= nvcpu )\n            break;\n    }\n    \n    return 0;\n}",
        "func": "static int alloc_xenoprof_struct(\n    struct domain *d, int max_samples, int is_passive)\n{\n    struct vcpu *v;\n    int nvcpu, npages, bufsize, max_bufsize;\n    unsigned max_max_samples;\n    int i;\n\n    nvcpu = 0;\n    for_each_vcpu ( d, v )\n        nvcpu++;\n\n    if ( !nvcpu )\n        return -EINVAL;\n\n    d->xenoprof = xzalloc(struct xenoprof);\n    if ( d->xenoprof == NULL )\n    {\n        printk(\"alloc_xenoprof_struct(): memory allocation failed\\n\");\n        return -ENOMEM;\n    }\n\n    d->xenoprof->vcpu = xzalloc_array(struct xenoprof_vcpu, d->max_vcpus);\n    if ( d->xenoprof->vcpu == NULL )\n    {\n        xfree(d->xenoprof);\n        d->xenoprof = NULL;\n        printk(\"alloc_xenoprof_struct(): vcpu array allocation failed\\n\");\n        return -ENOMEM;\n    }\n\n    bufsize = sizeof(struct xenoprof_buf);\n    i = sizeof(struct event_log);\n#ifdef CONFIG_COMPAT\n    d->xenoprof->is_compat = is_pv_32bit_domain(is_passive ? hardware_domain : d);\n    if ( XENOPROF_COMPAT(d->xenoprof) )\n    {\n        bufsize = sizeof(struct compat_oprof_buf);\n        i = sizeof(struct compat_event_log);\n    }\n#endif\n\n    /* reduce max_samples if necessary to limit pages allocated */\n    max_bufsize = (MAX_OPROF_SHARED_PAGES * PAGE_SIZE) / nvcpu;\n    max_max_samples = ( (max_bufsize - bufsize) / i ) + 1;\n    if ( (unsigned)max_samples > max_max_samples )\n        max_samples = max_max_samples;\n\n    bufsize += (max_samples - 1) * i;\n    npages = (nvcpu * bufsize - 1) / PAGE_SIZE + 1;\n\n    d->xenoprof->rawbuf = alloc_xenheap_pages(get_order_from_pages(npages), 0);\n    if ( d->xenoprof->rawbuf == NULL )\n    {\n        xfree(d->xenoprof->vcpu);\n        xfree(d->xenoprof);\n        d->xenoprof = NULL;\n        return -ENOMEM;\n    }\n\n    d->xenoprof->npages = npages;\n    d->xenoprof->nbuf = nvcpu;\n    d->xenoprof->bufsize = bufsize;\n    d->xenoprof->domain_ready = 0;\n    d->xenoprof->domain_type = XENOPROF_DOMAIN_IGNORED;\n\n    /* Update buffer pointers for active vcpus */\n    i = 0;\n    for_each_vcpu ( d, v )\n    {\n        xenoprof_buf_t *buf = (xenoprof_buf_t *)\n            &d->xenoprof->rawbuf[i * bufsize];\n\n        d->xenoprof->vcpu[v->vcpu_id].event_size = max_samples;\n        d->xenoprof->vcpu[v->vcpu_id].buffer = buf;\n        xenoprof_buf(d, buf, event_size) = max_samples;\n        xenoprof_buf(d, buf, vcpu_id) = v->vcpu_id;\n\n        i++;\n        /* in the unlikely case that the number of active vcpus changes */\n        if ( i >= nvcpu )\n            break;\n    }\n    \n    return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -52,6 +52,7 @@\n     d->xenoprof->rawbuf = alloc_xenheap_pages(get_order_from_pages(npages), 0);\n     if ( d->xenoprof->rawbuf == NULL )\n     {\n+        xfree(d->xenoprof->vcpu);\n         xfree(d->xenoprof);\n         d->xenoprof = NULL;\n         return -ENOMEM;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "        xfree(d->xenoprof->vcpu);"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-7969",
        "func_name": "xen-project/xen/free_xenoprof_pages",
        "description": "Multiple memory leaks in Xen 4.0 through 4.6.x allow local guest administrators or domains with certain permission to cause a denial of service (memory consumption) via a large number of \"teardowns\" of domains with the vcpu pointer array allocated using the (1) XEN_DOMCTL_max_vcpus hypercall or the xenoprofile state vcpu pointer array allocated using the (2) XENOPROF_get_buffer or (3) XENOPROF_set_passive hypercall.",
        "git_url": "https://github.com/xen-project/xen/commit/6e97c4b37386c2d09e09e9b5d5d232e37728b960",
        "commit_title": "xenoprof: free domain's vcpu array",
        "commit_text": " This was overlooked in fb442e2171 (\"x86_64: allow more vCPU-s per guest\").  This is CVE-2015-7969 / XSA-151. ",
        "func_before": "void free_xenoprof_pages(struct domain *d)\n{\n    struct xenoprof *x;\n    int order;\n\n    x = d->xenoprof;\n    if ( x == NULL )\n        return;\n\n    if ( x->rawbuf != NULL )\n    {\n        order = get_order_from_pages(x->npages);\n        free_xenheap_pages(x->rawbuf, order);\n    }\n\n    xfree(x);\n    d->xenoprof = NULL;\n}",
        "func": "void free_xenoprof_pages(struct domain *d)\n{\n    struct xenoprof *x;\n    int order;\n\n    x = d->xenoprof;\n    if ( x == NULL )\n        return;\n\n    if ( x->rawbuf != NULL )\n    {\n        order = get_order_from_pages(x->npages);\n        free_xenheap_pages(x->rawbuf, order);\n    }\n\n    xfree(x->vcpu);\n    xfree(x);\n    d->xenoprof = NULL;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -13,6 +13,7 @@\n         free_xenheap_pages(x->rawbuf, order);\n     }\n \n+    xfree(x->vcpu);\n     xfree(x);\n     d->xenoprof = NULL;\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    xfree(x->vcpu);"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-7969",
        "func_name": "xen-project/xen/complete_domain_destroy",
        "description": "Multiple memory leaks in Xen 4.0 through 4.6.x allow local guest administrators or domains with certain permission to cause a denial of service (memory consumption) via a large number of \"teardowns\" of domains with the vcpu pointer array allocated using the (1) XEN_DOMCTL_max_vcpus hypercall or the xenoprofile state vcpu pointer array allocated using the (2) XENOPROF_get_buffer or (3) XENOPROF_set_passive hypercall.",
        "git_url": "https://github.com/xen-project/xen/commit/d46896ebbb23f3a9fef2eb6066ae614fd1acfd96",
        "commit_title": "free domain's vcpu array",
        "commit_text": " This was overlooked in fb442e2171 (\"x86_64: allow more vCPU-s per guest\").  This is CVE-2015-7969 / XSA-149. ",
        "func_before": "static void complete_domain_destroy(struct rcu_head *head)\n{\n    struct domain *d = container_of(head, struct domain, rcu);\n    struct vcpu *v;\n    int i;\n\n    for ( i = d->max_vcpus - 1; i >= 0; i-- )\n    {\n        if ( (v = d->vcpu[i]) == NULL )\n            continue;\n        tasklet_kill(&v->continue_hypercall_tasklet);\n        vcpu_destroy(v);\n        sched_destroy_vcpu(v);\n        destroy_waitqueue_vcpu(v);\n    }\n\n    grant_table_destroy(d);\n\n    arch_domain_destroy(d);\n\n    watchdog_domain_destroy(d);\n\n    rangeset_domain_destroy(d);\n\n    sched_destroy_domain(d);\n\n    /* Free page used by xen oprofile buffer. */\n#ifdef CONFIG_XENOPROF\n    free_xenoprof_pages(d);\n#endif\n\n    xfree(d->vm_event);\n    xfree(d->pbuf);\n\n    for ( i = d->max_vcpus - 1; i >= 0; i-- )\n        if ( (v = d->vcpu[i]) != NULL )\n        {\n            free_cpumask_var(v->cpu_hard_affinity);\n            free_cpumask_var(v->cpu_hard_affinity_tmp);\n            free_cpumask_var(v->cpu_hard_affinity_saved);\n            free_cpumask_var(v->cpu_soft_affinity);\n            free_cpumask_var(v->vcpu_dirty_cpumask);\n            free_vcpu_struct(v);\n        }\n\n    if ( d->target != NULL )\n        put_domain(d->target);\n\n    evtchn_destroy_final(d);\n\n    radix_tree_destroy(&d->pirq_tree, free_pirq_struct);\n\n    xsm_free_security_domain(d);\n    free_cpumask_var(d->domain_dirty_cpumask);\n    free_domain_struct(d);\n\n    send_global_virq(VIRQ_DOM_EXC);\n}",
        "func": "static void complete_domain_destroy(struct rcu_head *head)\n{\n    struct domain *d = container_of(head, struct domain, rcu);\n    struct vcpu *v;\n    int i;\n\n    for ( i = d->max_vcpus - 1; i >= 0; i-- )\n    {\n        if ( (v = d->vcpu[i]) == NULL )\n            continue;\n        tasklet_kill(&v->continue_hypercall_tasklet);\n        vcpu_destroy(v);\n        sched_destroy_vcpu(v);\n        destroy_waitqueue_vcpu(v);\n    }\n\n    grant_table_destroy(d);\n\n    arch_domain_destroy(d);\n\n    watchdog_domain_destroy(d);\n\n    rangeset_domain_destroy(d);\n\n    sched_destroy_domain(d);\n\n    /* Free page used by xen oprofile buffer. */\n#ifdef CONFIG_XENOPROF\n    free_xenoprof_pages(d);\n#endif\n\n    xfree(d->vm_event);\n    xfree(d->pbuf);\n\n    for ( i = d->max_vcpus - 1; i >= 0; i-- )\n        if ( (v = d->vcpu[i]) != NULL )\n        {\n            free_cpumask_var(v->cpu_hard_affinity);\n            free_cpumask_var(v->cpu_hard_affinity_tmp);\n            free_cpumask_var(v->cpu_hard_affinity_saved);\n            free_cpumask_var(v->cpu_soft_affinity);\n            free_cpumask_var(v->vcpu_dirty_cpumask);\n            free_vcpu_struct(v);\n        }\n\n    if ( d->target != NULL )\n        put_domain(d->target);\n\n    evtchn_destroy_final(d);\n\n    radix_tree_destroy(&d->pirq_tree, free_pirq_struct);\n\n    xsm_free_security_domain(d);\n    free_cpumask_var(d->domain_dirty_cpumask);\n    xfree(d->vcpu);\n    free_domain_struct(d);\n\n    send_global_virq(VIRQ_DOM_EXC);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -52,6 +52,7 @@\n \n     xsm_free_security_domain(d);\n     free_cpumask_var(d->domain_dirty_cpumask);\n+    xfree(d->vcpu);\n     free_domain_struct(d);\n \n     send_global_virq(VIRQ_DOM_EXC);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    xfree(d->vcpu);"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-7970",
        "func_name": "xen-project/xen/p2m_pod_emergency_sweep",
        "description": "The p2m_pod_emergency_sweep function in arch/x86/mm/p2m-pod.c in Xen 3.4.x, 3.5.x, and 3.6.x is not preemptible, which allows local x86 HVM guest administrators to cause a denial of service (CPU consumption and possibly reboot) via crafted memory contents that triggers a \"time-consuming linear scan,\" related to Populate-on-Demand.",
        "git_url": "https://github.com/xen-project/xen/commit/101ce53266866144e724ed593173bc4098b300b9",
        "commit_title": "x86/PoD: Eager sweep for zeroed pages",
        "commit_text": " Based on the contents of a guests physical address space, p2m_pod_emergency_sweep() could degrade into a linear memcmp() from 0 to max_gfn, which runs non-preemptibly.  As p2m_pod_emergency_sweep() runs behind the scenes in a number of contexts, making it preemptible is not feasible.  Instead, a different approach is taken.  Recently-populated pages are eagerly checked for reclaimation, which amortises the p2m_pod_emergency_sweep() operation across each p2m_pod_demand_populate() operation.  Note that in the case that a 2M superpage can't be reclaimed as a superpage, it is shattered if 4K pages of zeros can be reclaimed.  This is unfortunate but matches the previous behaviour, and is required to avoid regressions (domain crash from PoD exhaustion) with VMs configured close to the limit.  This is CVE-2015-7970 / XSA-150. ",
        "func_before": "static void\np2m_pod_emergency_sweep(struct p2m_domain *p2m)\n{\n    unsigned long gfns[POD_SWEEP_STRIDE];\n    unsigned long i, j=0, start, limit;\n    p2m_type_t t;\n\n\n    if ( p2m->pod.reclaim_single == 0 )\n        p2m->pod.reclaim_single = p2m->pod.max_guest;\n\n    start = p2m->pod.reclaim_single;\n    limit = (start > POD_SWEEP_LIMIT) ? (start - POD_SWEEP_LIMIT) : 0;\n\n    /* FIXME: Figure out how to avoid superpages */\n    /* NOTE: Promote to globally locking the p2m. This will get complicated\n     * in a fine-grained scenario. If we lock each gfn individually we must be\n     * careful about spinlock recursion limits and POD_SWEEP_STRIDE. */\n    p2m_lock(p2m);\n    for ( i=p2m->pod.reclaim_single; i > 0 ; i-- )\n    {\n        p2m_access_t a;\n        (void)p2m->get_entry(p2m, i, &t, &a, 0, NULL, NULL);\n        if ( p2m_is_ram(t) )\n        {\n            gfns[j] = i;\n            j++;\n            BUG_ON(j > POD_SWEEP_STRIDE);\n            if ( j == POD_SWEEP_STRIDE )\n            {\n                p2m_pod_zero_check(p2m, gfns, j);\n                j = 0;\n            }\n        }\n        /* Stop if we're past our limit and we have found *something*.\n         *\n         * NB that this is a zero-sum game; we're increasing our cache size\n         * by re-increasing our 'debt'.  Since we hold the pod lock,\n         * (entry_count - count) must remain the same. */\n        if ( p2m->pod.count > 0 && i < limit )\n            break;\n    }\n\n    if ( j )\n        p2m_pod_zero_check(p2m, gfns, j);\n\n    p2m_unlock(p2m);\n    p2m->pod.reclaim_single = i ? i - 1 : i;\n\n}",
        "func": "static void\np2m_pod_emergency_sweep(struct p2m_domain *p2m)\n{\n    unsigned long gfns[POD_SWEEP_STRIDE];\n    unsigned long i, j=0, start, limit;\n    p2m_type_t t;\n\n\n    if ( p2m->pod.reclaim_single == 0 )\n        p2m->pod.reclaim_single = p2m->pod.max_guest;\n\n    start = p2m->pod.reclaim_single;\n    limit = (start > POD_SWEEP_LIMIT) ? (start - POD_SWEEP_LIMIT) : 0;\n\n    /* FIXME: Figure out how to avoid superpages */\n    /* NOTE: Promote to globally locking the p2m. This will get complicated\n     * in a fine-grained scenario. If we lock each gfn individually we must be\n     * careful about spinlock recursion limits and POD_SWEEP_STRIDE. */\n    p2m_lock(p2m);\n    for ( i=p2m->pod.reclaim_single; i > 0 ; i-- )\n    {\n        p2m_access_t a;\n        (void)p2m->get_entry(p2m, i, &t, &a, 0, NULL, NULL);\n        if ( p2m_is_ram(t) )\n        {\n            gfns[j] = i;\n            j++;\n            BUG_ON(j > POD_SWEEP_STRIDE);\n            if ( j == POD_SWEEP_STRIDE )\n            {\n                p2m_pod_zero_check(p2m, gfns, j);\n                j = 0;\n            }\n        }\n        /* Stop if we're past our limit and we have found *something*.\n         *\n         * NB that this is a zero-sum game; we're increasing our cache size\n         * by re-increasing our 'debt'.  Since we hold the pod lock,\n         * (entry_count - count) must remain the same. */\n        if ( i < limit && (p2m->pod.count > 0 || hypercall_preempt_check()) )\n            break;\n    }\n\n    if ( j )\n        p2m_pod_zero_check(p2m, gfns, j);\n\n    p2m_unlock(p2m);\n    p2m->pod.reclaim_single = i ? i - 1 : i;\n\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -37,7 +37,7 @@\n          * NB that this is a zero-sum game; we're increasing our cache size\n          * by re-increasing our 'debt'.  Since we hold the pod lock,\n          * (entry_count - count) must remain the same. */\n-        if ( p2m->pod.count > 0 && i < limit )\n+        if ( i < limit && (p2m->pod.count > 0 || hypercall_preempt_check()) )\n             break;\n     }\n ",
        "diff_line_info": {
            "deleted_lines": [
                "        if ( p2m->pod.count > 0 && i < limit )"
            ],
            "added_lines": [
                "        if ( i < limit && (p2m->pod.count > 0 || hypercall_preempt_check()) )"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-7970",
        "func_name": "xen-project/xen/p2m_pod_demand_populate",
        "description": "The p2m_pod_emergency_sweep function in arch/x86/mm/p2m-pod.c in Xen 3.4.x, 3.5.x, and 3.6.x is not preemptible, which allows local x86 HVM guest administrators to cause a denial of service (CPU consumption and possibly reboot) via crafted memory contents that triggers a \"time-consuming linear scan,\" related to Populate-on-Demand.",
        "git_url": "https://github.com/xen-project/xen/commit/101ce53266866144e724ed593173bc4098b300b9",
        "commit_title": "x86/PoD: Eager sweep for zeroed pages",
        "commit_text": " Based on the contents of a guests physical address space, p2m_pod_emergency_sweep() could degrade into a linear memcmp() from 0 to max_gfn, which runs non-preemptibly.  As p2m_pod_emergency_sweep() runs behind the scenes in a number of contexts, making it preemptible is not feasible.  Instead, a different approach is taken.  Recently-populated pages are eagerly checked for reclaimation, which amortises the p2m_pod_emergency_sweep() operation across each p2m_pod_demand_populate() operation.  Note that in the case that a 2M superpage can't be reclaimed as a superpage, it is shattered if 4K pages of zeros can be reclaimed.  This is unfortunate but matches the previous behaviour, and is required to avoid regressions (domain crash from PoD exhaustion) with VMs configured close to the limit.  This is CVE-2015-7970 / XSA-150. ",
        "func_before": "int\np2m_pod_demand_populate(struct p2m_domain *p2m, unsigned long gfn,\n                        unsigned int order,\n                        p2m_query_t q)\n{\n    struct domain *d = p2m->domain;\n    struct page_info *p = NULL; /* Compiler warnings */\n    unsigned long gfn_aligned;\n    mfn_t mfn;\n    int i;\n\n    ASSERT(gfn_locked_by_me(p2m, gfn));\n    pod_lock(p2m);\n\n    /* This check is done with the pod lock held.  This will make sure that\n     * even if d->is_dying changes under our feet, p2m_pod_empty_cache() \n     * won't start until we're done. */\n    if ( unlikely(d->is_dying) )\n        goto out_fail;\n\n    \n    /* Because PoD does not have cache list for 1GB pages, it has to remap\n     * 1GB region to 2MB chunks for a retry. */\n    if ( order == PAGE_ORDER_1G )\n    {\n        pod_unlock(p2m);\n        gfn_aligned = (gfn >> order) << order;\n        /* Note that we are supposed to call p2m_set_entry() 512 times to\n         * split 1GB into 512 2MB pages here. But We only do once here because\n         * p2m_set_entry() should automatically shatter the 1GB page into\n         * 512 2MB pages. The rest of 511 calls are unnecessary.\n         *\n         * NOTE: In a fine-grained p2m locking scenario this operation\n         * may need to promote its locking from gfn->1g superpage\n         */\n        p2m_set_entry(p2m, gfn_aligned, _mfn(0), PAGE_ORDER_2M,\n                      p2m_populate_on_demand, p2m->default_access);\n        return 0;\n    }\n\n    /* Only sweep if we're actually out of memory.  Doing anything else\n     * causes unnecessary time and fragmentation of superpages in the p2m. */\n    if ( p2m->pod.count == 0 )\n        p2m_pod_emergency_sweep(p2m);\n\n    /* If the sweep failed, give up. */\n    if ( p2m->pod.count == 0 )\n        goto out_of_memory;\n\n    /* Keep track of the highest gfn demand-populated by a guest fault */\n    if ( gfn > p2m->pod.max_guest )\n        p2m->pod.max_guest = gfn;\n\n    /* Get a page f/ the cache.  A NULL return value indicates that the\n     * 2-meg range should be marked singleton PoD, and retried */\n    if ( (p = p2m_pod_cache_get(p2m, order)) == NULL )\n        goto remap_and_retry;\n\n    mfn = page_to_mfn(p);\n\n    BUG_ON((mfn_x(mfn) & ((1 << order)-1)) != 0);\n\n    gfn_aligned = (gfn >> order) << order;\n\n    p2m_set_entry(p2m, gfn_aligned, mfn, order, p2m_ram_rw,\n                  p2m->default_access);\n\n    for( i = 0; i < (1UL << order); i++ )\n    {\n        set_gpfn_from_mfn(mfn_x(mfn) + i, gfn_aligned + i);\n        paging_mark_dirty(d, mfn_x(mfn) + i);\n    }\n    \n    p2m->pod.entry_count -= (1 << order);\n    BUG_ON(p2m->pod.entry_count < 0);\n\n    if ( tb_init_done )\n    {\n        struct {\n            u64 gfn, mfn;\n            int d:16,order:16;\n        } t;\n\n        t.gfn = gfn;\n        t.mfn = mfn_x(mfn);\n        t.d = d->domain_id;\n        t.order = order;\n        \n        __trace_var(TRC_MEM_POD_POPULATE, 0, sizeof(t), &t);\n    }\n\n    /* Check the last guest demand-populate */\n    if ( p2m->pod.entry_count > p2m->pod.count \n         && (order == PAGE_ORDER_2M)\n         && (q & P2M_ALLOC) )\n        p2m_pod_check_last_super(p2m, gfn_aligned);\n\n    pod_unlock(p2m);\n    return 0;\nout_of_memory:\n    pod_unlock(p2m);\n\n    printk(\"%s: Dom%d out of PoD memory! (tot=%\"PRIu32\" ents=%ld dom%d)\\n\",\n           __func__, d->domain_id, d->tot_pages, p2m->pod.entry_count,\n           current->domain->domain_id);\n    domain_crash(d);\n    return -1;\nout_fail:\n    pod_unlock(p2m);\n    return -1;\nremap_and_retry:\n    BUG_ON(order != PAGE_ORDER_2M);\n    pod_unlock(p2m);\n\n    /* Remap this 2-meg region in singleton chunks */\n    /* NOTE: In a p2m fine-grained lock scenario this might\n     * need promoting the gfn lock from gfn->2M superpage */\n    gfn_aligned = (gfn>>order)<<order;\n    for(i=0; i<(1<<order); i++)\n        p2m_set_entry(p2m, gfn_aligned+i, _mfn(0), PAGE_ORDER_4K,\n                      p2m_populate_on_demand, p2m->default_access);\n    if ( tb_init_done )\n    {\n        struct {\n            u64 gfn;\n            int d:16;\n        } t;\n\n        t.gfn = gfn;\n        t.d = d->domain_id;\n        \n        __trace_var(TRC_MEM_POD_SUPERPAGE_SPLINTER, 0, sizeof(t), &t);\n    }\n\n    return 0;\n}",
        "func": "int\np2m_pod_demand_populate(struct p2m_domain *p2m, unsigned long gfn,\n                        unsigned int order,\n                        p2m_query_t q)\n{\n    struct domain *d = p2m->domain;\n    struct page_info *p = NULL; /* Compiler warnings */\n    unsigned long gfn_aligned;\n    mfn_t mfn;\n    int i;\n\n    ASSERT(gfn_locked_by_me(p2m, gfn));\n    pod_lock(p2m);\n\n    /* This check is done with the pod lock held.  This will make sure that\n     * even if d->is_dying changes under our feet, p2m_pod_empty_cache() \n     * won't start until we're done. */\n    if ( unlikely(d->is_dying) )\n        goto out_fail;\n\n    \n    /* Because PoD does not have cache list for 1GB pages, it has to remap\n     * 1GB region to 2MB chunks for a retry. */\n    if ( order == PAGE_ORDER_1G )\n    {\n        pod_unlock(p2m);\n        gfn_aligned = (gfn >> order) << order;\n        /* Note that we are supposed to call p2m_set_entry() 512 times to\n         * split 1GB into 512 2MB pages here. But We only do once here because\n         * p2m_set_entry() should automatically shatter the 1GB page into\n         * 512 2MB pages. The rest of 511 calls are unnecessary.\n         *\n         * NOTE: In a fine-grained p2m locking scenario this operation\n         * may need to promote its locking from gfn->1g superpage\n         */\n        p2m_set_entry(p2m, gfn_aligned, _mfn(0), PAGE_ORDER_2M,\n                      p2m_populate_on_demand, p2m->default_access);\n        return 0;\n    }\n\n    pod_eager_reclaim(p2m);\n\n    /* Only sweep if we're actually out of memory.  Doing anything else\n     * causes unnecessary time and fragmentation of superpages in the p2m. */\n    if ( p2m->pod.count == 0 )\n        p2m_pod_emergency_sweep(p2m);\n\n    /* If the sweep failed, give up. */\n    if ( p2m->pod.count == 0 )\n        goto out_of_memory;\n\n    /* Keep track of the highest gfn demand-populated by a guest fault */\n    if ( gfn > p2m->pod.max_guest )\n        p2m->pod.max_guest = gfn;\n\n    /* Get a page f/ the cache.  A NULL return value indicates that the\n     * 2-meg range should be marked singleton PoD, and retried */\n    if ( (p = p2m_pod_cache_get(p2m, order)) == NULL )\n        goto remap_and_retry;\n\n    mfn = page_to_mfn(p);\n\n    BUG_ON((mfn_x(mfn) & ((1 << order)-1)) != 0);\n\n    gfn_aligned = (gfn >> order) << order;\n\n    p2m_set_entry(p2m, gfn_aligned, mfn, order, p2m_ram_rw,\n                  p2m->default_access);\n\n    for( i = 0; i < (1UL << order); i++ )\n    {\n        set_gpfn_from_mfn(mfn_x(mfn) + i, gfn_aligned + i);\n        paging_mark_dirty(d, mfn_x(mfn) + i);\n    }\n    \n    p2m->pod.entry_count -= (1 << order);\n    BUG_ON(p2m->pod.entry_count < 0);\n\n    pod_eager_record(p2m, gfn_aligned, order);\n\n    if ( tb_init_done )\n    {\n        struct {\n            u64 gfn, mfn;\n            int d:16,order:16;\n        } t;\n\n        t.gfn = gfn;\n        t.mfn = mfn_x(mfn);\n        t.d = d->domain_id;\n        t.order = order;\n        \n        __trace_var(TRC_MEM_POD_POPULATE, 0, sizeof(t), &t);\n    }\n\n    pod_unlock(p2m);\n    return 0;\nout_of_memory:\n    pod_unlock(p2m);\n\n    printk(\"%s: Dom%d out of PoD memory! (tot=%\"PRIu32\" ents=%ld dom%d)\\n\",\n           __func__, d->domain_id, d->tot_pages, p2m->pod.entry_count,\n           current->domain->domain_id);\n    domain_crash(d);\n    return -1;\nout_fail:\n    pod_unlock(p2m);\n    return -1;\nremap_and_retry:\n    BUG_ON(order != PAGE_ORDER_2M);\n    pod_unlock(p2m);\n\n    /* Remap this 2-meg region in singleton chunks */\n    /* NOTE: In a p2m fine-grained lock scenario this might\n     * need promoting the gfn lock from gfn->2M superpage */\n    gfn_aligned = (gfn>>order)<<order;\n    for(i=0; i<(1<<order); i++)\n        p2m_set_entry(p2m, gfn_aligned+i, _mfn(0), PAGE_ORDER_4K,\n                      p2m_populate_on_demand, p2m->default_access);\n    if ( tb_init_done )\n    {\n        struct {\n            u64 gfn;\n            int d:16;\n        } t;\n\n        t.gfn = gfn;\n        t.d = d->domain_id;\n        \n        __trace_var(TRC_MEM_POD_SUPERPAGE_SPLINTER, 0, sizeof(t), &t);\n    }\n\n    return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -38,6 +38,8 @@\n         return 0;\n     }\n \n+    pod_eager_reclaim(p2m);\n+\n     /* Only sweep if we're actually out of memory.  Doing anything else\n      * causes unnecessary time and fragmentation of superpages in the p2m. */\n     if ( p2m->pod.count == 0 )\n@@ -74,6 +76,8 @@\n     p2m->pod.entry_count -= (1 << order);\n     BUG_ON(p2m->pod.entry_count < 0);\n \n+    pod_eager_record(p2m, gfn_aligned, order);\n+\n     if ( tb_init_done )\n     {\n         struct {\n@@ -88,12 +92,6 @@\n         \n         __trace_var(TRC_MEM_POD_POPULATE, 0, sizeof(t), &t);\n     }\n-\n-    /* Check the last guest demand-populate */\n-    if ( p2m->pod.entry_count > p2m->pod.count \n-         && (order == PAGE_ORDER_2M)\n-         && (q & P2M_ALLOC) )\n-        p2m_pod_check_last_super(p2m, gfn_aligned);\n \n     pod_unlock(p2m);\n     return 0;",
        "diff_line_info": {
            "deleted_lines": [
                "",
                "    /* Check the last guest demand-populate */",
                "    if ( p2m->pod.entry_count > p2m->pod.count ",
                "         && (order == PAGE_ORDER_2M)",
                "         && (q & P2M_ALLOC) )",
                "        p2m_pod_check_last_super(p2m, gfn_aligned);"
            ],
            "added_lines": [
                "    pod_eager_reclaim(p2m);",
                "",
                "    pod_eager_record(p2m, gfn_aligned, order);",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2015-7970",
        "func_name": "xen-project/xen/p2m_initialise",
        "description": "The p2m_pod_emergency_sweep function in arch/x86/mm/p2m-pod.c in Xen 3.4.x, 3.5.x, and 3.6.x is not preemptible, which allows local x86 HVM guest administrators to cause a denial of service (CPU consumption and possibly reboot) via crafted memory contents that triggers a \"time-consuming linear scan,\" related to Populate-on-Demand.",
        "git_url": "https://github.com/xen-project/xen/commit/101ce53266866144e724ed593173bc4098b300b9",
        "commit_title": "x86/PoD: Eager sweep for zeroed pages",
        "commit_text": " Based on the contents of a guests physical address space, p2m_pod_emergency_sweep() could degrade into a linear memcmp() from 0 to max_gfn, which runs non-preemptibly.  As p2m_pod_emergency_sweep() runs behind the scenes in a number of contexts, making it preemptible is not feasible.  Instead, a different approach is taken.  Recently-populated pages are eagerly checked for reclaimation, which amortises the p2m_pod_emergency_sweep() operation across each p2m_pod_demand_populate() operation.  Note that in the case that a 2M superpage can't be reclaimed as a superpage, it is shattered if 4K pages of zeros can be reclaimed.  This is unfortunate but matches the previous behaviour, and is required to avoid regressions (domain crash from PoD exhaustion) with VMs configured close to the limit.  This is CVE-2015-7970 / XSA-150. ",
        "func_before": "static int p2m_initialise(struct domain *d, struct p2m_domain *p2m)\n{\n    int ret = 0;\n\n    mm_rwlock_init(&p2m->lock);\n    mm_lock_init(&p2m->pod.lock);\n    INIT_LIST_HEAD(&p2m->np2m_list);\n    INIT_PAGE_LIST_HEAD(&p2m->pages);\n    INIT_PAGE_LIST_HEAD(&p2m->pod.super);\n    INIT_PAGE_LIST_HEAD(&p2m->pod.single);\n\n    p2m->domain = d;\n    p2m->default_access = p2m_access_rwx;\n    p2m->p2m_class = p2m_host;\n\n    p2m->np2m_base = P2M_BASE_EADDR;\n\n    if ( hap_enabled(d) && cpu_has_vmx )\n        ret = ept_p2m_init(p2m);\n    else\n        p2m_pt_init(p2m);\n\n    return ret;\n}",
        "func": "static int p2m_initialise(struct domain *d, struct p2m_domain *p2m)\n{\n    unsigned int i;\n    int ret = 0;\n\n    mm_rwlock_init(&p2m->lock);\n    mm_lock_init(&p2m->pod.lock);\n    INIT_LIST_HEAD(&p2m->np2m_list);\n    INIT_PAGE_LIST_HEAD(&p2m->pages);\n    INIT_PAGE_LIST_HEAD(&p2m->pod.super);\n    INIT_PAGE_LIST_HEAD(&p2m->pod.single);\n\n    p2m->domain = d;\n    p2m->default_access = p2m_access_rwx;\n    p2m->p2m_class = p2m_host;\n\n    p2m->np2m_base = P2M_BASE_EADDR;\n\n    for ( i = 0; i < ARRAY_SIZE(p2m->pod.mrp.list); ++i )\n        p2m->pod.mrp.list[i] = INVALID_GFN;\n\n    if ( hap_enabled(d) && cpu_has_vmx )\n        ret = ept_p2m_init(p2m);\n    else\n        p2m_pt_init(p2m);\n\n    return ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,6 @@\n static int p2m_initialise(struct domain *d, struct p2m_domain *p2m)\n {\n+    unsigned int i;\n     int ret = 0;\n \n     mm_rwlock_init(&p2m->lock);\n@@ -15,6 +16,9 @@\n \n     p2m->np2m_base = P2M_BASE_EADDR;\n \n+    for ( i = 0; i < ARRAY_SIZE(p2m->pod.mrp.list); ++i )\n+        p2m->pod.mrp.list[i] = INVALID_GFN;\n+\n     if ( hap_enabled(d) && cpu_has_vmx )\n         ret = ept_p2m_init(p2m);\n     else",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    unsigned int i;",
                "    for ( i = 0; i < ARRAY_SIZE(p2m->pod.mrp.list); ++i )",
                "        p2m->pod.mrp.list[i] = INVALID_GFN;",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2015-7972",
        "func_name": "xen-project/xen/libxl__build_post",
        "description": "The (1) libxl_set_memory_target function in tools/libxl/libxl.c and (2) libxl__build_post function in tools/libxl/libxl_dom.c in Xen 3.4.x through 4.6.x do not properly calculate the balloon size when using the populate-on-demand (PoD) system, which allows local HVM guest users to cause a denial of service (guest crash) via unspecified vectors related to \"heavy memory pressure.\"",
        "git_url": "https://github.com/xen-project/xen/commit/e294a0c3af9f4443dc692b180fb1771b1cb075e8",
        "commit_title": "libxl: adjust PoD target by memory fudge, too",
        "commit_text": " PoD guests need to balloon at least as far as required by PoD, or risk crashing.  Currently they don't necessarily know what the right value is, because our memory accounting is (at the very least) confusing.  Apply the memory limit fudge factor to the in-hypervisor PoD memory target, too.  This will increase the size of the guest's PoD cache by the fudge factor LIBXL_MAXMEM_CONSTANT (currently 1Mby).  This ensures that even with a slightly-off balloon driver, the guest will be stable even under memory pressure.  There are two call sites of xc_domain_set_pod_target that need fixing:  The one in libxl_set_memory_target is straightforward.  The one in xc_hvm_build_x86.c:setup_guest is more awkward.  Simply setting the PoD target differently does not work because the various amounts of memory during domain construction no longer match up. Instead, we adjust the guest memory target in xenstore (but only for PoD guests).  This introduces a 1Mby discrepancy between the balloon target of a PoD guest at boot, and the target set by an apparently-equivalent `xl mem-set' (or similar) later.  This approach is low-risk for a security fix but we need to fix this up properly in xen.git#staging and probably also in stable trees.  This is XSA-153.  (cherry picked from commit 56fb5fd62320eb40a7517206f9706aa9188d6f7b)",
        "func_before": "int libxl__build_post(libxl__gc *gc, uint32_t domid,\n                      libxl_domain_build_info *info,\n                      libxl__domain_build_state *state,\n                      char **vms_ents, char **local_ents)\n{\n    libxl_ctx *ctx = libxl__gc_owner(gc);\n    char *dom_path, *vm_path;\n    xs_transaction_t t;\n    char **ents;\n    int i, rc;\n\n    if (info->num_vnuma_nodes && !info->num_vcpu_soft_affinity) {\n        rc = set_vnuma_affinity(gc, domid, info);\n        if (rc)\n            return rc;\n    }\n\n    rc = libxl_domain_sched_params_set(CTX, domid, &info->sched_params);\n    if (rc)\n        return rc;\n\n    rc = xc_domain_set_max_evtchn(ctx->xch, domid, info->event_channels);\n    if (rc) {\n        LOG(ERROR, \"Failed to set event channel limit to %d (%d)\",\n            info->event_channels, rc);\n        return ERROR_FAIL;\n    }\n\n    libxl_cpuid_apply_policy(ctx, domid);\n    if (info->cpuid != NULL)\n        libxl_cpuid_set(ctx, domid, info->cpuid);\n\n    if (info->type == LIBXL_DOMAIN_TYPE_HVM\n        && !libxl_ms_vm_genid_is_zero(&info->u.hvm.ms_vm_genid)) {\n        rc = libxl__ms_vm_genid_set(gc, domid,\n                                    &info->u.hvm.ms_vm_genid);\n        if (rc) {\n            LOG(ERROR, \"Failed to set VM Generation ID\");\n            return rc;\n        }\n    }\n\n    ents = libxl__calloc(gc, 12 + (info->max_vcpus * 2) + 2, sizeof(char *));\n    ents[0] = \"memory/static-max\";\n    ents[1] = GCSPRINTF(\"%\"PRId64, info->max_memkb);\n    ents[2] = \"memory/target\";\n    ents[3] = GCSPRINTF(\"%\"PRId64, info->target_memkb - info->video_memkb);\n    ents[4] = \"memory/videoram\";\n    ents[5] = GCSPRINTF(\"%\"PRId64, info->video_memkb);\n    ents[6] = \"domid\";\n    ents[7] = GCSPRINTF(\"%d\", domid);\n    ents[8] = \"store/port\";\n    ents[9] = GCSPRINTF(\"%\"PRIu32, state->store_port);\n    ents[10] = \"store/ring-ref\";\n    ents[11] = GCSPRINTF(\"%lu\", state->store_mfn);\n    for (i = 0; i < info->max_vcpus; i++) {\n        ents[12+(i*2)]   = GCSPRINTF(\"cpu/%d/availability\", i);\n        ents[12+(i*2)+1] = libxl_bitmap_test(&info->avail_vcpus, i)\n                            ? \"online\" : \"offline\";\n    }\n\n    dom_path = libxl__xs_get_dompath(gc, domid);\n    if (!dom_path) {\n        return ERROR_FAIL;\n    }\n\n    vm_path = xs_read(ctx->xsh, XBT_NULL, GCSPRINTF(\"%s/vm\", dom_path), NULL);\nretry_transaction:\n    t = xs_transaction_start(ctx->xsh);\n\n    libxl__xs_writev(gc, t, dom_path, ents);\n    libxl__xs_writev(gc, t, dom_path, local_ents);\n    libxl__xs_writev(gc, t, vm_path, vms_ents);\n\n    if (!xs_transaction_end(ctx->xsh, t, 0))\n        if (errno == EAGAIN)\n            goto retry_transaction;\n    xs_introduce_domain(ctx->xsh, domid, state->store_mfn, state->store_port);\n    free(vm_path);\n    return 0;\n}",
        "func": "int libxl__build_post(libxl__gc *gc, uint32_t domid,\n                      libxl_domain_build_info *info,\n                      libxl__domain_build_state *state,\n                      char **vms_ents, char **local_ents)\n{\n    libxl_ctx *ctx = libxl__gc_owner(gc);\n    char *dom_path, *vm_path;\n    xs_transaction_t t;\n    char **ents;\n    int i, rc;\n    int64_t mem_target_fudge;\n\n    if (info->num_vnuma_nodes && !info->num_vcpu_soft_affinity) {\n        rc = set_vnuma_affinity(gc, domid, info);\n        if (rc)\n            return rc;\n    }\n\n    rc = libxl_domain_sched_params_set(CTX, domid, &info->sched_params);\n    if (rc)\n        return rc;\n\n    rc = xc_domain_set_max_evtchn(ctx->xch, domid, info->event_channels);\n    if (rc) {\n        LOG(ERROR, \"Failed to set event channel limit to %d (%d)\",\n            info->event_channels, rc);\n        return ERROR_FAIL;\n    }\n\n    libxl_cpuid_apply_policy(ctx, domid);\n    if (info->cpuid != NULL)\n        libxl_cpuid_set(ctx, domid, info->cpuid);\n\n    if (info->type == LIBXL_DOMAIN_TYPE_HVM\n        && !libxl_ms_vm_genid_is_zero(&info->u.hvm.ms_vm_genid)) {\n        rc = libxl__ms_vm_genid_set(gc, domid,\n                                    &info->u.hvm.ms_vm_genid);\n        if (rc) {\n            LOG(ERROR, \"Failed to set VM Generation ID\");\n            return rc;\n        }\n    }\n\n    mem_target_fudge =\n        (info->type == LIBXL_DOMAIN_TYPE_HVM &&\n         info->max_memkb > info->target_memkb)\n        ? LIBXL_MAXMEM_CONSTANT : 0;\n\n    ents = libxl__calloc(gc, 12 + (info->max_vcpus * 2) + 2, sizeof(char *));\n    ents[0] = \"memory/static-max\";\n    ents[1] = GCSPRINTF(\"%\"PRId64, info->max_memkb);\n    ents[2] = \"memory/target\";\n    ents[3] = GCSPRINTF(\"%\"PRId64, info->target_memkb - info->video_memkb\n                        - mem_target_fudge);\n    ents[4] = \"memory/videoram\";\n    ents[5] = GCSPRINTF(\"%\"PRId64, info->video_memkb);\n    ents[6] = \"domid\";\n    ents[7] = GCSPRINTF(\"%d\", domid);\n    ents[8] = \"store/port\";\n    ents[9] = GCSPRINTF(\"%\"PRIu32, state->store_port);\n    ents[10] = \"store/ring-ref\";\n    ents[11] = GCSPRINTF(\"%lu\", state->store_mfn);\n    for (i = 0; i < info->max_vcpus; i++) {\n        ents[12+(i*2)]   = GCSPRINTF(\"cpu/%d/availability\", i);\n        ents[12+(i*2)+1] = libxl_bitmap_test(&info->avail_vcpus, i)\n                            ? \"online\" : \"offline\";\n    }\n\n    dom_path = libxl__xs_get_dompath(gc, domid);\n    if (!dom_path) {\n        return ERROR_FAIL;\n    }\n\n    vm_path = xs_read(ctx->xsh, XBT_NULL, GCSPRINTF(\"%s/vm\", dom_path), NULL);\nretry_transaction:\n    t = xs_transaction_start(ctx->xsh);\n\n    libxl__xs_writev(gc, t, dom_path, ents);\n    libxl__xs_writev(gc, t, dom_path, local_ents);\n    libxl__xs_writev(gc, t, vm_path, vms_ents);\n\n    if (!xs_transaction_end(ctx->xsh, t, 0))\n        if (errno == EAGAIN)\n            goto retry_transaction;\n    xs_introduce_domain(ctx->xsh, domid, state->store_mfn, state->store_port);\n    free(vm_path);\n    return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -8,6 +8,7 @@\n     xs_transaction_t t;\n     char **ents;\n     int i, rc;\n+    int64_t mem_target_fudge;\n \n     if (info->num_vnuma_nodes && !info->num_vcpu_soft_affinity) {\n         rc = set_vnuma_affinity(gc, domid, info);\n@@ -40,11 +41,17 @@\n         }\n     }\n \n+    mem_target_fudge =\n+        (info->type == LIBXL_DOMAIN_TYPE_HVM &&\n+         info->max_memkb > info->target_memkb)\n+        ? LIBXL_MAXMEM_CONSTANT : 0;\n+\n     ents = libxl__calloc(gc, 12 + (info->max_vcpus * 2) + 2, sizeof(char *));\n     ents[0] = \"memory/static-max\";\n     ents[1] = GCSPRINTF(\"%\"PRId64, info->max_memkb);\n     ents[2] = \"memory/target\";\n-    ents[3] = GCSPRINTF(\"%\"PRId64, info->target_memkb - info->video_memkb);\n+    ents[3] = GCSPRINTF(\"%\"PRId64, info->target_memkb - info->video_memkb\n+                        - mem_target_fudge);\n     ents[4] = \"memory/videoram\";\n     ents[5] = GCSPRINTF(\"%\"PRId64, info->video_memkb);\n     ents[6] = \"domid\";",
        "diff_line_info": {
            "deleted_lines": [
                "    ents[3] = GCSPRINTF(\"%\"PRId64, info->target_memkb - info->video_memkb);"
            ],
            "added_lines": [
                "    int64_t mem_target_fudge;",
                "    mem_target_fudge =",
                "        (info->type == LIBXL_DOMAIN_TYPE_HVM &&",
                "         info->max_memkb > info->target_memkb)",
                "        ? LIBXL_MAXMEM_CONSTANT : 0;",
                "",
                "    ents[3] = GCSPRINTF(\"%\"PRId64, info->target_memkb - info->video_memkb",
                "                        - mem_target_fudge);"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-7972",
        "func_name": "xen-project/xen/libxl_set_memory_target",
        "description": "The (1) libxl_set_memory_target function in tools/libxl/libxl.c and (2) libxl__build_post function in tools/libxl/libxl_dom.c in Xen 3.4.x through 4.6.x do not properly calculate the balloon size when using the populate-on-demand (PoD) system, which allows local HVM guest users to cause a denial of service (guest crash) via unspecified vectors related to \"heavy memory pressure.\"",
        "git_url": "https://github.com/xen-project/xen/commit/e294a0c3af9f4443dc692b180fb1771b1cb075e8",
        "commit_title": "libxl: adjust PoD target by memory fudge, too",
        "commit_text": " PoD guests need to balloon at least as far as required by PoD, or risk crashing.  Currently they don't necessarily know what the right value is, because our memory accounting is (at the very least) confusing.  Apply the memory limit fudge factor to the in-hypervisor PoD memory target, too.  This will increase the size of the guest's PoD cache by the fudge factor LIBXL_MAXMEM_CONSTANT (currently 1Mby).  This ensures that even with a slightly-off balloon driver, the guest will be stable even under memory pressure.  There are two call sites of xc_domain_set_pod_target that need fixing:  The one in libxl_set_memory_target is straightforward.  The one in xc_hvm_build_x86.c:setup_guest is more awkward.  Simply setting the PoD target differently does not work because the various amounts of memory during domain construction no longer match up. Instead, we adjust the guest memory target in xenstore (but only for PoD guests).  This introduces a 1Mby discrepancy between the balloon target of a PoD guest at boot, and the target set by an apparently-equivalent `xl mem-set' (or similar) later.  This approach is low-risk for a security fix but we need to fix this up properly in xen.git#staging and probably also in stable trees.  This is XSA-153.  (cherry picked from commit 56fb5fd62320eb40a7517206f9706aa9188d6f7b)",
        "func_before": "int libxl_set_memory_target(libxl_ctx *ctx, uint32_t domid,\n        int32_t target_memkb, int relative, int enforce)\n{\n    GC_INIT(ctx);\n    int rc = 1, abort_transaction = 0;\n    uint64_t memorykb;\n    uint32_t videoram = 0;\n    uint32_t current_target_memkb = 0, new_target_memkb = 0;\n    uint32_t current_max_memkb = 0;\n    char *memmax, *endptr, *videoram_s = NULL, *target = NULL;\n    char *dompath = libxl__xs_get_dompath(gc, domid);\n    xc_domaininfo_t info;\n    libxl_dominfo ptr;\n    char *uuid;\n    xs_transaction_t t;\n    libxl__domain_userdata_lock *lock;\n\n    CTX_LOCK;\n\n    lock = libxl__lock_domain_userdata(gc, domid);\n    if (!lock) {\n        rc = ERROR_LOCK_FAIL;\n        goto out_no_transaction;\n    }\n\nretry_transaction:\n    t = xs_transaction_start(ctx->xsh);\n\n    target = libxl__xs_read(gc, t, libxl__sprintf(gc,\n                \"%s/memory/target\", dompath));\n    if (!target && !domid) {\n        if (!xs_transaction_end(ctx->xsh, t, 1))\n            goto out_no_transaction;\n        rc = libxl__fill_dom0_memory_info(gc, &current_target_memkb,\n                                          &current_max_memkb);\n        if (rc < 0)\n            goto out_no_transaction;\n        goto retry_transaction;\n    } else if (!target) {\n        LOGE(ERROR, \"cannot get target memory info from %s/memory/target\",\n             dompath);\n        abort_transaction = 1;\n        goto out;\n    } else {\n        current_target_memkb = strtoul(target, &endptr, 10);\n        if (*endptr != '\\0') {\n            LOGE(ERROR, \"invalid memory target %s from %s/memory/target\\n\",\n                 target, dompath);\n            abort_transaction = 1;\n            goto out;\n        }\n    }\n    memmax = libxl__xs_read(gc, t, libxl__sprintf(gc,\n                \"%s/memory/static-max\", dompath));\n    if (!memmax) {\n        LOGE(ERROR, \"cannot get memory info from %s/memory/static-max\",\n             dompath);\n        abort_transaction = 1;\n        goto out;\n    }\n    memorykb = strtoul(memmax, &endptr, 10);\n    if (*endptr != '\\0') {\n        LOGE(ERROR, \"invalid max memory %s from %s/memory/static-max\\n\",\n             memmax, dompath);\n        abort_transaction = 1;\n        goto out;\n    }\n\n    videoram_s = libxl__xs_read(gc, t, libxl__sprintf(gc,\n                \"%s/memory/videoram\", dompath));\n    videoram = videoram_s ? atoi(videoram_s) : 0;\n\n    if (relative) {\n        if (target_memkb < 0 && abs(target_memkb) > current_target_memkb)\n            new_target_memkb = 0;\n        else\n            new_target_memkb = current_target_memkb + target_memkb;\n    } else\n        new_target_memkb = target_memkb - videoram;\n    if (new_target_memkb > memorykb) {\n        LOG(ERROR,\n            \"memory_dynamic_max must be less than or equal to\"\n            \" memory_static_max\\n\");\n        abort_transaction = 1;\n        goto out;\n    }\n\n    if (!domid && new_target_memkb < LIBXL_MIN_DOM0_MEM) {\n        LOG(ERROR, \"new target %d for dom0 is below the minimum threshold\",\n            new_target_memkb);\n        abort_transaction = 1;\n        goto out;\n    }\n\n    if (enforce) {\n        memorykb = new_target_memkb + videoram;\n        rc = xc_domain_setmaxmem(ctx->xch, domid, memorykb +\n                LIBXL_MAXMEM_CONSTANT);\n        if (rc != 0) {\n            LOGE(ERROR,\n                 \"xc_domain_setmaxmem domid=%u memkb=%\"PRIu64\" failed \"\"rc=%d\\n\",\n                 domid,\n                 memorykb + LIBXL_MAXMEM_CONSTANT,\n                 rc);\n            abort_transaction = 1;\n            goto out;\n        }\n    }\n\n    rc = xc_domain_set_pod_target(ctx->xch, domid,\n            new_target_memkb / 4, NULL, NULL, NULL);\n    if (rc != 0) {\n        LOGE(ERROR,\n             \"xc_domain_set_pod_target domid=%d, memkb=%d \"\"failed rc=%d\\n\",\n             domid,\n             new_target_memkb / 4,\n             rc);\n        abort_transaction = 1;\n        goto out;\n    }\n\n    libxl__xs_write(gc, t, libxl__sprintf(gc, \"%s/memory/target\",\n                dompath), \"%\"PRIu32, new_target_memkb);\n    rc = xc_domain_getinfolist(ctx->xch, domid, 1, &info);\n    if (rc != 1 || info.domain != domid) {\n        abort_transaction = 1;\n        goto out;\n    }\n\n    libxl_dominfo_init(&ptr);\n    xcinfo2xlinfo(ctx, &info, &ptr);\n    uuid = libxl__uuid2string(gc, ptr.uuid);\n    libxl__xs_write(gc, t, libxl__sprintf(gc, \"/vm/%s/memory\", uuid),\n            \"%\"PRIu32, new_target_memkb / 1024);\n    libxl_dominfo_dispose(&ptr);\n\nout:\n    if (!xs_transaction_end(ctx->xsh, t, abort_transaction)\n        && !abort_transaction)\n        if (errno == EAGAIN)\n            goto retry_transaction;\n\nout_no_transaction:\n    if (lock) libxl__unlock_domain_userdata(lock);\n    CTX_UNLOCK;\n    GC_FREE;\n    return rc;\n}",
        "func": "int libxl_set_memory_target(libxl_ctx *ctx, uint32_t domid,\n        int32_t target_memkb, int relative, int enforce)\n{\n    GC_INIT(ctx);\n    int rc = 1, abort_transaction = 0;\n    uint64_t memorykb;\n    uint32_t videoram = 0;\n    uint32_t current_target_memkb = 0, new_target_memkb = 0;\n    uint32_t current_max_memkb = 0;\n    char *memmax, *endptr, *videoram_s = NULL, *target = NULL;\n    char *dompath = libxl__xs_get_dompath(gc, domid);\n    xc_domaininfo_t info;\n    libxl_dominfo ptr;\n    char *uuid;\n    xs_transaction_t t;\n    libxl__domain_userdata_lock *lock;\n\n    CTX_LOCK;\n\n    lock = libxl__lock_domain_userdata(gc, domid);\n    if (!lock) {\n        rc = ERROR_LOCK_FAIL;\n        goto out_no_transaction;\n    }\n\nretry_transaction:\n    t = xs_transaction_start(ctx->xsh);\n\n    target = libxl__xs_read(gc, t, libxl__sprintf(gc,\n                \"%s/memory/target\", dompath));\n    if (!target && !domid) {\n        if (!xs_transaction_end(ctx->xsh, t, 1))\n            goto out_no_transaction;\n        rc = libxl__fill_dom0_memory_info(gc, &current_target_memkb,\n                                          &current_max_memkb);\n        if (rc < 0)\n            goto out_no_transaction;\n        goto retry_transaction;\n    } else if (!target) {\n        LOGE(ERROR, \"cannot get target memory info from %s/memory/target\",\n             dompath);\n        abort_transaction = 1;\n        goto out;\n    } else {\n        current_target_memkb = strtoul(target, &endptr, 10);\n        if (*endptr != '\\0') {\n            LOGE(ERROR, \"invalid memory target %s from %s/memory/target\\n\",\n                 target, dompath);\n            abort_transaction = 1;\n            goto out;\n        }\n    }\n    memmax = libxl__xs_read(gc, t, libxl__sprintf(gc,\n                \"%s/memory/static-max\", dompath));\n    if (!memmax) {\n        LOGE(ERROR, \"cannot get memory info from %s/memory/static-max\",\n             dompath);\n        abort_transaction = 1;\n        goto out;\n    }\n    memorykb = strtoul(memmax, &endptr, 10);\n    if (*endptr != '\\0') {\n        LOGE(ERROR, \"invalid max memory %s from %s/memory/static-max\\n\",\n             memmax, dompath);\n        abort_transaction = 1;\n        goto out;\n    }\n\n    videoram_s = libxl__xs_read(gc, t, libxl__sprintf(gc,\n                \"%s/memory/videoram\", dompath));\n    videoram = videoram_s ? atoi(videoram_s) : 0;\n\n    if (relative) {\n        if (target_memkb < 0 && abs(target_memkb) > current_target_memkb)\n            new_target_memkb = 0;\n        else\n            new_target_memkb = current_target_memkb + target_memkb;\n    } else\n        new_target_memkb = target_memkb - videoram;\n    if (new_target_memkb > memorykb) {\n        LOG(ERROR,\n            \"memory_dynamic_max must be less than or equal to\"\n            \" memory_static_max\\n\");\n        abort_transaction = 1;\n        goto out;\n    }\n\n    if (!domid && new_target_memkb < LIBXL_MIN_DOM0_MEM) {\n        LOG(ERROR, \"new target %d for dom0 is below the minimum threshold\",\n            new_target_memkb);\n        abort_transaction = 1;\n        goto out;\n    }\n\n    if (enforce) {\n        memorykb = new_target_memkb + videoram;\n        rc = xc_domain_setmaxmem(ctx->xch, domid, memorykb +\n                LIBXL_MAXMEM_CONSTANT);\n        if (rc != 0) {\n            LOGE(ERROR,\n                 \"xc_domain_setmaxmem domid=%u memkb=%\"PRIu64\" failed \"\"rc=%d\\n\",\n                 domid,\n                 memorykb + LIBXL_MAXMEM_CONSTANT,\n                 rc);\n            abort_transaction = 1;\n            goto out;\n        }\n    }\n\n    rc = xc_domain_set_pod_target(ctx->xch, domid,\n            (new_target_memkb + LIBXL_MAXMEM_CONSTANT) / 4, NULL, NULL, NULL);\n    if (rc != 0) {\n        LOGE(ERROR,\n             \"xc_domain_set_pod_target domid=%d, memkb=%d \"\"failed rc=%d\\n\",\n             domid,\n             new_target_memkb / 4,\n             rc);\n        abort_transaction = 1;\n        goto out;\n    }\n\n    libxl__xs_write(gc, t, libxl__sprintf(gc, \"%s/memory/target\",\n                dompath), \"%\"PRIu32, new_target_memkb);\n    rc = xc_domain_getinfolist(ctx->xch, domid, 1, &info);\n    if (rc != 1 || info.domain != domid) {\n        abort_transaction = 1;\n        goto out;\n    }\n\n    libxl_dominfo_init(&ptr);\n    xcinfo2xlinfo(ctx, &info, &ptr);\n    uuid = libxl__uuid2string(gc, ptr.uuid);\n    libxl__xs_write(gc, t, libxl__sprintf(gc, \"/vm/%s/memory\", uuid),\n            \"%\"PRIu32, new_target_memkb / 1024);\n    libxl_dominfo_dispose(&ptr);\n\nout:\n    if (!xs_transaction_end(ctx->xsh, t, abort_transaction)\n        && !abort_transaction)\n        if (errno == EAGAIN)\n            goto retry_transaction;\n\nout_no_transaction:\n    if (lock) libxl__unlock_domain_userdata(lock);\n    CTX_UNLOCK;\n    GC_FREE;\n    return rc;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -108,7 +108,7 @@\n     }\n \n     rc = xc_domain_set_pod_target(ctx->xch, domid,\n-            new_target_memkb / 4, NULL, NULL, NULL);\n+            (new_target_memkb + LIBXL_MAXMEM_CONSTANT) / 4, NULL, NULL, NULL);\n     if (rc != 0) {\n         LOGE(ERROR,\n              \"xc_domain_set_pod_target domid=%d, memkb=%d \"\"failed rc=%d\\n\",",
        "diff_line_info": {
            "deleted_lines": [
                "            new_target_memkb / 4, NULL, NULL, NULL);"
            ],
            "added_lines": [
                "            (new_target_memkb + LIBXL_MAXMEM_CONSTANT) / 4, NULL, NULL, NULL);"
            ]
        }
    },
    {
        "cve_id": "CVE-2007-5501",
        "func_name": "torvalds/linux/tcp_sacktag_write_queue",
        "description": "The tcp_sacktag_write_queue function in net/ipv4/tcp_input.c in Linux kernel 2.6.21 through 2.6.23.7, and 2.6.24-rc through 2.6.24-rc2, allows remote attackers to cause a denial of service (crash) via crafted ACK responses that trigger a NULL pointer dereference.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=96a2d41a3e495734b63bff4e5dd0112741b93b38",
        "commit_title": "NULL ptr can be returned from tcp_write_queue_head to cached_skb",
        "commit_text": "and then assigned to skb if packets_out was zero. Without this, system is vulnerable to a carefully crafted ACKs which obviously is remotely triggerable.  Besides, there's very little that needs to be done in sacktag if there weren't any packets outstanding, just skipping the rest doesn't hurt.  ",
        "func_before": "static int\ntcp_sacktag_write_queue(struct sock *sk, struct sk_buff *ack_skb, u32 prior_snd_una)\n{\n\tconst struct inet_connection_sock *icsk = inet_csk(sk);\n\tstruct tcp_sock *tp = tcp_sk(sk);\n\tunsigned char *ptr = (skb_transport_header(ack_skb) +\n\t\t\t      TCP_SKB_CB(ack_skb)->sacked);\n\tstruct tcp_sack_block_wire *sp = (struct tcp_sack_block_wire *)(ptr+2);\n\tstruct sk_buff *cached_skb;\n\tint num_sacks = (ptr[1] - TCPOLEN_SACK_BASE)>>3;\n\tint reord = tp->packets_out;\n\tint prior_fackets;\n\tu32 highest_sack_end_seq = tp->lost_retrans_low;\n\tint flag = 0;\n\tint found_dup_sack = 0;\n\tint cached_fack_count;\n\tint i;\n\tint first_sack_index;\n\tint force_one_sack;\n\n\tif (!tp->sacked_out) {\n\t\tif (WARN_ON(tp->fackets_out))\n\t\t\ttp->fackets_out = 0;\n\t\ttp->highest_sack = tp->snd_una;\n\t}\n\tprior_fackets = tp->fackets_out;\n\n\tfound_dup_sack = tcp_check_dsack(tp, ack_skb, sp,\n\t\t\t\t\t num_sacks, prior_snd_una);\n\tif (found_dup_sack)\n\t\tflag |= FLAG_DSACKING_ACK;\n\n\t/* Eliminate too old ACKs, but take into\n\t * account more or less fresh ones, they can\n\t * contain valid SACK info.\n\t */\n\tif (before(TCP_SKB_CB(ack_skb)->ack_seq, prior_snd_una - tp->max_window))\n\t\treturn 0;\n\n\t/* SACK fastpath:\n\t * if the only SACK change is the increase of the end_seq of\n\t * the first block then only apply that SACK block\n\t * and use retrans queue hinting otherwise slowpath */\n\tforce_one_sack = 1;\n\tfor (i = 0; i < num_sacks; i++) {\n\t\t__be32 start_seq = sp[i].start_seq;\n\t\t__be32 end_seq = sp[i].end_seq;\n\n\t\tif (i == 0) {\n\t\t\tif (tp->recv_sack_cache[i].start_seq != start_seq)\n\t\t\t\tforce_one_sack = 0;\n\t\t} else {\n\t\t\tif ((tp->recv_sack_cache[i].start_seq != start_seq) ||\n\t\t\t    (tp->recv_sack_cache[i].end_seq != end_seq))\n\t\t\t\tforce_one_sack = 0;\n\t\t}\n\t\ttp->recv_sack_cache[i].start_seq = start_seq;\n\t\ttp->recv_sack_cache[i].end_seq = end_seq;\n\t}\n\t/* Clear the rest of the cache sack blocks so they won't match mistakenly. */\n\tfor (; i < ARRAY_SIZE(tp->recv_sack_cache); i++) {\n\t\ttp->recv_sack_cache[i].start_seq = 0;\n\t\ttp->recv_sack_cache[i].end_seq = 0;\n\t}\n\n\tfirst_sack_index = 0;\n\tif (force_one_sack)\n\t\tnum_sacks = 1;\n\telse {\n\t\tint j;\n\t\ttp->fastpath_skb_hint = NULL;\n\n\t\t/* order SACK blocks to allow in order walk of the retrans queue */\n\t\tfor (i = num_sacks-1; i > 0; i--) {\n\t\t\tfor (j = 0; j < i; j++){\n\t\t\t\tif (after(ntohl(sp[j].start_seq),\n\t\t\t\t\t  ntohl(sp[j+1].start_seq))){\n\t\t\t\t\tstruct tcp_sack_block_wire tmp;\n\n\t\t\t\t\ttmp = sp[j];\n\t\t\t\t\tsp[j] = sp[j+1];\n\t\t\t\t\tsp[j+1] = tmp;\n\n\t\t\t\t\t/* Track where the first SACK block goes to */\n\t\t\t\t\tif (j == first_sack_index)\n\t\t\t\t\t\tfirst_sack_index = j+1;\n\t\t\t\t}\n\n\t\t\t}\n\t\t}\n\t}\n\n\t/* Use SACK fastpath hint if valid */\n\tcached_skb = tp->fastpath_skb_hint;\n\tcached_fack_count = tp->fastpath_cnt_hint;\n\tif (!cached_skb) {\n\t\tcached_skb = tcp_write_queue_head(sk);\n\t\tcached_fack_count = 0;\n\t}\n\n\tfor (i = 0; i < num_sacks; i++) {\n\t\tstruct sk_buff *skb;\n\t\t__u32 start_seq = ntohl(sp->start_seq);\n\t\t__u32 end_seq = ntohl(sp->end_seq);\n\t\tint fack_count;\n\t\tint dup_sack = (found_dup_sack && (i == first_sack_index));\n\t\tint next_dup = (found_dup_sack && (i+1 == first_sack_index));\n\n\t\tsp++;\n\n\t\tif (!tcp_is_sackblock_valid(tp, dup_sack, start_seq, end_seq)) {\n\t\t\tif (dup_sack) {\n\t\t\t\tif (!tp->undo_marker)\n\t\t\t\t\tNET_INC_STATS_BH(LINUX_MIB_TCPDSACKIGNOREDNOUNDO);\n\t\t\t\telse\n\t\t\t\t\tNET_INC_STATS_BH(LINUX_MIB_TCPDSACKIGNOREDOLD);\n\t\t\t} else {\n\t\t\t\t/* Don't count olds caused by ACK reordering */\n\t\t\t\tif ((TCP_SKB_CB(ack_skb)->ack_seq != tp->snd_una) &&\n\t\t\t\t    !after(end_seq, tp->snd_una))\n\t\t\t\t\tcontinue;\n\t\t\t\tNET_INC_STATS_BH(LINUX_MIB_TCPSACKDISCARD);\n\t\t\t}\n\t\t\tcontinue;\n\t\t}\n\n\t\tskb = cached_skb;\n\t\tfack_count = cached_fack_count;\n\n\t\t/* Event \"B\" in the comment above. */\n\t\tif (after(end_seq, tp->high_seq))\n\t\t\tflag |= FLAG_DATA_LOST;\n\n\t\ttcp_for_write_queue_from(skb, sk) {\n\t\t\tint in_sack = 0;\n\t\t\tu8 sacked;\n\n\t\t\tif (skb == tcp_send_head(sk))\n\t\t\t\tbreak;\n\n\t\t\tcached_skb = skb;\n\t\t\tcached_fack_count = fack_count;\n\t\t\tif (i == first_sack_index) {\n\t\t\t\ttp->fastpath_skb_hint = skb;\n\t\t\t\ttp->fastpath_cnt_hint = fack_count;\n\t\t\t}\n\n\t\t\t/* The retransmission queue is always in order, so\n\t\t\t * we can short-circuit the walk early.\n\t\t\t */\n\t\t\tif (!before(TCP_SKB_CB(skb)->seq, end_seq))\n\t\t\t\tbreak;\n\n\t\t\tdup_sack = (found_dup_sack && (i == first_sack_index));\n\n\t\t\t/* Due to sorting DSACK may reside within this SACK block! */\n\t\t\tif (next_dup) {\n\t\t\t\tu32 dup_start = ntohl(sp->start_seq);\n\t\t\t\tu32 dup_end = ntohl(sp->end_seq);\n\n\t\t\t\tif (before(TCP_SKB_CB(skb)->seq, dup_end)) {\n\t\t\t\t\tin_sack = tcp_match_skb_to_sack(sk, skb, dup_start, dup_end);\n\t\t\t\t\tif (in_sack > 0)\n\t\t\t\t\t\tdup_sack = 1;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t/* DSACK info lost if out-of-mem, try SACK still */\n\t\t\tif (in_sack <= 0)\n\t\t\t\tin_sack = tcp_match_skb_to_sack(sk, skb, start_seq, end_seq);\n\t\t\tif (unlikely(in_sack < 0))\n\t\t\t\tbreak;\n\n\t\t\tsacked = TCP_SKB_CB(skb)->sacked;\n\n\t\t\t/* Account D-SACK for retransmitted packet. */\n\t\t\tif ((dup_sack && in_sack) &&\n\t\t\t    (sacked & TCPCB_RETRANS) &&\n\t\t\t    after(TCP_SKB_CB(skb)->end_seq, tp->undo_marker))\n\t\t\t\ttp->undo_retrans--;\n\n\t\t\t/* The frame is ACKed. */\n\t\t\tif (!after(TCP_SKB_CB(skb)->end_seq, tp->snd_una)) {\n\t\t\t\tif (sacked&TCPCB_RETRANS) {\n\t\t\t\t\tif ((dup_sack && in_sack) &&\n\t\t\t\t\t    (sacked&TCPCB_SACKED_ACKED))\n\t\t\t\t\t\treord = min(fack_count, reord);\n\t\t\t\t}\n\n\t\t\t\t/* Nothing to do; acked frame is about to be dropped. */\n\t\t\t\tfack_count += tcp_skb_pcount(skb);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (!in_sack) {\n\t\t\t\tfack_count += tcp_skb_pcount(skb);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (!(sacked&TCPCB_SACKED_ACKED)) {\n\t\t\t\tif (sacked & TCPCB_SACKED_RETRANS) {\n\t\t\t\t\t/* If the segment is not tagged as lost,\n\t\t\t\t\t * we do not clear RETRANS, believing\n\t\t\t\t\t * that retransmission is still in flight.\n\t\t\t\t\t */\n\t\t\t\t\tif (sacked & TCPCB_LOST) {\n\t\t\t\t\t\tTCP_SKB_CB(skb)->sacked &= ~(TCPCB_LOST|TCPCB_SACKED_RETRANS);\n\t\t\t\t\t\ttp->lost_out -= tcp_skb_pcount(skb);\n\t\t\t\t\t\ttp->retrans_out -= tcp_skb_pcount(skb);\n\n\t\t\t\t\t\t/* clear lost hint */\n\t\t\t\t\t\ttp->retransmit_skb_hint = NULL;\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tif (!(sacked & TCPCB_RETRANS)) {\n\t\t\t\t\t\t/* New sack for not retransmitted frame,\n\t\t\t\t\t\t * which was in hole. It is reordering.\n\t\t\t\t\t\t */\n\t\t\t\t\t\tif (fack_count < prior_fackets)\n\t\t\t\t\t\t\treord = min(fack_count, reord);\n\n\t\t\t\t\t\t/* SACK enhanced F-RTO (RFC4138; Appendix B) */\n\t\t\t\t\t\tif (!after(TCP_SKB_CB(skb)->end_seq, tp->frto_highmark))\n\t\t\t\t\t\t\tflag |= FLAG_ONLY_ORIG_SACKED;\n\t\t\t\t\t}\n\n\t\t\t\t\tif (sacked & TCPCB_LOST) {\n\t\t\t\t\t\tTCP_SKB_CB(skb)->sacked &= ~TCPCB_LOST;\n\t\t\t\t\t\ttp->lost_out -= tcp_skb_pcount(skb);\n\n\t\t\t\t\t\t/* clear lost hint */\n\t\t\t\t\t\ttp->retransmit_skb_hint = NULL;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tTCP_SKB_CB(skb)->sacked |= TCPCB_SACKED_ACKED;\n\t\t\t\tflag |= FLAG_DATA_SACKED;\n\t\t\t\ttp->sacked_out += tcp_skb_pcount(skb);\n\n\t\t\t\tfack_count += tcp_skb_pcount(skb);\n\t\t\t\tif (fack_count > tp->fackets_out)\n\t\t\t\t\ttp->fackets_out = fack_count;\n\n\t\t\t\tif (after(TCP_SKB_CB(skb)->seq, tp->highest_sack)) {\n\t\t\t\t\ttp->highest_sack = TCP_SKB_CB(skb)->seq;\n\t\t\t\t\thighest_sack_end_seq = TCP_SKB_CB(skb)->end_seq;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif (dup_sack && (sacked&TCPCB_RETRANS))\n\t\t\t\t\treord = min(fack_count, reord);\n\n\t\t\t\tfack_count += tcp_skb_pcount(skb);\n\t\t\t}\n\n\t\t\t/* D-SACK. We can detect redundant retransmission\n\t\t\t * in S|R and plain R frames and clear it.\n\t\t\t * undo_retrans is decreased above, L|R frames\n\t\t\t * are accounted above as well.\n\t\t\t */\n\t\t\tif (dup_sack &&\n\t\t\t    (TCP_SKB_CB(skb)->sacked&TCPCB_SACKED_RETRANS)) {\n\t\t\t\tTCP_SKB_CB(skb)->sacked &= ~TCPCB_SACKED_RETRANS;\n\t\t\t\ttp->retrans_out -= tcp_skb_pcount(skb);\n\t\t\t\ttp->retransmit_skb_hint = NULL;\n\t\t\t}\n\t\t}\n\n\t\t/* SACK enhanced FRTO (RFC4138, Appendix B): Clearing correct\n\t\t * due to in-order walk\n\t\t */\n\t\tif (after(end_seq, tp->frto_highmark))\n\t\t\tflag &= ~FLAG_ONLY_ORIG_SACKED;\n\t}\n\n\tif (tp->retrans_out &&\n\t    after(highest_sack_end_seq, tp->lost_retrans_low) &&\n\t    icsk->icsk_ca_state == TCP_CA_Recovery)\n\t\tflag |= tcp_mark_lost_retrans(sk, highest_sack_end_seq);\n\n\ttcp_verify_left_out(tp);\n\n\tif ((reord < tp->fackets_out) && icsk->icsk_ca_state != TCP_CA_Loss &&\n\t    (!tp->frto_highmark || after(tp->snd_una, tp->frto_highmark)))\n\t\ttcp_update_reordering(sk, tp->fackets_out - reord, 0);\n\n#if FASTRETRANS_DEBUG > 0\n\tBUG_TRAP((int)tp->sacked_out >= 0);\n\tBUG_TRAP((int)tp->lost_out >= 0);\n\tBUG_TRAP((int)tp->retrans_out >= 0);\n\tBUG_TRAP((int)tcp_packets_in_flight(tp) >= 0);\n#endif\n\treturn flag;\n}",
        "func": "static int\ntcp_sacktag_write_queue(struct sock *sk, struct sk_buff *ack_skb, u32 prior_snd_una)\n{\n\tconst struct inet_connection_sock *icsk = inet_csk(sk);\n\tstruct tcp_sock *tp = tcp_sk(sk);\n\tunsigned char *ptr = (skb_transport_header(ack_skb) +\n\t\t\t      TCP_SKB_CB(ack_skb)->sacked);\n\tstruct tcp_sack_block_wire *sp = (struct tcp_sack_block_wire *)(ptr+2);\n\tstruct sk_buff *cached_skb;\n\tint num_sacks = (ptr[1] - TCPOLEN_SACK_BASE)>>3;\n\tint reord = tp->packets_out;\n\tint prior_fackets;\n\tu32 highest_sack_end_seq = tp->lost_retrans_low;\n\tint flag = 0;\n\tint found_dup_sack = 0;\n\tint cached_fack_count;\n\tint i;\n\tint first_sack_index;\n\tint force_one_sack;\n\n\tif (!tp->sacked_out) {\n\t\tif (WARN_ON(tp->fackets_out))\n\t\t\ttp->fackets_out = 0;\n\t\ttp->highest_sack = tp->snd_una;\n\t}\n\tprior_fackets = tp->fackets_out;\n\n\tfound_dup_sack = tcp_check_dsack(tp, ack_skb, sp,\n\t\t\t\t\t num_sacks, prior_snd_una);\n\tif (found_dup_sack)\n\t\tflag |= FLAG_DSACKING_ACK;\n\n\t/* Eliminate too old ACKs, but take into\n\t * account more or less fresh ones, they can\n\t * contain valid SACK info.\n\t */\n\tif (before(TCP_SKB_CB(ack_skb)->ack_seq, prior_snd_una - tp->max_window))\n\t\treturn 0;\n\n\tif (!tp->packets_out)\n\t\tgoto out;\n\n\t/* SACK fastpath:\n\t * if the only SACK change is the increase of the end_seq of\n\t * the first block then only apply that SACK block\n\t * and use retrans queue hinting otherwise slowpath */\n\tforce_one_sack = 1;\n\tfor (i = 0; i < num_sacks; i++) {\n\t\t__be32 start_seq = sp[i].start_seq;\n\t\t__be32 end_seq = sp[i].end_seq;\n\n\t\tif (i == 0) {\n\t\t\tif (tp->recv_sack_cache[i].start_seq != start_seq)\n\t\t\t\tforce_one_sack = 0;\n\t\t} else {\n\t\t\tif ((tp->recv_sack_cache[i].start_seq != start_seq) ||\n\t\t\t    (tp->recv_sack_cache[i].end_seq != end_seq))\n\t\t\t\tforce_one_sack = 0;\n\t\t}\n\t\ttp->recv_sack_cache[i].start_seq = start_seq;\n\t\ttp->recv_sack_cache[i].end_seq = end_seq;\n\t}\n\t/* Clear the rest of the cache sack blocks so they won't match mistakenly. */\n\tfor (; i < ARRAY_SIZE(tp->recv_sack_cache); i++) {\n\t\ttp->recv_sack_cache[i].start_seq = 0;\n\t\ttp->recv_sack_cache[i].end_seq = 0;\n\t}\n\n\tfirst_sack_index = 0;\n\tif (force_one_sack)\n\t\tnum_sacks = 1;\n\telse {\n\t\tint j;\n\t\ttp->fastpath_skb_hint = NULL;\n\n\t\t/* order SACK blocks to allow in order walk of the retrans queue */\n\t\tfor (i = num_sacks-1; i > 0; i--) {\n\t\t\tfor (j = 0; j < i; j++){\n\t\t\t\tif (after(ntohl(sp[j].start_seq),\n\t\t\t\t\t  ntohl(sp[j+1].start_seq))){\n\t\t\t\t\tstruct tcp_sack_block_wire tmp;\n\n\t\t\t\t\ttmp = sp[j];\n\t\t\t\t\tsp[j] = sp[j+1];\n\t\t\t\t\tsp[j+1] = tmp;\n\n\t\t\t\t\t/* Track where the first SACK block goes to */\n\t\t\t\t\tif (j == first_sack_index)\n\t\t\t\t\t\tfirst_sack_index = j+1;\n\t\t\t\t}\n\n\t\t\t}\n\t\t}\n\t}\n\n\t/* Use SACK fastpath hint if valid */\n\tcached_skb = tp->fastpath_skb_hint;\n\tcached_fack_count = tp->fastpath_cnt_hint;\n\tif (!cached_skb) {\n\t\tcached_skb = tcp_write_queue_head(sk);\n\t\tcached_fack_count = 0;\n\t}\n\n\tfor (i = 0; i < num_sacks; i++) {\n\t\tstruct sk_buff *skb;\n\t\t__u32 start_seq = ntohl(sp->start_seq);\n\t\t__u32 end_seq = ntohl(sp->end_seq);\n\t\tint fack_count;\n\t\tint dup_sack = (found_dup_sack && (i == first_sack_index));\n\t\tint next_dup = (found_dup_sack && (i+1 == first_sack_index));\n\n\t\tsp++;\n\n\t\tif (!tcp_is_sackblock_valid(tp, dup_sack, start_seq, end_seq)) {\n\t\t\tif (dup_sack) {\n\t\t\t\tif (!tp->undo_marker)\n\t\t\t\t\tNET_INC_STATS_BH(LINUX_MIB_TCPDSACKIGNOREDNOUNDO);\n\t\t\t\telse\n\t\t\t\t\tNET_INC_STATS_BH(LINUX_MIB_TCPDSACKIGNOREDOLD);\n\t\t\t} else {\n\t\t\t\t/* Don't count olds caused by ACK reordering */\n\t\t\t\tif ((TCP_SKB_CB(ack_skb)->ack_seq != tp->snd_una) &&\n\t\t\t\t    !after(end_seq, tp->snd_una))\n\t\t\t\t\tcontinue;\n\t\t\t\tNET_INC_STATS_BH(LINUX_MIB_TCPSACKDISCARD);\n\t\t\t}\n\t\t\tcontinue;\n\t\t}\n\n\t\tskb = cached_skb;\n\t\tfack_count = cached_fack_count;\n\n\t\t/* Event \"B\" in the comment above. */\n\t\tif (after(end_seq, tp->high_seq))\n\t\t\tflag |= FLAG_DATA_LOST;\n\n\t\ttcp_for_write_queue_from(skb, sk) {\n\t\t\tint in_sack = 0;\n\t\t\tu8 sacked;\n\n\t\t\tif (skb == tcp_send_head(sk))\n\t\t\t\tbreak;\n\n\t\t\tcached_skb = skb;\n\t\t\tcached_fack_count = fack_count;\n\t\t\tif (i == first_sack_index) {\n\t\t\t\ttp->fastpath_skb_hint = skb;\n\t\t\t\ttp->fastpath_cnt_hint = fack_count;\n\t\t\t}\n\n\t\t\t/* The retransmission queue is always in order, so\n\t\t\t * we can short-circuit the walk early.\n\t\t\t */\n\t\t\tif (!before(TCP_SKB_CB(skb)->seq, end_seq))\n\t\t\t\tbreak;\n\n\t\t\tdup_sack = (found_dup_sack && (i == first_sack_index));\n\n\t\t\t/* Due to sorting DSACK may reside within this SACK block! */\n\t\t\tif (next_dup) {\n\t\t\t\tu32 dup_start = ntohl(sp->start_seq);\n\t\t\t\tu32 dup_end = ntohl(sp->end_seq);\n\n\t\t\t\tif (before(TCP_SKB_CB(skb)->seq, dup_end)) {\n\t\t\t\t\tin_sack = tcp_match_skb_to_sack(sk, skb, dup_start, dup_end);\n\t\t\t\t\tif (in_sack > 0)\n\t\t\t\t\t\tdup_sack = 1;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t/* DSACK info lost if out-of-mem, try SACK still */\n\t\t\tif (in_sack <= 0)\n\t\t\t\tin_sack = tcp_match_skb_to_sack(sk, skb, start_seq, end_seq);\n\t\t\tif (unlikely(in_sack < 0))\n\t\t\t\tbreak;\n\n\t\t\tsacked = TCP_SKB_CB(skb)->sacked;\n\n\t\t\t/* Account D-SACK for retransmitted packet. */\n\t\t\tif ((dup_sack && in_sack) &&\n\t\t\t    (sacked & TCPCB_RETRANS) &&\n\t\t\t    after(TCP_SKB_CB(skb)->end_seq, tp->undo_marker))\n\t\t\t\ttp->undo_retrans--;\n\n\t\t\t/* The frame is ACKed. */\n\t\t\tif (!after(TCP_SKB_CB(skb)->end_seq, tp->snd_una)) {\n\t\t\t\tif (sacked&TCPCB_RETRANS) {\n\t\t\t\t\tif ((dup_sack && in_sack) &&\n\t\t\t\t\t    (sacked&TCPCB_SACKED_ACKED))\n\t\t\t\t\t\treord = min(fack_count, reord);\n\t\t\t\t}\n\n\t\t\t\t/* Nothing to do; acked frame is about to be dropped. */\n\t\t\t\tfack_count += tcp_skb_pcount(skb);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (!in_sack) {\n\t\t\t\tfack_count += tcp_skb_pcount(skb);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (!(sacked&TCPCB_SACKED_ACKED)) {\n\t\t\t\tif (sacked & TCPCB_SACKED_RETRANS) {\n\t\t\t\t\t/* If the segment is not tagged as lost,\n\t\t\t\t\t * we do not clear RETRANS, believing\n\t\t\t\t\t * that retransmission is still in flight.\n\t\t\t\t\t */\n\t\t\t\t\tif (sacked & TCPCB_LOST) {\n\t\t\t\t\t\tTCP_SKB_CB(skb)->sacked &= ~(TCPCB_LOST|TCPCB_SACKED_RETRANS);\n\t\t\t\t\t\ttp->lost_out -= tcp_skb_pcount(skb);\n\t\t\t\t\t\ttp->retrans_out -= tcp_skb_pcount(skb);\n\n\t\t\t\t\t\t/* clear lost hint */\n\t\t\t\t\t\ttp->retransmit_skb_hint = NULL;\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tif (!(sacked & TCPCB_RETRANS)) {\n\t\t\t\t\t\t/* New sack for not retransmitted frame,\n\t\t\t\t\t\t * which was in hole. It is reordering.\n\t\t\t\t\t\t */\n\t\t\t\t\t\tif (fack_count < prior_fackets)\n\t\t\t\t\t\t\treord = min(fack_count, reord);\n\n\t\t\t\t\t\t/* SACK enhanced F-RTO (RFC4138; Appendix B) */\n\t\t\t\t\t\tif (!after(TCP_SKB_CB(skb)->end_seq, tp->frto_highmark))\n\t\t\t\t\t\t\tflag |= FLAG_ONLY_ORIG_SACKED;\n\t\t\t\t\t}\n\n\t\t\t\t\tif (sacked & TCPCB_LOST) {\n\t\t\t\t\t\tTCP_SKB_CB(skb)->sacked &= ~TCPCB_LOST;\n\t\t\t\t\t\ttp->lost_out -= tcp_skb_pcount(skb);\n\n\t\t\t\t\t\t/* clear lost hint */\n\t\t\t\t\t\ttp->retransmit_skb_hint = NULL;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tTCP_SKB_CB(skb)->sacked |= TCPCB_SACKED_ACKED;\n\t\t\t\tflag |= FLAG_DATA_SACKED;\n\t\t\t\ttp->sacked_out += tcp_skb_pcount(skb);\n\n\t\t\t\tfack_count += tcp_skb_pcount(skb);\n\t\t\t\tif (fack_count > tp->fackets_out)\n\t\t\t\t\ttp->fackets_out = fack_count;\n\n\t\t\t\tif (after(TCP_SKB_CB(skb)->seq, tp->highest_sack)) {\n\t\t\t\t\ttp->highest_sack = TCP_SKB_CB(skb)->seq;\n\t\t\t\t\thighest_sack_end_seq = TCP_SKB_CB(skb)->end_seq;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif (dup_sack && (sacked&TCPCB_RETRANS))\n\t\t\t\t\treord = min(fack_count, reord);\n\n\t\t\t\tfack_count += tcp_skb_pcount(skb);\n\t\t\t}\n\n\t\t\t/* D-SACK. We can detect redundant retransmission\n\t\t\t * in S|R and plain R frames and clear it.\n\t\t\t * undo_retrans is decreased above, L|R frames\n\t\t\t * are accounted above as well.\n\t\t\t */\n\t\t\tif (dup_sack &&\n\t\t\t    (TCP_SKB_CB(skb)->sacked&TCPCB_SACKED_RETRANS)) {\n\t\t\t\tTCP_SKB_CB(skb)->sacked &= ~TCPCB_SACKED_RETRANS;\n\t\t\t\ttp->retrans_out -= tcp_skb_pcount(skb);\n\t\t\t\ttp->retransmit_skb_hint = NULL;\n\t\t\t}\n\t\t}\n\n\t\t/* SACK enhanced FRTO (RFC4138, Appendix B): Clearing correct\n\t\t * due to in-order walk\n\t\t */\n\t\tif (after(end_seq, tp->frto_highmark))\n\t\t\tflag &= ~FLAG_ONLY_ORIG_SACKED;\n\t}\n\n\tif (tp->retrans_out &&\n\t    after(highest_sack_end_seq, tp->lost_retrans_low) &&\n\t    icsk->icsk_ca_state == TCP_CA_Recovery)\n\t\tflag |= tcp_mark_lost_retrans(sk, highest_sack_end_seq);\n\n\ttcp_verify_left_out(tp);\n\n\tif ((reord < tp->fackets_out) && icsk->icsk_ca_state != TCP_CA_Loss &&\n\t    (!tp->frto_highmark || after(tp->snd_una, tp->frto_highmark)))\n\t\ttcp_update_reordering(sk, tp->fackets_out - reord, 0);\n\nout:\n\n#if FASTRETRANS_DEBUG > 0\n\tBUG_TRAP((int)tp->sacked_out >= 0);\n\tBUG_TRAP((int)tp->lost_out >= 0);\n\tBUG_TRAP((int)tp->retrans_out >= 0);\n\tBUG_TRAP((int)tcp_packets_in_flight(tp) >= 0);\n#endif\n\treturn flag;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -37,6 +37,9 @@\n \tif (before(TCP_SKB_CB(ack_skb)->ack_seq, prior_snd_una - tp->max_window))\n \t\treturn 0;\n \n+\tif (!tp->packets_out)\n+\t\tgoto out;\n+\n \t/* SACK fastpath:\n \t * if the only SACK change is the increase of the end_seq of\n \t * the first block then only apply that SACK block\n@@ -283,6 +286,8 @@\n \t    (!tp->frto_highmark || after(tp->snd_una, tp->frto_highmark)))\n \t\ttcp_update_reordering(sk, tp->fackets_out - reord, 0);\n \n+out:\n+\n #if FASTRETRANS_DEBUG > 0\n \tBUG_TRAP((int)tp->sacked_out >= 0);\n \tBUG_TRAP((int)tp->lost_out >= 0);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tif (!tp->packets_out)",
                "\t\tgoto out;",
                "",
                "out:",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2008-1367",
        "func_name": "torvalds/linux/ia32_setup_frame",
        "description": "gcc 4.3.x does not generate a cld instruction while compiling functions used for string manipulation such as memcpy and memmove on x86 and i386, which can prevent the direction flag (DF) from being reset in violation of ABI conventions and cause data to be copied in the wrong direction during signal handling in the Linux kernel, which might allow context-dependent attackers to trigger memory corruption. NOTE: this issue was originally reported for CPU consumption in SBCL.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=e40cd10ccff3d9fbffd57b93780bee4b7b9bff51",
        "commit_title": "The Linux kernel currently does not clear the direction flag before",
        "commit_text": "calling a signal handler, whereas the x86/x86-64 ABI requires that.  Linux had this behavior/bug forever, but this becomes a real problem with gcc version 4.3, which assumes that the direction flag is correctly cleared at the entry of a function.  This patches changes the setup_frame() functions to clear the direction before entering the signal handler.  ",
        "func_before": "int ia32_setup_frame(int sig, struct k_sigaction *ka,\n\t\t     compat_sigset_t *set, struct pt_regs *regs)\n{\n\tstruct sigframe __user *frame;\n\tvoid __user *restorer;\n\tint err = 0;\n\n\t/* copy_to_user optimizes that into a single 8 byte store */\n\tstatic const struct {\n\t\tu16 poplmovl;\n\t\tu32 val;\n\t\tu16 int80;\n\t\tu16 pad;\n\t} __attribute__((packed)) code = {\n\t\t0xb858,\t\t /* popl %eax ; movl $...,%eax */\n\t\t__NR_ia32_sigreturn,\n\t\t0x80cd,\t\t/* int $0x80 */\n\t\t0,\n\t};\n\n\tframe = get_sigframe(ka, regs, sizeof(*frame));\n\n\tif (!access_ok(VERIFY_WRITE, frame, sizeof(*frame)))\n\t\tgoto give_sigsegv;\n\n\terr |= __put_user(sig, &frame->sig);\n\tif (err)\n\t\tgoto give_sigsegv;\n\n\terr |= ia32_setup_sigcontext(&frame->sc, &frame->fpstate, regs,\n\t\t\t\t\tset->sig[0]);\n\tif (err)\n\t\tgoto give_sigsegv;\n\n\tif (_COMPAT_NSIG_WORDS > 1) {\n\t\terr |= __copy_to_user(frame->extramask, &set->sig[1],\n\t\t\t\t      sizeof(frame->extramask));\n\t\tif (err)\n\t\t\tgoto give_sigsegv;\n\t}\n\n\tif (ka->sa.sa_flags & SA_RESTORER) {\n\t\trestorer = ka->sa.sa_restorer;\n\t} else {\n\t\t/* Return stub is in 32bit vsyscall page */\n\t\tif (current->binfmt->hasvdso)\n\t\t\trestorer = VDSO32_SYMBOL(current->mm->context.vdso,\n\t\t\t\t\t\t sigreturn);\n\t\telse\n\t\t\trestorer = &frame->retcode;\n\t}\n\terr |= __put_user(ptr_to_compat(restorer), &frame->pretcode);\n\n\t/*\n\t * These are actually not used anymore, but left because some\n\t * gdb versions depend on them as a marker.\n\t */\n\terr |= __copy_to_user(frame->retcode, &code, 8);\n\tif (err)\n\t\tgoto give_sigsegv;\n\n\t/* Set up registers for signal handler */\n\tregs->sp = (unsigned long) frame;\n\tregs->ip = (unsigned long) ka->sa.sa_handler;\n\n\t/* Make -mregparm=3 work */\n\tregs->ax = sig;\n\tregs->dx = 0;\n\tregs->cx = 0;\n\n\tasm volatile(\"movl %0,%%ds\" :: \"r\" (__USER32_DS));\n\tasm volatile(\"movl %0,%%es\" :: \"r\" (__USER32_DS));\n\n\tregs->cs = __USER32_CS;\n\tregs->ss = __USER32_DS;\n\n\tset_fs(USER_DS);\n\tregs->flags &= ~X86_EFLAGS_TF;\n\tif (test_thread_flag(TIF_SINGLESTEP))\n\t\tptrace_notify(SIGTRAP);\n\n#if DEBUG_SIG\n\tprintk(KERN_DEBUG \"SIG deliver (%s:%d): sp=%p pc=%lx ra=%u\\n\",\n\t       current->comm, current->pid, frame, regs->ip, frame->pretcode);\n#endif\n\n\treturn 0;\n\ngive_sigsegv:\n\tforce_sigsegv(sig, current);\n\treturn -EFAULT;\n}",
        "func": "int ia32_setup_frame(int sig, struct k_sigaction *ka,\n\t\t     compat_sigset_t *set, struct pt_regs *regs)\n{\n\tstruct sigframe __user *frame;\n\tvoid __user *restorer;\n\tint err = 0;\n\n\t/* copy_to_user optimizes that into a single 8 byte store */\n\tstatic const struct {\n\t\tu16 poplmovl;\n\t\tu32 val;\n\t\tu16 int80;\n\t\tu16 pad;\n\t} __attribute__((packed)) code = {\n\t\t0xb858,\t\t /* popl %eax ; movl $...,%eax */\n\t\t__NR_ia32_sigreturn,\n\t\t0x80cd,\t\t/* int $0x80 */\n\t\t0,\n\t};\n\n\tframe = get_sigframe(ka, regs, sizeof(*frame));\n\n\tif (!access_ok(VERIFY_WRITE, frame, sizeof(*frame)))\n\t\tgoto give_sigsegv;\n\n\terr |= __put_user(sig, &frame->sig);\n\tif (err)\n\t\tgoto give_sigsegv;\n\n\terr |= ia32_setup_sigcontext(&frame->sc, &frame->fpstate, regs,\n\t\t\t\t\tset->sig[0]);\n\tif (err)\n\t\tgoto give_sigsegv;\n\n\tif (_COMPAT_NSIG_WORDS > 1) {\n\t\terr |= __copy_to_user(frame->extramask, &set->sig[1],\n\t\t\t\t      sizeof(frame->extramask));\n\t\tif (err)\n\t\t\tgoto give_sigsegv;\n\t}\n\n\tif (ka->sa.sa_flags & SA_RESTORER) {\n\t\trestorer = ka->sa.sa_restorer;\n\t} else {\n\t\t/* Return stub is in 32bit vsyscall page */\n\t\tif (current->binfmt->hasvdso)\n\t\t\trestorer = VDSO32_SYMBOL(current->mm->context.vdso,\n\t\t\t\t\t\t sigreturn);\n\t\telse\n\t\t\trestorer = &frame->retcode;\n\t}\n\terr |= __put_user(ptr_to_compat(restorer), &frame->pretcode);\n\n\t/*\n\t * These are actually not used anymore, but left because some\n\t * gdb versions depend on them as a marker.\n\t */\n\terr |= __copy_to_user(frame->retcode, &code, 8);\n\tif (err)\n\t\tgoto give_sigsegv;\n\n\t/* Set up registers for signal handler */\n\tregs->sp = (unsigned long) frame;\n\tregs->ip = (unsigned long) ka->sa.sa_handler;\n\n\t/* Make -mregparm=3 work */\n\tregs->ax = sig;\n\tregs->dx = 0;\n\tregs->cx = 0;\n\n\tasm volatile(\"movl %0,%%ds\" :: \"r\" (__USER32_DS));\n\tasm volatile(\"movl %0,%%es\" :: \"r\" (__USER32_DS));\n\n\tregs->cs = __USER32_CS;\n\tregs->ss = __USER32_DS;\n\n\tset_fs(USER_DS);\n\tregs->flags &= ~(X86_EFLAGS_TF | X86_EFLAGS_DF);\n\tif (test_thread_flag(TIF_SINGLESTEP))\n\t\tptrace_notify(SIGTRAP);\n\n#if DEBUG_SIG\n\tprintk(KERN_DEBUG \"SIG deliver (%s:%d): sp=%p pc=%lx ra=%u\\n\",\n\t       current->comm, current->pid, frame, regs->ip, frame->pretcode);\n#endif\n\n\treturn 0;\n\ngive_sigsegv:\n\tforce_sigsegv(sig, current);\n\treturn -EFAULT;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -75,7 +75,7 @@\n \tregs->ss = __USER32_DS;\n \n \tset_fs(USER_DS);\n-\tregs->flags &= ~X86_EFLAGS_TF;\n+\tregs->flags &= ~(X86_EFLAGS_TF | X86_EFLAGS_DF);\n \tif (test_thread_flag(TIF_SINGLESTEP))\n \t\tptrace_notify(SIGTRAP);\n ",
        "diff_line_info": {
            "deleted_lines": [
                "\tregs->flags &= ~X86_EFLAGS_TF;"
            ],
            "added_lines": [
                "\tregs->flags &= ~(X86_EFLAGS_TF | X86_EFLAGS_DF);"
            ]
        }
    },
    {
        "cve_id": "CVE-2008-1367",
        "func_name": "torvalds/linux/ia32_setup_rt_frame",
        "description": "gcc 4.3.x does not generate a cld instruction while compiling functions used for string manipulation such as memcpy and memmove on x86 and i386, which can prevent the direction flag (DF) from being reset in violation of ABI conventions and cause data to be copied in the wrong direction during signal handling in the Linux kernel, which might allow context-dependent attackers to trigger memory corruption. NOTE: this issue was originally reported for CPU consumption in SBCL.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=e40cd10ccff3d9fbffd57b93780bee4b7b9bff51",
        "commit_title": "The Linux kernel currently does not clear the direction flag before",
        "commit_text": "calling a signal handler, whereas the x86/x86-64 ABI requires that.  Linux had this behavior/bug forever, but this becomes a real problem with gcc version 4.3, which assumes that the direction flag is correctly cleared at the entry of a function.  This patches changes the setup_frame() functions to clear the direction before entering the signal handler.  ",
        "func_before": "int ia32_setup_rt_frame(int sig, struct k_sigaction *ka, siginfo_t *info,\n\t\t\tcompat_sigset_t *set, struct pt_regs *regs)\n{\n\tstruct rt_sigframe __user *frame;\n\tstruct exec_domain *ed = current_thread_info()->exec_domain;\n\tvoid __user *restorer;\n\tint err = 0;\n\n\t/* __copy_to_user optimizes that into a single 8 byte store */\n\tstatic const struct {\n\t\tu8 movl;\n\t\tu32 val;\n\t\tu16 int80;\n\t\tu16 pad;\n\t\tu8  pad2;\n\t} __attribute__((packed)) code = {\n\t\t0xb8,\n\t\t__NR_ia32_rt_sigreturn,\n\t\t0x80cd,\n\t\t0,\n\t};\n\n\tframe = get_sigframe(ka, regs, sizeof(*frame));\n\n\tif (!access_ok(VERIFY_WRITE, frame, sizeof(*frame)))\n\t\tgoto give_sigsegv;\n\n\terr |= __put_user((ed && ed->signal_invmap && sig < 32\n\t\t\t   ? ed->signal_invmap[sig] : sig), &frame->sig);\n\terr |= __put_user(ptr_to_compat(&frame->info), &frame->pinfo);\n\terr |= __put_user(ptr_to_compat(&frame->uc), &frame->puc);\n\terr |= copy_siginfo_to_user32(&frame->info, info);\n\tif (err)\n\t\tgoto give_sigsegv;\n\n\t/* Create the ucontext.  */\n\terr |= __put_user(0, &frame->uc.uc_flags);\n\terr |= __put_user(0, &frame->uc.uc_link);\n\terr |= __put_user(current->sas_ss_sp, &frame->uc.uc_stack.ss_sp);\n\terr |= __put_user(sas_ss_flags(regs->sp),\n\t\t\t  &frame->uc.uc_stack.ss_flags);\n\terr |= __put_user(current->sas_ss_size, &frame->uc.uc_stack.ss_size);\n\terr |= ia32_setup_sigcontext(&frame->uc.uc_mcontext, &frame->fpstate,\n\t\t\t\t     regs, set->sig[0]);\n\terr |= __copy_to_user(&frame->uc.uc_sigmask, set, sizeof(*set));\n\tif (err)\n\t\tgoto give_sigsegv;\n\n\tif (ka->sa.sa_flags & SA_RESTORER)\n\t\trestorer = ka->sa.sa_restorer;\n\telse\n\t\trestorer = VDSO32_SYMBOL(current->mm->context.vdso,\n\t\t\t\t\t rt_sigreturn);\n\terr |= __put_user(ptr_to_compat(restorer), &frame->pretcode);\n\n\t/*\n\t * Not actually used anymore, but left because some gdb\n\t * versions need it.\n\t */\n\terr |= __copy_to_user(frame->retcode, &code, 8);\n\tif (err)\n\t\tgoto give_sigsegv;\n\n\t/* Set up registers for signal handler */\n\tregs->sp = (unsigned long) frame;\n\tregs->ip = (unsigned long) ka->sa.sa_handler;\n\n\t/* Make -mregparm=3 work */\n\tregs->ax = sig;\n\tregs->dx = (unsigned long) &frame->info;\n\tregs->cx = (unsigned long) &frame->uc;\n\n\t/* Make -mregparm=3 work */\n\tregs->ax = sig;\n\tregs->dx = (unsigned long) &frame->info;\n\tregs->cx = (unsigned long) &frame->uc;\n\n\tasm volatile(\"movl %0,%%ds\" :: \"r\" (__USER32_DS));\n\tasm volatile(\"movl %0,%%es\" :: \"r\" (__USER32_DS));\n\n\tregs->cs = __USER32_CS;\n\tregs->ss = __USER32_DS;\n\n\tset_fs(USER_DS);\n\tregs->flags &= ~X86_EFLAGS_TF;\n\tif (test_thread_flag(TIF_SINGLESTEP))\n\t\tptrace_notify(SIGTRAP);\n\n#if DEBUG_SIG\n\tprintk(KERN_DEBUG \"SIG deliver (%s:%d): sp=%p pc=%lx ra=%u\\n\",\n\t       current->comm, current->pid, frame, regs->ip, frame->pretcode);\n#endif\n\n\treturn 0;\n\ngive_sigsegv:\n\tforce_sigsegv(sig, current);\n\treturn -EFAULT;\n}",
        "func": "int ia32_setup_rt_frame(int sig, struct k_sigaction *ka, siginfo_t *info,\n\t\t\tcompat_sigset_t *set, struct pt_regs *regs)\n{\n\tstruct rt_sigframe __user *frame;\n\tstruct exec_domain *ed = current_thread_info()->exec_domain;\n\tvoid __user *restorer;\n\tint err = 0;\n\n\t/* __copy_to_user optimizes that into a single 8 byte store */\n\tstatic const struct {\n\t\tu8 movl;\n\t\tu32 val;\n\t\tu16 int80;\n\t\tu16 pad;\n\t\tu8  pad2;\n\t} __attribute__((packed)) code = {\n\t\t0xb8,\n\t\t__NR_ia32_rt_sigreturn,\n\t\t0x80cd,\n\t\t0,\n\t};\n\n\tframe = get_sigframe(ka, regs, sizeof(*frame));\n\n\tif (!access_ok(VERIFY_WRITE, frame, sizeof(*frame)))\n\t\tgoto give_sigsegv;\n\n\terr |= __put_user((ed && ed->signal_invmap && sig < 32\n\t\t\t   ? ed->signal_invmap[sig] : sig), &frame->sig);\n\terr |= __put_user(ptr_to_compat(&frame->info), &frame->pinfo);\n\terr |= __put_user(ptr_to_compat(&frame->uc), &frame->puc);\n\terr |= copy_siginfo_to_user32(&frame->info, info);\n\tif (err)\n\t\tgoto give_sigsegv;\n\n\t/* Create the ucontext.  */\n\terr |= __put_user(0, &frame->uc.uc_flags);\n\terr |= __put_user(0, &frame->uc.uc_link);\n\terr |= __put_user(current->sas_ss_sp, &frame->uc.uc_stack.ss_sp);\n\terr |= __put_user(sas_ss_flags(regs->sp),\n\t\t\t  &frame->uc.uc_stack.ss_flags);\n\terr |= __put_user(current->sas_ss_size, &frame->uc.uc_stack.ss_size);\n\terr |= ia32_setup_sigcontext(&frame->uc.uc_mcontext, &frame->fpstate,\n\t\t\t\t     regs, set->sig[0]);\n\terr |= __copy_to_user(&frame->uc.uc_sigmask, set, sizeof(*set));\n\tif (err)\n\t\tgoto give_sigsegv;\n\n\tif (ka->sa.sa_flags & SA_RESTORER)\n\t\trestorer = ka->sa.sa_restorer;\n\telse\n\t\trestorer = VDSO32_SYMBOL(current->mm->context.vdso,\n\t\t\t\t\t rt_sigreturn);\n\terr |= __put_user(ptr_to_compat(restorer), &frame->pretcode);\n\n\t/*\n\t * Not actually used anymore, but left because some gdb\n\t * versions need it.\n\t */\n\terr |= __copy_to_user(frame->retcode, &code, 8);\n\tif (err)\n\t\tgoto give_sigsegv;\n\n\t/* Set up registers for signal handler */\n\tregs->sp = (unsigned long) frame;\n\tregs->ip = (unsigned long) ka->sa.sa_handler;\n\n\t/* Make -mregparm=3 work */\n\tregs->ax = sig;\n\tregs->dx = (unsigned long) &frame->info;\n\tregs->cx = (unsigned long) &frame->uc;\n\n\t/* Make -mregparm=3 work */\n\tregs->ax = sig;\n\tregs->dx = (unsigned long) &frame->info;\n\tregs->cx = (unsigned long) &frame->uc;\n\n\tasm volatile(\"movl %0,%%ds\" :: \"r\" (__USER32_DS));\n\tasm volatile(\"movl %0,%%es\" :: \"r\" (__USER32_DS));\n\n\tregs->cs = __USER32_CS;\n\tregs->ss = __USER32_DS;\n\n\tset_fs(USER_DS);\n\tregs->flags &= ~(X86_EFLAGS_TF | X86_EFLAGS_DF);\n\tif (test_thread_flag(TIF_SINGLESTEP))\n\t\tptrace_notify(SIGTRAP);\n\n#if DEBUG_SIG\n\tprintk(KERN_DEBUG \"SIG deliver (%s:%d): sp=%p pc=%lx ra=%u\\n\",\n\t       current->comm, current->pid, frame, regs->ip, frame->pretcode);\n#endif\n\n\treturn 0;\n\ngive_sigsegv:\n\tforce_sigsegv(sig, current);\n\treturn -EFAULT;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -82,7 +82,7 @@\n \tregs->ss = __USER32_DS;\n \n \tset_fs(USER_DS);\n-\tregs->flags &= ~X86_EFLAGS_TF;\n+\tregs->flags &= ~(X86_EFLAGS_TF | X86_EFLAGS_DF);\n \tif (test_thread_flag(TIF_SINGLESTEP))\n \t\tptrace_notify(SIGTRAP);\n ",
        "diff_line_info": {
            "deleted_lines": [
                "\tregs->flags &= ~X86_EFLAGS_TF;"
            ],
            "added_lines": [
                "\tregs->flags &= ~(X86_EFLAGS_TF | X86_EFLAGS_DF);"
            ]
        }
    },
    {
        "cve_id": "CVE-2008-1367",
        "func_name": "torvalds/linux/setup_frame",
        "description": "gcc 4.3.x does not generate a cld instruction while compiling functions used for string manipulation such as memcpy and memmove on x86 and i386, which can prevent the direction flag (DF) from being reset in violation of ABI conventions and cause data to be copied in the wrong direction during signal handling in the Linux kernel, which might allow context-dependent attackers to trigger memory corruption. NOTE: this issue was originally reported for CPU consumption in SBCL.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=e40cd10ccff3d9fbffd57b93780bee4b7b9bff51",
        "commit_title": "The Linux kernel currently does not clear the direction flag before",
        "commit_text": "calling a signal handler, whereas the x86/x86-64 ABI requires that.  Linux had this behavior/bug forever, but this becomes a real problem with gcc version 4.3, which assumes that the direction flag is correctly cleared at the entry of a function.  This patches changes the setup_frame() functions to clear the direction before entering the signal handler.  ",
        "func_before": "static int setup_frame(int sig, struct k_sigaction *ka,\n\t\t       sigset_t *set, struct pt_regs * regs)\n{\n\tvoid __user *restorer;\n\tstruct sigframe __user *frame;\n\tint err = 0;\n\tint usig;\n\n\tframe = get_sigframe(ka, regs, sizeof(*frame));\n\n\tif (!access_ok(VERIFY_WRITE, frame, sizeof(*frame)))\n\t\tgoto give_sigsegv;\n\n\tusig = current_thread_info()->exec_domain\n\t\t&& current_thread_info()->exec_domain->signal_invmap\n\t\t&& sig < 32\n\t\t? current_thread_info()->exec_domain->signal_invmap[sig]\n\t\t: sig;\n\n\terr = __put_user(usig, &frame->sig);\n\tif (err)\n\t\tgoto give_sigsegv;\n\n\terr = setup_sigcontext(&frame->sc, &frame->fpstate, regs, set->sig[0]);\n\tif (err)\n\t\tgoto give_sigsegv;\n\n\tif (_NSIG_WORDS > 1) {\n\t\terr = __copy_to_user(&frame->extramask, &set->sig[1],\n\t\t\t\t      sizeof(frame->extramask));\n\t\tif (err)\n\t\t\tgoto give_sigsegv;\n\t}\n\n\tif (current->binfmt->hasvdso)\n\t\trestorer = VDSO32_SYMBOL(current->mm->context.vdso, sigreturn);\n\telse\n\t\trestorer = &frame->retcode;\n\tif (ka->sa.sa_flags & SA_RESTORER)\n\t\trestorer = ka->sa.sa_restorer;\n\n\t/* Set up to return from userspace.  */\n\terr |= __put_user(restorer, &frame->pretcode);\n\t \n\t/*\n\t * This is popl %eax ; movl $,%eax ; int $0x80\n\t *\n\t * WE DO NOT USE IT ANY MORE! It's only left here for historical\n\t * reasons and because gdb uses it as a signature to notice\n\t * signal handler stack frames.\n\t */\n\terr |= __put_user(0xb858, (short __user *)(frame->retcode+0));\n\terr |= __put_user(__NR_sigreturn, (int __user *)(frame->retcode+2));\n\terr |= __put_user(0x80cd, (short __user *)(frame->retcode+6));\n\n\tif (err)\n\t\tgoto give_sigsegv;\n\n\t/* Set up registers for signal handler */\n\tregs->sp = (unsigned long) frame;\n\tregs->ip = (unsigned long) ka->sa.sa_handler;\n\tregs->ax = (unsigned long) sig;\n\tregs->dx = (unsigned long) 0;\n\tregs->cx = (unsigned long) 0;\n\n\tregs->ds = __USER_DS;\n\tregs->es = __USER_DS;\n\tregs->ss = __USER_DS;\n\tregs->cs = __USER_CS;\n\n\t/*\n\t * Clear TF when entering the signal handler, but\n\t * notify any tracer that was single-stepping it.\n\t * The tracer may want to single-step inside the\n\t * handler too.\n\t */\n\tregs->flags &= ~TF_MASK;\n\tif (test_thread_flag(TIF_SINGLESTEP))\n\t\tptrace_notify(SIGTRAP);\n\n#if DEBUG_SIG\n\tprintk(\"SIG deliver (%s:%d): sp=%p pc=%p ra=%p\\n\",\n\t\tcurrent->comm, current->pid, frame, regs->ip, frame->pretcode);\n#endif\n\n\treturn 0;\n\ngive_sigsegv:\n\tforce_sigsegv(sig, current);\n\treturn -EFAULT;\n}",
        "func": "static int setup_frame(int sig, struct k_sigaction *ka,\n\t\t       sigset_t *set, struct pt_regs * regs)\n{\n\tvoid __user *restorer;\n\tstruct sigframe __user *frame;\n\tint err = 0;\n\tint usig;\n\n\tframe = get_sigframe(ka, regs, sizeof(*frame));\n\n\tif (!access_ok(VERIFY_WRITE, frame, sizeof(*frame)))\n\t\tgoto give_sigsegv;\n\n\tusig = current_thread_info()->exec_domain\n\t\t&& current_thread_info()->exec_domain->signal_invmap\n\t\t&& sig < 32\n\t\t? current_thread_info()->exec_domain->signal_invmap[sig]\n\t\t: sig;\n\n\terr = __put_user(usig, &frame->sig);\n\tif (err)\n\t\tgoto give_sigsegv;\n\n\terr = setup_sigcontext(&frame->sc, &frame->fpstate, regs, set->sig[0]);\n\tif (err)\n\t\tgoto give_sigsegv;\n\n\tif (_NSIG_WORDS > 1) {\n\t\terr = __copy_to_user(&frame->extramask, &set->sig[1],\n\t\t\t\t      sizeof(frame->extramask));\n\t\tif (err)\n\t\t\tgoto give_sigsegv;\n\t}\n\n\tif (current->binfmt->hasvdso)\n\t\trestorer = VDSO32_SYMBOL(current->mm->context.vdso, sigreturn);\n\telse\n\t\trestorer = &frame->retcode;\n\tif (ka->sa.sa_flags & SA_RESTORER)\n\t\trestorer = ka->sa.sa_restorer;\n\n\t/* Set up to return from userspace.  */\n\terr |= __put_user(restorer, &frame->pretcode);\n\t \n\t/*\n\t * This is popl %eax ; movl $,%eax ; int $0x80\n\t *\n\t * WE DO NOT USE IT ANY MORE! It's only left here for historical\n\t * reasons and because gdb uses it as a signature to notice\n\t * signal handler stack frames.\n\t */\n\terr |= __put_user(0xb858, (short __user *)(frame->retcode+0));\n\terr |= __put_user(__NR_sigreturn, (int __user *)(frame->retcode+2));\n\terr |= __put_user(0x80cd, (short __user *)(frame->retcode+6));\n\n\tif (err)\n\t\tgoto give_sigsegv;\n\n\t/* Set up registers for signal handler */\n\tregs->sp = (unsigned long) frame;\n\tregs->ip = (unsigned long) ka->sa.sa_handler;\n\tregs->ax = (unsigned long) sig;\n\tregs->dx = (unsigned long) 0;\n\tregs->cx = (unsigned long) 0;\n\n\tregs->ds = __USER_DS;\n\tregs->es = __USER_DS;\n\tregs->ss = __USER_DS;\n\tregs->cs = __USER_CS;\n\n\t/*\n\t * Clear TF when entering the signal handler, but\n\t * notify any tracer that was single-stepping it.\n\t * The tracer may want to single-step inside the\n\t * handler too.\n\t */\n\tregs->flags &= ~(TF_MASK | X86_EFLAGS_DF);\n\tif (test_thread_flag(TIF_SINGLESTEP))\n\t\tptrace_notify(SIGTRAP);\n\n#if DEBUG_SIG\n\tprintk(\"SIG deliver (%s:%d): sp=%p pc=%p ra=%p\\n\",\n\t\tcurrent->comm, current->pid, frame, regs->ip, frame->pretcode);\n#endif\n\n\treturn 0;\n\ngive_sigsegv:\n\tforce_sigsegv(sig, current);\n\treturn -EFAULT;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -74,7 +74,7 @@\n \t * The tracer may want to single-step inside the\n \t * handler too.\n \t */\n-\tregs->flags &= ~TF_MASK;\n+\tregs->flags &= ~(TF_MASK | X86_EFLAGS_DF);\n \tif (test_thread_flag(TIF_SINGLESTEP))\n \t\tptrace_notify(SIGTRAP);\n ",
        "diff_line_info": {
            "deleted_lines": [
                "\tregs->flags &= ~TF_MASK;"
            ],
            "added_lines": [
                "\tregs->flags &= ~(TF_MASK | X86_EFLAGS_DF);"
            ]
        }
    },
    {
        "cve_id": "CVE-2008-1367",
        "func_name": "torvalds/linux/setup_rt_frame",
        "description": "gcc 4.3.x does not generate a cld instruction while compiling functions used for string manipulation such as memcpy and memmove on x86 and i386, which can prevent the direction flag (DF) from being reset in violation of ABI conventions and cause data to be copied in the wrong direction during signal handling in the Linux kernel, which might allow context-dependent attackers to trigger memory corruption. NOTE: this issue was originally reported for CPU consumption in SBCL.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=e40cd10ccff3d9fbffd57b93780bee4b7b9bff51",
        "commit_title": "The Linux kernel currently does not clear the direction flag before",
        "commit_text": "calling a signal handler, whereas the x86/x86-64 ABI requires that.  Linux had this behavior/bug forever, but this becomes a real problem with gcc version 4.3, which assumes that the direction flag is correctly cleared at the entry of a function.  This patches changes the setup_frame() functions to clear the direction before entering the signal handler.  ",
        "func_before": "static int setup_rt_frame(int sig, struct k_sigaction *ka, siginfo_t *info,\n\t\t\t   sigset_t *set, struct pt_regs * regs)\n{\n\tvoid __user *restorer;\n\tstruct rt_sigframe __user *frame;\n\tint err = 0;\n\tint usig;\n\n\tframe = get_sigframe(ka, regs, sizeof(*frame));\n\n\tif (!access_ok(VERIFY_WRITE, frame, sizeof(*frame)))\n\t\tgoto give_sigsegv;\n\n\tusig = current_thread_info()->exec_domain\n\t\t&& current_thread_info()->exec_domain->signal_invmap\n\t\t&& sig < 32\n\t\t? current_thread_info()->exec_domain->signal_invmap[sig]\n\t\t: sig;\n\n\terr |= __put_user(usig, &frame->sig);\n\terr |= __put_user(&frame->info, &frame->pinfo);\n\terr |= __put_user(&frame->uc, &frame->puc);\n\terr |= copy_siginfo_to_user(&frame->info, info);\n\tif (err)\n\t\tgoto give_sigsegv;\n\n\t/* Create the ucontext.  */\n\terr |= __put_user(0, &frame->uc.uc_flags);\n\terr |= __put_user(0, &frame->uc.uc_link);\n\terr |= __put_user(current->sas_ss_sp, &frame->uc.uc_stack.ss_sp);\n\terr |= __put_user(sas_ss_flags(regs->sp),\n\t\t\t  &frame->uc.uc_stack.ss_flags);\n\terr |= __put_user(current->sas_ss_size, &frame->uc.uc_stack.ss_size);\n\terr |= setup_sigcontext(&frame->uc.uc_mcontext, &frame->fpstate,\n\t\t\t        regs, set->sig[0]);\n\terr |= __copy_to_user(&frame->uc.uc_sigmask, set, sizeof(*set));\n\tif (err)\n\t\tgoto give_sigsegv;\n\n\t/* Set up to return from userspace.  */\n\trestorer = VDSO32_SYMBOL(current->mm->context.vdso, rt_sigreturn);\n\tif (ka->sa.sa_flags & SA_RESTORER)\n\t\trestorer = ka->sa.sa_restorer;\n\terr |= __put_user(restorer, &frame->pretcode);\n\t \n\t/*\n\t * This is movl $,%ax ; int $0x80\n\t *\n\t * WE DO NOT USE IT ANY MORE! It's only left here for historical\n\t * reasons and because gdb uses it as a signature to notice\n\t * signal handler stack frames.\n\t */\n\terr |= __put_user(0xb8, (char __user *)(frame->retcode+0));\n\terr |= __put_user(__NR_rt_sigreturn, (int __user *)(frame->retcode+1));\n\terr |= __put_user(0x80cd, (short __user *)(frame->retcode+5));\n\n\tif (err)\n\t\tgoto give_sigsegv;\n\n\t/* Set up registers for signal handler */\n\tregs->sp = (unsigned long) frame;\n\tregs->ip = (unsigned long) ka->sa.sa_handler;\n\tregs->ax = (unsigned long) usig;\n\tregs->dx = (unsigned long) &frame->info;\n\tregs->cx = (unsigned long) &frame->uc;\n\n\tregs->ds = __USER_DS;\n\tregs->es = __USER_DS;\n\tregs->ss = __USER_DS;\n\tregs->cs = __USER_CS;\n\n\t/*\n\t * Clear TF when entering the signal handler, but\n\t * notify any tracer that was single-stepping it.\n\t * The tracer may want to single-step inside the\n\t * handler too.\n\t */\n\tregs->flags &= ~TF_MASK;\n\tif (test_thread_flag(TIF_SINGLESTEP))\n\t\tptrace_notify(SIGTRAP);\n\n#if DEBUG_SIG\n\tprintk(\"SIG deliver (%s:%d): sp=%p pc=%p ra=%p\\n\",\n\t\tcurrent->comm, current->pid, frame, regs->ip, frame->pretcode);\n#endif\n\n\treturn 0;\n\ngive_sigsegv:\n\tforce_sigsegv(sig, current);\n\treturn -EFAULT;\n}",
        "func": "static int setup_rt_frame(int sig, struct k_sigaction *ka, siginfo_t *info,\n\t\t\t   sigset_t *set, struct pt_regs * regs)\n{\n\tvoid __user *restorer;\n\tstruct rt_sigframe __user *frame;\n\tint err = 0;\n\tint usig;\n\n\tframe = get_sigframe(ka, regs, sizeof(*frame));\n\n\tif (!access_ok(VERIFY_WRITE, frame, sizeof(*frame)))\n\t\tgoto give_sigsegv;\n\n\tusig = current_thread_info()->exec_domain\n\t\t&& current_thread_info()->exec_domain->signal_invmap\n\t\t&& sig < 32\n\t\t? current_thread_info()->exec_domain->signal_invmap[sig]\n\t\t: sig;\n\n\terr |= __put_user(usig, &frame->sig);\n\terr |= __put_user(&frame->info, &frame->pinfo);\n\terr |= __put_user(&frame->uc, &frame->puc);\n\terr |= copy_siginfo_to_user(&frame->info, info);\n\tif (err)\n\t\tgoto give_sigsegv;\n\n\t/* Create the ucontext.  */\n\terr |= __put_user(0, &frame->uc.uc_flags);\n\terr |= __put_user(0, &frame->uc.uc_link);\n\terr |= __put_user(current->sas_ss_sp, &frame->uc.uc_stack.ss_sp);\n\terr |= __put_user(sas_ss_flags(regs->sp),\n\t\t\t  &frame->uc.uc_stack.ss_flags);\n\terr |= __put_user(current->sas_ss_size, &frame->uc.uc_stack.ss_size);\n\terr |= setup_sigcontext(&frame->uc.uc_mcontext, &frame->fpstate,\n\t\t\t        regs, set->sig[0]);\n\terr |= __copy_to_user(&frame->uc.uc_sigmask, set, sizeof(*set));\n\tif (err)\n\t\tgoto give_sigsegv;\n\n\t/* Set up to return from userspace.  */\n\trestorer = VDSO32_SYMBOL(current->mm->context.vdso, rt_sigreturn);\n\tif (ka->sa.sa_flags & SA_RESTORER)\n\t\trestorer = ka->sa.sa_restorer;\n\terr |= __put_user(restorer, &frame->pretcode);\n\t \n\t/*\n\t * This is movl $,%ax ; int $0x80\n\t *\n\t * WE DO NOT USE IT ANY MORE! It's only left here for historical\n\t * reasons and because gdb uses it as a signature to notice\n\t * signal handler stack frames.\n\t */\n\terr |= __put_user(0xb8, (char __user *)(frame->retcode+0));\n\terr |= __put_user(__NR_rt_sigreturn, (int __user *)(frame->retcode+1));\n\terr |= __put_user(0x80cd, (short __user *)(frame->retcode+5));\n\n\tif (err)\n\t\tgoto give_sigsegv;\n\n\t/* Set up registers for signal handler */\n\tregs->sp = (unsigned long) frame;\n\tregs->ip = (unsigned long) ka->sa.sa_handler;\n\tregs->ax = (unsigned long) usig;\n\tregs->dx = (unsigned long) &frame->info;\n\tregs->cx = (unsigned long) &frame->uc;\n\n\tregs->ds = __USER_DS;\n\tregs->es = __USER_DS;\n\tregs->ss = __USER_DS;\n\tregs->cs = __USER_CS;\n\n\t/*\n\t * Clear TF when entering the signal handler, but\n\t * notify any tracer that was single-stepping it.\n\t * The tracer may want to single-step inside the\n\t * handler too.\n\t */\n\tregs->flags &= ~(TF_MASK | X86_EFLAGS_DF);\n\tif (test_thread_flag(TIF_SINGLESTEP))\n\t\tptrace_notify(SIGTRAP);\n\n#if DEBUG_SIG\n\tprintk(\"SIG deliver (%s:%d): sp=%p pc=%p ra=%p\\n\",\n\t\tcurrent->comm, current->pid, frame, regs->ip, frame->pretcode);\n#endif\n\n\treturn 0;\n\ngive_sigsegv:\n\tforce_sigsegv(sig, current);\n\treturn -EFAULT;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -75,7 +75,7 @@\n \t * The tracer may want to single-step inside the\n \t * handler too.\n \t */\n-\tregs->flags &= ~TF_MASK;\n+\tregs->flags &= ~(TF_MASK | X86_EFLAGS_DF);\n \tif (test_thread_flag(TIF_SINGLESTEP))\n \t\tptrace_notify(SIGTRAP);\n ",
        "diff_line_info": {
            "deleted_lines": [
                "\tregs->flags &= ~TF_MASK;"
            ],
            "added_lines": [
                "\tregs->flags &= ~(TF_MASK | X86_EFLAGS_DF);"
            ]
        }
    },
    {
        "cve_id": "CVE-2008-1367",
        "func_name": "torvalds/linux/setup_rt_frame",
        "description": "gcc 4.3.x does not generate a cld instruction while compiling functions used for string manipulation such as memcpy and memmove on x86 and i386, which can prevent the direction flag (DF) from being reset in violation of ABI conventions and cause data to be copied in the wrong direction during signal handling in the Linux kernel, which might allow context-dependent attackers to trigger memory corruption. NOTE: this issue was originally reported for CPU consumption in SBCL.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=e40cd10ccff3d9fbffd57b93780bee4b7b9bff51",
        "commit_title": "The Linux kernel currently does not clear the direction flag before",
        "commit_text": "calling a signal handler, whereas the x86/x86-64 ABI requires that.  Linux had this behavior/bug forever, but this becomes a real problem with gcc version 4.3, which assumes that the direction flag is correctly cleared at the entry of a function.  This patches changes the setup_frame() functions to clear the direction before entering the signal handler.  ",
        "func_before": "static int setup_rt_frame(int sig, struct k_sigaction *ka, siginfo_t *info,\n\t\t\t   sigset_t *set, struct pt_regs * regs)\n{\n\tstruct rt_sigframe __user *frame;\n\tstruct _fpstate __user *fp = NULL; \n\tint err = 0;\n\tstruct task_struct *me = current;\n\n\tif (used_math()) {\n\t\tfp = get_stack(ka, regs, sizeof(struct _fpstate)); \n\t\tframe = (void __user *)round_down(\n\t\t\t(unsigned long)fp - sizeof(struct rt_sigframe), 16) - 8;\n\n\t\tif (!access_ok(VERIFY_WRITE, fp, sizeof(struct _fpstate)))\n\t\t\tgoto give_sigsegv;\n\n\t\tif (save_i387(fp) < 0) \n\t\t\terr |= -1; \n\t} else\n\t\tframe = get_stack(ka, regs, sizeof(struct rt_sigframe)) - 8;\n\n\tif (!access_ok(VERIFY_WRITE, frame, sizeof(*frame)))\n\t\tgoto give_sigsegv;\n\n\tif (ka->sa.sa_flags & SA_SIGINFO) { \n\t\terr |= copy_siginfo_to_user(&frame->info, info);\n\t\tif (err)\n\t\t\tgoto give_sigsegv;\n\t}\n\t\t\n\t/* Create the ucontext.  */\n\terr |= __put_user(0, &frame->uc.uc_flags);\n\terr |= __put_user(0, &frame->uc.uc_link);\n\terr |= __put_user(me->sas_ss_sp, &frame->uc.uc_stack.ss_sp);\n\terr |= __put_user(sas_ss_flags(regs->sp),\n\t\t\t  &frame->uc.uc_stack.ss_flags);\n\terr |= __put_user(me->sas_ss_size, &frame->uc.uc_stack.ss_size);\n\terr |= setup_sigcontext(&frame->uc.uc_mcontext, regs, set->sig[0], me);\n\terr |= __put_user(fp, &frame->uc.uc_mcontext.fpstate);\n\tif (sizeof(*set) == 16) { \n\t\t__put_user(set->sig[0], &frame->uc.uc_sigmask.sig[0]);\n\t\t__put_user(set->sig[1], &frame->uc.uc_sigmask.sig[1]); \n\t} else\n\t\terr |= __copy_to_user(&frame->uc.uc_sigmask, set, sizeof(*set));\n\n\t/* Set up to return from userspace.  If provided, use a stub\n\t   already in userspace.  */\n\t/* x86-64 should always use SA_RESTORER. */\n\tif (ka->sa.sa_flags & SA_RESTORER) {\n\t\terr |= __put_user(ka->sa.sa_restorer, &frame->pretcode);\n\t} else {\n\t\t/* could use a vstub here */\n\t\tgoto give_sigsegv; \n\t}\n\n\tif (err)\n\t\tgoto give_sigsegv;\n\n#ifdef DEBUG_SIG\n\tprintk(\"%d old ip %lx old sp %lx old ax %lx\\n\", current->pid,regs->ip,regs->sp,regs->ax);\n#endif\n\n\t/* Set up registers for signal handler */\n\tregs->di = sig;\n\t/* In case the signal handler was declared without prototypes */ \n\tregs->ax = 0;\n\n\t/* This also works for non SA_SIGINFO handlers because they expect the\n\t   next argument after the signal number on the stack. */\n\tregs->si = (unsigned long)&frame->info;\n\tregs->dx = (unsigned long)&frame->uc;\n\tregs->ip = (unsigned long) ka->sa.sa_handler;\n\n\tregs->sp = (unsigned long)frame;\n\n\t/* Set up the CS register to run signal handlers in 64-bit mode,\n\t   even if the handler happens to be interrupting 32-bit code. */\n\tregs->cs = __USER_CS;\n\n\t/* This, by contrast, has nothing to do with segment registers -\n\t   see include/asm-x86_64/uaccess.h for details. */\n\tset_fs(USER_DS);\n\n\tregs->flags &= ~X86_EFLAGS_TF;\n\tif (test_thread_flag(TIF_SINGLESTEP))\n\t\tptrace_notify(SIGTRAP);\n#ifdef DEBUG_SIG\n\tprintk(\"SIG deliver (%s:%d): sp=%p pc=%lx ra=%p\\n\",\n\t\tcurrent->comm, current->pid, frame, regs->ip, frame->pretcode);\n#endif\n\n\treturn 0;\n\ngive_sigsegv:\n\tforce_sigsegv(sig, current);\n\treturn -EFAULT;\n}",
        "func": "static int setup_rt_frame(int sig, struct k_sigaction *ka, siginfo_t *info,\n\t\t\t   sigset_t *set, struct pt_regs * regs)\n{\n\tstruct rt_sigframe __user *frame;\n\tstruct _fpstate __user *fp = NULL; \n\tint err = 0;\n\tstruct task_struct *me = current;\n\n\tif (used_math()) {\n\t\tfp = get_stack(ka, regs, sizeof(struct _fpstate)); \n\t\tframe = (void __user *)round_down(\n\t\t\t(unsigned long)fp - sizeof(struct rt_sigframe), 16) - 8;\n\n\t\tif (!access_ok(VERIFY_WRITE, fp, sizeof(struct _fpstate)))\n\t\t\tgoto give_sigsegv;\n\n\t\tif (save_i387(fp) < 0) \n\t\t\terr |= -1; \n\t} else\n\t\tframe = get_stack(ka, regs, sizeof(struct rt_sigframe)) - 8;\n\n\tif (!access_ok(VERIFY_WRITE, frame, sizeof(*frame)))\n\t\tgoto give_sigsegv;\n\n\tif (ka->sa.sa_flags & SA_SIGINFO) { \n\t\terr |= copy_siginfo_to_user(&frame->info, info);\n\t\tif (err)\n\t\t\tgoto give_sigsegv;\n\t}\n\t\t\n\t/* Create the ucontext.  */\n\terr |= __put_user(0, &frame->uc.uc_flags);\n\terr |= __put_user(0, &frame->uc.uc_link);\n\terr |= __put_user(me->sas_ss_sp, &frame->uc.uc_stack.ss_sp);\n\terr |= __put_user(sas_ss_flags(regs->sp),\n\t\t\t  &frame->uc.uc_stack.ss_flags);\n\terr |= __put_user(me->sas_ss_size, &frame->uc.uc_stack.ss_size);\n\terr |= setup_sigcontext(&frame->uc.uc_mcontext, regs, set->sig[0], me);\n\terr |= __put_user(fp, &frame->uc.uc_mcontext.fpstate);\n\tif (sizeof(*set) == 16) { \n\t\t__put_user(set->sig[0], &frame->uc.uc_sigmask.sig[0]);\n\t\t__put_user(set->sig[1], &frame->uc.uc_sigmask.sig[1]); \n\t} else\n\t\terr |= __copy_to_user(&frame->uc.uc_sigmask, set, sizeof(*set));\n\n\t/* Set up to return from userspace.  If provided, use a stub\n\t   already in userspace.  */\n\t/* x86-64 should always use SA_RESTORER. */\n\tif (ka->sa.sa_flags & SA_RESTORER) {\n\t\terr |= __put_user(ka->sa.sa_restorer, &frame->pretcode);\n\t} else {\n\t\t/* could use a vstub here */\n\t\tgoto give_sigsegv; \n\t}\n\n\tif (err)\n\t\tgoto give_sigsegv;\n\n#ifdef DEBUG_SIG\n\tprintk(\"%d old ip %lx old sp %lx old ax %lx\\n\", current->pid,regs->ip,regs->sp,regs->ax);\n#endif\n\n\t/* Set up registers for signal handler */\n\tregs->di = sig;\n\t/* In case the signal handler was declared without prototypes */ \n\tregs->ax = 0;\n\n\t/* This also works for non SA_SIGINFO handlers because they expect the\n\t   next argument after the signal number on the stack. */\n\tregs->si = (unsigned long)&frame->info;\n\tregs->dx = (unsigned long)&frame->uc;\n\tregs->ip = (unsigned long) ka->sa.sa_handler;\n\n\tregs->sp = (unsigned long)frame;\n\n\t/* Set up the CS register to run signal handlers in 64-bit mode,\n\t   even if the handler happens to be interrupting 32-bit code. */\n\tregs->cs = __USER_CS;\n\n\t/* This, by contrast, has nothing to do with segment registers -\n\t   see include/asm-x86_64/uaccess.h for details. */\n\tset_fs(USER_DS);\n\n\tregs->flags &= ~(X86_EFLAGS_TF | X86_EFLAGS_DF);\n\tif (test_thread_flag(TIF_SINGLESTEP))\n\t\tptrace_notify(SIGTRAP);\n#ifdef DEBUG_SIG\n\tprintk(\"SIG deliver (%s:%d): sp=%p pc=%lx ra=%p\\n\",\n\t\tcurrent->comm, current->pid, frame, regs->ip, frame->pretcode);\n#endif\n\n\treturn 0;\n\ngive_sigsegv:\n\tforce_sigsegv(sig, current);\n\treturn -EFAULT;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -81,7 +81,7 @@\n \t   see include/asm-x86_64/uaccess.h for details. */\n \tset_fs(USER_DS);\n \n-\tregs->flags &= ~X86_EFLAGS_TF;\n+\tregs->flags &= ~(X86_EFLAGS_TF | X86_EFLAGS_DF);\n \tif (test_thread_flag(TIF_SINGLESTEP))\n \t\tptrace_notify(SIGTRAP);\n #ifdef DEBUG_SIG",
        "diff_line_info": {
            "deleted_lines": [
                "\tregs->flags &= ~X86_EFLAGS_TF;"
            ],
            "added_lines": [
                "\tregs->flags &= ~(X86_EFLAGS_TF | X86_EFLAGS_DF);"
            ]
        }
    },
    {
        "cve_id": "CVE-2008-1514",
        "func_name": "torvalds/linux/__poke_user",
        "description": "arch/s390/kernel/ptrace.c in Linux kernel 2.6.9, and other versions before 2.6.27-rc6, on s390 platforms allows local users to cause a denial of service (kernel panic) via the user-area-padding test from the ptrace testsuite in 31-bit mode, which triggers an invalid dereference.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=3d6e48f43340343d97839eadb1ab7b6a3ea98797",
        "commit_title": "When running a 31-bit ptrace, on either an s390 or s390x kernel,",
        "commit_text": "reads and writes into a padding area in struct user_regs_struct32 will result in a kernel panic.  This is also known as CVE-2008-1514.  Test case available here: http://sources.redhat.com/cgi-bin/cvsweb.cgi/~checkout~/tests/ptrace-tests/tests/user-area-padding.c?cvsroot=systemtap  Steps to reproduce: 1) wget the above 2) gcc -o user-area-padding-31bit user-area-padding.c -Wall -ggdb2 -D_GNU_SOURCE -m31 3) ./user-area-padding-31bit <panic>  Test status ----------- Without patch, both s390 and s390x kernels panic. With patch, the test case, as well as the gdb testsuite, pass without incident, padding area reads returning zero, writes ignored.  Nb: original version returned -EINVAL on write attempts, which broke the gdb test and made the test case slightly unhappy, Jan Kratochvil suggested the change to return 0 on write attempts.  ",
        "func_before": "static int __poke_user(struct task_struct *child, addr_t addr, addr_t data)\n{\n\tstruct user *dummy = NULL;\n\taddr_t offset;\n\n\tif (addr < (addr_t) &dummy->regs.acrs) {\n\t\t/*\n\t\t * psw and gprs are stored on the stack\n\t\t */\n\t\tif (addr == (addr_t) &dummy->regs.psw.mask &&\n#ifdef CONFIG_COMPAT\n\t\t    data != PSW_MASK_MERGE(psw_user32_bits, data) &&\n#endif\n\t\t    data != PSW_MASK_MERGE(psw_user_bits, data))\n\t\t\t/* Invalid psw mask. */\n\t\t\treturn -EINVAL;\n#ifndef CONFIG_64BIT\n\t\tif (addr == (addr_t) &dummy->regs.psw.addr)\n\t\t\t/* I'd like to reject addresses without the\n\t\t\t   high order bit but older gdb's rely on it */\n\t\t\tdata |= PSW_ADDR_AMODE;\n#endif\n\t\t*(addr_t *)((addr_t) &task_pt_regs(child)->psw + addr) = data;\n\n\t} else if (addr < (addr_t) (&dummy->regs.orig_gpr2)) {\n\t\t/*\n\t\t * access registers are stored in the thread structure\n\t\t */\n\t\toffset = addr - (addr_t) &dummy->regs.acrs;\n#ifdef CONFIG_64BIT\n\t\t/*\n\t\t * Very special case: old & broken 64 bit gdb writing\n\t\t * to acrs[15] with a 64 bit value. Ignore the lower\n\t\t * half of the value and write the upper 32 bit to\n\t\t * acrs[15]. Sick...\n\t\t */\n\t\tif (addr == (addr_t) &dummy->regs.acrs[15])\n\t\t\tchild->thread.acrs[15] = (unsigned int) (data >> 32);\n\t\telse\n#endif\n\t\t*(addr_t *)((addr_t) &child->thread.acrs + offset) = data;\n\n\t} else if (addr == (addr_t) &dummy->regs.orig_gpr2) {\n\t\t/*\n\t\t * orig_gpr2 is stored on the kernel stack\n\t\t */\n\t\ttask_pt_regs(child)->orig_gpr2 = data;\n\n\t} else if (addr < (addr_t) (&dummy->regs.fp_regs + 1)) {\n\t\t/*\n\t\t * floating point regs. are stored in the thread structure\n\t\t */\n\t\tif (addr == (addr_t) &dummy->regs.fp_regs.fpc &&\n\t\t    (data & ~((unsigned long) FPC_VALID_MASK\n\t\t\t      << (BITS_PER_LONG - 32))) != 0)\n\t\t\treturn -EINVAL;\n\t\toffset = addr - (addr_t) &dummy->regs.fp_regs;\n\t\t*(addr_t *)((addr_t) &child->thread.fp_regs + offset) = data;\n\n\t} else if (addr < (addr_t) (&dummy->regs.per_info + 1)) {\n\t\t/*\n\t\t * per_info is found in the thread structure \n\t\t */\n\t\toffset = addr - (addr_t) &dummy->regs.per_info;\n\t\t*(addr_t *)((addr_t) &child->thread.per_info + offset) = data;\n\n\t}\n\n\tFixPerRegisters(child);\n\treturn 0;\n}",
        "func": "static int __poke_user(struct task_struct *child, addr_t addr, addr_t data)\n{\n\tstruct user *dummy = NULL;\n\taddr_t offset;\n\n\tif (addr < (addr_t) &dummy->regs.acrs) {\n\t\t/*\n\t\t * psw and gprs are stored on the stack\n\t\t */\n\t\tif (addr == (addr_t) &dummy->regs.psw.mask &&\n#ifdef CONFIG_COMPAT\n\t\t    data != PSW_MASK_MERGE(psw_user32_bits, data) &&\n#endif\n\t\t    data != PSW_MASK_MERGE(psw_user_bits, data))\n\t\t\t/* Invalid psw mask. */\n\t\t\treturn -EINVAL;\n#ifndef CONFIG_64BIT\n\t\tif (addr == (addr_t) &dummy->regs.psw.addr)\n\t\t\t/* I'd like to reject addresses without the\n\t\t\t   high order bit but older gdb's rely on it */\n\t\t\tdata |= PSW_ADDR_AMODE;\n#endif\n\t\t*(addr_t *)((addr_t) &task_pt_regs(child)->psw + addr) = data;\n\n\t} else if (addr < (addr_t) (&dummy->regs.orig_gpr2)) {\n\t\t/*\n\t\t * access registers are stored in the thread structure\n\t\t */\n\t\toffset = addr - (addr_t) &dummy->regs.acrs;\n#ifdef CONFIG_64BIT\n\t\t/*\n\t\t * Very special case: old & broken 64 bit gdb writing\n\t\t * to acrs[15] with a 64 bit value. Ignore the lower\n\t\t * half of the value and write the upper 32 bit to\n\t\t * acrs[15]. Sick...\n\t\t */\n\t\tif (addr == (addr_t) &dummy->regs.acrs[15])\n\t\t\tchild->thread.acrs[15] = (unsigned int) (data >> 32);\n\t\telse\n#endif\n\t\t*(addr_t *)((addr_t) &child->thread.acrs + offset) = data;\n\n\t} else if (addr == (addr_t) &dummy->regs.orig_gpr2) {\n\t\t/*\n\t\t * orig_gpr2 is stored on the kernel stack\n\t\t */\n\t\ttask_pt_regs(child)->orig_gpr2 = data;\n\n\t} else if (addr < (addr_t) &dummy->regs.fp_regs) {\n\t\t/*\n\t\t * prevent writes of padding hole between\n\t\t * orig_gpr2 and fp_regs on s390.\n\t\t */\n\t\treturn 0;\n\n\t} else if (addr < (addr_t) (&dummy->regs.fp_regs + 1)) {\n\t\t/*\n\t\t * floating point regs. are stored in the thread structure\n\t\t */\n\t\tif (addr == (addr_t) &dummy->regs.fp_regs.fpc &&\n\t\t    (data & ~((unsigned long) FPC_VALID_MASK\n\t\t\t      << (BITS_PER_LONG - 32))) != 0)\n\t\t\treturn -EINVAL;\n\t\toffset = addr - (addr_t) &dummy->regs.fp_regs;\n\t\t*(addr_t *)((addr_t) &child->thread.fp_regs + offset) = data;\n\n\t} else if (addr < (addr_t) (&dummy->regs.per_info + 1)) {\n\t\t/*\n\t\t * per_info is found in the thread structure \n\t\t */\n\t\toffset = addr - (addr_t) &dummy->regs.per_info;\n\t\t*(addr_t *)((addr_t) &child->thread.per_info + offset) = data;\n\n\t}\n\n\tFixPerRegisters(child);\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -46,6 +46,13 @@\n \t\t */\n \t\ttask_pt_regs(child)->orig_gpr2 = data;\n \n+\t} else if (addr < (addr_t) &dummy->regs.fp_regs) {\n+\t\t/*\n+\t\t * prevent writes of padding hole between\n+\t\t * orig_gpr2 and fp_regs on s390.\n+\t\t */\n+\t\treturn 0;\n+\n \t} else if (addr < (addr_t) (&dummy->regs.fp_regs + 1)) {\n \t\t/*\n \t\t * floating point regs. are stored in the thread structure",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t} else if (addr < (addr_t) &dummy->regs.fp_regs) {",
                "\t\t/*",
                "\t\t * prevent writes of padding hole between",
                "\t\t * orig_gpr2 and fp_regs on s390.",
                "\t\t */",
                "\t\treturn 0;",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2008-1514",
        "func_name": "torvalds/linux/__peek_user_compat",
        "description": "arch/s390/kernel/ptrace.c in Linux kernel 2.6.9, and other versions before 2.6.27-rc6, on s390 platforms allows local users to cause a denial of service (kernel panic) via the user-area-padding test from the ptrace testsuite in 31-bit mode, which triggers an invalid dereference.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=3d6e48f43340343d97839eadb1ab7b6a3ea98797",
        "commit_title": "When running a 31-bit ptrace, on either an s390 or s390x kernel,",
        "commit_text": "reads and writes into a padding area in struct user_regs_struct32 will result in a kernel panic.  This is also known as CVE-2008-1514.  Test case available here: http://sources.redhat.com/cgi-bin/cvsweb.cgi/~checkout~/tests/ptrace-tests/tests/user-area-padding.c?cvsroot=systemtap  Steps to reproduce: 1) wget the above 2) gcc -o user-area-padding-31bit user-area-padding.c -Wall -ggdb2 -D_GNU_SOURCE -m31 3) ./user-area-padding-31bit <panic>  Test status ----------- Without patch, both s390 and s390x kernels panic. With patch, the test case, as well as the gdb testsuite, pass without incident, padding area reads returning zero, writes ignored.  Nb: original version returned -EINVAL on write attempts, which broke the gdb test and made the test case slightly unhappy, Jan Kratochvil suggested the change to return 0 on write attempts.  ",
        "func_before": "static u32 __peek_user_compat(struct task_struct *child, addr_t addr)\n{\n\tstruct user32 *dummy32 = NULL;\n\tper_struct32 *dummy_per32 = NULL;\n\taddr_t offset;\n\t__u32 tmp;\n\n\tif (addr < (addr_t) &dummy32->regs.acrs) {\n\t\t/*\n\t\t * psw and gprs are stored on the stack\n\t\t */\n\t\tif (addr == (addr_t) &dummy32->regs.psw.mask) {\n\t\t\t/* Fake a 31 bit psw mask. */\n\t\t\ttmp = (__u32)(task_pt_regs(child)->psw.mask >> 32);\n\t\t\ttmp = PSW32_MASK_MERGE(psw32_user_bits, tmp);\n\t\t} else if (addr == (addr_t) &dummy32->regs.psw.addr) {\n\t\t\t/* Fake a 31 bit psw address. */\n\t\t\ttmp = (__u32) task_pt_regs(child)->psw.addr |\n\t\t\t\tPSW32_ADDR_AMODE31;\n\t\t} else {\n\t\t\t/* gpr 0-15 */\n\t\t\ttmp = *(__u32 *)((addr_t) &task_pt_regs(child)->psw +\n\t\t\t\t\t addr*2 + 4);\n\t\t}\n\t} else if (addr < (addr_t) (&dummy32->regs.orig_gpr2)) {\n\t\t/*\n\t\t * access registers are stored in the thread structure\n\t\t */\n\t\toffset = addr - (addr_t) &dummy32->regs.acrs;\n\t\ttmp = *(__u32*)((addr_t) &child->thread.acrs + offset);\n\n\t} else if (addr == (addr_t) (&dummy32->regs.orig_gpr2)) {\n\t\t/*\n\t\t * orig_gpr2 is stored on the kernel stack\n\t\t */\n\t\ttmp = *(__u32*)((addr_t) &task_pt_regs(child)->orig_gpr2 + 4);\n\n\t} else if (addr < (addr_t) (&dummy32->regs.fp_regs + 1)) {\n\t\t/*\n\t\t * floating point regs. are stored in the thread structure \n\t\t */\n\t        offset = addr - (addr_t) &dummy32->regs.fp_regs;\n\t\ttmp = *(__u32 *)((addr_t) &child->thread.fp_regs + offset);\n\n\t} else if (addr < (addr_t) (&dummy32->regs.per_info + 1)) {\n\t\t/*\n\t\t * per_info is found in the thread structure\n\t\t */\n\t\toffset = addr - (addr_t) &dummy32->regs.per_info;\n\t\t/* This is magic. See per_struct and per_struct32. */\n\t\tif ((offset >= (addr_t) &dummy_per32->control_regs &&\n\t\t     offset < (addr_t) (&dummy_per32->control_regs + 1)) ||\n\t\t    (offset >= (addr_t) &dummy_per32->starting_addr &&\n\t\t     offset <= (addr_t) &dummy_per32->ending_addr) ||\n\t\t    offset == (addr_t) &dummy_per32->lowcore.words.address)\n\t\t\toffset = offset*2 + 4;\n\t\telse\n\t\t\toffset = offset*2;\n\t\ttmp = *(__u32 *)((addr_t) &child->thread.per_info + offset);\n\n\t} else\n\t\ttmp = 0;\n\n\treturn tmp;\n}",
        "func": "static u32 __peek_user_compat(struct task_struct *child, addr_t addr)\n{\n\tstruct user32 *dummy32 = NULL;\n\tper_struct32 *dummy_per32 = NULL;\n\taddr_t offset;\n\t__u32 tmp;\n\n\tif (addr < (addr_t) &dummy32->regs.acrs) {\n\t\t/*\n\t\t * psw and gprs are stored on the stack\n\t\t */\n\t\tif (addr == (addr_t) &dummy32->regs.psw.mask) {\n\t\t\t/* Fake a 31 bit psw mask. */\n\t\t\ttmp = (__u32)(task_pt_regs(child)->psw.mask >> 32);\n\t\t\ttmp = PSW32_MASK_MERGE(psw32_user_bits, tmp);\n\t\t} else if (addr == (addr_t) &dummy32->regs.psw.addr) {\n\t\t\t/* Fake a 31 bit psw address. */\n\t\t\ttmp = (__u32) task_pt_regs(child)->psw.addr |\n\t\t\t\tPSW32_ADDR_AMODE31;\n\t\t} else {\n\t\t\t/* gpr 0-15 */\n\t\t\ttmp = *(__u32 *)((addr_t) &task_pt_regs(child)->psw +\n\t\t\t\t\t addr*2 + 4);\n\t\t}\n\t} else if (addr < (addr_t) (&dummy32->regs.orig_gpr2)) {\n\t\t/*\n\t\t * access registers are stored in the thread structure\n\t\t */\n\t\toffset = addr - (addr_t) &dummy32->regs.acrs;\n\t\ttmp = *(__u32*)((addr_t) &child->thread.acrs + offset);\n\n\t} else if (addr == (addr_t) (&dummy32->regs.orig_gpr2)) {\n\t\t/*\n\t\t * orig_gpr2 is stored on the kernel stack\n\t\t */\n\t\ttmp = *(__u32*)((addr_t) &task_pt_regs(child)->orig_gpr2 + 4);\n\n\t} else if (addr < (addr_t) &dummy32->regs.fp_regs) {\n\t\t/*\n\t\t * prevent reads of padding hole between\n\t\t * orig_gpr2 and fp_regs on s390.\n\t\t */\n\t\ttmp = 0;\n\n\t} else if (addr < (addr_t) (&dummy32->regs.fp_regs + 1)) {\n\t\t/*\n\t\t * floating point regs. are stored in the thread structure \n\t\t */\n\t        offset = addr - (addr_t) &dummy32->regs.fp_regs;\n\t\ttmp = *(__u32 *)((addr_t) &child->thread.fp_regs + offset);\n\n\t} else if (addr < (addr_t) (&dummy32->regs.per_info + 1)) {\n\t\t/*\n\t\t * per_info is found in the thread structure\n\t\t */\n\t\toffset = addr - (addr_t) &dummy32->regs.per_info;\n\t\t/* This is magic. See per_struct and per_struct32. */\n\t\tif ((offset >= (addr_t) &dummy_per32->control_regs &&\n\t\t     offset < (addr_t) (&dummy_per32->control_regs + 1)) ||\n\t\t    (offset >= (addr_t) &dummy_per32->starting_addr &&\n\t\t     offset <= (addr_t) &dummy_per32->ending_addr) ||\n\t\t    offset == (addr_t) &dummy_per32->lowcore.words.address)\n\t\t\toffset = offset*2 + 4;\n\t\telse\n\t\t\toffset = offset*2;\n\t\ttmp = *(__u32 *)((addr_t) &child->thread.per_info + offset);\n\n\t} else\n\t\ttmp = 0;\n\n\treturn tmp;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -35,6 +35,13 @@\n \t\t */\n \t\ttmp = *(__u32*)((addr_t) &task_pt_regs(child)->orig_gpr2 + 4);\n \n+\t} else if (addr < (addr_t) &dummy32->regs.fp_regs) {\n+\t\t/*\n+\t\t * prevent reads of padding hole between\n+\t\t * orig_gpr2 and fp_regs on s390.\n+\t\t */\n+\t\ttmp = 0;\n+\n \t} else if (addr < (addr_t) (&dummy32->regs.fp_regs + 1)) {\n \t\t/*\n \t\t * floating point regs. are stored in the thread structure ",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t} else if (addr < (addr_t) &dummy32->regs.fp_regs) {",
                "\t\t/*",
                "\t\t * prevent reads of padding hole between",
                "\t\t * orig_gpr2 and fp_regs on s390.",
                "\t\t */",
                "\t\ttmp = 0;",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2008-1514",
        "func_name": "torvalds/linux/__poke_user_compat",
        "description": "arch/s390/kernel/ptrace.c in Linux kernel 2.6.9, and other versions before 2.6.27-rc6, on s390 platforms allows local users to cause a denial of service (kernel panic) via the user-area-padding test from the ptrace testsuite in 31-bit mode, which triggers an invalid dereference.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=3d6e48f43340343d97839eadb1ab7b6a3ea98797",
        "commit_title": "When running a 31-bit ptrace, on either an s390 or s390x kernel,",
        "commit_text": "reads and writes into a padding area in struct user_regs_struct32 will result in a kernel panic.  This is also known as CVE-2008-1514.  Test case available here: http://sources.redhat.com/cgi-bin/cvsweb.cgi/~checkout~/tests/ptrace-tests/tests/user-area-padding.c?cvsroot=systemtap  Steps to reproduce: 1) wget the above 2) gcc -o user-area-padding-31bit user-area-padding.c -Wall -ggdb2 -D_GNU_SOURCE -m31 3) ./user-area-padding-31bit <panic>  Test status ----------- Without patch, both s390 and s390x kernels panic. With patch, the test case, as well as the gdb testsuite, pass without incident, padding area reads returning zero, writes ignored.  Nb: original version returned -EINVAL on write attempts, which broke the gdb test and made the test case slightly unhappy, Jan Kratochvil suggested the change to return 0 on write attempts.  ",
        "func_before": "static int __poke_user_compat(struct task_struct *child,\n\t\t\t      addr_t addr, addr_t data)\n{\n\tstruct user32 *dummy32 = NULL;\n\tper_struct32 *dummy_per32 = NULL;\n\t__u32 tmp = (__u32) data;\n\taddr_t offset;\n\n\tif (addr < (addr_t) &dummy32->regs.acrs) {\n\t\t/*\n\t\t * psw, gprs, acrs and orig_gpr2 are stored on the stack\n\t\t */\n\t\tif (addr == (addr_t) &dummy32->regs.psw.mask) {\n\t\t\t/* Build a 64 bit psw mask from 31 bit mask. */\n\t\t\tif (tmp != PSW32_MASK_MERGE(psw32_user_bits, tmp))\n\t\t\t\t/* Invalid psw mask. */\n\t\t\t\treturn -EINVAL;\n\t\t\ttask_pt_regs(child)->psw.mask =\n\t\t\t\tPSW_MASK_MERGE(psw_user32_bits, (__u64) tmp << 32);\n\t\t} else if (addr == (addr_t) &dummy32->regs.psw.addr) {\n\t\t\t/* Build a 64 bit psw address from 31 bit address. */\n\t\t\ttask_pt_regs(child)->psw.addr =\n\t\t\t\t(__u64) tmp & PSW32_ADDR_INSN;\n\t\t} else {\n\t\t\t/* gpr 0-15 */\n\t\t\t*(__u32*)((addr_t) &task_pt_regs(child)->psw\n\t\t\t\t  + addr*2 + 4) = tmp;\n\t\t}\n\t} else if (addr < (addr_t) (&dummy32->regs.orig_gpr2)) {\n\t\t/*\n\t\t * access registers are stored in the thread structure\n\t\t */\n\t\toffset = addr - (addr_t) &dummy32->regs.acrs;\n\t\t*(__u32*)((addr_t) &child->thread.acrs + offset) = tmp;\n\n\t} else if (addr == (addr_t) (&dummy32->regs.orig_gpr2)) {\n\t\t/*\n\t\t * orig_gpr2 is stored on the kernel stack\n\t\t */\n\t\t*(__u32*)((addr_t) &task_pt_regs(child)->orig_gpr2 + 4) = tmp;\n\n\t} else if (addr < (addr_t) (&dummy32->regs.fp_regs + 1)) {\n\t\t/*\n\t\t * floating point regs. are stored in the thread structure \n\t\t */\n\t\tif (addr == (addr_t) &dummy32->regs.fp_regs.fpc &&\n\t\t    (tmp & ~FPC_VALID_MASK) != 0)\n\t\t\t/* Invalid floating point control. */\n\t\t\treturn -EINVAL;\n\t        offset = addr - (addr_t) &dummy32->regs.fp_regs;\n\t\t*(__u32 *)((addr_t) &child->thread.fp_regs + offset) = tmp;\n\n\t} else if (addr < (addr_t) (&dummy32->regs.per_info + 1)) {\n\t\t/*\n\t\t * per_info is found in the thread structure.\n\t\t */\n\t\toffset = addr - (addr_t) &dummy32->regs.per_info;\n\t\t/*\n\t\t * This is magic. See per_struct and per_struct32.\n\t\t * By incident the offsets in per_struct are exactly\n\t\t * twice the offsets in per_struct32 for all fields.\n\t\t * The 8 byte fields need special handling though,\n\t\t * because the second half (bytes 4-7) is needed and\n\t\t * not the first half.\n\t\t */\n\t\tif ((offset >= (addr_t) &dummy_per32->control_regs &&\n\t\t     offset < (addr_t) (&dummy_per32->control_regs + 1)) ||\n\t\t    (offset >= (addr_t) &dummy_per32->starting_addr &&\n\t\t     offset <= (addr_t) &dummy_per32->ending_addr) ||\n\t\t    offset == (addr_t) &dummy_per32->lowcore.words.address)\n\t\t\toffset = offset*2 + 4;\n\t\telse\n\t\t\toffset = offset*2;\n\t\t*(__u32 *)((addr_t) &child->thread.per_info + offset) = tmp;\n\n\t}\n\n\tFixPerRegisters(child);\n\treturn 0;\n}",
        "func": "static int __poke_user_compat(struct task_struct *child,\n\t\t\t      addr_t addr, addr_t data)\n{\n\tstruct user32 *dummy32 = NULL;\n\tper_struct32 *dummy_per32 = NULL;\n\t__u32 tmp = (__u32) data;\n\taddr_t offset;\n\n\tif (addr < (addr_t) &dummy32->regs.acrs) {\n\t\t/*\n\t\t * psw, gprs, acrs and orig_gpr2 are stored on the stack\n\t\t */\n\t\tif (addr == (addr_t) &dummy32->regs.psw.mask) {\n\t\t\t/* Build a 64 bit psw mask from 31 bit mask. */\n\t\t\tif (tmp != PSW32_MASK_MERGE(psw32_user_bits, tmp))\n\t\t\t\t/* Invalid psw mask. */\n\t\t\t\treturn -EINVAL;\n\t\t\ttask_pt_regs(child)->psw.mask =\n\t\t\t\tPSW_MASK_MERGE(psw_user32_bits, (__u64) tmp << 32);\n\t\t} else if (addr == (addr_t) &dummy32->regs.psw.addr) {\n\t\t\t/* Build a 64 bit psw address from 31 bit address. */\n\t\t\ttask_pt_regs(child)->psw.addr =\n\t\t\t\t(__u64) tmp & PSW32_ADDR_INSN;\n\t\t} else {\n\t\t\t/* gpr 0-15 */\n\t\t\t*(__u32*)((addr_t) &task_pt_regs(child)->psw\n\t\t\t\t  + addr*2 + 4) = tmp;\n\t\t}\n\t} else if (addr < (addr_t) (&dummy32->regs.orig_gpr2)) {\n\t\t/*\n\t\t * access registers are stored in the thread structure\n\t\t */\n\t\toffset = addr - (addr_t) &dummy32->regs.acrs;\n\t\t*(__u32*)((addr_t) &child->thread.acrs + offset) = tmp;\n\n\t} else if (addr == (addr_t) (&dummy32->regs.orig_gpr2)) {\n\t\t/*\n\t\t * orig_gpr2 is stored on the kernel stack\n\t\t */\n\t\t*(__u32*)((addr_t) &task_pt_regs(child)->orig_gpr2 + 4) = tmp;\n\n\t} else if (addr < (addr_t) &dummy32->regs.fp_regs) {\n\t\t/*\n\t\t * prevent writess of padding hole between\n\t\t * orig_gpr2 and fp_regs on s390.\n\t\t */\n\t\treturn 0;\n\n\t} else if (addr < (addr_t) (&dummy32->regs.fp_regs + 1)) {\n\t\t/*\n\t\t * floating point regs. are stored in the thread structure \n\t\t */\n\t\tif (addr == (addr_t) &dummy32->regs.fp_regs.fpc &&\n\t\t    (tmp & ~FPC_VALID_MASK) != 0)\n\t\t\t/* Invalid floating point control. */\n\t\t\treturn -EINVAL;\n\t        offset = addr - (addr_t) &dummy32->regs.fp_regs;\n\t\t*(__u32 *)((addr_t) &child->thread.fp_regs + offset) = tmp;\n\n\t} else if (addr < (addr_t) (&dummy32->regs.per_info + 1)) {\n\t\t/*\n\t\t * per_info is found in the thread structure.\n\t\t */\n\t\toffset = addr - (addr_t) &dummy32->regs.per_info;\n\t\t/*\n\t\t * This is magic. See per_struct and per_struct32.\n\t\t * By incident the offsets in per_struct are exactly\n\t\t * twice the offsets in per_struct32 for all fields.\n\t\t * The 8 byte fields need special handling though,\n\t\t * because the second half (bytes 4-7) is needed and\n\t\t * not the first half.\n\t\t */\n\t\tif ((offset >= (addr_t) &dummy_per32->control_regs &&\n\t\t     offset < (addr_t) (&dummy_per32->control_regs + 1)) ||\n\t\t    (offset >= (addr_t) &dummy_per32->starting_addr &&\n\t\t     offset <= (addr_t) &dummy_per32->ending_addr) ||\n\t\t    offset == (addr_t) &dummy_per32->lowcore.words.address)\n\t\t\toffset = offset*2 + 4;\n\t\telse\n\t\t\toffset = offset*2;\n\t\t*(__u32 *)((addr_t) &child->thread.per_info + offset) = tmp;\n\n\t}\n\n\tFixPerRegisters(child);\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -39,6 +39,13 @@\n \t\t */\n \t\t*(__u32*)((addr_t) &task_pt_regs(child)->orig_gpr2 + 4) = tmp;\n \n+\t} else if (addr < (addr_t) &dummy32->regs.fp_regs) {\n+\t\t/*\n+\t\t * prevent writess of padding hole between\n+\t\t * orig_gpr2 and fp_regs on s390.\n+\t\t */\n+\t\treturn 0;\n+\n \t} else if (addr < (addr_t) (&dummy32->regs.fp_regs + 1)) {\n \t\t/*\n \t\t * floating point regs. are stored in the thread structure ",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t} else if (addr < (addr_t) &dummy32->regs.fp_regs) {",
                "\t\t/*",
                "\t\t * prevent writess of padding hole between",
                "\t\t * orig_gpr2 and fp_regs on s390.",
                "\t\t */",
                "\t\treturn 0;",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2008-1514",
        "func_name": "torvalds/linux/__peek_user",
        "description": "arch/s390/kernel/ptrace.c in Linux kernel 2.6.9, and other versions before 2.6.27-rc6, on s390 platforms allows local users to cause a denial of service (kernel panic) via the user-area-padding test from the ptrace testsuite in 31-bit mode, which triggers an invalid dereference.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=3d6e48f43340343d97839eadb1ab7b6a3ea98797",
        "commit_title": "When running a 31-bit ptrace, on either an s390 or s390x kernel,",
        "commit_text": "reads and writes into a padding area in struct user_regs_struct32 will result in a kernel panic.  This is also known as CVE-2008-1514.  Test case available here: http://sources.redhat.com/cgi-bin/cvsweb.cgi/~checkout~/tests/ptrace-tests/tests/user-area-padding.c?cvsroot=systemtap  Steps to reproduce: 1) wget the above 2) gcc -o user-area-padding-31bit user-area-padding.c -Wall -ggdb2 -D_GNU_SOURCE -m31 3) ./user-area-padding-31bit <panic>  Test status ----------- Without patch, both s390 and s390x kernels panic. With patch, the test case, as well as the gdb testsuite, pass without incident, padding area reads returning zero, writes ignored.  Nb: original version returned -EINVAL on write attempts, which broke the gdb test and made the test case slightly unhappy, Jan Kratochvil suggested the change to return 0 on write attempts.  ",
        "func_before": "static unsigned long __peek_user(struct task_struct *child, addr_t addr)\n{\n\tstruct user *dummy = NULL;\n\taddr_t offset, tmp;\n\n\tif (addr < (addr_t) &dummy->regs.acrs) {\n\t\t/*\n\t\t * psw and gprs are stored on the stack\n\t\t */\n\t\ttmp = *(addr_t *)((addr_t) &task_pt_regs(child)->psw + addr);\n\t\tif (addr == (addr_t) &dummy->regs.psw.mask)\n\t\t\t/* Remove per bit from user psw. */\n\t\t\ttmp &= ~PSW_MASK_PER;\n\n\t} else if (addr < (addr_t) &dummy->regs.orig_gpr2) {\n\t\t/*\n\t\t * access registers are stored in the thread structure\n\t\t */\n\t\toffset = addr - (addr_t) &dummy->regs.acrs;\n#ifdef CONFIG_64BIT\n\t\t/*\n\t\t * Very special case: old & broken 64 bit gdb reading\n\t\t * from acrs[15]. Result is a 64 bit value. Read the\n\t\t * 32 bit acrs[15] value and shift it by 32. Sick...\n\t\t */\n\t\tif (addr == (addr_t) &dummy->regs.acrs[15])\n\t\t\ttmp = ((unsigned long) child->thread.acrs[15]) << 32;\n\t\telse\n#endif\n\t\ttmp = *(addr_t *)((addr_t) &child->thread.acrs + offset);\n\n\t} else if (addr == (addr_t) &dummy->regs.orig_gpr2) {\n\t\t/*\n\t\t * orig_gpr2 is stored on the kernel stack\n\t\t */\n\t\ttmp = (addr_t) task_pt_regs(child)->orig_gpr2;\n\n\t} else if (addr < (addr_t) (&dummy->regs.fp_regs + 1)) {\n\t\t/* \n\t\t * floating point regs. are stored in the thread structure\n\t\t */\n\t\toffset = addr - (addr_t) &dummy->regs.fp_regs;\n\t\ttmp = *(addr_t *)((addr_t) &child->thread.fp_regs + offset);\n\t\tif (addr == (addr_t) &dummy->regs.fp_regs.fpc)\n\t\t\ttmp &= (unsigned long) FPC_VALID_MASK\n\t\t\t\t<< (BITS_PER_LONG - 32);\n\n\t} else if (addr < (addr_t) (&dummy->regs.per_info + 1)) {\n\t\t/*\n\t\t * per_info is found in the thread structure\n\t\t */\n\t\toffset = addr - (addr_t) &dummy->regs.per_info;\n\t\ttmp = *(addr_t *)((addr_t) &child->thread.per_info + offset);\n\n\t} else\n\t\ttmp = 0;\n\n\treturn tmp;\n}",
        "func": "static unsigned long __peek_user(struct task_struct *child, addr_t addr)\n{\n\tstruct user *dummy = NULL;\n\taddr_t offset, tmp;\n\n\tif (addr < (addr_t) &dummy->regs.acrs) {\n\t\t/*\n\t\t * psw and gprs are stored on the stack\n\t\t */\n\t\ttmp = *(addr_t *)((addr_t) &task_pt_regs(child)->psw + addr);\n\t\tif (addr == (addr_t) &dummy->regs.psw.mask)\n\t\t\t/* Remove per bit from user psw. */\n\t\t\ttmp &= ~PSW_MASK_PER;\n\n\t} else if (addr < (addr_t) &dummy->regs.orig_gpr2) {\n\t\t/*\n\t\t * access registers are stored in the thread structure\n\t\t */\n\t\toffset = addr - (addr_t) &dummy->regs.acrs;\n#ifdef CONFIG_64BIT\n\t\t/*\n\t\t * Very special case: old & broken 64 bit gdb reading\n\t\t * from acrs[15]. Result is a 64 bit value. Read the\n\t\t * 32 bit acrs[15] value and shift it by 32. Sick...\n\t\t */\n\t\tif (addr == (addr_t) &dummy->regs.acrs[15])\n\t\t\ttmp = ((unsigned long) child->thread.acrs[15]) << 32;\n\t\telse\n#endif\n\t\ttmp = *(addr_t *)((addr_t) &child->thread.acrs + offset);\n\n\t} else if (addr == (addr_t) &dummy->regs.orig_gpr2) {\n\t\t/*\n\t\t * orig_gpr2 is stored on the kernel stack\n\t\t */\n\t\ttmp = (addr_t) task_pt_regs(child)->orig_gpr2;\n\n\t} else if (addr < (addr_t) &dummy->regs.fp_regs) {\n\t\t/*\n\t\t * prevent reads of padding hole between\n\t\t * orig_gpr2 and fp_regs on s390.\n\t\t */\n\t\ttmp = 0;\n\n\t} else if (addr < (addr_t) (&dummy->regs.fp_regs + 1)) {\n\t\t/* \n\t\t * floating point regs. are stored in the thread structure\n\t\t */\n\t\toffset = addr - (addr_t) &dummy->regs.fp_regs;\n\t\ttmp = *(addr_t *)((addr_t) &child->thread.fp_regs + offset);\n\t\tif (addr == (addr_t) &dummy->regs.fp_regs.fpc)\n\t\t\ttmp &= (unsigned long) FPC_VALID_MASK\n\t\t\t\t<< (BITS_PER_LONG - 32);\n\n\t} else if (addr < (addr_t) (&dummy->regs.per_info + 1)) {\n\t\t/*\n\t\t * per_info is found in the thread structure\n\t\t */\n\t\toffset = addr - (addr_t) &dummy->regs.per_info;\n\t\ttmp = *(addr_t *)((addr_t) &child->thread.per_info + offset);\n\n\t} else\n\t\ttmp = 0;\n\n\treturn tmp;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -35,6 +35,13 @@\n \t\t */\n \t\ttmp = (addr_t) task_pt_regs(child)->orig_gpr2;\n \n+\t} else if (addr < (addr_t) &dummy->regs.fp_regs) {\n+\t\t/*\n+\t\t * prevent reads of padding hole between\n+\t\t * orig_gpr2 and fp_regs on s390.\n+\t\t */\n+\t\ttmp = 0;\n+\n \t} else if (addr < (addr_t) (&dummy->regs.fp_regs + 1)) {\n \t\t/* \n \t\t * floating point regs. are stored in the thread structure",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t} else if (addr < (addr_t) &dummy->regs.fp_regs) {",
                "\t\t/*",
                "\t\t * prevent reads of padding hole between",
                "\t\t * orig_gpr2 and fp_regs on s390.",
                "\t\t */",
                "\t\ttmp = 0;",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2008-1294",
        "func_name": "torvalds/linux/sys_setrlimit",
        "description": "Linux kernel 2.6.17, and other versions before 2.6.22, does not check when a user attempts to set RLIMIT_CPU to 0 until after the change is made, which allows local users to bypass intended resource limits.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commitdiff;h=9926e4c74300c4b31dee007298c6475d33369df0",
        "commit_title": "As discovered here today, the change in Kernel 2.6.17 intended to inhibit",
        "commit_text": "users from setting RLIMIT_CPU to 0 (as that is equivalent to unlimited) by \"cheating\" and setting it to 1 in such a case, does not make a difference, as the check is done in the wrong place (too late), and only applies to the profiling code.  On all systems I checked running kernels above 2.6.17, no matter what the hard and soft CPU time limits were before, a user could escape them by issuing in the shell (sh/bash/zsh) \"ulimit -t 0\", and then the user's process was not ever killed.  Attached is a trivial patch to fix that.  Simply moving the check to a slightly earlier location (specifically, before the line that actually assigns the limit - *old_rlim = new_rlim), does the trick.  Do note that at least the zsh (but not ash, dash, or bash) shell has the problem of \"caching\" the limits set by the ulimit command, so when running zsh the fix will not immediately be evident - after entering \"ulimit -t 0\", \"ulimit -a\" will show \"-t: cpu time (seconds) 0\", even though the actual limit as returned by getrlimit(...) will be 1.  It can be verified by opening a subshell (which will not have the values of the parent shell in cache) and checking in it, or just by running a CPU intensive command like \"echo '65536^1048576' | bc\" and verifying that it dumps core after one second.  Regardless of whether that is a misfeature in the shell, perhaps it would be better to return -EINVAL from setrlimit in such a case instead of cheating and setting to 1, as that does not really reflect the actual state of the process anymore.  I do not however know what the ground for that decision was in the original 2.6.17 change, and whether there would be any \"backward\" compatibility issues, so I preferred not to touch that right now.  ",
        "func_before": "asmlinkage long sys_setrlimit(unsigned int resource, struct rlimit __user *rlim)\n{\n\tstruct rlimit new_rlim, *old_rlim;\n\tunsigned long it_prof_secs;\n\tint retval;\n\n\tif (resource >= RLIM_NLIMITS)\n\t\treturn -EINVAL;\n\tif (copy_from_user(&new_rlim, rlim, sizeof(*rlim)))\n\t\treturn -EFAULT;\n\tif (new_rlim.rlim_cur > new_rlim.rlim_max)\n\t\treturn -EINVAL;\n\told_rlim = current->signal->rlim + resource;\n\tif ((new_rlim.rlim_max > old_rlim->rlim_max) &&\n\t    !capable(CAP_SYS_RESOURCE))\n\t\treturn -EPERM;\n\tif (resource == RLIMIT_NOFILE && new_rlim.rlim_max > NR_OPEN)\n\t\treturn -EPERM;\n\n\tretval = security_task_setrlimit(resource, &new_rlim);\n\tif (retval)\n\t\treturn retval;\n\n\ttask_lock(current->group_leader);\n\t*old_rlim = new_rlim;\n\ttask_unlock(current->group_leader);\n\n\tif (resource != RLIMIT_CPU)\n\t\tgoto out;\n\n\t/*\n\t * RLIMIT_CPU handling.   Note that the kernel fails to return an error\n\t * code if it rejected the user's attempt to set RLIMIT_CPU.  This is a\n\t * very long-standing error, and fixing it now risks breakage of\n\t * applications, so we live with it\n\t */\n\tif (new_rlim.rlim_cur == RLIM_INFINITY)\n\t\tgoto out;\n\n\tit_prof_secs = cputime_to_secs(current->signal->it_prof_expires);\n\tif (it_prof_secs == 0 || new_rlim.rlim_cur <= it_prof_secs) {\n\t\tunsigned long rlim_cur = new_rlim.rlim_cur;\n\t\tcputime_t cputime;\n\n\t\tif (rlim_cur == 0) {\n\t\t\t/*\n\t\t\t * The caller is asking for an immediate RLIMIT_CPU\n\t\t\t * expiry.  But we use the zero value to mean \"it was\n\t\t\t * never set\".  So let's cheat and make it one second\n\t\t\t * instead\n\t\t\t */\n\t\t\trlim_cur = 1;\n\t\t}\n\t\tcputime = secs_to_cputime(rlim_cur);\n\t\tread_lock(&tasklist_lock);\n\t\tspin_lock_irq(&current->sighand->siglock);\n\t\tset_process_cpu_timer(current, CPUCLOCK_PROF, &cputime, NULL);\n\t\tspin_unlock_irq(&current->sighand->siglock);\n\t\tread_unlock(&tasklist_lock);\n\t}\nout:\n\treturn 0;\n}",
        "func": "asmlinkage long sys_setrlimit(unsigned int resource, struct rlimit __user *rlim)\n{\n\tstruct rlimit new_rlim, *old_rlim;\n\tunsigned long it_prof_secs;\n\tint retval;\n\n\tif (resource >= RLIM_NLIMITS)\n\t\treturn -EINVAL;\n\tif (copy_from_user(&new_rlim, rlim, sizeof(*rlim)))\n\t\treturn -EFAULT;\n\tif (new_rlim.rlim_cur > new_rlim.rlim_max)\n\t\treturn -EINVAL;\n\told_rlim = current->signal->rlim + resource;\n\tif ((new_rlim.rlim_max > old_rlim->rlim_max) &&\n\t    !capable(CAP_SYS_RESOURCE))\n\t\treturn -EPERM;\n\tif (resource == RLIMIT_NOFILE && new_rlim.rlim_max > NR_OPEN)\n\t\treturn -EPERM;\n\n\tretval = security_task_setrlimit(resource, &new_rlim);\n\tif (retval)\n\t\treturn retval;\n\n\tif (resource == RLIMIT_CPU && new_rlim.rlim_cur == 0) {\n\t\t/*\n\t\t * The caller is asking for an immediate RLIMIT_CPU\n\t\t * expiry.  But we use the zero value to mean \"it was\n\t\t * never set\".  So let's cheat and make it one second\n\t\t * instead\n\t\t */\n\t\tnew_rlim.rlim_cur = 1;\n\t}\n\n\ttask_lock(current->group_leader);\n\t*old_rlim = new_rlim;\n\ttask_unlock(current->group_leader);\n\n\tif (resource != RLIMIT_CPU)\n\t\tgoto out;\n\n\t/*\n\t * RLIMIT_CPU handling.   Note that the kernel fails to return an error\n\t * code if it rejected the user's attempt to set RLIMIT_CPU.  This is a\n\t * very long-standing error, and fixing it now risks breakage of\n\t * applications, so we live with it\n\t */\n\tif (new_rlim.rlim_cur == RLIM_INFINITY)\n\t\tgoto out;\n\n\tit_prof_secs = cputime_to_secs(current->signal->it_prof_expires);\n\tif (it_prof_secs == 0 || new_rlim.rlim_cur <= it_prof_secs) {\n\t\tunsigned long rlim_cur = new_rlim.rlim_cur;\n\t\tcputime_t cputime;\n\n\t\tcputime = secs_to_cputime(rlim_cur);\n\t\tread_lock(&tasklist_lock);\n\t\tspin_lock_irq(&current->sighand->siglock);\n\t\tset_process_cpu_timer(current, CPUCLOCK_PROF, &cputime, NULL);\n\t\tspin_unlock_irq(&current->sighand->siglock);\n\t\tread_unlock(&tasklist_lock);\n\t}\nout:\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -21,6 +21,16 @@\n \tif (retval)\n \t\treturn retval;\n \n+\tif (resource == RLIMIT_CPU && new_rlim.rlim_cur == 0) {\n+\t\t/*\n+\t\t * The caller is asking for an immediate RLIMIT_CPU\n+\t\t * expiry.  But we use the zero value to mean \"it was\n+\t\t * never set\".  So let's cheat and make it one second\n+\t\t * instead\n+\t\t */\n+\t\tnew_rlim.rlim_cur = 1;\n+\t}\n+\n \ttask_lock(current->group_leader);\n \t*old_rlim = new_rlim;\n \ttask_unlock(current->group_leader);\n@@ -42,15 +52,6 @@\n \t\tunsigned long rlim_cur = new_rlim.rlim_cur;\n \t\tcputime_t cputime;\n \n-\t\tif (rlim_cur == 0) {\n-\t\t\t/*\n-\t\t\t * The caller is asking for an immediate RLIMIT_CPU\n-\t\t\t * expiry.  But we use the zero value to mean \"it was\n-\t\t\t * never set\".  So let's cheat and make it one second\n-\t\t\t * instead\n-\t\t\t */\n-\t\t\trlim_cur = 1;\n-\t\t}\n \t\tcputime = secs_to_cputime(rlim_cur);\n \t\tread_lock(&tasklist_lock);\n \t\tspin_lock_irq(&current->sighand->siglock);",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tif (rlim_cur == 0) {",
                "\t\t\t/*",
                "\t\t\t * The caller is asking for an immediate RLIMIT_CPU",
                "\t\t\t * expiry.  But we use the zero value to mean \"it was",
                "\t\t\t * never set\".  So let's cheat and make it one second",
                "\t\t\t * instead",
                "\t\t\t */",
                "\t\t\trlim_cur = 1;",
                "\t\t}"
            ],
            "added_lines": [
                "\tif (resource == RLIMIT_CPU && new_rlim.rlim_cur == 0) {",
                "\t\t/*",
                "\t\t * The caller is asking for an immediate RLIMIT_CPU",
                "\t\t * expiry.  But we use the zero value to mean \"it was",
                "\t\t * never set\".  So let's cheat and make it one second",
                "\t\t * instead",
                "\t\t */",
                "\t\tnew_rlim.rlim_cur = 1;",
                "\t}",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2008-3686",
        "func_name": "torvalds/linux/rt6_fill_node",
        "description": "The rt6_fill_node function in net/ipv6/route.c in Linux kernel 2.6.26-rc4, 2.6.26.2, and possibly other 2.6.26 versions, allows local users to cause a denial of service (kernel OOPS) via IPv6 requests when no IPv6 input device is in use, which triggers a NULL pointer dereference.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=5e0115e500fe9dd2ca11e6f92db9123204f1327a",
        "commit_title": "Alexey Dobriyan wrote:",
        "commit_text": "> On Thu, Aug 07, 2008 at 07:00:56PM +0200, John Gumb wrote: >> Scenario: no ipv6 default route set. >  >> # ip -f inet6 route get fec0::1 >> >> BUG: unable to handle kernel NULL pointer dereference at 00000000 >> IP: [<c0369b85>] rt6_fill_node+0x175/0x3b0 >> EIP is at rt6_fill_node+0x175/0x3b0 >  > 0xffffffff80424dd3 is in rt6_fill_node (net/ipv6/route.c:2191). > 2186                    } else > 2187    #endif > 2188                            NLA_PUT_U32(skb, RTA_IIF, iif); > 2189            } else if (dst) { > 2190                    struct in6_addr saddr_buf; > 2191      ====>         if (ipv6_dev_get_saddr(ip6_dst_idev(&rt->u.dst)->dev, >\t\t\t\t\t       ^^^^^^^^^^^^^^^^^^^^^^^^ >\t\t\t\t\t\t\t\t\t\t\tNULL >  > 2192                                           dst, 0, &saddr_buf) == 0) > 2193                            NLA_PUT(skb, RTA_PREFSRC, 16, &saddr_buf); > 2194            }  The commit that changed this can't be reverted easily, but the patch below works for me.  Fix NULL de-reference in rt6_fill_node() when there's no IPv6 input device present in the dst entry.  ",
        "func_before": "static int rt6_fill_node(struct sk_buff *skb, struct rt6_info *rt,\n\t\t\t struct in6_addr *dst, struct in6_addr *src,\n\t\t\t int iif, int type, u32 pid, u32 seq,\n\t\t\t int prefix, int nowait, unsigned int flags)\n{\n\tstruct rtmsg *rtm;\n\tstruct nlmsghdr *nlh;\n\tlong expires;\n\tu32 table;\n\n\tif (prefix) {\t/* user wants prefix routes only */\n\t\tif (!(rt->rt6i_flags & RTF_PREFIX_RT)) {\n\t\t\t/* success since this is not a prefix route */\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\tnlh = nlmsg_put(skb, pid, seq, type, sizeof(*rtm), flags);\n\tif (nlh == NULL)\n\t\treturn -EMSGSIZE;\n\n\trtm = nlmsg_data(nlh);\n\trtm->rtm_family = AF_INET6;\n\trtm->rtm_dst_len = rt->rt6i_dst.plen;\n\trtm->rtm_src_len = rt->rt6i_src.plen;\n\trtm->rtm_tos = 0;\n\tif (rt->rt6i_table)\n\t\ttable = rt->rt6i_table->tb6_id;\n\telse\n\t\ttable = RT6_TABLE_UNSPEC;\n\trtm->rtm_table = table;\n\tNLA_PUT_U32(skb, RTA_TABLE, table);\n\tif (rt->rt6i_flags&RTF_REJECT)\n\t\trtm->rtm_type = RTN_UNREACHABLE;\n\telse if (rt->rt6i_dev && (rt->rt6i_dev->flags&IFF_LOOPBACK))\n\t\trtm->rtm_type = RTN_LOCAL;\n\telse\n\t\trtm->rtm_type = RTN_UNICAST;\n\trtm->rtm_flags = 0;\n\trtm->rtm_scope = RT_SCOPE_UNIVERSE;\n\trtm->rtm_protocol = rt->rt6i_protocol;\n\tif (rt->rt6i_flags&RTF_DYNAMIC)\n\t\trtm->rtm_protocol = RTPROT_REDIRECT;\n\telse if (rt->rt6i_flags & RTF_ADDRCONF)\n\t\trtm->rtm_protocol = RTPROT_KERNEL;\n\telse if (rt->rt6i_flags&RTF_DEFAULT)\n\t\trtm->rtm_protocol = RTPROT_RA;\n\n\tif (rt->rt6i_flags&RTF_CACHE)\n\t\trtm->rtm_flags |= RTM_F_CLONED;\n\n\tif (dst) {\n\t\tNLA_PUT(skb, RTA_DST, 16, dst);\n\t\trtm->rtm_dst_len = 128;\n\t} else if (rtm->rtm_dst_len)\n\t\tNLA_PUT(skb, RTA_DST, 16, &rt->rt6i_dst.addr);\n#ifdef CONFIG_IPV6_SUBTREES\n\tif (src) {\n\t\tNLA_PUT(skb, RTA_SRC, 16, src);\n\t\trtm->rtm_src_len = 128;\n\t} else if (rtm->rtm_src_len)\n\t\tNLA_PUT(skb, RTA_SRC, 16, &rt->rt6i_src.addr);\n#endif\n\tif (iif) {\n#ifdef CONFIG_IPV6_MROUTE\n\t\tif (ipv6_addr_is_multicast(&rt->rt6i_dst.addr)) {\n\t\t\tint err = ip6mr_get_route(skb, rtm, nowait);\n\t\t\tif (err <= 0) {\n\t\t\t\tif (!nowait) {\n\t\t\t\t\tif (err == 0)\n\t\t\t\t\t\treturn 0;\n\t\t\t\t\tgoto nla_put_failure;\n\t\t\t\t} else {\n\t\t\t\t\tif (err == -EMSGSIZE)\n\t\t\t\t\t\tgoto nla_put_failure;\n\t\t\t\t}\n\t\t\t}\n\t\t} else\n#endif\n\t\t\tNLA_PUT_U32(skb, RTA_IIF, iif);\n\t} else if (dst) {\n\t\tstruct in6_addr saddr_buf;\n\t\tif (ipv6_dev_get_saddr(ip6_dst_idev(&rt->u.dst)->dev,\n\t\t\t\t       dst, 0, &saddr_buf) == 0)\n\t\t\tNLA_PUT(skb, RTA_PREFSRC, 16, &saddr_buf);\n\t}\n\n\tif (rtnetlink_put_metrics(skb, rt->u.dst.metrics) < 0)\n\t\tgoto nla_put_failure;\n\n\tif (rt->u.dst.neighbour)\n\t\tNLA_PUT(skb, RTA_GATEWAY, 16, &rt->u.dst.neighbour->primary_key);\n\n\tif (rt->u.dst.dev)\n\t\tNLA_PUT_U32(skb, RTA_OIF, rt->rt6i_dev->ifindex);\n\n\tNLA_PUT_U32(skb, RTA_PRIORITY, rt->rt6i_metric);\n\n\tif (!(rt->rt6i_flags & RTF_EXPIRES))\n\t\texpires = 0;\n\telse if (rt->rt6i_expires - jiffies < INT_MAX)\n\t\texpires = rt->rt6i_expires - jiffies;\n\telse\n\t\texpires = INT_MAX;\n\n\tif (rtnl_put_cacheinfo(skb, &rt->u.dst, 0, 0, 0,\n\t\t\t       expires, rt->u.dst.error) < 0)\n\t\tgoto nla_put_failure;\n\n\treturn nlmsg_end(skb, nlh);\n\nnla_put_failure:\n\tnlmsg_cancel(skb, nlh);\n\treturn -EMSGSIZE;\n}",
        "func": "static int rt6_fill_node(struct sk_buff *skb, struct rt6_info *rt,\n\t\t\t struct in6_addr *dst, struct in6_addr *src,\n\t\t\t int iif, int type, u32 pid, u32 seq,\n\t\t\t int prefix, int nowait, unsigned int flags)\n{\n\tstruct rtmsg *rtm;\n\tstruct nlmsghdr *nlh;\n\tlong expires;\n\tu32 table;\n\n\tif (prefix) {\t/* user wants prefix routes only */\n\t\tif (!(rt->rt6i_flags & RTF_PREFIX_RT)) {\n\t\t\t/* success since this is not a prefix route */\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\tnlh = nlmsg_put(skb, pid, seq, type, sizeof(*rtm), flags);\n\tif (nlh == NULL)\n\t\treturn -EMSGSIZE;\n\n\trtm = nlmsg_data(nlh);\n\trtm->rtm_family = AF_INET6;\n\trtm->rtm_dst_len = rt->rt6i_dst.plen;\n\trtm->rtm_src_len = rt->rt6i_src.plen;\n\trtm->rtm_tos = 0;\n\tif (rt->rt6i_table)\n\t\ttable = rt->rt6i_table->tb6_id;\n\telse\n\t\ttable = RT6_TABLE_UNSPEC;\n\trtm->rtm_table = table;\n\tNLA_PUT_U32(skb, RTA_TABLE, table);\n\tif (rt->rt6i_flags&RTF_REJECT)\n\t\trtm->rtm_type = RTN_UNREACHABLE;\n\telse if (rt->rt6i_dev && (rt->rt6i_dev->flags&IFF_LOOPBACK))\n\t\trtm->rtm_type = RTN_LOCAL;\n\telse\n\t\trtm->rtm_type = RTN_UNICAST;\n\trtm->rtm_flags = 0;\n\trtm->rtm_scope = RT_SCOPE_UNIVERSE;\n\trtm->rtm_protocol = rt->rt6i_protocol;\n\tif (rt->rt6i_flags&RTF_DYNAMIC)\n\t\trtm->rtm_protocol = RTPROT_REDIRECT;\n\telse if (rt->rt6i_flags & RTF_ADDRCONF)\n\t\trtm->rtm_protocol = RTPROT_KERNEL;\n\telse if (rt->rt6i_flags&RTF_DEFAULT)\n\t\trtm->rtm_protocol = RTPROT_RA;\n\n\tif (rt->rt6i_flags&RTF_CACHE)\n\t\trtm->rtm_flags |= RTM_F_CLONED;\n\n\tif (dst) {\n\t\tNLA_PUT(skb, RTA_DST, 16, dst);\n\t\trtm->rtm_dst_len = 128;\n\t} else if (rtm->rtm_dst_len)\n\t\tNLA_PUT(skb, RTA_DST, 16, &rt->rt6i_dst.addr);\n#ifdef CONFIG_IPV6_SUBTREES\n\tif (src) {\n\t\tNLA_PUT(skb, RTA_SRC, 16, src);\n\t\trtm->rtm_src_len = 128;\n\t} else if (rtm->rtm_src_len)\n\t\tNLA_PUT(skb, RTA_SRC, 16, &rt->rt6i_src.addr);\n#endif\n\tif (iif) {\n#ifdef CONFIG_IPV6_MROUTE\n\t\tif (ipv6_addr_is_multicast(&rt->rt6i_dst.addr)) {\n\t\t\tint err = ip6mr_get_route(skb, rtm, nowait);\n\t\t\tif (err <= 0) {\n\t\t\t\tif (!nowait) {\n\t\t\t\t\tif (err == 0)\n\t\t\t\t\t\treturn 0;\n\t\t\t\t\tgoto nla_put_failure;\n\t\t\t\t} else {\n\t\t\t\t\tif (err == -EMSGSIZE)\n\t\t\t\t\t\tgoto nla_put_failure;\n\t\t\t\t}\n\t\t\t}\n\t\t} else\n#endif\n\t\t\tNLA_PUT_U32(skb, RTA_IIF, iif);\n\t} else if (dst) {\n\t\tstruct inet6_dev *idev = ip6_dst_idev(&rt->u.dst);\n\t\tstruct in6_addr saddr_buf;\n\t\tif (ipv6_dev_get_saddr(idev ? idev->dev : NULL,\n\t\t\t\t       dst, 0, &saddr_buf) == 0)\n\t\t\tNLA_PUT(skb, RTA_PREFSRC, 16, &saddr_buf);\n\t}\n\n\tif (rtnetlink_put_metrics(skb, rt->u.dst.metrics) < 0)\n\t\tgoto nla_put_failure;\n\n\tif (rt->u.dst.neighbour)\n\t\tNLA_PUT(skb, RTA_GATEWAY, 16, &rt->u.dst.neighbour->primary_key);\n\n\tif (rt->u.dst.dev)\n\t\tNLA_PUT_U32(skb, RTA_OIF, rt->rt6i_dev->ifindex);\n\n\tNLA_PUT_U32(skb, RTA_PRIORITY, rt->rt6i_metric);\n\n\tif (!(rt->rt6i_flags & RTF_EXPIRES))\n\t\texpires = 0;\n\telse if (rt->rt6i_expires - jiffies < INT_MAX)\n\t\texpires = rt->rt6i_expires - jiffies;\n\telse\n\t\texpires = INT_MAX;\n\n\tif (rtnl_put_cacheinfo(skb, &rt->u.dst, 0, 0, 0,\n\t\t\t       expires, rt->u.dst.error) < 0)\n\t\tgoto nla_put_failure;\n\n\treturn nlmsg_end(skb, nlh);\n\nnla_put_failure:\n\tnlmsg_cancel(skb, nlh);\n\treturn -EMSGSIZE;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -79,8 +79,9 @@\n #endif\n \t\t\tNLA_PUT_U32(skb, RTA_IIF, iif);\n \t} else if (dst) {\n+\t\tstruct inet6_dev *idev = ip6_dst_idev(&rt->u.dst);\n \t\tstruct in6_addr saddr_buf;\n-\t\tif (ipv6_dev_get_saddr(ip6_dst_idev(&rt->u.dst)->dev,\n+\t\tif (ipv6_dev_get_saddr(idev ? idev->dev : NULL,\n \t\t\t\t       dst, 0, &saddr_buf) == 0)\n \t\t\tNLA_PUT(skb, RTA_PREFSRC, 16, &saddr_buf);\n \t}",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tif (ipv6_dev_get_saddr(ip6_dst_idev(&rt->u.dst)->dev,"
            ],
            "added_lines": [
                "\t\tstruct inet6_dev *idev = ip6_dst_idev(&rt->u.dst);",
                "\t\tif (ipv6_dev_get_saddr(idev ? idev->dev : NULL,"
            ]
        }
    },
    {
        "cve_id": "CVE-2008-5033",
        "func_name": "torvalds/linux/chip_command",
        "description": "The chip_command function in drivers/media/video/tvaudio.c in the Linux kernel 2.6.25.x before 2.6.25.19, 2.6.26.x before 2.6.26.7, and 2.6.27.x before 2.6.27.3 allows attackers to cause a denial of service (NULL function pointer dereference and OOPS) via unknown vectors.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=5ba2f67afb02c5302b2898949ed6fc3b3d37dcf1",
        "commit_title": "NULL function pointers are very bad security wise. This one got caught by",
        "commit_text": "kerneloops.org quite a few times, so it's happening in the field....  Fix is simple, check the function pointer for NULL, like 6 other places in the same function are already doing.  ",
        "func_before": "static int chip_command(struct i2c_client *client,\n\t\t\tunsigned int cmd, void *arg)\n{\n\tstruct CHIPSTATE *chip = i2c_get_clientdata(client);\n\tstruct CHIPDESC  *desc = chiplist + chip->type;\n\n\tv4l_dbg(1, debug, chip->c, \"%s: chip_command 0x%x\\n\", chip->c->name, cmd);\n\n\tswitch (cmd) {\n\tcase AUDC_SET_RADIO:\n\t\tchip->radio = 1;\n\t\tchip->watch_stereo = 0;\n\t\t/* del_timer(&chip->wt); */\n\t\tbreak;\n\t/* --- v4l ioctls --- */\n\t/* take care: bttv does userspace copying, we'll get a\n\tkernel pointer here... */\n\tcase VIDIOC_QUERYCTRL:\n\t{\n\t\tstruct v4l2_queryctrl *qc = arg;\n\n\t\tswitch (qc->id) {\n\t\t\tcase V4L2_CID_AUDIO_MUTE:\n\t\t\t\tbreak;\n\t\t\tcase V4L2_CID_AUDIO_VOLUME:\n\t\t\tcase V4L2_CID_AUDIO_BALANCE:\n\t\t\t\tif (!(desc->flags & CHIP_HAS_VOLUME))\n\t\t\t\t\treturn -EINVAL;\n\t\t\t\tbreak;\n\t\t\tcase V4L2_CID_AUDIO_BASS:\n\t\t\tcase V4L2_CID_AUDIO_TREBLE:\n\t\t\t\tif (desc->flags & CHIP_HAS_BASSTREBLE)\n\t\t\t\t\treturn -EINVAL;\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\treturn -EINVAL;\n\t\t}\n\t\treturn v4l2_ctrl_query_fill_std(qc);\n\t}\n\tcase VIDIOC_S_CTRL:\n\t\treturn tvaudio_set_ctrl(chip, arg);\n\n\tcase VIDIOC_G_CTRL:\n\t\treturn tvaudio_get_ctrl(chip, arg);\n\tcase VIDIOC_INT_G_AUDIO_ROUTING:\n\t{\n\t\tstruct v4l2_routing *rt = arg;\n\n\t\trt->input = chip->input;\n\t\trt->output = 0;\n\t\tbreak;\n\t}\n\tcase VIDIOC_INT_S_AUDIO_ROUTING:\n\t{\n\t\tstruct v4l2_routing *rt = arg;\n\n\t\tif (!(desc->flags & CHIP_HAS_INPUTSEL) || rt->input >= 4)\n\t\t\t\treturn -EINVAL;\n\t\t/* There are four inputs: tuner, radio, extern and intern. */\n\t\tchip->input = rt->input;\n\t\tif (chip->muted)\n\t\t\tbreak;\n\t\tchip_write_masked(chip, desc->inputreg,\n\t\t\t\tdesc->inputmap[chip->input], desc->inputmask);\n\t\tbreak;\n\t}\n\tcase VIDIOC_S_TUNER:\n\t{\n\t\tstruct v4l2_tuner *vt = arg;\n\t\tint mode = 0;\n\n\t\tif (chip->radio)\n\t\t\tbreak;\n\t\tswitch (vt->audmode) {\n\t\tcase V4L2_TUNER_MODE_MONO:\n\t\tcase V4L2_TUNER_MODE_STEREO:\n\t\tcase V4L2_TUNER_MODE_LANG1:\n\t\tcase V4L2_TUNER_MODE_LANG2:\n\t\t\tmode = vt->audmode;\n\t\t\tbreak;\n\t\tcase V4L2_TUNER_MODE_LANG1_LANG2:\n\t\t\tmode = V4L2_TUNER_MODE_STEREO;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tchip->audmode = vt->audmode;\n\n\t\tif (desc->setmode && mode) {\n\t\t\tchip->watch_stereo = 0;\n\t\t\t/* del_timer(&chip->wt); */\n\t\t\tchip->mode = mode;\n\t\t\tdesc->setmode(chip, mode);\n\t\t}\n\t\tbreak;\n\t}\n\tcase VIDIOC_G_TUNER:\n\t{\n\t\tstruct v4l2_tuner *vt = arg;\n\t\tint mode = V4L2_TUNER_MODE_MONO;\n\n\t\tif (chip->radio)\n\t\t\tbreak;\n\t\tvt->audmode = chip->audmode;\n\t\tvt->rxsubchans = 0;\n\t\tvt->capability = V4L2_TUNER_CAP_STEREO |\n\t\t\tV4L2_TUNER_CAP_LANG1 | V4L2_TUNER_CAP_LANG2;\n\n\t\tif (desc->getmode)\n\t\t\tmode = desc->getmode(chip);\n\n\t\tif (mode & V4L2_TUNER_MODE_MONO)\n\t\t\tvt->rxsubchans |= V4L2_TUNER_SUB_MONO;\n\t\tif (mode & V4L2_TUNER_MODE_STEREO)\n\t\t\tvt->rxsubchans |= V4L2_TUNER_SUB_STEREO;\n\t\t/* Note: for SAP it should be mono/lang2 or stereo/lang2.\n\t\t   When this module is converted fully to v4l2, then this\n\t\t   should change for those chips that can detect SAP. */\n\t\tif (mode & V4L2_TUNER_MODE_LANG1)\n\t\t\tvt->rxsubchans = V4L2_TUNER_SUB_LANG1 |\n\t\t\t\t\t V4L2_TUNER_SUB_LANG2;\n\t\tbreak;\n\t}\n\tcase VIDIOC_S_STD:\n\t\tchip->radio = 0;\n\t\tbreak;\n\tcase VIDIOC_S_FREQUENCY:\n\t\tchip->mode = 0; /* automatic */\n\t\tif (desc->checkmode) {\n\t\t\tdesc->setmode(chip,V4L2_TUNER_MODE_MONO);\n\t\t\tif (chip->prevmode != V4L2_TUNER_MODE_MONO)\n\t\t\t\tchip->prevmode = -1; /* reset previous mode */\n\t\t\tmod_timer(&chip->wt, jiffies+msecs_to_jiffies(2000));\n\t\t\t/* the thread will call checkmode() later */\n\t\t}\n\t\tbreak;\n\n\tcase VIDIOC_G_CHIP_IDENT:\n\t\treturn v4l2_chip_ident_i2c_client(client, arg, V4L2_IDENT_TVAUDIO, 0);\n\t}\n\treturn 0;\n}",
        "func": "static int chip_command(struct i2c_client *client,\n\t\t\tunsigned int cmd, void *arg)\n{\n\tstruct CHIPSTATE *chip = i2c_get_clientdata(client);\n\tstruct CHIPDESC  *desc = chiplist + chip->type;\n\n\tv4l_dbg(1, debug, chip->c, \"%s: chip_command 0x%x\\n\", chip->c->name, cmd);\n\n\tswitch (cmd) {\n\tcase AUDC_SET_RADIO:\n\t\tchip->radio = 1;\n\t\tchip->watch_stereo = 0;\n\t\t/* del_timer(&chip->wt); */\n\t\tbreak;\n\t/* --- v4l ioctls --- */\n\t/* take care: bttv does userspace copying, we'll get a\n\tkernel pointer here... */\n\tcase VIDIOC_QUERYCTRL:\n\t{\n\t\tstruct v4l2_queryctrl *qc = arg;\n\n\t\tswitch (qc->id) {\n\t\t\tcase V4L2_CID_AUDIO_MUTE:\n\t\t\t\tbreak;\n\t\t\tcase V4L2_CID_AUDIO_VOLUME:\n\t\t\tcase V4L2_CID_AUDIO_BALANCE:\n\t\t\t\tif (!(desc->flags & CHIP_HAS_VOLUME))\n\t\t\t\t\treturn -EINVAL;\n\t\t\t\tbreak;\n\t\t\tcase V4L2_CID_AUDIO_BASS:\n\t\t\tcase V4L2_CID_AUDIO_TREBLE:\n\t\t\t\tif (desc->flags & CHIP_HAS_BASSTREBLE)\n\t\t\t\t\treturn -EINVAL;\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\treturn -EINVAL;\n\t\t}\n\t\treturn v4l2_ctrl_query_fill_std(qc);\n\t}\n\tcase VIDIOC_S_CTRL:\n\t\treturn tvaudio_set_ctrl(chip, arg);\n\n\tcase VIDIOC_G_CTRL:\n\t\treturn tvaudio_get_ctrl(chip, arg);\n\tcase VIDIOC_INT_G_AUDIO_ROUTING:\n\t{\n\t\tstruct v4l2_routing *rt = arg;\n\n\t\trt->input = chip->input;\n\t\trt->output = 0;\n\t\tbreak;\n\t}\n\tcase VIDIOC_INT_S_AUDIO_ROUTING:\n\t{\n\t\tstruct v4l2_routing *rt = arg;\n\n\t\tif (!(desc->flags & CHIP_HAS_INPUTSEL) || rt->input >= 4)\n\t\t\t\treturn -EINVAL;\n\t\t/* There are four inputs: tuner, radio, extern and intern. */\n\t\tchip->input = rt->input;\n\t\tif (chip->muted)\n\t\t\tbreak;\n\t\tchip_write_masked(chip, desc->inputreg,\n\t\t\t\tdesc->inputmap[chip->input], desc->inputmask);\n\t\tbreak;\n\t}\n\tcase VIDIOC_S_TUNER:\n\t{\n\t\tstruct v4l2_tuner *vt = arg;\n\t\tint mode = 0;\n\n\t\tif (chip->radio)\n\t\t\tbreak;\n\t\tswitch (vt->audmode) {\n\t\tcase V4L2_TUNER_MODE_MONO:\n\t\tcase V4L2_TUNER_MODE_STEREO:\n\t\tcase V4L2_TUNER_MODE_LANG1:\n\t\tcase V4L2_TUNER_MODE_LANG2:\n\t\t\tmode = vt->audmode;\n\t\t\tbreak;\n\t\tcase V4L2_TUNER_MODE_LANG1_LANG2:\n\t\t\tmode = V4L2_TUNER_MODE_STEREO;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tchip->audmode = vt->audmode;\n\n\t\tif (desc->setmode && mode) {\n\t\t\tchip->watch_stereo = 0;\n\t\t\t/* del_timer(&chip->wt); */\n\t\t\tchip->mode = mode;\n\t\t\tdesc->setmode(chip, mode);\n\t\t}\n\t\tbreak;\n\t}\n\tcase VIDIOC_G_TUNER:\n\t{\n\t\tstruct v4l2_tuner *vt = arg;\n\t\tint mode = V4L2_TUNER_MODE_MONO;\n\n\t\tif (chip->radio)\n\t\t\tbreak;\n\t\tvt->audmode = chip->audmode;\n\t\tvt->rxsubchans = 0;\n\t\tvt->capability = V4L2_TUNER_CAP_STEREO |\n\t\t\tV4L2_TUNER_CAP_LANG1 | V4L2_TUNER_CAP_LANG2;\n\n\t\tif (desc->getmode)\n\t\t\tmode = desc->getmode(chip);\n\n\t\tif (mode & V4L2_TUNER_MODE_MONO)\n\t\t\tvt->rxsubchans |= V4L2_TUNER_SUB_MONO;\n\t\tif (mode & V4L2_TUNER_MODE_STEREO)\n\t\t\tvt->rxsubchans |= V4L2_TUNER_SUB_STEREO;\n\t\t/* Note: for SAP it should be mono/lang2 or stereo/lang2.\n\t\t   When this module is converted fully to v4l2, then this\n\t\t   should change for those chips that can detect SAP. */\n\t\tif (mode & V4L2_TUNER_MODE_LANG1)\n\t\t\tvt->rxsubchans = V4L2_TUNER_SUB_LANG1 |\n\t\t\t\t\t V4L2_TUNER_SUB_LANG2;\n\t\tbreak;\n\t}\n\tcase VIDIOC_S_STD:\n\t\tchip->radio = 0;\n\t\tbreak;\n\tcase VIDIOC_S_FREQUENCY:\n\t\tchip->mode = 0; /* automatic */\n\t\tif (desc->checkmode && desc->setmode) {\n\t\t\tdesc->setmode(chip,V4L2_TUNER_MODE_MONO);\n\t\t\tif (chip->prevmode != V4L2_TUNER_MODE_MONO)\n\t\t\t\tchip->prevmode = -1; /* reset previous mode */\n\t\t\tmod_timer(&chip->wt, jiffies+msecs_to_jiffies(2000));\n\t\t\t/* the thread will call checkmode() later */\n\t\t}\n\t\tbreak;\n\n\tcase VIDIOC_G_CHIP_IDENT:\n\t\treturn v4l2_chip_ident_i2c_client(client, arg, V4L2_IDENT_TVAUDIO, 0);\n\t}\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -126,7 +126,7 @@\n \t\tbreak;\n \tcase VIDIOC_S_FREQUENCY:\n \t\tchip->mode = 0; /* automatic */\n-\t\tif (desc->checkmode) {\n+\t\tif (desc->checkmode && desc->setmode) {\n \t\t\tdesc->setmode(chip,V4L2_TUNER_MODE_MONO);\n \t\t\tif (chip->prevmode != V4L2_TUNER_MODE_MONO)\n \t\t\t\tchip->prevmode = -1; /* reset previous mode */",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tif (desc->checkmode) {"
            ],
            "added_lines": [
                "\t\tif (desc->checkmode && desc->setmode) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2008-5700",
        "func_name": "torvalds/linux/blk_fill_sgv4_hdr_rq",
        "description": "libata in the Linux kernel before 2.6.27.9 does not set minimum timeouts for SG_IO requests, which allows local users to cause a denial of service (Programmed I/O mode on drives) via multiple simultaneous invocations of an unspecified test program.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/stable/linux.git;a=commit;h=f2f1fa78a155524b849edf359e42a3001ea652c0",
        "commit_title": "There's no point in having too short SG_IO timeouts, since if the",
        "commit_text": "command does end up timing out, we'll end up through the reset sequence that is several seconds long in order to abort the command that timed out.  As a result, shorter timeouts than a few seconds simply do not make sense, as the recovery would be longer than the timeout itself.  Add a BLK_MIN_SG_TIMEOUT to match the existign BLK_DEFAULT_SG_TIMEOUT.  Suggested-by: Alan Cox <alan@lxorguk.ukuu.org.uk> Cc: Jeff Garzik <jeff@garzik.org> ",
        "func_before": "static int blk_fill_sgv4_hdr_rq(struct request_queue *q, struct request *rq,\n\t\t\t\tstruct sg_io_v4 *hdr, struct bsg_device *bd,\n\t\t\t\tfmode_t has_write_perm)\n{\n\tif (hdr->request_len > BLK_MAX_CDB) {\n\t\trq->cmd = kzalloc(hdr->request_len, GFP_KERNEL);\n\t\tif (!rq->cmd)\n\t\t\treturn -ENOMEM;\n\t}\n\n\tif (copy_from_user(rq->cmd, (void *)(unsigned long)hdr->request,\n\t\t\t   hdr->request_len))\n\t\treturn -EFAULT;\n\n\tif (hdr->subprotocol == BSG_SUB_PROTOCOL_SCSI_CMD) {\n\t\tif (blk_verify_command(&q->cmd_filter, rq->cmd, has_write_perm))\n\t\t\treturn -EPERM;\n\t} else if (!capable(CAP_SYS_RAWIO))\n\t\treturn -EPERM;\n\n\t/*\n\t * fill in request structure\n\t */\n\trq->cmd_len = hdr->request_len;\n\trq->cmd_type = REQ_TYPE_BLOCK_PC;\n\n\trq->timeout = (hdr->timeout * HZ) / 1000;\n\tif (!rq->timeout)\n\t\trq->timeout = q->sg_timeout;\n\tif (!rq->timeout)\n\t\trq->timeout = BLK_DEFAULT_SG_TIMEOUT;\n\n\treturn 0;\n}",
        "func": "static int blk_fill_sgv4_hdr_rq(struct request_queue *q, struct request *rq,\n\t\t\t\tstruct sg_io_v4 *hdr, struct bsg_device *bd,\n\t\t\t\tfmode_t has_write_perm)\n{\n\tif (hdr->request_len > BLK_MAX_CDB) {\n\t\trq->cmd = kzalloc(hdr->request_len, GFP_KERNEL);\n\t\tif (!rq->cmd)\n\t\t\treturn -ENOMEM;\n\t}\n\n\tif (copy_from_user(rq->cmd, (void *)(unsigned long)hdr->request,\n\t\t\t   hdr->request_len))\n\t\treturn -EFAULT;\n\n\tif (hdr->subprotocol == BSG_SUB_PROTOCOL_SCSI_CMD) {\n\t\tif (blk_verify_command(&q->cmd_filter, rq->cmd, has_write_perm))\n\t\t\treturn -EPERM;\n\t} else if (!capable(CAP_SYS_RAWIO))\n\t\treturn -EPERM;\n\n\t/*\n\t * fill in request structure\n\t */\n\trq->cmd_len = hdr->request_len;\n\trq->cmd_type = REQ_TYPE_BLOCK_PC;\n\n\trq->timeout = (hdr->timeout * HZ) / 1000;\n\tif (!rq->timeout)\n\t\trq->timeout = q->sg_timeout;\n\tif (!rq->timeout)\n\t\trq->timeout = BLK_DEFAULT_SG_TIMEOUT;\n\tif (rq->timeout < BLK_MIN_SG_TIMEOUT)\n\t\trq->timeout = BLK_MIN_SG_TIMEOUT;\n\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -29,6 +29,8 @@\n \t\trq->timeout = q->sg_timeout;\n \tif (!rq->timeout)\n \t\trq->timeout = BLK_DEFAULT_SG_TIMEOUT;\n+\tif (rq->timeout < BLK_MIN_SG_TIMEOUT)\n+\t\trq->timeout = BLK_MIN_SG_TIMEOUT;\n \n \treturn 0;\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tif (rq->timeout < BLK_MIN_SG_TIMEOUT)",
                "\t\trq->timeout = BLK_MIN_SG_TIMEOUT;"
            ]
        }
    },
    {
        "cve_id": "CVE-2008-5700",
        "func_name": "torvalds/linux/blk_fill_sghdr_rq",
        "description": "libata in the Linux kernel before 2.6.27.9 does not set minimum timeouts for SG_IO requests, which allows local users to cause a denial of service (Programmed I/O mode on drives) via multiple simultaneous invocations of an unspecified test program.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/stable/linux.git;a=commit;h=f2f1fa78a155524b849edf359e42a3001ea652c0",
        "commit_title": "There's no point in having too short SG_IO timeouts, since if the",
        "commit_text": "command does end up timing out, we'll end up through the reset sequence that is several seconds long in order to abort the command that timed out.  As a result, shorter timeouts than a few seconds simply do not make sense, as the recovery would be longer than the timeout itself.  Add a BLK_MIN_SG_TIMEOUT to match the existign BLK_DEFAULT_SG_TIMEOUT.  Suggested-by: Alan Cox <alan@lxorguk.ukuu.org.uk> Cc: Jeff Garzik <jeff@garzik.org> ",
        "func_before": "static int blk_fill_sghdr_rq(struct request_queue *q, struct request *rq,\n\t\t\t     struct sg_io_hdr *hdr, fmode_t mode)\n{\n\tif (copy_from_user(rq->cmd, hdr->cmdp, hdr->cmd_len))\n\t\treturn -EFAULT;\n\tif (blk_verify_command(&q->cmd_filter, rq->cmd, mode & FMODE_WRITE))\n\t\treturn -EPERM;\n\n\t/*\n\t * fill in request structure\n\t */\n\trq->cmd_len = hdr->cmd_len;\n\trq->cmd_type = REQ_TYPE_BLOCK_PC;\n\n\trq->timeout = msecs_to_jiffies(hdr->timeout);\n\tif (!rq->timeout)\n\t\trq->timeout = q->sg_timeout;\n\tif (!rq->timeout)\n\t\trq->timeout = BLK_DEFAULT_SG_TIMEOUT;\n\n\treturn 0;\n}",
        "func": "static int blk_fill_sghdr_rq(struct request_queue *q, struct request *rq,\n\t\t\t     struct sg_io_hdr *hdr, fmode_t mode)\n{\n\tif (copy_from_user(rq->cmd, hdr->cmdp, hdr->cmd_len))\n\t\treturn -EFAULT;\n\tif (blk_verify_command(&q->cmd_filter, rq->cmd, mode & FMODE_WRITE))\n\t\treturn -EPERM;\n\n\t/*\n\t * fill in request structure\n\t */\n\trq->cmd_len = hdr->cmd_len;\n\trq->cmd_type = REQ_TYPE_BLOCK_PC;\n\n\trq->timeout = msecs_to_jiffies(hdr->timeout);\n\tif (!rq->timeout)\n\t\trq->timeout = q->sg_timeout;\n\tif (!rq->timeout)\n\t\trq->timeout = BLK_DEFAULT_SG_TIMEOUT;\n\tif (rq->timeout < BLK_MIN_SG_TIMEOUT)\n\t\trq->timeout = BLK_MIN_SG_TIMEOUT;\n\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -17,6 +17,8 @@\n \t\trq->timeout = q->sg_timeout;\n \tif (!rq->timeout)\n \t\trq->timeout = BLK_DEFAULT_SG_TIMEOUT;\n+\tif (rq->timeout < BLK_MIN_SG_TIMEOUT)\n+\t\trq->timeout = BLK_MIN_SG_TIMEOUT;\n \n \treturn 0;\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tif (rq->timeout < BLK_MIN_SG_TIMEOUT)",
                "\t\trq->timeout = BLK_MIN_SG_TIMEOUT;"
            ]
        }
    },
    {
        "cve_id": "CVE-2008-5713",
        "func_name": "torvalds/linux/__qdisc_run",
        "description": "The __qdisc_run function in net/sched/sch_generic.c in the Linux kernel before 2.6.25 on SMP machines allows local users to cause a denial of service (soft lockup) by sending a large amount of network traffic, as demonstrated by multiple simultaneous invocations of the Netperf benchmark application in UDP_STREAM mode.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/stable/linux.git;a=commit;h=2ba2506ca7ca62c56edaa334b0fe61eb5eab6ab0",
        "commit_title": "The qdisc_run loop is currently unbounded and runs entirely in a",
        "commit_text": "softirq.  This is bad as it may create an unbounded softirq run.  This patch fixes this by calling need_resched and breaking out if necessary.  It also adds a break out if the jiffies value changes since that would indicate we've been transmitting for too long which starves other softirqs.  ",
        "func_before": "void __qdisc_run(struct net_device *dev)\n{\n\tdo {\n\t\tif (!qdisc_restart(dev))\n\t\t\tbreak;\n\t} while (!netif_queue_stopped(dev));\n\n\tclear_bit(__LINK_STATE_QDISC_RUNNING, &dev->state);\n}",
        "func": "void __qdisc_run(struct net_device *dev)\n{\n\tunsigned long start_time = jiffies;\n\n\twhile (qdisc_restart(dev)) {\n\t\tif (netif_queue_stopped(dev))\n\t\t\tbreak;\n\n\t\t/*\n\t\t * Postpone processing if\n\t\t * 1. another process needs the CPU;\n\t\t * 2. we've been doing it for too long.\n\t\t */\n\t\tif (need_resched() || jiffies != start_time) {\n\t\t\tnetif_schedule(dev);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tclear_bit(__LINK_STATE_QDISC_RUNNING, &dev->state);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,9 +1,21 @@\n void __qdisc_run(struct net_device *dev)\n {\n-\tdo {\n-\t\tif (!qdisc_restart(dev))\n+\tunsigned long start_time = jiffies;\n+\n+\twhile (qdisc_restart(dev)) {\n+\t\tif (netif_queue_stopped(dev))\n \t\t\tbreak;\n-\t} while (!netif_queue_stopped(dev));\n+\n+\t\t/*\n+\t\t * Postpone processing if\n+\t\t * 1. another process needs the CPU;\n+\t\t * 2. we've been doing it for too long.\n+\t\t */\n+\t\tif (need_resched() || jiffies != start_time) {\n+\t\t\tnetif_schedule(dev);\n+\t\t\tbreak;\n+\t\t}\n+\t}\n \n \tclear_bit(__LINK_STATE_QDISC_RUNNING, &dev->state);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tdo {",
                "\t\tif (!qdisc_restart(dev))",
                "\t} while (!netif_queue_stopped(dev));"
            ],
            "added_lines": [
                "\tunsigned long start_time = jiffies;",
                "",
                "\twhile (qdisc_restart(dev)) {",
                "\t\tif (netif_queue_stopped(dev))",
                "",
                "\t\t/*",
                "\t\t * Postpone processing if",
                "\t\t * 1. another process needs the CPU;",
                "\t\t * 2. we've been doing it for too long.",
                "\t\t */",
                "\t\tif (need_resched() || jiffies != start_time) {",
                "\t\t\tnetif_schedule(dev);",
                "\t\t\tbreak;",
                "\t\t}",
                "\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2009-0322",
        "func_name": "torvalds/linux/read_rbu_image_type",
        "description": "drivers/firmware/dell_rbu.c in the Linux kernel before 2.6.27.13, and 2.6.28.x before 2.6.28.2, allows local users to cause a denial of service (system crash) via a read system call that specifies zero bytes from the (1) image_type or (2) packet_size file in /sys/devices/platform/dell_rbu/.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/stable/linux.git;a=commit;h=81156928f8fe31621e467490b9d441c0285998c3",
        "commit_title": "Reading 0 bytes from /sys/devices/platform/dell_rbu/image_type or",
        "commit_text": "/sys/devices/platform/dell_rbu/packet_size by an ordinary user causes an oops.  ",
        "func_before": "static ssize_t read_rbu_image_type(struct kobject *kobj,\n\t\t\t\t   struct bin_attribute *bin_attr,\n\t\t\t\t   char *buffer, loff_t pos, size_t count)\n{\n\tint size = 0;\n\tif (!pos)\n\t\tsize = sprintf(buffer, \"%s\\n\", image_type);\n\treturn size;\n}",
        "func": "static ssize_t read_rbu_image_type(struct kobject *kobj,\n\t\t\t\t   struct bin_attribute *bin_attr,\n\t\t\t\t   char *buffer, loff_t pos, size_t count)\n{\n\tint size = 0;\n\tif (!pos)\n\t\tsize = scnprintf(buffer, count, \"%s\\n\", image_type);\n\treturn size;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,6 +4,6 @@\n {\n \tint size = 0;\n \tif (!pos)\n-\t\tsize = sprintf(buffer, \"%s\\n\", image_type);\n+\t\tsize = scnprintf(buffer, count, \"%s\\n\", image_type);\n \treturn size;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tsize = sprintf(buffer, \"%s\\n\", image_type);"
            ],
            "added_lines": [
                "\t\tsize = scnprintf(buffer, count, \"%s\\n\", image_type);"
            ]
        }
    },
    {
        "cve_id": "CVE-2009-0322",
        "func_name": "torvalds/linux/read_rbu_packet_size",
        "description": "drivers/firmware/dell_rbu.c in the Linux kernel before 2.6.27.13, and 2.6.28.x before 2.6.28.2, allows local users to cause a denial of service (system crash) via a read system call that specifies zero bytes from the (1) image_type or (2) packet_size file in /sys/devices/platform/dell_rbu/.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/stable/linux.git;a=commit;h=81156928f8fe31621e467490b9d441c0285998c3",
        "commit_title": "Reading 0 bytes from /sys/devices/platform/dell_rbu/image_type or",
        "commit_text": "/sys/devices/platform/dell_rbu/packet_size by an ordinary user causes an oops.  ",
        "func_before": "static ssize_t read_rbu_packet_size(struct kobject *kobj,\n\t\t\t\t    struct bin_attribute *bin_attr,\n\t\t\t\t    char *buffer, loff_t pos, size_t count)\n{\n\tint size = 0;\n\tif (!pos) {\n\t\tspin_lock(&rbu_data.lock);\n\t\tsize = sprintf(buffer, \"%lu\\n\", rbu_data.packetsize);\n\t\tspin_unlock(&rbu_data.lock);\n\t}\n\treturn size;\n}",
        "func": "static ssize_t read_rbu_packet_size(struct kobject *kobj,\n\t\t\t\t    struct bin_attribute *bin_attr,\n\t\t\t\t    char *buffer, loff_t pos, size_t count)\n{\n\tint size = 0;\n\tif (!pos) {\n\t\tspin_lock(&rbu_data.lock);\n\t\tsize = scnprintf(buffer, count, \"%lu\\n\", rbu_data.packetsize);\n\t\tspin_unlock(&rbu_data.lock);\n\t}\n\treturn size;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,7 +5,7 @@\n \tint size = 0;\n \tif (!pos) {\n \t\tspin_lock(&rbu_data.lock);\n-\t\tsize = sprintf(buffer, \"%lu\\n\", rbu_data.packetsize);\n+\t\tsize = scnprintf(buffer, count, \"%lu\\n\", rbu_data.packetsize);\n \t\tspin_unlock(&rbu_data.lock);\n \t}\n \treturn size;",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tsize = sprintf(buffer, \"%lu\\n\", rbu_data.packetsize);"
            ],
            "added_lines": [
                "\t\tsize = scnprintf(buffer, count, \"%lu\\n\", rbu_data.packetsize);"
            ]
        }
    },
    {
        "cve_id": "CVE-2009-0747",
        "func_name": "torvalds/linux/ext4_block_to_path",
        "description": "The ext4_isize function in fs/ext4/ext4.h in the Linux kernel 2.6.27 before 2.6.27.19 and 2.6.28 before 2.6.28.7 uses the i_size_high structure member during operations on arbitrary types of files, which allows local users to cause a denial of service (CPU consumption and error-message flood) by attempting to mount a crafted ext4 filesystem.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=06a279d636734da32bb62dd2f7b0ade666f65d7c",
        "commit_title": "Directories are not allowed to be bigger than 2GB, so don't use",
        "commit_text": "i_size_high for anything other than regular files.  E2fsck should complain about these inodes, but the simplest thing to do for the kernel is to only use i_size_high for regular files.  This prevents an intentially corrupted filesystem from causing the kernel to burn a huge amount of CPU and issuing error messages such as:  EXT4-fs warning (device loop0): ext4_block_to_path: block 135090028 > max  Thanks to David Maciejak from Fortinet's FortiGuard Global Security Research Team for reporting this issue.  http://bugzilla.kernel.org/show_bug.cgi?id=12375  Cc: stable@kernel.org ",
        "func_before": "static int ext4_block_to_path(struct inode *inode,\n\t\t\text4_lblk_t i_block,\n\t\t\text4_lblk_t offsets[4], int *boundary)\n{\n\tint ptrs = EXT4_ADDR_PER_BLOCK(inode->i_sb);\n\tint ptrs_bits = EXT4_ADDR_PER_BLOCK_BITS(inode->i_sb);\n\tconst long direct_blocks = EXT4_NDIR_BLOCKS,\n\t\tindirect_blocks = ptrs,\n\t\tdouble_blocks = (1 << (ptrs_bits * 2));\n\tint n = 0;\n\tint final = 0;\n\n\tif (i_block < 0) {\n\t\text4_warning(inode->i_sb, \"ext4_block_to_path\", \"block < 0\");\n\t} else if (i_block < direct_blocks) {\n\t\toffsets[n++] = i_block;\n\t\tfinal = direct_blocks;\n\t} else if ((i_block -= direct_blocks) < indirect_blocks) {\n\t\toffsets[n++] = EXT4_IND_BLOCK;\n\t\toffsets[n++] = i_block;\n\t\tfinal = ptrs;\n\t} else if ((i_block -= indirect_blocks) < double_blocks) {\n\t\toffsets[n++] = EXT4_DIND_BLOCK;\n\t\toffsets[n++] = i_block >> ptrs_bits;\n\t\toffsets[n++] = i_block & (ptrs - 1);\n\t\tfinal = ptrs;\n\t} else if (((i_block -= double_blocks) >> (ptrs_bits * 2)) < ptrs) {\n\t\toffsets[n++] = EXT4_TIND_BLOCK;\n\t\toffsets[n++] = i_block >> (ptrs_bits * 2);\n\t\toffsets[n++] = (i_block >> ptrs_bits) & (ptrs - 1);\n\t\toffsets[n++] = i_block & (ptrs - 1);\n\t\tfinal = ptrs;\n\t} else {\n\t\text4_warning(inode->i_sb, \"ext4_block_to_path\",\n\t\t\t\t\"block %lu > max\",\n\t\t\t\ti_block + direct_blocks +\n\t\t\t\tindirect_blocks + double_blocks);\n\t}\n\tif (boundary)\n\t\t*boundary = final - 1 - (i_block & (ptrs - 1));\n\treturn n;\n}",
        "func": "static int ext4_block_to_path(struct inode *inode,\n\t\t\text4_lblk_t i_block,\n\t\t\text4_lblk_t offsets[4], int *boundary)\n{\n\tint ptrs = EXT4_ADDR_PER_BLOCK(inode->i_sb);\n\tint ptrs_bits = EXT4_ADDR_PER_BLOCK_BITS(inode->i_sb);\n\tconst long direct_blocks = EXT4_NDIR_BLOCKS,\n\t\tindirect_blocks = ptrs,\n\t\tdouble_blocks = (1 << (ptrs_bits * 2));\n\tint n = 0;\n\tint final = 0;\n\n\tif (i_block < 0) {\n\t\text4_warning(inode->i_sb, \"ext4_block_to_path\", \"block < 0\");\n\t} else if (i_block < direct_blocks) {\n\t\toffsets[n++] = i_block;\n\t\tfinal = direct_blocks;\n\t} else if ((i_block -= direct_blocks) < indirect_blocks) {\n\t\toffsets[n++] = EXT4_IND_BLOCK;\n\t\toffsets[n++] = i_block;\n\t\tfinal = ptrs;\n\t} else if ((i_block -= indirect_blocks) < double_blocks) {\n\t\toffsets[n++] = EXT4_DIND_BLOCK;\n\t\toffsets[n++] = i_block >> ptrs_bits;\n\t\toffsets[n++] = i_block & (ptrs - 1);\n\t\tfinal = ptrs;\n\t} else if (((i_block -= double_blocks) >> (ptrs_bits * 2)) < ptrs) {\n\t\toffsets[n++] = EXT4_TIND_BLOCK;\n\t\toffsets[n++] = i_block >> (ptrs_bits * 2);\n\t\toffsets[n++] = (i_block >> ptrs_bits) & (ptrs - 1);\n\t\toffsets[n++] = i_block & (ptrs - 1);\n\t\tfinal = ptrs;\n\t} else {\n\t\text4_warning(inode->i_sb, \"ext4_block_to_path\",\n\t\t\t\t\"block %lu > max in inode %lu\",\n\t\t\t\ti_block + direct_blocks +\n\t\t\t\tindirect_blocks + double_blocks, inode->i_ino);\n\t}\n\tif (boundary)\n\t\t*boundary = final - 1 - (i_block & (ptrs - 1));\n\treturn n;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -32,9 +32,9 @@\n \t\tfinal = ptrs;\n \t} else {\n \t\text4_warning(inode->i_sb, \"ext4_block_to_path\",\n-\t\t\t\t\"block %lu > max\",\n+\t\t\t\t\"block %lu > max in inode %lu\",\n \t\t\t\ti_block + direct_blocks +\n-\t\t\t\tindirect_blocks + double_blocks);\n+\t\t\t\tindirect_blocks + double_blocks, inode->i_ino);\n \t}\n \tif (boundary)\n \t\t*boundary = final - 1 - (i_block & (ptrs - 1));",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\t\t\"block %lu > max\",",
                "\t\t\t\tindirect_blocks + double_blocks);"
            ],
            "added_lines": [
                "\t\t\t\t\"block %lu > max in inode %lu\",",
                "\t\t\t\tindirect_blocks + double_blocks, inode->i_ino);"
            ]
        }
    },
    {
        "cve_id": "CVE-2009-0747",
        "func_name": "torvalds/linux/ext4_isize",
        "description": "The ext4_isize function in fs/ext4/ext4.h in the Linux kernel 2.6.27 before 2.6.27.19 and 2.6.28 before 2.6.28.7 uses the i_size_high structure member during operations on arbitrary types of files, which allows local users to cause a denial of service (CPU consumption and error-message flood) by attempting to mount a crafted ext4 filesystem.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=06a279d636734da32bb62dd2f7b0ade666f65d7c",
        "commit_title": "Directories are not allowed to be bigger than 2GB, so don't use",
        "commit_text": "i_size_high for anything other than regular files.  E2fsck should complain about these inodes, but the simplest thing to do for the kernel is to only use i_size_high for regular files.  This prevents an intentially corrupted filesystem from causing the kernel to burn a huge amount of CPU and issuing error messages such as:  EXT4-fs warning (device loop0): ext4_block_to_path: block 135090028 > max  Thanks to David Maciejak from Fortinet's FortiGuard Global Security Research Team for reporting this issue.  http://bugzilla.kernel.org/show_bug.cgi?id=12375  Cc: stable@kernel.org ",
        "func_before": "static inline loff_t ext4_isize(struct ext4_inode *raw_inode)\n{\n\treturn ((loff_t)le32_to_cpu(raw_inode->i_size_high) << 32) |\n\t\tle32_to_cpu(raw_inode->i_size_lo);\n}",
        "func": "static inline loff_t ext4_isize(struct ext4_inode *raw_inode)\n{\n\tif (S_ISREG(le16_to_cpu(raw_inode->i_mode)))\n\t\treturn ((loff_t)le32_to_cpu(raw_inode->i_size_high) << 32) |\n\t\t\tle32_to_cpu(raw_inode->i_size_lo);\n\telse\n\t\treturn (loff_t) le32_to_cpu(raw_inode->i_size_lo);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,8 @@\n static inline loff_t ext4_isize(struct ext4_inode *raw_inode)\n {\n-\treturn ((loff_t)le32_to_cpu(raw_inode->i_size_high) << 32) |\n-\t\tle32_to_cpu(raw_inode->i_size_lo);\n+\tif (S_ISREG(le16_to_cpu(raw_inode->i_mode)))\n+\t\treturn ((loff_t)le32_to_cpu(raw_inode->i_size_high) << 32) |\n+\t\t\tle32_to_cpu(raw_inode->i_size_lo);\n+\telse\n+\t\treturn (loff_t) le32_to_cpu(raw_inode->i_size_lo);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\treturn ((loff_t)le32_to_cpu(raw_inode->i_size_high) << 32) |",
                "\t\tle32_to_cpu(raw_inode->i_size_lo);"
            ],
            "added_lines": [
                "\tif (S_ISREG(le16_to_cpu(raw_inode->i_mode)))",
                "\t\treturn ((loff_t)le32_to_cpu(raw_inode->i_size_high) << 32) |",
                "\t\t\tle32_to_cpu(raw_inode->i_size_lo);",
                "\telse",
                "\t\treturn (loff_t) le32_to_cpu(raw_inode->i_size_lo);"
            ]
        }
    },
    {
        "cve_id": "CVE-2009-2844",
        "func_name": "torvalds/linux/cmp_ies",
        "description": "cfg80211 in net/wireless/scan.c in the Linux kernel 2.6.30-rc1 and other versions before 2.6.31-rc6 allows remote attackers to cause a denial of service (crash) via a sequence of beacon frames in which one frame omits an SSID Information Element (IE) and the subsequent frame contains an SSID IE, which triggers a NULL pointer dereference in the cmp_ies function.  NOTE: a potential weakness in the is_mesh function was also addressed, but the relevant condition did not exist in the code, so it is not a vulnerability.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commitdiff;h=cd3468bad96c00b5a512f551674f36776129520e",
        "commit_title": "These pointers can be NULL, the is_mesh() case isn't",
        "commit_text": "ever hit in the current kernel, but cmp_ies() can be hit under certain conditions.  Cc: stable@kernel.org [2.6.29, 2.6.30] ",
        "func_before": "static int cmp_ies(u8 num, u8 *ies1, size_t len1, u8 *ies2, size_t len2)\n{\n\tconst u8 *ie1 = find_ie(num, ies1, len1);\n\tconst u8 *ie2 = find_ie(num, ies2, len2);\n\tint r;\n\n\tif (!ie1 && !ie2)\n\t\treturn 0;\n\tif (!ie1)\n\t\treturn -1;\n\n\tr = memcmp(ie1 + 2, ie2 + 2, min(ie1[1], ie2[1]));\n\tif (r == 0 && ie1[1] != ie2[1])\n\t\treturn ie2[1] - ie1[1];\n\treturn r;\n}",
        "func": "static int cmp_ies(u8 num, u8 *ies1, size_t len1, u8 *ies2, size_t len2)\n{\n\tconst u8 *ie1 = find_ie(num, ies1, len1);\n\tconst u8 *ie2 = find_ie(num, ies2, len2);\n\tint r;\n\n\tif (!ie1 && !ie2)\n\t\treturn 0;\n\tif (!ie1 || !ie2)\n\t\treturn -1;\n\n\tr = memcmp(ie1 + 2, ie2 + 2, min(ie1[1], ie2[1]));\n\tif (r == 0 && ie1[1] != ie2[1])\n\t\treturn ie2[1] - ie1[1];\n\treturn r;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -6,7 +6,7 @@\n \n \tif (!ie1 && !ie2)\n \t\treturn 0;\n-\tif (!ie1)\n+\tif (!ie1 || !ie2)\n \t\treturn -1;\n \n \tr = memcmp(ie1 + 2, ie2 + 2, min(ie1[1], ie2[1]));",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (!ie1)"
            ],
            "added_lines": [
                "\tif (!ie1 || !ie2)"
            ]
        }
    },
    {
        "cve_id": "CVE-2009-2844",
        "func_name": "torvalds/linux/is_mesh",
        "description": "cfg80211 in net/wireless/scan.c in the Linux kernel 2.6.30-rc1 and other versions before 2.6.31-rc6 allows remote attackers to cause a denial of service (crash) via a sequence of beacon frames in which one frame omits an SSID Information Element (IE) and the subsequent frame contains an SSID IE, which triggers a NULL pointer dereference in the cmp_ies function.  NOTE: a potential weakness in the is_mesh function was also addressed, but the relevant condition did not exist in the code, so it is not a vulnerability.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commitdiff;h=cd3468bad96c00b5a512f551674f36776129520e",
        "commit_title": "These pointers can be NULL, the is_mesh() case isn't",
        "commit_text": "ever hit in the current kernel, but cmp_ies() can be hit under certain conditions.  Cc: stable@kernel.org [2.6.29, 2.6.30] ",
        "func_before": "static bool is_mesh(struct cfg80211_bss *a,\n\t\t    const u8 *meshid, size_t meshidlen,\n\t\t    const u8 *meshcfg)\n{\n\tconst u8 *ie;\n\n\tif (!is_zero_ether_addr(a->bssid))\n\t\treturn false;\n\n\tie = find_ie(WLAN_EID_MESH_ID,\n\t\t     a->information_elements,\n\t\t     a->len_information_elements);\n\tif (!ie)\n\t\treturn false;\n\tif (ie[1] != meshidlen)\n\t\treturn false;\n\tif (memcmp(ie + 2, meshid, meshidlen))\n\t\treturn false;\n\n\tie = find_ie(WLAN_EID_MESH_CONFIG,\n\t\t     a->information_elements,\n\t\t     a->len_information_elements);\n\tif (ie[1] != IEEE80211_MESH_CONFIG_LEN)\n\t\treturn false;\n\n\t/*\n\t * Ignore mesh capability (last two bytes of the IE) when\n\t * comparing since that may differ between stations taking\n\t * part in the same mesh.\n\t */\n\treturn memcmp(ie + 2, meshcfg, IEEE80211_MESH_CONFIG_LEN - 2) == 0;\n}",
        "func": "static bool is_mesh(struct cfg80211_bss *a,\n\t\t    const u8 *meshid, size_t meshidlen,\n\t\t    const u8 *meshcfg)\n{\n\tconst u8 *ie;\n\n\tif (!is_zero_ether_addr(a->bssid))\n\t\treturn false;\n\n\tie = find_ie(WLAN_EID_MESH_ID,\n\t\t     a->information_elements,\n\t\t     a->len_information_elements);\n\tif (!ie)\n\t\treturn false;\n\tif (ie[1] != meshidlen)\n\t\treturn false;\n\tif (memcmp(ie + 2, meshid, meshidlen))\n\t\treturn false;\n\n\tie = find_ie(WLAN_EID_MESH_CONFIG,\n\t\t     a->information_elements,\n\t\t     a->len_information_elements);\n\tif (!ie)\n\t\treturn false;\n\tif (ie[1] != IEEE80211_MESH_CONFIG_LEN)\n\t\treturn false;\n\n\t/*\n\t * Ignore mesh capability (last two bytes of the IE) when\n\t * comparing since that may differ between stations taking\n\t * part in the same mesh.\n\t */\n\treturn memcmp(ie + 2, meshcfg, IEEE80211_MESH_CONFIG_LEN - 2) == 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -20,6 +20,8 @@\n \tie = find_ie(WLAN_EID_MESH_CONFIG,\n \t\t     a->information_elements,\n \t\t     a->len_information_elements);\n+\tif (!ie)\n+\t\treturn false;\n \tif (ie[1] != IEEE80211_MESH_CONFIG_LEN)\n \t\treturn false;\n ",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tif (!ie)",
                "\t\treturn false;"
            ]
        }
    },
    {
        "cve_id": "CVE-2008-7061",
        "func_name": "chromium/RenderWidgetHostHWND::SetTooltipText",
        "description": "The tooltip manager (chrome/views/tooltip_manager.cc) in Google Chrome 0.2.149.29 Build 1798 and possibly other versions before 0.2.149.30 allows remote attackers to cause a denial of service (CPU consumption or crash) via a tag with a long title attribute, which is not properly handled when displaying a tooltip, a different vulnerability than CVE-2008-6994.  NOTE: there is inconsistent information about the environments under which this issue exists.",
        "git_url": "https://github.com/chromium/chromium/commit/3413dd8e6353804a0931fc86f842194a6891be90",
        "commit_title": "Set an upper limit to the number of characters that can appear in a tooltip string.",
        "commit_text": " B=1368905  ",
        "func_before": "void RenderWidgetHostHWND::SetTooltipText(const std::wstring& tooltip_text) {\n  if (tooltip_text != tooltip_text_) {\n    tooltip_text_ = tooltip_text;\n    // Need to check if the tooltip is already showing so that we don't\n    // immediately show the tooltip with no delay when we move the mouse from\n    // a region with no tooltip to a region with a tooltip.\n    if (::IsWindow(tooltip_hwnd_) && tooltip_showing_) {\n      ::SendMessage(tooltip_hwnd_, TTM_POP, 0, 0);\n      ::SendMessage(tooltip_hwnd_, TTM_POPUP, 0, 0);\n    }\n  } else {\n    // Make sure the tooltip gets closed after TTN_POP gets sent. For some\n    // reason this doesn't happen automatically, so moving the mouse around\n    // within the same link/image/etc doesn't cause the tooltip to re-appear.\n    if (!tooltip_showing_) {\n      if (::IsWindow(tooltip_hwnd_))\n        ::SendMessage(tooltip_hwnd_, TTM_POP, 0, 0);\n    }\n  }\n}",
        "func": "void RenderWidgetHostHWND::SetTooltipText(const std::wstring& tooltip_text) {\n  if (tooltip_text != tooltip_text_) {\n    tooltip_text_ = tooltip_text;\n\n    // Clamp the tooltip length to kMaxTooltipLength so that we don't\n    // accidentally DOS the user with a mega tooltip (since Windows doesn't seem\n    // to do this itself).\n    if (tooltip_text_.length() > kMaxTooltipLength)\n      tooltip_text_ = tooltip_text_.substr(0, kMaxTooltipLength);\n\n    // Need to check if the tooltip is already showing so that we don't\n    // immediately show the tooltip with no delay when we move the mouse from\n    // a region with no tooltip to a region with a tooltip.\n    if (::IsWindow(tooltip_hwnd_) && tooltip_showing_) {\n      ::SendMessage(tooltip_hwnd_, TTM_POP, 0, 0);\n      ::SendMessage(tooltip_hwnd_, TTM_POPUP, 0, 0);\n    }\n  } else {\n    // Make sure the tooltip gets closed after TTN_POP gets sent. For some\n    // reason this doesn't happen automatically, so moving the mouse around\n    // within the same link/image/etc doesn't cause the tooltip to re-appear.\n    if (!tooltip_showing_) {\n      if (::IsWindow(tooltip_hwnd_))\n        ::SendMessage(tooltip_hwnd_, TTM_POP, 0, 0);\n    }\n  }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,13 @@\n void RenderWidgetHostHWND::SetTooltipText(const std::wstring& tooltip_text) {\n   if (tooltip_text != tooltip_text_) {\n     tooltip_text_ = tooltip_text;\n+\n+    // Clamp the tooltip length to kMaxTooltipLength so that we don't\n+    // accidentally DOS the user with a mega tooltip (since Windows doesn't seem\n+    // to do this itself).\n+    if (tooltip_text_.length() > kMaxTooltipLength)\n+      tooltip_text_ = tooltip_text_.substr(0, kMaxTooltipLength);\n+\n     // Need to check if the tooltip is already showing so that we don't\n     // immediately show the tooltip with no delay when we move the mouse from\n     // a region with no tooltip to a region with a tooltip.",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "    // Clamp the tooltip length to kMaxTooltipLength so that we don't",
                "    // accidentally DOS the user with a mega tooltip (since Windows doesn't seem",
                "    // to do this itself).",
                "    if (tooltip_text_.length() > kMaxTooltipLength)",
                "      tooltip_text_ = tooltip_text_.substr(0, kMaxTooltipLength);",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2008-7061",
        "func_name": "chromium/TooltipManager::TrimTooltipToFit",
        "description": "The tooltip manager (chrome/views/tooltip_manager.cc) in Google Chrome 0.2.149.29 Build 1798 and possibly other versions before 0.2.149.30 allows remote attackers to cause a denial of service (CPU consumption or crash) via a tag with a long title attribute, which is not properly handled when displaying a tooltip, a different vulnerability than CVE-2008-6994.  NOTE: there is inconsistent information about the environments under which this issue exists.",
        "git_url": "https://github.com/chromium/chromium/commit/3413dd8e6353804a0931fc86f842194a6891be90",
        "commit_title": "Set an upper limit to the number of characters that can appear in a tooltip string.",
        "commit_text": " B=1368905  ",
        "func_before": "void TooltipManager::TrimTooltipToFit(std::wstring* text,\n                                      int* max_width,\n                                      int* line_count,\n                                      int position_x,\n                                      int position_y,\n                                      HWND window) {\n  *max_width = 0;\n  *line_count = 0;\n\n  // Determine the available width for the tooltip.\n  CPoint screen_loc(position_x, position_y);\n  View::ConvertPointToScreen(view_container_->GetRootView(), &screen_loc);\n  gfx::Rect monitor_bounds =\n      win_util::GetMonitorBoundsForRect(gfx::Rect(screen_loc.x, screen_loc.y,\n                                                  0, 0));\n  RECT tooltip_margin;\n  SendMessage(window, TTM_GETMARGIN, 0, (LPARAM)&tooltip_margin);\n  const int available_width = monitor_bounds.width() - tooltip_margin.left -\n      tooltip_margin.right;\n  if (available_width <= 0)\n    return;\n\n  // Split the string.\n  std::vector<std::wstring> lines;\n  SplitTooltipString(*text, &lines);\n  *line_count = static_cast<int>(lines.size());\n\n  // Format each line to fit.\n  ChromeFont font = GetDefaultFont();\n  std::wstring result;\n  for (std::vector<std::wstring>::iterator i = lines.begin(); i != lines.end();\n       ++i) {\n    std::wstring elided_text = gfx::ElideText(*i, font, available_width);\n    *max_width = std::max(*max_width, font.GetStringWidth(elided_text));\n    if (i == lines.begin() && i + 1 == lines.end()) {\n      *text = elided_text;\n      return;\n    }\n    if (!result.empty())\n      result.append(GetLineSeparator());\n    result.append(elided_text);\n  }\n  *text = result;\n}",
        "func": "void TooltipManager::TrimTooltipToFit(std::wstring* text,\n                                      int* max_width,\n                                      int* line_count,\n                                      int position_x,\n                                      int position_y,\n                                      HWND window) {\n  *max_width = 0;\n  *line_count = 0;\n\n  // Clamp the tooltip length to kMaxTooltipLength so that we don't\n  // accidentally DOS the user with a mega tooltip (since Windows doesn't seem\n  // to do this itself).\n  if (text->length() > kMaxTooltipLength)\n    *text = text->substr(0, kMaxTooltipLength);\n\n  // Determine the available width for the tooltip.\n  CPoint screen_loc(position_x, position_y);\n  View::ConvertPointToScreen(view_container_->GetRootView(), &screen_loc);\n  gfx::Rect monitor_bounds =\n      win_util::GetMonitorBoundsForRect(gfx::Rect(screen_loc.x, screen_loc.y,\n                                                  0, 0));\n  RECT tooltip_margin;\n  SendMessage(window, TTM_GETMARGIN, 0, (LPARAM)&tooltip_margin);\n  const int available_width = monitor_bounds.width() - tooltip_margin.left -\n      tooltip_margin.right;\n  if (available_width <= 0)\n    return;\n\n  // Split the string.\n  std::vector<std::wstring> lines;\n  SplitTooltipString(*text, &lines);\n  *line_count = static_cast<int>(lines.size());\n\n  // Format each line to fit.\n  ChromeFont font = GetDefaultFont();\n  std::wstring result;\n  for (std::vector<std::wstring>::iterator i = lines.begin(); i != lines.end();\n       ++i) {\n    std::wstring elided_text = gfx::ElideText(*i, font, available_width);\n    *max_width = std::max(*max_width, font.GetStringWidth(elided_text));\n    if (i == lines.begin() && i + 1 == lines.end()) {\n      *text = elided_text;\n      return;\n    }\n    if (!result.empty())\n      result.append(GetLineSeparator());\n    result.append(elided_text);\n  }\n  *text = result;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -6,6 +6,12 @@\n                                       HWND window) {\n   *max_width = 0;\n   *line_count = 0;\n+\n+  // Clamp the tooltip length to kMaxTooltipLength so that we don't\n+  // accidentally DOS the user with a mega tooltip (since Windows doesn't seem\n+  // to do this itself).\n+  if (text->length() > kMaxTooltipLength)\n+    *text = text->substr(0, kMaxTooltipLength);\n \n   // Determine the available width for the tooltip.\n   CPoint screen_loc(position_x, position_y);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "  // Clamp the tooltip length to kMaxTooltipLength so that we don't",
                "  // accidentally DOS the user with a mega tooltip (since Windows doesn't seem",
                "  // to do this itself).",
                "  if (text->length() > kMaxTooltipLength)",
                "    *text = text->substr(0, kMaxTooltipLength);"
            ]
        }
    },
    {
        "cve_id": "CVE-2009-3043",
        "func_name": "torvalds/linux/tty_ldisc_hangup",
        "description": "The tty_ldisc_hangup function in drivers/char/tty_ldisc.c in the Linux kernel 2.6.31-rc before 2.6.31-rc8 allows local users to cause a denial of service (system crash, sometimes preceded by a NULL pointer dereference) or possibly gain privileges via certain pseudo-terminal I/O activity, as demonstrated by KernelTtyTest.c.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=5c58ceff103d8a654f24769bb1baaf84a841b0cc",
        "commit_title": "When I rewrote tty ldisc code to use proper reference counts (commits",
        "commit_text": "65b770468e98 and cbe9352fa08f) in order to avoid a race with hangup, the test-program that Eric Biederman used to trigger the original problem seems to have exposed another long-standing bug: the hangup code did the 'tty_ldisc_halt()' to stop any buffer flushing activity, but unlike the other call sites it never actually flushed any pending work.  As a result, if you get just the right timing, the pending work may be just about to execute (ie the timer has already triggered and thus cancel_delayed_work() was a no-op), when we then re-initialize the ldisc from under it.  That, in turn, results in various random problems, usually seen as a NULL pointer dereference in run_timer_softirq() or a BUG() in worker_thread (but it can be almost anything).  Fix it by adding the required 'flush_scheduled_work()' after doing the tty_ldisc_halt() (this also requires us to move the ldisc halt to before taking the ldisc mutex in order to avoid a deadlock with the workqueue executing do_tty_hangup, which requires the mutex).  The locking should be cleaned up one day (the requirement to do this outside the ldisc_mutex is very annoying, and weakens the lock), but that's a larger and separate undertaking.  Cc: Frederic Weisbecker <fweisbec@gmail.com> Cc: Greg Kroah-Hartman <gregkh@suse.de> Cc: Alan Cox <alan@lxorguk.ukuu.org.uk> ",
        "func_before": "void tty_ldisc_hangup(struct tty_struct *tty)\n{\n\tstruct tty_ldisc *ld;\n\n\t/*\n\t * FIXME! What are the locking issues here? This may me overdoing\n\t * things... This question is especially important now that we've\n\t * removed the irqlock.\n\t */\n\tld = tty_ldisc_ref(tty);\n\tif (ld != NULL) {\n\t\t/* We may have no line discipline at this point */\n\t\tif (ld->ops->flush_buffer)\n\t\t\tld->ops->flush_buffer(tty);\n\t\ttty_driver_flush_buffer(tty);\n\t\tif ((test_bit(TTY_DO_WRITE_WAKEUP, &tty->flags)) &&\n\t\t    ld->ops->write_wakeup)\n\t\t\tld->ops->write_wakeup(tty);\n\t\tif (ld->ops->hangup)\n\t\t\tld->ops->hangup(tty);\n\t\ttty_ldisc_deref(ld);\n\t}\n\t/*\n\t * FIXME: Once we trust the LDISC code better we can wait here for\n\t * ldisc completion and fix the driver call race\n\t */\n\twake_up_interruptible_poll(&tty->write_wait, POLLOUT);\n\twake_up_interruptible_poll(&tty->read_wait, POLLIN);\n\t/*\n\t * Shutdown the current line discipline, and reset it to\n\t * N_TTY.\n\t */\n\tif (tty->driver->flags & TTY_DRIVER_RESET_TERMIOS) {\n\t\t/* Avoid racing set_ldisc or tty_ldisc_release */\n\t\tmutex_lock(&tty->ldisc_mutex);\n\t\tif (tty->ldisc) {\t/* Not yet closed */\n\t\t\t/* Switch back to N_TTY */\n\t\t\ttty_ldisc_halt(tty);\n\t\t\ttty_ldisc_reinit(tty);\n\t\t\t/* At this point we have a closed ldisc and we want to\n\t\t\t   reopen it. We could defer this to the next open but\n\t\t\t   it means auditing a lot of other paths so this is\n\t\t\t   a FIXME */\n\t\t\tWARN_ON(tty_ldisc_open(tty, tty->ldisc));\n\t\t\ttty_ldisc_enable(tty);\n\t\t}\n\t\tmutex_unlock(&tty->ldisc_mutex);\n\t\ttty_reset_termios(tty);\n\t}\n}",
        "func": "void tty_ldisc_hangup(struct tty_struct *tty)\n{\n\tstruct tty_ldisc *ld;\n\n\t/*\n\t * FIXME! What are the locking issues here? This may me overdoing\n\t * things... This question is especially important now that we've\n\t * removed the irqlock.\n\t */\n\tld = tty_ldisc_ref(tty);\n\tif (ld != NULL) {\n\t\t/* We may have no line discipline at this point */\n\t\tif (ld->ops->flush_buffer)\n\t\t\tld->ops->flush_buffer(tty);\n\t\ttty_driver_flush_buffer(tty);\n\t\tif ((test_bit(TTY_DO_WRITE_WAKEUP, &tty->flags)) &&\n\t\t    ld->ops->write_wakeup)\n\t\t\tld->ops->write_wakeup(tty);\n\t\tif (ld->ops->hangup)\n\t\t\tld->ops->hangup(tty);\n\t\ttty_ldisc_deref(ld);\n\t}\n\t/*\n\t * FIXME: Once we trust the LDISC code better we can wait here for\n\t * ldisc completion and fix the driver call race\n\t */\n\twake_up_interruptible_poll(&tty->write_wait, POLLOUT);\n\twake_up_interruptible_poll(&tty->read_wait, POLLIN);\n\t/*\n\t * Shutdown the current line discipline, and reset it to\n\t * N_TTY.\n\t */\n\tif (tty->driver->flags & TTY_DRIVER_RESET_TERMIOS) {\n\t\t/* Make sure the old ldisc is quiescent */\n\t\ttty_ldisc_halt(tty);\n\t\tflush_scheduled_work();\n\n\t\t/* Avoid racing set_ldisc or tty_ldisc_release */\n\t\tmutex_lock(&tty->ldisc_mutex);\n\t\tif (tty->ldisc) {\t/* Not yet closed */\n\t\t\t/* Switch back to N_TTY */\n\t\t\ttty_ldisc_reinit(tty);\n\t\t\t/* At this point we have a closed ldisc and we want to\n\t\t\t   reopen it. We could defer this to the next open but\n\t\t\t   it means auditing a lot of other paths so this is\n\t\t\t   a FIXME */\n\t\t\tWARN_ON(tty_ldisc_open(tty, tty->ldisc));\n\t\t\ttty_ldisc_enable(tty);\n\t\t}\n\t\tmutex_unlock(&tty->ldisc_mutex);\n\t\ttty_reset_termios(tty);\n\t}\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -31,11 +31,14 @@\n \t * N_TTY.\n \t */\n \tif (tty->driver->flags & TTY_DRIVER_RESET_TERMIOS) {\n+\t\t/* Make sure the old ldisc is quiescent */\n+\t\ttty_ldisc_halt(tty);\n+\t\tflush_scheduled_work();\n+\n \t\t/* Avoid racing set_ldisc or tty_ldisc_release */\n \t\tmutex_lock(&tty->ldisc_mutex);\n \t\tif (tty->ldisc) {\t/* Not yet closed */\n \t\t\t/* Switch back to N_TTY */\n-\t\t\ttty_ldisc_halt(tty);\n \t\t\ttty_ldisc_reinit(tty);\n \t\t\t/* At this point we have a closed ldisc and we want to\n \t\t\t   reopen it. We could defer this to the next open but",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\ttty_ldisc_halt(tty);"
            ],
            "added_lines": [
                "\t\t/* Make sure the old ldisc is quiescent */",
                "\t\ttty_ldisc_halt(tty);",
                "\t\tflush_scheduled_work();",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2009-3290",
        "func_name": "torvalds/linux/kvm_emulate_hypercall",
        "description": "The kvm_emulate_hypercall function in arch/x86/kvm/x86.c in KVM in the Linux kernel 2.6.25-rc1, and other versions before 2.6.31, when running on x86 systems, does not prevent access to MMU hypercalls from ring 0, which allows local guest OS users to cause a denial of service (guest kernel crash) and read or write guest kernel memory via unspecified \"random addresses.\"",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commitdiff;h=07708c4af1346ab1521b26a202f438366b7bcffd",
        "commit_title": "So far unprivileged guest callers running in ring 3 can issue, e.g., MMU",
        "commit_text": "hypercalls. Normally, such callers cannot provide any hand-crafted MMU command structure as it has to be passed by its physical address, but they can still crash the guest kernel by passing random addresses.  To close the hole, this patch considers hypercalls valid only if issued from guest ring 0. This may still be relaxed on a per-hypercall base in the future once required.  Cc: stable@kernel.org ",
        "func_before": "int kvm_emulate_hypercall(struct kvm_vcpu *vcpu)\n{\n\tunsigned long nr, a0, a1, a2, a3, ret;\n\tint r = 1;\n\n\tnr = kvm_register_read(vcpu, VCPU_REGS_RAX);\n\ta0 = kvm_register_read(vcpu, VCPU_REGS_RBX);\n\ta1 = kvm_register_read(vcpu, VCPU_REGS_RCX);\n\ta2 = kvm_register_read(vcpu, VCPU_REGS_RDX);\n\ta3 = kvm_register_read(vcpu, VCPU_REGS_RSI);\n\n\ttrace_kvm_hypercall(nr, a0, a1, a2, a3);\n\n\tif (!is_long_mode(vcpu)) {\n\t\tnr &= 0xFFFFFFFF;\n\t\ta0 &= 0xFFFFFFFF;\n\t\ta1 &= 0xFFFFFFFF;\n\t\ta2 &= 0xFFFFFFFF;\n\t\ta3 &= 0xFFFFFFFF;\n\t}\n\n\tswitch (nr) {\n\tcase KVM_HC_VAPIC_POLL_IRQ:\n\t\tret = 0;\n\t\tbreak;\n\tcase KVM_HC_MMU_OP:\n\t\tr = kvm_pv_mmu_op(vcpu, a0, hc_gpa(vcpu, a1, a2), &ret);\n\t\tbreak;\n\tdefault:\n\t\tret = -KVM_ENOSYS;\n\t\tbreak;\n\t}\n\tkvm_register_write(vcpu, VCPU_REGS_RAX, ret);\n\t++vcpu->stat.hypercalls;\n\treturn r;\n}",
        "func": "int kvm_emulate_hypercall(struct kvm_vcpu *vcpu)\n{\n\tunsigned long nr, a0, a1, a2, a3, ret;\n\tint r = 1;\n\n\tnr = kvm_register_read(vcpu, VCPU_REGS_RAX);\n\ta0 = kvm_register_read(vcpu, VCPU_REGS_RBX);\n\ta1 = kvm_register_read(vcpu, VCPU_REGS_RCX);\n\ta2 = kvm_register_read(vcpu, VCPU_REGS_RDX);\n\ta3 = kvm_register_read(vcpu, VCPU_REGS_RSI);\n\n\ttrace_kvm_hypercall(nr, a0, a1, a2, a3);\n\n\tif (!is_long_mode(vcpu)) {\n\t\tnr &= 0xFFFFFFFF;\n\t\ta0 &= 0xFFFFFFFF;\n\t\ta1 &= 0xFFFFFFFF;\n\t\ta2 &= 0xFFFFFFFF;\n\t\ta3 &= 0xFFFFFFFF;\n\t}\n\n\tif (kvm_x86_ops->get_cpl(vcpu) != 0) {\n\t\tret = -KVM_EPERM;\n\t\tgoto out;\n\t}\n\n\tswitch (nr) {\n\tcase KVM_HC_VAPIC_POLL_IRQ:\n\t\tret = 0;\n\t\tbreak;\n\tcase KVM_HC_MMU_OP:\n\t\tr = kvm_pv_mmu_op(vcpu, a0, hc_gpa(vcpu, a1, a2), &ret);\n\t\tbreak;\n\tdefault:\n\t\tret = -KVM_ENOSYS;\n\t\tbreak;\n\t}\nout:\n\tkvm_register_write(vcpu, VCPU_REGS_RAX, ret);\n\t++vcpu->stat.hypercalls;\n\treturn r;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -19,6 +19,11 @@\n \t\ta3 &= 0xFFFFFFFF;\n \t}\n \n+\tif (kvm_x86_ops->get_cpl(vcpu) != 0) {\n+\t\tret = -KVM_EPERM;\n+\t\tgoto out;\n+\t}\n+\n \tswitch (nr) {\n \tcase KVM_HC_VAPIC_POLL_IRQ:\n \t\tret = 0;\n@@ -30,6 +35,7 @@\n \t\tret = -KVM_ENOSYS;\n \t\tbreak;\n \t}\n+out:\n \tkvm_register_write(vcpu, VCPU_REGS_RAX, ret);\n \t++vcpu->stat.hypercalls;\n \treturn r;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tif (kvm_x86_ops->get_cpl(vcpu) != 0) {",
                "\t\tret = -KVM_EPERM;",
                "\t\tgoto out;",
                "\t}",
                "",
                "out:"
            ]
        }
    },
    {
        "cve_id": "CVE-2009-3613",
        "func_name": "torvalds/linux/rtl8169_start_xmit",
        "description": "The swiotlb functionality in the r8169 driver in drivers/net/r8169.c in the Linux kernel before 2.6.27.22 allows remote attackers to cause a denial of service (IOMMU space exhaustion and system crash) by using jumbo frames for a large amount of network traffic, as demonstrated by a flood ping.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=97d477a914b146e7e6722ded21afa79886ae8ccd",
        "commit_title": "It shortens the code and fixes the current pci_unmap leak with",
        "commit_text": "padded skb reported by Dave Jones.  ",
        "func_before": "static int rtl8169_start_xmit(struct sk_buff *skb, struct net_device *dev)\n{\n\tstruct rtl8169_private *tp = netdev_priv(dev);\n\tunsigned int frags, entry = tp->cur_tx % NUM_TX_DESC;\n\tstruct TxDesc *txd = tp->TxDescArray + entry;\n\tvoid __iomem *ioaddr = tp->mmio_addr;\n\tdma_addr_t mapping;\n\tu32 status, len;\n\tu32 opts1;\n\tint ret = NETDEV_TX_OK;\n\n\tif (unlikely(TX_BUFFS_AVAIL(tp) < skb_shinfo(skb)->nr_frags)) {\n\t\tif (netif_msg_drv(tp)) {\n\t\t\tprintk(KERN_ERR\n\t\t\t       \"%s: BUG! Tx Ring full when queue awake!\\n\",\n\t\t\t       dev->name);\n\t\t}\n\t\tgoto err_stop;\n\t}\n\n\tif (unlikely(le32_to_cpu(txd->opts1) & DescOwn))\n\t\tgoto err_stop;\n\n\topts1 = DescOwn | rtl8169_tso_csum(skb, dev);\n\n\tfrags = rtl8169_xmit_frags(tp, skb, opts1);\n\tif (frags) {\n\t\tlen = skb_headlen(skb);\n\t\topts1 |= FirstFrag;\n\t} else {\n\t\tlen = skb->len;\n\n\t\tif (unlikely(len < ETH_ZLEN)) {\n\t\t\tif (skb_padto(skb, ETH_ZLEN))\n\t\t\t\tgoto err_update_stats;\n\t\t\tlen = ETH_ZLEN;\n\t\t}\n\n\t\topts1 |= FirstFrag | LastFrag;\n\t\ttp->tx_skb[entry].skb = skb;\n\t}\n\n\tmapping = pci_map_single(tp->pci_dev, skb->data, len, PCI_DMA_TODEVICE);\n\n\ttp->tx_skb[entry].len = len;\n\ttxd->addr = cpu_to_le64(mapping);\n\ttxd->opts2 = cpu_to_le32(rtl8169_tx_vlan_tag(tp, skb));\n\n\twmb();\n\n\t/* anti gcc 2.95.3 bugware (sic) */\n\tstatus = opts1 | len | (RingEnd * !((entry + 1) % NUM_TX_DESC));\n\ttxd->opts1 = cpu_to_le32(status);\n\n\tdev->trans_start = jiffies;\n\n\ttp->cur_tx += frags + 1;\n\n\tsmp_wmb();\n\n\tRTL_W8(TxPoll, NPQ);\t/* set polling bit */\n\n\tif (TX_BUFFS_AVAIL(tp) < MAX_SKB_FRAGS) {\n\t\tnetif_stop_queue(dev);\n\t\tsmp_rmb();\n\t\tif (TX_BUFFS_AVAIL(tp) >= MAX_SKB_FRAGS)\n\t\t\tnetif_wake_queue(dev);\n\t}\n\nout:\n\treturn ret;\n\nerr_stop:\n\tnetif_stop_queue(dev);\n\tret = NETDEV_TX_BUSY;\nerr_update_stats:\n\tdev->stats.tx_dropped++;\n\tgoto out;\n}",
        "func": "static int rtl8169_start_xmit(struct sk_buff *skb, struct net_device *dev)\n{\n\tstruct rtl8169_private *tp = netdev_priv(dev);\n\tunsigned int frags, entry = tp->cur_tx % NUM_TX_DESC;\n\tstruct TxDesc *txd = tp->TxDescArray + entry;\n\tvoid __iomem *ioaddr = tp->mmio_addr;\n\tdma_addr_t mapping;\n\tu32 status, len;\n\tu32 opts1;\n\tint ret = NETDEV_TX_OK;\n\n\tif (unlikely(TX_BUFFS_AVAIL(tp) < skb_shinfo(skb)->nr_frags)) {\n\t\tif (netif_msg_drv(tp)) {\n\t\t\tprintk(KERN_ERR\n\t\t\t       \"%s: BUG! Tx Ring full when queue awake!\\n\",\n\t\t\t       dev->name);\n\t\t}\n\t\tgoto err_stop;\n\t}\n\n\tif (unlikely(le32_to_cpu(txd->opts1) & DescOwn))\n\t\tgoto err_stop;\n\n\topts1 = DescOwn | rtl8169_tso_csum(skb, dev);\n\n\tfrags = rtl8169_xmit_frags(tp, skb, opts1);\n\tif (frags) {\n\t\tlen = skb_headlen(skb);\n\t\topts1 |= FirstFrag;\n\t} else {\n\t\tlen = skb->len;\n\t\topts1 |= FirstFrag | LastFrag;\n\t\ttp->tx_skb[entry].skb = skb;\n\t}\n\n\tmapping = pci_map_single(tp->pci_dev, skb->data, len, PCI_DMA_TODEVICE);\n\n\ttp->tx_skb[entry].len = len;\n\ttxd->addr = cpu_to_le64(mapping);\n\ttxd->opts2 = cpu_to_le32(rtl8169_tx_vlan_tag(tp, skb));\n\n\twmb();\n\n\t/* anti gcc 2.95.3 bugware (sic) */\n\tstatus = opts1 | len | (RingEnd * !((entry + 1) % NUM_TX_DESC));\n\ttxd->opts1 = cpu_to_le32(status);\n\n\tdev->trans_start = jiffies;\n\n\ttp->cur_tx += frags + 1;\n\n\tsmp_wmb();\n\n\tRTL_W8(TxPoll, NPQ);\t/* set polling bit */\n\n\tif (TX_BUFFS_AVAIL(tp) < MAX_SKB_FRAGS) {\n\t\tnetif_stop_queue(dev);\n\t\tsmp_rmb();\n\t\tif (TX_BUFFS_AVAIL(tp) >= MAX_SKB_FRAGS)\n\t\t\tnetif_wake_queue(dev);\n\t}\n\nout:\n\treturn ret;\n\nerr_stop:\n\tnetif_stop_queue(dev);\n\tret = NETDEV_TX_BUSY;\n\tdev->stats.tx_dropped++;\n\tgoto out;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -29,13 +29,6 @@\n \t\topts1 |= FirstFrag;\n \t} else {\n \t\tlen = skb->len;\n-\n-\t\tif (unlikely(len < ETH_ZLEN)) {\n-\t\t\tif (skb_padto(skb, ETH_ZLEN))\n-\t\t\t\tgoto err_update_stats;\n-\t\t\tlen = ETH_ZLEN;\n-\t\t}\n-\n \t\topts1 |= FirstFrag | LastFrag;\n \t\ttp->tx_skb[entry].skb = skb;\n \t}\n@@ -73,7 +66,6 @@\n err_stop:\n \tnetif_stop_queue(dev);\n \tret = NETDEV_TX_BUSY;\n-err_update_stats:\n \tdev->stats.tx_dropped++;\n \tgoto out;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "",
                "\t\tif (unlikely(len < ETH_ZLEN)) {",
                "\t\t\tif (skb_padto(skb, ETH_ZLEN))",
                "\t\t\t\tgoto err_update_stats;",
                "\t\t\tlen = ETH_ZLEN;",
                "\t\t}",
                "",
                "err_update_stats:"
            ],
            "added_lines": []
        }
    },
    {
        "cve_id": "CVE-2009-3613",
        "func_name": "torvalds/linux/rtl8169_rx_interrupt",
        "description": "The swiotlb functionality in the r8169 driver in drivers/net/r8169.c in the Linux kernel before 2.6.27.22 allows remote attackers to cause a denial of service (IOMMU space exhaustion and system crash) by using jumbo frames for a large amount of network traffic, as demonstrated by a flood ping.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=a866bbf6aacf95f849810079442a20be118ce905",
        "commit_title": "The leak hurts with swiotlb and jumbo frames.",
        "commit_text": " Fix http://bugzilla.kernel.org/show_bug.cgi?id=9468.  Heavily hinted by Ilpo Jrvinen <ilpo.jarvinen@helsinki.fi>.  Cc: Edward Hsu <edward_hsu@realtek.com.tw> ",
        "func_before": "static int rtl8169_rx_interrupt(struct net_device *dev,\n\t\t\t\tstruct rtl8169_private *tp,\n\t\t\t\tvoid __iomem *ioaddr, u32 budget)\n{\n\tunsigned int cur_rx, rx_left;\n\tunsigned int delta, count;\n\n\tcur_rx = tp->cur_rx;\n\trx_left = NUM_RX_DESC + tp->dirty_rx - cur_rx;\n\trx_left = min(rx_left, budget);\n\n\tfor (; rx_left > 0; rx_left--, cur_rx++) {\n\t\tunsigned int entry = cur_rx % NUM_RX_DESC;\n\t\tstruct RxDesc *desc = tp->RxDescArray + entry;\n\t\tu32 status;\n\n\t\trmb();\n\t\tstatus = le32_to_cpu(desc->opts1);\n\n\t\tif (status & DescOwn)\n\t\t\tbreak;\n\t\tif (unlikely(status & RxRES)) {\n\t\t\tif (netif_msg_rx_err(tp)) {\n\t\t\t\tprintk(KERN_INFO\n\t\t\t\t       \"%s: Rx ERROR. status = %08x\\n\",\n\t\t\t\t       dev->name, status);\n\t\t\t}\n\t\t\tdev->stats.rx_errors++;\n\t\t\tif (status & (RxRWT | RxRUNT))\n\t\t\t\tdev->stats.rx_length_errors++;\n\t\t\tif (status & RxCRC)\n\t\t\t\tdev->stats.rx_crc_errors++;\n\t\t\tif (status & RxFOVF) {\n\t\t\t\trtl8169_schedule_work(dev, rtl8169_reset_task);\n\t\t\t\tdev->stats.rx_fifo_errors++;\n\t\t\t}\n\t\t\trtl8169_mark_to_asic(desc, tp->rx_buf_sz);\n\t\t} else {\n\t\t\tstruct sk_buff *skb = tp->Rx_skbuff[entry];\n\t\t\tdma_addr_t addr = le64_to_cpu(desc->addr);\n\t\t\tint pkt_size = (status & 0x00001FFF) - 4;\n\t\t\tstruct pci_dev *pdev = tp->pci_dev;\n\n\t\t\t/*\n\t\t\t * The driver does not support incoming fragmented\n\t\t\t * frames. They are seen as a symptom of over-mtu\n\t\t\t * sized frames.\n\t\t\t */\n\t\t\tif (unlikely(rtl8169_fragmented_frame(status))) {\n\t\t\t\tdev->stats.rx_dropped++;\n\t\t\t\tdev->stats.rx_length_errors++;\n\t\t\t\trtl8169_mark_to_asic(desc, tp->rx_buf_sz);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\trtl8169_rx_csum(skb, desc);\n\n\t\t\tif (rtl8169_try_rx_copy(&skb, tp, pkt_size, addr)) {\n\t\t\t\tpci_dma_sync_single_for_device(pdev, addr,\n\t\t\t\t\tpkt_size, PCI_DMA_FROMDEVICE);\n\t\t\t\trtl8169_mark_to_asic(desc, tp->rx_buf_sz);\n\t\t\t} else {\n\t\t\t\tpci_unmap_single(pdev, addr, pkt_size,\n\t\t\t\t\t\t PCI_DMA_FROMDEVICE);\n\t\t\t\ttp->Rx_skbuff[entry] = NULL;\n\t\t\t}\n\n\t\t\tskb_put(skb, pkt_size);\n\t\t\tskb->protocol = eth_type_trans(skb, dev);\n\n\t\t\tif (rtl8169_rx_vlan_skb(tp, desc, skb) < 0)\n\t\t\t\tnetif_receive_skb(skb);\n\n\t\t\tdev->last_rx = jiffies;\n\t\t\tdev->stats.rx_bytes += pkt_size;\n\t\t\tdev->stats.rx_packets++;\n\t\t}\n\n\t\t/* Work around for AMD plateform. */\n\t\tif ((desc->opts2 & cpu_to_le32(0xfffe000)) &&\n\t\t    (tp->mac_version == RTL_GIGA_MAC_VER_05)) {\n\t\t\tdesc->opts2 = 0;\n\t\t\tcur_rx++;\n\t\t}\n\t}\n\n\tcount = cur_rx - tp->cur_rx;\n\ttp->cur_rx = cur_rx;\n\n\tdelta = rtl8169_rx_fill(tp, dev, tp->dirty_rx, tp->cur_rx);\n\tif (!delta && count && netif_msg_intr(tp))\n\t\tprintk(KERN_INFO \"%s: no Rx buffer allocated\\n\", dev->name);\n\ttp->dirty_rx += delta;\n\n\t/*\n\t * FIXME: until there is periodic timer to try and refill the ring,\n\t * a temporary shortage may definitely kill the Rx process.\n\t * - disable the asic to try and avoid an overflow and kick it again\n\t *   after refill ?\n\t * - how do others driver handle this condition (Uh oh...).\n\t */\n\tif ((tp->dirty_rx + NUM_RX_DESC == tp->cur_rx) && netif_msg_intr(tp))\n\t\tprintk(KERN_EMERG \"%s: Rx buffers exhausted\\n\", dev->name);\n\n\treturn count;\n}",
        "func": "static int rtl8169_rx_interrupt(struct net_device *dev,\n\t\t\t\tstruct rtl8169_private *tp,\n\t\t\t\tvoid __iomem *ioaddr, u32 budget)\n{\n\tunsigned int cur_rx, rx_left;\n\tunsigned int delta, count;\n\n\tcur_rx = tp->cur_rx;\n\trx_left = NUM_RX_DESC + tp->dirty_rx - cur_rx;\n\trx_left = min(rx_left, budget);\n\n\tfor (; rx_left > 0; rx_left--, cur_rx++) {\n\t\tunsigned int entry = cur_rx % NUM_RX_DESC;\n\t\tstruct RxDesc *desc = tp->RxDescArray + entry;\n\t\tu32 status;\n\n\t\trmb();\n\t\tstatus = le32_to_cpu(desc->opts1);\n\n\t\tif (status & DescOwn)\n\t\t\tbreak;\n\t\tif (unlikely(status & RxRES)) {\n\t\t\tif (netif_msg_rx_err(tp)) {\n\t\t\t\tprintk(KERN_INFO\n\t\t\t\t       \"%s: Rx ERROR. status = %08x\\n\",\n\t\t\t\t       dev->name, status);\n\t\t\t}\n\t\t\tdev->stats.rx_errors++;\n\t\t\tif (status & (RxRWT | RxRUNT))\n\t\t\t\tdev->stats.rx_length_errors++;\n\t\t\tif (status & RxCRC)\n\t\t\t\tdev->stats.rx_crc_errors++;\n\t\t\tif (status & RxFOVF) {\n\t\t\t\trtl8169_schedule_work(dev, rtl8169_reset_task);\n\t\t\t\tdev->stats.rx_fifo_errors++;\n\t\t\t}\n\t\t\trtl8169_mark_to_asic(desc, tp->rx_buf_sz);\n\t\t} else {\n\t\t\tstruct sk_buff *skb = tp->Rx_skbuff[entry];\n\t\t\tdma_addr_t addr = le64_to_cpu(desc->addr);\n\t\t\tint pkt_size = (status & 0x00001FFF) - 4;\n\t\t\tstruct pci_dev *pdev = tp->pci_dev;\n\n\t\t\t/*\n\t\t\t * The driver does not support incoming fragmented\n\t\t\t * frames. They are seen as a symptom of over-mtu\n\t\t\t * sized frames.\n\t\t\t */\n\t\t\tif (unlikely(rtl8169_fragmented_frame(status))) {\n\t\t\t\tdev->stats.rx_dropped++;\n\t\t\t\tdev->stats.rx_length_errors++;\n\t\t\t\trtl8169_mark_to_asic(desc, tp->rx_buf_sz);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\trtl8169_rx_csum(skb, desc);\n\n\t\t\tif (rtl8169_try_rx_copy(&skb, tp, pkt_size, addr)) {\n\t\t\t\tpci_dma_sync_single_for_device(pdev, addr,\n\t\t\t\t\tpkt_size, PCI_DMA_FROMDEVICE);\n\t\t\t\trtl8169_mark_to_asic(desc, tp->rx_buf_sz);\n\t\t\t} else {\n\t\t\t\tpci_unmap_single(pdev, addr, tp->rx_buf_sz,\n\t\t\t\t\t\t PCI_DMA_FROMDEVICE);\n\t\t\t\ttp->Rx_skbuff[entry] = NULL;\n\t\t\t}\n\n\t\t\tskb_put(skb, pkt_size);\n\t\t\tskb->protocol = eth_type_trans(skb, dev);\n\n\t\t\tif (rtl8169_rx_vlan_skb(tp, desc, skb) < 0)\n\t\t\t\tnetif_receive_skb(skb);\n\n\t\t\tdev->last_rx = jiffies;\n\t\t\tdev->stats.rx_bytes += pkt_size;\n\t\t\tdev->stats.rx_packets++;\n\t\t}\n\n\t\t/* Work around for AMD plateform. */\n\t\tif ((desc->opts2 & cpu_to_le32(0xfffe000)) &&\n\t\t    (tp->mac_version == RTL_GIGA_MAC_VER_05)) {\n\t\t\tdesc->opts2 = 0;\n\t\t\tcur_rx++;\n\t\t}\n\t}\n\n\tcount = cur_rx - tp->cur_rx;\n\ttp->cur_rx = cur_rx;\n\n\tdelta = rtl8169_rx_fill(tp, dev, tp->dirty_rx, tp->cur_rx);\n\tif (!delta && count && netif_msg_intr(tp))\n\t\tprintk(KERN_INFO \"%s: no Rx buffer allocated\\n\", dev->name);\n\ttp->dirty_rx += delta;\n\n\t/*\n\t * FIXME: until there is periodic timer to try and refill the ring,\n\t * a temporary shortage may definitely kill the Rx process.\n\t * - disable the asic to try and avoid an overflow and kick it again\n\t *   after refill ?\n\t * - how do others driver handle this condition (Uh oh...).\n\t */\n\tif ((tp->dirty_rx + NUM_RX_DESC == tp->cur_rx) && netif_msg_intr(tp))\n\t\tprintk(KERN_EMERG \"%s: Rx buffers exhausted\\n\", dev->name);\n\n\treturn count;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -60,7 +60,7 @@\n \t\t\t\t\tpkt_size, PCI_DMA_FROMDEVICE);\n \t\t\t\trtl8169_mark_to_asic(desc, tp->rx_buf_sz);\n \t\t\t} else {\n-\t\t\t\tpci_unmap_single(pdev, addr, pkt_size,\n+\t\t\t\tpci_unmap_single(pdev, addr, tp->rx_buf_sz,\n \t\t\t\t\t\t PCI_DMA_FROMDEVICE);\n \t\t\t\ttp->Rx_skbuff[entry] = NULL;\n \t\t\t}",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\t\tpci_unmap_single(pdev, addr, pkt_size,"
            ],
            "added_lines": [
                "\t\t\t\tpci_unmap_single(pdev, addr, tp->rx_buf_sz,"
            ]
        }
    },
    {
        "cve_id": "CVE-2009-3604",
        "func_name": "poppler/SplashOutputDev::drawImage",
        "description": "The Splash::drawImage function in Splash.cc in Xpdf 2.x and 3.x before 3.02pl4, and Poppler 0.x, as used in GPdf and kdegraphics KPDF, does not properly allocate memory, which allows remote attackers to cause a denial of service (application crash) or possibly execute arbitrary code via a crafted PDF document that triggers a NULL pointer dereference or a heap-based buffer overflow.",
        "git_url": "http://cgit.freedesktop.org/poppler/poppler/commit/?id=284a928996&id2=75c3466ba2",
        "commit_title": "",
        "commit_text": "",
        "func_before": "void SplashOutputDev::drawImage(GfxState *state, Object *ref, Stream *str,\n\t\t\t\tint width, int height,\n\t\t\t\tGfxImageColorMap *colorMap,\n\t\t\t\tint *maskColors, GBool inlineImg) {\n  double *ctm;\n  SplashCoord mat[6];\n  SplashOutImageData imgData;\n  SplashColorMode srcMode;\n  SplashImageSource src;\n  GfxGray gray;\n  GfxRGB rgb;\n#if SPLASH_CMYK\n  GfxCMYK cmyk;\n#endif\n  Guchar pix;\n  int n, i;\n\n  ctm = state->getCTM();\n  mat[0] = ctm[0];\n  mat[1] = ctm[1];\n  mat[2] = -ctm[2];\n  mat[3] = -ctm[3];\n  mat[4] = ctm[2] + ctm[4];\n  mat[5] = ctm[3] + ctm[5];\n\n  imgData.imgStr = new ImageStream(str, width,\n\t\t\t\t   colorMap->getNumPixelComps(),\n\t\t\t\t   colorMap->getBits());\n  imgData.imgStr->reset();\n  imgData.colorMap = colorMap;\n  imgData.maskColors = maskColors;\n  imgData.colorMode = colorMode;\n  imgData.width = width;\n  imgData.height = height;\n  imgData.y = 0;\n\n  // special case for one-channel (monochrome/gray/separation) images:\n  // build a lookup table here\n  imgData.lookup = NULL;\n  if (colorMap->getNumPixelComps() == 1) {\n    n = 1 << colorMap->getBits();\n    switch (colorMode) {\n    case splashModeMono1:\n    case splashModeMono8:\n      imgData.lookup = (SplashColorPtr)gmalloc(n);\n      for (i = 0; i < n; ++i) {\n\tpix = (Guchar)i;\n\tcolorMap->getGray(&pix, &gray);\n\timgData.lookup[i] = colToByte(gray);\n      }\n      break;\n    case splashModeRGB8:\n    case splashModeBGR8:\n      imgData.lookup = (SplashColorPtr)gmallocn(n, 3);\n      for (i = 0; i < n; ++i) {\n\tpix = (Guchar)i;\n\tcolorMap->getRGB(&pix, &rgb);\n\timgData.lookup[3*i] = colToByte(rgb.r);\n\timgData.lookup[3*i+1] = colToByte(rgb.g);\n\timgData.lookup[3*i+2] = colToByte(rgb.b);\n      }\n      break;\n    case splashModeXBGR8:\n      imgData.lookup = (SplashColorPtr)gmallocn(n, 3);\n      for (i = 0; i < n; ++i) {\n\tpix = (Guchar)i;\n\tcolorMap->getRGB(&pix, &rgb);\n\timgData.lookup[4*i] = colToByte(rgb.r);\n\timgData.lookup[4*i+1] = colToByte(rgb.g);\n\timgData.lookup[4*i+2] = colToByte(rgb.b);\n\timgData.lookup[4*i+3] = 255;\n      }\n      break;\n#if SPLASH_CMYK\n    case splashModeCMYK8:\n      imgData.lookup = (SplashColorPtr)gmallocn(n, 4);\n      for (i = 0; i < n; ++i) {\n\tpix = (Guchar)i;\n\tcolorMap->getCMYK(&pix, &cmyk);\n\timgData.lookup[4*i] = colToByte(cmyk.c);\n\timgData.lookup[4*i+1] = colToByte(cmyk.m);\n\timgData.lookup[4*i+2] = colToByte(cmyk.y);\n\timgData.lookup[4*i+3] = colToByte(cmyk.k);\n      }\n      break;\n#endif\n      break;\n    }\n  }\n\n  if (colorMode == splashModeMono1) {\n    srcMode = splashModeMono8;\n  } else {\n    srcMode = colorMode;\n  }\n  src = maskColors ? &alphaImageSrc : &imageSrc;\n  splash->drawImage(src, &imgData, srcMode, maskColors ? gTrue : gFalse,\n\t\t    width, height, mat);\n  if (inlineImg) {\n    while (imgData.y < height) {\n      imgData.imgStr->getLine();\n      ++imgData.y;\n    }\n  }\n\n  gfree(imgData.lookup);\n  delete imgData.imgStr;\n  str->close();\n}",
        "func": "void SplashOutputDev::drawImage(GfxState *state, Object *ref, Stream *str,\n\t\t\t\tint width, int height,\n\t\t\t\tGfxImageColorMap *colorMap,\n\t\t\t\tint *maskColors, GBool inlineImg) {\n  double *ctm;\n  SplashCoord mat[6];\n  SplashOutImageData imgData;\n  SplashColorMode srcMode;\n  SplashImageSource src;\n  GfxGray gray;\n  GfxRGB rgb;\n#if SPLASH_CMYK\n  GfxCMYK cmyk;\n#endif\n  Guchar pix;\n  int n, i;\n\n  ctm = state->getCTM();\n  mat[0] = ctm[0];\n  mat[1] = ctm[1];\n  mat[2] = -ctm[2];\n  mat[3] = -ctm[3];\n  mat[4] = ctm[2] + ctm[4];\n  mat[5] = ctm[3] + ctm[5];\n\n  imgData.imgStr = new ImageStream(str, width,\n\t\t\t\t   colorMap->getNumPixelComps(),\n\t\t\t\t   colorMap->getBits());\n  imgData.imgStr->reset();\n  imgData.colorMap = colorMap;\n  imgData.maskColors = maskColors;\n  imgData.colorMode = colorMode;\n  imgData.width = width;\n  imgData.height = height;\n  imgData.y = 0;\n\n  // special case for one-channel (monochrome/gray/separation) images:\n  // build a lookup table here\n  imgData.lookup = NULL;\n  if (colorMap->getNumPixelComps() == 1) {\n    n = 1 << colorMap->getBits();\n    switch (colorMode) {\n    case splashModeMono1:\n    case splashModeMono8:\n      imgData.lookup = (SplashColorPtr)gmalloc(n);\n      for (i = 0; i < n; ++i) {\n\tpix = (Guchar)i;\n\tcolorMap->getGray(&pix, &gray);\n\timgData.lookup[i] = colToByte(gray);\n      }\n      break;\n    case splashModeRGB8:\n    case splashModeBGR8:\n      imgData.lookup = (SplashColorPtr)gmallocn(n, 3);\n      for (i = 0; i < n; ++i) {\n\tpix = (Guchar)i;\n\tcolorMap->getRGB(&pix, &rgb);\n\timgData.lookup[3*i] = colToByte(rgb.r);\n\timgData.lookup[3*i+1] = colToByte(rgb.g);\n\timgData.lookup[3*i+2] = colToByte(rgb.b);\n      }\n      break;\n    case splashModeXBGR8:\n      imgData.lookup = (SplashColorPtr)gmallocn(n, 4);\n      for (i = 0; i < n; ++i) {\n\tpix = (Guchar)i;\n\tcolorMap->getRGB(&pix, &rgb);\n\timgData.lookup[4*i] = colToByte(rgb.r);\n\timgData.lookup[4*i+1] = colToByte(rgb.g);\n\timgData.lookup[4*i+2] = colToByte(rgb.b);\n\timgData.lookup[4*i+3] = 255;\n      }\n      break;\n#if SPLASH_CMYK\n    case splashModeCMYK8:\n      imgData.lookup = (SplashColorPtr)gmallocn(n, 4);\n      for (i = 0; i < n; ++i) {\n\tpix = (Guchar)i;\n\tcolorMap->getCMYK(&pix, &cmyk);\n\timgData.lookup[4*i] = colToByte(cmyk.c);\n\timgData.lookup[4*i+1] = colToByte(cmyk.m);\n\timgData.lookup[4*i+2] = colToByte(cmyk.y);\n\timgData.lookup[4*i+3] = colToByte(cmyk.k);\n      }\n      break;\n#endif\n      break;\n    }\n  }\n\n  if (colorMode == splashModeMono1) {\n    srcMode = splashModeMono8;\n  } else {\n    srcMode = colorMode;\n  }\n  src = maskColors ? &alphaImageSrc : &imageSrc;\n  splash->drawImage(src, &imgData, srcMode, maskColors ? gTrue : gFalse,\n\t\t    width, height, mat);\n  if (inlineImg) {\n    while (imgData.y < height) {\n      imgData.imgStr->getLine();\n      ++imgData.y;\n    }\n  }\n\n  gfree(imgData.lookup);\n  delete imgData.imgStr;\n  str->close();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -61,7 +61,7 @@\n       }\n       break;\n     case splashModeXBGR8:\n-      imgData.lookup = (SplashColorPtr)gmallocn(n, 3);\n+      imgData.lookup = (SplashColorPtr)gmallocn(n, 4);\n       for (i = 0; i < n; ++i) {\n \tpix = (Guchar)i;\n \tcolorMap->getRGB(&pix, &rgb);",
        "diff_line_info": {
            "deleted_lines": [
                "      imgData.lookup = (SplashColorPtr)gmallocn(n, 3);"
            ],
            "added_lines": [
                "      imgData.lookup = (SplashColorPtr)gmallocn(n, 4);"
            ]
        }
    },
    {
        "cve_id": "CVE-2009-3604",
        "func_name": "poppler/poppler_page_prepare_output_dev",
        "description": "The Splash::drawImage function in Splash.cc in Xpdf 2.x and 3.x before 3.02pl4, and Poppler 0.x, as used in GPdf and kdegraphics KPDF, does not properly allocate memory, which allows remote attackers to cause a denial of service (application crash) or possibly execute arbitrary code via a crafted PDF document that triggers a NULL pointer dereference or a heap-based buffer overflow.",
        "git_url": "http://cgit.freedesktop.org/poppler/poppler/commit/?id=9cf2325fb2",
        "commit_title": "",
        "commit_text": "",
        "func_before": "static void\npoppler_page_prepare_output_dev (PopplerPage *page,\n\t\t\t\t double scale,\n\t\t\t\t int rotation,\n\t\t\t\t gboolean transparent,\n\t\t\t\t OutputDevData *output_dev_data)\n{\n  CairoOutputDev *output_dev;\n  cairo_surface_t *surface;\n  double width, height;\n  int cairo_width, cairo_height, cairo_rowstride, rotate;\n  unsigned char *cairo_data;\n\n  rotate = rotation + page->page->getRotate ();\n  if (rotate == 90 || rotate == 270) {\n    height = page->page->getCropWidth ();\n    width = page->page->getCropHeight ();\n  } else {\n    width = page->page->getCropWidth ();\n    height = page->page->getCropHeight ();\n  }\n\n  cairo_width = (int) ceil(width * scale);\n  cairo_height = (int) ceil(height * scale);\n\n  output_dev = page->document->output_dev;\n  cairo_rowstride = cairo_width * 4;\n  cairo_data = (guchar *) gmalloc (cairo_height * cairo_rowstride);\n  if (transparent)\n      memset (cairo_data, 0x00, cairo_height * cairo_rowstride);\n  else\n      memset (cairo_data, 0xff, cairo_height * cairo_rowstride);\n\n  surface = cairo_image_surface_create_for_data(cairo_data,\n\t\t\t\t\t\tCAIRO_FORMAT_ARGB32,\n\t  \t\t\t\t\tcairo_width, cairo_height, \n\t\t\t\t\t\tcairo_rowstride);\n\n  output_dev_data->cairo_data = cairo_data;\n  output_dev_data->surface = surface;\n  output_dev_data->cairo = cairo_create (surface);\n  output_dev->setCairo (output_dev_data->cairo);\n}",
        "func": "static void\npoppler_page_prepare_output_dev (PopplerPage *page,\n\t\t\t\t double scale,\n\t\t\t\t int rotation,\n\t\t\t\t gboolean transparent,\n\t\t\t\t OutputDevData *output_dev_data)\n{\n  CairoOutputDev *output_dev;\n  cairo_surface_t *surface;\n  double width, height;\n  int cairo_width, cairo_height, cairo_rowstride, rotate;\n  unsigned char *cairo_data;\n\n  rotate = rotation + page->page->getRotate ();\n  if (rotate == 90 || rotate == 270) {\n    height = page->page->getCropWidth ();\n    width = page->page->getCropHeight ();\n  } else {\n    width = page->page->getCropWidth ();\n    height = page->page->getCropHeight ();\n  }\n\n  cairo_width = (int) ceil(width * scale);\n  cairo_height = (int) ceil(height * scale);\n\n  output_dev = page->document->output_dev;\n  cairo_rowstride = cairo_width * 4;\n  cairo_data = (guchar *) gmallocn (cairo_height, cairo_rowstride);\n  if (transparent)\n      memset (cairo_data, 0x00, cairo_height * cairo_rowstride);\n  else\n      memset (cairo_data, 0xff, cairo_height * cairo_rowstride);\n\n  surface = cairo_image_surface_create_for_data(cairo_data,\n\t\t\t\t\t\tCAIRO_FORMAT_ARGB32,\n\t  \t\t\t\t\tcairo_width, cairo_height, \n\t\t\t\t\t\tcairo_rowstride);\n\n  output_dev_data->cairo_data = cairo_data;\n  output_dev_data->surface = surface;\n  output_dev_data->cairo = cairo_create (surface);\n  output_dev->setCairo (output_dev_data->cairo);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -25,7 +25,7 @@\n \n   output_dev = page->document->output_dev;\n   cairo_rowstride = cairo_width * 4;\n-  cairo_data = (guchar *) gmalloc (cairo_height * cairo_rowstride);\n+  cairo_data = (guchar *) gmallocn (cairo_height, cairo_rowstride);\n   if (transparent)\n       memset (cairo_data, 0x00, cairo_height * cairo_rowstride);\n   else",
        "diff_line_info": {
            "deleted_lines": [
                "  cairo_data = (guchar *) gmalloc (cairo_height * cairo_rowstride);"
            ],
            "added_lines": [
                "  cairo_data = (guchar *) gmallocn (cairo_height, cairo_rowstride);"
            ]
        }
    },
    {
        "cve_id": "CVE-2009-3604",
        "func_name": "poppler/SplashBitmap::SplashBitmap",
        "description": "The Splash::drawImage function in Splash.cc in Xpdf 2.x and 3.x before 3.02pl4, and Poppler 0.x, as used in GPdf and kdegraphics KPDF, does not properly allocate memory, which allows remote attackers to cause a denial of service (application crash) or possibly execute arbitrary code via a crafted PDF document that triggers a NULL pointer dereference or a heap-based buffer overflow.",
        "git_url": "http://cgit.freedesktop.org/poppler/poppler/commit/?id=9cf2325fb2",
        "commit_title": "",
        "commit_text": "",
        "func_before": "SplashBitmap::SplashBitmap(int widthA, int heightA, int rowPad,\n\t\t\t   SplashColorMode modeA, GBool alphaA,\n\t\t\t   GBool topDown) {\n  width = widthA;\n  height = heightA;\n  mode = modeA;\n  switch (mode) {\n  case splashModeMono1:\n    rowSize = (width + 7) >> 3;\n    break;\n  case splashModeMono8:\n    rowSize = width;\n    break;\n  case splashModeRGB8:\n  case splashModeBGR8:\n    rowSize = width * 3;\n    break;\n  case splashModeXBGR8:\n    rowSize = width * 4;\n    break;\n#if SPLASH_CMYK\n  case splashModeCMYK8:\n    rowSize = width * 4;\n    break;\n#endif\n  }\n  rowSize += rowPad - 1;\n  rowSize -= rowSize % rowPad;\n  data = (SplashColorPtr)gmalloc(rowSize * height);\n  if (!topDown) {\n    data += (height - 1) * rowSize;\n    rowSize = -rowSize;\n  }\n  if (alphaA) {\n    alpha = (Guchar *)gmalloc(width * height);\n  } else {\n    alpha = NULL;\n  }\n}",
        "func": "SplashBitmap::SplashBitmap(int widthA, int heightA, int rowPad,\n\t\t\t   SplashColorMode modeA, GBool alphaA,\n\t\t\t   GBool topDown) {\n  width = widthA;\n  height = heightA;\n  mode = modeA;\n  switch (mode) {\n  case splashModeMono1:\n    rowSize = (width + 7) >> 3;\n    break;\n  case splashModeMono8:\n    rowSize = width;\n    break;\n  case splashModeRGB8:\n  case splashModeBGR8:\n    rowSize = width * 3;\n    break;\n  case splashModeXBGR8:\n    rowSize = width * 4;\n    break;\n#if SPLASH_CMYK\n  case splashModeCMYK8:\n    rowSize = width * 4;\n    break;\n#endif\n  }\n  rowSize += rowPad - 1;\n  rowSize -= rowSize % rowPad;\n  data = (SplashColorPtr)gmallocn(rowSize, height);\n  if (!topDown) {\n    data += (height - 1) * rowSize;\n    rowSize = -rowSize;\n  }\n  if (alphaA) {\n    alpha = (Guchar *)gmallocn(width, height);\n  } else {\n    alpha = NULL;\n  }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -26,13 +26,13 @@\n   }\n   rowSize += rowPad - 1;\n   rowSize -= rowSize % rowPad;\n-  data = (SplashColorPtr)gmalloc(rowSize * height);\n+  data = (SplashColorPtr)gmallocn(rowSize, height);\n   if (!topDown) {\n     data += (height - 1) * rowSize;\n     rowSize = -rowSize;\n   }\n   if (alphaA) {\n-    alpha = (Guchar *)gmalloc(width * height);\n+    alpha = (Guchar *)gmallocn(width, height);\n   } else {\n     alpha = NULL;\n   }",
        "diff_line_info": {
            "deleted_lines": [
                "  data = (SplashColorPtr)gmalloc(rowSize * height);",
                "    alpha = (Guchar *)gmalloc(width * height);"
            ],
            "added_lines": [
                "  data = (SplashColorPtr)gmallocn(rowSize, height);",
                "    alpha = (Guchar *)gmallocn(width, height);"
            ]
        }
    },
    {
        "cve_id": "CVE-2009-3604",
        "func_name": "poppler/SplashFTFont::makeGlyph",
        "description": "The Splash::drawImage function in Splash.cc in Xpdf 2.x and 3.x before 3.02pl4, and Poppler 0.x, as used in GPdf and kdegraphics KPDF, does not properly allocate memory, which allows remote attackers to cause a denial of service (application crash) or possibly execute arbitrary code via a crafted PDF document that triggers a NULL pointer dereference or a heap-based buffer overflow.",
        "git_url": "http://cgit.freedesktop.org/poppler/poppler/commit/?id=9cf2325fb2",
        "commit_title": "",
        "commit_text": "",
        "func_before": "GBool SplashFTFont::makeGlyph(int c, int xFrac, int yFrac,\n\t\t\t      SplashGlyphBitmap *bitmap, int x0, int y0, SplashClip *clip, SplashClipResult *clipRes) {\n  SplashFTFontFile *ff;\n  FT_Vector offset;\n  FT_GlyphSlot slot;\n  FT_UInt gid;\n  int rowSize;\n  Guchar *p, *q;\n  int i;\n\n  ff = (SplashFTFontFile *)fontFile;\n\n  ff->face->size = sizeObj;\n  offset.x = (FT_Pos)(int)((SplashCoord)xFrac * splashFontFractionMul * 64);\n  offset.y = 0;\n  FT_Set_Transform(ff->face, &matrix, &offset);\n  slot = ff->face->glyph;\n\n  if (ff->codeToGID && c < ff->codeToGIDLen) {\n    gid = (FT_UInt)ff->codeToGID[c];\n  } else {\n    gid = (FT_UInt)c;\n  }\n  if (ff->trueType && gid == 0) {\n    // skip the TrueType notdef glyph\n    return gFalse;\n  }\n\n  // if we have the FT2 bytecode interpreter, autohinting won't be used\n#ifdef TT_CONFIG_OPTION_BYTECODE_INTERPRETER\n  if (FT_Load_Glyph(ff->face, gid,\n\t\t    aa ? FT_LOAD_NO_BITMAP : FT_LOAD_DEFAULT)) {\n    return gFalse;\n  }\n#else\n  // FT2's autohinting doesn't always work very well (especially with\n  // font subsets), so turn it off if anti-aliasing is enabled; if\n  // anti-aliasing is disabled, this seems to be a tossup - some fonts\n  // look better with hinting, some without, so leave hinting on\n  if (FT_Load_Glyph(ff->face, gid,\n\t\t    aa ? FT_LOAD_NO_HINTING | FT_LOAD_NO_BITMAP\n                       : FT_LOAD_DEFAULT)) {\n    return gFalse;\n  }\n#endif\n\n  FT_Glyph_Metrics *glyphMetrics = &(ff->face->glyph->metrics);\n  // prelimirary values from FT_Glyph_Metrics\n  bitmap->x = splashRound(-glyphMetrics->horiBearingX / 64.0);\n  bitmap->y = splashRound(glyphMetrics->horiBearingY / 64.0);\n  bitmap->w = splashRound(glyphMetrics->width / 64.0);\n  bitmap->h = splashRound(glyphMetrics->height / 64.0);\n\n  *clipRes = clip->testRect(x0 - bitmap->x,\n                            y0 - bitmap->y,\n                            x0 - bitmap->x + bitmap->w,\n                            y0 - bitmap->y + bitmap->h);\n  if (*clipRes == splashClipAllOutside) {\n    bitmap->freeData = gFalse;\n    return gTrue;\n  }\n\n  if (FT_Render_Glyph(slot, aa ? ft_render_mode_normal\n\t\t               : ft_render_mode_mono)) {\n    return gFalse;\n  }\n\n  bitmap->x = -slot->bitmap_left;\n  bitmap->y = slot->bitmap_top;\n  bitmap->w = slot->bitmap.width;\n  bitmap->h = slot->bitmap.rows;\n  bitmap->aa = aa;\n  if (aa) {\n    rowSize = bitmap->w;\n  } else {\n    rowSize = (bitmap->w + 7) >> 3;\n  }\n  bitmap->data = (Guchar *)gmalloc(rowSize * bitmap->h);\n  bitmap->freeData = gTrue;\n  for (i = 0, p = bitmap->data, q = slot->bitmap.buffer;\n       i < bitmap->h;\n       ++i, p += rowSize, q += slot->bitmap.pitch) {\n    memcpy(p, q, rowSize);\n  }\n\n  return gTrue;\n}",
        "func": "GBool SplashFTFont::makeGlyph(int c, int xFrac, int yFrac,\n\t\t\t      SplashGlyphBitmap *bitmap, int x0, int y0, SplashClip *clip, SplashClipResult *clipRes) {\n  SplashFTFontFile *ff;\n  FT_Vector offset;\n  FT_GlyphSlot slot;\n  FT_UInt gid;\n  int rowSize;\n  Guchar *p, *q;\n  int i;\n\n  ff = (SplashFTFontFile *)fontFile;\n\n  ff->face->size = sizeObj;\n  offset.x = (FT_Pos)(int)((SplashCoord)xFrac * splashFontFractionMul * 64);\n  offset.y = 0;\n  FT_Set_Transform(ff->face, &matrix, &offset);\n  slot = ff->face->glyph;\n\n  if (ff->codeToGID && c < ff->codeToGIDLen) {\n    gid = (FT_UInt)ff->codeToGID[c];\n  } else {\n    gid = (FT_UInt)c;\n  }\n  if (ff->trueType && gid == 0) {\n    // skip the TrueType notdef glyph\n    return gFalse;\n  }\n\n  // if we have the FT2 bytecode interpreter, autohinting won't be used\n#ifdef TT_CONFIG_OPTION_BYTECODE_INTERPRETER\n  if (FT_Load_Glyph(ff->face, gid,\n\t\t    aa ? FT_LOAD_NO_BITMAP : FT_LOAD_DEFAULT)) {\n    return gFalse;\n  }\n#else\n  // FT2's autohinting doesn't always work very well (especially with\n  // font subsets), so turn it off if anti-aliasing is enabled; if\n  // anti-aliasing is disabled, this seems to be a tossup - some fonts\n  // look better with hinting, some without, so leave hinting on\n  if (FT_Load_Glyph(ff->face, gid,\n\t\t    aa ? FT_LOAD_NO_HINTING | FT_LOAD_NO_BITMAP\n                       : FT_LOAD_DEFAULT)) {\n    return gFalse;\n  }\n#endif\n\n  FT_Glyph_Metrics *glyphMetrics = &(ff->face->glyph->metrics);\n  // prelimirary values from FT_Glyph_Metrics\n  bitmap->x = splashRound(-glyphMetrics->horiBearingX / 64.0);\n  bitmap->y = splashRound(glyphMetrics->horiBearingY / 64.0);\n  bitmap->w = splashRound(glyphMetrics->width / 64.0);\n  bitmap->h = splashRound(glyphMetrics->height / 64.0);\n\n  *clipRes = clip->testRect(x0 - bitmap->x,\n                            y0 - bitmap->y,\n                            x0 - bitmap->x + bitmap->w,\n                            y0 - bitmap->y + bitmap->h);\n  if (*clipRes == splashClipAllOutside) {\n    bitmap->freeData = gFalse;\n    return gTrue;\n  }\n\n  if (FT_Render_Glyph(slot, aa ? ft_render_mode_normal\n\t\t               : ft_render_mode_mono)) {\n    return gFalse;\n  }\n\n  bitmap->x = -slot->bitmap_left;\n  bitmap->y = slot->bitmap_top;\n  bitmap->w = slot->bitmap.width;\n  bitmap->h = slot->bitmap.rows;\n  bitmap->aa = aa;\n  if (aa) {\n    rowSize = bitmap->w;\n  } else {\n    rowSize = (bitmap->w + 7) >> 3;\n  }\n  bitmap->data = (Guchar *)gmallocn(rowSize, bitmap->h);\n  bitmap->freeData = gTrue;\n  for (i = 0, p = bitmap->data, q = slot->bitmap.buffer;\n       i < bitmap->h;\n       ++i, p += rowSize, q += slot->bitmap.pitch) {\n    memcpy(p, q, rowSize);\n  }\n\n  return gTrue;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -75,7 +75,7 @@\n   } else {\n     rowSize = (bitmap->w + 7) >> 3;\n   }\n-  bitmap->data = (Guchar *)gmalloc(rowSize * bitmap->h);\n+  bitmap->data = (Guchar *)gmallocn(rowSize, bitmap->h);\n   bitmap->freeData = gTrue;\n   for (i = 0, p = bitmap->data, q = slot->bitmap.buffer;\n        i < bitmap->h;",
        "diff_line_info": {
            "deleted_lines": [
                "  bitmap->data = (Guchar *)gmalloc(rowSize * bitmap->h);"
            ],
            "added_lines": [
                "  bitmap->data = (Guchar *)gmallocn(rowSize, bitmap->h);"
            ]
        }
    },
    {
        "cve_id": "CVE-2009-3604",
        "func_name": "poppler/Splash::fillImageMask",
        "description": "The Splash::drawImage function in Splash.cc in Xpdf 2.x and 3.x before 3.02pl4, and Poppler 0.x, as used in GPdf and kdegraphics KPDF, does not properly allocate memory, which allows remote attackers to cause a denial of service (application crash) or possibly execute arbitrary code via a crafted PDF document that triggers a NULL pointer dereference or a heap-based buffer overflow.",
        "git_url": "http://cgit.freedesktop.org/poppler/poppler/commit/?id=9cf2325fb2",
        "commit_title": "",
        "commit_text": "",
        "func_before": "SplashError Splash::fillImageMask(SplashImageMaskSource src, void *srcData,\n\t\t\t\t  int w, int h, SplashCoord *mat,\n\t\t\t\t  GBool glyphMode) {\n  SplashPipe pipe;\n  GBool rot;\n  SplashCoord xScale, yScale, xShear, yShear, yShear1;\n  int tx, tx2, ty, ty2, scaledWidth, scaledHeight, xSign, ySign;\n  int ulx, uly, llx, lly, urx, ury, lrx, lry;\n  int ulx1, uly1, llx1, lly1, urx1, ury1, lrx1, lry1;\n  int xMin, xMax, yMin, yMax;\n  SplashClipResult clipRes, clipRes2;\n  int yp, yq, yt, yStep, lastYStep;\n  int xp, xq, xt, xStep, xSrc;\n  int k1, spanXMin, spanXMax, spanY;\n  SplashColorPtr pixBuf, p;\n  int pixAcc;\n  int x, y, x1, x2, y2;\n  SplashCoord y1;\n  int n, m, i, j;\n\n  if (debugMode) {\n    printf(\"fillImageMask: w=%d h=%d mat=[%.2f %.2f %.2f %.2f %.2f %.2f]\\n\",\n\t   w, h, (double)mat[0], (double)mat[1], (double)mat[2],\n\t   (double)mat[3], (double)mat[4], (double)mat[5]);\n  }\n\n  if (w == 0 && h == 0) return splashErrZeroImage;\n\n  // check for singular matrix\n  if (splashAbs(mat[0] * mat[3] - mat[1] * mat[2]) < 0.000001) {\n    return splashErrSingularMatrix;\n  }\n\n  // compute scale, shear, rotation, translation parameters\n  rot = splashAbs(mat[1]) > splashAbs(mat[0]);\n  if (rot) {\n    xScale = -mat[1];\n    yScale = mat[2] - (mat[0] * mat[3]) / mat[1];\n    xShear = -mat[3] / yScale;\n    yShear = -mat[0] / mat[1];\n  } else {\n    xScale = mat[0];\n    yScale = mat[3] - (mat[1] * mat[2]) / mat[0];\n    xShear = mat[2] / yScale;\n    yShear = mat[1] / mat[0];\n  }\n  // Note 1: The PDF spec says that all pixels whose *centers* lie\n  // within the region get painted -- but that doesn't seem to match\n  // up with what Acrobat actually does: it ends up leaving gaps\n  // between image stripes.  So we use the same rule here as for\n  // fills: any pixel that overlaps the region gets painted.\n  // Note 2: The \"glyphMode\" flag is a kludge: it switches back to\n  // \"correct\" behavior (matching the spec), for use in rendering Type\n  // 3 fonts.\n  // Note 3: The +/-0.01 in these computations is to avoid floating\n  // point precision problems which can lead to gaps between image\n  // stripes (it can cause image stripes to overlap, but that's a much\n  // less visible problem).\n  if (glyphMode) {\n    if (xScale >= 0) {\n      tx = splashRound(mat[4]);\n      tx2 = splashRound(mat[4] + xScale) - 1;\n    } else {\n      tx = splashRound(mat[4]) - 1;\n      tx2 = splashRound(mat[4] + xScale);\n    }\n  } else {\n    if (xScale >= 0) {\n      tx = splashFloor(mat[4] - 0.01);\n      tx2 = splashFloor(mat[4] + xScale + 0.01);\n    } else {\n      tx = splashFloor(mat[4] + 0.01);\n      tx2 = splashFloor(mat[4] + xScale - 0.01);\n    }\n  }\n  scaledWidth = abs(tx2 - tx) + 1;\n  if (glyphMode) {\n    if (yScale >= 0) {\n      ty = splashRound(mat[5]);\n      ty2 = splashRound(mat[5] + yScale) - 1;\n    } else {\n      ty = splashRound(mat[5]) - 1;\n      ty2 = splashRound(mat[5] + yScale);\n    }\n  } else {\n    if (yScale >= 0) {\n      ty = splashFloor(mat[5] - 0.01);\n      ty2 = splashFloor(mat[5] + yScale + 0.01);\n    } else {\n      ty = splashFloor(mat[5] + 0.01);\n      ty2 = splashFloor(mat[5] + yScale - 0.01);\n    }\n  }\n  scaledHeight = abs(ty2 - ty) + 1;\n  xSign = (xScale < 0) ? -1 : 1;\n  ySign = (yScale < 0) ? -1 : 1;\n  yShear1 = (SplashCoord)xSign * yShear;\n\n  // clipping\n  ulx1 = 0;\n  uly1 = 0;\n  urx1 = xSign * (scaledWidth - 1);\n  ury1 = (int)(yShear * urx1);\n  llx1 = splashRound(xShear * ySign * (scaledHeight - 1));\n  lly1 = ySign * (scaledHeight - 1) + (int)(yShear * llx1);\n  lrx1 = xSign * (scaledWidth - 1) +\n           splashRound(xShear * ySign * (scaledHeight - 1));\n  lry1 = ySign * (scaledHeight - 1) + (int)(yShear * lrx1);\n  if (rot) {\n    ulx = tx + uly1;    uly = ty - ulx1;\n    urx = tx + ury1;    ury = ty - urx1;\n    llx = tx + lly1;    lly = ty - llx1;\n    lrx = tx + lry1;    lry = ty - lrx1;\n  } else {\n    ulx = tx + ulx1;    uly = ty + uly1;\n    urx = tx + urx1;    ury = ty + ury1;\n    llx = tx + llx1;    lly = ty + lly1;\n    lrx = tx + lrx1;    lry = ty + lry1;\n  }\n  xMin = (ulx < urx) ? (ulx < llx) ? (ulx < lrx) ? ulx : lrx\n                                   : (llx < lrx) ? llx : lrx\n\t\t     : (urx < llx) ? (urx < lrx) ? urx : lrx\n                                   : (llx < lrx) ? llx : lrx;\n  xMax = (ulx > urx) ? (ulx > llx) ? (ulx > lrx) ? ulx : lrx\n                                   : (llx > lrx) ? llx : lrx\n\t\t     : (urx > llx) ? (urx > lrx) ? urx : lrx\n                                   : (llx > lrx) ? llx : lrx;\n  yMin = (uly < ury) ? (uly < lly) ? (uly < lry) ? uly : lry\n                                   : (lly < lry) ? lly : lry\n\t\t     : (ury < lly) ? (ury < lry) ? ury : lry\n                                   : (lly < lry) ? lly : lry;\n  yMax = (uly > ury) ? (uly > lly) ? (uly > lry) ? uly : lry\n                                   : (lly > lry) ? lly : lry\n\t\t     : (ury > lly) ? (ury > lry) ? ury : lry\n                                   : (lly > lry) ? lly : lry;\n  clipRes = state->clip->testRect(xMin, yMin, xMax, yMax);\n  opClipRes = clipRes;\n\n  // compute Bresenham parameters for x and y scaling\n  yp = h / scaledHeight;\n  yq = h % scaledHeight;\n  xp = w / scaledWidth;\n  xq = w % scaledWidth;\n\n  // allocate pixel buffer\n  pixBuf = (SplashColorPtr)gmalloc((yp + 1) * w);\n\n  // initialize the pixel pipe\n  pipeInit(&pipe, 0, 0, state->fillPattern, NULL, state->fillAlpha,\n\t   gTrue, gFalse);\n  if (vectorAntialias) {\n    drawAAPixelInit();\n  }\n\n  // init y scale Bresenham\n  yt = 0;\n  lastYStep = 1;\n\n  for (y = 0; y < scaledHeight; ++y) {\n\n    // y scale Bresenham\n    yStep = yp;\n    yt += yq;\n    if (yt >= scaledHeight) {\n      yt -= scaledHeight;\n      ++yStep;\n    }\n\n    // read row(s) from image\n    n = (yp > 0) ? yStep : lastYStep;\n    if (n > 0) {\n      p = pixBuf;\n      for (i = 0; i < n; ++i) {\n\t(*src)(srcData, p);\n\tp += w;\n      }\n    }\n    lastYStep = yStep;\n\n    // loop-invariant constants\n    k1 = splashRound(xShear * ySign * y);\n\n    // clipping test\n    if (clipRes != splashClipAllInside &&\n\t!rot &&\n\t(int)(yShear * k1) ==\n\t  (int)(yShear * (xSign * (scaledWidth - 1) + k1))) {\n      if (xSign > 0) {\n\tspanXMin = tx + k1;\n\tspanXMax = spanXMin + (scaledWidth - 1);\n      } else {\n\tspanXMax = tx + k1;\n\tspanXMin = spanXMax - (scaledWidth - 1);\n      }\n      spanY = ty + ySign * y + (int)(yShear * k1);\n      clipRes2 = state->clip->testSpan(spanXMin, spanXMax, spanY);\n      if (clipRes2 == splashClipAllOutside) {\n\tcontinue;\n      }\n    } else {\n      clipRes2 = clipRes;\n    }\n\n    // init x scale Bresenham\n    xt = 0;\n    xSrc = 0;\n\n    // x shear\n    x1 = k1;\n\n    // y shear\n    y1 = (SplashCoord)ySign * y + yShear * x1;\n    // this is a kludge: if yShear1 is negative, then (int)y1 would\n    // change immediately after the first pixel, which is not what we\n    // want\n    if (yShear1 < 0) {\n      y1 += 0.999;\n    }\n\n    // loop-invariant constants\n    n = yStep > 0 ? yStep : 1;\n\n    for (x = 0; x < scaledWidth; ++x) {\n\n      // x scale Bresenham\n      xStep = xp;\n      xt += xq;\n      if (xt >= scaledWidth) {\n\txt -= scaledWidth;\n\t++xStep;\n      }\n\n      // rotation\n      if (rot) {\n\tx2 = (int)y1;\n\ty2 = -x1;\n      } else {\n\tx2 = x1;\n\ty2 = (int)y1;\n      }\n\n      // compute the alpha value for (x,y) after the x and y scaling\n      // operations\n      m = xStep > 0 ? xStep : 1;\n      p = pixBuf + xSrc;\n      pixAcc = 0;\n      for (i = 0; i < n; ++i) {\n\tfor (j = 0; j < m; ++j) {\n\t  pixAcc += *p++;\n\t}\n\tp += w - m;\n      }\n\n      // blend fill color with background\n      if (pixAcc != 0) {\n\tpipe.shape = (pixAcc == n * m)\n\t                 ? (SplashCoord)1\n\t                 : (SplashCoord)pixAcc / (SplashCoord)(n * m);\n\tif (vectorAntialias && clipRes2 != splashClipAllInside) {\n\t  drawAAPixel(&pipe, tx + x2, ty + y2);\n\t} else {\n\t  drawPixel(&pipe, tx + x2, ty + y2, clipRes2 == splashClipAllInside);\n\t}\n      }\n\n      // x scale Bresenham\n      xSrc += xStep;\n\n      // x shear\n      x1 += xSign;\n\n      // y shear\n      y1 += yShear1;\n    }\n  }\n\n  // free memory\n  gfree(pixBuf);\n\n  return splashOk;\n}",
        "func": "SplashError Splash::fillImageMask(SplashImageMaskSource src, void *srcData,\n\t\t\t\t  int w, int h, SplashCoord *mat,\n\t\t\t\t  GBool glyphMode) {\n  SplashPipe pipe;\n  GBool rot;\n  SplashCoord xScale, yScale, xShear, yShear, yShear1;\n  int tx, tx2, ty, ty2, scaledWidth, scaledHeight, xSign, ySign;\n  int ulx, uly, llx, lly, urx, ury, lrx, lry;\n  int ulx1, uly1, llx1, lly1, urx1, ury1, lrx1, lry1;\n  int xMin, xMax, yMin, yMax;\n  SplashClipResult clipRes, clipRes2;\n  int yp, yq, yt, yStep, lastYStep;\n  int xp, xq, xt, xStep, xSrc;\n  int k1, spanXMin, spanXMax, spanY;\n  SplashColorPtr pixBuf, p;\n  int pixAcc;\n  int x, y, x1, x2, y2;\n  SplashCoord y1;\n  int n, m, i, j;\n\n  if (debugMode) {\n    printf(\"fillImageMask: w=%d h=%d mat=[%.2f %.2f %.2f %.2f %.2f %.2f]\\n\",\n\t   w, h, (double)mat[0], (double)mat[1], (double)mat[2],\n\t   (double)mat[3], (double)mat[4], (double)mat[5]);\n  }\n\n  if (w == 0 && h == 0) return splashErrZeroImage;\n\n  // check for singular matrix\n  if (splashAbs(mat[0] * mat[3] - mat[1] * mat[2]) < 0.000001) {\n    return splashErrSingularMatrix;\n  }\n\n  // compute scale, shear, rotation, translation parameters\n  rot = splashAbs(mat[1]) > splashAbs(mat[0]);\n  if (rot) {\n    xScale = -mat[1];\n    yScale = mat[2] - (mat[0] * mat[3]) / mat[1];\n    xShear = -mat[3] / yScale;\n    yShear = -mat[0] / mat[1];\n  } else {\n    xScale = mat[0];\n    yScale = mat[3] - (mat[1] * mat[2]) / mat[0];\n    xShear = mat[2] / yScale;\n    yShear = mat[1] / mat[0];\n  }\n  // Note 1: The PDF spec says that all pixels whose *centers* lie\n  // within the region get painted -- but that doesn't seem to match\n  // up with what Acrobat actually does: it ends up leaving gaps\n  // between image stripes.  So we use the same rule here as for\n  // fills: any pixel that overlaps the region gets painted.\n  // Note 2: The \"glyphMode\" flag is a kludge: it switches back to\n  // \"correct\" behavior (matching the spec), for use in rendering Type\n  // 3 fonts.\n  // Note 3: The +/-0.01 in these computations is to avoid floating\n  // point precision problems which can lead to gaps between image\n  // stripes (it can cause image stripes to overlap, but that's a much\n  // less visible problem).\n  if (glyphMode) {\n    if (xScale >= 0) {\n      tx = splashRound(mat[4]);\n      tx2 = splashRound(mat[4] + xScale) - 1;\n    } else {\n      tx = splashRound(mat[4]) - 1;\n      tx2 = splashRound(mat[4] + xScale);\n    }\n  } else {\n    if (xScale >= 0) {\n      tx = splashFloor(mat[4] - 0.01);\n      tx2 = splashFloor(mat[4] + xScale + 0.01);\n    } else {\n      tx = splashFloor(mat[4] + 0.01);\n      tx2 = splashFloor(mat[4] + xScale - 0.01);\n    }\n  }\n  scaledWidth = abs(tx2 - tx) + 1;\n  if (glyphMode) {\n    if (yScale >= 0) {\n      ty = splashRound(mat[5]);\n      ty2 = splashRound(mat[5] + yScale) - 1;\n    } else {\n      ty = splashRound(mat[5]) - 1;\n      ty2 = splashRound(mat[5] + yScale);\n    }\n  } else {\n    if (yScale >= 0) {\n      ty = splashFloor(mat[5] - 0.01);\n      ty2 = splashFloor(mat[5] + yScale + 0.01);\n    } else {\n      ty = splashFloor(mat[5] + 0.01);\n      ty2 = splashFloor(mat[5] + yScale - 0.01);\n    }\n  }\n  scaledHeight = abs(ty2 - ty) + 1;\n  xSign = (xScale < 0) ? -1 : 1;\n  ySign = (yScale < 0) ? -1 : 1;\n  yShear1 = (SplashCoord)xSign * yShear;\n\n  // clipping\n  ulx1 = 0;\n  uly1 = 0;\n  urx1 = xSign * (scaledWidth - 1);\n  ury1 = (int)(yShear * urx1);\n  llx1 = splashRound(xShear * ySign * (scaledHeight - 1));\n  lly1 = ySign * (scaledHeight - 1) + (int)(yShear * llx1);\n  lrx1 = xSign * (scaledWidth - 1) +\n           splashRound(xShear * ySign * (scaledHeight - 1));\n  lry1 = ySign * (scaledHeight - 1) + (int)(yShear * lrx1);\n  if (rot) {\n    ulx = tx + uly1;    uly = ty - ulx1;\n    urx = tx + ury1;    ury = ty - urx1;\n    llx = tx + lly1;    lly = ty - llx1;\n    lrx = tx + lry1;    lry = ty - lrx1;\n  } else {\n    ulx = tx + ulx1;    uly = ty + uly1;\n    urx = tx + urx1;    ury = ty + ury1;\n    llx = tx + llx1;    lly = ty + lly1;\n    lrx = tx + lrx1;    lry = ty + lry1;\n  }\n  xMin = (ulx < urx) ? (ulx < llx) ? (ulx < lrx) ? ulx : lrx\n                                   : (llx < lrx) ? llx : lrx\n\t\t     : (urx < llx) ? (urx < lrx) ? urx : lrx\n                                   : (llx < lrx) ? llx : lrx;\n  xMax = (ulx > urx) ? (ulx > llx) ? (ulx > lrx) ? ulx : lrx\n                                   : (llx > lrx) ? llx : lrx\n\t\t     : (urx > llx) ? (urx > lrx) ? urx : lrx\n                                   : (llx > lrx) ? llx : lrx;\n  yMin = (uly < ury) ? (uly < lly) ? (uly < lry) ? uly : lry\n                                   : (lly < lry) ? lly : lry\n\t\t     : (ury < lly) ? (ury < lry) ? ury : lry\n                                   : (lly < lry) ? lly : lry;\n  yMax = (uly > ury) ? (uly > lly) ? (uly > lry) ? uly : lry\n                                   : (lly > lry) ? lly : lry\n\t\t     : (ury > lly) ? (ury > lry) ? ury : lry\n                                   : (lly > lry) ? lly : lry;\n  clipRes = state->clip->testRect(xMin, yMin, xMax, yMax);\n  opClipRes = clipRes;\n\n  // compute Bresenham parameters for x and y scaling\n  yp = h / scaledHeight;\n  yq = h % scaledHeight;\n  xp = w / scaledWidth;\n  xq = w % scaledWidth;\n\n  // allocate pixel buffer\n  pixBuf = (SplashColorPtr)gmallocn((yp + 1), w);\n\n  // initialize the pixel pipe\n  pipeInit(&pipe, 0, 0, state->fillPattern, NULL, state->fillAlpha,\n\t   gTrue, gFalse);\n  if (vectorAntialias) {\n    drawAAPixelInit();\n  }\n\n  // init y scale Bresenham\n  yt = 0;\n  lastYStep = 1;\n\n  for (y = 0; y < scaledHeight; ++y) {\n\n    // y scale Bresenham\n    yStep = yp;\n    yt += yq;\n    if (yt >= scaledHeight) {\n      yt -= scaledHeight;\n      ++yStep;\n    }\n\n    // read row(s) from image\n    n = (yp > 0) ? yStep : lastYStep;\n    if (n > 0) {\n      p = pixBuf;\n      for (i = 0; i < n; ++i) {\n\t(*src)(srcData, p);\n\tp += w;\n      }\n    }\n    lastYStep = yStep;\n\n    // loop-invariant constants\n    k1 = splashRound(xShear * ySign * y);\n\n    // clipping test\n    if (clipRes != splashClipAllInside &&\n\t!rot &&\n\t(int)(yShear * k1) ==\n\t  (int)(yShear * (xSign * (scaledWidth - 1) + k1))) {\n      if (xSign > 0) {\n\tspanXMin = tx + k1;\n\tspanXMax = spanXMin + (scaledWidth - 1);\n      } else {\n\tspanXMax = tx + k1;\n\tspanXMin = spanXMax - (scaledWidth - 1);\n      }\n      spanY = ty + ySign * y + (int)(yShear * k1);\n      clipRes2 = state->clip->testSpan(spanXMin, spanXMax, spanY);\n      if (clipRes2 == splashClipAllOutside) {\n\tcontinue;\n      }\n    } else {\n      clipRes2 = clipRes;\n    }\n\n    // init x scale Bresenham\n    xt = 0;\n    xSrc = 0;\n\n    // x shear\n    x1 = k1;\n\n    // y shear\n    y1 = (SplashCoord)ySign * y + yShear * x1;\n    // this is a kludge: if yShear1 is negative, then (int)y1 would\n    // change immediately after the first pixel, which is not what we\n    // want\n    if (yShear1 < 0) {\n      y1 += 0.999;\n    }\n\n    // loop-invariant constants\n    n = yStep > 0 ? yStep : 1;\n\n    for (x = 0; x < scaledWidth; ++x) {\n\n      // x scale Bresenham\n      xStep = xp;\n      xt += xq;\n      if (xt >= scaledWidth) {\n\txt -= scaledWidth;\n\t++xStep;\n      }\n\n      // rotation\n      if (rot) {\n\tx2 = (int)y1;\n\ty2 = -x1;\n      } else {\n\tx2 = x1;\n\ty2 = (int)y1;\n      }\n\n      // compute the alpha value for (x,y) after the x and y scaling\n      // operations\n      m = xStep > 0 ? xStep : 1;\n      p = pixBuf + xSrc;\n      pixAcc = 0;\n      for (i = 0; i < n; ++i) {\n\tfor (j = 0; j < m; ++j) {\n\t  pixAcc += *p++;\n\t}\n\tp += w - m;\n      }\n\n      // blend fill color with background\n      if (pixAcc != 0) {\n\tpipe.shape = (pixAcc == n * m)\n\t                 ? (SplashCoord)1\n\t                 : (SplashCoord)pixAcc / (SplashCoord)(n * m);\n\tif (vectorAntialias && clipRes2 != splashClipAllInside) {\n\t  drawAAPixel(&pipe, tx + x2, ty + y2);\n\t} else {\n\t  drawPixel(&pipe, tx + x2, ty + y2, clipRes2 == splashClipAllInside);\n\t}\n      }\n\n      // x scale Bresenham\n      xSrc += xStep;\n\n      // x shear\n      x1 += xSign;\n\n      // y shear\n      y1 += yShear1;\n    }\n  }\n\n  // free memory\n  gfree(pixBuf);\n\n  return splashOk;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -143,7 +143,7 @@\n   xq = w % scaledWidth;\n \n   // allocate pixel buffer\n-  pixBuf = (SplashColorPtr)gmalloc((yp + 1) * w);\n+  pixBuf = (SplashColorPtr)gmallocn((yp + 1), w);\n \n   // initialize the pixel pipe\n   pipeInit(&pipe, 0, 0, state->fillPattern, NULL, state->fillAlpha,",
        "diff_line_info": {
            "deleted_lines": [
                "  pixBuf = (SplashColorPtr)gmalloc((yp + 1) * w);"
            ],
            "added_lines": [
                "  pixBuf = (SplashColorPtr)gmallocn((yp + 1), w);"
            ]
        }
    },
    {
        "cve_id": "CVE-2009-3726",
        "func_name": "torvalds/linux/nfs4_proc_lock",
        "description": "The nfs4_proc_lock function in fs/nfs/nfs4proc.c in the NFSv4 client in the Linux kernel before 2.6.31-rc4 allows remote NFS servers to cause a denial of service (NULL pointer dereference and panic) by sending a certain response containing incorrect file attributes, which trigger attempted use of an open file that lacks NFSv4 state.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=d953126a28f97ec965d23c69fd5795854c048f30",
        "commit_title": "We just had a case in which a buggy server occasionally returns the wrong",
        "commit_text": "attributes during an OPEN call. While the client does catch this sort of condition in nfs4_open_done(), and causes the nfs4_atomic_open() to return -EISDIR, the logic in nfs_atomic_lookup() is broken, since it causes a fallback to an ordinary lookup instead of just returning the error.  When the buggy server then returns a regular file for the fallback lookup, the VFS allows the open, and bad things start to happen, since the open file doesn't have any associated NFSv4 state.  The fix is firstly to return the EISDIR/ENOTDIR errors immediately, and secondly to ensure that we are always careful when dereferencing the nfs_open_context state pointer.  ",
        "func_before": "static int\nnfs4_proc_lock(struct file *filp, int cmd, struct file_lock *request)\n{\n\tstruct nfs_open_context *ctx;\n\tstruct nfs4_state *state;\n\tunsigned long timeout = NFS4_LOCK_MINTIMEOUT;\n\tint status;\n\n\t/* verify open state */\n\tctx = nfs_file_open_context(filp);\n\tstate = ctx->state;\n\n\tif (request->fl_start < 0 || request->fl_end < 0)\n\t\treturn -EINVAL;\n\n\tif (IS_GETLK(cmd))\n\t\treturn nfs4_proc_getlk(state, F_GETLK, request);\n\n\tif (!(IS_SETLK(cmd) || IS_SETLKW(cmd)))\n\t\treturn -EINVAL;\n\n\tif (request->fl_type == F_UNLCK)\n\t\treturn nfs4_proc_unlck(state, cmd, request);\n\n\tdo {\n\t\tstatus = nfs4_proc_setlk(state, cmd, request);\n\t\tif ((status != -EAGAIN) || IS_SETLK(cmd))\n\t\t\tbreak;\n\t\ttimeout = nfs4_set_lock_task_retry(timeout);\n\t\tstatus = -ERESTARTSYS;\n\t\tif (signalled())\n\t\t\tbreak;\n\t} while(status < 0);\n\treturn status;\n}",
        "func": "static int\nnfs4_proc_lock(struct file *filp, int cmd, struct file_lock *request)\n{\n\tstruct nfs_open_context *ctx;\n\tstruct nfs4_state *state;\n\tunsigned long timeout = NFS4_LOCK_MINTIMEOUT;\n\tint status;\n\n\t/* verify open state */\n\tctx = nfs_file_open_context(filp);\n\tstate = ctx->state;\n\n\tif (request->fl_start < 0 || request->fl_end < 0)\n\t\treturn -EINVAL;\n\n\tif (IS_GETLK(cmd)) {\n\t\tif (state != NULL)\n\t\t\treturn nfs4_proc_getlk(state, F_GETLK, request);\n\t\treturn 0;\n\t}\n\n\tif (!(IS_SETLK(cmd) || IS_SETLKW(cmd)))\n\t\treturn -EINVAL;\n\n\tif (request->fl_type == F_UNLCK) {\n\t\tif (state != NULL)\n\t\t\treturn nfs4_proc_unlck(state, cmd, request);\n\t\treturn 0;\n\t}\n\n\tif (state == NULL)\n\t\treturn -ENOLCK;\n\tdo {\n\t\tstatus = nfs4_proc_setlk(state, cmd, request);\n\t\tif ((status != -EAGAIN) || IS_SETLK(cmd))\n\t\t\tbreak;\n\t\ttimeout = nfs4_set_lock_task_retry(timeout);\n\t\tstatus = -ERESTARTSYS;\n\t\tif (signalled())\n\t\t\tbreak;\n\t} while(status < 0);\n\treturn status;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -13,15 +13,23 @@\n \tif (request->fl_start < 0 || request->fl_end < 0)\n \t\treturn -EINVAL;\n \n-\tif (IS_GETLK(cmd))\n-\t\treturn nfs4_proc_getlk(state, F_GETLK, request);\n+\tif (IS_GETLK(cmd)) {\n+\t\tif (state != NULL)\n+\t\t\treturn nfs4_proc_getlk(state, F_GETLK, request);\n+\t\treturn 0;\n+\t}\n \n \tif (!(IS_SETLK(cmd) || IS_SETLKW(cmd)))\n \t\treturn -EINVAL;\n \n-\tif (request->fl_type == F_UNLCK)\n-\t\treturn nfs4_proc_unlck(state, cmd, request);\n+\tif (request->fl_type == F_UNLCK) {\n+\t\tif (state != NULL)\n+\t\t\treturn nfs4_proc_unlck(state, cmd, request);\n+\t\treturn 0;\n+\t}\n \n+\tif (state == NULL)\n+\t\treturn -ENOLCK;\n \tdo {\n \t\tstatus = nfs4_proc_setlk(state, cmd, request);\n \t\tif ((status != -EAGAIN) || IS_SETLK(cmd))",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (IS_GETLK(cmd))",
                "\t\treturn nfs4_proc_getlk(state, F_GETLK, request);",
                "\tif (request->fl_type == F_UNLCK)",
                "\t\treturn nfs4_proc_unlck(state, cmd, request);"
            ],
            "added_lines": [
                "\tif (IS_GETLK(cmd)) {",
                "\t\tif (state != NULL)",
                "\t\t\treturn nfs4_proc_getlk(state, F_GETLK, request);",
                "\t\treturn 0;",
                "\t}",
                "\tif (request->fl_type == F_UNLCK) {",
                "\t\tif (state != NULL)",
                "\t\t\treturn nfs4_proc_unlck(state, cmd, request);",
                "\t\treturn 0;",
                "\t}",
                "\tif (state == NULL)",
                "\t\treturn -ENOLCK;"
            ]
        }
    },
    {
        "cve_id": "CVE-2009-3726",
        "func_name": "torvalds/linux/nfs_atomic_lookup",
        "description": "The nfs4_proc_lock function in fs/nfs/nfs4proc.c in the NFSv4 client in the Linux kernel before 2.6.31-rc4 allows remote NFS servers to cause a denial of service (NULL pointer dereference and panic) by sending a certain response containing incorrect file attributes, which trigger attempted use of an open file that lacks NFSv4 state.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=d953126a28f97ec965d23c69fd5795854c048f30",
        "commit_title": "We just had a case in which a buggy server occasionally returns the wrong",
        "commit_text": "attributes during an OPEN call. While the client does catch this sort of condition in nfs4_open_done(), and causes the nfs4_atomic_open() to return -EISDIR, the logic in nfs_atomic_lookup() is broken, since it causes a fallback to an ordinary lookup instead of just returning the error.  When the buggy server then returns a regular file for the fallback lookup, the VFS allows the open, and bad things start to happen, since the open file doesn't have any associated NFSv4 state.  The fix is firstly to return the EISDIR/ENOTDIR errors immediately, and secondly to ensure that we are always careful when dereferencing the nfs_open_context state pointer.  ",
        "func_before": "static struct dentry *nfs_atomic_lookup(struct inode *dir, struct dentry *dentry, struct nameidata *nd)\n{\n\tstruct dentry *res = NULL;\n\tint error;\n\n\tdfprintk(VFS, \"NFS: atomic_lookup(%s/%ld), %s\\n\",\n\t\t\tdir->i_sb->s_id, dir->i_ino, dentry->d_name.name);\n\n\t/* Check that we are indeed trying to open this file */\n\tif (!is_atomic_open(nd))\n\t\tgoto no_open;\n\n\tif (dentry->d_name.len > NFS_SERVER(dir)->namelen) {\n\t\tres = ERR_PTR(-ENAMETOOLONG);\n\t\tgoto out;\n\t}\n\tdentry->d_op = NFS_PROTO(dir)->dentry_ops;\n\n\t/* Let vfs_create() deal with O_EXCL. Instantiate, but don't hash\n\t * the dentry. */\n\tif (nd->flags & LOOKUP_EXCL) {\n\t\td_instantiate(dentry, NULL);\n\t\tgoto out;\n\t}\n\n\t/* Open the file on the server */\n\tres = nfs4_atomic_open(dir, dentry, nd);\n\tif (IS_ERR(res)) {\n\t\terror = PTR_ERR(res);\n\t\tswitch (error) {\n\t\t\t/* Make a negative dentry */\n\t\t\tcase -ENOENT:\n\t\t\t\tres = NULL;\n\t\t\t\tgoto out;\n\t\t\t/* This turned out not to be a regular file */\n\t\t\tcase -EISDIR:\n\t\t\tcase -ENOTDIR:\n\t\t\t\tgoto no_open;\n\t\t\tcase -ELOOP:\n\t\t\t\tif (!(nd->intent.open.flags & O_NOFOLLOW))\n\t\t\t\t\tgoto no_open;\n\t\t\t/* case -EINVAL: */\n\t\t\tdefault:\n\t\t\t\tgoto out;\n\t\t}\n\t} else if (res != NULL)\n\t\tdentry = res;\nout:\n\treturn res;\nno_open:\n\treturn nfs_lookup(dir, dentry, nd);\n}",
        "func": "static struct dentry *nfs_atomic_lookup(struct inode *dir, struct dentry *dentry, struct nameidata *nd)\n{\n\tstruct dentry *res = NULL;\n\tint error;\n\n\tdfprintk(VFS, \"NFS: atomic_lookup(%s/%ld), %s\\n\",\n\t\t\tdir->i_sb->s_id, dir->i_ino, dentry->d_name.name);\n\n\t/* Check that we are indeed trying to open this file */\n\tif (!is_atomic_open(nd))\n\t\tgoto no_open;\n\n\tif (dentry->d_name.len > NFS_SERVER(dir)->namelen) {\n\t\tres = ERR_PTR(-ENAMETOOLONG);\n\t\tgoto out;\n\t}\n\tdentry->d_op = NFS_PROTO(dir)->dentry_ops;\n\n\t/* Let vfs_create() deal with O_EXCL. Instantiate, but don't hash\n\t * the dentry. */\n\tif (nd->flags & LOOKUP_EXCL) {\n\t\td_instantiate(dentry, NULL);\n\t\tgoto out;\n\t}\n\n\t/* Open the file on the server */\n\tres = nfs4_atomic_open(dir, dentry, nd);\n\tif (IS_ERR(res)) {\n\t\terror = PTR_ERR(res);\n\t\tswitch (error) {\n\t\t\t/* Make a negative dentry */\n\t\t\tcase -ENOENT:\n\t\t\t\tres = NULL;\n\t\t\t\tgoto out;\n\t\t\t/* This turned out not to be a regular file */\n\t\t\tcase -ENOTDIR:\n\t\t\t\tgoto no_open;\n\t\t\tcase -ELOOP:\n\t\t\t\tif (!(nd->intent.open.flags & O_NOFOLLOW))\n\t\t\t\t\tgoto no_open;\n\t\t\t/* case -EISDIR: */\n\t\t\t/* case -EINVAL: */\n\t\t\tdefault:\n\t\t\t\tgoto out;\n\t\t}\n\t} else if (res != NULL)\n\t\tdentry = res;\nout:\n\treturn res;\nno_open:\n\treturn nfs_lookup(dir, dentry, nd);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -33,12 +33,12 @@\n \t\t\t\tres = NULL;\n \t\t\t\tgoto out;\n \t\t\t/* This turned out not to be a regular file */\n-\t\t\tcase -EISDIR:\n \t\t\tcase -ENOTDIR:\n \t\t\t\tgoto no_open;\n \t\t\tcase -ELOOP:\n \t\t\t\tif (!(nd->intent.open.flags & O_NOFOLLOW))\n \t\t\t\t\tgoto no_open;\n+\t\t\t/* case -EISDIR: */\n \t\t\t/* case -EINVAL: */\n \t\t\tdefault:\n \t\t\t\tgoto out;",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\tcase -EISDIR:"
            ],
            "added_lines": [
                "\t\t\t/* case -EISDIR: */"
            ]
        }
    },
    {
        "cve_id": "CVE-2009-3888",
        "func_name": "torvalds/linux/do_mmap_pgoff",
        "description": "The do_mmap_pgoff function in mm/nommu.c in the Linux kernel before 2.6.31.6, when the CPU lacks a memory management unit, allows local users to cause a denial of service (OOPS) via an application that attempts to allocate a large amount of memory.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=89a8640279f8bb78aaf778d1fc5c4a6778f18064",
        "commit_title": "Don't pass NULL pointers to fput() in the error handling paths of the NOMMU",
        "commit_text": "do_mmap_pgoff() as it can't handle it.  The following can be used as a test program:  \tint main() { static long long a[1024 * 1024 * 20] = { 0 }; return a;}  Without the patch, the code oopses in atomic_long_dec_and_test() as called by fput() after the kernel complains that it can't allocate that big a chunk of memory.  With the patch, the kernel just complains about the allocation size and then the program segfaults during execve() as execve() can't complete the allocation of all the new ELF program segments.  Cc: stable@kernel.org ",
        "func_before": "unsigned long do_mmap_pgoff(struct file *file,\n\t\t\t    unsigned long addr,\n\t\t\t    unsigned long len,\n\t\t\t    unsigned long prot,\n\t\t\t    unsigned long flags,\n\t\t\t    unsigned long pgoff)\n{\n\tstruct vm_area_struct *vma;\n\tstruct vm_region *region;\n\tstruct rb_node *rb;\n\tunsigned long capabilities, vm_flags, result;\n\tint ret;\n\n\tkenter(\",%lx,%lx,%lx,%lx,%lx\", addr, len, prot, flags, pgoff);\n\n\t/* decide whether we should attempt the mapping, and if so what sort of\n\t * mapping */\n\tret = validate_mmap_request(file, addr, len, prot, flags, pgoff,\n\t\t\t\t    &capabilities);\n\tif (ret < 0) {\n\t\tkleave(\" = %d [val]\", ret);\n\t\treturn ret;\n\t}\n\n\t/* we ignore the address hint */\n\taddr = 0;\n\n\t/* we've determined that we can make the mapping, now translate what we\n\t * now know into VMA flags */\n\tvm_flags = determine_vm_flags(file, prot, flags, capabilities);\n\n\t/* we're going to need to record the mapping */\n\tregion = kmem_cache_zalloc(vm_region_jar, GFP_KERNEL);\n\tif (!region)\n\t\tgoto error_getting_region;\n\n\tvma = kmem_cache_zalloc(vm_area_cachep, GFP_KERNEL);\n\tif (!vma)\n\t\tgoto error_getting_vma;\n\n\tatomic_set(&region->vm_usage, 1);\n\tregion->vm_flags = vm_flags;\n\tregion->vm_pgoff = pgoff;\n\n\tINIT_LIST_HEAD(&vma->anon_vma_node);\n\tvma->vm_flags = vm_flags;\n\tvma->vm_pgoff = pgoff;\n\n\tif (file) {\n\t\tregion->vm_file = file;\n\t\tget_file(file);\n\t\tvma->vm_file = file;\n\t\tget_file(file);\n\t\tif (vm_flags & VM_EXECUTABLE) {\n\t\t\tadded_exe_file_vma(current->mm);\n\t\t\tvma->vm_mm = current->mm;\n\t\t}\n\t}\n\n\tdown_write(&nommu_region_sem);\n\n\t/* if we want to share, we need to check for regions created by other\n\t * mmap() calls that overlap with our proposed mapping\n\t * - we can only share with a superset match on most regular files\n\t * - shared mappings on character devices and memory backed files are\n\t *   permitted to overlap inexactly as far as we are concerned for in\n\t *   these cases, sharing is handled in the driver or filesystem rather\n\t *   than here\n\t */\n\tif (vm_flags & VM_MAYSHARE) {\n\t\tstruct vm_region *pregion;\n\t\tunsigned long pglen, rpglen, pgend, rpgend, start;\n\n\t\tpglen = (len + PAGE_SIZE - 1) >> PAGE_SHIFT;\n\t\tpgend = pgoff + pglen;\n\n\t\tfor (rb = rb_first(&nommu_region_tree); rb; rb = rb_next(rb)) {\n\t\t\tpregion = rb_entry(rb, struct vm_region, vm_rb);\n\n\t\t\tif (!(pregion->vm_flags & VM_MAYSHARE))\n\t\t\t\tcontinue;\n\n\t\t\t/* search for overlapping mappings on the same file */\n\t\t\tif (pregion->vm_file->f_path.dentry->d_inode !=\n\t\t\t    file->f_path.dentry->d_inode)\n\t\t\t\tcontinue;\n\n\t\t\tif (pregion->vm_pgoff >= pgend)\n\t\t\t\tcontinue;\n\n\t\t\trpglen = pregion->vm_end - pregion->vm_start;\n\t\t\trpglen = (rpglen + PAGE_SIZE - 1) >> PAGE_SHIFT;\n\t\t\trpgend = pregion->vm_pgoff + rpglen;\n\t\t\tif (pgoff >= rpgend)\n\t\t\t\tcontinue;\n\n\t\t\t/* handle inexactly overlapping matches between\n\t\t\t * mappings */\n\t\t\tif ((pregion->vm_pgoff != pgoff || rpglen != pglen) &&\n\t\t\t    !(pgoff >= pregion->vm_pgoff && pgend <= rpgend)) {\n\t\t\t\t/* new mapping is not a subset of the region */\n\t\t\t\tif (!(capabilities & BDI_CAP_MAP_DIRECT))\n\t\t\t\t\tgoto sharing_violation;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\t/* we've found a region we can share */\n\t\t\tatomic_inc(&pregion->vm_usage);\n\t\t\tvma->vm_region = pregion;\n\t\t\tstart = pregion->vm_start;\n\t\t\tstart += (pgoff - pregion->vm_pgoff) << PAGE_SHIFT;\n\t\t\tvma->vm_start = start;\n\t\t\tvma->vm_end = start + len;\n\n\t\t\tif (pregion->vm_flags & VM_MAPPED_COPY) {\n\t\t\t\tkdebug(\"share copy\");\n\t\t\t\tvma->vm_flags |= VM_MAPPED_COPY;\n\t\t\t} else {\n\t\t\t\tkdebug(\"share mmap\");\n\t\t\t\tret = do_mmap_shared_file(vma);\n\t\t\t\tif (ret < 0) {\n\t\t\t\t\tvma->vm_region = NULL;\n\t\t\t\t\tvma->vm_start = 0;\n\t\t\t\t\tvma->vm_end = 0;\n\t\t\t\t\tatomic_dec(&pregion->vm_usage);\n\t\t\t\t\tpregion = NULL;\n\t\t\t\t\tgoto error_just_free;\n\t\t\t\t}\n\t\t\t}\n\t\t\tfput(region->vm_file);\n\t\t\tkmem_cache_free(vm_region_jar, region);\n\t\t\tregion = pregion;\n\t\t\tresult = start;\n\t\t\tgoto share;\n\t\t}\n\n\t\t/* obtain the address at which to make a shared mapping\n\t\t * - this is the hook for quasi-memory character devices to\n\t\t *   tell us the location of a shared mapping\n\t\t */\n\t\tif (capabilities & BDI_CAP_MAP_DIRECT) {\n\t\t\taddr = file->f_op->get_unmapped_area(file, addr, len,\n\t\t\t\t\t\t\t     pgoff, flags);\n\t\t\tif (IS_ERR((void *) addr)) {\n\t\t\t\tret = addr;\n\t\t\t\tif (ret != (unsigned long) -ENOSYS)\n\t\t\t\t\tgoto error_just_free;\n\n\t\t\t\t/* the driver refused to tell us where to site\n\t\t\t\t * the mapping so we'll have to attempt to copy\n\t\t\t\t * it */\n\t\t\t\tret = (unsigned long) -ENODEV;\n\t\t\t\tif (!(capabilities & BDI_CAP_MAP_COPY))\n\t\t\t\t\tgoto error_just_free;\n\n\t\t\t\tcapabilities &= ~BDI_CAP_MAP_DIRECT;\n\t\t\t} else {\n\t\t\t\tvma->vm_start = region->vm_start = addr;\n\t\t\t\tvma->vm_end = region->vm_end = addr + len;\n\t\t\t}\n\t\t}\n\t}\n\n\tvma->vm_region = region;\n\n\t/* set up the mapping\n\t * - the region is filled in if BDI_CAP_MAP_DIRECT is still set\n\t */\n\tif (file && vma->vm_flags & VM_SHARED)\n\t\tret = do_mmap_shared_file(vma);\n\telse\n\t\tret = do_mmap_private(vma, region, len, capabilities);\n\tif (ret < 0)\n\t\tgoto error_just_free;\n\tadd_nommu_region(region);\n\n\t/* okay... we have a mapping; now we have to register it */\n\tresult = vma->vm_start;\n\n\tcurrent->mm->total_vm += len >> PAGE_SHIFT;\n\nshare:\n\tadd_vma_to_mm(current->mm, vma);\n\n\tup_write(&nommu_region_sem);\n\n\tif (prot & PROT_EXEC)\n\t\tflush_icache_range(result, result + len);\n\n\tkleave(\" = %lx\", result);\n\treturn result;\n\nerror_just_free:\n\tup_write(&nommu_region_sem);\nerror:\n\tfput(region->vm_file);\n\tkmem_cache_free(vm_region_jar, region);\n\tfput(vma->vm_file);\n\tif (vma->vm_flags & VM_EXECUTABLE)\n\t\tremoved_exe_file_vma(vma->vm_mm);\n\tkmem_cache_free(vm_area_cachep, vma);\n\tkleave(\" = %d\", ret);\n\treturn ret;\n\nsharing_violation:\n\tup_write(&nommu_region_sem);\n\tprintk(KERN_WARNING \"Attempt to share mismatched mappings\\n\");\n\tret = -EINVAL;\n\tgoto error;\n\nerror_getting_vma:\n\tkmem_cache_free(vm_region_jar, region);\n\tprintk(KERN_WARNING \"Allocation of vma for %lu byte allocation\"\n\t       \" from process %d failed\\n\",\n\t       len, current->pid);\n\tshow_free_areas();\n\treturn -ENOMEM;\n\nerror_getting_region:\n\tprintk(KERN_WARNING \"Allocation of vm region for %lu byte allocation\"\n\t       \" from process %d failed\\n\",\n\t       len, current->pid);\n\tshow_free_areas();\n\treturn -ENOMEM;\n}",
        "func": "unsigned long do_mmap_pgoff(struct file *file,\n\t\t\t    unsigned long addr,\n\t\t\t    unsigned long len,\n\t\t\t    unsigned long prot,\n\t\t\t    unsigned long flags,\n\t\t\t    unsigned long pgoff)\n{\n\tstruct vm_area_struct *vma;\n\tstruct vm_region *region;\n\tstruct rb_node *rb;\n\tunsigned long capabilities, vm_flags, result;\n\tint ret;\n\n\tkenter(\",%lx,%lx,%lx,%lx,%lx\", addr, len, prot, flags, pgoff);\n\n\t/* decide whether we should attempt the mapping, and if so what sort of\n\t * mapping */\n\tret = validate_mmap_request(file, addr, len, prot, flags, pgoff,\n\t\t\t\t    &capabilities);\n\tif (ret < 0) {\n\t\tkleave(\" = %d [val]\", ret);\n\t\treturn ret;\n\t}\n\n\t/* we ignore the address hint */\n\taddr = 0;\n\n\t/* we've determined that we can make the mapping, now translate what we\n\t * now know into VMA flags */\n\tvm_flags = determine_vm_flags(file, prot, flags, capabilities);\n\n\t/* we're going to need to record the mapping */\n\tregion = kmem_cache_zalloc(vm_region_jar, GFP_KERNEL);\n\tif (!region)\n\t\tgoto error_getting_region;\n\n\tvma = kmem_cache_zalloc(vm_area_cachep, GFP_KERNEL);\n\tif (!vma)\n\t\tgoto error_getting_vma;\n\n\tatomic_set(&region->vm_usage, 1);\n\tregion->vm_flags = vm_flags;\n\tregion->vm_pgoff = pgoff;\n\n\tINIT_LIST_HEAD(&vma->anon_vma_node);\n\tvma->vm_flags = vm_flags;\n\tvma->vm_pgoff = pgoff;\n\n\tif (file) {\n\t\tregion->vm_file = file;\n\t\tget_file(file);\n\t\tvma->vm_file = file;\n\t\tget_file(file);\n\t\tif (vm_flags & VM_EXECUTABLE) {\n\t\t\tadded_exe_file_vma(current->mm);\n\t\t\tvma->vm_mm = current->mm;\n\t\t}\n\t}\n\n\tdown_write(&nommu_region_sem);\n\n\t/* if we want to share, we need to check for regions created by other\n\t * mmap() calls that overlap with our proposed mapping\n\t * - we can only share with a superset match on most regular files\n\t * - shared mappings on character devices and memory backed files are\n\t *   permitted to overlap inexactly as far as we are concerned for in\n\t *   these cases, sharing is handled in the driver or filesystem rather\n\t *   than here\n\t */\n\tif (vm_flags & VM_MAYSHARE) {\n\t\tstruct vm_region *pregion;\n\t\tunsigned long pglen, rpglen, pgend, rpgend, start;\n\n\t\tpglen = (len + PAGE_SIZE - 1) >> PAGE_SHIFT;\n\t\tpgend = pgoff + pglen;\n\n\t\tfor (rb = rb_first(&nommu_region_tree); rb; rb = rb_next(rb)) {\n\t\t\tpregion = rb_entry(rb, struct vm_region, vm_rb);\n\n\t\t\tif (!(pregion->vm_flags & VM_MAYSHARE))\n\t\t\t\tcontinue;\n\n\t\t\t/* search for overlapping mappings on the same file */\n\t\t\tif (pregion->vm_file->f_path.dentry->d_inode !=\n\t\t\t    file->f_path.dentry->d_inode)\n\t\t\t\tcontinue;\n\n\t\t\tif (pregion->vm_pgoff >= pgend)\n\t\t\t\tcontinue;\n\n\t\t\trpglen = pregion->vm_end - pregion->vm_start;\n\t\t\trpglen = (rpglen + PAGE_SIZE - 1) >> PAGE_SHIFT;\n\t\t\trpgend = pregion->vm_pgoff + rpglen;\n\t\t\tif (pgoff >= rpgend)\n\t\t\t\tcontinue;\n\n\t\t\t/* handle inexactly overlapping matches between\n\t\t\t * mappings */\n\t\t\tif ((pregion->vm_pgoff != pgoff || rpglen != pglen) &&\n\t\t\t    !(pgoff >= pregion->vm_pgoff && pgend <= rpgend)) {\n\t\t\t\t/* new mapping is not a subset of the region */\n\t\t\t\tif (!(capabilities & BDI_CAP_MAP_DIRECT))\n\t\t\t\t\tgoto sharing_violation;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\t/* we've found a region we can share */\n\t\t\tatomic_inc(&pregion->vm_usage);\n\t\t\tvma->vm_region = pregion;\n\t\t\tstart = pregion->vm_start;\n\t\t\tstart += (pgoff - pregion->vm_pgoff) << PAGE_SHIFT;\n\t\t\tvma->vm_start = start;\n\t\t\tvma->vm_end = start + len;\n\n\t\t\tif (pregion->vm_flags & VM_MAPPED_COPY) {\n\t\t\t\tkdebug(\"share copy\");\n\t\t\t\tvma->vm_flags |= VM_MAPPED_COPY;\n\t\t\t} else {\n\t\t\t\tkdebug(\"share mmap\");\n\t\t\t\tret = do_mmap_shared_file(vma);\n\t\t\t\tif (ret < 0) {\n\t\t\t\t\tvma->vm_region = NULL;\n\t\t\t\t\tvma->vm_start = 0;\n\t\t\t\t\tvma->vm_end = 0;\n\t\t\t\t\tatomic_dec(&pregion->vm_usage);\n\t\t\t\t\tpregion = NULL;\n\t\t\t\t\tgoto error_just_free;\n\t\t\t\t}\n\t\t\t}\n\t\t\tfput(region->vm_file);\n\t\t\tkmem_cache_free(vm_region_jar, region);\n\t\t\tregion = pregion;\n\t\t\tresult = start;\n\t\t\tgoto share;\n\t\t}\n\n\t\t/* obtain the address at which to make a shared mapping\n\t\t * - this is the hook for quasi-memory character devices to\n\t\t *   tell us the location of a shared mapping\n\t\t */\n\t\tif (capabilities & BDI_CAP_MAP_DIRECT) {\n\t\t\taddr = file->f_op->get_unmapped_area(file, addr, len,\n\t\t\t\t\t\t\t     pgoff, flags);\n\t\t\tif (IS_ERR((void *) addr)) {\n\t\t\t\tret = addr;\n\t\t\t\tif (ret != (unsigned long) -ENOSYS)\n\t\t\t\t\tgoto error_just_free;\n\n\t\t\t\t/* the driver refused to tell us where to site\n\t\t\t\t * the mapping so we'll have to attempt to copy\n\t\t\t\t * it */\n\t\t\t\tret = (unsigned long) -ENODEV;\n\t\t\t\tif (!(capabilities & BDI_CAP_MAP_COPY))\n\t\t\t\t\tgoto error_just_free;\n\n\t\t\t\tcapabilities &= ~BDI_CAP_MAP_DIRECT;\n\t\t\t} else {\n\t\t\t\tvma->vm_start = region->vm_start = addr;\n\t\t\t\tvma->vm_end = region->vm_end = addr + len;\n\t\t\t}\n\t\t}\n\t}\n\n\tvma->vm_region = region;\n\n\t/* set up the mapping\n\t * - the region is filled in if BDI_CAP_MAP_DIRECT is still set\n\t */\n\tif (file && vma->vm_flags & VM_SHARED)\n\t\tret = do_mmap_shared_file(vma);\n\telse\n\t\tret = do_mmap_private(vma, region, len, capabilities);\n\tif (ret < 0)\n\t\tgoto error_just_free;\n\tadd_nommu_region(region);\n\n\t/* okay... we have a mapping; now we have to register it */\n\tresult = vma->vm_start;\n\n\tcurrent->mm->total_vm += len >> PAGE_SHIFT;\n\nshare:\n\tadd_vma_to_mm(current->mm, vma);\n\n\tup_write(&nommu_region_sem);\n\n\tif (prot & PROT_EXEC)\n\t\tflush_icache_range(result, result + len);\n\n\tkleave(\" = %lx\", result);\n\treturn result;\n\nerror_just_free:\n\tup_write(&nommu_region_sem);\nerror:\n\tif (region->vm_file)\n\t\tfput(region->vm_file);\n\tkmem_cache_free(vm_region_jar, region);\n\tif (vma->vm_file)\n\t\tfput(vma->vm_file);\n\tif (vma->vm_flags & VM_EXECUTABLE)\n\t\tremoved_exe_file_vma(vma->vm_mm);\n\tkmem_cache_free(vm_area_cachep, vma);\n\tkleave(\" = %d\", ret);\n\treturn ret;\n\nsharing_violation:\n\tup_write(&nommu_region_sem);\n\tprintk(KERN_WARNING \"Attempt to share mismatched mappings\\n\");\n\tret = -EINVAL;\n\tgoto error;\n\nerror_getting_vma:\n\tkmem_cache_free(vm_region_jar, region);\n\tprintk(KERN_WARNING \"Allocation of vma for %lu byte allocation\"\n\t       \" from process %d failed\\n\",\n\t       len, current->pid);\n\tshow_free_areas();\n\treturn -ENOMEM;\n\nerror_getting_region:\n\tprintk(KERN_WARNING \"Allocation of vm region for %lu byte allocation\"\n\t       \" from process %d failed\\n\",\n\t       len, current->pid);\n\tshow_free_areas();\n\treturn -ENOMEM;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -193,9 +193,11 @@\n error_just_free:\n \tup_write(&nommu_region_sem);\n error:\n-\tfput(region->vm_file);\n+\tif (region->vm_file)\n+\t\tfput(region->vm_file);\n \tkmem_cache_free(vm_region_jar, region);\n-\tfput(vma->vm_file);\n+\tif (vma->vm_file)\n+\t\tfput(vma->vm_file);\n \tif (vma->vm_flags & VM_EXECUTABLE)\n \t\tremoved_exe_file_vma(vma->vm_mm);\n \tkmem_cache_free(vm_area_cachep, vma);",
        "diff_line_info": {
            "deleted_lines": [
                "\tfput(region->vm_file);",
                "\tfput(vma->vm_file);"
            ],
            "added_lines": [
                "\tif (region->vm_file)",
                "\t\tfput(region->vm_file);",
                "\tif (vma->vm_file)",
                "\t\tfput(vma->vm_file);"
            ]
        }
    },
    {
        "cve_id": "CVE-2009-4021",
        "func_name": "torvalds/linux/fuse_direct_io",
        "description": "The fuse_direct_io function in fs/fuse/file.c in the fuse subsystem in the Linux kernel before 2.6.32-rc7 might allow attackers to cause a denial of service (invalid pointer dereference and OOPS) via vectors possibly related to a memory-consumption attack.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=f60311d5f7670d9539b424e4ed8b5c0872fc9e83",
        "commit_title": "fuse_direct_io() has a loop where requests are allocated in each",
        "commit_text": "iteration. if allocation fails, the loop is broken out and follows into an unconditional fuse_put_request() on that invalid pointer.  Cc: stable@kernel.org ",
        "func_before": "ssize_t fuse_direct_io(struct file *file, const char __user *buf,\n\t\t       size_t count, loff_t *ppos, int write)\n{\n\tstruct fuse_file *ff = file->private_data;\n\tstruct fuse_conn *fc = ff->fc;\n\tsize_t nmax = write ? fc->max_write : fc->max_read;\n\tloff_t pos = *ppos;\n\tssize_t res = 0;\n\tstruct fuse_req *req;\n\n\treq = fuse_get_req(fc);\n\tif (IS_ERR(req))\n\t\treturn PTR_ERR(req);\n\n\twhile (count) {\n\t\tsize_t nres;\n\t\tfl_owner_t owner = current->files;\n\t\tsize_t nbytes = min(count, nmax);\n\t\tint err = fuse_get_user_pages(req, buf, &nbytes, write);\n\t\tif (err) {\n\t\t\tres = err;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (write)\n\t\t\tnres = fuse_send_write(req, file, pos, nbytes, owner);\n\t\telse\n\t\t\tnres = fuse_send_read(req, file, pos, nbytes, owner);\n\n\t\tfuse_release_user_pages(req, !write);\n\t\tif (req->out.h.error) {\n\t\t\tif (!res)\n\t\t\t\tres = req->out.h.error;\n\t\t\tbreak;\n\t\t} else if (nres > nbytes) {\n\t\t\tres = -EIO;\n\t\t\tbreak;\n\t\t}\n\t\tcount -= nres;\n\t\tres += nres;\n\t\tpos += nres;\n\t\tbuf += nres;\n\t\tif (nres != nbytes)\n\t\t\tbreak;\n\t\tif (count) {\n\t\t\tfuse_put_request(fc, req);\n\t\t\treq = fuse_get_req(fc);\n\t\t\tif (IS_ERR(req))\n\t\t\t\tbreak;\n\t\t}\n\t}\n\tfuse_put_request(fc, req);\n\tif (res > 0)\n\t\t*ppos = pos;\n\n\treturn res;\n}",
        "func": "ssize_t fuse_direct_io(struct file *file, const char __user *buf,\n\t\t       size_t count, loff_t *ppos, int write)\n{\n\tstruct fuse_file *ff = file->private_data;\n\tstruct fuse_conn *fc = ff->fc;\n\tsize_t nmax = write ? fc->max_write : fc->max_read;\n\tloff_t pos = *ppos;\n\tssize_t res = 0;\n\tstruct fuse_req *req;\n\n\treq = fuse_get_req(fc);\n\tif (IS_ERR(req))\n\t\treturn PTR_ERR(req);\n\n\twhile (count) {\n\t\tsize_t nres;\n\t\tfl_owner_t owner = current->files;\n\t\tsize_t nbytes = min(count, nmax);\n\t\tint err = fuse_get_user_pages(req, buf, &nbytes, write);\n\t\tif (err) {\n\t\t\tres = err;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (write)\n\t\t\tnres = fuse_send_write(req, file, pos, nbytes, owner);\n\t\telse\n\t\t\tnres = fuse_send_read(req, file, pos, nbytes, owner);\n\n\t\tfuse_release_user_pages(req, !write);\n\t\tif (req->out.h.error) {\n\t\t\tif (!res)\n\t\t\t\tres = req->out.h.error;\n\t\t\tbreak;\n\t\t} else if (nres > nbytes) {\n\t\t\tres = -EIO;\n\t\t\tbreak;\n\t\t}\n\t\tcount -= nres;\n\t\tres += nres;\n\t\tpos += nres;\n\t\tbuf += nres;\n\t\tif (nres != nbytes)\n\t\t\tbreak;\n\t\tif (count) {\n\t\t\tfuse_put_request(fc, req);\n\t\t\treq = fuse_get_req(fc);\n\t\t\tif (IS_ERR(req))\n\t\t\t\tbreak;\n\t\t}\n\t}\n\tif (!IS_ERR(req))\n\t\tfuse_put_request(fc, req);\n\tif (res > 0)\n\t\t*ppos = pos;\n\n\treturn res;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -49,7 +49,8 @@\n \t\t\t\tbreak;\n \t\t}\n \t}\n-\tfuse_put_request(fc, req);\n+\tif (!IS_ERR(req))\n+\t\tfuse_put_request(fc, req);\n \tif (res > 0)\n \t\t*ppos = pos;\n ",
        "diff_line_info": {
            "deleted_lines": [
                "\tfuse_put_request(fc, req);"
            ],
            "added_lines": [
                "\tif (!IS_ERR(req))",
                "\t\tfuse_put_request(fc, req);"
            ]
        }
    },
    {
        "cve_id": "CVE-2009-4308",
        "func_name": "torvalds/linux/ext4_decode_error",
        "description": "The ext4_decode_error function in fs/ext4/super.c in the ext4 filesystem in the Linux kernel before 2.6.32 allows user-assisted remote attackers to cause a denial of service (NULL pointer dereference), and possibly have unspecified other impact, via a crafted read-only filesystem that lacks a journal.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=78f1ddbb498283c2445c11b0dfa666424c301803",
        "commit_title": "We need to check to make sure a journal is present before checking the",
        "commit_text": "journal flags in ext4_decode_error().  ",
        "func_before": "static const char *ext4_decode_error(struct super_block *sb, int errno,\n\t\t\t\t     char nbuf[16])\n{\n\tchar *errstr = NULL;\n\n\tswitch (errno) {\n\tcase -EIO:\n\t\terrstr = \"IO failure\";\n\t\tbreak;\n\tcase -ENOMEM:\n\t\terrstr = \"Out of memory\";\n\t\tbreak;\n\tcase -EROFS:\n\t\tif (!sb || EXT4_SB(sb)->s_journal->j_flags & JBD2_ABORT)\n\t\t\terrstr = \"Journal has aborted\";\n\t\telse\n\t\t\terrstr = \"Readonly filesystem\";\n\t\tbreak;\n\tdefault:\n\t\t/* If the caller passed in an extra buffer for unknown\n\t\t * errors, textualise them now.  Else we just return\n\t\t * NULL. */\n\t\tif (nbuf) {\n\t\t\t/* Check for truncated error codes... */\n\t\t\tif (snprintf(nbuf, 16, \"error %d\", -errno) >= 0)\n\t\t\t\terrstr = nbuf;\n\t\t}\n\t\tbreak;\n\t}\n\n\treturn errstr;\n}",
        "func": "static const char *ext4_decode_error(struct super_block *sb, int errno,\n\t\t\t\t     char nbuf[16])\n{\n\tchar *errstr = NULL;\n\n\tswitch (errno) {\n\tcase -EIO:\n\t\terrstr = \"IO failure\";\n\t\tbreak;\n\tcase -ENOMEM:\n\t\terrstr = \"Out of memory\";\n\t\tbreak;\n\tcase -EROFS:\n\t\tif (!sb || (EXT4_SB(sb)->s_journal &&\n\t\t\t    EXT4_SB(sb)->s_journal->j_flags & JBD2_ABORT))\n\t\t\terrstr = \"Journal has aborted\";\n\t\telse\n\t\t\terrstr = \"Readonly filesystem\";\n\t\tbreak;\n\tdefault:\n\t\t/* If the caller passed in an extra buffer for unknown\n\t\t * errors, textualise them now.  Else we just return\n\t\t * NULL. */\n\t\tif (nbuf) {\n\t\t\t/* Check for truncated error codes... */\n\t\t\tif (snprintf(nbuf, 16, \"error %d\", -errno) >= 0)\n\t\t\t\terrstr = nbuf;\n\t\t}\n\t\tbreak;\n\t}\n\n\treturn errstr;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -11,7 +11,8 @@\n \t\terrstr = \"Out of memory\";\n \t\tbreak;\n \tcase -EROFS:\n-\t\tif (!sb || EXT4_SB(sb)->s_journal->j_flags & JBD2_ABORT)\n+\t\tif (!sb || (EXT4_SB(sb)->s_journal &&\n+\t\t\t    EXT4_SB(sb)->s_journal->j_flags & JBD2_ABORT))\n \t\t\terrstr = \"Journal has aborted\";\n \t\telse\n \t\t\terrstr = \"Readonly filesystem\";",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tif (!sb || EXT4_SB(sb)->s_journal->j_flags & JBD2_ABORT)"
            ],
            "added_lines": [
                "\t\tif (!sb || (EXT4_SB(sb)->s_journal &&",
                "\t\t\t    EXT4_SB(sb)->s_journal->j_flags & JBD2_ABORT))"
            ]
        }
    },
    {
        "cve_id": "CVE-2009-4138",
        "func_name": "torvalds/linux/ohci_queue_iso_receive_packet_per_buffer",
        "description": "drivers/firewire/ohci.c in the Linux kernel before 2.6.32-git9, when packet-per-buffer mode is used, allows local users to cause a denial of service (NULL pointer dereference and system crash) or possibly have unknown other impact via an unspecified ioctl associated with receiving an ISO packet that contains zero in the payload-length field.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=8c0c0cc2d9f4c523fde04bdfe41e4380dec8ee54",
        "commit_title": "Queueing to receive an ISO packet with a payload length of zero",
        "commit_text": "silently does nothing in dualbuffer mode, and crashes the kernel in packet-per-buffer mode.  Return an error in dualbuffer mode, because the DMA controller won't let us do what we want, and work correctly in packet-per-buffer mode.  Cc: stable@kernel.org ",
        "func_before": "static int ohci_queue_iso_receive_packet_per_buffer(struct fw_iso_context *base,\n\t\t\t\t\tstruct fw_iso_packet *packet,\n\t\t\t\t\tstruct fw_iso_buffer *buffer,\n\t\t\t\t\tunsigned long payload)\n{\n\tstruct iso_context *ctx = container_of(base, struct iso_context, base);\n\tstruct descriptor *d = NULL, *pd = NULL;\n\tstruct fw_iso_packet *p = packet;\n\tdma_addr_t d_bus, page_bus;\n\tu32 z, header_z, rest;\n\tint i, j, length;\n\tint page, offset, packet_count, header_size, payload_per_buffer;\n\n\t/*\n\t * The OHCI controller puts the isochronous header and trailer in the\n\t * buffer, so we need at least 8 bytes.\n\t */\n\tpacket_count = p->header_length / ctx->base.header_size;\n\theader_size  = max(ctx->base.header_size, (size_t)8);\n\n\t/* Get header size in number of descriptors. */\n\theader_z = DIV_ROUND_UP(header_size, sizeof(*d));\n\tpage     = payload >> PAGE_SHIFT;\n\toffset   = payload & ~PAGE_MASK;\n\tpayload_per_buffer = p->payload_length / packet_count;\n\n\tfor (i = 0; i < packet_count; i++) {\n\t\t/* d points to the header descriptor */\n\t\tz = DIV_ROUND_UP(payload_per_buffer + offset, PAGE_SIZE) + 1;\n\t\td = context_get_descriptors(&ctx->context,\n\t\t\t\tz + header_z, &d_bus);\n\t\tif (d == NULL)\n\t\t\treturn -ENOMEM;\n\n\t\td->control      = cpu_to_le16(DESCRIPTOR_STATUS |\n\t\t\t\t\t      DESCRIPTOR_INPUT_MORE);\n\t\tif (p->skip && i == 0)\n\t\t\td->control |= cpu_to_le16(DESCRIPTOR_WAIT);\n\t\td->req_count    = cpu_to_le16(header_size);\n\t\td->res_count    = d->req_count;\n\t\td->transfer_status = 0;\n\t\td->data_address = cpu_to_le32(d_bus + (z * sizeof(*d)));\n\n\t\trest = payload_per_buffer;\n\t\tfor (j = 1; j < z; j++) {\n\t\t\tpd = d + j;\n\t\t\tpd->control = cpu_to_le16(DESCRIPTOR_STATUS |\n\t\t\t\t\t\t  DESCRIPTOR_INPUT_MORE);\n\n\t\t\tif (offset + rest < PAGE_SIZE)\n\t\t\t\tlength = rest;\n\t\t\telse\n\t\t\t\tlength = PAGE_SIZE - offset;\n\t\t\tpd->req_count = cpu_to_le16(length);\n\t\t\tpd->res_count = pd->req_count;\n\t\t\tpd->transfer_status = 0;\n\n\t\t\tpage_bus = page_private(buffer->pages[page]);\n\t\t\tpd->data_address = cpu_to_le32(page_bus + offset);\n\n\t\t\toffset = (offset + length) & ~PAGE_MASK;\n\t\t\trest -= length;\n\t\t\tif (offset == 0)\n\t\t\t\tpage++;\n\t\t}\n\t\tpd->control = cpu_to_le16(DESCRIPTOR_STATUS |\n\t\t\t\t\t  DESCRIPTOR_INPUT_LAST |\n\t\t\t\t\t  DESCRIPTOR_BRANCH_ALWAYS);\n\t\tif (p->interrupt && i == packet_count - 1)\n\t\t\tpd->control |= cpu_to_le16(DESCRIPTOR_IRQ_ALWAYS);\n\n\t\tcontext_append(&ctx->context, d, z, header_z);\n\t}\n\n\treturn 0;\n}",
        "func": "static int ohci_queue_iso_receive_packet_per_buffer(struct fw_iso_context *base,\n\t\t\t\t\tstruct fw_iso_packet *packet,\n\t\t\t\t\tstruct fw_iso_buffer *buffer,\n\t\t\t\t\tunsigned long payload)\n{\n\tstruct iso_context *ctx = container_of(base, struct iso_context, base);\n\tstruct descriptor *d, *pd;\n\tstruct fw_iso_packet *p = packet;\n\tdma_addr_t d_bus, page_bus;\n\tu32 z, header_z, rest;\n\tint i, j, length;\n\tint page, offset, packet_count, header_size, payload_per_buffer;\n\n\t/*\n\t * The OHCI controller puts the isochronous header and trailer in the\n\t * buffer, so we need at least 8 bytes.\n\t */\n\tpacket_count = p->header_length / ctx->base.header_size;\n\theader_size  = max(ctx->base.header_size, (size_t)8);\n\n\t/* Get header size in number of descriptors. */\n\theader_z = DIV_ROUND_UP(header_size, sizeof(*d));\n\tpage     = payload >> PAGE_SHIFT;\n\toffset   = payload & ~PAGE_MASK;\n\tpayload_per_buffer = p->payload_length / packet_count;\n\n\tfor (i = 0; i < packet_count; i++) {\n\t\t/* d points to the header descriptor */\n\t\tz = DIV_ROUND_UP(payload_per_buffer + offset, PAGE_SIZE) + 1;\n\t\td = context_get_descriptors(&ctx->context,\n\t\t\t\tz + header_z, &d_bus);\n\t\tif (d == NULL)\n\t\t\treturn -ENOMEM;\n\n\t\td->control      = cpu_to_le16(DESCRIPTOR_STATUS |\n\t\t\t\t\t      DESCRIPTOR_INPUT_MORE);\n\t\tif (p->skip && i == 0)\n\t\t\td->control |= cpu_to_le16(DESCRIPTOR_WAIT);\n\t\td->req_count    = cpu_to_le16(header_size);\n\t\td->res_count    = d->req_count;\n\t\td->transfer_status = 0;\n\t\td->data_address = cpu_to_le32(d_bus + (z * sizeof(*d)));\n\n\t\trest = payload_per_buffer;\n\t\tpd = d;\n\t\tfor (j = 1; j < z; j++) {\n\t\t\tpd++;\n\t\t\tpd->control = cpu_to_le16(DESCRIPTOR_STATUS |\n\t\t\t\t\t\t  DESCRIPTOR_INPUT_MORE);\n\n\t\t\tif (offset + rest < PAGE_SIZE)\n\t\t\t\tlength = rest;\n\t\t\telse\n\t\t\t\tlength = PAGE_SIZE - offset;\n\t\t\tpd->req_count = cpu_to_le16(length);\n\t\t\tpd->res_count = pd->req_count;\n\t\t\tpd->transfer_status = 0;\n\n\t\t\tpage_bus = page_private(buffer->pages[page]);\n\t\t\tpd->data_address = cpu_to_le32(page_bus + offset);\n\n\t\t\toffset = (offset + length) & ~PAGE_MASK;\n\t\t\trest -= length;\n\t\t\tif (offset == 0)\n\t\t\t\tpage++;\n\t\t}\n\t\tpd->control = cpu_to_le16(DESCRIPTOR_STATUS |\n\t\t\t\t\t  DESCRIPTOR_INPUT_LAST |\n\t\t\t\t\t  DESCRIPTOR_BRANCH_ALWAYS);\n\t\tif (p->interrupt && i == packet_count - 1)\n\t\t\tpd->control |= cpu_to_le16(DESCRIPTOR_IRQ_ALWAYS);\n\n\t\tcontext_append(&ctx->context, d, z, header_z);\n\t}\n\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,7 +4,7 @@\n \t\t\t\t\tunsigned long payload)\n {\n \tstruct iso_context *ctx = container_of(base, struct iso_context, base);\n-\tstruct descriptor *d = NULL, *pd = NULL;\n+\tstruct descriptor *d, *pd;\n \tstruct fw_iso_packet *p = packet;\n \tdma_addr_t d_bus, page_bus;\n \tu32 z, header_z, rest;\n@@ -42,8 +42,9 @@\n \t\td->data_address = cpu_to_le32(d_bus + (z * sizeof(*d)));\n \n \t\trest = payload_per_buffer;\n+\t\tpd = d;\n \t\tfor (j = 1; j < z; j++) {\n-\t\t\tpd = d + j;\n+\t\t\tpd++;\n \t\t\tpd->control = cpu_to_le16(DESCRIPTOR_STATUS |\n \t\t\t\t\t\t  DESCRIPTOR_INPUT_MORE);\n ",
        "diff_line_info": {
            "deleted_lines": [
                "\tstruct descriptor *d = NULL, *pd = NULL;",
                "\t\t\tpd = d + j;"
            ],
            "added_lines": [
                "\tstruct descriptor *d, *pd;",
                "\t\tpd = d;",
                "\t\t\tpd++;"
            ]
        }
    },
    {
        "cve_id": "CVE-2009-4138",
        "func_name": "torvalds/linux/ohci_queue_iso_receive_dualbuffer",
        "description": "drivers/firewire/ohci.c in the Linux kernel before 2.6.32-git9, when packet-per-buffer mode is used, allows local users to cause a denial of service (NULL pointer dereference and system crash) or possibly have unknown other impact via an unspecified ioctl associated with receiving an ISO packet that contains zero in the payload-length field.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=8c0c0cc2d9f4c523fde04bdfe41e4380dec8ee54",
        "commit_title": "Queueing to receive an ISO packet with a payload length of zero",
        "commit_text": "silently does nothing in dualbuffer mode, and crashes the kernel in packet-per-buffer mode.  Return an error in dualbuffer mode, because the DMA controller won't let us do what we want, and work correctly in packet-per-buffer mode.  Cc: stable@kernel.org ",
        "func_before": "static int ohci_queue_iso_receive_dualbuffer(struct fw_iso_context *base,\n\t\t\t\t\t     struct fw_iso_packet *packet,\n\t\t\t\t\t     struct fw_iso_buffer *buffer,\n\t\t\t\t\t     unsigned long payload)\n{\n\tstruct iso_context *ctx = container_of(base, struct iso_context, base);\n\tstruct db_descriptor *db = NULL;\n\tstruct descriptor *d;\n\tstruct fw_iso_packet *p;\n\tdma_addr_t d_bus, page_bus;\n\tu32 z, header_z, length, rest;\n\tint page, offset, packet_count, header_size;\n\n\t/*\n\t * FIXME: Cycle lost behavior should be configurable: lose\n\t * packet, retransmit or terminate..\n\t */\n\n\tp = packet;\n\tz = 2;\n\n\t/*\n\t * The OHCI controller puts the isochronous header and trailer in the\n\t * buffer, so we need at least 8 bytes.\n\t */\n\tpacket_count = p->header_length / ctx->base.header_size;\n\theader_size = packet_count * max(ctx->base.header_size, (size_t)8);\n\n\t/* Get header size in number of descriptors. */\n\theader_z = DIV_ROUND_UP(header_size, sizeof(*d));\n\tpage     = payload >> PAGE_SHIFT;\n\toffset   = payload & ~PAGE_MASK;\n\trest     = p->payload_length;\n\n\t/* FIXME: make packet-per-buffer/dual-buffer a context option */\n\twhile (rest > 0) {\n\t\td = context_get_descriptors(&ctx->context,\n\t\t\t\t\t    z + header_z, &d_bus);\n\t\tif (d == NULL)\n\t\t\treturn -ENOMEM;\n\n\t\tdb = (struct db_descriptor *) d;\n\t\tdb->control = cpu_to_le16(DESCRIPTOR_STATUS |\n\t\t\t\t\t  DESCRIPTOR_BRANCH_ALWAYS);\n\t\tdb->first_size =\n\t\t    cpu_to_le16(max(ctx->base.header_size, (size_t)8));\n\t\tif (p->skip && rest == p->payload_length) {\n\t\t\tdb->control |= cpu_to_le16(DESCRIPTOR_WAIT);\n\t\t\tdb->first_req_count = db->first_size;\n\t\t} else {\n\t\t\tdb->first_req_count = cpu_to_le16(header_size);\n\t\t}\n\t\tdb->first_res_count = db->first_req_count;\n\t\tdb->first_buffer = cpu_to_le32(d_bus + sizeof(*db));\n\n\t\tif (p->skip && rest == p->payload_length)\n\t\t\tlength = 4;\n\t\telse if (offset + rest < PAGE_SIZE)\n\t\t\tlength = rest;\n\t\telse\n\t\t\tlength = PAGE_SIZE - offset;\n\n\t\tdb->second_req_count = cpu_to_le16(length);\n\t\tdb->second_res_count = db->second_req_count;\n\t\tpage_bus = page_private(buffer->pages[page]);\n\t\tdb->second_buffer = cpu_to_le32(page_bus + offset);\n\n\t\tif (p->interrupt && length == rest)\n\t\t\tdb->control |= cpu_to_le16(DESCRIPTOR_IRQ_ALWAYS);\n\n\t\tcontext_append(&ctx->context, d, z, header_z);\n\t\toffset = (offset + length) & ~PAGE_MASK;\n\t\trest -= length;\n\t\tif (offset == 0)\n\t\t\tpage++;\n\t}\n\n\treturn 0;\n}",
        "func": "static int ohci_queue_iso_receive_dualbuffer(struct fw_iso_context *base,\n\t\t\t\t\t     struct fw_iso_packet *packet,\n\t\t\t\t\t     struct fw_iso_buffer *buffer,\n\t\t\t\t\t     unsigned long payload)\n{\n\tstruct iso_context *ctx = container_of(base, struct iso_context, base);\n\tstruct db_descriptor *db = NULL;\n\tstruct descriptor *d;\n\tstruct fw_iso_packet *p;\n\tdma_addr_t d_bus, page_bus;\n\tu32 z, header_z, length, rest;\n\tint page, offset, packet_count, header_size;\n\n\t/*\n\t * FIXME: Cycle lost behavior should be configurable: lose\n\t * packet, retransmit or terminate..\n\t */\n\n\tp = packet;\n\tz = 2;\n\n\t/*\n\t * The OHCI controller puts the isochronous header and trailer in the\n\t * buffer, so we need at least 8 bytes.\n\t */\n\tpacket_count = p->header_length / ctx->base.header_size;\n\theader_size = packet_count * max(ctx->base.header_size, (size_t)8);\n\n\t/* Get header size in number of descriptors. */\n\theader_z = DIV_ROUND_UP(header_size, sizeof(*d));\n\tpage     = payload >> PAGE_SHIFT;\n\toffset   = payload & ~PAGE_MASK;\n\trest     = p->payload_length;\n\t/*\n\t * The controllers I've tested have not worked correctly when\n\t * second_req_count is zero.  Rather than do something we know won't\n\t * work, return an error\n\t */\n\tif (rest == 0)\n\t\treturn -EINVAL;\n\n\t/* FIXME: make packet-per-buffer/dual-buffer a context option */\n\twhile (rest > 0) {\n\t\td = context_get_descriptors(&ctx->context,\n\t\t\t\t\t    z + header_z, &d_bus);\n\t\tif (d == NULL)\n\t\t\treturn -ENOMEM;\n\n\t\tdb = (struct db_descriptor *) d;\n\t\tdb->control = cpu_to_le16(DESCRIPTOR_STATUS |\n\t\t\t\t\t  DESCRIPTOR_BRANCH_ALWAYS);\n\t\tdb->first_size =\n\t\t    cpu_to_le16(max(ctx->base.header_size, (size_t)8));\n\t\tif (p->skip && rest == p->payload_length) {\n\t\t\tdb->control |= cpu_to_le16(DESCRIPTOR_WAIT);\n\t\t\tdb->first_req_count = db->first_size;\n\t\t} else {\n\t\t\tdb->first_req_count = cpu_to_le16(header_size);\n\t\t}\n\t\tdb->first_res_count = db->first_req_count;\n\t\tdb->first_buffer = cpu_to_le32(d_bus + sizeof(*db));\n\n\t\tif (p->skip && rest == p->payload_length)\n\t\t\tlength = 4;\n\t\telse if (offset + rest < PAGE_SIZE)\n\t\t\tlength = rest;\n\t\telse\n\t\t\tlength = PAGE_SIZE - offset;\n\n\t\tdb->second_req_count = cpu_to_le16(length);\n\t\tdb->second_res_count = db->second_req_count;\n\t\tpage_bus = page_private(buffer->pages[page]);\n\t\tdb->second_buffer = cpu_to_le32(page_bus + offset);\n\n\t\tif (p->interrupt && length == rest)\n\t\t\tdb->control |= cpu_to_le16(DESCRIPTOR_IRQ_ALWAYS);\n\n\t\tcontext_append(&ctx->context, d, z, header_z);\n\t\toffset = (offset + length) & ~PAGE_MASK;\n\t\trest -= length;\n\t\tif (offset == 0)\n\t\t\tpage++;\n\t}\n\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -31,6 +31,13 @@\n \tpage     = payload >> PAGE_SHIFT;\n \toffset   = payload & ~PAGE_MASK;\n \trest     = p->payload_length;\n+\t/*\n+\t * The controllers I've tested have not worked correctly when\n+\t * second_req_count is zero.  Rather than do something we know won't\n+\t * work, return an error\n+\t */\n+\tif (rest == 0)\n+\t\treturn -EINVAL;\n \n \t/* FIXME: make packet-per-buffer/dual-buffer a context option */\n \twhile (rest > 0) {",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t/*",
                "\t * The controllers I've tested have not worked correctly when",
                "\t * second_req_count is zero.  Rather than do something we know won't",
                "\t * work, return an error",
                "\t */",
                "\tif (rest == 0)",
                "\t\treturn -EINVAL;"
            ]
        }
    },
    {
        "cve_id": "CVE-2009-4141",
        "func_name": "torvalds/linux/fasync_helper",
        "description": "Use-after-free vulnerability in the fasync_helper function in fs/fcntl.c in the Linux kernel before 2.6.33-rc4-git1 allows local users to gain privileges via vectors that include enabling O_ASYNC (aka FASYNC or FIOASYNC) on a locked file, and then closing this file.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=53281b6d34d44308372d16acb7fb5327609f68b6",
        "commit_title": "Yes, the add and remove cases do share the same basic loop and the",
        "commit_text": "locking, but the compiler can inline and then CSE some of the end result anyway.  And splitting it up makes the code way easier to follow, and makes it clearer exactly what the semantics are.  In particular, we must make sure that the FASYNC flag in file->f_flags exactly matches the state of \"is this file on any fasync list\", since not only is that flag visible to user space (F_GETFL), but we also use that flag to check whether we need to remove any fasync entries on file close.  We got that wrong for the case of a mixed use of file locking (which tries to remove any fasync entries for file leases) and fasync.  Splitting the function up also makes it possible to do some future optimizations without making the function even messier.  In particular, since the FASYNC flag has to match the state of \"is this on a list\", we can do the following future optimizations:   - on remove, we don't even need to get the locks and traverse the list    if FASYNC isn't set, since we can know a priori that there is no    point (this is effectively the same optimization that we already do    in __fput() wrt removing fasync on file close)   - on add, we can use the FASYNC flag to decide whether we are changing    an existing entry or need to allocate a new one.  but this is just the cleanup + fix for the FASYNC flag.  Cc: Jeff Dike <jdike@addtoit.com> Cc: Matt Mackall <mpm@selenic.com> Cc: stable@kernel.org ",
        "func_before": "int fasync_helper(int fd, struct file * filp, int on, struct fasync_struct **fapp)\n{\n\tstruct fasync_struct *fa, **fp;\n\tstruct fasync_struct *new = NULL;\n\tint result = 0;\n\n\tif (on) {\n\t\tnew = kmem_cache_alloc(fasync_cache, GFP_KERNEL);\n\t\tif (!new)\n\t\t\treturn -ENOMEM;\n\t}\n\n\t/*\n\t * We need to take f_lock first since it's not an IRQ-safe\n\t * lock.\n\t */\n\tspin_lock(&filp->f_lock);\n\twrite_lock_irq(&fasync_lock);\n\tfor (fp = fapp; (fa = *fp) != NULL; fp = &fa->fa_next) {\n\t\tif (fa->fa_file == filp) {\n\t\t\tif(on) {\n\t\t\t\tfa->fa_fd = fd;\n\t\t\t\tkmem_cache_free(fasync_cache, new);\n\t\t\t} else {\n\t\t\t\t*fp = fa->fa_next;\n\t\t\t\tkmem_cache_free(fasync_cache, fa);\n\t\t\t\tresult = 1;\n\t\t\t}\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tif (on) {\n\t\tnew->magic = FASYNC_MAGIC;\n\t\tnew->fa_file = filp;\n\t\tnew->fa_fd = fd;\n\t\tnew->fa_next = *fapp;\n\t\t*fapp = new;\n\t\tresult = 1;\n\t}\nout:\n\tif (on)\n\t\tfilp->f_flags |= FASYNC;\n\telse\n\t\tfilp->f_flags &= ~FASYNC;\n\twrite_unlock_irq(&fasync_lock);\n\tspin_unlock(&filp->f_lock);\n\treturn result;\n}",
        "func": "int fasync_helper(int fd, struct file * filp, int on, struct fasync_struct **fapp)\n{\n\tif (!on)\n\t\treturn fasync_remove_entry(filp, fapp);\n\treturn fasync_add_entry(fd, filp, fapp);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,49 +1,6 @@\n int fasync_helper(int fd, struct file * filp, int on, struct fasync_struct **fapp)\n {\n-\tstruct fasync_struct *fa, **fp;\n-\tstruct fasync_struct *new = NULL;\n-\tint result = 0;\n-\n-\tif (on) {\n-\t\tnew = kmem_cache_alloc(fasync_cache, GFP_KERNEL);\n-\t\tif (!new)\n-\t\t\treturn -ENOMEM;\n-\t}\n-\n-\t/*\n-\t * We need to take f_lock first since it's not an IRQ-safe\n-\t * lock.\n-\t */\n-\tspin_lock(&filp->f_lock);\n-\twrite_lock_irq(&fasync_lock);\n-\tfor (fp = fapp; (fa = *fp) != NULL; fp = &fa->fa_next) {\n-\t\tif (fa->fa_file == filp) {\n-\t\t\tif(on) {\n-\t\t\t\tfa->fa_fd = fd;\n-\t\t\t\tkmem_cache_free(fasync_cache, new);\n-\t\t\t} else {\n-\t\t\t\t*fp = fa->fa_next;\n-\t\t\t\tkmem_cache_free(fasync_cache, fa);\n-\t\t\t\tresult = 1;\n-\t\t\t}\n-\t\t\tgoto out;\n-\t\t}\n-\t}\n-\n-\tif (on) {\n-\t\tnew->magic = FASYNC_MAGIC;\n-\t\tnew->fa_file = filp;\n-\t\tnew->fa_fd = fd;\n-\t\tnew->fa_next = *fapp;\n-\t\t*fapp = new;\n-\t\tresult = 1;\n-\t}\n-out:\n-\tif (on)\n-\t\tfilp->f_flags |= FASYNC;\n-\telse\n-\t\tfilp->f_flags &= ~FASYNC;\n-\twrite_unlock_irq(&fasync_lock);\n-\tspin_unlock(&filp->f_lock);\n-\treturn result;\n+\tif (!on)\n+\t\treturn fasync_remove_entry(filp, fapp);\n+\treturn fasync_add_entry(fd, filp, fapp);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tstruct fasync_struct *fa, **fp;",
                "\tstruct fasync_struct *new = NULL;",
                "\tint result = 0;",
                "",
                "\tif (on) {",
                "\t\tnew = kmem_cache_alloc(fasync_cache, GFP_KERNEL);",
                "\t\tif (!new)",
                "\t\t\treturn -ENOMEM;",
                "\t}",
                "",
                "\t/*",
                "\t * We need to take f_lock first since it's not an IRQ-safe",
                "\t * lock.",
                "\t */",
                "\tspin_lock(&filp->f_lock);",
                "\twrite_lock_irq(&fasync_lock);",
                "\tfor (fp = fapp; (fa = *fp) != NULL; fp = &fa->fa_next) {",
                "\t\tif (fa->fa_file == filp) {",
                "\t\t\tif(on) {",
                "\t\t\t\tfa->fa_fd = fd;",
                "\t\t\t\tkmem_cache_free(fasync_cache, new);",
                "\t\t\t} else {",
                "\t\t\t\t*fp = fa->fa_next;",
                "\t\t\t\tkmem_cache_free(fasync_cache, fa);",
                "\t\t\t\tresult = 1;",
                "\t\t\t}",
                "\t\t\tgoto out;",
                "\t\t}",
                "\t}",
                "",
                "\tif (on) {",
                "\t\tnew->magic = FASYNC_MAGIC;",
                "\t\tnew->fa_file = filp;",
                "\t\tnew->fa_fd = fd;",
                "\t\tnew->fa_next = *fapp;",
                "\t\t*fapp = new;",
                "\t\tresult = 1;",
                "\t}",
                "out:",
                "\tif (on)",
                "\t\tfilp->f_flags |= FASYNC;",
                "\telse",
                "\t\tfilp->f_flags &= ~FASYNC;",
                "\twrite_unlock_irq(&fasync_lock);",
                "\tspin_unlock(&filp->f_lock);",
                "\treturn result;"
            ],
            "added_lines": [
                "\tif (!on)",
                "\t\treturn fasync_remove_entry(filp, fapp);",
                "\treturn fasync_add_entry(fd, filp, fapp);"
            ]
        }
    },
    {
        "cve_id": "CVE-2010-0410",
        "func_name": "torvalds/linux/cn_init",
        "description": "drivers/connector/connector.c in the Linux kernel before 2.6.32.8 allows local users to cause a denial of service (memory consumption and system crash) by sending the kernel many NETLINK_CONNECTOR messages.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=f98bfbd78c37c5946cc53089da32a5f741efdeb7",
        "commit_title": "On Tue, Feb 02, 2010 at 02:57:14PM -0800, Greg KH (gregkh@suse.de) wrote:",
        "commit_text": "> > There are at least two ways to fix it: using a big cannon and a small > > one. The former way is to disable notification registration, since it is > > not used by anyone at all. Second way is to check whether calling > > process is root and its destination group is -1 (kind of priveledged > > one) before command is dispatched to workqueue. >  > Well if no one is using it, removing it makes the most sense, right? >  > No objection from me, care to make up a patch either way for this?  Getting it is not used, let's drop support for notifications about (un)registered events from connector. Another option was to check credentials on receiving, but we can always restore it without bugs if needed, but genetlink has a wider code base and none complained, that userspace can not get notification when some other clients were (un)registered.  Kudos for Sebastian Krahmer <krahmer@suse.de>, who found a bug in the code.  ",
        "func_before": "static int __devinit cn_init(void)\n{\n\tstruct cn_dev *dev = &cdev;\n\tint err;\n\n\tdev->input = cn_rx_skb;\n\tdev->id.idx = cn_idx;\n\tdev->id.val = cn_val;\n\n\tdev->nls = netlink_kernel_create(&init_net, NETLINK_CONNECTOR,\n\t\t\t\t\t CN_NETLINK_USERS + 0xf,\n\t\t\t\t\t dev->input, NULL, THIS_MODULE);\n\tif (!dev->nls)\n\t\treturn -EIO;\n\n\tdev->cbdev = cn_queue_alloc_dev(\"cqueue\", dev->nls);\n\tif (!dev->cbdev) {\n\t\tnetlink_kernel_release(dev->nls);\n\t\treturn -EINVAL;\n\t}\n\n\tcn_already_initialized = 1;\n\n\terr = cn_add_callback(&dev->id, \"connector\", &cn_callback);\n\tif (err) {\n\t\tcn_already_initialized = 0;\n\t\tcn_queue_free_dev(dev->cbdev);\n\t\tnetlink_kernel_release(dev->nls);\n\t\treturn -EINVAL;\n\t}\n\n\tproc_net_fops_create(&init_net, \"connector\", S_IRUGO, &cn_file_ops);\n\n\treturn 0;\n}",
        "func": "static int __devinit cn_init(void)\n{\n\tstruct cn_dev *dev = &cdev;\n\n\tdev->input = cn_rx_skb;\n\n\tdev->nls = netlink_kernel_create(&init_net, NETLINK_CONNECTOR,\n\t\t\t\t\t CN_NETLINK_USERS + 0xf,\n\t\t\t\t\t dev->input, NULL, THIS_MODULE);\n\tif (!dev->nls)\n\t\treturn -EIO;\n\n\tdev->cbdev = cn_queue_alloc_dev(\"cqueue\", dev->nls);\n\tif (!dev->cbdev) {\n\t\tnetlink_kernel_release(dev->nls);\n\t\treturn -EINVAL;\n\t}\n\n\tcn_already_initialized = 1;\n\n\tproc_net_fops_create(&init_net, \"connector\", S_IRUGO, &cn_file_ops);\n\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,11 +1,8 @@\n static int __devinit cn_init(void)\n {\n \tstruct cn_dev *dev = &cdev;\n-\tint err;\n \n \tdev->input = cn_rx_skb;\n-\tdev->id.idx = cn_idx;\n-\tdev->id.val = cn_val;\n \n \tdev->nls = netlink_kernel_create(&init_net, NETLINK_CONNECTOR,\n \t\t\t\t\t CN_NETLINK_USERS + 0xf,\n@@ -21,14 +18,6 @@\n \n \tcn_already_initialized = 1;\n \n-\terr = cn_add_callback(&dev->id, \"connector\", &cn_callback);\n-\tif (err) {\n-\t\tcn_already_initialized = 0;\n-\t\tcn_queue_free_dev(dev->cbdev);\n-\t\tnetlink_kernel_release(dev->nls);\n-\t\treturn -EINVAL;\n-\t}\n-\n \tproc_net_fops_create(&init_net, \"connector\", S_IRUGO, &cn_file_ops);\n \n \treturn 0;",
        "diff_line_info": {
            "deleted_lines": [
                "\tint err;",
                "\tdev->id.idx = cn_idx;",
                "\tdev->id.val = cn_val;",
                "\terr = cn_add_callback(&dev->id, \"connector\", &cn_callback);",
                "\tif (err) {",
                "\t\tcn_already_initialized = 0;",
                "\t\tcn_queue_free_dev(dev->cbdev);",
                "\t\tnetlink_kernel_release(dev->nls);",
                "\t\treturn -EINVAL;",
                "\t}",
                ""
            ],
            "added_lines": []
        }
    },
    {
        "cve_id": "CVE-2010-0410",
        "func_name": "torvalds/linux/cn_del_callback",
        "description": "drivers/connector/connector.c in the Linux kernel before 2.6.32.8 allows local users to cause a denial of service (memory consumption and system crash) by sending the kernel many NETLINK_CONNECTOR messages.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=f98bfbd78c37c5946cc53089da32a5f741efdeb7",
        "commit_title": "On Tue, Feb 02, 2010 at 02:57:14PM -0800, Greg KH (gregkh@suse.de) wrote:",
        "commit_text": "> > There are at least two ways to fix it: using a big cannon and a small > > one. The former way is to disable notification registration, since it is > > not used by anyone at all. Second way is to check whether calling > > process is root and its destination group is -1 (kind of priveledged > > one) before command is dispatched to workqueue. >  > Well if no one is using it, removing it makes the most sense, right? >  > No objection from me, care to make up a patch either way for this?  Getting it is not used, let's drop support for notifications about (un)registered events from connector. Another option was to check credentials on receiving, but we can always restore it without bugs if needed, but genetlink has a wider code base and none complained, that userspace can not get notification when some other clients were (un)registered.  Kudos for Sebastian Krahmer <krahmer@suse.de>, who found a bug in the code.  ",
        "func_before": "void cn_del_callback(struct cb_id *id)\n{\n\tstruct cn_dev *dev = &cdev;\n\n\tcn_queue_del_callback(dev->cbdev, id);\n\tcn_notify(id, 1);\n}",
        "func": "void cn_del_callback(struct cb_id *id)\n{\n\tstruct cn_dev *dev = &cdev;\n\n\tcn_queue_del_callback(dev->cbdev, id);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,5 +3,4 @@\n \tstruct cn_dev *dev = &cdev;\n \n \tcn_queue_del_callback(dev->cbdev, id);\n-\tcn_notify(id, 1);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tcn_notify(id, 1);"
            ],
            "added_lines": []
        }
    },
    {
        "cve_id": "CVE-2010-0410",
        "func_name": "torvalds/linux/cn_fini",
        "description": "drivers/connector/connector.c in the Linux kernel before 2.6.32.8 allows local users to cause a denial of service (memory consumption and system crash) by sending the kernel many NETLINK_CONNECTOR messages.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=f98bfbd78c37c5946cc53089da32a5f741efdeb7",
        "commit_title": "On Tue, Feb 02, 2010 at 02:57:14PM -0800, Greg KH (gregkh@suse.de) wrote:",
        "commit_text": "> > There are at least two ways to fix it: using a big cannon and a small > > one. The former way is to disable notification registration, since it is > > not used by anyone at all. Second way is to check whether calling > > process is root and its destination group is -1 (kind of priveledged > > one) before command is dispatched to workqueue. >  > Well if no one is using it, removing it makes the most sense, right? >  > No objection from me, care to make up a patch either way for this?  Getting it is not used, let's drop support for notifications about (un)registered events from connector. Another option was to check credentials on receiving, but we can always restore it without bugs if needed, but genetlink has a wider code base and none complained, that userspace can not get notification when some other clients were (un)registered.  Kudos for Sebastian Krahmer <krahmer@suse.de>, who found a bug in the code.  ",
        "func_before": "static void __devexit cn_fini(void)\n{\n\tstruct cn_dev *dev = &cdev;\n\n\tcn_already_initialized = 0;\n\n\tproc_net_remove(&init_net, \"connector\");\n\n\tcn_del_callback(&dev->id);\n\tcn_queue_free_dev(dev->cbdev);\n\tnetlink_kernel_release(dev->nls);\n}",
        "func": "static void __devexit cn_fini(void)\n{\n\tstruct cn_dev *dev = &cdev;\n\n\tcn_already_initialized = 0;\n\n\tproc_net_remove(&init_net, \"connector\");\n\n\tcn_queue_free_dev(dev->cbdev);\n\tnetlink_kernel_release(dev->nls);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -6,7 +6,6 @@\n \n \tproc_net_remove(&init_net, \"connector\");\n \n-\tcn_del_callback(&dev->id);\n \tcn_queue_free_dev(dev->cbdev);\n \tnetlink_kernel_release(dev->nls);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tcn_del_callback(&dev->id);"
            ],
            "added_lines": []
        }
    },
    {
        "cve_id": "CVE-2010-0410",
        "func_name": "torvalds/linux/cn_add_callback",
        "description": "drivers/connector/connector.c in the Linux kernel before 2.6.32.8 allows local users to cause a denial of service (memory consumption and system crash) by sending the kernel many NETLINK_CONNECTOR messages.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=f98bfbd78c37c5946cc53089da32a5f741efdeb7",
        "commit_title": "On Tue, Feb 02, 2010 at 02:57:14PM -0800, Greg KH (gregkh@suse.de) wrote:",
        "commit_text": "> > There are at least two ways to fix it: using a big cannon and a small > > one. The former way is to disable notification registration, since it is > > not used by anyone at all. Second way is to check whether calling > > process is root and its destination group is -1 (kind of priveledged > > one) before command is dispatched to workqueue. >  > Well if no one is using it, removing it makes the most sense, right? >  > No objection from me, care to make up a patch either way for this?  Getting it is not used, let's drop support for notifications about (un)registered events from connector. Another option was to check credentials on receiving, but we can always restore it without bugs if needed, but genetlink has a wider code base and none complained, that userspace can not get notification when some other clients were (un)registered.  Kudos for Sebastian Krahmer <krahmer@suse.de>, who found a bug in the code.  ",
        "func_before": "int cn_add_callback(struct cb_id *id, char *name,\n\t\t    void (*callback)(struct cn_msg *, struct netlink_skb_parms *))\n{\n\tint err;\n\tstruct cn_dev *dev = &cdev;\n\n\tif (!cn_already_initialized)\n\t\treturn -EAGAIN;\n\n\terr = cn_queue_add_callback(dev->cbdev, name, id, callback);\n\tif (err)\n\t\treturn err;\n\n\tcn_notify(id, 0);\n\n\treturn 0;\n}",
        "func": "int cn_add_callback(struct cb_id *id, char *name,\n\t\t    void (*callback)(struct cn_msg *, struct netlink_skb_parms *))\n{\n\tint err;\n\tstruct cn_dev *dev = &cdev;\n\n\tif (!cn_already_initialized)\n\t\treturn -EAGAIN;\n\n\terr = cn_queue_add_callback(dev->cbdev, name, id, callback);\n\tif (err)\n\t\treturn err;\n\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -11,7 +11,5 @@\n \tif (err)\n \t\treturn err;\n \n-\tcn_notify(id, 0);\n-\n \treturn 0;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tcn_notify(id, 0);",
                ""
            ],
            "added_lines": []
        }
    },
    {
        "cve_id": "CVE-2012-0789",
        "func_name": "php/php-src/timelib_get_zone",
        "description": "Memory leak in the timezone functionality in PHP before 5.3.9 allows remote attackers to cause a denial of service (memory consumption) by triggering many strtotime function calls, which are not properly handled by the php_date_parse_tzfile cache.",
        "git_url": "https://github.com/php/php-src/commit/4c9fad8b362a7d2b6a94b4961e4b2dc037b2766d",
        "commit_title": "- Fixed bug #53502 (strtotime with timezone memory leak).",
        "commit_text": "- Fixed bug #52062 (large timestamps with DateTime::getTimestamp and   DateTime::setTimestamp). - Fixed bug #51994 (date_parse_from_format is parsing invalid date using 'yz'   format). - Fixed bug #51223 (Seg fault while creating (by unserialization)   DatePeriod).",
        "func_before": "static long timelib_get_zone(char **ptr, int *dst, timelib_time *t, int *tz_not_found, const timelib_tzdb *tzdb)\n{\n\ttimelib_tzinfo *res;\n\tlong            retval = 0;\n\n\t*tz_not_found = 0;\n\n\twhile (**ptr == ' ' || **ptr == '\\t' || **ptr == '(') {\n\t\t++*ptr;\n\t}\n\tif ((*ptr)[0] == 'G' && (*ptr)[1] == 'M' && (*ptr)[2] == 'T' && ((*ptr)[3] == '+' || (*ptr)[3] == '-')) {\n\t\t*ptr += 3;\n\t}\n\tif (**ptr == '+') {\n\t\t++*ptr;\n\t\tt->is_localtime = 1;\n\t\tt->zone_type = TIMELIB_ZONETYPE_OFFSET;\n\t\t*tz_not_found = 0;\n\t\tt->dst = 0;\n\n\t\tretval = -1 * timelib_parse_tz_cor(ptr);\n\t} else if (**ptr == '-') {\n\t\t++*ptr;\n\t\tt->is_localtime = 1;\n\t\tt->zone_type = TIMELIB_ZONETYPE_OFFSET;\n\t\t*tz_not_found = 0;\n\t\tt->dst = 0;\n\n\t\tretval = timelib_parse_tz_cor(ptr);\n\t} else {\n\t\tint found = 0;\n\t\tlong offset;\n\t\tchar *tz_abbr;\n\n\t\tt->is_localtime = 1;\n\n\t\toffset = timelib_lookup_zone(ptr, dst, &tz_abbr, &found);\n\t\tif (found) {\n\t\t\tt->zone_type = TIMELIB_ZONETYPE_ABBR;\n\t\t}\n#if 0\n\t\t/* If we found a TimeZone identifier, use it */\n\t\tif (tz_name) {\n\t\t\tt->tz_info = timelib_parse_tzfile(tz_name);\n\t\t\tt->zone_type = TIMELIB_ZONETYPE_ID;\n\t\t}\n#endif\n\t\t/* If we have a TimeZone identifier to start with, use it */\n\t\tif (strstr(tz_abbr, \"/\") || strcmp(tz_abbr, \"UTC\") == 0) {\n\t\t\tif ((res = timelib_parse_tzfile(tz_abbr, tzdb)) != NULL) {\n\t\t\t\tt->tz_info = res;\n\t\t\t\tt->zone_type = TIMELIB_ZONETYPE_ID;\n\t\t\t\tfound++;\n\t\t\t}\n\t\t}\n\t\tif (found && t->zone_type != TIMELIB_ZONETYPE_ID) {\n\t\t\ttimelib_time_tz_abbr_update(t, tz_abbr);\n\t\t}\n\t\tfree(tz_abbr);\n\t\t*tz_not_found = (found == 0);\n\t\tretval = offset;\n\t}\n\twhile (**ptr == ')') {\n\t\t++*ptr;\n\t}\n\treturn retval;\n}",
        "func": "static long timelib_get_zone(char **ptr, int *dst, timelib_time *t, int *tz_not_found, const timelib_tzdb *tzdb, timelib_tz_get_wrapper tz_wrapper)\n{\n\ttimelib_tzinfo *res;\n\tlong            retval = 0;\n\n\t*tz_not_found = 0;\n\n\twhile (**ptr == ' ' || **ptr == '\\t' || **ptr == '(') {\n\t\t++*ptr;\n\t}\n\tif ((*ptr)[0] == 'G' && (*ptr)[1] == 'M' && (*ptr)[2] == 'T' && ((*ptr)[3] == '+' || (*ptr)[3] == '-')) {\n\t\t*ptr += 3;\n\t}\n\tif (**ptr == '+') {\n\t\t++*ptr;\n\t\tt->is_localtime = 1;\n\t\tt->zone_type = TIMELIB_ZONETYPE_OFFSET;\n\t\t*tz_not_found = 0;\n\t\tt->dst = 0;\n\n\t\tretval = -1 * timelib_parse_tz_cor(ptr);\n\t} else if (**ptr == '-') {\n\t\t++*ptr;\n\t\tt->is_localtime = 1;\n\t\tt->zone_type = TIMELIB_ZONETYPE_OFFSET;\n\t\t*tz_not_found = 0;\n\t\tt->dst = 0;\n\n\t\tretval = timelib_parse_tz_cor(ptr);\n\t} else {\n\t\tint found = 0;\n\t\tlong offset;\n\t\tchar *tz_abbr;\n\n\t\tt->is_localtime = 1;\n\n\t\toffset = timelib_lookup_zone(ptr, dst, &tz_abbr, &found);\n\t\tif (found) {\n\t\t\tt->zone_type = TIMELIB_ZONETYPE_ABBR;\n\t\t}\n#if 0\n\t\t/* If we found a TimeZone identifier, use it */\n\t\tif (tz_name) {\n\t\t\tt->tz_info = timelib_parse_tzfile(tz_name);\n\t\t\tt->zone_type = TIMELIB_ZONETYPE_ID;\n\t\t}\n#endif\n\t\t/* If we have a TimeZone identifier to start with, use it */\n\t\tif (strstr(tz_abbr, \"/\") || strcmp(tz_abbr, \"UTC\") == 0) {\n\t\t\tif ((res = tz_wrapper(tz_abbr, tzdb)) != NULL) {\n\t\t\t\tt->tz_info = res;\n\t\t\t\tt->zone_type = TIMELIB_ZONETYPE_ID;\n\t\t\t\tfound++;\n\t\t\t}\n\t\t}\n\t\tif (found && t->zone_type != TIMELIB_ZONETYPE_ID) {\n\t\t\ttimelib_time_tz_abbr_update(t, tz_abbr);\n\t\t}\n\t\tfree(tz_abbr);\n\t\t*tz_not_found = (found == 0);\n\t\tretval = offset;\n\t}\n\twhile (**ptr == ')') {\n\t\t++*ptr;\n\t}\n\treturn retval;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,4 +1,4 @@\n-static long timelib_get_zone(char **ptr, int *dst, timelib_time *t, int *tz_not_found, const timelib_tzdb *tzdb)\n+static long timelib_get_zone(char **ptr, int *dst, timelib_time *t, int *tz_not_found, const timelib_tzdb *tzdb, timelib_tz_get_wrapper tz_wrapper)\n {\n \ttimelib_tzinfo *res;\n \tlong            retval = 0;\n@@ -47,7 +47,7 @@\n #endif\n \t\t/* If we have a TimeZone identifier to start with, use it */\n \t\tif (strstr(tz_abbr, \"/\") || strcmp(tz_abbr, \"UTC\") == 0) {\n-\t\t\tif ((res = timelib_parse_tzfile(tz_abbr, tzdb)) != NULL) {\n+\t\t\tif ((res = tz_wrapper(tz_abbr, tzdb)) != NULL) {\n \t\t\t\tt->tz_info = res;\n \t\t\t\tt->zone_type = TIMELIB_ZONETYPE_ID;\n \t\t\t\tfound++;",
        "diff_line_info": {
            "deleted_lines": [
                "static long timelib_get_zone(char **ptr, int *dst, timelib_time *t, int *tz_not_found, const timelib_tzdb *tzdb)",
                "\t\t\tif ((res = timelib_parse_tzfile(tz_abbr, tzdb)) != NULL) {"
            ],
            "added_lines": [
                "static long timelib_get_zone(char **ptr, int *dst, timelib_time *t, int *tz_not_found, const timelib_tzdb *tzdb, timelib_tz_get_wrapper tz_wrapper)",
                "\t\t\tif ((res = tz_wrapper(tz_abbr, tzdb)) != NULL) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-0789",
        "func_name": "php/php-src/timelib_parse_from_format",
        "description": "Memory leak in the timezone functionality in PHP before 5.3.9 allows remote attackers to cause a denial of service (memory consumption) by triggering many strtotime function calls, which are not properly handled by the php_date_parse_tzfile cache.",
        "git_url": "https://github.com/php/php-src/commit/4c9fad8b362a7d2b6a94b4961e4b2dc037b2766d",
        "commit_title": "- Fixed bug #53502 (strtotime with timezone memory leak).",
        "commit_text": "- Fixed bug #52062 (large timestamps with DateTime::getTimestamp and   DateTime::setTimestamp). - Fixed bug #51994 (date_parse_from_format is parsing invalid date using 'yz'   format). - Fixed bug #51223 (Seg fault while creating (by unserialization)   DatePeriod).",
        "func_before": "timelib_time *timelib_parse_from_format(char *format, char *string, int len, timelib_error_container **errors, const timelib_tzdb *tzdb)\n{\n\tchar       *fptr = format;\n\tchar       *ptr = string;\n\tchar       *begin;\n\ttimelib_sll tmp;\n\tScanner in;\n\tScanner *s = &in;\n\tint allow_extra = 0;\n\n\tmemset(&in, 0, sizeof(in));\n\tin.errors = malloc(sizeof(struct timelib_error_container));\n\tin.errors->warning_count = 0;\n\tin.errors->warning_messages = NULL;\n\tin.errors->error_count = 0;\n\tin.errors->error_messages = NULL;\n\n\tin.time = timelib_time_ctor();\n\tin.time->y = TIMELIB_UNSET;\n\tin.time->d = TIMELIB_UNSET;\n\tin.time->m = TIMELIB_UNSET;\n\tin.time->h = TIMELIB_UNSET;\n\tin.time->i = TIMELIB_UNSET;\n\tin.time->s = TIMELIB_UNSET;\n\tin.time->f = TIMELIB_UNSET;\n\tin.time->z = TIMELIB_UNSET;\n\tin.time->dst = TIMELIB_UNSET;\n\tin.tzdb = tzdb;\n\tin.time->is_localtime = 0;\n\tin.time->zone_type = 0;\n\n\t/* Loop over the format string */\n\twhile (*fptr && *ptr) {\n\t\tbegin = ptr;\n\t\tswitch (*fptr) {\n\t\t\tcase 'D': /* three letter day */\n\t\t\tcase 'l': /* full day */\n\t\t\t\t{\n\t\t\t\t\tconst timelib_relunit* tmprel = 0;\n\n\t\t\t\t\ttmprel = timelib_lookup_relunit((char **) &ptr);\n\t\t\t\t\tif (!tmprel) {\n\t\t\t\t\t\tadd_pbf_error(s, \"A textual day could not be found\", string, begin);\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tin.time->have_relative = 1; \n\t\t\t\t\t\tin.time->relative.have_weekday_relative = 1;\n\t\t\t\t\t\tin.time->relative.weekday = tmprel->multiplier;\n\t\t\t\t\t\tin.time->relative.weekday_behavior = 1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase 'd': /* two digit day, with leading zero */\n\t\t\tcase 'j': /* two digit day, without leading zero */\n\t\t\t\tTIMELIB_CHECK_NUMBER;\n\t\t\t\tif ((s->time->d = timelib_get_nr((char **) &ptr, 2)) == TIMELIB_UNSET) {\n\t\t\t\t\tadd_pbf_error(s, \"A two digit day could not be found\", string, begin);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase 'S': /* day suffix, ignored, nor checked */\n\t\t\t\ttimelib_skip_day_suffix((char **) &ptr);\n\t\t\t\tbreak;\n\t\t\tcase 'z': /* day of year - resets month (0 based) */\n\t\t\t\tTIMELIB_CHECK_NUMBER;\n\t\t\t\tif ((tmp = timelib_get_nr((char **) &ptr, 3)) == TIMELIB_UNSET) {\n\t\t\t\t\tadd_pbf_error(s, \"A three digit day-of-year could not be found\", string, begin);\n\t\t\t\t} else {\n\t\t\t\t\ts->time->m = 1;\n\t\t\t\t\ts->time->d = tmp + 1;\n\t\t\t\t}\n\t\t\t\tbreak;\n\n\t\t\tcase 'm': /* two digit month, with leading zero */\n\t\t\tcase 'n': /* two digit month, without leading zero */\n\t\t\t\tTIMELIB_CHECK_NUMBER;\n\t\t\t\tif ((s->time->m = timelib_get_nr((char **) &ptr, 2)) == TIMELIB_UNSET) {\n\t\t\t\t\tadd_pbf_error(s, \"A two digit month could not be found\", string, begin);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase 'M': /* three letter month */\n\t\t\tcase 'F': /* full month */\n\t\t\t\ttmp = timelib_lookup_month((char **) &ptr);\n\t\t\t\tif (!tmp) {\n\t\t\t\t\tadd_pbf_error(s, \"A textual month could not be found\", string, begin);\n\t\t\t\t} else {\n\t\t\t\t\ts->time->m = tmp;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase 'y': /* two digit year */\n\t\t\t\t{\n\t\t\t\t\tint length = 0;\n\t\t\t\t\tTIMELIB_CHECK_NUMBER;\n\t\t\t\t\tif ((s->time->y = timelib_get_nr_ex((char **) &ptr, 2, &length)) == TIMELIB_UNSET) {\n\t\t\t\t\t\tadd_pbf_error(s, \"A two digit year could not be found\", string, begin);\n\t\t\t\t\t}\n\t\t\t\t\tTIMELIB_PROCESS_YEAR(s->time->y, length);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase 'Y': /* four digit year */\n\t\t\t\tTIMELIB_CHECK_NUMBER;\n\t\t\t\tif ((s->time->y = timelib_get_nr((char **) &ptr, 4)) == TIMELIB_UNSET) {\n\t\t\t\t\tadd_pbf_error(s, \"A four digit year could not be found\", string, begin);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase 'g': /* two digit hour, with leading zero */\n\t\t\tcase 'h': /* two digit hour, without leading zero */\n\t\t\t\tTIMELIB_CHECK_NUMBER;\n\t\t\t\tif ((s->time->h = timelib_get_nr((char **) &ptr, 2)) == TIMELIB_UNSET) {\n\t\t\t\t\tadd_pbf_error(s, \"A two digit hour could not be found\", string, begin);\n\t\t\t\t}\n\t\t\t\tif (s->time->h > 12) {\n\t\t\t\t\tadd_pbf_error(s, \"Hour can not be higher than 12\", string, begin);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase 'G': /* two digit hour, with leading zero */\n\t\t\tcase 'H': /* two digit hour, without leading zero */\n\t\t\t\tTIMELIB_CHECK_NUMBER;\n\t\t\t\tif ((s->time->h = timelib_get_nr((char **) &ptr, 2)) == TIMELIB_UNSET) {\n\t\t\t\t\tadd_pbf_error(s, \"A two digit hour could not be found\", string, begin);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase 'a': /* am/pm/a.m./p.m. */\n\t\t\tcase 'A': /* AM/PM/A.M./P.M. */\n\t\t\t\tif (s->time->h == TIMELIB_UNSET) {\n\t\t\t\t\tadd_pbf_error(s, \"Meridian can only come after an hour has been found\", string, begin);\n\t\t\t\t} else if ((tmp = timelib_meridian_with_check((char **) &ptr, s->time->h)) == TIMELIB_UNSET) {\n\t\t\t\t\tadd_pbf_error(s, \"A meridian could not be found\", string, begin);\n\t\t\t\t} else {\n\t\t\t\t\ts->time->h += tmp;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase 'i': /* two digit minute, with leading zero */\n\t\t\t\t{\n\t\t\t\t\tint length;\n\t\t\t\t\ttimelib_sll min;\n\n\t\t\t\t\tTIMELIB_CHECK_NUMBER;\n\t\t\t\t\tmin = timelib_get_nr_ex((char **) &ptr, 2, &length);\n\t\t\t\t\tif (min == TIMELIB_UNSET || length != 2) {\n\t\t\t\t\t\tadd_pbf_error(s, \"A two digit minute could not be found\", string, begin);\n\t\t\t\t\t} else {\n\t\t\t\t\t\ts->time->i = min;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase 's': /* two digit second, with leading zero */\n\t\t\t\t{\n\t\t\t\t\tint length;\n\t\t\t\t\ttimelib_sll sec;\n\n\t\t\t\t\tTIMELIB_CHECK_NUMBER;\n\t\t\t\t\tsec = timelib_get_nr_ex((char **) &ptr, 2, &length);\n\t\t\t\t\tif (sec == TIMELIB_UNSET || length != 2) {\n\t\t\t\t\t\tadd_pbf_error(s, \"A two second minute could not be found\", string, begin);\n\t\t\t\t\t} else {\n\t\t\t\t\t\ts->time->s = sec;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase 'u': /* up to six digit millisecond */\n\t\t\t\t{\n\t\t\t\t\tdouble f;\n\t\t\t\t\tchar *tptr;\n\n\t\t\t\t\tTIMELIB_CHECK_NUMBER;\n\t\t\t\t\ttptr = ptr;\n\t\t\t\t\tif ((f = timelib_get_nr((char **) &ptr, 6)) == TIMELIB_UNSET || (ptr - tptr < 1)) {\n\t\t\t\t\t\tadd_pbf_error(s, \"A six digit millisecond could not be found\", string, begin);\n\t\t\t\t\t} else {\n\t\t\t\t\t\ts->time->f = (f / pow(10, (ptr - tptr)));\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase ' ': /* any sort of whitespace (' ' and \\t) */\n\t\t\t\ttimelib_eat_spaces((char **) &ptr);\n\t\t\t\tbreak;\n\t\t\tcase 'U': /* epoch seconds */\n\t\t\t\tTIMELIB_CHECK_NUMBER;\n\t\t\t\tTIMELIB_HAVE_RELATIVE();\n\t\t\t\ttmp = timelib_get_unsigned_nr((char **) &ptr, 24);\n\t\t\t\ts->time->y = 1970;\n\t\t\t\ts->time->m = 1;\n\t\t\t\ts->time->d = 1;\n\t\t\t\ts->time->h = s->time->i = s->time->s = 0;\n\t\t\t\ts->time->f = 0.0;\n\t\t\t\ts->time->relative.s += tmp;\n\t\t\t\ts->time->is_localtime = 1;\n\t\t\t\ts->time->zone_type = TIMELIB_ZONETYPE_OFFSET;\n\t\t\t\ts->time->z = 0;\n\t\t\t\tbreak;\n\n\t\t\tcase 'e': /* timezone */\n\t\t\tcase 'P': /* timezone */\n\t\t\tcase 'T': /* timezone */\n\t\t\tcase 'O': /* timezone */\n\t\t\t\t{\n\t\t\t\t\tint tz_not_found;\n\t\t\t\t\ts->time->z = timelib_get_zone((char **) &ptr, &s->time->dst, s->time, &tz_not_found, s->tzdb);\n\t\t\t\t\tif (tz_not_found) {\n\t\t\t\t\t\tadd_pbf_error(s, \"The timezone could not be found in the database\", string, begin);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tbreak;\n\n\t\t\tcase '#': /* separation symbol */\n\t\t\t\tif (*ptr == ';' || *ptr == ':' || *ptr == '/' || *ptr == '.' || *ptr == ',' || *ptr == '-' || *ptr == '(' || *ptr == ')') {\n\t\t\t\t\t++ptr;\n\t\t\t\t} else {\n\t\t\t\t\tadd_pbf_error(s, \"The separation symbol ([;:/.,-]) could not be found\", string, begin);\n\t\t\t\t}\n\t\t\t\tbreak;\n\n\t\t\tcase ';':\n\t\t\tcase ':':\n\t\t\tcase '/':\n\t\t\tcase '.':\n\t\t\tcase ',':\n\t\t\tcase '-':\n\t\t\tcase '(':\n\t\t\tcase ')':\n\t\t\t\tif (*ptr == *fptr) {\n\t\t\t\t\t++ptr;\n\t\t\t\t} else {\n\t\t\t\t\tadd_pbf_error(s, \"The separation symbol could not be found\", string, begin);\n\t\t\t\t}\n\t\t\t\tbreak;\n\n\t\t\tcase '!': /* reset all fields to default */\n\t\t\t\ttimelib_time_reset_fields(s->time);\n\t\t\t\tbreak; /* break intentionally not missing */\n\n\t\t\tcase '|': /* reset all fields to default when not set */\n\t\t\t\ttimelib_time_reset_unset_fields(s->time);\n\t\t\t\tbreak; /* break intentionally not missing */\n\n\t\t\tcase '?': /* random char */\n\t\t\t\t++ptr;\n\t\t\t\tbreak;\n\n\t\t\tcase '\\\\': /* escaped char */\n\t\t\t\t*fptr++;\n\t\t\t\tif (*ptr == *fptr) {\n\t\t\t\t\t++ptr;\n\t\t\t\t} else {\n\t\t\t\t\tadd_pbf_error(s, \"The escaped character could not be found\", string, begin);\n\t\t\t\t}\n\t\t\t\tbreak;\n\n\t\t\tcase '*': /* random chars until a separator or number ([ \\t.,:;/-0123456789]) */\n\t\t\t\ttimelib_eat_until_separator((char **) &ptr);\n\t\t\t\tbreak;\n\n\t\t\tcase '+': /* allow extra chars in the format */\n\t\t\t\tallow_extra = 1;\n\t\t\t\tbreak;\n\n\t\t\tdefault:\n\t\t\t\tif (*fptr != *ptr) {\n\t\t\t\t\tadd_pbf_error(s, \"The format separator does not match\", string, begin);\n\t\t\t\t}\n\t\t\t\tptr++;\n\t\t}\n\t\tfptr++;\n\t}\n\tif (*ptr) {\n\t\tif (allow_extra) {\n\t\t\tadd_pbf_warning(s, \"Trailing data\", string, ptr);\n\t\t} else {\n\t\t\tadd_pbf_error(s, \"Trailing data\", string, ptr);\n\t\t}\n\t}\n\t/* ignore trailing +'s */\n\twhile (*fptr == '+') {\n\t\tfptr++;\n\t}\n\tif (*fptr) {\n\t\t/* Trailing | and ! specifiers are valid. */\n\t\tint done = 0;\n\t\twhile (*fptr && !done) {\n\t\t\tswitch (*fptr++) {\n\t\t\t\tcase '!': /* reset all fields to default */\n\t\t\t\t\ttimelib_time_reset_fields(s->time);\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase '|': /* reset all fields to default when not set */\n\t\t\t\t\ttimelib_time_reset_unset_fields(s->time);\n\t\t\t\t\tbreak;\n\n\t\t\t\tdefault:\n\t\t\t\t\tadd_pbf_error(s, \"Data missing\", string, ptr);\n\t\t\t\t\tdone = 1;\n\t\t\t}\n\t\t}\n\t}\n\n\t/* clean up a bit */\n\tif (s->time->h != TIMELIB_UNSET || s->time->i != TIMELIB_UNSET || s->time->s != TIMELIB_UNSET) {\n\t\tif (s->time->h == TIMELIB_UNSET ) {\n\t\t\ts->time->h = 0;\n\t\t}\n\t\tif (s->time->i == TIMELIB_UNSET ) {\n\t\t\ts->time->i = 0;\n\t\t}\n\t\tif (s->time->s == TIMELIB_UNSET ) {\n\t\t\ts->time->s = 0;\n\t\t}\n\t}\n\n\t/* do funky checking whether the parsed time was valid time */\n\tif (s->time->h != TIMELIB_UNSET && s->time->i != TIMELIB_UNSET &&\n\t\ts->time->s != TIMELIB_UNSET && \n\t\t!timelib_valid_time( s->time->h, s->time->i, s->time->s)) {\n\t\tadd_pbf_warning(s, \"The parsed time was invalid\", string, ptr);\n\t}\n\t/* do funky checking whether the parsed date was valid date */\n\tif (s->time->y != TIMELIB_UNSET && s->time->m != TIMELIB_UNSET &&\n\t\ts->time->d != TIMELIB_UNSET && \n\t\t!timelib_valid_date( s->time->y, s->time->m, s->time->d)) {\n\t\tadd_pbf_warning(s, \"The parsed date was invalid\", string, ptr);\n\t}\n\n\tif (errors) {\n\t\t*errors = in.errors;\n\t} else {\n\t\ttimelib_error_container_dtor(in.errors);\n\t}\n\treturn in.time;\n}",
        "func": "timelib_time *timelib_parse_from_format(char *format, char *string, int len, timelib_error_container **errors, const timelib_tzdb *tzdb, timelib_tz_get_wrapper tz_get_wrapper)\n{\n\tchar       *fptr = format;\n\tchar       *ptr = string;\n\tchar       *begin;\n\ttimelib_sll tmp;\n\tScanner in;\n\tScanner *s = &in;\n\tint allow_extra = 0;\n\n\tmemset(&in, 0, sizeof(in));\n\tin.errors = malloc(sizeof(struct timelib_error_container));\n\tin.errors->warning_count = 0;\n\tin.errors->warning_messages = NULL;\n\tin.errors->error_count = 0;\n\tin.errors->error_messages = NULL;\n\n\tin.time = timelib_time_ctor();\n\tin.time->y = TIMELIB_UNSET;\n\tin.time->d = TIMELIB_UNSET;\n\tin.time->m = TIMELIB_UNSET;\n\tin.time->h = TIMELIB_UNSET;\n\tin.time->i = TIMELIB_UNSET;\n\tin.time->s = TIMELIB_UNSET;\n\tin.time->f = TIMELIB_UNSET;\n\tin.time->z = TIMELIB_UNSET;\n\tin.time->dst = TIMELIB_UNSET;\n\tin.tzdb = tzdb;\n\tin.time->is_localtime = 0;\n\tin.time->zone_type = 0;\n\n\t/* Loop over the format string */\n\twhile (*fptr && *ptr) {\n\t\tbegin = ptr;\n\t\tswitch (*fptr) {\n\t\t\tcase 'D': /* three letter day */\n\t\t\tcase 'l': /* full day */\n\t\t\t\t{\n\t\t\t\t\tconst timelib_relunit* tmprel = 0;\n\n\t\t\t\t\ttmprel = timelib_lookup_relunit((char **) &ptr);\n\t\t\t\t\tif (!tmprel) {\n\t\t\t\t\t\tadd_pbf_error(s, \"A textual day could not be found\", string, begin);\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tin.time->have_relative = 1; \n\t\t\t\t\t\tin.time->relative.have_weekday_relative = 1;\n\t\t\t\t\t\tin.time->relative.weekday = tmprel->multiplier;\n\t\t\t\t\t\tin.time->relative.weekday_behavior = 1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase 'd': /* two digit day, with leading zero */\n\t\t\tcase 'j': /* two digit day, without leading zero */\n\t\t\t\tTIMELIB_CHECK_NUMBER;\n\t\t\t\tif ((s->time->d = timelib_get_nr((char **) &ptr, 2)) == TIMELIB_UNSET) {\n\t\t\t\t\tadd_pbf_error(s, \"A two digit day could not be found\", string, begin);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase 'S': /* day suffix, ignored, nor checked */\n\t\t\t\ttimelib_skip_day_suffix((char **) &ptr);\n\t\t\t\tbreak;\n\t\t\tcase 'z': /* day of year - resets month (0 based) - also initializes everything else to !TIMELIB_UNSET */\n\t\t\t\tTIMELIB_CHECK_NUMBER;\n\t\t\t\tif ((tmp = timelib_get_nr((char **) &ptr, 3)) == TIMELIB_UNSET) {\n\t\t\t\t\tadd_pbf_error(s, \"A three digit day-of-year could not be found\", string, begin);\n\t\t\t\t} else {\n\t\t\t\t\ts->time->m = 1;\n\t\t\t\t\ts->time->d = tmp + 1;\n\t\t\t\t\ttimelib_do_normalize(s->time);\n\t\t\t\t}\n\t\t\t\tbreak;\n\n\t\t\tcase 'm': /* two digit month, with leading zero */\n\t\t\tcase 'n': /* two digit month, without leading zero */\n\t\t\t\tTIMELIB_CHECK_NUMBER;\n\t\t\t\tif ((s->time->m = timelib_get_nr((char **) &ptr, 2)) == TIMELIB_UNSET) {\n\t\t\t\t\tadd_pbf_error(s, \"A two digit month could not be found\", string, begin);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase 'M': /* three letter month */\n\t\t\tcase 'F': /* full month */\n\t\t\t\ttmp = timelib_lookup_month((char **) &ptr);\n\t\t\t\tif (!tmp) {\n\t\t\t\t\tadd_pbf_error(s, \"A textual month could not be found\", string, begin);\n\t\t\t\t} else {\n\t\t\t\t\ts->time->m = tmp;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase 'y': /* two digit year */\n\t\t\t\t{\n\t\t\t\t\tint length = 0;\n\t\t\t\t\tTIMELIB_CHECK_NUMBER;\n\t\t\t\t\tif ((s->time->y = timelib_get_nr_ex((char **) &ptr, 2, &length)) == TIMELIB_UNSET) {\n\t\t\t\t\t\tadd_pbf_error(s, \"A two digit year could not be found\", string, begin);\n\t\t\t\t\t}\n\t\t\t\t\tTIMELIB_PROCESS_YEAR(s->time->y, length);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase 'Y': /* four digit year */\n\t\t\t\tTIMELIB_CHECK_NUMBER;\n\t\t\t\tif ((s->time->y = timelib_get_nr((char **) &ptr, 4)) == TIMELIB_UNSET) {\n\t\t\t\t\tadd_pbf_error(s, \"A four digit year could not be found\", string, begin);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase 'g': /* two digit hour, with leading zero */\n\t\t\tcase 'h': /* two digit hour, without leading zero */\n\t\t\t\tTIMELIB_CHECK_NUMBER;\n\t\t\t\tif ((s->time->h = timelib_get_nr((char **) &ptr, 2)) == TIMELIB_UNSET) {\n\t\t\t\t\tadd_pbf_error(s, \"A two digit hour could not be found\", string, begin);\n\t\t\t\t}\n\t\t\t\tif (s->time->h > 12) {\n\t\t\t\t\tadd_pbf_error(s, \"Hour can not be higher than 12\", string, begin);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase 'G': /* two digit hour, with leading zero */\n\t\t\tcase 'H': /* two digit hour, without leading zero */\n\t\t\t\tTIMELIB_CHECK_NUMBER;\n\t\t\t\tif ((s->time->h = timelib_get_nr((char **) &ptr, 2)) == TIMELIB_UNSET) {\n\t\t\t\t\tadd_pbf_error(s, \"A two digit hour could not be found\", string, begin);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase 'a': /* am/pm/a.m./p.m. */\n\t\t\tcase 'A': /* AM/PM/A.M./P.M. */\n\t\t\t\tif (s->time->h == TIMELIB_UNSET) {\n\t\t\t\t\tadd_pbf_error(s, \"Meridian can only come after an hour has been found\", string, begin);\n\t\t\t\t} else if ((tmp = timelib_meridian_with_check((char **) &ptr, s->time->h)) == TIMELIB_UNSET) {\n\t\t\t\t\tadd_pbf_error(s, \"A meridian could not be found\", string, begin);\n\t\t\t\t} else {\n\t\t\t\t\ts->time->h += tmp;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase 'i': /* two digit minute, with leading zero */\n\t\t\t\t{\n\t\t\t\t\tint length;\n\t\t\t\t\ttimelib_sll min;\n\n\t\t\t\t\tTIMELIB_CHECK_NUMBER;\n\t\t\t\t\tmin = timelib_get_nr_ex((char **) &ptr, 2, &length);\n\t\t\t\t\tif (min == TIMELIB_UNSET || length != 2) {\n\t\t\t\t\t\tadd_pbf_error(s, \"A two digit minute could not be found\", string, begin);\n\t\t\t\t\t} else {\n\t\t\t\t\t\ts->time->i = min;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase 's': /* two digit second, with leading zero */\n\t\t\t\t{\n\t\t\t\t\tint length;\n\t\t\t\t\ttimelib_sll sec;\n\n\t\t\t\t\tTIMELIB_CHECK_NUMBER;\n\t\t\t\t\tsec = timelib_get_nr_ex((char **) &ptr, 2, &length);\n\t\t\t\t\tif (sec == TIMELIB_UNSET || length != 2) {\n\t\t\t\t\t\tadd_pbf_error(s, \"A two second minute could not be found\", string, begin);\n\t\t\t\t\t} else {\n\t\t\t\t\t\ts->time->s = sec;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase 'u': /* up to six digit millisecond */\n\t\t\t\t{\n\t\t\t\t\tdouble f;\n\t\t\t\t\tchar *tptr;\n\n\t\t\t\t\tTIMELIB_CHECK_NUMBER;\n\t\t\t\t\ttptr = ptr;\n\t\t\t\t\tif ((f = timelib_get_nr((char **) &ptr, 6)) == TIMELIB_UNSET || (ptr - tptr < 1)) {\n\t\t\t\t\t\tadd_pbf_error(s, \"A six digit millisecond could not be found\", string, begin);\n\t\t\t\t\t} else {\n\t\t\t\t\t\ts->time->f = (f / pow(10, (ptr - tptr)));\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase ' ': /* any sort of whitespace (' ' and \\t) */\n\t\t\t\ttimelib_eat_spaces((char **) &ptr);\n\t\t\t\tbreak;\n\t\t\tcase 'U': /* epoch seconds */\n\t\t\t\tTIMELIB_CHECK_NUMBER;\n\t\t\t\tTIMELIB_HAVE_RELATIVE();\n\t\t\t\ttmp = timelib_get_unsigned_nr((char **) &ptr, 24);\n\t\t\t\ts->time->y = 1970;\n\t\t\t\ts->time->m = 1;\n\t\t\t\ts->time->d = 1;\n\t\t\t\ts->time->h = s->time->i = s->time->s = 0;\n\t\t\t\ts->time->f = 0.0;\n\t\t\t\ts->time->relative.s += tmp;\n\t\t\t\ts->time->is_localtime = 1;\n\t\t\t\ts->time->zone_type = TIMELIB_ZONETYPE_OFFSET;\n\t\t\t\ts->time->z = 0;\n\t\t\t\tbreak;\n\n\t\t\tcase 'e': /* timezone */\n\t\t\tcase 'P': /* timezone */\n\t\t\tcase 'T': /* timezone */\n\t\t\tcase 'O': /* timezone */\n\t\t\t\t{\n\t\t\t\t\tint tz_not_found;\n\t\t\t\t\ts->time->z = timelib_get_zone((char **) &ptr, &s->time->dst, s->time, &tz_not_found, s->tzdb, tz_get_wrapper);\n\t\t\t\t\tif (tz_not_found) {\n\t\t\t\t\t\tadd_pbf_error(s, \"The timezone could not be found in the database\", string, begin);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tbreak;\n\n\t\t\tcase '#': /* separation symbol */\n\t\t\t\tif (*ptr == ';' || *ptr == ':' || *ptr == '/' || *ptr == '.' || *ptr == ',' || *ptr == '-' || *ptr == '(' || *ptr == ')') {\n\t\t\t\t\t++ptr;\n\t\t\t\t} else {\n\t\t\t\t\tadd_pbf_error(s, \"The separation symbol ([;:/.,-]) could not be found\", string, begin);\n\t\t\t\t}\n\t\t\t\tbreak;\n\n\t\t\tcase ';':\n\t\t\tcase ':':\n\t\t\tcase '/':\n\t\t\tcase '.':\n\t\t\tcase ',':\n\t\t\tcase '-':\n\t\t\tcase '(':\n\t\t\tcase ')':\n\t\t\t\tif (*ptr == *fptr) {\n\t\t\t\t\t++ptr;\n\t\t\t\t} else {\n\t\t\t\t\tadd_pbf_error(s, \"The separation symbol could not be found\", string, begin);\n\t\t\t\t}\n\t\t\t\tbreak;\n\n\t\t\tcase '!': /* reset all fields to default */\n\t\t\t\ttimelib_time_reset_fields(s->time);\n\t\t\t\tbreak; /* break intentionally not missing */\n\n\t\t\tcase '|': /* reset all fields to default when not set */\n\t\t\t\ttimelib_time_reset_unset_fields(s->time);\n\t\t\t\tbreak; /* break intentionally not missing */\n\n\t\t\tcase '?': /* random char */\n\t\t\t\t++ptr;\n\t\t\t\tbreak;\n\n\t\t\tcase '\\\\': /* escaped char */\n\t\t\t\t*fptr++;\n\t\t\t\tif (*ptr == *fptr) {\n\t\t\t\t\t++ptr;\n\t\t\t\t} else {\n\t\t\t\t\tadd_pbf_error(s, \"The escaped character could not be found\", string, begin);\n\t\t\t\t}\n\t\t\t\tbreak;\n\n\t\t\tcase '*': /* random chars until a separator or number ([ \\t.,:;/-0123456789]) */\n\t\t\t\ttimelib_eat_until_separator((char **) &ptr);\n\t\t\t\tbreak;\n\n\t\t\tcase '+': /* allow extra chars in the format */\n\t\t\t\tallow_extra = 1;\n\t\t\t\tbreak;\n\n\t\t\tdefault:\n\t\t\t\tif (*fptr != *ptr) {\n\t\t\t\t\tadd_pbf_error(s, \"The format separator does not match\", string, begin);\n\t\t\t\t}\n\t\t\t\tptr++;\n\t\t}\n\t\tfptr++;\n\t}\n\tif (*ptr) {\n\t\tif (allow_extra) {\n\t\t\tadd_pbf_warning(s, \"Trailing data\", string, ptr);\n\t\t} else {\n\t\t\tadd_pbf_error(s, \"Trailing data\", string, ptr);\n\t\t}\n\t}\n\t/* ignore trailing +'s */\n\twhile (*fptr == '+') {\n\t\tfptr++;\n\t}\n\tif (*fptr) {\n\t\t/* Trailing | and ! specifiers are valid. */\n\t\tint done = 0;\n\t\twhile (*fptr && !done) {\n\t\t\tswitch (*fptr++) {\n\t\t\t\tcase '!': /* reset all fields to default */\n\t\t\t\t\ttimelib_time_reset_fields(s->time);\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase '|': /* reset all fields to default when not set */\n\t\t\t\t\ttimelib_time_reset_unset_fields(s->time);\n\t\t\t\t\tbreak;\n\n\t\t\t\tdefault:\n\t\t\t\t\tadd_pbf_error(s, \"Data missing\", string, ptr);\n\t\t\t\t\tdone = 1;\n\t\t\t}\n\t\t}\n\t}\n\n\t/* clean up a bit */\n\tif (s->time->h != TIMELIB_UNSET || s->time->i != TIMELIB_UNSET || s->time->s != TIMELIB_UNSET) {\n\t\tif (s->time->h == TIMELIB_UNSET ) {\n\t\t\ts->time->h = 0;\n\t\t}\n\t\tif (s->time->i == TIMELIB_UNSET ) {\n\t\t\ts->time->i = 0;\n\t\t}\n\t\tif (s->time->s == TIMELIB_UNSET ) {\n\t\t\ts->time->s = 0;\n\t\t}\n\t}\n\n\t/* do funky checking whether the parsed time was valid time */\n\tif (s->time->h != TIMELIB_UNSET && s->time->i != TIMELIB_UNSET &&\n\t\ts->time->s != TIMELIB_UNSET && \n\t\t!timelib_valid_time( s->time->h, s->time->i, s->time->s)) {\n\t\tadd_pbf_warning(s, \"The parsed time was invalid\", string, ptr);\n\t}\n\t/* do funky checking whether the parsed date was valid date */\n\tif (s->time->y != TIMELIB_UNSET && s->time->m != TIMELIB_UNSET &&\n\t\ts->time->d != TIMELIB_UNSET && \n\t\t!timelib_valid_date( s->time->y, s->time->m, s->time->d)) {\n\t\tadd_pbf_warning(s, \"The parsed date was invalid\", string, ptr);\n\t}\n\n\tif (errors) {\n\t\t*errors = in.errors;\n\t} else {\n\t\ttimelib_error_container_dtor(in.errors);\n\t}\n\treturn in.time;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,4 +1,4 @@\n-timelib_time *timelib_parse_from_format(char *format, char *string, int len, timelib_error_container **errors, const timelib_tzdb *tzdb)\n+timelib_time *timelib_parse_from_format(char *format, char *string, int len, timelib_error_container **errors, const timelib_tzdb *tzdb, timelib_tz_get_wrapper tz_get_wrapper)\n {\n \tchar       *fptr = format;\n \tchar       *ptr = string;\n@@ -60,13 +60,14 @@\n \t\t\tcase 'S': /* day suffix, ignored, nor checked */\n \t\t\t\ttimelib_skip_day_suffix((char **) &ptr);\n \t\t\t\tbreak;\n-\t\t\tcase 'z': /* day of year - resets month (0 based) */\n+\t\t\tcase 'z': /* day of year - resets month (0 based) - also initializes everything else to !TIMELIB_UNSET */\n \t\t\t\tTIMELIB_CHECK_NUMBER;\n \t\t\t\tif ((tmp = timelib_get_nr((char **) &ptr, 3)) == TIMELIB_UNSET) {\n \t\t\t\t\tadd_pbf_error(s, \"A three digit day-of-year could not be found\", string, begin);\n \t\t\t\t} else {\n \t\t\t\t\ts->time->m = 1;\n \t\t\t\t\ts->time->d = tmp + 1;\n+\t\t\t\t\ttimelib_do_normalize(s->time);\n \t\t\t\t}\n \t\t\t\tbreak;\n \n@@ -195,7 +196,7 @@\n \t\t\tcase 'O': /* timezone */\n \t\t\t\t{\n \t\t\t\t\tint tz_not_found;\n-\t\t\t\t\ts->time->z = timelib_get_zone((char **) &ptr, &s->time->dst, s->time, &tz_not_found, s->tzdb);\n+\t\t\t\t\ts->time->z = timelib_get_zone((char **) &ptr, &s->time->dst, s->time, &tz_not_found, s->tzdb, tz_get_wrapper);\n \t\t\t\t\tif (tz_not_found) {\n \t\t\t\t\t\tadd_pbf_error(s, \"The timezone could not be found in the database\", string, begin);\n \t\t\t\t\t}",
        "diff_line_info": {
            "deleted_lines": [
                "timelib_time *timelib_parse_from_format(char *format, char *string, int len, timelib_error_container **errors, const timelib_tzdb *tzdb)",
                "\t\t\tcase 'z': /* day of year - resets month (0 based) */",
                "\t\t\t\t\ts->time->z = timelib_get_zone((char **) &ptr, &s->time->dst, s->time, &tz_not_found, s->tzdb);"
            ],
            "added_lines": [
                "timelib_time *timelib_parse_from_format(char *format, char *string, int len, timelib_error_container **errors, const timelib_tzdb *tzdb, timelib_tz_get_wrapper tz_get_wrapper)",
                "\t\t\tcase 'z': /* day of year - resets month (0 based) - also initializes everything else to !TIMELIB_UNSET */",
                "\t\t\t\t\ttimelib_do_normalize(s->time);",
                "\t\t\t\t\ts->time->z = timelib_get_zone((char **) &ptr, &s->time->dst, s->time, &tz_not_found, s->tzdb, tz_get_wrapper);"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-0789",
        "func_name": "php/php-src/timelib_strtotime",
        "description": "Memory leak in the timezone functionality in PHP before 5.3.9 allows remote attackers to cause a denial of service (memory consumption) by triggering many strtotime function calls, which are not properly handled by the php_date_parse_tzfile cache.",
        "git_url": "https://github.com/php/php-src/commit/4c9fad8b362a7d2b6a94b4961e4b2dc037b2766d",
        "commit_title": "- Fixed bug #53502 (strtotime with timezone memory leak).",
        "commit_text": "- Fixed bug #52062 (large timestamps with DateTime::getTimestamp and   DateTime::setTimestamp). - Fixed bug #51994 (date_parse_from_format is parsing invalid date using 'yz'   format). - Fixed bug #51223 (Seg fault while creating (by unserialization)   DatePeriod).",
        "func_before": "timelib_time* timelib_strtotime(char *s, int len, struct timelib_error_container **errors, const timelib_tzdb *tzdb)\n{\n\tScanner in;\n\tint t;\n\tchar *e = s + len - 1;\n\n\tmemset(&in, 0, sizeof(in));\n\tin.errors = malloc(sizeof(struct timelib_error_container));\n\tin.errors->warning_count = 0;\n\tin.errors->warning_messages = NULL;\n\tin.errors->error_count = 0;\n\tin.errors->error_messages = NULL;\n\n\tif (len > 0) {\n\t\twhile (isspace(*s) && s < e) {\n\t\t\ts++;\n\t\t}\n\t\twhile (isspace(*e) && e > s) {\n\t\t\te--;\n\t\t}\n\t}\n\tif (e - s < 0) {\n\t\tin.time = timelib_time_ctor();\n\t\tadd_error(&in, \"Empty string\");\n\t\tif (errors) {\n\t\t\t*errors = in.errors;\n\t\t} else {\n\t\t\ttimelib_error_container_dtor(in.errors);\n\t\t}\n\t\tin.time->y = in.time->d = in.time->m = in.time->h = in.time->i = in.time->s = in.time->f = in.time->dst = in.time->z = TIMELIB_UNSET;\n\t\tin.time->is_localtime = in.time->zone_type = 0;\n\t\treturn in.time;\n\t}\n\te++;\n\n\tin.str = malloc((e - s) + YYMAXFILL);\n\tmemset(in.str, 0, (e - s) + YYMAXFILL);\n\tmemcpy(in.str, s, (e - s));\n\tin.lim = in.str + (e - s) + YYMAXFILL;\n\tin.cur = in.str;\n\tin.time = timelib_time_ctor();\n\tin.time->y = TIMELIB_UNSET;\n\tin.time->d = TIMELIB_UNSET;\n\tin.time->m = TIMELIB_UNSET;\n\tin.time->h = TIMELIB_UNSET;\n\tin.time->i = TIMELIB_UNSET;\n\tin.time->s = TIMELIB_UNSET;\n\tin.time->f = TIMELIB_UNSET;\n\tin.time->z = TIMELIB_UNSET;\n\tin.time->dst = TIMELIB_UNSET;\n\tin.tzdb = tzdb;\n\tin.time->is_localtime = 0;\n\tin.time->zone_type = 0;\n\n\tdo {\n\t\tt = scan(&in);\n#ifdef DEBUG_PARSER\n\t\tprintf(\"%d\\n\", t);\n#endif\n\t} while(t != EOI);\n\n\t/* do funky checking whether the parsed time was valid time */\n\tif (in.time->have_time && !timelib_valid_time( in.time->h, in.time->i, in.time->s)) {\n\t\tadd_warning(&in, \"The parsed time was invalid\");\n\t}\n\t/* do funky checking whether the parsed date was valid date */\n\tif (in.time->have_date && !timelib_valid_date( in.time->y, in.time->m, in.time->d)) {\n\t\tadd_warning(&in, \"The parsed date was invalid\");\n\t}\n\n\tfree(in.str);\n\tif (errors) {\n\t\t*errors = in.errors;\n\t} else {\n\t\ttimelib_error_container_dtor(in.errors);\n\t}\n\treturn in.time;\n}",
        "func": "timelib_time* timelib_strtotime(char *s, int len, struct timelib_error_container **errors, const timelib_tzdb *tzdb, timelib_tz_get_wrapper tz_get_wrapper)\n{\n\tScanner in;\n\tint t;\n\tchar *e = s + len - 1;\n\n\tmemset(&in, 0, sizeof(in));\n\tin.errors = malloc(sizeof(struct timelib_error_container));\n\tin.errors->warning_count = 0;\n\tin.errors->warning_messages = NULL;\n\tin.errors->error_count = 0;\n\tin.errors->error_messages = NULL;\n\n\tif (len > 0) {\n\t\twhile (isspace(*s) && s < e) {\n\t\t\ts++;\n\t\t}\n\t\twhile (isspace(*e) && e > s) {\n\t\t\te--;\n\t\t}\n\t}\n\tif (e - s < 0) {\n\t\tin.time = timelib_time_ctor();\n\t\tadd_error(&in, \"Empty string\");\n\t\tif (errors) {\n\t\t\t*errors = in.errors;\n\t\t} else {\n\t\t\ttimelib_error_container_dtor(in.errors);\n\t\t}\n\t\tin.time->y = in.time->d = in.time->m = in.time->h = in.time->i = in.time->s = in.time->f = in.time->dst = in.time->z = TIMELIB_UNSET;\n\t\tin.time->is_localtime = in.time->zone_type = 0;\n\t\treturn in.time;\n\t}\n\te++;\n\n\tin.str = malloc((e - s) + YYMAXFILL);\n\tmemset(in.str, 0, (e - s) + YYMAXFILL);\n\tmemcpy(in.str, s, (e - s));\n\tin.lim = in.str + (e - s) + YYMAXFILL;\n\tin.cur = in.str;\n\tin.time = timelib_time_ctor();\n\tin.time->y = TIMELIB_UNSET;\n\tin.time->d = TIMELIB_UNSET;\n\tin.time->m = TIMELIB_UNSET;\n\tin.time->h = TIMELIB_UNSET;\n\tin.time->i = TIMELIB_UNSET;\n\tin.time->s = TIMELIB_UNSET;\n\tin.time->f = TIMELIB_UNSET;\n\tin.time->z = TIMELIB_UNSET;\n\tin.time->dst = TIMELIB_UNSET;\n\tin.tzdb = tzdb;\n\tin.time->is_localtime = 0;\n\tin.time->zone_type = 0;\n\n\tdo {\n\t\tt = scan(&in, tz_get_wrapper);\n#ifdef DEBUG_PARSER\n\t\tprintf(\"%d\\n\", t);\n#endif\n\t} while(t != EOI);\n\n\t/* do funky checking whether the parsed time was valid time */\n\tif (in.time->have_time && !timelib_valid_time( in.time->h, in.time->i, in.time->s)) {\n\t\tadd_warning(&in, \"The parsed time was invalid\");\n\t}\n\t/* do funky checking whether the parsed date was valid date */\n\tif (in.time->have_date && !timelib_valid_date( in.time->y, in.time->m, in.time->d)) {\n\t\tadd_warning(&in, \"The parsed date was invalid\");\n\t}\n\n\tfree(in.str);\n\tif (errors) {\n\t\t*errors = in.errors;\n\t} else {\n\t\ttimelib_error_container_dtor(in.errors);\n\t}\n\treturn in.time;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,4 +1,4 @@\n-timelib_time* timelib_strtotime(char *s, int len, struct timelib_error_container **errors, const timelib_tzdb *tzdb)\n+timelib_time* timelib_strtotime(char *s, int len, struct timelib_error_container **errors, const timelib_tzdb *tzdb, timelib_tz_get_wrapper tz_get_wrapper)\n {\n \tScanner in;\n \tint t;\n@@ -53,7 +53,7 @@\n \tin.time->zone_type = 0;\n \n \tdo {\n-\t\tt = scan(&in);\n+\t\tt = scan(&in, tz_get_wrapper);\n #ifdef DEBUG_PARSER\n \t\tprintf(\"%d\\n\", t);\n #endif",
        "diff_line_info": {
            "deleted_lines": [
                "timelib_time* timelib_strtotime(char *s, int len, struct timelib_error_container **errors, const timelib_tzdb *tzdb)",
                "\t\tt = scan(&in);"
            ],
            "added_lines": [
                "timelib_time* timelib_strtotime(char *s, int len, struct timelib_error_container **errors, const timelib_tzdb *tzdb, timelib_tz_get_wrapper tz_get_wrapper)",
                "\t\tt = scan(&in, tz_get_wrapper);"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-0789",
        "func_name": "php/php-src/do_adjust_special",
        "description": "Memory leak in the timezone functionality in PHP before 5.3.9 allows remote attackers to cause a denial of service (memory consumption) by triggering many strtotime function calls, which are not properly handled by the php_date_parse_tzfile cache.",
        "git_url": "https://github.com/php/php-src/commit/4c9fad8b362a7d2b6a94b4961e4b2dc037b2766d",
        "commit_title": "- Fixed bug #53502 (strtotime with timezone memory leak).",
        "commit_text": "- Fixed bug #52062 (large timestamps with DateTime::getTimestamp and   DateTime::setTimestamp). - Fixed bug #51994 (date_parse_from_format is parsing invalid date using 'yz'   format). - Fixed bug #51223 (Seg fault while creating (by unserialization)   DatePeriod).",
        "func_before": "static void do_adjust_special(timelib_time* time)\n{\n\tif (time->relative.have_special_relative) {\n\t\tswitch (time->relative.special.type) {\n\t\t\tcase TIMELIB_SPECIAL_WEEKDAY:\n\t\t\t\tdo_adjust_special_weekday(time);\n\t\t\t\tbreak;\n\t\t}\n\t}\n\tdo_normalize(time);\n\tmemset(&(time->relative.special), 0, sizeof(time->relative.special));\n}",
        "func": "static void do_adjust_special(timelib_time* time)\n{\n\tif (time->relative.have_special_relative) {\n\t\tswitch (time->relative.special.type) {\n\t\t\tcase TIMELIB_SPECIAL_WEEKDAY:\n\t\t\t\tdo_adjust_special_weekday(time);\n\t\t\t\tbreak;\n\t\t}\n\t}\n\ttimelib_do_normalize(time);\n\tmemset(&(time->relative.special), 0, sizeof(time->relative.special));\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -7,6 +7,6 @@\n \t\t\t\tbreak;\n \t\t}\n \t}\n-\tdo_normalize(time);\n+\ttimelib_do_normalize(time);\n \tmemset(&(time->relative.special), 0, sizeof(time->relative.special));\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tdo_normalize(time);"
            ],
            "added_lines": [
                "\ttimelib_do_normalize(time);"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-0789",
        "func_name": "php/php-src/do_adjust_special_early",
        "description": "Memory leak in the timezone functionality in PHP before 5.3.9 allows remote attackers to cause a denial of service (memory consumption) by triggering many strtotime function calls, which are not properly handled by the php_date_parse_tzfile cache.",
        "git_url": "https://github.com/php/php-src/commit/4c9fad8b362a7d2b6a94b4961e4b2dc037b2766d",
        "commit_title": "- Fixed bug #53502 (strtotime with timezone memory leak).",
        "commit_text": "- Fixed bug #52062 (large timestamps with DateTime::getTimestamp and   DateTime::setTimestamp). - Fixed bug #51994 (date_parse_from_format is parsing invalid date using 'yz'   format). - Fixed bug #51223 (Seg fault while creating (by unserialization)   DatePeriod).",
        "func_before": "static void do_adjust_special_early(timelib_time* time)\n{\n\tif (time->relative.have_special_relative) {\n\t\tswitch (time->relative.special.type) {\n\t\t\tcase TIMELIB_SPECIAL_DAY_OF_WEEK_IN_MONTH:\n\t\t\t\ttime->d = 1;\n\t\t\t\ttime->m += time->relative.m;\n\t\t\t\ttime->relative.m = 0;\n\t\t\t\tbreak;\n\t\t\tcase TIMELIB_SPECIAL_LAST_DAY_OF_WEEK_IN_MONTH:\n\t\t\t\ttime->d = 1;\n\t\t\t\ttime->m += time->relative.m + 1;\n\t\t\t\ttime->relative.m = 0;\n\t\t\t\tbreak;\n\t\t}\n\t}\n\tdo_normalize(time);\n}",
        "func": "static void do_adjust_special_early(timelib_time* time)\n{\n\tif (time->relative.have_special_relative) {\n\t\tswitch (time->relative.special.type) {\n\t\t\tcase TIMELIB_SPECIAL_DAY_OF_WEEK_IN_MONTH:\n\t\t\t\ttime->d = 1;\n\t\t\t\ttime->m += time->relative.m;\n\t\t\t\ttime->relative.m = 0;\n\t\t\t\tbreak;\n\t\t\tcase TIMELIB_SPECIAL_LAST_DAY_OF_WEEK_IN_MONTH:\n\t\t\t\ttime->d = 1;\n\t\t\t\ttime->m += time->relative.m + 1;\n\t\t\t\ttime->relative.m = 0;\n\t\t\t\tbreak;\n\t\t}\n\t}\n\ttimelib_do_normalize(time);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -14,5 +14,5 @@\n \t\t\t\tbreak;\n \t\t}\n \t}\n-\tdo_normalize(time);\n+\ttimelib_do_normalize(time);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tdo_normalize(time);"
            ],
            "added_lines": [
                "\ttimelib_do_normalize(time);"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-0789",
        "func_name": "php/php-src/do_adjust_relative",
        "description": "Memory leak in the timezone functionality in PHP before 5.3.9 allows remote attackers to cause a denial of service (memory consumption) by triggering many strtotime function calls, which are not properly handled by the php_date_parse_tzfile cache.",
        "git_url": "https://github.com/php/php-src/commit/4c9fad8b362a7d2b6a94b4961e4b2dc037b2766d",
        "commit_title": "- Fixed bug #53502 (strtotime with timezone memory leak).",
        "commit_text": "- Fixed bug #52062 (large timestamps with DateTime::getTimestamp and   DateTime::setTimestamp). - Fixed bug #51994 (date_parse_from_format is parsing invalid date using 'yz'   format). - Fixed bug #51223 (Seg fault while creating (by unserialization)   DatePeriod).",
        "func_before": "static void do_adjust_relative(timelib_time* time)\n{\n\tif (time->relative.have_weekday_relative) {\n\t\tdo_adjust_for_weekday(time);\n\t}\n\tdo_normalize(time);\n\n\tif (time->have_relative) {\n\t\ttime->s += time->relative.s;\n\t\ttime->i += time->relative.i;\n\t\ttime->h += time->relative.h;\n\n\t\ttime->d += time->relative.d;\n\t\ttime->m += time->relative.m;\n\t\ttime->y += time->relative.y;\n\t}\n\tswitch (time->relative.first_last_day_of) {\n\t\tcase 1: /* first */\n\t\t\ttime->d = 1;\n\t\t\tbreak;\n\t\tcase 2: /* last */\n\t\t\ttime->d = 0;\n\t\t\ttime->m++;\n\t\t\tbreak;\n\t}\n\tdo_normalize(time);\n}",
        "func": "static void do_adjust_relative(timelib_time* time)\n{\n\tif (time->relative.have_weekday_relative) {\n\t\tdo_adjust_for_weekday(time);\n\t}\n\ttimelib_do_normalize(time);\n\n\tif (time->have_relative) {\n\t\ttime->s += time->relative.s;\n\t\ttime->i += time->relative.i;\n\t\ttime->h += time->relative.h;\n\n\t\ttime->d += time->relative.d;\n\t\ttime->m += time->relative.m;\n\t\ttime->y += time->relative.y;\n\t}\n\tswitch (time->relative.first_last_day_of) {\n\t\tcase 1: /* first */\n\t\t\ttime->d = 1;\n\t\t\tbreak;\n\t\tcase 2: /* last */\n\t\t\ttime->d = 0;\n\t\t\ttime->m++;\n\t\t\tbreak;\n\t}\n\ttimelib_do_normalize(time);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,7 +3,7 @@\n \tif (time->relative.have_weekday_relative) {\n \t\tdo_adjust_for_weekday(time);\n \t}\n-\tdo_normalize(time);\n+\ttimelib_do_normalize(time);\n \n \tif (time->have_relative) {\n \t\ttime->s += time->relative.s;\n@@ -23,5 +23,5 @@\n \t\t\ttime->m++;\n \t\t\tbreak;\n \t}\n-\tdo_normalize(time);\n+\ttimelib_do_normalize(time);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tdo_normalize(time);",
                "\tdo_normalize(time);"
            ],
            "added_lines": [
                "\ttimelib_do_normalize(time);",
                "\ttimelib_do_normalize(time);"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-0789",
        "func_name": "php/php-src/date_interval_format",
        "description": "Memory leak in the timezone functionality in PHP before 5.3.9 allows remote attackers to cause a denial of service (memory consumption) by triggering many strtotime function calls, which are not properly handled by the php_date_parse_tzfile cache.",
        "git_url": "https://github.com/php/php-src/commit/4c9fad8b362a7d2b6a94b4961e4b2dc037b2766d",
        "commit_title": "- Fixed bug #53502 (strtotime with timezone memory leak).",
        "commit_text": "- Fixed bug #52062 (large timestamps with DateTime::getTimestamp and   DateTime::setTimestamp). - Fixed bug #51994 (date_parse_from_format is parsing invalid date using 'yz'   format). - Fixed bug #51223 (Seg fault while creating (by unserialization)   DatePeriod).",
        "func_before": "static char *date_interval_format(char *format, int format_len, timelib_rel_time *t)\n{\n\tsmart_str            string = {0};\n\tint                  i, length, have_format_spec = 0;\n\tchar                 buffer[33];\n\n\tif (!format_len) {\n\t\treturn estrdup(\"\");\n\t}\n\n\tfor (i = 0; i < format_len; i++) {\n\t\tif (have_format_spec) {\n\t\t\tswitch (format[i]) {\n\t\t\t\tcase 'Y': length = slprintf(buffer, 32, \"%02d\", (int) t->y); break;\n\t\t\t\tcase 'y': length = slprintf(buffer, 32, \"%d\", (int) t->y); break;\n\n\t\t\t\tcase 'M': length = slprintf(buffer, 32, \"%02d\", (int) t->m); break;\n\t\t\t\tcase 'm': length = slprintf(buffer, 32, \"%d\", (int) t->m); break;\n\n\t\t\t\tcase 'D': length = slprintf(buffer, 32, \"%02d\", (int) t->d); break;\n\t\t\t\tcase 'd': length = slprintf(buffer, 32, \"%d\", (int) t->d); break;\n\n\t\t\t\tcase 'H': length = slprintf(buffer, 32, \"%02d\", (int) t->h); break;\n\t\t\t\tcase 'h': length = slprintf(buffer, 32, \"%d\", (int) t->h); break;\n\n\t\t\t\tcase 'I': length = slprintf(buffer, 32, \"%02d\", (int) t->i); break;\n\t\t\t\tcase 'i': length = slprintf(buffer, 32, \"%d\", (int) t->i); break;\n\n\t\t\t\tcase 'S': length = slprintf(buffer, 32, \"%02d\", (int) t->s); break;\n\t\t\t\tcase 's': length = slprintf(buffer, 32, \"%d\", (int) t->s); break;\n\n\t\t\t\tcase 'a': {\n\t\t\t\t\tif ((int) t->days != -99999) {\n\t\t\t\t\t\tlength = slprintf(buffer, 32, \"%d\", (int) t->days);\n\t\t\t\t\t} else {\n\t\t\t\t\t\tlength = slprintf(buffer, 32, \"(unknown)\");\n\t\t\t\t\t}\n\t\t\t\t} break;\n\t\t\t\tcase 'r': length = slprintf(buffer, 32, \"%s\", t->invert ? \"-\" : \"\"); break;\n\t\t\t\tcase 'R': length = slprintf(buffer, 32, \"%c\", t->invert ? '-' : '+'); break;\n\n\t\t\t\tcase '%': length = slprintf(buffer, 32, \"%%\"); break;\n\t\t\t\tdefault: buffer[0] = '%'; buffer[1] = format[i]; buffer[2] = '\\0'; length = 2; break;\n\t\t\t}\n\t\t\tsmart_str_appendl(&string, buffer, length);\n\t\t\thave_format_spec = 0;\n\t\t} else {\n\t\t\tif (format[i] == '%') {\n\t\t\t\thave_format_spec = 1;\n\t\t\t} else {\n\t\t\t\tsmart_str_appendc(&string, format[i]);\n\t\t\t}\n\t\t}\n\t}\n\n\tsmart_str_0(&string);\n\n\treturn string.c;\n}",
        "func": "static char *date_interval_format(char *format, int format_len, timelib_rel_time *t)\n{\n\tsmart_str            string = {0};\n\tint                  i, length, have_format_spec = 0;\n\tchar                 buffer[33];\n\n\tif (!format_len) {\n\t\treturn estrdup(\"\");\n\t}\n\n\tfor (i = 0; i < format_len; i++) {\n\t\tif (have_format_spec) {\n\t\t\tswitch (format[i]) {\n\t\t\t\tcase 'Y': length = slprintf(buffer, 32, \"%02d\", (int) t->y); break;\n\t\t\t\tcase 'y': length = slprintf(buffer, 32, \"%d\", (int) t->y); break;\n\n\t\t\t\tcase 'M': length = slprintf(buffer, 32, \"%02d\", (int) t->m); break;\n\t\t\t\tcase 'm': length = slprintf(buffer, 32, \"%d\", (int) t->m); break;\n\n\t\t\t\tcase 'D': length = slprintf(buffer, 32, \"%02d\", (int) t->d); break;\n\t\t\t\tcase 'd': length = slprintf(buffer, 32, \"%d\", (int) t->d); break;\n\n\t\t\t\tcase 'H': length = slprintf(buffer, 32, \"%02d\", (int) t->h); break;\n\t\t\t\tcase 'h': length = slprintf(buffer, 32, \"%d\", (int) t->h); break;\n\n\t\t\t\tcase 'I': length = slprintf(buffer, 32, \"%02d\", (int) t->i); break;\n\t\t\t\tcase 'i': length = slprintf(buffer, 32, \"%d\", (int) t->i); break;\n\n\t\t\t\tcase 'S': length = slprintf(buffer, 32, \"%02ld\", (long) t->s); break;\n\t\t\t\tcase 's': length = slprintf(buffer, 32, \"%ld\", (long) t->s); break;\n\n\t\t\t\tcase 'a': {\n\t\t\t\t\tif ((int) t->days != -99999) {\n\t\t\t\t\t\tlength = slprintf(buffer, 32, \"%d\", (int) t->days);\n\t\t\t\t\t} else {\n\t\t\t\t\t\tlength = slprintf(buffer, 32, \"(unknown)\");\n\t\t\t\t\t}\n\t\t\t\t} break;\n\t\t\t\tcase 'r': length = slprintf(buffer, 32, \"%s\", t->invert ? \"-\" : \"\"); break;\n\t\t\t\tcase 'R': length = slprintf(buffer, 32, \"%c\", t->invert ? '-' : '+'); break;\n\n\t\t\t\tcase '%': length = slprintf(buffer, 32, \"%%\"); break;\n\t\t\t\tdefault: buffer[0] = '%'; buffer[1] = format[i]; buffer[2] = '\\0'; length = 2; break;\n\t\t\t}\n\t\t\tsmart_str_appendl(&string, buffer, length);\n\t\t\thave_format_spec = 0;\n\t\t} else {\n\t\t\tif (format[i] == '%') {\n\t\t\t\thave_format_spec = 1;\n\t\t\t} else {\n\t\t\t\tsmart_str_appendc(&string, format[i]);\n\t\t\t}\n\t\t}\n\t}\n\n\tsmart_str_0(&string);\n\n\treturn string.c;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -26,8 +26,8 @@\n \t\t\t\tcase 'I': length = slprintf(buffer, 32, \"%02d\", (int) t->i); break;\n \t\t\t\tcase 'i': length = slprintf(buffer, 32, \"%d\", (int) t->i); break;\n \n-\t\t\t\tcase 'S': length = slprintf(buffer, 32, \"%02d\", (int) t->s); break;\n-\t\t\t\tcase 's': length = slprintf(buffer, 32, \"%d\", (int) t->s); break;\n+\t\t\t\tcase 'S': length = slprintf(buffer, 32, \"%02ld\", (long) t->s); break;\n+\t\t\t\tcase 's': length = slprintf(buffer, 32, \"%ld\", (long) t->s); break;\n \n \t\t\t\tcase 'a': {\n \t\t\t\t\tif ((int) t->days != -99999) {",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\t\tcase 'S': length = slprintf(buffer, 32, \"%02d\", (int) t->s); break;",
                "\t\t\t\tcase 's': length = slprintf(buffer, 32, \"%d\", (int) t->s); break;"
            ],
            "added_lines": [
                "\t\t\t\tcase 'S': length = slprintf(buffer, 32, \"%02ld\", (long) t->s); break;",
                "\t\t\t\tcase 's': length = slprintf(buffer, 32, \"%ld\", (long) t->s); break;"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-0789",
        "func_name": "php/php-src/php_parse_date",
        "description": "Memory leak in the timezone functionality in PHP before 5.3.9 allows remote attackers to cause a denial of service (memory consumption) by triggering many strtotime function calls, which are not properly handled by the php_date_parse_tzfile cache.",
        "git_url": "https://github.com/php/php-src/commit/4c9fad8b362a7d2b6a94b4961e4b2dc037b2766d",
        "commit_title": "- Fixed bug #53502 (strtotime with timezone memory leak).",
        "commit_text": "- Fixed bug #52062 (large timestamps with DateTime::getTimestamp and   DateTime::setTimestamp). - Fixed bug #51994 (date_parse_from_format is parsing invalid date using 'yz'   format). - Fixed bug #51223 (Seg fault while creating (by unserialization)   DatePeriod).",
        "func_before": "long php_parse_date(char *string, signed long *now)\n{\n\ttimelib_time *parsed_time;\n\ttimelib_error_container *error = NULL;\n\tint           error2;\n\tsigned long   retval;\n\n\tparsed_time = timelib_strtotime(string, strlen(string), &error, DATE_TIMEZONEDB);\n\tif (error->error_count) {\n\t\ttimelib_error_container_dtor(error);\n\t\treturn -1;\n\t}\n\ttimelib_error_container_dtor(error);\n\ttimelib_update_ts(parsed_time, NULL);\n\tretval = timelib_date_to_int(parsed_time, &error2);\n\ttimelib_time_dtor(parsed_time);\n\tif (error2) {\n\t\treturn -1;\n\t}\n\treturn retval;\n}",
        "func": "long php_parse_date(char *string, signed long *now)\n{\n\ttimelib_time *parsed_time;\n\ttimelib_error_container *error = NULL;\n\tint           error2;\n\tsigned long   retval;\n\n\tparsed_time = timelib_strtotime(string, strlen(string), &error, DATE_TIMEZONEDB, php_date_parse_tzfile_wrapper);\n\tif (error->error_count) {\n\t\ttimelib_error_container_dtor(error);\n\t\treturn -1;\n\t}\n\ttimelib_error_container_dtor(error);\n\ttimelib_update_ts(parsed_time, NULL);\n\tretval = timelib_date_to_int(parsed_time, &error2);\n\ttimelib_time_dtor(parsed_time);\n\tif (error2) {\n\t\treturn -1;\n\t}\n\treturn retval;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,7 +5,7 @@\n \tint           error2;\n \tsigned long   retval;\n \n-\tparsed_time = timelib_strtotime(string, strlen(string), &error, DATE_TIMEZONEDB);\n+\tparsed_time = timelib_strtotime(string, strlen(string), &error, DATE_TIMEZONEDB, php_date_parse_tzfile_wrapper);\n \tif (error->error_count) {\n \t\ttimelib_error_container_dtor(error);\n \t\treturn -1;",
        "diff_line_info": {
            "deleted_lines": [
                "\tparsed_time = timelib_strtotime(string, strlen(string), &error, DATE_TIMEZONEDB);"
            ],
            "added_lines": [
                "\tparsed_time = timelib_strtotime(string, strlen(string), &error, DATE_TIMEZONEDB, php_date_parse_tzfile_wrapper);"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-0789",
        "func_name": "php/php-src/php_date_initialize",
        "description": "Memory leak in the timezone functionality in PHP before 5.3.9 allows remote attackers to cause a denial of service (memory consumption) by triggering many strtotime function calls, which are not properly handled by the php_date_parse_tzfile cache.",
        "git_url": "https://github.com/php/php-src/commit/4c9fad8b362a7d2b6a94b4961e4b2dc037b2766d",
        "commit_title": "- Fixed bug #53502 (strtotime with timezone memory leak).",
        "commit_text": "- Fixed bug #52062 (large timestamps with DateTime::getTimestamp and   DateTime::setTimestamp). - Fixed bug #51994 (date_parse_from_format is parsing invalid date using 'yz'   format). - Fixed bug #51223 (Seg fault while creating (by unserialization)   DatePeriod).",
        "func_before": "PHPAPI int php_date_initialize(php_date_obj *dateobj, /*const*/ char *time_str, int time_str_len, char *format, zval *timezone_object, int ctor TSRMLS_DC)\n{\n\ttimelib_time   *now;\n\ttimelib_tzinfo *tzi = NULL;\n\ttimelib_error_container *err = NULL;\n\tint type = TIMELIB_ZONETYPE_ID, new_dst;\n\tchar *new_abbr;\n\ttimelib_sll     new_offset;\n\t\n\tif (dateobj->time) {\n\t\ttimelib_time_dtor(dateobj->time);\n\t}\n\tif (format) {\n\t\tdateobj->time = timelib_parse_from_format(format, time_str_len ? time_str : \"\", time_str_len ? time_str_len : 0, &err, DATE_TIMEZONEDB);\n\t} else {\n\t\tdateobj->time = timelib_strtotime(time_str_len ? time_str : \"now\", time_str_len ? time_str_len : sizeof(\"now\") -1, &err, DATE_TIMEZONEDB);\n\t}\n\n\t/* update last errors and warnings */\n\tupdate_errors_warnings(err TSRMLS_CC);\n\n\n\tif (ctor && err && err->error_count) {\n\t\t/* spit out the first library error message, at least */\n\t\tphp_error_docref(NULL TSRMLS_CC, E_WARNING, \"Failed to parse time string (%s) at position %d (%c): %s\", time_str,\n\t\t\terr->error_messages[0].position, err->error_messages[0].character, err->error_messages[0].message);\n\t}\n\tif (err && err->error_count) {\n\t\treturn 0;\n\t}\n\n\tif (timezone_object) {\n\t\tphp_timezone_obj *tzobj;\n\n\t\ttzobj = (php_timezone_obj *) zend_object_store_get_object(timezone_object TSRMLS_CC);\n\t\tswitch (tzobj->type) {\n\t\t\tcase TIMELIB_ZONETYPE_ID:\n\t\t\t\ttzi = tzobj->tzi.tz;\n\t\t\t\tbreak;\n\t\t\tcase TIMELIB_ZONETYPE_OFFSET:\n\t\t\t\tnew_offset = tzobj->tzi.utc_offset;\n\t\t\t\tbreak;\n\t\t\tcase TIMELIB_ZONETYPE_ABBR:\n\t\t\t\tnew_offset = tzobj->tzi.z.utc_offset;\n\t\t\t\tnew_dst    = tzobj->tzi.z.dst;\n\t\t\t\tnew_abbr   = strdup(tzobj->tzi.z.abbr);\n\t\t\t\tbreak;\n\t\t}\n\t\ttype = tzobj->type;\n\t} else if (dateobj->time->tz_info) {\n\t\ttzi = dateobj->time->tz_info;\n\t} else {\n\t\ttzi = get_timezone_info(TSRMLS_C);\n\t}\n\n\tnow = timelib_time_ctor();\n\tnow->zone_type = type;\n\tswitch (type) {\n\t\tcase TIMELIB_ZONETYPE_ID:\n\t\t\tnow->tz_info = tzi;\n\t\t\tbreak;\n\t\tcase TIMELIB_ZONETYPE_OFFSET:\n\t\t\tnow->z = new_offset;\n\t\t\tbreak;\n\t\tcase TIMELIB_ZONETYPE_ABBR:\n\t\t\tnow->z = new_offset;\n\t\t\tnow->dst = new_dst;\n\t\t\tnow->tz_abbr = new_abbr;\n\t\t\tbreak;\n\t}\n\ttimelib_unixtime2local(now, (timelib_sll) time(NULL));\n\n\ttimelib_fill_holes(dateobj->time, now, TIMELIB_NO_CLONE);\n\ttimelib_update_ts(dateobj->time, tzi);\n\n\tdateobj->time->have_relative = 0;\n\n\ttimelib_time_dtor(now);\n\n\treturn 1;\n}",
        "func": "PHPAPI int php_date_initialize(php_date_obj *dateobj, /*const*/ char *time_str, int time_str_len, char *format, zval *timezone_object, int ctor TSRMLS_DC)\n{\n\ttimelib_time   *now;\n\ttimelib_tzinfo *tzi = NULL;\n\ttimelib_error_container *err = NULL;\n\tint type = TIMELIB_ZONETYPE_ID, new_dst;\n\tchar *new_abbr;\n\ttimelib_sll     new_offset;\n\t\n\tif (dateobj->time) {\n\t\ttimelib_time_dtor(dateobj->time);\n\t}\n\tif (format) {\n\t\tdateobj->time = timelib_parse_from_format(format, time_str_len ? time_str : \"\", time_str_len ? time_str_len : 0, &err, DATE_TIMEZONEDB, php_date_parse_tzfile_wrapper);\n\t} else {\n\t\tdateobj->time = timelib_strtotime(time_str_len ? time_str : \"now\", time_str_len ? time_str_len : sizeof(\"now\") -1, &err, DATE_TIMEZONEDB, php_date_parse_tzfile_wrapper);\n\t}\n\n\t/* update last errors and warnings */\n\tupdate_errors_warnings(err TSRMLS_CC);\n\n\n\tif (ctor && err && err->error_count) {\n\t\t/* spit out the first library error message, at least */\n\t\tphp_error_docref(NULL TSRMLS_CC, E_WARNING, \"Failed to parse time string (%s) at position %d (%c): %s\", time_str,\n\t\t\terr->error_messages[0].position, err->error_messages[0].character, err->error_messages[0].message);\n\t}\n\tif (err && err->error_count) {\n\t\treturn 0;\n\t}\n\n\tif (timezone_object) {\n\t\tphp_timezone_obj *tzobj;\n\n\t\ttzobj = (php_timezone_obj *) zend_object_store_get_object(timezone_object TSRMLS_CC);\n\t\tswitch (tzobj->type) {\n\t\t\tcase TIMELIB_ZONETYPE_ID:\n\t\t\t\ttzi = tzobj->tzi.tz;\n\t\t\t\tbreak;\n\t\t\tcase TIMELIB_ZONETYPE_OFFSET:\n\t\t\t\tnew_offset = tzobj->tzi.utc_offset;\n\t\t\t\tbreak;\n\t\t\tcase TIMELIB_ZONETYPE_ABBR:\n\t\t\t\tnew_offset = tzobj->tzi.z.utc_offset;\n\t\t\t\tnew_dst    = tzobj->tzi.z.dst;\n\t\t\t\tnew_abbr   = strdup(tzobj->tzi.z.abbr);\n\t\t\t\tbreak;\n\t\t}\n\t\ttype = tzobj->type;\n\t} else if (dateobj->time->tz_info) {\n\t\ttzi = dateobj->time->tz_info;\n\t} else {\n\t\ttzi = get_timezone_info(TSRMLS_C);\n\t}\n\n\tnow = timelib_time_ctor();\n\tnow->zone_type = type;\n\tswitch (type) {\n\t\tcase TIMELIB_ZONETYPE_ID:\n\t\t\tnow->tz_info = tzi;\n\t\t\tbreak;\n\t\tcase TIMELIB_ZONETYPE_OFFSET:\n\t\t\tnow->z = new_offset;\n\t\t\tbreak;\n\t\tcase TIMELIB_ZONETYPE_ABBR:\n\t\t\tnow->z = new_offset;\n\t\t\tnow->dst = new_dst;\n\t\t\tnow->tz_abbr = new_abbr;\n\t\t\tbreak;\n\t}\n\ttimelib_unixtime2local(now, (timelib_sll) time(NULL));\n\n\ttimelib_fill_holes(dateobj->time, now, TIMELIB_NO_CLONE);\n\ttimelib_update_ts(dateobj->time, tzi);\n\n\tdateobj->time->have_relative = 0;\n\n\ttimelib_time_dtor(now);\n\n\treturn 1;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -11,9 +11,9 @@\n \t\ttimelib_time_dtor(dateobj->time);\n \t}\n \tif (format) {\n-\t\tdateobj->time = timelib_parse_from_format(format, time_str_len ? time_str : \"\", time_str_len ? time_str_len : 0, &err, DATE_TIMEZONEDB);\n+\t\tdateobj->time = timelib_parse_from_format(format, time_str_len ? time_str : \"\", time_str_len ? time_str_len : 0, &err, DATE_TIMEZONEDB, php_date_parse_tzfile_wrapper);\n \t} else {\n-\t\tdateobj->time = timelib_strtotime(time_str_len ? time_str : \"now\", time_str_len ? time_str_len : sizeof(\"now\") -1, &err, DATE_TIMEZONEDB);\n+\t\tdateobj->time = timelib_strtotime(time_str_len ? time_str : \"now\", time_str_len ? time_str_len : sizeof(\"now\") -1, &err, DATE_TIMEZONEDB, php_date_parse_tzfile_wrapper);\n \t}\n \n \t/* update last errors and warnings */",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tdateobj->time = timelib_parse_from_format(format, time_str_len ? time_str : \"\", time_str_len ? time_str_len : 0, &err, DATE_TIMEZONEDB);",
                "\t\tdateobj->time = timelib_strtotime(time_str_len ? time_str : \"now\", time_str_len ? time_str_len : sizeof(\"now\") -1, &err, DATE_TIMEZONEDB);"
            ],
            "added_lines": [
                "\t\tdateobj->time = timelib_parse_from_format(format, time_str_len ? time_str : \"\", time_str_len ? time_str_len : 0, &err, DATE_TIMEZONEDB, php_date_parse_tzfile_wrapper);",
                "\t\tdateobj->time = timelib_strtotime(time_str_len ? time_str : \"now\", time_str_len ? time_str_len : sizeof(\"now\") -1, &err, DATE_TIMEZONEDB, php_date_parse_tzfile_wrapper);"
            ]
        }
    },
    {
        "cve_id": "CVE-2011-4326",
        "func_name": "torvalds/linux/udp6_ufo_fragment",
        "description": "The udp6_ufo_fragment function in net/ipv6/udp.c in the Linux kernel before 2.6.39, when a certain UDP Fragmentation Offload (UFO) configuration is enabled, allows remote attackers to cause a denial of service (system crash) by sending fragmented IPv6 UDP packets to a bridge device.",
        "git_url": "https://github.com/torvalds/linux/commit/a9cf73ea7ff78f52662c8658d93c226effbbedde",
        "commit_title": "ipv6: udp: fix the wrong headroom check",
        "commit_text": " At this point, skb->data points to skb_transport_header. So, headroom check is wrong.  For some case:bridge(UFO is on) + eth device(UFO is off), there is no enough headroom for IPv6 frag head. But headroom check is always false.  This will bring about data be moved to there prior to skb->head, when adding IPv6 frag header to skb. ",
        "func_before": "static struct sk_buff *udp6_ufo_fragment(struct sk_buff *skb, u32 features)\n{\n\tstruct sk_buff *segs = ERR_PTR(-EINVAL);\n\tunsigned int mss;\n\tunsigned int unfrag_ip6hlen, unfrag_len;\n\tstruct frag_hdr *fptr;\n\tu8 *mac_start, *prevhdr;\n\tu8 nexthdr;\n\tu8 frag_hdr_sz = sizeof(struct frag_hdr);\n\tint offset;\n\t__wsum csum;\n\n\tmss = skb_shinfo(skb)->gso_size;\n\tif (unlikely(skb->len <= mss))\n\t\tgoto out;\n\n\tif (skb_gso_ok(skb, features | NETIF_F_GSO_ROBUST)) {\n\t\t/* Packet is from an untrusted source, reset gso_segs. */\n\t\tint type = skb_shinfo(skb)->gso_type;\n\n\t\tif (unlikely(type & ~(SKB_GSO_UDP | SKB_GSO_DODGY) ||\n\t\t\t     !(type & (SKB_GSO_UDP))))\n\t\t\tgoto out;\n\n\t\tskb_shinfo(skb)->gso_segs = DIV_ROUND_UP(skb->len, mss);\n\n\t\tsegs = NULL;\n\t\tgoto out;\n\t}\n\n\t/* Do software UFO. Complete and fill in the UDP checksum as HW cannot\n\t * do checksum of UDP packets sent as multiple IP fragments.\n\t */\n\toffset = skb->csum_start - skb_headroom(skb);\n\tcsum = skb_checksum(skb, offset, skb->len- offset, 0);\n\toffset += skb->csum_offset;\n\t*(__sum16 *)(skb->data + offset) = csum_fold(csum);\n\tskb->ip_summed = CHECKSUM_NONE;\n\n\t/* Check if there is enough headroom to insert fragment header. */\n\tif ((skb_headroom(skb) < frag_hdr_sz) &&\n\t    pskb_expand_head(skb, frag_hdr_sz, 0, GFP_ATOMIC))\n\t\tgoto out;\n\n\t/* Find the unfragmentable header and shift it left by frag_hdr_sz\n\t * bytes to insert fragment header.\n\t */\n\tunfrag_ip6hlen = ip6_find_1stfragopt(skb, &prevhdr);\n\tnexthdr = *prevhdr;\n\t*prevhdr = NEXTHDR_FRAGMENT;\n\tunfrag_len = skb_network_header(skb) - skb_mac_header(skb) +\n\t\t     unfrag_ip6hlen;\n\tmac_start = skb_mac_header(skb);\n\tmemmove(mac_start-frag_hdr_sz, mac_start, unfrag_len);\n\n\tskb->mac_header -= frag_hdr_sz;\n\tskb->network_header -= frag_hdr_sz;\n\n\tfptr = (struct frag_hdr *)(skb_network_header(skb) + unfrag_ip6hlen);\n\tfptr->nexthdr = nexthdr;\n\tfptr->reserved = 0;\n\tipv6_select_ident(fptr);\n\n\t/* Fragment the skb. ipv6 header and the remaining fields of the\n\t * fragment header are updated in ipv6_gso_segment()\n\t */\n\tsegs = skb_segment(skb, features);\n\nout:\n\treturn segs;\n}",
        "func": "static struct sk_buff *udp6_ufo_fragment(struct sk_buff *skb, u32 features)\n{\n\tstruct sk_buff *segs = ERR_PTR(-EINVAL);\n\tunsigned int mss;\n\tunsigned int unfrag_ip6hlen, unfrag_len;\n\tstruct frag_hdr *fptr;\n\tu8 *mac_start, *prevhdr;\n\tu8 nexthdr;\n\tu8 frag_hdr_sz = sizeof(struct frag_hdr);\n\tint offset;\n\t__wsum csum;\n\n\tmss = skb_shinfo(skb)->gso_size;\n\tif (unlikely(skb->len <= mss))\n\t\tgoto out;\n\n\tif (skb_gso_ok(skb, features | NETIF_F_GSO_ROBUST)) {\n\t\t/* Packet is from an untrusted source, reset gso_segs. */\n\t\tint type = skb_shinfo(skb)->gso_type;\n\n\t\tif (unlikely(type & ~(SKB_GSO_UDP | SKB_GSO_DODGY) ||\n\t\t\t     !(type & (SKB_GSO_UDP))))\n\t\t\tgoto out;\n\n\t\tskb_shinfo(skb)->gso_segs = DIV_ROUND_UP(skb->len, mss);\n\n\t\tsegs = NULL;\n\t\tgoto out;\n\t}\n\n\t/* Do software UFO. Complete and fill in the UDP checksum as HW cannot\n\t * do checksum of UDP packets sent as multiple IP fragments.\n\t */\n\toffset = skb->csum_start - skb_headroom(skb);\n\tcsum = skb_checksum(skb, offset, skb->len- offset, 0);\n\toffset += skb->csum_offset;\n\t*(__sum16 *)(skb->data + offset) = csum_fold(csum);\n\tskb->ip_summed = CHECKSUM_NONE;\n\n\t/* Check if there is enough headroom to insert fragment header. */\n\tif ((skb_mac_header(skb) < skb->head + frag_hdr_sz) &&\n\t    pskb_expand_head(skb, frag_hdr_sz, 0, GFP_ATOMIC))\n\t\tgoto out;\n\n\t/* Find the unfragmentable header and shift it left by frag_hdr_sz\n\t * bytes to insert fragment header.\n\t */\n\tunfrag_ip6hlen = ip6_find_1stfragopt(skb, &prevhdr);\n\tnexthdr = *prevhdr;\n\t*prevhdr = NEXTHDR_FRAGMENT;\n\tunfrag_len = skb_network_header(skb) - skb_mac_header(skb) +\n\t\t     unfrag_ip6hlen;\n\tmac_start = skb_mac_header(skb);\n\tmemmove(mac_start-frag_hdr_sz, mac_start, unfrag_len);\n\n\tskb->mac_header -= frag_hdr_sz;\n\tskb->network_header -= frag_hdr_sz;\n\n\tfptr = (struct frag_hdr *)(skb_network_header(skb) + unfrag_ip6hlen);\n\tfptr->nexthdr = nexthdr;\n\tfptr->reserved = 0;\n\tipv6_select_ident(fptr);\n\n\t/* Fragment the skb. ipv6 header and the remaining fields of the\n\t * fragment header are updated in ipv6_gso_segment()\n\t */\n\tsegs = skb_segment(skb, features);\n\nout:\n\treturn segs;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -38,7 +38,7 @@\n \tskb->ip_summed = CHECKSUM_NONE;\n \n \t/* Check if there is enough headroom to insert fragment header. */\n-\tif ((skb_headroom(skb) < frag_hdr_sz) &&\n+\tif ((skb_mac_header(skb) < skb->head + frag_hdr_sz) &&\n \t    pskb_expand_head(skb, frag_hdr_sz, 0, GFP_ATOMIC))\n \t\tgoto out;\n ",
        "diff_line_info": {
            "deleted_lines": [
                "\tif ((skb_headroom(skb) < frag_hdr_sz) &&"
            ],
            "added_lines": [
                "\tif ((skb_mac_header(skb) < skb->head + frag_hdr_sz) &&"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-1601",
        "func_name": "torvalds/linux/kvm_vm_ioctl_create_vcpu",
        "description": "The KVM implementation in the Linux kernel before 3.3.6 allows host OS users to cause a denial of service (NULL pointer dereference and host OS crash) by making a KVM_CREATE_IRQCHIP ioctl call after a virtual CPU already exists.",
        "git_url": "https://github.com/torvalds/linux/commit/9c895160d25a76c21b65bad141b08e8d4f99afef",
        "commit_title": "KVM: Ensure all vcpus are consistent with in-kernel irqchip settings",
        "commit_text": " (cherry picked from commit 3e515705a1f46beb1c942bb8043c16f8ac7b1e9e)  If some vcpus are created before KVM_CREATE_IRQCHIP, then irqchip_in_kernel() and vcpu->arch.apic will be inconsistent, leading to potential NULL pointer dereferences.  Fix by: - ensuring that no vcpus are installed when KVM_CREATE_IRQCHIP is called - ensuring that a vcpu has an apic if it is installed after KVM_CREATE_IRQCHIP  This is somewhat long winded because vcpu->arch.apic is created without kvm->lock held.  Based on earlier patch by Michael Ellerman. ",
        "func_before": "static int kvm_vm_ioctl_create_vcpu(struct kvm *kvm, u32 id)\n{\n\tint r;\n\tstruct kvm_vcpu *vcpu, *v;\n\n\tvcpu = kvm_arch_vcpu_create(kvm, id);\n\tif (IS_ERR(vcpu))\n\t\treturn PTR_ERR(vcpu);\n\n\tpreempt_notifier_init(&vcpu->preempt_notifier, &kvm_preempt_ops);\n\n\tr = kvm_arch_vcpu_setup(vcpu);\n\tif (r)\n\t\tgoto vcpu_destroy;\n\n\tmutex_lock(&kvm->lock);\n\tif (atomic_read(&kvm->online_vcpus) == KVM_MAX_VCPUS) {\n\t\tr = -EINVAL;\n\t\tgoto unlock_vcpu_destroy;\n\t}\n\n\tkvm_for_each_vcpu(r, v, kvm)\n\t\tif (v->vcpu_id == id) {\n\t\t\tr = -EEXIST;\n\t\t\tgoto unlock_vcpu_destroy;\n\t\t}\n\n\tBUG_ON(kvm->vcpus[atomic_read(&kvm->online_vcpus)]);\n\n\t/* Now it's all set up, let userspace reach it */\n\tkvm_get_kvm(kvm);\n\tr = create_vcpu_fd(vcpu);\n\tif (r < 0) {\n\t\tkvm_put_kvm(kvm);\n\t\tgoto unlock_vcpu_destroy;\n\t}\n\n\tkvm->vcpus[atomic_read(&kvm->online_vcpus)] = vcpu;\n\tsmp_wmb();\n\tatomic_inc(&kvm->online_vcpus);\n\n\tmutex_unlock(&kvm->lock);\n\treturn r;\n\nunlock_vcpu_destroy:\n\tmutex_unlock(&kvm->lock);\nvcpu_destroy:\n\tkvm_arch_vcpu_destroy(vcpu);\n\treturn r;\n}",
        "func": "static int kvm_vm_ioctl_create_vcpu(struct kvm *kvm, u32 id)\n{\n\tint r;\n\tstruct kvm_vcpu *vcpu, *v;\n\n\tvcpu = kvm_arch_vcpu_create(kvm, id);\n\tif (IS_ERR(vcpu))\n\t\treturn PTR_ERR(vcpu);\n\n\tpreempt_notifier_init(&vcpu->preempt_notifier, &kvm_preempt_ops);\n\n\tr = kvm_arch_vcpu_setup(vcpu);\n\tif (r)\n\t\tgoto vcpu_destroy;\n\n\tmutex_lock(&kvm->lock);\n\tif (!kvm_vcpu_compatible(vcpu)) {\n\t\tr = -EINVAL;\n\t\tgoto unlock_vcpu_destroy;\n\t}\n\tif (atomic_read(&kvm->online_vcpus) == KVM_MAX_VCPUS) {\n\t\tr = -EINVAL;\n\t\tgoto unlock_vcpu_destroy;\n\t}\n\n\tkvm_for_each_vcpu(r, v, kvm)\n\t\tif (v->vcpu_id == id) {\n\t\t\tr = -EEXIST;\n\t\t\tgoto unlock_vcpu_destroy;\n\t\t}\n\n\tBUG_ON(kvm->vcpus[atomic_read(&kvm->online_vcpus)]);\n\n\t/* Now it's all set up, let userspace reach it */\n\tkvm_get_kvm(kvm);\n\tr = create_vcpu_fd(vcpu);\n\tif (r < 0) {\n\t\tkvm_put_kvm(kvm);\n\t\tgoto unlock_vcpu_destroy;\n\t}\n\n\tkvm->vcpus[atomic_read(&kvm->online_vcpus)] = vcpu;\n\tsmp_wmb();\n\tatomic_inc(&kvm->online_vcpus);\n\n\tmutex_unlock(&kvm->lock);\n\treturn r;\n\nunlock_vcpu_destroy:\n\tmutex_unlock(&kvm->lock);\nvcpu_destroy:\n\tkvm_arch_vcpu_destroy(vcpu);\n\treturn r;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -14,6 +14,10 @@\n \t\tgoto vcpu_destroy;\n \n \tmutex_lock(&kvm->lock);\n+\tif (!kvm_vcpu_compatible(vcpu)) {\n+\t\tr = -EINVAL;\n+\t\tgoto unlock_vcpu_destroy;\n+\t}\n \tif (atomic_read(&kvm->online_vcpus) == KVM_MAX_VCPUS) {\n \t\tr = -EINVAL;\n \t\tgoto unlock_vcpu_destroy;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tif (!kvm_vcpu_compatible(vcpu)) {",
                "\t\tr = -EINVAL;",
                "\t\tgoto unlock_vcpu_destroy;",
                "\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-1601",
        "func_name": "torvalds/linux/kvm_arch_vm_ioctl",
        "description": "The KVM implementation in the Linux kernel before 3.3.6 allows host OS users to cause a denial of service (NULL pointer dereference and host OS crash) by making a KVM_CREATE_IRQCHIP ioctl call after a virtual CPU already exists.",
        "git_url": "https://github.com/torvalds/linux/commit/9c895160d25a76c21b65bad141b08e8d4f99afef",
        "commit_title": "KVM: Ensure all vcpus are consistent with in-kernel irqchip settings",
        "commit_text": " (cherry picked from commit 3e515705a1f46beb1c942bb8043c16f8ac7b1e9e)  If some vcpus are created before KVM_CREATE_IRQCHIP, then irqchip_in_kernel() and vcpu->arch.apic will be inconsistent, leading to potential NULL pointer dereferences.  Fix by: - ensuring that no vcpus are installed when KVM_CREATE_IRQCHIP is called - ensuring that a vcpu has an apic if it is installed after KVM_CREATE_IRQCHIP  This is somewhat long winded because vcpu->arch.apic is created without kvm->lock held.  Based on earlier patch by Michael Ellerman. ",
        "func_before": "long kvm_arch_vm_ioctl(struct file *filp,\n\t\t       unsigned int ioctl, unsigned long arg)\n{\n\tstruct kvm *kvm = filp->private_data;\n\tvoid __user *argp = (void __user *)arg;\n\tint r = -ENOTTY;\n\t/*\n\t * This union makes it completely explicit to gcc-3.x\n\t * that these two variables' stack usage should be\n\t * combined, not added together.\n\t */\n\tunion {\n\t\tstruct kvm_pit_state ps;\n\t\tstruct kvm_pit_state2 ps2;\n\t\tstruct kvm_pit_config pit_config;\n\t} u;\n\n\tswitch (ioctl) {\n\tcase KVM_SET_TSS_ADDR:\n\t\tr = kvm_vm_ioctl_set_tss_addr(kvm, arg);\n\t\tif (r < 0)\n\t\t\tgoto out;\n\t\tbreak;\n\tcase KVM_SET_IDENTITY_MAP_ADDR: {\n\t\tu64 ident_addr;\n\n\t\tr = -EFAULT;\n\t\tif (copy_from_user(&ident_addr, argp, sizeof ident_addr))\n\t\t\tgoto out;\n\t\tr = kvm_vm_ioctl_set_identity_map_addr(kvm, ident_addr);\n\t\tif (r < 0)\n\t\t\tgoto out;\n\t\tbreak;\n\t}\n\tcase KVM_SET_NR_MMU_PAGES:\n\t\tr = kvm_vm_ioctl_set_nr_mmu_pages(kvm, arg);\n\t\tif (r)\n\t\t\tgoto out;\n\t\tbreak;\n\tcase KVM_GET_NR_MMU_PAGES:\n\t\tr = kvm_vm_ioctl_get_nr_mmu_pages(kvm);\n\t\tbreak;\n\tcase KVM_CREATE_IRQCHIP: {\n\t\tstruct kvm_pic *vpic;\n\n\t\tmutex_lock(&kvm->lock);\n\t\tr = -EEXIST;\n\t\tif (kvm->arch.vpic)\n\t\t\tgoto create_irqchip_unlock;\n\t\tr = -ENOMEM;\n\t\tvpic = kvm_create_pic(kvm);\n\t\tif (vpic) {\n\t\t\tr = kvm_ioapic_init(kvm);\n\t\t\tif (r) {\n\t\t\t\tmutex_lock(&kvm->slots_lock);\n\t\t\t\tkvm_io_bus_unregister_dev(kvm, KVM_PIO_BUS,\n\t\t\t\t\t\t\t  &vpic->dev_master);\n\t\t\t\tkvm_io_bus_unregister_dev(kvm, KVM_PIO_BUS,\n\t\t\t\t\t\t\t  &vpic->dev_slave);\n\t\t\t\tkvm_io_bus_unregister_dev(kvm, KVM_PIO_BUS,\n\t\t\t\t\t\t\t  &vpic->dev_eclr);\n\t\t\t\tmutex_unlock(&kvm->slots_lock);\n\t\t\t\tkfree(vpic);\n\t\t\t\tgoto create_irqchip_unlock;\n\t\t\t}\n\t\t} else\n\t\t\tgoto create_irqchip_unlock;\n\t\tsmp_wmb();\n\t\tkvm->arch.vpic = vpic;\n\t\tsmp_wmb();\n\t\tr = kvm_setup_default_irq_routing(kvm);\n\t\tif (r) {\n\t\t\tmutex_lock(&kvm->slots_lock);\n\t\t\tmutex_lock(&kvm->irq_lock);\n\t\t\tkvm_ioapic_destroy(kvm);\n\t\t\tkvm_destroy_pic(kvm);\n\t\t\tmutex_unlock(&kvm->irq_lock);\n\t\t\tmutex_unlock(&kvm->slots_lock);\n\t\t}\n\tcreate_irqchip_unlock:\n\t\tmutex_unlock(&kvm->lock);\n\t\tbreak;\n\t}\n\tcase KVM_CREATE_PIT:\n\t\tu.pit_config.flags = KVM_PIT_SPEAKER_DUMMY;\n\t\tgoto create_pit;\n\tcase KVM_CREATE_PIT2:\n\t\tr = -EFAULT;\n\t\tif (copy_from_user(&u.pit_config, argp,\n\t\t\t\t   sizeof(struct kvm_pit_config)))\n\t\t\tgoto out;\n\tcreate_pit:\n\t\tmutex_lock(&kvm->slots_lock);\n\t\tr = -EEXIST;\n\t\tif (kvm->arch.vpit)\n\t\t\tgoto create_pit_unlock;\n\t\tr = -ENOMEM;\n\t\tkvm->arch.vpit = kvm_create_pit(kvm, u.pit_config.flags);\n\t\tif (kvm->arch.vpit)\n\t\t\tr = 0;\n\tcreate_pit_unlock:\n\t\tmutex_unlock(&kvm->slots_lock);\n\t\tbreak;\n\tcase KVM_IRQ_LINE_STATUS:\n\tcase KVM_IRQ_LINE: {\n\t\tstruct kvm_irq_level irq_event;\n\n\t\tr = -EFAULT;\n\t\tif (copy_from_user(&irq_event, argp, sizeof irq_event))\n\t\t\tgoto out;\n\t\tr = -ENXIO;\n\t\tif (irqchip_in_kernel(kvm)) {\n\t\t\t__s32 status;\n\t\t\tstatus = kvm_set_irq(kvm, KVM_USERSPACE_IRQ_SOURCE_ID,\n\t\t\t\t\tirq_event.irq, irq_event.level);\n\t\t\tif (ioctl == KVM_IRQ_LINE_STATUS) {\n\t\t\t\tr = -EFAULT;\n\t\t\t\tirq_event.status = status;\n\t\t\t\tif (copy_to_user(argp, &irq_event,\n\t\t\t\t\t\t\tsizeof irq_event))\n\t\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tr = 0;\n\t\t}\n\t\tbreak;\n\t}\n\tcase KVM_GET_IRQCHIP: {\n\t\t/* 0: PIC master, 1: PIC slave, 2: IOAPIC */\n\t\tstruct kvm_irqchip *chip;\n\n\t\tchip = memdup_user(argp, sizeof(*chip));\n\t\tif (IS_ERR(chip)) {\n\t\t\tr = PTR_ERR(chip);\n\t\t\tgoto out;\n\t\t}\n\n\t\tr = -ENXIO;\n\t\tif (!irqchip_in_kernel(kvm))\n\t\t\tgoto get_irqchip_out;\n\t\tr = kvm_vm_ioctl_get_irqchip(kvm, chip);\n\t\tif (r)\n\t\t\tgoto get_irqchip_out;\n\t\tr = -EFAULT;\n\t\tif (copy_to_user(argp, chip, sizeof *chip))\n\t\t\tgoto get_irqchip_out;\n\t\tr = 0;\n\tget_irqchip_out:\n\t\tkfree(chip);\n\t\tif (r)\n\t\t\tgoto out;\n\t\tbreak;\n\t}\n\tcase KVM_SET_IRQCHIP: {\n\t\t/* 0: PIC master, 1: PIC slave, 2: IOAPIC */\n\t\tstruct kvm_irqchip *chip;\n\n\t\tchip = memdup_user(argp, sizeof(*chip));\n\t\tif (IS_ERR(chip)) {\n\t\t\tr = PTR_ERR(chip);\n\t\t\tgoto out;\n\t\t}\n\n\t\tr = -ENXIO;\n\t\tif (!irqchip_in_kernel(kvm))\n\t\t\tgoto set_irqchip_out;\n\t\tr = kvm_vm_ioctl_set_irqchip(kvm, chip);\n\t\tif (r)\n\t\t\tgoto set_irqchip_out;\n\t\tr = 0;\n\tset_irqchip_out:\n\t\tkfree(chip);\n\t\tif (r)\n\t\t\tgoto out;\n\t\tbreak;\n\t}\n\tcase KVM_GET_PIT: {\n\t\tr = -EFAULT;\n\t\tif (copy_from_user(&u.ps, argp, sizeof(struct kvm_pit_state)))\n\t\t\tgoto out;\n\t\tr = -ENXIO;\n\t\tif (!kvm->arch.vpit)\n\t\t\tgoto out;\n\t\tr = kvm_vm_ioctl_get_pit(kvm, &u.ps);\n\t\tif (r)\n\t\t\tgoto out;\n\t\tr = -EFAULT;\n\t\tif (copy_to_user(argp, &u.ps, sizeof(struct kvm_pit_state)))\n\t\t\tgoto out;\n\t\tr = 0;\n\t\tbreak;\n\t}\n\tcase KVM_SET_PIT: {\n\t\tr = -EFAULT;\n\t\tif (copy_from_user(&u.ps, argp, sizeof u.ps))\n\t\t\tgoto out;\n\t\tr = -ENXIO;\n\t\tif (!kvm->arch.vpit)\n\t\t\tgoto out;\n\t\tr = kvm_vm_ioctl_set_pit(kvm, &u.ps);\n\t\tif (r)\n\t\t\tgoto out;\n\t\tr = 0;\n\t\tbreak;\n\t}\n\tcase KVM_GET_PIT2: {\n\t\tr = -ENXIO;\n\t\tif (!kvm->arch.vpit)\n\t\t\tgoto out;\n\t\tr = kvm_vm_ioctl_get_pit2(kvm, &u.ps2);\n\t\tif (r)\n\t\t\tgoto out;\n\t\tr = -EFAULT;\n\t\tif (copy_to_user(argp, &u.ps2, sizeof(u.ps2)))\n\t\t\tgoto out;\n\t\tr = 0;\n\t\tbreak;\n\t}\n\tcase KVM_SET_PIT2: {\n\t\tr = -EFAULT;\n\t\tif (copy_from_user(&u.ps2, argp, sizeof(u.ps2)))\n\t\t\tgoto out;\n\t\tr = -ENXIO;\n\t\tif (!kvm->arch.vpit)\n\t\t\tgoto out;\n\t\tr = kvm_vm_ioctl_set_pit2(kvm, &u.ps2);\n\t\tif (r)\n\t\t\tgoto out;\n\t\tr = 0;\n\t\tbreak;\n\t}\n\tcase KVM_REINJECT_CONTROL: {\n\t\tstruct kvm_reinject_control control;\n\t\tr =  -EFAULT;\n\t\tif (copy_from_user(&control, argp, sizeof(control)))\n\t\t\tgoto out;\n\t\tr = kvm_vm_ioctl_reinject(kvm, &control);\n\t\tif (r)\n\t\t\tgoto out;\n\t\tr = 0;\n\t\tbreak;\n\t}\n\tcase KVM_XEN_HVM_CONFIG: {\n\t\tr = -EFAULT;\n\t\tif (copy_from_user(&kvm->arch.xen_hvm_config, argp,\n\t\t\t\t   sizeof(struct kvm_xen_hvm_config)))\n\t\t\tgoto out;\n\t\tr = -EINVAL;\n\t\tif (kvm->arch.xen_hvm_config.flags)\n\t\t\tgoto out;\n\t\tr = 0;\n\t\tbreak;\n\t}\n\tcase KVM_SET_CLOCK: {\n\t\tstruct kvm_clock_data user_ns;\n\t\tu64 now_ns;\n\t\ts64 delta;\n\n\t\tr = -EFAULT;\n\t\tif (copy_from_user(&user_ns, argp, sizeof(user_ns)))\n\t\t\tgoto out;\n\n\t\tr = -EINVAL;\n\t\tif (user_ns.flags)\n\t\t\tgoto out;\n\n\t\tr = 0;\n\t\tlocal_irq_disable();\n\t\tnow_ns = get_kernel_ns();\n\t\tdelta = user_ns.clock - now_ns;\n\t\tlocal_irq_enable();\n\t\tkvm->arch.kvmclock_offset = delta;\n\t\tbreak;\n\t}\n\tcase KVM_GET_CLOCK: {\n\t\tstruct kvm_clock_data user_ns;\n\t\tu64 now_ns;\n\n\t\tlocal_irq_disable();\n\t\tnow_ns = get_kernel_ns();\n\t\tuser_ns.clock = kvm->arch.kvmclock_offset + now_ns;\n\t\tlocal_irq_enable();\n\t\tuser_ns.flags = 0;\n\t\tmemset(&user_ns.pad, 0, sizeof(user_ns.pad));\n\n\t\tr = -EFAULT;\n\t\tif (copy_to_user(argp, &user_ns, sizeof(user_ns)))\n\t\t\tgoto out;\n\t\tr = 0;\n\t\tbreak;\n\t}\n\n\tdefault:\n\t\t;\n\t}\nout:\n\treturn r;\n}",
        "func": "long kvm_arch_vm_ioctl(struct file *filp,\n\t\t       unsigned int ioctl, unsigned long arg)\n{\n\tstruct kvm *kvm = filp->private_data;\n\tvoid __user *argp = (void __user *)arg;\n\tint r = -ENOTTY;\n\t/*\n\t * This union makes it completely explicit to gcc-3.x\n\t * that these two variables' stack usage should be\n\t * combined, not added together.\n\t */\n\tunion {\n\t\tstruct kvm_pit_state ps;\n\t\tstruct kvm_pit_state2 ps2;\n\t\tstruct kvm_pit_config pit_config;\n\t} u;\n\n\tswitch (ioctl) {\n\tcase KVM_SET_TSS_ADDR:\n\t\tr = kvm_vm_ioctl_set_tss_addr(kvm, arg);\n\t\tif (r < 0)\n\t\t\tgoto out;\n\t\tbreak;\n\tcase KVM_SET_IDENTITY_MAP_ADDR: {\n\t\tu64 ident_addr;\n\n\t\tr = -EFAULT;\n\t\tif (copy_from_user(&ident_addr, argp, sizeof ident_addr))\n\t\t\tgoto out;\n\t\tr = kvm_vm_ioctl_set_identity_map_addr(kvm, ident_addr);\n\t\tif (r < 0)\n\t\t\tgoto out;\n\t\tbreak;\n\t}\n\tcase KVM_SET_NR_MMU_PAGES:\n\t\tr = kvm_vm_ioctl_set_nr_mmu_pages(kvm, arg);\n\t\tif (r)\n\t\t\tgoto out;\n\t\tbreak;\n\tcase KVM_GET_NR_MMU_PAGES:\n\t\tr = kvm_vm_ioctl_get_nr_mmu_pages(kvm);\n\t\tbreak;\n\tcase KVM_CREATE_IRQCHIP: {\n\t\tstruct kvm_pic *vpic;\n\n\t\tmutex_lock(&kvm->lock);\n\t\tr = -EEXIST;\n\t\tif (kvm->arch.vpic)\n\t\t\tgoto create_irqchip_unlock;\n\t\tr = -EINVAL;\n\t\tif (atomic_read(&kvm->online_vcpus))\n\t\t\tgoto create_irqchip_unlock;\n\t\tr = -ENOMEM;\n\t\tvpic = kvm_create_pic(kvm);\n\t\tif (vpic) {\n\t\t\tr = kvm_ioapic_init(kvm);\n\t\t\tif (r) {\n\t\t\t\tmutex_lock(&kvm->slots_lock);\n\t\t\t\tkvm_io_bus_unregister_dev(kvm, KVM_PIO_BUS,\n\t\t\t\t\t\t\t  &vpic->dev_master);\n\t\t\t\tkvm_io_bus_unregister_dev(kvm, KVM_PIO_BUS,\n\t\t\t\t\t\t\t  &vpic->dev_slave);\n\t\t\t\tkvm_io_bus_unregister_dev(kvm, KVM_PIO_BUS,\n\t\t\t\t\t\t\t  &vpic->dev_eclr);\n\t\t\t\tmutex_unlock(&kvm->slots_lock);\n\t\t\t\tkfree(vpic);\n\t\t\t\tgoto create_irqchip_unlock;\n\t\t\t}\n\t\t} else\n\t\t\tgoto create_irqchip_unlock;\n\t\tsmp_wmb();\n\t\tkvm->arch.vpic = vpic;\n\t\tsmp_wmb();\n\t\tr = kvm_setup_default_irq_routing(kvm);\n\t\tif (r) {\n\t\t\tmutex_lock(&kvm->slots_lock);\n\t\t\tmutex_lock(&kvm->irq_lock);\n\t\t\tkvm_ioapic_destroy(kvm);\n\t\t\tkvm_destroy_pic(kvm);\n\t\t\tmutex_unlock(&kvm->irq_lock);\n\t\t\tmutex_unlock(&kvm->slots_lock);\n\t\t}\n\tcreate_irqchip_unlock:\n\t\tmutex_unlock(&kvm->lock);\n\t\tbreak;\n\t}\n\tcase KVM_CREATE_PIT:\n\t\tu.pit_config.flags = KVM_PIT_SPEAKER_DUMMY;\n\t\tgoto create_pit;\n\tcase KVM_CREATE_PIT2:\n\t\tr = -EFAULT;\n\t\tif (copy_from_user(&u.pit_config, argp,\n\t\t\t\t   sizeof(struct kvm_pit_config)))\n\t\t\tgoto out;\n\tcreate_pit:\n\t\tmutex_lock(&kvm->slots_lock);\n\t\tr = -EEXIST;\n\t\tif (kvm->arch.vpit)\n\t\t\tgoto create_pit_unlock;\n\t\tr = -ENOMEM;\n\t\tkvm->arch.vpit = kvm_create_pit(kvm, u.pit_config.flags);\n\t\tif (kvm->arch.vpit)\n\t\t\tr = 0;\n\tcreate_pit_unlock:\n\t\tmutex_unlock(&kvm->slots_lock);\n\t\tbreak;\n\tcase KVM_IRQ_LINE_STATUS:\n\tcase KVM_IRQ_LINE: {\n\t\tstruct kvm_irq_level irq_event;\n\n\t\tr = -EFAULT;\n\t\tif (copy_from_user(&irq_event, argp, sizeof irq_event))\n\t\t\tgoto out;\n\t\tr = -ENXIO;\n\t\tif (irqchip_in_kernel(kvm)) {\n\t\t\t__s32 status;\n\t\t\tstatus = kvm_set_irq(kvm, KVM_USERSPACE_IRQ_SOURCE_ID,\n\t\t\t\t\tirq_event.irq, irq_event.level);\n\t\t\tif (ioctl == KVM_IRQ_LINE_STATUS) {\n\t\t\t\tr = -EFAULT;\n\t\t\t\tirq_event.status = status;\n\t\t\t\tif (copy_to_user(argp, &irq_event,\n\t\t\t\t\t\t\tsizeof irq_event))\n\t\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tr = 0;\n\t\t}\n\t\tbreak;\n\t}\n\tcase KVM_GET_IRQCHIP: {\n\t\t/* 0: PIC master, 1: PIC slave, 2: IOAPIC */\n\t\tstruct kvm_irqchip *chip;\n\n\t\tchip = memdup_user(argp, sizeof(*chip));\n\t\tif (IS_ERR(chip)) {\n\t\t\tr = PTR_ERR(chip);\n\t\t\tgoto out;\n\t\t}\n\n\t\tr = -ENXIO;\n\t\tif (!irqchip_in_kernel(kvm))\n\t\t\tgoto get_irqchip_out;\n\t\tr = kvm_vm_ioctl_get_irqchip(kvm, chip);\n\t\tif (r)\n\t\t\tgoto get_irqchip_out;\n\t\tr = -EFAULT;\n\t\tif (copy_to_user(argp, chip, sizeof *chip))\n\t\t\tgoto get_irqchip_out;\n\t\tr = 0;\n\tget_irqchip_out:\n\t\tkfree(chip);\n\t\tif (r)\n\t\t\tgoto out;\n\t\tbreak;\n\t}\n\tcase KVM_SET_IRQCHIP: {\n\t\t/* 0: PIC master, 1: PIC slave, 2: IOAPIC */\n\t\tstruct kvm_irqchip *chip;\n\n\t\tchip = memdup_user(argp, sizeof(*chip));\n\t\tif (IS_ERR(chip)) {\n\t\t\tr = PTR_ERR(chip);\n\t\t\tgoto out;\n\t\t}\n\n\t\tr = -ENXIO;\n\t\tif (!irqchip_in_kernel(kvm))\n\t\t\tgoto set_irqchip_out;\n\t\tr = kvm_vm_ioctl_set_irqchip(kvm, chip);\n\t\tif (r)\n\t\t\tgoto set_irqchip_out;\n\t\tr = 0;\n\tset_irqchip_out:\n\t\tkfree(chip);\n\t\tif (r)\n\t\t\tgoto out;\n\t\tbreak;\n\t}\n\tcase KVM_GET_PIT: {\n\t\tr = -EFAULT;\n\t\tif (copy_from_user(&u.ps, argp, sizeof(struct kvm_pit_state)))\n\t\t\tgoto out;\n\t\tr = -ENXIO;\n\t\tif (!kvm->arch.vpit)\n\t\t\tgoto out;\n\t\tr = kvm_vm_ioctl_get_pit(kvm, &u.ps);\n\t\tif (r)\n\t\t\tgoto out;\n\t\tr = -EFAULT;\n\t\tif (copy_to_user(argp, &u.ps, sizeof(struct kvm_pit_state)))\n\t\t\tgoto out;\n\t\tr = 0;\n\t\tbreak;\n\t}\n\tcase KVM_SET_PIT: {\n\t\tr = -EFAULT;\n\t\tif (copy_from_user(&u.ps, argp, sizeof u.ps))\n\t\t\tgoto out;\n\t\tr = -ENXIO;\n\t\tif (!kvm->arch.vpit)\n\t\t\tgoto out;\n\t\tr = kvm_vm_ioctl_set_pit(kvm, &u.ps);\n\t\tif (r)\n\t\t\tgoto out;\n\t\tr = 0;\n\t\tbreak;\n\t}\n\tcase KVM_GET_PIT2: {\n\t\tr = -ENXIO;\n\t\tif (!kvm->arch.vpit)\n\t\t\tgoto out;\n\t\tr = kvm_vm_ioctl_get_pit2(kvm, &u.ps2);\n\t\tif (r)\n\t\t\tgoto out;\n\t\tr = -EFAULT;\n\t\tif (copy_to_user(argp, &u.ps2, sizeof(u.ps2)))\n\t\t\tgoto out;\n\t\tr = 0;\n\t\tbreak;\n\t}\n\tcase KVM_SET_PIT2: {\n\t\tr = -EFAULT;\n\t\tif (copy_from_user(&u.ps2, argp, sizeof(u.ps2)))\n\t\t\tgoto out;\n\t\tr = -ENXIO;\n\t\tif (!kvm->arch.vpit)\n\t\t\tgoto out;\n\t\tr = kvm_vm_ioctl_set_pit2(kvm, &u.ps2);\n\t\tif (r)\n\t\t\tgoto out;\n\t\tr = 0;\n\t\tbreak;\n\t}\n\tcase KVM_REINJECT_CONTROL: {\n\t\tstruct kvm_reinject_control control;\n\t\tr =  -EFAULT;\n\t\tif (copy_from_user(&control, argp, sizeof(control)))\n\t\t\tgoto out;\n\t\tr = kvm_vm_ioctl_reinject(kvm, &control);\n\t\tif (r)\n\t\t\tgoto out;\n\t\tr = 0;\n\t\tbreak;\n\t}\n\tcase KVM_XEN_HVM_CONFIG: {\n\t\tr = -EFAULT;\n\t\tif (copy_from_user(&kvm->arch.xen_hvm_config, argp,\n\t\t\t\t   sizeof(struct kvm_xen_hvm_config)))\n\t\t\tgoto out;\n\t\tr = -EINVAL;\n\t\tif (kvm->arch.xen_hvm_config.flags)\n\t\t\tgoto out;\n\t\tr = 0;\n\t\tbreak;\n\t}\n\tcase KVM_SET_CLOCK: {\n\t\tstruct kvm_clock_data user_ns;\n\t\tu64 now_ns;\n\t\ts64 delta;\n\n\t\tr = -EFAULT;\n\t\tif (copy_from_user(&user_ns, argp, sizeof(user_ns)))\n\t\t\tgoto out;\n\n\t\tr = -EINVAL;\n\t\tif (user_ns.flags)\n\t\t\tgoto out;\n\n\t\tr = 0;\n\t\tlocal_irq_disable();\n\t\tnow_ns = get_kernel_ns();\n\t\tdelta = user_ns.clock - now_ns;\n\t\tlocal_irq_enable();\n\t\tkvm->arch.kvmclock_offset = delta;\n\t\tbreak;\n\t}\n\tcase KVM_GET_CLOCK: {\n\t\tstruct kvm_clock_data user_ns;\n\t\tu64 now_ns;\n\n\t\tlocal_irq_disable();\n\t\tnow_ns = get_kernel_ns();\n\t\tuser_ns.clock = kvm->arch.kvmclock_offset + now_ns;\n\t\tlocal_irq_enable();\n\t\tuser_ns.flags = 0;\n\t\tmemset(&user_ns.pad, 0, sizeof(user_ns.pad));\n\n\t\tr = -EFAULT;\n\t\tif (copy_to_user(argp, &user_ns, sizeof(user_ns)))\n\t\t\tgoto out;\n\t\tr = 0;\n\t\tbreak;\n\t}\n\n\tdefault:\n\t\t;\n\t}\nout:\n\treturn r;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -46,6 +46,9 @@\n \t\tmutex_lock(&kvm->lock);\n \t\tr = -EEXIST;\n \t\tif (kvm->arch.vpic)\n+\t\t\tgoto create_irqchip_unlock;\n+\t\tr = -EINVAL;\n+\t\tif (atomic_read(&kvm->online_vcpus))\n \t\t\tgoto create_irqchip_unlock;\n \t\tr = -ENOMEM;\n \t\tvpic = kvm_create_pic(kvm);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t\t\tgoto create_irqchip_unlock;",
                "\t\tr = -EINVAL;",
                "\t\tif (atomic_read(&kvm->online_vcpus))"
            ]
        }
    }
]